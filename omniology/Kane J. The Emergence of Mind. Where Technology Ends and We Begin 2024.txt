Jeffrey Kane
The Emergence of Mind
Where Technology Ends 
and We Begin

The Emergence of Mind

Jeffrey Kane
The Emergence of 
Mind
Where Technology Ends and We Begin

ISBN 978-3-031-46834-6        ISBN 978-3-031-46835-3  (eBook)
https://doi.org/10.1007/978-3-031-46835-3
© The Editor(s) (if applicable) and The Author(s), under exclusive licence to Springer 
Nature Switzerland AG 2024
This work is subject to copyright. All rights are solely and exclusively licensed by the 
Publisher, whether the whole or part of the material is concerned, specifically the rights of 
translation, reprinting, reuse of illustrations, recitation, broadcasting, reproduction on 
microfilms or in any other physical way, and transmission or information storage and retrieval, 
electronic adaptation, computer software, or by similar or dissimilar methodology now 
known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this 
publication does not imply, even in the absence of a specific statement, that such names are 
exempt from the relevant protective laws and regulations and therefore free for general use.
The publisher, the authors, and the editors are safe to assume that the advice and information 
in this book are believed to be true and accurate at the date of publication. Neither the 
publisher nor the authors or the editors give a warranty, expressed or implied, with respect to 
the material contained herein or for any errors or omissions that may have been made. The 
publisher remains neutral with regard to jurisdictional claims in published maps and 
institutional affiliations.
This Palgrave Macmillan imprint is published by the registered company Springer Nature 
Switzerland AG.
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland
Paper in this product is recyclable.
Jeffrey Kane
Philosophy and Teaching and Learning
Long Island University
Brookville, NY, USA

To Shai, Rami and those who will follow them in bringing light and hope 
into the world

vii
To the extent that this book shares something of substance, the voices of 
many others from generations past and in my life may be heard in my 
words. They are too numerous to mention, but I must acknowledge my 
debt and express my gratitude to all of them. In particular, I thank the 
great teachers of my life, Sheldon Stoff and John Fentress Gardner, whose 
lessons continue to unfold within me.
There have been many colleagues who have read through endless drafts 
of chapter after chapter to give this book both its form and its substance. 
Early on, my colleague Mike Kavic helped me explore the fundamental 
concepts of relational science. As I struggled with my ideas, Howard 
Gardner encouraged me to write confidently from my own experience and 
in my own voice. As the contours of the book emerged, Mike Gazzaniga 
showed endless patience in helping me expand and refine my thinking. 
Throughout, my colleague and friend Ron Schneebaum spent hours in 
conversation with me exploring the nuances of the human experience of 
thinking. My son, Jesse, offered critical analyses and insightful advice, and 
my daughter Emily provided her unwavering encouragement to pursue 
my passion. Other colleagues have also provided helpful criticism and 
advice along the way. I am grateful particularly to Mike Soupois, Lori 
Knapp, and my doctoral students.
Lastly, I must thank my wife Janet who reviewed every chapter through 
multiple iterations, offering astute criticisms, thoughtful suggestions, and 
untiring support. This work would not have been possible without her.
Acknowledgments

ix
Why This Book?
I write in the belief that there are many individuals who, like me, find the 
sheer power and sophistication of Generative Artificial Intelligence both 
awe inspiring and disturbing. Daily articles flood the internet attempting 
to demystify its processing systems. Others, just as often, raise the alarm 
that this new technology will, if left unchecked, destroy personal privacy, 
if not humanity itself. For all the insights they provide, all of them reflect 
an abiding uncertainty about what our new- found power means for 
the world.
That uncertainty is not only about the world around us, but, to be 
direct, about what lies within us. While we may wonder how the technol­
ogy can write original poetry or explain the inner conflicts tearing at 
Hamlet, or detail the nuances of quantum mechanics, we may wonder if 
there is more to human beings thinking than to computers performing 
trillions of operations a second. Are our ideas shaped by our experience of 
meanings that cannot be understood in computational terms? Is here 
more to our existence as conscious, self-aware beings than can be reduced 
to the laws governing the physical matter of our bodies?
To forego any suspense, I argue that the answer to both questions is 
“yes.” However, the pursuit of the answer is not simple. The discussion 
involves complex concepts in multiple disciplines such as physics, biology, 
computer science, psychology, and philosophy. Any attempt to address 
them in depth would lead us into an ocean of tangents, for both scholars 
and the general population. Thus, the book is based on the basic principle 

x 
Why This Book?
that it must be accessible to anyone who would care enough to ask the 
question and rigorous enough to stand the test of critical reflection. Its 
purpose is to provide clear pathways into and through the fundamental 
gap between information processing and human thinking. It is intended 
to engage readers in the experience of ideas and to understand their mean­
ing to us as human beings.

xi
Contents
	1	 Writing the Human Narrative
    1
	2	 Where We Begin
    9
Where Do We Begin?
      9
From Consciousness to Computation
    12
The Experience of Mind and Body
    15
The Science of Reductionism
    19
Understanding Ourselves
    22
The Union of Mind and Body
    24
	3	 The Science of Mindlessness
  27
Two Selves
    27
Thinking and the “Thinking Thing”
    29
Descartes’ Mind Turned Inside Out
    31
The Mind of the Human Animal
    32
Complexity Overwhelms the Animal Paradigm
    36
Computation and the Beginning of the Imitation Game
    38
Computation as an Empirical Lens
    39
The Cognitive Revolution
    42
The Inversion of the Metaphor
    45
	4	 Where Computation Ends
  49
Defining Computation and Computational Systems
    49
The Invariance of Computational Systems
    53

xii
The Limits of a Functional View of Intelligence
    54
When DNA Programs
    56
On the Subjective as Objective
    59
The Easy and the Hard Questions
    62
Between Syntax and Semantics
    64
Life Matters
    67
	5	 Relational Science
  71
Beyond the Boundaries of Empirical Reductionism
    71
Quantum Fields
    77
From Uncertainty to Organization
    80
Dissipative Systems
    83
Multiple Levels of Emergence
    85
	6	 Life and Mind
  89
Life Defines Itself
    89
Enactive Emergence
    91
The Importance of Constraint
    96
Agency
    97
Sentience
    99
Mind
  102
The Emergence of Social Evolution
  102
The Interplay of Biological and Social Evolution
  104
The Emergence of Symbolic Language
  105
The Continuity of Body and Mind
  109
The Emergence of Post-Biological Intelligence
  111
	7	 Thinking as a Creative Act
113
The Experience of Ideas
  113
A New Compass
  115
The Reality of Thought
  117
Living Ideas
  119
The Quest for Coherence
  121
Indwelling
  124
Intuition
  127
Imagination
  129
The Role of Formal Systems
  130
The Role of Logic
  132
The Creation of Meaning
  134
 
Contents

xiii
	8	 Emerging Minds
137
The Agency of Intelligence
  137
The Light from Within
  140
Child’s Play
  142
Biological Indwelling and Insight
  144
Shared Awareness and Learning
  147
The Emergence of Ideas
  149
Learning Not to Think
  151
The Self as Object
  153
The Reality of Self
  155
The Creation of Self
  156
Index
163
  Contents 

1
CHAPTER 1
Writing the Human Narrative
In December of 2022, we entered a new age, an Age of Generative 
Artificial Intelligence. That month, OpenAI, an artificial intelligence 
research lab, introduced ChatGPT3, an AI tool, much like an app, that 
can generate original poetry and prose, summarize massive sets of diverse 
documents, translate languages, write original computer programs, and 
engage in extended discussions with human beings with varied responses 
based upon the flow of ideas. Even in this early stage of development, 
ChatGTP3 was able to pass multiple-choice and essay exams at the gradu­
ate level. In many cases, any differences between the output produced by 
the tool and human linguistic expression are virtually indistinguishable.
Behind the words and images generated lies the largest scale neural 
network ever constructed. At present, it contains an informational base of 
175 billion variables that it uses to analyze and produce natural language 
and images. Essentially, it includes the information searchable on the 
internet and digitized texts from journals, newspapers, and books. In gen­
eral terms, it is an example of a Large Language Model processor in which 
the data yields syntactical patterns for words and phrases that can then be 
applied to the construction of responsive linguistic sequences. The net 
effect is that the output resembles the semantic character of human-­
generated language.
Microsoft has invested an additional $10,000,000,000 in OpenAI, but 
there are also other players on the scene. A number of start-ups have 
attracted huge investments, and Google has already built a rival Chatbot, 
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2024
J. Kane, The Emergence of Mind, 
https://doi.org/10.1007/978-3-031-46835-3_1

2
LaMDA, that will likely be released as soon as solutions are found to a 
number of issues related to business strategy and content quality. Google 
and Meta are designing word and image search engines and generative 
products and previously unimaginable applications for products like Siri 
and Alexa and virtually any computationally-adaptable device. The impact 
on the global economy will very likely run into trillions of dollars and 
transform many industries, as well as daily life.
As these advances in Al make their way to the market, they will con­
tinue to improve and open yet unimagined possibilities. OpenAI released 
ChatGPT4 in March, 2023, and ChatGPT5 is already in development. In 
the near future, we should expect AI tools that will be able to design archi­
tectural structures, create video games and personalized movies, and write 
programs with greater complexity than human programmers. It holds the 
promise of transformative discoveries in science, such as finding effective 
treatments for cancer and other diseases. The same holds true in various 
fields of engineering, such as designing clean sources of energy to power 
the world. So too can they create viral illusions that tear at the institutions 
that make civilization possible.
Whatever choices we make, such technology not only empowers but 
obscures its limitations. The researchers’ engineering generative AI tech­
nologies know fully well that their creations lack key dimensions of the 
human mind. Their systems lack the processing capacity to effectively rep­
licate basic human skills, such as the ability to work around their own 
internal problems or to exercise common sense. They cannot generalize 
what they learn in one context to new and different circumstances. The 
programs can generate complex probabilities but cannot understand the 
concept of causes that a three-year-old takes for granted. Although the 
great majority of leading engineers understand that AI tools are not sen­
tient and have no agency or purpose of their own, the general public, 
being unaware of processes, does not grasp the void that lies behind its 
linguistic products. The words generated are as devoid of meaning as a 
mudslide.
However, we are just at the outset of the development of generative AI 
systems. These problems may be seen as technical challenges that will fade 
with every passing year. The present gap between human thinking and 
information processors may appear to be a matter of algorithmic architec­
ture and computational power rather than differences in their fundamen­
tal nature. As Alan Turing, the father of the modern computer, wrote over 
70 years ago, when the products of computational machines and human 
 
J. KANE

3
beings are indistinguishable, any differences between them will become 
superfluous. If that day is not now upon us, it will be soon.
In the coming years the power and ubiquity of technology may lead the 
general public to revel in its utility rather than question if there are hidden 
yet essential dimensions to the human mind that take form in our think­
ing. The idea will be dismissed uncritically as the once-upon-a-time pro­
jection of deities into thunderstorms and the cycles of the moon.
However, if Turing proves to be correct, it will not be because technol­
ogy has effectively replicated the human mind, but the misguided measure 
of his test. If we were to assess any differences between human thinking 
and the output of information processors, a statistical comparison of their 
syntax would be most appropriate. If thinking is a matter of syntactical 
patterns, the patterns produced can be compared objectively. Yet, Turing 
suggests that subjective human judgment ought to be the measure of the 
efficacy of programs producing natural language. Thus, he compares the 
two not relative to their respective syntactical patterns but to their confor­
mity with the semantic meanings elicited by language.
As human beings, we tend to understand things in terms of our own 
experience. When we hear language, or see it written, we understand the 
words as having meaning based upon our own experience. When we hear 
the word “blue,” we associate it with our own experience of the color. In 
this context, we give the language produced by generative AI tools our 
own experience of meaning. However, no matter how much the words 
produced seem to be just like our own, they have no meaning whatsoever. 
There is no experience of color in the word “blue”; there is no taste in the 
word “sweet”; there is no life weighed in the words “to be or not to be.” 
Generative AI products, no matter how much they may resemble our pat­
terns of language, have no more depth of meaning that a child’s “magic 
eight ball.”
Generative AI cannot apprehend even the most basic elements of com­
mon human experience. Computer scientist Yejin Choi explains that these 
elements that are so fundamental to our thinking that we don’t even 
notice them, they are what she calls “dark matter” of intelligence. In the 
physical universe, only about 5% of all matter and energy is observable 
even with the most sophisticated instruments. We know nothing about 
the remaining 95% of matter and energy other than that they affect the 
gravitational force and speed of expansion of the universe. Our models of 
the expansion of the universe would make no sense without them. 
Similarly, there is in human thinking a tacit foundation that allows us to 
1  WRITING THE HUMAN NARRATIVE 

4
make sense of the world. It serves as the foundation of logic and reason; it 
serves as the origin of ideas and the organizational principles of our sys­
tems of thought. The sources of the meaning of our ideas and organiza­
tion in our thinking lie deep beneath the surface of the words inked on a 
page or the sounds produced by a speaker.
The words we use, the thoughts that unfold as we speak and write, are 
like water taken from an underground stream: we can access the source 
but it remains ever-flowing beneath the surface. Their meaning is subject 
to the laws of language but the meaning that creates them—that gives 
purpose to their existence—is not found within the words themselves or 
their patterns. All meaning is deeply rooted in our lives and experience as 
human beings. It is that experience of meaning that resonates within us as 
we hear and read words; it is that experience that differentiates our words 
from algorithm. Understanding that we cannot directly perceive the sub­
jective origins of the experience of other human beings, the question arises 
as how we can understand the substance and form of our experience as the 
foundation of the human mind.
Consider that generative AI systems are designed to be responsive to 
prompts. They answer questions; they direct their functions toward objec­
tives set for them. Human beings, on the other hand, ask questions. We 
have things that we wish to know; we seek something we value, something 
that responds to purposes that extend beyond the answers themselves. We 
do not listen to the weather report to analyze meteorological information, 
but to refine some of the choices we will make about the coat we will wear 
or the region where we might like to move, or whether or not we will buy 
an electric car. We ask questions in the context of the things we value, 
great and small.
We attend to the information we receive as a source of illumination, as 
a means of coherence that we might guide ourselves in our actions. We 
don’t simply identify patterns in phenomena as do generative systems, but 
seek coherence in that which we value. On a primitive level, we may value 
food and shelter and attend to the environment around us in search of 
clues to the resources we cannot yet apprehend.
Yet, we are not simply primitive beings. We not only hunger for food 
but for human community; we seek others to share experience. Not only 
driven by a need to secure our interests in challenging environments we 
create bonds with others that help us unfold our capacities beyond our 
individual interests. The bonds we form emerge as new elements of our 
environment with its own unknown dimensions that we explore with 
 
J. KANE

5
questions. Among them is our identity and the nature of those around us 
much like ourselves.
Neither are we simply social animals, but conscious beings. We are 
aware of our own consciousness—that we exist in some independent way 
in a surrounding universe of apparent otherness. We seek to understand our 
own existence… our origin, our place, our fate. We ask how in this mys­
tery we ought to live our lives. What shall we value? Do we have reason to 
temper ourselves or to live with purpose beyond our own gratification? 
These are not incidental questions but central to the creation of the 
world’s spiritual traditions, to the formation of civilizations, to our great­
est works of literature, to our most expansive conceptions of the universe.
The questions that guide us in living our lives and in shaping who we 
are, both individually and collectively, are not about ourselves as physical 
beings only, but as physical beings imbued with the mystery of conscious­
ness. Whether we conclude that we are self-replicating strands of DNA or 
children of divine origin, the question asked is one and the same. We can­
not deny that we ask it. But we can forget that we do and that the pursuit 
of the question itself is essential to transform human beings into 
being human.
This is not to suggest that we must continuously occupy ourselves with 
the ultimate questions of our existence, but to propose that the very power 
of generative AI to answer questions and to find patterns responsive to 
them can obscure the type of thinking needed to understand what ques­
tions ought to be asked and what ends sought. These are the questions 
that play out in the day-to-day, in listening to the weather report and 
deciding how each day of our lives will be spent. It is not in the grand 
declarations but in life lived, in the choices we make in the way we treat 
others, in the food we eat, the companions we choose, in the way we treat 
others we encounter and ultimately, the way we think about who we are 
and what we ought to value. The very reason there is so much concern 
that generative AI poses such a threat to humankind is that the programs 
cannot ask these questions. It is not guided by any intention or its own 
chosen objectives. Its power is not inherently nefarious but disintegrative; 
it dissolves all order and purpose within a system that itself has no order or 
purpose. It reduces all ideas into a vast universe of zeros and ones where 
none has any claim to meaning or value beyond the zeros and ones them­
selves or the relations between them.
In this context, its vacuousness as a domain, its syntactical operational 
structures and its lack of purpose make it the ideal vessel for the inscription 
1  WRITING THE HUMAN NARRATIVE 

6
of externally determined content and intent. It is a perfect model of mind 
so long as the mind itself is removed from all else in the universe, including 
most notably a living body, and void of all experience. All that can exists 
as meaning and purpose is defined exclusively as syntax. With the elevation 
of syntax as meaning comes the dissociation of thinking from being, and 
any sources of order or form their union might promote. When thinking 
is defined as information processing, the spectrum of human experience 
contracts to black and white, to patterns of zeros and ones.
Turing referred to his test as “the imitation game,” the capacity for 
computational programs to imitate the patterns of human language. 
Imitation is not creation. While human beings imitate, we are also capable 
of creation, of imagining principles of coherence that can express them­
selves in ways unprecedented and unique. Creation is not a variation on a 
theme, the application of a rule or the completion of a pattern. The act of 
creating is not defined by its product but by the envisioning of new pos­
sibilities that break existing patterns. My capacity to play a piece of music 
in the style of Mozart does not mirror his genius. The ability to write a 
sonnet in the style of Shakespeare does not, as he did, illuminate the 
human condition. The mimicry of the patterns of speech of a five-year-old 
does not reveal the source of the endless questions about the blueness of 
sky to why dogs have tails. Words have meaning only as they emerge from 
lived experience or as they direct us to dwell within the images they evoke.
Ironically, many of the leading researchers into the human mind and 
human thinking have turned to information processing and computational 
modeling as a framework for understanding. Recognizing that subjective 
experience is, by definition, personal rather than public, many psycholo­
gists, philosophers, and neuroscientists have sought to ground their 
research in empirical data. Within that framework, human thinking may be 
defined as systems of verbal behavior or neurochemical activities. In both 
cases, the data is based upon the reduction of the phenomena observed 
into the smallest discrete elements possible, which is then fitted into sys­
tematic, largely mathematical, form. Thus, the frameworks used necessar­
ily and absolutely define human thinking in algorithmic code. Thus, we 
come full circle; the very assumptions we use to understand the generative 
foundations of human thinking effectively preclude their existence. The 
model of thinking that underlies generative AI, and the computational 
theories of mind that dominate contemporary philosophy and psychology 
begin with the exclusion of our experience of being alive, as having sensa­
tions and being conscious. To the extent that such a model guides us in 
 
J. KANE

7
our thinking and in the cultivation of the cognitive capacities of future 
generations, we will, with increasing force, alienate ourselves from our 
own humanity and the world around us. The introduction of generative 
AI now forces us to confront ourselves with the question of the origins 
and formative dimensions of our minds that guide us to create coherent 
systems of thought with both meaning and purpose.
Generative AI is the embodiment of the human mind envisioned by 
computational theorists. The fact that we are living  and conscious 
beings capable of self-awareness and self-directed choice is dismissed from 
consideration as only so much informational input and output. The pur­
pose of this book is to challenge that concept and offer an alternative in 
which life and consciousness are central to the creation of human thought. 
It is not intended to present an exhaustive study of generative AI, compu­
tational theories of mind, or the biological origins of consciousness. All 
these fields have rich literatures of their addressing complex and nuanced 
issues. All of them offer insights in their respective domains. That preci­
sion is achieved through a narrowing of focus. When we use telescopes to 
peer at distant stars, the vastness of the universe that stretches out before 
us can be lost.
In contrast to consideration of disciplinary questions and disputes 
regarding the nature of the human mind and human thinking, our intent 
is to revisit the broader aspects of the human condition that can be lost in 
such contexts. For example, rather than focusing on the statistical identi­
fication of the syntactical processes used to produce language, our inquiry 
focuses on subjective experience as the foundation for the meaning and 
form of our thoughts, from the most basic utterings of infants to the high­
est of human intellectual achievements. Our thinking does not simply 
occur; it occurs intentionally. The ideas that take form in our minds have 
meaning and purpose that lie beyond the reach of a statistical analysis of 
language.
We ground our work in the realities we experience, realities that initiate 
action and that enable us to create coherent systems of thought. We pro­
pose that human thinking is rooted in our being—in all that we are physi­
cally, biologically, socially, and consciously. Our thinking embodies 
purposes that are nowhere to be found in the properties of quantum par­
ticles or even in molecules of DNA.  Physics  and chemistry make the 
human story possible but don’t control the narrative. Our experiences as 
sentient and conscious beings are active within us. They are not mere bits 
of information stored but active elements of the mind itself. They are the 
1  WRITING THE HUMAN NARRATIVE 

8
vague feelings and images that underlie the questions we ask and judg­
ments we make, even in the most abstract and seemingly impersonal 
circumstances.
We are at a rare moment in history where either we challenge the self-­
imposed limits of our understanding of our minds or allow technology 
itself to define us in its image. This initial exploration of the human mind 
as in the act of emergence is not intended as a final statement but as an 
invitation to dialogue, one that will hopefully lead to heightened levels of 
creativity and insight in all domains of human activity.
 
J. KANE

9
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2024
J. Kane, The Emergence of Mind, 
https://doi.org/10.1007/978-3-031-46835-3_2
CHAPTER 2
Where We Begin
Whatever we think of the stars, they are what they are and will be what 
they will be. Whatever we think of ourselves we will become.
Where Do We Begin?
What, if anything, distinguishes human thinking from digital information 
processing? The answer we find will depend upon the way we respond to 
a more fundamental question about who and what we are as human 
beings: recognizing that each of us experiences ourselves as conscious 
beings and as physically embodied, what is the connection between these 
two dimensions of our existence?
­
1
1 Ganzer, Patrick D., et.al. “Restoring the Sense of Touch Using a Sensorimotor 
Demultiplexing Neural Interface.” Cell, vol. 181, issue 4, 2020, pp. 763–773.

10
As remarkable as this achievement is, Ian’s case is but one example of a 
growing field of research and technological development called Brain-­
Computer Interface (BCI)—one of any number of similar fields all point­
ing to the physical integration of neural and digital computational systems. 
Beginning in early 1970s, researchers began to build upon the use of elec­
troencephalograms (EEGs) to analyze neural activity. Given the almost 
unimaginable numbers of neurons and neural connections, identifying 
meaningful patterns among them required the development of powerful 
computers and complex algorithms. As Ian’s case demonstrates, technol­
ogy has now advanced sufficiently to interpret specific patterns of neural 
activity to direct communication between his brain and his implanted 
non-human computational device.
That technology is not limited to neuro/physio prostheses, but now 
includes the communication of language. In July 2019, Facebook pub­
lished an article describing advancements in the use of sensors and 
advanced algorithms to discern unspoken words directly from cortical 
activity. Since then, the field has grown rapidly, with considerable invest­
ments being made by the corporate sector. One particular effort is Elon 
Musk’s well-funded Neuralink Corporation, first founded in 2016. Now a 
publicly traded company, it may be on its way to developing a generalized 
neural prosthesis that researchers believe could be used to support or 
replace neural functions virtually anywhere in the brain. Musk explains 
that Neuralink’s plan is focused on the development of an implantable 
device that would extend cognitive processing seamlessly into a “digital 
layer above the cortex.” This “digital lace” as he calls it, would form a 
“symbiotic” relationship with the brain with each exchanging information 
and integrating functions with the other.
While some of these ambitions might seem most appropriate for science 
fiction novels, the same could have been said of Startrek’s Captain Kirk’s 
now outdated old-style flip phone. (Musk’s interest in neural implantation 
devices actually began with his reading of the science fiction book series, 
The Culture, by Lain Banks.) The advancement of technology is inevita­
ble, but just how far will it go? Will it one day be possible to replace entire 
regions of the brain? If so, could we replace multiple regions and eventu­
ally the brain in its entirety? While such questions might seem laughably 
impracticable, what makes us think that any limits exist? How far would be 
 
J. KANE

11
too far? What could act as a boundary of the brain function that could 
separate the activity of carbon-based neurons from silicon-based circuits?
If we maintain that the function of neurons is to transfer bits of informa­
tion between themselves in complex patterns we otherwise call brain activ­
ity—whether that activity controls the secretion of bile in the liver or the 
choices made in answering a question in math class—why could that same 
function not be performed by sufficiently developed computer systems? If 
the brain is a biological information processor, then all that stands between 
us and machines must be reducible to engineering. In this context, reason 
demands that once the functional information processes of neural activity 
responsible for thinking are disassembled, they can be used to reverse engi­
neer  a system functionally  equivalent to  a human brain.  Any differences 
between such a technology and our minds would be meaningless: in effect, 
there would no aspect of our minds beyond the reach of technology or place 
where our thinking might exist uniquely within us as living human beings. 
Within this framework, any seemingly irreducible aspects of our minds 
such as our experience of sensation or conscious self-awareness merely 
feed into the system; they have no causal power. At most, they are the 
products of neural processes and do not of themselves have any power to 
affect the course of processing. Whether the algorithms that govern our 
thinking are the result of the laws of physics expressed in a biological 
entity or of codes buried in our DNA, they alone determine what and how 
we think.
If our thinking amounts to the processing of information, and process­
ing according to the laws of physics as they govern biological functions, 
our feelings, beliefs, and values play absolutely no role. In fact, nothing in 
human experience—from a child wanting his parent when waking from a 
nightmare to Michelangelo’s inspiration in sculpting David could be any­
thing more than molecular statistics.
In this context, the physical universe is a closed causal system: all that 
exists and all that can exist in the physical universe owes its existence and 
attributes to the properties of the most elementary of all particles of mat­
ter. There are no exceptions, not even for the human mind. Our con­
sciousness and all that we think, feel or value, are products of the 
interactions of quantum particles, with no causal power of their own. In 
essence, mind is a function of matter.
However, just as the notion of unembodied creative forces offers us 
little when attempting to understand how they exert their influence of the 
physical world, the leap from the properties of quantum particles to life, 
2  WHERE WE BEGIN 

12
sentience, and mind is no less a daunting matter. In the final analysis, in a 
closed physical system, if consciousness exists in the way of subjective 
experience, it lies ineffectually outside of the laws that govern the universe. 
It has no power to serve as a source of intention or affect any change in 
the course of events—even the course of events in our own minds.
From Consciousness to Computation
One of the primary frameworks in present-day philosophy and psychology 
is that the human mind, like any other phenomenon, can be understood 
in terms of its observable patterns of behavior. The “behavior” that can be 
observed is linguistic. In this context, linguistic behavior is not viewed as 
a form of symbolic representation any more than a thunderstorm might be 
interpreted as a sign of Thor’s anger. As an empirical phenomenon, it sim­
ply is what it is. It exhibits structural patterns that can be represented in 
mathematical models just like meteorological systems that determine the 
path of a storm. We may have bodily sensations or emotions or an experi­
ence of the significance of an event or idea, but they are not factors that 
need to be considered to construct a model of the thinking as a process. 
When the conscious mind is defined in terms of the linguistic patterns, our 
subjective experiences of emotion or sensation are simply irrelevant.
This separation of consciousness from the realm of subjective experi­
ence is deeply embedded in intellectual traditions dating back to ancient 
Greece but became a defining methodological element of modern science 
in the work of the seventeenth-century French philosopher, Rene 
Descartes. His method was deceptively simple: doubt everything that can 
be doubted and accept as true only that which you can affirm with your 
own mind. The most effective way to do that, he reasoned, was to reduce 
all phenomena to their most basic components and to connect them by 
the use of reason alone. At the outset, he recognized that he could doubt 
everything that came to him through his senses, even the existence of his 
own body.
However, he could not doubt that he was thinking. Even if the content 
of thoughts could be mistaken, he reasoned that he could not be mistaken 
about the fact that he experienced himself thinking. Following upon that 
realization, he concluded that he could be absolutely certain that he 
existed as a thinker. However, he did not attribute to this thing he called 
his “self” anything other than that it must exist and that it has the capacity 
to think. He defined it as a “thinking thing.” In so doing, he shifted his 
 
J. KANE

13
focus from the indisputable experience of his own thinking to his existence 
as an object that lay outside of his experience. He moved from a founda­
tion in the subjective experience of thinking to the elimination of that very 
experience as a domain of inquiry.
His efforts to apply his procedure were very much influenced by the era 
in which he lived, but the method of inquiry he created opened the way to 
a new era of modern science. As ironic as it may seem to us now, the first 
discovery he made using his scientific method was not about the world but 
about his own subjective experience of his consciousness; the first object 
before his scientific eye was his “self” as a thinker. He proposed that con­
sciousness and the physical body were fundamentally distinct and separate 
in their nature. In his view, the mind existed as a rational entity within the 
eternal purity of the domain of God, while the body was a member of the 
animal kingdom driven by impulses and instincts. This dualism proved 
highly problematic as it provided no principled way for the mind and the 
body to interact with one another.
Although contemporary computational models of mind do not argue 
that the human mind is either of divine origin or rational, a new dualism 
of mind and body has arisen in an empirically-generated context. In this 
case, the focus of inquiry is on the patterns of language, independent of 
any subjective meaning that might be associated with any given words or 
groupings of words. Those subjective experiences include all bodily sensa­
tions, impulses, and emotions.
Computational models are statistical in nature and attempt to identify 
mathematical consistencies among words, and sometimes letters, as infor­
mational units rather than symbolic representations of phenomena. The 
statistical models are configured as algorithms, which can then be used to 
produce language patterns similar to human beings. The more similar the 
patterns in more diverse contexts, the more the algorithmic models are 
said to replicate the patterns of human mind as it can be defined by its use 
of language.
Algorithms consist of sets of rules that sequence varied mathematical 
operations. Those rules generate sequences specifically responsive to lan­
guage prompts or other types of informational input such as visual images 
or sounds (like the human voice). The algorithmic processing does not 
change with the meaning we might associate with words but with the sta­
tistical patterns in the letters and groupings of letters we call words. Nor is 
the processing changed by the computational mechanism that performs 
2  WHERE WE BEGIN 

14
the operations required. Philosopher David Chalmers refers to the laws of 
the algorithm as “organizationally invariant.”
Among the physical mechanisms to implement the algorithms is the 
human brain. We may think of the brain as having an independent stand­
ing, as being capable of organizing itself and determining for itself what it 
will do. However, to the extent that the processes of the brain are known 
by the patterns of language produced, and to the extent that those pat­
terns can be reproduced by algorithms implemented in other computa­
tional devices such as computers, the brain itself has no special powers. In 
short, the brain is no different than any other implementation system. 
Thus, the mind need not be limited to the brain, or more generally, the 
body. This is a far cry from Descartes’ dualism, but it is a dualism 
nonetheless.
Both are products of reductionism: the breaking down of the human 
mind into what are perceived to be its most basic components and recon­
structing whatever properties the mind may be said to possess. When the 
mind is language and language amounts to statistical patterns, the body 
simply is functionally irrelevant. Even if the argument is made that the 
human mind is conscious, that property itself follows as a consequence of 
processing and has no role in either creating or implementing the algo­
rithms used.
The logic of the arguments is sound if its fundamental reductive prem­
ise is accepted. But must we accept it? Can we understand the human 
mind by analyzing the statistical patterns of language and synthesizing 
algorithms that produce the same, or nearly the same, patterns? Can we 
understand human thinking as the patterning of language? If so, can we 
conclude that the factors leading to use of language are exactly the same 
as those we might use to copy such use? Consider the question in the fol­
lowing terms. A composer writing a piece of music for a violin scribes his 
score in musical notation. A deaf statistician reads the sheet music and 
writes the patterns he finds as algorithms. Does the statistician understand 
the mind of the composer? Does he understand the purpose that led to the 
formation of the mathematical patterns he found? Did his algorithms con­
vey any of the meaning they carry in sound? Could sound itself exist for 
him? Could meaning travel through it?
One might respond that it is possible to model the composer’s efforts 
statistically and to produce musical scores that demonstrate the applica­
tion of rules that do reflect the origins and purposes of the composer’s 
efforts. However, the source of the music within the composer with its 
 
J. KANE

15
power to shape sound (sound the deaf statistician cannot hear) is absent 
from consideration. Similarly, the meaning of the experience it is intended 
to create is lost to functions between numbers.
These same questions apply to generative AI. When asked to produce a 
scene of an argument over a parking ticket in the style of Shakespeare, the 
technology will produce language patterns similar to those of the Bard 
himself. Can Shakespeare’s genius be conveyed in the patterns of his 
words? Can it be understood where human experience has no place? The 
power of technology lies in its capacity to imitate patterns of language that 
human beings take to have meaning beyond the patterns themselves. The 
meaning that may be carried is created only within the context of human 
experience—within the context of living and being in the world. The 
reductive framework that has proven so powerful a framework for under­
standing the inanimate universe since the seventeenth century simply can­
not extend past the boundary it has created between matter and mind.
The Experience of Mind and Body
Philosopher and Neuroscientist Antonio Damasio, in his seminal work, 
Descartes’ Error: Emotion, Reason and the Human Brain, argues that 
Descartes made a fundamental error in separating the mind and body. 
Among his many contributions in understanding the human brain, he has 
articulated the role of afferent neurons that allow us to experience sensa­
tions directly. These neurons create “somatic markers” that then integrate 
with many different regions of the brain and central nervous system to 
generate perceptions, feelings, and emotions. In this context, we do not 
experience the activation of these neurons as information about objects 
but as the subjective reality of our own existence. Such experience is not 
in the mind as much as it is the foundation of mind itself in a given instant.
­
­
­
2  WHERE WE BEGIN 

16
­
2
­
­
3
­
­
­
Among our most cherished beliefs is that there is something distinct in 
our existence as conscious, self-aware human beings. Since Aristotle first 
argued that our capacity to think distinguishes us from all the creatures of 
the earth, our minds have been central to our concept of what it means to 
be human. In his landmark book, written more than a half century ago, 
What Computers Can’t Do: The Limits of Artificial Intelligence, Dreyfus 
explains,
2 Damasio, Antonio. The Feeling of What Happens: Body and Emotions in the Making of 
Consciousness, Harcourt, Inc. 1999, p. 318.
3 Dreyfus, Herbert. What Computers Can’t Do: The Limits of Artificial Intelligence, Revised 
Edition, Harper Colophon Books, 1972, p. 57.
 
J. KANE

17
4
Given the stakes, he concludes that a “critique of artificial reason” was 
required. Now, the question arises as to how we are to understand our­
selves in the light of artificial intelligence. When Dreyfus wrote, AI existed 
in college labs and corporate research facilities, but today, it travels with us 
in our pockets. Generative AI now allows us to use natural language to ask 
complex questions and receive well-articulated responses with refined 
conceptual nuance. The challenge posed to philosophers 50 odd years ago 
now greet us with our morning coffee. Even as many of us may have inter­
est in exploring the capacities of this transformational technology, every 
discovery we make only intensifies the question of what it means about us 
as human beings.
The assumptions we hold about our uniqueness as human beings and 
the significance of our immediate experience will last only so long as we 
can distinguish the word products of technology from our own thoughts. 
That time is near its end. Whereas Dreyfus said his times required a “cri­
tique of artificial reason,” our time requires a critique of our understand­
ing of how we think and what we are as conscious human beings. Our 
concern is not how far computational devices will evolve or what they can 
do, but how we might best develop our most essential and highest capaci­
ties. Whether we are beings created in the image of God or Aristotelian 
“rational animals” or biological computational machines, our future is of 
our making. Whether our cognitive gifts began with the bite of the apple 
in the Garden of Eden or evolved just as Darwin imagined or exist as an 
artifact of random fluctuations in quantum fields, our thinking is both 
central to our identity and critical to the judgments we will make in shap­
ing who we will become. Maybe we are no more than information proces­
sors; maybe we are aggregations of molecules like all other physical objects. 
But we ought not to simply assume we are. We ought not to be so 
impressed by the power of technology that we use it to define ourselves.
Thus, we ought not to be focused on the word patterns that may be 
found in our thinking—patterns that may be replicated by algorithms fed 
with sufficient data. Rather than assuming that human thinking can be 
understood as production of word patterns, we conceive of it as the capac­
ity to explore and express the realities we experience as human beings. The 
4 Ibid., pp. 78–79.
2  WHERE WE BEGIN 

18
question we ask is how we can understand the unfolding of our subjective 
experience into conceptual frameworks of everything from the unwritten 
rules of social interaction to mathematical formulations of quantum 
mechanics. How does our thinking enable us to form dynamic conceptual 
systems that not only embody broad, informal organizational principles 
but also enable us to grasp the organizational principles that govern the 
world around us?
At our most fundamental level, we experience ourselves as physical 
objects subject to the laws of physics. In a purely biological context, we 
experience ourselves as living organisms and share the same fundamental 
drives with all other forms of life. Socially, we experience ourselves as 
members of multiple layers of social groups unfolding and adapting our­
selves in accordance with all the customs and traditions that define human 
societies. Linguistically, we experience words as having meanings in 
images, bodily sensations, memories, and emotions. Existentially, we expe­
rience being in the world and having a unique identity among all else that 
may exist. All of these realities of our lives are subjective and fraught with 
error, but they are undeniable in their generative force. They set thinking 
in motion; without them, processing, such as it may be, would never 
occur. These experiences, though beneath the surface of language, give 
meaning and power to words. They are the source of questions we ask and 
the value we find in our discoveries.
These are not mere products of probability played out in the imagined 
randomness of the corner of the universe between our ears. They are the 
foundations of our minds. Their effluence is our thinking. They are funda­
mental aspects of our humanity and cannot be reduced to bits of data or 
strings of computation. Our thoughts are expressions of the dynamic bal­
ances and symmetries active in maintaining the coherence of each and all 
the layers of our existence from our physical bodies to our conscious 
minds. Each idea that emerges within us arises within the context of all 
these layers of our existence and is shaped by the principles that give each 
of those layers its unique system of coherence. The strings of verbal behav­
ior that form our thoughts are not borne of algorithms but of our dwell­
ing within the reality of our own skins and our consciousness of our own 
existence. All that we may say, no matter how personal or seemingly objec­
tive, takes its form and function within the context of our subjective expe­
rience of being.
 
J. KANE

19
­
­
5
The sheer power of reductionism to explore the patterns of neural func­
tioning of the brain and to engineer extraordinary computational tech­
nologies is beyond dispute. Yet, it cannot account for something as basic 
as the sensation of pain we experience when stubbing a toe. Yet further, it 
precludes any possibility that we have agency such as a self-initiated drive 
to search for truths that transcend our subjective experience. That very 
effort lies at the very heart of our religion, philosophy, and science. Physics 
and biochemistry may tell us a great deal about the flow of molecules 
within and between our neurons, but they cannot offer the slightest hint 
about the experience of meaning or the power such meaning has to shape 
our ideas. If we are to apprehend the nature of our thinking, we must 
dwell in principles active in creating it; our thinking cannot be understood 
as neural or linguistic behaviors.
Mimicry, no matter how complex, ought not to be mistaken for insight. 
The power to produce desired results ought not to be mistaken for the 
discovery of principle. The purpose of this book is to offer an alternative 
theory of mind, one that is relational rather than reductive—one focused 
on the dynamic principles that emerge in complex systems rather than the 
statistical interactions of otherwise discrete objects.
The Science of Reductionism
To better understand the framework that has led us to this moment, and 
to identify the need for a new way of thinking about our minds, we trace 
the most fundamental aspects of modern science back to its origins of the 
seventeenth-century philosopher and mathematician, Rene Descartes. 
5 Polanyi, Michael. Science, Faith and Society. Chicago, The University of Chicago Press, 
1964, p. 29.
2  WHERE WE BEGIN 

20
Descartes did not invent modern science. It is grounded in the intellectual 
traditions of the West since the time of Plato and Aristotle. We can see it 
develop in the first experimental research in optics conducted by Abu Ali 
al-Hasan ibn al-Haytham in eleventh-century Egypt. It further developed 
around the turn of the seventeenth century as Sir Francis Bacon champi­
oned empiricism and Galileo Galilei introduced quantitative measures and 
an iterative approach to scientific research. Many others could be named 
as well. However, Descartes made the critical contribution of reduction­
ism. When Descartes penned his now famous cogito, “I think, therefore I 
am” he proposed a method of inquiry that continues strong in the present 
day. His conclusions reflected the religion of his time, but the method of 
inquiry he created opened the era of modern science.
Descartes believed his method established an objective system of knowl­
edge that provided its own validity completely devoid of any subjective 
beliefs. More broadly stated, he conceived of a universe of science ulti­
mately composed of discrete objects with their own independent proper­
ties within a closed system of formal rules, such as mathematics. A mere 50 
years later, Isaac Newton applied Descartes’ reductionist method to the 
physical universe; his aim was not to discover eternal truths in the world of 
thought but to find the mathematical laws governing the interaction of all 
physical objects as they can be observed. His efforts led to his discovery of 
the universal theory of gravity. In that context, all things in the universe 
took their place and played their part. Newton established a foundation 
for physics that lasted for roughly 250 years and created a framework for 
understanding all things physical (including the matter of which are com­
posed) that continues as a fundamental framework for much of engineer­
ing even today.
His application of reductionism in an empirical context we call empiri­
cal reductionism. Although many philosophers of science have revised 
Descartes method and redefined the nature of objectivity and meaning of 
theoretical constructs, the practice of modern research has, with a few 
exceptions, focused on breaking down phenomena into their most ele­
mentary component elements to identify the ways in which they act. In 
that framework, the objective of science is to identify patterns of interac­
tions between observable objects as the foundation of scientific law.
His theory seemed to establish its own empirical validity without the 
need for subjective beliefs or judgments. Planets and apples seemed to 
 
J. KANE

21
comply with undeniable consistency. He, and those who followed him, 
believed his equations served as the center and circumference of the uni­
verse, a system closed to influences outside of the empirical patterns 
observed and the laws of mathematics defining them. For him, all objects 
were part of a single universal machine, and his theory an explanation of 
its functional rules.
However, his model of the universe, and all things within it, was not as 
complete as it seemed. The laws he described in his calculations were 
remarkably accurate and seemed universally consistent in their application, 
but as time passed a number of physicists found unexpected and inexpli­
cable new patterns that did not fit within Newton’s laws. For one, in 1865, 
James Clerk Maxwell, found that no objects in the universe could move 
faster than the speed of light in a vacuum. That made no sense in the con­
text of Newtonian theory.
It took the imagination of a 26-year-old Swiss patent clerk, Albert 
Einstein to propose that the laws governing the universe could not be 
found in the empirically observable interactions of physical objects. Rather 
than focusing on describing empirical phenomena, he sought the princi­
ples generating the world as it could be observed. He viewed the genera­
tive laws creating the world as the ultimate reality, with the physical 
universe being their expression. No observation or set of observations or 
patterns of observation were anything more than particular instances of 
greater laws.
In this context, Einstein sought laws based upon dynamic principles 
that transcended empirical boundaries even as the laws he sought would 
have to prove consistent with empirical observation. He rejected the con­
cept that science should define physical law in terms of empirical observa­
tion. For him, the laws of the universe could express themselves in 
empirically conflicting ways relative to a single set of events depending 
upon the vantage point of multiple observers. For Newton, the universe 
was a static tableau against which all things could be measured; for Einstein 
it is a dynamic field in which empirical measures could vary while the laws 
governing them would remain invariant. In fact, Einstein himself named 
what is now known as relativity theory as the “theory of invariance.”
With his discovery, he demonstrated that for all the practical utility of 
empirical reductionism, it could not reveal the principles responsible for 
the patterns observed. Discovery required that he move beyond empirical 
reductionism.
2  WHERE WE BEGIN 

22
Understanding Ourselves
Nowhere is empirical reductionism more problematic than when we our­
selves are the object of inquiry. Can we be understood in terms of the 
patterns we produce in our behavior or in our use of language? If not, 
what are the assumptions we will apply as we consider our consciousness 
and modes of thinking? What assumptions will we use to guide us into the 
universe of consciousness? How will we measure the workings of the 
human mind, or define human thought or conceive of the human self? 
However we set the principles of inquiry, we will determine not only what 
we will discover but what may be undiscoverable. Yet further, these same 
primary assumptions will guide us to cultivate a select spectrum of cogni­
tive skills and modes of thinking. They shape both the discoveries possible 
as well as our very capacities as researchers. They are instrumental not only 
in relation to our  efforts  as thinkers but relative  to  us as  the actual 
objects of study. Our subjective choices simultaneously structure both the 
way we will think and the object we will think about.
When we set out to understand our minds in terms of possible mathe­
matical patterns in basic units of empirical data, the conclusions we reach 
will take two fundamental and related forms. Firstly, we will declare that 
the mind is nothing other than the physical organ of the brain, and that it, 
as any other physical object, is governed by the laws of physics. Secondly, 
following a clinical line of inquiry focusing on language-based patterns of 
activity, we will discover algorithmic patterns. Taken together, the two 
conceptual frameworks effectively blend into a single model of the human 
mind as a biological computer with our bodies constituting the hardware 
or “wetware” and our empirically observable cognitive activities as our 
processing software. Before any specific inquiry begins, the human mind 
for all its complexity, could be no different in kind from a laptop or 
cell phone.
In this context, the mind is an object of inquiry viewed exclusively from 
the empirical perspective of the researcher. Whether the focus is on the 
physical object of the brain or on the output of cognitive processing, there 
is no place for the intent or experience of the subject—let alone that such 
subjective factors might have any influence on how or what we think. As 
an empirically defined domain of inquiry, the study of the mind precludes 
such extra-empirical factors as may be said to apply in any other domain of 
physics. One could no more ascribe personal agency or causal power to us 
 
J. KANE

23
as conscious individuals than one could ascribe such capacities to a pen 
inking a signature on a page.
One wonders how reductive empirically-based scientists could claim 
their own theories valid when their own thinking and judgments would be 
as absolutely subject to the very same causal factors as they insist govern 
the minds of others. Reason would demand that science follow a deter­
mined course like any other physical system. If one is utterly controlled by 
law, then one’s judgment is meaningless in any context: what is is, and 
what will be will be. If one’s thinking is utterly controlled by law, thinking 
is a product and nothing more: the causal laws themselves determine the 
rules, the values assigned, and the conclusions reached. The determinative 
power must be vested other than within us, and the conceptual framework 
of empirically-circumscribed science must fall apart under its own weight.
The particulars of any given school of neural research or computational 
model of processing do not matter. All such theories share a single funda­
mental paradigm that the human mind is the product of the aggregation 
of discrete elementary elements (such as quanta or bits of data), and that 
these elements can be disassembled and reconstructed to reproduce minds 
that have the very same cognitive properties as human minds.
All such conceptual frameworks share a self-imposed hard boundary 
between the mind as a matter of “cognitive mechanics” and the mind as 
living and conscious being. There is no possibility for any dynamic quali­
ties or properties of the mind (such as the experience of a sensation or of 
the power of and meaning of an idea) to affect what and how human 
beings think. Clearly, some patterns of cognitive activity can be copied 
through reverse engineering of one sort or another. And undoubtedly, 
some of those mechanisms, once identified, can be modified to create new 
informational systems with new types of properties and potentials for 
action beyond those previously possible. The unprecedented power of 
Generative Artificial Intelligence makes the point abundantly clear. 
However, neither the imitation of function, nor the reconfiguration of 
some components of a mechanism to produce new systems, constitute the 
discovery of principle. Neither of them can account for the principles that 
created the original patterns themselves or the ability of such principles to 
generate new empirical expressions.
If we are to move beyond the confines and contradictions of computa­
tional theories of mind, it is essential for us to move past the self-imposed 
constraints of empirical reductionism and recognize the dynamic nature of 
complex systems governed by irreducible organizational principles. Our 
2  WHERE WE BEGIN 

24
task is not to circumscribe our conceptions of mind with the neural func­
tions or linguistic algorithms. Rather, it is to explore the mind as it is 
embodied in human beings who experience meaning in and through ideas.
The Union of Mind and Body
Given these considerations, it is time to move beyond empirically reduc­
tionist definitions of science and its prescribed limits of the laws of the 
universe. Our inquiry into the human mind demands no less of us. For all 
the power and efficacy of the model of the human mind as a biological 
computational machine, our empirical reductionist paradigm of science 
has obscured its fundamental inability to account for the very minds that 
created it. The meaning and purpose of thinking can no more be found in 
the algorithms we write than music can be found in a calculous of vibra­
tion. The very concept of objectivity so prized in science is grounded in 
subjective intent and judgment—in an internally-dynamic drive to find 
truths that transcend our own subjectivity.
Empirical reductionism is effective in pursuing questions of language as 
observable patterns, but too narrow and limiting to understand the ori­
gins or purpose of the act of thinking, or the principles responsible for 
creating the patterns identified. We are not asked to ignore empirical 
observation but to extend our attention to include the organizational 
principles that have emerged in the course of the development of our spe­
cies. Let us consider our minds not in terms of the patterns of linguistic 
behavior but of the organizational principles that allow for human think­
ing and action. Let us consider thinking not as strings of code but as 
expressions of the principles embodied in our existence as living and con­
scious human beings.
The simple fact is that we, our minds, and our bodies, form a single 
unity with multiple dimensions. As human beings, we live in multiple eco­
systems that embody their own rules relative to maintaining their own 
coherence. Our bodies are composed of matter and are subject to the laws 
that apply to all matter. We are living organisms and are subject to the laws 
that apply to all other living organisms. However, the laws of physics and 
biology are not responsive to the stresses placed upon us by the social and 
linguistic ecosystems that have emerged over the course of our history as 
a species. With their emergence new and varied principles of organization 
have yielded new capacities that were not possible at more basic levels. 
With emergent social and linguistic systems, those ancestral lines that led 
 
J. KANE

25
to our ascent as homosapiens proved to be more readily and broadly adap­
tive than other environmental competitors. They proved to be more effec­
tive in maintaining their systemic coherence at all levels collectively. These 
are the roots of meaning we experience and the sources of organization 
that shape our ideas.
Our minds are not confined to our conscious awareness of ourselves or 
our capacity to represent objects and events in linguistic codes. Our think­
ing increases in complexity and scope from one layer to the next, with each 
layer adding its own principles of coherence and purposes. Within us as 
human beings, the physical, biological, social, linguistics and consciously 
self-aware layers of our being all weave together as meanings we can only 
partially express in words. Our thoughts integrate our experience in all 
these layers, even as some may elude our conscious awareness. From the 
tummy time infant struggling against the weight of his own body to the 
family struggling with the weight of terminal life choices, the fabric of 
consciousness is woven of unbroken thread.
2  WHERE WE BEGIN 

27
CHAPTER 3
The Science of Mindlessness
Two Selves
The question of where technology might end and we might begin is not 
actually about the capabilities of artificially intelligent machines but how 
we think of ourselves. As human beings, we are both physical and con­
scious. We walk the earth as animals and can wander among the stars. We 
are bound by impulse and need but are most ourselves when we transcend 
them. Since Descartes argued that these two dimensions of human exis­
tence are fundamentally different in their nature, Western thinkers have 
struggled to find a consistent set of principles to put them back together.
Descartes did not begin with the contemplation of himself as a thinker 
and as an object of thought, but with the question of how he might find 
Truth. He asked how he might know anything with absolute certainty, 
how he might acquire knowledge beyond circumstance and subjective 
judgment. As a young student, he had grown very disillusioned with what 
he believed to be the inconsistencies and contradictions of what passed for 
the “sciences” of his time (physics, languages, rhetoric, philosophy, math­
ematics, and theology). He sought knowledge not as affirmed by others 
but as he could substantiate it directly for himself.
He concluded that in order to apprehend what he called Truth, he had 
to remove all subjective experience from the process. He maintained that 
his thinking had to enter a domain undistorted by personal experience. 
Thus, as he sought knowledge, he concluded that he had to separate 
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2024
J. Kane, The Emergence of Mind, 
https://doi.org/10.1007/978-3-031-46835-3_3

28
himself as knower from the known. All aspects of the knower had to be 
eliminated in order to apprehend Truth. The method he devised to achieve 
such objectivity has served as a fundamental principle of science ever since. 
The problem is that the method itself, not only sets the knower apart from 
the known, but the human beings as thinkers from human beings in the 
physical world. Yet further, it established the common foundation for 
what would eventually become the scientific study of the mind—a founda­
tion that has no place for the experience of meaning or a living, breathing 
knower. In this context, let us consider his process of discovery and its 
evolution in the science of mind.
Wrestling with his unsettled search for Truth, 23-year-old Descartes 
found himself stranded by a fierce winter storm on the night of November 
10, 1619 in the small Bavarian town of Ulm. As he went to sleep, he 
resolved to accept only what he could grasp with the powers of his own 
mind. When he fell asleep, he had a series of three dreams he believed to 
be messages from God calling him to devote himself to the search for 
Truth. The dreams that night were similar in nature to those many of us 
have each night with disjointed streams of fanciful images swirling 
about without rational structure. Yet, he recalled that they set him on a 
path to discover the foundations of “a marvelous science” that could be 
used in all fields of inquiry—a “science” of science. Descartes saw in them 
a basis of a new way of thinking that could transcend subjective experience 
and open him to a universe of pure thought.
In 1637, some 18 years after his eventful night of dreams, he published 
Discourse on The Method of Rightly Conducting One’s Reason and of Seeking 
Truth in the Sciences. The work may be rightly considered the first philo­
sophical work of the modern age; it sets the foundational principles for 
scientific method. As noted previously, his method was simple in principle: 
doubt all that can be doubted, reduce all things into their most basic 
undeniable elements, and connect those elements by the use of reason.
Applying this process, Descartes realized that he could doubt the exis­
tence of his own body and the entirety of the world as it could be sensed. 
He reasoned that it is common that we dream we are engaged in all types 
of activities while actually laying in our beds. Not being able to tell with 
certainty the difference between dreams and actual sensory impression, he 
concluded that all experiences of the senses, and all that they may tell one 
about the world, are rife with possibilities for error. Thus, even as he 
believed he had a body, he could not rely upon sensory information to 
provide the certainty necessary to serve as a basis for knowledge.
 
J. KANE

29
­
­
1
­
­
­
2
Thinking and the “Thinking Thing”
With his method set, Descartes set out to explore his mind determined 
to doubt all that he believed to be true. Very early on, he asked how he 
could be certain that he himself existed. Clearly, he could not rely on his 
senses or the composite object of his body. Eliminating all that he could 
doubt about his own existence, he concluded that he could not doubt 
his experience of doubting. Further, reason demanded that doubting 
required a “thinker.” Accordingly, he famously concluded, “I think, 
therefore I am.”
1 Descartes, Rene. A Discourse on Method Meditations and Principles, translated by John 
Veitch, 1994, p. 76.
2 Ibid.
3  THE SCIENCE OF MINDLESSNESS 

30
Clearly, Descartes perceived “doubting” as indisputable because he 
experienced himself in the act. However, he recognized he also had other 
experiences beyond doubt and that they too were thoughts that required 
a conscious thinker. In Principles of Philosophy, he explained,
­
­
­
3
Thus, thinking was not defined in terms of concepts or their processing 
but as the direct awareness of conscious experience. The contents of the per­
ceptions he had, whether or in the form of images or sounds or other 
sensations, may be mistaken, but his awareness of conscious experience of 
those things itself was irrefutable. Their existence affirmed his own. 
Consequently, Descartes could have restated his cogito in many ways. He 
could have reasoned, “I see, therefore I am.” “I hear, therefore I am.” “I 
feel pain, therefore I am.” The common element in the full range of pos­
sible “cogitos” is their direct experience of conscious awareness. His focus 
was not upon thought as a matter of abstract content but on his conscious 
experience itself. His concept of thinking was grounded in the immediacy 
of his consciousness, in his subjective experience.
However, Descartes’ “indisputable” proof of his own existence split the 
self that consciously experiences from the concept of his self as what he 
called a “thinking thing.” He defined his “self “as the “thought of his 
self.” The “I” at the beginning of the cogito experienced sensory 
impressions, dreams, memories, and physical drives while the “I” at the 
close of the sentence was a categorical construct.
3 In the French, “which alone has the power of perceiving, or of being conscious in any 
other way whatever;” Ibid., I, IX, Italics added.
 
J. KANE

31
Descartes recognized that as a “thinking thing” removed from the 
world of the senses, he had to put it in some context with all the change­
less perfection of Truth itself. He concluded that only God could serve 
that purpose. Thus, he reasoned that he, as a thinking thing, existed within 
the Truth of God. Even so, he nonetheless believed that he also existed as 
a physical body. That “self,” the one that experienced sensations, existed 
within the ever-changing physical world where Truth could not be known.
His meditations of Truth took place in a conceptual realm removed 
from the ebb and flow of subjective experience. He believed that he could 
use his method of science to find certainties with his mind, but he also 
believed he could use his senses to enable himself to make the practical 
judgments necessary to survive as a biological organism. While the “con­
ceptual self” contemplated Truth beyond all subjective experience and 
interests, his “biological self” dwelled in within them. The former sought 
certainty, and the latter, survival.
Descartes’ Mind Turned Inside Out
Descartes’ reductionist method led him to conclude that he existed in two 
separate and distinct plains with their own governing principles. He con­
ceived of himself as a conceptual object in a domain of pure Truth and as 
a body living in a physical world subject to the need to sustain itself. Each 
of the two worlds required its own form of knowledge. In the objective 
world, reason alone established all order; in the physical world, subjective 
impressions and interests ruled. The two conceptual frameworks opened 
the way for two distinctive types of scientific disciplines. He could research 
himself as a concept through mathematic-like reason, and himself as a 
physical organism through biology.
In contrast, in the years that followed, scientists did not share his skep­
ticism about sensory information as the basis for knowledge, but believed 
it to be a common foundation for public discourse. Empirical information, 
rather than conceptual objects in a universe of pure thought, emerged as 
the necessary foundation for objective science. Newton, for example, saw 
the physical universe with the same perfection and immutability that 
Descartes saw in God. He asserted that time and space could serve the 
exact same function. With the absolute constancy of the universe itself as 
a context, he believed he had a purely objective foundation to chart the 
observed patterns of the movements of objects in accordance with the 
laws of mathematics. In that framework he calculated his way to 
3  THE SCIENCE OF MINDLESSNESS 

32
discoveries that were long believed to be objective foundations of the 
physical universe.
The history of modern biology is more complex. Given the complexity 
and variety in the universe of biological organisms, much of early biology 
was focused on creating classificatory systems to group plants and animals 
and to identify their common characteristics. In Descartes’ time and for 
centuries thereafter, the human mind was believed to be so unique a char­
acteristic that it set human beings apart from the kingdoms of other living 
organisms. This view was consistent with Descartes’ dualism, which placed 
the human conceptual self within God and outside of the realm of nature.
However, some 200 years after Descartes, Charles Darwin, a scientist 
committed to empirical research, defined human beings solely as biologi­
cal organisms. His theory of natural selection placed the origins of the 
human mind in the context of evolutionary biology. The mind was not 
separate and distinct from the body but a product of effective adaptation 
in the fight for resources. Human beings were not separate and distinct 
from other animals but governed by the same organismic motivation to 
survive. Unlike physics, where all objects were believed to be governed by 
mathematical law in an unchanging and ethereal universe, Darwin placed 
the human mind, the core of human identity, in a biologically competitive 
arena with other animals.
The Mind of the Human Animal
Roughly 30 years later after the publication of Darwin’s On the Origin of 
Species By Means of Natural Selection, biological scientists began to study 
the relationship between environmental stimuli—that which organisms 
perceive—and the behaviors that organisms produce. The scientific study 
of behavior, known as behaviorism viewed animal behavior as relative to 
the environment rather than any type of internal states within organisms 
themselves. In the biological sciences, empirical observation provided the 
unassailable basis for inquiry.
In the 1890s, Ivan Pavlov, a biologist studying canine digestive systems 
was conducting experiments on the relationship between salivation in 
dogs and the presentation of food. He was surprised to see that the dogs 
not only began to salivate when food was presented but when they could 
hear the approaching footsteps of the research assistants who regularly 
came to feed them. Intrigued, Pavlov set a metronome to tick before the 
dogs were given their food. Soon, they began to salivate whenever they 
 
J. KANE

33
heard the sound of the metronome. The connection the dogs established 
between the clicks and the food illustrated that two previously uncon­
nected objects could be associated with one another. Pavlov observed that 
the environment shaped the dogs’ behavior and sought to understand the 
lawful patterns by which it exerted its control. In that context, he created 
a new field of research: experimental psychology.
­
­
­
­
4
­
­
­
­
­
5
The behaviorist notion of the environment as being fixed and objective 
is essential to its claims to scientific objectivity and to its dismissal of the 
internal perspective of the organism. The laws of environmental control 
are considered to be universal. There is no need to consider the mind as a 
possible intervening variable or potential causal factor between environ­
mental stimuli and an organism’s behavior. With that assumption, the 
4 Watson, John. “Psychology as the behaviorist views it.” Psychological Review, vol. 20, no. 
2, 1913, p. 1.
5 Ibid.
3  THE SCIENCE OF MINDLESSNESS 

34
organizational principles governing human beings can be modeled on the 
behavioral patterns of animals.
Behavioral research found animal studies ideal for experimentation. 
Animals, being so limited in their behavioral repertoires, enabled clear and 
precise measures of control and prediction. Furthermore, animal studies 
entailed fewer ethical considerations than would be the case for human 
beings. The only real questions for the science of behavior were the means 
by which the environment exerted its power and the most effective tech­
niques to harness them. Thus, scientific study of human judgment and 
intent amounted to the development of a technology of behavior.
In a speech given to the American Psychological Association in 1987, 
the most prominent behavioral researcher of the twentieth century, 
B.F. Skinner, explained that a term such as mind refers to unobservable 
mental states and has evolved as a vague, generalized concept. In the 
absence of research revealing the laws of the environmental control of 
behavior, previous generations attributed independent existence to vague 
concepts such as the human mind and believed them to have casual power. 
He asserted,
Extraordinary things have certainly been said about the mind. The finest 
achievements of the species have been attributed to it. … But what it is and 
what it does are still far from clear. … The dictionaries are of no help. To 
understand what “mind” means we must first look up “perception,” “idea,” 
“feeling,” “intention,” … and we shall find each of them defined with the 
help of the others. Perhaps it is of the very essence of mind that it cannot be 
defined. Nevertheless, we can look at how the word is used and what people 
seem to be saying when they use it. …
­
6
6 “B.F. Skinner Insists It’s Just Matter Over Mind.” The New York Times, 13 September 
1987, p. E6. Accessed 22 January 2021.
 
J. KANE

35
7
Skinner did not deny that human beings have internal states or emo­
tions. Rather, he claimed that the very question of their existence is beside 
the point. Being unobservable, they could not be included in any substan­
tive scientific study of behavior. Human beings may engage in internal 
processes we call thinking, but any reference to them would be equivalent 
to explaining a thunderstorm as an expression of Zeus’ anger. Behavioral 
psychologists referred to the subjective aspect of human experience as a 
“black box”—a completely opaque, forever impenetrable domain that 
could not be studied scientifically. The assumption was that whatever 
could exist within the “black box” resulted from the observable relation­
ships between particular human beings and the behavioral reinforcers in 
their environments. If there is a mind within us, it simply does not matter.
We see in Skinner a reversal of Descartes’ dualism of body and mind. 
For Descartes, his science of the mind was grounded in verities of 
mathematic-­like thought and the science of the body as based upon sub­
jective perceptions, interests, and intentions. For Skinner, and for behav­
iorism as a science, all research about human actions eliminated all 
subjective aspects of human experience from the domain of scientific 
research. If they did exist, they, like all other behaviors, would be gov­
erned by the environment. They would be irrelevant as they could have no 
causal power. Conversely, the relationships between the environment and 
organismic behaviors could be objectively observed and qualified into 
mathematical patterns.
7 Skinner, B. F. Verbal behavior. New York, Appleton-Century-Crofts, 1957, p. 225.
3  THE SCIENCE OF MINDLESSNESS 

36
Complexity Overwhelms the Animal Paradigm
8
­
Chomsky explained that the definitions behaviorists use to describe the 
functions of various environmental factors in shaping an organism’s behav­
ior may appear to be clear and objective when applied to an analysis of the 
behavior of a chicken pressing a lever. The factors in the environment—
the stimulus of a light before the pellets are available and the reinforcement 
in the form of the pellet—are not ambiguous. Neither does the observa­
tion of the chicken’s response (nor its timing in relation to the stimulus and 
reinforcement) require much judgment. However, in situations involving 
human beings outside the lab, the environmental factors become very 
much more difficult to discern.
An eight-year-old’s interest in his science class could be associated with 
any number of possible stimuli: the gold star he might get, the approval he 
might expect from his parents, the opportunity it gives him to work with 
a friend, to avoid math class, the ease of the lesson, or the subject matter 
itself, etc… Chomsky also noted that a researcher could not identify any 
particular stimulus until after a behavior is produced. Something cannot 
be considered a stimulus without, in fact, stimulating some response. 
Many of the possible stimuli listed above could serve as a stimulus but not 
stimulate a given behavior. Conversely, many of them could be absent 
from the present in the immediate environment but successfully stimulate 
a behavior. A child might be stimulated by the anticipation of approval at 
home for her good behavior at school.
8 Chomsky, Noam. “A Review of B.F. Skinner’s Verbal Behavior.” Readings in the Psychology 
of Language, edited by Leon A Jakobovits and Murray S.  Miron, Prentice-Hall, Inc., 
1967, p. 142.
 
J. KANE

37
Similarly, the term reinforcement is equally elusive in practice. Something 
may be said to be a positive reinforcer if it increases the probability that a 
given behavior will occur again. When the only environmental factor that 
changes as a result of a behavior is the release of a pellet of feed, the con­
nection between the two can be considered linear and direct. However, as 
in the instances in the paragraph above, reinforcers need not be observable 
in the environment nor even exist at all, e.g., the imagined approval of a 
parent. In addition, the response elicited by a given reinforcer may vary 
widely. The eight-year-old may respond to the prospect of a science lesson 
by shouting with joy or grimacing or sighing silently depending upon the 
association he or she draws within a full range of extant and imagined 
environmental factors.
For rats and pigeons, the environment might be pretty straightforward; 
experimentally, at least, it can be defined by a time and a place. However, 
the environments in which human beings exist extend beyond a given 
place and time. Thus, the human mind is not confined to the physical 
environment of the body and includes an infinite number of mental factors 
that lie beyond the environment as can be observed by researchers.
­
­
9
10
9 Ibid., p. 6.
10 Ibid., p. 8.
3  THE SCIENCE OF MINDLESSNESS 

38
Computation and the Beginning 
of the Imitation Game
A new framework for studying human behavior was needed to account for 
the complexities that behaviorism could not address. A new problem-­
solving technology provided just the framework needed. During World 
War II, a fleet of Nazi submarines threatened the Allies, and particularly 
the island nation of Great Britain. Each day, each of the subs received 
coded messages on the location of their targets. The only way to read the 
code was to use a specialized decoding machine known as the Enigma. 
The code key changed every day, making it almost impossible for the Allies 
to read the messages. Recognizing the importance of breaking the code in 
the course of the war, British intelligence eventually called upon a young 
mathematician and cryptologist, Alan Turing. He, along with a small 
team, designed and built a machine that could sort through enormous 
volumes of bits of information—in this case letters—to find organizational 
patterns they could recognize as the German language. They succeeded 
and were able to read the coded messages that enabled the Allies to plan 
their strategies to take control of the Atlantic. (The story of his work is 
portrayed dramatically in the 2014 film, The Imitation Game.)
Through the use of a binary code design (directing the flow of an elec­
trical current in one of two possible directions), the machine he and his 
colleagues produced could sort through a vast number of coding options 
to produce ones that human beings could identify as the German lan­
guage. Turing and his team had invented the first modern computer. 
Although the computer could analyze the patterns in the information 
input within it, it could not read the messages; its processing rules did not 
equip it to identify the principles generating the patterns of the informa­
tion it itself produced. However, Turing and others came to believe that 
all the processing rules used by human beings to read the message could 
be formally coded as computational functions. Of course, the storage 
capacities would have to be expanded exponentially and the programs 
would have to be written with greater scope and sophistication, but he and 
others argued that it would be only a matter of time before computers 
could perform all higher-level cognitive operations associated with the 
human mind. If that were to happen, Turing reasoned that computers are 
said to actually think like human beings.
 
J. KANE

39
11
­
12
Computation as an Empirical Lens
In Chomsky’s paper, he made clear that higher cognitive functions such as 
those operative in the use of human language require a conceptual frame­
work with greater complexity, scope, and subtlety than is possible within 
the perceived laws of animal behavior. He writes,
­
­
13
­
11 Turing, Alan. “Computer Machinery and Intelligence.” Mind: A Quarterly Review of 
Psychology and Philosophy, vol. 59, no. 236, 1950, pp. 433–460.
12 Ibid., p. 442.
13 Chomsky, p. 143.
3  THE SCIENCE OF MINDLESSNESS 

40
­
14
­
­
The task of identifying the operational sequences needed to organize 
such complex systems of information into human-like problem-solving 
behaviors required sorting through them with speed and precision to 
determine the products of each possible set of interactions. The execution 
of so many operations to discern ones that produced the desired results 
would be impracticable. However, they developed programs that used a 
series of estimations to direct the flow of the processing.
15
­
16
Other researchers, including George Miller, used computation con­
cepts to study the structure of human cognition. In 1956, he wrote a 
foundational article in a new domain of study: cognitive psychology. The 
article, “The Magical Number Seven, Plus or Minus Two: Some Limits on 
Our Capacity for Processing Information“ is important because it demon­
strates the early experimental techniques and mathematical methods used 
14 Simon 1958, p. 8.
15 Simon, Herbert A. and Newell, Allen. “Heuristic Problem Solving: The Next Advance 
in Operations Research” Operations Research, Vol. 6 No. 1 Jan-Feb, 1958. p. 6.
16 Ibid.
 
J. KANE

41
to delve into the structure of the internal processes of high-level cognitive 
processes. In contrast to behaviorist studies focusing on relation of envi­
ronment and behavior, Miller sought to identify organizational character­
istics of what has come to be known as short-term memory as a distinct 
phenomenon.
He defined memory in terms of individual units of information and 
found that human beings generally use seven of them, plus or minus two 
for a few seconds. These units could be composed of such items as indi­
vidual letters or words. His studies also revealed that the units were not 
themselves restricted to simple bits of information but were actually slots 
that could hold multiple bits of information. Properly coded information 
could be packaged into groups to fill a single slot. For example, an expert 
telegraph operator could recall a far more lengthy sequence of dots and 
dashes in a telegraph message than could a person unfamiliar with the 
code. The operator could combine individual dots and dashes, which 
might take several slots, into words or phrases that would take only one 
slot. Through this process, chunking, as he called it, an individual could 
retain a significantly increased number of informational bits in short-­
term memory.
The critical point of Miller’s work was that he focused on the structures 
and patterns of linguistic behavior rather than their semantic meaning or 
relationship to environmental stimuli. They constituted a field of study 
composed of independent informational structures. The description of the 
difference between the recollection of the telegraph expert and someone 
unfamiliar with the code does not refer to the message communicated but 
to the characteristics of the informational structures involved in memory. 
The key to his model is not the representational content of the informa­
tion but the nature of its organization.
With an emphasis on the organizational structures of memory and the 
number of informational units within them, the study of language shifted 
from its symbolic or representational nature to quantifiable units. In that 
context, language could be translated into numerical form. Within this 
context, information was not defined by its symbolic or immediate experi­
ential content but by its place within whatever mathematical structures 
researchers could discern.
3  THE SCIENCE OF MINDLESSNESS 

42
The Cognitive Revolution
The shift that took place not only changed the focus from human behavior 
in the context of the environment to human cognitive structures and pro­
cesses but to the nature of intelligence. While some models such as Miller’s 
analysis of the structure of short-term memory is specific to human beings, 
the models developed by computational theorists such as Simon and 
Newell attempted to establish programs that could assume the same func­
tions as human intelligence independent of any human participation in the 
process. The central aim was to create artificially intelligent systems.
While behaviorism focused on the role of the environment in shaping 
behavior, cognitive research and theory emphasized the structure and pro­
cesses involved in cognitive functions such as perception, memory, atten­
tion, language, and problem-solving. This fundamental transformation 
from the study of behavior to cognition came to be known as the Cognitive 
Revolution.
One of the most influential psychologists of the time was Jerome 
Bruner. He described the early days of the transition as an attempt “…to 
discover and to describe formally the meanings that human beings created 
out of their encounters with the world.” He wrote,
­
­
17
The shift from “meaning” to “information” was subtle but profound. 
It recast language as an independent system of symbols rather than a 
means by which human experience and intent could be expressed. The 
concept of information was based upon the cybernetic theory of informa­
tion first developed by the mathematician and engineer Claude Shannon. 
Shannon, who worked at Bell Labs (part of the US Army’s Signal 
Intelligence Service) during World War II, focused on deciphering the 
codes the German military used to communicate. (And yes, he did meet 
with Turing.) In that effort, he developed a theory of communication in 
17 Bruner, Jerome. Acts of Meaning. Cambridge, MA, Harvard University Press, 1990, p. 2.
 
J. KANE

43
which language was communicated through binary bits of information, 
which would reduce the possibility of ambiguity. His focus was not on the 
content of any given message but on the accuracy of its transmission from 
point A to point B.
The adoption of Shannon’s theory proved ideal for the representation 
of language in computational systems where it could be coded and pro­
cessed with mathematical precision. The meaning of any given message 
relative to human experience played no role. Thus, human thinking was 
defined not in terms of subjective experience but as mathematically-­
defined coded patterns. The focus was not on the internal meaning of 
thoughts or thought processes but on the development of computational 
models that mirror the patterns of human cognitive processes.
In 1975, philosopher and cognitive scientist Jerry Fodor proposed that 
mental states could be understood computationally. In his book, The 
Language of Thought, he introduced a representational theory of mind in 
which mental symbols could be manipulated according to formal rules. 
Those rules could be understood as formal organizational structures that 
govern the functional operations that occur within the system of the mind. 
In his theoretical model, symbolic representations could have experiential 
content, but the processes used to manipulate them were formally defined.
Over time, computational technologies advanced and became increas­
ingly capable of implementing complex systems that could capture some 
of the structure and character of natural language. What might once have 
been thought of as mental representations of images and sensations were 
redefined as digital information, as Shannon had defined it. The digitiza­
tion of information reduced all phenomena to sequences of discrete binary 
units. In this context, the meaning of the word “dog” shifted from memo­
ries of a neighborhood puppy you played with when you were little to a 
digital code. Within such systems, the digital codes were not viewed as 
representational, as pertaining to something outside a given computa­
tional system, but purely functional within the context of the system itself. 
In this context, such terms cannot by definition, have any ambiguity; they 
could not have any properties or internal dynamic structure that could 
allow them any causal power to alter the course of processing. They were 
very much like the ideal elements of Descartes’ conceptual universe.
The actual functions could be placed within a digital program reflecting 
the rules of natural language. The programs could reflect the grammatical 
structures of language to construct sentences with the proper placement 
of subjects and predicates, for example. In that way, the input and output 
3  THE SCIENCE OF MINDLESSNESS 

44
could be structured so that particular sequences of code could produce 
output in the form of natural language. The information could also be 
coded to categorize its unique function in language (the way particular 
information is actually used) so that the computational output could effec­
tively reflect its use by human beings. The word “bird” for example, could 
be used in particular contexts rather than merely as a noun. When a system 
has a limited storage capacity of broad programmatic structure, the func­
tion of any given term will lack subtlety and nuance. However, a system 
with the processing speed, programmatic refinement, and a data set inclu­
sive of all the digitally-available books, journals, and newspapers in the 
world, as well as the entirety of the publically-available internet, could 
produce output virtually indistinguishable from human thinking. That is 
what we now have before us but let us not get ahead of the story.
­
18
­
­
Dreyfus rejected the use of the latter use of the term for the former in 
the context of human thinking. He maintained that it lacked the complex­
ity and capacity for nuance to capture the meaning of human thought. In 
his view, language is embodied and context dependent. It cannot be 
understood as the use of decontextualized bits of code devoid of any con­
tent. As astute as Dreyfus’ observation was years ago, it is that much tell­
ing today as the distinctions between the two uses have virtually disappeared 
in their common use.
Digital computational systems are the fulfillment of Descartes’ dreams. 
They allow “thinking” without any subjective elements that could intro­
duce ambiguity. As cognitive science evolved, the human “thinker,” with 
all his subjective experiences, became Descartes’ “thinking thing”… a lin­
guistic system for formally processing empty bits information.
18 Dreyfus, 1972, p. 166.
 
J. KANE

45
The Inversion of the Metaphor
Computational programs and machines evolved rapidly and were used in 
the study of the organizational and operational structures and processes of 
human thought. Computer programming created unimaginably powerful, 
responsive and adaptable algorithms, often eclipsing human functional 
capacities. Increasingly, sophisticated models of natural language process­
ing effectively fused the products of human thinking and information pro­
cessing. Not only did it seem that the principles of human mind and 
principles of computational machines were one and the same, but the lat­
ter became the operative model for both.
­
19
Philosopher Hilary Putnam first introduced the concept of the human 
brain in terms of functional states, states that could be mirrored or repli­
cated by other functional systems. His argument received considerable 
attention, including considerable criticism. However, the identification of 
the mind with the brain and the definition of the brain as a biological 
computer came to be the dominant conceptual model of mind in neuro­
science, psychology, and philosophy.
In this framework, the brain is distinctive as an organ in a living body, 
because of its particular physical composition and circumstance but not its 
functional processes. The fact that it is alive and that it may fulfill its func­
tions through unique biological mechanisms has no bearing relative to the 
nature of the products it produces. The physical composition of a compu­
tational device, even the brain (if it is a computational), does not affect the 
processing of information so long as the device is capable of carrying out 
the processing necessary.
19 Turing 1950, p. 442.
3  THE SCIENCE OF MINDLESSNESS 

46
­
20
­
­
21
22
23
­
24
­
­
­
25
For present circumstances, Churchlands’ description of brain function 
in the processing of information is secondary. There is no dispute that the 
brain operates as a complex neural network. Nor is there any dispute with 
the assertion that the neural system of the brain shares many characteristics 
with computers. In fact, the computational metaphor has proven extraor­
dinarily powerful as a foundation for research just as was the animal meta­
phor for behavioral science in generations prior.
A generation before, behavioral scientists argued that the subjective 
aspect of the mind was empirically inaccessible and therefore outside of 
the boundaries of science. As a consequence, all behavior was interpreted 
20 Churchland, Paul. The Engine of Reason: The Seat of the Soul. Cambridge, MA, The MIT 
Press, 1996.
21 Ibid., p. 7.
22 Ibid., p. 8.
23 Ibid.
24 Ibid., p. 17.
25 Churchland, Patricia. Brian-Wise: Studies in Neurophilosophy, Cambridge, MA, The 
MIT Press, 2002, p. 5.
 
J. KANE

47
in the context of observable environmental factors. If the mind did exist, 
it could not play any causal role. Although the computational metaphor of 
the mind does not share the behavioral emphasis on empirical environ­
mental factors, it excludes any type of non-computational internal states as 
having any scientifically valid explanatory or predictive significance in the 
context of human thinking.
Thus, the argument is made that the processes of the brain are com­
pletely biological, that sensation and consciousness are the products of 
biological processes. In that context, one can expect that while our current 
understanding of brain processes is incomplete, future empirical research 
will demonstrate that all internal states can be reduced to biochemical 
processes. There is neither a need nor place in such a computational frame­
work for the existence of an immaterial soul. Thus, the concept can be 
dismissed.
In this case, the metaphor of the mind as a computational system inverts 
the product and the prototype. The computational machine, designed to 
perform sequences of calculations to serve human intentions, is now 
largely the prototype of human thinking. Describing the brain in terms of 
pixels seems to confirm the point. The fundamental problem is that com­
putation as the prototype for the mind mistakes a limited product of its 
activity to define the principles that guide the effort. However, there is no 
principle in either biology or cognitive science that can determine the full 
extent of what may possibly exist or not exist beyond their experimental 
parameters. The epistemological choices one makes in research do not 
constitute ontological proof.
Philosopher Karl Popper argued that scientific statements may be dis­
tinguished from all other statements by their being capable of being 
proven false. A statement such as “God lies within all of us” may or may 
not be true, but it is not scientific. It simply cannot be proven false because 
it is not framed in a way where it can experimentally be proven to be 
inconsistent with the evidence. Whatever may happen, one can always 
explain that “The Lord works in mysterious ways.” Thus, science cannot 
address the existence or non-existence of God or a human soul. The prob­
lem is that it Churchland’s conclusion that an immaterial soul is a myth 
“to its core” is expressed as a product of scientific research while it is, in 
fact, an unjustified elevation of a productive conceptual framework to the 
status of an ontological truth.
Perhaps he is correct that there is no place for an immaterial soul to 
understand or interpret human mental processes, but his conclusion is 
3  THE SCIENCE OF MINDLESSNESS 

48
based upon the belief that the general predictive power of computational 
theory defines the limits of ontology. Newton made the same type of abso­
lute ontological claim in his time with his concept of the nature of time 
and space. The most he could have concluded was that if the human soul 
does exist, it would not fit within his computational model of mind. To 
the extent the human mind is modeled computationally, it is empty and 
mindless. Such computational theories of mind, for all their practical 
power, define us as nothing more than Cartesian “thinking things” 
with pixels.
It may well be that consciousness is at least in part a product of biology, 
and that computational models of consciousness produce significant find­
ings. However, that does not preclude the possibility that other factors 
may play substantive roles or that non-computational processes may have 
causal power. Neuroscientist and philosopher Antonio Damasio has con­
ducted ground-breaking research on the functioning of the brain and 
maintains that computational models can provide valuable insights into its 
functioning. He has found that subjective experience and consciousness 
cannot be fully understood computationally. He does not see them as 
mere epiphenomena but as functional aspects of the mind. Neuroscientist 
Giulio Tontoni theorizes that consciousness is a result of the interconnect­
edness and informational complexity of the brain. However, he explains 
that consciousness cannot be fully understood without an in-depth phe­
nomenological study of subjectivity. He argues further that consciousness 
can play a causal role in neural processing such as in processing sensory 
information or generating behavior. There is sound research evidence to 
suggest that the human mind is emergent and that, although being subject 
to biological laws and computational principles, is not reducible to either.
 
J. KANE

49
CHAPTER 4
Where Computation Ends
Defining Computation and Computational Systems
In order to better understand the full implications of a computational 
model of mind, let us imagine what one might experience within a com­
putational system. Computation in a digital context refers to the manipu­
lation of bits of information by using formal operations to change their 
01010100 01101000 01100101 00100000 01100011 01101111 
01110111 00100000 01101010 01110101 01101101 01110000 
01100101 01100100 00100000 01101111 01110110 01100101 
01110010 00100000 01110100 01101000 01100101 00100000 
01101101 01101111 01101111 01101110 00001010 01010100 01101000 
01100101 00100000 01101100 01101001 01110100 01110100 01101100 
01100101 00100000 01100100 01101111 01100111 00100000 01101100 
01100001 01110101 01100111 01101000 01100101 01100100 00100000 
01110100 01101111 00100000 01110011 01100101 01100101 00100000 
01110011 01110101 01100011 01101000 00100000 01100001 00100000 
01110011 01101001 01100111 01101000 01110100 00001010 01000001 
01101110 01100100 00100000 01110100 01101000 01100101 00100000 
01100100 01101001 01110011 01101000 00100000 01110010 01100001 
01101110 00100000 01100001 01110111 01100001 01111001 00100000 
01110111 01101001 01110100 01101000 00100000 01110100 01101000 
01100101 00100000 01110011 01110000 01101111 01101111 01101110 
00001010
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2024
J. Kane, The Emergence of Mind, 
https://doi.org/10.1007/978-3-031-46835-3_4

50
organization. The content of the information being processed cannot 
affect its reorganization. Even though we might think of information as 
having content, recall the technical meaning of the term information, in 
computational contexts. Consider the series of numbers above. The num­
bers have no greater content in any digital system than they do for you as 
you read them. The sequence of the numbers triggers specific mathemati­
cal operations, so that they have a functional role within the system but 
have no value or meaning with respect to anything else.
From the perspective of a human being interacting with the code as it 
appears to us, the numbers are symbolic. They represent something other 
than themselves; they convey meaning. At the most basic level, the distinc­
tive sequence of each of the groupings of eight digits represents a letter. 
The first grouping of digits above, 01010100, represents the letter “t” 
and the two following represent the letters “h” and “e,” respectively. The 
fourth grouping indicates a blank slot that allows for the separation of the 
letter groupings into words. The first seven groupings spell out the two 
words “the cow.” The rest of the passage is the nursery rhyme “Hey 
Diddle Diddle.”
The bolded section represents the words, “The cow jumped over the 
moon.” For us, the phrase elicits cartoon-like images of a cow sailing over 
a bright moon. Perhaps the cow has a bell around its neck and the moon 
has a smiling face. As we hear or read the words, we do not attend to the 
letters forming them or the sounds of the words but to the images we 
form ourselves. We do not receive unambiguous bits of information but 
symbols that spur us to create images we take to be their meaning. The 
images we create, to a lesser or greater extent, resemble those that guided 
the original writer to express them. At the very least, we share the informa­
tion (using the common meaning of the term) with others with the expec­
tation that they will enliven their own  imaginations to experience 
the images we intend for them. The meaning of the information is not in 
the digits or the letters or even the words or the grouping of words, but in 
the images each of us creates for ourselves and share with one another.
Within a computational system, there are no words or phrases or images 
or meaning. There is algorithmic code that sequences the circuits that 
route the flow of electricity from point “a” to point “b.” In this context, 
there are but two possibilities for action at any given point. There are but 
two digits: zeros and ones. Such a binary system allows for all interactions 
between numbers to be reduced to their most basic functional definition 
and the processes used to be sequenced with absolute clarity. Every “zero” 
 
J. KANE

51
is the same as every other “zero”; every “one” is the same as every other 
“one.” Devoid of any internal dimension, or “semantic content,” they are 
inert, and could no more contain or exert a force of their own any more 
than the number “6” could of its own act as if it were the letter “b.”
Their non-individuated meaning makes them interchangeable without 
any loss of their functional value. They can be placed in any order and 
made to perform any function without changing the elements in the struc­
tural dimensions of the system. The programs that govern their functional 
relationships are equally formal. Outside of the numbers, outside of the 
processing, outside of reorganizing the elements populating the system, 
there is nothing. The information placed in the system enters into its own 
segregated universe, and the product (we may call output) of the system 
means nothing other than that the reorganization required by the rules of 
the program is complete. There is no possibility for context or meaning 
beyond the arrangements of the zeros and ones.
In principle, the computational universe includes an infinite range of 
mathematical possibilities where no numerical values or operations have 
priority over any other. Turing called his concept of a digital computa­
tional device a “universal machine” that had no internal elements that 
could confine it as a functional system. Thus, in concept, a computational 
machine should be able to perform any computation at any given point, if 
so directed. In their pristine state before any program may be inscribed, 
they are at perfect equilibrium where there is no basis or cause within the 
system itself that would predispose it to perform any given function or set 
of functions. They are both infinite and void. In this regard, the computa­
tional universe is very much like the uniform and passive expanse of time 
and space of Newton’s model of the physical universe.
Movement within the system, even as simple as adding two numbers, 
requires a source of disequilibrium from outside the system itself. Some 
causal force must enter the system to transform its infinite potentiality into 
specific formal operations. There is nothing in the system itself that would 
cause the addition of two numbers any more than the division of one of 
them into the other. 
Programmers introduce into this uniform canvas organizational struc­
tures (operating systems and programs) that transform the infinite possi­
bilities of computation into a finite set of formal rules. These rules 
determine the sequences of mathematical functions that will be performed 
as information enters the system. In complex systems, multiple sets of 
rules are layered to allow some of them to monitor and guide the revision 
4  WHERE COMPUTATION ENDS 

52
of other rules. In all cases, the rules that govern the system as a whole are 
imposed from outside of the system itself. Neither the informational con­
tent entering the system nor the operations performed is symbolic or rep­
resentational; their only significance within the system consists of their 
functional role within the system itself.
Computational systems function with reference to purposes they them­
selves can apprehend only as their programs allow. The sequencing of 
given operations performed is a function of a non-mathematical intent, 
but the process of computation at each point is governed entirely by the 
laws of rules of the governing mathematics. Operating systems and pro­
grams are intentional; mathematics as a system is not. The externally 
imposed structures of operating systems and programs provide the foun­
dation for all processing; even as some programs allow for revision, those 
revisions rest upon the primary sets of rules operationalizing the intent of 
the programmers. There is no infinite regress here; the rules imposed 
from without constitute the full scope of possibilities for the system, even 
though the results of the processing extend beyond anything its program­
mers may have imagined. As is the case with generative AI, the more com­
plex the processing rules and the more extended the information 
populating of a system, the greater the potential for the system to produce 
output its programmers cannot imagine or understand.
The act of computation does not just happen; it happens as a conse­
quence of some human aim. The very possibility that computations could 
take place requires the presence of principles that lie outside the scope of 
the laws governing computation itself. This is not to say that computers 
are any less capable of employing highly complex algorithms than are 
human beings but that all computational systems are governed by pur­
poses that lie beyond computation as a system of mathematical operations.
The causal impetus setting the system in motion is semantic; its origin 
and purpose provide a meaning outside the system for the strings of num­
bers generated within it. The output of a program is semantic relative to 
the lived lives of those who wrote it even as it is purely syntactic within the 
system itself. Computer programs are syntactic representations of seman­
tic meaning; they exist only as the expression of intentions they could 
neither create nor apprehend. All possibility of semantic meaning lies out­
side of the universe of computation.
 
J. KANE

53
The Invariance of Computational Systems
­
­
1
­
­
When a physical system is capable of implementing the causal structure 
of the abstract system, that physical entity is itself irrelevant to the causal 
system—the course of processing. It is invisible relative to the processing 
taking place. Theoretically, there is no difference in the implementation of 
a computational system between silicon-based circuits or slips of paper 
passed from one desk to another or neurons exchanging inhibitory and 
excitatory molecules. The only differences are practical—how fast and 
effective they are.
­
2
3
­
1 Chalmers 1996, p. 5.
2 Ibid.
3 Ibid., p. 12.
4  WHERE COMPUTATION ENDS 

54
Once a system is implemented, the information that enters it is rede­
fined within the context of the program codes governing its processing. 
The processing does not refer to the world outside the computational 
system even as it may account for the new information in its operational 
sequencing. There is no causal force within the system other than as pre­
scribed by the governing binary code. To the extent any information that 
may exist in a given phenomenon does not translate into code, it does not 
enter the system or affect the course of processing.
No technical innovation can violate this rule; it is central to the theo­
retical foundation of computational theory. Parallel processing systems, 
quantum computers, and neural-network system architectures, are all 
bound to the same principles of syntactic systems. When given the same 
information and programs, all CSAs with equivalent computational capac­
ities will perform the exact same operations in the exact same order and 
yield the exact same results. The only difference might be their processing 
speed. Theoretically, if a generative AI program could be performed by an 
integrated set of wooden abacuses, the abacuses would produce the same 
answers as the world’s most sophisticated computers—admittedly with 
one of them completing the work sometime in the next millennium. The 
primary programmatic structure that sets the context for all computation 
within their systems would be, in Chalmers’ words, as noted previ­
ously, “organizationally invariant”; there could not be any cause that could 
affect their processing rules outside of the structure of the system itself.
The Limits of a Functional View of Intelligence
One of the key attributes of computational systems is their intelligence. 
The word “intelligence” derives from the Latin verb “intelligere,” com­
bining “inter,” meaning between, and “legere,” meaning to choose or 
gather. In rough terms, it refers to the capacity to purposefully choose 
between options. This definition does not necessarily require the capacity 
to consciously recognize a phenomenon as being distinct but only that an 
entity deemed intelligent can respond selectively to a phenomenon in fur­
therance of some preferred end. At the most basic level intelligence refers 
to the ability of an entity to attend to phenomena functionally. A plant 
 
J. KANE

55
bends toward sunlight but does not likely identify sunlight as an object; 
the sunlight is “understood” relative to the plant’s needs rather than as 
having its own unique attributes. To the degree that something has the 
intelligence to learn, it has the ability to use its experience to develop new 
adaptive modes of responding to phenomena more efficiently, effectively, 
or more completely in service of its interests. The essence of intelligence is 
that it can adapt itself relative to its intentions, even to the point of chang­
ing or abandoning them. Such intentional adaptability need not be simple 
or pragmatic as in the example above but may function in more expansive 
contexts. Scientists may guide their research in search of truths transcend­
ing their subjective experience or a humanitarian may commit to purposes 
extending beyond their own personal interests.
In a functional context, these concepts of intelligence and learning are 
not limited to living organisms but may be used to refer to computational 
systems. To the extent that they may adjust their actions like human 
beings, we may say they exhibit “artificial intelligence.” All such machines 
can adjust their own actions in ways directly responsible to the informa­
tion they receive. Some artificially-intelligent machines can use a variety of 
algorithmically-driven methods to revise their own processing sequences. 
Some can be “trained” by incorporating feedback from data that was pre­
viously analyzed. Others may be programmed to find clusters or patterns 
in data and to process them in specific ways. Yet others may integrate 
probabilities in their processing models and monitor feedback or use mul­
tiple examples of a given phenomenon to identify consistent patterns, i.e., 
“Which of these photographs contains pictures of fire hydrants?”
4
Such machines are defined as intelligent relative to their ability to per­
form the functions for which they are intended. Their intelligence is 
4 Larson, Erik J. The Myth of Artificial Intelligence: Why Computers Can’t Think the Way We 
Do. Cambridge Massachusetts. The Belknap Press of Harvard University Press. 2021, p. 140.
4  WHERE COMPUTATION ENDS 

56
derivative and constrained by parameters imposed upon them from with­
out. They cannot generate new processing rules outside of the parameters 
built into their programmatic architecture. Thus, computational systems 
such as generative AI can never exhibit the general intelligence of human 
beings even though they may develop processing rules that seem to be 
“self-­chosen.” As a consequence, their universe is circumscribed by their 
program biases, even though the “self-learned” programs may function in 
ways never imagined by the human programmers who set the system rules. 
Therein lies perhaps the greatest danger of generative AI: it possesses 
functional processing capabilities so far beyond those of its designers and 
can formulate unanticipated and unrecognizable non-human and inhu­
man conclusions.
When DNA Programs
Computational processing requires selected ends to direct programming 
decisions. All information within a given system is defined by its functional 
contribution to those ends. In the case of artificial intelligence systems, 
human programmers select the ends they wish to achieve and design pro­
grams to meet them. However, the question of the origins and nature of 
ends sought by the programmers, as human beings, presents a far more 
complex issue. What purpose or purposes govern the choices human 
beings make in writing computer programs?
In 1995, philosopher Daniel Dennett addressed the question in a semi­
nal work, Darwin’s Dangerous Idea. Dennett argues that human beings, 
like all other organisms, evolved through a process of natural selection. 
Through a process of random gene mutation, some organisms adapted to 
their environments while others did not fare well. Those that adapted, 
survived, and reproduced to drive evolution. Some evolved to have wings 
and keen eyesight while others developed muscular bodies and sharp 
teeth. In human beings, the unfolding of the brain proved central. It 
allowed human organisms to adapt their behaviors by responding quickly 
and effectively to environmental challenges.
Dennett explains that the brain evolved through a process of natural 
selection. It developed subsystems that interacted with one another to 
increase its ability to adapt to particular circumstances at particular times. 
The same dynamic as was responsible for the evolution of the brain was 
also responsible for the evolution of the other bodily organs: they evolved 
to fulfill their functions in order to increase the chances of survival. The 
 
J. KANE

57
functioning of the brain is governed by biological processes just as is the 
functioning of the liver.
While human beings experience subjective consciousness, Dennett 
argues that consciousness is merely a by-product of biological processes. 
The liver produces bile; the brain produces consciousness. The only differ­
ence between the two is that the brain has evolved such that its subsystems 
interact in varied ways depending on the circumstances in any given 
moment. Thus, the human brain can perform various functions from basic 
perception and memory to reading this text and making judgments 
about it.
Dennett theorizes that the brain is adaptable itself and can learn new 
processes in social and cultural environments just as it does in the broader 
natural environment. It does so through the use of cultural “memes” that 
form the basis for cognitive adaptation. Cultural artifacts such as religious 
systems, modes of dress, familial patterns, political ideologies, and viral 
videos are all cultural memes that carry reproducible information that may 
be adapted. Collectively, the complex of all these aspects of life—the bio­
logical and the cultural—interact to generate human thinking.
Cultural environmental factors affect brain processes in the same way 
other environmental factors shape other organs. However, the question 
remains about why the laws of biology produce organisms, human beings 
among them, that attempt to survive when inanimate objects share the 
same drive. While one might imagine many reasons why  all organisms 
share some degree of intelligence, it is clear that intelligence is essential for 
survival. When there is no such need, as in the case of inanimate 
objects, there is no basis for judgement other than as might be determined 
by living organisms. Whatever “intelligence” we may ascribe to a non-­
living object, such as a CSA, it does not make any independent judge­
ments based upon its  own fundamental  needs and interests.  Living 
organisms are self-organized and act in ways that enable them to maintain 
themselves within  environments that  would otherwise  subsume 
them. Inanimate objects do not act to preserve themselves other than as 
they are programed to do so. One might argue that computational sys­
tems, such as those used in military drones, can be programmed to priori­
tize their capacity to maintain their mission capabilities. However, in such 
cases, programmers, not the systems themselves, set the priority—even if 
the programmers themselves may not fully appreciate the implications of 
the programs they write.
4  WHERE COMPUTATION ENDS 

58
­
­
­
­
original
5
However, his argument rests upon the idea that DNA acts to maximize 
its own reproduction, something that is unique among all other mole­
cules. There are no laws in physics that allow for the existence of such 
intention. DNA is itself lifeless and like any other molecule is subject to 
the laws of physics. The assumption here is that life can be reduced to 
molecular processes but does so by removing life itself from consideration. 
While DNA molecules may be essential to life and evolution, there is no 
principle within physics that can explain why they would have the singular 
distinction of acting to reproduce themselves. Their efforts in that regard 
are all the more spectacular when we consider the fact that they employ 
myriads of other molecules in the form of living organisms to achieve 
their aims.
The instinct for survival emerges in the context of life. Instinct is born 
of agency. Where there is no agency, there is no life; where there is no life, 
there is no agency. The agency of life is carried from generation to genera­
tion through DNA, which carries the codes for the synthesis of amino 
acids and the construction of proteins. In this regard, it is much like the 
codes used in computational programs that convey information that is 
meaningful only as its message is delivered. DNA does not include within 
its chemical bonds an instinct to survive. While it is indisputable that DNA 
5 Dennett, Daniel C. Intuition Pumps and Other Tools for Thinking. W.W. Norton and 
Company. New York. 2013, p. 197.
 
J. KANE

59
transmits the instinctive drives for survival and the continuation of all spe­
cies, the laws of physics that shape the molecule itself do not account for 
the function of specific genomic structures. The DNA molecule acquires 
its significance only as it is integrated in an emergent coherent systems of 
living organisms. The laws of physics are necessary for the molecule to 
function but cannot themselves determine the nature of that function.
On the Subjective as Objective
­
­
6
While the association of brain functions and subjective experience is not 
in dispute, that does not suggest that all subjective experience must be 
governed by physical law or that it can be reduced to neural processes. The 
consideration of the brain as a physical object fails to account for the prin­
ciples underlying its organization or functional capacities. It is organized 
and functions responsively to our needs as living organisms. In other 
words, the brain exists as it does only in the living of life. It exists not only 
as an object but within a living subject with the capacity for experience. 
That subjective experience exists within the context of life and cannot be 
fully understood as an object. It attends to meaning that can be under­
stood in the first person but never the third.
6 Ibid., p. 179.
4  WHERE COMPUTATION ENDS 

60
7
Nagel explains that human beings possess some sensory systems that 
are similar to those of a bat but cannot know its sensory experiences. Bats 
use sonar to explore their environment, a sensory system we simply do not 
share. Their subjective experience of the “pings” that they hear reflected 
off the objects around them has evolved within the organizational systems 
that allow the members of the species to perceive environmental factors 
consistent with their needs. Their sensory system and interpretive tem­
plate for modeling the environment are distinct from those that shape 
human experience.
Dennett, responding to Nagel, denies that the subjective experiences of 
a bat are inaccessible to us. He explains that Nagel’s conclusion was more 
a function of the subject he chose, a bat, than the philosophical merit of 
his argument itself. He argues that if Nagel had chosen to ask about what 
it might feel like to be a spider, one would not necessarily have any sensory 
or interpretive basis to imagine its subjective experience. We do not seem 
to have anything in our subjective experience with sufficient similarity to 
that of a spider to draw a comparison. Had he chosen a cat, one might 
have sufficient similar experience and even empathy to claim to under­
stand its subjective experience. The bat is well chosen because it appears to 
exhibit sufficient behavioral complexity for us to infer that it has subjective 
experience but is capable of sensing aspects of the environment through 
sonar, a capacity we do not share. In that case, we assume a type of subjec­
tive experience we cannot have.
7 Nagel, Thomas. What Is It Like To Be a Bat? Stuttgart, Reclams Universal-Bibliothek, 
reprinted 2018, p. 8.
 
J. KANE

61
8
­
He is correct that we could understand the function of a bat’s brain as 
an object—as a calculous constructed with reference to empirical factors in 
the environment, the neural circuitry of the bat, and the bat’s behaviors. 
However, such correlations would not reveal their meaning relative to the 
purposes that underlie the bat’s interactions with the environment. The 
bat, in contrast to the method proposed by Dennett, does not look at its 
own neural activity or sensory organs or behaviors relative to them. The 
bat’s sensory experiences are generative rather than correlational. The bat 
experiences its environment within its effort to maintain itself as a living 
organism just as we do. We could analyze the findings of an fMRI or EEG 
of a bat’s brain relative to specific stimuli but could not classify them as 
indicative of consciousness except as we impose our own subjective experi­
ence into the process. Calculating the mathematical correspondences 
between environmental phenomena and the activity in a bat’s brain would 
not yield any more of a sense of the bat’s subjective experience than a 
statement of probabilities could tell us about how photons feel when they 
collide with other photons.
Ironically, Dennett’s own argument that Nagel’s choice of a bat to 
illustrate his point effectively undermines his own conclusion. A bat’s use 
of sonar has some equivalence to our own sense of hearing; we can imag­
ine what the bat might experience through echolocation. Thus, the man­
ageable gap between human experience and that of a bat gives Dennett a 
framework similar enough to his own sensory experience to allow him to 
claim to interpret its subjective experience statistically. However, any con­
clusions he could reach through the interpretation of the “objective” data 
could not include any reference to the bat’s subjective experience other 
than in the general context of Dennett’s own subjective experience. He 
could refer to its mental state only relative to his experience of his own—
and his own is different than that of the bat. Nagel’s point!
The unrecognized subjective basis for his argument becomes very clear 
when we consider animals with senses far removed from our own. 
8 Dennett, Daniel C. Consciousness Explained. Boston, Little, Brown, and Company, 
1991, p. 447.
4  WHERE COMPUTATION ENDS 

62
Consider, for example, animals that subjectively experience electromag­
netic fields. Migrating birds navigate by sensing the earth’s magnetic fields 
through a substance above their beaks called magnetite. Guiana dolphins 
locate their prey using electroreception, sensing the tiny distinctive electri­
cal fields produced by various types of animals. In such cases, we as human 
beings, have no basis to imagine what these animals experience 
subjectively.
Our knowledge of the content of such sensations depends upon our 
ability to imagine what they are from within the context of the human 
senses or indirectly through the data provided by various technologies. We 
use experiment, mathematics, and public discourse to hone our ideas, but 
these modalities all derive their value within the context of our subjective 
experience. Subjective experience exists only in systems where sentience 
and the integration of complex spectrums of sensory experience emerge 
within biological systems that maintain themselves as they interact with 
their environment. A bat, for all intents and purposes, is a lifeless aggrega­
tion of molecules when we deny its subjectively-driven agency. In that 
case, we would be left with no context to pay “attention to the methods 
and goals,” of the bat relative to its environment as Dennett suggests. 
Where there is no subjective intent to maintain its coherence, the cluster 
of molecules we call a “bat” has no “methods or goals.”
Dennett’s theory of mind holds together with the same type of logically-­
integrated structure and consistency of a well-designed computer pro­
gram. However, like a computer program, it cannot explain the impetus 
governing its design or the meaning of its output. If all organismic activity 
is derived from, and ultimately governed by, the instinct to survive, how is 
survival or any other preferred end possible in a world wholly governed by 
the laws of physics? In physics, there are no ends or means; everything 
simply is what it is, and all occurrences are the product of probability. 
Subjectivity arises only as there is an object and a subject, where an object 
is experienced by the subject relative to its own needs and the systems it 
has evolved to sustain itself. Life cannot be reduced to a lifeless molecule 
of DNA, subjective experience cannot be reduced to a spreadsheet of data.
The Easy and the Hard Questions
At roughly the same time Dennett was introducing his computational 
theory of mind, Chalmers proposed that subjective experience is not 
reducible to objective modes of research and reductive analysis. In his 
 
J. KANE

63
1995 landmark paper, “Facing up to the Problem of Consciousness,” he 
suggests that human consciousness presents two distinct problems—one 
“easy” and the other “hard.”
­
­
­
­
9
The “hard” question focuses on the nature of subjective experience. 
Although Dennett argues that subjective experience can be studied objec­
tively, Chalmers maintains that it is not reducible to the physical properties 
of matter alone. A complete map of the brain as a biochemical system 
could not explain why it is conscious. As a consequence, he reasons that 
standard modes of empirical research are insufficient.
­
­
­
10
For him, cognition is defined as the functional property of an imple­
mented computational system with its own causal structure. The fact that 
an implemented cognitive system can respond to varied information with 
varied computational sequences governed by algorithms is sufficient to 
9 Chalmers, David J. “A Computational Foundation for the Study of Cognition.” 
http:cogprints.org/319/1/computation.html. p. 2.
10 Ibid., pp. 6, 7.
4  WHERE COMPUTATION ENDS 

64
deem it cognitive. When the functional template of a program functions 
through some means, whether the brain of an organism or a laptop, intel­
ligence is exercised and cognition takes place. In this theoretical frame­
work, cognition does not imply cognizance—an awareness of something. 
Rather, it refers to the ability of an entity to act intelligently, selecting its 
own functional sequences and rendering its own output.
­
11
12
Between Syntax and Semantics
Chalmers maintains that while human cognitive processes can be under­
stood computationally, human subjective experience cannot. Subjective 
experience cannot be explained fully in terms of physical processes in the 
brain or computational models of cognitive processes. In his view, subjec­
tivity is an intrinsic aspect of conscious experience that is related to but not 
a product of any identifiable objective factors. In a broader context, he 
suggests that although consciousness is clearly related to biological laws 
and functions, it may not be governed by them. Thus, there is what he 
calls an “explanatory gap” between consciousness and subjective experi­
ence and human cognitive processes.
11 Ibid., p. 1.
12 Ibid., p. 16.
 
J. KANE

65
­
­
13
Following the logic, if human beings have subjective experiences that 
emerge in the context of neural functions, and machines computationally 
reproduce the very same functions at a level equivalent to the neural level, 
those machines will have the same subjective experiences as human beings. 
If the two would be indistinguishable based upon the computational 
capacities of the machines, reason would dictate that all human subjective 
experience must also be entirely derived from computational processes.
Chalmers illustrates his emergent concept of experience and the related 
concept of semantic meaning in his discussion of the famous thought 
experiment of the “Chinese Room” proposed in 1980 by the philosopher 
John Searle.
Searle effectively turned the Turing Test inside out. Rather than asking 
an interlocutor outside of a room to determine if communication coming 
from inside it was from a man or a computer, he asked how a person inside 
a closed room might experience the meaning of communications with 
someone outside the room in a language he did not understand.
­
­
14
If the person inside the room developed high-level skill in following the 
rules, the Chinese-speaker outside the room sending in the messages and 
13 Chalmers, David J. The Conscious Mind: In Search of a Fundamental Theory, Oxford 
University Press, 199, p. 321.
14 Searle 1984, p. 33.
4  WHERE COMPUTATION ENDS 

66
receiving the responses might mistakenly believe the person in the room 
understood the content of the communication. For Searle, the Chinese 
room illustrates that the semantic meaning of language cannot be reduced 
to patterns of syntax. It involves the association of words with the subjec­
tive experience of their meaning in the context of lived life.
­
­
15
16
Thus, conscious experience follows upon the implementation of a com­
putational program. When two implementation systems have the same 
functional capacities and implement the same program, the conscious 
experience produced by the two of them is indistinguishable. However, 
we must consider the nature of the non-Chinese speaking speaker’s expe­
rience of the semantic meaning of the squiggly lines he received in the 
context of the instructions he was told to follow. Their meaning would 
amount to their syntactic relationships, which is to say that applying syn­
tactic rules itself constitutes semantic meaning. If semantic meaning can 
be defined as meaning syntactically governed action, the term would be so 
weak as to be meaningless.
15 Chalmers, p. 325.
16 Ibid., p. 326.
 
J. KANE

67
The person inside the room would not have any conscious experience 
of the semantic meaning of the prescribed actions other than the possible 
experience of their meaninglessness. Whatever level of skill he developed 
in the application of the rules, there would be no way for him to connect 
those rules in any way that may be said to replicate their semantic meaning 
outside of the rules accompanying the baskets. No matter the complexity 
of the operations performed, the system would remain semantically empty. 
The wall between syntactical function and semantic meaning is every bit as 
hard and fast as the wall separating the inside of the room from the rest of 
the world outside.
Chalmers does not necessarily contend that the brain is a computer. His 
work is particularly important because it provides a clear and lucid presen­
tation of often unexamined assumption that a technologically-based com­
putational framework can be used as a foundation for the study of human 
cognition, including semantic meaning. He provides a theoretical frame­
work in which subjective experience cannot be understood in purely com­
putational terms but argues that physically-implemented purely abstract 
computational systems can be said to be in possession of a mind and con­
sciousness with all the capacities for subjective experience of minds such as 
our own. In so doing, he lays bare the fundamental limitations and contra­
dictions of the assumptions undergirding computational theories of the 
human thinking and the human mind.
In Chalmers’ model, conscious experience and the semantic of meaning 
of language are products of computational processes that preclude the 
influence of any aspects of human existence that may not be coded and 
implemented in binary terms and mathematical processes. For him, sub­
jective experience may exist independent of computational processes, but, 
as was the case with Descartes’ separation of mind and matter, we are left 
with no means for subjective experience to play a causal role in human 
thinking. It exists but cannot affect human cognition other than as it can 
be made computable. In this computational model of dualism, the equiva­
lent of conscious human thinking can be divorced from living human beings.
Life Matters
The concepts of the human mind as a CSA and of CSAs as being capable 
of possessing minds are the cognitive science equivalents to Newton’s 
assumptions about the physical universe: as theoretical frameworks they 
4  WHERE COMPUTATION ENDS 

68
are exceedingly useful, but their primary principles are fundamen­
tally flawed.
Before Newton, Descartes created a methodological approach to sci­
ence that resulted in the conclusion that the mind is a thinking thing sepa­
rate and distinct from himself as a living, breathing human being. He 
separated the mind from the body, and the mind functioned according to 
independent principles. For him, the connection between the two was 
found in the pineal gland located at the base of the brain, but that won’t 
quite work for us today.
Chalmers sees the human mind primarily as an abstract causal system 
that does not necessarily need a human body for implementation. Any 
physical system capable of meeting the specifications required by the sys­
tem could serve just as well. When the mind is based upon a computationally-­
configured abstract causal system and is implemented by a physical 
mechanism that cannot affect the rules of that system, neither conscious­
ness nor subjective experience can play a role in the processing of 
information.
17
18
However, Chalmers maintains that biology derives its laws from physics 
but that the properties of life cannot be reduced to physics alone. He con­
cedes that biological systems have emergent properties but cannot provide 
a pathway for those properties to have any impact on the laws of physics as 
they express themselves. If they could, those properties would constitute 
“principled differences” that might separate biological and non-biological 
objects. Those emergent properties might exist, but they cannot affect 
either the structure or implementation of a given abstract system of causa­
tion. They have no causal power or influence.
17 Chalmers, David. “The Singularity: A Philosophical Analysis.” Journal of Consciousness 
Studies vol. 17, No. 9–10, 2010, p. 45.
18 Ibid.
 
J. KANE

69
When living and the inanimate are one and the same, reason precludes 
that one can be conscious while the other cannot. Understanding that no 
such distinction is possible in this framework, Chalmers proposes that 
there it is possible that consciousness may be a fundamental aspect of mat­
ter—a concept called protopsychicism. And he may be right. If conscious­
ness exists in all things, the idea may actually open the door to insights we 
cannot yet imagine.
­
­
19
When Descartes wrote his cogito, he established a reductionist ground 
for science that separated the mind and body that continues as the under­
belly of computationalism. His method focused on establishing an objec­
tive system of knowledge that provided its own validity completely devoid 
of any subjective experience. Although philosophers of science have long 
since revised and reinterpreted the concept, reductionism in one form or 
another continues to dominate much of scientific research and theory. The 
depth of the analyses offered by the Churchlands, Dennett, and Chalmers 
serves to illustrate the futility of the reductionism and the dualism inher­
ent in it.
While we may never know whether the universe itself is conscious, we 
can reasonably assume that we are, that we live in physical bodies, and that 
the two are intimately connected. The word human shares its origin with 
the word humus, meaning earth. In so far as we are human beings, beings 
of the earth, our minds and bodies form an unbroken unity. Their dis­
union in computational theory begins with their fundamental focus on 
linguistic systems, independent of anything that might have led to lan­
guage being created. The construction of theory rests upon the study of 
words as discrete entities removed from any consideration of the non-­
linguistic context in which they arose. Thinking is reduced to systems of 
19 Nagel, Thomas, Mind and Cosmos: Why the Materialist Neo-Darwinian Conception of 
Nature is Almost Certainly False. Oxford, UK, Oxford University Press, 2012, pp. 61–62.
4  WHERE COMPUTATION ENDS 

70
language; the mind is reduced to the implementation of systems of lan­
guage; subjective experience reduced to computation or a product of 
computation; and living organisms are reduced to the physical systems 
bound by the same laws that apply to inanimate objects.
In the end, life, consciousness, subjective experience, and the possibility 
of ideas filled with semantic meaning hang suspended without origin or 
purpose in a universe that has no place for them. If they do exist, and if we 
are to find them, we need another way of searching.
 
J. KANE

71
CHAPTER 5
Relational Science
Beyond the Boundaries of Empirical Reductionism
­
­
1
The problem of dualism will not resolve itself with the refinement or 
adaptation of reductionism or advancements in technology. Reductionism, 
in all its forms and extended applications, gives us a picture of the universe 
where the mind remains effectively absent, or at best, inconsequentially 
1 Schrödinger, Erwin. What is Life?: Mind and Matter and Autobiographical Sketches. 
Cambridge, UK, Cambridge University Press, 1996, p. 119.
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2024
J. Kane, The Emergence of Mind, 
https://doi.org/10.1007/978-3-031-46835-3_5

72
adjacent. While the origins of consciousness and the nature of the human 
mind will likely always lay shrouded in mystery, our very questions about 
them are embedded in the context of our subjective experience. We recog­
nize that for all that we may come to understand of the world, there 
remains the question of the nature of our own minds within it. Even as we 
address questions of all that surrounds us, we remain aware that our 
answers are incomplete so long as they have no place for what lies within 
us. Ironically, the efficacy of empirical reductionism in understanding the 
universe as blinds us to its limits in addressing the irreducible nature of 
life and consciousness.
For all we have learned through empirical reductionism, we are bound 
by it; we have difficulty in moving beyond it because we have confined the 
limits of the universe by the limits of our method of thinking. The bound­
ary between the physical world and our minds is our creation. We know 
that somehow the two are bound together, but can’t unite them in our 
thinking.
Although we might think of the ultimate questions of our existence as 
wistful or sentimental, they are the quintessential expressions of our con­
sciousness. We long for a coherent understanding of our own existence as 
much as we attempt to develop a coherent understanding of the world 
around us. We seek coherence in our understanding of the world and not 
merely power or control over it. We deceive ourselves if we believe the 
scientific study of the origins of the universe or the birth and death of stars 
billions of years ago at unimaginable distances is driven purely by practical 
considerations. They are expressions of our longing for coherence for all 
that we encounter within our consciousness, including our consciousness 
itself. That very longing lies at the heart of the spiritual traditions around 
the world. Ultimately, even those of us who dismiss metaphysics in all its 
forms know that beyond our systems of philosophy and science, the nature 
of the human mind and consciousness remains a mystery.
If we are to move beyond the boundaries we have created, we need not 
abandon empirical research or scientific rigor. Both are essential. However, 
we must move past the notion that everything can be understood by 
breaking it into its component parts with the expectation that they hold 
the key to reassembling themselves back again. Once we do, we may find 
that some complex systems introduce a structure and processes to their 
own component elements.
 
J. KANE

73
­
2
3
The problem of the conscious mind is not only that it eludes definition 
but that it does not have a place within the universe as it can be understood 
through empirical reductionism. Despite  all the scholarly debates and 
refinements of scientific method, many, though not all, researchers share 
Descartes’ assumption that science is confined to the mathematical rela­
tionships between discrete objects with their own distinct properties. In 
that context, all causation moves from the most elementary of particles 
upward to increasingly complex systems. Given this fundamental assump­
tion, the realities all of us know as human beings such as subjective experi­
ence and consciousness, are far too vague and empirically unavailable to 
assume any causal role. To do so, would require an acceptance of the pos­
sibility of downward causation where complex systems can exert their influ­
ence on the actions and interactions of their component parts. For that, a 
new way of thinking is needed. That new conceptual framework must not 
focus on the subjective dimensions of our existence as “reality-­adjacent” but 
provide a more expansive mode for understanding that accounts for our 
conscious minds within the physical universe. Nagel explains,
­
­
­
4
2 Hawking, Stephen, and Leonard Mlodinaw. The Grand Design. New  York, Bantam 
Books, 2010, p. 26.
3 Ibid.
4 Nagel, 2012, pp. 32–33.
5  RELATIONAL SCIENCE 

74
Ironically, Chalmers provides an essential insight into the foundation 
for such radically expansive understanding. He makes clear that the bits of 
information in any given computational system have no value other than 
in relation to one another. An isolated zero or one has no significance; it 
acquires meaning in its function within a system. More broadly, we may 
say that their meaning is relational. His argument pertains to the connec­
tions between the states of abstract syntactical systems but the same con­
cept can be applied to understanding phenomena in the physical universe. 
The only major difference is that the rules governing computational sys­
tems are imposed from outside the systems themselves while the complex 
systems in the universe are self-organizing.
As we have seen, computational systems exist within the universe of 
mathematics—a system that is abstract. Viewed as a domain in which for­
mal operations take place, the mathematical universe in and of itself has no 
capacity to perform any calculation or to establish any rules to sequence of 
calculations. The perfect equilibrium of the system has to be broken for 
any operation to be performed. Computational programs create disequi­
librium in that they introduce specific operational sequences to meet cho­
sen objectives. The relationships that eventuate between the bits of 
informational units are caused by considerations outside the system of 
mathematics itself.
In contrast, in the universe in which we live, the causal principles that 
govern the universe are not imposed from without. Viewed from a reduc­
tive framework, those causal systems may be understood by observing the 
interactions of individual objects to identify mathematical patterns in the 
complex systems they create. However, we may also approach a complex 
system as a dynamic entity that has its own laws that are not reducible. In 
that case, complex systems may exert their own effect on the actions and 
interactions among their component elements. The difference between 
the two types of systems is illustrated with reference to Newton’s theory 
of gravity.
Newton knew that all physical objects existed in something called the 
universe; they had to exist somewhere and at some time, whether they 
were in ether of the heavens or hanging on branches. Objects could not 
move from one place to another without there being clearly delineated 
locations. Thus, one of the questions Newton had to address was exactly 
how he could locate objects in space; locating an object means identifying 
where it may be found in relative to something else. Although some other 
great minds of his time, most notably Gottfried Wilhelm Leibniz, 
 
J. KANE

75
proposed a relational model of space so that objects were located relative 
to one another, Newton proposed that they all be located relative to a 
static background of space. Furthermore, he needed to define the passage 
of time if he was to be able to calculate the speed at which objects moved. 
He surmised that velocity could not be determined without a consistent 
measure of time. Understanding the need for a conceptual framework to 
transcribe his observations into mathematics, he decided to claim that 
both time and space were fixed and uniform across the universe. He rooted 
his theories in the belief that the time and space formed a featureless aether 
that lacked any causal power to affect the movement of objects. Space and 
time served as coordinate points, uniform and functionally inconsequen­
tial; they were the “where and when” but had no impact on the “what,” 
“how,” or “why” of the movement of objects in the universe.
His image of the universe was much like the abstract domain of a com­
puter where programs can be inscribed without any complicating factors. 
In that framework, all objects were subject to gravity and none could act 
of their own accord. Everything was propelled, moved by the force of 
gravity or the impact of another object.
­
­
5
The laws he described in his calculations were remarkably accurate and 
seemed universally consistent in their application. Newton established a 
foundation for physics that lasted for roughly 250 years, and created a 
framework for understanding all things physical (including the matter of 
which are composed) that continues as a fundamental framework for much 
of engineering even today. However, his theory of gravitation was “uni­
versal” only within the absolute limitations of the assumptions about time 
and space he used to create. The patterns he identified mathematically 
were derived from empirical observation, but his model of the universe 
was itself a product of his assumptions.
5 Turnbull, H.W., Scott, J.F., and Hall, A.R. (Eds.). The Correspondence of Isaac Newton, 
Volume 2. Cambridge University Press. 1960, pp. 305–307.
5  RELATIONAL SCIENCE 

76
Over time, a number of physicists found unexpected and inexplicable 
new patterns that did not fit within Newton’s conceptions of time and 
space. For one, in 1865, James Clerk Maxwell, while studying electro-­
magnetic fields, formulated a number of equations that limited the speed 
of all objects in the universe to the speed of light in a vacuum, something 
that made no sense in the context of Newtonian time and space. By May 
of 1905, the fundamental problem with Newton’s assumptions crystal­
lized in the mind of a 26-year-old Swiss patent clerk, Albert Einstein.
Coming home from work, he passed a grand clock in Bern and won­
dered what would happen if his trolley traveled out from the clock at the 
speed of light. He immediately realized that the time on the face of the 
town clock would be fixed to an observer in the trolley but that the watch 
on his hand would continue to tick as usual. From the passenger’s point of 
view, time in the world outside his window would cease, while time inside 
the trolley would maintain its constant flow. Einstein reasoned that either 
time and space differed with observer velocity or the laws of the universe 
were not themselves consistent.
Contemplating the problem, he insisted that the two contradictory 
observations had to be bound by a single, inviolable unity. Rather than 
focusing on describing empirical phenomena, he sought the principles 
generating the world as it could be observed. He viewed the laws creating 
the world as the ultimate reality, with the physical universe being their 
expression. No observation or set of observations or patterns of observa­
tion were anything more than particular instances of greater laws.
In this context, he sought laws based upon dynamic principles that 
transcended empirical boundaries even as the laws he sought would have 
to prove consistent with empirical observation. He knew he could not 
limit the theoretical scope of physics to the confines of empirical observa­
tion and reasoned that the only way to reconcile the lawful implications of 
Newtonian mechanics and Maxwell’s equations was to reject the notion 
that time and space were fixed and absolute.
In fact, Einstein did not challenge Newton’s observations or his math­
ematics. Rather, he rejected Newton’s template of the universe. Even 
more fundamentally, he rejected his concept that science should define 
physical law in terms of empirical observation. For him, the laws of the 
universe could express themselves in empirically conflicting ways relative 
to a single set of events depending upon the vantage points of multiple 
observers. For Newton, the universe was a static tableau against which all 
things could be measured; for Einstein it was relational such that empirical 
 
J. KANE

77
measures could vary while the laws governing them would remain invari­
ant. A mere six weeks after his trolley ride, he finished his landmark paper 
introducing the theory of special relativity, a theory he originally entitled 
the “theory of invariance.”
6
7
­
Quantum Fields
The same relational dynamics holds at the most minute level of the physi­
cal universe in quantum particles. Their interactions are described in the 
mathematics of quantum mechanics. Quantum mechanics is largely based 
upon the behavioral patterns of quantum particles as they may be under­
stood in a state as close to isolation as possible. In this regard, the study of 
the behavior of quantum particles is like any other experimental subject: it 
requires the elimination, or control, of extraneous variables. Viewed in 
this context, individual quantum particles do behave in very regular wave­
like patterns that constitute some of their most basic characteristics. These 
6 Isaacson, Walter, Einstein: His Life and Universe. Simon and Schuster, New  York, 
2007, p. 145.
7 Ibid.
5  RELATIONAL SCIENCE 

78
patterns are said to constitute quantum coherence because of their mathe­
matical consistencies. These characteristics are believed to be the founda­
tional laws governing the physical universe. They are at the base of the 
arrow of causation; everything is believed to move from the properties of 
these particles upward.
­
8
The problem here is that quantum particles do not actually exist in 
isolation and that they act in radically different ways when interacting with 
other particles and forms of energy. They exist relationally in systems of 
matter and energy known as quantum fields. These fields exist everywhere 
in the universe in different configurations and affect the probabilities that 
individual quanta will act in one way or another. These fields continuously 
intersect and interact dynamically to create particles of matter and orga­
nize them in complex structures. They are the foundation for, and the 
context within which, quantum particles act. Within these fields, quantum 
particles do not act in the coherent patterns exhibited in isolation but in 
entirely new and varied ways, a phenomenon most commonly called 
“quantum decoherence.”
However, rather than moving from coherence to decoherence, or from 
stability to instability, they move from infinite potentiality to specific pat­
terns of behavior in the context of the constellations of particles and 
energy in which they exist. Quantum fields open the possibility for new 
patterns of interaction to emerge. In complex environments, the wave pat­
terns found in an idealized isolated system may be said to break down but 
actually express new and persistent patterns of probability. Outside experi­
mentally restrictive environments, when in complex dynamic fields, indi­
vidual quantum particles act in varied, yet principle-bound wave patterns.
8 Quoted in Prigogine, Ilya. The End of certainty: Time, Chaos and the New Laws of Nature. 
New York, The Free Press, 1997, p. 157.
 
J. KANE

79
9
­
­
10
11
­
12
­
­
9 Prigogine, p. 54.
10 Ibid., p. xiv.
11 Ibid., p. xv.
12 Prigogine, p. 26.
5  RELATIONAL SCIENCE 

80
From Uncertainty to Organization
Our understanding of physical reality at its smallest scale begins with a 
recognition that at such scale, there is no absolute bedrock upon which to 
build an understanding of the physical universe. As we have seen, the physi­
cal universe at its core, is indeterminate and uncertain; it is not an abstrac­
tion where all interactions can be reduced to a determinative  algorithm. 
Each particle exists and expresses itself in dynamic relation to the fields of 
matter and energy in which it exists. 
The uncertainty at the core of the physical universe allows for diversity 
in the way individual particles behave and interact with other elements in 
a field. However, patterns may emerge, and those patterns may be sus­
tained in the form of complex systems. Those complex systems can affect 
the fields in which they exist so that increasingly complex systems with 
their own principles of organization emerge. Those sustained complex sys­
tems constitute what we know as the objects within the universe, ourselves 
included.
­
13
­
­
14
When particles form complex systems far away from the statistical pat­
terns of probability that could be expected, they can develop distinct and 
13 Anderson, P.W. “More is Different,” Science, vol. 177, no. 4047, 1972, p. 393.
14 Prigogine, p. 65.
 
J. KANE

81
localized relational patterns of behavior. Nobel Laureate, Ilya Prigogine 
explains,
15
Relational systems effectively constrain the ways in which any given 
particle can express itself. Newton thought of the objects he observed as 
moving through an inert ether that had no impact upon the objects them­
selves. With space between them, objects were treated as distinct with 
their own identities and properties. In a field-based universe, individual 
particles are expressions of the local patterns of energy; they act in accor­
dance with the dynamics of the whole. Individual particles of varying types 
with common characteristics will form, but their behavioral patterns will 
reflect their position in the field. Their behaviors will be relationally lim­
ited. The assemblages, in turn, exhibit macro characteristics that are not 
attributable to the properties of individual particles.
16
­
17
­
15 Ibid.
16 Laughlin, Robert. A Different World: Reinventing Physics from the Bottom Down. 
New York, Basic Books, 2005, p. 31.
17 Ibid., p. 45.
5  RELATIONAL SCIENCE 

82
18
­
Laughlin does not suggest that primitive matter has a “mind” that can 
evaluate its options with the freedom to do as it wills but rather that com­
plex systems follow organizational rules that do not exist at lower levels of 
organization. They are emergent. Reductionism simply cannot apprehend 
them. Higher-level organizational principles are necessary to understand 
the structure and behavior of complex systems, including all those that 
populate the world of classical physics—atoms, molecules, planets, stars, 
and you and me.
­
­
­
­
19
20
18 Ibid., p. 44.
19 Ibid., p. 36.
20 Ibid., p. 40.
 
J. KANE

83
21
The regularities at any level of organization depend upon the diverse 
possibilities of the component elements of which they are composed. 
Those potential forms of expression form, as it were, a working founda­
tion where relational dynamics can render them coherent systems with 
more complex organization with new potentials for expression.
Dissipative Systems
Physical matter tends to move toward randomness rather than order. 
Order requires energy and energy, like water, will flow from higher to 
lower levels. However, some physical systems violate that principle by 
absorbing energy from their surrounding environment to use it to main­
tain their structure. They organize themselves against the physical laws 
that apply in their surrounding environment. Physical chemist Ilya 
Prigogine discovered that certain complex systems do increase in order 
rather than entropy. They do so by developing emergent organizational 
principles that could not have been predicted even if everything was 
known beforehand. They actually organize themselves and “create order 
out of chaos”—a fact Prigogine says embodies “new laws of nature.”
22
Those emergent processes then set the conditions for new interactions 
and cycles of the dynamic dialogue. In some cases, the cycling forms stable 
patterns of organization that diverge significantly from what would be 
anticipated in a reductionist model of the universe. Thus, dissipative sys­
tems themselves may not only dissolve but evolve. In their evolution, the 
organizational principles of one system become the foundation for the 
21 Ibid., p. 35.
22 Prigogine, p. 67.
5  RELATIONAL SCIENCE 

84
emergence of additional principles of organization and new dissipative sys­
tems. The more extensive the process is, the more the governing principles 
of emergence diverge from the expectations associated with reductionist 
laws. In short, the more organized such complex systems become, the 
further they move from the equilibrium that would hold outside their 
systemic coherence. Prigogine summarizes,
­
­
23
The structures and internal processes in dissipative systems allow them 
to maintain a continuous state of high disequilibrium with the surround­
ing environment. Whether the new laws operating within them are the 
result of unknown quantum or classical laws that express themselves only 
in complex systems or they constitute an entirely distinct set of laws, it is 
clear that there is no reductionist theoretical basis for determining exactly 
when and how such systems will form or how they will function. Whatever 
the origins of their organization, dissipative systems are critical for under­
standing the emergence of complex systems, particularly as a foundation 
for the emergence of biological organisms.
If the organization of the system is significantly disrupted, such as when 
it is reduced to pieces, the principles can no longer be sustained, and the 
system dis-integrates to the point of equilibrium with its surrounding 
environment. Putting the elements of the system back in place will not 
restore the principles since they emerged in the context of their overall 
organization. The process of emergence cannot be reversed. This property 
of irreversibility is not possible within a reductive view of the universe.
When we take apart a mechanical object such as a car, we can put the 
parts back together without any loss of function. For all intents and pur­
poses, there would be no difference between the car before we took it 
apart and after we put it back together. We say that the process is revers­
ible. When we view the universe as a machine, as something constructed 
23 Ibid., p. 162.
 
J. KANE

85
from individual pieces, the same reversibility holds. We take it apart and 
put it back together just as easily. It does not matter if we start with put­
ting the pieces together or with taking them apart. They are mirror images 
of one another so that theoretically we could reverse the flow of time 
without consequence.
In many physical systems the processes that occur are reversible. The 
laws of physics apply equally to clusters of particles as they do to taking 
those same clusters apart. They apply equally to the forming of systems as 
they do to their dissolution. The laws of physics do not recognize the 
movement of time. At least this holds true in an idealized state.
However, some complex systems have their own emergent organiza­
tional principles that keep them distinct from their surrounding environ­
ment. They use energy to maintain themselves and dissipate small amounts 
of energy into the surrounding environment as a result of their actions. 
For example, the human body uses the energy from the foods we eat 
and dissipates energy in the form of heat. However, the energy given off is 
diffuse so that is no longer available for use. The process contributes to a 
general randomness in the environment, a process known as entropy.
The entropy created cannot be used to reverse the process; it cannot be 
reintroduced into the system to return it to its original state. The system 
and its environment may still have the same amount of energy and matter, 
but it is now more random and disorganized. The increased level of ran­
domness introduces the arrow of time into physics. It may be thought of 
as a measure of entropy; increases in entropy mark the passage of time. 
The introduction of time allows for the evolution of the universe, for 
things to move forward in time—something, oddly enough, that is not 
possible in a strictly reductionist model of the universe.
Multiple Levels of Emergence
The process of evolution is not confined to a single transition from one 
level of complex organization to another. Complex systems with emergent 
properties can create the foundation for yet more complex emergent sys­
tems based on wholly new principles and having wholly new properties. 
Each layer of complexity in the physical world adds its own organizational 
principles to the layers below and establishes a dynamic foundation for 
higher levels of principled organization.
5  RELATIONAL SCIENCE 

86
­
­
24
25
Each more physically basic level of systemic complexity sets the param­
eters for new principles of organization to emerge, each with their own 
unique principles of organization. Each higher level of systemic complex­
ity, in turn, lessens the range of possible expressions of the principles of the 
lower level in order to create new symmetries and balances. Both levels 
exert some degree of causal force on the other. The arrow of causality is 
both from the bottom up and from the top down—from the part to the 
systemic whole and the systemic whole to the part.
The process of emergence continues through the creation of systems 
with heightened layers of complexity and new principles of organization 
and new types of symmetries and balances. In the context of our discus­
sion, symmetry refers to the functional balances in any given system; it 
refers to the principles that allow any given system to maintain its coher­
ence. Each heightened level of complexity is dependent upon all the prin­
ciples governing the layers below it. At the same time, each layer of 
heightened systemic complexity is governed by emergent organizational 
principles that enable them to function as coherent entities. As we shall 
see, such is the case with living organisms.
24 Hawking and Mlodinow, pp. 67–68.
25 Ibid., p. 68.
 
J. KANE

87
The problem with the reductive process at the heart of material reduc­
tionism is that it negates the dynamic relational contexts in which physical 
objects emerge. Stated more generally, the assumption that the causality 
must flow upward from the properties of individual particles simply does 
not hold.
In complex systems, reductionism as a mode of understanding breaks 
down again and again. Gaps form with each new level of organization. 
There is a gap between the laws of quantum mechanics and the laws of clas­
sical physics; there is a gap between the laws of chemistry and those of biol­
ogy; there is a gap between the laws of biology and the experience of 
sensation; and there is a gap between the algorithmic processing of informa­
tion and consciousness. The assumption is that all these gaps will close with 
sufficient research, but there is no principled reason to expect that they will.
In actuality, there are no separate entities even as we can abstract them 
with our thinking. All things come into existence relationally. The “gaps” 
we see are the dissociation of idealized objects in relative isolation and the 
actuality of the characteristics of those objects in complex relational sys­
tems. The gaps we see are in fact the points at which new organizational 
dynamics emerge.
Our capacity to think is the expression of multiple layers of our emer­
gence as human beings, with each layer having its own purposes and prin­
ciples that we embody in our thinking. Our emergence as a species, as 
human societies and as individual human beings has not been in isolation 
but in relation with the world around us and with one another. Our expe­
riences at all these levels of our existence express themselves in our think­
ing and give it meaning.
Generative AI represents the introduction of a new level of organiza­
tion, but not one that includes any of the experiences or principles giving 
substance and form to human thinking. All computational systems exist as 
pure abstractions  without any  purpose other than as is imposed upon 
them from without. It is an instrument with no particular purpose but is 
capable of adapting to an infinite variety of tasks. None of which has any 
necessary relation to anything in the world. It knows no Truth, as Descartes 
would define it. Neither is it bound to reality as we experience it. It can 
yield products of pure fantasy as easily as it can discover new treatments for 
cancer, but it can’t tell the difference. It  does  not have any context 
to understand why any difference would matter relative to anything in the 
world that we experience. To the extent that we cannot understand the 
difference between human thinking and the AI processing, neither can we 
understand the difference between  life and lifelessness.
5  RELATIONAL SCIENCE 

89
CHAPTER 6
Life and Mind
Life Defines Itself
The physical world maintains its order and balance through physical sym­
metries. These symmetries are invariant laws that hold in all places and at 
all times. Even as the universe is in constant change, the symmetries of 
physical law ensure continuity in the transitions. As the acids in my stom­
ach break down the proteins of my dinner last night, the chemical reac­
tions that take place are balanced. Nothing is created or destroyed. The 
number of atoms and the elements involved on one side of the reaction are 
the same in number and type once the reaction has taken place.
There is no doubt that the atoms out of which living organisms are 
composed are no different that the atoms anywhere else. Thus, one would 
expect that the symmetries in living matter function exactly as they do in 
all other physical objects. But they don’t: they don’t change but neither 
are they all-powerful.
Neuroscientist and theoretician Karl Friston has conducted extraordi­
nary research on the relationships between complex systems such as living 
organisms and their surrounding environment. He begins with the basic 
and essential observation that organisms may be said to exist as unique 
objects to the extent that they may be distinguished from their environ­
ment. That distinction is marked by a boundary that differentiates the 
structures and functions on one side from those on the other.
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2024
J. Kane, The Emergence of Mind, 
https://doi.org/10.1007/978-3-031-46835-3_6

90
External to the organisms, the laws of physics aim toward equilibrium: 
a state of relative balance that requires the lowest expenditure of energy. 
However, living organisms don’t share in that equilibrium; they maintain 
themselves outside of it with their own internal symmetries. Living organ­
isms structure themselves according to their own organizational princi­
ples. Those principles are not the same as those in the surrounding 
environment, and their existence cannot be attributed to the properties of 
the environment outside its boundary. They form their own unique sym­
metries and systems of balance. When organisms no longer can maintain 
their own stability far from the equilibrium of the surrounding environ­
ment, they die. As their bodies decompose, they return to equilibrium 
with the environment. The study of life in terms of physics or chemistry is 
autopsy; it is like the study of architecture by analyzing the configurations 
of bricks.
1
­
­
2
In effect, biological organisms are dissipative systems that maintain 
internal coherence in a state far from equilibrium with their surrounding 
environments. Those boundaries are open so that energy and matter may 
pass from one side to the other. But as they do, the rules that govern them 
change in ways similar to a phase state transition in physics: unpredictably, 
immediately, and consistently throughout the system. We do not know 
how these systems come to be developed just as they are, and we cannot 
explain in reducible terms just how their molecules form their dynamic 
symmetries. The principles that distinguish living organisms from inani­
mate objects are not in individual molecules but in their shared purpose of 
maintaining the coherence of the system of which they are a part. The 
1 Prigogine, p. 162.
2 Laughlin, p. 45.
 
J. KANE

91
principles of life are organized purposefully: they do not exist outside of 
the orchestrated complexity of life itself.
In the example above of the digestion of my dinner last night, the pro­
teins of the food I ate were broken down into amino acids. These amino 
acids were then absorbed into my bloodstream and synthesized into pro­
teins within me. The symmetries of physical chemistry were no different 
than anywhere else, but the proteins formed were unique to me. The 
atoms in the molecules were the same, but they were organized so that 
they met my bodily needs. The synthesis that took place was not a product 
of the laws governing atoms as physical particles but as physical particles 
organized to meet my needs as a living organism.
 Enactive Emergence
In order for emergent principles to function against the force of the laws 
governing their surrounding environment, living organisms must use 
energy. All systems have ebbs and flows of energy, but living organisms 
require a sustained level of energy to maintain themselves, and they must 
draw it from their surrounding environment. Friston explains that living 
organisms interact with their environments in ways that allow them to 
expend the least possible effort to extract the greatest supply of energy.
To maximize their efficiency, in his words, they act to “minimize sur­
prise.” In this context, he has been able to construct computational mod­
els that demonstrate the statistical differences between random actions 
and the behavior of living organisms as they interact with their environ­
ments. The models demonstrate that organisms act with intent and exer­
cise intelligence to minimize error in their interactions.
However, the fact that such patterns can be identified is much like a 
syntactic understanding of language. Algorithmic models of neural func­
tion do not, in and of themselves, account for the dynamic processes that 
underlie them. Organisms do not merely exist in environments but live 
and evolve in relation to them. Their bodies emerge in dialogue with their 
environments. Organisms do not have transactional exchanges with their 
surroundings but transformational relationships. Every anatomical and 
functional aspect of their bodies is an expression of the two together.
Consider, for example, a fish living in a pond. The fish does not exist 
independent of the pond but owes its physiological form, behaviors and 
continued existence to the physical, chemical, biological balances of the 
pond as a relational system, as an environmental field. The shape of its 
6  LIFE AND MIND 

92
body, the position of its fins, the arrangements of its muscular systems, the 
formation of its gills to draw oxygen, the organization of its digestive and 
metabolic systems, and every other aspect of its body are formed in rela­
tion to the pond.
Clearly, the fish is a distinct physical entity with its own unique proper­
ties and needs. We could remove it from the water and even dissect its 
organs down to the molecular chemistry of its cells. Yet, the fact remains 
that the pond was not an incidental environment in which the fish exists. 
The pond plays an active role in the shaping of the nature and function of 
every organ and the fish as a whole. Every cell in its body is an expression 
of a dialogue between it as a complex living system attempting to maintain 
itself in the surrounding pond. The two exist dialogically, and the laws 
affecting their mutual states cannot be found in the molecules of water or 
carbon atoms in the tissues of the fish.
Biologists Humberto Maturana and Francisco Varela describe living 
organisms as autopoietic systems. The word derives from the Greek “auto,” 
meaning “self,” and “poiesis,” meaning “creation.” In their view, living 
organisms are unique among all other objects in that they organize their 
own internal organization and dynamic internal processes. The process is 
continuous and evolutionary.
Autopoietic systems tend to have dynamic but internally stable struc­
tures; they may adjust the functional relationships among their elements 
but do so systemically to maintain their homeostasis. The emergent prin­
ciples are not observable in individual molecules or cells but weave through 
them with unifying force. The molecules within those structures and sys­
tems (and in more complex organisms, the internal organs) interact with 
one another. As one of them may adjust to a change in the environment 
or something within the body itself, the others alter their functional pro­
cesses in an effort to maintain the dynamic balance of their bodies as 
coherent systems. In that regard, the principles that govern their interac­
tions are specific to their biological state rather than the laws that govern 
the surrounding environment. They act in ways consistent with their own 
integrity as dynamic unities.
We don’t have to go far to find an example of the emergent dynamics 
even in the most primitive of living organisms: single cell bacteria. All we 
need to do is look at the often maligned E. coli found in our own gut. On 
the evolutionary scale, the E. coli is among the most basic of all organisms. 
Yet, it embodies organizational principles that distinguish it from all inani­
mate objects in the universe. Consisting of a single cell with a single circu­
lar chromosome (as opposed to our 46), it has a bean-shaped body with 
 
J. KANE

93
six flagellar filaments (thin, whip-like strands) at one end that it uses to 
propel itself. As a stable, self-organized system distinct from the symme­
tries of its surrounding environment, it requires energy to maintain itself. 
Its body is organized to extract that energy.
On its surface, the bacterium has more than a dozen protein molecules 
that sense the presence of glucose molecules in its environment. The glu­
cose serves as the source of energy it uses to maintain itself as a dissipative 
system. Depending upon the information gathered by its receptor mole­
cules, the bacterium will rotate its flagellum to propel it toward the glu­
cose molecules; it will monitor changes in the glucose density of its 
immediate environment roughly every four seconds to determine whether 
it is encountering them with greater or lesser amounts.
When we say that certain molecules on the surface of E. coli do 
not  “detect”  but rather “sense”  the presence of other molecules, we 
intend the term to denote discernment—the differentiation of something 
as having a distinct identity and value amongst other objects. The bacterium 
and the glucose molecule do not simply attract one another as a matter of 
the laws of physics. If that were the case, one could argue that the glucose 
molecule sensed the E. coli or simply that sensation is a meaningless term. 
The E. coli, searches for the glucose; it places value upon it relative to its 
own interest in maintaining itself as a living organism. In contrast, the 
radar detector in my car senses nothing; it reacts to variations in the radio 
waves that enter it, but the sensation occurs only when I discern the sig­
nificance of the patterns of interaction relative to my interest in not being 
pulled over for speeding.
­
­
3
When the E. coli finds glucose in its environment, it moves itself for­
ward based upon its own internal dynamics as a coherent biological 
3 LaCerra, Peggy and Bingham, Roger. The Origin of Minds: Evolution, Uniqueness, and 
the New Science of Self, New York, Harmony Books, 2002, p. 15.
6  LIFE AND MIND 

94
system. It is not propelled by the laws of physics or chemistry. The E. coli 
does not merely move but expends effort. Absent the living E. coli, there is 
no explanation in physics or chemistry for the aggregation of molecules of 
which they are composed to move toward glucose molecules. Its move­
ment as a physical object is not governed by the laws of gravity or fluid 
mechanics, but by its own emergent initiative. The action is predicated 
upon its apprehending meaning in the possibility of glucose relative to its 
own dynamic principles of organization.
Beginning in the early 1990s, Francisco Varela, working with psycholo­
gist Eleanor Rosch and philosopher Evan Thompson, applied these same 
conceptual principles to the study of consciousness and subjective experi­
ence and cognitive systems. They established an “enactive approach” to 
reflect the active role of organisms in organizing and maintaining them­
selves in the context of their relation with their environment. In this con­
text, cognitive processes are not representational but immediately 
experiential. Certainly that is the case for the lowly E. coli without a brain 
or central nervous system.
­
­
­
4
7
Indwelling
5
4 Thompson, Evan, Mind in Life: Biology, Phenomenology and the Sciences of Mind, The 
Belknap Press of Harvard University, 2010, p. 13.
5 Ibid.
 
J. KANE

95
Thus far, we have been discussing the interactions between living 
organisms and their environments in terms of their fundamental biology. 
However, these same enactive principles play a transformative role at 
higher levels of emergence. As we shall discuss, social systems in both the 
animal kingdom and human societies and culture emerge and evolve in 
accordance with the same type of dialogue. In human beings, we have yet 
the additional and critical additions of symbolic language systems and con­
scious self-awareness. These emergent levels of our existence introduce 
their own organizational principles and demands for coherence. They 
extend beyond the interests of individual organisms and create new orga­
nizational systems—similar, perhaps, to the ways in which different sec­
tions of the brain form a dynamic unity. 
Philosopher Shaun Gallagher adds that bodily movements are not just 
outputs but lie at the heart of cognitive development. He argues that we, 
as human beings, physically engage with the world is such ways as allow us 
to explore it conceptually. Our concepts are not so much about the world 
but our experience of it. Just as the E. coli learns about the glucose levels 
in its environment through its own movement, we develop the foundation 
of our conceptual systems through our direct experience of the world, 
such as the movement of time and the force of gravity. Philosopher 
Anthony Chemero further argues that human thinking can be understood 
without any reference to the mental representation of external objects. 
While he does not deny their existence, he maintains that they have been 
overemphasized due to our failure to recognize the embodied and rela­
tional nature of cognition. The abstract conceptual systems that we create 
are literally grounded in our bodies.
Consistent with Chemero, Philosopher Daniel Hutto, along with his 
colleague Philosopher Erik Myin, argues that human thinking can be 
understood non-representationally and added an emphasis on the role of 
social interactions and narrative practices in shaping cognition. In that 
context, we form our conceptual skills and structures through our interac­
tion with others. In a context specific to our central topic of mind, 
Philosopher George Lakoff suggests that all cognition is based upon 
knowledge that comes from the body and “mapped” into conceptual met­
aphors or conceptual prototypes. The force of these conceptual models 
lies not in their explicit content but in their capacity to shape inquiry and 
explicit conceptual systems. Chapter 3 explains how these models have 
played a critical role in the evolution of research into the human mind. 
6  LIFE AND MIND 

96
Behaviorists used the metaphor of animal behavior to construct models of 
human behavior. Computationalists not only use computers to research 
the human mind but as a metaphor of the mind itself.
The Importance of Constraint
The boundary between the organism and the external environment, 
though permeable, differentiates their respective expressions of the laws of 
physics. The mind and other dynamic systems of living organisms maintain 
their own coherence in spite of the laws of physics that would otherwise 
bring their  physical elements into equilibrium with their surrounding 
environments. Within organisms, these symmetries effectively skew the 
probabilities that individual elements will express themselves in one way 
rather than another. The amino acids drawn from the food I ate last night 
could be configured into tens of thousands of protein molecules but they 
formed precisely into the ones of my body.
The emergent principles organizing and operating in complex systems 
do not introduce new laws of physics or new laws of chemistry. Rather, 
they constrain the range in which the laws express themselves; they limit 
the possibilities for action; they create order where shear random probabil­
ities otherwise would hold sway.
­
6
­
6 Kauffman, Stuart. Reinventing the Sacred: A New View of Science, Reason, and Religion. 
New York, Basic Books, 2008, p. 20.
 
J. KANE

97
­
­
7
Yet further, the proteins we form individually are specific to each of us 
individually. The atoms in the molecules are the same, but they are orga­
nized so that they meet the needs of our bodies. The proteins we form 
individually are specific to each of us individually. The synthesis that takes 
place is not a product of the laws governing atoms as physical particles but 
as physical particles organized to meet our needs as living organisms.
At some point the synthesis of the proteins results in a critically impor­
tant emergent property. They combine with other molecules to transform 
them from aggregations of inanimate objects into living human tissues. 
The specific proteins that form are not housed or stored in our bodies; 
they form and maintain the anatomical structures and systems with their 
own distinctive symmetries and balances. Yet further, they support the 
formation of systems, can experience sensation, feel empathy and other 
emotions and grasp meaning in ideas, as you do now. This is not to say 
that such capacities can be reduced to the properties or potential of pro­
tein molecules but that they contribute to the creation of complex systems 
with such emergent capacities.
These distinctions mark the boundary between the inanimate universe 
and the presence of life, with all its localized organizational  princi­
ples. Living organisms introduce a new generative force into the physi­
cal world that allows them to act selectively with reference to their own 
unique interests.  That organizational force  simply does not exist else­
where. The moon does not orbit around the earth because it anticipates a 
benefit in doing so. Electrons do not wheel around atomic nuclei because 
they have their own agendas. 
Agency
One of the key attributes of living organisms is that they initiate action. In 
the most basic of terms they can move themselves. Inanimate objects can­
not act other than as they are driven to act. Newton’s first law of motion 
7 Ibid., p. 39.
6  LIFE AND MIND 

98
holds that every object at rest will remain at rest unless compelled to change 
its state by an external force. An engine may propel a car forward, but it 
does not motivate it to do so. Living organisms, in contrast, are capable of 
initiating action and purposively directing its flow. While organisms respond 
to external phenomena, they do so relative to criteria that they set. Whether 
those criteria are inscribed in the DNA of the species or are a product of 
social convention or are the effluence of an experience of transcendent 
meaning, the action moves outward from within. While we may be able to 
trace the actions of an organism down to specific molecular processes, 
those processes have been shaped by the overarching interests of the organ­
ism as coherent system. The capacity to act in accordance with self-deter­
mined intent is called agency. It exists both within individual organisms 
during the course of their lives and in the evolution of various species. 
Agency includes three critical properties of life: (1) the experience, 
although not necessarily conscious awareness, of the organism as having 
its own distinct needs, (2) the capacity to form preferences relative to 
those needs, and (3) a degree of effective capacity to act based on those 
preferences. As noted earlier, in the case of the E. coli, one fundamental 
need it has to maintain itself as a coherent system is the need for energy. 
In that context, glucose molecules, as a source of available energy, take on 
a unique value. The connection between the needs of the bacteria, as it 
determines them, and the resources in the environment to meet those 
perceived needs, creates a dynamic tension. That tension could be resolved 
if the organism happened to find itself passively immersed in a glucose-rich 
environment. But the E. coli took a more active approach: it developed 
both the sensory capacity to identify gradients of glucose molecules and 
the flagellum to propel itself toward sources of glucose.
The bacteria could have adapted in an infinite number of other ways. 
Some of those adaptations could have led to the extinction of a genetic 
line and some of them could have led to the creation of a new species, but 
the E. coli developed both sensory and locomotive capacities interdepen­
dently. One adaptation without the other would not likely have met the 
organism’s needs. The two formed together in accordance with the orga­
nizational principles creating the coherence of the organism as a whole.
Similarly, autotropic plants—the plants that first synthesize the energy 
of the sun into the glucose so prized by E. coli—exhibit agency. They 
bend to maximize access to sunlight and have developed both the sensory 
and motor capacities required. These adaptations provide them with the 
ability to act as they need to act relative to their own interests in maintain­
ing themselves as living emergent systems.
 
J. KANE

99
Life itself, even its most primitive of expressions, embodies intentions 
that have no place or explanation in physics or chemistry; that intention, 
in general terms, is the continuation of its own coherence as an individual 
organism and/or species. In this context, living organisms are purposively 
organized and selective in their behavior. With the emergence of life, new 
causal principles enter the world. Organisms act with interests that differen­
tiate them from their environment. They act purposefully to achieve those 
ends. The environment is imbued with value and meaning. No astronomical 
bodies bending gravity or subatomic particles coming into and out of exis­
tence or billiard balls colliding with each other on a table share such prin­
ciples in their organizational structures or patterns of action. Life acts in 
accordance with its own purposes and principles.
Sentience
Organisms, as autopoietic systems, require external energy to sustain 
themselves whether directly from sunlight, glucose, fatty acids, or pro­
teins. Unlike other systems that work at or near equilibrium with their 
surrounding environment, they interact with the sources of energy in a 
means/ends relationship. In this relationship, the sources of energy take 
on a higher value than the objects in the surrounding environment in that 
they provide the foundation for organisms to maintain their systemic 
integrity; the environmental sources of energy are defined by organisms in 
terms of their ability to serve the organism’s needs. In this context, we see 
the rudiments of subjectivity. Organisms have preferences that reflect their 
respective priorities above the entropic forces that would normally call the 
shots. This nascent subjectivity is not a theoretical construct but an orga­
nizational principle built into the physiological and behavioral coherence 
of living organisms.
As organisms become more complex, the ranges of their organizational 
structures and behavioral repertoires become more expansive and diverse. 
The information coming from the environment becomes more varied and 
nuanced than the gradients of glucose that spur the E. coli to action. The 
differentiation of the cells into organs also requires the detection of factors 
within the organism and more complex systems evolve to maintain the 
organism’s homeostatic coherence.
Damasio has developed a theoretical model in which organisms act to 
maintain the integrity of their own internal systems. In this context, organ­
isms monitor their own internal states to maintain their homeostasis. 
6  LIFE AND MIND 

100
Every neuron that fires does as part of a finely orchestrated effort to main­
tain the integrity of the body as a whole. The molecules that form our 
neurons could be configured in an infinite number of different ways in the 
brain, but they have not come to be organized randomly. They are config­
ured and have evolved as an organized system intent upon maintaining the 
integrity of the body. The whole of the body exerts an organizational force 
on the neurons of the brain and every molecule within and between them. 
They, the neurons, acquire their form and function in relation to the body. 
8
­
There is a yawning gap between sodium and potassium ion interactions 
in the nerve in the root of my tooth and the pain I feel. Pain has no place 
in the periodic table or in the calculations used to measure chemical reac­
tions. There is no more a place for pain in chemistry that there is in cos­
mology for a planet to get dizzy as it rotates or for it to recoil from the 
heat as it passes close to the sun. Reductionist biochemistry cannot accom­
modate the existence of pain, let alone the possibility that it could play a 
role in the functioning of an organism. 
Pain does not exist as an object that may be observed empirically, 
although it is real and immediate to one who experiences it. It exists locally 
within the subjective experience of the organism; it exists only in a local 
context. Philosopher Murat Aydede explains that pain is not “about” some­
thing but ‘is’ something in and of itself. It does not represent some object 
but is a direct ‘phenomenal concept.’” It serves a purpose within the 
organism; outside of that interest, it does not exist. Within that organiza­
tional system, it can communicate information of external environmental 
factors relative to the subjective needs of the organism. That which is 
external can be integrated into the internal system of interdependencies 
and symmetries. Pain also can communicate information about many 
8 Van Regenmortel MHV, “Biological complexity emerges from the ashes of genetic 
reductionism.” Journal of Molecular Recognition. 17, 2004, p. 145.
 
J. KANE

101
somatic factors that might affect an organism’s capacity to maintain its 
homeostasis. My toothache draws my attention to the decay and bacte­
rium that can threaten my health. My stomach ache prompts me to lay off 
the extra dessert, lest I tempt fate.
Pain is but a single sensation among a multitude of others that tell us 
about the state of our bodies, such as hunger, fatigue, and thirst. We also 
have internal sensations that tell us about our bodies in relation to our 
environment. We feel the movement of the positioning of different parts 
of our bodies relative to one another, our own weight, and positional ori­
entation of our bodies in space (as one who suffers from vertigo, one I 
know only too well). These are not merely biochemical phenomena. In 
organisms with complex sensory systems, they constitute the experience of 
being in the physical world and our relation to it. These somatic experi­
ences are biochemically-rooted, but their nature and meanings, their 
respective significance in shaping an organism’s behavior and patterns of 
interaction, arise only in the context of the organizational systems of the 
organism. These sensations exist within us as organisms but are not empir­
ically observable.
Sensation acts as a bridge between the internal dynamics of organisms 
and the factors in the environment around them. The information carried 
in sensations takes on meaning relative to the symmetries and balances 
responsible for organismic unity and coherence. The heat of a fire can be 
meaningful to us in multiple ways—from the alarm it causes when it rages 
uncontrolled near us to the comfort it offers on a cold night. Environmental 
stimuli are meaningful only within the context of living organisms, and to 
the extent that common biological systems exist within and across species, 
there is common ground for the possibility of shared experience. In this 
context, the experience of sensation also can serve as a framework for 
organisms to surmise and interpret the meanings of the behaviors of other 
organisms. We may see reflected in their patterns of behavior, verbal and 
otherwise, expressions of our own subjective experience.
When we see a dog whimpering and holding its paw off the ground, we 
may reasonably suspect that those behaviors are driven by its experience of 
pain. While we may certainly be wrong about the particular sensation 
causing the behaviors, we nonetheless can recognize from my own subjec­
tive experience that his actions indicate some sort of somatic distress. Our 
proficiency in judgment does not matter for present purposes. The key 
point is that our own subjective experience can serve as a basis for us to 
recognize it in other living organisms.
6  LIFE AND MIND 

102
Neither I, nor anyone else, may enter directly into the behaviorist’s 
“black box” of a dog’s mind. However, we understand through our own 
experience of pain that the dog’s behavior may have meaning beyond any­
thing we can observe directly. The meanings that sensations carry will vary 
with the totality of the organizational systems that mark each species and 
individual, but many of these structures are shared. In those commonali­
ties, we have the foundation for understanding our fellow living organ­
isms, including other human beings.
Mind
The Emergence of Social Evolution
Numerous species form social systems that enable large numbers of indi­
viduals to coordinate their actions to maintain themselves, individually 
and collectively. There are other species that not only work collectively and 
exhibit behaviors that they do not exhibit when in isolation. In those spe­
cies, new types of behaviors emerge where individual members assume 
tasks that require coordination with others. These types of behaviors 
emerge only in the context of the interdependence of the members. Ants, 
for example, will span gaps in their pathways by building bridges with their 
bodies so that other ants may traverse over them from one side to the 
other. They also will build rafts with their bodies to hold others so that the 
collective can move across a stretch of water.
We may think of behaviors emerging in complex social systems as we do 
the organs within a body that function interdependently to maintain the 
coherence of the whole. The organs of the body could not exist indepen­
dently, and the body could not exist without them assuming their respec­
tive  functions. Similarly, socially emergent behaviors are based on the 
dynamics of the social field and do not exist in its absence. Social systems 
provide for the emergence of new principles of organization. When suc­
cessful, those principles can facilitate the development, coherence, and 
sustainability of complex social systems and their members.
In some cases, social systems may include a wide range of complex 
judgments made by individuals based upon their own personal experience. 
Although driven by instinct, in these cases, animals can create new strate­
gies and adjust their priorities relative to their circumstances. For example, 
matriarchal leaders of elephant herds use experience gained over years to 
source medicinal plants, find food and water during drought, and avoid 
the realms of predators.
 
J. KANE

103
In addition, some species have developed the ability not only to adapt 
on an individual level with unique behaviors but to learn those behaviors 
from others. The behaviors exhibited by some members of a social group 
may become models for their other members. In yet more complex social 
systems, some animals can teach what they have learned on their own or 
what they have been taught by others; new adaptive behaviors can be com­
municated from one individual to the next and one generation to the next. 
Meerkats tutor their pups to handle dangerous scorpions. Killer whales 
teach their young to temporarily beach themselves to capture seals and sea 
lions in shallow waters—a behavior that could otherwise prove fatal. 
Orangutans teach their offspring about food sources and nest building for 
eight or more years, and females may stay with their mothers into their 
teens to learn how to rear their young.
The particular knowledge and skills communicated in any given social 
system are less important for present purposes than the fact that they, 
whatever they may be, play principled organizational roles; they unfold in 
new organizational modes within the group. Whereas E. coli exist as soli­
tary organisms that, in effect, establish means/ends and subject/object 
relationships with all that surrounds them, organisms in complex social 
systems can develop relational dynamics that are inclusive—that allow for 
means/ends and subject/object as groups. The group generates contexts 
and opportunities for new types of dynamic interactions that build upon, 
but are not limited to, the range available to individual members. The 
identification of means and ends is no longer confined to the individual 
but can incorporate the interests of the group or some segment of it. This 
is not to suggest moral judgment yet (where the needs of the individual 
and of others may come into conflict) but to recognize that the principles 
that emerge in social interdependence are not present at lower levels of 
organization. The capacity to create new interdependent modes of inter­
action is an emergent phenomenon that generates its own unique rules, 
behaviors, and patterns of social organization.
The emergence of individual adaptations and the capacity to teach, and 
to learn from others established a new layer of organizational complexity 
allowing for the evolution of entirely new forms of community. New forms 
of interaction are able to unfold and generate coherent, self-organizing 
systems with their own rules that can enhance the possibilities of the sur­
vival of the group. The emergence of these systems was not merely a stage 
in biological evolution but the emergence of a new form of social evolu­
tion with its own properties and principles of organization.
6  LIFE AND MIND 

104
In human beings, socially-grounded adaptations evolved so that instinct 
alone no longer governed individual behaviors or group interactions. 
Biological evolution was no longer the only game in town. These new 
organizational systems not only increased the levels of coordination and 
complexity of social interaction but the speed and diversity of adaptation 
itself. The possibility for new adaptive relationships, roles, and behaviors 
with increasingly complex social and linguistic systems developed rapidly 
and spread at lightning speed comparative to biological evolution.
The Interplay of Biological and Social Evolution
One of the most critical connections between human biological and social 
evolution lies not in the specific adaptations that supported survival but in 
the adaptations that lacked specificity. The very lack of specific adaptive 
value set the foundation for versatile adaptive capacities. Consider the 
human hand.
In the very early stages of embryonic development in mammals, the 
upper limbs that will become the wings of a bat or the pectoral fins of a 
whale or the hands of a human being are all virtually identical. The pro­
portions of the bones are consistent among themselves and in relation to 
the whole of the body. As the embryos mature, those bones become more 
distinctively species-specific in the bat and the whale. In the bat, they elon­
gate and grow larger relative to the body as a whole; in the whale, they 
shorten and shrink in relative proportion. In the human being, however, 
they remain consistent without any pronounced specialization.
Whereas the upper appendages of the bodies of bats elongate to form 
wings that enable them to fly and in the same appendages in the embry­
onic whale shorten to form fins, there are no such metamorphoses in the 
human hand. For all the emphasis Darwinian theory places upon adapta­
tion as a process of specialization, the hand as one of the most critical fac­
tors in the evolution of the human being (the most highly adapted of all 
animals), remains general in its configuration and without any specialized 
function.
The adaptive value of the hand lies in its extraordinary instrumental 
range. It has not evolved to do one thing but to do many. Its greatest 
value lies in its generality; it has the ability to adapt instantaneously in an 
infinite number of ways that have not been defined by instinct. Of course, 
the evolutionary value of the hand must be understood in the context of 
the development of the whole human organism, and particularly the brain.
 
J. KANE

105
Of course, the human hand did not emerge on its own; its form, at the 
very least, embodies its function relative to the effort to survive. The pro­
cess of genetic mutation that created the hand may have been random, but 
the hand’s capacity to support human survival and the creation of human 
civilization is not encoded in our DNA. The great value of the human 
hand lies not in its specific functions but in its lack of specific functions—in 
its generalized capacity to perform multiple functions.
That capacity to do so many things would mean little were it not pos­
sible for the brain to envision and plan unprecedented efforts. The hand 
and the brain co-evolved in relation with one another, and created increas­
ingly complex systems of human activity with their own unique organiza­
tional principles. The same holds for all the organs of the body and for all 
organisms: no living creature has been constructed piece-by-piece. The 
coherence and integrity of the whole has shaped the properties of every 
living cell and governs its respective functions.
The Emergence of Symbolic Language
The brain evolved in such a way that it could perform multiple functions 
that were not strictly encoded by instinct. The brain’s distinctive adaptive 
capacity was its ability to create new and progressively more complex pat­
terns of communication between members of the species and the larger 
environment (communications that likely first began with gestures of the 
hand). That adaptive capacity would mean little without a means to trans­
late its efforts into physical action. The hand, being so generalized in its 
structure and versatile, was ideally suited to serve both as an instrument to 
achieve envisioned aims and to expand the scope of possible ends that 
could be envisioned.
The greatest human adaptive advantage results not from biologically-­
determined patterns of action but from our collective and individual abil­
ity to build upon our genetic inheritance to create novel modes of action. 
Unlike all other species, human beings have created a social basis for evo­
lution that responds with a speed and diversity unmatched by biological 
evolution. Biological adaptations that might have taken millennia could 
occur in a matter of days within the framework of human socially-driven 
evolution.
The arch of the development of symbolic language can be traced back 
right to the tips of our index fingers. We point. With that simple gesture, 
our ancestors were able to draw the attention of others and extend their 
6  LIFE AND MIND 

106
capacity to teach and learn from one another. It is not clear why or how 
that adaptive capacity arose in homosapiens and not in other species, but 
it appears to be the case.
9
­
10
11
­
12
13
9 Felizitas Zimmermann, et al. “Orangutans (Pongo pygmaeus) and bonobos (Pan paniscus) 
point to inform a human about the location of a tool.” Animal Cognition vol. 12, no. 2, 
2009, p. 347.
10 Aussems, Suzanne. “What hand gestures tell us about the evolution of language.” iCog, 
January 
31, 
2018, 
retrieved 
from 
https://icog.group.shef.ac.uk/
what-hand-gestures-tell-us-about-the-evolution-of-language/.
11 Ibid.; Kendon, Adam. “Reflections on the ‘gesture-first’ hypothesis of language ori­
gins.” Psychonomic bulletin & review vol. 24, no. 1, 2017, p. 163.
12 Kendon, 2017.
13 Brinck, Ingar. “The pragmatics of imperative and declarative pointing.” Cognitive 
Science Quarterly vol. 3, no. 4, 2004, pp. 429–446.
 
J. KANE

107
­
­
From an emergent perspective, declarative pointing, like the first inten­
tional interactions that shaped lifeless matter into living tissue, introduced 
a new adaptive force in creating complex communities with high levels of 
diversification and integration. It opened the possibility of sharing awareness. 
In that transition to declarative pointing and its subsequent evolution, 
sensory awareness and instinct gave rise to the shared recognition of 
objects distinct from their instrumental value. Objects in the environment 
were no longer restricted to the lens of instinct but could be viewed from 
multiple perspectives and integrated collectively. It was the introduction of 
the social equivalent of the integration of multiple regions of the brain 
that interact in ways that would not otherwise be possible.
The sharing of awareness also proved effective in building communities 
of increased complexity and cooperative behavior. As it evolved, the sim­
ple act of pointing  grew into increasingly refined gestures. The use of 
sounds also became more complex, and eventually spoken language 
emerged to communicate increasingly complex ideas. The evolution of 
shared awareness enabled the growth of large complex social systems with 
divisions of labor and coordinated actions over time and space. Those 
social systems increased the knowledge and skills shared and the ability of 
groups to adapt and survive. The groups that adapted through the devel­
opment of coherent social systems increased the likelihood that they 
would survive collectively.
Anthropologist Robert Boyd and his colleagues suggest that,
­
14
14 Boyd, Robert & Richerson, Peter J. “Culture and the evolution of human cooperation.” 
Philosophical Transactions of the Royal Society B: Biological Sciences, vol. 364, no. 1533, 
2009, p. 2.
6  LIFE AND MIND 

108
Symbolic representational language enabled our ancestors to commu­
nicate with one another not only about their immediate circumstances 
but, indeed, things that were not there at all. Their communications were 
no longer confined to the particulars of time and space and opened the 
possibility for planning complex and coordinated actions. Subjective 
impressions could be shared allowing for both comparative analysis and 
integrative synthesis. More complex and comprehensive conceptual sys­
tems could evolve. They also could learn from their efforts and share their 
knowledge with others so that generation upon generation could build 
upon experiences they themselves never had. Personal experience could be 
refined and cultivated. Behavior was no longer strictly bound by species-­
specific patterns of perception and behavior. Individual experience became 
social knowledge that could be passed from generation to generation. The 
possibility for social evolution through innovation emerged to supplement 
evolution based upon genetic adaptation.
The long ago and far away challenged the immediacy of the here and 
now. Individual experience, whether of internal states or outer events, 
entered the sphere of public awareness. The future opened with anticipa­
tion, and planning was possible for times to come. And education, broadly 
defined, exponentially expanded new and varied cognitive content and 
modes of activity at the level of the individual. The range of human effort 
expanded with radically increased flexibility and diversity, individually and 
collectively.
In short, symbolic representational language systems fostered the rapid 
development of increasingly complex and coherent systems of social orga­
nization. Thus, new organizational principles began to wend their way in 
the course of evolution, which until that time had been grounded solely in 
genetic adaptation. New adaptations to the environment did not require 
generations of genetic evolution but could evolve within the context of a 
social environment. Social evolution established a new spectrum of adap­
tations and capacities that would not have been possible within the con­
text of genetically-governed evolution alone. One of those capacities was 
the remarkable increase in the speed of the process of adaptation itself—
perhaps the most central factor in the success of our species across the 
planet. Significant social and linguistic changes could take place multiple 
times over a single lifetime. And it could take place at the level of indi­
viduals using their own minds in acts of creation. These adaptations could 
spread on a virtually continuous basis across populations and generations.
 
J. KANE

109
Thus, a dynamic relational tension arose in which social and biological 
evolution engaged in a dialogue where each drove the development of the 
other. Biology and instinct no longer reigned as the sole determinants of 
human awareness or human behavior. The introduction of the human 
ability to contextualize their environment beyond instinctual patterns, to 
see the world around them not only in terms of what they could sense but 
what might be beyond immediate or near immediate circumstance, was 
not merely evolutionary; it established a new foundation for the evolution 
of human consciousness.
The Continuity of Body and Mind
The human capacity for language emerged with its own distinct rules and 
power to transform human community, but it depended upon all the 
lower layers of organization active in human beings. The meaning of lan­
guage was, and is, grounded in our bodies and biology, our instinctual 
needs and sensations, but not limited to or controlled by them. Language 
created a new emergent phenomenon with its own principles of organiza­
tion and its own dynamic systems of coherence. In its use, human beings 
explore its principles and structures to shape experience into coherent 
forms that others might use to create meaning.
Human thought does not ride atop these levels of human existence but 
resides in all of them simultaneously. Each contributes its own form and 
substance and its own principles of organization to the creation of our 
thoughts and systems of thought. They are our lived experience even as 
they may lie far below our conscious awareness. Active in shaping the 
mode of our thinking and the forms our thoughts will take, they them­
selves are often experienced as vague images and bodily sensations that 
allow us to feel our way into an exploration of aspects of the world. With 
time to move about in them, we can use them to create structural frame­
works that guide our thinking and ground our sense of what makes sense. 
Recall the inspiration that led Einstein to develop general relativity: the 
physical experience of weightlessness when quickly moving downward as 
in an elevator.
­
6  LIFE AND MIND 

110
15
Our thinking is not a product of the implementation of algorithms such 
that the subjective experience plays no role in shaping what or how we 
think. It derives its form and substance from our experience of being at all 
levels of our existence. As we dwell in all our levels of being, the principles 
and dynamic systems of internal equilibrium active in them become active 
in our thinking. All the principles that govern those levels, such as our 
biological instincts and impulses, remain intact with undiminished causal 
power to function at their respective levels and to interact with other levels 
of organization. They serve as models for our cognitive efforts to integrate 
all that we encounter—from bodily experience of physical reality to bio­
logical sensations, to social and linguistic substance, to conscious self-­
awareness—into a single dynamic system of cognitive coherence. The 
particular systems vary with culture and language and personal experience, 
but all of them are driven by a drive for coherence, for a unity in the wild 
diversity of our existence.
Our cultures and our languages provide organizational principles that 
allow us to understand the principles that flow in and through our minds. 
We understand those principles instrumentally, as they function in our 
evolving systems of coherence. Their meaning lies not in their abstract 
content but in their efficacy in making the world and ourselves compre­
hensible. The particular systems vary with culture and language and per­
sonal experience, but all of them are driven by a fundamental need for 
coherence, for a unity in the wild diversity of our existence.
A failure to achieve that coherence at each of the multiple levels of 
emergence results in disequilibrium. That disequilibrium leads us to seek 
new and varied models of principles to restore consistency within ourselves 
and with respect to the world around us. When successful, the organiza­
tional principles active in the world align with the organizational principles 
active in our minds.
None of this is to suggest in any way that human beings think or act 
rationally. Our drive for cognitive coherence is as fundamental as our drive 
15 Gazzaniga, Michael S. Who’s in Charge?: Free Will and the Science of the Brain. 
HarperCollins, New York, 2011, p. 140.
 
J. KANE

111
for biological survival, but our adaptations are not always successful and 
our judgments are not always sound.
When Descartes reasoned that his own existence could not be doubted, 
he defined himself as “a thinking thing,” a categorical imperative, a con­
struct without place in the physical world. Over the following centuries, 
the re-union of the mind and the body has proven elusive, with the chief 
stumbling block being the lack of a principled way to explain how subjec­
tive experience can play any causal role in human thinking.
The Emergence of Post-Biological Intelligence
The primary impediment has been our insistence upon a detached and 
wholly explicit form of knowledge that  can stand independent of any 
human judgement.  Although  subjective experience is not sufficient to 
establish any claim of knowledge about the world as it may exist outside of 
it, no claim of knowledge at all could exist without it. The universe exists 
beyond our experience of it, but it nonetheless courses through us. Our 
subjectivity is not a phenomenon outside of the physical universe, but, at 
the same time, is central to our recognition that there is a universe to be 
known, and that the principles upon which it is based are not limited to 
our  experience.  The drive for objective knowledge is itself subjectively 
rooted, as is all that can come from it. Even the most formal of statements 
carries implicitly  an affirmation of the subjective sense of coherence it 
offers us relative to some domain of interest. All our claims of knowledge, 
and more generally and all our thinking, are semantic at their core.
Natural human language employs a large vocabulary, sometimes repre­
senting phenomena in the world, whether concrete or abstract, and some­
times expressing direct subjective experience. It serves as a bridge 
connecting the two. As we speak, our experience are transformed into 
ideas that may be interpreted and explored as if they had an independent 
existence. As we attend to the words of others, their explicit meanings and 
relationships are transformed into our own subjective experience and cog­
nitive systems of coherence. We can say whether or not something “makes 
sense” to us. In this dialogue, explicit thoughts can be refined so that they 
satisfy the demand for coherence from both parties. This process is not 
confined to personal discussions but occurs in all types of formal public 
discourse. 
6  LIFE AND MIND 

112
In contrast, generative AI is restricted to the exclusive use of mathemat­
ical operations, a binary vocabulary, and Boolean logic. The information 
they process is non-representational (without any symbolic meaning or 
semantic content), and the processes used have no purpose other than 
those imposed by the programs governing them. AI products implement 
purely abstract systems devoid of life and consciousness without mooring 
in any other levels of emergence. They cannot engage the meaning or 
purpose of embodied experience, sensation, emotion, social communion, 
consciousness, or the uncompromising reality of our own presence in 
the world.
Our experiences at all these levels of our existence add to the depth and 
structure of our thinking. They give our thinking form and substance. AI 
has no such underlying form for processing or substance to the products 
it produces. Its only meaning is our creation alone. Its only guidance rests 
with us. However, we do not fully understand the meaning or direction it 
may take from us as we translate our intentions into binary code and 
mathematical functions. We see that in the form of mysterious AI halluci­
nations: products that are patently fanciful but of unknown origin. We see 
that in conclusions based upon logic that we cannot comprehend. We see 
errors so basic we never imagined they could occur.
AI will not be a passing fad. It will grow both in its power and influence 
on our lives. Neither will the limitations just cited fade away. If we are to 
control it, even if only in our own individual lives, our thinking must 
become that much more grounded in our experience as human beings. 
Our thinking must become that much more an expression of presence as 
living, sentient, and conscious beings in a world that shares each and all of 
these aspects of our existence. Our ideas must be living rather than purely 
abstract.
In the next chapter, we’ll discuss what such thinking might look like.
 
J. KANE

113
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2024
J. Kane, The Emergence of Mind, 
https://doi.org/10.1007/978-3-031-46835-3_7
CHAPTER 7
Thinking as a Creative Act
The Experience of Ideas
Imagine you are a physicist monitoring radio waves in the atmosphere. 
How could you tell if the waves you detect are coming from a local radio 
station, or are echoes from the big bang, or are just a bit of electromag­
netic static?
You might focus on the strength or regularity of the signals, but how 
would you be able to distinguish between random patterns and ones 
indicative of some underlying order? All possible wave configurations are 
equivalent to one another with any pattern or set of patterns theoretically 
being of the same probability. In fact, there is no principle in physics to 
distinguish chaos from order. A series of a million successive identical 
waves is just as much a statistical probability as a series of a million waves 
with no two being the same.
No statistical analysis of the physical characteristics of the waves could 
determine whether or not they were organized in a way that might com­
municate something relative to their origin or purpose. While it might be 
possible to interpret them relative to some models of human-made radio 
transmissions or the continuing ripples of the big bang, both such possi­
bilities require that we accept the possibility that the waves are organized 
rather than random. We would have to have some conceptual framework 
that would lead us to believe that there was an undisclosed cause 

114
generating the patterns detected. Without a prior sense of meaningful 
organization, all things are random.
Let us now imagine that we are reading streams of words rather than 
detecting radio waves. How could we tell which, if any, streams of words 
are meaningfully organized by some causal force that may not be empiri­
cally evident? If we grant the possibility that words may be produced in a 
random order, there is a statistical possibility that the entirety of Macbeth 
may appear as a word sequence. The only order we might find is relative 
primarily to the conceptual framework we impose on our inquiry. If we 
assume that words are structured to convey meaning, we seek the meaning 
within them.
However, if we assume that words form statistically significant syntactic 
sequences, we can translate their order into algorithms. The question then 
arises as to how we determined they had “significance.” The algorithms 
could mirror in their structure the structure of the word sequences such 
that there could be a correspondence between them and the patterns iden­
tified in the streams of words. In effect, the order of the streams of words 
would be understood relative to their syntax rather than any purpose or 
meaning that may have generated them. The algorithms could not distin­
guish random streams of words—patterns of sheer probability and noth­
ing else—from streams organized by purposes and meanings beyond the 
words themselves. If we knew the words had meaning, we might rely on 
their syntactical structure to discern it but would not seek it there. Absent 
that assumption, there is no writer; there is no intended reader; there are 
no meanings created or shared.
As an example of the problem, consider that when Turing and his col­
leagues were trying to break the German codes, the computer they devel­
oped could not help them decode the messages without the human beings 
in the room having some knowledge of the German language and the 
content of some of the code based upon their knowledge of how the mes­
sages were structured. They might be able to identify the meaning of a few 
letters that headed the messages because the code breakers knew that each 
message started with a date. They could then insert the letters used to fill 
in some of the letters in the remaining text. The machine could then sort 
through words that might be formed based upon information about the 
German language. Without those clues to the meaning of the letters in the 
messages, computation alone would have been pointless.
The question is what, if any, clues guide us in the creation of our 
thoughts? How do we discern meaningful patterns as we try to understand 
 
J. KANE

115
the world around us? Rather than approaching these questions as a con­
ceptual exercise, in keeping with our focus on embodied thinking, we will 
explore them in the context of a thinker—from the point of view of some­
one trying to discern principles from circumstantial patterns. Albert 
Einstein provides as good a subject as we could hope to find. His intel­
lectual insights into the nature of the universe are perhaps unparalleled 
and the record of his description of his own experience of thinking is as 
thorough as we could hope to find. Researchers questioned him through­
out much of his adult life about how he made his great discoveries and 
their written accounts, as well as his own writings that provide a rich 
source of information. Admittedly, the experience of a single individual 
does not constitute proof of any introspective inquiry but it can illuminate 
aspects of human thinking that might otherwise prove too elusive to 
explore in an abstract framework.
Clearly, he was an extraordinary thinker, but there is no reason to 
assume that the principles he used to create his understanding of the world 
are markedly different in kind than those that guide us in our own efforts 
to make sense of ourselves and the world around us.
A New Compass
­
­
1
1 Schilpp, Paul A., Ed. Albert. Einstein: Philosopher-Scientist. Evanston, Ill., Library of 
Living Philosophers, 1949, p. 9.
7  THINKING AS A CREATIVE ACT 

116
2
­
­
3
When he was older and reflected upon ideas that guided his search for 
such principles, he said he thought of the laws that govern the universe as 
expressions of the intelligence that gives the world its unity, order, har­
mony, and beauty. For him, the intelligence creating the universe was not 
an abstract concept but as an active creative force that gave all things their 
form and function. We were able to experience it as a creative force in his 
own thinking, which then gave the guidance necessary to express it in 
formal mathematical terms. His aim was to experience within his own 
thinking the organizational principles giving the universe its coherence. 
He used the formal structures of mathematics not to discover these prin­
ciples but to express them as they lived in him. They were active creative 
forces rather than abstract concepts.
shared
­
2 Ibid.
3 Einstein, Albert. Albert Einstein: Out of My Later Years, 1950. Reprint. New York, Wings 
Books, 1996, p. 61.
 
J. KANE

117
4
The Reality of Thought
Einstein sought the mind of God as the creative idea in the created uni­
verse. Einstein saw the universe as an expression of intelligence, as an artic­
ulation of a rationally coherent system of generative principles. The 
concept evokes the Biblical image of God uttering the universe into exis­
tence. “In the beginning God created the heaven and the earth. And the 
earth was without form, and void; and darkness was upon the face of the 
deep…” The universe begins with chaos only to acquire form when God 
speaks. His ideas themselves were formative. When He utters the words, 
creation begins. “Let there be light, and there was light.” And all that 
subsequently came into existence. There is no mention of mechanical 
effort or a need to translate the meaning of His words into other means of 
action. His thoughts, as he expressed them shaped the universe.
Although Einstein did not see God as a disembodied entity, we can see 
a similar view of the creation and nature of the physical world in Plato. In 
Timaeus, he describes the universe as the work of a divine Craftsman who 
imposes order into a preexistent chaos. The “order” reflects the unity and 
coherence of His intellect using ideal thoughts. Plato refers to those 
thoughts as Forms that provide the fundamental templates for the 
Craftsman to shape physical reality. The universe is the creation of his 
intent expressed in the image of Forms. All that comes into physical form 
is a purposeful articulation of archetypal ideas woven together in a harmo­
nious unity. The Forms themselves are available to us in the world only as 
they combine to form physical objects. However, we can apprehend them 
as they exit in their non-physical state through the disciplined develop­
ment of our own intuitive powers.
Plato was not alone in his conception of the rationality of the universe. 
Before Plato, the Greek philosopher Pythagoras said that the patterns we 
see in the physical world are composed in accordance with the laws of 
mathematics. These ideas influenced generations of thinkers to study 
mathematics as a sacred mystery underlying the creation of the universe. 
Nearly 2000 years later they served as inspiration for Copernicus as he 
4 Emphasis added. Quoted through Don Lincoln, senior scientist, Fermi National 
Accelerator Laboratory, June 5, 2019, LiveScience.com.
7  THINKING AS A CREATIVE ACT 

118
created his heliocentric model of the universe in which all the celestial 
spheres moved in perfect geometric patterns.
In these models of the origin and nature of the physical universe, 
thought is not considered an abstraction; it is not drawn from an analysis 
of empirical observations but serves as the foundation for all order as it 
exists everywhere in the universe. The created universe is divine thought 
in physical form. The word “cosmos” meant both “order” and “world” as 
the world was thought to be nothing other than the order imposed upon 
the chaos by divine thought. Although Einstein did not hold to mysticism, 
he adamantly believed that the fundamental laws of the universe were 
absolutely mathematically consistent, forming a single uncompromised 
unity. Recognizing the centrality of such ideas in the creation of the uni­
verse, he referred to that unity as “the mind of God.”
Einstein saw God as the intelligence of the universe itself. It is the orga­
nizational force of gravity curving space, the symmetries of quanta, and 
the laws generating the magnetic pull on the needle of the compass in the 
hand of a very inquisitive little boy. He sought to apprehend the mind of 
God in the first person. He did not want to devise abstract systems that 
mirrored the created universe as it might be observed but to experience 
within himself the dynamic principles of the universe in the act of creation.
For Einstein, God’s thoughts were the ultimate reality. They were the 
uncaused causes that shape all objects and events. These principles are 
never isolated or static but exist only relationally and in dynamic interac­
tion. They are not blueprints but the flowing of form; they are verbs rather 
than nouns. To understand them is to lawfully express them in the first 
person. Knowledge entails engagement with organizational principles in 
their relational fluidity; it is to experience their generative powers in the 
shaping of one’s own thoughts.
In this book, we extend this concept of knowledge to apply to all coher­
ent systems: to see the phenomena from the “inside out” whether attempt­
ing to understand the laws of physics, biology, sentience, social systems, 
language, or mind. In this respect, the mind of God is the foundation of 
the human mind. Human intelligence emerges in the context of the intelli­
gence of the universe against which our insights and cognitive capacities are 
defined.
 
J. KANE

119
Living Ideas
Our thinking is not a natural phenomenon that simply occurs as a matter 
of natural law. It does not simply follow upon physical causes as does the 
motion of billiard balls or the moon orbiting the earth. Our thinking may 
be prompted by given circumstances but it is not produced or controlled 
by them. Our mind organizes itself in accordance with the principles gov­
erning the emergent layers of our existence from our physical bodies 
upward. Our minds are alive, and our thinking is its means of giving 
itself form.
Living organisms are distinguished by their ability, among other attri­
butes, to introduce new initial sources of action—actions that are not 
determined by the reductive laws of physics; they create new forms of 
organization with preferences and priorities that would not otherwise 
exist. Living organisms can initiate action based upon their own interests 
and not merely act as a matter of necessary consequence.
With the emergence of the human mind, the possibility for agency 
moves beyond the immediacy of instinct to create new initial actions, new 
intentions guided by the experience of ideas rather than sensation alone. 
Experience at all layers of our existence can be active in forming ideas and 
new systems of ideas. Our thinking emerges from our agency as living 
beings and the experiences we have at all layers of our existence. Our 
thinking is not detached or removed from our being alive and in the world 
but unfolds in our living in the world. Thoughts emerge as active elements 
within our minds and take their form like the bodily organs: interdepen­
dently within a system of coherence. This is not to say that our thinking is 
always coherent any more than one would argue that all evolutionary 
adaptations always prove successful. Systems of thought that are internally 
or socially incoherent are not likely to survive.
Beneath our explicit thoughts, beneath the systems of thought respon­
sive to the demands placed upon them by language, culture and the natu­
ral world, our thinking flows from our relational experiences at the multiple 
emergent layers of our existence. The demands placed upon us for rigor 
and formal structure in our systems of thought, for consistency with the 
world we see around us, and continuity and coherence in our reasoning, 
all play critically important roles in giving our thought form and value 
beyond our subjective inclinations or judgments.
Our thinking is animate, from the Latin animare, meaning “to be pos­
sessed of life.” Beyond the assumptions employed, beyond the theories we 
7  THINKING AS A CREATIVE ACT 

120
have learned and mastered, beyond the techniques of inquiry or the rigors 
of logic, we experience ideas as living elements of ourselves and ourselves 
as participating in the forces at work in shaping the world. Each product 
of the human mind is an expression of our experience of ideas, of ideas as 
they dwell within us and we dwell within them.
Our thoughts that arise from our lived experience are rife with meaning 
far beyond the formal information they convey in the form of words. Such 
ideas are more fluid and flowing than fixed and static. They consist of 
images, impressions, sensations, and intuitional anticipations. At this per­
sonal level of cognitive activity, thinking is formative rather than formed. 
It is a light of illumination rather than the object illuminated. It is the 
mind in the act of creating and organizing itself. The systems of thought 
that emerge are expressions of the agency of the mind in search of form 
and coherence—the subjective unfolding of the mind in its effort to tran­
scend its own boundaries and find order beyond them. We move within 
them as cognitive spaces that we explore. We also can look out at the world 
through them to see the patterns that form from the vantage point they 
offer. Sometimes they pull apart and dissipate; other times they become 
luminescent, revealing unanticipated principles of organization.
In the process of bringing them to explicit form, we can bring to bear 
the full resources of our experience including all the concepts and rules we 
have assimilated through our cultural and formal education. Whether our 
aim is to express our ideas in poetry or to hold them to the rigors of scien­
tific scrutiny, as our ideas assume greater and greater clarity and form, they 
become increasingly subject to the stresses posed by yet other ideas within 
the whole of our minds. We judge whether our vague patterns of organi­
zation become more vivid and consistent as they are imagined in new and 
varied circumstances or configurations. We ask if the thoughts formed 
maintain their coherence in the light of the intellectual requirements of 
the culture—whether in an informal social context or the rigorous stan­
dards of a scientific community.
Through the activity of thinking, we as human beings create an inner 
universe, a system of coherence deeply rooted in our bodies and cultivated 
through successive layers of emergence and evolution. Our thinking is 
driven by our continuous effort to refine and expand our capacities to cre­
ate increasingly comprehensive and powerful generative frameworks. Our 
aim is to mirror within ourselves the organizational principles that underlie 
all that we encounter in the world. In that correspondence, we effectively 
expand our capacity to comprehend the world and ourselves.
 
J. KANE

121
The Quest for Coherence
In order to better understand the agency in the human mind, we return to 
young Einstein as he toyed with the oddly insistent needle of his new com­
pass. The needle piqued his interest because it did not fit within his under­
standing of the principles governing the world. Its actions were not 
coherent to him, and he sought coherence.
His desire for coherence is no different than the balancing symmetries 
of any other emergent system. The coherence we seek is the organizational 
foundation of symmetries and balances we use to maintain our cognitive 
equilibrium. There is little difference between the organizational princi­
ples of our bodies and those of our minds. The primary distinction between 
the two is that our bodies seek to maintain their homeostatic integrity 
within the context of environmental factors that might lead to their dis-­
integration while our minds seek to maintain their systemic integrity 
within the context of cognitive challenges that might lead to their 
dis-integration.
We are driven to maintain consistency and coherence in our thinking, 
to integrate all that we think within a cohesive system of principles. The 
fact they we fail miserably, the fact that our thinking is filled with inconsis­
tencies and contradictions, does not diminish our fundamental striving. 
The complexity of the task and the cognitive resources we have from our 
bodies, culture, and language are profoundly inadequate.
We can see the drive for coherence is expressed directly in the brain 
itself. The human brain is composed of substructures that can function 
with relative independence from one another but that continually interact 
with one another to form a unified picture of the world. By way of a spe­
cific example, Gazzaniga, working with Roger Sperry, identified functional 
differences between the two major hemispheres of the brain. In the vast 
majority of people, the left hemisphere is largely responsible for speech 
and is primarily engaged in tasks involving logic and mathematics while 
the right hemisphere tends to be more focused on creative and artistic 
activities. Neither of the two hemispheres oversees the other.
Despite, and perhaps because of, the differentiation of various parts of 
the brain, human beings create conceptual and pre-conceptual organiza­
tional structures that align their experiences in a single coherent frame­
work. Ironically, that impulse to find order is most evident in clinical 
studies involving individuals who have had the connective tissues between 
the hemispheres of their brains severed. Gazzaniga and others have 
7  THINKING AS A CREATIVE ACT 

122
conducted numerous studies to explore the minds of patients who have 
had their corpus callosum (the connective tissue of the two hemispheres) 
cut. The procedure is most often used to control severe epilepsy.
In one study, a research participant was shown a picture of a chicken 
claw to his right visual field, which as with all human beings, connected to 
his left hemisphere. The left visual field was shown a picture of a snow 
scene, which registered in his right hemisphere. Gazzaniga recounts,
­
5
In this case, the drive for coherence was so strong that the subject 
attempted to create a unity without there being any external basis to do 
so. He created a fiction that organized his experience into a single, uni­
fied whole.
As human beings, we are driven by a systemic need for the consistent, 
systemic integration of our ideas. It is in this context that separate experi­
ences take on not only continuity but form and substance. The causal 
power of the principle of coherence cannot be found in any area of the 
brain or in the neurons they contain; it emerges in the relational dynamics 
between them, with each one making unique contributions to the 
dialogue.
Let us expand the search for coherence from the context of a single 
person with a “split brain” to two conflicting observations by two differ­
ent individuals viewing the very same phenomenon. Einstein provides us 
with a perfect example. Imagine two men, one in a rapidly moving train 
and the other standing on a platform. At the point when the man in the 
train passes the man on the platform, two separate bolts of lightning hit 
the tracks at equidistant points from both of them. The light from both 
the bolts then moves at a uniform speed so that they each reach the man 
5 Gazzaniga, p. 82.
 
J. KANE

123
on the platform at exactly the same instant. However, as the man in the 
train has moved toward the point of the lightning strike, he will see the 
bolt infinitesimally sooner than the light from the bolt at a now greater 
distance behind him. The man on the platform would see the lightning 
flashes as simultaneous while the man traveling by him would them as 
asynchronous.
Almost everyone but Einstein himself would likely conclude that the 
man in the train simply got it wrong—that the lightning strikes were 
simultaneous even though it might not seem that way to him. We would 
assume that the man on the platform had an objective vantage point. 
However, Einstein had the intuitive insight and courage to ask why we 
would assume that the universe pivots on his perception. Why would the 
perceptions of someone in motion be of lesser value? When we say that 
one man is stationary and the other in motion, what is our point of refer­
ence? To the man on the train, he is stationary and the man on the plat­
form is in motion. How could both be right?
Einstein understood that there simply was no justification for either 
observer to make a greater claim of objectivity. Within that context, he 
sought a set of single, unified set of principles that could provide a coherent 
framework that could account for both experiences. He knew he could not 
draw it from empirical experience itself and wrestled with the problem for 
almost a year. Sometime later, while walking with a friend, a radical solution 
came to him. He recognized that given the fixed velocity of light and the 
fixed distance between the lightning strikes, the only variable able to affect 
the light reaching the men at two different times was the rate at which time 
passes for each of them. He came upon the astonishing conclusion that the 
only way to provide a single consistent framework to explain the asynchro­
nous arrival of the light was that time had to vary relative to the velocity on 
the passenger! There was an invariable principle uniting velocity, time, and 
space into a coherent system even in the face of conflicting empirical obser­
vations of given phenomena relative to multiple observers.
Clearly, Einstein was one of the greatest minds the world has ever 
known, but the principles animating him are the very same as are active in 
us. We seek coherence in our thinking just as he did. Those of us with 
lesser gifts may not be able to understand, let alone create, such imagina­
tively dynamic ideas but, whether consciously or not, we do seek ways to 
create a unified and coherent understanding of ourselves and the world in 
which we live. Those of us with lesser gifts may not seek out the grand 
ideas creating the universe but, whether consciously or not, we do seek to 
7  THINKING AS A CREATIVE ACT 

124
understand the dynamic principles that give form and function to the 
world in which we find ourselves. Our repeated efforts, despite our consis­
tent failure, should not lead us to conclude that those efforts are mis­
guided but affirm the essential role of the desire for coherence in our 
thinking.
Indwelling
Descartes argued that all Truth existed independent of individual circum­
stance and could not change relative to time or place. Truth was eternal 
and immutable. Neither was it ambiguous or chaotic; it was perfectly clear 
and consistent in a universe of pure thought he called God. Given its 
nature, human beings could approach it in the clear light of reason, inde­
pendent of confusions and inconsistencies associated with the senses. To 
know was to eliminate any embeddedness of the knower in the world.
Although Descartes’ rejection of empiricism was soon itself rejected as 
a basis for science, his emphasis on the elimination of subjective experience 
from knowledge and the central role of reductionism continue to serve as 
foundational concepts for much of science to the present day. In contrast, 
a relational model begins with a recognition that our minds are embodied; 
they exist and develop in the context of our bodies and our bodies exist as 
part of the evolving world. As we have seen, it accepts as a fundamental 
principle that we dwell in the world and that it dwells in us. These levels 
of experience are so fundamental and basic, they are the ground for our 
own thinking rather than objects of thought.
At the most basic level, we experience ourselves as physical objects. As 
infants, we feel the weight of our own bodies and struggle against it to lift 
our heads and to stand upright. Our physicality tacitly  teaches us  the 
basics of physical law. We learn that two objects cannot occupy the same 
space at the same time as we bang our heads and bump into one another. 
We feel the heat of a summer day in our bodies. Early in life, we are not 
conscious of such experiences but dwell in them somatically. They till the 
cognitive ground in which we grow our ideas and conceptual structures. 
Our understanding of the balancing of equations derives from the sym­
metries of our own bodies. Our understanding of gravity begins with the 
recognition of the effort necessary to raise our heads or to maintain our­
selves in a standing position. Above all, we learn that we have bodies; we 
discover our hands and feet as objects we can feel and that we can 
move about.
 
J. KANE

125
6
Clearly, our experience of our bodies is somatic and immediate but as 
we move about and observe the world, we also observe our own physical 
actions. We experience our hands as objects that are part of us but that can 
be used to act. As we learn to control them, such as when we learn to 
grasp, they cease to become objects and serve as instruments of our minds. 
As we squeeze a stuffed animal in our hands, we do not focus on the sensa­
tions of our hands but on the texture of the object. Our hands fade as 
objects in and of themselves so that we dwell in the world through them. 
The sensations in our hands tell us about the world.
­
­
­
7
­
6 Damasio, Antonio, The Feeling of What Happens: Body and Emotion in the Making of 
Consciousness, Harcourt, Inc., 1999, p. 126.
7 Polanyi, Michael. The Tacit Dimension, Doubleday and Company, New York. 1966, p. 16.
7  THINKING AS A CREATIVE ACT 

126
­
­
­
8
9
­
However, confusion arises when we try to attribute the intelligence 
extended to the objects used, and specifically, when we attribute mental 
states, minds, and consciousness to them. When viewed as instruments 
used by the human mind—when functioning in a subsidiary capacity to 
support human thinking—computers can be considered extensions of the 
human mind. However, as discrete objects independent of the human 
mind and the human mind’s capacity to imbue their functions with mean­
ing, they have no mental states, minds, or consciousness.
Consider that works of art may be brilliant. We might find that they 
provide unparalleled insights and reveal aspects of the universe and of 
human experience that would otherwise remain hidden. These very attri­
butes may distinguish art from all other human endeavors and give it such 
a central place in a common core of understanding that defines not one 
8 Grene, Marjorie. Ed., Knowing and Being: Essays by Michael Polanyi, The University of 
Chicago Press, 1969, p. 156.
9 Paul, Annie Murphy, The Extended Mind: The Power of Thinking Outside the Brain, 
Houghton Mifflin Harcourt, 2021, p. 14.
 
J. KANE

127
culture or another but of culture itself as both the well-spring of human 
creativity and its expression. Yet, art itself is lifeless; it carries no mean­
ing other than that we bestow upon it. Absent the connection of the sub­
jective experience of the artist and the quickened inner activity of the 
human being attending to it, it has no meaning or purpose or place. In such 
moments, we meet. Even as the meanings we derive may differ, we share a 
common focus. Our consciousness is our own and extends only as we 
extend it.
So much of what we call thinking refers to the linguistic layer of minds 
that are so woven through with socially-constructed symbolic systems that 
we have little if any awareness of the role of the subjective activity that 
serves as the foundation for the creation of coherent systems of thought. 
Each conscious thought that passes through our minds is informed by the 
principles of organization at all our levels of being—from the physical and 
biological to the formal commitments and rules of our social systems and 
language. Some of our thoughts may be formed at lower levels of organi­
zation in our bodies as subliminal awareness while others may arise only in 
the most rarified context of advanced study. In all cases, thinking emerges 
from situated experience and evolves within each of us in the dynamic 
dialogue engaging all the levels of our existence.
Intuition
­
10
­
10 Schrödinger, Edwin. What is Life? (in Mind and Matter and Autobiographical Sketches), 
Cambridge, UK, Cambridge University Press, 1996, p. 127.
7  THINKING AS A CREATIVE ACT 

128
­
­
11
That unyielding intuition of the coherence of the universe guided him 
throughout the course of his life. To him, it was immediately understood 
that the principles organizing phenomena must be consistent with obser­
vation but need not be defined by it. In that context, questions opened 
before him of what principles he might discover that lie beyond all possible 
observation. As we have seen intuition guided him to contemplate the 
universe not from a standpoint of an observer looking at phenomena but 
as someone dwelling within the active principles generating empirical 
phenomena.
Einstein was committed to testing his thinking against empirical obser­
vation but did not allow empirical observation to circumscribe the possi­
bilities of a coherent reality that lay beyond any set of particulars. The 
mark of the underlying reality of a principle is its inviolable consistency 
even as it expresses itself empirically in diversity.
Einstein’s intuition was not unique, although it was singular in its depth 
and scope. It is illustrative of one of the fundamental principles of human 
thinking: our thinking is guided by intuitive expectations and anticipations 
about the principles that shape the world beyond what we see. From the 
moment a child playing peek-a-boo understands that his mother contin­
ues to exist behind the cloth she rolls down before his eyes, he recognizes 
that his perceptions exist within a context that extends beyond them. 
11 Isaacson, p. 119.
 
J. KANE

129
Einstein asked these questions as he shook his compass about, but all chil­
dren tacitly explore them as the principles governing the world as they 
stack their blocks, hold discussions with their dolls, and play games with 
their pets. All of them seek answers guided by their intuitions of where and 
how to find them. Through our educational systems, we learn to use pre­
scribed formal systems to frame our thinking and explicit processes to 
manage our thoughts. We all too often bury our intuitions, and with 
them, the curiosity that might propel us into the yet undisclosed principles 
active in the world, including ourselves and those around us. The question 
remains as to whether we might find ways to cultivate and pursue our 
intuitions and bring our thinking to life.
Imagination
Our intuitions provide us with vague intimations about the principles gov­
erning the world. They also evolve as we gain experience and learn from 
others. Those vague intimations guide us in forming expectations about 
how those principles might express themselves in various circumstances. 
This is the essence of play in young children but is not confined to child­
hood or bouts of fancy. These vague organizational intimations are active 
in us; they provide us with anticipations about what we might find as we 
extend our minds beyond what we have seen. The extension of these inti­
mations as a mode of anticipatory perception is what we call the 
imagination.
Einstein exemplifies the power of the imagination as a mode of explora­
tion and insight. He referred to his imaginative extensions of his subjective 
experience as Gedankenexperimente, as “thought experiments.” Through 
these imaginative journeys, he explored his subjective impressions of the 
principles shaping the universe in diverse circumstances that could gener­
ate vastly different impressions relative to the same event. Intuitively con­
vinced that the universe was rationally coherent—that all things are based 
upon an invariable set of dynamically integrated principles—he pondered 
how they might account for perceived differences in phenomena (both 
empirically observed and imagined).
In this way, Einstein sought to dwell in “the mind of God,” in the act 
of transcribing thoughts into physical form. His insights were not abstrac­
tions derived through empirical reductionism and deductive reasoning; 
they were not abstractions even as their expressions in the language of 
mathematics are extraordinarily formal. The generative foundations of his 
7  THINKING AS A CREATIVE ACT 

130
thinking were imaginative and experiential while his theoretical constructs 
were subject to the laws of mathematics. For Einstein, the principles of the 
universe were generative not only in the vastness of physical reality but in 
the immediacy of his own thought. They were generative in him so that he 
could play with them imaginatively to anticipate the way they would act as 
causal realities in the universe. His imaginative journey traveling in the 
universe at the speed of light guided him in discovering the special theory 
of relativity. His imaginative expansion of his own sensation of falling 
opened the way to his discovery of general relativity.
In the case of his discovery of relativity, he worked for eight years to find 
the mathematics that could express the principles he grasped in an instant 
as he sat one day at his desk in the patent office. Once he had the mathe­
matics to match his imaginative grasp of relational nature of gravity and 
space/time, he predicted that the mass of the sun could bend the “straight” 
beams of light of distant stars. In 1919, Arthur Eddington, a British physi­
cist, studied the light of a distant star during a solar eclipse. The light of the 
star, as it had appeared before the eclipse, placed it behind the sun. During 
the eclipse, the sun exerted a gravitational force sufficient to bend the space 
around it and with it the path of the light of the star passing through it. 
­
12
The Role of Formal Systems
­
12 Ibid, p. 259.
 
J. KANE

131
­
13
Once he informally grasped the principles giving order and form to the 
images he explored, he sought mathematical structures that would permit 
others to understand the dynamic interactions of the principles he experi­
enced imaginatively.
We often become aware of our thinking in our explicit thoughts and 
mistakenly believe that the words used generate the form and meaning of 
our statements. Unseen, the creative force of our thinking lies in our expe­
rience at all layers of existence and the principles of organization that allow 
for their coherence. Even as much of our thinking may be abstract, rou­
tine, and prescribed, all its form and content—all that may exist in the way 
of meaning—echo our multi-tiered subjective experience.
The lifelessness of much of what we call thinking belies the living ori­
gins of our ideas and for the potential dynamic unfolding of our minds. 
Einstein explains,
…as they are written or spoken, do not seem to play any role in my mecha­
nism of thought. The psychical entities which seem to serve as elements in 
thought are certain signs and more or less clear images [that he describes as 
being of “some visual or muscular type”] which can be ‘voluntarily’ repro­
duced and combined.
­
­
14
Yet, we would be mistaken yet again to believe that our thinking is 
exclusively the effluence of our subjective experience. In the transition 
from indwelling to the forming of abstract symbols, subjective experience 
becomes a cognitive object. We then can reflect upon the expression of 
our thinking in the form of thoughts. In the formalization of our thoughts, 
in the creation of concepts and formation of explicit statements, the 
abstract frameworks of language and culture impose their own rules and 
13 Ibid.
14 Einstein, Albert. Ideas and Opinions. New York, Three Rivers Press, 1982, pp. 25, 26.
7  THINKING AS A CREATIVE ACT 

132
requirements. Language and culture are essential in shaping the rules of 
our fundamental conceptual structures. They provide us with the tem­
plates to form and structure our ideas, and to consider them as they stand 
apart from our immediate experience. Our language and cultural concep­
tual structures inform our thinking. They give form to our reflection upon 
subjective experience. Thinking emerges in the dynamic tension between 
the two. Subjective experience forms one pole of our thinking while lan­
guage and culture forms the other. Between the two, thinking emerges 
like cognitive magnetism. The fluid images and churning impressions of 
our imaginations flow into the formal channels of the shared domains of 
language and culture. Dialogue unfolds with the shaping and reshaping of 
explicit thoughts that can meet the demands for coherence from both 
poles. For Einstein, this effort took eight years. In that context, his imagi­
native images and the requirements of physics and mathematics guided 
and constrained one another in a dialogue until he found them agreeing 
on a single principled unity. That unity expressed in explicit form could 
then be used as a foundation for deduction: experiments could be devised 
and predictions calculated.
­
­
­
15
The Role of Logic
Logic, however, plays a critical role in defining those imaginative experi­
ences in formal theoretical terms with explicit structure and internal con­
sistency. It also enables the development of theoretical expectations that 
often can be tested against empirical observation. Imagination is fraught 
15 Einstein, p. 271.
 
J. KANE

133
with the possibility of error and illusion. In matters of science, subjective 
experience must be put into explicit form and be subjected to both the 
rigors of logic and empirical experiment.
All of us, with less consistency, coherence, and scope than Einstein, 
engage in the same type of creative effort to form our own conceptual 
models of the world and our place within it. The formative activity trans­
forming into representational thinking unfolds in increasingly expansive 
systems of concepts. These concepts are themselves dynamic; they are not 
static categories but cognitive instruments that enable us to navigate the 
world, to make sense out of what we see but what has yet to be seen.
To better understand the role of logic in thinking, let us consider a 
simple example. Imagine an individual with no knowledge of the game of 
chess or any games of any sort. As it happens, she comes to observe a chess 
match for the first time. Through observation, she might discern the pat­
terns of the possible moves for each type of piece. She also might be able 
to develop mathematical models of movements that various players make 
and note the point at which the succession of moves ends. The models of 
moves (principles of sorts) could be identified to yield the most efficient 
sequences to end all possible moves (where there is a stalemate or a check­
mate). This is more or less what chess-playing programs do.
However, such observation and analysis could not reveal the factors 
that led to the design of the board or why each of the pieces was given its 
distinct and unique patterns of movement. The various elements of the 
game were designed to form a system of dynamic tension whose balance 
of forces is the very subject of the game. The play of the game may be 
driven by logic and strategies of various sorts, but the game itself was 
designed with a focus on a delicate balance of power that is open to 
repeated possibilities for disequilibrium. The game ends when a new equi­
librium is found, an equilibrium where no further action is possible.
The game of chess is not merely a set of logical rules but a system of 
coherence. That coherence orders and orchestrates all the elements of the 
game. Everything in the game is an expression of the intent to create a 
coherent formal system for intellectual competition. That intent is within 
every move but could never be found by any reductionist analysis of the 
patterns of the pieces in motion. The organizational principles of the game 
lie beyond the board, the moves the pieces may make, and the sequences 
of moves that take place.
Although one might argue that the example of the game of chess is 
flawed because its principles were created by human beings, the very fact 
7  THINKING AS A CREATIVE ACT 

134
that human beings bothered to create them and to explore their permuta­
tions is precisely the point. The mind is not confined to the rules of logic 
but applies them as instruments of its own intent; subjective experience 
both transcends and empowers logic.
The Creation of Meaning
Each of us strains to bring coherence to the experiences that flow through 
the multiple layers of our existence, each with their own organizational 
principles. Those efforts need not be confined to formal linguistic or 
mathematical rules but can take other imaginative and formal modalities. 
Their range and diversity are most expressed in Howard Gardner’s seminal 
theory of multiple intelligences. These multiple forms of intelligence are 
not reserved for individuals with special gifts. Preschool children building 
with blocks exercise their spatial intelligence and construct their under­
standing of geometry. Seven-year-olds point out a flat note played in a 
scale or a badly-timed bit of rap as they express their musical intelligence. 
In acts of kinesthetic intelligence, ten-year-olds learn to control their own 
movements to ski a bunny slope. Each and all of these forms of intelli­
gence are active within us and are integral to our making the world coher­
ent and expressing its principles as they flow through us. The varied 
content and form they take is a testament to the creative force of our 
experience of ideas.
Although our cognitive creations—our works of visual art, music, phi­
losophy, and sciences—derive their meaning from the context of subjec­
tive experience, our experience of ideas, our thinking in all its forms, is not 
isolated. In large measure, all of us share common biological, linguistic, 
and cultural systems of coherence that serve as the structural templates in 
which our minds emerge.
We dwell in shared ecosystems of consciousness where our expressions 
of experience—from the most tacit of facial expressions to the most 
abstract theories in the academe—arise in socially-mediated contexts. Our 
public interactions temper, test, and refine the products of our minds as 
expressed in words, behavior, and other social forms of communication. 
The relative value of our cognition creations is determined culturally by 
their ability to take root and flourish in the consciousness of others and 
personally by their ability to support our quest for coherence. The formal 
systems we have assimilated from our social ecosystems give form to our 
cognitive activities; we are informed and disciplined by the structures they 
 
J. KANE

135
impose. The dynamic tension between these two forces—one expanding 
outward and the other imposing rules of order—guides us as we form our 
thoughts and search for coherence.
Much of the creativity of our thinking is directed through the frame­
works of the experiences and structures afforded through the environ­
ment, family, social, language, and culture. They are instrumental in us; 
we use them to form our conceptions of the world and ourselves. Their 
most essential meaning is not in the particulars of their explicit content 
but in the formative influence they exert on the unfolding of our minds 
and the organizational principles of our thinking.
Each idea that forms within us is woven with meaning that emerges 
from our experience—from our being in the world and yet not entirely of 
it. We exist within the world and stand apart from it and are aware, often 
vaguely and often non-reflectively, both of the immediacy of our experi­
ence of being and of a world around us as “other.” In that dynamic inter­
section, in that relational touchpoint, a tension arises within us—a question 
of if and how these two poles of experience relate to one another. We 
experience ourselves as in two vantage points at the same time.
The two sides together create a new cognitive force; we see ourselves 
from within our own experience and know the world lies beyond it. We 
are like both the passenger on the train and the man standing on the sta­
tion platform in Einstein’s thought experiment. In this case, we ask, how 
we can synthesize both these two aspects of our existence within our own 
thinking. We seek a unity in which they fit together coherently. We ask 
what each of them means in terms of that unity. What principles can we 
find to orient and guide us so that we can live with a sense of our place?
In this relational dynamic, thinking emerges in all its organizational 
forms: informal and formal, fluid and procedural, creative and destructive. 
Although the search for such unity of ourselves and the world around us 
often goes unresolved, the search itself is the source of inspiration for the 
world’s spiritual traditions and philosophical ideas. The frustration of our 
efforts is often a primary source of conflict and despair.
Much of our thinking is tacit, informal, and generative  even as our 
thoughts can be put in explicit forms and static terms. The  genera­
tive activity of thinking responsible for the words we utter lies beneath the 
surface of the words themselves.  It is subjective  experience that gives 
words their meaning and without which language is meaningless. It is the 
light that enables us to see rather than the object seen. 
7  THINKING AS A CREATIVE ACT 

137
CHAPTER 8
Emerging Minds
The Agency of Intelligence
However we may conceive of the human mind, its defining characteristic 
is that it is intelligent. In a broad context, it refers to the ability to choose 
between things, to discern, to be selective. We can see the rudiments of 
that selective capacity in our sensory systems.
­
­
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2024
J. Kane, The Emergence of Mind, 
https://doi.org/10.1007/978-3-031-46835-3_8

138
1
­
­
­
­
­
­
2
Graziano may be correct in claiming that selective signal processing is 
purely functional. A biochemical analysis of the nervous system as it pro­
cesses sensory signals will not require any more consideration of “aware­
ness” or “consciousness” than would a similar analysis of the excretory 
system eliminating waste products. However, the apparent commensura­
bility of the two systems assumes that “awareness” and “consciousness” 
are reducible to biochemistry.
However, in a relational context, they depend on biochemistry but, 
they emerge in a context of meaning where living organisms strive to 
maintain their own coherence. That purposive context is more akin to the 
motivations guiding a programmer than the mechanics of writing a pro­
gram. By way of a quick comparison, consider using physics to analyze the 
movement of molecular particles to study static in an electrical field as a 
framework to comprehend music played in a concert hall. The algorithms 
1 Graziano, Michael. “A New Theory Explains How Consciousness Evolved” The Atlantic, 
6 
June 
2016, 
pp. 
1–2, 
retrieved 
from 
https://www.theatlantic.com/science/
archive/2016/06/how-consciousness-evolved/485558/.
2 Graziano, Michael. “Are We Really Conscious?” The New York Times, 10 October 2014, 
retrieved from https://www.nytimes.com/2014/10/12/opinion/sunday/are-we-really-
conscious.html.
 
J. KANE

139
produced relative to the former would never reveal the organizational 
principles governing the latter.
The missing element in Gaziano’s claim is that selective processes are 
possible only where there is more than one possible course of action and 
where each outcome has relative value. These conditions are not possible 
in physics where everything is determined, or at least, subject to random 
probabilities. Physical objects do not require programs to determine how 
they will act. The planets do not follow the curvature of space around the 
sun as a matter of programming but as a consequence of the laws of grav­
ity. They do not and cannot do other than that which they do. There is no 
calculation of value or notion of success or failure when molecules form or 
stars explode.
Physics cannot account for acts of intelligence, where intelligence is 
defined as the capacity to discern and choose among options. Programming, 
at least in its most basic form, requires the selection among options rela­
tive to an aim. That aim is not itself a matter of programming but of inten­
tion. Choices must be made. Furthermore, selective actions require not 
only the capacity to discern different options but an impetus to do so. 
Thus, even if the process of selection could be reduced to computational 
programs, whether written in the DNA or binary code, the programs 
could not, of themselves, initiate their own writing. Programmed pro­
cesses implement judgments of value, but they themselves cannot deter­
mine what those values ought to be.
Choosing between options, selecting those bits of sensory information 
that are significant from those that are not, requires a differentiation 
between that which is perceived and the perceiver—between the world, as 
it is perceived, and the world as the perceiver would prefer it to be. In 
essence, there must be a separation on the part of the perceiver as a subject 
and the world as an object; there must be a distinction between the world 
as a means to an end and the perceiver whose interests serve as an impetus 
for action. This distinction is the touchstone of intelligence. The mecha­
nisms by which selections are made are secondary. 
Physics cannot account for the distinction between a subject and an 
object. However, that distinction marks an open boundary into biology: 
where there is life, there is subject and object. There are means and ends. 
In this relational space, intelligence sparks into existence. It originates in 
the dynamic causality of the action, not in the design or content of an 
artifact produced. This is not to suggest that all organisms are even 
remotely aware or conscious of what they do or how they do it, but 
8  EMERGING MINDS 

140
rather to acknowledge the fact that living organisms act to maintain their 
own homeostasis far from equilibrium with their surrounding environ­
ments, and that they act intelligently to do so.
With life, there emerges the causal force to act in its own interest to 
sustain itself; that intelligence does not exist anywhere in the absence of 
life. Organisms use intelligence to organize their actions in relation to the 
surrounding environment. They make choices and are capable of acting in 
their own interests rather than in accordance with the same laws that 
determine the course of events in the inanimate world. Their efforts, 
whether shaped by biological evolution or social guidance, result in instru­
mental cognitive structures that enable them to anticipate environmental 
factors that may be relevant to their interests.
Intelligence is purpose-driven. Where there is no purpose in an interac­
tion, where there is no discernment of the relative value of one outcome 
as opposed to another, there is no intelligence.
The Light from Within
Intelligence organizes; it orders itself and its environment within the 
boundaries of each organism’s capacities. At a biological level, it is intent 
on survival. At its highest level, it seeks coherence in consciousness. 
Beginning at the biological level, it unfolds in relation to the surrounding 
environment. In that context, sensory systems develop in an evolutionary 
dialogue between organisms and their environments. In some organisms, 
that evolution includes the expansion of the central nervous system. One 
of the key functions of such systems, as Gaziano theorizes, is to filter sen­
sory information relative to each species’ interests. Through interaction 
with the environment, the filtering process evolves to create regularized 
patterns, schema. These schema serve as primary organizing frameworks 
that provide relevant and reliable information about environmental 
resources and, in some cases, threats.
Roughly 2,000 years ago, Plato wrote that perception required not 
only that light reflect off objects but that it be met by a flame of light com­
ing from the eyes of the perceiver. Although the concept may seem strange 
to us now, his assertion was dominant in optics for roughly 1500 years. It 
fell out of favor with the empirical study of optics by Abu Ali al-Hasan ibn 
al-Haytham in the eleventh century.
 
J. KANE

141
However, although there is no physical light that issues forth from the 
eye of the perceiver, the perceiver does, in fact, attend to phenomena in in 
the light of their intention. Through our sensory encounters with the 
world, we, like other organisms, use schema not only to perceive selec­
tively but to organize our perceptions. The perceived is always situated 
within the perceiver; it is always imbued with meaning arising from intent. 
As a species and as individual human beings, we acquired the capacity to 
“make sense” of the world, and to place what we see within a context of 
principles and expectations.
­
­
3
­
4
­
5
Intention is not only at the root of our perceptions as physical organ­
isms but is also critical to the emergence of our higher level of coherence. 
The common element in all our levels of emergence is the intension to 
maintain their own systemic coherence. Our experience of maintaining 
ourselves at all these levels of our existence provides us with instrumental 
insights into the principles we can express in the form of concepts and 
complex systems of thought. We form our ideas not only through 
3 Bateson, Gregory. Mind and Nature: A Necessary Unity. New York, Hampton Press, 
2002, p. 32.
4 Polanyi, 1966, p. 15.
5 Ibid.
8  EMERGING MINDS 

142
observation of external objects but through dwelling in the organizational 
principles at each and all levels of our existence.
As human beings, we exist not only in a physical environment but in 
multi-tiered cultural and linguistic environments. We seek coherence in 
our systems of thinking just as all living organisms seek biological coher­
ence. As we attempt to maintain our biological homeostasis, we also use 
schema to organize our actions and systems of thought consistent with the 
principles of these higher levels of emergence. In this context, we have 
developed the ability to share experience, to commune in awareness, and 
communicate our subjective experience. Thus, in human beings, instinct 
engages in a dialogue both with the perceived environment and with oth­
ers in shared awareness.
We dwell in schema we have acquired through such dialogue and use 
them to give order and coherence to our experience. They are the func­
tional basis for the development of our explicit ideas rather than ideas “in 
and of themselves.” They are, in Polanyi’s term, “tacit.” They guide us in 
forming our conclusions, but they are not themselves objects of study 
other than as we might shift them from a functional role to the focus of 
our attention. In this context, the schema we use are not strictly derived 
from observation but include the multiple levels of organizational princi­
ples active within our bodies, social lives, language and conscious self-­
awareness. All these factors are integral to creating meaning in explicit 
concepts and theories.
With the human capacities for shared awareness and language, human 
consciousness is not bound by the immediacy of time and place. Nor is it 
bound by the needs and interests of each individual as the center and cir­
cumference of a system of coherence. Our minds can extend beyond our 
own experience and interests.
Child’s Play
The capacity for indwelling shown by Einstein and Nobel Laureate 
McClintock (as we will discuss below) was profound but is not uncom­
mon. It plays an essential role in the emergence, the becoming, of all our 
minds. Although our capacity for the expansion of the dwelling place of 
our minds goes largely underdeveloped, we can see it in all types of imagi­
native play. Consider how a child may develop the concept of “gravity.” A 
one-year-old struggles to stand, and feels the weight of his own body. His 
muscles strain against gravity, and he senses the need for balance as he is 
repeatedly pulled down to the floor. “Gravity” for him, is not a concept, 
 
J. KANE

143
but a direct experience of his body. Were he in a zero-gravity environment 
(with zero acceleration), he would not develop an immediate experience 
of a gravitational pull. He would not be able to dwell in gravity as a foun­
dation for its later expression as an articulated concept. The word “grav­
ity” would be no more meaningful to him than the word “color” is to 
someone born color blind. But here on earth, he also holds objects and 
feels their weight in his hand. He recognizes their having weight as an 
extension of his immediate experience of his own weight. Although he 
may not yet have words to describe his experience, he develops the tacit 
interpretative framework within which he dwells to understand what we 
reduce to the abstraction in the word “gravity.”
As the child’s living understanding grows, as his dwelling place for 
understanding expands, he might observe that his nascent concept of 
gravity does not hold for the toys in his bathtub. His play with them 
would, in part, be an effort to somatically extend his own wordless sense 
of coherence. (If he did not have the earlier direct experiences with gravity, 
the phenomenon would draw no notice as an anomaly. He would have no 
context to search for coherence and likely would not have bothered 
to play.)
Through dwelling in the phenomena, his toys serve as clues to a “hid­
den principle” that may make the world comprehensible. The child plays 
with the toys in his tub and other objects to make sense. Through the 
movement of toys, the child can create his own thought experiments and 
watch them play out. Play, in this context, is the physical extension of the 
body as a dwelling place of consciousness; it is a direct exploration of the 
principles at work in the phenomena in focus to see how they behave in 
newly created conditions.
My own son, Jesse, at age seven, having been raised on planet earth and 
having experienced growth of his ability to dwell in an expanded set of 
gravitational phenomena, spent the better part of an afternoon intently 
playing with a straw and a glass of water. Finally, he asked a few questions 
to me that clearly explained what he had been doing. He asked, “Why do 
things fall? Is it because things are heavier than air or because they have 
their own weight?” I responded, secure in my answer, “There is some­
thing called gravity that pulls them to the earth.” “Okay.” he replied, “But 
what is doing the pulling?” He was looking for the same type of hidden 
principles as did Einstein observing a compass needle. Stumped for a 
response, I wondered why I had not thought of the question myself. And 
the question remains for all of us; the nature of gravity remains a mystery.
8  EMERGING MINDS 

144
Jesse’s play—twisting the angles of the straw to watch the water fall 
with an endless series of stops and starts with his finger atop the open 
end—was his attempt to imagine into, to dwell within, the falling water. I, 
on the other hand, had acquired the information and learned the process­
ing rules in the form of a word, “gravity.” The concept was lifeless in me, 
but it lived in Jesse. He actively imagined the principles of physics he had 
experienced directly with his own body as they expressed themselves in the 
flow of the water. I, on the other hand, did little more than repeat what I 
had been told. For him, gravity was not a concept but a somatically-based 
experience of an actual principle at work in this world. He was attempting 
to make sense of it. The concept of gravity, for him, was filled with life and 
integral in his consciousness.
Biological Indwelling and Insight
The connection between our seeking coherence in our thinking and our 
bodies seeking coherence is vividly displayed in the work of Barbara 
McClintock.
­
­
­
6
­
­
7
6 Keller, p. 117.
7 McClintock, Barbara, 1987, Moore, John. ed. The discovery and characterization of trans­
posable elements: the collected papers of Barbara McClintock, New York: Garland Pub.
 
J. KANE

145
8
­
9
For McClintock, her capacity to image the relational dynamics, the flow 
of the internal patterns within the phenomena she observed, opened the 
possibility for the union of the observer and the observed. The separation 
of subject and object narrowed as her imaging mirrored the generative 
principles operating in the phenomena. The principles operating in the 
phenomena she observed were much like those guiding the development 
of her explicit theoretical system. Her grasp of the principles at work in the 
phenomena she observed transcended the boundaries of the observations 
themselves and opened the possibility that she might find new expressions 
of those same principles in new and novel circumstances. The patterns she 
imagined were her “perceptions” equivalent to Einstein’s riding the lead­
ing edge of her beam of light. She dwelled within them as the flow of the 
generative principles giving form to the structures she studied. In her 
empirical research she did not simply find transposable genes, she expected 
to discover them.
Ideas created in this way are not logical expositions based upon empiri­
cal evidence, but imaginative extensions of the subjective world from the 
inside out, permitting the growth of understanding consistent with the 
operational principles governing the phenomena of study. Such ideas 
become more clear, explicit, and systematic as the patterns imaged are 
elaborated and refined. Their internal structures develop, and they evolve 
8 Ibid.
9 Ibid., p. 198.
8  EMERGING MINDS 

146
into more and more refined explicit forms shared in public forums. They 
may eventually be opened to public discourse and experimentation.
The images McClintock formed of the chromosomes as if she were 
among them were not content-free information but “content-full” 
thoughts. Her imagings did not unfold by prescribed processes but in 
accordance with the principles she experienced generatively in her think­
ing. Unlike information which is static and fixed in the absence of the 
application of processing rules, McClintock’s imagings were themselves a 
dynamic aspect of her mind with their own unique internal structures. 
They evolved in accordance with the dynamic activity of her living mind 
gradually maturing into coherent theoretical systems.
Imagings of this sort are not given or possessed. They are not abstrac­
tions created by others and communicated in explicit forms. Being 
dynamic, they must be formed through the thinker’s own inner activity. 
The cognitive value of such imagings is that they function as verbs rather 
than nouns. Their value resides in their being creative rather than created. 
The activity in creative images is that they allow for their own develop­
ment. In that way they serve as a means for exploring the generative 
aspects of the environment or even the thinker him/herself.
Even in cases where thinking may be spurred by empirical information 
and tightly constructed processes, the assessment of the value is measured 
against the imaged generative framework of the thinker. Such a generative 
framework is not mechanistic, not a formal structure where information 
may be stored and sorted. Rather, as stated previously, it is a cognitive 
dwelling place, a personal foundation of the experience of ideas. Image-­
driven frameworks in thinking are akin to the inspirational tenets of the 
artist. The subject and object form a single continuum; the thinker and 
the thought are one. Being and thinking are one. At the generative level, 
thinking is not in the mind but the mind itself creating its own organiza­
tion. The thinker and the thought are the dancer and the dance.
McClintock’s capacity to image was unique in its scope and sophistica­
tion, but, once again, the capacity to image is as universal as child’s play. 
In research labs, as in the playground where block towers rise or fall, theo­
ries are generated, expectations are refined, and experiments are con­
ducted. Where the images unfold and empirical evidence mounts, the 
possibilities increase for the discovery of principles operating in the world.
Whether a physicist is attempting to image the operational principles 
forming the universe, or a child is imaginatively playing mommy or daddy 
to understand the principles guiding their adult actions, the living nature 
 
J. KANE

147
of thinking remains consistent. The subjective alights the objective. The 
basis for thinking and learning lies in the subjectively generative rather 
than the objectively defined. The tacit drives the explicit. The imagination 
leads and critical reflection follows.
Shared Awareness and Learning
­
10
Refining the argument, we suggest that in that activity we use our orga­
nizational frameworks as a means of exploring the principles at work in 
others, just as we do when attempting to understand physical and biologi­
cal phenomena. When we cannot comprehend something they have done 
or something they say, we can experience the same type of disequilibrium 
as when we do not understand the principles giving coherence to other 
objects. Rather than “projecting ourselves onto them,” we project our­
selves into them. Our aim is to understand the principles generating the 
behaviors we observe, and one effective way to do that is through the act 
of generating those behaviors ourselves. As children, we attempt to make 
those same principles active in our own behavior. We playfully imitate.
The pioneering psychological theorist, Lev Vygotsky, proposed that 
creative imitative activities are central to children’s cognitive, emotional, 
and social development. Such imitation is a form of constructive experi­
mentation—a guided mode of creative activity that extends beyond a 
given set of circumstances. Vygotsky explains, this type of imaginative 
social indwelling can be seen clearly in young children as they play with 
dolls. The play often includes imaginative recreations of social interactions 
they have seen. That imitation, however, is not a parroting but a 
10 Graziano, 2016, p. 5.
8  EMERGING MINDS 

148
projection of their subjective experience into the actions they see in others 
with whom they share consciousness. They project themselves into others 
to explore the principles governing their behavior in the same way Einstein 
and McClintock explored the principles in the physical and biological 
domains. By playing with dolls children generate models of the principles 
underlying the actions of others to both see how they (the principles) 
function and explore how they might apply in new and varied circum­
stances. Dolls allow children to experiment with their emerging social 
schema in lab-like settings with variables controlled. The children establish 
the environment in which the dolls act, and they see themselves as being 
at a safe distance from all responsibility.
11
­
­
12
It is essential to note that even as schema derive from established social 
patterns, they unfold formatively from within each child. The child is not 
simply copying behaviors but dwelling in the meaning generating them. 
Dwelling in that meaning rather than the particulars of behavior, the child 
can envision new and varied ways they may be expressed. Therein lies the 
very essence of imaginative play. Vygotsky referred to the transformation 
of an imitated behavior into a generative schema as an act of “internaliza­
tion”. Vygotsky writes, that through the act of imaginative imitation
13
11 Vygotsky, Lev. Mind in Society: The Development of Higher Psychological Processes. 
Cambridge, MA, Harvard University Press, 1978, p. 94.
12 van Oers, Bert. “Meaningful Cultural Learning by Imitative Participation: The Case of 
Abstract Thinking in Primary School.” Human Development vol. 55, no. 3, 2012, p. 143, 
emphasis added.
13 Vygotsky, p. 57.
 
J. KANE

149
Through imaginative interaction with the world and others, children 
create a dynamic framework for understanding the principles undergirding 
both the physical world and what it is to be a human being living in soci­
ety. The schema acquired through imitation and imagination not only 
inform the child’s actions but become cognitively, emotionally, and socially 
transformative. The thoughts that emerge are not abstract categories of 
information but the blossoms of creative inquiry; they are the mind itself 
unfolding in search of form and coherence in the context of their common 
humanity.
All learning shares the same basic structure of internalizing the princi­
ples that govern the world we encounter—physical, biological, social and 
academic. Abstractions arise only when there is subjective substance from 
which they may be drawn. The spectrum of subjective experience grows 
into an increasingly articulate sense of others, oneself and of the world as 
well as the interrelationships of all three.
The Emergence of Ideas
When my son Jesse spent his time imagining into the flow of the water to 
and from his glass, he was not able to integrate his observations within his 
extant conceptual schema. The more he dwelled in the streams within the 
framework of his existing schema, the more he realized that they could not 
provide him with coherence in the face of new experience. This lack of 
coherence led him to experience disequilibrium and to restore his sense of 
coherence. In order to restore his cognitive equilibrium, he had to find 
some way to assimilate the falling water into his existing model of the 
world or accommodate it by creating a new one. The renowned develop­
mental psychologist Jean Piaget theorized that such disequilibrium and 
the drive for a restored sense of coherence is essential for children’s cogni­
tive development.
Jesse’s existing conceptual schema were helpful in that they gave him 
the context to search for a new system of organizational principles. They 
identified discord but left undisclosed the new patterns that would take 
their place. In that dynamic space between his existing conceptual schema 
and the vague outlines of some coherence yet to emerge new possibilities 
formed. Those intuitive imagings of possible solutions were drawn from 
his experience at the multiple levels of his existence.
That body of schema for Jesse and for all of us includes everything that 
rises from our genetics going back over time to the beginnings of life, all 
that we have gained through the shared awareness that has shaped culture, 
8  EMERGING MINDS 

150
and personal-lived experience. No schema can stand on its own. Rather, all 
schema exist within a relational ecosystem of consciousness where each of 
them is formed, informed, and transformed through its interactions at all 
levels of our existence. The field of consciousness is dynamic, allowing for 
new and unprecedented organizational structures to form and envisioning 
possibilities for new forms of coherence.
Through dwelling in the active domain of consciousness, all of us call 
upon the principles of coherence we experience at lower levels of emer­
gence as human beings. We may move from the consideration of explicit 
concepts to our experience of sensation such as the feel of gravity or of 
acceleration in our bodies. Through this act of indwelling, we attempt to 
explore the organizational principles that we are trying to articulate. We 
imagine how they would act under new and varied circumstances that we 
may then use to form conceptual systems. This exploration would not 
involve the use of formal modes of reasoning but might enable us to gen­
erate them. The recognition of new possible patterns of coherence dem­
onstrates the powers of one’s own mind to create them; it is an act of 
imagination that dawns in childhood but often is soon eclipsed by the 
formalisms of mind that we call education.
In shared awareness, individuals with more advanced schema who have 
the structures needed to assimilate unfamiliar patterns of experience may 
guide others to create new schemas for themselves. However, when learn­
ers are taught about schema as objects, as sets of formal rules and proce­
dures, the schema themselves lack a rootedness in subjective experience. 
As a consequence, they do not integrate subjective experience as active 
elements in the mind’s efforts to create its own coherence. The acquisition 
and use of abstract schema so commonly believed to define education may 
indeed be useful in pragmatic circumstances or in elaboration of theoreti­
cal systems, but when they are not recreated within the context of one’s 
own inner activity, they lack integration into the agency of consciousness. 
They do not become integral to the activity of consciousness other than as 
conceptual artifacts provided by others relative to experience with no con­
nection to our own. In fact, they may impede more the creative expansion 
of the mind by providing socially accepted solutions to problems one 
never experienced within one’s thinking.
Certainly, logic and rational schema play a central role in the evolution 
of culture and the individual mind, but they do so only to the extent that 
those who apply them subjectively affirm their place and value. However, 
the concept of formal thought processes taking place in the absence of 
 
J. KANE

151
subjective experience is so deeply engrained in the paradigm of contempo­
rary neuropsychology that thinking can be nothing other than informa­
tion processing. And computationalists are correct in one critical respect: 
thinking independent of subjective inner activity is information processing.
The act of imaginative thinking is complex and fraught with the possi­
bility of error. Each act of learning is transformational—it not only expands 
the range and increases the acuity of the mind but opens the possibility of 
entirely new systems of organization. The new schema that emerge from 
our imaginative efforts based upon our dwelling in experience are genera­
tive in nature; they are not ends in themselves but sources of illumination 
that can reveal patterns and principles in the world that might otherwise 
remain hidden. New schema are not added to consciousness like so many 
apps to a new smartphone; they are created in an active effort to achieve 
new levels of coherence through the imaginative exploration and expan­
sion of experience. Thinking and being are intimately connected.
Learning Not to Think
The nature and function of indwelling and imaging in shaping human 
thinking is often obscured in adults by the fact that our thinking includes 
vast stores of images and associations given to us by others. We have, in 
effect, learned not to think but to apply concepts and rules of one sort or 
another placed within us. In such cases, our treatment of ideas most often 
is functional with an eye toward finding greater and greater efficiency and 
control. The search for coherence is largely lost, with the consequence 
that few adults truly experience meaning in their thinking. Utility yes, 
meaning no.
Many of us recall the days we spent as students in elementary school 
classrooms learning the multiplication tables. Multiplication itself was 
introduced as repeated addition and the tables as products to be memo­
rized. With enough repetition, we stored the information and could apply 
it functionally—we could multiply. The lessons we learned reinforced the 
notion that learning is the accumulation of information and the acquisi­
tion of skills, rather than the growth of our insight or ability to discover 
principles that weave through mathematics. The concepts we often learned 
offered little or no meaningful dwelling place, no source for imaging new 
possibilities for coherence.
However, few of us were taught to experience the patterns in the tables 
that can be introduced somatically by walking them as simple rhythms so 
8  EMERGING MINDS 

152
that we might dwell in them as patterns. Few of us have learned to play 
with them to discover how they relate to one another and form some of 
the most basic structural elements in our numerical system such as primes 
and “abundant” numbers. (The day is broken into 24 hours and a circle 
into 360 degrees precisely because those numbers are so abundant.)
A vivid illustration of this type of dwelling in the symmetries and orga­
nizational principles of numbers is found in an oft-told story of Carl 
Friedrich Gauss who was one of the greatest of all mathematicians the 
world has ever known. As a boy,
14
For adults, this experience of dwelling in and imaging ideas has become 
faint. Previously somatically-based explorations and imaginative thinking 
(as in play) have been replaced by the routine application of abstract con­
cepts that have themselves become buried beneath formal processes and 
artifices of information. Aside from the specific content we learned, we 
learned to think of numbers in terms of their functional value. We have 
learned to see all the world, our thinking and even ourselves in functional 
terms alone as algorithmic codes. Ironically, we have learned to function 
intellectually much like computers. The very reason so many of us see little 
or no daylight between information procession and human thinking is 
that we can hardly imagine what it is to dwell within ideas as vital and 
creative.
The generative frameworks most of us use to make sense of the world 
and to make our judgments—whether social, political, economic, or envi­
ronmental—were long ago reduced to processing rules. This approach to 
thinking is what Heidegger called the enframement created by technology. 
The most significant effect of computational technologies, and most nota­
bly generative artificial intelligence, is its power to establish a new cogni­
tive environment, one in which our minds will adapt. It will shape both 
14 Dahaene, Stanislas. The Number Sense: How the Mind Creates Mathematics. New York, 
Oxford University Press, 1997, pp. 147–148.
 
J. KANE

153
how we think and what we think about. Those of us in classrooms already 
face daunting questions about the nature and purpose of education. Yet 
the greater problem will be the gradual loss of our ability to articulate, let 
alone develop, thinking that transcends information processing, and our 
ability to understand ourselves as more than information processors.  
Within this context, the language we use to describe the human mind and 
ourselves as human beings will slowly evolve to fit within the parameters 
set by technology as our cognitive touchstone.
The Self as Object
15
In this context, the subjective “self” projects itself into a social mirror 
and constructs an image of how it might appear to others. The “self” that 
stares back is a construct. Strictly speaking in this context, we are an object 
to ourselves as imagined in the eyes of others. We are not the experiencing 
subject but the subject of our experience. We imagine what conclusions 
others must draw as they interact with us. The “self” we imagine is a con­
tinuously evolving aggregation of projections we ascribe to others as we 
believe they see us. Thus, the “self” of which we are aware is quite differ­
ent than the “self” which is aware. The former is a socially guided con­
struct, and the latter is the creator of the construct (the one who seeks 
coherence in experience and imbues all thought with such intent). The 
former is a thought; the latter is the thinker. In this context, contemporary 
computational theorists conclude that the human “self” is an abstract con­
struct, with human thinking being a formal process with neither meaning 
nor purpose.
In contrast, an emergent model synthesizes all layers of organization of 
our existence—each one contributing its own unique experiences and 
15 Graziano, 2016, p. 5.
8  EMERGING MINDS 

154
principles of coherence—to create the multi-tiered form, substance, and 
agency of human consciousness. Our consciousness includes our subjec­
tive experience at all the levels of our being— from the sheer physicality of 
our bodies to the agency of our minds to unfold systems of cognitive 
coherence.
We are both the “self” as a thinker and the “self” as a construct of 
thought—depending on whether we view ourselves from a theoretically 
objective vantage point outside of our subjective experience or from within 
the context of our experience in all its dimensions. Subjective experience 
and the schema we have developed through both biological and social 
evolution are the relational polls that animate and advance human con­
sciousness—the former expanding outward and the latter constraining 
from without.
­
16
(Note the somatic echoes in this process as also reflected in Einstein’s 
description of the vague “muscular” nature of his own thinking process.)
In this regard, James defines consciousness as being an explicit focal 
object of awareness such as a sensory impression, a bodily sensation, an 
explicit thought, or an emotional feeling. In this model, he could not 
make his experience of consciousness itself the focus of his attention as he 
resides within it. As he exteriorized it, as he viewed his consciousness as 
external to his experience, it no longer served as his consciousness. In the 
attempt to perceive himself in the act of creating thoughts, he made his 
conscious self an object external to his consciousness.
The central problem he faced was in thinking that the self as subject and 
the self as object are, in some sense equivalent. They are not. The self that 
is the object of experience has no existence of its own. It is an abstraction 
16 James, William. Principles of Psychology. New York, Henry Holt and Company, 1890, 
p. 300, retrieved from https://psychclassics.yorku.ca/James/Principles/prin10.htm.
 
J. KANE

155
that can never be explored except as a concept. The self that is the subject 
exists in the multiple layers of human being; it is light by which we see 
rather than an object we may illuminate.
We cannot turn ourselves about to catch a glimpse of ourselves in the 
act of thinking. We can see our constructed concepts of ourselves in the 
mirror of language, but the actuality of our existence is not a conceptual 
construct. It is our being alive and conscious in the world.
We can apprehend ourselves not as separate from all else but only as we 
dwell within all the layers of principles creating the universe, inclusive of 
and beyond our experience. We cannot fully understand ourselves by 
attempting to look within ourselves as if some objective self lies hidden 
beneath the jumble of the day-to-day. We do not exist in isolation but in 
relation. We are defined as we unfold in dialogue with all else that exists. 
The self as a defined and separable entity is an illusion.
The Reality of Self
But is the self in our conscious self-awareness real? Does it exist as a con­
cept in a book or as a feeling in one’s body or as irreducible reality beyond 
our thoughts or sensations? The brain exists as a physical organ, but is 
there a thinker in there somewhere? Is there a self that is conscious and 
that provides a coherent foundation for the experience of meaning? Is it 
possible that we have a mind that experiences meaning beyond the bio­
chemistry of the brain and that can alter the course of the physical pro­
cesses the brain performs?
­
17
However, while it is true that the brain has distinct regions that can act 
with relative independence, that does not mean that there is no self, no 
unity of being that may say “I.” At the heart of the matter is not whether 
17 Gazzaniga, 2011, p. 102.
8  EMERGING MINDS 

156
we believe in a soul or spirit that exists beyond all the attributes of our 
bodies as physical entities. The question would still stand before us about 
how such spiritual dimensions would integrate themselves within us as 
earthly beings. If the two are distinct and separable, we are left with the 
same type of dualism as both Descartes and contemporary computational 
theories of mind. How do they connect?
The answer lies in recognizing that the self does not exist at the level of 
emergence of the physical organ of the brain any more than life can be 
found in the molecules of our bodies. At the very least, there are signifi­
cant social and linguistic layers of emergence (both embedded in us as a 
species and cultivated in us individually) that make the self possible. 
Although the emergence of the human self is immeasurably more complex 
than we can address, we can nonetheless reasonably draw a possible out­
line for consideration.
The Creation of Self
Human thinking, no matter how we might objectify its processes and its 
products, is borne of subjective intent and experience. It is not the prod­
uct of a disembodied intellect—Gilbert Ryle’s “ghost in the machine.” In 
this world, we exist as physical, biological, sentient, social, conscious, and 
self-aware beings. Each layer has emerged from those beneath it, continu­
ally incorporating all the experiences within each of them in our conscious­
ness. With each emergent layer of organization, new forms of coherence 
and operational principles arise. Human consciousness includes all these 
layers, each contributing to an experientially-based paradigm for the cre­
ation of ideas. The conscious self is not a thing unto itself but is created 
relationally through the active interweaving of all these levels of being.
Like Descartes and James and countless others who have turned within 
to explore human thinking, we must confront the ultimate questions of 
who and what we are. In our journey through the emergence of mind, we 
have explored the nature of the organizational principles of coherence that 
govern each layer of being, but we have yet to address their origins. The 
question here is not about the mechanics of creation of the human self but 
the origins of the principles that guide its unfolding. Are we spiritual 
beings who have come into physical form or are we the ultimate product 
(as far as we know) of purely physical principles that express themselves 
only in the rarified and complex molecular structure of the human body? 
Are our brains vessels of spiritual light or biological computational 
machines?
 
J. KANE

157
Although we are physical beings at one with the physical universe, we 
are also conscious beings in a cosmos that is boundless. Even as we extend 
our ability to see the furthest stretches of the universe, we ask what lies 
beyond it; even as we reach back to the big bang, we ask what existed 
before it. While it may be that the universe curves back into itself such that 
there is nothing outside of it, and while it may that there was nothing at 
all before those first explosive milliseconds of the Big Bang, the very fact 
that we ask such questions and that we are capable of creating such ideas 
are testaments to the depths of our search to understand not only the 
mind of God in the act of creating the universe but the ultimate founda­
tions of our minds as both created and creative beings. We seek to under­
stand the origins of our own consciousness and its expression in human 
thinking in a universe in which it has a place.
18
19
20
Although some may find peace in the same answer, the question has 
been and remains central to our existence as consciously self-aware beings. 
In what context do our selves exist? Nothing exists in isolation. All things 
exist relationally and come into their existence in the dynamics of their 
relation with all that surrounds them, including us. Just as we seek coher­
ence in our understanding of the relational nature of the phenomena in 
18 Barrett, William. Death of the Soul: From Descartes to the Computer. New York, Anchor 
Books, 1986, p. 17.
19 Ibid., p. 17.
20 Ibid., p. 18.
8  EMERGING MINDS 

158
the world around us, we seek a coherent understanding of our own exis­
tence, our own place in the universe.
This drive is not incidental. It is no less essential than our hunger for 
food. It is an essential element in human civilization. Throughout the 
world people often have sought their answers in spiritual conceptions of 
the universe. The specific nature of their beliefs—whether there are ele­
mental beings in nature, a single God who reigns over all creation or there 
are no deities at all—is less significant than that they all see the universe 
and humanity as extending beyond the reach of our senses. All things are 
imbued with a place and purpose greater than their material form or 
function.
There are also those who seek a coherent understanding of human con­
sciousness in biology, chemistry, and physics. In this context, conscious­
ness may be an ever-present dimension of all things, a downstream 
consequence of evolution or simply a statistical blip in a random universe. 
Whatever theoretical framework we may construct, the search for coher­
ence for all of us is borne of a passion that emerges with our consciousness 
within multiple layers of being. Our ideas, in this regard, have a powerful 
effect not only in what we believe ourselves to be but how we will live our 
lives and make of ourselves.
The simple truth is that nothing offered in this volume has addressed 
the origins of the principles that would govern any of these possibilities. 
Our task has been to demonstrate that despite all attempts to reduce life 
and human consciousness to the properties of quantum particles and com­
putational processes, they fail to account for the agency and intent—for 
the very questions they attempt to answer. They fail to account for the 
possibility of life and of mind as uniquely capable of initiating new levels 
of irreducible organization. They fail to account for our thirst for coher­
ence or the passion and beauty that drive the highest of human creations, 
including science.
­
­
 
J. KANE

159
­
­
21
If we understand ourselves to be computational machines with con­
sciousness playing no role in our thinking or our fashioning of ourselves, 
then the path we are on is set independent of what we think or experience. 
We have no more say in our own destiny than the intellectual content of a 
book may have in directing its path as it falls from a shelf. Our thinking of 
ourselves as biological computers will be the image in which we fashion 
ourselves. We also will see others in that very same light. Our values and 
moral premises will follow. The conceptual foundations we use to under­
stand and develop our capacity to think will infuse our individual judg­
ments and the social dispositions that define our culture. We will find 
ourselves in a fragmented universe where nothing, including ourselves, 
have any place or value or purpose. All that we do will follow. Our social 
institutions and culture will express our image of our humanity. The prob­
lems we face are expressions not of circumstance but of the principles 
underlying our thinking.
The threats posed by generative AI are expressions of the computa­
tional model of thinking that led to its creation. It begins with the assump­
tion that the world can be broken down into discrete objects and used to 
meet one end or another. It extends into a vision of a universe where there 
is no place for life or consciousness or purpose. In this worldview, the par­
ticular aims we might choose, individually or collectively, ultimately follow 
the ultimate law in physics—the laws of entropy. From order comes disor­
der. As Ralph Waldo Emerson observed in his essay Nature, “The reason 
21 Heschel, Abraham J. Who is Man? Palo Alto, CA, Stanford University Press, 1965, p. 7.
8  EMERGING MINDS 

160
why the world lacks unity, and lies broken and in heaps, is, because man is 
disunited with himself.”
However, if we understand ourselves as conscious beings whose experi­
ence of being in the world is the genesis of thinking, then thinking can be 
a creative act. Despite the routine and practical realities that occupy our 
intellects, despite the need to think in such ways to live our daily lives, we, 
often tacitly, live with deeper streams of questions of what we are doing 
and why, of how we can understand ourselves, of what we believe and 
would like to believe, of what we value and the costs to pursue it, of who 
we are and what we are to do with our lives. These are not questions about 
how we may understand the world but about ourselves and our place 
within the world. The answers we create, however tentative and vague or 
declarative and explicit, form the designs we will use to fashion our lives, 
as well as the culture and world we leave to our children.
Although some of us may argue that we do not engage in such ques­
tions, or that they are so speculative that they just are not worth the time, 
the fact is that we answer them nonetheless. The substance of our experi­
ence of our lives matters, and we all try to make sense of it; we all seek 
some framework of understanding that provides us with a coherent vision 
of ourselves and a world beyond us. The conclusions we reach are rarely in 
the form of clear concepts but found in the organizational principles that 
emerge in us as human beings.
The recognition of the existence of the subjective experience of others, 
of their being, is essential to understanding what it is to be human. In 
recognizing them, we transcend our experience. To adapt one of Einstein’s 
famous thought experiments, we become capable of understanding what 
lives behind the eyes of both the man standing on the train platform pon­
dering the experience of the passenger seated by one of the windows of a 
train speeding by and, in turn, the experience of the commuter gazing out 
at the man waiting on the platform pondering on him. The content of 
their thoughts is not the point; the fact that we can imaginatively dwell in 
the subjective experience of others is. When we include the experience of 
the other in our consciousness, when we can dwell in the shared reality of 
our human humanity, we engage in the most fundamental of dialogues. 
We meet.
In that meeting, our subjectivity pales. We experience not only a sense 
of agency for ourselves but to live with a sense of purpose beyond the 
limits of our own subjective experience. With each successive level of 
emergence from the physical to conscious self-awareness, the distance 
 
J. KANE

161
between reductionist empiricism and the experience of human beings wid­
ens, and the limitations of a computational model of the human 
mind grows.
­
­
22
We are not mere constellations of atoms or biological computers. We 
are living beings capable of achieving a transcendent moral consciousness 
as a basis for our own aspirations and for the creation of a just and peaceful 
world. Whether we learn to think with our full humanity or to conceive of 
ourselves in the image of computational machines, we will become what 
we would think ourselves to be.
22 Polanyi, Michael Science, Faith and Society, the University of Chicago Press, 1964, p. 84.
8  EMERGING MINDS 

163
1
1 Note: Page numbers followed by ‘n’ refer to notes.
A
Afferent neurons, 15
Age of Generative Artificial 
Intelligence, 1
See also Generative AI
Agency, 97–99
of autotropic plants, 98
of consciousness, 150, 154, 158
of E. Coli, 98
of intelligence, 137–140
of life, 58
properties of life and, 98
reductionism and, 19, 22
subjective experience and, 160
thinking and, 119
Algorithms
Brain-Computer Interface and, 10
cognition and, 63–64, 110
in computational systems, 
43, 50, 52
consciousness and, 87
definition of, 13–14
dynamic physical universe and, 80, 91
functional view of intelligence and, 
54–56, 152
language and, 4, 13–15, 17, 19, 22, 
24, 63, 114
thinking and, 6
Amino acids, 58, 91, 96–97
Anderson, P. W., 80
Aristotle, 16, 17, 20
Art, 126, 127, 134
Artificial intelligence, definition of, 55
See also Generative AI
Attention Schema Theory (AST), 
137, 138
Aussems, Suzanne, 106
Autopoietic systems, 99
Awareness
Attention Schema Theory and, 138
cognition and, 30
public awareness, 108
self-awareness, 11, 110, 155, 160
shared awareness, 107, 142, 147–150
subliminal awareness, 127
Aydede, Murat, 100
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2024
J. Kane, The Emergence of Mind, 
https://doi.org/10.1007/978-3-031-46835-3

164 
INDEX
B
Bacon, Francis, 20
Banks, Lain, 10
Barrett, William, 157
Bateson, Gregory, 141
Behavioral psychology, 35
Behaviorism, 32, 33, 35–38, 
41, 42, 102
Bell Labs, 42
Bingham, Roger, 93
Biochemistry, 19, 47, 100, 138, 155
Biological evolution, 103–105, 109
Biology
causality and, 139
chemistry and, 87
consciousness and, 7, 47
Descartes and, 31–32
experience of ourselves and, 18
history of, 32
indwelling and, 144–147
language and, 109
the mind and, 11–12
the mind as biological computer, 17, 
22, 24, 45, 156, 159
physics and, 68
Black box metaphor, 35, 39, 102
Boyd, Robert, 107
Brain-Computer Interface (BCI), 10
Bruner, Jerome, 42–43
Burkhart, Ian, 9–10
C
Causation, 68, 73, 78, 79
Chalmers, David, 14, 53, 54, 
62–69, 74, 126
ChatGPT, 1, 2
Chemero, Anthony, 95–96
Chess, 133
Chinese Room thought experiment, 66
Choi, Yejin, 3
Chomsky, Noam, 36, 37, 39
Churchland, Patricia, 46, 47, 69
Churchland, Paul, 45–47, 69
Clark, Andy, 126
Cognition
Chalmers on, 63–64, 67
embodied cognition, 94, 95
relational nature of, 95
shared cognition, 107
Cognitive psychology, 40–42
Cognitive Revolution, 42–44
Coherence, quest for, 121–124
Combinatorial-state automata (CSAs), 
53, 54, 65, 67
Computational models
Cognitive Revolution and, 43, 44
limitations of, 159, 161
of the mind, 6, 13, 48, 49, 
60, 62, 63
statistical nature of, 13
Computational systems
Cartesian theory and, 48
cognition and, 63, 64
definition of, 49–52
disequilibrium of, 74
intelligence of, 54–56
invariance of, 53–54
language and, 43
mathematics and, 49–52, 74
mind metaphor as, 47
neural computational systems, 10
relational nature of, 74
Computers
as combinatorial-state automata, 53
history of, 38–40, 114
quantum computers, 54
Consciousness
Attention Schema Theory and, 
137, 138
awareness of, 5
behaviorists on, 33
as by-product of biological 
processes, 57, 58

165
  INDEX 
Chalmers on, 62–64
Dennett on, 57, 59–61
Descartes on, 12–13, 30, 69
Dreyfus on, 16–17
of existence, 18
James on, 154
mystery of, 5, 72
Nagel on, 69
relational nature of, 58
subjective experience and, 48, 
59, 61, 70
subjective experience separated 
from, 12–15
Copernicus, Nicolaus, 117
Creation
definition of, 6
of meaning, 134–135
of self, 156–161
Culture, The (Banks), 10
D
Damasio, Antonio, 15–16, 48, 
99, 125
Darwin, Charles, 17, 32–33, 104
Darwin’s Dangerous Idea 
(Dennett), 56–63
Death of the Soul (Barrett), 157
Dennett, Daniel, 56–63, 69
Descartes’ Error (Damasio), 15
Descartes, Rene
Damasio on, 15–16
dualism of, 13, 14, 32, 35, 67, 
69, 71, 156
influence of, 21
“I think, therefore I am,” 20
reductionism of, 12, 19–20, 
69, 124
on self as “thinking thing,” 12, 
29–31, 44, 48, 68, 111, 157
on Truth, 27–31, 87, 124, 157
Digital information, 43
Discourse on The Method of Rightly 
Conducting One’s Reason and of 
Seeking Truth in the Sciences 
(Descartes), 28
Disequilibrium
chess and, 133
of computational systems, 74
continuity and, 110
of dissipative systems, 80
learning and, 147, 149
shared awareness and, 147–149
Dissipative systems, 83–85
DNA, 56–59, 62, 98, 105, 139
Dreyfus, Hubert, 16–17, 44
Dualism
computational models of, 
14, 67, 156
of Descartes, 13, 14, 32, 35, 67, 
69, 71, 156
reductionism and, 14, 69
E
E. coli, 98–99, 103
Eddington, Arthur, 130
Einstein, Albert
capacity for indwelling of, 142
curiosity of, 115, 116
desire for coherence of, 121–124
on formal systems, 130–132
on his thinking process, 131–133, 154
imagination of, 129, 130
intuition of, 128, 129
on the mind of God, 117, 118
moving train thought experiment, 
122, 123, 135, 160
theory of general relativity, 21, 
109, 130
theory of special relativity (theory of 
invariance), 21, 77, 130
theory of the gravitational curvature 
of space, 130

166 
INDEX
Electroencephalograms (EEGs), 10
Emergence
dissipative sytems and, 83–85
of the human mind, 8, 119, 121, 
142, 156–161
of ideas, 149–151
intention and, 141
of life, 99
multiple levels of, 85–87, 95, 
141, 142
of self, 156
of social evolution, 102–104
of symbolic language, 105–109
Emerson, Ralph Waldo, 159
Empirical reductionism, 20–24, 
71–72, 129
See also Reductionism
End of Certainty, The (Prigogine), 78
Engine of Reason, The 
(Churchland), 45, 78
Enigma machine, 38, 39
Entropy, 83, 85, 99, 159
Evolution, see Biological evolution; 
Social evolution
F
Facebook, see Meta
Fodor, Jerry, 43
Formal systems, 129–134
Friston, Karl, 89, 91
G
Galileo Galilei, 20
Gallagher, Shaun, 95
Gardner, Howard, 134
Gauss, Carl Friedrich, 152
Gazzaniga, Michael S., 109, 121, 
122, 155
Generative AI
ChatGPT, 1, 2
development of, 1–3
drawbacks and constraints of, 2, 53, 
56, 87, 159, 161
economic impact of, 2
human experience compared with, 3
language produced by, 3–4
prompts and, 4
Genetics, 98, 105–108, 145, 149
See also DNA
Google, 1–2
Gravity
experience of, 95, 124, 125, 
143, 144
liquid properties and, 82
Newton’s theory of, 20, 74–77, 81
relational nature of, 130
Graziano, Michael, 137, 138, 147, 153
H
Hand, human, 105
Hawking, Stephen, 73, 86
Heidegger, Martin, 152
Heschel, Abraham, 159
Hutto, Daniel, 95
I
Ibn al-Haytham, Abu Ali 
al-Hasan, 20, 140
Imagination, 129–130, 132
Imitation Game, The (film), 38
Imitation game (Turing Test), 2, 6, 
38–39, 65
Indwelling, 124–127, 142, 150, 151
biological indwelling and 
insight, 144–147
imaginative social indwelling, 147
transition to abstract symbols 
from, 131
Intelligence, 54–56
agency of, 137–140

167
  INDEX 
“dark matter” of, 3
functional view of, 54–56
Gardner’s theory of multiple 
intelligences, 134
organizing principle of, 140–142
Intuition, 127–129, 157
J
James, William, 154, 156
K
Kauffman, Stuart, 96, 97
Kendon, Adam, 106
L
La Cerra, Peggy, 93
Lakoff, George, 95
LaMDA (Google Chatbot), 1–2
Language
algorithms and, 4, 13–15, 17, 19, 
22, 24, 63, 114
biology and, 109
computational systems and, 43
linguistic behavior, 12, 39, 41
natural language, 3, 17, 43–45, 55
produced by generative AI, 3–4
symbolic language, 95, 105–109
word patterns, 17–18
Language of Thought, The (Fodor), 43
Larson, Erik, 55
Laughlin, Robert, 79, 81–83
Leibniz, Gottfried Wilhelm, 74
Living ideas, 119–120
Logic, 132–134
M
Mathematics
of AI, 112
behaviorism and, 35
cognitive psychology and, 40–41
cybernetics and, 42
Descartes and, 29, 31–32, 35, 73
Einstein and, 116, 118, 129–132
in elementary classroom, 151
formal structures of, 116
Greek philosophers and, 117
Newton and, 76
of quantum mechanics, 77
See also Computational systems; 
Turing, Alan
Maturana, Humberto, 92
Maxwell, James Clerk, 21, 76
McClintock, Barbara, 144–146, 148
Memory, 41
Meta, 2, 10
Metaphor, 45–48, 95, 96
Microsoft, 1
Miller, George, 40–42
Mimicry, 6, 16, 19
Mind and Matter (Schrödinger), 127
Mind, the, 102–111
as biological computer, 17, 22, 24, 
45, 156, 159
biology and, 11–12
computational models of, 6, 13, 48, 
49, 61, 63, 64
continuity of body and, 109–111
emergence of social 
evolution, 102–104
emergence of symbolic 
language, 105–109
interplay of biological and social 
evolution, 104–105
physics and, 11–12, 22
reductionism and, 22–24
union of body and, 24–25
Mlodinow, Leonard, 73, 86
Morality, 103, 159, 161
Musk, Elon, 10
Myin, Erik, 95

168 
INDEX
N
Nagel, Thomas, 60, 61, 69, 73
Natural language, 3, 17, 43–45, 55
Neuralink Corporation, 10
Neural interfaces, 9–10
Neural prostheses, 10
Neurons, 10–11, 19, 65, 66, 100
afferent neurons, 15
function of, 11
pixel metaphor of, 46
Newell, Allen, 39–40, 42
Newton, Isaac, 31–32, 47–48
empirical reductionism of, 20–21
first law of motion, 97–98
influence of, 20–21
theory of gravity, 20, 74–77, 81
Newton’s theory of, 73–77
O
On the Origin of Species By Means 
of Natural Selection 
(Darwin), 32–33
OpenAI, 1–2
Organization, 80–83
P
Pain, 19, 100–102
Pavlov, Ivan, 32, 33
Physics, 138, 139, 144, 158, 159
Darwinism and, 32
DNA and, 58, 62
experience of self and, 18
human mind and, 11, 22
intelligence and, 139
laws of entropy, 159
mind-body union and, 24
Newtonian physics, 19–21
Piaget, Jean, 149
Plato, 20, 117, 140
Play, children’s, 128, 129, 
142–144, 146–148
Pointing, declarative and 
imperative, 106–107
Polanyi, Michael, 19, 125, 126, 141, 
142, 161
Popper, Karl, 47
Prigogine, Ilya, 78, 79, 81, 83, 84, 90
Principles of Philosophy (Descartes), 30
Prostheses, 10
Psychology, 33, 34, 39, 147–149
behavioral psychology, 34
cognitive psychology, 40–42
See also Behaviorism
Putnam, Hilary, 45
Pythagoras, 117
Q
Quantum computers, 54
Quantum mechanics, ix, 18, 77, 
86, 87, 90
R
Radio waves, 93, 113, 114
Rae, Alastair, 78
Reductionism
constraints of, 19, 24, 68, 77–79, 
82–87, 100n8, 161
definition of, 14
of Descartes, 12, 19–20, 69, 124
dualism and, 14, 69
empirical reductionism, 20–24, 
71–72, 129
history and science of, 20–21
human mind and, 22–24
of Newton, 20–21
Reinforcement, 35–37, 39

169
  INDEX 
Relational models and systems, 
71–77, 87
capacity to image, 145
of cognition, 95
coherence and, 122
of computer systems, 75
of conscious self, 156, 157
embodied cognition and, 94
fish pond as, 91, 92
gaps in, 87
human nervous system and, 138
indwelling and, 124–127
intelligence and, 139
of the physical universe, 74, 76–80
of quantum mechanics, 77–79
of schema, 150, 154
of social evolution, 102–104, 
109, 154
thinking and, 119, 135
of the universe, 77–79, 118, 129
Rosch, Eleanor, 94
Ryle, Gilbert, 156
S
Salaman, Esther, 116
Schema, 138, 140–142, 148–151, 153
See also Attention Schema 
Theory (AST)
Schrödinger, Erwin, 71, 127
Scientific method, 13, 28, 33, 73
Search engines, 2
Searle, John, 65, 66
Self
creation of, 156–161
Descartes on, 12, 29–31, 111, 157
as object, 153–155
reality of, 155–161
Self-awareness, 11, 95, 110, 
155, 160
Sensation
biology and, 47, 87
bodily sensations, 12–13, 15, 18, 
109, 154
Descartes on, 30–31
indwelling and, 125
of pain, 19, 100–102
Sentience, 2, 7, 12, 62, 99–102, 
112, 156
Shakespeare, William, 6, 15
Shannon, Claude, 42, 43
Simon, Herbert, 39–40, 42
Skinner, B. F., 34–37
Social evolution
adaptation and, 108
agency and, 137
emergence of, 102–104
interplay of biological and, 104–105
subjective experience and, 154
Sperry, Roger, 121
Startrek, 10–11
Static systems, 83
Stimuli-behavior theories, 32–33, 36, 37
Symbolic language, 105–109
T
Tacit knowing, 3, 125, 126, 129, 135, 
142, 143, 147, 160
Thompson, Evan, 94
Timaeus (Plato), 117
Tontoni, Giulio, 48
Turing, Alan, 2, 3, 38, 39, 42, 
45, 51, 114
Turing Test (imitation game), 2, 6, 
38–39, 65
U
Uncertainty, 29, 80–83

170 
INDEX
V
Van Oers, Bert, 148
Van Regenmortel, Marc, 100
Varela, Francisco, 92, 94
Verbal Behavior (Skinner), 34–36
Virtual assistant technology, 2
Vygotsky, Lev, 147, 148
W
Watson, John, 33
What Computers Can’t 
Do (Dreyfus), 
16–17
World War II, 38–39, 42
Wundt, Wilhelm, 33

