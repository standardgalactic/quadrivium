
International Series in Operations
Research & Management Science
Volume 108
For other titles published in this series, go to
http://www.springer.com/series/6161

Dirk Beyer · Feng Cheng · Suresh P. Sethi ·
Michael Taksar
Markovian Demand
Inventory Models
123

Dirk Beyer
M-Factor
1400 Fashion Island Blvd.
Suite 602
San Mateo CA 94404
USA
dirk.beyer@m-factor.com
Feng Cheng
Federal Aviation Administration
Ofﬁce of Performance Analysis and Strategy
800 Independence Ave. S.W.
Washington, D.C. 20591
USA
feng.cheng@faa.gov
Suresh P. Sethi
School of Management, M/S SM30
The University of Texas at Dallas
800 W. Campbell Road, SM 30
Richardson, TX 75080-3021
USA
sethi@utdallas.edu
Michael Taksar
Department of Mathematics
University of Missouri
Rollins Road
Columbia MO 65211
USA
taksar@math.missouri.edu
ISSN 0884-8289
ISBN 978-0-387-71603-9
e-ISBN 978-0-387-71604-6
DOI 10.1007/978-0-387-71604-6
Springer New York Dordrecht Heidelberg London
Library of Congress Control Number: 2009935383
c⃝Springer Science+Business Media, LLC 2010
All rights reserved. This work may not be translated or copied in whole or in part without the written
permission of the publisher (Springer Science+Business Media, LLC, 233 Spring Street, New York,
NY 10013, USA), except for brief excerpts in connection with reviews or scholarly analysis. Use in
connection with any form of information storage and retrieval, electronic adaptation, computer
software, or by similar or dissimilar methodology now known or hereafter developed is forbidden.
The use in this publication of trade names, trademarks, service marks, and similar terms, even if
they are not identiﬁed as such, is not to be taken as an expression of opinion as to whether or not
they are subject to proprietary rights.
Printed on acid-free paper
Springer is part of Springer Science+Business Media (www.springer.com)

Table of Contents
List of Figures
ix
List of Tables
xi
Preface
xiii
Notation
xvii
Part I
INTRODUCTION
1.
INTRODUCTION
3
1.1
Characteristics of Inventory Systems
3
1.2
Brief Historical Overview of Inventory Theory
5
1.3
Examples of Markovian Demand Models
12
1.4
Contributions
15
1.5
Plan of the Book
16
Part II
DISCOUNTED COST MODELS
2.
DISCOUNTED COST MODELS WITH BACKORDERS
21
2.1
Introduction
21
2.2
Review of the Related Literature
22
2.3
Formulation of the Model
23
2.4
Dynamic Programming and Optimal Feedback Policy
26
2.5
Optimality of (s, S)-type Ordering Policies
31
2.6
Nonstationary Inﬁnite Horizon Problem
33
2.7
Cyclic Demand Model
37
2.8
Constrained Models
37
2.9
Concluding Remarks and Notes
39

vi
Table of Contents
3. DISCOUNT COST MODELS WITH POLYNOMIALLY
GROWING SURPLUS COST
41
3.1
Introduction
41
3.2
Formulation of the Model
42
3.3
Dynamic Programming and Optimal Feedback Policy
44
3.4
Nonstationary Discounted Inﬁnite Horizon Problem
49
3.5
Optimality of (s, S)-type Ordering Policies
55
3.6
Stationary Inﬁnite Horizon Problem
57
3.7
Concluding Remarks and Notes
57
4.
DISCOUNTED COST MODELS WITH LOST SALES
59
4.1
Introduction
59
4.2
Formulation of the Model
60
4.3
Optimality of (s, S)-type Ordering Policies
63
4.4
Extensions
66
4.5
Numerical Results
69
4.6
Concluding Remarks and Notes
72
Part III
AVERAGE COST MODELS
5.
AVERAGE COST MODELS WITH BACKORDERS
83
5.1
Introduction
83
5.2
Formulation of the Model
86
5.3
Discounted Cost Model Results from Chapter 2
89
5.4
Limiting Behavior as the Discount Factor Approaches 1
90
5.5
Vanishing Discount Approach
98
5.6
Veriﬁcation Theorem
102
5.7
Concluding Remarks and Notes
106
6.
AVERAGE COST MODELS WITH POLYNOMIALLY
GROWING SURPLUS COST
107
6.1
Formulation of the Problem
107
6.2
Behavior of the Discounted Cost Model with Respect
to the Discount Factor
109
6.3
Vanishing Discount Approach
116
6.4
Veriﬁcation Theorem
125
6.5
Concluding Remarks and Notes
130

MARKOVIAN DEMAND INVENTORY MODELS
vii
7.
AVERAGE COST MODELS WITH LOST SALES
133
7.1
Introduction
133
7.2
Formulation of the Model
133
7.3
Discounted Cost Model Results from Chapter 4
137
7.4
Limiting Behavior as the Discount Factor Approaches 1
138
7.5
Vanishing Discount Approach
142
7.6
Veriﬁcation Theorem
145
7.7
Concluding Remarks and Notes
150
Part IV
MISCELLANEOUS
8.
MODELS WITH DEMAND INFLUENCED
BY PROMOTION
153
8.1
Introduction
153
8.2
Formulation of the Model
155
8.3
Assumptions and Preliminaries
162
8.4
Structural Results
164
8.5
Extensions
170
8.6
Numerical Results
173
8.7
Concluding Remarks and Notes
174
9. VANISHING DISCOUNT APPROACH VS. STATIONARY
DISTRIBUTION APPROACH
179
9.1
Introduction
179
9.2
Statement of the Problem
182
9.3
Review of Iglehart (1963b)
184
9.4
An Example
187
9.5
Asymptotic Bounds on the Optimal Cost Function
192
9.6
Review of the Veinott and Wagner Paper
195
9.7
Existence of Minimizing Values of s and S
197
9.8
Stationary Distribution Approach versus Dynamic
Programming and Vanishing Discount Approach
203
9.9
Concluding Remarks and Notes
206

viii
Table of Contents
Part V
CONCLUSIONS AND OPEN RESEARCH
PROBLEMS
10. CONCLUSIONS AND OPEN RESEARCH PROBLEMS
211
Part VI
APPENDICES
A. ANALYSIS
217
A.1 Continuous Functions on Metric Spaces
217
A.2 Convergence of a Sequence of Functions
219
A.3 The Arzel`a-Ascoli Theorems
220
A.4 Linear Operators
222
A.5 Miscellany
223
B. PROBABILITY
225
B.1
Integrability
225
B.2
Conditional Expectation
226
B.3
Renewal Theorem
227
B.4
Renewal Reward Processes
227
B.5
Stochastic Dominance
228
B.6
Markov Chains
229
C. CONVEX, QUASI-CONVEX AND K-CONVEX
FUNCTIONS
233
C.1
PF2 Density and Quasi-convex Functions
233
C.2
Convex and K-convex Functions
234
References
241
Copyright Permissions
247
Author Index
249
Subject Index
251

List of Figures
1.1
Relationships between diﬀerent chapters.
18
2.1
Temporal conventions used for the discrete-time
inventory problem.
25
4.1
Results for Case 1.1.
73
4.2
Results for Case 1.2.
74
4.3
Results for Case 1.3.
75
4.4
Results for Case 1.4.
76
4.5
Results for Case 2.1.
77
4.6
Results for Case 2.2.
78
4.7
Results for Case 2.3.
79
4.8
Results for Case 2.4.
80
8.1
Numerical results for Case 3.1.
175
8.2
Numerical results for Case 3.2.
176
8.3
Numerical results for Case 3.3.
177
8.4
Numerical results for Case 3.4.
178
9.1
Deﬁnitions of Sl and Su.
197

List of Tables
4.1
Numerical results for the lost sales model with uni-
form demand distribution.
71
4.2
Numerical results for the lost sales model with trun-
cated normal demand distribution.
71
8.1
Numerical results for the MDP model with uniform
demand distribution.
172
8.2
Numerical results for the MDP model with trun-
cated normal demand distribution.
173

Preface
Inventory management is among the most important topics in op-
erations management and operations research. It is perhaps also the
earliest, as evidenced by the economic order quantity (EOQ) formula,
which dates back to Ford W. Harris (1913). Inventory management is
concerned with matching supply with demand. The problem is to ﬁnd
the amount to be produced or purchased in order to maximize the total
expected proﬁt or minimize the total expected cost.
In the two decades following Harris, several variations of the formula
appeared, mostly in trade journals written by and for inventory man-
agers. These were ﬁrst collected in a full-length book on inventory man-
agement by Raymond (1931). Erlenkotter (1989,1990) has provided a
fascinating account of this early history of inventory management.
Another classic formula in the inventory literature is the newsvendor
formula. It can be attributed to Edgeworth (1888), although it was not
until the work of Arrow, Harris and Marschak (1951) and Dvoretzky,
Kiefer and Wolfowitz (1953) that a systematic study of inventory mod-
els, incorporating uncertainty as well as dynamics, began. These early
papers were followed by the well-known treatise by Arrow, Karlin and
Scarf (1958) as well as the seminal work of Scarf (1960). These works
established the optimality of base-stock and (s, S) policies, the most
well-known policies in dynamic stochastic inventory modeling.
An important assumption in this vast literature has been that the de-
mands in diﬀerent periods are independent and identically distributed
(i.i.d.). In real life, demands may depend on environmental considera-
tions or the states of the world, such as the weather, the state of the
economy, etc. Moreover, these states of the world are represented by
stochastic processes – exogenous or controlled.
In this book, we are concerned with inventory models where these
world states are modeled by Markov processes. We then show that we
obtain the optimality of (s, S)-type policies, or base-stock policies (i.e.,
s = S) when there are no ﬁxed ordering costs with the provision that the
policy parameters s and S depend on the current state of the Markov
process representing the environment. Models allowing backorders when
the entire demand cannot be ﬁlled from the available inventory, as well

xiv
Preface
as those when the current demand is lost, are considered. As for the
cost criterion, we treat both the minimization of the expected total dis-
counted cost and the long-run average cost. The average cost criterion
is mathematically more diﬃcult than the discounted cost criterion. Fi-
nally, we generalize the usual assumptions on holding and shortage costs
and on demands that are made in the literature.
Our research on Markovian demand inventory models was carried out
over a period of ten years, beginning in the early nineties. The research
was supported by the National Science and Engineering Research Coun-
cil of Canada, the Manufacturing Research Corporation of Ontario (a
provincial Center of Excellence), the Laboratory for Manufacturing Re-
search and The Canadian Centre for Marketing Information Technolo-
gies at the University of Toronto, and the University of Texas at Dallas.
The ﬁrst and second authors gratefully acknowledge the support from
Alexander v. Humboldt Foundation and IBM Corporation, respectively.
This research has appeared in several journals, and it is now the sub-
ject of this book.
The models and the results presented in this book could be used in
the analysis of inventory models with forecast updates. This topic is
covered in the book by Sethi et al. (2005a).
Mathematical tools employed in this book involve dynamic program-
ming and stochastic processes. This book is written for students, re-
searchers, and practitioners in the areas of operations management and
industrial engineering. It can also be used by those working in the areas
of operations research and applied mathematics.
We are grateful to Alain Bensoussan, Ganesh Janakiraman, Ernst
Presman, Selda Taskin, Yusen Xia, Xiangtong Qi, Hanqin Zhang, Jun
Zhang, Qing Zhang, Arnab Bisi, and Maqbool Dada for their careful
reading of parts of the manuscript. In addition, we express our appre-
ciation to Barbara Gordon for her assistance in the preparation of the
manuscript.
San Mateo, CA, USA, September, 2009
Dirk Beyer
Washington D.C., USA, September, 2009
Feng Cheng
Richardson, TX, USA, September, 2009
Suresh P. Sethi
Columbia, MO, USA, September, 2009
Michael Taksar

To my wife Michelle and sons Robert and Harry
Dirk Beyer
To my wife Yanyu and son Eric
Feng Cheng
To my wife Andrea
and daughters Chantal and Anjuli
Suresh P. Sethi
To my wife Tanya and son Serge
Michael Taksar

Notation
This book is divided into six parts containing ten chapters 1,2,...,10
and three appendices A, B, and C. Each of the ten chapters in this book
is divided into sections. In any given chapter, say Chapter 8, sections are
numbered consecutively as 8.1, 8.2, 8.3, and so on. Subsections within a
section, say Section 8.4, are numbered 8.4.1, 8.4.2, . . . . Sub-subsections
within a subsection, say Subsection 8.4.2, are numbered consecutively
as 8.4.2.1, 8.4.2.2, . . . . Mathematical expressions within a chapter such
as equations, inequalities, and conditions, are numbered consecutively
as (8.1), (8.2), (8.3), . . . .
Theorems, lemmas, corollaries, deﬁnitions,
remarks, examples, ﬁgures and tables within a chapter are also numbered
consecutively such as Theorem 8.1, Theorem 8.2, Theorem 8.3, . . . .
Each appendix, say Appendix B, has sections numbered consecutively
as B.1, B.2, B.3, . . . . Subsections within a section, say Section B.2, are
numbered consecutively as B.2.1, B.2.2, B.2.3, . . . . Mathematical ex-
pressions within an appendix are also numbered consecutively such as
(B.1), (B.2), (B.3), . . . . Unlike the numbering in the chapters, theorems,
lemmas, corollaries, deﬁnitions, and remarks within a section, say Sec-
tion B.5, are numbered consecutively such as Theorem B.5.1, Theorem
B.5.2, . . . .
The terms “surplus”, “inventory/shortage”, and “inventory/backlog”
are used interchangeably. The terms “control”, “policy”, and “decision”
are used interchangeably.
The order of the appearance of the notation used in this book is
symbols, numerals, capital letters in alphabetical order, lower case letters
in alphabetical order, Greek letters in alphabetical order regardless of
their case, and abbreviations.
□
indicates end of a proof, example, deﬁnition, or remark
:=
is deﬁned to be equal to
=⇒
implies
⟨0, N⟩
= {0, 1, 2, . . . , N}, horizon of the inventory problem
0
(0, . . . , 0), the policy of ordering nothing in every pe-
riod

xviii
Notation
1IA
indicator function of subset A ⊂Ω, i.e., 1IA(ω) = 1 if
ω ∈A and 1IA(ω) = 0, otherwise. Equivalently, A can
refer to a condition and 1IA = 1 if condition A holds
and 1IA = 0, otherwise
B (F)
set of real Borel functions deﬁned on a set F
B0
class of all continuous functions from I × R into R+
and pointwise limits of sequences of these functions
B1
subspace of functions in B0 that are lower semicon-
tinuous and of linear growth
B2
subspace of functions in B1 that are uniformly con-
tinuous in x
Bγ
Banach space of Borel functions b : I × R →R with
the norm ∥b ∥γ= maxi supx |b(i, x)|/(1 + |x|γ) < ∞
C ([0, T])
space of all continuous functions on [0, T]
C1
subspace of functions in B1 that are uniformly con-
tinuous
D
convex subset D ⊂R
E ξ
expectation of a random variable ξ
E(ξ; A)
E(ξ1IA) for any random variable ξ and any set A ⊂Ω
E{ξk|ik = i}
conditional expectation of ξk when ik = i
F1 ∩F2
intersection of sets F1 and F2
F1 ∪F2
union of sets F1 and F2
I
⟨1, L⟩= {1, 2, . . . , L}, ﬁnite collection of possible de-
mand states
Jn(i, x; U)
objective function representing the cost to go under
decision U from period n on, with the initial condi-
tions i and x at n
Jα(i, x; U)
objective function for the inﬁnite horizon problem
with dependence on the discount factor α made ex-
plicit
Ki
n
ﬁxed order cost in period k if ik = i
Lγ
subspace of lower semicontinuous functions in Bγ
Lγ−
class of all lower semicontinuous functions which are
of polynomial growth with power γ or less on (−∞, 0]
R
= (−∞, ∞), the real line
R+
= [0, ∞)
Rn
n-dimensional Euclidean space
S, Si, Sn,i, S∗
order-up-to level; i refers to state i and n refers to
period n,
Sα
i
order-up-to level when the state is i with dependence
on the discount factor α made explicit
U, Uα
U = (u0, u1, . . .), ui ≥0, i = 0, 1, . . ., a history-
dependent or nonanticipative decision

MARKOVIAN DEMAND INVENTORY MODELS
xix
Z
= {0, 1, 2, . . .}
a+
= max{a, 0} for a real number a
a−
= max{−a, 0} for a real number a
[a, b]
set {x|a ≤x ≤b}
[a, b)
set {x|a ≤x < b}, similarly (a, b] and (a, b)
∥b ∥, ∥b ∥γ
norm of b in B1 and Bγ, respectively
¯f(i)
= L
j=1 pijf(j) ≡Ef(i1|i0 = i), if f(·) is a function
on I
fk(i, x)
surplus cost when ik = i and xk = x
g′, g′+, g′−
derivative, right derivative, and left derivative of func-
tion g, respectively
ik
demand state in period k
{ik}
a Markov chain with an (L × L)-transition matrix
P = {pij}
{l}
sequence (l = 1, 2, . . .) or a subsequence of it
⟨n, N⟩
{n, n + 1, . . . , N}
{pij} = P
transition matrix
qk(i, x)
shortage cost in period k when ik = i and xk = x
s, s1, sn,i, s∗
ordering level; i refers to state i and n to period n,
sα
i
ordering level when the state is i with dependence on
the discount factor α made explicit
uk, uα
k, u∗
k
nonnegative order quantity in period k
v, vn, vn,k, . . .
value function
vα
value function for the inﬁnite horizon with depen-
dence on the discount factor α made explicit
w, w∗
potential function
wα
diﬀerential discounted value function
x, z, . . .
all English boldface letters stand for vectors
|x|
absolute value of x
| x |
=

x2
1 + · · · + x2n for a vector x = (x1, . . . , xn)
xk
surplus (inventory/backlog) level at the beginning of
period k
xn →x
xn converges to x
xn ↓x
xn decreases to x
xn ↑x
xn increases to x
α > 0
discount factor
αp
Type 1 service level; 0 < αp ≤1
λ, λ∗
average cost
ξk
demand in period k, ξk ≥0, ξk dependent on ik
σ{k(s) : s≤t}
σ-algebra generated by the process k(·)

xx
Notation
τy
:= min{n :
n
k=0
ξk ≥y} the ﬁrst time the cumulative
demand exceeds y
ϕi,k(·), ϕi(·)
conditional density function of demand ξk when ik = i
Φi,k(·), Φi(·)
conditional distribution functions corresponding to
ϕi,k and ϕi, respectively
(Ω, F, P)
probability space
a.s.
almost surely
EOQ
economic order quantity
i.i.d.
independent and identically distributed
inf
inﬁmum
limx↓0
limit when x approaches 0 from right
limx↑0
limit when x approaches 0 from left
lim inf
limit inferior
lim sup
limit superior
LHS
left-hand side
l.s.c.
lower semicontinuous
max
maximum
MDP
Markov decision process
min
minimum
PF2
P´olya frequency of order 2
RHS
right-hand side
sup
supremum
u.s.c.
upper semicontinuous

Chapter 1
INTRODUCTION
Inventory management is one of the most important tasks in busi-
ness. A business faces inventory problems in its most basic activities.
Inventory is held by the selling party to meet the demand made by
the buying party. The complexity of inventory problems varies signiﬁ-
cantly, depending on the situation. While some of the simple inventory
problems may be dealt with by common sense, some other inventory
problems that arise in complex business processes require sophisticated
mathematical tools and advanced computing power to get a reasonably
good solution.
The fundamental problem in inventory management can be described
by the following two questions: (1) when should an order be placed?
and (2) how much should be ordered? There are two basic trade-oﬀs
in an inventory problem. One is the trade-oﬀbetween setup costs and
inventory holding costs. By placing orders frequently, the size of each
order can be made relatively small. Therefore, the holding costs can
be reduced.
However, the total setup costs will go up.
Conversely,
less frequent orders will save on setup costs but incur higher holding
costs. The other trade-oﬀis between holding costs and stockout costs.
Holding more inventory reduces the likelihood of stockouts, and vice
versa. These trade-oﬀs give rise to an optimization problem of ﬁnding
the optimal ordering policy that minimizes the overall cost.
1.1.
Characteristics of Inventory Systems
The primary purpose of inventory control is to manage inventory to
eﬀectively meet demand. The eﬀectiveness can be measured in many
diﬀerent ways. The most commonly used methods measure how much
the total proﬁt and how little the total cost are. The majority of the
D. Beyer et al., Markovian Demand Inventory Models, International Series
3
in Operations Research & Management Science 108,
DOI 10.1007/978-0-387-71604-6 1, c⃝Springer Science+Business Media, LLC 2010

4
Introduction
operations research literature on inventory management has used the
criterion of cost minimization. In many cases, this criterion is equivalent
to that of proﬁt maximization.
There are many factors that should be taken into consideration when
solving an inventory problem. These factors are usually the characteris-
tics of, or the assumptions made about, the particular inventory system
under consideration. Among them, the most important ones are listed
below.
Cost structure. One of the most important prerequisites for solving
an inventory problem is an appropriate cost structure. A typical cost
structure incorporates the following four types of costs.
Purchase or production cost. This is the cost of buying or pro-
ducing items. The total purchase/production cost is usually ex-
pressed as cost per unit multiplied by the quantity procured or
produced. Sometimes a quantity discount applies if a large num-
ber of units are purchased at one time.
Fixed ordering (or setup) cost. The ﬁxed ordering cost is associ-
ated with ordering a batch of items. The ordering cost does not
depend on the number of items in the batch. It includes costs
of setting up the machine, costs of issuing the purchase order,
transportation costs, receiving costs, etc.
Holding (or carrying) cost. The holding or carrying cost is asso-
ciated with keeping items in inventory for a period of time. This
cost is typically charged as a percentage of dollar value per unit
time. It usually consists of the cost of capital, the cost of storage,
the costs of obsolescence and deterioration, the costs of breakage
and spoilage, etc.
Stockout cost. Stockout cost reﬂects the economic consequences
of unsatisﬁed demand. In cases when unsatisﬁed demands are
backlogged, there are costs for handling backorders as well as costs
associated with loss of customer goodwill on account of negative
eﬀects of backlogs on future customer demands. If the unsatisﬁed
demand is lost, i.e., there is no backlogging, then the stockout cost
will also include the cost of the foregone proﬁt.
Demand. Over time, demand may be constant or variable. Demand
may be known in advance or may be random. Its randomness may
depend on some exogenous factors such as the state of the economy,
the weather condition, etc. Another important factor often ignored
in the inventory literature is that demand can also be inﬂuenced

MARKOVIAN DEMAND INVENTORY MODELS
5
directly or indirectly by the decision maker’s choice. For example, a
promotion decision can have a positive eﬀect on demand.
Leadtime. The leadtime is deﬁned as the amount of time required to
deliver an order after the order is placed. The leadtime can be con-
stant (including zero) or random.
Review time. There are two types of review methods. One is called
continuous review, where the inventory levels are known at all times.
The other is called periodic review, where inventory levels are known
only at discrete points in time.
Excess demand. Excess demand occurs when demand cannot be ﬁlled
fully from the existing inventory. The two common assumptions are
that excess demand is either backordered or lost.
Deteriorating inventory. In many cases, the inventory deteriorates
over time which aﬀects its utility.
For example, food items have
limited shelf lives.
Constraints. There are various constraints involved in inventory prob-
lems. The typical constraints are supplier constraints – restrictions on
order quantities; marketing constraints – minimum customer service
levels; and internal constraints – storage space limitations, limited
budgets, etc.
1.2.
Brief Historical Overview of Inventory
Theory
Inventory control has been a main topic in the operations management
area for over half a century. Many advanced mathematical methods can
be applied to solve inventory control problems. This makes it an inter-
esting topic for researchers from a variety of academic disciplines. The
basic question in any inventory problem is to determine the timing and
the size of a replenishment order. While the fundamental questions in in-
ventory problems remain the same, the focus of one particular inventory
problem may be quite diﬀerent from another.
It is virtually impossible to summarize the enormous literature on
inventory models in this short section. Even with the limitation of fo-
cusing on studies aimed at ﬁnding optimal policies for dynamic inventory
models, it is still a tremendous task to cover all related issues. Diﬀer-
ent features of inventory systems also lead to diﬀerent treatments of the
resulting problems. Silver (1981) has illustrated such a diversity of in-
ventory problems by introducing a classiﬁcation scheme consisting of the
following characteristics of an inventory system.

6
Introduction
Single vs. Multiple Items
Deterministic vs. Probabilistic Demand
Single Period vs. Multiperiod
Stationary vs. Time-Varying Parameters
Nature of the Supply Process
Procurement Cost Structure
Backorders vs. Lost Sales
Shelf Life Considerations
Single vs. Multiple Stocking Points
Among various factors that aﬀect the model characterization, the na-
ture of the demand process is usually the most important one. Assump-
tions about other parameters of an inventory model also have important
implications on the model development. However, these assumptions are
more or less standard and well-accepted in practice.
In this book, we will consider ﬁnite and inﬁnite horizon inventory mod-
els involving a single product, a single stocking point, and a stochastic
demand. We will assume that supply is unconstrained and the product
has an inﬁnite shelf life.
We will allow the system to be with either
stationary or time-varying parameters. Both backorders and lost sales
models will be treated. We will consider zero leadtime. However, the
backlogging models with ﬁxed nonzero leadtimes can be transformed to
ones with no leadtime.
The main distinguishing characteristic of the inventory models studied
in this book is that the demand will be dependent on a Markov process.
The Markov process may be exogenous (i.e., outside our control) or it
may be inﬂuenced by our inventory decisions.
In what follows, we will brieﬂy summarize the relevant literature based
on the assumptions made about the demand process in a single product
setting.
1.2.1
Deterministic Demand Models
The most celebrated model in this category is the economic order
quantity (EOQ) model, which is the simplest and the most fundamental
of all inventory models. It describes the important trade-oﬀbetween the
ﬁxed ordering cost and the holding cost, and is the basis for the analysis
of many more complex systems.
The basic EOQ model is based on the following assumptions.

MARKOVIAN DEMAND INVENTORY MODELS
7
(i) The demand rate is a constant ξ units per unit time.
(ii) Shortages are not permitted.
(iii) The order leadtime is zero.
(iv) The order costs consist of a setup cost K for each ordered batch
and a ﬁxed unit cost c for each unit ordered.
(v) The holding cost is h per unit held per unit time.
The famous EOQ formula is given by
Q∗=

2Kξ
h .
Because of its form, it is also called the square-root formula; (see also
EOQ formula). The formula is due to Harris (1913); (see Erlenkotter
(1989) for a history of the development of this formula).
Some important variations of the EOQ model include planned back-
orders/lost sales, quantity discounts, a known shelf life, a known replen-
ishment leadtime, or constraints on the order size. A fairly comprehen-
sive discussion on these and related topics can be found in Hadley and
Whitin (1963).
Another important work in deterministic demand models is the so-
called dynamic lot size problem, where the demand level changes from
period to period but in a known fashion. Wagner and Whitin (1958)
provide a recursive algorithm for computing the optimal policy. Some
interesting properties of the optimal policy are identiﬁed by them. The
Wagner-Whitin model was republished in a 2004 issue of Management
Science with a commentary by Wagner (2004).
1.2.2
Stochastic Demand Models
The newsvendor formula for the single period inventory problem is
one of the most important results in the stochastic inventory theory;
(see Edgeworth (1888), Arrow et al.(1951)).
Many extensions of the
classical newsvendor model have been studied in the literature. These
allow for random yields, pricing policies, free distributions, etc. A com-
prehensive review of the literature on the newsvendor models can be
found in Khouja (1999), and references therein.
The base-stock policy has been extensively studied in the literature
for single-product periodic review inventory problems with stochastic
demand and no ﬁxed setup cost.
The early academic discussions on
the base-stock policy have focused on proving its optimality under the
situation that the demands are independent. Examples can be found in

8
Introduction
Gaver (1959,1961), Karlin (1958c), Karlin and Scarf (1958), etc. Bellman
et al. (1955) and Karlin (1960) are the classical papers for the stationary
and nonstationary demand cases, respectively.
Optimality of a base-
stock policy has been established in these situations.
For single-item models with probabilistic demand and a ﬁxed ordering
cost, it has been shown that an (s, S) policy is optimal under a variety of
conditions. The policy is to order up to the level S when the inventory
level is below s and to not order otherwise.
In the case of no ﬁxed
ordering cost, the optimal policy becomes a base-stock policy, which is
a special case of the (s, S) policy when s = S.
Classical papers on the optimality of (s, S) policies in dynamic inven-
tory models with stochastic demands and ﬁxed setup costs are those of
Arrow et al.(1951), Dvoretzky et al. (1953), Karlin (1958c), Scarf (1960),
and Veinott (1966). Scarf develops the concept of K-convexity, and uses
it to show that if the ordering cost is linear with a ﬁxed setup cost K
and if the inventory/backlog cost function is convex, then the optimal
ordering policy in any given period for a ﬁnite horizon model is charac-
terized by two critical numbers sn and Sn, with sn ≤Sn, such that if
the inventory level xn at time n is less than sn, then order Sn −xn; if
xn ≥sn, then do not order. That a stationary (s, S) policy is optimal
for the stationary inﬁnite horizon problem is proved by Iglehart (1963a).
Optimality of an (s, S) policy in the lost sales case was proved by Shreve
(1976). Proof in the lost sales case does not extend to the case when the
leadtime is nonzero; (see, e.g., Zipkin (2008b)).
Veinott (1966) presents a model similar to Scarf’s but with a diﬀerent
set of conditions, which neither imply nor are implied by the conditions
used by Scarf (1960). Instead of using the concept of K-convexity, he
proves the optimality of an (s, S) policy by showing that the negative of
the expected cost is a unimodal function of the initial inventory level.
His model also provides a uniﬁed approach for handling both backlogging
and lost sales assumptions, as well as the case of perishable products.
1.2.3
Markovian Demand Models
Most classical inventory models assume demand in each period to
be a random variable independent of environmental factors other than
time. However, many randomly changing environmental factors, such as
ﬂuctuating economic conditions and uncertain market conditions in dif-
ferent stages of a product life cycle, can have a major eﬀect on demand.
For such situations, the Markov chain approach provides a natural and
ﬂexible alternative for modeling the demand process. In such an ap-
proach, environmental factors are represented by the demand state or

MARKOVIAN DEMAND INVENTORY MODELS
9
the state-of-the-world of a Markov process, and demand in a period is a
random variable with a distribution function dependent on the demand
state in that period. Furthermore, the demand state can also aﬀect other
parameters of the inventory system such as the cost functions.
The eﬀect of a randomly changing environment in inventory models
with ﬁxed costs received only limited attention in the early literature. It
is conceivable that when the demands in diﬀerent periods are dependent,
the structure of the optimal policy does not change. The main diﬀerence
is that the parameters of an optimal policy will depend on the demand
state in the previous period.
Iglehart and Karlin (1962) consider the problem with dependent de-
mand and no setup cost. They consider an inventory model with the de-
mand process governed by a discrete-time Markov chain. In each period,
the current value of the state of the chain decides the demand density
for that period. They prove that the optimal policy is a state-dependent
base-stock policy.
Karlin and Fabens (1960) introduce a Markovian demand model in
which demand depends on the state of an underlying Markov chain.
They indicate that given the Markovian demand structure in their model,
it appears reasonable, in the presence of a ﬁxed ordering cost, to pos-
tulate an inventory policy of (s, S)-type with a diﬀerent set of critical
numbers for each demand state. However, due to the complexity of the
analysis, Karlin and Fabens concentrated on optimizing over the class
of ordering policies, with each policy characterized by a single pair of
critical numbers s and S, irrespective of the demand state.
Song and Zipkin (1993) present a continuous-time formulation with
a Markov-modulated Poisson demand and with linear costs of inventory
and backlogging. They show the optimality of a state-dependent (s, S)
policy for the case when there is a ﬁxed ordering cost. An algorithm for
computing optimal policies is also developed using a modiﬁed value iter-
ation approach. Sethi and Cheng (1997) provide a discrete-time version
of the problem with general demand distributions. They show the opti-
mality of a state-dependent (s, S) policy when the demand is modeled
as a Markov-modulated process.
Cheng and Sethi (1999b) extend the results to the case of Markov-
modulated demand with the lost sales assumption for unﬁlled demand.
The optimality of a state-dependent (s, S) policy is proved for this case
only under the condition of zero supply leadtime.
Another notable development in inventory models with Markovian
demand is due to Chen and Song (2001). Their paper considers a multi-
stage serial inventory system with a Markov-modulated demand. Ran-
dom demand arises at Stage 1, Stage 1 orders from Stage 2, etc., and

10
Introduction
Stage N orders from an outside supplier with unlimited stock.
The
demand distribution in each period is determined by the current state
of an exogenous Markov chain. Excess demand is backlogged. Linear
holding costs are incurred at every stage, and linear backorder costs are
incurred at Stage 1.
The ordering costs are also linear.
The objec-
tive is to minimize the long-run average cost in the system. The paper
shows that the optimal policy is an echelon base-stock policy with state-
dependent order-up-to levels. An eﬃcient algorithm is also provided for
determining the optimal base-stock levels. The results can be extended
to serial systems in which there is a ﬁxed ordering cost at stage N and
to assembly systems with linear ordering costs.
1.2.4
Models with Controllable Demands
When marketing tools such as promotions are used to stimulate con-
sumer demand, the coordination between marketing and inventory man-
agement decisions becomes important. While it is clear that an inte-
grated decision-making system should be adopted in order to maximize
total beneﬁts and avoid potential conﬂicts, little theoretical work can be
found in the literature to guide such integrated decision making. Most
works in the inventory theory do not deal with promotion decisions ex-
plicitly. Usually, promotion decisions are taken as given so that the eﬀect
of promotions can be determined in advance of inventory replenishment
decisions. Thus, the inventory/promotion problem reduces to a standard
inventory control problem with demand unaﬀected by the actions of the
decision maker. However, there have been a few papers that address
the issue of joint inventory/promotion decision making. Most of these
focus on inventory control problems in conjunction with price discount
decisions.
Used frequently in the literature, a simpliﬁed approach for modeling
the demand uncertainty is to assume that the random components of de-
mand are either additive or multiplicative; (see Young (1978)). Based on
this assumption, Karlin and Carr (1962), Mills (1962), and Zabel (1970)
obtained similar results. They showed that the optimal price is greater
than the riskless price in the multiplicative case and is less than the risk-
less price in the additive case. Furthermore, Thowsen (1975) showed that
if the demand uncertainty is additive, the probability density function
of the additive uncertainty is PF2, and if the expected demand function
is linear, then the optimal policy is a base-stock list price policy. If the
initial inventory level is below the base-stock level, then that stock level
is replenished and the list price is charged; if the initial inventory level is
above the base-stock level, then nothing is ordered and a price discount
is oﬀered.

MARKOVIAN DEMAND INVENTORY MODELS
11
A dynamic inventory model with partially controlled additive demand
is analyzed by Balcer (1983), who presents a joint inventory control and
advertising strategy and shows it to be optimal under certain restric-
tions. However, in the Balcer model, the demand/advertising relation-
ship is deterministic because only the deterministic component of de-
mand is inﬂuenced by advertising decisions.
Cheng and Sethi (1999a) extend the result of Markov-modulated
demand models by introducing promotional decisions by which demand
is aﬀected. For the case of no ﬁxed ordering cost, they show that a state-
dependent base-stock policy is optimal. Chen and Simchi-Levi (2004)
analyze a single-product, periodic-review model in which pricing and
production/inventory decisions are made simultaneously.
They show
that when the demand model is additive, the proﬁt-to-go functions are
K-concave; hence, an (s, S, p) policy is optimal. In such a policy, the
inventory is managed using an (s, S) policy, and price is determined
based on the inventory position at the beginning of each period.
1.2.5
Other Extensions
Beside diﬀerent treatments for modeling the demand process, exten-
sions intended to relax other restrictive assumptions on inventory mod-
els or to incorporate certain special features into inventory models have
also been studied by researchers. A great deal of eﬀort has been made
to adopt a more general cost function rather than the linear cost with a
setup cost. An interesting case of such a general cost function is that of
concave increasing cost. Porteus (1971) shows a generalized (s, S)-type
policy to be optimal when the ordering cost is concave and increasing,
given an additional assumption that the demand density function is a
P´olya frequency function.
Other extensions for single-product inventory models include incor-
porating more realistic features of the physical inventory systems, such
as capacity constraints, service level constraints, and supply constraints.
Veinott (1965) considers a model where orders must be placed in mul-
tiples of some ﬁxed batch size Q. It is shown that an optimal policy
is characterized by Q and a number k as follows. If the initial inven-
tory position is less than k, one orders the smallest multiple of Q, which
brings the inventory position to at least k; otherwise, no order is placed.
Among the recent research trends in the analysis of dynamic inventory
systems, one particular issue is to model the eﬀect of more ﬂexible pro-
curement options such as multiple delivery modes in connection with the
demand forecast updates available over time. Sethi et al. (2003) present
an inventory model with ﬁxed costs, forecast updates, and two delivery

12
Introduction
modes, with a forecast-update-dependent (s, S)-type policy shown to be
optimal. This and related models are also the subject of the book by
Sethi et al. (2005a).
Recently, Bensoussan et al.
(2007a,2008a) have considered Marko-
vian demand models with partially observed demands. In these models,
called the censored newsvendor models, only sales are observed when
the demand exceeds the inventory level. In other models, the informa-
tion regarding the inventory is incomplete; (see, e.g., Bensoussan et al.
(2005a,2007b,2008b)) .
There are several other related works extending the classical inventory
models in various ways. We do not intend to provide a complete list of
all relevant work in this fairly broad and active research area. Instead,
we have chosen to survey only those that are related to the topic of this
book either from a historical point of view or because similar modeling
issues are also addressed in the book.
1.2.6
Computational Methods
Following the theoretical work on establishing the optimal control
policies under various conditions, numerical procedures for computing
optimal policies have also been developed. Although the structure of
(s, S) policies is fairly simple, the computation of an (s, S) policy turns
out to be diﬃcult. Traditionally, two main approaches were explored in
computing the actual (s, S) values. The ﬁrst is based on the dynamic
programming formulation of the problem. The second approach, known
as stationary analysis, involves the determination of the limiting dis-
tribution of the inventory position under an (s, S) policy. Using this
distribution, an expected cost function is constructed with s and S as
decision variables; (see, e.g., Veinott and Wagner (1965)). Minimization
of this function determines the optimal (s, S) policy. A computationally
more eﬃcient approach is the one developed by Zheng and Federgruen
(1991).
The literature reviewed here is intended to provide the readers with
a basic idea about which models are relevant to this book. How models
presented in diﬀerent chapters of this book relate to the literature will
be discussed in those chapters.
1.3.
Examples of Markovian Demand Models
The classical and best known stochastic inventory models assume the
demand in diﬀerent time periods to be independent and often even iden-
tically distributed.
Nonetheless, demand forecasters have known all
along that the demand over time for most products does not form a

MARKOVIAN DEMAND INVENTORY MODELS
13
sequence of independent random variables. Most forecasting techniques
either rely on trends and autocorrelation in the sequence of demands
or on the fact that future demands are correlated to some observable
early indicator.
A speciﬁc structure of a Markov-modulated demand
process is used in this book in an attempt to formalize these dependen-
cies and allow for them when making inventory decisions. Below are a
few examples of such indicators and demand processes consistent with
our models.
The inﬂuence of weather on the demands for many products is one
of the ﬁrst things that come to mind. The demand for home-heating
oil in winter depends heavily on the temperature outside. Likewise, the
demand for electricity in summer increases as the temperatures rise and
vice versa. Diﬀerent temperature ranges can be thought of as diﬀerent
states of the world determining the probability distribution of demand.
Once the temperature is known, the demand is still uncertain but two
things have changed; ﬁrst, knowing the ambient temperature, demand
can likely be predicted more accurately, and therefore the demand distri-
bution will have lower variance. Second, since temperatures in adjacent
time periods are correlated, those correlations can be exploited to pre-
dict future temperatures and demands. The transition matrices of the
temperatures in a geographic area can be estimated from the historical
weather data. Also note that these matrices could be nonstationary over
time, i.e., they may be diﬀerent in diﬀerent months. For more weather
related examples, the demand for insecticides in an area may be posi-
tively correlated to the amount of total rainfall in the preceding week.
A good indicator for gasoline demand at gas stations along stretches of
highway I-80 would be the weather forecast for the Lake Tahoe region.
Here, the demand could be a high-level categorization of the forecast;
for example, pleasant, mediocre, or unpleasant.
When it comes to estimating the demand for consumable materials
like ink or toner cartridges for a speciﬁc type of printer, it is obvious
that the number of such printers currently in use, often referred to as
the installed base, is an important piece of information. Therefore, the
sales volume combined with data about typical usage patterns of the
products requiring the same consumables can be used to provide the
state information of the demand. The transition matrix of demand states
can also be estimated based on the projected life spans of the relevant
products. Similarly, in the case of demand for spare parts, the number
of installed units (for example, servers) in a given age range should be
a good choice to use as the demand state, since the failure rate of each
of the items is usually related to its age.

14
Introduction
Demand for replacement units under warranty also exhibits a similar
pattern that is directly associated with the number of new units (for
example, a speciﬁc model of a digital camera or a mainframe computer)
sold recently. Many electronic devices show high “infant mortality.” A
large number of those that fail are either defective on arrival or fail
shortly after being put to use.
For these reasons, the number of re-
placement units requested under warranty is positively correlated to the
recent sales volume of the product, a reasonable choice for the demand
state.
The product life cycle is another important indicator for product de-
mand. Typically, sales volume starts low in the introductory stage, in-
creases signiﬁcantly in the growth stage, reaches the peak in the mature
stage, and then falls in the decline stage. It is a natural and realistic
way to model the transitions of a product life cycle from one stage to
the next as a Markov chain.
In the setting of competitive market environment, the introduction
of a competing product into the market can be modeled as a Markov
process with the state variable representing the number of competing
products. A product may initially be the market leader when there are
no competitive products at the time of its introduction. However, its
market share is likely to diminish as competitive products are introduced
over time.
In the IT industry, the introduction of new software is often a catalyst
for hardware demand. For example, demand for memory upgrades on
notebook computers will be higher after the introduction of a new ver-
sion of software such as a new version of Microsoft Windows operating
system. In this case, the introduction of the new Windows operating
system can be used as the demand state when a Markovian model is
adopted for modeling the demand of an aﬀected hardware product.
Seasonality is a common factor that aﬀects product demand.
For
example, the demand for many consumer electronics products like note-
book computers or inkjet printers exhibits strong seasonal patterns. De-
mand for these products is the highest during “back to school” season
(August, September) and the holiday season (November, December).
During the remainder of the year, the monthly demand is lower and
more stable. Seasonal demand is also typical in commercial sales. It is
well known that IT related purchases and capital investments (servers,
large laser printers, storage devices, etc.)
follow a so-called “hockey
stick” curve. Demand tends to be highly skewed towards the end of a
month or a calendar quarter. This is thought to be the result of the
spend-it-or-loose-it regime of corporate budgeting, as well as the struc-
ture of sales incentives. This seasonality of demand can be captured by a

MARKOVIAN DEMAND INVENTORY MODELS
15
degenerate form of a Markov chain with the transition from one state to
the next being deterministic (or almost deterministic). See Section 2.7
of Chapter 2 for further discussion on this type of model.
The examples given above illustrate that Markovian demand models
can capture the relationship between the demand and the associated en-
vironmental factors. Certainly, these models are more realistic and more
ﬂexible representations of the demand process than i.i.d. demand mod-
els or nonstationary independent demand models. On the other hand,
the inventory models allowing for Markovian demands are more complex
than the classical inventory models especially in terms of data and com-
putational requirements. However, inventory decisions have tremendous
business consequences in terms of cost as well as customer satisfaction.
Because of this, the additional eﬀort required to use these models will
easily be justiﬁed in many cases by the value of improved decisions re-
sulting from them.
1.4.
Contributions
One of the most important developments in the inventory theory has
been to show that (s, S) policies (with base-stock policy as a special
case) are optimal for a class of dynamic inventory models with random
periodic demands and ﬁxed ordering costs.
Dynamic inventory models can be formulated in a continuous-time
setting or a discrete-time setting. The models presented in this book are
of the latter type.
The main contribution of the book is to generalize a class of inven-
tory models (with ﬁxed ordering costs) to allow for demands that de-
pend on an exogenous Markov process or a controlled Markov process,
and to show that the optimal policies are of (s, S)-type. In our mod-
els, the distribution of demands in successive periods is dependent on a
Markov chain. Special cases of such Markovian demand models include
the case of cyclic or seasonal demand. Finite horizon, as well as station-
ary and nonstationary inﬁnite horizon, problems are considered. Some
constraints commonly encountered in practice, namely no-ordering pe-
riods, ﬁnite storage capacities, and service levels, are also treated. We
show that (s, S)-type policies are also optimal for the generalized models
as well as their extensions.
We provide rigorous analyses under various modeling assumptions:
discounted cost models with backlog or lost sales assumptions, aver-
age cost models (also with backlog or lost sales assumptions), models
with demand controlled by a Markov decision process (MDP), and mod-

16
Introduction
els with cost functions of polynomial growth. Required results on the
existence of optimal solutions, as well as veriﬁcation theorems, are es-
tablished for the cases studied.
1.5.
Plan of the Book
This book consists of six parts. Part I (consisting of just Chapter 1)
is an introduction to the book. Part II (Chapters 2-4) covers the models
with the discounted cost criterion. The models with the average cost
criterion are presented in Part III (Chapters 5-7). Part IV (Chapters 8
and 9) collects miscellaneous results that are not covered in the previous
chapters. The concluding remarks are discussed in Part V. Appendices
are included in Part VI.
Part II starts with Chapter 2, where a discounted cost model with the
full backlog assumption is introduced. The model is a generalization of
classical inventory models with ﬁxed costs that exhibit (s, S) policies.
We model the demand process in a way that the demand distributions
in successive periods depend upon the state of an underlying Markov
chain. A dynamic programming formulation is used to provide the re-
sults on the uniqueness of the solution and the existence of an optimal
feedback policy. Also described in the chapter are some new properties
of K-convex functions, which provide the technical results needed for
the analysis in the rest of the chapter. The optimality of an (s, S)-type
policy is ﬁrst shown in a ﬁnite horizon model, with s and S dependent
on the demand state of the current time period and on the time remain-
ing. This result is extended to a nonstationary inﬁnite horizon version
of the model. Extensions with more realistic modeling assumptions are
also presented in this chapter.
Chapter 3 treats the discounted inﬁnite horizon inventory model in-
volving ﬁxed cost in Chapter 2 to allow for unbounded demand and
costs with polynomial growth. Finite horizon problems, as well as sta-
tionary and nonstationary discounted cost inﬁnite horizon problems, are
addressed. Existence of optimal Markov or feedback policies is estab-
lished with unbounded Markovian demand, ordering costs that are l.s.c.,
and inventory/backlog (or surplus) costs that are l.s.c. with polynomial
growth.
Furthermore, optimality of state-dependent (s, S) policies is
proved when the ordering cost consists of ﬁxed and proportional cost
components and the surplus cost is convex.
Chapter 4 extends the results developed in Chapter 2 to the lost sales
case, where demand that is not satisﬁed on time is lost. The lost sales
case is typically more diﬃcult to analyze than its backlog counterpart.
Generally it requires a diﬀerent treatment and sometimes additional

MARKOVIAN DEMAND INVENTORY MODELS
17
assumptions to establish the same type of results as in the backlog case.
A new K-convexity result associated with the cost functions in the lost
sales case is presented in this chapter.
Based on this new result, we
are able to show that a state-dependent (s, S) policy is optimal for the
Markovian demand inventory models with the lost sales assumption in
both ﬁnite horizon and inﬁnite horizon formulations. Extensions that
incorporate various realistic features and constraints are also developed
in the chapter.
Part III, consisting of Chapters 5, 6 and 7, analyzes the average cost
models.
Chapter 5 deals with a long-run average cost version of the
Markovian demand model treated in Chapter 2 with the backlog as-
sumption, ﬁxed ordering cost, and convex inventory cost. We develop
a vanishing discount approach to establish the average cost optimality
equation and provide the associated veriﬁcation theorem to show that a
state-dependent (s, S) policy is optimal for the average cost model.
Chapter 6 is devoted to studying the long-run average cost version of
the model presented in Chapter 3 with unbounded Markovian demands,
ordering cost that are l.s.c., and inventory costs that are l.s.c. and of
polynomial growth.
Finite horizon problems and stationary long-run
average cost problems are addressed.
Chapter 7 provides an analysis of the lost sales version of the problem
described in Chapter 5.
Similar to the approach used in Chapter 5,
we examine the asymptotic behavior of the diﬀerential discounted value
function as the discount rate approaches zero. Then, we establish the
average cost optimality equation using the vanishing discount approach.
Also included is the proof of the veriﬁcation theorem as well as the
optimality proof for a state-dependent (s, S) policy in this setting.
In Part IV, two additional topics that are not covered by the previous
chapters are discussed. In Chapter 8, we present a MDP based model
for a joint inventory/promotion decision problem. The state variable
of the MDP represents the demand state brought about by changing
environmental factors as well as promotion decisions.
We show that
the optimal joint inventory/promotion decision can be characterized by
policy of a simple form under certain conditions, where the promotion
decision follows a threshold policy and the inventory decision follows a
base-stock policy, with both policies dependent on the demand state.
Chapter 9 revisits the classical papers of Iglehart (1963b) and Veinott
and Wagner (1965) devoted to stochastic inventory problems with the
criterion of long-run average cost minimization. We indicate some of
the assumptions that are implicitly used without veriﬁcation in their
stationary distribution approach to the problems, and provide the miss-
ing (nontrivial) veriﬁcation. In addition to completing their analysis, we

18
Introduction
examine the relationship between the stationary distribution approach
and the dynamic programming approach to the average cost stochastic
inventory problems.
We conclude the book with Part V consisting of Chapter 10, where
conclusions and open research problems are described.
Part VI consists of Appendices. These Appendices provide some back-
ground material as well as the technical results that are used in the book.
The relationships between diﬀerent chapters are shown in Figure 1.1.
Chapter 1
Introduction
Chapter 9
Average cost
Backorder
Unbounded demand
Linear growth
i.i.d. demand
Chapter 4
Chapter 2
Discounted cost
Lost sales
Unbounded demand
Linear growth
Discounted cost
Backorder
Unbounded demand
Linear growth
Chapter 5C
ha
C
pter 3
Average cost
Backorder
Bounded demand
Linear growth
Discounted cost
Backorder
Unbounded demand
Polynomial growth
Chapter 8
Discounted cost
Backorder
Unbounded demand
Linear growth
Dependent state transform
Chapter 7
Discounted cost
Lost sales
Unbounded demand
Linear growth
Chapter 6
Average cost
Backorder
Unbounded demand
Polynomial growth
Chapter 10
Conclusion
Figure 1.1.
Relationships between diﬀerent chapters.
An extensive bibliography, author index, subject index, and the copy-
right permissions follow the Appendices.

Chapter 2
DISCOUNTED COST MODELS
WITH BACKORDERS
2.1.
Introduction
One of the most important developments in the inventory theory has
been to show that (s, S) policies are optimal for a class of dynamic in-
ventory models with random periodic demands and ﬁxed ordering costs.
Under an (s, S) policy, if the inventory level at the beginning of a pe-
riod is less than the reorder point s, then a suﬃcient quantity must be
ordered to achieve an inventory level S, the order-up-to level, upon re-
plenishment. There are a number of papers in the literature devoted to
proving the optimality of (s, S) policies under a variety of assumptions.
However, in real-life inventory problems, some of these assumptions do
not hold. It is our purpose to relax these assumptions toward realism
and still demonstrate the optimality of (s, S)-type policies.
The nature of the demand process is an important assumption in
stochastic inventory models.
With possible exceptions of Karlin and
Fabens (1960) and Iglehart and Karlin (1962), classical inventory mod-
els have assumed demand in each period to be a random variable inde-
pendent of demands in other periods and of environmental factors other
than time. However, as elaborated in Song and Zipkin (1993), many
randomly changing environmental factors, such as ﬂuctuating economic
conditions and uncertain market conditions in diﬀerent stages of a prod-
uct life cycle, can have a major eﬀect on demand. For such situations,
the Markov chain approach provides a natural and ﬂexible alternative
for modeling the demand process. In such an approach, environmental
factors are represented by the demand state or the state-of-the-world of
a Markov process, and demand in a period is a random variable with
its distribution function dependent on the demand state in that period.
D. Beyer et al., Markovian Demand Inventory Models, International Series
21
in Operations Research & Management Science 108,
DOI 10.1007/978-0-387-71604-6 2, c⃝Springer Science+Business Media, LLC 2010

22
Discounted Cost Models with Backorders
Furthermore, the demand state can also aﬀect other parameters of the
inventory system such as the cost functions.
Another feature that is not usually treated in the classical inventory
models, but is often observed in real life is the presence of various con-
straints on ordering decisions and inventory levels. For example, there
may be periods, such as weekends and holidays, during which deliveries
cannot take place. Also, the maximum inventory that can be accommo-
dated is often limited by a ﬁnite storage space. On the other hand, one
may wish to keep the amount of inventory above a certain level to reduce
the chance of a stockout, and ensure satisfactory service to customers.
While some of these features are dealt with in the literature in a
piecemeal fashion, we will formulate a suﬃciently general model that
has models with one or more of these features as special cases and still
retain the optimal policy to be of (s, S)-type. Thus, our model considers
more general demands, costs, and constraints than most of the ﬁxed cost
inventory models in the literature.
The plan of this chapter is as follows. The next section contains a
review of relevant models and how our model relates to them. In Sec-
tion 2.3, we develop a general ﬁnite horizon inventory model with a
Markovian demand process. In Section 2.4, we state the dynamic pro-
gramming equations for the problem and the results on the uniqueness of
the solution and the existence of an optimal feedback or Markov policy.
In Section 2.5, we use some properties of K-convex functions, derived
in Appendix C, to show that the optimal policy for the ﬁnite horizon
model under consideration is still of (s, S)-type, with the policy param-
eters s and S dependent on the demand state and the time remaining.
The nonstationary inﬁnite horizon version of the model is examined in
Section 2.6.
The cyclic demand case is treated in Section 2.7.
The
analysis of models incorporating no-ordering periods and those with the
shelf capacity and service level constraints is presented in Section 2.8.
Section 2.9 concludes the chapter.
2.2.
Review of the Related Literature
Classical papers on the optimality of (s, S) policies in dynamic in-
ventory models with stochastic demands and ﬁxed setup costs include
those of Arrow et al.(1951), Dvoretzky et al. (1953), Karlin (1958a),
Scarf (1960), Iglehart (1963b), and Veinott (1966). Scarf develops the
concept of K-convexity and uses it to show that (s, S) policies are opti-
mal for ﬁnite horizon inventory problems with ﬁxed ordering costs. That

MARKOVIAN DEMAND INVENTORY MODELS
23
a stationary (s, S) policy is optimal for the stationary inﬁnite horizon
problem is proved by Iglehart (1963b). Furthermore, Bensoussan et al.
(1983) provide a rigorous formulation of the problem with nonstationary
but stochastically independent demand. They also deal with the issue
of the existence of optimal feedback policies, along with a proof of the
optimality of an (s, S)-type policy in the nonstationary ﬁnite, as well as
inﬁnite horizon cases.
The eﬀect of a randomly changing environment in inventory models
with ﬁxed costs received only limited attention in the early literature.
Karlin and Fabens (1960) have introduced a Markovian demand model
similar to ours. They indicate that given the Markovian demand struc-
ture in their model, it appears reasonable to postulate an inventory
policy of (s, S)-type with a diﬀerent set of critical numbers for each
demand state. But they consider the analysis to be complex, and con-
centrate instead on optimizing only over the restricted class of ordering
policies, each characterized by a single pair of critical numbers, s and S,
irrespective of the demand state.
Song and Zipkin (1993) present a continuous-time, discrete-state for-
mulation with a Markov-modulated Poisson demand and with linear
costs of inventory and backlogging. They show the optimality of a state-
dependent (s, S) policy when the ordering cost consists of both a ﬁxed
cost and a linear variable cost. An algorithm for computing the optimal
policy is also developed using a modiﬁed value iteration approach.
The basic model presented in the next section extends the classical
Karlin and Fabens model in two signiﬁcant ways. It generalizes the cost
functions that are involved and it optimizes over the natural class of
all history-dependent ordering policies.
In relation to Song and Zip-
kin (1993), we consider more general demands (see Remark 2.3) and
state-dependent convex inventory/backlog costs without a standard as-
sumption made in the literature on backlog and purchase costs; (see Re-
marks 2.2 and 2.1). The nonstationary inﬁnite horizon model extends
Bensoussan et al. (1983) to allow for Markovian demands and more gen-
eral asymptotic behavior on the shortage cost as the shortage becomes
large; (see Remark 2.1).
2.3.
Formulation of the Model
Let us consider an inventory problem over a ﬁnite number of periods
⟨n, N⟩= {n, n + 1, . . . , N} and an initial inventory of x units at the
beginning of period n, where n and N are any given integers satisfy-
ing 0 ≤n ≤N < ∞. The demand in each period is assumed to be
a random variable deﬁned on a given probability space (Ω, F, P) and

24
Discounted Cost Models with Backorders
not necessarily identically distributed.
More speciﬁcally, the demand
distributions in successive periods are deﬁned as below.
Consider a ﬁnite collection of demand states I = {1, 2, . . . , L}, and let
ik denote the demand state in period k. We assume that ik, k ∈[n, N],
with known initial demand state in is a Markov chain over I with the
transition matrix P = {pij}. Thus,
0 ≤pij ≤1, i ∈I, j ∈I, and
L

j=1
pij = 1, i ∈I.
Let a nonnegative random variable ξk denote the demand in a given
period k, k = 0, . . . , N−1. Demand ξk depends only on period k and the
demand state in that period, by which we mean that it is independent
of past demand states and past demands.
We denote its cumulative
probability distribution by Φi,k(x), when the demand state ik = i. In
the following period, if the state changes to state j, which happens with
probability pij, then the demand distribution is Φj,k+1 in that period.
We further assume that for a positive constant D,
E(ξk|ik = i) =
∞

0
xdΦi,k(x) ≤D < ∞, k = 0, . . . , N −1, i ∈I.
(2.1)
This is not a very restrictive assumption from an applied perspective.
We denote by
Fk
l , the σ-algebra generated by
{il, . . . , ik−1, ik; ξl, . . . , ξk−1},
0 ≤l ≤k ≤N,
Fk = Fk
0 .
(2.2)
Since ik, k = 1, . . . , N, is a Markov chain and ξk depends only on ik, we
have
E(ξk|Fk)
=
E(ξk|i0, i1, . . . , ik; ξ0, ξ1, . . . , ξk−1)
=
E(ξk|ik).
(2.3)
An admissible decision (ordering quantities) for the problem on the
interval [n, N] with initial state in = i can be denoted as
U = (un, . . . , uN−1),
(2.4)
where uk is a nonnegative Fk
n-measurable random variable. In simpler
terms, this means that decision uk depends only on the past informa-
tion. Note that since in is known in period n, Fn
n = (Ω, ∅), and hence

MARKOVIAN DEMAND INVENTORY MODELS
25
0
1
period 0
k
k + 1
k + 2
period k
period k+1
ik
xk
yk
uk
ξk
ik+1
xk+1
N −1
N
period N −1
Figure 2.1.
Temporal conventions used for the discrete-time inventory problem.
un is deterministic. Moreover, it should be emphasized that this class
of admissible decisions is larger than the class of admissible feedback
policies. Let us also denote a policy of not ordering anything at all as
0 = (0, . . . , 0).
Ordering quantities are decided upon at the beginning of each period.
Demand in each period is supposed to occur at the end of the period after
the order has been delivered; (see Figure 2.1 for the temporal conventions
used). Unsatisﬁed demand is carried forward as backlog. The inventory
balance equations are deﬁned by
⎧
⎪
⎪
⎨
⎪
⎪
⎩
xk+1 = xk + uk −ξk, k = n, . . . , N −1,
xn = x, initial inventory level,
ik, k = n, . . . , N, Markov chain with transition matrix P,
in = i, initial state,
where xk is the surplus level at the beginning of period k, uk is the
quantity ordered at the beginning of period k, ik is the demand state in
period k, and ξk is the demand in period k. Note that xk > 0 represents
an inventory of xk and xk < 0 represents a backlog (or shortage) of −xk.
Also, the initial state i and the initial inventory level x are assumed to
be arbitrarily given.
Furthermore, we specify the relevant costs and the assumptions they
satisfy.
(i) The purchase or production cost is expressed as
ck(i, u) = Ki
k1Iu>0 + ci
ku,
k ∈⟨0, N −1⟩,
(2.5)
where the ﬁxed ordering costs are Ki
k ≥0, the variable costs are
ci
k ≥0, and 1Iu>0 equals 1 when u > 0 and equals 0 when u ≤0.

26
Discounted Cost Models with Backorders
(ii) The surplus (or inventory/backlog) cost functions fk(i, ·) are con-
vex, and they are asymptotically linear, i.e.,
fk(i, x) ≤C(1 + |x|)
for some C > 0,
k ∈⟨0, N⟩.
(2.6)
The objective function to be minimized is the expected value of all
the costs incurred during the interval ⟨n, N⟩with in = i and xn = x,
i.e.,
Jn(i, x; U) = E

N−1

k=n
[ck(ik, uk) + fk(ik, xk)] + fN(iN, xN)

,
(2.7)
where U = (un, . . . , uN−1) is a history-dependent or nonanticipative ad-
missible decision (order quantities) for the problem and uN = 0. The
inventory balance equations are given by
xk+1 = xk + uk −ξk, k ∈⟨n, N −1⟩.
(2.8)
Finally, we deﬁne the value function for the problem over ⟨n, N⟩with
in = i and xn = x to be
vn(i, x) = inf
U∈U Jn(i, x; U),
(2.9)
where U denotes the class of all admissible decisions.
Note that the
existence of an optimal policy is not required to deﬁne the value function.
Of course, once the existence is established, the “inf” in (2.9) can be
replaced by “min”.
2.4.
Dynamic Programming and Optimal
Feedback Policy
In this section we develop the dynamic programming equations sat-
isﬁed by the value function.
We then provide a veriﬁcation theorem
(Theorem 2.2), which states that the cost associated with the feedback
or Markov policy obtained from the solution of the dynamic program-
ming equations, equals the value function of the problem on ⟨0, N⟩.
Let B0 denote the class of all continuous functions from I × R into
R+ and the pointwise limits of sequences of these functions; (see Feller
(1971)). Note that it includes piecewise-continuous functions. Let B1
be the space of functions in B0 that are of linear growth, i.e., for any
b ∈B1, 0 ≤b(i, x) ≤Cb(1+|x|) for some Cb > 0. Let C1 be the subspace

MARKOVIAN DEMAND INVENTORY MODELS
27
of functions in B1 that are uniformly continuous with respect to x ∈R.
For any b ∈B1, we deﬁne the norm
∥b ∥= max
i
sup
x
b(i, x)
1 + |x|
and the operator
Fk+1b(i, y)
=
E[b(ik+1, y −ξk)|ik = i]
=
L

j=1
{P(ik+1 = j|ik = i)E[b(j, y −ξk)|ik = i]}
=
L

j=1
pij
 ∞
0
b(j, y −ξ)dΦi,k(ξ).
(2.10)
In addition to Assumptions (i) and (ii) on costs, we also require that
for k = 0, 1, . . . , N −1,
ci
kx + Fk+1(fk+1)(i, x) →+∞as x →∞.
(2.11)
Remark 2.1 Condition (2.11) means that either the unit ordering cost
ci
k > 0 or the expected holding cost Fk+1(fk+1)(i, x) →+∞as x →∞,
or both. Condition (2.11) is borne out of practical considerations and
is not very restrictive. In addition, it rules out such unrealistic trivial
cases as the one with ci
k = 0 and fk(i, x) = 0, x ≥0, for each i and k,
which implies ordering an inﬁnite amount whenever an order is placed.
The condition generalizes the usual assumptions made by Scarf (1960)
and others that the unit inventory carrying cost h > 0. Furthermore,
because of an essential asymmetry between the inventory side and the
backlog side we need not impose a condition like (2.11) on the backlog
side assumed in Bensoussan et al. (1983) and Bertsekas (1976). Whereas
we can order any number of units to decrease backlog or build inventory,
it is not possible to sell anything more than the demand in order to
decrease inventory or increase backlog.
If it were possible, then the
condition like (2.11) as x →−∞would be needed to make backlog more
expensive than the revenue obtained by sale of units, asymptotically.
In the special case of stationary linear backlog costs, this would imply
p > c (or p > αc if costs are discounted at the rate α, 0 < α ≤1), where
p is the unit backlog cost. But since sales in excess of demand are not
allowed, we are able to dispense with the condition like (2.11) on the
backlog side or the standard assumption p > c (or p > αc) as in Scarf
(1960) and others, or the strong assumption p > αci for each i as in
Song and Zipkin (1993).

28
Discounted Cost Models with Backorders
Using the principle of optimality, we can write the following dynamic
programming equations for the value function
⎧
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎩
vn(i, x)
=
fn(i, x) + inf
u≥0 {cn(i, u)
+ E[vn+1(in+1, x + u −ξn)|in = i]}
=
fn(i, x) + inf
u≥0 {cn(i, u) + Fn+1(vn+1)(i, x + u)} ,
n ∈⟨0, N −1⟩,
vN(i, x)
=
fN(i, x).
(2.12)
The next two theorems are fundamental. Together, they prove that
(i) the dynamic programming equations have a solution in an appro-
priate space, (ii) the inﬁma in these equations are attained, (iii) these
inﬁma provide an optimal feedback control within the class of admissi-
ble controls, and (iv) the solution of the equations is the value function.
Theorem 2.1 proves (i) and (ii). Theorem 2.2 takes the solution of the dy-
namic programming equations and the inﬁma obtained in Theorem 2.1
and goes on to prove (iii) and (iv). Its proof uses the property (vii)
of conditional expectations given in Appendix B.2. Note, furthermore,
that from (iv) it follows that the solution of the dynamic programming
equations is unique in the deﬁned space.
Theorem 2.1 The dynamic programming equations (2.12) deﬁne a se-
quence of functions in C1. Moreover, there exists a function ˆun(i, x) in
B0, which provides the inﬁmum in (2.12) for any x.
Proof. We proceed by induction. By Assumption (ii) on the function fN
and Theorems C.2.1 and A.1.3, vN is in C1. Now, assume that vn+1(i, x)
belongs to C1 for n < N. Consider points x such that |x| ≤M. It follows
from (2.12) that vn(i, x) ≥fn(i, x) for all n, i, and x. Let
BM
n,i = max
|x|≤M{cn(i, 0) + Fn+1(vn+1)(i, x)}.
We know that BM
n,i < ∞because vn+1 ∈C1. Let y = x + u. Then, we
have
cn(i, u) + Fn+1(vn+1)(i, x + u) ≥Ki
n + ci
n(y −x) + Fn+1(fn+1)(i, y)
≥Ki
n −ci
nM + ci
ny + Fn+1(fn+1)(i, y).
Because of (2.11), there is a constant ¯uM
n,i such that for all y > ¯uM
n,i −M,
we have
ci
ny + Fn+1(fn+1)(i, y) > BM
n,i + ci
nM −Ki
n.

MARKOVIAN DEMAND INVENTORY MODELS
29
Since y > ¯uM
n,i −M is implied by u > ¯uM
n,i, we have for all u > ¯uM
n,i,
cn(i, u) + Fn+1(vn+1)(i, x + u) > BM
n,i ≥cn(i, 0) + Fn+1(vn+1)(i, x).
Consequently, any u > ¯uM
n,i cannot be the inﬁmum in (2.12). Therefore
in (2.12), we can restrict u by the constraint 0 ≤u ≤¯uM
n,i for all the
points x satisfying |x| ≤M, without loss of optimality.
Since the function
ψn(i, x; u) = cn(i, u) + Fn+1(vn+1)(i, x + u)
is l.s.c. and bounded from below, its minimum over a compact set is
attained. Moreover, from the Selection Theorem A.1.7, we know that
there exists a Borel function ˆuM
n (i, x) such that
ψn(i, x; ˆuM
n (i, x)) =
inf
0≤u≤¯uM
n,i
ψn(i, x; u), ∀x.
With the deﬁnition
ˆun(i, x) = ˆuM
n (i, x) for M −1 < |x| ≤M,
we obtain a Borel function such that
ψn(i, x, ˆun(i, x)) = inf
u≥0 ψn(i, x, u), ∀x.
Now for |x1 −x2| ≤δ, we have
|ψn(i, x1, u) −ψn(i, x2, u)|
=
|Fn+1(vn+1)(i, x1 + u) −Fn+1(vn+1)(i, x2 + u)|
≤
L

j=1
pij
sup
|x1−x2|≤δ
|vn+1(j, x1) −vn+1(j, x2)|,
from which together with (2.5), (2.6) and (2.12), it follows easily that
vn(i, x) is uniformly continuous in x. Since
inf
u≥0 ψn(i, x, u) ≤cn(i, 0)+ ∥Fn+1 ∥∥vn+1 ∥(1 + |x|),
we can use (2.12) and (2.6) to conclude that vn(i, x) ∈C1.
□
To solve the problem of minimizing J0(i, x; U), we use ˆun(i, x) of The-
orem 2.1 to deﬁne

ˆun
=
ˆun(in, ˆxn), n ∈⟨0, N −1⟩
with i0 = i,
ˆxn+1
=
ˆxn + ˆun −ξn, n ∈⟨0, N −1⟩
with ˆx0 = x.
(2.13)

30
Discounted Cost Models with Backorders
Theorem 2.2 (Veriﬁcation Theorem) The decision ˆU=(ˆu0,ˆu1,. . . ,ˆuN−1)
is optimal for the problem J0(i, x; U). Moreover,
v0(i, x) = min
U∈U J0(i, x; U).
(2.14)
Proof. Let U = (u0, . . . , uN−1) be any admissible decision. Without
loss of generality, we may assume that Ecn(in, un) < ∞, Efn(in, xn) <
∞, n ∈⟨0, N −1⟩and EfN(iN, xN) < ∞. Otherwise, J0(i, x; U) = ∞
and U cannot be optimal since J0(i, x; 0) < ∞in view of (2.1) and
Assumptions (i) and (ii).
Because vN(iN, xN) = fN(iN, xN), it follows that EvN(iN, xN) < ∞. We
proceed by induction. Assume that Evn+1(in+1, yn+1) < ∞. Next, using
(2.8), the property (B.2-vii) of conditional expectations, the Markovian
property (2.3), the independence assumption of ξn, and the notation
(2.10), we obtain
E{vn+1(in+1, xn+1)|i0, . . . , in, ξ0, . . . , ξn−1}
=
E{vn+1(in+1, xn + un −ξn)|i0, . . . , in, ξ0, . . . , ξn−1}
=
E{vn+1(in+1, y −ξn)|i0, . . . , in, ξ0, . . . , ξn−1}y=xn+un
=
E{vn+1(in+1, y −ξn)|in}y=xn+un
=
Fn+1(vn+1)(in+1, y)y=xn+un
=
Fn+1(vn+1)(in+1, xn + un) a.s.
(2.15)
Now using (2.12), since U is admissible but not necessarily optimal, we
can assert that
vn(in, xn) ≤fn(in, xn) + cn(in, un) + Fn+1(vn+1)(in+1, xn + un) a.s.,
and from the relation (2.15), we can derive
vn(in, xn)
≤
fn(in, xn) + cn(in, un)
+E{vn+1(in+1, xn+1)|i0, . . . , in, ξ0, . . . , ξn−1} a.s.
By taking the expectation of both sides of the above inequality, we obtain
Evn(in, xn) ≤E(fn(in, xn) + cn(in, un)) + E(vn+1(in+1, xn+1)).
(2.16)
It follow from (2.16) that Evn(in, xn) < ∞and, therefore, (2.16) holds
for all n ∈⟨0, N⟩. Summing from 0 to N −1, we get
v0(i, x) ≤J0(i, x; U).
(2.17)

MARKOVIAN DEMAND INVENTORY MODELS
31
Now consider the decision ˆU. From the deﬁnition of ˆun(in, x) as the
Borel function that attains the inﬁmum in (2.12), and proceeding as
above, we can also obtain
Evn(in, ˆyn) = E(fn(in, ˆyn) + cn(in, ˆun)) + E(vn+1(in+1, yn+1)).
Note that ˆx0 = x is deterministic and v0(i, x) ∈C1. Thus, Ev0(i0, ˆx0) =
v0(i, x) < ∞, and we can prove recursively that Ecn(in, ˆun) < ∞, n ∈
⟨0, N −1⟩and Efn(in, ˆxn) < ∞, Evn(in, ˆxn) < ∞, n ∈⟨0, N⟩. Adding
up for n from 0 to N −1, it follows that
v0(i, x) = J0(i, x; ˆU).
This and the inequality (2.17) complete the proof.
□
Taken together, Theorems 2.1 and 2.2 establish the existence of an
optimal feedback policy. This means that there exists a policy in the
class of admissible policies whose objective function value equals the
value function deﬁned by (2.9), as well as a Markov (or feedback) policy
which gives the same objective function value. Furthermore, the solution
v0(i, x) obtained in Theorem 2.1 is the value function.
2.5.
Optimality of (s, S)-type Ordering Policies
We impose an additional condition on the costs under which the op-
timal feedback policy ˆun(i, x) turns out to be an (s, S)-type policy. For
n ∈⟨0, N −1⟩and i ∈I, let
Ki
n ≥¯Ki
n+1 ≡
L

j=1
pijKj
n+1 ≥0.
(2.18)
Remark 2.2 Condition (2.18) means that the ﬁxed cost of ordering in
a given period with demand state i should be no less than the expected
ﬁxed cost of ordering in the next period. The condition is a generaliza-
tion of the similar conditions used in the standard models. It includes
the cases of the constant ordering costs (Ki
n = K, ∀i, n) and the nonin-
creasing ordering costs (Ki
n ≥Kj
n+1, ∀i, j, n). The latter case may arise
on account of the learning curve eﬀect associated with ﬁxed ordering
costs over time. Moreover, when all the future costs are calculated in
terms of their present values, even if the undiscounted ﬁxed cost may
increase over time, Condition (2.18) still holds as long as the rate of
increase of the ﬁxed cost over time is less than or equal to the discount
rate.

32
Discounted Cost Models with Backorders
Theorems C.2.2 and C.2.3 are included in Appendix C to provide the
required existing results on K-convex functions or their extensions. We
can now derive the following result.
Theorem 2.3 Assume (2.18) in addition to the assumptions made in
Section 2.3.
Then there exists a sequence of numbers sn,i, Sn,i, n ∈
⟨0, N −1⟩, i ∈I, with sn,i ≤Sn,i, such that the optimal feedback policy is
ˆun(i, x) = (Sn,i −x)1Ix<sn,i.
(2.19)
Proof. The dynamic programming equations (2.12) can be written as

vn(i, x) = fn(i, x) −ci
nx + hn(i, x),
n ∈⟨0, N −1⟩, i ∈I,
vN(i, x) = fN(i, x),
i ∈I,
(2.20)
where
hn(i, x) = inf
y≥x[Ki
n1Iy>x + zn(i, y)]
(2.21)
and
zn(i, y) = ci
ny + Fn+1(vn+1)(i, y).
(2.22)
From (2.5) and (2.12), we have vn(i, x) ≥fn(i, x), ∀n ∈⟨0, N−1⟩. From
Theorem 2.1, we know that vn ∈C1. These, along with (2.11), ensure
for n ∈⟨0, N −1⟩and i ∈I, that zn(i, y) →+∞as y →∞, and zn(i, y)
is uniformly continuous.
In order to apply Theorem C.2.3 to obtain (2.19), we need only to
prove that zn(i, x) is Ki
n-convex.
According to Theorem C.2.2, it is
suﬃcient to show that vn+1(i, x) is Ki
n+1-convex. This is done by in-
duction. First, vN(i, x) is convex by deﬁnition and, therefore, K-convex
for any K ≥0. Let us now assume that for a given n ≤N −1 and i,
vn+1(i, x) is Ki
n+1-convex. By Theorem C.2.2 and Condition (2.18), it
is easy to see that zn(i, x) is ¯Ki
n+1-convex, hence also Ki
n-convex. Then,
Theorem C.2.3 implies that hn(i, x) is Ki
n-convex. Therefore, vn(i, x) is
Ki
n-convex. This completes the induction argument.
Thus, it follows that zn(i, x) is Ki
n-convex for each n and i. Since
zn(i, y) →+∞when y →∞, we apply Theorem C.2.3 to obtain the
desired sn,i and Sn,i. According to Theorem 2.2, the (s, S)-type policy
deﬁned in (2.19) is optimal.
□
Remark 2.3 Theorem 2.3 can be easily extended to allow for a constant
leadtime in the delivery of orders. The usual approach is to replace the
surplus level by the so-called surplus position. It can also be generalized
to Markovian demands with discrete components and countably many
states.

MARKOVIAN DEMAND INVENTORY MODELS
33
Remark 2.4 In the standard model with L = 1, Veinott (1966) gives
an alternate proof to the one by Scarf (1960) based on K-convexity.
For this, he does not need a condition like (2.11), but requires other
assumptions instead.
2.6.
Nonstationary Inﬁnite Horizon Problem
We now consider an inﬁnite horizon version of the problem formulated
in Section 2.3. By letting N = ∞and U = (un, un+1, . . .), the extended
real-valued objective function of the problem becomes
Jn(i, x; U) =
∞

k=n
αk−nE[ck(ik, uk) + fk(ik, xk)],
(2.23)
where α is a given discount factor, 0 < α ≤1. The dynamic programming
equations are
vn(i, x) = fn(i, x)+ inf
u≥0{cn(i, u)+αFn+1(vn+1)(i, x+u)}, n = 0, 1, 2, . . . .
(2.24)
In what follows, we will show that there exists a solution of (2.24) in
class C1, which is the value function of the inﬁnite horizon problem; (see
also Remark 2.5). Moreover, the decision that attains the inﬁmum in
(2.24) is an optimal feedback policy. Our method is that of successive
approximation of the inﬁnite horizon problem by longer and longer ﬁnite
horizon problems.
Therefore, we examine the ﬁnite horizon approximation Jn,m(i, x; U),
m ≥1, of (2.23), which is obtained by the ﬁrst m-period truncation of
the inﬁnite horizon problem of minimizing Jn(i, x; U), i.e.,
Jn,m(i, x; U) =
n+m−1

k=n
αk−nE[ck(ik, uk) + fk(ik, xk)].
(2.25)
Let vn,m(i, x) be the value function of the truncated problem, i.e.,
vn,m(i, x) = inf
U∈U Jn,m(i, x; U).
(2.26)
Since (2.26) is a ﬁnite horizon problem on the interval ⟨n, n + m⟩, we
may apply Theorems 2.1 and 2.2 and obtain its value function by solving
the dynamic programming equations

vn,m+1(i, x)
=
fn(i, x) + inf
u≥0{cn(i, u) + αFn+1(vn+1,m)(i, x + u)},
vn+m,0(i, x)
=
0.
(2.27)

34
Discounted Cost Models with Backorders
Moreover, vn,0(i, x) = 0, vn,m ∈C1, and the inﬁmum in (2.26) is at-
tained.
It is not diﬃcult to see that the value function vn,m increases in m.
In order to take its limit as m →∞, we need to establish an upper
bound on vn,m. One possible upper bound on infU∈U Jn(i, x; u) can be
obtained by computing the objective function value associated with a
policy of never ordering anything. With the notation 0 = {0, 0, . . .} for
this policy, let us write
wn(i, x) = Jn(i, x; 0)
= fn(i, x) + E
⎧
⎨
⎩
∞

k=n+1
αk−nfk(ik, x −
k−1

j=1
ξj)|in = i
⎫
⎬
⎭. (2.28)
In a way similar to Section I.5.1 of Chapter 4 in Bensoussan et al. (1983),
it is easy to see that given (2.6), wn(i, x) is well-deﬁned and is in C1.
Furthermore, in class C1, wn is the unique solution of
wn(i, x) = fn(i, x) + αFn+1(wn+1)(i, x).
(2.29)
We can state the following result for the inﬁnite horizon problem.
Theorem 2.4 Assume (2.5) and (2.6). Then, we have
0 = vn,0 ≤vn,1 ≤. . . ≤vn,m ≤wn
(2.30)
and as m →∞
vn,m ↑vn, a solution of (2.24) in B1.
(2.31)
Furthermore, vn ∈C1, and we can obtain ˆU = {ˆun, ˆun+1, . . .} for which
the inﬁmum in (2.24) is attained. Moreover, ˆU is an optimal feedback
policy, i.e.,
vn(i, x) = min
U∈U Jn(i, x; U) = Jn(i, x; ˆU).
(2.32)
Proof. By deﬁnition, vn,0 = 0. Let ˜Un,m = {˜un, ˜un+1, . . . , ˜un+m−1} be
a minimizer of (2.25). Thus,
vn,m(i, x)
=
Jn,m(i, x; ˜Un,m) ≥Jn,m−1(i, x; ˜Un,m)
≥
min
U∈U Jn,m−1(i, x; U) = vn,m−1(i, x).
It is also obvious from (2.25) and (2.28) that vn,m(i, x) ≤Jn,m(i, x; 0) ≤
wn(i, x). This proves (2.30). Since vn,m ∈C1, we have
vn,m(i, x) ↑vn(i, x) ≤wn(i, x),
(2.33)

MARKOVIAN DEMAND INVENTORY MODELS
35
with vn(i, x) l.s.c., and hence in B1. Next, we show that vn satisﬁes the
dynamic programming equations (2.24). Observe from (2.27) and (2.30)
that for each m, we have
vn,m(i, x) ≤fn(i, x) + inf
u≥0{cn(i, u) + αFn+1(vn+1,m)(i, x + u)}.
Thus, in view of (2.33), we obtain
vn(i, x) ≤fn(i, x) + inf
u≥0{cn(i, u) + αFn+1(vn+1)(i, x + u)}.
(2.34)
In order to obtain the reverse inequality, let ˆun,m attain the inﬁmum
on the RHS of (2.27). From (2.5) and (2.6), we obtain that
ci
nˆun,m(i, x) ≤αFn+1(vn+1,m)(i, x) ≤α(1 + M) ∥wn ∥(1 + |x|),
where ∥·∥is the norm deﬁned on B1. This provides us with the bound
0 ≤ˆun,m(i, x) ≤Mn(1 + |x|).
(2.35)
For l > m, we see from (2.27) that
vn,l+1(i, x)
=
fn(i, x) + cn(i, ˆun,l(x))
+αFn+1(vn+1,l)(i, x + ˆun,l(x))
≥
fn(i, x) + cn(i, ˆun,l(x))
+αFn+1(vn+1,m)(i, x + ˆun,l(x)).
(2.36)
Fix m and let l →∞. In view of (2.35), we can, for any given n, i and
x, extract a subsequence ˆun,l′(i, x) such that ˆun,l′(i, x) →¯un(i, x). Since
vn+1,m is uniformly continuous in m and cn is l.s.c., we can pass to the
limit on the RHS of (2.36). Noting that the left-hand side converges as
well, we obtain
vn(i, x)
≥
fn(i, x) + cn(i, ¯un(x)) + αFn+1(vn+1,m)(i, x + ¯un(x))
≥
fn(i, x) + inf
u≥0{cn(i, u) + αFn+1(vn+1,m)(i, x + u)}.
This, along with (2.33), (2.34), and the fact that vn(i, x) ∈B1, proves
(2.31).
Next we prove that vn ∈C1. Let us consider the problem (2.25) again.
From (2.23),
Jn(i, x′; U) −Jn(i, x; U)

36
Discounted Cost Models with Backorders
=
∞

k=n
αk−nE
⎡
⎣fk
⎛
⎝ik, x′ +
k−1

j=n
uj −
k

j=n+1
ξi
⎞
⎠
−fk
⎛
⎝ik, x +
k−1

j=n
uj −
k

j=n+1
ξi
⎞
⎠
⎤
⎦.
From (2.6), we have
|Jn,m(i, x′; U) −Jn,m(i, x; U)| ≤
∞

l=n
αl−nC|x′ −x| = C|x′ −x|/(1 −α),
which implies |vn,m(i, x′)−vn,m(i, x)| ≤C|x′ −x|/(1−α). By taking the
limit as m →∞, we have |vn(i, x′) −vn(i, x)| ≤C|x′ −x|/(1 −α), from
which it follows that vn ∈C1. Therefore, there exists a function ˆun(i, x)
in B0 such that
cn(i, ˆun(i, x))
+
αFn+1(vn+1)(i, x + ˆun(i, x))
=
inf
u≥0{cn(i, u) + αFn+1(vn+1)(i, x + u)}.
Hence, we have
vn(i, x) = Jn(i, x; ˆU) ≥inf
U∈U Jn(i, x; U).
But for any arbitrary admissible control U, we also know that vn(i, x) ≤
Jn(i, x; U). Therefore, we conclude that
vn(i, x) = Jn(i, x; ˆU) = min
U∈U Jn(i, x; U).
□
Remark 2.5 We should indicate that Theorem 2.4 does not imply that
there is a unique solution of the dynamic programming equations (2.24).
There may well be other solutions. Moreover, one can show that the
value function is the minimal positive solution of (2.24). It is also pos-
sible to obtain a uniqueness proof under additional assumptions.
With Theorem 2.4 in hand, we can now prove the optimality of an
(s, S)-type policy for the nonstationary inﬁnite horizon problem.
Theorem 2.5 Assume (2.5), (2.6), and (2.11) hold for the inﬁnite hori-
zon problem. Then, there exists a sequence of numbers sn,i, Sn,i, n =

MARKOVIAN DEMAND INVENTORY MODELS
37
0, 1, . . . , with sn,i ≤Sn,i for each i ∈I, such that the optimal feedback
policy is ˆun(i, x) = (Sn,i −x)1Ix<sn,i.
Proof. Let vn denote the value function. Deﬁne the functions zn and
hn as in Section 2.5.
We know that zn(i, x) →∞as x →+∞and
zn(i, x) ∈C1 for all n and i ∈I.
We now prove that vn is Ki
n-convex. Using the same induction as
in Section 2.5, we can show that vn,k(i, x), as deﬁned in (2.26), is Ki
n-
convex. This induction is possible since we know that vn,k(i, x) satisﬁes
the dynamic programming equations (2.27). It is clear from the deﬁni-
tion of K-convexity and from taking the limit as k →∞, that the value
function vn(i, x) is also Ki
n-convex.
From Theorem 2.4, we know that vn ∈C1 and that vn satisﬁes the
dynamic programming equations (2.24). Therefore, we can obtain an
optimal feedback policy ˆU = {ˆun, ˆun+1, . . .} that attains the inﬁmum in
(2.24). Because vn is Ki
n-convex, ˆun can be expressed as in Theorem 2.5.
□
2.7.
Cyclic Demand Model
Cyclic or seasonal demand often arises in practice. Such a demand
represents a special case of the Markovian demand, where the number
of demand states L is given by the cycle length, and
pij =

1,
if j = i + 1, i = 1, . . . , L −1, or i = L, j = 1,
0,
otherwise.
Furthermore, we assume that the cost functions and density functions
are all time invariant. The result is a considerably simpliﬁed optimal
policy, i.e., only L pairs of (sn, Sn) need to be computed.
We can state the following corollary to Theorem 2.5.
Corollary 2.1 In the inﬁnite horizon inventory problem with the de-
mand cycle of L periods, let n1 and n2 (n1 < n2) be any two periods such
that n2 = n1 +m·L, m = 1, 2, . . . . Then, we have sn1 = sn2 and Sn1 =
Sn2.
2.8.
Constrained Models
In this section, we incorporate some additional constraints that often
arise in practice. We show that (s, S)-type policies continue to remain
optimal for the extended models.

38
Discounted Cost Models with Backorders
2.8.1
No-ordering Periods
Consider the special situation in which ordering is not possible in cer-
tain periods (for example, suppliers do not accept orders on weekends).
We will show that the following theorem holds in such a situation.
Theorem 2.6 In the problem with some no-ordering periods, the opti-
mal policy is still of (s, S)-type for any period, except when the ordering
is not allowed.
Proof. To stay with our earlier notation, it is no loss of generality to
continue assuming the setup cost to be Ki
m in a no-ordering period m
with the demand state i; clearly, setup costs are of no use in no-ordering
periods. The deﬁnition (2.21) is revised as
hn(i, x) =

zn(i, x),
in a no-ordering period n,
inf
y≥x[Ki
n1Iy>x + zn(i, y)],
otherwise,
(2.37)
and zn(i, y) is deﬁned as before in (2.22).
Using the same induction
argument as in the proof of Theorem 2.3, we can show that hn(i, x) and
vn(i, x) are Ki
n-convex if ordering is allowed in period n. If ordering is
disallowed in period n, then hn(i, x) = zn(i, x), which is ¯Ki
n+1-convex,
and therefore also Ki
n-convex. Thus, in both cases vn(i, x) is Ki
n-convex.
□
Remark 2.6 Theorem 2.6 can be generalized to allow for supply un-
certainty as in Parlar et al. (1995). One needs to replace uk in (2.8) by
akuk, where P{ak = 1|ik = i} = qi
k and P{ak = 0|ik = i} = 1 −qi
k, and
modify (3.2) appropriately.
2.8.2
Storage and Service Level Constraints
Let B < ∞denote an upper bound on the inventory level. Moreover,
to guarantee a reasonable measure of service level, we introduce a chance
constraint requiring that the probability of the ending inventory falling
below zero in any given period does not exceed 1 −αp for a speciﬁed
αp ∈(0, 1], known as Type 1 service level. Thus,
P{xk+1 < 0} ≤1 −αp, k ∈⟨0, N −1⟩.
As an example, if we set αp = 0.95, then we are requiring that we satisfy
the demand in any given period with at least 95% probability.
Given the demand state i in period k and the inventory dynamics
(2.8), we can write the above condition as Φi,k(xk + uk) ≥αp, which
can be converted into xk + uk ≥Ai
k, where Ai
k = inf(a|Φi,k(a) ≥αp),

MARKOVIAN DEMAND INVENTORY MODELS
39
referred to as the safety stock in period k that guarantees the Type
1 service level αp in that period.
If we deﬁne the quantile function
Φ−1
i,k(η) = inf(a|Φi,k(a) ≥η), then we can also write Ai
k = Φ−1
i,k(αp).
The dynamic programming equations can be written as (2.22), where
zn(i, y) is as in (2.22) and
hn(i, x) =
inf
y≥x,Ain≤y≤B[Ki
n1Iy>x + zn(i, y)],
(2.38)
provided Ai
n ≤B, n ∈⟨0, N −1⟩, i ∈I; if not, then there is no feasible
solution, and hn(i, x) = inf Ø ≡∞. This time, since y is bounded by
B < ∞, Theorem 2.1 can be relaxed as follows.
Theorem 2.7 The dynamic programming equations (2.20) with (2.38)
deﬁne a sequence of l.s.c. functions on (−∞, B ]. Moreover, there exists
a function ˆun(i, x) in B0, which attains the inﬁmum in (2.20) for any
x ∈(−∞, B ].
With ˆun(i, x) of Theorem 2.7, it is possible to prove Theorem 2.2,
also known as the veriﬁcation theorem, for the constrained case. We
now show that the optimal policy is of (s, S)-type.
Theorem 2.8 There is a sequence of numbers sn,i, Sn,i, n∈⟨0, N −1⟩,
i ∈I, with sn,i ≤Sn,i and Ai
n ≤Sn,i ≤B such that optimal feedback
policy ˆun(i, x) = (Sn,i −x)1Ix<sn,i is optimal for the model with capacity
and service constraints deﬁned above.
Proof. First note that Theorem C.2.3 holds when g is l.s.c. and K-
convex on (−∞, B ], B < ∞. Also, by Theorem C.2.2 (iii) and (iv), one
can see that Eg(x−ξ) is K-convex on (−∞, B ] since ξ ≥0. Because g is
l.s.c., it is easily seen that Eg(x−ξ) is l.s.c. on (−∞, B ]. Furthermore, by
Theorem 2.7, vn is l.s.c. on (−∞, B ]. With these observations in mind,
the proof of Theorem 2.3 can easily be modiﬁed to complete the proof.
□
Remark 2.7 A constant integer leadtime τ ≥1 can also be included in
this model, with the surplus level replaced by the surplus position and
with the lower bound Ai
k properly redeﬁned in terms of the distribution
of the total demand during the leadtime; (see, e.g., Porteus (1971) or
Zipkin (2000)).
2.9.
Concluding Remarks and Notes
This chapter, based on Sethi and Cheng (1997), develops various real-
istic extensions of the classical dynamic inventory model with stochastic

40
Discounted Cost Models with Backorders
demands. The models consider demands that are dependent on a ﬁnite
state Markov chain including demands that are cyclic. Some constraints
commonly encountered in practice, namely no-ordering periods, ﬁnite
storage capacities, and service levels, are also treated. Both ﬁnite and
inﬁnite horizon cases are studied. It is shown that all of these mod-
els, not unlike the classical model, exhibit the optimality of (s, S)-type
policies.

Chapter 3
DISCOUNT COST MODELS WITH
POLYNOMIALLY GROWING
SURPLUS COST
3.1.
Introduction
This chapter studies stochastic inventory problems with unbounded
Markovian demands and more general costs than those considered in
Chapter 2. Finite horizon problems, as well as stationary and nonsta-
tionary discounted cost inﬁnite horizon problems, are addressed. Exis-
tence of optimal Markov or feedback policies is established with Marko-
vian demand: unbounded, ordering costs that are l.s.c., and surplus
costs that are l.s.c. with polynomial growth. Furthermore, optimality
of (s, S)-type policies is proved when the ordering cost consists of ﬁxed
and proportional cost components and the surplus cost is convex.
The literature on inﬁnite horizon inventory models involving a ﬁxed
ordering cost assumes surplus cost to be of linear growth and uniformly
continuous as in Karlin (1958c), Scarf (1960), Bensoussan et al. (1983),
and others. Even quadratic surplus costs that are popular in the pro-
duction planning literature dating back to the classical HMMS model of
Holt et al. (1960) have not been considered in inﬁnite horizon inventory
models.
As for demand, Karlin and Fabens (1960), Song and Zipkin (1993),
Sethi and Cheng (1997), and Beyer and Sethi (1997) have all considered
Markovian demands. Karlin and Fabens consider only the class of state-
independent (s, S) policies, which does not in general include optimal
policies. Song and Zipkin consider Markov-modulated Poisson demand
in their analysis. Sethi and Cheng consider general Markovian demands
in their treatment of discounted cost problems.
In this chapter, we consider unbounded Markovian demands but re-
quire that a certain number (depending on the growth rate of the surplus
D. Beyer et al., Markovian Demand Inventory Models, International Series
41
in Operations Research & Management Science 108,
DOI 10.1007/978-0-387-71604-6 3, c⃝Springer Science+Business Media, LLC 2010

42
Discount Cost Models with Polynomially Growing Surplus Cost
cost function) of moments be ﬁnite. This is an essential requirement and
yet not very restrictive. As both cost and demand are generalized, the
chapter represents a signiﬁcant extension of the inﬁnite horizon inven-
tory problems (involving a ﬁxed ordering cost component) that have
appeared in the literature.
In this chapter, we conduct a detailed analysis of the discounted cost
problem. The problem is carefully formulated in Section 3.2. In Sec-
tion 3.3, we use the dynamic programming equation to prove the ex-
istence of an optimal Markov control for the ﬁnite horizon problem.
We also provide a veriﬁcation theorem for the solution of the dynamic
programming equation to be the value function. We prove the value
function to be continuous when the surplus cost is continuous and the
ordering cost is l.s.c. As we will remark later, this has some implications
for whether or not to order at the level s in an optimal (s, S)-type pol-
icy. The nonstationary inﬁnite horizon problem is treated in Section 3.4.
With further assumptions on costs, the optimality of (s, S)-type policies
is established in Section 3.5. The stationary inﬁnite horizon problem is
brieﬂy discussed in Section 3.6. The chapter concludes with end notes
in Section 3.7.
3.2.
Formulation of the Model
Let us consider an inventory problem over a ﬁnite number of periods
⟨n, N⟩= {n, n + 1, . . . , N}, and an initial inventory of x units at the
beginning of period n, where n and N are any given integers satisfying
0 ≤n ≤N < ∞. The demand in each period is assumed to be a random
variable deﬁned on a given probability space (Ω, F, P), and not necessar-
ily identically distributed. More speciﬁcally, the demand distributions
in successive periods are deﬁned as below.
Consider a ﬁnite collection of demand states I = {1, 2, . . . , L}, and
let ik denote the demand state in the kth period. We assume that ik,
k ∈⟨n, N⟩, with known initial demand state in, is a Markov chain over
I with the transition matrix P = {pij}. Thus,
0 ≤pij ≤1, i ∈I, j ∈I, and
L

j=1
pij = 1, i ∈I.
Let a nonnegative random variable ξk denote the demand in a given
period k, k = 0, . . . , N−1. Demand ξk depends only on period k and the
demand state in that period, by which we mean that it is independent
of past demand states and past demands.
We denote its cumulative
probability distribution by Φi,k(x), when the demand state ik = i. In
the following period, if the state changes to state j, which happens with

MARKOVIAN DEMAND INVENTORY MODELS
43
probability pij, then the demand distribution is Φj,k+1 in that period.
We further assume that for some γ ≥1 and a positive constant D,
E(ξγ
k|ik = i) =
∞

0
xγdΦi,k(x) ≤D < ∞, k = 0, . . . , N −1, i ∈I.
(3.1)
This is not a very restrictive assumption from an applied perspective.
We denote by
Fk
l , the σ-algebra generated by {il, . . . , ik−1, ik; ξl, . . . , ξk−1},
0 ≤l ≤k ≤N,
Fk = Fk
0 .
(3.2)
Since ik, k = 1, . . . , N, is a Markov chain and ξk depends only on ik, we
have
E(ξk|Fk)
=
E(ξk|i0, i1, . . . , ik; ξ0, ξ1, . . . , ξk−1)
=
E(ξk|ik).
(3.3)
An admissible decision (ordering quantities) for the problem on the
interval ⟨n, N⟩with initial state in = i can be denoted as
U = (un, . . . , uN−1),
(3.4)
where uk is a nonnegative Fk
n-measurable random variable. In simpler
terms, this means that decision uk depends only on the past information.
Note that since in is known in period n, Fn
n = (Ω, ∅); hence un is deter-
ministic. Moreover, it should be emphasized that this class of admissible
decisions is larger than the class of admissible feedback policies.
Ordering quantities are decided upon at the beginning of each period.
Demand in each period is supposed to occur at the end of the period
after the order has been delivered. Unsatisﬁed demand is carried forward
as backlog. The inventory balance equations are deﬁned by
⎧
⎪
⎪
⎨
⎪
⎪
⎩
xk+1 = xk + uk −ξk, k = n, . . . , N −1,
xn = x, initial inventory level,
ik, k = n, . . . , N, Markov chain with transition matrix P,
in = i, initial state,
where xk is the surplus level at the beginning of period k, uk is the
quantity ordered at the beginning of period k, ik is the demand state in
period k, and ξk is the demand in period k. Note that xk > 0 represents
an inventory of xk and xk < 0 represents a backlog (or shortage) of −xk.
Next, we specify the relevant costs and the assumptions they satisfy.

44
Discount Cost Models with Polynomially Growing Surplus Cost
(i) The production cost function ck(i, u) : I × R+ →R+ is l.s.c.,
ck(i, 0) = 0, k = 0, 1, . . . , N −1.
(ii) The surplus cost function fk(i, x) : I × R+ →R+ is l.s.c., with
fk(i, x) ≤¯f(1 + |x|γ), i = 1, 2 . . . , L, k = 0, 1, . . . , N −1, where
¯f is a nonnegative constant. When x < 0, fk(i, x) is the cost of
backlogged sales x, and when x > 0, fk(i, x) is the carrying cost of
holding inventory x during that period.
(iii) fN(i, x) : I × R+ →R+, the penalty cost/disposal cost for the
terminal surplus, is l.s.c. with fN(i, x) ≤¯f(1 + |x|γ). When x < 0,
fN(i, x) represents the penalty cost of unsatisﬁed demand x, and
when x > 0, fN(i, x) represents the disposal cost of the inventory
level x.
The objective function to be minimized is the expected present value
of all the costs incurred during the interval ⟨n, N⟩, i.e.,
Jn(i, x; U)
=
E

N−1

k=n
αk−n[ck(ik, uk) + fk(ik, xk)]
+αN−nfN(iN, xN)

,
(3.5)
which is always deﬁned, provided we allow this quantity to be inﬁnite.
In (3.5), α denotes the discount factor with 0 < α < 1. While intro-
ducing α in this ﬁnite horizon model does not add to generality, in view
of the already time-dependent nature of the cost functions, we do so
for convenience of exposition in dealing with the average cost optimality
criterion studied in Chapter 6.
3.3.
Dynamic Programming and Optimal
Feedback Policy
Let us ﬁrst introduce the following deﬁnitions.
Bγ= Banach space of Borel functions b : I × R →R with polynomial
growth with power γ or less. More speciﬁcally, if b ∈Bγ, then
|b(i, x)| ≤∥b ∥γ (1 + |x|γ), where the norm
∥b ∥γ= max
i
sup
x
|b(i, x)|
1 + |x|γ < ∞.
(3.6)
Lγ = the subspace of l.s.c. functions in Bγ. The space Lγ is closed in
Bγ.

MARKOVIAN DEMAND INVENTORY MODELS
45
Lγ−= the class of all l.s.c. functions which are of polynomial growth
with power γ or less on (−∞, 0].
In view of (3.3), we can write
E[b(ik+1, ξk)|Fk] = E[b(ik+1, ξk)|ik],
(3.7)
for any b ∈Bγ.
To write the dynamic programming equations more concisely, we de-
ﬁne the operator Fn+1 on Bγ as follows:
Fk+1b(i, y)
=
E[b(ik+1, y −ξk)|ik = i]
=
L

j=1
{P(ik+1 = j|ik = i)E[b(j, y −ξk)|ik = i]}
=
L

j=1
pij
 ∞
0
b(j, y −ξ)dΦi,k(ξ).
(3.8)
In addition to Assumptions (i)-(iii) on costs, we also require that for
k = 0, 1, . . . , N −1,
0 ≤ck(i, u) + αFk+1(fk+1)(i, u) →∞for u →∞.
(3.9)
Remark 3.1 Condition (3.9) implies that both the purchase cost and
the inventory (or salvage) cost associated with a decision in any given
period cannot both be zero.
The conditions rule out the trivial and
unrealistic situation of ordering an inﬁnite amount as the optimal policy.
See Remark 2.2 for further elaboration.
Let vn(i, x) represent the optimal value of the expected costs during
the time horizon ⟨n, N⟩with demand state i in period n, i.e.,
vn(i, x) = inf
U Jn(i, x; U).
Then, vn(i, x) satisﬁes the dynamic programming equations
vn(i, x)
=
fn(i, x) + inf
u≥0 {cn(i, u) + αE[vn+1(in+1,
x + u −ξn)|in = i]}
=
fn(i, x) + inf
u≥0 {cn(i, u) + αFn+1(vn+1)(i, x + u)},
n = 0, 1, . . . , N −1,
(3.10)
vN(i, x)
=
fN(i, x).
(3.11)

46
Discount Cost Models with Polynomially Growing Surplus Cost
We can now state our existence results in the following two theorems.
Theorem 3.1 The dynamic programming equations (3.10) and (3.11)
deﬁne a sequence of functions in Lγ. Moreover, there exists a Borel
function ˆun(i, x) such that the inﬁmum in (3.10) is attained at u =
ˆun(i, x) for any x. Furthermore, if the functions fn(i, ·), n = 0, 1, . . . , N,
i = 1, 2 . . . , L, are continuous, then the functions deﬁned by (3.10) and
(3.11) are continuous.
Proof.
We proceed by induction.
Because of Assumption (iii) and
(3.11), it follows that vN(i, x) ∈Lγ. Assume vn+1(i, x) belongs to Lγ.
Consider points x such that |x| ≤M, where M is an arbitrary nonneg-
ative integer. Let
BM
n,i = sup
|x|≤M
{αFn+1(vn+1)(i, x)}.
(3.12)
The constant BM
n,i is ﬁnite since vn+1(i, x) is in Bγ and therefore bounded
on |x| ≤M, and Fn+1 is a continuous linear operator; (see Lemma A.4.1).
Because of (3.9), we know that the set
N M
n,i := {u ≥0 : inf
|x|≤M{cn(i, u) + αFn+1(fn+1)(i, x + u) ≤BM
n,i}
(3.13)
is bounded, i.e., there is a ¯uM
n,i such that
N M
n,i ⊆[0, ¯uM
n,i].
(3.14)
Because of vn+1 ≥fn+1, we conclude that
{u ≥0 : inf
|x|≤M{cn(i, u) + αFn+1(vn+1)(i, x + u) ≤BM
n,i}
⊆N M
n,i ⊆[0, ¯uM
n,i],
(3.15)
and, therefore without loss of optimality, we can restrict our attention
to 0 ≤u ≤¯uM
n,i for all x satisfying |x| ≤M. This is because for any
u > ¯uM
n,i,
cn(i, u)
+
αFn+1(vn+1)(i, x + u)
≥
inf
|x|≤M{cn(i, u) + αFn+1(vn+1)(i, x + u)}
>
BM
n,i = sup
|x|≤M
{αFn+1(vn+1)(i, x)}
≥
αFn+1(vn+1)(i, x)
=
cn(i, 0) + αFn+1(vn+1)(i, x),
and thus u cannot be the point where the inﬁmum is attained.

MARKOVIAN DEMAND INVENTORY MODELS
47
Since the function
ψn(i, x, u) = cn(i, u) + αFn+1(vn+1)(i, x + u)
is l.s.c. and bounded from below, its minimum over a compact set is
attained; (see Theorem A.1.5). Moreover, from the classical Selection
Theorem A.1.7, we know that there exists a Borel function ˆuM
n (i, x) such
that
ψn(i, x, ˆuM
n (i, x)) =
inf
0≤u≤¯uM
n,i
ψn(i, x, u), |x| ≤M.
(3.16)
Upon deﬁning
ˆun(i, x) = ˆuM
n (i, x) for M −1 < |x| ≤M,
we obtain a Borel function such that
ψn(i, x, ˆun(i, x)) = inf
u≥0 ψn(i, x, u), ∀x.
(3.17)
Since
inf
u≥0 ψn(i, x, u) ≤ψn(i, x, 0) ≤cn(i, 0) + α ∥Fn+1 ∥∥vn+1 ∥γ (1 + |x|γ),
we can use (3.10), Assumption (ii), and Lemma A.4.1 to conclude that
vn(i, x) ∈Bγ. Furthermore, because ψn(i, ·, ·) is l.s.c., it follows from
equation (3.16) that vn(i, ·) is l.s.c. for each i (see Theorem A.1.6), and
therefore vn ∈Lγ.
To prove the last part of the theorem, we begin with the fact that for
each i the function fn(i, ·) is continuous, n = 0, 1, . . . , N. Then vN(i, ·) =
fN(i, ·) is continuous for all i, and the continuity of vn can be proved by
induction as follows. Assume vn+1 to be continuous. From (3.10) and
(3.17) we derive
vn(i, x0) = fn(i, x0) + cn(i, ˆu(i, x0)) + Fn+1(vn+1)(i, x0 + ˆu(i, x0))
and, because for x = x1 the inﬁmum in (3.10) is not necessarily attained
at ˆu(i, x0), we have
vn(i, x1) ≤fn(i, x1) + cn(i, ˆu(i, x0)) + Fn+1(vn+1)(i, x1 + ˆu(i, x0)).
Thus,
vn(i, x1) −vn(i, x0) ≤fn(i, x1) −fn(i, x0)
+Fn+1(vn+1)(i, x1 + ˆu(i, x0)) −Fn+1(vn+1)(i, x0 + ˆu(i, x0)),
which, in view of the continuity of fn and vn+1 ∈Lγ and (3.1), yields
lim sup
x1→x0
vn(i, x1) −vn(i, x0) ≤0.

48
Discount Cost Models with Polynomially Growing Surplus Cost
On the other hand, we have already proved that vn is l.s.c., which means
lim inf
x1→x0 vn(i, x1) −vn(i, x0) ≥0.
Therefore, vn is continuous.
□
To solve the problem of minimizing J0(i, x; U), let us deﬁne
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
ˆx0 = x,
ˆun = ˆun(in, ˆxn), n = 0, . . . , N −1,
ˆxn + 1 = ˆxn + ˆun −ξn, n = 0, . . . , N −1,
in, n = 0, . . . , N, Markov chain with transition matrix P,
i0 = i,
where ˆun(i, x) is a Borel function for which the inﬁmum in (3.10) is
attained for any i and x.
Theorem 3.2 (Veriﬁcation Theorem) The policy ˆU = (ˆu0, ˆu1, . . . , ˆuN−1)
minimizes J0(i, x; U) over the class U of all admissible decisions. More-
over,
v0(i, x) = min
U∈U J0(i, x; U).
(3.18)
Proof.
Let U = (u0, . . . , uN−1) be any admissible decision with the
corresponding trajectory (x0, . . . , xN−1). Without loss of generality, we
may assume that Ecn(in, un) < ∞, Efn(in, xn) < ∞, n ∈⟨0, N −1⟩, and
EfN(iN, xN) < ∞. Otherwise, J0(i, x; U) = ∞and U cannot be optimal
since J0(i, x; 0) < ∞in view of (3.1) and Assumptions (i)-(iii).
Because vn(iN, xN) = fN(iN, xN), it follows that EvN(iN, xN) < ∞.
Using arguments analogous to those in the proof of Theorem 2.2, we
proceed by induction. Assume that Evn+1(in+1, xn+1) < ∞. Using prop-
erty (vii) in Section B.2, (3.7), and (3.8), we obtain (see details leading
to (2.15))
E{vn+1(in+1, xn+1)|Fn} = Fn+1(vn+1)(in, xn + un) a.s.
(3.19)
Since U is admissible but not necessarily optimal, we can use (3.10) to
assert that
vn(in, xn) ≤fn(in, xn) + cn(in, un) + αFn+1(vn+1)(in, xn + un) a.s.
Then from the relation (3.19), we can derive
vn(in, xn) ≤fn(in, xn) + cn(in, un) + αE{vn+1(in+1, xn+1)|Fn}.

MARKOVIAN DEMAND INVENTORY MODELS
49
Taking expectation of both sides of the above inequality, we obtain
αnEvn(in, xn)
≤
αnE(fn(in, xn) + cn(in, xn))
+αn+1E(vn+1(in+1, xn+1)).
(3.20)
We can conclude recursively that Evn(in, xn) < ∞for all n ∈⟨0, N⟩
and that (3.20) holds. Then, by summing (3.20) from 0 to N −1 and
canceling identical terms on both sides, we obtain
v0(i, x) ≤J0(i, x; U).
(3.21)
Consider now the decision ˆU. Using the deﬁnition of ˆun(in, x) as the
Borel function for which the inﬁmum in (3.10) is attained, and proceed-
ing as above, we can obtain
αnEvn(in, ˆxn)
=
αnE(fn(in, ˆxn) + cn(in, ˆun)) + αn+1E(vn+1(in+1, ˆxn+1)).
Note that ˆx0
= x is deterministic and v0(i, x) ∈Lγ. Therefore,
Ev0(i0, ˆx0) = v0(i, x) < ∞, and furthermore, it can be shown recursively
that Ecn(in, ˆun) < ∞, n ∈⟨0, N−1⟩and Efn(in, ˆxn) < ∞, Evn(in, ˆxn) <
∞, n ∈⟨0, N⟩. Adding up for n from 0 to N−1 and canceling terms, we
get
v0(i, x) = J0(i, x; ˆU).
This and the inequality (3.21) complete the proof.
□
3.4.
Nonstationary Discounted Inﬁnite Horizon
Problem
In this section, we consider an inﬁnite horizon version of the model
formulated in Section 3.2. We require that the Assumptions (i) and (ii)
hold with N = ∞, and that i0, i1, . . . is a Markov chain with the same
transition matrix P. We set N = ∞, replace ⟨n, N⟩by ⟨n, ∞⟩, replace
the admissible decision in (3.4) by
U = (un, un+1, . . .),
(3.22)
and replace (3.5) by the objective function
Jn(i, x; U) =
∞

k=n
αk−nE[ck(ik, uk) + fk(ik, xk)],
(3.23)

50
Discount Cost Models with Polynomially Growing Surplus Cost
where α is the given discount factor, 0 < α < 1. The dynamic pro-
gramming equations for each i ∈I and n = 0, 1, 2, . . . can be written
as
vn(i, x) = fn(i, x) + inf
u≥0{cn(i, u) + αFn+1(vn+1)(i, x + u)}.
(3.24)
In what follows, we will show that there exists an Lγ-solution of (3.24),
which is the value function of the inﬁnite horizon problem. Moreover,
the decision, for which the inﬁmum in (3.24) is attained, is an optimal
feedback policy.
First, let us examine the ﬁnite horizon approximation Jn,m(i, x; U),
m ≥1, of (3.23). The approximation is obtained by the ﬁrst m-period
truncation of the inﬁnite horizon problem of minimizing Jn(i, x; U), i.e.,
Jn,m(i, x; U) =
n+m−1

k=n
E[cl(ik, uk) + fk(ik, xk)]αk−n.
(3.25)
Let vn,m(i, x) be the value function of the truncated problem with no
penalty cost in the last period, i.e.,
vn,m(i, x) = inf
U Jn,m(i, x; U).
(3.26)
Since the truncated problem is a ﬁnite horizon problem deﬁned on the
interval ⟨n, n + m⟩, Theorems 3.1 and 3.2 apply. Therefore, its value
function can be obtained by solving the corresponding dynamic pro-
gramming equations
vn,m+1(i, x)
=
fn(i, x) + inf
u≥0{cn(i, u)
(3.27)
+αFn+1(vn+1,m)(i, x + u)},
vn+m,0(i, x)
=
0.
(3.28)
Moreover, vn,0(i, x) = 0 and
vn,m(i, x) = min
U Jn,m(i, x; U).
Next we will show that an a priori upper bound on inf Jn(i, x; U) can
be easily constructed. Let us deﬁne
wn(i, x) = Jn(i, x; 0),
(3.29)
where 0 = {0, 0, . . .} is the policy that never orders anything. Then,
since no production costs are incurred in view of Assumption (i), we

MARKOVIAN DEMAND INVENTORY MODELS
51
have
wn(i, x) = fn(i, x)+
E

∞

k=n+1
αk−nfk(ik, x −(ξn + ξn+1 + · · · + ξk−1)
in = i

.(3.30)
Lemma 3.1 wn(i, x) is well deﬁned and wn(i, x) ∈Lγ.
Proof. On account of fn(i, x) ∈Lγ, it is suﬃcient to show that
E

∞

k=n+1
αk−nfk(ik, x −(ξn + ξn+1 + · · · + ξk−1))
in = i

∈Lγ.
Assumption (ii) yields
E

∞

k=n+1
αk−nfk(ik, x −(ξn + ξn+1 + · · · + ξk−1))
in = i

≤
¯f
∞

k=n+1
αk−n(1 + E

|x −(ξn + ξn+1 + · · · + ξk−1)|γin = i

)
=
¯fα
1 −α + ¯f
∞

k=n+1
αk−nE

|x −(ξn + ξn+1 + · · · + ξk−1)|γ  in = i

.
Note that it follows from (3.1) that E(ξγ
k|ik = i) ≤D+1 for all k and i.
Let Mx = max{|x|γ, D+1}. Now let us consider the argument of the sum
for a ﬁxed k ≥n + 1. Let Πk := {(in, . . . , ik) : in, . . . , ik ∈I and in = i}
be the set of all combinations of demand states in periods n through k
for a given initial state in = i. Note that for a given sequence of demand
states, the one-period demands are independent. Then we have,
E

|x −(ξn + · · · + ξk−1)|γ  in = i

=

π∈Πk
E

|x −(ξn + · · · + ξk−1)|γ  (in, . . . , ik) = π

×P((in, . . . , ik) = π)
≤

π∈Πk
(k −n + 1)γE

|x|γ + |ξn|γ + · · · + |ξk−1)|γ  (in, . . . , ik) = π

×P((in, . . . , ik) = π)
≤

π∈Πk
(k −n + 1)γ(n −k) ¯
MxP((in, . . . , ik) = π)
=
(k −n + 1)γ(k −n) ¯
Mx.

52
Discount Cost Models with Polynomially Growing Surplus Cost
Therefore,
E

∞

k=n+1
αk−nfk(ik, x −(ξn + · · · + ξk−1))
in = i

≤
¯f

α
1 −α + ¯
Mx
∞

k=n+1
αk−n(k −n + 1)γ(k −n)

< ∞.
Consequently, wn(i, x) < ∞. In view of Theorem A.1.8, wn(i, x) is also
l.s.c. as the sum of nonnegative l.s.c. functions. Moreover, because ¯
Mx =
|x|γ for |x|γ ≥D+1, wn(i, x) is at most of polynomial growth with power
γ. Thus, we have wn(i, x) ∈Lγ.
□
We can now state the following result for the inﬁnite horizon problem.
Theorem 3.3 Let Assumptions (i)-(ii) and (3.1) hold. Then, we have
0 = vn,0 ≤vn,1 ≤. . . ≤vn,m ≤wn
(3.31)
and
vn,m ↑vn ∈Bγ,
(3.32)
where vn is a solution of (3.24) in Lγ. Furthermore, there exists ˆU =
{ˆun, ˆun+1, . . .} for which the inﬁmum in (3.24) is attained, and ˆU is an
optimal feedback policy, i.e.,
vn(i, x) = min
U Jn(i, x; U) = Jn(i, x; ˆU).
(3.33)
Proof. By deﬁnition, vn,0 = 0. Let ˜Un,m = {˜un, ˜un+1, . . . , ˜un+m−1} be
a minimizer of (3.25). Thus,
wn(i, x)
=
Jn(i, x; 0) ≥Jn,m(i, x; 0)
≥
vn,m(i, x) = Jn,m(i, x; ˜Un,m) ≥Jn,m−1(i, x; ˜Un,m−1)
≥
min
U Jn,m−1(i, x; U) = vn,m−1(i, x).
This proves (3.31).
Moreover, it follows from (3.31) that there is a
function vn(i, x) such that
vn,m(i, x) ↑vn(i, x) ≤wn(i, x).
(3.34)
Next, we will show that the functions vn satisfy the dynamic program-
ming equations (3.24). Observe from (3.27) and (3.31) that for each m,
we have
vn,m(i, x) ≤fn(i, x) + inf
u≥0{cn(i, u) + αFn+1(vn+1,m)(i, x + u)}.

MARKOVIAN DEMAND INVENTORY MODELS
53
Thus, in view of (3.34), we can replace vn+1,m by vn on the RHS of the
above inequality and then pass to the limit on the LHS as m →∞to
obtain
vn(i, x) ≤fn(i, x) + inf
u≥0{cn(i, u) + αFn+1(vn+1)(i, x + u)}.
(3.35)
Let the inﬁmum in (3.27) be attained at ˆun,m. In order to obtain the
reverse inequality, we ﬁrst prove that ˆun,m(i, x) is uniformly bounded
with respect to m.
In the proof of Theorem 3.1 we showed that for |x| ≤M, there is an
¯uM
n,i such that ˆun,N−n(i, x) ≤¯uM
n,i. Furthermore, if we replace vn+1 by
wn+1 in (3.12) and follow the same line of arguments as in the proof of
Theorem 3.1, we obtain an upper bound ¯¯uM
n,i, which does not depend on
the horizon N. Therefore, we can conclude that
¯un(i, x) := ¯¯uM
n,i is an upper bound for ˆun,m(i, x) if M −1 < |x| ≤M,
(3.36)
independent of m.
For l > m, we see from (3.27)that
vn,l+1(i, x)
=
fn(i, x) + cn(i, ˆun,l(x))
+αFn+1(vn+1,l)(i, x + ˆun,l(x))
≥
fn(i, x) + cn(i, ˆun,l(x))
+αFn+1(vn+1,m)(i, x + ˆun,l(x)).
(3.37)
Fix m and let l →∞. In view of (3.36), we can choose a sequence of
periods l′ such that
ˆun,l′(i, x) →˜un(i, x) for l′ →∞.
(3.38)
We then conclude from (3.37) and Fatou’s Lemma (Lemma B.1.1) that
vn(i, x) ≥fn(i, x) + lim
l′→∞cn(i, ˆun,l′(i, x))
+α lim inf
l′→∞Fn+1(vn+1,m)(i, x + ˆun,l′(i, x)),
≥fn(i, x) + lim
l′→∞cn(i, ˆun,l′(i, x))
+α
L

j=1
pij
∞

0
(lim inf
l′→∞vn+1,m(i, x + ˆun,l′(i, x) −ξ))dΦi,n(ξ).
Since vn+1,m and cn are l.s.c., we can, in view of (3.38), pass to the limit
in the argument of these functions to obtain
vn(i, x)
≥
fn(i, x) + cn(i, ˜un(i, x)) + αFn+1(vn+1,m)(i, x + ˜un(i, x)),
≥
fn(i, x) + inf
u≥0{cn(i, u) + αFn+1(vn+1,m)(i, x + u)}.
(3.39)

54
Discount Cost Models with Polynomially Growing Surplus Cost
This, along with (3.35) and (3.34), proves (3.32).
From Theorem A.1.8, it follows that vn is l.s.c., as the monotone limit
of l.s.c. functions vn,m as m →∞. Also, since vn is bounded by a function
wn of polynomial growth, we have vn ∈Lγ.
Because wn ≥vn ≥fn, it is clear that ¯un(i, x) deﬁned in (3.36) is also
an upper bound for the minimizer in (3.24). Therefore, there exists a
Borel map ˆun(i, x) such that
cn(i, ˆun(i, x)) + αFn+1(vn+1)(i, x + ˆun(i, x))
=
inf
u≥0{cn(i, u) + αFn+1(vn+1)(i, x + u)}.
(3.40)
With that in mind, we can use (3.24) to obtain
E[vk(ik, xk)]
=
E[fk(ik, xk) + ck(ik, ˆuk)] + αE[Fk+1(vk+1)(ik, xk + ˆuk)]
=
E[fk(ik, xk) + ck(ik, ˆuk] + αE[vk+1(ik+1, xk+1)], k = 0, 1, 2, . . . .
Multiplying by αk−n, summing from n to N −1, and canceling terms
yield
vn(i, x) ≥E
 N−1

k=n
αk−n(ck(ik, ˆuk) + fk(ik, ˆxk))

+ αN−nE[vN(iN, ˆxN)].
Letting N →∞, we conclude
vn(i, x) ≥Jn(i, x; ˆU).
(3.41)
From Theorem 3.2 we know that vn,k(i, x) ≤Jn,k(i, x; U) for any policy
U, and we let k →∞to obtain
vn(i, x) ≤Jn(i, x; U) for any admissible U.
(3.42)
Together, inequalities (3.41) and (3.42) imply
vn(i, x) = Jn(i, x; ˆU) = min
U
Jn(i, x; U),
which completes the proof.
□
Before we prove the optimality of an (s, S)-type policy for the nonsta-
tionary ﬁnite and inﬁnite horizon problems, we should note that Theo-
rem 3.3 does not imply uniqueness of the solution to the dynamic pro-
gramming equations (3.27) and (3.28). There may be other solutions.
Moreover, one can show that the value function is the minimal positive
solution of (3.27) and (3.28). It is also possible to obtain a uniqueness
proof under additional assumptions.
For our purpose, however, it is
suﬃcient to have the results of Theorem 3.3.

MARKOVIAN DEMAND INVENTORY MODELS
55
3.5.
Optimality of (s, S)-type Ordering Policies
The existence and optimality of a feedback (or Markov) policy ˆun(i, x)
was proved in Theorems 3.1 and 3.2. We now make additional assump-
tions to further characterize the optimal feedback policy.
Let us assume that for any demand state i,
fn(i, x)
is convex with respect to x,
n = 0, 1, . . . , N, (3.43)
cn(i, u)
=

0,
u = 0,
Ki
n + ci
n · u,
u > 0,
(3.44)
where ci
n ≥0 and Ki
n ≥0, n = 0, 1, . . . , N −1, and
Ki
n ≥α ¯Ki
n+1 ≡α
L

j=1
pijKj
n+1,
n = 0, 1, . . . , N.
(3.45)
It should be noted that (3.43) implies that fn(i, ·), for any i and
n = 0, 1, . . . , N, is continuous on R.
Remark 3.2 Assumptions (3.43)–(3.45) reﬂect the usual structure of
costs to prove optimality of an (s, S)-type policy.
Theorem 3.4 Let N be ﬁnite. Let Assumptions (i)-(iii), (3.1), (3.9),
and (3.43)-(3.45) hold. Then, there exists a sequence of numbers sn,i,
Sn,i, n = 0, . . . , N−1, i = 1, . . . , L, with sn,i ≤Sn,i, such that the optimal
feedback policy is
ˆun(i, x) =

Sn,i −x,
x ≤sn,i,
0,
x > sn,i.
(3.46)
Proof. The dynamic programming equations (3.10) and (3.11) can be
written as
vn(i, x) = fn(i, x) −ci
nx + hn(i, x),
0 ≤n ≤N −1, i = 1, . . . , L,
vN(i, x) = fN(i, x),
i = 1, . . . , L,
where
hn(i, x)
=
inf
y≥x[Ki
n1Iy>x + zn(i, y)],
(3.47)
zn(i, y)
=
ci
ny + αFn+1(vn+1)(i, y).
(3.48)
From (3.10), we have vn(i, x) ≥fn(i, x). This inequality, along with
(3.9), ensures for n = 1, 2, . . . , N −1 and i = 1, 2, . . . , L that
zn(i, x) →+∞as x →∞.
(3.49)

56
Discount Cost Models with Polynomially Growing Surplus Cost
Furthermore, from the last part of Theorem 3.1, it follows that vn+1 is
continuous; therefore zn(i, x) is continuous.
In order to obtain (3.46), we need to prove that zn(i, x) is Ki
n-convex.
This is done by induction. First, vN(i, x) is convex by deﬁnition and
therefore, K-convex for any K ≥0. Let us now assume that for a given
n ≤N −1 and i, vn+1(i, x) is Ki
n+1-convex. By Assumption (3.45), it is
easy to see that zn(i, x) is α ¯Ki
n+1-convex, hence also Ki
n-convex. Then,
Theorem C.2.3 implies that hn(i, x) is Ki
n-convex. Therefore, vn(i, x) is
Ki
n-convex. This completes the induction argument.
Thus, it follows that zn(i, x) is Ki
n-convex for each n and i. In view
of (3.49), we apply Theorem C.2.3 to obtain the desired sn,i and Sn,i.
According to Theorem 3.2 and the continuity of zn, the optimal feedback
policy deﬁned in (3.46) is optimal.
□
Theorem 3.5 Let Assumptions (i)-(ii), (3.1), (3.9), and (3.43)–(3.45)
hold for the cost functions for the inﬁnite horizon problem. Then, there
exists a sequence of numbers sn,i, Sn,i, n = 0, 1, . . . , with sn,i ≤Sn,i for
each i ∈I, such that the feedback policy
ˆun(i, x) =

Sn,i −x,
x < sn,i,
0,
x ≥sn,i,
(3.50)
is optimal.
Proof. Let vn denote the value function. Deﬁne the functions zn and
hn as above. We know that zn(i, x) →∞as x →+∞and zn(i, x) ∈Lγ
for all n and i = 1, 2, . . . , L.
We now prove that vn is Kn-convex. Using the same induction as in
the proof of Theorem 3.4, we can show that vn,m(i, x), deﬁned in (3.26),
is Ki
n-convex. This induction is possible since we know that vn,m(i, x)
satisﬁes the dynamic programming equations (3.27) and (3.28).
It is
clear from the deﬁnition of K-convexity that this property is preserved
under monotone limit procedures.
Thus, the value function vn(i, x),
which is the limit of vn,m(i, x) as m →∞, is Ki
n-convex.
From Theorem 3.3 we know that vn satisﬁes the dynamic program-
ming equations (3.27) and (3.28). Therefore, we can obtain an optimal
feedback policy ˆU = {ˆun, ˆun+1, . . .}, for which the inﬁmum in (3.27) is
attained. Because zn is Ki
n-convex and l.s.c., ˆun can be expressed as in
(3.50).
□
Remark 3.3 It is important to emphasize the diﬀerence between the
(s, S) policies deﬁned in (3.46) and (3.50). In (3.46), an order is placed
when the inventory level is s or below, whereas in (3.50) an order is

MARKOVIAN DEMAND INVENTORY MODELS
57
placed only when the inventory is strictly below s. Most of the literature
uses the policy type (3.46). While (3.46) in Theorem 3.4 can be replaced
by (3.50) on account of the continuity of zn, it is not possible to replace
(3.50) in Theorem 3.5 by (3.46), since zn is proved only to be l.s.c.
Remark 3.4 In the stationary inﬁnite horizon discounted cost case dis-
cussed in the next section, we are able to prove that the value function
is locally Lipschitz, and therefore continuous. The proof is provided in
Chapter 5, Lemma 5.3. Thus, in this case, policies of both types (3.50)
and (3.46) are optimal.
3.6.
Stationary Inﬁnite Horizon Problem
If the cost functions, as well as the distributions of the demands, do
not explicitly depend on time, i.e., for each k
ck(i, u) = c(i, u),
fk(i, x) = f(i, x),
and
Φi,k = Φi,
then it can be easily shown that the value function vn(i, x) does not
depend on n. In what follows, we will denote the value function of the
stationary discounted cost problem by vα(·, ·), in order to emphasize
the dependence on the discount factor α. In the same manner as in
Section 3.4, it can be proved that the function vα satisﬁes the dynamic
programming equation
vα(i, x) = f(i, x) + inf
u≥0{c(i, u) + αF(vα)(i, x + u)},
(3.51)
where F is the same as Fn+1, deﬁned in (3.8), i.e.,
Fb(i, y) =
L

j=1
pij
 ∞
0
b(j, y −ξ)dΦi(ξ),
for b ∈Bγ.
Furthermore, for any α, 0 < α < 1, there is a stationary optimal feed-
back policy Uα = (uα(i, x), uα(i, x), . . .), where uα(i, x) is the minimizer
on the RHS of (3.51). Moreover, if the cost functions also satisfy the
Assumptions (3.43)–(3.45) introduced in Section 3.5, then we can obtain
pairs (sα
i , Sα
i ) such that either of the (sα
i , Sα
i )-policies of types (3.50) and
(3.46) is optimal; (see Remark 3.4).
3.7.
Concluding Remarks and Notes
This chapter, based on Beyer and Sethi (1997) and Beyer et al. (1998),
generates the discounted inﬁnite horizon inventory model involving ﬁxed

58
Discount Cost Models with Polynomially Growing Surplus Cost
costs that have appeared in the literature, to allow for unbounded de-
mand and costs with polynomial growth. We have shown the existence
of an optimal Markov policy, and that this can be a state-dependent
(s, S) policy.
This chapter makes several speciﬁc contributions.
It extends the
proofs of existence and veriﬁcation of optimality in the discounted cost
case given in Chapter 2, to allow for more general costs including l.s.c.
surplus cost with polynomial growth.
Some problems of theoretical interest remain open. One might want
to show that the value function in the discounted nonstationary inﬁnite
horizon case is continuous if the surplus cost function is continuous.

Chapter 4
DISCOUNTED COST MODELS
WITH LOST SALES
4.1.
Introduction
In the literature of stochastic inventory models, there are two diﬀerent
assumptions about the excess demand unﬁlled from existing inventories:
the backlog assumption and the lost sales assumption. The former is
more popular in the literature, partly because historically the inventory
studies started with spare parts inventory management problems in mil-
itary applications, where the backlog assumption is realistic. However,
in many other business situations, it is quite often that demand that
cannot be satisﬁed on time is lost. This is particularly true in a compet-
itive business environment. For example, in many retail establishments
such as a supermarket or a department store, a customer chooses a com-
petitive brand and goes to another store if his/her preferred brand is
out of stock.
In the presence of ﬁxed ordering costs in inventory models under either
assumption, an important issue has been to establish the optimality
of (s, S)-type policies. However, in comparison to many classical and
recent papers dealing with this issue in the backlog case, there are only
a few that treat the lost sales case. These include Veinott (1966), Shreve
(1976), and Bensoussan et al. (1983). This is perhaps because the proofs
of the results in the lost sales case are usually more complicated than
those in the backlog case. Shreve (1976) and Bensoussan et al. (1983)
establish the optimality of an (s, S)-type policy by using the concept of
K-convexity. Veinott (1966) provides a diﬀerent proof for the optimality
of (s, S)-type policies in the lost sales case.
His proof is based on a
diﬀerent set of assumptions which neither implies nor is implied by those
D. Beyer et al., Markovian Demand Inventory Models, International Series
59
in Operations Research & Management Science 108,
DOI 10.1007/978-0-387-71604-6 4, c⃝Springer Science+Business Media, LLC 2010

60
Discounted Cost Models with Lost Sales
used in Shreve (1976) and Bensoussan et al. (1983). It should be noted
that all of these results are obtained under the condition of zero leadtime.
Many eﬀorts have been made to incorporate various realistic features
in inventory models. However, most of them are carried out under the
backlog assumption. One such feature is that of Markovian demand,
which is the subject of this book. In the previous two chapters, as in
many of the references cited therein, the backlog assumption is used in
all the analyses. As the lost sales situation is often the case in compet-
itive markets, it is interesting and worthwhile to extend the Markovian
demand model to allow for this situation.
This chapter studies a Markovian demand inventory model used when
any unsatisﬁed demand in a period is lost, whereas in Chapters 2 and
3, such unsatisﬁed demands are backlogged. The plan of this chapter is
as follows. In Section 4.2, we formulate our basic lost sales model with
Markovian demands, provide the dynamic programming equations, and
state the existence results. In Section 4.3, we show that state-dependent
(s, S) policies are optimal for the lost sales case of the Markovian demand
model using a K-convexity result associated with the cost functions in
the lost sales case. The proof of the K-convexity result is provided in
Section C.2. Furthermore, our Markovian demand model is formulated
under a set of less restrictive assumptions than those in the independent
demand models of Shreve (1976) and Bensoussan et al. (1983). In Sec-
tion 4.4, we discuss extensions that incorporate various realistic features
and constraints, such as supply uncertainty, service levels, and storage
capacities. An inﬁnite horizon stationary model is also presented. Nu-
merical results are presented in Section 4.5. We conclude the chapter
with some remarks in Section 4.6.
4.2.
Formulation of the Model
Consider an inventory problem over a ﬁnite horizon. The demand in
each period is assumed to be a random variable deﬁned on a given prob-
ability space, and not necessarily identically distributed. To precisely
deﬁne the demand process, we consider a ﬁnite collection of demand
states labeled i ∈I = {1, 2, . . . , L}, and let ik denote the demand state
observed at the beginning of period k. We assume that ik, k ∈⟨0, N⟩, is
a Markov chain over I, with the transition matrix P = {pij}. Thus,
0 ≤pij ≤1, i ∈I, j ∈I, and
L

j=1
pij = 1, i ∈I.
Let the nonnegative random variable ξk denote the demand at the
end of a given period k ∈⟨0, N−1⟩. Demand ξk depends only on period

MARKOVIAN DEMAND INVENTORY MODELS
61
k and the demand state in that period, by which we mean that it is
independent of past demand states and past demands. We denote its
probability density by ϕi,k(x), when the demand state ik = i. We assume
that
E(ξk|ik = i) =
 ∞
0
zϕi,k(z) dz ≤D < ∞, k ∈⟨0, N −1⟩, i ∈I.
(4.1)
At the beginning of period k, an order uk ≥0 is placed with the
knowledge that the demand state is ik and that the quantity uk will
be delivered at the end of period k, but before the period k demand ξk
materializes. If the on-hand inventory xk at the beginning of period k,
plus the amount uk delivered in period k, exceeds the demand, i.e., if
xk + uk ≥ξk, then the demand is met and the remaining inventory is
carried over to the next period as xk+1 = xk + uk −ξk. If xk + uk < ξk,
then the part ξk −xk −uk of the demand cannot be satisﬁed immediately
and is assumed to be completely lost. In this case, the next period will be
started with zero on-hand inventory. With the notation a+ = max{a, 0}
and 0 ≤n ≤N, the model dynamics can be expressed as
⎧
⎪
⎪
⎨
⎪
⎪
⎩
xk+1 = (xk + uk −ξk)+, k ∈⟨n, N −1⟩
xn = x ≥0,
ik, k ∈⟨n, N⟩, follows a Markov chain with transition matrix P,
in = i.
(4.2)
This describes the dynamics from period n onwards, given the inventory
level x and demand state i in period n.
Let B0 denote the class of all continuous functions from I × R into
R+, and the pointwise limits of sequences of these functions (see Feller
(1971)), where R = (−∞, ∞) and R+ = [0, ∞). Note that it includes
l.s.c. functions that arise in Section 4.4.
Let B1 be the subspace of
functions in B0 that are l.s.c. and of linear growth, i.e., 0 ≤b(i, x) ≤
Cb(1 + |x|) for some Cb > 0.
Next, we deﬁne various costs that are involved and the assumptions
they satisfy.
(i) For period k = 0, . . . , N −1 and demand state i = 1, . . . , L, let
Ki
k
=
the ﬁxed order cost in period k if ik = i, Ki
k ≥0,
ci
k
=
the variable order cost in period k if ik = i, ci
k ≥0,
ck(i, u)
=
Ki
k1Iu>0 + ci
ku, the cost of ordering u units in
period k if ik = i.
(4.3)

62
Discounted Cost Models with Lost Sales
(ii) The surplus cost in period k when ik = i and xk = x is denoted by
fk(i, x), and

fk(i, x) ∈B1, is convex and nondecreasing in x, and
fk(i, x) = 0, ∀x ≤0.
(4.4)
(iii) The shortage cost in period k when ik = i and xk = x is denoted
by qk(i, x), and we have

qk(i, x) ∈B1, is convex and nonincreasing in x, and
qk(i, x) = 0, ∀x ≥0.
(4.5)
(iv) Furthermore, for k ∈⟨0, N −1⟩,
ci
kx + Efk+1(i, x −ξk) →+∞as x →+∞.
(4.6)
With costs thus deﬁned, we can for any n, 0 ≤n ≤N, write the
objective function as
Jn(i, x; U)
=
E
 N−1

k=n
{ck(ik, uk) + fk(ik, xk) + qk(ik, xk + uk −ξk)}
+fN(iN, xN)|in = i, xn = x

,
(4.7)
where U = (un, . . . , uN−1) is an admissible history-dependent or nonan-
ticipative (order quantities) for the problem, and uk is a function of ik
and xk, k ∈⟨n, N−1⟩= {n, . . . , N−1}. The objective function Jn(i, x; U)
represents the cost to go from period n on with the initial conditions at
period n being i and x under the decision U. With U denoting the class
of all admissible decisions, we can deﬁne the value function vn(i, x) for
the problem over ⟨n, N⟩as
vn(i, x) = inf
U∈U Jn(i, x; U).
(4.8)
The dynamic programming equations for the model are deﬁned for
n ∈⟨0, N −1⟩and i = 1, 2, . . . , L as
vn(i, x)
=
fn(i, x) + inf
u≥0{cn(i, u) + E[qn(i, x + u −ξn)
(4.9)
+vn+1(in+1, (x + u −ξn)+)|in = i]},

MARKOVIAN DEMAND INVENTORY MODELS
63
and
vN(i, x) = fN(i, x),
i = 1, 2, . . . , L.
(4.10)
The existence of an optimal feedback policy can be established by
argument similar to those used in the backlog case treated in Chapter 2.
Therefore, we will state them without proof.
Theorem 4.1 (Veriﬁcation Theorem) The dynamic programming equa-
tions (4.10) and (4.10) deﬁne a sequence of functions vn(i, x) in B1.
Furthermore, there exists a function ˆun(i, x) in B1, which provides the
inﬁmum in (4.10) for any x, and ˆU = (ˆu0, ˆu1, . . . , ˆuN−1) is an optimal
decision for the problem J0(i, x; U). Moreover,
v0(i, x) = min
U∈U J0(i, x; U).
(4.11)
In simpler words, the theorem, called a veriﬁcation theorem, means
that there exists a policy in the class of all admissible (or history-
dependent) policies, whose objective function value equals the value
function deﬁned by (4.8). In addition, there is a Markov (or feedback)
policy which gives the same objective function value.
4.3.
Optimality of (s, S)-type Ordering Policies
The optimality of (s, S)-type policies has been established for stochas-
tic inventory models with various conditions on demand and cost func-
tions. A key concept used in proving the optimality of (s, S)-type policies
for standard models in the literature is K-convexity of a function, which
was ﬁrst utilized by Scarf (1960). Some useful properties of K-convex
functions are given in Section C.2.
The traditional deﬁnition of K-convex functions deﬁned on the real
line is extended in Section C.2 to include functions deﬁned on convex
subsets of the real line. Existing results on the properties of K-convex
functions are also generalized to allow for less restrictive assumptions
and more realistic features arising in inventory models. Based on these
results, the optimality of state-dependent (s, S) policies is established in
Markovian demand inventory models for the full backlog case.
However, in the lost sales case, the truncation due to lost sales requires
new conditions to be introduced to preserve K-convexity in the induction
step of the proof to establish the optimality of (s, S)-type policies. The
required K-convexity result is proved as Theorem C.2.4.
We now prove the optimality of (s, S)-type policies for the lost sales
case with the help of Theorem C.2.4.

64
Discounted Cost Models with Lost Sales
Theorem 4.2 In addition to Assumptions (i)-(iv) in Section 4.2, let for
each i ∈I and j ∈I,
Ki
n ≥¯Ki
n+1 ≡
L

j=1
pijKj
n+1 ≥0, n ∈⟨0, N −1⟩,
(4.12)
and
q
′−
n (i, 0) ≤f
′+
n+1(j, 0) −cj
n+1, n ∈⟨0, N −2⟩.
(4.13)
Then, there exists a sequence sn,i, Sn,i, with 0 ≤sn,i ≤Sn,i, j ∈I and
n ∈⟨0, N −1⟩, such that the feedback policy
ˆun(i, x) =

Sn,i −x,
for x < sn,i,
0,
for x ≥sn,i,
(4.14)
is optimal.
Proof. We can rewrite (4.10) as
vn(i, x)
=
fn(i, x) −ci
nx + inf
y≥x{Ki
n1Iy>x + ci
ny + E[qn(i, y −ξn)
+vn+1(in+1, (y −ξn)+)|in = i]},
x ≥0,
=
fn(i, x) −ci
nx + Hn(i, x),
x ≥0,
(4.15)
where for x ≥0,
Hn(i, x)
=
inf
y≥x≥0[Ki
n1Iy>x + Zn(i, y)],
(4.16)
Zn(i, x)
=
ci
nx + E [qn(i, x −ξn)
+ vn+1(in+1, (x −ξn)+)|in = i

.
(4.17)
Note that vn(i, x) is deﬁned for x ∈R+ = [0, ∞). In view of Theo-
rem C.2.3 with A = 0 and B = +∞, we need only to prove that
Zn(i, x) is l.s.c. and Ki
n-convex on R+ and
Zn(i, x) →+∞as x →+∞.
(4.18)
This is because with (4.16), (4.18), Theorem C.2.2(ii), and Theorem
C.2.3(iii), we can conclude vn(i, x) to be Ki
n-convex on R+. Since vN(i, x)
in (4.10) is convex by deﬁnition of fN(i, x), ZN−1(i, x) is convex and the
proof of the theorem follows from an induction argument beginning with
the premise that Zn+1(i, x) is Ki
n+1-convex on R+.
With regards to (4.18), note that Zn ∈B1 since vn ∈B1. Furthermore,
from Assumption (4.6) and the facts that vn+1 ≥fn+1 ≥0 in (4.17) and
qn(i, x) is nonincreasing in x, we have
Zn(i, x)
≥
ci
nx + qn(i, 0) + E
 
fn+1(in+1, (x −ξn)+)|in = i

→+∞,
as x →+∞.

MARKOVIAN DEMAND INVENTORY MODELS
65
Finally, to prove the Ki
n-convexity of Zn on R+, let us deﬁne
Qn(i, x) = qn(i, x) + ¯vn+1(i, x+),
(4.19)
where
¯vn+1(i, x) = E [vn+1(in+1, x)|in = i] =
L

j=1
pijvn+1(j, x).
Thus, we have
Zn(i, x)
=
ci
nx + E[Qn(i, x −ξn)|in = i]
=
ci
nx +
 ∞
0
Qn(i, x −ξ)ϕi,n+1(ξ)dξ.
Now we prove the Ki
n-convexity of Zn on R+ by induction. It is suﬃcient
to show that Qn(i, x) is ¯Ki
n+1-convex on R given the induction premise
that Zn+1(i, x) is Ki
n+1-convex on R+ for each j ∈I.
We note that if Zn+1(i, x) is Ki
n+1-convex on R+, then ¯vn+1(i, x) is
¯Ki
n+1-convex for x ∈R+ on account of Theorem C.2.3 and (4.3). In
the following, we will show that Qn(i, x) is ¯Ki
n+1-convex on R. This is
achieved by showing that qn(i, x) + vn+1(j, x+) is Kj
n+1-convex on R for
each j.
From the Kj
n+1-convexity of Zn+1(j, x) on R+ and Theorem C.2.3,
there exist sj
n+1 and Sj
n+1, Sj
n+1 ≥sj
n+1 ≥0, such that
vn+1(j, x) = fn+1(j, x)−cj
n+1x+

Kj
n+1 + Zn+1(j, Sj
n+1), if x < sj
n+1,
Zn+1(j, x),
if x ≥sj
n+1.
When sj
n+1 > 0, we in view of (4.13) have
v
′+
n+1(i, 0) = f
′+
n+1(j, 0) −cj
n+1 ≥q
′−
n (i, 0).
According to Theorem C.2.4, qn(i, x) + vn+1(j, x+) is Kj
n+1-convex on
R+.
When sj
n+1 = 0, we know that vn+1(j, x+) is Kj
n+1-convex for x ∈R+
given that Zn+1(j, x) is Kj
n+1-convex. Therefore, Qn(i, x) = qn(i, x) +
¯vn+1(i, x+) is ¯Ki
n+1-convex on R+. This completes the proof for the
theorem.
□
Remark 4.1 Assumption (4.6) is the same as (2.11) in Chapter 2; (see
Remark 2.1 for its meaning).

66
Discounted Cost Models with Lost Sales
Remark 4.2 Assumption (4.13) means that the marginal shortage cost
in one period is larger than or equal to the expected unit ordering cost
less the expected marginal inventory holding cost in any state of the
next period.
If this condition does not hold, that is, if −q
′−
n (i, 0) <
¯ci
n+1 −¯f
′+
n+1(i, 0) for some i, a speculative retailer may ﬁnd it attractive
to meet a smaller part of the demand in period n than is possible from
the available stock, carry the leftover inventories to period n + 1, and
order a little less as a result in period n + 1 with the expectation that
he will be better oﬀ. Thus, Assumption (4.13) rules out this kind of
speculation on the part of the retailer. But such a speculative behavior
is not allowed in our formulation of the dynamics (4.2) in any case,
since the demand in any period must be satisﬁed to the extent of the
availability of inventories.
This suggests that it might be possible to
prove Theorem 4.2 without (4.13). Moreover, our proof relies on the K-
convexity of the value function, whereas this property is only a suﬃcient
condition and not necessary for the optimality of an (s, S) policy.
Theorem 4.2 extends the analysis carried out in Chapter 2 to the lost
sales case with zero leadtime and additional minor restrictions on the
cost structure. In the backlog case, the mathematical analysis based
on the zero leadtime assumption can be extended easily to the nonzero
leadtime case by replacing the inventory level with the inventory posi-
tion, which is the sum of the inventory on-hand and amounts on order.
But the relationship between the inventory position, the inventory on-
hand, and amounts on order is not straightforward in the lost sales case.
Therefore, we cannot claim that the same results will hold for the lost
sales case with nonzero leadtime.
4.4.
Extensions
The model formulated and analyzed in Sections 4.2 and 4.3 can be ex-
tended to incorporate some additional constraints and realistic features
that often arise in practice. It can be shown that (s, S)-type policies
continue to remain optimal for the extended models. In the following,
we brieﬂy describe the new features in these extensions.
4.4.1
Supply Uncertainty
We model supply uncertainty by replacing the demand state i with a
demand/supply state i = (id, is), where id denotes the demand state and
is denotes the supply state. We also redeﬁne I to denote the set of all
possible demand/supply states. Let rk be a random variable representing
the availability of the supply in period k. If the supply is available in
period k, then rk = 1; otherwise, rk = 0. Therefore, the inventory

MARKOVIAN DEMAND INVENTORY MODELS
67
balance equations are given by
xk+1 = (xk + rk · uk −ξk)+, k ∈⟨n, N −1⟩.
We further assume that the probability of supply being available in pe-
riod k with the demand/supply state i is Rki, i.e.,
P(rk = 1|ik = i) = Rki, k ∈⟨0, N⟩, i ∈I,
with 0 ≤Rki ≤1. Accordingly, the dynamic programming equations of
the value functions should be revised as
vn(i, x)
=
fn(i, x) + (1 −Rn,i)E[qn(i, x −ξn+1)
+vn+1(in+1, (x −ξn)+)|in = i]
+Rn,i inf
u≥0 {cn(i, u) + E[qn(i, x + u −ξn)
+ vn+1(in+1, (x + u −ξn)+)|in = i]

.
(4.20)
Theorem 4.3 In the inventory problem with the dynamic programming
equations deﬁned by (4.20), the optimal policy is still of (s, S)-type.
Proof. First, note that the ﬁrst two items in the braces of (4.20) are
independent of u. Also, in a way similar to the proof of Theorem 4.2, one
can easily verify that the sum of these items is Ki
n-convex with respect
to x. The rest of the proof is straightforward in view of the proof of
Theorem 4.2.
□
4.4.2
Storage and Service Level Constraints
Following the same deﬁnition in Section 2.8.2 of Chapter 2, we let
B < ∞be the storage capacity, and Ai
k be the safety stock level in period
k with the demand state i. Thus, the inventory position is restricted by
the lower bound Ai
k and the upper bound B such that
Ai
k ≤xk + uk ≤B.
(4.21)
The dynamic programming equations can be written as (2.22), where
zn(i, y) is as in (2.22) and
hn(i, x) =
inf
y≥x,Ain≤y≤B[Ki
n1Iy>x + zn(i, y)],
(4.22)
provided Ai
n ≤B, n ∈⟨0, N −1⟩, i ∈I; if not, then there is no feasible
solution, and hn(i, x) = inf Ø ≡∞. Furthermore, a veriﬁcation theorem
can also be obtained for the constrained case; (see Bertsekas and Shreve
(1976)).

68
Discounted Cost Models with Lost Sales
Theorem 4.4 Assume Ai
n ≤B, n ∈⟨0, N−1⟩, i ∈I. Then, there exists
a sequence of numbers sn,i, Sn,i, n ∈⟨0, N−1⟩, i ∈I, with sn,i ≤Sn,i and
Ai
n ≤Sn,i ≤B such that the optimal feedback policy is
ˆun(i, x) =

Sn,i −x,
for
x < sn,i,
0,
for
x ≥sn,i,
(4.23)
for the model with capacity and service constraints deﬁned above.
Proof. The proof is similar to the proof for Theorem 2.8.
□
4.4.3
The Inﬁnite Horizon Model
The extension of the Markovian demand model with the lost sales
assumption to the inﬁnite horizon case can be obtained in the same way
as the inﬁnite horizon model presented in Chapter 2, Section 2.6. Par-
ticularly, let us assume that the cost functions and the density functions
are independent of time, i.e.,
fk(i, x) = f(i, x), qk(i, x) = q(i, x), ϕi,k = ϕi,
and
ck(i, x) = c(i, x) = K1Iu>0 + ciu, i ∈I, k = 0, 1, 2, . . . .
It is important to observe that the ﬁxed ordering cost K is independent of
the state i as well, so that Assumption (4.13) holds. Thus, the dynamic
programming equations become
v(i, x)
=
f(i, x) + inf
u≥0{c(i, u) + E[q(i, x + u −ξi)
+α
L

j=1
pijv(j, (x + u −ξi)+)]},
(4.24)
where α is a given discount factor, 0 < α ≤1, ξi is a random variable
with density function ϕi(·), and v(i, x) is the value function in any pe-
riod with initial inventory x and demand state i. Therefore, the optimal
inventory policies also become stationary, i.e., independent of period k.
Theorem 4.5 In the inﬁnite horizon inventory problem with the lost
sales assumption and the stationary cost and density functions, the op-
timal inventory control policy is given by
ˆu(i, x) =

Si −x,
for
x < si,
0,
for
x ≥si.
(4.25)
Proof. The proof is similar to that of Theorem 2.5.
□

MARKOVIAN DEMAND INVENTORY MODELS
69
The optimality of (s, S)-type policies for each of the above extended
models can be established in a way similar to that in Chapter 2 with
appropriate modiﬁcations for the lost sales situation. It should be noted
that for the inﬁnite horizon problem, the optimal policy parameters Si
and si are dependent only on the demand state i, and not on time.
4.5.
Numerical Results
The purpose of this numerical study is twofold. First, by providing
the algorithms and the computational results, we show that the theoreti-
cal results derived in the previous chapters are computationally feasible,
and therefore, can be applied to solving real-world problems. Also, by
comparing the performance of the results obtained from our models with
that obtained based on the standard models reported in the literature,
we demonstrate the advantages that can be achieved by Markovian de-
mand models.
From a computational point of view, in order to obtain an optimal
policy, it is necessary to solve the DP equations numerically. We have
used continuous inventory state models throughout our analysis in the
book. A discretization procedure will be necessary to make the com-
putation tractable. Technical issues regarding the convergence of dis-
cretization procedures have been dealt with by Bertsekas (1976), for
example. Under certain technical assumptions, a discretization proce-
dure is shown to be stable in the sense that it yields suboptimal policies
whose performance approaches the optimal value of the objective func-
tion arbitrarily closely as the discretization grids become ﬁner and ﬁner.
Moreover, such discretization is always justiﬁed in practice since both
demands and orders are in quantities of integer numbers. In particular,
in a practical problem, the control space is always a compact set. This
observation greatly simpliﬁes the convergence problems associated with
the discretization procedures.
We have established the optimality of an (s, S)-type policy for Marko-
vian demand models with the lost sales assumption. Nevertheless, their
computation is another matter. For the ﬁnite horizon models, we know
that optimal policies are nonstationary even when all the system param-
eters (costs, density functions, etc.) are time-invariant. Computation
has to be carried out for each period in the ﬁnite time horizon. Usually,
this is done using a backward dynamic programming algorithm. Since
computation in the ﬁnite horizon is rather straightforward, we will focus
on the computation for the inﬁnite horizon models.
It is clear that for inﬁnite horizon problems, computation of the op-
timal policy is intractable since it would require an inﬁnite pair of num-
bers (sn, Sn), n = 1, 2, . . . , to be speciﬁed. Moreover, the computation

70
Discounted Cost Models with Lost Sales
of each (sn, Sn) pair is based on the information about demands for the
entire remaining inﬁnite horizon. Therefore, we will only consider the
computation for stationary inﬁnite horizon models.
The algorithm we use for solving dynamic programming equations is
essentially a modiﬁed value iteration algorithm. In the ﬁnite horizon
case, the optimal policies can be computed in a ﬁnite number of iter-
ations, which are equal to the number of periods of the problem. In
the inﬁnite horizon case with stationary data, it can be shown that the
algorithm converges to an optimal policy; (see, e.g., Bertsekas (1976)).
Tables 4.1 and 4.2 list the numerical results obtained by the algo-
rithm. For comparison purposes, we also compute the cost functions
under a standard stationary (s, S) policy obtained without the consider-
ation of the demand state variables as in Karlin and Fabens (1960), i.e,
the decision space is restricted within the set of stationary (s, S) poli-
cies. In order to compute the stationary (s, S) policies, we ﬁrst obtain
the steady-state distribution of the demand state; hence, the limiting
stationary demand distribution. The cost functions are then computed
based on the stationary demand distribution. This approximating ap-
proach will enable one to obtain a stationary (s, S) policy. However,
such a stationary (s, S) policy would be theoretically inferior to our
state-dependent (s, S) policy as it is not optimal for the Markovian de-
mand model. In fact, our numerical results conﬁrm this assertion.
The results listed in Tables 4.1 and 4.2 show that a signiﬁcant improve-
ment is achieved by adopting a state-dependent (s, S) policy. A group
of uniform distributions are used for the cases in Table 4.1, and trun-
cated normal distributions are used in Table 4.2. The number of demand
states L = 3 in all cases. The parameters c, K, α, h, and p are the unit
purchase cost, the setup cost, the discount factor, the unit holding cost,
and the unit shortage cost, respectively. The values (si, Si), i = 1, 2, 3,
are optimal parameters computed based on our Markovian model, and
(s, S)KF is the parameter of the stationary (s, S) policy obtained based
on the model of Karlin and Fabens (KF).

MARKOVIAN DEMAND INVENTORY MODELS
71
Case
c
K
α
h
p
(s1, S1) (s2, S2) (s3, S3) (s, S)KF
1.1
0.50
1.0
0.90
1.00
5.00
7,9
13,15
18,20
14,16
1.2
0.50
1.5
0.90
1.00
5.00
6,9
12,15
17,20
13,17
1.3
1.00
2.0
0.90
1.00
5.00
5,8
11,14
16,19
12,16
1.4
0.50
2.0
0.90
1.00
2.00
3,8
9,14
14,19
8,14
1.5
0.50
2.0
0.90
1.00
1.00
0,0
4,11
9,16
1,10
1.6
0.50
2.0
0.95
1.00
2.00
3,8
9,14
14,19
8,13
1.7
0.50
2.0
0.85
1.00
2.00
3,8
9,14
14,19
8,14
1.8
1.00
2.0
0.90
1.00
2.00
0,0
6,11
11,16
5,12
1.9
1.00
5.0
0.90
1.00
2.00
0,0
3,11
8,16
2,13
1.10
2.00
5.0
0.90
1.00
2.00
0,0
0,0
0,0
0,0
1.11
2.50
5.0
0.90
1.00
2.00
0,0
0,0
0,0
0,0
1.12
1.00
5.0
0.90
2.00
4.00
2,8
8,14
13,19
7,14
1.13
1.00
5.0
0.90
1.00
4.00
2,8
8,14
13,19
9,16
Table 4.1.
Numerical results for the lost sales model with uniform demand distribu-
tion.
Case
c
K
α
h
p
(s1, S1) (s2, S2) (s3, S3) (s, S)KF
2.1
0.50
1.0
0.90
1.00
5.00
11,14
15,18
16,19
14, 17
2.2
0.50
1.5
0.90
1.00
5.00
10,14
14,18
16,19
14, 17
2.3
1.00
2.0
0.90
1.00
5.00
9,12
13,16
15,18
13, 17
2.4
0.50
2.0
0.90
1.00
2.00
7,12
10,16
14,17
10, 15
2.5
0.50
2.0
0.90
1.00
1.00
2,9
5,13
10,16
4, 12
2.6
0.50
2.0
0.95
1.00
2.00
7,12
10,16
14,17
10, 15
2.7
0.50
2.0
0.85
1.00
2.00
7,12
10,16
14,17
10, 15
2.8
1.00
2.0
0.90
1.00
2.00
4,9
8,13
12,16
8, 14
2.9
1.00
5.0
0.90
1.00
2.00
1,9
4,13
9,16
4, 14
2.10
2.00
5.0
0.90
1.00
2.00
0,0
0,0
0,0
0, 0
2.11
2.50
5.0
0.90
1.00
2.00
0,0
0,0
0,0
0, 0
2.12
1.00
5.0
0.90
2.00
4.00
6,12
10,16
13,17
9, 15
2.13
1.00
5.0
0.90
1.00
4.00
6,12
10,16
13,17
10, 16
Table 4.2.
Numerical results for the lost sales model with truncated normal demand
distribution.
In Figures 4.1-4.8, we also plot the curves of the value functions for
Cases 1.1-1.4 in Table 4.1 and Cases 2.1-2.4 in Table 4.2. The solid lines
are the value functions v(i, x) using the optimal policies (OP) based on
the Markovian demand model, and the dotted lines are the correspond-

72
Discounted Cost Models with Lost Sales
ing value functions using a stationary (s, S) policy obtained according to
the KF model. We observe from these ﬁgures that the state-dependent
(s, S) policies perform better than the stationary (s, S) policies.
4.6.
Concluding Remarks and Notes
The chapter, based on Cheng and Sethi (1999b) and Cheng (1996),
extends the Markovian demand models to incorporate the case in which
any unsatisﬁed demand is lost rather than backlogged. Our treatment
of this case excludes some of the assumptions on the growth rate of the
cost functions made in the literature. It is shown that like stochastic
inventory models with backorders, the lost sales model with Markovian
demands exhibits optimality of state-dependent (s, S) policies.
We also carry out a computational study to compare the performance
of the optimal state-dependent (s, S) policies over the optimal standard
(s, S) policies.
We have pointed out that the results for the lost sales case are obtained
under the condition of zero ordering leadtime. With nonzero leadtimes,
the optimality of (s, S)-type policies obtained in the backlog case do not
hold for the lost sales case.

MARKOVIAN DEMAND INVENTORY MODELS
73
80
100
120
140
160
180
200
220
0
5
10
15
20
25
30
35
40
v(i, 1)
x
OP
KF
90
100
110
120
130
140
150
160
170
180
190
0
5
10
15
20
25
30
35
40
v(i, 2)
x
OP
KF
100
110
120
130
140
150
160
170
180
0
5
10
15
20
25
30
35
40
v(i, 3)
x
OP
KF
Figure 4.1.
Results for Case 1.1.

74
Discounted Cost Models with Lost Sales
80
100
120
140
160
180
200
220
0
5
10
15
20
25
30
35
40
v(i, 1)
x
OP
KF
100
110
120
130
140
150
160
170
180
190
0
5
10
15
20
25
30
35
40
v(i, 2)
x
OP
KF
100
110
120
130
140
150
160
170
180
0
5
10
15
20
25
30
35
40
v(i, 3)
x
OP
KF
Figure 4.2.
Results for Case 1.2.

MARKOVIAN DEMAND INVENTORY MODELS
75
140
150
160
170
180
190
200
210
220
230
240
0
5
10
15
20
25
30
35
40
v(i, 1)
x
OP
KF
150
160
170
180
190
200
210
220
230
0
5
10
15
20
25
30
35
40
v(i, 2)
x
OP
KF
160
170
180
190
200
210
220
0
5
10
15
20
25
30
35
40
v(i, 3)
x
OP
KF
Figure 4.3.
Results for Case 1.3.

76
Discounted Cost Models with Lost Sales
90
100
110
120
130
140
150
160
170
180
190
200
0
5
10
15
20
25
30
35
40
v(i, 1)
x
OP
KF
90
100
110
120
130
140
150
160
170
180
0
5
10
15
20
25
30
35
40
v(i, 2)
x
OP
KF
100
110
120
130
140
150
160
170
0
5
10
15
20
25
30
35
40
v(i, 3)
x
OP
KF
Figure 4.4.
Results for Case 1.4.

MARKOVIAN DEMAND INVENTORY MODELS
77
110
120
130
140
150
160
170
180
0
5
10
15
20
25
30
35
40
v(i, 1)
x
OP
KF
110
120
130
140
150
160
170
180
0
5
10
15
20
25
30
35
40
v(i, 2)
x
OP
KF
110
120
130
140
150
160
170
0
5
10
15
20
25
30
35
40
v(i, 3)
x
OP
KF
Figure 4.5.
Results for Case 2.1.

78
Discounted Cost Models with Lost Sales
110
120
130
140
150
160
170
180
190
0
5
10
15
20
25
30
35
40
v(i, 1)
x
OP
KF
110
120
130
140
150
160
170
180
0
5
10
15
20
25
30
35
40
v(i, 2)
x
OP
KF
110
120
130
140
150
160
170
0
5
10
15
20
25
30
35
40
v(i, 3)
x
OP
KF
Figure 4.6.
Results for Case 2.2.

MARKOVIAN DEMAND INVENTORY MODELS
79
170
180
190
200
210
220
230
0
5
10
15
20
25
30
35
40
v(i, 1)
x
OP
KF
175
180
185
190
195
200
205
210
215
220
0
5
10
15
20
25
30
35
40
v(i, 2)
x
OP
KF
180
185
190
195
200
205
210
215
0
5
10
15
20
25
30
35
40
v(i, 3)
x
OP
KF
Figure 4.7.
Results for Case 2.3.

80
Discounted Cost Models with Lost Sales
100
110
120
130
140
150
160
170
180
0
5
10
15
20
25
30
35
40
v(i, 1)
x
OP
KF
100
110
120
130
140
150
160
170
0
5
10
15
20
25
30
35
40
v(i, 2)
x
OP
KF
100
110
120
130
140
150
160
170
0
5
10
15
20
25
30
35
40
v(i, 3)
x
OP
KF
Figure 4.8.
Results for Case 2.4.

Chapter 5
AVERAGE COST MODELS WITH
BACKORDERS
5.1.
Introduction
This chapter is devoted to the study of a stochastic inventory problem
with Markovian demand and ﬁxed cost from the viewpoint of minimiz-
ing the long-run average cost of inventory/backlog and ordering. The
purpose is to establish the dynamic programming equation or average
cost optimality equation for the problem, prove the existence of an op-
timal feedback (or Markov) policy, and show that a feedback policy of
(s, S)-type is optimal.
A Markov chain, whose states represent possible states of the envi-
ronment or the economy, underlies the Markovian demand process in
the sense that the distribution of the demand in any given period de-
pends on the environmental state in that period. Furthermore, these
states may also aﬀect various cost parameters in the model. Problems
with Markovian demand and ﬁxed costs were considered in Part II, but
only with the discounted cost criterion. There, we rigorously established
the existence of an optimal state-dependent (s, S) policy. Results from
Chapter 2 that we need for our analysis of the average cost problems are
recapitulated in Section 5.3.
The problems of long-run average cost minimization are mathemati-
cally much harder than those with discounted costs; (see Arapostathis
et al.
(1993) for a survey of discrete-time average cost problems). In
the context of inventory problems, Iglehart (1963b) and Veinott and
Wagner (1965) were the ﬁrst to study the issue of the existence of an
optimal (s, S) policy for average cost problems with independent de-
mands, linear holding and backlog costs, and ordering costs consisting
of a ﬁxed cost and a proportional variable cost. Iglehart obtained the
D. Beyer et al., Markovian Demand Inventory Models, International Series
83
in Operations Research & Management Science 108,
DOI 10.1007/978-0-387-71604-6 5, c⃝Springer Science+Business Media, LLC 2010

84
Average Cost Models with Backorders
stationary distribution of the inventory/backlog (or surplus) level given
an (s, S) policy using renewal theory arguments (see also Karlin (1958a)
and Karlin (1958b)), and developed an explicit formula for the stationary
average cost L(s, S), s ≤S, associated with the policy. His subsequent
analysis is carried out under the assumption that L(s, S) is continuously
diﬀerentiable and that there exists a pair (s∗, S∗), s∗< S∗, which mini-
mizes L(s, S) and satisﬁes the ﬁrst-order conditions for a local minimum.
While he does not specify these assumptions explicitly, he uses them in
showing the key result that the minimum average cost of ﬁnite horizon
problems approaches L(s∗, S∗) asymptotically as the horizon becomes
inﬁnitely large.
Veinott and Wagner deal with the case of discrete demands. With an
additional argument suggested by Derman (1965), they were able to con-
vert the Iglehart result, under the same assumptions on L(s, S), into the
optimality of the (s∗, S∗) policy; (see also Veinott (1966)). It should be
noted that Veinott and Wagner, dealing with discrete demands, require
a discrete demand version of the results in Iglehart.
A great deal of research has been carried out in connection with the
average cost (s, S) models since then.
With the exception of Zheng
(1991) and Huh et al. (2008), most of the research is concerned with the
computation of (s∗, S∗) that minimizes L(s, S), and not with the issue
of establishing the optimality of an (s, S)-type policy. The examples are
Stidham (1977), Zheng and Federgruen (1991), Federgruen and Zipkin
(1984), Hu et al. (1993), and Fu (1994). For other references, the reader
is directed to Porteus (1985), Sahin (1990), and Zheng and Federgruen
(1991). Furthermore, this literature has assumed that taken together,
the papers of Iglehart (1963b) and Veinott and Wagner (1965) have
established the optimality of an (s, S) policy for the problem. This is
not quite the case, however, since the assumptions on L(s, S) implicit in
Iglehart (1963b), to our knowledge, have not been satisfactorily veriﬁed.
In Chapter 9 based on Beyer and Sethi (1999), we discuss these issues in
detail, as well as derive the required results that are missing in Iglehart
(1963b).
Zheng (1991) has provided a rigorous proof of the optimality of an
(s, S)-type policy in the case of discrete demands. He was able to use
the theory of countable state Markov decision processes in the case when
the solution of the average cost optimality equation for the given prob-
lem is bounded, which is clearly not the case since the inventory cost is
unbounded. So, he relaxed the problem by allowing inventory disposals,
and since the inventory costs are charged on ending inventories in his
problem (see Remark 5.3), he obtained a bounded solution for the av-

MARKOVIAN DEMAND INVENTORY MODELS
85
erage cost optimality equation of the relaxed problem, which involves a
dispose-down-to-S component. But the dispose-down-to-S component
of the optimal policy would be invoked in the relaxed problem only in
the ﬁrst period (and only when the initial inventory is larger than S),
which has no inﬂuence on the long-run average cost of the policy. It
therefore follows that the (s, S) policy, without the dispose-down-to-S
component, will also be optimal for the original problem.
More importantly for the purpose of this chapter, the methodology of
Iglehart (1963b) and Veinott and Wagner (1965) crucially depends on
being able to obtain the stationary distribution of the surplus variable,
and thus on the speciﬁcs of the problem. For more general problems
such as the one involving Markovian demand considered in this chapter,
where it may not be possible to explicitly obtain the stationary distri-
bution of the state variables of the system, a general methodology is
required. Also, the disposal device used by Zheng (1991) does not work
in the case of Markovian demand. Furthermore, without establishing a
bounded solution of the average cost optimality equation, the optimality
conditions established in the theory of Markov decision processes are, in
Zheng’s own words, tedious to verify.
The problem under consideration in this chapter involves a Borel state
space, a noncompact action set, and unbounded costs, the study of which
has begun only recently and is far from complete. The general results
obtained to date involve restrictive and diﬃcult to verify conditions;
(see Arapostathis et al.
(1993)). Thus, it is important to study spe-
cial problems of this kind. Sethi et al. (2005a) have used the vanishing
discount approach for optimization of continuous-time stochastic man-
ufacturing systems with unreliable machines. They require the concept
of viscosity solutions to the average cost optimality equation because of
the continuous-time nature of their model.
In this chapter, we use a vanishing discount approach to study the
long-run average cost problem with Markovian demand, ﬁxed ordering
cost, and convex surplus cost. The idea is to use the results obtained
in Chapter 2 for the discounted cost inﬁnite horizon problem and ana-
lyze them as the discount factor approaches one. In order to use this
procedure, we impose an additional condition for the demands to be
uniformly bounded. The unique features of our average cost problem
are the Markovian demand and the ﬁxed ordering cost. Presence of the
latter renders the value functions involved to be nonconvex, and thus
harder to handle as also mentioned in Iglehart (1963b).
The plan of this chapter is as follows. In the next section, we provide
a precise formulation of the problem. Relevant results for the discounted
cost problem obtained in Chapter 2 are summarized in Section 5.3. The

86
Average Cost Models with Backorders
asymptotic behavior of the diﬀerential discounted value function, as the
discount rate approaches zero, is obtained in Section 5.4. In Section 5.5,
we develop the vanishing discount approach to establish the average
cost optimality equation. The associated veriﬁcation theorem is proved
in Section 5.6, and the theorem is used to show that a state-dependent
(s, S) policy is optimal for the problem. Section 5.7 concludes the chap-
ter with suggestions for future research.
5.2.
Formulation of the Model
In order to specify the stationary, discrete-time, inﬁnite horizon inven-
tory problem under consideration, we introduce the following notation
and basic assumptions.
(Ω, F, P)
=
the probability space;
I
=
{1, 2, . . . , L}, ﬁnite collection of possible demand states;
ik
=
the demand state in period k, k ∈Z = {0, 1, 2, . . .};
{ik}
=
a Markov chain with the (L × L)-transition matrix
P = {pij};
ξk
=
the demand in period k; it depends on ik but not on
k, and is independent of past demand states and
past demands;
ϕi(·)
=
the conditional density function of ξk when ik = i;
Φi(·)
=
the distribution function corresponding to ϕi;
uk
=
the nonnegative order quantity in period k;
xk
=
the surplus (inventory/backlog) level at the
beginning of period k (or, at the end of period k −1);
c(i, u)
=
the cost of ordering u≥0 units in period k when ik =i;
f(i, x)
=
the surplus cost when ik = i and xk = x; fk(i, 0) ≡0.
We suppose that orders are placed at the beginning of a period, delivered
instantaneously, and followed by the period’s demand; (see Figure 2.1 in
Chapter 2). Unsatisﬁed demands are fully backlogged.
In what follows, we list the assumptions that are needed to derive the
main results of the chapter in Sections 5.5 and 5.6. Because not all the
results proved in this chapter require all of these assumptions, we label
them as follows for ease of specifying the assumptions required in the
statements of the speciﬁc results proved in this chapter.

MARKOVIAN DEMAND INVENTORY MODELS
87
(i) The production cost is given by c(i, u) = K1Iu>0 + ciu, where the
ﬁxed ordering cost is denoted by K ≥0 and the variable cost by
ci ≥0.
(ii) For each i, the surplus cost function f(i, ·) is convex and asymp-
totically linear, i.e., f(i, x) ≤C(1 + |x|) for some C > 0. Also,
f(i, 0) = 0.
(iii) There is a state l ∈I such that f(l, x) is not identically zero for
x ≤0.
(iv) There is a state g ∈I such that f(g, x) is not identically zero for
x ≥0.
(v) The production and inventory costs satisfy
cix +
L

j=1
pij
∞

0
f(j, x −z)dΦi(z) →∞as x →∞.
(5.1)
(vi) The Markov chain (ik)∞
k=0 is irreducible.
(vii) There is a state h ∈I such that 1 −Φh(ε) = ρ > 0 for some ε > 0.
(viii) There is an M, 0 < M < ∞, such that 0 ≤ξk ≤M, a.s.
Remark 5.1 Assumptions (i) and (ii) reﬂect the usual structure of the
production and inventory costs to prove the optimality of an (si, Si) pol-
icy. Note that K is the same for all i. In the stationary case, this is equiv-
alent to the condition (2.18) required in the nonstationary model for the
existence of an optimal (si, Si) policy; (see Chapter 2). Assumptions (iii)
and (iv) rule out trivial cases which lead to degenerate optimal policies.
In fact, if Assumption (iii) is violated, the optimal policy is never to
order. If Assumption (iii) holds and Assumption (iv) is violated, it is
optimal to wait for a period with a demand state for which ci is minimal
and then to order an inﬁnite amount. Assumption (v) means that either
the unit ordering cost ci > 0 or the second term in (5.1), which is the
expected holding cost, or both, go to inﬁnity as the surplus level x goes
to inﬁnity. While related, Assumption (v) neither implies nor is implied
by Assumption (iv). Assumption (v) is borne out of practical consid-
erations and is not very restrictive. In addition, it rules out unrealistic
trivial cases such as the one with ci = 0 and f(i, x) = 0, x ≥0, for
each i, which implies ordering an inﬁnite amount whenever an order is
placed. Assumptions (iv) and (v) generalize the usual assumption made
by Scarf (1960) and others, that the unit inventory holding cost h > 0.

88
Average Cost Models with Backorders
Remark 5.2 Assumptions (vi) and (vii) are needed to deplete any given
initial inventory in a ﬁnite expected time. While Assumption (vii) says
that in at least one state h, the expected demand is strictly larger than
zero, Assumption (vi) implies that the state h would occur inﬁnitely
often with ﬁnite expected intervals between successive occurrences. As-
sumption (viii) requires that the demand to be bounded is realistic. At
any rate, it is not a crucial assumption, since it could be replaced by a
growth condition on the distribution functions. Moreover, it does sim-
plify the proofs considerably.
The objective is to minimize the expected long-run average cost
J(i, x; U) = lim sup
N→∞
1
N E

N−1

k=0
[c(ik, uk) + f(ik, xk)]

,
(5.2)
with i0 = i and x0 = x, where U = (u0, u1, . . .), ui ≥0, i = 0, 1, . . . , is a
history-dependent or nonanticipative decision (order quantities) for the
problem. Such a control U is termed admissible. Let U denote the class
of all admissible controls. The surplus balance equations are given by
xk+1 = xk + uk −ξk, k = 0, 1, . . . .
(5.3)
Our aim is to show that there exist a constant λ∗termed the optimal
average cost, which is independent of the initial i and x, and a control
U∗∈U such that
λ∗= J(i, x; U∗) ≤J(i, x; U),
for all
U ∈U,
(5.4)
and
λ∗= lim
N→∞
1
N E

N−1

k=0
[c(ik, u∗
k) + f(ik, x∗
k)]

,
(5.5)
where x∗
k, k ∈Z, is the surplus process corresponding to U∗with i0 = i
and x0 = x.
To prove these results we will use the vanishing discount approach.
That is, by letting the discount factor α in the discounted cost problem
approach one, we will show that we can derive a dynamic programming
equation whose solution provides an average optimal control and the
associated minimum average cost λ∗.
For this purpose, we recapitulate relevant results for the discounted
cost problem obtained in Chapter 2.
Remark 5.3 Note that the objective function (5.2) is slightly, but not
essentially, diﬀerent from that used in the classical literature. Whereas

MARKOVIAN DEMAND INVENTORY MODELS
89
we base the surplus cost on the initial surplus in each period, the usual
practice in the literature is to charge the cost on the ending surplus levels,
which means to have f(ik, xk+1) instead of f(ik, xk) in (5.2). Note that
xk+1 is also the ending inventory in period k. It should be obvious that
this diﬀerence in the objective functions does not change the long-run
average cost for any admissible policy.
5.3.
Discounted Cost Model Results from
Chapter 2
Consider the model formulated above with the average cost objective
(5.2) replaced by the extended real-valued objective function
Jα(i, x; U) =
∞

k=0
αkE[c(ik, uk) + f(ik, xk)],
0 ≤α < 1.
(5.6)
Deﬁne the value function with i0 = i and x0 = x as
vα(i, x) = inf
U∈U Jα(i, x; U).
(5.7)
Let B0 denote the class of all continuous functions from I × R into
[0, ∞), and the pointwise limits of sequences of these functions; (see
Feller (1971)). Note that it includes piecewise-continuous functions. Let
B1 denote the space of functions in B0 that are of linear growth, i.e., for
any b ∈B1, 0 ≤b(i, x) ≤Cb(1 + |x|) for some Cb > 0. Let B2 denote the
subspace of functions in B1 that are uniformly continuous with respect
to x ∈R. For any b ∈B1, we deﬁne the notation
Fb(i, y) =
L

j=1
pij

M
0
b(j, y −z)dΦi(z).
(5.8)
The following results for the more general case of nonstationary cost
functions are proved in Chapter 2 for α > 0; (see Theorems 2.4 and 2.5).
Theorem 5.1 Let Assumptions (i), (ii), (v) and (vi) hold. Then, we
have the following.
(a) The value function vα(·, ·) is in B2 and is the unique solution of
the dynamic programming equation
vα(i, x) = f(i, x) + inf
u≥0{c(i, u) + αF(vα)(i, x + u)}.
(5.9)
(b) vα(i, ·) is K-convex and there are real numbers (sα
i , Sα
i ), sα
i ≤Sα
i ,
i ∈I, such that the feedback policy ˆuα
k(i, x) = (Sα
i −x)1Ix<sα
i is optimal.

90
Average Cost Models with Backorders
Hereafter, we will omit the additional superscript α on the control
policies for ease of notation. Thus, for example, ˆuα
k(i, x) will be denoted
simply as ˆuk(i, x). Since we do not consider the limits of the control
variables as α →1, the practice of omitting the superscript α will not
cause any confusion. In any case, the dependence of controls on α will
always be clear from the context.
5.4.
Limiting Behavior as the Discount Factor
Approaches 1
To insure a “smooth” limiting behavior for α →1, we prove in
Lemma 5.3 that vα(i, ·) is locally equi-Lipschitzian.
To do so, some
preliminary results are needed.
For any y > 0, deﬁne
τy := min{n :
n

k=0
ξk ≥y}
(5.10)
to be the ﬁrst index for which the cumulative demand is not less than
y.
Lemma 5.1 Let Assumptions (vi) and (vii) hold. Then, El(τy) < ∞,
where
El(η) = E(η|i0 = l).
(5.11)
Proof. We ﬁrst show that El(τε) < ∞for ε > 0 deﬁned in Assump-
tion (vii) and any l. Let ψn := n
k=0 ξk. Clearly, τε is a nonnegative
integer random variable, and therefore it is
El(τε) =
∞

k=0
P(τε > k|i0 = l) =
∞

k=0
P(ψk < ε | i0 = l).
In view of Assumption (vi), we can apply Theorem B.6.3 and see that
there exists a stationary distribution ν = (ν1, ν2, . . . , νL) with νi > 0,
i = 1, 2, . . . , L. From Theorem B.6.4, we see that there is an N such
that
P(ik = i for some k ∈⟨0, N−1⟩| i0 = l) ≥νi/2,
i = 1, 2, . . . , L. (5.12)
Deﬁne ψa := (a+1)N−1
k=aN
ξk for any nonnegative integer a. By (5.12) and
Assumption (vii), we have
P(ψj ≥ε | i0 = l)
≥
P(ξk ≥ε and ik−1 = h for some
k ∈⟨jN, (j + 1)N −1⟩| i0 = l)
≥
ρνh/2.

MARKOVIAN DEMAND INVENTORY MODELS
91
Thus,
P(ψj < ε | i0 = l) = 1 −P(ψj ≥ε | i0 = l) ≤1 −ρνh/2.
(5.13)
Since the set {ψaN < ε} ⊂{ψ0 < ε, ψ1 < ε, . . . , ψa < ε}, we have
P(ψaN < ε | i0 = l)
≤
P(ψ0 < ε, ψ1 < ε, . . . , ψa < ε | i0 = l)
≤
(1 −ρνh/2)a.
From the decreasing property of P(ψk < ε | i0 = l) with respect to k, we
obtain
El(τε)
=
∞

a=0
(a+1)N−1

k=aN
P(ψk < ε | i0 = l)
≤
∞

a=0
(a+1)N−1

k=aN
P(ψaN < ε | i0 = l)
≤
N
∞

a=0
(1 −ρνh/2)a = 2N/ρνh < ∞.
To prove the ﬁniteness of El(τy), we ﬁrst show that El(τnε) < ∞for
each l ∈I. We have already proved this for n = 1. Assume that it is true
for n = k, i.e., El(τkε) < ∞for each l ∈I. Then we have
El(τ(k+1)ε) ≤El(τkε) + max
j∈I {Ej(τε)} < ∞,
and, therefore, by induction El(τnε) < ∞. Obviously, El(τy) is increasing
in y. Choosing m ≥y/ε, we ﬁnally obtain El(τy) ≤El(τmε) < ∞.
□
If the ordering cost function in the demand state i has the form
c(i, u) = K1Iu>0 + ciu, we know from Chapter 2 that in the station-
ary case, an (si, Si) policy is optimal.
Lemma 5.2 Under Assumptions (i)-(iii) and (v)-(viii), there are real
numbers 0 < α0 < 1 and C2 > −∞such that maxi∈I{sα
i } ≥C2 for all
1 > α ≥α0.
Proof. For any ﬁxed discount factor 0 < α < 1, let U be an optimal
strategy with parameters (sα
i , Sα
i ). Because of Assumptions (ii) and (iii),
there are constants 0 ≥C3 > −∞and q > 0, such that f(l, C3 −y) ≥qy
for all y > 0. Let us ﬁx a positive integer T and let C2 = C3 −MT.
Assume sα
i < C2 for each i ∈I. In what follows, we specify a value of T,
namely T ∗, in terms of which we will construct an alternative strategy
that is better than U, at least when the initial surplus x = C3.

92
Average Cost Models with Backorders
Consider the alternate policy ˜U = (˜u0, ˜u1, . . .), deﬁned by
˜u0 = 0, ˜uk = ξk−1 for k = 1, 2, . . . , T,
and
˜uk = [xk + uk −˜xk]+ for k ≥T + 1.
For convenience of notation we deﬁne ξ−1 = 0.
We investigate the strategy ˜U with the initial surplus ˜x0 = C3. Let
˜xk denote the inventory level in period k resulting from ˜U. With the
initial inventory level x0 = ˜x0 = C3, we know that under the optimal
policy U, no order is placed in or before period T, since the corresponding
surplus xk ≥C3 −Mk ≥C2 > sα
i , k = 0, 1, . . . , T. It is easy to see that
˜xk = C3 −ξk−1 ≥xk = C3 −k−1
t=0 ξt, k ≤T. For k ≥T + 1, we have
the following situation. As long as the inventory level after ordering for
U is less than the inventory level before ordering for ˜U, the strategy ˜U
orders nothing. As soon as xk + uk is greater than or equal to ˜xk, we
order up to the level xk +uk, and the inventory level is the same for both
strategies from then on. Obviously, the expected cost corresponding to
U from period T + 1 on is not smaller than the one corresponding to ˜U
from T + 1 on. Therefore,
vα(i, C3) −Jα(i, C3, ˜U)
= E
! ∞

k=0
αk(c(ik, uk) + f(ik, xk) −c(ik, ˜uk) −f(ik, ˜xk))
"
(5.14)
≥E
!
T

k=0
αk(f(ik, C3 −
k−1

t=0
ξt) −c(ik, ξk−1) −f(ik, C3 −ξk−1))
"
.
Furthermore, because of the boundedness of the demand, we know
that there is a constant C4 such that E(c(ik, ξk−1)+f(ik, C3−ξk−1)) ≤C4
for all k and, therefore,
E
!
T

k=0
αk(c(ik, ξk−1) + f(ik, C3 −ξk−1))
"
< C4(T + 1).
(5.15)
To investigate the remaining term on the RHS of (5.14), it is con-
venient to introduce the notation
g(T, α) := E
!
T

k=0
αk(f(ik, C3 −
k−1

t=0
ξt)
"
.
We show that g(·, 1) is at least of quadratic growth. Let ε and ρ be
the same as in Assumption (vii), and νh, νl, and N as in the proof of

MARKOVIAN DEMAND INVENTORY MODELS
93
Lemma 5.1.
We split the sum with respect to k into sections of the
length N and get
g(aN −1, 1) :=
a−1

k=0
E
⎛
⎝
(k+1)N−1

j=kN
(f(ij, C3 −
j−1

t=0
ξt)
⎞
⎠.
(5.16)
To obtain a lower bound for the argument of the ﬁrst sum, we use the
conditional expectation with respect to the event that the cumulative
demand up to time kN is equal to z, i.e.,
E
⎛
⎝
(k+1)N−1

j=kN
f(ij, C3 −
j−1

t=0
ξt)
⎞
⎠
=
∞

0
E
⎛
⎝
(k+1)N−1

j=kN
f(ij, C3 −
j−1

t=0
ξt)

kN−1

t=0
ξt = z
⎞
⎠dP
!kN−1

t=0
ξt < z
"
.
Because j ≥kN, we have j−1
t=0 ξt ≥kN−1
t=0 ξt = z. It follows from
Assumption (ii) that f(ij, x) is decreasing for x ≤0, and since C3 ≤0,
we can conclude
E
⎛
⎝
(k+1)N−1

j=kN
f(ij, C3 −
j−1

t=0
ξt)
⎞
⎠
≥
∞

0
E
⎛
⎝
(k+1)N−1

j=kN
f(ij, C3 −z)
⎞
⎠dP
!kN−1

t=0
ξt < z
"
.
(5.17)
If we restrict our attention to those periods j in which ij = l, we can
replace f(l, C3 −z) by its lower bound qz, use (5.12), and obtain
E
⎛
⎝
(k+1)N−1

j=kN
f(ij, C3 −z)
⎞
⎠
≥
E
⎛
⎝
(k+1)N−1

j=kN
f(ij, C3 −z)1Iij=l
⎞
⎠
=
E
⎛
⎝
(k+1)N−1

j=kN
f(l, C3 −z)1Iij=l
⎞
⎠
≥
qz
(k+1)N−1

j=kN
P(ij = l) ≥qzνl/2.
(5.18)

94
Average Cost Models with Backorders
Substituting (5.18) into (5.17) yields
E
⎛
⎝
(k+1)N−1

j=kN
f(ij, C3 −
j−1

t=0
ξt)
⎞
⎠≥qνl
2 E
!kN−1

t=0
ξt
"
.
(5.19)
From (5.13) we can easily derive
E
⎛
⎝
(a+1)N−1

t=aN
ξt
⎞
⎠= E(ψa) ≥νhρε/2 > 0
and, therefore,
E
!kN−1

t=0
ξt
"
≥kνhρε/2.
(5.20)
Combining (5.16), (5.20), and (5.19) ﬁnally yields
g(aN −1, 1) ≥
a−1

k=0
kνhρεqνl/4 = νhρεqνla(a −1)/8.
(5.21)
Because g(·, 1) is increasing, (5.21) establishes that it is at least of
quadratic growth. But from this and (5.15), it follows that there is a T ∗
such that g(T ∗, 1) > C4(T ∗+ 1). Because of the continuity of g(T, ·), it
follows that there is an α0 < 1 such that for all α ≥α0, it holds that
g(T ∗, α) > C4(T ∗+ 1). Therefore,
vα(i, C3) −Jα(i, C3, ˜U) > 0,
1 > α ≥α0,
for the policy ˜U deﬁned by T = T ∗. This leads to a contradiction that
the policy U is optimal, and helps us to conclude that any strategy with
max{sα
i } < C2 = C3 −T ∗M cannot be optimal.
□
Lemma 5.3 Under Assumptions (i)-(iii), (v)-(viii), and for α0 obtained
in Lemma 5.2, vα(i, ·) is locally equi-Lipschitzian for α ≥α0, i.e., for
b > 0 there is a constant C5 ≥0, independent of α, such that
|vα(i, x)−vα(i, ˜x)| ≤C5|x−˜x|
for all
x, ˜x ∈[−b, b],
α ≥α0. (5.22)
Proof. Consider the case ˜x ≥x. Let us ﬁx an α ≥α0, use the optimal
strategy U with initial surplus x, and the strategy ˜U deﬁned by
˜uk = [uk −(˜xk −xk)]+ =

0
if
uk ≤˜xk −xk,
uk + xk −˜xk
if
uk > ˜xk −xk,

MARKOVIAN DEMAND INVENTORY MODELS
95
with initial ˜x. It is easy to see that if we deﬁne ˜τ := inf{t : ˜ut > 0}, then
˜uk =
⎧
⎨
⎩
0
for
0 ≤k ≤˜τ −1,
uk + xk −˜xk
for
k = ˜τ,
uk
for
k ≥˜τ + 1,
(5.23)
and, therefore,
˜x˜τ+1 = ˜x˜τ + ˜u˜τ −ξ˜τ = x˜τ + u˜τ −ξ˜τ = x˜τ+1.
It follows that for k ≥˜τ, the surplus levels ˜xk and xk are equal and the
order quantities ˜uk and uk are equal.
Furthermore, it is easy to conclude that
0 ≤˜uk ≤uk and |˜xk −xk| ≤|˜x −x| for all k.
From Assumptions (i) and (ii), we have
c(ik, ˜uk) ≤c(ik, uk) and |f(ik, ˜xk) −f(ik, xk)| ≤C|˜x −x|.
Therefore,
vα(i, ˜x) −vα(i, x)
≤
Jα(i, ˜x; ˜U) −Jα(i, x; U)
=
E

˜τ

k=0
αk(f(ik, ˜xk) −f(ik, xk) + c(ik, ˜uk) −c(ik, uk))

≤
E

˜τ

k=0
αkC|˜x −x|

≤E(˜τ + 1)C|˜x −x|.
(5.24)
In order to prove that E(˜τ + 1) is bounded, note from (5.23) that
˜xk −xk = ˜x −x −k−1
t=0 uk for k ≤˜τ and, therefore,
˜τ = inf{k : uk > ˜xk −xk} = inf{k :
k

t=0
uk > ˜x −x}.
Now consider the inventory level yn = xn +un after ordering in a period
n, if there exists one, in which in = i∗with sα
i∗≥C2. From the structure
of the optimal strategy, we know that under the assumption α ≥α0 we
have yn ≥C2 (see Lemma 5.2), and therefore,
C2 −1 < yn = x +
n

j=0
uj −
n−1

j=0
ξj.

96
Average Cost Models with Backorders
This implies that if n−1
j=0 ξj > ˜x −C2 + 1 and in = i∗, then n
j=0 uj >
˜x −x, and therefore ˜τ ≤n, a.s. It is easy to see that from Lemma 5.1,
Assumption (vi), and the fact that x, ˜x ∈[−b, b], we have
E(˜τ)
≤
E[inf{k :
k−1

j=0
ξj ≥˜x −C2 + 1 and ik = i∗}]
≤
Ei(τ˜x−C2+1 + inf{k ≥τ˜x−C2+1 : ik = i∗}) < ∞.
This inequality, together with (5.24), implies that for α ≥α0 and ˜x ≥x,
we have
vα(i, ˜x) −vα(i, x) ≤C5|˜x −x|.
To complete the proof, it is suﬃcient to prove the above inequality
for ˜x < x. In this case, let us deﬁne
˜uk =

uk + x −˜x
if k = k∗,
uk
otherwise,
where k∗is the ﬁrst k with uk > 0. It is obvious that
vα(i, ˜x) −vα(i, x)
≤
Jα(i, ˜x; ˜U) −Jα(i, x; U)
=
E
 k∗

k=0
αk(f(ik, ˜xk) −f(ik, xk)) + αk∗cik∗(˜uk∗−uk∗)

≤
E(k∗+ 1)C|˜x −x| + max{ci : i ∈I}|˜x −x|
≤
C5|˜x −x|,
(5.25)
where the boundedness of E(k∗+ 1) can be proved in a similar manner
as above.
□
Lemma 5.4 Let Assumptions (i)-(viii) hold. For α0 deﬁned in Lemma
5.2, there are α1 ≥α0 and C6 ≥0 such that for α ≥α1 and x ≥C6,
the function vα(i, x) is increasing. Furthermore, vα(i, x) is decreasing
for x ≤0.
Proof. We begin with the proof of the ﬁrst part of the lemma. Because
of Assumptions (ii) and (iv), there are constants 0 ≤C7 < ∞and q > 0
such that f(g, x) ≥qx for all x ≥C7. Let us ﬁx a positive integer T and
let C6 = C7 + (T + 1)M. Recall from Assumption (viii) that M is the
upper bound on the demand. Later we will specify a value of T, namely
T ∗, for which the assertion of the lemma holds.

MARKOVIAN DEMAND INVENTORY MODELS
97
Assume the initial surplus x > C6 and apply the optimal policy U =
(u(i0, x0), u(i1, x1), . . .), where u(i, x) is an optimal stationary feedback
control and xk is the associated surplus in the beginning of period k.
Since x > C6, there is an ˜x such that x > ˜x = x−ε > C6 and 1 ≥ε > 0.
Let us apply the policy ˜U, with the initial surplus ˜x, deﬁned by
˜uk = u(ik, xk) for k < τ and ˜uk = u(ik, ˜xk) for k ≥τ,
where τ := inf{k : ˜xk < C7+M}, with ˜xk denoting the surplus in period
k corresponding to the initial ˜x and the policy ˜U. It is clear that ˜U orders
the same amount in each of the periods from 0 to τ −1 as those ordered
under the optimal strategy with the initial value x0 = x. Beginning with
τ, ˜U follows the optimal feedback policy.
For k = 0, 1, . . . , τ, the diﬀerence of the inventory processes xk −˜xk
remains ε and ˜xk ≥C7 in view of the fact that ξk−1 < M. Furthermore,
the bound M on periodic demands implies τ > T. Thus,
vα(i, x) −vα(i, ˜x)
≥
vα(i, x) −Jα(i, x −ε; ˜U)
=
∞

k=0
αkE(f(ik, xk) −f(ik, ˜xk) + c(ik, u(ik, xk) −c(ik, ˜uk))
=
τ−1

k=0
αkE(f(ik, xk) −f(ik, ˜xk)) + E(ατ(vα(iτ, xτ) −vα(iτ, ˜xτ))).
Since vα(i, ·) is locally equi-Lipschitzian, xτ −˜xτ = ε, and
C7 + M + 1 ≥C7 + M + ε > xτ > ˜xτ ≥C7,
there is a nonnegative constant C8 independent of x and ε such that
E(ατ (vα(iτ, xτ) −vα(iτ, ˜xτ))) ≥−C8ε
for all α0 ≤α < 1.
For further analysis, set
h(t, α) :=
t−1

k=0
αkE(f(ik, xk) −f(ik, ˜xk)),
t ≥1.
Furthermore, because τ ≥T + 1 and xk > ˜xk for k ≤τ, we have for the
state g speciﬁed in Assumption (iv),
h(τ, 1)
≥
h(T + 1, 1) ≥
T

k=0
E((f(ik, xk) −f(ik, ˜xk))1Iik=g)
=
T

k=0
E((f(g, xk) −f(g, ˜xk))1Iik=g) ≥qε
T

k=0
P(ik = g).

98
Average Cost Models with Backorders
On the other hand, with the notation of the proof of Lemma 5.1, we
know that
aN ≥
aN−1

k=0
P(ik = g) =
a−1

b=0
(b+1)N−1

k=bN
P(ik = g) ≥aνg/2
and, therefore, qε T
k=0 P(ik = g) is of linear growth in T. But then,
there is a T ∗such that
qε
T ∗

k=0
P(ik = g) > C8ε,
which implies the strict inequality h(T ∗+ 1, 1) > C8ε. Because h(t, ·)
is continuous, we know that there is an α1 ≥α0 such that the strict
inequality holds for all 1 ≥α ≥α1, and we have
vα(i, x) −vα(i, x −ε) ≥0
for x ≥C6 and 1 ≥α ≥α1.
The second part of the lemma claiming that vα(i, x) is decreasing for
x ≤0 is easy to prove. We only want to sketch the proof here. Let
x < ˜x ≤0 and let U denote an optimal decision used with the initial
value x. Let ˜U be a strategy applied to the initial value ˜x according to
˜uk := [uk −(˜xk −xk)]+ for k = 0, 1, . . . .
Then, it is easy to see that ˜uk ≤uk, ˜xk ≥xk if ˜xk ≤˜x ≤0, and ˜xk = xk
if ˜xk > ˜x.
Thus, the control cost is not higher, the shortage is not larger, and the
inventory is equal under ˜u when compared to u. Therefore, vα(i, ˜x) ≤
Jα(i, ˜x; ˜U) ≤vα(i, x), which is the required monotonicity property.
□
5.5.
Vanishing Discount Approach
Lemma 5.5 Under Assumptions (i)-(iii), (v)-(viii), and for α0 obtained
in Lemma 5.2, the diﬀerential discounted value function wα(i, x) :=
vα(i, x) −vα(1, 0) is uniformly bounded with respect to α ≥α0 for all x
and i.
Proof. Since Lemma 5.3 implies
|wα(i, x)|
=
|vα(i, x) −vα(1, 0)|
≤
|vα(i, x) −vα(i, 0)| + |vα(i, 0) −vα(1, 0)|
≤
C5|x| + |wα(i, 0)|,

MARKOVIAN DEMAND INVENTORY MODELS
99
it is suﬃcient to prove that wα(i, 0) is uniformly bounded. Note that C5
may depend on x, but it is independent of α ≥α0.
First, we show that there is an M > −∞with wα(i, 0) ≥M for
all α ≥α0. Let α be ﬁxed.
From Theorem 5.1, we know that in
this discounted case there is a stationary optimal feedback policy U =
(u(i, x), u(i, x), . . .). With k∗= inf{k : ik = i}, we consider the cost for
the initial state (i0, ˜x0) = (1, 0), and the following inventory policy ˜U:
˜uk = ξk−1 for k < k∗, ˜uk∗= u(ik∗, 0) −xk∗= u(ik∗, 0) + ξk∗−1,
and ˜uk = u(ik, ˜xk) for k > k∗.
That is, we order the previous period demand until the demand state is
equal to i in period k∗. In that period, we order as much as is needed
to reach an inventory level after ordering, that is equal to the inventory
level in period 0 after ordering the optimal amount u(i, 0) for the problem
starting in the state (i, 0). From that instant on, we apply the optimal
feedback policy U.
The cost corresponding to this policy is
Jα(1, 0; ˜U)
=
E
!k∗−1

k=0
αk(c(ik, ˜uk) + f(ik, ˜xk)) + αk∗vα(i, −ξk∗−1)
"
. (5.26)
To derive an upper bound for E(vα(i, −ξk∗−1)) in terms of vα(i, 0),
we use the dynamic programming equation (5.9). For y ≥0, we have
vα(i, −y)≤f(i, −y)+c(i, u(i, 0)+y)+α
L

j=1
pij
M

0
vα(j, u(i, 0)−z)ϕi(z)dz.
On the other hand, because U is optimal, we have
vα(i, 0) = f(i, 0) + c(i, u(i, 0)) + α
L

j=1
pij
M

0
vα(j, u(i, 0) −z)ϕi(z)dz.
Thus,
vα(i, −y)
≤
vα(i, 0) + f(i, −y) + c(i, u(i, 0) + y)
−f(i, 0) −c(i, u(i, 0)).
(5.27)
We use (5.27) with y = ξk∗−1, use ˜uk = ξk−1 and ˜xk = −ξk−1 for k < k∗
in (5.26), and combine them to obtain
Jα(1, 0; ˜U)
≤
E
 k∗−1

k=0
αk(c(ik, ξk−1) + f(ik, −ξk−1)) + αk∗vα(i, 0)

100
Average Cost Models with Backorders
+αk∗(c(i, u(i, 0) + ξk∗−1) + f(i, −ξk∗−1)
−c(i, u(i, 0)) −f(i, 0))

.
(5.28)
Because of the bounded demand, all arguments of the sums in the
ﬁrst line and the expressions on the second line are uniformly bounded
from above by a constant M. Moreover, E(k∗) < ∞because of Assump-
tion (vi). Therefore, it holds that
wα(i, 0)
=
vα(i, 0) −vα(1, 0) ≥vα(i, 0) −Jα(1, 0; ˜U)
≥
vα(i, 0) −E
 k∗−1

k=0
αk(c(ik, ξk−1) + f(ik, −ξk−1))
+αk∗vα(i, 0) + αk∗(c(i, u(i, 0) + ξk∗−1)
+f(i, −ξk∗−1) −c(i, u(i, 0)) −f(i, 0))

≥
vα(i, 0)(1 −E(αk∗)) + M ≥M.
(5.29)
The opposite inequality, wα(i, 0) ≤M, is shown analogously by chang-
ing the role of the states 1 and i. Thus, |wα(i, x)| ≤C5|x|+max{M, M},
and the proof is completed.
□
Lemma 5.6 Under Assumption (viii), (1 −α)vα(1, 0) is uniformly
bounded on 0 < α < 1.
Proof. Consider the strategy ˜U = (0, ξ0, ξ1, . . .). Then, because ˜U is
not necessarily optimal,
0 ≤vα(1, 0) ≤Jα(1, 0; ˜U) = E
! ∞

k=0
αk(c(ik, ξk−1) + f(ik, −ξk−1))
"
.
Because the demand is bounded, there is a C9 < ∞such that
E(c(ik, ξk−1) + f(ik, −ξk−1)) < C9.
Therefore,
0 ≤(1 −α)vα(1, 0)
≤
(1 −α)
∞

k=0
αkE(c(ik, ξk−1) + f(ik, −ξk−1))
≤
(1 −α)
∞

k=0
αkC9 = C9.
□

MARKOVIAN DEMAND INVENTORY MODELS
101
Theorem 5.2 Let Assumptions (i)-(iii) and (v)-(viii) hold. There exist
a sequence (αk)∞
k=1 converging to 1, a constant λ∗, and a locally Lipschitz
continuous function w∗(·, ·) such that
(1 −αk)vαk(i, x) →λ∗
and
wαk(i, x) →w∗(i, x),
locally uniformly in x and i as k goes to inﬁnity. Moreover, (λ∗, w∗)
satisﬁes the average cost optimality equation
w(i, x) + λ = f(i, x) + inf
u≥0{c(i, u) + F(w)(i, x + u)}.
(5.30)
Proof. It is immediate from Lemma 5.3 and the deﬁnition of wα(i, x)
that wα(i, ·) is locally equi-Lipschitzian for α ≥α0, and therefore it
is uniformly equicontinuous in any ﬁnite interval by Theorem A.3.2.
Additionally, according to Lemma 5.5, wα(i, ·) is uniformly bounded, and
by Lemma 5.6, (1 −α)vα(1, 0) is uniformly bounded. Therefore, from
the Arzel`a-Ascoli Theorem A.3.5 and Lemma 5.3, there is a sequence
αk →1, a locally Lipschitz continuous function w∗(i, x), and a constant
λ∗such that
(1 −αk)vαk(1, 0) →λ∗,
and
wαk(i, x) →w∗(i, x)
for each x locally uniformly in any given interval. By the diagonalization
procedure, a subsequence can be found so that wαk(i, ·) converges to a
locally Lipschitz continuous function w∗(i, ·) on the entire real line; (see
Kirszbraun Theorem A.1.4).
Next, it is easy to see that
lim
k→∞(1 −αk)vαk(i, x) = lim
k→∞(1 −αk)(wαk(i, x) + vαk(1, 0)) = λ∗.
Substituting vαk(i, x) = wαk(i, x) + vαk(1, 0) in (5.9) yields
wαk(i, x) + (1 −αk)vαk(1, 0)
= f(i, x) + inf
u≥0{c(i, u) + F(wαk)(i, x + u)}.
(5.31)
Since wαk(i, x) converges locally uniformly with respect to x and i and
since for a given x, x + u −ξ ∈[x −M, max{x, C6 + M}] by Lemma 5.4,
we can pass to the limit on both sides of (5.31) and obtain (5.30); (see
Theorem A.2.4). This completes the proof.
□

102
Average Cost Models with Backorders
5.6.
Veriﬁcation Theorem
Definition 5.1 Let (λ, w) be a solution of the average optimality equa-
tion (5.30). An admissible strategy U = (u0, u1, . . .) is called stable with
respect to w if for each initial surplus level x and for each i ∈I,
lim
k→∞
1
k E(w(ik, xk)) = 0,
where xk is the surplus level in period k corresponding to the initial
state (i, x) and the strategy U. Here α is called the average cost and w
is called a potential function.
Theorem 5.3 (Veriﬁcation Theorem)
(a) Let (λ, w(·, ·)) be a solution of the average cost optimality equation
(5.30). Then, λ ≤J(i, x; U) for any admissible U.
(b) If it exists, let u∗(i, x) attain the inﬁmum in (5.30). Furthermore,
let U∗= (u∗, u∗, . . .), the stationary feedback policy given by u∗, be stable
with respect to w. Then,
λ = J(i, x; U∗) = λ∗= lim
N→∞
1
N E
!
N−1

k=0
f(ik, x∗
k) + c(ik, u∗
k)
"
,
and U∗is an average optimal strategy.
(c) Moreover, U∗minimizes
lim inf
N→∞
1
N E
!
N−1

k=0
f(ik, xk) + c(ik, uk)
"
over the class of admissible decisions which are stable with respect to w.
Proof. Let U = (u0, u1, . . .) denote any admissible decision. Suppose
J(i, x; U) < λ.
(5.32)
Put ˜f(k) = E[f(ik, xk) + c(ik, uk)]. From (5.32), it immediately follows
that n−1
k=0 ˜f(k) < ∞for each positive integer n, since otherwise we
would have J(i, x; U) = ∞. Note that
J(i, x; U) = lim sup
n→∞
1
n
n−1

k=0
˜f(k),
while
(1 −α)Jα(i, x; U) = (1 −α)
∞

k=0
αk ˜f(k).
(5.33)

MARKOVIAN DEMAND INVENTORY MODELS
103
Since ˜f(k) is nonnegative for each k, the sum in (5.33) is well deﬁned
for 0 ≤α < 1, and we can use the Tauberian Theorem A.5.2 to obtain
lim sup
α↑1
(1 −α)Jα(i, x; U) ≤J(i, x; U) < λ.
On the other hand, we know from Theorem 5.2 that (1−αk)vαk(i, x) →λ
on a subsequence {αk}∞
k=1 converging to one. Thus, there exists an α < 1
such that
(1 −α)Jα(i, x; U) < (1 −α)vα(i, x),
which
contradicts
the
deﬁnition
of
the
value
function
vα(i, x).
This proves part (a) of the theorem.
To prove part (c), we assume that U is stable with respect to w, and
then follow the same approach used in deriving (2.15) to obtain
E{w(ik+1, xk+1) | i0, . . . , ik, ξ0, . . . , ξk−1} = F(w)(ik, xk + uk)
a.s.
(5.34)
Because uk does not necessarily attain the inﬁmum in (5.30), we have
w(ik, xk) + λ ≤f(ik, xk) + c(ik, uk) + F(w)(ik, xk + uk)
a.s.,
and from (5.34) we derive
w(ik, xk) + λ ≤f(ik, xk) + c(ik, uk) + E(w(ik+1, xk + uk −ξk) | ik)
a.s.
By taking the expectation on both sides, we obtain
E(w(ik, xk)) + λ ≤E(f(ik, xk) + c(ik, uk)) + E(w(ik+1, xk+1)).
Summing from 0 to n −1 yields
nλ ≤E
!n−1

k=0
f(ik, xk) + c(ik, uk)
"
+E(w(in, xn))−E(w(i0, x0)). (5.35)
Divide by n, let n go to inﬁnity, and use the fact that U is stable with
respect to w, to obtain
λ ≤lim inf
n→∞
1
nE
!n−1

k=0
f(ik, xk) + c(ik, uk)
"
.
(5.36)
On the other hand, if there exists a u∗which attains the inﬁmum in
(5.30), we then have
w(ik, xk)+λ = f(ik, xk)+c(ik, u∗(ik, xk))+F(w)(ik, xk+u∗(ik, xk)), a.s.,

104
Average Cost Models with Backorders
and we analogously obtain
nλ = E
!n−1

k=0
f(ik, xk) + c(ik, u∗(ik, xk))
"
+ E(w(in, xn)) −E(w(i0, x0)).
(5.37)
Because U∗is assumed stable with respect to w, we get
λ = lim
n→∞
1
nE
!n−1

k=0
f(ik, xk) + c(ik, u∗(ik, xk)
"
= J(i, x; U∗).
(5.38)
This proves part (b) of the theorem.
□
Remark 5.4 It should be obvious that any solution (λ, w) of the aver-
age cost optimality equation and control u∗satisfying (b) of Theorem 5.3
will have a unique λ, since it represents the minimum average cost. On
the other hand, if (λ, w) is a solution, then (λ, w + c), where c is any
constant, is also a solution. For the purpose of this chapter, we do not
require w to be unique up to a constant. If w is not unique up to a
constant, then u∗may not be unique. We also do not need w∗in Theo-
rem 5.2 to be unique.
Lemma 5.7 The function w∗(i, ·), deﬁned in Theorem 5.2, is K-convex.
Proof. We know from Chapter 2 that vα(i, ·) is K-convex for each α < 1.
Therefore, the function wαk(i, ·) is K-convex for each k. It follows that
w∗(i, ·), the limit of a sequence of K-convex functions, is itself K-convex.
□
Theorem 5.4 Let Assumptions (i)-(viii) hold. There are constants ∞≥
Si ≥0 and si ≤Si, i ∈I satisfying maxi∈I{si} ≥C2, with C2 speciﬁed in
Lemma 5.2, such that the stationary feedback strategy U∗= (u∗, u∗, . . .),
according to u∗(i, x) = (Si −x)1Ix<si, is average optimal.
Proof. The proof is based on verifying that (λ∗, w∗) obtained in The-
orem 5.2 satisﬁes the conditions of Theorem 5.3 and that w∗(i, ·) is
K-convex according to Lemma 5.7. The details follow.
It immediately follows from Lemma 5.4 that wα(i, x) is decreasing for
x ≤0 and increasing for x ≥C6 for α1 ≤α < 1. This implies the same
property for w∗(i, x). Furthermore, by Theorem 5.2, w∗(i, ·) is locally
Lipschitz continuous. Therefore, w∗(i, ·) is bounded from below.
Also, by Theorem 5.2, (λ∗, w∗) satisﬁes the average cost optimality
equation (5.30), and w∗(i, ·) is of linear growth.
Because w∗(i, ·) is K-convex, we know that a minimizer in (5.30) is
given by u∗(i, x) = (Si −x)1Ix<si, where Si minimizes G(i, y) := ciy +

MARKOVIAN DEMAND INVENTORY MODELS
105
F(w)(i, y), and si is a solution of the equation G(i, y) = K + G(i, Si) in
y, if one exists, or si = −∞otherwise.
To prove that the strategy U∗is stable with respect to w, we de-
rive bounds for Si and si. Obviously, Si as a global minimizer of ciy +
F(w∗)(i, y) can be chosen to be less than or equal to C6 + M, because
w∗(i, x) is increasing for x ≥C6, which implies that F(w∗)(i, y) is in-
creasing for y ≥C6 + M.
For α0 ≤α < 1, an (sα
i , Sα
i ) strategy is optimal, vα(i, ·) is K-convex,
and, from Lemma 5.2 there is a j ∈I such that sα
j ≥C2. We denote the
smallest such j by j(α). For the sequence (αk)∞
k=1 from Theorem 5.2, at
least one j∗appears inﬁnitely often among the j(αk). In the following,
we choose a subsequence, still denoted by (αk)∞
k=1, such that j(αk) = j∗.
Then, for all 1 > αk ≥α0, we know that sα
j∗≥C2 and vαk(j∗, x) are
decreasing for x ≤sj∗on account of the K-convexity of vαk(j∗, x) given
in Theorem 5.1.
Furthermore, vα(j∗, x) is increasing for x ≥C6 for
α1 ≤α < 1, F(vαk)(j∗, y) is increasing for y ≥C6 +M, and the inﬁmum
is attained for y ≤C6 + M. By the deﬁnition of sα
i , we know that the
minimum of vα(i, x) is taken at a value not less than sα
i , and therefore
at or above C2. Thus, we can conclude that for 1 > αk > max{α0, α1},
we have
cj∗C2 + αkF(vαk)(j∗, C2) −
min
C2≤y≤C6+M{cj∗y + αkF(vαk)(j∗, y)} ≥K.
Subtracting αkvαk(1, 0) from both the terms on the LHS yields
cj∗C2 + αkF(wαk)(j∗, C2) −
min
C2≤y≤C6+M{cj∗y + αkF(wαk)(j∗, y)} ≥K.
The functions wαk(j∗, y) converge uniformly in any closed interval to
w∗(j∗, y). Therefore, we can pass to the limit and get
cj∗C2 + F(w∗)(j∗, C2) −
min
C2≤y≤C6+M{cj∗y + F(w∗)(j∗, y)} ≥K. (5.39)
From (5.39) and the continuity of w∗(j∗, ·), it follows that we can choose
an sj∗∈[C2, Sj∗] such that
cj∗sj∗+ F(w∗)(j∗, sj∗) −cj∗Sj∗−F(w∗)(j∗, Sj∗) = K.
This means that under U∗, there will be some ordering inﬁnitely often.
Because of the structure of the strategy, the inventory level under U∗
will never be higher than max{x, S1, . . . , SL}. Therefore, we have
xk ≤max{x, C6 + M}.
(5.40)
Furthermore, the inventory level is at its lowest between any two con-
secutive orders right before the second order. Similar to the proof of

106
Average Cost Models with Backorders
Lemma 5.1, it is easy to see that E(τ0) is ﬁnite, where τ0 is the time
between any two consecutive orders.
On the other hand, the expected demand between any two consecutive
orders is less than or equal to M(1 + E(τ0)). It follows that
lim
k→∞E(xk) ≥min{S1, S2, . . . , SL} −M(1 + E(τ0)).
(5.41)
Furthermore, setting u = −x in (5.30) we get
w∗(i, x) + λ ≤f(i, x) + c(i, −x) + F(w∗)(i, 0),
x < 0.
Therefore, w∗(i, x) is of at most linear growth for x →−∞. Because
w∗(i, x) is decreasing as x increases for x ≤0 by Lemma 5.6, we can
ﬁnally conclude from (5.40) and (5.41) that U∗is stable with respect to
w∗.
We have now shown that the policy U∗satisﬁes all the conditions of
the veriﬁcation theorem (Theorem 5.3), and therefore it minimizes the
long-run average cost.
□
5.7.
Concluding Remarks and Notes
In this chapter based on Beyer and Sethi (1997), we have carried
out a rigorous analysis of the average cost stochastic inventory problem
with Markovian demand and ﬁxed ordering cost.
We have proved a
veriﬁcation theorem for the average cost optimality equation, which we
have used to establish the existence of an optimal state-dependent (s, S)
policy.
The chapter generalizes the earlier studies of Iglehart (1963b), Veinott
and Wagner (1965), Zheng (1991), and others in several ways. We use
Markovian demand and convex surplus cost instead of independent de-
mand and linear surplus cost, as assumed in the classical literature. Our
Assumption (v) generalizes the usual assumption p > c in the classical
literature; (see Remark 2.1 in Chapter 2 for details).
The vanishing
discount approach used here does not require the stationary analysis
carried out in Iglehart (1963b), which is not possible in all but the sim-
plest of the cases. Instead, the approach requires solving the average
cost optimality equation for obtaining the optimal solution.
We have, however, made the assumption that the demand is bounded
and the costs are of linear growth. One reason for making the assumption
was to simplify the mostly constructive proofs obtained in this chapter.
Nevertheless, we relax these assumptions in the next chapter.
The vanishing discount approach has been also used very eﬀectively
to study continuous-time stochastic manufacturing systems. The reader
is referred to Sethi et al. (2005b).

Chapter 6
AVERAGE COST MODELS WITH
POLYNOMIALLY GROWING
SURPLUS COST
With the results in hand for the discounted cost models with polyno-
mially growing surplus cost as described in Chapter 3, we can now begin
the analysis of the corresponding average cost model.
This chapter extends the model of Chapter 5 by allowing for un-
bounded demand and polynomially growing cost. To accomplish these
relaxations, we impose a condition on a particular moment of the de-
mand to be ﬁnite. The plan of the chapter is a follows. In Section 6.1,
we provide a precise formulation of the problem, while relying on the
notations introduced in Chapters 3 and 5. In Section 6.2, we derive rele-
vant properties of the discounted cost value function that are uniform in
the discount factor α, and examine the asymptotic behavior of the dif-
ferential discounted value function as α approaches one. In Section 6.3,
we employ the vanishing discount approach to establish the average cost
optimality equation. The associated veriﬁcation theorem is proved in
Section 6.4, and the theorem is used to show that there exists an opti-
mal policy characterized by parameters (si, Si), i ∈I, where I denotes
a ﬁnite collection of possible demand states. Moreover, these parame-
ters can be obtained by taking the limit of a converging subsequence of
(sα
i , Sα
i ) as α →1.
6.1.
Formulation of the Problem
In what follows, we show the existence of an optimal (si, Si) policy
for the stationary long-run average cost problem. We use the notation
introduced at the beginning of Section 5.2. To establish this result we
have to make assumptions in addition to those already made in Sec-
tion 3.2 of Chapter 3. For the convenience of the reader, we list all the
required assumptions here.
D. Beyer et al., Markovian Demand Inventory Models, International Series
107
in Operations Research & Management Science 108,
DOI 10.1007/978-0-387-71604-6 6, c⃝Springer Science+Business Media, LLC 2010

108
Average Cost Models with Polynomially Growing Surplus Cost
(i) The production cost is given by c(i, u) = K + ciu for u > 0 and
c(i, 0) = 0, where the ﬁxed ordering cost K ≥0 and the variable
cost ci ≥0.
(ii) For each i, the nonnegative surplus cost function f(i, ·) is convex
and at most of polynomial growth with power γ, i.e., f(i, x) ≤
¯f(1 + |x|γ) for some ¯f > 0.
(iii) There is a state l ∈I such that f(l, x) is not identically zero for
x ≤0.
(iv) There is a state g ∈I such that f(g, x) is not identically zero for
x ≥0.
(v) The production and inventory costs satisfy
cix +
L

j=1
pij
∞

0
f(j, x −z)dΦi(z) →∞as x →∞.
(vi) The Markov chain (ik)∞
k=0 is irreducible.
(vii) There is a state h ∈I such that 1 −Φh(ε) = ρ > 0 for some ε > 0.
(viii) There exists an ε > 0 such that E(ξk)γ+ε ≤D < ∞for all k.
Remark 6.1 Assumptions (i), (ii), and (v) are the same as the ones
needed in Sections 3.5 and 3.6 of Chapter 3 to establish the optimality
of a stationary (sα
i , Sα
i ) strategy in the stationary discounted inﬁnite-
horizon problem; (see Remarks 3.1 and 3.2).
Remark 6.2 Assumptions (iii) and (iv) rule out trivial cases which lead
to degenerate optimal policies. In fact, if Assumption (iii) is violated,
the optimal policy is never to order. If Assumption (iii) holds and As-
sumption (iv) is violated, then it is optimal to wait for a period with a
demand state for which ci is minimal, and order an inﬁnite amount in
that period. Assumptions (iv) and (v) generalize the usual assumption
made by Scarf (1960) and others that the unit inventory holding cost
h > 0.
Remark 6.3 Assumptions (vi)-(viii) are needed in order to guarantee
that the exogenous demand depletes any given initial inventory in a
ﬁnite expected time. While Assumption (vii) says that in at least one
state h, the expected demand is strictly larger than zero, Assumption (vi)
implies that the state h would occur inﬁnitely often with a ﬁnite expected
interval between successive occurrences. Assumption (viii) is technical.

MARKOVIAN DEMAND INVENTORY MODELS
109
It ensures ﬁniteness of various expectations involved in the analysis of
problems with the long-run average cost criterion.
The objective is to minimize the expected long-run average cost
J(i, x; U) = lim sup
N→∞
1
N E

N−1

k=0
[c(ik, uk) + f(ik, xk)]

,
(6.1)
with i0 = i and x0 = x, where as before U = (u0, u1, . . .), ui ≥0, i =
0, 1, . . . , is a history-dependent or nonanticipative decision (order quan-
tities) for the problem. Such a control U is termed admissible. Let U
denote the class of all admissible controls. The surplus balance equations
are given by
xk+1 = xk + uk −ξk, k = 0, 1, . . . .
Our aim is to show that there exist a constant λ∗, termed the optimal
average cost, which is independent of the initial i and x, and a control
U∗∈U such that
λ∗= J(i, x; U∗) ≤J(i, x; U),
∀
U ∈U,
and
λ∗= lim
N→∞
1
N E

N−1

k=0
[c(ik, u∗
k) + f(ik, x∗
k)]

,
where x∗
k, k = 0, 1, . . . , is the surplus process corresponding to U∗with
i0 = i and x0 = x.
To prove these results, we will use the vanishing discount approach.
That is, by letting the discount factor α in the discounted cost problem
approach one, we will show that we can derive a dynamic programming
equation whose solution provides an average optimal control and the
associated minimum average cost λ∗.
6.2.
Behavior of the Discounted Cost Model with
Respect to the Discount Factor
As a ﬁrst step in the vanishing discount approach, we will establish
a uniform lower bound for the largest of the optimal ordering levels sα
i
with respect to α. We will do so by comparing the cost of two policies.
The ﬁrst one is an (sα
i , Sα
i ) policy with sα
i less than a negative real
number −y. In the proof of Lemma 6.3, we will give a modiﬁed policy
and prove that there is a value y∗for y that is independent of the values
of α close to one, such that this modiﬁed policy produces lower cost than
the original policy. This will prove that any policy with sα
i < −y∗for

110
Average Cost Models with Polynomially Growing Surplus Cost
all i and α in the neighborhood of one cannot be optimal. To do so we
need to obtain some preliminary results.
For convenience of exposition, let us deﬁne x0
0 = 0 and x0
k as the
surplus level at the beginning of period k corresponding to the policy of
not ever ordering (i.e. U = 0). Thus,
x0
k = −(ξ1 + ξ2 + . . . + ξk).
(6.2)
Let the stopping time
τy := inf{k : ξ1 + ξ2 + . . . + ξk ≥y}
(6.3)
be the time required for the cumulative demand to reach y.
The following two lemmas are needed to establish that the cost up to
τy for a policy that does not order grows faster than that of a policy that
always orders the last period’s demand. We show in Lemma 6.1 that the
cost up to τy for the no-order policy grows faster than linear in y, while
Lemma 6.2 states that ordering the last period’s demand results in cost
growing linearly in y.
Lemma 6.1 For y →∞and any given real number d, the expression
1
yE
! τy

k=0
f(ik, −
k

t=1
ξt)
"
is bounded from below by a function νd(y) which approaches d as y →∞.
Proof. Fix the initial state i. We deﬁne recursively the sequence (tj
k)∞
k=0
of periods, in which the demand state is j, by
tj
0
=
0,
tj
k+1
=
inf{n > tj
k : in = j},
k = 0, 1, . . . .
(6.4)
By convention, we deﬁne tj
∞= ∞. We refer to the interval containing
the periods tj
k through tj
k+1 −1 as the kth cycle, k = 0, 1, . . . .
The kth cycle demand and surplus cost, respectively, are
Xj
k := x0
tj
k+1 −x0
tj
k = ξtj
k+1 + . . . + ξtj
k+1,
Y j
k :=
tj
k+1−1

n=tj
k
f(in, x0
n). (6.5)
Because of the Markov property of the demand process and the fact
that itj
k = j for all k ≥1, we know that the random variables Xj
k

MARKOVIAN DEMAND INVENTORY MODELS
111
are independent for k ≥0, and identically distributed for k = 1, 2, . . . .
Furthermore, it is easy to prove that EXj
0 < ∞and EXj
1 < ∞, and thus
EXj
k < ∞, k = 0, 1, . . . . Let
T j
y := inf{n : x0
tj
n ≤−y} = inf{n :
tj
n

t=0
ξt ≥y} = inf{n :
n−1

k=0
Xk ≥y}
be the index of the ﬁrst cycle for which the beginning shortage corre-
sponding to the no-ordering policy is larger or equal to y. Thus, tj
T j
y is
the index of the ﬁrst period in which the demand state is j and the
surplus level at the beginning of the period in less than or equal to −y.
On the other hand, τy is the index of the ﬁrst period in which the start-
ing surplus is less than or equal to −y, regardless of the demand state.
Therefore, it is clear that
tj
T j
y−1 < τy ≤tj
T j
y.
(6.6)
Also note that T j
y is nondecreasing in y. By construction, {T j
y , y ≥0}
is a delayed (or general) renewal process with waiting times {Xj
k, k =
0, 1, . . .}; (see, e.g., Ross (1983)).
Now consider the case where the demand state j = l, the special state
deﬁned in Assumption (iii). Because of Assumptions (ii) and (iii), we
have limx→∞f(l, −x) = ∞. Therefore, we can choose a constant yd,
0 ≤yd < ∞, such that f(l, −x) ≥E(Xl
1)d for all −x ≤−yd. Then, from
(6.2), (6.5), and (6.6), we have
τy

k=0
f(ik, −
k

t=1
ξt)
≥
tT ly−1

k=0
f(ik, x0
k) ≥
T l
y−2

k=0
Y l
k ≥
T l
y−2

k=T lyd
Y l
k
≥
T l
y−2

k=T lyd
E(X1)d ≥(T l
y −T l
yd −1)E(Xl
1)d,
for any y ≥yd. Clearly E(T l
yd) < ∞, and the Elementary Renewal The-
orem B.3.1 yields
lim
y→∞
E(T l
y)
y
=
1
E(Xl
1).
Finally with νd(y) := E(T l
y −T l
yd −1)E(Xl
1)d/y, we obtain
1
yE
! τy

k=0
f(ik, −
k

t=1
ξt)
"
≥νd(y)
and
lim
y→∞νd(y) = d.

112
Average Cost Models with Polynomially Growing Surplus Cost
This completes the proof.
□
Lemma 6.2 For y →∞, the expression
1
yE
! τy

k=0
(c(ik, ξk) + f(ik, −ξk))
"
is bounded from above by a function ¯ν(y) which tends to a constant
c < ∞as y →∞.
Proof. Let Xj
k and T j
y be deﬁned as in the proof of Lemma 6.1. In what
follows, we set the initial state j := i0 = i, and omit the superscript.
With this, the 0th cycle also begins with its ﬁrst period in demand state
i. Let
Zk :=
tk+1

n=tk+1
(c(in, ξn) + f(in, −ξn))
represent a ‘reward’ corresponding to the kth cycle. The stationarity
of the Markovian demands implies that the pairs (Xk, Zk) are i.i.d. for
all k, including k = 0. Furthermore, we already know E(X0) > 0, and
because of Assumptions (i), (ii), and (viii), we have E(Z0) < ∞.
Now we have
1
yE
! τy

k=0
(c(ik, ξk) + f(ik, −ξk))
"
≤
1
yE
⎛
⎝
tτy

k=0
(c(ik, ξk) + f(ik, −ξk))
⎞
⎠
≤
1
yE
⎛
⎝
T y−1

k=0
Zk
⎞
⎠≤1
yE
! T y

k=0
Zk
"
.
(6.7)
Setting the RHS of (6.7) equal to ¯ν(y), we conclude from Theorem B.4.1
that
lim
y→∞¯ν(y) = lim
y→∞
1
yE
! T y

k=0
Zk
"
= E(Z0)
E(X0) := c < ∞.
This completes the proof.
□
Lemma 6.3 Under Assumptions (i)-(iii) and (v)-(viii), there are real
numbers 0 < α0 < 1 and C2 > −∞such that maxi∈I{sα
i } ≥C2 for all
α ∈[α0, 1).

MARKOVIAN DEMAND INVENTORY MODELS
113
Proof. Fix a discount factor α, 0 < α < 1. Let U be an optimal strategy
with parameters (sα
i , Sα
i ). Let us ﬁx a positive real number y and assume
sα
i < −y for each i ∈I. In what follows, we specify a value of y, namely
y∗, in terms of which we will construct an alternative strategy that is
better than U, at least when the initial surplus x = 0.
Consider the alternate policy ˜U = (˜u0, ˜u1, . . .) deﬁned by
⎧
⎨
⎩
˜u0 = 0,
˜uk = ξk, k = 1, 2, . . . , τy −1,
˜uk = [xk + uk −˜xk]+, k ≥τy,
where τy is as in (6.3).
We investigate the strategy ˜U with the initial surplus ˜x0 = 0. Let ˜xk
denote the inventory level in period k resulting from ˜U. With the initial
inventory level x0 = ˜x0 = 0, we know that under the optimal policy
U, no order is placed in or before the period τy since the corresponding
surplus xk > −y > sα
i , k = 0, 1, . . . , τy −1. It is easy to see that
˜xk = −ξk ≥xk = −
k

t=1
ξt, k ≤τy −1.
For k ≥τy, we have the following situation. As long as the inventory
level after ordering for U is less than the inventory level before ordering
for ˜U, the strategy ˜U orders nothing. As soon as xk + uk is greater than
or equal to ˜xk, we order up to the level xk +uk, and the inventory level is
the same for both strategies from then on. Obviously, the expected cost
corresponding to U from τy on is not smaller than the one corresponding
to ˜U from τy on. Therefore,
vα(i, 0) −Jα(i, 0, ˜U)
= E
! ∞

k=0
αk(c(ik, uk) + f(ik, xk) −c(ik, ˜uk) −f(ik, ˜xk))
"
≥E
⎛
⎝
τy−1

k=0
αk(f(ik, −
k

t=1
ξt) −c(ik, ξk) −f(ik, −ξk))
⎞
⎠.
(6.8)
Let
g(y, α) := E
⎛
⎝
τy−1

k=0
αk(f(ik, −
k

t=1
ξt) −c(ik, ξk) −f(ik, −ξk))
⎞
⎠.

114
Average Cost Models with Polynomially Growing Surplus Cost
It follows from Lemmas 6.2 and 6.1 that there is a y∗> 0 such that
g(y∗, 1)
=
E
⎛
⎝
τy∗−1

k=0
f(ik, −
k

t=1
ξt)
⎞
⎠
−E
⎛
⎝
τy∗−1

k=0
(c(ik, ξk) + f(ik, −ξk))
⎞
⎠> 0.
Because limα→1 g(y∗, α) = g(y∗, 1), it follows that there is an α0 < 1
such that for all α ≥α0, we have g(y∗, α) > 0. Therefore,
vα(i, 0) −Jα(i, 0, ˜U) > 0,
1 > α ≥α0,
for the policy ˜U deﬁned by y = y∗. This leads to a contradiction that
the policy U is optimal, which helps us to conclude that any strategy
with max{sα
i } < C2 = −y∗cannot be optimal.
□
Lemma 6.4 Let α0 be the same as in Lemma 6.3. If Assumptions (i)-
(iii) and (v)-(viii) are satisﬁed, then vα(i, ·) is locally equi-Lipschitzian
for α ≥α0, i.e., for any b > 0, there exists a positive constant C5 < ∞,
independent of α, such that
|vα(i, x) −vα(i, ˜x)| ≤C5|x −˜x|
∀
x, ˜x ∈[−b, b].
(6.9)
Proof. Note that from the convexity and polynomial growth properties
of f(i, ·), it follows that f(i, ·) is locally Lipschitz continuous. The proof
is very similar to the one of Lemma 5.3.
Consider the case ˜x ≥x. Let us ﬁx an α ≥α0. Then use the optimal
strategy U with the initial surplus x, and the strategy ˜U deﬁned by
˜uk = [uk −(˜xk −xk)]+ =

0
if
uk ≤˜xk −xk,
uk + xk −˜xk
if
uk > ˜xk −xk,
with the initial surplus ˜x. (Here xk and ˜xk are the surplus levels at time
k under the strategies U and ˜U, respectively). It is easy to see that if
we deﬁne ˜τ := inf{t : ˜ut > 0}, then
˜uk =
⎧
⎨
⎩
0
for
0 ≤k ≤˜τ −1,
uk + xk −˜xk
for
k = ˜τ,
uk
for
k ≥˜τ + 1,
(6.10)
and, therefore,
˜x˜τ+1 = ˜x˜τ + ˜u˜τ −ξ˜τ = x˜τ + u˜τ −ξ˜τ = x˜τ+1.

MARKOVIAN DEMAND INVENTORY MODELS
115
It follows that for k > ˜τ, the surplus levels ˜xk and xk are equal and the
order quantities ˜uk and uk are equal.
Furthermore, it is easy to conclude that
0 ≤˜uk ≤uk and |˜xk −xk| ≤|˜x −x| for all k.
From Assumptions (i) and (ii), we have
c(ik, ˜uk) ≤c(ik, uk) and |f(ik, ˜xk) −f(ik, xk)| ≤C|˜x −x|.
Therefore,
vα(i, ˜x) −vα(i, x)
≤
Jα(i, ˜x; ˜U) −Jα(i, x; U)
=
E

˜τ

k=0
αk(f(ik, ˜xk) −f(ik, xk) + c(ik, ˜uk) −c(ik, uk))

≤
E

˜τ

k=0
αkC|˜x −x|

≤E(˜τ + 1)C|˜x −x|.
(6.11)
In order to prove that E(˜τ + 1) is bounded, note from (6.10) that
˜xk −xk = ˜x −x −k−1
t=0 uk for k ≤˜τ and, therefore,
˜τ = inf{k : uk > ˜xk −xk} = inf{k :
k

t=0
uk > ˜x −x}.
Let i∗be such that sα
i∗≥C2. Consider the inventory level yn = xn + un
after ordering in period n, if there exists one, in which in = i∗. From the
structure of the optimal strategy, we know that under the assumption
α ≥α0 we have yn ≥C2 (see Lemma 6.3), and therefore,
C2 −1 < yn = x +
n

j=0
uj −
n−1

j=0
ξj.
This implies that if n−1
j=0 ξj > ˜x −C2 + 1 and in = i∗, then n
j=0 uj >
˜x −x, and therefore ˜τ ≤n, a.s. It is easy to see from Lemma 5.1, the
fact that x, ˜x ∈[−b, b], and Assumption (vi) that
E(˜τ)
≤
E[inf{k :
k−1

j=0
ξj ≥˜x −C2 + 1 and ik = i∗}]
≤
Ei(τ˜x−C2+1 + inf{k ≥τ˜x−C2+1 : ik = i∗}) < ∞,

116
Average Cost Models with Polynomially Growing Surplus Cost
where τy is deﬁned by (6.3). This inequality, together with (6.11), implies
that for α ≥α0 and ˜x ≥x, we have
vα(i, ˜x) −vα(i, x) ≤C5|˜x −x|.
To complete the proof, it is suﬃcient to prove the above inequality
for ˜x < x. In this case, let us deﬁne
˜uk =

uk + x −˜x
if k = k∗,
uk
otherwise,
where k∗is the ﬁrst k with uk > 0. It is obvious that
vα(i, ˜x) −vα(i, x)
≤
Jα(i, ˜x; ˜U) −Jα(i, x; U)
=
E
 k∗

k=0
αk(f(ik, ˜xk) −f(ik, xk)) + αk∗cik∗(˜uk∗−uk∗)

≤
E(k∗+ 1)C|˜x −x| + max{ci : i ∈I}|˜x −x|
≤
C5|˜x −x|,
(6.12)
where the boundedness of E(k∗+ 1) can be proved in a similar manner
as above.
□
6.3.
Vanishing Discount Approach
Theorem 6.1 Under Assumptions (i)-(iii) and (v)-(viii), the following
results hold.
(a) Let α0 be the same as in Lemma 6.3. Then, the diﬀerential dis-
counted value function wα(i, x):=vα(i, x)−vα(1, 0) is uniformly bounded
with respect to α, α ≥α0, for each ﬁxed x and i, and (1−α)vα(1, 0) is
uniformly bounded on 0 < α < 1.
(b) There exist a sequence (αk)∞
k=1 converging to one, a constant λ∗,
and a locally Lipschitz continuous function w∗(·, ·), such that
(1 −αk)vαk(i, x) →λ∗
and
wαk(i, x) →w∗(i, x),
(6.13)
locally uniformly in x and i as k goes to inﬁnity.
(c) w∗(i, ·) is K-convex.
Proof. To prove (a) we ﬁrst show that the diﬀerential discounted value
function wα(i, x) := vα(i, x)−vα(1, 0) is uniformly bounded with respect
to α, α ≥α0 for each ﬁxed x and i. The proof of this part is similar to
the proof of Lemma 5.5.

MARKOVIAN DEMAND INVENTORY MODELS
117
Lemma 6.4 implies
|wα(i, x)|
=
|vα(i, x) −vα(1, 0)|
≤
|vα(i, x) −vα(i, 0)| + |vα(i, 0) −vα(1, 0)|
≤
C5|x| + |wα(i, 0)|.
Thus, it is suﬃcient to prove that wα(i, 0) is uniformly bounded. (Note
that C5 may depend on x, but it is independent of α ≥α0.)
First, we show that there is an M > −∞with wα(i, 0) ≥M for
all α ≥α0. Let α be ﬁxed.
We have shown in Section 3.6 that in
this discounted case there is a stationary optimal feedback policy U =
(u(i, x), u(i, x), . . .). With k∗= inf{k : ik = i}, we consider the cost for
the initial state (i0, ˜x0) = (1, 0) and the following inventory policy ˜U:
˜uk = ξk−1 for k < k∗, ˜uk∗= u(ik∗, 0) −xk∗= u(ik∗, 0) + ξk∗−1,
and ˜uk = u(ik, ˜xk) for k > k∗.
That is, we order the previous period’s demand until the demand state
is equal to i in period k∗. In that period we order as much as is needed
to reach an inventory level after ordering, that is equal to the inventory
level in period 0 after ordering the optimal amount u(i, 0) for the problem
starting in the state (i, 0). From that instant on, we apply the optimal
feedback policy U.
The cost corresponding to this policy is
Jα(1, 0; ˜U)
=
E
!k∗−1

k=0
αk(c(ik, ˜uk) + f(ik, ˜xk)) + αk∗vα(i, −ξk∗−1)
"
.
(6.14)
To derive an upper bound for E(vα(i, −ξk∗−1)) in terms of vα(i, 0), we
use the dynamic programming equation (3.51). For y ≥0, we have
vα(i, −y)≤f(i, −y)+c(i, u(i, 0)+y)+α
L

j=1
pij
∞

0
vα(j, u(i, 0)−z)ϕi(z)dz.
On the other hand, because U is optimal, we have
vα(i, 0) = f(i, 0) + c(i, u(i, 0)) + α
L

j=1
pij
∞

0
vα(j, u(i, 0) −z)ϕi(z)dz.
Thus,
vα(i, −y)
≤
vα(i, 0) + f(i, −y) + c(i, u(i, 0) + y)
−f(i, 0) −c(i, u(i, 0)).
(6.15)

118
Average Cost Models with Polynomially Growing Surplus Cost
We use (6.15) with y = ξk∗−1, use ˜uk = ξk−1 and ˜xk = −ξk−1 for k < k∗
in (6.14), and combine them to obtain
Jα(1, 0; ˜U)
≤
E
 k∗−1

k=0
αk(c(ik, ξk−1) + f(ik, −ξk−1)) + αk∗vα(i, 0)
+αk∗(c(i, u(i, 0) + ξk∗−1) + f(i, −ξk∗−1)
−c(i, u(i, 0)) −f(i, 0))

.
(6.16)
Because of Assumptions (i), (ii), and (viii), all arguments of the sums
in the ﬁrst line and the expressions on the second line are uniformly
bounded from above by a constant M. Moreover, E(k∗) < ∞because of
Assumption (vi). Therefore, it holds that
wα(i, 0)
=
vα(i, 0) −vα(1, 0) ≥vα(i, 0) −Jα(1, 0; ˜U)
≥
vα(i, 0) −E
 k∗−1

k=0
αk(c(ik, ξk−1) + f(ik, −ξk−1))
+αk∗vα(i, 0) + αk∗(c(i, u(i, 0) + ξk∗−1)
+f(i, −ξk∗−1) −c(i, u(i, 0)) −f(i, 0))

≥
vα(i, 0)(1 −E(αk∗)) + M ≥M.
(6.17)
The opposite inequality wα(i, 0) ≤M is shown analogously by chang-
ing the role of the states 1 and i. Thus, |wα(i, x)| ≤C5|x|+max{M, M},
which proves that wα(i, x) is uniformly bounded with respect to α, α ≥
α0.
We now prove the second part of (a), i.e., that (1 −α)vα(1, 0) is uni-
formly bounded on 0 < α < 1. Consider the strategy ˜U = (0, ξ0, ξ1, . . .).
Then, because ˜U is not necessarily optimal,
0 ≤vα(1, 0) ≤Jα(1, 0; ˜U) = E
! ∞

k=0
αk(c(ik, ξk−1) + f(ik, −ξk−1))
"
.
Owing to Assumptions (i), (ii), and (viii), there exists a constant C9 < ∞
such that E(c(ik, ξk−1) + f(ik, −ξk−1)) < C9. Therefore,
0 ≤(1 −α)vα(1, 0)
≤
(1 −α)
∞

k=0
αkE(c(ik, ξk−1) + f(ik, −ξk−1))
≤
(1 −α)
∞

k=0
αkC9 = C9.

MARKOVIAN DEMAND INVENTORY MODELS
119
This completes the proof of part (a) of the theorem.
It is immediate from Lemma 6.4 and the deﬁnition of wα(i, x) that
wα(i, ·) is locally equi-Lipschitzian for α ≥α0, and therefore it is uni-
formly equicontinuous in any ﬁnite interval by Theorem A.3.2. Addition-
ally, according to part (a) of Theorem 6.1, wα(i, ·) and (1−α)vα(1, 0) are
uniformly bounded. Therefore, from the Arzel`a-Ascoli Theorem A.3.5
and Lemma 6.4, there is a sequence αk →1, a locally Lipschitz contin-
uous function w∗(i, x), and a constant λ∗such that
(1 −αk)vαk(1, 0) →λ∗
and wαk(i, x) is locally uniformly convergent to w∗(i, x). This completes
the proof of part (b).
The proof of (c) follows from the fact that w∗as a limit of K-convex
functions is K-convex; (see Theorem C.2.2).
□
Lemma 6.5 There are constants α2 ∈[0, 1) and C8 > 0 such that for
all α ≥α2, we have Sα
i ≤C8 < ∞for any i for which sα
i > −∞.
Proof. Let us ﬁx the initial state i0 = i for which sα
i > −∞. Fix α2 > 0
and a discount factor α ≥α2. Let U = (u(i0, x0), u(i1, x1), . . .) be an
optimal strategy with parameters (sα
j , Sα
j ), j ∈I. Let us ﬁx a positive
real number y and assume Sα
i > y. In what follows, we specify a value of
y, namely y∗, in terms of which we will construct an alternative strategy
˜U that is better than U.
For the demand state g speciﬁed in Assumption (iv), let
τ g := inf{n > 0 : in = g}
be the ﬁrst period (not counting the period 0) with the demand state g.
Furthermore, let d be the state with the lowest per unit ordering cost,
i.e., cd ≤ci for all i ∈I. Then, we deﬁne
τ := inf{n ≥τ g : in = d}.
Assume x0 = ˜x0 = ¯x := min{0, sα
i } and consider the policy ˜U deﬁned
by
⎧
⎪
⎪
⎨
⎪
⎪
⎩
˜u0 = −¯x ≥0,
˜uk = 0, k = 1, 2, . . . , τ −1,
˜uτ = xτ + u(iτ, xτ) −˜xτ ≥0,
˜uk = u(ik, xk), k ≥τ + 1.
The two policies and the resulting trajectories diﬀer only in the periods
0 through τ. Therefore, we have
vα(i, ¯x) −Jα(i, ¯x; ˜U)

120
Average Cost Models with Polynomially Growing Surplus Cost
=
Jα(i, ¯x; U) −Jα(i, ¯x; ˜U)
=
E
! τ

k=0
αk(f(ik, xk) −f(ik, ˜xk) + c(ik, uk) −c(ik, ˜uk))
"
=
E
! τ

k=1
αk(f(ik, xk) −f(ik, −
k

t=1
ξk))
"
+E
! τ

k=0
αkc(ik, uk)
"
−E(ατc(iτ , ˜uτ)) −c(i, −¯x).
(6.18)
After ordering in period τ, the total accumulated ordered amount up
to period τ is the same for both the policies, because x0 = ˜x0 and
xτ+1 = ˜xτ+1. Observe that the policy ˜U orders only in the periods 0
and τ. In the period 0, ˜u0 ≤u0 so that ˜U orders no more than U at
the unit cost ci. The second order of the policy ˜U is executed at the
lowest possible per unit cost cd in period τ which is not earlier than any
of the ordering periods of policy U. Because ˜U orders at most twice in
periods 0, 1, . . . , τ, the total ﬁxed ordering cost of ˜U exceeds the total
ﬁxed ordering cost of U by at most 2K. Thus,
2K + E
! τ

k=0
αkc(ik, uk)
"
≥c(i, −¯x) + E(ατc(iτ, ˜uτ)).
Furthermore, it follows from Assumptions (ii) and (vi)–(viii) that
E
! τ

k=1
f(ik, −
k

t=1
ξt)
"
< ∞.
Because τ ≥τ g, we obtain
E
! τ

k=1
αkf(ik, xk)
"
≥E
! τ g

k=1
αkf(ik, xk)
"
,
and because sα
i ≥y, we obtain
xk ≥y −
k

t=1
ξt.
Irreducibility of the Markov chain (in)∞
n=0 implies the existence of an
integer m, 0 ≤m ≤L, such that P(im = g) > 0. Let m0 be the smallest

MARKOVIAN DEMAND INVENTORY MODELS
121
of such m. It follows that τ g ≥m0 and therefore,
E
! τ g

k=1
αkf(ik, xk)
"
≥
αm0E(f(im0, xm0))
≥
αm0
2 E(f(g, y −
m0

t=1
ξt)|im0 = g)P(im0 = g), ∀α ≥α2. (6.19)
Using Assumptions (ii), (iv), and (viii), it is easy to show that the RHS of
(6.19) (and consequently of (6.18)) tends to inﬁnity as y goes to inﬁnity.
Therefore, we can choose y∗, 0 ≤y∗< ∞, such that for all α ≥α2,
vα(i, ¯x)−Jα(i, ¯x; ˜U) ≥E
! τ

k=1
αk(f(ik, xk) −f(ik, −
k

t=1
ξk))
"
−2K > 0.
Thus, for α ≥α2, a policy with Sα
i > C8 := y∗cannot be optimal.
□
Lemma 6.6 For the sequence {αk} deﬁned in Theorem 6.1, there is a
positive integer N0 such that for k ≥N0, functions wαk(i, ·) on (−∞, 0]
are uniformly bounded from above by a function of polynomial growth
with power γ.
Proof. Choose N1 such that αk > α2 for k ≥N1, with α2 deﬁned in
Lemma 6.5. Substituting vαk(i, x) = wαk(i, x)+vαk(1, 0) in (3.51) yields
wαk(i, x) + (1 −αk)vαk(1, 0)
=
f(i, x) + inf
u≥0{c(i, u) + αkF(wαk)(i, x + u)}.
(6.20)
First, let x ≥C8, where C8 is deﬁned in Lemma 6.5. Then it follows from
the structure of the optimal policy and Lemma 6.5 that the inﬁmum is
obtained for u = 0, and we ﬁnd
wαk(i, x) + (1 −αk)vαk(1, 0) = f(i, x) + αkF(wαk)(i, x).
Because limk→∞(1−αk)vαk(1, 0) = λ∗and limk→∞wαk(i, x) = w∗(i, x),
it follows that
lim
k→∞αkF(wαk)(i, x) = w∗(i, x) + λ∗−f(i, x).
Now let x < C8 and set u = C8 −x > 0. Then, because the inﬁmum is
not necessarily attained at u, we have
wαk(i, x) + (1 −αk)vαk(1, 0) ≤f(i, x) + c(i, C8 −x) + αkF(wαk)(i, C8).

122
Average Cost Models with Polynomially Growing Surplus Cost
Choose N0, N0 ≥N1, such that for all k ≥N0,
|(1 −αk)vαk(1, 0) −λ∗| ≤ε
and
|αkF(wαk)(i, C8) −w∗(i, C8) + λ∗−f(i, C8)| ≤ε.
Then for k ≥N0, we obtain
wαk(i, x) ≤f(i, x) + c(i, C8 −x) + w∗(i, C8) + λ∗−f(i, C8) + 2ε,
which provides a uniform upper bound of growth rate γ for x ≤0.
□
Lemma 6.7 For α0 obtained in Lemma 6.3, there is a ﬁnite constant C9
such that for all α, α0 ≤α < 1,
wα(i, x) ≥

C9 −cix,
x > 0,
C9,
x ≤0.
Proof. First assume x > 0. We know that there is an optimal stationary
feedback policy U = (u(i0, x0), u(i1, x1), . . .). Consider the modiﬁed pol-
icy ˜U = (u(i0, x0)+x, u(i1, x1), u(i2, x2), . . .). If we use U with the initial
inventory x0 = x and ˜U with the initial inventory ˜x0 = 0, then under
both policies the trajectories diﬀer only in the initial period. Therefore,
we have
wα(i, x)
=
vα(i, x) −vα(i, 0) + wα(i, 0)
≥
vα(i, x) −Jα(i, 0; ˜U) + wα(i, 0)
=
Jα(i, x; U) −Jα(i, 0; ˜U) + wα(i, 0)
=
c(i, u) −c(i, ˜u) + f(i, x) −f(i, 0) + wα(i, 0)
≥
−K −cix + wα(i, 0).
(6.21)
By Lemma 6.3, wα(i, 0) is uniformly bounded for α ≥α0. Therefore,
there is a constant C9 such that
wα(i, x) ≥C9 −cix for α ≥α0 and x > 0.
If x ≤0, it follows from Lemma 5.4 that wα(i, x) is decreasing in x.
Then, by using the same arguments concerning the uniform boundedness
of wα(i, 0) as above, we obtain
wα(i, x) ≥wα(i, 0) ≥C9, α ≥α0 and x ≤0.
This completes the proof.
□

MARKOVIAN DEMAND INVENTORY MODELS
123
Theorem 6.2 The limit (λ∗, w∗), obtained in Theorem 6.1, satisﬁes the
average cost optimality equation
w(i, x) + λ = f(i, x) + inf
u≥0{c(i, u) + F(w)(i, x + u)}.
(6.22)
Furthermore, w∗∈Lγ−. Moreover, let Uα be an optimal policy for the
discounted cost problem for which the inﬁmum in (3.51) is attained. Let
u∗(i, x) be a cluster point of (uαk(i, x))∞
k=0, where the sequence (αk)∞
k=1
is deﬁned in Theorem 6.1. Then the inﬁmum in (6.22) is attained at
u∗(i, x) for w = w∗.
Proof. From (6.20), it follows that for any u,
wαk(i, x)+(1−αk)vαk(1, 0) ≤f(i, x)+c(i, u)+F(wαk)(i, x+u). (6.23)
Now deﬁne the random variable
ηk(j, z) := wαk(j, z −ξj),
where ξj is a random variable with the distribution P(ξj < t) = Φj(t).
Then, we can write
F(wαk)(i, z) =
L

j=1
pijE(ηk(j, z)).
For αk suﬃciently close to one, it follows from Lemma 6.6 that there is
a constant C3 such that
ηk(j, z) ≤C3(1 + |z −ξj|)γ ≤C4(1 + ξj)γ,
(6.24)
and it follows from Lemma 6.7 that
ηk(j, z) ≥inf
x≤z wαk(j, x) = C6 > −∞,
(6.25)
where C4 and C6 depend on z, which is ﬁxed. We know from Theorem 6.1
that wαk converges locally uniformly to w∗. Therefore, ηk(j, z) converges
everywhere to η(j, z) := w∗(j, z −ξj). On the other hand, we see from
(6.24) and (6.25) that
E(|ηk(j, z)|)(γ+ε)/γ ≤(max{C4, C6})(γ+ε)/γ(1 + ξj)γ+ε < ∞
by Assumption (viii).
Therefore, the random variables ηk(j, y, z) are
uniformly integrable with respect to k for any ﬁxed j and z, and we can
pass to the limit in (6.23) to obtain, for each x and u,
w∗(i, x) + λ ≤f(i, x) + c(i, u) + F(w∗)(i, x + u).
(6.26)

124
Average Cost Models with Polynomially Growing Surplus Cost
Now let the inﬁmum in (6.20) be attained at uk for ﬁxed x and j.
Then, we have
wαk(i, x)+(1−αk)vαk(1, 0) = f(i, x)+c(i, uk)+F(wαk)(i, x+uk). (6.27)
It follows from Lemma 6.5 that, for suﬃciently large k, uk are uniformly
bounded.
Therefore, we can choose a subsequence (still denoted by
(αk)∞
k=0) such that uk →u∗. Let
ˆηk(j, x) := wαk(j, x + uk −ξj).
The boundedness of uk also allows us to to prove the inequalities
ˆηk(j, x) ≤C3(1 + |x + uk −ξj|)γ ≤ˆC4(1 + ξj)γ
(6.28)
and
ˆηk(j, x) ≥
inf
v≤x+uk wαk(j, v) = ˆC6 > −∞.
(6.29)
It is easy to see that as k →∞,
ˆηk(j, x) →ˆη(j, x) := w∗(j, x + u∗−ξj).
The inequalities (6.28) and (6.29) imply that ˆηk(j, x) is uniformly inte-
grable. By taking the limit in (6.27) as k →∞, we obtain
w∗(i, x) + λ ≥f(i, x) + c(i, u∗) + F(w∗)(i, x + u∗);
(6.30)
(see Section B.1 for details). The reason we write (6.30) as an inequality
rather than an equality is because of the lower semicontinuity of c(i, ·).
Nevertheless, the inequality (6.30) together with (6.26) prove (6.22) and
the last part of the theorem. The result that w∗∈Lγ−immediately
follows from Lemmas 6.6 and 6.7.
□
Lemma 6.8
For each i∈I, the function w∗(i, x) is decreasing for x≤0,
w∗(i, ·) is bounded from below, and limx→∞w∗(i, x) = ∞.
Proof. It follows from Lemma 5.4 that the function wα(i, x) is decreas-
ing for x ≤0. This implies the same property for the limit w∗.
Because w∗(i, x) is locally Lipschitz by Theorem 6.1, it follows that
w∗(i, 0) is ﬁnite. Assume
lim
u→∞(c(i, u) + F(w∗)(i, u)) = −∞.
Then, it follows from (6.22) that w∗(i, 0) = −∞, and we obtain a con-
tradiction. Therefore, c(i, u) + F(w∗)(i, u) is bounded from below, as is
w∗(i, x).

MARKOVIAN DEMAND INVENTORY MODELS
125
Let I∞:= {i ∈I : limx→∞w∗(i, x) = ∞}. Since c(g, u) + F(w∗)(g, u)
is bounded from below and Assumptions (i) and (iv) imply that
limx→∞f(g, x) = ∞, it follows that limx→∞w∗(g, x) = ∞. Therefore,
g ∈I∞̸= ∅. Assume I∞̸= I and choose j ∈I∞and i ∈I \ I∞. Then, it
follows that pij = 0. Otherwise, we would have limx→∞F(w∗)(i, x) = ∞
and therefore, limx→∞w∗(i, x) = ∞, which contradicts i ̸∈I∞. We can
now conclude that pij = 0 for all i ̸∈I∞and j ∈I∞. The latter implies
that the Markov process (in)∞
n=0 is not irreducible, which contradicts
Assumption (vi). This proves I∞= I.
□
6.4.
Veriﬁcation Theorem
Definition 6.1 An admissible strategy U = (u0, u1, . . .) is called stable
with respect to w if for each initial surplus level x and for each i ∈I,
lim
k→∞
1
k E(w(ik, xk)) = 0,
where xk is the surplus level in period k corresponding to the initial
state (i, x) and the strategy U.
Lemma 6.9 Let Assumptions (i)-(viii) hold. Let C2 be the constant spec-
iﬁed in Lemma 6.3. Then there are constants Si < ∞and si ≤Si, i ∈I,
satisfying maxi∈I{si} ≥C2, such that
u∗(i, x) =

Si −x,
x ≤si,
0,
x > si,
attains the minimum in the RHS of (6.22) for w = w∗, as deﬁned
in Theorem 6.1.
Furthermore, the stationary feedback strategy U∗=
(u∗, u∗, . . .) is stable with respect to any w ∈Lγ−.
Proof. Let
Gαk(i, y) = ciy + αkF(wαk)(i, y),
(6.31)
G(i, y) = ciy + F(w∗)(i, y).
(6.32)
Because w∗(i, ·) is K-convex, we know that a minimizer in (6.22) is
given by
u∗(i, x) =

Si −x,
x ≤si,
0,
x > si,
where Si is the point where G(i, y) deﬁned by (6.32) attains its minimum,
and si is a solution of the equation G(i, y) = K + G(i, Si) in y, if one
exists, or si = −∞otherwise.

126
Average Cost Models with Polynomially Growing Surplus Cost
To prove that the strategy U∗is stable with respect to any w ∈Lγ−,
we derive bounds for Si and si. Obviously, Si as a global minimizer of
G(i, y) is less than inﬁnity for all i because G(i, y) →∞for y →∞.
For α0 ≤α < 1, the (sα
i , Sα
i ) strategy is optimal, vα(i, ·) is K-convex,
and from Lemma 6.3 there is a j ∈I such that sα
j ≥C2. We denote the
smallest such j by j(α). For the sequence (αk)∞
k=1 from Theorem 6.1,
at least one j∗appears inﬁnitely often among the j(αk). We choose a
subsequence (still denoted by (αk)∞
k=1) such that j(αk) = j∗. Then, we
know that for all 1 > αk ≥α0, it holds that sα
j∗≥C2 and that vαk(j∗, x)
is decreasing for x ≤sj∗due to the K-convexity of vαk(j∗, x); (see proof
of Theorem 3.4 in Chapter 3). Furthermore, by Lemma 6.5 we know
that Sα
j∗≤C8 for α2 ≤α < 1.
Let C7 := max{Sj∗, C8}. By the deﬁnition of sα
i , we know that the
argmin of vα(i, x) is greater then or equal to sα
i , and therefore is greater
than or equal to C2. Thus, we can conclude that for 1 > αk > α0, we
have
cj∗C2 + αkF(vαk)(j∗, C2) −
min
C2≤y≤C7{cj∗y + αkF(vαk)(j∗, y)} ≥K.
Subtracting αkvαk(1, 0) from both the terms on the LHS, we obtain
Gαk(j∗, C2) −
min
C2≤y≤C7{Gαk(j∗, y)} ≥K,
where Gαk(·, ·) is deﬁned by (6.31). The functions Gαk(j∗, ·) converge
uniformly to G(j∗, ·) on any ﬁnite interval. Therefore, we can pass to a
limit and get
G(j∗, C2) −
min
C2≤y≤C7{G(j∗, y)} ≥K.
(6.33)
Note that the minimum in (6.33) is attained at Sj∗. From (6.33) and
the continuity of G(j∗, ·), it follows that we can choose an sj∗∈[C2, Sj∗]
such that
G(j∗, sj∗) −G(j∗, Sj∗) = K.
This means that under U∗there will be inﬁnitely many nonzero orders.
Because of the structure of the strategy, the inventory level under U∗
will never be higher than max{x, S1, . . . , SL}. Therefore, we have
xk ≤max{x, S1, . . . , SL} < ∞,
a.s.
(6.34)
Furthermore, it follows from sj∗≥C2 that if in = j∗, then xn+1 ≥
C2 −ξn. It follows from Assumption (viii) that the cumulative demand
between two consecutive periods with demand state j∗has a ﬁnite γth

MARKOVIAN DEMAND INVENTORY MODELS
127
moment. This implies that E(xγ
k) is uniformly bounded for all k. This,
together with (6.34), proves stability of U∗with respect to any w ∈Lγ−.
□
Lemma 6.10 Let λ∗be deﬁned as in Theorem 6.1. Then, for any ad-
missible strategy U, λ∗≤J(i, x; U).
Proof. Let U = (u0, u1, . . .) denote any admissible decision. Suppose
J(i, x; U) < λ∗.
(6.35)
Put ˜f(k) = E[f(ik, xk) + c(ik, uk)]. From (6.35), it immediately follows
that n−1
k=0 ˜f(k) < ∞for each positive integer n, since otherwise we
would have J(i, x; U) = ∞. Note that
J(i, x; U) = lim sup
n→∞
1
n
n−1

k=0
˜f(k),
while
(1 −α)Jα(i, x; U) = (1 −α)
∞

k=0
αk ˜f(k).
(6.36)
Since ˜f(k) is nonnegative for each k, the sum in (6.36) is well-deﬁned
for 0 ≤α < 1, and we can use the Tauberian Theorem A.5.2 to obtain
lim sup
α↑1
(1 −α)Jα(i, x; U) ≤J(i, x; U) < λ∗.
On the other hand, we know from Theorem 3.2 that (1−αk)vαk(i, x)→λ∗
on a subsequence {αk}∞
k=1 converging to one. Thus, there exists an α < 1
such that
(1 −α)Jα(i, x; U) < (1 −α)vα(i, x),
which contradicts the deﬁnition of the value function vα(i, x).
□
Theorem 6.3 (Veriﬁcation Theorem)
(a) Let (λ, w(·, ·)) be a solution of the average cost optimality equation
(6.22) with w ∈Lγ−. Then, λ ≤J(i, x; U) for any admissible U.
(b) Suppose there exists an ˆu(i, x) for which the inﬁmum in (6.22) is
attained. Furthermore, let ˆU = (ˆu, ˆu, . . .), the stationary feedback policy
given by ˆu, be stable with respect to w. Then,
λ = J(i, x; ˆU) = λ∗= lim
N→∞
1
N E
!
N−1

k=0
f(ik, ˆxk) + c(ik, ˆuk)
"
,

128
Average Cost Models with Polynomially Growing Surplus Cost
and ˆU is an average optimal strategy.
(c) Moreover, ˆU minimizes
lim inf
N→∞
1
N E
!
N−1

k=0
f(ik, xk) + c(ik, uk)
"
over the class of admissible decisions which are stable with respect to w.
Proof. We start by showing that
λ ≤J(i, x; U) for any U stable with respect to w.
(6.37)
We assume that U is stable with respect to w, and then follow the same
approach used in (2.15)) to obtain
E{w(ik+1, xk+1) | i0, . . . , ik, ξ0, . . . , ξk−1} = F(w)(ik, xk + uk)
a.s.
(6.38)
Because uk does not necessarily attain the inﬁmum in (6.22), we have
w(ik, xk) + λ ≤f(ik, xk) + c(ik, uk) + F(w)(ik, xk + uk)
a.s.,
and from (6.38) we derive
w(ik, xk) + λ ≤f(ik, xk) + c(ik, uk) + E(w(ik+1, xk + uk −ξk) | ik) a.s.
By taking the expectation of both sides, we obtain
E(w(ik, xk)) + λ ≤E(f(ik, xk) + c(ik, uk)) + E(w(ik+1, xk+1)).
Summing from 0 to n −1 yields
nλ ≤E
!n−1

k=0
f(ik, xk) + c(ik, uk)
"
+E(w(in, xn))−E(w(i0, x0)). (6.39)
Divide by n, let n go to inﬁnity, and use the fact that U is stable with
respect to w to obtain
λ ≤lim inf
n→∞
1
nE
!n−1

k=0
f(ik, xk) + c(ik, uk)
"
.
(6.40)
Note that if the above inequality holds for ‘liminf,’ it certainly also holds
for ‘limsup’. This proves (6.37).
On the other hand, if there exists a ˆu which attains the inﬁmum in
(6.22), we then have
w(ik, ˆxk) + λ = f(ik, ˆxk) + c(ik, ˆu(ik, ˆxk)) + F(w)(ik, ˆxk + ˆu(ik, ˆxk)) a.s.,

MARKOVIAN DEMAND INVENTORY MODELS
129
and in a similar way we get
nλ = E
!n−1

k=0
f(ik, ˆxk) + c(ik, ˆu(ik, ˆxk))
"
+E(w(in, ˆxn)) −E(w(i0, ˆx0)).
(6.41)
Because ˆU is assumed to be stable with respect to w, we get
λ = lim
n→∞
1
nE
!n−1

k=0
f(ik, ˆxk) + c(ik, ˆu(ik, ˆxk)
"
= J(i, x; ˆU).
(6.42)
For the special solution (λ∗, w∗) deﬁned in Theorem 6.1 (see also The-
orem 6.2), and the strategy U∗deﬁned in Lemma 6.9, we get
λ∗= J(i, x; U∗).
Since by Lemma 6.9, U∗is stable with respect to any function in Lγ−,
it follows that
λ ≤J(i, x; U∗) = λ∗,
(6.43)
which, in view of Lemma 6.10, proves part (a) of the theorem.
Part (a) of the theorem, together with (6.42), proves the average op-
timality of ˆU over all admissible strategies.
Furthermore, since λ =
J(i, x; ˆU) ≥λ∗by (6.42) and Lemma 6.10, it follows from (6.43) that
λ = λ∗, and the proof of Part (b) is completed.
Finally, Part (c) immediately follows from Part (a) and (6.40).
□
Remark 6.4 It should be obvious that any solution (λ, w) of the av-
erage cost optimality equation and control ˆu satisfying (a) and (b) of
Theorem 6.3 will have a unique λ, since it represents the minimum av-
erage cost. On the other hand, if (λ, w) is a solution, then (λ, w + c) is
also a solution, where c is any constant. For the purpose of this chapter
we do not require w to be unique up to a constant. If w is not unique
up to a constant, then ˆu may not be unique. We also do not need w∗in
Theorem 6.1 to be unique.
The ﬁnal result of this section, namely, that there exists an average
optimal policy of (s, S)-type, is an immediate consequence of Lemmas 6.9
and 6.3.
Theorem 6.4 Let Assumptions (i)-(viii) hold. Let si and Si, i ∈I be
deﬁned as in Lemma 6.9. Then, the stationary feedback strategy U∗=
(u∗, u∗, . . .) deﬁned by
u∗(i, x) =

Si −x,
x ≤si,
0,
x > si

130
Average Cost Models with Polynomially Growing Surplus Cost
is average optimal.
The derivation of an optimal strategy presented above only uses prop-
erties of the function w∗. We want to mention here an additional way to
obtain an average optimal state-dependent (s, S) policy.
Corollary 6.1 Let (αk)∞
k=0 be a sequence of discount factors that con-
verges to one and let (si, Si) be any cluster point of the pairs of strategy
parameters (sαk
i , Sαk
i ) on [−∞, ∞). Then, (si, Si) is an average optimal
policy.
Proof. Because Sα
i is uniformly bounded from above for α suﬃciently
close to one, as proved in Lemma 6.5, a cluster point exists, if we allow
the possibility of it being equal to −∞. We choose a subsequence of the
sequence (αk)∞
k=0 deﬁned in Theorem 6.1, still denoted by (αk)∞
k=0, such
that the strategy parameters sαk
i
and Sαk
i
converge to si and Si, and
wαk converges to w∗. Then, by Theorem 6.2, w∗satisﬁes the average
optimality equation (6.22). Furthermore, it is easy to show that for any
ﬁxed x ̸= si, uαk(i, x) converges to
u∗(i, x) =

0,
x > si
Si −x,
x ≤si.
For x = si, we can choose at least one of the following types of subse-
quences:
(a) sαk
i
< x for all k, or
(b) sαk
i
≥x for all k.
For the type (a) subsequence we obtain uαk(i, x) →x, and for type
(b) we get uαk(i, x) →Si −x. By Theorem 6.2, the limit u∗(i, x) is
precisely the function for which the inﬁmum in (6.22) is attained. Then,
by Theorem 6.3, the policy U∗= (u∗(i0, x0), u∗(i1, x1), . . .) is average
optimal. This proves the optimality of at least one of the two types of
(s, S) strategies deﬁned in (3.46) and (3.50), respectively. On the other
hand, because of the continuity of w∗, if one of the types is optimal, then
so is the other type with the same parameters (si, Si).
□
6.5.
Concluding Remarks and Notes
In this chapter based on Beyer et al. (1998), we have generalized
the average cost inﬁnite horizon inventory models involving ﬁxed cost
that have appeared in the literature to allow for unbounded demands

MARKOVIAN DEMAND INVENTORY MODELS
131
and costs with polynomial growth. We have shown the existence of an
optimal Markov policy, and that this can be a state-dependent (s, S)
policy.
In the vanishing discount approach to the average cost problem, re-
laxation of the bounded Markovian demand assumption in Chapter 5 to
unbounded Markovian demands requires the use of renewal arguments
for the establishment of the crucial local equi-Lipschitzian property of
the discounted cost value function. This has been carried out in Lem-
mas 6.1–6.4. Finally, the establishment of the ergodic dynamic program-
ming equation requires proving uniform integrability of the diﬀerential
discounted value functions, accomplished in Lemmas 6.6, 6.7 and The-
orem 6.2, and the uniform boundedness of the discounted order-up-to-
levels accomplished in Lemma 6.5.
The question of whether or not the potential function w∗is unique up
to a constant remains open. The considerable literature on average cost
MDPs, surveyed in Arapostathis et al.
(1993) and Hern´andez-Lerma
and Lasserre (1996), could be found useful in addressing the question.

Chapter 7
AVERAGE COST MODELS
WITH LOST SALES
7.1.
Introduction
This chapter is concerned with the long-run average cost minimiza-
tion of a stochastic inventory problem with Markovian demand, ﬁxed
ordering cost, and convex surplus cost in the case of lost sales. The for-
mulation of the problem is similar to that introduced in Chapter 4 except
that we replace the discounted cost objective function by the long-run
average cost objective function. To deal with this average cost problem,
we apply the vanishing discount method to solve the dynamic program-
ming equations deﬁned for the problem, and establish the corresponding
veriﬁcation theorem.
The plan of this chapter is as follows. Required results for the dis-
counted cost model derived in Chapter 4 are recapitulated in Section 7.3.
In the next section, we provide a precise formulation of the problem. In
Section 7.4, we obtain the asymptotic behavior of the diﬀerential dis-
counted value function as the discount rate goes to zero. The vanishing
discount approach to establish the average cost optimality equation is
developed in Section 7.5. The associated veriﬁcation theorem is proved
in Section 7.6, and the theorem is used to show that a state-dependent
(s, S) policy is optimal for the problem. Section 7.7 concludes the chap-
ter with suggestions for future research.
7.2.
Formulation of the Model
Consider an inventory problem over an inﬁnite horizon.
The de-
mand in each period is assumed to be a random variable deﬁned on
a given probability space, and not necessarily identically distributed.
To precisely deﬁne the demand process, we consider a ﬁnite collection
D. Beyer et al., Markovian Demand Inventory Models, International Series
133
in Operations Research & Management Science 108,
DOI 10.1007/978-0-387-71604-6 7, c⃝Springer Science+Business Media, LLC 2010

134
Average Cost Models with Lost Sales
of demand states labeled i ∈I = {1, 2, . . . , L}, and let ik denote the
demand state observed at the beginning of period k. We assume that
ik, k = 0, 1, 2, . . . , is a Markov chain over I, with the transition matrix
P = {pij}. Thus,
0 ≤pij ≤1, i ∈I, j ∈I, and
L

j=1
pij = 1, i ∈I.
Let the nonnegative random variable ξk denote the demand at the end
of a given period k ∈⟨0, N−1⟩. Demand ξk depends only on the demand
state in period k, by which we mean that it does does not depend on k
and is independent of past demand states and past demands. We denote
its probability density by ϕi(x) and its probability distribution by Φi(x)
when the demand state ik = i.
We suppose that orders are placed at the beginning of a period, deliv-
ered instantaneously, and followed by the period’s demand. Unsatisﬁed
demands are lost.
In what follows, we list the assumptions that are needed to derive the
main results of the chapter in Sections 7.5 and 7.6. Because not all the
results proved in this chapter require all of these assumptions, we label
them as follows so that we can specify the assumptions required in the
statements of the speciﬁc results proved in this chapter.
(i) The production cost is given by c(i, u) = K1Iu>0+ciu, where K ≥0
is the ﬁxed ordering cost and ci ≥0 is the variable cost.
(ii) For each i, the inventory cost function f(i, ·) is convex, nondecreas-
ing and of linear growth, i.e., f(i, x) ≤Cf(1+|x|) for some Cf > 0
and all x. Also, f(i, x) = 0 for all x ≤0.
(iii) For each i, the shortage cost function q(i, ·) is convex, nonincreasing
and of linear growth, i.e., q(i, x) ≤Cq(1+|x|) for some Cq > 0 and
all x. Also, q(i, x) = 0 for all x ≥0.
(iv) There is a state g ∈I such that f(g, x) is not identically zero.
(v) The production and inventory costs satisfy for all i,
cix +
L

j=1
pij
∞

0
f(j, (x −z)+)dΦi(z) →∞as x →∞.
(7.1)
(vi) The Markov chain (ik)∞
k=0 is irreducible.

MARKOVIAN DEMAND INVENTORY MODELS
135
(vii) There is a state h ∈I such that 1 −Φh(ε) = ρ > 0 for some ε > 0.
(viii) For each i, the inequality q
′−(i, 0) ≤¯f
′+(i, 0) −¯ci holds.
(ix) E ξk ≤D < ∞for all k.
Remark 7.1 Assumptions (i)–(iii) reﬂect the usual structure of the pro-
duction and inventory costs to prove the optimality of an (si, Si) policy.
Note that K is the same for all i. In the stationary case, this is equivalent
to the condition (2.18) required in the nonstationary model for the exis-
tence of an optimal (si, Si) policy; (see Chapter 2). Assumption (iv) rules
out trivial cases where the optimal policy is never to order. Assump-
tion (v) means that either the unit ordering cost ci > 0 or the second
term in (7.1), which is the expected holding cost, or both, go to inﬁnity
as the surplus level x goes to inﬁnity. While related, Assumption (v) nei-
ther implies nor is implied by Assumption (iv). Assumption (v) is borne
out of practical considerations and is not very restrictive. In addition,
it rules out such unrealistic trivial cases as the one with ci = 0 and
f(i, x) = 0, x ≥0, for each i, which implies ordering an inﬁnite amount
whenever an order is placed. Assumptions (iv) and (v) generalize the
usual assumption made by Scarf (1960) and others that the unit inven-
tory holding cost h > 0. Assumption (viii) replaces the more stringent
assumption in the classical literature that the unit shortage cost is not
smaller than the unit price.
Remark 7.2 Assumptions (vi) and (vii) are needed to deplete any given
initial inventory in a ﬁnite expected time. While Assumption (vii) says
that in at least one state h, the expected demand is strictly larger than
zero, Assumption (vi) implies that the state h would occur inﬁnitely
often with ﬁnite expected intervals between successive occurrences.
Remark 7.3 Assumption (viii) means that the marginal shortage cost
in one period is larger than or equal to the expected unit ordering cost
less the expected marginal inventory holding cost in any state of the
next period.
If this condition does not hold, that is, if −q
′−
n (i, 0) <
¯ci
n+1 −¯f
′+
n+1(i, 0) for some i, a speculative retailer may ﬁnd it attractive
to meet a smaller part of the demand in period n than is possible from
the available stock, carry the leftover inventories to period (n + 1), and
order a little less as a result in period (n + 1), with the expectation
that he will be better oﬀ. Thus, Assumption (viii) rules out this kind of
speculation on the part of the retailer. But such a speculative behavior
is not allowed in our formulation of the dynamics in any case, since the
demand in any period must be satisﬁed to the extent of the availability of

136
Average Cost Models with Lost Sales
inventories. This suggests that it might be possible to prove our results
without Assumption (viii).
The objective is to minimize the expected long-run average cost
J(i, x; U)
=
lim sup
N→∞
1
N E
# N−1

k=0
[c(ik, uk) + f(ik, xk)
+q(ik, xk + uk −ξk)]
$
,
(7.2)
with i0 = i and x0 = x ≥0, where U = (u0, u1, . . .), ui ≥0, i = 0, 1, . . . ,
is a history-dependent or nonanticipative decision (order quantities) for
the problem. Such a control U is termed admissible. Let U denote the
class of all admissible controls. The surplus balance equations are given
by
xk+1 = (xk + uk −ξk)+, k = 0, 1, . . . .
(7.3)
Our aim is to show that there exist a constant λ∗, termed the optimal
average cost, which is independent of the initial i and x, and a control
U∗∈U such that
λ∗= J(i, x; U∗) ≤J(i, x; U)
for all
U ∈U,
(7.4)
and
λ∗
=
lim
N→∞
1
N E
# N−1

k=0
[c(ik, u∗
k) + f(ik, x∗
k)
+q(ik, xk + uk −ξk)]
$
,
(7.5)
where x∗
k, k = 0, 1, . . . , is the surplus process corresponding to U∗with
i0 = i and x0 = x.
To prove these results, we will use the vanishing discount approach.
That is, by letting the discount factor α in the discounted cost problem
approach one, we will show that we can derive a dynamic programming
equation whose solution provides an average optimal control and the
associated minimum average cost λ∗.
For this purpose, we recapitulate relevant results for the discounted
cost problem obtained in Chapter 4.
Remark 7.4 Note that the objective function (7.2) is slightly, but not
essentially, diﬀerent from that used in the classical literature. Whereas
we base the surplus cost on the initial surplus in each period, the usual
practice in the literature is to charge the cost on the ending surplus levels,
which means to have f(ik, xk+1) instead of f(ik, xk) in (7.2). Note that

MARKOVIAN DEMAND INVENTORY MODELS
137
xk+1 is also the ending inventory in period k. It should be obvious that
this diﬀerence in the objective functions does not change the long-run
average cost for any admissible policy. By the same token, we can justify
our choice to charge shortage costs at the end of a given period.
7.3.
Discounted Cost Model Results
from Chapter 4
Consider the model formulated above with the average cost objective
(7.2) replaced by the extended real-valued objective function
Jα(i, x; U) =
∞

k=0
αkE[c(ik, uk)+f(ik, xk)+q(ik, xk+uk−ξk)], 0 ≤α < 1.
(7.6)
Deﬁne the value function with i0 = i and x0 = x as
vα(i, x) = inf
U∈U Jα(i, x; U).
(7.7)
Let B0 denote the class of all continuous functions from I × R into
[0, ∞), and the pointwise limits of sequences of these functions; (see
Feller (1971)). Note that it includes piecewise-continuous functions. Let
B1 denote the space of functions in B0 that are of linear growth, i.e., for
any b ∈B1, 0 ≤b(i, x) ≤Cb(1 + |x|) for some Cb > 0. Let B2 denote the
subspace of functions in B1 that are uniformly continuous with respect
to x ∈R. For any b ∈B1, we deﬁne
F(b)(i, y) =
L

j=1
pij

M
0
b(j, (y −z)+)dΦi(z).
(7.8)
Theorem 7.1 Let Assumptions (i)–(iii), (v), (viii), and (ix) hold.
Then, we have the following results.
(a) The value function vα(·, ·) is in B2, and it solves the dynamic
programming equation
vα(i, x)
=
f(i, x) + inf
u≥0{c(i, u) + E[q(i, x + u −ξi)
+α
L

j=1
pijvα(j, (x + u −ξi)+)]}
=
f(i, x) + inf
u≥0{c(i, u) + Eq(i, x + u −ξi)
+αF(vα)(j, x + u)}.
(7.9)

138
Average Cost Models with Lost Sales
(b) vα(i, ·) is K-convex and there are real numbers (sα
i , Sα
i ), sα
i ≤Sα
i ,
such that the feedback policy ˆuα
k(i, x) = (Sα
i −x)1Ix<sα
i is optimal.
Proof. (Actually Theorem 7.1 has been stated but not proved in Chap-
ter 4.) The proof of part (a) follows the lines of the proof of Theorem 3.3
in Chapter 3 by taking the limit of the n-period value function, for n
tending to inﬁnity.
Part (b) immediately follows since the limit of a
sequence of K-convex functions is K-convex.
□
7.4.
Limiting Behavior as the Discount Factor
Approaches 1
Hereafter, we will omit the additional superscript α on the control
policies for ease of notation. Thus, for example, ˆuα
k(i, x) will be denoted
simply as ˆuk(i, x). Since we do not consider the limits of the control
variables as α →1, the practice of omitting the superscript α will not
cause any confusion. In any case, the dependence of controls on α will
always be clear from the context.
To insure a “smooth” limiting behavior for α →1, we prove in
Lemma 7.2 that vα(i, ·) is locally equi-Lipschitzian. For this we need
some notation and a preliminary result. For any y > 0, let
τy := inf{n :
n

k=0
ξk ≥y}
be the ﬁrst index for which the cumulative demand is not less than y.
The following required result is proved in Chapter 5.
Lemma 7.1 Let Assumptions (vii) and (viii) hold. Then, for any l ∈I,
we have E(τy|i0 = l) < ∞.
Lemma 7.2 Under Assumptions (i)-(iii), (vi) , (vii), and (ix), vα(i, ·)
is locally equi-Lipschitzian, i.e., for X > 0 there is a positive constant
C1 < ∞, independent of α, such that
|vα(i, x) −vα(i, ˜x)| ≤C1|x −˜x|
for all
x, ˜x ∈[0, X].
(7.10)
Proof. Consider the case ˜x ≥x. Let us ﬁx an α ∈[0, 1). It follows
from Theorem 7.1 that there is an optimal feedback strategy U. Use the
strategy U with initial surplus x, and the strategy ˜U deﬁned by
˜uk = [uk −(˜xk −xk)]+ =

0
if
uk ≤˜xk −xk,
uk + xk −˜xk
if
uk > ˜xk −xk,

MARKOVIAN DEMAND INVENTORY MODELS
139
with initial ˜x, xk, and ˜xk denoting the inventory levels resulting from
the respective strategies. It is easy to see that the inequalities
0 ≤˜xk −xk ≤˜x −x and ˜uk ≤uk
hold for all k. Let ˜τ := τ˜x for ease of notation. If ˜uk = 0 for all k ∈[0, ˜τ],
then ˜x˜τ = x˜τ = 0, and the two trajectories are identical for all k > ˜τ. If
˜uk′ ̸= 0 for some k′ ∈[0, ˜τ], then ˜xk′ = xk′, and the two trajectories are
identical for all k > k′. In any case, the two trajectories are identical for
all k > ˜τ. From Assumptions (i)–(iii), we have
c(ik, ˜uk) ≤c(ik, uk),
|f(ik, ˜xk) −f(ik, xk)| ≤Cf|˜x −x|,
|q(ik, ˜xk + ˜uk −ξk) −q(ik, xk + uk −ξk)| ≤Cq|˜x −x|.
Therefore,
vα(i, ˜x) −vα(i, x)
≤
Jα(i, ˜x; ˜U) −Jα(i, x; U)
=
E

˜τ

k=0
αk(f(ik, ˜xk) −f(ik, xk) + q(ik, ˜xk + ˜uk −ξk)
−q(ik, xk + uk −ξk) + c(ik, ˜uk) −c(ik, uk))

≤
E

˜τ

k=0
αk(Cf + Cq)|˜x −x|

≤
E(˜τ + 1)(Cf + Cq)|˜x −x|.
(7.11)
It immediately follows from Lemma 7.1 that E(˜τ +1)=E(τ˜x +1|i0 =i) ≤
E(τx + 1|i0 = i) < ∞.
To complete the proof, it is suﬃcient to prove the above inequality
for ˜x < x. In this case, let us deﬁne the strategy ˜U by
˜uk =

uk + x −˜x
if uk > 0,
0
otherwise,
It is easy to see that the inequalities
0 ≥˜xk −xk ≥˜x −x and ˜uk −uk ≤x −˜x
hold for all k. Let τ := τx for ease of notation. If uk = 0 for all k ∈[0, τ],
then ˜xτ = xτ = 0, and the two trajectories are identical for all k > τ. If
uk′ ̸= 0 for some k′ ∈[0, τ], then ˜xk′ = xk′, and the two trajectories are

140
Average Cost Models with Lost Sales
identical for all k > k′. In either case, the two trajectories are identical
for all k > τ.
From Assumptions (i)–(iii), we have
c(ik, ˜uk) −c(ik, uk) ≤max{ci}|x −˜x|,
|f(ik, ˜xk) −f(ik, xk)| ≤Cf|˜x −x|,
|q(ik, ˜xk + ˜uk −ξk) −q(ik, xk + uk −ξk)| ≤Cq|˜x −x|.
Therefore,
vα(i, ˜x) −vα(i, x)
≤
Jα(i, ˜x; ˜U) −Jα(i, x; U)
=
E

τ

k=0
αk(f(ik, ˜xk) −f(ik, xk) + q(ik, ˜xk + ˜uk −ξk)
−q(ik, xk + uk −ξk) + c(ik, ˜uk) −c(ik, uk))

≤
E

τ

k=0
αk(Cf + Cq + max{ci})|˜x −x|

≤
E(τ + 1)(Cf + Cq + max{ci})|˜x −x|.
(7.12)
Lemma 7.1 implies again that E(τ+1)=E(τx+1|i0 =i)≤E(τ˜x+1|i0 =i)<∞
and the proof is complete.
□
Lemma 7.3 Under Assumptions (i)–(ix), there are constants α0 ∈[0, 1)
and C2 > 0 such that for all α ≥α0 and for any i for which sα
i > 0, we
have Sα
i ≤C2 < ∞.
Proof. Let us ﬁx the initial state i0 = i for which sα
i > 0. Fix α0 > 0
and a discount factor α ≥α0. Let U = (u(i0, x0), u(i1, x1), . . .) be an
optimal strategy with parameters (sα
j , Sα
j ), j ∈I. Let us ﬁx a positive
real number Y and assume Sα
i > Y . In what follows, we specify a value
of Y, namely Y ∗, in terms of which we will construct an alternative
strategy ˜U that is better than U.
For the demand state g speciﬁed in Assumption (iv), let
τ g := inf{n > 0 : in = g}
be the ﬁrst period (not counting the period 0) with the demand state g.
Furthermore, let d be the state with the lowest per unit ordering cost,
i.e., cd ≤ci for all i ∈I. Then we deﬁne
τ := inf{n ≥τ g : in = d}.

MARKOVIAN DEMAND INVENTORY MODELS
141
Assume x0 = ˜x0 = ¯x := 0, and consider the policy ˜U deﬁned by
⎧
⎨
⎩
˜uk = 0, k = 0, 1, 2, . . . , τ −1,
˜uτ = xτ + u(iτ, xτ),
˜uk = u(ik, xk), k ≥τ + 1.
The two policies and the resulting trajectories diﬀer only in the periods
0 through τ. Therefore, we have
vα(i, ¯x) −Jα(i, ¯x; ˜U)
=
Jα(i, ¯x; U) −Jα(i, ¯x; ˜U)
=
E

τ

k=0
αk(f(ik, xk) −f(ik, ˜xk) + q(ik, xk + uk −ξk)
−q(ik, ˜xk + ˜uk −ξk) + c(ik, uk) −c(ik, ˜uk))

=
E
! τ

k=1
αk(f(ik, xk) + q(ik, xk + uk −ξk) −q(ik, −ξk))
"
+E
! τ

k=0
αkc(ik, uk)
"
−E(ατc(iτ, ˜uτ)).
(7.13)
After ordering in period τ, the total accumulated ordered amount up
to period τ is less for the policy ˜U than it is for U. Observe that the
policy ˜U orders only in the period τ or later. The order of the policy ˜U
is executed at the lowest possible per unit cost cd in the period τ, which
is not earlier than any of the ordering periods of policy U. Because ˜U
orders only once and U orders at least once in periods 0, 1, . . . , τ, the
total ﬁxed ordering cost of ˜U does not exceed the total ﬁxed ordering
cost of U. Thus,
E
! τ

k=0
αkc(ik, uk)
"
≥E(ατc(iτ, ˜uτ)).
Furthermore, it follows from Assumptions (iii), (vi), and (ix) that
E
! τ

k=1
q(ik, −ξt)
"
< ∞.
Because τ ≥τ g, we obtain
E
! τ

k=1
αk(f(ik, xk) + q(ik, xk + uk −ξk))
"
≥E
! τ g

k=1
αkf(ik, xk)
"
,

142
Average Cost Models with Lost Sales
and because Sα
i ≥Y, we obtain
xk ≥Y −
k

t=1
ξt.
Irreducibility of the Markov chain (in)∞
n=0 implies existence of an integer
m, 0 ≤m ≤L, such that P(im = g) > 0. Let m0 be the smallest such
m. It follows that τ g ≥m0 and therefore, for all α ≥α0
E
! τ g

k=1
αkf(ik, xk)
"
≥
αm0E(f(im0, xm0))
≥
αm0
0 E(f(g, Y −
m0

t=1
ξt)|im0 = g)P(im0 = g).
(7.14)
Using Assumptions (ii), (iv), and (ix), it is easy to show that the RHS
of (7.14) tends to inﬁnity as Y goes to inﬁnity. Therefore, we can choose
Y ∗, 0 ≤Y ∗< ∞such that for all α ≥α0,
vα(i, ¯x) −Jα(i, ¯x; ˜U)
≥
αm0
0 E(f(g, Y ∗−
m0

t=1
ξt)|im0 = g)P(im0 = g)
−E
! τ

k=1
q(ik, −ξt)
"
> 0.
(7.15)
Note that the RHS of (7.15) is independent of α. Therefore, for α ≥α0,
a policy with Sα
i > C2 := Y ∗cannot be optimal.
□
7.5.
Vanishing Discount Approach
Lemma 7.4 Under Assumptions (i)-(ix), the diﬀerential discounted
value function wα(i, x) := vα(i, x) −vα(1, 0) is uniformly bounded with
respect to α for all x and i.
Proof. Since Lemma 7.2 implies
|wα(i, x)|
=
|vα(i, x) −vα(1, 0)|
≤
|vα(i, x) −vα(i, 0)| + |vα(i, 0) −vα(1, 0)|
≤
C3|x| + |wα(i, 0)|,
it is suﬃcient to prove that wα(i, 0) is uniformly bounded. Note that C3
may depend on x, but it is independent of α.

MARKOVIAN DEMAND INVENTORY MODELS
143
First, we show that there is an M > −∞with wα(i, 0) ≥M for all α.
Let α be ﬁxed. From Theorem 7.1 we know that in this discounted case
there is a stationary optimal feedback policy U = (u(i, x), u(i, x), . . .).
With k∗= inf{k : ik = i}, we consider the cost for the initial state
(i0, ˜x0) = (1, 0), and the inventory policy ˜U that does not order in peri-
ods 0, 1, . . . , k∗−1, and follows U starting from the period k∗, i.e., ˜U is
deﬁned by

˜uk = 0 for k < k∗,
˜uk = u(ik, xk) for k ≥k∗.
The cost corresponding to this policy is
Jα(1, 0; ˜U) = E
!k∗−1

k=0
αkq(ik, −ξk) + αk∗vα(i, 0)
"
.
(7.16)
Because of Assumptions (iii), (vi) and (ix), there exists a constant M
such that
E
!k∗−1

k=0
q(ik, −ξk)
"
≤−M < ∞.
Therefore, we have
wα(i, 0)
=
vα(i, 0) −vα(1, 0) ≥vα(i, 0) −Jα(1, 0; ˜U)
≥
vα(i, 0) −E
!k∗−1

k=0
αkq(ik, −ξk) + αk∗vα(i, 0)
"
≥
vα(i, 0)(1 −E(αk∗)) + M ≥M.
(7.17)
The validity of the inequality wα(i, 0) ≤M is shown analogously by
changing the role of the states 1 and i. Thus,
|wα(i, x)| ≤C3|x| + max{M, M},
and the proof is complete.
□
Lemma 7.5 Under Assumptions (iii) and (viii), (1 −α)vα(1, 0) is uni-
formly bounded for 0 < α < 1.
Proof. Consider the strategy 0 = (0, 0, . . .). Then, because 0 is not
necessarily optimal,
0 ≤vα(1, 0) ≤Jα(1, 0; 0) = E
! ∞

k=0
αkq(ik, −ξk)
"
.

144
Average Cost Models with Lost Sales
Because of Assumptions (iii) and (ix), Eq(i, −ξk) is bounded for all i and
there is a C4 < ∞such that E(q(ik, −ξk)) < C4. Therefore,
0 ≤(1 −α)vα(1, 0) ≤(1 −α)
∞

k=0
αkC4 = C4.
□
Theorem 7.2 Let Assumptions (i)–(ix) hold. There exist a sequence
(αk)∞
k=1 converging to 1, a constant λ∗, and a locally Lipschitz continuous
function w∗(·, ·), such that
(1 −αk)vαk(i, x) →λ∗
and
wαk(i, x) →w∗(i, x),
locally uniformly in x and i as k goes to inﬁnity. Moreover, (λ∗, w∗)
satisﬁes the average cost optimality equation
w(i, x) + λ
=
f(i, x) + inf
u≥0{c(i, u) + Eq(i, x + u −ξi)
+F(w)(i, x + u)}.
(7.18)
Proof. It is immediate from Lemma 7.2 and the deﬁnition of wα(i, x)
that wα(i, ·) is locally equi-Lipschitzian for α ≥α0, and therefore it
is uniformly continuous on any ﬁnite interval.
Additionally, accord-
ing to Lemma 7.4, wα(i, ·) is uniformly bounded, and by Lemma 7.5,
(1 −α)vα(1, 0) is also uniformly bounded. Therefore, the Arzel`a-Ascoli
Theorem A.3.5 and Lemma 7.2, lead to the existence of a sequence
αk →1, a locally Lipschitz continuous function w∗(i, x), and a constant
λ∗such that
(1 −αk)vαk(1, 0) →λ∗
and
wαk(i, x) →w∗(i, x),
with the convergence of wαk(i, x) to w∗(i, x) being locally uniform.
It is easily seen that
lim
k→∞(1 −αk)vαk(i, x) = lim
k→∞(1 −αk)(wαk(i, x) + vαk(1, 0)) = λ∗.
Substituting vαk(i, x) = wαk(i, x) + vαk(1, 0) into (7.9) yields
wαk(i, x)
+
(1 −αk)vαk(1, 0) = f(i, x) + inf
u≥0{c(i, u)
+Eq(i, x + u −ξi) + αkF(wαk)(i, x + u)}. (7.19)
Since wαk(i, x) converges locally uniformly with respect to x and i and
since for any given x a minimizer u∗in (7.19) can be chosen such that,

MARKOVIAN DEMAND INVENTORY MODELS
145
x + u∗−ξ ∈[0, x + C2], we can use Lemma 7.3 and pass to a limit on
both sides of (7.19) to obtain (7.18). This completes the proof.
□
Lemma 7.6 Let λ∗be deﬁned as in Theorem 7.2. Let Assumptions (i)–
(ix) hold. Then, for any admissible strategy U, we have λ∗≤J(i, x; U).
Proof. Let U = (u0, u1, . . .) denote any admissible decision. Suppose
J(i, x; U) < λ∗.
(7.20)
Put
˜f(k) = E[f(ik, xk) + q(ik, xk + uk −ξk) + c(ik, uk)].
From (7.20), it immediately follows that n−1
k=0 ˜f(k) < ∞for each pos-
itive integer n, since otherwise we would have J(i, x; U) = ∞.
Note
that
J(i, x; U) = lim sup
n→∞
1
n
n−1

k=0
˜f(k),
while
(1 −α)Jα(i, x; U) = (1 −α)
∞

k=0
αk ˜f(k).
(7.21)
Since ˜f(k) is nonnegative for each k, the sum in (7.21) is well-deﬁned
for 0 ≤α < 1, and we can use the Tauberian Theorem A.5.2 to obtain
lim sup
α↑1
(1 −α)Jα(i, x; U) ≤J(i, x; U) < λ∗.
On the other hand, we know from Theorem 7.2 that (1−αk)vαk(i, x)→λ∗
for a subsequence {αk}∞
k=1 converging to one. Thus, there exists an α < 1
such that
(1 −α)Jα(i, x; U) < (1 −α)vα(i, x),
which contradicts the deﬁnition of the value function vα(i, x).
□
7.6.
Veriﬁcation Theorem
Definition 7.1 Let (λ, w) be a solution of the average optimality equa-
tion (7.18). An admissible strategy U = (u0, u1, . . .) is called stable with
respect to w if for each initial inventory level x ≥0 and for each initial
demand state i ∈I,
lim
k→∞
1
k E(w(ik, xk)) = 0,

146
Average Cost Models with Lost Sales
where xk is the inventory level in period k corresponding to the initial
state (i, x) and the strategy U.
Lemma 7.7 Let Assumptions (i)-(ix) hold. Then, there are constants
Si < ∞and 0 ≤si ≤Si, i ∈I, such that
u∗(i, x) =

Si −x,
x < si,
0,
x ≥si,
attains the minimum on the RHS in (7.18) for w = w∗, as deﬁned
in Theorem 7.2.
Furthermore, the stationary feedback strategy U∗=
(u∗, u∗, . . .) is stable with respect to any continuous function w.
Proof. Let {αk}∞
k=0 be the sequence deﬁned in Theorem 7.2. Let
Gαk(i, y)
=
ciy + Eq(i, y −ξi) + αkF(wαk)(i, y)
(7.22)
and
G(i, y)
=
ciy + Eq(i, y −ξi) + F(w∗)(i, y).
(7.23)
Because w∗(i, ·) is K-convex, we know that a minimizer in (7.18) is
given by
u∗(i, x) =

Si −x,
x < si,
0,
x ≥si,
where 0 ≤Si ≤∞minimizes G(i, ·), and si solves
G(si) = K + G(Si)
if a solution to this equation exists, or si = 0 otherwise. Note that if
si = 0, it follows that u∗(i, x) = 0 for all nonnegative x. It remains to
show that Si < ∞.
We distinguish two cases.
Case 1.
If there is a subsequence, still denoted by {αk}∞
k=0, such
that sαk
i
> 0 for all k = 0, 1, ..., then it follows from Lemma 7.3 that
Gαk attains its minimum in [0, C2] for all αk > α0. Thus, Gαk, k =
0, 1, ... are locally uniformly continuous and converge uniformly to
G. Therefore, G attains its minimum also in [0, C2], which implies
Si ≤C2.
Case 2. If there is no such sequence, then there is a sequence, still
denoted by {αk}∞
k=0, such that sαk
i
= 0 for all k = 0, 1, .... It follows
that for all y > x,
Gαk(x) < K + Gαk(y),

MARKOVIAN DEMAND INVENTORY MODELS
147
and therefore, in the limit,
G(x) < K + G(y).
This implies that the inﬁmum in (7.18) is attained for u∗(i, x) ≡0,
which is equivalent to si = 0.
But if si = 0, we can choose Si
arbitrarily, say Si = C2.
It is obvious that the stationary policy U∗is stable with respect to
any continuous function, since we have xk ∈[0, max{C2, x0}] for all
k = 0, 1, . . . for such a policy.
□
Theorem 7.3 (Veriﬁcation Theorem)
(a) Let (λ, w(·, ·)) be a solution of the average cost optimality equa-
tion (7.18), with w continuous on [0, ∞). Then, λ ≤J(i, x; U) for any
admissible U.
(b) Suppose there exists an ˆu(i, x) for which the inﬁmum in (7.18) is
attained. Furthermore, let ˆU = (ˆu, ˆu, . . .), the stationary feedback policy
given by ˆu, be stable with respect to w. Then,
λ
=
J(i, x; ˆU) = λ∗
=
lim
N→∞
1
N E
!
N−1

k=0
f(ik, ˆxk) + q(ik, xk + uk −ξk) + c(ik, ˆuk)
"
,
and ˆU is an average optimal strategy.
(c) Moreover, ˆU minimizes
lim inf
N→∞
1
N E
!
N−1

k=0
f(ik, xk) + q(ik, xk + uk −ξk) + c(ik, uk)
"
over the class of admissible decisions which are stable with respect to w.
Proof. We start by showing that
λ ≤J(i, x; U) for any U stable with respect to w.
(7.24)
We assume that U is stable with respect to w, and then follow the same
approach used in deriving (2.15) to obtain
E{w(ik+1, xk+1) | i0, . . . , ik, ξ0, . . . , ξk−1} = F(w)(ik, xk + uk)
a.s.
(7.25)

148
Average Cost Models with Lost Sales
Because uk does not necessarily attain the inﬁmum in (7.18), we have
w(ik, xk) + λ
≤
f(ik, xk) + c(ik, uk)
+q(ik, xk + uk −ξk) + F(w)(ik, xk + uk)
a.s.,
and from (7.25) we derive
w(ik, xk) + λ
≤
f(ik, xk) + q(ik, xk + uk −ξk) + c(ik, uk)
+E(w(ik+1, xk + uk −ξk) | ik)
a.s.
By taking the expectation of both sides, we obtain
E(w(ik, xk)) + λ
≤
E(f(ik, xk) + q(ik, xk + uk −ξk) + c(ik, uk))
+E(w(ik+1, xk+1)).
Summing from 0 to n −1 yields
nλ
≤
E
!n−1

k=0
f(ik, xk) + q(ik, xk + uk −ξk)
+c(ik, uk)) + E(w(in, xn)) −E(w(i0, x0)).
(7.26)
Divide by n, let n go to inﬁnity, and use the fact that U is stable with
respect to w, to obtain
λ
≤
lim inf
n→∞
1
nE
!n−1

k=0
f(ik, xk)
+ q(ik, xk + uk −ξk) + c(ik, uk)) .
(7.27)
Note that if the above inequality holds for ‘liminf’, it certainly also holds
for ‘limsup’. This proves (7.24).
On the other hand, if there exists a ˆu for which the inﬁmum in (7.18)
is attained , we then have
w(ik, ˆxk) + λ
=
f(ik, ˆxk) + q(ik, ˆxk + ˆuk −ξk) + c(ik, ˆu(ik, ˆxk))
+F(w)(ik, ˆxk + ˆu(ik, ˆxk)),
a.s.,
and we analogously obtain
nλ
=
E
!n−1

k=0
f(ik, ˆxk) + q(ik, ˆxk + ˆuk −ξk) + c(ik, ˆu(ik, ˆxk))
"
+E(w(in, ˆxn)) −E(w(i0, ˆx0)).
(7.28)

MARKOVIAN DEMAND INVENTORY MODELS
149
Because ˆU is assumed stable with respect to w, we get
λ
=
lim
n→∞
1
nE
!n−1

k=0
f(ik, ˆxk) + q(ik, ˆxk + ˆuk −ξk) + c(ik, ˆu(ik, ˆxk)
"
=
J(i, x; ˆU).
(7.29)
For the special solution (λ∗, w∗) deﬁned in Theorem 7.2, and the strat-
egy U∗deﬁned in Lemma 7.7, we have
λ∗= J(i, x; U∗).
Since U∗is stable with respect to any continuous function by Lemma 7.7,
it follows that
λ ≤J(i, x; U∗) = λ∗,
(7.30)
which, in view of Lemma 7.6, proves part (a) of the theorem.
Part (a) of the theorem, together with (7.29), proves the average op-
timality of ˆU over all admissible strategies.
Furthermore, since λ =
J(i, x; ˆU) ≥λ∗by (7.29) and Lemma 7.6, it follows from (7.30) that
λ = λ∗, and the proof of Part (b) is completed.
Finally, Part (c) immediately follows from Part (a) and (7.27).
□
Remark 7.5 It should be obvious that any solution (λ, w) of the av-
erage cost optimality equation and control u∗satisfying (a) and (b) of
Theorem 7.3 will have a unique λ, since it represents the minimum aver-
age cost. On the other hand, if (λ, w) is a solution, then (λ, w+c), where
c is any constant, is also a solution. For the purpose of this chapter, we
do not require w to be unique up to a constant. If w is not unique up
to a constant, then u∗may not be unique. We also do not need w∗in
Theorem 7.2 to be unique.
The ﬁnal result of this section, namely, that there exists an average
optimal policy of (s, S)-type, is an immediate consequence of Lemma 7.7
and Theorem 7.3.
Theorem 7.4 Let Assumptions (i)-(viii) hold. Let si and Si, i ∈I be
deﬁned as in Lemma 7.7. Then, the stationary feedback strategy U∗=
(u∗, u∗, . . .) deﬁned by
u∗(i, x) =

Si −x,
x < si,
0,
x ≥si,
is average optimal.

150
Average Cost Models with Lost Sales
7.7.
Concluding Remarks and Notes
This chapter is based on Cheng and Sethi (1999b) and Beyer and
Sethi (2005). We have proved a veriﬁcation theorem for the average cost
optimality equation, which we have used to establish the existence of an
optimal state-dependent (s, S) policy.
As with the discounted cost models, the optimality of an (s, S) policy
for a lost sales case is established only under the condition of zero order-
ing leadtime; (see references in Chapter 4). With nonzero leadtimes, the
results for models with backlog do not generalize to the lost sales case.
Speciﬁcally, an (s, S) policy is no longer optimal, and the form of the
optimal policy is more complicated; (see, e.g., Zipkin (2008a) and Huh
et al. (2008)). Nevertheless, an (s, S)-type policy is often used without
the optimality proof; (see, e.g., Kapalka, et al. (1999)).

Chapter 8
MODELS WITH DEMAND INFLUENCED
BY PROMOTION
8.1.
Introduction
This chapter deals with a stochastic inventory model in which the
probability distribution of the product demand in any given period de-
pends on some environmental factors, as well as on whether or not the
product is promoted in the period. The problem is to obtain optimal
inventory ordering and product promotion decisions jointly so as to max-
imize the total proﬁt.
Such problems arise in many business environments, where market-
ing tools such as promotions are often used to stimulate consumer de-
mand. The coordination between marketing and inventory management
becomes critical in their decision making. Traditionally, marketing is
mainly concerned with satisfying customers while manufacturing is pri-
marily interested in production eﬃciency. Conﬂicts may arise between
the two business functions because of their diﬀerent primary focus ar-
eas. Furthermore, it is necessary to evaluate the trade-oﬀbetween the
beneﬁt brought by higher sales, and the increased costs caused by pro-
motion and holding more inventory. On the other hand, a promotion
plan must be supported by a coordinated procurement plan to ensure
that suﬃcient stock is available to meet the stimulated demand.
It is obviously desirable to adopt an integrated decision making system
by considering the two types of decisions jointly. However, most works
in inventory literature assume exogenous demand and do not deal with
promotion decisions explicitly. Early eﬀorts in integrating promotional
decisions have been mostly focused on pricing.
A typical approach for modeling the price demand relationship is to
assume that the price-dependent portion of the demand is either additive
D. Beyer et al., Markovian Demand Inventory Models, International Series
153
in Operations Research & Management Science 108,
DOI 10.1007/978-0-387-71604-6 8, c⃝Springer Science+Business Media, LLC 2010

154
Models with Demand Inﬂuenced by Promotion
or multiplicative to the base demand; (see Young (1978)). Karlin and
Carr (1962), Mills (1962), and Zabel (1970) studied the price demand
models with this assumption, and obtained structural results for the ad-
ditive and/or multiplicative cases. Furthermore, Thowsen (1975) showed
that the optimal pricing/inventory policy is a base-stock list price policy
under some additional assumptions. That is, if the initial inventory level
is below the base-stock level, then that stock level is replenished and the
list price is charged; if the initial inventory level is above the base-stock
level, then nothing is ordered, and a price discount is oﬀered.
A dynamic inventory/advertising model with partially controlled ad-
ditive demand is analyzed by Balcer (1983), who obtains a joint optimal
inventory and advertising strategy under certain restrictions. However,
in the Balcer model, the demand/advertising relationship is determinis-
tic because only the deterministic component of demand is aﬀected by
the advertising decision.
Sogomonian and Tang (1993) formulate a mixed integer program for
an integrated promotion and production decision problem, and devise
a “longest path” algorithm for ﬁnding an optimal joint promotion and
production plan.
Their model assumes that demand at each period
depends on the time elapsed since the last promotion, the level of the
last promotion, and the retail price of the current period.
In this chapter, we analyze the joint promotion/inventory manage-
ment problem for a single item in the context of Markov decision process-
es (MDP). Speciﬁcally, we assume that consumer demand is aﬀected by
a Markov process that depends on promotion decisions. The state vari-
able of the Markov process represents the demand state brought about
by changing environmental factors as well as promotion decisions. The
demand state in a period, in turn, determines the distribution of the
random demand in that period.
At the beginning of each period, a decision maker observes the demand
state and the inventory level, and then decides on (a) whether or not
to promote and (b) how much to order. The MDP is modeled so that
demand, and hence the revenue, will increase in the following period after
the product is promoted. However, there is a ﬁxed cost for promoting
the product.
We solve the ﬁnite horizon problem via a dynamic programming ap-
proach. We show that there is a threshold inventory level P for each
demand state such that if the threshold is exceeded, then it is desirable
to promote the product. For the linear ordering cost case, the optimal
inventory replenishment policy is a base-stock type policy.
Our model diﬀers from the existing models in the literature in several
ways. First, we do not stipulate a deterministic functional form of the

MARKOVIAN DEMAND INVENTORY MODELS
155
relationship between promotion and demand. This allows the maximum
ﬂexibility for modeling the demand uncertainty in the presence of pro-
motions. Second, we model the demand as an MDP, which provides a
better modeling approach for demand under the inﬂuence of marketing
activities and other uncertain environmental factors.
We should note that Sethi and Zhang (1994,1995) have developed
a general stochastic production/advertising model with unreliable ma-
chines and random demand inﬂuenced by the level of advertising via a
Markov process. They developed the dynamic programming equations
and show how various hierarchical solutions of the problem can be con-
structed.
They do not study the nature of optimal solutions.
Their
focus is on proving that the constructed hierarchical solutions are ap-
proximately optimal.
The Markov demand modeling technique adopted in this chapter ex-
tends the existing Markov-modulated demand models by introducing
promotion decisions. It provides a new, ﬂexible approach to model de-
mand that depends not only on uncertain environmental factors, but is
also inﬂuenced by promotion decisions. While we limit the scope of our
analysis by including only the promotion decision, other factors that
potentially aﬀect customer demand could also be incorporated in the
model in a similar way.
The remainder of the chapter is organized as follows. In Section 8.2,
we present the mathematical formulation of the promotion/inventory
problem, and provide a preliminary analysis of the problem in a general
setting. The assumptions required for obtaining additional structural
results of the model are discussed in Section 8.3.
In Section 8.4, we
provide the optimality proof for the optimal promotion/inventory poli-
cies. Solutions with simpliﬁed parameters are also discussed. Further
extensions of the model, including those with price discounts as a pro-
motion device, are brieﬂy discussed in Section 8.5. A numerical study is
presented in Section 8.6. The chapter concludes with some concluding
remarks and end notes in Section 8.7.
8.2.
Formulation of the Model
In most classical inventory models, it is usually assumed that both the
price and the demand of the product are parameters and not decision
variables. Hence, the revenue from sales is independent of any decision
variables and can be neglected from the model except for the situation
in which demand not satisﬁed directly from inventory cannot be back-
logged. Furthermore, even in this lost sales case, the situation can be
handled by including the loss in revenue as a penalty cost of the unsatis-
ﬁed demand. Therefore, an optimal inventory policy can be determined

156
Models with Demand Inﬂuenced by Promotion
by minimizing the total cost. However, in our model, promotion deci-
sions will aﬀect the future demand, and hence the future revenue. Thus,
it is important to include the revenue explicitly in the objective function
of the model.
When both revenues and costs are included in the objective function,
one usually formulates a proﬁt maximization problem. Nevertheless, in
order to preserve the similarity with the approach commonly used in
classical inventory literature, we will formulate the problem as a cost
minimization problem by treating revenues as negative costs. This is
equivalent to formulating the problem as a proﬁt maximization problem.
8.2.1
Notation
We will formulate a discrete-time N-period problem consisting of pe-
riod 0, 1, 2, . . . , N−1. For the temporal conventions used in our discrete-
time setting, (see Figure 2.1 of Chapter 2), we introduce the following
notation.
mk
=
the promotion decision in period k such that
mk =

1,
if the product is promoted in period k
0,
otherwise;
pij(m)
=
the transition probability that the demand state changes
from i to j in one period if the promotion value is m;
{ik}
=
a discrete MDP with the transition
matrix P = {pij(mk)};
ξk
=
the demand in period k; it depends on ik but not on
k, and is independent of past demand states and
past demands;
ϕi(·)
=
the conditional density function of ξk when ik = i;
Φi(·)
=
the distribution function corresponding to ϕi;
μi
=
E{ξk|ik = i};
uk
=
the nonnegative order quantity in period k;
xk
=
the inventory level at the beginning of period k;
ck
=
the unit purchase cost in period k, k ∈⟨0, N −1⟩;
cN
=
the shortage cost per unit in period N;
rk
=
the unit revenue in period k, k ∈⟨0, N −1⟩;
rN
=
the salvage cost per unit in period N;
Ak
=
the promotion cost in period k when the product is

MARKOVIAN DEMAND INVENTORY MODELS
157
promoted in the period;
hk
=
the unit inventory holding cost in period k assessed
on the ending inventory in the period;
pk
=
the unit backlogging cost in period k assessed on the
backlog at the end of the period;
lk(z)
=
hkz+ + pkz−, the inventory/backlog cost function in
period k when z is the ending inventory in the period,
z+ = max(0, z), and z−= −min(0, z).
Remark 8.1 All of the cost/revenue parameters are assumed to be in-
dependent of the demand states for the sake of simplicity in exposition.
Given that the unit revenue is independent of the promotion decision,
this may imply that the model does not allow price discount.
How-
ever, as it will be shown in Section 8.5, the price discount can easily be
incorporated in the model by treating it as a part of the promotion cost.
8.2.2
An MDP Formulation
We suppose that an order is placed at the beginning of a period and
delivered instantaneously. Also the promotion decision is made at the
beginning of the period. Subsequently, the actual demand materializes
during the period.
The unsatisﬁed portion of the demand, if any, is
carried forward as backlog.
The expected one-period inventory cost for period k ∈⟨0, N−1⟩, given
the demand state i, is
Lk(i, y)
=
E[lk(y −ξk)|ik = i]
=
 y
0
hk(y −ξ)ϕi(ξ)dξ +
 ∞
y
pk(ξ −y)ϕi(ξ)dξ,
(8.1)
where y is the amount of stock available at the beginning of a period
after the order, if any, is delivered.
We assume that the revenue is received when the demand occurs.
Hence, the total expected net cost in period k, given the initial inventory
level x, the order quantity u ≥0, and the promotion decision m, can be
expressed as
Gk(i, x; m, u)
=
E[lk(x + u −ξk) + Ak1Im=1 + cku −rkξk|ik = i]
=
Lk(i, x + u) + Ak1Im=1 + cku −rkμi.
In the last period N−1, if the ending inventory is positive, it is salvaged
at rN per unit; if the ending inventory is negative, the shortage is met

158
Models with Demand Inﬂuenced by Promotion
at cN per unit. Thus, the terminal cost function can be deﬁned as
gN(x) = cNx−−rNx+.
(8.2)
Since the unit salvage value is normally less than the purchase price, we
have
cN ≥rN ≥0.
(8.3)
Note that cN and rN have diﬀerent meanings than ck and rk, k∈⟨0, N−1⟩.
Let Jn(i, x; M, U), n ∈⟨0, N −1⟩, denote the total expected cost,
including the terminal cost, when the system is operated under the
promotion policy M = {mn, mn+1, . . . , mN−1} and the ordering policy
U = {un, un+1, . . . , uN−1} from period n through period N −1, given
the initial demand state i and the inventory level x at the beginning of
period n. That is,
Jn(i, x; M, U) = E
%
N−1

k=n
Gk(ik, xk; mk, uk) + gN(xN)
&
.
(8.4)
The inventory balance equations are given by

xk+1 = xk + uk −ξk, k ∈⟨n, N −1⟩, with
xn = x, the beginning inventory level in period n.
(8.5)
The objective is to determine M = {mn, mn+1, . . . , mN−1} and U =
{un, un+1, . . . , uN−1} to minimize the expected total cumulative cost. De-
note vn(i, x) to be the inﬁmum of Jn(i, x; M, U), i.e.,
vn(i, x) = inf
M,U Jn(i, x; M, U).
(8.6)
Then, vn(i, x) satisﬁes the dynamic programming equations
⎧
⎪
⎨
⎪
⎩
vn(i, x)
=
inf
m;u≥0 {Gn(i, x; m, u)
+ E[vn+1(in+1, x + u −ξn) | in = i]} , n ∈⟨0, N −1⟩,
vN(i, x)
=
gN(x).
(8.7)
Note that in this MDP formulation, the additional decision variable m
takes values in a ﬁnite set. Thus, the results on the existence of optimal
policies and the veriﬁcation theorem can be obtained in a fashion similar
to those in Chapters 2 and 4. We refer the readers to Bertsekas and
Shreve (1976) for further discussion on the related issues.
Now, we rewrite (8.7) as
vn(i, x)
=
min
m;y≥x {Gn(i, x; m, y −x) + E[vn+1(in+1, y −ξn) | in = i]}

MARKOVIAN DEMAND INVENTORY MODELS
159
=
−cnx + min
m;y≥x{An1Im=1 + cny + Ln(i, y) −rnμi
+
 ∞
0
L

j=1
pij(m)vn+1(j, y −ξ)ϕi(ξ)dξ},
n = 0, . . . , N −1,
(8.8)
vN(i, x)
=
gN(x).
(8.9)
To simplify our analysis, we convert (8.8) and (8.9) to an alternative
set of dynamic programming equations in terms of functions wn, using
the relation
vn(i, x) = wn(i, x) −cnx, n = 0, . . . , N.
(8.10)
The resulting dynamic programming equations are
wn(i, x)
=
min
m;y≥x {An1Im=1 + (cn+1 −rn)μi + (cn −cn+1)y
+Ln(i, y) +
 ∞
0
L

j=1
pij(m)wn+1(j, y −ξ)ϕi(ξ)dξ},
n = 0, . . . , N −1,
(8.11)
wN(i, x)
=
gN(x) + cNx.
(8.12)
Let us deﬁne for n = 0, . . . , N −1,
gn(i, y, m)
=
(cn+1 −rn)μi + (cn −cn+1)y + Ln(i, y)
+
 ∞
0
L

j=1
pij(m)wn+1(j, y −ξ)ϕi(ξ)dξ,
(8.13)
qn(i, x, m)
=
An1Im=1 + min
y≥x gn(i, y, m).
(8.14)
Then, we have for n = 0, . . . , N −1,
wn(i, x) = min
m {qn(i, x, m)}.
(8.15)
For n = N, we use (8.2) and (8.12) and write
wN(i, x) = gN(x) + cNx =

0,
x < 0,
(cN −rN)x,
x ≥0.
(8.16)
8.2.3
The Newsvendor Problem – a Myopic Solution
The value function wn(i, x) given by (8.11) and (8.12), consists of two
components – the cost incurred in the current period and the cost to

160
Models with Demand Inﬂuenced by Promotion
go. A myopic solution can be obtained by ignoring the cost to go, i.e.,
by ignoring the last term in (8.11). Since a promotion aﬀects only the
demand in the future, it will always be true that m = 0 in a myopic
solution. The remaining problem becomes a newsvendor-type problem,
in which the only decision variable is the inventory position y (after the
order is delivered). Let us denote the cost function of the newsvendor
problem by
min
y
gb
n(i, y)
=
(cn+1 −rn)μi + (cn −cn+1)y
+Ln(i, y), n ∈⟨0, N −2⟩.
(8.17)
We can obtain the minimum of gb
n(i, y), n ∈⟨0, N −2⟩, at
¯Sn,i = Φ−1
i
'cn+1 −cn + pn
hn + pn
(
,
(8.18)
provided the various unit costs satisfy the condition
−pn ≤cn+1 −cn ≤hn.
(8.19)
When cn+1−cn+pn < 0, we have ¯Sn,i = 0. In this case, the “newsven-
dor” is always better oﬀby postponing the purchase since the saving of
cn −cn+1 from the decreased purchase cost outweighs the backlogging
cost pn. On the other hand, when cn+1−cn > hn, we have ¯Sn,i = ∞. This
means that the “newsvendor” makes money on each unsold unit by sal-
vaging it at cn+1 in period n+1, which is greater than the unit purchase
plus holding cost. In our dynamic inventory problem, Condition (8.19) is
nothing but the usual condition which rules out any speculative motive.
Henceforth, we will assume that the costs satisfy (8.19).
It is clear from Assumption 8.2 (i) that
¯Sn,i′ ≥¯Sn,i, ∀n ∈⟨0, N −1⟩and i′ > i.
(8.20)
We further assume that
¯Sn+1,i ≥¯Sn,i, n ∈⟨0, N −2⟩, and i ∈I.
(8.21)
Assumption (8.21) is equivalent to assuming that (cn+1−cn+pn)/(hn+
pn) is nondecreasing in n. When cn+1 = cn, n ∈⟨0, N−1⟩, (8.21) would
imply that hn/pn is nonincreasing in n.

MARKOVIAN DEMAND INVENTORY MODELS
161
8.2.4
Joint Optimal Promotion and Inventory Policies
In this section, we will characterize the optimal policies derived from
the dynamic programming equations by identifying the special structures
that an optimal policy exhibits under certain conditions.
We will ﬁrst deﬁne the optimal policy for the inventory/promotion
problem as follows.
Theorem 8.1 The optimal inventory policy for the problem deﬁned by
(8.11) can be characterized by two base-stock levels, and the optimal pro-
motion policy is of multithreshold type.
The proof of this theorem is given in Section 8.4, after additional
assumptions have been made and the relevant preliminary results are
provided in Section 8.3.
The ﬁrst structural property of the optimal policy is like that of the
standard inventory models with linear ordering costs; a base-stock policy
is still optimal. Moreover, the optimal base-stock level in each period
is contingent on the demand state and the promotion decision to be
made. The two base-stock levels correspond to two diﬀerent decisions
on promotions, respectively.
While the optimality of a base-stock policy with the base-stock level
given by Sm
n,i, immediately follows from the quasi-convexity of gn(i, x, m)
(the proof will be provided in Section 8.4), the promotion policy is de-
termined by the relative position of the two functions qn(i, x, 0) and
qn(i, x, 1). We deﬁne the diﬀerence between the two functions as
Δqn(i, x) = qn(i, x, 0) −qn(i, x, 1),
n = 0, . . . , N −1.
Given i and x, if Δqn(i, x) ≥0, then it is optimal to promote; otherwise,
it is optimal not to promote.
Let us consider the equation
Δqn(i, x) = 0.
(8.22)
Suppose there exists a ﬁnite number of real roots of this equation. Let us
label these roots as P k
n,i, k = 1, 2, . . . , Nr, such that P 1
n,i < P 2
n,i < . . . <
P
Nr
n,i . If there exists no real root of (8.22), we let Nr = 1 and P 1
n,i = −∞
when Δqn(i, x) > 0, ∀x, and P 1
n,i = ∞when Δqn(i, x) < 0, ∀x.
It follows that the optimal promotion policy is a function of x and is
implemented in the following fashion. When x ≤P 1
n,i, do not promote;
when P 1
n,i < x ≤P 2
n,i, promote; when P 2
n,i < x ≤P 3
n,i, do not promote;
and so on. We may call this type of policy a multithreshold policy.
□

162
Models with Demand Inﬂuenced by Promotion
8.3.
Assumptions and Preliminaries
In order to provide a simple and meaningful characterization to the
optimal policy for the somewhat general MDP problem formulated in
Section 8.3, we introduce some additional assumptions.
8.3.1
Quasi-convexity
To obtain the optimality of simple form policies for our model, we
would like to have the function gn(i, y, m) to be quasi-convex in y ac-
cording to Deﬁnition C.1.2. For this purpose, we make the following
important, albeit restrictive, assumption on the demand density func-
tions.
Assumption 8.1 The demand density functions ϕi(·), i = 1, . . . , L, are
assumed to be of P´olya frequency of order 2 (PF2) according to Deﬁni-
tion C.1.1.
Assumption 8.1 is, in fact, a popular assumption made in the inventory
literature; (see Porteus (1971)). As Porteus and others have argued, such
a condition is not very restrictive because the class of PF2 densities is
not lacking signiﬁcant members. It contains all exponential densities and
all ﬁnite convolutions of such densities. Furthermore, any mean μ and
any variance in the range [μ2/n, μ2] can be produced with a convolution
of n exponential densities.
We will further note that such a condition on demand densities is
not necessary for our results. However, we use this condition for the
convenience of mathematical derivation for our results.
8.3.2
Stochastic Dominance
In the inventory literature (see the review in Section 8.1), it is usu-
ally assumed that demand consists of a deterministic component and a
stochastic component, with promotion activities aﬀecting only the de-
terministic component. Such an assumption provides a simpliﬁed math-
ematical modeling approach for describing the promotion/demand re-
lationship. However, it does not accurately reﬂect the real-world situ-
ation, since the eﬀect of promotional activities on demand cannot be
predetermined with certainty. To capture the stochastic nature of the
promotion/demand relationship, we will use a more realistic modeling
approach based on the concept of stochastic dominance for our joint
inventory/promotion decision problem.
Modeling the demand uncertainty induced by environmental factors
and promotional activities in a stochastic fashion has not been attempted
in the inventory literature. Our models represent a new approach to de-

MARKOVIAN DEMAND INVENTORY MODELS
163
mand modeling. Based on the stochastic ordering relations introduced
above, we are able to describe the relationship between demand and pro-
motion activities in mathematical terms. See Section B.5 for additional
information on stochastic dominance and some of the commonly used
deﬁnitions of stochastic ordering.
For the purpose of the analysis carried out in this chapter, we adopt
Deﬁnition B.5.1 of stochastic ordering.
Assumption 8.2
(i) There exists a stochastic ordering relation between demands in dif-
ferent demand states such that
ζ1 ≤
st ζ2 ≤
st . . . ≤
st ζL.
(ii) For any 1 ≤l ≤L,
L

j=l
pij(1) ≥
L

j=l
pij(0), and
(8.23)
(iii)
L

j=l
pij(m) is nondecreasing in i.
(8.24)
Remark 8.2 In simpler terms, Assumption 8.2 (i) means that the de-
mand in a higher demand state is more likely to be larger than that
in a lower demand state. Assumption 8.2 (ii) reﬂects the fact that a
promotion would more likely lead to a demand state with a stochas-
tically larger demand. Assumption 8.2 (iii) means that if the current
demand state is higher, the next period is more likely to be in a demand
state with a stochastically larger demand. Together, these assumptions
will ensure that a promotion not only always generates a stochastically
greater demand in the next period, but also has a positive impact on
future demand.
Assumption 8.2 may not apply to the cases in which customers build
inventories during an on-sale period and purchase less afterwards. How-
ever, our current model is more suitable to the situation where promo-
tions are made in the form of advertising.
Assumption 8.3
pij(1) = 0, ∀j < i
and
pij(0) = 0, ∀i < j.
Remark 8.3 Assumption 8.3 means that the demand state in the next
period after the product is promoted cannot be stochastically smaller

164
Models with Demand Inﬂuenced by Promotion
than that in the current period. Likewise, if the product is not promoted
in the current period, the demand state in the next period cannot be
stochastically greater than that in the current period. Assumption 8.3
is stronger than Assumption 8.2, in the sense that some of the transition
probabilities are ﬁxed at zero. However, the nonzero elements of the
transition probability matrix are not binding by Assumption 8.2.
The purpose of making these assumptions is to overcome some math-
ematical diﬃculties that are involved in proving the optimality of the
simple form policies introduced in Section 8.4.2.
8.4.
Structural Results
We have formulated a proﬁt-maximizing inventory/promotion deci-
sion problem as a cost minimization problem, and have developed the
dynamic programming equations for it.
In Section 8.2, we have characterized the general structure of the op-
timal policies without detailed proofs. We have shown that the optimal
policies for (8.7) can be expressed in simple forms. Speciﬁcally, the in-
ventory policy still retains the simplicity of base-stock policies, while the
promotion policy is of threshold type.
In this section, we will provide the proof for the optimality of the
policies deﬁned in Theorem 8.1.
Furthermore, we will show that the
optimal policies can be further simpliﬁed under certain conditions.
8.4.1
Quasi-convexity of gn
Now we present some useful properties of the dynamic programming
equations and functions involved in (8.11-8.15).
Lemma 8.1 Denote the minimizer of gn(i, y, m) by Sm
n,i. For i = 1, . . . , L
and m = 0, 1,
(a) gn(i, y, m) is quasi-convex in y with Sm
n,i ≥0 for n = 0, . . . , N −1;
(b) wn(i, x) is nondecreasing in x and constant when x ≤0 for n =
0, . . . , N.
Proof. In view of cN ≥rN, part(b) is obvious from (8.16) when n = N.
It is easy to see from (8.13) and (8.15) that (b) follows directly from (a)
for n < N −1.
We will now prove part (a) for n = 0, . . . , N −1I1 by induction. Let
us deﬁne
¯gn(i, y, m) = (cn −cn+1)y + ln(y) +
L

j=1
pij(m)wn+1(j, y),

MARKOVIAN DEMAND INVENTORY MODELS
165
where ln(y) is the surplus cost function as deﬁned in Section 8.2.1. Then,
(8.13) can be written as
gn(i, y, m) = (cn −rn)μi +
 ∞
0
¯gn(i, y −ξ, m)ϕi(ξ)dξ.
When n = N−1, wn+1(j, y) = wN(j, y) is nondecreasing in y and is a
constant when y ≤0 by deﬁnition. From the deﬁnition of ln(y), we have
(cn −cn+1)y + ln(y) = (cn −cn+1 + hn)y+ + (pn −cn+1 + cn)y−,
which is convex in y with the minimum at 0.
Therefore, ¯gn(i, y, m)
is quasi-convex in y. Furthermore, the demand density ϕi is assumed
to be PF2. By Theorem C.1.1,
) ∞
0
¯gn(i, y −ξ, m)ϕi(ξ)dξ, and hence,
gn(i, y, m) is also quasi-convex in y with its minimizer Sm
n,i ≥0. Now, we
have completed the induction for the base case n = N −1.
Let us assume that (a) holds for n = k < N −1 and prove that (a) is
true for n = k −1. Since (a) is assumed to be true for k = n, it follows
that (b) is true for k = n, i.e., wn+1(j, y) is nondecreasing in y and
constant when y ≤0. Using the same line of reasoning used above for
the base case, we can show that for n = k −1, gn(i, y, m) is quasi-convex
in y with its minimizer Sm
n,i ≥0. Therefore, (a) is proved for n = k −1,
and the induction is completed.
□
8.4.2
Simple Form Solutions
In this subsection we will demonstrate that under certain conditions,
the optimal solution exhibits some special structures that will simplify its
computation greatly. Furthermore, the simplicity of the special struc-
tures allows for easier interpretations and implementation of optimal
policies.
The simple form solutions will be obtained with additional
assumptions made about demand and transition probabilities of the
Markov chain.
8.4.2.1
(S0, S1, P ) Policies
We will show in this subsection that if a stochastic dominance rela-
tionship exists between the demands with and without promotions, the
optimal promotion and ordering policy for the ﬁnite horizon problem
can be characterized as an (S0, S1, P) policy, which is deﬁned below.
Definition 8.1 An (S0, S1, P) policy is speciﬁed by three control pa-
rameters S0, S1, and P with S0 ≤S1. Under an (S0, S1, P) policy, the
product is promoted when the initial inventory x is above or equal to P.
Furthermore, an order is placed to increase the inventory position to S1

166
Models with Demand Inﬂuenced by Promotion
when x < S1 and the product is promoted, and to S0 when x < S0 and
the product is not promoted.
This is a special case of the optimal policies described in Section 8.4.
Here, the multithreshold policy for promotion decisions is simpliﬁed to
a single threshold policy.
First, we show some monotonicity properties that are needed for de-
riving the new results.
Lemma 8.2 Let cN = rN and let Assumption 8.2 hold. Then for
1 ≤i < i′ ≤L,
(a) wn(i, x) ≥wn(i′, x), n ∈⟨0, N⟩;
(b) S1
n,i′ ≥S1
n,i , n ∈⟨0, N −1⟩; and
(c) S1
n+1,i ≥S1
n,i and S1
n,i ≥S0
n,i, n ∈⟨0, N −1⟩.
Proof. We prove (a) by induction. When n = N, wN(i, x) = 0 by deﬁ-
nition. Suppose that wn+1(i, x) is nonincreasing in i. First, let us prove
that gn(i, y, m) ≥gn(i′, y, m), ∀m, y. Since wn+1(j, y) is nonincreasing
in j, according to Assumption 8.2 (iii), L
j=1 pij(m)wn+1(j, y) is also
nonincreasing in i. Furthermore, by (B.3) we have
 ∞
0
L

j=1
pij(m)wn+1(j, y −ξ)ϕi(ξ)dξ
≥
 ∞
0
L

j=1
pij(m)wn+1(j, y −ξ)ϕi′(ξ)dξ.
Using Assumption 8.2 (ii), we obtain that
 ∞
0
L

j=1
pij(m)wn+1(j, y −ξ)ϕi′(ξ)dξ
≥
 ∞
0
L

j=1
pi′j(m)wn+1(j, y −ξ)ϕi′(ξ)dξ.
On account of
gn(i, y, m) = gb
n(i, y) +
 ∞
0
L

j=1
pij(m)wn+1(j, y −ξ)ϕi(ξ)dξ
(8.25)
and (8.13), it is clear that
gn(i, y, m) ≥gn(i′, y, m).

MARKOVIAN DEMAND INVENTORY MODELS
167
In view of (8.14) and the quasi-convexity of gn, we have
qn(i, x, m) ≥qn(i′, x, m), ∀i′ > i, x, m.
Finally, from (8.15), we conclude that
wn(i, x) ≥wn(i′, x),
which proves (a).
Let us examine (8.25) again. For n = N −1, it is clear that S1
N−1,i =
¯SN−1,i since wN(i, x) = 0. Hence, from (8.20) we know that S1
N−1,i′ ≥
S1
N−1,i, ∀i′ > i. When n = N −2, from Assumption 8.3 we have
 ∞
0
L

j=1
pij(1)w′
n+1(j, y −ξ)ϕi(ξ)dξ
=
 ∞
0
L

j=i
pij(1)w′
n+1(j, y −ξ)ϕi(ξ)dξ,
which is equal to 0 when y ≤¯SN−1,i and is nonnegative otherwise, ac-
cording to Lemma 8.1 (b). By Assumption (8.21), ¯SN−2,i ≤¯SN−1,i. Thus,
S1
N−2,i = ¯SN−2,i. Therefore, by (8.20), S1
N−2,i′ ≥S1
N−2,i, ∀i′ > i. Repeating
this step for n = N −3, . . . , 0, we complete the proof for (b).
Since S1
n,i = ¯Sn,i, then according to (8.21), S1
n+1,i ≥S1
n,i. Now let us
examine (8.25) with m = 0. Since
 ∞
0
L

j=1
pij(0)w′
n+1(j, y −ξ)ϕi(ξ)dξ ≥0,
we have S0
n,i ≤¯Sn,i, i.e., S0
n,i ≤S1
n,i. Thus, (c) is proved.
□
Remark 8.4 The assumption cN = rN is used in this proof for conve-
nience in the exposition. However, it can be relaxed by recalculating
¯SN−1,i with the last item included in (8.13).
Because of Assumption 8.3, we are able to determine the optimal
base-stock level in a myopic fashion, which is reﬂected in part (b) of
Lemma 8.2. We are now ready to show that the optimal policies for the
N-period problem are of (S0, S1, P) type.
Theorem 8.2 When x ≤S1
n,i, an (S0
n,i, S1
n,i, Pn,i) policy is optimal for
the problem deﬁned by (8.10-8.13) under Assumption 8.2, with Pn,i given
by the smallest root of equation (8.22).

168
Models with Demand Inﬂuenced by Promotion
Proof. From the quasi-convexity of gn(i, y, m), g′
n(i, y, m) ≥0 when y ≤
Sm
n,i. By (8.14), we have q′
n(i, x, m) = 0 when x ≤Sm
n,i, and q′
n(i, x, m) ≥
0 when x > Sm
n,i. Also, we know that S0
n,i ≤S1
n,i by Lemma 8.2 (c).
Hence, for x ≤S1
n,i,
∂
∂x(qn(i, x, 0) −qn(i, x, 1)) ≥0,
which means that there exists at most one real root for (8.22) when
x ≤S1
n,i. Hence, a simple threshold policy is optimal for the promotion
decision when x ≤S1
n,i.
□
Remark 8.5 First, x ≤S1
n,i is not a necessary condition for Theo-
rem 8.2. It is used for obtaining a simple proof. Second, the condition
is not very restrictive and is satisﬁed for all n ≥k if xk ≤S1
k,i for any
period k ≥0 with demand state i. This can be seen from the following
argument.
By Assumption 8.3, if the product is promoted in period
k, the demand state j in period k + 1 will not be lower than i. Since
S1
k,i ≤S1
k+1,j, and ∀j ≥i and S0
k,i ≤S1
k,i, ∀i as shown in Lemma 8.2 (c),
then as soon as xk ≤S1
k,i for any k ≥0, we have xn ≤S1
n,i for all sub-
sequent periods n = k + 1, k + 2, . . . , N −1 and all possible i. In view
of these arguments, the condition will hold when x0 = 0, which is often
the case.
Remark 8.6 Without further specifying cost and density functions, we
may have three typical cases in terms of the relative position of Pn,i as
given below.
Case 1. Pn,i = −∞. In this case, a promotion is always desired. The
corresponding optimal inventory policy is a base-stock policy with
the base-stock level given by S1
n,i. In fact, this is the only case in
which Pn,i < S0
n,i, since q′
n(i, x, m) = 0 when x ≤Sm
n,i, m = 1, 2.
Case 2. S0
n,i < Pn,i ≤S1
n,i. In this case, a promotion is desirable only
when the initial inventory level exceeds the critical level Pn,i. Two
base-stock levels S0
n,i and S1
n,i are applied, respectively, depending on
whether or not the product is promoted.
Case 3. S0
n,i ≤S1
n,i < Pn,i. This case is similar to Case 2 except that
no order will be placed once the product is promoted.
8.4.2.2
(S, P ) Policies
In this subsection, we replace Assumptions 8.2 (i) and 8.2 (iii) by the
following.

MARKOVIAN DEMAND INVENTORY MODELS
169
Assumption 8.4 We assume that ξ1 ≤ξ2 ≤. . . ξL, in the sense of the
ﬁrst moment ordering.
Remark 8.7 Although Assumption 8.4 is more restrictive than As-
sumption 8.2 (i) used in the previous subsection, it still represents a
generalization of the commonly used assumption of the additive random
demands in the literature. On the positive side, we can now drop As-
sumption 8.3 for the results to be obtained in this subsection. We further
note that Assumption 8.4 can be replaced by some weaker assumptions
under which the results in this subsection would still hold.
Theorem 8.3 Under Assumptions 8.4, 8.2 (ii), and 8.2 (iii), a special
case of the (S0, S1, P) policy, i.e., the (S, P) policy with Sn,i = S0
n,i =
S1
n,i, is optimal for the model.
Proof. Assumption 8.4 is equivalent to
ϕ1(x −μ1) = ϕ2(x −μ2) = · · · = ϕL(x −μL)
in view of Deﬁnition B.5.3. Since ξ1 is nonnegative, i.e., ϕ1(x)=0, ∀x≤0,
it follows that
ϕi(x) = 0, ∀x ≤μi −μ1, i = 1, . . . , L.
(8.26)
Also from (8.18),
¯Sn,1 −μ1 = ¯Sn,2 −μ2 = · · · = ¯Sn,L −μL.
(8.27)
The proof is done by induction. For k = N −1, SN−1,i = S0
N−1,i =
S1
N−1,i = ¯SN−1,i for all i. Assume for k = n + 1 that Sn+1,i = S0
n+1,i =
S1
n+1,i = ¯Sn+1,i for all i.
It is known from Lemma 8.1 (b) that w′
n+1(i, y) = 0, ∀y ≤S0
n+1,i,
and w′
n+1(i, y) ≥0, ∀y > S0
n+1,i. Thus,
L

j=1
pij(m)w′
n+1(j, y)
 = 0,
y ≤S0
n+1,1 = ¯Sn+1,1,
≥0,
otherwise.
Furthermore, by (8.26) and (8.27),
 ∞
0
L

j=1
pij(m)w′
n+1(j, y −ξ)ϕi(ξ)dξ
⎧
⎨
⎩
= 0,
y ≤¯Sn+1,1 + μi −μ1
= ¯Sn+1,i,
≥0,
otherwise.
Since ¯Sn,i ≤¯Sn+1,i, we conclude that Sn,i = S0
n,i = S1
n,i = ¯Sn,i.
□

170
Models with Demand Inﬂuenced by Promotion
8.5.
Extensions
In this section, we brieﬂy discuss some extensions of our model.
Inﬁnite Horizon Problems. When the planning horizon is inﬁnite,
the formulation of the model can be presented as follows. The total
cost of the inﬁnite horizon problem to be minimized is given by
Jn(i, x; M, U) = E
∞

k=n
αk−nGk(ik, xk; mk, uk),
(8.28)
where 0 < α < 1 is a discount factor. The inventory balance equa-
tions are given by

xk+1 = xk + uk −ξk, k = n, n + 1, . . . , with
xn = x, the initial inventory level.
(8.29)
Denote the minimum of Jn(i, x; M, U) by vn(i, x), i.e.,
vn(i, x) = inf
M,U Jn(i, x; M, U).
(8.30)
Then, vn(i, x) satisﬁes the dynamic programming equations
vn(i, x)
=
min
m;u≥0 {Gn(i, x; m, u)
+α E[vn+1(in+1, x + u −ξn)|in = i]} ,
(8.31)
n = 0, 1, . . . .
By assuming stationary data, we can suppress the time index in the
formulation and expect that there exists a stationary optimal policy
which does not depend on time. (Issues regarding the existence of an
optimal feedback-type policy in inﬁnite horizon models have been ad-
dressed in Bertsekas and Shreve (1976).) Therefore, the DP equation
can be written as
v(i, x)
=
min
m;u≥0{G(i, x; m, u)
+α
L

j=1
pij(m)
 ∞
0
v(j, x + u −ξ)ϕi(ξ)dξ}. (8.32)
Since the inﬁnite horizon problem can be considered as a limiting case
of the ﬁnite horizon problem when N →∞, its optimal policy will
have the same structure as the optimal policy in the ﬁnite horizon
case, i.e., base-stock inventory policies and the threshold promotion
policy, or (S0, S1, P) policy, under the corresponding assumptions
made in the ﬁnite horizon problem.

MARKOVIAN DEMAND INVENTORY MODELS
171
Lost Sales. The dynamic programming equations can be written as
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
vn(i, x)
=
min
m;u≥0 {Gn(i, x; m, u)
+
) ∞
0 [vn+1(in+1, (x + u −ξ)+)ϕi(ξ)dξ

,
0 ≤n ≤N −1,
vN(i, x)
=
−cNx+.
(8.33)
For this problem, we only need to verify that
gn(i, y, m)=cny + Ln(i, y) +
 ∞
0
L

j=1
pij(m)vn+1(j, (y −ξ)+)ϕi(ξ)dξ
is also quasi-convex in y, where Ln(i, y) is deﬁned as
Ln(i, y) =
 ∞
0
[ln(i, y −ξ) −rn(y −E(y −ξ)+)]ϕi(ξ)dξ.
Furthermore, we have
gn(i, y, m)
=
(cn −rn)y +
 ∞
0
[ln(i, y −ξ) + rnE(y −ξ)+
+
L

j=1
pij(m)wn+1(j, (y −ξ)+)
−cn+1E(y −ξ)+]ϕi(ξ)dξ
=
 ∞
0
[ln(i, y −ξ) + (rn −cn)(y −ξ)−
+(cn −cn+1)(y −ξ)+
+
L

j=1
pij(m)wn+1(j, (y −ξ)+)]ϕi(ξ)dξ.
It is easy to verify that
ln(i, y) + (rn −cn)y−+ (cn −cn+1)y+ +
L

j=1
pij(m)wn+1(j, y+)
is quasi-convex in y. Therefore, gn(i, y, m) is also quasi-convex in y
since the density of ξi is assumed to be PF2.
Price Discounts.
Price discounts can be considered a part of the
promotion cost. Let bk be a proportional price discount oﬀered if the
product is promoted in period k. Then, the actual unit revenue will

172
Models with Demand Inﬂuenced by Promotion
be (1−bk)rk. By considering the revenue loss as part of the promotion
cost, the problem has the same form as the original problem.
Multiple Promotion Levels. We assume that the promotion eﬀort
can take on one of M discrete levels. These discrete levels could repre-
sent promotions communicated through diﬀerent advertising media.
At diﬀerent promotion levels, the promotion expenditures incurred
are also diﬀerent.
Carryover Eﬀect of Promotions. First of all, the carryover eﬀect
of a promotion can be partially captured by the Markovian transi-
tion law associated with the demand process. However, we may also
incorporate this factor explicitly in the following way. If we assume
that the eﬀect of a promotion lasts J −1 periods, then we can redeﬁne
the demand state as
˜i = (i, j), i = 1, . . . , L, j = 0, . . . , J −1,
where j is the number of periods elapsed from the last promotion. In
such a way, we can transform the new problem to the standard form
and obtain a similar solution.
Nonlinear Inventory Cost Function.
By assuming the demand
density function to be PF2, we may relax the requirements on the
inventory cost function. We only require lk(x) to be quasi-convex in
x and attain its minimum at x = 0. It is clear that such a generalized
form of lk(x) will not change the results obtained in this chapter.
Case
c
α
p
q
A
S0
1, S0
2, S0
3
S1
1, S1
2, S1
3
3.1
0.50
0.90
1.00
5.00
2.00
12,12,16
16,17,17
3.2
1.00
0.90
1.00
2.00
2.00
8,8,12
12,15,15
3.3
2.00
0.90
1.00
2.00
2.00
0,0,0
0,0,0
3.4
2.50
0.90
1.00
2.00
2.00
0,0,0
0,0,0
3.5
1.00
0.90
2.00
4.00
2.00
9,9,13
13,16,16
3.6
1.00
0.90
1.00
4.00
2.00
11,11,15
15,16,16
3.7
1.00
0.90
1.00
5.00
2.00
11,11,15
15,17,17
3.8
0.50
0.90
1.00
2.00
2.00
9,9,13
13,16,16
3.9
0.50
0.90
1.00
1.00
2.00
7,7,10
10,14,14
3.10
0.50
0.95
1.00
2.00
2.00
9,9,13
13,16,16
3.11
0.50
0.85
1.00
2.00
2.00
9,9,13
13,16,16
Table 8.1.
Numerical results for the MDP model with uniform demand distribution.

MARKOVIAN DEMAND INVENTORY MODELS
173
Case
c
α
p
q
A
S0
1, S0
2, S0
3
S1
1, S1
2, S1
3
4.1
0.50
0.90
1.00
5.00
2.00
8,8,14
14,19,19
4.2
1.00
0.90
1.00
2.00
2.00
4,4,10
10,15,15
4.3
2.00
0.90
1.00
2.00
2.00
0,0,0
0,0,0
4.4
2.50
0.90
1.00
2.00
2.00
0,0,0
0,0,0
4.5
1.00
0.90
2.00
4.00
2.00
6,6,12
12,17,17
4.6
1.00
0.90
1.00
4.00
2.00
7,7,13
13,18,18
4.7
1.00
0.90
1.00
5.00
2.00
7,7,13
13,18,18
4.8
0.50
0.90
1.00
2.00
2.00
6,6,12
12,17,17
4.9
0.50
0.90
1.00
1.00
2.00
3,3,9
9,14,14
4.10
0.50
0.95
1.00
2.00
2.00
6,6,12
12,17,17
4.11
0.50
0.85
1.00
2.00
2.00
6,6,12
12,17,17
Table 8.2.
Numerical results for the MDP model with truncated normal demand
distribution.
8.6.
Numerical Results
In this section, we design a comparison study to demonstrate the
advantage of the joint promotion and inventory decision making. For
the same sample data, two types of policies are computed. One is the
(S0, S1, P) policy, which we have shown to be optimal under certain
conditions. The other is the policy that one would use in a decentral-
ized system, i.e., promotion decisions and inventory decisions are made
separately. More speciﬁcally, we assume that in a decentralized system,
the information about the current inventory level is not considered for
the promotion decision making purpose. A promotion will be conducted
only if the expected revenue increase exceeds the promotion cost.
Our numerical results conﬁrm that the joint decision making leads
to better performance than the decentralized decision making. Tables
8.1 and 8.2 are the results for the cases with uniform demand distribu-
tions and truncated normal distributions, respectively. The parameters
c, α, h, p and A are the unit purchase cost, the discount factor, the unit
holding cost, the unit shortage cost, and the promotion cost, respec-
tively. Figures 8.1-8.4 plot some of the cost functions obtained by two
types of decision making systems corresponding to the Cases 3.1-3.4 in
Table 8.1 . The solid lines (OP) are the results using our MDP models,
while the dotted lines (DC) represent the results obtained based on the
decentralized system.
The base-stock values computed using the two diﬀerent approaches
happen to be the same in these particular cases. However, the values

174
Models with Demand Inﬂuenced by Promotion
of the cost functions are diﬀerent. In each case, our model performs no
worse than the decentralized model.
8.7.
Concluding Remarks and Notes
In this chapter based on Cheng and Sethi (1999a) and Cheng (1996),
we have developed an MDP model for a joint inventory/promotion de-
cision problem, where the state variable of the MDP represents the de-
mand state brought about by changing environmental factors as well as
promotion decisions. Optimal inventory and promotion decision poli-
cies in a ﬁnite horizon setting are obtained via dynamic programming.
Under certain conditions, we show that there is a threshold inventory
level P for each demand state such that if the threshold is exceeded,
then it is desirable to promote the product. For the proportional order-
ing cost case, the optimal inventory replenishment policy is a base-stock
type policy with the optimal base-stock level dependent on the promo-
tion decision. Several extensions of the model are also discussed. We
also provided numerical results in Section 8.6 to demonstrate the beneﬁt
achieved by the joint inventory/promotion decision making.

MARKOVIAN DEMAND INVENTORY MODELS
175
10
20
30
40
50
60
70
80
90
100
0
5
10
15
20
25
30
35
40
v(i, 1)
x
OP
DC
10
20
30
40
50
60
70
80
0
5
10
15
20
25
30
35
40
v(i, 2)
x
OP
DC
10
15
20
25
30
35
40
45
50
55
60
0
5
10
15
20
25
30
35
40
v(i, 3)
x
OP
DC
Figure 8.1.
Numerical results for Case 3.1.

176
Models with Demand Inﬂuenced by Promotion
0
10
20
30
40
50
60
70
80
90
0
5
10
15
20
25
30
35
40
v(i, 1)
x
OP
DC
0
10
20
30
40
50
60
70
0
5
10
15
20
25
30
35
40
v(i, 2)
x
OP
DC
0
5
10
15
20
25
30
35
40
45
50
0
5
10
15
20
25
30
35
40
v(i, 3)
x
OP
DC
Figure 8.2.
Numerical results for Case 3.2.

MARKOVIAN DEMAND INVENTORY MODELS
177
-10
0
10
20
30
40
50
60
70
80
0
5
10
15
20
25
30
35
40
v(i, 1)
x
OP
DC
-10
0
10
20
30
40
50
60
0
5
10
15
20
25
30
35
40
v(i, 2)
x
OP
DC
-20
-10
0
10
20
30
40
0
5
10
15
20
25
30
35
40
v(i, 3)
x
OP
DC
Figure 8.3.
Numerical results for Case 3.3.

178
Models with Demand Inﬂuenced by Promotion
0
10
20
30
40
50
60
70
80
90
100
0
5
10
15
20
25
30
35
40
v(i, 1)
x
OP
DC
0
10
20
30
40
50
60
70
0
5
10
15
20
25
30
35
40
v(i, 2)
x
OP
DC
0
5
10
15
20
25
30
35
40
45
50
55
0
5
10
15
20
25
30
35
40
v(i, 3)
x
OP
DC
Figure 8.4.
Numerical results for Case 3.4.

Chapter 9
VANISHING DISCOUNT APPROACH
VERSUS STATIONARY DISTRIBUTION
APPROACH
9.1.
Introduction
In Part III, we derived the structure of the optimal policy to minimize
the long-run average cost by using the vanishing discount method. In
the classical inventory literature, a stationary distribution approach is
often used to minimize the long-run average cost. In this approach, the
stationary distribution of the inventory levels is obtained for a speciﬁc
class of policies, the best policy in this class is found, and then it is
proven that this policy is average optimal. In this chapter, we review
the stationary distribution approach in solving the simpler problem of
an inventory model with i.i.d demands, and then show how the results of
this analysis relate to those obtained by the vanishing discount approach.
In the context of inventory problems, Iglehart (1963b) and Veinott
and Wagner (1965) were the ﬁrst to study the issue of the existence of
an optimal (s, S)-type policy for average cost problems with independent
demands, linear holding and backlog costs, and ordering costs consisting
of a ﬁxed cost and a proportional variable cost. Iglehart obtained the
stationary distribution of the inventory/backlog (or surplus) level given
an (s, S) policy using renewal theory arguments (see also Karlin (1958a)
and Karlin (1958b)), and developed an explicit formula for the stationary
average cost L(s, S), s ≤S, associated with the policy.
Iglehart assumed that the function L(s, S) is continuously diﬀeren-
tiable and that there exists a pair (s∗, S∗), −∞< s∗< S∗< ∞, which
minimizes L(s, S) and satisﬁes the ﬁrst-order conditions for an interior
local minimum. While he does not specify these assumptions explic-
itly, and certainly does not verify them, he uses them in showing the
key result that the minimum average cost of a sequence of problems
D. Beyer et al., Markovian Demand Inventory Models, International Series
179
in Operations Research & Management Science 108,
DOI 10.1007/978-0-387-71604-6 9, c⃝Springer Science+Business Media, LLC 2010

180
Vanishing Discount Approach vs. Stationary Distribution Approach
with increasing ﬁnite horizons approaches L(s∗, S∗) asymptotically as
the horizon becomes larger. Veinott and Wagner (1965), with a short
additional argument suggested by Derman (1965), were able to advance
the Iglehart result into the optimality of the (s∗, S∗) policy in the special
case of discrete demands; (see also Veinott (1966)). While Veinott and
Wagner deal with the case of discrete demands, they assume, without
proving, that Iglehart’s results derived for the continuous demand case
also hold for their case. It should also be mentioned that Derman’s short
additional argument also applies to the continuous demand case treated
in Iglehart and proves that an L(s, S)-minimizing pair (s∗, S∗), if there
exists one, provides an optimal inventory policy; (see Section 9.7).
A good deal of research has been carried out in connection with the
average cost (s, S) models since then.
With the exception of Zheng
(1991) and Huh et al. (2008), however, most of this research devoted to
establishing the optimality of (s, S) strategies, uses bounds on the in-
ventory position after ordering. Examples are Tijms (1972), Wijngaard
(1975), and K¨uenle and K¨uenle (1977). On the other hand, quite a few
papers are concerned with the computation of the (s∗, S∗) pair that min-
imizes L(s, S), and not with the issue of establishing the optimality of an
(s, S) policy. Some examples are Stidham (1977), Zheng and Federgruen
(1991), Federgruen and Zipkin (1984), Hu et al. (1993), and Fu (1994).
For other references, the reader is directed to Zheng and Federgruen
(1991), Porteus (1985), Sahin (1990), and Presman and Sethi (2006).
Furthermore, this literature has generally assumed that together, the
papers of Iglehart (1963b) and Veinott and Wagner (1965), have estab-
lished the optimality of an (s, S)-type policy for the problem.1 But, this
is not quite the case, however, since the assumptions on L(s, S) implicit
in Iglehart, to our knowledge, have not been satisfactorily veriﬁed.
We will compare the stationary cost analyses of Iglehart (1963b) and
Veinott and Wagner (1965) and the vanishing discount approach used
in Part II of this book. Both approaches prove the optimality of (s, S)
strategies, but for somewhat diﬀerent notions of the long-run average
1Another possible approach views continuous demand distributions as the limit of a sequence
of discrete demand distributions. Such a limiting procedure could lead to a proof of optimality
of (s, S) policies in the continuous demand case.
However, this is by no means a trivial
exercise.

MARKOVIAN DEMAND INVENTORY MODELS
181
cost to be minimized. It turns out that the optimal (s, S) strategies are
optimal for these diﬀerent notions of long-run average cost.
We will reproduce the results of Iglehart (1963b) and Veinott and
Wagner (1965) in some detail. Some of the proofs of implicit assumptions
are missing in Iglehart (1963b) with respect to the model under his
consideration. Without these results, the Iglehart analysis cannot be
considered complete. Moreover, these results are by no means trivial.2
For this purpose, we need to precisely specify Iglehart’s model. Then
for this model, we must show that there exists a pair (s∗, S∗), −∞<
s∗≤S∗< ∞that minimizes L(s, S). In order to accomplish this, we
establish in Section 9.7, a priori bounds on the minimizing values of
s and S. We should caution that any veriﬁcation of these assumptions
on L(s, S) should not use arguments that rely on the optimality of an
(s, S) policy. With the bounds established in Section 9.7, the continuity
of L(s, S) provides us with the existence of a minimum.
Continuous
diﬀerentiability of L(s, S) follows from the deﬁnition of the surplus cost
function L(y) and the assumption of a continuous density for the de-
mand. We then show that if (s∗, S∗) with s∗= S∗is a minimum, then
there is another minimum (s, S) with s < S. It is then possible to assume
that an interior solution always exists, and to obtain it by the ﬁrst-order
conditions of an interior minimum.
Tijms (1972) uses the theory of Markov decision processes (MDP) to
prove the optimality of (s, S) strategies for a modiﬁed inventory prob-
lem with discrete demand. In particular, he imposes upper and lower
bounds on the inventory position after ordering. These bounds provide
a compact (ﬁnite) action space as well as bounded costs. Under these
conditions, standard MDP results yield the optimality of an (s, S) strat-
egy.
Zheng (1991) has provided a rigorous proof of the optimality of an
(s, S) policy in the case of discrete demands for the model in Veinott
and Wagner (1965). He was able to use the theory of countable state
Markov decision processes in the case when the solution of the average
cost optimality equation for the given problem is bounded, which is
clearly not the case here since the inventory cost is unbounded. Note
that this theory does not deal with the continuous demand case as it
would involve an uncountable state MDP. Zheng relaxed the problem
by allowing inventory disposals, and since the inventory costs are charged
2In fact, the motivation to write our paper arose from Example 9.4 in Section 9.4.
The
example shows that even for a well-behaved demand density function satisfying Iglehart’s
assumptions, the derivation of equation (9.12) crucial for the subsequent analysis requires
additional arguments not given in Iglehart’s paper. The example also shows that in some
cases a base-stock policy can be optimal even in the presence of a positive ﬁxed ordering cost.

182
Vanishing Discount Approach vs. Stationary Distribution Approach
on ending inventories in his problem, he obtained a bounded solution for
the average cost optimality equation of the relaxed problem that involves
a dispose-down-to-S component. But the dispose-down-to-S component
of the optimal policy would be invoked in the relaxed problem only in
the ﬁrst period (and only when the initial inventory is larger than S),
which has no inﬂuence on the long-run average cost of the policy. It
follows, therefore, that the (s, S) policy, without the dispose-down-to-S
component, will also be optimal for the original problem.
The plan of the chapter is as follows. In Section 9.2, we state the
problem under consideration.
Section 9.3 summarizes the results of
Iglehart relevant to the average cost minimization problem. Further-
more, we point out exactly which implicit assumptions have been used
by Iglehart without veriﬁcation. We develop an example in Section 9.4
to show that even under the quite restrictive assumption of the exis-
tence of a continuous demand density, the assumptions implicit in the
Iglehart analysis are not necessarily satisﬁed. In Section 9.5, we derive
asymptotic bounds on the minimum cost function. In Section 9.6, we
review the analysis contained in Veinott and Wagner (1965) that is de-
voted to the solution of the average cost problem in the case of discrete
demands. To the extent that they use Iglehart’s analysis for their solu-
tion, we show how their paper is not quite complete and how it can be
completed. Section 9.7 contains the proofs needed for the completion of
Iglehart’s analysis and for establishing the optimality of an (s, S) policy
in the continuous demand case. Section 9.8 lists results that connect the
stationary distribution approach and the vanishing discount approach;
both are undertaken to prove the existence of an optimal (s, S) strat-
egy for the average cost inventory problem. Section 9.9 concludes the
chapter.
9.2.
Statement of the Problem
In this section we formulate a stationary one-product periodic review
inventory model with the following notation and assumptions.
(i) The surplus (inventory/backlog) level at the beginning of period
k prior to ordering is denoted by xk. Unsatisﬁed demand is fully
backlogged.
(ii) The surplus level after ordering, but before demand realizes, in
period k is denoted by yk. Orders arrive immediately.
(iii) The one period demands ξk, k = 1, 2, . . ., are i.i.d. and the demand
distribution has a density ϕ(·). Let μ denote the mean demand.
Assume 0 < μ < ∞.

MARKOVIAN DEMAND INVENTORY MODELS
183
(iv) The surplus cost function L(y), where y is the surplus level imme-
diately after ordering, is given by
L(y) = E(h([y −ξ]+)) + E(p([y −ξ]−)),
where h(·) and p(·) represent holding and shortage cost functions,
respectively. Furthermore, L(y) is assumed to be convex and ﬁnite
for all y.
(v) The ordering cost when an amount u is ordered is given by
ˆc(u) = K1Iu>0 + cu, c ≥0, K > 0.
Given an ordering up to policy Y = (y1, y2, . . .), the inventory balance
equation is
xk+1 = yk −ξk.
Let fn(x|Y ) denote the expected total cost for an n-period problem with
the initial inventory x1 = x when the order policy Y is used, i.e.,
fn(x|Y ) = E
 n

k=1
[ˆc(yk −xk) + L(yk)]

.
The objective is to minimize the expected long-run average cost
a(x|Y ) = lim inf
n→∞
1
nfn(x|Y )
(9.1)
over the class of all nonanticipative or history-dependent policies Y.
In what follows we use fn(x|s, S) and a(x|s, S) instead of fn(x|Y ) and
a(x|Y ), with a slight abuse of notation, if Y is a stationary (s, S) strat-
egy.
The model described above is investigated in a more general setting of
Markovian demand and polynomially growing surplus cost in Chapter 6
for the average cost objective function
J(x|Y ) = lim sup
n→∞
1
nfn(x|Y ).
(9.2)
There we establish the average cost optimality equation and prove the
optimality of an (s, S)-type policy by using the vanishing discount ap-
proach.
A policy minimizing either (9.1) or (9.2) does not necessarily minimize
the other.
However, if an optimal policy Y ∗with respect to (9.1) is
such that limn→∞(1/n)fn(x|Y ∗) exists, then this limit is less than or
equal to both objective functions associated with any policy Y ∈Y. On

184
Vanishing Discount Approach vs. Stationary Distribution Approach
the other hand, if a policy Y ∗is optimal with respect to (9.2) and if
limn→∞(1/n)fn(x|Y ∗) exists, then Y ∗may still not minimize (9.1). For
this reason, Veinott and Wagner (1965) consider the objective function
(9.1) to be the stronger of the two; often the term more conservative is
used instead. In Sections 9.7 and 9.8, we complete Iglehart’s stationary
state analysis and use Derman’s short additional argument to obtain
an (s, S) policy, which is optimal with respect to (9.1) and has the
limit (1/n)fn(x|s, S)) as n →∞. Thus, this (s, S) policy also minimizes
both objective functions (9.1) and (9.2). In addition, by combining the
stationary approach with the dynamic programming approach, we show
in Section 9.8 that any (s, S) policy that is optimal with respect to (9.2)
is also optimal with respect to (9.1).
9.3.
Review of Iglehart (1963b)
In this section we will summarize the results of a paper by Iglehart
(1963b) relevant to the problem of minimizing the long-run average cost,
and point out the implicit assumptions which have been used in his paper
without veriﬁcation.
Let fn(x) denote the minimal total cost for the n-period problem when
the initial surplus level is x, i.e.,
fn(x) = min
Y fn(x|Y ).
The sequence of functions (fm(x))n
m=1 satisﬁes the dynamic program-
ming equation
fn(x) = min
y≥x[ˆc(y −x) + L(y) +
∞

0
fn−1(y −ξ)ϕ(ξ)dξ].
(9.3)
Furthermore, it is known that fm(x) is K-convex, and an optimal strat-
egy minimizing the total cost is determined by a sequence (sm, Sm)n
m=1
of real numbers with sm ≤Sm, such that the optimal order quantity in
period m is
um =

Sm −xm
if
xm ≤sm,
0
if
xm > sm,
where xm denotes the surplus level at the beginning of the mth period.3
It is obvious that limn→∞fn(x) = ∞for all initial surplus levels x.
Iglehart investigates the asymptotic behavior of the function fn(x) for
large n. Heuristic arguments suggest that for a stationary inﬁnite hori-
3Well-known papers dealing with this ﬁnite horizon problem are those of Scarf (1960), Sch¨al
(1976), and Veinott (1966).

MARKOVIAN DEMAND INVENTORY MODELS
185
zon inventory problem, a stationary strategy should be optimal. Fur-
thermore, it is reasonable to expect that this stationary strategy is of
(s, S)-type.
Iglehart obtains the stationary distribution of the surplus level and
the expected one-period cost under any given (s, S) strategy satisfying
−∞< s ≤S < ∞. He uses the result of Karlin (1958a,b) that the
surplus level xn at the beginning of period n converges in distribution
to a random variable whose distribution has the density
f(x) =
⎧
⎪
⎨
⎪
⎩
m(S −x)
1 + M(Δ),
s < x ≤S,
h(Δ, s −x)
1 + M(Δ) ,
x ≤s,
(9.4)
where Δ := S −s, M(·) and m(·) are the renewal function and the
renewal density associated with ϕ(·), respectively, and h(Δ, ·) is the
density of the order quantity in excess of Δ. Note that by the Elementary
Renewal Theorem B.3.1, we have M(t)/t →1/μ as t →∞. Also M(t) →
∞as t →∞.
Furthermore, the one-period cost C(x), given the initial surplus x, is
C(x) =

K + L(S) + c(S −x),
x ≤s,
L(x),
s < x ≤S.
(9.5)
Averaging C(x) with respect to f(x) yields the following formula for the
stationary cost L(s, S) per period corresponding to the strategy param-
eters s and S:
L(s, S)
=
s

−∞

K + L(S) + c(S −x)

f(x)dx +
S

s
L(x)f(x)dx
=
K + L(S) +
S)
s
L(x)m(S −x)dx
1 + M(S −s)
+ cμ.
(9.6)
Remark 9.1 It follows from the convergence in distribution of the sur-
plus level in period n that the expected cost E(C(xn)) in period n con-
verges to L(s, S). Therefore, we have
a(x|s, S) = lim
n→∞
1
nfn(x|s, S) = lim
n→∞
1
n
! n

i=1
E(C(xn))
"
= L(s, S).

186
Vanishing Discount Approach vs. Stationary Distribution Approach
In many cases, it is more convenient to deﬁne the stationary cost in
terms of Δ and S:
˜L(Δ, S) := L(S −Δ, S) =
K + L(S) +
Δ)
0
L(S −x)m(x)dx
1 + M(Δ)
+ cμ, (9.7)
or in terms of s and Δ:
ˆL(s, Δ)
:=
L(s, s + Δ)
=
K + L(s + Δ) +
Δ)
0
L(s + Δ −x)m(x)dx
1 + M(Δ)
+ cμ. (9.8)
Iglehart then attempts to minimize L(s, S) with respect to s and S.
Implicitly, he assumes L(s, S) to be continuously diﬀerentiable and that
the minimum is attained for some s∗and S∗satisfying −∞< s∗<
S∗< ∞, i.e., the minimum is attained at an interior point and not at
the boundary s = S of the feasible parameter set. Therefore, he can
take derivatives of ˆL(s, Δ) with respect to s and Δ and obtain necessary
conditions for the minimum by setting them equal to zero:
∂ˆL(s, Δ)
∂s
= L′(s + Δ) +
Δ

0
L′(s + Δ −x)m(x)dx = 0
(9.9)
and
∂ˆL(s, Δ)
∂Δ
=
L′(s + Δ) +
Δ)
0
L′(s + Δ −x)m(x)dx + L(s)m(Δ)
1 + M(Δ)
−
K + L(s + Δ) +
Δ)
0
L(s + Δ −x)m(x)dx
(1 + M(Δ))2
m(Δ) = 0. (9.10)
Note that if s∗= S∗, Condition (9.9) must be relaxed to ∂ˆL/∂s ≤0.
Combining the necessary Conditions (9.9) and (9.10), one obtains
((1+M(Δ))L(s)−K−L(s+Δ)−
Δ

0
L(s+Δ−x)m(x)dx)m(Δ)=0. (9.11)

MARKOVIAN DEMAND INVENTORY MODELS
187
Assuming further that m(Δ∗) = m(S∗−s∗) > 0 for the minimizing
values s∗and S∗, Iglehart obtains the following formula, crucial for his
subsequent analysis, by dividing by m(Δ) :
L(s∗) =
K+ L(s∗+ Δ∗) +
Δ∗
)
0
L(s∗+ Δ∗−x)m(x)dx
1 + M(Δ∗)
= L(s∗, S∗) −cμ.
(9.12)
Let us recapitulate Iglehart’s implicit assumptions here. For his sub-
sequent analysis, he requires that
(I1) there is a pair (s∗, S∗) with −∞< s∗< S∗< ∞(i.e., an interior
solution) that minimizes L(s, S),
(I2) L(s, S) is continuously diﬀerentiable, and
(I3) the minimizing pair (s∗, S∗) satisﬁes m(S∗−s∗) > 0.
We will see that there is always a pair (s∗, S∗) satisfying Assumption
(I1) since K > 0. On the other hand, in general, not every minimizer of
L(s, S) satisﬁes Assumption (I1) even though K > 0; (see Example 9.4).
Assumption (I2) is satisﬁed because of the continuous diﬀerentiability of
L(·) and the existence of a continuous density, which implies continuous
diﬀerentiability of M(·). Assumption (I3) is more diﬃcult to deal with.
In Example 9.4, Assumption (I3), i.e., m(S∗−s∗) > 0, is violated for
all minimizing (s∗, S∗) pairs. The fact that Assumption (I3) does not
hold in general is a problem that can be ﬁxed. It turns out that it is
not Assumption (I3) itself but rather equation (9.12) derived with the
help of this assumption that is crucial for the subsequent analysis. In
Section 9.7, we prove that there is always a minimizing pair (s∗, S∗) that
satisﬁes (9.12), even if m(S∗−s∗) = 0 for all minimizing pairs.
9.4.
An Example
We develop an example with K > 0, in which s = S is optimal and
m(S∗−s∗) = 0 for all minimizing pairs of parameters (s∗, S∗). To do so,
we prove two preliminary results.
Lemma 9.1 Let L(·) be a convex function with limx→±∞L(x) = ∞.
Then for 0 ≤x1 ≤x2,
min
S {L(S) + L(S −x1)} ≤min
S {L(S) + L(S −x2)}.
Proof. Because of the limit property and the convexity of L(·), L(S) +
L(S −x2) attains its minimum. Let S2 be a minimum point of L(S) +

188
Vanishing Discount Approach vs. Stationary Distribution Approach
L(S −x2). Let us ﬁrst assume that L(S2) ≥L(S2 −x2). Then, it follows
from the convexity of L(·) that L(S2 −x2 + x1) ≤L(S2), and we obtain
min
S {L(S) + L(S −x1)}
≤
L(S2 −x2 + x1) + L(S2 −x2)}
≤
L(S2) −L(S2 −x2)
=
min
S {L(S) + L(S −x2)}.
If L(S2) < L(S2 −x2), we conclude from the convexity of L(·) that
L(S2 −x1) ≤L(S2 −x2). Thus,
min
S {L(S) + L(S −x1)}
≤
L(S2) + L(S2 −x1)}
≤
L(S2) + L(S2 −x2)
=
min
S {L(S) + L(S −x2)},
which completes the proof.
□
Lemma 9.2 Let L(·) be a convex function with limx→±∞L(x) = ∞.
Then
lim
D→∞min
S {L(S) + L(S −D)} = ∞.
Proof. Fix D > 0 and let S∗denote a ﬁxed minimum point of L(·). It
is easy to see that
L(S) ≥min{L(S∗+ D/2), L(S∗−D/2)} for |S −S∗| ≥D/2.
Also, substituting S −D for S,
L(S −D) ≥min{L(S∗+ D/2), L(S∗−D/2)} for |S −D −S∗| ≥D/2.
Since at least one of the above conditions is satisﬁed and L(x) ≥L(S∗)
for all x, we obtain
L(S) + L(S −D) ≥min{L(S∗+ D/2), L(S∗−D/2)} + L(S∗).
Therefore, it follows that
lim
D→∞min
S {L(S) + L(S −D)}
≥
lim
D→∞min{L(S∗+ D/2), L(S∗−D/2)} + L(S∗) = ∞,
and the proof is completed.
□
For the purpose of this example, we assume the unit purchase cost
c = 0. It can easily be extended to the case c > 0. Let the one-period

MARKOVIAN DEMAND INVENTORY MODELS
189
demand consist of a deterministic component D ≥0 and a random
component d. Let ϕ(·) be the density of d, where ϕ(·) is continuous on
(−∞, ∞), ϕ(t) = 0 for t ≤0, and ϕ(t) > 0 for t ∈(0, ε) for some ε > 0.
The density of the one-period demand is then given by ϕD(t) = ϕ(t−D).
It is continuous on the entire real line. We denote the renewal density
and the renewal function with respect to ϕD by mD and M D, respectively.
Let
LD(x) =
∞

−∞
l(x −ξ)ϕD(ξ)dξ
be the expected one-period surplus cost function.
Let L(·) = L0(·).
Then, we have
LD(x) = L(x −D).
Now the stationary cost function, given s and S, is
LD(s, S) =
K + LD(S) +
S)
s
LD(x)mD(S −x)dx
1 + M D(S −s)
,
and in view of Δ = S −s, we deﬁne
˜LD(Δ, S) = LD(S −Δ, S) =
K + LD(S) +
Δ)
0
LD(S −x)mD(x)dx
1 + M D(Δ)
.
We will show that there is a constant D0 such that for all D > D0, the
pair that minimizes the stationary average cost is of the following form
(s∗, S∗) is a minimum point of LD(s, S) if, and only if, S∗minimizes
LD(S) and 0 ≤S∗−s∗≤D.
It is obvious that because of ϕD(t) = 0 for all t ≤D, mD(t) = 0 and
M D(t) = 0 for t ≤D. Therefore, for any given Δ ≤D,
min
S
˜LD(Δ, S) = K + min
S
LD(S) = K + min
S
L(S).
We will show that for a suﬃciently large D,
min
S
˜LD(Δ, S) > K + min
S
L(S) for all Δ > D.
To do so, we consider three cases that arise when Δ > D for any given
D.

190
Vanishing Discount Approach vs. Stationary Distribution Approach
Case 1. Let Δ ∈{Δ : 0 < M D(Δ) ≤1}. Then,
min
S
˜LD(Δ, S)
=
K + min
S

LD(S) +
Δ)
0
LD(S −x)mD(x)dx
*
1 + M D(Δ)
≥
K + min
S

LD(S) + min
x∈[D,Δ]{LD(S −x)}M D(Δ)
*
1 + M D(Δ)
=
K +
1
1 + M D(Δ)
!
min
S
#
(1 −M D(Δ))LD(S)
+ min
x∈[D,Δ]{LD(S −x) + LD(S) −K}M D(Δ)}
$"
≥
K +
1
1 + M D(Δ)
!
(1 −M D(Δ)) min
S
LD(S)
+M D(Δ) min
S { min
x∈[D,Δ]{LD(S −x) + LD(S) −K}}
"
.
(9.13)
Using Lemma 9.1, we have
min
S { min
x∈[D,Δ]{LD(S −x) + LD(S) −K}}
=
min
S { min
x∈[D,Δ]{L(S −D −x) + L(S −D) −K}}
=
min
S { min
x∈[D,Δ]{L(S −x) + L(S) −K}}
=
min
S {L(S −D) + L(S) −K}.
(9.14)
On account of Lemma 9.2, this expression tends to inﬁnity as D →∞.
Therefore, there is a D1 > 0 such that
min
S {L(S −D) + L(S) −K} > 2 min
S
L(S) for all D ≥D1.
(9.15)
Thus from (9.13)–(9.15), we have
min
S
˜LD(Δ, S) > K + min
S
L(S) for all D ≥D1,
implying that Δ in this case cannot be a minimizer.

MARKOVIAN DEMAND INVENTORY MODELS
191
Case 2. Let Δ ∈{Δ : 1 < M D(Δ) ≤2}. Then,
˜LD(Δ, S)
=
K + LD(S) +
Δ)
0
LD(S −x)mD(x)dx
1 + M D(Δ)
≥
K + 1
2
Δ)
0
(LD(S −x) + LD(S))mD(x)dx
3
≥
1
6 min
x∈[D,Δ]{LD(S −x) + LD(S)}M D(Δ)
≥
1
6 min
x∈[D,Δ]{LD(S −x) + LD(S)}.
In view of Lemma 9.1, taking the minimum with respect to S yields
min
S
˜LD(Δ, S)
≥
1
6 min
S { min
x∈[D,Δ]{LD(S −x) + LD(S)}}
=
1
6 min
S {LD(S −D) + LD(S)}
=
1
6 min
S {L(S −D) + L(S)}.
(9.16)
From Lemma 9.2 we know that this expression tends to inﬁnity as
D →∞. Therefore, there is a D2 > 0 such that
min
S {L(S −D) + L(S)} > 6(K + min
S
L(S)) for all D ≥D2. (9.17)
Then, from (9.16) and (9.17),
min
S
˜LD(Δ, S) > K + min
S
L(S) for all D ≥D2,
and thus Δ in Case 2 cannot be optimal.
Case 3. Let Δ ∈{Δ : 2 < M D(Δ)}. Now we deﬁne C := 3(K +
minS L(S)) = 3(K + minS LD(S)), Sl := min{S : LD(S) ≤C}, and
Su := max{S : LD(S) ≤C}. It follows from the convexity of LD(·)
and the fact that limx→±∞LD(x) = ∞that Sl and Su are ﬁnite. Let
D0 := max{D1, D2, Su −Sl} and choose D ≥D0. Then we obtain
˜LD(Δ, S)
=
K + LD(S) +
Δ)
0
LD(S −x)mD(x)dx
1 + M D(Δ)
≥
Δ)
0
LD(S −x)mD(x)dx
1 + M D(Δ)
.

192
Vanishing Discount Approach vs. Stationary Distribution Approach
It is easy to conclude from the deﬁnitions of Sl and Su that LD(S −
x) ≥C for x ∈[0, Δ] \ [S −Su, S −Sl]. Because
[0, Δ] \ [S −Su, S −Sl] = [0, Δ] \ [(S −Su)+, (S −Sl)+],
we obtain
˜LD(Δ, S) ≥CM(Δ) −C(M D((S −Sl)+) −M D((S −Su)+))
1 + M D(Δ)
.
(9.18)
Since 0 ≤(S −Sl)+ −(S −Su)+ ≤Su −Sl ≤D, it is clear that
there is almost surely at most one renewal between (S −Su)+ and
(S −Sl)+, and therefore M D((S −Sl)+)−M D((S −Su)+) ≤1. Thus,
˜LD(Δ, S) ≥C(M D(Δ) −1)
1 + M D(δ)
> C
3 = K + min
S
L(S).
Therefore, for D > D0 and all Δ = S −s > D, we have
min
S
LD(s, S) = min
S
˜LD(Δ, S) ≥min
S
LD(S, S).
Because LD(s, S) is constant in s for S −D ≤s ≤S, it is clear that the
minimizing point (s∗, S∗) satisﬁes the desired conditions. Furthermore,
because mD(t) = 0 for 0 ≤t ≤D, it holds that
mD(S∗−s∗) = 0 for all minimum points of LD(s, S).
9.5.
Asymptotic Bounds on the Optimal Cost
Function
As the horizon n of the inventory problem becomes large, it is rea-
sonable to expect that the optimal strategy parameters (sm, Sm) and
(sm+1, Sm+1) for small m do not diﬀer signiﬁcantly and that the optimal
strategy tends to a stationary one. On the other hand, if a stationary
strategy is applied, the inventory level tends towards a steady state.
The minimum cost per period that one can achieve in the steady state
is k := L(s∗, S∗). If the system approaches the steady state fast enough,
one could expect the diﬀerence fn(x)−nk to be uniformly bounded with
respect to n for any x. In Section 4 of his paper, Iglehart obtains bounds
on fn(x) in terms of an explicitly given solution ψ(·) of the equation
ψ(x) = min
y≥x[ˆc(y −x) + L(y) −k +
∞

0
ψ(y −ξ)ϕ(ξ)dξ].
(9.19)

MARKOVIAN DEMAND INVENTORY MODELS
193
He proves that the function ψ(·) deﬁned as
ψ(s∗+ y) =
⎧
⎨
⎩
−cy,
y ≤0,
L(y + s∗) −k +
∞
)
0
ψ(y + s∗−ξ)ϕ(ξ)dξ,
y > 0,
(9.20)
satisﬁes (9.19). The pair (s∗, S∗) is a minimizer of L(s, S), which satisﬁes
(9.12).
Brieﬂy, the proof goes as follows.
First, Iglehart veriﬁes that the
function ψ(·) deﬁned in (9.20) is K-convex.
Remark 9.2 It should be mentioned that ψ(·) is also K-convex if we
replace k by any value larger than L(s∗, S∗) = L(s∗) + cμ.
In the next step, he shows that the function
G(y) = cy + L(y) +
∞

0
ψ(y −ξ)ϕ(ξ)dξ,
which represents the function to be minimized in (9.19), attains its min-
imum at y = S∗, and G(s∗) = K + G(S∗) for ψ(·) deﬁned in (9.20). To
show this, it is essential that (9.12) holds.
The K-convexity of G(·) follows from the K-convexity of ψ(·). Now
we return to equation (9.19) written in terms of G(·), i.e.,
ψ(x) = −k −cx + min
y≥x[K1Iy>x + G(y)],
and transform its RHS. For x ≤s∗, the minimum is attained for y = S∗
and we get
−k −cx + min
y≥x[K1Iy>x + G(y)]
=
−k −cx + K + G(S∗) = −k −cx + G(s∗)
=
−k −cx + cs∗+ L(s∗) +
∞

0
ψ(s∗−ξ)ϕ(ξ)dξ
=
−c(x −s∗).
For x > s∗, the minimum is attained for y = x and we obtain
−k −cx + min
y≥x[K1Iy>x + G(y)]
=
−k −cx + G(x)
=
−k + L(x) +
∞

0
ψ(x −ξ)ϕ(ξ)dξ.

194
Vanishing Discount Approach vs. Stationary Distribution Approach
Therefore, the function ψ(·) deﬁned in (9.20) actually satisﬁes (9.19).
Observe that we can write explicitly,
G(y + s∗) =
⎧
⎪
⎪
⎨
⎪
⎪
⎩
c(s∗+ μ) + L(y + s∗)
for
y < 0,
c(s∗+ μ) + L(s∗) + L(y + s∗)
+
) y
0 L(y + s∗−ξ)m(ξ)dξ
−L(s∗)[1 + M(y)]
for
y ≥0.
The main result of this section is that for given W ∈R, there are
constants r and R depending on W such that the inequalities
nk + ψ(x) −r ≤fn(x) ≤nk + ψ(x) + R, for x ≤W,
(9.21)
hold. The assertion is proved by induction. First, Iglehart shows that the
optimal order levels Sk for the n-period problem are uniformly bounded
from above, i.e., the bound does not depend on n. Then he chooses
a constant W larger than this bound and proves that the inequality
holds for n = 1. Since f1(x) and ψ(x) are both linear with slope −c for
x ≤min{s1, s}, we can set
r =
min
min{s1,s}≤x≤W{f1(x) −ψ(x) −k}
and
R =
max
min{s1,s}≤x≤W{f1(x) −ψ(x) −k}.
The induction step for n = N + 1 uses (9.3) and (9.19).
Note that
because x ≤W and Sn ≤W, the minimum in (9.3) is attained for some
y ≤W, and the inequality (9.21) can be used for n = N.
Because ψ(·) is continuous and therefore ψ(x) < ∞for any x, it
follows from (9.21) that
lim
n→∞
fn(x)
n
= k.
(9.22)
It should be mentioned that the proof of (9.21) requires only that ψ(·)
solves (9.19) and that ψ(x) is linear with slope −c for all x smaller than
some ﬁnite constant. Moreover, it follows from (9.22) that there is no
such solution for k ̸= L(s∗) + cμ.
In Sections 6 and 7, Iglehart investigates the limiting behavior of the
function gn(x) = fn(x) −nk as n →∞. He proves that for K = 0,
lim
n→∞gn(x) = ψ(x) + A,
where ψ(·) is given by (9.20) and A is a constant. For K > 0, he is only
able to obtain
lim sup
n→∞gn(x) ≤ψ(x) + B

MARKOVIAN DEMAND INVENTORY MODELS
195
for a constant B. For K > 0, he also conjectures that lim infn→∞gn(x) ≥
ψ(x) + B, which would lead to limn→∞gn(x) = ψ(x) + B.
9.6.
Review of the Veinott and Wagner Paper
Veinott and Wagner (1965) deal with the inventory problem intro-
duced in Section 9.2 with one essential diﬀerence. They consider the
demand ξi in period i to be a discrete random variable taking nonnega-
tive integer values. They assume that one-period demands ξ1, ξ2, . . . are
i.i.d. random variables with the probability
P(ξi = k) = ϕ(k),
k = 0, 1, . . . ,
i = 1, 2, . . . .
We only recapitulate here the results of Veinott and Wagner that are
important in the context of the existence of an optimal (s, S) strategy.
We restrict our attention to the case of the zero leadtime for convenience
in exposition.
The discrete renewal density and the renewal function are deﬁned as
m(k)
=
∞

i=1
ϕi(k),
M(k)
=
∞

i=1
Φi(k) =
k

j=0
m(j),
k = 0, 1, . . . ,
where ϕi and Φi denote the probabilities and the cumulative distribu-
tion function of the i-fold convolution of the demand distribution, re-
spectively.
Employing a renewal approach or a stationary probability approach,
Veinott and Wagner derive a formula for the stationary average cost
a(x|s, S), given a particular stationary (s, S) strategy. Since the unit
purchase cost does not inﬂuence the optimal strategy, the formulas are
derived for the case c = 0. An extension to c > 0 is straightforward.
Veinott and Wagner (VW) obtain
a(x|s, S) = LVW(s, S) =
K + L(S) +
S−s

i=0
L(S −j)m(j)
1 + M(S −s)
for integer values of s and S. It should be mentioned that this function
does not depend on the initial surplus x.
For their discrete demand case, Veinott and Wagner claim that, just as
in Iglehart’s continuous demand density case, a minimizing pair (s∗, S∗)

196
Vanishing Discount Approach vs. Stationary Distribution Approach
of LVW(s, S) would satisfy (9.22), i.e.,
lim
n→∞
1
nfn(x) = LVW(s∗, S∗).
(9.23)
Furthermore, in the appendix of their paper, Veinott and Wagner es-
tablish the bounds for the parameters minimizing LVW(s, S). The proofs
of these bounds, derived in their paper for computational purposes, do
not require the existence of a stationary optimal (s, S) strategy in the
average cost case, but critically depend on the discrete nature of the
demand.
Having established bounds on the minimizers of LVW(s, S), it is clear
that the discrete function LVW(s, S) attains its minimum for an integer
pair (s∗, S∗).
However, the claim by Veinott and Wagner that a discrete analog of
Iglehart’s analysis yields (9.23) for the discrete demand case, requires
some additional arguments not included in their paper. Observe that
a completion of Iglehart’s analysis not only requires the existence of a
ﬁnite minimizer of the stationary average cost function, but it also needs
the minimizer to satisfy equation (9.12), which with c = 0 reduces to
L(s∗, S∗) = L(s∗).
(9.24)
In general, the integer minimizer of LVW(s, S) will not satisfy this con-
dition.
Subsequently, in order to establish the dynamic programming equa-
tion in the MDP context, Tijms (1972) has shown that there are integer
minimizers (s∗, S∗) of L(s, S) such that
L(s∗−1) ≥L(s∗, S∗) ≥L(s∗).
(9.25)
For our purpose, it immediately follows from (9.25) and the continuity
of L(x) that there is an s# < S∗such that
(a) (⌊s#⌋, S∗) is an integer minimizer of LVW(s, S), implying that
LVW(⌊s#⌋, S∗) = LVW(s∗, S∗), and
(b) LVW(⌊s#⌋, S∗) = L(s#),
where ⌊x⌋denotes the largest integer smaller or equal to x. Using the pair
(s#, S∗) and the function L(s, S) := LVW(⌊s⌋, S) in Iglehart’s analysis,
we can get the desired formula (9.24).
Once (9.24) is established, the short additional argument suggested by
Derman and used by Veinott and Wagner would provide the optimality
of a stationary (s, S) strategy for the average cost inventory problem.
Speciﬁcally, it follows from the deﬁnition of fn that fn(x) ≤fn(x|Y )
for all initial values x and all history-dependent strategies Y ∈Y. Thus,
a(x|s∗, S∗)
=
L(s∗, S∗) = lim
n→∞
1
nfn(x)

MARKOVIAN DEMAND INVENTORY MODELS
197
=
lim inf
n→∞
1
nfn(x) ≤lim inf
n→∞
1
nfn(x|Y ) = a(x|Y ),
for any history-dependent strategy Y ∈Y. Therefore, (s∗, S∗) is average
optimal.
We now return to the continuous demand case of Iglehart.
9.7.
Existence of Minimizing Values of s and S
In this section, we ﬁrst establish a priori bounds on the values of s
and S that minimize L(s, S). Once that is done, the continuity of L(s, S)
ensures the existence of a solution (s∗, S∗) that minimizes L(s, S). While
Veinott and Wagner have proved bounds on the minimizing s and S,
their proofs use the fact that the demands are discrete, and there is
no obvious way to transfer their proofs to the continuous demand case.
Additionally, they employ a vanishing discount argument.
Since the
discounted problem is not within the scope of the original Iglehart paper,
we will provide bounds on the minimizing parameters (s, S) using only
the properties of the stationary cost function.
L(x)
Su
C = 2L(0, 0)
Sl
x
Figure 9.1.
Deﬁnitions of Sl and Su
Lemma 9.3 There is a constant ¯S such that for all S ≥¯S and s ≤S,
the stationary cost L(s, S) > L(0, 0).
Proof. Let C = 2L(0, 0) > 0. Choose Sl and Su such that Sl ≤Su and
L(Sl) = L(Su) = C; (see Figure 9.1). Let S ≥Su. Our proof requires
three cases to be considered: s ≤Sl, Sl < s < Su, and Su ≤s ≤S.
Case s ≤Sl. In this case, M(S −Sl) ≤M(S −s), which we will
use later. From the cost formula (9.5) and the stationary probability

198
Vanishing Discount Approach vs. Stationary Distribution Approach
density (9.4), we have
L(s, S)
≥
S

s
L(x)f(x)dx ≥C
Sl

s
f(x)dx + C
S

Su
f(x)dx
=
C
1 + M(S −s)
⎡
⎣
S

s
m(S −x)dx −
Su

Sl
m(S −x)dx
⎤
⎦
=
C
1 + M(S −s)

M(S −s) −M(S −Sl) + M(S −Su)

=
C −C
+1 + M(S −Sl) −M(S −Su)
1 + M(S −s)
,
≥
C −C
+1 + M(S −Sl) −M(S −Su)
1 + M(S −Sl)
,
=
C
+
M(S −Su)
1 + M(S −Sl)
,
.
(9.26)
Case Sl < s < Su. In this second case, we use (9.5) and (9.4) to
immediately obtain
L(s, S) ≥
S

Su
L(x)f(x)dx
=
C
1 + M(S −s)
S

Su
m(S −x)dx
=
C
+ M(S −Su)
1 + M(S −s)
,
.
But in this case, S −s ≤S −Sl. Therefore,
L(s, S) ≥C
+
M(S −Su)
1 + M(S −Sl)
,
.
(9.27)
Since M(t)/t →1/μ as t →∞, the expression in the square brackets
in (9.26) and (9.27), which does not depend on s, goes to one as
S →∞, i.e.,
lim
S→∞
M(S −Su)
1 + M(S −Sl)
=
lim
S→∞
M(S −Su)
M(S −Sl)
=
lim
S→∞
M(S −Su)
S −Su
S −Sl
M(S −Sl)
S −Su
S −Sl
=
1
μ · μ · 1 = 1.

MARKOVIAN DEMAND INVENTORY MODELS
199
Therefore, there is an ¯S ≥Su, independent of s, such that M(S −Su)
/(1 + M(S −Sl)) > 1/2 for all S ≥¯S. This means that
L(s, S) > L(0, 0) for all S ≥¯S and s < Su,
which proves the lemma in the ﬁrst two cases.
Case Su ≤s ≤S. Finally, for this third case, we use (9.5) to obtain
L(s, S) =
s

−∞
[K + L(S)]f(x)dx +
S

s
L(x)f(x)dx ≥C > L(0, 0).
This completes the proof.
□
Lemma 9.4 For Sl deﬁned in Lemma 9.3, L(s, S)>L(0, 0) for all S ≤Sl
and s ≤S.
Proof. For S ≤Sl, it is clear from (9.5) that
L(s, S) =
s

−∞
[K + L(S)]f(x)dx +
S

s
L(x)f(x)dx ≥C > L(0, 0).
This completes the proof.
□
It is easy to see that together, Lemmas 9.3 and 9.4, prove that the
minimizing value of S lies in the set [Sl, ¯S]. In the next lemma, we show
that the minimizing value of s is bounded as well.
Lemma 9.5 There is a constant ¯s such that for all s ≤¯s and S ≥s,
L(s, S) > L(0, 0).
Proof. Let Sl and ¯S be deﬁned as in Lemma 9.3. Let s ≤Sl. For any
S satisfying s ≤S ≤Sl or s ≤Sl ≤¯S ≤S, it follows from Lemmas 9.3
and 9.4 that L(s, S) > L(0, 0). Therefore, we can restrict our attention
to the values of S which satisfy Sl ≤S ≤¯S. Then, from (9.5) and (9.4)
we have
L(s, S)
≥
Sl

s
L(x)f(x)dx
≥
C
Sl

s
f(x)dx =
C
1 + M(S −s)
⎡
⎢⎣
Sl

s
m(S −x)dx
⎤
⎥⎦

200
Vanishing Discount Approach vs. Stationary Distribution Approach
=
C
1 + M(S −s)

M(S −s) −M(S −Sl)

=
C −C
+1 + M(S −Sl)
1 + M(S −s)
,
≥
C −C
+1 + M( ¯S −Sl)
1 + M(Sl −s)
,
.
(9.28)
Since M(t) →∞as t →∞, the expression in the square brackets in
(9.28), which does not depend on S, goes to zero as s →−∞. Therefore,
there is an ¯s ≤Sl, independent of S, such that (1 + M( ¯S −Sl))/(1 +
M(Sl −s)) < 1/2 for all s ≤¯s. This means that
L(s, S) > C/2 = L(0, 0) for all s ≤¯s and S > s,
and the proof is completed.
□
Remark 9.3 The proofs of Lemmas 9.3 and 9.4 can be easily extended
to nondiﬀerentiable renewal functions M by using Lebesgue-Stieltjes in-
tegrals.
Therefore, the assertions of these two lemmas also hold for
demand distributions which do not have densities.
Theorem 9.1 If the one-period demand has a density, then the function
L(s, S), deﬁned on −∞< S < ∞, s ≤S, attains its minimum. Fur-
thermore, if (s∗, S∗) is a minimum point of L(s, S), then Sl ≤S∗≤¯S
and ¯s ≤s∗≤S∗.
Proof. Because of Lemmas 9.3–9.5, the search for a minimum point
can be restricted to the compact set {(s, S) : Sl ≤S ≤¯S, ¯s ≤s ≤S}.
It immediately follows from the existence of a density of the one-period
demand that L(s, S) is continuous, and therefore it attains its inﬁmum
over the compact set.
□
It remains to show that the minimum is attained at an interior point
and that there is a minimum point that satisﬁes (9.12).
Lemma 9.6 If K > 0, then there is a pair (s∗, S∗), with s∗< S∗, that
minimizes L(s, S).
Proof. We distinguish three cases.
Case 1. If m(x) is identically zero on [0, ε] for some ε > 0, it imme-
diately follows that ˜L(Δ, S) is constant for Δ ∈[0, ε] and any ﬁxed
S. Therefore, if (0, S∗) minimizes ˜L(Δ, S), so does (ε, S∗), which is
an interior point.

MARKOVIAN DEMAND INVENTORY MODELS
201
Case 2. Now let m(0) > 0. Any minimal point of ˆL(s, Δ) satisﬁes
(9.9). Let s∗be a solution of (9.9) for Δ = 0. Then it follows from
(9.10) that
∂ˆL(s∗, Δ)
∂Δ
Δ=0 = −Km(0) < 0
and therefore, Δ = 0 cannot be a minimizer.
Case 3. If m(·) does not satisfy either of the two cases above, it follows
from the continuity of m as a sum of convolutions of continuous
densities that there is an ε > 0 such that m(x) > 0 for all x ∈(0, ε].
This property implies that M(x) > 0 for x > 0. For a ﬁxed S, it holds
that
˜L(S, Δ) −˜L(S, 0)
=
K + L(S) +
Δ)
0
L(S −x)m(x)dx
1 + M(Δ)
−(K + L(S))
=
1
1 + M(Δ) (−M(Δ)(K + L(S)) + L(S −η)M(Δ)) (9.29)
for some η ∈[0, Δ]. Since M(Δ) > 0 for Δ ∈(0, ε] and L is continu-
ous, it follows that for suﬃciently small Δ
˜L(S, Δ) −˜L(S, 0) < 0,
and Δ = 0 cannot be a minimizer.
□
Lemma 9.7 There are s∗and S∗, with s∗< S∗, which minimize L(s, S)
and, at the same time, satisfy (9.12).
Proof. It follows from Lemma 9.6 that there is an interior minimizer
(s#, S∗) of L(s, S). If m(S∗−s#) > 0, it immediately follows from Igle-
hart’s analysis that (9.12) is satisﬁed.
If m(S∗−s#) = 0, we deﬁne
Δ0 = inf{Δ ≥0 : m(x) ≡0 on [Δ, S∗−s#]}
and
Δ1 = sup{Δ ≥0 : m(x) ≡0 on [S∗−s#, Δ]}.
Obviously for Δ ∈[Δ0, Δ1], the pair (S∗−Δ, S∗) minimizes L. Let ε > 0.
Then we have
˜L(Δ1, S∗) −˜L(Δ1 + ε, S∗) ≤0.

202
Vanishing Discount Approach vs. Stationary Distribution Approach
Therefore, it follows that
⎛
⎝K + L(S∗) +
Δ1

0
L(S∗−ξ)m(ξ)dξ
⎞
⎠(1 + M(Δ1 + ε))
−
⎛
⎝K + L(S∗) +
Δ1+ε

0
L(S∗−ξ)m(ξ)dξ
⎞
⎠(1 + M(Δ1)) ≤0
or
⎛
⎝K + L(S∗) +
Δ1

0
L(S∗−ξ)m(ξ)dξ
⎞
⎠(M(Δ1 + ε) −M(Δ1))
−(1 + M(Δ1))
Δ1+ε

Δ1
L(S∗−ξ)m(ξ)dξ ≤0.
Applying the Mean Value Theorem A.1.9 and dividing by (M(Δ1 +ε)−
M(Δ1))(1 + M(Δ1)), which is strictly positive by the deﬁnition of Δ1
and the monotonicity of M(·), we obtain
K + L(S∗) +
Δ1
)
0
L(S∗−ξ)m(ξ)dξ
1 + M(Δ1)
≤L(S∗−η)
for some η ∈[Δ1, Δ1 + ε]. Since L(y) is continuous, we ﬁnd for ε →0,
L(Δ1, S∗) −cμ =
K + L(S∗) +
Δ1
)
0
L(S∗−ξ)m(ξ)dξ
1 + M(Δ1)
≤L(S∗−Δ1).
(9.30)
If Δ0 > 0, we analogously ﬁnd
˜L(Δ0, S∗) ≥L(S∗−Δ0).
(9.31)
If Δ0 = 0, it is easy to see from (9.7) that
˜L(0, S∗) −cμ = K + L(S∗) > L(S∗).
(9.32)
Since ˜L(·, S∗) and L(·) are both continuous, it follows from (9.30)-(9.32)
that there is a Δ∗> 0 such that
˜L(Δ∗, S∗) −cμ = L(S∗−Δ∗),

MARKOVIAN DEMAND INVENTORY MODELS
203
i.e., the pair (s∗, S∗) := (S∗−Δ∗, S∗) is an interior minimizer that
satisﬁes (9.12).
□
Lemma 9.7 ﬁnally establishes the existence of an interior minimizer of
the stationary cost function that satisﬁes equation (9.12) as required for
Iglehart’s analysis. With that analysis completed, the following result is
easily established with the help of the same short additional argument
that Derman suggested to Veinott and Wagner.
Theorem 9.2 The parameters s∗and S∗, obtained in Lemma 9.7, de-
termine a stationary (s, S) strategy which is average optimal.
Remark 9.4 It follows from (9.9) that for any minimizer (s∗, S∗) of
L(s, S), we have s∗≤argmin L(y). Therefore, for any two minimizers
(s∗
1, S∗
1) and (s∗
2, S∗
2) of L(s, S) that satisfy (9.12), it holds that
L(s∗
1) = L(s∗
1, S∗
1) −cμ = k −cμ = L(s∗
2, S∗
2) −cμ = L(s∗
2).
Since k −cμ > minS L(S), L(x) is convex, and limx→±∞L(x) = ∞, it
follows that s∗
1 = s∗
2.
9.8.
Stationary Distribution Approach versus
Dynamic Programming and Vanishing
Discount Approach
In Chapters 5 and 6, we have established the average optimality of
an (s, S) strategy in the more general setting of Markovian demand.
We use dynamic programming and a vanishing discount approach to
obtain the average cost optimality equation and show that it has a K-
convex solution, which provides an (s, S) strategy that minimizes (9.2).
Furthermore, we prove a veriﬁcation theorem stating that any stable
policy (deﬁned later in the section; see (9.35)) satisfying the average
cost optimality equation is average optimal.
More speciﬁcally, we prove that there is a policy Y ∗that minimizes
the average cost deﬁned by
J(x|Y ) = lim sup
n→∞
1
nfn(x|Y )
over all history-dependent policies Y ∈Y. Furthermore, this policy Y ∗
can be represented as an (s, S) policy. In addition, we show that this
policy also minimizes the criterion
a(x|Y ) = lim inf
n→∞
1
nfn(x|Y )

204
Vanishing Discount Approach vs. Stationary Distribution Approach
over the class of all stable policies.4
Moreover, the completion of Iglehart’s analysis in the previous sec-
tion allows us to drop the stability restriction on the class of admissible
strategies and to obtain the stronger result that an optimal (s, S) strat-
egy also minimizes a(x|Y ) over all history-dependent policies Y ∈Y.
Theorem 9.3 that follows connects the two approaches.
For the average cost problem under consideration, the average cost
optimality equation derived in Chapter 6 is given by
ψ(x) = min
y≥x[ˆc(y −x) + L(y) −λ +
∞

0
ψ(y −ξ)ϕ(ξ)dξ].
(9.33)
A pair (λ∗, ψ∗) such that
ψ∗(x) = min
y≥x[ˆc(y −x) + L(y) −λ∗+
∞

0
ψ∗(y −ξ)ϕ(ξ)dξ]
is called a solution of (9.33). Note that for λ = k, (9.33) reduces to
equation (9.19), speciﬁed by Iglehart.
Theorem 9.3 Let (λ∗, ψ∗) be a solution of the average cost optimality
equation (9.33). Let ψ∗be continuous and let the minimizer on the RHS
of (9.33) be given by
y(x) =

S∗
if
x ≤s∗,
x
if
x > s∗,
for −∞< s∗≤S∗< ∞. Then,
(a) the pair (s∗, S∗) minimizes L(s, S),
(b) (s∗, S∗) satisﬁes (9.12), and
(c) for all history-dependent policies Y ∈Y, it holds that
λ∗= k = lim
n→∞
1
nfn(x|s∗, S∗) ≤lim inf
n→∞
1
nfn(x|Y ).
4Bounds on the action space imposed by Tijms (1972) imply that the admissible policies he
considers are stable. In this case, either of the criteria — lim inf or lim sup — can be used in
the MDP context.

MARKOVIAN DEMAND INVENTORY MODELS
205
Proof. To prove (a) we assume to the contrary that the pair (s∗, S∗)
does not minimize L(s, S). Then, there is another strategy (s, S) with
L(s∗, S∗) > L(s, S). Therefore, in view of Remark 9.1, we obtain
lim sup
n→∞
1
nfn(x|s∗, S∗) = L(s∗, S∗) > L(s, S) = lim sup
n→∞
1
nfn(x|s, S).
(9.34)
Equation (9.34) contradicts the optimality of (s∗, S∗) proved in Chap-
ter 6 for the average cost objective function (9.2). Therefore, (s∗, S∗)
minimizes L(s, S).
It is shown in Chapter 6 that the λ∗from the solution of the average
cost optimality equation is equal to the minimum of the average cost
deﬁned in (9.2), and is therefore equal to k = L(s∗, S∗). Knowing this,
part (c) of Theorem 9.3 immediately follows from (a) and Theorem 9.2.
For the proof of (b), we note that ψ∗can by expressed as in (9.20).
As shown in Iglehart, ψ∗is continuous if and only if (9.12) holds. This
proves part (b) of Theorem 9.3.
□
Theorem 9.4 If limx→−∞[cx+L(x)] = ∞, then there is a unique (up to
a constant) continuous bounded-from-below K-convex function ψ∗such
that (λ∗, ψ∗) is a solution of the average cost optimality equation (9.33).
Furthermore, λ∗is equal to the minimal average cost with respect to
either (9.1) or (9.2).
Proof. Because of the K-convexity of the solution, the minimizer on
the RHS of (9.19) is given by
y(x) =

S∗
if
x ≤s∗,
x
if
x > s∗,
for some not necessarily ﬁnite s∗≤S∗. Since limx→−∞(cx + L(x)) = ∞
and ψ∗is bounded from below, it follows that
lim
x→−∞

cx + L(x) −k +
∞

0
ψ∗(x −ξ)ϕ(ξ)dξ

= ∞,
and therefore, s∗> −∞. Since limx→∞L(x) = ∞and ψ∗is bounded
from below, it is obvious that
lim
y→∞

cy + L(y) −k +
∞

0
ψ∗(y −ξ)ϕ(ξ)dξ

= ∞,
and therefore, S∗< ∞.

206
Vanishing Discount Approach vs. Stationary Distribution Approach
It is easy to show that the (s, S) strategy with ﬁnite parameters s∗
and S∗is stable with respect to ψ∗, i.e.,
lim
n→∞
ψ∗(xn)
n
= 0.
(9.35)
Given this fact, it is proved in Chapter 6 that (s∗, S∗) is an optimal
strategy with respect to the average cost deﬁned in (9.2) with minimal
average cost λ∗. It follows from Theorem 9.3 that λ∗= k.
By Theorem 9.3, (s∗, S∗) minimizes L(s, S) and satisﬁes (9.12). It
follows from Remark 9.4 that s∗is unique. The K-convexity and the
parameter s∗uniquely determine the solution (9.20) of (9.19) (up to a
constant). Therefore, (λ∗, ψ∗) is the unique solution of (9.33) with the
desired properties.
□
Remark 9.5 In the case of a constant unit shortage cost p, the condi-
tion limx→−∞(cx + L(x)) = ∞is equivalent to the requirement p > c.
This condition is only introduced to simplify the proof and can be
dropped altogether.
9.9.
Concluding Remarks and Notes
In this chapter, based on Beyer and Sethi (1999), we have reviewed
the classical papers of Iglehart (1963b) and Veinott and Wagner (1965),
treating single-product average cost inventory problems. We have point-
ed out some conditions that are assumed implicitly but not proved in
these papers, and we have proved them rigorously.
In particular, we
have provided bounds for any pair (s∗, S∗) minimizing the stationary
one-period cost L(s, S), using only the properties of the stationary cost
function.
The main purpose of our analysis in this chapter has been to complete
the stationary distribution analyses of Iglehart and Veinott and Wagner
and relate it to the vanishing discount approach. Therefore, we have
stayed with the relatively restrictive assumptions on the demand distri-
bution made by Iglehart. However, these assumptions are not necessary
for the results obtained in this chapter. Indeed, it can be shown that
even for general demand distributions consisting of discrete and contin-
uous components, the corresponding stationary cost function attains its
minimum provided the expected values of all the quantities required in
the analysis exist. Furthermore, there is a pair minimizing L(s, S) that
satisﬁes (9.12) and that can in turn be proved to be average optimal.
We have also introduced the connection between the stationary distri-
bution approach and the dynamic programming approach to the prob-
lem. While dynamic programming is applicable even in problems defying

MARKOVIAN DEMAND INVENTORY MODELS
207
a stationary analysis but with objective function (9.2), the stationary
analysis, when possible, can prove optimality with respect to the more
conservative objective function (9.1). Finally, by combining both ap-
proaches, we have shown that an (s, S) policy – optimal with respect
to either of the objective functions (9.1) or (9.2) – is also optimal with
respect to the other.
Finally, we mention that Presman and Sethi (2006) have developed a
uniﬁed stationary distribution approach that deals with both the discoun-
ted and long-run average cost problems in continuous time. Bensoussan
et al. (2005b), on the other hand, use the dynamic programming approach
in the continuous-time case, which use the theory of quasivariational in-
equalities. They only deal with the discounted problem, however.

Chapter 10
CONCLUSIONS AND OPEN RESEARCH
PROBLEMS
The Markovian demand approach provides a realistic way of modeling
real-world demand scenarios. It allows us to relax the common assump-
tion of demands being independent over time in the inventory literature.
By associating the demand process with an underlying Markov chain,
we are able to capture the eﬀect of environmental factors that inﬂuence
the demand process. Although the modeling capability is signiﬁcantly
enhanced by the incorporation of Markovian demands in inventory mod-
els, the simplicity of the optimal policies normally exhibited in the clas-
sical inventory problems is still preserved. Speciﬁcally, we show that
the (s, S)-type policies shown to be optimal for a large class of inventory
models with independent demands continue to be optimal for Markovian
demand models, with one diﬀerence. That is, with Markovian demands,
the (s, S) values depend on the state of the Markov process.
In this book, we provide a comprehensive treatment for various in-
ventory models with Markovian demands. We treat the discounted cost
models as well as the long-run average cost models. Both the backlog
and the lost sales cases are treated. Moreover, the assumptions on the
demand and various costs are generalized. The results are derived in
a mathematically rigorous manner. For each model presented, we use
dynamic programming to prove the existence of an optimal feedback pol-
icy before analyzing its speciﬁc structure. For the analysis of long-run
average cost models, we use the vanishing discount approach.
In Chapter 9, we provide a complete analysis of the classical inventory
model with a ﬁxed cost by using the stationary distribution approach as
a way of contrasting with the vanishing discount approach throughout
the book. For this analysis, we use i.i.d. demands.
D. Beyer et al., Markovian Demand Inventory Models, International Series
211
in Operations Research & Management Science 108,
DOI 10.1007/978-0-387-71604-6 10, c⃝Springer Science+Business Media, LLC 2010

212
Conclusions and Open Research Problems
Some of the results derived for the Markovian demand models require
nontrivial extensions of the existing results in the literature. An example
is the generalization of the concept of K-convexity and its related prop-
erties. The generalization allows us to also relax some of the restrictive
assumptions used in the literature.
We have introduced Markov decision processes (MDP) as a way of
modeling demand when demand is endogenous. This can happen when
the advertising or promotion is used to increase the demand as in Chap-
ter 8. It would be of great interest to include pricing decisions in such
models. We believe our attempt is just a starting point toward using
the rich literature on the MDP theory for analysis of realistic inventory
models.
Some of the open problems have been discussed in the concluding
remarks and end notes of the relevant chapters. In addition, there are
many possible, as well as interesting, extensions of the works presented
in this book. Song and Zipkin (1993) have analyzed an inventory model
that corresponds to a continuous-time version of the model presented
in Chapter 2. It would be of interest to study continuous-time models
corresponding to other models analyzed here. In this vein, Presman and
Sethi (2006) and Bensoussan et al. (2005b) have proved the optimality
of the (s, S) policy in inventory models that incorporate constant and/or
diﬀusion demands, along with the standard compound Poisson demand.
Extending these works to allow for a Markovian demand structure re-
mains an open problem.
A second set of extensions concerns the inclusion of pricing and other
marketing activities in the MDP framework, along the lines pursued in
Chapter 8.
In the literature, there have been some attempts to develop procedures
to compute the (s, S) policy parameters deﬁning the optimal policy. Ear-
lier computational methods based on the policy iteration algorithm for
dynamic programming problems proved to be prohibitively expensive be-
cause of the computational complexity involved in the two-dimensional
search for the optimal values of s and S. For example, the methods of
Veinott and Wagner (1965) essentially apply a full enumeration on the
two-dimensional grid of s and Δ (Δ = S −s), facilitated by the bounds
identiﬁed for the optimal s and S. Zheng and Federgruen (1991) pro-
vide the ﬁrst eﬃcient algorithm for computing the optimal (s, S) policy
by reducing the dimensionality of the modiﬁed policy iteration to one
dimension in each iteration. To compute state-dependent (s, S) policy
parameters that arise in this book is a much harder problem, as well as
an interesting research area.

MARKOVIAN DEMAND INVENTORY MODELS
213
It continues to be a challenging open research problem to ﬁnd optimal
policy structures in inventory problems with multiple products that are
interrelated by way of joint setup costs, warehousing constraints, joint
demand distributions, etc. Some attempts involving multiple products
with i.i.d. demands, but connected by a warehouse constraint, include
Beyer and Sethi (1997) and Beyer et al. (2001), and references therein.
These could be extended to allow for Markovian demands. Recently,
Gallego and Sethi (2005) have generalized the concept of K-convexity to
n-dimensional spaces. An obvious next step is to see how these concepts
could be used for analysis of inventory problems with related multiple
products, possibly with Markovian demands.
Recently, with the realization that demands and inventories may not
be fully observed even after they are realized; (see, e.g., Raman et al.
(2001)), there has been a great deal of interest in studying problems with
incomplete inventory information. Bensoussan et al. (2007c,2008b) have
formulated models where signals such as presence or absence of inven-
tories are observed instead of full inventory levels.
For these models
with partial observations, they derive appropriate dynamic program-
ming equations in inﬁnite dimensional spaces and prove the existence
of optimal feedback policies in terms of the conditional distribution of
the inventory level given the past signal observations. Sometimes, full
observation comes after a delay, in which case Bensoussan et al. (2007b)
have shown a modiﬁed (s, S) policy to be optimal in the case when the
information delays are modeled as a Markov process. A generalization
of these works to allow for environmental states remains open.
Ding et al. (2002), Lu et al. (2005), Bensoussan et al. (2009a,2009b)
have considered censored demand models when the demands are i.i.d.
with an unknown parameter, whereas Bensoussan et al. (2007a,2008a)
allow for demands to be Markov processes. While optimal policies in
these models are much more complicated, they can still be extended to
allow for environmental states. Furthermore, these environmental states
may also be only partially observed.

VI
APPENDICES

Appendix A
ANALYSIS
The deﬁnitions and results presented here can be found in standard
texts on analysis such as Rudin (1976), Friedman (1970), Krantz (2004),
Ross (1980), and Yosida (1980). See Rockafellar (1970) for concepts and
results related to Lipschitz continuity. Internet sources that deal with
these topics are websites such as mathworld.wolfram.com, answers.com,
en.wikipedia.org, and planetmath.org.
A.1.
Continuous Functions on Metric Spaces
We consider only real-valued functions deﬁned on a metric space X
endowed with a metric ρ. Thus, ρ(x, y) denotes the distance between
x, y ∈X. Throughout the book, the cases of X that we are interested in
are R, Rn and I × Rn, where I is a ﬁnite set.
Definition A.1.1 (Continuity) A function f deﬁned on a subset A of
a metric space X is said to be continuous on A if for any ε > 0 and
x ∈A, there is a δ > 0 such that |f(y) −f(x)| < ε whenever y ∈A with
ρ(y, x) < δ.
Definition A.1.2 (Lower Semicontinuity) A function f deﬁned on a
metric space X is said to be lower semicontinuous (l.s.c.)
if for any
x ∈X,
lim inf
y→x f(y) ≥f(x).
Furthermore, f is upper semicontinuous (u.s.c.) if the function −f is
l.s.c.
Example. Any increasing function on real line is l.s.c. if it is continu-
ous from the left, and it is u.s.c. if it is continuous from the right. In
particular, a cumulative distribution function Φ of any random variable
ξ is always u.s.c.
Theorem A.1.1 A function f deﬁned on [a, b] ⊂R∪{−∞, ∞} is l.s.c.
if and only if the set {x ∈[a, b]|f(x) ≤M} is closed for each M.
D. Beyer et al., Markovian Demand Inventory Models, International Series
217
in Operations Research & Management Science 108,
DOI 10.1007/978-0-387-71604-6, c⃝Springer Science+Business Media, LLC 2010

218
Appendix A
Definition A.1.3 (Uniform Continuity) A function f, deﬁned on a
subset A of a metric space X, is said to be uniformly continuous on
A if for any ε > 0 there is a δ > 0 such that |f(y) −f(x)| < ε whenever
y and x belong to A and ρ(y, x) < δ.
Theorem A.1.2 If f is a continuous function on a compact subset A
of a metric space X, then f is uniformly continuous on A.
Definition A.1.4 (Lipschitz Continuity) A function f deﬁned on a
subset A of a metric space X is Lipschitz continuous if there is a con-
stant C ≥0 such that |f(y) −f(x)| < Cρ(y, x) for all x and y in A.
Furthermore, the smallest such C is called the Lipschitz constant of f.
Definition A.1.5 (Local Lipschitz Continuity) A function f deﬁned
on R is locally Lipschitz continuous if for any b > 0 there is a constant
C ≥0 such that |f(y) −f(x)| < C|y −x| for all x, y ∈[−b, b].
Theorem A.1.3 Every locally Lipschitz continuous function on R is
uniformly continuous on any ﬁnite interval of R.
Theorem A.1.4 (Kirszbraun Theorem) If A ⊂Rn and f : A →Rm
is Lipschitz continuous, then there is a Lipschitz continuous function
F : Rn →Rm that extends f, and has the same Lipschitz constant as f.
Moreover, if f is locally Lipschitz continuous, then the extension F is
also locally Lipschitz continuous.
Theorem A.1.5 (Existence Theorem) A l.s.c. function from Rn →R,
which is bounded from below, attains its minimum on a compact subset
of Rn.
Theorem A.1.6 Let c(x, u), a function from Rn × R+ into R, be l.s.c.
Then, the function ν : x →ν(x) = infu≥0 c(x, u) is l.s.c.
Theorem A.1.7 (Selection Theorem) Let c(x, u), a function from Rn×
Rm into R, be l.s.c. and bounded from below. Consider
inf
u∈A c(x, u),
where A is a compact subset in Rm. Then, the minimum is attained on
a bounded subset of points in A, which depends on x. Furthermore, there
exists a Borel map u∗(x) : Rn →Rm such that
c(x, u∗(x)) = inf
u∈A c(x, u).
The following theorem shows that the property of l.s.c. is also preserved
under the monotone limit procedure.

MARKOVIAN DEMAND INVENTORY MODELS
219
Theorem A.1.8 Let f1(x) ≤f2(x) ≤. . . , be a sequence of l.s.c. func-
tions on Rn, and suppose that for each x ∈Rn,
lim
n→∞fn(x) = f(x).
Then, the function f(x) is l.s.c. In particular, if {gn(x)} is a sequence
of nonnegative l.s.c. functions such that
∞

n=1
gn(x) = g(x),
then the function g(x) is l.s.c.
Theorem A.1.9 (Mean Value Theorem) If f : [a, b] →R is continuous
on [a, b] and diﬀerentiable on (a, b), then there is a point x ∈(a, b) at
which
f(b) −f(a) = (b −a)f ′(x).
A.2.
Convergence of a Sequence of Functions
In this section, we consider only real-valued functions deﬁned on R.
Definition A.2.1 (Pointwise Convergence) A sequence of functions
{fn} is said to be pointwise convergent to a function f on a set A if
for any x ∈A and any ε > 0, there exists an integer Nε,x such that
|fn(x) −f(x)| < ε for n ≥Nε,x.
Definition A.2.2 (Uniform Convergence) A sequence of functions {fn}
is said to be uniformly convergent to a function f on a set A if for each
ε > 0, there corresponds an integer Nε such that |fn(x)−f(x)| < ε for
each x ∈A and n ≥Nε.
Theorem A.2.1 (Dini’s Theorem) If an increasing sequence of contin-
uous functions {fn} is pointwise convergent to a continuous function f
on a compact set A, then it is uniformly convergent to f on A.
Theorem A.2.2 Let {fn} be a sequence of continuous functions on
[a, b] that converges uniformly to a function f on [a, b]. Let {xn} be a
sequence in [a, b] converging to x. Then,
lim
n→∞fn(xn) = f(x).
Definition A.2.3 (Local Uniform Convergence) A sequence of func-
tions {fn} deﬁned on R is said to be locally uniformly convergent to a
function f if for any b > 0 and ε > 0, there corresponds an integer Nε,b
such that |fn(x) −f(x)| < ε for each x ∈[−b, b] and n ≥Nε,b.

220
Appendix A
Theorem A.2.3 (Uniform Convergence Theorem) If {fn} is a sequence
of continuous functions on a set A that converges uniformly to a function
f on the set A, then f is continuous on the set A.
The theorem below allows us to exchange integrals and limit processes.
Theorem A.2.4 If {fn} is a sequence of integrable functions on a
bounded interval [a, b] that converge uniformly to a limit f on [a, b], then
f is integrable and
 b
a
f = lim
n→∞
 b
a
fn.
Theorem A.2.5 Let {fn} be a sequence of functions diﬀerentiable on
an interval [a, b], converging pointwise to a function f. Suppose that the
derivative f ′
n is continuous for all n, and that the diﬀerentiated sequence
converges uniformly to a function g. Then, the sequence {fn} converges
uniformly to f on [a, b] and f ′ = g.
A.3.
The Arzel`a-Ascoli Theorems
Definition A.3.1 (Uniform Boundedness) A family {fβ} of continuous
functions on a subset A ⊂R is said to be uniformly bounded if there is
a constant C > 0 such that |fβ(x)| ≤C for all β and for all x ∈A.
Definition A.3.2 (Equicontinuity) A family {fβ} of functions deﬁned
on a subset A ⊂R is said to be equicontinuous if for any given ε > 0
and x ∈A, there exists a δ > 0 such that
|fβ(y) −fβ(x)| < ε
for all y in A, for which |y −x| < δ and for all β.
Definition A.3.3 (Uniform Equicontinuity) A family {fβ} of functions
deﬁned on a subset A ⊂R is said to be uniformly equicontinuous if for
any given ε > 0, there exists a δ > 0 such that
|fβ(y) −fβ(x)| < ε
for each x, y in A, for which |y −x| < δ and for all β.
For comparison, the statement that all functions in {fβ} are contin-
uous on A ⊂R means that for every ε > 0, every β, and every x ∈A,
there exists a δ > 0 such that for y ∈A with |y −x| < δ, we have
|fβ(y) −fβ(x)| < ε. So, for continuity, δ may depend on ε, x, and β.
For uniform continuity, δ may depend on ε and β, but not on x; for
equicontinuity, δ may depend on ε and x, but not on β; and for uniform
equicontinuity, δ may depend on ε, but not on β and x.

MARKOVIAN DEMAND INVENTORY MODELS
221
Definition A.3.4 (Equi-Lipschitz Continuity) A family {fβ} of func-
tions deﬁned on a subset A ⊂R is equi-Lipschitzian on A if there exists
a C ≥0 such that
|fβ(y) −fβ(x)| < C|y −x|
for all x, y in A and all β.
Theorem A.3.1 If a family {fβ} of functions is equi-Lipschitzian on
an interval [a, b] ∈R, then {fβ} is uniformly equicontinuous on [a, b].
Definition A.3.5 (Local Equi-Lipschitz Continuity) A family {fβ} of
functions deﬁned on R is locally equi-Lipschitzian if for any b > 0, there
exists a C ≥0 such that
|fβ(y) −fβ(x)| < C|y −x|
for all x, y in [−b, b] and all β.
Theorem A.3.2 Let {fβ} be a locally equi-Lipschitzian family of func-
tions deﬁned on R. Then {fβ} is uniformly equicontinuous on any com-
pact subset of R.
Properties of boundedness, continuity, Lipschitz continuity, and local
Lipschitz continuity are preserved under pointwise convergence if they
are satisﬁed uniformly with the same constants for the converging se-
quence. Namely, the following result holds.
Theorem A.3.3 If {fn} is a sequence of equicontinuous, locally equi-
Lipschitzian, equi-Lipschitzian, or uniformly bounded functions on a set
A that converge pointwise to a function f on the set A, then f is con-
tinuous, Lipschitzian, locally Lipschitzian, or bounded, respectively on
A.
Theorem A.3.4 (Arzel`a-Ascoli Theorem) Let {fβ} be a family of func-
tions, uniformly bounded and uniformly equicontinuous on a compact
subset A ⊂R. Then, any sequence {fn} of functions of {fβ} has a sub-
sequence that is uniformly convergent on A to a continuous function f
on A.
In this book, we use the following version of the Arzel`a-Ascoli Theo-
rem, which can easily be derived from Theorems A.3.3, A.3.2, and A.3.4.
Theorem A.3.5 (Arzel`a-Ascoli Theorem) Let {fβ} be a family of func-
tions, uniformly bounded and locally equi-Lipschitz continuous. Then,
any sequence {fn} of functions of {fβ} has a subsequence that is locally
uniformly convergent to a locally Lipschitz continuous function f.

222
Appendix A
The sketch of the proof of this theorem is the following. Take a se-
quence of intervals AN = [−N, N], N = 1, 2 . . . . Let {f1,nk}, k = 1, 2 . . .
be a subsequence of {fn}, which is uniformly convergent on A1. Choose
{m, nk}, k = 1, 2 . . . a subsequence of {(m −1), nk} in such a way
that {fm,nk} converges uniformly on Am. The sequence of functions
{fN,nN}, N = 1, 2 . . . converges uniformly on any Ak, i.e., it is locally
uniformly convergent. The rest follows from Theorem A.3.3.
A.4.
Linear Operators
Definition A.4.1 (Linear Operator) Let X and Y be linear vector
spaces. A function T from a subset A ⊂X into Y is called an operator.
The set A where T is deﬁned is called the domain of T. Furthermore, T
is linear if A is a linear subset of X and if
T(λ1x1 + λ2x2) = λ1Tx1 + λ2Tx2
for all x1, x2 in A and λ1, λ2 scalars.
Definition A.4.2 (Continuous Linear Operator) Let X and Y
be
normed linear spaces. A continuous linear operator T from X into Y
is a linear operator that is also continuous – that is, if xn →x, then
Txn →Tx.
Let X and Y be normed linear spaces, and let T be a linear operator
from X into Y. If there is a constant K such that, for all x ∈X,
||Tx|| ≤K||x||,
then we say that T is bounded and we call T a bounded linear operator.
Note that the norms on the diﬀerent sides of the last inequality are
taken in diﬀerent spaces. Furthermore, the norm of the linear operator
T, denoted as ||T||, is deﬁned as
||T|| = sup
x̸=0
||Tx||
||x|| = sup
||x||=1
||Tx||.
Theorem A.4.1 A linear operator T from a normed linear space X
into a normed linear space Y is continuous if and only if it is bounded.
For the operator Fk+1 deﬁned in (3.8), we have the following result.
Lemma A.4.1 Fk+1 is a continuous linear operator from Bγ into Bγ.
Proof.
It immediately follows from the deﬁnition of Fk+1 that it is
a linear operator from Bγ into Bγ. By deﬁnition of ∥b ∥γ we have

MARKOVIAN DEMAND INVENTORY MODELS
223
|b(i, x)| ≤∥b ∥γ (1 + |x|γ), and we can conclude that
∥Fk+1 ∥
=
sup
b̸=0
∥Fk+1b ∥γ
∥b ∥γ
=
sup
b̸=0
∥L
j=1 pij
) ∞
0
b(j, y −ξ)dΦi,k(ξ) ∥γ
∥b ∥γ
≤
sup
b̸=0
∥L
j=1 pij
) ∞
0
∥b ∥γ (1 + |y −ξ|γ)dΦi,k(ξ) ∥γ
∥b ∥γ
=
∥
L

j=1
pij
 ∞
0
(1 + |y −ξ|γ)dΦi,k(ξ) ∥γ
=
max
i
sup
y
| L
j=1 pij
) ∞
0 (1 + |y −ξ|γ)dΦi,k(ξ)|
1 + |y|γ
≤
1 + max
i
sup
y
L
j=1 pij
) ∞
0 (|y| + |ξ|)γdΦi,k(ξ)
1 + |y|γ
.
Using the inequality (a + b)γ ≤2γ(|a|γ + |b|γ), we obtain
∥Fk+1 ∥
≤
1 + 2γ max
i
sup
y
L
j=1 pij(|y|γ +
) ∞
0 |ξ|γdΦi,k(ξ))
1 + |y|γ
≤
1 + 2γ(1 + max
i
 ∞
0
|ξ|γdΦi,k(ξ))
=
1 + 2γ
1 + max
i
E

|ξk|γik = i

,
which is ﬁnite on account of (3.1).
Therefore, the operator Fk+1 is
bounded and therefore continuous.
□
A.5.
Miscellany
Definition A.5.1 A sequence of {an}∞
n=0 is said to be Cesaro-sum-
mable to the limit s if
lim
N→∞SN = s,
where
SN =
1
N + 1
N

n=0
an.
A sequence of {an}∞
n=0 is said to be Abel-summable to a if
lim
β→1−(1 −β)
∞

n=0
βnan = a.

224
Appendix A
Theorem A.5.1 If a sequence of real numbers {an}∞
n=0 is Cesaro-
summable to s, then it is also Abel-summable to s.
Theorem A.5.2 (The Tauberian Theorem) Consider an arbitrary se-
quence {an}∞
n=0 for which the function
f(β) := (1 −β)
∞

n=0
βnan
is well deﬁned for all |β| < 1, that is, the RHS in the above expression
converges absolutely. Then, we have
lim inf
N→∞SN ≤lim inf
β→1−f(β) ≤lim sup
β→1−f(β) ≤lim sup
N→∞SN.
(A.1)
See Sznajder and Filar (1992), Theorem 2.2.

Appendix B
PROBABILITY
In Sections B.1 and B.2, we deﬁne concepts and related results used
in this book. In Section B.3, we state the Elementary Renewal Theo-
rem. See standard references such as Chow and Teicher (1978), Chung
(1974), and Kallenberg (2001), and websites such as en.wikipedia.org,
mathworld.wolfram.com, and planetmath.org. Section B.4 is concerned
with concepts of stochastic dominance, for which Shaked and Shanthiku-
mar (1984) is a good reference.
Let (Ω, F, P) denote a probability space.
Let X = X(ω), ω ∈Ω,
denote a random variable deﬁned on the probability space. Two random
variables X and Y are said to be equivalent (or to coincide) if X = Y
a.s. Let B be a sub σ-algebra of F.
B.1.
Integrability
Definition B.1.1 (Integrability) A random variable X is said to be
integrable if
E|X| =

|X|dP < ∞.
Definition B.1.2 (Uniform Integrability) A sequence Xn of random
variables is called uniformly integrable if
sup
n≥1
E|Xn|dP < ∞;
and in addition, for any ε > 0, there exists a δ > 0 such that
sup
n≥1

A
|Xn|dP < ε,
whenever P(A) < δ. Or, equivalently, if
lim
β→∞sup
n≥1

{|Xn|>β}
|Xn|dP = 0.

226
Appendix B
Lemma B.1.1 (Fatou’s Lemma) Let {Xn} be a sequence of nonnegative
integrable random variables. Then,
E lim inf
n→∞Xn ≤lim inf
n→∞EXn.
B.2.
Conditional Expectation
Definition B.2.1 (Conditional Expectation) The conditional expecta-
tion of the random variable X with respect to B is the unique (up to
equivalence) B-measurable random variable, denoted as E(X|B), such
that
E[E(X|B)Y ] = EXY
for any bounded B-measurable random variable Y. Alternatively, we de-
ﬁne E(X|B) to be any B-measurable random variable such that

B
E(X|B)dP =

B
XdP, ∀B ∈B.
Furthermore, the conditional expectation of X with respect to a random
variable Z, denoted as E(X|Z), is equal to its conditional expectation
with respect to the σ-algebra generated by Z.
B.2.1
Properties of Conditional Expectation
(i) X ≥0 implies E(X|B) ≥0 a.s.;
(ii) E|E(X|B)| ≤E|X|;
(iii) 0 ≤Xn ↑X implies E(Xn|B) ↑E(X|B) a.s.;
(iv) E(XY |B) = Y E(X|B) a.s. when Y is B-measurable;
(v) E(Y E(X|B)) = E(XE(Y |B)) = E(E(X|B)E(Y |B));
(vi) E(E(X|B)|C)) = E(X|C) a.s. for all C ⊂B;
(vii) Let X and Y be two random variables and g : R2 →R be a measur-
able function such that E|g(X, Y )| < ∞. Let Y be B-measurable.
Let h(ω, y) be a measurable function on Ω × R such that for each
y ∈R,
h(ω, y) = E(g(X, y)|B).
Then, we have
E(g(X, Y )|B) = h(ω, Y ).

MARKOVIAN DEMAND INVENTORY MODELS
227
B.3.
Renewal Theorem
Let {Xn} be a sequence of nonnegative i.i.d. random variables, with
Xn denoting time between the (n −1)st and nth event and μ = EXn.
Let
Sn =
n

i=1
Xi, n ≥1,
and N(t) = max{n|Sn ≤t}, the number of events by time t. It is easy to
verify that N(t)+1 is a stopping time of the sequence {Xn}, that is, the
event N(t)+1 = k belongs to the σ-algebra generated by X1, X2, . . . , Xk.
The counting process {N(t), t ≥0} is called a renewal process. Let
the renewal function m(t) = EN(t).
Theorem B.3.1 (The Elementary Renewal Theorem) The expected av-
erage rate of renewals is deﬁned by
lim
t→∞
m(t)
t
=

1/μ
when 0 < μ < ∞,
0
when μ = ∞.
B.4.
Renewal Reward Processes
Definition B.4.1 Suppose we are given a sequence of pairs of ran-
dom variables (Xk, Zk), where Xk > 0. Let N(t) be the renewal process
formed out of the sequence Xk as in Section B.3, that is, N(t) = max{n :
X1 + X2 + . . . + Xn ≤t}. The process
Y (t) =
N(t)

k=1
Zk
(B.1)
is called a renewal reward process.
In other words at the kth point of renewal, a reward of Zk is added
to the process. When Zk ≡1 for each k, the renewal reward process
coincides with the renewal process N(t). The main theorem describing
the limiting behavior of the renewal reward process is the following; (see
Proposition 4.1 in Ross (1989)).
Theorem B.4.1 If Y (t) is a renewal reward process given by (B.1) with
E(X), E(Z) < ∞, where X and Z are generic random variables whose
distributions are equal to those of {Xk} and {Zk}, respectively. Then,
lim
t→∞
Y (t)
t
= lim
t→∞
E(Y (t))
t
= EZ
EX .

228
Appendix B
B.5.
Stochastic Dominance
Definition B.5.1 Let ζ1 and ζ2 be two random variables with cumu-
lative probability distributions Φ1 and Φ2, respectively. We say that ζ2
dominates ζ1, or equivalently, that ζ2 is stochastically greater than ζ1, if
Φ1(x) ≥Φ2(x)
∀x.
(B.2)
This concept of stochastic dominance was ﬁrst introduced by Karlin
(1958b) to compare stochastic demands. Heuristically, a demand ζ2 is
stochastically greater than a demand ζ1, denoted as ζ2 ≥
st ζ1, if demands
based on Φ1 have a greater probability of taking smaller values than
those based on Φ2.
If ζ2 ≥ζ1, then ζ2 is stochastically greater than ζ1. The converse
is true in the following sense.
If ζ2 is stochastically greater than ζ1,
then there exist a probability space (˜Ω, ˜F, ˜P) and random variables ˜ζ1
and ˜ζ2 on this space having the same distribution functions Φ1 and
Φ2, respectively, and satisfying ˜ζ2 ≥˜ζ1. In fact, one can take ˜Ω as an
interval [0, 1] with ˜F being the set of all Borel sets and ˜P being Lebesgue
measure.
For any ω ∈˜Ω, we deﬁne ˜ζi(ω) = Φ−1
i (ω), i = 1, 2, where
Φ−1(y) = inf{x : Φ(x) ≥y} (if Φ is a continuous increasing function,
then Φ−1 coincides with the usual inverse function).
One can easily
check that from Φ1(x) ≥Φ2(x), follows Φ−1
1 (y) ≤Φ−1
2 (y).
Theorem B.5.1 If ζ2 dominates ζ1, then
EΨ(ζ1) ≤EΨ(ζ2)
(B.3)
for any nondecreasing real-valued function Ψ, for which both expectations
exist.
Proof. See Veinott (1966).
□
There are some other concepts of stochastic orderings between ran-
dom variables. For example, the likelihood ratio ordering and the ﬁrst
moment ordering are also commonly used in the literature.
Let ϕ1 and ϕ2 denote the probability density functions of ζ1 and ζ2,
respectively.
Definition B.5.2 We say that ζ2 is greater than ζ1 in the sense of
likelihood ratio ordering, if
ϕ2(x)
ϕ1(x) ≤ϕ2(y)
ϕ1(y),
∀x ≤y.

MARKOVIAN DEMAND INVENTORY MODELS
229
Definition B.5.3 We say that ζ2 is greater than ζ1 in the sense of ﬁrst
moment ordering, if for a constant C > 0,
ϕ2(x) = ϕ1(x −C), ∀x ≥0.
Clearly, these two types of stochastic ordering are stronger than the
stochastic dominance ordering.
B.6.
Markov Chains
Let (Ω, F, P) be a probability space with a sequence of increasing σ-
algebras F0 ⊆F1 ⊆. . . ⊆Fk ⊆F called ﬁltration. Let I be a ﬁnite
set {1, 2, . . . , L}, called the state space and let ik ∈I, k = 0, 1, ..., be
a sequence of random variables adapted to {Fk}∞
k=0 (that is, ik is Fk-
measurable). This sequence is called Markov chain with respect to the
ﬁltration {Fk}∞
k=0, if
P(ik+1 = j|Fk) = P(ik+1 = j|ik),
k = 0, 1, ....
(B.4)
In addition, if
P(ik+1 = j|Fk) = P(i1 = j|i0 = l)
on the set {ik = l}, then the Markov chain is called time-homogeneous.
When Fk is itself generated by the sequence {i0, i1, . . . , ik}, that is, when
Fk = σ(i0, i1, . . . , ik), the deﬁnition of the Markov property takes the
form
P(ik+1 = j|i0 = l0, i1 = l1, . . . , ik−1 = lk−1, ik = l)
= P(ik+1 = j|ik = l),
k = 0, 1, ....
The quantities plj = P(i1 = j|i0 = l), l, j = 1, 2, . . . , L, are called
transition probabilities and the matrix P{plj} is called the transition
matrix of the Markov chain ik, k = 1, 2 . . . . The n-step transition prob-
abilities p(n)
lj
are deﬁned as
p(n)
lj
= P(in+k = j|ik = l) = P(in = j|i0 = l).
The matrix {p(n)
lj } is equal to {plj}n.
Definition B.6.1 Two states j and l are said to be communicating,
if there exist n ≥1 and m ≥1 such that p(n)
lj
> 0 and p(m)
jl
> 0. A
Markov chain is irreducible if any two states j and l, j, l = 1, 2 . . . , L,
are communicating.

230
Appendix B
Definition B.6.2 The period d(j) of a state j is the greatest common
divisor of the set {n : p(n)
jj > 0}. If d(j) = 1, then the state j is aperiodic.
Markov chain is said to have a period d, if all its states have the period
d. If all states of the Markov chain are aperiodic, then the chain is said
to be aperiodic.
The proof of the following theorem can be found in Section 2.7 of Hoel
et al. (1972).
Theorem B.6.1 All states of an irreducible Markov chain have the
same period.
Denote by ηj the ﬁrst hitting time of a state j, i.e.,
ηj = min{k : ik = j},
and let
mlj = E(ηj|i0 = l).
Definition B.6.3 A state j is positive recurrent if mjj < ∞. A Markov
chain is positive recurrent if all of its states are positive recurrent.
The proof of the next theorem is standard and it can be found in Section
2.4 of Hoel et al. (1972).
Theorem B.6.2 If a Markov chain is irreducible, then all of its states
are positive recurrent. Moreover, for each two states j and l,
mlj < ∞.
Definition B.6.4 A nonnegative sequence ν1, ν2, . . . , νL is called a sta-
tionary distribution of a Markov chain, if L
l=1 νl = 1 and
L

l=1
νlplj = νj.
The proof of the following theorems can be found in Hoel et al. (1972),
Sections 2.5 and 2.7.
Theorem B.6.3 For an irreducible ﬁnite state Markov chain, there
exists a unique stationary distribution ν1, ν2, . . . , νL, with νl > 0, l =
1, 2 . . . , L.
Theorem B.6.4 Let i0, i1 . . . be an irreducible Markov chain with period
d. Let l and j be any two states in {1, 2, . . . , L} and a positive integer k
be such that p(k)
lj > 0. Then,
lim
n→∞p(k+nd)
lj
= dνj,

MARKOVIAN DEMAND INVENTORY MODELS
231
where ν1, ν2, . . . , νL is the unique stationary distribution for the Markov
chain.
The conditional independence of the future and the past as it is ex-
pressed in (B.4) can also be applied in cases when n in (B.4) becomes a
random variable. An important class of random variables for which the
Markov property holds is the class of stopping times.
Definition B.6.5 A random variable τ taking on nonnegative integer
values is called a stopping time with respect to the ﬁltration {Fk} if
{τ = k} ⊂Fk.
A σ-algebra Fτ is the set of all events A ∈F such that A∩{τ ≤k} ∈
Fk.
The Markov property (B.4) remains valid if n in (B.4) is replaced by a
stopping time τ; namely, the following theorem holds. Its proof can be
found in Section II.9 of Chung (1967).
Theorem B.6.5 If τ is a stopping time, then
P(iτ+1 = j|Fτ ) = plj on {iτ = l}.
(B.5)
In this book we deal with the case when the ﬁltration {Fk} is gen-
erated by a Markov chain i0, i1, . . . and a sequence of random vari-
ables ξ0, ξ1, . . . (that is, Fk = σ(i0, i1, . . . , ik; ξ0, ξ1, . . . , ξk−1)), having
the following properties.
The random vector (ξ0, ξ1, . . . , ξk) and the
sequence (ik+1, ik+2 . . .) are independent.
Conditioned on the event
{i0 = l0, i1 = l1, . . . , ik = lk}, the random variables ξ0, ξ1, . . . , ξk are in-
dependent, with the distribution functions Φ0,l0, Φ1,l1, . . . , Φk,lk, respec-
tively.
The proof of the following lemma is straightforward.
Lemma B.6.1 The sequence of random variables ξk, k = 1, 2, . . . , is a
Markov chain with respect to the ﬁltration {Fk}, where
Fk = σ(i0, i1 . . . , ik; ξ0, ξ1, . . . , ξk−1).

Appendix C
CONVEX, QUASI-CONVEX AND
K-CONVEX FUNCTIONS
C.1.
PF2 Density and Quasi-convex Functions
A brief description of the deﬁnition and some useful properties of PF2
densities can be found in Porteus (1971) and Porteus (2002). We adopt
a deﬁnition of a PF2 density given by Ross (1983).
Definition C.1.1 A density function φ : R →R+ for which log φ is
concave is PF2.
Definition C.1.2 A function f : R →R is quasi-convex on a convex
set X ⊂R if for x, y ∈X and 0 ≤λ ≤1,
f(λx + (1 −λ)y) ≤max(f(x), f(y)).
It should be clear from the deﬁnition that the class of real-valued quasi-
convex functions deﬁned on R includes convex functions and monotone
functions deﬁned on R.
Assume that a global minimum of a function f exists and let
f ∗= min
x f(x).
Let
mf = inf(x|f(x) = f ∗).
It is clear that f(x) is nonincreasing when x < mf and nondecreasing
when x ≥mf.
Theorem C.1.1 Let f : R →R be a quasi-convex function and let mf
be as deﬁned above. Let ξ be a nonnegative random variable with a PF2
density. Then,
g(x) = Ef(x −ξ)
is a real-valued quasi-convex function deﬁned on R. Furthermore, there
exists a minimizer of g at mg such that mg ≥mf.
Proof. It follows from Lemma 9.6 in Porteus (2002) with K = 0.
□

234
Appendix C
C.2.
Convex and K-convex Functions
If g is a convex function, then
λg(x) + (1 −λ)g(u) ≥g(y)
(C.1)
for any 0 < λ < 1, where y = λx + (1 −λ)u. From this deﬁnition we see
that
(1 −λ)(g(u) −g(x)) ≥g(y) −g(x).
Dividing both sides of this inequality by (y −x) and observing that
y −x = (1 −λ)(u −x), we get
g(u) −g(x)
u −x
≥g(y) −g(x)
y −x
for x < y < u. Thus, for a convex function, g(u)−g(x)
u−x
is an increasing
function of u, and g(u)−g(x)
u−x
is a decreasing function of x.
Theorem C.2.1 Suppose g(x) is a convex nonnegative function with
linear growth, i.e. 0 ≤g(x) ≤C(1+|x|). Then, g is Lipschitz continuous
on (−∞, ∞).
Proof. For any x > 0 and any y > x,
g(y) −g(x)
y −x
≤lim
u→∞
g(u) −g(x)
u −x
= lim
u→∞
g(u) −g(x)
u
= lim
u→∞
g(u)
u
≤C.
The last inequality is a consequence of the linear growth condition. Sim-
ilarly, by ﬁxing y and letting x →−∞, we get
g(y) −g(x)
y −x
≥−C,
wherefrom Lipschitz continuity follows.
□
Putting x = y −b and u = y + z (and as a result, λ = z/(z + b)) in
(C.1), we have an equivalent formulation for convexity. For any y and
any b, z > 0
b
z + bf(y + z) +
z
z + bf(y −b) ≥g(y)
or
bg(z + y) + zg(y −b) ≥(z + b)g(y).
The property of K-convexity corresponds to the case when g(z + y)
in the LHS of the above inequality is replaced by g(z + y) + K with
K ≥0. If we divide both sides of this inequality by b and then leave only
g(z + y) + K in the LHS, then we arrive at the following deﬁnition.

MARKOVIAN DEMAND INVENTORY MODELS
235
Definition C.2.1 A function g : R →R is said to be K-convex, K ≥0,
if it satisﬁes the property
K + g(z + y) ≥g(y) + z g(y) −g(y −b)
b
, ∀z ≥0, b > 0, y.
(C.2)
Definition C.2.2 A function g : R →D, where D is a convex subset
D ⊂R, is K-convex if (C.2) holds whenever y + z, y, and y −b are in D.
Required well-known results on K-convex functions or their extensions
are collected in the following two theorems (see, e.g., Bertsekas (1976)
or Bensoussan et al. (1983)).
Theorem C.2.2
(a) If g : R →R is K-convex, it is L-convex for any L ≥K. In
particular, if g is convex, i.e., 0-convex, it is also K-convex for any
K ≥0.
(b) If g1 is K-convex and g2 is L-convex, then for a, b ≥0, ag1 + bg2
is (aK + bL)-convex.
(c) If g is K-convex, and ξ is a random variable such that E|g(x−ξ)| <
∞, then Eg(x −ξ) is also K-convex.
(d) Restriction of g on any convex set D ⊂R is K-convex.
(e) Let {gn}∞
n=1 be a sequence of K-convex functions converging point-
wise to g. Then, g is also K-convex.
Proof. Statements (a)-(c) are proved in Bertsekas (1976). Proofs of (d)
and (e) are straightforward.
□
Theorem C.2.3 Let g : R →R be a K-convex (l.s.c.) function such
that g(x) →+∞as x →+∞. Let A and B, A ≤B, be two extended real
numbers with the understanding that the closed interval [ A, B ] becomes
open at A (or B) if A = −∞(or B = ∞). Let the notation g(−∞)
denote the extended real number lim inf
x→−∞g(x). Let
g∗=
inf
A≤x≤B g(x) > −∞.
(C.3)
Let the function h : (−∞, B ] →R be deﬁned as
h(x) =
inf
y≥x,A≤y≤B[K1Iy>x + g(y)].
Deﬁne the extended real numbers S and s, S ≥s ≥−∞as follows:
S = min{x ∈R ∪{−∞}|g(x) = g∗, A ≤x ≤B},
(C.4)

236
Appendix C
s = min{x ∈R ∪{−∞}|g(x) ≤K + g(S), A ≤x ≤S}.
(C.5)
Then,
(a) g(x) ≥g(S), ∀x ∈[A, B];
(b) g(x) ≤g(y) + K, ∀x, y with s ≤x ≤y ≤B;
(c) the function
h(x)
=

K + g(S),
for x < s
g(x),
for s ≤x ≤B
*
(C.6)
is l.s.c., and if g is continuous, A = −∞, and B = ∞, then h : R →R
is continuous;
(d) h is K-convex on (−∞, B ].
Moreover, if s > A, then
(e) g(s) = K + g(S);
(f) g(x) is strictly decreasing on (A, s ].
Proof. When s > A, it is easy to see from (C.5) that (e) holds and
that g(x) > g(s) for x ∈(A, s). Furthermore, for A < x1 < x2 < s,
K-convexity implies
K + g(S) ≥g(x2) + S −x2
x2 −x1
[g(x2) −g(x1)].
According to (C.5), g(x2) > K +g(S) when A < x2 < s. Then, it is easy
to conclude that g(x2) < g(x1). This proves (f).
As for (a), it follows directly from (C.3) and (C.4).
Property (b)
holds trivially for x = y, holds for x = S in view of (a), and holds
for x = s since g(s) ≤K + g(S) ≤K + g(y) from (C.5) and (a). We
need now to examine two other cases: (1) S < x < y ≤B and (2)
s < x < S, x < y ≤B.
Case 1 (S < x < y ≤B). Let z = S if S > −∞, and z ∈(S, x) if
S = −∞. By K-convexity of g, we have
K + g(y) ≥g(x) + y −x
x −z [g(x) −g(z)].
Use (a) to conclude K + g(y) ≥g(x) if S > −∞. If S = −∞, let
z →−∞. Since lim inf g(z) = g∗< ∞, we can once again conclude
K + g(y) ≥g(x).
Case 2 (s < x < S, x < y ≤B).
If s = −∞, let z ∈(−∞, x).
Then, K +g(S) ≥g(x)+[(S −x)/(x−z)][g(x)−g(z)]. Let z →−∞.

MARKOVIAN DEMAND INVENTORY MODELS
237
Since lim inf g(z) ≤K + g∗< ∞, we can use (a) to conclude g(x) ≤
K + g(S) ≤K + g(y). If s > −∞, then by K-convexity of g and (e),
K+g(S) ≥g(x)+ S −x
x −s [g(x)−g(s)] ≥g(x)+ S −x
x −s [g(x)−g(S)−K],
which leads to
'
1 + S −x
x −s
(
[K + g(S)] ≥
'
1 + S −x
x −s
(
g(x).
Dividing both sides of the above inequality by [1+(S−x)/(x−s)] and
using (a), we obtain g(x) ≤K + g(S) ≤K + g(y), which completes
the proof of (b).
To prove (c), it follows easily from (a) and (b) that h(x) equals the
RHS. Moreover, since g is l.s.c. and g(s) ≤K + g(S), h : R →R is also
l.s.c. The last part of (c) is obvious.
Next, if s = −∞, then h(x) = g(x), x ∈(−∞, B ], and (d) follows
from Theorem C.2.2(d). Now, let s > −∞. Therefore, S > −∞. Note
from (C.5) that s ≥A. To show (d), we need to verify
K + h(y + z) −
+
h(y) + z h(y) −h(y −b)
b
,
≥0
in the following four cases: (3) s ≤y−b < y ≤y+z ≤B, (4) y−b < y ≤
y+z < s, (5) y−b < s ≤y ≤y+z ≤B, and (6) y−b < y < s ≤y+z ≤B.
Case 3 (s ≤y−b < y ≤y+z ≤B) and Case 4 (y−b < y ≤y+z < s).
The proofs in these cases are obvious from the deﬁnition of h(x).
Case 5 (y −b < s ≤y ≤y + z ≤B,). In this case, the deﬁnition of
h(x) and the fact that g(s) ≤g(S) + K imply
K + h(y + z) −
+
h(y) + z h(y) −h(y −b)
b
,
= K + g(y + z) −
+
g(y) + z g(y) −g(S) −K
b
,
≥K + g(y + z) −
+
g(y) + z g(y) −g(s)
b
,
.
(C.7)
Clearly if g(y) ≤g(s), then the RHS of (C.7) is nonnegative in view
of (b). If g(y) > g(s), then y > s and b > y −s, and we can use

238
Appendix C
K-convexity of g to conclude
K + g(y + z)
−
+
g(y) + z g(y) −g(s)
b
,
>
K + g(y + z) −
+
g(y) + z g(y) −g(s)
y −s
,
≥0.
Case 6 (y −b < y < s ≤y + z ≤B). In this case, we have from the
deﬁnition of h(x) and (a) that
K + h(y + z) −
+
h(y) + z h(y) −h(y −b)
b
,
= K + g(y + z) −[g(S) + K]
= g(y + z) −g(S) ≥0.
□
Remark C.2.1 Theorem C.2.3 is an important extension of similar
results found in the literature; (see Lemma (d) in Bertsekas (1976),
p.85).
The extension allows us to easily prove the optimality of an
(s, S) policy without imposing a condition like (2.11) for x →−∞as
discussed in Remark 2.1, and with the capacity constraints discussed in
Section 2.8.2. Note that Theorem C.2.3 allows the possibility of s = −∞
or s = S = −∞; such an (s, S) pair simply means that it is optimal not
to order.
Theorem C.2.4 Let
Q(x) = q(x) + g(x+).
(C.8)
If q(x) is convex and nonincreasing with q(x) = 0, ∀x ≥0, g(x) is
K-convex, and q
′−(0) ≤g
′+(0), where
g
′+(0) = lim
x↓0
∂
∂xg(x)
and
q
′−(0) = lim
x↑0
∂
∂xq(x),
then Q(x) is K-convex.
Proof. Clearly, we have Q(x) = q(x) + g(0) for x < 0 and Q(x) = g(x)
for x ≥0. We need to verify that
K+Q(y+z)−
+
Q(y) + z Q(y) −Q(y −b)
b
,
≥0, ∀z ≥0, b > 0, y, (C.9)

MARKOVIAN DEMAND INVENTORY MODELS
239
in the following four cases: (1) 0 ≤y −b < y ≤y + z, (2) y −b < y ≤
y + z < 0, (3) y −b < 0 ≤y ≤y + z, and (4) y −b < y < 0 ≤y + z.
Case 1 (0 ≤y −b < y ≤y + z) and Case 2 (y −b < y ≤y + z < 0).
The proofs in these cases are obvious from the deﬁnition of Q(x).
Case 3 (y −b < 0 ≤y ≤y + z). In this case, we have from (C.8) that
K + Q(y + z) = K + g(y + z),
and
Q(y) + z Q(y) −Q(y −b)
b
= g(y) + z g(y) −g(0) −q(y −b)
b
.
Since q(y −b) ≥0 and y ≤b, we have
K + g(y + z)
≥
g(y) + z g(y) −g(0)
y
≥
g(y) + z g(y) −g(0) −q(y −b)
b
.
Therefore, (C.9) holds in case (3).
Case 4 (y −b < y < 0 ≤y + z). In this case, the deﬁnition of Q(x)
implies that
K + Q(y + z) = K + g(y + z),
and
Q(y) + z Q(y) −Q(y −b)
b
= q(y) + g(0) + z q(y) −q(y −b)
b
.
From the K-convexity of g(x), we know that for 0 ≤w ≤y + z,
K + g(y + z) ≥g(w) + (y + z −w)g(w) −g(0)
w
.
Letting w →0, we have
K + Q(y + z) ≥g(0) + (y + z)g
′+(0).
Since
g
′+(0) ≥q
′−(0) ≥q′(y) ≥q(y) −q(y −b)
b
,
and
yq′(y) ≥q(y), ∀y ≤0,

240
Appendix C
we obtain
K + Q(y + z) ≥g(0) + (y + z)q′(y) ≥g(0) + q(y) + z q(y) −q(y −b)
b
.
This validates (C.9) for Case 4.
□
Gallego and Sethi (2005) generalize the concept of K-convexity to an
n-dimensional Euclidean space. The resulting concept of K-convexity,
where K = (K0, K1, K2, ..., Kn) with K0 representing the joint setup cost
and Ki representing the individual setup cost associated with product
i, is useful in addressing production and inventory problems when there
are individual product setup costs and/or joint setup costs.

References
Arapostathis, A., V. S. Borkar, E. Fernandez-Gaucherand, M. K. Ghosh,
and S. I. Marcus, Discrete Time Controlled Markov-Processes with Average Cost
Criterion: A Survey, SIAM Journal of Control and Optimization, 31(2), 282-344,
1993.
Arrow, K. J., T. Harris, and J. Marschak, Optimal Inventory Policy, Econo-
metrica, 29, 250-272, 1951.
Arrow, K. J., Karlin, S., and H. Scarf, Studies in the Mathematical Theory of
Inventory and Production, Stanford, CA: Stanford University Press, 1958.
Balcer, Y., Partially Controlled Demand and Inventory Control: an Additive Model,
Naval Research Logistics Quarterly, 30, 273-288, 1983.
Bellman, R., I. Glicksberg, and O. Gross, On the optimal inventory equation,
Management Science, 2(1), 83-104, 1955.
Bensoussan, A., M. Cakanyildirim, J. A. Minjarez-Sosa, A. Royal, and S. P.
Sethi, Inventory Problems with Partially Observed Demands and Lost Sales, Jour-
nal of Optimization Theory and Applications, 136(3), 321-340, 2008a.
Bensoussan, A., M. Cakanyildirim, J. A. Minjarez-Sosa, S. P. Sethi, and
R, Shi, Partially Observed Inventory Systems: The Case of Rain Checks, SIAM
Journal of Control and Optimization, 47(5), 2490-2519, 2008b.
Bensoussan, A., M. Cakanyildirim, A. Royal, and S. P. Sethi, Bayesian and
Adaptive Controls for a Newsvendor Facing Exponential Demand, Journal on De-
cision and Risk Analysis, 2009a.
Bensoussan, A., M. Cakanyildirim, and S. P. Sethi, On the Optimal Control of
Partially Observed Inventory Systems, Comptes Rendus de l’Academi´e des Sciences
Paris, Ser. I 341, 419-426, 2005a.
Bensoussan, A., M. Cakanyildirim, and S. P. Sethi, A Multiperiod Newsvendor
Problem with Partially Observed Demand, Mathematics of Operations Research,
32(2), 322-344, 2007a.
Bensoussan, A., M. Cakanyildirim, and S. P. Sethi, Optimal Ordering Policies
for Inventory Problems with Dynamic Information Delays, Production and Oper-
ations Management, 16(2), 241-256, 2007b.
Bensoussan, A., M. Cakanyildirim, and S. P. Sethi, Partially Observed In-
ventory Systems: The Case of Zero-Balance Walk, SIAM Journal of Control and
Optimization, 46(1), 176-209, 2007c.

242
References
Bensoussan, A., M. Cakanyildirim, and S. P. Sethi, A Note on ’The Censored
Newsvendor and the Optimal Acquisition of Information,’ Operations Research,
57(3), 2009b.
Bensoussan, A., M. Crouhy, and J. Proth, Mathematical Theory of Production
Planning, Amsterdam, The Netherlands: North-Holland, 1983.
Bensoussan,
A., R. Liu, and S. P. Sethi, Optimality of an (s, S) Policy with Compound Poisson
and Diﬀusion Demands: A Quasi-variational Inequalities Approach, SIAM Journal
on Control and Optimization, 44(5), 1650-1676, 2005b.
Bertsekas, D., Dynamic Programming and Stochastic Control, New York: Academic
Press, 1976.
Bertsekas, D., and S. E. Shreve, Stochastic Optimal Control: the Discrete Time
Case, New York: Academic Press, 1976.
Beyer, D., and S. P. Sethi, Average Cost Optimality in Inventory Models with
Markovian Demand, Journal of Optimization Theory and Applications, 92(3), 497-
526, 1997.
Beyer, D., and S. P. Sethi, The Classical Average-Cost Inventory Models of Igle-
hart and Veinott-Wagner Revisited, Journal of Optimization Theory and Applica-
tions, 101(3), 523-555, 1999.
Beyer, D., and S. P. Sethi, Average-Cost Optimality in Inventory Models with
Markovian Demands and Lost Sales, in Analysis, Control and Optimization of
Complex Dynamic Systems, Edited by E.K. Boukas and R.P. Malhame, New York:
Springer, 3-23, 2005.
Beyer, D., S. P. Sethi, and R. Sridhar, Stochastic Multiproduct Inventory Models
with Limited Storage, Journal of Optimization Theory and Applications, 111(3),
553-588, 2001.
Beyer, D., S. P. Sethi, and M. Taksar, Inventory Models with Markovian De-
mands and Cost Functions of Polynomial Growth, Journal of Optimization Theory
and Application, 98(2), 281-323, 1998.
Chen, F., and J. S. Song, Optimal Policies for Multi-echelon Inventory Problems
with Markov-modulated Demand, Operations Research, 49(2), 226-234, 2001.
Chen, X., and D. Simchi-Levi, Coordinating Inventory Control and Pricing Strate-
gies with Random Demand and Fixed Ordering Cost: The Inﬁnite Horizon Case,
Mathematics of Operations Research, 29(3), 698-723, 2004.
Cheng, F., Inventory Models with Markovian Demands, Doctoral Dissertation, Uni-
versity of Toronto, 1996.
Cheng, F., and S. P. Sethi, A Periodic Review Inventory Model with Demand In-
ﬂuenced by Promotion Decisions, Management Science, 45(11), 1510-1523, 1999a.
Cheng, F., and S. P. Sethi, Optimality of State-Dependent (s,S) Policies in In-
ventory Models with Markov-Modulated Demand and Lost Sales, Production and
Operations Management, 8(2), 183-192, 1999b.
Chow, Y. S., and H. Teicher, Probability Theory, New York: Springer-Verlag, 1978.
Chung, K. L., Markov Chains with Stationary Transition Probabilities, New York:
Springer, 1967.
Chung, K. L., A Course in Probability Theory, New York: Academic Press, 1974.
Derman, C., Private Correspondence mentioned in Veinott and Wagner (1965), 1965.
Ding, X., M. L. Puterman, and A. Bisi, The Censored Newsvendor and the Op-
timal Acquisition of Information, Operations Research, 50, 517-527, 2002.
Dvoretzky, A., J. Kiefer, and J. Wolfowitz, On the Optimal Character of the
(s, S) Policy in Inventory Theory, Econometrica, 20, 586-596, 1953.

MARKOVIAN DEMAND INVENTORY MODELS
243
Edgeworth, F. Y., The Mathematical Theory of Banking, Journal of Royal Statis-
tical Society, 51(1), 113-127, 1888.
Erlenkotter, D., An Early Classic Misplaced: Ford W. Harris’ Economic Order
Quantity Model of 1915, Management Science, 35(7), 898-900, 1989.
Erlenkotter, D., Ford Whitman Harris and the Economic Order Quantity Model,
Operations Research, 38, 937-946, 1990.
Federgruen, A., and P. Zipkin, An Eﬃcient Algorithm for Computing Optimal
(s, S) Policies, Operations Research, 32, 1268-1285, 1984.
Feller, W. An Introduction to Probability Theory and its Application, Vol. 2, 2nd
Edition, New York: Wiley, 1971.
Friedman, A., Foundation of Modern Analysis, New York: Holt, Rinehart and Wing-
ton, 1970.
Fu, M., Sample Path Derivatives for (s, S) Inventory Systems, Operations Research,
42, 351-364, 1994.
Gallego, G., and S. P. Sethi, K-Convexity in Rn, Journal of Optimization Theory
and Applications, 127(1), 71-88, 2005.
Gaver, D. P., Jr., On Base-stock Level Inventory Control, Operations Research,
7(6), 689-703, 1959.
Gaver, D. P., Jr., Operating Characteristics of a Simple Production, Inventory-
control Model, Operations Research, 9(5), 635-649, 1961.
Hadley, G., and T. Whitin, Analysis of Inventory Systems, Englewood Cliﬀs, New
Jersey: Prentice-Hall, 1963.
Harris, F., Operations and Cost, (Factory Management Series), Chicago: A.W. Shaw
and Company, 1913.
Hern´andez-Lerma, O., and J. B. Lasserre, Discrete-Time Markov Control Pro-
cesses, New York: Springer, 1996.
Hoel, P. G., S. C. Port, and S.J. Stone, Introduction to Stochastic Processes,
Waveland Press, 1972.
Holt, C., F. Modigliani, J. F. Muth, and H. A. Simon, Planning Production,
Inventory, and Workforce, Englewood Cliﬀs, New Jersey: Prentice-Hall, 1960.
Hu, J. Q., S. Nananukul, and W. B. Gong, A New Approach to (s, S) Inventory
Systems, Journal of Applied Probability, 30, 898-912, 1993.
Huh, W. T., G. Janakiraman, and M. Nagarajan, Average Cost Inventory Mod-
els: An Analysis Using a Vanishing Discount Approach, Working Paper, Columbia
University, 2008.
Iglehart, D., Optimality of (s, S) Policies in the Inﬁnite Horizon Dynamic Inventory
Problem, Management Science, 9(2), 259-267, 1963a.
Iglehart, D., Dynamic Programming and Stationary Analysis of Inventory Prob-
lems, Multistage Inventory Models and Techniques, Edited by H. Scarf, D. Gilford,
and M. Shelly, Stanford, CA: Stanford University Press, 1-31, 1963b.
Iglehart, D., and S. Karlin, Optimal Policy for Dynamic Inventory Process Inven-
tory Process With Nonstationary Stochastic Demands, Studies in Applied Prob-
ability and Management Science, Edited by K. Arrow, S. Karlin, and H. Scarf,
Stanford, CA: Stanford University Press, 1962.
Kallenberg, O., Foundation of Modern Probability, 2nd edition, New York: Springer,
2001.
Kapalka, B. A., K. Katircioglu, and M. L. Puterman, Retail Inventory Control
with Lost Sales, Service Constraints, and Fractional Lead Times, Production and
Operations Management, 8(4), 1059-1478, 1999.

244
References
Karlin, S., Steady State Solutions, Studies in the Mathematical Theory of Inven-
tory and Production, Edited by K. Arrow, S. Karlin, and H. Scarf, Stanford, CA:
Stanford University Press, 223-269, 1958a.
Karlin, S., The Application of Renewal Theory to the Study of Inventory Policies,
Studies in the Mathematical Theory of Inventory and Production, Edited by K.
Arrow, S. Karlin, and H. Scarf, Stanford, CA: Stanford University Press, 270-297,
1958b.
Karlin, S., Optimal Inventory Policy for the Arrow-Harris-Marshak Dynamic Model,
Studies in the Mathematical Theory of Inventory and Production, Edited by K.
Arrow, S. Karlin, and H. Scarf, Stanford, CA: Stanford University Press, 135-154,
1958c.
Karlin, S., Dynamic Inventory Policy with Varying Stochastic Demands, Manage-
ment Science, 6(3), 231-258, 1960.
Karlin, S., and C. Carr, Prices and Optimal Inventory Policies, Studies in Applied
Probability and Management Science, Edited by K. Arrow, S. Karlin, and H. Scarf,
Stanford, CA: Stanford University Press, 1962.
Karlin, S., and A. Fabens, The (s, S) Inventory Model under Markovian Demand
Process, Mathematical Methods in the Social Sciences, Edited by K. Arrow, S.
Karlin, and P. Suppes, Stanford, CA: Stanford University Press, 159-175, 1960.
Karlin, S., and H. Scarf, Inventory Models and Related Stochastic Processes.
Studies in the Mathematical Theory of Inventory and Production, Edited by K.
Arrow, S. Karlin, and H. Scarf, Stanford, CA: Stanford University Press, Chapter
17, 319-336, 1958.
Khouja, B., The Single Period (News-vendor) Problem: Literature Review and Sug-
gestions for Future Research, Omega, 27, 537-553, 1999.
Krantz, S. A., A Handbook of Real Variables, New York: Birkh¨auser, 2004.
K¨uenle, C. and H. U. K¨uenle, Durchschnittskostenoptimale Strategien in Mar-
kovschen Entscheidungsmodellen bei unbeschr¨ankten Kosten. Mathematische Ope-
rationsforschung und Statistik, Series Optimization, 8(4), 549-564, 1977.
Lu, X., J. S. Song, and K. Zhu, On ’The Censored Newsvendor and the Optimal
Acquisition of Information,’ Operations Research, 53, 1024-1027, 2005.
Mills, E., Price, Output and Inventory Policy; A Study in the Economics of the Firm
Industry, New York: J. Wiley & Sons, 1962.
Parlar, M., Y. Wang, and Y. Gerchak, A Periodic Review Inventory Model with
Markovian Supply Availability, International Journal of Production Economics,
42(2), 131-136, 1995.
Porteus, E., On the Optimality of Generalized (s, S) Policies, Management Science,
17(7), 411-426, 1971.
Porteus, E., Numerical Comparison of Inventory Policies for Periodic Review Sys-
tems, Operations Research, 33, 134-152, 1985.
Porteus, E., Foundations of Stochastic Inventory Theory, Stanford, CA: Stanford
University Press, 2002.
Presman, E. and S. P. Sethi, Inventory Models with Continuous and Poisson De-
mands and Discounted and Average Costs, Production and Operations Manage-
ment, 15(2), 279-293, 2006.
Raman, A., N. DeHoratius, and Z. Ton, Execution: The Missing Link in Retail
Operations, California Management Review, 43(3), 136-152, 2001.
Raymond, F. E., Quantity and Economy in Manufacture, New York: McGraw-Hill,
1931.

MARKOVIAN DEMAND INVENTORY MODELS
245
Rockafellar, R. T., Convex Analysis, Princeton, NJ: Princeton University Press,
1970.
Ross, K. A., Elementary Analysis: The Theory of Calculus, New York: Springer,
1980.
Ross, S. M., Stochastic Processes, Wiley Series in Probability and Statistics, New
York: Wiley, 1983.
Ross, S. M., Introduction to Probability Models, San Diego, CA: Academic Press,
1989.
Rudin, W., Principles of Mathematical Analysis, New York: McGraw-Hill, 1976.
Sahin, I., Regeneration Inventory Systems: Operating Characteristics and Optimiza-
tion, Bilkent University Lecture Series, New York: Springer-Verlag, 1990.
Scarf, H., The Optimality of (s, S) Policies in the Dynamic Inventory Problem,
Mathematical Methods in the Social Sciences, Edited by K. Arrow, S. Karlin, and
P. Suppes, Stanford, CA: Stanford University Press, 196-202, 1960.
Sch¨al, M., On the Optimality of (s, S) Policies in Dynamic Inventory Models with
Finite Horizon, SIAM Journal on Applied Mathematics, 30(3), 528-537, 1976.
Sethi, S. P., and F. Cheng, Optimality of (s, S) Policies in Inventory Models with
Markovian Demand, Operations Research, 45(6), 931-939, 1997.
Sethi, S. P., H. Yan, and H. Zhang, Inventory Models with Fixed Costs, Forecast
Updates, and Two Delivery Modes, Operations Research, 51(2), 321-328, 2003.
Sethi, S. P., H. Yan, and H. Zhang, Inventory and Supply Chain Decisions with
Forecast Updates, New York: Springer, 2005a.
Sethi, S. P., and Q. Zhang, Hierarchical Decision Making in Stochastic Manufac-
turing Systems, Boston, MA: Birkh¨auser, 1994.
Sethi, S. P., and Q. Zhang, Multilevel Hierarchical Decision Making in Stochas-
tic Marketing-Production Systems, SIAM Journal on Control and Optimization,
33(2), 528-553, 1995.
Sethi, S. P., H. Zhang, and Q. Zhang, Average-Cost Control of Stochastic Man-
ufacturing Systems, New York, NY: Springer, 2005b.
Shaked, M., and J. G. Shanthikumar, Stochastic Order and Their Applications,
New York: Academic Press, 1984.
Shreve, S. E., Abbreviated proof [in the lost sales case], Dynamic Programming and
Stochastic Control, Edited by D.P. Bertsekas, New York: Academic Press, 105-106,
1976.
Silver, E., Operations Research in Inventory Management: a Review and Critique,
Operations Research, 29, 628-645, 1981.
Sogomonian, A., and C. Tang, A Modeling Framework for Coordinating Promotion
and Production Decisions within a Firm, Management Science, 39(2), 191-203,
1993.
Song, J. S., and P. Zipkin, Inventory Control in a Fluctuating Demand Environ-
ment, Operations Research, 41, 351-370, 1993.
Stidham, S. Jr., Cost Models for Stochastic Clearing Systems, Operations Research,
25(1), 100-127, 1977.
Sznajder, R., and J. A. Filar, Some Comments on a Theorem of Hardy and
Littlewood, Journal of Optimization Theory and Applications, 75, 201-208, 1992.
Thowsen, G. T., A Dynamic Nonstationary Inventory Problem for a Price/Quantity
Setting Firm, Naval Research Logistics Quarterly, 22, 461-476, 1975.
Tijms, H., Analysis of (s, S) inventory models, Mathematical Centre Tracts, 40, Am-
sterdam, The Netherlands: Mathematisch Centrum, 1972.

246
References
Veinott, A., The Optimal Inventory Policy for Batch Ordering, Operations Research,
13, 1103-1145, 1965.
Veinott, A., On the Optimality of (s, S) Inventory Policies: New Conditions and a
New Proof, SIAM Journal on Applied Mathematics, 14(5), 1067-1083, 1966.
Veinott, A., and H. Wagner, Computing Optimal (s, S) policies, Management
Science, 11, 525-552, 1965.
Wagner, H., Comments on “Dynamic Version of the Economic Lot Size Model,”
Management Science, 50(12) Supplement, 1775-1777, December 2004.
Wagner, H., and T. Whitin, Dynamic Version of the Economic Lot Size Model,
Management Science, 5, 89-96, 1958; republished in Management Science, 50(12)
Supplement, 1770-1774, December 2004.
Wijngaard, J., Stationary Markovian Decision Problems. Doctoral Theses, Technis-
che Hogeschool Eindhoven, The Netherlands, 1975.
Yosida, K., Functional Analysis, 6th Edition, New York: Springer-Verlag, 1980.
Young, L., Price, Inventory and the Structure of Uncertain Demand, New Zealand
Journal of Operations Research, 6, 157-177, 1978.
Zabel, E., Monopoly and Uncertainty, The Review of Economic Studies, 37, 205-219,
1970.
Zheng, Y. S., A Simple Proof for Optimality of (s, S) Policies in Inﬁnite-Horizon
Inventory Systems, Journal of Applied Probability, 28, 802-810, 1991.
Zheng, Y. S., and A. Federgruen, Finding Optimal (s, S) Policies Is About As
Simple as Evaluating a Single Policy, Operations Research, 39(4), 654-665, 1991.
Zipkin, P., Foundations of Inventory Management, New York: McGraw-Hill, 2000.
Zipkin, P., On the Structure of Lost-Sales Inventory Model, Operations Research,
56(4), 937-944, 2008a.
Zipkin, P., Old and New Methods for Lost-Sales Inventory Systems, Operations Re-
search, 56(5), 1256-1263, 2008b.

Copyright Permissions
Selected portions of the publications below have been reprinted with
permissions as indicated.
“Optimality of (s,S) Policies in Inventory Models with Markovian De-
mand” by Sethi, S.P. and Cheng, F., Operations Research, 45(6), 931–
939. Copyright c⃝1997, the Institute for Operations Research and the
Management Sciences, 7240 Parkway Drive, Suite 300, Hanover, MD
21076, USA.
“A Periodic Review Inventory Model with Demand Inﬂuenced by Pro-
motion Decisions” by Cheng, F. and Sethi, S.P., Management Science,
45(11), 1510–1523. Copyright c⃝1999, the Institute for Operations Re-
search and the Management Sciences, 7240 Parkway Drive, Suite 300,
Hanover, MD 21076, USA.
“Inventory Models with Markovian Demands and Cost Functions of
Polynomial Growth” by Beyer, D., Sethi, S.P., and Taksar, M.I., Journal
of Optimization Theory and Applications, 98(2), 281–323.
Copyright
c⃝1998 by Springer, 233 Spring St., New York, NY 10013, USA.
“Average Cost Optimality in Inventory Models with Markovian De-
mands” by Beyer, D. and Sethi, S.P., Journal of Optimization Theory
and Applications, 92(3), 497–526. Copyright c⃝1997 by Springer, 233
Spring St., New York, NY 10013, USA.
“The Classical Average-Cost Inventory Models of Iglehart and Veinott-
Wagner Revisited” by Beyer, D. and Sethi, S.P., Journal of Optimiza-
tion Theory and Applications, 101(3), 523–555.
Copyright c⃝1999 by
Springer, 233 Spring St., New York, NY 10013, USA.

248
Copyright permission
“Optimality of State-Dependent(s,S) Policies in Inventory Models with
Markov-Modulated Demand and Lost Sales” by Cheng, F.M. and Sethi,
S.P., Production and Operations Management, 8(2), 183–192. Copyright
c⃝1999 by Production and Operations Management Society, 11200 SW
8th Street, Miami, FL 33199, USA.
“Average-Cost Optimality in Inventory Models with Markovian De-
mands and Lost Sales” by Beyer, D. and Sethi, S.P., in Analysis, Control
and Optimization of Complex Dynamic Systems, E.K. Boukas and R.P.
Malhame (editors), 3–23. Copyright c⃝2005 by Springer, 233 Spring St.,
New York, NY 10013, USA.

Author Index
Arapostathis, A., 83, 85, 131
Arrow, K. J., xiii, 7–8, 22
Balcer, Y., 11, 154
Bellman, R., 8
Bensoussan, A., 12, 23, 27, 34, 41, 59–60,
207, 212–213, 235
Bertsekas, D., 27, 67, 69–70, 158, 170, 235,
238
Beyer, D., 41, 57, 84, 106, 130, 150, 206, 213
Bisi, A., 213
Borkar, V. S., 83, 85, 131
Cakanyildirim, M., 12, 213
Carr, C., 10, 154
Chen, F., 9
Chen, X., 11
Cheng, F., 9, 11, 39, 41, 72, 150, 174
Chow, Y. S., 225
Chung, K. L., 225, 231
Crouhy, M., 23, 27, 34, 41, 59–60, 235
DeHoratius, N., 213
Derman, C., 84, 180
Ding, X., 213
Dvoretzky, A., xiii, 8, 22
Edgeworth, F. Y., xiii, 7
Erlenkotter, D., xiii, 7
Fabens, A., 9, 21, 23, 41, 70, 72
Federgruen, A., 12, 84, 180, 212
Feller, W., 26, 61, 89, 137
Fernandez-Gaucherand, E., 83, 85, 131
Filar, J. A., 224
Friedman, A., 217
Fu, M., 84, 180
Gallego, G., 213, 239
Gaver, D. P., Jr., 8
Gerchak, Y., 38
Ghosh, M. K., 83, 85, 131
Glicksberg, I., 8
Gong, W. B., 84, 180
Gross, O., 8
Hadley, G., 7
Harris, F., xiii, 7
Harris, T., xiii, 7–8, 22
Hern´andez-Lerma, O., 131
Hoel, P. G., 230
Holt, C., 41
Hu, J. Q., 84, 180
Huh, W. T., 84, 150, 180
Iglehart, D., 8–9, 17, 21–23, 83–85, 106,
179–182, 184–187, 192–197, 201,
203–206
Janakiraman, G., 84, 150, 180
Kallenberg, O., 225
Kapalka, B., 150
Karlin, S., xiii, 8–10, 21–23, 41, 70, 72, 84,
154, 179, 185, 228
Katircioglu, K., 150
Khouja, B., 7
Kiefer, J., xiii, 8, 22
Krantz, S. A., 217
K¨uenle, C., 180
K¨uenle, H. U., 180
Lasserre, J. B., 131
Liu, R., 207, 212
Lu, X., 213
Marcus, S. I., 83, 85, 131
Marschak, J., xiii, 7–8, 22
Mills, E., 10, 154
Minjarez-Sosa, J. A., 12, 213
Modigliani, F., 41
Muth, J. F., 41
Nagarajan, M., 84, 150, 180
Nananukul, S., 84, 180
Parlar, M., 38
Port, S. C., 230
Porteus, E., 11, 39, 84, 162, 180, 233
Presman, E., 180, 207, 212
Proth, J., 23, 27, 34, 41, 59–60, 235
Puterman, M. L., 150, 213
Raman, A., 213

250
Author Index
Raymond, F. E., xiii
Rockafellar, R. T., 217
Ross, K. A., 217
Ross, S. M., 111, 227, 233
Royal, A., 12, 213
Rudin, W., 217
Sahin, I., 84, 180
Scarf, H., xiii, 8, 22, 27, 33, 41, 63, 87, 108,
135, 184
Sch¨al, M., 184
Sethi, S. P., xiv, 9, 11–12, 39, 41, 57, 72,
84–85, 106, 130, 150, 155, 174, 180,
206–207, 212–213, 239
Shaked, M., 225
Shanthikumar, J. G., 225
Shi, R., 12, 213
Shreve, S. E., 8, 59–60, 67, 158, 170
Silver, E., 5
Simchi-Levi, D., 11
Simon, H. A., 41
Sogomonian, A., 154
Song, J. S., 9, 21, 23, 27, 41, 212–213
Sridhar, R., 213
Stidham, S. Jr., 84, 180
Stone, C. J., 230
Sznajder, R., 224
Taksar, M., 57, 130
Tang, C., 154
Teicher, H., 225
Thowsen, G. T., 10, 154
Tijms, H., 180–181, 196, 204
Ton, Z., 213
Veinott, A., 8, 11–12, 17, 22, 33, 59, 83–85,
106, 179–182, 184, 195–197, 203, 206,
212, 228
Wagner, H., 7, 12, 17, 83–85, 106, 179–182,
184, 195–197, 203, 206, 212
Wang, Y., 38
Whitin, T., 7
Wijngaard, J., 180
Wolfowitz, J., xiii, 8, 22
Yan, H., xiv, 11–12, 85
Yosida, K., 217
Young, L., 10, 154
Zabel, E., 10, 154
Zhang, H., xiv, 11–12, 85, 106
Zhang, Q., 106, 155
Zheng, Y. S., 12, 84–85, 106, 180–181, 212
Zhu, K., 213
Zipkin, P., 8–9, 21, 23, 27, 39, 41, 84, 150,
180, 212

Subject Index
Admissible decision, 24–26, 30, 43, 48–49,
62, 102, 127–128, 145, 147
Arzel`a-Ascoli Theorem, 101, 119, 144,
220–221
Asymptotic behavior, 17, 23, 86, 107, 133,
184
Asymptotically linear cost; (see also linear
growth), 26, 87
Average cost inventory problem, 130, 182,
196, 206
Average cost optimality equation, 17, 83–86,
101–102, 104, 106–107, 123, 127,
129–130, 133, 144–145, 147, 149–150,
181–183, 203–205
Average optimal policy, 129–130, 149, 179
Backlog case, 17, 59, 63, 66
Banach space, xviii, 44
Base-stock list price policy, 10, 154
Base-stock policy, xiii, 7–11, 15, 17, 154,
161, 164, 168, 171, 174, 181
Borel function, xviii, 29, 31, 44, 46–49
Carryover eﬀect of promotions, 172
Computational methods, 12, 212
Conditional expectation, 28, 30, 93, 226
Constrained models, 37
Controlled Markov process; (see also
Markov decision process), 15
Convergence, 222
Convex cost, 85, 87, 106, 133
Countably many states, 32
Cyclic demand, 22, 37
Decentralized decision making, 173
Diagonalization procedure, 101
Diﬀerential discounted value function, 17,
86, 98, 107, 116, 131, 133, 142
Dini’s Theorem, 219
Dispose-down-to-S, 85, 182
Elementary Renewal Theorem, 111, 185,
225, 227
EOQ: economic order quantity; (see also
square-root formula), xiii, xx, 6–7
Equi-Lipschitzian, 221
Equicontinuity, 220–221
Ergodic dynamic programming equation,
131
Existence Theorem, 218
Fatou’s Lemma, 53, 226
Feedback policy; (see also Markov policy),
16, 26, 31–34, 37, 39, 44, 50, 52,
55–56, 63–64, 68, 83, 89, 97, 99, 102,
104, 117, 122, 125, 127, 129, 138, 143,
146–147, 149, 211
Filtration, 229
First moment ordering; (see also stochastic
dominance), 169, 228–229
History-dependent; (see also
nonanticipative), 23, 26, 62–63, 88,
109, 136, 183, 196–197, 203–204
Induction argument, 32, 38, 56
Joint inventory/promotion problem, 10, 17,
154, 161–162, 172, 174
K-convex, 8, 16–17, 22, 32–33, 37, 39, 56,
59–60, 63, 66, 89, 104–105, 116, 119,
125–126, 138, 146, 184, 193, 203,
205–206, 212–213, 234–239
(K0, K1, K2, ...
Kn)-convex, 239
Kirszbraun Theorem, 218
Leadtime, 5–9, 32, 39, 60, 66, 72, 150, 195
Lebesgue-Stieltjes integrals, 200
Likelihood ratio ordering; (see also
stochastic dominance), 228
Liminf, 128, 148
Limsup, 128, 148
Linear growth; (see also asymptotically
linear cost), xviii, 26, 41, 61, 89, 98,
104, 106, 134, 137
Linear operator, 46, 222

252
Subject Index
Lipschitz continuity, 217–218, 221, 234
Local Lipschitz continuity, 57, 101, 104, 114,
116, 119, 124, 144, 218, 221
Local uniform convergence, 119, 219,
221–222
Locally equi-Lipschitzian, 90, 94, 97, 101,
114, 119, 131, 138, 144, 221
Locally uniformly continuous, 146
Long-run average cost, xiv, 10, 17, 83, 85,
88–89, 106–107, 109, 133, 136–137,
179–184, 207, 211
Lost sales case, 8, 16–17, 59–60, 63, 66, 72,
150, 155
Lower semicontinuous (l.s.c.), xviii, xx,
16–17, 29, 35, 39, 41–42, 44–45,
47–48, 52–54, 56–58, 61, 64, 217–219,
235, 237
m-period truncation, 33, 50
Markov-modulated Poisson demand, 9, 23,
41
Markov chain, xix, 8–10, 14–16, 21, 24, 40,
42–43, 49, 60, 83, 134, 165, 211,
229–231
Markov chain: irreducible, 87, 108, 120, 134,
142, 229–230
Markov decision process (MDP); (see also
controlled Markov process), xx, 15,
17, 84–85, 131, 154–158, 162,
173–174, 181, 196, 204, 212
Markov policy; (see also feedback policy),
16, 22, 26, 31, 41, 55, 58, 63, 83, 131
Markovian demand: unbounded, 16–17, 41,
131
Mean Value Theorem, 202, 219
Monotonicity property, 98, 166
Multiple promotion levels, 172
Newsvendor, xiii, 7, 12, 159–160
No-ordering periods, 15, 22, 38, 40
Nonanticipative; (see also
history-dependent), xix, 26, 62, 88,
109, 136, 183
Nonstationary cost functions, 89
Nonstationary ﬁnite and inﬁnite horizon
problems, 16, 22–23, 33, 36, 42, 49,
54, 58
Normed linear space, 222
PF2 density, xx, 162, 165, 171–172, 233
Piecewise-continuous functions, 26, 89, 137
Pointwise convergent, 219–221, 235
Poisson demand, 212
Polynomial growth, 16–17, 41, 44–45, 52, 54,
58, 108, 114, 121, 131
Positive recurrent, 230
Potential function, xix, 102, 131
Price demand models, 153–154
Price discounts, 155, 172
Production planning, 41
Proﬁt maximization, 4, 156
Promotion, 153
Quadratic growth, 92, 94
Quantile function, 39
Quasi-convex functions, 233
Quasi-convexity, 161–162, 164, 167–168, 233
Renewal approach, 195
Renewal function, 185, 189, 195, 200, 227
(S0, S1, P ) policy, 165
(s, S) policy, xiii, 8, 11–12, 15–16, 21–23,
56, 66, 70, 72, 83–85, 150, 212, 238
(s, S) policy: state-dependent; (see also (s,
S)-type policy), 9, 16–17, 23, 58, 60,
63, 70, 72, 83, 86, 106, 130–131, 133,
150, 212
(s, S)-type policy; (see also (s, S)-type
policy: state-dependent), xiii, 9,
11–12, 15–16, 21–23, 31–32, 36–42,
54–55, 59, 63, 66–67, 69, 72, 83–84,
129, 149–150, 179–180, 183, 211
Safety stock, 39, 67
Seasonal demand, 14–15, 37
Selection Theorem, 29, 47, 218
Service level constraints, 22, 38, 67
Square-root formula; (see also EOQ
formula), 7
State-of-the-world, 9, 21
Stationary distribution approach, 17–18,
179, 182, 195, 203, 206–207, 211
Stationary optimal feedback policy, 57
Stochastic dominance; (see also ﬁrst
moment ordering and likelihood ratio
ordering), 162–163, 165, 225, 228–229
Stopping time, 110, 227, 231
Storage constraints, 38, 67
Supply uncertainty, 38, 60, 66
Surplus balance equations, 88, 109, 136
Surplus position, 32, 39
Tauberian Theorem, 103, 127, 145, 224
Threshold policy, 17, 166, 168
Threshold promotion policy, 164, 171
Transition matrix, xix, 13, 24–25, 42–43,
48–49, 60–61, 86, 134, 156, 164, 229
Truncated normal distribution, 70–71, 173
Type 1 service level, xix, 38–39
Uniform boundedness, 53, 85, 98–101,
116–119, 121–122, 124, 127, 130–131,
142–144, 192, 194, 220–221
Uniform continuity, xviii, 27, 29, 32, 35, 41,
89, 137, 144, 218, 220
Uniform convergence, 219, 221
Uniform Convergence Theorem, 220
Uniform demand distribution, 70–71, 173
Uniform equicontinuity, 101, 119, 220–221
Uniform integrability, 123–124, 131, 225
Uniqueness of the DP equation, 16, 22, 36,
54

MARKOVIAN DEMAND INVENTORY MODELS
253
Upper semicontinuous (u.s.c.), xx, 217
Value iteration algorithm, 9, 23, 70
Vanishing discount approach, 17, 85–86, 88,
98, 106–107, 109, 116, 131, 133, 136,
142, 179–180, 182–183, 203, 206, 211
Veriﬁcation theorem, 26, 30, 39, 42, 46, 48,
63, 67, 86, 102, 106–107, 125, 127,
133, 145, 147, 150, 158, 203
Viscosity solutions, 85

