The Zakon Series on Mathematical Analysis
Basic Concepts of Mathematics
Mathematical Analysis I
(in preparation)
Mathematical Analysis II
(in preparation)
9 781931 705004


The Zakon Series on Mathematical Analysis
Basic Concepts of
Mathematics
Elias Zakon
University of Windsor
The Trillia Group
West Lafayette, IN

Terms and Conditions
You may download, print, transfer, or copy this work, either electronically
or mechanically, only under the following conditions.
If you are a student using this work for self-study, no payment is required.
If you are a teacher evaluating this work for use as a required or recommended
text in a course, no payment is required.
Payment is required for any and all other uses of this work. In particular,
but not exclusively, payment is required if:
(1) You are a student and this is a required or recommended text for a course.
(2) You are a teacher and you are using this book as a reference, or as a
required or recommended text, for a course.
Payment is made through the website http://www.trillia.com.
For each
individual using this book, payment of US$10 is required. A site-wide payment
of US$300 allows the use of this book in perpetuity by all teachers, students,
or employees of a single school or company at all sites that can be contained
in a circle centered at the location of payment with a radius of 25 miles (40
kilometers). You may post this work to your own website or other server (ftp,
gopher, etc.) only if a site-wide payment has been made and it is noted on your
website (or other server) precisely which people have the right to download this
work according to these terms and conditions.
Any copy you make of this work, by any means, in whole or in part, must
contain this page, verbatim and in its entirety.
Basic Concepts of Mathematics
c⃝1973 Elias Zakon
c⃝2001 Bradley J. Lucier and Tamara Zakon
ISBN 1-931705-00-3
Published by The Trillia Group, West Lafayette, Indiana, USA
First published: May 26, 2001. This version released: October 29, 2001.
Technical Typist: Judy Mitchell. Copy Editor: John Spiegelman. Logo: Miriam Bogdanic.
The phrase “The Trillia Group” and The Trillia Group logo are trademarks of The Trillia
Group.
This book was prepared by Bradley J. Lucier and Tamara Zakon from a manuscript
prepared by Elias Zakon. We intend to correct and update this work as needed. If you notice
any mistakes in this work, please send e-mail to lucier@math.purdue.edu and they will be
corrected in a later version.
Half the proceeds from the sale of this book go to the Elias Zakon Memorial Scholarship
fund at the University of Windsor, Canada, funding scholarships for undergraduate students
majoring in Mathematics and Statistics.

Preface
This text helps the student complete the transition from purely manipulative
to rigorous mathematics. It spells out in all detail what is often treated too
brieﬂy or vaguely because of lack of time or space. It can be used either for sup-
plementary reading or as a half-year course. It is self-contained, though usually
the student will have had elementary calculus before starting it. Without the
“starred” sections and problems, it can be (and was) taught even to freshmen.
The three chapters are fairly independent and, with small adjustments, may
be taught in arbitrary order. The chapter on n-space “imitates” the geometry
of lines and planes in 3-space, and ensures a thorough review of the latter, for
students who may not have had it. A wealth of problems, some simple, some
challenging, follow almost every section.
Several years’ class testing led the author to these conclusions:
(1) The earlier such a course is given, the more time is gained in the follow-
up courses, be it algebra, analysis or geometry.
The longer students
are taught “vague analysis”, the harder it becomes to get them used to
rigorous proofs and formulations and the harder it is for them to get rid of
the misconception that mathematics is just memorizing and manipulating
some formulas.
(2) When teaching the course to freshmen, it is advisable to start with Sec-
tions 1–7 of Chapter 2, then pass to Chapter 3, leaving Chapter 1 and
Sections 8–10 of Chapter 2 for the end. The students should be urged to
preread the material to be taught next. (Freshmen must learn to read
mathematics by rereading what initially seems “foggy” to them.) The
teacher then may conﬁne himself to a brief summary, and devote most
of his time to solving as many problems (similar to those assigned) as
possible. This is absolutely necessary.
(3) An early and constant use of logical quantiﬁers (even in the text) is ex-
tremely useful. Quantiﬁers are there to stay in mathematics.
(4) Motivations are necessary and good, provided they are brief and do not
use terms that are not yet clear to students.

Contents
∗
Chapter 1. Some Set Theoretical Notions
1
1. Introduction. Sets and their Elements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1
2. Operations on Sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
Problems in Set Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9
3. Logical Quantiﬁers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
4. Relations (Correspondences) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
Problems in the Theory of Relations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
5. Mappings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
Problems on Mappings. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .26
∗6. Composition of Relations and Mappings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
Problems on the Composition of Relations. . . . . . . . . . . . . . . . . . . . . . . . .30
∗7. Equivalence Relations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32
Problems on Equivalence Relations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .35
8. Sequences. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .37
Problems on Sequences. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .42
∗9. Some Theorems on Countable Sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44
Problems on Countable and Uncountable Sets . . . . . . . . . . . . . . . . . . . . . 48
Chapter 2. The Real Number System
50
1. Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50
2. Axioms of an Ordered Field . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51
3. Arithmetic Operations in a Field . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54
4. Inequalities in an Ordered Field. Absolute Values. . . . . . . . . . . . . . . . . . . .57
Problems on Arithmetic Operations and Inequalities in a Field . . . . 61
5. Natural Numbers. Induction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62
6. Induction (continued) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67
Problems on Natural Numbers and Induction. . . . . . . . . . . . . . . . . . . . . .70
7. Integers and Rationals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73
Problems on Integers and Rationals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75
8. Bounded Sets in an Ordered Field . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76
∗“Starred” sections may be omitted by beginners.

vii
9. The Completeness Axiom. Suprema and Inﬁma. . . . . . . . . . . . . . . . . . . . . .78
Problems on Bounded Sets, Inﬁma, and Suprema. . . . . . . . . . . . . . . . . .82
10. Some Applications of the Completeness Axiom . . . . . . . . . . . . . . . . . . . . . . 84
Problems on Complete and Archimedean Fields . . . . . . . . . . . . . . . . . . . 88
11. Roots. Irrational Numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
Problems on Roots and Irrationals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
∗12. Powers with Arbitrary Real Exponents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92
Problems on Powers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95
∗13. Decimal and other Approximations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97
Problems on Decimal and q-ary Approximations. . . . . . . . . . . . . . . . . .102
∗14. Isomorphism of Complete Ordered Fields. . . . . . . . . . . . . . . . . . . . . . . . . . . 102
Problems on Isomorphisms. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .109
∗15. Dedekind Cuts. Construction of E1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110
Problems on Dedekind Cuts. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .118
16. The Inﬁnities. ∗The lim and lim of a Sequence. . . . . . . . . . . . . . . . . . . . . .120
Problems on Upper and Lower Limits of Sequences in E∗. . . . . . . . .125
Chapter 3. The Geometry of n Dimensions. ∗Vector Spaces
127
1. Euclidean n-space, En . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127
Problems on Vectors in En. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .132
2. Inner Products. Absolute Values. Distances . . . . . . . . . . . . . . . . . . . . . . . . 133
Problems on Vectors in En (continued). . . . . . . . . . . . . . . . . . . . . . . . . . .138
3. Angles and Directions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .139
4. Lines and Line Segments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143
Problems on Lines, Angles, and Directions in En . . . . . . . . . . . . . . . . . 147
5. Hyperplanes in En. ∗Linear Functionals on En . . . . . . . . . . . . . . . . . . . . . 150
Problems on Hyperplanes in En . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .155
6. Review Problems on Planes and Lines in E3 . . . . . . . . . . . . . . . . . . . . . . . .158
7. Intervals in En. Additivity of their Volume . . . . . . . . . . . . . . . . . . . . . . . . . 162
Problems on Intervals in En . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 168
8. Complex Numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170
Problems on Complex Numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174
∗9. Vector Spaces. The Space Cn. Euclidean Spaces. . . . . . . . . . . . . . . . . . . .176
Problems on Linear Spaces. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .180
∗10. Normed Linear Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181
Problems on Normed Linear Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184
Notation
187
Index
188

About the Author
Elias Zakon was born in Russia under the czar in 1908, and he was swept
along in the turbulence of the great events of twentieth-century Europe.
Zakon studied mathematics and law in Germany and Poland, and later he
joined his father’s law practice in Poland. Fleeing the approach of the German
Army in 1941, he took his family to Barnaul, Siberia, where, with the rest of
the populace, they endured ﬁve years of hardship. The Leningrad Institute of
Technology was also evacuated to Barnaul upon the siege of Leningrad, and he
met there the mathematician I. P. Natanson; with Natanson’s encouragement,
Zakon again took up his studies and research in mathematics.
Zakon and his family spent the years from 1946 to 1949 in a refugee camp
in Salzburg, Austria, where he taught himself Hebrew, one of the six or seven
languages in which he became ﬂuent. In 1949, he took his family to the newly
created state of Israel and he taught at the Technion in Haifa until 1956. In
Israel he published his ﬁrst research papers in logic and analysis.
Throughout his life, Zakon maintained a love of music, art, politics, history,
law, and especially chess; it was in Israel that he achieved the rank of chess
master.
In 1956 Zakon moved to Canada. As a research fellow at the University of
Toronto, he worked with Abraham Robinson. In 1957, he joined the mathemat-
ics faculty at the University of Windsor, where the ﬁrst degrees in the newly
established Honours program in Mathematics were awarded in 1960. While
at Windsor, he continued publishing his research results in logic and analysis.
In this post-McCarthy era, he often had as his house-guest the proliﬁc and
eccentric mathematician Paul Erd˝os, who was then banned from the United
States for his political views. Erd˝os would speak at the University of Windsor,
where mathematicians from the University of Michigan and other American
universities would gather to hear him and to discuss mathematics.
While at Windsor, Zakon developed three volumes on mathematical analysis,
which were bound and distributed to students.
His goal was to introduce
rigorous material as early as possible, on which later courses could rely.
We are publishing here the latest complete version of the ﬁrst of these vol-
umes, which was used in a one-semester class required of all ﬁrst-year science
students at Windsor. We have added an index and a list of notation. The elec-
tronic presentation, with extensive hypertextual cross references, is designed to
make it easy to use the book either as a text or a reference. To disseminate this
material as widely as possible, we are making it available free on the Internet
for self-study, and are relying on the good faith of colleges and universities
(with some help from the copyright laws) to pay a modest fee for the use of
this volume as a text.

Chapter 1
Some Set Theoretical Notions
§1. Introduction. Sets and Their Elements
The theory of sets, initiated by the German mathematician G. Cantor (1842–
1918), constitutes the basis of almost all modern mathematics. The set concept
itself cannot be deﬁned in simpler terms. A set is often described as a collection
(“aggregate”, “class”, “totality”, “family”) of objects of any speciﬁed kind.
However, such descriptions are no deﬁnitions, as they merely replace the term
“set” by other undeﬁned terms. Thus the term “set” must be accepted as a
primitive notion, without deﬁnition. Examples of sets are as follows: the set of
all men; the set of all letters appearing on this page; the set of all straight lines
in a given plane; the set of all positive integers; the set of all English songs;
the set of all books in a library; the set consisting of the three numbers 1, 4,
17. Sets will usually be denoted by capital letters, A, B, C, . . ., X, Y , Z.
The objects belonging to a set A are called its elements or members. We
write x ∈A if x is an element of the set A, and x /∈A if it is not.
Example.
If N is the set of all positive integers, then 1 ∈N, 3 ∈N, +
√
9 ∈N, but
√
7 /∈N, 0 /∈N, −1 /∈N, 1
2 /∈N.
It is also convenient to introduce the so-called empty (“void”, “vacuous”)
set, denoted by ∅, i.e., a set that contains no elements at all. Instead of saying
that there are no objects of some speciﬁc kind, we shall say that the set of these
elements is empty; however, this set itself , though empty, will be regarded as
an existing thing.
Once a set has been formed, it is regarded as a new entity, that is, a new
object, diﬀerent from any of its elements. This object may, in its turn, be an
element of some other set. In fact, we can consider whole collections of sets
(also called “families of sets”, “classes of sets”, etc.), i.e., sets whose elements
are other sets. Thus, if M is a collection of certain sets A, B, C, . . . , then
these sets are elements of M, i.e., we have A ∈M, B ∈M, C ∈M, . . . ;

2
Chapter 1. Some Set Theoretical Notions
but the single elements of A need not be members of M, and the same applies
to single elements of B, C, . . . .
Brieﬂy, from p ∈A and A ∈M, it does
not follow that p ∈M. This may be illustrated by the following examples.
Let a “nation” be deﬁned as a certain set of individuals, and let the United
Nations (U.N.) be regarded as a certain set of nations. Then single persons are
elements of the nations, and the nations are members of U.N., but individuals
are not members of U.N. Similarly, the Big Ten consists of ten universities,
each university contains thousands of students, but no student is one of the
Big Ten. Families of sets will usually be denoted by script letters: M, N , P,
etc.
If all elements of a set A are also elements of a set B, we say that A is a
subset of B, and write A ⊆B. In this instance, we also say that B is a superset
of A, and we can write B ⊇A. The set B is equal to A if A ⊆B and B ⊆A,
i.e., the two sets consist of exactly the same elements. If, however, A ⊆B but
B ̸= A (i.e., B contains some elements not in A), then A is referred to as a
proper subset of B; in this case we shall use the notation A ⊂B. The empty
set ∅is considered a subset of any set; it is a proper subset of any nonempty
set. The equality of two sets A and B is expressed by the formula A = B.1
Instead of A ⊆B we shall also write B ⊇A; similarly, we write B ⊃A instead
of A ⊂B. The relation “⊆” is called the inclusion relation.2 Summing up, for
any sets A, B, C, the following are true:
(a) A ⊆A.
(b) If A ⊆B and B ⊆C, then A ⊆C.
(c) If A ⊆B and B ⊆A, then A = B.
(d) ∅⊆A.
(e) If A ⊆∅, then A = ∅.
The properties (a), (b), (c) are usually referred to as the reﬂexivity, tran-
sitivity, and anti-symmetry of the inclusion relation, respectively; (c) is also
called the axiom of extensionality.3
A set A may consist of a single element p; in this case we write A = {p}.
This set must not be confused with the element p itself, especially if p itself is
a set consisting of some elements a, b, c, . . . , (recall that these elements are not
regarded as elements of A; thus A consists of a single element p, whereas p may
have many elements; A and p then are not identical). Similarly, the empty set
1 The equality sign, here and in the sequel, is tantamount to logical identity. A formula
like “A = B” means that the letters A and B denote one and the same thing.
2 Some authors write A ⊂B for A ⊆B. We prefer, however, to reserve the sign ⊂for
proper inclusion.
3 The statement that A = B if A and B have the same elements shall be treated as an
axiom, not a deﬁnition.

§1. Introduction. Sets and Their Elements
3
∅has no elements, while {∅} has an element, namely ∅. Thus ∅̸= {∅} and, in
general, p ̸= {p}.
If A contains the elements a, b, c, . . . , we write
A = {a, b, c, . . . }
(the dots in this symbol imply that A may contain some other elements). If A
consists of a small number of elements, it may be convenient to list them all in
braces. In particular, if A consists of two elements a, b, we write A = {a, b}.
Similarly for a set of three elements, A = {a, b, c}, etc. If confusion is unlikely,
a ﬁnite set may be indicated by the use of dots and a terminal member, as with
{1, 2, 3, . . . , 10}, or {2, 4, 6, . . . , 100}, or {1, 3, 5, . . . , 2n −1}.
It should be noted that the order in which the elements of a set follow each
other does not aﬀect the equality of sets as stated above. For instance, we
have {a, b} = {b, a} because the two sets consist of the same elements. Also,
if some element is mentioned several times, it still counts as one element only.
Thus we have {a, a} = {a}. In this respect, a set consisting of two elements a
and b must be distinguished from the ordered pair (a, b); and, more generally, a
set consisting of n elements, {x1, x2, . . . , xn}, should not be confused with the
ordered n-tuple (x1, . . ., xn). Two ordered pairs (a, b) and (x, y) are considered
equal iﬀ4 a = x and b = y, whereas the sets {a, b} and {x, y} are also equal if
a = y and b = x. A similar distinction applies to ordered n-tuples.5
If P(x) is some proposition or formula involving a variable x, we shall use
the symbol
{x | P(x)}
to denote the set of all objects x for which the formula P(x) is true.
For
instance, the set of all men can be denoted by {x | x is a man}. Similarly,
{x | x is a number, x < 5} stands for “the set of all numbers less than 5.”
We write {x ∈A | P(x)} for “the set of all elements of A for which P(x) is
true.” The variable x in such symbols may be replaced by any other variable;
{x | P(x)} is the same as {y | P(y)}.
Thus the set of all positive integers less than 5 can be denoted either by
{1, 2, 3, 4}, or by {x | x is an integer, 0 < x < 5}. Note: The comma in such
symbols stands for the word “and”.
§2. Operations on Sets
We now proceed to deﬁne some operations on sets.
4 “iﬀ” means “if and only if”.
5 We shall not attempt at this stage to give a deﬁnition of an ordered pair or n-tuple,
though this can be done (cf. Problem 6 after §2).

4
Chapter 1. Some Set Theoretical Notions
Deﬁnition 1.
For any two sets A and B, we deﬁne as follows:
(a) The union, or join, of A and B, denoted by A ∪B, is the set of all
elements x such that x ∈A or x ∈B (i.e., the set of all elements of
A and B taken together).1
(b) The intersection, or meet, of A and B, denoted by A ∩B, is the set
of all elements x such that x ∈A and x ∈B simultaneously (it is
the set of all common elements of A and B).
(c) The diﬀerence A −B is the set of all elements that are in A but not
in B (B may, but need not, be a subset of A).
In symbols,
A ∪B = {x | x ∈A or x ∈B}, A ∩B = {x | x ∈A, x ∈B}, and
A −B = {x | x ∈A, x /∈B}.
The sets A and B are said to be disjoint iﬀA ∩B = ∅, i.e., iﬀthey have
no elements in common. The symbols ∪and ∩are called “cup” and “cap”,
respectively; sometimes the symbols + and · are used instead. Note that, if A
and B have some elements in common, these elements need not be mentioned
twice when forming the union A ∪B. The diﬀerence A −B is also called the
complement of B relative to A (brieﬂy, “in A”).2
Examples.
(1) If A = {1, 2, 3, 4, 5} and B = {2, 4, 6}, then
A ∪B = {1, 2, 3, 4, 5, 6},
A ∩B = {2, 4},
A −B = {1, 3, 5},
B −A = {6}.
(2) If A is the set of all soldiers and B the set of all students, then A ∪B
consists of all persons who are either soldiers or students or both; A ∩B
is the set of all studying soldiers; A −B is the set of all soldiers who do
not study; and B −A consists of those students who are not soldiers.
When speaking of sets, we shall always tacitly assume that we are given some
“master set”, called the space, from which our initial elements are selected.
From these elements we then form the various sets (subsets of the space);
then we proceed to form families of sets, etc. The space will often remain
unspeciﬁed, so that we retain the possibility of changing it if required. If S is
1 The word “or” is used in mathematics in the inclusive sense; that is, “x ∈A or x ∈B”
means “x ∈A or x ∈B or both”.
2 Some authors write A \ B for A −B; some use this notation only if B ⊆A. Others use
the terms “sum” and “product” for “union” and “intersection”, respectively. We shall not
follow this practice.

§2. Operations on Sets
5
the space, and E is its subset (i.e., E ⊆S), we call the diﬀerence S −E simply
the complement of E and denote it brieﬂy by −E; thus −E = S −E (provided
that S is the space and E ⊆S).3
The notions of union, intersection, and diﬀerence can be graphically illus-
trated by means of so-called “Venn diagrams”4 on which they appear as the
shaded areas of two or more intersecting circles or other suitable areas. In Fig-
ures 1, 2, and 3, we provide Venn diagrams illustrating the union, intersection,
and diﬀerence of two sets A and B.
A
B
Figure 1: A ∪B
A
B
Figure 2: A ∩B
A
B
Figure 3: A −B
Theorem 1. For any sets A, B, and C, we have the following:
(a) A ∪A = A; A ∩A = A
(idempotent laws).
(b) A ∪B = B ∪A; A ∩B = B ∩A
(commutative laws).
(c) (A ∪B) ∪C = A ∪(B ∪C)
(d) (A ∩B) ∩C = A ∩(B ∩C)
)
(associative laws).
(e) (A ∪B) ∩C = (A ∩C) ∪(B ∩C)
(f) (A ∩B) ∪C = (A ∪C) ∩(B ∪C)
)
(distributive laws).
(g) A ∪∅= A; A ∩∅= ∅; A −∅= A; A −A = ∅.
To verify these formulas, we have to check, each time, that every element
contained in the set occurring on the left-hand side of the equation also belongs
to the right-hand side, and conversely. For example, we shall verify formula (e),
leaving the proof of the remaining formulas to the reader. Suppose then that
some element x belongs to the set (A ∪B) ∩C; this means that x ∈(A ∪B)
and, simultaneously, x ∈C; in other words, we have x ∈A or x ∈B and,
simultaneously, x ∈C. It follows that we have (x ∈A and x ∈C) or (x ∈B
and x ∈C); that is, x ∈(A∩C) or x ∈(B ∩C), whence x ∈[(A∩C)∪(B ∩C)].
Thus we see that every element x contained in the left-hand side of (e) is also
contained in the right-hand side. The converse assertion is proved in the same
way by simply reversing the order of the steps of the proof.
In Figures 4 and 5, we illustrate the distributive laws (e) and (f) by Venn
diagrams; the shaded area represents the set resulting from the operations
involved in each case.
3 Other notations in use for complement are as follows: ∼E, e
E, E∼, ∁E, E′, etc.
4 After the English logician John Venn (1834–1883).

6
Chapter 1. Some Set Theoretical Notions
A
B
C
(A ∩B) ∪C = (A ∪C) ∩(B ∪C)
Figure 5
A
B
C
(A ∪B) ∩C = (A ∩C) ∪(B ∩C)
Figure 4
Because of the associative laws, we may omit the brackets in expressions
occurring in formulas (c) and (d). Thus we may write A∪B ∪C and A∩B ∩C
instead of (A ∪B) ∪C and (A ∩B) ∩C, respectively.5 Similarly, unions and
intersections of four or more sets may be written in various ways:
A ∪B ∪C ∪D = (A ∪B) ∪(C ∪D) = A ∪(B ∪C ∪D) = (A ∪B ∪C) ∪D;
A ∩B ∩C ∩D = (A ∩B ∩C) ∩D = (A ∩B) ∩(C ∩D), etc.
As we noted in §1, we may consider not just one or two, but a whole family
of sets, even inﬁnitely many of them. Sometimes we can number the sets under
consideration: X1, X2, X3, . . . , Xn, . . . (compare this to the numbering of
buildings in a street, or books in a library). More generally, we may denote
all sets of a family M by one and the same letter (say, X), with some indices
(subscripts or superscripts) attached to it: Xi or Xi, where i runs over a
suitable (suﬃciently large) set I of indices, called the index set. The indices
may, but need not, be numbers. They are just “labels” of arbitrary nature,
used solely to distinguish the sets from each other, in the same way that a good
cook uses labels to distinguish the jars in the kitchen. The whole family M
then is denoted by {Xi | i ∈I}, brieﬂy {Xi}. Here i is a variable ranging over
the index set I. This is called index notation.
The notions of union and intersection can easily be extended to arbitrary
families of sets. If M is such a family, we deﬁne its union, S M, to be the
set of all elements x, each belonging to at least one set of the family. The
intersection, T M, consists of those elements x that belong to all sets of the
family simultaneously. Instead of S M and T M, we also use
[
{X | X ∈M}
and
\
{X | X ∈M},
respectively.
Here X is a variable denoting any arbitrary set of the family. Note: x ∈S M
iﬀx is in at least one set X of the family; x ∈T M iﬀx belongs to every set
X of the family.
5 As will be seen, unions and intersections of three or more sets can be deﬁned indepen-
dently. Thus, in set theory, such formulas as A∩B∩C = (A∩B)∩C or A∪B∪C = (A∪B)∪C
are theorems, not deﬁnitions.

§2. Operations on Sets
7
Thus T M is the common part of all sets X from M (possibly T M = ∅),
while S M comprises all elements of all these sets combined.
If M = {Xi | i ∈I} (index notation), we also use symbols like
[
{Xi | i ∈I} =
[
i∈I
Xi =
[
i
Xi =
[
Xi and
\
{Xi | i ∈I} =
\
i∈I
Xi =
\
i
Xi =
\
Xi
for S M and T M, respectively. Finally, if the indices are integers, we use
symbols like
∞
[
n=1
Xn,
q\
n=1
Xn,
∞
[
n=k
Xn, X1 ∪X2 ∪· · · ∪Xn ∪· · · ,
or the same with S and T interchanged, imitating a similar notation known
from elementary algebra for sums and products of numbers.
The following theorem has many important applications.
Theorem 2 (de Morgan’s duality laws6). Given a set E and any family of
sets {Ai} (where i ranges over some index set I), we always have
(i) E −
[
i
Ai =
\
i
(E −Aj);
(ii) E −
\
i
Ai =
[
i
(E −Ai).
Verbally, this reads as follows:
(i) The complement (in E) of the union of a family of sets equals the inter-
section of their complements (in E).
(ii) The complement (in E) of the intersection of a family of sets equals the
union of their complements (in E).
Proof of (i). We have to show that the set E −S
i Ai consists of exactly the
same elements as the set T
i(E −Ai), i.e., that we have
x ∈E −
[
i
Ai iﬀx ∈
\
i
(E −Ai).
This follows from the equivalence of the following statements (we indicate log-
6 Augustus de Morgan, Indian-born English mathematician and logician (1806–1871).

8
Chapter 1. Some Set Theoretical Notions
ical inference by arrows):7
y
x ∈E −
[
i
Ai,
x ∈E but x /∈
[
i
Ai,
x ∈E but x is not in any of the sets Ai,
x is in each of the sets E −Ai,
x ∈
\
i
(E −Ai).
x
Similarly for part (ii), which we leave to the reader.
□
Note: In the special case where E is the entire space, the duality laws can
be written more simply:
(i) −
[
i
Ai =
\
i
(−Ai);
(ii) −
\
i
Ai =
[
i
(−Ai).
Note: The duality laws (Theorem 2) hold also when the sets Ai are not
subsets of E.
The importance of the duality laws consists in that they make it possible to
derive from each general set identity its so-called “dual”, i.e., a new identity that
arises from the ﬁrst by interchanging all “cap” and “cup” signs. For example,
the two associative laws, Theorem 1(c) and (d), are each other’s duals, and so
are the two distributive laws, (e) and (f).
To illustrate this fact, we shall show how the second distributive law, (f),
can be deduced from the ﬁrst, (e), which has already been proved.
Since
Theorem 1(e) holds for any sets, it also holds for their complements. Thus we
have, for any sets A, B, C,
(−A) ∩(−B ∪−C) = (−A ∩−B) ∪(−A ∩−C).
But, by the duality laws, −B ∪−C = −(B ∩C); similarly,
−A ∩−B = −(A ∪B) and −A ∩−C = −(A ∪C).
Therefore, we obtain
−A ∩−(B ∩C) = −(A ∪B) ∪−(A ∪C),
or, applying again the duality laws to both sides,
−[A ∪(B ∩C)] = −[(A ∪B) ∩(A ∪C)],
7 Sometimes horizontal arrows are used instead of the vertical ones (to be explained in
§3).

§2. Operations on Sets
9
whence A ∪(B ∩C) = (A ∪B) ∩(A ∪C), as required. This procedure is quite
general and leads to the following duality rule: Whenever an identity holds for
all sets, so also does its dual.8
As an exercise, the reader may repeat the same procedure for the two asso-
ciative laws (prove one of them in the ordinary way and then derive the second
by using the duality laws), as well as for the following theorem.
Theorem 3 (Generalized distributive laws). If E is a set and {Ai} is any set
family, then
(i) E ∩
[
i
Ai =
[
i
(E ∩Ai);
(ii) E ∪
\
i
Ai =
\
i
(E ∪Ai).
Problems in Set Theory
1. Verify the formulas (c), (d), (f), and (g) of Theorem 1.
2. Prove that −(−A) = A.
3. Verify the following formulas (distributive laws with respect to the sub-
traction of sets), and illustrate by Venn diagrams:
(a) A ∩(B −C) = (A ∩B) −(A ∩C);
(b) (A −C) ∩(B −C) = (A ∩B) −C.
4. Show that the relations (A ∪C) ⊂(A ∪B) and (A ∩C) ⊂(A ∩B), when
combined, imply C ⊂B. Disprove the converse by an example.
5. Describe geometrically the following sets on the real line:
(i) {x | x < 0};
(ii) {x | |x| < 1};
(iii) {x | |x −a| < ε};
(iv) {x | |x| < 0};
(v) {x | a < x < b};
(vi) {x | a ≤x ≤b}.
6. If (x, y) denotes the set { {x}, {x, y} }, prove that, for any x, y, v, u, we
have (x, y) = (u, v) iﬀx = u and y = v. Treat this as a deﬁnition of an
ordered pair.
[Hint: Consider separately the two cases x = y and x ̸= y, noting that {x, x} = {x}.]
7. Let A = {x1, x2, . . . , xn} be a set consisting of n distinct elements. How
many subsets does it have? How many proper subsets?
8. Prove that
(A ∪B) ∩(B ∪C) ∩(C ∪A) = (A ∩B) ∪(B ∩C) ∪(C ∩A)
8 More precisely, this applies to set identities involving no operations other than ∩and ∪;
cf. also Problem 10 (iii) below.

10
Chapter 1. Some Set Theoretical Notions
in two ways:
(i) using deﬁnitions only;
(ii) using the commutative, associative, and distributive laws.
(In the second case, write AB for A ∩B and A + B for A ∪B, etc., and
proceed to remove brackets, noting that A + A = A = AA.)
9. Show that the following relations hold iﬀA ⊆E:
(i) (E −A) ∪A = E;
(ii) E −(E −A) = A;
(iii) A ∪E = E;
(iv) A ∩E = A;
(v) A −E = ∅.
10. Prove de Morgan’s duality laws:
(i) E −T Xi = S(E −Xi);
(ii) E −S Xi = T(E −Xi);
(iii) if A ⊆B, then (E −B) ⊆(E −A).
11. Prove the generalized distributive laws:
(i) A ∩S Xi = S(A ∩Xi);
(ii) A ∪T Xi = T(A ∪Xi);
(iii) T Xi ∪T Yj = T
i,j(Xi ∪Yj);
(iv) S Xi ∩S Yj = S
i,j(Xi ∩Yj).
12. In Problem 11, show that (i) and (ii) are duals (i.e., follow from each
other by de Morgan’s duality laws) and so are (iii) and (iv).
13. Prove the following:
(i)
\
Xi

−A =
\
(Xi −A);
(ii)
[
Xi

−A =
[
(Xi −A)
(generalized distributive laws with respect to diﬀerences).
14. If (x, y) is deﬁned as in Problem 6, which of the following is true?
x ∈(x, y);
{x} ∈(x, y);
y ∈(x, y);
{y} ∈(x, y);
{x, y} ∈(x, y);
{x} = (x, x);
{{x}} = (x, x).
15. Prove that
(i) A −B = A ∩−B = (−B) −(−A) = −((−A) ∪B) and
(ii) A ∩B = A −(−B) = B −(−A) = −(−A ∪−B).
Give also four various expressions for A ∪B.

§2. Operations on Sets
11
16. Prove the following:
(i) (A ∪B) −B = A −B = A −(A ∩B);
(ii) (A −B) −C = A −(B ∪C);
(iii) A −(B −C) = (A −B) ∪(A ∩C);
(iv) (A −B) ∩(C −D) = (A ∩C) −(B ∪D).
17. The symmetric diﬀerence of two sets A and B is
A △B = (A −B) ∪(B −A).
Prove the following:
(i) A △B = B △A;
∗(ii) A △(B △C) = (A △B) △C;
(iii) A △∅= A;
(iv) If A ∩B = ∅, A △B = A ∪B;
(v) If A ⊇B, A △B = A −B;
(vi) A △B = (A ∪B) −(A ∩B) = (A ∪B) ∩(−A ∪−B);
(vii) A △A = ∅;
(viii) A △B = (−A) △(−B);
(ix) −(A △B) = A △(−B) = (−A) △B = (A ∩B) ∪(−A ∩−B);
(x) (A △B) ∩C = (A ∩C) △(B ∩C).
∗18. For n = 2, 3, . . . deﬁne the following:
n
△
i=1
Ai = A1 △A2 △· · · △An = (A1 △A2 △· · · △An−1) △An.
Prove that x ∈△n
i=i Ai iﬀx ∈Ai for an odd number of values of i.
19. Use Venn diagrams to check the consistency of this report: Of 100 pa-
tients, 47 were inoculated against smallpox, 43 against polio, 51 against
tetanus, 21 against both smallpox and polio, and 19 against tetanus and
polio, while 7 had to obtain all three shots.
∗20. (Russell paradox.) A set M is said to be abnormal iﬀM ∈M, i.e., iﬀ
it contains itself as one of its members (such as, e.g., the family of “all
possible” sets); and normal iﬀM /∈M. Let N be the class of all normal
sets, i.e., N = {X | X /∈X}. Is N itself normal? Verify that any answer
to this question implies its own negation, and thus the very deﬁnition of
N is contradictory, i.e., N is an impossible (“contradictory”) set. (To
exclude this and other paradoxes, various systems of axioms have been
set up, so as to deﬁne which sets may, and which may not, be formed.)

12
Chapter 1. Some Set Theoretical Notions
§3. Logical Quantiﬁers
From logic we borrow the following widely-used abbreviations:
“(∀x ∈A) . . . ” means “For each member x of A, it is true that . . . .”
“(∃x ∈A) . . . ” means “There is at least one x in A such that . . . .”
“(∃!x ∈A) . . .” means “There is a unique x in A such that . . . .”
The symbols “(∀x ∈A)” and “(∃x ∈A)” are called the universal and
existential quantiﬁers, respectively. If confusion is ruled out, we simply write
“(∀x)”, “(∃x)”, and “(∃!x)” instead. For example, if N is the set of all naturals
(positive integers), then the formula
“(∀n ∈N) (∃m ∈N) m > n”
means “For each natural n there is a natural m such that m > n.” If we agree
that m, n denote naturals, we may write “(∀n) (∃m) m > n” instead. Some
more examples follow:
Let M = {Ai | i ∈I} be an indexed set family (see §2). By deﬁnition,
x ∈S
i Ai means that x is in at least one of the sets Ai. In other words, there
is at least one index i ∈I for which x ∈Ai; in symbols, (∃i ∈I) x ∈Ai. Thus
x ∈
[
i∈I
Ai iﬀ(∃i ∈I) x ∈Ai;
similarly,
x ∈
\
i
Ai iﬀ(∀i) x ∈Ai.
Also note that x /∈S
i Ai iﬀx is in none of the Ai, i.e., (∀i) x /∈Ai. Similarly,
x /∈T
i Ai iﬀx fails to be in some Ai, i.e., (∃i) x /∈Ai. Thus
x /∈
\
i
Ai iﬀ(∃i) x /∈Ai;
x /∈
[
i
Ai iﬀ(∀i) x /∈Ai.
As an application, we now prove Theorem 2 of §2, using quantiﬁers:
(i)
y
x ∈E −
[
Ai,
x ∈E but x /∈∪Ai,
x ∈E and (∀i) x /∈Ai,
(∀i) x ∈E −Ai,
x ∈
\
(E −Ai).
x
(ii)
y
x ∈E −
\
Ai,
x ∈E but x /∈∩Ai,
x ∈E and (∃i) x /∈Ai,
(∃i) x ∈E −Ai,
x ∈
[
(E −Ai).
x
.
□
The reader should practice such examples thoroughly. Quantiﬁers not only
shorten formulations but often make them more precise. We shall therefore
brieﬂy dwell on their properties.
Order. The order in which quantiﬁers follow each other is essential; e.g.,
the formula
“(∀n ∈N) (∃m ∈N) m > n”

§3. Logical Quantiﬁers
13
(each natural n is exceeded by some m ∈N) is true; but
“(∃m ∈N) (∀n ∈N) m > n”
is false since it states that some natural m exceeds all naturals. However, two
consecutive universal quantiﬁers (or two consecutive existential ones) may be
interchanged. Instead of “(∀x ∈A) (∀y ∈A)” we brieﬂy write “(∀x, y ∈A)”.
Similarly, we write “(∃x, y ∈A)” for “(∃x ∈A) (∃y ∈A)”, “(∀x, y, z ∈A)”
for “(∀x ∈A) (∀y ∈A) (∀z ∈A)”, and so on.
Qualiﬁcations. Sometimes a formula P(x) holds not for all x ∈A, but
only for those with some additional property Q(x). This will be written as
“(∀x ∈A | Q(x)) P(x),” where the vertical stroke | stands for “such that”. For
example, if N is again the naturals, then the formula
“(∀x ∈N | x > 3)
x ≥4”
(1)
means “For each natural x such that x > 3, it is true that x ≥4.” In other
words, for naturals, x > 3 implies x ≥4; this is also written
“(∀x ∈N)
[x > 3 =⇒x ≥4]”
(the arrow =⇒stands for “implies”). The symbol ⇐⇒is used for “iﬀ” (“if
and only if”). For instance,
“(∀x ∈N)
[x > 3 ⇐⇒x ≥4]”
means “For natural numbers x, we have x > 3 if and only if x ≥4.”
Negations. In mathematics, we often have to form the negation of a for-
mula that starts with one or several quantiﬁers. Then it is noteworthy that each
universal quantiﬁer is replaced by an existential one (and vice versa), followed
by the negation of the subsequent part of the original formula. For example, in
calculus, a real number p is called the limit of a sequence x1, x2, . . . , xn, . . .
iﬀthe following is true: “For every real ε > 0, there is a natural k (depending
on ε) such that for all integers n > k, we have |xn −p| < ε.” If we agree that
lower-case letters (possibly with subscripts) denote real numbers, and that n,
k denote naturals, this sentence can be written thus:
(∀ε > 0) (∃k) (∀n > k)
|xn −p| < ε.
(2)
Here “(∀ε > 0)” and “(∀n > k)” stand for “(∀ε | ε > 0)” and “(∀n | n > k)”.
Such self-explanatory abbreviations will also be used in other similar cases.
Now let us form the negation of (2). As (2) states that “for all ε > 0”
something (i.e., the rest of the formula) is true, the negation of (2) starts with
“there is an ε > 0” (for which the rest of the formula fails). Thus we start
with “(∃ε > 0)” and form the negation of the rest of the formula, i.e., of “(∃k)
(∀n > k) |xn −p| < ε”. This negation, in turn, starts with “(∀k)” (why?), and

14
Chapter 1. Some Set Theoretical Notions
so on. Step by step, we ﬁnally arrive at
(∃ε > 0) (∀k) (∃n > k)
|xn −p| ≥ε,
i.e., “there is at least one ε > 0 such that, for every natural k, one can ﬁnd an
integer n > k, with |xn −p| ≥ε”. Note that here the choice of n may depend
on k. To stress it, we write nk for n. Thus the negation of (2) emerges as
(∃ε > 0) (∀k) (∃nk > k)
|xnk −p| ≥ε.
(3)
Rule: To form the negation of a quantiﬁed formula, replace all universal
quantiﬁers by existential ones, and conversely; ﬁnally, replace the remaining
(unquantiﬁed) formula by its negation. Thus, in (2), “|xn −p| < ε” must be
replaced by “|xn −p| ≥ε”, or rather by “|xnk −p| ≥ε”, as explained.
Note 1. Formula (3) is also the negation of (2) when (2) is written as
“(∀ε > 0) (∃k) (∀n)
[n > k =⇒|xn −p| < ε]”.
In general, to form the negation of a formula containing the implication sign
=⇒, it is advisable ﬁrst to re-write all without that sign, using the notation
“(∀x | . . . )” (here: “(∀n | n > k)”).
Note 2. The universal quantiﬁer in a formula (∀x ∈A) P(x) does not imply
the existence of an x for which P(x) is true. It is only meant to imply that
there is no x in A for which P(x) fails. This remains true even if A = ∅; we
then say that “(∀x ∈A) P(x)” is vacuously true. For example, the statement
“all witches are beautiful” is vacuously true because there are no witches at
all; but so also is the statement “all witches are ugly”. Similarly, the formula
∅⊆B, i.e., (∀x ∈∅) x ∈B, is vacuously true.
Problem. Redo Problems 11 and 13 of §2 using quantiﬁers.
§4. Relations (Correspondences)
We already have occasionally used terms like “relation”, “operation”, etc., but
they did not constitute part of our theory. In this and the next sections, we
shall give a precise deﬁnition of these concepts and dwell on them more closely.
Our deﬁnition will be based on the concept of an ordered pair.
As has
already been mentioned, by an ordered pair (brieﬂy “pair”) (x, y), we mean
two (possibly equal) objects x and y given in a deﬁnite order, so that one of
them, x, becomes the ﬁrst (or left) and the other, y, is the second (or right)
part of the pair.1 We recall that two pairs (a, b) and (x, y) are equal iﬀtheir
corresponding members are the same, that is, iﬀa = x and b = y. The pair
1 For a more precise deﬁnition (avoiding the undeﬁned term “order”), see Problem 6 after
§2.

§4. Relations (Correspondences)
15
(y, x) should be distinguished from (x, y); it is called the inverse to (x, y). Once
a pair (x, y) has been formed, it is treated as a new thing (i.e., as one object,
diﬀerent from x and y taken separately); x and y are called the coordinates of
the pair (x, y).
Nothing prevents us, of course, from considering also sets of ordered pairs,
i.e., sets whose elements are pairs, (each pair being regarded as one element of
the set). If the pair (x, y) is an element of such a set R, we write (x, y) ∈R.
Note: This does not imply that x and y taken separately, are elements of R;
(then we write x, y ∈R).
Deﬁnition 1.
By a relation, or correspondence, we mean any set of ordered pairs.2
If R is a relation, and (x, y) ∈R, then y is called an R-relative of x (but
x is not called an R-relative of y unless (y, x) ∈R); we also say in this case
that y is R-related to x or that the relation R holds between x and y. Instead
of (x, y) ∈R, we also write xRy. The letter R, designating a relation, may be
replaced by other letters; it is often replaced by special symbols like <, >, ∼,
≡, etc.
Examples.
(1) Let R be the set of all pairs (x, y) of integers x and y such that x is
less than y.3
Then R is a relation (called “inequality relation between
integers”). The formula xRy means in this case that x and y are integers,
with x less than y. Usually the letter R is here replaced by the special
symbol <, so that “xRy” turns into “x < y”.
(2) The inclusion relation ⊆introduced in §1 may be interpreted as the set
of all pairs (X, Y ) where X and Y are subsets of a given space, with X a
subset of Y . Similarly, the ∈-relation is the set of all pairs (x, A) where
A is a subset of the space and x is an element of A.
(3) ∅is a relation (“an empty set of pairs”).
If P(x, y) is a proposition or formula involving the variables x and y, we
denote by {(x, y) | P(x, y)} the set of all ordered pairs for which the formula
P(x, y) is true. For example, the set of all married couples could be denoted
by {(x, y) | x is the wife of y}.4 Any such set is a relation.
2 This use of the term “relation” may seem rather strange to a reader unfamiliar with
exact mathematical terminology. The justiﬁcation of this deﬁnition is in that it ﬁts exactly
all mathematical purposes, as will be seen later, and makes the notion of relation precise,
reducing it to that of a “set”.
3 Though the theory of integers and real numbers will be formally introduced only in
Chapter 2, we feel free to use them in illustrative examples.
4 This set could be called “the relation of being married”.

16
Chapter 1. Some Set Theoretical Notions
Since relations are sets, the equality of two relations, R and S, means that
they consist of exactly the same elements (ordered pairs); that is, we have
R = S iﬀxRy always implies xSy, and vice versa. Similarly, R ⊆S means
that xRy always implies xSy (but the converse need not be true).
By replacing all pairs (x, y) belonging to a relation R by their inverses (y, x)
we obtain a new relation, called the inverse of R and denoted by R−1. Clearly,
we have xR−1y iﬀyRx; thus
R−1 = {(x, y) | yRx} = {(y, x) | xRy}.
This shows that R, in its turn, is the inverse of R−1; i.e., (R−1)−1 = R. For
example, the relations < and > between numbers are inverse to each other; so
also are the relations ⊆and ⊇between sets.
If a correspondence R contains the ordered pairs (x, x′), (y, y′), (z, z′), . . . ,
we shall write
R =

x
y
z
. . .
x′
y′
z′
. . .

,
(1)
i.e., the pairs will be written in vertical notation, so that each left coordinate
of a pair is written above the corresponding right coordinate (i.e., above its
R-relative). Thus, e.g., the symbol

1
4
1
3
2
2
1
1

(2)
denotes the relation consisting of the four pairs (1, 2), (4, 2), (1, 1), and (3, 1).
The inverse relation is obtained by simply interchanging the upper and the
lower rows.
Deﬁnition 2.
The set of all left coordinates of pairs contained in a relation R is called
the domain of R, denoted DR. The set of all right coordinates of these
pairs is called the range or co-domain of R, denoted D′
R. Clearly, x ∈DR
iﬀxRy for some y. Thus (note these formulas)
DR = {x | xRy for some y};
D′
R = {y | xRy for some x};
or, using quantiﬁers,
DR = {x | (∃y) xRy};
D′
R = {y | (∃x) xRy}.
In symbols of the form (1), the domain and range appear as the upper and
the lower row, respectively; thus, e.g., in (2) the domain is {1, 4, 3} and the
range is {2, 1}. Clearly, if all pairs of a relation R are replaced by their inverses,
then the left coordinates turn into the right ones, and conversely. Therefore,

§4. Relations (Correspondences)
17
the domain of the inverse relation R−1 coincides with the range of R, and the
range of R−1 is the domain of R; that is,
DR−1 = D′
R,
D′
R−1 = DR.
(3)
Deﬁnition 3.
Given a relation R and any set A we say that R is
(i) reﬂexive on A iﬀwe have xRx for all elements x of A;
(ii) symmetric on A iﬀxRy implies yRx for any x and y in A;
(iii) transitive on A iﬀxRy combined with yRz implies xRz for all x, y,
and z in A;
(iv) trichotomic on A iﬀ, for any x and y in A, we always have either
xRy, or yRx, or x = y, but never two of these together.
Examples.
(a) The inequality relation < between real numbers is transitive and tri-
chotomic because x < y and y < z always implies x < z (transitivity);
and we always have either x < y, or y < x, or x = y (trichotomy); we
shall dwell on these properties more closely in Chapter 2.
(b) The inclusion relation ⊆between sets is reﬂexive (because A ⊆A) and
transitive (because A ⊆B and B ⊆C implies A ⊆C); but it is neither
symmetric nor trichotomic, the latter because it may well happen that
neither of two sets contains the other, and because A ⊆B and A = B
may both hold.
(c) The relation of proper inclusion, ⊂, is only transitive.
(d) The equality relation, =, is reﬂexive, symmetric, and transitive because
we always have x = x, x = y always implies y = x, and x = y = z implies
x = z. It is, however, not trichotomic. (Why?)
(e) The ∈relation between an element and a set is neither reﬂexive nor
symmetric, nor transitive, nor trichotomic (on the set A consisting of all
elements and all subsets of a given space).
Deﬁnition 4.
The image of a set A under a relation R (brieﬂy, the R-image of A) is
the set of all R-relatives of elements of A; it is denoted by R[A] (square
brackets always!).
The inverse image (the R−1-image) of A, denoted
R−1[A], is the image of A under the inverse relation, R−1. The R-image
of a single element x (or of the set {x}) is simply the set of all R-relatives
of x. It is customary to denote it by R[x] instead of the more precise
notation R[{x}]. Note: R[A] may be empty!

18
Chapter 1. Some Set Theoretical Notions
To form R[A], we ﬁrst ﬁnd the R-relatives of every element x of A (if any),
thus obtaining R[x] for each x ∈A. The union of all these R[x] combined is
the desired image R[A].
Example.
Let
R =

1
1
1
2
2
3
3
3
3
4
1
3
4
5
3
4
1
3
5
1

.
Then R[1] = {1, 3, 4}; R[2] = {3, 5}; R[3] = {1, 3, 4, 5}; R[5] = ∅;
R−1[1] = {1, 3, 4}; R−1[2] = ∅; R−1[3] = {1, 2, 3}; R−1[4] = {1, 3}.
If, further, A = {1, 2} and B = {2, 4}, then R[A] = {1, 3, 4, 5};
R[B] = {1, 3, 5}; R−1[A] = {1, 3, 4}; and R−1[B] = {1, 3}.
By deﬁnition, R[x] is the set of all R-relatives of x. Hence y ∈R[x] means
that y is an R-relative of x, i.e., that (x, y) ∈R, which can also be written as
xRy. Thus the formulas
(x, y) ∈R,
xRy
and
y ∈R[x]
are equivalent. More generally, y ∈R[A] means that y is an R-relative of some
element x ∈A; i.e., there is x ∈A such that (x, y) ∈R. In symbols, y ∈R[A]
is equivalent to (∃x ∈A) (x, y) ∈R, or (∃x ∈A) xRy.
Note that the expressions R[A], R−1[A], R[x] and R−1[x] are deﬁned even
if A or x are not contained in the domain (or range) of R. These images may,
however, be empty. In particular, R[x] = ∅iﬀx /∈DR.
We conclude this section with an important example of a relation. Given
any two sets A and B, we can consider the set of all ordered pairs (x, y) with
x ∈A and y ∈B. This set is called the Cartesian product, or cross product, of
A and B, denoted A × B. Thus
A × B = {(x, y) | x ∈A, y ∈B}.
In particular, A×A is the set of all ordered pairs that can be formed of elements
of A. Note: A × ∅= ∅× A = ∅. (Why?)
The Cartesian product A × B is a relation since it is a set of ordered pairs.
Its domain is A and its range is B (provided that A and B are not empty).
Moreover, it is the “largest” possible relation with this domain and this range,
because any other relation with the same domain and range is a subset of A×B,
i.e., it contains only some of the ordered pairs contained in A × B. Thus, to
form a relation with domain A and range B means to select certain pairs from
A × B. The inverse of A × B is B × A (the set of all inverse pairs).
On the other hand, the formation of Cartesian products may also be treated
as a new operation on sets (called cross multiplication). This operation is not
commutative since, in general, the inverse relation B×A is diﬀerent from A×B,

§4. Relations (Correspondences)
19
so that A × B ̸= B × A. It is also not associative; i.e., we have, in general,
(A × B) × C ̸= A × (B × C). (Why?) Nevertheless, we can speak of cross
products of more than two sets if we agree to write A × B × C for (A × B) × C
(but not for A × (B × C)). Similarly, we deﬁne
A×B ×C ×D = (A×B ×C)×D,
A×B ×C ×D×E = (A×B ×C ×D)×E,
etc. Instead of A × A, we also write A2. Similarly, A3 = A × A × A, A4 =
A × A × A × A, etc.
O
Y
X
P
Q
R
S
A
B
Figure 6
There is a simple and suggestive
graphic representation of the Carte-
sian product A × B. Take two per-
pendicular straight lines OX and OY .
Represent A and B symbolically as
line segments on OX and OY , re-
spectively. Then the rectangle PQRS
(see diagram) represents A × B. Of
course, this representation is symbolic
only since the sets A and B need not
actually be line segments, and A × B need not actually be a rectangle in the
xy-plane. This is similar to Venn diagrams, where sets are symbolically repre-
sented by discs or other areas.
Problems in the Theory of Relations
1. For each of the following relations R, ﬁnd its domain DR, its range D′
R,
and the inverse relation R−1. Specify some values (if any) of x and y such
that xRy is true, and some for which it is false; similarly for xR−1y.
(i) R =

1
1
2
3
7
3
1
4
4
0

;
(ii) R =

3
7
1
−15
2
1
8
2
−20
9

;
(iii) R =

−1
0
1
1

;
(iv) R =

3
5
7
9
11
2
2
4
0
1
1
5

;
(v) R =

1
2
3
4
5
6
7
1
1
1
1
1
1
1

;
(vi) R = ∅.
1′. In Problem 1(i)–(vi), ﬁnd R[A] and R−1[A], given that
(a) A =
1
2

;
(b) A = {1};
(c) A = {7};
(d) A = {0};
(e) A = ∅;
(f) A = {0, 3, −15};
(g) A = {3, 4, 7, 0, −1, 6};
(h) A = {3, 8, 2, 4, 5};

20
Chapter 1. Some Set Theoretical Notions
(i) A = E1 (= the entire real axis);
(j) A = {x ∈E1 | −20 < x < 5}.
2. Describe the following sets in the xy-plane:
(i) {(x, y) | x < y};
(ii) {(x, y) | x2 + y2 < 1};
(iii) {(x, y) | max(|x|, |y|) < 1};
(iv) {(x, y) | |x| + |y| ≤4};
(v) {(x, y) | (x −2)2 + (y + 5)2 > 9};
(vi) {(x, y) | y2 ≥x};
(vii) {(x, y) | x2 + y < 1};
(viii) {(x, y) | x2 −2xy + y2 < 0};
(ix) {(x, y) | x2 −2xy + y2 = 0}.
Treating each of these sets as a relation R, answer the same questions as
in Problem 1. Then ﬁnd R[A] and R−1[A] as in Problem 1′.
3. Prove the following: If A ⊆B, then R[A] ⊆R[B]. Disprove the converse
by giving an example in which R[A] ⊆R[B] but A ⊈B.
4. Prove the following:
(i) R[A ∪B] = R[A] ∪R[B];
(ii) R[A ∩B] ⊆R[A] ∩R[B];
(iii) R[A −B] ⊇R[A] −R[B].
Generalize formulas (i) and (ii) by proving them with A, B replaced by
an arbitrary family of sets {Ai} (i ∈I). Disprove the reverse inclusions
in (ii) and (iii) by counterexamples (thus showing that equality may fail).
Also, try to prove them and explain where and why the proof fails.
5. State and prove necessary and suﬃcient conditions for the following:
(i) R[x] = ∅;
(ii) R−1[x] = ∅;
(iii) R[A] = ∅;
(iv) R−1[A] = ∅.
6. In what case does R[x] ⊆A imply x ∈R−1[A]? Give a proof.
7. Which of the relations speciﬁed in Problems 1 and 2 are transitive, re-
ﬂexive, symmetric, or trichotomic on A if
(i) A = DR ∪D′
R?
(ii) A = {1}?
(iii) A = ∅?
8. In Problem 1, add (as few as possible) new pairs to each of the relations
R, so as to make them reﬂexive, symmetric, and transitive. Try to achieve
the same results by dropping some pairs.
8′. Solve (as far as possible) Problem 8 for trichotomy.
9. Is R−1 reﬂexive, symmetric, transitive, or trichotomic on a set A if R is?
(Give a proof or a counterexample.) Consider the general case and the
case A = DR ∪D′
R.
10. Let R be a relation with DR = D′
R = A. Show that
(i) R is symmetric on A iﬀR = R−1;

§4. Relations (Correspondences)
21
(ii) R is reﬂexive on A iﬀR ⊇IA, where IA = {(x, x) | x ∈A} is the
identity relation on A;
(iii) R is trichotomic on A if R ∩R−1 = ∅= R ∩IA and A × A ⊆
R ∪R−1 ∪IA.
11. Let R be a transitive relation on A, and let S = {(x, y) | xRy, (y, x) /∈R}.
Show that S is transitive and trichotomic on A. Is it true that the relation
T = {(x, y) | xRy, yRx} is reﬂexive, symmetric, and transitive on A? Is
it so on some subset B ⊆A?
∗12. Show by examples that a relation R may have any two of the properties
“reﬂexive”, “symmetric”, and “transitive” on a set A, without possessing
the third one (i.e., the three properties are independent of each other).
13. Which of the properties “reﬂexive”, “symmetric”, “transitive”, and “tri-
chotomic” (on A = DR ∪D′
R) does the relation R possess if xRy means
(i) x is a brother of y;
(ii) x is an ancestor of y;
(iii) x is the father of y;
(iv) x and y are integers, such that x divides y;
(v) x and y are concentric disks in a plane such that x ⊂y;
(vi) x ∈A and y ∈A.
14. Treat A × B as a relation. What are its inverse, domain, and range?
What if A = ∅or B = ∅? How many elements (ordered pairs) does A×B
contain if A has m elements and B has n elements (both ﬁnite)? How
many subsets?5
15. Prove the following identities, and illustrate by diagrams. (In each case
show that a pair (x, y) is in one set iﬀit is in the other.)
(i) (A ∪B) × C = (A × C) ∪(B × C);
(ii) (A ∩B) × (C ∩D) = (A × C) ∩(B × D);
∗(iii) (X × Y ) −(X′ × Y ′) = [(X ∩X′) × (Y −Y ′)] ∪[(X −X′) × Y ].
16. Prove the following:
(i) (A × B) ∩(C × D) = ∅iﬀA ∩C = ∅or B ∩D = ∅;
(ii) A×B = C ×D iﬀeach product has ∅as one of the factors or A = C
and B = D;
5 In this and the following problems, we shall be satisﬁed with the intuitive notion of a
ﬁnite set and the number of its elements. A precise deﬁnition of a ﬁnite set will be given in
§8.

22
Chapter 1. Some Set Theoretical Notions
(iii) If A × B = (A′ × B′) ∪(A′′ × B′′), with all three products not void,
then either A′ = A′′ = A and B = B′ ∪B′′, or B′ = B′′ = B and
A = A′ ∪A′′.
(iv) If A ̸= ∅̸= B and (A × B) ∪(B × A) = C × C, then A = B = C.
(v) If A has at least two elements p and q, then (A×{p})∪({q}×A) ̸=
A × A.
17. Prove the following:
(i) (S Ai) × B = S(Ai × B);
(ii) (T Ai) × B = T(Ai × B);
(iii) (S
i Ai) × (S
j Bj) = S
i,j(Ai × Bj);
(iv) T
i(Ai × Bi) = (T
i)Ai) × (T Bi);
(v) T
i(Ai × Bi × Ci) = (T
i Ai) × (T
i Bi) × (T
i Ci).
∗18. We say that a family M of sets is closed under intersections iﬀM contains
the intersection of any two of its members, i.e., iﬀ
(∀X, Y ∈M)
X ∩Y ∈M.
Let M1 and M2 be two such set families, and let P be the family of all
cross products X × Y , with X ∈M1, Y ∈M2. Show that P is likewise
closed under intersections.
[Hint: Use Problem 15(ii).]
∗19. In Problem 18 assume that the families M1 and M2 also have the fol-
lowing property: The diﬀerence X −Y of any two sets X, Y ∈Mi can
always be represented as a union of ﬁnitely many disjoint members of Mi
(i = 1, 2). Show that, then, the family P also has this property.
[Hint: First, verify the following identity (see Problem 15 (iii)):
(X × Y ) −(X′ × Y ′) = [(X −X′) × Y ] ∪[(X ∩X′) × (Y −Y ′)].
Note that the union on the right side is disjoint. (Why?) Now, if X, X′ ∈M1 and
Y, Y ′ ∈M2, then X −X′ and Y −Y ′ can be represented as ﬁnite disjoint unions, say
X −X′ = Sm
i=1 Xi, Y −Y ′ = Sn
k=1 Yk, with Xi ∈M1, Yk ∈M2, and the required
decomposition of (X × Y ) −(X′ × Y ′) is obtained by Problem 17 (iii).]
§5. Mappings
We shall now consider an especially important class of relations, called map-
pings or functions. The mapping concept is a generalization of that of a func-
tion as usually given in calculus.

§5. Mappings
23
Deﬁnition 1.
A relation R is a mapping, a map, or a function iﬀthe image R[x] or
every element x ∈DR consists of a single element (in other words, every
element x ∈DR has a unique relative under R). This unique element is
denoted by R(x) and is called the function value at x. (Thus R(x) is the
unique element of R[x].)1 Equivalently, R is a mapping iﬀno two pairs
belonging to R have the same ﬁrst coordinate. (Explain!)
If, in addition, diﬀerent elements of DR have diﬀerent images, R is
called a one-to-one-mapping or a one-to-one correspondence. In this case,
x ̸= y implies R(x) ̸= R(y),
provided that x, y ∈DR. Equivalently,
R(x) = R(y) implies x = y for x, y ∈DR.
Mappings will usually be denoted by the letters f, g, h, F, ϕ, ψ, etc.
A mapping f is said to be “from A to B” if Df = A and D′
f ⊆B. In
this case we write f : A →B. If, in particular, Df = A and D′
f = B, we
say that f is a mapping of A onto B and write f : A →B
onto . If f is both
onto and one-to-one, we write f : A ↔B
onto . We shall also use expressions
like “f maps A into B” and “f maps A onto B” instead of f : A →B
and f : A →B
onto , respectively.
Since every element x ∈Df has a unique f-relative, f(x), under a mapping
f, all pairs belonging to f have the form (x, f(x)), where f(x) is the function
value at x. Therefore, in order to deﬁne a function f, it suﬃces to deﬁne its
domain Df and to indicate the function value f(x) for every x ∈Df.2 We
shall often use such deﬁnitions.
It is customary to say that a function f is deﬁned on a set A if A = Df.3
Examples.
(1) The relation R = {(x, y) | x is the wife of y} is a one-to-one map of the
set of all wives onto the set of all husbands.
Under this map, every
husband is the (unique) R-relative of his wife. The inverse relation, R−1,
is a one-to-one map of the set of all husbands onto the set of all wives.
(2) The relation f = {(x, y) | y is the father of x} is a mapping of the set of
all people onto the set of their fathers. It is not one-to-one since several
1 R(x) is often called the image of x under R if confusion with R[x] is irrelevant. Note
that R(x) is deﬁned only if x ∈DR, whereas R[x] is always deﬁned. If x /∈DR, R[x] = ∅.
2 Note, however, that it does not suﬃce to give a formula for f(x) only, without indicating
the domain Df .
3 In this connection, Df is often referred to as the domain of deﬁnition of the function,
while D′
f is called its range of values.

24
Chapter 1. Some Set Theoretical Notions
persons may have one and the same father, and thus x ̸= x′ does not
imply f(x) ̸= f(x′).
(3) Let g be the set of the four pairs (1, 2), (2, 2), (3, 3), (4, 8). Then g is
a mapping from Dg = {1, 2, 3, 4} onto D′
g = {2, 3, 8}, with g(1) = 2,
g(2) = 2, g(3) = 3, g(4) = 8. (These formulas could serve as the deﬁnition
of g.)4 It is not one-to-one since g(1) = g(2), i.e., two distinct elements
of the domain have one and the same image.
(4) Let the domain of a mapping f be the set of all integers, J, with f(x) = 2x
for every integer x. By what has been said above, f is well deﬁned. f is
one-to-one since x ̸= y implies 2x ̸= 2y. The domain of f is J; its range,
however, consists of even integers only. Thus f : J →J, but it is not onto
J. This example shows that a mapping may be one-to-one without being
onto.5
(5) The identity map (denoted I) is the set of all pairs of the form (x, x)
where x ranges over some given space (i.e., it is the set of all pairs with
equal left and right coordinates). It can also be deﬁned by the formula
I(x) = x for each x; that is, the function value at x is x itself. This map
is clearly one-to-one and onto.6
If f is a mapping, its inverse, f −1, is always a certain relation (namely, the
set of all ordered pairs inverse to those contained in f). However, this relation
may fail to be a mapping. For example, let
f =

1
2
3
4
2
3
3
8

;
then
f −1 =

2
3
3
8
1
2
3
4

.
Here f is a mapping (see Example (3)), but f −1 is not, because f −1[3] = {2, 3}
consists of two elements (not of one). On the other hand, as is easily seen, the
mappings given in Examples (1), (4), and (5) yields inverse relations that are
mappings likewise. This justiﬁes the following deﬁnition.
Deﬁnition 2.
A mapping f is said to be invertible iﬀits inverse, f −1, is a map itself.
In this case f −1 is called the inverse map or inverse function.
Equivalently,
a mapping (function) is invertible iﬀit is one-to-one.
4 As we have noted, such a deﬁnition suﬃces provided that the domain of the function is
known.
5 Note, however, that we may also regard it as a map of J onto the smaller set E of all
even integers: f : J ↔
onto E.
6 We may also consider the relation {(x, x) | x ∈A}, denoted IA, where A is a proper
subset of the given space S. Then IA : A →S is one-to-one but not onto S (it is onto A
only). IA is called the identity map on A.

§5. Mappings
25
For, if f is one-to-one, then no distinct elements of its domain can have one
and the same function value y. But this very fact means that f −1[y] cannot
consist of more than one element, i.e., that f −1 is a function.
The function value f(x) is also sometimes denoted by fx, xf, or fx. In the
latter case (called “index notation”), the domain of f is also referred to as an
index set, and the range of f is denoted by {fx}. It is convenient to regard x
in such symbols as a variable ranging over the domain of f (index set). Then
also the function value f(x) (respectively, fx, xf, or fx) becomes a variable
depending on x; we call it then the variable function value. If, in particular, Df
and D′
f are sets of real numbers, we obtain what is called a real-valued function
of a real variable. Such functions are considered in the elementary calculus.
Our function concept is, however, much more general since we consider maps
with arbitrary domains and ranges (not necessarily sets of numbers).
Note 1. We shall strictly distinguish between the function value f(x) and
the function f itself. The latter is a set of ordered pairs while the former, f(x),
is only a single (though possibly variable) element of the range of values of
f. These two notions are very often confused in elementary calculus, e.g., in
such expressions as “the function f(x) = 2x.” What is actually meant is “the
function f deﬁned by the formula f(x) = 2x.” Another correct way of express-
ing this is by saying that “f is the function that carries (or transforms) each
x ∈Df into 2x” or, brieﬂy, that “f is the map x →2x” or “f assigns to x the
value 2x,” etc.
Note 2. Mappings are also often referred to as transformations.
Note 3. If index notation is used, the range of function values D′
f, also
written as {fx}, can be regarded as a certain set of objects {fx} that are
distinguished from each other by the various values of the variable index x. We
have already encountered this notation in §2, with respect to families of sets.
As we have already mentioned, the domain and range of a function f may
be quite arbitrary sets.7
In particular, we can consider functions in which
each element of the domain is itself an ordered pair, (x, y). Such mappings
are called functions of two variables. Similarly, we speak of a function of n
variables if the domain Df of that function is a set of ordered n-tuples. To
any such n-tuple, (x1, x2, . . ., xn), the function f assigns a unique function
value, denoted by f(x1, x2, . . ., xn), provided that the n-tuple belongs to Df.
Note that each n-tuple (x1, . . ., xn) is treated as one element of Df and is
assigned only one function value. Usually (but not always) the domain Df
consists of all n-tuples that can be formed from elements of a given set A; that
is, Df = An (the Cartesian product of n sets, each equal to A). The range
may be any arbitrary set. The formula f : An →B is used to denote such a
7 These sets may even be empty. Then also f = ∅(“an empty set of ordered pairs”). Thus
∅is a mapping, with Df = D′
f = ∅.

26
Chapter 1. Some Set Theoretical Notions
function. Similarly, we write f : (A × B) →C for a function of two variables,
with Df = A × B and D′
f ⊆C, etc.
Note 4. Functions of two variables are also called (binary) operations.
When this terminology is used, we usually replace the function symbols f,
g, F, . . . by special symbols +, ·, ∪, ∩, etc., and write x + y, x · y, etc., in-
stead of f(x, y). The function value f(x, y) then is called the sum (product,
composite, etc.) of x and y.
Problems on Mappings
1. Which of the following relations, or their inverses, are mappings?
{(x, y) | y is the mother of x};
{(x, y) | x is the father of y};
{(x, y) | y is a child of x};
{(x, y) | x is a friend of y};
{(x, y) | y is the oldest son of x};
{(x, y) | x is the oldest cousin of y};
{(x, y) | x real, y = x2};
{(x, y) | y real, x = y3}.
2. Are there any mappings among the relations speciﬁed in Problems 1 and
2 of §4? Which, if any, are one-to-one? Why or why not?
3. Let f : N →N, where N is the set of all positive integers (naturals).
Specify f[N] (i.e., D′
f) and determine whether f is one-to-one and onto
given that, for all x ∈N,
(i) f(x) = |x| + 2;
(ii) f(x) = x3;
(ii) f(x) = 4x + 5;
(iv) f(x) = x2;
(v) f(x) = 1;
(vi) f(x) is the greatest common divisor of x and 15.
4. Do Problem 3 assuming that N is the set of all integers. Do cases (i)–(v)
also with N = set of all real numbers.
5. In Problems 3 and 4, ﬁnd (in all cases) f −1[A] and f[A] given that
(a) A = {x ∈N | x ≥0};
(b) A = {x ∈N | −1 ≤x ≤0};
(c) A = {x ∈N | −1 ≤x ≤4}.
6. Prove that, for any mapping f, any set A, and any x, we have x ∈f −1[A]
iﬀx ∈Df and f(x) ∈A.
7. Using the result of Problem 6, prove for any mapping f that
(i) f −1[A ∪B] = f −1[A] ∪f −1[B];
(ii) f −1[A ∩B] = f −1[A] ∩f −1[B];
(iii) f −1[A −B] = f −1[A] −f −1[B].

§5. Mappings
27
Compare this with Problem 4 of §4. In what case do these formulas hold
with “f −1” replaced by “f”? In what case are they true for both f and
f −1?
8. Generalize formulas (i) and (ii) of Problem 7 by proving them with A, B
replaced by an arbitrary family of sets, {Ai}; i.e., prove that
(i) f −1 h[
Ai
i
=
[
f −1[Ai];
(ii) f −1 h\
Ai
i
=
\
f −1[Ai].
9. If f is a mapping, show that f[f −1[A]] ⊆A and that if A ⊆D′
f, then
f[f −1[A]] = A. In what case do we have f −1[f[A]] = A? Give a proof.
10. Which (if any) of the relations ⊆and ⊇holds between the sets f[A] ∩B
and f[A ∩f −1[B]]? Give a proof.
11. The characteristic function CA of a set A in a space S is deﬁned on S
by setting CA(x) = 1 if x ∈A, and CA(x) = 0 if x /∈A. Given A ⊆S,
B ⊆S, prove the following:
(i) If A ⊆B, then CB−A(x) = CB(x) −CA(x) for x ∈S. (Brieﬂy:
CB−A = CB −CA.)
(ii) With a similar notation, we have CA∩B = CA ·CB, and if A∩B = ∅,
then CA∪B = CA + CB.
(iii) CA∪B = max(CA, CB), the larger of CA and CB.
(iv) CA + CB = CA∪B + CA∩B.
(v) A ⊆B iﬀCA ≤CB.
(vi) A = B iﬀCA = CB.
12. Use Problem 11(vi) to give another proof of the set identities speciﬁed in
the following problems of §2: 1, 2, 3, 8, 9, 14, 15.
[Hint: Use the results of Problem 11 to show that the characteristic functions of the
left and right sides of the required identities coincide.]
∗13. An ordered triple (x, y, z) can be deﬁned as an ordered pair ((x, y), z) in
which the ﬁrst coordinate is itself an ordered pair, (x, y). Accordingly,
every function f of two variables is a set of ordered triples ((x, y), z) in
which the pairs (x, y) form the domain Df of f; and, for each such pair,
z = f(x, y), so that z is uniquely determined by (x, y). Is every set T of
ordered triples a function of two variables? If not, what condition must
T satisfy? Give a proof.
[Hint: T must not contain two diﬀerent triples (x, y, z) and (x′, y′, z′) with x = x′ and
y = y′.]
∗14. Using Problem 13, investigate which of the following sets of ordered triples
are functions of two variables.
If they are, specify the function value

28
Chapter 1. Some Set Theoretical Notions
f(x, y), as well as Df and D′
f. (Below, x, y, and z denote real numbers.)
(i) f = {(x, y, z) | x < y < z};
(ii) f = {(x, y, z) | x < y = z};
(iii) f = {(x, y, z) | x = y + z};
(iv) f = {(x, y, z) | z = xy};
(v) f = {(x, y, z) | z = 1};
(vi) f = {(x, y, z) | x2 + y2 = z2}.
15. Let N be the set of all positive integers. Deﬁne a function of two variables
f : (N × N) →N by setting, for x, y ∈N,
f(x, y) = 1
2(x + y −1) · (x + y) + (1 −y).
Verify whether this function is one-to-one and onto N.
∗§6. Composition of Relations and Mappings
1
A relation R can be treated as a mechanism that transforms any given set A
into its image R[A]. If S is another relation, we can apply it to the set R[A]
to obtain its image under S, i.e., S[R[A]]. Given a third relation T, we can
apply it to the set S[R[A]] to obtain its image, T [S[R[A]]], and so on. This
process of successively applying several relations leads to the important notion
of composition of relations. Before deﬁning this notion, it is useful to prove the
following lemma.
Lemma. Two relations R and S are equal iﬀR[x] = S[x] for every element
x.
Proof. Recall that R and S are equal iﬀthey consist of exactly the same
ordered pairs, that is, iﬀ(x, y) ∈R ⇐⇒(x, y) ∈S, for all x, y. But, as was
shown in §4, this can also be written as
y ∈R[x] ⇐⇒y ∈S[x] for all x and y.
Fixing x, we see from this that, whenever some element y belongs to the set
R[x], it also belongs to S[x], and vice versa. In other words, the two sets R[x]
and S[x] consist of the same elements. Thus we have
R[x] = S[x] for every x,
as required. The converse is obtained by reversing the steps of the proof. Thus
the lemma is proved.
□
This lemma shows that a relation R is uniquely determined if the sets R[x]
are given for all x. (Indeed, if any relation has the same image sets, it must
1 This and other “starred” sections may be omitted in the ﬁrst reading of Chapter 1.
Indeed, the beginner is advised to postpone them, pending further directives.

∗§6. Composition of Relations and Mappings
29
coincide with R, by the lemma.) Therefore, a relation can be deﬁned by indi-
cating the sets R[x] for all x.2 We shall now apply this method to deﬁne the
notion of the composite relation.
Deﬁnition.
By the composite of two relations R and S, denoted R◦S or RS, we mean
the relation with images deﬁned by
(R ◦S)[x] = R[S[x]] for every x.
(1)
In other words, the image of any element x under the composite relation
R ◦S is obtained by ﬁrst taking its image under S, i.e., S[x], and then taking
the image of the set S[x] under R. Thus all images under R◦S are well deﬁned;
hence so is R ◦S. Note that formula (1) deﬁnes implicitly also the domain of
R ◦S; it consists of those x whose images under R ◦S are nonvoid.
Example.
Let
R =

1
2
3
2
3
4

,
S =

2
3
1
5

.
Then RS consists of the pair (2, 2) alone, while SR consists of (1, 1) and
(2, 5). This example shows that RS ̸= SR; that is, the composition of
relations is, in general, not commutative (even when they are mappings,
as in this example). It is, however, associative, as is shown next.
Theorem 1. For any relations R, S, T, we have (RS)T = R(ST).
Proof. By the lemma, it suﬃces to show that ((RS)T)[x] = (R(ST))[x], for
every x. But, by deﬁnition (see formula (1) above), we obtain
((RS)T) [x] = (RS) [T[x]] = R [S [T[x]]] .
Similarly, (R(ST)) [x] = R [S [T[x]]]. Thus the images coincide, as required,
and all is proved.
□
Theorem 2. For any relations R and S, we have (RS)−1 = S−1R−1.
The proof is left as an exercise (see Problem 4 below).
Theorem 3. If R and S are functions, so also is RS. In particular, if R and
S are one-to-one mappings, so is RS.
Proof. Formula (1) above shows that (RS)[x] contains at most one element
if R[S[x]] does, and this is clearly the case when S and R are mappings. The
second clause likewise follows easily from Theorem 2.
□
2 This is analogous to deﬁning a function R by indicating R(x) for all x ∈DR. In the
present case, however, it is unnecessary to specify DR because R[x], unlike R(x), is deﬁned
for all x.

30
Chapter 1. Some Set Theoretical Notions
Problems on the Composition of Relations
1. Find (RS)T, R(ST), (RT)S, and R(TS) by actual computation, if
R =

1
1
2
3
3
2
4
4

,
S =

1
2
2
5
2
2
1
3

,
T =

4
3
5
6
7
1
2
3
4
5

.
Comment on associativity and commutativity in these examples.
2. For any relation R and any positive integer n, deﬁne Rn = R ◦R ◦· · ·◦R
(n times). Using the relations R, S, T of Problem 1, ﬁnd the following:
(i) R3 ◦(R−1)3;
(ii) R2 ◦(S−1)2 ◦T;
(iii) T 2S2R−1.
Also, setting R−n = (R−1)n, ﬁnd the following:
(iv) R−2S2T −1;
(v) S−3TR−2.
3. Prove that R ◦S = {(x, y) | (∃z) xSz, zRy} = {(x, y) | y ∈R[S[x]]}.
4. Using the result of Problem 3, show that (RS)−1 = S−1 ◦R−1. State and
prove a similar formula for three relations and for n relations. Verify it
also, by actual computation, for the three relations of Problem 1.
5. Which of the properties “reﬂexive”, “symmetric”, “transitive”, and “tri-
chotomic” does the relation R possess if R ◦R ⊆R? Give a proof and
compare with Problem 10 of §4.
6. Show that, for any relations R and S, DRS ⊆DS and D′
RS ⊆D′
R. If,
further, D′
S ⊆DR, then DRS = DS. (Use Problem 3.)
7. Show that, for every mapping f : A →
onto B, we have f ◦f −1 = IB, where
IB = {(y, y) | y ∈B} (= identity map on B); if, instead, f : A →B is
one-to-one, we have f −1 ◦f = IA = {(x, x) | x ∈A} (= identity map
on A). Show by counterexamples that the second formula may fail if f is
not one-to-one, and the ﬁrst may fail if f is not onto B.
8. Let T be the family of all one-to-one maps of a set A onto itself. Prove
the following:
(i) If f, g ∈T , then f ◦g ∈T .
(ii) If f ∈T , then f −1 ∈T , and f ◦f −1 = f −1 ◦f = IA (= identity
map on A).
(iii) If f ∈T , then f ◦IA = IA ◦f = f. Note: By Theorem 1, we also
have (f ◦g) ◦h = f ◦(g ◦h) for all f, g, h ∈T . (A reader familiar
with group theory will infer from all this that T is a group.)
9. Deﬁne a map of the xy-plane into itself by
f(x, y) = (x · cos θ −y · sin θ, x · sin θ + y · cos θ)
(rotation).

∗§6. Composition of Relations and Mappings
31
Show that f is one-to-one and onto, and give a similar formula for the
mapping f −1◦g◦f, where (i) g(x, y) = (x+1, y), (ii) g(x, y) = (x+1, y+1).
Interpret geometrically.
10. Prove that a mapping f : A →B is one-to-one iﬀthere is a map g : B →A
with g ◦f = IA.
[Hint: If f is one-to-one, ﬁx some a ∈A. Then deﬁne g(y) = f −1(y) if y ∈D′
f , and
g(y) = a if y /∈D′
f .]
11. Prove that a mapping f : A →B is onto B if there is a map h: B →A
such that f ◦h = IB (= identity map on B).
Combining this with
Problem 10, infer that f is one-to-one and onto if there are two maps g,
h: B →A such that g ◦f = IA and f ◦h = IB.
[Hint: If f ◦h = IB, choose any b ∈B and ﬁnd some x ∈A such that f(x) = b. (It
suﬃces, e.g., to take x = h(b). Why?)]
12. Prove the following:
(i) f : A →B is one-to-one iﬀf ◦g = f ◦h implies g = h for all maps
g, h: B →A.
(ii) If A has at least two elements, then f : A →B is onto B iﬀg ◦f =
h ◦f implies g = h for all maps g, h: B →A.
[Hint for part (ii): If f is not onto B, ﬁx some x0, x1 ∈A (x0 ̸= x1) and deﬁne two
maps g, h: B →A, setting: (∀y ∈B) g(y) = x0; and h(y) = x0 = g(y) if y ∈D′
f ,
while h(y) = x1 if y /∈D′
f . Verify that g ◦f = h ◦f, though g ̸= h. Thus g ◦f = h ◦f
does not imply g = h if f is not onto.]
13.
A
B
C
B′
A′
C′
Figure 7
An equilateral triangle ABC (see dia-
gram) is carried into itself by these rigid
motions: clockwise rotations about its
center through 0◦, 120◦, and 240◦(call
them r0, r1, r2) and reﬂections in its
altitudes AA′, BB′, CC′ (call these re-
ﬂections ha, hb, hc, respectively). Treat
these motions as mappings of the tri-
angle onto itself, and set up for them
a composition table (i.e., compute their
mutual composites).
Thus verify that
the composite of any two of them is such a map itself; e.g., r1r2 = r0
(= the identity map); r1ha = hc; har1 = hb, etc. (Note that har1 is the
result of carrying out ﬁrst the rotation r1 and then the reﬂection ha.)
The maps r0, r1, r2, ha, hb, hc are called the symmetries of the triangle.
14. Set up and solve problems similar to 13 for
(i) the symmetries of the square (4 rotations and 4 reﬂections);
(ii) the symmetries of the rectangle (2 rotations and 2 reﬂections);

32
Chapter 1. Some Set Theoretical Notions
(iii) the symmetries of the regular pentagon (5 rotations and 5 reﬂec-
tions).
∗§7. Equivalence Relations
In mathematics, as in everyday life, it is often convenient not to distinguish
between certain objects that, however diﬀerent, serve the same purpose and
thus may be “identiﬁed” (i.e., regarded as the same) as far as this purpose is
concerned. For example, diﬀerent coins and bills of the same value may be
regarded as equivalent in all money transactions. Parallel lines may be treated
as the same in all angle measurements. Congruent ﬁgures may be “identiﬁed”
in geometry. In all such cases some relation (like parallelism or congruence)
plays the same role as equality. Such relations, called equivalence relations,
resemble equality in that they are reﬂexive, symmetric and transitive. Usually
they also have, to a certain degree, the so-called substitution property; that is,
within certain limits, equivalent objects may be substituted for each other. We
now give precise deﬁnitions.
Deﬁnition 1.
A binary relation E is called an equivalence relation on a set A if E is
reﬂexive, symmetric, and transitive on A and moreover its domain DE
and its range D′
E coincide with A.1
Equivalence relations are usually denoted by special symbols resembling
equality, such as ≡, ≈, ∼, etc.
The formula (x, y) ∈E or xEy, where E
is such a symbol, is read “x is equivalent to y,” “x is congruent with y,”
etc. Sometimes the phrase “modulo E” is added. Thus we write x ≡y, or
x ≡y (mod E), for xEy. If such a formula is true, we say that x and y are
E-equivalent, or equivalent modulo E, or, brieﬂy, equivalent.
Deﬁnition 2.
An equivalence relation E is said to have the substitution property with
respect to another relation R if xRy implies x′Ry′ whenever x ≡x′
(mod E) and y ≡y′ (mod E). In this case we also say that E is consistent
with R. In other words, consistency means that the formula xRy does not
alter its validity or nonvalidity if x and y are replaced by some equivalent
elements, x′ ≡x, and y′ ≡y.
Similarly, we say that E is consistent with an operation ◦in a set A,
or that E has the substitution property with respect to ◦, if x ◦y ≡x′ ◦y′
whenever x, x′, y, y′ ∈A, x′ ≡x, and y′ ≡y (all mod E).
1 Note that the domain DE of E must coincide with its range D′
E due to symmetry.
Explain!

∗§7. Equivalence Relations
33
The equality relation (i.e., the identity map on a set A) is itself an equivalence
relation since it is reﬂexive, symmetric, and transitive. It has the (unlimited)
substitution property since we have deﬁned it as logical identity. Other exam-
ples (such as parallelism of lines, or congruence of ﬁgures) have been mentioned
above; see also the problems below.
Deﬁnition 3.
If E is an equivalence relation on A, and if p ∈DE, we deﬁne the E-class,
or equivalence class modulo E, generated by p in A to be the set of all
those elements of A that are E-equivalent to p. Thus it is the set
{y ∈A | pEy} = E[p]
(= image of p under E).
If confusion is ruled out, we denote it simply by [p] and call it the E-class
of p (in A); p is called a generator or representative of [p].2 The family of
all E-classes, generated in A by diﬀerent elements, is called the quotient
set of A by E, denoted A/E. Note: By deﬁnition, x ∈[p] iﬀx ≡p.
Examples.
(a) If E = IA (the identity map on A), then E[x] = [p] = {p} for each p ∈A.
Thus here each E-class consists of a single element (its generator).
(b) Under the parallelism relation between straight lines, an equivalence class
consists of all lines parallel to a given line in space.
(c) Under congruence, an equivalence class consists of all ﬁgures congruent
to a given ﬁgure.
Theorem 1. If E is an equivalence relation on a set A, then we have the
following:
(i) Every element p ∈A is in some E-class; speciﬁcally, p ∈[p] ⊆A.
(ii) Two elements p, q ∈A are E-equivalent iﬀthey are in one and the same
equivalence class, i.e., iﬀ[p] = [q].
(iii) Any two E-classes in Q are either identical or disjoint.
(iv) The set A is the (disjoint) union of all E-classes.
Proof. (i) By deﬁnition, x ∈[p] iﬀx ≡p. Now, if p ∈A, reﬂexivity of E
yields p ≡p, whence p ∈[p] ⊆A, as asserted.
(ii) If p ≡q, then, by symmetry and transitivity, (∀x ∈A) p ≡x iﬀq ≡x.
This means that x ∈[p] iﬀx ∈[q], i.e., [p] = [q]. Conversely, if [p] = [q], then
part (i) yields q ∈[q] = [p], i.e., q ∈[p], when p ≡q, by the deﬁnition of [p].
2 As we shall see (Theorem 1(ii) below), any other element q ≡p is likewise a generator
of [p] because the E-classes generated by p and q coincide if q ≡p (i.e., q ∈[p]).

34
Chapter 1. Some Set Theoretical Notions
(iii) Suppose [p] ∩[q] ̸= ∅, i.e., (∃x) x ∈[p] ∩[q]. Then x ∈[p] and x ∈[q],
i.e., x ≡p ≡q, whence, by (ii), [p] = [q]. Thus [p] and [q] cannot have a
common element unless [p] = [q].
(iv) is a direct consequence of (i) and (iii). Thus all is proved.
□
Part (iv) of this theorem shows that every equivalence relation E on A
deﬁnes a partition of A into E-classes. The converse is likewise true, as we
show next.
Theorem 2. Every partition of a set A into disjoint sets Ai (i ∈I) uniquely
determines an equivalence relation E on A, such that the sets Ai are exactly
the E-classes in A.
Proof. Given A = S Ai (disj.),3 deﬁne E as the set of all pairs (x, y) such
that x and y belong to one and the same Ai. The relation E is easily shown
to be reﬂexive, symmetric and transitive on A, with DE = D′
E = A, so that E
is an equivalence relation in A (we leave the details to the reader). Moreover,
the E-classes clearly coincide with the sets Ai. Thus E has all the required
properties.
Next, let E′ be another equivalence relation on A, with the same properties,
and take any p ∈A. Then, by assumption, E[p] = Ai, where Ai is the partition
set that contains p; also, E′[p] = Ai for the same i.
It follows that (∀p)
E[p] = E′[p], and this implies that E = E′ (by the lemma of §6). Thus any
two such E and E′ must coincide, i.e., E is unique.
□
We see that there is a close connection between all equivalence relations on
A and all partitions of A: Every equivalence relation deﬁnes (or, as we shall say,
induces) a partition, and vice versa. Note that the quotient set A/E is exactly
the family of the disjoint sets Ai whose union equals A, i.e., the family of the
disjoint equivalence classes, under the equivalence relation E that corresponds
to a given partition.
Now we can give a more exact mathematical interpretation to the procedure
of “identifying” equivalent elements (see introductory remarks to this section).
This procedure applies whenever an equivalence relation E is consistent with
some operation or relation R, so that the substitution property holds with
respect to R. Then, as far as R is concerned, equivalent elements behave as
if they were identical, so that they may be treated as “copies” of one element.
We achieve actual identity if we replace each element p of the set A by the
equivalence class [p] generated by p. Indeed, then, all E-equivalent elements
are replaced by one and the same equivalence class and thus become one thing.
Thus, from the mathematical point of view, the “identiﬁcation” of equivalent
elements amounts to replacing the set A by the quotient set A/E. In what
follows, we shall often speak of “identifying” certain objects. The reader should,
3 We use this notation to indicate that A is the union of disjoint sets Ai(i ∈I).

∗§7. Equivalence Relations
35
however, be aware of the fact that what is meant is actually the procedure
outlined here, i.e., the replacement of A by the quotient set A/E.
Problems on Equivalence Relations
1. Prove in detail that the relation E deﬁned in the proof of Theorem 2 is
reﬂexive, symmetric, and transitive on A and that DE = D′
E = A.
2. Which of the following relations on the set J of all integers are equivalence
relations? If so, describe the E-classes, i.e., J/E.
(i) E = {(x, y) | x, y ∈J; and x −y is divisible by a ﬁxed n ∈J};
(ii) E = {(x, y) | x, y ∈J; x −y is odd};
iii) E = {(x, y) | x, y ∈J; and x −y is a prime}.
3. Are the equivalence relations of Problem 2 consistent with the addition,
multiplication, and inequality relation (<) deﬁned in J?
Problems 4–10 are of theoretical importance for the construction of the rational
number system from natural numbers (including 0), i.e., nonnegative integers.
4. Let N be the set of all integers ≥0, so that N ×N is the set of all ordered
pairs of nonnegative integers. Assuming the arithmetic of such integers to
be known, let (x, y)E(p, q) mean that x+q = y +p, and let (x, y) < (p, q)
mean that x + q < y + p, where x, y, p, q ∈N. Without ever using
subtraction or minus signs, show that E is an equivalence relation on
N × N, consistent with <. (Write ≡for E.) Also show that the relation
< is transitive and “quasi-trichotomic”; i.e., we have either
(x, y) < (p, q) or (p, q) < (x, y) or (x, y) ≡(p, q),
but never two of these together.
5. Continuing Problem 4, deﬁne addition and multiplication in N × N, set-
ting
(x, y) + (p, q) = (x + p, y + q)
and
(x, y) · (p, q) = (xp + yq, yp + xq).
Show that E is consistent with these operations. Also verify the following
laws:
(i) If (x, y) and (p, q) belong to N × N, so do their sum and product.
(ii) (x, y) + (p, q) ≡(p, q) + (x, y); (x, y) · (p, q) ≡(p, q) · (x, y).
(iii) {(x, y) + (p, q)} + (r, s) ≡(x, y) + {(p, q) + (r, s)}, and similarly for
multiplication:
{(x, y) · (p, q)} · (r, s) ≡(x, y) · {(p, q) · (r, s)}.

36
Chapter 1. Some Set Theoretical Notions
(iv) (x, y) + (0, 0) ≡(x, y); (x, y) · (1, 0) ≡(x, y).
(v) (x, y) + (y, x) ≡(0, 0). (Hence we may write −(x, y) for (y, x).)
(vi) (x, y) · {(p, q) + (r, s)} ≡(x, y) · (p, q) + (x, y) · (r, s).
(vii) If (p, q) < (r, s) then (p, q) + (x, y) < (r, s) + (x, y). Similarly for
multiplication, provided, however, that (0, 0) < (x, y).
Observe that (x, y) < (0, 0) iﬀx < y (verify!); we call the pair (x, y)
“negative” in this case. Show that (x, y) < (0, 0) iﬀ−(x, y) > (0, 0).
6. The laws proved in Problems 4 and 5 show that ordered pairs (x, y) in
N × N, with inequalities and operations deﬁned as above, “behave” like
integers (positive, negative and 0) except that equality “=” is replaced by
“≡”. To avoid the latter we pass to equivalence classes. Let [x, y] denote
the E-class of the pair (x, y). Deﬁne addition and multiplication of such
E-classes by
[x, y] + [p, q] = [x + p, y + q],
[x, y] · [p, q] = [xp + yq, yp + xq].
Using the consistency of E (proved in Problem 5), show that these deﬁni-
tions are nonambiguous; i.e., the sum and product remain the same also
when x, y, p, q are replaced by some x′, y′, p′, q′ such that (x, y) ≡(x′, y′)
and (p, q) ≡(p′, q′). Then show that the laws (ii)–(vi) are valid for E-
classes of the pairs involved, with all equivalence signs “≡” turning into
“=”.
7. Continuing Problems 4–6, deﬁne [x, y] < [p, q] to mean that (x, y) < (p, q),
as in Problem 4.
Show that this is unambiguous, i.e., the inequality
holds also if (x, y) or (p, q) is replaced by an equivalent pair.
Verify
that Problem 5(vii), as well as the transitivity and “trichotomy” laws of
Problem 4, hold for E-classes, with “≡” replaced by “=”. (We now deﬁne
“integers” to be the equivalence classes [x, y].)
8. Let J be the set of all integers (positive or not), and let Q be the set of
all ordered pairs (x, y) ∈J × J, with y > 0. Assuming the arithmetic
of integers to be known, let (x, y)E(p, q) mean that xq = yp, and let
(x, y) < (p, q) mean that xq < yp, for (x, y) and (p, q) in Q. Without
using division or fraction signs, answer the questions of Problem 4, with
N × N replaced by Q. (Subtraction and minus signs are now permitted.)
9. In Problem 8, show that E is consistent with addition and multiplication
deﬁned in Q as follows:
(x, y) + (p, q) = (xq + yp, qy) and (x, y) · (p, q) = (xp, yq).
For such sums and products, establish the laws of Problem 5, with (iv)
and (v) replaced by
(iv′) (x, y) + (0, 1) ≡(x, y) ≡(x, y) · (1, 1);

∗§7. Equivalence Relations
37
(v′) (x, y) + (−x, y) ≡(0, 1);
(v′′) if x > 0, then (x, y) · (y, x) ≡(1, 1); and
(v′′′) if x < 0, then (x, y) · (−y, −x) ≡(1, 1).
Observe that pairs (x, y) ∈Q behave like fractions x/y in ordinary arith-
metic (with “=” replaced by “≡” here).
10. Continuing Problems 8 and 9, let [x, y] denote the E-class of the pair
(x, y) ∈Q, with E as in Problem 8. For such E-classes, deﬁne inequalities,
addition and multiplication as for pairs in Problems 8 and 9, replacing
(x, y) by [x, y]. Verify that these deﬁnitions are unambiguous, i.e., inde-
pendent of the particular choice of the “representative pairs” (x, y) and
(p, q) from the E-classes [x, y] and [p, q] (use the consistency properties of
E). Verify that all laws proved in Problems 8 and 9 hold also for E-classes
(with “≡” now turning into “=”).
Note. Problems 4–10 show how, starting with nonnegative integers,
one can construct ﬁrst a system N × N and then a system Q that (on
passage to suitable equivalence classes) behave exactly like integers and
rational numbers, respectively.
This is how integers and rationals are
constructed from nonnegative integers, in precise mathematics.
11. A reader acquainted with group theory will verify that, if A is a group,
and B its subgroup, then each of the following relations is an equivalence
relation on A (we use multiplicative notation):
(i) E = {(x, y) | x, y ∈A, x−1y ∈B};
(ii) E = {(x, y) | x, y ∈A, yx−1 ∈B}.
Also show that if the group operation is commutative (i.e., xy = yx) then
in both cases E is consistent with that operation.
§8. Sequences
One of the basic notions of analysis is that of a sequence (inﬁnite or ﬁnite).
It is closely connected with the theory of mappings and sets. Therefore we
consider it here, even though it involves the notion of integers, to be formally
introduced in Chapter 2, along with real numbers.
Deﬁnition 1.
By an inﬁnite sequence we mean a mapping (call it u) whose domain
Du consists of all positive integers 1, 2, 3, . . . (it may also contain 0).
A ﬁnite sequence is a mapping u in which Du consists of positive (or
nonnegative) integers less than some ﬁxed integer p. The range D′
u may
consist of arbitrary objects (numbers, points, lines, sets, books, etc.).

38
Chapter 1. Some Set Theoretical Notions
Note 1. In a wider sense, one may speak of “sequences” in which Du also
contains some negative integers, or excludes some positive integers. We shall
not need this more general notion.
Note that a sequence, being a mapping, is a set of ordered pairs. For exam-
ple,
u =

1
2
3
. . .
n
. . .
2
4
6
. . .
2n
. . .

(1)
is an inﬁnite sequence, with Du = {1, 2, 3, . . . }; its range D′
u consists of the
function’s values
u(1) = 2, u(2) = 4, u(3) = 6, . . ., u(n) = 2n, n = 1, 2, . . . .
Instead of u(n), we usually write un (“index notation”), and call un the n-th
term of the sequence. If n is treated as a variable, un is called the general term
of u, and {un} is used to denote the entire sequence, as well as its range D′
u.
The formula {un} ⊆B means that D′
u is contained in a set B; we then call
u a sequence of elements of B, or a sequence from B, or in B. To uniquely
determine a sequence u, it suﬃces to deﬁne its general term (by some formula
or rule) for every n ∈Du. In Example (1) above, un = 2n.
Since the domain of a sequence is known to consist of integers, we often
omit it and give only the range D′
u, specifying the terms un in the order of
their indices n. Thus, instead of (1), we brieﬂy write 2, 4, 6, . . . , 2n, . . . or,
more generally, u1, u2, . . . , un, . . ., along with the still shorter notation {un}.
Nevertheless, whatever the notation, the sequence u (a set of ordered pairs)
should not be confused with D′
u (the set of single terms un).
A sequence need not be a one-to-one mapping; it may have equal (“re-
peating”) terms: um = un (m ̸= n). For instance, in the inﬁnite sequence
1, 1, . . . , 1, . . . , with general term un = 1, all terms are equal to 1, so that
its range D′
u has only one element, D′
u = {1}. Nevertheless, by Deﬁnition 1,
the sequence itself is inﬁnite. This becomes apparent if we write it out in full
notation:
u =

1
2
3
. . .
n
. . .
1
1
1
. . .
1
. . .

.
(2)
Indeed, it is now clear that Du contains all positive integers 1, 2, 3, . . . , and u
itself contains inﬁnitely many pairs (n, 1), n = 1, 2, . . . , even though D′
u = {1}.
Sequences in which all terms are equal are referred to as constant or stationary.
In sequences (1) and (2) we were able to deﬁne the general term by means
of a formula: un = 2n or un = 1. This is not always possible. For example,
nobody has yet succeeded in ﬁnding a formula expressing the general term of
the sequence
1, 2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, . . .
(3)

§8. Sequences
39
of so-called prime numbers (i.e., integers with no positive divisors except 1 and
themselves).1 Nevertheless, this sequence is well deﬁned since its terms can be
obtained step by step: start with all positive integers, 1, 2, 3, . . .; then remove
from them all multiples of 2 except 2 itself; from the remaining set remove all
multiples of 3 except 3 itself, etc., ad inﬁnitum. After the ﬁrst step, we are left
with
1, 2, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, . . . ;
after the second step, we obtain
1, 2, 3, 5, 7, 11, 13, 17, 19, 23, 25, . . . ,
and so on, gradually obtaining (3).
Other cases of such “step-by-step” deﬁnitions (also called algorithmic or
inductive deﬁnitions) will occur in the later work. In general, a sequence is
regarded as well deﬁned if some formula (or formulas) or rule has been given
that makes it possible to ﬁnd all terms of the sequence, either directly or
by some “step-by-step” or other procedure.
One should carefully avoid the
misconception that, if several terms in a sequence conform to some law or
formula, then the same law applies to all the other terms. For instance, if only
the ﬁrst three terms of (3) were given, it would be wrong to conclude that the
sequence is necessarily 1, 2, 3, 4, 5, . . . , n, . . . , with general term un = n. Thus
an inﬁnite set can never be deﬁned by giving a ﬁnite number of terms only;
in this case one can only make a “plausible” guess as to the intended general
term. Moreover, one may well think of sequences in which the terms have been
chosen “at random,” without any particular law. Such a “law” may, but need
not, exist.
As noted above, the terms of a sequence need not be numbers; they may
be arbitrary objects. In particular, we shall often consider sequences of sets:
A1, A2, . . . , An, . . . , where each term An is a set (treated as one thing). The
following deﬁnitions will be useful in the later work.
Deﬁnition 2.
A sequence of sets {An}, n = 1, 2, . . . , is said to be expanding iﬀeach
term An is a subset of the next term An+1, i.e.,
An ⊆An+1,
n = 1, 2, . . .
(except if An is the last term in a ﬁnite sequence).
The sequence {An} is contracting iﬀ
An ⊇An+1,
n = 1, 2, . . .
1 For our purposes it is convenient to include 1 in this sequence, though usually 1 is not
regarded as a prime number.

40
Chapter 1. Some Set Theoretical Notions
(with the same remark). In both cases, {An} is called a monotonic, or
monotone, set sequence.
This deﬁnition imitates a similar deﬁnition for number sequences:
Deﬁnition 3.
A sequence of real numbers {un}, n = 1, 2, . . . , is said to be monotonic or
monotone iﬀit is either nondecreasing (i.e., un ≤un+1) or nonincreasing
(i.e., un ≥un+1) for all terms. Notation: {un}↑and {un}↓.
If the strict inequalities, un < nn+1 (un > un+1, respectively) hold,
the sequence is said to be strictly monotonic (increasing or decreasing).
Note 2. Sometimes we say “strictly increasing” (or “strictly decreasing”)
in the latter case.
For example, the sequences (1) and (3) above are strictly increasing. Se-
quence (2) (and any constant number sequence) is monotonic, but not strictly
so; it is both nondecreasing and nonincreasing. Any sequence of concentric
discs in a plane, with increasing radii, is an expanding sequence of sets (we
treat each disc as the set of all points inside its circumference). If the radii
decrease, we obtain a contracting sequence.
By a subsequence of a sequence {un} is meant (roughly speaking) any se-
quence obtained by dropping some terms from {un}, without changing the order
of the remaining terms, which then form the subsequence. More precisely, to
obtain a subsequence, we must prescribe the terms that are supposed to remain
in it. This is best done by indicating the subscripts of these terms. Note that
all such subscripts necessarily form an increasing sequence of integers:
n1 < n2 < n3 < · · · < nk < · · · .
If these subscripts are given, they uniquely determine the corresponding terms
of the subsequence:
un1, un2, un3, . . .
with general term (or k-th term)
unk,
k = 1, 2, . . . .
The subsequence is brieﬂy denoted by {unk}; in special cases, also other nota-
tions are used. Thus we have the following.
Deﬁnition 4.
Let {un} be any sequence, and let {nk} be a strictly increasing sequence
of integers from Du. Then the sequence {unk}, with k-th term equal to
unk, is called the subsequence of {un}, determined by the sequence of
subscripts {nk} ⊆Du, k = 1, 2, 3, . . . .

§8. Sequences
41
For example, let us select from (3) the subsequence of terms with subscripts
2, 4, 6, . . . , 2k, . . .
(i.e., consisting of the 2nd, 4th, 6th, . . . , 2k-th, . . . terms of (3)). We obtain
2, 5, 11, 17, 23, 31, 41, . . . .
If, instead, the terms
u1, u3, u5, . . . , u2k−1, . . .
were selected, we would obtain the subsequence
1, 3, 7, 19, 29, 37, . . . .
The ﬁrst subsequence could brieﬂy be denoted by {u2k} (here nk = 2k); the
second subsequence is {u2k−1}, nk = 2k −1, k = 1, 2, . . . .
Observe that, in every sequence u, the integers belonging to its domain
Du are used to “number” the terms of u, i.e., the elements of the range D′
u;
e.g., u1 is the ﬁrst term, u2 the second, and so on. This procedure is actually
well known from everyday life: by numbering the buildings in a street or the
books in a library, we put them in a certain order or sequence. The question
now arises: given a set A, is it always possible to “number” its elements by
integers? More precisely, is there a sequence {un}, ﬁnite or inﬁnite, such that
A is contained in its range:
A ⊆D′
u = {u1, u2, . . . , un, . . . }?
As we shall see later, this question must, in general, be answered in the negative;
the set A may be so large that even all integers are too few to number its
elements. At this stage we only formulate the following deﬁnition.
Deﬁnition 5.
A set A is said to be countable iﬀA is contained in the range of some
sequence (brieﬂy: “A can be put in a sequence”).
If, in particular, this sequence can be chosen ﬁnite, we call A a ﬁnite set
(∅is ﬁnite, since ∅⊆D′
u always). Thus all ﬁnite sets are countable.
Sets that are not ﬁnite are called inﬁnite.
Sets that are not countable are called uncountable.
A ﬁnite set A is said to have exactly n elements iﬀit is the range of a
sequence of n distinct terms; i.e., the range of a one-to-one map u with domain
Du = {1, 2, . . ., n}. The simplest example of an inﬁnite countable set is N =
{1, 2, . . . }.

42
Chapter 1. Some Set Theoretical Notions
Problems on Sequences
1. Find the ﬁrst six terms of the sequence of numbers with general term:
(a) un = 2;
(b) um = (−1)m;
(c) un = n2 −1;
(d) um = −m/(m + 1).
2. Find a suitable formula, or formulas, for the general term of a sequence
that starts with
(a) 2, 5, 10, 17, 26, . . . ;
(b) 2, −2, 2, −2, 2, . . . ;
(c) 2, −2, −6, −10, −14, . . . ;
(d) 1, 1, −1, −1, 1, 1, −1, −1, . . . ;
(e) 3 · 2
1 , 4 · 6
4 , 5 · 10
9
, 6 · 14
16 , . . . ;
(f)
1
2 · 3, −8
3 · 4,
27
4 · 5, −64
5 · 6, 125
6 · 7, . . . .
3. Which of the sequences in Problems 1 and 2 are monotonic or constant?
Which have ﬁnite ranges (even though the sequences are inﬁnite)?
4. Find the general term of the sequence obtained from {un} by dropping
(a) the ﬁrst term;
(b) the ﬁrst two terms;
(c) the ﬁrst p terms.
5. (Lagrange interpolation formula.) Given the ﬁrst p terms a1, . . . , ap of a
number sequence, let f(n, k) be the product of the p −1 numbers
n −1, n −2, . . . , n −(k −1), n −(k + 1), . . . , n −p
(excluding n −k), for n = 1, 2, . . . , and k = 1, 2, . . . , p.
Setting bk = f(k, k), verify that bk ̸= 0 and that, for n = 1, 2, . . . , p,
we have
an = a1f(n, 1)/b1 + a2f(n, 2)/b2 + · · · + apf(n, p)/bp.
(*)
Thus (*) is a suitable formula for the general term of the sequence. Using
it, ﬁnd new answers to Problem 2(a)–(d), thus showing that there are
many “plausible” answers to the questions posed.
6. Find the general term un of the number sequence deﬁned inductively2 by
(i) u1 = a, un+1 = un + d, n = 1, 2, . . . (arithmetic sequence; a, d
ﬁxed);
(ii) u1 = a, un+1 = unq, n = 1, 2, . . . (geometric sequence; a, q ﬁxed);
(iii) s1 = u1, sn+1 = sn + un+1, with un as in case (i); same for (ii);
2 Problems 6–8 may be postponed until induction and other properties of natural numbers
have been studied in more detail (Chapter 2, §§5–6).

§8. Sequences
43
(iv) u1 = a, u2 = b, un+2 = 1
2(un+1 + un), n = 1, 2, . . . (a, b ﬁxed).
[Hint: un+2 = u3 + (u4 −u3) + (u5 −u4) + · · · + (un+2 −un+1), where u3 =
1
2 (a + b). Show that the bracketed terms (uk+1 −uk) form a geometric series
with ratio 1
2 , and compute its sum.]
7. Show that if a number sequence {un} has no largest term, then it has a
strictly increasing inﬁnite subsequence {unk}.
[Hint: Deﬁne unk step by step. Let un1 = u1. Then let n2 be the least subscript
such that un2 > un1 (why does such un2 exist?). Next take the least n3 such that
un3 > un2, and so on.]
∗8. Let {un} be an inﬁnite sequence of real numbers. By dropping from it
the ﬁrst k terms, we get a subsequence uk+1, uk+2, . . . , uk+n, . . . (call it
the “k-subsequence”). Show that if every k-subsequence (k = 1, 2, 3, . . . )
has a largest term (call it qk, for a given k), then the original sequence
{un} has a nonincreasing subsequence formed from all such qk-terms.
[Hint: Show that qk ≥qk+1, k = 1, 2, . . . , i.e., the maximum term qk cannot increase
as the number k of the dropped terms increases. Note that {un} may have several
terms equal to qk for a given k; choose the one with the least subscript inside the given
k-subsequence.]
∗9. From Problems 7 and 8 infer that every inﬁnite sequence of real numbers
{un} has an inﬁnite monotonic subsequence.
[Hint: There are two possible cases:
(i) either every k-subsequence (as described in Problem 8) has a largest term, or
(ii) some k-subsequence has no largest term (then apply to it the result of Problem 7
to obtain an increasing subsequence of it and hence of {un}).]
10. How many ﬁnite sequences of p terms, i.e., with domain {1, 2, . . . , p},
can one form, given that the range of the sequences is a ﬁxed set of m
elements?
11. Let {An} be an inﬁnite sequence of sets. For each n, let
Bn =
n
[
k=1
Ak,
Cn =
n
\
k=1
Ak,
Dn =
∞
\
k=n
Ak,
En =
∞
[
k=n
Ak.
Show that the sequences {Bn} and {Dn} are expanding, while {Cn} and
{En} are contracting.
∗12. Given a sequence of sets {An}, n = 1, 2, . . . , we deﬁne
lim An =
∞
\
n=1
∞
[
k=n
Ak and lim An =
∞
[
n=1
∞
\
k=n
Ak
and call these sets the upper limit and the lower limit of the sequence
{An}, respectively. If they coincide, the sequence is said to be convergent,

44
Chapter 1. Some Set Theoretical Notions
and we put
lim An = lim An = lim An
(= limit of An).
Prove the following:
(i) T∞
n=1 An ⊆lim An ⊆lim An ⊆S∞
n=1 An.
(ii) If An ⊆Bn, n = 1, 2, . . . , then
lim An ⊆lim Bn and lim An ⊆lim Bn.
(iii) Every monotonic sequence of sets is convergent, with lim An =
T∞
n=1 An if {An} is contracting, and lim An = S∞
n=1 An if {An}
is expanding.
∗13. Continuing Problem 12, prove the following:
(i) E −lim An = lim(E −An) and E −lim An = lim(E −An) for any
set E.
(ii) lim(An∩Bn) = lim An∩lim Bn and lim(An∪Bn) = lim An∪lim Bn.
(iii) lim(An∪Bn) ⊇lim An∪lim Bn and lim(An∩Bn) ⊆lim An∩lim Bn.
Investigate whether inclusion signs can be replaced by equality if one
or both sequences are convergent.
∗14. Continuing Problem 12, prove the following:
(i) If the sets An are mutually disjoint, then lim An = lim An = ∅.
(ii) If An = A for all n, then lim An = lim An = A.
(iii) {An} converges iﬀfor no x are there inﬁnitely many n with x ∈An
and inﬁnitely many n with x /∈An.
∗§9. Some Theorems on Countable Sets
We now derive some consequences of Deﬁnition 5 of §8.
Theorem 1. If a set A is countable or ﬁnite, so also is any subset B ⊆A,
and so is the image f[A] of A under any mapping f.
Proof. If A ⊆D′
u for a sequence u (ﬁnite or not), then certainly B ⊆A ⊆D′
u.
Thus B can be put in the same sequence, proving our ﬁrst assertion.
Next, let f be any map, and suppose ﬁrst that Df ⊇A. We may assume that
A ﬁlls a sequence (if not, drop some terms); say, A = {u1, u2, . . . , un, . . . }.
Then f[A] consists exactly of the function values f(u1), f(u2), . . ., f(un), . . . .
But this very fact shows that f[A] can be put in a sequence {vn}, with general
term vn = f(un). Thus f[A] is countable (ﬁnite if A is), as claimed. The case
A ⊈Df is treated in Problem 1 below. Thus all is proved.
□

∗§9. Some Theorems on Countable Sets
45
Theorem 2. If a set A is uncountable, so also is any set B ⊇A, and so is
f[A] under any one-to-one map f, with Df ⊇A. (Similarly for inﬁnite sets.)
Proof. The set B ⊇A cannot be countable or ﬁnite. Otherwise, its subset A
would have the same property, by Theorem 1, contrary to assumption.
Next, if f is one-to-one, so is its inverse, f −1. If further A ⊆Df, then
A = f −1[f[A]] by Problem 9 of §5. Now, if f[A] were countable or ﬁnite then,
by Theorem 1, so would be its image under any map, such as f −1. Thus the
set f −1[f[A]] = A would be countable or ﬁnite, contrary to assumption.
□
Corollary 1. If all terms of an inﬁnite sequence u are distinct (diﬀerent from
each other), then its range is an inﬁnite, though countable, set.
Proof. By assumption, u is a one-to-one map (its terms being distinct), with
Du = N = {1, 2, . . . }. The range of u is the u-image of its domain N, i.e., u[N].
Now, as N is inﬁnite,1 so also is u[N] by Theorem 2.
□
Theorem 3. If the sets A and B are both countable, so is A × B.
Proof. If A or B is empty, then A × B = ∅, and all is proved.
Thus let A and B be nonempty. As before, we may assume that they ﬁll
two sequences, A = {an} and B = {bm}. For convenience, we also assume that
these sequences are inﬁnite (if not, repeat some terms). Then, by deﬁnition,
A × B is the set of all ordered pairs of the form (an, bm), where n and m take
on independently the values 1, 2, . . . . Call n+m the rank of the pair (an, bm).
The only pair of rank 2 is (a1, b1). Of rank 3 are (a1, b2) and (a2, b1). More
generally,
(a1, br−1), (a2, br−2), . . . , (ar−1, b1)
(1)
are the r −1 pairs of rank r.
We now put all pairs (an, bm) in one sequence as follows. We start with
(a1, b1); then take the two pairs of rank 3; then the three pairs of rank 4, and
so on. At the (r −1)-th step, we take all pairs of rank r in the order shown in
(1). Continuing this process for all ranks ad inﬁnitum, we obtain the sequence
of pairs
(a1, b1), (a1, b2), (a2, b1), (a1, b3), (a2, b2), . . . .
By construction, this sequence contains all pairs of any rank, hence all pairs
that form the set A × B (for every such pair has some rank r; so it must occur
in the sequence). Thus A × B is put in a sequence.
□
As an application, consider the set Q of all positive rationals, i.e., fractions
n/m where n and m are naturals. Let n + m be called the rank of n/m, where
n/m is written in lowest terms. By the same process (writing the fractions in
1 A proof of this fact will be suggested in Chapter 2, §6, Problem 15.

46
Chapter 1. Some Set Theoretical Notions
the order of their ranks), we put Q in an inﬁnite sequence of distinct terms:
1/1, 1/2, 2/1, 1/3, 3/1, 1/4, 2/3, 3/2, . . . .
Hence we obtain the following.
Corollary 2. The set R of all rational numbers is countable.
Indeed, we only have to insert the negative rationals and 0 in the above
sequence, as follows:
0, 1, −1, 1
2, −1
2, 2, −2, 1
3, −1
3, 3, −3, . . . .
A similar “ranking” method also yields the following result.
Theorem 4. The union of any sequence of countable sets {An} is countable.
Proof. We must show that A = S
n An can be put in one sequence. Now, as
each An is countable, we may set
An = {an1, an2, . . . , anm, . . . },
where the double subscripts are to distinguish the sequences representing dif-
ferent sets An. As before, we may assume that all sequences are inﬁnite.
Clearly S An consists of the elements of all An combined, i.e., of all anm
(n, m ∈N). Call n + m the rank of the term anm. Proceed as in Theorem 3
to obtain
A =
[
An = {a11, a12, a21, a13, a22, a31, . . . }.
Thus A can be put in a sequence.
□
Note 1. Theorem 4 is brieﬂy stated as “Any countable union of countable
sets is countable” (“countable union” means “union of a countable family of
sets,” i.e., one that can be put in a ﬁnite or inﬁnite sequence {An}).
Note 2. In particular, Theorem 4 applies to ﬁnite unions. Thus, if A and
B are countable sets, so is A ∪B. (So also are A ∩B and A −B since they are
subsets of the countable set A; see Theorem 1.)
In the proof of Theorem 4, we see a set A whose elements anm carried two
subscripts. To any pair (n, m) of such subscripts there corresponds a unique
element anm of A. Thus we can deﬁne a function u (of two variables, n and
m) by setting
u(n, m) = anm,
n, m ∈N.
Its domain is the set N × N of all pairs (m, n) of positive (or nonnegative)
integers. Such a function is called an inﬁnite double sequence, brieﬂy denoted
by {unm}. Its range D′
u may consist of arbitrary objects, namely the function
values u(n, m), brieﬂy unm.
Exactly as in Theorem 4, we obtain the following result.

∗§9. Some Theorems on Countable Sets
47
Corollary 3. The range of any double sequence {unm} is a countable set.
To show that uncountable sets exist also, we shall now prove the uncount-
ability of the interval [0, 1), i.e., the set of all reals x such that 0 ≤x < 1.
We assume as known that each real x ∈[0, 1) has a unique inﬁnite decimal
expansion 0.x1x2 . . . xn . . ., where the xn are the decimal digits, possibly zeros,
and the sequence {xn} does not terminate in nines (e.g., instead of 0.4999. . .,
we write 0.50000. . .). This fact is proved in Chapter 2, §13.
Theorem 5. The interval [0, 1) of the real axis is uncountable.
Proof. We must show that no sequence can comprise all of [0, 1).
Indeed, take any sequence {un} from [0, 1). Write each term un as an inﬁnite
decimal fraction; say, un = 0.an1an2 . . . anm . . . . Then construct a new decimal
fraction z = 0.x1x2 . . . xn . . . , choosing the digits xn as follows.
If ann (i.e., the nth digit of un) is 0, take xn = 1; otherwise, take xn = 0.
Thus, in all cases, xn ̸= ann, i.e., z diﬀers from each un in at least one decimal
digit (namely the nth digit). It follows that z diﬀers from all un and hence is
not in the sequence {un}, even though z ∈[0, 1). Thus, no matter what the
choice of {un} was, we found some z ∈[0, 1), not in the range of that sequence.
Hence no {un} contains all of [0, 1).
□
Note 3. Observe that the members ann used in that proof form the “diag-
onal” of the indeﬁnitely extending square consisting of all ann:
a11
a12
a13
. . .. . .
a1n
. . .
a21
a22
a23
. . .. . .
a2n
. . .
a31
a32
a33
. . .. . .
a3n
. . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
an1
an2
an3
. . .. . .
ann
. . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Therefore the method used above is called the diagonal process (due to
Cantor).
Now, by Corollary 2, all rationals can be put in a sequence. But, as shown
above, no such sequence can cover all of [0, 1). Thus [0, 1) must contain num-
bers that are not rational, i.e., cannot be written as ratios of integers, n/m.
Moreover, such numbers, called irrational, must form an uncountable set, for
otherwise its union with the countable set of all rationals in [0, 1) would be
countable (by Note 2), whereas actually this union is the uncountable set [0, 1).
The same argument applies to any other line interval with endpoints a and
b (a < b), since any such interval is uncountable (see Problem 2). Thus we
have the following.
Corollary 4. Between any two real numbers a and b (a < b) there are un-
countably many irrational numbers.

48
Chapter 1. Some Set Theoretical Notions
Note 4. By Theorem 2, any superset of [0, 1) is uncountable. In particular,
so is the entire set of real numbers (the real axis).
We thus see that the irrationals form an uncountable set. In this sense, there
are many more irrationals than rationals. Both sets are inﬁnite. Thus there
are diﬀerent kinds of “inﬁnities”.
Problems on Countable and Uncountable Sets
1. Show that Theorem 1 holds also if A ⊈Df.
[Hint: Deﬁne a new map g on A∪Df by g(x) = f(x) if x ∈Df and g(x) = x if x /∈Df .
Noting that Dg ⊇A, infer from what was already proved that g[A] is countable, and
hence so is f[A] (why?).]
2. Let a and b be real numbers, a < b. Deﬁne a mapping f on [0, 1) by
setting f(x) = a + x(b −a). Show that f is one-to-one and that it is onto
[a, b). Then, from Theorems 2 and 5, infer that [a, b) is uncountable.
3. Show that if B is countable but A is not, then A −B is uncountable.
[Hint: If A −B were countable, so would be (A −B) ∪B ⊇A.]
4. Show that every inﬁnite set A contains a countable inﬁnite set.
[Hint: Fix any element x1 ∈A; A cannot consist of x1 alone (why?), so there is
another element x2 ∈A −{x1}. Again, A ̸= {x1, x2} (why?), so there is an element
x3 ∈A −{x1, x2}, and so on. Proceeding step by step, we select from A an inﬁnite
sequence {xn} of distinct terms. Then C = {x1, x2, . . . , xn, . . . } is the required subset
of A. (A reader acquainted with axiomatic set theory will observe that this proof uses
the so-called axiom of choice.)]
5. Infer from Problem 4 that if A is inﬁnite, then there is a mapping f : A →
A that is one-to-one but not onto A.
[Hint: Choose C = {x1, x2, . . . , xn . . . } as in Problem 4. Then deﬁne f as follows: If
x ∈A −C, then f(x) = x; if, however, x = xn for some n, then f(x) = f(xn) = xx+1.
Observe that never f(x) = x1, and so f is not onto A.
Verify however that f is
one-to-one.]
6. Let f : A →B be a one-to-one map such that B ⊂A, and let x1 ∈A−B.
Inductively (step by step) deﬁne an inﬁnite sequence:
x2 = f(x1), x3 = f(x2), . . . , xn+1 = f(xn), . . . , n = 1, 2, . . . .
Observe that all xn except x1 are in B (why?), and so xn ̸= x1, n =
2, 3, . . . . Show that all xn are distinct (i.e., diﬀerent from each other)
and hence B is an inﬁnite set by Corollary 1.
[Hint: Seeking a contradiction, suppose there is an n such that xn = xm for some
m > n, and take the least such n. Then n −1 does not have this property, and so
xn−1 ̸= xm for all m > n −1. As f is one-to-one, we get f(xn−1) ̸= f(xm), i.e.,
xn ̸= xm+1, for all m > n −1 (contradiction!).]
Combining this with Problem 5, infer that a set A is inﬁnite iﬀthere is
a map f : A →A that is one-to-one but not onto A.

∗§9. Some Theorems on Countable Sets
49
7. Using the result of Problem 6, show that the number n of elements in a
ﬁnite set A is uniquely determined. More precisely, if A = the range of a
sequence u of distinct terms with Du = {1, 2, . . ., n}, it is not the range
of any sequence v with Dv = {1, 2, . . ., m}, m ̸= n.
[Hint: Suppose this is the case, with m < n, say. Then show that the composite map
u · v−1 is one-to-one (by Theorem 2 of §6) but not onto A, though its domain is A.
Infer that A is inﬁnite (contradiction!).]

Chapter 2
The Real Number System
§1. Introduction
Historically, the real number system is the result of a long gradual develop-
ment that started with positive integers (“natural numbers”) 1, 2, 3, . . . , later
followed by the invention of the rational numbers (i.e., fractions p/q where p
and q are integers); it was completed by the discovery of irrational numbers.
It is possible to reproduce this gradual development also in exact theory, that
is, to build up the real number system step by step from natural numbers. At
this stage, however, we shall assume the set of all real numbers as already given,
without attempting to reduce the notion of real number to simpler concepts.
Also without deﬁnition (i.e., as so-called primitive concepts) shall we introduce
the notions of the sum (a + b) and the product, (a · b) or (ab), of two real
numbers a and b, as well as the inequality relation < (read: “less than”). The
set of all real numbers taken together will be denoted by E1 (read: “E one”).
The formula “x ∈E1” means that x is in E1, i.e., x is a real number.
Thus our primitive concepts are E1 (set of all reals), + (plus sign), · (mul-
tiplication sign), and < (inequality sign).
Remark. Every mathematical theory must start with certain concepts ac-
cepted as primitive (i.e., without deﬁnition), since it is impossible to deﬁne
all terms used. Indeed, any deﬁnition can only explain some terms by means
of others. If the latter, too, were to be deﬁned, new deﬁning terms would be
needed, and this process would never end. It is often only a matter of con-
vention, which notions to accept as the ﬁrst (i.e., the primitive) ones. Once,
however, the choice has been made, all other notions should be deﬁned in terms
of the primitive ones. Similarly, it is impossible to prove all statements of a
deductive theory. Certain propositions (called axioms) must be accepted as
the ﬁrst ones, without proof. Once, however, the axioms have been stated, all
the following propositions (called theorems) must be proved, i.e., deduced in a
strictly logical way from the axioms. This procedure characterizes every exact
deductive science.

§1. Introduction
51
We now proceed to state a system of axioms for real numbers. The ﬁrst
nine axioms will be given in §2 (for a reason to be explained later, they will be
called “axioms of an ordered ﬁeld”). The last (10th) axiom will be formulated
in a later section.
§2. Axioms of an Ordered Field
We shall assume as axioms (i.e., without proof) the following simple properties
of real numbers. (The reader is certainly familiar with these properties from
school algebra, where they are often regarded as “obvious”, so that it might
seem superﬂuous to mention them. We must, however, state them as axioms
in accordance with our introductory remarks made in §1. Each axiom has a
name given in parenthesis.)
A. Axioms of addition and multiplication.
I (Closure law) The sum x + y and the product xy of any two real numbers
x and y are themselves real numbers. In symbols:
(∀x, y ∈E1)
(x + y) ∈E1, (xy) ∈E1.
II (Commutative laws) (∀x, y ∈E1) x + y = y + x, xy = yx.
III (Associative laws) (∀x, y, z ∈E1) (x+y)+z = x+(y +z), (xy)z = x(yz).
IV (Existence of neutral elements)
(a) There exists a (unique) real number, called “zero” (0), such that,
for all real x, x + 0 = x.
(b) There exists a (unique) real number, called “one” (1), such that
1 ̸= 0 and, for all real x, x · 1 = x. In symbols:
(∃! 0 ∈E1) (∀x ∈E1)
x + 0 = x,
(∃! 1 ∈E1) (∀x ∈E1)
x · 1 = x,
1 ̸= 0.
The numbers 0 and 1 are called the neutral elements of addition and
multiplication, respectively.
V (Existence of inverses)
(a) For every real number x, there is a (unique) real number, denoted
−x, such that x + (−x) = 0.
(b) For every real number x, other than 0, there is a (unique) real num-
ber denoted x−1, such that x · x−1 = 1. In symbols:
(∀x ∈E1) (∃! −x ∈E1)
x + (−x) = 0,
(∀x ∈E1 | x ̸= 0) (∃! x−1 ∈E1)
x · x−1 = 1.

52
Chapter 2. The Real Number System
The numbers −x and x−1 are called, respectively, the additive inverse (or
the symmetric) and the multiplicative inverse (or the reciprocal) of x.
VI (Distributive law) (∀x, y, z ∈E1) (x + y)z = xz + yz.
Note. The uniqueness assertions in Axioms IV and V could actually be
omitted since they can be proved from other axioms.
B. Axioms of order.
VII (Trichotomy) For any real numbers x and y, we have either x < y or
y < x or x = y, but never two of these relations together.
VIII (Transitivity) If x, y, z are real numbers, with x < y and y < z, then
x < z. In symbols:
(∀x, y, z ∈E1)
x < y < z implies x < z.
IX (Monotonicity of addition and multiplication)
(a) (∀x, y, z ∈E1) x < y implies x + z < y + z.
(b) (∀x, y, z ∈E1) x < y and 0 < z implies xz < yz.
Note 1. As has already been mentioned, one additional (10th) axiom will
be stated later.
Note 2. While every real number has an additive inverse (Axiom V(a)),
only nonzero numbers have reciprocals. The number 0 has no reciprocal. (Ax-
iom V(b).)
Note 3. Note the restriction 0 < z in Axiom IX(b). It is easy to see that
without this restriction the axiom would be false. For example, we have 2 < 3,
but 2(−1) is not less than 3(−1). No such restriction occurs in Axiom IX(a).
Due to the introduction of inequalities “<” and the Axioms VII–IX, the
real numbers may be regarded as given in some deﬁnite order, under which
smaller numbers precede the larger ones.
(This is why Axioms VII–IX are
called “axioms of order”.) We express this fact brieﬂy by saying that E1 is an
ordered set. More precisely, an ordered set is a set in which a certain relation
“<” has been deﬁned in such a manner that the trichotomy and transitivity
laws are satisﬁed.
The ordering of real numbers can be visualized by “plotting” them as points
on a directed line (“the real axis”), as shown below in Figure 8:
−2
−1 1
2
−1
−1
2
0
1
2
1
2
Figure 8

§2. Axioms of an Ordered Field
53
Therefore, real numbers are also often referred to as “points” of the real
axis. We say, e.g., “the point x” instead of “the number x.” We assume that the
reader is familiar with this process of geometric representation of real numbers.
We shall not dwell on its justiﬁcation since it will only be used as illustration,
not as proof.
It should be noted that the axioms only specify certain properties of real
numbers without indicating what these numbers actually are. This question is
left entirely open, so that we may regard real numbers as just any mathematical
objects that are only supposed to satisfy our axioms but otherwise are entirely
arbitrary. This makes our theory more general. Indeed, our theory also applies
to any other set of objects (numbers or not numbers), provided only that they
satisfy our axioms with respect to a certain relation of order (<) and certain
operations (+) and (·), which may, but need not, coincide with ordinary number
addition and multiplication. Whatever follows logically from the axioms must
be true not only for real numbers but also for any other set that conforms with
these axioms. In this connection, we introduce the following deﬁnitions.
Deﬁnition 1.
A ﬁeld F is any set of objects with two operations (+) and (·) (usually
called “addition” and “multiplication”) deﬁned in it, provided that these
objects and operations satisfy the ﬁrst six axioms (I–VI) listed above.
If this set is also equipped with an order relation (<) satisfying the
additional three axioms VII–IX, it is called an ordered ﬁeld.
In particular, the real number system E1 is an ordered ﬁeld. Of course,
when speaking of ordered ﬁelds in general, the term “real number” in the
axioms should be replaced by “element of F.” Similarly, 0 and 1 should
be interpreted as elements of the ﬁeld satisfying Axiom IV(a) and (b),
but not necessarily as ordinary numbers.
E1 is not the only ordered ﬁeld known in mathematics. Indeed, many ex-
amples of ordered and unordered ﬁelds are studied in higher algebra. We shall
encounter some of them later.
As has been mentioned, everything that can be deduced from Axioms I–
IX applies not only to E1 but also to any other ordered ﬁeld F (since F is
supposed to satisfy these axioms). Therefore, we shall henceforth formulate our
deﬁnitions and theorems in a more general way, speaking of “ordered ﬁelds” in
general instead of E1 alone. Of course, whatever we say about ordered ﬁelds
applies in particular to E1, and this particular example should be always kept
in mind.
Deﬁnition 2.
An element x of an ordered ﬁeld F is said to be positive or negative
according as x > 0 or x < 0. The element 0 itself is neither positive nor
negative.

54
Chapter 2. The Real Number System
Here and henceforth “x > y” means the same as “y < x”. We also write
“x ≤y” for “x < y or x = y”; similarly for x ≥y.
The numbers 0 and 1 have been introduced in Axiom IV, but we do not
yet “oﬃcially” know what such symbols as 2, 3, 4, . . . , etc. mean, since they
have not yet been deﬁned. Indeed, we have only introduced the notion of real
number, but not that of natural number (or integer). Therefore, in our system,
the latter must be deﬁned in terms of our primitive concepts. Since, however,
addition is already known, we can use it to deﬁne positive integers step by step,
as follows:
2 = 1 + 1, 3 = 2 + 1, 4 = 3 + 1, 5 = 4 + 1, etc.
If this process is continued indeﬁnitely, we obtain what is called the set of all
“positive integers” (or “natural numbers”). We may say that a natural number
is one that can be obtained from 0 by adding to it 1 a ﬁnite number of times.
A similar process is, of course, possible not only in E1 but in any ﬁeld. Thus
we may speak of “natural elements” in any ﬁeld.
This may serve as a preliminary deﬁnition of natural numbers. A more exact
deﬁnition will be given in §5.
Deﬁnition 3.
Given several elements a, b, c, d of a ﬁeld F, we deﬁne
a + b + c = (a + b) + c, a + b + c + d = (a + b + c) + d, etc.
Similarly for multiplication.
§3. Arithmetic Operations in a Field
All arithmetic properties of real numbers can be deduced from the axioms
stated in §2. We shall dwell on only some of these properties to illustrate the
method of proving them. In this section we shall investigate inferences of the
ﬁrst six axioms, which hold in every (even unordered) ﬁeld F.
Deﬁnition 1.
Given two elements x and y of a ﬁeld F, we deﬁne their diﬀerence,
x −y = x + (−y).
In other words, to subtract an element y means to add its additive inverse,
−y.
If y ̸= 0, we also deﬁne the quotient of x by y,
x
y = x · (y−1),

§3. Arithmetic Operations in a Field
55
also denoted by x/y. In other words, to divide x by y means to multiply
x by the reciprocal of y (provided that y−1 exists, i.e., that y ̸= 0).
In this way we have deﬁned two new operations: subtraction (i.e., formation
of diﬀerences) and division (i.e., formation of quotients). Note: Division by
0 is undeﬁned, hence inadmissible. Since subtraction and division have been
deﬁned as special cases of addition and multiplication, respectively, we can
apply to them our axioms to obtain the following corollaries.
Corollary 1. The diﬀerence x −y and the quotient x/y (where y ̸= 0) of two
real numbers x and y are themselves real numbers. (Similarly for diﬀerences
and quotients of ﬁeld elements in general.)
In symbols:
(∀x, y ∈E1)
(x −y) ∈E1, (x/y) ∈E1 (the latter if y ̸= 0).
Corollary 2. If a, b, c are elements of a ﬁeld F, with a = b, then
a + c = b + c and ac = bc.
(In other words, we may add one and the same element c to both sides of an
equation a = b; similarly for multiplication.)
In symbols:
(∀a, b, c ∈F)
a = b implies a + c = b + c and ac = bc.
Proof. By properties of equality, we obviously have a + c = a + c (since the
left side is the same as the right side). Now, as a = b, we may replace a by b on
the right side. This yields a + c = b + c, as required. Similarly for ac = bc.
□
The converse to this corollary is the following.
Corollary 3 (Cancellation law). If a, b, c are elements of a ﬁeld F, then
a + c = b + c implies a = b.
If , further, c ̸= 0, then
ac = bc implies a = b.
(In other words, we may cancel a summand and a nonzero factor on both sides
of an equation.)
Proof. Let a + c = b + c. By Corollary 2, we may add (−c) on both sides of
this equation to get
(a + c) + (−c) = (b + c) + (−c),
or, by associativity (Axiom III),
a + [c + (−c)] = b + [c + (−c)].

56
Chapter 2. The Real Number System
As c + (−c) = 0 (by Axiom V), we obtain a + 0 = b + 0, i.e., a = b (by
Axiom IV); similarly for multiplication.
□
Theorem 1. Given two elements, a and b, of a ﬁeld F, there always exists a
unique element x such that a + x = b; this element equals the diﬀerence b −a.
(Thus a + x = b means that x = b −a.)
If , further, a ̸= 0, there also is a unique element y ∈F, with ay = b; this
element equals the quotient b/a. (Thus ay = b, a ̸= 0, means that y = b/a.)
In symbols:
(∀a, b ∈F) (∃! x, y ∈F)
a + x = b,
ay = b (the latter if a ̸= 0).
We prove only the ﬁrst part of the theorem, leaving the second (which is
proved in the same way) to the reader.
It is easily checked that the equation a + x = b is satisﬁed by x = b −a. In
fact, we have (using commutativity, associativity, and Axioms IV and V)
a + x = a + (b −a) = (b −a) + a = [b + (−a)] + a = b + [(−a) + a] = b + 0 = b.
Thus the equation a + x = b has at least one solution for x, namely x =
b −a. To prove that this solution is unique, suppose that we have still another
solution, x′, say. Then we obtain a+x = b and a+x′ = b, so that a+x = a+x′,
or x + a = x′ + a. Cancelling a (by Corollary 3), we see that x = x′, so that
the two solutions necessarily coincide.
Thus both the existence and uniqueness of the solution have been proved.
Theorem 1 shows that subtraction and division are inverse operations with
respect to addition and multiplication. It can also be interpreted as a rule for
transferring a summand or a factor from one side of an equation to the other.
Corollary 4. For any element x of a ﬁeld F, we have 0−x = −x. If , further,
x ̸= 0, then 1/x = x−1.
In fact, we have, by deﬁnition,
0 −x = 0 + (−x) = −x
(Axiom IV).
Similarly,
1/x = 1 · x−1 = x−1.
Corollary 5. For any element x of a ﬁeld F, we have
x · 0 = 0 · x = 0.
(Hence we never have 0 · x = 1; this is why 0 cannot have a multiplicative
inverse.)
In fact, by distributivity (Axiom VI) and by Axiom IV, we get
0x + 0x = (0 + 0)x = 0x = 0 + 0x.

§3. Arithmetic Operations in a Field
57
Thus 0x+0x = 0+0x. Cancelling 0x on both sides (Corollary 3), we obtain
0 · x = 0, and by commutativity, also x · 0 = 0.
Corollary 6 (Rule of signs). For any elements a, b of a ﬁeld F, we have
(i) a(−b) = (−a)b = −(a · b);
(ii) −(−a) = a;
(iii) (−a)(−b) = ab.
Proof. Formula (i) means that a(−b), and similarly (−a)b, equals the additive
inverse of ab. Therefore, to prove its ﬁrst part, we have to show that a(−b) +
ab = 0 (for, this is the deﬁnition of the additive inverse). But, by distributivity,
we have
a(−b) + ab = a[(−b) + b] = a · 0 = 0
(by Corollary 5), as required.
Similarly we show that (−a)b = −(ab) and that −(−a) = a.
Finally, (iii) is obtained from (i) when a is replaced by (−a). Thus all is
proved.
□
§4. Inequalities in an Ordered Field. Absolute Values
As further examples of applications of our axioms, we now proceed to deduce
some corollaries to Axioms VI–IX. They apply to any ordered ﬁeld.
Corollary 1. If x is a positive element of an ordered ﬁeld F, then −x is
negative; and if x is negative, then −x is positive.
Proof. Given x > 0, we may add (−x) on both sides, by Axiom IX. Then we
obtain
x + (−x) > 0 + (−x), i.e., 0 > −x,
as required. Similarly, it is shown that x < 0 implies −x > 0.
□
Corollary 2 (Addition and multiplication of inequalities). If a, b, x, y are
elements of an ordered ﬁeld F, such that a < b and x < y, then
a + x < b + y
(i.e., we may always add two inequalities).
If , further, a, b, x, y are positive, then a < b and x < y implies ax < by
(i.e., the inequalities may be multiplied).
Proof. Both parts of the corollary are proved in a similar way, so we prove
only the second part.

58
Chapter 2. The Real Number System
Suppose that a < b, and x < y, with a, b, x, y positive. Then, multiplying
the ﬁrst inequality by x and the second by b (Axiom IX(b)), we have
ax < bx and bx < by.
Hence, by transitivity, ax < bx < by, i.e., ax < by, as required.
□
Note 1. Multiplication of inequalities may fail if the numbers involved are
not positive. For example, we have −2 < 3 and −2 < 1, but multiplication
would lead to a false result: 4 < 3. (However, it suﬃces that only b and x in
Corollary 2 be positive.)
Corollary 3. All nonzero elements of an ordered ﬁeld have positive squares.
That is, if a ̸= 0, then a2 = a · a > 0. (Hence 1 = 12 > 0.)
Proof. As a ̸= 0, we have, by trichotomy, either a > 0 or a < 0.
If a > 0, then we may multiply by a, obtaining a · a > 0 · a = 0, i.e., a2 > 0.
If a < 0, then, by Corollary 1, −a > 0; so we may multiply the inequality
a < 0 by (−a), using again Axiom IX(b). We then obtain
a(−a) < 0 · (−a) = 0, i.e., −a2 < 0, whence a2 > 0, as required.
□
Deﬁnition.
Given an element x of an ordered ﬁeld F, we deﬁne its absolute value,
denoted |x|, as follows:
If x ≥0, then |x| = x; if , however, x < 0, then |x| = −x.
In particular, |0| = 0. It follows that |x| is always nonnegative. In fact, if
x ≥0, then |x| = x ≥0; and if x < 0, then by Corollary 1, −x > 0; and here
−x = |x| > 0. Moreover, we always have
−|x| ≤x ≤|x|.
(1)
For, if x ≥0, then |x| = x by deﬁnition, and −|x| = −x ≤0 ≤x. If, however,
x < 0, then |x| > x since |x| is positive, while x is negative and x = −|x|. Thus
(1) holds in both cases.
Corollary 4. For any elements x and y of an ordered ﬁeld F, we have |x| < y
iﬀ−y < x < y.
Proof. Suppose ﬁrst that |x| < y. Then, by formula (1), we have x ≤|x| < y,
whence x < y. It remains to prove that −y < x. This is certainly true if x
is nonnegative (for −y is negative here). If, however, x is negative, then by
deﬁnition, −x = |x|, whence −x < y (for |x| < y, by assumption); that is,
−y < x. Thus, in all cases, |x| < y implies −y < x < y.
The converse is proved in a similar way, by distinguishing the two cases:
x ≥0 and x < 0. The details are left to the reader.
□

§4. Inequalities in an Ordered Field. Absolute Values
59
Note 2. This corollary has a simple geometric interpretation. Namely, if x
is plotted on the real axis, then |x| is its (undirected) distance from the origin
0. Thus the formulas |x| < y and −y < x < y express both the fact that this
distance is < y.
Corollary 5. For any elements a and b of an ordered ﬁeld F, we have
|ab| = |a| · |b|.
If further b ̸= 0, then
|a|
|b| =
a
b
 .
For the proof, consider the four possible cases:
(1) a ≥0, b ≥0; (2) a ≥0, b < 0; (3) a < 0, b ≥0; and (4) a < 0, b < 0.
The result then easily follows by the deﬁnition of absolute value.
Corollary 6. For any elements a and b of an ordered ﬁeld F, we have
(i) |a + b| ≤|a| + |b|;
(ii)
|a| −|b|
 ≤|a −b|.
(These are the so-called triangle inequalities.)
Inequality (i) can be proved by considering the four cases speciﬁed in the
proof of Corollary 5, but it is much simpler to use Corollary 4. Indeed, by
formula (1) on page 58, we have
−|a| ≤a ≤|a| and −|b| ≤b ≤|b|.
Adding, we obtain
−(|a| + |b|) ≤a + b ≤|a| + |b|.
But by Corollary 4, with x = a + b and y = |a| + |b|, this means that |a + b| ≤
|a| + |b|, as required.
To prove (ii), let x = a −b. By part (i), |x + b| ≤|x| + |b|, i.e.,
|(a −b) + b| ≤|a −b| + |b|,
whence |a| ≤|a −b| + |b|, or
|a| −|b| ≤|a −b|.
Interchanging a and b, we also have |b| −|a| ≤|a −b|, and (ii) follows.
Corollary 7. Given any two elements a and b (a < b) of an ordered ﬁeld F,
there always is an element x ∈F such that a < x < b. (This element is said to
lie between a and b.)
This important proposition is often expressed by saying that every ordered
ﬁeld (in particular, E1) is densely ordered. More generally, an ordered set F

60
Chapter 2. The Real Number System
is said to be densely ordered if it has the property expressed in Corollary 7. In
this connection, Corollary 7 will be referred to as the density property of real
numbers, or the density of an ordered ﬁeld.
Proof. It suﬃces to take
x = 1
2(a + b).
Then Axiom II easily yields a < x < b. The details are left to the reader.
□
Note 3. Corollary 7 shows that, given a real number a, there never exists
a number “closest” or “next” to a. In fact, if b were such a number, then by
Corollary 7, one could ﬁnd a number x (a < x < b) still closer to a.
Note 4. Having found one number, say x1, between a and b, we can again
apply Corollary 7 to ﬁnd a number x2 between x1 and b, then again a number x3
between x2 and b, and so on. Since this process can be continued indeﬁnitely,
Corollary 7 may be strengthened to say that there are inﬁnitely many real
numbers between any two given numbers a and b; similarly for ordered ﬁelds
in general.
As previously noted, the propositions proved in §§3 and 4 are only examples
illustrating the deduction of arithmetic rules from axioms. Other such examples
are given in problems below. We shall use them freely later.
These problems are to be treated as logical exercises, with the purpose of
ﬁnding out which particular axioms are needed in each case. From the theoreti-
cal point of view, this is important in its own right. Practically, one might think
of a computer programmed to deduce the rules of arithmetic purely mechan-
ically from certain axioms. The computer does not “know” anything but the
rules that have been fed into it. Even such “obvious” formulas as “2 + 2 = 4”
the computer will have to deduce from axioms and deﬁnitions, as for example,
2 + 2 = 2 + (1 + 1)
(deﬁnition of “2”)
= (2 + 1) + 1
(associativity of addition)
= 3 + 1
(deﬁnition of “3”)
= 4
(deﬁnition of “4”).
Conclusion: To enable the computer to prove that 2+2 = 4, one must “feed”
into it at least the associative law of addition and the deﬁnitions of 2, 3, 4.
The main thing in such exercises is not to “jump” some axiom or deﬁnition
(otherwise the computer will get “stuck”); use only one at a time! Do not omit
parentheses in such expressions as (a+b)+c without mentioning the deﬁnition
of a+b+c. Caution: The commutative laws were stated for two elements only;
such formulas as abc = bac, i.e., (ab)c = (ba)c, must be proved.

§4. Inequalities in an Ordered Field. Absolute Values
61
Problems on Arithmetic Operations
and Inequalities in a Field
1. Supply the missing details (in particular, those “left to the reader”) in
the proofs of all corollaries stated in §§3 and 4.
2. Using the “preliminary deﬁnition” of natural numbers, deduce from our
axioms that
(a) 2 + 3 = 5;
(b) 3 + 4 = 7;
(c) 2 · 2 = 4;
(d) 3 · 2 = 6.
Name the axioms used at each step (e.g., “associativity of addition,” etc.).
3. Deduce from axioms, step by step, that in any ﬁeld F we have the fol-
lowing:
(i) abcd = cbad = dacb; similarly for addition.
(ii) If x ̸= 0 and y ̸= 0, then xy ̸= 0.
[Hint: If xy were zero, then multiplication by y−1 would yield x = 0, contrary
to our assumption.]
(iii) (xy)−1 = x−1y−1, provided that x ̸= 0 and y ̸= 0. Why must one
assume that neither x nor y are zero?
[Hint: Proceed as in the proof of Corollary 6 of §3.]
(iv) If x ̸= 0, y ̸= 0 and z ̸= 0, then (xyz)−1 = x−1y−1z−1.
(v) If x ̸= 0 and y ̸= 0, then
a
x · b
y = ab
xy
and
a
x + b
y = ay + bx
xy
.
[Hint: By deﬁnition, a/x = ax−1, b/y = by−1, etc.
Use axioms, previous
corollaries, and the result of Problem 3(iii).]
(vi) (a + b)(x + y) = ax + bx + ay + by;
(vi′) (a + b)2 = a2 + 2ab + b2.
(vii) (a + b)(x −y) = ax + bx −ay −by;
(vii′) (a + b)(a −b) = a2 −b2.
In all cases, arrange the proof in such a manner that, at each step, only
one axiom, one deﬁnition or one previous corollary is used, and name it
(except for the closure law, which is used at each step). Only Axioms I–VI
may be used since F is not necessarily an ordered ﬁeld.
4. Continuing Problem 3 (with the same directives), use Deﬁnition 3 of §2
to show that
(a + b + c)x = ax + bx + cx and (a + b + c + d)x = ax + bx + cx + dx;
similarly for a sum of 5 terms (ﬁrst deﬁne it!).

62
Chapter 2. The Real Number System
5. In the same manner as in Problem 3, prove the following for ordered
ﬁelds:
(i) If x > 0, then also x−1 > 0.
(ii) If x > y > z > u, then x > u.
(iii) If x > y ≥0, then
x2 > y2 and x3 > y3 ≥0
(where x3 = x2x);
similarly,
x4 > y4 ≥0
(where x4 = x3x).
Which (if any) of these propositions remain valid also if x or y is
negative? Give proof.
(iv) If x > y > 0, then 1/x < 1/y. What if x < 0 or y < 0?
(v) |a + b + c| ≤|a| + |b| + |c| and |a + b + c + d| ≤|a| + |b| + |c| + |d|.
§5. Natural Numbers. Induction
At the end of §2, we showed how to select from E1 the natural numbers
1, 2, 3, . . ., starting with 1 and then adding 1 to each preceding number to
get the following one. This process also applies to any other ﬁeld F; the ele-
ments so selected are called the natural elements of F, and the set of all such
elements (obtained by continuing the process indeﬁnitely) is denoted by N.
Note that, by this construction, we always have n + 1 ∈N if n ∈N.
∗A more precise approach to natural elements is as follows.1 A subset S of
a ﬁeld F is called inductive iﬀ
(i) 1 ∈S (S contains the unity element of F) and
(ii) (∀x ∈S) x + 1 ∈S (S contains x + 1 whenever x is in S).2
Deﬁne N to be the intersection of all such subsets. We then obtain the follow-
ing.
∗Theorem 1. The set N so deﬁned is inductive itself .
In fact, it is the
“smallest” inductive set in F (i.e., contained in any other such set).
Proof. We have to show that, with our new deﬁnition,
(i) 1 ∈N and
1 The beginner may omit all “starred” passages and simply assume Theorems 1′ and 2′
below as additional axioms without proof.
2 Such subsets do exist; e.g., the entire ﬁeld F is inductive since 1 ∈F and (∀x ∈F ) x+1 ∈
F , by the closure law.

§5. Natural Numbers. Induction
63
(ii) (∀x ∈N) x + 1 ∈N.
Now, by deﬁnition, the unity 1 is in each inductive set; hence it also belongs
to the intersection of such sets, i.e., to N. Thus 1 ∈N, as claimed.
Next, take any x ∈N. Then, by our new deﬁnition of N, x is in every
inductive set S. Hence, by property (ii) of such sets, also x + 1 is in every such
S; thus x + 1 is in the intersection of all inductive sets, i.e., x + 1 ∈N, and so
N is inductive, indeed.
Finally, by deﬁnition, N is the common part of all such sets, hence contained
in each.
□
For applications, Theorem 1 is usually expressed as follows.
Theorem 1′ (First induction law). A proposition P(n) involving a natural n
holds for all n ∈N in a ﬁeld F if
(i) it holds for n = 1 [P(1) is true]; and
(ii) whenever P(n) holds for n = m, it holds for n = m + 1; [P(m)
=⇒
P(m + 1)].
∗Proof. Let S be the set of all those n ∈N for which P(n) is true; that
is, S = {n ∈N | P(n)}. We must show that actually each n ∈N is in S,
i.e., N ⊆S.
First, we show that S is inductive. By our assumption (i), P(1) is true, so
1 ∈S.
Next, suppose x ∈S. This means that P(x) is true. But by assumption (ii),
this implies P(x + 1), i.e., x + 1 ∈S. Thus (∀x ∈S) x + 1 ∈S and 1 ∈S; so
S is inductive. But then, by Theorem 1 (second clause), N ⊆S.
□
This theorem is widely used to prove general propositions on natural ele-
ments, as follows. In order to show that some formula or proposition P(n) is
true for every natural n, we ﬁrst verify P(1), i.e., show that P(n) holds for
n = 1. We then show that
(∀m ∈N)
P(m) =⇒P(m + 1);
that is, if P(n) holds for some value n = m, then it also holds for n = m + 1.
Once these two facts are established, Theorem 1′ ensures that P(n) holds for
all natural n.
Proofs of this kind are called inductive, or proofs by induction. Note that
every such proof consists of two steps:
(i) P(1)
and
(ii) P(m) =⇒P(m + 1).
Special caution must be applied in step (ii).
Here we temporarily assume
that P(n) has already been veriﬁed for some particular (but unspeciﬁed) value

64
Chapter 2. The Real Number System
n = m.3 From this assumption, we then try to deduce that P(n) holds for
n = m + 1 as well. This fact must be proved; it would be a bad error to simply
substitute m + 1 for m in the assumed formula P(m) since it was assumed for
a particular value m, not for m + 1. The following examples illustrate this
procedure.4
Examples.
(A) If m and n are natural elements, so are m + n and mn. To prove it,
ﬁx any m ∈N. Let P(n) mean that m + n ∈N. We now verify the
following:
(i) P(1) is true; for m ∈N is given. Hence, by the very deﬁnition of
N, m + 1 ∈N. But this means exactly that P(n) holds for n = 1,
i.e., P(1) is true.
(ii) P(k) =⇒P(k+1) (here we use a diﬀerent letter, k, since m is ﬁxed
already). Suppose that P(n) holds for some particular n = k. This
means that m+k ∈N. Hence, by the deﬁnition of N, (m+k)+1 ∈
N; or, by associativity, m + (k + 1) ∈N. But this means exactly
that P(k +1) is true (if P(k) is). Thus, indeed, P(k) =⇒P(k +1).
Since (i) and (ii) have been established, induction is complete;
that is, Theorem 1′ shows that P(n) holds for each n ∈N, and this
means that m+n ∈N. As m and n are arbitrary naturals, our ﬁrst
assertion is proved.5
To show that mn ∈N also, we now let P(n) mean that mn ∈N
(for a ﬁxed m ∈N) and proceed similarly. We leave this to the
reader.
(B) If n ∈N, then n −1 = 0 or n −1 ∈N. Indeed, let P(n) mean that
n −1 = 0 or n −1 ∈N (one of the two is required). We again verify the
two steps:
(i) P(1) is true; for if n = 1, then n −1 = 1 −1 = 0. Thus one of the
two desired alternatives, namely n −1 = 0, holds if n = 1. Hence
P(1) is true.
(ii) P(m) =⇒P(m+1). Suppose P(n) holds for some particular value
n = m (inductive hypothesis). This means that either m −1 = 0 or
m −1 ∈N.
In the ﬁrst case, we have (m −1) + 1 = 0 + 1 = 1 ∈N. But
(m−1)+1 = (m+1)−1 by associativity and commutativity (verify!).
Thus (m + 1) −1 ∈N.
3 This temporary assumption is called the inductive hypothesis.
4 Actually, these examples are basic theorems on naturals, to be well noted.
5 Note the technique we applied here. Faced with two variables m and n, we ﬁxed m and
carried out the induction on n. This is a common procedure.

§5. Natural Numbers. Induction
65
In the second case, m −1 ∈N implies (m −1) + 1 ∈N by the
very deﬁnition of N. Thus, in both cases, (m+1) −1 ∈N, and this
shows that P(m + 1) is true if P(m) is.
As (i) and (ii) have been established, induction is complete.
(C) In an ordered ﬁeld, all naturals are ≥1. Indeed, let P(n) now mean that
n ≥1. As before, we again carry out the two inductive steps.
(i) P(1) holds; for if n = 1, then certainly n ≥1; so P(n) holds for
n = 1.
(ii) P(m) =⇒P(m+1). We make the inductive hypothesis that P(m)
holds for some particular m. This means that m ≥1. Hence, by
monotonicity of addition and transitivity (Axioms II and VIII), we
have m + 1 ≥1 + 1 > 1 (the latter follows by adding 1 on both
sides of 1 > 0). Thus m + 1 > 1 and certainly m + 1 ≥1, that is,
P(m + 1) holds (if P(m) does). Induction is complete.
(D) In an ordered ﬁeld, m, n ∈N and m > n implies m −n ∈N. Indeed,
ﬁxing an arbitrary m ∈N, let P(n) mean “m −n ≤0 or m −n ∈N.”
Then we have the following:
(i) P(1) is true; for if n = 1, then m−n = m−1. But, by Example (B),
m −1 = 0 or m −1 ∈N. This shows that P(n) holds for n = 1;
P(1) is true.
(ii) P(k) =⇒P(k+1). Suppose P(k) holds for some particular k ∈N.
This means that
m −k ≤0 or m −k ∈N.
By Example (B), it easily follows that either
(m −k) −1 ≤0 or (m −k) −1 ∈N;
that is,
either m −(k + 1) ≤0 or m −(k + 1) ∈N.
But this shows that P(k + 1) holds (if P(k) does). By induction,
then, P(n) holds for every n ∈N; that is,
either m −n ≤0 or m −n ∈N for every n ∈N.
Lemma. For no naturals m, n in an ordered ﬁeld is m < n < m + 1.
For, by Example (D), n > m would imply n −m ∈N, hence n −m ≥1 (by
Example (C)). But n −m ≥1, or n ≥m+1, excludes n < m+1 (trichotomy).
Thus m < n < m + 1 is impossible for naturals.

66
Chapter 2. The Real Number System
Theorem 2. In an ordered ﬁeld, every nonempty subset of N (the naturals)
has a least element, i.e., one not exceeding any other of its members.6
∗Proof. Given ∅̸= A ⊆N, we want to show that A has a least element. To
do this, let
An = {x ∈A | x ≤n}
n = 1, 2 . . . .
That is, An consists of those elements of A that are ≤n (An may be empty).
Now let P(n) mean
“either An = ∅or An has a least element.”
(1)
We show by induction that P(n) holds for each n ∈N. Indeed, we have the
following:
(i) P(1) is true; for, by construction, A1 consists of all naturals from A that
are ≤1 (if any). But, by Example (C), the only such natural is 1. Thus A1, if
not empty, consists of 1 alone, and so 1 is also its least member. We see that
either A1 = ∅or A1 has a least element; i.e., P(1) is true.
(ii) P(m) =⇒P(m + 1). Suppose P(m) holds for some particular m. This
means that Am = ∅or Am has a least element (call it m0). In the latter case,
m0 is also the least member of Am+1; for, by the lemma, Am+1 diﬀers from
Am by the element m + 1 at most, which is greater than all members of Am.
If, however, Am = ∅, then for the same reason, Am+1 (if ̸= ∅) consists of
m + 1 alone; so m + 1 is also its least element.
This shows that P(m + 1) is true (if P(m) is). Thus the inductive proof is
complete, and (1) holds for every An.
Now, by assumption, A ̸= ∅; so we ﬁx some n ∈A. Then the set
An = {x ∈A | x ≤n}
contains n, and hence An ̸= ∅. Thus by (1), An must have a least element m0,
m0 ≤n. But A diﬀers from An only by elements > n (if any), which are all
> m0. Thus m0 is the desired least element of A as well.
□
Theorem 2 yields a new form of the induction law for ordered ﬁelds.
Theorem 2′ (Second induction law). A proposition P(n) holds for each nat-
ural n in an ordered ﬁeld if
(i′) P(1) holds, and
(ii′) whenever P(n) holds for all naturals n less than some m ∈N, it also
holds for n = m.
6 This is the so-called well-ordering property of N. A simpler proof for E1 will be given
in §10. Thus the present proof may be omitted.

§5. Natural Numbers. Induction
67
∗Proof. We use a so-called indirect proof or proof by contradiction. That is,
instead of proving our assertion directly, we shall show that the opposite is
false, and so our theorem must be true.
Thus assume (i′) and (ii′) and, seeking a contradiction, suppose P(n) fails for
some n ∈N (call such n “bad”). Then these “bad” naturals form a nonempty
subset of N, call it A. By Theorem 2, A has a least member m. Thus m is the
least natural for which P(n) fails. It follows that all n less than m do satisfy
P(n) (among them is 1 by (i′)). But then, by our assumption (ii′), P(n) also
holds for n = m, which is impossible since m is “bad” by construction.
This contradiction shows that there cannot be any “bad” naturals, and the
theorem is proved.
□
Note. In inductive proofs, Theorem 2′ is used in much the same manner
as Theorem 1′, but it leaves us more freedom in step (ii): instead of assuming
that just P(m) is true, we may assume that P(1), P(2), . . . , P(m−1) are true.
Problem. Verify Example (A) for mn. (See other problems in §6.)
§6. Induction (continued)
A similar induction law applies to deﬁnitions. It reads as follows.
A notion C(n) is regarded as deﬁned for every natural element of an ordered
ﬁeld F if
(i) it has been deﬁned for n = 1, and
(ii) some rule or formula is given that expresses C(n) in terms of C(1), C(2),
. . . , C(n −1), i.e., in terms of all C(k) with k < n, or some of them.
Such deﬁnitions are referred to as inductive or recursive. Step (ii), i.e., the
rule that deﬁnes C(n) in terms of all C(k), k < n, or some of them, is called the
recursive part of the deﬁnition. We have already encountered such deﬁnitions in
Chapter 1, §8. The underlying intuitive idea is again a step-by-step procedure:
ﬁrst, we deﬁne C(1); then, once C(1) is known, we may use it to deﬁne C(2);
next, once both C(1) and C(2) are known, we may use them to deﬁne C(3),
and so on. The admissibility of inductive deﬁnitions can be proved rigorously,1
in much the same manner as it was done in §5 for inductive proofs; however,
we shall not go deeper into that problem.
The variable n in a recursive deﬁnition may run over the natural elements
of any ordered ﬁeld under consideration. However, for simplicity, we shall use
only those inductive deﬁnitions in which n ranges over the natural elements
of E1, i.e., natural numbers. (Actually, this is no restriction; for, as we shall
1 Cf., e.g., P. Halmos, Naive Set Theory, D. Van Nostrand.

68
Chapter 2. The Real Number System
show in §14, the natural elements in all ordered ﬁelds have exactly the same
mathematical properties and may be “identiﬁed” with the natural numbers in
E1.) The expression C(n) itself need not denote a number; it may be of quite
arbitrary nature.
We shall now illustrate this procedure by several important examples of
inductive deﬁnitions to be used throughout our later work.
Deﬁnition 1.
Given an element x of a ﬁeld F, we deﬁne the n-th power of x, denoted
xn, for every natural number n ∈E1 (n = 1, 2, 3, . . .) by setting
(i) x1 = x and (ii) xn = xn−1x,
n = 2, 3, . . . .
By the inductive law expressed above, xn is deﬁned for every natural
n. Intuitively, we may think of it as a step-by-step deﬁnition:
x1 = x, x2 = x1x = xx, x3 = x2x = (xx)x = xxx,
and so on, indeﬁnitely. Thus, formulas (i) and (ii) actually replace an
inﬁnite sequence of deﬁnitions, obtained consecutively by setting n =
2, 3, 4, . . . in (ii) and substituting the value of xn−1 known from the
preceding step.
If x ̸= 0, we also deﬁne x0 = 1 and x−n = 1
xn , n = 1, 2, . . . (division
makes sense if x ̸= 0). The expression 00 remains undeﬁned.
Deﬁnition 2.
For every natural number n, we deﬁne recursively the expression n! (read
“n factorial”) as follows:
(i) 1! = 1; (ii) n! = (n −1)! · n,
n = 2, 3, . . . .
Thus, e.g., 2! = (1!)·2 = 2; 3! = (2!)·3 = 6, etc. We also deﬁne 0! = 1.
Deﬁnition 3.
The sum and product of n elements x1, . . . , xn ∈F of a ﬁeld, denoted
by
x1 + x2 + · · · + xn and x1 · x2 · · · xn
(or Pn
k=1 xk and Qn
k=1 xk), respectively, are deﬁned recursively as follows:
Sums:
(i)
1
X
k=1
xk = x1;
(ii)
n
X
k=1
xk =
 n−1
X
k=1
xk
!
+ xn,
n = 2, 3, . . . ;
Products:
(i)
n
Y
k=1
xk = x1;
(ii)
n
Y
k=1
xk =
 n−1
Y
k=1
xk
!
· xn,
n = 2, 3, . . . .

§6. Induction (continued)
69
Note. If x1 = x2 = · · · = xn = x, we write nx for Pn
k=1 xk. Observe that
here n ∈E1, while x ∈F; thus nx is not, in general, a product, as deﬁned
in F.
However, if F ⊆E1, nx coincides with the ordinary product in E1
(cf. Problem 13).
Induction can be used to deﬁne the notion of an ordered n-tuple if the concept
of an ordered pair is assumed to be known. In fact, an ordered triple can be
regarded as an ordered pair of the form
((x1, x2), x3),
that is, as a pair in which the left coordinate is itself a pair. Similarly, an
ordered quadruple is a pair
((x1, x2, x3), x4)
in which the left coordinate is an ordered triple (x1, x2, x3), and so on. This
leads to the following deﬁnition.
Deﬁnition 4.
For any objects x1, x2, . . ., xn, the ordered n-tuple (x1, . . ., xn) is deﬁned
by
(i) (x1) = x1 (i.e., an ordered “one-tuple” (x1) is x1 itself);
(ii) (x1, . . . , xn) = ((x1, . . . , xn−1), xn), n = 2, 3, 4, . . . .
Accordingly, we may now also deﬁne the Cartesian product
A1 × A2 × · · · × An
of n sets (see the end of §4 in Chapter 1) either as the set of all n-tuples
(x1, . . . , xn) such that xk ∈Ak, k = 1, 2, . . ., n, or directly by induction:
Assuming the deﬁnition is known for two factors and writing Qn
k=1 Ak
for A1 × A2 × · · · × An, we deﬁne
(i)
1
Y
k=1
Ak = A1 and (ii)
n
Y
k=1
Ak =
 n−1
Y
k=1
Ak
!
× An,
n = 1, 2, . . . .
Sometimes we start an inductive proof or deﬁnition not with n = 1 but with
n = 0 or with n = 2, say. For example, Deﬁnition 2 could be stated thusly:
(i) 0! = 1;
(ii) n! = (n −1)! · n, n = 1, 2, . . . .
Formula (ii) may also be written as follows:
(ii) (n + 1)! = n! · (n + 1), n = 0, 1, 2, . . . ;
similarly in other cases of this kind.

70
Chapter 2. The Real Number System
Note. The notion of an ordered n-tuple as deﬁned above diﬀers from that
of a ﬁnite sequence (cf. Chapter 1, §8, Deﬁnition 1). However, for all practical
purposes, both behave in the same way; namely, two sequences, or two n-
tuples, are the same iﬀthe corresponding terms coincide (cf. Problem 16 below).
Therefore, in most cases, we may “forget” about the diﬀerence between the two
concepts.
Problems on Natural Numbers and Induction
1. Using induction (Theorem 1′ in §5), prove the following:
(i)
1n = 1 in any ﬁeld;
(ii) (∀n ∈N) 2n ≥2 in any ordered ﬁeld; specify the proposition P(n).
2. Prove that if x1, . . ., xn are natural elements of a ﬁeld, so are
n
X
k=1
xk and
n
Y
k=1
xk.
Assume this known for n = 2, and use induction on n.
3. Prove that the sum and product of n elements of an ordered ﬁeld are
positive if all these elements are. (Use induction on n.)
4. Prove by induction that if x1, x2, . . ., xn are nonzero elements of a ﬁeld,
so is Qn
k=1 xk; and
 n
Y
k=1
xk
!−1
=
n
Y
k=1
x−1
k .
Assume this known for n = 2.
5. Use induction over n to prove that for any ﬁeld elements c, xk and yk:
(i)
c
 n
X
k=1
xk
!
=
n
X
k=1
cxk;
(ii)
n
X
k=1
(xk ± yk) =
n
X
k=1
xk ±
n
X
k=1
yk.
6. Prove by induction that in any ordered ﬁeld

n
X
k=1
xk
 ≤
n
X
k=1
|xk|.
7. Prove that in any ordered ﬁeld, a < b iﬀan < bn, provided a, b ≥0. Infer
that an < 1 if 0 ≤a < 1; an > 1 if a > 1 (n = 1, 2, . . .).
8. Use induction over n to prove that for any element ϵ of an ordered ﬁeld
F,
(i) (1 + ϵ)n ≥1 + nϵ if ϵ > −1;
(ii) (1 −ϵ)n ≥1 −nϵ if ϵ < 1

§6. Induction (continued)
71
(Bernoulli inequalities). Infer that 2n > n, n = 1, 2, . . ., in E1.
9. Prove that in any ﬁeld,
an+1 −bn+1 = (a −b) ·
n
X
k=0
akbn−k,
n = 1, 2, . . ..
10. Prove in E1,
(i) 1 + 2 + · · · + n = 1
2n(n + 1);
(ii)
n
X
k=1
k2 = 1
6n(n + 1)(2n + 1);
(iii)
n
X
k=1
k3 = 1
4n2(n + 1)2;
(iv)
n
X
k=1
k4 = 1
30n(n + 1)(2n + 1)(3n2 + 3n −1).
11. For any ﬁeld elements a, b and natural numbers m, n ∈E1, prove the
following:
(i) aman = am+n;
(ii) (am)n = amn;
(iii) (ab)n = anbn.
If a ̸= 0, then also
(iv) an
am = an−m;
(v)
 b
a
n
= bn
an .
If a, b ̸= 0 show that these laws hold for negative exponents, too. Also,
prove the following:
(vi) ma + na = (m + n)a;
(vii) ma · nb = (mn)(ab);
(viii) n(a ± b) = na ± nb.
[Hints: Fix m and use induction on n. The “natural multiples” nx can be deﬁned
inductively by 1 · x = x, nx = (n −1)x + x, n = 1, 2, . . . .]
11′. Show by induction that each natural element x of an ordered ﬁeld F can
be uniquely represented as x = n · 1′, where n is a natural number in E1
(n ∈N) and 1′ is the unity in F; that is, x is the sum of n unities.
Conversely, show that each such n · 1′ is a natural element of F.
Finally, show that, for m, n ∈N, we have
m < n iﬀmx < nx,
provided x > 0.

72
Chapter 2. The Real Number System
12. Deﬁne the binomial coeﬃcient
n
k

=
n!
k! (n −k)!
for nonnegative integers n, k (k ≤n) in E1. Verify Pascal’s law:
n
k

+

n
k + 1

=
n + 1
k + 1

.
Using it, prove inductively that
 n
k

is always a natural number. Then
establish inductively the binomial theorem: for elements a, b of any ﬁeld
F and any natural number n,
(a + b)n =
n
X
k=0
n
k

akbn−k.
13. Show by induction that if x1 = x2 = · · · = xn = x, then
n
X
k=1
xk = nx and
n
Y
k=1
xk = xn (where x is in any ﬁeld).
14. Show by induction that in any ﬁeld
n
X
k=1
(xk −xk−1) = xn −x0.
Deduce from it the formulas of Problem 10 directly.
[Hints: For Problem 10(i), take xk = k2.
For Problem 10(ii), take xk = k3, etc.
Substitute and simplify.]
15. Show by induction that every ﬁnite sequence x1, x2, . . ., xn of elements
of an ordered ﬁeld contains a largest and a smallest term (which need
not be xn and x1 since the sequence is not necessarily monotonic). Show
by examples that the theorem fails for inﬁnite sequences. Infer that the
set of all natural numbers 1, 2, 3, . . . is inﬁnite. (For the deﬁnition of
“ﬁnite” and “inﬁnite”, see Chapter 1, §8).
16. Prove by induction that two ordered n-tuples (x1, . . ., xn) and (y1, . . ., yn)
are equal iﬀx1 = y1, x2 = y2, . . ., xn = yn. Assume this known for n = 2.
17. Show that if the sets A and B are ﬁnite (cf. Chapter 1, §8, Deﬁnition 5),
so are A ∪B and A × B. By induction, prove this for n sets.
18. Solve Problems 6 and 7 of Chapter 1, §9 by induction.
19. Show by induction that if the ﬁnite sets A and B have m and n elements,
respectively, then
(i) A × B has mn elements;

§6. Induction (continued)
73
(ii) A has 2m subsets;
(iii) If further A ∩B = ∅, then A ∪B has m + n elements.
20. Prove the division theorem: Let N ′ = N ∪{0} be the set consisting of 0
and all naturals (N) in an ordered ﬁeld. Then for any m, n ∈N ′ (n > 0),
there is a unique pair (q, r) ∈N ′ × N ′ such that
m = nq + r and 0 ≤r < n
(q and r are called, respectively, the quotient and remainder from the
division of m by n). If r = 0, we say that n divides m and write n | m).
[Hints: Let q be the least element of
A = {x ∈N′ | (x + 1)n > m}
(why does it exist?) and put r = m −nq; show that r ∈N′, r < n, using the fact that
q ∈A.
To prove uniqueness, let (q′, r′) be another such pair and show that the assumption
r < r′ or r′ > r leads to a contradiction; thus r = r′, and hence q = q′.]
§7. Integers and Rationals
Deﬁnition 1.
All naturals in a ﬁeld F, their additive inverses, and the zero element 0
are called the integral elements or integers (in F).
Below we denote by J the set of all integers in F and by N the set of all
naturals, as before. In order to investigate J, we need a lemma.
Lemma. If m, n ∈N in a ﬁeld F, then m−n is an integer in F (m−n ∈J).
Proof. We proceed by induction.1 Fix m ∈N, and let P(n) mean m−n ∈J.
(i) P(1) is true. Indeed, m −1 = 0 or m −1 ∈N by Example (B) in §5.
Thus m−1 ∈J, by deﬁnition. But this means that P(n) holds for n = 1.
(ii) P(k) =⇒P(k +1). Suppose P(n) holds for some particular n = k. This
means that m−k ∈J; that is, m−k ∈N or m−k = 0 or −(m−k) ∈N.
We must show that this implies [m −(k + 1)] ∈J, i.e., [(m −k) −1] ∈J.
Now, if m−k ∈N, then (m−k)−1 = 0 or (m−k)−1 ∈N by Example (B)
in §5. Hence (m −k) −1 ∈J, as required. This settles the case m −k ∈N.
If m −k = 0, then (m −k) −1 = −1 ∈J by deﬁnition.
1 If F is an ordered ﬁeld, one can simply apply Example (D) in §5.
Indeed, we have
m −n ∈N, m −n = 0, or −(m −n) ∈N accordingly as m > n, m = n, or m < n. Thus
m −n ∈J by deﬁnition. This may suﬃce at a ﬁrst reading.

74
Chapter 2. The Real Number System
Finally, if −(m−k) ∈N, then −(m−k)+1 ∈N; that is, −[m−(k+1)] ∈N,
and so, by deﬁnition, [m −(k + 1)] ∈J. But this means that P(k + 1) is true.
Thus, in all three cases, P(k + 1) results from P(k). This completes the
induction, and so P(n) holds for every n ∈N, i.e., m −n ∈J for any m, n ∈
N.
□
Theorem 1. If x and y are integers in a ﬁeld F, so are x + y and xy.2
Proof. As x, y ∈J, we must consider the following possible cases.
(i) If x and y are both naturals, so are x + y and xy by Example (A) in §5.
Thus they are integers, as claimed.
(ii) If x or y is 0, all is trivial (we leave this case to the reader).
(iii) If x and y are both additive inverses of naturals, then −x and −y are
naturals; hence so is their sum, (−x) + (−y) = −(x + y). This shows
that x + y is the additive inverse of a natural element; so x + y ∈J by
deﬁnition. Similarly xy = (−x)(−y) ∈N; hence certainly xy ∈J.
(iv) Suppose that one of x and y (say x) is a natural element while the other
(y) is not. Then either y = 0 or −y ∈N. The case y = 0 was taken care
of in (ii). If, however, −y ∈N, the lemma yields x −(−y) ∈J; that is,
x + y ∈J, as claimed. Also, x(−y) ∈N. Hence xy is an integer, being
the additive inverse of the natural element x(−y) = −xy.
Thus, in all cases, x + y ∈J and xy ∈J. The theorem is proved.
□
We also have an induction rule for integers similar to that applying to natural
elements.
Induction Law for Integers. A proposition P(n) holds for all integers n
greater than a ﬁxed integer p in an ordered ﬁeld if
(i′) p(n) holds for n = p + 1, and
(ii′) whenever P(n) holds for all integers n such that p < n < m, then P(n)
also holds for n = m (m ∈J).
This is proved from Theorem 2′ in §5 by substituting x −p for n and noting
that x −p runs over all natural values when x takes on integral values greater
than p. (Here we say that “induction starts with p + 1.”)
Deﬁnition 2.
An element x of a ﬁeld F is said to be rational iﬀx = p/q for some
integral elements p and q, with q ̸= 0.3
2 So also is x −y since it reduces to x + (−y), where x and −y are integers.
3 In particular, the rationals in E1 are called rational numbers.

§7. Integers and Rationals
75
Theorem 2. The sum, the diﬀerence, and the product of two rationals x and
y in a ﬁeld F are rational. So also is x/y if y ̸= 0.
Proof. Let x = p/q and y = r/s, where p, q, r, s are integers, with q and s
diﬀerent from 0. Then, as is easily seen (cf. Problem 3 in §4),
x ± y = ps ± qr
qs
,
xy = pr
qs,
and
x
y = ps
qr
(the latter provided that y and r, too, are diﬀerent from zero). Thus x ± y,
xy, and x/y can be written as fractions with integral numerators and denomi-
nators. (The fact that numerators and denominators are integers follows from
Theorem 1. It is also easily seen that these denominators are not 0 since q, r,
s ̸= 0.) By Deﬁnition 2, they are rational elements of F, as required.
□
It follows, in particular, that −x is rational whenever x is; similarly for
x−1 = 1/x if x ̸= 0. All integers (including 0 and 1) are rationals since an
integer m can be written as m/1.
It is easy to verify that Axioms I to IX remain valid if E1 is replaced by the
set R of all rational elements of an ordered ﬁeld F. This means that R is an
ordered ﬁeld. It is called the rational subﬁeld of F.
Problems on Integers and Rationals
1. Prove in detail the induction law for integers, stated above.
2. Show that the result of Problem 20 in §6, i.e., the division theorem, holds
also with N ′ replaced by J, the set of all integers.
3. Verify that the set J of all integers in an ordered ﬁeld F satisﬁes Axioms I–
IX of §2 except Axiom V(b). Thus J is not a ﬁeld.
Structures satisfying Axioms I–IX, except possibly IV(b) and V(b),
are called ordered commutative rings. In particular, J is such a ring.
4. Verify that the set R of all rationals in F is a ﬁeld if F is and an ordered
ﬁeld if F is.
5. Show that every rational r in an ordered ﬁeld F has a unique representa-
tion r = m/n in lowest terms, i.e., such that n > 0 and |m| has the least
possible value (along with |n|). Also prove that, in this case, m and n are
relatively prime, i.e., have no common divisors > 1.
[Hint: If r > 0, let A be the set of all naturals m occurring in various representations
r = m/n. Then apply Theorem 2 of §5. The rest follows from the minimality of m.]
6. Let A be a nonempty set of integers (A ⊂J) in an ordered ﬁeld F. Show
that if all elements of A are greater than some integer p, then A has a
least element.
[Hint: The diﬀerences x −p (x ∈A) are naturals; so by Theorem 2 of §5, one of them
is the least; the corresponding x is the least in A.]

76
Chapter 2. The Real Number System
7. Let A be as in Problem 6. Show that if all elements of A are less than
some integer p, then A has a largest element.
[Hint: Apply the result of Problem 6 to the set F of all additive inverses −x of elements
x ∈A, noting that −x > −p for all x ∈A.]
8. From Problems 6 and 7 infer that in any ordered ﬁeld, two nonzero inte-
gers m and n always have a least common multiple and a greatest common
divisor.
[Hint: Show ﬁrst that all common multiples (such as mn) are ≥|m|, while all common
divisors are ≤|m|.]
9. Prove: Every integer n > 1 in an ordered ﬁeld is the product of some
ﬁnite sequence of primes, i.e., integers ≥2, each divisible only by 1 and
itself.
[Hint: Let P (n) mean that n can be so factored, and use induction. P (n) is trivial if
n is itself a prime (e.g., n = 2).
Now suppose P (n) is true for all n less than some m. If m is not a prime, then
m = n1n2 for some integers n1 and n2 greater than 1 but less than m (why?); so by
our assumption, n1 and n2 factor into primes, and the same follows for m.]
Note: It can be shown that the factorization into primes is unique except
for the order in which they occur.
10. Show that there are inﬁnitely many primes.
[Hint: Seeking a contradiction, suppose all primes can be put in a ﬁnite sequence
p1, . . . , pn.
Then show that
1 +
n
Y
k=1
pk
is not divisible by any of the pk (use the division algorithm theorem; cf. Problem 2).
Infer from Problem 9 that 1+Qn
k=1 pk is a prime diﬀerent from all pk (k = 1, 2, . . . , n).]
11. Show that every strictly decreasing sequence of positive integers is neces-
sarily ﬁnite.
[Hint: Use Problem 6 or Theorem 2 in §5.]
§8. Bounded Sets in an Ordered Field
Deﬁnition 1.
A subset A of an ordered ﬁeld F is said to be bounded below, or left-
bounded, if there is an element p ∈F such that (∀x ∈A) p ≤x.
The set A is bounded above, or right-bounded, if there is an element
q ∈F such that (∀x ∈A) x ≤q.
In this case, p and q are called, respectively, a lower (or left) and an
upper (or right) bound of A.

§8. Bounded Sets in an Ordered Field
77
If A is both left- and right-bounded, it is simply referred to as bounded
(by p and q). The empty set ∅is always regarded as bounded, and all
elements of F are considered both its lower and upper bounds.
Note. The bounds p and q may, but need not, belong to the set A.
If a set A is bounded below, it has many lower bounds; for if p is one of
them, so also is every element less than p. Similarly, a right-bounded set always
has many upper bounds.
All this applies, in particular, to sets of real numbers, i.e., sets in E1.
Examples.
(1) The set of four numbers {1, −2, 3, 7} is bounded, both above (e.g., by 7,
8, 9, 100, etc.) and below (e.g., by −2, −5, −12, etc.).
(2) The set of all natural numbers N = {1, 2, 3, . . .} is bounded below (e.g., by
1, 0, −1
2, −9, etc.) but not above. (An exact proof of this fact will be
given later, after the introduction of the missing 10th axiom, on which it
is based.) On the other hand, the set of all negative integers is bounded
above but not below.
(3) The set J of all integers has no lower and no upper bounds in E1. In
fact, given any number p ∈E1, one can always ﬁnd an integer > p and
an integer < p. Thus no such p can be a lower or an upper bound for J.
Geometrically, an upper bound of a set A ⊂E1 is a point q on the real axis
that lies on the right side of A, while a lower bound p lies on the left side; see
Figure 9.
p
q
Figure 9
A
z
}|
{
An especially important class of bounded sets form the so-called intervals.
Deﬁnition 2.
Given any real numbers a and b (a ≤b), we deﬁne
(i) the open interval (a, b) to be the set of all real numbers x such that
a < x < b, i.e.,
(a, b) = {x ∈E1 | a < x < b};
(ii) the closed interval [a, b] to be the set of all real numbers x such that
a ≤x ≤b, i.e.,
[a, b] = {x ∈E1 | a ≤x ≤b}.

78
Chapter 2. The Real Number System
We also deﬁne, in a similar way, the half-open interval (a, b] and the half-
closed interval [a, b) by the inequalities a < x ≤b and a ≤x < b, respectively.
The same deﬁnitions also apply to intervals in any ordered ﬁeld F.
In all cases, a and b are called the endpoints of the interval. Note that a
belongs to [a, b] and [a, b) but not to (a, b) and (a, b], while b belongs to [a, b]
and (a, b] but not to (a, b) and [a, b) (square brackets are written beside those
endpoints that are included in the interval). If a = b, i.e., if the endpoints
coincide, the interval is said to be degenerate. In this case the closed interval
[a, a] consists of a single point, a, while (a, a) = (a, a] = [a, a) = ∅. (Why?)
Every interval is a bounded set since its endpoints are its bounds by its very
deﬁnition. Geometrically, intervals are segments of the real axis.
If an upper bound q of a set A is itself in A, then q is clearly the greatest
element of A (i.e., one not exceeded by any other element of A). We then also
call it the maximum of A, denoted max A. Similarly, if A contains its lower
bound p, then p is its least element, also called the minimum of A or, brieﬂy,
min A. A set A can have at most one maximum and one minimum; for if, say,
q and q′ were both maxima, then by deﬁnition, q ≤q′ (since q ∈A and q′ is an
upper bound) and, similarly, q′ ≤q, so that q = q′. However, a set may have
no maximum and no minimum even if it is bounded; such a set is, for example,
every open interval. (Why?) We denote by max(a, b) the larger of the two
elements a and b; similarly for min(a, b) and for sets of several elements.
It is important to note that every nonempty ﬁnite set A in an ordered ﬁeld
must have a maximum and a minimum. This is easily proved by induction on
the number n of elements in A; the details are left to the reader (cf. Problem 15
in §6). In particular, given n real numbers x1, x2, . . . , xn, one of them must
be the largest, i.e., max(x1, . . ., xn), and one of them must be the smallest,
i.e., min(x1, . . ., xn).
§9. The Completeness Axiom. Suprema and Inﬁma
In §8 it was shown that a right-bounded set of real numbers always has many
upper bounds. The question arises as to whether or not there exists among
them a least one. Similarly, one may ask whether or not a left-bounded set
always has a greatest lower bound, i.e., one “closest” to the set.
Geometrically, this problem may be illustrated as follows. Figure 10 shows
a bounded set M of real numbers plotted on the real axis.
u
u′
p
v′
v
q
Figure 10
M
z
}|
{

§9. The Completeness Axiom. Suprema and Inﬁma
79
The points u and v on the axis represent a lower and an upper bound of M,
respectively. It is, however, evident from Figure 10 that v is not the least upper
bound since also the smaller number v′ is an upper bound of M. Similarly, u
is not the greatest lower bound since there is a greater lower bound, u′.
Now imagine that the point v moves along the axis in the direction of the
set M but remaining to the right of all points of M. It is geometrically evident
that v will eventually arrive at a certain position q where it can no longer
continue its motion without passing some points of M, i.e., without ceasing to
be an upper bound of M. This very position q (if it actually exists) is clearly
that of the least upper bound. Similarly, by moving the point u in the positive
direction, one arrives at a position p that corresponds to the greatest lower
bound of M. Note that p and q need not be the minimum and maximum of M.
For example, if M is the open interval (p, q), it has no minimum or maximum
at all. Nevertheless, p and q are its greatest lower, and least upper, bounds.
(To ﬁx ideas, assume that M in Figure 10 has no maximum or minimum).
These geometric considerations, however plausible, cannot be considered a
rigorous proof of the existence of the least upper and greatest lower bounds.
This proof also cannot be derived from the nine axioms stated thus far. On
the other hand, the existence of the least upper and greatest lower bounds is of
very great importance for the entire mathematical analysis. Therefore, it has
to be introduced as a special axiom, which, for reasons to be explained later,
is called the completeness axiom. It is the last (tenth) axiom in our system.
Completeness Axiom.
X Every nonvoid right-bounded set M of real numbers has a least upper
bound (also called the supremum of M, abbreviated sup M or l.u.b. M).
No special axiom is needed for lower bounds since the corresponding propo-
sition can now be proved from the completeness axiom, as follows.
Theorem 1. Every nonvoid left-bounded set M of real numbers has a greatest
lower bound (also called the nﬁmum of M, abbreviated inf M or g.l.b. M).
Proof. Let B denote the (nonvoid) set of all lower bounds of M (such bounds
exist since M is left-bounded). Clearly, each element of M is, in turn, an upper
bound for B (because no element of B can exceed any element of M by the
deﬁnition of a lower bound). Thus B is nonvoid and right-bounded. By the
completeness axiom, B has a supremum, call it p. We shall now prove that p
is also the required inﬁmum of M. Indeed, we have the following:
(i) p is a lower bound of M; for p is, by deﬁnition, the least of all upper
bounds of B. But, as we have seen, all elements of M are such upper
bounds; so p cannot exceed anyone of them, as required.
(ii) p is the greatest lower bound of M. In fact, as p is an upper bound of B,
it is not exceeded by any element of B. But, by deﬁnition, B contains all
lower bounds of M; so p is not exceeded by any one of them.

80
Chapter 2. The Real Number System
This completes the proof.
□
Note 1. Theorem 1 could, in turn, be assumed as an axiom. Then our
completeness axiom could be deduced from it in a similar manner.
Note 2. The supremum and inﬁmum of a set M (if they exist) are unique;
for the inﬁmum of M is, by deﬁnition, the greatest element of the set B of all
lower bounds of M, i.e., max B. But max B is unique, as shown at the end of
§8; hence so is inf M. Similarly for sup M.
Note 3. To explain the “completeness axiom”, consider again Figure 10
and imagine that the points p and q have been removed from the axis, leaving
two “gaps” in it. Then the set M, though bounded, would have no supremum
and no inﬁmum since the required points would be missing. The completeness
axiom asserts, in fact, that such “gaps” never occur, i.e., that the real axis is
“complete”.
As we mentioned, the completeness axiom is independent of the ﬁrst nine
axioms, i.e., cannot be deduced from them. In fact, there are ordered ﬁelds
that do not satisfy it, though they certainly satisfy the ﬁrst nine axioms. Such
a ﬁeld is, e.g., the ﬁeld of all rational numbers (see §11). On the other hand,
some ordered ﬁelds do have the completeness property, and E1 is one of them.
This justiﬁes the following deﬁnition.
Deﬁnition.
An ordered ﬁeld F is said to be complete iﬀevery nonvoid right-bounded
subset M of F has a supremum (i.e., a least upper bound) in F.
In particular, E1 is a complete ordered ﬁeld by the completeness axiom. We
can now restate Theorem 1 in a more general form:
Theorem 1′. In a complete ordered ﬁeld F, every nonvoid left-bounded set
M ⊂F has an inﬁmum (i.e., a greatest lower bound).
The proof is exactly the same as in Theorem 1.
Also the following corollaries will be stated for ordered ﬁelds in general.
They apply, of course, to E1 as well.
Corollary 1. An element q of an ordered ﬁeld F is the supremum of a set
M ⊂F iﬀq satisﬁes these two conditions:
(i) (∀x ∈M) x ≤q; i.e., q is not exceeded by any element x in M.
(ii) Every element p < q is exceeded by some x in M, i.e.,
(∀p < q) (∃x ∈M)
p < x.
A similar result holds for the inﬁmum (with all inequalities reversed).
In fact, condition (i) states that q is an upper bound of M, while (ii) states
that no smaller element p ∈F is such a bound (since it is exceeded by some
x ∈M). When combined, (i) and (ii) mean that q is the least upper bound.

§9. The Completeness Axiom. Suprema and Inﬁma
81
Note 4. Every element p < q can be written as q −ϵ, where ϵ > 0. Hence
Condition (ii) in Corollary 1 can also be rephrased thusly:
(ii′) For every ﬁeld element ϵ > 0, there is an x ∈M with q −ϵ < x.
In case q = inf M, we have instead that
(∀ϵ > 0) (∃x ∈M)
q + ϵ > x.1
Corollary 2. Let M be a nonempty set in an ordered ﬁeld F, and let b ∈F.
If each element x of M satisﬁes the inequality x ≤b (x ≥b), so does sup M
(inf M, respectively), provided that sup M (inf M) exists.
In fact, the condition
(∀x ∈M)
x ≤b
means that b is an upper bound of M. But sup M is the least upper bound of
M, so (sup M) ≤b; similarly for inf M.
Corollary 3. If A and B are subsets of an ordered ﬁeld, both nonvoid, and if
A ⊆B, then
sup A ≤sup B and inf A ≥inf B,
provided that the suprema and inﬁma involved exist. (Thus if new elements
are added to a set A, its supremum cannot decrease and its inﬁmum cannot
increase.)
Proof. Let
p = sup A and q = sup B.
As q is an upper bound of B, we have x ≤q for each x ∈B. But, by assumption,
B contains all elements of A. Hence, the inequality x ≤q holds also for each
x ∈A (since x ∈B as well). As each x ∈A satisﬁes x ≤q, Corollary 2 yields
sup A ≤q, i.e.,
sup A ≤sup B
(for q = sup B); similarly for inﬁma.
□
Note 5. If A is a proper subset of B (A ⊂B), it does not follow that
sup A < sup B, but only that sup A ≤sup B (and inf A ≥inf B). For example,
the open interval (a, b) is a proper subset of the closed interval [a, b], but their
suprema and inﬁma are the same, namely b and a. Similarly, if in Corollary 2
each x ∈M satisﬁes x < b (x > b), it only follows that sup M ≤b (inf M ≥b),
but not sup M < b (inf M > b). For example, we have x < b for all x ∈(a, b),
but sup(a, b) = b.
1 Here we may assume ϵ as small as we like (only ϵ > 0); for if the required inequalities
hold for a small ϵ, they certainly hold for any larger ϵ.

82
Chapter 2. The Real Number System
Corollary 4. If a subset M of an ordered ﬁeld F has a maximum q, then q is
also its supremum. Similarly, the minimum of M (if it exists) is its inﬁmum.
The converse statements are, however, not true.
The proof (which is obvious) is left to the reader.
Problems on Bounded Sets, Inﬁma, and Suprema
1. Assume Theorem 1 as an axiom and deduce from it the completeness
axiom.
2. Complete the proofs of Corollaries 1–3 (for inﬁma) and Corollary 4.
3. Show that if inf A and sup A exist in an ordered ﬁeld, then inf A ≤sup A.
4. Prove that the endpoints of an open interval (a, b) (a < b) in an ordered
ﬁeld F are the inﬁmum and supremum of (a, b).
5. In an ordered ﬁeld F, let A ⊂F (A ̸= ∅), and let cA denote the set of all
products cx (x ∈A) for some ﬁxed element c ∈F; so
cA = {cx | x ∈A}.
Prove the following:
(i) If c ≥0, then
sup(cA) = c · sup A and inf(cA) = c · inf A,
provided that sup A (in the ﬁrst formula) and inf A (in the second
formula) exist.
(ii) If c < 0, then
sup(cA) = c · inf A and inf(cA) = c · sup A,
provided again that inf A and sup A (as the case may be) exist.
What if c = −1?
6. From Problem 5(ii), with c = −1, obtain a new proof of Theorem 1.
[Hint: If M is bounded below, show that (−1)M is bounded above, then take its sup.]
7. Let A and B be subsets of an ordered ﬁeld F. Assuming that the required
l.u.b. and g.l.b. exist in F, prove the following:
(i) If (∀x ∈A) (∀y ∈B) x ≤y, then sup A ≤inf B.
[Hint: Each y ∈B is an upper bound of A and, hence, cannot be less than the
least upper bound of A. Thus (∀y ∈B) sup A ≤y, i.e., sup A is a lower bound
of B, and so sup A ≤inf B (cf. Corollary 2).]
(ii) If (∀x ∈A) (∃y ∈B) x ≤y, then sup A ≤sup B.
(iii) If (∀y ∈B) (∃x ∈A) x ≤y, then inf A ≤inf B.
(iv) If B consists of all upper bounds of A, then sup A = inf B.

§9. The Completeness Axiom. Suprema and Inﬁma
83
8. In an ordered ﬁeld F, let A + B denote the set of all sums x + y, with
x ∈A and y ∈B (A ⊆F, B ⊆F); so
A + B = {x + y | x ∈A, y ∈B}.
Prove that if sup A = p and sup B = q exist in F, then p+q = sup(A+B);
similarly for inﬁma.
[Hint: By Corollary 1 and Note 4, we must show (in the case of sup) that
(i) (∀x ∈A) (∀y ∈B) x + y ≤p + q (which is easy), and
(ii′) (∀ϵ > 0) (∃x ∈A and y ∈B) x + y > (p + q) −ϵ.
For (ii′), take any ϵ > 0. By Note 4, there are x ∈A and y ∈B, with
x > p −1
2ϵ and y > q −1
2ϵ.
(Why?) Then
x + y > (p −1
2ϵ) + (q −1
2ϵ) = (p + q) −ϵ,
as required.]
9. Continuing Problem 8, let A and B consist of positive elements only, and
let
AB = {xy | x ∈A, y ∈B}.
Prove that if sup A = p and sup B = q exist in F, then pq = sup(AB);
similarly for inﬁma.
[Hint: Using Note 4, we may take ϵ > 0 so small that
ϵ
p + q < p, q;
take
x > p −
ϵ
p + q > 0 and y > q −
ϵ
p + q > 0
and show that
xy > pq −ϵ +
ϵ2
(p + q)2 > pq −ϵ.
For inf(AB), let s = inf B, r = inf A, ϵ > 0. By density, there is d < 1, with
0 < d <
ϵ
1 + r + s .
Now take x ∈A and y ∈B with x < r + d, y < s + d, and show that xy < rs + ϵ.]
10. Prove that if a ≥b −ϵ for all ϵ > 0, then a ≥b. What if (∀ϵ > 0)
a ≤b + ϵ?
∗11. Prove the principle of nested intervals: If [an, bn] are closed intervals in
a complete ﬁeld F, with
[an, bn] ⊇[an+1, bn+1],
n = 1, 2, 3, . . . ,
then
∞
\
n=1
[an, bn] ̸= ∅.

84
Chapter 2. The Real Number System
[Hint: Let A = {a1, a2, . . . , an, . . . }. Show that A is right-bounded by each bn. By
completeness, let sup A = p. Show that an ≤p ≤bn, i.e.,
p ∈[an, bn],
n = 1, 2, . . . ,
and so
p ∈
∞
\
n=1
[an, bn].]
12. Prove by induction that any union of ﬁnitely many bounded sets in an
ordered ﬁeld F is itself bounded in F (ﬁrst prove it for two sets).
13. Prove that for any bounded subset A ̸= ∅of a complete ordered ﬁeld
F, there is a smallest closed interval C containing A (“smallest” means
that C is a subset of any other such interval). Is this true with “closed”
replaced by “open”?
[Hint: Let C = [a, b], a = inf A, b = sup A.]
§10. Some Applications of the Completeness Axiom
From everyday experience, one knows that even a large distance y can be
measured by a small yardstick x; one only has to mark x oﬀsuﬃciently many
times.
This fact was noticed by ancient Greeks; it goes back to the Greek
geometer and scientist Archimedes. Mathematically, it means that, given a
positive number x (no matter how small) and another number y (no matter how
large), there always is a natural number n such that nx > y. This fact, known
as the Archimedean property, holds not only for real numbers (i.e., in E1) but
also in many other ordered ﬁelds. All such ﬁelds are called Archimedean ﬁelds
to distinguish them from other ﬁelds in which this property fails. In particular,
we shall now prove that every complete ﬁeld (such as E1) is Archimedean. That
is, we have following.
Theorem 1 (Archimedean property). If x and y are elements of a complete
ordered ﬁeld F (e.g., E1) and if x > 0, then there always is a natural n ∈F
such that nx > y.
We shall prove this theorem by showing that the opposite assertion is im-
possible since it leads to a contradiction; it will then follow that our theorem
must be true.
Thus, given a ﬁxed element x > 0, assume (seeking a contradiction) that
there is no natural n with nx > y. Then, for all natural n, we have nx ≤y.
This means that y is an upper bound of the set of all products
nx
(n = 1, 2, 3, . . . );
call this set M. Clearly, M is nonvoid and bounded above (by y); so, by the
assumed completeness of F, M has a supremum, say, q = sup M. As q is an

§10. Some Applications of the Completeness Axiom
85
upper bound of M, we have (by the deﬁnition of M) that nx ≤q for each
natural element n. But if n is a natural element, so is n + 1. Thus, replacing
n by n + 1, we get (n + 1)x ≤q, whence
nx ≤q −x,
n = 1, 2, 3, . . . .
In other words, q −x (which is less than q since x > 0) is another upper
bound of all nx, i.e., of the set M. But this is impossible because q = sup M
is by deﬁnition the least upper bound of M; so no smaller element, such as
q −x, can be its upper bound. This contradiction shows that the negation of
our theorem must be false. The theorem is proved.
Note 1. The theorem also holds, with the same proof, for “natural multi-
ples” nx = x + x + · · · + x as deﬁned in §6 (see the note after Deﬁnition 3).
Note 2. Theorem 1 shows that no complete ordered ﬁeld, such as E1 can
contain so-called “inﬁnitely small” elements, supposedly ̸= 0 but such that all
their integral multiples are less than 1. (However, such elements do exist in
non-Archimedean ﬁelds; and recent research, due to A. Robinson, made use of
them in what is now generally called “Nonstandard Analysis”.)
Corollary 1. Given any element y in an Archimedean ﬁeld F, there always
are naturals m, n ∈N such that −m < y < n.
Proof. Given any y ∈F, use the Archimedean property (with x = 1) to ﬁnd
a natural n ∈F such that n · 1 > y, i.e., n > y. Similarly there is another
natural m such that m > −y, i.e., −m < y < n.
□
Corollary 2. In any Archimedean ﬁeld, the set N of all naturals has no upper
bound, and the set J of all integers has neither upper nor lower bounds. (The
negative integers are not bounded below.)
For, by Corollary 1, no element y ∈F can be an upper bound of N (being
exceeded by n ∈N), nor can it be a lower bound of the negative integers (since
it exceeds some −m, m ∈N).
Although our next theorem is valid in all Archimedean ﬁelds (see Problem 2
below), a simpler proof (avoiding the use of Theorem 2 of §5) can be given for
complete ﬁelds, such as E1. This is our purpose here.
Theorem 2. In an Archimedean ﬁeld F, every nonvoid right-bounded set of
integers has a maximum, and every nonvoid left-bounded set of integers has a
minimum.
Proof for complete ﬁelds. Let M be a nonvoid right-bounded set of integers
in a complete ﬁeld F. By completeness, M has a supremum, call it q. The
theorem will be proved if we show that q ∈M (for, an upper bound that belongs
to the set is its maximum). To prove it, we assume the opposite, q /∈M, and
seek a contradiction.

86
Chapter 2. The Real Number System
Consider the element q−1. As q−1 < q, Corollary 1 of §9 shows that q−1 is
exceeded by some element x ∈M. Since q /∈M, q cannot equal x. Therefore,
as q is an upper bound of M, we have x < q, so that q −1 < x < q. Now, as
x < q, Corollary 1 of §9 yields another element y ∈M such that x < y < q,
and so
q −1 < x < y < q.
But this is impossible because x and y are integers (being elements of M),
and no two distinct integers can lie between q −1 and q (indeed, this would
imply 0 < y −x < 1, with y −x a positive integer, contrary to what was shown
in Example (C) of §5).
This contradiction shows that q must belong to M, and hence q = max M,
proving the ﬁrst clause of the theorem.
The second clause is proved quite
similarly. We leave it to the reader.
□
We now use Theorem 2 to obtain two further results.
Corollary 3. Given any element x of an Archimedean ﬁeld F, there always
is a unique integer n ∈F such that
n ≤x < n + 1.
(This integer is called the integral part of x, denoted [x].)
Proof. By Corollary 1, there are integers ≤x. Clearly, the set of all such
integers (call it M) is bounded above by x. Hence, by Theorem 2, M has a
maximum; call it n. Thus, n is the greatest integer ≤x. It follows that n + 1
cannot be ≤x, and so n + 1 > x ≥n. Thus n has the desired property. This
property, in turn, implies that n = max M. Hence n is unique, as max M
is.
□
Examples. [ 1
2] = 0; [−1 1
4] = −2; [−4] = −4; [
√
2] = 1.
As we saw in §4, any ordered ﬁeld is dense:
If a < b in F, there is x ∈F such that a < x < b.
We shall now show that, in Archimedean ﬁelds, x can be chosen rational, even
if a, b are not. We call this the density of rationals.
Theorem 3 (Density of rationals). Given any elements a and b (a < b) in
an Archimedean ﬁeld F, there always is a rational r ∈F such that a < r < b.
(Brieﬂy: The rationals are dense in any Archimedean ﬁeld.)
Proof. Let p = [a] (the integral part of a); so p ∈J, p ≤a. The idea of the
proof is to start with p, and then to mark oﬀa small “yardstick” 1
n < b −a
several (say m) times until p + m
n lands inside the interval (a, b) (see Figure
11).

§10. Some Applications of the Completeness Axiom
87
p
a
r
b
Figure 11
p + m
n
1
n
More precisely, as F is Archimedean, there are n, m ∈N, with
n(b −a) > 1 and m
 1
n

> a −p.1
Among all such m, ﬁx the least one (it exists by Theorem 2). Then
a −p < m
n but (m −1)
n
≤a −p,2
so that
p + m
n ≤a + 1
n.
Hence
a < p + m
n ≤a + 1
n < a + (b −a)

for 1
n < b −a, by construction

.
Setting
r = p + m
n ,
we ﬁnd that
a < r < a + b −a = b.
Moreover, r is rational, being the sum of two rationals, p and m
n . (The number
p is even an integer, namely the integral part of a.) Thus r is the desired
rational, with a < r < b.
□
Note 3. Having found one rational r1, a < r1 < b, we can apply Theorem 3
to ﬁnd another rational r2, with r1 < r2 < b, then a third rational r3, with r2 <
r3 < b, and so on, ad inﬁnitum. Continuing, we obtain inﬁnitely many rationals
between a and b. Thus any interval (a, b), with a < b, in an Archimedean ﬁeld
(such as E1) contains inﬁnitely many rationals.
1 Here we apply the Archimedean property twice: ﬁrst to ﬁnd n, we take x = (b −a) and
y = 1; then (having ﬁxed n) we ﬁnd m, taking x = 1
n, y = a −p.
2 By the minimality of m.

88
Chapter 2. The Real Number System
Problems on Complete and Archimedean Fields
1. Prove the second part of Theorem 2.
2. Prove Theorem 2 for Archimedean ﬁelds.
[Hint: If M ̸= ∅is left-bounded (right-bounded), its elements are greater (less) than
some integer (why?); so one can use the results of Problems 6 and 7 of §7.]
3. From Theorem 2, prove the induction law of §7 for integers in E1.
[Hint: Let A be the set of those integers n ∈E1 that satisfy P (n) and are > p. Show
(as in Theorem 2′ of §5) that A contains all integers > p.]
∗4. In Problem 11 of §9, show that if the intervals [an, bn] also satisfy (for a
ﬁxed d > 0)
bn −an ≤d
n,
n = 1, 2, . . .,
then
∞
\
n=1
[an, bn] contains only one point, p,
and this p is both sup an and inf bn. Also show that, if F is only Archi-
medean, the same result follows, provided that
∞
\
n=1
[an, bn] ̸= ∅.
[Hint: Seeking a contradiction, suppose T∞
n=1[an, bn] contains two points p, q with
p −q = r > 0, say. Then, using the Archimedean property, show that there is an
n ∈N such that
r > d
n ≥bn −an,
so that p and q cannot be both in [an, bn], let alone in T∞
n=1[an, bn].]
∗5. Prove that if the principle of nested intervals (cf. Problem 11 of §9) holds
in some Archimedean ﬁeld F, then F is complete.
[Outline: If M has an upper bound b, prove that sup M exists as follows.
Fix any a ∈M and let
d = b −a, c = 1
2(a + b);
so c bisects [a, b].
If there is an a1 ∈M with a1 > c, replace [a, b] by the interval
[a1, b] ⊆[a, b],
noting that
b −a1 < b −c = d
2.
If, however, all elements of M are ≤c, replace [a, b] by
[a, c] ⊆[a, b].

§10. Some Applications of the Completeness Axiom
89
In both cases, the new smaller interval (call it [a1, b1]) is such that
[a1, b1] ⊆[a, b], b1 −a1 ≤d
2 , a1 ∈M and b1 is an upper bound of M.
Now let c1 = 1
2(a1 +b1), and repeat this process for [a1, b1] to obtain a new interval
[a2, b2] ⊆[a1, b1]; b2 −a2 ≤d
4 ; b2 an upper bound of M, a2 ∈M.
Continuing this process indeﬁnitely, obtain a contracting sequence of intervals [an, bn],
with bn −an ≤d/2n (cf. §6, Problem 8), such that an ∈M and bn is an upper bound
of M for each n. Then obtain p as in Problem 4 and show that p = sup M, as required.]
6. Prove that an ordered ﬁeld F is Archimedean iﬀ, for any x, y ∈F with
x > 0, there is a natural number n ∈E1, with nx > y.
[Hint: Use Problem 11′ of §6.]
§11. Roots. Irrational Numbers
An element of a ordered ﬁeld is said to be irrational iﬀit is not rational,
i.e., cannot be represented as a ratio m/n of two integers. As we shall see,
irrationals exist in any complete ordered ﬁeld. Irrational elements of E1 are
called irrational numbers. We shall also show that the completeness axiom
implies the existence of the q-th root of any positive element. First, we must
prove a lemma.
Lemma. Let n be a natural number, and let p ≥0 and a ≥0 be elements of
an ordered ﬁeld F. If pn < a (respectively, pn > a), then there is a positive
element x ∈F such that p < x and xn < a (respectively, p > x and xn > a).
In other words, the given inequality pn < a (pn > a) is still preserved if p
increases (respectively, decreases) by a suﬃciently small quantity ϵ.
Proof 1. Let pn < a (p ≥0), and consider the fraction
a −pn
(p + 1)n −pn .
It is positive because pn < a, and so a −pn > 0. Thus by density (Corollary 7
of §4), there is an element ϵ > 0 in F, so small that ϵ < 1 and also
a −pn
(p + 1)n −pn > ϵ.
Expanding the binomial (cf. §6, Problem 12) and simplifying, we obtain
a −pn > ϵ[(p+1)n −pn] =
n
1

pn−1ϵ+
n
2

pn−2ϵ+· · · +

n
n −1

pϵ+ϵ. (1)
1 At a ﬁrst reading, the beginner may omit this proof, noting only the lemma itself.

90
Chapter 2. The Real Number System
Now, as 0 < ϵ < 1, we have ϵ ≥ϵm for any natural m. Hence the inequality
(1) can only be strengthened if we replace in it ϵ by various natural powers of
ϵ. In this manner, we obtain
a −pn >
n
1

pn−1ϵ +
n
2

pn−2ϵ2 + · · · +

n
n −1

pϵn−1 + ϵn.
Hence, transposing pn to the right side and applying the binomial theorem, we
have a > (p + ϵ)n. Thus, setting x = p + ϵ, we obtain the required x > p, with
a > xn. This settles the case pn < a of the lemma.
The other case, pn > a, is trivial if a = 0. Thus we assume pn > a > 0.
Then
 1
pn

< 1
a
and, by what was proved above (with p replaced by 1
p and a by 1
a), there is
some
y > 1
p, with yn < 1
a, i.e.,
1
y
n
> a.
Thus 1
y is the required element x, and the proof is complete.
□
Theorem 1. Given any element a ≥0 in a complete ordered ﬁeld F and a
natural number n ∈E1, there always exists a unique element p ≥0 (p ∈F)
such that pn = a. This p ≥0 is called the n-th root of a, denoted p =
n√a.
Proof. Let M be the set of all elements x ≥0 such that xn ≤a.
M is
nonempty since 0 ∈M.
Also, M is right-bounded; e.g., one of its upper
bounds is the element a + 1 (verify this!). Thus, by completeness, M has a
supremum, call it p. Clearly, p ≥0 since p = sup M and, by deﬁnition, all
elements of M are ≥0. We shall now show that this p is the required element
of F, i.e., that pn = a.
Indeed, if pn were less than a, then by the previous lemma, there would be
some x > p such that xn < a, i.e., x ∈M. But this is impossible because no
element x of M can exceed the supremum p of M.
On the other hand, if pn > a, then again by the lemma, there is some q < p
(q ≥0) with qn > a. Then for every x ∈M, we have xn ≤a < qn, whence
(since everything is nonnegative) x < q. Thus q exceeds all elements x ∈M,
i.e., q is an upper bound of M. But this is impossible because q < p and p is
the least upper bound of M.
Thus we see that the inequalities pn < a and pn > a are impossible; and
it follows by trichotomy that pn = a, as asserted.
It remains to prove the
uniqueness of p. Suppose that there is yet another element r ∈F (r > 0) with
rn = a = pn. Then
0 = rn −pn = (r −p)(rn1 + rn−2p + · · · + pn−1).

§11. Roots. Irrational Numbers
91
Dividing by the positive bracketed expression, we obtain r −p = 0, whence
r = p after all. This shows that p is indeed unique.
□
Note 1.
n√a will always denote the nonnegative value of the root. As usual,
we write √a for
2√a.
Theorem 2. Every complete ordered ﬁeld F (such as E1) contains irrational
elements. In particular,
√
2 is irrational.
Proof. By Theorem 1, F contains the element p =
√
2, with p2 = 2. Seeking
a contradiction, we assume that
√
2 is rational, i.e.,
√
2 = m
n
for some natural elements m and n.
Now, by Theorem 2 of §10 (or Problem 5 of §7), we choose the least possible
such m. Then m and n are not both even (otherwise reduction by 2 would yield
a smaller m). From
m
n =
√
2,
we obtain m2 = 2n2, whence m2 is even. But, as is easily seen, only even
elements have even squares. Thus m itself must be even; i.e., m = 2r for some
natural element r. It follows that 4r2 = m2 = 2n2, whence 2r2 = n2; and the
same argument shows that n must be even. But this is a contradiction since m
and n are not both even.
This contradiction shows that, indeed, 2 is irrational, and thus the theorem
is proved.
□
Note 2. In a similar manner one can prove the irrationality of √n, where
the natural n is not a full square. Moreover, one can show that the irrationals
are dense in E1 (cf. Problem 4 below; also, Chapter 1, §9, Corollary 4).
Note 3. From Theorem 2 it follows that the ﬁeld of all rationals is not
complete (otherwise, it would contain irrational elements, contrary to its very
deﬁnition), even though it is Archimedean (cf. Problem 6).
Thus there are
incomplete Archimedean ﬁelds.
Problems on Roots and Irrationals
1. Prove the irrationality of
√
3 and
√
5.
2. Prove that if a natural n is not a full square, then √n is irrational.
[Hint: Consider ﬁrst the case where q is not divisible by any square of a prime, i.e.,
n = p1p2 . . . pm,
where the pk are distinct primes. The general case reduces to that case; for if n = p2q
then √n = p√q.]

92
Chapter 2. The Real Number System
3. Prove that if r is rational and q is not, then r ± q is irrational; so also are
rq, r/q, and q/r if r ̸= 0.
[Hint: Assume the opposite and ﬁnd a contradiction.]
4. Prove that the irrationals are dense in any complete ordered ﬁeld F; that
is, between any two elements a, b ∈F (a < b) there is an irrational x ∈F
(a < x < b), and hence there are inﬁnitely many such x.
[Hint: By Theorem 3 of §10, there is a rational r that satisﬁes
a
√
2 < r < b
√
2.
Put x = r/
√
2.]
5. Show by examples that the sum or product of two irrationals may be
rational. Thus the irrationals do not form a ﬁeld. Specify which ﬁeld
axioms fail for irrationals.
6. Show that the rationals in any ordered ﬁeld form an Archimedean subﬁeld.
7. Let p ∈E1,
A = set of all rationals < p, B = set of all irrationals < p.
Show that p = sup A = sup B. Solve a similar problem for inﬁma.
8. Let A be the set of all positive rationals x in an ordered ﬁeld F such that
x2 < 2. Without explicitly using
√
2 (which may not exist in F), show
that A is bounded above but has no rational supremum. Thus give a
direct proof that the rational subﬁeld R of F is incomplete.
[Hint: Use the lemma and the fact (proved in Theorem 2) that for no x ∈R, x2 = 2.]
∗§12. Powers with Arbitrary Real Exponents
In §11, we proved the existence and uniqueness of
n√a
(n = 1, 2, . . . )
for elements a ≥0 in a complete ordered ﬁeld. Using this, we shall now deﬁne
the power ar for any rational r > 0.
Deﬁnition 1.
Given any element a ≥0 in a complete ordered ﬁeld F and any rational
number r = m/n > 0 (where m and n are natural numbers in E1), we
deﬁne
ar =
n√
am.

∗§12. Powers with Arbitrary Real Exponents
93
Here we must clarify two facts:
(1) In case n = 1, we have
ar = am/1 =
1√
am = am.
Thus for natural values of r, our new deﬁnition agrees with the original
meaning of am (as deﬁned in §6), and so contradictions are excluded.
(2) Our deﬁnition does not depend on the particular representation of r in
the form m
n , and thus is unambiguous. Indeed, if r is represented as a
fraction in two diﬀerent ways,
r = m
n = p
q ,
then mq = np, whence amq = apn, i.e., (am)q = (ap)n.
Now, by deﬁnition,
n√
am is exactly the element whose n-th power is
am, i.e.,
(
n√
am)n = am.
Similarly, (
q√ap)q = ap. Substituting this for am and ap in the equation
(am)q = (ap)n,
we get
(
n√
am)nq = (
q√
ap)nq, whence
n√
am =
q√
ap
(by taking the nq-th root of both sides). Thus, indeed, all representations
of r yield the same value of
n√
am = ar, and so ar is well deﬁned.
By using our deﬁnition of
n√a (which can now also be written as a1/n) and
the formulas stated in Problems 11 and 7 in §6, the reader will easily verify that
these formulas remain valid also for powers ar (a > 0) with rational exponents
> 0 as deﬁned above. That is, we have
aras = ar+s; (ar)s = ars; (ab)r = arbr; a < b iﬀar < br (a, b, r > 0);
ar < as if 0 < a < 1 and r > s; ar > as if a > 1 and r > s; 1r = 1.
(1)
Henceforth, we assume these formulas known for rational r, s > 0.
Next we deﬁne ar for any real r > 0 and any element a > 1 in a complete
ﬁeld F. Let Aar denote the set of all elements of F of the form ax, where x is
a rational number, 0 < x ≤r; i.e.,
Aar = {ax | 0 < x ≤r, x rational}.
By the density of rationals in E1 (Theorem 3 of §10), such rationals x exist;
so Aar ̸= ∅.

94
Chapter 2. The Real Number System
Moreover, Aar is right-bounded in F. Indeed, ﬁx any rational number y > r.
By formulas (1), we have, for any positive rational x ≤r,
ay = ax+(y−x) = axay−x > ax
(since a > 1, and y −x > 0 implies ay−x > 1). Thus, ay is an upper bound of
all ax in Aar.
By the assumed completeness of F, sup Aar exists; so we may (and do)
deﬁne
ar = sup Aar.1
We also deﬁne
a−r = 1
ar .
If 0 < a < 1 (so that 1
a > 1), we set
ar =
1
a
−r 
and a−r = 1
ar

,
where
1
a
r
= sup A1/a,r,
as above. Summing up, we have the following.
Deﬁnition 2.
Given a > 0 in a complete ﬁeld F and r ∈E1, we deﬁne the following:
(i) If r > 0 and a > 1, then
ar = sup Aar,
with Aar as above.
(ii) If r > 0 and 0 < a < 1, then
ar =
1
(1/a)r ,
also written (1/a)−r.
(iii) a−r = 1/ar (this deﬁnes powers with negative exponents, too).
We also deﬁne 0r = 0 for any real r > 0, and a0 = 1 for any a ∈F, a ̸= 0;
00 remains undeﬁned.
The power ar is also deﬁned if a < 0, provided r ∈N (see §6), hence also
if r is an integer < 0 (then ar = 1/a−r), and even if r is a rational m/n, with
1 Note that if r is itself a positive rational, then ar is the largest ax with x ≤r (where ar
and ax are as in Deﬁnition 1). Thus ar = max Aar = sup Aar, and so our present deﬁnition
agrees with Deﬁnition 1.

∗§12. Powers with Arbitrary Real Exponents
95
n odd, because ar =
n√
am has sense in this case, even if a < 0. (Why?) This
does not work for other values of r. Therefore, in general, we assume a > 0.
Again, one can show that formulas (1) hold also for powers with real expo-
nents, provided F is complete (see the problems below).
Problems on Powers
1. Verify formulas (1) for powers with positive rational exponents r, s.
2. Prove that if A consists of positive elements only, then q = sup A iﬀwe
have
(i) (∀x ∈A) x ≤q, and
(ii) (∀d > 1) (∃x ∈A) q
d < x.
[Hint: Use Corollary 1 of §9.]
In Problems 3–9, the ﬁeld F is assumed complete.
3. Prove that (i) ar+s = aras and (ii) ar−s = ar/as for r, s ∈E1 and a > 0
in F.
[Hint: (i) If r, s > 0 and a > 1, use Problem 9 of §9, to get
aras = sup Aar · sup Aas = sup(Aar · Aas).
Verify that
Aar · Aas = {axay | x, y ∈R, 0 < x ≤r, 0 < y ≤r}
= {az | z ∈R, 0 < x ≤r + s},
where R = rationals. Hence, deduce
aras = sup(Aa,r+s) = ar+s
by Deﬁnition 2.
(ii) If r > s > 0 and a > 1 then, by (i), ar−sas = ar; so ar−s = ar/as. For the
cases r < 0 or s < 0, or 0 < a < 1, use above results and Deﬁnition 1(ii)–(iii).]
4. From Deﬁnition 2, prove that if r > 0 (r ∈E1), then
a > 1 ⇐⇒ar > 1
for a ∈F (a > 0).
5. Prove for r, s ∈E1 that
(i) r < s ⇐⇒ar < as if a > 1;
(ii) r < s ⇐⇒ar > as if 0 < a < 1.
[Hint: By Problems 3–4,
as = ar+(s−r) = aras−r > ar
since as−r > 1 if a > 1 and s −r > 0. If 0 < a < 1, use Deﬁnition 2(ii).]

96
Chapter 2. The Real Number System
6. Prove that
(ab)r = arbr and
a
b
r
= ar
br
for r ∈E1 and positive a, b ∈F.
[Hint: Proceed as in Problem 3.]
7. Given a, b > 0 in F and r ∈E1, prove the following:
(i) a > b ⇐⇒ar > br if r > 0; and
(ii) a > b ⇐⇒ar < br if r < 0.
[Hint:
a > b ⇐⇒a
b > 1 ⇐⇒
  a
b
r > 1
if r > 0, by Problems 4 and 6.]
8. Prove that (ar)s = ars for r, s ∈E1 and a ∈F (a > 0).
[Outline: First let r, s > 0 and a > 1. Use Problem 2 to show that
(ar)s = ars = sup Aa,rs = sup{axy | x, y ∈R, 0 < xy ≤rs},
with R = {rationals}. Thus, prove the following:
(i) (∀x, y ∈R | 0 < xy ≤rs) axy ≤(ar)s, which is easy; and
(ii) (∀d > 1) (∃x, y ∈R | 0 < xy ≤rs) (ar)s < daxy. To do this, ﬁx any d > 1 and
set b = ar. Then
(ar)s = bs = sup Abs = sup{by | y ∈R, 0 < y ≤s}.
Hence there is some y ∈R (0 < y ≤s) such that
(ar)s < d
1
2 (ar)y. (Why?)
Fix that y. Now,
ar = sup Aar = sup{ax | x ∈R, 0 < x ≤r};
so
(∃x ∈R | 0 < x ≤r)
ar < d
1
2y ax. (Why?)
Combining all, and using formulas (1) for rational x, y, obtain
(ar)s < d
1
2 (ar)y < d
1
2 (d
1
2y ax)y = daxy,
proving (ii). Proceed.]

∗§13. Decimal and Other Approximations
97
∗§13. Decimal and Other Approximations
The reader is certainly familiar with decimal approximations of real numbers;
e.g.,
√
2 = 1.414213 . . . .
A terminating decimal fraction is a sum of powers of 10 multiplied by certain
coeﬃcients (the “digits”); e.g.,
1.413 = 1 · 100 + 4 · 10−1 + 1 · 10−2 + 3 · 10−3.
The idea behind decimal approximations is best explained geometrically.
Given a real number x > 0, we ﬁrst ﬁnd a “coarse” decimal approximation of
the form 10s−1 ≤x < 10s, where s is an integer (possibly 0 or negative).
Note 1. Such an s exists and is unique. For, by the binomial theorem,
10n = (1 + 9)n = 1 + 9n + · · · > 9n;
hence, by the Archimedean property, 10n > 9n > x for large n. Similarly,
10m > 1
x for some natural m, and so
10−m < x < 10n.
Thus, the set of all integers n such that 10n > x is nonvoid and bounded below
(e.g., by −m). By Theorem 2 of §10, there is a least such n; call it s. Then
10s > x ≥10s−1,
as required.
Thus, x is in the interval [10s−1, 10s). To ﬁnd a better approximation, we
subdivide this interval into 9 equal subintervals of length 10s−1. Then x must
be in one of these subintervals; let it be
[x1, x1 + 10s−1),
where x1 is some multiple of 10s−1; say,
x1 = m1 · 10s−1.
Thus,
x1 ≤x < x1 + 10s−1.
Next we subdivide [x1, x1+10s−1) into 10 still smaller subintervals of length
10s−2. Again one of them must contain x; let it be
[x2, x2 + 10s−2),
where x2 is obtained from x1 by marking oﬀsome multiple of 10s−2; say,
x2 = x1 + m2 · 10s−2.

98
Chapter 2. The Real Number System
Then we subdivide the interval [x2, x2 + 10s−2) into 10 still smaller intervals,
of length 10s−3, and so on. At the n-th step, x is enclosed in an interval
[xn, xn + 10s−n),
approximating x to within 10s−n. Thus one obtains decimal approximations
as accurate as is desired.
Instead of using powers of 10, one could use powers of any other number
q > 1 to obtain, quite similarly, approximations to within qs−n. Moreover, this
is possible not only in E1, but in any Archimedean ﬁeld F.
Indeed, ﬁxing q > 1 and any x > 0 in F, we ﬁnd, exactly as before, a whole
number s such that
qs−1 ≤x < qs.
Then, by the Archimedean property of F there is an integer m1 in F such that
(m1 + 1)qs−1 > x.
Taking the least such m1, we also achieve that
m1qs−1 ≤x.
(Why?) For brevity, let x1 = m1qs−1, so
x1 ≤x < x1 + qs−1.
We also put x0 = 0. Note that 1 ≤m1 < q. For if m1 ≥q, then
m1qs−1 ≥qqs−1 = qs > x,
contrary to m1qs−1 ≤x.
Now, proceeding by induction, suppose that the xn and the integers mn in
F have already been deﬁned (up to some n) in such a manner that
xn ≤x < xn + qs−n,
xn = xn−1 + mnqs−n,
and
0 ≤mn < q.
(1)
Then let mn+1 + 1 be the least integer in F, with
x < xn + (mn+1 + 1)qs−(n+1);
equivalently, mn+1 is the largest integer such that
xn + mn+1 · qs−(n+1) ≤x.
Setting
xn+1 = xn + mn+1 · qs−(n+1),
we have
xn+1 ≤x < xn+1 + qs−(n+1).

∗§13. Decimal and Other Approximations
99
Moreover, 0 ≤mn+1 < q; for if mn+1 ≥q, then
xn + xn+1 · qs−(n+1) ≥xn + qqs−(n+1) = xn + qs−n > x
(by (1)),
contrary to our choice of mn+1.
Thus, by induction, we obtain two inﬁnite sequences {xn} and {mn} in F
such that the mn are integers in F (0 ≤mn < q), and (1) holds for all n. We
call xn the n-th q-ary approximation of x (from below). In particular, if q = 2,
q = 3, or q = 10, we speak of binary, ternary, or decimal approximations,
respectively.
If the integers mn (called q-ary digits) and s are given, they
determine all xn uniquely. Indeed, setting n = 1, 2, 3, . . . in the second part
of (1), we obtain (with x0 = 0), step by step,
xn = m1qs−1 + m2qs−2 + · · · + mnqs−n,
n = 1, 2, 3, . . . .
(2)
The inﬁnite sequence s, m1, m2, . . ., mn, . . . is called the q-ary (e.g., bi-
nary, ternary, decimal) expansion of x. Customarily, one brieﬂy writes x =
m1m2 . . . , indicating the value of s by placing a dot (the “q-ary point”) at an
appropriate step (namely, after the coeﬃcient ms of q0).
Note 2. If s is negative (say, s = −p), we insert p + 1 zeros before m1 and
place the “dot” after the ﬁrst zero so inserted.
Note 3
If all mn from some digit onward are equal to some m, we say that
{mn} terminates in m (any such repeating digit or group of digits is called the
period of {mn}). This m cannot be q −1 (cf. Problem 3). If m = 0, we simply
say that {mn} terminates, and we may omit the zeros at its “end”. Then, for
suﬃciently large n, xn = x; that is, formula (2) expresses x exactly.
Examples.
(1) The decimal expansion of 40/33 is 1.2121212 . . ., also written 1.2(12)
where (12) is the repeating “period” of the expansion. Here s = 1 since
101 > 40/33 > 100; and m1 = 1, m2 = 2, m3 = 1, and so on. In practice,
the digits mn are found by the familiar division algorithm.
(2) The binary expansion of 10 is 1010.000 . . . (brieﬂy, 1010).
Here s =
4 since 24 > 10 > 23; we have 10 = 1 · 23 + 0 · 22 + 1 · 21 + 0 · 20,
i.e., m1 = 1, m2 = 0, m3 = 1, m4 = m5 = m6 = · · · = 0. The expansion
terminates, and we may omit the zeros at its “end”, leaving, however,
the zero preceding the “binary” point, so as to indicate the value of s.
Observe that the digits mn in a binary expansion can have only the value
0 or 1 since 0 ≤mn < q = 2. Similarly, in ternary expansions, mn is
either 0 or 1 or 2.
In practice, the q-ary expansion of x is obtained by “trying” to represent x
as a sum of powers of q (i.e., qs−1, qs−2, . . .) multiplied by suitable coeﬃcients
mn < q (mn ≥0); the latter are the digits. If the process does not terminate,

100
Chapter 2. The Real Number System
one obtains an inﬁnite sequence of q-ary approximations xn, as in formula (2).
In all cases, we have the following.
Theorem 1. Every element x > 0 in an Archimedean ﬁeld F is the supremum
of the set {x1, x2, . . . , xn, . . .} of its q-ary approximations (q > 1, q ∈F).
Proof. By the deﬁnition of the xn, we have
xn ≤x < xn + qs−n,
n = 1, 2, . . . .
Thus none of the xn exceeds x, and so x is an upper bound of all xn.
It remains to show that x is the least upper bound. Seeking a contradiction,
suppose there is a smaller upper bound y, y < x. Then we have
xn ≤y < x < xn + qs−n,
and hence
0 < x −y < (xn + qs−n) −xn = qs−n,
i.e., 0 < x −y < qs/qn, or
qn(x −y) < qs,
n = 1, 2, 3, . . . .
But this is incompatible with the Archimedean property. (Why?) Thus the
theorem is proved.
□
If the ﬁeld F is complete and q is an integer > 1, the process described
above can be reversed. More precisely, we have the following.
Theorem 2. Let s be an integer in E1, and let q and mn (n = 1, 2, 3, . . . ) be
integers in a complete ﬁeld F, with q > 1, 0 ≤mn ≤q −1, and m1 ≥1. If the
sequence {mn} does not terminate in q −1, there is a unique element x > 0 in
F, whose q-ary expansion, as deﬁned above, is exactly s, m1, m2, . . . , mn, . . . .
Proof. With q, s and mn as above, deﬁne
xn =
n
X
k=1
mkqs−k,
yn =
n
X
k=1
(q −1)qs−k,
n = 1, 2, 3, . . . ,
so that the xn are as in (2). As mk ≤q −1, we have xn ≤yn. Moreover, as
{mk} does not terminate in q −1, we have mk < q −1 for inﬁnitely many k,
and hence xn < yn for large n so that dn = yn −xn > 0, and the diﬀerences
dn increase with n. So also do xn and yn. Let d be one of the dn > 0. Then,
for suﬃciently large n, yn −xn = dn > d > 0, and we obtain
qs−1 ≤
n
X
k=1
mkqs−k = xn < yn−d =
n
X
k=1
(q−1)qs−k −d = qs−qs−n−d < qs−d.

∗§13. Decimal and Other Approximations
101
Thus, the set of all xn is bounded above by qs −d; so, by completeness, it
has a supremum; call it x. By Corollary 2 of §9,
qs−1 ≤x = sup xn ≤qs −d < qs.
Also, for p > n, we obtain as above (for suﬃciently large p and some d0 > 0)
xp −xn =
p
X
k=n+1
mkqs−k
<
p
X
k=n+1
(q −1)qs−k −d0
= qs−n −qs−p −d0
< qs−n −d0,
(3)
whence xp < xn +qs−n −d0. Keeping n ﬁxed and passing to supp>n xp, we get
x = sup
p>n xp ≤xn + qs−n −d0 < xn + qs−n.
Thus, xn ≤x < xn + qs−n for each n.
Finally, from xn = Pn
k=1 mkqs−k, we obtain
xn+1 =
n+1
X
k=1
mkqs−k = xn + mn+1qs−(n+1).
This, combined with the previously obtained inequalities,
xn ≤x < xn + qs−n and qs−1 ≤x < qs,
shows that the xn coincide with the q-ary approximations of x as deﬁned in
(1) and (2), and that s, m1, m2, . . . , mn, . . . is the q-ary expansion of x, as
required. The proof is complete.
□
Thus, we see that, for any integer q > 1 in a complete ﬁeld F, there is a
one-to-one correspondence between positive elements x ∈F and their q-ary
expansions, i.e., sequences s, m1, m2, . . ., mn, . . . , not terminating in q −1
and such that 0 ≤mn < q and m1 ≥1 (with s an integer in E1, and mn
integers in F). By Theorem 1, x is the supremum of all xn, i.e., sums of the
form (2). This supremum is denoted by
∞
X
k=1
mkqs−k.
The representation of x as a supremum of ﬁnite sums is not unique. For ex-
ample, in decimal notation, 2 = 2.0000 . . .; but 2 is also the supremum of

102
Chapter 2. The Real Number System
approximations of the form 1.9999 . . . . However, as noted above, our deﬁni-
tions exclude q −1 as a period, and so uniqueness is achieved.
Problems on Decimal and q-ary Approximations
1
1. Why is there a largest integer mn such that xn−1 + mnqs−n ≤x?
2. Given c > 0 and 0 < r < 1, show that c/(1 −r) is the supremum of all
sums
n
X
k=1
crk,
n = 1, 2, . . . .
[Hint: Compute Pn
k=1 crk from Problem 9 in §6.]
3. Why can q −1 never occur as a period, by our deﬁnitions?
[Hint: If (∀n > p) mn = q −1, formula (2) yields xn = xp + qs−p −qs−n. (Verify!)
From Problem 2, show that x = sup xn = xp + qs−p, contrary to formula (1).]
4. Write in binary and ternary notation the following decimal expressions:
a) 2.311;
b) 23.11;
c) 231.11;
d) 231110;
e) 45/4;
f) 1/3.
5. Write the following binary fractions in decimal and ternary notation:
a) 1.0101;
b) 1001, 001;
c) 10100.1;
d) 0.0001001;
e) 0.0010001.
6. Explain how (and why) decimal expansions of rationals m/n can be ob-
tained by repeated division (cf. Problem 20 of §6). Similarly for q-ary
expansions, with q an integer > 1.
7. Let q be an integer > 1. Show that the q-ary expansion of x is periodic2
iﬀx is a rational, m/n.
[Hint: If x = m/n, consecutive division by n yields remainders < n. As there are
only ﬁnitely many such remainders, they must eventually repeat. For the converse,
use Problem 2 and Theorem 1.]
8. Using the result of Problem 2, ﬁnd x from its periodic q-ary expansion:
a) x = 0.00(13), q = 10;
b) same with q = 4;
c) same with q = 5.
9. Answer the question (“why?”) posed at the end of the proof of Theorem 1.
∗§14. Isomorphism of Complete Ordered Fields
We shall now show that, in a sense, there is only one complete ordered ﬁeld.
That is, all such ﬁelds have the same mathematical properties as E1 and thus
cannot be distinguished mathematically from E1.
1 In these problems, q > 1, x, xn and mn are elements of an Archimedean ordered ﬁeld
F , deﬁned as above in §13. The mn are integers in F .
2 The sequence {mn} is called periodic iﬀit terminates in consecutive repetitions of a
ﬁnite subsequence (p1, p2, . . . , pk), possibly (0).

∗§14. Isomorphism of Complete Ordered Fields
103
Deﬁnition 1.
Two ﬁelds, F and F ′, are said to be isomorphic iﬀthere is a one-to-one
mapping f: F ↔
onto F ′ such that (denoting addition and multiplication in
both ﬁelds by the same symbols, + and ·)
(∀x, y ∈F)
f(x + y) = f(x) + f(y) and f(x · y) = f(x) · f(y).
(1)
If F and F ′ are ordered ﬁelds, we also require that
(∀x, y ∈F)
x < y ⇐⇒f(x) < f(y).
(2)
In other words, the mapping f (called an isomorphism between F and F ′)
establishes a one-to-one correspondence between elements x ∈F and f(x) ∈F ′
that carries the sum and product of any elements x, y ∈F into the sum and
product, respectively, of f(x) and f(y) in F ′. We brieﬂy say that f preserves
the operations in F and F ′. In the ordered case, the map f is also supposed
to preserve order (formula (2)). Writing brieﬂy x′ for f(x), we may say that,
under the correspondence x ↔x′, sums correspond to sums and products
correspond to products:
(x + y) ↔(x′ + y′),
xy ↔x′y′.
Thus, any formula valid in F can be “translated” into a formula valid in F ′;
one only has to replace
x, y, z, . . . ∈F by x′, y′, z′, . . . ∈F ′.
Anything that can be proved in F can also be proved in F ′, and conversely. In
ordered ﬁelds, this applies to inequalities as well, due to (2). Thus F ′ behaves
exactly like F, as far as ﬁeld operations and inequalities are concerned. There-
fore, it is customary not to distinguish between two isomorphic ﬁelds F and
F ′, even though their elements may be objects of diﬀerent nature. (Compare
this to playing one and the same game of chess or cards with two diﬀerent sets
of chessmen or decks of cards: it is not the color or shape of the chessmen but
the game itself that really matters.)
Consequently, if F and F ′ are isomorphic, we treat them as just two “copies”
of the same ﬁeld; we call F ′ the isomorphic image of F (under the isomorphism
f) and brieﬂy write
F ∼= F ′, or F
f∼= F ′.
The same deﬁnitions and conventions also apply if F and F ′ are any sets (not
necessarily ﬁelds) with some “addition” and “multiplication” deﬁned in them,
satisfying the closure law but not necessarily the other ﬁeld axioms. If only one
operation in F and F ′ (say, addition) is considered, or deﬁned, the isomorphism
f is supposed to preserved this particular operation: f(x + y) = f(x) + f(y).
We then say that F and F ′ are isomorphic with respect to addition (though,

104
Chapter 2. The Real Number System
possibly, not with respect to multiplication).1
Order isomorphism (2) may
apply to any ordered sets, regardless of operations.
Note.
If the map f satisﬁes (1) but is not necessarily one-to-one or onto
F ′, we call it a homomorphism (of F into F ′).
Examples.
(a) Let F = E1 and let F ′ be the set of all ordered pairs of the form (x, 0),
x ∈E1. For such pairs, deﬁne
(x, 0) + (y, 0) = (x + y, 0), (x, 0) · (y, 0) = (xy, 0);
and
(x, 0) < (y, 0) ⇐⇒x < y.
It is easy to verify that F ′ is an ordered ﬁeld under these operations, and
the mapping x ↔(x, 0) is an isomorphism satisfying both (1) and (2).
Thus E1 ∼= F ′.
(b) Let N be the set of all natural numbers, and let N ′′ be the set of all even
elements of N. Deﬁne the mapping f: N →N ′′ by f(x) = 2x. This map
is one-to-one and onto N ′′. (Verify!) Moreover,
(∀x, y ∈N)
f(x + y) = 2(x + y) = 2x + 2y = f(x) + f(y).
Thus f preserves addition; so it is an isomorphism with respect to addition
(but not with respect to multiplication). It also preserves the order since
we have
x < y iﬀ2x < 2y, i.e., f(x) < f(y).
Thus, N ∼= N ′′, with respect to addition and order.
(c) The identity map I: F ↔F, deﬁned by I(x) = x, obviously preserves
any operations or ordering deﬁned in F; e.g., for multiplication, we have
I(xy) = xy = I(x) · I(y). Thus, I is an isomorphism of F onto itself :
F
I∼= F.
Below, N and R will denote the naturals and rationals in E1, while N ′
and R′ are the corresponding sets in some arbitrary ordered ﬁeld F.
The
unity element of F is denoted by 1′ to distinguish it from 1 ∈E1. From §6
(Deﬁnition 3 and the subsequent note), we recall that, for any n ∈N and
a ∈F,
na = a + a + · · · + a
(n terms).
We shall now deﬁne ra for any r ∈R and a ∈F.
1 Of course, it does not matter whether the operation involved is denoted by (+) or some
other symbol and whether it is called “addition” or some other name. It may also occur that
the operations in F and F ′ have diﬀerent names and are diﬀerently denoted.

∗§14. Isomorphism of Complete Ordered Fields
105
Deﬁnition 2.
Given any element a of a ﬁeld F, and a rational number r = m/n ∈E1
(m, n ∈N), we deﬁne
ra = ma
n · 1′
(1′ being the unity of F). We also put
(−r) · a = −ra and 0 · a = 0′ ∈F.
Note that ra ∈F in all cases.
This deﬁnition is unambiguous, inasmuch as it does not depend on the par-
ticular representation of r as a fraction m/n. For, if r = m/n = p/q for some
m, n, p, q ∈N, then mq = np, whence (mq) (a · 1′) = (np)(a · 1′). It easily
follows [cf. Problem 11(vii) in §6] that (ma) · (q1′) = (pa) (n1′), and hence
pa
q1′ = ma
n1′ = ra.
Thus, indeed, ra is uniquely determined. Moreover, if r ∈N, i.e., r = m/l,
then
ra = ma
1 · 1′ = ma
1′ = ma.
Thus, for a natural r, Deﬁnition 2 agrees with our previous deﬁnition of the
natural multiple ma, and so there is no danger of contradiction. We now obtain
the following.
Theorem 1. For any elements a and b of a ﬁeld F and any rational numbers
r and s (in E1), we have the following:
(i) ra + sa = (r + s)a;
(ii) ra · sb = (rs) (ab);
(iii) r(a + b) = ra + rb;
(iv) if F is an ordered ﬁeld, we also have ra < sa iﬀr < s, provided a > 0′.
Indeed, if r, s ∈N, all this follows from Problems 11(vi)–(viii) and 11′ of
§6. The general case (r, s ∈R) easily follows by Deﬁnition 2. We leave the
details to the reader.
Theorem 2. The ordered subﬁeld R of E1 (i.e., the ﬁeld of all rational num-
bers) is isomorphic with the rational subﬁeld R′ of any other ordered ﬁeld F
(with zero element 0′ and unity 1′).
Proof. As was noted at the end of §7, R and R′ are ordered ﬁelds (subﬁelds of
E1 and F, respectively). To establish their isomorphism, we deﬁne a mapping
f: R →R′ by setting
f(x) = x · 1′
for x ∈R.

106
Chapter 2. The Real Number System
Then, by Theorem 1, (∀x, y ∈R)
f(x + y) = (x + y) · 1′ = x1′ + y1′ = f(x) + f(y)
and
f(xy) = (xy) · 1′ = (x1′) · (y1′) = f(x) · f(y).
Thus, f preserves the operations.
By part (iv) of the theorem, f also preserves order. This also implies that
f is one-to-one; for, if
x ̸= y
(x, y ∈R),
then either
x < y or x > y,
whence
f(x) < f(y) or f(x) > f(y),
and in both cases f(x) ̸= f(y), as required.
It only remains to show that f is onto R′, i.e., that each element r′ ∈R′ has
the form r′ = f(x) for some x ∈R. Let
r′ = m′
n′
(m′, n′ ∈N).
Now, by Problem 11′ of §6, we have
m′ = m · 1′ and n′ = n · 1′
for some m, n ∈N. Hence,
r′ = m′
n′ = m · 1′
n · 1′ .
Setting x = m/n, we have, by deﬁnition,
f(x) = x · 1′ = m1′
n1′ = r′.
Thus, our assertion is proved in case r′ > 0′.
If, however, r′ < 0′, then −r′ > 0′; so, by what was proved above, −r′ =
f(x) = x · 1′ for some x ∈R, and it easily follows that r′ = (−x) · 1′ = f(−x).
Finally, 0′ = 0 · 1′ = f(0), by deﬁnition. Thus, f is, indeed, onto R′. This
completes the proof.
□
Observe that the map f carries naturals and integers of E1 onto those of
F. Thus, we have also proved that the set F of all natural numbers (in E1) is
isomorphic, with respect to addition, multiplication, and order, to the set N ′
of all naturals in any ordered ﬁeld F, and similarly for the integers (J and J′).
Because of the isomorphism established above, we may regard R and R′ as
“copies” of one and the same set and not distinguish between them. Similarly

∗§14. Isomorphism of Complete Ordered Fields
107
for N and N ′, or J and J′. Thus, henceforth, we adopt the convention that
R, N, and J are the same in each ordered ﬁeld F, so that each F contains the
rational numbers, R, themselves (R = R′). In particular, 0 = 0′, 1 = 1′, and
r · 1′ = r · 1 = r for any rational r.
Next, let F be complete. Then one can deﬁne ra (a ∈F) for any real r, in
much the same manner as we deﬁned ar in §12. Fixing ﬁrst some r > 0 in E1
and a > 0′ in F, let
Ara = {xa | x ∈R, 0 < x ≤r};
i.e., Ara is the set of all xa (deﬁned as in Deﬁnition 2), with x ∈R, 0 < x ≤r.
Clearly, Ara ̸= ∅and, by Theorem 1(iv), Ara is right-bounded in F by any ya,
with y ∈R, y > r. Thus, by completeness, sup Ara exists in F; so we deﬁne
ra = sup Ara
(r > 0, a > 0′).
(3)
If, in particular, r is rational then, by Theorem 1(iv), ra is the largest of
all xa in Ara; so ra (as in Deﬁnition 2) equals sup Ara = max Ara. Thus, in
the rational case, our new deﬁnition of ra agrees with Deﬁnition 2. Finally, if
r < 0, we put ra = −(−r)a, and if a < 0′, we deﬁne ra = −[r(−a)]. Thus, ra
is deﬁned for all r ∈E1 and all a ∈F.
It is easy to verify that Theorem 1 remains valid for arbitrary real r and s
(provided F is complete); cf. Problems 2–4 below. We now have the following.
Theorem 3. Any complete ordered ﬁeld F is isomorphic with E1.
Proof. As before, we deﬁne f: E1 →F by setting
f(r) = r · 1′
for r ∈E1.
Exactly as in Theorem 2, it follows that f preserves the operations and the
order and is one-to-one. Only the fact that f is onto F requires a diﬀerent
proof.
Given any q ∈F, we have to ﬁnd an r ∈E1 such that q = f(r) = r · 1′.
First let q > 0′, and let
Q′ = {x ∈R′ | 0 < x ≤q};
i.e., Q′ consists of all rational x such that 0 < x ≤q in F. Clearly, q is an upper
bound of Q′. Moreover, there is no smaller upper bound; for if p < q then, by
the density of rationals in the complete ﬁeld F, there is x ∈R′ with p < x < q
(x > 0), so that x ∈Q′ and x > p, and hence p is not an upper bound of Q′.
Thus q = sup Q′. It also follows that Q′ has rational upper bounds (take any
rational y > q).
Since R′ = R, we may also regard Q′ as a set of rationals in E1, with rational
upper bounds in E1. Thus Q′ also has a supremum in E1; call it r. Let us

108
Chapter 2. The Real Number System
denote Q′ by Q when it is regarded as a subset of E1.2 Thus
Q = {x ∈R | 0 < x ≤r} in E1,
while
Q′ = {x ∈R′ | 0′ < x ≤q} in F.
More precisely, the sets Q and Q′ correspond to each other under the isomor-
phism
x ↔x · 1′.
Thus Q′ is exactly the set of all elements in F of the form
x · 1′
(x ∈R, 0 < x ≤r).
In other words, Q′ = Ara with a = 1′, and
q = sup Q′ = sup Ara = r · 1′ = f(r);
i.e., q has the form f(r) for some r ∈E1, as required. This proves our assertion
in case q > 0′.
On the other hand, if q < 0′, then −q > 0′ and hence, by what was proved
above, −q = f(s) for some s ∈E1. Hence, by deﬁnition, f(−s) = q; so our
assertion is true in the negative case as well.
Finally, by deﬁnition, 0′ = f(0). Thus every element of F has the form f(r),
r ∈E1, and so f is indeed onto F. This completes the proof.
□
The theorems that we have proved show that, except for isomorphic “copies”,
there is only one complete ordered ﬁeld (E1), only one rational ordered ﬁeld
(R), and only one ordered system of naturals (N). We express this brieﬂy by
saying that E1, R, and N are unique to within isomorphism. Due to this, we
may henceforth treat natural multiples na (n ∈N, a ∈F) as products in F;
similarly for rational multiples ra (r ∈R, a ∈F).
While the uniqueness of E1 is thus established, there still remains the ques-
tion of its existence.
Indeed, right from the start, E1 was introduced only
axiomatically; that is, we have assumed that there is some set E1 with two
operations (+) and (·) and an order relation < satisfying our Axioms I–X (in-
cluding completeness). However, this fact was never proved. In the next sec-
tion, we shall take up the problem of constructing E1 from simpler structures,
thus proving its existence.
2 To make the same distinction, we also continue writing R′, N′, 1′, and 0′ for the rationals,
naturals, unity, and zero of F , even though R′ = R by our convention.

∗§14. Isomorphism of Complete Ordered Fields
109
Problems on Isomorphisms
1. Complete the proof of Theorem 1.
2. Prove parts (i)–(iii) of Theorem 1 for positive real r, s and positive a, b
in a complete ﬁeld F.
[Hint: Proceed as in Problems 8 and 9 in §9 to show that
sup Ara · sup Asb = sup Ars,ab and sup Ara + sup Asb = sup(Ar+s,a+b).
Then apply formula (3) from p. 107, noting that Theorem 1 holds for rational r, s.]
3. Solve Problem 2 for arbitrary r, s ∈E1 and a, b ∈F.
[Hint for part (i): Let ﬁrst r > s > 0, a > 0′. As r −s > 0, Problem 2 yields
(r −s)a + sa = (r −s + s)a = ra,
whence (r −s)a = ra −sa.
This holds also if s > r > 0 since, by deﬁnition, (r −s)a = −(s −r)a, where
s −r > 0; so, as shown above, (s −r)a = sa −ra, and hence
(r −s)a = −(sa −ra) = ra −sa.
Thus (r ± s)a = ra ± sa for positive r, s, a. Now, if r > 0 > s and a > 0′, then
−s > 0 and hence (r + s)a = [r −(−s)]a = ra + sa. Similarly in the other cases.]
4. Prove part (iv) of Theorem 1 for any real r, s and any a, b in a complete
ordered ﬁeld F.
[Hint:
r < s =⇒s −r > 0 =⇒(s −r) · 1′ > 0′,
by the very deﬁnition of multiples ra for positive r, a (here a = 1′). But, by Problem 3,
(s −r) · 1′ = s1′ −r1′ = f(s) −f(r);
thus f(s) −f(r) > 0′, as required. Conversely, if f(r) < f(s), we cannot have r ≥s
(why?), and so r < s.]
Give also a direct proof based on properties of suprema (without referring
to Problem 3).
5. Let F and F ′ be two ﬁelds, with zero-elements 0 and 0′, and unities 1
and 1′, respectively. Prove that if f: F ↔
onto F ′ is an isomorphism, then
(i) f(0) = 0′;
(ii) f(1) = 1′;
(iii) (∀x ∈F) f(−x) = −f(x), and f
 1
x

=
1′
f(x) (the latter if x ̸= 0).
Also show (by induction) that
x ∈N iﬀf(x) ∈N ′,
i.e., f[N] = N ′ (with N and N ′ as in the text). Hence, infer that f[J] = J′
and f[R] = R′.

110
Chapter 2. The Real Number System
[Hint for part (i): To prove that f(0) is the zero element of F ′, show that (∀y ∈F ′)
y + f(0) = y, noting that y = f(x) for some x (why?), and using (1) from p. 103. Use
similar arguments for parts (ii) and (iii).]
6. With the notation of Problem 5, let F and F ′ be ordered ﬁelds, F
f∼= F ′.
Prove by induction that
(∀n ∈N)
(n) = n · 1′,
and infer that
(∀r ∈R)
f(r) = r · 1′,
with r · 1′ as in the text. Also show that if p = sup A (A ⊂F), then
f(p) = sup f[A] in F ′, and similarly for inﬁma. (The last part also holds
for order-isomorphisms of ordered sets, regardless of operations.)
7. Continuing Problem 6, show that if F and F ′ are Archimedean ﬁelds,
with F
f∼= F ′, then necessarily
(∀x ∈F)
f(x) = x · 1′
(with x · 1′ deﬁned as in the text, for x ∈E1). Thus there is at most one
isomorphism f: F ↔
onto F ′.
8. Show that the relation of isomorphism is reﬂexive, symmetric, and tran-
sitive, i.e., an equivalence relation.
[Hint: F
I∼
= F by Example (c). Show that F
f∼
= F ′ and F ′ g∼
= F ′′ implies F ′ f−1
∼
= F and
F
h∼
= F ′′, where h(x) = g(f(x)).]
∗§15. Dedekind Cuts. Construction of E
1
I. In the problems of §7 in Chapter 1, we sketched a method of constructing
integers from naturals, and rationals from integers. Now we shall show how
reals can be constructed from rationals. More generally, we shall show how
an Archimedean ﬁeld R can be extended to a complete one, and consider a
similar problem for ordered sets in general.1 This can be done by using so-
called Dedekind cuts (R. Dedekind, German mathematician, 1831–1916). We
deﬁne them now for any ordered set R.
1 We recall from §2 that an ordered set is a set in which a transitive and trichotomic
relation “<” is deﬁned. The notions of upper and lower bound, supremum, inﬁmum, etc. are
deﬁned in such a set exactly as in ordered ﬁelds. Similarly for “completeness”.

∗§15. Dedekind Cuts. Construction of E1
111
Deﬁnition 1.
A Dedekind cut (brieﬂy, cut) in an ordered set R is a pair (A, B) of
nonempty subsets of R such that A is exactly the set of all lower bounds
of B, and B is the set of all upper bounds of A, in R.
A cut (A, B) is called a gap (in R) iﬀA ∩B = ∅.
If (A, B) is not a gap, i.e., A∩B ̸= ∅, then A∩B consists of a single element;
for, by the deﬁnition of (A, B), any element p ∈A ∩B is an upper bound of A
(since p ∈B) and hence p = max A (for p ∈A); similarly, p = min B. Thus,
by the uniqueness of max A and min B,
p = max A = min B is unique.
From Deﬁnition 1, it also follows that
y ≤x ∈A =⇒y ∈A; and y ≥x ∈B =⇒y ∈B.
(Why?) In the examples below, R is the set of all rationals.
Examples.
(1) Let p ∈R, let
A = {x ∈R | x ≤p},
B = {x ∈R | x ≥p}.
This yields a cut (A, B); it is not a gap, for maxA = min B = p ∈A ∩B.
(2) Let
A = {x ∈R | x ≤0 or x2 ≤2},
B = {x ∈R | x > 0, x2 > 2}.
Then (A, B) is a cut. (Verify!) It is a gap since A ∩B = ∅. Also, max A
and min B do not exist in R (cf. §11, Problem 8).
Thus, we see that there are cuts of both kinds in R: gaps and nongaps.
Theorem 1. For any cut (A, B) in an ordered set R, we have R = A ∪B.
Indeed, by Deﬁnition 1,
A ⊆R and B ⊆R,
whence A ∪B ⊆R. Conversely, if x ∈R and, say, x /∈A, then x is not a lower
bound of B; i.e.,
x > y for some y ∈B.
But, as noted above, x > y ∈B =⇒x ∈B. Similarly, if x /∈B, then x ∈A.
Thus, x must be in one of A and B, i.e., x ∈A ∪B.
□
Theorem 2. For any cuts (A, B) and (A′, B′) in an ordered set R, we have
either
A ⊂A′ or A ⊃A′ or A = A′.

112
Chapter 2. The Real Number System
Moreover,
A ⊂A′ ⇐⇒B ⊃B′.
Proof. If A ⊇A′, then either A = A′ or A ⊃A′, so there is nothing to prove.
So suppose A′ has an element r not in A. Then, by Theorem 1, r ∈B.
Hence r is an upper bound of A, i.e., (∀x ∈A) x ≤r. As
x ≤r ∈A′ =⇒x ∈A′,
we get (∀x ∈A) x ∈A′, i.e., A ⊂A′.2 Thus we have either A ⊇A′, or else
A ⊂A′, as asserted. We leave to the reader the proof that A ⊂A′ is equivalent
to B ⊃B′.
□
We shall now show that any ordered set R can be made complete by adding
to it new elements, so as to “ﬁll” its gaps. The nature of these elements may
be arbitrary; it is only required that they be diﬀerent from the original (“old”)
elements of R. Thus, for each gap (A, B) in R, we introduce a new element p
in such a manner that diﬀerent elements p correspond to diﬀerent gaps (A, B);
we shall say that this p is determined by the corresponding gap (A, B), and
conversely.
If (A, B) is not a gap then, as was shown above, there is in R an element
p = max A = min B; in this case, too, we shall say that p is determined by the
cut (A, B). Thus each cut (A, B) in R determines a certain element p that is
“new” or “old” according as (A, B) is, or is not, a gap.3 The set consisting of
the “old” and “new” elements together is called the completion of R, denoted
R. By what was said above, there is a one-to-one correspondence between all
elements of R and all cuts in R; the “new” elements correspond to gaps in R.
For brevity, we write “p ≡(A, B)” to mean that p is determined by (A, B).
Deﬁnition 2.
For any elements p ≡(A, B) and q ≡(A′, B′) in R, we write
p < q iﬀA ⊂A′, and p ≤q iﬀA ⊆A′.
Similarly for p > q and p ≥q.
The relation “<” so deﬁned is trichotomic on R by Theorem 2. It is also
transitive (for so is ⊂). Thus, it makes R an ordered set. Moreover, it agrees
with the original ordering of R if p, q ∈R. Indeed, in this case (A, B) and
(A′, B′) are not gaps, and so
A = {x ∈R | x ≤p},
A′ = {x ∈R | x ≤q}.
Hence it easily follows (by Corollary 3 of §9) that A ⊆A′ iﬀp ≤q, and A ⊂A′
iﬀp < q, under the original meaning of “p < q”in R. (Verify!)
2 A is a proper subset of A′ because r ∈A′, while r /∈A, by assumption.
3 p is said to be “old” if p ∈R and “new” if p /∈R.

∗§15. Dedekind Cuts. Construction of E1
113
Theorem 3. For any p ≡(A, B) in R,
p = sup A = inf B.
If , further, p < q in R, there always are x, y ∈R such that
p ≤x < y ≤q.
Proof. All this is trivial if p ∈R, i.e., if (A, B) is not a gap. Thus, we assume
A ∩B = ∅, i.e., p is a “new” element.
First we show that p is an upper bound of A. Take any element r ∈A. As
A ⊂R, r ∈R; so r is determined by a cut (A′′, B′′) (no gap!), with r = max A′′.
Hence,
(∀x ∈A′′)
x ≤r ∈A,
implying
(∀x ∈A′′)
x ∈A.
Thus, A′′ ⊆A, i.e., r ≤p (by Deﬁnition 2). As this holds for any r ∈A, p is
indeed an upper bound of A. Similarly it is shown that p is a lower bound of
B. We shall brieﬂy say that p “bounds” A and B.
As the next step, let p < q ≡(A′, B′). Then, by deﬁnition, A ⊂A′; so we
can ﬁnd some y ∈A′ −A. As y /∈A, we have y ∈B; so, by what was proved
above, p ≤y ≤q (for q bounds A′, and y ∈A′). Moreover, as (A, B) is a gap,
B has no minimum in R; thus, B must also contain some x < y, so that
p ≤x < y ≤q.
This proves the second clause of the theorem. It also shows that no q > p
can be a lower bound of B (for it exceeds some x ∈B). Thus, p is the greatest
lower bound of B, i.e., p = inf B. Similarly for p = sup A.
□
Note 1 It follows that if a set M ⊆R has an upper (lower) bound q in R,
then M must also have such a bound in R. For example, if q ≡(A′, B′) is an
upper bound, then (∀b ∈B′) q ≤b; so b is another bound of M, and b ∈R.
Theorem 4. The completion R of any ordered set R is a complete ordered set.
(This justiﬁes the name “completion”.)
Proof. The fact that R is an ordered set was established above. We only have
to show that any nonempty right-bounded subset M of R has a supremum in
R.
Now, by Note 1, such an M has upper bounds belonging to R. Let B ̸= ∅
be the set of all such upper bounds on M, so that B ⊆R. In turn, let A
be the set of all lower bounds of B in R. (They exist, by Note 1, for B has
left bounds in M.) As is easily seen, (A, B) is a cut in R; so it determines an
element p ≡(A, B). We shall show that p = sup M.

114
Chapter 2. The Real Number System
Indeed, by Theorem 3, p = inf B; so p is not less than any lower bound of
B, e.g., any m ∈M. Thus (∀m ∈M) m ≤p; i.e., p is an upper bound of M.
Now, seeking a contradiction, suppose there is a smaller upper bound r, r < p.
Then, again by Theorem 3, r ≤x < p for some x ∈R. Hence, x too is an
upper bound of M, and since x ∈R, it must belong to B, by the deﬁnition of
B. But this is impossible since x < p = inf B. This contradiction shows that p
is the least upper bound of M, p = sup M.
□
II. Thus far we have only assumed that R is an ordered set. Now suppose that
it is an ordered ﬁeld. Then we not only can construct the complete ordered set
R as above but also deﬁne operations in it, as follows.
Deﬁnition 3.
Let R be an ordered ﬁeld and let R be as above. Assuming that p, q ∈R,
p ≡(A, B), and q ≡(A′, B′), we have the following:
(i) We deﬁne
p + q = inf(B + B′),
where B + B′ is the set of all sums x + y, with x ∈B and y ∈B′.
(These sums are deﬁned in R, since B ⊂R and B′ ⊂R.)
(ii) We deﬁne
−p = inf(∼A),
where ∼A is the set of all additive inverses −x of elements x ∈A
(similarly for ∼B).
Note that ∼B is exactly the set of all lower bounds of ∼A in
R, and, conversely, ∼A consists of all upper bounds of ∼B. Thus
(∼B, ∼A) is a cut.
By Theorem 3, the element determined by
(∼B, ∼A) equals inf(∼A), i.e., −p. Thus −p ≡(∼B, ∼A).
(iii) If p > q and q > 0, we deﬁne
pq = inf(BB′),
where BB′ is the set of all products xy, with x ∈B, y ∈B′.
We also put p · 0 = 0 · p = 0. In case p < 0, q < 0, we put
pq = (−p)(−q).
If p < 0 < q, we deﬁne pq = −((−p)q), and if q < 0 < p, then
pq = −(p(−q)),
so as to preserve the rule of signs. This reduces everything to the
positive case; for if p < 0, then −p > 0, as easily follows from
part (ii) of the deﬁnition.

∗§15. Dedekind Cuts. Construction of E1
115
(iv) If p > 0, we deﬁne
p−1 = inf(A−1),
where A−1 is the set of all reciprocals of positive elements x ∈A.
(Such elements exist if p > 0; why?)
Finally, if p < 0, we put
p−1 = −(−p)−1.
Observe that all the inﬁma required above exist in R because R is complete
(by Theorem 4) and all sets involved are left-bounded. For, by Deﬁnition 1, B
and B′ have lower bounds r ∈A and r ∈A′, respectively. Thus
(∀x ∈B) (∀y ∈B′)
r ≤x, r′ ≤y.
As R is a ﬁeld and x, y, r, r′ ∈R, we may add the inequalities and obtain
r + r′ ≤x + y for all x + y in B + B′;
so r + r′ is a lower bound of B + B′.
Also, as A is right-bounded by some s ∈B, −A is left-bounded by −s.
All this is still simpler in parts (iii) and (iv); for the assumption p > 0,
q > 0 implies that B and B′ consist of positive elements only (why?); so 0 is a
lower bound of BB′ in (iii), and similarly in (iv). Thus, indeed, all the required
inﬁma are well-deﬁned elements of R; hence so are p + q and pq. This proves
the closure laws in R.
Finally note that if p, q ∈R, then our deﬁnition of p + q and pq agrees with
the original meaning of p + q and pq in the ﬁeld R. For, by Theorem 3, if
p = inf B and q = inf B′,
then
p + q = inf(B + B′) and pq = inf(BB′)
in R (cf. Problems 8 and 9 of §9). We can now prove our main result.
Theorem 5. With operations and inequalities (<) deﬁned as above, the com-
pletion of an Archimedean ﬁeld R is a complete ordered ﬁeld.
Proof. Closure laws, trichotomy, transitivity, and completeness have already
been veriﬁed above. The easy veriﬁcation of Axioms II–IV is sketched in Prob-
lems 9–12 below. It remains to verify V, VI, and IX.
Axiom V(a). Given an element p ≡(A, B) in R, we must show that p+(−p) =
0, where −p ≡(∼B, ∼A) by Deﬁnition 3(ii). This amounts to proving that
0 = inf[B + (∼A)], where
B + (∼A) = {y −x | y ∈B, x ∈A},
by Deﬁnition 3(i).

116
Chapter 2. The Real Number System
Now, as (A, B) is a cut, we have
(∀x ∈A) (∀y ∈B)
y ≥x,
i.e., y −x ≥0. Thus, 0 is a lower bound of the set B + (∼A), and we must
only show that 0 is the greatest lower bound.
Seeking a contradiction, suppose there is a larger lower bound, r > 0. Then,
ﬁxing any x ∈A, we have
(∀y ∈B)
r ≤y −x
since r is a lower bound of all such y −x. Thus
(∀y ∈B)
y ≥r + x,
i.e., r + x is a lower bound of B, and hence r + x ∈A, by the deﬁnition of a
cut. We see that
(∀x ∈A)
r + x ∈A.
As this applies to any x ∈A, we may replace x by r + x, and thus obtain
r + (r + x) = 2r + x ∈A. Repeating this process, we obtain
nr + x ∈A,
n = 1, 2, . . .
for any x ∈A; hence nr + x ≤y for y ∈B (for each y ∈B is an upper bound
of A). Thus, ﬁxing x ∈A and y ∈B, we get
nr ≤y −x,
n = 1, 2, . . .
contrary to the assumed Archimedean property of R. This contradiction shows
that, indeed, B + (∼A) has no lower bounds > 0, and completes the proof.
Axiom V(b) is proved quite analogously in case p > 0.
One only has to
replace everywhere addition and subtraction by multiplication and division.
Accordingly,
0, −p, B + (∼A), y −x, r + x, and nr
are replaced, respectively, by
1, p−1, BA−1, y
x, rx, and rn,
but essentially the argument is the same. Note that the binomial expansion
yields
rn = (1 + a)n = 1 + na + · · · > na
if we put r = 1 +a (using the fact that r > 1 here). Thus, by the Archimedean
property
rn > na > y
x

∗§15. Dedekind Cuts. Construction of E1
117
for large n, and this yields the required contradiction in the last part of the
proof. The details are left to the reader. Finally, the proof for p < 0 easily
follows from the positive case, by the formula p−1 = −(−p)−1. Thus Axiom V
is veriﬁed in full.
Axiom VI. Let
p ≡(A, B), q ≡(A′, B′), r ≡(A′′, B′′).
We must show that (p + q)r = pr + qr.
Assume ﬁrst that p, q, r > 0. Then it easily follows that
(p + q)r = inf[(B + B′)B′′] and pr + qr = inf(BB′′ + B′B′′);
cf. Problem 10(c). Thus all reduces to proving that
(B + B′)B′′ = BB′′ + B′B′′.
But, by deﬁnition, the elements of (B + B′)B′′ have the form (b + b′)b′′, and
those of BB′′ + B′B′′ have the form bb′′ + b′b′′ (b ∈B, b′ ∈B′, b′′ ∈B′′, all in
R). Thus, by the distributive law for R (a ﬁeld, by assumption),
(b + b′)b′′ = bb′′ + b′b′′,
and so the sets (B + B′)B′′ and BB′′ + B′B′′ coincide. This settles the case p,
q, r > 0.
Moreover, if p > q > 0 and r > 0, we also have
(p −q)r + qr = [(p −q) + q]r,
by what was proved above (replacing p by p −q). Hence (p −q)r = pr −qr.
This holds also if q > p > 0, since
(p −q)r = −[(q −p)r] = −(qr −pr) = pr −qr.
Thus
(p ± q)r = pr ± qr
for p, q, r > 0. Now also the other cases can be handled. For example, if
p > 0 > q and r > 0, then −q > 0 and
(p + q)r = [p −(−q)]r = pr −(−q)r = pr + qr.
Axiom IX(a). Let again p ≡(A, B), q ≡(A′, B′), r ≡(A′′, B′′), p > q. We
must show that
p + r > q + r.
Now, by Deﬁnition 2 and Theorem 2, p > q implies A ⊃A′ and B′ ⊃B;
hence
B′ + B′′ ⊇B + B′′.

118
Chapter 2. The Real Number System
(Verify!) Thus, by Corollary 3 in §9,
inf(B + B′′) ≥inf(B′ + B′′),
i.e., p + r ≥q + r. Equality is excluded here, for p + r = q + r would imply
p = q (by Axioms III–V, which we assume as proved already for R), and this
is contrary to p > q. Thus p + r > q + r, as claimed.
Axiom IX(b) is proved similarly for p, q > 0 and is obvious if p = 0 or q = 0.
In the general case (with r > 0, always), p > q implies p −q > 0, whence
(p −q)r > 0 · r = 0,
i.e., pr > qr, by distributivity (Axiom VI).
□
Thus the theorem is proved. In particular, we can apply it to the ﬁeld R of
all rational numbers (for R is Archimedean).4 By Theorem 5, the completion
R of R satisﬁes all axioms valid for real numbers, and so we may simply deﬁne
E1 to be R. In this case, the “old” elements of R are the rationals, and hence
the “new” ones are the irrationals.
Problems on Dedekind Cuts
1. Prove that in any cut (A, B),
y ≤x ∈A implies y ∈A, and y ≥x ∈B =⇒y ∈B.
2. Verify that (A, B) in Example 2 is a cut.
3. Prove that if (A, B) and (A′, B′) are cuts, then A ⊂A′ iﬀB ⊃B′.
4. Prove in detail the assertions immediately preceding Theorem 3.
5. Complete the proof of Theorem 3 by showing that p is a lower bound of
B. Also, carry out the proof for the case p ∈R, q /∈R.
6. Prove for any p ∈R that
p ≡(A, B) iﬀA = {x ∈R | x ≤p} and B = {x ∈R | x ≥p}.
7. Complete the proof of Theorem 4 by showing that (A, B) is indeed a cut.
8. Prove that (∼B, ∼A) is a cut if (A, B) is, and that p < 0 iﬀ−p > 0.
9. From Deﬁnitions 3(i) and (iii) prove the following:
(a) B + B′ = {x ∈R | x ≥p + q} if p, q ∈R; and B + B′ = {x ∈R |
x > p + q} if p /∈R or q /∈R.
4 For if x, y ∈R and x, y > 0, then y/x ∈R and so y/x = m/n for some m, n ∈N. Hence
y/x ≤m, i.e., y ≤mx < (m + 1)x, and the Archimedean property follows.

∗§15. Dedekind Cuts. Construction of E1
119
(b) If p, q > 0, then
BB′ = {x ∈R | x ≥pq}
if p, q ∈R, and
BB′ = {x ∈R | x > pq}
otherwise. Hence we infer the following.
(c) p + q determines a cut (A∗, B∗) in which B∗= (B + B′) ∪{p + q},
or B∗= B + B′ (cf. Problem 6); similarly for pq if p, q > 0.
[Hint for (a): First show that
{x ∈R | x > p + q} ⊆B + B′:
Let x ∈R, x > p + q; or x > inf(B + B′) (by the deﬁnition of p + q). Then x is
not a lower bound of B + B′ (why?); so x > b + b′ for some b ∈B and b′ ∈B′.
Let t = x −b′; so t + b′ = x > b + b′. Hence t ∈R and t > b ∈B, implying
t ∈B (cf. Problem 1). Thus x = t + b′, with t ∈B and b′ ∈B, i.e., x ∈B + B′,
as required.
Next, prove the converse inclusion in case p /∈R or q /∈R. Finally, consider
the case p, q ∈R.]
10. Using the results of Problem 9, prove that if p ≡(A, B), q ≡(A′, B′),
and r ≡(A′′, B′′), then the following are true.
(a) (p + q) + r = inf[(B + B′) + B′′] = inf[B + (B′ + B′′)] = p + (q + r).
(First show that (B + B′) + B′′ = B + (B′ + B′′).)
(b) (pq)r = p(qr). (First assume p, q, and r are greater than 0, then
extend this to all p, q, r ∈R by the rule of signs.)
(c) (p + q)r = inf[(B + B′)B′′] and pr + qr = inf(BB′′ + B′B′′).
[Hint: Observe that
inf(B + B′) = inf[(B + B′) ∪{p + q}].
(Why?) Thus, it does not matter whether p + q ∈B + B′. Hence, using Problem 9(c),
we may safely assume that
p + q ≡(A∗, B∗),
with B∗= B + B′, disregarding the case B∗= (B + B′) ∪{p + q}. Then, by Deﬁni-
tion 3(i),
(p + q) + r = inf(B∗+ B′′) = inf[(B + B′) + B′′],
etc.]
11. Show that (∀p, q ∈R)
pp−1 = 1, p + q = q + p, and pq = qp.

120
Chapter 2. The Real Number System
12. Verify Axiom IV for R: p + 0 = p and p · 1 = p.
[Hint: 0 corresponds to a cut (A0, B0) with B0 = {x ∈R | x ≥0}. If p ≡(A, B), then
p = inf B, by Theorem 3. Show that inf B = inf(B + B0), since (∀x ∈B0) x ≥0 and
so b + x ≥b.]
13. Prove Dedekind’s theorem: An ordered set is complete iﬀit has no gaps.
§16. The Inﬁnities. ∗The lim and lim of a Sequence
I. As we know, a set A ̸= ∅in E1 has a l.u.b. (g.l.b.) if A is bounded above
(below, respectively), but not otherwise. In order to avoid this inconvenient
restriction, we now add to E1 two new objects of arbitrary nature (“two peb-
bles”) and call them “minus inﬁnity” (−∞) and “plus inﬁnity”(+∞), with the
convention that −∞< +∞and −∞< x < +∞for all x ∈E1.
It is readily seen that, with this convention, the laws of trichotomy and
transitivity (Axioms VII and VIII) remain valid. The set consisting of all reals
and the two inﬁnities is called the extended real number system. We denote
it by E∗and call its elements extended real numbers. The ordinary reals are
also called ﬁnite numbers, while ±∞are the only two inﬁnite elements of E∗.
(Caution: They are not real numbers. E∗is not a ﬁeld.)
At this stage we do not deﬁne any operations involving ±∞(though this
can be done).
However, the notions of upper and lower bound, maximum,
minimum, supremum, and inﬁmum are deﬁned in E∗exactly as in E1. In
particular, −∞= min E∗and +∞= max E∗.
Thus, in E∗, all sets are
bounded by −∞and +∞.1
It follows that in E∗every set A ̸= ∅has a l.u.b. and a g.l.b. For if A has
no upper bound in E1, it still has the upper bound +∞in E∗, which in this
case is the unique (hence also the least) upper bound; thus sup A = +∞.2 It
is also customary to deﬁne sup ∅= −∞and inf ∅= +∞(this is the only case
where sup A < inf A). All properties of l.u.b. and g.l.b. stated in §9 remain
valid in E∗, with the same proof. The only exception is Note 4, since +∞−ϵ
and −∞+ ϵ make no sense.
We can now deﬁne intervals in E∗exactly as in E1 (see §8), allowing also
inﬁnite values of a, b, x. Thus
(−∞, a) = {x ∈E∗| −∞< x < a} = {x ∈E1 | x < a},
[a, +∞) = {x ∈E∗| a ≤x < +∞},
1 Therefore, when speaking of “bounded” sets in E∗, one usually has in mind those
bounded in E1, i.e., having ﬁnite bounds.
2 Unless A consists of −∞alone, in which case sup A = −∞. Similarly, ∞= inf A if there
is no other lower bound.

§16. The Inﬁnities. ∗The lim and lim of a Sequence
121
(−∞, ∞) = {x ∈E∗| −∞< x < ∞} = E1,
[−∞, +∞] = {x ∈E∗| −∞≤x ≤+∞} = E∗,
etc.
Intervals with ﬁnite endpoints are said to be ﬁnite; all other intervals
are called inﬁnite. If a ∈E1, the intervals (−∞, a), (−∞, a], (a, +∞), [a, ∞)
are actually subsets of E1, as is (−∞, +∞). Thus we may speak of inﬁnite
intervals in E1 as well.
∗II. Upper and Lower Limits.3 We have already mentioned that a real
number p is called the limit of a sequence {xn} ⊆E1 (p = lim
n→∞xn) iﬀ
(∀ϵ > 0) (∃k) (∀n > k)
|xn −p| < ϵ, i.e., p −ϵ < xn < p + ϵ;
(1)
in this deﬁnition, ϵ is in E1 and n and k are in N.
This may be stated thusly: “For suﬃciently large n (n > k), xn becomes
and stays as close to p as we like (‘ϵ-close’).” We also deﬁne the following:
lim
n→∞xn = +∞⇐⇒(∀a ∈E1) (∃k) (∀n > k)
xn > a,
(2)
and
lim
n→∞xn = −∞⇐⇒(∀b ∈E1) (∃k) (∀n > k)
xn < b.
(3)
Note that (2) and (3) make sense in E1, too, since the symbols ±∞do not
occur on the right side of the formulas. Formula (2) means that xn becomes
arbitrarily large (larger than any a ∈E1 given in advance) for suﬃciently large
n (n > k). The interpretation of (3) is analogous. We shall now develop a
more general and uniﬁed approach for E∗, allowing inﬁnite terms xn, too.
Let {xn} be any sequence in E∗. For each n, let An consist of all terms from
xn onward:
An = {xn, xn+1, . . . }.
Thus,
A1 = {x1, x2, . . . }, A2 = {x2, x3, . . .}, etc.
The An form a contracting sequence (Chapter 1, §8), as A1 ⊇A2 ⊇· · · .
Now, for each n let
pn = inf An and qn = sup An,
also denoted
pn = inf
k≥n xk, qn = sup
k≥n
xk.
3 Before taking up this topic, the reader should review §§8 and 3 (quantiﬁers) of Chapter 1.

122
Chapter 2. The Real Number System
(These inﬁma and suprema always exist in E∗, as noted above.) Since An ⊇
An+1, Corollary 3 of §9 yields
inf An ≤inf An+1 ≤sup An+1 ≤sup An.
Thus,
p1 ≤p2 ≤· · · ≤pn ≤pn+1 ≤· · · ≤qn+1 ≤qn ≤· · · ≤q2 ≤q1,
(4)
and so {pn}↑, while {qn}↓in E∗. Also, each qm is an upper bound of all pn
and hence qm ≥supn pn (= l.u.b. of all pn). It follows that this l.u.b. (call it
L) is a lower bound of all qm, and so
L ≤inf
m qm.
We set L = infm qm.
Deﬁnition 1.
For each sequence {xn ⊆E∗}, we deﬁne its upper limit L and its lower
limit L, denoted
L = lim xn (or lim sup
n→∞xn) and L = lim xn = lim inf
n→∞xn,
as follows. We put
(∀n)
qn = sup
k≥n
xk and pn = inf
k≥n xk,
as before. Then we set
L = lim xn = inf
n qn and L = lim xn = sup
n pn, all in E∗.
(5)
Here and below, infn qn is the inf of all qn, and supn pn is the sup of all
pn.
Corollary 1. For any sequence in E∗,
inf
n xn ≤lim xn ≤lim xn ≤sup
n xn.
For, as we noted before,
L = sup
n pn ≤inf
m qm = L.
Also,
L ≥pn = inf An ≥inf A1 = inf
n xn and
L ≤qn = sup An ≤sup A1 = sup
n xn,
with An as above.

§16. The Inﬁnities. ∗The lim and lim of a Sequence
123
Examples.
(a) xn = 1/n. Here
q1 = sup
n
1, 1
2, . . . , 1
n, . . .
o
= 1, q2 = 1
2, qn = 1
n.
Hence
L = inf
n qn = inf
n
1, 1
2, . . ., 1
n, . . .
o
= 0,
as easily follows by Theorem 2, §§8–9, and the Archimedean property.
(Verify!) Also,
p1 = inf
k≥1
1
k = 0, p2 = inf
k≥2
1
k = 0, . . ., pn = inf
k≥n
1
k = 0.
Since all pn are 0 so is L = supn pn. Thus, here L = L = 0.
(b) Consider the sequence
1, −1, 2, −1
2, . . . , n, −1
n, . . . .
Here
p1 = −1 = p2, p3 = −1
2 = p4, . . .; p2n−1 = −1
n = p2n.
Thus
lim xn = sup
n pn = sup
n
−1, −1
2, . . . , −1
n, . . .
o
= 0.
On the other hand, qn = +∞for all n. (Why?) Thus,
lim xn = inf
n qn = +∞.
(Why?)
Theorem 1.
(i) If xn ≥b for inﬁnitely many n, then lim xn ≥b as well.
(ii) If xn ≤a for all but ﬁnitely many n,4 then lim xn ≤a as well.
Similarly for lower limits (with all inequalities reversed).
Proof. (i) If xn ≥b for inﬁnitely many n, then such n must occur in each set
An = {xm, xm+1, . . . }. Hence (∀m) qm = sup Am ≥b; so L = infm qm ≥b, by
Corollary 2 of §9.
(ii) If xn ≤a except for ﬁnitely many n, let n0 be the last of these “ex-
ceptional” n. Then, for n > n0, xn ≤a, i.e., the set An = {xn, xn+1, . . .} is
bounded above by a; so qn = sup An ≤a. Hence, certainly L = infn qn ≤a.
□
4 In other words, for all except (at most) a ﬁnite number of terms xn. This is stronger
than just “inﬁnitely many n” (allowing inﬁnitely many exceptions as well). Caution: Avoid
confusing “all but ﬁnitely many” with just “inﬁnitely many”.

124
Chapter 2. The Real Number System
Corollary 2.
(i) If lim xn > a, then also xn > a for inﬁnitely many n.
(ii) If lim xn < b, then xn < b for all but ﬁnitely many n.
Similarly for lower limits (with all inequalities reversed).
Proof. Assume the opposite and ﬁnd a contradiction to Theorem 1.
□
To unify our deﬁnitions, we now introduce some useful notions. By a neigh-
borhood of p (p ∈E1), brieﬂy Gp,5 we mean any interval of the form (p−ϵ, p+ϵ),
ϵ > 0. If p = +∞(resp., p = −∞), Gp is an inﬁnite interval of the form (a, +∞]
(resp., [−∞, b)), with a, b ∈E1. We can now combine formulas (1)–(3) in one
equivalent deﬁnition.
Deﬁnition 2.
An element p ∈E∗(ﬁnite or not) is called the limit of a sequence {xn} ⊂
E∗if each Gp (no matter how small it is) contains all but ﬁnitely many
xn, i.e., all xn from some xk onward.
In symbols,
(∀Gp) (∃k) (∀n > k)
xn ∈Gp.

Notation: p = lim xn or lim
n→∞xn.

(6)
Indeed, if p ∈E1, then xn ∈Gp means that p −ϵ < xn < p + ϵ, as in (1). If,
however, p = +∞(resp., p = −∞), it means that xn > a (resp., xn < b), as in
(2) and (3).
Theorem 2. We have q = lim xn in E∗iﬀthese two conditions hold:
(i′) Each neighborhood Gq contains xn for inﬁnitely many n.
(ii′) If q < b, then xn ≥b for at most ﬁnitely many n.6
Proof. If q = lim xn, Corollary 2 yields (ii′). It also shows that any interval
(a, b), with a < q < b, contains inﬁnitely many xn (for there are inﬁnitely many
xn > a, and only ﬁnitely many xn ≥b, by (ii′)).
Now, if q ∈E1, Gq = (q −ϵ, q + ϵ) is such an interval; so we obtain (i′). The
cases q = ±∞are analogous; we leave them to the reader.
Conversely, assume (i′) and (ii′). Seeking a contradiction, let q < L; say,
q < b < lim xn.
Then Corollary 2(i) yields xn > b for inﬁnitely many n,
contrary to our assumption (ii′). Similarly, q > lim xn would contradict (i′).
Thus necessarily q = lim xn.
□
5 This terminology and notation anticipates some more general ideas.
6 A similar theorem (with all inequalities reversed) holds for lim xn.

§16. The Inﬁnities. ∗The lim and lim of a Sequence
125
Theorem 3. We have
q = lim xn in E∗iﬀlim xn = lim xn = q.
Proof. Suppose lim xn = lim xn = q. If q ∈E1, then every Gq is an interval
(a, b), a < q < b; so Corollary 2(ii) and its analogue for lim xn imply (with q
treated as both lim xn and lim xn) that a < xn < b for all but ﬁnitely many n.
Thus, by Deﬁnition 2, q = lim xn, as claimed.
Conversely, if q = lim xn, then any Gq (no matter how small) contains all
but ﬁnitely many xn. Hence, so does any interval (a, b) with a < q < b; for
it contains some small Gq. Now, exactly as in the proof of Theorem 2, one
excludes q ̸= lim xn and q ̸= lim xn. This settles the case q ∈E1. The cases
q = ±∞are quite analogous.
□
Problems on Upper and Lower Limits of Sequences in E∗
7
1. Complete the missing details in the proofs of Theorems 2 and 3, Corol-
lary 1, and Examples (a) and (b).
2. State and prove the analogues of Theorems 1 and 2, and Corollary 2, for
lim xn.
3. Find lim xn and lim xn if
(a) xn = c (constant);
(b) xn = −n;
(c) xn = n;
(d) xn = (−1)nn −n.
Does lim xn exist in each case?
⇒4. A sequence {xn} is said to cluster at q ∈E∗, and q is called its cluster
point, iﬀeach Gq contains xn for inﬁnitely many values of n. Show that
both L and L are cluster points (L the least and L the largest).
[Hint: Use Theorem 2, and its analogue for L. To show that no p < L (or q > L) is a
cluster point, assume the opposite and ﬁnd a contradiction to Corollary 2.]
⇒5. Prove that
(i) lim(−xn) = −lim xn;
(ii) lim(axn) = a · lim xn if 0 ≤a < +∞.
6. Prove that lim xn < +∞(lim xn > −∞) iﬀ{xn} is bounded above (be-
low) in E1.
7 The problems marked by ⇒are theoretically important. Study them!

126
Chapter 2. The Real Number System
7. If {xn} and {yn} are bounded in E1, then
lim xn + lim yn ≥lim(xn + yn) ≥lim xn + lim yn
≥lim(xn + yn) ≥lim xn + lim yn.
Give a proof.
⇒8. Prove that if p = lim xn in E1, then
lim(xn + yn) = p + lim yn.
Similarly for L.
⇒9. Prove that if {xn} is monotone, then lim xn exists in E∗. Speciﬁcally, if
{xn}↑then lim xn = supn xn, and if {xn}↓then lim xn = infn xn.
⇒10. Prove that
(i) if lim xn = +∞and (∀n) xn ≤yn, then also lim yn = +∞;
(ii) if lim xn = −∞and (∀n) yn ≤xn, then also lim yn = −∞.
11. Prove that if xn ≤yn for all n, then
lim xn ≤lim yn and lim xn ≤lim yn.

Chapter 3
The Geometry of n Dimensions
∗Vector Spaces
§1. Euclidean n-Space, En
y
Y
x
X
(0, 0)
(x, y)
Figure 12
The reader is certainly familiar with
the representation of ordered pairs
of real numbers (x, y) as points in
the xy-plane. Because of this repre-
sentation, such pairs are often called
“points” of the Cartesian plane (each
pair being regarded as one “point”).
The set of all such pairs is, by deﬁni-
tion, the Cartesian product (or cross
product) E1×E1, also brieﬂy denoted
by E2. An ordered pair (x, y) ∈E2
can also be graphically represented as a directed line segment (“vector”) pass-
ing from the origin (0, 0) to (x, y) (see Figure 12). Therefore, such pairs are
also called “vectors” in E2.
Quite similarly, ordered triples (x, y, z) of real numbers are called “points”
or “vectors” of the three-dimensional space E3 = E1 × E1 × E1.
Nothing
prevents us also from considering the set En of all ordered n-tuples of real
numbers (with n ﬁxed). Though in n dimensions there is no actual geometric
representation, it is convenient to use the geometric language in this case, too.
Thus every ordered n-tuple of real numbers
(x1, x2, . . . , xn)
will also be called a “point” or “vector” in En, and the single numbers
x1, x2, . . . , xn
of which it is composed are called its coordinates or components. En itself is
called n-dimensional Euclidean space, brieﬂy, “n-space”. A point in En will

128
Chapter 3. The Geometry of n Dimensions. ∗Vector Spaces
often be denoted by a single letter (preferably with a bar or arrow above it), and
then its n coordinates will be denoted by the same letter, with corresponding
subscripts (but without the bar or arrow). Thus we write
⃗x = (x1, x2, . . . , xn), ¯u = (u1, u2, . . . , un), etc.;
the notation ¯x = (0, −1, 2, 4) means that ¯x is a point (vector) in E4, with
coordinates 0, −1, 2, and 4 (in this order).
In E2 and E3, we shall also
sometimes use x, y, z to denote the coordinates; e.g., ⃗v = (x, y, z) ∈E3, or ¯u =
(x, y) ∈E2. It should be well noted that the term “point” or “vector” means
the n-tuple, and not its graphical representation (“dot” or “line segment”); a
drawing may not be used at all. The formula ¯x ∈En means that ¯x is a point
in En, i.e., an n-tuple, namely (x1, x2, . . . , xn).
As we know, two ordered n-tuples are equal only if the corresponding coor-
dinates are the same. Thus two vectors (points) ⃗x and ⃗y in En are equal iﬀ
they have the same corresponding components, i.e., if
x1 = y1, x2 = y2, . . . , xn = yn,
but not if the components occur in diﬀerent order; e.g., (4, 2, 1) ̸= (2, 1, 4).
Note. One vector equation is equivalent to n coordinate equations.
The point whose coordinates are all 0 is called the origin or the zero-vector,
denoted by ⃗0 or ¯0. Thus ⃗0 = (0, 0, . . . , 0) (n times). The vector whose k-th
coordinate is 1 and whose remaining n −1 coordinates are 0 is called the k-th
basic unit vector, denoted by ⃗ek; there are exactly n such vectors, namely,
⃗e1 = (1, 0, 0, . . . , 0), ⃗e2 = (0, 1, 0, . . . , 0), . . . , ⃗en = (0, 0, . . . , 0, 1).
In E2, we often denote these vectors by ⃗ı and ⃗; in E3, we denote them by ⃗ı, ⃗,
and ⃗k, respectively.
The term “vector” (rather than “point”) is preferably used when certain
operations are involved, which we shall deﬁne next; single real numbers are
then called scalars. Note: No scalar can be equal to a vector in En (since
the latter is an n-tuple), except if n = 1 (i.e., if we consider E1 itself as our
“space”). Also note that the n components of a vector in En are scalars, not
vectors. Sometimes we write −→
0x for a vector ⃗x (especially when we think of
⃗x as represented by a directed line segment); −→
0x is often called the “position
vector” of the “point” ¯x. In our theory, it is just another name for the vector
(point) ⃗x itself.
Deﬁnition 1.
Given two vectors ⃗x = (x1, x2, . . ., xn) and ⃗y = (y1, y2, . . ., yn) in En,
we deﬁne their sum and diﬀerence to be the vector whose coordinates
are obtained by adding or subtracting, respectively, the corresponding

§1. Euclidean n-Space, En
129
coordinates of x and y; thus
⃗x ± ⃗y = (x1 ± y1, x2 ± y2, . . . , xn ± yn).
Similarly for the sum of three or more vectors. Instead of ⃗0 −⃗x (where ⃗0 is
the zero-vector), we simply write −⃗x, and we call −⃗x the additive inverse of ⃗x,
or the vector inverse to ¯x. The reader will note that this deﬁnition agrees with
the familiar geometric rule of constructing the sum of two vectors, in E2 or E3,
as the diagonal of the parallelogram whose sides are these vectors, represented
as directed line segments. Imitating the usual geometric terminology, we shall
also call ⃗x −⃗y the “vector passing from the point ⃗y to the point ⃗x ” and denote
it also by −→
yx. Thus −→
yx = ⃗x −⃗y, by deﬁnition. In particular, this agrees with
our notation ⃗x = −→
0x = ⃗x −⃗0.
By our deﬁnitions,
−⃗x = (0 −x1, 0 −x2, . . . , 0 −xn) = (−x1, −x2, . . . , −xn).
Thus the coordinates of −⃗x are exactly the additive inverses of the corresponding
coordinates of ⃗x.
Deﬁnition 2.
Given a vector ⃗x = (x1, . . . , xn) in En and a scalar a ∈E1, we deﬁne the
product of a by ⃗x to be the vector
a⃗x = (ax1, ax2, . . . , axn),
i.e., the vector whose coordinates are products of a by the corresponding
coordinates of ⃗x.
Instead of
1
a

⃗x we sometimes write ⃗x
a (here a must be a scalar ̸= 0).
Caution: We have as yet no deﬁnition for a product of two vectors, only
for the product of a scalar by a vector. Such products are also called scalar
multiples of the given vector ⃗x.
Examples.
If ⃗u = (0, −1, 4, 2), ⃗v = (2, 2, −3, 1), and ⃗w = (1, 5, 4, 2) are vectors in
E4, then
(1) ⃗u + ⃗v + ⃗w = (3, 6, 5, 5), ⃗u −⃗w = (−1, −6, 0, 0);
(2) 2⃗u = (0, −2, 8, 4), 1⃗v = (2, 2, −3, 1) = ⃗v;
(3) 3⃗e1 = 3(1, 0, 0, 0) = (3, 0, 0, 0);
(4) 5⃗e2 = (0, 5, 0, 0), 1
2⃗u = (0, −1
2, 2, 1);
(5) 3⃗e1 + 2⃗e2 −5⃗e3 +⃗e4 = (3, 2, −5, 1), 3⃗u −2⃗v + 5⃗w = (1, 18, 38, 14);
(6) 0⃗u = 0⃗v = 0⃗w = (0, 0, 0, 0) = ⃗0;

130
Chapter 3. The Geometry of n Dimensions. ∗Vector Spaces
(7) (−1)⃗u = (0, 1, −4, −2) = −⃗u;
(8) ⃗u + (−⃗u) = (0, 0, 0, 0) = ⃗0.
Theorem 1. For any vectors ⃗u, ⃗v, ⃗w in En and any scalars a, b ∈E1, we
have the following:
(a) ⃗u + ⃗v and a⃗v are vectors in En (closure laws);
(b) ⃗u + ⃗v = ⃗v + ⃗u (commutativity of vector addition);
(c) ⃗u + (⃗v + ⃗w) = (⃗u + ⃗v) + ⃗w (associativity of addition);
(d) ⃗u +⃗0 = ⃗0 + ⃗u = ⃗u (i.e., ⃗0 is the neutral element of vector addition);
(e) ⃗u + (−⃗u) = ⃗0 (−⃗u is the additive inverse of ⃗u);
(f) a(⃗u + ⃗v) = a⃗u + a⃗v; (a + b)⃗u = a⃗u + b⃗u (distributive laws);
(g) (ab)⃗u = a(b⃗u);
(h) 1⃗u = ⃗u.
Proof. Assertion (a) is immediate from Deﬁnitions 1 and 2. The remaining
assertions easily follow from the corresponding properties of real numbers. For
example, to prove (b), let ⃗u = (u1, . . . , un), ⃗v = (v1, . . ., vn).
Then, by
deﬁnition, we have
⃗u + ⃗v = (u1 + v1, u2 + v2, . . ., un + vn)
and
⃗v + ⃗u = (v1 + u1, v2 + u2, . . ., vn + un).
But the right sides in both equations coincide because of the commutativity of
addition in E1. Thus ⃗u + ⃗v = ⃗v + ⃗u, as required; similarly for the remaining
assertions, which we leave to the reader as an exercise, along with the proofs
of the next two corollaries.
□
Corollary 1. (∀⃗v ∈En) 0⃗v = ⃗0; and (∀a ∈E1) a⃗0 = ⃗0.
Corollary 2. (∀⃗v, ⃗w ∈En) (−1)⃗v = −⃗v, and ⃗v + (−⃗w) = ⃗v −⃗w.
Theorem 2. If ⃗v = (v1, . . . , vn) is a vector in En, then
⃗v = v1⃗e1 + v2⃗e2 + · · · + vn⃗en =
n
X
k=1
vk⃗ek,
where the ⃗ek are the basic unit vectors in En. Moreover, if ⃗v =
n
X
k=1
akek for
some scalars ak, then necessarily ak = vk, k = 1, 2, . . . , n.
Proof. By deﬁnition,
⃗e1 = (1, 0, 0, . . ., 0), ⃗e2 = (0, 1, . . . , 0), . . . , ⃗en = (0, . . . , 0, 1).

§1. Euclidean n-Space, En
131
Thus
v1⃗e1 = (v1, 0, . . . , 0), v2⃗e2 = (0, v2, . . . , 0), . . . , vn⃗en = (0, 0, . . . , vn).
(Observe that the vk are scalars; the ⃗ek are vectors.)
Adding up componentwise, we obtain
n
X
k=1
vk⃗ek = v1⃗e1 + v2⃗e2 + · · · + vn⃗en = (v1, v2, . . . , vn) = ⃗v,
as asserted. Moreover, for any other scalars a1, . . ., an, exactly the same pro-
cedure shows that
n
X
k=1
ak⃗ek = (a1, a2, . . . , an).
Thus, if ⃗v =
n
X
k=1
ak⃗ek, then ⃗v = (a1, . . . , an). Since also ⃗v = (v1, . . . , vn), the
two n-tuples must coincide, i.e., ak = vk, k = 1, 2, . . . , n, and all is proved.
□
Note 1. Any sum of the form
m
X
k=1
ak⃗xk
(ak ∈E1, ⃗xk ∈En)
is called a linear combination of the vectors ⃗x1, ⃗x2, . . . , ⃗xm (their number must
be deﬁnite but otherwise arbitrary). Thus Theorem 2 shows that any vector
⃗v ∈En can be expressed, in a unique way, as a linear combination of the n
basic unit vectors ⃗ek (the coeﬃcients ak being necessarily the components of
⃗v).
Note 2. As we have noted, in E3 the basic unit vectors are often denoted
by ⃗ı, ⃗, ⃗k and the coordinates by x, y, z. Then, by Theorem 2,
⃗v = (x, y, z) = x⃗ı + y⃗+ z⃗k,
and this representation of ⃗v is unique. Thus the right side sum may be treated
as a standard notation for a vector, instead of (x, y, z). It should, however, be
well-noted that this sum represents an ordered triple, namely, (x, y, z).
Note 3. From our deﬁnitions and Theorem 1, the n-space En has emerged
as a set of elements (called “vectors” or “points”) for which two operations are
deﬁned, namely, addition of vectors and multiplication of a vector by a scalar
(real number). There also are many other sets (not necessarily sets of n-tuples)
for which two such operations are deﬁned in some manner. Any set with two
such operations is called a real vector space if these operations obey all laws
speciﬁed in Theorem 1. E1 is called its ﬁeld of scalars. Thus En is a real
vector space under the operations deﬁned above.

132
Chapter 3. The Geometry of n Dimensions. ∗Vector Spaces
Caution: We shall not deﬁne any inequalities (<) for vectors in En. Thus,
expressions like ¯x < ¯y will not be used and should be carefully avoided except
if n = 1, i.e., if the “vectors” under consideration are simply real numbers
(elements of E1).
Despite the two operations deﬁned in En, the n-space is not a ﬁeld (except
in the case of E1), mainly because the multiplication of a vector by a vector
is not deﬁned in En. Scalar multiples are not products of two vectors, even
though some of their properties resemble those of products of real numbers.
There also is no such thing as a “neutral element of vector multiplication”
(though there is a neutral element of vector addition, namely, ⃗0). In the next
section we shall deﬁne certain products (“inner products”) of vectors; but even
so, En will not become a ﬁeld, because these products do not satisfy the ﬁeld
axioms in full. Only for E2 shall we later deﬁne a vector multiplication that
will satisfy these axioms, and so E2 will become a ﬁeld.
Note 4. As we have seen in Theorem 2, sometimes we have to num-
ber several vectors by aﬃxing appropriate subscripts; e.g., ⃗e1, ⃗e2, . . ., ⃗en or
⃗x1, ⃗x2, . . . , ⃗xm.
In this case, the coordinates of these vectors are denoted
by attaching a second subscript.
For example, the coordinates of ⃗x1 are
x11, x12, . . . , x1n. Similarly, ⃗x2 = (x21, x22, . . . , x2n), etc.
Problems on Vectors in En
1. Find the expression 2⃗u −⃗v −3⃗w + 5⃗w, given that
(a) ⃗u = (−1, 2, 0, −7), ⃗v = (0, 0, −1, −2), ⃗w = (2, 4, −3, −3),
⃗x = (0, 1, 0, 1);
(b) ⃗u = (2, 2, 2), ⃗v = (−3, 4, 1), ⃗w = ⃗0, ⃗x = (5, −7, 0);
(c) ⃗u = 3⃗ı + ⃗−2⃗k, ⃗v = −4⃗ı + 2⃗−⃗k, ⃗w = 2⃗ı + ⃗, ⃗x = −3⃗+ 2⃗k;
(d) ⃗u = (2, 1, −1, 0), ⃗v = (0, −5, 6, 6), ⃗w = (3, −2, 4, 8),
⃗x = (3, 3, 3, 3).
(In part (c), ﬁrst rewrite the given vectors as triples.)
2. Complete the proof of Theorem 1.
3. Prove Corollaries 1 and 2 in two ways:
(a) using deﬁnitions only (in terms of coordinates);
(b) using the laws of Theorem 1 (without coordinates) and assuming
⃗v −⃗w = ⃗v + (−⃗w) as a deﬁnition.
4. In Problem 1, parts (a), (b), and (d), express the given vectors as linear
combinations of the basic unit vectors, and compute the required expres-
sion 2⃗u −⃗v −3⃗w + 5⃗x directly in terms of these unit vectors. Moreover,
express ⃗w as a linear combination of ⃗u, ⃗v, ⃗w, ⃗x, if possible.

§1. Euclidean n-Space, En
133
5. Find (if possible) four scalars a, b, c, and d such that ⃗y = a⃗u+b⃗v+c⃗w+d⃗x,
where ⃗u, ⃗v, ⃗w, ⃗x are as in Problem 1(a), if
(a) ⃗y = ⃗e1;
(b) ⃗y = ⃗e2;
(c) ⃗y = ⃗e3;
(d) ⃗y = (−2, 4, 0, 1);
(e) ⃗y = ⃗e4.
6. Do Problem 5 with ⃗u, ⃗v, ⃗w, ⃗x as in Problem 1(d).
7. Set up and solve for E3 a problem analogous to Problem 5, working with
the three vectors ⃗u, ⃗v, ⃗x of Problem 1(b). Do the same for ⃗u, ⃗v, ⃗x of 1(c).
8. A ﬁnite set of vectors ⃗v1, ⃗v2, . . ., ⃗vm in En is said to be linearly dependent
if there are scalars a1, a2, . . ., am, not all zero, such that
m
X
k=1
ak⃗vk = ⃗0;
if no such scalars exist, the vectors are linearly independent (this means
that
m
X
k=1
ak⃗vk
cannot vanish unless all ak are 0). Prove that the following sets of vectors
are linearly independent:
(a) the basic unit vectors in E3;
(b) same for En;
(c) the vectors (1, 2, −3, 4), (2, 3, 0, 0) in E4;
(d) the vectors (2, 0, 0), (4, −1, 3), and (0, 4, 1) in E3.
Which of the sets of vectors given in Problem 1 are linearly dependent
and which are not? (Give a proof!)
§2. Inner Products. Absolute Values. Distances
We shall now deﬁne some new operations on vectors in En.
Deﬁnition 1.
The inner product or dot product ⃗u·⃗v of two vectors ⃗u = (u1, u2, . . . , un)
and ⃗v = (v1, v2, . . . , vn) in En is deﬁned as follows:
⃗u · ⃗v = u1v1 + u2v2 + · · · + unvn =
n
X
k=1
ukvk.

134
Chapter 3. The Geometry of n Dimensions. ∗Vector Spaces
Note that the dot product is a scalar (real number), not a vector. Therefore,
the dot product is sometimes called the scalar product of two vectors.1
Example.
Let ⃗u = (3, 1, −9, 4), ⃗v = (−1, 3, 1, 0). Then
⃗u · ⃗v = 3 · (−1) + 1 · 3 + (−9) · 1 + 4 · 0 = −9.
Deﬁnition 2.
The absolute value (or length, or norm, or magnitude, or modulus), |⃗v|,
of a vector ⃗v = (v1, v2, . . . , vn) in En is the scalar deﬁned by
|⃗v| =
q
v2
1 + v2
2 + · · · + v2n =
s n
X
k=1
v2
k,
i.e., it is the nonnegative value of the square root of
n
X
k=1
v2
k.
Example.
Let ⃗v = (3, 4, 0) ∈E3. Then |⃗v| = √9 + 16 + 0 = 5.
Note 1. In E1, all “vectors” are simply real numbers, and v has only one
component, namely, itself. Thus, by this deﬁnition, |v| =
√
v2 ; the root equals
v if v ≥0 and −v if v < 0 (since we always take the nonnegative value). Thus
it equals the absolute value of v as deﬁned previously, for real numbers, so the
two deﬁnitions agree.
y
Y
x
X
¯0
¯v
p
x2 + y2 = |⃗v|
Figure 13
Note 2.
Geometrically (in E1,
E2 and E3), |⃗v| is the length of the
line segment joining the origin with
the point ⃗v.
For example, if ⃗v =
(x, y) ∈E2 (see Figure 13) then
|⃗v| =
p
x2 + y2 is exactly that dis-
tance from ⃗0 to ⃗v, as is known by el-
ementary geometry. Similarly for E3,
where |⃗v| =
p
x2 + y2 + z2.
Note 3. By Deﬁnitions 1 and 2, we have
⃗u · ⃗u =
n
X
k=1
ukuk =
n
X
k=1
u2
k = |⃗u|2;
hence
√
⃗u · ⃗u =
s n
X
k=1
u2
k = |⃗u|.
1 Some authors also use the notation (⃗u, ⃗v) or [⃗u, ⃗v] instead of ⃗u · ⃗v. We shall not use this
terminology.

§2. Inner Products. Absolute Values. Distances
135
This could serve as a deﬁnition of the absolute value, |⃗u|, equivalent to Deﬁni-
tion 2. We shall use it below.
Theorem 1. For any vectors ⃗u, ⃗v, ⃗w ∈En and scalars a, b ∈E1, we have
(a) ⃗u · ⃗u ≥0; and ⃗u · ⃗u > 0 iﬀ⃗u ̸= ⃗0;
(b) (a⃗u) · (b⃗v) = ab(⃗u · ⃗v);
(c) ⃗u · ⃗v = ⃗v · ⃗u (commutativity of inner products);
(d) (⃗u + ⃗v) · ⃗w = ⃗u · ⃗w + ⃗v · ⃗w (distributive law).
The proof is immediate from our deﬁnitions. (One only has to express ⃗u, ⃗v,
and ⃗w in terms of their coordinates and proceed as in Theorem 1 of §1.) We
leave it to the reader. Note that (b) implies that ⃗u · ⃗0 = 0 (put a = 1 and
b = 0), and a(⃗u · ⃗v) = (a⃗u) · ⃗v.
Deﬁnition 3.
Two vectors ⃗u and ⃗v are said to be parallel or collinear iﬀone of them is
a scalar multiple of the other, i.e.,
⃗u = t⃗v
or
⃗v = t⃗u
for some scalar t ∈E1. Notation: ⃗u ∥⃗v.
Geometrically (if ⃗u and ⃗v are represented as directed line segments), ⃗u
and ⃗v have the same direction (if t > 0) or opposite directions (if t < 0).
Note. ⃗0 ∥⃗u always since ⃗0 = 0⃗u, (t = 0).
Theorem 2. For any vectors ⃗u, ⃗v ∈En and any scalar a ∈E1, we have
(a′) |⃗u| ≥0; and |⃗u| = 0 iﬀ⃗u = ⃗0;
(b′) |a⃗u| = |a| |⃗u|;
(c′) |⃗u · ⃗v| ≤|⃗u| |⃗v| (Cauchy–Schwarz inequality) and |⃗u · ⃗v| = |⃗u| |⃗v| iﬀ⃗u ∥⃗v;
(d′) |⃗u + ⃗v| ≤|⃗u| + |⃗v| and
|⃗u| −|⃗v|
 ≤|⃗u −⃗v| (triangle inequalities).
Proof. Property (a′) follows from Theorem 1(a) since |⃗u|2 = ⃗u · ⃗u, by Note 3
to Deﬁnition 2.
For (b′), we use Theorem 1(b) to obtain
(a⃗u) · (a⃗u) = a2(⃗u · ⃗u) = a2|⃗u|2
(since ⃗u · ⃗u = |⃗u|2).
Also, (a⃗u) · (a⃗u) = |a⃗u|2. Hence |a⃗u|2 = a2|⃗u|2, and (b′) follows.
(c′) If ⃗u ∥⃗v, then ⃗u = t⃗v or ⃗v = t⃗u (Deﬁnition 3); say, ⃗u = t⃗v. Then, by (b′)
and Theorem 1(b),
|⃗u · ⃗v| = |t⃗v · ⃗v| = |t|(⃗v · ⃗v) = |t| |⃗v|2 = |t| |⃗v| |⃗v| = |t⃗v| |⃗v| = |⃗u| |⃗v|.
Thus, ⃗u ∥⃗v implies the equality |⃗u · ⃗v| = |⃗u| |⃗v|.

136
Chapter 3. The Geometry of n Dimensions. ∗Vector Spaces
Now suppose ⃗u and ⃗v are not parallel. Then ⃗v = t⃗u for no t ∈E1. Hence
(∀t ∈E1) |t⃗u −⃗v|2 ̸= 0. But, by Deﬁnition 2,
|t⃗u −⃗v|2 =
n
X
k=1
(tuk −vk)2.
Thus,
0 ̸= |t⃗u −⃗v|2 =
n
X
k=1
(tuk −vk)2 = t2
n
X
k=1
u2
k −2t
n
X
k=1
ukvk +
n
X
k=1
v2
k,
(t ∈E1).
Setting, for brevity,
A =
n
X
k=1
u2
k, B = 2
n
X
k=1
ukvk, and C =
n
X
k=1
v2
k,
we see that the quadratic equation 0 = At2 −Bt + C has no real solutions for
t. Thus, by elementary algebra, its discriminant B2 −4AC must be negative.
Substituting the values of A, B, C in B2 −4AC < 0 and dividing by 4, we get
 n
X
k=1
ukvk
2
<
 n
X
k=1
u2
k
 n
X
k=1
v2
k

.
By Deﬁnitions 1 and 2, this means that |⃗u · ⃗v|2 < |⃗u|2|⃗v|2, or |⃗u · ⃗v| < |⃗u| |⃗v|.
We have shown that |⃗u · ⃗v| = |⃗u| |⃗v| or |⃗u · ⃗v| < |⃗u| |⃗v|, according to whether
⃗u is or is not parallel to ⃗v. Thus assertion (c′) is proved.
(d′) Expand |⃗u + ⃗v|2 using Theorem 1(d) and Note 3 to get
|⃗u + ⃗v|2 = (⃗u + ⃗v) · (⃗u + ⃗v) = ⃗u · ⃗u + 2⃗u · ⃗v + ⃗v · ⃗v = |⃗u|2 + 2⃗u · ⃗v + |⃗v|2.
As ⃗u · ⃗v ≤|⃗u · ⃗v| ≤|⃗u| |⃗v| (by (c′)), this yields
|⃗u + ⃗v|2 ≤|⃗u|2 + 2|⃗u| |⃗v| + |⃗v|2 = (|⃗u| + |⃗v|)2,
proving the ﬁrst formula in (d′). The second formula follows from it exactly as
in Chapter 2, §4, Corollary 6. Thus all is proved.
□
⃗u
⃗v
⃗u
⃗v
⃗u + ⃗v
⃗u + ⃗v
Figure 14
Note 4.
In E2 and E3, the tri-
angle inequalities have a simple geo-
metric interpretation. Represent the
vectors ⃗u and ⃗v as (directed) sides
in a triangle. Then ⃗u + ⃗v represents
geometrically the third side (see Fig-
ure 14). The absolute values |⃗u|, |⃗v|,
and |⃗u+⃗v| are the lengths of the sides.
Thus the ﬁrst formula (d′) states that
a side of a triangle never exceeds the

§2. Inner Products. Absolute Values. Distances
137
sum of the other two sides, while the second formula (d′) says that the dif-
ference of two sides never exceeds the third side.
(This explains the name
“triangle inequalities”.)
If ⃗u ∥⃗v, the triangle “collapses”, and inequalities
become equalities (see Problem 7).
From elementary geometry in E2 and E3, the reader is certainly familiar
with the formulas for the distance between two points ¯u and ¯v, in terms of
their coordinates. Denoting this distance by ρ(¯u, ¯v), we have in E2
ρ(¯u, ¯v) =
p
(u1 −v1)2 + (u2 −v2)2 ;
and in E3
ρ(¯u, ¯v) =
p
(u1 −v1)2 + (u2 −v2)2 + (u3 −v3)2 .
Note that the diﬀerences uk −vk are the coordinates of ¯u −¯v. Hence, by
Deﬁnition 2, the square roots given above equal exactly the absolute value of
the vector ¯u −¯v, so that ρ(¯u, ¯v) = |¯u −¯v|, in both E2 and E3. It is natural to
deﬁne distances in En in a similar manner, as we shall do now.
Deﬁnition 4.
The distance ρ(¯u, ¯v) between two points ¯u = (u1, . . . , un) and ¯v =
(v1, . . . , vn) in En is the scalar deﬁned by
ρ(¯u, ¯v) = |¯u −¯v| =
s n
X
k=1
(uk −vk)2 =
p
(¯u −¯v) · (¯u −¯v) .
−→
0v
−→
0u
¯v
−→
vu
¯u
¯0
Figure 15
Note 5.
When speaking of dis-
tances, we shall use the term “point”
rather than “vector”, and the nota-
tion ¯u rather than ⃗u. As previously
noted, we call ¯u −¯v = −→
vu the “vector
passing from the point ¯v to the point
¯u” or, brieﬂy, “the vector from ¯v to
¯u” (in this order), as is suggested by
Figure 15. With this terminology and
notation, we have
ρ(¯u, ¯v) = |−→
vu| = |¯u −¯v|;
i.e., the distance ρ(¯u, ¯v) is the length of the vector from ¯v to ¯u.
Theorem 3. For any points ¯u, ¯v, ¯w ∈En, we have
(i) ρ(¯u, ¯v) ≥0; and ρ(¯u, ¯v) = 0 iﬀ¯u = ¯v;
(ii) ρ(¯u, ¯v) = ρ(¯v, ¯u) (symmetry law);
(iii) ρ(¯u, ¯w) ≤ρ(¯u, ¯v) + ρ(¯v, ¯w) (triangle inequality).

138
Chapter 3. The Geometry of n Dimensions. ∗Vector Spaces
Proof. (i) Since ρ(¯u, ¯v) = |¯u −¯v|, we have, by Theorem 2(a′),
ρ(¯u, ¯v) = |¯u −¯v| ≥0.
Also, |¯u −¯v| ̸= 0 iﬀ¯u −¯v ̸= 0, i.e., iﬀ¯u ̸= ¯v. Hence ρ(¯u, ¯v) ̸= 0 iﬀu ̸= v;
i.e., ρ(¯u, ¯v) = 0 iﬀ¯u = ¯v, as asserted.
(ii) By Theorem 2(b′),
|¯u −¯v| = |(−1)(¯u −¯v)| = |¯v −¯u|.
As |¯u −¯v| = ρ(¯u, ¯v), this means that ρ(¯u, ¯v) = ρ(¯v, ¯u), as required.
(iii) By deﬁnition,
ρ(¯u, ¯v) + ρ(¯v, ¯w) = |¯u −¯v| + |¯v −¯w|;
and by the triangle inequality for absolute values,
|¯u −¯v| + |¯v −¯w| ≥|¯u −¯w| = ρ(¯u, ¯w).
Hence ρ(¯u, ¯v) + ρ(¯v, ¯w) ≥ρ(¯u, ¯w), and all is proved.
□
Note 6. We also have |ρ(¯u, ¯v) −ρ( ¯w, ¯v)| ≤ρ(¯u, ¯w). The proof is left to the
reader as an exercise.
Problems on Vectors in En (continued)
1. Complete the proofs of Theorems 1 and 2 (last part) and Note 6.
2. Prove Theorem 2(a′)(b′) from our deﬁnitions, without using Theorem 1.
3. Given the vectors (points) ⃗u, ⃗v, ⃗w, ⃗x as in Problem 1 of §1, compute their
absolute values, mutual distances and dot products. (Treat the cases (a),
(b), (c), and (d) separately.) Take any three of these vectors and verify
by direct computation that they satisfy the formulas of Theorems 1 and
2. Are any two of these vectors parallel?
4. Slightly modify the proof of Theorem 2(c′) to obtain the stronger result
 n
X
k=1
|ukvk|
2
≤
 n
X
k=1
u2
k
 n
X
k=1
v2
k

.
Why is this stronger than the ordinary Cauchy–Schwarz inequality?
5. Give another proof of the Cauchy–Schwarz inequality, |⃗u · ⃗v| ≤|⃗u| |⃗v|.
[Outline: If |⃗u| = 0 or |⃗v| = 0, this reduces to the trivial 0 ≤0. Thus assume |⃗u| > 0,
|⃗v| > 0, and set a = |⃗v|/|⃗u|; so a > 0 and a|⃗u| = |⃗v|. Deduce that
a2(⃗u · ⃗u) = a2|⃗u|2 = a|⃗u| |⃗v| = |⃗v|2 = ⃗v · ⃗v.
(i)
Now consider (a⃗u ±⃗v) · (a⃗u ±⃗v) ≥0 (Theorem 1(a)). By Theorem 1(d)(b), expanding
in the usual way, obtain
0 ≤(a⃗u ± v) · (a⃗u ± ⃗v) = a2⃗u · ⃗u + ⃗v · ⃗v ± 2a⃗u · ⃗v.

§2. Inner Products. Absolute Values. Distances
139
Hence, by step (i),
0 ≤a|⃗u| |⃗v| + a|⃗u| |⃗v| ± 2a(⃗u · ⃗v) = 2a|⃗u| |⃗v| ± 2a(⃗u · ⃗v);
or, transposing, ±2a(⃗u · ⃗v) ≤2a|⃗u| |⃗v|. Divide by 2a to obtain the result.]
6. If ⃗v ̸= ⃗0, prove that ⃗u ∥⃗v iﬀ
u1
v1
= u2
v2
= · · · = un
vn
= t,
for some t ∈E1, where “uk/vk = t” is to be replaced by “uk = 0” if
vk = 0.
7. Prove that
(i) |⃗u + ⃗v| = |⃗u| + |⃗v| iﬀ⃗u = t⃗v or ⃗v = t⃗u for some t ≥0;
(ii) |⃗u −⃗v| = |⃗u| + |⃗v| iﬀ⃗u = t⃗v or ⃗v = t⃗u for some t ≤0.
[Hint: For the “only if ”, proceed as in the proof of Theorem 2(d′), using the “equality”
part of Theorem 2(c′).]
∗8. Use induction on n to prove the Lagrange identity (valid in any ﬁeld):
 n
X
k=1
u2
k
 n
X
k=1
v2
k

−
 n
X
k=1
ukvk
2
=
X
1≤i≤k≤n
(uivk −ukvi)2,
where the right-hand sum contains all terms for which 1 ≤i ≤k ≤n
(only).
∗9. Using the results of Problems 6 and 8, ﬁnd a new proof of Theorem 2(c′).
§3. Angles and Directions
⃗u
⃗v
⃗v −⃗u
¯0
⟨⃗u,⃗v⟩
Figure 16
The inner product ⃗u · ⃗v of two vec-
tors, as deﬁned in §2, has a simple
geometric interpretation (in E2 and
E3), when the vectors are represented
as directed line segments: it equals the
product of the lengths of ⃗u and ⃗v mul-
tiplied by the cosine of the angle be-
tween ⃗u and ⃗v,
⃗u · ⃗v = |⃗u| |⃗v| cos⟨⃗u,⃗v⟩,
where ⟨⃗u,⃗v⟩denotes that angle. Indeed (see Figure 16), by the law of cosines,
|⃗u|2 + |⃗v|2 −2|⃗u| |⃗v| cos⟨⃗u,⃗v⟩= |⃗v −⃗u|2.

140
Chapter 3. The Geometry of n Dimensions. ∗Vector Spaces
As |⃗u|2 = ⃗u · ⃗u, |⃗v|2 = ⃗v · ⃗v, etc., we obtain
⃗u · ⃗u + ⃗v · ⃗v −2|⃗u| |⃗v| cos⟨⃗u,⃗v⟩= |⃗v −⃗u|2
= (⃗v −⃗u) · (⃗v −⃗u)
= ⃗v · ⃗v + ⃗u · ⃗u −2⃗u · ⃗v,
by the distributive law. Cancelling and reducing, we get
⃗u · ⃗v = |⃗u| |⃗v| cos⟨⃗u,⃗v⟩,
as asserted. If ⃗u ̸= ⃗0 and ⃗v ̸= ⃗0, we also obtain
cos⟨⃗u,⃗v⟩= ⃗u · ⃗v
|⃗u| |⃗v|.
It is natural to accept this as a deﬁnition of an angle in En as well.
Deﬁnition 1.
Given two vectors ⃗u ̸= ⃗0 and ⃗v ̸= ⃗0 in En, we deﬁne the (undirected)
angle between them, denoted ⟨⃗u,⃗v⟩, as the main value of
arccos ⃗u · ⃗v
|⃗u| |⃗v|,
i.e., the (unique) number between 0 and π such that
cos⟨⃗u,⃗v⟩= ⃗u · ⃗v
|⃗u| |⃗v|
(⃗u ̸= ⃗0, ⃗v ̸= ⃗0).
(1)
Note 1. Throughout this and some other sections, we assume the notions
and laws of elementary trigonometry to be known. Actually, however, what
will be needed are only the cosines of the angles, and we may treat formula (1)
as a deﬁnition, even without speaking of the “angle” itself. It is only for the
sake of geometric interpretation that we speak of “angles”, “cosines”, “perpen-
dicularity”, etc., and sometimes express “angles” in degrees instead of radians.
Note 2. By the Cauchy–Schwarz inequality, we always have |⃗u·⃗v| ≤|⃗u| |⃗v|.
Hence the fraction (⃗u · ⃗v)/(|⃗u| |⃗v|) in formula (1) never exceeds 1 in absolute
value, so that an angle with cos⟨⃗u,⃗v⟩= (⃗u · ⃗v)/(|⃗u| |⃗v|) does exist. However, it
is not deﬁned if ⃗u = ⃗0 or ⃗v = ⃗0.
Deﬁnition 2.
Two vectors ⃗u and ⃗v in En are said to be orthogonal or perpendicular if
⃗u · ⃗v = 0; or, in terms of coordinates,
n
X
k=1
ukvk = 0.
We then write ⃗u ⊥⃗v.

§3. Angles and Directions
141
This notion is deﬁned also if ⃗u = ⃗0 or ⃗v = ⃗0. In particular, ⃗0 ⊥⃗v for every
⃗v ∈En; and ⃗ek ⊥⃗ei (k ̸= i) for the basic unit vectors. (Verify!) If, however,
⃗u ̸= ⃗0 and ⃗v ̸= ⃗0, then ⃗u ⊥⃗v also means that
cos⟨⃗u,⃗v⟩= ⃗u · ⃗v
|⃗u| |⃗v| = 0, i.e., ⟨⃗u,⃗v⟩= π
2 .
Of special importance are the n angles which a given vector ⃗v ̸= ⃗0 forms
with the basic unit vectors ⃗e1, . . .,⃗en, i.e., the angles ⟨⃗v,⃗ek⟩, k = 1, . . ., n. They
are called the direction angles of ⃗v, and their cosines are called the direction
cosines of ⃗v. Thus every vector ⃗v ̸= ⃗0 in En has exactly n direction cosines.
Geometrically (in E2 and E3), the direction angles are those between ⃗v and the
positive directions of the coordinate axes (⃗ı, ⃗, ⃗k). We now obtain the following
result.
Corollary 1. For any vector ⃗v = (v1, . . . , vn) ̸= ⃗0 in En, the following is
true:
(a) We have
cos⟨⃗v,⃗ek⟩= vk
|⃗v|,
k = 1, . . ., n;
i.e., the direction cosines of ⃗v are obtained by dividing its coordinates vk
by the length |⃗v| of ⃗v.
(b) The sum of the squares of the direction cosines of ⃗v always equals 1:
n
X
k=1
cos2⟨⃗v,⃗ek⟩= 1.
(2)
Proof. By deﬁnition, all coordinates of ⃗ek are 0 except the k-th, which is
1. Thus, computing the length of ⃗ek, we obtain |⃗ek| = 1. Similarly, the dot
product ⃗v · ⃗ek equals vk (the k-th coordinates of ⃗v) because, by deﬁnition, it is
a sum in which all terms but one, vk × 1, are equal to 0. Substituting this in
formula (1), we have
cos⟨⃗v,⃗ek⟩= ⃗v · ⃗ek
|⃗v| |⃗ek| = vk
|⃗v|,
proving assertion (a).
Part (b) is obtained by substituting this in (2) and noting that
n
X
k=1
v2
k = |⃗v|2;
we leave the details to the reader.
□
Note 3. In E3, the direction angles of ⃗v are often denoted by α, β, γ. Then
formula (2) simpliﬁes to
cos2 α + cos2 β + cos2 γ = 1.

142
Chapter 3. The Geometry of n Dimensions. ∗Vector Spaces
Deﬁnition 3.
By a unit vector or a direction in En is meant any vector of length |⃗v| = 1.
Such are, e.g., the n basic unit vectors ⃗ek (see above).
By dividing any vector ⃗v ̸= ⃗0 by its own magnitude |⃗v| ̸= 0, we always obtain
a unit vector (called the unit of ⃗v, or the direction of ⃗v, or the normalized vector
of ⃗v). Indeed, the resulting ⃗u = ⃗v/|⃗v| has length 1 since, by Theorem 2(b′) of
§2,

1
|⃗v|⃗v
 = 1
|⃗v||⃗v| = 1.
To normalize a vector ⃗v ̸= ⃗0 means to divide it by its own magnitude |⃗v|, i.e., to
multiply by 1/|⃗v|. Of course, this is only possible if ⃗v ̸= ⃗0.
We also obtain the following result.
Corollary 2. The direction cosines of any vector ⃗v ̸= ⃗0 in En are equal to
the corresponding components of its unit ⃗v/|⃗v|. Hence, if |⃗v| = 1, these cosines
are simply the components of ⃗v. (It also follows that the components of a unit
vector never exceed 1 in absolute value.)
Indeed, the coordinates of ⃗v/|⃗v|, by deﬁnition, are obtained by dividing those
of ⃗v by the scalar |⃗v|. But, by Corollary 1(a), so also are obtained the direction
cosines of ⃗v. Thus our assertion follows.
Examples.
Take two vectors in E4: ⃗u = (1, −2, 0, −1) and ⃗v = (0, 3, 2, −2). Then
|⃗u| =
p
12 + (−2)2 + 02 + (−1)2 =
√
6;
similarly |⃗v| =
√
17. Since ⃗u ̸= ⃗0 and ⃗v ̸= ⃗0, the angle ⟨⃗u,⃗v⟩exists and,
by deﬁnition,
cos⟨⃗u,⃗v⟩= ⃗u · ⃗v
|⃗u| |⃗v| =
−3
√
6 · 17
=
−3
√
102
.
To obtain the direction cosines of ⃗u, we normalize it:
⃗u
|⃗u| = (1, −2, 0, −1)
√
6
=
 1
√
6, −2
√
6, 0, −1
√
6

.
These four numbers are the required cosines, by Corollary 2.
We leave to the reader the proof of the following proposition.
Corollary 3. The direction cosines of a vector ⃗v ̸= ⃗0 in En do not change if
⃗v is multiplied by a scalar a > 0; they change sign only if a < 0. Hence the
direction cosines of −⃗v are those of ⃗v with opposite signs.

§3. Angles and Directions
143
Note 4. The notions of angle and unit vector were deﬁned by using inner
products and absolute values. Thus one can deﬁne them, in exactly the same
manner, not only in En but also in other vector spaces (see Note 3, §1) in which
inner products (satisfying Theorem 1 of §2) are deﬁned. Such vector spaces are
called Euclidean. For more details, see §9.
§4. Lines and Line Segments
The term “line” shall always mean a line extending indeﬁnitely (never a line
segment, which is only a part of a line).
¯a
¯b
⃗u
¯x
¯0
Figure 17
To obtain all points of a straight
line in E2 or E3, we take a “vector”
⃗u = −→
ab (joining two given points ¯a
and ¯b on the line) and then, so to say,
“stretch” it indeﬁnitely in both direc-
tions, i.e., multiply ⃗u by all possible
scalars t ∈E1 (positive, negative, and
0). Now, by deﬁnition,
⃗u = −→
ab = ¯b −¯a = −→
0b −−→
0a
(see Figure 17). The “position vector” −→
0x of any point ¯x on the line ab is,
geometrically, the sum of −→
0a and −→
ax: −→
0x = −→
0a + −→
ax. Here the vector −→
ax is a
scalar multiple of −→
ab = ⃗u; speciﬁcally, −→
ax = t⃗u, where
t = |−→
ax|
|⃗u|
or
t = −|−→
ax|
|⃗u|
according to whether the vectors −→
ax and ⃗u have the same or opposite directions.
Thus we have
¯x = −→
0x = −→
0a + −→
ax = ¯a + t⃗u.
Conversely, every point of that form (for any t ∈E1) lies on the line ab. Thus
the line ab in E2 or E3 is exactly the set of all points ¯x of the form
¯x = ¯a + t⃗u = ¯a + t(¯b −¯a),
t ∈E1.
By varying t, we obtain all points of ab.
It is natural to accept this as a deﬁnition of a line in En.
Deﬁnition 1.
The line passing through two given points ¯a, ¯b ∈En (¯a ̸= ¯b) (equivalently,
the line passing through ¯a in the direction of a vector ⃗u = −→
ab = ¯b −¯a) is

144
Chapter 3. The Geometry of n Dimensions. ∗Vector Spaces
the set of all points ¯x ∈En of the form
¯x = ¯a + t⃗u = ¯a + t(¯b −¯a),
where t is a variable which takes on all real values (we call it a real
parameter). In symbols,
Line ab = {¯x ∈En | ¯x = ¯a + t⃗u for some t ∈E1};
⃗u = ¯b −¯a = −→
ab ̸= ⃗0. (1)
Brieﬂy, we call it “the line ¯x = ¯a + t⃗u ” or “the line ¯x = ¯a + t(¯b −¯a)”;
instead, we may write ¯x = (1 −t)¯a + t¯b (rearranging brackets). The formula
¯x = ¯a + t⃗u (respectively, ¯x = ¯a + t(¯b −¯a)) is called the equation of the line
(more precisely, its parametric equation). In the ﬁrst case, we say that the line
is given by a point ¯a and a direction ⃗u; in the second case, it is determined
by two of its points, ¯a and ¯b. In terms of the coordinates of ¯x, ¯a and ⃗u (or ¯b),
the parametric equation is equivalent to n simultaneous equations (called the
parametric coordinate equations of the line):
xk = ak + tuk = ak + t(bk −ak),
k = 1, 2, . . ., n.
(2)
It is a great advantage of the vector notation that one vector equation replaces
n coordinate equations.
Now, since the vector ⃗u (used to form the line) is anyway being multiplied
by arbitrary scalars t, it is clear that the line (1) will not gain or lose any of
its points if ⃗u is replaced by some scalar multiple c⃗u (c ̸= 0). In particular,
we may replace ⃗u by its unit ⃗u/|⃗u| (taking c = 1/|⃗u|). Thus we may always
assume (if desirable) that ⃗u is a unit vector itself. In this case the equation
¯x = ¯a + t⃗u (and the equations (2)) are said to be normal. To normalize an
equation of a line means to replace ⃗u by ⃗u/|⃗u|. Since c may also be negative,
the line (1) does not change if we replace ⃗u by −⃗u; thus the direction of a
line is not uniquely determined: we always have two choices of the unit vector
⃗u. If, however, a particular ⃗u is prescribed in advance, we speak of a directed
line. The coordinates of the direction vector ⃗u (or any of its scalar multiples
c⃗u) are called a set of n direction numbers for the line (1); of course, there are
inﬁnitely many such sets corresponding to diﬀerent values of c. In particular,
the direction cosines of ⃗u (i.e., the components of the unit vector ⃗u/|⃗u|) are
called a set of direction cosines of the line. (There are precisely two such sets,
namely the direction cosines of ⃗u and those of −⃗u.)
In addition to changing the vector ⃗u, we may also alter the parameter t.
Indeed, since t is anyway supposed to take on all real values, nothing will
change if we replace it by some other variable expression θ which likewise runs
over all real values, e.g., by θ = 1 −t. Thus, every line has inﬁnitely many
parametric equations, depending on the choice of the parameter. We can also
entirely eliminate the parameter from equations (2) by rewriting them as follows

§4. Lines and Line Segments
145
(assuming that bk −ak ̸= 0), and then dropping “t” on the right, if desirable:
x1 −a1
b1 −a1
= x2 −a2
b2 −a2
= · · · = xn −an
bn −an
= t.
(3)
One can write the equations in that form even if some of the denominators
vanish.
It is then understood that the corresponding numerators are to be
equated to 0, e.g., xk −ak = 0, and this equation replaces the (senseless)
equation involving the fraction with the vanishing denominator. Note that the
xk in (3) and (2) are variables.
Dropping t in (3), we are left with n −1 equations between n fractions
involving only the (ﬁxed) coordinates of ¯a and ¯b and the (variable) coordinates
of ¯x. A point ¯x then belongs to the line ab if and only if its coordinates satisfy
these n −1 equations (called the nonparametric equations of a line through
two given points). If, instead, the line is given in terms of one point ¯a and a
direction vector ⃗u = ¯b −¯a, then, replacing bk −ak by uk, we get
x1 −a1
u1
= x2 −a2
u2
= · · · = xn −an
uk
.
(4)
Here the uk form a set of direction numbers. Normalizing (i.e., dividing the
uk by |⃗u| =
p
u2
1 + u2
2 + · · · + u2n ), we get a set of direction cosines of ab.
If ⃗u and ⃗v are the direction vectors of two lines, we also call ⟨⃗u,⃗v⟩(as deﬁned
in §3) the angle between the two lines. This angle is uniquely determined if
the lines are directed; otherwise, by changing the sign of ⃗u or ⃗v, one can also
change the sign of cos⟨⃗u,⃗v⟩. (Verify this!) Thus one obtains two angles, α and
π −α. Two lines are said to be perpendicular or orthogonal if ⃗u ⊥⃗v, i.e., if
⃗u · ⃗v =
n
X
k=1
ukvk = 0.
They are said to be parallel if one of ⃗u and ⃗v is a scalar multiple of the other,
say ⃗u = c⃗v; in this case, we also say that the vectors ⃗u and ⃗v are collinear (see
Deﬁnition 3 in §2).
Note 1. More precisely, we say that ⃗u and ⃗v are vector-collinear to mean
that ⃗u = c⃗v or ⃗v = c⃗u. On the other hand, it is customary to say that three
points ¯a, ¯b, ¯c are collinear iﬀthey lie on one and the same line (a diﬀerent
notion!).
If, in the parametric equation ¯x = ¯a + t⃗u, or
¯x = ¯a + t(¯b −¯a) = (1 −t)¯a + t¯b,
we let t vary not over all of E1 but only over some subset of E1, then we obtain
only a part of the line ab. In particular, by letting t vary over some interval
in E1, we obtain what is called a line segment in En. (We reserve the name
“interval” for another kind of sets, to be deﬁned in §7. In E1, both kinds of

146
Chapter 3. The Geometry of n Dimensions. ∗Vector Spaces
sets coincide with ordinary intervals.) Exactly as in E1, we have four types of
such line segments. We deﬁne them below.
Deﬁnition 2.
Given two points ¯a and ¯b in En, we deﬁne the open line segment from ¯a
to ¯b, denoted L(¯a,¯b), as the set of all points ¯x ∈En of the form
¯x = ¯a + t(¯b −¯a) = (1 −t)¯a + t¯b,
where t varies over the interval (0, 1) ⊂E1, i.e., 0 < t < 1. In symbols,
L(a, b) = {¯x ∈En | ¯x = ¯a + t(¯b −¯a) for some t ∈(0, 1)}.
This is also brieﬂy written as L(a, b) = {¯a+t(¯b−¯a) | 0 < t < 1}, i.e., “the
set of all points ¯a + t(¯b −¯a) for 0 < t < 1.”
Similarly, the closed line segment L[¯a,¯b] is
L[¯a,¯b] = {¯a + t(¯b −¯a) | 0 ≤t ≤1};
the half-open line segment is
L(¯a,¯b] = {¯a + t(¯b −¯a) | 0 < t ≤1},
and the half-closed one is
L[¯a,¯b) = {¯a + t(¯b −¯a) | 0 ≤t < 1}.
In all cases, ¯a and ¯b are called the endpoints of the line segment, and
|¯b −¯a| is called its length.
Note 2. (i) The line segments are also deﬁned in case ¯a = ¯b (“degenerate
case”). (ii) Setting t = 0 or t = 1, we obtain the endpoints ¯a and ¯b, respectively.
The other points are obtained as t varies between 0 and 1.
Examples.
Take three points in E3: ¯a = (0, −1, 2), ¯b = (1, 1, 1), ¯c = (3, 1, −1).
Then the line ab has the parametric equation ¯x = ¯a + t(¯b −¯a); or, in
coordinates,
x1 = 0 + t(1 −0) = t, x1 = −1 + 2t, x3 = 2 −t;
or, writing (x, y, z) for (x1, x2, x3),
x = t, y = −1 + 2t, z = 2 −t.
Eliminating t (as in formula (3)), we obtain
x
1 = y + 1
2
= z −2
−1 ; or, normalizing,
x
1/
√
6
= y + 1
2/
√
6
=
z −2
−1/
√
6
,

§4. Lines and Line Segments
147
where (1, 2, −1) is a set of direction numbers (coordinates of the vector
⃗u = −→
ab = ¯b −¯a), while
 1
√
6,
2
√
6, −1
√
6

is a set of direction cosines (coordinates of the unit vector ⃗u/|⃗u|). A set
of direction numbers for the line bc is obtained from the vector ⃗v = −→
bc =
¯c −¯b = (2, 0, −2); the direction cosines are (2/
√
8, 0, −2/
√
8). Using
formula (4), we obtain the coordinate equations in the symbolic form
(not normalized)
x −1
2
= y −1
0
= z −1
−2 ; i.e., x −1
2
= z −1
−2
and y −1 = 0.
The angle between −→
ab and −→
bc is given by
cos⟨⃗u,⃗v⟩= ⃗u · ⃗v
|⃗u| |⃗v| =
4
√
48
=
1
√
3
.
∗Note 3. Any line, ¯x = ¯a + t⃗u, in En is an isomorphic copy of E1, in
the sense of §14 of Chapter 2. Indeed, let us deﬁne a mapping f on E1 by
setting (∀t ∈E1) f(t) = ¯a + t⃗u (with ¯a and ⃗u ﬁxed) and let L denote the
given line. Clearly, as t varies over E1, f(t) varies over L; thus f is a map of
E1 onto L. This map is also easily proved to be one-to-one, and it becomes
an ordered-ﬁeld–isomorphism if operations and inequalities in L are deﬁned as
follows: Let ¯x = f(t), ¯x′ = f(t′); then, by deﬁnition,
x + x′ = f(t + t′), ¯x¯x′ = f(tt′), and ¯x < ¯x′ iﬀt < t′
(cf. Problem 10 below).
Problems on Lines, Angles, and Directions in En
1. Prove in detail Corollary 1(b) and Corollary 3 of §3. Also show that the
angle ⟨⃗u,⃗v⟩does not change if ⃗u and ⃗v are multiplied by some scalars of
the same sign. What if the scalars are of diﬀerent signs?
2. Prove geometrically (in E3) that the dot product ⃗v · ⃗u, where ⃗u is a unit
vector, is the orthogonal (directed) projection of ⃗v on the directed line
¯x = ¯a+t⃗u (where ¯a is arbitrary but ﬁxed). Deﬁne analogously projections
of vectors on directed lines in En.
3. Find the mutual angles between the vectors ⃗u, ⃗v, and ⃗w speciﬁed in
Problem 1 of §1 (do cases (a)–(d) separately). Also normalize these vec-
tors and ﬁnd their direction cosines. Verify by actual computation, in at
least one case, that Formula (b) of Corollary 1 in §3 holds. Are any two
of the vectors perpendicular?

148
Chapter 3. The Geometry of n Dimensions. ∗Vector Spaces
4. Let ⃗u, ⃗v ∈E3, and let
⃗w = (u2v3 −u3v2, u3v1 −u1v3, u1v2 −u2v1).
Show that ⃗u ⊥⃗w and ⃗v ⊥⃗w.
Note: The vector ⃗w so deﬁned is called the cross product of ⃗u and ⃗v
and is denoted by ⃗u × ⃗v or symbolically by the “determinant”

⃗ı
⃗
⃗k
u1
u2
u3
v1
v2
v3

,
where ⃗ı, ⃗, ⃗k are the basic unit vectors in E3. Show that
⃗u × ⃗v = −(⃗v × ⃗u)
and that in general
(⃗u × ⃗v) × ⃗x ̸= ⃗u × (⃗v × ⃗x).
(Give a counterexample!)
Also prove that two lines ¯x = ¯a + t⃗u and
¯x = ¯b + t⃗v in E3 are parallel iﬀ⃗u × ⃗v = 0. (Note that cross products are
deﬁned only in E3.)
5. Find a vector (unit) in E3, with positive coordinates, which forms equal
angles with the axes (i.e., with the basic unit vectors). Solve a similar
problem in E4.
6. Given three points in E4: ¯a = (0, 0, −1, 2), ¯b = (2, 4, −3, −1), ¯c =
(5, 4, 2, 0). Find the angles of the triangle ¯a¯b ¯c and the equations of its
sides, in nonparametric form. Normalize the equations. For each side
give a set of direction numbers and direction cosines.
6’. Let ¯b be any point on the line ¯x = ¯a + t⃗u. Show that this line coincides
with the line ¯x = ¯b + θ⃗u.
[Hint: Let ¯b = ¯a + t0⃗u. Find θ.]
7. A globe (solid sphere) in En, with center ¯p and radius ϵ > 0, is by deﬁni-
tion the set
{¯x ∈En | ρ(¯x, ¯p) < ϵ},
denoted G¯p(ϵ).
Show that if ¯a, ¯b ∈G¯p(ϵ), then also L[¯a, ¯b] ⊆G¯p(ϵ).
Prove the same property (called convexity) also for the closed globe
G¯p(ϵ) = {¯x ∈En | ρ(¯x, ¯p) ≤ϵ}.
Disprove it for the nonsolid sphere
S¯p(ϵ) = {¯x ∈En | ρ(¯x, ¯p) = ϵ}.
[Hint: Take a line through ¯p; say, ¯x = ¯p + t⃗e1. Let −ϵ ≤t ≤ϵ.]

§4. Lines and Line Segments
149
8. In Problem 6 ﬁnd the nonparametric equations of the lines through each
vertex parallel to the opposite side of the triangle ¯a¯b ¯c. Find also the
points of intersection of these three lines.
9. Prove that if a vector ⃗v in En is perpendicular to each of the n basic unit
vectors, i.e., ⃗v · ⃗ek = 0, k = 1, 2, . . ., n, then necessarily ⃗v = ⃗0. Infer that
if ⃗v · ⃗x = 0 for all ¯x, then ⃗v = ⃗0.
10. Prove that the map f deﬁned in Note 3 of §4 is one-to-one.
[Hint: Show that t ̸= t′ =⇒|f(t) −f(t′)| = ρ(f(t), f(t′)) ̸= 0.]
Next, verify that the line L is an ordered ﬁeld, with zero element f(0) = a
and unity f(1), under operations and ordering as deﬁned in Note 3, and
that f(t+t′) = f(t)+f(t′) and f(tt′) = f(t)·f(t′), by deﬁnition. ∗(Hence
infer that f is an isomorphism between the ﬁelds E1 and L.)
11. (i) Given a point ¯p ∈En and a line ¯x = ¯a + t⃗u (|⃗u| = 1), ﬁnd the
orthogonal projection of ¯p on the line, i.e., a point ¯x0 = ¯a + t0⃗u such that
−→
x0p ⊥⃗u.
[Hint: By Problem 2, t0 = (¯p −¯a) · ⃗u; verify that (¯p −¯x0) · ⃗u = 0 if ¯x0 = ¯a + t0⃗u.]
(ii) Show that
ρ(¯p, ¯x0) = |¯p −¯x0| =
q
|¯p −¯a|2 −t2
0 = |¯p −¯a| | sin α|,
where α = ⟨⃗u, ¯p −¯a⟩.
[Hint: Use the formulas
|¯p −¯x0|2 = (¯p −¯x0) · (¯p −¯x0)
and
| sin α| =
p
1 −cos2 α.]
(iii) Noting that ¯a is an arbitrary point on the line, infer that ρ(¯p, ¯x0) is
the least distance from ¯p to a point ¯a on the line.
12. Find the three altitudes of the triangle ¯a¯b ¯c of Problem 6. (Use Prob-
lem 11.)
13. Given two nonparallel lines in En: ¯x = ¯a + t⃗u and ¯y = ¯b + θ⃗v, where t, θ
are real parameters and |⃗u| = |⃗v| = 1. Find two points ¯x and ¯y on these
lines such that (¯x −¯y) ⊥⃗u and simultaneously (¯x −¯y) ⊥⃗v. Infer from
Problem 11 that, for these points, ρ(¯x, ¯y) is the shortest distance between
a point on one line and a point on the other line.
[Hint: We have to satisfy the simultaneous equations in two unknowns:
(¯x −¯y) · ⃗u = 0
and
(¯x −¯y) · ⃗v = 0.
Substitute ¯x = ¯a + t⃗u and ¯y = ¯b + θ⃗v, and transform the two equations into
(¯a −¯b) · ⃗u + t −θ(⃗u · ⃗v) = 0 and (¯a −¯b) · ⃗v −θ + t(⃗u · ⃗v) = 0.
Solve for t, θ.]

150
Chapter 3. The Geometry of n Dimensions. ∗Vector Spaces
§5. Hyperplanes in En. ∗Linear Functionals on En
I. A plane in E3 can be geometrically described as follows. Fix a point ¯a of
the plane and a vector ⃗u = −→
ab perpendicular to the plane (imagine a pencil
standing vertically at ¯a on the horizontal plane of the table). Then a point ¯x
lies on the plane iﬀ⃗u ⊥−→
ax (the pencil ⃗u is perpendicular to the line ax drawn
on the table). It is natural to accept this as a deﬁnition in En as well (here
“planes” are also called “hyperplanes”).
Deﬁnition 1.
By a hyperplane (brieﬂy, plane) through a given point ¯a ∈En, perpen-
dicular to a ﬁxed vector ⃗u ̸= ⃗0, we mean the set of all points ¯x ∈En such
that ⃗u is perpendicular to −→
ax. In symbols, it is the set
{¯x ∈En | ⃗u ⊥−→
ax}.
The vector ⃗u is called a normal vector of the plane (not to be confused
with “normalized vector”). Note: ⃗u ̸= ⃗0.
Since
−→
ax = ¯x −¯a = (x1 −a1, x2 −a2, . . . , xn −an),
the formula ⃗u ⊥−→
ax, or (by deﬁnition) ⃗u · (−→
ax) = 0, can also be written as
⃗u · (¯x −¯a) = 0; or, in terms of coordinates,
n
X
k=1
uk(xk −ak) = 0, where ⃗u ̸= 0 (i.e., not all uk vanish).
(1)
Formula (1) is called the coordinate equation of the plane, while the formula
⃗u · (¯x −¯a) = 0 is its vector equation. We brieﬂy refer to the plane by giving its
equation; e.g.,
“the plane
n
X
k=1
uk(xk −ak) = 0”
(with the numbers uk and ak as speciﬁed).
The plane consists of exactly
the points ¯x whose coordinates satisfy the equation of the plane. Removing
brackets in (1) and transposing the constant terms, we obtain
u1x1 + u2x2 + · · · + unxn = c

where c =
n
X
k=1
ukak

.
(2)
Algebraically, this is a linear equation in the variables xk, with given coef-
ﬁcients uk (not all 0) and constant term c. Thus every hyperplane in En has
a linear coordinate equation, i.e., one of the form (2). Conversely, given any

§5. Hyperplanes in En. ∗Linear Functionals on En
151
equation of that form, with at least one of the uk (say, u1) not zero, we can
rewrite it in the form
u1

x1 −c
u1

+ u2x2 + · · · + unxn = 0.
Then, setting a1 = c
u1
and ak = 0 for k ≥2, we obtain from it an equation of
the form (1), representing a hyperplane through
¯a =
 c
u1
, 0, . . . , 0

,
perpendicular to ⃗u = (u1, . . . , un). Thus we have proved the following propo-
sition.
Theorem 1. A set A ⊂En is a hyperplane iﬀA is exactly the set of all points
¯x = (x1, . . . , xn) satisfying some equation of the form (2), with at least one
of the coeﬃcients uk not 0. These coeﬃcients are the components of a vector
⃗u = (u1, . . . , un) normal to the plane.
In this connection, (2) is called the general equation of a hyperplane. Clearly,
we obtain an equivalent equation (representing the same point set) if we multi-
ply both sides of (2) by a nonzero scalar q. Then uk is replaced by quk, i.e., ⃗u
is replaced by q⃗u. This shows that we may replace the normal vector ⃗u by any
scalar multiple q⃗u (q ̸= 0), without changing the hyperplane. In particular,
setting q = 1/|⃗u|, we replace ⃗u by its uit ⃗u/|⃗u| and get
1
|⃗u|(u1x1 + · · · + unxn) = c
|⃗u|, with |⃗u| =
s n
X
k=1
u2
k.
(3)
This is called the normalized or normal equation of the hyperplane. Actually,
there are two normal equations since we may also replace ⃗u by −⃗u, changing
all signs in (3), i.e., changing the direction of ⃗u. If, however, the direction is
prescribed, we speak of a directed hyperplane.
If all but one coeﬃcients uk vanish, then ⃗u becomes a scalar multiple of the
corresponding basic unit vector ⃗ek; the plane is then perpendicular to ⃗ek, and
we say that it is “perpendicular to the k-th axis”. Equation (2) then turns into
ukxk = c or xk = ck, where ck = c/uk; e.g., x1 = 5 is the equation of a plane
perpendicular to ⃗e1. It consists of all ⃗x ∈En, with x1 = 5. Imitating geometry
in E3, we also deﬁne the following:
The angle between two hyperplanes with normal vectors ⃗u and ⃗v is, by deﬁ-
nition, the angle ⟨⃗u,⃗v⟩between these vectors. Actually, unless the hyperplanes
are directed, there are two angles: ⟨⃗u,⃗v⟩and ⟨−⃗u,⃗v⟩. In particular, the hyper-
planes are perpendicular to each other iﬀ⃗u ⊥⃗v and parallel to each other iﬀ
⃗u = q⃗v or ⃗v = q⃗u for some q ∈E1 (i.e., if ⃗u and ⃗v are collinear). The angle
between a hyperplane (with normal vector ⃗u) and a line with direction vector
⃗v is, by deﬁnition, the complement of ⟨⃗u,⃗v⟩. It may be deﬁned as the angle α

152
Chapter 3. The Geometry of n Dimensions. ∗Vector Spaces
whose cosine equals sin⟨⃗u,⃗v⟩= ±
p
1 −cos2⟨⃗u,⃗v⟩. (Clearly, there are two such
angles.) Accordingly, the plane and the line are said to be parallel if ⃗u ⊥⃗v
and perpendicular if ⃗u ∥⃗v. A set of points in En is said to be coplanar if it
is contained in some hyperplane. A set of vectors in En is vector-coplanar iﬀ
these vectors are perpendicular to some ﬁxed vector ⃗u ∈En; so are, e.g., any
n −1 of the basic unit vectors ⃗ek, because all of them are perpendicular to the
remaining ⃗ek.
∗II.
Consider again the left side of equation (2), without the constant term c:
n
X
k=1
ukxk,
or, in vector form, ¯u · ¯x. Let us deﬁne a map f: En →E1, setting (∀¯x ∈En)
f(¯x) = ¯u · ¯x, with ¯u ﬁxed. By properties of dot products (Theorem 1 of §2),
we have, for any ¯x, ¯y ∈En and a ∈E1,
¯u · (¯x + ¯y) = ¯u · ¯x + ¯u · ¯y and ¯u · (a¯x) = a(¯u · ¯x);
or, since ¯u · ¯x = f(¯x),
f(¯x + ¯y) = f(¯x) + f(¯y) and f(a¯x) = af(¯x)
(4)
for all ¯x, ¯y ∈En, a ∈E1.
It follows that (∀a, b ∈E1) (∀¯x, ¯y ∈En)
f(a¯x + b¯y) = f(a¯x) + f(b¯y) = af(¯x) + bf(¯y).
By induction (which we leave to the reader), given any scalars a1, a2, . . . , am ∈
E1 and vectors ¯x1, . . . , ¯xm ∈En, we obtain
f
 m
X
i=1
ai¯xi

=
m
X
i=1
aif(¯xi).
(5)
In other words, the map f carries every linear combination of vectors ¯x1,
. . . , ¯xm in En into the corresponding linear combination of the function values
f(¯xi), i = 1, 2, . . ., m. We express this by saying that f preserves linear combi-
nations, or preserves vector addition and multiplication by scalars. Mappings
with that property turn out to be of great importance for the theory of vector
spaces in general (cf. §1, Note 3). They are called linear maps (because they
preserve linear combinations).
In particular, for Euclidean spaces En and Er, we have the following.
Deﬁnition 2.
A mapping f: En →Er is said to be linear iﬀit preserves linear combi-
nations, i.e., satisﬁes (4) and hence (5) (see above). Linear maps of En
into E1, f: En →E1 (r = 1), are called linear functionals.

§5. Hyperplanes in En. ∗Linear Functionals on En
153
Theorem 2. A mapping f: En →E1 is a linear functional iﬀthere is a vector
¯u ∈En such that (∀¯x ∈En)
f(¯x) = ¯u · ¯x =
n
X
k=1
ukxk.1
Proof. If such a vector ¯u exists then, as was shown above, f satisﬁes (4) and
hence is linear. Conversely, if f is linear, then f preserves linear combinations.
Now, by Theorem 2 of §1, every ¯x ∈En is such a combination, namely,
¯x =
n
X
k=1
xk¯ek.
Thus, by (5),
f(¯x) = f
 n
X
k=1
xn¯ek

=
n
X
k=1
xkf(¯ek),
¯x ∈En.
Here, since f is a map into E1, the function values f(¯ek) are in E1, i.e., cer-
tain real numbers.
Then let f(¯ek) = uk ∈E1, k = 1, 2, . . ., n, and set
¯u = (u1, . . . , un). Then we have, for all ¯x ∈En,
f(¯x) =
n
X
k=1
xkf(¯ek) =
n
X
k=1
xkuk = ¯x · ¯u = ¯u · ¯x,
by the properties of dot products.
Thus u is the desired vector, and all is
proved.
□
Note 1.
The vector ¯u of Theorem 2 is unique. Indeed, suppose there are
two vectors, ¯u and ¯v such that
¯u · ¯x = f(¯x) = ¯v · ¯x
for all ¯x ∈En. Then
(¯u −¯v) · ¯x = ¯u · ¯x −¯v · ¯x = 0
for all ¯x ∈En. But, by Problem 9 of §4, this implies that ¯u −¯v = ¯0, i.e., ¯u = ¯v
after all. Thus ¯u is unique indeed.
We now establish a connection between hyperplanes and those linear func-
tionals that are not identically zero.2
1 In other words, all linear functionals on En are of the kind that we considered above,
i.e., arise from dot products, as in equation (2).
2 We say that a function f: En →E1 is identically zero, and write f ≡0, iﬀf(¯x) = 0 for
all ¯x ∈En. Otherwise, we write f ̸≡0. The latter means that f(¯x) ̸= 0 for at least one
¯x ∈En.

154
Chapter 3. The Geometry of n Dimensions. ∗Vector Spaces
Our next theorem shows that hyperplanes are exactly all those sets in En
whose equations are of the form f(¯x) = c, where f is a linear functional not
identically 0 and c is a real constant. More precisely, we have the following
result.
Theorem 3. A set A ⊆En is a hyperplane iﬀthere is a linear functional
f: En →E1, f ̸≡0, and some c ∈E1, such that
A = {¯x ∈En | f(¯x) = c},
i.e., A consists of exactly those points ¯x ∈En for which f(¯x) = c.
Proof. If A is a hyperplane, its general equation (2) may also be written
as ¯u · ¯x = c (since ¯u · ¯x is, by deﬁnition, the left-hand side of (2)).
Thus
A = {¯x ∈En | ¯u · ¯x = c}. Setting f(¯x) = ¯u · ¯x, we obtain a linear functional
f: En →E1, by Theorem 2. Then A = {¯x ∈En | f(¯x) = c}. Moreover, as
¯u ̸= ¯0 in (2), f is not ≡0 (Problem 9 of §4). Thus A is as stated in Theorem 3.
Conversely, if A = {⃗x ∈En | f(¯x) = c}, with f a linear functional ̸≡0, then
again Theorem 2 yields a vector ¯u ̸= ¯0 such that
f(¯x) = ¯u · ¯x =
n
X
k=1
ukxk
for all ¯x ∈En. Then we obtain
A = {¯x ∈En | f(¯x) = c} =

¯x ∈En |
n
X
k=1
ukxk = c

,
and this means that A is exactly the set of points satisfying equation (2), i.e., a
hyperplane. Thus all is proved.
□
Note 2.
This theorem could be accepted as an alternative deﬁnition of a
hyperplane. It has the advantage that it replaces the notion of dot products by
that of a linear functional, without any reference to “angles” or orthogonality
(which are deﬁned in Euclidean spaces only; cf. Note 4 in §3).
Examples.
(1′′) Let ¯a = (1, −2, 0, 3) and ⃗u = (1, 1, 1, 1) in E4. Then the plane normal
to ⃗u through ¯a has the equation
(¯x −¯a) · ⃗u =
4
X
k=1
(xk −ak)uk = 0,
or
(x1 −1) · 1 + (x2 + 2) · 1 + (x3 −0) · 1 + (x4 −3) · 1 = 0,
or x1 +x2 +x3 +x4 = 2. The corresponding linear functional f: E4 →E1
is deﬁned by f(¯x) = x1 + x2 + x3 + x4.

§5. Hyperplanes in En. ∗Linear Functionals on En
155
(2′′) The two linear equations
x + 3y −2 = 1 and 2x + y −z = 0
(where x, y, z stand for x1, x2, x3) represent two planes in E3 with
normal vectors
⃗u = (1, 3, −2) and ⃗v = (2, 1, −1),
respectively. (Note that, by formulas (1) and (2), the components uk of
the normal vector are exactly the coeﬃcients of the variables xk, here
denoted by x, y, z; thus, in the ﬁrst plane, u1 = 1, u2 = 3 and u3 = −2,
so that ⃗u = (1, 3, −2); similarly for ⃗v.)
The corresponding linear functionals on E3 (call them f and g, respec-
tively) are given by
f(x, y, z) = x + 3y −2z and g(x, y, z) = 2x + y −z
(these are the left sides of the equations of the planes, without the con-
stant terms). The second plane passes through ¯0 (why?), and so its vector
equation is (¯x−¯0)·⃗v = 0 or ⃗x·⃗v = 0, where ⃗v = (2, 1, −1). The equation
of the ﬁrst plane can be rewritten as
(x1 −1) + 3(x2 −0) −2(x3 −0) = 0;
it passes through ¯a = (1, 0, 0), and its vector equation is (¯x −¯a) · ⃗u = 0,
with ¯a and ⃗u as above. The angle between the planes is given by
cos⟨⃗u,⃗v⟩= ⃗u · ⃗v
|⃗u| |⃗v| =
7
√
14 · 6 =
7
√
84 =
7
2
√
21.
Their normalized equations are
x + 3y −2z −1
√
14
= 0 and 2x + y −z
√
6
= 0.
Problems on Hyperplanes in En (cf. also §6)
1. Given a hyperplane 3x1 + 5x2 −x3 + 2x4 = 9 in E4, ﬁnd
(i) a few points that lie on it, and some that do not;
(ii) a unit vector normal to the plane (thus normalize the equation);
(iii) the angles between the plane and the basic unit vectors ⃗ek;
(iv) the equations of the planes parallel to the given plane and passing
through
(a) the origin;
(b) ¯p = (2, 1, 0, −1);

156
Chapter 3. The Geometry of n Dimensions. ∗Vector Spaces
(v) the equations of the line through ¯0, perpendicular to the plane;
(vi) the intercepts of the plane, i.e., four numbers a, b, c, d such that the
points (a, 0, 0, 0), (0, b, 0, 0), (0, 0, c, 0), and (0, 0, 0, d) lie on the
plane (at these points the plane meets the four “axes”);
(vii) the angle between the plane and the line
x1 −1
3
= x2
4 = x3
5 = x4 + 2
−1
;
(viii) the point of intersection of the plane and line given in (vii).
[Hint: Using parametric equations, express x1, x2, x3, and x4 in terms of t and
substitute in the equation of the plane to evaluate t. Explain!]
2. Find the normal equation of the hyperplane in E4 that
(i) is perpendicular to the line given in Problem 1(vii) and passes
through the point
(a) ¯p = (3, 1, −2, 0);
(b) ¯p = (−1, 2, 1, 1);
(ii) is perpendicular to, and bisects, the line segment L(¯a,¯b), where ¯a =
(0, −1, 2, 2), ¯b = (2, −3, 0, 4) (ﬁrst ﬁnd the midpoint of L(¯a,¯b));
(iii) contains the points
(2, 0, 0, −1), (−3, 0, 2, 3), (1, 1, 2, 0), and (0, 0, 0, 0).
[Hint for (iii): As the points lie on the plane, their coordinates satisfy its general
equation, ax1 + bx2 + cx3 + dx4 = e. Substituting them, obtain four equations
in the unknowns a, b, c, d, e.
Solve them for the ratios b/a, c/a, d/a, e/a
(assuming a ̸= 0) and substitute into
x1 + b
a x2 + c
a x3 + d
a x4 = e
a .
This is the required equation.]
3. A reader acquainted with the theory of determinants will verify that the
equation of a hyperplane in En through n given points ¯a1, . . ., ¯an is

x1
x2
. . .
xn
1
a11
a12
. . .
a1n
1
. . . . . . . . . . . . . . . . . . . . . . .
an1
an2
. . .
ann
1

= 0,
(6)
provided the determinant does not vanish identically, i.e., regardless of
the choice of the point ¯x = (x1, x2, . . ., xn).

§5. Hyperplanes in En. ∗Linear Functionals on En
157
[Hint:
Each of the n points ¯ai = (ai1, ai2, . . . , ain) when substituted for ¯x =
(x1, . . . , xn) in (6) makes the determinant vanish (for two rows become equal). Thus
all ¯ai satisfy equation (6) and so lie in the plane represented by (6) (the equation being
linear in x1, . . . , xn, upon expansion by elements of the ﬁrst row).]
Use this result for another solution of Problem 2(iii).
4. Show that the perpendicular distance from a point ¯p to a hyperplane
n
X
k=1
ukxk = c
(or ¯u · ¯x = c, where ¯u is a normal vector) in En is given by
ρ(¯p, ¯x0) = |¯u · ¯p −c|
|¯u|
.
(Here ¯x0 is the orthogonal projection of ¯p, i.e., a point on the plane such
that −→
px0 is perpendicular to the plane.)
[Hint: Consider the line ¯x = ¯p + t⃗v, where ⃗v = −⃗u/|⃗u|, and ﬁnd the value of t for
which ¯x = ¯p + t⃗v lies on both the line and the plane. Then |t| = ρ(¯p, ¯x0).]
Note. For a directed plane, this t is called the directed distance from ¯p
to the plane (it may be negative). Unless otherwise stated, the direction
of the plane is so chosen that the constant c in ¯u · ¯x = c is positive. Thus
the directed distance is deﬁned always, except when c = 0.
5. Let P = 0 and P ′ = 0 be the equations of two intersecting planes in E3.
(Here P stands for P3
k=1 ukxk −c, and P ′ stands for P3
k=1 vkxk −d.)
Show that, for any choice of k, k′ ∈E1, the equation
kP + k′P ′ = 0
represents a plane passing through the intersection line of the planes
P = 0 and P ′ = 0, and that all such planes in E3 can be obtained by a
suitable choice of k and k′. Note: kP + kk′P ′ = 0 is called the equation
of the pencil of planes passing through the intersection line of the two
given planes; k, k′ are called parameters.
[Hint: To show that all the required planes can be so obtained, take any point ¯p ∈E3
and prove that the parameters k, k′ can always be so chosen that the plane kP +k′P ′ =
0 passes through ¯p.]
6. Find the direction cosines of the intersection line of two planes in E3:
2x −3y + z = 4 and x + y −2 = 1.
Also give a set of parametric equations for the line.
[Hint: The points of the line satisfy the equations of both planes, hence also all equa-
tions that follow from them by eliminating one of the variables x, y, z. Thus, obtain
two equations: one in x and y, the other in x and z only. Choose x as the param-
eter t: x = t, and also express y and z in terms of t, thus obtaining the parametric
equations.]

158
Chapter 3. The Geometry of n Dimensions. ∗Vector Spaces
7. From Problem 4, ﬁnd the distance between two parallel planes: ¯u · ¯x = c
and ¯u · ¯x = d in En. (Answer: |c −d|/|⃗u|.) Give an example in E3.
§6. Review Problems on Planes and Lines in E
3
1. Determine whether the plane 4x −y + 3z + 1 = 0 contains the points
(−1, 6, 3), (3, −2, −5), (0, 4, 1), (2, 0, 5), (2, 7, 0), (0, 1, 0).
2. A point M moves from (5, −1, 2) in a direction parallel to OY . At what
point will it meet the plane x −2y −3z + 2 = 0?
3. What special properties have the planes
(a) 3x −5z + 1 = 0?
(b) 9y −2 = 0?
(c) x + y −5 = 0?
(d) 2x + 3y −7z = 0?
(e) 8y −3z = 0?
4. Find equations of the planes
(a) parallel to the XOY -plane and passing through (2, −5, 3);
(b) containing OZ and the point (−3, 1, −2);
(c) parallel to OX and passing through (4, 0, −2) and (5, 1, 7).
5. Find the x, y, z intercepts of the planes
(a) 2x −3y −z + 12 = 0;
(b) 5x + y −3z −15 = 0;
(c) x −y + z −1 = 0;
(d) x −4z + 6 = 0;
(e) 5x −2y + z = 0.
6. Draw the lines of intersection between the coordinate planes and the plane
5x + 2y −3z −10 = 0.
7. The plane 3x+y −2z = 18 and the coordinate planes form a tetrahedron
OABC. Find the sides of the cube inscribed in that tetrahedron, with
one vertex lying in the given plane, while three faces of the cube lie in
the coordinate planes.
8. Find an equation of the plane passing through (7, −5, 1) and marking oﬀ
equal positive intercepts on the three coordinate axes.
9. A tetrahedron lying in the second octant has three of its faces in the
coordinate planes. Find an equation of the fourth face, given that three
of its edges equal CA = 5, BC =
√
29, and AB = 6.
10. Normalize the equations of the planes
(a) 2x −9y + 6z = 22,

§6. Review Problems on Planes and Lines in E3
159
(b) 10x + 2y −11z = 0, and
(c) 6x −yx −z = 33.
11. Find the distance from the origin ¯0 to the plane 15x −10y + 6z = 190.
12. Find the plane whose distance from the origin equals 6, given the ratios
between its intercepts: a : b : c = 1 : 3 : 2.
13. Find the direction cosines of the line perpendicular to the plane 2x −y +
2z = −9.
14. Repeat Problem 13, assuming the line is perpendicular to the plane with
intercepts are a = 11, b = 55, c = 10.
15. Find the angle between the planes Y OZ and x −y +
√
2 z = 5.
16. Find the point symmetric to ¯0 with respect to the plane x−y +
√
2 z = 5.
17. Find an equation of the plane given that the perpendicular dropped on
it from the origin meets the plane at (3, −6, 2).
18. Find the distance between the given point and the given plane:
(a) (3, 1, −1), 22x + 4y −20z = 45.
(b) (4, 3, −2), 3x −y + 5z + 1 = 0.
(c) (2, 0, −1/2), 4x −4y + 2z = 17.
19. Find the altitude h¯a of the pyramid with vertices (0, 6, 4) = ¯a, (1, −1, 4),
(−2, 11, −5), and (3, 5, 3).
20. Find an equation of the plane through (7, 4, 4) perpendicular to ab if
¯a = (1, 3, −2), ¯b = (1, −1, 0).
21. Find the point symmetric to (1, 2, 3) with respect to the plane −3x+y +
z = 1.
22. The plane of a mirror is 2x −6y + 3z = 42. Find the image of (3, 7, 5).
23. Find the angle between the two given planes:
(a) x −4y −z + 9 = 0 and 4x −5y + 3z = 1;
(b) 3x −y + 2z = −15 and 5x + 9y −3z = 1;
(c) 6x + 2y −4z = 17 and 9x + 3y −6z = 4.
24. Find the angle between two planes through (−5, 16, 12) given that one
of them contains the axis OX and the other contains OY .
25. Find equations of the planes
(a) through (−2, 7, 3) and parallel to the plane x −4y + 5 = 1;
(b) through the origin and perpendicular to the two planes 2x−y+5z =
−3 and x + 3y −z = 7;

160
Chapter 3. The Geometry of n Dimensions. ∗Vector Spaces
(c) passing through (3, 0, 0) and (0, 0, 1) and forming an angle of 60◦
with the plane XOY .
26. Find an equation of the plane containing the OZ-axis and forming an
angle of 60◦with the plane 2x + y −
√
5 z = 7.
27. Verify that the planes
2x −2y + z = 3, 3x −6z + 1 = 0, and 4x + 5y + 2z = 0
are perpendicular to each other, and ﬁnd the transformation formulas to
a system of coordinates in which these planes would become, respectively,
the XOY , Y OZ, and ZOX planes.
In the following problems, the results of Problems 4–6 of §5, are used.
28. Given the points (6, 1, −1), (0, 5, 4), and (5, 2, 0), ﬁnd the plane whose
distances from these points are −1, 3, and 0, respectively.
29. Find the planes bisecting the angles between the planes
3x −y + 7z = 4 and 5x + 3y −5z + 2 = 0.
30. Find a point on the OZ-axis equidistant from the two planes
x + 4y −3z = 2 and 5x + z + 8 = 0.
31. Find the distance between the planes
11x −2y −10z = 45 and 11x −2y −10z = −15.
(First check that they are parallel.)
32. Find the center of the sphere inscribed in the tetrahedron formed by the
plane 2x + 3y −6z = 4 and the coordinate planes.
33. Find the planes parallel to the plane 14 + 3x −6y −2z = 0 given that the
distance between the latter and each of them is 3.
34. Find the plane passing through ¯0 and the points (1, 4, 0), (3, −2, 1).
35. Find the equations of the faces of the tetrahedron with vertices (0, 0, 2),
(3, 0, 5), (1, 1, 0), (4, 1, 2).
36. Find the volume of the tetrahedron of Exercise 35.
37. Verify the coplanarity or noncoplanarity of the points
(a) (3, 1, 0), (0, 7, 2), (−1, 0, −5), (4, 1, 5);
(b) (4, 0, 3), (1, 3, 3), (0, 2, 4), (1, −1, 1).
38. Find the intersection point of the given three planes:
(a) 2x −3y + 2z = 9, x + 2y + 3z = 1, 5x + 8y −z = 7;

§6. Review Problems on Planes and Lines in E3
161
(b) −3x + 12y + 6z = 7, 3x + y + z = 5, x −4y −2z + 3 = 0;
(c) 3x −z + 5 = 0, 5x + 2y −13z = −23, 2x −y + 5z = 4.
39. Verify whether the four given planes meet at a single point:
(a) 5x −z = −3, 2x −y + 5z = 4, 3y + 2z = 1, 3x + 4y + 5z = 3;
(b) 5x + 2y = 6, x + y = 3, 2x −3y + z = −8, 3x + 2z = 1.
40. A plane passes through the line of intersection of the planes
x + 5y + 2 = z and 4x + 3 −y = 1.
Find its equation if
(a) it passes through the origin;
(b) it passes through (1, 1, 1);
(c) it is parallel to OY ;
(d) it is perpendicular to the plane 2x −y + 5z = 3.
41. In the pencil of planes determined by the planes 3x + y + 3z = 2 and
x −2y + 5z = 1, ﬁnd planes perpendicular to these planes.
42. Find an equation of the plane perpendicular to the plane 5x −y + 3z = 2
and intersecting with it along a line lying in the XOY plane.
43. Find an equation of the plane tangent to the sphere
x2 + y2 + z2 = 1
and containing the intersection line of the planes
5x + 8y + 1 = z and x + 28y + 17 = 2z.
(For the notion of “sphere”, cf. Problem 7 of §4.)
44. In the pencil of planes
x + 3y −5 + t(x −y −2z + 4) = 0,
ﬁnd a plane with equal intercepts a, b, c.
45. Which of the coordinate planes belongs to the pencil of planes
4x −y + 2z −6 + t(6x + 5y + 3z −9) = 0?
46. Find the plane passing through the intersection line of the planes x+5y+
z = 0 and z = 4 at an angle of 45◦to the plane x −4y −8z = −12.
47. Find the three planes that are each parallel to a coordinate axis and pass
through the line
x −3
2
= y + 1
−1
= z + 3
4
.

162
Chapter 3. The Geometry of n Dimensions. ∗Vector Spaces
48. Verify that the given two lines intersect and ﬁnd the intersection point,
as well as the equation of the plane passing through them:
(i) x −2
−3
= y
2 = z + 5
5
and x + 15
−7
= y + 4
−3
= z −8
4
;
(ii) x + 1
0
= y + 1
5
= z −3
3
and x −8
3
= y + 2
−2
= z −6
0
;
(iii) x = 4 + 3t, y = 7 + 6t, z = −10 −2t and x = −3 −t, y = 5t,
z = 2 + 8t.
49. In each case ﬁnd the direction cosines and parametric equations of the
intersection line of the two given planes:
(i) x −2y + 3z + 4 = 0, 2x + 3y −z = 0;
(ii) 4x −y + 5z = 2, 3x + 3y −2z = 7.
50. In Problem 49, ﬁnd the an equation of plane passing through line (i) and
parallel to line (ii).
51. Find the perpendicular distance from the point ¯p = (2, −1, 2) to the line
(i) x −1
2
= y
1 = z + 2
−3 ;
(ii) x + 5
3
= y −1
−1
= z + 4
5
.
Also ﬁnd the perpendicular distance between the two lines.
[Hint: Cf. Problems 11 and 13 of §4. Alternatively, project (orthogonally) the vec-
tor −−−−−−−−−−−−−−−→
(1, 0, −2)(−5, 1, −4) on the unit vector perpendicular to both lines using cross
products; cf. Problems 4 and 2 of §4.]
§7. Intervals in En
¯0
Y
X
¯a
¯b
a1
b1
a2
b2
Figure 18
Consider the rectangle in E2 shown
in Figure 18.
Its interior (without
the perimeter) consists of all points
(x, y) ∈E2 such that
a1 < x < b1 and a2 < y < b2,
i.e.,
x ∈(a1, b1) and y ∈(a2, b2).
Thus it is the cross product of two line intervals, (a1, b1), (a2, b2). To include
also all or some sides, we would have to replace open line intervals by closed,

§7. Intervals in En
163
half-closed, or half-open ones. Similarly, cross products of three line intervals
yield rectangular parallelepipeds in E3. We may also consider cross products
of n line intervals. This leads us to the following deﬁnition.
Deﬁnition 1.
By an interval in En, we mean the Cartesian product of any n intervals
in E1 (some may be open, some closed or half-open, etc.).
In particular, given ¯a = (a1, . . ., an) and ¯b = (b1, . . . , bn), with ak ≤bk,
k = 1, . . ., n, we deﬁne the open interval (¯a, ¯b), the closed interval [¯a, ¯b], the
half-open interval (¯a, ¯b], and the half-closed interval [¯a, ¯b) as follows. First,
(¯a, ¯b) = (a1, b1) × (a2, b2) × · · · × (an, bn)
= {¯x ∈En | ak < xk < bk, k = 1, 2, . . ., n}.
Thus (¯a, ¯b), the cross product of n open line intervals (ak, bk), is the set of
all those points ¯x in En whose coordinates xk all satisfy the inequalities ak <
xk < bk, k = 1, . . ., n. Similarly,
[¯a, ¯b] = [a1, b1] × [a2, b2] × · · · × [an, bn]
= {¯x ∈En | ak ≤xk ≤bk, k = 1, 2, . . . , n};
(¯a, ¯b] = (a1, b1] × (a2, b2] × · · · × (an, bn]
= {¯x ∈En | ak < xk ≤bk, k = 1, 2, . . . , n};
[¯a, ¯b) = [a1, b1) × [a2, b2) × · · · × [an, bn)
= {¯x ∈En | ak ≤xk < bk, k = 1, 2, . . . , n}.
While in E1 there are only these four types of intervals, in En we can
form many more kinds of them by cross-multiplying diﬀerent (mixed) kinds of
line intervals. In all cases, the points ¯a and ¯b are called the endpoints of the
interval. If ak = bk for some k, the interval is called degenerate. We often
denote intervals by single capitals; e.g., A = (¯a, ¯b).
Note 1.
A point ¯x belongs to (¯a, ¯b) only if the inequalities ak < xk < bk
hold simultaneously for k = 1, 2, . . . , n.
This is impossible if ak = bk for
some k. Thus a degenerate open interval is always empty. Similarly for other
nonclosed intervals. A closed interval contains at least its endpoints ¯a, ¯b.
Deﬁnition 2.
If ¯a and ¯b are the endpoints of an interval A in En, their distance ρ(¯a,¯b) =
|¯b −¯a| is called the diagonal dA of A; the n diﬀerences bk −ak = ℓk are
called its n edgelengths; their product
n
Y
k=1
ℓk =
n
Y
k=1
(bk −ak)

164
Chapter 3. The Geometry of n Dimensions. ∗Vector Spaces
is called the volume of A (in E2 it is its area, in E1 its length), denoted
vol A or vA.
The point ¯c = 1
2(¯a + ¯b) is called the center of A.
The set diﬀerence [¯a, ¯b]−(¯a, ¯b) is called the boundary of any interval with
endpoints ¯a and ¯b; it consists of 2n “faces” deﬁned in a natural manner.
(How?)
If all edgelengths ℓk = ak −bk are equal, A is called a cube (in E2, a
square).
If one of the ℓk is 0, then A is degenerate and volA, being the product of
all the ℓk, is 0.
In E2, we can split an interval into two subintervals by drawing a line (in E3,
a plane) perpendicular to one of the axes (see Figure 19 below). To “imitate”
this in En, we use hyperplanes (see §5). A hyperplane perpendicular to the
k-th axis (i.e., to ⃗ek) can be deﬁned as the set of all those points ¯x in En
whose k-th coordinate equals some ﬁxed number c (the other coordinates may
be arbitrary). Brieﬂy, we call it “the hyperplane xk = c”. If ak < c < bk (¯a
and ¯b being the endpoints of A), then A splits into two disjoint sets:
P = {¯x ∈A | xk < c} and Q = {¯x ∈A | xk ≥c},
or
P = {¯x ∈A | xk ≤c} and Q = {¯x ∈A | xk > c}.
We shall now show that P and Q are indeed intervals, with vA = vP + vQ.
Theorem 1. If an interval A ⊂En with endpoints ¯a and ¯b is split by a
hyperplane xk = c (ak < c < bk), then the partition sets P and Q (as above)
are intervals, and one of them is closed if A is. In particular, if c = 1
2(ak +bk)
(the plane bisects the k-th edge), then the k-th edgelength of P and Q equals
1
2ℓk = 1
2(bk −ak); the other edgelengths equal those of A.
Moreover, the volume of A is the sum of vP and vQ: vA = vP + vQ.
¯0
Y
X
¯a
¯p
¯b
¯q
a1
b1
c
a2
b2
P
Q
Figure 19
Proof.
To ﬁx ideas, let A be half-
open, i.e., A = (¯a, ¯b]; let a1 < c < b1
(i.e., we cut the ﬁrst edge), and let
P = {¯x ∈A | x1 ≤c},
Q = {¯x ∈A | x1 > c}
(i.e., we include the cross section x1 =
c in P). Consider the points
¯p = (c, a2, a3, . . . , an) and
¯q = (c, b2, b3, . . . , bn)

§7. Intervals in En
165
(see Figure 19), so that p1 = q1 = c, while pk = ak and qk = bk for k ≥2. To
prove that P is an interval, we show that P = (¯a, ¯q].
Indeed, if some ¯x is in P, then, by deﬁnition, ¯x ∈A and a1 < x1 ≤c =
q1, and ak < xk ≤bk = qk, k = 2, . . . , n. Thus ak < xk ≤qk for all k,
i.e., x ∈(a, q]. Reversing steps, we also see that ¯x ∈(a, q] implies ¯x ∈P. Thus
P ⊆(¯a, ¯q] ⊆P, i.e., P = (¯a, ¯q]. Quite similarly it is shown that Q = (¯p, ¯b].
Thus P and Q are indeed intervals. It is clear that if A is closed, i.e., A = [¯a, ¯b],
the same proof yields P = [¯a, ¯q] (so P is closed!). This proves the ﬁrst part of
the theorem.
Next, we compute the edgelengths of P and Q. For k ≥2, we have qk = bk
and pk = ak. Thus the edgelengths of P = (¯a, ¯q] are qk −ak = bk −ak, i.e., the
same as those of A (for k ≥2); similarly for Q. On the other hand, the ﬁrst
edgelength of P is q1 −a1 = c −a1 and that of Q is b1 −p1 = b1 −c. If
c = 1
2(a1 + b1), both expressions simplify to 1
2(b1 −a1). This proves the second
part of the theorem.
Finally, the formula vA = vP + vQ is proved by computing vA and vQ; we
leave the details to the reader. Thus the theorem is proved.
□
Note that, by including the cross section x1 = c in Q (instead of P), we
could make Q closed (if A itself is). Thus the choice is ours; but we cannot
make both P and Q closed. (Why?) Also note that, by what was shown above,
a half-open interval (a, b] can be split into two half-open intervals P and Q;
similarly for half-closed intervals.
¯a
¯b
¯0
Y
X
Figure 20
Next, we consider partitions into
more than two subintervals. One im-
portant case is where we draw n hy-
perplanes, each bisecting one of the
edges of an interval A and perpendic-
ular to the corresponding axis. The
ﬁrst hyperplane bisects the ﬁrst edge,
leaving the others unchanged (as was
shown in Theorem 1). The resulting
two subintervals P and Q then are
both cut (each into two parts) by the
second hyperplane, which bisects the second edge in A, P, and Q. Thus, we get
four disjoint intervals (see Figure 20 for E2). The third hyperplane bisects the
third edge in each of them. This yields eight subintervals. Thus each successive
hyperplane doubles the number of the subintervals. After all n steps, we thus
obtain 2n intervals, with all edges bisected, so that every edgelength in each of
the 2n subintervals equals 1
2 of the corresponding edgelength of A. Moreover,
if A is closed then, as previously noted, we can make any one of them (but
only one) closed, by properly manipulating the cross sections at each of the n
steps. This argument yields the following result.

166
Chapter 3. The Geometry of n Dimensions. ∗Vector Spaces
Theorem 2. By drawing n hyperplanes bisecting the edges of an interval A ⊂
En, one can split A into 2n disjoint subintervals whose edgelengths equal one
half of the corresponding edgelengths of A and whose diagonals equal 1
2dA. Any
one (but only one) of the subintervals can be made closed if A is closed.
Indeed, all this was proved except the statement about the diagonals. But
if ¯a and ¯b are the endpoints of A, then clearly
dA = |¯b −¯a| =
s n
X
k=1
(bk −ak)2 =
s n
X
k=1
ℓ2
k.
Since the edgelengths of the subintervals are 1
2ℓk, their diagonals, by the
same formula, equal
s n
X
k=1
1
4ℓ2
k = 1
2
s n
X
k=1
ℓ2
k = 1
2dA,
as claimed.
Our next theorem states an important property of the volume, called its
additivity. It generalizes the last clause of Theorem 1.
Theorem 3. If an interval A ⊂En is split, in any manner, into m mutually
disjoint subintervals A1, A2, . . . , Am, then
vA =
m
X
i=1
vAi.
Brieﬂy, “the volume of the whole equals the sum of the volumes of the parts.”
Proof. The case m = 2 was proved in Theorem 1.
¯0
Y
X
¯a
c
¯p
¯b
¯d
A1
A2
A3
Figure 21
Now, using induction, suppose ad-
ditivity holds for any number of subin-
tervals less than a certain m (m > 1).
We must show that it also holds for m
subintervals. To begin, let
A =
m
[
i=1
Ai
(Ai disjoint).
As m > 1, one of the Ai (say, A1 =
[¯a, ¯p]) must have some edgelength less
than the corresponding edgelength of
A (say, ℓ1). Now cut all of A into P = [¯a, ¯d] and Q = A −P by the hyperplane
x1 = c (c = p1) (to ﬁx ideas, we assume A and A1 closed, but the proof
works also in all other cases).
Then (see Figure 21) A1 ⊆P while A2 ⊆
Q. For simplicity, we also assume that the hyperplane cuts each Ai into two

§7. Intervals in En
167
subintervals A′
i and A′′
i (one of which may be empty); so
P =
m
[
i=1
A′
i,
Q =
m
[
i=1
A′′
i .
Actually, however, P and Q are split into less than m (nonvoid) intervals, since
A′′
1 = ∅= A′
2 by construction. Thus, by our inductive hypothesis,
vP =
m
X
i=1
A′
i and vQ =
m
X
i=1
vA′′
i
(where vA′′
1 = 0 = vA′
2). Also, by Theorem 1, vA = vP + vQ and vAi =
vA′
i + vA′′
i . Thus
vA = vP + vQ =
m
X
i=1
vA′
i +
m
X
i=1
vA′′
i =
m
X
i=1
(vA′
i + vA′′
i ) =
m
X
i=1
vAi,
and the inductive proof is complete.
□
Note 2.
The theorem and its proof remain valid also if some of the Ai
contain common faces but it fails if the Ai overlap beyond that (i.e., have some
internal points in common). As special cases, we obtain the additivity of areas
of intervals in E2 and lengths of intervals in E1.
The proofs of the following corollaries are left to the reader.
Corollary 1. The distance between any two points of an interval A ⊂En
never exceeds the diagonal of A. Moreover, dA is the supremum of all such
distances (provided A ̸= ∅).
(Hint for the second clause: If ¯a ̸= ¯b are the endpoints of A, consider the
line segment L(¯a,¯b) whose length is |¯b −¯a| = dA. Show that L(¯a,¯b) ⊆A.
Given 0 < ϵ <
1
2dA, show that L(¯a,¯b) contains two points ¯x, ¯y such that
ρ(¯x, ¯y) = |¯x −¯y| > dA −ϵ; e.g., take x = ¯a + 1
2ϵ⃗u and ¯y = ¯b −1
2ϵ⃗u, where
⃗u =
¯b −¯a
|¯b −¯a|.
Then apply Corollary 1 and Note 4 of §9 in Chapter 2.)
Corollary 2. Every interval A ⊂En contains all line segments L[¯p, ¯q] whose
endpoints ¯p and ¯q lie in A.
(This property is called convexity. Thus all intervals are convex sets. See
also Problem 7 of §4.)
Corollary 3. The volume, the edgelengths, and the diagonal of a subinterval
never exceed those of the containing interval.

168
Chapter 3. The Geometry of n Dimensions. ∗Vector Spaces
Corollary 4. Every nondegenerate interval in En contains rational points,
i.e., points whose coordinates are rational.
(Hint: Apply the density of rationals in E1 for each coordinate separately.)
Problems on Intervals in En
1. Complete the missing details in the proof of Theorem 1. In particular,
show that Q = (¯p, ¯b] and that vA = vP + vQ. Then, assuming that A is
closed, modify the proof so as to make Q closed.
2. Prove Corollaries 1 through 4.
2′. Verify Note 2.
3. Give a suitable deﬁnition of a “face” of an interval A ⊂En and of its 2n
“vertices” (the endpoints are only two of them).
4. Compute the edgelengths, the diagonal, and the volume of [¯a, ¯b] in E4,
given that ¯a = (1, −2, 4, 0) and ¯b = (2, 0, 5, 3). Is it a cube? Find all
its “vertices” (see Problem 3). Split it by the plane x4 = 1 and verify
Theorem 1 (last part) by actually computing the volumes involved.
5. Verify that the cross product of n line intervals (ak, bk), k = 1, . . ., n,
coincides with the set {¯x ∈En | ak < xk < bk}.
(Thus justify the
second part of Deﬁnition 1.) Show also that Deﬁnition 1 could be stated
inductively: An interval in En is the cross product of an interval in En−1
by a line interval. (Use the inductive deﬁnition of an n-tuple, given in §6
of Chapter 2.)
∗6. A nonempty family of (arbitrary) sets is called a semi-ring of sets iﬀ
(i) it contains the intersection of any two (hence any ﬁnite number) of
its members; that is, if A and B are members of the family, so is
A ∩B; and
(ii) the diﬀerence A −B of any two members can always be represented
as a union of a ﬁnite number of disjoint members of the family;
i.e., A −B = Sm
i=1 Ci for some disjoint sets Ci belonging to the
family.
Given this deﬁnition, solve the following problems:
(a) Prove that all intervals in E1 satisfy (i) and (ii) and hence consti-
tute a semi-ring; show that so also do the half-open intervals in E1
alone; similarly for the half-closed intervals. Disprove this for open
intervals and for closed intervals.
[Hint: (ii) fails.]
(b) Do question (a) for intervals in En; in particular, show that all
half-open intervals in En form a semi-ring.

§7. Intervals in En
169
[Hint: Use the inductive deﬁnition given at the end of Problem 5, and apply
induction on the number n of dimensions; i.e., assuming all for En−1, prove it
for En.]
∗7. A set in En is said to be simple iﬀit is the union of a ﬁnite number
of disjoint intervals (in particular, all intervals are simple). Prove the
following:
(a) If A and B are simple, so is A ∩B.
[Hint: Let
A =
m
[
i=1
Ai,
B =
r[
k=1
Bk.
Then
A ∩B =
m
[
i=1
r[
k=1
(Ai ∩Bk).
(Verify!)
If Ai and Bk are intervals, so are all Ai ∩Bk by Problem 6 (since the intervals
form a semi-ring). The sets Ai ∩Bk are disjoint if so are Ai or Bk. Thus A∩B
is a ﬁnite union of disjoint intervals, i.e., A ∩B is simple.]
Extend this, by induction, to intersections of any ﬁnite number of
simple sets: If A1, A2, . . . , Ar are simple, so is Tr
k=1 Ak.
(b) If A is simple and B is an interval, then A −B is simple.
[Hint: Let A = Sm
i=1 Ai, where the Ai are disjoint intervals. Then
A −B =
m
[
i=1
(Ai −B).
(Verify!)
By Problem 6, Ai −B is the union of some disjoint intervals C1, C2, . . . , Cni.
Thus
A −B =
m
[
i=1
ni
[
k=1
Ck,
with all Ck disjoint. (Why?)]
(c) If A and B are simple, so is A −B.
[Hint: Let B = Sm
i=1 Bi for some disjoint intervals Bi. Then
A −B = A −
m
[
i=1
Bi =
m
\
i=1
(A −Bi),
by duality laws. By (b), each A −Bi is simple, and so is
m
\
i=1
(A −Bi)
by (a).]
(d) If A and B are simple, so is A ∪B (similarly for all ﬁnite unions,
by induction).
[Hint: A ∪B = (B −A) ∪A; A is a disjoint union of intervals (by assumption);
so is B −A, by (c); hence, so is A ∪B.]

170
Chapter 3. The Geometry of n Dimensions. ∗Vector Spaces
∗8. A nonempty family M of (arbitrary) sets is called a ring of sets iﬀ
(∀A, B ∈M)
A −B ∈M and A ∪B ∈M.
(We then also say that M is closed under ﬁnite unions and diﬀerences.)
Infer from Problem 7 that all simple sets in En form a ring. Moreover,
show that if C is a semi-ring of sets (cf. Problem 6), then all ﬁnite unions
of disjoint members of C form a ring.
[Hint: Proceed as in Problem 7.]
∗9. Prove the subadditivity of the volume for intervals A, B1, B2, . . . , Bm
(not necessarily disjoint): If A = Sm
i=1 Bi, then
vA ≤
m
X
i=1
vBi.
[Hint: Let C1 = B1 and Ck = Bk −Sk−1
i=1 Bi, k = 2, 3, . . . , m. Verify that the sets
Ck are disjoint and that A = Sm
k=1 Ck, with Ck ⊆Bk. From Problem 7(d)(c), infer
that each Ck is simple, and so is each Bk −Ck. Thus Ck is the union of some disjoint
intervals Dkj, j = 1, . . . , mk, while Bk contains some additional intervals (those in
Bk −Ck). Now, use additivity (Theorem 3) to obtain
mk
X
j=1
vDkj ≤vBk
and, from A = Sm
k=1 Ck,
vA =
m
X
k=1
mk
X
j=1
vDkj ≤
m
X
k=1
vBk,
as required.]
§8. Complex Numbers
As we have already noted, En is not a ﬁeld, because of the lack of a vector
multiplication that would satisfy the ﬁeld axioms. Now we shall deﬁne such a
multiplication, but only for E2. Thus E2 will become a ﬁeld which we shall
call the complex ﬁeld, denoted C.
In this connection, it will be convenient to introduce some notational and
terminological changes. Points of E2, when regarded as elements of the ﬁeld C,
will be called complex numbers (each being an ordered pair of real numbers).
We shall denote them by lower case letters (preferably z), without a bar or an
arrow; e.g., z = (x, y) denotes a complex number with coordinates x and y.
We shall preferably write (x, y) instead of (x1, x2). The coordinates x and y of
z are also called the real and imaginary parts of z, respectively.

§8. Complex Numbers
171
0
Y
X
z
z
Figure 22
If z = (x, y), then z will denote
the complex number (x, −y), called
the conjugate of z.
Thus z has the
same real part as z, but its imaginary
part is the additive inverse of that of
z. Geometrically, the point z is sym-
metric to z with respect to the x-axis
(see Figure 22).
Complex numbers of the form (x, 0), i.e., those with vanishing imaginary
part, are called real points of C. For brevity, we shall simply write x for (x, 0);
e.g., 2 = (2, 0). In particular, we write 1 for ¯e1 = (1, 0) and call it the real unit
in C. Points of the form (0, y), with vanishing real part, are called (purely)
imaginary numbers. In particular, the unit vector ¯e2 is such a number since
¯e2 = (0, 1); we shall now denote it by i and call it the imaginary unit in C.
Apart from these notational and terminological peculiarities, all our former
deﬁnitions that were given for En remain valid in E2 = C. In particular, this
applies to the deﬁnition of the sum and diﬀerence,
(x, y) ± (x′, y′) = (x ± x′, y ± y′),
and that of the absolute value: If z = (x, y), then |z| =
p
x2 + y2. Similarly,
if z = (x, y) and z(x′, y′), then ρ(z, z′) =
p
(x −x′)2 + (y −y′)2. Hence, also,
all previous theorems remain valid.
We now deﬁne the new multiplication in C. The deﬁnition may seem strange
at ﬁrst sight, but it makes a ﬁeld out of E2, as will be seen.
Deﬁnition 1.
The product of two complex numbers (x, y) = z and (x′, y′) = z′ is the
complex number (xx′ −yy′, xy′ + yx′), denoted (x, y)(x′, y′) or zz′.
Theorem 1. E2 = C is a ﬁeld under addition and multiplication as deﬁned
above, with the zero element 0 = (0, 0) and unity 1 = (1, 0).
Proof. We only must show that multiplication obeys the ﬁeld axioms I–VI (as
for addition, all is proved in Theorem 1 of §1).
Axiom I (closure law) is obvious from Deﬁnition 1: if z, z′ are in C, so is
zz′. To prove commutativity, we take any two complex numbers, z = (x, y)
and z′ = (x′, y′), and verify that zz′ = z′z. Indeed, by deﬁnition,
zz′ = (xx′ −yy′, xy′ + yx′), while z′z = (x′x −y′y, x′y + y′x);
but the bracketed expressions coincide, by the commutative laws for real num-
bers. Thus, indeed, zz′ = z′z. Associativity and distributivity are proved in a
similar manner, and we leave it to the reader.
Next, we show that 1 = (1, 0) is the “unity” element required in Ax-
iom IV(b), i.e., that for any number z = (x, y) ∈C, we have 1z = z.
In

172
Chapter 3. The Geometry of n Dimensions. ∗Vector Spaces
fact, by Deﬁnition 1,
1z = (1, 0)(x, y) = (1x −0y, 1y + 0x) = (x −0, y + 0) = (x, y) = z
(here we have used the corresponding laws for reals).
It remains to establish Axiom V(b), i.e., to show that every complex number
z = (x, y) ̸= (0, 0) has a multiplicative inverse z−1 such that zz−1 = 1. It turns
out that this inverse is obtained by setting
z−1 =
 x
|z|2 , −y
|z|2

,
where |z|2 = x2 + y2. In fact, with z−1 so deﬁned, we have
zz−1 = (x, y)
 x
|z|2 , −y
|z|2

=
x2 + y2
|z|2
, −xy + yx
|z|2

=
x2 + y2
|z|2
, 0

= (1, 0) = 1.
Thus, indeed, zz−1 = 1, as required, and all is proved.
□
We now obtain some immediate corollaries.
Corollary 1. i2 = −1. In fact, by deﬁnition,
i2 = (0, 1)(0, 1) = (0 · 0 −1 · 1, 0 · 1 + 1 · 0) = (−1, 0) = −1.
Thus the complex ﬁeld C has an element i = (0, 1) whose square is −1 =
(−1, 0), whereas there is no such element in E1, by Corollary 3 in §4 of Chap-
ter 2.
This is not a contradiction since that corollary was proved only for
ordered ﬁelds (it is based on Axioms VII–IX). This only shows that C cannot
be ordered, so as to satisfy Axioms VII–IX. Thus we shall deﬁne no inequalities
(<) in C.
From our deﬁnitions one easily obtains the following equations for “real
points” (x, 0) and (x′, 0):
(x, 0) + (x′, 0) = (x + x′, 0) and (x, 0) · (x′, 0) = (xx′, 0).
(Verify!) Thus two “real points” in C are added (multiplied) by simply adding
(multiplying) their real parts, x and x′, while the imaginary part, i.e., 0, remains
unchanged, as an “onlooker” only. Similarly for subtraction and division. In
other words, when carrying out ﬁeld operations on “real points” in C, we may
safely forget about the distinction between the real number x (x ∈E1) and the
real point (x, 0) in C. The real points in C behave exactly like real numbers.
One easily veriﬁes that they form a ﬁeld (called the real subﬁeld of C), and we
may even order them exactly as we order their real parts, i.e., by setting
(x, 0) < (x′, 0) ⇐⇒x < x′.

§8. Complex Numbers
173
Then the real points in C become an ordered ﬁeld that, mathematically, is an
exact copy of E1. Geometrically, it is the x-axis in the xy-plane representing
C.
(∗More precisely, one can describe this situation by using the notion of iso-
morphism deﬁned in §14 of Chapter 2. The mapping x →(x, 0) is an isomor-
phism of E1 onto the real subﬁeld of C, since it preserves addition, multiplica-
tion, and order. (Verify!))
Therefore it is customary not to distinguish between real numbers and real
points in C, “identifying” x with (x, 0) in C, as was explained above. With this
convention, E1 becomes simply a subset (and a subﬁeld) of C. Henceforth, we
shall simply say that “x is real” or “x ∈E1,” instead of saying that “x = (x, 0)
is a real point in C.” We then also obtain the following result.
Theorem 2. Every complex number z has a unique representation as a sum:
z = x + yi, where x and y are real and i = (0, 1) is the imaginary unit.
Proof. By our convention, x and y stand for (x, 0) and (y, 0), respectively;
thus x + yi = (x, 0) + (y, 0) · (0, 1). Computing the right side expression from
deﬁnitions, we obtain for any x, y ∈E1
x + yi = (x, 0) + (y · 0 −0 · 1, y · 1 + 0 · 0) = (x, 0) + (0, y) = (x, y).
Thus (x, y) = x+yi for any x, y ∈E1. If, in particular, we take the coordinates
of z for x and y in that formula, we obtain z = (x, y) = x + yi, which is the
required representation.
To prove its uniqueness, suppose that we also have = x′ + y′i, where x′ =
(x′, 0) and y′ = (y′, 0). But then, as was shown above,
z = (x′, 0) + (y′, 0) · (0, 1) = (x′, y′),
and so z = (x′, y′). Since also z = (x, y), we have (x, y) = (x′, y′), i.e., the
pairs (x, y) and (x′, y′) are the same, and so x = x′, y = y′ after all. Thus the
theorem is proved.
□
y
Y
θ
x
X
0
z
r
Figure 23
We shall now consider the geomet-
ric representation of complex num-
bers as points of the Cartesian plane
(see Figure 23). The x-axis comprises
all the “real points”; the y-axis con-
sists of all “imaginary” points”. The
rest of the plane represents all the
other complex numbers.
Instead of
the Cartesian coordinates (x, y), we
may also use polar coordinates (r, θ),
where r =
p
x2 + y2 is the absolute
value |z| of z = (x, y) and θ is the (counterclockwise) rotation angle from the

174
Chapter 3. The Geometry of n Dimensions. ∗Vector Spaces
x-axis to 0z (represented as the directed line segment 0z). Clearly, z is uniquely
determined by r and θ, but θ is not uniquely determined by z; indeed, the same
point of the plane results if θ is replaced by θ + 2nπ (n = 1, 2, . . . ); r and θ
are called, respectively, the modulus and argument of z = (x, y). By elemen-
tary trigonometry, we have x = r cos θ and y = r sin θ. Substituting this in
z = x + yi (see Theorem 2), we obtain the following corollary.
Corollary 2. z = r(cos θ + i sin θ) (“trigonometric form of z”).
In conclusion, we note that since C is a ﬁeld, all consequences of the ﬁeld
Axioms I–VI (but not VII–IX) apply to it. Quotients and diﬀerences are deﬁned
as in §3 of Chapter 2, and all propositions proved there for (unordered) ﬁelds
apply to C.
Problems on Complex Numbers
1. Complete the proof of Theorem 1 (associativity, distributivity, etc.).
1′. Verify that the “real points” in C form an ordered ﬁeld.
2. Prove that zz = |z|2. Infer that if z ̸= 0, then z−1 = z/|z|2.
3. Show that the conjugate of the sum (product) of z and z′ in C equals the
sum (product) of their conjugates:
z + z′ = z + z′,
zz′ = z · z′.
Show also (by induction) that
zn = (z)n
(n = 1, 2, . . .)
and that
n
X
k=1
akzk =
n
X
k=1
akzk.
∗4. From Problem 3 infer that the map z →z is an isomorphism of C onto
itself (such isomorphisms are called automorphisms).
5. Compute
(a) (1 + 2i) (3 −i);
(b) (1 + 2i)/(3 −i);
(c) in, n = 1, 2, . . . ;
(d) (1 ± i)n;
(e) 1/(1 + i)n;
(f) (x + 1 + i)/(x + 1 −i), x ∈E1;
(g) (z + 1 + i) (z + i −i) (z −1 + i) (z −1 −i).

§8. Complex Numbers
175
Do (a), (b), and (f) in two ways:
1) Use deﬁnitions only, and use the notation (x, y) instead of x + yi.
2) Use all laws valid in a ﬁeld. In fractions, multiply the numerator
and the denominator by the conjugate of the denominator to get a
real denominator.
6. Solve the equation (2, −1)(x, y) = (3, 2) for x and y.
7. Use Corollary 2 to show that if
z′ = r′(cos θ′ + i sin θ′) and z′′ = r′′(cos θ′′ + i sin θ′′),
then the modulus r of the product z = z′z′′ equals r′r′′, i.e., |z| = |z′| |z′′|,
and the argument θ of z equals θ′ + θ′′. Hence, derive the geometric in-
terpretation of the product: to multiply two complex numbers z′ and z′′
means to multiply the vector −→
0z′ by the scalar |z′′| and rotate it coun-
terclockwise around ¯0 by the angle θ′′. Consider the cases z′′ = i and
z′′ = −1.
[Hint: Expand
r′(cos θ′ + i sin θ′) · r′′(cos θ′′ + i sin θ′′)
and apply the laws of trigonometry.]
8. Use induction to extend the result of Problem 7 to products of n complex
numbers. Also derive de Moivre’s formula: If = r(cos θ + i sin θ), then
zn = rn(cos nθ + i sin nθ).
Using it, solve again 5(c), (d), and (e).
9. From Problem 8 derive that, for every complex number z ̸= 0, there are
exactly n complex numbers w such that wn = z (n = 1, 2, . . . ); they are
called the n-th roots of z.
[Hint: If
z = r(cos θ + i sin θ) and w = r′(cos θ′ + i sin θ′),
the equation wn = z implies (r′)n = r and nθ′ = θ, and conversely, so that r′ =
n√r
and θ′ = θ/n. While r′ is thus determined uniquely, there are diﬀerent choices of θ′,
since θ may be replaced by θ + 2kπ without aﬀecting z. Thus,
θ′ = θ + 2kπ
n
,
k = 1, 2, . . . .
Distinct points w result only for k = 0, 1, . . . , n −1 (after which they repeat cycli-
cally).]

176
Chapter 3. The Geometry of n Dimensions. ∗Vector Spaces
∗§9. Vector Spaces. The Space Cn. Euclidean Spaces
I. We have occasionally mentioned that there are vector spaces other than En.
Now we shall dwell on this matter in more detail.
Let V be an arbitrary set whose elements will be called “points” or “vectors”
(even though they may have nothing in common with E1 or En). Suppose
that a certain binary operation (call it “addition”) has somehow been deﬁned
in V in such a manner that the ﬁrst ﬁve axioms for real numbers hold for
this “addition”. That is, we have the closure law, (∀x, y ∈V ) x + y ∈V ,
commutativity, and associativity; there is a (unique) zero-element, denoted ⃗0,
such that (∀x ∈V ) x + ⃗0 = x; and each vector x ∈V has a (unique) additive
inverse −x, such that x + (−x) = ⃗0. A set V together with such an operation
is called an Abelian or commutative group.
Note.
If commutativity is not assumed, V is simply called a group. In
this section, however, only commutative groups will be considered. Note that
the operation (+) need not be the ordinary addition, and sometimes other
symbols are used instead of “+”. For an example of a noncommutative group,
see Problem 8 in §6 of Chapter 1.
Next, let F be any ﬁeld (e.g., E1 or C); its elements will be called scalars; its
zero-element will be denoted by 0, and its unity by 1. Suppose that yet another
operation (call it “multiplication of scalars by vectors”) has been deﬁned that
assigns to every scalar a ∈F and every vector x ∈V a certain vector ax ∈V ,
called the a-multiple of x, and suppose that it satisﬁes the following laws:
(∀a, b ∈F) (∀x, y ∈V )
a(x + y) = ax + ay, (a + b)x = ax + bx, (ab)x = a(bx), and 1x = x.
In other words, we assume that all laws of Theorem 1 of §1 are valid. In this
case, V together with these two operations is called a vector space, or a linear
space, over the ﬁeld F; F is called its ﬁeld of scalars or scalar ﬁeld.
Examples.
(a) En is a vector space over E1 (its scalar ﬁeld), with operations as deﬁned
in §1.
So also is Rn, the set of all points with rational coordinates,
i.e., ordered n-tuples (x1, . . ., xn) of rationals; but its ﬁeld of scalars is
R, not E1.
We also could choose R as the ﬁeld of scalars for all of En. This would
yield a diﬀerent vector spaces: En over R, not over E1. It contains Rn
as a subspace (a smaller space over the same ﬁeld).
(b) Let F be any ﬁeld, and let F n be the set of all n-tuples of elements of F
(x1, x2, . . . , xn), xk ∈F, with sums and scalar multiples deﬁned exactly
as for En (with F playing the role of E1). Then F n is a vector space over
F. (The proof is exactly as in Theorem 1 of §1.)

∗§9. Vector Spaces. The Space Cn. Euclidean Spaces
177
(c) Every ﬁeld F is also a vector space under the addition and multiplication
deﬁned in F, with F treated as its own ﬁeld of scalars. (Verify!)
(d) Let V be a vector space over a ﬁeld F, and let W be the set of all mappings
f: A →V from some arbitrary set A ̸= ∅into V . Deﬁne the sum of two
such maps f and g, denoted f + g, by setting
(f + g)(x) = f(x) + g(x) for all x ∈A.
(Here “(f + g)” is to be treated as one letter (function symbol). Thus,
“(f + g)(x)” means “h(x)” where h = f + g.) Similarly, given a ∈F and
f ∈W, we deﬁne the map (af): A →V by
(af)(x) = af(x).
Then, under these operations, W is a vector space over the same ﬁeld F.
(Verify!) In particular, taking V = E1 or V = C, we obtain the vector
space of all real-valued functions f: A →E1 (with F = E1) or that of all
complex-valued functions f: A →C (with F = C or F = E1).
In every vector space V over a ﬁeld F we can deﬁne linear combinations of
vectors, i.e., sums of the form
m
X
k=1
akxk
(ak ∈F, xk ∈V ),
hence also linearly dependent and independent sets of vectors (cf. §1, Problem 8).
Moreover, given two vector spaces V and W over the same ﬁeld F, we can con-
sider linear maps f: V →W, i.e., mappings which preserve linear combinations,
so that
(∀x, y ∈V ) (∀a, b ∈F)
f(ax + by) = af(x) + bf(y)
(cf. §5, Deﬁnition 2). Such a map is called a linear functional (on V ) if the
range space W is simply the scalar ﬁeld F of V , so that f: V →F. (Recall
that a ﬁeld F may be treated as a vector space.)
Vector spaces over E1 (respectively, C) are called real (respectively, complex)
vector spaces. Complex spaces can always be transformed into real ones by
restricting their scalar ﬁeld C to its real subﬁeld (which we identify with E1).
II. An important example of a complex linear space is Cn, i.e., the set of all
n-tuples x = (x1, . . . , xn) of complex numbers xk (now treated as scalars),
with sums and scalar multiples deﬁned as in En. In order to avoid confusion
with conjugates of complex numbers, we shall not use the notation ¯x for a
vector in Cn, writing simply x for it. Dot products in Cn are deﬁned by
x · y =
n
X
k=
xkyk,

178
Chapter 3. The Geometry of n Dimensions. ∗Vector Spaces
where yk is the conjugate of the complex number yk (cf. §8).
Note that if
yk ∈E1, then yk = yk. Thus, for points with real coordinates,
x · y =
n
X
k=1
xkyk,
in agreement with our deﬁnition of x · y in En.
The reader will easily verify (exactly as for En) that for x, y ∈Cn, we have
the following:
(i) x · y ∈C; thus x · y is a scalar, not a vector.
(ii) x · x ∈E1 and x · x ≥0; i.e., the dot product of a vector by itself is a
real number ≥0. Moreover, x · x = 0 iﬀx = ⃗0.
(iii) x · y = y · x (= conjugate of y · x). Thus commutativity fails in general.
(iv) (∀a, b ∈C) (ax) · (by) = (ab) (x · y); hence
(iv′) (ax) · y = a(x · y) = x · (ay).
(v) (x + y) · z = x · z + y · z and
(v′) z · (x + y) = z · x + z · y (distributive laws).
Observe that (v′) follows from (v) by using (iii). Verify!
III. Sometimes (but not always) dot products can also be deﬁned on complex
or real linear spaces other than Cn or En in such a manner that they satisfy
the laws (i)–(v) listed above (with C replaced by E1 if the space is real). If
these laws hold, the space is called a (complex or real) Euclidean space.1 In
particular, Cn is a complex Euclidean space, and En is a real Euclidean space.
In every Euclidean space (real or complex), one can deﬁne absolute values of
vectors by setting |x| = √x · x (this root exists in E1 since x·x ≥0 by formula
(ii) above). In particular, this deﬁnition applies to Cn and En (cf. §2, Note 3).
Then, similarly as was done for En, one obtains the following laws, valid for
all vectors x, y and any scalar a:
(a′) |x| ≥0; and |x| = 0 iﬀx = ¯0;
(b′) |ax| = |a| |x|;
(c′) |x + y| ≤|x| + |y| (triangle inequality);
(d′) |x · y| ≤|x| |y| (Cauchy–Schwarz inequality).
In particular, these laws are valid in Cn and En.
The proof is analogous to that of Theorem 2 of §2. Only the Cauchy–Schwarz
inequality requires a somewhat diﬀerent approach, as follows.
1 Note that the scalar ﬁeld in a Euclidean space is always C or E1. The same applies to
normed linear spaces, to be deﬁned later.

∗§9. Vector Spaces. The Space Cn. Euclidean Spaces
179
If |x · y| = 0, there is nothing to prove. Thus let x · y ̸= 0, and put
a = x · y
|x · y| ̸= 0.
Let t be an arbitrary real number, t ∈E1, and consider the expression (tx+ay)·
(tx + ay) ≥0 (see formula (ii) above). Removing brackets (by distributivity)
and using (iii) and (iv), we obtain
0 ≤(tx + ay) · (tx + ay)
= tx · tx + ay · tx + tx · ay + ay · ay
= t2|x|2 + (at) (y · x) + (ta) (x · y) + |a|2|y|2
(for aa = |a|2 in C).
As t ∈E1, we have t = t. Also, as
a = x · y
|x · y|, we have a = x · y
|x · y|.
Thus
(ta) (x · y) = t x · y
|x · y| (x · y) =
t
|x · y| |x · y|2 = t |x · y|.
Similarly,
(at) (y · x) = t|x · y|, and |a|2 = aa = |x · y|2
|x · y|2 = 1.
Substituting, we get
0 ≤t2|x|2 + 2t|x · y| + |y|2
for an arbitrary t ∈E1.
Here |x|2, |x·y|, and |y|2 are ﬁxed real numbers (by the deﬁnition of absolute
value). We treat them as coeﬃcients and t as a variable. Thus we have a qua-
dratic trinomial in t which remains nonnegative for all t ∈E1. By elementary
algebra (which we assume known) its discriminant must be ≤0. Thus
4|x · y|2 −4|x|2|y|2 ≤0, whence |x · y| ≤|x| |y|.
□
Once absolute values have been deﬁned and laws (a′)–(d′) have been estab-
lished, we can also deﬁne distances, as in En, by setting ρ(x, y) = |x −y| for
any vectors x and y. We treat this matter in the next section in a more general
setting, so we omit it here.
Finally, in any real or complex linear space V , we deﬁne lines and line
segments exactly as in En. That is, given two ﬁxed points a, b ∈V , we deﬁne
the line ab to be the set of all points x ∈V which are of the form
x = a + t(b −a) = (1 −t)a + tb,

180
Chapter 3. The Geometry of n Dimensions. ∗Vector Spaces
where t varies over E1 (not over all of C, even if the space is complex). Line
segments are obtained by letting t vary over corresponding intervals in E1
(cf. §4).
Problems on Linear Spaces
1. Prove that F n in Example (b) is a vector space, i.e., satisﬁes all laws
stated in Theorem 1 of §1. Similarly for W in Example (d).
2. Verify that inner products (dot products) in Cn obey laws (i)–(v). Which
of the laws would fail if these products were deﬁned by
x · y =
n
X
k=1
xkyk instead of
n
X
k=1
xkyk?
How would this aﬀect the deﬁnition of absolute values? Would such values
satisfy laws (a′)–(d′)?
3. Complete the proof of properties (a′)–(c′) of absolute values in a Euclidean
space V . What change in (a′) would result if property (ii) of dot products
were weakened to say only that x · x ≥0 and ⃗0 ·⃗0 = 0?
4. Deﬁne angles, directions, and orthogonality (perpendicularity) in a gen-
eral Euclidean space, following the pattern of §3. Show that a vector v is
orthogonal to all vectors of the space iﬀv = ⃗0.
5. Deﬁne hyperplanes in Cn following the pattern of §5 (parts I and II), and
prove Theorems 1, 2, and 3 of §5 for such hyperplanes.
6. Which (if any) of the problems following §5 remain valid for hyperplanes
in Cn?
7. Prove the principle of nested line segments: Every contracting sequence
of closed line segments L[am, bm], m = 1, 2, . . ., in a real or complex
Euclidean space V has a nonempty intersection,
∞
\
m=1
L[am, bm] ̸= ∅.
[Hint: All the line segments L[am, bm] lie on the line x = a1 + tu, where u = b1 −a1.
(Why?) In particular,
am = a1 + tmu and bm = a1 + t′
mu
for some tm, t′
m ∈E1.
Show that the intervals [tm, t′
m] in E1 form a contracting sequence, i.e.,
[tm, t′
m] ⊇[tm+1, t′
m+1],
m = 1, 2, . . . .
Now, from Problem 11 in §9 of Chapter 2, infer that there is
t0 ∈
∞
\
m=1
[tm, t′
m]
in E1,

∗§9. Vector Spaces. The Space Cn. Euclidean Spaces
181
and let p = a1 + t0u. Then show that p ∈T∞
m=1 L[am, bm].]
8. Prove Note 3 at the end of §4 for lines in any Euclidean space.
9. Deﬁne the basic unit vectors ek in Cn exactly as in En, and show that
they are linearly independent, i.e.,
n
X
k=1
akek = ⃗0
(ak ∈C)
iﬀall ak vanish.
10. Prove that if a set of vectors B = {v1, . . ., vm} in a vector space is linearly
independent, then:
(a) B does not contain ⃗0;
(b) every subset of B is linearly independent;
(c) if
m
X
k=1
akvk =
m
X
k=1
bkvk
for scalars ak, bk ∈F, then necessarily ak = bk, k = 1, 2, . . . , m.
∗§10. Normed Linear Spaces
In §9 we saw how absolute values can be deﬁned from inner products in Eu-
clidean spaces. Sometimes, however, absolute values can be deﬁned directly,
even in non-Euclidean linear spaces (where there are no dot products), “by-
passing” inner products altogether. All that is required is to assign, in some
way or other, a real absolute value |x| to every vector x in such a manner that
laws (a′)–(c′) speciﬁed in §9 are satisﬁed (excluding (d′) since it has no sense if
there are no dot products). A vector space equipped with such absolute values
is called a normed linear space. Thus, we have the following deﬁnition.
Deﬁnition 1.
A normed linear space is a real or complex vector space V in which every
vector v is associated with a real number |v|, called its absolute value (or
norm or magnitude), such that, for any vectors u, v ∈V and any scalar
a (in E1 or C, as the case may be),
(i) |v| ≥0;
(i′) |v| = 0 iﬀv = ⃗0;
(ii) |av| = |a| |v|; and
(iii) |u + v| ≤|u| + |v| (triangle inequality).

182
Chapter 3. The Geometry of n Dimensions. ∗Vector Spaces
Sometimes we write ∥v∥for |v| or use other similar symbols.
Mathematically, the existence of absolute values in V amounts to the exis-
tence of a mapping v →|v| on V , i.e., a mapping ϕ: V →E1, with function
values ϕ(v) written as |v|, satisfying the laws (i)–(iii). Any such mapping is
called a norm map (brieﬂy, “norm”) on V . Thus, to deﬁne absolute values in
V means to deﬁne a norm map v →|v| on V , satisfying (i)–(iii). Often this
can be done in many diﬀerent ways, thus giving rise to diﬀerent norms on V ,
all satisfying (i)–(iii).
Note 1.
There also are maps v →|v| that satisfy (i), (ii), and (iii) but
only a weaker form of (i′), namely, |⃗0| = 0, so that |v| may vanish if v ̸= ⃗0.
Such maps are called semi-norms, and vector spaces equipped with such maps
are called semi-normed linear spaces.
Examples.
(1) Every Euclidean space (in particular, En and Cn) is also a normed linear
space, with the norm deﬁned by
|v| = √v · v.
Indeed, as was shown in §9, absolute values so deﬁned satisfy (a′)–(c′),
i.e., laws (i)–(iii) of Deﬁnition 1. In En and Cn, one can also deﬁne |v|
directly in terms of coordinates, setting
|v| =
s n
X
k=1
|vk|2,
which is equivalent to |v| = √v · v. This is the so-called standard norm
on En (Cn).
(2) One can also deﬁne various “nonstandard” norms on En and Cn; e.g., ﬁx
some real number p ≥1 and put
∥v∥=
p
s n
X
k=1
|vk|p.
It can be shown that this yields another norm map v →∥v∥. (See Prob-
lems 9–11 below.)
(3) A semi-norm on En and Cn is obtained by setting
|v| = |v1| where v = (v1, v2, . . . , vn);
e.g., if v = (0, 1, 1, . . . , 1), then |v| = 0 because v1 = 0. Thus formula
(i′) fails here, but the remaining laws (i)–(iii) do hold, as is easily veriﬁed.
Therefore, we have a semi-norm here, not a norm.

∗§10. Normed Linear Spaces
183
(4) Let W be the set of all bounded real functions on a set A ̸= ∅, i.e., maps
f: A →E1 such that
(∀x ∈A)
|f(x)| < c
for some constant c (depending on f only). Due to boundedness, the set
of all absolute values |f(x)|, for a given f ∈W, has a l.u.b. in E1; we
denote it by ∥f∥. Thus
∥f∥= sup |f(x)|,
x ∈A.
We also deﬁne operations in W as in Example (d) of §9, i.e., setting for
any a ∈E1 and any f, g ∈W,
(∀x ∈A)
(f + g)(x) = f(x) + g(x) and (af)(x) = a · f(x).
Thus the maps f + g and af are deﬁned on A.
It is easy to show that these deﬁnitions make W a normed linear space,
with norm ∥f∥= sup |f(x)| for f ∈W. (Here each function f ∈W is
to be treated as a “vector” or “point” in W.) Leaving other details to
the reader, we verify the triangle inequality: ∥f + g∥≤∥f∥+ ∥g∥. By
deﬁnition, we have, for f, g ∈W,
|(f + g)(x)| = |f(x) + g(x)| ≤|f(x)| + |g(x)| ≤∥f∥+ ∥g∥.
(4′)
(The last inequality holds because ∥f∥= sup |f(x)| and ∥g∥= sup |g(x)|.)
By (4′), ∥f∥+∥g∥is an upper bound of all expressions |(f +g)(x)|, x ∈A.
Thus ∥f∥+ ∥g∥cannot be less than sup |(f + g)(x)|, x ∈A. But, by
deﬁnition, sup |(f + g)(x)| = ∥f + g∥. Thus ∥f + g∥≤∥f∥+ ∥g∥, as
required.
Formula (4′) also shows that the function f + g is bounded on A and
hence is a member of W. Thus we have the closure law
(∀f, g ∈W)
f + g ∈W.
The reader will easily verify that also af ∈W when a ∈E1 and f ∈W
(i.e., af is bounded if f is) and that W also has all other properties of a
normed linear space over E1.
Deﬁnition 2.
In every normed (or semi-normed) linear space V , we deﬁne the distance
ρ(u, v) between two points u, v ∈V by ρ(u, v) = |u −v|.
The resulting distances depend, of course, on the norm deﬁned in V . In
particular, using the standard norm in Cn or En (cf. Example 1), we have
ρ(u, v) =
s n
X
k=1
|uk −vk|2.

184
Chapter 3. The Geometry of n Dimensions. ∗Vector Spaces
If, instead, the “nonstandard” norm of Example (2) is used, we obtain
ρ(u, v) =
p
s n
X
k=1
|uk −vk|p.
Under the semi-norm of Example (3), we have ρ(u, v) = |u1 −v1|. In the space
W described in Example (4), we have ρ(f, g) = ∥f −g∥= sup |f(x) −g(x)|,
x ∈A.
In all cases, distances are nonnegative real numbers (for so are all abso-
lute values by deﬁnition).
Moreover, proceeding exactly as in the proof of
Theorem 3 of §2, we see that distances resulting from any norm on V (“norm-
induced” distances) obey the laws stated there, i.e.,
(1) ρ(u, v) ≥0;
(1′) ρ(u, v) = 0 iﬀu = v;
(2) ρ(u, v) = ρ(v, u) (symmetry law); and
(3) ρ(u, w) ≤ρ(u, v) + ρ(v, w) (triangle inequality).
The details are left to the reader.
Note 2.
Distances resulting from a semi-norm (“seminorm-induced” dis-
tances) have the same properties, except that (1′) is replaced by the weaker
law ρ(u, u) = 0; so distances may vanish even if u ̸= v (which is excluded under
norm-induced distances).
Moreover, in normed and semi-normed spaces, distances are translation in-
variant; that is, the distance ρ(u, v) does not change if both u and v are in-
creased by one and the same vector x, so that we have the following:
(4) ρ(u, v) = ρ(u + x, v + x) (translation invariance).
Indeed, by deﬁnition,
ρ(u + x, v + x) = |(u + x) −(v + x)| = |u −v| = ρ(u, v).
Problems on Normed Linear Spaces
1. Prove laws (1), (2), and (3) for distances in semi-normed spaces and (1′)
for normed spaces. Show also that |ρ(u, w) −ρ(v, w)| ≤ρ(u, v).
2. Complete the proof of the assertions made in Example (4) as to the space
W.
3. Verify that Example (3) yields a semi-norm; i.e., verify properties (i),
(ii), and (iii) of Deﬁnition 1.
Give examples of points u, v such that
ρ(u, v) = 0, though u ̸= v, under distances induced by that semi-norm.
4. Verify that Note 3 at the end of §4 applies to normed linear spaces (not
only to Euclidean spaces), with lines deﬁned as in §9.

∗§10. Normed Linear Spaces
185
5. Prove the principle of nested line segments (Problem 7 of §9) for normed
linear spaces in general.
6. Let M be the set of all inﬁnite bounded sequences {xm} in E1 (or in C),
i.e., sequences such that
(∀m)
|xm| ≤c
for some ﬁxed c ∈E1.1 We brieﬂy denote such a sequence by a single let-
ter (e.g., x) and use the same letter, with subscripts, to denote the terms
xm; thus x = (x1, x2, . . . , xm, . . . ).
Addition of sequences is deﬁned
termwise, i.e.,
x + y = (x1 + y1, x2 + y2, . . . , xm + ym, . . . ).
Similarly, for a ∈E1 (a ∈C),
ax = (ax1, ax2, . . . , axm, . . . ).
Show that this makes M a vector space (with each bounded sequence
treated as a single “point” in M). Also solve a similar problem for the
set S of all sequences in E1 (or C).
7. Continuing Problem 6, deﬁne a norm on M by
∥x∥= sup
m |xm|,
m = 1, 2, . . . .
Verify properties (i)–(iii) of Deﬁnition 1 for that norm, and give a formula
for distances in M.
[Hint: Proceed as in Example 4.]
8. Verify that Example 4 remains valid also if W is deﬁned to be the set
of all bounded functions from A into the complex ﬁeld C, with all other
deﬁnitions unchanged.
9. In diﬀerential calculus it is shown that
a1/p b1/q ≤a
p + b
q
if a, b, p, q ∈E1, a ≥0, b ≥0, p > 0, q > 0, and
1
p + 1
q = 1.
Assuming this result, prove H¨older’s inequality: If p > 1 and 1
p + 1
q = 1,
then for any xk, yk ∈C,
n
X
k=1
|xkyk| ≤
 n
X
k=1
|xk|p
1/p n
X
k=1
|yk|q
1/q
.
1 The constant c may be diﬀerent for diﬀerent sequences in M.

186
Chapter 3. The Geometry of n Dimensions. ∗Vector Spaces
[Hint: Let
A =
 n
X
k=1
|xk|p
1/p
and B =
 n
X
k=1
|yk|q
1/q
.
If A = 0 or B = 0, then all xk or all yk vanish, and the inequality is trivial. Thus
assume A ̸= 0, B ̸= 0. Then, setting
a = |xk|p
Ap
and b = |yk|q
Bq
in the “calculus” inequality stated above, obtain
|xkyk|
AB
≤|xk|p
pAp + |yk|q
qBq ,
k = 1, 2, . . . , n.
Now add up these inequalities, substitute the values of A, B, and simplify.]
10. Prove the Minkowski inequality:
 n
X
k=1
|xk + yk|p
1/p
≤
 n
X
k=1
|xk|p
1/p
+
 n
X
k=1
|yk|p
1/p
for any real p ≥1 and xk, yk ∈C.
[Hint: If p = 1, this follows by the triangle inequality in C. If p > 1, let
A =
n
X
k=1
|xk + yk|p ̸= 0
(if A = 0, all is trivial).
Then verify (writing P for Pn
k=1 for simplicity):
A =
X
|xk + yk| |xk + yk|p−1
≤
X
|xk| |xk + yk|p−1 +
X
|yk| |xk + yk|p−1.
Now apply H¨older’s inequality (Problem 9) to each of the last two sums, with q =
p/(p −1), so that (p −1)q = p and 1/p = 1 −1/q. Thus obtain
A ≤
X
|xk|p1/pX
|xk + yk|p1/q
+
X
|yk|p1/pX
|xk + yk|p1/q
.
Now divide by A1/q = (P |xk + yk|p)1/q and simplify.]
11. Verify that
∥v∥=
p
s n
X
k=1
|vk|p
deﬁnes a norm for En and Cn, satisfying the norm properties (i)–(iii), if
p ≥1.
[Hint: For the triangle inequality, use Problem 10. The rest is easy.]

Notation
∈(set element), 1
∅(empty set), 1, 41
⊆(subset), 2
⊂(proper subset), 2
⊇(superset), 2
∪(union of sets), 4
S (union of a family of sets), 6
∩(intersection of sets), 4
T (intersection of a family of sets), 6
−(diﬀerence of sets), 4
(diﬀerence of ﬁeld elements), 54
△(symmetric diﬀerence of sets), 11
∃(“there exists”), 12. See also Quantiﬁers
∃! (“there exists a unique”), 12. See also
Quantiﬁers
∀(“for each”), 12. See also Quantiﬁers
=⇒(“implies”), 13
⇐⇒(“if and only if”), 13. See also iﬀ
× (Cartesian product of sets), 18
lim (upper limit of a sequence of sets), 43
lim (lower limit of a sequence of sets), 43
+ (“plus”), 50
· (“times”), 50
< (“less than”), 50
/ (quotient), 54
| | (absolute value), 58
xn (“n-th power of x”), 68
n! (“n factorial”), 68
P (sum), 68
Q (product), 68
(Cartesian product), 69
(x1, . . . , xn) (ordered n-tuple), 69
n
k

(“n choose k”), 72
n | m (“n divides m”), 73
(a, b) (“the open interval from a to b”), 77
[a, b] (“the closed interval from a to b”), 77
(a, b] (“the half-open interval from a to
b”), 78
[a, b) (“the half-closed interval from a to
b”), 78
max(a, b) (“the maximum of a and b”), 78
min(a, b) (“the minimum of a and b”), 78
sup M (“the supremum of M”), 79
l.u.b. M (“the least upper bound of M”),
79
inf M (“the inﬁmum of M”), 79
g.l.b. M (“the greatest lower bound of
M”), 79
[x] (“the integral part of x”), 86
n√a (“the nth root of a”), 90
F ∼
= F ′ (“F is isomorphic to F ′”), 103
+∞(“plus inﬁnity”), 120
−∞(“minus inﬁnity”), 120
lim (“upper limit”), 122
lim sup (“upper limit”), 122
lim (“lower limit”), 122
lim inf (“lower limit”), 122
⃗x (“the vector x”), 128
¯x (“the point x”), 128
−→
xy (“the vector from ¯x to ¯y”), 129
⃗x + ⃗y (“the sum of ⃗x and ⃗y ”), 128
⃗x −⃗y (“the diﬀerence of ⃗x and ⃗y ”), 128
−⃗x (“the additive inverse of ⃗x ”), 129
a⃗x (“the product of a by ⃗x ”), 129
⃗u · ⃗v (“the inner product of ⃗u and ⃗v ”), 133
|⃗v| (“the absolute value of ⃗v ”), 134
⃗u ∥⃗v (“⃗u is parallel to ⃗v ”), 135
ρ(¯u, ¯v) (“the distance between ¯u and ¯v”),
137
⟨⃗u,⃗v⟩(“the angle between ⃗u and ⃗v ”), 140
⃗u ⊥⃗v (“⃗u is orthogonal to ⃗v ”), 140
⃗u ×⃗v (“the cross product of ⃗u and ⃗v ”), 148
|z| (“the modulus of the complex number
z”), 174
z (“the complex conjugate of z”), 171
|v|, ∥v∥(“the norm of v”), 181, 182

Index
Abelian group, 176
Absolute value (| |)
in E1, 58
in En, 134
in Euclidean space, 178
in a normed linear space, 181
Additive inverse in En, 129
Additivity of the volume of intervals in
En, 166
Angle
between two hyperplanes in En, 151
between two lines in En, 145
between two vectors in En, 140
Anti-symmetry of set inclusion, 2
Archimedean ﬁeld. See Field, Archimedean
Archimedean property, 84
Argument of complex numbers, 174
Arithmetic sequence, 42
Associative laws
of addition and multiplication, 51
of set union and intersection, 5
of composition of relations, 29
Axioms
of addition and multiplication, 51
of an ordered ﬁeld, 51
of order, 52
completeness axiom, 79
Basic unit vector in En, 128, 131
Bernoulli inequalities, 71
Binary operations, 26. See also Function
Binomial coeﬃcient, 72
Pascal’s law, 72
Binomial theorem, 72
Boundary of an interval in En, 164
Bounded set in an ordered ﬁeld, 77
left, or lower, bound of a, 76
maximum and minimum of a, 78
right, or upper, bound of a, 76
C (the complex numbers), 170
Cn, 177
dot product in, 177
Cancellation laws in a ﬁeld, 55
Cantor’s diagonal process, 47. See also
Sets
Cartesian product of sets, 18, 69, 127. See
also Relations
Cauchy-Schwarz inequality
in En, 135
in Euclidean space, 178
Center of an interval in En, 164
Characteristic function, 27
Closed
interval in E1, 77
interval in En, 163
line segment in En, 146
Closure
of addition and multiplication in a ﬁeld,
51
of addition and multiplication of inte-
gers, 74
of arithmetic operations on rationals, 75
Co-domain. See Range
Collinear
lines in En, 145
points in En, 145
vectors in En, 135
Commutative
group, 176
laws of addition and multiplication, 51
laws of set union and intersection, 5
Complement of sets. See Diﬀerence of sets
Completeness axiom, 79
Complete ordered ﬁeld. See Field, com-
plete ordered
Complete ordered set, 112
Completion
of an Archimedean ﬁeld, 115
of an ordered set, 112

Index
189
Complex ﬁeld, 170. See also Complex
numbers.
Complex numbers (C), 170
argument of, 174
conjugate of, 171
geometric representation of, 173
imaginary numbers in, 171
imaginary part of, 170
modulus of, 174
de Moivre’s formula, 175
multiplicative inverse of, 172
polar coordinates of, 173
real part of, 170
real points in, 171
trigonometric form of, 174
Composition of relations, 28
associativity of, 29
Conjugate of a complex number, 171
Contracting sequence of sets, 39
Convergent sequence of sets, 43
Convex sets in En, 148, 167
Coplanar
set of points in En, 152
vectors in En, 152
Correspondences. See Relations
Countable
set, 41, 44
union, 46
Cross product
determinant deﬁnition of, 148
of sets, 18, 69, 127. See also Relations
of vectors in E3, 148
Dedekind cut, 111
Dedekind’s theorem, 120
Density of an ordered ﬁeld, 60, 86
Determinant
deﬁnition of cross products, 148
deﬁnition of hyperplanes, 156
Diagonal of an interval in En, 163
Diagonal process, Cantor’s, 47. See also
Sets
Diﬀerence of ﬁeld elements (−), 54
Diﬀerence of sets (−), 4
generalized distributive laws with re-
spect to, 10
symmetric (△), 11
Directed line in En, 144
Direction angles of a vector in En, 141
Direction cosines
of a line in En, 144
of a vector in En, 141
Disjoint sets, 4
Distance
between a point and a hyperplane in
En, 157
between a point and a line in En, 149
between two lines in En, 149
between two points in En, 137
in Euclidean space, 179
in a normed linear space, 183
Distributive laws
of addition and multiplication, 52
of set union and intersection, 5, 9
with set diﬀerences, 10
Division of ﬁeld elements, 55
Division theorem, 73
quotient, 73
remainder, 73
Domain
of a relation, 16
of a function or mapping, 23
Dot product, 133, 177. See also En
Double sequence, 46
Duality laws, de Morgan’s, 7. See also Sets
E1 (the real numbers), 50
En (Euclidean n-space), 127
absolute value of a vector in, 134
additive inverse of a vector in, 129
angle between two vectors in, 140
basic unit vector in, 128, 131
Cauchy-Schwarz inequality, 135
collinear vectors in, 135
convex sets in, 148, 167
coplanar set of points in, 152
coplanar vectors in, 152
diﬀerence of vectors in, 128
direction, 142
direction angles of a vector in, 141
direction cosines of a vector in, 141
distance between points in, 137
dot product of vectors in, 133
globe in, 148
hyperplane in, 150 (see also Hyperplane
in En)
inner product of vectors in, 133
intervals in, 163 (see also Intervals in
En)
length of a vector in, 134
line in, 143 (see also Line in En)

190
Index
line segment in, 145 (see also Line seg-
ment in En)
linear combination of vectors in, 131
linear functionals on, 152
linearly dependent set of vectors in, 133
linearly independent set of vectors in,
133
magnitude of a vector in, 134
modulus of a vector in, 134
norm of a vector in, 134
normalized vector in, 142
origin in, 128
orthogonal vectors in, 140
perpendicular vectors in, 140
plane in, 150 (see also Hyperplane in
En)
position vector in, 128
product of a scalar and a vector in, 129
scalar multiple of a vector in, 129
scalars of, 128
sphere in, 148
sum of vectors in, 128
triangle inequality in, 135
unit vector in, 142
vectors in, 128
zero-vector of, 128
Edgelengths of an interval in En, 163
Elements of sets (∈), 1
Empty set (∅), 1, 41
Endpoints
of an interval in E1, 78
of an interval in En, 163
of a line segment in En, 146
Equality
of sets, 2
of relations, 28
Equivalence class, 33. See also Equivalence
relation
Equivalence relation, 32
equivalence class, 33
consistency of an, 32
modulo under an, 32
partition by an, 34
quotient set by an, 33
reﬂexivity of an, 32
substitution property of an, 32
symmetry of an, 32
transitivity of an, 32
Euclidean n-space. See En
Euclidean space, 178
absolute value in, 178
Cauchy-Schwarz inequality in, 178
distance in, 179
principle of nested intervals, 180
Existential quantiﬁer (∃), 12
Expanding sequence of sets, 39
Extended real numbers, 120
Family of sets, 1, 6
Field, 53
associative laws of addition and multipli-
cation, 51
binomial theorem, 72
cancellation laws, 55
closure laws of addition and multiplica-
tion, 51
commutative laws of addition and multi-
plication, 51
complex, 170
diﬀerence, 54
distributive law of addition over multi-
plication, 52
division, 55
existence of additive and multiplicative
inverses, 51
existence of additive and multiplicative
neutral elements, 51
factorials in a, 68
ﬁrst induction law, 63
inductive sets in a, 62
integers in a, 73
Lagrange identity, 139
natural elements in a, 62
powers in a, 68
quotient, 54
rationals in a, 74
subtraction, 55
Field, Archimedean. 84. See also Field,
ordered
density of rationals in an, 86
integral part of an element of an, 86
Field, complete ordered. See also Field,
Archimedean
Archimedean property of a, 84
completeness axiom, 79
deﬁnition of a, 80
greatest lower bound (g.l.b.), 79
inﬁmum (inf), 79
isomorphism of, 103
least upper bound (l.u.b.), 79
powers in a, 92
roots, 89

Index
191
supremum (sup), 79
Field, ordered, 53. See also Field
Archimedean ﬁeld, 84
absolute value (| |), 58
Bernoulli inequalities, 71
bounded sets in an, 77 (see also Bounded
sets)
density of an, 60
division theorem, 73
inductive deﬁnitions in an, 39, 67
intervals in an, 77 (see also Interval)
irrational in an, 89
monotonicity, 52
negative elements of an, 53, 57
positive elements of an, 53, 57
prime numbers in an, 76
quotient of natural elements in an, 73
rational subﬁeld of an, 75
rationals in lowest terms in an, 75
relatively prime integers in an, 75
remainder of natural elements in an, 73
second induction law, 66
transitivity, 52
trichotomy, 52
well-ordering property of naturals in an,
66
Finite
sequence, 37
set, 41
Function, 23. See also Mapping
binary operations, 26
characteristic, 27
domain of a, 23
index notation or set, 25, 38
range of a, 23
value, 23
Geometric representation of complex num-
bers, 173
Geometric sequence, 42
Globe in En, 148
Greatest lower bound (g.l.b.), 79
Group
Abelian, 176
commutative, 176
noncommutative, 176, 30
Half-closed
interval in E1, 78
interval in En, 163
line segment in En, 146
Half-open
interval in E1, 78
interval in En, 163
line segment in En, 146
H¨older’s inequality, 185. See also Normed
linear space
Homomorphism, 104
Hyperplane in En, 150
angle between two hyperplanes, 151
coordinate equation of a, 150
determinant deﬁnition of a, 156
directed, 151
distance between a point and a, 157
linear functionals and, 152
normalized equations of a, 151
orthogonal projection of a point on a,
157
parallel hyperplanes, 151
pencil of hyperplanes, 157
perpendicular hyperplanes, 152
vector equation of a, 150
Idempotent laws of set union and intersec-
tion, 5
Identity map, 24
iﬀ(if and only if), 3, 13
Image of a set under a relation, 17
Imaginary numbers in C, 171
Imaginary part of a complex number, 170
Inclusion relation of sets, 2
anti-symmetry of, 2
reﬂexivity of, 2
transitivity of, 2
Index
notation, 6, 25, 38
sets, 6, 25
Induction, 62
ﬁrst induction law, 63
induction law for integers in an ordered
ﬁeld, 74
inductive deﬁnitions, 39, 67
inductive hypothesis, 64
proof by, 63
second induction law, 66
Inductive
deﬁnitions, 39, 67
hypothesis, 64
proof, 63
set, 62
Inﬁmum (inf), 79
Inﬁnite sets, 41, 48, 45
Inner product, 133. See also En

192
Index
Integers
closure of addition and multiplication,
74
in a ﬁeld, 73
induction law for integers in an ordered
ﬁeld, 74
prime integers in an ordered ﬁeld, 76
relatively prime integers in an ordered
ﬁeld, 75
Integral part, 86
Intersection
of sets (∩), 4
of a family of sets (T), 6
Intervals in E1, 77
closed, 77
endpoints of, 78
half-closed, 78
half-open, 78
open, 77
principle of nested, 83
Intervals in En, 163
additivity of volume of, 166
boundary of, 164
center of, 164
closed, 163
convexity of, 167
diagonal of, 163
edgelengths of, 163
endpoints of, 163
half-closed, 163
half-open, 163
open, 163
subadditivity of the volume of, 170
volume of, 164
Intervals of extended real numbers, 120
Inverse
image of a set under a relation, 17
function, map, or mapping, 24
relation, 16
Inverses, existence of additive and multi-
plicative, 51
Invertible function, map, or mapping, 24
Irrational numbers, 47, 89, 118
Isomorphism, 103
isomorphic image, 103
of complete ordered ﬁelds, 103
Lagrange identity, 139
Lagrange interpolation formula, 42
Least upper bound (l.u.b.), 79
Length
of an line segment in En, 146
of a vector in En, 134
Line in En, 143
angle between two lines, 145
directed, 144
direction cosines of a, 144
direction numbers of a, 144
distance between two lines in En, 149
nonparametric equations of a, 145
orthogonal projection of a point on a,
149
orthogonal projection of a vector on a,
147
parametric coordinate equations of a,
144
parametric equation of a, 144
Line segment in En, 145
closed, 146
endpoints of a, 146
half-closed, 146
half-open, 146
length of a, 146
open, 146
Linear
combination of vectors, 131, 177
equation, 150
functional, 152
mapping, 152, 177
space, 176 (see also Vector space)
Linearly dependent
set of vectors in En, 133
set of vectors in a vector space V , 177
Linearly independent
set of vectors in En, 133
set of vectors in a vector space V , 177
Logical quantiﬁers. See Quantiﬁers, logical
Lower limit
of a sequence of numbers, 122
of a sequence of sets, 43
Magnitude of a vector in En, 134
Map. See Mapping
Mapping, 23. See also Function
as a relation, 23
identity, 24
inverse, 24
invertible, 24
linear, 152
one-to-one, 23
onto, 23
Maximum of a bounded set, 78

Index
193
Minkowski’s inequality, 186. See also
Normed linear space
Minimum of a bounded set, 78
Modulus
of a complex number, 174
of a vector in En, 134
de Moivre’s formula, 175
Monotone
sequence of sets, 40
sequence of numbers, 40
strictly, 40
Monotonic, See Monotone
Monotonicity of < with respect to addition
and multiplication, 52
de Morgan’s duality laws, 7
Natural elements in a ﬁeld, 62
Natural numbers, 54
and induction, 62
well-ordering property of, 66
Negative numbers, 53, 57
Nested line segments, principle of
in E1, 83
in Euclidean space, 180
in a normed linear space, 185
Neutral elements, existence of additive and
multiplicative, 51
Noncommutative group, 176, 30
Nonstandard analysis, 85
Norm
of a vector in En, 134
in a normed linear space, 181
Normalized vector in En, 142
Normed linear space, 181
absolute value in a, 181
distance in a, 183
H¨older’s inequality, 185
Minkowski’s inequality, 186
norm in a, 181
principle of nested line segments in a,
185
translation invariance of distance in a,
184
triangle inequality of distance in a, 184
triangle inequality of the norm in a, 181
Numbers
irrational, 47, 118
natural, 54
rational, 35, 46, 74, 118
real, 51 (see also Field, complete or-
dered)
Open
interval in E1, 77
interval in En, 163
line segment in En, 146
Ordered
ﬁeld, 53 (see also Field, ordered)
n-tuple, 69, 3, 127
pair, 9; 3, 14, 38, 127
set, 52, 110
triple, 27, 127
Origin in En, 128
Orthogonal projection
of a point on a line, 149
of a point on a hyperplane, 157
of a vector on a line, 147
Orthogonal vectors in En, 140
Pair, ordered, 9; 3, 14, 38
inverse of, 15
Parallel
hyperplanes in En, 151
lines in En, 145, 148
vectors in En, 135, 148
Parametric coordinate equations of a line
in En, 144
Parametric equation of a line in En, 144
Pascal’s law, 72
Pencil of hyperplanes, 157
Perpendicular
hyperplanes in En, 152
vectors in En, 140
Plane in En. See Hyperplane in En
Polar coordinates of complex numbers, 173
Position vector in En, 128
Positive numbers, 53, 57
Powers
with integer exponents, 68
with rational exponents, 92
with real exponents, 94
Prime
integers in an ordered ﬁeld, 76
relatively, 75
Projection, orthogonal. See Orthogonal
projection
Proof
by contradiction, 67
by induction, 63
Proper subset (⊂), 2

194
Index
Quantiﬁers, logical
existential (∃), 12
negation of, 14
universal (∀), 12, 14
Quotient
set by an equivalence relation, 33
of ﬁeld elements (/), 54
of natural elements in an ordered ﬁeld,
73
Range
of a relation, 16
of a function or mapping, 23
Rationals
in a ﬁeld, 74
in lowest terms in an ordered ﬁeld, 75
Rational numbers, 118
countability of, 46
from natural numbers, 35
Rational subﬁeld of an ordered ﬁeld, 75
Real axis, 52
Real numbers. See also Field, complete
ordered
binary approximations of, 99
construction of the, 110
decimal approximations of, 97
Dedekind cuts, 111
completeness axiom, 79
expansions of, 99
extended, 120
geometric representation of, 53
intervals of, 77
period of expansions of, 99
q-ary approximations of, 99
real axis, 52
terminating expansions of, 99
ternary approximations of, 99
Real part of a complex number, 170
Real points in C, 171
Reﬂexive relations, 17, 32
inclusion relation, 2
Relations, 14
as sets, 15
associativity of composition of, 29
composition of, 28
domain of, 16
equality of, 28
equivalence, 32 (see also Equivalence
relations)
from Cartesian products of sets, 18
from cross products of sets, 18
image of a set under, 17
inverse of, 16
inverse image of a set under, 17
range of, 16
reﬂexive, 17, 32
symmetric, 17, 32
transitive, 17, 32
trichotomic, 17
Remainder (of natural elements in an or-
dered ﬁeld), 73
Ring of sets, 170
Roots in a complete ordered ﬁeld, 89, 90
Russell paradox, 11. See also Sets
Scalar of En, 128
Scalar multiple in En, 129
Semi-ring of sets, 168
Semi-norm, 182
Semi-normed linear space, 182
Sequence, 37
arithmetic, 42
constant, 38
double, 46
ﬁnite, 37
geometric, 42
in index notation, 38
inductive deﬁnition of, 39
inﬁnite, 37
lower limit of a, 122
as mappings, 37
monotone, 40
as ordered pairs, 38
strictly monotone, 40
subsequence, 40
upper limit of a, 122
Sets, 1
associative laws, 5
bounded sets in an ordered ﬁeld, 77 (see
also Bounded sets)
Cartesian products of, 18, 69
commutative laws, 5
complement of (−), 4
contracting sequence of, 39
convergent sequence of, 43
countable, 41, 44
countable union of, 46
cross products of, 18
diﬀerence of (−), 4
disjoint, 4
distributive laws, 5, 9, 10
duality laws, de Morgan’s, 7
element of (∈), 1
empty set (∅), 1, 41

Index
195
equality of, 2
expanding sequence of, 39
family of, 1, 6
ﬁnite, 41
idempotent laws, 5
index, 6
inductive, 62
inﬁnite, 41, 48, 45
intersection of (∩), 4
intersection of a family of (T), 6
lower limit of a sequence of, 43
monotone sequence of, 40
ordered, 52
proper subset of (⊂), 2
ring of, 170
Russell paradox, 11
semi-ring of, 168
subset of (⊆), 2
superset of (⊇), 2
symmetric diﬀerence of (△), 11
uncountable, 41, 45
union of (∪), 4
union of a family of (S), 6
upper limit of a sequence of, 43
Venn diagrams, 5
Simple sets in En, 169
Sphere in En, 148
Strictly monotone sequences, 40
Subsequence, 40
Subadditivity of the volume of intervals in
En, 170
Subset (⊆), 2
proper subset (⊂), 2
Subtraction of ﬁeld elements, 55
Superset (⊇), 2
Supremum (sup), 79
Symmetric diﬀerence of sets, 11
Symmetric relations, 17, 32
Symmetries of plane ﬁgures, 31
as mappings, 31
Transformation, 25. See also Mapping
Transitive relation, 17, 32
< as a, 52,
inclusion relation, 2
Translation invariance of distance in a
normed linear space, 184
Triangle inequality
in an ordered ﬁeld, 59
in En, 135
of the distance in a normed linear space,
184
of the norm in a normed linear space,
181
Trichotomic relation, 17
< as a, 52
Trigonometric form of complex numbers,
174
Tuple (ordered), 69; 3
Uncountable sets, 41, 45
Cantor’s diagonal process, 47
irrational numbers, 47
Union
countable, 46
of sets (∪), 4
of a family of sets (S), 6
Unit vector in En, 142
Universal quantiﬁer (∀), 12
Upper limit
of a sequence of numbers, 122
of a sequence of sets, 43
Vector in En, 128
Vector space, 176
complex, 177
normed linear space, 181 (see also
Normed linear space)
real, 177
semi-normed linear space, 182
Venn diagrams, 5. See also Sets
Volume of an interval in En, 164
additivity of the, 166
subadditivity of the, 170
Well-ordering property, 66
Zero-vector in En, 128

