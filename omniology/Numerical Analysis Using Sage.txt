Springer Undergraduate Texts 
in Mathematics and Technology
George A. Anastassiou
Razvan A. Mezei
Numerical 
Analysis 
Using Sage

Springer Undergraduate Texts
in Mathematics and Technology
Series Editors:
J. M. Borwein, Callaghan, NSW, Australia
H. Holden, Trondheim, Norway
V. Moll, New Orleans, LA, USA
Editorial Board:
L. Goldberg, Berkeley, CA, USA
A. Iske, Hamburg, Germany
P.E.T. Jorgensen, Iowa City, IA, USA
S. M. Robinson, Madison, WI, USA
More information about this series at http://www.springer.com/series/7438


George A. Anastassiou • Razvan A. Mezei
Numerical Analysis Using Sage
123

George A. Anastassiou
Department of Mathematical Sciences
The University of Memphis
Memphis, TN, USA
Razvan A. Mezei
Mathematics and Computing Sciences
Lenoir-Rhyne University
Hickory, NC, USA
Additional material to this book can be downloaded from http://extras.springer.com.
ISSN 1867-5506
ISSN 1867-5514
(electronic)
Springer Undergraduate Texts in Mathematics and Technology
ISBN 978-3-319-16738-1
ISBN 978-3-319-16739-8
(eBook)
DOI 10.1007/978-3-319-16739-8
Library of Congress Control Number: 2015934903
Mathematics Subject Classiﬁcation (2010): 47N40, 97N40, 97N80, 97U20
Springer Cham Heidelberg New York Dordrecht London
© Springer International Publishing Switzerland 2015
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the material is concerned,
speciﬁcally the rights of translation, reprinting, reuse of illustrations, recitation, broadcasting, reproduction on microﬁlms or in
any other physical way, and transmission or information storage and retrieval, electronic adaptation, computer software, or by
similar or dissimilar methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication does not imply,
even in the absence of a speciﬁc statement, that such names are exempt from the relevant protective laws and regulations and
therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this book are believed to be true
and accurate at the date of publication. Neither the publisher nor the authors or the editors give a warranty, express or implied,
with respect to the material contained herein or for any errors or omissions that may have been made.
Printed on acid-free paper
Springer International Publishing AG Switzerland is part of Springer Science+Business Media (www.springer.com)

I dedicate this book to my wife Koula, and my children
Angela and Peggy
George A. Anastassiou
I would like to dedicate this work to my High-School Math-
ematics teacher, Aurel Netea, whose passion for teaching
inspired me. There are no words that can completely describe
my gratitude for his great support and his encouragements
that helped me choose this path in my career. He was the ﬁrst
“giant” that I met in my search of new knowledge. I would
also like to thank my wife Fernanda, and my mother Ileana,
for their great love and support. I could not have done this
work without their constant support.
Razvan A. Mezei.


Contents
1
Fundamentals ....................................................................................
1
1.1
Why Sage ..................................................................................
1
1.2
A Taste of Sage ............................................................................
2
1.3
Absolute Error vs. Relative Error .........................................................
20
1.4
Accuracy and Precision ...................................................................
21
1.5
Rounding and Chopping ..................................................................
23
1.6
Introduction to Sage Programming Through Examples .................................
24
1.6.1
Deﬁning a Function: Evaluating It for a Given Input ..........................
24
1.6.2
Print and Range ..................................................................
25
1.6.3
For Loop: A First Example ......................................................
26
1.6.4
For Loop: Another Example.....................................................
27
1.6.5
Conditional Statement ...........................................................
28
1.6.6
More on Conditional Statements ................................................
29
1.6.7
Working with Strings ............................................................
30
1.6.8
Computing a Running Total .....................................................
31
1.6.9
Counting..........................................................................
31
1.6.10
While Loops......................................................................
32
1.6.11
Another Example on Writing Functions ........................................
33
1.6.12
Nested Functions: Randomly Generated Numbers .............................
34
1.6.13
Working with Arrays.............................................................
35
1.7
Taylor Series ...............................................................................
37
1.8
Alternating Series..........................................................................
56
1.9
Sage Interacts ..............................................................................
58
1.10
Exercises ...................................................................................
60
1.11
Computer Exercises .......................................................................
61
References .........................................................................................
63
2
Solving Nonlinear Equations ...................................................................
65
2.1
Bisection Method ..........................................................................
65
2.1.1
The Algorithm....................................................................
66
2.1.2
Pseudocode .......................................................................
68
2.1.3
Sage Code ........................................................................
68
2.1.4
Error Bounds .....................................................................
70
2.1.5
Comments on the Bisection Method ............................................
71
2.1.6
Examples .........................................................................
71
2.1.7
Sage Library......................................................................
75
vii

viii
Contents
2.2
Newton–Raphson’s Method ...............................................................
76
2.2.1
The Algorithm....................................................................
78
2.2.2
Pseudocode .......................................................................
79
2.2.3
Sage Code ........................................................................
80
2.2.4
Error Bounds .....................................................................
81
2.2.5
Comments on the Newton–Raphson’s Method .................................
81
2.2.6
Examples .........................................................................
85
2.2.7
Sage Library......................................................................
88
2.2.8
Sage Library 2....................................................................
89
2.3
Secant Method .............................................................................
90
2.3.1
The Algorithm....................................................................
93
2.3.2
Pseudocode .......................................................................
95
2.3.3
Sage Code ........................................................................
96
2.3.4
Error Bounds .....................................................................
97
2.3.5
Comments on the Secant Method ...............................................
98
2.3.6
Examples .........................................................................
98
2.3.7
Sage Library...................................................................... 100
2.4
Fixed-Point Iteration....................................................................... 101
2.4.1
The Algorithm.................................................................... 102
2.4.2
Pseudocode ....................................................................... 108
2.4.3
Sage Code ........................................................................ 109
2.4.4
Examples ......................................................................... 109
2.4.5
Sage Library...................................................................... 111
2.5
An Application to Business ............................................................... 112
2.6
Exercises ................................................................................... 113
2.7
Computer Exercises ....................................................................... 114
References ......................................................................................... 115
3
Polynomial Interpolation........................................................................ 117
3.1
Interpolation ............................................................................... 118
3.1.1
Linear Interpolation .............................................................. 118
3.1.2
Quadratic Interpolation .......................................................... 120
3.1.3
Lagrange Formula................................................................ 123
3.1.4
Sage Code for Lagrange Formula ............................................... 126
3.1.5
Newton Formula ................................................................. 128
3.1.6
Sage Code for Newton Formula ................................................. 132
3.1.7
Divided Differences.............................................................. 134
3.1.8
Sage Code for Divided Differences ............................................. 137
3.1.9
Inverse Interpolation ............................................................. 138
3.1.10
Sage Library...................................................................... 139
3.2
Error Bounds in Polynomial Interpolation ............................................... 143
3.3
An Application to Physics................................................................. 153
3.4
Exercises ................................................................................... 154
3.5
Computer Exercises ....................................................................... 156
References ......................................................................................... 159
4
Numerical Differentiation....................................................................... 161
4.1
Derivative Formulae Using Taylor Series ................................................ 161
4.1.1
First Order Derivatives........................................................... 161
4.1.2
Second Order Derivatives........................................................ 166
4.1.3
Method of Undetermined Coefﬁcients .......................................... 167

Contents
ix
4.2
Derivative Formulae Using Interpolating Polynomials .................................. 169
4.3
Exercises ................................................................................... 171
4.4
Computer Exercises ....................................................................... 172
References ......................................................................................... 173
5
Numerical Integration ........................................................................... 175
5.1
Trapezoidal Rule........................................................................... 178
5.1.1
Basic Trapezoidal Rule .......................................................... 178
5.1.2
Composite Trapezoidal Rule .................................................... 180
5.1.3
Sage Code ........................................................................ 181
5.1.4
Error Bounds ..................................................................... 184
5.1.5
Sage Library...................................................................... 187
5.2
Simpson’s Rule ............................................................................ 188
5.2.1
Basic Simpson’s Rule............................................................ 188
5.2.2
Composite Simpson’s Rule ...................................................... 190
5.2.3
Sage Code ........................................................................ 192
5.2.4
Error Bounds ..................................................................... 195
5.2.5
Sage Library...................................................................... 198
5.3
Using the Method of Undetermined Coefﬁcients ........................................ 200
5.3.1
Basic Trapezoidal Rule Using the Method of Undetermined
Coefﬁcients....................................................................... 200
5.3.2
Basic Simpson’s Rule Using the Method of Undetermined
Coefﬁcients....................................................................... 200
5.4
Richardson Extrapolation ................................................................. 201
5.5
Romberg Method .......................................................................... 203
5.5.1
Motivation ........................................................................ 203
5.5.2
Algorithm ........................................................................ 205
5.5.3
Sage Code ........................................................................ 205
5.5.4
Error Bounds ..................................................................... 208
5.6
Newton–Cotes Formulae .................................................................. 208
5.6.1
Closed Newton–Cotes Formulae ................................................ 209
5.6.2
Open Newton–Cotes Formulae.................................................. 209
5.7
Gauss Quadrature Formula ................................................................ 210
5.7.1
A Brief Outline................................................................... 210
5.7.2
Algorithm by Example........................................................... 211
5.7.3
The General Algorithm .......................................................... 214
5.7.4
Sage Code ........................................................................ 216
5.8
An Application to Materials Science and Engineering .................................. 217
5.9
Exercises ................................................................................... 218
5.10
Computer Exercises ....................................................................... 222
References ......................................................................................... 224
6
Spline Interpolation.............................................................................. 227
6.1
Linear Splines.............................................................................. 230
6.1.1
Sage Code ........................................................................ 232
6.1.2
Sage Library...................................................................... 233
6.2
Quadratic Splines .......................................................................... 234
6.2.1
Algorithm ........................................................................ 235
6.2.2
Sage Code ........................................................................ 237
6.3
Natural Cubic Splines ..................................................................... 240
6.3.1
Algorithm ........................................................................ 243

x
Contents
6.3.2
Sage Code ........................................................................ 247
6.3.3
Sage Library...................................................................... 250
6.4
An Application to Computer Science..................................................... 253
6.5
Exercises ................................................................................... 257
6.6
Computer Exercises ....................................................................... 259
References ......................................................................................... 261
7
Numerical Methods for Differential Equations............................................... 263
7.1
Introduction ................................................................................ 263
7.2
Euler’s Method............................................................................. 267
7.2.1
Algorithm ........................................................................ 268
7.2.2
Sage Code ........................................................................ 270
7.2.3
Sage Library...................................................................... 273
7.2.4
Sage Interacts .................................................................... 276
7.2.5
Error Bounds ..................................................................... 277
7.3
Taylor Series Method ...................................................................... 279
7.3.1
Algorithm ........................................................................ 279
7.3.2
Sage Code ........................................................................ 282
7.4
Runge–Kutta’s Method .................................................................... 284
7.4.1
Runge–Kutta Method of Order 2 ................................................ 284
7.4.2
Runge–Kutta Method of Order 4 ................................................ 285
7.4.3
Sage Code ........................................................................ 286
7.5
Systems of Ordinary Differential Equations ............................................. 288
7.5.1
Taylor Series Method ............................................................ 288
7.6
Higher-Order Ordinary Differential Equations........................................... 294
7.6.1
Sage Library...................................................................... 297
7.7
Systems of Higher-Order Differential Equations ........................................ 299
7.7.1
Sage Library...................................................................... 304
7.8
An Application to Biology ................................................................ 307
7.9
Exercises ................................................................................... 307
7.10
Computer Exercises ....................................................................... 309
References ......................................................................................... 311
Index................................................................................................... 313

Preface
To the best of our knowledge, this is the ﬁrst numerical analysis text that uses Sage for algorithms
implementation. We chose to base our presentation of a basic numerical analysis course on Sage
for the following reasons. Firstly, Sage is FREE. Secondly, it uses a Python-like syntax. This is
particularly important since, in the recent years, Python became a very popular choice of script to use
in introductory programming courses. Moreover, it gained the great reputation of being easy to learn.
Some even claim that Python is the easiest programming language to learn by ﬁrst-time programmers.
An analysis made by Philip Guo in July 2014 (see http://pgbovine.net/) shows that “Python is now the
most popular introductory teaching language at top U.S. universities”, with eight out of the top ten
Universities in the U.S. using Python in their CS 0 or CS 1 courses.
Numerical analysis has applications in virtually every applied science including computer graphics,
engineering, economics, biology, physics, aerodynamics, statistics, and more. Therefore, we recom-
mend this text to all undergraduates in mathematics, mathematics education, computer science &
information technology, pre-engineering, and mathematical science students. The material included in
this book was used in a one-semester course called “Introduction to Numerical Analysis” (at Lander
University, Greenwood, SC) to undergraduate students in mathematics, computer science, and pre-
engineering.
We need approximation techniques to deal with the basic fact that every calculator and every
computer has ﬁnite memory. This implies that only a ﬁnite number of digits can be stored and hence no
irrational number can be stored on any computer. Still, nowadays computers can perform very accurate
computations, and even graph various functions, including sin.x/, ln.x/,
5px, and even much more
elaborate functions. This is possible because of the approximation techniques developed in numerical
analysis.
As an example, numerical analysis techniques are extensively used in computer science. Most
image and video compression/decompression algorithms use interpolation. Using various sampling
techniques, we can compress images (“lossy” compression), and then, using interpolation techniques,
we can decompress them. Image restoration, digital sounds, GPS coordination, video games, etc. all
use interpolation techniques. Interpolation techniques help us make the transition from discrete into
continuous, and in particular, from digital into analog.
In this book, we present both: how to implement from scratch different algorithms using Sage (for
this, look for sections called Sage Code), and how to use the existing Sage Library functions that are
already implemented (look for sections called Sage Library).
The content is mostly self-contained. You do not need to have any Python programming
background in order to read this book, although familiarity with any programming language is a plus.
We present enough examples so that hopefully, the student will become proﬁcient in writing efﬁcient
Sage code and develop algorithms on their own. This text, however, is not meant to be an introduction
xi

xii
Preface
to programming. For a great introduction to programming textbook using Python, the reader is invited
to refer the great reference: Tony Gaddis, Starting Out with Python, second edition, Addison-Wesley,
2012.
With one exception (the image included on page 21), all the graphs included in this book were
composed in Sage and for most of the graphs, we provide in this book its corresponding Sage code.
For your convenience, all the Sage source code will also be provided at http://extras.springer.com.
We put every effort in writing Sage code that is easy to read and understand. As such, we
occasionally simpliﬁed the code for easier reading, at the expense of a few extra operations. Therefore,
some of the algorithms may not contain the most optimal computational solutions. We challenge the
reader to optimize these Sage programs. To help with the code, in the chapter Solving Nonlinear
Equations we also include pseudocode in addition to its Sage implementation.
Through the use of Sage “Interacts”, which are very brieﬂy presented in this book, the reader can
create great demonstrations that can be used while teaching or during presentations.
Memphis, TN, USA
George A. Anastassiou
Hickory, NC, USA
Razvan A. Mezei
December 30, 2014

Chapter 1
Fundamentals
1.1
Why Sage
Most existing Numerical Analysis textbooks, are centered around some programming language (such
as C, CCC, etc.) or some Mathematical programs (e.g., Mathematicar, Mapler, Matlabr; etc.) see
[3, 6, 7]. What we are proposing here is a Numerical Analysis book that uses Sage Math. Throughout
this book we will refer to it shortly as Sage.
A ﬁrst question that we will address next is: Why use Sage? What are the beneﬁts of using Sage
over the other existing options mentioned above and how is it similar to them?
1. Sage can be used as a comprehensive Mathematics computation engine (similarly to
Mathematicar, or Mapler), by calling the functions that are already available for you. “Whenever
you use Sage you are accessing one of the world’s largest collections of open source computational
algorithms” [11].
2. Sage uses a Python-like syntax (as an alternative to using Pascal, C, or CCC, etc.). There is a
reason why, in the recent years, the Python programming language became more and more popular
and now many Universities are teaching Python as a ﬁrst programming language (CS 0) to students
that are majoring in Engineering, Computer Science, Computer Information Systems, Information
Technology, even Mathematics. Some even teach CS 1 in Python and CS 2 in CCC. There are
several articles claiming that Python is THE favorite Introduction to Programming Language.
3. Perhaps one of the greatest advantage of using Sage is the fact that it is FREE. You simply can’t
beat that price. Moreover, there are many user manuals available on Sage website [11] and on a
growing number of other websites.
4. Sage is Open Source. What does this imply? Among others it means that there are a lot of source
codes available for everyone to see, analyze, and use for free. This gives you a tremendous potential
for new research.
5. Easy access to Sage. You can download Sage and use it as a stand alone application, on your
own computer, without any need to be connected to the Internet or you can use web-based client
that can be accessible from virtually everywhere you have access to the Internet, without installing
anything on your computer. We present, below, these options.
Electronic supplementary material The online version of this chapter (doi:978-3-319-16739-8_1) contains supple-
mentary material, which is available to authorized users.
© Springer International Publishing Switzerland 2015
G.A. Anastassiou, R. Mezei, Numerical Analysis Using Sage, Springer Undergraduate
Texts in Mathematics and Technology, DOI 10.1007/978-3-319-16739-8_1
1

2
1
Fundamentals
(a) The way we prefer to access Sage and we used it for almost all the examples given in this
book is through the “Sage Cell Server”. This is available on [10]. In this web client you can
simply insert your Sage code, edit it, and run it without installing anything on your computer.
Moreover, you never have to worry about having the latest edition of Sage on your computer,
or having a powerful enough computer. You can even use smart phones to access this website.
It does however have some shortcomings: you need to have access to the Internet, and it
does not save your code automatically. This can be a challenge if your browser becomes
unresponsive from time to time, or if you need to refresh the page.
(b) An alternative to “Sage Cell Server” is a Sage Notebook (see http://sagenb.org/). Similar to the
one above, you don’t need to install anything on your computer. You need to create an account
once (this is FREE) and then you can save, access old ﬁles, and even share your Sage code.
This can successfully be used for research, homework assignments, and even lab works. For
the latest trend in Sage you may want to check the SageMathCloud (https://cloud.sagemath.
com) which is still under active development at the time we are writing this book.
(c) If Internet connection can be an issue, at times, then you can install Sage on your machine.
This way you don’t need to worry about not having access to the Internet, and you can also
save your work. The challenge with this option though is that it is your responsibility to keep
up with the latest version of Sage. Also, it will use the computing power of your own machine.
6. Sage Math is a great tool for many other courses not only Numerical Analysis. There are several
existing books on how to use it in Calculus, Linear Algebra, Number Theory, Computational
Statistics, Discrete Mathematics, Differential Equations and many others courses. There are
extensive libraries that can be used for these subject areas, and the number of them grows every
day.
We hope that we already convinced you on the great potential Sage has. Next we present you some
basic examples and try to exhibit the great potential and the easiness to use Sage. All the examples in
this book used the following Sage version: “Sage Version 6.3, Release Date: 2014-08-10”. To check
the version of the Sage that you are using, one can run the following code:
sage: version
to obtain
‘Sage Version 6.3, Release Date: 2014-08-10’
1.2
A Taste of Sage
To get you started with some very basic examples in Sage Math, please go on [10] and try each of
the examples given below. They should give you a brief idea of what Sage can do. Do not worry if
you don’t know all the details of the code you are using in these examples. We will give you a more
detailed explanation of how to code in Sage as you read through the book. These ﬁrst examples should
help you get a little familiar with how to use Sage see also [12].
In Sage, as well as in Python (see [8]), everything in a line that comes after the character # is a
comment, and therefore it is completely ignored by Sage. Comments are text that are being used to
make the code easier to read. Although they are completely ignored by the compiler, you are strongly
encouraged to use comments when you write code. Comments can help you read the code much faster,
without focusing on every detail of the syntax, and they become very handy especially when your code
becomes lengthy, or when you use some trick to shorten the code. They also help other developers

1.2
A Taste of Sage
3
who may need to read, use, or simply check your code. You simply cannot overestimate the value of
using comments in your code.
IMPORTANT: to avoid frustration, please read the following carefully and know it. In Sage, as
well as in Python, leading whitespaces (spaces or tabs at the beginning of a line) are used to compute
the indentation level of that line. They are used to determine the grouping of the statements. Same
level of indentation means they are part of the same group of statements. Other programming
languages (such as Java, C/CCC, and C#) use the symbols { and } for the same purpose, and some
programming languages, like Pascal, use the keywords begin and end. Therefore don’t add leading
whitespaces if they are not necessary, and DO add them if they are needed. Wrong indentation can
lead to compiling errors, or worst: wrong outputs and challenges to debug errors.
ALSO IMPORTANT: Sage, as well as Python, is case-sensitive. That means, print, Print, and
PRINT are considered different. Please make sure you use the correct letter case as indicated in the
examples.
NOTE: Please note that in most programming languages, including Python (and Sage), we use
DD when comparing two values or expressions, and we use D for the assignment operator. That
means a DD 7 compares a against the value 7, while a D 7 assigns the value 7 to a. It is very
common for novice programmers to mix these two. Do your best and try to avoid this error, as it can
sometimes be very challenging to debug code containing such logical errors.
The lines below that start with “sage:” are the lines of code you should submit to the Sage
interpreter. You do not need to include “sage:” when you type your code into Sage. The lines without
“sage:” are the output lines. After you type in your code, you can either click on the “Evaluate” button,
or press “ShiftCEnter” for Sage to run the code you just inserted.
Sage Math syntax is broader than Python. For example the exponential operator in Python is **.
Sage accepts both of the following exponential operators: ** and ^. Therefore, while only 2  3 is a
legitimate code in Python for computing 23, Sage accepts both of the following: 23 as well as 2^3.
We will make use of this throughout the book.
sage: #computes 2 to the power of 3
sage: 2**3
8
sage: #computes 2 to the power of 3
sage: 2^3
8
sage: #factors the number 2013
sage: 2013.factor()
3 * 11 * 61
sage: #also works with fractions
sage: factor(-2014/2016)
-1 * 2^-4 * 3^-2 * 7^-1 * 19 * 53
sage: #computes the square of a matrix
sage: matrix([[1,2], [3,4]])^(2)

4
1
Fundamentals
[ 7 10]
[15 22]
sage: #computes the inverse of a matrix
sage: matrix([[1,2], [3,4]])^(-1)
[
-2
1]
[ 3/2 -1/2]
sage: #outputs the value of e with 100 bits of precision
sage: e.n(100)
2.7182818284590452353602874714
sage: #outputs the value of pi with 100 bits of precision
sage: pi.n(100)
3.1415926535897932384626433833
sage: #outputs the value of pi with 200 bits of precision
sage: pi.n(200)
3.1415926535897932384626433832795028841971693993751058209749
sage: #outputs pi with default (53) bits of precision
sage: pi.n()
2.71828182845905
sage: #outputs the value with 200 bits of precision
sage: sqrt(2).n(200)
1.4142135623730950488016887242096980785696718753769480731767
sage: #IMPORTANT: So how can we print decimal values? Use n()
sage: #If you need to output multiple items on the same line:
sage: #
you can separate them by commas
sage: print e^10, e^10.0,
(e^10).n(52), (e^10).n()
The previous example shows several alternatives in how to print values using decimal notation.
One way is to use bit precision: simply add .n(52). Instead of 52, you could use any desired bit
precision. The other way is to use 10.0, which is a decimal value, rather than the whole number 10.
In this case, Sage will use the implicit 52 bit precision for the output. If you use .n(), the default 53
bits of precision will be used. The output of the previous example will be:
e^10 22026.4657948067 22026.4657948067 22026.4657948067

1.2
A Taste of Sage
5
sage: R.<x,y> = QQ[]
sage: factor(x^21 + y^21)
#factors a polynomial
(x + y) * (x^2 - x*y + y^2) * (x^6 - x^5*y + x^4*y^2
- x^3*y^3 + x^2*y^4 - x*y^5 + y^6) * (x^12 + x^11*y
- x^9*y^3 - x^8*y^4 + x^6*y^6 - x^4*y^8 - x^3*y^9 + x*y^11 + y^12)
sage: var(’x,y’)
sage: #simplifies an expression
sage: (4*(x-3)^3+5*(x-4)^2+8).full_simplify()
4*x^3 - 31*x^2 + 68*x - 20
sage: factorial(70)
#try factorial(1000)
1197857166996989179607278372168909873645893814254642585755536
2864628009582789845319680000000000000000
sage: find_root(cos(x)-x, 0,2) #only finds a root, not all!!!
0.7390851332151607
sage: is_prime(2015)
#checks if 2015 is a prime number
False
sage: #try something more impressive
sage: #PUT THE NEXT NUMBER IN ONLY ONE LINE!
sage: is_prime(2012314234235235252352234234234234234234234235\
4546576785543563676894568467896795789485678780789044811234124\
123132343535635234235547567512343243241)
False
sage: #plots a given function, for x in [0, 40]
sage: show(plot(sin(x) + sin(1.6*x), 0, 40))

6
1
Fundamentals
sage: #computes the value of sine, at pi
sage: sin(pi)
0
sage: #EVALUATES the expression
sage: cos(3*pi/4)
-1/2*sqrt(2)
sage: #specifies u as a symbolic variable
sage: u = var(’u’)
sage: #computes the DERIVATIVE of cos(u) as a function of u
sage: diff(cos(u),u)
-sin(u)
sage: #specifies u as a symbolic variable
sage: u = var(’u’)
sage: #computes the FIFTH derivative of cos(u)*sin(u)
sage: diff(cos(u)*sin(u),u, 5)

1.2
A Taste of Sage
7
16*cos(u)^2 - 16*sin(u)^2
sage: var(’x’)
sage: f(x) = (x^2 - 1+cos(x)) / (x^4 + 1)
sage: #an alternative to ’print’ is ’show’
sage: show(derivative(f, x))
sage: var(’x’)
sage: f(x) = (x^4+3*x^2+4*x+6) / ((x+2)*(x+3)^2)
sage: #computes partial fractions of f
sage: g(x)=f.partial_fraction(x)
sage: #command show() will display the function g
sage: show(g)
sage: #declares u as a symbolic variable
sage: u = var(’u’)
sage: #computes the ANTIDERIVATIVE of cos(u)sin(u)
sage: #
as a function of u
sage: integral(cos(u)*sin(u),u)
-1/2*cos(u)^2
sage: #declares u as a symbolic variable
sage: u = var(’u’)
sage: #computes the DEFINITE INTEGRAL on [1,5]
sage: # of cos(u)sin(u) as a function of u
sage: integral(cos(u)*sin(u),u, 1, 5)
-1/2*cos(5)^2 + 1/2*cos(1)^2
sage: #declares u as a symbolic variable
sage: u = var(’u’)
sage: #computes the DEFINITE INTEGRAL on [1,5]

8
1
Fundamentals
sage: # of cos(u)sin(u) as a function of u
sage: # and outputs as a decimal
sage: integral(cos(u)*sin(u),u, 1, 5).n()
0.105731173132328
sage: #plot will create a graph of the given function, for x in [0,2]
sage: g = plot ( sin ( x ) + (1 - x ^2) , (x , 0 , 2))
sage: #and will create a pdf file of the plot
sage: g.save(’plot.pdf’)
sage: #Sage can compute the eigenvalues of the matrix and plot them
sage: myMatrix = random_matrix(RDF,300)
sage: theEigenvalue = myMatrix.eigenvalues()
sage: w=[(i,abs(theEigenvalue[i])) for i in range(len(theEigenvalue))]
sage: show(points(w))
sage: var(’x’)
sage: #defines f(x) to be the function sin(x)
sage: f(x) = sin(x)
sage: p=plot(f(x), (x,-pi/2, pi/2), linestyle=’--’,
sage:
thickness=3,color=’red’)
sage: #displays the plot we created above
sage: p.show()

1.2
A Taste of Sage
9
sage: var(’x’)
sage: solve(x^4>8, x)
#solves an inequality
[[x < -8^(1/4)], [x > 8^(1/4)]]
sage: var(’x,y’)
#specifies the variables x and y
sage: solve([x+y==7, x-y==-3], x, y)
#solves a system of two equations
[[x == 2, y == 5]]
sage: var(’x,y’)
sage: solve([x+y==7, x+y==-3], x, y)
#this system has no solutions
[]
sage: var(’x,y’)
sage: solve([x+y==7, x+y==7], x, y) #this system is dependent
([x == -y + 7], [1])

10
1
Fundamentals
sage: var(’x,y,z’)
sage: solve([x+y==7, x+y+z==11], x, y,z)
#this is also dependent
[[x == -r1 + 7, y == r1, z == 4]]
sage: var(’t’)
sage: p = parametric_plot( [sin(3*t), sin(2*t)], (t, 0, 3*pi),
thickness=2, color=’red’, linestyle="--")
sage: p.show()
#YOU CAN ALSO USE:
show(p)
sage: f(x,y) = sin(x)^2+cos(y)*x*y
sage: #defines the function f in two variables x and y
sage: plot3d(f, (x,-1,1), (y,-2,2))

1.2
A Taste of Sage
11
1.54
0.68
–0.19
–1.0
0.0
0.0
1.0 –2.0
2.0
sage: for i in range(4):
sage: #it means i takes on the values 0, 1, 2, and 3 respectively
sage: #please note the indentation used in the next line!
sage:
print i , "
" , i^2, "
" ,i^3
0
0
0
1
1
1
2
4
8
3
9
27
sage: #a bit more elaborate example!
sage: #first, define the function to be used
sage: f(x) = sin(x)*x+4
sage: #graphs the two horizontal lines
sage: P = line([(2,0),(2,f(2))], color=’black’)
sage: P += line([(8,0),(8,f(8))], color=’black’)
sage: #make the shade between the graph of f(x) and the x-axis

12
1
Fundamentals
sage: #this will be a polygon with many points
sage: P += polygon(
[(2,0),(2,f(2))] +
sage: [(x, f(x)) for x in [2,2.1,..,8]] +
sage: [(8,0),(2,0)],
sage: rgbcolor=(0.5,0.8,0.7),aspect_ratio=’automatic’)
sage: #draw the text above the graph
sage: #notice how we used LaTeX style!
sage: P += text("$\\int_{2}^8 (sin(x) x+4) dx$",
sage:
(5, 8), fontsize=20, color=’black’)
sage: #draw the curve
sage: P += plot(f, (x, 1.5, 8.5), thickness=3)
sage: #show the plot
sage: show(P)
The next example shows how one can format the x-axis scale:
sage: #how to scale your x-axis
sage: p = plot(sin(x), 0, 2*pi, linestyle = "--")
sage: p.show(ticks=pi/6, tick_formatter=pi)

1.2
A Taste of Sage
13
1.0
0.5
–0.5
–1.0
1
6 π
1
3 π
1
2 π
2
3 π
5
6 π
7
6 π
4
3 π
3
2 π
5
3 π
11
6 π
π
π
2
If you wish to display only a part of a graph, you can specify the desired window size in the
show() method.
sage: g = plot(2*sin(x), (x, -2*pi, 2*pi) )
sage: g.show(xmin=-pi, xmax=pi, ymin=-1, ymax=1,
sage:
ticks=pi/6, tick_formatter=pi)

14
1
Fundamentals
1.0
0.5
–0.5
–1.0
–π
π
––5
6
π
––2
3
π
––1
2
π
––1
3
π
––1
6
π
–1
6
π
–1
3
π
–1
2
π
–2
3
π
π
–5
6
If you want to display two graphs, in two separate coordinate systems you can use code similar to:
sage: graph1 = plot(sin(x), (x, -10, 10))
sage: graph2 = plot(sin(x-pi), (x, -10, 10))
sage: show(graphics_array([graph1, graph2], 2, 1))

1.2
A Taste of Sage
15
sage: graph1 = plot(sin(x), (x, -10, 10))
sage: graph2 = plot(sin(x-pi), (x, -10, 10))
sage: show(graphics_array([graph1, graph2], 1, 2))
If you want both graphs to be displayed in the same coordinate system:
sage: graph1 = plot(sin(x), (x, -10, 10), color = ’red’)
sage: graph2 = plot(sin(x-pi), (x, -10, 10))
sage: show(graph1+graph2)
OR

16
1
Fundamentals
How to plot a set of points? Here is an example that plots 100 randomly generated points. The
function random() will return a decimal value between 0 and 1. Hence r will be an array of 100
pairs of numbers (or 2D points, if you wish) whose values are between 0 and 1.
sage: r = [(random(),random()) for i in range(100)]
sage: list_plot(r,color=’red’)

1.2
A Taste of Sage
17
The following example will plot 100 random points with integer coordinates between 10
and 99. To obtain a random integer between 10 and 99 (inclusively), one can use the function
random.randint(10,99). When we display these points, were can given each point a display
size. In our code we used size = 70.
sage: import random
sage: r = [(random.randint(10,99),
sage:
random.randint(10,99)) for i in range(100)]
sage: list_plot(r,color=’blue’, size = 70)
If you wish to graph parametric equations you can use code similar to:
sage: var(’t’)
sage: parametric_plot( (t*cos(t), t*sin(t)), (t, 0, 8*pi))

18
1
Fundamentals
The graphs can be FILLED with a color. For example:
sage: var(’t’)
sage: parametric_plot( (10*sin(t)^3,
sage:
9*cos(t)-4*cos(2*t)-cos(3*t)-cos(4*t)),
sage:
(t, 0, 2*pi), color = ’red’,
sage:
fill = True, fillcolor=’orange’)

1.2
A Taste of Sage
19
One last example that shows how one line of code in Sage can do a lot. Adding several graphs into
one and displaying the result.
sage: show(sum(circle((i,0), i) for i in [10,9.9,..,0]))
The graph is displayed on the next page.
Most of the code given above should be fairly self-explanatory and the use of comments (the text
in a line that follows the # symbol) should help you at least guess what the code does before you
actually run the code. If there are any parts of the code that are not entirely clear, do not worry too
much, we’ll cover some of these examples in more details in the following sections of this book.

20
1
Fundamentals
For a more in-depth introduction to Sage, and how to use SciPy library for numerical and scientiﬁc
computing in Sage or Python, the reader may also want to check the following resource [5]. Other
useful books that provide plenty of Sage code examples are: [2] for Linear Algebra and Differential
Geometry, and [4] for Abstract Algebra.
1.3
Absolute Error vs. Relative Error
Irrational numbers, such as , have an inﬁnite number of digits. Whenever we want to write down its
decimal representation, we can only include a ﬁnite part of it, and hence only write an approximation
of it. This however introduces an error. For example, when we approximate  by 3:14159265, we
are introducing an error. Approximating  by 3:14 will introduce a larger error.
As we see next, there are several ways to estimate the magnitude of the errors that result from an
approximation. Depending on the targeted audience we may want to use one or another of these
deﬁnitions. Here we will mention three of the most common deﬁnitions: the error formula, the
absolute error formula, or the relative error formula. Each one of these deﬁnitions is given below.
The simplest of these three is the error formula. The absolute error formula is an alternative to
the error formula for cases where the sign is irrelevant. A bit more elaborate, but occasionally more
relevant, is the relative error formula which measures the error in relation to the size of the true
value.

1.4
Accuracy and Precision
21
Deﬁnition 1. Let ˛ be a number and ˇ be an approximation for ˛.
The expression ˛  ˇ is called the error of ˇ as an approximation to ˛. Put another way, we have
that
error D true value  approximate value:
The expression j˛  ˇj is called the absolute error of ˇ as an approximation to ˛.
The relative error of ˇ as an approximation to ˛ is given by j˛ˇj
j˛j . Relative error measures the
error in relation to the size of the true value.
Deﬁnition 2. The number of digits, starting with the leftmost nonzero digit, and ending with the
rightmost (zero or nonzero) correct digit, is called the number of signiﬁcant digits.
Example 3. Let x D 0:000123 rounded to x D 0:00012 and y D 120:128 rounded to y D 120:13.
In each case, ﬁnd the number of signiﬁcant digits, the absolute errors, and the relative errors.
Solution. In the ﬁrst case x has two signiﬁcant digits. The absolute error is given by
j0:000123  0:00012j D 0:000003 D 0:3  105:
The relative error is given by
j0:000123  0:00012j
j0:000123j
' 0:02439 D 0:2439  101:
In the second case y has four signiﬁcant digits. The absolute error is given by
j120:128  120:13j D 0:002 D 0:2  102:
The relative error in this case is given by
j120:128  120:13j
j120:128j
' 0:00001665 D 0:1665  104:

1.4
Accuracy and Precision
Accuracy is the degree of conformity of a measure to a true value. We have
Deﬁnition 4. Accurate to n decimal places means the n digits to the right of the decimal point are
meaningful (you can trust them to be exact).
And
Deﬁnition 5. Accurate to n signiﬁcant digits means that n digits, starting with leftmost nonzero
digit, are meaningful (you can trust them to be exact).
We call precision the accuracy with which a number can be represented [14].

22
1
Fundamentals
Example 6. Let’s suppose you use a millimeter ruler to measure some lengths. This means your
measurements are accurate to 1 mm. If you give the lengths in meters, then your measures are accurate
to three decimal places, since 1 mm equals 0:001 m.
A measurement such as 173:1234567 m would be as accurate as 173:123 m since the ruler is
accurate to 1 mm only.
In this example, the measurement of 173:123 m is accurate to three decimal places. It is accurate
to six signiﬁcant digits.
The measurement 0:023 m is accurate to three decimal places and to two signiﬁcant digits.
As you may expect, the higher the number of signiﬁcant digits used in calculations, the more
accurate answers we obtain. But how much does this actually matter? Would it make a big difference
if, let’s say, we would use only three signiﬁcant digits of precision instead of four?
The answer is, it depends—sometimes it does, other times it doesn’t. In the following example, it
will make quite a bit of a difference.
Example 7. Solve only for the variable y in the linear system of equations in two variables
 0:1052x C 0:2155y D 0:7234
0:2141x C 0:4402y D 0:9562
(1.1)

1.5
Rounding and Chopping
23
First only carry three signiﬁcant digits of precision in all the calculations. Then repeat the work using
four signiﬁcant digits.
Solution. In the ﬁrst part we’ll use only three signiﬁcant digits. We can multiply the ﬁrst equation
by ˛ D 0:214=0:105  2:038 and add it to the second equation. We should obtain y D
0:517=0:001 D 517.
In the second part, we’ll repeat the same work, using now four signiﬁcant digits. We can multiply
the ﬁrst equation by ˛ D 0:2141=0:1052  2:0352 and add it to the second equation. We should
obtain y D 0:5161=0:0016 D 322:5625.
As you can see, there is quite a difference between the values of y, in those two cases.
If we would want to solve this system of equations using Sage, we can use the code below so solve
a system of equation:
sage: x = var(’x’) #declare x a variable
sage: y = var(’y’) #declare y a variable
sage: solve([0.1052*x+0.2155*y==0.7234,
0.2141*x+0.4402*y==0.9562], x, y)
[[x == (3745986/5683), y == (-1809590/5683)]]
If we want to know the decimal form of these numbers, using let’s say a 40 bit precision, just type
in the following command:
sage: (3745986/5683).n(40),(-1809590/5683).n(40)
(659.15643146, -318.42160831) 
From this example, we should learn that we should always try to carry all calculations with full
precision (or as much as it is possible) and not round off prior to each of the calculations.
REMEMBER: Whenever we have a numeric expression in Sage, we can append .n(40) to it in
order to get its decimal form, with a 40-bit precision. Of course 40 can be replaced with any other
positive integer that we want. If we simply omit the number 40, then we would use the default, 53 bits
of precision.
For example, we can use the following expression to obtain the decimal form, with 50 bits of
precision, of the golden ratio:
sage: ((1+sqrt(5))/2).n(50)
1.6180339887499
1.5
Rounding and Chopping
Sometimes we need to replace a number by another value that is approximately equal but has a shorter,
simpler representation. For this we can use either rounding or chopping.
If we discard all the digits that follow the nth digit, and leave all the remaining digits unchanged,
then we say that the number was chopped to n digits.
Example 8. The results of chopping 12:437, 12:460, 12:475, and 12:485, to 2 digits are: 12:43, 12:46,
12:47, and 12:48, respectively.
If we approximate a number with an n-digit number that approximates the ﬁrst with the minimum
error, then we say that the number was rounded to n digits.

24
1
Fundamentals
Example 9. The results of rounding 12:437, 15:632, and 12:460, to 2 digits are: 12:44, 15:63, and
12:46, respectively.
One question when rounding is deciding whether we should round up or down an .n C 1/-digit
decimal number. For example, should we round up or down the following: 12:475, and 12:485?
Here is the convention we’ll usually use in this book:
1. If the last digit equal 0, then we don’t need to round up or down.
2. If the digit equals 1, 2, 3, or 4, we should round down.
3. Similarly, if the digit equals 6, 7, 8, or 9, we should round up.
4. The challenging question is: what should we do in the case that digit equals 5? If we would always
round up, we would be biased, towards case 3. Similarly, if we would always round down, we
would be biased, towards case 2. So a compromise solution would be one that rounds up roughly
about half the times. The round-to-even method (also called unbiased rounding, or bankers’
rounding), means to round to the nearest number such that the nth digit is even. Round-to-odd
method means to round to the nearest number whose nth digit is odd.
Example 10. The results of rounding 12:475, and 12:485, to 2 digits are 12:48, and 12:48,
respectively.
1.6
Introduction to Sage Programming Through Examples
We will introduce here several examples on how to develop basic Sage code. If you are not very
familiar with programming, hopefully this section will help you get up to speed and write your very
ﬁrst Sage programs. If you are, however, familiar with Python, or Sage, then you may want to skip
this section, or read it brieﬂy.
1.6.1
Deﬁning a Function: Evaluating It for a Given Input
Example 11. Write Sage code that will create the following function:
f .x/ D 3 sin2 x C cos3 x  5
Then evaluate this function at x D 5.
Solution. One way you can deﬁne the function f .x/ and then use it to compute f .5/ is given below.
sage: f(x)=3*sin(x)+cos(x)^3-5
sage: f(5.0)
You should get an output similar to the one below:
-7.85394816310670
Another way to create a function in Sage is given next. This is the standard way to create a function
in Python. First we need to use the def keyword. This keyword should be followed by the function’s
name (of our choice) and a set of parentheses. In parentheses we include any number of parameters
we wish this function to have (comma separated). In the example below, function f will have only
one parameter, x. Notice the use of the colon at the end of this line of code. This line is called the
header of the function. Then, we deﬁne the body of the function. All the lines of code immediately

1.6
Introduction to Sage Programming Through Examples
25
following the header of the function, that are indented relative to the header, are collectively called
the body of the function. The functions may or may not return a value. In order to return a value, you
should include a return statement (a statement that uses the keyword return).
Please note that once the return statement is executed, all the remaining lines of code within the
body of the same function will be ignored. Therefore, within a body of a function, you should not
have any lines of code following a return statement.
sage: def f(x):
sage:
return 3*sin(x)+cos(x)^3-5
sage: f(5.0)
and get:
-7.85394816310670
For more practice, let’s take a look at the following function deﬁnition. We will create a function
called square() that will square an argument. Then we will use the newly created function. In order
to print something to the console, we can use the print function.
sage: def square(x):
sage:
return x*x
sage: print(square(2.5))
6.25000000000000
The alternative to the code above, with the same output, would be:
sage: square(x) = x*x
sage: print(square(2.5))
In future examples the body of the functions will usually be more elaborate. The above functions
are just some basic examples that should help you understand how to create functions in Sage.
1.6.2
Print and Range
Example 12. Create Sage code that will print all the numbers strictly between 10 and 20.
Solution. In order to print something to the console, we can use the print method. For example, we
could use the following command, to print the numbers strictly between 10 and 20:
sage: print 11, 12, 13, 14, 15, 16, 17, 18, 19
Please note how you need to use commas between the values you want to be printed out. You
should get an output similar to the one below:
11 12 13 14 15 16 17 18 19
Another handy method is range. The function range(a,b) returns the set of integers fxja  x < bg.
For example range.10; 40/ will return the set: f10; 11; 12; : : : ; 39g. And range.10; 40/ will return
the set: f10; 9; 8; : : : ; 39g. We can also use range function with only one parameter. In this case
the lower value is considered 0 implicitly. Hence range.40/ will return the set: f0; 1; 2; : : : ; 39g.

26
1
Fundamentals
Therefore we could use the following code to get a similar output to the one above
sage: print range(11, 20)
Yet another way to get the same output is using arrays, as shown below:
sage: print [11,12,..,19]
Below we show another way to get the same output by using arrays (also called lists) and explicit
for loops. We will explain loops in more details in the next subsection:
sage: print [x for x in [11,12,..,19]]
Note: in all these examples, the word print was not necessary, but we included it in order to
make our code easier to read. Try running the code with the work print omitted.
1.6.3
For Loop: A First Example
Example 13. Create Sage code that will print out the square of the ﬁrst ten positive integer numbers:
Solution. One way to do this is using the Sage code given below:
sage: print 0^2 , 1^2 , 2^2 , 3^2, 4^2, 5^2, 6^2, 7^2, 8^2, 9^2
You should get an output similar to the one below.
0 1 4 9 16 25 36 49 64 81
Another way to solve the same problem is using arrays. You could use something like:
sage: print [x^2 for x in [0,1,..,9]]
to get a similar output.
If you want to access the array later, you can ﬁrst create it and name it (in our case we named it
arr), then print it.
sage: arr =
[x^2 for x in [0,1,..,9]]
sage: print arr
The next example shows how we can use a loop to solve the same problem. Loops are statements
that allow you to repeat a set of instructions either for a number of times, or until an expression
(condition) becomes false. Loops are very important in programming and as such, you should
invest as much time as needed in order to fully understand them. If you have experience with any
other programming language, you most likely have already learned how they work, and here they
should be very similar. We will make extensive use of loops throughout this book.
sage: for number in range(10):
sage:
print number^2

1.6
Introduction to Sage Programming Through Examples
27
The output should look like:
0
1
4
9
16
25
36
49
64
81
The code range(10) returns the set of values (the array of values, to be more exact)
f0; 1; 2; : : : ; 9g. To consider every value in this set and do something meaningful with each of them,
we are using a for loop. To refer to each of these values and do something useful, we need a “dummy
variable” (above we chose to name it number). What we choose to do with each of the numbers is
part of the code that come in the indented line, under the for loop. In our example, we square each
number, and print it. Please note that the for statement ends with a colon “:”. That is part of the Sage
and Python syntax rule and therefore this is required.
Although the range() method is pretty common in Python, and we included it in our previous
example, throughout this book we will mostly use an easier approach. Please note that this second
approach works in Sage but not in Python. First we can create an array that contains the squares of
the 1-digit numbers. As in the previous example, here we use the same name for the dummy variable:
number. Then we simply print the array squares.
sage: squares = [number^2 for number in [0,1,..,9]]
sage: print squares
We obtain the following output
[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]
1.6.4
For Loop: Another Example
Example 14. Create Sage code that will print the prime factorization of all the integers strictly
between 2000 and 2030:
Solution. To consider the integers strictly between 2000 and 2030, we need to use range(2001, 2030).
Since we want to process each one of these integers, we’ll use a for loop. The process here is to print
each one of these numbers out as well as it’s prime factorization. Note how we separated by commas
the items we wanted to print in the second line of the Sage code below.
sage: for x in range(2001, 2030):
sage:
print x, "=", factor(x)
You should get an output similar to the one below.
2001 = 3 * 23 * 29
2002 = 2 * 7 * 11 * 13
2003 = 2003
2004 = 2^2 * 3 * 167

28
1
Fundamentals
2005 = 5 * 401
2006 = 2 * 17 * 59
2007 = 3^2 * 223
2008 = 2^3 * 251
2009 = 7^2 * 41
2010 = 2 * 3 * 5 * 67
2011 = 2011
2012 = 2^2 * 503
2013 = 3 * 11 * 61
2014 = 2 * 19 * 53
2015 = 5 * 13 * 31
2016 = 2^5 * 3^2 * 7
2017 = 2017
2018 = 2 * 1009
2019 = 3 * 673
2020 = 2^2 * 5 * 101
2021 = 43 * 47
2022 = 2 * 3 * 337
2023 = 7 * 17^2
2024 = 2^3 * 11 * 23
2025 = 3^4 * 5^2
2026 = 2 * 1013
2027 = 2027
2028 = 2^2 * 3 * 13^2
2029 = 2029
When outputting each of the factorization, we included the number, x, the equal symbol (hence we
used quotations), and the output of the factor method applied to x.
Note: whenever you want to output a text, you should include it between quotation marks (they are
called strings). For example, print 2C3 will output 5, while print “2C3” will output 2C3.
We can also obtain the same exact output using the following Sage code:
sage: for x in [2001,2002,..,2029]:
sage:
print x, "=", factor(x)
1.6.5
Conditional Statement
The operator % is called the modulus operator. The expression a%b gives the remainder of a upon
division by b.
For example a%2 gives the remainder of a upon division by 2. Hence a%2 is equal to 0 if and
only if a is an even number.
Another example c%7 gives the remainder of c upon division by 7. Hence c%7 is equal to 0 if
and only if c is a multiple of 7.
The next example will check if a number is even, and if so, it will print out the message "the
number is even". Otherwise, it will print out: "the number is odd". Please note the
colon that ends the line of code containing if and else.
sage: a = 7812
sage: if a%2 == 0:
sage:
print "the number is even"

1.6
Introduction to Sage Programming Through Examples
29
sage: else:
sage:
print "the number is odd"
The obtained output is:
the number is even
The if statement checks if the condition (in our example a%2==0) is true. If it is, then it will
execute the statement (or block of statements) that follows immediately after it, and is indented. If the
condition is false, then it will skip to the statement (or block of statements) that follow the else:
and is indented.
We can make the previous code more user friendly, by including the value of a into the output
message. For example, we could use the following Sage code:
sage: a = 7812
sage: if a%2 == 0:
sage:
print str(a) + " is even"
sage: else:
sage:
print str(a) + " is odd"
to obtain
7812 is even
In the previous code, we used the str function to change the number a into a string (text) so
we can then append it to the string “is even” or “is odd”. In Sage we can “add” (append) two
strings, such as "text1" + "text2", to obtain a concatenation of it: "text1text2".
If we plan to use this code multiple times, it would be nicer to create and use a function. Below we
deﬁne a function, isEven, and then we call it three times.
sage: def isEven(a):
sage:
if a%2 == 0:
sage:
print str(a) + " is even"
sage:
else:
sage:
print str(a) + " is odd"
sage: isEven(7812)
sage: isEven(2014)
sage: isEven(2015)
We obtain:
7812 is even
2014 is even
2015 is odd
1.6.6
More on Conditional Statements
Example 15. Create a function, called GetLetterGrade, that will return the corresponding letter
grade for a given score.
Solution. This is a very common example used in Introductory Programming courses to illustrate
the use of the conditional statements. The function should return “A”, for a score of at least 90, “B”
for scores at least 80 but less than 90, “C” for a score at least 70 but less than 80, and so on. Please

30
1
Fundamentals
note that in Sage, like in Python, but unlike C/CCC, Java, and many others, a string is a text that is
enclosed in either “ ” or in ’ ’. They are equivalent.
sage: def GetLetterGrade( score ):
sage:
if (score >= 90):
sage:
return ’A’
sage:
elif(score >= 80):
sage:
return ’B’
sage:
elif(score >= 70):
sage:
return ’C’
sage:
elif(score >= 60):
sage:
return ’D’
sage:
else:
sage:
return ’F’
sage: print ’a score of 87 will give you a/an:’, GetLetter
Grade(87)
a score of 87 will give you a/an: B
1.6.7
Working with Strings
A string is printed AS IS, without being evaluated. For example the code
sage: a = 7812
sage: b = 1082
sage: print "a+b"
will output:
a+b
and the previous Sage code is equivalent to
sage: a = 7812
sage: b = 1082
sage: print ’a+b’
a+b
If you wish to output the value of the expression a+b, you need to remove the quotation marks.
Therefore
sage: a = 7812
sage: b = 1082
sage: print a+b
will output:
8894
The character ’nt’ is a tab character, and it will be used in several examples throughout this
book to format the output. Other characters like this (which are all called escape characters) are:
’nn’ (for a new line) and ’nn’ (if you wish to output one backslash: n).
If you wish to create a more user-friendly output, you could use code as below, where we append
(“add”) several strings together for a nicer output.

1.6
Introduction to Sage Programming Through Examples
31
sage: a = 7812
sage: b = 1082
sage: print ’a+b = ’, a+b
to obtain:
a+b = 8894
Another alternative to the code given above, with a similar output, is:
sage: a = 7812
sage: b = 1082
sage: print ’a+b = ’+str(a+b)
In the last line, we used the str method to change the value of the number a+b into a string,
so we can append it to the string ’a+b = ’. We could not just add the number a+b to the string
’a+b=’.
1.6.8
Computing a Running Total
Example 16. Create Sage code that will compute the following sum
2015
X
iD7
1
i3
Solution. To compute a sum, we ﬁrst need a variable (a location where to store a value), let’s call it
answer, that is initialized to 0. Then, using a loop, we consider every number from the required range,
and add the expression
 1
i3 in our example

to our sum. At the end we report the total using a print
statement. We can report a decimal form, using the .n() method.
sage: answer = 0
sage: for i in range (7, 2015+1):
sage:
answer = answer + 1/(i^3)
sage: print answer.n(50)
to obtain:
0.011765113408142
An alternative to this code, with the same exact output is:
sage: answer = 0
sage: for i in [7,8,..,2015]:
sage:
answer = answer + 1/(i^3)
sage: print answer.n(50)
1.6.9
Counting
Example 17. Create Sage code that will count the number of primes less than 2015.

32
1
Fundamentals
Solution. For this example one could use a for loop, to consider all nonnegative integers less than
2015. Hence the line for i in range(2015). Then, using an if statement, we check if any i
from the given range is prime. For this, we write the code if(is_prime(i)==True). Please
note that this line is indented, since we want to use this line with every i from the for loop. Also note
that we use a colon at the end of this line, since this is an if statement. It is important to remember that
i order to compare if two values are the same, we use ==.
sage: num_of_primes = 0
sage: for i in range (2015):
sage:
if( is_prime(i) == True ):
sage:
num_of_primes
= num_of_primes + 1
sage: print "we have " , num_of_primes , " primes less than 2015"
We get the following output:
we have 305 primes less than 2015
This example is very similar with the previous example, in the sense that we are computing a sum.
Using a for loop, we are considering all nonnegative numbers less than 2015. Then, for each such
number we check to see whether it is prime or not. Each time we ﬁnd a prime number we add 1 to the
total sum. At the end, we report this total.
1.6.10
While Loops
Example 18. Create Sage code that will output the ﬁrst ten prime numbers that are larger than 2015.
Solution. For loops are great when we know a priori the number of times we need to repeat a
statement, or group of statements. Whether this number is a constant or given by a variable.
There are cases, however, when we need to repeat a group of statements without knowing for how
many times. We only know when we need to stop. In these cases, we will use an alternative to for
loops, called a while loop. While loops will repeatedly execute a group of statements until a given
expression (condition) becomes false.
In our example, we will start with the current_number set to 2016. Check whether it is prime
or not. Then check 2017, then check 2018, and so on. We need to do this until we have found ten prime
numbers. Since we don’t know exactly how many numbers we need to check until we have found our
tenth prime number, for loops are not suitable here. Therefore we’ll use a while loop. This loop
executes its body (all the statements that are indented/“inside” this loop) as long as the expression
primes_found<10 remains true. So as long as primes_found < 10, we need check if the
current_number is prime. If it is, then we increase the counter for the number of prime numbers
found, primes_found, and output it. Then, we increase the current_number by one, so we
can advance and check the next one.
sage: primes_found = 0
sage: #the first number to check is 2016
sage: current_number = 2015+1
sage: while(primes_found<10):
sage:
if(is_prime(current_number) == True):
sage:
#we found another prime. Count it in
sage:
primes_found=primes_found+1
sage:
#Print the prime number just found
sage:
print current_number

1.6
Introduction to Sage Programming Through Examples
33
sage:
#"move" current number to the next number
sage:
current_number=current_number+1
We ﬁnd:
2017
2027
2029
2039
2053
2063
2069
2081
2083
2087
How would you change the previous code to print out the smallest 20 prime numbers greater than
1,000,000?
1.6.11
Another Example on Writing Functions
Example 19. Using the previous example, create a function called print10primes that will print
the next ten primes greater than a value given as parameter, start. Then use this function to print the
next ten prime numbers greater than 1000, and then the next ten prime numbers greater than 23456.
Solution. We can use the Sage code below
sage: def print10primes(start):
sage:
primes_found = 0
sage:
number = start+1
sage:
while(primes_found<10):
sage:
if(is_prime(number) == True):
sage:
primes_found=primes_found+1
sage:
print number
sage:
number=number+1
sage: print10primes(1000)
sage: print "======="
sage: print10primes(23456)
to obtain
1009
1013
1019
1021
1031
1033
1039
1049
1051

34
1
Fundamentals
1061
=======
23459
23473
23497
23509
23531
23537
23539
23549
23557
23561
1.6.12
Nested Functions: Randomly Generated Numbers
Example 20. Create a function, called GenerateQuestion, that will randomly generate two
integers between 10 and 99, inclusively, and will output a basic algebra question. The question should
be constructed in such a way that it will randomly contain an addition, subtraction, multiplication, or
division. Then create another function GenerateTest that prints a set of six such basic algebra
questions. Then generate two such tests.
Solution. First, we need to write Sage code for a function GenerateQuestion. In order to be
able to generate random numbers, we need to import random library. Then calling the method
random.randint(10, 99) twice, this will generate two random numbers between 10 and 99.
After that, we randomly generate a number between 0 and 3 (using random.randint(0,3)) and
based on this number we choose a basic operation: addition, subtraction, multiplication, or division
and then print a question.
In the body of the GenerateTest method, we could use a for loop and call the newly created
function (also called method) GenerateQuestion() for six times.
We ﬁnish this program by calling the method GenerateTest() twice.
sage: import random
sage: def GenerateQuestion():
sage:
#randomly generate two numbers
sage:
number1 = random.randint(10,99)
sage:
number2 = random.randint(10,99)
sage:
#randomly choose an operation:
sage:
# 0 for +,
1 for -,
2 for
*, 3 for /
sage:
operation = random.randint(0, 3)
sage:
if(operation == 0):
sage:
print number1
, " + " , number2
,
" =?"
sage:
elif (operation == 1):
sage:
print number1
, " - " , number2
,
" =?"
sage:
sage:
elif (operation == 2):
sage:
print number1
, " * " , number2
,
" =?"
sage:
else:
sage:
print number1
, " / " , number2
,
" =?"
sage: def GenerateTest():

1.6
Introduction to Sage Programming Through Examples
35
sage:
for x in range(6):
sage:
GenerateQuestion()
sage: print "Generating Test 1:"
sage: print "------------------"
sage: GenerateTest()
sage: print "Generating Test 2:"
sage: print "------------------"
sage: GenerateTest()
The output of this code is shown next.
Generating Test 1:
------------
55 / 95 =?
26 + 11 =?
74 + 35 =?
17 * 19 =?
81 * 37 =?
88 + 97 =?
Generating Test 2:
------------
70 * 100 =?
45 / 100 =?
80 / 24 =?
58 / 33 =?
67 - 61 =?
10 - 56 =?
1.6.13
Working with Arrays
Example 21. The next several examples should demonstrate how one can use arrays in Sage/Python.
Solution. One-dimensional arrays
sage: #creates a simple array of values
sage: mylist = [1, 3, 5, 7]
sage: #computes and outputs the length of it
sage: len(mylist)
sage: #should display 4
sage: #creates a simple array of values
sage: mylist = [1, 3, 5, 7, 9, 11]
sage: #outputs the first element
sage: mylist[0]
sage: #outputs the second element
sage: mylist[1]
sage: #outputs the last element
sage: mylist[len(mylist)-1]
Two-dimensional arrays

36
1
Fundamentals
sage: #creates an array of pairs
sage: #
(for example, points in the plane)
sage: mylist = [(1,4),
(3,5),
(7, 11)]
sage: #computes and outputs the length of it
sage: len(mylist)
sage: #should display 3
sage: #outputs the first element of the array
sage: mylist[0]
sage: #should display (1,4)
sage: #outputs the third element of the array
sage: mylist[2]
sage: #should display (7, 11)
sage: #outputs the first coordinate of
sage: #
the third element in the array
sage: mylist[2][0]
sage: #should display 7
sage: #outputs the second coordinate of
sage: #
the third element in the array
sage: mylist[2][1]
sage: #should display
11
sage: #create an array of points
sage: myArray = [(x, 2^x) for x in [1, 2,..,6]]
sage: #display the array
sage: myArray
sage: #you should get:
[(1, 2), (2, 4), (3, 8), (4, 16), (5, 32), (6, 64)]
sage: #create arrays:
sage: myArray = range(9)
sage: #display the array
sage: myArray
sage: #you should get:
[0, 1, 2, 3, 4, 5, 6, 7, 8]
sage: #another way to create arrays:
sage: A = matrix(QQ, 2, 5, range(10))
sage: #display the array
sage: A
sage: #you should get:
[0 1 2 3 4]
[5 6 7 8 9]
Remark 22. Please note that in most of the Sage examples that follow we omitted to include the
optional “sage: ” from the beginning of each line to better display it in page.

1.7
Taylor Series
37
1.7
Taylor Series
Polynomials are some of the easiest and most commonly used class of functions that we encounter
in Mathematics. They can easily and efﬁciently be evaluated at every speciﬁc value and have very
nice properties: they are continuous everywhere, differentiable everywhere, and integrable on any
bounded interval. Finding the derivatives or antiderivatives of a polynomial are very easy tasks too.
Also, we can easily write computer programs that can evaluate a polynomial at any speciﬁc value: it
only involves the four basic arithmetic operators—addition, subtraction, multiplication, and division.
It is this and other very useful analytical properties (e.g., the Weierstrass Approximation Theorem
given next) that make polynomials a great choice in many approximation problems.
Most of the functions that do occur in Mathematics, however, do not have all those nice properties.
It is hard, if not impossible, to evaluate exactly functions like cos.x/, arctan.x/, ln.x/; ex,
5px, etc.
For example, how would you evaluate these functions, if you were not allowed to use any library or
built-in functions already created for you? Could you easily compute ln.1:01/, or say e0:1, or even
5p
3‹
In 1885, Karl Weierstrass [15] proved the famous Weierstrass Approximation Theorem (also known
by the name of The Fundamental Theorem of Approximation) which, in a simpliﬁed form, states that
any continuous function on a closed and bounded interval can be uniformly approximated on that
interval by polynomials to any degree of accuracy. This powerful statement gives Numerical Analysis
a very strong foundation.
A next step, knowing it is possible to approximate a continuous function by a polynomial, would
be to ﬁnd/construct such a polynomial. Given a function f .x/, we would like to ﬁnd some polynomial
T .x/ so that we can easily approximate f .a/ by computing T .a/ and the error of approximation is
small enough.
Perhaps the most widely used polynomial approximation are the Taylor polynomials, which
students should have already encounter in their study of Calculus (see [13] for a review of Calculus).
Without going into all the details about all the conditions that are needed to be satisﬁed (they will be
described further down in this Chapter!), let us be reminded the following formulae:
Tn.x/ D
n
X
kD0
f .k/.c/
kŠ
.x  c/k
(1.2)
is called the nth order Taylor polynomial, and
T .x/ D
1
X
kD0
f .k/.c/
kŠ
.x  c/k
(1.3)
is called the Taylor series, for the function f at x, around c.
In particular (see [1, 9]), some familiar examples of Taylor series (again, we are anticipating the D
sign included in the next formulae!)
cos.x/ D 1  x2
2Š C x4
4Š  x6
6Š C x8
8Š    
(1.4)
D
1
X
kD0
.1/k x2k
.2k/Š;
for  1 < x < 1:
(1.5)
arctan.x/ D 1  x3
3 C x5
5  x7
7 C x9
9    
(1.6)

38
1
Fundamentals
D
1
X
kD0
.1/k x2kC1
2k C 1;
for  1  x  1:
(1.7)
ln.1 C x/ D 1  x2
2 C x3
3  x4
4 C x5
5    
(1.8)
D
1
X
kD1
.1/kC1 xk
k ;
for  1 < x  1:
(1.9)
ex D 1 C x C x2
2Š C x3
3Š C x4
4Š C x5
5Š C   
(1.10)
D
1
X
kD0
xk
kŠ ;
for  1 < x < 1:
(1.11)
1
1  x D 1 C x C x2 C x3 C x4 C x5 C   
(1.12)
D
1
X
kD0
xk;
for  1 < x < 1:
(1.13)
Remark 23. The Taylor series around c D 0 are also called Maclaurin Series. All of the above
examples are Maclaurin Series.
For the purpose of approximation, we could, intuitively for now, approximate f .x/ D ex by the
Taylor polynomial T4.x/ D 1Cx C x2
2Š C x3
3Š C x4
4Š and hence e0:1 could be approximated by T4.0:1/ D
1 C 0:1 C 0:12
2Š C 0:13
3Š C 0:14
4Š  1:10517091. Therefore one could say e0:1 D
10pe  1:10517091. The
error we committed by this approximation is less that
1
108 but we’ll see later in this chapter how one
can estimate the error of approximation. For now, we’ll use a rather intuitive approach.
All those formulae can be derived using (1.3). Similarly, for the partial sum, one could use (1.3).
But one can also use Sage to get the previous formulae (the partial sums only!). For this we’ll use the
code like f.x/:taylor.x; c; n/, where f .x/ is the function under consideration, x is the variable
of the function, c is the point around which the Taylor series are developed, with n being the degree
up to which the terms from the Taylor series are displayed.
For example, cos.x/:taylor.x; 0; 5/ will display the Taylor polynomial of degree at most 5, around
c D 0, for the function cos.x/.
var(’x’)
print "cos(x) = " , cos(x).taylor(x, 0, 5)
print "arctan(x) = " , arctan(x).taylor(x, 0, 5)
print "ln(x) = " , ln(x).taylor(x, 0, 5)
print "e^x = " , (e^x).taylor(x, 0, 5)
print "1/(1-x) = " , (1/(1-x)).taylor(x, 0, 5)

1.7
Taylor Series
39
we obtain the following:
cos(x) = 1/24*x^4 - 1/2*x^2 + 1
arctan(x) = 1/5*x^5 - 1/3*x^3 + x
ln(x) = log(x)
e^x = 1/120*x^5 + 1/24*x^4 + 1/6*x^3 + 1/2*x^2 + x + 1
1/(1-x) = x^5 + x^4 + x^3 + x^2 + x + 1
Example 24. Use the ﬁrst few (up to degree ﬁve) terms of the Taylor series approximate the value of
the function ex at x D 0:5. That is, approximate pe:
Solution. Using the formula (1.10) we obtain the following approximation:
ex  1 C x C x2
2 C x3
3Š C x4
4Š C x5
5Š :
(1.14)
Therefore we obtain
e0:5  1 C 0:5 C 0:52
2
C 0:53
3Š C 0:54
4Š C 0:55
5Š
(1.15)
 1:64869791666667
(1.16)
which is accurate to four decimal places. The symbol  means approximately equal.
If we want to use Sage, we could use the following Sage code:
var(’x’)
f(x)=e^x
T5(x)=(e^x).taylor(x, 0, 5)
print T5(0.5)
#we used
print T5(x)
to output the Taylor polynomial
to get the same result:
1.64869791666667
Next we give an algorithm in Sage that will create a table of values that can be used to compare
partial sums up to degree nine (rather than ﬁve, as requested by the problem) against the “true” value.
Please note that the “true” value is itself an approximation, one in which we expect the error to be
small (and which is truncated to the default number of digits!). First we declare the variable x and we
deﬁne the function f that we’ll use in this example. In the third line of code we print the ﬁrst line of
the table. Please note that strings need to be enclosed in double quotation marks. The “nt” is a special
string and it will print a tab space, so the results are nicely aligned. Then, instead of using a statement
for each partial sum requested, we are using a for loop. Hence in a for loop we are requesting Sage to
compute the Taylor’s partial sum of degree i (x is the variable, 0 is the point about which the Taylor’s
series is computed, and i is the power of this partial sum), and print the line number, the obtained
approximation and the “true” value.
var(’x’)
f(x) = e^x
print "#", "\tUsing Taylor Approx",
"\tTrue Value"
for i in range(1, 9+1):
partial(x)=f(x).taylor(x, 0, i)
print
i, "\t", partial(0.5), "\t", f(0.5)

40
1
Fundamentals
will generate the output:
#
Using Taylor Approx
True Value
1
1.50000000000000
1.64872127070013
2
1.62500000000000
1.64872127070013
3
1.64583333333333
1.64872127070013
4
1.64843750000000
1.64872127070013
5
1.64869791666667
1.64872127070013
6
1.64871961805556
1.64872127070013
7
1.64872116815476
1.64872127070013
8
1.64872126503596
1.64872127070013
9
1.64872127041825
1.64872127070013
From this table we can easily see that using merely 4–5 terms from the Taylor series, we get quite
a good approximation (although, of course, “quite good” is a relative expression).
While the previous example worked quite well, the next example shows why we need to be careful
with the intuition, and follow a more Mathematical approach. It is very important that we know the
conditions that need to be satisﬁed in order to guarantee that such an approach works. Just because an
intuitive approach worked in one example it doesn’t imply it will always work, for every example.
Example 25. Using the ﬁrst few (up to degree ﬁve) terms of the Taylor series approximate the value
of the function ex at x D 10. That is, approximate e10.
Solution. Using (1.14) we obtain:
e10  1 C 10 C 102
2 C 103
3Š C 104
4Š C 105
5Š
(1.17)
 1477:66666667
(1.18)
which is quite far from the more accurate value of 22026:4657948067.
For a better view of what’s going on, we could use the following Sage code in order to create a
table of values using partial sums up to degree twenty:
var(’x’)
f(x) = e^x
print "#", "\tUsing Taylor Approx",
"\tTrue Value"
for i in range(1, 20+1):
partial(x)=f(x).taylor(x, 0, i)
print
i, "\t", partial(10.0), "\t", f(10.0)
We obtain:
#
Using Taylor Approx
True Value
1
11.0000000000000
22026.4657948067
2
61.0000000000000
22026.4657948067
3
227.666666666667
22026.4657948067
4
644.333333333333
22026.4657948067
5
1477.66666666667
22026.4657948067
6
2866.55555555556
22026.4657948067
7
4850.68253968254
22026.4657948067
8
7330.84126984127
22026.4657948067
9
10086.5731922399
22026.4657948067
10
12842.3051146384
22026.4657948067

1.7
Taylor Series
41
11
15347.5159531826
22026.4657948067
12
17435.1916519694
22026.4657948067
13
19041.0960356516
22026.4657948067
14
20188.1705954246
22026.4657948067
15
20952.8869686065
22026.4657948067
16
21430.8347018453
22026.4657948067
17
21711.9804272798
22026.4657948067
18
21868.1724969657
22026.4657948067
19
21950.3788494319
22026.4657948067
20
21991.4820256651
22026.4657948067
From this table we can easily see that we need more than just a few terms from Taylor series in
order to get a good enough approximation. We should also note that the point x D 10 is further away
from c D 0 than x D 0:5, which may indicate that further away points from x D c would usually
yield less accurate results. This is actually a true statement as we will see later in this chapter.
Remark 26. Taylor’s series will converge much faster (to the true value) near the point of
expansion and slower (if at all) at more remote points. This result is a direct consequence of the
Taylor’s Theorem with Remainder (given on page 48).
Following the expression “a picture is worth a thousand words” it may be worth seeing the graphs
of Taylor polynomials compared to the true function. Let’s graph, below, the function f .x/ D ex,
along with few partial sums of the Taylor series for f , about the point c D 0. For this we can write
the following Sage code
x = var(’x’)
f(x) = e^x
#this is the function we’ll use
#the original plot, for x in [-1.6]
p=plot(f(x),-1,6, color= ’black’, linestyle=’--’,
legend_label=’f(x)’)
#plot for one partial sum - of degree 1
g1(x) = f(x).taylor(x, 0, 1)
p1=plot(g1(x),-1,6, color= ’red’, legend_label=’dgr 1’)
#plot for one partial sum - of degree 4
g4(x) = f(x).taylor(x, 0, 4)
p4=plot(g4(x),-1,6, color= ’green’, legend_label=’dgr 4’)
#plot for one partial sum - of degree 5
g5(x) = f(x).taylor(x, 0, 5)
p5=plot(g5(x),-1,6, color= ’brown’, legend_label=’dgr 5’)
#plot for one partial sum - of degree 7
g7(x) = f(x).taylor(x, 0, 7)
p7=plot(g7(x),-1,6, color= ’blue’, legend_label=’dgr 7’)
#graph all the plots together
show(p+p1+p4+p5+p7)

42
1
Fundamentals
Above, q1.x/; q2.x/; : : : ; q7.x/, are the partial sums from the Taylor polynomial expansion of the
function f .x/ D ex, around c D 0, of degrees 1, 4, 5, and 7 respectively. Then, p; p1; p4; p5, and
p7, are the plots (graphs) for each of these functions, graphed in the interval Œ1; 6. To show all these
plots together in one graph, we use the command: show(pCp1Cp4Cp5Cp7).
This code will produce the following graph.
Please note, from the graph, that:
– the partial sums graph become less accurate (further away from f .x/) for points that are further
away from c D 0.
– for any given point, usually, the higher the degree of the partial sum, the more accurate it gets (the
closer it gets to the original function).
Another (similar) example would be for the function f .x/ D arctan.x/. Using the following Sage
code we obtain the graph:
x = var(’x’)
f(x) = arctan(x) #this is the function we’ll use
#the original plot
p=plot(f(x),-pi/2,pi/2, color= ’black’, linestyle=’--’,
legend_label=’f(x)’)
#plot for one partial sum - of degree 1
g1(x) = f(x).taylor(x, 0, 1)
p1=plot(g1(x),-pi/2,pi/2, color= ’red’, legend_label=’dgr 1’)
#plot for one partial sum - of degree 5
g5(x) = f(x).taylor(x, 0, 5)
p5=plot(g5(x),-pi/2,pi/2, color= ’brown’, legend_label=’dgr 5’)
#plot for one partial sum - of degree 7

1.7
Taylor Series
43
g7(x) = f(x).taylor(x, 0, 7)
p7=plot(g7(x),-pi/2,pi/2, color= ’blue’, legend_label=’dgr 7’)
#graph all the plots together
show(p+p1+p5+p7)
We observe again that for points close to c D 0, the partial sums from the Taylor series are
providing quite good estimates. For more remote points, however, this does not hold anymore.
Changing the value of c from the previous example to c D 1, we obtain the following graph:

44
1
Fundamentals
x = var(’x’)
f(x) = arctan(x) #this is the function we’ll use
#the original plot
p=plot(f(x),-pi/2,pi/2, color= ’black’, linestyle=’--’,
legend_label=’f(x)’)
#plot for one partial sum - of degree 1
g1(x) = f(x).taylor(x, 1, 1)
p1=plot(g1(x),-pi/2,pi/2, color= ’red’, legend_label=’dgr 1’)
#plot for one partial sum - of degree 5
g5(x) = f(x).taylor(x, 1, 5)
p5=plot(g5(x),-pi/2,pi/2, color= ’brown’, legend_label=’dgr 5’)
#plot for one partial sum - of degree 7
g7(x) = f(x).taylor(x, 1, 7)
p7=plot(g7(x),-pi/2,pi/2, color= ’blue’, legend_label=’dgr 7’)
#graph all the plots together
show(p+p1+p5+p7)
Notice that in this case the partial sums of the Taylor series provide results that are more accurate
for values of x that are closer to 1, rather than values close to 0.
Below, we give the Sage code that will provide Sage interacts that can be used for an interactive
visualization of the graphs seen above.
x = var(’x’)
f(x) = arctan(x) #this is the function we’ll use
@interact
def echo_input(c = slider(vmin=-2, vmax=2,
step_size=0.5, default=0,
label="Select a value for c: "),
n = slider(vmin=1, vmax=10,
step_size=1, default=5,
label="Select a value for n: ")):
print "We output the function f(x)\
with it’s Taylor sum approximation"
#the original plot
p1=plot(f(x),-pi/2,pi/2,
color= ’black’,
linestyle=’--’,
legend_label=’f(x)’)
#compute the Taylor sum of degree n
taylorN(x) = f(x).taylor(x, c, n)
p2=plot(taylorN(x),-pi/2,pi/2,
color= ’blue’,
legend_label="taylor"+str(n))
(p1+p2).show()
and obtain:

1.7
Taylor Series
45
2
1
–1
–2
–1.5
0.5
–0.5
–1
1
1.5
Select a
Select a
value for c:
value for n:
5
0.000000000000000
f(x)
taylor5
We output the function f (x) with it ’ s Taylor sum approximation
Please feel free to try this code and move the two sliders to select different values of x and c.
–1.5
0.5
0.5
–0.5
–0.5
–1
–1
1
1
1.5
Select a
Select a
value for c:
value for n:
2
1.50000000000000
f(x)
taylor2
We output the function f (x) with it ’ s Taylor sum approximation
It’s time now to see the Mathematical reasoning behind Taylor series and the conditions that need
to be satisﬁed in order for us to get a “good” approximation.
Let’s start with a deﬁnition. As mentioned above, the general formula for the Taylor series for a
function f , about the point c is given by

46
1
Fundamentals
T .x/ D f .c/ C f 0.c/.x  c/ C f 00.c/
2Š
.x  c/2 C    C f .n/.c/
nŠ
.x  c/n C   
D
1
X
kD0
f .k/.c/
kŠ
.x  c/k;
(1.19)
provided that f , f 0, f 00, f 000, f .4/, : : : all exist at the point c.
Example 27. Find the ﬁrst ﬁve partial sums of the Taylor series for the function f .x/ D ln.x/ around
c D 1. Then use them to (intuitively) approximate value for ln.1:2/.
Solution. Using (1.19) we obtain:
f .x/ D ln.x/ H) f .1/ D ln.1/ D 0
f 0.x/ D 1
x H) f 0.1/ D 1
f 00.x/ D  1
x2 H) f 00.1/ D 1
f 000.x/ D 2
x3 H) f 000.1/ D 2
f .4/.x/ D  6
x4 H) f .4/.1/ D 6
Hence
ln.1:2/  T0.1:2/
(1.20)
D f .1/ D 0
ln.1:2/  T1.1:2/
(1.21)
D f .1/ C f 0.1/.1:2  1/ D 0:2
ln.1:2/  T2.1:2/
(1.22)
D f .1/ C f 0.1/.1:2  1/ C f 00.1/
2Š
.1:2  1/2 D 0:18
ln.1:2/  T3.1:2/
(1.23)
D f .1/ C f 0.1/.1:2  1/ C f 00.1/
2Š
.1:2  1/2 C f 000.1/
3Š
.1:2  1/3
' 0:1826666667
ln.1:2/  T4.1:2/
(1.24)
D f .1/ C f 0.1/.1:2  1/ C f 00.1/
2Š
.1:2  1/2

1.7
Taylor Series
47
Cf 000.1/
3Š
.1:2  1/3 C f .4/.1/
4Š
.1:2  1/4
' 0:1822666667
The last answer is correct to three decimal places.
Using the following Sage code:
var(’x’)
f(x) = ln(x)
c
= 1
T0(x) =
f(x).taylor(x, c, 0)
print T0(1.2), " from " , T0(x)
T1(x) =
f(x).taylor(x, c, 1)
print T1(1.2), " from " , T1(x)
T2(x) =
f(x).taylor(x, c, 2)
print T2(1.2), " from " , T2(x)
T3(x) =
f(x).taylor(x, c, 3)
print T3(1.2), " from " , T3(x)
T4(x) =
f(x).taylor(x, c, 4)
print T4(1.2), " from " , T4(x)
we get similar results:
0 from 0
0.200000000000000 from x - 1
0.180000000000000 from -1/2*(x - 1)^2 + x - 1
0.182666666666667 from 1/3*(x - 1)^3 - 1/2*(x - 1)^2 + x - 1
0.182266666666667 from -1/4*(x - 1)^4 + 1/3*(x - 1)^3 - 1/2*(x -
1)^2 + x - 1
Note: loops are smarter! The same exact output could be achieved using the following alternative
code:
var(’x’)
f(x) = ln(x)
c = 1
for i in range(5):
T(x)=f(x).taylor(x, c, i)
print T(1.2), " from " , T(x)
Using the Sage interact:
var(’x’)
f(x) = ln(x)
c = 1
@interact
def echo_input(i = slider(vmin=0, vmax=5,
step_size=1, default=2,

48
1
Fundamentals
label="Select a value for n: ")):
T = f(x).taylor(x, c, i)
print T(1.2) , " is obtained from " , T(x)
one can obtain the following interactive representation:
Moving the slider to the left or right, one can obtain all the values shown above.
In the previous examples we used partial sums of the Taylor series for a function f .x/ to
approximate the value of that function, at a given value of x. When can we say that f .x/ is the
same or approximately the same as T .x/‹ And how large will the error be when we approximate
f .x/ by T .x/? The answers to these questions are given in the next theorem:
Theorem 28 (Taylor’s Theorem with Remainder). If the function f is continuous and has
continuous derivatives of order 1, 2, . . . , (nC1) in some closed interval Œa; b, then for any x and
c from Œa; b we have that
f .x/ D
n
X
kD0
f .k/.c/
kŠ
.x  c/k C En.x/
(1.25)
where the error term En given by:
En.x/ D f .nC1/./
.n C 1/Š .x  c/nC1;
for some  between c and x.
It is important to note that  depends on both values of c and x.
The polynomial
Tn.x/ D
n
X
kD0
f .k/.c/
kŠ
.x  c/k
(1.26)

1.7
Taylor Series
49
is called the nth order Taylor polynomial. With this notation, the formula (1.25) becomes f .x/ D
Tn.x/ C En.x/.
Proof. Let x; c from Œa; b be ﬁxed. The case x D c is trivial (since it reduces to f .x/ D f .c/). So
let’s assume that x ¤ c.
There must be a K, depending on x such that
f .x/ D Tn.x/ C
K
.n C 1/Š.x  c/nC1
D
n
X
kD0
f .k/.c/
kŠ
.x  c/k C
K
.n C 1/Š.x  c/nC1:
In order to prove the theorem, it remains to show that K D f .nC1/./, for some  between c and x.
Let’s deﬁne the helper function
H.t/ D f .x/ 
n
X
kD0
f .k/.t/
kŠ
.x  t/k 
K
.n C 1/Š.x  t/nC1
with t between c and x inclusively.
Since f .t/; f 0.t/; : : : ; f .n/.t/ are all continuous we conclude that H is continuous on its domain.
Since f has continuous derivatives of order 1, 2, . . . , (nC1) we conclude that also H is
differentiable and we have that
H 0.t/ D 
n
X
kD0
f .kC1/.t/
kŠ
.x  t/k C
n
X
kD1
f .k/.t/
.k  1/Š.x  t/k1 C K
nŠ.x  t/n
D f .nC1/.t/
nŠ
.x  t/n C K
nŠ.x  t/n
Furthermore, we have that H.c/ D H.x/ D 0.
Then, applying Rolle’s Theorem, there must some  strictly between c and x such that H 0./ D 0.
This implies that for some  strictly between c and x we have that
H 0./ D 0:
Hence,
f .nC1/./
nŠ
.x  /n C K
nŠ.x  /n D 0
and since x   ¤ 0 we obtain
K D f .nC1/./:

The following examples are direct applications of Taylor’s Theorem with Remainder:
Example 29. Prove formula (1.10), that is prove: ex D
1
X
kD0
xk
kŠ , for 1 < x < 1.

50
1
Fundamentals
Solution. Let f .x/ D ex, and c D 0. Let’s consider x from some interval Œa; b. Then we have that
f .k/.x/ D ex, for k D 1; 2; : : : ; n; n C 1. Since all the conditions needed in Taylor’s Theorem with
Remainder are satisﬁed, we can apply it and get
f .x/ D
n
X
kD0
e0
kŠ.x  0/k C En.x/
(1.27)
D
n
X
kD0
xk
kŠ C En.x/
where En.x/ D
e
.nC1/ŠxnC1. Since
0  jEn.x/j D
ˇˇˇˇ
e
.n C 1/ŠxnC1
ˇˇˇˇ 
eb
.n C 1/Š jxjnC1 ! 0; as n ! 1;
we obtain that En.x/ ! 0, as n ! 1. If we take limit as n ! 1 on both sides of (1.27) we obtain
formula (1.10). 
Example 30. Let’s assume we want to use the following approximation
ex  T5.x/ D 1 C x C x2
2Š C x3
3Š C x4
4Š C x5
5Š ; for x in Œ1; 1:
Find an upper bound (worst case scenario) for the error resulted from this approximation.
Solution. Using Taylor’s Theorem with Remainder, with f .x/ D ex, and c D 0 we obtain
0  jE5.x/j D
ˇˇˇˇ
e
6Š x6
ˇˇˇˇ  e
6Š  1 < 0:004

Example 31. Let’s assume we want to use the following approximation
ex  T10.x/ D 1 C x C x2
2Š C x3
3Š C x4
4Š C x5
5Š
Cx6
6Š C x7
7Š C x8
8Š C x9
9Š C x10
10Š; for x in Œ1; 1:
Find an upper bound (worst case scenario) for the error resulted from this approximation.
Solution. Using Taylor’s Theorem with Remainder, with f .x/ D ex, and c D 0 we obtain
0  jE10.x/j D
ˇˇˇˇ
e
11Šx11
ˇˇˇˇ 
e
11Š  1 < :00000007:

Example 32. Find a polynomial that approximates ex on the interval Œ1; 1 with an error no greater
than 105, for any x in Œ1; 1.

1.7
Taylor Series
51
Solution. Using Taylor’s Theorem with Remainder, with f .x/ D ex, and c D 0 we obtain
jEn.x/j D
ˇˇˇˇ
e
.n C 1/ŠxnC1
ˇˇˇˇ 
e
.n C 1/Š  105:
This implies that n  8. Hence we would use the following approximation
ex  1 C x C x2
2Š C x3
3Š C x4
4Š C x5
5Š C x6
6Š C x7
7Š C x8
8Š :

Example 33. Produce linear and quadratic Taylor polynomial approximations for f .x/ D ln x, in the
interval Œ0:3; 1:7. Graph the function and its polynomial approximations.
Solution. Using Taylor’s Theorem with Remainder, with f .x/ D ln x, and c D 1 we obtain
T1.x/ D 0 C 1  .x  1/
D x  1
T2.x/ D 0 C 1  .x  1/ C 1
2 .x  1/2
D 0:5x2 C 2x  1:5:
We can obtain the same results using Sage. Below you can ﬁnd the graph as well as the Sage code:

#this part of the code computes the Taylor polynomials
var(’x’)
f(x) = ln(x)

52
1
Fundamentals
c
= 1
T1(x) =
f(x).taylor(x, c, 1)
T2(x) =
f(x).taylor(x, c, 2)
T1(x), T2(x).full_simplify()
to obtain
(x - 1, -1/2*x^2 + 2*x - 3/2)
#next part of the code will generate the graph
p=plot(f(x),0.3,1.7, color= ’black’, linestyle=’--’,
legend_label=’f(x)’)
p1=plot(T1(x), 0.3,1.7, color = ’red’, legend_label=’T1’)
p2=plot(T2(x), 0.3,1.7, color = ’green’, legend_label=’T2’)
show(p+p1+p2)
We can also obtain the previous results using Sage interacts:
var(’x’)
f(x) = ln(x)
c = 1
@interact
def echo_input(i = slider(vmin=0, vmax=5,
step_size=1, default=2,
label="Select a value for n: ")):
print "T(x) = " , (f(x).taylor(x, c, i)).full_simplify()
for:
and
var(’x’)
f(x) = ln(x)
c = 1
@interact
def echo_input(i = slider(vmin=0, vmax=5,
step_size=1, default=2,
label="Select a value for n: ")):
print "T(x) = " , (f(x).taylor(x, c, i)).full_simplify()
p=plot(f(x),0.3,1.7, color= ’black’, linestyle=’--’,
legend_label=’f(x)’)
T1(x) =
f(x).taylor(x, c, i)

1.7
Taylor Series
53
T=plot(T1(x), 0.3,1.7, color = ’red’, legend_label=’T’)
show(p+T)
for:
An important application of Taylor’s Theorem with Remainder is the Mean Value Theorem, which
is obtained when we let n D 0:
Theorem 34 (Mean-Value Theorem). If the function f is continuous in some closed interval Œa; b,
and differentiable on .a; b/ then
f .b/ D f .a/ C f 0./.b  a/
(1.28)
for some  in .a; b/.
This theorem can be used when we want to obtain an approximation for the value of f 0.x/, with x
in .a; b/. We could use that
f 0.x/  f .b/  f .a/
b  a
; for any x in .a; b/:
And this value is exact for at least one value, , in .a; b/.
Of course, the smaller the interval .a; b/ is, the more accurate answers we expect to get for f 0.x/.
This should not be surprising, given the deﬁnition of f 0.x/.
Taylor’s Theorem is frequently written in the following equivalent form (by changing x into x Ch,
and c into x):

54
1
Fundamentals
Theorem 35 (Taylor’s Theorem with Remainder (2)). If the function f is continuous and has
continuous derivatives of order 1, 2, . . . , (nC1) in some closed interval Œa; b, then for any x and
x C h from Œa; b we have that
f .x C h/ D
n
X
kD0
f .k/.x/
kŠ
hk C En.x C h/
(1.29)
where the error term En given by:
En.x C h/ D f .nC1/./
.n C 1/Š hnC1;
(1.30)
for some  between x and x C h.
The nth order Taylor polynomial can be rewritten as:
Tn.x C h/ D
n
X
kD0
f .k/.x/
kŠ
hk:
(1.31)
Instead of using values of c that are close to x, in the new form one could use values of h that
are close to 0, which may be more intuitive in some applications (although they are equivalent!). In
many applications, this form provides a much more convenient notation. We will use this form quite
frequently throughout this book.
We can easily see, from formula (1.30), that as h ! 0, so does the error term, En ! 0. But this is
just a part of the information given by that formula. That formula says so much more than that. It also
gives us information about the rate of convergence. It tells us how fast it converges to 0. It gives us
the “speed”, the “rapidity” with which the error term approaches 0, as h ! 0.
For this, we introduce the following deﬁnition of the big O notation.
Deﬁnition 36 (Big O Notation). We say that a quantity
E D O.hn/;
(1.32)
(read it as: “E is big Oh hn”) if you can ﬁnd some constant C, independent of h, such that, for all
small enough values of jhj
jEj  C  hn:
(1.33)
From this deﬁnition, it follows that E; E
h ; E
h2 ; : : :,
E
hn1 ! 0, as h ! 0. It also tells us that E ! 0
at least as fast as hn ! 0. This deﬁnition is very handy when we do error estimation.
Using Taylor’s Theorem and the Big O Notation we have
f .x C h/ D f .x/ C f 0./h
D f .x/ C O.h/
f .x C h/ D f .x/ C f 0.x/h C f 00./
2Š
h2
D f .x/ C f 0.x/h C O.h2/

1.7
Taylor Series
55
f .x C h/ D f .x/ C f 0.x/h C f 00.x/
2Š
h2 C f 000./
3Š
h3
D f .x/ C f 0.x/h C f 00.x/
2Š
h2 C O.h3/
We can see how Big O Notation simpliﬁes our notation, without giving up the essential part, the
rate of convergence.
Using this notation and (1.30) we have
En D O.hnC1/:
(1.34)
A simpliﬁed notation for O.hn/ that is being used in some textbooks is O.n/. We consider this
notation somewhat misleading and therefore we will try avoiding it throughout this book.
Both notations imply that as you decrease h into half, the quantity (usually the error) that is O.hn/
will get decreased by a factor of 2n. If you decrease h by a factor of 10, then the quantity will be
decreased by a factor of 10n.
Example 37. Expand ln.1 C h/ into powers of h. Then compute ln.1:00001/. Estimate the maximum
error involved from using a third order Taylor polynomial.
Solution. Let f .x/ D ln.x/. Then we have that f 0.x/ D 1=x, f 00.x/ D 1=x2, f 000.x/ D 2=x3,
f .4/.x/ D 6=x4. Using
f .x C h/ D f .x/ C f 0.x/h C f 00.x/
2Š
h2 C f 000.x/
3Š
h3 C f .4/./
4Š
h4
we get
ln.1 C h/ D 0 C 1  h  1
2Šh2 C 2
3Šh3 
6
4Š4 h4
D h  h2
2 C h3
3  h4
44 ;
with  unknown, between 1 and 1 C h.
If we let h D 0:00001, we obtain that
ln.1:00001/  0:00001  0:000012
2
C 0:000013
3
D 0:000009999950000333333333 : : : ::
and for h D 0:00001, we obtain that
ln.0:99999/  0:00001  0:000012
2
 0:000013
3
D 0:0000100000500000000:
In the ﬁrst case, the error cannot exceed:
ˇˇˇˇ
h4
44
ˇˇˇˇ D
ˇˇˇˇ
0:000014
44
ˇˇˇˇ

56
1
Fundamentals
<
ˇˇˇˇ
0:000014
4
ˇˇˇˇ
D 0:00000 00000 00000 00000 25:
D 2:5  1021
Hence, our approximation should be correct to at least 20 decimal places.
A quick check on Sage seems to disagree with this:
sage: ln(1.00001)-0.000009999950000333333333
It displays
6.55078340747531e-17
This is because of the default rounding used by Sage.
But the following code:
sage: ln(1.00001.n(500))-0.000009999950000333333333
displays a more accurate answer:
-2.49891263052269661e-21

1.8
Alternating Series
We recall from Calculus that a series
1
X
kD0
ak D a0 C a1 C    C an C   
is convergent to some value V if the sequence of partial sums fSngn; where
Sn D
n
X
kD0
ak D a0 C a1 C    C an
converges to V . That is, if
lim
n!1 Sn D V:
Theorem 38 (Alternating Series Theorem). If a0  a1  a2      an      0 and an ! 0, as
n ! 0 then the following alternating series
1
X
kD0
.1/kak D a0  a1 C a2  a3 C   
(1.35)
converges. Let V WD
1
X
kD0
.1/kak. Then we have the following error estimation:
jV  Snj  anC1:
(1.36)

1.8
Alternating Series
57
That means that if we sum only terms up to an, and omit all the remaining terms, then the error of
approximation is at most as large as anC1.
Example 39. How many terms are needed if we want to compute cos.1/ with an error strictly less
that 106.
Solution. From (1.4) we have that
cos.1/ D 1  1
2Š C 1
4Š  1
6Š C 1
8Š    
If we stop at the term
1
.2n/Š, then the error will be at most
1
.2nC2/Š. Solving the problem means solving
the following inequality
1
.2n C 2/Š < 106:
We can solve this problem either by trying several values for n, until the previous inequality is
satisﬁed, or using the Sage code below. There are other Mathematical ways to solve this inequality
but having Sage available, we decided use a very simple method to solve it. In either case, we should
get that n D 4 is the smallest positive integer value that satisﬁes our inequality, and conclude that
cos.1/  1  1
2Š C 1
4Š  1
6Š C 1
8Š
with an error less that 106. The error is actually at most
1
10Š which is less than 2:756  107.
The Sage code below starts with n D 1, and keep increasing n as long as the previous inequality is
not yet satisﬁed. Once we ﬁnd a satisfying n, we stop and print it. 
n=1;
#we start with n=1
#then try all values until our inequality is satisfied
while (1/factorial(2*n+2) >= 10^-6 ):
n = n+1
print n;
Example 40. How many terms are needed if we want to compute arctan.1/ with an error strictly less
that 106.
Solution. From (1.6) we have that
cos.1/ D 1  1
3 C 1
5  1
7 C 1
9    
If we stop at the term
1
2nC1, then the error will be at most
1
2nC3. Solving the problem means solving
the following inequality
1
2n C 3 < 106:
Hence
2n C 3 > 1; 000; 000

58
1
Fundamentals
or
n > 499998:5:
Therefore we need to include the term with n D 499; 999 (which is 500,000th term) if we need to
approximate arctan 1 with an error less than 106: 
1.9
Sage Interacts
A very useful tool that we did not fully explore in this book is “Sage interact” (also called Sage
Interactions).
The following Sage code will create a Sage interact for computing and graphing Taylor polynomi-
als of degrees up to 10. The order can be chosen using a slider. We prepared a slider that can take any
value between 1 and 10, inclusively. Then, it will compute, display, and graph the original function,
as well as the corresponding Taylor polynomial, or the order selected by the user.
html(’<h2>Taylor Polynomials using Sage Interactions</h2>’)
#select the interval [a,b]
a = -3
b =
3
@interact
#default function is sin(x)
#order:
interval=[1,10], step = 1, default = 3
def taylor_through_sage_interaction(f = input_box(default=sin(x)),
order = slider(1,10,1,3) ):
var(’x’)
#compute the taylor polynomial of order given by the slider
taylor_pol(x) =f.taylor(x,0, order )
#plot the taylor polynomial
p = plot( taylor_pol(x) , (x, a, b), color = ’red’ )
#plot the original function
p+= plot( f , (x, a, b), color = ’blue’ )
print ’Taylor polynomial = ’ + str(taylor_pol(x))
show(p)
The output should look similar to:

1.9
Sage Interacts
59
1.5
1
0.5
–0.5
–1
–1.5
–3
–2
–1
1
2
3
order
f
sin (x)
3
Taylor polynomial = –1/6*xˆ3 + x
Turning the slider to the value 6, we obtain
–3
–2
–1
1
2
3
1
0.5
–0.5
–1
order
f
sin (x)
6
Taylor polynomial = 1/120*xˆ5 – 1/6*xˆ3 + x

60
1
Fundamentals
Changing the function f to sin.x/ C ecos.x/, and the order to 4, we obtain the Taylor polynomial:
Taylor polynomial = 1/6*x^4*e - 1/6*x^3 - 1/2*x^2*e + x + e
and the graph
25
20
15
10
5
–3
–1
–2
1
2
3
order
f
sin(x)+eˆcos(x)
Taylor polynomial = 1/6*xˆ4*e – 1/6*xˆ3 – 1/2*xˆ2*e + x + e
4
1.10
Exercises
1. Consider x D 0:000147 rounded to Ox D 0:00015. Find the number of signiﬁcant digits, absolute
errors, and relative errors?
2. Consider x D 0:00237 rounded to Ox D 0:0024. Find the number of signiﬁcant digits, absolute
errors, and relative errors?
3. Consider x D 123:4567 rounded to Ox D 123:46. Find the number of signiﬁcant digits, absolute
errors, and relative errors?
4. Consider x D 314:57823 rounded to Ox D 314:59. Find the number of signiﬁcant digits, absolute
errors, and relative errors?
5. For each of the following numbers, what are the results of rounding them? 0.0418, 0.0459, 0.0451,
0.0455, 0.0465.
6. For each of the following numbers, what are the results of chopping them? 0.0418, 0.0459,
0.0451, 0.0455, 0.0465.
7. Find the linear and quadratic Taylor polynomials for the function f .x/ D px, using c D 1 as
the point of expansion. Graph the function and these Taylor polynomials on the same set of axes.
8. Find the linear and quadratic Taylor polynomials for the function f .x/ D ecos x, using c D 0 as
the point of expansion. Graph the function and these Taylor polynomials on the same set of axes.

1.11
Computer Exercises
61
9. Find the linear and quadratic Taylor polynomials for the function f .x/ D esin x, using c D 0 as
the point of expansion. Graph the function and these Taylor polynomials on the same set of axes.
10. Find the linear and quadratic Taylor polynomials for the function f .x/ D log.1 C ex/, using
c D 0 as the point of expansion. Graph the function and these Taylor polynomials on the same
set of axes.
11. Find the Taylor series expansion for the function sin.x/, around c D 0.
12. Find the Taylor series expansion for the function cos.x/, around c D 0.
13. Write the Taylor series expansion for the function f .x/ D x3 C 3x2  2x C 3, using c D 2 as
the point of expansion.
14. Write the Taylor series expansion for the function f .x/ D x3 C 3x2  2x C 3, using c D 3 as
the point of expansion.
15. Find the
a. Taylor polynomial of degrees 1 through 5, for the function f .x/ D ex2 using c D 0 as the
point of expansion
b. Taylor polynomial of degrees 1 through 5, for the function f .x/ D ex2 using the Taylor
polynomials for f .x/ D ex. Compare the results with part a).
16. Find the
a. Taylor polynomial of degrees 1 through 5, for the function f .x/ D cos.x2/ using c D 0 as
the point of expansion
b. Taylor polynomial of degrees 1 through 5, for the function f .x/ D cos.x2/ using the Taylor
polynomials for f .x/ D cos.x/. Compare the results with part a).
17. The function f .x/ D sin x
x
is undeﬁned at x D 0. Use Taylor series for sin.x/ to determine a
natural deﬁnition for f .0/.
18. The function f .x/ D ex1
x
is undeﬁned at x D 0. Use Taylor series for sin.x/ to determine a
natural deﬁnition for f .0/.
19. How can values of the function f .x/ D sin.1 C x/ be accurately computed for values of x close
to 0?
20. How can values of the function f .x/ D cos.2 C x/ be accurately computed for values of x close
to 0?
21. If the sine series is to be used in computing sin 1 with an error less than 107, ﬁnd the number of
terms needed to be used from the series.
22. If the ln series is to be used in computing ln 2 with an error less than 107, ﬁnd the number of
terms needed to be used from the series.
23. If the arctan series is to be used in computing arctan 2 with an error less than 108, ﬁnd the
number of terms needed to be used from the series.
24. If the ex series is to be used in computing e1 with an error less than 109, ﬁnd the number of
terms needed to be used from the series.
1.11
Computer Exercises
1. Use Sage to solve the following system of equations:
 x  2y D 7
3x C y D 0 :
2. Use Sage to solve the following system of equations:

62
1
Fundamentals
 2x  5y D 17
3x C 7y D 21 :
3. Create Sage code that will deﬁne the function f .x/ D 2e3x  5 cos.x/ C 3, and evaluate it at the
points x D 0 and x D .
4. Create Sage code that will deﬁne the function f .x/ D ex2  3 sin.x2/ C 2, and evaluate it at the
points x D 0 and x D p 
2 :
5. Use Sage to graph the function f .x/ D 2e3x  5 cos.x/ C 3.
6. Use Sage to graph the function f .x/ D ex2  3 sin.x2/ C 2.
7. Use Sage to compute the following sum f .x/ D
2015
X
iD0
1
i2CiC1.
8. Use Sage to compute the following sum f .x/ D
512
X
iD0
1
i3C2i2C8.
9. Use Sage to ﬁnd the number of primes between 1945 and 2015.
10. Use Sage to ﬁnd the number of primes between 123,456 and 123,456,789.
11. Use Sage to smallest 10 prime numbers larger than 2016.
12. Use Sage to smallest 20 prime numbers larger than 123,456,789.
13. Use Sage to print the function f .x/ D cos.x/, for x in Œ2; 2.
14. Use Sage to print the function f .x/ D sin.x/, for x in Œ2; 2.
15. Use Sage to print the function f .x/ D sin. 3px/, for x in Œ20; 20.
16. Use Sage to print the function f .x/ D cos. 3px/, for x in Œ20; 20.
17. Use Sage to ﬁnd 10th order Taylor polynomial of the function f .x/ D cos.x/. Then use this
polynomial to ﬁnd an approximate value for cos.0:001/.
18. Use Sage to ﬁnd 8th order Taylor polynomial of the function f .x/ D sin.x/. Then use this
polynomial to ﬁnd an approximate value for sin.0:003/.
19. Use Sage to ﬁnd 8th order Taylor polynomial of the function f .x/ D sin.x/. Then use this
polynomial to ﬁnd an approximate value for sin.7:001/.
20. Use Sage to ﬁnd 10th order Taylor polynomial of the function f .x/ D cos.x/. Then use this
polynomial to ﬁnd an approximate value for cos.8:003/.
21. Use Sage to ﬁnd 5th order Taylor polynomial for the function f .x/ D cos. 3px/. Then use this
polynomial to ﬁnd an approximate value for cos.
3p
2/.
22. Use Sage to plot on the same graph, the function f .x/ D sin.x/, and the Taylor’s polynomials
up to order 5, around c D 0.
23. Use Sage to plot on the same graph, the function f .x/ D cos.x/, and the Taylor’s polynomials
up to order 5, around c D 0.
24. Use Sage to plot on the same graph, the function f .x/ D cos.x/, and the Taylor’s polynomials
up to order 5, around c D 7.
25. Use Sage to plot on the same graph, the function f .x/ D ln.x/, and the Taylor’s polynomials up
to order 5, around c D 7.
26. Use Sage to ﬁnd the linear and quadratic Taylor polynomials for the function f .x/ D px, using
c D 1 as the point of expansion. Graph the function and these Taylor polynomials on the same
set of axes.
27. Use Sage to ﬁnd the linear and quadratic Taylor polynomials for the function f .x/ D ecos x,
using c D 0 as the point of expansion. Graph the function and these Taylor polynomials on the
same set of axes.
28. Use Sage to ﬁnd the linear and quadratic Taylor polynomials for the function f .x/ D esin x,
using c D 0 as the point of expansion. Graph the function and these Taylor polynomials on the
same set of axes.

References
63
29. Use Sage to ﬁnd the linear and quadratic Taylor polynomials for the function f .x/ D log.1Cex/,
using c D 0 as the point of expansion. Graph the function and these Taylor polynomials on the
same set of axes.
30. If the sine series is to be used in computing sin 1 with an error less than 107, use Sage to ﬁnd
the number of terms needed to be used from the series.
31. If the ln series is to be used in computing ln 2 with an error less than 107, use Sage to ﬁnd the
number of terms needed to be used from the series.
32. If the arctan series is to be used in computing arctan 2 with an error less than 108, use Sage to
ﬁnd the number of terms needed to be used from the series.
33. If the ex series is to be used in computing e1 with an error less than 109, use Sage to ﬁnd the
number of terms needed to be used from the series.
References
1. Abramowitz, M., Stegun, I.A. (eds.): Handbook of Mathematical Functions with Formulae, Graphs, and Mathemat-
ical Tables. Dover, New York (1972)
2. Anastassiou, G.A., Iatan, I.F.: Intelligent Routines II: Solving Linear Algebra and Differential Geometry with Sage.
Springer, Cham (2014)
3. Atkinson, K., Han, W.: Elementary Numerical Analysis, 3rd edn. Wiley, New York (2003)
4. Beezer, R.A.: Sage for abstract algebra. http://abstract.pugetsound.edu/Sage-aata.html (2013)
5. Blanco-Silva, F.J.: Learning SciPy for Numerical and Scientiﬁc Computing. Packt Publishing, Birmingham/Mumbai
(2013)
6. Cheney, W., Kincaid, D.: Numerical Mathematics and Computing, 7th edn. Brooks/Cole: Cengage Learning, Boston
(2013)
7. Epperson, J.F.: An Introduction to Numerical Methods and Analysis, revised edition. Wiley, Hoboken (2007)
8. Gaddis, T.: Starting Out with Python, 2nd edn. Addison-Wesley, Boston (2012)
9. Rivlin, T.J.: An Introduction to the Approximation of Functions. Dover, New York (2003)
10. Sage Cell Server: http://sagecell.sagemath.org/. Retrieved 2014
11. Stein, W.A., et al.: Sage mathematics software (Version 6.3). The sage development team. Sage ofﬁcial webpage:
http://www.sagemath.org (2014)
12. Stein, W.A.: Sage for power users. http://www.wstein.org/books/sagebook/sagebook.pdf (2012)
13. Sullivan, M., Miranda, K.: Calculus: Early Transcendentals. W. H. Freeman and Company, New York (2014)
14. Webster’s American English Dictionary: http://www.merriam-webster.com/dictionary. Retrieved 2014
15. Weierstrass, K.: Uber die analytische Darstellbarkeit sogenannter willkurlicher Functionen einer reellen Verander-
lichen. Sitzungsberichte der Akademie zu Berlin 2, 633–639 (1885)

Chapter 2
Solving Nonlinear Equations
In this chapter we’ll deal with ﬁnding (or rather approximating) the solution of an equation f .x/ D 0.
This is a very common problem in Applied Mathematics, but ﬁnding the exact solution is not always
an easy task.
A real number r that satisﬁes the relation f .r/ D 0 is called a root (or a zero, or a solution) for
the equation f .x/ D 0.
Solving for linear equations of type ax C b D 0 is a rather trivial job. We have formulae to deal
will solving quadratic and cubic equations, such as ax2 C bx C c D 0 or ax3 C bx2 C cx C d D 0.
But what about equations such as: 2x2  10x C 1 D 0? Or 3:7x8  7:5x3 C 3x  10:3 D 0? Or
2x  3xe D 0? How would you solve these equations?
In this chapter we will learn a few methods that will help us “solve” any nonlinear equation.
Although “to solve” means to ﬁnd every possible solution of a given equation, the methods presented
in this chapter will help us obtain only one solution at a time, and although usually not exact, we can
get these answers to any desired degree of accuracy.
We will focus here on both the Mathematical reasoning of these methods and the corresponding
algorithms that we will implement in Sage.
Notation: in this chapter, by r we will denote the exact solution of the equation we are trying
to solve. If there are more than one solutions, then it should be clear from the context which one r
refers to.
2.1
Bisection Method
In this section we will present the ﬁrst method, which although not the fastest, it is one of the simplest,
and its convergence is guaranteed.
So let us start by reminding you the Intermediate Value Theorem, a result that can be found in
virtually any Calculus textbook (see for example [9]):
Theorem 41 (Intermediate Value Theorem). Let f be a continuous function on the closed interval
Œa; b such that f .a/ ¤ f .b/. Then, for any value K strictly between f .a/ and f .b/, there is at least
one r in .a; b/ such that f .r/ D K.
Electronic supplementary material The online version of this chapter (doi:978-3-319-16739-8_2) contains supple-
mentary material, which is available to authorized users.
© Springer International Publishing Switzerland 2015
G.A. Anastassiou, R. Mezei, Numerical Analysis Using Sage, Springer Undergraduate
Texts in Mathematics and Technology, DOI 10.1007/978-3-319-16739-8_2
65

66
2
Solving Nonlinear Equations
In particular, we obtain the foundation for the Bisection Method
Corollary 42. Let f be a continuous function on the closed interval Œa; b such that f .a/f .b/ < 0.
Then there is at least one r in .a; b/ such that f .r/ D 0.
Given the previous Corollary, it should come at no surprise that in this section we only consider
real-valued functions that are continuous on a closed and bounded interval Œa; b such that f .a/ 
f .b/ < 0. These will guarantee that we have at least one solution in the interval .a; b/.
The algorithm for the Bisection Method, which is described below, simply means using the
previous Corollary repeatedly until we obtain a solution with the desired degree of accuracy.
2.1.1
The Algorithm
Let f be a continuous function on the closed interval Œa; b such that f .a/  f .b/ < 0. We are trying
to ﬁnd a solution of the equation f .x/ D 0 in the interval Œa; b. Here is how we do it:
We ﬁrst compute f
 aCb
2

. Then, exactly one of the following is true:
•
If f
 aCb
2

D 0 then we are done. We found a solution, r D aCb
2 .
•
Otherwise, if f .a/  f
 aCb
2

< 0 then we repeat this process and search again for a solution, in
the interval

a; aCb
2

.
•
Otherwise, f
 aCb
2

 f .b/ < 0, we repeat this process and search again for a solution, in the
interval
 aCb
2 ; b

.
We then keep repeating these iterations until either we found a solution, or the length of the interval
is less than some predeﬁned error bound.
So as we could see above, this method starts with an interval Œa; b. If a solution is not found in
the middle, at x D aCb
2
it then “bisects” the interval Œa; b into two equal subintervals:

a; aCb
2

and
 aCb
2 ; b

. Of these two, it is guaranteed that at least one of them contains a solution. You discard the
other one. And keep on halving these intervals until you ﬁnd a solution (either exactly, or within a
predeﬁned error bound).
For example, let’s try to ﬁnd a solution for the following equation: 3:7x8 7:5x3 C3x 10:3 D 0.
In this case, f .x/ D 3:7x8  7:5x3 C 3x  10:3. We can either try two random values for a and b or
we can use a graphing calculator to get a starting interval Œa; b. Let’s try using a graph. In Sage (see
[6–8]) (and adjusting the graphing interval as needed), we could use the following code:
sage: var(’x’)
sage: f(x) = 3.7*x^8-7.5*x^3+3*x-10.3
sage: p=plot(f(x), (x,-1.5, -0.5))
sage: p.show()
And obtain

2.1
Bisection Method
67
From this graph, we can see that a solution exists in the interval Œ1:5; 0:5.
Since f is continuous on Œ1:5; 0:5, f .1:5/ > 0 and f .0:5/ < 0, we can see that all the
conditions for the Bisection Method are satisﬁed and we can use it to estimate the zero in this interval.
Let’s consider the following error bound: 0:05. If we stop once the interval has the length less than
0.05, then taking the midpoint of this interval will yield an estimation of the solution with an absolute
error less than 0.05/2 = 0.025. Below we apply the Bisection Method:
Since f

1:5C.0:5/
2

< 0, we next consider the ﬁrst half of the interval Œ1:5; 0:5, which is
Œ1:5; 1.
Then, since f . 1:5C.1/
2
/ > 0, we next consider the second half of Œ1:5; 1, that is Œ1:25; 1.
Then, since f . 1:25C.1/
2
/ > 0, we next consider the second half of Œ1:25; 1, that is
Œ1:125; 1.
Since f . 1:125C.1/
2
/ > 0, we next consider the second half of Œ1:125; 1, that is Œ1:0625; 1.
Since f . 1:0625C.1/
2
/
<
0, we next consider the second half of Œ1:0625; 1, that is
Œ1:0625; 1:03125.
But since the length of the interval Œ1:0625; 1:03125 is less than 0.05 we can stop and estimate
the solution to be it’s midpoint: r D 1:0625C.1:03125/
2
D 1:046875. Obviously r is less than 0.05/2
away from any point in this interval, and hence it is less than 0.025 away from the true (exact) solution
of the given equation.
We could visually see this example in the image below.

68
2
Solving Nonlinear Equations
40
20
0
–0.6
–0.8
–1
–1.2
–1.4
Exact Solution
Approximations
Note from this illustration that not every value of r is closer to the exact solution of the equation.
2.1.2
Pseudocode
We give below the pseudocode for Bisection Method
function Bisection(f, lower, upper, errorBound)
{
r = (lower+upper)/2
while(f(r)¤0 and (upper-lower)errorBound)
{
if(f(lower)*f(r)<0)
upper = r
else if(f(upper)*f(r)<0)
lower = r
r = (lower+upper)/2
}
return r
}
2.1.3
Sage Code
This algorithm implemented in Sage as a function would look like
def Bisection(f, lower, upper, errorBound):
r = (lower+upper)/2
while( f(r)!=0 and
(upper-lower) >= errorBound
):
if(f(lower)*f(r)<0):
upper = r
else:
#(f(upper)*f(r)<0)
lower = r

2.1
Bisection Method
69
r = (lower+upper)/2
return r
Another way to implement the same method is using recursivity. It is a less efﬁcient, but maybe
more clear:
def Bisection(f, lower, upper, errorBound):
r = (lower+upper)/2
if( f(r)!=0 and
(upper-lower) >= errorBound
):
if(f(lower)*f(r)<0):
return Bisection(f, lower, r, errorBound)
else:
return Bisection(f, r, upper, errorBound)
return r
The previous example can be solved, using Sage, by the following code:
def Bisection(f, lower, upper, errorBound):
r = (lower+upper)/2
while( f(r)!=0 and
(upper-lower) >= errorBound
):
if(f(lower)*f(r)<0):
upper = r
else:
lower = r
r = (lower+upper)/2
return r
def f(x):
return 3.7*x^8-7.5*x^3+3*x-10.3
print "solution = ", Bisection(f, -1.5, -0.5, 0.05).n()
And we obtain the output:
solution =
-1.04687500000000
If we wish, we can include some print statements to output all the intermediate steps, then we
could modify the previous code as it is shown below:
def Bisection(f, lower, upper, errorBound):
print ’Starting with the interval [’, lower,’,’, upper,’]’
print ’f(’, lower,’
)=’, f(lower)
print ’f(’, upper, ’ )=’, f(upper)
print ’------------------------------------------’
print ’------------------------------------------’
#computing the middle of the interval
#this is our first approximation of r
r = (lower+upper)/2
while( f(r)!=0 and
(upper-lower) >= errorBound
):
print
’in the interval [’ , lower,
’,’ , upper , ’]’
print
’
midpoint = ’ , r,
’ f(r)= ’, f(r)
print
if(f(lower)*f(r)<0):

70
2
Solving Nonlinear Equations
upper = r
else:
lower = r
r = (lower+upper)/2
return ’the approximate solution is: ’+str(r)
def f(x):
return 3.7*x^8-7.5*x^3+3*x-10.3
Bisection(f, -1.5, -0.5, 0.05)
And we obtain the output:
Starting with the interval [ -1.50000000000000 ,
-0.500000000000000 ]
f( -1.50000000000000
)= 105.339453125000
f( -0.500000000000000
)= -10.8480468750000
------------------------------------------
------------------------------------------
in the interval [ -1.50000000000000 , -0.500000000000000 ]
midpoint =
-1.00000000000000
f(r)=
-2.10000000000000
in the interval [ -1.50000000000000 , -1.00000000000000 ]
midpoint =
-1.25000000000000
f(r)=
22.6521560668945
in the interval [ -1.25000000000000 , -1.00000000000000 ]
midpoint =
-1.12500000000000
f(r)=
6.49711363911629
in the interval [ -1.12500000000000 , -1.00000000000000 ]
midpoint =
-1.06250000000000
f(r)=
1.51790103104431
in the interval [ -1.06250000000000 , -1.00000000000000 ]
midpoint =
-1.03125000000000
f(r)=
-0.435675070687559
’the approximate solution is: -1.04687500000000’
2.1.4
Error Bounds
At the ﬁrst iteration of this algorithm, we estimate the solution of the equation f .x/ D 0 with the
midpoint of the interval Œa; b, that is we estimate r D aCb
2 . Since this value of r is less than ba
2
away
from any value in the interval .a; b/ (and in particular from the exact solution of the equation), the
error of approximation is bounded above by ba
2 . Hence the absolute error committed is less than ba
2 .
At the second iteration of this algorithm, we look either at Œa; aCb
2  or at Œ aCb
2 ; b, depending on the
signs of f .a/; f .b/, and f .r/. Since the midpoint of either one of these intervals is at a distance less
than half the size of that interval, in this case ba
4 , from all the other points within the same interval,
the error is bounded above by ba
4 .
If we continue to apply the Bisection Method in the same fashion over and over again, we would
get the following upper bounds for the errors: ba
8 , ba
16 ; : : : ; ba
2nC1 ; : : :.

2.1
Bisection Method
71
It can be proven, using Mathematical Induction, that after n iterations of applying the Bisection
Method,
the error of approximation < b  a
2nC1 :
(2.1)
Note that the sequence
n
ba
2nC1
o
nD1;2;::: will always converge to 0, hence this algorithm always
converges. Therefore (if we ignore the limitations of computers or calculators) we can always ﬁnd
an approximation of the solution with any desired level of accuracy.
2.1.5
Comments on the Bisection Method
As we can observe from the previous subsection, each new iteration gives us a lower error of
approximation. The upper bound of this error gets cut into half with each iteration. In terms of
bits (base 2 digits) we can say that with each iteration we gain one bit of accuracy in our solution.
Therefore this method will always converge to a solution. However, as we will see once we introduce
other methods, the Bisection Method converges signiﬁcantly slower than the other methods. In
particular, this method makes no use of the magnitudes of values of the function, it only uses their
signs (positive or negative).
It is very important to note one of the limitations of this method. It cannot be used to ﬁnd zero’s
whose multiplicity is 2 (or any other even number). Can you elaborate on this issue? Can you see why
this is the case?
Another note that is worth being mentioned: if you ever took any Data Structures related course
(usually also taught in a Computer Science 2 course), you should observe that this method uses the
same exact idea as in a Binary Search method (which is used to search for a given element, in a sorted
list/container of items).
2.1.6
Examples
Example 43. Using Sage, ﬁnd a solution of the equation x2 D 4 sin.x/ in Œ1; 3, with an error less
than 0:000005.
Solution. Let f .x/ D x2  4 sin.x/, on the interval Œ1; 3. Since 1  sin.x/  1 we can easily
check that f .1/ < 0, and f .3/ > 0: Also, f is a continuous function, being a linear sum of two
continuous functions (a polynomial function and a trigonometric function). Given all these conditions
that are satisﬁed, we know f has a root in .1; 3/, and we can apply the Bisection Method. The Sage
code below does the job of ﬁnding the root, with an error of approximation less than 0:000005, that is
an error bound (for the interval) of 0:00001. For completeness, we include code that will also output
a table with all intermediate calculations.
def Bisection(f, lower, upper, errorBound):
print ’a \t\t\t\t f(a) \t\t\t b \t\t\t f(b)’
print ’--------------------------------------------\
---------------------------------------------’
r = (lower+upper)/2
while( f(r)!=0 and (upper-lower) >= errorBound ):
print lower,’\t’,f(lower),’\t’, upper,’\t’,f(upper)

72
2
Solving Nonlinear Equations
if(f(lower)*f(r)<0):
upper = r
else:
lower = r
r = (lower+upper)/2
return ’approximate solution: ’ + str(r)
def f(x):
return x^2-4*sin(x)
Bisection(f, 1.0, 3.0, 0.00001)
We obtained the approximate solution r D 1:93375015258789 and the following output
Since the error of approximation is less than 0:000005, only the ﬁrst ﬁve decimal places are
accurate, and therefore we should only report the following answer: r D 1:93375.
If we wish to use Sage library methods to compute the solution to this equation, one can use the
following:
find_root(x^2-4*sin(x), 1,3)
to obtain
1.9337537628270214
Example 44. Find the largest root of f .x/ D x8  x  7, accurate to within 0.00001.
Solution. In order to have an idea where could the largest root be, we should ﬁrst graph the function.
This will help us ﬁnd an interval Œa; b that can be used in the Bisection Method. The function is
continuous everywhere, since it is a polynomial. Running the Sage code below and adjusting the
interval Œa; b until we get a satisfactorily graph, we obtain
sage: var(’x’)
sage: f(x) = x^8-x-7
sage: p=plot(f(x), (x,-1.5, -0.8))
sage: p.show()

2.1
Bisection Method
73
This will produce the following graph:
Then we apply the Bisection method for function f on Œ1:5; 0:8. We can do the computation
manually, using a calculator, or using Sage code.
def Bisection(f, lower, upper, errorBound):
print ’a \t\t\t\t f(a) \t\t\t b \t\t\t f(b) ’
print ’--------------------------------------------\
---------------------------------------------’
r = (lower+upper)/2
while( f(r)!=0 and (upper-lower) >= errorBound ):
print lower,’\t’,f(lower), ’\t’, upper,’\t’,f(upper)
if(f(lower)*f(r)<0):
upper = r
else:
lower = r
r = (lower+upper)/2
return ’approximate solution: ’ + str(r)
def f(x):
return
x^8-x-7
Bisection(f, -1.5, -0.8, 0.00002)
#NOTE: accurate to 0.00001 means
# the size of the interval is at most 0.00002
In either case, we would obtain something similar to:

74
2
Solving Nonlinear Equations
Hence our answer would be 1:24454421997070 (or rather 1:24454 since the other digits many
not be accurate).
Like in the previous example, one could use Sage library methods to compute/approximate the
solution to this equation:
find_root(x^8-x-7, -1.5, -0.8)
to obtain
-1.2445431960326296
Example 45. In the previous example, starting with the same interval Œa; b, how many iterations are
needed in order to ﬁnd the largest root accurate to within 0.000000000001?
Solution. Using the formula (2.1) we need to ﬁnd n large enough so that
the error of approximation < b  a
2nC1 < 0:000000000001:
Hence
0:8  .1:5/
2nC1
< 0:000000000001
or
2nC1 > 0:7  1012
hence
n > ln.0:7  1012/
ln 2
 1
 38:3485639658
hence n should be at least 39. Therefore, if we use at least 39 iterations, then it is guaranteed
that the Bisection Method will produce an approximate solution with an absolute error less than
0.000000000001. Check this value also using Sage (Use Bisection(f, 1.5, 0.8, 0.000000000002).)

2.1
Bisection Method
75
Example 46. How many iterations are needed to compute the root of x3 C100ex2 from the interval
Œ0; 4 with an error of approximation less than 107?
Solution. Using the formula (2.1) we need to ﬁnd n large enough so that
the error of approximation < b  a
2nC1 < 107:
Therefore
4  0
2nC1 < 107
or
2n1 > 107
hence
n > ln.107/
ln 2
C 1
 24:2534966
hence n should be at least 25. Try to check this result using a Sage example.
2.1.7
Sage Library
Below we show how one can use the scipy library to use the Bisection Method already imple-
mented there (see [3]). Using that method we will solve the examples given above.
Example 47. Using Sage, ﬁnd a solution of the equation x2 D 4 sin.x/ in [1,3].
Solution. We can use the following Sage code
import scipy.optimize
f(x) = x^2-4*sin(x)
print "solution = " , scipy.optimize.bisect(f, 1, 3)
to obtain
solution =
1.93375376283
Example 48. Find the largest root of f .x/ D x8  x  7.
Solution. Using a graph, as before, we can see that the largest root is inside the interval Œ1:5; 0:8.
Then we can use the following Sage code
import scipy.optimize
f(x) = x^8-x-7
print "solution = " , scipy.optimize.bisect(f, -1.5, -0.8)
to obtain
solution =
-1.24454319603

76
2
Solving Nonlinear Equations
2.2
Newton–Raphson’s Method
Newton–Raphson’s Method is also known as Newton’s Method (see also [4, 5]).
In this section we assume that the function f is differentiable (and hence it is also continuous).
As we will see below, this method usually converges much faster than the Bisection Method.
We say usually, because there are some cases when this method may converge very slowly, or not
converge at all.
As opposed to Bisection method, which will always lead to a solution, there are cases when the
Newton’s Method will diverge. This is one of the reasons why in practice some hybrid methods, that
combines both methods for an optimal result, are being used.
Let’s have a look at the following graph. For completeness, we included it’s Sage code come below,
without giving too many details other than the comments embedded in it. Please refer to the ofﬁcial
Sage Math Documentation to ﬁnd more details about “2D Plotting” [6].
Here comes a basic outline of the Newton–Raphson’s Method: As with the previous section, we
are trying to solve the equation f .x/ D 0. This is the same as ﬁnding the point where the graph
of f .x/ crosses the x-axis (See the “exact solution” plotted in the previous graph.) Let’s start with
some approximation to the exact solution (or “guess” if you wish), and call it x0 (we will need that
f 0.x0/ ¤ 0). From the given graph it seems reasonable to approximate the function f .x/ with the
tangent line to f .x/ at x0. That is
f .x/  f .x0/ C f 0.x0/.x  x0/
Doing so, we can easily compute the zero of the tangent line (this zero is “usually” is a better
approximation to the exact solution than x0). Since, f .x0/ C f 0.x0/.x  x0/ D 0 can be easily
solved, we obtain our approximate solution:
x1 D x0  f .x0/
f 0.x0/:

2.2
Newton–Raphson’s Method
77
We can see from the graph that we expect x1 to be a more accurate approximation of the exact solution
than x0. Now repeat this process and compute
x2 D x1  f .x1/
f 0.x1/;
and so on. Our hope (for now) is that we will obtain better and better approximations with each new
iteration.
Below we give the Sage code for the above graph, and then we will give the outline of the Newton–
Raphson’s Method. For now, we assume f 0.xi/ ¤ 0, for every i D 0; 1; : : : ; n; : : :. The special case
when f 0.xi/ D 0, for some value of i, is treated towards the end of this section.
#the function we considered is
var(’x’)
f(x)=x^3+3*x-5
#next we compute its derivative
fp(x)=diff(f(x),x)
#the particular choice of x0
x0 = 2.2
#the interval [a,b] is
a = -0.2
b = 2.7
#preparing the plots
#first comes the function
function = plot(f(x), (x,a,b), linestyle=’-’, thickness=2,
color=’blue’, legend_label=’function f(x)’)
#then comes the tangent line
tangent = plot( (fp(x0)*(x-x0)+f(x0)) , (x,1.5,b),
linestyle=’--’, thickness=3, color=’red’,
legend_label=’tangent line at x0’)
#we include some text on the graph
textt = text(’x1’, (1.5,-2), color=’black’)
#we plot some of the points, and some text
points = list_plot( [(x0, f(x0)), (x0, 0), (1.5,0)],
color=’black’, size=70)
textp = text(’x0’, (x0,-2), color=’black’)
#then we plot the exact solution, with text
Exact = list_plot( [(1.15,0)] , color=’blue’, size=70)
textExact = text(’exact solution’, (1.15,-2), color=’blue’)
#next we display all the plots we created above
show(function+tangent+textt+points+textp+textExact+Exact)

78
2
Solving Nonlinear Equations
2.2.1
The Algorithm
Newton–Raphson’s method is as follows: start with some approximate value to the exact solution,
let’s say x0. Then, using formula
xnC1 D xn  f .xn/
f 0.xn/; n D 0; 1; 2; : : :
(2.2)
we successively compute x1; x2; x3; : : :. Under special circumstances (to be discussed below), this
sequence of points will converge to the exact solution, r.
15
10
5
0.5
1
1.5
2
2.5
x2
x1
x0
exact
solution
For example, suppose we wish to ﬁnd a positive solution for the equation x2  4 cos.x/ D 0. Here
f .x/ D x2  4 cos.x/ and f 0.x/ D 2x C sin.x/. Using Sage to graph this function we can see that a
candidate for x0 could be 1.
plot( x^2-4*cos(x) , (x,-1,2))

2.2
Newton–Raphson’s Method
79
Then, we get the following successive approximations: x0 D 1, x1 D 1  f .1/
f 0.1/ ' 1:216405952,
x2 D x1  f .x1/
f 0.x1/ ' 1:201599182; x3 D x2  f .x2/
f 0.x2/ ' 1:20153830. Therefore, the exact solution is
approximately r ' 1:20153830. Below is the Sage code we used to carry these computations.
var(’x’)
f(x)= x^2-4*cos(x)
fp(x)=diff(f(x),x)
x0=1.0
x1=x0-f(x0)/fp(x0)
x2=x1-f(x1)/fp(x1)
x3=x2-f(x2)/fp(x2)
print x0, x1, x2, x3
to obtain:
1.00000000000000 1.21640595223885 1.20159918212198 1.20153830038108
2.2.2
Pseudocode
Before we write the pseudocode and Sage code, we should be aware of some potential challenges
when running the algorithm.
First issue is that the iterations may not converge. Because of this, we want to make sure the
program will “know” to eventually give up. So for this, we need to introduce a parameter maxSteps
that will tell the algorithm when to give up. In the example below, we chose this value to be 100. That
guarantees that the algorithm will stop after at most 100 iterations.
Then, we also need to decide when do we consider that our approximation is “good” enough.
What does “good” mean for us? Or, “how good is good enough”? In the example below, we chose
almostZero D 0:000000001. That means any answer, such that jf .answer/j < 0:000000001 will be
considered accurate enough, and the Newton–Raphson’s iterations should stop there.
One challenge we will not take into account here (in order to keep the algorithm simple) is the
case when f 0.xi/ is zero for some i. What happens if f 0.xi/ is so close to zero that when represented
on computer, it appears as a zero (an obvious example that would be a challenge for most computers
today is: 10102014 which would be represented as a 0). What do we do when an underﬂow occurs?
Here comes the pseudocode that we will use for Newton–Raphson algorithm:
function printNewtonRaphson(f, f’, x0, maxSteps, almostZero )
{
output x0, ’nt’, f(x0)
#we compute the iterations and stop when we get
#a "good" approximation, or tried too many steps
i = 0
while(
i < maxSteps and
jf(xi)j > almostZero )
{
xiC1 D xi  f .xi/=f 0.xi/
print xi, ’nt’, f .xi/
i = i + 1
}
}

80
2
Solving Nonlinear Equations
2.2.3
Sage Code
We give, below, our Sage implementation for the Newton–Raphson’s Method.
def printNewtonRaphson(f, fp, x0, maxSteps, almostZero ):
print ’\t’, ’xi’, ’\t\t\t’,’f(xi)’
#we start with x0, and print it
approx = x0
print x0, ’\t’, f(x0)
#then we compute the iterations and
#stop when we get a "good" approximation
#or when tried too many steps
steps = 0
while(
steps<maxSteps and
abs(f(approx))>almostZero ) :
approx = approx - f(approx)/fp(approx)
print approx, ’\t’, f(approx)
steps = steps + 1
To apply this code to out previous example, we simply need to add the Sage code below:
#define f(x)
var(’x’)
f(x)= x^2-4*cos(x)
#compute f’(x)
fp(x)=diff(f(x),x)
#choose a starting point
x0=1.0
#choose the max number of iterations
maxSteps = 100
#choose what makes an approx acceptable
almostZero = 0.000000001
#call the function
printNewtonRaphson(f, fp, x0, maxSteps, almostZero)
The example above could be equivalently simpliﬁed to
#define f(x)
var(’x’)
f(x)= x^2-4*cos(x)
#compute f’(x)
fp(x)=diff(f(x),x)
#call the function
printNewtonRaphson(f, fp, 1.0, 100, 0.000000001)

2.2
Newton–Raphson’s Method
81
Either one will yield the following output:
xi
f(xi)
1.00000000000000
-1.16120922347256
1.21640595223885
0.0915686905445798
1.20159918212198
0.000373428376449381
1.20153830038108
6.38189456836358e-9
1.20153829934058
6.66133814775094e-16
2.2.4
Error Bounds
The error of approximation formula for Newton–Raphson Method is not as nice and clear as the one
given in the Bisection Method. For example, in the Bisection Method we could compute ahead of
time the number of iterations needed to achieve a certain accuracy. Such an exact computation is not
available for Newton–Raphson’s Method. For Bisection Method we had a clear upper bound formula
but for Newton’s Method we can only estimate it.
We will give below the standard approach for the error of approximation in the case of Newton–
Raphson’s Method:
error D exact solution  xn:
Let’s denote by r the exact solution. Since r is a zero for the f , using the Mean Value Theorem (see
page 53), we obtain:
f .xn/ D f .xn/  f .r/
D f 0.n/.xn  r/
for some n between xn and r. Hence
r  xn D  f .xn/
f 0.n/:
Therefore, if xn is close to r, so must be n, and we have
r  xn '  f .xn/
f 0.xn/ D xnC1  xn:
So the error of approximation formula use for Newton–Raphson’s Method is given by
exact solution  xn ' xnC1  xn
which in practice seems to be quite accurate.
2.2.5
Comments on the Newton–Raphson’s Method
As mentioned above these iterations, under certain conditions, converge much faster than in Bisection
Method. The number of correct ﬁgures nearly doubles with each new iteration and therefore about ﬁve

82
2
Solving Nonlinear Equations
iterations will usually give us a pretty accurate approximation. In those cases, we say that Newton–
Raphson’s Method has a quadratic convergence.
Theorem 49 (Newton’s Method Theorem). If r is such that f .r/ D 0, and f; f 0; f 00 are continuous
in a neighborhood of r, and f 0.r/ ¤ 0, then, for any x0 sufﬁciently close r, we have that x0, x1, x2,
: : :, xn; : : : will converge to r and for some C
jr  xnC1j  C jr  xnj2 ;
n D 0; 1; 2; : : : :
Proof. An outline only!
Using Taylor’s Theorem with Remainder (see page 48) we obtain that for any xn close enough to r
we have
f .r/ D f .xn/ C f 0.xn/.r  xn/ C f 00./
2
.r  xn/2;
for some  between r and xn. Therefore
0 D f .xn/
f 0.xn/ C .r  xn/ C f 00./
2f 0.xn/.r  xn/2
hence
0 D .xn  xnC1/ C .r  xn/ C f 00./
2f 0.xn/.r  xn/2:
From here we deduce
r  xnC1 D f 00./
2f 0.xn/.r  xn/2
therefore
jr  xnC1j D
ˇˇˇˇ
f 00./
2f 0.xn/
ˇˇˇˇ jr  xnj2 :
This last equation can be used to deduce the statement of the Theorem.

But there are cases when the convergence may be slower, about linear (for example when the exact
solution has multiplicity more than one). And there are yet other cases when the sequence will not
converge at all. These cases are discussed next.
If, for some n, the value of f 0.xn/ is so small that f .xn/=f 0.xn/ cannot be represented on the
computer, then the method will fail. We will not be able to compute the iterations past that point xn
(xnC1; xnC2; : : :). To address this issue, we should use an improved version of the Pseudocode given
above, so that we stop the algorithm and report this incident. Here is what we could do: if at any time
f 0.xn/ becomes less than a certain value (let’s say 0:00000001) then we simply stop the algorithm
and output an error message.
function printNewtonRaphson(f, f’, x0, maxSteps, almostZero )
{
output x0, ’\t’, f(x0)
#we compute the iterations and stop when we get

2.2
Newton–Raphson’s Method
83
#a "good" approximation, or tried too many steps
i = 0
while(i < maxSteps and jf .xi/j > almostZero and jf 0.xi/j  0:00000001)
{
xiC1 D xi  f .xi/=f 0.xi/
print xi, ’nt’, f .xi/
i = i + 1
}
if(jf 0.xi/j > smallestPositiveValuej)
print “ERROR: Max. number of steps reached”
if(f 0.xi/j < 0:00000001)
print “ERROR: derivative has a very small value, or it is 0”
}
One way to try avoiding this issue, and that will work in many cases, would be to choose a closer
value of x0 to the exact solution, r. As an exercise, modify the Sage code given earlier so it can address
the challenge just discussed here.
Another possible challenge is when the sequence of iterations, x0; x1; : : : ; xn; : : : does not
converge. The iterations can get into a cycle, by repeatedly taking on the same values over and over
again. Here is an example: let f .x/ D x3  2x C 2, and x0 D 0. Then, using Newton’s Method, we
obtain x1 D 1; x2 D 0; x3 D 1; : : :. Hence we get a cycle, not a convergent sequence.
Iterations Enter an Inﬁnite Cycle
There are cases when we might get f 0.xn/ D 0, for some n. As an example, take the previous
function, f .x/ D x3  2x C 2, but choose x0 D
q
2
3. Then, f 0.x0/ D 0 and we cannot compute x1
and hence we cannot make use of Newton–Raphson’s Method.

84
2
Solving Nonlinear Equations
Horizontal Tangent Line
In some cases the iterations diverge by moving further and further away from the exact solution
(instead of approaching it). In the case of, f .x/ D .x  1/ex, if we choose x0 D 3, we will see that
the iterations are going further and further away from the only zero of the function r D 1. In this case,
the iterations are not converging to 1, and the Sage will stop only because the value of f .xn/ becomes
very small, making the algorithm believe it found a solution.
xi are getting further and further away from the exact solution
Usually all these situations can be avoided by selecting a value of x0 closer to the exact solution.

2.2
Newton–Raphson’s Method
85
2.2.6
Examples
Example 50. Compute the ﬁrst ﬁve iterations of Newton–Raphson’s method to ﬁnd a solution of the
equation x2 D 4 sin.x/.
Solution. Let f .x/ D x2  4 sin.x/. Then f 0.x/ D 2x  4 cos.x/. Using x0 D 1:5, we obtain:
x1 D x0  f .x0/
f 0.x0/ ' 2:14039277238801;
x2 D x1  f .x1/
f 0.x1/ ' 1:95200894640563;
x3 D x2  f .x2/
f 0.x2/ ' 1:93393057392984;
x4 D x3  f .x3/
f 0.x3/ ' 1:93375377978974;
and
x5 D x4  f .x4/
f 0.x4/ ' 1:93375376282702:
Example 51. Using Sage, ﬁnd a solution of the equation x2 D 4 sin.x/ in [1,3].
Solution. Let f .x/ D x2  4 sin.x/, on the interval Œ1; 3. Let’s apply Newton–Raphson’s Method
using x0 D 1:5.
#define f(x)
var(’x’)
f(x)= x^2-4*sin(x)
#compute f’(x)
fp(x)=diff(f(x),x)
#call the function
printNewtonRaphson(f, fp, 1.0, 100, 0.000000001)
Then we obtain:
xi
f .xi/
1:00000000000000
2:36588393923159
13:6758596578334
190:611022845009
7:13289172861309
53:8824908755625
3:94582296731645
12:6883310840735
1:46617193667756
6:12778758471310
0:362975604615735
1:28847882452474
0:0646036910653746
0:262408683769386
0:000925601534061141
0:00370326234577898
2:13821352164768e  7 8:55285454378637e  7
1:14298881865264e  14 4:57195527461057e  14
If you compare these results with the corresponding example that used Bisection Method
(see page 43), you will see that this method converges faster.

86
2
Solving Nonlinear Equations
Example 52. Using Sage, ﬁnd the largest solution of the equation ex D x3  3.
Solution. Let f .x/ D ex  x3 C 3. If we graph this function, we can see that the largest solution is
around 4.5. Therefore we can apply Newton–Raphson’s Method using x0 D 4:5.
plot(e^x-x^3+3, (x, -5,5))
Then, we can apply Newton–Raphson’s Method using the code
#define f(x)
var(’x’)
f(x)= e^x-x^3+3
#compute f’(x)
fp(x)=diff(f(x),x)
#call the function
printNewtonRaphson(f, fp, 4.5, 100, 0.000000001)
To obtain:
xi
f(xi)
4.50000000000000
1.89213130052181
4.43534961520168
0.127976347740542
4.43030415283240
0.000733634812831951
4.43027489423740
2.45581048829990e-8
4.43027489325791
0.000000000000000
Example 53. Using Newton–Raphson, ﬁnd the largest root of f .x/ D x8  x  7.

2.2
Newton–Raphson’s Method
87
Solution. In order to have an idea where could the largest root be, we should provide a graph of the
function.
plot(x^8-x-7, (x, -1.5,-0.8))
Since the solution seems to be close to 1:2 we choose this value for x0. Using the code
#define f(x)
var(’x’)
f(x)= x^8-x-7
#compute f’(x)
fp(x)=diff(f(x),x)
#call the function
printNewtonRaphson(f, fp, -1.2, 100, 0.000000001)
we obtain:
xi
f(xi)
-1.20000000000000
-1.50018304000000
-1.25057004771720
0.232814860486689
-1.24464131599207
0.00372920995296955
-1.24454322238949
1.00146604165019e-6
-1.24454319603264
7.37188088351104e-14
For comparison purposes, if we choose x0 D 0:8, which is further away from the exact solution,
we would need more iterations
xi
f(xi)
-0.800000000000000
-6.03222784000000
-3.05274645429906
7538.73623499328
-2.67137213793097
2589.10499016581

88
2
Solving Nonlinear Equations
-2.33805087708853
888.297339207666
-2.04741544726537
303.826449940133
-1.79580193886599
102.956003751903
-1.58257000864920
33.9288292520208
-1.41283933426179
10.2888806076826
-1.29964510559836
2.43915405062124
-1.25191491788326
0.285820586171777
-1.24468954991890
0.00556315419511222
-1.24454325466533
2.22783322012532e-6
-1.24454319603265
3.60600438398251e-13
You may want to try other values, to compare the speed of convergence. Try to relate your answers
to the shape of the graph.
Example 54. Use Newton’s Method to compute
3p
5
Solution. Since
3p
5 is the solution of the equation x3  5 D 0, we will apply Newton’s Method to
f .x/ D x3  5. Let’s start with x0 D 2. We have f 0.x/ D 3x2 and:
x1 D x0  f .x0/
f 0.x0/ D 1:75
x2 D x1  f .x1/
f 0.x1/ D 1:7108843537415
x3 D x2  f .x2/
f 0.x2/ D 1:70997642891697
x4 D x3  f .x3/
f 0.x3/ D 1:70997594667683:
Since the last two iterations are very close to each other we can stop and, we conclude that
3p
5 ' 1:70997:
If we want more digits of precision, we simply compute a few more iterations.
2.2.7
Sage Library
Sage already has a Newton–Raphson’s Method included in its libraries. Below is an example on how
to solve the following problem: use Newton–Raphson’s Method to compute
3p
5.
sage: x = PolynomialRing(RealField(), ’x’).gen()
sage: f = x^3 - 5
sage: #if we want n = 4 iterations
sage: #and start with x0 = 2 then use:
sage: f.newton_raphson(4, 2)
The output obtained is:
[1.75000000000000, 1.71088435374150, 1.70997642891697,
1.70997594667683]

2.2
Newton–Raphson’s Method
89
2.2.8
Sage Library 2
We present, below, another Sage function that implements the Newton–Raphson’s Method. This
method is included in the scipy library. We will apply this method to all the examples given above
in this section.
Example 55. Use Newton–Raphson’s method to ﬁnd a solution of the equation x2 D 4 sin.x/.
Solution. Using x0 D 1:5, and the following Sage code
#import the following library
import scipy.optimize
#the function f(x) from our problem
f(x) = x^2-4*sin(x)
#compute the derivative of f
fp(x)=diff(f(x),x)
#call the Newton’s method and output the result
print "solution = " , scipy.optimize.newton(f, 1.5, fp)
we obtain:
solution =
1.93375376282702
Example 56. Using Sage, ﬁnd the largest solution of the equation ex D x3  3.
Solution. Using x0 D 4:5 and the following Sage code
#import the following library
import scipy.optimize
#the function f(x) from our problem
f(x) = e^x-x^3+3
#compute the derivative of f
fp(x)=diff(f(x),x)
#call the Newton’s method and output the result
print "solution = " , scipy.optimize.newton(f, 4.5, fp)
we obtain:
solution =
4.43027489325791
Example 57. Find the largest root of f .x/ D x8  x  7.
Solution. Using x0 D 1:2 and the following Sage code
#import the following library
import scipy.optimize
#the function f(x) from our problem
f(x) = x^8-x-7

90
2
Solving Nonlinear Equations
#compute the derivative of f
fp(x)=diff(f(x),x)
#call the Newton’s method and output the result
print "solution = " , scipy.optimize.newton(f, -1.2, fp)
we obtain:
solution =
-1.24454319603264
Example 58. Use Newton’s Method to compute
3p
5
Solution. Using x0 D 2 and the following Sage code
#import the following library
import scipy.optimize
#the function f(x) from our problem
f(x) = x^3-5
#compute the derivative of f
fp(x)=diff(f(x),x)
#call the Newton’s method and output the result
print "solution = " , scipy.optimize.newton(f, 2, fp)
we obtain:
solution =
1.709975946676697
2.3
Secant Method
In this section we only require that f is a continuous function.
As opposed to Newton’s Method, this method does not need f to be differentiable.
As opposed to Bisection Method, this method does not require that the initial two points, a; b be
chosen such that the function f .a/ and f .b/ have opposite signs.
The idea behind the Secant Method is similarly to Newton’s Method: it approximates the function
f with a line. Rather than using a tangent line, here we will be using a secant line. Then, the zero of
the secant line would give us an approximation for the exact zero of the original function.
We start by choosing two initial points, x0 and x1. Then, we can easily compute the line that passes
through .x0; f .x0// and .x1; f .x1//. This line is called a secant line. The equation of this line is
y D f .x1/ C .x  x1/  f .x1/  f .x0/
x1  x0
:
Solving for the zero of this line
0 D f .x1/ C .x  x1/  f .x1/  f .x0/
x1  x0

2.3
Secant Method
91
we obtain
x2 D x1  f .x1/ 
x1  x0
f .x1/  f .x0/:
As mentioned above, the two initial points can be on either side of the exact solution of f . The next
two graphs illustrate both of these cases. We will also give their Sage code below.
Both initial points are to the left of the exact solution
and
The two initial points are on either side of the exact solution

92
2
Solving Nonlinear Equations
Using x1 and the newly computed x2, we can repeat this process and get
x3 D x2  f .x2/ 
x2  x1
f .x2/  f .x1/
and then compute x4; x5, so on.
The Sage code for the above graphs is given below:
##############################
######
FIRST GRAPH
#######
##############################
#the function we considered is
var(’x’)
f(x)=x^3+3*x-5
#the particular choice of x0, and x1
x0 = 2.5
x1 = 1.5
x2 = x1-f(x1)*((x1-x0)/(f(x1)-f(x0)))
#the interval [a,b]
a = -0.2
b = 2.7
#first comes the function
function = plot(f(x), (x,a,b), linestyle=’-’, thickness=2,
color=’blue’, legend_label=’function f(x)’)
#then comes the secant line
secant = plot( f(x1)+(x-x1)*(((f(x1)-f(x0)))/(x1-x0)) , (x,a,b),
linestyle=’--’, thickness=3, color=’red’,
legend_label=’secant line through x0 and x1’)
#plotting the points at x0, x1, x2
points = list_plot( [(x0, f(x0)),
(x0, 0), (x1,f(x1)), (x1,0), (x2,0)],
color=’black’, size=70)
#plotting the exact solution
Exact = list_plot( [(1.15,0)] , color=’blue’, size=70)
#we include some labels on the graph
textx0 = text(’x0’, (x0,-2), color=’black’)
textx1 = text(’x1’, (x1,-2), color=’black’)
textx2 = text(’x2’, (x2,-2), color=’black’)
textExact = text(’exact \n solution’, (1.15,-2), color=’blue’)
#displaying all the plots
show(function+secant+textx0+textx1+textx2+points+textExact+Exact)
##############################
######
SECOND GRAPH
######
##############################

2.3
Secant Method
93
# all the code remains the same except for the next line
x1 = 0.5
2.3.1
The Algorithm
Starting with two initial points, x0 and x1, and using the recursive formula
xnC1 D xn  f .xn/ 
xn  xn1
f .xn/  f .xn1/;
n D 1; 2; 3; : : :
(2.3)
we obtain a sequence of approximations x0; x1; x2; : : : ; xn; : : :. Like in the case of Newton’s Method,
the sequence converges to an exact solution if x0 and x1 are chosen sufﬁciently close to that exact
solution.
As an exercise, write a Sage code to reproduce this graph. The function used was f .x/ D x5 C
3x  5.
If we redraw the previous graph, this time without graphing the secant lines, we would obtain:

94
2
Solving Nonlinear Equations
Note how the points x0, x1, x2, x3, x4, x5 are approaching the exact solution r.
For example, for f .x/ D x5 C 3x  5 and x0 D 1:5; x1 D 0:5, we would obtain the following
values
x1 D 0:828402366863905
x2 D 1:34752525292843
x3 D 1:02499744774395
x4 D 1:08481190418994
x5 D 1:11124254590685
x6 D 1:10849301757437
x7 D 1:10857522427947
x8 D 1:10857550808747:
Hence, we can conclude that
exact solution ' 1:108575:
Another way to derive the Secant Method recurrence formula is using the deﬁnition of derivative
and Newton’s Method formula. Starting with Newton’s Method formula we obtain:
xnC1 D xn  f .xn/ 
1
f 0.xn/

2.3
Secant Method
95
D xn  f .xn/ 
	
lim
h!0
xn  .xn  h/
f .xn/  f .xn  h/

 xn  f .xn/ 
	
xn  xn1
f .xn/  f .xn1/

;
for n D 0; 1; 2; : : :.
2.3.2
Pseudocode
function printSecant(f, x0, x1, maxSteps, almostZero )
{
#output the initial values
output ’#’,’\t’, ’xi’, ’\t\t\t’,’f(xi)’
output 0, x0, ’\t’, f(x0)
output 1, x1, ’\t’, f(x1)
#then we compute the iterations
#and stop when we get a "good" approximation
#or tried too many steps
x2 = x1-f(x1)*((x1-x0)/(f(x1)-f(x0)))
steps = 1
while(
steps<maxSteps and
abs(f(x2))>almostZero )
{
steps = steps + 1
output steps, x2, ’\t’, f(x2)
#save the values of x1 and x2 into x0 and x1
x0=x1
x1=x2
#then compute the new value of x2
x2 = x1-f(x1)*((x1-x0)/(f(x1)-f(x0)))
}
if( abs(f(x2))<=almostZero )
output steps, x2, ’\t’, f(x2)
output ’solution = ’, x2
else if (steps<maxSteps)
output ’ERROR: max number of steps!’
}

96
2
Solving Nonlinear Equations
2.3.3
Sage Code
The code below uses the Secant Method Iteration formula repeatedly, until either it reaches a max
number of steps allowed, or f .xk/ is essentially 0 (jf .xk/j is less than some predeﬁned value
“almostZero”).
def printSecant(f, x0, x1, maxSteps, almostZero ):
#output the initial values
print ’#’,’\t’, ’xi’, ’\t\t\t’,’f(xi)’
print 0, x0, ’\t’, f(x0)
print 1, x1, ’\t’, f(x1)
#then we compute the iterations
#and stop when we get a "good" approximation
#or tried too many steps
x2 = x1-f(x1)*((x1-x0)/(f(x1)-f(x0)))
steps = 1
while(
steps<maxSteps and
abs(f(x2))>almostZero ) :
steps = steps + 1
print steps, x2, ’\t’, f(x2)
#save the values of x1 and x2 into x0 and x1
x0=x1
x1=x2
#compute the new value of x2
x2 = x1-f(x1)*((x1-x0)/(f(x1)-f(x0)))
if( abs(f(x2))<= almostZero ) :
print steps+1, x2, ’\t’, f(x2)
print ’solution = ’, x2
elif (steps<maxSteps):
print ’ERROR: max number of steps!’
For example, if you wish to ﬁnd a zero for the function f .x/ D x2  4 cos.x/ you would add the
following Sage code
#define f(x)
var(’x’)
f(x)= x^2-4*cos(x)
#choose two starting points
x0 = 1.0
x1 = 1.3
#choose the max number of iterations
maxSteps = 100
#choose an error of approximation
almostZero = 0.000000001
#call the function
printSecant(f, x0, x1, maxSteps, almostZero)

2.3
Secant Method
97
And obtain the following output:
#
xi
f(xi)
0 1.00000000000000
-1.16120922347256
1 1.30000000000000
0.620004685501651
2 1.19557604243186
-0.0365079126687797
3 1.20138293895457
-0.000952854869568753
4 1.20153856040398
1.60122160486331e-6
5 1.20153829932919
-6.98432423007489e-11
solution = 1.20153829932919
Another way to write this algorithm is using the Secant Method repeatedly, until two consecutive
values, let’s say xn and xnC1, have the ﬁrst k decimal places equal. In this case, you would conclude
that your answer would have k accurate digits. For this, simply replace the lines of code:
while(
steps<maxSteps and
abs(f(x2))>almostZero ) :
and
if( abs(f(x2))<= almostZero ) :
with
while(
steps<maxSteps and
abs(x2-x1)>almostZero ) :
and
if( abs(x2-x1)<=almostZero ) :
respectively.
Running this new version of code, on the previous example, we would obtain:
#
xi
f(xi)
0 1.00000000000000
-1.16120922347256
1 1.30000000000000
0.620004685501651
2 1.19557604243186
-0.0365079126687797
3 1.20138293895457
-0.000952854869568753
4 1.20153856040398
1.60122160486331e-6
5 1.20153829932919
-6.98432423007489e-11
6 1.20153829934058
6.66133814775094e-16
solution = 1.20153829934058
2.3.4
Error Bounds
It can be shown that for values of xn close enough to the exact solution, the rate of convergence of
Secant Method is equal to the Golden Ratio 1C
p
5
2
' 1:61803398874989. Hence:
jr  xnC1j  C jr  xnj1:618; for n  1:
(2.4)
Therefore, for xn close enough to the exact solution, we could use again the following error estimate:
r  xn1  xn  xn1:
(2.5)

98
2
Solving Nonlinear Equations
2.3.5
Comments on the Secant Method
Although the rate of convergence of the Secant Method is slower than the one for Newton’s Method
(and therefore it requires more steps in order to get the same precision), the Secant Method doesn’t
require the computation of the derivative, f 0, for each point xi. After the ﬁrst step, each new iteration
requires only one function evaluation.
Overall, the Secant Method is usually comparable to (but slightly slower than) Newton’s Method,
and it is usually faster than Bisection Method. But, similar to Newton’s Method, under certain
circumstances, the iterations may not converge.
2.3.6
Examples
Example 59. Using Secant Method, ﬁnd the solution of x2 D 4 sin x, accurate to within 0.00001.
Solution. Graphing this function we can see that it has two roots. One is r1 D 0, and the other one is
around 2. For the second one, we can choose x0 D 2:2 and x1 D 2. Then, using Secant Method we
obtain:
x2 D x1  f .x1/ 
x1  x0
f .x1/  f .x0/
D 1:94163302791153
x3 D 1:93402441194247
x4 D 1:93375491430541
x5 D 1:93375376299613
and since the last two iterations have the ﬁrst ﬁve decimal places identical, we conclude that
r2 ' 1:93375
We could also get the same result using the Sage algorithm given above. We include the complete
code below
def printSecant(f, x0, x1, maxSteps, almostZero ):
#output the initial values
print ’#’,’\t’, ’xi’, ’\t\t\t’,’f(xi)’
print 0, x0, ’\t’, f(x0)
print 1, x1, ’\t’, f(x1)
#then we compute the iterations
#and stop when we get a "good" approximation
#or tried too many steps
x2 = x1-f(x1)*((x1-x0)/(f(x1)-f(x0)))
steps = 1
while(
steps<maxSteps and
abs(x2-x1)>almostZero ) :
steps = steps + 1
print steps, x2, ’\t’, f(x2)
#save the values of x1 and x2 into x0 and x1
x0=x1

2.3
Secant Method
99
x1=x2
#compute the new value of x2
x2 = x1-f(x1)*((x1-x0)/(f(x1)-f(x0)))
if( abs(x2-x1)<= almostZero ) :
print steps+1, x2, ’\t’, f(x2)
print ’----------------------’
print ’solution = ’, x2
elif (steps<maxSteps):
print ’ERROR: max number of steps!’
#define f(x)
f(x)= x^2-4*sin(x)
#choose two starting points
x0 = 2.2
x1 = 2.0
#choose the max number of iterations
maxSteps = 100
#choose what makes an approx acceptable
almostZero = 0.00001
#call the main function
printSecant(f, x0, x1, maxSteps, almostZero)
We get the following output:
#
xi
f(xi)
0 2.20000000000000
1.60601438472164
1 2.00000000000000
0.362810292697273
2 1.94163302791153
0.0418409940408484
3 1.93402441194247
0.00143131333084412
4 1.93375491430541
6.08864118234465e-6
5 1.93375376299613
8.94181173549669e-10
                    
solution = 1.93375376299613
Example 60. Find all the solutions of the equation ex D x4  x3  100, accurate to within 0.00001.
Solution. Graphing the function f .x/ D ex  x4 C x3 C 100, we can observe that there are three
solutions. One of them is around 3, the other one is around 4, and the last one is a little over 8.
To ﬁnd these solutions accurately, we could run the Secant Method three times, once for each of the
solutions.
For the ﬁrst solution, we could use the following Sage code:
#define f(x)
f(x)= e^x-x^4+x^3+100
#choose two starting points
x0 = -3.0
x1 = -2.8

100
2
Solving Nonlinear Equations
#choose the max number of iterations
maxSteps = 100
#choose what makes an approx acceptable
almostZero = 0.00001
#call the main function
printSecant(f, x0, x1, maxSteps, almostZero)
to obtain r1 ' 2:93944 W
#
xi
f(xi)
0 -3.00000000000000
-7.95021293163214
1 -2.80000000000000
16.6432100626252
2 -2.93534683696947
0.521443126747268
3 -2.93972450091570
-0.0359812249035273
4 -2.93944192676814
0.0000701070880942956
5 -2.93944247627490
9.39725806892167e-9
---------------
solution = -2.93944247627490
For r2, we simply change x0 D 3:8 and x1 D 4:0, to obtain r2 ' 3:73004 W
#
xi
f(xi)
0 3.80000000000000
-8.94041550669917
1 4.00000000000000
-37.4018499668558
2 3.73717522903341
-0.888108078153977
3 3.73078265489117
-0.0917692766445555
4 3.73004598112390
-0.000270493391042237
5 3.73004380333116
-8.27927522095706e-8
                    
solution = 3.73004380333116
For the last solution we could use x0 D 8:0 and x1 D 8:2, to obtain r3 ' 8:32527 W
#
xi
f(xi)
0 8.00000000000000
-503.042012958272
1 8.20000000000000
-228.899292667646
2 8.36699279296928
87.5023802602154
3 8.32081014565299
-9.02152589511661
4 8.32512656803232
-0.306694702937421
5 8.32527847273938
0.00113321161097701
6 8.32527791353026
-1.41546479426324e-7
                    
solution = 8.32527791353026
2.3.7
Sage Library
We present, below, a Sage Library function that implements the Secant Method. We will apply this
to the examples given above in this section. The difference between Newton–Raphson’s Method
and Secant Method is that the method scipy.optimize.newton is not given any derivative
function.

2.4
Fixed-Point Iteration
101
Example 61. Use Secant method to ﬁnd a solution of the equation x2 D 4 sin.x/.
Solution. Using x0 D 1:5, and the following Sage code
#import the following library
import scipy.optimize
#the function f(x) from our problem
f(x) = x^2-4*sin(x)
#if no derivative of f is given
#then newton becomes secant method!
###################################
#call the secant method and output the result
print "solution = " , scipy.optimize.newton(f, 2.2)
we obtain:
solution =
1.93375376282702
Example 62. Using Sage, ﬁnd all the solutions of the equation ex D x4  x3  100.
Solution. Using x0 D 3; x0 D 3:8, and x0 D 8 and the following Sage code
#import the following library
import scipy.optimize
#the function f(x) from our problem
f(x) = e^x-x^4+x^3+100
#if no derivative of f is given
#then newton becomes secant method!
###################################
#call the secant method and output the result
print "solution1 = " , scipy.optimize.newton(f, -3.0)
print "solution2 = " , scipy.optimize.newton(f, 3.8)
print "solution3 = " , scipy.optimize.newton(f, 8.0)
we obtain the ﬁrst solution:
solution1 = -2.93944247634856
solution2 = 3.73004380266438
solution3 = 8.32527791360010
2.4
Fixed-Point Iteration
We start with the following deﬁnition
Deﬁnition 63. An element c from the domain of a function f is called a ﬁxed point of f if f .c/ D c.
Graphically, the ﬁxed points of a function f are the x-coordinates (or the y-coordinates) of the
points where the graph of f intersects the graph of y D x.

102
2
Solving Nonlinear Equations
In this subsection, rather than trying to ﬁnd a zero of an equation of the form g.x/ D 0, we will try
to solve an equation of the form f .x/ D x. That is, we are trying to ﬁnd a ﬁxed point of f .
Any equation of the form g.x/ D 0 can be translated into an equation of the form f .x/ D x and
vice versa. In fact, there are multiple equivalent ways one can do so, and some of these are “better”
(their corresponding iterations will have a faster convergence) than others.
The following two results provide us the theoretical background for the Fixed-Point Iteration.
Theorem 64. If f is a continuous function on the interval Œa; b such that a  f .x/  b, then it has
at least one ﬁxed point in that interval.
Proof. We use Intermediate Value Theorem (see page 65) for the function g.x/ D f .x/  x deﬁned
on Œa; b.
If g.a/ D 0, then we are done. a is a ﬁxed point for f .
If g.b/ D 0, then we are done. b is a ﬁxed point for f .
If both g.a/; g.b/ ¤ 0 then it must be the case that g.a/ D f .a/a > 0 and g.b/ D f .b/b < 0.
Therefore, by Intermediate Value Theorem, there must be a value r in .a; b/ such that g.r/ D 0,
which means f .r/ D r.

The following result (see [1]) is a consequence of the Banach Fixed Point Theorem that was
published in 1922.
Theorem 65. Let f be a function such that both f; f 0 are continuous on the interval Œa; b, a 
f .x/  b, and
max
axb
ˇˇf 0.x/
ˇˇ < 1:
(2.6)
Then f has a unique ﬁxed point in Œa; b and for any initial value x0 from Œa; b, the sequence x0; x1 D
f .x0/; x2 D f .x1/; : : : will converge to that ﬁxed point.
In practice, however, these theorems are often skipped (since ﬁnding such an interval Œa; b may
prove challenging!), and we usually use a less restrictive result (such as the Theorem below) or even
go straight and use the computing power of Sage (or other Software packages).
The following is a more practical result that can be used
Theorem 66 (See Corollary 3.4.3 in [1]). If f; f 0 are continuous on some interval Œc; d containing
the ﬁxed point, r, such that
ˇˇf 0.r/
ˇˇ < 1
then there must be some interval Œa; b containing r such that the previous theorem can be applied to.
If, jf 0.r/j > 1 then the Fixed-Point Iteration method will not converge.
We will use this Theorem in our next examples.
2.4.1
The Algorithm
Start by choosing an initial value x0. Then, use the following iteration formula
xn D f .xn1/;
n  1;

2.4
Fixed-Point Iteration
103
then compute enough iterations until you get convergence. In practice, that means, until the difference
between two consecutive values becomes sufﬁciently small.
For example, if we try to ﬁnd the largest root of the equation x2 D 4 sin.x/, one could choose to
the transform this equation into x D 2
p
sin x; and hence use f .x/ D 2
p
sin x. Then choosing, let’s
say x0 D 2:5, we would obtain:
#
xi
f(xi)
0 2.50000000000000
1.54721962772446
1 1.54721962772446
1.99972206319223
2 1.99972206319223
1.90726301723324
3 1.90726301723324
1.94311820681003
4 1.94311820681003
1.93026962424369
5 1.93026962424369
1.93502686037230
6 1.93502686037230
1.93328543686329
7 1.93328543686329
1.93392562006977
8 1.93392562006977
1.93369064094332
9 1.93369064094332
1.93377693933650
10 1.93377693933650
1.93374525205397
11 1.93374525205397
1.93375688797486
12 1.93375688797486
1.93375261525684
13 1.93375261525684
1.93375418421809
                    
solution = 1.93375261525684
It may be useful to see a graph with the ﬁrst three iterations.
The Sage code for getting this image is given below, at the end of this subsection.

104
2
Solving Nonlinear Equations
Please note that from the previous graph, we could see that the ﬁxed point r is inside the interval
 
2 ; 3
4

. And since f 0.x/ D
cos x
p
sin x , we have that
ˇˇf 0.r/
ˇˇ 
max

2 x 3
4
ˇˇˇˇ
cos x
p
sin x
ˇˇˇˇ D cos 3
4
q
sin 3
4
D
1
4p
2
< 1
hence, using the previous theorem, we expected to be able to use the Fixed-Point Iteration method.
We could also transform x2 D 4 sin.x/, into x D
4 sin.x/
x
, and hence use f .x/ D
4 sin.x/
x
. Then
choosing, the same x0 D 2:5, we could not obtain convergence in less than 100 steps
#
xi
f(xi)
0 2.50000000000000
0.957555430566331
1 0.957555430566331
3.41614526513983
2 3.41614526513983
-0.317452931107809
3 -0.317452931107809
3.93315347572487
4 3.93315347572487
-0.723542560382597
5 -0.723542560382597
3.66001328626969
6 3.66001328626969
-0.541537830270961
7 -0.541537830270961
3.80733802699290
8 3.80733802699290
-0.648900101565583
9 -0.648900101565583
3.72513690203326
10 3.72513690203326
-0.591640129711840
11 -0.591640129711840
3.77069165174771
12 3.77069165174771
-0.624200055562205
13 -0.624200055562205
3.74526311018305
14 3.74526311018305
-0.606278389468001
15 -0.606278389468001
3.75941547072754
16 3.75941547072754
-0.616331796398259
17 -0.616331796398259
3.75152338144045
18 3.75152338144045
-0.610749950572025
19 -0.610749950572025
3.75592003835844
20 3.75592003835844
-0.613867187445809
21 -0.613867187445809
3.75346923799843
22 3.75346923799843
-0.612131926781433
23 -0.612131926781433
3.75483493883959
24 3.75483493883959
-0.613099629027355
25 -0.613099629027355
3.75407376948671
26 3.75407376948671
-0.612560510820985
27 -0.612560510820985
3.75449796288972
28 3.75449796288972
-0.612861027717393
29 -0.612861027717393
3.75426155025950
30 3.75426155025950
-0.612693564794332
31 -0.612693564794332
3.75439330432377
32 3.75439330432377
-0.612786899632573
33 -0.612786899632573
3.75431987578976
34 3.75431987578976
-0.612734884834889
35 -0.612734884834889
3.75436079823005
36 3.75436079823005
-0.612763873848995
37 -0.612763873848995
3.75433799163164
38 3.75433799163164
-0.612747718105886

2.4
Fixed-Point Iteration
105
39 -0.612747718105886
3.75435070200217
40 3.75435070200217
-0.612756721944439
[
... OMITTED ...]
87 -0.612753499771556
3.75434615336968
88 3.75434615336968
-0.612753499778813
89 -0.612753499778813
3.75434615336397
90 3.75434615336397
-0.612753499774768
91 -0.612753499774768
3.75434615336715
92 3.75434615336715
-0.612753499777022
93 -0.612753499777022
3.75434615336537
94 3.75434615336537
-0.612753499775766
95 -0.612753499775766
3.75434615336636
96 3.75434615336636
-0.612753499776466
97 -0.612753499776466
3.75434615336581
98 3.75434615336581
-0.612753499776076
99 -0.612753499776076
3.75434615336612
100 3.75434615336612
-0.612753499776293
In fact, we could see that the sequence seems to diverge.
The corresponding graph would look like:
Similar to the previous case, note from the graph that the ﬁxed point r is inside the interval
 
2 ; 3
4

.
And since f 0.x/ D 4x cos.x/4 sin x
x2
, we have that
ˇˇf 0.r/
ˇˇ 
min

2 x 3
4
ˇˇˇˇ
4x cos.x/  4 sin x
x2
ˇˇˇˇ D
ˇˇˇˇ
4x cos. 
2 /  4 sin 
2
. 
2 /2
ˇˇˇˇ D 16
2 > 1
hence the iteration method would not converge.

106
2
Solving Nonlinear Equations
Here come the Sage code of obtaining the previous graphs. For the ﬁrst one,
var(’x’)
f(x) = 2*sqrt(sin(x))
#interval is (a,b)
a = 0
b = 2.7
#plot the functions y=f(x) and y=x
allPlots = plot( f(x), (x, a, b) )
allPlots += plot( x, (x, a, b), color = ’black’)
x0=2.5
#plot the first vertical line
allPlots += line([(x0,0),(x0,f(x0))], color=’red’,
linestyle = "-.", thickness=3)
#plot the point of intersection with
y = f(x)
allPlots += list_plot(
[(x0,f(x0))]
, size = 50)
#plot the first horizontal
line
allPlots += line([(x0,f(x0)), (f(x0),f(x0))],
color=’red’, linestyle = "-.", thickness=3)
#plot the point of intersection with
y = x
allPlots += list_plot(
[ (f(x0) , f(x0)) ]
, size = 50)
x1=f(x0)
#plot the second vertical line
allPlots += line([(x1,f(x0)),(x1,f(x1))],
color=’red’, linestyle = "-." , thickness=3)
#plot the point of intersection with
y = f(x)
allPlots += list_plot(
[(x1,f(x1))]
, size = 50)
#plot the second horizontal
line
allPlots += line([(x1,f(x1)), (f(x1),f(x1))],
color=’red’, linestyle = "-.", thickness=3)
#plot the point of intersection with
y = x
allPlots += list_plot(
[(f(x1),f(x1))]
, size = 50)
x2=f(x1)
#plot the second vertical line
allPlots += line([(x2,f(x1)),(x2,f(x2))],
color=’red’, linestyle = "-." , thickness=3)
#plot the point of intersection with
y = f(x)
allPlots += list_plot(
[(x2,f(x2))]
, size = 50)

2.4
Fixed-Point Iteration
107
#plot the second horizontal
line
allPlots += line([(x2,f(x2)), (f(x2),f(x2))],
color=’red’, linestyle = "-.", thickness=3)
#plot the point of intersection with
y = x
allPlots += list_plot(
[(f(x2),f(x2))]
, size = 50)
#display the graph
show(allPlots)
For the second graph, we could just change the previous code with the corresponding function.
Below, we included more than three steps (we used 10); hence we felt the need to redesign our code.
And hence, we used the following Sage code,
var(’x’)
f(x) = 4*sin(x)/x
#interval is (a,b)
a = -1
b = 4
#plot the functions y=f(x) and y=x
allPlots = plot( f(x), (x, a, b) )
allPlots += plot( x, (x, a, b), color = ’black’)
x0=2.5
steps = 0
while steps<10:
#plot the first vertical line
allPlots += line([(x0,x0),(x0,f(x0))], color=’red’,
linestyle = "-.", thickness=3)
#plot the point of intersection with
y = f(x)
allPlots += list_plot(
[(x0,f(x0))]
, size = 50)
#plot the first horizontal
line
allPlots += line([(x0,f(x0)), (f(x0),f(x0))],
color=’red’, linestyle = "-.", thickness=3)
#plot the point of intersection with
y = x
allPlots += list_plot(
[ (f(x0) , f(x0)) ]
, size = 50)
steps = steps+1
x0=f(x0)
#display the graph
show(allPlots)
we would obtain:

108
2
Solving Nonlinear Equations
2.4.2
Pseudocode
function printFixedPoint(f, x0, maxSteps, almostZero )
{
#output the initial values
output ’#’,’\t’, ’xi’, ’\t\t\t’,’f(xi)’
output 0, x0, ’\t’, f(x0)
#then we compute the iterations and stop when we either
#get a "good" approximation or tried too many steps
steps = 0
while(
steps<maxSteps and
|x0-f(x0)|>almostZero )
{
steps = steps + 1
x0 = f(x0)
print steps, x0, ’\t’, f(x0)
}
if( |x0-f(x0)| <= almostZero )
{
output steps+1, x0, ’\t’, f(x0)
output ’----------------------’
output ’solution = ’, x0
}
else if (steps<maxSteps):
print ’ERROR: max number of steps!’
}

2.4
Fixed-Point Iteration
109
2.4.3
Sage Code
def printFixedPoint(f, x0, maxSteps, almostZero ):
#output the initial values
print ’#’,’\t’, ’xi’, ’\t\t\t’,’f(xi)’
print 0, x0, ’\t’, f(x0)
#then we compute the iterations and stop when we
# either get a "good" approximation or tried too many steps
x1 = f(x0)
steps = 0
while(
steps<maxSteps and
abs(x1-x0)>almostZero ) :
steps = steps + 1
print steps, x1, ’\t’, f(x1)
x0=x1
x1=f(x0)
if( abs(x1-x0)<= almostZero ) :
print steps+1, x1, ’\t’, f(x1)
print ’----------------------’
print ’solution = ’, x1
elif (steps<maxSteps):
print ’ERROR: max number of steps!’
For the example given above, one would only need to add
#define f(x)
f(x)= 2*sqrt(sin(x))
#choose a starting point
x0 = 2.0
#choose the max number of iterations
maxSteps = 100
#choose what makes an approx acceptable
almostZero = 0.00001
#call the main function
printFixedPoint(f, x0, maxSteps, almostZero)
2.4.4
Examples
Example 67. Solve x2  x  7 D 0, correct to three decimal places.

110
2
Solving Nonlinear Equations
Solution. The problem is equivalent to x D xC7
x . Hence we use f .x/ D 1 C 7
x . Let’s choose some
starting value, say x0 D 3:0. Then we have
x1 D 1 C 7
x0
' 3:33333333333333
x2 D 1 C 7
x1
D 3:1
x3 D 1 C 7
x2
' 3:25806451612903
x4 D 1 C 7
x3
' 3:14851485148515
: : :
x16 D 1 C 7
x15
D 3:19209328550934
x17 D 1 C 7
x16
D 3:19291836857552
and hence
x ' 3:192:
A similar work can be done to ﬁnd the second solution.
Compare the previous answer with the exact solution, obtained from using quadratic formula
x D 1 
p
29
2
' 2:19258240357;
x D 1 C
p
29
2
' 3:19258240357:
Using the Sage code above and adding
#define f(x)
f(x)= 1+7/x
#choose a starting point
x0 = 3.0
#choose the max number of iterations
maxSteps = 100
#choose what makes an approx acceptable
almostZero = 0.001
#call the main function
printFixedPoint(f, x0, maxSteps, almostZero)
or simply
f(x)= 1+7/x
printFixedPoint(f, 3.0, 100, 0.001)

2.4
Fixed-Point Iteration
111
we obtain
#
xi
f(xi)
0 3.00000000000000
3.33333333333333
1 3.33333333333333
3.10000000000000
2 3.10000000000000
3.25806451612903
3 3.25806451612903
3.14851485148515
4 3.14851485148515
3.22327044025157
5 3.22327044025157
3.17170731707317
6 3.17170731707317
3.20701322669948
7 3.20701322669948
3.18271628620756
8 3.18271628620756
3.19937920019287
9 3.19937920019287
3.18792445721283
10 3.18792445721283
3.19578603381337
11 3.19578603381337
3.19038443936350
12 3.19038443936350
3.19409294805755
13 3.19409294805755
3.19154549157906
14 3.19154549157906
3.19329475906566
15 3.19329475906566
3.19209328550934
16 3.19209328550934
3.19291836857552
17 3.19291836857552
3.19235169583210
              
solution = 3.19291836857552
Before we run Sage, we should ﬁrst verify the conditions of Theorem 65 (see page 102). Note that
both, f .x/ D 1 C 7
x , and f 0.x/ D  7
x2 are continuous on Œ3; 3:5, and 3  f .x/  3:5. Also
max
axb
ˇˇf 0.x/
ˇˇ D
max
3x3:5
7
x2 D 7
9 < 1
hence any value from the interval Œ3; 3:5 would lead to a convergent sequence of iterations.
2.4.5
Sage Library
If we wish to solve the previous problem using Sage Library functions, we could use the code given
below
Example 68. Solve x2  x  7 D 0, correct to three decimal places.
Solution. The problem is equivalent to x D xC7
x . Hence we use f .x/ D 1 C 7
x . Let’s choose some
starting value, say x0 D 3:0. Then using
#import the following library
import scipy.optimize
#the function f(x) from our problem
def f(x):
return
1+7/x
#if no derivative of f is given
#then newton becomes secant method!

112
2
Solving Nonlinear Equations
###################################
#call the fixed_point method and output the result
print "solution = " , scipy.optimize.fixed_point(f,[3.0])
we obtain
solution =
[ 3.1925824]
If we wish to ﬁnd both solutions, using the Fixed-Point Iteration, then we could use the following
code
#import the following library
import scipy.optimize
#the function f(x) from our problem
def f(x):
return
1+7/x
#if no derivative of f is given
#then newton becomes secant method!
###################################
#call the fixed_point method and output the result
print "solutions: " , scipy.optimize.fixed_point(f,[3.0, -3.0])
to obtain
solutions:
[ 3.1925824 -2.1925824]
2.5
An Application to Business
Suppose we need to borrow $200,000 in order to be able to buy a new home. But our monthly salary
only allows us to pay around $800 per month. Assume a 30-year mortgage, and the following formula
PV D PMT
	1  .1 C i/n
i

;
(2.7)
given in [2, p. 159], where
PV D present value of all payments,
PMT D periodic payment,
i D rate per period,
n D number of periods.
What annual interest rates can we afford to pay?
Solution. Using the information given above, we would ﬁrst need to solve for i—the monthly
interest rate, from the equation
200;000 D 800
	1  .1 C i/3012
i

;

2.6
Exercises
113
or
250i  1 C .1 C i/360 D 0:
How would you solve for i in this equation?
Using one of the methods we learned in this chapter, solving this equation should not be too
challenging. For example, if we choose to use the Newton–Raphson’s Method, we would use the
following Sage code:
#define f(x)
var(’x’)
f(x)= 250*x-1+(1+x)^(-360)
#compute f’(x)
fp(x)=diff(f(x),x)
#choose a starting point
x0=3.0
#choose the max number of iterations
maxSteps = 100
#choose what makes an approx acceptable
almostZero = 0.000000001
#call the function
printNewtonRaphson(f, fp, x0, maxSteps, almostZero)
and obtain the following monthly interest rate i D 0:00216126116310383.
Hence, we would conclude that the maximum annual interest rate r that we can afford would be
r D 0:00216126116310383  12 D 0:02593513395724596;
or approximately 2:59 %.
2.6
Exercises
1. Do ﬁve iterations (by hand) of the Bisection Method to compute a root of f .x/ D x3  3 in the
interval Œ0; 3. Then give an estimate of the error of approximation.
2. Using Bisection Method ﬁnd the largest root of f .x/ D x6  x  7, accurate to within 0.001.
3. Using Bisection Method ﬁnd all the root of f .x/ D x3  2x C 2, accurate to within 0.0001.
4. Find all the roots of f .x/ D 2  x2ex, accurate to within 0.0001.
5. Find the points of intersection of the curves y D 5x2 and y D ex by ﬁnding the zeros of
ex  5x2 D 0 correct to ﬁve decimal places.
6. How many steps of the Bisection Method are needed to compute a root of 3:7x87:5x3C3x10:3
in the interval Œ1:5; 0:5 with precision of 10 decimal places?
7. How many steps of the Bisection Method are needed to compute a root of 3:7x87:5x3C3x10:3
in the interval Œ1:5; 0:5 with an error of approximation less than 0.00005?

114
2
Solving Nonlinear Equations
8. How many steps of the Bisection Method are needed to compute a root of 3:7x87:5x3C3x10:3
in the interval Œ1:5; 0:5 with an error of approximation less than 1017?
9. How many steps of the Bisection Method are needed to compute a root of the equation x D ex
in the interval Œ1; 1 with an error tolerance of 104?
10. Using Newton Method, solve the equation f .x/ D x6  x  7.
11. Find the three points of intersection of the following graphs: y D 3  x4 and y D 1
x .
12. Use Newton Method to compute
p
7.
13. Using previous example, ﬁnd the Newton’s Iteration formula for computing pa.
14. Using Newton method, develop a strategy to ﬁnd the value of ln 7, correct to ﬁve decimal places.
15. Find the zeros of f .x/ D x3 C4x2 7 using Newton’s Method, correct to two signiﬁcant ﬁgures.
16. Find the solution of x D 2 sin x using four steps of the Newton’s Method.
17. Using Secant Method, ﬁnd the solution of cos x D x, accurate to within 0.0001.
18. Using Secant method, develop a strategy to ﬁnd the value of ln 7, correct to ﬁve decimal places.
19. Using Fixed-Point Iteration, develop a strategy to solve x2  x  2 D 0; correct to three decimal
places.
20. Using Fixed-Point Iteration, solve x2  4 sin x D 0, correct to three decimal places.
21. Decide whether or not you can ﬁnd the solution of x2 D 5 using the Fixed Point Iteration method
applied to f .x/ D  x2
5 C x C 1. Include a complete argument for your answer.
22. Decide whether or not you can ﬁnd the solution of x2 D 5 using the Fixed Point Iteration method
applied to f .x/ D x2 C x C 5. Include a complete argument for your answer.
23. Decide whether or not you can ﬁnd the solution of x2 D 5 using the Fixed Point Iteration method
applied to f .x/ D 5
x . Include a complete argument for your answer.
2.7
Computer Exercises
For all these problems, you are expected to use Sage. Make sure to include a conclusion with your
answer.
1. Using Bisection Method ﬁnd the largest root of f .x/ D x6  x  7, accurate to within 0.000001.
2. Using Bisection Method, ﬁnd a solution of the equation x3 D 3x  1 in [0, 1], with an error less
than 0:00000025.
3. Using Bisection Method, ﬁnd a solution of the equation x3 D 2 sin.x/ in [0.5, 2], with an error
less than 0:00000025.
4. Using Bisection Method, ﬁnd a solution of the equation x D ex in [0, 1], with accuracy within
106.
5. Find all the root of f .x/ D 2  x2ex, accurate to within 0.0000001.
6. Find the points of intersection of the curves y D x4  10 and y D ln.x/ by ﬁnding the zeros of
x4  10  ln.x/ D 0 correct to seven decimal places.
7. Using Bisection Method ﬁnd all the root of f .x/ D x3  2x C 2, accurate to within 0.0001.
8. Using Newton Method ﬁnd the largest root of f .x/ D x6  x  7.
9. Find the three points of intersection of the following graphs: y D 3  x4 and y D 1
x . Include a
graph.
10. Use Newton Method to compute
p
7, correct to seven decimal places.
11. Find the zeros of f .x/ D x3 C 4x2  7 using Newton’s Method, correct to seven signiﬁcant
ﬁgures.
12. Find the solution of x D 2 sin x using ten steps of the Newton’s Method.
13. Find the solution of sin x D ex  2 using ten steps of the Newton’s Method.
14. Find the root for x3  x sin x C 6 using ten steps of the Newton’s Method.

References
115
15. Use Newton’s Method to compute
p
3 with 100 decimal places of accuracy. Note: you may need
to modify the Sage code given so that it will carry all the operations with sufﬁcient signiﬁcant
digits.
16. Using Secant Method, ﬁnd the solution of cos x D x, accurate to within 0.0001.
17. Using Secant Method, ﬁnd both solutions of cos x D x2, accurate to within 0.0000001.
18. Find all solutions of the equation ex D 1 C x C x2
2 C x3
3 , accurate to within 0.0000001.
19. Using Fixed-Point Iteration, develop a strategy to solve x2  x  2 D 0, correct to six decimal
places.
20. Using Fixed-Point Iteration, solve x2  4 sin x D 0, correct to six decimal places.
21. Using Fixed Point Iteration method, compute the ﬁrst ten iterations for f .x/ D 1 C 2
x , with
x0 D 1.
22. Try to solve these problems using Sage Library functions.
23. Suppose you need to borrow $150,000 in order to be able to buy a new home. But your monthly
salary only allows us to pay around $650 per month. Assuming a 30-year mortgage, and the
formula (2.7) given on page (112), what annual interest rates could you afford to pay?
24. Suppose you need to borrow $150,000 in order to be able to buy a new home. But your monthly
salary only allows us to pay around $800 per month. Assuming a 20-year mortgage, and the
formula (2.7) given on page (112), what annual interest rates could you afford to pay?
25. Suppose you need to borrow $450,000 in order to be able to buy a new home. But your monthly
salary only allows us to pay around $1,500 per month. Assuming a 30-year mortgage, and the
formula (2.7) given on page (112), what annual interest rates could you afford to pay?
References
1. Atkinson, K., Han, W.: Elementary Numerical Analysis, 3rd edn. Wiley, New York (2003)
2. Barnett, R., Ziegler, M., Byleen, K. Finite Mathematics for Business, Economics, Life Sciences, and Social Sciences
(11th ed.). Pearson Prentice Hall, Boston, MA (2008)
3. Blanco-Silva, F.J.: Learning SciPy for Numerical and Scientiﬁc Computing. Packt Publishing, Birmingham (2013)
4. Cheney, W., Kincaid, D.: Numerical Mathematics and Computing, 7th edn. Brooks/Cole: Cengage Learning, Boston
(2013)
5. Epperson, J.F.: An Introduction to Numerical Methods and Analysis, revised edn. Wiley, Hoboken (2007)
6. Stein, W.A., et al.: Sage Mathematics Software (Version 6.3), The Sage Development Team (2014). Sage ofﬁcial
webpage: http://www.sagemath.org
7. Sage Cell Server: http://sagecell.sagemath.org/
8. Stein, W.A.: Sage for Power Users (2012). http://www.wstein.org/books/sagebook/sagebook.pdf
9. Sullivan, M., Miranda, K.: Calculus – Early Transcendentals. W.H. Freeman and Company, New York (2014)

Chapter 3
Polynomial Interpolation
In this chapter we will deal with the following type of problems (see also [1, 4, 5]): suppose you are
given a set of data points,
x0 x1 x2 : : : xn
y0 y1 y0 : : : yn
; n  1:
Can you ﬁnd a function whose graph passes through every one of the points? That is, can you ﬁnd
a function p such that p.x0/ D y0; : : : ; p.xn/ D yn‹
The process of ﬁnding and evaluation such a function is what we call interpolation. x0; x1; : : : ; xn
are called nodes.
The process of ﬁnding a polynomial that passes through a given set of data points is called
polynomial interpolation. This is the topic of the current chapter.
There are many reasons why we may want to use interpolation. For example, if you measure the
outside temperature every hour, then using interpolation you can estimate the outside temperature for
any minute of the day.
We can also apply this technique when we are missing some data and need some values to ﬁll in.
They are extensively used in Computer Science. Most image and video compression/decompression
algorithms use interpolation. Using various sampling techniques, we can compress images (“lossy”
compression), and then, using interpolation techniques, we can decompress them. Image restoration,
digital sounds, GPS coordination, video games, fonts, etc. all use interpolation techniques.
Interpolation techniques help us make the transition from discrete into continuous, and in particular,
from digital into analog.
Electronic supplementary material The online version of this chapter (doi:978-3-319-16739-8_3) contains supple-
mentary material, which is available to authorized users.
© Springer International Publishing Switzerland 2015
G.A. Anastassiou, R. Mezei, Numerical Analysis Using Sage, Springer Undergraduate
Texts in Mathematics and Technology, DOI 10.1007/978-3-319-16739-8_3
117

118
3
Polynomial Interpolation
3.1
Interpolation
In this chapter, for simplicity, by polynomial of degree n; n  1, we mean a function p.x/ D
anxn C an1xn1 C    C a1x C a0 where a0; a1; : : : ; an are constants, and some of them (if not all!)
can be zero. This is somewhat different than most of the other Mathematics subjects, where such a
polynomial is said to be of degree at most n, but this is a common notation in Numerical Analysis
language.
IMPORTANT NOTE: Throughout this chapter, we will assume that all the nodes x;
is are distinct.
3.1.1
Linear Interpolation
Perhaps the simplest polynomial interpolation is the linear interpolation. Given two points .x0; y0/
and .x1; y1/, we need to ﬁnd the linear function p.x/ D a1xCa0 that passes through these two points.
That means, p.x0/ D y0 and p.x1/ D y1.
Since p.x/ is, in this case, a linear function, and since we are given two points, .x0; y0/ and
.x1; y1/, the polynomial p.x/ is the unique line that passes through the given points. Therefore a1 D
y1y0
x1x0 is the slope of the line, and a0 D y1  a1x1. Hence
p.x/ D a1x C a0
(3.1)
D y1  y0
x1  x0
 x C y1  y1  y0
x1  x0
 x1
D
	 x  x1
x0  x1

 y0 C
	 x  x0
x1  x0

 y1:
(3.2)
At this point, formula (3.1) may seem more intuitive than its equivalent form (3.2), but the latter will
be easier to use and memorize once we go to quadratic and higher degree interpolation. To anticipate,
the form in (3.2) is called Lagrange Form (see the subsection Lagrange Form below).
Example 69. You are given the following data points
x
2
8
y
1
3 . Find the linear function that
interpolates this table.
Solution. Using formula (3.2) we obtain
p.x/ D
	x  8
2  8

 1 C
	x  2
8  2

 3
D 1
3x C 1
3:
Hence, if you wish to estimate the value of y for x D 7:5, we get p.7:5/ D 1
37:5C 1
3 D 8:5
3 ' 2:83333.

3.1
Interpolation
119
The graph above was given by the Sage code (see also [2, 3, 6–8]):
#given points
x0 = 2
y0 = 1
x1 = 8
y1 = 3
#compute the linear interpolation
p(x)=(((x-x1)/(x0-x1)))*y0+(((x-x0)/(x1-x0)))*y1
#graph the linear interpolation
pl=plot(p(x),
(x,-1,10),
legend_label =
"
p(x) = "+str(p(x)))
pl += list_plot([(x0,p(x0)),(x1,p(x1))],
color = ’black’, size = 70)
pl+= text( ’(x0,y0)’ , ( x0, p(x0)-0.3 ),
fontsize = 14, color = ’black’)
pl+= text( ’(x1,y1)’ , ( x1, p(x1)-0.3 ),
fontsize = 14, color = ’black’)
show(pl)
In the next graph, we will include both the polynomial of interpolation, p.x/, and the function
f .x/ D log2 x (this is where our data points came from!).

120
3
Polynomial Interpolation
2
1
–1
–2
–3
–4
2
4
6
8
10
p(x) = 1/3*x + 1/3
f(x) = log2(x)
(x0,y0)
(x1,y1)
Please note that the linear function will provide fairly good estimations for values of x close to the
nodes (x0 or x1/. For values of x further away from these nodes, the estimations can be quite bad.
In our example, we obtained that p.7:5/ ' 2:83333, while log2.7:5/ ' 2:90689. On the other side,
p.5/ D 2, and log2.5/ ' 2:321928, hence the error of approximation is about ﬁve times higher in
this case.
Another note, which may be obvious: if the original function f is a linear function, then the linear
interpolation will be equal to f, p.x/ D f .x/. We say that linear interpolation is exact for linear
functions.
Example 70. Knowing that
p
109 ' 10:4403 and
p
111 ' 10:5356, estimate
p
110.
Solution. Using formula (3.2) we obtain
p.x/ D
	 x  111
109  111

 10:4403 C
	 x  109
111  109

 10:5356
D 0:04765x C 5:24645
hence
p
110 ' 0:04765  110 C 5:24645
D 10:48795:
For comparison, the true value is
p
110 ' 10:48808.
3.1.2
Quadratic Interpolation
For this type of interpolation, we are given three points .x0; y0/; .x1; y1/, and .x2; y2/, and we’ll need
to ﬁnd the quadratic function p.x/ D a2x2 C a1x C a0 that passes through all of these three points.
That means, p.x0/ D y0, p.x1/ D y1 and p.x2/ D y2.
Note again that here, by quadratic function, we mean a function of the form f .x/ D ax2 C bx C c,
where a; b; c are constants and they can all be zero. In particular, if the given data points are on a
straight line, then the “quadratic function” turns out to be a line.

3.1
Interpolation
121
To ﬁnd the coefﬁcients a0; a1, and a2, one can solve the following system of equations
8
<
:
a2x2
0 C a1x0 C a0 D y0
a2x2
1 C a1x1 C a0 D y1
a2x2
2 C a1x2 C a0 D y2
:
Then the interpolating function is given by: p.x/ D a2x2 C a1x C a0.
Next we’ll give you another way to ﬁnd p.x/ D a2x2 C a1x C a0 and these formulae will be
consistent to the following subsection, Lagrange Formula. The motivation for these formulae will
be presented in the next subsection and hence many of the details will be included there, and omitted
here. We have that
p.x/ D y0L0.x/ C y1L1.x/ C y2L2.x/;
(3.3)
where
L0.x/ D
	 x  x1
x0  x1

 	 x  x2
x0  x2

(3.4)
L1.x/ D
	 x  x0
x1  x0

 	 x  x2
x1  x2

L2.x/ D
	 x  x0
x2  x0

 	 x  x1
x2  x1

are called Lagrange Basis Polynomials.
It should be easy to check that p.x/ is quadratic function (since it is a linear combination of such
polynomials) and that it interpolates the given data: p.x0/ D y0, p.x1/ D y1, and p.x2/ D y2.
Let’s see some examples.
Example 71. You are given the following data points
x
2
4
8
y
1
2
3 . Find the quadratic function
that interpolates this table.
Solution. Using formula (3.4) we get
L0.x/ D
	x  4
2  4

 	x  8
2  8

D 1
12.x2  12x C 32/
L1.x/ D
	x  2
4  2

 	x  8
4  8

D 1
8.x2  10x C 16/
L2.x/ D
	x  2
8  2

 	x  4
8  4

D 1
24.x2  6x C 8/
and hence, by (3.3) we obtain
p.x/ D L0.x/ C 2L1.x/ C 3L2.x/
D  1
24x2 C 3
4x  1
3:
Below we include a graph for our interpolating polynomial.

122
3
Polynomial Interpolation
Hence, if you wish to estimate the value of y, for x D 7:5, we get p.7:5/ D  1
24 7:52C 3
4 7:5 1
3 D
283
96 ' 2:94791.
In the next graph, we will include both, the quadratic polynomial of interpolation, p.x/, and the
function f .x/ D log2 x (this is where our data points came from!). As you can see, the quadratic
polynomial of interpolation seems to follow more closely the function f .x/ D log2 x, than the linear
polynomial obtained in the previous subsection. Hence we will expect that in the case of quadratic
interpolation to obtain better estimates.
In this case we have: p.7:5/ ' 2:94791, compared to the correct value of log2.7:5/ ' 2:90689,
and p.5/ D
19
8
D 2:375, compared to log2.5/ ' 2:3219. Compare these results with the ones
obtained in Example 69.
Later in this chapter we will discuss more about the error estimates.
Example 72. Knowing that
p
109 ' 10:4403,
p
111 ' 10:5356, and
p
112 ' 10:5830, estimate
p
110.
Solution. Using formula (3.3) we obtain
p.x/ ' 0:00008333x2 C 0:06598333x C 4:2382
hence
p
110 ' 10:48807:

3.1
Interpolation
123
For comparison, the true value is
p
110 ' 10:48808. As we can see, we obtained a much better
estimate than in the Example 70.
3.1.3
Lagrange Formula
We consider here the general case. Given the set of n C 1 data points,
x0 x1 x2 : : : xn
y0 y1 y0 : : : yn
we want to ﬁnd the polynomial function of degree (at most) n,
p.x/ D anxn C an1xn1 C    C a1x C a0
such that p.x/ interpolates these points. That is:
p.x0/ D y0; p.x1/ D y1; : : : ; p.xn/ D yn:
For this, let us start by deﬁning the Lagrange Basis Polynomials, L0.x/, L1.x/, : : :, Ln.x/, each
of degree (exactly) n:
Li.x/ D
n
Y
jD0;j¤i

x  xj


xi  xj
; for
i D 0; 1; : : : ; n:
(3.5)
D
.x  x0/  .x  x1/      .x  xi1/  .x  xiC1/      .x  xn/
.xi  x0/  .xi  x1/      .xi  xi1/  .xi  xiC1/      .xi  xn/:
Please note that the denominators given in the previous formula, are product of constant numbers,
hence they are constant. Therefore the fact that each one of these Lagrange Basis Polynomials has
degree exactly n should be trivial. They also have the following very nice property:
Li.xj / D ıij D
 0; for i ¤ j
1; for i D j ; 0  i; j  n:
(3.6)
Hence, the polynomial
p.x/ D y0L0.x/ C y1L1.x/ C    C ynLn.x/;
(3.7)
will interpolate the data points given, and is called the interpolation polynomial of degree n; in the
Lagrange formula.
Since p.x/ is a linear combination of polynomials of degree n, it implies that p.x/ has degree at
most n (since some cancellation may occur when we add these terms).
To check that the polynomial p.x/ given in formula (3.7) interpolates the given set of data points,
we have:
p.x0/ D y0L0.x0/ C y1L1.x0/ C    C ynLn.x0/
D y0  1 C y1  0 C    C yn  0
D y0;

124
3
Polynomial Interpolation
p.x1/ D y0L0.x1/ C y1L1.x1/ C    C ynLn.x1/
D y0  0 C y1  1 C    C yn  0
D y1;
and in general:
p.xi/ D y0L0.xi/ C y1L1.xi/ C    C ynLn.xi/
D yi  1
D yi:
In particular, for n D 1, we obtain the linear interpolation formula given in (3.2). For n D 2, we
get the quadratic interpolation formula given in (3.3). Hence, each of the previous two subsections is
a particular case of this current subsection.
Example 73. Find the polynomial that interpolates the following data points:
x 2 4 8 16
y 1 2 3 4 :
Solution. We have
L0.x/ D .x  4/  .x  8/  .x  16/
.2  4/  .2  8/  .2  16/
D  1
168x3 C 1
6x2  4
3x C 64
21:
We could also use Sage to simplify this, using the following code:
f(x) = (((x-4)*(x-8)*(x-16))/((2-4)*(2-8)*(2-16)))
f.full_simplify()
to obtain:
x j   > -1/168*x^3 + 1/6*x^2 - 4/3*x + 64/21
Similarly,
L1.x/ D .x  2/  .x  8/  .x  16/
.4  2/  .4  8/  .4  16/
D 1
96x3  13
48x2 C 11
6 x  8
3;
L2.x/ D .x  2/  .x  4/  .x  16/
.8  2/  .8  4/  .8  16/
D  1
192x3 C 11
96x2  13
24x C 2
3;

3.1
Interpolation
125
L3.x/ D
.x  2/  .x  4/  .x  8/
.16  2/  .16  4/  .16  8/
D
1
1344x3  1
96x2 C 1
24x  1
21:
Hence, the polynomial of interpolation is given by
p.x/ D L0.x/ C 2L1.x/ C 3L2.x/ C 4L3.x/
D
1
448x3  7
96x2 C 7
8x  10
21:
Example 74. Find the polynomial that interpolates the following data points:
x 1 2 3 4
y 2 4 6 8 :
Solution. We have
L0.x/ D .x  2/  .x  3/  .x  4/
.1  2/  .1  3/  .1  4/
D 1
6x3 C 3
2x2  13
3 x C 4
L1.x/ D .x  1/  .x  3/  .x  4/
.2  1/  .2  3/  .2  4/
D 1
2x3  4x2 C 19
2 x  6
L2.x/ D .x  1/  .x  2/  .x  4/
.3  1/  .3  2/  .3  4/
D 1
2x3 C 7
2x2  7x C 4
L3.x/ D .x  1/  .x  2/  .x  3/
.4  1/  .4  2/  .4  3/
D 1
6x3  x2 C 11
6 x  1
Hence, the polynomial of interpolation is given by
p.x/ D 2L0.x/ C 4L1.x/ C 6L2.x/ C 8L3.x/
D 2x:
Notice how every one of the Lagrange Basis Polynomials have degree 3, but in the end, once we
compute the linear combination, the polynomial of interpolation p.x/ has degree 1.

126
3
Polynomial Interpolation
By construction we can see the existence of a polynomial of interpolation, of degree (at most) n,
for any given set of n C 1 data points,
x0 x1 x2 : : : xn
y0 y1 y0 : : : yn
:
This can also be proven by induction (which will lead to another formula that can be used for the
polynomial of interpolation: Newton Formula).
The uniqueness can also be proven: given set of n C 1 data points, there is one, and only one,
polynomial of degree at most n that interpolates them.
Both, the existence and the uniqueness will be proven below.
3.1.4
Sage Code for Lagrange Formula
Below we give the Sage implementation for computing the Lagrange formula of the polynomial
interpolation given a set of n C 1 data points:
x0 x1 x2 : : : xn
y0 y1 y0 : : : yn
:
We start with some explanation of the code. First, we put those values into a two-dimensional array
(or, an array of pairs in this case). For more details on how to work with arrays, please check the
examples we provided on page 35.
To simplify the code, we chose to use points and n as global variables, rather than parameters of
the functions that use them. If you are somewhat experienced with programming, you may choose to
follow the better programming practice and send these values as parameters. We hope that simplifying
the code will help you better understand the code and focus more on the Mathematical model.
Next we compute n, from this array, so that everything that comes next will be computed
automatically from the given array. That is, you only need to change the values in the array points,
and the algorithm will work without having to change anything else.
Then we implemented the function L that computes the Lagrange Basis Polynomials. For example,
you want to get L0.x/, you only need to call the function L.0; x/.
Last function that we implemented, Lagrange_Interpolation.x/, will compute the interpola-
tion polynomial p.x/ using Lagrange formula.
For example, let’s assume we are given the following data
x 1 2 3 4
y 3 6 9 12 :
#the array of data points given
points = [(1,3), (2,6), (3,9), (4,12)]
#we compute n from the size of the array
n = len(points)-1
#compute the Lagrange Basis Polynomials
def L(i, x):
#initial value before a repeated product

3.1
Interpolation
127
Li=1
for j in range(n+1) :
if(i!=j):
#we repeatedly multiply by (x-xj)/(xi-xj)
Li=Li*(x-points[j][0])/(points[i][0]-points[j][0])
return Li
#compute the Lagrange interpolation polynomial
def Lagrange_Interpolation(x):
#initial value before a repeated sum
p=0
for i in range(n+1):
#we repeatedly add by yi*Li(x)
p = p + points[i][1]*L(i,x)
#simplify the answer before we return it
return p.full_simplify()
#output the Lagrange interpolation polynomial
Lagrange_Interpolation(x)
Then the output should be:
3*x
In the previous example, if you wanted to change the previous code, so that it will print all the
Lagrange Basis Polynomials, you would only have to include one line of code
print "L"+ str(i) +"(x) = "+ str(Li)
inside the deﬁnition of the L(i,x) function like below:
#compute the Lagrange Basis polynomials
def L(i, x):
#initial value before a repeated product
Li=1
for j in range(n+1) :
if(i!=j):
#we repeatedly multiply by (x-xj)/(xi-xj)
Li=Li*(x-points[j][0])/(points[i][0]-points[j][0])
print "L"+ str(i) +"(x) = "+ str(Li)
return Li
and, leaving everything else unchanged. Then you would get the following output:
L0(x) = -1/6*(x - 2)*(x - 3)*(x - 4)
L1(x) = 1/2*(x - 1)*(x - 3)*(x - 4)
L2(x) = -1/2*(x - 1)*(x - 2)*(x - 4)
L3(x) = 1/6*(x - 1)*(x - 2)*(x - 3)
3*x

128
3
Polynomial Interpolation
In the previous example, instead of printing the polynomial of interpolation p.x/, let’s say you
wanted to compute p.2:75/. Then you could, for example, replace the last line of Sage code
Lagrange_Interpolation(x)
with
p(x) = Lagrange_Interpolation(x)
p(2.75)
You would get:
8.25000000000000
You could also simply use
Lagrange_Interpolation(2.75)
to get the same output, but you would have to remove the part of code .full_simplify()
from the deﬁnition of the function Lagrange_Interpolation().
3.1.5
Newton Formula
The Lagrange’s formula of ﬁnding the interpolation polynomial is a fairly intuitive, and an easy to
understand and apply formula. For any given table of data points
x0 x1 x2 : : : xn
y0 y1 y0 : : : yn
:
we could easily compute the polynomial of interpolation.
Lagrange Formula has a challenge. Suppose you want to add a new data point to the given table of
points. How would you ﬁnd the new polynomial of interpolation? Using Lagrange form you would
have to do the entire work again, to ﬁnd this new polynomial. You could not take advantage of the
previous work done to ﬁnd the polynomial of interpolation for the old list. Newton’s formula will
be able to overcome this challenge and take advantage of knowing the polynomial of interpolation
found before adding the new data point. That is: Newton Formula can easily extend the polynomial
of interpolation when adding more data points. Also, Newton Formula will be more suitable in actual
computations, since it generally uses less operations.
It should be noted that both Newton formula and Lagrange formula give us the very same
polynomial of interpolation (an obvious truth given its uniqueness).
The proof of the next theorem gives us the motivation behind the Newton Formula.
Theorem 75. Given any set of data points
x0 x1 x2 : : : xn
y0 y1 y0 : : : yn
:
with all x;
is distinct, there is a unique polynomial p.x/, of degree at most n, that interpolates the given
set. That is p.x0/ D y0; p.x1/ D y1; : : : ; p.xn/ D yn, n  0.
Proof.
Part 1: Existence.
We can easily prove this by induction, over n.
For veriﬁcation step, for n D 0 we have that p.x/ D y0 is a polynomial of degree 0 (constant
function) that interpolates the given set.

3.1
Interpolation
129
Although not needed, we also include the case n D 1. Here
p.x/ D
	 x  x1
x0  x1

 y0 C
	 x  x0
x1  x0

 y1
is a polynomial of degree at most 1 (linear function) that interpolates the given set.
For the induction step, let’s assume that given any set of k C 1 data points, k  0, we can always
ﬁnd an interpolation function p.x/ of degree at most k. Let’s prove that we can also ﬁnd one for
any given set of k C 2 data points.
Let’s suppose we are given the following k C 2 data points:
x0 x1 x2 : : : xk xkC1
y0 y1 y0 : : : yk ykC1
:
Then, by the assumption of the induction step, we can ﬁnd a polynomial p.x/ of degree at most k
such that p.x0/ D y0, p.x1/ D y1; : : : ; p.xk/ D yk. We need to construct polynomial q.x/ such that
q.x0/ D y0, q.x1/ D y1; : : : ; q.xkC1/ D ykC1 and q.x/ has degree at most k C 1. For this, let
q.x/ D p.x/ C c.x  x0/ .x  x1/    .x  xk/
(3.8)
where c is a constant to be determined such that q.xkC1/ D ykC1. Using basic algebra we can easily
ﬁnd that:
c D
ykC1  p.xkC1/
.xkC1  x0/ .xkC1  x1/    .xkC1  xk/:
(3.9)
Then, it is an easy task to check that q.x/ interpolates all the k C 1 data points. Since p.x/ is a
polynomial of degree at most k, and .x  x0/ .x  x1/    .x  xk/ is a polynomial of degree k C 1,
we can see that q.x/ D p.x/ C c.x  x0/ .x  x1/    .x  xk/ has degree at most k C 1.
Part 2: Uniqueness.
This part is left as an exercise.

The following formula is what we will call Newton interpolation formula
p.x/ D c0 C c1 .x  x0/ C c2 .x  x0/ .x  x1/
Cc3 .x  x0/ .x  x1/ .x  x2/ C   
Ccn .x  x0/ .x  x1/ .x  x2/    .x  xn1/
(3.10)
Let’s see through an example, how we can obtain a polynomial of interpolation for a given set of
data points. We’ll use the same technique as in the proof of the previous Theorem. This is known as
the Newton Algorithm.
Example 76. Using Newton Algorithm, ﬁnd the polynomial of least degree that interpolates the
following data points:
x 2 4 8 16
y 1 2 3 4 :
Proof. We will repeatedly use the formulae (3.8) and (3.9) to obtain our answer.

130
3
Polynomial Interpolation
Looking at the ﬁrst data point, .2; 1/, we can easily construct a polynomial that interpolates it:
p0.x/ D 1.
Next step is to ﬁnd a polynomial that interpolates the ﬁrst two data points, .2; 1/ and .4; 2/. For
this, we ﬁrst compute
c1 D y1  p0.x1/
x1  x0
D 2  1
4  2 D 1
2;
and obtain the new interpolating function
p1.x/ D p0.x/ C c1.x  x0/
D 1 C 1
2 .x  2/ :
Then, we will look for the polynomial that interpolates the ﬁrst three data points. For this, we
ﬁrst ﬁnd
c2 D
y2  p1.x2/
.x2  x0/ .x2  x1/
D
3  4
.8  2/ .8  4/ D  1
24;
and then we have that
p2.x/ D p1.x/ C c2.x  x0/ .x  x1/
D 1 C 1
2 .x  2/  1
24 .x  2/ .x  4/ :
If we apply this procedure one more step we get
c3 D
y3  p2.x3/
.x3  x0/ .x3  x1/ .x3  x2/
D
4  p2.16/
.16  2/ .16  4/ .16  8/ D
3
1344
and conclude that
p3.x/ D p2.x/ C c3.x  x0/ .x  x1/ .x  x2/
D 1 C 1
2 .x  2/  1
24 .x  2/ .x  4/
C
3
1344 .x  2/ .x  4/ .x  8/ :
(3.11)
Although this answer looks different than
p.x/ D
1
448x3  7
96x2 C 7
8x  10
21;
obtained in Example 73 (page 124), after simplifying it you can see that they are actually the same.

3.1
Interpolation
131
If you want to let Sage simplify for you the polynomial given in (3.11) you can use:
p(x)= 1+(1/2)*(x-2)-(1/(24))*(x-2)*(x-4) +(3/(1344))*(x-2)
*(x-4)*(x-8)
p(x).full_simplify()
and obtain
1/448*x^3 - 7/96*x^2 + 7/8*x - 10/21
Let’s see what happens when the polynomial of interpolation for a given set of n C 1 data points
has a degree strictly less than n.
Example 77. Using Newton Algorithm, ﬁnd the polynomial of least degree that interpolates the
following data points:
x 2 3
5
8
y 8 12 20 32 :
Proof. We will, again, repeatedly use the formulae (3.8) and (3.9) to obtain our answer.
First, the constant polynomial that interpolates the point .2; 8/ is given by
p0.x/ D 8:
Then, adding the data point .3; 12/ we have:
c1 D 12  8
3  2 D 4
hence
p1.x/ D 8 C 4.x  2/
D 4x:
At this point, we could observe that p1.x/ interpolates all the other points, and hence (by uniqueness)
is the polynomial of interpolation for the entire table.
We will compute one more step to see what would happen in this special case, once we found our
polynomial of interpolation. The next step would be
c2 D
12  12
.5  2/ .5  3/ D 0
and hence
p2.x/ D p1.x/ C 0
D 4x:
and so on for the last data point (c3 D 0).

132
3
Polynomial Interpolation
3.1.6
Sage Code for Newton Formula
We give, below, our Sage implementation for the Newton’s algorithm. We start with some explanations
ﬁrst.
Given a set of data points, we will compute the polynomial of interpolation using Newton Formula.
As with the Sage code for Lagrange Formula, the code below is quite generic, in the sense that one
only needs to change the set of given data points, and the rest of the code will work unchanged.
For more details on how to use arrays, please check the examples we provided on page 35.
Like in the case of Lagrange formula, we again use a global array, called points, and a global
variable n. We challenge you to improve this code by using parameters rather than global variables.
In the implementation of Newton_Interpolation() function we started with the
polynomial that interpolates the very ﬁrst data point, p0.x/ D y0. Hence we used p(x) =
points[0][1].
Remember that points[0] gives you the very ﬁrst data point (which in this case is a pair .x; y/),
points[1]gives you the second data point, points[2]gives you the third data point, etc. For the
third (or any other) data point, you can access the x-coordinate using points[2][0], and the
y-coordinate using points[2][1].
When using the Newton formula, we’ll need to use an expression of the form .x 
x0/ .x  x1/ : : : .x  xk/.
We’ll
build
it
in
newTerm(x).
At
ﬁrst,
newTerm(x)=x-x0,
hence we initialize it using the code newTerm(x) = x-points[0][0]. Then, inside
the for loop, we repeatedly multiply it by .x  xk/, hence we used newTerm(x) =
newTerm(x)*(x-points[k][0]).
The Newton Formula is applied by using the for loop, which will repeatedly add a new data point
to our interpolation polynomial, and hence compute a new value for c, and updating the expression of
p.x/.
Let’s suppose we want to ﬁnd the polynomial of interpolation of least degree for the following
data set
x 1 2 3 4
y 3 6 9 12 :
then we would use the following Sage code:
#the array of data points given
points = [(2,1), (4,2), (8,3), (16,4)]
#we compute n from the size of the array
n = len(points)-1
#compute the Newton interpolation polynomial
def Newton_Interpolation(x):
#the very first step is computed here
#p0(x)=y0
p(x) = points[0][1]
#new term will be x-x0
#it will eventually store (xk-x0)(xk-x1)...(xk-xk-1)
newTerm(x) = x-points[0][0]
#for k in range(1,n+1):
for k in [1, 2, .., n]:

3.1
Interpolation
133
#we repeatedly add the new data point
#first compute the new c
c = ((points[k][1]-p(points[k][0])) / newTerm(points
[k][0]))
#and then add it to the interpolating function
p(x) = p(x) + c*newTerm(x)
#prepare for next iteration
newTerm(x) = newTerm(x)*(x-points[k][0])
#simplify the answer before we return it
return p
#call the function and find the final answer
Newton_Interpolation(x)
This will give you
x j   > 1/448*(x - 2)*(x - 4)*(x - 8) - 1/24*(x - 2)*(x - 4) + 1/2*x
If you want your answer to be fully simpliﬁed, you could replace the last line with
Newton_Interpolation(x).full_simplify()
to get
x j   > 1/448*x^3 - 7/96*x^2 + 7/8*x - 10/21
For a better visual representation, one can use the show method, and hence replace the last line
with
show( Newton_Interpolation(x).full_simplify() )
to obtain:
If one wants to also include a graph of the interpolating polynomial, then Sage code similar to the
following can be useful:
#plot the interpolating function
p = plot( Newton_Interpolation(x) , x, points[0][0]-1,points[n]
[0]+1)
#plot the points of the table
p += list_plot( points, color = ’black’, size = 70)
#display the plot
show(p)
#display the interpolating polynomial
Newton_Interpolation(x).full_simplify()
to obtain the graph and the interpolating polynomial:

134
3
Polynomial Interpolation
3.1.7
Divided Differences
Using Newton formula (see formula (3.10), on page 129), one can observe that the polynomial of least
degree that interpolates
x0 x1 x2 : : : xn
y0 y1 y0 : : : yn
is given by
p.x/ D c0 C c1.x  x0/ C c2.x  x0/ .x  x1/ C   
Ccn.x  x0/ .x  x1/    .x  xn1/ :
In this section, we’ll see how we can use divided differences to efﬁciently ﬁnd the coefﬁcients
c0; c1; : : : ; cn, and hence efﬁciently ﬁnd the polynomial of interpolation p.x/. For notation purposes,
let’s assume that y0 D f .x0/; y1 D f .x1/; : : : ; yn D f .xn/, for some function f . Then we
can use the following notation c0 D f Œx0; c1 D f Œx0; x1, c2 D f Œx0; x1; x2, : : :, cn D
f Œx0; x1; x2; : : : ; xn. The quantity f Œx0; x1; : : : ; xk will be called divided difference of order k
for f:
How would you normally solve for c0; c1; : : : ; cn‹ Using the fact that p.x0/ D y0, p.x1/ D y1,
: : :, p.xn/ D yn we could solve the following system of n C 1 equations
8
ˆˆˆˆˆ<
ˆˆˆˆˆ:
p.x0/ D y0
p.x1/ D y1
p.x2/ D y2
: : :
p.xn/ D yn
;
(3.12)

3.1
Interpolation
135
which is equivalent to
8
ˆˆˆˆˆˆˆ<
ˆˆˆˆˆˆˆ:
c0 D y0
c0 C c1.x1  x0/ D y1
c0 C c1.x2  x0/ C c2.x2  x0/ .x2  x1/ D y2
  
c0 C c1.xn  x0/ C c2.xn  x0/ .xn  x1/ C   
Ccn.xn  x0/ .xn  x1/    .xn  xn1/ D yn
;
(3.13)
hence
8
ˆˆˆ<
ˆˆˆ:
c0 D y0
c1 D y1c0
x1x0 D y1y0
x1x0
c2 D
y2y1
x2x1  y1y0
x1x0
x2x0
  
;
(3.14)
or
8
ˆˆˆ<
ˆˆˆ:
f Œx0 D y0
f Œx0; x1 D y1y0
x1x0 D f Œx1f Œx0
x1x2
f Œx0; x1; x2 D
y2y1
x2x1  y1y0
x1x0
x2x0
D f Œx1;x2f Œx0;x1
x2x1
  
:
(3.15)
Using Mathematical Induction, it can be shown that the divided differences of order k have the
following properties
1. f Œx0; x1; : : : ; xk stays the same if we interchange (permute) any of x0; x1; : : : ; xk.
2. it satisﬁes the following recursive formula
f Œx0; x1; : : : ; xk D f Œx1; x2; : : : ; xk  f Œx0; x1; : : : ; xk1
xk  x0
; for k  1
f Œxi D f .xi/; for i D 0; 1; : : : ; n:
(3.16)
A proof for each of these properties an be found in [1, p. 126] and [4, pp. 162–163].
To compute each of these divided differences, we could use a table such as the one below, and
formula (3.16)
x
f Œ
f Œ; 
f Œ; ; 
f Œ; ; ; 
x0 f Œx0 D f .x0/
f Œx0; x1 D f Œx1f Œx0
x1x0
x1 f Œx1 D f .x1/
f Œx0; x1; x2
f Œx1; x2 D f Œx2f Œx1
x2x1
f Œx0; x1; x2; x3
x2 f Œx2 D f .x2/
f Œx1; x2; x3
f Œx2; x3 D f Œx3f Œx2
x3x2
x3 f Œx3 D f .x3/

136
3
Polynomial Interpolation
Example 78. Use Divided Differences to ﬁnd the Newton form of the polynomial that interpolates
the following data points:
x 2 4 8 16
y 1 2 3 4 :
Proof. We will need to ﬁnd each of the following f Œx0, f Œx0; x1, f Œx0; x1; x2, and f Œx0; x1; x2; x3.
For this, using a table like the one above, we would get:
x f Œ
f Œ; 
f Œ; ; 
f Œ; ; ; 
2
1
21
42 D 1
2
4
2
1
4  1
2
82 D  1
24
32
84 D 1
4
. 1
96/. 1
24/
162
D
1
448
8
3
1
8  1
4
164 D  1
96
43
168 D 1
8
16
4
hence the Newton formula for the polynomial of interpolation of the given data points is given by
p.x/ D 1 C 1
2.x  2/  1
24.x  2/.x  4/ C
1
448.x  2/.x  4/.x  8/
which is consistent with the result we obtained in the previous subsections using the other methods.
Example 79. Use Divided Differences to ﬁnd the Newton form of the polynomial that interpolates
the following data points:
x 1 2 3 4
y 3 6 9 12 :
Proof. We will need to ﬁnd each of the following f Œx0, f Œx0; x1, f Œx0; x1; x2, and f Œx0; x1; x2; x3.
For this, using a table like the one above, we would get:
x f Œ
f Œ; 
f Œ; ; 
f Œ; ; ; 
1
3
63
21 D 3
2
6
33
31 D 0
96
32 D 3
00
41 D 0
3
9
33
42 D 0
129
43 D 3
4 12

3.1
Interpolation
137
hence the Newton formula for the polynomial of interpolation of the given data points is given by
p.x/ D 3 C 3.x  1/ C .x  1/.x  2/ C 0.x  1/.x  2/.x  3/
3x:
which is consistent with the result we obtained in the previous subsections using the other methods.
3.1.8
Sage Code for Divided Differences
We present, below, the Sage code that makes use of the divided differences presented above to compute
the coefﬁcients c0, c1, : : :, cn.
#the array of data points given
points = [(2,1),(4,2),(8,3), (16,4)]
#we compute n from the size of the array
n = len(points)-1
#computes the set of divided differences
def DividedDifferences():
#create an array n+1 by n+1
divDiff = [[0 for i in range(n+1)] for i in range(n+1)]
#first column will contain the y values
#this is column 0!
for row in [0,1,2,..,n]:
divDiff[row][0]=points[row][1]
#compute, recursively the div differences
#one column at a time
#in second column will have f[.]
#in third column will have f[.,.], etc
for column in [1,2,..,n]:
#for a column, compute the value in each row
for row in [0,1, 2, .., n-column]:
divDiff[row][column]=(divDiff[row+1][column-1]-
divDiff[row][column-1])/(points[row+column][0]-points[row][0])
return [divDiff[0][i] for i in [0,1,..,n]]
#call the function and find the final answer
DividedDifferences()
The output should be
[1, 1/2, -1/24, 1/448]
If you wish, you can modify the previous code as follows, so it will print the entire table of divided
differences.
#the array of data points given
points = [(2,1),(4,2),(8,3), (16,4)]

138
3
Polynomial Interpolation
#we compute n from the size of the array
n = len(points)-1
#computes the set of divided differences
def PrintDividedDifferencesTable():
#create an array n+1 by n+1
divDiff = [[0 for i in range(n+1)] for i in range(n+1)]
#first column will contain the y values
#this is column 0!
for row in [0,1,2,..,n]:
divDiff[row][0]=points[row][1]
#compute, recursively the div differences
#one column at a time
#in second column will have f[.]
#in third column will have f[.,.], etc
for column in [1,2,..,n]:
#for a column, compute the value in each row
for row in [0,1, 2, .., n-column]:
divDiff[row][column]=(divDiff[row+1][column-1]
-divDiff[row][column-1])/(points[row+
column][0]-points[row][0])
for row in [0,1, 2, .., n]:
print points[row][0],"\t|", [ divDiff[row][column]
for
column in [0,1,2,..,n-row]]
#call the function
PrintDividedDifferencesTable()
This will output
2
j [1, 1/2, -1/24, 1/448]
4
j [2, 1/4, -1/96]
8
j [3, 1/8]
16
j [4]
3.1.9
Inverse Interpolation
An interesting application of interpolation is approximating the inverse of a function. Suppose we are
given a set of n C 1 data points
x0 x1 x2 : : : xn
y0 y1 y0 : : : yn
:
Let’s assume they come from a function f .x/. That is y0 D f .x0/, y1 D f .x1/, etc.
Using the formulae we have seen in this chapter, we can ﬁnd the polynomial q.y/, of degree at
most n that interpolates the table

3.1
Interpolation
139
y0 y1 y2 : : : yn
x0 x1 x0 : : : xn
This polynomial, q.y/, can be used as an approximation for the inverse of the function f .x/.
Another application for the inverse interpolation is ﬁnding an approximate value for the root of
a function. Once you ﬁnd q.x/, under favorable conditions, computing q.0/ can give you a good
estimation of the solution of the equation f .x/ D 0.
Example 80. Find the inverse interpolation for the following set of data points
x 2 4 8 16
y 1 2 3 4 :
Solution. We can use Sage and apply the Newton’s Method to ﬁnd the polynomial of interpolation for
y 1 2 3 4
x 2 4 8 16 :
Then we get q.y/ D 1
3x3  x2 C 8
3x.
3.1.10
Sage Library
If you need to ﬁnd the polynomial of interpolation without willing to write your own code, the you
can use Sage library, which already contains a function that can be used to ﬁnd Lagrange Polynomial.
For example, one can write code similar to:
R = PolynomialRing(QQ, ’x’)
R.lagrange_polynomial([(0,
1),(1,
2.4),(2,
2.001),(3, 3.45)])
And obtain
0.607833333333333*x^3 - 2.72300000000000*x^2
+ 3.51516666666667*x + 1.00000000000000
Example 81. Use the Sage library to ﬁnd the polynomial of interpolation, p.x/, for
x 0 1 2 3 4
5
y 0 3 6 9 12 15 :
Solution. We could use the following Sage code
R = PolynomialRing(QQ, ’x’)
R.lagrange_polynomial([(0,
0),(1,
3),(2,
6),(3, 9), (4,12),
(5,15)])
This would yield the following result:
3*x
Example 82. Use Sage library functions to ﬁnd the polynomial of interpolation, p.x/, for the
following set of data points

140
3
Polynomial Interpolation
x 0 1
2
3 4
5
y 0 3 6:000001 9 12 15 :
Solution. We could use the following Sage code
R = PolynomialRing(QQ, ’x’)
R.lagrange_polynomial([(0,0),(1,3),(2, 6.000001),(3, 9),(4,12),
(5,15)])
This would yield the following result:
4.16666666667546e-6*x^5 - 0.0000583333333334564*x^4
+ 0.000295833333333958*x^3 - 0.000641666666668021*x^2
+ 3.00050000000000*x
As you can see, a very small change in values can have a very high impact in the polynomial of
interpolation. For all the values of x between 0 and 3, the two graphs are relatively the same. But for
larger values, they will get signiﬁcantly different.
We give below the graph of the previously two functions:
p1.x/ D 3x
and
p2.x/ D 4:16666666667546  106x5  0:0000583333333334564x4
C0:000295833333333958x3  0:000641666666668021x2 C 3:0005x
Example 83. Use the Sage library to ﬁnd the polynomial of interpolation, p.x/, for
x 2 4 8 16
y 1 2 3 4 ;
and then graph both, p.x/ and f .x/ D log2 x.
Solution. We could use the following Sage code
#create
the table of data points
size = 4
points = [
( 2^x,x ) for x in
[1, 2,.., size] ]

3.1
Interpolation
141
#find the polynomial of interpolation, p(x)
R = PolynomialRing(QQ, ’x’)
p(x) = R.lagrange_polynomial(points)
#plot the polynomial of interpolation
pl=plot(p(x),
(x,0,2^size+1),
legend_label =
"
p(x) = "+str(p(x).full_simplify()))
#plot the points of the table
pl += list_plot( points, color = ’black’, size = 70)
#plot the function f(x)
f(x)=ln(x)/ln(2)
pl +=plot(f(x),
(x,0,2^size+1),
legend_label =
"
f(x) = log2(x)", color = ’red’)
#display the plot
show(pl)
We obtain
As you can see, in this case the polynomial of interpolation provides a fairly accurate approxima-
tion for f .x/ D log2 x.
Example 84. Modify the previous code to only include the ﬁrst three points of the table given above,
namely,
x 2 4 8
y 1 2 3 ;

142
3
Polynomial Interpolation
Solution. We would only need to change one line:
size = 4
into
size = 3
and obtain:
To get the divided differences, using Sage library, one can use code similar to the one in the next
example.
Example 85. Use the Sage library to obtain the divided differences for
x 2 4 8 16
y 1 2 3 4 :
Solution. We could use the following
points = [(2,1),(4,2),(8,3), (16,4)]
R = PolynomialRing(QQ, "x")
R.divided_difference(points)
and obtain
[1, 1/2, -1/24, 1/448]
If you modify the last line and into
show( R.divided_difference(points) )
then you obtain output similar to:

1; 1
2;  1
24;
1
448

To get the full divided differences table, one can use the following code

3.2
Error Bounds in Polynomial Interpolation
143
Example 86. Use the Sage library to obtain the full table of Newton divided differences for
x 2 4 8 16
y 1 2 3 4 :
Solution. We could use the following
points = [(2,1),(4,2),(8,3), (16,4)]
R = PolynomialRing(QQ, "x")
R.divided_difference(points, full_table=True)
and obtain
[[1], [2, 1/2], [3, 1/4, -1/24], [4, 1/8, -1/96, 1/448]]
Using the show method, you can get a more appealing output:
3.2
Error Bounds in Polynomial Interpolation
Suppose we are given a set of n C 1 data points
x0 x1 x2 : : : xn
y0 y1 y0 : : : yn
:
Let’s assume they come from a function f .x/. That is y0 D f .x0/, y1 D f .x1/, etc. Let p.x/ be the
polynomial that interpolates these data points.
A natural question regarding the error of approximation would be: how well does the polynomial
p.x/ approximate f .x/‹ In this section, we’ll try to answer it.
To simplify things, in this section, by error of approximation of a function f by another function
p we will mean
sup
x in domain of f
jf .x/  p.x/j :
(3.17)
In particular, if the domain of f is Œa; b, and both, f and p are continuous, then the previous
expression can be rewritten as
max
x2Œa;b jf .x/  p.x/j :
(3.18)
We might expect that the worst case scenario to be when f is not continuous. In this case, we really
cannot say much about the error of approximating f by p. One thing we can count on is the fact that
f .x/ D p.x/ for x D x0; x1; : : : ; xn since p interpolates the data points. For any other value of x,
the value of jf .x/  p.x/j can be anything, from very small, even 0, to very large.

144
3
Polynomial Interpolation
Next, we will focus our analysis on continuous functions that are deﬁned on some closed interval
Œa; b. In this case, one might expect that the larger the set of data points, the better we can estimate
f by p. That is, we might expect (or guess!) that the larger the value of n, the smaller the error of
approximation. As we will see next, this conjecture turns out to be false.
A classical example to show divergence in the case of interpolating polynomials is given by the
Runge Function
f .x/ D
1
1 C 25x2
deﬁned on Œ1; 1. If we let pn be the polynomial that interpolates the values of f at the nC1 equally
spaced nodes between 1 and 1,
x0 D 1;
(3.19)
x1 D 1 C 2
n;
x2 D 1 C 2  2
n;
  
xn1 D 1 C .n  1/  2
n;
xn D 1
we would have that
lim
n!1 max
x2Œ1;1 jf .x/  pn.x/j D 1:
We can see this idea using Sage.
#runge function
f(x) = 1/(1+25*x^2)
#plot the function
myPlot = plot(f(x), (x, -1,1), color = ’black’)
#plot 4 polynomials of interpolation using colors
colors = [’orange’,
’green’]
step = 0
for n in [4, 8]:
#compute the data points
points = [(-1+i*(2/n),
f(-1+i*2/n)) for i in [0,1,..,n]]
#compute the polynomial of interpolation
R = PolynomialRing(QQ, ’x’)
p(x) = R.lagrange_polynomial(points)
#plot it
myPlot += plot(p(x), (x, -1,1), color = colors[step],
legend_label = "p"+str(n)+"(x)")

3.2
Error Bounds in Polynomial Interpolation
145
step = step + 1
#plot the points too
myPlot += list_plot(points, color = ’red’ , size = 70)
#display the plot
myPlot.show()
We would obtain
We can notice here how p8.x/ has a higher error of approximation than p4.x/.
If we wish to include p16.x/, then we only need to change the following two lines
colors = [’orange’,
’green’,
’blue’]
and
for n in [4, 8, 16]:

146
3
Polynomial Interpolation
to obtain
Last but not least, let’s also include p32. For this we make the following two changes:
colors = [’orange’,
’green’,
’blue’, ’purple’]
and
for n in [4, 8, 16, 32]:
to obtain

3.2
Error Bounds in Polynomial Interpolation
147
We give below a Sage interact that allows the user to select the number of points for interpolating
the Runge’s function.
#runge function
f(x) = 1/(1+25*x^2)
#plot the function
myPlot = plot(f(x), (x, -1,1), color = ’black’)
@interact
def echo_input(j = slider(vmin=1, vmax=5,
step_size=1, default=2,
label="Select a degree: ")):

148
3
Polynomial Interpolation
print "You selected: " + str(2^j) + " points!"
step = 0
n = 2^j
#compute the data points
points = [(-1+i*(2/n),
f(-1+i*2/n)) for i in [0,1,..,n]]
#compute the polynomial of interpolation
R = PolynomialRing(QQ, ’x’)
p(x) = R.lagrange_polynomial(points)
#plot it
myPlot = plot(p(x), (x, -1,1),
legend_label = "p"+str(n)
+"(x)")
#plot the points too
myPlot += list_plot(points, color = ’red’ , size = 70)
#display the plot
myPlot.show()
This will output the following graphs:
For n D 2 W

3.2
Error Bounds in Polynomial Interpolation
149
For n D 3 W
What you should see in these graphs is what is commonly called as Runge’s Phenomenon. This
is a proof that higher order polynomials do not always improve the accuracy.
One way to deal with this phenomenon in this case is to choose points that are not evenly spaced.
For this, one can choose the following nodes, called Chebyshev nodes,
xi D cos
	 2i C 1
2n C 2

;
i D 0; 1; : : : ; n:
(3.20)
Using Chebyshev’s nodes, and the Sage code we wrote for Newton Formula:
def Newton_Interpolation(x):
#copy here the code given on page 132!
#runge function
f(x) = 1/(1+25*x^2)
#plot the function
myPlot = plot(f(x), (x, -1,1), color = ’black’)
#plot 4 polynomials of interpolation using colors
colors = [’orange’,
’green’,
’blue’, ’purple’]
step = 0

150
3
Polynomial Interpolation
for n in [4,8,16, 32]:
#compute the data points
#xi=cos( (2*i+1)*pi/(2*n+2))
#xi=-1+i*(2/n)
points = [(
(cos( (2*i+1)*pi/(2*n+2))).n(),
f(
( cos( (2*i+1)*pi/(2*n+2)))).n()) for
i in [0,1,..,n]]
#compute the interpolation polynomial
p(x) = Newton_Interpolation(x)
#plot it
myPlot += plot(p(x), (x, -1,1), color = colors[step],
legend_label = "p"+str(n)+"(x)")
step = step + 1
#plot the points too
myPlot += list_plot(points, color = ’red’ , size = 70)
#display the plot
myPlot.show()
we obtain the following graph:
which “shows” (although without a proof!) a better behavior for pn.x/ as n increases.

3.2
Error Bounds in Polynomial Interpolation
151
Despite these challenges, for a certain class of continuous functions, deﬁned on a closed and
bounded interval Œa; b, we can give an upper bound for the error of approximation. For this, let’s
consider the case of evenly spaced nodes in Œa; b W
x0 D a;
x1 D a C h;
x2 D a C 2h;
: : :
xn D a C nh D b;
where
h D b  a
n
:
We give the following theorem without a proof. Interested reader may refer to [4, pp. 181–183].
Theorem 87. If f is a continuous function on Œa; b with f .nC1/ also continuous, such that
ˇˇf .nC1/.x/
ˇˇ  M, for some M, then for the polynomial pn.x/ that interpolates the evenly spaced
nodes x0; x1; : : : ; xn we have that
jf .x/  pn.x/j 
1
4.n C 1/MhnC1
(3.21)
for all x in Œa; b.
Example 88. Obtain a polynomial that interpolates cos.x/ on Œ; , using 6 evenly spaced nodes,
and estimate cos.2:5/. Then give an upper bound for the error of approximation.
Solution. Using the following Sage code, and the Newton_Interpolation() function we
wrote earlier in this chapter:
def Newton_Interpolation(x):
#copy the code given on page 132
#function f
f(x) = cos(x)
#interval [a,b]
a = -pi
b = pi
#plot function f on [a,b]
myPlot = plot(f(x), (x, a, b), color = ’red’,
linestyle=’--’,
legend_label = "f(x)")
#we want 6 evenly spaced nodes, hence n=5
n = 5
#the evenly spaced nodes are
points = [ (a + (b-a)/n*i ,
f(a + (b-a)/n*i)) for
i in [0,1,..,n]]

152
3
Polynomial Interpolation
#compute the polynomial of interpolation
p(x) = Newton_Interpolation(x)
#plot it
myPlot += plot(p(x), (x, a,b), color = ’green’,
legend_label = "p"+str(n)+"(x)")
#plot the points too
myPlot += list_plot(points, color = ’red’ , size = 70)
#display the plot, the function, and p(2.5)
myPlot.show(), p(x).full_simplify(), p(2.5).n()
we obtained the following graph,
and
p5.x/ D
1
15364 .34.175
p
5 C 113/  502x2.73
p
5  25/ C 3125x4.
p
5  1//;
cos.2:5/ ' 0:856062012732586:

3.3
An Application to Physics
153
In order to give an upper bound for the error of approximation we will use formula (3.21) of the
previous theorem. We have
jf .x/  p5.x/j  1
24  1 
	2
5

6
(3.22)
' 0:164077089036852:
Using a calculator, we can estimate the actual error of approximation for x D 2:5 W
cos.2:5/  .0:856062012732586/ ' 0:0549183971856523:
3.3
An Application to Physics
Secretariat (March 30, 1970–October 4, 1989) is considered to be one of the greatest Thoroughbred
racehorses of all time. On the First Saturday of May 1973, he made history by ﬁnishing the race of the
Kentucky Derby in less than 2 min (119.4 s), and its record is still unsurpassed (as of 2014). Another
surprising thing is that the Big Red Horse ran faster every quarter of mile of the race.
Below, we give the quarter mile fractions recorded at Kentucky Derby
distance (in miles) 0:00 0:25 0:50 0:75 1:00
1:25
time (in seconds)
0:0 25:2 49:2 73:0 96:4 119:4 :
1. Find the polynomial p that interpolates the data given above, treating time as the independent
variable.
2. Use this polynomial to estimate Secretariat’s speed at the ﬁnish of the race. That is, ﬁnd p0.119:4/.
Solution.
1. Using the Sage code we developed for Newton Interpolation,
#the array of data points given
points=[(0,0),(25.2,0.25),(49.2,0.5),(73,0.75),(96.4,1),(119.4,1.25)]
#we compute n from the size of the array
n = len(points)-1
#call the function and find the final answer
Newton_Interpolation(x).full_simplify()
we obtain the polynomial:
x j   > -(1.44369270474e-11)*x^5 + (4.97960558388e-09)*x^4
- (6.29658403201e-07)*x^3 + (3.88206642935e-05)*x^2
+ 0.00926834584814*x
2. Replacing the last line of Sage code given above with
#call the Newton Interpolation Function
p(x) = Newton_Interpolation(x).full_simplify()
#compute the derivative of this polynomial

154
3
Polynomial Interpolation
p_prime(x) = diff( p(x), x )
#evaluate it at x = 119.4
p_prime(119.4)
we obtain 0:0108430556766 miles per second, which means 39:035 miles per hour.
3.4
Exercises
1. Knowing that e0:72 ' 2:054433 and e0:73 ' 2:075080, estimate e0:722.
2. Knowing that e0:72 ' 2:054433 and e0:73 ' 2:075080, estimate e0:727.
3. Find the polynomial of least degree that interpolates the table
x 1:4 1:7
y 4:7 3:3 :
Use your answer to estimate the y value for x D 1:5.
4. Find the polynomial of least degree that interpolates the table
x 1:4 1:7
y 4:7 4:7 :
Use your answer to estimate the y value for x D 1:5.
5. Find the polynomial of least degree that interpolates the table
x 1:4 1:2 1:7
y 4:7 2:3 4:7 :
Use your answer to estimate the y value for x D 1:5.
6. Find the polynomial of least degree that interpolates the table
x 1:4 1:7 2:1
y 4:7 7
10 :
Use your answer to estimate the y value for x D 1:5.
7. Find the polynomial of least degree that interpolates the table
x 1:4 1:7 2:1
y 7
7
7
:
Use your answer to estimate the y value for x D 1:5.
8. Describe the steps you would use to estimate the value of
3p
7 using linear interpolation. Then
estimate this value.
9. Describe the steps you would use to estimate the value of
3p
7 using quadratic interpolation.
Then estimate this value.
10. Describe the steps you would use to estimate the value of
3p
7 using cubic interpolation. Then
estimate this value.

3.4
Exercises
155
11. Describe the steps you would use to estimate the value of
4p
213 using linear interpolation. Then
estimate this value.
12. Prove the following: given a set of n C 1 data points, there is only one polynomial of degree at
most n that interpolates them.
13. Use Lagrange interpolation formula to obtain a polynomial of least degree that interpolates the
table
x 0 2
3
4
7
y 7 10 20 32 1:
14. Verify that both polynomials p.x/ D  1
2x3C 13
2 x28x, and q.x/ D  1
40x4 9
40x3C 111
20 x27x,
interpolate the table
x 0 2 4
5
y 0 6 40 60 :
Does this violate the “uniqueness” part of the statement given on page 3.1.3?
15. Use Newton Algorithm to ﬁnd the polynomial of least degree that interpolates the table
x 0 2
3
4
7
y 7 10 20 32 1:
16. Use Newton Algorithm to ﬁnd the polynomial of least degree that interpolates the table
x 0 2 4
5
y 0 6 40 60 :
17. Use Newton Algorithm to ﬁnd the polynomial of least degree that interpolates the table
x 1:4 1:7 2:1
y 7
7
7
:
18. Use Newton Algorithm to ﬁnd the polynomial of least degree that interpolates the table
x 2
7
9
y 10 35 45 :
19. Construct a divided-differences table and then write the Newton formula for the polynomial that
interpolates the table
x 0 2
3
4
7
y 7 10 20 32 1:
20. Construct a divided-differences table and then write the Newton formula for the polynomial that
interpolates the table
x 0 2 4
5
y 0 6 40 60 :

156
3
Polynomial Interpolation
21. Construct a divided-differences table and then write the Newton formula for the polynomial that
interpolates the table
x 1:4 1:7 2:1
y 7
7
7
:
22. Give an upper bound for the error of approximation, if sin x is replaced by the polynomial of
interpolation p.x/, for 11 evenly spaced nodes in Œ2:2.
23. Give an upper bound for the error of approximation, if sin x is replaced by the polynomial
of interpolation p.x/, for 6 evenly spaced nodes in Œ:.
24. Give an upper bound for the error of approximation, if cos x is replaced by the polynomial of
interpolation p.x/, for 11 evenly spaced nodes in Œ2:2.
25. Give an upper bound for the error of approximation, if cos x is replaced by the polynomial
of interpolation p.x/, for 6 evenly spaced nodes in Œ:.
3.5
Computer Exercises
Use Sage to solve each of the following (include Sage code and a conclusion in your answers)
1. Knowing that e0:72 ' 2:054433 and e0:73 ' 2:075080, estimate e0:722: What is the error of
approximation committed using this value? Use Sage to compute this error.
2. Find the polynomial of least degree that interpolates the table
x 1:4 1:7
y 4:7 3:3 :
Using Sage, graph the interpolation polynomial.
3. Find the polynomial of least degree that interpolates the table
x 1:4 1:7 2:1
y 4:7 7
10 :
Using Sage, graph the interpolation polynomial.
4. Describe the steps you would use to estimate the value of
3p
17 using linear interpolation.
Then estimate this value. Use Sage to compute the error of approximation.
5. Describe the steps you would use to estimate the value of
4p
213 using linear interpolation. Then
estimate this value. Use Sage to compute the error of approximation.
6. Describe the steps you would use to estimate the value of
3p
17 using quadratic interpolation.
Then estimate this value. Use Sage to compute the error of approximation.
7. Describe the steps you would use to estimate the value of
4p
213 using quadratic interpolation.
Then estimate this value. Use Sage to compute the error of approximation.
8. Describe the steps you would use to estimate the value of
3p
17 using cubic interpolation.
Then estimate this value. Use Sage to compute the error of approximation.
9. Describe the steps you would use to estimate the value of
4p
213 using cubic interpolation. Then
estimate this value. Use Sage to compute the error of approximation.

3.5
Computer Exercises
157
10. Use the Sage library to ﬁnd the polynomial of interpolation, p.x/, for
x 2:4 4:5 7:1 8:2
y 12 2:5 3:7 4
;
and then use if to ﬁnd the value of y for x D 6:7.
11. Use the Sage library to ﬁnd the polynomial of interpolation, p.x/, for the following stock market
values
x 2009
2010
2011
2012
2013
y 10; 428 11; 577 12; 657 13; 437 16; 469 ;
and then use if to ﬁnd the value of y for the year 2015.
12. Use the Sage library to ﬁnd the polynomial of interpolation, p.x/, for
x 2 4 9 16
y 1 2 3 4 ;
and then graph both, p.x/ and f .x/ D px.
13. Use the Sage library to ﬁnd the polynomial of interpolation, p.x/, for
x 2 4 9 16 25
y 1 2 3 4
5 ;
and then graph both, p.x/ and f .x/ D px.
14. Use the Sage library to ﬁnd the polynomial of interpolation, p.x/, for
x 2 4 9 16
25
y 1 2 3 4:0001 5 ;
and then graph both, p.x/ and f .x/ D px. Compare this result with the one given in the previous
problem.
15. Use Lagrange interpolation formula to obtain a polynomial of least degree that interpolates the
table
x 0 2 4
5
y 7 9 40 61 :
Graph each of the Lagrange Basis Polynomials, and the interpolation polynomials on the same
set of axes.
16. Use Lagrange interpolation formula to obtain a polynomial of least degree that interpolates the
table
x 1 2 3 5
y 3 5 5 7 :
Graph each of the Lagrange Basis Polynomials, and the interpolation polynomials on the same
set of axes.

158
3
Polynomial Interpolation
17. Use Lagrange interpolation formula to obtain a polynomial of least degree that interpolates
the table
x 1 1:5 2 2:5 3 3:4 4
y 3 5:1 7 6:5 4 3:2 2 :
Graph each of the Lagrange Basis Polynomials, and the interpolation polynomials on the same
set of axes. Also approximate the y value for x D 3:75.
18. Construct a divided-differences table and then write the Newton formula for the polynomial that
interpolates the table
x 0 2
3
4
7
y 7 10 20 32 1:
19. Construct a divided-differences table and then write the Newton formula for the polynomial that
interpolates the table
x 0 2 4
5
y 0 6 40 60 :
20. Construct a divided-differences table and then write the Newton formula for the polynomial that
interpolates the table
x 1:4 1:7 2:1
y 7
7
7
:
21. Obtain a polynomial that interpolates cos.x/ on Œ2; 2, using 6 evenly spaced nodes, and
estimate cos.2:5/. Then give an upper bound for the error of approximation. Include a graph
showing both f .x/ and p.x/.
22. Obtain a polynomial that interpolates sin.x/ on Œ; , using 6 evenly spaced nodes, and
estimate sin.2:5/. Then give an upper bound for the error of approximation. Include a graph
showing both f .x/ and p.x/.
23. Obtain a polynomial that interpolates sin.x/ on Œ; , using 16 evenly spaced nodes, and
estimate sin.1:2/. Then give an upper bound for the error of approximation. Include a graph
showing both f .x/ and p.x/.
24. Obtain a polynomial that interpolates cos.x/ on Œ; , using 10 evenly spaced nodes, and
estimate cos.1:5/. Then give an upper bound for the error of approximation. Include a graph
showing both f .x/ and p.x/.
25. Obtain a polynomial that interpolates cos.x/ on Œ2; 2, using 10 evenly spaced nodes, and
estimate cos.1:5/. Then give an upper bound for the error of approximation. Include a graph
showing both f .x/ and p.x/.
26. Obtain the polynomial p.x/ that interpolates f .x/ D
1
1C25x2 on Œ1; 1, using 11 evenly spaced
nodes. Then, for each of the 31 evenly spaced points, output the values of f and p. Observe the
largest difference between these values.
27. Obtain the polynomial p.x/ that interpolates f .x/ D
1
1C25x2 on Œ1; 1, using 11 Chebyshev
nodes. Then, for each of the 31 evenly spaced points, output the values of f and p. Observe
the difference between these values. Are they signiﬁcantly different than the ones obtained in the
previous example?

References
159
28. Obtain the polynomial p.x/ that interpolates f .x/ D
1
1C25x2 on Œ1; 1, using 25 evenly spaced
nodes. Then, for each of the 49 evenly spaced points, output the values of f and p. Observe the
largest difference between these values.
29. Obtain the polynomial p.x/ that interpolates f .x/ D
1
1C25x2 on Œ1; 1, using 25 Chebyshev
nodes. Then, for each of the 49 evenly spaced points, output the values of f and p. Observe
the difference between these values. Are they signiﬁcantly different than the ones obtained in the
previous example?
References
1. Atkinson, K., Han, W.: Elementary Numerical Analysis, 3rd edn. Wiley, New York (2003)
2. Beezer, R.A.: Sage for Abstract Algebra (2013). http://abstract.pugetsound.edu/sage-aata.html
3. Blanco-Silva, F.J.: Learning SciPy for Numerical and Scientiﬁc Computing. Packt Publishing, Birmingham (2013)
4. Cheney, W., Kincaid, D.: Numerical Mathematics and Computing, 7th edn. Brooks/Cole: Cengage Learning, Boston
(2013)
5. Epperson, J.F.: An Introduction to Numerical Methods and Analysis, revised edn. Wiley, Hoboken (2007)
6. Stein W.A., et al.: Sage Mathematics Software (Version 6.3), The Sage Development Team (2014). Sage ofﬁcial
webpage: http://www.sagemath.org
7. Sage Cell Server: http://sagecell.sagemath.org/
8. Stein, W.A.: Sage for Power Users (2012). http://www.wstein.org/books/sagebook/sagebook.pdf

Chapter 4
Numerical Differentiation
In this chapter we discuss different numerical approximation techniques for estimating the derivatives
of functions.
4.1
Derivative Formulae Using Taylor Series
4.1.1
First Order Derivatives
Let us recall the deﬁnition of the derivative of a function f (see [7]):
f 0.x/ D lim
h!0
f .x C h/  f .x/
h
:
(4.1)
This motivates the following approximation formula
f 0.x/ ' f .x C h/  f .x/
h
;
(4.2)
for h close enough to 0.
The expression f .xCh/f .x/
h
is called the numerical derivative of f at x, with stepsize h.
The same formula (4.2) can also be derived using Taylor Series. But in here, we will be able to
derive an estimate for the error of approximation, assuming that f is twice differentiable, with the
second order derivative continuous around x. Using Theorem 35 (Taylor’s Theorem with Remainder
(2), given on page 54), with n D 1, we can derive the following formula:
f .x C h/ D f .x/ C hf 0.x/ C h2
2 f 00./;
(4.3)
Electronic supplementary material The online version of this chapter (doi:978-3-319-16739-8_4) contains supple-
mentary material, which is available to authorized users.
© Springer International Publishing Switzerland 2015
G.A. Anastassiou, R. Mezei, Numerical Analysis Using Sage, Springer Undergraduate
Texts in Mathematics and Technology, DOI 10.1007/978-3-319-16739-8_4
161

162
4
Numerical Differentiation
for some , between x and x C h. Therefore, by solving for f 0.x/ we obtain
f 0.x/ D f .x C h/  f .x/
h
 h
2f 00./
(4.4)
D f .x C h/  f .x/
h
C O.h/:
(4.5)
This formula shows that the error of approximating f 0.x/ by f .xCh/f .x/
h
is given by  h
2f 00./,
for some  between x and x C h. From it we can see that the rate of convergence is linear. It means
that when h is halved, so is the error of approximation. In this estimation we did not take into account
the change of the term f 00./, which can speed up the convergence.
Example 89. Approximate the ﬁrst derivative of the function f .x/ D cos x, at x D 0, and assess the
error of approximation.
Solution. In this example, f .x/ D cos x. Hence, for small (close to 0!) values of h, we approximate
f 0.x/ ' cos.x C h/  cos x
h
:
Doing so, the error of approximation is given by
h
2f 00./ D h
2 cos./;
for some  between x and x C h. Since jcos./j  1, we estimate our error to be at most h
2.
Using the Sage code (see also [2, 4–6])
#the given function
f(x)= cos(x)
#computing its derivative
fp(x) = diff(f(x),x)
#the given point x
x0 = 0
print "values of h",’\t’, "numerical approx",’
\t’ ,
"error estimate",’\t’ , "actual error"
for step in [1,2,..10]:
#getting h
h = 0.1/(2^step)
#computing the numerical derivative
df(x)=(f(x+h)-f(x))/h
#actual error
error = fp(x0)-df(x0)
#displaying the results
print h.n(30),’\t’,df(x0).n(30),’
\t’,h/2.n(30),’\t’ ,error

4.1
Derivative Formulae Using Taylor Series
163
we obtain the following table displaying the values of h used, the numerical approximations we
obtained for the derivative of f .x/ D cos x at x D 0, the estimation for the error (which was supposed
to be at most h
2), and the actual error:
values of h
numerical approx
error estimate
actual error
0.050000000
-0.024994792
0.025000000
0.0249947921006743
0.025000000
-0.012499349
0.012500000
0.0124993489718932
0.012500000
-0.0062499186
0.0062500000
0.00624991862021318
0.0062500000
-0.0031249898
0.0031250000
0.00312498982748366
0.0031250000
-0.0015624987
0.0015625000
0.00156249872844683
0.0015625000
-0.00078124984
0.00078125000
0.000781249841111276
0.00078125000
-0.00039062498
0.00039062500
0.000390624980127541
0.00039062500
-0.00019531250
0.00019531250
0.000195312497453415
0.00019531250
-0.000097656250
0.000097656250
0.0000976562496362021
0.000097656250 -0.000048828126
0.000048828125
0.0000488281257275958
Example 90. Approximate the ﬁrst derivative of the function f .x/ D sin x, at x D 2:67, and assess
the error of approximation.
Solution. In this example, f .x/ D sin x. Hence, for small values of h, we can approximate
f 0.x/ ' sin.x C h/  sin x
h
:
Doing so, the error of approximation is given by
h
2f 00./ D h
2 sin./;
for some  between x and x C h. Since jsin./j  1, we again estimate our error to be at most h
2.
Using the Sage code
#the given function
f(x)= sin(x)
#computing its derivative
fp(x) = diff(f(x),x)
#the given point x
x0 = 2.67
print "values of h",’\t’, "numerical approx",’
\t’ ,\
"error estimate",’\t’ , "actual error"
for step in [1,2,..10]:
#getting h
h = 0.1/(2^step)
#computing the numerical derivative
df(x)=(f(x+h)-f(x))/h
#actual error
error = fp(x0)-df(x0)
#displaying the results
print h.n(30),’\t
’,df(x0).n(30),’
\t’,h/2.n(30),
’\t’,error

164
4
Numerical Differentiation
we obtain
values of h
numerical approx error estimate
actual error
0.050000000
-0.90183000
0.025000000
0.0109841363851974
0.025000000
-0.89643160
0.012500000
0.00558573156250508
0.012500000
-0.89366204
0.0062500000
0.00281617453528005
0.0062500000
-0.89225977
0.0031250000
0.00141390083034698
0.0031250000
-0.89155427
0.0015625000
0.000708402087643001
0.0015625000
-0.89120043
0.00078125000
0.000354563746217784
0.00078125000
-0.89102324
0.00039062500
0.000177372521822483
0.00039062500
-0.89093458
0.00019531250
0.0000887089198083890
0.00019531250
-0.89089023
0.000097656250
0.0000443601230170065
0.000097656250 -0.89086805
0.000048828125
0.0000221814767126238
In order to improve the speed of convergence, one can use Theorem 35 (Taylor’s Theorem with
Remainder (2), given on page 54), with n D 2, to obtain
f .x C h/ D f .x/ C hf 0.x/ C h2
2 f 00.x/ C h3
6 f 000.1/
(4.6)
for some 1 between x and x C h. Hence, we have
f .x  h/ D f .x/  hf 0.x/ C h2
2 f 00.x/  h3
6 f 000.2/
(4.7)
for some 2 between x and x  h. Subtracting these two last formulae, we obtain
f .x C h/  f .x  h/ D 2hf 0.x/ C h3
6

f 000.1/ C f 000.2/

(4.8)
hence
f 0.x/ D f .x C h/  f .x  h/
2h
 h2
12

f 000.1/ C f 000.2/

(4.9)
D f .x C h/  f .x  h/
2h
C O.h2/:
(4.10)
Therefore, one could use the following numerical approximation for the ﬁrst order derivative of f ,
f 0.x/ ' f .x C h/  f .x  h/
2h
;
(4.11)
for h close to zero. The right-hand side of the previous expression is called the central difference
formula. Notice that the error of approximation here, given by  h2
12 Œf 000.1/ C f 000.2/, converges to
0 quadratically, as h goes to zero.
Example 91. Use formula (4.11) to approximate the ﬁrst derivative of the function f .x/ D cos x, at
x D 0, and assess the error of approximation.
Solution. In this example, f .x/ D cos x. Hence, for small values of h, we approximate
f 0.x/ ' cos.x C h/  cos.x  h/
2h
:

4.1
Derivative Formulae Using Taylor Series
165
Doing so, the error of approximation is given by
h2
12

f 000.1/ C f 000.2/

D h2
12 .cos.1/ C cos.2// ;
for some 1; 2 between x  h and x C h. Since jcos.x/j  1, we estimate our error to be at most h2
6 .
Using the Sage code
#the given function
f(x)= cos(x)
#computing its derivative
fp(x) = diff(f(x),x)
#the given point x
x0 = 0
print "values of h",’\t’, "numerical approx",’
\t’ ,\
"error estimate",’\t’ , "actual error"
for step in [1,2,..10]:
#getting h
h = 0.1/(2^step)
#computing the numerical derivative
df(x)=(f(x+h)-f(x-h))/(2*h)
#actual error
error = fp(x0)-df(x0)
#displaying the results
print h.n(30),’\t’,df(x0).n(30),’
\t\t’,(h^2/6).n(30),’\t’,error
we obtain the following table of values
values of h
numerical approx
error estimate
actual error
0.050000000
0.00000000
0.00041666667
0
0.025000000
0.00000000
0.00010416667
0
0.012500000
0.00000000
0.000026041667
0
0.0062500000
0.00000000
6.5104167e-6
0
0.0031250000
0.00000000
1.6276042e-6
0
0.0015625000
0.00000000
4.0690104e-7
0
0.00078125000
0.00000000
1.0172526e-7
0
0.00039062500
0.00000000
2.5431315e-8
0
0.00019531250
0.00000000
6.3578288e-9
0
0.000097656250 0.00000000
1.5894572e-9
0
Example 92. Use formula (4.11) to approximate the ﬁrst derivative of the function f .x/ D sin x, at
x D 2:67, and assess the error of approximation.
Solution. In this example, f .x/ D sin x. Hence, for small values of h, we approximate
f 0.x/ ' sin.x C h/  sin.x  h/
2h
:

166
4
Numerical Differentiation
Doing so, the error of approximation is given by
h2
12

f 000.1/ C f 000.2/

D h2
12 .sin.1/ C sin.2// ;
for some 1; 2 between x  h and x C h. Since jsin.x/j  1, we estimate our error to be at most h2
6 .
Using the Sage code
#the given function
f(x)= sin(x)
#computing its derivative
fp(x) = diff(f(x),x)
#the given point x
x0 = 2.67
print "values of h",’\t’, "numerical approx",’
\t’ ,\
"error estimate",’\t’ , "actual error"
for step in [1,2,..10]:
#getting h
h = 0.1/(2^step)
#computing the numerical derivative
df(x)=(f(x+h)-f(x-h))/(2*h)
#actual error
error = fp(x0)-df(x0)
#displaying the results
print h.n(30),’\t’,df(x0).n(30),’
\t\t’,(h^2/6).n(30),’\t’,error
we obtain
values of h
numerical approx
error estimate
actual error
0.050000000
-0.89047473
0.00041666667
-0.000371139382367880
0.025000000
-0.89075307
0.00010416667
-0.0000927935446132233
0.012500000
-0.89082267
0.000026041667
-0.0000231989298594693
0.0062500000
-0.89084007
6.5104167e-6
-5.79976643744207e-6
0.0031250000
-0.89084442
1.6276042e-6
-1.44994377715424e-6
0.0015625000
-0.89084550
4.0690104e-7
-3.62486101246340e-7
0.00078125000
-0.89084578
1.0172526e-7
-9.06213660778477e-8
0.00039062500
-0.89084584
2.5431315e-8
-2.26552249182888e-8
0.00019531250
-0.89084586
6.3578288e-9
-5.66472702079324e-9
0.000097656250 -0.89084587
1.5894572e-9
-1.41693201616278e-9
4.1.2
Second Order Derivatives
We can do a similar work as above to derive a formula for the second derivative. Here, we use
Theorem 35 (Taylor’s Theorem with Remainder (2), given on page 54), with n D 3, to obtain
f .x C h/ C f .x  h/ D 2f .x/ C h2f 00.x/ C h4
24

f .4/.1/  f .4/.2/


4.1
Derivative Formulae Using Taylor Series
167
for some 1; 2 between x  h and x C h. Hence, we get
f 00.x/ D f .x C h/  2f .x/ C f .x  h/
h2
 h2
24

f .4/.1/  f .4/.2/

D f .x C h/  2f .x/ C f .x  h/
h2
C O.h2/:
(4.12)
From the last formula, we see that the rate of convergence is quadratic. That is, as h is halved, the
error is approximately quartered.
Therefore, for h close enough to zero, we have that
f 00.x/ ' f .x C h/  2f .x/ C f .x  h/
h2
:
Example 93. Approximate the second derivative of the function f .x/ D cos x, at x D 0, and assess
the error of approximation.
Solution. In this example, f .x/ D cos x. Hence, for small values of h, we approximate
.cos.x//00 ' cos.x C h/  2 cos.x/ C cos.x  h/
h2
:
Doing so, the error of approximation is at most
ˇˇˇˇ
h2
24

f .4/.1/  f .4/.2/
ˇˇˇˇ  h2
12:
Using similar Sage code as the one above, we obtain the following table
values of h
numerical approx
error estimate
actual error
0.050000000
-0.99979168
0.00020833333
-0.000208315973054596
0.025000000
-0.99994792
0.000052083333
-0.0000520822482030781
0.012500000
-0.99998698
0.000013020833
-0.0000130207663460169
0.0062500000
-0.99999675
3.2552083e-6
-3.25520522892475e-6
0.0031250000
-0.99999919
8.1380208e-7
-8.13801307231188e-7
0.0015625000
-0.99999980
2.0345052e-7
-2.03377567231655e-7
0.00078125000
-0.99999995
5.0862630e-8
-5.07570803165436e-8
0.00039062500
-0.99999999
1.2715658e-8
-1.30385160446167e-8
0.00019531250
-0.99999999
3.1789144e-9
-7.45058059692383e-9
0.000097656250 -1.0000000
7.9472860e-10
0.000000000000000
4.1.3
Method of Undetermined Coefﬁcients
Other formulae can be derived using the Method of Undetermined Coefﬁcients. We will present this
method by means of an example.
Suppose we wish to ﬁnd a formula for f 00.x/ in terms of f .xC2h/; f .xCh/, f .x/, and f .xh/.
That is, we want to ﬁnd the constants A; B; C, and D, such that
f 00.x/ ' Af .x C 2h/ C Bf.x C h/ C Cf.x/ C Df.x  h/:
(4.13)

168
4
Numerical Differentiation
By Theorem 35 (Taylor’s Theorem with Remainder (2), given on page 54), with n D 3, to obtain
f .x C h/ D f .x/ C hf 0.x/ C h2
2 f 00.x/ C h3
6 f 000.x/ C h4
24f .4/.x/ C    :
Hence we have
f .x C h/ ' f .x/ C hf 0.x/ C h2
2 f 00.x/ C h3
6 f 000.x/ C h4
24f .4/.x/ C    ;
f .x  h/ ' f .x/  hf 0.x/ C h2
2 f 00.x/  h3
6 f 000.x/ C h4
24f .4/.x/ C    ;
and
f .x C 2h/ ' f .x/ C 2hf 0.x/ C 2h2f 00.x/ C 4h3
3 f 000.x/ C 2h4
3 f .4/.x/ C    :
Then, denoting DDh.x/ D Af.x C 2h/ C Bf.x C h/ C Cf.x/ C Df.x  h/, we have
DDh.x/ ' Af.x/ C 2Ahf 0.x/ C 2Ah2f 00.x/ C 4Ah3
3
f 000.x/ C 2Ah4
3
f .4/.x/ C   
CBf.x/ C Bhf 0.x/ C Bh2
2 f 00.x/ C Bh3
6 f 000.x/ C Bh4
24 f .4/.x/ C   
CCf.x/
CDf.x/  Dhf 0.x/ C Dh2
2 f 00.x/  Dh3
6 f 000.x/ C Dh4
24 f .4/.x/ C   
hence
DDh.x/ ' .A C B C C C D/ f .x/
(4.14)
C .2A C B  D/ hf 0.x/
C
	
2A C B
2 C D
2

h2f 00.x/
C
	4A
3 C B
6  D
6

h3f 000.x/
C
	2A
3 C B
24 C D
24

h4f .4/.x/ : : : :
Since we want our formula to work for arbitrary functions f , we need to solve
8
ˆˆ<
ˆˆ:
A C B C C C D D 0
.2A C B  D/ h D 0

2A C B
2 C D
2

h2 D 1
 4A
3 C B
6  D
6

h3 D 0
:

4.2
Derivative Formulae Using Interpolating Polynomials
169
Solving this system, we obtain
8
ˆˆˆ<
ˆˆˆ:
A D 0
B D
1
h2
C D 2
h2
D D
1
h2
:
(4.15)
hence we obtain again the formula
f 00.x/ ' f .x C h/  2f .x/ C f .x  h/
2h2
:
(4.16)
In order to obtain the error of approximation formula, one can substitute (4.15), into (4.14) to
obtain
DDh.x/ ' f 00.x/ C
1
12h2 h4f .4/.x/ C    :
Therefore, the error of approximation can be estimated by
f 00.x/  DDh.x/ '  1
12h2f .4/.x/:
4.2
Derivative Formulae Using Interpolating Polynomials
We can use interpolating polynomials to approximate the derivative of a function f at given values of
x. For this, let p.x/ be the polynomial that interpolates f at n C 1 nodes: x0; x1, : : :, xn. That is
p.x0/ D f .x0/; p.x1/ D f .x1/; : : : ; p.xn/ D f .xn/:
(4.17)
Then, using the fact that
f .x/ ' p.x/
(4.18)
we can derive the following
f 0.x/ ' p0.x/:
(4.19)
In particular, when n D 1 we need two nodes, x0; x1, so we can compute the interpolating function
p.x/. Then, we would obtain
p.x/ D f .x0/ C f Œx0; x1.x  x0/;
therefore
p0.x/ D f Œx0; x1
(4.20)
D f .x1/  f .x0/
x1  x0
;

170
4
Numerical Differentiation
hence
f 0.x/ ' f .x1/  f .x0/
x1  x0
:
(4.21)
There are different ways to choose x0 and x1, which will lead to different formulae.
If we choose x0 D x, x1 D x C h, we obtain
f 0.x/ ' f .x C h/  f .x/
h
(4.22)
which recovers formula (4.2) given on page 161. The error of approximation was already discussed
there, hence we will not repeat it here.
If we choose x0 D x  h, x1 D x C h, we obtain
f 0.x/ ' f .x C h/  f .x  h/
2h
(4.23)
which recovers formula (4.11) given on page 164. The error of approximation for this formula was
also discussed there, and we will not repeat it here.
A similar discussion can hold for n D 2, where we would have to choose three nodes. There we
have
p.x/ D f .x0/ C f Œx0; x1.x  x0/
Cf Œx0; x1; x2.x  x0/.x  x1/;
therefore
p0.x/ D f Œx0; x1 C f Œx0; x1; x2.2x  x0  x1/;
(4.24)
hence
f 0.x/ ' f Œx0; x1 C f Œx0; x1; x2.2x  x0  x1/:
(4.25)
If we choose x0 D x  h, x1 D x; x2 D x C h, we obtain
f 0.x/ ' f .x1/  f .x0/
x1  x0
C
f .x2/f .x1/
x2x1
 f .x1/f .x0/
x1x0
x2  x0
.2x  x0  x1/
D f .x C h/  f .x  h/
2h
;
(4.26)
which again recovers formula (4.11) given on page 164.
If we choose x0 D x  h, x1 D x C h, we obtain
f 0.x/ ' f .x C h/  f .x  h/
2h
(4.27)

4.3
Exercises
171
It can be shown (see [1, p. 235] and [3, p. 195]) that if f is n C 2 continuous derivatives, then the
error of approximation is given by
f 0.x/  p0.x/ D
1
.n C 1/Š.x  x0/.x  x1/ : : : .x  xn/f .nC2/./
C
1
.n C 1/Š Œ.x  x0/.x  x1/ : : : .x  xn/0 f .nC1/./;
for some  between the largest and the smallest of the n C 1 nodes: x0; x1, : : :, xn.
4.3
Exercises
1. Use formula (4.2) to approximate the ﬁrst derivative of the function f .x/ D sin x, at x D 1:5,
and assess the error of approximation.
2. Use formula (4.2) to approximate the ﬁrst derivative of the function f .x/ D ex, at x D 0, and
assess the error of approximation.
3. Use formula (4.2) to approximate the ﬁrst derivative of the function f .x/ D cos x, at x D 
6 , and
assess the error of approximation.
4. Use formula (4.2) to approximate the ﬁrst derivative of the function f .x/ D cos x, at x D , and
assess the error of approximation.
5. Use formula (4.2) to approximate the ﬁrst derivative of the function f .x/ D sin x, at x D , and
assess the error of approximation.
6. Use formula (4.11) to approximate the ﬁrst derivative of the function f .x/ D sin x, at x D 1:5,
and assess the error of approximation.
7. Use formula (4.11) to approximate the ﬁrst derivative of the function f .x/ D ex, at x D 0, and
assess the error of approximation.
8. Use formula (4.11) to approximate the ﬁrst derivative of the function f .x/ D cos x, at x D 
6 ,
and assess the error of approximation.
9. Use formula (4.11) to approximate the ﬁrst derivative of the function f .x/ D cos x, at x D ,
and assess the error of approximation.
10. Use formula (4.11) to approximate the ﬁrst derivative of the function f .x/ D sin x, at x D ,
and assess the error of approximation.
11. Approximate the second derivative of the function f .x/ D sin x, at x D , and assess the error
of approximation.
12. Approximate the second derivative of the function f .x/ D cos x, at x D 
6 , and assess the error
of approximation.
13. Approximate the second derivative of the function f .x/ D sin x, at x D 1:5, and assess the error
of approximation.
14. Derive the formula
f 0.x/ ' f .x C 2h/  f .x  2h/
4h
;
and estimate the error of approximation in using it.
15. Derive the formula
f 0.x/ ' f .x C 3h/  f .x  h/
4h
;
and estimate the error of approximation in using it.

172
4
Numerical Differentiation
16. Derive the formula
f 0.x/ ' f .x C 2h/ C 8f .x C h/  8f .x  h/ C f .x  2h/
12h
;
and estimate the error of approximation in using it.
4.4
Computer Exercises
1. Use formula (4.2) to approximate the ﬁrst derivative of the function f .x/ D sin x, at x D 1:5, and
assess the error of approximation. Print a table for values of h D 0:1, 0:01, 0:001, : : :, 0:000001.
2. Use formula (4.2) to approximate the ﬁrst derivative of the function f .x/ D ex, at x D 0, and
assess the error of approximation. Print a table for values of h D 0:1, 0:01, 0:001, : : :, 0:000001.
3. Use formula (4.2) to approximate the ﬁrst derivative of the function f .x/ D cos x, at x D 
6 , and
assess the error of approximation. Print a table for values of h D 0:1, 0:01, 0:001, : : :, 0:000001.
4. Use formula (4.2) to approximate the ﬁrst derivative of the function f .x/ D cos x, at x D , and
assess the error of approximation. Print a table for values of h D 0:1, 0:01, 0:001, : : :, 0:000001.
5. Use formula (4.2) to approximate the ﬁrst derivative of the function f .x/ D sin x, at x D , and
assess the error of approximation. Print a table for values of h D 0:1, 0:01, 0:001, : : :, 0:000001.
6. Use formula (4.2) to approximate the ﬁrst derivative of the function f .x/ D arctan.x2 C x C 1/,
at x D 0, and assess the error of approximation. Print a table for values of h D 0:1, 0:01, 0:001,
: : :, 0:000001.
7. Use formula (4.11) to approximate the ﬁrst derivative of the function f .x/ D sin x, at x D 1:5,
and assess the error of approximation. Print a table for values of h D 0:1, 0:01, 0:001, : : :,
0:000001.
8. Use formula (4.11) to approximate the ﬁrst derivative of the function f .x/ D ex, at x D 0, and
assess the error of approximation. Print a table for values of h D 0:1, 0:01, 0:001, : : :, 0:000001.
9. Use formula (4.11) to approximate the ﬁrst derivative of the function f .x/ D cos x, at x D 
6 ,
and assess the error of approximation. Print a table for values of h D 0:1, 0:01, 0:001, : : :,
0:000001.
10. Use formula (4.11) to approximate the ﬁrst derivative of the function f .x/ D cos x, at x D ,
and assess the error of approximation. Print a table for values of h D 0:1, 0:01, 0:001, : : :,
0:000001.
11. Use formula (4.11) to approximate the ﬁrst derivative of the function f .x/ D sin x, at x D , and
assess the error of approximation. Print a table for values of h D 0:1, 0:01, 0:001, : : :, 0:000001.
12. Use formula (4.11) to approximate the ﬁrst derivative of the function f .x/ D arctan.x2 Cx C1/,
at x D 0, and assess the error of approximation. Print a table for values of h D 0:1, 0:01, 0:001,
: : :, 0:000001.
13. Approximate the second derivative of the function f .x/ D sin x, at x D , and assess the error
of approximation. Print a table for values of h D 0:1, 0:01, 0:001, : : :, 0:000001.
14. Approximate the second derivative of the function f .x/ D cos x, at x D 
6 , and assess the error
of approximation. Print a table for values of h D 0:1, 0:01, 0:001, : : :, 0:000001.
15. Approximate the second derivative of the function f .x/ D sin x, at x D 1:5, and assess the error
of approximation. Print a table for values of h D 0:1, 0:01, 0:001, : : :, 0:000001.

References
173
16. Given the following table of values
x 0:2
0:4
0:6
0:8
1:0
y 7:11 10:21 20:98 32:91 1:12 ;
estimate f 0.0:6/, using h D 0:2. Estimate the error of approximation.
17. Given the following table of values
x 0:2
0:4
0:6
0:8
1:0
y 7:11 10:21 20:98 32:91 1:12 ;
estimate f 0.0:6/, using h D 0:4. Estimate the error of approximation.
18. Given the following table of values
x 0:2
0:4
0:6
0:8
1:0
y 7:11 10:21 20:98 32:91 1:12 ;
estimate f 00.0:6/, using h D 0:2. Estimate the error of approximation.
19. Given the following table of values
x 0:2
0:4
0:6
0:8
1:0
y 7:11 10:21 20:98 32:91 1:12 ;
estimate f 00.0:6/, using h D 0:4. Estimate the error of approximation.
References
1. Atkinson, K., Han, W.: Elementary Numerical Analysis, 3rd edn. Wiley, New York (2003)
2. Blanco-Silva, F.J.: Learning SciPy for Numerical and Scientiﬁc Computing. Packt Publishing, Birmingham (2013)
3. Cheney, W., David Kincaid, D.: Numerical Mathematics and Computing, 7th edn. Brooks/Cole: Cengage Learning,
Boston (2013)
4. Stein, W.A. et al.: Sage mathematics software (Version 6.3), The sage development team, Sage ofﬁcial webpage:
http://www.sagemath.org (2014)
5. Sage cell server: http://sagecell.sagemath.org/
6. Stein, W.A.: Sage for power users, http://www.wstein.org/books/sagebook/sagebook.pdf (2012)
7. Sullivan, M., Miranda, K.: Calculus-Early Transcendentals. W. H. Freeman and Company, New York (2014)

Chapter 5
Numerical Integration
Deﬁnite integrals have many applications in several ﬁelds, including Physics, Mathematics, Prob-
ability and Statistics, Computer Science, Economics, and others. In this chapter we will see some
numerical methods that can be used to approximate deﬁnite integrals. Quadrature, a Mathematical
term used for the problems of calculating areas, will be used in the names of some of these methods.
Recall from Calculus (see, for example [10, p. 362–364]) the following result
Theorem 94 (Fundamental Theorem of Calculus). Let f be a continuous function on Œa; b. Then
Z b
a
f .x/dx D F.b/  F.a/;
for any antiderivative F of f , on Œa; b.
By an antiderivative of a function f on Œa; b, we mean a function F that is differentiable on
Œa; b, and F 0.x/ D f .x/ for every x in Œa; b.
Having this result, we can easily solve the following
Example 95. Find the value of the following deﬁnite integral:
Z e
1
1
x dx:
Solution. Let f .x/ D
1
x , for x in Œ1; e. Then we can easily check that F.x/ D ln x is an
antiderivative of f on Œ1; e, since F 0.x/ D
1
x . Therefore, using the Fundamental Theorem of
Calculus, we obtain
Z e
1
1
x dx D ln e  ln 1
D 1  0 D 0:
Electronic supplementary material The online version of this chapter (doi:978-3-319-16739-8_5) contains supple-
mentary material, which is available to authorized users.
© Springer International Publishing Switzerland 2015
G.A. Anastassiou, R. Mezei, Numerical Analysis Using Sage, Springer Undergraduate
Texts in Mathematics and Technology, DOI 10.1007/978-3-319-16739-8_5
175

176
5
Numerical Integration
An interpretation of the deﬁnite integral, for nonnegative functions, is that it represents the area
under the curve (between the function and the x-axis). So in our previous example, the region that is
shaded has an area equal to 1.
The graph above was obtained using the following Sage code
#define the function to be used
f(x) = 1/x
#define the interval
a = 1
b = e
#graph the two horizontal lines
P = line([(a,0),(a,f(a))], color=’black’)
P += line([(b,0),(b,f(b))], color=’black’)
#make the shade between the graph and x-axis
#this will be a polygon with many points
P += polygon( [(a,0),(a,f(a))] +
[(x, f(x)) for x in [a,a+0.005,..,b]] +
[(b,0),(a,0)],
rgbcolor=(0.5,0.8,0.7),aspect_ratio=’automatic’)
#draw the text above the graph
#NOTE THE USE OF LATEX CODE BELOW!!!
P += text("$\\int_{1}^e \\frac{1}{x} dx$ = 1",
( (a+b)/2, max(f(a),f(b)) ), fontsize=20, color=’black’)
#draw the curve
P += plot(f, (x, a-0.5, b+0.5), thickness=3)

5
Numerical Integration
177
#show the plot
show(P)
In the previous example, if we replace the function f .x/ D 1
x with g.x/ D sin x
x , or h.x/ D ex2
then we obtain the following graphs:
and

178
5
Numerical Integration
We can see that those functions have a well-deﬁned area under their curves, and hence the following
expressions should be well deﬁned
Z e
1
sin x
x
dx; and
Z e
1
ex2dx:
But how could you compute them? Neither one of the functions g.x/ D sin x
x , and h.x/ D ex2,
have an antiderivative that can be expressed in terms of elementary functions. Therefore, we cannot
simply apply the Fundamental Theorem of Calculus to ﬁnd their values.
The answer to this question is the subject of the current chapter. We will see some formulae that
will allow us to compute the values of the deﬁnite integral
Z b
a
f .x/dx
to any desired accuracy.
5.1
Trapezoidal Rule
5.1.1
Basic Trapezoidal Rule
The main idea of Trapezoidal Rule (see also [2, 5, 6, 10]) is to replace the function f .x/ with the
linear function p.x/ that interpolates f at the nodes a and b (see formula (3.2), on page 118). From
f .x/ ' p.x/
(5.1)
D
	x  b
a  b

f .a/ C
x  a
b  a

f .b/
we obtain
Z b
a
f .x/dx '
Z b
a
p.x/dx
D
Z b
a
	x  b
a  b

f .a/ C
x  a
b  a

f .b/

dx
D .b  a/
f .a/ C f .b/
2

:
Hence, we call the basic trapezoidal rule, for the interval Œa; b the formula:
Z b
a
f .x/dx ' .b  a/
f .a/ C f .b/
2

:
(5.2)

5.1
Trapezoidal Rule
179
We can illustrate this using the following graph.
As we can observe here, the area under the curve f .x/ is approximated with the area of a trapezoid,
hence the name of the rule.
Let’s see an example.
Example 96. Approximate the integral
R 5
1

sin x  1 C px

dx using the Basic Trapezoid Rule.
Solution. The previous graph is related to this problem, as it represents the function given here.
Applying the formula (5.2), to f .x/ D sin x  1 C px, we obtain
Z 5
1

sin x  1 C px

dx ' .5  1/
f .5/ C f .1/
2

' 4:47445875057819:
This particular example was chosen so we can compute the true value of the integral directly (by
applying the Fundamental Theorem of Calculus):
Z 5
1

sin x  1 C px

dx D
	
 cos x  x C 2
3xpx

ˇˇˇˇ
5
1
' 3:04353337873755:
Or use the following Sage code (see [3, 7–9]) to get the same result:
integral(sin(x)-1+sqrt(x),x,1,5).n()
We obtain
3.04353337873755
Whichever the way we choose to compute it, we can see that the error of approximation using
Basic Trapezoid Rule is 1.43092537184064, which is rather large.

180
5
Numerical Integration
Next we’ll see a technique that will allow us to improve the Basic Trapezoidal Rule and get an
answer much more accurate value. The error can be made as small as needed, using appropriate
parameters.
5.1.2
Composite Trapezoidal Rule
We should note that the Basic Trapezoidal Rule works best when the graph of f .x/ is linear or nearly
linear. However, this is usually not the case. So the trick we’ll do in here is to split the interval
Œa; b into several subintervals: Œa D x0; x1; Œx1; x2; : : : ; Œxn1; xn D b and then apply the Basic
Trapezoidal Rule on each of these subintervals. This is what we call the Composite Trapezoidal
Rule:
Z b
a
f .x/dx '
n
X
kD1
.xk  xk1/
f .xk/ C f .xk1/
2

:
(5.3)
If we split the interval Œa; b in subintervals that are small enough, then the function f .x/ will be
approximately linear on each one, and hence we expect to get a much better estimate.
In general, the more nodes we use, the more accurate answers we should expect. When dealing with
computers, there is a limit, of course, in how many nodes we can actually use, due to the propagation
of errors.
Example 97. Approximate the integral
R 5
1

sin x  1 C px

dx using the Composite Trapezoid Rule,
with ﬁve evenly spaced nodes.

5.1
Trapezoidal Rule
181
Solution. The previous graph is related to this problem, as it represents the function given here. Using
formula (5.3), for f .x/ D sin x  1 C px, we obtain
Z 5
1

sin x  1 C px

dx ' .2  1/
f .2/ C f .1/
2

C .3  2/
f .3/ C f .2/
2

C .4  3/
f .4/ C f .3/
2

C .5  4/
f .5/ C f .4/
2

D 1
2f .1/ C f .2/ C f .3/ C f .4/ C 1
2f .5/
' 2:99918665334187;
which is a much better estimate. The error of approximation is in this case about 0.0443467253956832,
which is a great improvement.
When we choose the nodes, we can select them as either uniformly or nonuniformly spaced in
Œa; b. The previous formula works with either case. In practice, however, when we are using the
power of computers, we would usually prefer to use nodes that are evenly spaced, as it simpliﬁes the
algorithm we will be implementing next. For this, we are dividing the interval Œa; b into n subintervals
of equal length each,
h D b  a
n
;
(5.4)
and obtain the following evenly spaced nodes
xi D a C i  h; i D 0; 1; : : : ; n:
(5.5)
Then we obtain the following simpliﬁed formula called Composite Trapezoidal Rule with evenly
spaced nodes:
Z b
a
f .x/dx ' h
n
X
kD1
f .xk/ C f .xk1/
2

(5.6)
D h
1
2f .x0/ C f .x1/ C f .x2/ C    C f .xn1/ C 1
2f .xn/

D h
1
2f .a/ C f .x1/ C f .x2/ C    C f .xn1/ C 1
2f .b/

:
5.1.3
Sage Code
Here we will implement Sage code to compute a deﬁnite integral using Composite Trapezoidal Rule
with evenly spaced nodes in Œa; b. Then we will apply this code to ﬁnd the answer to each of the
following problems:
Z e
1
sin x
x
dx;
Z 1
0
ex2dx;
Z e
1
ex2dx;
and compare these answers against the values given by the Sage Library function integral().

182
5
Numerical Integration
Below, we give the Sage code that implements the formula (5.6)
#this function needs [a,b] and n, for n+1 nodes
def CompositeTrapezoidal(f, a, b, n):
#compute the size of each subinterval
h = (b-a)/n
#here we add all the terms
sum = 1/2*f(a)
#add the values for all intermediate nodes
for i in [1,2,..,n-1] :
sum += f(a+i*h)
#add the last node
sum +=1/2*f(b)
#multiply by h to complete the computation
sum = sum*h
#return the sum
return sum
Let’s use this code to solve some of the problems.
Example 98. Apply the previous Sage code to ﬁnd the value of
Z e
1
sin x
x
dx;
using n D 5 subintervals.
Solution. For this, to the previous Sage code, we simply add
#define the function we will be using
f(x) = sin(x)/x
#call the function on [1,e], with 5+1 nodes
print CompositeTrapezoidal(f, 1, e, 5).n()
and obtain
0.874072951263462
Using the Sage Library function, integral(sin(x)/x,x,1,e).n() we obtain:
0.874957198780384
Example 99. Create a table of values obtained using the Composite Trapezoidal Rule, with n D
1; 2; 4; 8; 16 and 32, for the expression
Z 1
0
1
1 C x2 dx;
and print out the error of approximation in each case.

5.1
Trapezoidal Rule
183
Solution. For this, we use the following Sage code:
#define the function we will be using
f(x) = 1/(1+x^2)
#print the top part of the table
print ’trapezoidal’ , ’\t\t’, ’error’
print ’------------------------------------------’
#call the function several times
for power in [0,1,2,3,4, 5]:
n = 2^power
trapezoidal = CompositeTrapezoidal(f, 0, 1, n).n()
error = (trapezoidal - integral(f(x) ,x,0,1)).n()
print trapezoidal , ’\t’, error
to obtain
trapezoidal
error
                      
0.750000000000000
-0.0353981633974483
0.775000000000000
-0.0103981633974483
0.782794117647059
-0.00260404575038942
0.784747123622772
-0.000651039774676065
0.785235403010347
-0.000162760387101057
0.785357473293744
-0.0000406901037046659
Example 100. Use the Composite Trapezoidal Rule, with n D 32, to ﬁnd an approximate value for
Z 1
0
ex2dx:
Solution. For this, we use the following Sage code:
#define the function we will be using
f(x) = e^(-x^2)
#set the value of n
n = 32
#call the function on [0,1], with n+1 nodes
CompositeTrapezoidal(f, 0, 1, n).n()
to obtain
0.746764254652294
Using the Sage Library function, integral(f(x),x,0,1).n() we obtain
0.746824132812427
Example 101. Use the Composite Trapezoidal Rule, with n D 64, to ﬁnd an approximate value for
Z e
1
ex2dx:

184
5
Numerical Integration
Solution. For this, we use the following Sage code:
#define the function we will be using
f(x) = e^(x^2)
#set the value of n
n = 64
#call the function on [1,e], with n+1 nodes
CompositeTrapezoidal(f, 1, e, n).n()
and obtain
323.823079851799
Using the Sage Library function, integral(f(x),x,1,e).n() we obtain
323.295188678248
5.1.4
Error Bounds
Let us use the following notation for a function f deﬁned on Œa; b W
I D
Z b
a
f .x/dx
which will represent the deﬁnite integral of f on Œa; b and
T D h
n
X
kD1
f .xk/ C f .xk1/
2

D h
1
2f .a/ C f .x1/ C f .x2/ C    C f .xn1/ C 1
2f .b/

;
which is given by the Composite Trapezoidal Rule with n C 1 evenly spaced nodes
xi D a C i  h; i D 0; 1; : : : ; n;
(5.7)
with
h D b  a
n
:
(5.8)
We give next, without a proof, the following error estimation. The reader interested in the proof of
this result can refer to [5, p. 206].
Theorem 102. Let f be a function deﬁned on Œa; b that is twice differentiable, with f 00 also
continuous. Then the error of approximation is given by
I  T D .b  a/h2
12
f 00./;
(5.9)
for some  in .a; b/.

5.1
Trapezoidal Rule
185
In particular we have the following estimation for the error of approximation
Corollary 103. Let f be a function deﬁned on Œa; b that is twice differentiable, with f 00 also
continuous, such that jf 00.x/j  M, for all x in Œa; b. Then
jI  T j  .b  a/Mh2
12
:
(5.10)
This last result shows that the Composite Trapezoidal Rule with evenly spaced nodes converges
quadratically.
Another direct consequence of the previous theorem is
Corollary 104. Let f be a linear function deﬁned on Œa; b. Then the Trapezoid Rule gives us exact
answers, that is
I D T:
(5.11)
Example 105. How many evenly spaced nodes do we need to use in Composite Trapezoidal Rule, in
order to ﬁnd an approximate value for
Z e
1
ex2dx;
with an error less than 0:001?
Solution. We have f .x/ D ex2, deﬁned on Œ1; e. Hence
f 0.x/ D 2xex2
and
f 00.x/ D .2 C 4x2/ex2
and therefore
ˇˇf 00.x/
ˇˇ  .2 C 4e2/ee2
< 51063:58783:
Using formula (5.10), we have
jI  T j  .b  a/Mh2
12
< 51063:58783 .e  1/3
12n2
< 21588:04287
n2
Therefore, from
21588:04287
n2
< 0:001

186
5
Numerical Integration
we obtain
n  4647:
The answer to the question is therefore 4648 evenly spaced nodes would be sufﬁcient.
Example 106. How many evenly spaced nodes do we need to use in Composite Trapezoidal Rule, in
order to ﬁnd an approximate value for
Z 1
0
ex2dx;
with an error less than 0:0001? Then estimate the value of
R 1
0 ex2dx.
Solution. We have f .x/ D ex2, deﬁned on Œ0; 1. Hence
f 0.x/ D 2xex2
and
f 00.x/ D .2 C 4x2/ex2
and therefore
ˇˇf 00.x/
ˇˇ  6e:
Using formula (5.10), we have
jI  T j  .b  a/Mh2
12

e
2n2 :
Therefore, from
e
2n2 < 0:0001
we obtain
n  117;
which means we would need at least 117+1=118 evenly spaced nodes to make sure the error of
approximation is less than 0.0001. Using the Sage code we developed earlier, we obtain the following
estimation
Z 1
0
ex2dx ' 1:46268484119943:
Compare this to 1.46265174590718, the value obtained from integrate(e^(x^2), x,
0, 1).n().

5.1
Trapezoidal Rule
187
5.1.5
Sage Library
If we want to utilize Sage libraries, we can use Sage code similar to the one in the next examples
Example 107. Find the value of
Z e
1
sin x
x
dx;
using n D 5 subintervals.
Solution. For this, one can use
#import the needed libraries
from scipy.integrate import simps
import scipy
import numpy
#define the function, the interval [a,b], and n
def f(x):
return sin(x)/x
a=1.0
b=e
n=5
#define the n+1 evenly spaced nodes in [a,b]
x = numpy.array([a+i*(b-a)/n
for i in [0,1,..,n]])
#compute and output the Trapezoidal Rule
print
scipy.integrate.trapz(f(x), x).n()
to obtain
0.874072951263462
Example 108. Find the value of
Z 1
0
1
1 C x2 dx;
using n D 32 subintervals.
Solution. For this, we can use the following Sage code:
#import the needed libraries
from scipy.integrate import simps
import scipy
import numpy
#define the function, the interval [a,b], and n
def f(x):
return 1/(1+x^2)
a=0

188
5
Numerical Integration
b=1
n=32
#define the n+1 evenly spaced nodes in [a,b]
x = numpy.array([a+i*(b-a)/n
for i in [0,1,..,n]])
#compute and output the Trapezoidal Rule
print
scipy.integrate.trapz(f(x), x)
and obtain:
0.785357473294
5.2
Simpson’s Rule
5.2.1
Basic Simpson’s Rule
In Basic Trapezoidal Rule, we approximated the function f .x/ on Œa; b by the linear function that
interpolated f at the nodes a and b. Hence we used
f .x/ '
	x  b
a  b

f .a/ C
x  a
b  a

f .b/:
In Simpson’s Rule, we will replace the function f .x/ with the quadratic interpolation function p.x/
that interpolates f at the nodes a; aCb
2 , and b (see formula (3.3), on page 121):
f .x/ ' p.x/
(5.12)
D
 
x  aCb
2
a  aCb
2
! 	x  b
a  b

f .a/
C
 
x  a
aCb
2
 a
!  
x  b
aCb
2
 b
!
f
	a C b
2

C
x  a
b  a
  
x  aCb
2
b  aCb
2
!
f .b/
hence we obtain the following basic trapezoidal rule, for the interval Œa; b W
Z b
a
f .x/dx '
Z b
a
p.x/dx
(5.13)
D b  a
6

f .a/ C 4f
	a C b
2

C f .b/

:

5.2
Simpson’s Rule
189
We illustrate this means of an example.
Example 109. Approximate the integral
R 5
1

sin x  1 C px

dx using the Basic Simpson’s Rule.
Solution. The above given graph is related to this problem, as it represents the function given here.
Applying the formula (5.13), to f .x/ D sin x  1 C px, we obtain
Z 5
1

sin x  1 C px

dx ' 5  1
6

f .1/ C 4f
	1 C 5
2

C f .5/

' 3:07419863343968:
This particular example was chosen so we can compute true value of the integral directly (by
applying the Fundamental Theorem of Calculus):
Z 5
1

sin x  1 C px

dx D
	
 cos x  x C 2
3xpx

ˇˇˇˇ
5
1
' 3:04353337873755:
As we can see that the error of approximation is approximately 0.0306652547021335, which is fairly
good.
Next we’ll see the Composite Simpson’s Rule that will help us improve our estimation. As with the
Trapezoid Rule, the error can be made as small as needed, using appropriate parameters. We’ll also
discuss this below, after we give the Sage implementation for our algorithm.

190
5
Numerical Integration
5.2.2
Composite Simpson’s Rule
We should note from the way de derived Simpson’s Rule that the more close to a linear or quadratic
a function f is on a given interval Œa; b, the more accurate answers we obtain using Simpson’s Rule.
In particular, if f is a polynomial of degree at most two, then the Simpson’s Rule will give an exact
answer. In reality, it is exact also for cubic polynomials, but this will become clear once we analyze
the error of approximation.
As before, it makes sense to divide the interval Œa; b into a number of subintervals, Œa D x0; x2,
Œx2; x4; : : :, Œxn2; xn, and apply the Basic Simpson’s Rule on each such subinterval. Note that here n
must be even, and x1 D x0Cx2
2
; x3 D x2Cx4
2
; : : : ; xn1 D xn2Cxn
2
. Then we combine (add) the answers
for each such subinterval to obtain an estimation for the entire interval. This is what will be called the
Composite Simpson’s Rule.
Z b
a
f .x/dx D
Z x2
x0
f .x/dx C
Z x4
x2
f .x/dx C    C
Z xn
xn2
f .x/dx
' x0  x2
6
Œf .x0/ C 4f .x1/ C f .x2/
Cx2  x4
6
Œf .x2/ C 4f .x3/ C f .x4/
C   
Cxn2  xn
6
Œf .xn2/ C 4f .xn1/ C f .xn/ :
In particular, if the nodes are evenly spaced in Œa; b, that is
xi D a C ih;
where
h D b  a
n
;
and n is even, then we obtain the following simpliﬁed formula
Z b
a
f .x/dx ' h
3 Œf .a/ C 4f .x1/ C 2f .x2/ C 4f .x3/ C 2f .x4/
C    C 2f .xn2/ C 4f .xn1/ C f .b/ ;
(5.14)
called the Composite Simpson’s Rule with evenly spaced nodes.

5.2
Simpson’s Rule
191
Let’s see an example.
Example 110. Approximate the integral
R 5
1

sin x  1 C px

dx using the Composite Simpson’s
Rule, with ﬁve evenly spaced nodes.
Solution. We have that n D 4. The above given graph is related to this problem, as it represents the
function given here. Using formula (5.14), for f .x/ D sin x  1 C px, we obtain
Z 5
1

sin x  1 C px

dx '
	5  1
12

Œf .1/ C 4f .2/ C 2f .3/ C 4f .4/ C f .5/
' 3:04393009815514;
which is a much better estimate than the one obtained earlier. The error of approximation is, in this
case, about 0.000396719417593783, which is a signiﬁcant improvement.
For completeness, we give below the Sage code used to create the previous graph
#define the function to be used
f(x) = sin(x)-1+sqrt(x)
a = 1
b = 5
#draw the curve f
P = plot(f, (x, a-0.05, b+0.05), thickness=3)
#draw the texts above the graph
P += text("$\\int_{a}^b f(x) dx \\approx
\\int_{a}^b p(x) dx$ ",
( 4.0 , 1.1), fontsize=20, color=’black’)
P += text("$y=f(x)$",(1.7,f(1.7)+0.1), fontsize=20, color=’blue’)
P += text("$y=p(x)$",(1.7,1.0), fontsize=20, color=’black’)

192
5
Numerical Integration
def BasicSimpson(f, aa,bb,x):
#interpolation
p(x)=
(((x-((aa+bb)/2))/(aa-((aa+bb)/2)))) * \
(((x-bb)/(aa-bb)))* f(aa) +(((x-aa)/
(((aa+bb)/2) \ -aa)))*(((x-bb)/
(((aa+bb)/2)-bb)))*f(((aa+bb)/2)) \
+(((x-aa)/(bb-aa))) \ *(((x-((aa+bb)/2))/
(bb-((aa+bb)/2))))*f(bb)
global P
#graph the horizontal lines
P += line([(aa,0),(aa,f(aa))], color=’black’)
P += line([(bb,0),(bb,f(bb))], color=’black’)
P += line([( (aa+bb)/2,0),((aa+bb)/2,f((aa+bb)/2))],
color=’black’)
#plot the interpolating function p(x)
P += plot(p, (x, aa, bb), thickness=3, color = ’black’)
#make the shade - as a polygon with many points
#use only one line for the following 4 lines of code!
P += polygon( [(aa,0),(aa,p(aa))] +
[(x, p(x)) for x in [aa,aa+0.005,..,bb]] +
[(bb,0),(aa,0)], rgbcolor=(0.5,0.8,0.7),
aspect_ratio=’automatic’)
P += list_plot([ (aa,f(aa)), (bb, f(bb)),
((aa+bb)/2, f((aa+bb)/2))],
color = ’black’, size = 70)
#call the basic simpson on each subinterval
BasicSimpson(f, 1, 3, x)
BasicSimpson(f, 3, 5, x)
#show the plot
show(P)
5.2.3
Sage Code
Below we give the Sage implementation for the Composite Simpson’s Rule we derived (5.14), on
page 190.
def CompositeSimpson(f, a, b, n):
#if n is odd return error
if int(n)%2 == 1:
return
"ERROR - n should be even!!!"
#compute the size of each subinterval
h = (b-a)/n

5.2
Simpson’s Rule
193
#here we add all the terms
sum = f(a)
#add the values for all intermediate nodes
for i in [1,2,..,n-1] :
#odd i’s are terms multiplied by 4
if( i%2 == 1 ):
sum += 4* f(a+i*h)
else:
sum += 2* f(a+i*h)
#add the last node
sum +=f(b)
#multiply by h to complete the computation
sum = sum*h/3
#return the sum
return sum.n()
This function returns an error message if n is odd. For even values of n it returns the Composite
Simpson’s Rule estimation for the
R b
a f .x/dx.
Next, we use this code to solve the same problems that we solved in the previous section, where
we used Trapezoidal Rule.
Example 111. Apply the previous Sage code to ﬁnd the value of
Z e
1
sin x
x
dx;
using n D 5 subintervals.
Solution. Since n is odd, we obtain an error message. Hence the code
#define the function we will be using
f(x) = sin(x)/x
#call the function on [0,1], with 5+1 nodes
print CompositeSimpson(f, 1, e, 5)
produces the following error message
ERROR - n should be even!!!
Example 112. Apply the previous Sage code to ﬁnd the value of
Z e
1
sin x
x
dx;
using n D 4 subintervals.

194
5
Numerical Integration
Solution. Adding the following code
#define the function we will be using
f(x) = sin(x)/x
#call the function on [0,1], with 5+1 nodes
print CompositeSimpson(f, 1, e, 4)
we obtain
0.874958585267728
Using the Sage Library function, integral(sin(x)/x,x,1,e).n() we obtained a very
close value:
0.874957198780384
Example 113. Create a table of values obtained using the Composite Simpson’s Rule, with n D
2; 4; 8; 16 and 32, for
Z 1
0
1
1 C x2 dx;
and print out the error of approximation in each case.
Solution. For this, we could use the following Sage code:
#define the function we will be using
f(x) = 1/(1+x^2)
#print the top part of the table
print "simpson’s rule" , ’\t\t’, ’error’
print ’------------------------------------------’
#call the function several times
for power in [1,2,3,4, 5]:
n = 2^power
simpson = CompositeSimpson(f, 0, 1, n).n()
error = (simpson - integral(f(x) ,x,0,1)).n()
print simpson , ’\t’, error
to obtain:
simpson’s rule
error
                      
0.783333333333333
-0.00206483006411495
0.785392156862745
-6.00653470317347e-6
0.785398125614677
-3.77827715780654e-8
0.785398162806206
-5.91242721448282e-10
0.785398163388209
-9.23916498862809e-12
Please compare these results with the ones obtained using Trapezoidal Rule, on page 183.
Example 114. Use the Composite Simpson’s Rule, with n D 32, to ﬁnd an approximate value for
Z 1
0
ex2dx:

5.2
Simpson’s Rule
195
Solution. For this, we could use the following Sage code:
#define the function we will be using
f(x) = e^(-x^2)
#set the value of n
n = 32
#call the function on [0,1], with n+1 nodes
CompositeSimpson(f, 0, 1, n)
and obtain:
0.746824140606985
Using the Sage Library function, integral(f(x),x,0,1).n() we obtain:
0.746824132812427
Example 115. Use the Composite Simpson’s Rule, with n D 64, to ﬁnd an approximate value for
Z e
1
ex2dx:
Solution. Using the following Sage code:
#define the function we will be using
f(x) = e^(x^2)
#set the value of n
n = 64
#call the function on [1,e], with n+1 nodes
CompositeSimpson(f, 1, e, n)
we obtain
323.296088136270
Using the Sage Library function, integral(f(x),x,1,e).n() we obtain:
323.295188678248
5.2.4
Error Bounds
In here, let us use the following notation
I D
Z b
a
f .x/dx

196
5
Numerical Integration
and
S D h
3 Œf .a/ C 4f .x1/ C 2f .x2/ C 4f .x3/ C 2f .x4/
(5.15)
C    C 2f .xn2/ C 4f .xn1/ C f .b/ ;
where
xi D a C i  h; i D 0; 1; : : : ; n;
(5.16)
with
h D b  a
n
;
(5.17)
and n is even.
We give next, without a proof, the following error estimation. The reader interested in the proof of
this result can refer to [5, p. 231].
Theorem 116. Let f be a function deﬁned on Œa; b that is four times differentiable, with f .4/
continuous. Then the error of approximation is given by
I  T D .b  a/h4
180
f .4/./;
(5.18)
for some  in .a; b/.
In particular we have the following estimation for the error of approximation
Corollary 117. Let f be a function deﬁned on Œa; b that is four differentiable, with f .4/ continuous,
such that
ˇˇf .4/.x/
ˇˇ  M, for all x in Œa; b. Then
jI  T j  .b  a/Mh4
180
:
(5.19)
This last result shows that the Composite Simpson’s Rule with evenly spaced nodes converges
quartically.
Another direct consequence of the previous theorem is
Corollary 118. Let f be a polynomial function of degree at most three, deﬁned on Œa; b. Then the
Simpson’s Rule gives us exact answer, that is
I D T:
(5.20)
Compare the results of the following examples with the corresponding ones obtained in the
previous section.
Example 119. How many evenly spaced nodes do we need to use in Composite Simpson’s Rule, in
order to ﬁnd an approximate value for
Z e
1
ex2dx;
with an error less than 0:001?

5.2
Simpson’s Rule
197
Solution. We have f .x/ D ex2, deﬁned on Œ1; e. Hence
f 0.x/ D 2xex2;
f 00.x/ D .2 C 4x2/ex2;
f 000.x/ D .12x C 8x3/ex2;
f .4/.x/ D .12 C 48x2 C 16x4/ex2;
therefore
ˇˇf .4/.x/
ˇˇ  .12 C 48e2 C 16e4/ee2
< 2; 006; 938:
Using formula (5.19), we have
jI  T j  .b  a/Mh4
180
< .2006938/ .e  1/5
180n4
Therefore, from
.2006938/ .e  1/5
180n4
< 0:001
we obtain
n  114:
Example 120. How many evenly spaced nodes do we need to use in Composite Simpson’s Rule, in
order to ﬁnd an approximate value for
Z 1
0
ex2dx;
with an error less than 0:0001? Then estimate the value of
R 1
0 ex2dx.
Solution. We have f .x/ D ex2, deﬁned on Œ0; 1. Hence
f 0.x/ D 2xex2;
f 00.x/ D .2 C 4x2/ex2;
f 000.x/ D .12x C 8x3/ex2;
f .4/.x/ D .12 C 48x2 C 16x4/ex2;

198
5
Numerical Integration
therefore
ˇˇf .4/.x/
ˇˇ  76e:
Using formula (5.19), we have
jI  T j  .b  a/Mh4
180
 19e
45n4 :
Therefore, from
19e
45n4 < 0:0001
we obtain
n  12;
which means we would need at least 12+1=13 evenly spaced nodes to make sure the error of
approximation is less than 0.0001. Using the Sage code we developed earlier, we obtain the following
estimation
Z 1
0
ex2dx ' 1:46266612641848:
Compare this to 1.46265174590718, the value obtained from integrate(e^(x^2), x,
0, 1).n().
5.2.5
Sage Library
If we want to utilize Sage libraries, we can use Sage code similar to the one given in the next example.
Example 121. Find the value of
Z e
1
sin x
x
dx;
using n D 5 subintervals.
Solution. For this, one can use
#import the needed libraries
from scipy.integrate import simps
import scipy
import numpy

5.2
Simpson’s Rule
199
#define the function, the interval [a,b], and n
def f(x):
return sin(x)/x
a=1.0
b=e
n=5
#define the n+1 evenly spaced nodes in [a,b]
x = numpy.array([a+i*(b-a)/n
for i in [0,1,..,n]])
#compute and output the Simpson’s Rule
print
scipy.integrate.simps(f(x), x).n()
to obtain
0.874782324470474
Example 122. Find the value of
Z 1
0
1
1 C x2 dx;
using n D 32 subintervals.
Solution. For this, we can use the following Sage code:
#import the needed libraries
from scipy.integrate import simps
import scipy
import numpy
#define the function, the interval [a,b], and n
def f(x):
return 1/(1+x^2)
a=0
b=1
n=32
#define the n+1 evenly spaced nodes in [a,b]
x = numpy.array([a+i*(b-a)/n
for i in [0,1,..,n]])
#compute and output the Simpson’s Rule
print
scipy.integrate.simps(f(x), x)
to obtain
0.785398163388

200
5
Numerical Integration
5.3
Using the Method of Undetermined Coefﬁcients
Applying the Method of Undetermined Coefﬁcients we used on page 167, we can ﬁnd alternative
ways to obtain new and existing integration rules. In particular, we will see alternative ways to derive
the same formulae given above: the Trapezoidal Rule and the Simpson’s Rule.
5.3.1
Basic Trapezoidal Rule Using the Method of Undetermined
Coefﬁcients
For example, if we want to ﬁnd a rule that approximates
R b
a f .x/dx using only the nodes a and b,
then we would need to ﬁnd A; B such that
Z b
a
f .x/dx ' Af.a/ C Bf.b/:
(5.21)
If we want this rule to be exact for all linear functions, then (by the linearity of the integral), it is
sufﬁcient that the rule is exact for f .x/ D 1, and f .x/ D x. Therefore
Z b
a
1dx D A  1 C B  1;
and
Z b
a
xdx D A  a C B  b:
This leads to
(
A C B D b  a
Aa C Bb D b2a2
2
;
hence
 A D ba
2
B D ba
2
;
giving us the same formula (5.2), given on page 178.
5.3.2
Basic Simpson’s Rule Using the Method of Undetermined
Coefﬁcients
Next, let’s try to ﬁnd a rule that approximates
R b
a f .x/dx using only the nodes a; aCb
2 , and b. We are
trying to ﬁnd A; B, and C such that
Z b
a
f .x/dx ' Af .a/ C Bf
	a C b
2

C Cf.b/:
(5.22)

5.4
Richardson Extrapolation
201
Here, we will try to ﬁnd a rule that is exact for all polynomials up to degree two. Hence, using
again the linearity of integrals, we will solve for A; B; C, such that the approximation given above is
exact for f .x/ D 1, f .x/ D x, and f .x/ D x2. Then
Z b
a
1dx D A  1 C B  1 C C  1;
Z b
a
xdx D A  a C B  a C b
2
C C  b;
and
Z b
a
x2dx D A  a2 C B 
	a C b
2

2
C C  b2:
This leads to
8
ˆ<
ˆ:
A C B C C D b  a
aA C aCb
2 B C bC D b2a2
2
a2A C
 aCb
2
2 B C b2C D b3a3
3
;
hence
8
<
:
A D ba
6
B D 4.ba/
6
C D ba
6
;
giving us the same formula (5.13), given on page 188.
5.4
Richardson Extrapolation
We present here the idea of Richardson Extrapolation and provide a motivation for using it. Then, in
the next section, we’ll see how we can apply Richardson Extrapolation to the Trapezoidal Rule, in
order to obtain a more accurate approximation formula, Romberg Method. Please note that the idea of
Richardson Extrapolation can be easily applied to other approximation techniques too, and not only to
numerical integration. In particular, it was already used on page 164, although this was not mentioned
explicitly.
We have seen on page 184 that we have the following error of approximation in the case of
Trapezoidal Rule
I  T D O.h2/;
and
I  S D O.h4/:
for the Simpson’s Rule (see page 196). Recall that h is the size of each of the n subintervals of Œa; b.
The same discussion can be done, similarly, based on n, instead of h.

202
5
Numerical Integration
In general, let’s suppose we are using some approximation method, M D Mh, whose error is of
the form
I  Mh D O.hp/:
Let’s be a little more precise and assume the error of approximation looks something like
I  Mh D aphp C aqhq C arhr C : : :
(5.23)
where r > q > p.
If we apply the same method for a smaller value of h (here, for simplicity, let’s look at h
2), we
obtain
I  Mh=2 D ap
	h
2

p
C aq
	h
2

q
C ar
	h
2

r
C   
(5.24)
D ap
2p hp C aq
2q hq C ar
2r hr C    :
Therefore, we can linearly combine (5.23) and (5.24) to obtain a more accurate formula. We can use
the following linear combination, to cancel the hp term:
.I  Mh/  2p 
I  Mh=2

D

aphp C aqhq C arhr C   

2p ap
2p hp C aq
2q hq C ar
2r hr C   

D
	
1 
1
2qp

aqhq C
	
1 
1
2rp

arhr C    ;
therefore
I 
	
2p
2p  1Mh=2 
1
2p  1Mh

D aqhq C arhr C    ;
where
aq D
1
.1  2p/
	
1 
1
2qp

aq;
ar D
1
.1  2p/
	
1 
1
2rp

ar;
: : :
Hence, the following linear combination of two approximations
M D
	
2p
2p  1Mh=2 
1
2p  1Mh

;
(5.25)
gives us a better estimate,
I  M D aqhq C arhr C    :

5.5
Romberg Method
203
We can repeat this process on the values of M, to obtain even better estimates
I  M D arhr C    ;
and so on.
5.5
Romberg Method
5.5.1
Motivation
We can apply the Richardson Extrapolation technique to the Trapezoidal Rule, in order to improve the
error of approximation. For Trapezoidal Rule we had:
I  T D .b  a/h2
12
f 00./;
hence
I  T D a2h2 C a3h3 C a4h4 C    :
In this section, we’ll assume that f has as many derivatives as needed. And a consequence of this is
the following Euler–MacLaurin Formula
I  T D a2h2 C a4h4 C a6h6 C    :
Using (5.25), for p D 2, we obtain the values
M D
	
22
22  1Mh=2 
1
22  1Mh

(5.26)
D
4
4  1Mh=2 
1
4  1Mh
whose error of approximation is given by
I  M D a4h4 C a6h6 C    ;
hence they represent improved estimations.
If we apply this step again on the values of M
;s, now with p D 4, from (5.25), we would the values
M D
	
24
24  1M h=2 
1
24  1M h

(5.27)
whose error of approximation is given by
I  M D a6h6 C : : : ;
and so on.

204
5
Numerical Integration
In general, for p D k, we would use
M D
	
22k
22k  1M h=2 
1
22k  1M h

(5.28)
whose error of approximation is given by
I  M D a2kC2h2kC2 C : : : ;
(5.29)
Hence we obtained the following algorithm (called the Romberg Integration Method) for
estimating
R b
a f .x/dx.
Step 1:
We start with using the Basic Trapezoidal Rule on the interval Œa; b, to obtain R.0; 0/.
Then, using the Composite Trapezoidal Rule on 21 equal subintervals, we obtain R.1; 0/.
Then, halving each subinterval, we use the Composite Trapezoidal Rule on 22 equal subintervals,
to obtain R.2; 0/.
We keep on going, in the same fashion, several times, and obtain R.n; 0/.
This step can be further improved by using a recursive version of the Trapezoidal Rule. In order to
simplify the presentation of this algorithm, we did not include this step here.
Step 2:
Using the Richardson Extrapolation technique, and formula (5.26)
R.k; 1/ D
22
22  1R.k; 0/ 
22
22  1R.k  1; 0/; for k D 1; 2; : : : ; n:
Step 3:
Using the Richardson Extrapolation technique, and formula (5.26)
R.k; 2/ D
24
24  1R.k; 1/ 
1
24  1R.k  1; 1/; for k D 2; : : : ; n:
and so on
Step n:
Using the Richardson Extrapolation technique, and formula (5.26)
R.n; n/ D
22n
22n  1R.n; n  1/ 
1
22n  1R.n  1; n  1/:

5.5
Romberg Method
205
5.5.2
Algorithm
The Romberg Integration Method is described as obtaining a triangular array of numbers:
R.0; 0/
R.1; 0/
R.1; 1/
R.2; 0/
R.2; 1/
R.2; 2/
: : :
: : :
: : :
: : :
R.n  1; 0/ R.n  1; 1/ R.n  1; 2/ : : : R.n  1; n  1/
R.n; 0/
R.n; 1/
R.n; 2/
: : :
R.n; n  1/
R.n; n/
(each value being a better and better estimation of
R b
a f .x/dx).
These numbers are obtained as follows
R.i; 0/
are given by the applying the Trapezoidal Rule on 2i equal subintervals of Œa; b, i D 0; 1; : : : ; n, and
R.i; j / D
22i
22i  1R.i; j  1/ 
1
22i  1R.i  1; j  1/;
(5.30)
for i D 1; 2; : : : ; n, and j D 1; 2; : : : ; i.
At the end of this, R.n; n/ will represent our best estimate:
Z b
a
f .x/dx ' R.n; n/:
5.5.3
Sage Code
We present below our Sage implementation of the previous algorithm.
def CompositeTrapezoidal(f, a, b, n):
#include this with your code!
def RombergAlgorithm(f, a,b,n):
#create an ’empty’ n+1 by n+1 array
R = [[0 for i in range(n+1)] for i in range(n+1)]
#compute the first column, the R(i,0)
for row in [0,1,..,n]:
R[row][0] = CompositeTrapezoidal(f, a, b, 2^row)
#compute the remaining columns
for column in [1,2,..,n]:
for row in [1,2,..,n]:
if(row>=column):
R[row][column] = ((2^(2*row))/(2^(2*row)-1))*
R[row][column-1] -(1/(2^(2*row)-1))*R[row-1][column-1]

206
5
Numerical Integration
#print the array
for row in [0,1,..,n]:
print [ (R[row][column]).n()
for column in
[0,1,..,row] ]
Let’s use this code to solve some problems.
Example 123. Apply the previous Sage code to estimate
Z e
1
sin x
x
dx;
using Romberg Method with n D 5.
Solution. For this, to the previous Sage code, we simply add
#define the function we will be using
f(x) = sin(x)/x
#define the parameters and call the function
n = 5
a = 1
b = e
RombergAlgorithm(f, a, b, n)
we obtain
[0.852773800639980]
[0.869425981076183, 0.874976707888250]
[0.873575434219842, 0.873852064429419, 0.873777088198830]
[0.874611824389402, 0.874628275027014, 0.874640595830151, 0.874654302300489]
[0.874870859381198, 0.874871875204695, 0.874872830499510, 0.874873741223703,
0.874874601768500]
[0.874935614193412, 0.874935677492349, 0.874935739860177, 0.874935801355153,
0.874935862019993, 0.874935921902937]
If we change the default precision in the print statement of the CompositeTrapezoidal()
method, and replace .n() by .n(30), we obtain:
[0.85277380]
[0.86942598, 0.87497671]
[0.87357544, 0.87385207, 0.87377709]
[0.87461182, 0.87462828, 0.87464060, 0.87465430]
[0.87487086, 0.87487187, 0.87487283, 0.87487374, 0.87487460]
[0.87493561, 0.87493568, 0.87493574, 0.87493580, 0.87493586,
0.87493592]
Hence
Z e
1
sin x
x
dx ' 0:874935921902937:
Using the Sage Library function, integral(sin(x)/x,x,1,e).n() we obtain:
0.874957198780384

5.5
Romberg Method
207
Example 124. Apply Romberg Method with n D 3 to estimate
Z 1
0
1
1 C x2 dx:
Solution. For this, we use the following Sage code:
#define the function
f(x) = 1/(1+x^2)
#define the parameters and call the function
n = 3
a = 0
b = 1
RombergAlgorithm(f, a, b, n)
to obtain
[0.750000000000000]
[0.775000000000000, 0.783333333333333]
[0.782794117647059, 0.783313725490196, 0.783312418300654]
[0.784747123622772, 0.784778123717625, 0.784801368133933,
0.784825002258271]
Therefore we conclude that
Z 1
0
1
1 C x2 dx ' 0:784825002258271:
Using the Sage Library function, integral(1/(1+x^2),x,0,1).n() we obtain:
0.785398163397448
Example 125. Modify the Sage code for the Romberg Method, so it only prints the last value from
table. Then use it to estimate
Z 1
0
ex2dx;
with n D 7.
Solution. For this, we only need to modify the last two statements of the RombergAlgorithm()
into:
#print only the last value of the array
print ’ Romberg Method Estimate = ’ , (R[n][n]).n()
and add the following
#define the function
f(x) = e^(-x^2)
#define the parameters and call the function
RombergAlgorithm(f, 0, 1, 7)
to obtain
Romberg Method Estimate =
0.746820395325466

208
5
Numerical Integration
Using the Sage Library function, integral(f(x),x,0,1).n() we obtain:
0.746824132812427
Example 126. Use the previous Sage code, with n D 8, to estimate
Z e
1
ex2dx:
Solution. For this, we use the following Sage code:
#define the function we will be using
f(x) = e^(x^2)
#call the function
RombergAlgorithm(f, 1, e, 8)
to obtain
Romberg Method Estimate =
323.328183013859
Using the Sage Library function, integral(f(x),x,1,e).n() we obtain
323.295188678248
5.5.4
Error Bounds
From (5.28) and (5.29), given on page 204 we can see that
I  R.n; n/ D a2nC2h2nC2 C    D O

h2nC2
:
(5.31)
Hence, with some extra work on the values obtained using Simpson’s Rule, we can obtain a much
more accurate approximation.
5.6
Newton–Cotes Formulae
Most of the numerical integration formulae have the following form
Z b
a
f .x/dx ' w0f .x0/ C w1f .x1/ C    C wnf .xn/:
(5.32)
One way to obtain the weights w0; w1; : : : ; wn is by approximating f .x/ with a polynomial p.x/
that interpolates f at the nodes x0; x1; : : : ; xn. Hence, using (3.7) and (3.5) we would obtain
Z b
a
f .x/dx '
Z b
a
p.x/
D
Z b
a
Œf .x0/L0.x/ C f .x1/L1.x/ C    C f .xn/Ln.x/ dx
D
"Z b
a
L0.x/dx
#
f .x0/ C    C
"Z b
a
Ln.x/dx
#
f .xn/

5.6
Newton–Cotes Formulae
209
giving us
w0 D
Z b
a
L0.x/dx; w1 D
Z b
a
L1.x/dx; : : : ; wn D
Z b
a
Ln.x/dx:
If the nodes x0; x1; : : : ; xn are evenly spaced (that is, xi D x0 C i  h, with h D .xnx0/
n
, for i D
0; 1; : : : ; n/, then the formula (5.32) is called a Newton–Cotes formula. There are two types of
Newton–Cotes formulae: closed (if the nodes include x0 D a, and xn D b/, and open (if they do
not include x0 D a, and xn D b). Without a proof, we give, below, some of these formulae. Interested
reader may also refer to [1, See Section 25.4, p. 885], for a more comprehensive list. For some 
between a and b we have:
5.6.1
Closed Newton–Cotes Formulae
Trapezoid Rule (n D 1):
Z b
a
f .x/dx D .b  a/
f .a/ C f .b/
2

 .b  a/3
12
f 00./:
Simpson’s Rule (n D 2):
Z b
a
f .x/dx D .b  a/
6
Œf .a/ C 4f .x1/ C f .b/  .b  a/5
2880
f .4/./:
Simpson’s 3/8 rule (n D 3):
Z b
a
f .x/dx D .b  a/
8
Œf .a/ C 3f .x1/ C 3f .x2/ C f .b/  .b  a/5
6480
f .4/./:
Boole’s rule (n D 4):
Z b
a
f .x/dx D .b  a/
90
Œ7f .a/ C 32f .x1/ C 12f .x2/ C 32f .x3/ C 7f .b/
 .b  a/7
1935360f .6/./:
5.6.2
Open Newton–Cotes Formulae
Midpoint Rule (n D 2):
Z b
a
f .x/dx D .b  a/f .x1/ C .b  a/3
24
f 00./:

210
5
Numerical Integration
Two-Point Newton–Cotes Open Rule (n D 3):
Z b
a
f .x/dx D .b  a/
2
Œf .x1/ C f .x2/ C .b  a/3
108
f 00./:
Three-Point Newton–Cotes Open Rule (n D 4):
Z b
a
f .x/dx D .b  a/
3
Œ2f .x1/  f .x2/ C 2f .x3/ C 7.b  a/5
23040
f .4/./:
Four-Point Newton–Cotes Open Rule (n D 5):
Z b
a
f .x/dx D .b  a/
24
Œ11f .x1/ C f .x2/ C f .x3/ C 11f .x4/
C19.b  a/5
90000
f .4/./:
5.7
Gauss Quadrature Formula
5.7.1
A Brief Outline
In the previous formulae, we ﬁxed the nodes x0; x1; : : : ; xn to be evenly spaced in the interval Œa; b,
and searched for appropriate coefﬁcients w0; w1, : : :, wn to obtain a quadrature formula of the form
Z b
a
f .x/dx ' w0f .x0/ C w1f .x1/ C    C wnf .xn/:
(5.33)
To obtain the Gauss Quadrature Formula, we will not hold these nodes, evenly distributed. This
ﬂexibility will allow us to obtain more accurate quadrature formulae that are exact for polynomials of
higher degrees. We will employ the Method of Undetermined Coefﬁcients technique in order to obtain
these results.
As we have seen in one of the previous sections, the Trapezoidal Rule has the form
Z b
a
f .x/dx ' w0f .a/ C w1f .b/;
(5.34)
and one way to ﬁnd the weights w0 and w1 (See the Subsection “Using the Method of Undetermined
Coefﬁcients”) was to impose that the formula (5.34) is exact for f .x/ D 1 and x. The nodes x0 D a
and x1 D b were ﬁxed.
By not ﬁxing the values of the nodes to x0 D a and x1 D b, one can obtain a higher degree of
accuracy. For example, we can ﬁnd nodes x0; x1 and weights w0; w1 such that
Z b
a
f .x/dx ' w0f .x0/ C w1f .x1/;
(5.35)
is exact for f .x/ D 1, x, x2, and x3: Then, by linearity of the integrals, the formula will be exact for
all polynomials of degree at most 3. See the example given below.

5.7
Gauss Quadrature Formula
211
Similarly, the Simpson’s Rule has the form
Z b
a
f .x/dx ' w0f .a/ C w1f .a C b
2
/ C w2f .b/;
(5.36)
and the weights w0; w1; w2 were chosen such that the formula (5.36) is exact for f .x/ D 1, f .x/ D x,
and x2. Here, the nodes x0 D a; x1 D aCb
2
and x2 D b were ﬁxed.
By not ﬁxing the values of the nodes to x0 D a; x1 D aCb
2 , and x2 D b, we can expect to obtain a
higher degree of accuracy. For example, we can ﬁnd the nodes x0; x1; x2 and weights w0; w1; w2 such
that
Z b
a
f .x/dx ' w0f .x0/ C w1f .x1/ C w2f .x2/;
(5.37)
is exact for f .x/ D 1, x, x2; x3; x4, and x5. Then, by linearity of the integrals, the formula will be
exact for all polynomials of degree at most 5. See the example given below.
To simplify our discussion, we will ﬁrst only consider integrals of the form
R 1
1 f .x/dx. Then,
using the change of variables
t D a C b
2
C b  a
2
x
(5.38)
we obtain a formula applicable to any interval Œa; b
Z b
a
f .t/dt D b  a
2
Z 1
1
f
	a C b
2
C b  a
2
x

dx
and hence we will replace a formula obtained on Œ1; 1
Z 1
1
f .x/dx ' w0f .x0/ C w1f .x1/ C    C wnf .xn/;
with one applicable on Œa; b
Z b
a
f .x/dx ' b  a
2

w0f
	a C b
2
C b  a
2
x0

C    C wnf
	a C b
2
C b  a
2
xn


:
(5.39)
5.7.2
Algorithm by Example
Example 127. Determine x0; x1; w0; w1, such that
Z 1
1
f .x/dx ' w0f .x0/ C w1f .x1/
(5.40)
is exact for f .x/ D 1, x, x2, and x3. Then obtain the corresponding quadrature formula for
R b
a f .x/dx.

212
5
Numerical Integration
Solution. Knowing that (5.40) is exact for f .x/ D 1, x, x2, and x3 we obtain the following equations
Z 1
1
1dx D w0  1 C w1  1
Z 1
1
xdx D w0  x0 C w1  x1
Z 1
1
x2dx D w0  x2
0 C w1  x2
1
Z 1
1
x3dx D w0  x3
0 C w1  x3
1
hence solving
8
ˆˆ<
ˆˆ:
w0 C w1 D 2
w0x0 C w1x1 D 0
w0x2
0 C w1x2
1 D 2
3
w0x3
0 C w1x3
1 D 0
:
we obtain
w0 D w1 D 1
x0 D  1
p
3
; x1 D
1
p
3
giving us the following Gaussian Quadrature Formula
Z 1
1
f .x/dx ' f
	
 1
p
3

C f
	 1
p
3

:
(5.41)
Using the change of variable given in (5.39), we obtain the following Gaussian Quadrature Formula
that works for any interval Œa; b W
Z b
a
f .x/dx ' b  a
2

f
	a C b
2
 b  a
2
 1
p
3

C f
	a C b
2
C b  a
2
 1
p
3


:
Example 128. Determine x0; x1; x2; w0; w1; w2, such that
Z 1
1
f .x/dx ' w0f .x0/ C w1f .x1/ C w2f .x2/
(5.42)
is exact for f .x/ D 1, x, x2; x3; x4, and x5. Then obtain the corresponding quadrature formula for
R b
a f .x/dx.

5.7
Gauss Quadrature Formula
213
Solution. Knowing that (5.40) is exact for f .x/ D 1, x, x2; x3; x4, and x5 we obtain the following
equations
Z 1
1
1dx D w0  1 C w1  1 C w2  1
Z 1
1
xdx D w0  x0 C w1  x1 C w2  x2
Z 1
1
x2dx D w0  x2
0 C w1  x2
1 C w2  x2
2
Z 1
1
x3dx D w0  x3
0 C w1  x3
1 C w2  x3
2
Z 1
1
x4dx D w0  x4
0 C w1  x4
1 C w2  x4
2
Z 1
1
x5dx D w0  x5
0 C w1  x5
1 C w2  x5
2
hence solving
8
ˆˆˆˆˆˆˆ<
ˆˆˆˆˆˆˆ:
w0 C w1 C w2 D 2
w0x0 C w1x1 C w2x2 D 0
w0x2
0 C w1x2
1 C w2x2
2 D 2
3
w0x3
0 C w1x3
1 C w2x3
2 D 0
w0x4
0 C w1x4
1 C w2x4
2 D 2
5
w0x5
0 C w1x5
1 C w2x5
2 D 0
:
we obtain
w0 D 5
9 D w2; w1 D 8
9
x0 D 
r
3
5 D x2; x1 D 0
giving us the following Gaussian Quadrature Formula
Z 1
1
f .x/dx ' 5
9f
 

r
3
5
!
C 8
9f .0/ C 5
9f
 r
3
5
!
:
(5.43)
Using the change of variable given in (5.39), we obtain the following Gaussian Quadrature Formula
that works for any interval Œa; b W
Z b
a
f .x/dx ' b  a
2
"
5
9f
 
a C b
2
 b  a
2

r
3
5
!
(5.44)
C8
9f
	a C b
2

C 5
9f
 
a C b
2
 b  a
2

r
3
5
!#
:

214
5
Numerical Integration
5.7.3
The General Algorithm
The previous two examples suggest us the following technique: for a ﬁxed n; using the Method
of Undetermined Coefﬁcients, we are looking to ﬁnd the nodes x0; x1; : : : ; xn and the weights
w0; w1;    ; wn such that
Z 1
1
f .x/dx ' w0f .x0/ C w1f .x1/ C    C wnf .xn/
is exact for each of the monomials 1; x; x2; : : : ; x2nC1. Hence, the formula will be exact for any
polynomial of degree up to 2n C 1.
Hence, we need to solve for x0; x1; : : : ; xn and w0; w1; : : : ; wn from
8
ˆˆˆˆˆˆˆˆˆ<
ˆˆˆˆˆˆˆˆˆ:
w0 C w1 C    C wn D 2
w0x0 C w1x1 C    C wnxn D 0
w0x2
0 C w1x2
1 C    C wnx2
n D 2
3
w0x3
0 C w1x3
1 C    C wnx3
n D 0
: : :
w0x2n
0 C w1x2n
1 C    C wnx2n
n D
2
2nC1
w0x2nC1
0
C w1x2nC1
1
C    C wnx2nC1
n
D 0
(5.45)
Once we solve this system, by a change of variables, we obtain the corresponding Gauss
Quadrature Formula for the interval Œa; b W
Z b
a
f .x/dx ' b  a
2

w0f
	a C b
2
C b  a
2
x0

C
(5.46)
   C wnf
	a C b
2
C b  a
2
xn


:
As you can see from the previous two examples, the system (5.45) will get increasingly
complicated, as n increases. For this reason, in practice, alternative ways are being used. For example,
it can be shown that x0; x1; : : : ; xn are the solutions of the Legendre polynomials PnC1.x/, where
P0.x/ D 1; P1.x/ D x; and
(5.47)
PnC1.x/ D 2n C 1
n C 1 xPn.x/ 
n
n C 1Pn1.x/; for n D 1; 2; : : : :
From (5.47) and (5.45) we can obtain the following list of nodes and weights

5.7
Gauss Quadrature Formula
215
n Nodes xi
Weights wi
1  1
p
3
1
1
p
3
1
2 
q
3
5
5
9
0
8
9
q
3
5
5
9
3 
r
3
7 C 2
7
q
6
5
1
2 
p
30
36

r
3
7  2
7
q
6
5
1
2 C
p
30
36
r
3
7  2
7
q
6
5
1
2 C
p
30
36
r
3
7 C 2
7
q
6
5
1
2 
p
30
36
4  1
3
r
5 C 2
q
10
7
161
450  13
p
70
900
 1
3
r
5  2
q
10
7
161
450 C 13
p
70
900
0
128
225
1
3
r
5  2
q
10
7
161
450 C 13
p
70
900
1
3
r
5 C 2
q
10
7
161
450  13
p
70
900
(5.48)
As one can easily notice, although Gauss Quadrature Formulae are exact for higher degree
polynomials, and therefore we expect more accurate answers in less steps, these steps themselves
are more complex and require more work.
Example 129. Use Gaussian Quadrature to estimate
R 5
1 .sin x  1 C px/dx.
Solution. For n D 1, we can use the following Gaussian Quadrature Formula:
Z 5
1
f .x/dx ' 2

f
	
3  2
p
3

C f
	
3 C 2
p
3


:
Hence, using for example the following Sage code
f(x) = sin(x)-1+sqrt(x)
( 2*( f(3-(2/sqrt(3))) + f(3+(2/sqrt(3))))).n()
we obtain
Z 5
1
.sin x  1 C px/dx ' 3:02161108118542;
which is a pretty good answer. Compare this with 4.47445875057819, obtained using Trapezoid
Method, and the true value of 3.04353337873755.

216
5
Numerical Integration
For n D 2, we can use
Z 5
1
f .x/dx ' 2
"
5
9f
 
3  2 
r
3
5
!
C8
9f .3/ C 5
9f
 
3  2 
r
3
5
!#
:
Hence, using for example the following Sage code
f(x) = sin(x)-1+sqrt(x)
( 2*( f(3-(2/sqrt(3))) + f(3+(2/sqrt(3))))).n()
we obtain
Z 5
1
.sin x  1 C px/dx ' 3:04505358424349:
5.7.4
Sage Code
We give, below, Sage implementation for the Gauss Quadrature, based on (5.47) and (5.48).
For n D 1 W
def GaussQuad1(f, a, b):
w0 = 1
w1 = 1
x0 = -1/sqrt(3)
x1 = 1/sqrt(3)
return (b-a)/2*( w0* f( (a+b)/2+(b-a)/2*x0)
+
w1* f( (a+b)/2+(b-a)/2*x1) )
For n D 2 W
def GaussQuad2(f, a, b):
w0 = 5/9
w1 = 8/9
w2 = 5/9
x0 = -sqrt(3/5)
x1 = 0
x2 = sqrt(3/5)
return (b-a)/2*( w0* f( (a+b)/2+(b-a)/2*x0)
+
w1*f( (a+b)/2+(b-a)/2*x1)+
w2*f( (a+b)/2+(b-a)/2*x2) )
Similar code can be written for higher values of n.
Example 130. Estimate the value of
R 1
0
1
1Cx2 dx.
Solution. Using the previous Sage code, and
f(x) =
1/(1+x^2)
#we print two Gauss Quadratures
GaussQuad1(f,0,1).n(), GaussQuad2(f,0,1).n()
we obtain
(0.786885245901639, 0.785267034990792)

5.8
An Application to Materials Science and Engineering
217
Therefore we conclude that
Z 1
0
1
1 C x2 dx  0:786885245901639
and
Z 1
0
1
1 C x2 dx  0:785267034990792:
Example 131. Estimate the value of
R e
1 ex2dx.
Solution. Using the previous Sage code, and
f(x) =
e^(x^2)
#we print Gauss Quadratures and the exact answer
print GaussQuad1(f,0,1).n()
print GaussQuad2(f,0,1).n()
print integral(f(x),x,0,1).n()
we obtain
1.45416788923913
1.46240971147732
1.46265174590718
5.8
An Application to Materials Science and Engineering
Fick’s second law of diffusion is given by the following (second order differential equation):
@C
@t D D @2C
@x2 :
Under certain (boundary) conditions, this can be solved and the solution has the form
Cx  C0
Cs  C0
D 1  erf
	
x
2
p
Dt

;
with Cs surface concentration, which remains constant, C0 the initial concentration, and
erf.x/ D
2
p
Z x
0
et2dt
called the error function. See [4] for more details.
Assuming x D 4  103 cm, C0 D 0, and that the surface concentration Cs D 7  1018 cm3 is held
constant, ﬁnd the donor concentration Cx of germanium if diffusion is carried out for two hours at
790 ıC. Use D790ıC D 4:8  1011 cm2=s.

218
5
Numerical Integration
Solution. We have
Cx  0
Cs  0 D 1  erf
 
4  103
2
p
.4:8  1011/ .2  3600/
!
hence the donor concentration of germanium is
Cx D 7  1018 
 
1  erf
 
4  103
2
p
.4:8  1011/ .2  3600/
!!
:
Using the following Sage code:
def CompositeSimpson(f, a, b, n):
#GIVEN EARLIER IN THIS CHAPTER
#define the function f(x)
f(x) = e^-(x^2)
#use Composite Simpson Method to compute
#the error function using 100+1 nodes
def erf(xx):
return
(2/sqrt(pi) * CompositeSimpson(f, 0, xx, 100))
#display the answer
print "answer = ", 7*10^18*(1-
erf(4*10^-3/(2*sqrt(4.8*(10^(-11))*2*3600)))).n()
we obtain that
answer =
1.04992815120886e13
hence
Cx D 1:0499  1013=cm3:
5.9
Exercises
1. Using the Composite Trapezoidal Rule, and the nodes
˚
0; 1
6; 1
3; 1
2; 1

, ﬁnd an approximate value
for
Z 1
0
ecos xdx:
Estimate the error.
2. Using the Composite Trapezoidal Rule, and the nodes
˚
0; 
6 ; 
3 ; 
2 ; 

, ﬁnd an approximate value
for
Z 
0
sin x
x
dx:
Estimate the error.

5.9
Exercises
219
3. Using the Composite Trapezoidal Rule, with evenly spaced nodes, and n D 3, ﬁnd an
approximate value for
Z 1
0
ex2dx:
Estimate the error.
4. Using the Composite Simpson’s Rule, with evenly spaced nodes, and n D 2; ﬁnd an approximate
value for
Z 1
0
ex2dx:
Estimate the error.
5. In the Romberg Method, what will the value of R.6; 3/ be, if R.6; 2/ D 10 and R.5; 2/ D 8‹
6. In the Romberg Method, what will the value of R.5; 5/ be, if R.5; 4/ D 10 and R.4; 4/ D 8‹
7. Use Romberg Method, to estimate
R 1
0 ex2dx by R.1; 1/.
8. Using the Romberg Method, with n D 4, to estimate
Z 1
0
ex2dx:
9. Using the Composite Trapezoidal Rule, with evenly spaced nodes, and n D
3, ﬁnd an
approximate value for
Z 1
0
sin x
x
dx:
Estimate the error.
10. Using the Composite Simpson’s Rule, with evenly spaced nodes, and n D 2; ﬁnd an approximate
value for
Z 1
0
sin x
x
dx:
Estimate the error.
11. Using the Romberg Method, with n D 4, to estimate
Z 1
0
sin x
x
dx:
12. Using the Composite Trapezoidal Rule, with evenly spaced nodes, and n D 2, ﬁnd an
approximate value for
Z 1
1
ecos xdx:
Estimate the error.

220
5
Numerical Integration
13. Using the Composite Trapezoidal Rule, with evenly spaced nodes, and n D 4, ﬁnd an
approximate value for
Z 1
1
ecos xdx:
14. Using the Romberg Method, with n D 4, to estimate
Z 1
1
ecos xdx:
15. Using the Composite Trapezoidal Rule, with evenly spaced nodes, and n D 4, ﬁnd an
approximate value for
Z 1
0
1
1 C x2 dx:
Estimate the error.
16. Using the Composite Trapezoidal Rule, with evenly spaced nodes, and n D
4, ﬁnd an
approximate value for
Z 1
0
arctan xdx:
Estimate the error.
17. Using the Composite Simpson’s Rule, with evenly spaced nodes, and n D 4; ﬁnd an approximate
value for
Z 1
0
arctan xdx:
Estimate the error.
18. Using the Composite Trapezoidal Rule, and the table
x 0:2
0:4
0:6
0:8
1:0
y 7:11 10:21 20:98 32:91 1:12 ;
estimate
R 1
0:2 f .x/dx.
19. Using the Composite Simpson’s Rule, and the table
x 0:2
0:4
0:6
0:8
1:0
y 7:11 10:21 20:98 32:91 1:12 ;
estimate
R 1
0:2 f .x/dx.
20. Using the Composite Trapezoidal Rule, and the table
x 0 0:4 0:7 0:8 1:0
y 7 10 20 32 1
;
estimate
R 1
0 f .x/dx.

5.9
Exercises
221
21. How many evenly spaced nodes do one need to use in the Composite Trapezoidal Rule in order
to estimate
Z 1
1
ex2dx
with error less than 0.0001?
22. How many evenly spaced nodes do one need to use in the Composite Trapezoidal Rule in order
to estimate
Z 1
1
ecos2.x/dx
with error less than 0.0001?
23. How many evenly spaced nodes do one need to use in the Composite Trapezoidal Rule in order
to estimate
Z 
1
sin.x/
x
dx
with error less than 0.0001?
24. Estimate
R 2
2 ex3dx, using the nodes and weights given in (5.48), for n D 1.
25. Estimate
R 2
0
sin x
x dx, using the nodes and weights given in (5.48), for n D 2.
26. Estimate
R 2
2 ex2dx, using the nodes and weights given in (5.48), for n D 3.
27. Estimate
R 2
2 ex3dx, using the nodes and weights given in (5.48), for n D 4.
28. Estimate
R 1
1 ecos xdx, using the nodes and weights given in (5.48), for n D 1.
29. Estimate
R 1
1 ecos xdx, using the nodes and weights given in (5.48), for n D 2.
30. Determine the weights w0, and w1 such that the estimation
Z 4
0
f .x/dx ' w0f .0/ C w1f .4/
is exact for all polynomials of as large as possible degree. What is that degree?
31. Determine the weights w0, and w1, and the nodes x0, and x1 such that the estimation
Z 4
0
f .x/dx ' w0f .x0/ C w1f .x1/
is exact for all polynomials of as large as possible degree. What is that degree?
32. Determine the weights w0, and w1 such that the estimation
Z 1
0
pxf .x/dx ' w0f .0/ C w1f .1/
is exact for all polynomials of as large as possible degree. What is that degree?
33. Determine the weight w0, and the node x0, such that the estimation
Z 1
0
pxf .x/dx ' w0f .x0/
is exact for all polynomials of as large as possible degree. What is that degree?

222
5
Numerical Integration
34. Determine the weights w0, and w1, and the nodes x0, and x1 such that the estimation
Z 1
0
pxf .x/dx ' w0f .x0/ C w1f .x1/
is exact for all polynomials of as large as possible degree. What is that degree?
35. Determine the weights w0, and w1 such that the estimation
Z b
a
f .x/dx ' w0f .a/ C w1f 0.b/
is exact for all polynomials of as large as possible degree. What is that degree?
5.10
Computer Exercises
1. Create a table of values obtained using the Composite Trapezoidal Rule, with n D 1; 2; 4; 8; 16
and 32, for
Z 1
0
ex2dx:
Also output the estimated errors, and the actual errors in each case.
2. Create a table of values obtained using the Composite Simpson’s Rule, with n D 2; 4; 8; 16 and
32, for
Z 1
0
ex2dx:
Also output the estimated errors, and the actual errors in each case.
3. Create a table of values obtained using the Composite Trapezoidal Rule, with n D 1; 2; 4; 8; 16
and 32, for
Z 1
0
sin x
x
dx:
Also output the estimated errors, and the actual errors in each case.
4. Create a table of values obtained using the Composite Simpson’s Rule, with n D 2; 4; 8; 16 and
32, for
Z 1
0
sin x
x
dx:
Also output the estimated errors, and the actual errors in each case.
5. Create a table of values obtained using the Composite Trapezoidal Rule, with n D 1; 2; 4; 8; 16
and 32, for
Z 1
1
ecos xdx:
Also output the estimated errors.

5.10
Computer Exercises
223
6. Create a table of values obtained using the Composite Simpson’s Rule, with n D 1; 2; 4; 8; 16
and 32, for
Z 1
1
ecos xdx:
Also output the estimated errors.
7. Create Sage code that will use the Composite Trapezoidal Rule for nodes that may not necessarily
be evenly spaced in Œa; b. Then use it to compute
Z 1
0
sin x
x
dx:
for the following nodes
˚
1; 1
2; 1
4; 1
8; 1
16 ; 1
32; 0

.
8. Create Sage code that will use the Composite Trapezoidal Rule for nodes that may not necessarily
be evenly spaced in Œa; b. Then use it to compute
Z 1
1
ex2dx:
using Chebyshev’s nodes given in formula (3.20), on page 149. Apply this for n D 8; 16; 32 and
64.
9. Create Sage code that will use the Composite Trapezoidal Rule for nodes that may not necessarily
be evenly spaced in Œa; b. Then use it to compute
Z 1
1
ex2dx:
using Chebyshev’s nodes given in formula (3.20), on page 149. Apply this for n D 8; 16; 32 and
64.
10. Using Trapezoidal Rule, estimate
Z 1
1
ex2dx:
with an error less than 0.000001.
11. Using Simpson’s Rule, estimate
Z 1
1
ex2dx:
with an error less than 0.000001
12. Using Trapezoidal Rule, estimate
Z 1
1
ecos xdx:
with an error less than 0.000001.

224
5
Numerical Integration
13. Using Simpson’s Rule, estimate
Z 1
1
ecos xdx:
with an error less than 0.000001.
14. Using the Romberg Method, with n D 8, to estimate
Z 1
1
ecos xdx:
15. Using Trapezoidal Rule, estimate
Z 2
0
ex2dx:
with an error less than 0.000001.
16. Using Simpson’s Rule, estimate
Z 2
0
ex2dx:
with an error less than 0.000001.
17. Using the Romberg Method, with n D 16, to estimate
Z 2
0
ex2dx:
18. Estimate
R 2
0 ex2dx, using the nodes and weights given in (5.48), for n D 1.
19. Estimate
R 2
0 ex2dx, using the nodes and weights given in (5.48), for n D 2.
20. Estimate
R 2
0 ex2dx, using the nodes and weights given in (5.48), for n D 3.
21. Estimate
R 2
0 ex2dx, using the nodes and weights given in (5.48), for n D 4.
22. Estimate
R 
0 e sin 2xdx, using the nodes and weights given in (5.48), for n D 3.
23. Estimate
R 1
0
sin x
x dx, using the nodes and weights given in (5.48), for n D 3.
24. Estimate
R 1
0
1
p
sin x dx, using the nodes and weights given in (5.48), for n D 3.
References
1. Abramowitz, M., Stegun, I.A. (eds.): Handbook of Mathematical Functions with Formulae, Graphs, and Mathemat-
ical Tables. Dover, New York (1972)
2. Atkinson, K., Han, W.: Elementary Numerical Analysis, 3rd edn. Wiley, New York (2003)
3. Blanco-Silva, F.J.: Learning SciPy for Numerical and Scientiﬁc Computing. Packt Publishing, Birmingham (2013)
4. Callister, W.D.: Materials Science and Engineering, 6th edn. Wiley, New York (2003)
5. Cheney, W., Kincaid, D.: Numerical Mathematics and Computing, 7th edn. Brooks/Cole: Cengage Learning,
Boston, MA (2013)

References
225
6. Epperson, J.F.: An Introduction to Numerical Methods and Analysis, revised edition. Wiley, Hoboken (2007)
7. Stein, W.A., et al.: Sage mathematics software (Version 6.3), The sage development team, Sage ofﬁcial webpage:
http://www.sagemath.org (2014)
8. Sage cell server: http://sagecell.sagemath.org/
9. Stein, W.A.: Sage for power users, http://www.wstein.org/books/sagebook/sagebook.pdf (2012)
10. Sullivan, M., Miranda K.: Calculus - Early Transcendentals. W. H. Freeman and Company, New York (2014)

Chapter 6
Spline Interpolation
Given the set of n C 1 data points,
x0 x1 x2 : : : xn
y0 y1 y0 : : : yn
; with x0 < x1 <    < xn;
we have seen how we can obtain a polynomial function of degree (at most) n; p.x/ D anxn C
an1xn1 C    C a1x C a0 that interpolates these points. That is:
p.x0/ D y0; p.x1/ D y1; : : : ; p.xn/ D yn:
This, however, has a major drawback: the polynomial can have a very high degree (up to n) and hence,
the interpolating function can oscillate too much. The oscillation may be quite wild even when all the
y-values of the data set given are essentially constant.
Let’s see this challenge through an example. Consider the following set of data points
f.3; 1/; .2; 1/; .4; 1:01/; .5; 1/; .16; 1/; .40; 1/g :
Notice that all the data points, but one, have a y-value equal to 1. Even that exceptional data point has
a y-value of 1.01, which is fairly close to 1. Therefore, one would normally expect that all y values
(including those that correspond to x D 30; or x D 35/; be somewhere close to 1. Also, the value
1.01 could easily be the result of rounding, or an entry error.
We give next the polynomial of interpolation:
p.x/ ' .1:65343915344  106/x5 C .9:92063492063  105/x4
0:00141038359788x3 C 0:00316468253968x2
C0:014417989418x C 0:968253968254
Electronic supplementary material The online version of this chapter (doi:978-3-319-16739-8_6) contains supple-
mentary material, which is available to authorized users.
© Springer International Publishing Switzerland 2015
G.A. Anastassiou, R. Mezei, Numerical Analysis Using Sage, Springer Undergraduate
Texts in Mathematics and Technology, DOI 10.1007/978-3-319-16739-8_6
227

228
6
Spline Interpolation
and the graph of the polynomial of interpolation p.x/ W
Notice that p.35/ is somewhere around 7, way different than 1.
Ideally, we would love to obtain a curve that more closely follows the datapoints. One that is
smooth, interpolates the datapoints, and does not oscillate that much. Something that looks like:

6
Spline Interpolation
229
Here is another example where polynomial interpolations are not performing very well and an
alternative is very desirable. Consider the following set of data points
f.3; 1/; .2; 2/; .4; 1/; .5; 3/; .16; 1/; .20; 2/g :
The corresponding polynomial interpolation oscillates quite wildly. We would like to control, if
possible, this oscillation.
As we will see below, we can control this oscillation by limiting the degree of the (piecewise-
deﬁned) polynomial.
In this chapter, we will learn about an alternative to interpolating polynomials, namely spline
functions (see also [1, 3, 4]). These are piece-wise deﬁned functions, whose pieces are polynomials
joined together, to form functions with certain smoothness properties (such as continuity). Not only
that we can limit the degree of the polynomial, for each piece, but this technique will also help us
attenuate the effect of small error that may be contained in the table of data points.
Spline functions are extensively used in several areas, including aircraft industry, automotive
industry, computer graphics, geometric modeling, and so on. As we mentioned earlier in this
book, most image and video compression/decompression algorithms use interpolation. Using various
sampling techniques, we can compress images (“lossy” compression), and then, using interpolation
techniques, we can decompress them. Image restoration, digital sounds, GPS coordination, video
games, etc. all use interpolation techniques. Interpolation techniques help us make the transition from
discrete into continuous, and in particular, from digital into analog.
Because of the nice properties of the spline interpolations, they are the most used in practice, and
are preferred more than the polynomial interpolations.

230
6
Spline Interpolation
6.1
Linear Splines
The simplest spline function is the linear spline (also called polygonal line), that is obtained by
connecting every two adjacent nodes by a straight line.
The linear spline function LS.x/ for a given the set of n C 1 data points,
x0 x1 x2 : : : xn
y0 y1 y0 : : : yn
;
is a function that satisﬁes the following requirements:
1. It interpolates the given table. That is: LS.x0/ D y0; LS.x1/ D y1; : : : ; LS.xn/ D yn:
2. Smoothness: LS.x/ is continuous on Œx0; xn:
3. On each of the subintervals Œxi1; xi; i D 1; 2; : : : ; n; LS.x/ is a linear function.
That is
LS.x/ D
8
ˆˆ<
ˆˆ:
a1x C b1; for x 2 Œx0; x1
a2x C b2; for x 2 Œx1; x2
: : :
anx C bn; for x 2 Œxn1; xn
:
Please note that requirement 2. is a direct consequence of requirements 1 and 3. We included it here,
to help make the transition to higher order spline functions a little easier.
To ﬁnd the coefﬁcients a1; b1; we need to ﬁnd the linear function y D a1x C b1 that interpolates
.x0; y0/ and .x1; y1/: Therefore, we compute a1 D y1y0
x1x0 ; and then b1 D y1  a1x1: We do a similar
work for a2; b2; : : : ; an; bn:
For example, let’s consider the following set of data points
f.3; 12/; .2; 5/; .4; 7/; .9; 7/; .16; 1/; .40; 15/g :
Then, its corresponding linear spline looks like

6.1
Linear Splines
231
and can be written as
LS.x/ D
8
ˆˆˆˆˆ<
ˆˆˆˆˆ:
397x
5
; for x 2 Œ3; 2
x C 3; for x 2 Œ2; 4
7; for x 2 Œ4; 9
1218x
7
; for x 2 Œ9; 16
2x35
3
; for x 2 Œ16; 40
:
As one can easily notice, linear splines are continuous functions, but they are usually not smooth.
They are not differentiable. If smoothness is essential, we should use quadratic or even cubic splines
(deﬁned in the next sections).
Before we go forward, it would be worth making a comparison between the linear spline functions
versus polynomial interpolation applied to the same set of data points.
First, we scaled the y-axis of the previous graph, for a more objective comparison
and next we show the graph of the polynomial interpolation for the same set of data points:

232
6
Spline Interpolation
Please note how the spline function follows the points more closely, without having any large
spikes.
6.1.1
Sage Code
We give, below, the Sage code (see [2, 5–7]) we used to graph the above linear spline.
#the array of data points given
points = [(-3,12),(2,5),(4,7),(9,7),(16,-1),(40,15)]
#we compute n from the size of the array
n = len(points)-1
#compute and draw the linear spline
def DrawLinearSpline():
#plot the points
p = list_plot( points, color = ’blue’, size = 70)
#plot each branch, one by one
for i in [1,..,n]:
#first, find the constant in y=ax+b
slope = (points[i][1]-points[i-1][1])/(points[i][0]
-points[i-1][0])
yIntercept = points[i][1]-slope*points[i][0]
#then plot the y=ax+b on the interval [xi-1, xi]
p += plot(slope*x+yIntercept,
(x,points[i-1][0],points[i][0]),
color = ’red’,
title = ’linear spline interpolation’)

6.1
Linear Splines
233
#display the plot
p.show()
#call the function
DrawLinearSpline()
Next, we’ll write a Sage function that can be used to evaluate the Linear Spline function for a given
value of x: For example, we may wish to compute LS.1:34/:
#the array of data points given
points = [(-3,12),(2,5),(4,7),(9,7),(16,-1),(40,15)]
#we compute n from the size of the array
n = len(points)-1
#computes the value of
LS(x)
#it assumes x is inside the interval [x0,xn]!
def ComputeLinearSpline(x):
#search for the subinterval [xi-1,xi] where x belongs
i = 0
while x>points[i][0]:
#if x is too large,
#then go to the next subinterval
i = i+1
slope = (points[i][1]-points[i-1][1])/(points[i][0]
-points[i-1][0])
yIntercept = points[i][1]-slope*points[i][0]
return slope*x+yIntercept
#call the function
ComputeLinearSpline(1.34)
We obtain the following output
5.92400000000000
6.1.2
Sage Library
If we want to draw the linear spline function using Sage Library, we can use code similar to
#the array of data points given
points = [(-3,12),(2,5),(4,7),(9,7),(16,-1),(40,15)]
#draw the linear spline
line(points)
to obtain

234
6
Spline Interpolation
6.2
Quadratic Splines
As we have seen in the previous section, linear splines, although they are continuous, they usually
are not very smooth. In particular, they are not everywhere differentiable inside the domain Œx0; xn:
We can improve this by using quadratic functions in place of linear functions.
The quadratic spline function QS.x/ for a given the set of n C 1 data points,
x0 x1 x2 : : : xn
y0 y1 y0 : : : yn
;
is a function that satisﬁes the following requirements:
1. Interpolation: QS.x0/ D y0; QS.x1/ D y1; : : : ; QS.xn/ D yn:
2. Smoothness: QS.x/ and QS0.x/ are both continuous on Œx0; xn
3. On each of the subintervals Œxi1; xi; i D 1; 2; : : : ; n; QS.x/ is a polynomial of degree at
most two.
That is
QS.x/ D
8
ˆˆ<
ˆˆ:
a1x2 C b1x C c1; for x 2 Œx0; x1
a2x2 C b2x C c2; for x 2 Œx1; x2
: : :
anx2 C bnx C cn; for x 2 Œxn1; xn
:
Please note that there are 3n coefﬁcients to determine, and the requirements 1–3 only give us 2n C
.n  1/ D 3n  1 conditions. Therefore, to uniquely determine a quadratic spline function, one needs
an additional condition. Standard examples of such conditions are: QS0.x0/ D 0; or QS0.xn/ D 0; or
QS00.x0/ D 0; etc.

6.2
Quadratic Splines
235
To solve for QS.x/; we need to ﬁnd a1; b1; c1; : : : ; an; bn; cn: Let’s use the following notation:
QS1.x/ D a1x2 C b1x C c1
QS2.x/ D a2x2 C b2x C c2
: : :
QSn.x/ D anx2 C bnx C cn
QS0.x0/ D z0; QS0.x1/ D z1; : : : ; QS0.xn/ D zn:
Then, from QSi.xi1/ D yi1; QS0
i.xi1/ D zi1; and QS0
i.xi/ D zi;it can be shown that
QSi.x/ D
zi  zi1
2.xi  xi1/.x  xi1/2 C zi1.x  xi1/ C yi1:
(6.1)
Since QSi.xi/ D yi; we obtain
yi D
zi  zi1
2.xi  xi1/.xi  xi1/2 C zi1.xi  xi1/ C yi1;
hence
zi D 2.yi  yi1/
.xi  xi1/  zi1
(6.2)
for all i D 1; 2; : : : ; n: This gives us the following algorithm to compute QS.x/ W
6.2.1
Algorithm
We give, below, the algorithm for ﬁnding a Quadratic Spline for a given set of data points. To uniquely
determine such a spline function, will use the following additional condition: QS0.x0/ D 0: In this
case, the quadratic spline is called natural quadratic spline.
Step 1: using (6.2) we ﬁnd the values for z1; z2; : : : ; zn:
Step 2: using (6.1) we ﬁnd each of QS1.x/; QS2.x/ ; : : : ; QSn.x/ and hence ﬁnd QS.x/:
Example 132. Find the Quadratic Spline function for the following set of data points
f.3; 12/; .2; 5/; .4; 7/; .9; 7/; .16; 1/; .40; 15/g :
Solution. Step 1:
we need to ﬁnd z1; z2; z3; z4; and z5: Using (6.2) we obtain

236
6
Spline Interpolation
z1 D 2.y1  y0/
.x1  x0/  z0 D 14
5
z2 D 2.y2  y1/
.x2  x1/  z1 D 24
5
z3 D 2.y3  y2/
.x3  x2/  z2 D 24
5
z4 D 2.y4  y3/
.x4  x3/  z3 D 88
35
z5 D 2.y5  y4/
.x5  x4/  z4 D 124
105
Step 2:
using (6.1) we obtain
QS.x/ D
8
ˆˆˆˆˆ<
ˆˆˆˆˆ:
 7
25x2  42
25x C 237
25 ; for x 2 Œ3; 2
19
10x2  52
5 x C 91
5 ; for x 2 Œ2; 4
 24
25x2 C 312
25 x  689
25 ; for x 2 Œ4; 9
128
245x2  696
49 x C 22667
245 ; for x 2 Œ9; 16
 97
1260x2 C 224
45 x  3839
63 ; for x 2 Œ16; 40
:
The corresponding graph is
Compare this to the linear spline obtained on page 230.
Note: If we change the additional condition QS0.x0/ D 0 into QS0.x0/ D 10 we obtain the
following graph of the Quadratic Spline Function, which is another Quadratic Spline function that
interpolates the same given data set.

6.2
Quadratic Splines
237
6.2.2
Sage Code
We give, below, the Sage code we used to graph the above quadratic spline. It also contains code to
generate the quadratic spline.
#the array of data points given
points = [(-3,12),(2,5),(4,7),(9,7),(16,-1),(40,15)]
#we compute n from the size of the array
n = len(points)-1
#compute and draw the quadratic spline
def DrawQuadraticSpline():
#plot the points
p = list_plot( points, color = ’blue’, size = 70)
#we use this extra condition z0=0
oldZ=0
#plot each branch, one by one
for i in [1,..,n]:
#first, find the z’s
newZ = 2*(((points[i][1]-points[i-1][1]))/
((points[i][0]-points[i-1][0])))-oldZ
#find
the corresponding branch
QS(x)=((newZ-oldZ)/(2*(points[i][0]-points[i-1][0])))* \
(x-points[i-1][0])^2+oldZ*(x-points[i-1][0])
\
+points[i-1][1]

238
6
Spline Interpolation
#save newZ as oldZ, to make room for next z
oldZ=newZ
#then plot the branch in the interval [xi-1, xi]
p += plot(QS(x),
(x,points[i-1][0],points[i][0]),
color = ’red’,
title = ’quadratic spline interpolation’)
#display the plot
p.show()
#call the function
DrawQuadraticSpline()
The following Sage code will compute and display QS.x/
#the array of data points given
points = [(-3,12),(2,5),(4,7),(9,7),(16,-1),(40,15)]
#we compute n from the size of the array
n = len(points)-1
#compute and draw the quadratic spline
def DisplayQuadraticSpline():
#we use this extra condition z0=0
oldZ=0
#plot each branch, one by one
for i in [1,..,n]:
#first, find the z’s
newZ = 2*(((points[i][1]-points[i-1][1]))
/((points[i][0]-points[i-1][0])))-oldZ
#find
the corresponding branch
QS(x)=((newZ-oldZ)/(2*(points[i][0]-points[i-1][0]))) \
*(x-points[i-1][0])^2+oldZ*(x-points[i-1][0])
\
+points[i-1][1]
print ’QS’+str(i)+’(x)=’,
QS(x).full_simplify()
#save newZ as oldZ, to make room for next z
oldZ=newZ
#call the function
DisplayQuadraticSpline()
and obtain
QS1(x)= -7/25*x^2 - 42/25*x + 237/25
QS2(x)= 19/10*x^2 - 52/5*x + 91/5
QS3(x)= -24/25*x^2 + 312/25*x - 689/25
QS4(x)= 128/245*x^2 - 696/49*x + 22667/245
QS5(x)= -97/1260*x^2 + 224/45*x - 3839/63
Next, we’ll write a Sage function that can be used to evaluate the Quadratic Spline function for a
given value of x: For example, we may wish to compute QS.1:34/:

6.2
Quadratic Splines
239
#the array of data points given
points = [(-3,12),(2,5),(4,7),(9,7),(16,-1),(40,15)]
#we compute n from the size of the array
n = len(points)-1
#computes the value of
QS(x)
#it assumes x is inside the interval [x0,xn]!
def ComputeQuadraticSpline(xx):
#search for the subinterval [xi-1,xi] where x belongs
i = 0
#we use this extra condition z0=0
oldZ=0
#skip the intervals that are below x
#but compute the z’s
while xx>points[i][0]:
i = i+1
#first, find the z’s
newZ = 2*(((points[i][1]-points[i-1][1]))/
((points[i][0]-points[i-1][0])))-oldZ
#save newZ as oldZ, to make room for next z
oldZ=newZ
#compute zi
newZ = 2*(((points[i][1]-points[i-1][1]))/
((points[i][0]-points[i-1][0])))-oldZ
#find
the corresponding branch QSi
QS(x)=((newZ-oldZ)/(2*(points[i][0]-points[i-1][0]))) \
*(x-points[i-1][0])^2+oldZ*(x-points[i-1][0])
\
+points[i-1][1]
#display the plot
return QS(xx)
#call the function
ComputeQuadraticSpline(1.34)
We obtain the following output
5.12196800000000
Putting side by side the linear and the quadratic spline functions we obtain

240
6
Spline Interpolation
6.3
Natural Cubic Splines
In applications, it is common to require that the ﬁrst and second derivatives of the approximating
function to be also continuous. Neither the linear spline nor the quadratic spline have this smoothness
property. For this we would need higher order spline functions. In this section we will present the
Natural Cubic Spline functions.
The cubic spline function CS.x/ for a given the set of n C 1 data points,
x0 x1 x2 : : : xn
y0 y1 y0 : : : yn
;
is a function that satisﬁes the following requirements:
1. Interpolation: CS.x0/ D y0; CS.x1/ D y1; : : : ; CS.xn/ D yn:
2. Smoothness: CS.x/; CS0.x/ and CS00.x/ are all continuous on Œx0; xn
3. On each of the subintervals Œxi1; xi; i D 1; 2; : : : ; n; CS.x/ is a polynomial of degree at most
three.
That is
CS.x/ D
8
ˆˆ<
ˆˆ:
a1x3 C b1x2 C c1x C d1; for x 2 Œx0; x1
a2x3 C b2x2 C c2x C d2; for x 2 Œx1; x2
: : :
anx3 C bnx2 C cnx C dn; for x 2 Œxn1; xn
:
In order to uniquely determine a Cubic Spine function, two extra conditions need to be added. If we
impose the extra conditions

6.3
Natural Cubic Splines
241
CS00.x0/ D 0; and CS00.xn/ D 0;
(6.3)
then we obtain what is called Natural Cubic Splines.
If the y values are coming from a function f; y D f .x/; and instead of (6.3), we impose the extra
conditions
CS0.x0/ D f 0.x0/; CS0.xn/ D f 0.xn/;
(6.4)
then we obtain what is called Complete Cubic Splines.
In this section we will only focus on Natural Cubic Spline Functions. Before we present the general
algorithm to ﬁnd the natural cubic spline for a given set of data points, let’s start with a simple example.
Example 133. Find the natural cubic spline function for the following set of data points
f.1; 2/; .0; 5/; .2; 1/g:
Solution. To solve for CS.x/; we need to ﬁnd a1; b1; c1; d1; a2; b2; c2; d2; such that the function
CS.x/ D
 CS1.x/ D a1x3 C b1x2 C c1x C d1; for x 2 Œ1; 0
CS2.x/ D a2x3 C b2x2 C c2x C d2; for x 2 Œ0; 1
;
satisfy the Natural Cubic Spline properties. That is:
8
ˆˆˆˆˆˆˆˆˆˆˆ<
ˆˆˆˆˆˆˆˆˆˆˆ:
CS1.1/ D 2
CS1.0/ D 5
CS2.0/ D 5
CS2.2/ D 1
CS0
1.0/ D CS0
2.0/
CS00
1.0/ D CS00
2.0/
CS00
1.1/ D 0
CS00
2.2/ D 0
therefore
8
ˆˆˆˆˆˆˆˆˆˆˆ<
ˆˆˆˆˆˆˆˆˆˆˆ:
a1 C b1  c1 C d1 D 2
d1 D 5
d2 D 5
8a2 C 4b2 C 2c2 C d2 D 1
c1 D c2
2b1 D 2b2
6a1 C 2b1 D 0
12a2 C 2b2 D 0
;
obtaining
CS.x/ D
 x3  3x2 C x C 5; for x 2 Œ1; 0
0:5x3  3x2 C x C 5; for x 2 Œ0; 1 :

242
6
Spline Interpolation
We describe, below, an algorithm that can be used to solve for the Natural Cubic Spline Function.
For this, let’s use the following notation:
CS1.x/ D a1x3 C b1x2 C c1x C d1;
CS2.x/ D a2x3 C b2x2 C c2x C d2;
: : :
CSn.x/ D anx3 C bnx2 C cnx C dn;
CS0.x0/ D z0; CS0.x1/ D z1; : : : ; CS0.xn/ D zn;
CS00.x0/ D t0; CS00.x1/ D t1; : : : ; CS00.xn/ D tn:
Since CSi.x/ is a cubic polynomial on each subinterval Œxi1; xi; i D 1; 2; : : : ; n; we have that
CS00
i .x/ is a linear function on each of these subintervals. Using the continuity of CS00.x/; on Œx0; xn;
and the interpolation conditions, we have that CS00
i .xi1/ D ti1 and CS00
i .xi/ D ti; hence using linear
interpolation (see for example (3.2), on page 118) we obtain
CS00
i .x/ D
	 x  xi
xi1  xi

 ti1 C
	 x  xi1
xi  xi1

 ti; i D 1; 2; : : : ; n:
(6.5)
Then, by integrating twice, we get
CSi.x/ D .x  xi/3
ti1
6 .xi1  xi/ C .x  xi1/3
ti
6 .xi  xi1/ C Cix C Di;
(6.6)
for i D 1; 2; : : : ; n; with Ci; Di constants that have to be determined.
Using the interpolation conditions and continuity of CS.x/; we have that CSi.xi1/ D yi1 and
CSi.xi/ D yi i D 1; 2; : : : ; n; hence solving for Ci and Di from these conditions we obtain
Ci D .yi  yi1/
.xi  xi1/  .xi  xi1/ .ti  ti1/
6
Di D yi1 C .xi  xi1/
6
.tixi1  xiti1/  .yi  yi1/
.xi  xi1/xi1
therefore, after simplifying we get
CSi.x/ D ti1 .xi  x/3 C ti .x  xi1/3
6 .xi  xi1/
(6.7)
C.x  xi1/ yi C yi1 .xi  x/
.xi  xi1/
.xi  xi1/
6
Œti .x  xi1/ C ti1 .xi  x/
for i D 1; 2; : : : ; n:

6.3
Natural Cubic Splines
243
The only missing piece of the puzzle is to ﬁnd the values of ti; i D 1; 2; : : : ; n  1: To ﬁnd these
values we will use the continuity of CS0.x/: Hence from
CS0
i.xi/ D CS0
iC1.xi/
for i D 1; 2; : : : ; n  1; and t0 D tn D 0; we obtain the following tri-diagonal system
8
ˆˆˆˆˆˆˆˆ<
ˆˆˆˆˆˆˆˆ:
t0 D 0
ti1 .xi  xi1/ C 2ti .xiC1  xi1/ C tiC1 .xiC1  xi/
D 6

yiC1yi
xiC1xi  yiyi1
xixi1

tn D 0
;
(6.8)
for i D 1; 2; : : : ; n  1: Then solving it for t0; t1; : : : ; tn, and using these in (6.7), we ﬁnd the Natural
Cubic Spline function for our given set of data.
This gives us the following computational algorithm for CS.x/ W
6.3.1
Algorithm
We give, below, the algorithm for ﬁnding a Natural Cubic Spline for a given set of data points. First
we need to solve the system (6.8), to ﬁnd t1; t2; : : : ; tn1: Then, substituting them, and t0 D tn D 0;
into (6.7) we solve the problem.
Step 1:
solve the system (6.8).
Step 2:
using the answer to Step 1, we will ﬁnd each of CS1.x/; CS2.x/; : : : ; CSn.x/ and hence ﬁnd
CS.x/:
Example 134. Find the Natural Cubic Spline function for the following set of data points
f.3; 12/; .2; 5/; .4; 7/; .9; 7/; .16; 1/; .40; 15/g :
Solution. Step 1:
we need to ﬁnd t1; t2; t3; and t4: Using (6.8) we obtain
8
ˆˆˆˆˆˆˆˆˆˆ<
ˆˆˆˆˆˆˆˆˆˆ:
t0 D 0
t0 .x1  x0/ C 2t1 .x2  x0/ C t2 .x2  x1/ D 6

y2y1
x2x1  y1y0
x1x0

t1 .x2  x1/ C 2t2 .x3  x1/ C t3 .x3  x2/ D 6

y3y2
x3x2  y2y1
x2x1

t2 .x3  x2/ C 2t3 .x4  x2/ C t4 .x4  x3/ D 6

y4y3
x4x3  y3y2
x3x2

t3 .x4  x3/ C 2t4 .x5  x3/ C t5 .x5  x4/ D 6

y5y4
x5x4  y4y3
x4x3

t5 D 0
;
(6.9)

244
6
Spline Interpolation
therefore
8
ˆˆˆˆˆˆˆ<
ˆˆˆˆˆˆˆ:
t0 D 0
14t1 C 2t2 D 72
5
2t1 C 14t2 C 5t3 D 6
5t2 C 24t3 C 7t4 D 48
7
7t3 C 62t4 D 76
7
t5 D 0
;
(6.10)
hence
8
ˆˆˆˆˆˆˆ<
ˆˆˆˆˆˆˆ:
t0 D 0
t1 D 2450341
2227645
t2 D  159049
318235
t3 D  107190
445529
t4 D
90121
445529
t5 D 0
:
(6.11)
If you want, you can use Sage to compute the previous system. You can use, for example, the
following code
var(’t1,t2,t3,t4’)
solve( (14*t1+2*t2== 72/5,
2*t1+14*t2+5*t3==-6,
5*t2+24*t3+7*t4==-48/7,
7*t3+62*t4==76/7),
t1, t2, t3, t4)
to obtain
[[t1 == (2450341/2227645), t2 == (-159049/318235),
t3 == (-107190/445529), t4 == (90121/445529)]]
Then
Step 2:
using (6.7) we obtain
CS.x/ D
8
ˆˆˆˆˆˆˆˆˆ<
ˆˆˆˆˆˆˆˆˆ:
2450341
66829350x3 C 7351023
22276450x2  44330204
33414675x C 67275427
11138225; for x 2 Œ3; 2
 890921
6682935x3 C 1202805
891058 x2  22497502
6682935 x C 16484299
2227645 ; for x 2 Œ2; 4
577393
66829350x3  7876287
22276450x2 C 115190962
33414675 x  18768937
11138225; for x 2 Œ4; 9
197311
18712218x3  2526129
6237406x2 C 36583846
9356109 x  9585679
3118703; for x 2 Œ9; 16

90121
64156176x3 C 450605
2673174x2  2346530
445529 x C 183929215
4009761 ; for x 2 Œ16; 40
:
One can also use Sage to make these computations:
#the array of data points given
points = [(-3,12),(2,5),(4,7),(9,7),(16,-1),(40,15)]
#we compute n from the size of the array
n = len(points)-1

6.3
Natural Cubic Splines
245
t = [0, 2450341/2227645, -159049/318235,
-107190/445529, 90121/445529, 0]
for i in [1,2,..,n]:
#compute each branch
CS(x) = ((t[i-1]*(points[i][0]-x)^3+t[i]*(x-points[i-1][0])^3) \
/(6*(points[i][0]-points[i-1][0])))
\
+(((x-points[i-1][0])*points[i][1]+points[i-1][1]
\
*(points[i][0]-x))
\
/((points[i][0]-points[i-1][0])))
\
-(((points[i][0]-points[i-1][0]))/6)*(t[i]*(x-points[i-1][0])\
+t[i-1]*(points[i][0]-x))
print "CS"+str(i)+"(x)=", CS(x).full_simplify()
and obtain:
CS1(x)= 2450341/66829350*x^3 + 7351023/22276450*x^2
- 44330204/33414675*x + 67275427/11138225
CS2(x)= -890921/6682935*x^3 + 1202805/891058*x^2
- 22497502/6682935*x + 16484299/2227645
CS3(x)= 577393/66829350*x^3 - 7876287/22276450*x^2
+ 115190962/33414675*x - 18768937/11138225
CS4(x)= 197311/18712218*x^3 - 2526129/6237406*x^2
+ 36583846/9356109*x - 9585679/3118703
CS5(x)= -90121/64156176*x^3 + 450605/2673174*x^2
- 2346530/445529*x + 183929215/4009761
The corresponding graph for the Natural Cubic Spline is given by

246
6
Spline Interpolation
Compare this to the linear and quadratic splines obtained earlier:
And if we include the polynomial interpolation, we obtain

6.3
Natural Cubic Splines
247
6.3.2
Sage Code
We will see next how to implement a Sage function that computes the Natural Cubic Spline for a given
data set.
It can be shown (see [3, pp. 269–270]) that the system (6.8) can be solved in two steps as follows:
Step 1:
compute the following intermediate values
ui D
(
2.x2  x0/; for i D 1
2 .xiC1  xi1/  .xi xi1/2
ui1
; for i D 2; 3; : : : ; n  1
(6.12)
vi D
8
<
:
6

y2y1
x2x1  y1y0
x2x0

; for i D 1
6

yiC1yi
xiC1xi  yiyi1
xixi1

 .xi xi1/vi1
ui1
; for i D 2; 3; : : : ; n  1
:
Step 2:
compute the values of ti
t0 D 0; tn D 0
(6.13)
ti D vi  .xiC1  xi/ tiC1
ui
; for i D n  1; n  2; : : : ; 1:
Once you obtain the values of t0; t1; t2; : : : ; tn you can substitute them in (6.7) to get CS.x/:
We give, below, the Sage implementation that uses (6.12), (6.13) and (6.7) to draw CS.x/: We will
apply this to the data set given in the previous example.
#the array of data points given
points = [(-3,12),(2,5),(4,7),(9,7),(16,-1),(40,15)]
#we compute n from the size of the array
n = len(points)-1
def DrawNaturalCubicSpline():
#plot the points
p = list_plot( points, color = ’blue’, size = 70)
#compute the value of t_i’s
t = [0
for i in [0,1,..,n]]
u = [0
for i in [0,1,..,n]]
v = [0
for i in [0,1,..,n]]
u[1] = 2*((points[2][0]-points[0][0]))
v[1] = 6*(((points[2][1]-points[1][1])
\
/((points[2][0]-points[1][0])))
\
-((points[1][1]-points[0][1])
\
/((points[1][0]-points[0][0]))))
for i in [2,3,..,n-1]:
u[i]=2*(points[i+1][0]-points[i-1][0]) \
-((points[i][0]-points[i-1][0])^2)/(u[i-1])
v[i]=6*((points[i+1][1]-points[i][1])
\
/(points[i+1][0]-points[i][0])
\

248
6
Spline Interpolation
-(points[i][1]-points[i-1][1])
\
/(points[i][0]-points[i-1][0])) \
-((points[i][0]-points[i-1][0]))*v[i-1]/u[i-1]
for i in [n-1,n-2,..,1]:
t[i]=( v[i] - (points[i+1][0]-points[i][0])*t[i+1] )/u[i]
for i in [1,2,..,n]:
#compute each branch
CS(x) = ((t[i-1]*(points[i][0]-x)^3
\
+t[i]*(x-points[i-1][0])^3)/
\
(6*(points[i][0]-points[i-1][0]))) \
+(((x-points[i-1][0])*points[i][1]
\
+points[i-1][1]*(points[i][0]-x))
\
/((points[i][0]-points[i-1][0])))
\
-(((points[i][0]-points[i-1][0]))/6) \
*(t[i]*(x-points[i-1][0])+t[i-1]*(points[i][0]-x))
p += plot(CS(x), (x,points[i-1][0],points[i][0]), color
= ’red’)
#display the plot
p.show()
#call the function
DrawNaturalCubicSpline()
We obtained
If you want to calculate and display the pieces of the Natural Cubic Spline associated with the set
of data, then you can use Sage code similar to:

6.3
Natural Cubic Splines
249
#the array of data points given
points = [(-3,12),(2,5),(4,7),(9,7),(16,-1),(40,15)]
#we compute n from the size of the array
n = len(points)-1
def DisplayNaturalCubicSpline():
#compute the value of t_i’s
t = [0
for i in [0,1,..,n]]
u = [0
for i in [0,1,..,n]]
v = [0
for i in [0,1,..,n]]
u[1] = 2*((points[2][0]-points[0][0]))
v[1] = 6*(((points[2][1]-points[1][1])
\
/((points[2][0]-points[1][0])))
\
- ((points[1][1]-points[0][1])
\
/((points[1][0]-points[0][0]))))
for i in [2,3,..,n-1]:
u[i]=2*(points[i+1][0]-points[i-1][0])
\
-((points[i][0]-points[i-1][0])^2)/(u[i-1])
v[i]=6*((points[i+1][1]-points[i][1])
\
/(points[i+1][0]-points[i][0])
\
-(points[i][1]-points[i-1][1])
\
/(points[i][0]-points[i-1][0]))
\
-((points[i][0]-points[i-1][0]))*v[i-1]/u[i-1]
for i in [n-1,n-2,..,1]:
t[i]=( v[i] - (points[i+1][0]-points[i][0])*t[i+1] )/u[i]
for i in [1,2,..,n]:
#compute each branch
CS(x) = ((t[i-1]*(points[i][0]-x)^3+t[i]*(x-points[i-1]
[0])^3)
\
/(6*(points[i][0]-points[i-1][0])))
\
+(((x-points[i-1][0])*points[i][1]
\
+points[i-1][1]*(points[i][0]-x))
\
/((points[i][0]-points[i-1][0])))
\
-(((points[i][0]-points[i-1][0]))/6)
\
*(t[i]*(x-points[i-1][0])+t[i-1]*(points[i][0]-x))
print "CS"+str(i)+"(x)=" , CS(x).full_simplify()
#call the function
DisplayNaturalCubicSpline()
to get again, the same answer as the one obtained in the example we solved earlier:
CS1(x)= 2450341/66829350*x^3 + 7351023/22276450*x^2
- 44330204/33414675*x + 67275427/11138225
CS2(x)= -890921/6682935*x^3 + 1202805/891058*x^2
- 22497502/6682935*x + 16484299/2227645
CS3(x)= 577393/66829350*x^3 - 7876287/22276450*x^2
+ 115190962/33414675*x - 18768937/11138225
CS4(x)= 197311/18712218*x^3 - 2526129/6237406*x^2
+ 36583846/9356109*x - 9585679/3118703

250
6
Spline Interpolation
CS5(x)= -90121/64156176*x^3 + 450605/2673174*x^2
- 2346530/445529*x + 183929215/4009761
6.3.3
Sage Library
One can also use the following Sage Library function to compute the Natural Cubic Spline
spline(points)
If you only wish to evaluate the Natural Cubic Spline function at x D 1:34; for the data set
f.3; 12/; .2; 5/; .4; 7/; .9; 7/; .16; 1/; .40; 15/g ;
then you would use the following code
#the array of data points given
points = [(-3,12),(2,5),(4,7),(9,7),(16,-1),(40,15)]
#obtain the natural cubic
spline function
cs = spline(points)
#compute and output the value at x=1.34
print cs(1.34)
to obtain
4.9430659023
To plot the graph of the Natural Cubic Spline given in the previous example, we could use the
following code
#the array of data points given
points = [(-3,12),(2,5),(4,7),(9,7),(16,-1),(40,15)]
#we compute n from the size of the array
n = len(points)-1
#obtain the natural cubic
spline function
s = spline(points)
#plot the points
p = list_plot( points, color = ’blue’, size = 70)
#plot the spline
p += plot(s, (x,points[0][0],points[n][0]),
color = ’red’,
title = ’natural cubic spline’)
p.show()
Example 135. Graph the natural cubic spline function that interpolates the function f .x/ D sin x at
11 evenly spaced points in Œ0; 4 : Also include the graph of the function f .x/:
Solution. Using the code
#the array of data points given
f(x) = sin(x)

6.3
Natural Cubic Splines
251
points = [(0+i*4*pi/10,f(0+i*4*pi/10)) for i in [0,1,2,..,10]]
#we compute n from the size of the array
n = len(points)-1
#obtain the natural cubic
spline function
s = spline(points)
#plot the points
p = list_plot( points, color = ’blue’, size = 70)
#plot the spline
p += plot(s, (x,points[0][0],points[n][0]),
color = ’red’, thickness = 2,
legend_label = ’natural cubic spline’)
#plot the function f
p += plot(f(x), (x,points[0][0],points[n][0]),
color = ’green’,
legend_label = ’sin(x)’)
p.show(ticks=4*pi/10, tick_formatter=pi)
we obtain
1.0
0.5
–0.5
–1.0
2
5 π
4
5 π
6
5 π
8
5 π
π
12
5 π
14
5 π
16
5 π
18
5 π
2
π
4
natural cubic spline
sin(x)

252
6
Spline Interpolation
Example 136. Graph the natural cubic spline function and the polynomial function that interpolate the
function f .x/ D jxj at 10 evenly spaced points in Œ1:6; 2 : Also include the graph of the function
f .x/:
Solution. Using the code
#the array of data points given
f(x) = abs(x)
points = [( -2+i*4/10,f(-2+i*4/10)) for i in [1,2,..,10]]
#we compute n from the size of the array
n = len(points)-1
#obtain the natural cubic
spline function
s = spline(points)
#plot the points
p = list_plot( points, color = ’blue’, size = 70)
#plotting the cubic spline
p += plot(s, (x,points[0][0],points[n][0]),
color = ’red’, thickness = 2,
legend_label = ’natural cubic spline’)
#plotting the function f
p += plot(f(x), (x,points[0][0],points[n][0]),
color = ’green’,
legend_label = ’f(x)’)
#plotting the polynomial interpolation
R = PolynomialRing(QQ, ’xx’)
pol(xx) = R.lagrange_polynomial(points)
p +=plot(pol(xx),
(xx,points[0][0], points[n][0]),
color = ’yellow’, thickness = 3,
legend_label =
"polynomial interpolation")
p.show()
we obtain

6.4
An Application to Computer Science
253
6.4
An Application to Computer Science
Font creation, Animation Paths, Shape Modeling, Tessellation, Spline Images, and Vector Graphics
are just a few examples of the wide range of applications of spline functions in Computer Science.
In particular, PostScript fonts use cubic splines, and TrueType fonts use quadratic. Storing each
character using splines allows us to easily scale, stretch, or even rotate their display, while maintaining
their smooth appearance.
The interested reader is invited to obtain more details by visiting the following websites: http://
fontforge.org and http://apple.com.
Let us develop our own code that will make use of spline functions to display characters using
our own font speciﬁcation. For the sake of simplicity our system will contain very limited and simple
characters, and hence some details that would normally be used in a real font system are omitted here.
In order to specify our font, we will only need to specify the set of points that described the character
we want to be displayed. Then, we will let Sage use spline functions to do the rest, connect those
points to obtain the intended character.
As an example, let’s say we want to display a letter such as a calligraphic “A”. How can we do
that? First, we obtain a set of points (using the two dimensions) that describes the letter with the
desired level of ﬁdelity. For our example, we could use:
t 0
1
2
3
4
5
6
x 0:2 1:0 2:0 3:0 4:0 5:0 6:0
y 0:5 0:0 2:7 5:5 2:7 0:0 0:5
;
and for the middle part,
t 0
1
2
3
x 1:5 2:5 3:5 4:5
y 2:5 2:7 2:3 2:5
:

254
6
Spline Interpolation
Note: for two-dimensional curves, we can use two cubic spline functions together to form a
parametric representation of such a curve that can turn and twist. In our example, we will use t as
the parametric variable. For this, we could, for example, use the following Sage code
points1 = [(0,0.2),(1,1.0),(2,2.0),(3,3.0),(4,4.0),
(5, 5.0), (6, 6.0)]
points2 = [(0,0.5),(1,0.0),(2,2.7),(3,5.5),(4,2.7),
(5, 0.0), (6, 0.5)]
n = len(points1)-1
points = [(points1[i][1],points2[i][1]) for i in range(len(points1))]
p = list_plot(points, color = ’red’, size = 70)
pol1 = spline(points1)
pol2 = spline(points2)
p+=parametric_plot((pol1,pol2),(x,0.0,points1[len(points1)-1][0]))
points1 = [(0,1.5),(1,2.5),(2,3.5),(3,4.5)]
points2 = [(0,2.5),(1,2.7),(2,2.3),(3,2.5)]
n = len(points1)-1
points = [(points1[i][1],points2[i][1]) for i in range(len(points1))]
p += list_plot(points, color = ’red’, size = 70)
pol1 = spline(points1)
pol2 = spline(points2)
p+=parametric_plot((pol1,pol2) , (x, 0.0, points1[len(points1)-1][0]))
p.show(xmax=8,ymax=6)
and obtain the following image

6.4
An Application to Computer Science
255
To see the power of splines, we can center the coordinates given above so that the origin is
somewhere in the center of the character. Then, we can multiply the x coordinates (for a horizontal
stretch) or the y-coordinates (for a vertical stretch), or both (for a change in size). Splines are used
in some fonts (such as TrueType fonts) rather than image copy of each characters in order to avoid
pixilation.
Using the following Sage code:
sX = 1 #used for horizontal stretch
sY = 1 #used for
vertical
stretch
points1 = [(0,-2.8*sX),(1,-2.0*sX),(2,-1.0*sX),(3,0.0*sX),
(4,1.0*sX), (5, 2.0*sX), (6, 3.0*sX)]
points2 = [(0,-2.5*sY),(1,-3.0*sY),(2,-0.3*sY),(3,2.5*sY),
(4,-0.3*sY),(5,-3.0*sY), (6,-2.5*sY)]
n = len(points1)-1
points = [(points1[i][1],points2[i][1]) for i in range(len(points1))]
p = list_plot(points, color = ’red’, size = 70)
pol1 = spline(points1)
pol2 = spline(points2)
p+=parametric_plot((pol1,pol2),(x,0.0,points1[len(points1)-1][0]))
points1 = [(0,-1.5*sX),(1,-0.5*sX),(2,0.5*sX),(3,1.5*sX)]
points2 = [(0,-0.5*sY),(1,-0.3*sY),(2,-0.7*sY),(3,-0.5*sY)]
n = len(points1)-1
points = [(points1[i][1],points2[i][1]) for i in range(len(points1))]
p += list_plot(points, color = ’red’, size = 70)
pol1 = spline(points1)
pol2 = spline(points2)
p+=parametric_plot((pol1,pol2) , (x, 0.0, points1[len(points1)-1][0]))
p.save(’s.png’,xmax=8,ymax=6)
one obtains:

256
6
Spline Interpolation
Changing the values of sX to 0.75 and sY to 0.75 we obtain:
Changing the values of sX to 0.5 and sY to 0.5 we obtain:

6.5
Exercises
257
Changing the values of sX to 0.25 and sY to 0.75 we obtain:
We challenge you to adapt the previous example using Sage interacts.
6.5
Exercises
1. Find the linear spline function that interpolates the following set of data points, then graph it
f.3; 1/; .2; 5/; .4; 7/; .9; 7/; .16; 1/; .20; 5/g :
2. Find the linear spline function that interpolates the following set of data points, then graph it
f.3; 1/; .2; 1/; .4; 1:01/; .5; 1/; .16; 1/; .40; 1/g :

258
6
Spline Interpolation
3. Find the linear spline function that interpolates the following set of data points, then graph it
f.0; 7/; .1; 10/; .3; 2/; .4; 5/; .8; 0/g :
4. Find the quadratic spline function that interpolates the following set of data points, then graph it
f.3; 1/; .2; 5/; .4; 7/; .9; 7/; .16; 1/; .20; 5/g :
5. Find the quadratic spline function that interpolates the following set of data points, then graph it
f.3; 1/; .2; 1/; .4; 1:01/; .5; 1/; .16; 1/; .40; 1/g :
6. Find the quadratic spline function that interpolates the following set of data points, then graph it
f.0; 7/; .1; 10/; .3; 2/; .4; 5/; .8; 0/g :
7. Find the natural cubic spline function that interpolates the following set of data points, then
graph it
f.3; 1/; .2; 5/; .4; 7/; .9; 7/g :
8. Find the natural cubic spline function that interpolates the following set of data points, then
graph it
f.3; 1/; .4; 1:01/; .5; 1/g :
9. Find the natural cubic spline function that interpolates the following set of data points, then
graph it
f.3; 2/; .4; 5/; .8; 0/g :
10. Find the cubic spline function that satisﬁes the following set of conditions, then graph it: CS.0/ D
0; CS.1/ D 1; CS.2/ D 2; CS0.0/ D 0; CS00.2/ D 3:
11. For what values of C; the following function

2x3  6x2 C 8x C 6; for x 2 Œ1; 2
2x3 C 18x2  40x C C; for x 2 Œ2; 3
is a cubic spline? Can it be a natural cubic spline?
12. Find the values of C; and D; such that

2x3 C 6x2 C x C C; for x 2 Œ1; 2
2x3 C 18x2 C Dx C 3; for x 2 Œ2; 3
is a cubic spline function. Can it also be a natural cubic spline?
13. Do there exist A; B; C; and D; such that
 Ax3 C 6x2 C Bx C 7; for x 2 Œ1; 2
Cx3 C Dx2 C x C 3; for x 2 Œ2; 3
is a natural cubic spline function?

6.6
Computer Exercises
259
14. Do there exist A; B; C; and D; such that
 6x2 C Ax C B; for x 2 Œ1; 2
Cx3 C Dx2 C x; for x 2 Œ2; 3
is a natural cubic spline function?
15. Find the natural cubic spline that interpolates the function f .x/
D
x4; using the
nodes x D 0; 1; 2:
16. Find the natural cubic spline that interpolates the function f .x/
D
sin x; using the
nodes x D 0; 
6 ; 
2 :
17. Find the natural cubic spline that interpolates the function f .x/
D
sin x; using the
nodes x D 0; 
6 ; 
2 ; :
6.6
Computer Exercises
1. Use Sage to graph the linear spline function that interpolates the following set of data points. Then
compare this graph with the one obtained from the polynomial interpolation for the same set of
points.
f.2; 2/; .1; 1/; .0; 0:5/; .1; 1/; .2; 2/; .3; 3:5/g :
2. Use Sage to graph the linear spline function that interpolates the following set of data points. Then
compare this graph with the one obtained from the polynomial interpolation for the same set of
points.
f.1; 1/; .2; 0:5/; .3; 0:333/; .4; 0:25/; .5; 0:20/g :
3. Use Sage to graph the linear spline function that interpolates the following set of data points. Then
compare this graph with the one obtained from the polynomial interpolation for the same set of
points.
f.0; 2:5/; .1; 0:5/; .2; 0:5/; .3; 2/; .4; 2/; .5; 1:5/; .6; 0/g :
4. Use Sage to graph the linear spline function that interpolates the following set of data points. Then
compare this graph with the one obtained from the polynomial interpolation for the same set of
points.
f.0; 7/; .1; 10/; .3; 2/; .4; 5/; .8; 0/g :
5. Use Sage to graph the quadratic spline function that interpolates the following set of data points.
Then compare this graph with the one obtained from the polynomial interpolation for the same
set of points.
f.2; 2/; .1; 1/; .0; 0:5/; .1; 1/; .2; 2/; .3; 3:5/g :

260
6
Spline Interpolation
6. Use Sage to graph the quadratic spline function that interpolates the following set of data points.
Then compare this graph with the one obtained from the polynomial interpolation for the same
set of points.
f.1; 1/; .2; 0:5/; .3; 0:333/; .4; 0:25/; .5; 0:20/g :
7. Use Sage to graph the quadratic spline function that interpolates the following set of data points.
Then compare this graph with the one obtained from the polynomial interpolation for the same
set of points.
f.0; 2:5/; .1; 0:5/; .2; 0:5/; .3; 2/; .4; 2/; .5; 1:5/; .6; 0/g :
8. Use Sage to graph the quadratic spline function that interpolates the following set of data points.
Then compare this graph with the one obtained from the polynomial interpolation for the same
set of points.
f.0; 7/; .1; 10/; .3; 2/; .4; 5/; .8; 0/g :
9. Use Sage to graph the natural cubic spline function that interpolates the following set of data
points. Then compare this graph with the one obtained from the polynomial interpolation for the
same set of points.
f.2; 2/; .1; 1/; .0; 0:5/; .1; 1/; .2; 2/; .3; 3:5/g :
10. Use Sage to graph the natural cubic spline function that interpolates the following set of data
points. Then compare this graph with the one obtained from the polynomial interpolation for the
same set of points.
f.1; 1/; .2; 0:5/; .3; 0:333/; .4; 0:25/; .5; 0:20/g :
11. Use Sage to graph the natural cubic spline function that interpolates the following set of data
points. Then compare this graph with the one obtained from the polynomial interpolation for the
same set of points.
f.0; 2:5/; .1; 0:5/; .2; 0:5/; .3; 2/; .4; 2/; .5; 1:5/; .6; 0/g :
12. Use Sage to graph the natural cubic spline function that interpolates the following set of data
points. Then compare this graph with the one obtained from the polynomial interpolation for the
same set of points.
f.0; 7/; .1; 10/; .3; 2/; .4; 5/; .8; 0/g :
13. Use Sage to construct and graph the natural cubic spline function that interpolates the function
f .x/ D 1
x at 10 evenly spaced points in Œ0:5; 3: Then compare this graph with the one obtained
from interpolating the same set of points using polynomial interpolation.
14. Use Sage to construct and graph the natural cubic spline function that interpolates the function
f .x/ D sin x at 10 evenly spaced points in

 
2 ; 
2

: Then compare this graph with the one
obtained from interpolating the same set of points using polynomial interpolation.

References
261
References
1. Atkinson, K., Han, W.: Elementary Numerical Analysis, 3rd edn. Wiley, New York (2003)
2. Blanco-Silva, F.J.: Learning SciPy for Numerical and Scientiﬁc Computing. Packt Publishing, Birmingham/Mumbai
(2013)
3. Cheney, W., Kincaid, D.: Numerical Mathematics and Computing, 7th edn. Brooks/Cole: Cengage Learning, Boston
(2013)
4. Epperson, J.F.: An Introduction to Numerical Methods and Analysis, revised edition. Wiley, New York (2007)
5. Sage Cell Server: http://sagecell.sagemath.org/
6. Stein, W.A., et al.: Sage mathematics software (Version 6.3). The Sage development team. Sage ofﬁcial webpage:
http://www.sagemath.org (2014). Retrieved 2014
7. Stein, W.A.: Sage for power users. http://www.wstein.org/books/sagebook/sagebook.pdf (2012)

Chapter 7
Numerical Methods for Differential Equations
7.1
Introduction
An equation that involves an unknown function, y and one or more of its derivatives is called a
differential equation. In this chapter, we will consider the case when y D y.x/ is a function of x:
In this case, the differential equation is called an ordinary differential equation (or ODE). The case
when the function y is a function of two or more independent variable is called a partially differential
equation (or PDE) (see also [3, 4, 10]).
In this chapter, we will mainly consider ordinary differential equations. Examples of these are
y0 D 2x C 3 sin.x/ C ex
y0 D 2y C 3 sin.x/ C ex
y0 D
2x
1 C e
p
x2sin x C 3 sin
ˇˇsin x C cosh x5ˇˇ
cos.y0/  ejyj D ln.1 C x2/ C 7:
Some differential equations can be solved easily. For example
y0 D 2x C 3 sin.x/ C ex
can be solved by integrating both sides. In this case we would obtain
y D x2  3 cos.x/ C ex C C;
where C can be any constant. Hence this equation has an inﬁnite number of solutions. If we specify
an extra condition like
y.0/ D 7
Electronic supplementary material The online version of this chapter (doi:978-3-319-16739-8_7) contains supple-
mentary material, which is available to authorized users.
© Springer International Publishing Switzerland 2015
G.A. Anastassiou, R. Mezei, Numerical Analysis Using Sage, Springer Undergraduate
Texts in Mathematics and Technology, DOI 10.1007/978-3-319-16739-8_7
263

264
7
Numerical Methods for Differential Equations
then we obtain that C D 9 hence the desired solution is
y D x2  3 cos.x/ C ex C 9:
One can also solve this equation using the following Sage code (see [2, 6–8])
x = var(’x’)
y = function(’y’, x)
de =
diff(y,x) == 2*x+3*sin(x)+e^(x)
desolve(de, y)
and obtain the same answer:
x^2 + _C - 3*cos(x) + e^x
If we want to ﬁnd the particular solution that satisﬁes the extra condition y.0/ D 7; then Sage
code like
x = var(’x’)
y = function(’y’, x)
de =
diff(y,x) == 2*x+3*sin(x)+e^(x)
desolve(de, y, ics=[0,7])
would give us the solution:
x^2 - 3*cos(x) + e^x + 9
Other types of equations may be solved, using some tricks or recipes that are explained in any
standard Differential Equations Course. For example
y0 D 2y C 3 sin.x/ C ex
can be solved by multiplying both sides by e2x

ye2x0 D 3 sin.x/e2x C ex
and then integrating both sides, hence obtaining
y D 3
5 .cos.x/ C 2 sin.x//  ex C Ce2x:
Again, we could use the following Sage code
x = var(’x’)
y = function(’y’, x)
de =
diff(y,x) == 2*y+3*sin(x)+e^(x)
desolve(de, y).full_simplify()
to obtain the solution:
_C*e^(2*x) - 3/5*cos(x) - e^x - 6/5*sin(x)
There are differential equations that can be solved, in theory, but in practice they may be too
complicated and hence not feasible to be used in computations. Also, some differential equations
simply cannot be solved, or no solutions are known at this time. Try, for example, solving the following
equations
y0 D
2x
1 C e
p
x2sin x C 3 sin
ˇˇsin x C cosh x5ˇˇ
y0 D 2 sin.y/  cos.x/ C y:

7.1
Introduction
265
In this chapter we will focus on initial-value problems for a ﬁrst-order differential equation, of
the form
 y0 D f .x; y/; for x 2 Œa; b
y.a/ - given
:
(7.1)
By y0 we mean dy
dx :
For example,
 y0 D 2y C 3 sin.x/ C ex
y.0/ D 7
:
can be solved by ﬁnding the value of C; such that y D  3
5 .cos.x/ C 2 sin.x//  ex C Ce2x satisﬁes
the initial-value condition y.0/ D 7: Therefore
7 D 3
5 .cos.0/ C 2 sin.0//  e0 C Ce0
hence
C D 43
5 ;
giving us the solution
y D 3
5 .cos.x/ C 2 sin.x//  ex C 43
5 e2x:
To include an initial condition of the form y.a/ D y0; when using Sage, you should use the
following option ics=[a,y0] inside the desolve method. Therefore, the equation
 y0 D 2y C 3 sin.x/ C ex
y.0/ D 7
:
(7.2)
can be solved using the code:
x = var(’x’)
y = function(’y’, x)
desolve( diff(y,x) == 2*y+3*sin(x)+e^(x), y, ics=[0,7])
obtaining
-3/5*cos(x) + 43/5*e^(2*x) - e^x - 6/5*sin(x)
Let us discuss, brieﬂy, the analytic interpretation of the solution of a ﬁrst-order differential
equation (7.1). The graph of the solution y; at any point .x; y/; is a tangent line whose slope is given
by f .x; y/: These lines can be represented graphically by short line segments having the prescribed
values. Such a graphical representation is called a directional ﬁeld. We can use Sage to create such
diagrams. For example, we can draw the solutions of
 y0 D 2y C 3 sin.x/ C ex
y.0/ D 7
;

266
7
Numerical Methods for Differential Equations
and
 y0 D 2y C 3 sin.x/ C ex
y.0/ D 4
;
using the following Sage code
var(’x,y’)
#plotting the directional field
df = plot_slope_field(2*y+3*sin(x)+e^(x), (x,-3,3), (y,-5,5))
#plotting the solution with C = 7
sol1 = plot(-(3/5)*(cos(x)+2*sin(x))-e^(x)+7*e^(2*x),
(x,-3,3), thickness = 3)
#plotting the solution with C = 4
sol2 = plot(-(3/5)*(cos(x)+2*sin(x))-e^(x)+4*e^(2*x),
(x,-3,3), thickness = 3, color = ’red’)
show(df+sol1+sol2, ymax=6)
to obtain
If we include the options headaxislength = 3, headlength = 3
like in the code
below:
df = plot_slope_field(2*y+3*sin(x)+e^(x), (x,-3,3), (y,-5,5),
headaxislength = 3, headlength = 3)
we obtain
Before we describe the numerical methods of solving an initial value problem of ﬁrst-order
derivatives, it is worth mentioning the following result (see [3, p. 304]): under certain conditions, (7.1)
has a unique solution.

7.2
Euler’s Method
267
Theorem 137 (Uniqueness of Initial-Value Problems). If both f .x; y/ and @f .x;y/
@y
are continuous
around .a; y.a// (including at .a; y.a//) then there is a unique continuous solution to the initial-value
problem given by (7.1).
7.2
Euler’s Method
Most numerical methods for solving ordinary differential equations of the type
 y0 D f .x; y/; for x 2 Œa; b
y.a/ D y0
:
(7.3)
will come in the form of a table of values, for the nodes x0 D a; x1; : : : ; xn D b. If one needs to know
an approximate value of the solution y for other values of x than the ones in the table, interpolation
techniques can be used.
One of the simplest, although not very efﬁcient, numerical methods for solving initial-value
problems of ﬁrst-order derivatives is Euler’s Method. It is based on the Taylor series formula, with
n D 1 (see (1.29), on page 54):
f .x C h/ ' f .x/ C hf 0.x/:
(7.4)
From it, we derive
y.x C h/ D y.x/ C hy0.x/
hence we will use the following formula
y.x C h/ D y.x/ C hf .x; y/:
(7.5)

268
7
Numerical Methods for Differential Equations
7.2.1
Algorithm
We will create a table of values for y; at the nodes
x0 D a; x1 D a C h; x2 D a C 2h; : : : ; xn D b;
(7.6)
where
h D b  a
n
:
(7.7)
Using (7.3) and (7.5) we have
y.x0/ D y0;
(7.8)
y.xi/ D y.xi1/ C hf .xi1; y.xi1//; for i D 1; 2; : : : ; n;
hence obtaining
x
y
x0
y0
x1
y.x1/
: : :
: : :
xn
y.xn/
(7.9)
Example 138. Using Euler’s method, compute an approximate value for y.1/; where y is the solution
for the differential equation
 y0 D 2y C 3 sin.x/ C ex
y.0/ D 7
:
using n D 5 steps:
Solution. We have that f .x; y/ D 2y C3 sin.x/Cex; and a D 0; b D 1: Then, using (7.6), (7.7),
and (7.8) we obtain
y.0/ D 7
y.0:2/ D 7 C 0:2f .0; 7/
D 10
y.0:4/ D 10 C 0:2f .0:2; 10/
' 14:3634821501091
y.0:6/ D 14:3634821501091 C 0:2f .0:4; 14:3634821501091/
' 20:6408909550662
y.0:8/ D 20:6408909550662 C 0:2f .0:6; 20:6408909550662/
' 29:6004565812077

7.2
Euler’s Method
269
y.1/ D 29:6004565812077 C 0:2f .0:8; 29:6004565812077/
' 42:3161610539290:
Hence y.1/ ' 42:3161610539290:
Compare these values with the ones obtained from using the actual solution
y D 3
5 .cos.x/ C 2 sin.x//  ex C 43
5 e2x
y.0/ D 7
y.0:2/ D 10:7818464978959
y.0:4/ D 16:6278886802218
y.0:6/ D 25:5581143981239
y.0:8/ D 39:0916865866178
y.1/ D 59:4936540570542
If we plot the exact solution and the table obtained above, we would get
Please note how the errors accumulate and they increases with each new point. They are getting
further and further away from the exact solution. This phenomenon will make more sense once we
discuss the error bounds. This will be discussed below in Sect. 7.2.5.
As we will also see later using Sage, a larger value of n will give us a better estimate.

270
7
Numerical Methods for Differential Equations
7.2.2
Sage Code
We can use the following Sage code to implement the Euler’s Method Algorithm presented in the
previous subsection.
def PrintEuler(a,b,n,f, y0):
#set up the initial values
h = (b-a)/n
xi = a
yi = y0
#print the first line of the table
print "y("+str(a.n()) +") = ", y0.n()
for i in [1,2,..,n]:
#compute the next value of yi
yi= yi+h*f(xi,yi)
#prepare for the next x
xi = xi + h
#print the next line of the table
print "y("+str(xi.n()) +") = ", yi.n()
Example 139. Using Euler’s method, compute an approximate value for y.1/; where y is the solution
for the differential equation
 y0 D 2y C 3 sin.x/ C ex
y.0/ D 7
:
using n D 100 steps:
Solution. We can use the following code
def PrintEuler(a,b,n,f, y0):
#copy here its implementation!!!
#set up the problem
a = 0; b = 1; n = 100
f(x,y) = 2*y+3*sin(x)+e^(x)
y0 = 7
#call the function for Euler’s Method
PrintEuler(a,b,n,f, y0)
to obtain
y(0.000000000000000) =
7.00000000000000
y(0.0100000000000000) =
7.15000000000000
y(0.0200000000000000) =
7.30340049667087
y(0.0300000000000000) =
7.46027048000535
y(0.0400000000000000) =
7.62068029995107
y(0.0500000000000000) =
7.78470169371761

7.2
Euler’s Method
271
y(0.0600000000000000) =
7.95240781363385
y(0.0700000000000000) =
8.12387325556636
y(0.0800000000000000) =
8.29917408791036
y(0.0900000000000000) =
8.47838788116439
y(0.100000000000000) =
8.66159373810067
y(0.110000000000000) =
8.84887232454284
y(0.120000000000000) =
9.04030590076340
y(0.130000000000000) =
9.23597835351313
y(0.140000000000000) =
9.43597522869523
y(0.150000000000000) =
9.64038376469704
y(0.160000000000000) =
9.84929292639247
y(0.170000000000000) =
10.0627934398287
y(0.180000000000000) =
10.2809778276104
y(0.190000000000000) =
10.5039404449966
y(0.200000000000000) =
10.7317775167225
y(0.210000000000000) =
10.9645871745624
y(0.220000000000000) =
11.2024694956485
[ ...
OMITTED
...]
y(0.890000000000000) =
46.3695278742487
y(0.900000000000000) =
47.3445818806723
y(0.910000000000000) =
48.3395693566862
y(0.920000000000000) =
49.3548890813445
y(0.930000000000000) =
50.3909478154718
y(0.940000000000000) =
51.4481604617839
y(0.950000000000000) =
52.5269502282151
y(0.960000000000000) =
53.6277487945162
y(0.970000000000000) =
54.7509964821898
y(0.980000000000000) =
55.8971424278272
y(0.990000000000000) =
57.0666447599179
y(1.00000000000000) =
58.2599707791977
Hence we conclude
y.1/ ' 58:2599707791977
which is pretty close to the actual solution
y.1/ D 59:4936540570542:
On the next page a graph containing the exact solution and the table obtained above using the
Euler’s Method.
Using n D 400; we obtain y.1/ ' 59:1798634022700; and for n D 1;000; we obtain y.1/ '
59:3676993862066:
Below, we give the Sage code used to generate the graphs given in subsections 7.2.1 and 7.2.2.
def PlotEuler(a,b,n,f, y0):
#set up the initial values
h = (b-a)/n
xi = a
yi = y0
#print the first line of the table

272
7
Numerical Methods for Differential Equations
EulerTable = [(xi, y0)]
for i in [1,2,..,n]:
#compute the next value of yi
yi= yi+h*f(xi,yi)
#prepare for the next x
xi = xi + h
#compute the next node, add it to the table
EulerTable.append((xi.n(),yi.n()))
#plot the points obtained from Euler’s Method
p = list_plot (EulerTable, color=’red’, size = 70)
#compute the actual solution
yy = function(’yy’,x)
ActualSol(x) = desolve( diff(yy,x) == f(x,yy), yy, ics=[a,y0])
#plot the actual solution
p+=plot(ActualSol(x), x,a,a+n*h,color = ’blue’, thickness = 2)
p.show()
#set up the problem
a = 0; b = 1; n = 5
f(x,y) = 2*y+3*sin(x)+e^(x)
y0 = 7
#call the function for Euler’s Method
PlotEuler(a,b,n,f, y0)

7.2
Euler’s Method
273
7.2.3
Sage Library
To solve the previous problem, one can also use the Sage Library. For example
x,y=PolynomialRing(QQ,2,"xy").gens()
a =0
y0=7
b =1
h =0.01
eulers_method(2*y+3*sin(x)+e^(x),a,y0,h,b)
would return the following
x
y
h*f(x,y)
0
7
0.150000000000000
0.0100000000000000
7.15000000000000
0.153400496670867
0.0200000000000000
7.30340049667087
0.156869983334485
0.0300000000000000
7.46027048000535
0.160409819945717
0.0400000000000000
7.62068029995107
0.164021393766544
0.0500000000000000
7.78470169371761
0.167706119916233
0.0600000000000000
7.95240781363385
0.171465441932514
0.0700000000000000
8.12387325556636
0.175300832343995
0.0800000000000000
8.29917408791036
0.179213793254032
0.0900000000000000
8.47838788116439
0.183205856936280
0.100000000000000
8.66159373810067
0.187278586442175
0.110000000000000
8.84887232454284
0.191433576220561
0.120000000000000
9.04030590076340
0.195672452749729
0.130000000000000
9.23597835351313
0.199996875182100
0.140000000000000
9.43597522869523
0.204408536001804
0.150000000000000
9.64038376469703
0.208909161695432
0.160000000000000
9.84929292639247
0.213500513436195
0.170000000000000
10.0627934398287
0.218184387781787
0.180000000000000
10.2809778276104
0.222962617386202
0.190000000000000
10.5039404449966
0.227837071725800
0.200000000000000
10.7317775167224
0.232809657839903
0.210000000000000
10.9645871745624
0.237882321086198
0.220000000000000
11.2024694956485
0.243057045911271
0.230000000000000
11.4455265415598
0.248335856636547
0.240000000000000
11.6938623981964
0.253720818259955
0.250000000000000
11.9475832164563
0.259214037273640
0.260000000000000
12.2067972537300
0.264817662498022
0.270000000000000
12.4716149162280
0.270533885932557
0.280000000000000
12.7421488021605
0.276364943623509
0.290000000000000
13.0185137457841
0.282313116549081
0.300000000000000
13.3008268623331
0.288380731522263
0.310000000000000
13.5892075938554
0.294570162111733
0.320000000000000
13.8837777559671
0.300883829581186
0.330000000000000
14.1846615855483
0.307324203847450
0.340000000000000
14.4919857893958
0.313893804457776
0.350000000000000
14.8058795938535
0.320595201586667
0.360000000000000
15.1264747954402
0.327431017052660
0.370000000000000
15.4539058124929
0.334403925355439
0.380000000000000
15.7883097378483
0.341516654733698

274
7
Numerical Methods for Differential Equations
0.390000000000000
16.1298263925820
0.348771988244161
0.400000000000000
16.4785983808262
0.356172764862196
0.410000000000000
16.8347711456884
0.363721880604428
0.420000000000000
17.1984930262928
0.371422289673829
[...
OMITTED
...]
0.930000000000001
50.3909478154718
1.05721264631213
0.940000000000001
51.4481604617839
1.07878976643112
0.950000000000001
52.5269502282151
1.10079856630114
0.960000000000001
53.6277487945162
1.12324768767359
0.970000000000001
54.7509964821898
1.14614594563749
0.980000000000001
55.8971424278273
1.16950233209060
0.990000000000001
57.0666447599179
1.19332601927987
1.00000000000000
58.2599707791977
1.21762636341278
If we include the option algorithm = ’none’ option, like in the following Sage code:
x,y=PolynomialRing(QQ,2,"xy").gens()
a =0
y0=7
b =1
h =0.01
eulers_method(2*y+3*sin(x)+e^(x),a,y0,h,b, algorithm = ’none’)
then we obtain:
[[0, 7],
[0.0100000000000000, 7.15000000000000],
[0.0200000000000000, 7.30340049667087],
[0.0300000000000000, 7.46027048000535],
[0.0400000000000000, 7.62068029995107],
[0.0500000000000000, 7.78470169371761],
[0.0600000000000000, 7.95240781363385],
[0.0700000000000000, 8.12387325556636],
[0.0800000000000000, 8.29917408791036],
[0.0900000000000000, 8.47838788116439],
[0.100000000000000, 8.66159373810067],
[0.110000000000000, 8.84887232454284],
[0.120000000000000, 9.04030590076340],
[0.130000000000000, 9.23597835351313],
[0.140000000000000, 9.43597522869523],
[0.150000000000000, 9.64038376469703],
[0.160000000000000, 9.84929292639247],
[0.170000000000000, 10.0627934398287],
[0.180000000000000, 10.2809778276104],
[0.190000000000000, 10.5039404449966],
[0.200000000000000, 10.7317775167224],
[0.210000000000000, 10.9645871745624],
[0.220000000000000, 11.2024694956485],
[0.230000000000000, 11.4455265415598],
[0.240000000000000, 11.6938623981964],
[0.250000000000000, 11.9475832164563],
[0.260000000000000, 12.2067972537300],
[0.270000000000000, 12.4716149162280],
[0.280000000000000, 12.7421488021605],

7.2
Euler’s Method
275
[0.290000000000000, 13.0185137457841],
[0.300000000000000, 13.3008268623331],
[0.310000000000000, 13.5892075938554],
[0.320000000000000, 13.8837777559671],
[0.330000000000000, 14.1846615855483],
[0.340000000000000, 14.4919857893958],
[...
OMITTED
...]
[0.890000000000001, 46.3695278742487],
[0.900000000000001, 47.3445818806724],
[0.910000000000001, 48.3395693566862],
[0.920000000000001, 49.3548890813445],
[0.930000000000001, 50.3909478154718],
[0.940000000000001, 51.4481604617839],
[0.950000000000001, 52.5269502282151],
[0.960000000000001, 53.6277487945162],
[0.970000000000001, 54.7509964821898],
[0.980000000000001, 55.8971424278273],
[0.990000000000001, 57.0666447599179],
[1.00000000000000, 58.2599707791977],
[1.01000000000000, 59.4775971426105]]
To plot the points obtained from calling the eulers_method() we could use the following
code:
x,y=PolynomialRing(QQ,2,"xy").gens()
a =0
y0=7
b =1
h =0.01
points = eulers_method(2*y+3*sin(x)+e^(x),a,y0,h,b, algorithm =
’none’) list_plot(points)
to obtain

276
7
Numerical Methods for Differential Equations
7.2.4
Sage Interacts
Below, we put the previous Sage code into a Sage interact:
html(’<h2>Euler Method using Sage Interacts</h2>’)
var(’x y’)
@interact
def taylor_through_Sage_interaction(
f = input_box(default= 2*y+3*sin(x)+e^(x)),
h = slider(0.001,0.5,0.001,0.25) ):
x,y=PolynomialRing(QQ,2,"xy").gens()
a =0
y0=7
b =1
points = eulers_method(f,a,y0,h,b, algorithm = ’none’)
p = list_plot(points)
show(p)
and obtained
and
50
40
30
20
10
0
0.2
0.4
0.6
0.8
1
Euler Method using Sage Interacts 
h
f
0.0220000000000000
2*y + eˆx + 3*sin(x)

7.2
Euler’s Method
277
50
40
30
20
10
0
0.2
0.4
0.6
0.8
1
1.2
Euler Method using Sage Interacts 
h
f
2*y + eˆx + 3*sin(x)
0.2940000000000000
7.2.5
Error Bounds
There are two error sources we should be concerned about, and they both are independent from the
use of computers in this process (which introduces yet another type of errors). They are called the
truncation error, and the propagated error. Let us denote by y the true, exact solution.
The truncation error is coming from using the Taylor formula with n D 1 (see (7.4)) at each step.
y.xiC1/ D y.xi/ C hf .xi; y.xi// C ET
If f is two times continuously differentiable (see also (1.29), on page 54) then this error is
ET D f 00./
2
h2; with xn    xnC1
' O.h2/:
Hence, each time we approximated y.xiC1/ by y.xi/ C hf .xi; y.xi//; we committed a truncation
error.
The propagated error comes from the accumulated errors given by the truncation errors obtained
at each step. When computing y.xiC1/; we used y.xi/ which already contains errors due truncation
errors. It can be shown (see [1, p. 387]) that at each step, this error is
EP D f .xi; y.xi//  f .xi; y.xi//
' O.h/:

278
7
Numerical Methods for Differential Equations
Hence, overall, as h ! 0 (or equivalently, as n ! 1) we have a linear convergence.
y.xi/  y.xi/ D O.h/:
In our previous example, when we used Euler’s Method to solve
 y0 D 2y C 3 sin.x/ C ex
y.0/ D 7
;
we had the following errors:
Case n D 5; hence h D 0:2 W
y(0.000000000000000) =
7.00000000000000
actual error =
0
y(0.200000000000000) =
10.0000000000000
actual error =
0.781846497895935
y(0.400000000000000) =
14.3634821501091
actual error =
2.26440653011277
y(0.600000000000000) =
20.6408909550661
actual error =
4.91722344305780
y(0.800000000000000) =
29.6004565812077
actual error =
9.49123000541007
y(1.00000000000000) =
42.3161610539290
actual error =
17.1774930031252
Note how the errors accumulate as you go down the list of computations!
Case n D 10; hence h D 0:1 W
y(0.000000000000000) =
7.00000000000000
actual error =
0
y(0.100000000000000) =
8.50000000000000
actual error =
0.182090202958805
y(0.200000000000000) =
10.3404671168016
actual error =
0.441379381094323
y(0.300000000000000) =
12.5903016152165
actual error =
0.802235119096930
y(0.400000000000000) =
15.3320038810158
actual error =
1.29588479920607
y(0.500000000000000) =
18.6644126296756
actual error =
1.96222964091275
y(0.600000000000000) =
22.7059949442620
actual error =
2.85211945386190
y(0.700000000000000) =
27.5987985551720
actual error =
4.03020191516578
y(0.800000000000000) =
33.5131988431248
actual error =
5.57848774349302
y(0.900000000000000) =
40.6535995318688
actual error =
7.60080727841018
y(1.00000000000000) =
49.2652778222465
actual error =
10.2283762348076
and when n D 20; hence h D 0:05 W
y(0.000000000000000) =
7.00000000000000
actual error =
0
y(0.0500000000000000) =
7.75000000000000
actual error =
0.0439736397127519
y(0.100000000000000) =
8.58506043020940
actual error =
0.0970297727494013
y(0.150000000000000) =
9.51380003163115
actual error =
0.160563065064250
y(0.200000000000000) =
10.5456874668017
actual error =
0.236159031094215
y(0.250000000000000) =
11.6911267510092
actual error =
0.325618556192389
y(0.300000000000000) =
12.9615512908326
actual error =
0.430985443480764
y(0.350000000000000) =
14.3695273912939
actual error =
0.554577347703969
y(0.400000000000000) =
15.9288681789713
actual error =
0.699020501250567
y(0.450000000000000) =
17.6547589830968
actual error =
0.867288685017754
y(0.500000000000000) =
19.5638953207976
actual error =
1.06274694979076
y(0.550000000000000) =
21.6746347472030
actual error =
1.28920065291640
y(0.600000000000000) =
24.0071639571563
actual error =
1.55095044096764
y(0.650000000000000) =
26.5836826639007
actual error =
1.85285388259820
y(0.700000000000000) =
29.4286059326019
actual error =
2.20039453773590
y(0.750000000000000) =
32.5687868143213
actual error =
2.59975934062112
y(0.800000000000000) =
36.0337613105875
actual error =
3.05792527603027
y(0.850000000000000) =
39.8560179017058
actual error =
3.58275644152276
y(0.900000000000000) =
44.0712940952438
actual error =
4.18311271503526
y(0.950000000000000) =
48.7189026967701
actual error =
4.86897138809019
y(1.00000000000000) =
53.8420907751313
actual error =
5.65156328192288

7.3
Taylor Series Method
279
7.3
Taylor Series Method
Euler’s Method is just a particular case of a more general algorithm, called Taylor Series Method.
In Euler’s Method, we used Taylor series formula, with N D 1 (see (1.29), on page 54) to derive
y.x C h/ ' y.x/ C hy0.x/
hence
y.x C h/ D y.x/ C hf .x; y/:
(7.10)
We can use Taylor series with N larger than one. For example, we can go all the way up to N D 5 to
obtain more accurate formulae.
Let us see how Taylor Series Method works for N D 5: From (1.29), on page 54) we have
y.x C h/ ' y.x/ C hy0.x/ C h2
2 y00.x/ C h3
3Š y000.x/ C h4
4Š y.4/.x/ C h5
5Š y.5/.x/;
(7.11)
giving us the following algorithm:
7.3.1
Algorithm
We will create a table of values for y; at the nodes
x0 D a; x1 D a C h; x2 D a C 2h; : : : ; xn D b;
(7.12)
where
h D b  a
n
:
(7.13)
Using (7.3) and (7.5) we have
y.x0/ D y0;
(7.14)
y.xiC1/ D y.xi/ C y0.xi/ C h2
2 y00.xi/ C h3
3Š y000.xi/
Ch4
4Š y.4/.xi/ C h5
5Š y.5/f .xi/;
for i D 1; 2; : : : ; n;
hence obtaining the table
x
y
x0
y0
x1
y.x1/
: : :
: : :
xn
y.xn/
(7.15)

280
7
Numerical Methods for Differential Equations
Example 140. Using Taylor Series method, with N D 5; compute an approximate value for y.1/;
with y the solution for the following differential equation
 y0 D 2y C 3 sin.x/ C ex
y.0/ D 7
:
using n D 5 steps:
Solution. We have that a D 0; b D 1; and
y0 D 2y C 3 sin.x/ C ex
y00 D 2y0 C 3 cos.x/ C ex
y000 D 2y00  3 sin.x/ C ex
y.4/ D 2y000  3 cos.x/ C ex
y.5/ D 2y.4/ C 3 sin.x/ C ex
using (7.12), (7.13), and (7.14) we obtain
y.0/ D 7
y.0:2/ D 10:757288
y.0:4/ D 16:5759433020146
y.0:6/ D 25:4741965479400
y.0:8/ D 38:9661958471361
y.1/ D 59:3063724625059
Hence y.1/ ' 42:3161610539290:
Compare these values with the ones obtained from using the actual solution
y D 3
5 .cos.x/ C 2 sin.x//  ex C 43
5 e2x
y.0/ D 7
y.0:2/ D 10:7818464978959
y. 0:4/ D 16:6278886802218
y. 0:6/ D 25:5581143981239
y. 0:8/ D 39:0916865866178
y.1/ D 59:4936540570542

7.3
Taylor Series Method
281
If we plot the exact solution and the table obtained above, we would get
Notice what a great improvement compared to Euler’s Method that gave us the following plot:

282
7
Numerical Methods for Differential Equations
7.3.2
Sage Code
This part is left as an exercise.
Example 141. Using Taylor’s method, with N D 5, compute an approximate value for y.1/ for the
following differential equation
 y0 D 2y C 3 sin.x/ C ex
y.0/ D 7
:
using n D 5 steps. Also give the error of approximation for each node.
Solution. The Sage code is left as a homework. We obtain
y(0.000000000000000) = 7.00000000000000
error = 0.000000000000000
y(0.200000000000000) = 10.7572880000000
error = 0.0245584978959342
y(0.400000000000000) = 16.5759433020146
error = 0.0519453782072922
y(0.600000000000000) = 25.4741965479400
error = 0.0839178501839517
y(0.800000000000000) = 38.9661958471361
error = 0.125490739481717
y(1.00000000000000)
= 59.3063724625059
error = 0.187281594548264
Example 142. Using Taylor’s method, with N D 5, compute an approximate value for y.1/ for the
following differential equation
 y0 D 2y C 3 sin.x/ C ex
y.0/ D 7
:
using n D 100 steps. Also give the error of approximation for each node.
Solution. The Sage code is left as a homework. We obtain
y(0.000000000000000) = 7.00000000000000
error = 0.000000000000000
y(0.0100000000000000) = 7.15166105396500
error = 0.0000505029299312509
y(0.0200000000000000) = 7.30679189783291
error = 0.000101016162930123
y(0.0300000000000000) = 7.46546361552791
error = 0.000151530316279569
y(0.0400000000000000) = 7.62774870660780
error = 0.000202036183907572
y(0.0500000000000000) = 7.79372111496462
error = 0.000252524748135086
y(0.0600000000000000) = 7.96345625810909
error = 0.000302987191725723
y(0.0700000000000000) = 8.13703105705068
error = 0.000353414910254091
y(0.0800000000000000) = 8.31452396678522
error = 0.000403799524804738
y(0.0900000000000000) = 8.49601500740261
error = 0.000454132894933568
y(0.100000000000000) = 8.68158579582678
error = 0.000504407132023155
y(0.110000000000000) = 8.87131957820105
error = 0.000554614612922499
y(0.120000000000000) = 9.06530126293170
error = 0.000604747993978805
y(0.130000000000000) = 9.26361745440318
error = 0.000654800225330376
y(0.140000000000000) = 9.46635648737840
error = 0.000704764565665039
y(0.150000000000000) = 9.67360846209816
error = 0.000754634597242565
y(0.160000000000000) = 9.88546528009366
error = 0.000804404241290690
y(0.170000000000000) = 10.1020206807265
error = 0.000854067773913503
y(0.180000000000000) = 10.3233702784711
error = 0.000903619842153147
y(0.190000000000000) = 10.5496116009543
error = 0.000953055480623743
y(0.200000000000000) = 10.7808441277675
error = 0.00100237012846160
y(0.210000000000000) = 11.0171693300670
error = 0.00105155964671011
y(0.220000000000000) = 11.2586907109786
error = 0.00110062033608682
y(0.230000000000000) = 11.5055138468224
error = 0.00114954895519548

7.3
Taylor Series Method
283
y(0.240000000000000) = 11.7577464291745
error = 0.00119834273917008
y(0.250000000000000) = 12.0154983077828
error = 0.00124699941869721
y(0.260000000000000) = 12.2788815343538
error = 0.00129551723958921
y(0.270000000000000) = 12.5480104072277
error = 0.00134389498271226
y(0.280000000000000) = 12.8230015169612
error = 0.00139213198441090
y(0.290000000000000) = 13.1039737928343
error = 0.00144022815743161
y(0.300000000000000) = 13.3910485503011
error = 0.00148818401228912
y(0.310000000000000) = 13.6843495394037
error = 0.00153600067909099
[...
OMITTED
...]
y(0.850000000000000) = 43.4344605207091
error = 0.00431382251949236
y(0.860000000000000) = 44.3585244195329
error = 0.00438612316260789
y(0.870000000000000) = 45.3016916335822
error = 0.00446029509808016
y(0.880000000000000) = 46.2643481117555
error = 0.00453643249167290
y(0.890000000000000) = 47.2468876029601
error = 0.00461463265753442
y(0.900000000000000) = 48.2497118141456
error = 0.00469499613341662
y(0.910000000000000) = 49.2732305715357
error = 0.00477762675683974
y(0.920000000000000) = 50.3178619851199
error = 0.00486263174334284
y(0.930000000000000) = 51.3840326164738
error = 0.00495012176595783
y(0.940000000000000) = 52.4721776499729
error = 0.00504021103691904
y(0.950000000000000) = 53.5827410674708
error = 0.00513301738945549
y(0.960000000000000) = 54.7161758265093
error = 0.00522866236334968
y(0.970000000000000) = 55.8729440421336
error = 0.00532727129045996
y(0.980000000000000) = 57.0535171723850
error = 0.00542897338254633
y(0.990000000000000) = 58.2583762075448
error = 0.00553390182098651
y(1.00000000000000) = 59.4880118632060
error = 0.00564219384817183
Hence, y.1/ ' 59:4880118632060
Using n D 200; we obtain
y(1.00000000000000) = 59.4908900310364 error = 0.00276402601785891
We can plot the values in the previous table to obtain the following graph

284
7
Numerical Methods for Differential Equations
where the continuous line represents the actual solution, and the dots represent the estimates obtained
using Taylor Series Method. Compare this to the graph we obtained from the Euler’s Method.
7.4
Runge–Kutta’s Method
One of the most popular methods for solving initial-value problems is Runge–Kutta’s Method. It
is designed to imitate the Taylor Series Method but avoid the need to compute the time-consuming
higher-order derivatives. These techniques were named after the German mathematicians Carl Runge
and Martin Wilhelm Kutta around 1900.
Although the Runge–Kutta family of methods is very rich, we will only present the Runge–Kutta
Method of Order 2, and the Runge–Kutta Method of Order 4 (also called the “classic” or “original”
Runge–Kutta method).
7.4.1
Runge–Kutta Method of Order 2
This method will need two function evaluations
k1 D hf .x; y/
k2 D hf .x C ˛h; y C ˇk1/
and then the formula will be given by adding a linear combination of them to the value of y.x/ to
obtain the value at y.x C h/
y.x C h/ D y.x/ C k1 C ık2;
(7.16)
with ˛; ˇ; ; ı—constants to be determined next.
Note: if we choose  D 1; ı D 0; then we obtain again the Euler’s Method. But we can do better
than that.
The constants ˛; ˇ; ; ı will be determined so that (7.16) will be as accurate as possible. Using
Taylor Series we obtain
y.x C h/ D y.x/ C hy0.x/ C h2
2 y00.x/ C O.h3/
(7.17)
and
f .x C ˛h; y C ˇhf .x; y// D f .x; y/ C ˛h @
@x f .x; y/ C ˇhf .x; y/ @
@y f .x; y/ C O.h2/
(7.18)
hence, from (7.16), (7.17), (7.18), and using y0.x/ D f .x; y/; we obtain
y.x/ C hy0.x/ C h2
2 y00.x/ C O.h3/ D y.x/ C . C ı/ hf .x; y/ C ı˛h2 @
@x f .x; y/
Cıˇh2f .x; y/ @
@y f .x; y/ C O.h3/

7.4
Runge–Kutta’s Method
285
From here, we deduce
8
<
:
 C ı D 1
ı˛ D 1
2
ıˇ D 1
2
:
This system has inﬁnitely many solutions. Some of the most common solutions are
8
ˆˆ<
ˆˆ:
˛ D 1
ˇ D 1
 D 1
2
ı D 1
2
also called Heun’s method,
8
ˆˆ<
ˆˆ:
˛ D 2
3
ˇ D 2
3
 D 1
4
ı D 3
4
(7.19)
and
8
ˆˆ<
ˆˆ:
˛ D 1
2
ˇ D 1
2
 D 0
ı D 1
; also called Midpoint method.
From the way we derived this formula, see (7.17), we can see that the truncation error has order O.h3/:
7.4.2
Runge–Kutta Method of Order 4
This method will need four function evaluations
k1 D hf .x; y/
k2 D hf
	
x C 1
2h; y C 1
2k1

k3 D hf
	
x C 1
2h; y C 1
2k2

k4 D hf .x C h; y C k3/
and then the formula will be given by adding the following linear combination of them to the value of
y.x/ to obtain the value at y.x C h/ W
y.x C h/ D y.x/ C 1
6 .k1 C 2k2 C 2k3 C k4/ :
(7.20)
In this case, it can be shown that the truncation error has order O.h5/; while the total accumulated
error has order O.h4/:

286
7
Numerical Methods for Differential Equations
7.4.3
Sage Code
We present, below, the Sage implementation for each of the Runge–Kutta Methods presented above,
applied to the initial-value problem
 y0 D 2y C 3 sin.x/ C ex
y.0/ D 7
:
(7.21)
Example 143. Using Heun’s method (Runge–Kutta’s Method of order 2), compute an approximate
value for y.1/ for the differential equation (7.21) using n D 5 steps. Also give the error of
approximation for each node.
Solution. Using the Sage code
def HeunMethod(a,b,n,f, y0):
h = (b-a)/n
xi = a
yi = y0
#compute the actual solution
yy = function(’yy’,x)
TrueAnswer(x) = desolve( diff(yy,x) == f(x,yy), yy, ics=[a,y0])
#print the first line
print "y("+str(xi.n()) +") = ", yi.n() , "\terror = ", \
(TrueAnswer(xi)-yi).n()
#apply the method to compute each line in the table
for i in [1,2,..,n]:
k1 = h*f(xi,yi)
k2 = h*f(xi+h,yi+k1)
yi =yi + k1/2+k2/2
xi=xi+h
print "y("+str(xi.n()) +") = ", yi.n() , "\terror = ", \
(TrueAnswer(xi)-yi).n()
#set up the problem
a = 0; b = 1; n = 5
f(x,y) = 2*y+3*sin(x)+e^(x)
y0 = 7
#call the function for Heun’s Method
HeunMethod(a,b,n,f, y0)
we obtain
y(0.000000000000000) = 7.00000000000000
error = 0.000000000000000
y(0.200000000000000) = 10.6817410750545
error = 0.100105422841400
y(0.400000000000000) = 16.3294222686138
error = 0.298466411608058
y(0.600000000000000) = 24.8915607410454
error = 0.666553657078574
y(0.800000000000000) = 37.7695172877468
error = 1.32216929887095
y(1.00000000000000) = 57.0360203523203
error = 2.45763370473384

7.4
Runge–Kutta’s Method
287
Example 144. Using Midpoint method (Runge–Kutta’s Method of order 2), compute an approximate
value for y.1/ for the differential equation (7.21) using n D 5 steps. Also give the error of
approximation for each node.
Solution. Using the Sage code
def MidpointMethod(a,b,n,f, y0):
h = (b-a)/n
xi = a
yi = y0
#compute the actual solution
yy = function(’yy’,x)
TrueAnswer(x) = desolve( diff(yy,x) == f(x,yy), yy, ics=[a,y0])
#print the first line
print "y("+str(xi.n()) +") = ", yi.n() , "\terror = ", \
(TrueAnswer(xi)-yi).n()
#apply the method to compute each line in the table
for i in [1,2,..,n]:
k1 = h*f(xi,yi)
k2 = h*f(xi+h/2,yi+k1/2)
yi =yi+k2
xi=xi+h
print "y("+str(xi.n()) +") = ", yi.n() , "\terror = ", \
(TrueAnswer(xi)-yi).n()
#set up the problem
a = 0; b = 1; n = 5
f(x,y) = 2*y+3*sin(x)+e^(x)
y0 = 7
#call the function for Midpoint Method
MidpointMethod(a,b,n,f, y0)
we obtain
y(0.000000000000000) = 7.00000000000000
error = 0.000000000000000
y(0.200000000000000) = 10.6809342336032
error = 0.100912264292709
y(0.400000000000000) = 16.3277629812666
error = 0.300125698955248
y(0.600000000000000) = 24.8888919785598
error = 0.669222419564151
y(0.800000000000000) = 37.7654831309282
error = 1.32620345568956
y(1.00000000000000)
= 57.0299361698293
error = 2.46371788722488
Example 145. Using Runge–Kutta’s Method of order 4, compute an approximate value for y.1/ for
the differential equation (7.21) using n D 5 steps. Also give the error of approximation for each node.
Solution. Using the Sage code
def RungeKuttaOrder4(a,b,n,f, y0):
h = (b-a)/n
xi = a
yi = y0
#compute the actual solution

288
7
Numerical Methods for Differential Equations
yy = function(’yy’,x)
TrueAnswer(x) = desolve( diff(yy,x) == f(x,yy), yy, ics=[a,y0])
print "y("+str(xi.n()) +")=", yi.n() , ", error=", \
(TrueAnswer(xi)-yi).n()
#apply the method
for i in [1,2,..,n]:
k1 = h*f(xi,yi)
k2 = h*f(xi+h/2,yi+k1/2)
k3 = h*f(xi+h/2,yi+k2/2)
k4 = h*f(xi+h
,yi+k3
)
yi =yi+(k1+2*k2+2*k3+k4)/6
xi=xi+h
print "y("+str(xi.n()) +")=", yi.n() , ", error=", \
(TrueAnswer(xi)-yi).n()
#set up the problem
a = 0; b = 1; n = 5
f(x,y) = 2*y+3*sin(x)+e^(x)
y0 = 7
#call the function for RungeKutta’s Method of order 4
RungeKuttaOrder4(a,b,n,f, y0)
we obtain
y(0.000000000000000)= 7.00000000000000, error= 0.000000000000000
y(0.200000000000000)= 10.7810735350155, error= 0.000772962880466022
y(0.400000000000000)= 16.6255751950963, error= 0.00231348512556406
y(0.600000000000000)= 25.5529272101886, error= 0.00518718793531631
y(0.800000000000000)= 39.0813557670383, error= 0.0103308195794800
y(1.00000000000000) = 59.4743733524585, error= 0.0192807045956751
7.5
Systems of Ordinary Differential Equations
7.5.1
Taylor Series Method
Taylor Series Method can be used to solve not only an initial-value problem of an ordinary differential
equation, but also systems of such equations. Suppose we are trying to solve the following system
8
ˆˆ<
ˆˆ:
y0
1.x/ D f1 .x; y1; y2; : : : ; ym/
y0
2.x/ D f2 .x; y1; y2; : : : ; ym/
: : :
y0
m.x/ D fm .x; y1; y2; : : : ; ym/
;

7.5
Systems of Ordinary Differential Equations
289
with the initial conditions
8
ˆˆ<
ˆˆ:
y1.a/ D y0
1
y2.a/ D y0
2
: : :
ym.a/ D y0
m
:
Then, we can use Taylor Polynomial of Order n W
Y.x C h/ ' Y.x/ C hY 0.x/ C h2
2 Y 00.x/ C    C hn
nŠ Y .n/.x/
to obtain an approximation for the next iteration.
Example 146. For the system of differential equations
8
<
:
y0.x/ D 2y C 3 sin.x/ C ex
z0.x/ D 4z C cos.z/  x2
y.1/ D 7; z.1/ D 1:2
ﬁnd the values of y.2/; and z.2/, using Taylor series Method of order N D 4; with n D 5 steps:
Solution. We have
 y0.x/ D 2y C 3 sin.x/ C ex
z0.x/ D 4z C cos.z/  x2
Therefore
 y00.x/ D 2y0 C 3 cos.x/ C ex
z00.x/ D 4z0  sin.z/z0  2x
;

y000.x/ D 2y00  3 sin.x/ C ex
z000.x/ D 4z00  cos.z/ .z0/2  sin.z/z00  2 ;
and

y.4/.x/ D 2y000  3 cos.x/ C ex
z.4/.x/ D 4z000 C sin.z/ .z0/3  3 cos.z/z0z00  sin.z/z000 ;
then, starting with
 y.1/ D 7
z.1/ D 1:2 ;
and using
Y.x C h/ ' Y.x/ C hY 0.x/ C h2
2 Y 00.x/ C h3
6 Y 000.x/ C h4
24Y .4/.x/;

290
7
Numerical Methods for Differential Equations
we have
(
y.xiC1/ ' y.xi/ C hy0.xi/ C h2
2 y00.xi/ C h3
6 y000.xi/ C h4
24y.4/.xi/
z.xiC1/ ' z.xi/ C hz0.xi/ C h2
2 z00.xi/ C h3
6 z000.xi/ C h4
24z.4/.xi/
;
for i D 0; 1; 2; 3; 4; hence we obtain the following
 y.1:2/ D 2:28606910353070
z.1:2/ D 0:596892537878381
 y.1:4/ D 4:75699820755308
z.1:4/ D 1:24492429778426
 y.1:6/ D 18:3631941512904
z.1:6/ D 6:52269434184452
 y.1:8/ D 1217:15058952107
z.1:8/ D 593:064833163811
 y.2/ D 17617714583:4531
z.2/ D 6304669145:88529 :
We can also implement this in Sage as follows:
def PrintSystemTaylorN3(a,b,n,yp,y2p,y3p,zp,z2p,z3p,y0, z0):
#set up the initial values
h = (b-a)/n
xi = a
yi = y0
zi = z0
#print the first line of the table
print "y("+str(xi.n()) +") = ", yi.n()
print "
and z("+str(xi.n()) +") = ", zi.n()
for i in [1,2,..,n]:
#compute the next value of yi
new_yi= yi+h*yp(xi,yi,zi)+h^2/2*y2p(xi,yi,zi)+h^3/6*y3p(xi,yi,zi)
new_zi= zi+h*zp(xi,yi,zi)+h^2/2*z2p(xi,yi,zi)+h^3/6*z3p(xi,yi,zi)
yi = new_yi
zi = new_zi
#prepare for the next x
xi = xi + h
#print the next line of the table
print "y("+str(xi.n()) +") = ", yi.n()
print "
and z("+str(xi.n()) +") = ", zi.n()
#set up the problem
a = 1; b = 2; n = 5
#the functions y’,y’’ and y’’’
#the functions z’,z’’ and z’’’
def yp(x,y,z):
return y^2+z+x^3

7.5
Systems of Ordinary Differential Equations
291
def zp(x,y,z):
return e^(z)+cos(y)-(y+z)^2
def y2p(x,y,z) :
return 2 * y* yp(x,y,z)+zp(x,y,z)+3*x^2
def z2p(x,y,z) :
return e^(z)*zp(x,y,z)-sin(y)*yp(x,y,z)
\
-2*(y+z)*(yp(x,y,z)+zp(x,y,z))
def y3p(x,y,z) :
return 2*((yp(x,y,z))^2+y*y2p(x,y,z))+z2p(x,y,z)+6*x
def z3p(x,y,z) :
return e^(z)*((zp(x,y,z))^2+z2p(x,y,z))-
\
(cos(y)*(yp(x,y,z))^2+sin(y)*y2p(x,y,z))-
\
2*((yp(x,y,z)+zp(x,y,z))^2+
\
(y+z)*(y2p(x,y,z)+z2p(x,y,z)))
y0 = 1.2
z0 = 1.7
#call the function for Euler’s Method
PrintSystemTaylorN3(a,b,n,yp,y2p,y3p,zp,z2p,z3p,y0, z0)
to obtain
y(1.00000000000000) =
1.20000000000000
and z(1.00000000000000) =
1.70000000000000
y(1.20000000000000) =
2.28606910353070
and z(1.20000000000000) =
0.596892537878381
y(1.40000000000000) =
4.75699820755308
and z(1.40000000000000) =
-1.24492429778426
y(1.60000000000000) =
18.3631941512904
and z(1.60000000000000) =
-6.52269434184452
y(1.80000000000000) =
1217.15058952107
and z(1.80000000000000) =
-593.064833163811
y(2.00000000000000) =
1.76177145834531e10
and z(2.00000000000000) =
-6.30466914588529e9
Example 147. For the system of differential equations
8
<
:
y0.x/ D y2 C ln.z/ C x3
z0.x/ D ez C cos.y/  .y C z/2
y.1/ D 1:2; z.1/ D 1:7
ﬁnd the values of y.2/; and z.2/, using Taylor series Method of order N D 3; with n D 5 steps:
Solution. We have

y0.x/ D y2 C z C x3
z0.x/ D ez C cos.y/  .y C z/2

292
7
Numerical Methods for Differential Equations
Therefore

y00.x/ D 2yy0 C z0 C 3x2
z00.x/ D ezz0  sin.y/y0  2.y C z/.y0 C z0/ ;
and
8
ˆˆ<
ˆˆ:
y000.x/ D 2

.y0/2 C yy00
C z00 C 6x
z000.x/ D ez 
.z0/2 C z00


cos.y/ .y0/2 C sin.y/  y00
2

.y0 C z0/2 C .y C z/.y00 C z00/

;
then, starting with
 y.1/ D 1:2
z.1/ D 1:7 ;
and using
Y.x C h/ ' Y.x/ C hY 0.x/ C h2
2 Y 00.x/ C h3
6 Y 000.x/;
we have
(
y.xiC1/ ' y.xi/ C hy0.xi/ C h2
2 y00.xi/ C h3
6 y000.xi/
z.xiC1/ ' z.xi/ C hz0.xi/ C h2
2 z00.xi/ C h3
6 z000.xi/
;
for i D 1; 2; 3; 4; 5; hence we obtain the following
 y.1:2/ D 2:28606910353070
z.1:2/ D 0:596892537878381
 y.1:4/ D 4:75699820755308
z.1:4/ D 1:24492429778426
 y.1:6/ D 18:3631941512904
z.1:6/ D 6:52269434184452
 y.1:8/ D 1217:15058952107
z.1:8/ D 593:064833163811
 y.2/ D 17617714583:4531
z.2/ D 6304669145:88529 :
We can also implement this in Sage as follows:
def PrintSystemTaylorN2(a,b,n,yp,y2p,y3p,zp,z2p,z3p,y0, z0):
#set up the initial values
h = (b-a)/n
xi = a
yi = y0
zi = z0
#print the first line of the table
print "y("+str(xi.n()) +") = ", yi.n()

7.5
Systems of Ordinary Differential Equations
293
print "
and z("+str(xi.n()) +") = ", zi.n()
for i in [1,2,..,n]:
#compute the next value of yi
new_yi= yi+h*yp(xi,yi,zi)+h^2/2*y2p(xi,yi,zi)+h^3/6*y3p(xi,yi,zi)
new_zi= zi+h*zp(xi,yi,zi)+h^2/2*z2p(xi,yi,zi)+h^3/6*z3p(xi,yi,zi)
yi = new_yi
zi = new_zi
#prepare for the next x
xi = xi + h
#print the next line of the table
print "y("+str(xi.n()) +") = ", yi.n()
print "
and z("+str(xi.n()) +") = ", zi.n()
#set up the problem
a = 1; b = 2; n = 5
#the functions y’,y’’ and y’’’
#the functions z’,z’’ and z’’’
def yp(x,y,z):
return y^2+z+x^3
def zp(x,y,z):
return e^(z)+cos(y)-(y+z)^2
def y2p(x,y,z) :
return 2 * y* yp(x,y,z)+zp(x,y,z)+3*x^2
def z2p(x,y,z) :
return e^(z)*zp(x,y,z)-sin(y)*yp(x,y,z)
\
-2*(y+z)*(yp(x,y,z)+zp(x,y,z))
def y3p(x,y,z) :
return 2*((yp(x,y,z))^2+y*y2p(x,y,z))+z2p(x,y,z)+6*x
def z3p(x,y,z) :
return e^(z)*((zp(x,y,z))^2+z2p(x,y,z))-
\
(cos(y)*(yp(x,y,z))^2+sin(y)*y2p(x,y,z))-
\
2*((yp(x,y,z)+zp(x,y,z))^2+
\
(y+z)*(y2p(x,y,z)+z2p(x,y,z)))
y0 = 1.2
z0 = 1.7
#call the function for Euler’s Method
PrintSystemTaylorN2(a,b,n,yp,y2p,y3p,zp,z2p,z3p,y0, z0)
to obtain
y(1.00000000000000) =
1.20000000000000
and z(1.00000000000000) =
1.70000000000000
y(1.20000000000000) =
2.28606910353070
and z(1.20000000000000) =
0.596892537878381
y(1.40000000000000) =
4.75699820755308
and z(1.40000000000000) =
-1.24492429778426

294
7
Numerical Methods for Differential Equations
y(1.60000000000000) =
18.3631941512904
and z(1.60000000000000) =
-6.52269434184452
y(1.80000000000000) =
1217.15058952107
and z(1.80000000000000) =
-593.064833163811
y(2.00000000000000) =
1.76177145834531e10
and z(2.00000000000000) =
-6.30466914588529e9
7.6
Higher-Order Ordinary Differential Equations
In this section we will present a way to solve initial-value problems for higher-order differential
equations, by using systems of Ordinary Differential Equations.
To solve an equation of the form
 y.n/.x/ D f

x; y; y0; y00; : : : ; y.n1/
y.a/; y0.a/; y00.a/; : : : ; y.n1/.a/ given ;
(7.22)
we could ﬁrst turn it into a system of ﬁrst order differential equations, by deﬁning the new variables
y1 D y; y2 D y0; : : : ; yn D y.n1/;
therefore (7.22) becoming
8
ˆˆˆˆˆ<
ˆˆˆˆˆ:
y0
1 D y2
y0
2 D y3
: : :
y0
n1 D yn
y0
n.x/ D f .x; y1; y2; y3; : : : ; yn/
;
with the given initial conditions:
8
ˆˆˆˆˆ<
ˆˆˆˆˆ:
y1.a/ D y.a/
y2.a/ D y0.a/
y3.a/ D y00.a/
: : : ;
yn.a/ D y.n1/.a/
;
and then we could simply apply the techniques we have already seen in the previous section.
Example 148. For the following higher order differential equation
8
ˆˆ<
ˆˆ:
y000.x/ D 2y0 C 3 sin.y/ C ey00 C ex
y.1/ D 7;
y0.1/ D 1:2;
y00.1/ D 2
ﬁnd the value of the solution y at x D 1:5; using Taylor series Method of order N D 2; with n D 5
steps:

7.6
Higher-Order Ordinary Differential Equations
295
Solution. We need to ﬁnd y.1:5/:
First, we turn the given problem into a system of ﬁrst order differential equations. By deﬁning the
new variables
y1 D y; y2 D y0; y3 D y00;
we obtain
8
<
:
y0
1 D y2
y0
2 D y3
y0
3 D f .x; y1; y2; y3/ D 2y2 C 3 sin.y1/ C ey3 C ex
;
with the given initial conditions:
8
<
:
y1.1/ D 7
y2.1/ D 1:2
y3.1/ D 2
:
Then, we can use Taylor’s Series Method of order N D 2; to solve it. For this, we will need to
compute
8
<
:
y00
1 .x/ D y0
2.x/
y00
2 .x/ D y0
3.x/
y00
3 .x/ D 2y0
2.x/ C 3 cos.y1.x//  y0
1.x/ C y0
3.x/ey3.x/ C ex
Therefore using
Y.x C h/ ' Y.x/ C hY 0.x/ C h2
2 Y 00.x/;
we have
8
ˆ<
ˆ:
y1.xiC1/ ' y1.xi/ C hy0
1.xi/ C h2
2 y00
1 .xi/
y2.xiC1/ ' y2.xi/ C hy0
2.xi/ C h2
2 y00
2 .xi/
y3.xiC1/ ' y3.xi/ C hy0
3.xi/ C h2
2 y00
3 .xi/
;
for i D 0; 1; 2; 3; 4; hence we obtain the following
8
<
:
y1.1:1/ D 7:11
y2.1:1/ D 1:03612288453926
y3.1:1/ D 1:26549195868388
8
<
:
y1.1:2/ D 7:20728482866051
y2.1:2/ D 0:947402919205352
y3.1:2/ D 0:485344501650709
8
<
:
y1.1:3/ D 7:29959839807279
y2.1:3/ D 0:939991685974457
y3.1:3/ D 0:382740618947083

296
7
Numerical Methods for Differential Equations
8
<
:
y1.1:4/ D 7:39551126976497
y2.1:4/ D 1:02609701549618
y3.1:4/ D 1:43909717879495
8
<
:
y1.1:5/ D 7:50531645720857
y2.1:5/ D 1:23507909629775
y3.1:5/ D 3:05642611369023
;
and conclude that
y.1:5/ ' y1.1:5/ D 7:50531645720857:
If we let Sage do the work for n D 10; we obtain:
y1(1.00000000000000) =
7.00000000000000
y2(1.00000000000000) =
1.20000000000000
y3(1.00000000000000) =
-2.00000000000000
y1(1.05000000000000) =
7.05750000000000
y2(1.05000000000000) =
1.10903072113481
y3(1.05000000000000) =
-1.63575856697467
y1(1.10000000000000) =
7.11090683784802
y2(1.10000000000000) =
1.03645303783972
y3(1.10000000000000) =
-1.26309872542805
y1(1.15000000000000) =
7.16115061633322
y2(1.15000000000000) =
0.982759381368820
y3(1.15000000000000) =
-0.878745078880483
y1(1.20000000000000) =
7.20919015405306
y2(1.20000000000000) =
0.948631300008566
y3(1.20000000000000) =
-0.478199612804905
y1(1.25000000000000) =
7.25602396953748
y2(1.25000000000000) =
0.935015010996149
y3(1.25000000000000) =
-0.0549781662309876
y1(1.30000000000000) =
7.30270599737950
y2(1.30000000000000) =
0.943249027734137
y3(1.30000000000000) =
0.400933616499468
y1(1.35000000000000) =
7.35036961578684
y2(1.35000000000000) =
0.975301438649356
y3(1.35000000000000) =
0.906531634991313
y1(1.40000000000000) =
7.40026785226304
y2(1.40000000000000) =
1.03426712636244
y3(1.40000000000000) =
1.49471562794438
y1(1.45000000000000) =
7.45384960311609
y2(1.45000000000000) =
1.12560075704766
y3(1.45000000000000) =
2.24312971247186
y1(1.50000000000000) =
7.51293355310907
y2(1.50000000000000) =
1.26113239330543
y3(1.50000000000000) =
3.41097550740710
concluding
y.1:5/ ' y1.1:5/ D 7:51293355310907:

7.6
Higher-Order Ordinary Differential Equations
297
For n D 100; we obtain
y.1:5/ ' y1.1:5/ D 7:51612031631261:
We leave the Sage implementation as a homework.
7.6.1
Sage Library
Instead of Taylor’s Method, one can use other methods, to get more accurate answers.
Next, we show how we can use Sage library function to solve the previous example using Runge–
Kutta Method of order 4.
Example 149. For the following higher order differential equation
8
ˆˆ<
ˆˆ:
y000.x/ D 2y0 C 3 sin.y/ C ey00 C ex
y.1/ D 7;
y0.1/ D 1:2;
y00.1/ D 2
ﬁnd the value of the solution y at x D 1:5; using Runge–Kutta Method of order 4; with n D 5 steps:
Solution. We need to ﬁnd y.1:5/: First, we turn the given problem into a system of ﬁrst order
differential equations. By deﬁning the new variables
y1 D y; y2 D y0; y3 D y00;
we obtain
8
<
:
y0
1 D y2
y0
2 D y3
y0
3 D f .x; y1; y2; y3/ D 2y2 C 3 sin.y1/ C ey3 C ex
;
with the given initial conditions:
8
<
:
y1.1/ D 7
y2.1/ D 1:2
y3.1/ D 2
:
Next, we use the following Sage code to solve this problem:
#include the library
from Sage.calculus.desolvers import desolve_system_rk4
#declare the variables
var(’y1 y2 y3 x’)
#solve the system of equations using Runge Kuta 4
P=desolve_system_rk4(
#specify the right hand side of each equation
[y2,
y3,
2*y2*3*sin(y1)+e^(y3)+e^x],

298
7
Numerical Methods for Differential Equations
#specify the dependent variables
[y1, y2,
y3],
#specify the initial values for x, y1,y2,y3
ics=[1, 7, 1.2, -2],
#specify the independent variable
ivar=x,
#specify the value of h
step = 0.1,
#specify the value of b
end_points=1.5)
#print all the values
# either use [ [x,y1,y2, y3] for x,y1,y2, y3 in P]
# or
simply use:
print(P)
and obtain
[[1, 7, 1.20000000000000, -2],
[1.1, 7.11127216554, 1.03834128834, -1.22807586556],
[1.2, 7.21029897501, 0.955852822027, -0.410207404994],
[1.3, 7.30531028447, 0.95985149834, 0.518468982343],
[1.4, 7.4057306258, 1.06892608707, 1.75113974135],
[1.5, 7.52461476811, 1.35759828593, 5.7648996391]]
Hence we conclude
y.1:5/ ' y1.1:5/ D 7:52461476811:
If we change n D 50; hence h D 0:01; we obtain:
[[1, 7, 1.20000000000000, -2],
[1.01, 7.01190126496, 1.18037959255, -1.92404169641],
[1.02, 7.02361012775, 1.16151996837, -1.84784253549],
[1.03, 7.03513420835, 1.14342356623, -1.77139589307],
[1.04, 7.0464811515, 1.12609290858, -1.69469166277],
[1.05, 7.05765862774, 1.10953063627, -1.61771627584],
[1.06, 7.06867433476, 1.09373954312, -1.54045270493],
[1.07, 7.07953599907, 1.07872261056, -1.46288045015],
[1.08, 7.09025137811, 1.06448304251, -1.38497550587],
[1.09, 7.1008282626, 1.05102430071, -1.30671030586],
[1.1, 7.11127447931, 1.03835014067, -1.22805364465],
[1.11, 7.12159789421, 1.02646464857, -1.14897057208],
[1.12, 7.13180641593, 1.01537227939, -1.06942225765],
[1.13, 7.14190799966, 1.00507789648, -0.98936582072],
[1.14, 7.15191065142, 0.995586813129, -0.908754121657],
[1.15, 7.16182243283, 0.986904836333, -0.827535508081],

7.7
Systems of Higher-Order Differential Equations
299
[1.16, 7.17165146621, 0.979038313434, -0.745653509266],
[1.17, 7.18140594028, 0.971994182066, -0.663046470102],
[1.18, 7.1910941163, 0.965780024127, -0.579647114217],
[1.19, 7.20072433482, 0.960404124513, -0.495382023506],
[1.2, 7.21030502301, 0.955875535545, -0.410171018281],
[1.21, 7.21984470271, 0.952204148173, -0.323926418521],
[1.22, 7.22935199917, 0.949400771255, -0.236552161772],
[1.23, 7.2388356507, 0.947477220504, -0.147942746998],
[1.24, 7.24830451921, 0.946446419024, -0.0579819654381],
[1.25, 7.25776760185, 0.946322511799, 0.033458631224],
[1.26, 7.26723404386, 0.947120997082, 0.126521589462],
[1.27, 7.27671315286, 0.948858878337, 0.221365822576],
[1.28, 7.28621441475, 0.951554841356, 0.318169398871],
[1.29, 7.29574751157, 0.95522946245, 0.417132994742],
[1.3, 7.30532234156, 0.959905455282, 0.518484208057],
[1.31, 7.31494904201, 0.965607966205, 0.622482998007],
[1.32, 7.32463801528, 0.972364931107, 0.729428619127],
[1.33, 7.33439995883, 0.980207511144, 0.8396685656],
[1.34, 7.34424590003, 0.989170630917, 0.953610262929],
[1.35, 7.35418723707, 0.999293651583, 1.07173658036],
[1.36, 7.36423578738, 1.01062122456, 1.19462676118],
[1.37, 7.37440384583, 1.02320439131, 1.32298520609],
[1.38, 7.38470425547, 1.03710202528, 1.45768192651],
[1.39, 7.39515049503, 1.05238276109, 1.59981084187],
[1.4, 7.40575678902, 1.06912763648, 1.7507762793],
[1.41, 7.41653824923, 1.08743381097, 1.91242581026],
[1.42, 7.42751106123, 1.10741997371, 2.08726281938],
[1.43, 7.4386927376, 1.12923452623, 2.27880417267],
[1.44, 7.45010247475, 1.15306858993, 2.49222094238],
[1.45, 7.46176167984, 1.17917803067, 2.73558257185],
[1.46, 7.47369479863, 1.20792402021, 3.02254873422],
[1.47, 7.48593073249, 1.2398571056, 3.37916388986],
[1.48, 7.49850559653, 1.2759260398, 3.86571421988],
[1.49, 7.51146941271, 1.31819567565, 4.68894162633],
[1.5, 7.52491343636, 1.37601034736, 11.3245065041]]
and conclude
y.1:5/ ' y1.1:5/ D 7:52491343636:
7.7
Systems of Higher-Order Differential Equations
This section is similar to the previous one, in the sense that we can reduce a system of higher-order
differential equations to a system of ﬁrst order differential equations.
If we are given to solve a system of higher-order differential equations of the form
 y.n/.x/ D f

x; y; y0; y00; : : : ; y.n1/; z; z0; z00; : : : ; z.m1/
z.m/.x/ D g

x; y; y0; y00; : : : ; y.n1/; z; z0; z00; : : : ; z.m1/ ;
(7.23)

300
7
Numerical Methods for Differential Equations
with
 y.a/; y0.a/; y00.a/; : : : ; y.n1/.a/
z.a/; z0.a/; z00.a/; : : : ; z.m1/.a/
all given, we ﬁrst turn it into a system of ﬁrst order differential equations, by deﬁning the new variables
y1 D y; y2 D y0; : : : ; yn D y.n1/;
ynC1 D z; ynC2 D z0; : : : ; ynCm D z.m1/
therefore (7.23) becomes
8
ˆˆˆˆˆˆˆˆˆˆˆˆˆˆˆ<
ˆˆˆˆˆˆˆˆˆˆˆˆˆˆˆ:
y0
1 D y2
y0
2 D y3
: : :
y0
n1 D yn
y0
n D f .x; y1; y2; y3; : : : ; ynCm/
y0
nC1 D ynC2
y0
nC2 D ynC3
: : :
y0
nCm1 D ynCm
y0
nCm D g .x; y1; y2; y3; : : : ; ynCm/
;
with the given initial conditions:
8
ˆˆˆˆˆˆˆˆˆˆˆˆˆ<
ˆˆˆˆˆˆˆˆˆˆˆˆˆ:
y1.a/ D y.a/
y2.a/ D y0.a/
y3.a/ D y00.a/
: : : ;
yn.a/ D y.n1/.a/
ynC1.a/ D z.a/
ynC2.a/ D z0.a/
: : : ;
ynCm.a/ D z.m1/.a/
;
and then we can apply the techniques we have already seen in the previous two sections.
NOTE: A similar work can be done for a system with more than two higher-order differential
equations.
Example 150. For the following system of higher order differential equations
8
ˆˆˆˆˆˆˆˆˆ<
ˆˆˆˆˆˆˆˆˆ:
y000.x/ D 3 sin.y/ C ey00 C z0  z4 C ex
z00.x/ D z0  y4 C cos.x/
y.1/ D 2;
y0.1/ D 1;
y00.1/ D 1
z.1/ D 2
z0.1/ D 1

7.7
Systems of Higher-Order Differential Equations
301
ﬁnd the values of the solutions y; and z; at x D 1:5; using Taylor series Method of order N D 2; with
n D 5 steps:
Solution. We need to ﬁnd y.1:5/; and z.1:5/:
First, we turn the given problem into a system of ﬁrst order differential equations, by deﬁning the
new variables
y1 D y; y2 D y0; y3 D y00; y4 D z; y5 D z0
obtaining
8
ˆˆˆˆˆ<
ˆˆˆˆˆ:
y0
1 D y2
y0
2 D y3
y0
3 D f .x; y1; y2; y3; y4; y4/ D 3 sin.y1/ C ey3 C y5  y4
4 C ex
y0
4 D y5
y0
5 D y5  y4
1 C cos.x/
;
with the given initial conditions:
8
ˆˆˆˆˆ<
ˆˆˆˆˆ:
y1.1/ D 2
y2.1/ D 1
y3.1/ D 1
y4.1/ D 2
y5.1/ D 1
:
Then, we can use Taylor’s Series Method of order, let’s say, N D 2; to solve it. For this, we will
need
8
ˆˆˆˆˆ<
ˆˆˆˆˆ:
y00
1 D y0
2
y00
2 D y0
3
y00
3 D 3 cos.y1/y0
1 C y0
3ey3 C y0
5  4y3
4y0
4 C ex
y00
4 D y0
5
y00
5 D y0
5  4y3
1y0
1  sin.x/:
Therefore using
Y.x C h/ ' Y.x/ C hY 0.x/ C h2
2 Y 00.x/;
we have
8
ˆˆˆˆˆ<
ˆˆˆˆˆ:
y1.xiC1/ ' y1.xi/ C hy0
1.xi/ C h2
2 y00
1 .xi/
y2.xiC1/ ' y2.xi/ C hy0
2.xi/ C h2
2 y00
2 .xi/
y3.xiC1/ ' y3.xi/ C hy0
3.xi/ C h2
2 y00
3 .xi/
y4.xiC1/ ' y4.xi/ C hy0
4.xi/ C h2
2 y00
4 .xi/
y5.xiC1/ ' y5.xi/ C hy0
5.xi/ C h2
2 y00
5 .xi/
;

302
7
Numerical Methods for Differential Equations
for i D 0; 1; 2; 3; 4; hence using Sage we obtain the following results
y1(1.00000000000000) =
-2.00000000000000
y2(1.00000000000000) =
-1.00000000000000
y3(1.00000000000000) =
1.00000000000000
y4(1.00000000000000) =
-2.00000000000000
y5(1.00000000000000) =
-1.00000000000000
-----------------------------------------
y1(1.10000000000000) =
-2.09500000000000
y2(1.10000000000000) =
-0.971456643117795
y3(1.10000000000000) =
-0.525837033645837
y4(1.10000000000000) =
-2.18229848847066
y5(1.10000000000000) =
-2.89247561280789
-----------------------------------------
y1(1.20000000000000) =
-2.19477484948001
y2(1.20000000000000) =
-1.14691597429669
y3(1.20000000000000) =
-2.54094212601509
y4(1.20000000000000) =
-2.58005814946148
y5(1.20000000000000) =
-5.35433676347818
-----------------------------------------
y1(1.30000000000000) =
-2.32217115753975
y2(1.30000000000000) =
-1.64451900892177
y3(1.30000000000000) =
-5.70545237672101
y4(1.30000000000000) =
-3.25647093080549
y5(1.30000000000000) =
-8.56206920818365
-----------------------------------------
y1(1.40000000000000) =
-2.51515032031554
y2(1.40000000000000) =
-2.81276075182632
y3(1.40000000000000) =
-11.8994744363292
y4(1.40000000000000) =
-4.29954484614262
y5(1.40000000000000) =
-12.9029557410429
-----------------------------------------
y1(1.50000000000000) =
-2.85592376767981
y2(1.50000000000000) =
-5.76441779205738
y3(1.50000000000000) =
-26.8319860156146
y4(1.50000000000000) =
-5.85359554976254
y5(1.50000000000000) =
-19.3418058178558
and conclude that:
y.1:5/ ' y1.1:5/ D 2:85592376767981
z.1:5/ ' y4.1:5/ D 5:85359554976254:
If we let Sage do the work for n D 10; we obtain:
y1(1.00000000000000) =
-2.00000000000000
y2(1.00000000000000) =
-1.00000000000000
y3(1.00000000000000) =
1.00000000000000
y4(1.00000000000000) =
-2.00000000000000
y5(1.00000000000000) =
-1.00000000000000
-----------------------------------------

7.7
Systems of Higher-Order Differential Equations
303
y1(1.05000000000000) =
-2.04875000000000
y2(1.05000000000000) =
-0.967864160779449
y3(1.05000000000000) =
0.261257525999567
y4(1.05000000000000) =
-2.07057462211767
y5(1.05000000000000) =
-1.88461134555527
-----------------------------------------
y1(1.10000000000000) =
-2.09681663613147
y2(1.10000000000000) =
-0.978267504157610
y3(1.10000000000000) =
-0.642728655180003
y4(1.10000000000000) =
-2.18856145227679
y5(1.10000000000000) =
-2.90131753818579
-----------------------------------------
y1(1.15000000000000) =
-2.14653342215833
y2(1.15000000000000) =
-1.04153884698139
y3(1.15000000000000) =
-1.77405379796278
y4(1.15000000000000) =
-2.36085003513012
y5(1.15000000000000) =
-4.06365547688984
-----------------------------------------
y1(1.20000000000000) =
-2.20082793175485
y2(1.20000000000000) =
-1.17313822807305
y3(1.20000000000000) =
-3.25487352984490
y4(1.20000000000000) =
-2.59513930725166
y5(1.20000000000000) =
-5.39166893452345
-----------------------------------------
y1(1.25000000000000) =
-2.26355343507081
y2(1.25000000000000) =
-1.39814918446889
y3(1.25000000000000) =
-5.30567061500437
y4(1.25000000000000) =
-2.90033549692836
y5(1.25000000000000) =
-6.91548486496673
-----------------------------------------
y1(1.30000000000000) =
-2.34009298256301
y2(1.30000000000000) =
-1.75904456298052
y3(1.30000000000000) =
-8.32037134494797
y4(1.30000000000000) =
-3.28717498934296
y5(1.30000000000000) =
-8.68142295705742
-----------------------------------------
y1(1.35000000000000) =
-2.43844567489322
y2(1.35000000000000) =
-2.32997104630311
y3(1.35000000000000) =
-13.0137467347423
y4(1.35000000000000) =
-3.76924724379470
y5(1.35000000000000) =
-10.7633785553386
-----------------------------------------
y1(1.40000000000000) =
-2.57121141062680
y2(1.40000000000000) =
-3.24402219702593
y3(1.40000000000000) =
-20.7122636643571
y4(1.40000000000000) =
-4.36479053870162
y5(1.40000000000000) =
-13.2858589814962
-----------------------------------------
y1(1.45000000000000) =
-2.75930285005855
y2(1.45000000000000) =
-4.74689316089311

304
7
Numerical Methods for Differential Equations
y3(1.45000000000000) =
-33.9343436346622
y4(1.45000000000000) =
-5.10011212131771
y5(1.45000000000000) =
-16.4749840780874
-----------------------------------------
y1(1.50000000000000) =
-3.03906543764653
y2(1.50000000000000) =
-7.30599859438698
y3(1.50000000000000) =
-57.5730973206327
y4(1.50000000000000) =
-6.01676595541085
y5(1.50000000000000) =
-20.7839438492649
concluding
y.1:5/ ' y1.1:5/ D 3:03906543764653;
z.1:5/ ' y4.1:5/ D 6:01676595541085:
For n D 100; we obtain
y.1:5/ ' y1.1:5/ D 3:30881013044170;
z.1:5/ ' y4.1:5/ D 6:17561463102781:
We leave the Sage implementation as a homework.
7.7.1
Sage Library
Next, we show the solution to the previous problem using Sage library function for Runge–Kutta
Method of order 4.
Example 151. For the following system of higher order differential equations
8
ˆˆˆˆˆˆˆˆˆ<
ˆˆˆˆˆˆˆˆˆ:
y000.x/ D 3 sin.y/ C ey00 C z0  z4 C ex
z00.x/ D z0  y4 C cos.x/
y.1/ D 2;
y0.1/ D 1;
y00.1/ D 1
z.1/ D 2
z0.1/ D 1
ﬁnd the values of the solutions y; and z; at x D 1:5; using Runge–Kutta’s Method of order 4; with
n D 5 steps:
Solution. We need to ﬁnd y.1:5/; and z.1:5/:
First, we turn the given problem into a system of ﬁrst order differential equations, by deﬁning the
new variables
y1 D y; y2 D y0; y3 D y00; y4 D z; y5 D z0

7.7
Systems of Higher-Order Differential Equations
305
obtaining
8
ˆˆˆˆˆ<
ˆˆˆˆˆ:
y0
1 D y2
y0
2 D y3
y0
3 D f .x; y1; y2; y3; y4; y4/ D 3 sin.y1/ C ey3 C y5  y4
4 C ex
y0
4 D y5
y0
5 D y5  y4
1 C cos.x/
;
with the given initial conditions:
8
ˆˆˆˆˆ<
ˆˆˆˆˆ:
y1.1/ D 2
y2.1/ D 1
y3.1/ D 1
y4.1/ D 2
y5.1/ D 1
:
Next, we use the following Sage code to solve this problem:
#include the library
from sage.calculus.desolvers import desolve_system_rk4
#declare the variables
var(’y1 y2 y3 y4 y5 x’)
#solve the system of equations using Runge Kuta 4
P=desolve_system_rk4(
#specify the right hand side of each equation
[y2,
y3,
3*sin(y1)+e^(y3)+y5-y4^4+e^x,
y5,
y5-y1^4+cos(x)],
#specify the dependent variables
[y1, y2,
y3, y4, y5],
#specify the initial values for x, y1,y2,y3,y4,y5
ics=[1, -2, -1, 1, -2, -1],
#specify the independent variable
ivar=x,
#specify the value of h
step = 0.1,
#specify the value of b
end_points=1.5)
#print all the values
#
use
[ [x,y1, y2, y3, y4, y5] for x,y1,y2,y3,y4,y5 in P]
#
or use:
P

306
7
Numerical Methods for Differential Equations
and obtain
[[1, -2, -1, 1, -2, -1],
[1.1,
-2.09768745142,
-0.986702389997,
-0.917932774628,
-2.19078813367,
-2.90550714494],
[1.2,
-2.20579333122,
-1.235557241,
-4.48335702511,
-2.60089031308,
-5.41273066194],
[1.3,
-2.36209135572,
-2.02523868598,
-12.5863904403,
-3.30117637398,
-8.77701427303],
[1.4,
-2.65508219847,
-4.21179591097,
-35.5661928443,
-4.40665753611,
-13.7313684517],
[1.5,
-3.3436380293,
-10.8505196966,
-115.680182878,
-6.18228660237,
-23.213247068]]
Hence we conclude
y.1:5/ ' y1.1:5/ D 3:3436380293;
z.1:5/ ' y4.1:5/ D 6:18228660237:
If we use n D 100; hence using a step = 0.005, we would obtain
y.1:5/ ' y1.1:5/ D 3:34816700595;
z.1:5/ ' y4.1:5/ D 6:19246861798:

7.9
Exercises
307
7.8
An Application to Biology
In [4, p. 353] the author gives the following tumor growth model, based on the work given in [5]:
(
R0.t/ D  Si R
3 C
2
RCp
.R/2C4
R.0/ D a
;
(7.24)
where R.t/ is the radius of a tumor that is assumed to be spherical, Si the death rate of the cells at the
core of the tumor,  is the nutrient level, and  and  are scale parameters.
Assuming that Si D 0:90;  D 0:05; a D 0:25; and that  D 1 and  D 1; ﬁnd the radius of the
tumor R.2/:
Solution. Using the assumptions given, we need to solve for R.2/ from the following Initial Value
Problem
(
R0.t/ D 0:3R C
0:1
RC
p
R2C0:2
R.0/ D 0:25
:
For this, we can use Sage code similar to the one below
def PrintEuler(a,b,n,f, y0):
#GIVEN EARLIER IN THIS CHAPTER!
#set up the problem
a = 0; b = 2; n = 100
#our R is the y,
and t is the x
f(x,y) = -0.3*y+0.1/(y + sqrt(y*y+0.2))
y0 = 0.25
#call the function for Euler’s Method
PrintEuler(a,b,n,f, y0)
and obtain that at time t D 2; the tumor’s radius is R.2/ D 0:319065833427810:
Using similar code, one can obtain that R.8/ D 0:356036825570526:
7.9
Exercises
1. Using Euler’s Method, compute an approximate value for y.1/ for the differential equation
 y0 D y
y.0/ D 1
using n D 5 steps.
2. Using Euler’s Method, compute an approximate value for y.7/ for the differential equation
 y0 D y
y.6/ D 10
using n D 5 steps.

308
7
Numerical Methods for Differential Equations
3. Using Euler’s Method, compute an approximate value for y.10/ for the differential equation
 y0 D y2 C 4x  cos.y/
y.6/ D 10
using n D 5 steps.
4. Find the formulae for the Taylor Series Method with N D 4:
5. Find the formulae for the Taylor Series Method with N D 6:
6. Using Runge–Kutta’s Method of order 2, compute an approximate value for y.1/ for the
differential equation
 y0 D y2 C 4x  cos.y/
y.6/ D 10
using n D 5 steps. Also give the error of approximation for each node.
7. Using Runge–Kutta’s Method of order 4, compute an approximate value for y.1/ for the
differential equation
 y0 D y2 C 4x  cos.y/
y.6/ D 10
using n D 5 steps. Also give the error of approximation for each node.
8. Using Runge–Kutta’s Method of order 2, compute an approximate value for y.1/ for the
differential equation
 y0 D y
y.0/ D 1
using n D 5 steps. Also give the error of approximation for each node.
9. Using Runge–Kutta’s Method of order 4, compute an approximate value for y.1/ for the
differential equation
 y0 D y
y.0/ D 1
using n D 5 steps. Also give the error of approximation for each node.
10. For the following higher order differential equation
8
ˆˆ<
ˆˆ:
y000.x/ D cos.2y/ C sin.y0/  ey00 C x5
y.1/ D 4;
y0.1/ D 7;
y00.1/ D 2
ﬁnd the value of the solution y at x D 1:5; using Taylor series Method of order N D 2; with
n D 5 steps:
11. For the following higher order differential equation
8
ˆˆ<
ˆˆ:
y000.x/ D cos.2y/ C 3y0  ey00 C x2
y.0/ D 4;
y0.0/ D 7;
y00.0/ D 2
ﬁnd the value of the solution y at x D 2; using Taylor series Method of order N D 3; with n D 4
steps:

7.10
Computer Exercises
309
12. For the following system of higher order differential equations
8
ˆˆˆˆˆˆˆˆˆ<
ˆˆˆˆˆˆˆˆˆ:
y000.x/ D y00  z0 C ez  x
z00 D z  y  4.z0/2 C .y0/3 C 6y00 C 3x
y.0/ D 2;
y0.0/ D 7;
y00.0/ D 5
z.0/ D 2
z0.0/ D 4
ﬁnd the values of y; and z at x D 1:5; using Taylor series Method of order N D 3; with n D 5
steps:
7.10
Computer Exercises
1. Using Euler’s method, compute an approximate value for y.1/ for the differential equation
 y0 D y
y.0/ D 1
using n D 100 steps. Then graph its true solution and the table of values obtained from Euler’s
Method.
2. Using Euler’s method, compute an approximate value for y.1/ for the differential equation
 y0 D y
y.0/ D 1
using n D 100 steps. Output the table of values. In this table include a column computing the
error of approximation for each node.
3. Using Euler’s method, compute an approximate value for y.10/ for the differential equation
 y0 D arctan x
y.0/ D 0
using n D 100 steps. Then graph its true solution and the table of values obtained from Euler’s
Method.
4. Using Euler’s method, compute an approximate value for y.5/ for the differential equation
(
y0 D
2x
1Cx2  2y2
y.0/ D 0
using n D 100 steps. Then graph its true solution and the table of values obtained from Euler’s
Method.

310
7
Numerical Methods for Differential Equations
5. Using Euler’s method, compute an approximate value for y.4/ for the differential equation
(
y0 D x4
y
y.0/ D 1
using n D 100 steps. Then graph the table of values obtained from Euler’s Method. Find an
approximate value for y./:
6. Using Euler’s method, compute an approximate value for y.4/ for the differential equation
(
y0 D
2x
1Ce
p
x2sin x C 3 sin
ˇˇsin x C cosh x5ˇˇ
y.0/ D 1
using n D 100 steps. Then graph the table of values obtained from Euler’s Method.
7. Using Euler’s method, compute an approximate value for y.5/ for the differential equation
 cos.y0/  ejyj D ln.1 C x2/ C 7
y.3/ D 1
using n D 100 steps. Then graph the table of values obtained from Euler’s Method.
8. Write the Sage code implementation of the Taylor Series Method with N D 4: Then apply it to
ﬁnd y.2/ from the following differential equation
(
y0 D
2x
1Cx2  2y2
y.0/ D 0
with n D 10:
9. Write the Sage code implementation of the Taylor Series Method with N D 5. Then apply it to
ﬁnd y.2/ from the following differential equation
(
y0 D
2x
1Cx2  2y2
y.0/ D 0
with n D 50:
10. Implement the Sage code for Runge–Kutta’s Method of order 2 given by (7.19), on page 285.
11. Using Runge–Kutta’s Method of order 2, compute an approximate value for y.1/ for the
differential equation
 y0 D y2 C 4x  cos.y/
y.6/ D 10
using n D 100 steps. Also give the error of approximation for each node. Then plot the obtained
values.
12. Using Runge–Kutta’s Method of order 4, compute an approximate value for y.1/ for the
differential equation
 y0 D y2 C 4x  cos.y/
y.6/ D 10
using n D 100 steps. Also give the error of approximation for each node. Then plot the obtained
values.

References
311
13. Implement the Sage solution for the problem 148, given on page 294.
14. Implement Sage code for the following higher order differential equation
8
ˆˆ<
ˆˆ:
y000.x/ D cos.2y/ C sin.y0/  ey00 C x5
y.1/ D 4;
y0.1/ D 7;
y00.1/ D 2
to ﬁnd the value of the solution y at x D 1:5; using Taylor series Method of order N D 2; with
n D 50 steps:
15. Implement Sage code for the following higher order differential equation
8
ˆˆ<
ˆˆ:
y000.x/ D cos.2y/ C 3y0  ey00 C x2
y.0/ D 4;
y0.0/ D 7;
y00.0/ D 2
to ﬁnd the value of the solution y at x D 2; using Taylor series Method of order N D 3; with
n D 50 steps:
16. Implement the Sage solution for the problem 150, given on page 300.
17. Implement Sage code for the following system of higher order differential equations
8
ˆˆˆˆˆˆˆˆˆ<
ˆˆˆˆˆˆˆˆˆ:
y000.x/ D y00  z0 C ez  x
z00 D z  y  4.z0/2 C .y0/3 C 6y00 C 3x
y.0/ D 2;
y0.0/ D 7;
y00.0/ D 5
z.0/ D 2
z0.0/ D 4
to ﬁnd the values of y; and z at x D 1:5; using Taylor series Method of order N D 3; with n D 50
steps:
References
1. Atkinson, K., Han, W.: Elementary Numerical Analysis, 3rd edn. Wiley, New York (2003)
2. Blanco-Silva, F.J.: Learning SciPy for Numerical and Scientiﬁc Computing. Packt Publishing, Birmingham/Mumbai
(2013)
3. Cheney, W., Kincaid, D.: Numerical Mathematics and Computing, 7th edn. Brooks/Cole: Cengage Learning, Boston
(2013)
4. Epperson, J.F.: An Introduction to Numerical Methods and Analysis, revised edition. Wiley, Hoboken (2007)
5. Greenspan, H.P.: On the growth and stability of cell cultures and solid tumors. J. Theor. Biol. 56(1), 229–242 (1976)
6. Rivlin, T.J.: An Introduction to the Approximation of Functions. Dover, New York (2003)
7. Sage Cell Server: http://sagecell.sagemath.org/. Retrieved 2014
8. Stein, W.A., et al.: Sage mathematics software (Version 6.3). The sage development team. Sage Ofﬁcial Webpage:
http://www.sagemath.org (2014)
9. Stein, W.A.: Sage for power users. http://www.wstein.org/books/sagebook/sagebook.pdf (2012)
10. Sullivan, M., Miranda, K.: Calculus: Early Transcendentals. W. H. Freeman and Company, New York (2014)

Index
A
Absolute Error Formula, 20
Accuracy, 21
Accurate to n Decimal Places, 21
Accurate to n Signiﬁcant Digits, 21
Alternating Series Theorem, 56
Antiderivative, 175
B
Bankers’ Rounding, 24
Basic Simpson’s Rule, 188
Basic Trapezoidal Rule, 178
Big O Notation, 54
Bisection Method, 65
Body of a Function, 24
C
Central Difference Formula, 164
Chebyshev Nodes, 149
Chopped to n Digits, 23
Complete Cubic Splines, 241
Composite Simpson’s Rule, 190
Composite Trapezoidal Rule, 180
Composite Trapezoidal Rule with Evenly Spaced Nodes,
181
Cubic Equation, 65
Cubic Spline Function, 240
D
Deﬁnite Integral, 176
Derivative of a Function, 161
Differential Equation, 263
Directional Field, 265
Divided Differences, 134
E
Error Formula, 20
Euler’s Method, 267
Euler-MacLaurin Formula, 203
Evenly Spaced Nodes, 209
F
Fixed Point, 101
Fixed-Point Iteration, 101
Fundamental Theorem of Approximation Theorem, 37
Fundamental Theorem of Calculus, 175
G
Gaussian Quadrature Formula, 210
H
Header of the Function, 24
Heun’s Method, 285
Higher-Order Differential Equations, 294
I
Initial-Value Problems, 265
Interacts, 44
Intermediate Value Theorem, 65
Interpolation, 117
Interpolation Polynomial of Degree n, 123
L
Lagrange Basis Polynomials, 123
Lagrange Formula, 123
Legendre Polynomials, 214
Linear Equation, 65
Linear Interpolation, 118
Linear Spline Function, 230
Loop, 26
M
Maclaurin Series, 38
Mean-Value Theorem, 53
© Springer International Publishing Switzerland 2015
G.A. Anastassiou, R. Mezei, Numerical Analysis Using Sage, Springer Undergraduate
Texts in Mathematics and Technology, DOI 10.1007/978-3-319-16739-8
313

314
Index
Method of Undetermined Coefﬁcients, 167
Midpoint Method, 285
N
Natural Cubic Splines, 241
Natural Quadratic Spline, 235
Newton Algorithm, 129
Newton Formula, 129
Newton Interpolation Formula, 129
Newton Method, 76
Newton-Cotes Formula, 209
Newton-Raphson’s Method, 76
Newton’s Method Theorem, 82
Node, 117
Numerical Derivative, 161
O
Ordinary Differential Equation, 263
P
Partially Differential Equation, 263
Polygonal Line, 230
Polynomial, 37
Polynomial Interpolation, 117
Polynomial of Degree at most n, 118
Polynomial of Degree n, 118
Precision, 21
Print Method, 25
Propagated Error, 277
Q
Quadratic Equation, 65
Quadratic Function, 120
Quadratic Interpolation, 120
quadratic spline function, 234
Quadrature, 175
R
Range Method, 25
Relative Error Formula, 20
Richardson Extrapolation, 201
Romberg Integration Method, 205
Root of an Equation, 65
Rounded to n Digits, 23
Round-to-Even , 24
Round-to-Odd, 24
Runge Function, 144
Runge-Kutta’s Method, 284
Runge’s Phenomenon, 149
S
Sage Math, 2
Sage Interacts, 44
Secant Method, 90
Solution of an Equation, 65
T
Tab Space, 39
Taylor Polynomial, 37
Taylor Series, 37
Taylor Series Method, 279
Taylor’s Theorem with Remainder, 48
Truncation Error, 277
U
Unbiased Rounding, 24
W
Weierstrass Approximation Theorem, 37
Z
Zero of an Equation, 65

