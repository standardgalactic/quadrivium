Solutions to Selected Exercises
for
Braun and Murdoch’s
A First Course in Statistical Programming with R, 3rd edition
Kristy Alexander, Yiwen Diao, Qiang Fu, and Yu Han
W. John Braun and Duncan J. Murdoch
September 1, 2021

Chapter 2
Introduction to the R Language
2.1
First steps
1. 170166719 %% 31079
## [1] 9194
3. round(2000*(1.03^(1:30) - 1), 2)
##
[1]
60.00
121.80
185.45
251.02
318.55
388.10
459.75
533.54
609.55
## [10]
687.83
768.47
851.52
937.07 1025.18 1115.93 1209.41 1305.70 1404.87
## [19] 1507.01 1612.22 1720.59 1832.21 1947.17 2065.59 2187.56 2313.18 2442.58
## [28] 2575.86 2713.13 2854.52
5. r <- 7
area <- pi * r^2
area
## [1] 153.938
7. 48:(14*3)
## [1] 48 47 46 45 44 43 42
48:14*3
##
[1] 144 141 138 135 132 129 126 123 120 117 114 111 108 105 102
99
96
93
90
## [20]
87
84
81
78
75
72
69
66
63
60
57
54
51
48
45
42
Yes, the parentheses are necessary, because the : has higher priority than the *, and in the second
case the sequence is multiplied by 3.
2.3
Vectors in R
2

2.3. VECTORS IN R
3
1.
(a) r <- 1.08
n <- c(10, 20, 30, 40)
sum1 <- c()
for(i in n){
x <- 0:i
sum1 <- c(sum1, sum(r^x))
}
sum1
## [1]
16.64549
50.42292 123.34587 280.78104
This gives the calculated sums for n = 10, 20, 30, 40.
sum2 <- (1 - r^(n + 1)) / (1 - r)
sum2
## [1]
16.64549
50.42292 123.34587 280.78104
sum2 - sum1
## [1] 0 0 0 0
The formula works.
3.
(a) n <- 100
sum(1:n)
## [1] 5050
(n * (n + 1)) / 2
## [1] 5050
(c) n <- 400
sum(1:n)
## [1] 80200
(n * (n + 1)) / 2
## [1] 80200
7.
(a) N <- 500
sum(1/(1:N))
## [1] 6.792823
sum(1/(1:N)) - (log(N) + 0.6)
## [1] -0.02178467
(c) N <- 2000
sum(1/(1:N))
## [1] 8.178368
sum(1/(1:N)) - (log(N) + 0.6)
## [1] -0.02253436

4
CHAPTER 2. INTRODUCTION TO THE R LANGUAGE
(e) N <- 8000
sum(1/(1:N))
## [1] 9.564475
sum(1/(1:N)) - (log(N) + 0.6)
## [1] -0.02272184
8.
(a) rep( 0:4, rep(5,5))
##
[1] 0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4
10. x <- rep( c(rep(0, 3), rep(1, 4)), 5)
x
##
[1] 0 0 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 1 1 1 1
x <- as.factor(x)
levels(x) <- c("Male", "Female")
x
##
[1] Male
Male
Male
Female Female Female Female Male
Male
Male
## [11] Female Female Female Female Male
Male
Male
Female Female Female
## [21] Female Male
Male
Male
Female Female Female Female Male
Male
## [31] Male
Female Female Female Female
## Levels: Male Female
11. more.colors <- c("red","yellow","blue","green","magenta","cyan")
more.colors[rep( seq(1,3), times = 4) + rep( seq(0,3), each=3)]
##
[1] "red"
"yellow"
"blue"
"yellow"
"blue"
"green"
"blue"
##
[8] "green"
"magenta" "green"
"magenta" "cyan"
2.4
Data storage in R
1.
(a) To ﬁnd binary expansions, use the method described in section 2.4.1.
x <- 6/7
2*x
## [1] 1.714286
x <- 2*x - 1
2*x
## [1] 1.428571
x <- 2*x - 1
2*x
## [1] 0.8571429

2.4. DATA STORAGE IN R
5
x <- 2*x
2*x
## [1] 1.714286
Thus the ﬁrst 4 binary digits for 6/7 are 0.1101.
(b) Similarly, 1/7 in binary is 0.0010.
(c) Adding these gives 0.1111, which corresponds to
sum(2^(-(1:4)))
## [1] 0.9375
(d) The correct answer using exact arithmetic is 1; using only 4 binary digits gives us an error of
sum(2^(-(1:4))) - 1
## [1] -0.0625
3. k <- 1:4
2^52 + k - 2^52
## [1] 1 2 3 4
2^53 + k - 2^53
## [1] 0 2 4 4
2^54 + k - 2^54
## [1] 0 0 4 4
We are right at the borderline of accuracy for double precision ﬂoating point. The ﬁrst expression is
done accurately, the other two suﬀer rounding error.
The result would be correct if done in a diﬀerent order, e.g.
2^52
- 2^52 + k
## [1] 1 2 3 4
2^53
- 2^53 + k
## [1] 1 2 3 4
2^54
- 2^54 + k
## [1] 1 2 3 4
5. R guesses the century correctly.
6. R understands calendar dates.

6
CHAPTER 2. INTRODUCTION TO THE R LANGUAGE
2.7
Useful R features
2.7.2
Some elementary built-in functions
1.
(a) solar.radiation <- c(11.1,10.6,6.3,8.8,10.7,11.2,8.9,12.2)
(b) mean(solar.radiation)
## [1] 9.975
median(solar.radiation)
## [1] 10.65
range(solar.radiation)
## [1]
6.3 12.2
var(solar.radiation)
## [1] 3.525
(c)
i. sr10 <- solar.radiation + 10
ii. mean(sr10)
## [1] 19.975
median(sr10)
## [1] 20.65
range(sr10)
## [1] 16.3 22.2
var(sr10)
## [1] 3.525
iii. The mean, median and both ends of the range are increased by 10. The variance remains
unchanged.
2. n <- 1:15
sum(pmin(2^n, n^3))
## [1] 13396
2.8
Logical vectors and relational operators
1. n <- 1:15
2^n > n^3
##
[1]
TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
TRUE
TRUE
TRUE
## [13]
TRUE
TRUE
TRUE

2.9. DATA FRAMES, TIBBLES AND LISTS
7
4.
(a) !(A & B) == (!A)|(!B)
The event that A and B are not both true is the same as the event that either A is not true or
B is not true.
The statement ”There is no sun shower” is equivalent to the statement ”Either the sky is not
clear or it is not raining”.
Truth Table to confirm that !(A & B) == (!A)|(!B)
A
B
not (A and B)
(not A) or (not B)
True
True
False
False
True
False
True
True
False
True
True
True
False
False
True
True
This implies that they are equivalent.
6. Use the && operator:
testValue <- 7
(testValue > 0) && (sqrt(testValue) < 5)
## [1] TRUE
testValue <- -7
(testValue > 0) && (sqrt(testValue) < 5)
## [1] FALSE
2.9
Data Frames, Tibbles and Lists
1.
(a) Formaldehyde[3,]
##
carb optden
## 3
0.5
0.446
(b) Formaldehyde[, "carb"]
## [1] 0.1 0.3 0.5 0.6 0.7 0.9
(c) plot(optden ~ carb, data = Formaldehyde)

8
CHAPTER 2. INTRODUCTION TO THE R LANGUAGE
0.2
0.4
0.6
0.8
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
carb
optden
It appears to be a linear relationship.
2.10
Data Input and Output
2.10.2
dump() and source()
3. numbers <- c(3,5,8,10,12)
dump( "numbers", file = "numbers.R")
rm(numbers)
ls()
# numbers should not appear in the resulting listing
##
[1] "A"
"B"
"FV"
"N"
##
[5] "a"
"ans"
"area"
"b"
##
[9] "formula"
"i"
"intRate"
"interest"
## [13] "k"
"more.colors"
"n"
"payment"
## [17] "principal"
"r"
"solar.radiation" "sr10"
## [21] "srm2"
"sum1"
"sum2"
"sums"
## [25] "testValue"
"values"
"vp"
"vp1"
## [29] "x"
numbers
## Error in eval(expr, envir, enclos):
object ’numbers’ not found

2.10. DATA INPUT AND OUTPUT
9
source("numbers.R")
ls()
# numbers should now appear in the resulting listing
##
[1] "A"
"B"
"FV"
"N"
##
[5] "a"
"ans"
"area"
"b"
##
[9] "formula"
"i"
"intRate"
"interest"
## [13] "k"
"more.colors"
"n"
"numbers"
## [17] "payment"
"principal"
"r"
"solar.radiation"
## [21] "sr10"
"srm2"
"sum1"
"sum2"
## [25] "sums"
"testValue"
"values"
"vp"
## [29] "vp1"
"x"
numbers
## [1]
3
5
8 10 12
2.10.5
The read.table function
1. Creating pretend.df:
x <- c(61,175,111,124)
y <- c(13,21,24,23)
z <- c(4,18,14,18)
pretend.df <- cbind(x,y,z)
pretend.df <- data.frame(pretend.df)
pretend.df
##
x
y
z
## 1
61 13
4
## 2 175 21 18
## 3 111 24 14
## 4 124 23 18
Displaying the item:
pretend.df[ 1, 3]
## [1] 4
Chapter exercises
1. 11^2
## [1] 121
111^2
## [1] 12321
1111^2

10
CHAPTER 2. INTRODUCTION TO THE R LANGUAGE
## [1] 1234321
save <- options(digits = 18)
11111111^2
## [1] 123456787654321
111111111^2
## [1] 12345678987654320
options(save)
The ﬁnal answer is wrong in the last digit due to rounding error.
3.
(a) chickwts300p <- subset(chickwts, weight > 300)
(b) chickwtslinseed <- subset(chickwts, feed == "linseed")
(c) mean(chickwtslinseed$weight)
## [1] 218.75
(d) mean(subset(chickwts, feed != "linseed")$weight)
## [1] 269.9661
5. rain.df <-read.table("http://www.statprogr.science/data/rnf6080.dat",
header = FALSE, na.strings = "-999")
(a) rain.df[ 2, 4]
## [1] 0
(b) names(rain.df)
##
[1] "V1"
"V2"
"V3"
"V4"
"V5"
"V6"
"V7"
"V8"
"V9"
"V10" "V11" "V12"
## [13] "V13" "V14" "V15" "V16" "V17" "V18" "V19" "V20" "V21" "V22" "V23" "V24"
## [25] "V25" "V26" "V27"
(c) rain.df[ 2, ]
##
V1 V2 V3 V4 V5 V6 V7 V8 V9 V10 V11 V12 V13 V14 V15 V16 V17 V18 V19 V20 V21
## 2 60
4
2
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
##
V22 V23 V24 V25 V26 V27
## 2
0
0
0
0
0
0

2.10. DATA INPUT AND OUTPUT
11
(e) rain.df$daily <- rowSums(rain.df[ , 4:27], na.rm=TRUE)
7.
(a) dieRolls <- sample(1:6, 1000000, replace = TRUE)
(b) dieRollsFactor <- factor(dieRolls)
levels(dieRollsFactor) <- c("One", "Two", "Three", "Four", "Five", "Six")
(c) dieRollsChar <- as.character(dieRollsFactor)
(d) table(dieRolls)
## dieRolls
##
1
2
3
4
5
6
## 166328 166787 167470 166847 166826 165742
table(dieRollsFactor)
## dieRollsFactor
##
One
Two
Three
Four
Five
Six
## 166328 166787 167470 166847 166826 165742
table(dieRollsChar)
## dieRollsChar
##
Five
Four
One
Six
Three
Two
## 166826 166847 166328 165742 167470 166787
(e) system.time(table(dieRolls))
##
user
system elapsed
##
0.068
0.007
0.075
system.time(table(dieRollsFactor))
##
user
system elapsed
##
0.023
0.000
0.023
system.time(table(dieRollsChar))
##
user
system elapsed
##
0.069
0.002
0.072
9. char <- c("2", "1", "0")
num <- 0:2
charnum <- data.frame(char, num, stringsAsFactors = TRUE)
as.numeric(char)
## [1] 2 1 0
as.numeric(charnum$char)
## [1] 3 2 1

12
CHAPTER 2. INTRODUCTION TO THE R LANGUAGE
In the data frame, the char column is a factor, so we see the indices of the factor levels rather than
conversions of the strings.

Chapter 3
Programming statistical graphics
3.1
Simple High Level Plots
1.
(a) par(mfrow=c(2,2))
hist(islands, breaks = "Sturges", main = "Sturges")
hist(islands, breaks = "Scott", main = "Scott")
hist(log(islands), breaks = "Sturges", main = "Sturges on log scale")
hist(log(islands), breaks = "Scott", main = "Scott on log scale")
Sturges
islands
Frequency
0
5000
10000
15000
0
20
40
Scott
islands
Frequency
0
5000
15000
0
20
40
Sturges on log scale
log(islands)
Frequency
2
4
6
8
10
0
5
10
Scott on log scale
log(islands)
Frequency
2
4
6
8
10
0
10
20
30
13

14
CHAPTER 3. PROGRAMMING STATISTICAL GRAPHICS
(c) par(mfrow=c(1,2))
boxplot(islands, main = "Original scale")
boxplot(log(islands), main = "Log scale")
0
5000
10000
15000
Original scale
4
6
8
10
Log scale
(d) par(mfrow=c(1,2))
dotchart(islands,main="Original scale")
dotchart(log(islands),main="Log scale")

3.1. SIMPLE HIGH LEVEL PLOTS
15
Africa
Antarctica
Asia
Australia
Axel Heiberg
Baffin
Banks
Borneo
Britain
Celebes
Celon
Cuba
Devon
Ellesmere
Europe
Greenland
Hainan
Hispaniola
Hokkaido
Honshu
Iceland
Ireland
Java
Kyushu
Luzon
Madagascar
Melville
Mindanao
Moluccas
New Britain
New Guinea
New Zealand (N)
New Zealand (S)
Newfoundland
North America
Novaya Zemlya
Prince of Wales
Sakhalin
South America
Southampton
Spitsbergen
Sumatra
Taiwan
Tasmania
Tierra del Fuego
Timor
Vancouver
Victoria
0
5000
10000
15000
Original scale
Africa
Antarctica
Asia
Australia
Axel Heiberg
Baffin
Banks
Borneo
Britain
Celebes
Celon
Cuba
Devon
Ellesmere
Europe
Greenland
Hainan
Hispaniola
Hokkaido
Honshu
Iceland
Ireland
Java
Kyushu
Luzon
Madagascar
Melville
Mindanao
Moluccas
New Britain
New Guinea
New Zealand (N)
New Zealand (S)
Newfoundland
North America
Novaya Zemlya
Prince of Wales
Sakhalin
South America
Southampton
Spitsbergen
Sumatra
Taiwan
Tasmania
Tierra del Fuego
Timor
Vancouver
Victoria
4
6
8
10
Log scale
The log scale separates the islands better.
(e) This depends on the use; the ones we like best are the Sturges histogram on the log scale, and
the dot chart on the log scale.
The latter would be improved by sorting on size instead of
alphabetically:
dotchart(sort(log(islands)), main = "Log scale, sorted")

16
CHAPTER 3. PROGRAMMING STATISTICAL GRAPHICS
Vancouver
Hainan
Prince of Wales
Timor
Kyushu
Taiwan
New Britain
Spitsbergen
Axel Heiberg
Melville
Southampton
Tierra del Fuego
Devon
Banks
Celon
Tasmania
Moluccas
Sakhalin
Hispaniola
Hokkaido
Novaya Zemlya
Ireland
Mindanao
Iceland
Luzon
Cuba
Newfoundland
New Zealand (N)
Java
New Zealand (S)
Celebes
Ellesmere
Victoria
Britain
Honshu
Sumatra
Baffin
Madagascar
Borneo
New Guinea
Greenland
Australia
Europe
Antarctica
South America
North America
Africa
Asia
4
6
8
10
Log scale, sorted

3.1. SIMPLE HIGH LEVEL PLOTS
17
3.
(a) plot(pressure ~ temperature, data = pressure)
0
50
100
150
200
250
300
350
0
200
400
600
800
temperature
pressure
(c) plot(pressure^(3/20) ~ temperature, data = pressure)

18
CHAPTER 3. PROGRAMMING STATISTICAL GRAPHICS
0
50
100
150
200
250
300
350
0.5
1.0
1.5
2.0
2.5
temperature
pressure^(3/20)
3.3
Low level graphics functions
2. plot(circumference ~ age, pch = as.numeric(as.character(Tree)),
data = Orange)
lines(circumference ~ age, data = Orange, subset = Tree == "1", lty = 1)
lines(circumference ~ age, data = Orange, subset = Tree == "2", lty = 2)
lines(circumference ~ age, data = Orange, subset = Tree == "3", lty = 3,
lwd = 2)
lines(circumference ~ age, data = Orange, subset = Tree == "4", lty = 4)
lines(circumference ~ age, data = Orange, subset = Tree == "5", lty = 5)
legend("bottomright", legend = paste("Tree", 1:5), lty=1:5, pch = 1:5)

3.3. LOW LEVEL GRAPHICS FUNCTIONS
19
500
1000
1500
50
100
150
200
age
circumference
Tree 1
Tree 2
Tree 3
Tree 4
Tree 5
3. par(list = list(mfrow = c(3, 2), mar = c(2.1,2.1,4.1,0.1)))
Z <- rnorm(1000)
hist(Z, main = "Histogram-Sturges")
hist(Z, breaks = "Freedman-Diaconis", main = "Histogram-FD")
plot(density(Z), main = "Density Estimate")
boxplot(Z, main = "Boxplot")
qqnorm(Z, main = "QQ Plot"); qqline(Z)
ts.plot(Z, main = "Trace Plot")

20
CHAPTER 3. PROGRAMMING STATISTICAL GRAPHICS
Histogram−Sturges
−4
−2
0
2
0
50
100
150
200
Histogram−FD
−4
−2
0
2
0
20
40
60
80
−4
−2
0
2
4
0.0
0.1
0.2
0.3
0.4
Density Estimate
−4
−2
0
2
Boxplot
−3
−2
−1
0
1
2
3
−4
−2
0
2
QQ Plot
Trace Plot
0
200
400
600
800
1000
−4
−2
0
2

3.4. GRAPHICS AS A LANGUAGE: GGPLOT2
21
3.4
Graphics as a Language: ggplot2
1. library(ggplot2)
landmasses <- data.frame(area = log(1000*islands, 10))
ggplot(landmasses, aes(area)) +
geom_histogram(binwidth=.5)
0
5
10
15
4
5
6
7
area
count
ggplot(landmasses, aes(area)) +
geom_histogram(binwidth=.5, boundary=TRUE)

22
CHAPTER 3. PROGRAMMING STATISTICAL GRAPHICS
0
5
10
15
20
4
5
6
7
area
count
3.
(a) library(DAAG)
ggplot(cuckoos, aes(y = breadth, x = length)) +
geom_jitter()

3.4. GRAPHICS AS A LANGUAGE: GGPLOT2
23
15.0
15.5
16.0
16.5
17.0
17.5
20
21
22
23
24
25
length
breadth
Chapter exercises
1.
(a) hist(log(islands, 10), breaks = "Scott", axes = FALSE, xlab = "area",
main = "Histogram of Island Areas")
axis(1, at = 1:5, labels = 10^(1:5))
axis(2)
box()

24
CHAPTER 3. PROGRAMMING STATISTICAL GRAPHICS
Histogram of Island Areas
area
Frequency
10
100
1000
10000
1e+05
0
5
10
15
20
25
30
35
(c) hist(log(islands, 10), breaks = "Sturges", axes = FALSE,
xlab = "area", main = "Histogram of Island Areas")
axis(1, at=1:5, labels = 10^(1:5))
axis(2)
box()

3.4. GRAPHICS AS A LANGUAGE: GGPLOT2
25
Histogram of Island Areas
area
Frequency
10
100
1000
10000
0
5
10
15
20
The note about round() in the question is incorrect.
3. library(lattice)
xyplot(circumference ~ age | Tree, data = Orange)

26
CHAPTER 3. PROGRAMMING STATISTICAL GRAPHICS
age
circumference
50
100
150
200
500
1000
1500
3
1
500
1000
1500
5
2
500
1000
1500
50
100
150
200
4
4. wind2D <- function(x,y) a1*a2*exp(-x^a1/b2 -
y^a2/(b0+b1*x))*x^(a1-1)*y^(a2-1)/(b2*(b0+b1*x))
library(rgl)
a1 <- 3/2; a2 <- 5/3; b0 <- 108; b1 <- 5.3; b2 <- 65
persp3d(wind2D, xlim = c(0,50), ylim = c(0, 60), polygon_offset = 1)

3.4. GRAPHICS AS A LANGUAGE: GGPLOT2
27
60
50
40
y
30
20
0
x
10
0
10
20
0
30
0.0005
40
0.001
0.0015
50
wind2D
(a) persp3d(wind2D, xlim = c(0,50), ylim = c(0, 60), polygon_offset = 1,
front = "lines", col = "lightgreen", alpha = 0.5)

28
CHAPTER 3. PROGRAMMING STATISTICAL GRAPHICS
60
50
40
y
30
20
10
wind2D
0
10
0
20
30
40
0
50
0.0005
0.001
0.0015
x

Chapter 4
Programming with R
4.1
Flow control
4.1.1
The for() loop
1.
(a) Fibonacci <- numeric(12)
Fibonacci[1] <- 2
Fibonacci[2] <- 2
for (i in 3:12) Fibonacci[i] <- Fibonacci[i-2] + Fibonacci[i-1]
Fibonacci
##
[1]
2
2
4
6
10
16
26
42
68 110 178 288
(c) Fibonacci <- numeric(12)
Fibonacci[1] <- Fibonacci[2] <- 1
for (i in 3:12) Fibonacci[i] <- Fibonacci[i-1] - Fibonacci[i-2]
Fibonacci
##
[1]
1
1
0 -1 -1
0
1
1
0 -1 -1
0
3.
(a) answer <- 0
for (j in 1:5) answer <- answer + j
answer
## [1] 15
(b) answer <- NULL
for (j in 1:5) answer <- c(answer, j)
answer
## [1] 1 2 3 4 5
(c) answer <- 0
for (j in 1:5) answer <- c(answer, j)
answer
## [1] 0 1 2 3 4 5
29

30
CHAPTER 4. PROGRAMMING WITH R
(d) answer <- 1
for (j in 1:5) answer <- answer * j
answer
## [1] 120
(e) answer <- 3
for (j in 1:15) answer <- c(answer, (7 * answer[j]) %% 31)
answer
##
[1]
3 21 23
6 11 15 12 22 30 24 13 29 17 26 27
3
5. x <- 0.5
count <- 0
while(abs(x - cos(x)) > 0.01){
x <- cos(x)
count <- count + 1
}
count
## [1] 10
x <- 0.5
count <- 0
while(abs(x - cos(x)) > 0.001){
x <- cos(x)
count <- count + 1
}
count
## [1] 15
x <- 0.5
count <- 0
while(abs(x - cos(x)) > 0.0001){
x <- cos(x)
count <- count + 1
}
count
## [1] 21
x <- 0.7
count <- 0
while(abs(x - cos(x))>0.0001){
x <- cos(x)
count <- count + 1
}
count
## [1] 17

4.1.
FLOW CONTROL
31
x <- 0.0
count <- 0
while(abs(x - cos(x)) > 0.0001){
x <- cos(x)
count <- count + 1
}
count
## [1] 23
4.1.2
The if() statement
1. Yes, the function will work properly when n is not an integer.
4. GIC <- function(P, n) {
if (n<=3)
i <- 0.04
else
i <- 0.05
P * ((1 + i)^n - 1)
}
4.1.3
The while() loop
1. Fib1 <- 1
Fib2 <- 1
Fibonacci <- c(Fib1, Fib2)
while (Fib1 < 300) {
Fibonacci <- c(Fibonacci, Fib2)
Fib2 <- Fib1 + Fib2
Fib1 <- max(Fibonacci)
}
print(Fibonacci)
##
[1]
1
1
1
2
3
5
8
13
21
34
55
89 144 233 377
3. Fibonacci <- c(1, 1, 1)
while (max(Fibonacci) < 1000000){
Fibonacci <- c(Fibonacci, Fibonacci[length(Fibonacci)] +
Fibonacci[length(Fibonacci) - 1])
}
sum(Fibonacci < 1000000)
## [1] 31
4.1.4
Newton’s method for root ﬁnding

32
CHAPTER 4. PROGRAMMING WITH R
1. x <- 0
f <- x^7 + 10000*x^6 + 1.06 * x^5 + 10600*x^4 + 0.0605 * x^3 +
605 * x^2 + 0.0005 *x + 5
tolerance <- 0.000001
count <- 0
while (abs(f) > tolerance){
f.prime <- 7*x^6 + 6*10000*x^5 + 5*1.06*x^4 + 4*10600*x^3 + 3*0.0605*x^2 +
2*605*x + 0.0005
x <- x - f/f.prime
f <- x^7 + 10000*x^6 + 1.06*x^5 + 10600*x^4 + 0.0605*x^3 +
605*x^2 + 0.0005*x + 5
count <- count + 1
}
count
## [1] 1
3. x <- -1.5
f <- cos(x) + exp(x)
tolerance <- 0.000001
while (abs(f) > tolerance){
f.prime <- -sin(x) - 1/x
x <- x - f/f.prime
f <- cos(x) + exp(x)
}
x
## [1] -1.746139
5. The function has only one zero which is x = 0.6. For initial guess 0.5, 0.75 and 0.2, Newton’s method
gives a solution that approaches x = 1. For initial guess 1.25, the method does not converge.
7. i <- 0.006
count <- 0
f <- (1- (1 + i)^(-20))/19 - i
tolerance <- 0.000001
while (abs(f) > tolerance){
f.prime <- (20/19)*((1 + i)^(-21))-1
i <- i - f/f.prime
f <- (1 - (1 + i)^(-20))/19 - i
count <- count+1
}
i
## [1] 0.004939979
count
## [1] 2

4.2. MANAGING COMPLEXITY THROUGH FUNCTIONS
33
4.1.5
The repeat loop, and the break and next statements
1.
(a) x1 <- 0
x2 <- 2
repeat{
f1 <- x1^3 + 2*x1^2 - 7
f2 <- x2^3 + 2*x2^2 - 7
x3 <- (x1 + x2)/2
f3 <- x3^3 + 2*x3^2 - 7
if(f3==0){
print(x3)
break
} else {
if (f3*f1 > 0) {
x1 <- x3
} else {
x2 <- x3
}
}
if(abs(x1 - x2) < 0.000001){
print((x1 + x2)/2)
break
}
}
## [1] 1.428817
4.2
Managing complexity through functions
4.2.1
What are functions?
1. Call typeof or str or just type in the function names on each:
typeof(var)
## [1] "closure"
str(cos)
## function (x)
median
## function (x, na.rm = FALSE, ...)
## UseMethod("median")
## <bytecode: 0x7f92ec17f4d0>
## <environment: namespace:stats>
typeof(read.table)
## [1] "closure"
str(dump)
## function (list, file = "dumpdata.R", append = FALSE, control = "all", envir = parent.frame(),
##
evaluate = TRUE)

34
CHAPTER 4. PROGRAMMING WITH R
Note that functions are usually listed as type “closure”.
3. bisection <- function(f, x1, x2) {
repeat{
f1 <- f(x1)
f2 <- f(x2)
x3 <- (x1 + x2)/2
f3 <- f(x3)
if(f3 == 0) {
return(x3)
} else {
if (f3*f1 > 0) {
x1 <- x3
} else {
x2 <- x3
}
}
if (abs(x1 - x2) < 0.000001) {
return((x1 + x2)/2)
}
}
}
bisection(function(x) cos(x) - 0.5, 0, pi)
## [1] 1.047198
4.4
Miscellaneous Programming tips
1. factorial(10)
## [1] 3628800
factorial(50)
## [1] 3.041409e+64
factorial(100)
## [1] 9.332622e+157
factorial(1000)
## [1] Inf
3. compound.interest <- function(P, j, m, n){
i.r <- j/m
P*(1+i.r)^(n*m)
}

4.5.
SOME GENERAL PROGRAMMING GUIDELINES
35
5.
(a) mortgage.payment <- function(P, i.r, n)
P*i.r/(1 - (1 + i.r)^(-n))
4.5
Some general programming guidelines
4.5.1
Top-down design
1. mergesort <- function (x, decreasing = FALSE) {
len <- length(x)
if (len < 2) result <- x
else {
y <- x[1:(len %/% 2)]
z <- x[(len %/% 2 + 1):len]
y <- mergesort(y, decreasing)
z <- mergesort(z, decreasing)
result <- c()
while (min(length(y), length(z)) > 0) {
if ((!decreasing && y[1] < z[1]) ||
(decreasing && y[1] > z[1])) {
result <- c(result, y[1])
y <- y[-1]
} else {
result <- c(result, z[1])
z <- z[-1]
}
}
if (length(y) > 0)
result <- c(result, y)
else
result <- c(result, z)
}
return(result)
}
x <- c(1:5, 10:6)
mergesort(x)
##
[1]
1
2
3
4
5
6
7
8
9 10
mergesort(x, decreasing = TRUE)
##
[1] 10
9
8
7
6
5
4
3
2
1
4.6
Debugging and maintenance
4.6.7
The browser(), debug(), and debugonce() functions
1. We’ll modify the function to print values as it runs:
mergesort <- function (x) {
cat("x = "); print(x)

36
CHAPTER 4. PROGRAMMING WITH R
len <- length(x)
if (len < 2) result <- x
else {
y <- x[1:(len %/% 2)]
z <- x[(len %/% 2 + 1):len]
cat("y = "); print(y)
cat("z = "); print(z)
y <- mergesort(y)
z <- mergesort(z)
result <- c()
while (min(length(y), length(z)) > 0) {
if (y[1] < z[1]) {
result <- c(result, y[1])
y <- y[-1]
} else {
result <- c(result, z[1])
z <- z[-1]
}
}
if (length(y) > 0)
result <- c(result, y)
else
result <- c(result, z)
}
return(result)
}
mergesort(c(3, 5, 4, 2))
## x = [1] 3 5 4 2
## y = [1] 3 5
## z = [1] 4 2
## x = [1] 3 5
## y = [1] 3
## z = [1] 5
## x = [1] 3
## x = [1] 5
## x = [1] 4 2
## y = [1] 4
## z = [1] 2
## x = [1] 4
## x = [1] 2
## [1] 2 3 4 5
Chapter Exercises
1. # RANDU exercise from programming.Rnw
n <- 3000000
results <- numeric(n)
x <- 123
for (i in 1:n) {

4.6. DEBUGGING AND MAINTENANCE
37
x <- (65539*x) %% (2^31)
results[i] <- x / (2^31)
}
m <- matrix(round(results, 3), ncol = 3, byrow = TRUE)
keep <- m[,1] == 0.1
plot(m[keep, 2], m[keep, 3])
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
m[keep, 2]
m[keep, 3]
par(mfrow = c(3, 3))
for (i in 1:9) {
keep <- m[,1] == round(i/10, 3)
plot(m[keep, 2], m[keep, 3], main=paste("x = ", i/10))
}

38
CHAPTER 4. PROGRAMMING WITH R
0.0
0.4
0.8
0.0
0.4
0.8
x =  0.1
m[keep, 2]
m[keep, 3]
0.0
0.4
0.8
0.0
0.4
0.8
x =  0.2
m[keep, 2]
m[keep, 3]
0.0
0.4
0.8
0.0
0.4
0.8
x =  0.3
m[keep, 2]
m[keep, 3]
0.0
0.4
0.8
0.0
0.4
0.8
x =  0.4
m[keep, 2]
m[keep, 3]
0.0
0.4
0.8
0.0
0.4
0.8
x =  0.5
m[keep, 2]
m[keep, 3]
0.0
0.4
0.8
0.0
0.4
0.8
x =  0.6
m[keep, 2]
m[keep, 3]
0.0
0.4
0.8
0.0
0.4
0.8
x =  0.7
m[keep, 2]
m[keep, 3]
0.0
0.4
0.8
0.0
0.4
0.8
x =  0.8
m[keep, 2]
m[keep, 3]
0.0
0.4
0.8
0.0
0.4
0.8
x =  0.9
m[keep, 2]
m[keep, 3]
2. directpoly <- function(x, coef){
n <- length(coef)
result <- 0
for(i in seq_len(n)){
result <- result + coef[i]*x^(n-i)
}
result
}
3. hornerpoly <- function(x, coef){
n <- length(coef)
a <- rep(coef[1], length(x))
for(i in rev(seq_len(n-1))) {
a <- a*x + coef[n - i + 1]
}

4.6. DEBUGGING AND MAINTENANCE
39
a
}
4.
(a) library(microbenchmark)
microbenchmark(directpoly(x = seq(-10, 10, length = 5000000),
c(1, -2, 2, 3, 4, 6, 7)),
hornerpoly(x = seq(-10, 10, length = 5000000),
c(1, -2, 2, 3, 4, 6, 7)))
## Unit: milliseconds
##
expr
##
directpoly(x = seq(-10, 10, length = 5e+06), c(1, -2, 2, 3, 4,
6, 7))
##
hornerpoly(x = seq(-10, 10, length = 5e+06), c(1, -2, 2, 3, 4,
6, 7))
##
min
lq
mean
median
uq
max neval cld
##
925.5204 930.8662 942.3311 934.6454 938.9728 1181.5203
100
b
##
195.3395 198.2386 202.6118 200.1129 202.7350
311.4089
100
a
6.
(a) microbenchmark({
x1 <- 2.1
x2 <- 3.1
repeat{
f1 <- (x1-3)*exp(-x1)
f2 <- (x2-3)*exp(-x2)
x3 <- (x1+x2)/2
f3 <- (x3-3)*exp(-x3)
if(f3==0){
break
}else{
if(f3*f1>0){
x1 <- x3
}else{
x2 <- x3
}
}
if(abs(x1-x2)<0.0000001){
break
}
}
})
## Unit: milliseconds
##
##
{
x1 <- 2.1
x2 <- 3.1
repeat {
f1 <- (x1 - 3) * exp(-x1)
f2 <-
##
min
lq
mean
median
uq
max neval
##
12.06189 15.46662 16.05128 15.92132 16.26 24.0204
100
(b) microbenchmark({
x1 <- 2.1
x2 <- 3.1
repeat{
f1 <- (x1^2 -6*x1 +9)*exp(-x1)
f2 <- (x2^2 -6*x2 +9)*exp(-x2)

40
CHAPTER 4. PROGRAMMING WITH R
x3 <- (x1+x2)/2
f3 <- (x3^2 -6*x3 +9)*exp(-x3)
if(f3==0){
break
}else{
if(f3*f1>0){
x1 <- x3
}else{
x2 <- x3
}
}
if(abs(x1-x2)<0.0000001){
break
}
}
})
## Unit: milliseconds
##
##
{
x1 <- 2.1
x2 <- 3.1
repeat {
f1 <- (x1^2 - 6 * x1 + 9) * exp(-x1)
##
min
lq
mean
median
uq
max neval
##
16.44497 19.42453 20.59897 20.02202 21.81349 28.21682
100
8. library(grid)
b1 <- sqrt(1/cos(36*pi/180)^2-1)/2
b2 <- sin(72*pi/180)/(2*(1+cos(72*pi/180))) - (1-sin(72*pi/180))/2
triangle <- polygonGrob(c(0,.5,1), c(b2,b2+b1,b2),
name = "triangle", gp = gpar(fill = "yellow", col = 0))
grid.draw(triangle) # nothing appears until this line is executed

4.6. DEBUGGING AND MAINTENANCE
41
for (i in 0:2) {
pushViewport(vp=viewport(angle=72*i))
grid.draw(triangle)
upViewport()
}

42
CHAPTER 4. PROGRAMMING WITH R

Chapter 6
Simulation
6.2
Generation of pseudorandom numbers
1. x0 <- 17218
x <- numeric(20)
x[1] <- (172 * x0) %% 30307
for(i in 2:20){
x[i] <- (x[i-1] * 172) %% 30307
}
x
##
[1] 21717
7563 27942 17518 12703
2812 29059 27800 23401 24448 22690 23384
## [13] 21524
4674 15946 15082 18009
6234 11503
8561
3.
(a) set.seed(32078)
runif(10, 0, 1)
##
[1] 0.2564626 0.4988177 0.5266549 0.6269816 0.8052754 0.1843452 0.5102327
##
[8] 0.3683905 0.1708176 0.7432888
(b) set.seed(32078)
runif(10, 3, 7)
##
[1] 4.025850 4.995271 5.106620 5.507927 6.221102 3.737381 5.040931 4.473562
##
[9] 3.683270 5.973155
(c) set.seed(32078)
runif(10, -2, 2)
##
[1] -0.974149697 -0.004729333
0.106619657
0.507926506
1.221101642
##
[6] -1.262619189
0.040930690 -0.526437979 -1.316729628
0.973155177
5.
(a) r <- runif(10000, 3.7, 5.8)
mean(r)
## [1] 4.747523
var(r)
43

44
CHAPTER 6. SIMULATION
## [1] 0.3623486
sd(r)
## [1] 0.601954
(3.7 + 5.8)/2
## [1] 4.75
(5.8 - 3.7)^2/12
## [1] 0.3675
sqrt((5.8 - 3.7)^2/12)
## [1] 0.6062178
(b) mean(r > 4)
## [1] 0.86
(5.8 - 4)/(5.8 - 3.7)
## [1] 0.8571429
7. U1 <- runif(10000)
U2 <- runif(10000)
U3 <- runif(10000)
U <- U1 + U2 + U3
(a) mean(U)
## [1] 1.500841
(b) var(U)
## [1] 0.2418042
var(U1) + var(U2) + var(U3)
## [1] 0.247073
(c) mean(sqrt(U))
## [1] 1.206707
(d) V <- sqrt(U1) + sqrt(U2) + sqrt(U3)
mean(V >= 0.8)
## [1] 0.9978
9.
(a) sample(1:100, size = 50, replace = FALSE)
##
[1] 79 40 99 77 73 47 72 26 81 63 75 88 52 55
5 32 69 65 44 82 17 33
6 92
7
## [26] 54 11 91 13 84 28 96 95 34 90 59 86 30 35 22 48 71 94
1
2 24 46 51 70 39

6.3. SIMULATION OF OTHER RANDOM VARIABLES
45
(b) sample(1:100, size = 50, replace = TRUE)
##
[1]
43
44
44
24
36
94
14
1 100
26
31
40
54
17
61
50
31
34
74
## [20]
70
34
84
53
76
61
1
94
95
5
23
37
29
47
35
64
99
27
50
## [39]
48
83
36
91
45
81
58
95
23
93
49
16
6.3
Simulation of other random variables
6.3.1
Bernoulli random variables
1.
(a) guess <- function(n) {
rbinom(n, size = 1, prob = 0.5)
}
sum(guess(10))
## [1] 4
(b) sum(guess(1000))
## [1] 483
3. r <- rbinom(500, size = 1, prob = 0.99)
mean(r)
## [1] 0.988
var(r)
## [1] 0.01187976
0.99
## [1] 0.99
0.99*0.01
## [1] 0.0099
6.3.2
Binomial random variables
1. x <- rbinom(24, prob = 0.15, size = 25); x
##
[1] 3 4 2 4 2 5 3 2 2 2 6 0 3 4 5 3 4 1 1 6 4 6 4 7
sum(x > 5)
## [1] 4
x <- rbinom(24, prob = 0.2, size = 25); x

46
CHAPTER 6. SIMULATION
##
[1]
8
5
0 10
3
8
4
5
4
4
5
4
4 10
2
7 10
2
5
4
4
4
2
5
sum(x > 5)
## [1] 6
x <- rbinom(24, prob = 0.25, size = 25); x
##
[1]
7 13
6
7
8
5
3
4
7 11 10
9
4
7
5
8
8
9
6
7
7
7
3
4
sum(x > 5)
## [1] 17
3. r <- rbinom(1000, size = 18, prob = 0.76)
mean(r)
## [1] 13.651
var(r)
## [1] 3.298497
18*0.76
## [1] 13.68
18*0.76*0.24
## [1] 3.2832
5.
(a) #Generate binomial pseudorandom variables by summing Bernoulli
ranbin2 <- function(n, size, prob){
#'singlenumber' generates one binomial random variable.
singlenumber <- function(){
x <- runif(size)
sum(x < prob)
}
replicate(n, singlenumber())
}
(b) microbenchmark(ranbin2(n = 10000, size = 10, prob = 0.4),
rbinom(n = 10000, size = 10, prob = 0.4),
ranbin2(n = 10000, size = 100, prob = 0.4),
rbinom(n = 10000, size = 100, prob = 0.4),
ranbin2(n = 10000, size = 1000, prob = 0.4),
rbinom(n = 10000, size = 1000, prob = 0.4),
times = 10)

6.3. SIMULATION OF OTHER RANDOM VARIABLES
47
## Unit: microseconds
##
expr
min
lq
mean
##
ranbin2(n = 10000, size = 10, prob = 0.4)
37466.266
37603.833
41031.1954
##
rbinom(n = 10000, size = 10, prob = 0.4)
580.372
586.913
604.4989
##
ranbin2(n = 10000, size = 100, prob = 0.4)
73313.157
79823.471
86072.4019
##
rbinom(n = 10000, size = 100, prob = 0.4)
1019.980
1027.284
1046.3172
##
ranbin2(n = 10000, size = 1000, prob = 0.4) 374813.598 378417.237 394440.5873
##
rbinom(n = 10000, size = 1000, prob = 0.4)
732.194
739.948
754.2176
##
median
uq
max neval
cld
##
38950.3260
45233.987
50089.683
10
b
##
595.1230
622.575
640.472
10 a
##
84023.8205
90681.554 103641.583
10
c
##
1044.5380
1063.052
1077.599
10 a
##
390325.1360 401351.757 453438.668
10
d
##
750.8225
770.931
781.978
10 a
7.
(a) Rather than show a movie, here are 6 “frames” from it:
par(mfrow = c(3,2))
for (m in c(1, 2, 6, 16, 40, 100)) {
z <- (rbinom(20000, size = m, prob = 0.4) - m * 0.4) /
sqrt(m * 0.4 * 0.6)
qqnorm(z, ylim = c(-4, 4), main = paste("QQ-plot, m = ", m))
qqline(z)
}

48
CHAPTER 6. SIMULATION
−4
−2
0
2
4
−4
0
2
4
QQ−plot, m =  1
Theoretical Quantiles
Sample Quantiles
−4
−2
0
2
4
−4
0
2
4
QQ−plot, m =  2
Theoretical Quantiles
Sample Quantiles
−4
−2
0
2
4
−4
0
2
4
QQ−plot, m =  6
Theoretical Quantiles
Sample Quantiles
−4
−2
0
2
4
−4
0
2
4
QQ−plot, m =  16
Theoretical Quantiles
Sample Quantiles
−4
−2
0
2
4
−4
0
2
4
QQ−plot, m =  40
Theoretical Quantiles
Sample Quantiles
−4
−2
0
2
4
−4
0
2
4
QQ−plot, m =  100
Theoretical Quantiles
Sample Quantiles
(b) par(mfrow=c(3,2))
for (p in c(0.3, 0.2, 0.1, 0.05)) {
for (m in c(1, 2, 6, 16, 40, 100)) {
z <- (rbinom(20000, size = m, prob = p) - m * p) /
sqrt(m * p * (1 - p))
qqnorm(z, ylim = c(-4, 4), main = paste("QQ-plot, p = ", p, " m = ", m))
qqline(z)
}
}

6.3. SIMULATION OF OTHER RANDOM VARIABLES
49
−4
−2
0
2
4
−4
0
2
4
QQ−plot, p =  0.3  m =  1
Theoretical Quantiles
Sample Quantiles
−4
−2
0
2
4
−4
0
2
4
QQ−plot, p =  0.3  m =  2
Theoretical Quantiles
Sample Quantiles
−4
−2
0
2
4
−4
0
2
4
QQ−plot, p =  0.3  m =  6
Theoretical Quantiles
Sample Quantiles
−4
−2
0
2
4
−4
0
2
4
QQ−plot, p =  0.3  m =  16
Theoretical Quantiles
Sample Quantiles
−4
−2
0
2
4
−4
0
2
4
QQ−plot, p =  0.3  m =  40
Theoretical Quantiles
Sample Quantiles
−4
−2
0
2
4
−4
0
2
4
QQ−plot, p =  0.3  m =  100
Theoretical Quantiles
Sample Quantiles

50
CHAPTER 6. SIMULATION
−4
−2
0
2
4
−4
0
2
4
QQ−plot, p =  0.2  m =  1
Theoretical Quantiles
Sample Quantiles
−4
−2
0
2
4
−4
0
2
4
QQ−plot, p =  0.2  m =  2
Theoretical Quantiles
Sample Quantiles
−4
−2
0
2
4
−4
0
2
4
QQ−plot, p =  0.2  m =  6
Theoretical Quantiles
Sample Quantiles
−4
−2
0
2
4
−4
0
2
4
QQ−plot, p =  0.2  m =  16
Theoretical Quantiles
Sample Quantiles
−4
−2
0
2
4
−4
0
2
4
QQ−plot, p =  0.2  m =  40
Theoretical Quantiles
Sample Quantiles
−4
−2
0
2
4
−4
0
2
4
QQ−plot, p =  0.2  m =  100
Theoretical Quantiles
Sample Quantiles

6.3. SIMULATION OF OTHER RANDOM VARIABLES
51
−4
−2
0
2
4
−4
0
2
4
QQ−plot, p =  0.1  m =  1
Theoretical Quantiles
Sample Quantiles
−4
−2
0
2
4
−4
0
2
4
QQ−plot, p =  0.1  m =  2
Theoretical Quantiles
Sample Quantiles
−4
−2
0
2
4
−4
0
2
4
QQ−plot, p =  0.1  m =  6
Theoretical Quantiles
Sample Quantiles
−4
−2
0
2
4
−4
0
2
4
QQ−plot, p =  0.1  m =  16
Theoretical Quantiles
Sample Quantiles
−4
−2
0
2
4
−4
0
2
4
QQ−plot, p =  0.1  m =  40
Theoretical Quantiles
Sample Quantiles
−4
−2
0
2
4
−4
0
2
4
QQ−plot, p =  0.1  m =  100
Theoretical Quantiles
Sample Quantiles

52
CHAPTER 6. SIMULATION
−4
−2
0
2
4
−4
0
2
4
QQ−plot, p =  0.05  m =  1
Theoretical Quantiles
Sample Quantiles
−4
−2
0
2
4
−4
0
2
4
QQ−plot, p =  0.05  m =  2
Theoretical Quantiles
Sample Quantiles
−4
−2
0
2
4
−4
0
2
4
QQ−plot, p =  0.05  m =  6
Theoretical Quantiles
Sample Quantiles
−4
−2
0
2
4
−4
0
2
4
QQ−plot, p =  0.05  m =  16
Theoretical Quantiles
Sample Quantiles
−4
−2
0
2
4
−4
0
2
4
QQ−plot, p =  0.05  m =  40
Theoretical Quantiles
Sample Quantiles
−4
−2
0
2
4
−4
0
2
4
QQ−plot, p =  0.05  m =  100
Theoretical Quantiles
Sample Quantiles
6.3.3
Poisson random variables
1. rpois(15, lambda = 2.8)
##
[1] 2 2 2 3 1 3 3 5 0 3 2 4 0 3 1
3. x <- rpois(10000, lambda = 7.2)
mean(x)
## [1] 7.2372
var(x)
## [1] 7.366873
7.2

6.3. SIMULATION OF OTHER RANDOM VARIABLES
53
## [1] 7.2
7.2
## [1] 7.2
7. N <- rpois(10000, lambda=2.5 * 2)
pts <- list()
for (i in 1:10000)
pts[[i]] <- runif(N[i], 0, 2)
(a) count1 <- numeric(10000)
count2 <- numeric(10000)
for(i in 1:10000){
count1[i] <- sum(pts[[i]] < 1)
count2[i] <- sum(pts[[i]] > 1)
}
(b) table(count1)
## count1
##
0
1
2
3
4
5
6
7
8
9
10
##
874 2120 2540 2093 1337
623
259
115
31
5
3
table(count2)
## count2
##
0
1
2
3
4
5
6
7
8
9
10
##
777 2057 2527 2177 1324
694
301
100
34
6
3
round(10000*dpois(0:12, 2.5))
##
[1]
821 2052 2565 2138 1336
668
278
99
31
9
2
0
0
The distributions look quite similar.
(c) plot(jitter(count1), jitter(count2))

54
CHAPTER 6. SIMULATION
0
2
4
6
8
10
0
2
4
6
8
10
jitter(count1)
jitter(count2)
8. N <- rpois(1, 0.023*24*62)
U <- sort(runif(N, 0, 62))
as.POSIXct("2016-07-01") + U*24*60*60
##
[1] "2016-07-02 16:04:08 EDT" "2016-07-06 07:21:24 EDT"
##
[3] "2016-07-08 06:04:35 EDT" "2016-07-11 00:36:16 EDT"
##
[5] "2016-07-15 22:11:53 EDT" "2016-07-17 03:57:18 EDT"
##
[7] "2016-07-17 12:16:50 EDT" "2016-07-18 17:02:16 EDT"
##
[9] "2016-07-20 17:06:08 EDT" "2016-07-23 09:07:11 EDT"
## [11] "2016-07-23 11:49:56 EDT" "2016-07-25 03:56:38 EDT"
## [13] "2016-07-28 20:27:54 EDT" "2016-08-01 05:08:18 EDT"
## [15] "2016-08-02 11:55:43 EDT" "2016-08-04 09:08:29 EDT"
## [17] "2016-08-04 09:35:13 EDT" "2016-08-04 19:06:42 EDT"
## [19] "2016-08-05 02:09:01 EDT" "2016-08-06 13:49:26 EDT"
## [21] "2016-08-08 11:38:43 EDT" "2016-08-08 13:46:57 EDT"
## [23] "2016-08-10 10:46:43 EDT" "2016-08-16 02:09:20 EDT"
## [25] "2016-08-20 14:23:50 EDT" "2016-08-21 19:13:18 EDT"

6.3. SIMULATION OF OTHER RANDOM VARIABLES
55
## [27] "2016-08-23 04:13:41 EDT" "2016-08-24 02:19:13 EDT"
## [29] "2016-08-26 07:22:02 EDT" "2016-08-28 21:23:33 EDT"
9. par(mfrow = c(1, 2))
lambda <- 2
regionlength <- 10
regionwidth <- 10
N <- rpois(1, lambda*regionlength*regionwidth)
U1 <- runif(N, min = 0, max = regionwidth)
U2 <- runif(N, min = 0, max = regionlength)
plot(U1, U2, main = "lambda = 2", sub = paste("N =", N))
lambda <- 4
N <- rpois(1, lambda*regionlength*regionwidth)
U1 <- runif(N, min = 0, max = regionwidth)
U2 <- runif(N, min = 0, max = regionlength)
plot(U1, U2, main = "lambda = 4", sub = paste("N =", N))

56
CHAPTER 6. SIMULATION
0
2
4
6
8
10
0
2
4
6
8
10
lambda = 2
N = 211
U1
U2
0
2
4
6
8
10
0
2
4
6
8
10
lambda = 4
N = 422
U1
U2
6.3.4
Exponential random numbers
1. r <- rexp(50000, rate = 3)
(a) mean(r < 1)
## [1] 0.95164
pexp(1, rate = 3)
## [1] 0.9502129
(b) mean(r)
## [1] 0.3306863

6.3. SIMULATION OF OTHER RANDOM VARIABLES
57
1/3
## [1] 0.3333333
(c) var(r)
## [1] 0.1097441
1/3^2
## [1] 0.1111111
3. r1 <- rexp(100000, rate=1/3)
r2 <- rexp(100000, rate=1/6)
r.min <- pmin(r1, r2)
mean(r.min)
## [1] 2.00405
var(r.min)
## [1] 3.974251
5. count <- numeric(10000)
for(i in 1:10000){
cum <- 0
j <- 0
while(cum <= 2){
j <- j + 1
r <- rexp(1, rate=2.5)
cum <- cum + r
}
count[i] <- j - 1
}
table(count)
## count
##
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
##
64
359
818 1431 1789 1782 1458
975
634
378
178
75
39
13
6
1
round(10000*dpois(0:20, lambda = 5))
##
[1]
67
337
842 1404 1755 1755 1462 1044
653
363
181
82
34
13
5
## [16]
2
0
0
0
0
0
6.3.7
All built-in distributions
1. r <- rnorm(100, mean = 51, sd = 5.2)
mean(r)

58
CHAPTER 6. SIMULATION
## [1] 52.31954
sd(r)
## [1] 4.953902
3. sim <- function(n){
count <- 0
ans <- numeric(n)
while(count < n){
X <- rnorm(n - count, mean = 3, sd = 4)
X <- X[abs(X) > 2]
ans[(count + 1):(count + length(X))] <- X
count <- count + length(X)
}
ans
}
hist(sim(1000), breaks = "Scott")

6.3. SIMULATION OF OTHER RANDOM VARIABLES
59
Histogram of sim(1000)
sim(1000)
Frequency
−5
0
5
10
15
0
20
40
60
80
100
120
140
5. r <- rchisq (10000, df = 8)
mean(r)
## [1] 7.960771
var(r)
## [1] 15.67677
7.
(a) Simulate the exponential with rate b−a, then take the power 1/a.
(b) myrweibull <- function(n, a, b) {
x <- rexp(n, rate = b^(-a))
x^(1/a)
}

60
CHAPTER 6. SIMULATION
# Check that it worked
a <- 3/2
b <- 65^(2/3)
b*gamma(1 + 1/a)
# This is the theoretical mean
## [1] 14.59399
mean(myrweibull(10000, 3/2, (65)^(2/3)))
## [1] 14.66222
6.4
Multivariate Random Number Generation
1.
(a) rweibull2 <- function(n, par) {
alpha1 <- par[1]
alpha2 <- par[2]
beta0 <- par[3]
beta1 <- par[4]
beta2 <- par[5]
x1 <- myrweibull(n, alpha1, beta2^(1/alpha1))
x2 <- myrweibull(n, alpha2, (beta0 + beta1*x1)^(1/alpha2))
cbind(x1, x2)
}
par <- c(3/2, 5/3, 108, 5.3, 65)
rweibull2(5, par)
##
x1
x2
## [1,] 21.241684 17.641432
## [2,]
6.782057
6.298824
## [3,] 17.062081 15.342021
## [4,] 11.933557 30.877528
## [5,]
5.325177
2.633207
(b) # Compute values from the proposed density function
a1 <- 3/2; a2 <- 5/3; b0 <- 108; b1 <- 5.3; b2 <- 65
grid <- with(MPV::windWin80,
expand.grid(x1 = seq(0, max(h0), len=101),
x2 = seq(0, max(h12), len=101)))
grid$z <- with(grid, a1*a2*exp(-x1^a1/b2 - x2^a2/
(b0+b1*x1))*x1^(a1-1)*x2^(a2-1)/(b2*(b0+b1*x1)) )
library(ggplot2)
sims <- rweibull2(366, par)
colnames(sims) <- c("h0", "h12")
ggplot(as.data.frame(sims), aes(x = h0, y = h12)) +
geom_density2d(col = "white") +
geom_contour(data = grid, aes(x = x1, y = x2, z = z) ) +
geom_jitter() +
xlab("Wind speed at midnight (km/h)") +
ylab("Wind speed at noon (km/h)") +
theme(panel.grid = element_blank())

6.6. MONTE CARLO INTEGRATION
61
0
20
40
60
80
0
20
40
60
Wind speed at midnight (km/h)
Wind speed at noon (km/h)
6.6
Monte Carlo Integration
1. #Monte Carlo
u <- runif(1000)
mean(u)
## [1] 0.4985008
#Integrate function
f <- function(x){
x
}
integrate(f, lower = 0, upper = 1)
## 0.5 with absolute error < 5.6e-15

62
CHAPTER 6. SIMULATION
#Monte Carlo
u <- runif(1000, min = 1, max = 3)
mean(u^2)*(3 - 1)
## [1] 8.900909
#Integrate function
f <- function(x){
x^2
}
integrate(f, lower = 1, upper = 3)
## 8.666667 with absolute error < 9.6e-14
#Monte Carlo
u <- runif(1000, max = pi)
mean(sin(u))*(pi - 0)
## [1] 1.986493
#Integrate function
f <- function(x){
sin(x)
}
integrate(f, lower = 0, upper = pi)
## 2 with absolute error < 2.2e-14
6.7
Advanced simulation methods
6.7.1
Rejection sampling
1. rand.normal <- function(n){
# Ask for twice as many as we need, because we'll reject a
# lot of them
r1 <- runif(2*n, min = -4, max = 4)
r2 <- runif(2*n)
ans <- r1[ r2 < 2.5*dnorm(r1)]
while(length(ans) < n){
need <- n - length(ans)
r1 <- runif(2*need, min = -4, max = 4)
r2 <- runif(2*need)
ans <- c(ans,r1[ r2 < 2.5*dnorm(r1)])
}
ans[1:n]
}
hist(rand.normal(1000))

6.7. ADVANCED SIMULATION METHODS
63
Histogram of rand.normal(1000)
rand.normal(1000)
Frequency
−4
−3
−2
−1
0
1
2
3
0
50
100
150
200
To handle the whole line, we’d need a proposal distribution with support on (−∞, ∞) instead of a
uniform distribution.
4. set.seed(91626)
probs <- runif(100) + 100
probs <- probs/sum(probs)
microbenchmark(randiscrete1(100, probs),
randiscrete1(1000, probs),
randiscrete1(10000, probs),
randiscrete2(100, probs),
randiscrete2(1000, probs),
randiscrete2(10000, probs))
## Unit: microseconds
##
expr
min
lq
mean
median
uq
##
randiscrete1(100, probs)
362.108
410.746
532.1821
427.5990
467.363
##
randiscrete1(1000, probs)
3471.681
3754.073
4566.7497
3904.5520
4136.995

64
CHAPTER 6. SIMULATION
##
randiscrete1(10000, probs) 37234.355 44916.094 49553.4528 47929.5595 51486.988
##
randiscrete2(100, probs)
515.149
565.817
895.2444
621.9325
659.620
##
randiscrete2(1000, probs)
5028.246
5327.768
6283.8589
5982.8530
6192.785
##
randiscrete2(10000, probs) 51021.904 60217.881 65501.0113 64653.8240 69562.875
##
max neval
cld
##
9193.926
100 a
##
14127.980
100
b
##
175699.298
100
c
##
11451.995
100 a
##
30268.247
100
b
##
181563.137
100
d
For very long probs vectors, the rejection method is faster.
6.7.2
Rejection sampling for bivariate distributions
1.
(a) rbexp <- function(n, theta = 2, multiple = 1) {
nremaining <- n
rejectStep <- function(n, theta) {
X <- rexp(n, rate = theta - 1)
Y <- rexp(n, rate = theta - 1)
V <- runif(n)*dexp(X, rate = theta - 1)*
dexp(Y, rate = theta - 1)/(theta-1)^2
ACCEPT <- V <= exp(-(X*Y + theta*(X+Y)))
X <- X[ACCEPT]; Y <- Y[ACCEPT]
cbind(X, Y)
}
XY <- cbind(c(), c())
while (nremaining > 0) {
XY <- rbind(XY, rejectStep(multiple*nremaining, theta = theta))
nObs <- nrow(XY)
nremaining <- n - nObs
}
XY[1:n, ]
}
library(microbenchmark)
microbenchmark(rbexp(1000, 2, 1),
rbexp(1000, 2, 2),
rbexp(1000, 2, 3),
rbexp(1000, 2, 4),
rbexp(1000, 2, 5),
rbexp(1000, 2, 6),
rbexp(1000, 2, 7),
rbexp(1000, 2, 8),
rbexp(1000, 2, 9),
rbexp(1000, 2, 10))
## Unit: microseconds
##
expr
min
lq
mean
median
uq
max
##
rbexp(1000, 2, 1) 1317.097 1437.3995 1692.034 1512.2880 1609.320
9678.535
##
rbexp(1000, 2, 2) 1016.737 1094.8990 1159.150 1154.4065 1197.838
1583.193
##
rbexp(1000, 2, 3)
898.089
989.7410 1128.789 1019.5115 1072.073
9680.989
##
rbexp(1000, 2, 4)
834.044
920.5435 1325.562
964.2025 1004.115 19229.830

6.8. CHAPTER EXERCISES
65
##
rbexp(1000, 2, 5)
874.981 1010.3515 1220.833 1033.7205 1074.130
9852.600
##
rbexp(1000, 2, 6) 1054.073 1200.1655 1222.406 1207.2055 1226.106
1723.542
##
rbexp(1000, 2, 7) 1205.376 1395.1895 1522.337 1411.8200 1441.476
9422.656
##
rbexp(1000, 2, 8) 1380.994 1585.6730 1615.719 1603.0690 1629.204
2536.460
##
rbexp(1000, 2, 9) 1603.984 1812.1660 1929.541 1832.4190 1864.644
9486.705
##
rbexp(1000, 2, 10) 1943.972 2029.3120 2362.877 2052.2760 2082.713 10074.387
##
neval
cld
##
100
cd
##
100 ab
##
100 a
##
100 abc
##
100 abc
##
100 abc
##
100 a
d
##
100
b d
##
100
de
##
100
e
6.7.3
Importance sampling
6.8
Chapter Exercises
1. hitBall <- function(probSuccess) {
rbinom(1, 1, probSuccess)
}
# hitBall generates a 1 (success) or a 0 (failure)
rally <- function(probs, hitter = 1) {
serve <- 1
while (serve == 1) {
serve <- hitBall(probs[hitter])
hitter <- 3 - hitter
}
hitter
}
# rally generates the outcome of a combination of serve and returns until first failed hit
# at which point the opponent wins the rally; probs is a 2-vector of success probabilities for
# the 2 players
game <- function(successProbs = c(.5, .5), winningScore = 11, initialServer = 1) {
score <- c(0, 0)
server <- initialServer
while (max(score) < max(11, min(score) + 2)) {
winner <- rally(successProbs, server)
score[winner] <- score[winner] + 1
if (sum(score) %% 2 == 0) server <- 3 - server
}
score
}

66
CHAPTER 6. SIMULATION
# the probability of a successful serve is usually higher than any subsequent return; the
# following code adds this feature, through the 2-vector serveProbs which specifies
# the probability of success on the serve for each player
rally <- function(probs, hitter = 1, serveProbs) {
serve <- 1
serve <- hitBall(serveProbs[hitter])
hitter <- 3 - hitter
while (serve == 1) {
serve <- hitBall(probs[hitter])
hitter <- 3 - hitter
}
hitter
}
game <- function(successProbs = c(0.5, 0.5), winningScore = 11,
initialServer = 1, serveProbs = c(0.75, 0.75)) {
score <- c(0, 0)
server <- initialServer
while (max(score) < max(11, min(score) + 2)) {
winner <- rally(successProbs, server, serveProbs)
score[winner] <- score[winner] + 1
if (sum(score) %% 2 == 0) server <- 3 - server
}
score
}
2. The question asks for a population of 10000, but that takes too long, so we’ll use N = 100.
(a) simulate <- function(N, p, init = 1, stop = N){
time.line <- 0
time.current <- 0
n.sick <- init
while (n.sick < stop) {
time.current <- time.current + 1
#if encounters==0, then none of the two persons is sick
#if encounters==1, then one of the two persons is sick
#if encounters==2, then both of the two persons are sick
encounters <- rhyper(nn = 1, m = n.sick, n = N - n.sick, k = 2)
if (encounters == 1){
contage <- rbinom(n = 1, size = 1, p)
if (contage == 1){
#record current time
time.line <- c(time.line, time.current)
n.sick <- n.sick + 1
}
}
}

6.8. CHAPTER EXERCISES
67
time.line
}
N <- 100
par(mfrow = c(2,2))
for(p in c(0.01, 0.05, 0.1)) {
ans <- simulate(N, p)
plot(ans, 1:N, xlab='Time', ylab='Number of sick people',
type = 's', main = p)
}
0
10000
30000
50000
0
20
40
60
80
0.01
Time
Number of sick people
0
4000
8000
12000
0
20
40
60
80
0.05
Time
Number of sick people
0
1000
3000
5000
0
20
40
60
80
0.1
Time
Number of sick people
(d) simulate <- function(N, p, precover, init = 1, stop = N){
time.line <- 0
nsick.line <- init
time.current <- 0
n.sick <- init

68
CHAPTER 6. SIMULATION
while (n.sick > 0 & n.sick < stop) {
time.current <- time.current + rexp(1, rate = 1/5)
#if encounters==0, then none of the two persons is sick
#if encounters==1, then one of the two persons is sick
#if encounters==2, then both of the two persons are sick
encounters <- rhyper(nn = 1, m = n.sick, n = N - n.sick, k = 2)
if (encounters == 1){
contage <- rbinom(n = 1, size = 1, p)
if (contage == 1){
#record current time
n.sick <- n.sick + 1
}
}
n.sick <- rbinom(1, size = n.sick, prob = 1 - precover)
if (n.sick != nsick.line[length(nsick.line)]) {
time.line <- c(time.line, time.current)
nsick.line <- c(nsick.line, n.sick)
}
}
cbind(time.line, nsick.line)
}
N <- 100
p <- .05
ans <- simulate(N, p, 0)
plot(ans, xlab='Time', ylab='Number of sick people', type = 's')

6.8. CHAPTER EXERCISES
69
0
10000
20000
30000
40000
50000
0
20
40
60
80
100
Time
Number of sick people
4.
(a) simulate <- function(){
N <- rpois(1, lambda = 100)
claimSize <- rgamma(N, shape = 2, rate = 2)
claimTime <- sort(runif(N))
asset <- 0
asset.1 <- 105 * claimTime[1] - claimSize[1]
asset <- c(asset, asset.1)
for(i in 2:N){
len <- length(asset)
asset.i <- asset[len] + (claimTime[i] - claimTime[i-1])*105 -
claimSize[i]
asset <- c(asset, asset.i)
}
claimTime <- c(0, claimTime)
list(time=claimTime, asset=asset)

70
CHAPTER 6. SIMULATION
}
ans <- simulate()
plot(ans$time, ans$asset, type='l')
0.0
0.2
0.4
0.6
0.8
1.0
0
5
10
ans$time
ans$asset
(b) minimum <- c()
final <- c()
for(i in 1:1000){
ans <- simulate()
minimum <- c(minimum, min(ans$asset))
final <- c(final, rev(ans$asset)[1])
}
mean(minimum)
## [1] -7.374455
mean(final)
## [1] 3.829063

Chapter 7
Computational Linear Algebra
7.1
Vectors and Matrices in R
7.1.1
Constructing matrix objects
1. A <- matrix(rep(seq(1, 5), 5), nrow = 5) +
matrix(rep(seq(0, 4), 5), byrow = TRUE, nrow = 5)
A
##
[,1] [,2] [,3] [,4] [,5]
## [1,]
1
2
3
4
5
## [2,]
2
3
4
5
6
## [3,]
3
4
5
6
7
## [4,]
4
5
6
7
8
## [5,]
5
6
7
8
9
Hankel <- function(x){
A <- matrix(rep(seq(1, x), x), nrow = x) +
matrix(rep(seq(0, x - 1), x), byrow = TRUE, nrow = x)
return(A)
}
Hankel(10)
##
[,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
##
[1,]
1
2
3
4
5
6
7
8
9
10
##
[2,]
2
3
4
5
6
7
8
9
10
11
##
[3,]
3
4
5
6
7
8
9
10
11
12
##
[4,]
4
5
6
7
8
9
10
11
12
13
##
[5,]
5
6
7
8
9
10
11
12
13
14
##
[6,]
6
7
8
9
10
11
12
13
14
15
##
[7,]
7
8
9
10
11
12
13
14
15
16
##
[8,]
8
9
10
11
12
13
14
15
16
17
##
[9,]
9
10
11
12
13
14
15
16
17
18
## [10,]
10
11
12
13
14
15
16
17
18
19
Hankel(12)
##
[,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]
##
[1,]
1
2
3
4
5
6
7
8
9
10
11
12
71

72
CHAPTER 7. COMPUTATIONAL LINEAR ALGEBRA
##
[2,]
2
3
4
5
6
7
8
9
10
11
12
13
##
[3,]
3
4
5
6
7
8
9
10
11
12
13
14
##
[4,]
4
5
6
7
8
9
10
11
12
13
14
15
##
[5,]
5
6
7
8
9
10
11
12
13
14
15
16
##
[6,]
6
7
8
9
10
11
12
13
14
15
16
17
##
[7,]
7
8
9
10
11
12
13
14
15
16
17
18
##
[8,]
8
9
10
11
12
13
14
15
16
17
18
19
##
[9,]
9
10
11
12
13
14
15
16
17
18
19
20
## [10,]
10
11
12
13
14
15
16
17
18
19
20
21
## [11,]
11
12
13
14
15
16
17
18
19
20
21
22
## [12,]
12
13
14
15
16
17
18
19
20
21
22
23
3. W <- cbind(c(1, 1, 1, 1, 1, 1, 1),
c(2, 3, 4, 5, 6, 7, 8),
c(4, 7, 5, 6, 7, 5, 3))
W
##
[,1] [,2] [,3]
## [1,]
1
2
4
## [2,]
1
3
7
## [3,]
1
4
5
## [4,]
1
5
6
## [5,]
1
6
7
## [6,]
1
7
5
## [7,]
1
8
3
7.1.2
Accessing matrix elements; row and column names
1. P <- matrix(c(0.2, 0.3, 0.8, 0.7), ncol = 2)
rownames(P) <- c("sunny", "rainy")
colnames(P) <- c("sunny", "rainy")
P
##
sunny rainy
## sunny
0.2
0.8
## rainy
0.3
0.7
w <- character(30)
w[1] <- "sunny"
for (i in 2:30)
w[i] <- sample(colnames(P), 1,
prob = P[w[i-1], ])
w
##
[1] "sunny" "rainy" "rainy" "sunny" "rainy" "rainy" "rainy" "rainy" "rainy"
## [10] "rainy" "sunny" "sunny" "sunny" "rainy" "rainy" "rainy" "rainy" "rainy"
## [19] "rainy" "rainy" "rainy" "sunny" "rainy" "rainy" "rainy" "sunny" "rainy"
## [28] "sunny" "rainy" "rainy"

7.1. VECTORS AND MATRICES IN R
73
3. matrix["Pardeep", "height"] <- 162
matrix["Hao", "height"] <- 181
matrix["Hao", "weight"] <- 68
matrix
##
height weight
## Neil
172
62
## Cindy
168
64
## Pardeep
162
51
## Deepak
175
71
## Hao
181
68
7.1.3
Matrix Properties
1. A <- matrix(c(3, 5, 4, 8), ncol = 2)
det(A)
## [1] 4
det(t(A))
## [1] 4
A <- matrix(c(3, 20, 15, 7), ncol = 2)
det(A)
## [1] -279
det(t(A))
## [1] -279
A <- matrix(c(4, 2, 25, 23), ncol = 2)
det(A)
## [1] 42
det(t(A))
## [1] 42
7.1.4
Triangular matrices
1. H3 <- matrix(c(1, 1/2, 1/3, 1/2, 1/3, 1/4, 1/3, 1/4, 1/5), nrow=3)
Hnew <- H3
Hnew[lower.tri(H3, diag = FALSE)] <- 0
Hnew
##
[,1]
[,2]
[,3]

74
CHAPTER 7. COMPUTATIONAL LINEAR ALGEBRA
## [1,]
1 0.5000000 0.3333333
## [2,]
0 0.3333333 0.2500000
## [3,]
0 0.0000000 0.2000000
3. X <- matrix(c(1, 2, 3, 1, 4, 9), ncol = 2)
X[3, 2]
## [1] 9
X[3, 2, drop = FALSE]
##
[,1]
## [1,]
9
dim(X[3, 2])
## NULL
dim(X[3, 2, drop = FALSE])
## [1] 1 1
7.2
Matrix multiplication and inversion
1. X <- matrix(c(1, 2, 3, 1, 4, 9), ncol = 2)
1.5*X
##
[,1] [,2]
## [1,]
1.5
1.5
## [2,]
3.0
6.0
## [3,]
4.5 13.5
3.
(a) No.
(b) Only vector multiplications.
(c) A <- matrix(rep(1, 1000000), nrow = 1000) # a matrix of 1<U+2019>s
B <- diag(1000) # 1000 x 1000 identity matrix
v <- rep(1, 1000) # a vector of 1<U+2019>s
library(microbenchmark)
microbenchmark( A %*% B %*% v,
(A %*% B) %*% v,
A %*% (B %*% v), times = 10)
## Unit: milliseconds
##
expr
min
lq
mean
median
uq
##
A %*% B %*% v 781.786444 789.438494 805.934353 802.102550 811.792980
##
(A %*% B) %*% v 794.070092 795.653908 812.012312 811.424824 827.088393
##
A %*% (B %*% v)
2.797333
2.842156
3.036879
2.857982
3.059897

7.2. MATRIX MULTIPLICATION AND INVERSION
75
##
max neval cld
##
867.314724
10
b
##
844.999726
10
b
##
3.730605
10
a
This varies from computer to computer. Some linear algebra libraries recognize the identity matrix
and essentially eliminate B.
7.2.3
Matrix inversion in R
1. X <- matrix(c(1, 2, 3, 1, 4, 9), ncol = 2)
XX <- t(X) %*% X
XXinv <- solve(XX)
XXinv
##
[,1]
[,2]
## [1,]
1.2894737 -0.4736842
## [2,] -0.4736842
0.1842105
# Verification:
crossprod(XX, XXinv)
##
[,1]
[,2]
## [1,]
1 8.881784e-16
## [2,]
0 1.000000e+00
This is numerically close to the identity matrix.
3.
(a) Hilbert <- function(n) {
A <- matrix(rep(NA, n*n), nrow=n)
for(i in 1:n){
for(j in 1:n){
A[i, j] <- 1/(i + j - 1)
}
}
A
}
# or
Hilbert <- function(n) {
outer(1:n, 1:n, function(x, y) 1/(x + y - 1))
}
(b) Yes. (Showing that all Hilbert matrices are invertible is not obvious, but see
https://en.wikipedia.org/wiki/Hilbert_matrix for the formula.)
(c) solve(Hilbert(1))
##
[,1]
## [1,]
1
solve(Hilbert(2))

76
CHAPTER 7. COMPUTATIONAL LINEAR ALGEBRA
##
[,1] [,2]
## [1,]
4
-6
## [2,]
-6
12
qr.solve(Hilbert(1))
##
[,1]
## [1,]
1
qr.solve(Hilbert(2))
##
[,1] [,2]
## [1,]
4
-6
## [2,]
-6
12
7.2.4
Solving linear systems
1. X1 <- c(10, 11, 12, 13, 14, 15)
X2 <- X1^2
X3 <- X1^3
X4 <- X1^4
X5 <- X1^5
X0 <- c(1, 1, 1, 1, 1, 1)
A <- cbind(X0, X1, X2, X3, X4, X5)
f <- matrix(c(25, 16, 26, 19, 21, 20), nrow = 6)
a <- solve(A, f)
a
##
[,1]
## X0
2.536100e+05
## X1 -1.025510e+05
## X2
1.650092e+04
## X3 -1.320667e+03
## X4
5.258333e+01
## X5 -8.333333e-01
A %*% a
##
[,1]
## [1,]
25
## [2,]
16
## [3,]
26
## [4,]
19
## [5,]
21
## [6,]
20
# or
x <- c(10, 11, 12, 13, 14, 15)
y <- c(25, 16, 26, 19, 21, 20)
A <- outer(x, 0:5, function(x, y) x^y)
A

7.3. EIGENVALUES AND EIGENVECTORS
77
##
[,1] [,2] [,3] [,4]
[,5]
[,6]
## [1,]
1
10
100 1000 10000 100000
## [2,]
1
11
121 1331 14641 161051
## [3,]
1
12
144 1728 20736 248832
## [4,]
1
13
169 2197 28561 371293
## [5,]
1
14
196 2744 38416 537824
## [6,]
1
15
225 3375 50625 759375
A <- outer(x, 0:5, function(x, y) x^y)
solve(A, y)
# Solve Aa = y
for a
## [1]
2.536100e+05 -1.025510e+05
1.650092e+04 -1.320667e+03
5.258333e+01
## [6] -8.333333e-01
f(x) = 253610 −102551x + 16500.92x2 −1320.667x3 + 52.58333x4 −.8333x5
7.3
Eigenvalues and eigenvectors
1. X <- matrix(c(1, 2, 3, 1, 4, 9), ncol=2)
H <- X %*% solve(t(X) %*% X) %*% t(X)
H
##
[,1]
[,2]
[,3]
## [1,]
0.5263158 0.4736842 -0.1578947
## [2,]
0.4736842 0.5263158
0.1578947
## [3,] -0.1578947 0.1578947
0.9473684
5. Hint: Note that HX = X and H(I −X) = 0.
7.4
Other matrix decompositions
1. SVD <- svd(Hilbert(4))
SVD
## $d
## [1] 1.5002142801 0.1691412202 0.0067382736 0.0000967023
##
## $u
##
[,1]
[,2]
[,3]
[,4]
## [1,] -0.7926083
0.5820757 -0.1791863 -0.02919332
## [2,] -0.4519231 -0.3705022
0.7419178
0.32871206
## [3,] -0.3224164 -0.5095786 -0.1002281 -0.79141115
## [4,] -0.2521612 -0.5140483 -0.6382825
0.51455275
##
## $v
##
[,1]
[,2]
[,3]
[,4]
## [1,] -0.7926083
0.5820757 -0.1791863 -0.02919332
## [2,] -0.4519231 -0.3705022
0.7419178
0.32871206
## [3,] -0.3224164 -0.5095786 -0.1002281 -0.79141115
## [4,] -0.2521612 -0.5140483 -0.6382825
0.51455275

78
CHAPTER 7. COMPUTATIONAL LINEAR ALGEBRA
inv <- SVD$v %*% diag(1/SVD$d) %*% t(SVD$u)
inv
##
[,1]
[,2]
[,3]
[,4]
## [1,]
16
-120
240
-140
## [2,] -120
1200 -2700
1680
## [3,]
240 -2700
6480 -4200
## [4,] -140
1680 -4200
2800
inv %*% Hilbert(4)
##
[,1]
[,2]
[,3]
[,4]
## [1,]
1.000000e+00 -3.552714e-15 -1.065814e-14 -3.552714e-15
## [2,]
5.684342e-14
1.000000e+00
5.684342e-14 -5.684342e-14
## [3,] -9.094947e-13 -4.547474e-13
1.000000e+00 -3.410605e-13
## [4,]
0.000000e+00 -1.136868e-13
5.684342e-14
1.000000e+00
2. This is kind of a square root:
SQRT <- chol(Hilbert(4))
SQRT
##
[,1]
[,2]
[,3]
[,4]
## [1,]
1 0.5000000 0.3333333 0.25000000
## [2,]
0 0.2886751 0.2886751 0.25980762
## [3,]
0 0.0000000 0.0745356 0.11180340
## [4,]
0 0.0000000 0.0000000 0.01889822
t(SQRT) %*% SQRT
##
[,1]
[,2]
[,3]
[,4]
## [1,] 1.0000000 0.5000000 0.3333333 0.2500000
## [2,] 0.5000000 0.3333333 0.2500000 0.2000000
## [3,] 0.3333333 0.2500000 0.2000000 0.1666667
## [4,] 0.2500000 0.2000000 0.1666667 0.1428571
Since the matrix is symmetric, here’s a true square root:
SVD <- svd(Hilbert(4))
SQRT <- SVD$u %*% diag(sqrt(SVD$d)) %*% t(SVD$v)
SQRT
##
[,1]
[,2]
[,3]
[,4]
## [1,] 0.9114604 0.3390312 0.1927197 0.1309843
## [2,] 0.3390312 0.3528552 0.2474522 0.1806979
## [3,] 0.1927197 0.2474522 0.2411021 0.2085577
## [4,] 0.1309843 0.1806979 0.2085577 0.2226032
SQRT %*% SQRT
##
[,1]
[,2]
[,3]
[,4]

7.4. OTHER MATRIX DECOMPOSITIONS
79
## [1,] 1.0000000 0.5000000 0.3333333 0.2500000
## [2,] 0.5000000 0.3333333 0.2500000 0.2000000
## [3,] 0.3333333 0.2500000 0.2000000 0.1666667
## [4,] 0.2500000 0.2000000 0.1666667 0.1428571
Chapter Exercises
1.
(a) P <- matrix(c(0.1, 0.4, 0.3, 0.2,
0.2, 0.1, 0.4, 0.3,
0.3, 0.2, 0.1, 0.4,
0.4, 0.3, 0.2, 0.1), nrow=4)
apply(P, 1, sum)
## [1] 1 1 1 1
(b) P2 <- P %*% P
P2
##
[,1] [,2] [,3] [,4]
## [1,] 0.26 0.28 0.26 0.20
## [2,] 0.20 0.26 0.28 0.26
## [3,] 0.26 0.20 0.26 0.28
## [4,] 0.28 0.26 0.20 0.26
P3 <- P %*% P2
P3
##
[,1]
[,2]
[,3]
[,4]
## [1,] 0.256 0.244 0.240 0.260
## [2,] 0.260 0.256 0.244 0.240
## [3,] 0.240 0.260 0.256 0.244
## [4,] 0.244 0.240 0.260 0.256
P5 <- P2 %*% P3
P5
##
[,1]
[,2]
[,3]
[,4]
## [1,] 0.25056 0.25072 0.24928 0.24944
## [2,] 0.24944 0.25056 0.25072 0.24928
## [3,] 0.24928 0.24944 0.25056 0.25072
## [4,] 0.25072 0.24928 0.24944 0.25056
P10 <- P5 %*% P5
P10
##
[,1]
[,2]
[,3]
[,4]
## [1,] 0.2500000 0.2500016 0.2500000 0.2499983
## [2,] 0.2499983 0.2500000 0.2500016 0.2500000
## [3,] 0.2500000 0.2499983 0.2500000 0.2500016
## [4,] 0.2500016 0.2500000 0.2499983 0.2500000
(c) solve(rbind(rep(1, 4), (diag(rep(1, 4)) - t(P))[-4, ]), c(1, 0, 0, 0))
## [1] 0.25 0.25 0.25 0.25

80
CHAPTER 7. COMPUTATIONAL LINEAR ALGEBRA
The values in P n and the values in x all appear to be converging to 0.25.
(d) set.seed(361)
pseudo <- function(n) {
Y <- numeric(n)
Y[1] <- 1
for(j in 2:n) {
Y[j] <- sample(1:4, 1,
prob=P[Y[j-1], ],
replace=T)
}
return(Y)
}
yresult <- pseudo(10000)
(e) table(yresult)
## yresult
##
1
2
3
4
## 2502 2508 2523 2467
The relative frequency distribution is near x.

Chapter 8
Numerical optimization
8.1
The golden section search method
golden <- function(f, a, b, tol = 0.0000001){
ratio <- 2/(sqrt(5) + 1)
x1 <- b - ratio*(b - a)
x2 <- a + ratio*(b - a)
f1 <- f(x1)
f2 <- f(x2)
while( abs(b -a) > tol){
if(f2 > f1){
b <- x2
x2 <- x1
f2 <- f1
x1 <- b - ratio*(b - a)
f1 <- f(x1)
}else{
a <- x1
x1 <- x2
f1 <- f2
x2 <- a + ratio*(b - a)
f2 <- f(x2)
}
}
return((a + b) / 2)
}
1.
(a) f <- function(x) {
abs(x - 3.5) + abs(x - 2) + abs(x - 1)
}
curve ( f, from = -1, to = 5)
81

82
CHAPTER 8. NUMERICAL OPTIMIZATION
−1
0
1
2
3
4
5
3
4
5
6
7
8
9
x
f(x)
This indicates that there is only one minimum close to zero and it is located to the right of zero.
golden( f, 1, 5)
## [1] 2
(b) f <- function(x) {
abs(x - 3.2) + abs(x - 3.5) + abs(x - 2) + abs(x - 1)
}
curve(f, from = 0, to = 5)

8.1. THE GOLDEN SECTION SEARCH METHOD
83
0
1
2
3
4
5
4
5
6
7
8
9
10
x
f(x)
This shows that between 1 and 4 there is more than one minimum point.
golden( f, 1, 2.15)
## [1] 2.15
golden( f, 1, 5)
## [1] 3.2
golden( f, 1, 3)
## [1] 3
golden( f, 2.5, 3.5)
## [1] 3.2
3. goldenmax <- function(f, a, b, tol = 0.0000001)
golden(function(x) -f(x), a, b, tol = 0.0000001)

84
CHAPTER 8. NUMERICAL OPTIMIZATION
f <- function(x) -(x-2)^2
goldenmax(f, 1, 10)
## [1] 2
8.4
Built-in functions
1.
(a) f <- function(x) {
abs(x - 3.5) + abs(x - 2) + abs(x - 1)
}
optimize( f, c(1, 3))
## $minimum
## [1] 2
##
## $objective
## [1] 2.5
(b) f <- function(x) {
abs(x - 3.2) + abs(x - 3.5) + abs(x - 2) + abs(x - 1)
}
optimize( f, c(1, 4))
## $minimum
## [1] 2.145956
##
## $objective
## [1] 3.7
8.5
Linear programming
1.
(a) library(lpSolve)
a.lp <- lp(objective.in = c(1, 3, 4, 1),
const.mat = matrix(c(1, -2, 0, 0,
0, 3, 1, 0,
0, 1, 0, 1), nrow = 3, byrow = TRUE),
const.rhs = c(9, 9, 10),
const.dir = c(">=", ">=", ">="))
a.lp
## Success: the objective function is 31
a.lp$solution
## [1] 15
3
0
7
(b) The solution will not change since the optimal solution requires that all decision variables are
integers.

8.6. CHAPTER EXERCISES
85
(c) c.lp <- lp(objective.in = c(1, -3, 4, 1),
const.mat = matrix(c(1, -2, 0, 0,
0, 3, 1, 0,
0, 1, 0, 1), nrow = 3, byrow = TRUE),
const.rhs = c(9, 9, 10),
const.dir = c(">=", ">=", ">="))
c.lp
## Error: status 3
This says that the solution is unbounded.
8.6
Chapter exercises
1. x <- c( 0.45, 0.08, -1.08, 0.92, 1.65, 0.53, 0.52, -2.15, -2.2, -0.32, -1.87, -0.16,
-0.19, -0.98, -0.2, 0.67, 0.08, 0.38, 0.76, -0.78)
y <- c( 1.26, 0.58, -1, 1.07, 1.28, -0.33, 0.68, -2.22, -1.82, -1.17, -1.54, 0.35,
-0.23, -1.53, 0.16, 0.91, 0.22, 0.44, 0.98, -0.98)
library(quadprog)
X <- cbind( rep(1, 20), x)
XX <- t(X) %*% X
Xy <- t(X) %*% y
A <- matrix( c(1, -1), ncol = 1)
b <- 0
ans <- solve.QP( Dmat = XX, dvec = Xy, Amat = A, bvec = b)
ans$solution
## [1] 0.5314036 0.5314036
This implies that the intercept = slope = 0.5314036
3. A <- matrix( c( 1, 1, -1, 0, 0, 0, 0, 1, 0, 0, 1, -1, 0, 0, 1, 0, 0, 0, 0, 1, -1),
nrow=3, byrow=TRUE)
D <- matrix( c( 0.01, 0.002, 0.002,
0.002, 0.01, 0.002,
0.002, 0.002, 0.01), nrow = 3)
x <- c( 0.002, 0.005, 0.01)
b <- c( 1, 0, -0.5, 0, -0.5, 0, -0.5)
ans <- solve.QP(2*D, x, A, b, meq = 1)
ans$solution
## [1] 0.15625 0.34375 0.50000
5. D <- matrix( c( 0.01, 0,
0, 0.04), nrow = 2, byrow = TRUE)
A <- matrix( c( 1, 1, 1,
0, 0, 1), nrow = 2, byrow = TRUE)
x <- c( 0.005, 0.01)
b <- c( 1, 0, 0)

86
CHAPTER 8. NUMERICAL OPTIMIZATION
(a) ans <- solve.QP(D, x, A, b, meq = 1)
ans$solution
## [1] 1.00 0.25
(b) ans <- solve.QP(2*D, x, A, b, meq = 1)
ans$solution
## [1] 1.000 0.125

