


OPERATIONS MANAGEMENT
Queueing problems
4–7, 788–806, 811–814,
817–830
Ordering problems (newsvendor)
23–27, 573–610, 
619, 736–739
Ordering with quantity discounts
40–44
Manufacturing operations
67–68, 329–334
Product mix problems
70–94, 100–107, 171–176,
306–318
Production scheduling
108–117, 152–162,
442–447, 620, 632–637
Production, inventory management
133–134, 
16-37–16-39
Scheduling workers
145–151
Aggregate planning
152–162
Gasoline, oil blending
163–170, 212–214
Logistics problems
227–228, 229–240, 248–256
Assigning workers to jobs
241–243
Assigning school buses to routes
243–247
Finding a shortest route
257–261
Equipment replacement
261–266
Airline crew scheduling
267–272
Airline ﬂight scheduling
273–280
Global manufacturing and distribution
288–289
Motor carrier selection
290–292
Airline hub location
319–324
Locating plants and warehouses
324–328, 388–392
Cutting stock problems
335–339
Plant expansion and retooling
350–351
Selecting telecommunication carriers
352
Telephone call processing
836–837
Railway planning
421–422
Loading a gas truck
438–442
Traveling salesperson problem
464–467
Determining trade–off between proﬁt 
and pollution
16-15–16-18
Airline boarding strategies
551–552
Deming’s funnel experiment
637–641
Global supply chain decisions
713–714
Economic order quantity models
718–734
Ordering decisions with demand uncertainty
740–754
Production planning in fashion industry
755–760
Managing supply chain inventory
760–764
Reducing work in progress
773–774
Operations at banks
838–839
Scheduling multiple projects
15-1–15-2, 
15-25–15-28
Project scheduling with CPM
15-8–15-24, 
15-30–15-34
Forecasting problems
848–853, 879–883, 
885–895, 906
SPORTS AND GAMES
Rating NFL teams
393–397
Playing craps
682–685
NCAA basketball tournament
685–689
MISCELLANEOUS
Investment in U.S. Space Systems
293–294
Prioritizing projects at NASA
16-1–16-2
Biotechnical engineering
549–550
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

       This is an electronic version of the print textbook. Due to electronic rights restrictions,
some third party content may be suppressed. Editorial review has deemed that any suppressed 
content does not materially affect the overall learning experience. The publisher reserves the right 
to remove content from this title at any time if subsequent rights restrictions require it. For
valuable information on pricing, previous editions, changes to current editions, and alternate 
formats, please visit www.cengage.com/highered to search by ISBN#, author, title, or keyword for 
materials in your areas of interest.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Practical Management Science
Wayne L. Winston
Kelley School of Business, Indiana University
S. Christian Albright
Kelley School of Business, Indiana University
With Cases by
Mark Broadie
Graduate School of Business, Columbia University
Lawrence L. Lapin
San Jose State University
William D. Whisler
California State University, Hayward
4TH
EDITION
Australia • Brazil • Japan • Korea • Mexico • Singapore • Spain • United Kingdom • United States
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Practical Management Science, 
Fourth Edition
Wayne L. Winston,
S. Christian Albright
Vice President of Editorial, Business: 
Jack W. Calhoun
Editor-in-Chief: 
Joe Sabatino
Senior Acquisitions Editor: 
Charles McCormick Jr.
Senior Developmental Editor: 
Laura Boﬁnger Ansara
Editorial Assistants: 
Nora Heink, Courtney Bavaro
Marketing Communications Manager: 
Libby Shipp
Marketing Manager: 
Adam Marsh
Senior Content Project Manager: 
Holly Henjum
Media Editor: 
Chris Valentine
Senior Buyer, Manufacturing: 
Miranda Klapper
Production Service: 
MPS Limited, a Macmillan Company
Art Director: 
Stacy Jenkins Shirley
Cover Designer: 
Lou Ann Thesing
Cover Image: 
iStock Photo
Rights Acquisitions Specialist: 
John Hill
© 2012, 2009 South-Western, Cengage Learning
ALL RIGHTS RESERVED. No part of this work covered by the copyright
herein may be reproduced, transmitted, stored, or used in any form or by
any means graphic, electronic, or mechanical, including but not limited to
photocopying, recording, scanning, digitizing, taping, web distribution,
information networks, or information storage and retrieval systems, except
as permitted under Section 107 or 108 of the 1976 United States Copyright
Act, without the prior written permission of the publisher.
ExamView® is a registered trademark of eInstruction Corp. Windows 
is a registered trademark of the Microsoft Corporation used herein 
under license. Macintosh and Power Macintosh are registered 
trademarks of Apple Computer, Inc. used herein under license.
Library of Congress Control Number: 2011922240
Student Edition PKG ISBN-13: 978-1-111-53131-7
Student Edition PKG ISBN-10: 1-111-53131-5
Student Edition ISBN-13: 978-1-111-53127-0
Student Edition ISBN-10: 1-111-53127-7
South-Western 
5191 Natorp Boulevard
Mason, OH 45040
USA
Cengage Learning products are represented in Canada by 
Nelson Education, Ltd.
For your course and learning solutions, visit 
www.cengage.com
Purchase any of our products at your local college store or at our preferred
online store www.cengagebrain.com
For product information and technology assistance, contact us 
at Cengage Learning Customer & Sales Support, 1-800-354-9706
For permission to use material from this text or product,
submit all requests online at www.cengage.com/permissions
Further permissions questions can be emailed to
permissionrequest@cengage.com
Printed in the United States of America
1 2 3 4 5 6 7 15 14 13 12 11
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

To Mary, my wonderful wife, best friend, and constant companion
And to our Welsh Corgi, Bryn, who still just wants to play ball
S.C.A.
To my wonderful family
Vivian, Jennifer, and Gregory
W.L.W.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

S. Christian Albright got his B.S. degree in Mathematics from
Stanford in 1968 and his Ph.D. degree in Operations Research
from Stanford in 1972. Since then he has been teaching in the
Operations & Decision Technologies Department in the Kelley
School of Business at Indiana University. He has taught courses in
management science, computer simulation, and statistics to all
levels of business students: undergraduates, MBAs, and doctoral
students. He has also taught courses on database analysis to
the U.S. Army. He has published over 20 articles in leading
operations research journals in the area of applied probability,
and he has authored several books, including Practical Management Science, Data
Analysis and Decision Making, Data Analysis for Managers, Spreadsheet Modeling
and Applications, and VBA for Modelers. He jointly developed StatTools, a statistical
add-in for Excel, with the Palisade Corporation. His current interests are in spreadsheet
modeling and the development of VBA applications in Excel, as well as Web programming
with Microsoft’s .NET technology.
On the personal side, Chris has been married to his wonderful wife Mary for
40 years. They have one son, Sam, who is currently ﬁnishing a law degree at Penn Law
School. Chris has many interests outside the academic area. They include activities with
his family (especially traveling with Mary), going to cultural events at Indiana University,
playing golf and tennis, power walking, and reading. And although he earns his
livelihood from statistics and management science, his real passion is for playing
classical music on the piano.
Wayne L. Winston is Professor of Operations & Decision
Technologies in the Kelley School of Business at Indiana
University, where he has taught since 1975. Wayne received his
B.S. degree in Mathematics from MIT and his Ph.D. degree in
Operations Research from Yale. He has written the successful
textbooks Operations Research: Applications and Algorithms,
Mathematical Programming: Applications and Algorithms,
Simulation Modeling Using @RISK, Data Analysis and
Decision Making, and Financial Models Using Simulation and
Optimization. Wayne has published over 20 articles in leading
journals and has won many teaching awards, including the schoolwide MBA award four
times. He has taught classes at Microsoft, GM, Ford, Eli Lilly, Bristol-Myers Squibb,
Arthur Andersen, Roche, PriceWaterhouseCoopers, and NCR. His current interest is in
showing how spreadsheet models can be used to solve business problems in all
disciplines, particularly in ﬁnance and marketing.
Wayne enjoys swimming and basketball, and his passion for trivia won him an
appearance several years ago on the television game show Jeopardy, where he won two
games. He is married to the lovely and talented Vivian. They have two children, Gregory
and Jennifer.
About the Authors
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

v
Preface
xi
1 Introduction to Modeling
1
2 Introduction to Spreadsheet Modeling
21
3 Introduction to Optimization Modeling
67
4 Linear Programming Models
133
5 Network Models
227
6 Optimization Models with Integer Variables
293
7 Nonlinear Optimization Models
353
8 Evolutionary Solver: An Alternative Optimization Procedure
421
9 Decision Making Under Uncertainty
475
10 Introduction to Simulation Modeling
551
11 Simulation Models
621
12 Inventory Models
713
13 Queueing Models
773
14 Regression and Forecasting Models
841
References
907
Index
913
Online Chapters
15 Project Management
15-1
16 Multiobjective Decision Making
16-1
Brief Contents
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

vii
Preface xi
CHAPTER 1 Introduction to Modeling 1
1.1 Introduction 3
1.2 A Waiting-Line Example 4
1.3 Modeling Versus Models 7
1.4 The Seven-Step Modeling Process 8
1.5 A Great Source for Management Science
Applications: Interfaces 14
1.6 Why Study Management Science? 14
1.7 Software Included with This Book 16
1.8 Conclusion 18
CHAPTER 2 Introduction to Spreadsheet 
Modeling 21
2.1 Introduction 22
2.2 Basic Spreadsheet Modeling: Concepts and 
Best Practices 22
2.3 Cost Projections 27
2.4 Breakeven Analysis 31
2.5 Ordering with Quantity Discounts and Demand
Uncertainty 40
2.6 Estimating the Relationship between Price and
Demand 45
2.7 Decisions Involving the Time Value of 
Money 55
2.8 Conclusion 61
Appendix  Tips for Editing and Documenting
Spreadsheets 65
CHAPTER 3 Introduction to Optimization 
Modeling 67
3.1 Introduction 68
3.2 Introduction to Optimization 69
3.3 A Two-Variable Product Mix Model 70
3.4 Sensitivity Analysis 83
3.5 Properties of Linear Models 94
Contents
3.6 Infeasibility and Unboundedness 97
3.7 A Larger Product Mix Model 100
3.8 A Multiperiod Production Model 108
3.9 A Comparison of Algebraic and Spreadsheet
Models 118
3.10 A Decision Support System 118
3.11 Conclusion 121
Appendix  Information on Solvers 128
CASE 3.1 Shelby Shelving 129
CASE 3.2 Sonoma Valley Wines 131
CHAPTER 4 Linear Programming Models 133
4.1 Introduction 134
4.2 Advertising Models 135
4.3 Worker Scheduling Models 145
4.4 Aggregate Planning Models 152
4.5 Blending Models 163
4.6 Production Process Models 171
4.7 Financial Models 177
4.8 Data Envelopment Analysis (DEA) 188
4.9 Conclusion 195
CASE 4.1 Amarco, Inc. 212
CASE 4.2 American Ofﬁce Systems, Inc. 215
CASE 4.3 Lakeﬁeld Corporation’s Oil Trading 
Desk 220
CASE 4.4 Foreign Currency Trading 225
CHAPTER 5 Network Models 227
5.1 Introduction 228
5.2 Transportation Models 229
5.3 Assignment Models 241
5.4 Other Logistics Models 248
5.5 Shortest Path Models 257
5.6 Network Models in the Airline 
Industry 267
5.7 Conclusion 281
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

8.8 Cluster Analysis 455
8.9 Discriminant Analysis 461
8.10 The Traveling Salesperson Problem 464
8.11 Conclusion 469
CASE 8.1 Assigning MBA Students to Teams 474
CHAPTER 9 Decision Making under 
Uncertainty 475
9.1 Introduction 476
9.2 Elements of Decision Analysis 478
9.3 The PrecisionTree Add-In 492
9.4 Bayes’ Rule 505
9.5 Multistage Decision Problems 509
9.6 Incorporating Attitudes toward Risk 525
9.7 Conclusion 533
CASE 9.1 Jogger Shoe Company 547
CASE 9.2 Westhouser Paper Company 548
CASE 9.3 Biotechnical Engineering 549
CHAPTER 10 Introduction to Simulation 
Modeling 551
10.1 Introduction 552
10.2 Probability Distributions for 
Input Variables 554
10.3 Simulation and the Flaw of Averages 573
10.4 Simulation with Built-In Excel Tools 576
10.5 Introduction to @RISK 587
10.6 The Effects of Input Distributions 
on Results 603
10.7 Conclusion 612
CASE 10.1 Ski Jacket Production 619
CASE 10.2 Ebony Bath Soap 620
CHAPTER 11 Simulation Models 621
11.1 Introduction 623
11.2 Operations Models 623
11.3 Financial Models 642
11.4 Marketing Models 667
11.5 Simulating Games of Chance 682
11.6 An Automated Template for 
@RISK Models 690
viii
Contents
CASE 5.1 International Textile Company,
Ltd. 288
CASE 5.2 Optimized Motor Carrier Selection at
Westvaco 290
CHAPTER 6 Optimization Models with Integer
Variables 293
6.1 Introduction 294
6.2 Overview of Optimization with Integer 
Variables 295
6.3 Capital Budgeting Models 299
6.4 Fixed-Cost Models 306
6.5 Set-Covering and Location-Assignment 
Models 319
6.6 Cutting Stock Models 335
6.7 Conclusion 340
CASE 6.1 Giant Motor Company 350
CASE 6.2 Selecting Telecommunication Carriers to
Obtain Volume Discounts 352
CHAPTER 7 Nonlinear Optimization Models 353
7.1 Introduction 354
7.2 Basic Ideas of Nonlinear Optimization 355
7.3 Pricing Models 361
7.4 Advertising Response and Selection 
Models 379
7.5 Facility Location Models 388
7.6 Models for Rating Sports Teams 393
7.7 Portfolio Optimization Models 398
7.8 Estimating the Beta of a Stock 407
7.9 Conclusion 412
CASE 7.1 GMS Stock Hedging 419
CHAPTER 8 Evolutionary Solver: An Alternative
Optimization Procedure 421
8.1 Introduction 422
8.2 Introduction to Genetic Algorithms 425
8.3 Introduction to Evolutionary Solver 426
8.4 Nonlinear Pricing Models 431
8.5 Combinatorial Models 438
8.6 Fitting an S-Shaped Curve 448
8.7 Portfolio Optimization 452
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Contents
ix
11.7 Using TopRank with 
@RISK for Powerful Modeling 691
11.8 Conclusion 699
CASE 11.1 College Fund Investment 710
CASE 11.2 Bond Investment Strategy 711
CHAPTER 12 Inventory Models 713
12.1 Introduction 714
12.2 Categories of Inventory Models 715
12.3 Types of Costs in Inventory Models 717
12.4 Economic Order Quantity (EOQ) Models 718
12.5 Probabilistic Inventory Models 736
12.6 Ordering Simulation Models 749
12.7 Supply Chain Models 754
12.8 Conclusion 765
CASE 12.1 Subway Token Hoarding 772
CHAPTER 13 Queueing Models 773
13.1 Introduction 774
13.2 Elements of Queueing Models 776
13.3 The Exponential Distribution 779
13.4 Important Queueing Relationships 784
13.5 Analytical Steady-State Queueing Models 787
13.6 Approximating Short-Run Behavior 
Analytically 809
13.7 Queueing Simulation Models 815
13.8 Conclusion 831
CASE 13.1 Catalog Company Phone Orders 836
CASE 13.2 Paciﬁc National Bank 838
CHAPTER 14 Regression and Forecasting 
Models 841
14.1 Introduction 843
14.2 Overview of Regression Models 844
14.3 Simple Regression Models 848
14.4 Multiple Regression Models 861
14.5 Overview of Time Series Models 874
14.6 Moving Averages Models 878
14.7 Exponential Smoothing Models 884
14.8 Conclusion 897
CASE 14.1 Demand for French Bread at Howie’s
Bakery 904
CASE 14.2 Forecasting Overhead at Wagner
Printers 905
CASE 14.3 Arrivals at the Credit Union 906
Online Chapters
CHAPTER 15 Project Management 15-1
15.1 Introduction 15-2
15.2 The Basic CPM Model 15-4
15.3 Modeling Allocation of Resources 15-14
15.4 Models with Uncertain Activity Times 15-30
15.5 A Brief Look at Microsoft Project 15-35
15.6 Conclusion 15-38
CHAPTER 16 Multiobjective Decision Making 16-1
16.1 Introduction 16-2
16.2 Goal Programming 16-3
16.3 Pareto Optimality and Trade-Off Curves 16-13
16.4 The Analytic Hierarchy Process (AHP) 16-22
16.5 Conclusion 16-32
CASE 16.1 Play Time Toy Company 16-37
References 907
Index 913
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

xi
Practical Management Science provides a spreadsheet-
based, example-driven approach to management
science. Our initial objective in writing the book was to
reverse negative attitudes about the course by making
the subject relevant to students. We intended to do this
by imparting valuable modeling skills that students can
appreciate and take with them into their careers. We are
very gratiﬁed by the success of the ﬁrst three editions.
The book has exceeded our initial objectives. We are
especially pleased to hear about the success of the book
at many other colleges and universities around the
world. The acceptance and excitement that has been
generated has motivated us to revise the book and make
the fourth edition even better.
When we wrote the first edition, management
science courses were regarded as irrelevant or
uninteresting to many business students, and the use of
spreadsheets in management science was in its early
stages of development. Much has changed since the
ﬁrst edition was published in 1996, and we believe that
these changes are for the better. We have learned a lot
about the best practices of spreadsheet modeling for
clarity and communication. We have also developed
better ways of teaching the materials, and we
understand more about where students tend to have
difficulty with the concepts. Finally, we have had
the opportunity to teach this material at several
Fortune 500 companies (including Eli Lilly, Price
Waterhouse Coopers, General Motors, Tomkins,
Microsoft, and Intel). These companies, through their
enthusiastic support, have further enhanced the
realism of the examples included in this book.
Our objective in writing the ﬁrst edition was very
simple—we wanted to make management science
relevant and practical to students and professionals.
This book continues to distinguish itself in the market
in four fundamental ways:
■
Teach by Example. The best way to learn
modeling concepts is by working through
examples and solving an abundance of problems.
This active learning approach is not new, but our
text has more fully developed this approach than
any book in the ﬁeld. The feedback we have
received from many of you has conﬁrmed the
success of this pedagogical approach for
management science.
■
Integrate Modeling with Finance, Marketing,
and Operations Management. We integrate
modeling into all functional areas of business.
This is an important feature because the majority
of business students major in ﬁnance and
marketing. Almost all competing textbooks
emphasize operations management–related
examples. Although these examples are
important, and many are included in the book,
the application of modeling to problems in
ﬁnance and marketing is too important to ignore.
Throughout the book, we use real examples from
all functional areas of business to illustrate the
power of spreadsheet modeling to all of these
areas. At Indiana University, this has led to the
development of two advanced MBA electives
in ﬁnance and marketing that build upon the
content in this book. The inside front cover of
the book illustrates the integrative applications
contained in the book. 
■
Teach Modeling, Not Just Models. Poor attitudes
among students in past management science
courses can be attributed to the way in which they
were taught: emphasis on algebraic formulations
and memorization of models. Students gain more
insight into the power of management science by
developing skills in modeling. Throughout the
book, we stress the logic associated with model
development, and we discuss solutions in this
context. Because real problems and real models
often include limitations or alternatives, we
include many “Modeling Issues” sections to
discuss these important matters. Finally, we
include “Modeling Problems” in most chapters to
help develop these skills.
■
Provide Numerous Problems and Cases.
Whereas all textbooks contain problem sets for
students to practice, we have carefully and
judiciously crafted the problems and cases
contained in this book. Each chapter contains
four types of problems: Skill-Building Problems,
Skill-Extending Problems, Modeling Problems,
and Cases. Most of the problems following
sections of chapters ask students to extend the
examples in the preceding section. The end-of-
chapter problems then ask students to explore
Preface
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

xii
Preface
new models. Selected solutions are available to
students who purchase the Student Solution Files
online and are denoted by the second-color
numbering of the problem. Solutions for all of
the problems and cases are provided to adopting
instructors. In addition, shell ﬁles (templates) are
available for most of the problems for adopting
instructors. The shell ﬁles contain the basic
structure of the problem with the relevant
formulas omitted. By adding or omitting hints in
individual solutions, instructors can tailor these
shell ﬁles to best meet the individual/speciﬁc
needs of their students.
New to the Fourth Edition
The main reason for the fourth edition was the
introduction of Excel 2010. Admittedly, this is not
nearly as much a game changer as Excel 2007, but it
does provide new features that ought to be addressed.
In addition, once we were motivated by Excel 2010 to
revise the book, we saw the possibility for a lot of
other changes that will hopefully improve the book.
Important changes to the fourth edition include the
following:
■
Undoubtedly, the biggest change in Excel 2010,
the one that affects our book the most, is the new
Solver add-in. Frontline Systems, the develop of
Solver, swapped the previous version of Solver
for what we used to provide separately: Premium
Solver. Now all Excel 2010 users have essentially
the old Premium Solver. (Therefore, we no longer
provide an academic version of Premium Solver
with the book.) As discussed in detail in the
optimization chapters, the new Solver provides
several important enhancements: (1) It has a
nicer, more compact user interface; (2) it appears
to work better, giving many fewer “conditions
for linear model not satisﬁed” messages for
models that are indeed linear; and (3) it includes
Evolutionary Solver, which we continue to use
for difﬁcult non-smooth models in Chapter 8.
■
To make the book somewhat shorter, we moved
the old chapters 9 (Multiobjective Decision
Making) and 15 (Project Management) online,
renumbering the former as 16. Based on user
reports, these are two of the less-covered
chapters in the book, but they are still available
online if you want to use them. Of course, the
remaining chapters have been renumbered
accordingly. (Both chapters are found on the
Instructor web site and the students’ Essential
Resource Web site. Instructions for access to
these sites are described later in this preface.)
■
In the ﬁrst optimization chapter, Chapter 3, we
replaced the introductory two-variable diet
model with a simpler two-variable product mix
model. Then we follow it up with a larger
version of the same basic product mix model. We
believe this should make the introduction to
optimization easier for instructors to teach and
for students to follow.
■
In the regression and forecasting chapter, now
numbered Chapter 14, we discontinued the use
of the Analysis Toolpak and jumped directly into
the Palisade StatTools add-in. We believe that
StatTools is vastly superior to Analysis Toolpak,
so we decided to take full advantage of it.
■
One of the main strengths of this book has
always been its numerous problems. However,
some of these had been around for over a decade
and were either totally out of date or required
better data. Therefore, we deleted some
problems, added some brand new ones, and
changed the input data for many others. We have
included a ﬁle for instructors, PMS4e Problem
Database.xlsx, that lists all of the changes.
■
One last change didn’t make it into the book, but
we are offering it on a limited trial basis to
instructors. Speciﬁcally, we have added several
large optimization models (more changing cells
than Solver can handle) to the instructor
materials. (They are under Extra subfolders in
the Example Files folders.) The motivation for
these additions is to let students experience what
it is like for managers who do not have access to
optimization software. What kinds of heuristics
might they use? Will these heuristics get
anywhere near optimality? For comparison, we
have provided optimal solutions. If nothing else,
we believe these examples might make students
appreciate the true power of optimization
software such as Solver.
The Essential Resource Web Site
for Students
The tools offered with the fourth edition of Practical
Management Science extend beyond the textbook.
Students purchasing a new textbook receive access to
the Essential Resource Web site that accompanies this
book. For students who do not purchase a new
textbook, there are other access and product options
available at CengageBrain.com. 
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Preface
xiii
Software
We continue to be very excited about offering the most
comprehensive suite of software ever available with a
management science textbook. The commercial value
of the software available with this text exceeds $1000
if purchased directly. This software is available free
with new copies of the fourth edition. The following
Palisade software is available from a link that is
provided on the Essential Resource Web site: 
■
Palisade’s DecisionTools™Suite, including the
award-winning @RISK, PrecisionTree,
StatTools, TopRank, RISKOptimizer,
NeuralTools, and Evolver. This software is not
available with any competing textbook and comes
in an educational version that is only slightly
scaled down from the expensive commercial
version. (StatTools replaces Albright’s StatPro
add-in that came with the second edition. If you
are interested, StatPro is still freely available from
http://www.kelley.iu.edu/albrightbooks, although
it will not be updated for Excel 2007 or 2010.)
For more information about the Palisade
Corporation and the DecisionTools Suite, visit
Palisade’s Web site at http://www.palisade.com.
■
To make sensitivity analysis useful and intuitive,
we continue to provide Albright’s SolverTable
add-in (which is also freely available from
http://www.kelley.iu.edu/albrightbooks).
SolverTable provides data table–like sensitivity
output for optimization models that is easy to
interpret.
Example Files, Data Sets, Problem Files,
and Cases
Also on the Essential Resource Web site are the Excel
ﬁles for all of the examples in the book, as well as many
data files required for problems and cases. As in
previous editions, there are two versions of the example
ﬁles: a completed version and a template to get students
started. Because this book is so example- and problem-
oriented, these files are absolutely essential. For
instructors, there is a third annotated version of each
example ﬁle that provides even more insights into the
model.
How to Access the Essential Resource Web Site 
Student Access: Students are given access instructions
to the Essential Resource Web site via the bind-in
card in new editions of their book. Go to http://
login.cengagebrain.com, click on “Create an
Account,” and then, in the space provided, enter the
unique access code found on the access card bound in
your new book. Students who do not buy a new,
printed textbook may search CengageBrain.com for
other purchase options, such as CourseMate, which
offers an eBook format of the book with access to the
Essential Resource Web site.
Instructor Access: Go to http://login.cengage.com.
Use your current user account to sign in. If you do not
have an account, follow the screen instructions to create
one. Veriﬁcation of instructor status takes 24 to 48 hours
for new accounts. Once you are logged in, type this
textbook’s ISBN number in the search box. (The ISBN
is found on the back of your textbook.) You are then
presented with selection options to add to your
“Bookshelf,” such as the Instructor Web site, Student
Essentials Resource Web site, and CourseMate (if
applicable to your class). Your selections will show up
on your account home page for access to instructor and
student materials.
Ancillaries
Instructor Materials
Adopting instructors can obtain the Instructors’
Resource CD (IRCD) from your regional Cengage
Learning sales representative. The IRCD includes:
■
PMS4e Problem Database.xlsx ﬁle, which
contains information about all problems in the
book and the correspondence between them and
those in the previous edition
■
Solution ﬁles (in Excel format) for all of the
problems and cases in the book and solution
shells (templates) for selected problems in the
modeling chapters
■
PowerPoint® presentation ﬁles 
■
Test Bank in Word format and now also in
ExamView Testing Software
Instructor ancillaries are also posted on the Instructor
Web site. Access instructions are described in the
previous section. Albright also maintains his own Web
site at http://www.kelley.iu.edu/albrightbooks. Among
other things, this site includes errata for each edition.
Student Solutions
Student Solutions for many of the odd-numbered
problems (indicated in the text with a colored box on
the problem number) are available in Excel format.
Students can purchase access to Student Solutions
Files on CengageBrain.com. In the search window of
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

xiv
Preface
this Web site, type in this book’s ISBN number (found
on the back cover of your book) and hit enter. A
product page will show you “Related Products” you
can purchase, including the Student Solutions.
Companion VBA Book
Soon after the ﬁrst edition appeared, we began using
Visual Basic for Applications (VBA), the program-
ming language for Excel, in some of our management
science courses. VBA allows you to develop decision
support systems around the spreadsheet models. (An
example appears at the end of Chapter 3.) This use of
VBA has been popular with our students, and many
instructors have expressed interest in learning how to
do it. For additional support on this topic, a companion
book, VBA for Modelers, 3e (ISBN 1-4390-7984-6) is
available. It assumes no prior experience in computer
programming, but it progresses rather quickly to the
development of interesting and nontrivial applications.
The fourth edition of Practical Management Science
depends in no way on this companion VBA book, but
we encourage instructors to incorporate some VBA
into their management science courses. This is not
only fun, but students quickly learn to appreciate its
power. If you are interested in adopting VBA for
Modelers, contact your local Cengage Learning
representative.
Acknowledgments
This book has gone through several stages of reviews,
and it is a much better product because of them. The
majority of the reviewers’ suggestions were very good
ones, and we have attempted to incorporate them. We
would like to extend our appreciation to:
Sue Abdinnour, Wichita State University
Robert Aboolian, California State University–San
Marcos
Mohammad Ahmadi, University of Tennessee at
Chattanooga
Kelly Alvey, Old Dominion University 
Jerry Bilbrey, Anderson University
Fattaneh Cauley, Pepperdine University
Gordon Corzine, University of Massachusetts–Boston
Parthasarati Dileepan, University of Tennessee  at
Chattanooga
Ehsan Elahi, University of Massachusetts–Boston
Kathryn Ernstberger, Indiana University Southeast
Levon R. Hayrapetyan, Houston Baptist University
Max Peter Hoefer, Pace University
Harvey Iglarsh, Georgetown University
D. K. Kim, Dalton State College
Mary Kurz, Clemson University
Larry J. LeBlanc, Vanderbilt University
Stephen Mahar, University of North
Carolina–Wilmington
James Morris, University of Wisconsin–Madison
Khosrow Moshirvaziri, Caliornia State
University–Long Beach
Ozgur Ozluk, San Francisco State University
Susan Palocsay, James Madison University
Prakash P. Shenoy, University of Kansas
Ekundayo Shittu, Tulane University
Steven Slezak, California Polytechnic State
University–San Luis Obispo
Christine Spencer, University of Baltimore
Robert Stoll, Cleveland State University
Charles Watts, John Carroll University
Yuri Yatsenko, Houston Baptist University
We would also like to thank two special people.
First, we want to thank our previous editor Curt
Hinrichs. Although Curt has moved from this position
and is no longer our editor, his vision in the early years
was largely responsible for the success of the ﬁrst and
second editions of Practical Management Science.
Second, we were lucky to move from one great editor
to another in Charles McCormick Jr. Charles is a
consummate professional, he is both patient and
thorough, and his experience in the publishing
business ensures that the tradition Curt started will be
carried on.
In addition, we would like to thank Marketing
Manager, Adam Marsh; Senior Developmental Editor,
Laura Ansara; Content Project Manager, Holly
Henjum; Art Director, Stacy Shirley; Editorial
Assistants, Nora Heink and Courtney Bavaro; and
Project Manager at MPS, Gunjan Chandola.
We would also enjoy hearing from you—we can
be reached by e-mail. And please visit either of the
following Web sites for more information and
occasional updates: 
■
http://www.kelley.iu.edu/albrightbooks
■
CengageBrain.com
Wayne L. Winston (winston@indiana.edu)
S. Christian Albright (albright@indiana.edu)
Bloomington, Indiana
January 2011 
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

1
Introduction to Modeling 
C H A P T E R
COMPLEX ALGORITHMS AND                         T HE “SOFTO
 R”
APPR     OACH SOLVE REAL-W          ORLD PR       OBLEMS
A
s you embark on your study of management science, you might question
the usefulness of quantitative methods to the “real world.” A front-page 
article in the December 31,1997,edition of USA Today entitled “Higher Math 
Delivers Formula for Success” provides some convincing evidence of the applica-
bility of the methods you will be learning. (More recent evidence that math skills
continue to be valuable can be found in the January 23,2006,Business Week
cover story “Math Will Rock Your World.” You can find this article by doing a
Web search for the title.) The subheading of the article,“Businesses turn to algo-
rithms to solve complex problems,” says it all. Today’s business problems tend to
be very complex.In the past,many managers and executives used a “seat of the
pants” approach to solve problems—that is,they used their business experience,
their intuition,and some thoughtful guesswork to solve problems.But common
sense and intuition go only so far in the solution of the complex problems busi-
nesses now face. This is where management science models—and the algo-
rithms mentioned in the title of the article—are so useful.When the methods in
this book are implemented in user-friendly computer software packages that are
applied to complex problems,the results can be amazing.Robert Cross,whose
company,DFI Aeronomics,sells algorithm-based systems to airlines,states it suc-
cinctly:“It’s like taking raw information and spinning money out of it.”
1
Monkey Business Images/2010/Used under license from Shutterstock.com
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

The methods in this book are powerful because they apply to so many problems
and environments. The article mentions the following “success stories” in which manage-
ment science has been applied; others will be discussed throughout this book.
■
United Airlines installed one of DFI’s systems,which cost between 
$10 million and $20 million.United expected the system to add $50 million to 
$100 million annually to its revenues.
■
The Gap clothing chain uses management science to determine exactly how many
employees should staff each store during the holiday rush.
■
Management science has helped medical researchers test potentially dangerous drugs
on fewer people with better results.
■
IBM obtained a $93 million contract to build a computer system for the U.S.
Department of Energy that would do a once-impossible task: make exact real-time
models of atomic blasts. It won the contract—and convinced the DOE that its sys-
tem was cost-effective—only by developing management science models that would
cut the processing time by half.
■
Hotels,airlines,and television broadcasters all use management science to implement a
method called yield management.In this method,different prices are charged to different
customers,depending on their willingness to pay.The effect is that more customers are
attracted and revenues increase.
Although most of this book describes how quantitative methods can be used to solve
business problems, solutions do not always need to be quantitatively based. In a recent
article, Kimbrough and Murphy (2005), two academics located in Philadelphia, describe
how they were commissioned by the city to study the knowledge economy of the
region and make recommendations on ways to improve its rate of growth. Unlike
most of the success stories chronicled in the Interfaces journal (which is described in
section 1.5), the authors state right away that they used no quantitative methods or
mathematical models to develop recommendations for the city. Instead, they used a soft
OR approach.1 By this, they imply that they used a systematic approach to formulate and
solve their client’s problem, even though the approach does not employ quantitative
methods.
Specifically, Kimbrough and Murphy used two interrelated approaches in their study.
First, using ideas in the management science and economics literature, they developed a
comprehensive framework for thinking about regional economic development. This
allowed them to identify the many factors that influence a region’s economic vitality or
lack thereof. Second, they interviewed a wide range of people from the region, including
researchers in science and technology, business people, government officials, and acade-
mics. Instead of asking these people what ought to be done, they asked them to propose
ideas or policy initiatives that might improve the region’s economy. As they state, “The
results were gratifying. The framework we developed focuses people’s thinking on prob-
lems, bottlenecks, and leverage points in the knowledge economy. Asking for specific ideas
produced a rich and constructive list of more than 50 promising, realistic, and detailed
policy initiatives.”
However, the study went beyond brainstorming. After conducting the interviews
and analyzing the responses, the authors made specific recommendations to their client
2
Chapter 1
Introduction to Modeling
1OR is an abbreviation for operations research, another term for management science. Over the years, the two
terms have become practically synonymous, although some people in the field still prefer to be called manage-
ment scientists, whereas others prefer to be called operations researchers.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

on initiatives that might be implemented to improve the knowledge economy. Based on
these recommendations, the board of directors of Greater Philadelphia First adopted 
Six for Success, a strategy that commits leaders to (1) attract more research dollars and
expertise, (2) implement strategies to accelerate science and technology, (3) promote an
entrepreneurial climate, (4) launch a business marketing plan, (5) leverage quality-of-life
infrastructure and amenities, and (6) streamline and rationalize business-oriented non-
profits. Granted, these ideas are not necessarily groundbreaking, but they made sense to
leaders in Philadelphia. The important point is that they were developed through a
systematic approach to solving a problem—even if it wasn’t the quantitative approach
discussed through most of this book. ■
1.1 Introduction
3
1.1 INTRODUCTION
The purpose of this book is to expose you to a variety of problems that have been solved
successfully with management science methods and to give you experience in modeling
these problems in the Excel spreadsheet package. The subject of management science has
evolved for more than 60 years and is now a mature field within the broad category of
applied mathematics. This book will emphasize both the applied and mathematical aspects
of management science. Beginning in this chapter and continuing throughout the rest of
the book, we discuss many successful management science applications, where teams of
highly trained people have implemented solutions to the problems faced by major compa-
nies and have saved these companies millions of dollars. Many airlines and oil companies,
for example, could hardly operate as they do today without the support of management sci-
ence. In this book, we will lead you through the solution procedure of many interesting
and realistic problems, and you will experience firsthand what is required to solve these
problems successfully. Because we recognize that most of you are not highly trained in
mathematics, we use Excel spreadsheets to solve problems, which makes the quantitative
analysis much more understandable and intuitive.
The key to virtually every management science application is a mathematical
model. In simple terms, a mathematical model is a quantitative representation, or ideal-
ization, of a real problem. This representation might be phrased in terms of mathemati-
cal expressions (equations and inequalities) or as a series of interrelated cells in a
spreadsheet. We prefer the latter, especially for teaching purposes, and we concentrate
primarily on spreadsheet models in this book. However, in either case, the purpose of a
mathematical model is to represent the essence of a problem in a concise form. This has
several advantages. First, it enables managers to understand the problem better. In par-
ticular, the model helps to define the scope of the problem, the possible solutions, and
the data requirements. Second, it allows analysts to employ a variety of the mathemati-
cal solution procedures that have been developed over the past half century. These solu-
tion procedures are often computer intensive, but with today’s cheap and abundant
computing power, they are usually feasible. Finally, the modeling process itself, if done
correctly, often helps to “sell” the solution to the people who must work with the system
that is eventually implemented.
In this introductory chapter, we begin by discussing a relatively simple example of a
mathematical model. Then we discuss the distinction between modeling and a collection
of models. Next, we discuss a seven-step modeling process that is used, in essence if not in
strict conformance, in most successful management science applications. Finally, we discuss
why the study of management science is valuable, not only to large corporations, but also
to students like you who are about to enter the business world.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

1.2 A WAITING-LINE EXAMPLE
As indicated earlier, a mathematical model is a set of mathematical relationships that rep-
resent, or approximate, a real situation. Models that simply describe a situation are called
descriptive models. Other models that suggest a desirable course of action are called
optimization models. To get started, consider the following simple example of a mathe-
matical model. It begins as a descriptive model, but then becomes an optimization model.
Consider a convenience store with a single cash register. The manager of the store sus-
pects that customers are waiting too long in line at the checkout register and that these
excessive waiting times are hurting business. Customers who have to wait a long time
might not come back, and potential customers who see a long line might not enter the store
at all. Therefore, the manager builds a mathematical model to help understand the prob-
lem. The manager wants the model to reflect the current situation at the store, but it should
also suggest improvements to the current situation.
A Descriptive Model
This example is a typical waiting line, or queueing, problem. (Such problems are studied
in detail in Chapter 13.) The manager first wants to build a model that reflects the current
situation at the store. Later, he will alter the model to predict what might make the situation
better. To describe the current situation, the manager realizes that there are two important
inputs to the problem: (1) the arrival rate of potential customers to the store and (2) the rate
at which customers can be served by the single cashier. Clearly, as the arrival rate increases
and/or the service rate decreases, the waiting line will tend to increase and each customer
will tend to wait longer in line. In addition, more potential customers will probably decide
not to enter at all. These latter quantities (length of waiting line, time in line per customer,
fraction of customers who don’t enter) are commonly referred to as outputs. The manager
believes he has some understanding of the relationship between the inputs and the outputs,
but he is not at all sure how to quantify this relationship.
This is where a mathematical model is useful. By making several simplifying as-
sumptions about the nature of the arrival and service process at the store (as discussed in
Chapter 13), the inputs can be related to the outputs. In some cases, when the model is
sufficiently simple, it is possible to write an equation for an output in terms of the inputs.
For example, in one of the simplest queueing models, if A is the arrival rate of customers
per minute, S is the service rate of customers per minute, and W is the average time a typi-
cal customer waits in line (assuming that all potential customers enter the store), the
following relationship can be derived mathematically:
W  
S(S
A
 A)

(1.1)
This relationship is intuitive in one sense. It correctly predicts that as the service rate S
increases, the average waiting time W decreases. It also predicts that as the arrival rate A
increases, the average waiting time W increases. Finally, if the arrival rate is just barely less
than the service rate—that is, the difference S  A is positive but very small—the average
waiting time becomes quite large. [This model requires that the arrival rate be less than the
service rate; otherwise, Equation (1.1) makes no sense.]
In many other models, there is no such equation that relates outputs to inputs (or if
there is, it is too complex for the level of this book). Nevertheless, there may still be a
mathematical procedure for calculating outputs from inputs, and it may be possible to
implement this procedure in Excel. This is the case for the convenience store problem.
Again, by making certain simplifying assumptions, including the assumption that potential
4
Chapter 1
Introduction to Modeling
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

1.2 A Waiting-Line Example
5
1
2
3
4
5
6
7
8
9
10
11
B
A
Descripve queueing model for convenience store
Inputs
Arrival rate (customers per 
5.0
)
e
t
u
ni
m
Service rate (customers per 
4.0
)
e
t
u
ni
m
Maximum customers (before others go elsewhere)
5
Outputs
Average number in 
2
2.2
e
nil
Average me (minutes) spent in 
9
0.6
e
nil
Percentage of potenal arrivals who don't enter
27.1%
Figure 1.1
Descriptive
Queueing Model for
Convenience Store
customers will not enter if the waiting line is sufficiently long, it is possible to develop a
spreadsheet model of the situation at the store.
Before developing the spreadsheet model, however, we should discuss how the man-
ager obtains the inputs he needs. There are actually three inputs: (1) the arrival rate A,
(2) the service rate S, and (3) the number in the store, labeled N, that will induce future cus-
tomers not to enter. The first two of these can be measured with a timer. For example, the
manager can instruct an employee to measure the times between customer arrivals. Let’s
say the employee does this for several hours, and the average time between arrivals is
observed to be 2 minutes. Then the arrival rate can be estimated as A  12  0.5
(one customer every 2 minutes). Similarly, the employee can record the times it takes the
cashier to serve successive customers. If the average of these times (taken over many
customers) is, say, 2.5 minutes, then the service rate can be estimated as S  12.5  0.4
(one customer every 2.5 minutes). Finally, if the manager notices that potential customers
tend to take their business elsewhere when five customers are in line, he can let N  5.
These input estimates can now be entered in the spreadsheet model shown in Figure 1.1.
Don’t worry about the details of this spreadsheet—they are discussed in Chapter 13. The for-
mulas built into this spreadsheet reflect an adequate approximation of the convenience store’s
situation. For now, the important thing is that this model allows the manager to enter any sen-
sible values for the inputs in cells B4 through B6 and observe the resulting outputs in cells B9
through B11. The input values in Figure 1.1 represent the store’s current input values. These
values indicate that slightly more than two customers are waiting in line on average, an aver-
age customer waits slightly more than 6 minutes in line, and about 27% of all potential cus-
tomers do not enter the store at all (due to the perception that waiting times will be long).
The information in Figure 1.1 is probably of limited use to the manager. After all, he
probably already has a sense of how long waiting times are and how many customers are
being lost. The power of the model is that it allows the manager to ask many what-if ques-
tions. For example, what if he could somehow speed up the cashier, say, from 2.5 minutes
per customer to 1.8 minutes per customer? He might guess that the 28% decrease in the
average service time leads to a 28% decrease in all of the outputs. However, this reasonable
guess would be wrong, as shown in Figure 1.2. The average line length decreases to 1.41,
a 36% decrease; the average waiting time decreases to 3.22, a 47% decrease; and the
percentage of customers who do not enter decreases to 12.6%, a 54% decrease. To
1
2
3
4
5
6
7
8
9
10
11
B
A
Descripve queueing model for convenience store 
 
 
Inputs
Arrival rate (customers per minute) 
0.5
Service rate (customers per minute)
0.556
Maximum customers (before others go elsewhere)
5
Outputs
Average number in line
1.41
Average me (minutes) spent in line
3.22
Percentage of potenal arrivals who don't enter
 
12.6%
Figure 1.2
Queueing Model
with a Faster Service
Rate
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

illustrate an even more extreme change, suppose the manager could cut the service time in
half, from 2.5 minutes to 1.25 minutes. The spreadsheet in Figure 1.3 shows that the aver-
age number in line decreases to 0.69, a 69% decrease from the original value; the average
waiting time decreases to 1.42, a 77% decrease; and the percentage of customers who do
not enter decreases to 3.8%, a whopping 86% decrease. The important lesson to be learned
from the spreadsheet model is that as the manager increases the service rate, the output
measures improve more than he might have expected.
In reality, the manager would attempt to validate the spreadsheet model before trusting
its answers to these what-if questions. At the very least, the manager should examine the
reasonableness of the assumptions. For example, one assumption is that the arrival rate
remains constant for the time period under discussion. If the manager intends to use this
model—with the same input parameters—during periods of time when the arrival rate
varies a lot (such as peak lunchtime traffic followed by slack times in the early afternoon),
then he is almost certainly asking for trouble. Besides determining whether the assumptions
are reasonable, the manager can also check the outputs predicted by the model when the
current inputs are used. For example, Figure 1.1 predicts that the average time a customer
waits in line is approximately 6 minutes. At this point, the manager could ask his employee
to measure customers’ waiting times. If they average close to 6 minutes, the manager can
have more confidence in the model. However, if they average much more or much less than
6 minutes, the manager probably needs to modify the model.
An Optimization Model
So far, the model fails to reflect any economic information, such as the cost of speeding up
service, the cost of making customers wait in line, or the cost of losing customers. Given
the spreadsheet model developed previously, however, it is relatively easy to incorporate
economic information and then make rational choices. To keep this example simple,
assume that the manager can do one of three things: (1) leave the system as it is, (2) hire a
second person to help the first cashier process customers more quickly, or (3) lease a new
model of cash register that will speed up the service process significantly. The effect of
(2) is to decrease the average service time from 2.5 to 1.8 minutes. The effect of (3) is to
decrease the service time from 2.5 to 1.25 minutes. What should the manager do?
He needs to examine three types of costs. The first is the cost of hiring the extra person
or leasing the new cash register. These costs are probably known. For example, let’s
assume that the hourly wage for the extra person is $8, and the cost to lease a new cash reg-
ister (converted to a per-hour rate) is $11 per hour. The second type of cost is the “cost” of
making a person wait in line. Although this is not an out-of-pocket cost to the store, it does
represent the cost of potential future business—a customer who has to wait a long time might
not return. This cost is difficult to estimate on a per-minute or per-hour basis, but let’s assume
that it is approximately $13 per customer per hour in line.2 Finally, there is the opportunity
6
Chapter 1
Introduction to Modeling
2This charge is only for time in the queue. An alternative model is to charge for time in the queue and for time in
service.
1
2
3
4
5
6
7
8
9
10
11
B
A
Descripve queueing model for convenience store
 
Inputs
Arrival rate (customers per minute)
0.5
Service rate (customers per minute)
 
 
 
0.8
Maximum customers (before others go elsewhere)
 
5
Outputs
Average number in line
 
0.69
Average me (minutes) spent in line  
 
1.42
Percentage of potenal arrivals who don't enter
 
 
3.8%
Figure 1.3
Queueing Model
with an Even Faster
Service Rate
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

cost for customers who decide not to enter the store. The store loses not only their current
revenue but also potential future revenue if they decide never to return. Again, this is a dif-
ficult cost to measure, but let’s assume that it is approximately $25 per lost customer.
The next step in the modeling process is to combine these costs for each possible deci-
sion. Let’s find the total cost per hour for decision (3), where the new cash register is
leased. The lease cost is $11 per hour. From Figure 1.3, you can see that there is, on aver-
age, 0.69 customer in line at any time. Therefore, the average waiting cost per hour is
0.69($13)  $8.91. (This is because 0.69 customer-hour is spent in line each hour on aver-
age.) Finally, from Figure 1.3 you can see that the average number of potential arrivals per
hour is 60(12)  30, and 3.8% of them do not enter. Therefore, the average cost per hour
from lost customers is 0.038(30)($25)  $28.52. The combined cost for decision (3) is
$11  $8.91  $28.52  $48.43 per hour.
The spreadsheet model in Figure 1.4 incorporates these calculations and similar cal-
culations for the other two decisions. As you can see in row 24, the option to lease the new
cash register is the clear winner from a cost standpoint. However, if the manager wants to
see how sensitive these cost figures are to the rather uncertain input costs assessed for wait-
ing time and lost customers, it is simple to enter new values in rows 10 and 11 and see how
the “bottom lines” in row 24 change. This flexibility represents the power of spreadsheet
models. They not only allow you to build realistic and complex models, but they also allow
you to answer many what-if questions simply by changing input values.
1.3 Modeling Versus Models
7
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
D
C
B
A
Decision queueing model for convenience store
Inputs
Decision 1
Decision 2
Decision 3
Arrival rate (customers per minute)
0.5
0.5
0.5
Service rate (customers per minute)
0.8
0.556
0.4
Maximum customers (before others go elsewhere)
5
5
5
Cost of extra person per hour
$0
$8
$0
Cost of leasing new cash register per hour
$0
$0
$11
Cost per customer per hour waing in line
$13
$13
$13
Cost per customer who doesn't enter the store
$25
$25
$25
Outputs
Average number in line
0.69
1.41
2.22
Average me (minutes) spent in line
1.42
3.22
6.09
Percentage of potenal arrivals who don't enter
27.1%
12.6%
3.8%
Cost informaon
Cost of extra person per hour
$0
$8
$0
Cost of leasing new cash register per hour
$0
$0
$11
Cost per hour of waing me
$8.91
$18.31
$28.87
Cost per hour of lost customers
$203.29
$94.52
$28.52
Total cost per hour
$232.16
$120.82
$48.43
Figure 1.4
Queueing Model
with Alternative
Decisions
1.3 MODELING VERSUS MODELS
Management science, at least as it has been taught in many traditional courses, has evolved
as a collection of mathematical models. These include various linear programming models
(the transportation model, the diet model, the shortest route model, and others), inventory
models, queueing models, and so on. Much time has been devoted to teaching the intricacies
of these particular models. Management science practitioners, on the other hand, have justi-
fiably criticized this emphasis on specific models. They argue that the majority of real-world
management science problems cannot be neatly categorized as one of the handful of models
typically included in a management science textbook. That is, often no “off-the-shelf”
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

model can be used, at least not without modification, to solve a company’s real problem.
Unfortunately, management science students have gotten the impression that all problems
must be “shoe-horned” into one of the textbook models.
The good news is that this emphasis on specific models has been changing in the past
decade or two, and our goal in this book is to continue that change. Specifically, this book
stresses modeling, not models. The distinction between modeling and models will become
clear as you proceed through the book. Learning specific models is essentially a memoriza-
tion process—memorizing the details of a particular model, such as the transportation model,
and possibly learning how to “trick” other problems into looking like a transportation model.
Modeling, on the other hand, is a process, where you abstract the essence of a real problem
into a model, spreadsheet or otherwise. Although many problems fall naturally into several
categories, successful modelers do not try to shoe-horn each problem into one of a small
number of well-studied models. Instead, they treat each problem on its own merits and model
it appropriately, using all of the logical, analytical, or spreadsheet skills they have at their
disposal—and, of course, using their experience with previous models they have developed.
This way, if they come across a problem that does not look exactly like anything they have
ever seen, they still have the skills and flexibility to model it successfully.
This doesn’t mean you won’t learn some “classical” models from management sci-
ence in this book; in fact, we will discuss the transportation model in linear programming,
the M/M/1 model in queueing, the EOQ model in inventory, and other classics. These are
important models that should not be ignored; however, you certainly do not have to mem-
orize these specific models. They are simply a few of the many models you will learn how
to develop. The real emphasis throughout is on the modeling process—how a real-world
problem is abstracted into a spreadsheet model of that problem. We discuss this modeling
process in more detail in the following section.
1.4 THE SEVEN-STEP MODELING PROCESS
The discussion of the queueing model in section 1.2 presented some of the basic principles
of management science modeling. This section further expands on these ideas by charac-
terizing modeling as the following seven-step process.
Step 1: Problem Definition
The analyst first defines the organization’s problem. Defining the problem includes specify-
ing the organization’s objectives and the parts of the organization that must be studied before
the problem can be solved. In the simple queueing model, the organization’s problem is how
to minimize the expected net cost associated with serving customers.
Step 2: Data Collection
After defining the problem, the analyst collects data to estimate the value of parameters
that affect the organization’s problem. These estimates are used to develop a mathematical
model (step 3) of the organization’s problem and predict solutions (step 4). In the conve-
nience store queueing example, the manager needs to observe the arrivals and the checkout
process to estimate the arrival rate A, the service rate S, and possibly other inputs.
Step 3: Model Development
In the third step, the analyst develops a model of the problem. In this book, we present
many methods that can be used to model systems.3 Models such as the equation for W,
8
Chapter 1
Introduction to Modeling
3All of these models can generically be called mathematical models. However, because we implement them in
spreadsheets, we generally refer to them as spreadsheet models.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

where an equation is used to relate inputs such as A and S to outputs such as W, are called
analytical models. Most realistic applications are so complex, however, that an analytical
model does not exist or is too complex to work with. For example, if the convenience store
has more than one cash register and customers are allowed to join any line or jump from
one line to another, there is no tractable analytical model—no equation or system of
equations—that can be used to determine W from knowledge of A, S, and the number
of lines. When no tractable analytical model exists, the analyst must often rely instead on a
simulation model, which approximates the behavior of the actual system. Simulation
models are covered in Chapters 10 and 11.
Step 4: Model Verification
The analyst now tries to determine whether the model developed in the previous step is an
accurate representation of reality. A first step in determining how well the model fits real-
ity is to check whether the model is valid for the current situation. As discussed previously,
to validate the equation for the waiting time W, the manager might observe actual customer
waiting times for several hours. As we saw, the equation for W predicts that when A  0.5
and S  0.4, the average customer spends 6.09 minutes in line. Now suppose the manager
observes that 120 customers spend a total of 750 minutes in line. This indicates an average
of 750120  6.25 minutes in line per customer. Because 6.25 is reasonably close to 6.09,
the manager’s observations lend credibility to the model. In contrast, if the 120 customers
had spent 1,200 minutes total in line, for an average of 10 minutes per customer, this would
not agree very well with the model’s prediction of 6.09 minutes, and it would cast doubt on
the validity of the model.
Step 5: Optimization and Decision Making
Given a model and a set of possible decisions, the analyst must now choose the decision or
strategy that best meets the organization’s objectives. We briefly discussed an optimization
model for the convenience store example, and we will discuss many other optimization
models throughout the book.
Step 6: Model Communication to Management
The analyst presents the model and the recommendations from the previous steps to the
organization. In some situations, the analyst might present several alternatives and let the
organization choose the best one.
Step 7: Model Implementation
If the organization has accepted the validity and usefulness of the study, the analyst then
helps to implement its recommendations. The implemented system must be monitored
constantly (and updated dynamically as the environment changes) to ensure that the model
enables the organization to meet its objectives.
Flowchart of Procedure and Discussion of Steps
Figure 1.5 illustrates this seven-step process. As the arrows pointing down and to the left
indicate, there is certainly room for feedback in the process. For example, at various steps,
the analyst might realize that the current model is not capturing some key aspects of the
real problem. In this case, the problem definition can be changed or a new model can be
developed.
1.4 The Seven-Step Modeling Process
9
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

The following discussion explores these seven steps in more detail.
Step 1: Problem Definition
Typically, a management science model is initiated when an organization believes it has a
problem. Perhaps the company is losing money, perhaps its market share is declining, per-
haps its customers are waiting too long for service—any number of problems might be evi-
dent. The organization (which we refer to as the client) calls in a management scientist (the
analyst) to help solve this problem.4 In such cases, the problem has probably already been
defined by the client, and the client hires the analyst to solve this particular problem.
As Miser (1993) and Volkema (1995) point out, however, the analyst should do some
investigating before accepting the client’s claim that the problem has been properly
defined. Failure to do so could mean solving the wrong problem and wasting valuable
time, money, and energy.
For example, Miser cites the experience of an analyst who was hired by the military to
investigate overly long turnaround times between fighter planes landing and taking off
again to rejoin the battle. The military (the client) was convinced that the problem was
caused by inefficient ground crews—if they worked faster, turnaround times would cer-
tainly decrease. The analyst nearly accepted this statement of the problem and was about to
do classical time-and-motion studies on the ground crew to pinpoint the sources of their
inefficiency. However, by snooping around, he found that the problem lay elsewhere.
Specifically, he learned that the trucks that refueled the planes were frequently late, which
in turn was due to the inefficient way they were refilled from storage tanks at another loca-
tion. After this latter problem was solved—and its solution was embarrassingly simple—
the turnaround times decreased to an acceptable level without any changes on the part of
the ground crews. If the analyst had accepted the client’s statement of the problem, the real
problem would never have been located or solved.
The moral of this story is clear: If an analyst defines a problem incorrectly or too
narrowly, the solution to the real problem might never emerge. In his article, Volkema (1995)
advocates spending as much time thinking about the problem and defining it properly as
modeling and solving it. This is undoubtedly good advice, especially in real-world appli-
cations where problem boundaries are often difficult to define.
Step 2: Data Collection
This crucial step in the modeling process is often the most tedious. All organizations keep
track of various data on their operations, but the data are often not in the form the analyst
requires. In addition, data are often stored in different places throughout the organization
and in different formats. Therefore, one of the analyst’s first jobs is to gather exactly the
right data and put the data into an appropriate and consistent format for use in the model.
10
Chapter 1
Introduction to Modeling
Problem
definition
Data
collection
Model
development
Model
verification
Possible feedback loops
Optimization
and decision
making
Model
communication
to
management
Model
implementation
Figure 1.5
Flowchart for the Seven-Step Process
4Most organizations hire outside consultants, sometimes academics, to help solve problems. However, a number
of large organizations employ a staff of management scientists who function as inside consultants.
It is important to solve
the correct problem,
and defining that
problem is not always
easy.
The data collection
step often takes the
most time.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

This typically requires asking questions of key people (such as the cost accountants)
throughout the organization, studying existing organizational databases, and performing
time-consuming observational studies of the organization’s processes. In short, it typically
entails a lot of legwork.
In this book, as in most management science textbooks, we shield you from this
data-collection process by supplying the appropriate data to develop and solve a model.
Although this makes the overall modeling process seem easier than it really is, it is
impractical in most class setting to have you go to companies and gather data. (In many
cases, it would not even be allowed for proprietary reasons.) Nevertheless, we provide
some insights with “Where Do the Numbers Come From?” sections. If nothing else,
these sections remind you that in real applications, someone has to gather the necessary
data.
Step 3: Model Development
This step, along with step 5, is where the analyst brings his or her quantitative skills into
play. After defining the client’s problem and gathering the necessary data, the analyst must
develop a model of the problem. Several properties are desirable for a good model. First, it
should represent the client’s real problem accurately. If it uses a linear (straight-line) func-
tion for costs when the real cost function is highly nonlinear (curved), the recommenda-
tions of the model can be very misleading. Similarly, if the model ignores an important
constraint, such as an upper bound on capacity, its recommendations might not be possible
to implement.
On the other hand, the model should be as simple as possible. Most good models
(where “good” really means useful) capture the essence of the problem without getting
bogged down in less important details. They should be approximations of the real world,
not mirror images of every last detail. Overly complex models are often of little practical
use. First, overly complex models are sometimes too difficult to solve with the solution
algorithms available. Second, complex models tend to be incomprehensible to clients. If a
client cannot understand a model, the chances are that the model’s recommendations will
never be implemented. Therefore, a good model should achieve the right balance between
being too simple and too complex. This is often much easier said than done.
Step 4: Model Verification
This step is particularly important in real management science applications. A client is
much more likely to accept an analyst’s model if the analyst can provide some type of veri-
fication. This verification can take several forms. For example, the analyst can use the
model with the company’s current values of the inputs. If the model’s outputs are then in
line with the outputs currently observed by the client, the analyst has at least shown that the
model can duplicate the current situation.
A second way to verify a model is to enter several sets of input values (even if they 
are not the company’s current input values) and see whether the outputs from the model are
reasonable. One common approach is to use extreme values of the inputs to determine
whether the outputs behave as they should. For example, for the convenience store queue-
ing model, you could enter an extremely large service rate or a service rate just barely
above the arrival rate in the equation for W. In the first case, you would expect the average
waiting time to approach 0, whereas in the latter case, you would expect it to become very
large. You can use equation (1.1) for W to verify that this is exactly what happens. This
provides another piece of evidence that the model is reasonable.
If the model’s outputs for certain inputs are not as expected, there are two possible
causes. First, the model could be a poor approximation of the actual situation. In this case,
the analyst must refine the model until it lines up more accurately with reality. Second, the
model might be fine, but the analyst’s intuition might not be very good. That is, when
1.4 The Seven-Step Modeling Process
11
Steps 3 and 5,
developing and
optimizing models, are
the steps emphasized
most heavily in this
book.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

asked what he or she thinks would happen if certain input values are used, the analyst
might provide totally wrong predictions. In this case, the fault lies with the analyst, not
the model. Sometimes, good models prove that people’s ability to predict outcomes in
complex environments is lacking. In such cases, the verification step becomes harder
because of “political” reasons (office politics).
Step 5: Optimization and Decision Making
After the problem has been defined, the data has been collected, and the model has been
developed and verified, it is time to use the model to recommend decisions or strategies. In
the majority of management science models, this requires the optimization of an objective,
such as maximizing profit or minimizing cost.
The optimization phase is typically the most difficult phase from a mathematical
standpoint. Indeed, much of the management science literature (mostly from academics)
has focused on complex solution algorithms for various classes of models. Fortunately, this
research has led to a number of solution algorithms—and computer packages that imple-
ment these algorithms—that can be used to solve real problems. The most famous of these
is the simplex algorithm. This algorithm, which has been implemented by many commer-
cial software packages, including Excel’s Solver, is used on a daily basis to solve linear
optimization models for many companies. (We take advantage of the simplex method in
Chapters 3 through 5.)
Not all solution procedures find the optimal solution to a problem. Many models are
either too large or too complex to be solved exactly. Therefore, many complex problems
use heuristic methods to locate “good” solutions. A heuristic is a solution method that is
guided by common sense, intuition, and trial and error to achieve a good, but probably not
optimal, solution. Some heuristics are “quick and dirty,” whereas others are quite sophisti-
cated. As models become larger and more complex, good heuristics are sometimes the best
that can be achieved—and they are often perfectly adequate.
Step 6: Model Communication to Management
The analyst must eventually communicate a model and its recommendations to the client.
To appreciate this step, you must understand the large gap that typically exists between
management science analysts and the managers of organizations. Managers know their
business, but they often don’t understand much about mathematics or mathematical
models—even spreadsheet implementations of these models. The burden is therefore on the
analyst to present the model in terms that nonmathematical people can understand; other-
wise, a perfectly good model might never see the light of day.
The best strategy for successful presentation is to involve key people in the organiza-
tion, including top executives, in the project from the beginning. If these people have been
working with the analyst, helping to supply appropriate data and helping the analyst to
understand the way the organization really works, they are much more likely to accept the
eventual model. Step 6, therefore, should really occur throughout the modeling process,
not just toward the end.
The analyst should also try to make the model as intuitive and user-friendly as possi-
ble. Clients appreciate menu-driven systems with plenty of graphics. They also appreciate
the ability to ask what-if questions and get answers quickly in a form that is easy to under-
stand. This is one reason for developing spreadsheet models. Although not all models can
be developed in spreadsheets due to size and/or complexity, the spreadsheet approach in
this book is an excellent choice whenever possible because most business people are com-
fortable with spreadsheets. Spreadsheet packages support the use of graphics, customized
menus and toolbars, data tables and other tools for what-if analyses, and even macros (that
can be made transparent to users) for running complex programs.
12
Chapter 1
Introduction to Modeling
A heuristic is a
relatively simple
solution method that
often provides “good”
but not necessarily
optimal solutions.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Step 7: Model Implementation
A real management science application is not complete until it has been implemented. A
successful implementation can occur only when step 6 has been accomplished. That is, the
analyst must demonstrate the model to the client, and the client must be convinced that
the model adds real value and can be used by the people who need to use it. For this reason,
the analyst’s job is not really complete until the system is up and running on a daily basis.
To achieve a successful implementation, it isn’t enough for management to accept the
model; the people who will run it every day must also be thoroughly trained to use it. At
the very least, they should understand how to enter appropriate inputs, run what-if analy-
ses, and interpret the model’s outputs correctly. If they conclude that the model is more
trouble than it’s worth, they might simply refuse to use it, and the whole exercise will have
been a waste of time. An interesting trend (as evidenced in many of the Interfaces articles
discussed shortly) is for analysts to build a user-friendly Excel “front end” for their clients,
even if the actual number crunching is performed behind the scenes in some non-Excel
package. Because many employees understand at least the basics of Excel, a user-friendly
front end makes the system much more attractive for daily use.
Many successful management science applications take on a life of their own after the
initial implementation. After an organization sees the benefits of a useful model—and of
management science in general—it is likely to expand the model or create new models for
uses beyond those originally intended. Knowing that this is often the case, the best analysts
design models that can be expanded. They try to anticipate problems the organization
might face besides the current problem. They also stay in contact with the organization
after the initial implementation, just in case the organization needs guidance in expanding
the scope of the model or in developing new models.
This discussion of the seven-step modeling process has taken an optimistic point of
view by assuming that a successful study employs these seven steps, in approximately this
chronological order, and that everything goes smoothly. It does not always work out this
way. Numerous potential applications are never implemented even though the technical
aspects of the models are perfectly correct. The most frequent cause is a failure to commu-
nicate. The analyst builds a complex mathematical model, but the people in the organiza-
tion don’t understand how it works and are reluctant to use it. Also, company politics can
be a model’s downfall, especially if the model recommends a course of action that top
management simply does not want to follow—for whatever reasons.
Even for applications that are eventually implemented, the analyst doesn’t always pro-
ceed through the seven steps exactly as described in this section. He or she might backtrack
considerably throughout the process. For example, based on a tentative definition of the
problem, a model is built and demonstrated to management. Management says that the
model is impressive, but it doesn’t really solve the company’s problem. Therefore, the ana-
lyst returns to step 1, redefines the problem, and builds a new model (or modifies the orig-
inal model). In this way, the analyst generates several iterations of some or all of the seven
steps before the project is considered complete.
The Model as a Beginning, Not an End
This book places heavy emphasis on developing spreadsheet models, which is step 3 of the
seven-step modeling process. We lead you, step-by-step, through the model development
process for many examples, and we ask you to do this on your own in numerous problems.
Given this emphasis, it is easy to think of the completed model as the end of the process—
you complete the model and then proceed to the next model. However, a completed model
is really a starting point. After you have a working model of the problem, you can—and
1.4 The Seven-Step Modeling Process
13
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

you should—use it as a tool for gaining insights. For most models, many what-if questions
can be asked. If the model has been developed correctly, it should be capable of answering
such what-if questions fairly easily. In other words, it should be relatively easy to perform
sensitivity analysis on the model. This is, in fact, how management science models are
used in the business world. They are typically developed to solve a particular problem, but
they are then used as a tool to analyze a number of variations of the basic problem.
For most of the examples in the book, we not only show you how to develop a model
to obtain an “answer,” but we often include a section called “Discussion of the Solution”
(or a similar title) and a section called “Sensitivity Analysis.” The first of these asks you to
step back and look at the solution. Does it make sense? Does it provide any insights, espe-
cially surprising ones? The second section indicates how the model can be expanded in one
or more natural ways. What happens if there is more or less of some scarce resource? What
happens if a new constraint is added? The point is that before moving to the next model,
you should spend some time taking a close look at the model you just developed. This is
not just for pedagogical purposes; it is exactly the way real management science projects
proceed.
1.5 A GREAT SOURCE FOR MANAGEMENT SCIENCE 
APPLICATIONS: INTERFACES
Many of the chapter openers in this book are based on successful management science
applications that have been reported in the Interfaces journal. This is a highly respected
bimonthly journal that chronicles real applications of management science that have gen-
erated proven benefits, often in the millions or even hundreds of millions of dollars. The
applications are in a wide range of industries, are global, and employ a variety of manage-
ment science techniques.
Of special interest are the January-February and (since 1999) the September-October
issues. Each January-February issue contains the winner and finalists for that year’s Franz
Edelman Award for Achievement in Operations Research and the Management Sciences.
This is the profession’s most honored prize for the practice of management science. The
prize is awarded for “implemented work that has had significant, verifiable, and preferably
quantifiable impact.” Similarly, each September-October issue contains the winner and
runners-up for that year’s Daniel H. Wagner Prize for Excellence in Operations Research
Practice. Each prize is named after a pioneer in the field of operations research and man-
agement science, and the winning papers honor them by documenting the practice of man-
agement science at its best.
The journal is probably available from your school’s library, either in paper or elec-
tronic format. Check with your librarian about gaining access to Interfaces. Its articles will
confirm what we have been saying: Management science makes a huge difference to both
large and small organizations all over the world.
1.6 WHY STUDY MANAGEMENT SCIENCE?
We hope that you are convinced by now that management science is an important area 
and that highly trained analysts are needed to solve the large and complex problems faced
by the business world. However, unless you are one of the relatively few students who
intends to become a professional management scientist, you are probably wondering 
why you need to study management science. This is a legitimate concern. For many years,
those in the field of management science education received criticism from students and
14
Chapter 1
Introduction to Modeling
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

educators that management science courses were irrelevant for the majority of students
who were required to take them. Looking back, it is difficult to argue with these critics.
Typical management courses were centered primarily around a collection of very specific
models and, worse, a collection of mind-numbing mathematical solution techniques—
techniques that students were often required to implement by hand! (Some courses are
probably still taught this way, but we hope the number is decreasing rapidly.)
Two forces have helped to change this tendency toward irrelevance. First, the many
vocal critics motivated many of us to examine our course materials and teaching methods.
Certain topics have been eliminated and replaced by material that is more relevant and
interesting to students. We have certainly attempted to do so here. The second force is the
emergence of powerful computers and the accompanying easy-to-use software, especially
spreadsheet software. With the availability of computers to do the number crunching, there
is no need—except in advanced courses—to delve into the mathematical details of the
solution techniques. This task can be delegated to machines that are far better at it than
humans. The time formerly spent on such details can now be used to develop valuable
modeling skills.
The intent in this book is not just to cover specific models and specific approaches to
these models, but to teach a more general approach to the model-building process. We
believe that the spreadsheet approach is the best way to do this because it appeals to the
largest audience. We have been teaching our own courses with this spreadsheet-modeling
approach for nearly two decades—to a wide range of business students—and have
received very few complaints about irrelevance. In fact, many students have stated that this
is the most valuable business course they have taken. The following are some of the rea-
sons for this new-found relevance:
■
The modeling approach emphasized throughout this book is an important way to
think about problems in general, not just the specific problems we discuss. This
approach forces you to think logically. You must discover how given data can be
used (or which data are necessary), you must determine the elements of the problem
that you can control (the decision variables), and you must determine how the ele-
ments of the problem are logically related. These logical thinking skills are valuable
for your career, regardless of the specific field you enter.
■
Management science is admittedly built around quantitative skills—it deals primarily
with numbers and relationships between numbers. Some critics object that not
everything in the real world can be reduced to numbers, but as one of our reviewers
correctly points out, “a great deal that is of importance can.” As you work through
the many models in this book, your quantitative skills will be sharpened immensely.
In a business world driven increasingly by numbers, quantitative skills are an
important asset.
■
No matter what your spreadsheet abilities are when you enter this course, by the time
you are finished, you will be a proficient spreadsheet user. We deliberately chose the
spreadsheet package Excel, which is arguably the most widely used package (other
than word-processing packages) in the business world today. Many of our students
state that the facility they gain in Excel is the most valuable part of the course. That
doesn’t mean this is a course in spreadsheet fundamentals and neat tricks, although
you will undoubtedly pick up many useful tricks along the way. A great spreadsheet
package—and we strongly believe that Excel is the greatest spreadsheet package
written to date—gives you complete control over your model. You can apply spread-
sheets to an endless variety of problems. Excel gives you the flexibility to work in a
way that suits your style best, and it enables you to present results (and often catch
errors) almost immediately. As you succeed with relatively easy problems, your con-
fidence will build, and before long, you will be able to tackle more difficult problems
1.6 Why Study Management Science?
15
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

successfully. In short, spreadsheets enable everyone, not just technical people, to
develop and use their quantitative skills.
■
Management science modeling helps you develop your intuition, and it also indicates
where intuition alone sometimes fails. When you confront a problem, you often make
an educated (or maybe not so educated) guess at the solution. If the problem is suffi-
ciently complex, as many of the problems in this book are, this guess will be fre-
quently wide of the mark. In this sense, the study of management science can be a
humbling experience—you find that your unaided intuition is often not very good.
But by studying many models and examining their solutions, you can sharpen your
intuition considerably. This is sometimes called the “Aha!” effect. All of a sudden,
you see why a certain solution is so good. The chances are that when you originally
thought about the problem, you forgot to consider an important constraint or a key
relationship, and this caused your poor initial guess. Presumably, the more problems
you analyze, the better you will become at recognizing the critical elements of new
problems. Experienced management scientists tend to have excellent intuition, the
ability to see through to the essence of a problem almost immediately. However, they
are not born with this talent; it comes through the kind of analysis you will be per-
forming as you work through this book.
1.7 SOFTWARE INCLUDED WITH THIS BOOK
Very few business problems are small enough to be solved with pencil and paper. They
require powerful software. The software included in this book, together with Microsoft®
Excel, provides you with a powerful software combination that you will use for this course
and beyond. This software is being used—and will continue to be used—by leading com-
panies all over the world to solve large, complex problems. The experience you obtain with
this software, through working the examples and problems in this book, will give you a key
competitive advantage in the marketplace.
It all begins with Excel. All the quantitative methods that we discuss are implemented
in Excel. Specifically, in this edition, we use Excel 2010.5 Although it is impossible to
forecast the state of computer software into the long-term or even medium-term future, as
we are writing this book, Excel is the most heavily used spreadsheet package on the mar-
ket, and there is every reason to believe that this state will persist for quite awhile. Most
companies use Excel, most employees and most students have been trained in Excel, and
Excel is a very powerful, flexible, and easy-to-use package.
Although Excel has a huge set of tools for performing quantitative analysis, we have
included several add-ins with this book that make Excel even more powerful. (Access to
add-ins are available on the Essential Resource Web site. See the preface for details.) We
discuss these briefly here and in much more depth in the specific chapters where they
apply.
Together with Excel and the add-ins included in this book, you have a wealth of
software at your disposal. The examples and step-by-step instructions throughout the book
will help you to become a power user of this software. This takes plenty of practice and a
willingness to experiment, but it’s certainly within your grasp. When you are finished,
don’t be surprised if you rate improved software skills as one of the most valuable things
you have learned from the book.
16
Chapter 1
Introduction to Modeling
5Excel 2007 was a big change from Excel 2003 and earlier versions. The changes in Excel 2010 are much more
minor. So if you have been using Excel 2007, you will see very few changes here. 
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Built-in Excel Features
Virtually everyone in the business world knows the basic features of Excel, but relatively few
know some of its more powerful features. In short, relatively few people are the “power
users” we expect you to become by working through this book. To get you started, the file
Excel Tutorial.xlsx explains some of the “intermediate” features of Excel—features that we
expect you to be able to use (access this file on the textbook’s Web site that accompanies
new copies of this book). These include the SUMPRODUCT, VLOOKUP, IF, NPV, and
COUNTIF functions. They also include range names, data tables, the Paste Special option,
the Goal Seek tool, and many others. Finally, although we assume you can perform routine
spreadsheet tasks such as copying and pasting, the tutorial includes many tips to help you
perform these tasks more efficiently.
Solver Add-in
In Chapters 3–8 and 16 we make heavy use of Excel’s Solver add-in. This add-in, devel-
oped by Frontline Systems (not Microsoft), uses powerful algorithms—all behind the
scenes—to perform spreadsheet optimization. Before this type of spreadsheet optimization
add-in was available, specialized (nonspreadsheet) software was required to solve opti-
mization problems. Now you can do it all within a familiar spreadsheet environment.
SolverTable Add-in
An important theme throughout this book is sensitivity analysis: How do outputs change
when inputs change? Typically these changes are made in spreadsheets with a data table, a
built-in Excel tool. However, data tables don’t work in optimization models, where we
want to see how the optimal solution changes when certain inputs change. Therefore, we
include an Excel add-in called SolverTable, which works almost exactly like Excel’s data
tables. (This add-in was developed by Albright.) In Chapters 3–8 and 16 we illustrate the
use of SolverTable.
Palisade Decision Tools Suite
In addition to SolverTable and built-in Excel add-ins, we also have included on this text-
book’s essential resource Web site an educational version of Palisade Corporation’s pow-
erful Decision Tools suite. All of the programs in this suite are Excel add-ins, so the
learning curve isn’t very steep. There are seven separate add-ins in this suite: @RISK,
StatTools, PrecisionTree, TopRank, RISKOptimizer, NeuralTools, and Evolver.6 We will
use the first three most heavily in this book, but all are useful for certain tasks and are
described briefly below.
@RISK
The simulation add-in @RISK enables you to run as many replications of a spreadsheet sim-
ulation as you like. As the simulation runs, @RISK automatically keeps track of the outputs
you select, and it then displays the results in a number of tabular and graphical forms.
@RISK also enables you to perform a sensitivity analysis, so that you can see which inputs
have the most effect on the outputs. Finally, @RISK provides a number of spreadsheet func-
tions that enable you to generate random numbers from a variety of probability distributions.
StatTools
Palisade has also developed a statistics add-in called StatTools, which enhances the statisti-
cal capabilities of Excel. Excel’s built-in statistical tools are rather limited. It has several
1.7 Software Included in This Book
17
6The Palisade suite has traditionally included two stand-alone programs, BestFit and RISKview. The functional-
ity of both of these is now included in @RISK, so they are not included in the suite.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

functions, such as AVERAGE and STDEV for summarizing data, and it includes the Analysis
ToolPak, an add-in that was developed by a third party. However, these tools are not suffi-
ciently powerful or flexible for the heavy-duty statistical analysis that is sometimes
required. StatTools provides a collection of tools that help fill this gap. Admittedly, this is
not a statistics book, but StatTools will come in particularly handy in Chapter 14 when you
study regression analysis and forecasting.
PrecisionTree
The PrecisionTree add-in is used in Chapter 9 to analyze decision problems with uncer-
tainty. The primary method for performing this type of analysis is to draw a decision tree.
Decision trees are inherently graphical, and they have always been difficult to implement in
spreadsheets, which are based on rows and columns. However, PrecisionTree does this in a
very clever and intuitive way. Equally important, once the basic decision tree has been built,
it is easy to use PrecisionTree to perform a sensitivity analysis on the model’s inputs.
TopRank
TopRank is a “what-if” add-in used for sensitivity analysis. It starts with any spreadsheet
model, where a set of inputs, along with a number of spreadsheet formulas, leads to one or
more outputs. TopRank then performs a sensitivity analysis to see which inputs have the
largest effect on a given output. For example, it might indicate which input affects after-tax
profit the most: the tax rate, the risk-free rate for investing, the inflation rate, or the price
charged by a competitor. Unlike @RISK, TopRank is used when uncertainty is not
explicitly built into a spreadsheet model. However, it considers uncertainty implicitly by
performing sensitivity analysis on the important model inputs.
RISKOptimizer
RISKOptimizer combines optimization with simulation. There are often times when you
want to use simulation to model some business problem, but you also want to optimize a
summary measure, such as a mean, of an output distribution. This optimization can be
performed in a trial-and-error fashion, where you try a few values of the decision vari-
able(s) and see which provides the best solution. However, RISKOptimizer provides a
more automatic (and time-intensive) optimization procedure.
NeuralTools
In Chapter 14, we show how regression can be used to find a linear equation that quantifies the
relationship between a dependent variable and one or more explanatory variables. Although
linear regression is a powerful tool, it is not capable of quantifying all possible relationships.
The NeuralTools add-in mimics the working of the human brain to find “neural networks” that
quantify complex nonlinear relationships.
Evolver
In Chapter 8, we show how Solver 2010’s Evolutionary algorithm can be used to solve some
“non-smooth” nonlinear models that Solver’s other algorithms cannot handle. Evolutionary
Solver uses genetic algorithms to solve these difficult problems. Although we will not use it in
this book, Palisade’s Evolver add-in is an alternative implementation of genetic algorithms.
1.8 CONCLUSION
In this chapter, we have introduced the field of management science and the process of
mathematical modeling. To provide a more concrete understanding of these concepts, we
reviewed a simple queueing model. We also explored a seven-step model-building process
18
Chapter 1
Introduction to Modeling
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

that begins with problem definition and proceeds through final implementation. Finally,
we discussed why the study of management science is a valuable experience, even if you
do not intend to pursue a professional career in this field.
Don’t worry if you don’t understand some of the terms, such as linear programming,
that were used in this chapter. Although the seven-step process is not too difficult to com-
prehend, especially when discussed in the context of real applications, it typically entails
some rather complex logical relationships and mathematical concepts. These ideas are pre-
sented in much greater detail in the rest of this book. Specifically, you will learn how to
build spreadsheet models in Excel, how to use them to answer what-if questions, and how
to find optimal solutions with the help of Excel’s Solver add-in. For practical reasons, most
of your work will take place in the classroom or in front of your own PC as you work
through the examples and problems. The primary emphasis of this book, therefore, is on
steps 3 through 6, that is, developing the model, testing the model with different inputs,
optimizing the model, and presenting (and interpreting) the results to a client—probably
your instructor.
Keep in mind, however, that with real problems, you must take crucial steps before
and after the procedures you will be practicing in this book. Because real problems don’t
come as nicely packaged as those we discuss and because the necessary data are seldom
given to you on a platter, you will have to wrestle with the problem’s scope and precise
data requirements when you solve problems in a real setting. (We have included “modeling
problems” at the ends of most chapters. These problems are not as well structured as the
“skill” problems, so the burden is on you to determine an appropriate structure and decide
the necessary data.) Also, because a mathematically accurate model doesn’t necessarily
result in a successful implementation, your work is not finished just because the numbers
check out. To gain acceptance for a model, an analyst must have the right combination of
technical skills and people skills. Try to keep this in mind as you write up your solutions to
the problems in this book. Don’t just hand in a mass of numbers with little or no explana-
tion. Sell your solution!
1.8 Conclusion
19
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

21
Introduction to Spreadsheet Modeling
C H A P T E R
ANAL   YSIS OF HIV/AIDS 
M
any of management science’s most successful applications are traditional
functional areas of business, including operations management, logistics,
finance, and marketing. Indeed, many such applications are analyzed in this
book. However, another area where management science has had a strong
influence over the past two decades has been the analysis of the worldwide
HIV/AIDS epidemic. Not only have theoretical models been developed, but
even more important, they have also been applied to help understand the
epidemic and reduce its spread. To highlight the importance of management
science modeling in this area,an entire special issue (May–June 1998) of
Interfaces,the journal that reports successful management science applications,
was devoted to HIV/AIDS models.Some of the highlights are discussed here to
give you an idea of what management science has to offer in this important area.
Kahn et al.(1998) provides an overview of the problem. They discuss how
governments,public-health agencies,and health-care providers must deter-
mine how best to allocate scarce resources for HIV treatment and prevention
among different programs and populations. They discuss in some depth how
management science models have influenced,and will continue to influence,
AIDS policy decisions.Other articles in the issue discuss more specific prob-
lems.Caulkins et al.(1998) analyze whether the distribution of difficult-to-
reuse syringes would reduce the spread of HIV among injection drug users.
Based on their model,they conclude that the extra expense of these types of
syringes would not be worth the marginal benefit they might provide.
2
Lise Gagne/istockphoto 
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Paltiel and Freedberg (1998) investigate the costs and benefits of developing and
administering treatments for cytomegalovirus (CMV), an infection to which HIV carriers
are increasingly exposed. (Retinitis, CMV’s most common manifestation, is associated
with blindness and sometimes death.) Their model suggests that the costs compare
unfavorably with alternative uses of scarce resources. Owens et al. (1998) analyze the
effect of women’s relapse to high-risk sexual and needle-sharing behavior on the costs
and benefits of a voluntary program to screen women of childbearing age for HIV. They
find, for example, that the effect of relapse to high-risk behaviors on screening program
costs and benefits can be substantial, suggesting that behavioral interventions that pro-
duce sustained reductions in risk behavior, even if expensive, could be cost-saving.
The important point is that these articles (and others not mentioned here) base their
results on rigorous management science models of the HIV/AIDS phenomenon. In addi-
tion, they are backed up with real data. They are not simply opinions of the authors. ■
22
Chapter 2
Introduction to Spreadsheet Modeling
2.1 INTRODUCTION
This book is all about spreadsheet modeling. By the time you are finished, you will have
seen some reasonably complex—and realistic—models. Many of you will also be trans-
formed into Excel “power” users. However, we don’t want to start too quickly or assume too
much background on your part. For practice in getting up to speed with basic Excel features,
we have included an Excel tutorial on this textbook’s essential resource Web site. (See the
Excel Tutorial.xlsx file.) You can work through this tutorial at your own speed and cover
the topics you need help with. Even if you have used Excel extensively, give this tutorial a
look. You might be surprised how some of the tips can improve your productivity.
In addition, this chapter provides an introduction to Excel modeling and illustrates
some interesting and relatively simple models. The chapter also covers the modeling
process and includes some of the less well known, but particularly helpful, Excel tools
that are available. These tools include data tables, Goal Seek, lookup tables, and auditing
commands. Keep in mind, however, that our objective is not the same as that of the many
“how-to” Excel books on the market. We are not teaching Excel just for its many inter-
esting features. Rather, we plan to use these features to provide insights into real busi-
ness problems. In short, Excel is a problem-solving tool, not an end in itself, in this
book.
2.2 BASIC SPREADSHEET MODELING:
CONCEPTS AND BEST PRACTICES
Most mathematical models, including spreadsheet models, involve inputs, decision vari-
ables, and outputs. The inputs have given fixed values, at least for the purposes of the
model. The decision variables are those a decision maker controls. The outputs are the
ultimate values of interest; they are determined by the inputs and the decision variables.
For example, suppose a manager must place an order for a certain seasonal product. This
product will go out of date fairly soon, so this is the only order that will be made for the
product. The inputs are the fixed cost of the order; the unit variable cost of each item
ordered; the price charged for each item sold; the salvage value for each item, if any, left in
inventory after the product has gone out of date; and the demand for the product. The deci-
sion variable is the number of items to order. Finally, the key output is the profit (or loss)
from the product. This output can also be broken down into the outputs that contribute to
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

2.2 Basic Spreadsheet Modeling: Concepts and Best Practices
23
it: the total ordering cost, the revenue from sales, and the salvage value from leftover items.
These outputs must be calculated to obtain profit.
Spreadsheet modeling is the process of entering the inputs and decision variables into
a spreadsheet and then relating them appropriately, by means of formulas, to obtain the
outputs. After you have done this, you can then proceed in several directions. You might
want to perform a sensitivity analysis to see how one or more outputs change as selected
inputs or decision variables change. You might want to find the values of the decision vari-
able(s) that minimize or maximize a particular output, possibly subject to certain con-
straints. You might also want to create charts that show graphically how certain parameters
of the model are related.
These operations are illustrated with several examples in this chapter. Getting all the
spreadsheet logic correct and producing useful results is a big part of the battle; however,
we go farther by stressing good spreadsheet modeling practices. You probaby won’t be
developing spreadsheet models for your sole use; instead, you will be sharing them with
colleagues or even a boss (or an instructor). The point is that other people will be reading
and trying to make sense out of your spreadsheet models. Therefore, you should construct
your spreadsheet models with readability in mind. Features that can improve readability
include the following:
■
A clear, logical layout to the overall model
■
Separation of different parts of a model, possibly across multiple worksheets
■
Clear headings for different sections of the model and for all inputs, decision vari-
ables, and outputs
■
Use of range names
■
Use of boldface, italics, larger font size, coloring, indentation, and other formatting
features
■
Use of cell comments
■
Use of text boxes for assumptions and explanations
Obviously, the formulas and logic in any spreadsheet model must be correct; however,
correctness will not take you very far if no one can understand what you have done. Much
of the power of spreadsheets derives from their flexibility. A blank spreadsheet is like a big
blank canvas waiting for you to insert useful data and formulas. Almost anything is
allowed. However, you can abuse this power if you don’t have an overall plan for what
should go where. Plan ahead before diving in, and if your plan doesn’t look good after you
start filling in the spreadsheet, revise your plan.
The following example illustrates the process of building a spreadsheet model according
to these guidelines. We build this model in stages. In the first stage, we build a model that is
correct, but not very readable. At each subsequent stage, we modify the model to make it
more readable. You do not need to go through each of these stages explicitly when you build
your own models. You can often strive for the final stage right away, at least after you get
accustomed to the modeling process. The various stages are shown here simply for contrast.
E X A M P L E  
2.1 ORDERING NCAA T-SHIRTS
I
t is March, and the annual NCAA Basketball Tournament is down to the final four teams.
Randy Kitchell is a T-shirt vendor who plans to order T-shirts with the names of the final
four teams from a manufacturer and then sell them to the fans. The fixed cost of any order
is $750, the variable cost per T-shirt to Randy is $8, and Randy’s selling price is $18.
However, this price will be charged only until a week after the tournament. After that time,
Randy figures that interest in the T-shirts will be low, so he plans to sell all remaining
Some inputs, such as
demand in this
example, contain a
considerable degree
of uncertainty. In
some cases, as in
Example 2.4 later in
this chapter, this
uncertainty is modeled
explicitly.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

T-shirts, if any, at $6 each. His best guess is that demand for the T-shirts during the full-
price period will be 1500. He is thinking about ordering 1450 T-shirts, but he wants to
build a spreadsheet model that will let him experiment with the uncertain demand and his
order quantity. How should he proceed?
Objective 
To build a spreadsheet model in a series of stages, all stages being correct but
each stage being more readable and flexible than the previous stages.
Solution
The logic behind the model is fairly simple, but the model is built for generality.
Specifically, the formulas used allow for the order quantity to be less than, equal to, or
greater than demand. If demand is greater than the order quantity, Randy will sell all the T-
shirts ordered for $18 each. However, if demand is less than the order quantity, Randy will
sell as many T-shirts as are demanded at the $18 price and all leftovers at the $6 price. You
can implement this logic in Excel with an IF function.
A first attempt at a spreadsheet model appears in Figure 2.1. (See the file TShirt Sales
Finished.xlsx, where each stage appears on a separate worksheet.) You enter a possible
demand in cell B3, a possible order quantity in cell B4, and then calculate the profit in
cell B5 with the formula
=-750-8*B4+IF(B3>B4,18*B4,18*B3+6*(B4-B3))
This formula subtracts the fixed and variable costs and then adds the revenue accord-
ing to the logic just described.
24
Chapter 2
Introduction to Spreadsheet Modeling
1
2
3
4
5
A
B
NCAA t-shirt sales 
Demand
Order
Proﬁt
1500
1450
13750
Figure 2.1
Base Model
Excel Function: IF
Excel’s IF function is probably already familiar to you, b ut it is too important not to dis-
cuss. It has the syntax 
=IF(condition,resultIf True,resultIfFalse). The condition is any
expression that is either true or false . The two e xpressions resultIf True and resultIfFalse
can be any expressions you would enter in a cell: number s, text, or other Excel functions
(including other IF functions). Note that if either e xpression is text, it must be enclosed in
double quotes, such as
=IF(Score>=90,"A","B")
Finally, condition can be complex combinations of conditions, using the keywords AND or
OR. Then the syntax is, for example,
=IF(AND(Score1<60,Score2<60),"Fail","Pass")
This model in Figure 2.1 is entirely correct, but it isn’t very readable or flexible because
it breaks a rule that you should strive never to break: It hard codes input values into the
profit formula. A spreadsheet model should never include input numbers in formulas.
Instead, the spreadsheet model should store input values in separate cells and then include
cell references to these inputs in its formulas. A remedy appears in Figure 2.2. Here, the
inputs have been entered in the range B3:B6, and the profit formula in cell B10 has been
changed to
=-B3-B4*B9+IF(B8>B9,B5*B9,10*B8+B6*(B9-B8))
Never hard code
numbers into Excel
formulas. Use cell
references instead.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

2.2 Basic Spreadsheet Modeling: Concepts and Best Practices
25
This is exactly the same formula as before, but it is now more flexible. If an input changes,
the profit recalculates automatically. Most important, the inputs are no longer buried in the
formula.1
Still, the profit formula is not very readable as it stands. You can make it more read-
able by using range names. The mechanics of range names are covered in detail later in this
chapter. For now, the results of using range names for cells B3 through B6, B8, and B9 are
shown in Figure 2.3. This model looks exactly like the previous model, but the formula in
cell B10 is now
=-Fixed_order_cost-Variable_cost*Order+IF(Demand>Order,
Selling_price*Order,Selling_price*Demand+Discount_Price*(Order-Demand))
This formula is admittedly more long-winded, but it is certainly easier to read.
1
2
3
4
5
6
7
8
9
10
A
B
NCAA t-shirt sales
Fixed order cost
Variable cost
Selling price
Discount price
Demand
Order
Proﬁt
$750
$8
$18
$6
1500
1450
$13,750
Figure 2.2
Model with Input
Cells
1
2
3
4
5
6
7
8
9
10
A
B
C
D
E
F
NCAA t-shirt sales
Fixed order cost
Range names used 
Variable cost
Selling price
Discount price
Order   
Demand
Order
Proﬁt
$750
$8
$18
$6
1500
1450
$13,750
Demand
Discount_price
Fixed_order_cost
Selling_price
Variable_cost
='Model 3'!$B$8 
='Model 3'!$B$6 
='Model 3'!$B$3 
='Model 3'!$B$9   
='Model 3'!$B$5
='Model 3'!$B$4
Figure 2.3
Model with Range
Names in Profit
Formula
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
A
B
C
D
E
F
NCAA t-shirt sales
Fixed order cost
$750
Range names used
Variable cost
$8
Demand
='Model 4'!$B$8
Selling price
$18
Discount_price
='Model 4'!$B$6
Discount price
$6
Fixed_order_cost
='Model 4'!$B$3
Order
='Model 4'!$B$9
le
d
o
M
'=
e
cir
p
_
g
nille
S
0
0
5
1
d
n
a
m
e
D
 4'!$B$5
le
d
o
M
'=
ts
o
c
_
elb
air
a
V
0
5
4
1
r
e
d
r
O
 4'!$B$4
Costs
Fixed cost
$750
Variable costs
$11,600
Revenues
Full-price shirts
$26,100
Discount-price shirts
$0
$13,750
tif
o
r
P
Figure 2.4
Model with 
Intermediate 
Outputs
Randy might like to have profit broken down into various costs and revenues
(Figure 2.4), rather than one single profit cell. The formulas in cells B12, B13, B15, and
B16 are straightforward, so they are not repeated here. You can then accumulate these to
get profit in cell B17 with the formula
=-(B12+B13)+(B15+B16)
1Some people refer to such numbers buried in formulas as magic numbers because they just seem to appear out of
nowhere. Avoid magic numbers!
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Of course, range names could be used for these intermediate output cells, but this is prob-
ably more work than it’s worth. You should always use some judgment when deciding how
many range names to use.
If Randy’s assistant is presented with this model, how does she know at a glance which
cells contain inputs or decision variables or outputs? Labels and/or color coding can help to
distinguish these types. A blue/red/gray color-coding style has been applied in Figure 2.5,
along with descriptive labels in boldface. The blue cells at the top are input cells, the red cell
in the middle is a decision variable, and the gray cell at the bottom is the key output.2 There
is nothing sacred about this particular convention.
Feel free to adopt your own convention and style,
but be sure to use it consistently.
The model in Figure 2.5 is still not the last
word on this example. As shown in later examples,
you can create data tables to see how sensitive
profit is to the inputs, the demand, and the order
quantity. You can also create charts to show any
numerical results graphically. But this is enough for
now. You can see that the model in Figure 2.5 is
now much more readable and flexible than the orig-
inal model in Figure 2.1.
■
Because good spreadsheet style is so important, the
appendix to this chapter discusses a few tools for
editing and documenting your spreadsheet models.
Use these tools right away and as you progress
through the book.
In the rest of this chapter, we discuss a number
of interesting examples and introduce important
modeling concepts (such as sensitivity analysis),
important Excel features (such as data tables), and
even some important business concepts (such as
26
Chapter 2
Introduction to Spreadsheet Modeling
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
A
B
C
D
E
F
NCAA t-shirt sales
Input 
e
g
n
a
R
s
elb
air
a
v
 names used
Fixed order cost
$750
Demand
='Model 5'!$B$10
Variable cost
$8
Discount_price
='Model 5'!$B$7
Selling price
$18
Fixed_order_cost
='Model 5'!$B$4
Discount price
$6
Order
='Model 5'!$B$13
Selling_price
='Model 5'!$B$6
Uncertain variable
Variable_cost
='Model 5'!$B$5
0
0
5
1
d
n
a
m
e
D
Decision variable
0
5
4
1
r
e
d
r
O
Output variables
Costs
Fixed cost
$750
Variable costs
$11,600
Revenues
Full-price shirts
$26,100
Discount-price shirts
$0
$13,750
tif
o
r
P
Figure 2.5
Model with
Category Labels and
Color Coding
2This color convention shows up clearly in the Excel files that accompany the book. However, in this two-color
book (shades of gray and blue), it is difficult to see the color-coding scheme. We recommend that you look not only
at the figures in the book, but at the actual Excel files.
Spreadsheet Layout and Documentation
If you want y our spreadsheets to be used (and y ou
want your value in your company to rise),give a lot of
thought to y our spreadsheet layout and then docu-
ment y our w ork car efully. For la yout, think about
whether cer tain data ar e best oriented in r ows or
columns, whether y our w ork is better placed in a
single sheet or in multiple sheets, and so on. For doc-
umentation, use descriptive labels and headings,color
coding, cell comments, and text boxes to make your
spreadsheets more readable. It takes time and careful
planning to design and then document y our spread-
sheet models, but the time is w ell spent. And if you
come back in a few days to a spreadsheet model you
developed and y ou can’t make heads or tails of it,
don’t be afraid to r edesign your work completely—
from the ground up.
FUNDAMENTAL INSIGHT
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

net present value). To get the most from these examples, follow along at your own PC,
starting with a blank spreadsheet. It is one thing to read about spreadsheet modeling; it is
quite another to actually do it!
2.3 COST PROJECTIONS
In this next example, a company wants to project its costs of producing products, given that
material and labor costs are likely to increase through time. We build a simple model and
then use Excel’s charting capabilities to obtain a graphical image of projected costs.
2.3 Cost Projections
27
E X A M P L E
2.2 PROJECTING THE COSTS OF BOOKSHELVES AT WOODWORKS
T
he Woodworks Company produces a variety of custom-designed wood furniture for its
customers. One favorite item is a bookshelf, made from either cherry or oak. The com-
pany knows that wood prices and labor costs are likely to increase in the future. Table 2.1
shows the number of board-feet and labor hours required for a bookshelf, the current costs
per board-foot and labor hour, and the anticipated annual increases in these costs. (The top
row indicates that either type of bookshelf requires 30 board-feet of wood and 16 hours of
labor.) Build a spreadsheet model that enables the company to experiment with the growth
rates in wood and labor costs so that a manager can see, both numerically and graphically,
how the costs of the bookshelves vary in the next few years.
Table 2.1
Input Data for Manufacturing a Bookshelf
Resource
Cherry
Oak
Labor
Required per bookshelf
30
30
16
Current unit cost
$5.50
$4.30
$18.50
Anticipated annual cost increase
2.4%
1.7%
1.5%
Business Objectives3
To build a model that allows Woodworks to see, numerically and
graphically, how its costs of manufacturing bookshelves increase in the future and to allow
the company to answer what-if questions with this model.
Excel Objectives
To learn good spreadsheet practices, to enable copying formulas with
the careful use of relative and absolute addresses, and to create line charts from multiple
series of data.
Solution
Listing the key variables in a table before developing the actual spreadsheet model is use-
ful, so we will continue to do this in many later examples (see Table 2.2.) This practice
forces you to examine the roles of the variables—which are inputs, which are decision
variables, and which are outputs. Although the variables and their roles are fairly clear for
this example, later examples will require more thought.
3In later chapters, we simply list the “Objective” of each example as we did in Example 2.1. However, because
this chapter has been written to enhance basic spreadsheet skills, we separate the business objectives from the
Excel objectives.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

The reasoning behind the model is straightforward. You first project the unit costs for
wood and labor into the future. Then for any year you multiply the unit costs by the
required numbers of board-feet and labor hours per bookshelf. Finally, you add the wood
and labor costs to obtain the total cost of a bookshelf.
DEVELOPINGTHE SPREADSHEETMODEL
The completed spreadsheet model appears in Figure 2.6 and in the file Bookshelf
Costs.xlsx.4 You can develop it with the following steps.
28
Chapter 2
Introduction to Spreadsheet Modeling
Table 2.2
Key Variables for the Bookshelf Manufacturing Example
Input variables
Wood and labor requirements per bookshelf, current unit costs of wood and
labor, anticipated annual increases in unit costs
Output variables
Projected unit costs of wood and labor, projected total bookshelf costs
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
A
B
C
D
E
F
G
H
I
J
K
Projecng bookshelf costs at Woodworks
Inputs
Requirements per bookshelf
Cherry
Oak
Board-feet required
30
30
Labor hours required
16
16
Costs of 
k
a
O
y
rr
e
h
C
d
o
o
w
Current cost per board-foot
$5.50
$4.30
Projected annual increase
2.4%
1.7%
Cost of labor
Current cost per labor hour
$18.50
Projected annual increase
1.5%
Projected costs
Cost per hour
Years from now
Cherry
Oak
Labor
Cherry
Oak
0
$5.50
$4.30
$18.50
$461.00
$425.00
1
$5.63
$4.37
$18.78
$469.40
$431.63
2
$5.77
$4.45
$19.06
$477.96
$438.37
3
$5.91
$4.52
$19.35
$486.69
$445.21
4
$6.05
$4.60
$19.64
$495.58
$452.16
5
$6.19
$4.68
$19.93
$504.65
$459.22
6
$6.34
$4.76
$20.23
$513.89
$466.39
Cost per board-foot
Cost per bookshelf
$300.00
$350.00
$400.00
$450.00
$500.00
$550.00
0
1
2
3
4
5
6
Years from Now
Projected Bookshelf Costs
Cherry
Oak
Figure 2.6
Bookshelf Cost
Model
1
Inputs. You should usually enter the inputs for a model in the upper-left corner of a
worksheet as you can see in the shaded ranges in Figure 2.6, using the data from Table 2.1.
We have used our standard convention of coloring inputs—the numbers from the statement
of the problem—blue. You can develop your own convention, but the input cells should be
distinguished in some way. Note that the inputs are grouped logically and are explained
with appropriate labels. You should always document your spreadsheet model with infor-
mational labels. Also, note that by entering inputs explicitly in input cells, you can refer to
them later in Excel formulas.
2
Design output table. Plan ahead for how you want to structure your outputs. We cre-
ated a table where there is a row for every year in the future (year 0 corresponds to the cur-
rent year), there are three columns for projected unit costs (columns B–D), and there are
two columns for projected total bookshelf costs (columns E–F). The headings reflect this
design. Of course, this isn’t the only possible design, but it works well. The important
point is that you should have some logical design in mind before diving in.
4This textbook’s essential resource Web site includes templates and completed files for all examples in the book,
where all of the latter have “Finished” appended to their file names. However, especially in this chapter, we sug-
gest that you start with a blank spreadsheet and follow the step-by-step instructions on your own.
Always enter input
values in input cells
and then refer to them
in Excel formulas. Do
not bury input values
in formulas.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

3
Projected unit costs of wood. The dollar values in the range B19:F25 are all calcu-
lated from Excel formulas. Although the logic in this example is straightforward, it is still
important to have a strategy in mind before you enter formulas. In particular, you should
always try to design your spreadsheet so that you can enter a single formula and then copy
it. This saves work and avoids errors. For the costs per board-foot in columns B and C,
enter the formula
=B9
in cell B19 and copy it to cell C19. Then enter the general formula
=B19*(1+B$10)
in cell B20 and copy it to the range B20:C25. We assume you know the rules for absolute
and relative addresses (dollar sign for absolute, no dollar sign for relative), but it takes
some planning to use these so that copying is possible. Make sure you understand why we
made row 10 absolute but column B relative.
Excel Tip: Relative and Absolute Addresses in Formulas
Relative and absolute addresses are used in Excel formulas to facilitate copying. A dollar
sign next to a column or r ow address indicates that the addr ess is absolute and will not
change when copying. The lack of a dollar sign indicates that the addr ess is relative and
will change when copying. After you select a cell in a formula, you can pr ess the F4 k ey
repeatedly to cycle through the relative/absolute possibilities, for example, =B4 (both col-
umn and row relative), =$B$4 (both column and r ow absolute), =B$4 (column r elative,
row absolute), and =$B4 (column absolute, row relative).
4
Projected unit labor costs.
To calculate projected hourly labor costs, enter the
formula
=B13
in cell D19. Then enter the formula
=D19*(1+B$14)
in cell D20 and copy it down column D.
5
Projected bookshelf costs. Each bookshelf cost is the sum of its wood and labor
costs. By a careful use of absolute and relative addresses, you can enter a single formula
for these costs—for all years and for both types of wood. To do this, enter the formula
=B$5*B19+B$6*$D19
in cell E19 and copy it to the range E19:F25. The idea here is that the units of wood and
labor per bookshelf are always in rows 5 and 6, and the projected unit labor cost is always
in column D, but all other references are relative to allow copying.
6
Chart. A chart is a valuable addition to any table of data, especially in the business
world, so charting in Excel is a skill worth mastering. Although not everyone agrees, the
many changes Microsoft made regarding charts in Excel 2007 and 2010 help you create
charts more efficiently and effectively. We illustrate some of the possibilities here, but
we urge you to experiment with other possibilities on your own. Start by selecting the
range E18:F25—yes, including the labels in row 18. Next, click on the Line dropdown list
on the Insert ribbon and select the Line with Markers type. You instantly get the basic line
chart you want, with one series for Cherry and another for Oak. Also, when the chart is
selected (that is, it has a border around it), you see three Chart Tools ribbons: Design,
Layout, and Format. The most important button on any of these ribbons is the Select Data
button on the Design ribbon. It lets you choose the ranges of the data for charting in case
2.3 Cost Projections
29
Always try to organize
your spreadsheet
model so that you can
copy formulas across
multiple cells.
Typing dollar signs in
formulas for absolute
references is inefficient.
Press the F4 key
instead.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

30
Chapter 2
Introduction to Spreadsheet Modeling
Excel’s default choices (which are based on the selected range when you create the chart)
are wrong. Click on Select Data now to obtain the dialog box in Figure 2.7. On the left,
you control the series (one series or multiple series) being charted; on the right, you con-
trol the data used for the horizontal axis. By selecting E18:F25, you have the series on the
left correct, including the names of these series (Cherry and Oak), but if you didn’t, you
could select one of the series and click on Edit to change it. The data on the horizontal
axis is currently the default 1, 2, and so on. To make it the data in column A, click on the
Edit button on the right and select the range A19:A25. (See Figure 2.8.) Your chart is now
correctly labeled and charts the correct data. Beyond this, you can experiment with vari-
ous formatting options to make the chart even better. For example, we rescaled the verti-
cal axis to start at $300 rather than $0 (right-click on the numbers on the vertical axis and
select Format Axis, or look at the many options on the Axes dropdown list on the Layout
ribbon), and we added a chart title at the top and a title for the horizontal axis at the bot-
tom (see buttons on the Labels group on the Layout ribbon). You can spend a lot of time
fine-tuning charts—maybe even too much time—but professional-looking charts are defi-
nitely appreciated.
Figure 2.7
Select Data 
Dialog Box
Figure 2.8
Dialog Box for
Changing
Horizontal 
Axis Labels
The many chart
options are easily
accessible from the
three Chart Tools 
ribbons in Excel 2007
and 2010. Don’t be
afraid to experiment
with them to produce
professional-looking
charts.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

2.4 Breakeven Analysis
31
A carefully constructed
model—with no input
numbers buried in
formulas—allows a
manager to answer
many what-if questions
with a few keystrokes.
Using the Model for What-If Questions
The model in Figure 2.6 can now be used to answer
many what-if questions. In fact, many models are
built for the purpose of permitting experimentation
with various scenarios. The important point is that
the model has been built in such a way that a man-
ager can enter any desired values in the input cells,
and all of the outputs, including the chart, will
update automatically. As a simple example, if the
annual percentage increases for wood costs are
twice as high as Woodworks anticipated, you can
enter these higher values in row 10 and immedi-
ately see the effect, as shown in Figure 2.9. By
comparing bookshelf costs in this scenario to those
in the original scenario, the projected cost in year 6 for cherry bookshelves, for example,
increases by about 5.5%, from $513.89 to $542.26.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
A
B
C
D
E
F
G
H
I
J
K
Projecng bookshelf costs at Woodworks
Inputs
Requirements per bookshelf
Cherry
Oak
Board-feet required
30
30
Labor hours required
16
16
Costs of 
k
a
O
y
rr
e
h
C
d
o
o
w
Current cost per board-foot
$5.50
$4.30
Projected annual increase
4.8%
3.4%
Cost of labor
Current cost per labor hour
$18.50
Projected annual increase
1.5%
Projected costs
Cost per hour
Years from now
Cherry
Oak
Labor
Cherry
Oak
0
$5.50
$4.30
$18.50
$461.00
$425.00
1
$5.76
$4.45
$18.78
$473.36
$433.83
2
$6.04
$4.60
$19.06
$486.17
$442.87
3
$6.33
$4.75
$19.35
$499.44
$452.13
4
$6.63
$4.92
$19.64
$513.20
$461.62
5
$6.95
$5.08
$19.93
$527.46
$471.35
6
$7.29
$5.26
$20.23
$542.26
$481.32
Cost per board-foot
Cost per bookshelf
$300.00
$350.00
$400.00
$450.00
$500.00
$550.00
$600.00
0
1
2
3
4
5
6
Years from Now
Projected Bookshelf Costs
Cherry
Oak
Figure 2.9
Effect of Higher Increases in Wood Costs
The Power of Charts
A chart is typically much more informative to a busi-
ness manager than the table of n umbers it is based
on. Don’t underestimate the po wer of Excel charts
for getting y our points acr oss, and include them 
in y our spr eadsheet models whene
ver possible .
However, be prepared to do some in vestigating on
your own. Excel offers an abundance of char t types
and chart options to choose fr om, and they are not
all equally suited to telling your story.
FUNDAMENTAL INSIGHT
You should appreciate by now why burying input numbers inside Excel formulas is
such a bad practice. For example, if you had buried the annual increases of wood costs
from row 10 in the formulas in columns B and C, imagine how difficult it would be to
answer the what-if question in the previous paragraph. You would first have to find and
then change all the numbers in the formulas, which is a lot of work. Even worse, it is
likely to lead to errors.
■
2.4 BREAKEVEN ANALYSIS
Many business problems require you to find the appropriate level of some activity. This
might be the level that maximizes profit (or minimizes cost), or it might be the level that
allows a company to break even—no profit, no loss. We discuss a typical breakeven analy-
sis in the following example.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

32
Chapter 2
Introduction to Spreadsheet Modeling
E X A M P L E
2.3 BREAKEVEN ANALYSIS AT QUALITY SWEATERS
T
he Quality Sweaters Company sells hand-knitted sweaters. The company is planning to
print a catalog of its products and undertake a direct mail campaign. The cost of printing
the catalog is $20,000 plus $0.10 per catalog. The cost of mailing each catalog (including
postage, order forms, and buying names from a mail-order database) is $0.15. In addition, the
company plans to include direct reply envelopes in its mailings and incurs $0.20 in extra
costs for each direct mail envelope used by a respondent. The average size of a customer
order is $40, and the company’s variable cost per order (due primarily to labor and material
costs) averages about 80% of the order’s value—that is, $32. The company plans to mail
100,000 catalogs. It wants to develop a spreadsheet model to answer the following questions:
1.
How does a change in the response rate affect profit?
2.
For what response rate does the company break even?
3.
If the company estimates a response rate of 3%, should it proceed with the mailing?
4.
How does the presence of uncertainty affect the usefulness of the model?
Business Objectives
To create a model to determine the company’s profit and to see how
sensitive the profit is to the response rate from the mailing.
Excel Objectives
To learn how to work with range names, to learn how to answer what-
if questions with one-way data tables, to introduce Excel’s Goal Seek tool, and to learn
how to document and audit Excel models with cell comments and the auditing toolbar.
Solution
The key variables appear in Table 2.3. Note that we have designated all variables as input
variables, decision variables, or output variables. Furthermore, there is typically a key out-
put variable, in this case, profit, that is of most concern. (In the next few chapters, we refer
to it as the objective variable.) Therefore, we distinguish this key output variable from the
other output variables that we calculate along the way.
Table 2.3
Key Variables in Quality Sweaters Problem
Input variables
Various unit costs, average order size, response rate
Decision variable
Number mailed
Key output variable
Profit
Other output variables
Number of responses, revenue, and cost totals
Adopt some layout
and formatting
conventions, even if
they differ from ours,
to make your
spreadsheets readable
and easy to follow.
The logic for converting inputs and decision variable into outputs is straightforward.
After you do this, you can investigate how the response rate affects the profit with a sensi-
tivity analysis.
The completed spreadsheet model appears in Figure 2.10. (See the file Breakeven
Analysis.xlsx.) First, note the clear layout of the model. The input cells are colored blue,
they are separated from the outputs, headings are boldfaced, several headings are indented,
numbers are formatted appropriately, and a list to the right spells out all range names we
have used. (See the next Excel Tip on how to create this list.) Also, following the conven-
tion we use throughout the book, the decision variable (number mailed) is colored red, and
the bottom-line output (profit) is colored gray.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

2.4 Breakeven Analysis
33
Excel Tip: Creating Range Names
To create a r ange name for a r ange of cells (whic h could be a single cell), highlight the
cell(s), click in the Name Box just to the left of the F ormula Bar, and type a r ange name.
Alternatively, if a column (or r ow) of labels appear s next to the cells to be r ange-named,
you can use these labels as the r ange names. To do this, highlight the labels and the cells
to be named (for e xample, A4:B5 in F igure 2.10), select Cr eate from Selection on the
Formulas ribbon, and make sure the appropriate box in the resulting dialog box (see Fig-
ure 2.11) is checked. The labels in our example are to the left of the cells to be named, so
the Left column box should be checked. This is a very quick way to create range names, and
we did it for all range names in the example. In fact, by keeping your finger on the Ctrl key,
you can select multiple ranges.5 After all your ranges are selected, you can sometimes cre-
ate all your r ange names in one step. Note that if a label contains any “ille
gal” range-
name characters, such as a space, the illegal characters are converted to underscores.
1
2
3
4
5
6
7
8
9
10
11
12
13
I
H
G
F
E
D
C
B
A
Quality Sweaters direct mail model
 
 
 
 
Range names used
1
1
$
B
$
!le
d
o
M
=
r
e
d
r
o
_
e
g
a
r
e
v
A
Catalog 
le
d
o
M
st
u
p
ni
 of responses
Fixed_cost_of_prinng
=Model!$B$4
Fixed cost of prinng
$20,000
Response 
8
$
B
$
!le
d
o
M
=
d
elia
m
_
r
e
b
m
u
N
%
8
e
t
a
r
Variable cost of prinng mailing
$0.25
Number of 
5
$
E
$
!le
d
o
M
=
s
e
s
n
o
p
s
e
r
_
f
o
_
r
e
b
m
u
N
0
0
0
8
s
e
s
n
o
p
s
e
r
3
1
$
E
$
!le
d
o
M
=
tif
o
r
P
Decision 
le
d
o
M
elb
air
a
v
 of revenue, costs, and proﬁt
4
$
E
$
!le
d
o
M
=
e
t
a
r
_
e
s
n
o
p
s
e
R
Number 
la
t
o
T
0
0
0
0
0
1
d
elia
m
 
2
1
$
E
$
!le
d
o
M
=
ts
o
c
_la
t
o
T
0
0
0,0
2
3
$
e
u
n
e
v
e
R
Fixed cost of prinng
$20,000
Total_Revenue
=Model!$E$8
Order inputs
Total variable cost of prinng mailing
$25,000
Variable_cost_of_prinng_mailing
=Model!$B$5
Average 
la
t
o
T
0
4
$
r
e
d
r
o
 variable cost of orders
$257,600
Variable_cost_per_order
=Model!$B$12
Variable cost per order
$32.20
Total 
0
0
6,2
0
3
$
ts
o
c
0
0
4,7
1
$
tif
o
r
P
Figure 2.10
Quality Sweaters Model
We refer to this as the
Create from Selection
shortcut. If you like it,
you can get the dialog
box in Figure 2.11
even more quickly:
press Ctrl+Shift+F3.
If you like this tip, you
can perform it even
faster: press the F3
key to bring up the
Paste Name dialog
box. (This works only 
if there is at least one
range name in the
workbook.)
Figure 2.11
Range Name Create
Dialog Box
Excel Tip: Pasting Range Names
Including a list of the r ange names in your spr eadsheet is useful for documentation pur-
poses. To do this, select a cell (suc h as cell G4 in Figure 2.10), select the Use in Formula
dropdown list from the Formulas ribbon, and then click on the Paste List option. You get a
list of all range names and their cell addresses. However, if you change any of these range
names (delete one, for example), the paste list does not update automatically; you have to
create it again.
5Many users apparently believe range names are more work than they are worth. This shortcut for creating range
names helps to remedy this problem.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

34
Chapter 2
Introduction to Spreadsheet Modeling
DEVELOPING THE SPREADSHEET MODEL
To create this model, you can proceed through the following steps.
1
Headings and range names.
We have named a lot of cells, more than you might
want to name, but you will see their value when you create formulas. In general, we
strongly support range names, but it is possible to go overboard. You can waste time nam-
ing ranges that do not really need to be named. Of course, you can use the Create from 
Selection shortcut described previously to speed up the process.6
2
Values of input variables and the decision variable. Enter these values and format
them appropriately. As usual, we have used our blue/red/gray color-coding scheme. Note
that the number mailed has been designated as a decision variable, not as an input vari-
able (and it is colored red, not blue). This is because the company gets to choose the value
of this variable. Finally, note that some of the values have been combined in the statement
of the problem. For example, the $32.20 in cell B12 is really 80% of the $40 average order
size, plus the $0.20 per return envelope. To document this process, comments appear in a
few cells, as shown in Figure 2.12.
1
2
3
4
5
6
7
8
9
10
11
12
13
I
H
G
F
E
D
C
B
A
Great Threads direct mail model
Range names used
1
1
$
B
$
!le
d
o
M
=
r
e
d
r
o
_
e
g
a
r
e
v
A
Catalog 
le
d
o
M
st
u
p
ni
 of responses
Fixed_cost_of_prinng
=Model!$B$4
Fixed cost of prinng
$20,000
Response 
8
$
B
$
!le
d
o
M
=
d
elia
m
_
r
e
b
m
u
N
%
8
e
t
a
r
Variable cost of prinng mailing
$0.25
Number of 
5
$
E
$
!le
d
o
M
=
s
e
s
n
o
p
s
e
r
_
f
o
_
r
e
b
m
u
N
0
0
0
8
s
e
s
n
o
p
s
e
r
3
1
$
E
$
!le
d
o
M
=
tif
o
r
P
Decision 
le
d
o
M
elb
air
a
v
 of revenue, costs, and proﬁt
4
$
E
$
!le
d
o
M
=
e
t
a
r
_
e
s
n
o
p
s
e
R
Number 
la
t
o
T
0
0
0
0
0
1
d
elia
m
 
2
1
$
E
$
!le
d
o
M
=
ts
o
c
_la
t
o
T
0
0
0,0
2
3
$
e
u
n
e
v
e
R
Fixed cost of prinng
$20,000
Total_Revenue
=Model!$E$8
Order inputs
Total variable cost of prinng mailing
$25,000
Variable_cost_of_prinng_mailing
=Model!$B$5
Average 
la
t
o
T
0
4
$
r
e
d
r
o
 variable cost of orders
$257,600
Variable_cost_per_order
=Model!$B$12
Variable cost per order
$32.20
Total 
0
0
6,2
0
3
$
ts
o
c
0
0
4,7
1
$
tif
o
r
P
Trial value, will do 
sensitivity analysis on
Includes $0.10 for 
printing and $0.15 for 
mailing each catalog
Includes 80% of the average 
$40 order size, plus $0.20 per 
return envelope
Figure 2.12
Cell Comments in Model
Excel Tip: Inserting Cell Comments
Inserting comments in cells is a gr eat way to document your spr eadsheet models without
introducing excessive clutter. To enter a comment in a cell, right-click on the cell, select the
Insert Comment item, and type your comment. This cr eates a little r ed mark in the cell,
indicating a comment, and you can see the comment by r
esting the cur sor over the cell.
When a cell contains a comment, you can edit or delete the comment by right-clic king on
the cell and selecting the appropriate item. If you want all the cell comments to be visible
(for example, in a printout as in F igure 2.12), clic k on the F ile tab (or Of fice button in
Excel 2007), then on Options (Excel Options in Excel 2007), then on the Advanced link,
and select the Comment & Indicator option from the Display group. Note that the Indicator
Only option is the default.
CHANGES IN EXCEL 2010
After Microsoft got all of us used to the Office button in the upper left corner of all Office 2007
applications, it switched to a File tab in Office 2010.The menu structure under this File tab is
slightly different from the structure under the Office button, but the functionality is basically the
same. In particular, this is where you go to change most of the Excel options.
6We have heard of one company that does not allow any formulas in its corporate spreadsheets to include cell ref-
erences; they must all reference range names. This is probably too extreme, but that company’s formulas are cer-
tainly easy to read.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

2.4 Breakeven Analysis
35
3
Model the responses. You have not yet specified the response rate to the mailing, so
enter any reasonable value, such as 8%, in the Response_rate cell. You will perform sensi-
tivity on this value later on. Then enter the formula
=Number_mailed*Response_rate
in cell E5. (Are you starting to see the advantage of range names?)
4
Model the revenue, costs, and profits. Enter the formula
=Number_of_responses*Average_order
in cell E8, enter the formulas
=Fixed_cost_of_printing
=Variable_cost_of_printing_mailing*Number_mailed
and
=Number_of_responses*Variable_cost_per_order
in cells E9, E10, and E11, enter the formula
=SUM(E9:E11)
in cell E12, and enter the formula
=Total_revenue-Total_cost
in cell E13. These formulas should all be self-explanatory, especially because of the range
names used.
Excel Tip: Entering Formulas with Range Names
To enter a formula that contains range names, you do not have to type the full range names.
You actually have two convenient options. One, you can point to the cells, and range names
will appear in your formulas. Or two, you can start typing the r ange name in the formula,
and after a few letters, Excel will show you a list you can choose from.
Forming a One-Way Data Table
Now that a basic model has been created, the questions posed by the company can be
answered. For question 1, you can form a one-way data table to show how profit varies with
the response rate as shown in Figure 2.13. Data tables are used often in this book, so make
sure you understand how to create them. We will walk you through the procedure once or
twice, but from then on, you are on your own. First, enter a sequence of trial values of the
response rate in column A, and enter a link to profit in cell B17 with the formula =Profit.
This cell is shaded for emphasis, but this isn’t necessary. (In general, other outputs could be
part of the table, and they would be placed in columns C, D, and so on. There would be a
link to each output in row 17.) Finally, highlight the entire table range, A17:B27, and select
Data Table from the What-If Analysis dropdown list on the Data ribbon to bring up the
15
16
17
18
19
20
21
22
23
24
25
26
27
F
E
D
C
B
A
Queson 1 - sensivity of proﬁt to response rate
Response rate
Proﬁt
$17,400
1%
-$37,200
2%
-$29,400
3%
-$21,600
4%
-$13,800
5%
-$6,000
6%
$1,800
7%
$9,600
8%
$17,400
9%
$25,200
10%
$33,000
-$60,000
-$40,000
-$20,000
$0
$20,000
$40,000
1% 2% 3% 4% 5% 6% 7% 8% 9% 10%
Proﬁt
Response Rate
Proﬁt versus Response Rate
Figure 2.13
Data Table for Profit
Data tables are also
called what-if tables.
They let you see what
happens to selected
outputs as selected
inputs change.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

36
Chapter 2
Introduction to Spreadsheet Modeling
dialog box in Figure 2.14. Fill it in as shown to indicate that the only input, Response_rate,
is listed along a column. (You can enter either a range name or a cell address in this dialog
box. The easiest way is to point to the cell.)
When you click on OK, Excel substitutes each response rate value in the table into the
Response_rate cell, recalculates profit, and reports it in the table. For a final touch, you can
create a chart of the values in the data table. (To do this, highlight the A18:B27 range and
select the type of chart you want from the Insert ribbon. Then you can fix it up by adding
titles, removing the legend, and making other modifications to suit your taste.)
Excel Tool: One-Way Data Table
A one-way data table allows you to see how one or more output variables vary as a single input
variable varies over a selected range of values. These input values can be arranged vertically in
a column or horizontally in a row. We will explain only
the vertical arrangement because it is the most com-
mon. To create the table, enter the input values in a
column range, such as A18:A27 of Figure 2.13, and
enter links to one or more output cells in columns to
the right and one row above the inputs, as in cell B17
of Figure 2.13. Then highlight the entire table, begin-
ning with the upper-left blank cell (A17 in the figure),
select Data Table from the What-If Analysis dropdown
list on the Data ribbon, and fill in the resulting dialog
box as in Figure 2.14. Leave the Row Input cell blank
and use the cell where the original value of the input
variable lives as the Column Input cell. When you
click on OK, each value in the left column of the table
is substituted into the column input cell, the spread-
sheet recalculates, and the resulting value of the output is placed in the table. Also, if you click
anywhere in the body of the table (B18:B27 in the figure), you will see that Excel has entered
the TABLE function to remind you that a data table lives here. Note that the column input cell
must be on the same worksheet as the table itself; otherwise, Excel issues an error.
As the chart indicates, profit increases in a linear manner as the response rate varies. More
specifically, each percentage point increase in the response rate increases profit by $7800. Here
is the reasoning. Each percentage point increase in response rate results in 100,000(0.01) 
1000 more orders. Each order yields a revenue of $40, on average, but incurs a variable cost of
$32.20. The net gain in profit is $7.80 per order, or $7800 for 1000 orders.
USING GOAL SEEK
From the data table, you can see that profit changes from negative to positive when the
response rate is somewhere between 5% and 6%. Question 2 asks for the exact breakeven
point. You could find this by trial and error, but it is easier to use Excel’s Goal Seek tool.
Essentially, Goal Seek is used to solve a single equation in a single unknown. Here, the
equation is Profit=0, and the unknown is the response rate. In Excel terminology, the
unknown is called the changing cell because you can change it to make the equation true.
The Power of Data Tables
Unfortunately, many Excel users (most of them?) are
unaware of data tables, which are among the most
powerful and useful tools Excel has to offer. After you
have developed a model that r elates inputs to out-
puts,you can then build data tables in a matter of sec-
onds to see how the outputs vary as key inputs vary
over some range . Data tables are the perfect means
for ans wering a large n umber of what-if questions
quickly and easily.
The purpose of the
Goal Seek tool is to
solve one equation in
one unknown. It is 
used here to find the 
response rate that
makes profit equal 
to 0.
FUNDAMENTAL INSIGHT
Figure 2.14
Data Table Dialog
Box
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

2.4 Breakeven Analysis
37
To implement Goal Seek, select Goal Seek from the What-If Analysis dropdown list on the
Data ribbon and fill in the resulting dialog box as shown in Figure 2.15. (Range names or
cell addresses can be used in the top and bottom boxes, but a number must be entered in the
middle box.) After you click on OK, the Response_rate and Profit cells have values 5.77%
and $0. In words, if the response rate is 5.77%, Great Threads breaks even. If the response
rate is greater than 5.77%, the company makes money; if the rate is less than 5.77%, the
company loses money. Of course, this assumes that the company mails 100,000 catalogs. If
it sends more or fewer catalogs, the breakeven response rate will change.
Excel Tool: Goal Seek
The purpose of the Goal Seek tool is to solve one equation in one unknown. Specifically, Goal
Seek allows you to vary a single input cell to force a single output cell to a selected value. To use
it, select Goal Seek from the What-If Analysis dropdown list on the Data ribbon and fill in the
resulting dialog box in Figure 2.15. Enter a reference to the output cell in the Set cell box, enter
the numeric value you want the output cell to equal in the To value box, and enter a reference to
the input cell in the By changing cell box. Note that Goal Seek sometimes stops when the Set cell
is close, but not exactly equal to, the desired value. To improve Goal Seek’s accuracy, click on
the File tab (the Office button in Excel 2007), then Options  (Excel Options in Excel 2007), and
then the Formulas link. Then check the Enable iterative calculation box and reduce Maximum
Change to any desired level of precision. We chose a precision level of 0.000001. For this level
of precision, Goal Seek searches until profit is within 0.000001 of the desired value, $0.
Limitations of the Model
Question 3 asks whether the company should proceed with the mailing if the response rate
is only 3%. From the data table (see Figure 2.13), the apparent answer is no, because profit
is negative. However, like many companies, we are taking a short-term view with this rea-
soning. The model does not include the fact that many customers who respond to direct
mail will reorder in the future. The company nets $7.80 per order. If each of the respon-
dents ordered two more times, say, the company would earn 3000($7.80)(2) = $46,800
more than appears in the model, and profit would then be positive. The moral is that man-
agers must look at the long-term impact of their decisions. However, if you want to incor-
porate the long term explicitly into the model, you must build a more complex model.
Finally, question 4 asks about the impact of uncertainty in the model. Obviously, not all
model inputs are known with certainty. For example, the size of an order is not always
$40—it might range, say, from $10 to $100. When there is a high degree of uncertainty
about model inputs, it makes little sense to talk about the profit level or the breakeven
response rate. It makes more sense to talk about the probability that profit will have a certain
value or the probability that the company will break even. You will see how this can be done
in the following example and in many more such examples in Chapters 10 through 12.
Using the Formula Auditing Tool
The model in this example is fairly small and simple. Even so, you can use a handy Excel
feature to see how all the parts fit together. This is the Formula Auditing tool, which is
available on the Formulas ribbon. See Figure 2.16. 
Figure 2.15
Goal Seek Dialog
Box
Later chapters,
especially Chapters 10
through 12, deal
explicitly with
uncertainty.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

38
Chapter 2
Introduction to Spreadsheet Modeling
The Trace Precedents and Trace Dependents buttons are probably the most useful
buttons in this group. To see which formulas have direct links to the Number_of_
responses cell, select this cell and click on the Trace Dependents button. Arrows are
drawn to each cell that directly depends on the number of responses, as shown in
Figure 2.17. Alternatively, to see which cells are used to create the formula in the Total_
revenue cell, select this cell and click on the Trace Precedents button. Now you see that 
the Average_order and Number_of_responses cells are used directly to calculate revenue,
as shown in Figure 2.18. Using these two buttons, you can trace your logic (or someone
else’s logic) as far backward or forward as you like. When you are finished, just click on
the Remove Arrows button.
The Formula Auditing
tool is indispensable
for untangling the logic
in a spreadsheet,
especially if someone
else developed it.
Figure 2.16
Formula Auditing
Toolbar
1
2
3
4
5
6
7
8
9
10
11
12
13
E
D
C
B
A
Great Threads direct mail model
Catalog 
le
d
o
M
st
u
p
ni
 of responses
Fixed cost of prinng
$20,000
Response 
%
8
e
t
a
r
Variable cost of prinng mailing
$0.25
Number of 
0
0
0
8
s
e
s
n
o
p
s
e
r
Decision 
le
d
o
M
elb
air
a
v
 of revenue, costs, and proﬁt
Number 
la
t
o
T
0
0
0
0
0
1
d
elia
m
 
0
0
0,0
2
3
$
e
u
n
e
v
e
R
Fixed cost of prinng
$20,000
Order inputs
Total variable cost of prinng mailing
$25,000
Average 
la
t
o
T
0
4
$
r
e
d
r
o
 variable cost of orders
$257,600
Variable cost per order
$32.20
Total 
0
0
6,2
0
3
$
ts
o
c
0
0
4,7
1
$
tif
o
r
P
Figure 2.17
Dependents of
Number_of_
responses Cell
1
2
3
4
5
6
7
8
9
10
11
12
13
E
D
C
B
A
Great Threads direct mail model
Catalog 
le
d
o
M
st
u
p
ni
 of responses
Fixed cost of prinng
$20,000
Response 
%
8
e
t
a
r
Variable cost of prinng mailing
$0.25
Number of 
0
0
0
8
s
e
s
n
o
p
s
e
r
Decision 
le
d
o
M
elb
air
a
v
 of revenue, costs, and proﬁt
Number 
la
t
o
T
0
0
0
0
0
1
d
elia
m
 
0
0
0,0
2
3
$
e
u
n
e
v
e
R
Fixed cost of prinng
$20,000
Order inputs
Total variable cost of prinng mailing
$25,000
Average 
la
t
o
T
0
4
$
r
e
d
r
o
 variable cost of orders
$257,600
Variable cost per order
$32.20
Total 
0
0
6,2
0
3
$
ts
o
c
0
0
4,7
1
$
tif
o
r
P
Figure 2.18
Precedents of
Total_revenue Cell
Excel Tool: Formula Auditing Toolbar
The formula auditing toolbar allows you to see dependents of a selected cell (which
cells have formulas that reference this cell) or precedents of a given cell (which cells
are referenced in this cell’s formula). In fact, you can even see dependents or precedents
that reside on a different worksheet. In this case, the auditing arrows appear as dashed
lines and point to a small spreadsheet icon. By double-clicking on the dashed line, you
can see a list of dependents or precedents on other worksheets. These tools are especially
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

2.4 Breakeven Analysis
39
useful for understanding how someone else’s spreadsheet works. Unlike in pre-2007
versions of Excel, the Formula Auditing tools in Excel 2007 and 2010 are clearly visible
on the Formulas ribbon.
■
You can place charts
on the same worksheet
as the underlying data
or on separate chart
sheets.The choice is
a matter of personal
preference.
P R O B L E M S
Solutions for problems whose numbers appear within a
colored box can be found in the Student Solutions Files.
Refer to this book’s preface for purchase information.
Skill-Building Problems
1.
The sensitivity analysis in the Quality Sweaters exam-
ple was on the response rate. Suppose now that the
response rate is known to be 8%, and the company
wants to perform a sensitivity analysis on the number
mailed. After all, this is a variable under direct control
of the company. Create a one-way data table and a cor-
responding line chart of profit versus the number
mailed, where the number mailed varies from 80,000
to 150,000 in increments of 10,000. Does it appear,
from the results you see here, that there is an optimal
number to mail, from all possible values, that maxi-
mizes profit? Write a concise memo to management
about your results.
2.
Continuing the previous problem, use Goal Seek for
each value of number mailed (once for 80,000, once
for 90,000, and so on). For each, find the response rate
that allows the company to break even. Then chart
these values, where the number mailed is on the hori-
zontal axis, and the breakeven response rate is on the
vertical axis. Explain the behavior in this chart in a
brief memo to management.
3.
In the Quality Sweaters model, the range E9:E11 does
not have a range name. Open your completed Excel
file and name this range Costs. Then look at the for-
mula in cell E12. It does not automatically use the new
range name. Modify the formula so that it does. Then
click on cell G4 and paste the new list of range names
over the previous list.
Skill-Extending Problem
4.
As the Quality Sweaters problem is now modeled, if
all inputs remain fixed except for the number mailed,
profit will increase indefinitely as the number mailed
increases. This hardly seems realistic—the company
could become infinitely rich. Discuss realistic ways to
modify the model so that this unrealistic behavior is
eliminated.
Is the spreadsheet layout in Figure 2.12 the best possible layout? This question is not too
crucial because this model is so small. However, we have put all the inputs together (usu-
ally a good practice), and we have put all the outputs together in a logical order. You might
want to put the answers to questions 1 and 2 on separate worksheets, but with such a small
model, it is arguably better to keep everything on a single worksheet. We generally avoid
separate worksheets unless things start getting bigger and more complex. 
One other issue is the placement of the chart. From the Chart Tools Design ribbon,
you can click on the Move Chart button to select whether you want to place the chart on the
worksheet (floating above the cells) or on a separate chart sheet that has no rows or
columns. This choice depends on your personal preference—neither choice is necessarily
better than the other—but for this small model, we favor keeping everything on a single
worksheet.
Finally, we could have chosen the number mailed, rather than the response rate, as the
basis for a sensitivity analysis. A sensitivity analysis is typically based on an uncertain
input variable, such as the response rate, or a decision variable that the decision maker con-
trols. Fortunately, there is no limit to the number of data tables you can create for a partic-
ular model.
■
MODELING ISSUES
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

40
Chapter 2
Introduction to Spreadsheet Modeling
2.5 ORDERING WITH QUANTITY DISCOUNTS 
AND DEMAND UNCERTAINTY
In the following example, we again attempt to find the appropriate level of some activity:
how much of a product to order when customer demand for the product is uncertain. Two
important features of this example are the presence of quantity discounts and the explicit
use of probabilities to model uncertain demand. Except for these features, the problem is
very similar to the one discussed in Example 2.1.
E X A M P L E
2.4 ORDERING WITH QUANTITY DISCOUNTS AT SAM’S BOOKSTORE
S
am’s Bookstore, with many locations across the United States, places orders for all of
the latest books and then distributes them to its individual bookstores. Sam’s needs a
model to help it order the appropriate number of any title. For example, Sam’s plans to
order a popular new hardback novel, which it will sell for $30. It can purchase any number
of this book from the publisher, but due to quantity discounts, the unit cost for all books it
orders depends on the number ordered. Specifically, if the number ordered is less than
1000, the unit cost is $24. After each 1000, the unit cost drops: to $23 for at least 1000
copies, to $22.25 for at least 2000, to $21.75 for at least 3000, and to $21.30 (the lowest
possible unit cost) for at least 4000. For example, if Sam’s orders 2500 books, its total cost
is $22.25(2500)  $55,625. Sam’s is very uncertain about the demand for this book—it
estimates that demand could be anywhere from 500 to 4500. Also, as with most hardback
novels, this one will eventually come out in paperback. Therefore, if Sam’s has any hard-
backs left when the paperback comes out, it will put them on sale for $10, at which price,
it believes all leftovers will be sold. How many copies of this hardback novel should Sam’s
order from the publisher?
Business Objectives
To create a model to determine the company’s profit, given fixed
values of demand and the order quantity, and then to model the demand uncertainty explic-
itly and to choose the expected profit-maximizing order quantity.
Excel Objectives
To learn how to build in complex logic with IF formulas, to get online
help about Excel functions with the fx button, to learn how to use lookup functions, to see
how two-way data tables allow you to answer more extensive what-if questions, and to
learn about Excel’s SUMPRODUCT function.
Solution
The key variables for this model appear in Table 2.4. The primary modeling tasks are (1) to
show how any combination of demand and order quantity determines the number of units
sold, both at the regular price and at the leftover sale price, and (2) to calculate the total
ordering cost for any order quantity. After you accomplish these tasks, you can model the
uncertainty of demand explicitly and then find the optimal order quantity.
Table 2.4
Key Variables for Sam’s Bookstore Problem
Input variables
Unit prices, table of unit costs specifying quantity discount structure
Uncertain variable
Demand
Decision variable
Order quantity
Key output variable
Profit
Other output variables
Units sold at each price, revenue, and cost totals
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

2.5 Ordering with Quantity Discounts and Demand Uncertainty
41
The first step is to develop a spreadsheet model to calculate Sam’s profit for any order
quantity and any possible demand. Then you can perform a sensitivity analysis to see how
profit depends on these two quantities. Finally, you can decide how Sam’s might choose
the optimal order quantity.
DEVELOPING THE SPREADSHEET MODEL
The profit model appears in Figure 2.19. (See the file Quantity Discounts.xlsx.) Note that
the order quantity and demand in the Order_quantity and Demand cells are trial values.
(Comments in these cells are a reminder of this.) You can put any values in these cells, just
to test the logic of the model. The Order_quantity cell is colored red because the company
can choose its value. In contrast, the Demand cell is colored green here and in later chap-
ters to indicate that this input value is uncertain and is being treated explicitly as such.
Also, note that a table is used to indicate the quantity discounts cost structure. You can use
the following steps to build the model.
Whenever the term
trial value is used for
an input or a decision
variable, you can be
sure that we will follow
up with a data table 
or (in later chapters)
by running Solver to
optimize.
1
2
A
B
C
D
E
F
G
H
I
J
K
Ordering decision with quanty 
e
g
n
a
R
st
n
u
o
c
sid
 names used:
C
t
M d l!$B$18
2
3
4
5
6
7
8
9
10
11
12
!le
d
o
M
=
ts
o
C
$B$18
y
tit
n
a
u
Q
st
u
p
n
I
 discount structure
9
$
E
$:5
$
D
$
!le
d
o
M
=
p
u
k
o
o
Lts
o
C
Unit cost - see table to 
t
A
t
h
gir
 least
Unit 
2
1
$
B
$
!le
d
o
M
=
d
n
a
m
e
D
ts
o
c
Regular 
6
$
B
$
!le
d
o
M
=
e
cir
p
_
r
e
v
o
tf
e
L
0
0.4
2
$
0
0
3
$
e
cir
p
Leover 
9
$
B
$
!le
d
o
M
=
ytit
n
a
u
q
_
r
e
d
r
O
0
0.3
2
$
0
0
0
1
0
1
$
e
cir
p
5
3
$
J
$:5
3
$
B
$
!le
d
o
M
=
s
eitilib
a
b
o
r
P
5
2.2
2
$
0
0
0
2
Decision variable
9
1
$
B
$
!le
d
o
M
=
tif
o
r
P
5
7.1
2
$
0
0
0
3
Order 
5
$
B
$
!le
d
o
M
=
e
cir
p
_
r
alu
g
e
R
0
3.1
2
$
0
0
0
4
0
0
5
2
ytit
n
a
u
q
7
1
$
B
$
!le
d
o
M
=
e
u
n
e
v
e
R
Uncertain quanty
Units_sold_at_leover_price
=Model!$B$16
stin
U
0
0
0
2
d
n
a
m
e
D
_sold_at_regular_price
=Model!$B$15
12
13
14
15
16
17
18
19
Demand
2000
Units_sold_at_regular_price
Model!$B$15
Proﬁt model
Units sold at regular price
2000
Units sold at leover price
500
0
0
0,5
6
$
e
u
n
e
v
e
R
5
2
6,5
5
$
ts
o
C
5
7
3,9
$
tif
o
r
P
Figure 2.19
Sam’s Profit Model
1
Inputs and range names. Enter all inputs and name the ranges as indicated. Note
that the Create from Selection shortcut was used to name all ranges except for CostLookup
and Probabilities. For these latter two, you can highlight the ranges and enter the names
in the Name Box—the “manual” method. (Why the difference? To use the Create from
Selection shortcut, you must have appropriate labels in adjacent cells. Sometimes this is
simply not convenient.)
2
Revenues. The company can sell only what it has, and it sells any leftovers at the dis-
counted sale price. Therefore, enter the formulas
=MIN(Order_quantity,Demand)
=IF(Order_quantity>Demand, Order_quantity-Demand,0)
and
=Units_sold_at_regular_price*Regular_price
+Units_sold_at_leftover_price*Leftover_price
in cells B15, B16, and B17. The logic in the first two of these cells is necessary to account
correctly for the cases when the order quantity is greater than demand and when it is less
than or equal to demand. Note that you could use the following equivalent alternative to the
IF function in cell B16: 
=MAX(Order_quantity-Demand,0)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

42
Chapter 2
Introduction to Spreadsheet Modeling
Excel Tool: fx Button and Function Library Group
If you want to learn more about how an Excel function operates, click on the fx button next
to the Formula bar. This is called the Insert Function button, although some people call it
the Function Wizard. If there is already a function, such as an IF function, in a cell and you
then click on the fx button, you will get help on this function. If you select an empty cell and
then click on the f x button, you can c hoose a function to g et help on. (The same help is
available from the Function Library group on the Formulas ribbon.)
3
Total ordering cost. Depending on the order quantity, you can find the appropriate
unit cost from the unit cost table and multiply it by the order quantity to obtain the total
ordering cost. This can be accomplished with a complex nested IF formula, but a much
better way is to use the VLOOKUP function. Specifically, enter the formula
=VLOOKUP(Order_quantity,CostLookup,2)*Order_quantity
in cell B18. The VLOOKUP part of this formula says to compare the order quantity to the
first (leftmost) column of the table in the CostLookup range and return the corresponding
value in the second column (because the last argument is 2).
Excel Function: VLOOKUP
The VLOOKUP function acts like a tax table, where you look up the tax corr esponding to
your adjusted gross income from a table of incomes and taxes. To use it, first create a ver-
tical lookup table, with values to use for comparison listed in the left column of the table
and corresponding output values in as many columns to the right as you lik
e. (See the
CostLookup r ange in F igure 2.19 for an e xample.) Then the VLOOKUP function tak es
three or four arguments: (1) the value you want to compare to the values in the left column;
(2) the lookup table range; (3) the index of the column you want the returned value to come
from, where the index of the left column is 1, the inde x of the next column is 2, and so on;
and optionally (4) TRUE (for an approximate match, the default) or FALSE (for an e xact
match). If you omit the last ar gument, the values in the left column of the table must be
entered in ascending order. (See online help for more details.) If the last argument is TRUE
or is omitted, Excel scans down the leftmost column of the table and finds the last entry less
than or equal to the first argument. (In this sense, it finds an approximate match.) There is
also an HLOOKUP function that works exactly the same way, except that the lookup table
is arranged in rows, not columns.
4
Profit. Calculate the profit with the formula
=Revenue-Cost
Two-Way Data Table
The next step is to create a two-way data table for profit as a function of the order
quantity and demand (see Figure 2.20). To create this table, first enter a link to the
profit with the formula =Profit in cell A22, and enter possible order quantities and
possible demands in column A and row 22, respectively. (We used the same values for
both order quantity and demand, from 500 to 4500 in increments of 500. This is not
necessary—the demand could change in increments of 100 or even 1—but it is reason-
able. Perhaps Sam’s is required by the publisher to order in multiples of 500.) Then select
Data Table from the What-If Analysis dropdown list on the Data ribbon, and enter the
Demand cell as the Row Input cell and the Order_quantity cell as the Column Input
cell (see Figure 2.21).
A two-way data table
allows you to see how
a single output varies
as two inputs vary
simultaneously.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

2.5 Ordering with Quantity Discounts and Demand Uncertainty
43
21
A
B
C
D
E
F
G
H
I
J
Data table of proﬁt as a funcon of order quanty (along side) and demand (along top)
22
23
24
25
26
27
28
29
30
p
q
y (
g
)
(
g
p)
$9,375
500
1000
1500
2000
2500
3000
3500
4000
4500
500
$3,000
$3,000
$3,000
$3,000
$3,000
$3,000
$3,000
$3,000
$3,000
1000
-$3,000
$7,000
$7,000
$7,000
$7,000
$7,000
$7,000
$7,000
$7,000
1500
-$9,500
$500
$10,500
$10,500
$10,500
$10,500
$10,500
$10,500
$10,500
2000
-$14,500
-$4,500
$5,500
$15,500
$15,500
$15,500
$15,500
$15,500
$15,500
2500
-$20,625
-$10,625
-$625
$9,375
$19,375
$19,375
$19,375
$19,375
$19,375
3000
-$25,250
-$15,250
-$5,250
$4,750
$14,750
$24,750
$24,750
$24,750
$24,750
3500
-$31,125
-$21,125
-$11,125
-$1,125
$8,875
$18,875
$28,875
$28,875
$28,875
4000
$35 200
$25 200
$15 200
$5 200
$4 800
$14 800
$24 800
$34 800
$34 800
30
31
4000
-$35,200
-$25,200
-$15,200
-$5,200
$4,800
$14,800
$24,800
$34,800
$34,800
4500
-$40,850
-$30,850
-$20,850
-$10,850
-$850
$9,150
$19,150
$29,150
$39,150
Figure 2.20
Profit as a Function of Order Quantity and Demand
Figure 2.21
Dialog Box for 
Two-Way Data Table
Excel Tool: Two-Way Data Table
A two-way data table allows you to see how a single 
output cell varies as you vary two
input cells. (Unlike a one-way data table, only a single output cell can be chosen.) To cre-
ate this type of table, enter a reference to the output cell in the top-left corner of the table,
enter possible values of the two inputs below and to the right of this corner cell, and high-
light the entire table. Then select Data T able from the What-If Analysis dr opdown on the
Data ribbon, and enter references to the cells where the original two input variables live .
The Row Input cell corr esponds to the values along the top r
ow of the table , and the
Column Input cell corresponds to the values along the left-most column of the table. When
you click on OK, Excel substitutes each pair of input values into these two input cells,
recalculates the spr eadsheet, and enter s the corr esponding output value in the table . By
clicking on any cell in the body of the table, you can see that Excel also enters the function
TABLE as a reminder that the cell is part of a data table.
The resulting data table shows that profit depends heavily on both order quantity and
demand and (by scanning across rows) how higher demands lead to larger profits. But
which order quantity Sam’s should select is still unclear. Remember that Sam’s has com-
plete control over the order quantity (it can choose the row of the data table), but it has no
direct control over demand (it cannot choose the column).
The ordering decision depends not only on which demands are possible, but on
which demands are likely to occur. The usual way to express this information is with a
set of probabilities that sum to 1. Suppose Sam’s estimates these as the values in row
35 of Figure 2.22. These estimates are probably based on other similar books it has
sold in the past. The most likely demands are 2000 and 2500, with other values on both
sides less likely. You can use these probabilities to find an expected profit for each order
quantity. This expected profit is a weighted average of the profits in any row in the
data table, using the probabilities as the weights. The easiest way to do this is to enter
the formula
=SUMPRODUCT(B23:J23,Probabilities)
This is actually a
preview of decision
making under
uncertainty.To
calculate an expected
profit, you multiply
each profit by its
probability and add
the products.This 
topic is covered in
depth in Chapter 9.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

44
Chapter 2
Introduction to Spreadsheet Modeling
in cell B38 and copy it down to cell B46. You can also create a bar chart of these expected
profits, as shown in Figure 2.22. (Excel refers to these as column charts. The height of each
bar is the expected profit for that particular order quantity.)
Excel Function: SUMPRODUCT
The SUMPRODUCT function takes two range arguments, which must be exactly the same
size and shape, and it sums the products of the corresponding values in these two r anges.
For example, the formula =SUMPRODUCT(A10:B11,E12:F13) is a shortcut for a formula
involving the sum of 4 pr
oducts: =A10*E12+A11*E13+B10*F12+B11*F13. This is an
extremely useful function, especially when the r anges involved are large, and it is used
repeatedly throughout this book. (Actually , the SUMPR ODUCT function can have mor e
than two r ange arguments, all of the same size and shape , but the most common use of
SUMPRODUCT is when only two ranges are involved.)
The largest of the expected profits, $12,250, corresponds to an order quantity of 2000,
so we would recommend that Sam’s order 2000 copies of the book. This does not guaran-
tee that Sam’s will make a profit of $12,250—the actual profit depends on the eventual 
demand—but it represents a reasonable way to proceed in the face of uncertain demand.
You will learn much more about making decisions under uncertainty and the expected
value criterion in Chapter 9.
■
33
34
A
B
C
D
E
F
G
H
I
J
K
Model of expected demands
D
d
500
1000
1500
2000
2500
3000
3500
4000
4500
34
35
36
37
38
39
40
41
42
43
44
0
0
5
4
0
0
0
4
0
0
5
3
0
0
0
3
0
0
5
2
0
0
0
2
0
0
5
1
0
0
0
1
0
0
5
d
n
a
m
e
D
5
1
0.0
4
0.0
7
0.0
5
1.0
5
2.0
5
2.0
5
1.0
5
0.0
5
2
0.0
ytilib
a
b
o
r
P
Sum of probabilies -->
1
Order quanty
Expected proﬁt
500
$3,000
1000
$6,750
1500
$9,500
2000
$12,250
2500
$11,375
3000
$9,500
3500
$4,875
Order 2000 to 
maximize the 
expected proﬁt.
$6,000
$8,000
$10,000
$12,000
$14,000
Proﬁt
Expected Proﬁt versus Order Quanty
44
45
46
47
48
49
50
51
52
3500
$4,875
4000
$1,350
4500
-$4,150
-$6,000
-$4,000
-$2,000
$0
$2,000
$4,000
500
1000
1500
2000
2500
3000
3500
4000
4500
Expected 
Order Quanity
Figure 2.22
Comparison of Expected Profits
P R O B L E M S
Skill-Building Problems
5.
In some ordering problems, like the one for Sam’s
Bookstore, whenever demand exceeds existing inven-
tory, the excess demand is not lost but is filled by
expedited orders—at a premium cost to the company.
Change Sam’s model to reflect this behavior. Assume
that the unit cost of expediting is $40, well above the
highest regular unit cost.
6.
The spreadsheet model for Sam’s Bookstore contains a
two-way data table for profit versus order quantity and
demand. Experiment with Excel’s chart types to create
a chart that shows this information graphically in an
intuitive format. (Choose the format you would choose
to give a presentation to your boss.)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

2.6 Estimating the Relationship Between Price and Demand
45
7.
In the Sam’s Bookstore problem, the quantity discount
structure is such that all the units ordered have the
same unit cost. For example, if the order quantity is
2500, then each unit costs $22.25. Sometimes the
quantity discount structure is such that the unit cost
for the first so many items is one value, the unit cost
for the next so many units is a slightly lower value,
and so on. Modify the model so that Sam’s pays
$24 for units 1 to 1500, $23 for units 1501 to 2500,
and $22 for units 2501 and above. For example,
the total cost for an order quantity of 2750 is
1500(24)  1000(23)  250(22). (Hint: Use IF
functions, not VLOOKUP.)
Skill-Extending Problems
8.
The current spreadsheet model essentially finds the
expected profit in several steps. It first finds the profit
in cell B19 for a fixed value of demand. Then it uses
a data table to find the profit for each of several
demands, and finally it uses SUMPRODUCT to find
the expected profit. Modify the model so that expected
profit is found directly, without a data table. To do
this, change row 11 so that instead of a single demand,
there is a list of possible demands, those currently in
row 34. Then insert a new row below row 11 that lists
the probabilities of these demands. Next, in the rows
below the Profit Model label, calculate the units
sold, revenue, cost, and profit for each demand. For
example, the quantities in column C will be for the
second possible demand. Finally, use SUMPRODUCT
to calculate expected profit below the Profit row.
9.
Continuing Problem 5, create a two-way data table for
expected profit with order quantity along the side and
unit expediting cost along the top. Allow the order
quantity to vary from 500 to 4500 in increments of
500, and allow the unit expediting cost to vary from
$36 to $45 in increments of $1. Each column of this
table will allow you to choose an optimal order quan-
tity for a given unit expediting cost. How does this
best order quantity change as the unit expediting cost
increases? Write up your results in a concise memo to
management. (Hint: You will have to modify the exist-
ing spreadsheet model so that there is a cell for
expected profit that changes automatically when you
change either the order quantity or the unit expediting
cost. See Problem 8 for guidelines.)
2.6 ESTIMATING THE RELATIONSHIP BETWEEN 
PRICE AND DEMAND
The following example illustrates a very important modeling concept: estimating relation-
ships between variables by curve fitting. You will study this topic in much more depth in
the discussion of regression in Chapter 14, but the ideas can be illustrated at a relatively
low level by taking advantage of some of Excel’s useful features.
E X A M P L E
2.5 ESTIMATING SENSITIVITY OF DEMAND TO PRICE
AT THE LINKS COMPANY
T
he Links Company sells its golf clubs at golf outlet stores throughout the United States.
The company knows that demand for its clubs varies considerably with price. In fact,
the price has varied over the past 12 months, and the demand at each price level has been
observed. The data are in the data sheet of the file Golf Club Demand.xlsx (see Figure
2.23.) For example, during the past month, when the price was $390, 6800 sets of clubs
were sold. (The demands in column C are in hundreds of units. The cell comment in cell C3
reminds you of this.) The company wants to estimate the relationship between demand and
price and then use this estimated relationship to answer the following questions:
1.
Assuming the unit cost of producing a set of clubs is $250 and the price must be a
multiple of $10, what price should Links charge to maximize its profit?
2.
How does the optimal price depend on the unit cost of producing a set of clubs?
3.
Is the model an accurate representation of reality?
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

46
Chapter 2
Introduction to Spreadsheet Modeling
Business Objectives
To estimate the relationship between demand and price, and to use
this relationship to find the optimal price to charge.
Excel Objecti ves
To illustrate Excel’s Trendline tool, and to illustrate conditional
formatting.
Solution
This example is divided into two parts: estimating the relationship between price and
demand, and creating the profit model.
Estimating the Relationship Between Price and Demand 
A scatterplot of demand versus price appears in Figure 2.24. (This can be created in the
usual way with Excel’s Scatter chart.) Obviously, demand decreases as price increases, but
the goal is to quantify this relationship. Therefore, after creating this chart, right-click on
any point on the chart to bring up the dialog box in Figure 2.25. This allows you to super-
impose several different curves (including a straight line) on the scatterplot. We consider
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
A
B
C
Demand for golf clubs
Month
Price
Demand
1
450
45
2
300
103
3
440
49
4
360
86
5
290
125
6
450
52
7
340
87
8
370
68
9
500
45
10
490
44
11
430
58
12
390
68
Figure 2.23
Demand and Price
Data for Golf Clubs
90
100
110
120
130
40
50
60
70
80
90
280
320
360
400
440
480
520
Figure 2.24
Scatterplot of
Demand Versus
Price
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

2.6 Estimating the Relationship Between Price and Demand
47
three possibilities, the linear, power, and exponential curves, defined by the following
general equations (where y and x, a general output and a general input, correspond to
demand and price for this example):
■
Linear: y  a  bx
■
Power: y  axb
■
Exponential: y  aebx
Before proceeding, we describe some general properties of these three functions because
of their widespread applicability. The linear function is the easiest. Its graph is a straight
line. When x changes by 1 unit, y changes by b units. The constant a is called the intercept,
and b is called the slope.
The power function is a curve except in the special case where the exponent b is 1.
(Then it is a straight line.) Assuming that a is positive, the shape of this curve depends pri-
marily on the exponent b. If b  1, y increases at an increasing rate as x increases. If 0  b
 1, y increases, but at a decreasing rate, as x increases. Finally, if b  0, y decreases as x
increases. An important property of the power curve is that when x changes by 1%, y
changes by a constant percentage, and this percentage is approximately equal to b%. For
example, if y  100x2.35, then every 1% increase in x leads to an approximate 2.35%
decrease in y.
The exponential function also represents a curve whose shape depends on the constant
b in the exponent. Again, assume that a is positive. Then if b  0, y increases as x
increases; if b  0, y decreases as x increases. An important property of the exponential
function is that if x changes by 1 unit, y changes by a constant percentage, and this per-
centage is approximately equal to 100  b%. For example, if y  100e0.014x, then when-
ever x increases by 1 unit, y decreases by approximately 1.4%. Here e is the special number
2.7182 . . . , and e to any power can be calculated in Excel with the EXP function. For
example, you can calculate e0.014 with the formula =EXP(-0.014).
Figure 2.25
Trendline Options
Dialog Box
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

48
Chapter 2
Introduction to Spreadsheet Modeling
y = -0.3546x + 211.3147
100
110
120
130
Linear Fit
40
50
60
70
80
90
100
280
320
360
400
440
480
520
Figure 2.26
Best-Fitting 
Straight Line
y = 5871064.2031x-1.9082
100
110
120
130
Power Fit
40
50
60
70
80
90
100
280
320
360
400
440
480
520
Figure 2.27
Best-Fitting 
Power Curve
Returning to the example, if you superimpose any of these curves on the scatterplot of
demand versus price, Excel chooses the best-fitting curve of that type. Better yet, if you
check the Display Equation on Chart option, you see the equation of this best-fitting curve.
Doing this for each type of curve gives the results in Figures 2.26, 2.27, and 2.28. (The
equations might not appear exactly as in the figures. However, they can be resized and
reformatted to appear as shown.)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

2.6 Estimating the Relationship Between Price and Demand
49
Each of these curves provides the best-fitting member of its “family” to the demand/price
data, but which of these three is best overall? You can answer this question by finding the
mean absolute percentage error (MAPE) for each of the three curves. To do so, for any
price in the data set and any of the three curves, first predict demand by substituting the
given price into the equation for the curve. The predicted demand is typically not the same
as the observed demand, so you can calculate the absolute percentage error (APE) with the
general formula:
APE 
(2.1)
Then for any curve, MAPE is the average of these APE values. The curve with the small-
est MAPE is the best fit overall.
The calculations appear in Figure 2.29. After (manually) entering the parameters of
the equations from the scatterplots into column B, you can proceed as follows.
1
Predicted demands. Substitute observed prices into the linear, power, and exponen-
tial functions to obtain the predicted demands in columns E, F, and G. Specifically, enter
the formulas
=$B$19+$B$20*B4
=$B$22*B4^$B$23
and
=$B$25*EXP($B$26*B4)
in cells E19, F19, and G19, and copy them down their respective columns.
Observed demand  Predicted demand

Observed demand
y = 466.5101e-0.0049x
100
110
120
130
Exponenal Fit
40
50
60
70
80
90
100
280
320
360
400
440
480
520
Figure 2.28
Best-Fitting Exponential Curve
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

50
Chapter 2
Introduction to Spreadsheet Modeling
2
Average percentage errors. Apply Equation (2.1) to calculate APEs in columns H, I,
and J. Specifically, enter the general formula
=ABS($C4-E19)$C4
in cell H19 and copy it to the range H19:J30. (Do you see why column C is made absolute?
Remember that this is where the observed demands are stored.)
3
MAPE. Average the APEs in each column with the AVERAGE function to obtain the
MAPEs in row 32.
Evidently, the power curve provides the best fit, with a MAPE of 5.88%. In other words, its
predictions are off, on average, by 5.88%. This power curve predicts that each 1% increase
in price leads to an approximate 1.9% decrease in demand. (Economists call this relation-
ship elastic—demand is quite sensitive to price.)
DEVELOPING THE PROFIT MODEL
Now we move to the profit model, using the best-fitting power curve to predict demand
from price. The key variables appear in Table 2.5. Note there is now one input variable,
unit variable cost, and one decision variable, unit price. (The red background for the deci-
sion variable distinguishes it as such.) The profit model is straightforward to develop using
the following steps (see Figure 2.30).
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
A
B
C
D
E
F
G
H
I
J
Parameters of best-ﬁng curves
lait
n
e
n
o
p
x
E
r
e
w
o
P
r
a
e
niL
lait
n
e
n
o
p
x
E
r
e
w
o
P
r
a
e
niL
r
a
e
niL
%
8
7.3
1
%
9
8.2
1
%
8
9.4
1
0
2.1
5
0
8.0
5
4
7.1
5
1
3.1
1
2
t
p
e
cr
e
t
nI
Slope
-
%
3
8.3
%
1
9.6
%
7
8.1
4
9.6
0
1
2
1.0
1
1
3
9.4
0
1
6
4
5
3.0
%
5
7.9
%
1
2.8
%
3
8.2
1
8
7.3
5
2
0.3
5
9
2.5
5
r
e
w
o
P
%
8
3.7
%
8
5.9
%
3
7.2
5
6.9
7
6
7.7
7
5
6.3
8
4
6
0
1
7
8
5
t
n
a
ts
n
o
C
Exponent
-
%
4
1.0
1
%
1
0.6
%
2
2.3
1
2
3.2
1
1
8
4.7
1
1
8
4.8
0
1
2
8
0
9.1
%
3
5.1
%
1
3.2
%
0
5.0
0
2.1
5
0
8.0
5
4
7.1
5
lait
n
e
n
o
p
x
E
%
0
0.1
%
2
3.0
%
1
3.4
7
8.7
8
3
7.6
8
5
7.0
9
1
5.6
6
4
t
n
a
ts
n
o
C
Exponent
-
%
2
5.1
1
%
3
5.8
%
1
8.7
1
4
8.5
7
0
8.3
7
1
1.0
8
1
9
4
0
0.0
34.01
41.55
40.06
24.42%
7.67%
10.99%
37.56
43.18
42.07
14.65%
1.86%
4.38%
58.83
55.40
56.49
1.43%
4.48%
2.61%
73.02
66.75
68.74
7.38%
1.84%
1.09%
MAPE
9.68%
5.88%
6.50%
e
t
ulo
s
b
A
n
oitcid
e
r
P
 percentage error
Figure 2.29
Finding the Best-Fitting Curve Overall
Table 2.5
Key Variables for Golf Club Problem
Input variable
Unit cost to produce
Decision variable
Unit price
Key output variable
Profit
Other output variables
Predicted demand, total revenue, total cost
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

2.6 Estimating the Relationship Between Price and Demand
51
1
Predicted demand. Calculate the predicted demand in cell B14 with the formula
=B4*B11^B5
This uses the power function that was estimated earlier.
2
Revenue, cost, profit. Enter the following formulas in cells B15, B16, and B17:
=B11*B14
=B8*B14
and
=B15-B16
The assumption here is that the company produces exactly enough sets of clubs to meet
customer demand.
Maximizing Profit
To see which price maximizes profit, you can build the data table
shown in Figure 2.31. Here, the column input cell is B11 and the linking formula in
cell B25 is =B17. The corresponding scatter chart shows that profit first increases and
then decreases. You can find the maximum profit and corresponding price in at least
three ways. First, you can attempt to read them from the chart. Second, you can scan
down the data table for the maximum profit, which is shown in the figure. The
following Excel Tip describes a third method that uses some of Excel’s more powerful
features.
Excel Tip: Conditional Formatting
Cell B53 in Figure 2.31 is colored because it corresponds to the maximum profit in the col-
umn, but Excel’s Conditional Formatting tool can do this for you—automatically.7 To color
the maximum pr ofit, select the r
ange of pr ofits, B26:B75, clic k on the Conditional
Formatting dropdown arrow, then Top/Bottom Rules, and then Top 10 Items to bring up the
dialog box in Figure 2.32. By asking for the top 1 item, the maximum value in the range is
colored. You can experiment with the many other Conditional Formatting options. This is a
great tool.
1
A
B
C
D
E
Proﬁt model using best ﬁng power curve for esmang demand
1
2
3
4
5
6
7
Proﬁt model, using best ﬁng power curve for esmang demand
Parameters of best-ﬁng power curve (from Esmaon sheet)
Constant
5871064
Exponent
-1.9082
Monetary inputs
8
9
10
11
12
13
14
y
p
Unit cost to produce
$250
Decision variable
Unit price (trial value)
$400
Proﬁt model
P
di t d d
d
63 601
14
15
16
17
Predicted demand
63.601
Total revenue
$25,441
Total cost
$15,900
0
4
5,9
$
tif
o
r
P
Figure 2.30
Profit Model
7The value in cell B52 also appears to be the maximum, but to two decimals, it is slightly lower.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

52
Chapter 2
Introduction to Spreadsheet Modeling
What about the corresponding best price, shown in cell B21 of Figure 2.31? You could
enter this manually, but wouldn’t it be nice if you could get Excel to find the maximum
profit in the data table, determine the price in the cell to its left, and report it in cell B21, all
automatically? This is indeed possible. Just enter the formula
=INDEX(A26:A75,MATCH(B20,B26:B75,0),1)
in cell B21, and the best price appears. This formula uses two Excel functions, MATCH
and INDEX. MATCH compares the first argument (the maximum profit in cell B20) to
the range specified in the second argument (the range of profits), and returns the index of
the cell where a match appears. (The third argument, 0, specifies that you want an exact
match.) In this case, the MATCH function returns 28 because the maximum profit is in
the 28th cell of the profits range. Then the INDEX function is called effectively as
=INDEX(A26:A75,28,1). The first argument is the range of prices, the second is a row
index, and the third is a column index. Very simply, this function says to return the value in
the 28th row and first column of the prices range.
To learn more about these functions, you can click on the fx button and examine the
functions in the Lookup & Reference category. After experimenting, you can see that the
19
A
B
C
D
E
F
G
H
I
Maximum proﬁt from data table below, with corresponding best unit price
20
21
22
23
24
25
26
27
28
p
,
p
g
p
Maximum proﬁt
$10,409
Best 
0
3
5
$
e
cir
p
Data table for Proﬁt as a funcon of Unit price
Unit price
Proﬁt
$9,540
$260
$1,447
$270
$2,693
$280
$3 769
$12 000
Proﬁt versus Price
28
29
30
31
32
33
34
35
36
37
$280
$3,769
$290
$4,699
$300
$5,506
$310
$6,207
$320
$6,815
$330
$7,345
$340
$7,805
$350
$8,206
$360
$8,554
$370
$8 856
$0
$2,000
$4,000
$6,000
$8,000
$10,000
$12,000
Proﬁt
37
38
39
40
41
42
43
44
45
$370
$8,856
$380
$9,118
$390
$9,345
$400
$9,540
$410
$9,708
$420
$9,851
$430
$9,973
$440
$10,075
$450
$10,160
Price
46
47
48
49
50
51
52
53
54
$
$
,
$460
$10,230
$470
$10,286
$480
$10,330
$490
$10,363
$500
$10,387
$510
$10,402
$520
$10,409
$530
$10,409
$540
$10 403
Maximum proﬁt
54
55
56
57
58
59
60
$540
$10,403
$550
$10,391
$560
$10,375
$570
$10,354
$580
$10,329
$590
$10,300
$600
$10,269
Figure 2.31
Profit as a 
Function of Price
Figure 2.32
Conditional 
Formatting 
Dialog Box
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

2.6 Estimating the Relationship Between Price and Demand
53
INDEX and MATCH combination solves the problem. You don’t have to memorize these
functions, although this combination really does come in handy. Rather, you can often
solve a problem by investigating some of Excel’s less well-known features. You don’t even
need a manual—everything is in online help.
Sensitivity to Variable Cost 
We now return to question 2 in the example: How does the best price change as the unit vari-
able cost changes? You can answer this question with a two-way data table. Remember that
this is a data table with two inputs—one along the left side and the other across the top row—
and a single output. The two inputs for this problem are unit variable cost and unit price, and
the single output is profit. The corresponding data table is in the range A83:F168, the top part
of which appears in Figure 2.33. To develop this table, enter desired inputs in column A and
row 83, enter the linking formula =B17 in cell A83 (it always goes in the top-left corner of a
two-way data table), highlight the entire table, select Data Table from the What-If Analysis
dropdown list, and enter B8 as the Row Input cell and B11 as the Column Input cell.
77
78
A
B
C
D
E
F
G
H
I
J
K
L
M
Maximum proﬁt for diﬀerent unit costs (from data table below)
Unit cost
$150
$200
$250
$300
$350
78
79
80
81
82
83
84
85
86
87
88
89
Unit cost
$150
$200
$250
$300
$350
Maximum proﬁt
$16,552
$12,748
$10,409
$8,821
$7,669
Corresponding best price
$320
$420
$530
$630
$740
Sensivity of proﬁt to unit cost (unit cost is along the top, unit price is along the side)
$9,540
$150
$200
$250
$300
$350
$160
$3,654
-$14,618
-$32,890
-$51,161
-$69,433
$170
$6,510
-$9,766
-$26,041
-$42,317
-$58,593
$180
$8,756
-$5,838
-$20,432
-$35,026
-$49,620
$190
$10,531
-$2,633
-$15,796
-$28,960
-$42,123
$200
$11,936
$0
-$11,936
-$23,872
-$35,808
$210
$13,050
$2,175
-$8,700
-$19,575
-$30,450
$0
$5,000
$10,000
$15,000
$20,000
Maximum Proﬁt
Maximum Proﬁt versus Unit Cost
90
91
92
93
94
95
96
97
98
99
100
101
$220
$13,932
$3,980
-$5,971
-$15,922
-$25,873
$230
$14,627
$5,485
-$3,657
-$12,799
-$21,941
$240
$15,172
$6,743
-$1,686
-$10,115
-$18,543
$250
$15,594
$7,797
$0
-$7,797
-$15,594
$260
$15,917
$8,682
$1,447
-$5,788
-$13,023
$270
$16,157
$9,425
$2,693
-$4,039
-$10,772
$280
$16,330
$10,049
$3,769
-$2,512
-$8,793
$290
$16,447
$10,573
$4,699
-$1,175
-$7,049
$300
$16,518
$11,012
$5,506
$0
-$5,506
$310
$16,551
$11,379
$6,207
$1,034
-$4,138
$320
$16,552
$11,683
$6,815
$1,947
-$2,921
$330
$16 526
$11 935
$7 345
$2 754
$1 836
$100
$150
$200
$250
$300
$350
Unit Cost
101
102
103
104
105
106
107
108
109
110
$330
$16,526
$11,935
$7,345
$2,754
-$1,836
$340
$16,478
$12,142
$7,805
$3,469
-$867
$350
$16,412
$12,309
$8,206
$4,103
$0
$360
$16,331
$12,442
$8,554
$4,666
$778
$370
$16,237
$12,547
$8,856
$5,166
$1,476
$380
$16,132
$12,625
$9,118
$5,611
$2,104
$390
$16,020
$12,682
$9,345
$6,007
$2,670
$400
$15,900
$12,720
$9,540
$6,360
$3,180
$410
$15,775
$12,742
$9,708
$6,674
$3,640
$420
$15,646
$12,748
$9,851
$6,954
$4,056
Figure 2.33
Profit as a Function of Unit Cost and Unit Price
As before, you can scan the columns of the data table for the maximum profits
and enter them (manually) in rows 79 and 80. (Alternatively, you can use the Excel fea-
tures described in the previous Excel Tip to accomplish these tasks. Take a look at the
finished version of the file for details. This file also explains how conditional format-
ting is used to color the maximum profit in each column of the table.) Then you can cre-
ate a chart of maximum profit (or best price) versus unit cost. The chart in Figure 2.33
shows that the maximum profit decreases, but at a decreasing rate as the unit cost
increases.
Limitations of the Model 
Question 3 asks you to step back from all these details and evaluate whether the model is
realistic. First, there is no real reason to restrict golf club prices to multiples of $10. This
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

54
Chapter 2
Introduction to Spreadsheet Modeling
was only required so that a data table could be used to find the profit-maximizing price.
Ideally, you should search over all possible prices to find the profit-maximizing price.
Fortunately, Excel’s built-in Solver tool enables you to accomplish this task fairly easily.
The problem of finding a profit-maximizing price is an example of an optimization
model. In optimization models, you try to maximize or minimize a specified output cell by
changing the values of the decision variable cells. Chapters 3–8 and 16 contain a detailed
discussion of optimization models.
A second possible limitation of the model is the implicit assumption that price is the
only factor that influences demand. In reality, other factors, such as advertising, the state of
the economy, competitors’ prices, strength of competition, and promotional expenses, also
influence demand. In Chapter 14, you will learn how to use multiple regression to analyze
the dependence of one variable on two or more other variables. This technique allows you
to incorporate other factors into the model for profit.
A final limitation of the model is that demand might not equal sales. For example, if
actual demand for golf clubs during a year is 70,000 but the company’s annual capacity is
only 50,000, the company will observe sales of only 50,000. This will cause it to underes-
timate actual demand, and the curve-fitting method will produce biased predictions. (Can
you guess the probable effect on pricing decisions?)
Other Modeling Issues 
The layout of the Golf Club Demand.xlsxfile is fairly straightforward. However, note that
instead of a single worksheet, there are two worksheets, partly for logical purposes and
partly to reduce clutter. There is one worksheet for estimation of the demand function and
the various scatterplots, and there is another for the profit model. 
One last issue is the placement of the data tables for the sensitivity analysis. You might
be inclined to put these on a separate Sensitivity worksheet. However, Excel does not allow
you to build a data table on one worksheet that uses a row or column input cell from
another worksheet. Therefore, you are forced to put the data tables on the same worksheet
as the profit model.
■
P R O B L E M S
Skill-Building Problems
10. Suppose you have an extra six months of data on
demands and prices, in addition to the data in the
example. These extra data points are (350,84), (385,72),
(410,67), (400,62), (330,92), and (480,53). (The price is
shown first and then the demand at that price.) After
adding these points to the original data, use Excel’s
Trendline tool to find the best-fitting linear, power, and
exponential trend lines. Finally, calculate the MAPE for
each of these, based on all 18 months of data. Does the
power curve still have the smallest MAPE?
11. Consider the power curve y  10000x2.35. Calculate
y when x  5; when x  10; and when x  20. For
each of these values of x, find the percentage change
in y when x increases by 1%. That is, find the percent-
age change in y when x increases from 5 to 5.05; when
it increases from 10 to 10.1; and when it increases
from 20 to 20.2. Is this percentage change constant?
What number is it very close to? Write a brief memo
on what you have learned about power curves from
these calculations.
12. Consider the exponential curve y  1000e0.014x.
Calculate y when x  5; when x  10; and when
x  20. For each of these values of x, find the
percentage change in y when x increases by one unit.
That is, find the percentage change in y when x
increases from 5 to 6; when it increases from 10 to 11;
and when it increases from 20 to 21. Is this percentage
change constant? When expressed as a decimal, what
number is it very close to? Write a brief memo on
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

2.7 Decisions Involving the Time Value of Money
55
2.7 DECISIONS INVOLVING THE TIME VALUE OF MONEY
In many business situations, cash flows are received at different points in time, and a com-
pany must determine a course of action that maximizes the “value” of cash flows. Here are
some examples:
■
Should a company buy a more expensive machine that lasts for 10 years or a less
expensive machine that lasts for 5 years?
■
What level of plant capacity is best for the next 20 years?
■
A company must market one of several midsize cars. Which car should it market?
To make decisions when cash flows are received at different points in time, the key
concept is that the later a dollar is received, the less valuable the dollar is. For example,
suppose you can invest money at a 5% annual interest rate. Then $1.00 received now is
essentially equivalent to $1.05 a year from now. The reason is that if you have $1.00 now,
you can invest it and gain $0.05 in interest in one year. If r  0.05 is the interest rate
(expressed as a decimal), we can write this as
$1.00 now  $1.05 a year from now  $1.00(1  r)
(2.2)
Dividing both sides of Equation (2.2) by 1  r, we can rewrite it as
$1.00  1(1  r) now  $1.00 a year from now
(2.3)
The value 1(1  r) in Equation (2.3) is called the discount factor, and it is always less
than 1. The quantity on the left, which evaluates to $0.952 for r  0.05, is called the pre-
sent value of $1.00 received a year from now. The idea is that if you had $0.952 now, you
could invest it at 5% and have it grow to $1.00 in a year.
In general, if money can be invested at annual rate r compounded each year, then $1
received t years from now has the same value as 1(1  r)t dollars received today—that is,
the $1 is discounted by the discount factor raised to the t power. If you multiply a cash flow
received t years from now by 1(1  r)t to obtain its present value, then the total of these
present values over all years is called the net present value (NPV) of the cash flows. Basic
financial theory states that projects with positive NPVs increase the value of the company,
whereas projects with negative NPVs decrease the value of the company.
The rate r (usually called the discount rate) used by major corporations generally
comes from some version of the capital asset pricing model. The value of r used to eval-
uate any particular project depends on a number of things and can vary from project to pro-
ject. Because this is the focus of finance courses, we will not pursue it here. But given a
suitable value of r, the following example illustrates how spreadsheet models and the time
value of money can be used to make complex business decisions.
what you have learned about exponential curves from
these calculations.
Skill-Extending Problem
13. In the profit model in this section, we used the power
curve to relate demand and price because it has the
lowest MAPE. However, the exponential curve was
not far behind. Rework the profit model using the
exponential curve to relate demand to price. Write a
brief memo indicating whether you get basically the
same results as with the power curve or you get sub-
stantially different results.
The discount factor is 1 divided by (1 plus the discount rate). To discount a cash
flow that occurs t years from now, multiply it by the discount factor raised to the
t power. The NPV is the sum of all discounted cash flows.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

56
Chapter 2
Introduction to Spreadsheet Modeling
FUNDAMENTAL INSIGHT
TheTimeValue of Money
Money earned in the future is less valuable than money
earned today,for the simple reason that money earned
today can be in vested to earn inter est. Similarly, costs
incurred in the futur e ar e less “costly” than costs
incurred today, which is why you don’t simply sum up
revenues and costs in a multiperiod model.You instead
discount future revenues and costs f or a fair compari-
son with r evenues and costs incur
red toda y. The
resulting sum of discounted cash flo ws is the net pr e-
sent value (NPV),
and it f orms the cornerstone of
much of financial theory and applications.
E X A M P L E
2.6 CALCULATING NPV AT ACRON
A
cron is a large drug company. At the current time, the beginning of year 0, Acron is
trying to decide whether one of its new drugs, Niagra, is worth pursuing. Niagra is in
the final stages of development and will be ready to enter the market one year from now.
The final cost of development, to be incurred at the beginning of year 1, is $9.3 million.
Acron estimates that the demand for Niagra will gradually grow and then decline over its
useful lifetime of 20 years. Specifically, the company expects its gross margin (revenue
minus cost) to be $1.2 million in year 1, then to increase at an annual rate of 10% through
year 8, and finally to decrease at an annual rate of 5% through year 20. Acron wants to
develop a spreadsheet model of its 20-year cash flows, assuming its cash flows, other than
the initial development cost, are incurred at the ends of the respective years.8 Using an
annual discount rate of 12% for the purpose of calculating NPV, the drug company wants
to answer the following questions:
1.
Is the drug worth pursuing, or should Acron abandon it now and not incur the $9.3
million development cost?
2.
How do changes in the model inputs change the answer to question 1?
3.
How realistic is the model?
Business Objectives
To develop a model that calculates the NPV of Acron’s cash flows,
to use this model to determine whether the drug should be developed further and then mar-
keted, and to see how sensitive the answer to this question is to model parameters.
Excel Objecti ves
To illustrate efficient selection and copying of large ranges and to
learn Excel’s NPV function.
Solution
The key variables in Acron’s problem appear in Table 2.6. The first two rows contain the
inputs stated in the problem. We have made a judgment call as to which of these are known
with some certainty and which are uncertain. Although we won’t do so in this chapter, a
thorough study of Acron’s problem would treat this uncertainty explicitly, probably with
simulation. For now, you can accept the values given in the statement of the problem and
leave the simulation for a later chapter.
8To simplify the model, taxes are ignored.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

2.7 Decisions Involving the Time Value of Money
57
The model of Acron’s cash flows appears in Figure 2.34. As with many financial
spreadsheet models that extend over a multiyear period, you enter “typical” formulas in the
first year or two and then copy this logic down to all years. (In a previous edition, we made
the years go across, not down. In that case, splitting the screen is useful so that you can see
the first and last years of data. Splitting the screen is explained in the following Excel Tip.
The main reason we modified the model to have the years go down, not across, is that it
now fits easily on a screen, without needing to split the screen.)
Table 2.6
Key Variables for Acron’s Problem
Input variables
Development cost, first year gross margin, rate of increase 
during early years, years of growth, rate of decrease in later 
years, discount rate
Key output variable
NPV
Other calculated variables
Yearly gross margins
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
A
B
C
D
E
F
G
Calculang NPV at 
e
g
n
a
R
n
o
rc
A
 names used:
Development_cost
=Model!$B$4
Inputs
9
$
B
$
!le
d
o
M
=
e
t
a
r
_
t
n
u
o
c
si
D
Development cost
9.3
Gross_margin_year_1
=Model!$B$5
Gross margin year 1 
2
3
$
B
$:3
1
$
B
$
!le
d
o
M
=
nig
r
a
m
_
ss
o
r
G
2.1
Rate of increase
10%
Increase_through_year
=Model!$B$7
Increase through year 
8
Rate_of_decrease
=Model!$B$8
Rate of decrease
5%
Rate_of_increase
=Model!$B$6
Discount 
%
2
1
e
t
a
r
Cash ﬂows
End of year
Gross margin
1
1.2000
2
1.3200
3
1.4520
4
1.5972
5
1.7569
6
1.9326
7
2.1259
8
2.3385
9
2.2215
10
2.1105
11
2.0049
12
1.9047
13
1.8095
14
1.7190
15
1.6330
16
1.5514
17
1.4738
18
1.4001
19
1.3301
20
1.2636
3
0
0
3.3
V
P
N
Figure 2.34
Acron’s Model of
20-Year NPV
Excel Tip: Splitting the Screen
To split the screen horizontally, drag the separator just to the right of the bottom scrollbar
to the left. To split the screen vertically, drag the separator just above the right scrollbar
downward. Drag either separator back to its original position to remove the split.
DEVELOPING THE SPREADSHEET MODEL
To create the model, complete the following steps. (See the file Calculating NPV.xlsx.)
1
Inputs and range names. Enter the given input data in the blue cells, and name the
ranges as shown. As usual, note that the range names for cells B4 through B9 can be cre-
ated all at once with the Create from Selection shortcut, as can the range name for the gross
margins in column B. In the latter case, highlight the whole range B12:B32 and then use
the Create from Selection shortcut.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

58
Chapter 2
Introduction to Spreadsheet Modeling
2
Cash flows. Start by entering the formula
=Gross_margin_year_1
in cell B13 for the year 1 gross margin. Then enter the general formula
=IF(A14<=Increase_through_year,B13*(1+Rate_of_increase),
B13*(1-Rate_of_decrease))
in cell B14 and copy it down to cell B32 to calculate the other yearly gross margins. Note
how this IF function checks the year index in column A to see whether sales are still
increasing or have started to decrease. Of course, by using the (range-named) input cells in
this formula, you can change any of these inputs in cells B6 through B8, and the calculated
cells will automatically update. This is a much better practice than embedding the numbers
in the formula itself.
Excel Tip: Efficient Selection
An easy way to select a large range, assuming that the first and last cells of the range are visible,
is to select the first cell and then, with your finger on the Shift key, select the last cell. (Don’t for-
get that you can split the scr een horizontally and/or vertically to mak e these first and last cells
visible when the range is large.) This selects the entire range and is easier than scrolling.9
Excel Tip: Efficient Copying with Ctrl+Enter
An easy way to enter the same formula in a range all at once is to select the range (as in the
preceding Excel Tip), type the formula, and press Ctrl+Enter (both keys at once). After you
get used to this shortcut, you will probably use it all the time.
3
Net present value. The NPV is based on the sequence of cash flows in column B.
From the general discussion of NPV, to discount everything back to the beginning of year
1, the value in cell B13 should be multiplied by 1(1  r)1, the value in cell B14 should be
multiplied by 1(1  r)2, and so on, and these quantities should be summed to obtain the
NPV. (Here, r  0.12 is the discount rate.) Fortunately, however, Excel has a built-in NPV
function to accomplish this calculation. To use it, enter the formula
=-Development_cost+NPV(Discount_rate,Gross_margin)
in cell B34. The NPV function takes two arguments: the discount rate and a range of cash
flows. Furthermore, it assumes that the first cell in this range is the cash flow at the end of
year 1, the second cell is the cash flow at the end of year 2, and so on. This explains why
the development cost is subtracted outside of the NPV function—it is incurred at the begin-
ning of year 1. In general, any cash flow incurred at the beginning of year 1 must be placed
outside the NPV function.
To get some understanding of NPV, note that the sum of the cash flows in column B is
slightly more than $34.14 million, but the NPV (aside from the development cost) is only
about $12.60 million. This is because values further into the future are discounted so heav-
ily. At the extreme, the $1.2636 million cash flow in year 20 is equivalent to only
$1.2636[1(1  0.12)20]  $0.131 million now.
Excel Function: NPV
The NPV function takes two arguments, the discount rate (entered as a decimal, such as 0.12
for 12%) and a stream of cash flows. These cash flows are assumed to occur in consecutive
years, starting at the end of year 1. If there is an initial cash flow at the beginning of year 1,
such as an initial investment, it should be entered outside the NPV function. (There is also an
XNPV function that has three arguments: a discount rate, a series of cash flows, and a series
of dates when the cash flows occur. Because these dates do not have to be equally spaced
Use the Ctrl+Enter
shortcut to enter a
formula in a range
all at once. It is 
equivalent to 
copying.
9You can find other tips like this for increasing your efficiency in the Excel Tutorial.xlsx file on this textbook’s
essential resource Web site.
The stream of cash
flows in the NPV
function must occur
at the ends of year 1,
year 2, and so on. If
the timing is irregular,
you can discount 
“manually” or you 
can use Excel's XNPV
function.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

2.7 Decisions Involving the Time Value of Money
59
through time, this function is considerably more flexible than the NPV function.
We will not use the XNPV function in this book, but you can learn more about it in Excel’s
online help.)
Deciding Whether to Continue with the Drug
NPV calculations are typically used to see whether a certain project should be undertaken.
If the NPV is positive, the project is worth pursuing. If the NPV is negative, the company
should look for other places to invest its money. Figure 2.34 shows that the NPV for this
drug is positive, over $3 million.10 Therefore, if Acron is comfortable with its predictions
of future cash flows, it should continue with the development and marketing of the drug.
However, Acron might first want to see how sensitive the NPV is to changes in the sales
predictions. After all, these predictions are intelligent guesses at best.
One possible sensitivity analysis appears in Figure 2.35. Here you can build a one-way
data table to see how the NPV changes when the number of years of increase (the input in
cell B7) changes. Again, the important question is whether the NPV stays positive. It cer-
tainly does when the input variable is greater than its current value of 8. However, if sales
start decreasing soon enough—that is, if the value in B7 is 3 or less—the NPV turns nega-
tive. This should probably not concern Acron, because its best guess for the years of
increase is considerably greater than 3.
11
12
13
14
15
16
17
18
19
20
D
E
F
Sensivity to years of increase (cell B7)
3.3003
3
-0.7190
4
0.1374
5
0.9687
6
1.7739
7
2.5516
8
3.3003
9
4.0181
10
4.7027
Figure 2.35
Sensitivity of
NPV to Years of
Sales Increase
22
23
24
25
26
27
28
29
30
31
D
E
F
G
H
I
J
Sensivity to rate of increase in early years (cell B6) and years of increase (cell B7)
3.3003
5%
6%
7%
8%
9%
10%
3
-1.3405
-1.2184
-1.0951
-0.9708
-0.8454
-0.7190
4
-0.8203
-0.6352
-0.4469
-0.2554
-0.0606
0.1374
5
-0.3383
-0.0897
0.1652
0.4265
0.6943
0.9687
6
0.1074
0.4195
0.7419
1.0750
1.4189
1.7739
7
0.5182
0.8934
1.2838
1.6899
2.1123
2.5516
8
0.8958
1.3330
1.7912
2.2711
2.7738
3.3003
9
1.2413
1.7392
2.2643
2.8182
3.4023
4.0181
10
1.5559
2.1125
2.7033
3.3306
3.9963
4.7027
Figure 2.36
Sensitivity of
NPV to Years of
Increase and
Yearly Increase
Another possibility is to see how long and how good the good years are. To do this,
you can create the two-way data table shown in Figure 2.36, where cell B6 is the row input
cell and cell B7 is the column input cell. Now you can see that if sales increase through
year 6, all reasonable yearly increases result in a positive NPV. However, if sales increase
only through year 5, then a low enough yearly increase can produce a negative NPV. Acron
might want to step back and estimate how likely these bad scenarios are before proceeding
with the drug.
10You might wonder why we didn’t discount back to the beginning of the current year, year 0, instead of year 1.
This is a fairly arbitrary decision on our part. To discount back to year 0, you would simply divide the current 
NPV by 1.12. The important point, however, is that this would have no bearing on Acron’s decision: A positive NPV
would stay positive, and a negative NPV would stay negative.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

60
Chapter 2
Introduction to Spreadsheet Modeling
Limitations of the Model
Probably the major flaw in this model is that it ignores uncertainty, and future cash flows
are highly uncertain, due mainly to uncertain demand for the drug. Incorporating uncer-
tainty into this type of model will be covered when we discuss simulation in Chapters 10
and 11. Aside from this uncertainty, there are almost always ways to make any model more
realistic—at the cost of increased complexity. For example, you could model the impact of
competition on Niagra’s profitability. Alternatively, you could allow Acron to treat its
prices as decision variables. However, this might influence the likelihood of competition
entering the market, which would certainly complicate the model. The point is that this
model is only a start. When millions of dollars are at stake, a more thorough analysis is cer-
tainly warranted.
■
P R O B L E M S
Skill-Building Problems
14. Modify Acron’s model so that development lasts for
an extra year. Specifically, assume that development
costs of $7.2 million and $2.1 million are incurred at
the beginnings of years 1 and 2, and then the sales in
the current model occur one year later, that is, from
year 2 until year 21. Again, calculate the NPV dis-
counted back to the beginning of year 1, and perform
the same sensitivity analyses. Comment on the effects
of this change in timing.
15. Modify Acron’s model so that sales increase, then
stay steady, and finally decrease. Specifically, assume
that the gross margin is $1.2 million in year 1, then
increases by 10% annually through year 6, then stays
constant through year 10, and finally decreases by 5%
annually through year 20. Perform a sensitivity analy-
sis with a two-way data table to see how NPV varies
with the length of the increase period (currently 6
years) and the length of the constant period (currently
4 years). Comment on whether Acron should pursue
the drug, given your results.
16. Create a one-way data table in the Acron model to see
how the NPV varies with discount rate, which is
allowed to vary from 8% to 18% in increments of
0.5%. Explain intuitively why the results go in the
direction they go—that is, the NPV decreases as the
discount rate increases. Should Acron pursue the drug
for all of these discount rates?
Skill-Extending Problems
17. The NPV function automatically discounts each of the
cash flows and sums the discounted values. Verify that
it does this correctly for Acron’s model by calculating
the NPV the long way. That is, discount each cash
flow and then sum these discounted values. Use Excel
formulas to do this, but don’t use the NPV function.
(Hint: Remember that the discounted value of $1
received t years from now is 1(1  r)t dollars today.)
18. In a situation such as Acron’s, where a one-time cost
is followed by a sequence of cash flows, the internal
rate of return (IRR) is the discount rate that makes
the NPV equal to 0. The idea is that if the discount
rate is greater than the IRR, the company will not pur-
sue the project, but if the discount rate is less than the
IRR, the project is financially attractive.
a. Use Excel’s Goal Seek tool to find the IRR for the
Acron model.
b. Excel also has an IRR function. Look it up in
online help to see how it works, and then use it on
Acron’s model. Of course, you should get the same
IRR as in part a.
c. Verify that the NPV is negative when the discount
rate is slightly greater than the IRR, and that it is
positive when the discount rate is slightly less than
the IRR.
19. The XNPV function can calculate NPV for any
(possibly irregular) series of cash flows. Look this
function up in Excel’s online help. Then use it to 
develop a spreadsheet model that finds the NPV of 
the following series: a payment of $25,000 today
(assumed to be June 15, 2010), and cash inflows of
$10,000 on March 1, 2011; $15,000 on September 15,
2011; $8000 on January 20, 2012; $20,000 on April 1,
2012; and $10,000 on May 15, 2012. Discount these
back to “today” using a discount rate of 12%.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

2.8 Conclusion
61
2.8 CONCLUSION
The examples in this chapter provide a glimpse of things to come in later chapters. You have
seen the spreadsheet modeling approach to realistic business problems, learned how to
design spreadsheet models for readability, and explored some of Excel’s powerful tools, par-
ticularly data tables. In addition, at least three important themes have emerged from these
examples: relating inputs and decision variables to outputs by means of appropriate formu-
las, optimization (for example, finding a “best” order quantity), and the role of uncertainty
(uncertain response rate or demand). Although you have not yet learned the tools to explore
these themes fully, you will have plenty of opportunities to do so in the rest of this book.
Summary of Key Management Science Terms
Term
Explanation
Page
Model inputs
The numeric values that are given in any 
22
problem statement
Decision variables
The variables a decision maker has control over 
22
to obtain better solutions
Model outputs
The numeric values that result from combinations 
22
of inputs and decision variables through the use 
of logical formulas
Net present value (NPV)
The current worth of a stream of cash flows that 
55
occur in the future
Discount rate
Interest rate used for discounting future cash flows 
55
to get the net present value
Summary of Key Excel Terms
Term
Explanation
Excel
Page
IF function
Useful for implementing logic
=IF(condition,resultIfTrue, 
24
resultIfFalse)
Relative, absolute 
Useful for copying formulas;
A1 (relative), $A1 or A$1 (mixed),
29
cell addresses
absolute row or column stays fixed,
$A$1 (absolute); press F4 to
relative row or column “moves”
cycle through possibilities
Range names
Useful for making formulas more 
Type name in Name box, or use
33
meaningful
Create from Selection shortcut  
(Ctrl+Shift+F3)
Pasting range names
Provides a list of all range names in 
Use Paste List from Use 
33
the current workbook
in Formula dropdown list (F3)
Cell comments
Useful for documenting contents 
Right-click on cell, select Insert
34
of the cell
Comment menu item
One-way data table
Shows how one or more outputs 
Use Data Table from What-If 
36
vary as a single input varies
Analysis dropdown list
Goal Seek
Solves one equation in one unknown
Use Goal Seek from What-If 
37
Analysis dropdown list
Formula Auditing 
Useful for checking which cells are
Use Formula Auditing buttons 
38
toolbar
related to other cells through formulas
on Formulas ribbon
fx button
Useful for getting help on 
On Formula Bar
42
Excel functions
(continued)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

62
Chapter 2
Introduction to Spreadsheet Modeling
Summary of Key Excel Terms
(Continued)
Term
Explanation
Excel
Page
VLOOKUP function
Useful for finding a particular value 
=VLOOKUP(valueToCompare,
42
based on a comparison
lookupTable, columnToReturn)
Two-way data table
Shows how a single output varies 
Use Data Table from What-If 
43
as two inputs vary
Analysis dropdown list
SUMPRODUCT 
Calculates the sum of products of
=SUMPRODUCT(range1,range2)
44
function
values in two (or more) similar-
sized ranges
Trendline tool
Superimposes the best-fitting line 
With chart selected, right-click on 
47
or curve of a particular type on 
any point and select Add Trendline
a scatter chart or time series graph
Conditional 
Formats cells depending on whether
Use Conditional Formatting
51
formatting
specified conditions hold
on Home ribbon
Splitting screen
Useful for separating the screen 
Use screen splitters at top and right
57
horizontally and/or vertically
of scrollbars
Efficient selection
Useful for selecting a large 
While pressing the Shift key, click
58
rectangular range
on upper-left and bottom-right cells 
of range
Efficient copying
Shortcut for copying a formula 
Select the range, enter the formula, 
58
to a range
and press Ctrl+Enter
NPV function
Calculates NPV of a stream of cash 
=NPV(discountRate,cashFlows)
58
flows at the ends of consecutive 
years, starting in year 1
P R O B L E M S
Skill-Building Problems
20. Julie James is opening a lemonade stand. She believes
the fixed cost per week of running the stand is $50.00.
Her best guess is that she can sell 300 cups per week
at $0.50 per cup. The variable cost of producing a cup
of lemonade is $0.20.
a. Given her other assumptions, what level of sales
volume will enable Julie to break even?
b. Given her other assumptions, discuss how a change
in sales volume affects profit.
c. Given her other assumptions, discuss how a change
in sales volume and variable cost jointly affect
profit.
d. Use Excel’s Formula Auditing tools to show which
cells in your spreadsheet affect profit directly.
21. You are thinking of opening a Broadway play, I Love
You, You’re Mediocre, Now Get Better! It will cost 
$5 million to develop the show. There are 8 shows
per week, and you project the show will run for
100 weeks. It costs $1000 to open the theater each
night. Tickets sell for $50.00, and you earn an average
of $1.50 profit per ticket holder from concessions. The
theater holds 800, and you expect 80% of the seats to
be full.
a. Given your other assumptions, how many weeks
will the play have to run for you to earn a 100%
return on the play’s development cost?
b. Given your other assumptions, how does an
increase in the percentage of seats full affect profit?
c. Given your other assumptions, determine how a
joint change in the average ticket price and number
of weeks the play runs influence profit.
d. Use Excel’s Formula Auditing tools to show which
cells in the spreadsheet are directly affected by the
percentage of seats full.
22. You are thinking of opening a small copy shop. It
costs $5000 to rent a copier for a year, and it costs
$0.03 per copy to operate the copier. Other fixed costs
of running the store will amount to $400 per month.
You plan to charge an average of $0.10 per copy, and
the store will be open 365 days per year. Each copier
can make up to 100,000 copies per year.
a. For one to five copiers rented and daily demands 
of 500, 1000, 1500, and 2000 copies per day, find
annual profit. That is, find annual profit for each of
these combinations of copiers rented and daily 
demand.
b. If you rent three copiers, what daily demand for
copies will allow you to break even?
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

2.8 Conclusion
63
c. Graph profit as a function of the number of copiers
for a daily demand of 500 copies; for a daily
demand of 2000 copies. Interpret your graphs.
23. Georgia McBeal is trying to save for her retirement.
She believes she can earn 10% on average each year
on her retirement fund. Assume that at the beginning
of each of the next 40 years, Georgia will allocate x
dollars to her retirement fund. If at the beginning of a
year Georgia has y dollars in her fund, by the end of
the year, it will grow to 1.1y dollars. How much
should Georgia allocate to her retirement fund each
year to ensure that she will have $1 million at the end
of 40 years? What key factors are being ignored in this
analysis of the amount saved for retirement?
24. A European call option on a stock earns the owner an
amount equal to the price at expiration minus the exer-
cise price, if the price of the stock on which the call is
written exceeds the exercise price. Otherwise, the call
pays nothing. A European put option earns the owner
an amount equal to the exercise price minus the price
at expiration, if the price at expiration is less than the
exercise price. Otherwise, the put pays nothing. The
file P02_24.xlsx contains a template that finds (based
on the well-known Black–Scholes formula) the price
of a European call and put based on the following
inputs: today’s stock price, the duration of the option
(in years), the option’s exercise price, the risk-free rate
of interest (per year), and the annual volatility in stock
price. For example, a 40% volatility means approxi-
mately that the standard deviation of annual percent-
age changes in the stock price is 40%.
a. Consider a six-month European call option with
exercise price $40. Assume a current stock price of
$35, a risk-free rate of 5%, and an annual volatility
of 40%. Determine the price of the call option.
b. Use a data table to show how a change in volatility
changes the value of the option. Give an intuitive
explanation for your results.
c. Use a data table to show how a change in today’s
stock price changes the option’s value. Give an
intuitive explanation for your results.
d. Use a data table to show how a change in the
option’s duration changes the option’s value. Give
an intuitive explanation for your results.
25. Repeat parts a–d of the previous problem for a 
six-month European put option with exercise price
$40. Again, assume a current stock price of $35, a
risk-free rate of 5%, and an annual volatility of 40%.
26. The file P02_26.xlsx lists sales (in millions of dollars)
of Dell Computer during the period 1987–1997 (where
year 1 corresponds to 1987).
a. Fit a power and an exponential trend curve to these
data. Which fits the data better?
b. Use your part a answer to predict 1999 sales for
Dell.
c. Use your part a answer to describe how the sales of
Dell have grown from year to year.
d. Search the Web for more recent Dell sales data.
Then repeat the preceding parts using all of the data.
27. Dataware is trying to determine whether to give a
$10 rebate, cut the price $6, or have no price change
on a software product. Currently, 40,000 units of the
product are sold each week for $45 apiece. The vari-
able cost of the product is $5. The most likely case
appears to be that a $10 rebate will increase sales
30%, and half of all people will claim the rebate. 
For the price cut, the most likely case is that sales
will increase 20%.
a. Given all other assumptions, what increase in sales
from the rebate would make the rebate and price
cut equally desirable?
b. Dataware does not really know the increase in sales
that will result from a rebate or price cut. However,
the company is sure that the rebate will increase
sales by between 15% and 40% and that the price
cut will increase sales by between 10% and 30%.
Perform a sensitivity analysis that could be used to
help determine Dataware’s best decision.
28. The file P02_28.xlsx gives the annual sales for
Microsoft (in millions of dollars) for the years
1984–1993, where 1984 = year 1.
a. Fit an exponential curve to these data.
b. Assuming you are back in 1993, by what percent-
age do you estimate that Microsoft has grown each
year, based on this historical data?
c. Why can’t a high rate of exponential growth
continue for a long time?
d. Rather than an exponential curve, what curve might
better represent the growth of a new technology?
e. Search the Web for more recent Microsoft sales
data. Then repeat the preceding parts using all 
the data.
29. Assume that the number of units sold of a product is
given by 100  0.5P  26A, where P is the price
(in dollars) charged for the product and A is the
amount spent on advertising (in thousands of dollars).
Each unit of the product costs $5 to produce. Use a
data table to find the combination of price and adver-
tising that maximizes profit.
30. A company manufacturers a product in the U.S. and
sells it in England. The unit cost of manufacturing is
$50. The current exchange rate (dollars per pound) is
1.51. The demand function, which indicates how many
units the company can sell in England as a function of
price (in pounds) is of the power type, with constant
27556759 and exponent 2.4.
a. Develop a model for the company’s profit (in dol-
lars) as a function of the price it charges (in
pounds). Then use a data table to find the profit-
maximizing price to the nearest pound.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

64
Chapter 2
Introduction to Spreadsheet Modeling
b. If the exchange rate varies from its current value, does
the profit-maximizing price increase or decrease?
Does the maximum profit increase or decrease?
31. The yield of a chemical reaction is defined as the ratio
(expressed as a percentage) of usable output to the
amount of raw material input. Suppose the yield of a
chemical reaction depends on the length of time the
process is run and the temperature at which the process
is run. The yield can be expressed as follows:
Yield  90.79  1.095x1  1.045x2  2.7812
1
 2.524x2
2  0.775x1x2
Here x1  (Temperature  125)10 and x2  (Time 
 300)30, where temperature is measured in degrees
Fahrenheit, and time is measured in seconds. Use a
data table to find the temperature and time settings that
maximize the yield of this process.
32. A bond is currently selling for $1040. It pays the
amounts listed in the file P02_32.xlsx at the ends of
the next six years. The yield of the bond is the interest
rate that would make the NPV of the bond’s payments
equal to the bond’s price. Use Excel’s Goal Seek tool
to find the yield of the bond.
33. Assume the demand for a company’s drug Wozac during
the current year is 50,000, and assume demand will grow
at 5% a year. If the company builds a plant that can pro-
duce x units of Wozac per year, it will cost $16x. Each
unit of Wozac is sold for $3. Each unit of Wozac pro-
duced incurs a variable production cost of $0.20. It costs
$0.40 per year to operate a unit of capacity. Determine
how large a Wozac plant the company should build to
maximize its expected profit over the next 10 years.
34. Consider a project with the following cash flows: year
1, $400; year 2, $200; year 3, $600; year 4, $900;
year 5, $1000; year 6, $250; year 7, $230. Assume a
discount rate of 15% per year.
a. Find the project’s NPV if cash flows occur at the
ends of the respective years.
b. Find the project’s NPV if cash flows occur at the
beginnings of the respective years.
c. Find the project’s NPV if cash flows occur at the
middles of the respective years.
35. A software company is considering translating its
program into French. Each unit of the program sells
for $50 and incurs a variable cost of $10 to produce.
Currently, the size of the market for the product is
300,000 units per year, and the English version of the
software has a 30% share of the market. The company
estimates that the market size will grow by 10% a year
for the next five years, and at 5% per year after that. It
will cost the company $6 million to create a French
version of the program. The translation will increase
its market share to 40%. Given a 10-year planning
horizon, for what discount rates is it profitable to
create the French version of the software?
36. The payback of a project is the number of years it takes
before the project’s total cash flow is positive. Payback
ignores the time value of money. It is interesting, how-
ever, to see how differing assumptions on project
growth impact payback. Suppose, for example, that a
project requires a $300 million investment at year 0
(right now). The project yields cash flows for 10 years,
and the year 1 cash flow will be between $30 million
and $100 million. The annual cash flow growth will be
between 5% and 25% per year. (Assume that this
growth is the same each year.) Use a data table to see
how the project payback depends on the year 1 cash
flow and the cash flow growth rate.
Skill-Extending Problems
37. You are entering the widget business. It costs $500,000,
payable in year 1, to develop a prototype. This cost can
be depreciated on a straight-line basis during years 1–5.
Each widget sells for $40 and incurs a variable cost of
$20. During year 1, the market size is 100,000, and the
market is growing at 10% per year. You believe you
will attain a 30% market share. Profits are taxed at
40%, but there are no taxes on negative profits.
a. Given your other assumptions, what market share is
needed to ensure a total free cash flow (FCF) of $0
over years 1 to 5? (Note: FCF during a year equals
after-tax profits plus depreciation minus fixed
costs, if any.)
b. Explain how an increase in market share changes
profit.
c. Explain how an increase in market size growth
changes profit.
d. Use Excel’s auditing tool to show how the market
growth assumption influences your spreadsheet.
38. Suppose you are borrowing $25,000 and making
monthly payments with 1% interest. Show that the
monthly payments should equal $556.11. The key
relationships are that for any month t
(Ending month t balance) 
 (Ending month t  1 balance) 
 ((Monthly payment)  (Month t interest))
(Month t interest)  (Beginning month t balance) 
(Monthly interest rate)
Of course, the ending month 60 balance must equal 0.
39. You are thinking of starting Peaco, which will produce
Peakbabies, a product that competes with Ty’s Beanie
Babies. In year 0 (right now), you will incur costs of $4
million to build a plant. In year 1, you expect to sell
80,000 Peakbabies for a unit price of $25. The price of
$25 will remain unchanged through years 1 to 5. Unit
sales are expected to grow by the same percentage (g)
each year. During years 1 to 5, Peaco incurs two types
of costs: variable costs and SG&A (selling, general, and
administrative) costs. Each year, variable costs equal
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Appendix Tips for Editing and Documenting Spreadsheets
65
half of revenue. During year 1, SG&A costs equal 40%
of revenue. This percentage is assumed to drop 2% per
year, so during year 2, SG&A costs will equal 38% of
revenue, and so on. Peaco’s goal is to have profits for
years 0 to 5 sum to 0 (ignoring the time value of
money). This will ensure that the $4 million investment
in year 0 is paid back by the end of year 5. What annual
percentage growth rate g does Peaco require to pay
back the plant cost by the end of year 5?
40. Suppose the demand (in thousands) for a toaster is
given by 100p2, where p is the price in dollars
charged for the toaster.
a. If the variable cost of producing a toaster is $10,
what price maximizes profit?
b. The elasticity of demand is defined as the percent-
age change in demand created by a 1% change in
price. Using a data table, show that the demand for
toasters has constant elasticity, that is, the elasticity
doesn’t depend on the price. Would this be true if
the demand for toasters were linear in price?
41. The file P02_41.xlsx contains the cumulative
number of bits (in trillions) of DRAM (a type of
computer memory) produced and the price per bit 
(in thousandths of a cent).
a. Fit a power curve that can be used to show how
price per bit drops with increased production. This
relationship is known as the learning curve.
b. Suppose the cumulative number of bits doubles. Create
a prediction for the price per bit. Does the change in
the price per bit depend on the current price?
42. A large U.S. drug company, Pharmco, has 100 million
yen coming due in one year. Currently the yen is
worth $0.01. Because the value of the yen in U.S.
dollars in one year is unknown, the value of this
100 million yen in U.S. dollars is highly uncertain. To
hedge its risk, Pharmco is thinking of buying one-year
put options on the yen with an exercise price of
$0.008. For example, if the yen falls in value a year
from now to $0.007, the owner of the put receives
$0.001. The price of such a put is $0.00007. Show
how the dollar value of Pharmco’s receipts and
hedging expenses depends on the number of puts
purchased and the final $/yen exchange rate.
Assume final exchange rates between 0.006 $/yen
and 0.015 $/yen are possible.
43. The file P02_43.xlsx contains a template for a car
loan. Specifically, once values are entered in the blue
cells, you need to enter formulas in the gray cells to
calculate the amount financed, the monthly payment
(assuming that monthly payments stay the same
throughout the term of the loan), the total interest paid,
and an amortization schedule. For the latter, fill in the
entire gray area with formulas, but use IF functions so
that blanks appear past the term of the loan. 
44. The IRR is the discount rate r that makes a project have
an NPV of $0. You can find IRR in Excel with the
built-in IRR function, using the syntax =IRR(range of
cash flows). However, it can be tricky. In fact, if the
IRR is not near 10%, this function might not find an
answer, and you would get an error message. Then you
must try the syntax =IRR(range of cash flows, guess),
where “guess” is your best guess for the IRR. It is best
to try a range of guesses (say, 90% to 100%). Find
the IRR of the project described in Problem 34.
45. A project does not necessarily have a unique IRR.
(Refer to the previous problem for more information
on IRR.) Show that a project with the following cash
flows has two IRRs: year 1, $20; year 2, $82; year 3,
$60; year 4, $2. (Note: It can be shown that if the
cash flow of a project changes sign only once, the
project is guaranteed to have a unique IRR.)
46. The file P02_46.xlsx contains data on prices of prod-
ucts for several of a chain store’s locations, a discount
schedule offered to customers depending on how
much they spend, and commission rates of the sales-
people at the various stores. Your job is to develop an
invoice form. Specifically, you should enter formulas
in the gray cells so that whenever data are entered in
the blue cells, the formulas in the gray cells calculate
automatically. As an extra, use data validation in cell
B23 so that the user can choose a city from a list of
cities where the chain has its stores.
APPENDIX TIPS FOR EDITING AND 
DOCUMENTING SPREADSHEETS
Editing and documenting your spreadsheet models is crucial, and the following tips make
these tasks much easier.
Format Appropriately
Appropriate formatting can make a spreadsheet model much easier to read. To boldface, for
example,selectoneormorecellsandclickontheBbuttonontheHomeribbon(orpressCtrl+B).
Similarly, to italicize, indent, increase or decrease the number of decimal places, right-justify, or
perform other common formatting tasks, use the buttons on the Home ribbon or shortcut keys.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

66
Chapter 2
Introduction to Spreadsheet Modeling
Use Range Names
Naming ranges takes time but makes formulas much easier to read and understand. To
enter a range name, highlight any cell or range of cells and enter a name for the range in the
Name box (just to the left of the Formula Bar). If you want to edit or delete range names,
select Name Manager on the Formulas ribbon. Here are some other options you have from
the Defined Names group on the Formulas ribbon.
■
After you have named some ranges, you can get a list of them in your spreadsheet by
placing the cursor at the top of the range where you want the list to be placed,
selecting the Use in Formula dropdown list on the Formulas ribbon, and clicking on
the Paste List option. Alternatively, you can press the F3 button.
■
Suppose you have labels such as Fixed Cost, Variable Cost, Revenue, and Profit in the
range A3:A6, with their values next to them in column B. If you want to name the
cells in column B with the labels in column A, highlight the range A3:B6, select
Create from Selection on the Formulas ribbon (or press Ctrl+Shift+F3), and make 
sure the Left Column box is checked. This creates the range names you want. A similar
trick works if you have descriptive labels above columns of data you want 
to name.
■
If you have a formula, such as =SUM(A10:A20), and then you name the range
A10:A20 Costs, say, the formula does not change automatically to =SUM(Costs).
However, you can make it adapt to your new range name by selecting Apply Names
from the Define Name dropdown list on the Formulas ribbon.
■
Sometimes you might want to use the same range name, such as Total_cost, on
multiple worksheets of a workbook. For example, you might want Total_cost to refer
to cell B26 in Sheet1 and to cell C59 in Sheet2. The trick is to use a sheet-level name
rather than a workbook-level name for one or both versions of Total_cost. This is easy
to do from the Name Manager. When you define a new name, just select a worksheet
as the Scope of the name.
Use Text Boxes
Text boxes are very useful for documenting your work. To enter an explanation or any
other text into a text box, click on the Text Box button on the Insert ribbon, drag a box, and
start typing. This technique is much better than typing explanations into cells because text
boxes have word wrap. Therefore, text in text boxes is much easier to edit than text in cells.
Use Cell Comments
Cell comments provide another good way to document your work. To enter a comment in
a cell, select the cell and right-click. This brings up a dialog box (which is also useful for
other tasks such as formatting). Click on the Insert Comment item to enter a comment. If a
comment is already in the cell, this menu will contain Edit Comment and Delete Comment
items. The cells with comments should have small red triangles in their corners. When you
hover the cursor over the cell, the comment appears.
Other Tips
Finally, we urge you once again to open the Excel Tutorial.xlsx file on the Essential
Resource Web site and work through it. The file includes a number of techniques that will
make you a better and more efficient Excel user.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

67
Introduction to Optimization 
Modeling
C H A P T E R
OPTIMIZING MANUFACTURING OPERATIONS AT
GE PLASTICS
T
he General Electric Company (GE) is a global organization that must
deliver products to its customers anywhere in the world in the right
quantity, at the right time, and at a reasonable cost. One arm of GE is GE
Plastics (GEP), a $5 billion business that supplies plastics and raw materials to
such industries as automotive, appliance, computer, and medical equipment.
(GEP has now been reorganized into GE Advanced Materials [GEAM].) As
described in Tyagi et al. (2004), GEP practiced a “pole-centric” manufacturing
approach, making each product in the geographic area (Americas, Europe, or
Pacific) where it was to be delivered. However, it became apparent in the early
2000s that this approach was leading to higher distribution costs and mismat-
ches in capacity as more of GEP’s demand was originating in the Pacific region.
Therefore, the authors of the article were asked to develop a global optimi-
zation model to aid GEP’s manufacturing planning. Actually, GEP consists of
seven major divisions, distinguished primarily by the capability of their products
to withstand heat.The fastest growing of these divisions, the high performance
polymer (HPP) division, was chosen as the pilot for the new global approach.
3
© Keith Dannemiller/Corbis
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

All GEP divisions operate as two-echelon manufacturing systems.The first echelon
consists of resin plants,which convert raw material stocks into resins and ship them to the
second echelon,the finishing plants. These latter plants combine the resins with additives to
produce various grades of the end products.Each physical plant consists of several “plant
lines” that operate independently,and each of these plant lines is capable of producing
multiple products. All end products are then shipped to GE Polymerland warehouses
throughout the world.GE Polymerland is a wholly owned subsidiary that acts as the
commercial front for GEP.It handles all customer sales and deliveries from its network of
distribution centers and warehouses in more than 20 countries.Because of its experience
with customers,GE Polymerland is able to aid the GEP divisions in their planning processes
by supplying forecasts of demands and prices for the various products in the various global
markets.These forecasts are key inputs to the optimization model.
The optimization model itself attempts to maximize the total contribution margin
over a planning horizon, where the contribution margin equals revenues minus the sum
of manufacturing, material, and distribution costs.There are demand constraints,
manufacturing capacity constraints, and network flow constraints. The decision variables
include (1) the amount of resin produced at each resin plant line that will be used at
each finishing plant line, and (2) the amount of each end product produced at each
finishing plant line that will be shipped to each geographic region.The completed model
has approximately 3100 decision variables and 1100 constraints and is completely linear.
It was developed and solved in Excel (using LINGO, a commercial optimization solver,
not Excel’s Solver add-in), and execution time is very fast—about 10 seconds.
The demand constraints are handled in an interesting way. The authors of the study
constrain manufacturing to produce no more than the forecasted demands, but they do
not force manufacturing to meet these demands. Ideally, manufacturing would meet
demands exactly. However, because of its rapid growth, capacity at HPP in 2002 appeared
(at the time of the study) to be insufficient to meet the demand in 2005 and later years.
The authors faced this challenge in two ways. First, in cases where demand exceeds
capacity, they let their model of maximizing total contribution margin determine which
demands to satisfy.The least profitable demands are simply not met. Second, the authors
added a new resin plant to their model that would come on line in the year 2005 and
provide much needed capacity.They ran the model several times for the year 2005 (and
later years), experimenting with the location of the new plant.Although some of the
details are withheld in the article for confidentiality reasons, the authors indicate that
senior management approved the investment of a Europe-based plant that would cost
more than $200 million in plant and equipment.This plant was planned to begin
operations in 2005 and ramp up to full production capacity by 2007.
The decision support system developed in the study has been a success at the HPP
division since its introduction in 2002. Although the article provides no specific dollar
gains from the use of the model, it is noteworthy that the other GEP divisions are
adopting similar models for their production planning. ■
68
Chapter 3
Introduction to Optimization Modeling
3.1 INTRODUCTION
In this chapter, we introduce spreadsheet optimization, one of the most powerful and flexible
methods of quantitative analysis. The specific type of optimization we will discuss here is
linear programming (LP). LP is used in all types of organizations, often on a daily basis, to
solve a wide variety of problems. These include problems in labor scheduling, inventory
management, selection of advertising media, bond trading, management of cash flows, oper-
ation of an electrical utility’s hydroelectric system, routing of delivery vehicles, blending in
oil refineries, hospital staffing, and many others. The goal of this chapter is to introduce the
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

basic elements of LP: the types of problems it can solve, how LP problems can be modeled
in Excel, and how Excel’s powerful Solver add-in can be used to find optimal solutions. Then
in the next few chapters we will examine a variety of LP applications, and we will also look
at applications of integer and nonlinear programming, two important extensions of LP.
3.2 INTRODUCTION TO OPTIMIZATION
Before we discuss the details of LP modeling, it is useful to discuss optimization in general. All
optimization problems have several common elements. They all have decision variables, the
variables whose values the decision maker is allowed to choose. Either directly or indirectly, the
values of these variables determine such outputs as total cost, revenue, and profit. Essentially,
they are the variables a company or organization must know to function properly; they deter-
mine everything else. All optimization problems have an objective function (objective, for
short) to be optimized—maximized or minimized.1 Finally, most optimization problems have
constraints that must be satisfied. These are usually physical, logical, or economic restrictions,
depending on the nature of the problem. In searching for the values of the decision variables
that optimize the objective, only those values that satisfy all of the constraints are allowed.
Excel uses its own terminology for optimization, and we will use it as well. Excel refers
to the decision variables as the changing cells. These cells must contain numbers that are
allowed to change freely; they are not allowed to contain formulas. Excel refers to the objec-
tive as the objective cell. There can be only one objective cell, which could contain profit, total
cost, total distance traveled, or others, and it must be related through formulas to the changing
cells. When the changing cells change, the objective cell should change accordingly.
3.2 Introduction to Optimization
69
The changing cells contain the values of the decision variables.
The objective cell contains the objective to be minimized or maximized.
The constraints impose restrictions on the values in the changing cells.
Finally, there must be appropriate cells and cell formulas that operationalize the con-
straints. For example, one constraint might indicate that the amount of labor used can be no
more than the amount of labor available. In this case there must be cells for each of these two
quantities, and typically at least one of them (probably the amount of labor used) will be related
through formulas to the changing cells. Constraints can come in a variety of forms. One very
common form is nonnegativity. This type of constraint states that changing cells must have
nonnegative (zero or positive) values. Nonnegativity constraints are usually included for physi-
cal reasons. For example, it is impossible to produce a negative number of automobiles.
There are basically two steps in solving an optimization problem. The first step is the
model development step. Here you decide what the decision variables are, what the objec-
tive is, which constraints are required, and how everything fits together. If you are devel-
oping an algebraic model, you must derive the correct algebraic expressions. If you are
developing a spreadsheet model, the main focus of this book, you must relate all variables
with appropriate cell formulas. In particular, you must ensure that your model contains for-
mulas that relate the changing cells to the objective cell and formulas that operationalize
the constraints. This model development step is where most of your effort goes.
Nonnegativity constraints imply that changing cells must contain nonnegative values.
Typically, most of your
effort goes into the
model development
step.
1Actually, some optimization models are multicriteria models that try to optimize several objectives simultane-
ously. However, we will not discuss multicriteria models in this book.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

The second step in any optimization model is to optimize. This means that you must sys-
tematically choose the values of the decision variables that make the objective as large (for
maximization) or small (for minimization) as possible and cause all of the constraints to be
satisfied. Some terminology is useful here. Any set of values of the decision variables that sat-
isfies all of the constraints is called a feasible solution. The set of all feasible solutions is
called the feasible region. In contrast, an infeasible solution is a solution that violates at least
one constraint. Infeasible solutions are disallowed. The desired feasible solution is the one that
provides the best value—minimum for a minimization problem, maximum for a maximiza-
tion problem—for the objective. This solution is called the optimal solution.
Although most of your effort typically goes into the model development step, much of
the published research in optimization has been about the optimization step. Algorithms
have been devised for searching through the feasible region to find the optimal solution.
One such algorithm is called the simplex method. It is used for linear models. There are
other more complex algorithms used for other types of models (those with integer decision
variables and/or nonlinearities).
We will not discuss the details of these algorithms. They have been programmed into
the Excel’s Solver add-in. All you need to do is develop the model and then tell Solver
what the objective cell is, what the changing cells are, what the constraints are, and what
type of model (linear, integer, or nonlinear) you have. Solver then goes to work, finding the
best feasible solution with the appropriate algorithm. You should appreciate that if you
used a trial-and-error procedure, even a clever and fast one, it could take hours, weeks, or
even years to complete. However, by using the appropriate algorithm, Solver typically
finds the optimal solution in a matter of seconds.
Before concluding this discussion, we mention that there is really a third step in the
optimization process: sensitivity analysis. You typically choose the most likely values of
input variables, such as unit costs, forecasted demands, and resource availabilities, and
then find the optimal solution for these particular input values. This provides a single
“answer.” However, in any realistic situation, it is wishful thinking to believe that all of the
input values you use are exactly correct. Therefore, it is useful—indeed, mandatory in
most applied studies—to follow up the optimization step with what-if questions. What if
the unit costs increased by 5%? What if forecasted demands were 10% lower? What if
resource availabilities could be increased by 20%? What effects would such changes have
on the optimal solution? This type of sensitivity analysis can be done in an informal man-
ner or it can be highly structured. Fortunately, as with the optimization step itself, good
software allows you to obtain answers to various what-if questions quickly and easily.
3.3 A TWO-VARIABLE PRODUCT MIX MODEL
We begin with a very simple two-variable example of a product mix problem. This is a type
of problem frequently encountered in business where a company must decide its product
mix—how much of each of its potential products to produce—to maximize its net profit.
You will see how to model this problem algebraically and then how to model it in Excel.
You will also see how to find its optimal solution with Solver. Next, because it contains
70
Chapter 3
Introduction to Optimization Modeling
A feasible solution is a solution that satisfies all of the constraints.
The feasible region is the set of all feasible solutions.
An infeasible solution violates at least one of the constraints.
The optimal solution is the feasible solution that optimizes the objective.
An algorithm is
basically a plan of
attack. It is a
prescription for
carrying out the steps
required to achieve
some goal, such as
finding an optimal
solution.An algorithm
is typically translated
into a computer
program that does the
work.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

T
he PC Tech company assembles and then tests two models of computers, Basic and XP.
For the coming month, the company wants to decide how many of each model to
assembly and then test. No computers are in inventory from the previous month, and
because these models are going to be changed after this month, the company doesn’t want
to hold any inventory after this month. It believes the most it can sell this month are 600
Basics and 1200 XPs. Each Basic sells for $300 and each XP sells for $450. The cost of
component parts for a Basic is $150; for an XP it is $225. Labor is required for assembly
and testing. There are at most 10,000 assembly hours and 3000 testing hours available. Each
labor hour for assembling costs $11 and each labor hour for testing costs $15. Each Basic
requires five hours for assembling and one hour for testing, and each XP requires six hours
for assembling and two hours for testing. PC Tech wants to know how many of each model
it should produce (assemble and test) to maximize its net profit, but it cannot use more labor
hours than are available, and it does not want to produce more than it can sell.
Objective
To use LP to find the best mix of computer models that stays within the com-
pany’s labor availability and maximum sales constraints.
Solution
In all optimization models, you are given a variety of numbers—the inputs—and you are
asked to make some decisions that optimize an objective, while satisfying all constraints.
We summarize this information in a table such as Table 3.1. We believe it is a good idea to
create such a table before diving into the modeling details. In particular, you always need
to identify the appropriate decision variables, the appropriate objective, and the con-
straints, and you should always think about the relationships between them. Without a
clear idea of these elements, it is almost impossible to develop a correct algebraic or
spreadsheet model.
3.3 A Two-Variable Product Mix Model
71
E X A M P L E
3.1 ASSEMBLING AND TESTING COMPUTERS
Tables such as this 
one serve as a bridge
between the problem
statement and the
ultimate spreadsheet
(or algebraic) model.
Table 3.1
Variables and Constraints for Two-Variable Product Mix Model
Input variables
Hourly labor costs, labor availabilities, labor required 
for each computer, costs of component parts, unit 
selling prices, and maximum sales
Decision variables (changing cells)
Number of each computer model to produce 
(assemble and test)
Objective cell
Total net profit
Other calculated variables
Labor of each type used
Constraints
Labor used 
Labor available,
Number produced 
Maximum sales
…
…
The decision variables in this product mix model are fairly obvious. The company
must decide two numbers: how many Basics to produce and how many XPs to produce.
Once these are known, they can be used, along with the problem inputs, to calculate the
only two decision variables, you will see how it can be solved graphically. Although this
graphical solution is not practical for most realistic problems, it provides useful insights
into general LP models. The final step is then to ask a number of what-if questions about
the completed model.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

number of computers sold, the labor used, and the revenue and cost. However, as you will
see with other models in this chapter and the next few chapters, determining the decision
variables is not always this obvious.
An Algebraic Model
In the traditional algebraic solution method, you first identify the decision variables.2 In
this small problem they are the numbers of computers to produce. We label these x1 and x2,
although any other labels would do. The next step is to write expressions for the total net
profit and the constraints in terms of the xs. Finally, because only nonnegative amounts can
be produced, explicit constraints are added to ensure that the xs are nonnegative. The
resulting algebraic model is
Maximize 80x1  129x2
subject to:
To understand this model, consider the objective first. Each Basic produced sells for $300, and
the total cost of producing it, including component parts and labor, is 150  5(11)  1(15) 
 $220, so the profit margin is $80. Similarly, the profit margin for an XP is $129. Each profit
margin is multiplied by the number of computers produced and these products are then
summed over the two computer models to obtain the total net profit.
The first two constraints are similar. For example, each Basic requires five hours for
assembling and each XP requires six hours for assembling, so the first constraint says that the
total hours required for assembling is no more than the number available, 10,000. The third
and fourth constraints are the maximum sales constraints for Basics and XPs. Finally, nega-
tive amounts cannot be produced, so nonnegativity constraints on x1 and x2 are included.
For many years all LP problems were modeled this way in textbooks. In fact, many
commercial LP computer packages are still written to accept LP problems in essentially
this format. Since around 1990, however, a more intuitive method of expressing LP prob-
lems has emerged. This method takes advantage of the power and flexibility of spread-
sheets. Actually, LP problems could always be modeled in spreadsheets, but now with the
addition of Solver, spreadsheets have the ability to solve—that is, optimize—LP problems
as well. We use Excel’s Solver for all examples in this book.3
A Graphical Solution
When there are only two decision variables in an LP model, as there are in this product mix
model, you can solve the problem graphically. Although this graphical solution approach
is not practical in most realistic optimization models—where there are many more than
two decision variables—the graphical procedure illustrated here still yields important
insights for general LP models.
x1, x2 Ú 0
x2 … 1200
x1 … 600
x1 + 2x2 … 3000
5x1 + 6x2 … 10000
72
Chapter 3
Introduction to Optimization Modeling
2This is not a book about algebraic models; the main focus is on spreadsheet modeling. However, we present
algebraic models of the examples in this chapter for comparison with the corresponding spreadsheet models.
3The Solver add-in built into Microsoft Excel was developed by a third-party software company, Frontline
Systems. This company develops much more powerful versions of Solver for commercial sales, but its standard
version built into Office suffices for us. More information about Solver software offered by Frontline is given in
a brief appendix to this chapter.
Many commercial
optimization packages
require, as input, an
algebraic model of a
problem. If you ever
use one of these
packages, you will be
required to think
algebraically.
This graphical
approach works only
for problems with two
decision variables.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

In general, if the two decision variables are labeled x1 and x2, then the steps of the
method are to express the constraints and the objective in terms of x1 and x2, graph the
constraints to find the feasible region [the set of all pairs (x1, x2) satisfying the constraints,
where x1 is on the horizontal axis and x2 is on the vertical axis], and then move the objec-
tive through the feasible region until it is optimized.
To do this for the product mix problem, note that the constraint on assembling labor hours
can be expressed as 5x1  6x2  10000. To graph this, consider the associated equality
(replacing  with ) and find where the associated line crosses the axes. Specifically, when 
x1  0, then x2  10000/6  1666.7, and when x2  0, then x1  10000/5  2000. This pro-
vides the line labeled “assembling hour constraint” in Figure 3.1. It has slope 5/6  0.83.
The set of all points that satisfy the assembling hour constraint includes the points on this line
plus the points below it, as indicated by the arrow drawn from the line. (The feasible points are
below the line because the point (0, 0) is obviously below the line, and (0, 0) clearly satisfies
the assembly hour constraint.) Similarly, the testing hour and maximum sales constraints can
be graphed as shown in the figure. The points that satisfy all three of these constraints and are
nonnegative comprise the feasible region, which is below the dark lines in the figure.
To see which feasible point maximizes the objective, it is useful to draw a sequence of lines
where, for each, the objective is a constant. A typical line is of the form 80x1  129x2  c,
where c is a constant. Any such line has slope 80/129  0.620, regardless of the value of c.
This line is steeper than the testing hour constraint line (slope 0.5), but not as steep as the
assembling hour constraint line (slope 0.83). The idea now is to move a line with this slope up
and to the right, making c larger, until it just barely touches the feasible region. The last feasible
point that it touches is the optimal point.
Several lines with slope 0.620 are shown in Figure 3.1. The middle dotted line is the
one with the largest net profit that still touches the feasible region. The associated optimal
point is clearly the point where the assembling hour and XP maximum sales lines intersect.
You will eventually find (from Solver) that this point is (560,1200), but even if you didn’t
have the Solver add-in, you could find the coordinates of this point by solving two equa-
tions (the ones for assembling hours and XP maximum sales) in two unknowns.
Again, the graphical procedure illustrated here can be used only for the simplest of LP
models, those with two decision variables. However, the type of behavior pictured in Figure 3.1
generalizes to all LP problems. In general, all feasible regions are (the multidimensional
3.3 A Two-Variable Product Mix Model
73
Recall from algebra
that any line of the
form ax1  bx2  c
has slope a/b.This 
is because it can be 
put into the slope
intercept form 
x2  c/b  (a/b)x1.
3000
2000
1500
1666.7
600
1200
Feasible region 
(below dark lines)
Tesng hour
constraint
Assembling hour
constraint
Basic sales
constraint
XP sales
constraint
Isoproﬁt lines
(doed)
Opmal
soluon
XPs produced
Basics produced
Figure 3.1
Graphical Solution
to Two-Variable
Product Mix
Problem
Although limited in 
use, the graphical
approach yields the
important insight that
the optimal solution 
to any LP model is a
corner point of a
polygon.This limits the
search for the optimal
solution and makes 
the simplex method
possible.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

versions of) polygons. That is, they are bounded by straight lines (actually hyperplanes) that
intersect at several corner points. There are five corner points in Figure 3.1, three of which
are on the axes. (One of them is (0,0).) When the dotted objective line is moved as far as pos-
sible toward better values, the last feasible point it touches is one of the corner points. The
actual corner point it last touches is determined by the slopes of the objective and constraint
lines. Because there are only a finite number of corner points, it suffices to search among this
finite set, not the infinite number of points in the entire feasible region.4 This insight is
largely responsible for the efficiency of the simplex method for solving LP problems.
A Spreadsheet Model
We now turn our focus to spreadsheet modeling. There are many ways to develop an LP
spreadsheet model. Everyone has his or her own preferences for arranging the data in the
various cells. We do not provide exact prescriptions, but we do present enough examples to
help you develop good habits. The common elements in all LP spreadsheet models are the
inputs, changing cells, objective cell, and constraints.
■
Inputs. All numerical inputs—that is, all numeric data given in the statement of the
problem—should appear somewhere in the spreadsheet. Our convention is to color
all of the input cells blue. We also try to put most of the inputs in the upper left sec-
tion of the spreadsheet. However, we sometimes violate this latter convention when
certain inputs fit more naturally somewhere else.
■
Changing cells. Instead of using variable names, such as xs, spreadsheet models use
a set of designated cells for the decision variables. The values in these changing cells
can be changed to optimize the objective. The values in these cells must be allowed
to vary freely, so there should not be any formulas in the changing cells. To designate
them clearly, our convention is to color them red.
■
Objective cell. One cell, called the objective cell, contains the value of the objective.
Solver systematically varies the values in the changing cells to optimize the value in
the objective cell. This cell must be linked, either directly or indirectly, to the chang-
ing cells by formulas. Our convention is to color the objective cell gray.5
74
Chapter 3
Introduction to Optimization Modeling
4This is not entirely true. If the objective line is exactly parallel to one of the constraint lines, there can be multi-
ple optimal solutions—a whole line segment of optimal solutions. Even in this case, however, at least one of the
optimal solutions is a corner point.
5Our blue/red/gray color scheme shows up very effectively on a color monitor. For users of previous editions who
are used to colored borders, we find that it is easier in Excel 2007 and Excel 2010 to color the cells rather than put
borders around them.
FUNDAMENTAL INSIGHT
Geometry of LP Models and the Simplex
Method
The feasible region in any LP model is al ways a multi-
dimensional version of a pol ygon, and the objectiv e is
always a hyperplane, the multidimensional version of a
straight line.The objective should always be moved as
far as possible in the maximizing or minimizing dir
ec-
tion until it just touches the edge of the feasible region.
Because of this geometry,the optimal solution is always
a corner point of the polygon.The simplex method for
LP works so w ell because it can sear ch through the
finite number of corner points extremely efficiently and
recognize when it has found the best corner point.This
rather simple insight, plus its clever implementation in
software packages, has sa ved companies man y, many
millions of dollars in the past 50 years.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

■
Constraints. Excel does not show the constraints directly on the spreadsheet. Instead,
they are specified in a Solver dialog box, to be discussed shortly. For example, a set
of related constraints might be specified by
B16:C16B18:C18
This implies two separate constraints. The value in B16 must be less than or equal to the
value in B18, and the value in C16 must be less than or equal to the value in C18. We will
always assign range names to the ranges that appear in the constraints. Then a typical con-
straint might be specified as
Number_to_produceMaximum_sales
This is much easier to read and understand. (If you find that range names take too long to cre-
ate, you certainly do not have to use them. Solver models work fine with cell addresses only.)
■
Nonnegativity. Normally, the decision variables—that is, the values in the changing
cells—must be nonnegative. These constraints do not need to be written explicitly;
you simply check an option in the Solver dialog box to indicate that the changing
cells should be nonnegative. Note, however, that if you want to constrain any other
cells to be nonnegative, you must specify these constraints explicitly.
Overview of the Solution Process
As mentioned previously, the complete solution of a problem involves three stages. In the
model development stage you enter all of the inputs, trial values for the changing cells, and
formulas relating these in a spreadsheet. This stage is the most crucial because it is here that
all of the ingredients of the model are included and related appropriately. In particular, the
spreadsheet must include a formula that relates the objective to the changing cells, either
directly or indirectly, so that if the values in the changing cells vary, the objective value
varies accordingly. Similarly, the spreadsheet must include formulas for the various con-
straints (usually their left sides) that are related directly or indirectly to the changing cells.
After the model is developed, you can proceed to the second stage—invoking Solver.
At this point, you formally designate the objective cell, the changing cells, the constraints,
and selected options, and you tell Solver to find the optimal solution. If the first stage has
been done correctly, the second stage is usually very straightforward.
The third stage is sensitivity analysis. Here you see how the optimal solution changes
(if at all) as selected inputs are varied. This often provides important insights about the
behavior of the model.
We now illustrate this procedure for the product mix problem in Example 3.1.
WHERE DO THE NUMBERS COME FROM?
Textbooks typically state a problem, including a number of input values, and proceed
directly to a solution—without saying where these input values might come from. However,
finding the correct input values can sometimes be the most difficult step in a real-world sit-
uation. (Recall that finding the necessary data is step 2 of the overall modeling process, as
discussed in Chapter 1.) There are a variety of inputs in PC Tech’s problem, some easy to
find and others more difficult. Here are some ideas on how they might be obtained.
3.3 A Two-Variable Product Mix Model
75
Our coloring conventions
Color all input cells blue (appears light blue on the printed page).
Color all of the changing cells red (appears deep blue on the printed page).
Color the objective cell gray.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

■
The resource usages in rows 8 and 9, often called technological coefficients, should
be available from the production department. These people know how much labor it
takes to assemble and test these computer models.
■
The unit selling prices in row 11 have actually been chosen by PC Tech’s manage-
ment, probably in response to market pressures and the company’s own costs.
■
The maximum sales values in row 18 are probably forecasts from the marketing and
sales department. These people have some sense of how much they can sell, based on
current outstanding orders, historical data, and the prices they plan to charge.
■
The labor hour availabilities in rows 21 and 22 are probably based on the current
workforce size and possibly on new workers who could be hired in the short run.
Again, if these are regular-time hours and overtime is possible, the model would have
to be modified to include overtime.
DEVELOPING THE SPREADSHEET MODEL
The spreadsheet model appears in Figure 3.2. (See the file Product Mix 1.xlsx .) To
develop this model, use the following steps.
76
Chapter 3
Introduction to Optimization Modeling
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
G
F
E
D
C
B
A
Assembling and tesng
e
g
n
a
R
sr
e
t
u
p
m
o
c
names used:
Hours_available
=Model!$D$21:$D$22
Cost per labor hour assembling
$11
Hours_used
=Model!$B$21:$B$22
Cost per labor hour
$15
Maximum_sales
=Model!$B$18:$C$18
Number_to_produce
=Model!$B$16:$C$16
Inputs for assembling and tesng a
5
2
$
D
$
!le
d
o
M
=
tif
o
r
p
_la
t
o
T
r
e
t
u
p
m
o
c
Basic
XP
Labor hours for
6
5
ylb
m
e
ss
a
Labor hours for
2
1
g
nits
e
t
Cost of component parts
$150
$225
Selling
0
5
4
$
0
0
3
$
e
cir
p
Unit
9
2
1
$
0
8
$
nig
r
a
m
Assembling, tesng plan (# of computers)
Basic
XP
Number to
0
0
2
1
0
0
6
e
c
u
d
o
r
p
<=
<=
Maximum
0
0
2
1
0
0
6
s
ela
s
Constraints (hours per month)
Hours used
Hours available
Labor availability for assembling
10200
<=
10000
Labor availability for
3000
<=
3000
tesng
tesng
Net proﬁt ($ this month)
Basic
XP
Total
$48,000
$154,800
$202,800
Figure 3.2
Two-Variable Product Mix Model with an Infeasible Solution
■
The unit costs in rows 3, 4, and 10 should be easy to obtain. (See Figure 3.2.) These
are the going rates for labor and the component parts. Note, however, that the labor
costs are probably regular-time rates. If the company wants to consider overtime
hours, then the overtime rate (and labor hours availability during overtime) would be
necessary, and the model would need to be modified.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

1
Inputs. Enter all of the inputs from the statement of the problem in the shaded cells as
shown.
2
Range names. Create the range names shown in columns E and F. Our convention is
to enter enough range names, but not to go overboard. Specifically, we enter enough range
names so that the setup in the Solver dialog box, to be explained shortly, is entirely in
terms of range names. Of course, you can add more range names if you like (or you can
omit them altogether). The following tip indicates a quick way to create range names.
Excel Tip:
Shortcut for Creating Range Names
Select a range such as A16:C16 that includes nice labels in column A and the r ange you
want to name in columns B and C. Then, fr
om the Formulas ribbon, select Cr eate from
Selection and accept the default. You automatically get the labels in cells A16 as the range
name for the range B16:C16. This shortcut illustrates the usefulness of adding concise but
informative labels next to ranges you want to name.
3
Unit margins. Enter the formula
B11B8*$B$3B9*$B$4B10
in cell B12 and copy it to cell C12 to calculate the unit profit margins for the two models.
( Enter relative/absolute addresses that allow you to copy whenever possible.)
4
Changing cells. Enter any two values for the changing cells in the Number_to_produce
range. Any trial values can be used initially; Solver eventually finds the optimal values. Note
that the two values shown in Figure 3.2 cannot be optimal because they use more assembling
hours than are available. However, you do not need to worry about satisfying 
constraints at this point; Solver takes care of this later on.
5
Labor hours used. To operationalize the labor availability constraints, you must cal-
culate the amounts used by the production plan. To do this, enter the formula
SUMPRODUCT(B8:C8,Number_to_produce)
in cell B21 for assembling and copy it to cell B22 for testing. This formula is a shortcut for
the following fully written out formula:
B8*B16C8*C16
The SUMPRODUCT function is very useful in spreadsheet models, especially LP mod-
els, and you will see it often. Here, it multiplies the number of hours per computer by the
number of computers for each model and then sums these products over the two models.
When there are only two products in the sum, as in this example, the SUMPRODUCT
formula is not really any simpler than the written-out formula. However, imagine that
there are 50 models. Then the SUMPRODUCT formula is much simpler to enter (and
read). For this reason, use it whenever possible. Note that each range in this function,
B8:C8 and Number_to_produce, is a one-row, two-column range. It is important in the
SUMPRODUCT function that the two ranges be exactly the same size and shape.
6
Net profits. Enter the formula
B12*B16
in cell B25, copy it to cell C25, and sum these to get the total net profit in cell D25. This
latter cell is the objective to maximize. Note that if you didn’t care about the net profits for
the two individual models, you could calculate the total net profit with the formula
SUMPRODUCT(B12:C12,Number_to_produce)
As you see, the SUMPRODUCT function appears once again. It and the SUM function are
the most used functions in LP models.
3.3 A Two-Variable Product Mix Model
77
At this stage, it is
pointless to try to
outguess the optimal
solution.Any values in
the changing cells will
suffice.
The “linear”in linear
programming is all
about sums of
products.Therefore,
the SUMPRODUCT
function is natural 
and should be used
whenever possible.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Experimenting with Possible Solutions
The next step is to specify the changing cells, the objective cell, and the constraints in a
Solver dialog box and then instruct Solver to find the optimal solution. However, before
you do this, it is instructive to try a few guesses in the changing cells. There are two rea-
sons for doing so. First, by entering different sets of values in the changing cells, you can
confirm that the formulas in the other cells are working correctly. Second, this experimen-
tation can help you to develop a better understanding of the model.
For example, the profit margin for XPs is much larger than for Basics, so you might
suspect that the company will produce only XPs. The most it can produce is 1200 (maxi-
mum sales), and this uses fewer labor hours than are available. This solution appears in
Figure 3.3. However, you can probably guess that it is far from optimal. There are still
many labor hours available, so the company could use them to produce some Basics and
make more profit.
You can continue to try different values in the changing cells, attempting to get as
large a total net profit as possible while staying within the constraints. Even for this small
model with only two changing cells, the optimal solution is not totally obvious. You can
only imagine how much more difficult it is when there are hundreds or even thousands of
changing cells and many constraints. This is why software such as Excel’s Solver is
required. Solver uses a quick and efficient algorithm to search through all feasible solu-
tions (or more specifically, all corner points) and eventually find the optimal solution.
Fortunately, it is quite easy to use, as we now explain.
78
Chapter 3
Introduction to Optimization Modeling
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
G
F
E
D
C
B
A
Assembling and tesng computers
Range names used:
Hours_available
=Model!$D$21:$D$22
Cost per labor hour assembling
$11
Hours_used
=Model!$B$21:$B$22
Cost per labor hour
$15
Maximum_sales
=Model!$B$18:$C$18
Number_to_produce
=Model!$B$16:$C$16
Inputs for assembling and tesng a
5
2
$
D
$
!le
d
o
M
=
tif
o
r
p
_la
t
o
T
r
e
t
u
p
m
o
c
Basic
XP
Labor hours for
6
5
ylb
m
e
ss
a
Labor hours for
2
1
g
nits
e
t
Cost of component parts
$150
$225
Selling
0
5
4
$
0
0
3
$
e
cir
p
Unit
9
2
1
$
0
8
$
nig
r
a
m
Assembling, tesng plan (# of computers)
Basic
XP
Number to
0
0
2
1
0
e
c
u
d
o
r
p
<=
<=
Maximum
0
0
2
1
0
0
6
s
ela
s
Constraints (hours per month)
Hours used
Hours available
Labor availability for assembling
7200
<=
10000
Labor availability for
2400
<=
3000
tesng
tesng
Net proﬁt ($ this month)
Basic
XP
Total
$0
$154,800
$154,800
Figure 3.3
Two-Variable Product Mix Model with a Suboptimal Solution
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

USING SOLVER
To invoke Excel’s Solver, select Solver from the Data ribbon. (If there is no such item on
your PC, you need to load Solver. To do so, click on the Office button, then Excel Options,
then Add-Ins, and then Go at the bottom of the dialog box. This shows you the list of avail-
able add-ins. If there is a Solver Add-in item in the list, check it to load Solver. If there is no
such item, you need to rerun the Microsoft Office installer and elect to install Solver. It
should be included in a typical install, but some people elect not to install it the first time
around.) The dialog box in Figure 3.4 appears.6 It has three important sections that you must
fill in: the objective cell, the changing cells, and the constraints. For the product mix prob-
lem, you can fill these in by typing cell references or you can point, click, and drag the
appropriate ranges in the usual way. Better yet, if there are any named ranges, these range
names appear instead of cell addresses when you drag the ranges. In fact, for reasons of
readability, our convention is to use only range names, not cell addresses, in this dialog box.
3.3 A Two-Variable Product Mix Model
79
Figure 3.4
Solver Dialog Box
(in Excel 2010)
6This is the new Solver dialog box for Excel 2010. It is more convenient than similar dialog boxes in previous
versions because the typical settings now all appear in a single dialog box. In previous versions you have to click
on Options to complete the typical settings.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Excel Tip:
Range Names in Solver Dialog Box
Our usual procedure is to use the mouse to select the relevant ranges for the Solver dialog
box. Fortunately, if these ranges have already been named, then the range names will auto-
matically replace the cell addresses.
1
Objective. Select the Total_profit cell as the objective cell, and click on the Max
option. (Actually, the default option is Max.)
2
Changing cells. Select the Number_to_produce range as the changing cells.
3
Constraints. Click on the Add button to bring up the dialog box in Figure 3.5. Here
you specify a typical constraint by entering a cell reference or range name on the left, the
type of constraint from the dropdown list in the middle, and a cell reference, range name,
or numeric value on the right. Use this dialog box to enter the constraint
Number_to_produceMaximum_sales
(Note: You can type these range names into the dialog box, or you can drag them in the
usual way. If you drag them, the cell addresses shown in the figure eventually change into
range names if range names exist.) Then click on the Add button and enter the constraint
Hours_usedHours_available
Then click on OK to get back to the Solver dialog box. The first constraint says to produce
no more than can be sold. The second constraint says to use no more labor hours than are
available.
80
Chapter 3
Introduction to Optimization Modeling
Figure 3.5
Add Constraint
Dialog Box
Excel Tip: Inequality and Equality Labels in Spreadsheet Models
The  signs in cells B17:C17 and C21:C22 (see F igure 3.2 or Figure 3.3) are not a
necessary part of the Excel model. They are entered simply as labels in the spreadsheet
and do not substitute for entering the constr
aints in the Add Constr aint dialo g box.
However, they help to document the model, so we include them in all of the examples. In
fact, you should try to plan your spreadsheet models so that the two sides of a constraint
are in nearby cells, with “gutter” cells in between where you can attach labels like ,
, or . This convention tends to make the resulting spreadsheet models much more
readable.
Solver Tip: Entering Constraints in Groups
Constraints typically come in gr oups. Be ginners often enter these one at a time
, suc h as
B16B18 and C16 C18, in the Solver dialo g box. This can lead to a long list of con-
straints, and it is time-consuming
. It is better to enter them as a gr
oup, as in
B16:C16B18:C18. This is not only quicker, but it also takes advantage of range names you
have created. For example, this group ends up as Number_to_produce
Maximum_Sales.
…
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4
Nonnegativity. Because negative production quantities make no sense, you must tell
Solver explicitly to make the changing cells nonnegative. To do this, check the Make
Unconstrained Variables Non-Negative option shown in Figure 3.4. This automatically
ensures that all changing cells are nonnegative. (In previous versions of Solver, you have to
click on the Options button and then check the Assume Non-Negative option in the result-
ing dialog box.)
5
Linear model. There is one last step before clicking on the Solve button. As stated
previously, Solver uses one of several numerical algorithms to solve various types of mod-
els. The models discussed in this chapter are all linear models. (We will discuss the prop-
erties that distinguish linear models shortly.) Linear models can be solved most efficiently
with the simplex method. To instruct Solver to use this method, make sure Simplex LP is
selected in the Select a Solving Method dropdown list in Figure 3.4. (In previous versions
of Solver, you have to click on the Options button and then check the Assume Linear
Model option in the resulting dialog box. In fact, from now on, if you are using a pre-2010
version of Excel and we instruct you to use the simplex method, you should check the
Assume Linear Model option. In contrast, if we instruct you to use a nonlinear algorithm,
you should uncheck the Assume Linear Model option.)
6
Optimize. Click on the Solve button in the dialog box in Figure 3.4. At this point,
Solver does its work. It searches through a number of possible solutions until it finds the
optimal solution. (You can watch the progress on the lower left of the screen, although for
small models the process is virtually instantaneous.) When it finishes, it displays the mes-
sage shown in Figure 3.6. You can then instruct it to return the values in the changing cells
to their original (probably nonoptimal) values or retain the optimal values found by Solver.
In most cases you should choose the latter. For now, click on the OK button to keep the
Solver solution. You should see the solution shown in Figure 3.7.
3.3 A Two-Variable Product Mix Model
81
Checking the Non-
Negative option
ensures only that the
changing cells, not any
other cells, will be
nonnegative.
Figure 3.6
Solver Results
Message
Solver Tip: Messages from Solver
Actually, the message in Figure 3.6 is the one you hope for. However, in some cases Solver
is not able to f
ind an optimal solution, in whic
h case one of se
veral other messa ges
appears. We discuss some of these later in the chapter.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Discussion of the Solution
This solution says that PC Tech should produce 560 Basics and 1200 XPs. This plan uses
all available labor hours for assembling, has a few leftover labor hours for testing, pro-
duces as many XPs as can be sold, and produces a few less Basics than could be sold. No
plan can provide a net profit larger than this one—that is, without violating at least one of
the constraints.
The solution in Figure 3.7 is typical of solutions to optimization models in the follow-
ing sense. Of all the inequality constraints, some are satisfied exactly and others are not. In
this solution the XP maximum sales and assembling labor constraints are met exactly. We
say that they are binding. However, the Basic maximum sales and testing labor constraints
are nonbinding. For these nonbinding constraints, the differences between the two sides of
the inequalities are called slack.7 You can think of the binding constraints as bottlenecks.
They are the constraints that prevent the objective from being improved. If it were not for
the binding constraints on maximum sales and labor, PC Tech could obtain an even larger
net profit.
82
Chapter 3
Introduction to Optimization Modeling
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
G
F
E
D
C
B
A
Assembling and tesng
e
g
n
a
R
sr
e
t
u
p
m
o
c
names used:
Hours_available
=Model!$D$21:$D$22
Cost per labor hour assembling
$11
Hours_used
=Model!$B$21:$B$22
Cost per labor hour tesng
$15
Maximum_sales
=Model!$B$18:$C$18
Number_to_produce
=Model!$B$16:$C$16
Inputs for assembling and tesng a
5
2
$
D
$
!le
d
o
M
=
tif
o
r
p
_la
t
o
T
r
e
t
u
p
m
o
c
BasicXP
Labor hours for
6
5
ylb
m
e
ss
a
Labor hours for
2
1
g
nits
e
t
Cost of component parts
$150
$225
Selling
0
5
4
$
0
0
3
$
e
cir
p
Unit
9
2
1
$
0
8
$
nig
r
a
m
Assembling, tesng plan (# of computers)
Basic
XP
Number to
0
0
2
1
0
6
5
e
c
u
d
o
r
p
<=
<=
Maximum
0
0
2
1
0
0
6
s
ela
s
Constraints (hours per month)
Hours used
Hours available
Labor availability for assembling
10000
<=
10000
Labor availability for
2960
<=
3000
Net proﬁt ($ this month)
Basic
XP
Total
$44,800
$154,800
$199,600
tesng
Figure 3.7
Two-Variable Product Mix Model with the Optimal Solution
An inequality constraint is binding if the solution makes it an equality. Otherwise, it is
nonbinding, and the positive difference between the two sides of the constraint is
called the slack.
7Some analysts use the term slack only for  constraints and the term surplus for  constraints. We refer to both
of these as slack—the absolute difference between the two sides of the constraint.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

In a typical optimal solution, you should usually pay particular attention to two aspects of
the solution. First, you should check which of the changing cells are positive (as opposed
to 0). Generically, these are the “activities” that are done at a positive level. In a product
mix model, they are the products included in the optimal mix. Second, you should check
which of the constraints are binding. Again, these represent the bottlenecks that keep the
objective from improving.
■
3.4 Sensitivity Analysis
83
FUNDAMENTAL INSIGHT
Binding and Nonbinding Constraints
Most optimization models contain constraints
expressed as inequalities.In an optimal solution,each
such constraint is either binding (holds as an equal-
ity) or nonbinding. It is extremely important to iden-
tify the binding constraints because the
y ar e the
constraints that prevent the objective from improving.
A typical constraint is on the a
vailability of a
resource. If such a constraint is binding,the objective
could typicall y impr ove b y ha ving mor e of that
resource. But if such a r esource constraint is non-
binding, more of that r esource would not impr ove
the objective at all.
3.4 SENSITIVITY ANALYSIS
Having found the optimal solution, it might appear that the analysis is complete. But in real
LP applications the solution to a single model is hardly ever the end of the analysis. It is
almost always useful to perform a sensitivity analysis to see how (or if) the optimal solu-
tion changes as one or more inputs vary. We illustrate systematic ways of doing so in this
section. Actually, we discuss two approaches. The first uses an optional sensitivity report
that Solver offers. The second uses an add-in called SolverTable that one of the authors
(Albright) developed.
3.4.1 Solver’s Sensitivity Report
When you run Solver, the dialog box in Figure 3.6 offers you the option to obtain a sensi-
tivity report.8 This report is based on a well-established theory of sensitivity analysis in opti-
mization models, especially LP models. This theory was developed around algebraic
models that are arranged in a “standardized” format. Essentially, all such algebraic models
look alike, so the same type of sensitivity report applies to all of them. Specifically, they
have an objective function of the form c1x1  · · ·  cnxn, where n is the number of decision
variables, the cs are constants, and the xs are the decision variables, and each constraint can
be expressed as a1x1  · · ·  anxn
b, a1x1  · · ·  anxn
b, or a1x1  · · ·  anxn  b,
where the as and bs are constants. Solver’s sensitivity report performs two types of sensi-
tivity analysis: (1) on the coefficients of the objective, the cs, and (2) on the right sides of the
constraints, the bs.
Ú
…
Indeed, many analysts
view the “finished”
model as a starting
point for all sorts of
what-if questions.We
agree.
8It also offers Answer and Limits reports. We don’t find these particularly useful, so we will not discuss them
here.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

We illustrate the typical analysis by looking at the sensitivity report for PC Tech’s product
mix model in Example 3.1. For convenience, the algebraic model is repeated here.
Maximize 80x1  129x2
subject to:
On this Solver run, a sensitivity report is requested in Solver’s final dialog box. (See Figure
3.6.) The sensitivity report appears on a new worksheet, as shown in Figure 3.8.9 It con-
tains two sections. The top section is for sensitivity to changes in the two coefficients, 80
and 129, of the decision variables in the objective. Each row in this section indicates how
the optimal solution changes if one of these coefficients changes. The bottom section is for
the sensitivity to changes in the right sides, 10000 and 3000, of the labor constraints. Each
row of this section indicates how the optimal solution changes if one of these availabilities
changes. (The maximum sales constraints represent a special kind of constraint—upper
bounds on the changing cells. Upper bound constraints are handled in a special way in the
Solver sensitivity report, as described shortly.)
x1, x2 Ú 0
x2 … 1200
x1 … 600
x1 + 2x2 … 3000
5x1 + 6x2 … 10000
84
Chapter 3
Introduction to Optimization Modeling
Final
Reduced
Objecve
Allowable
Allowable
Cell
Name
Value
Cost
Coeﬃcient
Increase
Decrease
Final
Shadow
Constraint
Allowable
Allowable
Cell
Name
Value
Price
R.H. Side
Increase
Decrease
Figure 3.8
Solver Sensitivity Results
Now let’s look at the specific numbers and their interpretation. In the first row of the
top section, the allowable increase and allowable decrease indicate how much the coeffi-
cient of profit margin for Basics in the objective, currently 80, could change before the
optimal product mix would change. If the coefficient of Basics stays within this allowable
range, from 0 (decrease of 80) to 107.5 (increase of 27.5), the optimal product mix—the
set of values in the changing cells—does not change at all. However, outside of these lim-
its, the optimal mix between Basics and XPs might change.
9If your table looks different from ours, make sure you chose the Simplex LP method (or checked Assume Linear
Model in pre-2010 versions of Solver). Otherwise, Solver uses a nonlinear algorithm and produces a different
type of sensitivity report.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

To see what this implies, change the selling price in cell B11 from 300 to 299, so that
the profit margin for Basics decreases to $79. This change is well within the allowable
decrease of 80. If you rerun Solver, you will obtain the same values in the changing cells,
although the objective value will decrease. Next, change the value in cell B11 to 330. This
time, the profit margin for Basics increases by 30 from its original value of $300. This
change is outside the allowable increase, so the solution might change. If you rerun Solver,
you will indeed see a change—the company now produces 600 Basics and fewer than 
1200 XPs.
The reduced costs in the second column indicate, in general, how much the objective
coefficient of a decision variable that is currently 0 or at its upper bound must change
before that variable changes (becomes positive or decreases from its upper bound). The
interesting variable in this case is the number of XPs, currently at its upper bound of 1200.
The reduced cost for this variable is 33, meaning that the number of XPs will stay at 1200
unless the profit margin for XPs decreases by at least $33. Try it. Starting with the original
inputs, change the selling price for XPs to $420, a change of less than $33. If you rerun
Solver, you will find that the optimal plan still calls for 1200 XPs. Then change the selling
price to $410, a change of more than $33 from the original value. After rerunning Solver,
you will find that fewer than 1200 XPs are in the optimal mix.
3.4 Sensitivity Analysis
85
The reduced cost for any decision variable with value 0 in the optimal solution
indicates how much better that coefficient must be before that variable enters at a
positive level. The reduced cost for any decision variable at its upper bound in the
optimal solution indicates how much worse its coefficient must be before it will
decrease from its upper bound. The reduced cost for any variable between 0 and its
upper bound in the optimal solution is irrelevant.
Now turn to the bottom section of the report in Figure 3.8. Each row in this section
corresponds to a constraint, although upper bound constraints on changing cells are omit-
ted in this section. To have this part of the report make economic sense, the model should
be developed as has been done here, where the right side of each constraint is a numeric
constant (not a formula). Then the report indicates how much these right-side constants
can change before the optimal solution changes. To understand this more fully, the concept
of a shadow price is required. A shadow price indicates the change in the objective when
a right-side constant changes.
The term shadow price is an economic term. It indicates the change in the optimal
value of the objective when the right side of some constraint changes by one unit.
A shadow price is reported for each constraint. For example, the shadow price for the
assembling labor constraint is 16. This means that if the right side of this constraint
increases by one hour, from 10000 to 10001, the optimal value of the objective will
increase by $16. It works in the other direction as well. If the right side of this constraint
decreases by one hour, from 10000 to 9999, the optimal value of the objective will
decrease by $16. However, as the right side continues to increase or decrease, this $16
change in the objective might not continue. This is where the reported allowable increase
and allowable decrease are relevant. As long as the right side increases or decreases within
its allowable limits, the same shadow price of 16 still applies. Beyond these limits, how-
ever, a different shadow price might apply.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

You can prove this for yourself. First, increase the right side of the assembling labor
constraint by 200 (exactly the allowable increase), from 10000 to 10200, and rerun Solver.
(Don’t forget to reset other inputs to their original values.) You will see that the objective
indeed increases by 16(200)$3200, from $199,600 to $202,800. Now increase this right
side by one more hour, from 10200 to 10201 and rerun Solver. You will observe that the
objective doesn’t increase at all. This means that the shadow price beyond 10200 is less
than 16; in fact, it is zero. This is typical. When a right side increases beyond its allowable
increase, the new shadow price is typically less than the original shadow price (although it
doesn’t always fall to zero, as in this example).
86
Chapter 3
Introduction to Optimization Modeling
FUNDAMENTAL INSIGHT
Resource Availability and Shado
w Prices
If a r esource constraint is binding in the optimal
solution, the company is willing to pa y up to some
amount, the shadow price , to obtain mor e of the
resource.This is because the objective improves by
having more of the resource. However, there is typ-
ically a decreasing marginal eff ect: As the compan y
owns more and more of the resource, the shadow
price tends to decr
ease. This is usuall y because
other constraints become binding,
which causes
extra units of this resource to be less useful (or not
useful at all).
FUNDAMENTAL INSIGHT
The Effect of Constraints on the
Objective
If a constraint is ad
ded or an existing constraint
becomes mor e constraining (f or example , less of
some resource is available), the objective can only get
worse; it can ne ver impr ove. The easiest wa y to
understand this is to think of the f
easible r egion.
When a constraint is added or an existing constraint
becomes mor e constraining,
the f easible r egion
shrinks, so some solutions that w ere feasible before,
maybe even the optimal solution, are no longer feasi-
ble.The opposite is true if a constraint is deleted or
an existing constraint becomes less constraining.
In
this case, the objective can only improve; it can never
get worse. Again, the idea is that when a constraint 
is deleted or an existing constraint becomes less 
constraining, the f easible r egion expands.
In this 
case, all solutions that w ere feasible before are still
feasible, and there are some additional feasible solu-
tions available.
The idea is that a constraint “costs” the company by keeping the objective from being better
than it would be. A shadow price indicates how much the company would be willing to pay (in
units of the objective) to “relax” a constraint. In this example, the company would be willing to
pay $16 for each extra assembling hour. This is because such a change would increase the net
profit by $16. But beyond a certain point—200 hours in this example—further relaxation of the
constraint does no good, and the company is not willing to pay for any further increases.
The constraint on testing hours is slightly different. It has a shadow price of zero. In
fact, the shadow price for a nonbinding constraint is always zero, which makes sense. If the
right side of this constraint is changed from 3000 to 3001, nothing at all happens to the
optimal product mix or the objective value; there is just one more unneeded testing hour.
However, the allowable decrease of 40 indicates that something does change when the
right side reaches 2960. At this point, the constraint becomes binding—the testing hours
used equal the testing hours available—and beyond this, the optimal product mix starts to
change. By the way, the allowable increase for this constraint, shown as 1E30, means
that it is essentially infinite. The right side of this constraint can be increased above 3000
indefinitely and absolutely nothing will change in the optimal solution.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

3.4.2 SolverTable Add-In
The reason Solver’s sensitivity report makes sense for the product mix model is that the
spreadsheet model is virtually a direct translation of a standard algebraic model.
Unfortunately, given the flexibility of spreadsheets, this is not always the case. We have
seen many perfectly good spreadsheet models—and have developed many ourselves—that
are structured quite differently from their standard algebraic-model counterparts. In these
cases, we have found Solver’s sensitivity report to be more confusing than useful.
Therefore, Albright developed an Excel add-in called SolverTable. SolverTable allows
you to ask sensitivity questions about any of the input variables, not just coefficients of the
objective and right sides of constraints, and it provides straightforward answers.
The SolverTable add-in is on this book’s essential resource Web site.10 To install it,
simply copy the SolverTable files to a folder on your hard drive. These files include the
add-in itself (the .xlam file) and the online help files. To load SolverTable, you can proceed
in one of two ways:
1. Open the SolverTable.xlam file just as you open any other Excel file.
2. Go to the add-ins list in Excel (click on the Office button, then Excel Options, then
Add-Ins, then Go) and check the SolverTable item. If it isn’t in the list, Browse for
the SolverTable.xlam file.
The advantage of the second option is that if SolverTable is checked in the add-ins list, it
will automatically open every time you open Excel, at least until you uncheck its item in
the list.
The SolverTable add-in was developed to mimic Excel’s built-in data table tool.
Recall that data tables allow you to vary one or two inputs in a spreadsheet model and see
instantaneously how selected outputs change. SolverTable is similar except that it runs
Solver for every new input (or pair of inputs), and the newest version also provides auto-
matic charts of the results. There are two ways it can be used.
1. One-way table. A one-way table means that there is a single input cell and any num-
ber of output cells. That is, there can be a single output cell or multiple output cells.
2. Two-way table. A two-way table means that there are two input cells and one or
more output cells. (You might recall that an Excel two-way data table allows only
one output. SolverTable allows more than one. It creates a separate table for each
output as a function of the two inputs.)
We illustrate some of the possibilities for the product mix example. Specifically, we check
how sensitive the optimal production plan and net profit are to (1) changes in the selling
price of XPs, (2) the number of labor hours of both types available, and (3) the maximum
sales of the two models.
We assume that the model has been formulated and optimized, as shown in Figure 3.7,
and that the SolverTable add-in has been loaded. To run SolverTable, click on the Run
SolverTable button on the SolverTable ribbon. You will be asked whether there is a Solver
model on the active sheet. (Note that the active sheet at this point should be the sheet con-
taining the model. If it isn’t, click on Cancel and then activate this sheet.) You are then
given the choice between a one-way or a two-way table. For the first sensitivity question,
choose the one-way option. You will see the dialog box in Figure 3.9. For the sensitivity
analysis on the XP selling price, fill it in as shown. Note that ranges can be entered as cell
addresses or range names. Also, multiple ranges in the Outputs box should be separated by
commas.
3.4 Sensitivity Analysis
87
Solver’s sensitivity
report is almost
impossible to unravel
for some models. In
these cases Solver
Table is preferable
because of its easily
interpreted results.
We chose the input
range from 350 to 
550 in increments of
25 fairly arbitrarily.
You can choose any
desired range of input
values.
10It is also available from the Free Downloads link on the authors’ Web site at www.kelley.iu.edu/albrightbooks.
Actually, there are several versions of SolverTable available, each for a particular version of Solver. The one
described in the text is for Solver in Excel 2007 or 2010. This Web site contains more information about these
versions, as well as possible updates to SolverTable.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

88
Chapter 3
Introduction to Optimization Modeling
Figure 3.9
SolverTable One-
Way Dialog Box
1
2
3
4
5
6
7
8
9
10
11
12
13
A
B
C
D
E
F
G
Oneway analysis for Solver model in Model worksheet
Selling Price XP (cell $C$11) values along side, output cell(s) along top
Number_to_produce_1
Number_to_produce_2
Total_proﬁt
0
7
0
0
0
$350
600 1166.667
$81,833
$375
600 1166.667 $111,00
$400
600 1166.667 $140,16
$425
560
1200 $169,60
$450
560
1200 $199,60
$475
560
1200 $229,60
$500
560
1200 $259,600
0
$525
560
1200 $289,60
$550
560
1200 $319,600
Figure 3.10
SolverTable Results
for Varying XP Price
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Excel Tip:
Selecting Multiple Ranges
If you need to select multiple output ranges, the trick is to keep your finger on the Ctrl key as
you drag the ranges. This automatically enter s the separating comma(s) for you. Actually ,
the same trick works for selecting multiple changing cell ranges in Solver’s dialog box.
When you click on OK, Solver solves a separate optimization problem for each of the
nine rows of the table and then reports the requested outputs (number produced and net
profit) in the table, as shown in Figure 3.10. It can take a while, depending on the speed of
your computer and the complexity of the model, but everything is automatic. However, if
you want to update this table—by using different XP selling prices in column A, 
for example—you must repeat the procedure. Note that if the requested outputs are
included in named ranges, the range names are used in the SolverTable headings. For
example, the label Number_to_produce_1 indicates that this output is the first cell in the
Number_to_produce range. The label Total_profit indicates that this output is the only cell
in the Total_profit range. (If a requested output is not part of a named range, its cell address
is used as the label in the SolverTable results.)
3.4 Sensitivity Analysis
89
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
K
L
M
N
O
P
Q
R
Data for chart
Total_proﬁt
81833.33
111000
140166.7
169600
199600
229600
259600
289600
319600
0
50000
100000
150000
200000
250000
300000
350000
$350
$375
$400
$425
$450
$475
$500
$525
$550
Selling Price XP ($C$11)
Sensivity of Total_proﬁt to Selling Price XP
When you select an output address from
the dropdown list in cell $K$4, the chart
will adapt to that output.
Figure 3.11
Associated
SolverTable Chart
for Net Profit
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

The outputs in this table show that when the selling price of XPs is relatively low, the
company should make as many Basics as it can sell and a few less XPs, but when the sell-
ing price is relatively high, the company should do the opposite. Also, the net profit
increases steadily through this range. You can calculate these changes (which are not part
of the SolverTable output) in column E. The increase in net profit per every extra $25 in
XP selling price is close to, but not always exactly equal to, $30,000.
SolverTable also produces the chart in Figure 3.11. There is a dropdown list in cell K4
where you can choose any of the SolverTable outputs. (We selected the net profit, cell
D25.) The chart then shows the data for that column from the table in Figure 3.10. Here
there is a steady increase (slope about $30,000) in net profit as the XP selling price
increases.
The second sensitivity question asks you to vary two inputs, the two labor availabili-
ties, simultaneously. This requires a two-way SolverTable, so fill in the SolverTable dialog
box as shown in Figure 3.12. Here two inputs and two input ranges are specified, and mul-
tiple output cells are again allowed. An output table is generated for each of the output
cells, as shown in Figure 3.13. For example, the top table shows how the optimal number
of Basics varies as the two labor availabilities vary. Comparing the columns of this top
table, it is apparent that the optimal number of Basics becomes increasingly sensitive to the
available assembling hours as the number of available testing hours increases. The
SolverTable output also includes two charts (not shown here) that let you graph any row or
any column of any of these tables.
The third sensitivity question, involving maximum sales of the two models, reveals the
flexibility of SolverTable. Instead of letting these two inputs vary independently in a two-
way SolverTable, it is possible to let both of them vary according to a single percentage
change. For example, if this percentage change is 10%, both maximum sales increase by
90
Chapter 3
Introduction to Optimization Modeling
Figure 3.12
SolverTable Two-
Way Dialog Box
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

10%. The trick is to modify the model so that one percentage-change cell drives changes in
both maximum sales. The modified model appears in Figure 3.14. Starting with the origi-
nal model, enter the original values, 600 and 1200, in new cells, E18 and F18. (Do not
copy the range B18:C18 to E18:F18. This would make the right side of the constraint
3.4 Sensitivity Analysis
91
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
A
B
C
D
E
F
G
H
I
Assembling hours (cell $D$21) values along side, Tesng hours (cell $D$22) values along top, output cell in corner
Number_to_produce_1
2000
2500
3000
3500
4000
4500
5000
8000
600
250
160
160
160
160
160
8500
600
500
260
260
260
260
260
9000
600
600
360
360
360
360
360
9500
600
600
460
460
460
460
460
10000
600
600
560
560
560
560
560
10500
600
600
600
600
600
600
600
11000
600
600
600
600
600
600
600
11500
600
600
600
600
600
600
600
12000
600
600
600
600
600
600
600
8000
700
1125
1200
1200
1200
1200
1200
8500
700
1000
1200
1200
1200
1200
1200
9000
700
950
1200
1200
1200
1200
1200
9500
700
950
1200
1200
1200
1200
1200
10000
700
950
1200
1200
1200
1200
1200
10500
700
950
1200
1200
1200
1200
1200
11000
700
950
1200
1200
1200
1200
1200
11500
700
950
1200
1200
1200
1200
1200
12000
700
950
1200
1200
1200
1200
1200
Number_to_produce_2
2000
2500
3000
3500
4000
4500
5000
Total_proﬁt
2000
2500
3000
3500
4000
4500
5000
8000
$138,300
$165,125
$167,600
$167,600
$167,600
$167,600
$167,600
8500
$138,300
$169,000
$175,600
$175,600
$175,600
$175,600
$175,600
9000
$138,300
$170,550
$183,600
$183,600
$183,600
$183,600
$183,600
9500
$138,300
$170,550
$191,600
$191,600
$191,600
$191,600
$191,600
10000
$138,300
$170,550
$199,600
$199,600
$199,600
$199,600
$199,600
10500
$138,300
$170,550
$202,800
$202,800
$202,800
$202,800
$202,800
11000
$138,300
$170,550
$202,800
$202,800
$202,800
$202,800
$202,800
11500
$138,300
$170,550
$202,800
$202,800
$202,800
$202,800
$202,800
12000
$138,300
$170,550
$202,800
$202,800
$202,800
$202,800
$202,800
Figure 3.13
Two-Way SolverTable Results
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

E18:F18, which is not the desired behavior.) Then enter any percentage change in cell G18.
Finally, enter the formula
E18*(1$G$18)
in cell B18 and copy it to cell C18. Now a one-way SolverTable can be used with the per-
centage change in cell G18 to drive two different inputs simultaneously. Specifically, the
SolverTable dialog box should be set up as in Figure 3.15, with the corresponding results
in Figure 3.16.
You should always scan these sensitivity results to see if they make sense. For exam-
ple, if the company can sell 20% or 30% more of both models, it makes no more profit than
if it can sell only 10% more. The reason is labor availability. By this point, there isn’t
enough labor to produce the increased demand.
It is always possible to run a sensitivity analysis by changing inputs manually in the
spreadsheet model and rerunning Solver. The advantages of SolverTable, however, are that
it enables you to perform a systematic sensitivity analysis for any selected inputs and out-
puts, and it keeps track of the results in a table and associated chart(s). You will see other
applications of this useful add-in later in this chapter and in the next few chapters.
3.4.3 Comparison of Solver’s Sensitivity Report and SolverTable
Sensitivity analysis in optimization models is extremely important, so it is important that
you understand the pros and cons of the two tools in this section. Here are some points to
keep in mind.
92
Chapter 3
Introduction to Optimization Modeling
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
H
G
F
E
D
C
B
A
Assembling and tesng computers
Cost per labor hour assembling
$11
Cost per labor hour tesng
$15
Inputs for assembling and tesng a computer
Basic
XP
Labor hours for
6
5
ylb
m
e
ss
a
Labor hours for
2
1
g
nits
e
t
Cost of component parts
$150
$225
Selling
0
5
4
$
0
0
3
$
e
cir
p
Unit
9
2
1
$
0
8
$
nig
r
a
m
Assembling, tesng plan (# of computers)
Basic
XP
Number to
0
0
2
1
0
6
5
e
c
u
d
o
r
p
<=
<=
Original values
% change in both
Maximum
%
0
0
0
2
1
0
0
6
0
0
2
1
0
0
6
s
ela
s
Constraints (hours per month)
Hours used
Hours available
Labor availability for assembling
10000
<=
10000
Labor availability for tesng
2960
<=
3000
Net proﬁt ($ this month)
Basic
XP
Total
$44,800
$154,800
$199,600
Figure 3.14
Modified Model for Simultaneous Changes
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

3.4 Sensitivity Analysis
93
Figure 3.15
SolverTable One-
Way Dialog Box
3
4
5
6
7
8
9
10
11
A
B
C
D
E
F
G
% change in max sales (cell $G$18) values along side, output cell(s) along top
Number_to_produce_1
Number_to_produce_2
Total_proﬁt
$B$12
-
-
-
30%
420
840
$141,960
$80
20%
480
960
$162,240
$80
10%
540
1080
$182,520
$80
0%
560
1200
$199,600
$80
10%
500
1250
$201,250
$80
20%
500
1250
$201,250
$80
30%
500
1250
$201,250
$80
Figure 3.16
Sensitivity to 
Percentage Change
in Maximum Sales
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

■
Solver’s sensitivity report focuses only on the coefficients of the objective and 
the right sides of the constraints. SolverTable allows you to vary any of the 
inputs.
■
Solver’s sensitivity report provides very useful information through its reduced costs,
shadow prices, and allowable increases and decreases. This same information can be
obtained with SolverTable, but it requires a bit more work and some experimentation
with the appropriate input ranges.
■
Solver’s sensitivity report is based on changing only one objective coefficient or one
right side at a time. This one-at-a-time restriction prevents you from answering
certain questions directly. SolverTable is much more flexible in this respect.
■
Solver’s sensitivity report is based on a well-established mathematical theory of
sensitivity analysis in linear programming. If you lack this mathematical
background—as many users do—the outputs can be difficult to understand,
especially for somewhat nonstandard spreadsheet formulations. In contrast,
SolverTable’s outputs are straightforward. You can vary one or two inputs and see
directly how the optimal solution changes.
■
Solver’s sensitivity report is not even available for integer-constrained models, and
its interpretation for nonlinear models is more difficult than for linear models.
SolverTable’s outputs have the same interpretation for any type of optimization
model.
■
Solver’s sensitivity report comes with Excel. SolverTable is a separate add-in that is
not included with Excel—but it is included with this book and is freely available from
the Free Downloads link at the authors’ Web site, www.kelley.iu.edu/albrightbooks.
Because the SolverTable software essentially automates Solver, which has a number
of its own idiosyncrasies, some users have had problems with SolverTable on their
PCs. We have tried to document these on our Web site, and we are hoping that the
revised Solver in Excel 2010 helps to alleviate these problems.
In summary, each of these tools can be used to answer certain questions. We tend to favor
SolverTable because of its flexibility, but in the optimization examples in this chapter 
and the next few chapters we will illustrate both tools to show how each can provide useful
information.
3.5 PROPERTIES OF LINEAR MODELS
Linear programming is an important subset of a larger class of models called mathemati-
cal programming models.11 All such models select the levels of various activities that can
be performed, subject to a set of constraints, to maximize or minimize an objective such as
total profit or total cost. In PC Tech’s product mix example, the activities are the numbers
of PCs to produce, and the purpose of the model is to find the levels of these activities that
maximize the total net profit subject to specified constraints.
In terms of this general setup—selecting the optimal levels of activities—there are
three important properties that LP models possess that distinguish them from general
mathematical programming models: proportionality, additivity, and divisibility. We dis-
cuss these properties briefly in this section.
94
Chapter 3
Introduction to Optimization Modeling
11The word programming in linear programming or mathematical programming has nothing to do with com-
puter programming. It originated with the British term programme, which is essentially a plan or a schedule
of operations.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

3.5.1 Proportionality
Proportionality means that if the level of any activity is multiplied by a constant factor,
the contribution of this activity to the objective, or to any of the constraints in which the
activity is involved, is multiplied by the same factor. For example, suppose that the pro-
duction of Basics is cut from its optimal value of 560 to 280—that is, it is multiplied by
0.5. Then the amounts of labor hours from assembling and from testing Basics are both cut
in half, and the net profit contributed by Basics is also cut in half.
Proportionality is a perfectly valid assumption in the product mix model, but it is often
violated in certain types of models. For example, in various blending models used by
petroleum companies, chemical outputs vary in a nonlinear manner as chemical inputs are
varied. If a chemical input is doubled, say, the resulting chemical output is not necessarily
doubled. This type of behavior violates the proportionality property, and it takes us into the
realm of nonlinear optimization, which we discuss in Chapters 7 and 8.
3.5.2 Additivity
The additivity property implies that the sum of the contributions from the various activi-
ties to a particular constraint equals the total contribution to that constraint. For example,
if the two PC models use, respectively, 560 and 2400 testing hours (as in Figure 3.7), then
the total number used in the plan is the sum of these amounts, 2960 hours. Similarly, the
additivity property applies to the objective. That is, the value of the objective is the sum
of the contributions from the various activities. In the product mix model, the net profits
from the two PC models add up to the total net profit. The additivity property implies that
the contribution of any decision variable to the objective or to any constraint is indepen-
dent of the levels of the other decision variables.
3.5.3 Divisibility
The divisibility property simply means that both integer and noninteger levels of the activ-
ities are allowed. In the product mix model, we got integer values in the optimal solution,
560 and 1200, just by luck. For slightly different inputs, they could easily have been frac-
tional values. In general, if you want the levels of some activities to be integer values, there
are two possible approaches: (1) You can solve the LP model without integer constraints,
and if the solution turns out to have fractional values, you can attempt to round them to
integer values; or (2) you can explicitly constrain certain changing cells to contain integer
values. The latter approach, however, takes you into the realm of integer programming,
which we study in Chapter 6. At this point, we simply state that integer problems are much
more difficult to solve than problems without integer constraints.
3.5.4 Discussion of Linear Properties
The previous discussion of these three properties, especially proportionality and additivity, is
fairly abstract. How can you recognize whether a model satisfies proportionality and additivity?
This is easy if the model is described algebraically. In this case the objective must be of the form
a1x1  a2x2  · · ·  anxn
where n is the number of decision variables, the as are constants, and the xs are decision
variables. This expression is called a linear combination of the xs. Also, each constraint
must be equivalent to a form where the left side is a linear combination of the xs and the
right side is a constant. For example, the following is a typical linear constraint:
3x1  7x2  2x3
50
…
3.5 Properties of Linear Models
95
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

It is not quite so easy to recognize proportionality and additivity—or the lack of them—in
a spreadsheet model, because the logic of the model is typically embedded in a series of
cell formulas. However, the ideas are the same. First, the objective cell must ultimately
(possibly through a series of formulas in intervening cells) be a sum of products of con-
stants and changing cells, where a “constant” means that it does not depend on changing
cells. Second, each side of each constraint must ultimately be either a constant or a sum of
products of constants and changing cells. This explains why linear models contain so many
SUM and SUMPRODUCT functions.
It is usually easier to recognize when a model is not linear. Two particular situations
that lead to nonlinear models are when (1) there are products or quotients of expressions
involving changing cells or (2) there are nonlinear functions, such as squares, square roots,
or logarithms, that involve changing cells. These are typically easy to spot, and they guar-
antee that the model is nonlinear.
Whenever you model a real problem, you usually make some simplifying assumptions.
This is certainly the case with LP models. The world is frequently not linear, which means
that an entirely realistic model typically violates some or all of the three properties in this
section. However, numerous successful applications of LP have demonstrated the useful-
ness of linear models, even if they are only approximations of reality. If you suspect that the
violations are serious enough to invalidate a linear model, you should use an integer or non-
linear model, as we illustrate in Chapters 6–8.
In terms of Excel’s Solver, if the model is linear—that is, if it satisfies the propor-
tionality, additivity, and divisibility properties—you should check the Simplex option
(or the Assume Linear Model option in pre-2010 versions of Excel). Then Solver uses
the simplex method, a very efficient method for a linear model, to solve the problem.
Actually, you can check the Simplex option even if the divisibility property is
violated—that is, for linear models with integer-constrained variables—but Solver then
embeds the simplex method in a more complex algorithm (branch and bound) in its
solution procedure.
3.5.5 Linear Models and Scaling12
In some cases you might be sure that a model is linear, but when you check the Simplex
option (or the Assume Linear Model option) and then solve, you get a Solver message to
the effect that the conditions for linearity are not satisfied. This can indicate a logical error
in your formulation, so that the proportionality and additivity conditions are indeed not sat-
isfied. However, it can also indicate that Solver erroneously thinks the linearity conditions
are not satisfied, which is typically due to roundoff error in its calculations—not any error
on your part. If the latter occurs and you are convinced that the model is correct, you can
try not using the simplex method to see whether that works. If it does not, you should con-
sult your instructor. It is possible that the non-simplex algorithm employed by Solver sim-
ply cannot find the solution to your problem.
In any case, it always helps to have a well-scaled model. In a well-scaled model, all
of the numbers are roughly the same magnitude. If the model contains some very large
numbers—100,000 or more, say—and some very small numbers—0.001 or less, say—
it is poorly scaled for the methods used by Solver, and roundoff error is far more likely
to be an issue, not only in Solver’s test for linearity conditions but in all of its
algorithms.
96
Chapter 3
Introduction to Optimization Modeling
Real-life problems are
almost never exactly
linear. However, linear
approximations often
yield very useful
results.
12This section might seem overly technical. However, when you develop a model that you are sure is linear and
Solver then tells you it doesn’t satisfy the linear conditions, you will appreciate this section.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

If you believe your model is poorly scaled, there are three possible remedies. The first
is to check the Use Automatic Scaling option in Solver. (It is found by clicking on the
Options button in the main Solver dialog box.) This might help and it might not; we have
had mixed success. (Frontline Systems, the company that develops Solver, has told us that
the only drawback to checking this box is that the solution procedure can be slower.) The
second option is to redefine the units in which the various quantities are defined. Finally,
you can change the Precision setting in Solver’s Options dialog box to a larger number,
such 0.00001 or 0.0001. (The default has five zeros.)
Excel Tip: Rescaling a Model
Suppose you have a whole range of input values expressed, say, in dollars, and you would
like to reexpress them in thousands of dollars, that is, you would like to divide each value
by 1000. There is a simple copy/paste way to do this. Enter the value 1000 in some unused
cell and copy it. Then highlight the r ange you want to r escale, and from the Paste drop-
down menu, select P aste Special and then the Divide option. No formulas ar
e required;
your original values ar e automatically rescaled (and you can then delete the 1000 cell).
You can use this same method to add, subtract, or multiply by a constant.
3.6 INFEASIBILITY AND UNBOUNDEDNESS
In this section we discuss two of the things that can go wrong when you invoke Solver. Both
of these might indicate that there is a mistake in the model. Therefore, because mistakes are
common in LP models, you should be aware of the error messages you might encounter.
3.6.1 Infeasibility
The first problem is infeasibility. Recall that a solution is feasible if it satisfies all of the
constraints. Among all of the feasible solutions, you are looking for the one that optimizes
the objective. However, it is possible that there are no feasible solutions to the model.
There are generally two reasons for this: (1) there is a mistake in the model (an input was
entered incorrectly, such as a  symbol instead of a ) or (2) the problem has been so con-
strained that there are no solutions left. In the former case, a careful check of the model
should find the error. In the latter case, you might need to change, or even eliminate, some
of the constraints.
To show how an infeasible problem could occur, suppose in PC Tech’s product mix
problem you change the maximum sales constraints to minimum sales constraints (and
leave everything else unchanged). That is, you change these constraints from  to . If
Solver is then used, the message in Figure 3.17 appears, indicating that Solver cannot find
a feasible solution. The reason is clear: There is no way, given the constraints on labor
hours, that the company can produce these minimum sales values. The company’s only
choice is to set at least one of the minimum sales values lower. In general, there is no fool-
proof way to remedy the problem when a “no feasible solution” message appears. Careful
checking and rethinking are required.
3.6.2 Unboundedness
A second type of problem is unboundedness. In this case, the model has been formulated in
such a way that the objective is unbounded—that is, it can be made as large (or as small, for
minimization problems) as you like. If this occurs, you have probably entered a wrong input
or forgotten some constraints. To see how this could occur in the product mix problem,
3.6 Infeasibility and Unboundedness
97
You can decrease the
chance of getting an
incorrect “Conditions
for Assume Linear
Model are not
satisfied” message by
changing Solver’s
Precision setting.
A perfectly reasonable
model can have no
feasible solutions
because of too many
constraints.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

98
Chapter 3
Introduction to Optimization Modeling
Figure 3.17
No Feasible Solution
Message
Figure 3.18
Unbounded
Solution Message
suppose that you change all constraints to be  instead of . Now there is no upper bound on
how much labor is available or how many PCs the company can sell. If you make this change
in the model and then use Solver, the message in Figure 3.18 appears, stating that the objective
cell does not converge. In other words, the total net profit can grow without bound.
3.6.3 Comparison of Infeasibility and Unboundedness
Infeasibility and unboundedness are quite different in a practical sense. It is quite possible
for a reasonable model to have no feasible solutions. For example, the marketing depart-
ment might impose several constraints, the production department might add some more,
the engineering department might add even more, and so on. Together, they might
constrain the problem so much that there are no feasible solutions left. The only way out is
Except in very rare
situations, if Solver
informs you that your
model is unbounded, you
have made an error.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

to change or eliminate some of the constraints. An unboundedness problem is quite differ-
ent. There is no way a realistic model can have an unbounded solution. If you get the mes-
sage shown in Figure 3.18, then you must have made a mistake: You entered an input
incorrectly, you omitted one or more constraints, or there is a logical error in your model.
3.6 Infeasibility and Unboundedness
99
P R O B L E M S
Solutions for problems whose numbers appear within a
colored box can be found in the Student Solutions Files.
Refer to this book’s preface for purchase information.
Skill-Building Problems
1.
Other sensitivity analyses besides those discussed
could be performed on the product mix model. Use
SolverTable to perform each of the following. In each
case keep track of the values in the changing cells and
the objective cell, and discuss your findings.
a. Let the selling price for Basics vary from $220 to
$350 in increments of $10.
b. Let the labor cost per hour for assembling vary
from $5 to $20 in increments of $1.
c. Let the labor hours for testing a Basic vary from
0.5 to 3.0 in increments of 0.5.
d. Let the labor hours for assembling and testing an XP
vary independently, the first from 4.5 to 8.0 and the
second from 1.5 to 3.0, both in increments of 0.5.
2.
In PC Tech’s product mix problem, assume there is
another PC model, the VXP, that the company can
produce in addition to Basics and XPs. Each VXP
requires eight hours for assembling, three hours for
testing, $275 for component parts, and sells for $560.
At most 50 VXPs can be sold.
a. Modify the spreadsheet model to include this new
product, and use Solver to find the optimal product
mix.
b. You should find that the optimal solution is not
integer-valued. If you round the values in the chang-
ing cells to the nearest integers, is the resulting
solution still feasible? If not, how might you obtain 
a feasible solution that is at least close to optimal?
3.
Continuing the previous problem, perform a sensitivity
analysis on the selling price of VXPs. Let this price
vary from $500 to $650 in increments of $10, and
keep track of the values in the changing cells and the
objective cell. Discuss your findings.
4.
Again continuing Problem 2, suppose that you want to
force the optimal solution to be integers. Do this in
Solver by adding a new constraint. Select the changing
cells for the left side of the constraint, and in the
middle dropdown list, select the “int” option. How
does the optimal integer solution compare to the
optimal noninteger solution in Problem 2? Are the
changing cell values rounded versions of those in
Problem 2? Is the objective value more or less than 
in Problem 2?
5.
If all of the inputs in PC Tech’s product mix problem
are nonnegative (as they should be for any realistic
version of the problem), are there any input values
such that the resulting model has no feasible
solutions? (Refer to the graphical solution.)
6.
There are five corner points in the feasible region 
for the product mix problem. We identified the
coordinates of one of them: (560, 1200). Identify the
coordinates of the others.
a. Only one of these other corner points has positive
values for both changing cells. Discuss the changes
in the selling prices of either or both models that
would be necessary to make this corner point
optimal.
b. Two of the other corner points have one changing
cell value positive and the other zero. Discuss the
changes in the selling prices of either or both
models that would be necessary to make either of
these corner points optimal.
Skill-Extending Problems
7.
Using the graphical solution of the product mix model
as a guide, suppose there are only 2800 testing hours
available. How do the answers to the previous problem
change? (Is the previous solution still optimal? Is it
still feasible?)
8.
Again continuing Problem 2, perform a sensitivity
analysis where the selling prices of Basics and XPs
simultaneously change by the same percentage, but the
selling price of VXPs remains at its original value. Let
the percentage change vary from 25% to 50% in
increments of 5%, and keep track of the values in the
changing cells and the total profit. Discuss your findings.
9.
Consider the graphical solution to the product mix
problem. Now imagine that another constraint—any
constraint—is added. Which of the following three
things are possible: (1) the feasible region shrinks;
(2) the feasible region stays the same; (3) the feasible
region expands? Which of the following three things
are possible: (1) the optimal value in objective cell
decreases; (2) the optimal value in objective cell stays
the same; (3) the optimal value in objective cell
increases? Explain your answers. Do they hold just for
this particular model, or do they hold in general?
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

3.7 A LARGER PRODUCT MIX MODEL
The problem we examine in this section is a direct extension of the product mix model in
the previous section. There are two modifications. First, the company makes eight com-
puter models, not just two. Second, testing can be done on either of two lines, and these
two lines have different characteristics.
100
Chapter 3
Introduction to Optimization Modeling
E X A M P L E
3.2 PRODUCING COMPUTERS AT PC TECH
A
s in the previous example, PC Tech must decide how many of each of its computer
models to assemble and test, but there are now eight available models, not just two.
Each computer must be assembled and then tested, but there are now two lines for testing.
The first line tends to test faster, but its labor costs are slightly higher, and each line has a
certain number of hours available for testing. Any computer can be tested on either line.
The inputs for the model are same as before: (1) the hourly labor costs for assembling and
testing, (2) the required labor hours for assembling and testing any computer model,
(3) the cost of component parts for each model, (4) the selling prices for each model,
(5) the maximum sales for each model, and (6) labor availabilities. These input values are
listed in the file Product Mix 2.xlsx. As before, the company wants to determine the prod-
uct mix that maximizes its total net profit.
Objective
To use LP to find the mix of computer models that maximizes total net profit
and stays within the labor hour availability and maximum sales constraints.
WHERE DO THE NUMBERS COME FROM?
The same comments as in Example 3.1 apply here.
Solution
Table 3.2 lists the variables and constraints for this model. You must choose the number of
computers of each model to produce on each line, the sum of which cannot be larger than the
maximum that can be sold. This choice determines the labor hours of each type used and all
revenues and costs. No more labor hours can be used than are available.
Table 3.2
Variables and Constraints for Larger Product Mix Model
Input variables
Hourly labor costs, labor availabilities, labor required for 
each computer, costs of component parts, unit selling 
prices, and maximum sales
Decision variables (changing cells)
Numbers of computer of each model to test on each line
Objective cell
Total net profit
Other calculated variables
Number of each computer model produced, hours of labor 
used for assembling and for each line of testing
Constraints
Computers produced 
Maximum sales
Labor hours used 
Labor hours available
…
…
It is probably not immediately obvious what the changing cells should be for this model (at
least not before you look at Table 3.2). You might think that the company simply needs to
decide how many computers of each model to produce. However, because of the two
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

testing lines, this is not enough information. The company must also decide how many of
each model to test on each line. For example, suppose they decide to test 100 model 4s on
line 1 and 300 model 4s on line 2. This means they will need to assemble (and ultimately
sell) 400 model 4s. In other words, given the detailed plan of how many to test on each
line, everything else is determined. But without the detailed plan, there is not enough infor-
mation to complete the model. This is the type of reasoning you must go through to deter-
mine the appropriate changing cells for any LP model.
An Algebraic Model
We will not spell out the algebraic model for this expanded version of the product mix
model because it is so similar to the two-variable product mix model. However, we will say
that it is larger, and hence probably more intimidating. Now we need decision variables of
the form 
, the number of model j computers to test on line i, and the total net profit and
each labor availability constraint will include a long SUMPRODUCT formula involving
these variables. Instead of focusing on these algebraic expressions, we turn directly to the
spreadsheet model.
DEVELOPING THE SPREADSHEET MODEL
The spreadsheet in Figure 3.19 illustrates the solution procedure for PC Tech’s product
mix problem. (See the file Product Mix 2.xlsx.) The first stage is to develop the spread-
sheet model step by step.
1
Inputs. Enter the various inputs in the blue ranges. Again, remember that our conven-
tion is to color all input cells blue. Enter only numbers, not formulas, in input cells. They
should always be numbers directly from the problem statement. (In this case, we supplied
them in the spreadsheet template.)
2
Range names. Name the ranges indicated. According to our convention, there are
enough named ranges so that the Solver dialog box contains only range names, no cell
addresses. Of course, you can name additional ranges if you like. (Note that you can again
use the range-naming shortcut explained in the Excel tip for the previous example. That is,
you can take advantage of labels in adjacent cells, except for the Profit cell.)
3
Unit margins. Note that two rows of these are required, one for each testing line,
because the costs of testing on the two lines are not equal. To calculate them, enter the
formula
B$13-$B$3*B$9-$B4*B10-B$12
in cell B14 and copy it to the range B14:I15.
4
Changing cells. As discussed above, the changing cells are the red cells in rows 19
and 20. You do not have to enter the values shown in Figure 3.19. You can use any trial val-
ues initially; Solver will eventually find the optimal values. Note that the four values
shown in Figure 3.19 cannot be optimal because they do not satisfy all of the constraints.
Specifically, this plan uses more labor hours for assembling than are available. However,
you do not need to worry about satisfying constraints at this point; Solver will take care of
this later.
5
Labor used. Enter the formula
SUMPRODUCT(B9:E9,Total_computers_produced)
in cell B26 to calculate the number of assembling hours used. Similarly, enter the formulas
SUMPRODUCT(B10:I10,Number_tested_on_line_1)
xij
3.7 A Larger Product Mix Model
101
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

and
SUMPRODUCT(B11:I11,Number_tested_on_line_2)
in cells B27 and B28 for the labor hours used on each testing line.
Excel Tip: Copying formulas with range names
When you enter a r ange name in an Excel formula and then copy the formula, the r ange
name reference acts like an absolute reference. Therefore, it wouldn’t work to copy the for-
mula in cell B27 to cell B28. Howe ver, this would work if r ange names hadn’t been used.
This is one potential disadvantage of range names that you should be aware of.
102
Chapter 3
Introduction to Optimization Modeling
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
J
I
H
G
F
E
D
C
B
A
Assembling and tesng computers
Cost per labor hour assembling
$11
Cost per labor hour tesng, line 1
$19
Cost per labor hour tesng, line 2
$17
Inputs for assembling and tesng a computer
Model 1
Model 2
Model 3
Model 4
Model 5
Model 6
Model 7
Model 8
Labor hours for assembly
Labor hours for tesng, line
Labor hours for tesng, line
5
5.5
5.5
5.5
6
1
1.5
4
5
5
2
2
2
2.5
2.5
2.5
3
2
2
2.5
2.5
2.5
3
3
3.5
3.5
Cost of component parts
$150
$225
$225
$225
$250
$250
$250
$300
Selling
0
0
6
$
0
3
5
$
5
2
5
$
0
0
5
$
0
7
4
$
0
6
4
$
0
5
4
$
0
5
3
$
e
cir
p
Unit margin, tested on line
Unit margin, tested on line
1
$128
$132
$142
$152
$142
$167
$172
$177
2
$122
$128
$138
$148
$139
$164
$160
$175
Assembling, tesng plan (# of computers)
Model 1
Model 2
Model 3
Model 4
Model 5
Model 6
Model 7
Model 8
Number tested on line
0
0
5
0
0
0
0
0
1
1000
800
Number tested on line
0
5
2
1
0
0
0
2
0
0
0
0
Total computers produced
0
0
0
1250
0
500
1000
800
<=
<=
<=
<=
<=
<=
<=
<=
Maximum
0
0
8
0
0
0
1
0
0
0
1
0
0
0
1
0
5
2
1
0
5
2
1
0
5
2
1
0
0
5
1
s
ela
s
Constraints (hours per month)
Hours used
Hours available
Labor availability for
Labor availability for tesng, line
Labor availability for tesng, line
assembling
19300
<=
20000
1
6150
<=
5000
2
3125
<=
6000
Net proﬁt ($ per month)
Model 1
Model 2
Model 3
Model 4
Model 5
Model 6
Model 7
Model 8
Totals
Tested on line
0
5,3
8
$
0
$
0
$
0
$
0
$
0
$
1
0 $172,000 $141,600 $397,100
Tested on line
5
7
3,4
8
1
$
0
$
0
$
0
$
0
$
5
7
3,4
8
1
$
0
$
0
$
0
$
2
$581,475
Range names used:
8
2
$
D
$:6
2
$
D
$
!le
d
o
M
=
elb
alia
v
a
_
sr
u
o
H
8
2
$
B
$:6
2
$
B
$
!le
d
o
M
=
d
e
s
u
_
sr
u
o
H
3
2
$I$:3
2
$
B
$
!le
d
o
M
=
s
ela
s
_
m
u
m
ix
a
M
Number_tested_on_line_1
=Model!$B$19:$I$19
Number_tested_on_line_2
=Model!$B$20:$I$20
Total_computers_produce d
=Model!$B$21:$I$21
3
3
$
J
$
!le
d
o
M
=
tif
o
r
p
_la
t
o
T
Figure 3.19
Larger Product Mix Model with Infeasible Solution
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

6
Revenues, costs, and pr ofits. The area from row 30 down shows the summary of
monetary values. Actually, only the total profit in cell J33 is needed, but it is also useful to
calculate the net profit from each computer model on each testing line. To obtain these,
enter the formula
B14*B19
in cell B31 and copy it to the range B31:I32. Then sum these to obtain the totals in column
J. The total in cell J33 is the objective to maximize.
Experimenting with Other Solutions
Before going any further, you might want to experiment with other values in the changing
cells. However, it is a real challenge to guess the optimal solution. It is tempting to fill up
the changing cells corresponding to the largest unit margins. However, this totally ignores
their use of the scarce labor hours. If you can guess the optimal solution to this model, you
are better than we are!
USING SOLVER
The Solver dialog box should be filled out as shown in Figure 3.20. (Again, note that there are
enough named ranges so that only range names appear in this dialog box.) Except that this
model has two rows of changing cells, the Solver setup is identical to the one in Example 3.1.
3.7 A Larger Product Mix Model
103
Figure 3.20
Solver Dialog Box
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Discussion of the Solution
When you click on Solve, you obtain the optimal solution shown in Figure 3.21. The opti-
mal plan is to produce computer models 1, 4, 6, and 7 only, some on testing line 1 and oth-
ers on testing line 2. This plan uses all of the available labor hours for assembling and
testing on line 1, but about 1800 of the testing line 2 hours are not used. Also, maximum
sales are achieved only for computer models 1, 6, and 7. This is typical of an LP solution.
Some of the constraints are met exactly—they are binding—whereas others contain a cer-
tain amount of slack. The binding constraints prevent PC Tech from earning an even higher
profit.
104
Chapter 3
Introduction to Optimization Modeling
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
J
I
H
G
F
E
D
C
B
A
Assembling and tesng computers
Cost per labor hour
Cost per labor hour tesng, line
Cost per labor hour tesng, line
assembling
$11
1
$19
2
$17
Inputs for assembling and tesng a computer
Model 1
Model 2
Model 3
Model 4
Model 5
Model 6
Model 7
Model 8
Labor hours for assembly
Labor hours for tesng, line
Labor hours for tesng, line
Cost of component
5
5.5
5.5
5.5
6
1
1.5
4
5
5
2
2
2
2.5
2.5
2.5
3
2
2
2.5
2.5
2.5
3
3
3.5
3.5
parts
$150
$225
$225
$225
$250
$250
$250
$300
Selling
0
0
6
$
0
3
5
$
5
2
5
$
0
0
5
$
0
7
4
$
0
6
4
$
0
5
4
$
0
5
3
$
e
cir
p
Unit margin, tested on line
Unit margin, tested on line
1
$128
$132
$142
$152
$142
$167
$172
$177
2
$122
$128
$138
$148
$139
$164
$160
$175
Assembling, tesng plan (# of computers)
Model 1
Model 2
Model 3
Model 4
Model 5
Model 6
Model 7
Model 8
Number tested on line 1
1500
0
0
125
0
0
1000
0
Number tested on line
0
0
0
0
0
1
0
5
7
4
0
0
0
2
Total computers produced
1500
0
0
600
0
1000
1000
0
<=
<=
<=
<=
<=
<=
<=
<=
Maximum
0
0
8
0
0
0
1
0
0
0
1
0
0
0
1
0
5
2
1
0
5
2
1
0
5
2
1
0
0
5
1
s
ela
s
Constraints (hours per month)
Hours used
Hours available
Labor availability for assembling
20000
<=
20000
Labor availability for tesng, line
Labor availability for tesng, line
1
5000
<=
5000
2
4187.5
<=
6000
Net proﬁt ($ per month)
Model 1
Model 2
Model 3
Model 4
Model 5
Model 6
Model 7
Model 8
Totals
Tested on line
5
2,1
9
1
$
1
0
$0
$0
$19,000
$0
$0
$172,000
$0
$382,250
Tested on line
0
5,3
6
1
$
0
$
3
6
0,0
7
$
0
$
0
$
0
$
2
0
$0
$0
$233,563
$615,813
Figure 3.21
Optimal Solution to Larger Product Mix Model
You typically gain
insights into a solution
by checking which
constraints are binding
and which contain
slack.
Excel Tip: Roundoff Error
Because of the way numbers are stored and calculated on a computer, the optimal values in
the changing cells and elsewhere can contain small roundoff errors. For example, the value
that really appears in cell E20 on one of our Excel 2007 PCs is 475.000002015897, not
exactly 475. For all pr actical purposes, this number can be tr eated as 475, and we have
formatted it as such in the spreadsheet. (We have been told that roundoff in Solver results
should be less of a problem in Excel 2010.)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Sensitivity Analysis
If you want to experiment with different inputs to this problem, you can simply change the
inputs and then rerun Solver. The second time you use Solver, you do not have to specify
the objective and changing cells or the constraints. Excel remembers all of these settings
and saves them when you save the file.
You can also use SolverTable to perform a more systematic sensitivity analysis on one
or more input variables. One possibility appears in Figure 3.22, where the number of avail-
able assembling labor hours is allowed to vary from 18,000 to 25,000 in increments
of 1000, and the numbers of computers produced and profit are designated as outputs.
3.7 A Larger Product Mix Model
105
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
A
B
C
D
E
F
G
H
I
J
Assembling labor (cell $D$26) values along side, output cell(s) along top
Total_computers_produced_1
Total_computers_produced_2
Total_computers_produced_3
Total_computers_produced_4
Total_computers_produced_5
Total_computers_produced_6
Total_computers_produced_7
Total_computers_produced_8
Total_proﬁt
18000
1500
0
0
200
0
1000
1000
0
$556,813
19000
1500
0
0
400
0
1000
1000
0
$586,313
20000
1500
0
0
600
0
1000
1000
0
$615,813
21000
1500
0
0
800
0
1000
1000
0
$645,313
22000
1500
0
0
1000
0
1000
1000
0
$674,813
23000
1500
0
0
1200
0
1000
1000
0
$704,313
24000
1500
0
700
1250
0
1000
500
0
$724,750
25000
1500
0
1250
1250
0
1000
60
0
$727,170
0
100000
200000
300000
400000
500000
600000
700000
800000
18000
19000
20000
21000
22000
23000
24000
25000
Assembling labor ($D$26) 
Sensivity of Total_proﬁt to Assembling labor 
Figure 3.22
Sensitivity to Assembling Labor Hours
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

There are several ways to interpret the output from this sensitivity analysis. First, you can
look at columns B through I to see how the product mix changes as more assembling labor
hours become available. For assembling labor hours from 18,000 to 23,000, the only thing
that changes is that more model 4s are produced. Beyond 23,000, however, the company
starts to produce model 3s and produces fewer model 7s. Second, you can see how extra
labor hours add to the total profit. Note exactly what this increased profit means. For exam-
ple, when labor hours increase from 20,000 to 21,000, the model requires that the company
must pay $11 apiece for these extra hours (if it uses them). But the net effect is that profit
increases by $29,500, or $29.50 per extra hour. In other words, the labor cost increases by
$11,000 [$11(1000)], but this is more than offset by the increase in revenue that comes
from having the extra labor hours.
As column J illustrates, it is worthwhile for the company to obtain extra assembling
labor hours, even though it has to to pay for them, because its profit increases. However,
the increase in profit per extra labor hour—the shadow price of assembling labor hours—
is not constant. In the top part of the table, it is $29.50 (per extra hour), but it then
decreases to $20.44 and then $2.42. The accompanying SolverTable chart of column J
illustrates this decreasing shadow price through its decreasing slope.
SolverTable Technical Tip:
Charts and Roundoff
As SolverTable makes all of its Solver runs, it r eports and then charts the values found by
Solver. These can include small roundoff errors and slightly misleading charts. For exam-
ple, the chart in Figure 3.23 shows one possibility, where we varied the cost of testing on
line 2 and charted the assembling hours used. Throughout the range, this output value was
20,000, but because of slight roundoff (19999.9999999292 and 20000.0000003259) in two
of the cells, the chart doesn’t appear to be flat. If you see this behavior, you can change it
manually.
106
Chapter 3
Introduction to Optimization Modeling
$10
20000
20000
20000
20000
20000
20000
20000
20000
$11 $12 $13 $14 $15 $16 $17 $18 $19 $20 $21 $22 $23 $24 $25
Tesng cost 2 ($B$5)
Sensivity of Hours_used_1 to Tesng cost 2
Figure 3.23
A Misleading
SolverTable Chart
Finally, you can gain additional insight from Solver’s sensitivity report, shown in
Figure 3.24. However, you have to be very careful in interpreting this report. Unlike
Example 3.1, there are no upper bound (maximum sales) constraints on the changing
cells. The maximum sales constraints are on the total computers produced (row 21 of
the model), not the changing cells. Therefore, the only nonzero reduced costs in the top
part of the table are for changing cells currently at zero (not those at their upper bounds
as in the previous example). Each nonzero reduced cost indicates how much the profit
margin for this activity would have to change before this activity would be profitable.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Also, there is a row in the bottom part of the table for each constraint, including the
maximum sales constraints. The interesting values are again the shadow prices. The
first two indicate the amount the company would pay for an extra assembling or line 1
testing labor hour. (Does the 29.5 value look familiar? Compare it to the SolverTable
results above.) The shadow prices for all binding maximum sales constraints indicate
how much more profit the company could make if it could increase its demand by one
computer of that model.
3.7 A Larger Product Mix Model
107
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
H
G
F
E
D
C
B
A
Variable Cells
Final
Reduced
Allowable
Allowable
e
s
a
e
rc
e
D
e
s
a
e
rc
n
I
t
n
eiciff
e
o
C
ts
o
C
e
ula
V
e
m
a
N
lle
C
tested on line 1 Model 1
1500
0
127.5
1E+30
2.125
tested on line 1 Model
0
2
-
tested on line 1 Model
0
3
-
20
132
20
1E+30
10
142
10
1E+30
tested on line 1 Model 4
125
0
152
2.833
1.7
tested on line 1 Model
0
5
-25.875
142
25.875
1E+30
tested on line 1 Model
0
6
-
tested on line 1 Model
tested on line 1 Model
0
8
-
tested on line 2 Model
0
1
-
tested on line 2 Model
0
2
-
tested on line 2 Model
0
3
-
tested on line 2 Model
tested on line 2 Model
0
5
-
tested on line 2 Model
tested on line 2 Model
0
7
-
$B$19 Number
$C$19 Number
$D$19 Number
$E$19 Number
$F$19 Number
$G$19 Number
$H$19 Number
$I$19
Number
$B$20 Number
$C$20 Number
$D$20 Number
$E$20 Number
$F$20 Number
$G$20 Number
$H$20 Number
$I$20
Number tested on line 2 Model
0
8
-
2.125
167
2.125
1E+30
7
1000
0
172
1E+30
4.125
6.75
177
6.75
1E+30
2.125
122
2.125
1E+30
20
127.5
20
1E+30
10
137.5
10
1E+30
4
475
0
147.5
1.136
2.083
23.75
138.5
23.75
1E+30
6
1000
0
163.5
1E+30
1.25
6.375
160
6.375
1E+30
2.5
174.5
2.5
1E+30
Constraints
Final
Shadow
Constraint
Allowable
Allowable
.
H
.
R
e
cir
P
e
ula
V
e
m
a
N
lle
C
Side
Increase
Decrease
availability for assembling Hours used
20000
29.5
20000
3250
2375
availability for tesng, line 1 Hours
availability for tesng, line 2 Hours used
4187.5
0
6000
1E+30
1812.5
computers produced Model
used
5000
2.25
5000
950
250
1
1500
6.125
1500
166.667
812.5
computers produced Model
0
5
2
1
0
3
+
E
1
0
5
2
1
0
0
2
computers produced Model
0
5
2
1
0
3
+
E
1
0
5
2
1
0
0
3
computers produced Model 4
600
0
1250
1E+30
650
computers produced Model
0
0
0
1
0
3
+
E
1
0
0
0
1
0
0
5
computers produced Model
computers produced Model
6
1000
1.25
1000
431.818
590.909
7
1000
4.125
1000
100
590.909
$B$26 Labor
$B$27 Labor
$B$28 Labor
$B$21 Total
$C$21 Total
$D$21 Total
$E$21 Total
$F$21 Total
$G$21 Total
$H$21 Total
$I$21
Total computers produced Model
0
0
8
0
3
+
E
1
0
0
8
0
0
8
Objecve
Figure 3.24
Solver’s Sensitivity Report
The information in this sensitivity report is all relevant and definitely provides some
insights if studied carefully. However, this really requires you to know the exact rules
Solver uses to create this report. That is, it requires a fairly in-depth knowledge of the the-
ory behind LP sensitivity analysis, more than we have provided here. Fortunately, we
believe the same basic information—and more—can be obtained in a more intuitive way
by creating several carefully chosen SolverTable reports.
■
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

3.8 A MULTIPERIOD PRODUCTION MODEL
The product mix examples illustrate a very important type of LP model. However, LP
models come in many forms. For variety, we now present a quite different type of model
that can also be solved with LP. (In the next few chapters we provide other examples, lin-
ear and otherwise.) The distinguishing feature of the following model is that it relates deci-
sions made during several time periods. This type of problem occurs when a company
must make a decision now that will have ramifications in the future. The company does not
want to focus completely on the short run and forget about the long run.
108
Chapter 3
Introduction to Optimization Modeling
P R O B L E M S
Skill-Building Problems
Note: All references to the product mix model in the following
problems are to the larger product mix model in this section.
10. Modify PC Tech’s product mix model so that there is
no maximum sales constraint. (This is easy to do in
the Solver dialog box. Just highlight the constraint and
click on the Delete button.) Does this make the
problem unbounded? Does it change the optimal
solution at all? Explain its effect.
11. In the product mix model it makes sense to change the
maximum sales constraint to a “minimum sales”
constraint, simply by changing the direction of the
inequality. Then the input values in row 23 can be
considered customer demands that must be met. Make
this change and rerun Solver. What do you find? What
do you find if you run Solver again, this time making
the values in row 23 one-quarter of their current
values?
12. Use SolverTable to run a sensitivity analysis on the
cost per assembling labor hour, letting it vary from $5
to $20 in increments of $1. Keep track of the
computers produced in row 21, the hours used in the
range B26:B28, and the total profit. Discuss your
findings. Are they intuitively what you expected?
13. Create a two-way SolverTable for the product mix
model, where total profit is the only output and the
two inputs are the testing line 1 hours and testing line
2 hours available. Let the former vary from 4000 to
6000 in increments of 500, and let the latter vary from
3000 to 5000 in increments of 500. Discuss the
changes in profit you see as you look across the
various rows of the table. Discuss the changes in profit
you see as you look down the various columns of the
table.
14. Model 8 has fairly high profit margins, but it isn’t
included at all in the optimal mix. Use SolverTable,
along with some experimentation on the correct range,
to find the (approximate) selling price required for
model 8 before it enters the optimal product mix.
Skill-Extending Problems
15. Suppose that you want to increase all three of the
resource availabilities in the product mix model
simultaneously by the same percentage. You want this
percentage to vary from -25% to 50% in increments of
5%. Modify the spreadsheet model slightly so that this
sensitivity analysis can be performed with a one-way
SolverTable, using the percentage change as the single
input. Keep track of the computers produced in row
21, the hours used in the range B26:B28, and the total
profit. Discuss the results.
16. Some analysts complain that spreadsheet models are
difficult to resize. You can be the judge of this.
Suppose the current product mix problem is changed
so that there is an extra resource, packaging labor
hours, and two additional PC models, 9 and 10.
What additional input data are required? What
modifications are necessary in the spreadsheet
model (including range name changes)? Make up
values for any extra required input data and
incorporate these into a modified spreadsheet model.
Then optimize with Solver. Do you conclude that it
is easy to resize a spreadsheet model? (By the way,
it turns out that algebraic models are typically much
easier to resize.)
17. In Solver’s sensitivity report for the product mix
model, the allowable decrease for available assembling
hours is 2375. This means that something happens
when assembling hours fall to 20,000  2375 
17,625. See what this means by first running Solver
with 17,626 available hours and then again with
17,624 available hours. Explain how the two solutions
compare to the original solution and to each other.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

3.8 A Multiperiod Production Model
109
E X A M P L E
3.3 PRODUCING FOOTBALLS AT PIGSKIN
T
he Pigskin Company produces footballs. Pigskin must decide how many footballs to pro-
duce each month. The company has decided to use a six-month planning horizon. The
forecasted monthly demands for the next six months are 10,000, 15,000, 30,000, 35,000,
25,000, and 10,000. Pigskin wants to meet these demands on time, knowing that it currently
has 5000 footballs in inventory and that it can use a given month’s production to help meet the
demand for that month. (For simplicity, we assume that production occurs during the month,
and demand occurs at the end of the month.) During each month there is enough production
capacity to produce up to 30,000 footballs, and there is enough storage capacity to store up to
10,000 footballs at the end of the month, after demand has occurred. The forecasted produc-
tion costs per football for the next six months are $12.50, $12.55, $12.70, $12.80, $12.85, and
$12.95, respectively. The holding cost per football held in inventory at the end of any month is
figured at 5% of the production cost for that month. (This cost includes the cost of storage and
also the cost of money tied up in inventory.) The selling price for footballs is not considered
relevant to the production decision because Pigskin will satisfy all customer demand exactly
when it occurs—at whatever the selling price is. Therefore, Pigskin wants to determine the
production schedule that minimizes the total production and holding costs.
Objective
To use LP to find the production schedule that meets demand on time and
minimizes total production and inventory holding costs.
WHERE DO THE NUMBERS COME FROM?
The input values for this problem are not all easy to find. Here are some thoughts on where
they might be obtained. (See Figure 3.25.)
■
The initial inventory in cell B4 should be available from the company’s database sys-
tem or from a physical count.
■
The unit production costs in row 8 would probably be estimated in two steps. First,
the company might ask its cost accountants to estimate the current unit production
cost. Then it could examine historical trends in costs to estimate inflation factors for
future months.
■
The holding cost percentage in cell B5 is typically difficult to determine. Depending
on the type of inventory being held, this cost can include storage and handling, rent,
property taxes, insurance, spoilage, and obsolescence. It can also include capital
costs—the cost of money that could be used for other investments.
■
The demands in row 18 are probably forecasts made by the marketing and sales
department. They might be “seat-of-the-pants” forecasts, or they might be the result
of a formal quantitative forecasting procedure as discussed in Chapter 14. Of course,
if there are already some orders on the books for future months, these are included in
the demand figures.
■
The production and storage capacities in rows 14 and 22 are probably supplied by the
production department. They are based on the size of the workforce, the available
machinery, availability of raw materials, and physical space.
Solution
The variables and constraints for this model are listed in Table 3.3. There are two keys to
relating these variables. First, the months cannot be treated independently. This is because
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

the ending inventory in one month is the beginning inventory for the next month. Second,
to ensure that demand is satisfied on time, the amount on hand after production in each
month must be at least as large as the demand for that month. This constraint must be
included explicitly in the model.
Table 3.3
Variables and Constraints for Production/Inventory Planning Model
Input variables
Initial inventory, unit holding cost percentage, unit 
production costs, forecasted demands, production and 
storage capacities
Decision variables (changing cells)
Monthly production quantities
Objective cell
Total cost
Other calculated variables
Units on hand after production, ending inventories, 
monthly production and inventory holding costs
Constraints
Units on hand after production 
Demand (each month)
Units produced 
Production capacity (each month)
Ending inventory 
Storage capacity (each month)
When you model this type of problem, you must be very specific about the timing of
events. In fact, depending on the assumptions you make, there can be a variety of potential
models. For example, when does the demand for footballs in a given month occur: at the
beginning of the month, at the end of the month, or continually throughout the month? The
same question can be asked about production in a given month. The answers to these two
questions indicate how much of the production in a given month can be used to help satisfy
the demand in that month. Also, are the maximum storage constraint and the holding cost
based on the ending inventory in a month, the average amount of inventory in a month, or
the maximum inventory in a month? Each of these possibilities is reasonable and could be
implemented.
To simplify the model, we assume that (1) all production occurs at the beginning of
the month, (2) all demand occurs after production, so that all units produced in a month
can be used to satisfy that month’s demand, and (3) the storage constraint and the holding
cost are based on ending inventory in a given month. (You are asked to modify these
assumptions in the problems.)
An Algebraic Model
In the traditional algebraic model, the decision variables are the production quantities for the
six months, labeled P1 through P6. It is also convenient to let I1 through I6 be the correspond-
ing end-of-month inventories (after demand has occurred).13 For example, I3 is the number of
footballs left over at the end of month 3. Therefore, the obvious constraints are on production
and inventory storage capacities: Pj
30000 and Ij
10000 for 1
j
6.
In addition to these constraints, balance constraints that relate the Ps and Is are
necessary. In any month the inventory from the previous month plus the current production
equals the current demand plus leftover inventory. If Dj is the forecasted demand for 
month j, the balance equation for month j is
Ij1  Pj  Dj  Ij
…
…
…
…
…
…
Ú
110
Chapter 3
Introduction to Optimization Modeling
13This example illustrates a subtle difference between algebraic and spreadsheet models. It is often convenient
in algebraic models to define “decision variables,” in this case the Is, that are really determined by other
decision variables, in this case the Ps. In spreadsheet models, however, we typically define the changing cells
as the smallest set of variables that must be chosen—in this case the production quantities. Then values that are
determined by these changing cells, such as the ending inventory levels, can be calculated with spreadsheet
formulas.
By modifying the 
timing assumptions in
this type of model,
alternative—and
equally realistic—
models with very
different solutions 
can be obtained.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

The balance equation for month 1 uses the known beginning inventory, 5000, for the previ-
ous inventory (the Ij1 term). By putting all variables (Ps and Is) on the left and all known
values on the right (a standard LP convention), these balance constraints can be written as
P1  I1  10000  5000
I1  P2  I2  15000
I2  P3  I3  30000
I3  P4  I4  35000
I4  P5  I5  25000
I5  P6  I6  10000
(3.1)
As usual, there are nonnegativity constraints: all Ps and Is must be nonnegative.
What about meeting demand on time? This requires that in each month the inventory
from the preceding month plus the current production must be at least as large as the cur-
rent demand. But take a look, for example, at the balance equation for month 3. By rear-
ranging it slightly, it becomes
I3  I2  P3  30000
Now, the nonnegativity constraint on I3 implies that the right side of this equation, 
I2  P3  30000, is also nonnegative. But this implies that demand in month 3 is
covered—the beginning inventory in month 3 plus month 3 production is at least 30000.
Therefore, the nonnegativity constraints on the Is automatically guarantee that all demands
will be met on time, and no other constraints are needed. Alternatively, the constraint can
be written directly as I2  P3
30000. In words, the amount on hand after production in
month 3 must be at least as large as the demand in month 3. The spreadsheet model takes
advantage of this interpretation.
Finally, the objective to minimize is the sum of production and holding costs. It is the
sum of unit production costs multiplied by Ps, plus unit holding costs multiplied by Is.
DEVELOPING THE SPREADSHEET MODEL
The spreadsheet model of Pigskin’s production problem is shown in Figure 3.25. (See the
file Production Scheduling.xlsx.) The main feature that distinguishes this model from the
product mix model is that some of the constraints, namely, the balance Equations (3.1), are
built into the spreadsheet itself by means of formulas. This means that the only changing
cells are the production quantities. The ending inventories shown in row 20 are determined
by the production quantities and Equations (3.1). As you can see, the decision variables in
an algebraic model (the Ps and Is) are not necessarily the same as the changing cells in an
equivalent spreadsheet model. (The only changing cells in the spreadsheet model corre-
spond to the Ps.)
To develop the spreadsheet model in Figure 3.25, proceed as follows.
1
Inputs. Enter the inputs in the blue cells. Again, these are all entered as numbers
directly from the problem statement. (Unlike some spreadsheet modelers who prefer to put
all inputs in the upper left corner of the spreadsheet, we enter the inputs wherever they fit
most naturally. Of course, this takes some planning before diving in.)
2
Name ranges. Name the ranges indicated. Note that all but one of these (Total_cost)
can be named easily with the range-naming shortcut, using the labels in column A.
Ú
3.8 A Multiperiod Production Model
111
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

3
Production quantities. Enter any values in the range Units_produced as production
quantities. As always, you can enter values that you believe are good, maybe even optimal.
This is not crucial, however, because Solver eventually finds the optimal production
quantities.
4
On-hand inventory. Enter the formula
B4B12
in cell B16. This calculates the first month’s on-hand inventory after production (but
before demand). Then enter the typical formula
B20C12
for on-hand inventory after production in month 2 in cell C16 and copy it across row 16.
5
Ending inventories. Enter the formula
B16-B18
112
Chapter 3
Introduction to Optimization Modeling
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
A
B
C
D
E
F
G
H
Mulperiod producon model
Input data
Inial inventory (100s)
5000
Holding cost as % of prod cost
5%
Month
1
2
3
4
5
6
Producon cost/unit
$12.50
$12.55
$12.70
$12.80
$12.85
$12.95
Producon plan (all quanes are in 100s of footballs)
Month
Units
0
0
0
0
1
0
0
0
5
2
0
0
0
0
3
0
0
0
0
3
0
0
0
5
1
0
0
0
5
1
d
e
c
u
d
o
r
p
Producon capacity
30000
30000
30000
30000
30000
30000
On hand aer
n
20000
25000
40000
40000
30000
15000
0
0
0
0
1
0
0
0
5
2
0
0
0
5
3
0
0
0
0
3
0
0
0
5
1
0
0
0
0
1
d
n
a
m
e
D
Ending
0
0
0
5
0
0
0
5
0
0
0
5
0
0
0
0
1
0
0
0
0
1
0
0
0
0
1
y
r
o
t
n
e
v
ni
<=
<=
<=
<=
<=
<=
>=
>=
>=
>=
>=
>=
<=
<=
<=
<=
<=
<=
Storage
0
0
0
0
1
0
0
0
0
1
0
0
0
0
1
0
0
0
0
1
0
0
0
0
1
0
0
0
0
1
ytic
a
p
a
c
Summary of costs (all costs are in hundreds of dollars)
Month
1
2
3
4
5
6
Totals
Producon costs
$187,500.00 $188,250.00 $381,000.00 $384,000.00 $321,250.00 $129,500.00 $1,591,500.00
Holding
0
0.5
2
5,8
2
$
0
5.7
3
2,3
$
0
5.2
1
2,3
$
0
0.0
0
2,3
$
0
0.0
5
3,6
$
0
0.5
7
2,6
$
0
0.0
5
2,6
$
sts
o
c
0
0.5
2
0,0
2
6,1
$
0
5.7
3
7,2
3
1
$
0
5.2
6
4,4
2
3
$
0
0.0
0
2,7
8
3
$
0
0.0
5
3,7
8
3
$
0
0.5
2
5,4
9
1
$
0
0.0
5
7,3
9
1
$
sla
t
o
T
Range names used
8
1
$
G
$:8
1
$
B
$
!le
d
o
M
=
d
n
a
m
e
D
Ending_inventory
=Model!$B$20:$G$20
n
=Model!$B$16:$G$16
y
=Model!$B$14:$G$14
Storage_capacity
=Model!$B$22:$G$22
8
2
$
H
$
!le
d
o
M
=
ts
o
C
_la
t
o
T
Units_produced
=Model!$B$12:$G$12
1
2
3
4
5
6
Figure 3.25
Production Planning Model with a Suboptimal Solution
In multiperiod
problems, there is
often one formula for
the first period and a
slightly different
(copyable) formula for
all other periods.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

for ending inventory in cell B20 and copy it across row 20. This formula calculates ending
inventory in the current month as on-hand inventory before demand minus the demand in
that month.
6
Production and holding costs. Enter the formula
B8*B12
in cell B26 and copy it across to cell G26 to calculate the monthly production costs. Then
enter the formula
$B$5*B8*B20
in cell B27 and copy it across to cell G27 to calculate the monthly holding costs. Note
that these are based on monthly ending inventories. Finally, calculate the cost totals in
column H with the SUM function.
USING SOLVER
To use Solver, fill out the main dialog box as shown in Figure 3.26. The logic behind the
constraints is straightforward. The constraints are that (1) the production quantities cannot
exceed the production capacities, (2) the on-hand inventories after production must be at
least as large as demands, and (3) ending inventories cannot exceed storage capacities.
Check the Non-Negative option, and then click on Solve.
3.8 A Multiperiod Production Model
113
Figure 3.26
Solver Dialog Box
for Production
Planning Model
Discussion of the Solution
The optimal solution from Solver appears in Figure 3.27. The solution can be interpreted
best by comparing production quantities to demands. In month 1, Pigskin should produce
just enough to meet month 1 demand (taking into account the initial inventory of 5000). In
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

month 2, it should produce 5000 more footballs than month 2 demand, and then in month
3 it should produce just enough to meet month 3 demand, while still carrying the extra
5000 footballs in inventory from month 2 production. In month 4, Pigskin should finally
use these 5000 footballs, along with the maximum production amount, 30,000, to meet
month 4 demand. Then in months 5 and 6 it should produce exactly enough to meet these
months’ demands. The total cost is $1,535,563, most of which is production cost.
114
Chapter 3
Introduction to Optimization Modeling
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
A
B
C
D
E
F
G
H
Mulperiod producon model
Input data
Inial inventory (100s)
5000
Holding cost as % of prod cost
5%
Month
1
2
3
4
5
6
Producon cost/unit
$12.50
$12.55
$12.70
$12.80
$12.85
$12.95
Producon plan (all quanes are in 100s of footballs)
Month
1
2
3
4
5
6
Units
0
0
0
0
1
0
0
0
5
2
0
0
0
0
3
0
0
0
0
3
0
0
0
0
2
0
0
0
5
d
e
c
u
d
o
r
p
<=
<=
<=
<=
<=
<=
Producon capacity
30000
30000
30000
30000
30000
30000
On hand aer producon
10000
20000
35000
35000
25000
10000
>=
>=
>=
>=
>=
>=
0
0
0
0
1
0
0
0
5
2
0
0
0
5
3
0
0
0
0
3
0
0
0
5
1
0
0
0
0
1
d
n
a
m
e
D
Ending
0
0
0
0
0
0
5
0
0
0
5
0
y
r
o
t
n
e
v
ni
<=
<=
<=
<=
<=
<=
Storage
0
0
0
0
1
0
0
0
0
1
0
0
0
0
1
0
0
0
0
1
0
0
0
0
1
0
0
0
0
1
ytic
a
p
a
c
Summary of costs (all costs are in hundreds of dollars)
Month
1
2
3
4
5
6
Totals
Producon costs
$62,500.00
$251,000.00 $381,000.00 $384,000.00 $321,250.00 $129,500.00 $1,529,250.00
Holding
0
5.2
1
3,6
$
0
0.0
$
0
0.0
$
0
0.0
$
0
0.5
7
1,3
$
0
5.7
3
1,3
$
0
0.0
$
sts
o
c
0
5.2
6
5,5
3
5,1
$
0
0.0
0
5,9
2
1
$
0
0.0
5
2,1
2
3
$
0
0.0
0
0,4
8
3
$
0
0.5
7
1,4
8
3
$
0
5.7
3
1,4
5
2
$
0
0.0
0
5,2
6
$
sla
t
o
T
Range names used
8
1
$
G
$:8
1
$
B
$
!le
d
o
M
=
d
n
a
m
e
On_hand_aer_producon
Ending_inventory
=Model!$B$20:$G$20
=Model!$B$16:$G$16
=Model!$B$14:$G$14
Storage_capacity
=Model!$B$22:$G$22
8
2
$
H
$
!le
d
o
M
=
ts
o
C
_la
t
o
T
Units_produced
=Model!$B$12:$G$12
D
Producon_capacity
Figure 3.27
Optimal Solution for Production Planning Model
You can often improve
your intuition by trying
to reason why Solver’s
solution is indeed
optimal.
Could you have guessed this optimal solution? Upon reflection, it makes perfect
sense. Because the monthly holding costs are large relative to the differences in monthly
production costs, there is little incentive to produce footballs before they are needed to take
advantage of a “cheap” production month. Therefore, the Pigskin Company produces foot-
balls in the month when they are needed—when possible. The only exception to this rule is
the 20,000 footballs produced during month 2 when only 15,000 are needed. The extra
5000 footballs produced in month 2 are needed, however, to meet the month 4 demand of
35,000, because month 3 production capacity is used entirely to meet the month 3 demand.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Thus month 3 capacity is not available to meet the month 4 demand, and 5000 units of
month 2 capacity are used to meet the month 4 demand.
3.8 A Multiperiod Production Model
115
FUNDAMENTAL INSIGHT
Multiperiod Optimization Pr
oblems and
Myopic Solutions
Many optimization pr oblems ar e of a m ultiperiod
nature, where a sequence of decisions must be made
over time.When making the first of these decisions,
the one for this week or this month, say, it is usually
best to include future decisions in the model, as has
been done her e. If y ou ignor e futur e periods and
make the initial decision based onl
y on the first
period, the resulting decision is called myopic (short-
sighted). Myopic decisions ar e occasionally optimal,
but not very often.The idea is that if y ou act now in
a way that looks best in the shor t run, it might lead
you do wn a strategicall y unattractiv e path f or the
long run.
If you want Solver
Table to keep track 
of a quantity that is
not in your model,
you need to create it
with an appropriate
formula in a new cell.
Sensitivity Analysis
SolverTable can now be used to perform a number of interesting sensitivity analyses. We
illustrate two possibilities. First, note that the most inventory ever carried at the end of a
month is 5000, although the storage capacity each month is 10,000. Perhaps this is because
the holding cost percentage, 5%, is fairly large. Would more ending inventory be carried if
this holding cost percentage were lower? Or would even less be carried if it were higher?
You can check this with the SolverTable output shown in Figure 3.28. Now the single input
cell is cell B5, and the single output is the maximum ending inventory ever held, which
you can calculate in cell B31 with the formula
MAX(Ending_inventory)
As the SolverTable results indicate, the storage capacity limit is reached only when the
holding cost percentage falls to 1%. (This output doesn’t indicate which month or how
3
4
5
6
7
8
9
10
11
12
13
14
A
B
C
D
E
F
G
Holding cost % (cell $B$5) values along side, output cell(s) along top
Max_inventory
1%
10000
2%
5000
3%
5000
4%
5000
5%
5000
6%
5000
7%
5000
8%
5000
9%
5000
10%
5000
Figure 3.28
Sensitivity of
Maximum Inventory
to Holding Cost
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

many months the ending inventory is at the upper limit.) On the other hand, even when the
holding cost percentage reaches 10%, the company still continues to hold a maximum end-
ing inventory of 5000.
A second possible sensitivity analysis is suggested by the way the optimal production
schedule would probably be implemented. The optimal solution to Pigskin’s model speci-
fies the production level for each of the next six months. In reality, however, the company
would probably implement the model’s recommendation only for the first month. Then at
the beginning of the second month, it would gather new forecasts for the next six months,
months 2 through 7, solve a new six-month model, and again implement the model’s rec-
ommendation for the first of these months, month 2. If the company continues in this man-
ner, we say that it is following a six-month rolling planning horizon.
The question, then, is whether the assumed demands (really, forecasts) toward the end
of the planning horizon have much effect on the optimal production quantity in month 1.
You would hope not, because these forecasts could be quite inaccurate. The two-way
Solver table in Figure 3.29 shows how the optimal month 1 production quantity varies with
the forecasted demands in months 5 and 6. As you can see, if the forecasted demands for
months 5 and 6 remain fairly small, the optimal month 1 production quantity remains at
5000. This is good news. It means that the optimal production quantity in month 1 is fairly
insensitive to the possibly inaccurate forecasts for months 5 and 6.
116
Chapter 3
Introduction to Optimization Modeling
3
4
5
6
7
A
B
C
D
E
F
G
H
I
J
Month 5 demand (cell $F$18) values along side, Month 6 demand (cell $G$18) values along top, output cell in corner
Units_produced_1
10000
20000
30000
10000
5000
5000
5000
20000
5000
5000
5000
30000
5000
5000
5000
Figure 3.29
Sensitivity of Month 1 Production to Demand in Months 5 and 6
Solver’s sensitivity report for this model appears in Figure 3.30. The bottom part of
this report is fairly straightforward to interpret. The first six rows are for sensitivity to
changes in the storage capacity, whereas the last six are for sensitivity to changes in the
demand. (There are no rows for the production capacity constraints, because these are sim-
ple upper-bound constraints on the decision variables. Recall that Solver’s sensitivity
report handles this type of constraint differently from “normal” constraints.) In contrast,
the top part of the report is virtually impossible to unravel. This is because the objective
coefficients of the decision variables are each based on multiple inputs. (Each is a combi-
nation of unit production costs and the holding cost percentage.) Therefore, if you want to
know how the solution will change if you change a single unit production cost or the hold-
ing cost percentage, this report does not answer your question. This is one case where a
sensitivity analysis with SolverTable is much more straightforward and intuitive. It allows
you to change any of the model’s inputs and directly see the effects on the solution.
Modeling Issues
We assume that Pigskin uses a six-month planning horizon. Why six months? In multi-
period models such as this, the company has to make forecasts about the future, such as the
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

level of customer demand. Therefore, the length of the planning horizon is usually the
length of time for which the company can make reasonably accurate forecasts. Here,
Pigskin evidently believes that it can forecast up to six months from now, so it uses a six-
month planning horizon.
■
3.8 A Multiperiod Production Model
117
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
A
B
C
D
E
F
G
H
Variable Cells
Final
Reduced
Allowable
Allowable
Cell
Name
Value
Cost
Coeﬃcien
Objecve
t
Increase
Decrease
$B$12 Units produced
5000
0
16.318
1E+30
0.575
$C$12 Units produced
20000
0
15.743
0.575
0.478
$D$12 Units produced
30000
-0.478
15.265
0.478
1E+30
$E$12 Units produced
30000
-1.013
14.730
1.013
1E+30
$F$12 Units produced
25000
0
14.140
1.603
0.543
$G$12 Units produced
10000
0
13.598
0.543
13.598
Constraints
Final
Shadow
Constraint
Allowable
Allowable
Cell
Name
Value
Price
R.H. Side
Increase
Decrease
$B$16 On hand aer producon
aer producon
aer producon
aer producon
aer producon
aer producon
 
 
 <=
10000
0.575
10000
10000
5000
$C$16 On hand 
 
 <=
20000
0
15000
5000
1E+30
$D$16 On hand 
 
 <=
35000
0
30000
5000
1E+30
$E$16 On hand 
 
 <=
35000
1.603
35000
5000
5000
$F$16 On hand 
 
 <=
25000
0.543
25000
5000
20000
$G$16 On hand 
 
 <=
10000
13.598
10000
10000
10000
$B$20 Ending inventory >=
0
0
10000
1E+30
10000
$C$20 Ending inventory >=
5000
0
10000
1E+30
5000
$D$20 Ending inventory >=
5000
0
10000
1E+30
5000
$E$20 Ending inventory >=
0
0
10000
1E+30
10000
$F$20 Ending inventory >=
0
0
10000
1E+30
10000
$G$20 Ending inventory >=
0
0
10000
1E+30
10000
Figure 3.30
Solver Sensitivity Report for Production Planning Model
P R O B L E M S
Skill-Building Problems
18. Can you guess the results of a sensitivity analysis on
the initial inventory in the Pigskin model? See if your
guess is correct by using SolverTable and allowing 
the initial inventory to vary from 0 to 10,000 in
increments of 1000. Keep track of the values in the
changing cells and the objective cell.
19. Modify the Pigskin model so that there are eight
months in the planning horizon. You can make up
reasonable values for any extra required data. Don’t
forget to modify range names. Then modify the model
again so that there are only four months in the
planning horizon. Do either of these modifications
change the optimal production quantity in month 1?
20. As indicated by the algebraic formulation of the
Pigskin model, there is no real need to calculate
inventory on hand after production and constrain it to
be greater than or equal to demand. An alternative is to
calculate ending inventory directly and constrain it to
be nonnegative. Modify the current spreadsheet model
to do this. (Delete rows 16 and 17, and calculate
ending inventory appropriately. Then add an explicit
nonnegativity constraint on ending inventory.)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

3.9 A COMPARISON OF ALGEBRAIC AND SPREADSHEET MODELS
To this point you have seen three algebraic optimization models and three corresponding
spreadsheet models. How do they differ? If you review the two product mix examples in this
chapter, we believe you will agree that (1) the algebraic models are quite straightforward and
(2) the spreadsheet models are almost direct translations into Excel of the algebraic models.
In particular, each algebraic model has a set of xs that corresponds to the changing cell range
in the spreadsheet model. In addition, each objective and each left side of each constraint in
the spreadsheet model corresponds to a linear expression involving xs in the algebraic model.
However, the Pigskin production planning model is quite different. The spreadsheet
model includes one set of changing cells, the production quantities, and everything else is
related to these through spreadsheet formulas. In contrast, the algebraic model has two sets
of variables, the Ps for the production quantities and the Is for the ending inventories, and
together these constitute the decision variables. These two sets of variables must then be
related algebraically, and this is done through a series of balance equations.
This is a typical situation in algebraic models, where one set of variables (the produc-
tion quantities) corresponds to the real decision variables, and other sets of variables, along
with extra equations or inequalities, are introduced to capture the logic. We believe—and
this belief is reinforced by many years of teaching experience—that this extra level of
abstraction makes algebraic models much more difficult for typical users to develop and
comprehend. It is the primary reason we have decided to focus almost exclusively on
spreadsheet models in this book.
3.10 A DECISION SUPPORT SYSTEM
If your job is to develop an LP spreadsheet model to solve a problem such as Pigskin’s pro-
duction problem, then you will be considered the “expert” in LP. Many people who need to
use such models, however, are not experts. They might understand the basic ideas behind
LP and the types of problems it is intended to solve, but they will not know the details. In
this case it is useful to provide these users with a decision support system (DSS) that can
help them solve problems without having to worry about technical details.
118
Chapter 3
Introduction to Optimization Modeling
21. In one modification of the Pigskin problem, the
maximum storage constraint and the holding cost are
based on the average inventory (not ending inventory)
for a given month, where the average inventory is
defined as the sum of beginning inventory and ending
inventory, divided by 2, and beginning inventory is
before production or demand. Modify the Pigskin
model with this new assumption, and use Solver to
find the optimal solution. How does this change the
optimal production schedule? How does it change the
optimal total cost?
Skill-Extending Problems
22. Modify the Pigskin spreadsheet model so that except
for month 6, demand need not be met on time. The
only requirement is that all demand be met eventually
by the end of month 6. How does this change the
optimal production schedule? How does it change the
optimal total cost?
23. Modify the Pigskin spreadsheet model so that demand
in any of the first five months must be met no later
than a month late, whereas demand in month 6 must
be met on time. For example, the demand in month 3
can be met partly in month 3 and partly in month 4.
How does this change the optimal production
schedule? How does it change the optimal total cost?
24. Modify the Pigskin spreadsheet model in the following
way. Assume that the timing of demand and
production are such that only 70% of the production in
a given month can be used to satisfy the demand in
that month. The other 30% occurs too late in that
month and must be carried as inventory to help satisfy
demand in later months. How does this change the
optimal production schedule? How does it change the
optimal total cost? Then use SolverTable to see how
the optimal production schedule and optimal cost vary
as the percentage of production usable for this month’s
demand (now 70%) is allowed to vary from 20% to
100% in increments of 10%.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

We will not teach you in this book how to build a full-scale DSS, but we will show you
what a typical DSS looks like and what it can do.14 (We consider only DSSs built around
spreadsheets. There are many other platforms for developing DSSs that we will not con-
sider.) Basically, a spreadsheet-based DSS contains a spreadsheet model of a problem,
such as the one in Figure 3.27. However, as a user, you will probably never even see this
model. Instead, you will see a front end and a back end. The front end allows you to select
input values for your particular problem. The user interface for this front end can include
several features, such as buttons, dialog boxes, toolbars, and menus—the things you are
used to seeing in Windows applications. The back end will then produce a report that
explains the solution in nontechnical terms.
We illustrate a DSS for a slight variation of the Pigskin problem in the file Decision
Support.xlsm. This file has three worksheets. When you open the file, you see the
Explanation sheet shown in Figure 3.31. It contains two buttons, one for setting up the prob-
lem (getting the user’s inputs) and one for solving the problem (running Solver). When you
click on the Set Up Problem button, you are asked for the inputs: the initial inventory, the
forecasted demands for each month, and others. An example appears in Figure 3.32. These
input boxes should be self-explanatory, so that all you need to do is enter the values you
3.10 A Decision Support System
119
Figure 3.31
Explanation Sheet
for DSS
Figure 3.32
Dialog Box for
Obtaining User
Inputs
14For readers interested in learning more about this DSS, this textbook’s essential resource Web site includes
notes about its development in the file Developing the Decision Support A pplication.docx under Chapter 3
Example Files. If you are interested in learning more about spreadsheet DSSs in general, Albright has written
the book VBA for Modelers, now in its third edition. It contains a primer on the Visual Basic for Applications
language and presents many applications and instructions for creating DSSs with VBA.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

want to try. (To speed up the process, the inputs from the previous run are shown by
default.) After you have entered all of these inputs, you can take a look at the Model
worksheet. This sheet contains a spreadsheet model similar to the one in Figure 3.27 but
with the inputs you just entered.
Now go back to the Explanation sheet and click on the Find Optimal Solution button.
This automatically sets up the Solver dialog box and runs Solver. There are two possibili-
ties. First, it is possible that there is no feasible solution to the problem with the inputs you
entered. In this case you see a message to this effect, as in Figure 3.33. In most cases, how-
ever, the problem has a feasible solution. In this case you see the Report sheet, which sum-
marizes the optimal solution in nontechnical terms. Part of one sample output appears in
Figure 3.34.
120
Chapter 3
Introduction to Optimization Modeling
Figure 3.33
Indication of No
Feasible Solutions
Figure 3.34
Optimal Solution
Report
After studying this report, you can then click on the Solve Another Problem button,
which takes you back to the Explanation sheet so that you can solve a new problem. All of
this is done automatically with Excel macros. These macros use Microsoft’s Visual Basic
for Applications (VBA) programming language to automate various tasks. In most
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

professional applications, nontechnical people need only to enter inputs and look at
reports. Therefore, the Model sheet and VBA code will most likely be hidden and pro-
tected from end users.
3.11 CONCLUSION
This chapter has provided a good start to LP modeling—and to optimization modeling in
general. You have learned how to develop three basic LP spreadsheet models, how to use
Solver to find their optimal solutions, and how to perform sensitivity analyses with Solver’s
sensitivity reports or with the SolverTable add-in. You have also learned how to recognize
whether a mathematical programming model satisfies the linear assumptions. In the next
few chapters you will see a variety of other optimization models, but the three basic steps of
model development, Solver optimization, and sensitivity analysis remain the same.
3.11 Conclusion
121
Summary of Key Terms
Term
Explanation
Excel
Page
Linear programming 
An optimization model with a linear
68
model
objective and linear constraints
Objective
The value, such as profit, to be optimized
69
in an optimization model
Constraints
Conditions that must be satisfied in
69
an optimization model
Changing cells
Cells that contain the values of the
Specify in Solver
69
decision variables
dialog box
Objective cell
Cell that contains the value
Specify in
69
of the objective
Solver dialog box
Nonnegativity constraints
Constraints that require the decision
69
variables to be nonnegative,
usually for physical reasons
Feasible solution
A solution that satisfies all of the constraints
70
Feasible region
The set of all feasible solutions
70
Optimal solution
The feasible solution that has
70
the best value of the objective
Solver
Add-in that ships with Excel for
Solver on
70
performing optimization
Data ribbon
Simplex method
An efficient algorithm for finding the
70
optimal solution in a linear programming model
Sensitivity analysis
Seeing how the optimal solution changes
70
as various input values change
Algebraic model
A model that expresses the constraints
72
and the objective algebraically
Graphical solution
Shows the constraints and objective
72
graphically so that the optimal solution
can be identified; useful only when
there are two decision variables
Spreadsheet model
A model that uses spreadsheet formulas
74
to express the logic of the model
Binding constraint
A constraint that holds as an equality
82
(continued)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

122
Chapter 3
Introduction to Optimization Modeling
Summary of Key Terms
(Continued)
Term
Explanation
Excel
Page
Nonbinding constraint,
A constraint where there is a difference, the
82
slack
slack, between the two sides of
the inequality
Solver’s sensitivity
Report available from Solver that shows
Available in Solver
83
report
sensitivity to objective coefficients and
dialog box
right sides of constraints
after Solver runs
Reduced cost
Amount the objective coefficient of a
85
variable currently equal to zero must change
before it is optimal for that variable to be positive
(or the amount the objective of a variable currently 
at its upper bound must change before that variable 
decreases from its upper bound)
Shadow price
The change in the objective for a change in
85
the right side of a constraint; indicates amount  
a company would pay for more of a scarce 
resource
SolverTable
Add-in that performs sensitivity analysis 
SolverTable ribbon
87
to any inputs and reports results in
tabular and graphical form
Selecting multiple ranges
Useful when changing cells, e.g., are in
Pressing Ctrl key,
89
noncontiguous ranges
drag ranges, one
after the other
Mathematical
Any optimization model, whether linear, integer, 
94
programming model
or nonlinear
Proportionality,
Properties of optimization model that result
94
additivity, divisibility
in a linear programming model
Infeasibility
Condition where a model has no feasible solutions
97
Unboundedness
Condition where there is no limit to the objective;
97
almost always a sign of an error in the model
Rolling planning horizon
Multiperiod model where only the decision in the
116
first period is implemented, and then a new multiperiod 
model is solved in succeeding periods
Decision support system
User-friendly system where an end user can
118
enter inputs to a model and see outputs, but need
not be concerned with technical details
P R O B L E M S
Skill-Building Problems
25. A chemical company manufactures three chemicals:
A, B, and C. These chemicals are produced via two
production processes: 1 and 2. Running process 1 for
an hour costs $400 and yields 300 units of A, 100
units of B, and 100 units of C. Running process 2 for
an hour costs $100 and yields 100 units of A and 100
units of B. To meet customer demands, at least 1000
units of A, 500 units of B, and 300 units of C must be
produced daily.
a. Use Solver to determine a daily production plan
that minimizes the cost of meeting the company’s
daily demands.
b. Confirm graphically that the daily production plan
from part a minimizes the cost of meeting the
company’s daily demands.
c. Use SolverTable to see what happens to the
decision variables and the total cost when the
hourly processing cost for process 2 increases in
increments of $0.50. How large must this cost
increase be before the decision variables change?
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

What happens when it continues to increase
beyond this point?
26. A furniture company manufactures desks and chairs.
Each desk uses four units of wood, and each chair uses
three units of wood. A desk contributes $400 to profit,
and a chair contributes $250. Marketing restrictions
require that the number of chairs produced be at least
twice the number of desks produced. There are 2000
units of wood available.
a. Use Solver to maximize the company’s profit.
b. Confirm graphically that the solution in part a
maximizes the company’s profit.
c. Use SolverTable to see what happens to the
decision variables and the total profit when the
availability of wood varies from 1000 to 3000 in
100-unit increments. Based on your findings, how
much would the company be willing to pay for
each extra unit of wood over its current 2000 units?
How much profit would the company lose if it lost
any of its current 2000 units?
27. A farmer in Iowa owns 450 acres of land. He is going to
plant each acre with wheat or corn. Each acre planted
with wheat yields $2000 profit, requires three workers,
and requires two tons of fertilizer. Each acre planted
with corn yields $3000 profit, requires two workers, and
requires four tons of fertilizer. There are currently 1000
workers and 1200 tons of fertilizer available.
a. Use Solver to help the farmer maximize the profit
from his land.
b. Confirm graphically that the solution from part a
maximizes the farmer’s profit from his land.
c. Use SolverTable to see what happens to the
decision variables and the total profit when the
availability of fertilizer varies from 200 tons to
2200 tons in 100-ton increments. When does the
farmer discontinue producing wheat? When does
he discontinue producing corn? How does the
profit change for each 10-ton increment?
28. During the next four months, a customer requires,
respectively, 500, 650, 1000, and 700 units of a
commodity, and no backlogging is allowed (that is, the
customer’s requirements must be met on time).
Production costs are $50, $80, $40, and $70 per unit
during these months. The storage cost from one month
to the next is $20 per unit (assessed on ending
inventory). It is estimated that each unit on hand at the
end of month 4 can be sold for $60. Assume there is
no beginning inventory.
a. Determine how to minimize the net cost incurred in
meeting the demands for the next four months.
b. Use SolverTable to see what happens to the decision
variables and the total cost when the initial inventory
varies from 0 to 1000 in 100-unit increments. How
much lower would the total cost be if the company
started with 100 units in inventory, rather than none?
3.11 Conclusion
123
Would this same cost decrease occur for every 
100-unit increase in initial inventory?
29. A company faces the following demands during the
next three weeks: week 1, 2000 units; week 2, 1000
units; week 3, 1500 units. The unit production costs
during each week are as follows: week 1, $130; week
2, $140; week 3, $150. A holding cost of $20 per unit
is assessed against each week’s ending inventory. At
the beginning of week 1, the company has 500 units
on hand. In reality, not all goods produced during a
month can be used to meet the current month’s
demand. To model this fact, assume that only half of
the goods produced during a week can be used to meet
the current week’s demands.
a. Determine how to minimize the cost of meeting the
demand for the next three weeks.
b. Revise the model so that the demands are of the form
Dt  k	t, where Dt is the original demand (from
above) in month t, k is a given factor, and 	t is an
amount of change in month t demand. (The Greek
symbol delta is typically used to indicate change.)
Develop the model in such a way that you can use
SolverTable to analyze changes in the amounts
produced and the total cost when k varies from 0 to
10 in 1-unit increments, for any fixed values of the
	ts. For example, try this when 	1  200, 	2  500,
and 	3  300. Describe the behavior you observe in
the table. Can you find any reasonable 	ts that
induce positive production levels in week 3?
30. Maggie Stewart loves desserts, but due to weight and
cholesterol concerns, she has decided that she must
plan her desserts carefully. There are two possible
desserts she is considering: snack bars and ice cream.
After reading the nutrition labels on the snack bar and
ice cream packages, she learns that each serving of a
snack bar weighs 37 grams and contains 120 calories
and 5 grams of fat. Each serving of ice cream weighs
65 grams and contains 160 calories and 10 grams of
fat. Maggie will allow herself no more than 450
calories and 25 grams of fat in her daily desserts, but
because she loves desserts so much, she requires at
least 120 grams of dessert per day. Also, she assigns a
“taste index” to each gram of each dessert, where 0 is
the lowest and 100 is the highest. She assigns a taste
index of 95 to ice cream and 85 to snack bars (because
she prefers ice cream to snack bars).
a. Use Solver to find the daily dessert plan that stays
within her constraints and maximizes the total taste
index of her dessert.
b. Confirm graphically that the solution from part a
maximizes Maggie’s total taste index.
c. Use a two-way Solver table to see how the optimal
dessert plan varies when the calories per snack bar
and per ice cream vary. Let the former vary from
80 to 200 in increments of 10, and let the latter
vary from 120 to 300 in increments of 10.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

31. For a telephone survey, a marketing research group
needs to contact at least 600 wives, 480 husbands, 400
single adult males, and 440 single adult females. It
costs $3 to make a daytime call and (because of higher
labor costs) $5 to make an evening call. The file
P03_31.xlsx lists the results that can be expected. For
example, 30% of all daytime calls are answered by a
wife, 15% of all evening calls are answered by a single
male, and 40% of all daytime calls are not answered at
all. Due to limited staff, at most 40% of all phone calls
can be evening calls.
a. Determine how to minimize the cost of completing
the survey.
b. Use SolverTable to investigate changes in the unit
cost of either type of call. Specifically, investigate
changes in the cost of a daytime call, with the cost
of an evening call fixed, to see when (if ever) only
daytime calls or only evening calls will be made.
Then repeat the analysis by changing the cost of an
evening call and keeping the cost of a daytime call
fixed.
32. A furniture company manufactures tables and chairs.
Each table and chair must be made entirely out of oak
or entirely out of pine. A total of 15,000 board feet of
oak and 21,000 board feet of pine are available. A
table requires either 17 board feet of oak or 30 board
feet of pine, and a chair requires either 5 board feet of
oak or 13 board feet of pine. Each table can be sold for
$800, and each chair for $300.
a. Determine how the company can maximize its
revenue.
b. Use SolverTable to investigate the effects of
simultaneous changes in the selling prices of the
products. Specifically, see what happens to the total
revenue when the selling prices of oak products
change by a factor 1  k1 and the selling prices of
pine products change by a factor 1  k2. Revise
your model from the previous problem so that you
can use SolverTable to investigate changes in total
revenue as k1 and k2 both vary from 0.3 to 0.3 in
increments of 0.1. Can you conclude that total
revenue changes linearly within this range?
33. A manufacturing company makes two products. Each
product can be made on either of two machines. The
time (in hours) required to make each product on each
machine is listed in the file P03_33.xlsx. Each month,
500 hours of time are available on each machine. Each
month, customers are willing to buy up to the
quantities of each product at the prices also given in
the same file. The company’s goal is to maximize the
revenue obtained from selling units during the next
two months.
a. Determine how the company can meet this goal.
Assume that it will not produce any units in a
month that it cannot sell in that month.
124
Chapter 3
Introduction to Optimization Modeling
b. Use SolverTable to see what happens if customer
demands for each product in each month
simultaneously change by a factor 1  k. Revise
the model so that you can use SolverTable to
investigate the effect of this change on total
revenue as k varies from 0.3 to 0.3 in increments
of 0.1. Does revenue change in a linear manner
over this range? Can you explain intuitively why it
changes in the way it does?
34. There are three factories on the Momiss River. Each
emits two types of pollutants, labeled P1 and P2, into
the river. If the waste from each factory is processed,
the pollution in the river can be reduced. It costs
$1500 to process a ton of factory 1 waste, and each ton
processed reduces the amount of P1 by 0.10 ton and
the amount of P2 by 0.45 ton. It costs $1000 to process
a ton of factory 2 waste, and each ton processed
reduces the amount of P1 by 0.20 ton and the amount
of P2 by 0.25 ton. It costs $2000 to process a ton of
factory 3 waste, and each ton processed reduces the
amount of P1 by 0.40 ton and the amount of P2 by
0.30 ton. The state wants to reduce the amount of P1 in
the river by at least 30 tons and the amount of P2 by at
least 40 tons.
a. Use Solver to determine how to minimize the cost
of reducing pollution by the desired amounts. Are
the LP assumptions (proportionality, additivity,
divisibility) reasonable in this problem?
b. Use SolverTable to investigate the effects of
increases in the minimal reductions required by the
state. Specifically, see what happens to the amounts
of waste processed at the three factories and the
total cost if both requirements (currently 30 and 40
tons, respectively) are increased by the same
percentage. Revise your model so that you can use
SolverTable to investigate these changes when the
percentage increase varies from 10% to 100% in
increments of 10%. Do the amounts processed at
the three factories and the total cost change in a
linear manner?
Skill-Extending Problems
35. A company manufactures two types of trucks. Each
truck must go through the painting shop and the
assembly shop. If the painting shop were completely
devoted to painting type 1 trucks, 800 per day could
be painted, whereas if the painting shop were
completely devoted to painting type 2 trucks, 700 per
day could be painted. If the assembly shop were
completely devoted to assembling truck 1 engines,
1500 per day could be assembled, whereas if the
assembly shop were completely devoted to
assembling truck 2 engines, 1200 per day could be
assembled. It is possible, however, to paint both
types of trucks in the painting shop. Similarly, it is
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

possible to assemble both types in the assembly shop.
Each type 1 truck contributes $1000 to profit; each
type 2 truck contributes $1500. Use Solver to
maximize the company’s profit. (Hint: One approach,
but not the only approach, is to try a graphical
procedure first and then deduce the constraints from
the graph.)
36. A company manufactures mechanical heart valves
from the heart valves of pigs. Different heart
operations require valves of different sizes. The
company purchases pig valves from three different
suppliers. The cost and size mix of the valves
purchased from each supplier are given in the file
P03_36.xlsx. Each month, the company places an
order with each supplier. At least 500 large, 300
medium, and 300 small valves must be purchased each
month. Because of the limited availability of pig
valves, at most 500 valves per month can be purchased
from each supplier.
a. Use Solver to determine how the company can
minimize the cost of acquiring the needed valves.
b. Use SolverTable to investigate the effect on total
cost of increasing its minimal purchase
requirements each month. Specifically, see how the
total cost changes as the minimal purchase
requirements of large, medium, and small valves
all increase from their original values by the same
percentage. Revise your model so that SolverTable
can be used to investigate these changes when the
percentage increase varies from 2% to 20% in
increments of 2%. Explain intuitively what
happens when this percentage is at least 16%.
37. A company that builds sailboats wants to determine
how many sailboats to build during each of the next
four quarters. The demand during each of the next four
quarters is as follows: first quarter, 160 sailboats;
second quarter, 240 sailboats; third quarter, 300
sailboats; fourth quarter, 100 sailboats. The company
must meet demands on time. At the beginning of the
first quarter, the company has an inventory of 40
sailboats. At the beginning of each quarter, the
company must decide how many sailboats to build
during that quarter. For simplicity, assume that
sailboats built during a quarter can be used to meet
demand for that quarter. During each quarter, the
company can build up to 160 sailboats with regular-
time labor at a total cost of $1600 per sailboat. By
having employees work overtime during a quarter, the
company can build additional sailboats with overtime
labor at a total cost of $1800 per sailboat. At the end
of each quarter (after production has occurred and the
current quarter’s demand has been satisfied), a holding
cost of $80 per sailboat is incurred.
a. Determine a production schedule to minimize the
sum of production and inventory holding costs
during the next four quarters.
3.11 Conclusion
125
b. Use SolverTable to see whether any changes in the
$80 holding cost per sailboat could induce the
company to carry more or less inventory. Revise
your model so that SolverTable can be used to
investigate the effects on ending inventory during
the four-quarter period of systematic changes in the
unit holding cost. (Assume that even though the
unit holding cost changes, it is still constant over
the four-quarter period.) Are there any
(nonnegative) unit holding costs that would induce
the company to hold more inventory than it holds
when the holding cost is $80? Are there any unit
holding costs that would induce the company to
hold less inventory than it holds when the holding
cost is $80?
38. During the next two months an automobile
manufacturer must meet (on time) the following
demands for trucks and cars: month 1, 400 trucks and
800 cars; month 2, 300 trucks and 300 cars. During
each month at most 1000 vehicles can be produced.
Each truck uses two tons of steel, and each car uses
one ton of steel. During month 1, steel costs $700 per
ton; during month 2, steel is projected to cost $800 per
ton. At most 2500 tons of steel can be purchased each
month. (Steel can be used only during the month in
which it is purchased.) At the beginning of month 1,
100 trucks and 200 cars are in the inventory. At the
end of each month, a holding cost of $200 per vehicle
is assessed. Each car gets 20 miles per gallon (mpg),
and each truck gets 10 mpg. During each month, the
vehicles produced by the company must average at
least 16 mpg.
a. Determine how to meet the demand and mileage
requirements at minimum total cost.
b. Use SolverTable to see how sensitive the total cost
is to the 16 mpg requirement. Specifically, let this
requirement vary from 14 mpg to 18 mpg in
increments of 0.25 mpg. Explain intuitively what
happens when the requirement is greater than 
17 mpg.
39. A textile company produces shirts and pants. Each
shirt requires two square yards of cloth, and each pair
of pants requires three square yards of cloth. During
the next two months the following demands for shirts
and pants must be met (on time): month 1, 1000 shirts
and 1500 pairs of pants; month 2, 1200 shirts and
1400 pairs of pants. During each month the following
resources are available: month 1, 9000 square yards of
cloth; month 2, 6000 square yards of cloth. In
addition, cloth that is available during month 1 and is
not used can be used during month 2. During each
month it costs $8 to produce an article of clothing with
regular-time labor and $16 with overtime labor.
During each month a total of at most 2500 articles of
clothing can be produced with regular-time labor, and
an unlimited number of articles of clothing can be
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

produced with overtime labor. At the end of each
month, a holding cost of $3 per article of clothing is
incurred (There is no holding cost for cloth.)
a. Determine how to meet demands for the next two
months (on time) at minimum cost. Assume that
100 shirts and 200 pairs of pants are already in
inventory at the beginning of month 1.
b. Use a two-way SolverTable to investigate the effect
on total cost of two simultaneous changes. The first
change is to allow the ratio of overtime to regular-
time production cost (currently $16/$8  2) to vary
from 1.2 to 1.8 in increments of 0.2, while keeping
the regular time cost at $8. The second change is
to allow the production capacity each month
(currently 2500) to decrease by 10% to 50% in
increments of 10%. The idea here is that less
regular-time capacity is available, but overtime
becomes relatively cheaper. Is the net effect on
total cost positive or negative?
40. Each year, a shoe manufacturing company faces
demands (which must be met on time) for pairs of
shoes as shown in the file P03_40.xlsx. Employees
work three consecutive quarters and then receive one
quarter off. For example, a worker might work during
quarters 3 and 4 of one year and quarter 1 of the next
year. During a quarter in which an employee works, he
or she can produce up to 500 pairs of shoes. Each
worker is paid $5000 per quarter. At the end of each
quarter, a holding cost of $10 per pair of shoes is
incurred.
a. Determine how to minimize the cost per year
(labor plus holding) of meeting the demands for
shoes. To simplify the model, assume that at the
end of each year, the ending inventory is 0. (You
can assume that a given worker gets the same
quarter off during each year.)
b. Suppose the company can pay a flat fee for a
training program that increases the productivity of
all of its workers. Use SolverTable to see how
much the company would be willing to pay for a
training program that increases worker productivity
from 500 pairs of shoes per quarter to P pairs of
shoes per quarter, where P varies from 525 to 700
in increments of 25.
41. A small appliance manufacturer must meet (on time)
the following demands: quarter 1, 3000 units;
quarter 2, 2000 units; quarter 3, 4000 units. Each
quarter, up to 2700 units can be produced with
regular-time labor, at a cost of $40 per unit. During
each quarter, an unlimited number of units can be
produced with overtime labor, at a cost of $60 per
unit. Of all units produced, 20% are unsuitable and
cannot be used to meet demand. Also, at the end of
each quarter, 10% of all units on hand spoil and
cannot be used to meet any future demands. After
each quarter’s demand is satisfied and spoilage is
126
Chapter 3
Introduction to Optimization Modeling
accounted for, a cost of $15 per unit in ending
inventory is incurred.
a. Determine how to minimize the total cost of
meeting the demands of the next three quarters.
Assume that 1000 usable units are available at the
beginning of quarter 1.
b. The company wants to know how much money it
would be worth to decrease the percentage of
unsuitable items and/or the percentage of items that
spoil. Write a short report that provides relevant
information. Base your report on three uses of
SolverTable: (1) where the percentage of unsuitable
items decreases and the percentage of items that
spoil stays at 10%, (2) where the percentage of
unsuitable items stays at 20% and the percentage of
items that spoil decreases, and (3) where both
percentages decrease. Does the sum of the separate
effects on total cost from the first two tables equal
the combined effect from the third table? Include an
answer to this question in your report.
42. A pharmaceutical company manufactures two drugs 
at Los Angeles and Indianapolis. The cost of
manufacturing a pound of each drug depends on 
the location, as indicated in the file P03_42.xlsx.
The machine time (in hours) required to produce a
pound of each drug at each city is also shown in this
table. The company must produce at least 1000
pounds per week of drug 1 and at least 2000 pounds
per week of drug 2. It has 500 hours per week of
machine time at Indianapolis and 400 hours per week
at Los Angeles.
a. Determine how the company can minimize the cost
of producing the required drugs.
b. Use SolverTable to determine how much the
company would be willing to pay to purchase a
combination of A extra hours of machine time at
Indianapolis and B extra hours of machine time at
Los Angeles, where A and B can be any positive
multiples of 10 up to 50.
43. A company manufactures two products on two
machines. The number of hours of machine time and
labor depends on the machine and product as shown in
the file P03_43.xlsx. The cost of producing a unit of
each product depends on which machine produces it.
These unit costs also appear in the same file. There are
200 hours available on each of the two machines, and
there are 400 labor hours available total. This month at
least 200 units of product 1 and at least 240 units of
product 2 must be produced. Also, at least half of the
product 1 requirement must be produced on machine
1, and at least half of the product 2 requirement must
be produced on machine 2.
a. Determine how the company can minimize the cost
of meeting this month’s requirements.
b. Use SolverTable to see how much the “at least
half” requirements are costing the company. Do
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

this by changing both of these requirements from
“at least half” to “at least x percent,” where x can
be any multiple of 5% from 0% to 50%.
Modeling Problems
44. Suppose you use Solver to find the optimal solution to
a maximization model. Then you remember that you
omitted an important constraint. After adding the
constraint and running Solver again, is the optimal
value of the objective guaranteed to decrease? Why or
why not?
45. Consider an optimization model with a number of
resource constraints. Each indicates that the amount of
the resource used cannot exceed the amount available.
Why is the shadow price of such a resource constraint
always zero when the amount used in the optimal
solution is less than the amount available?
46. If you add a constraint to an optimization model, and
the previously optimal solution satisfies the new
constraint, will this solution still be optimal with the
new constraint added? Why or why not?
47. Why is it generally necessary to add nonnegativity
constraints to an optimization model? Wouldn’t Solver
automatically choose nonnegative values for the
changing cells?
48. Suppose you have a linear optimization model where
you are trying to decide which products to produce to
maximize profit. What does the additive assumption
imply about the profit objective? What does the
proportionality assumption imply about the profit
objective? Be as specific as possible. Can you think of
any reasonable profit functions that would not be
linear in the amounts of the products produced?
49. In a typical product mix model, where a company
must decide how much of each product to produce to
maximize profit, discuss possible situations where
3.11 Conclusion
127
there might not be any feasible solutions. Could these
be realistic? If you had such a situation in your
company, how might you proceed?
50. In a typical product mix model, where a company
must decide how much of each product to produce to
maximize profit, there are sometimes customer
demands for the products. We used upper-bound
constraints for these: Don’t produce more than you
can sell. Would it be realistic to have lower-bound
constraints instead: Produce at least as much as is
demanded? Would it be realistic to have both (where
the upper bounds are greater than the lower bounds)?
Would it be realistic to have equality constraints:
Produce exactly what is demanded?
51. In a typical production scheduling model like
Pigskin’s, if there are no production capacity
constraints—the company can produce as much as it
needs in any time period—but there are storage
capacity constraints and demand must be met on time,
is it possible that there will be no feasible solutions?
Why or why not?
52. In a production scheduling problem like Pigskin’s,
suppose the company must produce several products
to meet customer demands. Would it suffice to solve a
separate model for each product, as we did for
Pigskin, or would one big model for all products be
necessary? If the latter, discuss what this big model
might look like.
53. In any optimization model such as those in this chapter,
we say that the model is unbounded (and Solver will
indicate as such) if there is no limit to the value of the
objective. For example, if the objective is profit, then
for any dollar value, no matter how large, there is a
feasible solution with profit at least this large. In the
real world, why are there never any unbounded
models? If you run Solver on a model and get an
“unbounded” message, what should you do?
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

APPENDIX INFORMATION ON SOLVERS
Microsoft Office (or Excel) ships with a built-in version of Solver. This version and all
other versions of Solver have been developed by Frontline Systems, not Microsoft. When
you install Office (or Excel), you have the option of installing or not installing Solver. In
most cases, a typical install should install Solver. To check whether Solver is installed on
your system, open Excel, select the Office Button (or the File tab in Excel 2010), select
Excel Options, select Add-Ins, and click on Go. If there is a Solver item in the list, Solver
has been installed. (To actually add it in, make sure this item is checked.) Otherwise, you
need to run the Office Setup program with the Add/Remove feature to install Solver. Users
of previous versions of Excel (2003 or earlier) should note that the actual Solver add-in file
is a different one in Excel 2007 or Excel 2010. In previous versions, it was Solver.xla; now
it is Solver.xlam. However, the basic functionality is the same.
If you have used versions of Solver in Excel 2007 or earlier, you will see some changes
in Solver for Excel 2010. First, the user interface is slightly different, as you have already
seen in the screen shots of its main dialog box. Second, it now includes the Evolutionary
algorithm, which used to be available only in the Premium Solver product. (Because of
this, we no longer need to supply an educational version of Premium Solver with the book.)
We will continue to use the Evolutionary algorithm extensively in Chapter 8. Third, the
Solver algorithms have been revised to work better. Specifically, we have very rarely seen
the annoying message about a model not being linear when we know it is linear. This mes-
sage can still occur in certain models, but it is less likely to occur than in previous versions
of Solver.
The built-in version of Solver is able to solve most problems you are likely to
encounter. However, it has two important limitations you should be aware of. First, it
allows only 200 changing cells. This might sound like plenty, but many real-world prob-
lems go well beyond 200 changing cells. Second, Solver for Excel 2010 allows only 100
constraints. (There was no such limit in previous versions.) For example, if you specify a
constraint such as B15:B17<=D15:D17, this counts as three constraints against the 100-
constraint limit. However, simple upper or lower bound constraints, such as B15<=100 or
B15>=50, where B15 is a changing cell, do not count against the 100-constraint limit. If
you want to solve larger problems, you will need to purchase one of Frontline’s commer-
cial versions of Solver. For more information, check Frontline Systems’ Web site at
www.solver.com.
128
Chapter 3
Introduction to Optimization Modeling
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Case 3.1 Shelby Shelving
129
C A S E
S
helby Shelving is a small company that
manufactures two types of shelves for grocery
stores. Model S is the standard model; model LX is a
heavy-duty version. Shelves are manufactured in
three major steps: stamping, forming, and assembly. In
the stamping stage, a large machine is used to stamp
(i.e., cut) standard sheets of metal into appropriate
sizes. In the forming stage, another machine bends
the metal into shape.Assembly involves joining the
parts with a combination of soldering and riveting.
Shelby’s stamping and forming machines work on
both models of shelves. Separate assembly
departments are used for the final stage of
production.
The file Shelby Shelving.xlsxcontains relevant
data for Shelby. (See Figure 3.35.) The hours required
on each machine for each unit of product are shown
in the range B5:C6 of the Accounting Data sheet.
For example, the production of one model S shelf
requires 0.25 hour on the forming machine. Both 
the stamping and forming machines can operate for
800 hours each month.The model S assembly
department has a monthly capacity of 1900 units.
The model LX assembly department has a monthly
capacity of only 1400 units. Currently Shelby is
producing and selling 400 units of model S and 
1400 units of model LX per month.
Model S shelves are sold for $1800, and model
LX shelves are sold for $2100. Shelby’s operation is
fairly small in the industry, and management at Shelby
believes it cannot raise prices beyond these levels
because of the competition. However, the marketing
department believes that Shelby can sell as much as it
can produce at these prices.The costs of production
are summarized in the Accounting Data sheet.
As usual, values in blue cells are given, whereas other
values are calculated from these.
Management at Shelby just met to discuss next
month’s operating plan.Although the shelves are
selling well, the overall profitability of the company is
a concern.The plant’s engineer suggested that the
current production of model S shelves be cut back.
According to him,“Model S shelves are sold for
3.1 SHELBY SHELVING
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
A
B
C
D
E
F
G
H
I
Shelby Shelving Data for Current
Schedule
Machine requirements (hours per
n
e
vi
G
)tin
u
monthly overhead cost data
Model S
Model LX
Available
Fixed
Variable S
Variable LX
0
9
$
0
8
$
0
0
0,5
2
1
$
g
nip
m
a
tS
0
0
8
3.0
3.0
g
nip
m
a
tS
0
7
1
$
0
2
1
$
0
0
0,5
9
$
g
ni
m
r
o
F
0
0
8
5.0
5
2.0
g
ni
m
r
o
F
Model S Assembly
$80,000
$165
$0
Model S
Model LX
Model LX Assembly
$85,000
$0
$185
Current monthly
400
1400
Standard costs of the shelves -- based on the current
levels
Hours spent in departments
Model S
Model LX
Model S
Model LX
Totals
Direct materials
$1,000
$1,200
tc
e
ri
D
0
4
5
0
2
4
0
2
1
g
nip
m
a
tS
labor:
0
0
8
0
0
7
0
0
1
g
ni
m
r
o
F
Stamping
$35
$35
Forming
$60
$90
Percentages of
spent in departments
Assembly
$80
$85
Model S
Model LX
Total direct labor
$175
$210
d
a
e
h
r
e
v
O
%
8.7
7
%
2.2
2
g
nip
m
a
tS
%
5.7
8
%
5.2
1
g
ni
m
r
o
F
Stamping
$149
$159
Forming
$150
$229
Unit selling price
$1,800
$2,100
Assembly
$365
$246
Total overhead
$664
$635
Assembly capacity
1900
1400
Total cost
$1,839
$2,045
Producon
producon
me
allocaon
producon
Figure 3.35
Data for Shelby Case
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

130
Chapter 3
Introduction to Optimization Modeling
$1800 per unit, but our costs are $1839. Even
though we’re selling only 400 units a month, we’re
losing money on each one.We should decrease
production of model S.” The controller disagreed. He
said that the problem was the model S assembly
department trying to absorb a large overhead with a
small production volume.“The model S units are
making a contribution to overhead. Even though
production doesn’t cover all of the fixed costs, we’d
be worse off with lower production.”
Your job is to develop an LP model of Shelby’s
problem, then run Solver, and finally make a
recommendation to Shelby management, with a
short verbal argument supporting the engineer or
the controller.
Notes on Accounting Data Calculations
The fixed overhead is distributed using activity-based
costing principles. For example, at current production
levels, the forming machine spends 100 hours on
model S shelves and 700 hours on model LX shelves.
The forming machine is used 800 hours of the month,
of which 12.5% of the time is spent on model S
shelves and 87.5% is spent on model LX shelves.The
$95,000 of fixed overhead in the forming department
is distributed as $11,875 ( 95,000 
 0.125) to
model S shelves and $83,125 ( 95,000 
 0.875) to
model LX shelves.The fixed overhead per unit of
output is allocated as $29.69 ( 11,875/400) for
model S and $59.38 ( 83,125/1400) for model LX.
In the calculation of the standard overhead cost, the
fixed and variable costs are added together, so that
the overhead cost for the forming department
allocated to a model S shelf is $149.69 ( 29.69  120,
shown in cell G20 rounded up to $150). Similarly, the
overhead cost for the forming department allocated
to a model LX shelf is $229.38 ( 59.38  170,
shown in cell H20 rounded down to $229).
■
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Case 3.2 Sonoma Valley Wines
131
C A S E
A
fter graduating from business school, George
Clark went to work for a Big Six accounting firm
in San Francisco. Because his hobby has always been
wine making, when he had the opportunity a few
years later he purchased five acres plus an option to
buy 35 additional acres of land in Sonoma Valley in
Northern California. He plans eventually to grow
grapes on that land and make wine with them.
George knows that this is a big undertaking and that
it will require more capital than he has at the
present. However, he figures that if he persists, he
will be able to leave accounting and live full time
from his winery earnings by the time he is 40.
Because wine making is capital-intensive and
because growing commercial-quality grapes with a
full yield of five tons per acre takes at least eight
years, George is planning to start small.This is
necessitated by both his lack of capital and his
inexperience in wine making on a large scale,
although he has long made wine at home. His plan is
first to plant the grapes on his land to get the vines
started.Then he needs to set up a small trailer
where he can live on weekends while he installs the
irrigation system and does the required work to the
vines, such as pruning and fertilizing.To help maintain
a positive cash flow during the first few years, he also
plans to buy grapes from other nearby growers so
he can make his own label wine. He proposes to
market it through a small tasting room that he will
build on his land and keep open on weekends during
the spring–summer season.
To begin, George is going to use $10,000 in
savings to finance the initial purchase of grapes from
which he will make his first batch of wine. He is also
thinking about going to the Bank of Sonoma and
asking for a loan. He knows that if he goes to the
bank, the loan officer will ask for a business plan; so
he is trying to pull together some numbers for
himself first.This way he will have a rough notion of
the profitability and cash flows associated with his
ideas before he develops a formal plan with a pro
forma income statement and balance sheet. He has
decided to make the preliminary planning horizon
two years and would like to estimate the profit over
that period. His most immediate task is to decide
how much of the $10,000 should be allocated to
purchasing grapes for the first year and how much to
purchasing grapes for the second year. In addition,
each year he must decide how much he should
allocate to purchasing grapes to make his favorite
Petite Sirah and how much to purchasing grapes to
make the more popular Sauvignon Blanc that seems
to have been capturing the attention of a wider
market during the last few years in California.
In the first year, each bottle of Petite Sirah
requires $0.80 worth of grapes and each bottle of
Sauvignon Blanc uses $0.70 worth of grapes. For the
second year, the costs of the grapes per bottle are
$0.75 and $0.85, respectively.
George anticipates that his Petite Sirah will sell
for $8.00 a bottle in the first year and for $8.25 in
the second year, while his Sauvignon Blanc’s price
remains the same in both years at $7.00 a bottle.
Besides the decisions about the amounts of
grapes purchased in the two years, George must
make estimates of the sales levels for the two wines
during the two years.The local wine-making
association has told him that marketing is the key to
success in any wine business; generally, demand is
directly proportional to the amount of effort spent
on marketing.Thus, since George cannot afford to do
any market research about sales levels due to his lack
of capital, he is pondering how much money he
should spend to promote each wine each year.The
wine-making association has given him a rule of
thumb that relates estimated demand to the amount
of money spent on advertising. For instance, they
estimate that for each dollar spent in the first year
promoting the Petite Sirah, a demand for five bottles
will be created; and for each dollar spent in the
second year, a demand for six bottles will result.
Similarly, for each dollar spent on advertising for the
Sauvignon Blanc in the first year, up to eight bottles
can be sold; and for each dollar spent in the second
year, up to ten bottles can be sold.
3.2 SONOMA VALLEY WINES15
15This case was written by William D. Whisler, California State
University, Hayward.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

132
Chapter 3
Introduction to Optimization Modeling
The initial funds for the advertising will come
from the $10,000 savings.Assume that the cash
earned from wine sales in the first year is available in
the second year.
A personal concern George has is that he
maintain a proper balance of wine products so that
he will be well positioned to expand his marketing
capabilities when he moves to the winery and makes
it his full-time job.Thus, in his mind it is important to
ensure that the number of bottles of Petite Sirah
sold each year falls in the range between 40% and
70% of the overall number of bottles sold.
Questions
1. George needs help to decide how many grapes
to buy, how much money to spend on
advertising, how many bottles of wine to sell,
and how much profit he can expect to earn over
the two-year period. Develop a spreadsheet LP
model to help him.
2. Solve the linear programming model formulated
in Question 1.
The following questions should be attempted only
after Questions 1 and 2 have been answered correctly.
3. After showing the business plan to the Bank of
Sonoma, George learns that the loan officer is
concerned about the market prices used in
estimating the profits—recently it has been
forecasted that Chile and Australia will be
flooding the market with high-quality, low-priced
white wines over the next couple of years. In
particular, the loan officer estimates that the price
used for the Sauvignon Blanc in the second year is
highly speculative and realistically might be only
half the price George calculated.Thus, the bank is
nervous about lending the money because of the
big effect such a decrease in price might have on
estimated profits.What do you think?
4. Another comment the loan officer of the Bank
of Sonoma has after reviewing the business plan
is:“I see that you do have an allowance in your
calculations for the carryover of inventory of
unsold wine from the first year to the second
year, but you do not have any cost associated
with this.All companies must charge something
for holding inventory, so you should redo your
plans to allow for this.” If the holding charges are
$0.10 per bottle per year, how much, if any, does
George’s plan change?
5. The president of the local grape growers’
association mentions to George that there is
likely to be a strike soon over the unionization
of the grape workers. (Currently they are not
represented by any union.) This means that the
costs of the grapes might go up by anywhere
from 50% to 100%. How might this affect
George’s plan?
6. Before taking his business plan to the bank,
George had it reviewed by a colleague at the
accounting firm where he works.Although his
friend was excited about the plan and its
prospects, he was dismayed to learn that George
had not used present value in determining his
profit.“George, you are an accountant and must
know that money has a time value; and although
you are only doing a two-year planning problem,
it still is important to calculate the present value
profit.” George replies,“Yes, I know all about
present value. For big investments over long
time periods, it is important to consider. But in
this case, for a small investment and only a 
two-year time period, it really doesn’t matter.”
Who is correct, George or his colleague? Why?
Use an 8% discount factor in answering this
question. Does the answer change if a 6% or
10% discount rate is used? Use a spreadsheet to
determine the coefficients of the objective
function for the different discount rates.
7. Suppose that the Bank of Sonoma is so excited
about the prospects of George’s wine-growing
business that they offer to lend him an extra
$10,000 at their best small business rate—28%
plus a 10% compensating balance.16 Should he
accept the bank’s offer? Why or why not?
8. Suppose that the rule of thumb George was
given by the local wine-making association is
incorrect.Assume that the number of bottles 
of Petite Sirah sold in the first and second 
years is at most four for each dollar spent on
advertising.And likewise for the Sauvignon Blanc,
assume that it can be at most only five in years
1 and 2.
9. How much could profits be increased if
George’s personal concerns (that Petite Sirah
sales should account for between 40% and 70%
of overall sales) are ignored?
16The compensating balance requirement means that only $9,000
of the $10,000 loan is available to George; the remaining $1,000
remains with the bank.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

C H A P T E R
4
Linear Programming Models
PRODUCTION,INVENTORY, AND 
DISTRIBUTION AT KELLOGG
T
he Kellogg Company is the largest cereal producer in the world and is a
leading producer of convenience foods. Its worldwide sales in 1999 were
nearly $7 billion. Kellogg’s ﬁrst product in 1906 was Corn Flakes, and it
developed a variety of ready-to-eat cereals over the years, including Raisin
Bran, Rice Krispies, Corn Pops, and others. Although the company continues
to develop and market new cereals, it has recently gone into convenience
foods, such as Pop-Tarts and Nutri-Grain cereal bars, and has also entered
the health-food market. Kellogg produces hundreds of products and sells
thousands of stock-keeping units (SKUs). Managing production, inventory,
and distribution of these—that is, the daily operations—in a cost-effective
manner is a challenge.
By the late 1980s, Kellogg realized that the increasing scale and
complexity of its operations required optimization methods to coordinate
its daily operations in a centralized manner. As described in Brown et al.
(2001), a team of management scientists developed an optimization software
system called KPS (Kellogg Planning System). This system was originally in-
tended for operational (daily and weekly) decisions, but it expanded into a
system for making tactical (longer-range) decisions about issues such as plant
budgets, capacity expansion, and consolidation. By the turn of the century,
KPS had been in use for about a decade. Operational decisions made by
ROB KIM/Landov
133
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

KPS reduced production, inventory, and distribution costs by approximately $4.5 million
per year. Better yet, the tactical side of KPS recently suggested a consolidation of pro-
duction capacity that saved the company approximately $35 million to $40 million
annually.
Kellogg operates 5 plants in the United States and Canada, has 7 distribution centers
(DCs) in such areas as Los Angeles and Chicago, and has about 15 co-packers, companies
that contract to produce or pack some of Kellogg’s products. Customer demands are
seen at the DCs and the plants. In the cereal business alone, Kellogg has to coordinate
the packaging, inventorying, and distributing of 600 SKUs at about 27 locations with a
total of about 90 productions lines and 180 packaging lines. This requires a tremendous
amount of day-to-day coordination to meet customer demand at a low cost. The KPS
operational system that guides operational decisions is essentially a large linear program-
ming model that takes as its inputs the forecasted customer demands for the various
products and speciﬁes what should be produced, held, and shipped on a daily basis. The
resulting model is similar to the Pigskin model of football production discussed in the
previous chapter, except that it is much larger.
Speciﬁcally, for each week of its 30-week planning horizon, the model speciﬁes 
(1) how much of each product to make on each production line at each facility, (2) how
much of each SKU to pack on each packaging line at each facility, (3) how much inven-
tory of each SKU to hold at each facility, and (4) how much of each SKU to ship from
each location to other locations. In addition, the model has to take constraints into ac-
count. For example, the production within a given plant in a week cannot exceed the
processing line capacity in that plant. Linear programming models such as Kellogg’s tend
to be very large—thousands of decision variables and hundreds or thousands of con-
straints—but the algorithms Kellogg uses are capable of optimizing such models very
quickly. Kellogg runs its KPS model each Sunday morning and uses its recommendations
in the ensuing week.
Kellogg’s KPS illustrates a common occurrence when companies turn to manage-
ment science for help. As stated earlier, the system was originally developed for making
daily operational decisions. Soon, however, the company developed a tactical version of
KPS for long-range planning on the order of 12 to 24 months. The tactical model is simi-
lar to the operational model except that time periods are now months, not days or
weeks, and other considerations must be handled, such as limited product shelf lives. The
point is, however, that when companies such as Kellogg become comfortable with man-
agement science methods in one part of their operations, they often look for other
areas to apply similar methods. As with Kellogg, such methods can save the company
millions of dollars. ■
134
Chapter 4
Linear Programming Models
4.1 INTRODUCTION
In a recent survey of Fortune 500 ﬁrms, 85% of those responding said that they used linear
programming. In this chapter, we discuss some of the LP models that are most often ap-
plied to real applications. In this chapter’s examples, you will discover how to build
optimization models to
■
purchase television ads
■
schedule postal workers
■
create an aggregate labor and production plan at a shoe company
■
create a blending plan to transform crude oils into end products
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

■
plan production of interdependent products at a drug company
■
choose an investment strategy at a ﬁnancial investment company
■
manage a pension fund
■
determine which of several hospitals use their inputs “efﬁciently”
The two basic goals of this chapter are to illustrate the wide range of real applications
that can take advantage of LP and to increase your facility in modeling LP problems in
Excel. We present a few principles that will help you model a wide variety of problems.
The best way to learn, however, is to see many examples and work through numerous prob-
lems. In short, mastering the art of LP spreadsheet modeling takes hard work and practice,
which you will ﬁnd plenty of in this chapter.
Before continuing, remember that all of the models in this chapter are linear models
as described in the previous chapter. This means that the target cell is ultimately (possibly
through a series of formulas in intervening cells) a sum of products of constants and chang-
ing cells, where a constant is deﬁned by the fact that it does not depend on changing cells.
Similarly, each side of each constraint is either a constant or a sum of products of constants
and changing cells. Also, each changing cell (except in a few cases where it is speciﬁed
otherwise) is allowed to contain a continuous range of values, not just integer values.
These properties allow Solver to use its very efﬁcient simplex method to ﬁnd the optimal
solution.1
4.2 ADVERTISING MODELS
Many companies spend enormous amounts of money to advertise their products. They
want to ensure that they are spending their money wisely. Typically, they want to reach
large numbers of various groups of potential customers and keep their advertising costs as
low as possible. The following example illustrates a simple model—and a reasonable ex-
tension of this model—for a company that purchases television ads.
4.2 Advertising Models
135
E X A M P L E
4.1 PURCHASING TELEVISION ADS
T
he General Flakes Company sells a brand of low-fat breakfast cereal that appeals to
people of all age groups and both genders. The company advertises this cereal in a va-
riety of 30-second television ads, and these ads can be placed in a variety of television
shows. The ads in different shows vary by cost—some 30-second slots are much more ex-
pensive than others—and by the types of viewers they are likely to reach. The company has
segmented the potential viewers into six mutually exclusive categories: males age 18 to 35,
males age 36 to 55, males over 55, females age 18 to 35, females age 36 to 55, and females
over 55. A rating service can supply data on the numbers of viewers in each of these cate-
gories who will watch a 30-second ad on any particular television show. Each such viewer
is called an exposure. The company has determined the required number of exposures it
wants to obtain for each group. It wants to know how many ads to place on each of several
television shows to obtain these required exposures at minimum cost. The data on costs per
ad, numbers of exposures per ad, and minimal required exposures are listed in Table 4.1,
where numbers of exposures are expressed in millions, and costs are in thousands of
dollars. What should the company do?
1In the special cases where integer constraints are imposed on some changing cells, the Simplex LP option can still
be chosen. However, Solver uses a somewhat different optimization algorithm when there are integer-constrained
changing cells. This is covered in more depth in Chapter 6.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Objective
To develop an LP spreadsheet model that relates the numbers of ads on vari-
ous television shows to the exposures to various viewer groups, and to use Solver to ﬁnd
the minimum-cost advertising strategy that meets minimum exposure constraints.
WHERE DO THE NUMBERSCOME FROM?
The data for this problem would probably be straightforward to obtain, as suggested here:
■
The advertising costs per ad are the going rates for 30-second slots for the various
types of shows.
■
The exposures per ad on the various shows are typically supplied by the media
planning departments of advertising agencies. (However, see the “Modeling Issues”
section at the end of this example.)
■
The required numbers of exposures are probably determined internally by the
company. The company’s marketing department knows which population groups are
its best customers and probably has some sense of the numbers of exposures the
company should obtain for a general level of advertising.
Solution
This problem is straightforward to model. As indicated in Table 4.2, the company needs to
decide how many ads to place on each television show. This determines the total advertis-
ing cost, which becomes the objective to minimize, and the total number of exposures to
each viewer group. The only constraint, other than nonnegativity, is that there must be at
least the required number of exposures for each group.
136
Chapter 4
Linear Programming Models
Table 4.1
Data for Advertising Problem
Viewer “Monday 
“The Real
Lifetime
“Law
Minimal
Group/
“Desperate
Night
“The “Sports
World”
Evening
& Order
Required 
TV Show
Housewives”
Football”
Simpsons” Center”
(MTV)
Movie
CNN
SVU”
Exposures
Men 18–35
5
6
5
0.5
0.7
0.1
0.1
3
60
Men 36–55
3
5
2
0.5
0.2
0.1
0.2
5
60
Men over 55
1
3
0
0.3
0
0
0.3
4
28
Women 18–35
6
1
4
0.1
0.9
0.6
0.1
3
60
Women 36–55
4
1
2
0.1
0.1
1.3
0.2
5
60
Women over 55
2
1
0
0
0
0.4
0.3
4
28
Cost per Ad
140
100
80
9
13
15
8
140
Table 4.2
Variables and Constraints for Advertising Model
Input variables
Cost per ad, exposures per ad, minimal required exposures
Decision variables (changing cells)
Numbers of ads to place on various types of shows
Objective (target cell)
Total advertising cost
Other calculated variables
Total exposures to each viewer group
Constraints
Actual exposures  Required exposures
Comparison to Product Mix Model
Before continuing, note that this model is essentially the opposite of the product mix
models in the previous chapter. With a product mix model, the goal is to make the values
of the decision variables (numbers of items to produce) as large as possible to make a large
proﬁt. The constraints on resource availability impose a limit on these values. In contrast,
the goal now is to make the values of the decision variables as small as possible to mini-
mize cost. This time, the constraints on required exposures impose lower limits on these
This list is a small
subset of shows from
which a company
could choose, but it is
a good representation
of the types of shows
favored by various age
groups and genders.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

values. These two prototype LP models—maximizing proﬁt subject to “less than or equal
to” constraints, and minimizing cost subject to “greater than or equal to” constraints—are
certainly not the only types of LP models that exist, but they are very common.
DEVELOPINGTHE SPREADSHEETMODEL
The completed model for the advertising problem appears in Figure 4.1.2 (See the file
Advertising 1.xlsx.) The model can be created with the following steps:
4.2 Advertising Models
137
LP models tend to
fall into “types,” at
least from a structural
point of view, even
though their actual
contexts might be
very different.The two
types mentioned here
are among the most
common.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
I
H
G
F
E
D
C
B
A
Adversing model
Inputs
Exposures to various groups per ad
Desperate Housewives
MNF
The Simpsons
Sports Center The Real World
Lifeme movie
CNN
Law & Order SVU
Men 18-35
3
1.0
1.0
7.0
5.0
5
6
5
Men 36-55
5
2.0
1.0
2.0
5.0
2
5
3
Men >55
4
3.0
0
0
3.0
0
3
1
Women 18-35
3
1.0
6.0
9.0
1.0
4
1
6
Women 36-55
5
2.0
3.1
1.0
1.0
2
1
4
Women >55
4
3.0
4.0
0
0
0
1
2
Total viewers
4
2
2.1
5.2
9.1
5.1
3
1
7
1
1
2
Cost per 
0
4
1
8
5
1
3
1
9
0
8
0
0
1
0
4
1
d
a
Cost per million 
4
5
1.6
2
8
8.5
7
6
6.6
s
e
r
u
s
o
p
x
e
6.000
6.842
6.000
6.667
5.833
Adversing plan
Desperate Housewives
MNF
The Simpsons
Sports Center The Real World
Lifeme movie
CNN
Law & Order SVU
Number ads 
9
1
7.8
0
0
0.0
0
0
0.0
d
e
s
a
h
cr
u
p
20.625
0.000
6.875
0.000
6.313
Constraints on numbers of exposures
Range names used:
Actual exposures
Required 
8
2
$
B
$:3
2
$
B
$
!le
d
o
M
=
s
e
r
u
s
o
p
x
e
_la
u
tc
A
s
e
r
u
s
o
p
x
e
Men 18-35
9
1
$I$:9
1
$
B
$
!le
d
o
M
=
d
e
s
a
h
cr
u
p
_
s
d
a
_
r
e
b
m
u
N
0
6
=
>
1
3
5.3
7
Men 36-55
8
2
$
D
$:3
2
$
D
$
!le
d
o
M
=
s
e
r
u
s
o
p
x
e
_
d
e
riu
q
e
R
0
6
=
>
0
0
0.0
6
Men >55
1
3
$
B
$
!le
d
o
M
=
ts
o
c
_la
t
o
T
8
2
=
>
8
3
4.1
3
Women 18-35
0
6
=
>
0
0
0.0
6
Women 36-55
0
6
=
>
0
0
0.0
6
Women >55
8
2
=
>
0
0
0.8
2
Objecve to minimize
Total 
0
0
0.0
7
8,1
$
ts
o
c
Note: All monetary values are in $1000s, and all 
exposures to ads are in millions of exposures.
Figure 4.1
Optimal Solution for the Advertising Model
1
Input values and range names. Enter the inputs from Table 4.1 in the shaded ranges,
and name the ranges as shown.
Excel Tip: Range Name Shortcut
We’ve said it before, but we’ll say it a gain. Whenever possible, use short and descriptive
labels such as in cells A19 and B22. Then you can tak e advantage of these labels, along
with the Create from Selection shortcut, to name multiple ranges quickly.
2
Ads purchased. Enter any values in the Number_ads_purchased range. These are the
only changing cells for this model.
3
Exposures obtained. The numbers of ads purchased determine the numbers of expo-
sures to the various viewer groups. To calculate these exposures, enter the formula
=SUMPRODUCT(B6:I6,Number_ads_purchased)
in cell B23 and copy it down to cell B28.
2 From here on, to save space we typically show only the optimal solution. However, remember that when you
develop a spreadsheet optimization model, you can enter any values in the changing cells initially. Solver will
eventually ﬁnd the optimal solution.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4
Total cost. The quantities of ads purchased also determine the total cost of advertising.
Calculate this cost in cell B31 with the formula
=SUMPRODUCT(B14:I14,Number_ads_purchased)
USING SOLVER
The main Solver dialog box appears in Figure 4.2. After ﬁlling it out as shown and check-
ing the Non-Negative option and selecting the Simplex LP method, click on the Solve
button to obtain the solution shown in Figure 4.1.
138
Chapter 4
Linear Programming Models
Figure 4.2
Solver Dialog
Box for the
Advertising 
Model
Discussion of the Solution
The optimal solution is probably not the one you would have guessed. With a set of ads that
cost very different amounts and reach very different mixes of viewers, it is difﬁcult to guess
the optimal strategy. For comparison, however, we calculated the total number of viewers
from each type of ad in row 12 and divided the costs in row 14 by the numbers of viewers
in row 12 to obtain the cost per million viewers in row 15. You might expect the ads with
low cost per million viewers to be chosen most frequently. However, this is not necessarily
the case. For example, “Monday Night Football” (MNF) has the second-lowest cost per
million viewers, but the optimal solution doesn’t include any ads for this show.
Sensitivity Anal
ysis
Solver’s sensitivity report, shown in Figure 4.3, is enlightening for this solution. Here is a
sample of the information it provides.
■
The company is not currently purchasing any ads on “Desperate Housewives.” The
reduced cost for this show implies that the cost per ad would have to decrease by at
least 10 ($10,000) before it would be optimal to purchase any ads on this show.
■
The company is currently purchasing about 20 ads on “Sports Center.” The allowable
increase and decrease for this show indicate how much the cost per ad would have to
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

change before the optimal number of ads on the show would change. For example, if
the price per ad increased above 9  0.762 ($9762), the company might purchase
fewer than 20 ads. How many fewer? You would have to rerun Solver to know.
■
The constraint on exposures to men in the 36–55 age range has the largest shadow
price, 15.000. If the company relaxed this constraint to require only 59 million
exposures, it would save $15,000 in total advertising cost. On the other side, if the
company required 61 million exposures to this group, rather than 60 million, its cost
would increase by $15,000.
A Dual-Objective Extension of the Model
This advertising model can be extended in a very natural way. General Flakes really 
has two competing objectives: (1) to obtain as many exposures as possible, and (2) to keep
the total advertising cost as low as possible. In the original model, we decided to minimize
total cost and constrain the exposures to be at least as large as a required level. An 
alternative is to maximize the total number of excess exposures and put a budget constraint
on total cost. Here, excess exposures are those above the minimal required level.
To implement this alternative, only minor modifications to the original model are
necessary, as shown in Figure 4.4. (See the ﬁle Advertising 2.xlsx.) You can do this with
the following steps:
1
Excess exposures. For each viewer group, calculate the number of excess exposures
by entering the formula
=B23-D23
in cell F23 and copying it down. Then sum these in cell B35 with the SUM function. This
cell becomes the new target cell to maximize.
2
Budget constraint. Calculate the total cost exactly as before, but now constrain it to be
less than or equal to a given budget in cell D32.
3
Solver dialog box. Modify the Solver dialog box as shown in Figure 4.5.
4.2 Advertising Models
139
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
H
G
F
E
D
C
B
A
Variable Cells
$B$19 Number ads purchased Desperate Housewives
0
10
140
1E+30
10
$C$19 Number ads purchased 
5.7
0
3
+
E
1
0
0
1
5.7
0
F
N
M
$D$19 Number ads purchased The Simpsons
8.719
0
80
1.744
29.091
$E$19 Number ads purchased Sports Center
20.625
0
9
0.762
0.451
$F$19 Number ads purchased The Real World
0
0.5
13
1E+30
0.5
$G$19 Number ads purchased Lifeme movie
6.875
0
15
2.286
1.103
$H$19 Number ads purchased 
5
2.2
0
3
+
E
1
8
5
2.2
0
N
N
C
$I$19
Number ads purchased Law & Order SVU
6.313
0
140
11.034
6.957
Constraints
$B$23 Men 18-35 Actual 
0
3
+
E
1
1
3
5.3
1
0
6
0
1
3
5.3
7
s
e
r
u
s
o
p
x
e
$B$24 Men 36-55 Actual 
6
1
1.5
4
4
0
6
5
1
0
6
s
e
r
u
s
o
p
x
e
$B$25 Men >55 Actual 
0
3
+
E
1
8
3
4.3
8
2
0
8
3
4.1
3
s
e
r
u
s
o
p
x
e
$B$26 Women 18-35 Actual 
1
3
9.4
1
1
1
0
6
0
1
0
6
s
e
r
u
s
o
p
x
e
$B$27 Women 36-55 Actual 
9
8
8.4
9
8
8.4
4
0
6
5
0
6
s
e
r
u
s
o
p
x
e
$B$28 Women >55 Actual 
6
8
5.7
6
8
2.6
8
2
5.2
8
2
s
e
r
u
s
o
p
x
e
Final
Reduced
Objecve
Allowable
Allowable
Cell
Name
Value
Cost
Coeﬃcient
Increase
Decrease
Final
Shadow
Constraint
Allowable
Allowable
Cell
Name
Value
Price
R.H. Side
Increase
Decrease
 
Figure 4.3
Sensitivity Report for the Advertising Model 
This is called a dual-
objective optimization
model.Typically, the
two objectives are
pulling in different di-
rections, as they are
here.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

At this point, you are probably wondering where the budget of $2 million in Figure 4.4
comes from. This requires some explanation of the solution strategy in this extension of the
original model. The basic assumption is that the company has two objectives: to maximize
total excess exposures and to minimize total cost. Unfortunately, it is impossible to do both
because they are pulling in different directions. When you have a dual-objective problem
140
Chapter 4
Linear Programming Models
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
I
H
G
F
E
D
C
B
A
Two-objecve adversing model
Inputs
Exposures to various groups per ad
Desperate Housewives
MNF
The Simpsons
Sports Center
The Real World
Lifeme movie
CNN
Law & Order SVU
Men 18-35
3
1.0
1.0
7.0
5.0
5
6
5
Men 36-55
5
2.0
1.0
2.0
5.0
2
5
3
Men >55
4
3.0
0
0
3.0
0
3
1
Women 18-35
3
1.0
6.0
9.0
1.0
4
1
6
Women 36-55
5
2.0
3.1
1.0
1.0
2
1
4
Women >55
4
3.0
4.0
0
0
0
1
2
Total viewers
4
2
2.1
5.2
9.1
5.1
3
1
7
1
1
2
Cost per 
0
4
1
8
5
1
3
1
9
0
8
0
0
1
0
4
1
d
a
Cost per million exposures
6.667
5.882
6.154
6.000
6.842
6.000
6.667
5.833
Adversing plan
Desperate Housewives
MNF
The Simpsons
Sports Center
The Real World
Lifeme movie
CNN
Law & Order SVU
Number ads 
0
3
0.6
0
0
0.0
0
0
0.0
d
e
s
a
h
cr
u
p
0.000
0.000
12.060
0.000
9.548
Constraints on numbers of exposures
Range names used:
Actual exposures
Required exposures
Excess exposures
Actual_exposures
=Model!$B$23:$B$28
Men 18-35
2
3
$
D
$
!le
d
o
M
=
t
e
g
d
u
B
0
0
0.0
0
6
=
>
0
0
0.0
6
Men 36-55
8
2
$
F
$:3
2
$
F
$
!le
d
o
M
=
s
e
r
u
s
o
p
x
e
_
ss
e
c
x
E
5
0
0.1
0
6
=
>
5
0
0.1
6
Men >55
9
1
$I$:9
1
$
B
$
!le
d
o
M
=
d
e
s
a
h
cr
u
p
_
s
d
a
_
r
e
b
m
u
N
1
9
1.0
1
8
2
=
>
1
9
1.8
3
Women 18-35
8
2
$
D
$:3
2
$
D
$
!le
d
o
M
=
s
e
r
u
s
o
p
x
e
_
d
e
riu
q
e
R
0
0
0.0
0
6
=
>
0
0
0.0
6
Women 36-55
2
3
$
B
$
!le
d
o
M
=
ts
o
c
_la
t
o
T
7
7
4.5
1
0
6
=
>
7
7
4.5
7
Women >55
5
3
$
B
$
!le
d
o
M
=
s
e
r
u
s
o
p
x
e
_
ss
e
c
x
e
_la
t
o
T
5
1
0.5
1
8
2
=
>
5
1
0.3
4
Budget constrain on total cost
Total 
t
e
g
d
u
B
ts
o
c
$2,000
<=
$2,000
Objecve to maximize
Total excess 
8
8
6.1
4
s
e
r
u
s
o
p
x
e
Note: All monetary values are in $1000s, and all 
exposures to ads are in millions of exposures.
Figure 4.4
Spreadsheet Model for Extension to the Advertising Problem
Figure 4.5
Modiﬁed Solver
Dialog Box for
Extension to the
Advertising 
Problem
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

such as this, you typically use one of the objectives as the target cell and constrain the other.
Here, the company is asking how many excess exposures it can get for a given budget.
There is no natural budget to use, and it makes perfect sense to ask questions such as these:
How many exposures can the company get for $1.9 million? How many for $2.0 million?
How many for $2.1 million?
Fortunately, SolverTable is the perfect tool to answer all of these questions in one step.
You ﬁrst develop the model as in Figure 4.4, using any budget such as $2.0 million in
cell D32, and run Solver in the usual way. Then you run a one-way SolverTable, allowing
the budget to vary over some desired range, and keep track of selected output variables.
Typical results appear in Figure 4.6, which are based on the SolverTable settings in
Figure 4.7. For low budget levels, the problem is infeasible—there is no way with this bud-
get to obtain the required exposures. Above a certain budget level, the problem becomes
feasible, and the optimal solutions are shown. As the budget increases, the company can
clearly obtain larger numbers of excess exposures, but the optimal advertising strategy in
columns B through I changes in a somewhat unpredictable way.
The results of this sensitivity analysis can be shown graphically in a trade-off curve,
as in Figure 4.8. To create this, highlight the numbers in columns A and J of Figure 4.6
(from row 43 down) and insert a line chart. This chart illustrates the rather obvious fact that
when the company is allowed to spend more on advertising, it can achieve more total
excess exposures.
4.2 Advertising Models
141
Figure 4.6
Sensitivity of Optimal Solution to the Advertising Budget
For dual-objective
models, you optimize
one objective and put
a constraint on the
other.Then you can
use SolverTable to
vary the right-hand
side of this constraint.
The result is a 
trade-off curve.
1
2
3
A
B
C
D
E
F
G
H
I
J
Oneway analysis for Solver model in Model worksheet
Budget (cell $D$32) values along side, output cell(s) along top
hased_1
hased_2
hased_3
hased_4
hased_5
hased_6
hased_7
hased_8
osures
4
5
Number_ads_purch
Number_ads_purch
Number_ads_purch
Number_ads_purch
Number_ads_purch
Number_ads_purch
Number_ads_purch
Number_ads_purch
Total_excess_expos
$1,800 Not feasible
5
6
7
8
9
10
11
12
$1,800 Not feasible
$1,850 Not feasible
$1,900
0.000
0.000
8.208
0.000
0.000
1.887
0.000
8.679
23.717
$1,950
0.000
0.000
6.934
0.000
0.000
8.491
0.000
9.057
32.726
$2,000
0.000
0.000
6.030
0.000
0.000
12.060
0.000
9.548
41.688
$2,050
0.000
0.000
5.653
0.000
0.000
11.307
0.000
10.201
50.583
$2,100
0.000
0.000
5.276
0.000
0.000
10.553
0.000
10.854
59.477
$2 150
0 000
0 000
4 899
0 000
0 000
9 799
0 000
11 508
68 372
12
13
14
15
16
17
18
$2,150
0.000
0.000
4.899
0.000
0.000
9.799
0.000
11.508
68.372
$2,200
0.000
0.000
4.523
0.000
0.000
9.045
0.000
12.161
77.266
$2,250
0.000
0.000
4.146
0.000
0.000
8.291
0.000
12.814
86.161
$2,300
0.000
0.000
3.769
0.000
0.000
7.538
0.000
13.467
95.055
$2,350
0.000
0.000
3.392
0.000
0.000
6.784
0.000
14.121
103.950
$2,400
0.000
0.000
3.015
0.000
0.000
6.030
0.000
14.774
112.844
$2,450
0.000
0.000
2.638
0.000
0.000
5.276
0.000
15.427
121.739
19
$2,500
0.000
0.000
2.261
0.000
0.000
4.523
0.000
16.080
130.633
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

40
60
80
100
120
140
Sensivity of Total_excess_exposures to Budget
0
20
40
60
80
100
120
140
$1,900$1,950$2,000$2,050$2,100$2,150$2,200$2,250$2,300$2,350$2,400$2,450$2,500
Budget ($D$32)
Sensivity of Total_excess_exposures to Budget
142
Chapter 4
Linear Programming Models
Figure 4.8
Trade-Off Curve Between Total Excess Exposures and Total Cost
Figure 4.7
SolverTable 
Settings for 
Sensitivity Analysis
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Consider the following about this integer solution:
■
The total cost in the target cell is now worse (larger) than before. This illustrates the
general rule that when any additional constraints are imposed, including integer con-
straints, the objective can only get worse or remain the same; it can never get better.
■
The optimal integer solution is not the rounded noninteger solution. In fact, it isn’t
even close. (Compare the before and after “The Real World” and “Sports Center”
Using Integer Constraints
The two advertising models to this point have allowed noninteger values in the chang-
ing cells. In reality, this is not allowed; the company cannot purchase, say, 6.313 ads on
“Law & Order SVU.” It must purchase integer numbers of ads. Given this, your ﬁrst in-
stinct is probably to round the optimal values in the changing cells to the nearest integers
to obtain the optimal integer solution. Unfortunately, this can have unpredictable results.
First, the rounded solution might not be feasible. Second, even if it is feasible, it might not
be the optimal integer solution.
Although all of Chapter 6 is devoted to special types of integer programming models—
those with integer constraints on at least some of the changing cells—we can preview the
topic here. In fact, from a user’s standpoint, there isn’t much to it. To force the changing
cells to have integer values, you simply add another constraint in the Solver dialog box, as
shown in Figure 4.9. In the left text box, select the changing cell range. In the middle text box,
select int (for integer). The right text box then automatically contains the word Integer. When
you eventually click on Solve, you get the optimal integer solution shown in Figure 4.10.
4.2 Advertising Models
143
Figure 4.9
Specifying an
Integer Constraint
Use the int option in
the Solver constraint
dialog box to constrain
changing cells to be
integers.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
I
H
G
F
E
D
C
B
A
Adversing model
Inputs
Exposures to various groups per ad
Desperate Housewives
MNF
The Simpsons
Sports Center The Real World
Lifeme movie
CNN
Law & Order SVU
Men 18-35
3
1.0
1.0
7.0
5.0
5
6
5
Men 36-55
5
2.0
1.0
2.0
5.0
2
5
3
Men >55
4
3.0
0
0
3.0
0
3
1
Women 18-35
3
1.0
6.0
9.0
1.0
4
1
6
Women 36-55
5
2.0
3.1
1.0
1.0
2
1
4
Women >55
4
3.0
4.0
0
0
0
1
2
Total viewers
4
2
2.1
5.2
9.1
5.1
3
1
7
1
1
2
Cost per 
0
4
1
8
5
1
3
1
9
0
8
0
0
1
0
4
1
d
a
Cost per million exposures
6.667
5.882
6.154
6.000
6.842
6.000
6.667
5.833
Adversing plan
Desperate Housewives
MNF
The Simpsons
Sports Center The Real World
Lifeme movie
CNN
Law & Order SVU
Number ads 
7
0
6
2
6
1
8
0
0
d
e
s
a
h
cr
u
p
Constraints on numbers of exposures
Actual exposures
Required exposures
Men 18-35
0
6
=
>
0
0
0.1
7
Men 36-55
0
6
=
>
0
0
0.0
6
Men >55
8
2
=
>
0
0
8.2
3
Women 18-35
0
6
=
>
0
0
0.0
6
Women 36-55
0
6
=
>
0
0
6.0
6
Women >55
8
2
=
>
0
0
4.0
3
Objecve to minimize
Total 
0
0
0.0
8
8,1
$
ts
o
c
Note: All monetary values are in $1000s, and all 
exposures to ads are in millions of exposures.
Figure 4.10
Optimal Integer Solution to the Advertising Problem
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

144
Chapter 4
Linear Programming Models
P R O B L E M S
Solutions for problems whose numbers appear within a
colored box can be found in the Student Solutions Files.
Refer to this book’s preface for purchase information.
Skill-Building Problems
1.
In addition to the constraints already in the (original)
advertising model, suppose General Flakes also wants
to obtain at least 180 million exposures to men and at
least 160 million exposures to women. Does the
current optimal solution satisfy these constraints? If
not, modify the model as necessary, and rerun Solver
to ﬁnd the new optimal solution.
2.
Suppose, as a matter of corporate policy, that General
Flakes decides not to advertise on the Lifetime
channel. Modify the original advertising model
appropriately and ﬁnd the new optimal solution. How
much has it cost the company to make this policy
decision?
3.
Suppose, in addition to the shows already listed,
General Flakes wants to open the possibility of pur-
chasing ads on the “Good Morning America” show on
ABC. Make up any reasonable input data you need to
include this possibility in the (original) model, and
ﬁnd the optimal solution.
4.
Suppose that General Flakes decides that it shouldn’t
place any more than 10 ads on any given show.
Modify the (original) advertising model appropriately
to incorporate this constraint, and then reoptimize
(with integer constraints on the numbers of ads).
Finally, run SolverTable to see how sensitive the
optimal solution is to the maximum number of ads per
show allowed. You can decide on a reasonable range
for the sensitivity analysis.
Unfortunately, many
marketing models,
including this one, are
inherently nonlinear.
The advertising model has one weakness, at least for realistic applications. Perhaps you
have already spotted it: double-counting. Suppose a company runs three ads for the same
product on a “Monday Night Football” telecast. Also, suppose that the rating service
claims that an ad reaches, say, six million men age 18–35. How many total exposures do
these three ads reach for this viewer group? Our model claims that it reaches 3(6)  18 mil-
lion. However, the effective number of exposures is probably lower than 18 million, for the
simple reason that many of the same men are watching all three ads.
This presents two difﬁculties for the modeler. First, it is probably difﬁcult to estimate
the effective number of exposures to any viewer group when an ad is run multiple times on
the same show. Second, even if a company can obtain such estimates, it faces a nonlinear
model, as discussed in Chapter 7. This is because the proportionality assumption of LP no
longer holds. Speciﬁcally, each extra ad on a given show reaches a decreasing number of
new exposures. (We will revisit this model in Chapter 7.)
■
MODELING ISSUES
values, for example.) Rounding noninteger solutions sometimes works, and some-
times it doesn’t. Using Solver with explicit integer constraints is always safer.
■
When there are integer constraints, Solver uses an algorithm—called branch and
bound—that is signiﬁcantly different from the simplex method. (Actually, the sim-
plex method is still used to solve subproblems, but we won’t discuss the details here.)
Integer-constrained models are typically much harder to solve than models without
any integer constraints. Although this small model still solves in a fraction of a sec-
ond, larger integer models can take minutes or even hours of solution time.
■
If the model is linear except for the integer constraints—that is, it satisﬁes the
proportionality and additivity assumptions of linear models—you should still select
the Simplex LP method.
■
Specifying integer
constraints in the
Solver dialog box is
easy. Be aware,
however, that Solver
must typically do a lot
more work to solve
problems with integer
constraints.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4.3 Worker Scheduling Models
145
E X A M P L E
4.2 POSTAL EMPLOYEE SCHEDULING
A
post ofﬁce requires different numbers of full-time employees on different days of the
week. The number of full-time employees required each day is given in Table 4.3.
Union rules state that each full-time employee must work ﬁve consecutive days and then
receive two days off. For example, an employee who works Monday to Friday must be off
on Saturday and Sunday. The post ofﬁce wants to meet its daily requirements using only
full-time employees. Its objective is to minimize the number of full-time employees on its
payroll.
Table 4.3
Employee Requirements for Post Ofﬁce
Day of Week
Minimum Number of Employees Required
Monday
17
Tuesday
13
Wednesday
15
Thursday
19
Friday
14
Saturday
16
Sunday
11
In real employee-
scheduling problems,
much of the work
involves forecasting
and queueing analysis
to obtain worker
requirements.This 
must be done before
an optimal schedule
can be found.
Objective
To develop an LP spreadsheet model that relates ﬁve-day shift schedules to
daily numbers of employees available, and to use Solver on this model to ﬁnd a schedule
that uses the fewest number of employees and meets all daily workforce requirements.
WHERE DO THE NUMBERS COME FROM?
The only inputs needed for this problem are the minimum employee requirements in 
Table 4.3, but these are not easy to obtain. They would probably be obtained through a
combination of two quantitative techniques: forecasting (Chapter 14) and queueing 
analysis (Chapter 13). The post ofﬁce would ﬁrst use historical data to forecast customer
and mail arrival patterns throughout a typical week. It would then use queueing analysis
to translate these arrival patterns into worker requirements on a daily basis. Actually, 
we have kept the problem relatively simple by considering only daily requirements. In a
realistic setting, the organization might forecast worker requirements on an hourly or even
a 15-minute basis.
trade-off curve from the results of the sensitivity
analysis.
6.
Suppose there are three objectives, not just two:
the total advertising cost, the total number of excess
exposures to men, and the total number of excess
exposures to women. Continuing the approach sug-
gested in the previous problem, how might you
proceed? Take it as far as you can, including a
sensitivity analysis and a trade-off curve.
Skill-Extending Problems
5.
In the dual-objective advertising model, we put a
budget constraint on the total advertising cost and
then maximized the total number of excess expo-
sures. Do it the opposite way, reversing the roles of
the two objectives. That is, model it so that you put a
lower limit on the total number of excess exposures
and minimize the total advertising cost. Then run a
sensitivity analysis on this lower limit, and create a
4.3 WORKER SCHEDULING MODELS
Many organizations must determine how to schedule employees to provide adequate ser-
vice. The following example illustrates how LP can be used to schedule employees.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

146
Chapter 4
Linear Programming Models
FUNDAMENTAL INSIGHT
Choosing the Changing Cells
The changing cells, which are really just the decision
variables,should always be chosen so that their values
determine all required outputs in the model. In other
words, their values should tell the compan y exactly
how to run its business. Sometimes the choice of
changing cells is obvious, but in many cases (as in this
worker scheduling model),
the pr oper choice of
changing cells takes some deeper thinking about the
problem. An improper choice of changing cells typi-
cally leads to a dead end, where their values do not
supply enough information to calculate required out-
puts or implement certain constraints.
Note that this is a “wraparound” problem. We assume that the daily requirements in
Table 4.3 and the worker schedules continue week after week. So, for example, if eight em-
ployees are assigned to the Thursday through Monday shift, these employees always wrap
around from one week to the next on their ﬁve-day shift.
DEVELOPING THE SPREADSHEET MODEL
The spreadsheet model for this problem is shown in Figure 4.11. (See the ﬁle Worker
Scheduling.xlsx.) To form this spreadsheet, proceed as follows.
1
Inputs and range names. Enter the number of employees needed on each day of the
week (from Table 4.3) in the blue cells, and create the range names shown.
2
Employees beginning each day. Enter any trial values for the number of employees
beginning work on each day of the week in the Employees_starting range. These beginning
Table 4.4
Variables and Constraints for Postal Scheduling Problem
Input variables
Minimum required number of workers each day
Decision variables (changing cells)
Number of employees working each of the ﬁve-day shifts
(deﬁned by their ﬁrst day of work)
Objective cell
Total number of employees on the payroll
Other calculated variables
Number of employees working each day
Constraints
Employees working
Employees required
Ú
The key to this model
is choosing the correct
changing cells.
Solution
The variables and constraints for this problem appear in Table 4.4. The trickiest part is iden-
tifying the appropriate decision variables. Many students believe the decision variables
should be the numbers of employees working on the various days of the week. Clearly, these
values must eventually be determined. However, it is not enough to specify, say, that 18 em-
ployees are working on Monday. The problem is that this doesn’t indicate when these 
18 employees start their ﬁve-day shifts. Without this knowledge, it is impossible to implement
the ﬁve-consecutive-day, two-day-off requirement. (If you don’t believe this, try developing
your own model with the wrong decision variables. You will eventually reach a dead end.)
The trick is to deﬁne the decision variables as the numbers of employees working each
of the seven possible ﬁve-day shifts. By knowing the values of these decision variables, the
other output variables can be calculated. For example, the number working on Thursday is
the sum of those who begin their ﬁve-day shifts on Sunday, Monday, Tuesday, Wednesday,
and Thursday.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4.3 Worker Scheduling Models
147
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
A
B
C
D
E
F
G
H
I
J
K
Worker scheduling 
e
g
n
a
R
le
d
o
m
 names used
Employees_available
=Model!$B$23:$H$23
Decision variables: number of employees starng their ﬁve-day shi on various days
Employees_required
=Model!$B$25:$H$25
0
1
$
B
$:4
$
B
$
!le
d
o
M
=
g
nitr
a
tS
_
s
e
e
y
olp
m
E
3
3.6
n
o
M
8
2
$
B
$
!le
d
o
M
=
s
e
e
y
olp
m
e
_la
t
o
T
0
0.5
e
u
T
3
3.0
d
e
W
3
3.7
u
h
T
0
0.0
ir
F
3
3.3
t
a
S
0
0.0
n
u
S
Result of decisions: number of employees working on various days (along top) who started their shi on various days (along side)
Mon
Tue
Wed
Thu
Fri
Sat
Sun
3
3.6
3
3.6
3
3.6
3
3.6
3
3.6
n
o
M
0
0.5
0
0.5
0
0.5
0
0.5
0
0.5
e
u
T
3
3.0
3
3.0
3
3.0
3
3.0
3
3.0
d
e
W
3
3.7
3
3.7
3
3.7
3
3.7
3
3.7
u
h
T
0
0.0
0
0.0
0
0.0
0
0.0
0
0.0
ir
F
3
3.3
3
3.3
3
3.3
3
3.3
3
3.3
t
a
S
0
0.0
0
0.0
0
0.0
0
0.0
0
0.0
n
u
S
Constraint on worker availabilies
Employees available
17.00
14.67
15.00
19.00
19.00
16.00
11.00
>=
>=
>=
>=
>=
>=
>=
Employees required
17
13
15
19
14
16
11
Objecve to maximize
Total employees
22.33
Figure 4.11
Worker Scheduling Model with Optimal Solution
days determine the possible ﬁve-day shifts. For example, the employees in cell B4 work
Monday through Friday.
3
Employees on hand each day. The key to this solution is to realize that the numbers
in the Employees_starting range—the changing cells—do not represent the number of
workers who will show up each day. As an example, the number in cell B4 represent those
who start on Monday and work Monday through Friday. Therefore, enter the formula
$B$4
in cell B14 and copy it across to cell F14. Proceed similarly for rows 15–20, being careful
to take wraparounds into account. For example, the workers starting on Thursday work
Thursday through Sunday, plus Monday. Then calculate the total number who are available
on each day by entering the formula
SUM(B14:B20)
in cell B23 and copying it across to cell H23.
Excel Tip: CTRL+Enter Shortcut
You often enter a typical formula in a cell and then copy it. One way to do this efficiently is
to highlight the entir e r ange, her e B23:H23. Then enter the typical formula, her
e
SUM(B14:B20), and press CtrlEnter. This has the same ef fect as copying , but it is
slightly quicker.
4
Total employees. Calculate the total number of employees in cell B28 with the
formula
SUM(Employees_starting)
Note that there is no double-counting in this sum. For example, the employees in cells B4
and B5 are not the same people.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

148
Chapter 4
Linear Programming Models
Figure 4.12
Solver Dialog Box
for Worker 
Scheduling Model
At this point, you might want to experiment with the numbers in the changing cell
range to see whether you can guess an optimal solution (without looking at Figure 4.11). It
is not that easy. Each worker who starts on a given day works the next four days as well, so
when you ﬁnd a solution that meets the minimal requirements for the various days, you
usually have a few more workers available on some days than are needed.
USING SOLVER
Invoke Solver and ﬁll out its main dialog box as shown in Figure 4.12. (You don’t need to
include the integer constraints yet. We will discuss them shortly.) Make sure you check the
Non-Negative option and use the Simplex LP method.
Discussion of the Solution
The optimal solution shown in Figure 4.11 has one drawback: It requires the number of em-
ployees starting work on some days to be a fraction. Because part-time employees are not
allowed, this solution is unrealistic. However, it is simple to add an integer constraint on the
changing cells. This integer constraint appears in Figure 4.12. With this integer constraint,
the optimal solution appears in Figure 4.13.
The changing cells in the optimal solution indicate the numbers of workers who start
their ﬁve-day shifts on the various days. You can then look at the columns of the B14:H20
range to see which employees are working on any given day. This optimal solution is typi-
cal in scheduling problems. Due to a labor constraint—each employee must work five
consecutive days and then have two days off—it is typically impossible to meet the mini-
mum employee requirements exactly. To ensure that there are enough employees available
on busy days, it is necessary to have more than enough on hand on light days.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4.3 Worker Scheduling Models
149
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
A
B
C
D
E
F
G
H
I
J
K
Worker scheduling
e
g
n
a
R
le
d
o
m
names used
Employees_available
=Model!$B$23:$H$23
Decision variables: number of employees starng their ﬁve-day shi on various days
Employees_required
=Model!$B$25:$H$25
0
1
$
B
$:4
$
B
$
!le
d
o
M
=
g
nitr
a
tS
_
s
e
e
y
olp
m
E
6
Mon
8
2
$
B
$
!le
d
o
M
=
s
e
e
y
olp
m
e
_la
t
o
T
6
e
u
T
0
d
e
W
7
u
h
T
0
ir
F
4
t
a
S
0
n
u
S
Result of decisions: number of employees working on various days (along top) who started their shi on various days (along side)
Mon
Tue
Wed
Thu
Fri
Sat
Sun
6
6
6
6
6
n
o
M
6
6
6
6
6
e
u
T
0
0
0
0
0
d
e
W
7
7
7
7
7
u
h
T
0
0
0
0
0
ir
F
4
4
4
4
4
t
a
S
0
0
0
0
0
n
u
S
Constraint on worker availabilies
Employees available
17
16
16
19
19
17
11
>=
>=
>=
>=
>=
>=
>=
Employees required
17
13
15
19
14
16
11
Objecve to maximize
Total employees
23
Figure 4.13
Optimal Integer Solution to Worker Scheduling Model
Another interesting aspect of this problem is that if you solve this problem on your own
PC, you might get a different schedule that is still optimal—that is, a solution that still uses a
total of 23 employees and meets all constraints. This is a case of multiple optimal solutions,
not at all uncommon in LP problems. In fact, it is typically good news for a manager, who can
then choose among the optimal solutions using other, possibly nonquantitative criteria.3
Technical Tip: Solver Tolerance Setting
When working with inte ger constraints, you should be awar e of Solver’s Tolerance setting.
The idea is as follows. As Solver searches for the best integer solution, it is often able to ﬁnd
a “good” solution fairly quickly, but it often has to spend a lot of time ﬁnding slightly better
solutions. A nonzero tolerance setting allows it to quit early. The default tolerance setting is
5 (percent). This means that if Solver ﬁnds a feasible solution that is guar anteed to have an
objective value no more than 5% from the optimal value, it will quit and report this good so-
lution (which might even be the optimal solution). Therefore, if you keep this default tolerance
value, your integer solutions will sometimes not be optimal, but they will be close. If you want
to ensure that you get an optimal solution, you can change the Solver tolerance value to zero.
(In Excel 2010, this setting is directly under the Solver Options on the All Methods tab.)
Sensitivity Analysis
The most obvious type of sensitivity analysis in this example is to analyze the effect of
worker requirements on the optimal solution. Speciﬁcally, let’s suppose the number of em-
ployees needed on each day of the week increases by two, four, or six. How does this
change the total number of employees needed? You can answer this with SolverTable, but
you must ﬁrst modify the model slightly, as shown in Figure 4.14. The problem is that we
want to increase each of the daily minimal required values by the same amount. The trick
is to enter the original requirements in row 12, enter a trial value for the extra number
Set Solver’s Tolerance
to zero to ensure that 
you get the optimal
integer solution. Be
aware, however, that
this can incur
significant extra
computing time for
larger models.
Multiple optimal
solutions have
different values in 
the changing cells,
but they all have the 
same objective value.
3 It is usually difﬁcult to tell whether there are multiple optimal solutions. You typically discover this by rerunning
Solver from different starting solutions.
To run some 
sensitivity analyses 
with SolverTable, you
need to modify the
original model slightly
to incorporate the
effect of the input
being varied.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

150
Chapter 4
Linear Programming Models
required per day in cell K12, enter the formula B12+$K$12 in cell B27, and then copy
this formula across to cell H27. Now you can use the one-way SolverTable option, using
cell K12 as the single input, letting it vary from 0 to 6 in increments of 2, and specifying
the Total_employees cell as the single output cell.
The results appear in Figure 4.15. When the requirement increases by two each day,
only two extra employees are necessary (scheduled appropriately). However, when the
requirement increases by four each day, more than four extra employees are necessary.
The same is true when the requirement increases by six each day. This might surprise you
at ﬁrst, but there is an intuitive reason: Each extra worker works only ﬁve days of the
week.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
K
J
I
H
G
F
E
D
C
B
A
Worker scheduling model
Range names used
Decision variables: number of employees starng their ﬁve-day shi on various days
Employees_available
=Model!$B$23:$H$23
Employees_required
=Model!$B$25:$H$25
0
1
$
B
$:4
$
B
$
!le
d
o
M
=
g
nitr
a
tS
_
s
e
e
y
olp
m
E
2
n
o
M
8
2
$
B
$
!le
d
o
M
=
s
e
e
y
olp
m
e
_la
t
o
T
3
e
u
T
3
d
e
W
7
u
h
T
0
ir
F
4
t
a
S
4
n
u
S
Employees required (original
a
rtx
E
1
1
6
1
4
1
9
1
5
1
3
1
7
1
)s
e
ula
v
required each day
0
Result of decisions: number of employees working on various days (along top) who started their shi on various days (along side)
Mon
Tue
Wed
Thu
Fri
Sat
Sun
2
2
2
2
2
n
o
M
3
3
3
3
3
e
u
T
3
3
3
3
3
d
e
W
7
7
7
7
7
u
h
T
0
0
0
0
0
ir
F
4
4
4
4
4
t
a
S
4
4
4
4
4
n
u
S
Constraint on worker availabilies
Employees
8
1
7
1
5
1
9
1
6
1
3
1
7
1
elb
alia
v
a
>=
>=
>=
>=
>=
>=
>=
Employees
1
1
6
1
4
1
9
1
5
1
3
1
7
1
d
e
riu
q
e
r
Objecve to maximize
Total
3
2
s
e
e
y
olp
m
e
Figure 4.14
Modiﬁed Worker Scheduling Model
3
4
5
6
7
8
9
10
11
12
13
A
B
C
D
E
F
G
H
I
J
Extra required (cell $K$12) values along side, output cell(s) along top
Total_employees
0
23
2
25
4
28
6
31
0
10
20
30
40
0
2
4
6
Extra required ($K$12)
Sensivity of Total_employees to Extra
required
Figure 4.15
Sensitivity to Number of Extra Workers Required per Day
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4.3 Worker Scheduling Models
151
P R O B L E M S
Skill-Building Problems
7.
Modify the post ofﬁce model so that employees are
paid $10 per hour on weekdays and $15 per hour on
weekends. Change the objective so that you now mini-
mize the weekly payroll. (You can assume that each
employee works eight hours per day.) Is the previous
optimal solution still optimal?
8.
How much inﬂuence can the worker requirements for
one, two, or three days have on the weekly schedule in
the post ofﬁce example? Explore this in the following
questions:
a. Let Monday’s requirements change from 17 to 25
in increments of 1. Use SolverTable to see how the
total number of employees changes.
b. Suppose the Monday and Tuesday requirements
can each, independently of one another, increase
from 1 to 8 in increments of 1. Use a two-way
SolverTable to see how the total number of
employees changes.
1. The postal employee scheduling example is called a static scheduling model because
we assume that the post ofﬁce faces the same situation each week. In reality, de-
mands change over time, workers take vacations in the summer, and so on, so the
post ofﬁce does not face the same situation each week. A dynamic scheduling model
(not covered here) is necessary for such problems.
2. In a weekly scheduling model for a supermarket or a fast-food restaurant, the number
of decision variables can grow quickly and optimization software such as Solver 
will have difﬁculty ﬁnding an optimal solution. In such cases, heuristic methods 
(essentially clever trial-and-error algorithms) have been used to ﬁnd good solutions
to the problem. Love and Hoey (1990) indicate how this was done for a particular
staff scheduling problem.
3. Our model can easily be expanded to handle part-time employees, the use of overtime,
and alternative objectives such as maximizing the number of weekend days off received
by employees. You are asked to explore such extensions in the problems.
■
MODELING ISSUES
Heuristic solutions are
often close to optimal,
but they are never
guaranteed to be
optimal.
Scheduling Employees in Quebec’s Liquor Stores
The SAQ is a public corporation of the Province of Quebec that is responsible for distribu-
ting and selling alcohol-based products through a large network of more than 400 stores
and warehouses. Every week, the SAQ has to schedule more than 3000 employees. Until
2002, the scheduling of these employees was done manually, incurring an annual expense
of about Can $1,300,000. Gendron (2005) developed an integer programming model that is
estimated to have saved the SAQ about Can $1,000,000 annually. The model has to deal
with complex union rules. For example, there is a rule that shifts of six hours or more can
be split between two employees, but it must be coupled with another rule that forces em-
ployees to take one-hour unpaid lunch or dinner breaks.
■
ADDITIONAL APPLICATIONS
Note that we did not use Solver’s sensitivity report here for two reasons. First, Solver
does not offer a sensitivity report for models with integer constraints. Second, even if the
integer constraints are deleted, Solver’s sensitivity report does not answer questions about
multiple input changes, as we have asked here. It can be used only for questions about one-
at-a-time changes to inputs, such as a change to a speciﬁc day’s worker requirement. In this
sense, SolverTable is a more ﬂexible tool.
■
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4.4 AGGREGATE PLANNING MODELS
In this section, the production planning model discussed in Example 3.3 of the previous
chapter is extended to include a situation where the number of workers available inﬂuences
the possible production levels. The workforce level is allowed to change each period
through the hiring and ﬁring of workers. Such models, where we determine workforce
levels and production schedules for a multiperiod time horizon, are called aggregate
planning models. There are many versions of aggregate planning models, depending on
the detailed assumptions we make. The following example is a fairly simple version that
you will have a chance to modify in the “Problems” section.
152
Chapter 4
Linear Programming Models
E X A M P L E
4.3 WORKER AND PRODUCTION PLANNING AT SURESTEP
D
uring the next four months the SureStep Company must meet (on time) the following
demands for pairs of shoes: 3000 in month 1; 5000 in month 2; 2000 in month 3; and
1000 in month 4. At the beginning of month 1, 500 pairs of shoes are on hand, and SureStep
has 100 workers. A worker is paid $1500 per month. Each worker can work up to 160 hours
a month before he or she receives overtime. A worker can work up to 20 hours of overtime
per month and is paid $13 per hour for overtime labor. It takes four hours of labor and $15
of raw material to produce a pair of shoes. At the beginning of each month, workers can be
hired or ﬁred. Each hired worker costs $1600, and each ﬁred worker costs $2000. At the
end of each month, a holding cost of $3 per pair of shoes left in inventory is incurred. Pro-
duction in a given month can be used to meet that month’s demand. SureStep wants to use
LP to determine its optimal production schedule and labor policy.
Objective
To develop an LP spreadsheet model that relates workforce and production de-
cisions to monthly costs, and to ﬁnd the minimum-cost solution that meets forecasted de-
mands on time and stays within limits on overtime hours and production capacity.
c. Suppose the Monday, Tuesday, and Wednesday
requirements each increase by the same amount,
where this increase can be from 1 to 8 in increments
of 1. Use a one-way SolverTable to investigate how
the total number of employees changes.
9.
In the post ofﬁce example, suppose that each full-time
employee works eight hours per day. Thus, Monday’s
requirement of 17 workers can be viewed as a require-
ment of 8(17)  136 hours. The post ofﬁce can meet
its daily labor requirements by using both full-time
and part-time employees. During each week, a full-
time employee works eight hours a day for ﬁve con-
secutive days, and a part-time employee works four
hours a day for ﬁve consecutive days. A full-time em-
ployee costs the post ofﬁce $15 per hour, whereas a
part-time employee (with reduced fringe beneﬁts)
costs the post ofﬁce only $10 per hour. Union require-
ments limit part-time labor to 25% of weekly labor re-
quirements.
a. Modify the model as necessary, and then use Solver
to minimize the post ofﬁce’s weekly labor costs.
b. Use SolverTable to determine how a change in
the part-time labor limitation (currently 25%)
inﬂuences the optimal solution.
Skill-Extending Problems
10. In the post ofﬁce example, suppose the employees want
more ﬂexibility in their schedules. They want to be al-
lowed to work ﬁve consecutive days followed by two
days off or to work three consecutive days followed by
a day off, followed by two consecutive days followed
by another day off. Modify the original model (with in-
teger constraints) to allow this ﬂexibility. Might this be
a good deal for management as well as labor? Explain.
11. Suppose the post ofﬁce has 25 full-time employees
and is not allowed to hire or ﬁre any of them.
Determine a schedule that maximizes the number of
weekend days off received by these employees.
12. In the post ofﬁce example, suppose that the post ofﬁce
can force employees to work one day of overtime each
week on the day immediately following this ﬁve-day
shift. For example, an employee whose regular shift is
Monday to Friday can also be required to work on
Saturday. Each employee is paid $100 a day for each
of the ﬁrst ﬁve days worked during a week and $124
for the overtime day (if any). Determine how the post
ofﬁce can minimize the cost of meeting its weekly
work requirements.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

WHERE DO THE NUMBERS COME FROM?
There are a number of required inputs for this type of problem. Some, including initial in-
ventory, holding costs, and demands, are similar to requirements for Example 3.3 in the
previous chapter, so we won’t discuss them again here. Others might be obtained as follows:
■
The data on the current number of workers, the regular hours per worker per month,
the regular hourly wage rates, and the overtime hourly rate, should be well known.
The maximum number of overtime hours per worker per month is probably either the
result of a policy decision by management or a clause in the workers’ contracts.
■
The costs for hiring and ﬁring a worker are not trivial. The hiring cost includes train-
ing costs and the cost of decreased productivity due to the fact that a new worker
must learn the job. The ﬁring cost includes severance costs and costs due to loss of
morale. Neither the hiring nor the ﬁring cost would be simple to estimate accurately,
but the human resources department should be able to estimate their values.
■
The unit production cost is a combination of two inputs: the raw material cost
per pair of shoes and the labor hours per pair of shoes. The raw material cost is the
going rate from the supplier(s). The labor per pair of shoes represents the “produc-
tion function”—the average labor required to produce a unit of the product. The
operations managers should be able to supply this number.
Solution
The variables and constraints for this aggregate planning model are listed in Table 4.5. As
you see, there are a lot of variables to keep track of. In fact, the most difﬁcult aspect of
modeling this problem is knowing which variables the company gets to choose—the
decision variables—and which variables are determined by these decisions. It should be
clear that the company gets to choose the number of workers to hire and ﬁre and the num-
ber of shoes to produce. Also, because management sets only an upper limit on overtime
hours, it gets to decide how many overtime hours to use within this limit. But once it de-
cides the values of these variables, everything else is determined. We will show how these
are determined through detailed cell formulas, but you should mentally go through the list
of “Other calculated variables” in the table and deduce how they are determined by the de-
cision variables. Also, you should convince yourself that the three constraints listed are the
ones, and the only ones, that are required.
4.4 Aggregate Planning Models
153
Table 4.5
Variables and Constraints for Aggregate Planning Model
Input variables
Initial inventory of shoes, initial number of workers,
number and wage rate of regular hours, maximum
number and wage rate of overtime hours, hiring and
ﬁring costs, data for unit production and holding costs,
forecasted demands
Decision variables (changing cells)
Monthly values for number of workers hired and ﬁred,
number of shoes produced, and overtime hours used
Objective cell
Total cost
Other calculated variables
Monthly values for workers on hand before and after
hiring/ﬁring, regular hours available, maximum overtime
hours available, total production hours available,
production capacity, inventory on hand after production,
ending inventory, and various costs
Constraints
Overtime labor hours used  Maximum overtime hours
allowed 
Production  Capacity 
Inventory on hand after production  Demand 
The key to this model
is choosing the correct
changing cells—the
decision variables that
determine all outputs.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

DEVELOPING THE SPREADSHEET MODEL
The spreadsheet model appears in Figure 4.16. (See the ﬁle Aggregate Planning 1.xlsx.)
It can be developed as follows.
1
Inputs and range names. Enter the input data and create the range names listed.
2
Production, hiring and ﬁring plan. Enter any trial values for the number of pairs of
shoes produced each month, the overtime hours used each month, the workers hired each
month, and the workers ﬁred each month. These four ranges, in rows 18, 19, 23, and 30,
comprise the changing cells.
3
Workers available each month. In cell B17 enter the initial number of workers
available with the formula
B5
Because the number of workers available at the beginning of any other month (before
hiring and ﬁring) is equal to the number of workers from the previous month, enter the
formula
B20
154
Chapter 4
Linear Programming Models
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
I
H
G
F
E
D
C
B
A
SureStep aggregate planning model
Input data
Range names used:
Inial inventory of
6
3
$
E
$:6
3
$
B
$
!le
d
o
M
=
d
n
a
m
e
d
_
d
e
ts
a
c
e
r
o
F
0
0
5
s
e
o
h
s
Inial number of
4
3
$
E
$:4
3
$
B
$
!le
d
o
M
=
n
oitc
u
d
o
r
p
_
r
e
tfa
_
y
r
o
t
n
e
v
nI
0
0
1
sr
e
k
r
o
w
Regular
5
2
$
E
$:5
2
$
B
$
!le
d
o
M
=
elb
alia
v
a
_
sr
u
o
h
_
r
o
b
al_
e
m
itr
e
v
o
_
m
u
m
ix
a
M
0
6
1
h
t
n
o
m
/r
e
k
r
o
w
/sr
u
o
h
Maximum overme
3
2
$
E
$:3
2
$
B
$
!le
d
o
M
=
d
e
s
u
_
sr
u
o
h
_
r
o
b
al_
e
m
itr
e
v
O
0
2
h
t
n
o
m
/r
e
k
r
o
w
/sr
u
o
h
Hiring
2
3
$
E
$:2
3
$
B
$
!le
d
o
M
=
ytic
a
p
a
c
_
n
oitc
u
d
o
r
P
0
0
6,1
$
r
e
k
r
o
w
/ts
o
c
Firing
0
3
$
E
$:0
3
$
B
$
!le
d
o
M
=
d
e
c
u
d
o
r
p
_
s
e
o
h
S
0
0
0,2
$
r
e
k
r
o
w
/ts
o
c
Regular
6
4
$
F
$
!le
d
o
M
=
ts
o
c
_la
t
o
T
0
0
5,1
$
h
t
n
o
m
/r
e
k
r
o
w
/s
e
g
a
w
Overme wage
9
1
$
E
$:9
1
$
B
$
!le
d
o
M
=
d
e
rif
_
sr
e
k
r
o
W
3
1
$
r
u
o
h
/
e
t
a
r
Labor hours/pair of
8
1
$
E
$:8
1
$
B
$
!le
d
o
M
=
d
e
rih
_
sr
e
k
r
o
W
4
s
e
o
h
s
Raw material cost/pair of
5
1
$
s
e
o
h
s
Holding cost/pair of shoes in inventory/month
$3
Worker plan
Month 1
Month 2
Month 3
Month 4
Workers from previous
0
5
3
9
4
9
0
0
1
h
t
n
o
m
Workers hired
0
0
0
0
Workers
0
3
4
1
6
d
e
rif
Workers available aer hiring and ﬁring
94
93
50
50
Regular-me hours
0
0
0
8
0
0
0
8
0
8
8
4
1
0
4
0
5
1
elb
alia
v
a
Overme labor hours
0
0
0
8
0
d
e
s
u
<=
<=
<=
<=
Maximum overme labor hours available
1880
1860
1000
1000
Total hours for
0
0
0
8
0
0
0
8
0
6
9
4
1
0
4
0
5
1
n
oitc
u
d
o
r
p
Producon plan
Month 1
Month 2
Month 3
Month 4
Shoes
0
0
0
1
0
0
0
2
0
4
7
3
0
6
7
3
d
e
c
u
d
o
r
p
Producon
0
0
0
2
0
0
0
2
0
4
7
3
0
6
7
3
ytic
a
p
a
c
Inventory aer
0
0
0
1
0
0
0
2
0
0
0
5
0
6
2
4
n
oitc
u
d
o
r
p
<=
<=
<=
<=
>=
>=
>=
>=
Forecasted
0
0
0
1
0
0
0
2
0
0
0
5
0
0
0
3
d
n
a
m
e
d
Ending
0
0
0
0
6
2
1
y
r
o
t
n
e
v
ni
Monetary outputs
Month 1
Month 2
Month 3
Month 4
Totals
Hiring
0
$
0
$
0
$
0
$
0
$
ts
o
c
Firing
0
0
0,0
0
1
$
0
$
0
0
0,6
8
$
0
0
0,2
$
0
0
0,2
1
$
ts
o
c
Regular-me
0
0
5,0
3
4
$
0
0
0,5
7
$
0
0
0,5
7
$
0
0
5,9
3
1
$
0
0
0,1
4
1
$
s
e
g
a
w
Overme
0
4
0,1
$
0
$
0
$
0
4
0,1
$
0
$
s
e
g
a
w
Raw material
0
0
5,7
5
1
$
0
0
0,5
1
$
0
0
0,0
3
$
0
0
1,6
5
$
0
0
4,6
5
$
ts
o
c
Holding
0
8
7,3
$
0
$
0
$
0
$
0
8
7,3
$
ts
o
c
0
2
8,2
9
6
$
0
0
0,0
9
$
0
0
0,1
9
1
$
0
4
6,8
9
1
$
0
8
1,3
1
2
$
sla
t
o
T
Objecve to minimize
Figure 4.16
Aggregate Planning Model
This is common in
multiperiod problems.
You usually have to
relate a beginning
value in one period to
an ending value from
the previous period.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

in cell C17 and copy it to the range D17:E17. Then in cell B20 calculate the number of
workers available in month 1 (after hiring and ﬁring) with the formula
B17+B18-B19
and copy this formula to the range C20:E20 for the other months.
4
Overtime capacity. Because each available worker can work up to 20 hours of over-
time in a month, enter the formula
$B$7*B20
in cell B25 and copy it to the range C25:E25.
5
Production capacity. Because each worker can work 160 regular-time hours per month,
calculate the regular-time hours available in month 1 in cell B22 with the formula
$B$6*B20
and copy it to the range C22:E22 for the other months. Then calculate the total hours avail-
able for production in cell B27 with the formula
SUM(B22:B23)
and copy it to the range C27:E27 for the other months. Finally, because it takes four hours
of labor to make a pair of shoes, calculate the production capacity in month 1 with the
formula
B27/$B$12
in cell B32 and copy it to the range C32:E32.
6
Inventory each month. Calculate the inventory after production in month 1 (which
is available to meet month 1 demand) with the formula
B4+B30
in cell B34. For any other month, the inventory after production is the previous month’s
ending inventory plus that month’s production, so enter the formula
B37+C30
in cell C34 and copy it to the range D34:E34. Then calculate the month 1 ending inventory
in cell B37 with the formula
B34-B36
and copy it to the range C37:E37.
7
Monthly costs. Calculate the various costs shown in rows 40 through 45 for month 1
by entering the formulas
$B$8*B18
$B$9*B19
$B$10*B20
$B$11*B23
$B$13*B30
$B$14*B37
in cells B40 through B45. Then copy the range B40:B45 to the range C40:E45 to calculate
these costs for the other months.
8
Totals. In row 46 and column F, use the SUM function to calculate cost totals, with
the value in F46 being the overall total cost to minimize.
4.4 Aggregate Planning Models
155
In Example 3.3 from
the previous chapter,
production capacities
were given inputs.
Now they are based 
on the size of the
workforce, which itself
is a decision variable.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Excel Tip: Calculating Row and Column Sums Quickly
A common oper ation in spreadsheet models is to calculate r ow and column sums for a
rectangular range, as we did for costs in step 8. There is a very quick way to do this. High-
light the row and column where the sums will go (remember to press the Ctrl key to high-
light nonadjacent ranges) and click on the summation () toolbar button. This enters all of
the sums automatically. It even calculates the “grand sum” in the corner (cell F46 in the
example) if you highlight this cell.
USING SOLVER
The Solver dialog box should be ﬁlled in as shown in Figure 4.17. Note that the changing
cells include four separate named ranges. To enter these in the dialog box, drag the four
ranges, keeping your ﬁnger on the Ctrl key. (Alternatively, you can drag a range, type a
comma, drag a second range, type another comma, and so on.) As usual, you should also
check the Non-Negative option and select the Simplex LP method before optimizing.
Note that there are integer constraints on the numbers hired and ﬁred. You could also
constrain the numbers of shoes produced to be integers. However, integer constraints typi-
cally require longer solution times. Therefore, it is often best to omit such constraints, 
especially when the optimal values are fairly large, such as the production quantities in this
model. If the solution then has noninteger values, you can usually round them to integers
for a solution that is at least close to the optimal integer solution.
156
Chapter 4
Linear Programming Models
Figure 4.17
Solver Dialog Box
for Aggregate 
Planning Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Discussion of the Solution
The optimal solution is given in Figure 4.16. Observe that SureStep should never hire any
workers, and it should ﬁre six workers in month 1, one worker in month 2, and 43 workers
in month 3. Eighty hours of overtime are used, but only in month 2. The company produces
over 3700 pairs of shoes during each of the ﬁrst two months, 2000 pairs in month 3, and
1000 pairs in month 4. A total cost of $692,820 is incurred. The model will recom-
mend overtime hours only when regular-time production capacity is exhausted. This is
because overtime labor is more expensive.
Again, you would probably not force the number of pairs of shoes produced
each month to be an integer. It makes little difference whether the company produces
3760 or 3761 pairs of shoes during a month, and forcing each month’s shoe produc-
tion to be an integer can greatly increase the time Solver needs to find an optimal
solution. On the other hand, it is somewhat more important to ensure that the number of
workers hired and fired each month is an integer, given the relatively small numbers
of workers involved.
Finally, if you want to ensure that Solver ﬁnds the optimal solution in a problem where
some or all of the changing cells must be integers, you should go into Options 
(in the Solver dialog box) and set the tolerance to zero. Otherwise, Solver might stop when
it ﬁnds a solution that is only close to optimal.
Sensitivity Analysis
There are many possible sensitivity analyses for this SureStep model. We illustrate one of
them with SolverTable, where we see how the overtime hours used and the total cost vary
with the overtime wage rate.4 The results appear in Figure 4.18. As you can see, when the
wage rate is really low, the company uses considerably more overtime hours, whereas when
it is sufﬁciently large, the company uses no overtime hours. It is not surprising that the
company uses much more overtime when the overtime rate is $7 or $9 per hour. The 
regular-time wage rate is $9.375 per hour ( 1500/160). Of course, the company would
never pay less per hour for overtime than for regular time.
4.4 Aggregate Planning Models
157
Because integer con-
straints make a model
more difficult to solve,
use them sparingly—
only when they are
really needed.
3
4
5
6
7
8
9
10
11
12
A
B
C
D
E
F
G
rate (cell $B$11) values along side, output cell(s) along top
Total_cost
$7
1620
1660
0
0 $684,755
$9
80
1760
0
0 $691,180
$11
0
80
0
0 $692,660
$13
0
80
0
0 $692,820
$15
0
80
0
0 $692,980
$17
0
80
0
0 $693,140
$19
0
0
0
0 $693,220
$21
0
0
0
0 $693,220
Figure 4.18
Sensitivity to Over-
time Wage Rate
4Solver’s sensitivity report isn’t even available here because of the integer constraints.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

158
Chapter 4
Linear Programming Models
The term backlogging
means that the cus-
tomer’s demand is 
met at a later date.
The term backordering
means the same thing.
5GRG stands for generalized reduced gradient. This is a technical term for the mathematical algorithm used. The
other algorithm available in Solver (starting with Excel 2010) is the Evolutionary algorithm. It can handle IF func-
tions, but we will not discuss this algorithm here. It is discussed in detail in Chapter 8.
The Rolling Planning Horiz
on Approach
In reality, an aggregate planning model is usually implemented via a rolling planning hori-
zon. To illustrate, we assume that SureStep works with a four-month planning horizon. To
implement the SureStep model in the rolling planning horizon context, we view the de-
mands as forecasts and solve a four-month model with these forecasts. However, the com-
pany would implement only the month 1 production and work scheduling recommenda-
tion. Thus (assuming that the numbers of workers hired and fired in a month must
be integers) the company would hire no workers, ﬁre six workers, and produce 3760 pairs
of shoes with regular-time labor in month 1. Next, the company would observe month 1’s
actual demand. Suppose it is 2950. Then SureStep would begin month 2 with 1310 
( 4260  2950) pairs of shoes and 94 workers. It would now enter 1310 in cell B4 and 94
in cell B5 (referring to Figure 4.16). Then it would replace the demands in the Demand
range with the updated forecasts for the next four months. Finally, SureStep would rerun
Solver and use the production levels and hiring and ﬁring recommendations in column B as
the production level and workforce policy for month 2.
Model with Backlogging Allowed
In many situations, backlogging of demand is allowed—that is, customer demand can be
met at a later date. We now show how to modify the SureStep model to include the option
of backlogging demand. We assume that at the end of each month a cost of $20 is incurred
for each unit of demand that remains unsatisﬁed at the end of the month. This is easily
modeled by allowing a month’s ending inventory to be negative. For example, if month 1’s
ending inventory is 10, a shortage cost of $200 (and no inventory holding cost) is in-
curred. To ensure that SureStep produces any shoes at all, we constrain the ending
inventory in month 4 to be nonnegative. This implies that all demand is eventually satisﬁed
by the end of the four-month planning horizon. We now need to modify the monthly cost
calculations to incorporate costs due to backlogging.
There are actually several modeling approaches to this backlogging problem. We show
the most natural approach in Figure 4.19. (See the ﬁle Aggregate Planning 2.xlsx .) To
begin, enter the per-unit monthly shortage cost in cell B15. (A new row was inserted for
this cost input.) Note in row 38 how the ending inventory in months 1 through 3 can be pos-
itive (leftovers) or negative (shortages). You can account correctly for the resulting costs
with IF functions in rows 46 and 47. For holding costs, enter the formula
IF(B380,$B$14*B38,0)
in cell B46 and copy it across. For shortage costs, enter the formula
IF(B380,$B$15*B38,0)
in cell B47 and copy it across. (The minus sign makes this a positive cost.)
Although these formulas accurately compute holding and shortage costs, the IF func-
tions make the objective cell a nonlinear function of the changing cells, and Solver’s GRG
Nonlinear method must be used, as indicated in Figure 4.20.5 (How do you know the model
is nonlinear? Although there is a mathematical reason, it is easier to try running Solver with
the Simplex LP method. Solver will then inform you that the model is nonlinear.)
We ran Solver with this setup from a variety of initial solutions in the changing
cells, and it always found the solution shown in Figure 4.19. It turns out that this is
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4.4 Aggregate Planning Models
159
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
I
H
G
F
E
D
C
B
A
SureStep aggregate planning model with backlogging: a nonsmooth model Solver might not handle correctly
Input data
Range names used:
Inial inventory of
7
3
$
E
$
!le
d
o
M
=
4
_
d
n
a
m
e
d
_
d
e
ts
a
c
e
r
o
F
0
0
5
s
e
o
h
s
Inial number of
5
3
$
E
$
!le
d
o
M
=
4
_
n
oitc
u
d
o
r
p
_
r
e
tfa
_
y
r
o
t
n
e
v
nI
0
0
1
sr
e
k
r
o
w
Regular
6
2
$
E
$:6
2
$
B
$
!le
d
o
M
=
elb
alia
v
a
_
sr
u
o
h
_
r
o
b
al_
e
m
itr
e
v
o
_
m
u
m
ix
a
M
0
6
1
h
t
n
o
m
/r
e
k
r
o
w
/sr
u
o
h
Maximum overme
4
2
$
E
$:4
2
$
B
$
!le
d
o
M
=
d
e
s
u
_
sr
u
o
h
_
r
o
b
al_
e
m
itr
e
v
O
0
2
h
t
n
o
m
/r
e
k
r
o
w
/sr
u
o
h
Hiring
3
3
$
E
$:3
3
$
B
$
!le
d
o
M
=
ytic
a
p
a
c
_
n
oitc
u
d
o
r
P
0
0
6,1
$
r
e
k
r
o
w
/ts
o
c
Firing
1
3
$
E
$:1
3
$
B
$
!le
d
o
M
=
d
e
c
u
d
o
r
p
_
s
e
o
h
S
0
0
0,2
$
r
e
k
r
o
w
/ts
o
c
Regular
8
4
$
F
$
!le
d
o
M
=
ts
o
c
_la
t
o
T
0
0
5,1
$
h
t
n
o
m
/r
e
k
r
o
w
/s
e
g
a
w
Overme wage
0
2
$
E
$:0
2
$
B
$
!le
d
o
M
=
d
e
rif
_
sr
e
k
r
o
W
3
1
$
r
u
o
h
/
e
t
a
r
Labor hours/pair of
9
1
$
E
$:9
1
$
B
$
!le
d
o
M
=
d
e
rih
_
sr
e
k
r
o
W
4
s
e
o
h
s
Raw material cost/pair of
5
1
$
s
e
o
h
s
Holding cost/pair of shoes in inventory/month
$3
Shortage cost/pair of
0
2
$
h
t
n
o
m
/s
e
o
h
s
Worker plan
Month 1
Month 2
Month 3
Month 4
Workers from previous
8
3
3
9
4
9
0
0
1
h
t
n
o
m
Workers hired
0
0
0
0
Workers
0
5
5
1
6
d
e
rif
Workers available aer hiring and
8
3
8
3
3
9
4
9
g
nirif
Regular-me hours
0
8
0
6
0
8
0
6
0
8
8
4
1
0
4
0
5
1
elb
alia
v
a
Overme labor hours used
0
0
0
0
<=
<=
<=
<=
Maximum overme labor hours available
1880
1860
760
760
Total hours for
0
8
0
6
0
8
0
6
0
8
8
4
1
0
4
0
5
1
n
oitc
u
d
o
r
p
Producon plan
Month 1
Month 2
Month 3
Month 4
Shoes
0
0
5
1
0
2
5
1
0
2
7
3
0
6
7
3
d
e
c
u
d
o
r
p
<=
<=
<=
<=
Producon
0
2
5
1
0
2
5
1
0
2
7
3
0
6
7
3
ytic
a
p
a
c
Inventory aer
0
0
0
1
0
0
5
1
0
8
9
4
0
6
2
4
n
oitc
u
d
o
r
p
>=
Forecasted
0
0
0
1
0
0
0
2
0
0
0
5
0
0
0
3
d
n
a
m
e
d
Ending
0
6
2
1
y
r
o
t
n
e
v
ni
-20
-500
0
Monetary outputs
Month 1
Month 2
Month 3
Month 4
Totals
Hiring
0
$
0
$
0
$
0
$
0
$
ts
o
c
Firing
0
0
0,4
2
1
$
0
$
0
0
0,0
1
1
$
0
0
0,2
$
0
0
0,2
1
$
ts
o
c
Regular-me
0
0
5,4
9
3
$
0
0
0,7
5
$
0
0
0,7
5
$
0
0
5,9
3
1
$
0
0
0,1
4
1
$
s
e
g
a
w
Overme
0
$
0
$
0
$
0
$
0
$
s
e
g
a
w
Raw material
0
0
5,7
5
1
$
0
0
5,2
2
$
0
0
8,2
2
$
0
0
8,5
5
$
0
0
4,6
5
$
ts
o
c
Holding
0
8
7,3
$
0
$
0
$
0
$
0
8
7,3
$
ts
o
c
Shortage
0
0
4,0
1
$
0
$
0
0
0,0
1
$
0
0
4
$
0
$
ts
o
c
0
8
1,0
9
6
$
0
0
5,9
7
$
0
0
8,9
9
1
$
0
0
7,7
9
1
$
0
8
1,3
1
2
$
sla
t
o
T
Objecve to minimize
Note that we use IF funcons in rows 46 and 47 to capture the
holding and shortage costs. These IF funcons make the model
nonlinear (and "nonsmooth"), and Solver can't handle these
funcons in a predictable manner. We just got lucky here! Try
changing the unit shortage cost in cell B15 to $40 and rerun
Solver. Then you won't be so lucky -- Solver will converge to a
soluon that is prey far from opmal.
Figure 4.19
Nonlinear Aggregate Planning Model Using IF Functions
Figure 4.20
Solver Dialog Box
for the GRG 
Nonlinear Method
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

160
Chapter 4
Linear Programming Models
Linearizing the Backlo
gging Model
Although this nonlinear model with IF functions is “natural,” the fact that it is not guaran-
teed to ﬁnd the optimal solution is disturbing. Fortunately, it is possible to handle shortages
with a linear model. The method is illustrated in Figure 4.21. (See the ﬁle Aggregate Plan-
ning 3.xlsx.) To develop this modiﬁed spreadsheet model, starting from the original model
in the Aggregate Planning 1.xlsx ﬁle, follow these steps:
1
Enter shortage cost. Insert a new row below row 14 and enter the shortage cost per
pair of shoes per month in cell B15.
2
Rows for amounts held and short. Insert ﬁve new rows (which will now be rows 38
through 42) between the Demand and Ending inventory rows. The range B39:E40 will be
changing cells. The Leftover range in row 39 contains the amounts left in inventory (if any),
whereas the Shortage range in row 40 contains the shortages (if any). Enter any values in
these ranges.
FUNDAMENTAL INSIGHT
Nonsmooth Functions and Solv
er
Excel’s Solv er, as w ell as most other commer
cial
optimization softwar e packages, has tr ouble with 
nonlinear functions that ar e not smooth. These non-
smooth functions typically have sharp edges or discon-
tinuities that make them difﬁcult to handle in optimiza-
tion models,
and (in Excel) the
y ar e typicall y
implemented with functions such as IF, MAX, MIN,
ABS, and a f ew others. There is nothing wrong with
using such functions to implement complex logic in
Excel optimization models. The only problem is that
Solver cannot handle models with these functions
predictably.This is not really the fault of Solver. Such
problems are inherently difﬁcult.
indeed the optimal solution, but we were lucky. When certain functions, including IF,
MIN, MAX, and ABS, are used to relate the objective cell to the changing cells, the
resulting model becomes not only nonlinear but nonsmooth. Essentially, nonsmooth
functions can have sharp edges or discontinuities. Solver’s GRG nonlinear algorithm
can handle “smooth” nonlinearities, as you will see in Chapter 7, but it has trouble with
nonsmooth functions. Sometimes it gets lucky, as it did here, and other times it finds a
nonoptimal solution that is not even close to the optimal solution. For example, we
changed the unit shortage cost from $20 to $40 and reran Solver. Starting from a solu-
tion where all changing cells contain zero, Solver stopped at a solution with total cost
$726,360, even though the optimal solution has total cost $692,820. In other words, we
weren’t so lucky this time.
The moral is that you should avoid these nonsmooth functions in optimization 
models if at all possible. If you do use them, as we have done here, you should run
Solver several times, starting from different initial solutions. There is still no guarantee
that you will get the optimal solution, but you will see more evidence of how Solver is
progressing. Alternatively, you can use Frontline Systems’s Evolutionary Solver, which
became available in Excel’s Solver in Excel 2010 and is discussed in detail in 
Chapter 8.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

3
Ending inventory (positive or negative). The key observation is the following. Let Lt
be the amount of leftover inventory at the end of month t, and let St be the amount short at
the end of month t. Then Lt  0 if St  0, and St  0 if Lt  0. So ending inventory can be
written as
It  Lt  St
For example, if I2  6, then L2  6 and S2  0, indicating that SureStep has six pairs of
shoes left over at the end of month 2. But if I2  3, then L2  0 and S2  3, indicating that
SureStep has a shortage of three pairs of shoes at the end of month 2. To incorporate this into
the model, enter the formula
=B39–B40
in cell B41 and copy it to the range C41:E41.
4
Monthly costs. Insert a new row (which will be row 52) below the holding cost row.
Modify the holding cost for month 1 by entering the formula 
=$B$14*B39 
4.4 Aggregate Planning Models
161
Figure 4.21
Linear Model of Backlogging
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
K
J
I
H
G
F
E
D
C
B
A
SureStep aggregate planning model with backlogging: a nonsmooth model Solver might not handle correctly
Input data
Range names used:
Inial inventory of 
3
4
$
E
$:3
4
$
B
$
!le
d
o
M
=
y
r
o
t
n
e
v
ni_
g
nid
n
E
0
0
5
s
e
o
h
s
Inial number of 
7
3
$
E
$
!le
d
o
M
=
4
_
d
n
a
m
e
d
_
d
e
ts
a
c
e
r
o
F
0
0
1
sr
e
k
r
o
w
Regular 
5
3
$
E
$
!le
d
o
M
=
4
_
n
oitc
u
d
o
r
p
_
r
e
tfa
_
y
r
o
t
n
e
v
nI
0
6
1
h
t
n
o
m
/r
e
k
r
o
w
/sr
u
o
h
Maximum overme 
6
2
$
E
$:6
2
$
B
$
!le
d
o
M
=
elb
alia
v
a
_
sr
u
o
h
_
r
o
b
al_
e
m
itr
e
v
o
_
m
u
m
ix
a
M
0
2
h
t
n
o
m
/r
e
k
r
o
w
/sr
u
o
h
Hiring 
4
2
$
E
$:4
2
$
B
$
!le
d
o
M
=
d
e
s
u
_
sr
u
o
h
_
r
o
b
al_
e
m
itr
e
v
O
0
0
6,1
$
r
e
k
r
o
w
/ts
o
c
Firing 
3
3
$
E
$:3
3
$
B
$
!le
d
o
M
=
ytic
a
p
a
c
_
n
oitc
u
d
o
r
P
0
0
0,2
$
r
e
k
r
o
w
/ts
o
c
Regular 
1
3
$
E
$:1
3
$
B
$
!le
d
o
M
=
d
e
c
u
d
o
r
p
_
s
e
o
h
S
0
0
5,1
$
h
t
n
o
m
/r
e
k
r
o
w
/s
e
g
a
w
Overme wage 
3
5
$
F
$
!le
d
o
M
=
ts
o
c
_la
t
o
T
3
1
$
r
u
o
h
/
e
t
a
r
Labor hours/pair of 
9
3
$
E
$:9
3
$
B
$
!le
d
o
M
=
r
e
v
o
_
tf
el_
stin
U
4
s
e
o
h
s
Raw material cost/pair of 
1
4
$
E
$:1
4
$
B
$
!le
d
o
M
=
tr
o
h
s
_
stin
u
_
s
u
ni
m
_
r
e
v
o
_
tf
el_
stin
U
5
1
$
s
e
o
h
s
Holding cost/pair of shoes in 
0
4
$
E
$:0
4
$
B
$
!le
d
o
M
=
tr
o
h
s
_
stin
U
3
$
h
t
n
o
m
/
y
r
o
t
n
e
v
ni
Shortage cost/pair of 
0
2
$
E
$:0
2
$
B
$
!le
d
o
M
=
d
e
rif
_
sr
e
k
r
o
W
0
2
$
h
t
n
o
m
/s
e
o
h
s
9
1
$
E
$:9
1
$
B
$
!le
d
o
M
=
d
e
rih
_
sr
e
k
r
o
W
Worker plan
Month 1
Month 2
Month 3
Month 4
Workers from previous 
8
3
3
9
4
9
0
0
1
h
t
n
o
m
Workers hired
0
0
0
0
Workers 
0
5
5
1
6
d
e
rif
Workers available aer hiring and ﬁring
94
93
38
38
Regular-me hours 
0
8
0
6
0
8
0
6
0
8
8
4
1
0
4
0
5
1
elb
alia
v
a
Overme labor hours used
0
0
0
0
<=
<=
<=
<=
Maximum overme labor hours available
1880
1860
760
760
Total hours for 
0
8
0
6
0
8
0
6
0
8
8
4
1
0
4
0
5
1
n
oitc
u
d
o
r
p
Producon plan
Month 1
Month 2
Month 3
Month 4
Shoes 
0
0
5
1
0
2
5
1
0
2
7
3
0
6
7
3
d
e
c
u
d
o
r
p
<=
<=
<=
<=
Producon 
0
2
5
1
0
2
5
1
0
2
7
3
0
6
7
3
ytic
a
p
a
c
Inventory aer 
0
0
0
1
0
0
5
1
0
8
9
4
0
6
2
4
n
oitc
u
d
o
r
p
>=
Forecasted 
0
0
0
1
0
0
0
2
0
0
0
5
0
0
0
3
d
n
a
m
e
d
0
0
0
0
6
2
1
r
e
v
o
tf
e
L
0
0
0
5
0
2
0
e
g
a
tr
o
h
S
Leover minus 
0
6
2
1
e
g
a
tr
o
h
s
-20
-500
0
=
=
=
=
Ending 
0
6
2
1
y
r
o
t
n
e
v
ni
-20
-500
0
Monetary outputs
Month 1
Month 2
Month 3
Month 4
Totals
Hiring 
0
$
0
$
0
$
0
$
0
$
ts
o
c
Firing 
0
0
0,4
2
1
$
0
$
0
0
0,0
1
1
$
0
0
0,2
$
0
0
0,2
1
$
ts
o
c
Regular-me 
0
0
5,4
9
3
$
0
0
0,7
5
$
0
0
0,7
5
$
0
0
5,9
3
1
$
0
0
0,1
4
1
$
s
e
g
a
w
Overme 
0
$
0
$
0
$
0
$
0
$
s
e
g
a
w
Raw material 
0
0
5,7
5
1
$
0
0
5,2
2
$
0
0
8,2
2
$
0
0
8,5
5
$
0
0
4,6
5
$
ts
o
c
Holding 
0
8
7,3
$
0
$
0
$
0
$
0
8
7,3
$
ts
o
c
Shortage 
0
0
4,0
1
$
0
$
0
0
0,0
1
$
0
0
4
$
0
$
ts
o
c
0
8
1,0
9
6
$
0
0
5,9
7
$
0
0
8,9
9
1
$
0
0
7,7
9
1
$
0
8
1,3
1
2
$
sla
t
o
T
Objecve to minimize
There is a somewhat unintuive trick to making this backlogging model linear, 
without using any IF funcons.  The trick is to create new changing cells in rows 39 
and 40 for the amounts leover and short.  The purpose of these is to enable 
simple linear formulas in rows 51 and 52 for the holding and shortage costs.  
However, because they are changing cells, they can freely vary.  To make sure they 
have "sensible" values, we need to constrain them. This is done by equang rows 
41 and 43.  Essenally, these two rows evaluate ending inventory in two diﬀerent 
ways: (1) as Leover minus Shortage (row 41) and (2) as Inventory aer producon 
minus Forecasted demand (row 43).  These two should be the same, so we add a 
constraint to force them to be equal.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

162
Chapter 4
Linear Programming Models
P R O B L E M S
Skill-Building Problems
13. Extend SureStep’s original no-backlogging aggregate
planning model from four to six months. Try several
different values for demands in months 5 and 6, 
and run Solver for each. Is your optimal solution 
for the ﬁrst four months the same as the one in the 
example?
14. SureStep is currently getting 160 regular-time hours
from each worker per month. This is actually
calculated from 8 hours per day times 20 days per
month. For this, they are paid $9.375 per hour
(1500160). Suppose workers can change their
contract so that they only have to work 7.5 hours per
day regular-time—everything above this becomes
overtime—and their regular-time wage rate increases
1.
Silver et al. (1998) recommend that when demand is seasonal, the planning horizon
should extend beyond the next seasonal peak.
2.
Beyond a certain point, the cost of using extra hours of overtime labor increases
because workers become less efﬁcient. We haven’t modeled this type of behavior, but
it would make the model nonlinear.
■
MODELING ISSUES
USING SOLVER FOR THE BACKLOG MODEL
The changes from the original Solver setup are as follows.
1
Extra changing cells. Add the Leftover and Shortage ranges as changing cells. This
allows Solver to adjust each month’s amount leftover and amount short to be consistent
with the desired ending inventory for the month.
2
Constraint on last month’
s in ventory. Change the constraints that were
previously listed as Inventory_after_production>=Forecasted_demand to Inventory_
after_ production_4>=Forecasted_demand_4. This allows months 1 through 3 to have
negative ending inventory, but it ensures that all demand is met by the end of month 4.
3
Logical constraint on ending in ventory. Add the constraint Leftover_minus_
shortage=Ending_inventory. If you study the model closely, you will notice that ending
inventory is calculated in two different ways (in rows 41 and 43). This constraint ensures
that both ways produce the same values.
4
Optimize. Make sure the Simplex LP method is selected, and click on Solve to obtain
the optimal solution shown in Figure 4.21.
Note that this solution is the same as the one in Figure 4.19 that was obtained with the “IF
function” model. So this time, Solver handled the IF function correctly, but it will not
always do so. Admittedly, the linearized version in Figure 4.21 involves a somewhat unin-
tuitive trick, but it does guarantee a linear model, which means that Solver will ﬁnd the 
optimal solution.
■
in cell B51. Calculate the shortage cost for month 1 in cell B52 with the formula
=$B$15*B40
Then copy the range B51:B52 to the range C51:E52 for the other months. Make sure the to-
tals in row 53 and column F are updated to include the shortage costs.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4.5 Blending Models
163
4.5 BLENDING MODELS
In many situations, various inputs must be blended together to produce desired outputs. In
many of these situations, linear programming can ﬁnd the optimal combination of outputs
as well as the mix of inputs that are used to produce the desired outputs. Some examples of
blending problems are given in Table 4.6.
to $10 per hour. They will still work 20 days per
month. Will this change the optimal no-backlogging
solution?
15. The current solution to SureStep’s no-backlogging
aggregate planning model requires a lot of ﬁring.
Run a one-way SolverTable with the ﬁring cost as the
input variable and the numbers ﬁred as the outputs.
Let the ﬁring cost increase from its current value to
double that value in increments of $400. Do high ﬁr-
ing costs eventually induce the company to ﬁre fewer
workers?
16. Suppose SureStep could begin a machinery upgrade
and training program to increase its worker
productivity. This program would result in the
following values of labor hours per pair of shoes over
the next four months: 4, 3.9, 3.8, and 3.8. How much
would this new program be worth to SureStep, at least
for this four-month planning horizon with no backlog-
ging? How might you evaluate the program’s worth
beyond the next four months?
Skill-Extending Problems
17. In the current no-backlogging problem, SureStep
doesn’t hire any workers and uses almost no overtime.
This is evidently because of low demand. Change the
demands to 6000, 8000, 5000, and 3000, and reopti-
mize. Is there now hiring and overtime? With this new
demand pattern, explore the trade-off between hiring
and overtime by running a two-way SolverTable.
As inputs, use the hiring cost per worker and the
maximum overtime hours allowed per worker per
month, varied as you see ﬁt. As outputs, use the total
number of workers hired over the four months and the
total number of overtime hours used over the four
months. Write up your results in a short memo to
SureStep management.
18. In the SureStep no-backlogging problem, change the
demands so that they become 6000, 8000, 5000, 3000.
Also, change the problem slightly so that newly hired
workers take six hours to produce a pair of shoes dur-
ing their ﬁrst month of employment. After that, they
take only four hours per pair of shoes. Modify the
model appropriately, and use Solver to ﬁnd the optimal
solution.
19. We saw that the natural way to model SureStep’s
backlogging model, with IF functions, leads to a
nonsmooth model that Solver has difﬁculty handling.
Another version of the problem is also difﬁcult 
for Solver. Suppose SureStep wants to meet all
demand on time (no backlogging), but it wants to
keep its employment level as constant across time 
as possible. To induce this, it charges a cost of $1000
each month on the absolute difference between the
beginning number of workers and the number after
hiring and ﬁring—that is, the absolute difference
between the values in rows 17 and 20 of the original
spreadsheet model. Implement this extra cost in the
model in the natural way, using the ABS function.
Using demands of 6000, 8000, 5000, and 3000, see
how well Solver does in trying to solve this non-
smooth model. Try several initial solutions, and see
whether Solver gets the same optimal solution from
each of them.
Table 4.6 Examples of Blending Problems
Inputs
Outputs
Meat, ﬁller, water
Different types of sausage
Various types of oil
Heating oil, gasolines, aviation fuels
Carbon, iron, molybdenum
Different types of steel
Different types of pulp
Different kinds of recycled paper
The following example illustrates how to model a typical blending problem in Excel.
Although this example is small relative to blending problems in real applications, it is still
probably too complex for you to guess the optimal solution.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

164
Chapter 4
Linear Programming Models
4.4 BLENDING AT CHANDLER OIL
C
handler Oil has 5000 barrels of crude oil 1 and 10,000 barrels of crude oil 2 available.
Chandler sells gasoline and heating oil. These products are produced by blending the
two crude oils together. Each barrel of crude oil 1 has a “quality level” of 10 and each barrel
of crude oil 2 has a quality level of 5.6 Gasoline must have an average quality level of at
least 8, whereas heating oil must have an average quality level of at least 6. Gasoline sells
for $75 per barrel, and heating oil sells for $60 per barrel. We assume that demand for heat-
ing oil and gasoline is unlimited, so that all of Chandler’s production can be sold. Chandler
wants to maximize its revenue from selling gasoline and heating oil.
Objective
To develop an LP spreadsheet model for ﬁnding the revenue-maximizing plan
that meets quality constraints and stays within limits on crude oil availabilities.
WHERE DO THE NUMBERS COME FROM?
Most of the inputs for this problem should be easy to obtain.
■
The selling prices for outputs are dictated by market pressures.
■
The availabilities of inputs are based on crude supplies from the suppliers.
■
The quality levels of crude oils are known from chemical analysis, whereas the 
required quality levels for outputs are speciﬁed by Chandler, probably in response to
competitive or regulatory pressures.
Solution
The variables and constraints required for this blending model are listed in Table 4.7. The
key is the selection of the appropriate decision variables. Many students, when asked what
decision variables should be used, specify the amounts of the two crude oils used and the
amounts of the two products produced. However, this is not enough. The problem is that
this information doesn’t tell Chandler how to make the outputs from the inputs. The com-
pany instead requires a blending plan: how much of each input to use in the production of
a barrel of each output. Once you understand that this blending plan is the basic decision,
all other output variables follow in a straightforward manner.
6To avoid being overly technical, we use the generic term quality level. In real oil blending, qualities of interest
might be octane rating, viscosity, and others.
In typical blending
problems, the correct
decision variables are
the amounts of each
input blended into
each output.
Table 4.7
Variables and Constraints for Blending Model
Input variables
Unit selling prices, availabilities of inputs, quality levels 
of inputs, required quality levels of outputs
Decision variables (changing cells)
Barrels of each input used to produce each output
Objective cell
Revenue from selling gasoline and heating oil
Other calculated variables
Barrels of inputs used, barrels of outputs produced (and 
sold), quality obtained and quality required for outputs
Constraints
Barrels of inputs used
Barrels available
Quality of outputs obtained
Quality required
Ú
…
A secondary, but very important, issue in typical blending models is how to implement
the quality constraints. (The constraints here are in terms of quality. In other blending 
E X A M P L E
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4.5 Blending Models
165
problems they are often expressed in terms of percentages of some ingredient(s). For
example, a typical quality constraint might be that some output can contain no more than
2% sulfur.) When we explain how to develop the spreadsheet model, we will discuss the
preferred way to implement quality constraints.
DEVELOPING THE SPREADSHEET MODEL
The spreadsheet model for this problem appears in Figure 4.22. (See the ﬁle Blending
Oil.xlsx.) To set it up, proceed as follows.
1
Inputs and range names. Enter the unit selling prices, quality levels for inputs, re-
quired quality levels for outputs, and availabilities of inputs in the blue cells. Then name
the ranges as indicated.
2
Inputs blended into each output.As discussed, the quantities Chandler must specify
are the barrels of each input used to produce each output. Enter any trial values for these
quantities in the Blending_plan range. For example, the value in cell B16 is the amount of
crude oil 1 used to make gasoline and the value in cell C16 is the amount of crude oil 1 used
to make heating oil. The Blending_plan range contains the changing cells.
3
Inputs used and outputs sold. Calculate the row sums (in column D) and column
sums (in row 18) of the Blending_plan range. There is a quick way to do this. Highlight
both the row and column where the sums will go (highlight one, then hold down the Ctrl
key and highlight the other), and click on the Summation () button on the Home ribbon.
This creates SUM formulas in each highlighted cell.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
A
B
C
D
E
F
G
H
Chandler oil blending model
Range names used
Barrels_available
=Model!$F$16:$F$17
Monetary inputs
Gasolin
Heang
Heang
Heang
Heang
e
 
8
1
$
C
$:8
1
$
B
$
!le
d
o
M
=
dlo
s
_
sle
rr
a
B
lio
Selling 
7
1
$
D
$:6
1
$
D
$
!le
d
o
M
=
d
e
s
u
_
sle
rr
a
B
0
6
$
5
7
$
le
rr
a
b
/
e
cir
p
Blending_plan
=Model!$B$16:$C$17
Quality level per barrel of crudes
Quality_points_obtained
=Model!$B$22:$C$22
Crude oil 
2
$
C
$:4
2
$
B
$
!le
d
o
M
=
d
e
riu
q
e
r
_
st
nio
p
_
ytila
u
Q
0
1
1
4
Crude oil 
7
2
$
B
$
!le
d
o
M
=
e
u
n
e
v
e
R
5
2
Required quality level per barrel of product
Gasoline
 oil
8
6
Blending plan (barrels of crudes in each product)
Gasoline
 oil
Barrels 
sle
rr
a
B
d
e
s
u
 available
Crude oil 
0
0
0
5
=
<
0
0
0
5
0
0
0
2
0
0
0
3
1
Crude oil 
0
0
0
0
1
=
<
0
0
0
0
1
0
0
0
8
0
0
0
2
2
Barrels 
0
0
0
0
1
0
0
0
5
dlo
s
Constraints on quality
Gasoline
 oil
Quality points obtained
40000
60000
>=
>=
Quality points required
40000
60000
 to maximize
Objecve
0
0,5
7
9
$
e
u
n
e
v
e
R
0
Figure 4.22
Oil Blending Model
From here on, the
solutions shown are
optimal. However,
remember that you 
can start with any
solution. It doesn’t 
even have to be
feasible.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

166
Chapter 4
Linear Programming Models
4
Quality achieved. Keep track of the quality level of gasoline and heating oil in the
Quality_points_obtained range as follows. Begin by calculating for each output the num-
ber of quality points (QP) in the inputs used to produce this output:
QP in gasoline  10 * Oil 1 in gasoline  5 * Oil 2 in gasoline
QP in heating oil  10 * Oil 1 in heating oil  5 * Oil 2 in heating oil
The gasoline quality constraint is then
QP in gasoline 
8 * Gasoline sold
(4.1)
Similarly, the heating oil quality constraint is
QP in heating oil 
6 * Heating oil sold
(4.2)
To implement Inequalities (4.1) and (4.2), calculate the QP for gasoline in cell B22 with the
formula
SUMPRODUCT(B16:B17, $B$7:$B$8)
and copy this formula to cell C22 to generate the QP for heating oil.
5
Quality required. Calculate the required quality points for gasoline and heating oil
in cells B24 and C24. Speciﬁcally, determine the required quality points for gasoline in cell
B24 with the formula
B12*B18
and copy this formula to cell C24 for heating oil.
6
Revenue. Calculate the total revenue in cell B27 with the formula
SUMPRODUCT(B4:C4,B18:C18)
USING SOLVER
To solve Chandler’s problem with Solver, ﬁll out the main Solver dialog box as shown in
Figure 4.23. As usual, check the Non-Negative option and specify the Simplex LP method
before optimizing. You should obtain the optimal solution shown in Figure 4.22.
Discussion of the Solution
The optimal solution implies that Chandler should make 5000 barrels of gasoline with
3000 barrels of crude oil 1 and 2000 barrels of crude oil 2. The company should also make
10,000 barrels of heating oil with 2000 barrels of crude oil 1 and 8000 barrels of crude oil
2. With this blend, Chandler will obtain a revenue of $975,000. As stated previously, this
problem is sufﬁciently complex to defy intuition. Clearly, gasoline is more proﬁtable per
barrel than heating oil, but given the crude availability and the quality constraints, it turns
out that Chandler should sell twice as much heating oil as gasoline. This would have been
difﬁcult to guess ahead of time.
Sensitivity Analysis
We perform two typical sensitivity analyses on this blending model. In each, we see
how revenue and the amounts of the outputs produced (and sold) vary. In the first analy-
sis, we use the unit selling price of gasoline as the input and let it vary from $50 to 
$90 in increments of $5. The SolverTable results appear in Figure 4.24. Two things are
Ú
Ú
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4.5 Blending Models
167
Figure 4.23
Solver Dialog Box
for Blending Model
1
2
3
A
B
C
D
E
F
G
Oneway analysis for Solver model in Model worksheet
Selling price gasoline (cell $B$4) values along side, output cell(s) along top
_sold_1
_sold_2
e
e
4
5
6
7
8
Barrels_
Barrels_
Revenue
Increase
$50
0
15000
$900,000
$55
0
15000
$900,000
$0
$60
5000
10000
$900,000
$0
$65
5000
10000
$925,000
$25,000
9
10
11
12
13
$70
5000
10000
$950,000
$25,000
$75
5000
10000
$975,000
$25,000
$80
5000
10000 $1,000,000
$25,000
$85
5000
10000 $1,025,000
$25,000
$90
5000
10000 $1,050,000
$25,000
Figure 4.24
Sensitivity to the
Selling Price of
Gasoline
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

168
Chapter 4
Linear Programming Models
1
2
3
A
B
C
D
E
F
G
Oneway analysis for Solver model in Model worksheet
Barrels available crude 1 (cell $F$16) values along side, output cell(s) along top
_sold_1
_sold_2
e
e
4
5
6
7
8
Barrels_
Barrels_
Revenue
Increase
9
10
11
12
13
14
15
12000
19000
3000 $1 605 000
$90 000
15
16
17
18
19
20
21
12000
19000
3000 $1,605,000
$90,000
22
23
2000
0
10000
$600,000
3000
1000
12000
$795,000
$195,000
4000
3000
11000
$885,000
$90,000
5000
5000
10000
$975,000
$90,000
6000
7000
9000 $1,065,000
$90,000
7000
9000
8000 $1,155,000
$90,000
8000
11000
7000 $1,245,000
$90,000
9000
13000
6000 $1,335,000
$90,000
10000
15000
5000 $1,425,000
$90,000
11000
17000
4000 $1,515,000
$90,000
13000
21000
2000 $1,695,000
$90,000
14000
23000
1000 $1,785,000
$90,000
15000
25000
0 $1,875,000
$90,000
16000
26000
0 $1,950,000
$75,000
17000
27000
0 $2,025,000
$75,000
18000
28000
0 $2,100,000
$75,000
19000
29000
0 $2,175,000
$75,000
20000
30000
0 $2,250,000
$75,000
Figure 4.25
Sensitivity to the
Availability of
Crude 1
of interest. First, as the price of gasoline increases from $55 to $65, Chandler starts pro-
ducing gasoline and less heating oil, exactly as you would expect. Second, the revenue
can only increase or stay the same, as the changes in column E (calculated manually) 
indicate.
In the second sensitivity analysis, we vary the availability of crude 1 from 2000
barrels to 20,000 barrels in increments of 1000 barrels. The resulting SolverTable out-
put appears in Figure 4.25. These results make sense if you analyze them carefully.
First, the revenue increases, but at a decreasing rate, as more crude 1 is available. This
is a common occurrence in LP models. As more of a resource is made available, rev-
enue can only increase or remain the same, but each extra unit of the resource pro-
duces less (or at least no more) revenue than the previous unit. Second, the amount of
gasoline produced increases, whereas the amount of heating oil produced decreases.
Here’s why: Crude 1 has a higher quality than crude 2, and gasoline requires higher
quality. Gasoline also sells for a higher price. Therefore, as more crude 1 is available,
Chandler can produce more gasoline, receive more revenue, and still meet quality
standards.
Could these sensitivity questions also be answered with Solver’s sensitivity report,
shown in Figure 4.26? Consider the sensitivity to the change in the price of gasoline. The
ﬁrst and third rows of the top table in this report are for sensitivity to the objective coefﬁ-
cients of decision variables involving gasoline. The problem is that when the price of gaso-
line changes, both of these coefﬁcients change. The reason is that the objective includes the
sum of these two decision variables, multiplied by the unit price of gasoline. However,
Solver’s sensitivity report is valid only for one-at-a-time coefﬁcient changes. Therefore, it
cannot answer our question.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4.5 Blending Models
169
Heang
Heang
Heang
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
A
B
C
D
E
F
G
H
Adjustable Cells
Final
Reduce
Objecve
d
Allowable
Allowable
Cell
Name
Value
Cost
Coeﬃcient
Increase
Decrease
$B$16 Crude oil 1 Gasoline
3000
0
75
175
25
$C$16 Crude oil 1 
 oil
2000
0
60
25
175
$B$17 Crude oil 2 Gasoline
2000
0
75
262.5
18.75
$C$17 Crude oil 2 
 oil
8000
0
60
18.75
43.75
Constraints
Final
Shadow
Constraint
Allowable
Allowable
Cell
Name
Value
Price
R.H. Side
Increase
Decrease
$D$16 Crude oil 1 Barrels used
5000
90
5000
10000
2500
$D$17 Crude oil 2 Barrels used
10000
53
10000
10000 6666.666667
$B$22 Quality points obtained Gasoline
40000
-7
0
5000
20000
$C$22 Quality points obtained 
 oil
60000
-7
0
10000 6666.666667
Figure 4.26
Sensitivity Report for Blending Model
In contrast, the first row of the bottom table in Figure 4.26 complements the
SolverTable sensitivity analysis on the availability of crude 1. It shows that if the availabil-
ity increases by no more than 10,000 barrels or decreases by no more than 2500 barrels, the
shadow price remains $90 per barrel—that is, the same $90,000 increase in proﬁt per 1000
barrels in Figure 4.25. Beyond that range, the sensitivity report indicates only that the
shadow price will change. The SolverTable results indicate how it changes. For example,
when crude 1 availability increases beyond 15,000 barrels, the SolverTable results indicate
that the shadow price decreases to $75 per barrel.
A Caution About Blending Constraints
Before concluding this example, we discuss why the model is linear. The key is the imple-
mentation of the quality constraints, shown in Inequalities (4.1) and (4.2). To keep a model
linear, each side of an inequality constraint must be a constant, the product of a constant
and a variable, or a sum of such products. If the quality constraints are implemented as in
Inequalities (4.1) and (4.2), the constraints are indeed linear. However, it is arguably more
natural to rewrite this type of constraint by dividing through by the amount sold. For ex-
ample, the modiﬁed gasoline constraint becomes
(4.3)
Although this form of the constraint is perfectly valid—and is possibly more natural to
many people—it suffers from two drawbacks. First, it makes the model nonlinear. This is
because the left side is no longer a sum of products; it involves a quotient. We prefer linear
models whenever possible. Second, suppose it turns out that Chandler’s optimal solution
calls for no gasoline at all. Then Inequality (4.3) includes division by zero, and this causes
an error in Excel. Because of these two drawbacks, it is best to “clear denominators” in all
such blending constraints.
■
QP in gasoline
Gasoline sold Ú 8
Blending models
usually have various
quality constraints,
often expressed as
required percentages
of various ingredients.
To keep these models
linear (and avoid
dividing by zero), it is
important to clear
denominators.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

170
Chapter 4
Linear Programming Models
FUNDAMENTAL INSIGHT
Clearing Denominators
Some constraints, particularly those that arise in
blending models, are most naturall y expressed in
terms of ratios. For example, the percentage of sulfur
in a product is the ratio (amount of sulfur in product)/
(total amount of product), which could then be con-
strained to be less than or equal to 6%, say. This is a
perfectly valid way to expr ess the constraint, but it
has the undesirable eff ect of making the model non-
linear.The ﬁx is simple.To make the model linear, mul-
tiply through by the denominator of the ratio.This has
the added beneﬁt of ensuring that ther e division b y
zero will not occur.
P R O B L E M S
Skill-Building Problems
20. Use SolverTable in Chandler’s blending model to see
whether, by increasing the selling price of gasoline,
you can get an optimal solution that produces only
gasoline, no heating oil. Then use SolverTable again to
see whether, by increasing the selling price of heating
oil, you can get an optimal solution that produces only
heating oil, no gasoline.
21. Use SolverTable in Chandler’s blending model to ﬁnd
the shadow price of crude oil 1—that is, the amount
Chandler would be willing to spend to acquire more
crude oil 1. Does this shadow price change as
Chandler keeps getting more of crude oil 1? Answer
the same questions for crude oil 2.
22. How sensitive is the optimal solution (barrels of each
output sold and proﬁt) to the required quality points?
In reality, a company using a blending model would run the model periodically (each day,
say) and set production on the basis of the current inventory of inputs and the current fore-
casts of demands and prices. Then the forecasts and the input levels would be updated, and
the model would be run again to determine the next day’s production.
■
MODELING ISSUES
Blending at Texaco
Texaco, in DeWitt et al. (1989), uses a nonlinear programming model (OMEGA) to plan
and schedule its blending applications. Texaco’s model is nonlinear because blend volatil-
ities and octanes are nonlinear functions of the amount of each input used to produce a par-
ticular gasoline. 
Blending in the Oil Industry
Many oil companies use LP to optimize their reﬁnery operations. Magoulas and Marinos-
Kouris (1988) discuss one such blending model that has been used to maximize a reﬁnery’s
proﬁt.
■
ADDITIONAL APPLICATIONS
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4.6 Production Process Models
171
Answer this by running a two-way SolverTable with
these three outputs. You can choose the values of the
two inputs to vary.
23. In Chandler’s blending model, suppose a chemical
ingredient called CI is needed by both gasoline and
heating oil. At least 3% of every barrel of gasoline
must be CI, and at least 5% of every barrel of heating
oil must be CI. Suppose that 4% of all crude oil 1
is CI, and 6% of all crude oil 2 is CI. Modify the
model to incorporate the constraints on CI, and then
optimize. Don’t forget to clear denominators.
24. In the current blending model, a barrel of any input re-
sults in a barrel of output. However, in a real blending
problem, there can be losses. Suppose a barrel of input
results in only a fraction of a barrel of output. Speciﬁ-
cally, each barrel of either crude oil used for gasoline
results in only 0.95 barrel of gasoline, and each barrel
of either crude used for heating oil results in only 0.97
barrel of heating oil. Modify the model to incorporate
these losses, and reoptimize.
Skill-Extending Problem
25. We warned you about clearing denominators in the
quality constraints. This problem illustrates what can
happen if you don’t do so.
a. Implement the quality constraints as indicated in
Inequality (4.3) of the text. Then run Solver with
the Simplex LP method. What happens? What if
you use the GRG Nonlinear method instead?
b. Repeat part a, but increase the selling price of
heating oil to $120 per barrel. What happens now?
Does it matter whether you use the Simplex LP
method, as opposed to the GRG Nonlinear
method? Why?
4.6 PRODUCTION PROCESS MODELS
LP is often used to determine the optimal method of operating a production process. In
particular, many oil reﬁneries use LP to manage their production operations. The models
are often characterized by the fact that some of the products produced are inputs to the pro-
duction of other products. The following example is typical.
E X A M P L E
4.5 DRUG PRODUCTION AT REPCO
R
epco produces three drugs, A, B, and C, and can sell these drugs in unlimited quanti-
ties at unit prices $8, $70, and $100, respectively. Producing a unit of drug A requires
one hour of labor. Producing a unit of drug B requires two hours of labor and two units of
drug A. Producing one unit of drug C requires three hours of labor and one unit of drug B.
Any drug A that is used to produce drug B cannot be sold separately, and any drug B that
is used to produce drug C cannot be sold separately. A total of 4000 hours of labor are
available. Repco wants to use LP to maximize its sales revenue.
Objective
To develop an LP spreadsheet model that relates production decisions to
amounts required for production and amounts available for selling, and to use Solver to
maximize sales revenue, subject to limited labor hours.
WHERE DO THE NUMBERSCOME FROM?
The inputs for this problem should be easy to obtain:
■
The company sets its selling prices, which are probably dictated by the market.
■
The available labor hours are based on the size of the current workforce assigned to
production of these drugs. These might be ﬂexible quantities, depending on whether
workers could be diverted from other duties to work on these drugs and whether new
labor could be hired.
■
The labor and drug usage inputs for producing the various drugs are probably well
known, based on productivity levels and chemical requirements.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Solution
The variables and constraints required to model this problem are listed in Table 4.8. The
key to the model is understanding which variables can be chosen—the decision variables—
and which variables are determined by this choice. It is probably clear that Repco must de-
cide how much of each drug to produce. However, it might not be clear why the amounts
used for production of other drugs and the amounts sold are not decision variables. The
idea is that as soon as Repco decides to produce, say, 10 units of drug B, it automatically
knows that it must produce at least 20 units of drug A. In fact, it cannot decide to produce
just any quantities of the three drugs. For example, it can’t produce 10 units of drug B and
only 15 units of drug A. Therefore, the drugs required for producing other drugs put auto-
matic constraints on the production quantities. Note that any drugs not used in production
of other drugs are sold.
172
Chapter 4
Linear Programming Models
Table 4.8 Variables and Constraints for the Production Process Model
Input variables
Labor inputs to drug production, drugs required for
production of other drugs, selling prices of drugs, labor
hours available
Decision variables (changing cells)
Units of drugs to produce
Objective (target cell)
Revenue from sales
Other calculated variables
Units of drugs used to make other drugs, units of drugs left
over to sell
Constraints
Drugs produced  Drugs required for production of other
drugs 
Labor hours used  Labor hours available
The decision
variables should be
the smallest set of
variables that deter-
mines everything else.
After the company
decides how much of
each drug to produce,
there is really nothing
left to decide.
DEVELOPINGTHE SPREADSHEETMODEL
The key to the spreadsheet model is that everything produced is used in some way. Either
it is used as an input to the production of some other drug, or it is sold. Therefore, the fol-
lowing balance equation holds for each product:
Amount produced  Amount used to produce other drugs  Amount sold
(4.4)
This balance equation can be implemented in three steps:
1
Specify the amounts produced in changing cells.
2
Calculate the amounts used to produce other drugs based on the way the production
process works.
3
Calculate the amounts sold from Equation (4.4) by subtraction. Then impose a con-
straint that Equation (4.4) must be satisﬁed.
The spreadsheet model for Repco appears in Figure 4.27. (See the ﬁle Production
Process.xlsx.) To proceed, carry out the following steps:
1
Inputs and range names. Enter the inputs in the shaded blue ranges. For example,
the 2 in cell C7 indicates that two units of drug A are needed to produce each unit of
drug B, and the 0s in this range indicate which drugs are not needed to produce other
drugs. (Note, however, the 0 in cell D7, which could be misleading. Drug A is required
to make drug B, and drug B is required to make drug C. Therefore, drug A is required
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4.6 Production Process Models
173
indirectly to make drug C. However, this indirect effect is accounted for by the values in
cells C7 and D8, so the 0 in cell D7 is appropriate.) Then create the range names 
indicated.
2
Units produced. Enter any trial values for the number of units produced in the
Units_produced range. This range contains the only changing cells.
3
Units used to make other products. In the range G16:I18, calculate the total number
of units of each product that are used to produce other products. Begin by calculating the
amount of A used to produce A in cell G16 with the formula
=B7*B$16
and copy this formula to the range G16:I18 for the other combinations of products. For
example, in the solution shown, 10 units of drug B are produced, so 2000 units of drug A
are required, as calculated in cell H16. Then calculate the row totals in column J with the
SUM function. Then it is convenient to transfer these sums in column J to the B18:D18
range. There are two ways to do this, that is, to make a column into a row or vice versa.
The easiest way is to copy the range J16:J18, then select cell B18, select the Edit/Paste
Special menu item, and check the Transpose option. Unfortunately, this method doesn’t
copy formulas correctly. The second way uses Excel’s TRANSPOSE function. To copy
the formulas correctly, highlight the B18:D18 range, type the formula
=TRANSPOSE(J16:J18)
and press Ctrl+Shift+Enter (all three keys at once).
Excel Tool: Paste Special Transpose
To copy a row range to a column range, copy the row range, select the ﬁrst cell in the col-
umn range, and select Transpose from the Paste dropdown menu on the Home ribbon. The
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
A
B
C
D
E
F
G
H
I
J
Repco producon process 
e
g
n
a
R
le
d
o
m
 names used:
Hours_available
=Model!$D$23
Inputs used (along side) to make one unit of product (along top)
Hours_used
=Model!$B$23
Drug A
Drug B
Drug C
Revenue_from_sales
=Model!$B$25
Labor 
6
1
$
D
$:6
1
$
B
$
!le
d
o
M
=
d
e
c
u
d
o
r
p
_
stin
U
3
2
1
sr
u
o
h
Units_sold
=Model!$B$19:$D$19
Drug 
8
1
$
D
$:8
1
$
B
$
!le
d
o
M
=
n
oitc
u
d
o
r
p
_
ni_
d
e
s
u
_
stin
U
0
2
0
A
Drug 
1
0
0
B
Drug 
0
0
0
C
Unit selling prices
Drug A
Drug B
Drug C
$8
$70
$100
Producon and sales 
stin
U
n
alp
 of products used (along side) to make products (along top)
Drug A
Drug B
Drug 
g
u
r
D
C
 A
Drug B
Drug C Total used
Units 
g
u
r
D
0
0
0
0
1
0
0
0
2
d
e
c
u
d
o
r
p
 A
0
2000
0
2000
g
u
r
D
=
>
=
>
=
>
 B
0
0
0
0
Units used in 
g
u
r
D
0
0
0
0
0
2
n
oitc
u
d
o
r
p
 C
0
0
0
0
Units 
0
0
0
0
1
0
dlo
s
Labor hour constraint
Hours used
Hours available
4000
<=
4000
Revenue from sales
$70,000
Objecve to maximize
Figure 4.27
Repco Production Process Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

174
Chapter 4
Linear Programming Models
same method can be used to copy a column r ange to a row range. However, this method
doesn’t copy formulas correctly.
Excel Function: TRANSPOSE and Other Array Functions
The TRANSPOSE function is useful for linking a row to a column or vice versa. It has the
syntax =TRANSPOSE(Range). To implement it, highlight the row or column range where
the results will go, type the formula, and pr ess Ctrl+Shift+Enter. This function is one of
several array functions in Excel, which means that it ﬁlls an entire range, not just a single
cell, all at once. All array formulas require you to highlight the entire range where the re-
sults will go, type the formula, and then press Ctrl+Shift+Enter. After you do this, you will
notice curly brackets around the formula in the Formula Bar. You should not actually type
these curly brackets. They simply indicate the presence of an array function. 
4
Units sold. Referring to Equation (4.4), determine the units sold of each drug by sub-
traction. Speciﬁcally, enter the formula
=B16-B18
in cell B19 and copy it to the range C19:D19.
5
Labor hours used. Calculate the total number of labor hours used in cell B23 with the
formula
=SUMPRODUCT(B5:D5,Units_produced)
6
Total revenue. Calculate Repco’s revenue from sales in cell B25 with the formula
=SUMPRODUCT(B12:D12,Units_sold)
USING SOLVER
To use Solver to maximize Repco’s revenue, fill in the Solver dialog box as shown in
Figure 4.28. As usual, check the Non-Negative option and select the Simplex LP method
before optimizing. Note that the drugs produced are constrained to be greater than or equal
to the drugs used in production of other drugs. An equivalent alternative is to constrain the
units sold to be nonnegative.
Figure 4.28
Solver Dialog Box
for Repco Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4.6 Production Process Models
175
Discussion of the Solution
The optimal solution in Figure 4.27 indicates that Repco obtains a revenue of $70,000 by
producing 2000 units of drug A, all of which are used to produce 1000 units of drug B. All
units of drug B produced are sold. Even though drug C has the highest selling price, Repco
produces none of drug C, evidently because of the large labor requirement for drug C.
Sensitivity Anal
ysis
Drug C is not produced at all, even though its selling price is by far the highest. How high
would this selling price have to be to induce Repco to produce drug C? You can use
SolverTable to answer this, using drug C selling price as the input variable, letting it vary from
$100 to $200 in increments of $10, and keeping track of the total revenue, the units produced
of each drug, and the units used (row 18) of each drug. The results are shown in Figure 4.29.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
A
B
C
D
E
F
G
H
Oneway analysis for Solver model in Model worksheet
Drug C selling price (cell $D$12) values along side, output cell(s) along top
Units_produced_1
Units_produced_2
Units_produced_3
Units_used_in_producon_1
Units_used_in_producon_2
Units_used_in_producon_3
Revenue_from_sales
$100
2000
1000
0
2000
0
0
$70,000
$110
2000
1000
0
2000
0
0
$70,000
$120
2000
1000
0
2000
0
0
$70,000
$130
1142.857
571.4286
571
1143
571
0
$74,286
$140
1142.857
571.4286
571
1143
571
0
$80,000
$150
1142.857
571.4286
571
1143
571
0
$85,714
$160
1142.857
571.4286
571
1143
571
0
$91,429
$170
1142.857
571.4286
571
1143
571
0
$97,143
$180
1142.857
571.4286
571
1143
571
0 $102,857
$190
1142.857
571.4286
571
1143
571
0 $108,571
$200
1142.857
571.4286
571
1143
571
0 $114,286
Figure 4.29
Sensitivity to Selling
Price of Drug C 
7 If you obtain Solver’s sensitivity report, you will see that the change actually occurs when the price of drug C
reaches $122.50. Our SolverTable grid of prices is too coarse to detect this exact changeover point.
As you can see, until the drug C selling price reaches $130, Repco uses the same so-
lution as before.7 However, when it increases to $130 and beyond, 571.4 units of drug C
are produced. This in turn requires 571.4 units of drug B, which requires 1142.9 units of
drug A, but only drug C is actually sold. Of course, Repco would like to produce even more
of drug C (which would require more production of drugs A and B), but the labor hour con-
straint does not allow it. Therefore, further increases in the selling price of drug C have no
effect on the solution—other than increasing revenue.
Because available labor imposes an upper limit on the production of drug C even when
it is very proﬁtable, it is interesting to see what happens when the selling price of drug C
and the labor hours available both increase. Here you can use a two-way SolverTable, se-
lecting selling price of drug C and labor hour availability as the two inputs with reasonable
values, and selecting the amount produced of drug C as the single output. The results from
SolverTable appear in Figure 4.30.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

This table again shows that no drug C is produced, regardless of labor hour availabil-
ity, until the selling price of drug C reaches $130. (Of course, the actual breakpoint is prob-
ably between $120 and $130. You can’t tell from the grid of input values used in the table.)
The effect of increases in labor hour availability is to let Repco produce more of drug C.
Speciﬁcally, Repco produces as much of drug C as possible, given that one unit of drug B,
and hence two units of drug A, are required for each unit of drug C.
Before leaving this example, we provide further insight into the sensitivity behavior in
Figure 4.29. Speciﬁcally, why should Repco start producing drug C when its unit selling
price increases to some value between $120 and $130? There is a straightforward answer
to this question because the model contains a single resource constraint: the labor hour con-
straint. (The analysis would be more complicated with multiple resources.)
Consider the production of one unit of drug B, which requires two labor hours plus
two units of drug A, each of which requires one labor hour, for a total of four labor hours. It
returns $70 in revenue. Therefore, revenue per labor hour when producing drug B is $17.50.
To be eligible as a “winner,” drug C has to beat this. Note that each unit of drug C requires
seven labor hours (three for itself and four for the unit of drug B it requires). To beat the
$17.50 revenue per labor hour of drug B, the unit selling price of drug C must be at least
$122.50 [ 17.50(7)]. If its selling price is below this, for example, $121, Repco will sell all
drug B and no drug C. If its selling price is above this, for example, $127, Repco will sell
all drug C and no drug B.
■
176
Chapter 4
Linear Programming Models
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
A
B
C
D
E
F
G
H
Twoway analysis for Solver model in Model worksheet
Selling price drug C (cell $D$12) values along side, Hours available (cell $D$23) values along top
Units_produced_3
4000
5000
6000
7000
8000
9000
10000
$100
0.0
0.0
0.0
0.0
0.0
0.0
0.0
$110
0.0
0.0
0.0
0.0
0.0
0.0
0.0
$120
0.0
0.0
0.0
0.0
0.0
0.0
0.0
$130
571.4
714.3
857.1
1000.0
1142.9
1285.7
1428.6
$140
571.4
714.3
857.1
1000.0
1142.9
1285.7
1428.6
$150
571.4
714.3
857.1
1000.0
1142.9
1285.7
1428.6
$160
571.4
714.3
857.1
1000.0
1142.9
1285.7
1428.6
$170
571.4
714.3
857.1
1000.0
1142.9
1285.7
1428.6
$180
571.4
714.3
857.1
1000.0
1142.9
1285.7
1428.6
$190
571.4
714.3
857.1
1000.0
1142.9
1285.7
1428.6
$200
571.4
714.3
857.1
1000.0
1142.9
1285.7
1428.6
Figure 4.30
Sensitivity to Selling
Price of Drug C
and Labor Hour
Availability
As this analysis
illustrates, you can 
sometimes—but not 
always—gain an
intuitive understanding
of the information
obtained by Solver
Table.
P R O B L E M S
Skill-Building Problems
26. Run a one-way sensitivity analysis on the optimal
solution to the unit selling price of drug A in the
Repco problem. If this price is high enough, will
Repco start selling drug A in addition to producing
it? Then run a similar one-way sensitivity analysis
on the optimal solution to the price of drug B. If this
price gets low enough, what happens to the optimal
solution?
27. Suppose there is a fourth drug, drug D, that Repco
can produce and sell. Each unit of drug D requires
four labor hours, one unit of drug A, and one unit of
drug C to produce, and it sells for $150 per unit.
Modify the current model to incorporate drug D and
reoptimize. If drug D isn’t produced in the optimal so-
lution, use sensitivity analysis to see how much higher
its selling price would have to be before Repco would
produce it. If drug D is produced in the optimal solu-
tion, use sensitivity analysis to see how much lower its
selling price would have to be before Repco would
stop producing it.
28. We claimed that the Repco model could either con-
strain the units produced to be greater than or equal to
the units used by production or constrain the units sold
to be nonnegative. Modify the model to implement the
latter (deleting the former), and verify that you get the
same optimal solution.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4.7 Financial Models
177
Skill-Extending Problem
29. In a production process model such as Repco’s, certain
inputs make no sense in the usage table (the range
B7:D9 of the model). For example, suppose that, in
addition to current usages, each unit of drug A
requires one unit of drug C. Why does this result in a
nonsensical problem? What happens if you run Solver
on it anyway? What happens if you run Solver on it
after adding a constraint that the sum of the units pro-
duced (over all three drugs) must be at least 1?
4.7 FINANCIAL MODELS
The majority of optimization examples described in management science textbooks are
in the area of operations: scheduling, blending, logistics, aggregate planning, and others.
This is probably warranted, because many of the most successful management science
applications in the real world have been in these areas. However, optimization and other
management science methods have also been applied successfully in a number of ﬁnan-
cial areas, and they deserve recognition. Several of these applications are discussed
throughout this book. In this section, we begin the discussion with two typical applications
of LP in ﬁnance. The ﬁrst involves investment strategy. The second involves pension fund
management.
E X A M P L E
4.6 FINDING AN OPTIMAL INVESTMENT STRATEGY AT BARNEY-JONES
A
t the present time, the beginning of year 1, the Barney-Jones Investment Corporation
has $100,000 to invest for the next four years. There are ﬁve possible investments, la-
beled A through E. The timing of cash outﬂows and cash inﬂows for these investments is
somewhat irregular. For example, to take part in investment A, cash must be invested at the
beginning of year 1, and for every dollar invested, there are returns of $0.50 and $1.00 at
the beginnings of years 2 and 3. Information for the other investments follows, where all re-
turns are per dollar invested:
■
Investment B: Invest at the beginning of year 2, receive returns of $0.50 and $1.00 at
the beginnings of years 3 and 4
■
Investment C: Invest at the beginning of year 1, receive return of $1.20 at the
beginning of year 2
■
Investment D: Invest at the beginning of year 4, receive return of $1.90 at the
beginning of year 5
■
Investment E: Invest at the beginning of year 3, receive return of $1.50 at the
beginning of year 4
We assume that any amounts can be invested in these strategies and that the returns are the
same for each dollar invested. However, to create a diversiﬁed portfolio, Barney-Jones
wants to limit the amount put into any investment to $75,000. The company wants an in-
vestment strategy that maximizes the amount of cash on hand at the beginning of year 5. At
the beginning of any year, it can invest only cash on hand, which includes returns from pre-
vious investments. Any cash not invested in any year can be put in a short-term money mar-
ket account that earns 3% annually.
Objective
To develop an LP spreadsheet model that relates investment decisions to total
ending cash, and to use Solver to ﬁnd the strategy that maximizes ending cash and invests
no more than a given amount in any one investment.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

178
Chapter 4
Linear Programming Models
WHERE DO THE NUMBERS COME FROM?
There is no mystery here. We assume that the terms of each investment are spelled out, so
that Barney-Jones knows exactly when money must be invested and what the amounts and
timing of returns will be. Of course, this would not be the case for many real-world invest-
ments, such as money put into the stock market, where considerable uncertainty is in-
volved. We consider one such example of investing with uncertainty when we study port-
folio optimization in Chapter 7.
Solution
The variables and constraints for this investment model are listed in Table 4.9. On the
surface, this problem appears to be very straightforward. You must decide how much to
invest in the available investments at the beginning of each year, using only the cash
available. If you try modeling this problem without our help, however, we suspect that you
will have some difﬁculty. It took us a few tries to get a model that is easy to read and
generalizes to other similar investment problems. Note that the second constraint in the
table can be expressed in two ways. It can be expressed as shown, where the cash on hand
after investing is nonnegative, or it can be expressed as “cash invested in any year must be
less than or equal to cash on hand at the beginning of that year.” These are equivalent. The
one you choose is a matter of taste.
Table 4.9
Variables and Constraints for Investment Model
Input variables
Timing of investments and returns, initial cash, maximum
amount allowed in any investment, money market rate on cash
Decision variables (changing cells)
Amounts to invest in investments
Objective cell
Ending cash at the beginning of year 5
Other calculated variables
Cash available at the beginning of years 2–4
Constraints
Amount in any investment  Max investment amount 
Cash on hand after investing each year  0 
There are often
multiple equivalent
ways to state a
constraint.You can
choose the one that is
most natural for you.
DEVELOPING THE SPREADSHEET MODEL
The spreadsheet model for this investment problem appears in Figure 4.31. (See the ﬁle 
Investing.xlsx.) To set up this spreadsheet, proceed as follows.
1
Inputs and range names. As usual, enter the given inputs in the blue cells and name
the ranges indicated. Pay particular attention to the two shaded tables. This is probably the
ﬁrst model you have encountered where model development is affected signiﬁcantly by the
way you enter the inputs, speciﬁcally, the information about the investments. We suggest
separating cash outflows from cash inflows, as shown in the two ranges B11:F14 and
B19:F23. The top table indicates when investments can be made, where $0.00 indicates no
possible investment, and $1.00 indicates a dollar of investment. The bottom table then in-
dicates the amounts and timing of returns per dollar invested.
2
Investment amounts. Enter any trial values in the Dollars_invested range. This range
contains the changing cells. Also put a link to the maximum investment amount per invest-
ment by entering the formula
$B$5
in cell B28 and copying it across.
Note how the two
input tables allow you
to create copyable
SUMPRODUCT
formulas for cash
outflows and inflows.
Careful spreadsheet
planning can often
greatly simplify the
necessary formulas.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4.7 Financial Models
179
3
Cash balances and ﬂows. The key to the model is the section in rows 32 through 36.
For each year, you need to calculate the beginning cash held from the previous year, the re-
turns from investments that are due in that year, the investments made in that year, and cash
balance after investments. Begin by entering the initial cash in cell B32 with the formula
B4
Moving across, calculate the return due in year 1 in cell C32 with the formula
SUMPRODUCT(B19:F19,Dollars_invested)
Admittedly, no returns come due in year 1, but this formula can be copied down column C for
other years. Next, calculate the total amount invested in year 1 in cell D32 with the formula
SUMPRODUCT(B11:F11,Dollars_invested)
Now ﬁnd the cash balance after investing in year 1 in cell E32 with the formula
B32C32-D32
The only other required formula is the formula for the cash available at the beginning of
year 2. Because any cash not invested earns 3% interest, enter the formula
E32*(1$B$6)
in cell B33. This formula, along with those in cells C32, D32, and E32, can now be copied
down. (The zeros in column G are entered manually as a reminder of the nonnegativity
constraint on cash after investing.)
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
Investments with irregular
of returns
Range names used
Inputs
amount to
Maximum per
invest
$100,000
investment
$75,000
Interest rate on
%
3
h
s
a
c
Cash outlays on investments (all incurred at beginning of year)
Investment
E
D
C
B
A
r
a
e
Y
0
0.0
$
0
0.0
$
0
0.1
$
0
0.0
$
0
0.1
$
1
0
0.0
$
0
0.0
$
0
0.0
$
0
0.1
$
0
0.0
$
2
0
0.1
$
0
0.0
$
0
0.0
$
0
0.0
$
0
0.0
$
3
0
0.0
$
0
0.1
$
0
0.0
$
0
0.0
$
0
0.0
$
4
Cash returns from investments (all incurred at beginning of year)
Investment
E
D
C
B
A
r
a
e
Y
0
0.0
$
0
0.0
$
0
0.0
$
0
0.0
$
0
0.0
$
1
0
0.0
$
0
0.0
$
0
2.1
$
0
0.0
$
0
5.0
$
2
0
0.0
$
0
0.0
$
0
0.0
$
0
5.0
$
0
0.1
$
3
0
5.1
$
0
0.0
$
0
0.0
$
0
0.1
$
0
0.0
$
4
0
0.0
$
0
9.1
$
0
0.0
$
0
0.0
$
0
0.0
$
5
Investment decisions
Dollars
0
0
0,5
7
$
0
0
0,5
7
$
4
1
7,5
3
$
0
0
0,5
7
$
6
8
2,4
6
$
d
e
ts
e
v
ni
<=
<=
<=
<=
<=
Maximum per
Constraints on cash
Year
Beginning cash
Returns from
investments
Cash invested
Cash
0
=
>
0
$
0
0
0,0
0
1
$
0
$
0
0
0,0
0
1
$
1
0
=
>
0
$
0
0
0,5
7
$
0
0
0,5
7
$
0
$
2
0
=
>
6
8
7,6
2
$
0
0
0,5
7
$
6
8
7,1
0
1
$
0
$
3
0
=
>
9
8
0,0
4
1
$
0
0
0,5
7
$
0
0
5,7
8
1
$
9
8
5,7
2
$
4
0
0
5,2
4
1
$
2
9
2,4
4
1
$
5
Final cash
$286,792
to maximize: ﬁnal cash at beginning of year 5
A
B
C
D
E
F
G
H
I
J
g
=Model!$E$32:$E$35
Dollars_invested
=Model!$B$26:$F$26
Final_cash
=Model!$B$38
Maximum_per_investment
=Model!$B$28:$F$28
investment
$75,000
$75,000
$75,000
$75,000
$75,000
balance
Figure 4.31
Investment Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

180
Chapter 4
Linear Programming Models
4
Ending cash. The ending cash at the beginning of year 5 is the sum of the amount in the
money market and any returns that come due in year 5. Calculate this sum with the formula
SUM(B36:C36)
in cell B38. (Note: Here is the type of error to watch out for. We originally failed to
calculate the return in cell C36 and mistakenly used the beginning cash in cell B36 as the
objective cell. We realized our error when the optimal solution called for no money in in-
vestment D, which is clearly an attractive investment. The moral is that you can often catch
errors by looking at the plausibility of the outputs.)
Review of the Model
Take a careful look at this model and how it has been set up. There are undoubtedly many
alternative ways to model this problem, but the attractive feature of this model is the way
the tables of inﬂows and outﬂows in rows 11 through 14 and 19 through 23 create copyable
formulas for returns and investment amounts in columns C and D of rows 32 through 35.
In fact, this same model setup, with only minor modiﬁcations, will work for any set of in-
vestments, regardless of the timing of investments and their returns. Generalizability is a
quality you should strive for in your spreadsheet models.
USING SOLVER
To find the optimal investment strategy, fill in the Solver dialog box as shown in Fig-
ure 4.32. Note that the explicit nonnegativity constraint in Figure 4.32 is necessary, even
though the Non-Negative option is checked. Again, this is because the Non-Negative
option covers only the changing cells. If you want other output cells to be nonnegative, you
must add such constraints explicitly.
Always look at the
Solver solution for 
signs of implausibility.
This can often enable
you to find an error in 
your model.
Figure 4.32
Solver Dialog Box
for Investment
Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4.7 Financial Models
181
Discussion of the Results
The optimal solution appears in Figure 4.31. Let’s follow the cash. The company spends all
of its cash in year 1 on the two available investments, A and C ($64,286 in A, $35,714 in
C). A total of $75,000 in returns from these investments is available in year 2, and all of this
is invested in investment B. At the beginning of year 3, a total of $101,786 is available from
investment A and B returns, and $75,000 of this is invested in investment E. This leaves
$26,786 for the money market, which grows to $27,589 at the beginning of year 4. In
addition, returns totaling $187,500 from investments B and E come due in year 4. Of this
total cash of $215,089, $75,000 is invested in investment D, and the rest, $140,089, is put
in the money market. The return from investment D, $142,500, plus the money available
from the money market, $144,292, equals the ﬁnal cash in the objective cell, $286,792.
Sensitivity Analysis
A close look at the optimal solution in Figure 4.31 indicates that Barney-Jones is penalizing
itself by imposing a maximum of $75,000 per investment. This upper limit is forcing the
company to put cash into the money market fund, despite this fund’s low rate of return.
Therefore, a natural sensitivity analysis is to see how the optimal solution changes as this
maximum value changes. You can perform this sensitivity analysis with a one-way
SolverTable, shown in Figure 4.33.8 The maximum in cell B5 is the input cell, varied from
$75,000 to $225,000 in increments of $25,000, and the optimal changing cells and objective
cell are outputs. As you can see, the ﬁnal cash (column G) grows steadily as the maximum
allowable investment amount increases. This is because the company can take greater ad-
vantage of the attractive investments and put less in the money market account.
8Because Solver’s sensitivity reports do not help answer our speciﬁc sensitivity questions in this example or the
next example, we discuss only SolverTable results.
3
4
5
6
7
8
9
10
11
A
B
C
D
E
F
G
Max per investment (cell $B$5) values along side, output cell(s) along top
Dollars_invested_1
Dollars_invested_2
Dollars_invested_3
Dollars_invested_4
Dollars_invested_5
Final_cash
$75,000
$64,286
$75,000
$35,714
$75,000
$75,000
$286,792
$100,000
$61,538
$76,923
$38,462
$100,000
$100,000
$320,731
$125,000
$100,000
$50,000
$0
$125,000
$125,000
$353,375
$150,000
$100,000
$50,000
$0
$150,000
$125,000
$375,125
$175,000
$100,000
$50,000
$0
$175,000
$125,000
$396,875
$200,000
$100,000
$50,000
$0
$200,000
$125,000
$418,625
$225,000
$100,000
$50,000
$0
$225,000
$125,000
$440,375
Figure 4.33
Sensitivity of
Optimal Solution 
to Maximum 
Investment 
Amount
You can go one step further with the two-way SolverTable in Figure 4.34. Now both the
maximum investment amount and the money market rate are inputs, and the maximum
amount ever put in the money market fund is the single output. Because this latter amount is
not calculated in the spreadsheet model, you need to calculate it with the formula
MAX(Cash_after_investing) in an unused cell before using it as the output cell for
SolverTable. In every case, even with a large maximum investment amount and a low money
market rate, the company puts some money into the money market account. The reason is
simple. Even when the maximum investment amount is $225,000, the company evidently has
more cash than this to invest at some point (probably at the beginning of year 4). Therefore,
it will have to put some of it in the money market.
■
To perform sensitivity
on an output variable
not calculated 
explicitly in your
spreadsheet model,
calculate it in some
unused portion of the
spreadsheet before
running SolverTable.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

182
Chapter 4
Linear Programming Models
The following example illustrates a common situation where ﬁxed payments are due
in the future and current funds must be allocated and invested so that their returns are
sufﬁcient to make the payments. We place this in a pension fund context.
3
4
5
6
7
8
9
10
11
12
13
A
B
C
D
E
F
G
H
I
Interest on cash (cell $B$6) values along side, Max per investment (cell $B$5) values along top, output cell in corner
Maximum_in_money_market
$75,000
$100,000
$125,000
$150,000
$175,000
$200,000
$225,000
0.5%
$139,420
$126,923
$112,500
$87,500
$62,500
$37,500
$12,500
1.0%
$139,554
$126,923
$112,500
$87,500
$62,500
$37,500
$12,500
1.5%
$139,688
$126,923
$112,500
$87,500
$62,500
$37,500
$12,500
2.0%
$139,821
$126,923
$112,500
$87,500
$62,500
$37,500
$12,500
2.5%
$139,955
$126,923
$112,500
$87,500
$62,500
$37,500
$12,500
3.0%
$140,089
$126,923
$112,500
$87,500
$62,500
$37,500
$12,500
3.5%
$140,223
$126,923
$112,500
$87,500
$62,500
$37,500
$12,500
4.0%
$140,357
$126,923
$112,500
$87,500
$62,500
$37,500
$12,500
4.5%
$140,491
$126,923
$112,500
$87,500
$62,500
$37,500
$12,500
Figure 4.34
Sensitivity of Maximum in Money Market to Two Inputs
E X A M P L E
4.7 MANAGING A PENSION FUND AT ARMCO
J
ames Judson is the ﬁnancial manager in charge of the company pension fund at Armco
Incorporated. James knows that the fund must be sufﬁcient to make the payments listed
in Table 4.10. Each payment must be made on the ﬁrst day of each year. James is going to
ﬁnance these payments by purchasing bonds. It is currently January 1, 2010, and three
bonds are available for immediate purchase. The prices and coupons for the bonds are as
follows. (All coupon payments are received on January 1 and arrive in time to meet cash
demands for the date on which they arrive.)
■
Bond 1 costs $980 and yields a $60 coupon in the years 2011 through 2014 and a
$1060 payment on maturity in the year 2015.
■
Bond 2 costs $970 and yields a $65 coupon in the years 2011 through 2020 and a
$1065 payment on maturity in the year 2021.
■
Bond 3 costs $1050 and yields a $75 coupon in the years 2011 through 2023 and a
$1075 payment on maturity in the year 2024.
James must decide how much cash to allocate (from company coffers) to meet the initial
$11,000 payment and buy enough bonds to make future payments. He knows that any
excess cash on hand can earn an annual rate of 4% in a ﬁxed-rate account. How should
he proceed?
Table 4.10 Payments for Pension Example
Year
Payment
Year
Payment
Year
Payment
2010
$11,000
2015
$18,000
2020
$25,000
2011
$12,000
2016
$20,000
2021
$30,000
2012
$14,000
2017
$21,000
2022
$31,000
2013
$15,000
2018
$22,000
2023
$31,000
2014
$16,000
2019
$24,000
2024
$31,000 
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4.7 Financial Models
183
Objective
To develop an LP model that relates initial allocation of money and bond pur-
chases to future cash availabilities, and to minimize the initialize allocation of money re-
quired to meet all future pension fund payments.
WHERE DO THE NUMBERS COME FROM?
As in the previous ﬁnancial example, the inputs are fairly easy to obtain. A pension fund
has known liabilities that must be met in future years, and information on bonds and ﬁxed-
rate accounts is widely available.
Solution
The variables and constraints required for this pension fund model are listed in Table 4.11.
When modeling this problem, there is a new twist that involves the money James must 
allocate now for his funding problem. It is clear that he must decide how many bonds of
each type to purchase now (note that no bonds are purchased in the future), but he must also
decide how much money to allocate from company coffers. This allocated money has to
cover the initial pension payment this year and the bond purchases. In addition, James
wants to ﬁnd the minimum allocation that will sufﬁce. Therefore, this initial allocation
serves two roles in the model. It is a decision variable and it is the objective to minimize.
In terms of spreadsheet modeling, it is perfectly acceptable to make the objective cell one
of the changing cells, and this is done here. You will not see this in many models—because
the objective typically involves a linear combination of several decision variables—but it is
occasionally the most natural way to proceed.
Table 4.11 Variables and Constraints for Pension Model
Input variables
Pension payments, information on bonds, ﬁxed interest rate on cash
Decision variables 
Money to allocate now, numbers of bonds to purchase now
(changing cells)
Object cell
Money to allocate in now (minimize)
Other calculated variables
Cash available to meet pension payments each year
Constraints
Cash available for payments  Required payments 
FUNDAMENTAL INSIGHT
The Objective as a Changing Cell
In all optimization models,the objective cell has to be
a function of the changing cells, that is, the objective
value should change as values in the changing cells
change. It is perf ectly consistent with this r equire-
ment to have the objective cell be one of the changing
cells. This doesn’t occur in v ery many optimization
models, but it is sometimes useful, even necessary.
DEVELOPING THE SPREADSHEET MODEL
The completed spreadsheet model is shown in Figure 4.35. (See the ﬁle Pension Fund
Management.xlsx.) You can create it with the following steps.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

184
Chapter 4
Linear Programming Models
1
Inputs and range names. Enter the given data and name the ranges as indicated.
Note that the bond costs in the range B5:B7 have been entered as positive quantities. Some
financial analysts might prefer that they be entered as negative numbers, indicating
outflows. It doesn’t really matter, however, as long as you are careful with the Excel
formulas later on.
2
Money allocated and bonds pur chased. As discussed previously, the money
allocated in the current year and the numbers of bonds purchased now are both decision
variables, so enter any values for these in the Money_allocated and Bonds_purchased
ranges. Note that the color-coding convention for the Money_allocated cell have to be
modiﬁed. Because it is both a changing cell and the objective cell, we colored it red but
added a note to emphasize that it is the objective to minimize.
3
Cash available to make payments. In the current year, the only cash available is the
money initially allocated minus cash used to purchase bonds. Calculate this quantity in cell
B20 with the formula
Money_allocated-SUMPRODUCT(Bonds_purchased,B5:B7)
For all other years, the cash available comes from two sources: excess cash invested at the
ﬁxed interest rate the year before and payments from bonds. Calculate this quantity for
2011 in cell C20 with the formula
(B20-B22)*(1$B$9)SUMPRODUCT(Bonds_purchased,C5:C7)
and copy it across row 20 for the other years.
As you can see, this model is fairly straightforward to develop once you understand the
role of the amount allocated in cell B16. However, we have often given this problem as an
assignment to our students, and many fail to deal correctly with the amount allocated.
(They usually forget to make it a changing cell.) So make sure you understand what we
have done, and why we have done it this way.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
A
B
C
D
E
F
G
H
I
J
K
L
M
N
O
P
Pension fund management
Costs (now) and income (in other years) from bonds
4
2
0
2
3
2
0
2
2
2
0
2
1
2
0
2
0
2
0
2
9
1
0
2
8
1
0
2
7
1
0
2
6
1
0
2
5
1
0
2
4
1
0
2
3
1
0
2
2
1
0
2
1
1
0
2
0
1
0
2
r
a
e
Y
Bond 
0
6
0,1
$
0
6
$
0
6
$
0
6
$
0
6
$
0
8
9
$
1
Bond 
5
6
0,1
$
5
6
$
5
6
$
5
6
$
5
6
$
5
6
$
5
6
$
5
6
$
5
6
$
5
6
$
5
6
$
0
7
9
$
2
Bond 3
$1,050
$75
$75
$75
$75
$75
$75
$75
$75
$75
$75
$75
$75
$75
$1,075
Interest rate
4%
Number of bonds (allowing fraconal values) to purchase now
Bond 
9
6.3
7
1
Bond 
1
2.7
7
2
Bond 
4
8.8
2
3
Money allocated
$197,768
Objecve to minimize, also a changing cell
Constraints to meet payments
4
2
0
2
3
2
0
2
2
2
0
2
1
2
0
2
0
2
0
2
9
1
0
2
8
1
0
2
7
1
0
2
6
1
0
2
5
1
0
2
4
1
0
2
3
1
0
2
2
1
0
2
1
1
0
2
0
1
0
2
r
a
e
Y
Amount available
$20,376
$21,354
$21,332
$19,228
$16,000
$85,298
$77,171
$66,639
$54,646
$41,133
$25,000
$84,390
$58,728
$31,000
$31,000
>=
>=
>=
>=
>=
>=
>=
>=
>=
>=
>=
>=
>=
>=
>=
Amount required
$11,000
$12,000
$14,000
$15,000
$16,000
$18,000
$20,000
$21,000
$22,000
$24,000
$25,000
$30,000
$31,000
$31,000
$31,000
Range names used:
Amount_available
=Model!$B$20:$P$20
Amount_required
=Model!$B$22:$P$22
Bonds_purchased
=Model!$B$12:$B$14
Money_allocated
=Model!$B$16
The value in cell B16 is the money allocated to make the 
current payment and buy bonds now. It is both a changing 
cell and the target cell to minimize.
Figure 4.35
Pension Fund Management Model
Always document your
spreadsheet conven-
tions as clearly as 
possible.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4.7 Financial Models
185
USING SOLVER
The main Solver dialog box should be ﬁlled out as shown in Figure 4.36. Once again, notice
that the Money_allocated cell is both the objective cell and one of the changing cells.
Figure 4.36
Solver Dialog Box
for Pension Fund
Model
Discussion of the Solution
The optimal solution appears in Figure 4.35. You might argue that the numbers of bonds
purchased should be constrained to integer values. We tried this and the optimal solution
changed very little: The optimal numbers of bonds to purchase changed to 74, 79, and 27,
and the optimal money to allocate increased to $197,887. With this integer solution, shown
in Figure 4.37, James sets aside $197,887 initially. Any less than this would not work—he
couldn’t make enough from bonds to meet future pension payments. All but $20,387 of this
(see cell B20) is spent on bonds, and of the $20,387, $11,000 is used to make the current
pension payment. After this, the amounts in row 20, which are always sufﬁcient to make
the payments in row 22, are composed of returns from bonds and cash, with interest, from
the previous year. Even more so than in previous examples, there is no way to guess this
optimal solution. The timing of bond returns and the irregular pension payments make a
spreadsheet optimization model absolute necessary.
Sensitivity Analysis
Because the bond information and pension payments are evidently ﬁxed, there is only one
obvious direction for sensitivity analysis: on the ﬁxed interest rate in cell B9. We tried this,
Constraints always
have the potential to
penalize the objective
to some extent.
SolverTable is a 
perfect tool for finding
the magnitude of 
this penalty.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

186
Chapter 4
Linear Programming Models
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
A
B
C
D
E
F
G
H
I
J
K
L
M
N
O
P
Pension fund management
Costs (now) and income (in other years) from bonds
4
2
0
2
3
2
0
2
2
2
0
2
1
2
0
2
0
2
0
2
9
1
0
2
8
1
0
2
7
1
0
2
6
1
0
2
5
1
0
2
4
1
0
2
3
1
0
2
2
1
0
2
1
1
0
2
0
1
0
2
r
a
e
Y
Bond 
6
0,1
$
0
6
$
0
6
$
0
6
$
0
6
$
0
8
9
$
1
0
Bond 
5
6
0,1
$
5
6
$
5
6
$
5
6
$
5
6
$
5
6
$
5
6
$
5
6
$
5
6
$
5
6
$
5
6
$
0
7
9
$
2
Bond 3
$1,050
$75
$75
$75
$75
$75
$75
$75
$75
$75
$75
$75
$75
$75
$1,075
Interest rate
4%
Number of bonds (allowing fraconal values) to purchase now
Bond 
0
0.4
7
1
Bond 
0
0.9
7
2
Bond 
0
0.7
2
3
Money allocated
$197,887
Objecve to minimize, also a changing cell
Constraints to meet payments
4
2
0
2
3
2
0
2
2
2
0
2
1
2
0
2
0
2
0
2
9
1
0
2
8
1
0
2
7
1
0
2
6
1
0
2
5
1
0
2
4
1
0
2
3
1
0
2
2
1
0
2
1
1
0
2
0
1
0
2
r
a
e
Y
Amount available
$20,387
$21,363
$21,337
$19,231
$16,000
$85,600
$77,464
$66,923
$54,919
$41,396
$25,252
$86,422
$60,704
$32,917
$31,019
>=
>=
>=
>=
>=
>=
>=
>=
>=
>=
>=
>=
>=
>=
>=
Amount required
$11,000
$12,000
$14,000
$15,000
$16,000
$18,000
$20,000
$21,000
$22,000
$24,000
$25,000
$30,000
$31,000
$31,000
$31,000
Figure 4.37
Optimal Integer Solution for Pension Fund Model
allowing this rate to vary from 2% to 6% in increments of 0.5% and keeping track of the
optimal changing cells, including the objective cell. The results appear in Figure 4.38
(without the integer constraints). They indicate that as the interest rate increases, James can
get by with fewer bonds of types 1 and 2, and he can allocate less money for the problem.
The reason is that he is making more interest on excess cash. ■
3
4
5
6
7
8
9
10
11
12
13
14
15
A
B
C
D
E
F
Interest rate (cell $B$9) values along side, output cell(s) along top
Bonds_purchased_1
Bonds_purchased_2
Bonds_purchased_3
Money_allocated
2.0%
77.12
78.71
28.84 $202,010
2.4%
76.41
78.40
28.84 $201,145
2.8%
75.72
78.10
28.84 $200,288
3.2%
75.03
77.80
28.84 $199,439
3.6%
74.36
77.50
28.84 $198,600
4.0%
73.69
77.21
28.84 $197,768
4.4%
73.04
76.92
28.84 $196,946
4.8%
72.40
76.63
28.84 $196,131
5.2%
71.77
76.34
28.84 $195,325
5.6%
71.15
76.06
28.84 $194,527
6.0%
70.54
75.78
28.84 $193,737
Figure 4.38
Sensitivity to Fixed
Interest Rate
Using LP to Optimize Bond Portfolios
Many Wall Street ﬁrms buy and sell bonds. Rohn (1987) developed a bond selection model
that maximizes proﬁt from bond purchases and sales subject to constraints that minimize
the ﬁrm’s risk exposure. The method used to model this situation is closely related to the
method used to model the Barney-Jones problem.
■
ADDITIONAL APPLICATIONS
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4.7 Financial Models
187
P R O B L E M S
Skill-Building Problems
30. In the Barney-Jones investment model, increase the
maximum amount allowed in any investment to
$150,000. Then run a one-way sensitivity analysis to
the money market rate on cash. Capture one output
variable: the maximum amount of cash ever put in the
money market. You can choose any reasonable range
for varying the money market rate.
31. Modify the Barney-Jones investment model so that a
minimum amount must be put into any investment,
although this minimum can vary by investment. For
example, the minimum amount for investment A
might be $0, whereas the minimum amount for invest-
ment D might be $50,000. These minimum amounts
should be inputs; you can make up any values you
like. Run Solver on your modiﬁed model.
32. We claimed that our model for Barney-Jones is gener-
alizable. Try generalizing it to the case where there are
two more potential investments, F and G. Investment F
requires a cash outlay in year 2 and returns $0.50 in
each of the next four years for every dollar invested.
Investment G requires a cash outlay in year 3 and
returns $0.75 in each of years 5, 6, and 7 for every dol-
lar invested. Modify the model as necessary, making
the objective the ﬁnal cash after year 7.
33. In the Barney-Jones investment model, we ran invest-
ments across columns and years down rows. Many
ﬁnancial analysts seem to prefer the opposite. Modify
the spreadsheet model so that years go across columns
and investments go down rows. Run Solver to ensure
that your modiﬁed model is correct. (There are two
possible ways to do this, and you can experiment to
see which you prefer. First, you could basically start
over on a blank worksheet. Second, you could use
Excel’s TRANSPOSE function.)
34. In the pension fund model, suppose there is an upper
limit of 60 on the number of bonds of any particular
type that can be purchased. Modify the model to
incorporate this extra constraint and then reoptimize.
How much more money does James need to allocate
initially?
35. In the pension fund model, suppose there is a fourth
bond, bond 4. Its unit cost in 2010 is $1020, it returns
coupons of $70 in years 2011 to 2014 and a payment
of $1070 in 2015. Modify the model to incorporate
this extra bond and reoptimize. Does the solution
change—that is, should James purchase any of
bond 4?
36. In the pension fund model, suppose James has been
asked to see how the optimal solution will change if
the required payments in years 2015 to 2024 all
increase by the same percentage, where this percent-
age could be anywhere from 5% to 25%. Use an ap-
propriate one-way SolverTable to help him out, and
write a memo describing the results.
37. The pension fund model is streamlined, perhaps too
much. It does all of the calculations concerning cash
ﬂows in row 20. James decides he would like to break
these out into several rows of calculations: Beginning
cash (for 2010, this is the amount allocated; for other
years, it is the unused cash, plus interest, from the pre-
vious year), Amount spent on bonds (positive in 2010
only), Amount received from bonds (positive for years
2011 to 2024 only), Cash available for making pension
fund payments, and (below the Amount required row)
Cash left over (amount invested in the ﬁxed interest
rate). Modify the model by inserting these rows, 
enter the appropriate formulas, and run Solver. You
should obtain the same result but get more detailed 
information.
Skill-Extending Problems
38. Suppose the investments in the Barney-Jones
model sometimes require cash outlays in more
than one year. For example, a $1 investment in invest-
ment B might require $0.25 to be spent in year 1 and
$0.75 to be spent in year 2. Does the current model
easily accommodate such investments? Try it with
some cash outlay data you make up, run Solver, and
interpret the results.
39. In the pension fund model, if the amount of money
initially is less than the amount found by Solver, then
James will not be able to meet all of the pension fund
payments. Use the current model to demonstrate that
this is true. To do so, enter a value less than the opti-
mal value into cell B16. Then run Solver, but remove
the Money_allocated cell as a changing cell and as the
target cell. (If there is no target cell, Solver simply
tries to ﬁnd a solution that satisﬁes all of the con-
straints.) What do you ﬁnd?
40. Continuing the previous problem in a slightly different
direction, continue to use the Money_allocated cell
as a changing cell, and add a constraint that it must be
less than or equal to any value, such as $195,000,
that is less than its current optimal value. With this
constraint, James will not be able to meet all of the
pension fund payments. Create a new target cell to
minimize the total amount of payments not met. The
easiest way to do this is with IF functions. Unfortu-
nately, this makes the model nonsmooth, and Solver
might have trouble ﬁnding the optimal solution. Try
it and see.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

188
Chapter 4
Linear Programming Models
Objective
To develop an LP spreadsheet model, using the DEA methodology, to 
determine whether each hospital is efficient in terms of using its inputs to produce its
outputs.
E X A M P L E
4.8 DEA IN THE HOSPITAL INDUSTRY
C
onsider a group of three hospitals. To keep the model small, assume that each hospi-
tal uses two inputs to produce three outputs. (In a real DEA, there are typically many
more inputs and outputs.) The two inputs used by each hospital are
input 1  capital (measured by hundreds of hospital beds)
input 2  labor (measured by thousands of labor hours used in a month)
The outputs produced by each hospital are
output 1  hundreds of patient-days during month for patients under age 14
output 2  hundreds of patient-days during month for patients between 14 and 65
output 3  hundreds of patient-days for patients over 65
The inputs and outputs for these hospitals are given in Table 4.12. Which of these three
hospitals is efﬁcient in terms of using its inputs to produce outputs?
Table 4.12 Input and Output for the Hospital Example
Inputs
Outputs
1
2
1
2
3
Hospital 1
5
14
9
4
16
Hospital 2
8
15
5
7
10
Hospital 3
7
12
4
9
13
4.8 DATA ENVELOPMENT ANALYSIS (DEA)
The data envelopment analysis (DEA) method can be used to determine whether a uni-
versity, hospital, restaurant, or other business is operating efﬁciently. Speciﬁcally, DEA can
be used by inefﬁcient organizations to benchmark efﬁcient and best-practice organizations.
According to Sherman and Ladino (1995):
Many managers of service organizations would describe benchmarking and best prac-
tice analysis as basic, widely accepted concepts already used in their businesses.
Closer examination indicates that the traditional techniques used to identify and pro-
mulgate best practices are not very effective, largely because the operations of these
service organizations are too complex to allow them to identify best practices
accurately. DEA provides an objective way to identify best practices in these service
organizations and has consistently generated new insights that lead to substantial pro-
ductivity gains that were not otherwise identiﬁable.
The following example illustrates DEA and is based on Callen (1991). See also Norton
(1994b).
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4.8 Data Envelopment Analysis (DEA)
189
WHERE DO THE NUMBERSCOME FROM?
In a general DEA analysis, the organization’s inputs and outputs must ﬁrst be deﬁned. Then
for each input or output, a unit of measurement must be selected. Neither of these is neces-
sarily an easy task, because organizations such as hospitals, banks, and schools consume a
variety of inputs and produce a variety of outputs that can be measured in alternative ways.
However, after the list of inputs and outputs has been chosen and units of measurement
have been selected, accounting data can be used to ﬁnd the required data for the model, as
in Table 4.12.
Solution
The idea is that each hospital should be shown in its best possible light. That is, the inputs
and outputs should be valued in such a way that a given hospital looks as good as possible
relative to the other hospitals. Speciﬁcally, to determine whether a hospital is efﬁcient, the
model determines a price per unit of each output and a cost per unit of each input. Then the
efﬁciency of a hospital is deﬁned as
Efﬁciency of hospital 
The DEA approach uses the following four ideas to determine whether a hospital is
efﬁcient.
■
No hospital can be more than 100% efﬁcient. Therefore, the efﬁciency of each hospi-
tal is constrained to be less than or equal to 1. To make this a linear constraint, it is
expressed in the form
Value of hospital’s outputs  Value of hospital’s inputs
■
When determining whether a hospital is efﬁcient, it is useful to scale input prices so
that the value of the hospital’s inputs equals 1. Any other value would sufﬁce, but
using 1 causes the efﬁciency of the hospital to be equal to the value of the hospital’s
outputs.
■
To put a given hospital in its best light, the input costs and output prices should be
chosen to maximize this hospital’s efﬁciency. If the hospital’s efﬁciency equals 1, 
the hospital is efﬁcient; if the hospital’s efﬁciency is less than 1, the hospital is 
inefﬁcient.
■
All input costs and output prices must be nonnegative.
Putting these ideas together, the variables required for the DEA model are summarized in
Table 4.13. Note the reference to “selected hospital.” The model is actually analyzed three
times, once for each hospital. So the selected hospital each time is the one currently in
focus.
Value of hospital’s outputs

Value of hospital’s inputs
Table 4.13 Variables and Constraints for the DEA Model
Input variables
Inputs used, outputs produced for each hospital
Decision variables 
Unit costs of inputs, unit prices of outputs for selected hospital
(changing cells)
Objective (target cell)
Total output value of selected hospital
Other calculated variables
Total input cost, total output value (for each hospital)
Constraints
Total input cost  Total output value (for each hospital)
Total cost for selected hospital  1
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

190
Chapter 4
Linear Programming Models
DEVELOPINGTHE SPREADSHEETMODEL
Figure 4.39 contains the DEA spreadsheet model used to determine the efﬁciency of hos-
pital 1. (See the ﬁle Hospital DEA.xlsx.) To develop this model, proceed as follows.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
K
J
I
H
G
F
E
D
C
B
A
DEA model for checking eﬃciency of a selected hospital
Range names used
Input_costs
=Model!$B$14:$B$16
Selected hospital
1
Output_values
=Model!$D$14:$D$16
Selected_hospital
=Model!$B$3
Inputs used
Input 1
Input 2
Outputs produced
Output 1
Output 2
Output 3
Selected_hospital_input_cost
=Model!$B$19
Hospital 
la
tip
s
o
H
4
1
5
1
 
2
2
$
B
$
!le
d
o
M
=
e
ula
v
_
t
u
p
t
u
o
_la
tip
s
o
h
_
d
e
tc
ele
S
6
1
4
9
1
Hospital 
la
tip
s
o
H
5
1
8
2
 
0
1
$
C
$:0
1
$
B
$
!le
d
o
M
=
st
u
p
ni_
f
o
_
sts
o
c
_
tin
U
0
1
7
5
2
Hospital 
la
tip
s
o
H
2
1
7
3
 
0
1
$
H
$:0
1
$
F
$
!le
d
o
M
=
st
u
p
t
u
o
_
f
o
_
s
e
cir
p
_
tin
U
3
1
9
4
3
Unit costs of 
tin
U
1
7
0.0
0
0
0.0
st
u
p
ni
 prices of outputs
0.0000
0.0000
0.063
Constraints that input costs must cover output values
Hospital
Input costs
Output values
1
1.000
>=
1.000
2
1.071
>=
0.625
3
0.857
>=
0.813
Constraint that selected hospital's input cost must equal a nominal value of 1
Selected hospital input cost
1.000
=
1
Maximize selected hospital's output value (to see if it is 1, hence eﬃcient)
Selected hospital output value
1.000
Figure 4.39
DEA Model for Hospital 1
1
Input given data and name ranges. Enter the input and output information for each
hospital in the ranges B6:C8 and F6:H8 and name the various ranges as indicated.
2
Selected hospital. Enter 1, 2, or 3 in cell B3, depending on which hospital you want to
analyze. (You will eventually analyze all three.)
3
Unit input costs and output prices. Enter any trial values for the input costs and out-
put prices in the Unit_costs_of_inputs and Unit_prices_of_outputs ranges.
4
Total input costs and output values. In the Input_costs range, calculate the cost of the
inputs used by each hospital. To do this, enter the formula
=SUMPRODUCT(Unit_costs_of_inputs,B6:C6)
in cell B14 for hospital 1, and copy this to the rest of the Input_costs range for the other hos-
pitals. Similarly, calculate the output values by entering the formula
=SUMPRODUCT(Unit_prices_of_outputs,F6:H6)
in cell D14 and copying it to the rest of the Output_values range. Note that even though the
focus is currently on hospital 1’s efﬁciency, you still need to calculate input costs and output
values for the other hospitals so that you have something to compare hospital 1 to.
5
Total input cost and output value for the selected hospital. In row 19, constrain the
total input cost of the selected hospital to be 1 by entering the formula
=VLOOKUP(Selected_hospital,A14:B16,2)
in cell B19, and enter a 1 in cell D19. Similarly, enter the formula
=VLOOKUP(Selected_hospital,A14:D16,4)
in cell B22. (Make sure you understand how these VLOOKUP functions work.) Remember
that because the selected hospital’s input cost is constrained to be 1, its output value in cell
B22 is automatically its efﬁciency.
USING SOLVERTO DETERMINEWHETHERHOSPITAL 1 IS EFFICIENT
To determine whether hospital 1 is efﬁcient, use Solver as follows. When you are ﬁnished,
the Solver dialog box should appear as shown in Figure 4.40.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4.8 Data Envelopment Analysis (DEA)
191
1
Objective. Select cell B22 as the target cell to maximize. Because the cost of
hospital 1 inputs is constrained to be 1, this causes Solver to maximize the efﬁciency of
hospital 1.
2
Changing cells. Choose the Unit_costs_of_inputs and Unit_prices_of_outputs ranges
as the changing cells.
3
Selected hospital’s input cost constraint. Add the constraint Selected_hospital_
input_cost=1. This sets the total value of hospital 1’s inputs equal to 1.
4
Efﬁciency constraint. Add the constraint Input_costs>=Output_values. This ensures
that no hospital is more than 100% efﬁcient.
5
Specify nonnegati vity and optimize.
Check the Non-Negative option and the
Simplex LP method, and then solve to obtain the optimal solution shown in Figure 4.39.
The 1 in cell B22 of this solution means that hospital 1 is efﬁcient. In words, Solver
has found a set of unit costs for the inputs and the unit prices for the outputs such that the
total value of hospital 1’s outputs equals the total cost of its inputs.
Figure 4.40
Solver Dialog Box
for the DEA Model
1
2
K
J
I
H
G
F
E
D
C
B
A
DEA model for checking eﬃciency of a selected hospital
Range names used
Input_costs
=Model!$B$14:$B$16
3
4
5
6
7
8
9
10
11
12
13
14
15
p
_
$ $
$ $
Selected hospital
2
Output_values
=Model!$D$14:$D$16
Selected_hospital
=Model!$B$3
Inputs used
Input 1
Input 2
Outputs produced
Output 1
Output 2
Output 3
Selected_hospital_input_cost
=Model!$B$19
Hospital 
la
tip
s
o
H
4
1
5
1
 
2
2
$
B
$
!le
d
o
M
=
e
ula
v
_
t
u
p
t
u
o
_la
tip
s
o
h
_
d
e
tc
ele
S
6
1
4
9
1
Hospital 
la
tip
s
o
H
5
1
8
2
 
0
1
$
C
$:0
1
$
B
$
!le
d
o
M
=
st
u
p
ni_
f
o
_
sts
o
c
_
tin
U
0
1
7
5
2
Hospital 
la
tip
s
o
H
2
1
7
3
 
0
1
$
H
$:0
1
$
F
$
!le
d
o
M
=
st
u
p
t
u
o
_
f
o
_
s
e
cir
p
_
tin
U
3
1
9
4
3
Unit costs of 
tin
U
7
6
0.0
0
0
0.0
st
u
p
ni
 prices of outputs
0.0800
0.0533
0.000
Constraints that input costs must cover output values
Hospital
Input costs
Output values
1
0.933
>=
0.933
2
1.000
>=
0.773
15
16
17
18
19
20
21
22
2
1.000
>=
0.773
3
0.800
>=
0.800
Constraint that selected hospital's input cost must equal a nominal value of 1
Selected hospital input cost
1.000
=
1
Maximize selected hospital's output value (to see if it is 1, hence eﬃcient)
Selected hospital output value
0.773
Figure 4.41 DEA Model for Hospital 2
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

192
Chapter 4
Linear Programming Models
Determining Whether Hospitals 2 and 3 
Are Efﬁcient
To determine whether hospital 2 is efﬁcient, simply replace the value in cell B3 by 2 and
rerun Solver. The Solver settings do not need to be modiﬁed. The optimal solution appears
in Figure 4.41. From the value of 0.773 in cell B22, you can see that hospital 2 is not efﬁ-
cient. Similarly, you can determine that hospital 3 is efﬁcient by replacing the value in cell
B3 by 3 and rerunning Solver (see Figure 4.42).
In summary, the Solver results imply that hospitals 1 and 3 are efﬁcient, but hospital 2
is inefﬁcient.
What Does It Mean to Be Efﬁcient or Inefﬁcient?
This idea of efﬁciency or inefﬁciency might still be a mystery, so let’s consider it further. A
hospital is efﬁcient if the inputs and outputs can be priced in such a way that this hospital
gets out all of the value that it puts in. The pricing scheme depends on the hospital. Each
hospital tries to price inputs and outputs to put its operations in the best possible light. In
the example, hospital 1 attaches 0 prices to input 1 (hospital beds) and output 3 (patient-
days for patients over 65), and it attaches positive prices to the rest. This makes hospital 1
look efﬁcient. Hospital 3, which is also efﬁcient, also attaches 0 prices to input 1 and output 3,
but its prices for the others are somewhat different from hospital 1’s prices.
If DEA ﬁnds that a hospital is inefﬁcient, there is no pricing scheme where that hospi-
tal can recover its entire input costs in output values. Actually, it can be shown that if a hos-
pital is inefﬁcient, then a combination of the efﬁcient hospitals can be found that uses no
more inputs than the inefﬁcient hospital, yet produces at least as much of each output as the
inefﬁcient hospital. In this sense, the hospital is inefﬁcient.
To see how this combination can be found, consider the spreadsheet model in 
Figure 4.43. Begin by entering any positive weights in the Weights range. For any such
weights (they don’t even need to sum to 1), consider the combination hospital as a fraction
of hospital 1 and another fraction of hospital 3. For example, with the weights shown, the
combination hospital uses about 26% of the inputs and produces about 26% of the outputs
of hospital 1, and it uses about 66% of the inputs and produces about 66% of the outputs of
hospital 3. When they are combined in row 6 with the SUMPRODUCT function [for ex-
ample, the formula in cell D6 is =SUMPRODUCT(Weights,D4:D5)], you can see the
quantities of inputs this combination hospital uses and the quantities of outputs it produces.
1
2
K
J
I
H
G
F
E
D
C
B
A
DEA model for checking eﬃciency of a selected hospital
Range names used
Input_costs
=Model!$B$14:$B$16
3
4
5
6
7
8
9
10
11
12
13
14
15
p
_
$ $
$ $
Selected hospital
3
Output_values
=Model!$D$14:$D$16
Selected_hospital
=Model!$B$3
Inputs used
Input 1
Input 2
Outputs produced
Output 1
Output 2
Output 3
Selected_hospital_input_cost
=Model!$B$19
Hospital 
la
tip
s
o
H
4
1
5
1
 
2
2
$
B
$
!le
d
o
M
=
e
ula
v
_
t
u
p
t
u
o
_la
tip
s
o
h
_
d
e
tc
ele
S
6
1
4
9
1
Hospital 
la
tip
s
o
H
5
1
8
2
 
0
1
$
C
$:0
1
$
B
$
!le
d
o
M
=
st
u
p
ni_
f
o
_
sts
o
c
_
tin
U
0
1
7
5
2
Hospital 
la
tip
s
o
H
2
1
7
3
 
0
1
$
H
$:0
1
$
F
$
!le
d
o
M
=
st
u
p
t
u
o
_
f
o
_
s
e
cir
p
_
tin
U
3
1
9
4
3
Unit costs of 
tin
U
3
8
0.0
0
0
0.0
st
u
p
ni
 prices of outputs
0.1000
0.0667
0.000
Constraints that input costs must cover output values
Hospital
Input costs
Output values
1
1.167
>=
1.167
2
1.250
>=
0.967
15
16
17
18
19
20
21
22
2
1.250
>=
0.967
3
1.000
>=
1.000
Constraint that selected hospital's input cost must equal a nominal value of 1
Selected hospital input cost
1.000
=
1
Maximize selected hospital's output value (to see if it is 1, hence eﬃcient)
Selected hospital output value
1.000
Figure 4.42 DEA Model for Hospital 3
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4.8 Data Envelopment Analysis (DEA)
193
In reality, after DEA analysis identiﬁes an organizational unit as being inefﬁcient, this unit
should consider benchmarking itself relative to the competition to see where it can make
more efﬁcient use of its inputs.
■
1
2
3
4
5
6
7
8
A
B
C
D
E
F
G
H
I
Comparing combinaon of hospitals 1 and 3 to ineﬃcient hospital 2
Weights
Input 1
Input 2
Output 1
Output 2
Output 3
Hospital 1
0.2615
5
14
9
4
16
Hospital 2
0.6615
7
12
4
9
13
5
8
7.2
1
7
5
6.1
1
8
3
9.5
n
oit
a
nib
m
o
C
<=
<=
>=
>=
>=
Hospital 
0
1
7
5
5
1
8
2
Figure 4.43
Illustrating How
Hospital 2 Is
Inefﬁcient
Figure 4.44
Solver Setup for
Finding an
Inefﬁciency
To ﬁnd weights where the combination hospital is better than hospital 2, it sufﬁces to ﬁnd
any feasible solution to the inequalities indicated in rows 6 to 8, and this can be done by
using the Solver setup in Figure 4.44. (The weights in Figure 4.43 do the job.) Note that
there is no objective to maximize or minimize; all you want is a solution that satisﬁes the
constraints. Furthermore, there is guaranteed to be a feasible solution because hospital 2
has already been identiﬁed as inefﬁcient.
1. The ratio (input i cost)/(input j cost) can be interpreted as the marginal rate of substi-
tution (at the optimal solution) of input i for input j. That is, the same level of outputs
can be maintained if the use of input i decreases by a small amount 
and the use
of input j increases by [(input i cost)/(input j cost)]
. For example, for hospital 2,
(input 2 cost/input 1 cost)  6700. This implies that if the use of input 2 decreases by
a small amount , hospital 2 can maintain its current output levels if the usage of
input 1 increases by 6700 .
2. The ratio (output i price)/(output j price) can be interpreted as the marginal rate of
substitution (at the optimal solution) of output i for output j. That is, the same level
¢
¢
¢
¢
MODELING ISSUES
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

194
Chapter 4
Linear Programming Models
P R O B L E M S
Skill-Building Problems
41. Pine Valley Bank has three branches. You have 
been asked to evaluate the efﬁciency of each. The
following inputs and outputs are to be used for the
study:
■input 1  labor hours used (hundreds per month)
■input 2  space used (in hundreds of square feet)
■input 3  supplies used per month (in dollars)
■output 1  loan applications per month
■output 2  deposits processed per month (in
thousands)
■output 3  checks processed per month (in
thousands)
The relevant information is given in the ﬁle
P04_41.xlsx. Use these data to determine whether any
bank branches are inefﬁcient.
DEA for Evaluating School Bus Transportation
Sexton et al. (1994) used DEA to evaluate the efﬁciency of school bus transportation for the
counties of North Carolina. For each county, they used two inputs: buses used and total
operating expense. They used a single output: pupils transported per day. However, they
noted a problem with traditional DEA. Consider two counties (county 1 and county 2) that
use exactly the same inputs and produce the same outputs. Suppose that county 1 is very
sparsely populated and county 2 is densely populated. Clearly, county 1 is transporting
pupils more efﬁciently than county 2, but a DEA conducted by the method described will
not show this. Realizing this, the authors developed a method to adjust the output of county
2 downward and the output of county 1 upward to compensate for this problem. The North
Carolina Department of Education penalized the inefﬁcient counties by reducing their bud-
getary appropriations. Since the time DEA was performed, most counties have greatly
increased their efﬁciency.
DEA in the Banking Industry
Sherman and Ladino (1995) used DEA to identify the most and least efﬁcient branches in
a banking ﬁrm with 33 branch banks. They found efﬁciency ratings that varied from 37%
to 100%, with 23 of the 33 branches rated below 100% and 10 below 70%. Each of the in-
efﬁcient branches was compared to a reference set of best-practice branches—efﬁcient
branches that offered the same types of services as the inefﬁcient branch. This allowed
them to make speciﬁc suggestions as to how the inefﬁcient branches could improve. For ex-
ample, they showed that branch 1 should be able to provide its current level and mix of ser-
vices with 4.5 fewer customer-service personnel, 1.8 fewer sales service personnel, 
0.3 fewer managers, $222,928 less in operating expenses, and 1304 fewer square feet. They
also indicated the added amount of service that the inefﬁcient branches could provide, in
addition to resource savings, if these branches could become as efficient as the best-
practice branches. For example, branch 1 could handle (per year) about 15,000 additional
deposits, withdrawals, and checks cashed; 2000 added bank checks, bonds, and travelers’
checks; 8 additional night deposits, while reducing the resources needed, if it attained the
efﬁciency level of the best-practice branches. See the May–June 1999 issue of Interfaces
for more applications of DEA in the banking industry.
■
ADDITIONAL APPLICATIONS
of input usage can be maintained if the production of output i decreases by a small
amount 
and the production of output j increases by [(output i price)/(output
j price)] . For example, for hospital 2, (output 2 price)/(output 1 price)  0.67. This
implies that if the use of output 2 decreases by a small amount , hospital 2 can
maintain its current resource usage if the production of output 1 increases by 0.67 .
■
¢
¢
¢
¢
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4.9 Conclusion
195
be evaluated. The inputs and outputs for each precinct
are as follows:
■input 1  number of policemen
■input 2  number of vehicles used
■output 1  number of patrol units responding to
service requests (thousands per year)
■output 2  number of convictions obtained each
year (in hundreds)
You are given the data in the ﬁle P04_43.xlsx. Use this
information to determine which precincts, if any, are
inefﬁcient.
44. You have been commissioned by Indiana University to
evaluate the relative efﬁciency of four degree-granting
units: Business, Education, Arts and Sciences, and
Health, Physical Education, and Recreation (HPER).
You are given the information in the ﬁle P04_44.xlsx.
Use DEA to identify all inefﬁcient units.
42. The Salem Board of Education wants to evaluate the
efﬁciency of the town’s four elementary schools. The
three outputs of the schools are
■output 1  average reading score
■output 2  average mathematics score
■output 3  average self-esteem score
The three inputs to the schools are
■input 1  average educational level of mothers
(deﬁned by highest grade completed: 12  high
school graduate; 16  college graduate, and so on)
■input 2  number of parent visits to school (per child)
■input 3  teacher-to-student ratio
The relevant information for the four schools is given
in the ﬁle P04_42.xlsx. Determine which (if any)
schools are inefﬁcient.
43. You have been asked to evaluate the efﬁciency of the
Port Charles Police Department. Three precincts are to
4.9 CONCLUSION
In this chapter, we have presented LP spreadsheet models of many diverse situations.
Although there is no standard procedure that can be used to attack all problems, there are
several keys you should use with most spreadsheet optimization models:
■
Determine the changing cells, the cells that contain the values of the decision
variables. These cells should contain the values the decision maker has direct control
over, and they should determine all other outputs, either directly or indirectly. 
For example, in blending models, the changing cells should contain the amount
of each input used to produce each output; in employee scheduling models, the
changing cells should contain the number of employees who work each possible 
ﬁve-day shift.
■
Set up the spreadsheet model so that you can easily calculate what you want to maxi-
mize or minimize (usually proﬁt or cost). For example, in the aggregate planning
model, a good way to compute total cost is to compute the monthly cost of operation
in each row.
■
Set up the spreadsheet model so that the relationships between the cells in the spread-
sheet and the problem constraints are readily apparent. For example, in the post ofﬁce
scheduling example, it is convenient to calculate the number of employees working
each day of the week near the number of employees needed for each day of the week.
■
Make your spreadsheet readable. Use descriptive labels, use range names, use cell
comments and text boxes for explanations, and plan your model layout before you
dive in. This might not be too important for small, straightforward models, but it is
crucial for large, complex models. Just remember that other people are likely to be
examining your spreadsheet models.
■
Keep in mind that LP models tend to fall into categories, but they are deﬁnitely not
all alike. For example, a problem might involve a combination of the ideas discussed
in the worker scheduling, blending, and production process examples of this chapter.
Each new model presents new challenges, and you must be ﬂexible and imaginative
to meet these challenges. It takes practice and perseverance.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

196
Chapter 4
Linear Programming Models
P R O B L E M S
Skill-Building Problems
45. A bus company believes that it will need the following
numbers of bus drivers during each of the next
ﬁve years: 60 drivers in year 1; 70 drivers in year 2; 
50 drivers in year 3; 65 drivers in year 4; 75 drivers in
year 5. At the beginning of each year, the bus
company must decide how many drivers to hire or ﬁre.
It costs $4000 to hire a driver and $2000 to ﬁre a
driver. A driver’s salary is $10,000 per year. At the
beginning of year 1, the company has 50 drivers.
A driver hired at the beginning of a year can be used
to meet the current year’s requirements and is paid
full salary for the current year.
Summary of Key Management Science Terms
Term
Explanation
Page
Dual-objective model
Model with two competing objectives; usual strategy is to 
141
constrain one of them and optimize the other
Integer constraints
Constraints that limit (some) changing cells to integer 
143
values
Multiple optimal 
Case where several solutions have the same optimal value 
149
solutions
of the objective
Heuristic
An educated guess solution, not guaranteed to be 
151
optimal but usually quick and easy to obtain
Nonsmooth problems
Nonlinear models with “sharp edges” or discontinuities 
160
that make them difﬁcult to solve
DEA (Data Envelopment
Method for determining whether organizational 
188
Analysis)
units are efﬁcient in terms of using their inputs to produce 
their outputs
Summary of Key Excel Terms
Term Explanation 
Excel 
Page 
Range name 
Quick way to create range names,
Use Create from Selection
137
shortcut 
using labels in adjacent cells
on Formulas ribbon
Solver integer 
Constraints on changing cells
Specify in Add Constraint
143
constraints 
forcing them to be integers 
dialog box with Solver 
Row, column 
Quick way of getting row and/or
Highlight row under table
156
sums shortcut 
column sums from a table 
and column to right of table, 
click on  buttom
Nonsmooth 
Avoid use of functions such as IF,
160
functions with 
MIN, MAX, and ABS in Solver
Solver 
models; Solver can’t handle them 
predictably (except with its 
Evolutionary algorithm, the 
topic of Chapter 8) 
TRANSPOSE 
Useful function for transferring
Highlight result range, type 
173
function 
column range to row range, or
=TRANSPOSE(range), press
vice versa
Ctrl+Shift+Enter 
Array functions
Excel functions such as 
Highlight result range, type
174
TRANSPOSE that ﬁll a whole 
formula, press Ctrl+Shift+Enter
range at once 
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4.9 Conclusion
197
a. Determine how to minimize the bus company’s
salary, hiring, and ﬁring costs over the next ﬁve
years.
b. Use SolverTable to determine how the total number
hired, total number ﬁred, and total cost change as
the unit hiring and ﬁring costs each increase by the
same percentage.
46. During each four-hour period, the Smalltown police
force requires the following number of on-duty police
ofﬁcers: eight from midnight to 4 A.M.; seven from
4 A.M. to 8 A.M.; six from 8 A.M. to noon; six from
noon to 4 P.M.; ﬁve from 4 P.M. to 8 P.M.; and four from
8 P.M. to midnight. Each police ofﬁcer works two
consecutive four-hour shifts.
a. Determine how to minimize the number of police ofﬁ-
cers needed to meet Smalltown’s daily requirements.
b. Use SolverTable to see how the number of police
ofﬁcers changes as the number of ofﬁcers needed
from midnight to 4 A.M. changes.
47. Shoemakers of America forecasts the following
demand for the next six months: 5000 pairs in month
1; 6000 pairs in month 2; 7000 pairs in month 3; 9000
pairs in month 4; 6000 pairs in month 5; 5000 pairs in
month 6. It takes a shoemaker 20 minutes to produce a
pair of shoes. Each shoemaker works 150 hours per
month plus up to 40 hours per month of overtime.
A shoemaker is paid a regular salary of $2000 per
month plus $20 per hour for overtime. At the
beginning of each month, Shoemakers can either hire
or ﬁre workers. It costs the company $1000 to hire a
worker and $1200 to ﬁre a worker. The monthly
holding cost per pair of shoes is 5% of the cost of
producing a pair of shoes with regular-time labor.
The raw materials in a pair of shoes cost $10. At the
beginning of month 1, Shoemakers has 15 workers 
and 500 pairs of shoes in inventory. Determine how to
minimize the cost of meeting (on time) the demands of
the next six months.
48. NewAge Pharmaceuticals produces the drug NasaMist
from four chemicals. Today, the company must pro-
duce 1000 pounds of the drug. The three active ingre-
dients in NasaMist are A, B, and C. By weight, at least
8% of NasaMist must consist of A, at least 4% of B,
and at least 2% of C. The cost per pound of each
chemical and the amount of each active ingredient in
one pound of each chemical are given in the ﬁle
P04_48.xlsx. At least 100 pounds of chemical 2 must
be used.
a. Determine the cheapest way of producing today’s
batch of NasaMist.
b. Use SolverTable to see how much the percentage
of requirement of A is really costing NewAge. Let
the percentage required vary from 6% to 12%.
49. You have decided to enter the candy business. You are
considering producing two types of candies: Slugger
candy and Easy Out candy, both of which consist
solely of sugar, nuts, and chocolate. At present, you
have in stock 10,000 ounces of sugar, 2000 ounces of
nuts, and 3000 ounces of chocolate. The mixture used
to make Easy Out candy must contain at least 20%
nuts. The mixture used to make Slugger candy must
contain at least 10% nuts and 10% chocolate. Each
ounce of Easy Out candy can be sold for $1.20, and
each ounce of Slugger candy for $1.40.
a. Determine how you can maximize your revenue
from candy sales.
b. Use SolverTable to determine how changes in the
price of Easy Out change the optimal solution.
c. Use SolverTable to determine how changes in the
amount of available sugar change the optimal
solution.
50. Sunblessed Juice Company sells bags of oranges and
cartons of orange juice. Sunblessed grades oranges
on a scale of 1 (poor) to 10 (excellent). At present,
Sunblessed has 100,000 pounds of grade 9 oranges
and 120,000 pounds of grade 6 oranges on hand. The
average quality of oranges sold in bags must be at
least 7, and the average quality of the oranges used to
produce orange juice must be at least 8. Each pound
of oranges that is used for juice yields a revenue of
$1.50 and incurs a variable cost (consisting of labor
costs, variable overhead costs, inventory costs, and so
on) of $1.05. Each pound of oranges sold in bags
yields a revenue of $1.50 and incurs a variable cost 
of $0.70.
a. Determine how Sunblessed can maximize its proﬁt.
b. Use SolverTable to determine how a change in the
cost per bag of oranges changes the optimal
solution.
c. Use SolverTable to determine how a change in the
amount of grade 9 oranges available affects the
optimal solution.
d. Use SolverTable to determine how a change in the
required average quality required for juice changes
the optimal solution.
51. A bank is attempting to determine where its assets
should be invested during the current year. At present,
$500,000 is available for investment in bonds, home
loans, auto loans, and personal loans. The annual rates
of return on each type of investment are known to be
the following: bonds, 10%; home loans, 16%; auto
loans, 13%; personal loans, 20%. To ensure that the
bank’s portfolio is not too risky, the bank’s investment
manager has placed the following three restrictions on
the bank’s portfolio:
■The amount invested in personal loans cannot ex-
ceed the amount invested in bonds.
■The amount invested in home loans cannot exceed
the amount invested in auto loans.
■No more than 25% of the total amount invested can
be in personal loans.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

198
Chapter 4
Linear Programming Models
Help the bank maximize the annual return on its
investment portfolio.
52. Young MBA Erica Cudahy can invest up to $15,000 in
stocks and loans. Each dollar invested in stocks yields
$0.10 proﬁt, and each dollar invested in a loan yields
$0.15 proﬁt. At least 30% of all money invested must
be in stocks, and at least $6000 must be in loans.
Determine how Erica can maximize the proﬁt earned
on her investments.
53. A fertilizer company blends silicon and nitrogen to
produce two types of fertilizers. Fertilizer 1 must be
at least 40% nitrogen and sells for $70 per pound.
Fertilizer 2 must be at least 70% silicon and sells for
$40 per pound. The company can purchase up to
8000 pounds of nitrogen at $15 per pound and up to
10,000 pounds of silicon at $10 per pound.
a. Assuming that all fertilizer produced can be sold,
determine how the company can maximize its
proﬁt.
b. Use SolverTable to explore the effect on proﬁt of
changing the minimum percentage of nitrogen
required in fertilizer 1.
c. Suppose the availabilities of nitrogen and silicon
both increase by the same percentage from their
current values. Use SolverTable to explore the
effect of this change on proﬁt.
54. A chemical manufacturer uses chemicals 1 and 2 to
produce two drugs. Drug 1 must be at least 70%
chemical 1, and drug 2 must be at least 60% 
chemical 2. Up to 50,000 ounces of drug 1 can be sold
at $30 per ounce; up to 60,000 ounces of drug 2 can be
sold at $25 per ounce. Up to 45,000 ounces of chemi-
cal 1 can be purchased at $15 per ounce, and up to
55,000 ounces of chemical 2 can be purchased at 
$18 per ounce. Determine how to maximize the 
manufacturer’s proﬁt.
55. Hiland’s Appliances stocks laptops, TVs, refrigerators,
microwave ovens, and ranges. These products compete
for ﬂoor space, tie up different amounts of capital, and
have different proﬁt margins. The company has also
speciﬁed minimum percentages of these products it
wants to stock (out of the total of all items stocked).
The relevant data are listed in the ﬁle P04_55.xlsx. 
Hiland’s wants no more than $750,000 to be tied 
up in inventory of these products, and it has only
10,000 square feet of ﬂoor space for them. 
a. Assuming that the value of the company’s inven-
tory is the sum of all proﬁt margins of all items,
how many units of each product should the com-
pany stock to maximize its value?
b. If the company could obtain an extra 2500 square
feet of ﬂoor space, how much would it be worth in
terms of extra value? Is the value from 5000 extra
square feet twice as much as the value from 2500
extra square feet? 
56. Many Wall Street ﬁrms use LP models to select a
desirable bond portfolio. The following is a simpliﬁed
version of such a model. Solodrex is considering
investing in four bonds; $1 million is available for
investment. The expected annual return, the worst-case
annual return on each bond, and the duration of each
bond are given in the ﬁle P04_56.xlsx. (The duration of
a bond is a measure of the bond’s sensitivity to interest
rates.) Solodrex wants to maximize the expected return
from its bond investments, subject to three 
constraints:
■The worst-case return of the bond portfolio must
be at least 8%.
■The average duration of the portfolio must be at
most 6. For example, a portfolio that invests
$600,000 in bond 1 and $400,000 in bond 4
has an average duration of [600,000(3) 
400,000(9)]1,000,000  5.4.
■Because of diversiﬁcation requirements, at most
40% of the total amount invested can be invested in
a single bond.
Determine how Solodrex can maximize the expected
return on its investment.
57. A coal company produces coal at three mines and
ships it to four customers. The cost per ton of produc-
ing coal, the ash and sulfur content (per ton) of the
coal, and the production capacity (in tons) for each
mine are given in the ﬁle P04_57.xlsx. The number of
tons of coal demanded by each customer and the cost
(in dollars) of shipping a ton of coal from a mine to
each customer are also provided in this same ﬁle. The
amount of coal shipped to each customer must
contain at most 6% ash and at most 3.5% sulfur.
Show the company how to minimize the cost of meet-
ing customer demands.
58. A furniture company manufactures tables and chairs.
A table requires 40 board feet of wood, and a chair re-
quires 30 board feet of wood. Wood can be purchased
at a cost of $1.50 per board foot, and 40,000 board feet
of wood are available for purchase. It takes two hours
of skilled labor to manufacture an unﬁnished table or
an unﬁnished chair. Three more hours of skilled labor
will turn an unﬁnished table into a ﬁnished table, and
two more hours of skilled labor will turn an unﬁnished
chair into a ﬁnished chair. A total of 5000 hours of
skilled labor is available (and have already been
paid for). All furniture produced can be sold at the
following unit prices: an unﬁnished table, $130; a
ﬁnished table, $220; an unﬁnished chair, $80; a
ﬁnished chair, $175.
a. Determine how to maximize the company’s proﬁt
from manufacturing tables and chairs.
b. Use a two-way SolverTable to see how the
numbers of unﬁnished products (both chairs and
tables) sold depend on the selling prices of
these unﬁnished products. Of course, neither
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4.9 Conclusion
199
unﬁnished selling price should be as large as the
corresponding ﬁnished selling price.
59. A chemical company produces three products, A, B,
and C, and can sell these products in unlimited quan-
tities at the following unit prices: A, $10; B, $55; C,
$100. Producing a unit of A requires one hour of
labor; a unit of B, two hours of labor plus two units of
A; and a unit of C, three hours of labor plus one unit
of B. Any A that is used to produce B cannot be sold.
Similarly, any B that is used to produce C cannot be
sold. A total of 4000 hours of labor is available. Only
as many as 500 units of product C can be sold. Deter-
mine how to maximize the company’s revenue.
60. Abotte Products produces three products, A, B, and C.
The company can sell up to 300 pounds of each
product at the following prices (per pound): product
A, $10; product B, $12; product C, $20. Abotte
purchases raw material at $5 per pound. Each pound
of raw material can be used to produce either 
one pound of A or one pound of B. For a cost of 
$3 per pound processed, product A can be converted to
0.6 pound of product B and 0.4 pound of product C.
For a cost of $2 per pound processed, product B can
be converted to 0.8 pound of product C. Determine
how Abotte can maximize its proﬁt.
61. An investor has $100,000 to invest right now (the
beginning of year 1). The cash ﬂows associated with
ﬁve available investments are listed in the ﬁle
P04_61.xlsx. For example, every dollar invested in
A in year 1 yields $1.40 in year 4. In addition to these
investments, the investor can invest as much money
each year as he wants in CDs, which pay 3% interest.
The investor wants to maximize his available cash
in year 4. Assuming that he can put no more than
$50,000 in any investment, develop an LP model to
help the investor achieve his goal.
62. At the beginning of year 1, you have $10,000. Invest-
ments A and B are available; their cash ﬂows are shown
in the ﬁle P04_62.xlsx. Assume that any money not in-
vested in A or B earns interest at an annual rate of 3%.
a. Determine how to maximize your cash on hand in
year 4.
b. Use SolverTable to determine how a change in the
year 3 yield for investment A changes the optimal
solution to the problem.
c. Use SolverTable to determine how a change in the
year 4 yield of investment B changes the optimal
solution to the problem.
63. You now have $10,000, and the following investment
plans are available to you during the next three years:
■Investment A: Every dollar invested now yields
$0.10 a year from now and $1.30 three years from
now.
■Investment B: Every dollar invested now yields $0.20
a year from now and $1.10 two years from now.
■Investment C: Every dollar invested a year from
now yields $1.50 three years from now.
During each year, you can place uninvested cash in
money market funds that yield 3% interest per year.
However, you can invest at most $5000 in any one of
plans A, B, or C. Determine how to maximize your
cash on hand three years from now.
64. An oil company processes oil into aviation fuel and
heating oil. It costs $65,000 to purchase each 
1000 barrels of oil, which is then distilled and yields
500 barrels of aviation fuel and 500 barrels of heating
oil. Output from the distillation can be sold directly or
processed in the catalytic cracker. If sold after distilla-
tion without further processing, aviation fuel sells for
$80,000 per 1000 barrels, and heating oil sells for
$65,000 per 1000 barrels. It takes one hour to process
1000 barrels of aviation fuel in the catalytic cracker,
and these 1000 barrels can be sold for $145,000. It
takes 45 minutes to process 1000 barrels of heating oil
in the cracker, and these 1000 barrels can be sold for
$125,000. Each day at most 20,000 barrels of oil can
be purchased, and eight hours of cracker time are
available. Determine how to maximize the company’s
proﬁt.
65. All steel manufactured by Allied Steel must meet the
following requirements: between 3.2% and 3.5% car-
bon; between 1.8% and 2.5% silicon; between 0.9%
and 1.2% nickel; tensile strength of at least 45,000
pounds per square inch (psi). The company manufac-
tures steel by combining two alloys. The cost and
properties of each alloy are given in the ﬁle
P04_65.xlsx. Assume that the tensile strength of a
mixture of the two alloys can be determined by aver-
aging the tensile strength of the alloys that are mixed
together. For example, a one-ton mixture that is 40%
alloy 1 and 60% alloy 2 has a tensile strength of
0.4(42,000)  0.6(50,000). Determine how to mini-
mize the cost of producing a ton of steel.
66. United Steel manufactures two types of steel at three
different steel mills. During a given month, each steel
mill has 200 hours of blast furnace time available.
Because of differences in the furnaces at each mill, the
time and cost to produce a ton of steel differ for each
mill, as listed in the ﬁle P04_66.xlsx. Each month, the
company must manufacture at least 500 tons of steel 1
and 600 tons of steel 2. Determine how United Steel can
minimize the cost of manufacturing the desired steel.
67. Based on Heady and Egbert (1964). Walnut Orchard
has two farms that grow wheat and corn. Because of
differing soil conditions, there are differences in the
yields and costs of growing crops on the two farms.
The yields and costs are listed in the ﬁle P04_67.xlsx.
Each farm has 100 acres available for cultivation;
11,000 bushels of wheat and 7000 bushels of corn
must be grown.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

200
Chapter 4
Linear Programming Models
a. Determine a planting plan that will minimize the
cost of meeting these requirements.
b. Use SolverTable to see how the total cost changes if
the requirements for wheat and corn both change by
the same percentage, where this percentage change
can be as low as 50% or as high as 50%.
68. Candy Kane Cosmetics (CKC) produces Leslie
Perfume, which requires chemicals and labor. Two
production processes are available. Process 1
transforms one unit of labor and two units of chemi-
cals into three ounces of perfume. Process two trans-
forms two units of labor and three units of chemicals
into ﬁve ounces of perfume. It costs CKC $3 to pur-
chase a unit of labor and $2 to purchase a unit of
chemicals. Each year up to 20,000 units of labor and
35,000 units of chemicals can be purchased. In the
absence of advertising, CKC believes it can sell
1000 ounces of perfume. To stimulate demand for
Leslie, CKC can hire the beautiful model Jenny
Nelson. Jenny is paid $100 per hour. Each hour Jenny
works for the company is estimated to increase the
demand for Leslie Perfume by 200 ounces. Each
ounce of Leslie Perfume sells for $5. Determine how
CKC can maximize its proﬁt.
69. Federated Oil has reﬁneries in Los Angeles and
Chicago. The Los Angeles reﬁnery can reﬁne up to
two million barrels of oil per year, and the Chicago
reﬁnery up to three million. After the oil is reﬁned, it
is shipped to two distribution points, Houston and
New York City. Federated Oil estimates that each
distribution point can sell up to ﬁve million barrels
per year. Because of differences in shipping and reﬁn-
ing costs, the proﬁt earned (in dollars) per million
barrels of oil shipped depends on where the oil was
reﬁned and on the point of distribution. This informa-
tion is listed in the ﬁle P04_69.xlsx. The company is
considering expanding the capacity of each reﬁnery.
Each million barrels of annual reﬁning capacity 
that is added will cost $120,000 for the Los Angeles
reﬁnery and $150,000 for the Chicago reﬁnery.
Determine how Federated Oil can maximize its
proﬁt (including expansion costs) over a 
10-year period.
70. A feed company produces two types of cattle feed,
both consisting totally of wheat and alfalfa. Feed 1
must contain at least 80% wheat, and feed 2 must con-
tain at least 60% alfalfa. Feed 1 sells for $1.50 per
pound, and feed 2 sells for $1.30 per pound. The
company can purchase up to 1000 pounds of wheat at
$0.50 per pound and up to 800 pounds of alfalfa at
$0.40 per pound. Demand for each type of feed is
unlimited. Determine how to maximize the company’s
proﬁt.
71. Carrington Oil produces gas 1 and gas 2 from two
types of crude oil: crude 1 and crude 2. Gas 1 is
allowed to contain up to 4% impurities, and gas 2
is allowed to contain up to 3% impurities. Gas 1
sells for $72 per barrel, whereas gas 2 sells for
$84 per barrel. Up to 4200 barrels of gas 1 and up to
4300 barrels of gas 2 can be sold. The cost per barrel
of each crude, their availability, and the level of
impurities in each crude are listed in the ﬁle
P04_71.xlsx. Before blending the crude oil into gas,
any amount of each crude can be “puriﬁed” for a cost
of $3.50 per barrel. Puriﬁcation eliminates half of the
impurities in the crude oil.
a. Determine how to maximize proﬁt.
b. Use SolverTable to determine how an increase in
the availability of crude 1 affects the optimal proﬁt.
c. Use SolverTable to determine how an increase in
the availability of crude 2 affects the optimal proﬁt.
d. Use SolverTable to determine how a change in the
price of gas 2 changes the optimal proﬁt and the
types of gas produced.
72. Based on Thomas (1971). A toy company produces
toys at two plants and sells them in three regions. The
current demands at these regions are given in the ﬁle
P04_72.xlsx. Each plant can produce up to 2500 units.
Each toy sells for $10, and the cost of producing and
shipping a toy from a given plant to a region is given
in the same ﬁle. The company can advertise locally
and nationally. Each $1 spent on a local ad raises
sales in a region by 0.5 units, whereas each $1 spent
advertising nationally increases sales in each region
by 0.3 units.
a. Determine how the company can maximize its
proﬁt.
b. If sales stimulated by advertising exhibits
diminishing returns, how would you change your
model?
73. A company produces two products: A and B. Product
A sells for $11 per unit and product B sells for
$23 per unit. Producing a unit of product A requires
two hours on assembly line 1 and one unit of raw ma-
terial. Producing a unit of product B requires two units
of raw material, one unit of A, and two hours on as-
sembly line 2. On line 1, 1300 hours of time are avail-
able, and 500 hours are available on line 2. A unit of
raw material can be bought (for $5 a unit) or produced
(at no cost) by using two hours of time on line 1.
a. Determine how to maximize proﬁt.
b. The company will stop buying raw material when
the price of raw material exceeds what value? (Use
SolverTable.)
74. A bank needs exactly two employees working each
hour from 9 A.M. to 5 P.M. Workers can work the shifts
and are paid the wages listed in the ﬁle P04_74.xlsx.
For example, a worker working 9 A.M. to 2 P.M. is paid
$42.00. Find an assignment of workers that provides
enough workers at minimum cost.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4.9 Conclusion
201
75. Based on Gaballa and Pearce (1979). Northwest
Airlines has determined that it needs the number of
ticket agents during each hour of the day listed in the
ﬁle P04_75.xlsx. Workers work nine-hour shifts, one
hour of which is for lunch. The lunch hour can be
either the fourth or ﬁfth hour of their shift. What is the
minimum number of workers needed by Northwest?
76. A rock company uses ﬁve types of rocks to ﬁll four
orders. The phosphate content, availability of each
type of rock, and the production cost per pound for
each rock are listed in the ﬁle P04_76.xlsx, as well as
the size of each order and the minimum and maximum
phosphate percentage in each order. What is the
cheapest way to ﬁll the orders?
77. An automobile manufacturer needs to plan its produc-
tion for the next year. Demands for the next 12 months
are forecasted to be 940, 790, 360, 720, 270, 130, 160,
300, 990, 290, 280, and 790. Other relevant informa-
tion is as follows:
■Workers are paid $5000 per month.
■It costs $500 to hold a car in inventory for a month.
The holding cost is based on each month’s ending
inventory.
■It costs $4000 to hire a worker.
■It costs $6000 to ﬁre a worker.
■Each worker can make up to eight cars a month.
■Workers are hired and ﬁred at the beginning of
each month.
■At the beginning of month 1 there are 500 cars in
inventory and 60 workers.
How can the company minimize the cost of meeting
demand for cars on time?
78. An oil company produces gasoline from ﬁve inputs.
The cost, density, viscosity, and sulfur content, and the
number of barrels available of each input are listed in
the ﬁle P04_78.xlsx. Gasoline sells for $72 per barrel.
Gasoline can have a density of at most 0.98 units per
barrel, a viscosity of at most 37 units per barrel, and a
sulfur content of at most 3.7 units per barrel.
a. How can the company maximize its proﬁt?
b. Describe how the optimal solution to the problem
changes as the price of gasoline ranges from $65 to
$80 per barrel.
79. The HiTech company produces Blu-Ray disc players.
Estimated demands for the next four quarters are 5000,
10,000, 8000, and 2000. At the beginning of quarter 1,
HiTech has 60 workers. It costs $2000 to hire a worker
and $4000 to ﬁre a worker. Workers are paid $10,000
per quarter plus $80 for each unit they make during
overtime. A new hire can make up to 60 units per
quarter during regular-time, whereas a previously
hired worker can make up to 90 units per quarter. Any
worker can make up to 20 units per quarter during
overtime. Each disc player is sold for $160. It costs
$20 to hold a disc player in inventory for a quarter.
Assume workers are hired and ﬁred at the beginning of
each quarter and that all of a quarter’s production is
available to meet demand for that quarter. Initial inven-
tory at the beginning of quarter 1 is 1000 disc players.
How can the company maximize its proﬁt? Assume that
demand is lost if insufﬁcient stock is available. That is,
there is no backlogging of demand (and there is no
requirement that HiTech must satisfy all of its demand).
Skill-Extending Problems
80. MusicTech manufactures and sells a portable music
device called an mTune (similar to an iPod). At
beginning of month 1, the company has $100,000
and 15 employees. Each machine the company owns
has the capacity to make up to 900 mTunes per
month, and each worker can make up to 600 mTunes
per month. The company cannot use more labor or
machine capacity than is available in any given
month. Also, the company wants to have a
nonnegative cash balance at all points in time.
The company’s costs are the following:
■Holding cost of $2 each month per mTune in
ending inventory
■Cost in month 1 of buying machines ($3000 per
machine)
■Raw material cost of $6 per mTune
■Monthly worker wage of $3500
■Hiring cost of $4000 per worker
■Firing cost of $5000 per worker
In the absence of advertising, the monthly demands in
months 1 through 6 are forecasted to be 5000, 8000,
7000, 6000, 5000, and 5000. However, MusicTech can
increase demand each month by advertising. Every
$10 (up to a maximum of $50,000 per month) spent
on advertising during a month increases demand for
that month by one mTune. The devices are sold for
$75 each. The sequence of events in any month is that
the company buys machines (month 1 only), hires and
ﬁres workers, makes the mTunes, advertises, pays all
costs for the month, and collects revenues for the
month. Develop a model to maximize proﬁt (total
revenue minus total costs) earned during the next
six months.
81. You want to take out a $300,000 loan on a 20-year
mortgage with end-of-month payments. The annual
rate of interest is 6%. Twenty years from now, you will
need to make a $40,000 ending balloon payment. Be-
cause you expect your income to increase, you want to
structure the loan so at the beginning of each year,
your monthly payments increase by 2%.
a. Determine the amount of each year’s monthly
payment. You should use a lookup table to look 
up each year’s monthly payment and to look up 
the year based on the month (e.g., month 13 is 
year 2, etc.).
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

202
Chapter 4
Linear Programming Models
b. Suppose payment each month is to be the same,
and there is no balloon payment. Show that the
monthly payment you can calculate from your
spreadsheet matches the value given by the Excel
PMT function PMT(0.0612,240,300000,0,0).
82. A graduated payment mortgage (GPM) enables the
borrower to have lower payments earlier in the
mortgage and increased payments later on. The
assumption is the borrower’s income will increase
over time so that it will be easier for the borrower
to meet all payments. Suppose you borrow $60,000
on a 30-year monthly mortgage. You obtain a GPM
where monthly payments increase 7.5% per year
through year 5 and then remain constant from year 5
through year 30. For annual interest rates of 10%,
11%, 12%, 13%, and 14%, use Solver to ﬁnd the
amount of each year’s monthly payment.
83. Suppose you are planning for retirement. At the
beginning of this year and each of the next 39 years,
you plan to contribute some money to your retirement
fund. Each year, you plan to increase your retirement
contribution by $500. When you retire in 40 years,
you plan to withdraw $100,000 at the beginning of
each year for the next 20 years. You assume the
following about the yields of your retirement
investment portfolio:
■During the ﬁrst 20 years, your investments will
earn 10% per year.
■During all other years, your investments will earn
5% per year.
All contributions and withdrawals occur at the
beginnings of the respective years.
a. Given these assumptions, what is the least amount
of money you can contribute this year and still
have enough to make your retirement withdrawals?
b. How does your answer change if inﬂation is 2%
per year and your goal is to withdraw $100,000 per
year (in today’s dollars) for 20 years?
84. Based on Brams and Taylor (2000). Suppose that Eli
Lilly and Pﬁzer are going to merge. Merger negotia-
tions must settle the following issues:
■What will the name of the merged corporation be?
■Will corporate headquarters be in Indianapolis
(Lilly wants this) or New York (Pﬁzer wants this)?
■Which company’s chairperson will be chairperson
of the merged corporation?
■Which company gets to choose the CEO?
■On the issue of layoffs, what percentage of each
company’s view will prevail?
Brams developed a remarkably simple method for the
two adversaries to settle their differences. (This same
method could be used to settle differences between
other adversaries, such as a husband and wife in a
divorce, Arab and Israel in Middle East, and so on.)
Each adversary allocates 100 points between all of the
issues. These allocations are listed in the ﬁle
P04_84.xlsx. For example, Lilly believes headquarters
is worth 25 points, whereas Pﬁzer thinks headquarters
is only worth 10 points. Layoffs may be divided (for
example, Lilly might get 70% of the say in layoffs and
Pﬁzer 30%), but on all other issues, only one company
gets its way. The adjusted winner procedure says
that the best way to make decisions on each issue is to:
■give each adversary the same number of points;
■ensure that each company prefers its allocation to
the allocation of its opponent;
■maximize the number of points received by either
participant.
Such a solution is equitable (because each party
receives the same number of points) and is envy-free
(because neither side prefers what its opponent
receives to what it receives). It can also be shown that
the adjusted winner procedure yields a Pareto optimal
solution. This means that no other allocation can make
one player better off without making the other player
worse off. Find the adjusted winner solution to the
merger example. Also show that the adjusted winner
solution for this example is Pareto optimal.
85. AdminaStar processes Medicare claims. At the
beginning of month 1 they have a backlog of 40,000
difﬁcult claims and 60,000 easy claims. The predicted
claim volume for months 1 through 8 is listed in the
ﬁle P04_85.xlsx. At the beginning of month 1,
AdminaStar has 70 experienced claim processors. Each
month it can hire up to 10 trainees. At the end of each
month, 5% of experienced employees quit, and 20% of
trainees are ﬁred. Each worker is available for 160 hours
per month. The number of minutes needed by each
worker to process each type of claim is listed in this
same ﬁle. AdminaStar wants ending inventory for
months 2 through 7 to be no greater than 50,000 of
each type of claim. All claims must be processed by
the end of month 8. What is the minimum number of
trainees that need to be hired during months 1 to 8?
(Note: Trainees must be integers. Experienced
workers will probably end up being fractional. You
have two options. First, you can ignore the fractional
values. Second, you can use the ROUND function to
round them to the nearest integers. However, this
makes the model nonlinear, so you won't be able
to use Solver’s Simplex LP method. Try this second
option.)
86. Based on Charnes and Cooper (1955). A small
company is trying to determine employee salary
based on the following attributes: effectiveness,
responsibility, initiative, experience, education, self-
expression, planning ability, intelligence, and the
ability to get things done. Each of the company’s
seven executives has been rated on each of these attrib-
utes, with the ratings shown in the ﬁle P04_86.xlsx.
The company wants to set each executive’s salary
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4.9 Conclusion
203
by multiplying a weight for each attribute by the
executive’s score on each attribute. The salaries must
satisfy the following constraints:
■The salary of a lower-numbered executive must be
at least as large as the salary of a higher-numbered
executive.
■Executive 1’s salary can be at most $160,000 and
executive 7’s salary must be at least $40,000.
■The salaries of executives 1, 5, and 7 should match
$160,000, $100,000, and $40,000, respectively, as
closely as possible.
■All attribute weights must be nonnegative.
Develop a method for setting salaries. [Hint: For exec-
utives 1, 5, and 7, deﬁne “over” and “under” changing
cells and add a constraint such as Executive 5 salary
 (Amount executive 5 salary under $100,000)
 (Amount executive 5 salary over $100,000) 
$100,000. Then the target cell to minimize is the sum
of over and under changing cells for positions 1, 5,
and 7. If you did not include the over and under
changing cells, why would your model fail to be
linear?]
87. During the next four quarters, Dorian Auto must meet
(on time) the following demands for cars: 4000
in quarter 1; 2000 in quarter 2; 5000 in quarter 3;
1000 in quarter 4. At the beginning of quarter 1,
there are 300 autos in stock. The company has the
capacity to produce at most 3000 cars per quarter.
At the beginning of each quarter, the company can
change production capacity. It costs $100 to increase
quarterly production capacity by one unit. For
example, it would cost $10,000 to increase capacity
from 3000 to 3100. It also costs $50 per quarter to
maintain each unit of production capacity (even if it
is unused during the current quarter). The variable cost
of producing a car is $2000. A holding cost of $150
per car is assessed against each quarter’s ending inven-
tory. At the end of quarter 4, plant capacity must be at
least 4000 cars.
a. Determine how to minimize the total cost incurred
during the next four quarters.
b. Use SolverTable to determine how much the total
cost increases as the required capacity at the end of
quarter 4 increases (from its current value of 4000).
88. The Internal Revenue Service (IRS) has determined
that during each of the next 12 months it will need
the numbers of supercomputers given in the ﬁle
P04_88.xlsx. To meet these requirements, the IRS
rents supercomputers for a period of one, two, or
three months. It costs $1000 to rent a supercomputer
for one month, $1800 for two months, and $2500 for
three months. At the beginning of month 1, the IRS
has no supercomputers.
a. Determine the rental plan that meets the require-
ments for the next 12 months at minimum cost.
You can assume that fractional rentals are allowed.
Thus, if your solution says to rent 140.6 computers
for one month, you can round this up to 141 or
down to 140 without much effect on the total cost.
b. Suppose the monthly requirement increases any-
where from 10% to 50% each month. (Assume that
whatever the percentage increase is, it is the same
each month.) Use SolverTable to see whether
the total rental cost increases by this same
percentage.
89. You own a wheat warehouse with a capacity of 20,000
bushels. At the beginning of month 1, you have 6000
bushels of wheat. Each month, wheat can be bought
and sold at the prices per bushel listed in the ﬁle
P04_89.xlsx. The sequence of events during each
month is as follows:
■You observe your initial stock of wheat.
■You can sell any amount of wheat up to your initial
stock at the current month’s selling price.
■You can buy as much wheat as you want, subject to
the limitation of warehouse size.
a. Determine how to maximize the proﬁt earned
over the next 10 months.
b. Use SolverTable to determine how a change
in the capacity of the warehouse affects the
optimal solution.
90. You can calculate the risk index of an investment by
taking the absolute values of percentage changes in the
value of the investment for each year and averaging
them. Suppose you are trying to determine the
percentages of your money to invest in several poten-
tial investments. The ﬁle P04_90.xlsx lists the annual
returns (percentage changes in value) for these invest-
ments for a 20-year period. Let the risk index of a
portfolio be the weighted average of the risk indices of
these investments, where the weights are the fractions
of the portfolio assigned to the investments. Suppose
that the amount of each investment must be between
10% and 40% of the total invested. You would like the
risk index of your portfolio to equal 0.16, and your
goal is to maximize the expected return on your port-
folio. Determine the maximum expected return on
your portfolio, subject to the stated constraints. Use
the average return earned by each investment during
the 20-year period as your estimate of expected return.
91. Based on Magoulas and Marinos-Kouris (1988). An
oil company produces two products: regular and pre-
mium gasoline. Each product contains 0.15 gram of
lead per liter. The two products are produced from
these six inputs: reformate, ﬂuid catalytic cracker
gasoline (FCG), isomerate (ISO), polymer (POL),
methyl tertiary butyl ether (MTBE), and butane
(BUT). Each input has four attributes: research octane
number (RON), Reid vapor pressure (RVP), ASTM
volatility at 70 degrees Celsius, and ASTM volatility
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

204
Chapter 4
Linear Programming Models
at 130 degrees Celsius. (ASTM is the American
Society for Testing and Materials.) The attributes and
daily availability (in liters) of each input are listed in
the ﬁle P04_91.xlsx. The requirements for each output
are also listed in this ﬁle. The daily demand (in thou-
sands of liters) for each product must be met, but more
can be produced if desired. The RON and ASTM re-
quirements are minimums; the RVP requirement is a
maximum. Regular gasoline sells for $0.754 per liter;
premium gasoline for $0.819. Before each product is
ready for sale, 0.15 gram per liter of lead must be
removed. The cost of removing 0.1 gram per liter is
$0.213. At most, 38% of each type of gasoline can
consist of FCG. How can the company maximize its
daily proﬁt?
92. Capsule Drugs manufactures two drugs. The drugs are
produced by blending two chemicals. By weight, drug
1 must contain at least 65% chemical 1, and drug 2
must contain at least 55% chemical 1. Drug 1 sells for
$6 per ounce, and drug 2 sells for $4 per ounce.
Chemicals 1 and 2 can be produced by one of two pro-
duction processes. Running process 1 for an hour re-
quires 7 ounces of raw material and 2 hours skilled
labor, and it yields 3 ounces of each chemical. Run-
ning process 2 for an hour requires 5 ounces of raw
material and 3 hours of skilled labor, and it yields
3 ounces of chemical 1 and 1 ounce of chemical 2.
A total of 3000 hours of skilled labor and 5000 ounces
of raw material are available. Determine how to
maximize Capsule’s sales revenues.
93. Molecular Products produces three chemicals: B, C,
and D. The company begins by purchasing chemical A
for a cost of $650 per 100 liters. For an additional cost
of $320 and the use of three hours of skilled labor, 100
liters of A can be transformed into 40 liters of C and
60 liters of B. Chemical C can either be sold or
processed further. It costs $130 and one hour of skilled
labor to process 100 liters of C into 60 liters of D and
40 liters of B. For each chemical, the selling price per
100 liters and the maximum amount (in 100s of liters)
tha can be sold are listed in the ﬁle P04_93.xlsx.
A maximum of 200 labor hours is available.
Determine how Molecular can maximize its proﬁt.
94. Bexter Labs produces three products: A, B, and C.
Bexter can sell up to 3000 units of product A, up to
2000 units of product B, and up to 2000 units of prod-
uct C. Each unit of product C uses two units of A and
three units of B and incurs $5 in processing costs.
Products A and B are produced from either raw mater-
ial 1 or raw material 2. It costs $6 to purchase and
process one unit of raw material 1. Each processed
unit of raw material 1 yields two units of A and three
units of B. It costs $3 to purchase and process a unit
of raw material 2. Each processed unit of raw material
2 yields one unit of A and two units of B. The unit
prices for the products are A, $5; B, $4; C, $25. The
quality levels of each product are: A, 8; B, 7; C, 6.
The average quality level of the units sold must be at
least 7. Determine how to maximize Bexter’s proﬁt.
95. Mondo Motorcycles is determining its production
schedule for the next four quarters. Demands for
motorcycles are forecasted to be 400 in quarter 1;
700 in quarter 2; 500 in quarter 3; 200 in quarter 4.
Mondo incurs four types of costs, as described here:
■It costs Mondo $800 to manufacture each
motorcycle.
■At the end of each quarter, a holding cost of $100
per motorcycle left in inventory is incurred.
■When production is increased from one quarter to
the next, a cost is incurred, primarily for training
employees. If the increase in production is x motor-
cycles, the cost is $700x.
■When production is decreased from one quarter to
the next, a cost is incurred, primarily for severance
pay and decreased morale. If the decrease in
production is x motorcycles, the cost is $600x.
All demands must be met on time, and a quarter’s
production can be used to meet demand for the
current quarter (as well as future quarters). During
the quarter immediately preceding quarter 1, 500
Mondos were produced. Assume that at the beginning
of quarter 1, no Mondos are in inventory.
a. Determine how to minimize Mondo’s total cost
during the next four quarters.
b. Use SolverTable to determine how Mondo’s
optimal production schedule would be affected by
a change in the cost of increasing production from
one quarter to the next.
c. Use SolverTable to determine how Mondo’s
optimal production schedule would be affected by
a change in the cost of decreasing production from
one quarter to the next.
96. An automobile manufacturing company has a
$1,500,000 advertising budget. To increase its automo-
bile sales, the company is considering advertising in
newspapers and on television. The more the company
uses a particular medium, the less effective each
additional ad is. The ﬁle P04_96.xlsx lists the number
of new customers reached by each ad. Each newspaper
ad costs $1000, and each television ad costs $10,000.
At most, 30 newspaper ads and 15 television ads can
be placed. How can the company maximize the num-
ber of new customers created by advertising?
97. Broker Sonya Wong is currently trying to maximize
her proﬁt in the bond market. Four bonds are available
for purchase and sale at the bid and ask prices shown
in the ﬁle P04_97.xlsx. Sonya can buy up to 1000
units of each bond at the ask price or sell up to 1000
units of each bond at the bid price. During each of the
next three years, the person who sells a bond will pay
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4.9 Conclusion
205
the owner of the bond the cash payments listed in the
same ﬁle. Sonya’s goal is to maximize her revenue
from selling bonds minus her payment for buying
bonds, subject to the constraint that after each year’s
payments are received, her current cash position (due
only to cash payments from bonds and not purchases
or sales of bonds) is nonnegative. Note that her cur-
rent cash position can depend on past coupons and
that cash accumulated at the end of each year earns
5.25% annual interest. Determine how to maximize
net proﬁt from buying and selling bonds, subject to
the constraints previously described. Why do you
think we limit the number of units of each bond that
can be bought or sold?
98. Budget Auto produces inexpensive cars. Each car is
sold for $7900. The raw material in a car costs
$5000. Labor time and robot time are needed to pro-
duce cars. A worker can do the needed labor on, at
most, 100 cars per month; a robot can complete the
needed work on, at most, 200 cars per month. The
company currently has four workers. Each worker re-
ceives a monthly salary of $6000. It costs $2500 to
hire a worker and $1000 to ﬁre a worker. Hired
workers are fully productive during the month they
are hired. Robots must be bought at the beginning of
month 1 at a cost of $15,000 per robot. The (assumed
known) demand for cars is listed in the ﬁle
P04_98.xlsx. At the end of each month, the company
incurs a holding cost of $200 per car. How can the
company maximize the proﬁt earned during the next
six months?
99. The ZapCon Company is considering investing in
three projects. If it fully invests in a project, the
realized cash ﬂows (in millions of dollars) will be as
listed in the ﬁle P04_99.xlsx. For example, project 1
requires a cash outﬂow of $3 million today and re-
turns $5.5 million three years from now. Today Zap-
Con has $2 million in cash. At each time point (0,
0.5, 1, 1.5, 2, and 2.5 years from today), the company
can, if desired, borrow up to $2 million at 3.5% (per
six months) interest. Leftover cash earns 3% (per
six months) interest. For example, if after borrowing
and investing at time 0, ZapCon has $1 million, it
would receive $30,000 in interest at time 0.5 year.
The company’s goal is to maximize cash on hand
after cash ﬂows three years from now are accounted
for. What investment and borrowing strategy should
it use? Assume that the company can invest in a
fraction of a project. For example, if it invests in 0.5
of project 3, it has, for example, cash outﬂows of
–$1 million at times 0 and 0.5.
100. You are a CFA (chartered ﬁnancial analyst). An
overextended client has come to you because she
needs help paying off her credit card bills. She owes
the amounts on her credit cards listed in the ﬁle
P04_100.xlsx. The client is willing to allocate up to
$5000 per month to pay off these credit cards. All
cards must be paid off within 36 months. The client’s
goal is to minimize the total of all her payments. To
solve this problem, you must understand how interest
on a loan works. To illustrate, suppose the client pays
$5000 on Saks during month 1. Then her Saks bal-
ance at the beginning of month 2 is $20,000 
[$5000  0.005(20,000)]. This follows because she
incurs 0.005(20,000) in interest charges on her Saks
card during month 1. Help the client solve her prob-
lem. After you have solved this problem, give an in-
tuitive explanation of the solution found by Solver.
101. Aluminaca produces 100-foot-long, 200-foot-long,
and 300-foot-long ingots for customers. This week’s
demand for ingots is listed in the ﬁle P04_101.xlsx.
Aluminaca has four furnaces in which ingots can be
produced. During one week, each furnace can be
operated for 50 hours. Because ingots are produced
by cutting up long strips of aluminum, longer ingots
take less time to produce than shorter ingots. If a fur-
nace is devoted completely to producing one type of
ingot, the number it can produce in one week is listed
in the same ﬁle. For example, furnace 1 could pro-
duce 350 300-foot ingots per week. The material in
an ingot costs $10 per foot. A customer who wants a
100-foot or 200-foot ingot will accept an ingot of
that length or longer. How can Aluminaca minimize
the material costs incurred in meeting required
weekly demands?
102. Each day, Eastinghouse produces capacitors during
three shifts: 8 A.M. to 4 P.M., 4 P.M. to 12 A.M., and
12 A.M. to 8 A.M. The hourly salary paid to the
employees on each shift, the price charged for each
capacitor made during each shift, and the number of
defects in each capacitor produced during a given
shift are listed in the ﬁle P04_102.xlsx. The company
can employ up to 125 workers, and each worker can
be assigned to one of the three shifts. A worker pro-
duces 10 capacitors during a shift, but due to machin-
ery limitations, no more than 50 workers can be as-
signed to any shift. Each capacitor produced can be
sold, but the average number of defects per capacitor
for the day’s production cannot exceed 3. Determine
how Eastinghouse can maximize its daily proﬁt.
103. During the next three months, a heating and cooling
company must meet (on time) the following demands
for air conditioners: month 1, 300; month 2, 400;
month 3, 500. Air conditioners can be produced in
either New York or Los Angeles. It takes 1.5 hours of
skilled labor to produce an air conditioner in Los An-
geles, and it takes 2 hours in New York. It costs $400
to produce an air conditioner in Los Angeles, and it
costs $350 in New York. During each month, each
city has 420 hours of skilled labor available. It costs
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

206
Chapter 4
Linear Programming Models
$100 to hold an air conditioner in inventory for a
month. At the beginning of month 1, the company
has 200 air conditioners in stock. Determine how the
company can minimize the cost of meeting air condi-
tioner demands for the next three months.
104. Gotham City National Bank is open Monday through
Friday from 9 A.M. to 5 P.M. From past experience,
the bank knows that it needs the numbers of tellers
listed in the ﬁle P04_104.xlsx. Gotham City Bank
hires two types of tellers. Full-time tellers work
9 A.M. to 5 P.M. ﬁve days a week, with one hour off
each day for lunch. The bank determines when a full-
time employee takes his or her lunch hour, but each
teller must go between 12 P.M. and 1 P.M. or between
1 P.M. and 2 P.M. Full-time employees are paid (in-
cluding fringe beneﬁts) $15 per hour, which includes
payment for lunch hour. The bank can also hire part-
time tellers. Each part-time teller must work exactly
four consecutive hours each day. A part-time teller is
paid $9 per hour and receives no fringe beneﬁts. To
maintain adequate quality of service, the bank has
decided that, at most, ﬁve part-time tellers can be
hired. Determine how to meet the bank’s teller
requirements at minimum cost.
105. Based on Rothstein (1973). The Springﬁeld City
Police Department employs 30 police ofﬁcers. Each
ofﬁcer works ﬁve days per week. The crime rate
ﬂuctuates with the day of the week, so the number of
police ofﬁcers required each day depends on the day
of the week, as follows: Saturday, 28; Sunday, 18;
Monday, 18; Tuesday, 24; Wednesday, 25; Thursday,
16; Friday, 21. The police department wants to
schedule police ofﬁcers to minimize the number
whose days off are not consecutive. Determine how
to accomplish this goal.
106. Based on Charnes and Cooper (1955). Alex Cornby
makes his living buying and selling corn. On January
1, he has 5000 bushels of corn and $10,000 in cash.
On the ﬁrst day of each month, Alex can buy corn at
the forecasted prices per bushel listed in the ﬁle
P04_106.xlsx. On the last day of each month, Alex
can sell corn at the forecasted prices listed in the
same ﬁle. Alex stores his corn in a warehouse that
can hold 10,000 bushels of corn. He must be able to
pay cash for all corn at the time of purchase. Deter-
mine how Alex can maximize his cash on hand at the
end of April.
107. City 1 produces 500 tons of waste per day, and city 2
produces 400 tons of waste per day. Waste must be
incinerated at incinerator 1 or 2, and each incinerator
can process up to 500 tons of waste per day. The cost
to incinerate waste is $40 per ton at incinerator 1 and
$30 per ton at incinerator 2. Incineration reduces
each ton of waste to 0.2 ton of debris, which must be
dumped at one of two landﬁlls. Each landﬁll can
receive at most 200 tons of debris per day. It costs
$3 per mile to transport a ton of material (either de-
bris or waste). Distances (in miles) between locations
are listed in the ﬁle P04_107.xlsx. Determine how to
minimize the total cost of disposing of the waste
from both cities.
108. Based on Smith (1965). Silicon Valley Corporation
(Silvco) manufactures transistors. An important as-
pect of the manufacture of transistors is the melting
of the element germanium (a major component of a
transistor) in a furnace. Unfortunately, the melting
process yields germanium of highly variable quality.
Two methods can be used to melt germanium.
Method 1 costs $50 per transistor, and method 2
costs $70 per transistor. The qualities of germanium
obtained by methods 1 and 2 are listed in the ﬁle
P04_108.xlsx. Silvco can reﬁre melted germanium in
an attempt to improve its quality. It costs $25 to reﬁre
the melted germanium for one transistor. The results
of the reﬁring process are also listed in the same ﬁle.
For example, if grade 3 germanium is reﬁred, half of
the resulting germanium will be grade 3, and the
other half will be grade 4. Silvco has sufﬁcient fur-
nace capacity to melt or reﬁre germanium for at most
20,000 transistors per month. Silvco’s monthly
demands are for 1000 grade 4 transistors, 2000 grade
3 transistors, 3000 grade 2 transistors, and 3000 grade
1 transistors. Determine how to minimize the cost of
producing the needed transistors.
109. The Fresh Turkey Company produces two types of
turkey cutlets for sale to fast-food restaurants. Each
type of cutlet consists of white meat and dark meat.
Cutlet 1 sells for $2.79 per pound and must consist of
at least 70% white meat. Cutlet 2 sells for $1.89 per
pound and must consist of at least 60% white meat.
At most, 10,000 pounds of cutlet 1 and 4000 pounds
of cutlet 2 can be sold. The two types of turkey used
to manufacture the cutlets are purchased from a
turkey farm. Each type 1 turkey costs $8.99 and yields
six pounds of white meat and two pounds of dark
meat. Each type 2 turkey costs $5.99 and yields three
pounds of white meat and three pounds of dark meat.
Determine how to maximize Fresh Turkey’s proﬁt.
110. The production line employees at Grummins Engine
work four days a week, 10 hours a day. Each day of
the week, the following minimum numbers of line
employees are needed: Monday through Friday,
70 employees; Saturday and Sunday, 30 employees.
Grummins employs 110 line employees. Determine
how to maximize the number of consecutive days off
received by these employees. For example, a worker
who gets Sunday, Monday, and Wednesday off
receives two consecutive days off.
111. Based on Lanzenauer et al. (1987). To process
income tax forms, the IRS ﬁrst sends each form
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4.9 Conclusion
207
through the data preparation (DP) department, where
information is coded for computer entry. Then the
form is sent to data entry (DE), where it is entered
into the computer. During the next 3 weeks, the fol-
lowing quantities of forms will arrive: week 1,
40,000; week 2, 30,000; week 3, 60,000. All employ-
ees work 40 hours per week and are paid $500 per
week. Data preparation of a form requires 15 min-
utes, and data entry of a form requires 10 minutes.
Each week, an employee is assigned to either data
entry or data preparation. The IRS must complete
processing all forms by the end of week 5 and wants
to minimize the cost of accomplishing this goal. As-
sume that all workers are full-time employees and
that the IRS will have the same number of employees
each week. Assume that all employees are capable of
performing data preparation and data entry. Deter-
mine how many workers should be working and how
the workers should allocate their hours during the
next ﬁve weeks.
112. Based on Robichek et al. (1965). The Korvair
Department Store has $100,000 in available cash. At
the beginning of each of the next six months, Korvair
will receive revenues and pay bills as listed in the
ﬁle P04_112.xlsx. It is clear that Korvair will have a
short-term cash ﬂow problem until the store receives
revenues from the Christmas shopping season. To
solve this problem, Korvair must borrow money.
At the beginning of July, the company takes out a
six-month loan. Any money borrowed for a six-
month period must be paid back at the end of De-
cember along with 9% interest (early payback does
not reduce the total interest of the loan). Korvair can
also meet cash needs through month-to-month bor-
rowing. Any money borrowed for a one-month pe-
riod incurs an interest cost of 4% per month. Deter-
mine how Korvair can minimize the cost of paying
its bills on time.
113. Mackk Engine produces diesel trucks. New govern-
ment emission standards have dictated that the aver-
age pollution emissions of all trucks produced in the
next three years cannot exceed 10 grams per truck.
Mackk produces two types of trucks. Each type
1 truck sells for $20,000, costs $15,000 to manufac-
ture, and emits 15 grams of pollution. Each type 2
truck sells for $17,000, costs $14,000 to manufac-
ture, and emits 5 grams of pollution. Production ca-
pacity limits total truck production during each year
to at most 320 trucks. The maximum numbers of
each truck type that can be sold during each of the
next three years are listed in the ﬁle P04_113.xlsx.
Demand can be met from previous production or the
current year’s production. It costs $2000 to hold one
truck (of any type) in inventory for one year. Deter-
mine how Mackk can maximize its proﬁt during the
next three years.
114. Each hour from 10 A.M. to 7 P.M., Bank One receives
checks and must process them. Its goal is to process
all checks the same day they are received. The bank
has 13 check processing machines, each of which
can process up to 500 checks per hour. It takes one
worker to operate each machine. Bank One hires
both full-time and part-time workers. Full-time work-
ers work 10 A.M. to 6 P.M., 11 A.M. to 7 P.M., or
12 P.M. to 8 P.M. and are paid $160 per day. Part-time
workers work either 2 P.M. to 7 P.M. or 3 P.M. to 8 P.M.
and are paid $75 per day. The numbers of checks re-
ceived each hour are listed in the ﬁle P04_114.xlsx.
In the interest of maintaining continuity, Bank One
believes that it must have at least three full-time
workers under contract. Develop a work schedule
that processes all checks by 8 P.M. and minimizes
daily labor costs.
115. Owens-Wheat uses two production lines to produce
three types of ﬁberglass mat. The demand require-
ments (in tons) for each of the next four months are
shown in the ﬁle P04_115.xlsx. If it were dedicated
entirely to the production of one product, a line 1
machine could produce either 20 tons of type 1 mat
or 30 tons of type 2 mat during a month. Similarly, a
line 2 machine could produce either 25 tons of type 2
mat or 28 tons of type 3 mat. It costs $5000 per
month to operate a machine on line 1 and $5500 per
month to operate a machine on line 2. A cost of
$2000 is incurred each time a new machine is pur-
chased, and a cost of $1000 is incurred if a machine
is retired from service. At the end of each month,
Owens would like to have at least 50 tons of each
product in inventory. At the beginning of month 1,
Owens has ﬁve machines on line 1 and eight ma-
chines on line 2. Assume the per-ton cost of holding
either product in inventory for one month is $5.
a. Determine a minimum cost production schedule
for the next four months.
b. There is an important aspect of this situation that
cannot be modeled by linear programming. What
is it? (Hint: If Owens makes product 1 and prod-
uct 2 on line 1 during a month, is this as efﬁcient
as making just product 1 on line 1?)
116. Rylon Corporation manufactures Brute cologne and
Chanelle perfume. The raw material needed to
manufacture each type of fragrance can be purchased
for $60 per pound. Processing 1 pound of raw mater-
ial requires 1 hour of laboratory time. Each pound of
processed raw material yields 3 ounces of Regular
Brute cologne and 4 ounces of Regular Chanelle
perfume. Regular Brute can be sold for $140 per
ounce and Regular Chanelle for $120 per ounce.
Rylon also has the option of further processing Regu-
lar Brute and Regular Chanelle to produce Luxury
Brute, sold at $360 per ounce, and Luxury Chanelle,
sold at $280 per ounce. Each ounce of Regular Brute
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

208
Chapter 4
Linear Programming Models
processed further requires an additional 3 hours of
laboratory time and a $40 processing cost and yields
1 ounce of Luxury Brute. Each ounce of Regular
Chanelle processed further requires an additional
2 hours of laboratory time and a $40 processing cost
and yields 1 ounce of Luxury Chanelle. Each year,
Rylon has 6000 hours of laboratory time available
and can purchase up to 4000 pounds of raw material.
a. Determine how Rylon can maximize its proﬁt.
Assume that the cost of the laboratory hours is a
ﬁxed cost (so that it can be ignored for this
problem).
b. Suppose that 1 pound of raw material can be used
to produce either 3 ounces of Brute or 4 ounces of
Chanelle. How does your answer to part a
change?
c. Use SolverTable to determine how a change in the
price of Luxury Chanelle changes the optimal
proﬁt.
d. Use SolverTable to determine how simultaneous
changes in lab time and raw material availability
change the optimal proﬁt.
e. Use SolverTable to determine how a change in the
extra lab time required to process Luxury Brute
changes the optimal proﬁt.
117. Sunco Oil has three different processes that can be
used to manufacture various types of gasoline. Each
process involves blending oils in the company’s
catalytic cracker. Running process 1 for an hour costs
$20 and requires two barrels of crude oil 1 and
three barrels of crude oil 2. The output from running
process 1 for an hour is two barrels of gas 1 and one
barrel of gas 2. Running process 2 for an hour costs
$30 and requires one barrel of crude 1 and three bar-
rels of crude 2. The output from running process 2
for an hour is three barrels of gas 2. Running process
3 for an hour costs $14 and requires two barrels of
crude 2 and three barrels of gas 2. The output from
running process 3 for an hour is two barrels of gas 3.
Each month, 4000 barrels of crude 1, at $45 per bar-
rel, and 7000 barrels of crude 2, at $55 per barrel,
can be purchased. All gas produced can be sold at the
following per-barrel prices: gas 1, $85; gas 2, $90;
gas 3, $95. Determine how to maximize Sunco’s
proﬁt (revenues less costs). Assume that only
2500 hours of time on the catalytic cracker are avail-
able each month.
118. Flexco produces six products in the following man-
ner. Each unit of raw material purchased yields
4 units of product 1, 2 units of product 2, and 1 unit
of product 3. Up to 1200 units of product 1 can be
sold, and up to 300 units of product 2 can be sold.
Demand for products 3 and 4 is unlimited. Each unit
of product 1 can be sold or processed further. Each
unit of product 1 that is processed further yields
1 unit of product 4. Each unit of product 2 can be
sold or processed further. Each unit of product 2 that
is processed further yields 0.8 unit of product 5 and
0.3 unit of product 6.
Up to 1000 units of product 5 can be sold, and up
to 800 units of product 6 can be sold. Up to 3000 units
of raw material can be purchased at $6 per unit. Left-
over units of products 5 and 6 must be destroyed. It
costs $4 to destroy each leftover unit of product 5
and $3 to destroy each leftover unit of product 6.
Ignoring raw material purchase costs, the unit price
and production cost for each product are listed in the
ﬁle P04_118.xlsx. Determine a proﬁt-maximizing
production schedule for Flexco.
119. Each week, Chemco can purchase unlimited quanti-
ties of raw material at $6 per pound. Each pound of
purchased raw material can be used to produce either
input 1 or input 2. Each pound of raw material can
yield 2 ounces of input 1, requiring 2 hours of
processing time and incurring $2 in processing costs.
Each pound of raw material can yield 3 ounces of
input 2, requiring 2 hours of processing time and
incurring $4 in processing costs. Two production
processes are available. It takes 2 hours to run process 1,
requiring 2 ounces of input 1 and 1 ounce of input 2.
It costs $1 to run process 1. Each time process 1 is
run, 1 ounce of product A and 1 ounce of liquid waste
are produced. Each time process 2 is run requires
3 hours of processing time, 2 ounces of input 2, and
1 ounce of input 1. Each process 2 run yields 1 ounce
of product B and 0.8 ounce of liquid waste. Process 2
incurs $8 in costs. Chemco can dispose of liquid
waste in the Port Charles River or use the waste to
produce product C or product D. Government regula-
tions limit the amount of waste Chemco is allowed to
dump into the river to 5000 ounces per week.
Each ounce of product C costs $4 to produce and
sells for $18. Producing 1 ounce of product C re-
quires 1 hour of processing time, 2 ounces of input 1,
and 0.8 ounce of liquid waste. Each ounce of product
D costs $5 to produce and sells for $12. Producing 1
ounce of product D requires 1 hour of processing
time, 2 ounces of input 2, and 1.2 ounces of liquid
waste. At most, 7000 ounces of product A and
5000 ounces of product B can be sold each week, but
weekly demand for products C and D is unlimited.
Product A sells for $22 per ounce and product B sells
for $24 per ounce. Each week, 25,000 hours of pro-
cessing time are available. Determine how Chemco
can maximize its weekly proﬁt.
120. Bexter Labs produces three products: A, B, and C.
Bexter can sell up to 2000 units of product A, up to
2500 units of product B, and up to 800 units of prod-
uct C. Each unit of product C uses two units of A and
three units of B and incurs $5 in processing costs.
Products A and B are produced from either raw ma-
terial 1 or raw material 2. It costs $6 to purchase and
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4.9 Conclusion
209
process one unit of raw material 1. Each processed
unit of raw material 1 yields two units of A and three
units of B. It costs $3 to purchase and process a unit
of raw material 2. Each processed unit of raw mater-
ial 2 yields one unit of A and two units of B. The unit
prices for the products are A, $5; B, $4; C, $25. The
quality levels of each product are A, 8; B, 7; C, 6.
The average quality level of the units sold must be at
least 7. Determine how to maximize Bexter’s proﬁt.
121. Based on Franklin and Koenigsberg (1973). The
city of Busville contains three school districts. The
numbers of minority and nonminority students in
each district are given in the ﬁle P04_121.xlsx. The
local court has decided that each of the town’s two
high schools (Cooley High and Walt Whitman High)
must have approximately the same percentage of
minority students (within 5%) as the entire town.
The distances (in miles) between the school
districts and the high schools are also given in the
same ﬁle. Each high school must have an enrollment
of 300 to 500 students. Determine an assignment of
students to schools that minimizes the total distance
students must travel to school.
122. Based on Carino and Lenoir (1988). Brady
Corporation produces cabinets. Each week, Brady
requires 90,000 cubic feet of processed lumber. The
company can obtain lumber in two ways. First, it
can purchase lumber from an outside supplier and
then dry it at the Brady kiln. Second, Brady can
chop down trees on its land, cut them into lumber at
its sawmill, and then dry the lumber at its kiln. The
company can purchase grade 1 or grade 2 lumber.
Grade 1 lumber costs $3 per cubic foot and when
dried yields 0.7 cubic foot of useful lumber. Grade 2
lumber costs $7 per cubic foot and when dried yields
0.9 cubic foot of useful lumber. It costs the company
$3 to chop down a tree. After being cut and dried, a
log yields 0.8 cubic feet of lumber. Brady incurs
costs of $4 per cubic foot of lumber it dries. It costs
$2.50 per cubic foot of logs sent through the sawmill.
Each week, the sawmill can process up to 35,000
cubic feet of lumber. Each week, up to 40,000 cubic
feet of grade 1 lumber and up to 60,000 cubic feet
of grade 2 lumber can be purchased. Each week,
40 hours of time are available for drying lumber.
The time it takes to dry one cubic foot of lumber is as
follows: grade 1, 2 seconds; grade 2, 0.8 second;
log, 1.3 seconds. Determine how Brady can mini-
mize the weekly cost of meeting its demand for
processed lumber.
123. Based on Dobson and Kalish (1988). Chandler
Enterprises produces two competing products, A and
B. The company wants to sell these products to two
groups of customers. The values each customer
places on a unit of A and B are shown in the ﬁle
P04_123.xlsx. Each customer will buy either
product A or product B, but not both. A customer is
willing to buy product A if she believes that the
premium of product A is greater than or equal to the
premium of product B and premium of product A is
greater than or equal to 0. Here, the “premium” of a
product is its value minus its price. Similarly, a
customer is willing to buy B if she believes the
premium of product B is greater than or equal to the
premium of product A and the premium of product B
is greater than or equal to 0. Group 1 has 1000
members, and group 2 has 1500 members. Chandler
wants to set prices for each product to ensure that
group 1 members purchase product A and group 2
members purchase product B. Determine how
Chandler can maximize its revenue.
124. Based on Robichek et al. (1965). At the beginning of
month 1, Finco has $4500 in cash. At the beginning
of months 1, 2, 3, and 4, Finco receives certain
revenues, after which it pays bills. (See the ﬁle
P04_124.xlsx.) Any money left over can be invested
for one month at the interest rate of 0.25% per
month; for two months at 0.28% per month; for three
months at 0.33% per month; or for four months at
0.37% per month. Determine an investment strategy
that maximizes cash on hand at the beginning of
month 5.
125. During each six-hour period of the day, the Blooming-
ton Police Department needs at least the number of
police ofﬁcers shown in the ﬁle P04_125.xlsx. Police
ofﬁcers can be hired to work either 12 consecutive
hours or 18 consecutive hours. Police ofﬁcers are paid
$15 per hour for each of the ﬁrst 12 hours they work
in a day and $23 per hour for each of the next six
hours they work in a day. Determine how to minimize
the cost of meeting Bloomington’s daily police
requirements.
126. Based on Glassey and Gupta (1978). A paper recy-
cling plant processes box board, tissue paper,
newsprint, and book paper into pulp that can be used
to produce three grades of recycled paper. The prices
per ton and the pulp contents of the four inputs are
shown in the ﬁle P04_126.xlsx.
Two methods, de-inking and asphalt dispersion,
can be used to process the four inputs into pulp. It
costs $20 to de-ink a ton of any input. The process of
de-inking removes 10% of the input’s pulp, leaving
90% of the original pulp. It costs $15 to apply as-
phalt dispersion to a ton of material. The asphalt
dispersion process removes 20% of the input’s pulp.
At most, 3000 tons of input can be run through the
asphalt dispersion process or the de-inking process.
Grade 1 paper can be produced only with newsprint
or book paper pulp; grade 2 paper only with book
paper, tissue paper, or box board pulp; and grade 3
paper only with newsprint, tissue paper, or box board
pulp. To meet its current demands, the company
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

needs 500 tons of pulp for grade 1 paper, 500 tons of
pulp for grade 2 paper, and 600 tons of pulp for
grade 3 paper. Determine how to minimize the cost
of meeting the demands for pulp.
127. At the beginning of month 1, GE Capital has 50 mil-
lion accounts. Of these, 40 million are paid up (0-
due), 4 million are 1 month overdue (1-due), 4 mil-
lion are 2 months overdue (2-due), and 2 million are
3 months overdue (3-due). After an account is more
than 3 months overdue, it is written off as a bad debt.
For each overdue account, GE Capital can either
phone the cardholder, send a letter, or do nothing.
A letter requires an average of 0.05 hour of labor,
whereas a phone call requires an average of 0.10 hour
of labor. Each month 500,000 hours of labor are
available. We assume that the average amount of a
monthly payment is $30. Thus, if a 2-due account
remains 2-due, it means that 1 month’s payment
($30) has been received, and if a 2-due account
becomes 0-due, it means that 3 months’ payments
($90) have been received. On the basis of thousands
of accounts, DMMs (Delinquency Movement
Matrices) shown in the ﬁle P04_127.xlsx have been
estimated. For example, the top-left 0.60 entry in the
ﬁrst table means that 60% of all 1-due accounts that
receive a letter become 0-due by the next month. The
0.10 and 0.30 values in this same row mean that 10%
of all 1-due accounts remain 1-due after receiving a
letter, and 30% of all 1-due accounts become 2-due
after receiving a letter. Your goal is to determine how
to allocate your workforce over the next four months
to maximize the expected collection revenue received
during that time. (Note: 0-due accounts are never
contacted, which accounts for the lack of 0-due rows
in the ﬁrst two tables.)
128. Three bonds, as listed in the ﬁle P04_128.xlsx, are
currently for sale. Each bond has a face value of
$100. Every six months, starting six months from the
current date and ending at the expiration date, each
bond pays 0.5*(coupon rate)*(Face value). At the
expiration date the face value is paid. For example,
the second bond pays 
■
$2.75 six months from now
■
$102.75 a year from now
Given the current price structure, the question is
whether there is a way to make an inﬁnite amount of
money. To answer this, you need to look for an arbi-
trage. An arbitrage exists if there is a combination of
bond sales and purchases today that yields
■
a positive cash ﬂow today
■
nonnegative cash ﬂows at all future dates
If such a strategy exists, then it is possible to make
an inﬁnite amount of money. For example, if buying
10 units of bond 1 today and selling 5 units of bond 2
today yielded, say, $1 today and nothing at all future
210
Chapter 4
Linear Programming Models
dates, you could make $k by purchasing 10k units of
bond 1 today and selling 5k units of bond 2 today.
You could also cover all payments at future dates
from money received on those dates.
a. Show that an arbitrage opportunity exists for the
bonds in the ﬁle P04_128.xlsx. (Hint: Set up an
LP that maximizes today’s cash ﬂow subject to
constraints that cash ﬂow at each future date is
nonnegative. You should get a “no convergence”
message from Solver.)
b. Usually bonds are bought at an ask price and sold
at a bid price. Consider the same three bonds as
before and suppose the ask and bid prices are as
listed in the same ﬁle. Show that these bond
prices admit no arbitrage opportunities.
Modeling Problems
129. You have been assigned to develop a model that can
be used to schedule employees at a local fast-food
restaurant. Assume that computer technology has
advanced to the point where very large problems can
be solved on a PC at the restaurant.
a. What data would you collect as inputs to your
model?
b. Describe in words several appropriate objective
functions for your model.
c. Describe in words the constraints needed for your
model.
130. You have been assigned to develop a model that can
be used to schedule the nurses working in a mater-
nity ward.
a. What data would you collect as inputs to your
model?
b. Describe in words several appropriate objective
functions for your model.
c. Describe in words the constraints needed for your
model.
131. Keefer Paper produces recycled paper from paper
purchased from local ofﬁces and universities. The
company sells three grades of paper: high-brightness
paper, medium-brightness paper, and low-brightness
paper. The high-brightness paper must have a bright-
ness level of at least 90, the medium-brightness paper
must have a brightness level of between 80 and 90,
and the low-brightness paper must have a brightness
level no greater than 80. Discuss how Keefer might
use a blending model to maximize its proﬁt.
132. In this chapter, we give you the cost of producing a
product and other inputs that are used in the analysis.
Do you think most companies ﬁnd it easy to deter-
mine the cost of producing a product? What difﬁcul-
ties might arise?
133. Discuss how the aggregate planning model could
be extended to handle a company that produces
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

several products on several types of machines.
What information would you need to model this
type of problem?
134. A large CPA ﬁrm currently has 100 junior staff
members and 20 partners. In the long run—say,
20 years from now—the ﬁrm would like to consist
of 130 junior staff members and 20 partners. During
a given year, 10% of all partners and 30% of all ju-
nior staff members leave the ﬁrm. The ﬁrm can
control the number of hires each year and the
fraction of junior employees who are promoted to
partner each year. Can you develop a personnel
strategy that would meet the CPA ﬁrm’s goals?
4.9 Conclusion
211
135. The worker scheduling model in this chapter was
purposely made small (only seven changing cells).
What would make a similar problem for a company
like McDonald’s much harder? What types of con-
straints would be required? How many changing
cells (approximately) might there be?
136. Explain why it is problematic to include a constraint
such as the following in an LP model for a blending
problem:
Total octane in gasoline 1 blend
Barrels of gasoline 1 blended daily Ú 10
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

C A S E
S
audi Arabia is a kingdom in the Middle East with
an area of 865,000 square miles, occupying about
four-ﬁfths of the Arabian Peninsula. With a popula-
tion of about 10 million, this Muslim and Arab state is
generally recognized as being formed in 1927 when
Ibn Sa’ud united the country and was acknowledged
as the sovereign independent ruler. Summer heat is
intense in the interior, reaching 124°F, but it is dry
and tolerable in contrast to coastal regions and some
highlands, which have high humidity during the
summer. Winters (December through February) are
cool, with the coldest weather occurring at high
altitudes and in the far north. A minimum tempera-
ture recorded at at-Turayf in 1950 was 10°F, and it
was accompanied by several inches of snow and an
inch of ice on ponds. Average winter temperatures
are 74°F at Jidda and 58°F at Riyadh (the capital city),
which has an annual precipitation of 2.5 to 3 inches.
After oil was discovered in Bahrain in 1932, many
companies turned to Saudi Arabia and started explor-
ing. Thus, in 1937, the American Arabian Oil Com-
pany, Inc. (AMARCO), was formed as a joint venture
between Standard Oil Company of California
(SOCAL) and the Government of Saudi Arabia to ex-
plore, produce, and market any petroleum found in
the country. The year before, a geologist from
SOCAL had discovered a small quantity of oil in the
Eastern Province at Dammam Dome, on which the
oil company town of Dhahran is now built. It was just
beginning to be developed when another discovery
was made—of what was to prove to be the largest
oil ﬁeld in the world. Called the Ghamar ﬁeld, it
would start Saudi Arabia on the road to becoming a
highly developed country in just a generation. Located
about 50 miles inland from the western shores of the
Persian Gulf, the Ghamar ﬁeld is a structural accumu-
lation along 140 miles of a north–south anticline. The
productive area covers approximately 900 square
miles, and the vertical oil column is about 1,300 feet.
It is generally considered to have recoverable re-
serves of about 75 billion barrels of oil. Total proven
reserves in Saudi Arabia are estimated at more than
500 billion barrels, enough for more than a hundred
years of production.
4.1 AMARCO, INC.9
Since 1950, Saudi Arabia has experienced greater
and more rapid changes than it had in the several
preceding centuries. For example, during this time, as
skilled nationals became available, more and more of
the exploration, drilling, reﬁning, and other produc-
tion activities came under the control of the country.
SOCAL was left primarily with the marketing and
transportation functions outside the country.
During the 1960s, AMARCO increased its
proﬁtability substantially by hiring Dr. George
Dantzig, then of the University of California, as a
consultant. He supervised the development and
implementation of LP models to optimize the
production of different types of crude oils, their
reﬁning, and the marketing of some of their principal
products. As a result of this effort, an operations
research (OR) department was started in the
company with the responsibility of continuing to
review the ﬁrm’s operations to ﬁnd other areas
where costs might be decreased or proﬁts increased
by applications of OR.
Now attention is being focused on another
aspect of one of the company’s small California
reﬁnery operations: the production of three types
of aviation gasoline from the Saudi Arabian crude
oil available. Recently, the marketing of petroleum
products to the airline industry has become a rather
substantial portion of AMARCO’s business. As
shown in Figure 4.45, the three aviation gasolines, A,
B, and C, are made by blending four feedstocks:
Alkylate, Catalytic Cracked Gasoline, Straight Run
Gasoline, and Isopentane.
In Table 4.14,TEL stands for tetraethyl lead,
which is measured in units of milliliters per
gallon (ml/gal). Thus, a TEL of 0.5 means there is
0.5 milliliter of tetraethyl lead per gallon of
feedstock. Table 4.14 shows that TEL does
inﬂuence the octane number but does not
inﬂuence the Reid vapor pressure.
Each type of aviation gasoline has a maximum
permissible Reid vapor pressure of 7. Aviation
gasoline A has a TEL level of 0.5 ml/gal and has a
minimum octane number of 80. The TEL level of
aviation gasolines B and C is 4 ml/gal, but the former
has a minimum octane number of 91, whereas the
latter has a minimum of 100.
9 This case was written by William D. Whisler, California State Uni-
versity, Hayward.
212
Chapter 4
Linear Programming Models
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Assume that all feedstocks going into aviation
gasoline A are leaded at a TEL level of 0.5 ml/gal and
that those going into aviation gasolines B and C are
leaded at a TEL level of 4 ml/gal. Table 4.15 gives the
Aviation
Gas A
Refinery
Crude Oil
Aviation
Gas C
Alkylate
Catalytic
Cracked
Gasoline
Straight
Run
Gasoline
Isopentane
Aviation
Gas B
Figure 4.45
The Production of
Aviation Gasoline
Table 4.14 Stock Availabilitiesa
Feedstock
Catalytic
Straight
Cracked
Run
Characteristic
Alkylate
Gasoline
Gasoline
Isopentane
Reid Vapor Pressure
5
8
4
20
Octane Number
If TEL is 0.5
94
83
74
95 
If TEL is 4.0
107.5
93
87
108
Available (Bbl/day)
14,000
13,000
14,000
11,000 
Value ($/Bbl)
17.00
14.50
13.50
14.00 
aSome of the data in this case have been adapted from Walter W. Garvin, Introduction to Linear Programming (New York: 
McGraw-Hill, 1960), Chapter 5.
Table 4.15 Aviation Gasoline Data
Aviation Gasoline
Characteristic
A
B
C
Minimum requirements (Bbl/day)
12,000
13,000
12,000
Price ($/Bbl)
15.00
16.00
16.50
aviation gasoline data. A ﬁnal condition is that
marketing requires that the amount of aviation gas
A produced be at least as great as the amount of
aviation gas B.
Case 4.1 AMARCO, Inc.
213
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Questions
1.
AMARCO’s planners want to determine how
the three grades of aviation gasoline should be
blended from the available input streams so
that the speciﬁcations are met and income is
maximized. Develop an LP spreadsheet model
of the company’s problem.
2.
Solve the linear programming model devel-
oped in Question 1.
The following questions should be attempted only after
Questions 1 and 2 have been answered correctly.
3.
Suppose that a potential supply shortage of
Saudi Arabian petroleum products exists in the
near future due to possible damage to
AMARCO’s oil production facilities from Iraqi
attacks. This could cause the prices of the
three types of aviation gasolines to double
(while the values of the stocks remain the
same, because they are currently on hand).
How would this affect the reﬁnery’s opera-
tions? If, after current stocks are exhausted,
additional quantities must be obtained at
values double those given in Table 4.14, how
might AMARCO’s plans be affected?
4.
Suppose that because of the new Iraqi crisis,
the supply of alkylate is decreased by 1,800
bbl/day, catalytic cracked gas is decreased by
2,000 bbl/day, and straight run gasoline is
decreased by 5,000 bbl/day. How does this
affect AMARCO’s operations?
5.
AMARCO is considering trying to ﬁll the avia-
tion gasoline shortage created by the new Iraqi
crisis by increasing its own production. If addi-
tional quantities of alkylate, catalytic cracked
gasoline, straight run gasoline, and isopentane
are available, should they be processed? If so,
how much of them should be processed, and
how do their values affect the situation?
6.
Due to the uncertainty about both the U.S.
economy and the world economy resulting
from the Iraqi crisis, AMARCO’s economists
are considering doing a new market research
study to reestimate the minimum requirement
forecasts. With the economy continually
weakening, it is felt that demand will decrease,
possibly drastically, in the future. However,
because such marketing research is expensive,
management is wondering whether it would be
worthwhile. That is, do changes in the minimum
requirements have a signiﬁcant effect on
AMARCO’s operations? What is the change in
proﬁt from an increase or a decrease in the
minimum requirements? Over what ranges of
demand do these proﬁt changes apply?
7.
Suppose that the Middle East crisis ends and a
ﬂood of oil ﬁlls the marketplace, causing the
prices of aviation gasoline to drop to $10.00,
$11.00, and $11.50, respectively, for A, B, and C.
How would this affect the company’s plans?
8.
Suppose that the U.S. government is considering
mandating the elimination of lead from aviation
gasoline to decrease air pollution. This law
would be based on new technology that allows
jet engines to burn unleaded gasoline efﬁciently
at any octane level. Thus, there would no longer
be any need for constraints on octane level.
How would such a new law affect AMARCO?
9.
The Environmental Protection Agency is propos-
ing regulations to decrease air pollution. It plans
to improve the quality of aviation gasolines by
decreasing the requirement on Reid vapor
pressure from 7 to 6. Management is concerned
about this regulation and wonders how it might
affect AMARCO’s proﬁtability. Analyze and
make a recommendation.
10. The Marketing Department indicates that
AMARCO will be able to increase its share of
the market substantially with a new contract
being negotiated with a new customer. The
difﬁculty is that this contract will require that
the amount of aviation gas A plus the amount of
B must be at least as great as the amount of C
produced. Because aviation gasolines A and B are
least proﬁtable of the three, this could cause a
big decrease in proﬁt for the company. However,
marketing indicates that this is a short-run view,
because the “large” increase in market share
with the concomitant long-run proﬁt increases
will more than offset the “temporary small
decrease” in proﬁts because of the additional
restriction.What do you recommend? Why? ■
214
Chapter 4
Linear Programming Models
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

A
merican Ofﬁce Systems, Inc., was established by
the late R. J. Miller, Sr., in 1939. It started as an
ofﬁce supply store in MountainView, California, and
expanded slowly over the years into the manufacture
of small ofﬁce equipment, overhead projectors, and
bookkeeping machines. In the 1950s, computers
started eroding its market for bookkeeping machines,
so the company diversiﬁed into the copy machine
market. However, it never captured a large market
share because bigger ﬁrms such as Xerox, Canon,
Sharp, and A. B. Dick were so ﬁrmly entrenched.
A few years ago, American Ofﬁce Systems’
engineering staff developed an adapter that links a
standard copy machine to personal computers,
allowing a copy machine to be used as a laser printer,
scanner, and fax. The adapters show great promise
for both home and ofﬁce use. However, the company
is not well known by either the ﬁnancial community
or the copy machine market, principally due to its
small size and rather lackluster record, so it could
secure only $15 million in initial ﬁnancial backing for
the adapters. The $15 million was used to ﬁnance
the construction of a small production facility and of
administrative ofﬁces in 1994, and in 1995 produc-
tion and sales began. Two versions of the adapter
exist, one for PCs and one for Apple computers. The
former sells for $175 and the latter for $200.
At the beginning of December 1995, Dr. R. J.
Miller, II, the president, convened a meeting about the
coming year’s plans for the adapters. Rob Olsen,Vice
President of Production, argued that production
facilities should be expanded: “Until we have sufﬁcient
capacity to produce the adapters,” he said,“there is no
use advertising.” SueWilliams, Director of Marketing,
replied,“On the contrary, without any demand for the
adapters, there is no reason to produce them. We
need to focus on advertising ﬁrst.” J.T. Howell, the
Comptroller, pointed out that Olsen and Williams
were talking about the situation as if it only involved a
decision between production and marketing: “Yes,
funds need to be allocated between production and
advertising. However, more important than both is
the cash ﬂow difﬁculty that the company has been
experiencing. As you know, it was only yesterday that,
C A S E
4.2 AMERICAN OFFICE SYSTEMS, INC.10
ﬁnally, I was able to secure a $750,000 line of credit
for the coming year from Citibank. I might add that it
is at a very favorable interest rate of 16%. This will
partially solve our cash ﬂow problems and it will have
a big effect on both production and advertising deci-
sions. In addition, there are ﬁnancial and accounting
factors that must be allowed for in any decision about
the adapters.” Olsen interjected, “Wow, this is more
complicated than I anticipated originally. Before we
make a decision, I think we ought to use some
modern management science techniques to be sure
that all the relevant factors are considered. Last week
I hired Carlos Garcia from Stanford. He has a Master’s
degree in Operations Research. I think this would be a
good project for him.” However, Williams said that
she thinks that an executive, judgmental decision
would be much better.“Let’s not get carried away with
any of the quantitative mumbo-jumbo that Rob is
always suggesting. Besides, his studies always take too
much time and are so technical that no one can
understand them. We need a decision by the end of
next week.” After listening to the discussion, Miller
decided to appoint an executive action team to study
the problem and make a recommendation at next
week’s meeting.“Rob and Sue, I want both of you to
document your arguments in more detail. J.T., be more
precise with your comments about the cash ﬂow,
accounting, and ﬁnancial problems. And, by the way
Rob, have Carlos look into a model to see if it might
produce some insights.”
Most of the $15 million initial ﬁnancing was used
to build a ﬁve-story building in Mountain View, south
of San Francisco. Although currently only about 90%
complete, it is being used. The ﬁrst ﬂoor contains the
production and shipping facilities plus a small storage
area. A larger warehouse, already owned by the
company, is located across the street. The other four
ﬂoors of the building are for the engineering depart-
ment (second ﬂoor), a research lab (third ﬂoor), and
administration (top two ﬂoors). The production
facility operates two shifts per day and has a produc-
tion capacity of 30 PC adapters and 10 Apple
adapters per hour. Olsen uses 20 production days
per month in his planning. Usually there are a few
more, but these are reserved for maintenance and
repairs. The last stage of the initial construction will
be ﬁnished by the beginning of the fourth quarter,
10 This case was written by William D. Whisler, California State
University, Hayward.
Case 4.2 American Ofﬁce Systems, Inc.
215
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

216
Chapter 4
Linear Programming Models
making the building 100% ﬁnished. This will increase
the production capacity rates by 10%.
Howell normally does the company’s ﬁnancial
planning monthly, and he assumes that cash ﬂows as-
sociated with all current operating expenses, sales
revenues (taking collections into account), advertising
costs, loans from the line of credit, investments of
excess cash in short-term government securities, and
so forth, occur at the end of the corresponding
month. Because he needs information for the meeting
next week, however, he decides to do a rough plan on
a quarterly basis. This means that all the just men-
tioned cash ﬂows, and so on, will be assumed to occur
at the end of the quarter. After the meeting, when
more time is available, the plan will be expanded to
a monthly basis. To get started, one of his senior
ﬁnancial analysts prepares the list of quarterly ﬁxed
operating expenses shown in Table 4.16. In addition,
the accounting department calculates that the variable
costs of the adapters are $100 each for the PC
version and $110 each for the Apple version.
Table 4.16 Quarterly Fixed Operating Expenses
Expense
Cost
Administrative expense
$1,500,000
Fixed manufacturing costs 
750,000
Sales agents’ salaries
750,000
Depreciation
100,000
At present, American Ofﬁce Systems is
experiencing a cash ﬂow squeeze due to the large
cash requirements of the startup of the adapter
production, advertising, and sales costs. If excess cash
is available in any quarter, however, Howell says that
the company policy is to invest it in short-term
government securities, such as treasury bills. He
estimates that during the coming year these
investments will yield a return of 6%.
Olsen asks Garcia to look into the production
and inventory aspects of the situation ﬁrst, because
this area was his specialty at Stanford. Then he says
that he wants him to think about a programming
model that might integrate all components of the
problem—production, sales, advertising, inventory,
accounting, and ﬁnance. A mixed-integer programming
model appears to be the most appropriate;however,
he asks Garcia to use linear programming as an
approximation due to the time limitations and
Williams’s concern about his ideas always being too
technical. “There will be more time after next week’s
meeting to reﬁne the model,” he says.
After discussions with Olsen and Williams,
Garcia feels that something needs to be done to help
the company handle the uncertainty surrounding
future sales of the adapters. He points out that it is
impossible to guarantee that the company will never
be out of stock. However, it is possible to decrease
shortages so that any difﬁculties associated with
them would be small and not cause major disrup-
tions or additional management problems, such as
excess time and cost spent expediting orders. Thus,
Garcia formulates an inventory model. To be able to
solve the model, he has to check the inventory levels
of the adapters currently on hand in the warehouse.
From these quantities, he calculates that there will
be 10,000 PC and 5,000 Apple adapters on hand at
the beginning of 1996. Based on the results of the
model, he recommends that a simple rule of thumb
be used: production plus the end-of-period inventory
for the adapters should be at least 10% larger than
the estimated sales for the next period. This would
be a safety cushion to help prevent shortages of the
adapters. In addition, to provide a smooth transition
to 1997, the inventory level plus production at the
end of the fourth quarter of 1996 should be at least
twice the maximum expected sales for that quarter.
Garcia says that using these rules of thumb will
minimize annual inventory costs. When explaining
the inventory model to Olsen, Garcia emphasizes
the importance of including inventory carrying costs
as part of any analysis, even though such costs
frequently are not out-of-pocket. He says that his
analysis of data provided by the accounting depart-
ment yielded a 1% per month inventory carry cost,
and this is what he used in his model.
Sales during the ﬁrst year (1995) for the adapters
are shown in Table 4.17. Next year’s sales are
uncertain. One reason for the uncertainty is that
they depend on the advertising. To begin the analysis,
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Williams asks her marketing research analyst, Debra
Lu, to estimate the maximum sales levels for the
coming four quarters if no advertising is done. Since
last year’s sales of both models showed a steady
increase throughout the year, Lu projects a
continuation of the trend. She forecasts that the
company will be able to sell any number of adapters
up to the maximum expected sales amounts shown
in Table 4.17.
Table 4.17 1995 Adapter Sales and Maximum
Expected 1996 Sales
1996 Maximum
1995 Sales
Expected Sales
PC
Apple
PC
Apple
Quarter
Adapters Adapters
Adapters Adapters
1
5,000
1,000
9,000
1,800
2
6,000
1,200
10,000
2,000
3
7,000
1,400
11,000
2,200
4
8,000
1,600
12,000
2,400
Miller suggests that advertising in magazines
such as PC World and Home Ofﬁce will increase
consumer awareness of both the company and the
adapters. The next day, Williams has a meeting with
several staff members of a San Francisco advertising
agency. They show her recommendations for two
types of ads (one for the PC adapters and one for
the Apple adapters), give her cost information, and
the estimated effectiveness of an advertising cam-
paign. Armed with this information and some data
from Lu, Williams prepares a brief report for Miller
setting out her reasons for thinking that each
$10 spent on advertising will sell an additional PC
adapter; the same relationship holds true for the
Apple adapter.
Based on an analysis of 1995 sales and accounts
receivable, the accounting department determines that
collection experience is as shown in Table 4.18. For
example, 75% of the PC adapters sold in a quarter are
paid for during the quarter, 20% are paid for during
the following quarter, and 3% are paid for during the
third quarter. The remaining 2% are written off and
sold to a collection agency for $0.50 on the dollar.
Table 4.18 Collections
Quarter
PC Adapters
Apple Adapters
1
0.75
0.80
2
0.20
0.11
3
0.03
0.05
Questions
1.
Suppose that you are Garcia. Develop an LP
spreadsheet model of the situation to help the
executive action team make a decision about
how to allocate funds between production and
advertising so that all the cash ﬂow, ﬁnancial,
accounting, marketing, inventory, and production
considerations are taken into account and
American Ofﬁce Systems’ proﬁts are maximized.
Use the data collected and the estimates made
by the members of the executive action team.
2.
Solve the LP model formulated in Question 1.
The executive action team has assembled to reconsider
the plans for the adapters for the coming year. Garcia, who
developed the LP model, concludes his presentation by
saying,“As everyone can see, the model gives the optimal
solution that maximizes proﬁts. Since I have incorporated
the estimates and assumptions that all of you made,
clearly it is the best solution. No other alternative can give
a higher proﬁt.” EvenWilliams, who initially was skeptical
of using quantitative models for making executive-level
decisions, is impressed and indicates that she will go along
with the results.
Miller says,“Good work, Carlos! This is a complex
problem but your presentation made it all seem so simple.
However, remember that those ﬁgures you used were
based on estimates made by all of us. Some were little bet-
ter than guesses. What happens if they are wrong? In
other words, your presentation has helped me get a handle
on the problem we are facing, and I know that models are
useful where hard, accurate data exist. However, with all
the uncertainty in our situation and the many rough esti-
mates made, it seems to me that I will still have to make a
judgment call when it comes down to making a ﬁnal
decision. Also, there has been a new development. J.T. tells
me that we might be able to get another $1 million
Case 4.2 American Ofﬁce Systems, Inc.
217
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

218
Chapter 4
Linear Programming Models
line of credit from a Bahamian bank. It will take a while
to work out the details and maybe it will cost us a little.
I am wondering if it is worth it. What would we do with
the $1 million if we got it?” J. T. responds,“We really need
the $1 million. But it is a drop in the bucket. My analysis
shows that we really need another $8 million line of
credit.”
Analyze, as Garcia is going to do, the effect of uncer-
tainty and errors on the results of Questions 1 and 2 by
answering the following questions.They should be
attempted only after Questions 1 and 2 have been
answered correctly.
3.
One area where assumptions were made is
adapter price.
a. What happens if the prices for the adapters
are a little weak and they decrease to $173
for the PC version and $198 for the Apple
version? Does this make any difference?
b. What about decreases to $172 and $197,
respectively, for the PC and Apple versions?
Explain the answers in terms that Miller will
understand.
c. Suppose that American Ofﬁce Systems can
increase the price of the adapters to $180
and $205. How would this affect the original
solution?
4.
Another potential variable is adapter production
cost.
a. Suppose that an error was made in determin-
ing the costs of the adapters and that they
really should have been $102 for the PC
version and $112 for the Apple version.What
is the effect of this error?
b. What about costs of $105 and $115? Explain
the answers in terms that Miller will
understand.
5.
Howell notes that one of the contributing factors
to American Ofﬁce Systems’ cash squeeze is the
slow collection of accounts receivable. He is con-
sidering adopting a new collection procedure
recommended by a consulting company. It will
cost $100,000 and will change the collection
rates to those given in Table 4.19.
a. Analyze the effect of this new collection
policy and make a recommendation to Howell
about whether to implement the new proce-
dure. As before, any accounts receivable not
collected by the end of the third quarter will
be sold to a collection agency for $0.50 on
the dollar.
b. Howell wonders whether switching to selling
adapters for all cash is worth the effort. This
would ameliorate the cash squeeze because it
would eliminate not only the slow collections
but also the use of the collection agency for
accounts that remain unpaid after nine
months. It would cost about $90,000 more
than at present to implement the all-cash
policy because the accounting system would
need to be modiﬁed and personnel would
have to be retrained. Analyze this possibility
and make a recommendation to Howell.
Table 4.19 New Collections
Quarter
PC Adapters
Apple Adapters
1
0.90
0.92
2
0.07
0.03
3
0.01
0.01
6.
Yet another variable is advertising effectiveness.
a. Suppose that Williams overestimated the
effectiveness of advertising. It now appears
that $100 is needed to increase sales by one
adapter. How will this affect the original
solution? Explain the answer in terms that
Miller will understand.
b. What happens if the required advertising
outlay is $12.50 per additional adapter sold?
7.
Suppose that the line of credit from Citibank that
Howell thought he had arranged did not work
out because of the poor ﬁnancial situation of the
company. The company can obtain one for the
same amount from a small local bank; however,
the interest rate is much higher, 24%. Analyze
how this change affects American Ofﬁce Systems.
8.
The safety cushion for inventory is subject to
revision.
a. Suppose that Garcia ﬁnds a bug in his original
inventory model. Correcting it results in a
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

safety cushion of 15% instead of the 10% he
suggested previously. Determine whether this
is important.
b. What if the error is 20%? Explain the answers
in terms that Miller will understand.
9.
Production capacity is scheduled to increase by
10% in the fourth quarter.
a. Suppose that Miller is advised by the
construction company that the work will not
be ﬁnished until the following year. How will
this delay affect the company’s plans?
b. In addition to the delay in part a, suppose
that an accident in the production facility
damages some of the equipment so that the
capacity is decreased by 10% in the fourth
quarter. Analyze how this will affect the
original solution.
10. Williams is worried about the accuracy of 
Lu’s 1996 maximum expected sales forecasts. If
errors in these forecasts have a big effect on the
company proﬁts, she is thinking about hiring a
San Francisco marketing research ﬁrm to do a
more detailed analysis. They would charge
$50,000 for a study. Help Williams by analyzing
what would happen if Lu’s forecasts are in error
by 1,000 for PC adapters and 200 for Apple
adapters each quarter. Should she hire the mar-
keting research ﬁrm?
11. a. To determine whether the extra $1 million
line of credit is needed, analyze its effect on
the original solution given in Question 2.
b. To fully understand the ramiﬁcations of the
extra $1,000,000 line of credit, redo (1)
Question 3b, (2) Question 4b, (3) Question 6a,
and (4) Question 8b. Summarize your results.
c. What about Howell’s claim that an extra
$8,000,000 line of credit is necessary? Use
that adjustment and redo Question 6a. ■
Case 4.2 American Ofﬁce Systems, Inc.
219
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

L
akeﬁeld Corporation’s oil trading desk buys and
sells oil products (crude oil and reﬁned fuels),
options, and futures in international markets. The
trading desk is responsible for buying raw material
for Lakeﬁeld’s reﬁning and blending operations and
for selling ﬁnal products. In addition to trading for
the company’s operations, the desk also takes
speculative positions. In speculative trades, the desk
attempts to proﬁt from its knowledge and informa-
tion about conditions in the global oil markets.
One of the traders, Lisa Davies, is responsible for
transactions in the cash market (as opposed to the
futures or options markets). Lisa has been trading for
several years and has seen the prices of oil-related
products ﬂuctuate tremendously. Figure 4.46 shows
the prices of heating oil #2 and unleaded gasoline
from January 1986 through July 1992. Although ex-
cessive volatility of oil prices is undesirable for most
businesses, Lakeﬁeld’s oil trading desk often makes
substantial proﬁts in periods of high volatility.
The prices of various oil products tend to move
together over long periods of time. Because ﬁnished
oil products are reﬁned from crude oil, the prices of
all ﬁnished products tend to rise if the price of crude
increases. Because ﬁnished oil products are not per-
fect substitutes, the prices of individual products do
not move in lockstep. In fact, over short time peri-
ods, the price movements of two products can have
a low correlation. For example, in late 1989 and early
1990, there was a severe cold wave in the north-
eastern United States. The price of heating oil rose
from $0.60 per gallon to over $1 per gallon. In the
same time period, the price of gasoline rose just over
$0.10 per gallon.
Davies believes that some mathematical analysis
might be helpful to spot trading opportunities in the
cash markets. The next section provides background
about a few important characteristics of fuel oils,
along with a discussion of the properties of blended
fuels and some implications for pricing.
Characteristics of Hydr
ocarbon Fuels
The many varieties of hydrocarbon fuels include
heating oil, kerosene, gasoline, and diesel oil. Each
type of fuel has many characteristics, for example,
heat content, viscosity, freezing point, luminosity,
C A S E
4.3 LAKEFIELD CORPORATION’S OIL TRADING DESK
20
40
60
80
100
120
Jan-86
Jan-89
Jan-92
Jan-87
Jan-88
Jan-90
Jan-91
Heating Oil #2                    Unleaded Gasoline
Date
Price (cents/gallon)
Figure 4.46
Price of Heating 
Oil #2 and Unleaded
Gasoline
220
Chapter 4
Linear Programming Models
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Case 4.3 Lakeﬁeld Corporation’s Oil Trading Desk
221
volatility (speed of vaporization), and so on. The
relative importance of each characteristic depends
on the intended use of the fuel. For example, octane
rating is one of the most important characteristics
of gasoline. Octane is a measure of resistance to
ignition under pressure. An engine burning low-
octane fuel is susceptible to “engine knock,” which
reduces its power output. Surprisingly, octane rating
is more important than heat content for gasoline. In
contrast, the most important characteristic of
kerosene jet fuel is its heat content, but viscosity is
also important. High-viscosity fuels do not ﬂow as
smoothly through fuel lines.
For the types of fuels Lisa Davies usually trades,
the most important characteristics are density,
viscosity, sulfur content, and ﬂash point, which are
described next.When trading and blending other
fuels, characteristics besides these four are important
to consider.
Density The density of a substance is its mass per
unit volume (e.g., grams per cubic centimeter). The
density of water is 1 g/cc. A related measure is
American Petroleum Institute gravity (API), which is
measured in degrees. API is related to density by 
API  
14
D
1.5
 131.5
where D is density measured in g/cc. Water has an
API of 10°. Note that density and API are inversely
related.
The speciﬁcations for kerosene jet fuel are
nearly identical for all civilian airlines worldwide.
Kerosene jet fuel should have an API gravity between
37° and 51°. Diesel fuel and heating oil are required
to have an API not less than 30°. API is important for
controlling the ﬂow of fuel in a combustion engine. It
can also be used to limit the concentration of heavy
hydrocarbon compounds in the fuel.
Viscosity Viscosity refers to the resistance of
a liquid to ﬂow. A highly viscous liquid, such as
ketchup or molasses, does not pour easily. Viscosity
is measured by the amount of time a speciﬁed
volume of liquid takes to ﬂow through a tube of a
certain diameter. It is commonly measured in units
of centistokes (hundredths of stokes). Most fuel
speciﬁcations place upper limits on viscosity. Less
viscous fuel ﬂows easily through lines and atomizes
easily for efﬁcient combustion. More viscous fuels
must be heated initially to reduce viscosity.
Sulfur Content The content of sulfur is mea-
sured in percentage of total sulfur by weight. For
example, a fuel with 2% sulfur content has 2 grams of
sulfur for every 100 grams of fuel. Sulfur causes
corrosion and abrasion of metal surfaces. Low sulfur
content is important for maintaining the proper
operation of equipment.
Flash Point
The ﬂash point of a substance is the
lowest temperature at which the substance ignites
when exposed to a ﬂame. The product description
of kerosene jet fuel from the American Society for
Testing and Materials speciﬁes a ﬂash point of at least
100°F. The New York Mercantile Exchange futures
contract for heating oil #2 speciﬁes a ﬂash point of
at least 130°F. Flash-point restrictions are often
prescribed for safety reasons.
Table 4.20 gives a description of some fuels and
their prices on a given day. In Table 4.20, the units of
viscosity are centistokes, sulfur is given in percentage
by weight, and ﬂash point is in degrees Fahrenheit.
For convenience, all prices in Table 4.20 are given in
dollars per barrel. In practice, the prices of heating
oil, gasoline, and kerosene jet fuel are typically
quoted in cents per gallon. (There are 42 gallons in a
barrel.)
Blending Fuels
Because hydrocarbon fuels are made of similar
compounds and have similar characteristics, a certain
degree of substitutability exists among fuels. Differ-
ent fuels can also be blended to form a new fuel.
Next we describe how the characteristics of the
individual fuels combine in the blended fuel.
Sulfur combines linearly by weight. This means,
for example, that mixing equal weights of a 1% sulfur
oil with a 3% sulfur oil produces a 2% sulfur oil. To a
close approximation, sulfur combines linearly by
volume (because the densities of oils are not very
different). That is, combining 0.5 barrel of 1% sulfur
oil with 0.5 barrel of 3% sulfur oil gives 1 barrel of
very nearly 2% sulfur oil.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

222
Chapter 4
Linear Programming Models
In general, to say that a certain property of oil
combines linearly (by volume) means the following:
Suppose xj barrels of oil j (for j  1, 2, . . . , n) are
blended together to form one barrel of oil; that is,
n
j1xj  1. Also suppose that cj is the measure of the
property of oil j. Then if the property combines
linearly, the measure of the property for the blended
oil is a linear combination of the cj’s; that is, n
j1cjxj.
API gravity does not combine linearly, but den-
sity does combine linearly. For example, consider
blending 0.5 barrel of oil that has a density of 0.8
g/cc with 0.5 barrel of oil with a density of 1.2 g/cc.
The resulting barrel of oil has a density of 1.0
( 0.8[0.5]  1.2[0.5]). The 0.8 g/cc density oil has
an API of 45.38 , and the 1.2 g/cc density oil has an
API of 13.58°. If API combined linearly, the blended
barrel of oil would have an API of 15.90°( 45.38
[0.5] 13.58 [0.5]). However, an API of 15.90
corresponds to a density of 0.96 g/cc, not 1.0 g/cc.11
Viscosity, measured in centistokes, does not
combine linearly. However, chemical engineers have
determined that viscosity can be transformed to
another measure, called linear viscosity, which
(nearly) combines linearly.12 Similarly, ﬂash points
measured in degrees Fahrenheit do not combine
linearly. But chemical engineers deﬁned a new
measure, termed linear ﬂash point, which does
combine linearly.13 Table 4.21 summarizes the
properties of the 12 fuels measured in units that
combine linearly.
Implications for Pricing
Sulfur in oil is a contaminant. Therefore, oil with a
low sulfur content is more valuable than oil with a
higher sulfur content, all other characteristics being
equal. This relationship can be seen in Table 4.20 by
comparing the prices of fuels 1, 2, and 3 and fuels 5,
11 To convert API to density, use D  141.5(API  131.5).
12 Let vs represent viscosity measured in centistokes. Then linear vis-
cosity, denoted v, is deﬁned v  ln(ln[vs  0.08]).
13 Let fp denote ﬂash point measured in degrees Fahrenheit. Then
linear flash point is defined f  1042(fp  460)14.286. Empirical
analysis of oil blending data conﬁrms that the measure f combines
nearly linearly.
Table 4.20 Description of Available Fuels
Fuel 1
Fuel 2
Fuel 3 
Fuel 4
Fuel 5
Fuel 6 
1% Sulfur
3% Sulfur
0.7% Sulfur
Heating
1% Vacuum 
2% Vacuum
Fuel Oil 
Fuel Oil 
Fuel Oil 
Oil 
Gas Oil 
Gas Oil 
API 
10.50 
10.50 
10.50 
34.00 
25.00 
25.00 
Viscosity 
477.00 
477.00 
477.00 
3.50 
25.00 
25.00 
Sulfur 
1.00 
3.00 
0.70 
0.20 
1.00 
2.00 
Flash point 
140.00 
140.00 
140.00
130.00 
200.00 
200.00 
Price 
16.08 
13.25 
17.33 
24.10 
20.83 
20.10 
Fuel 7 
Fuel 8 
Fuel 9 
Fuel 10 
Fuel 11 
Fuel 12
0.5% Vacuum
Straight Run
Straight Run
Kerosene 
Diesel
Gas Oil 
(Low Sulfur)
(High Sulfur)
Jet Fuel 
Fuel 
Slurry 
API 
25.00 
21.00 
17.00 
46.000 
35.00 
4.50 
Viscosity 
25.00 
212.00 
212.00 
1.500 
2.50 
261.00 
Sulfur 
0.50 
0.30 
2.75 
0.125 
0.20 
2.37 
Flash point 
200.00 
250.00 
250.00 
123.000 
150.00 
109.00 
Price 
21.46 
21.00 
20.00 
25.520 
24.30 
11.50 
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Case 4.3 Lakeﬁeld Corporation’s Oil Trading Desk
223
6, and 7. Lower-density oils are generally preferred to
higher-density oils, because energy per unit mass is
higher for low-density fuels, which reduces the
weight of the fuel. Lower-viscosity oils are preferred
because they ﬂow more easily through fuel lines than
oils with higher viscosities. High ﬂash points are
preferred for safety reasons. However, because ﬂash
point and linear ﬂash point are inversely related, this
means that oils with lower linear ﬂash point are
preferred to oils with higher linear ﬂash point.
That fuels can be blended cheaply to form new
fuels affects price as well. For example, fuel 2 and fuel
3 from Table 4.20 can be blended to form a fuel with
the same API, viscosity, sulfur, and ﬂash point as fuel
1. In particular, 0.1304 barrel of fuel 2 and 0.8696
barrel of fuel 3 can be blended to form one barrel of
a new fuel, which, in terms of the four main charac-
teristics, is identical to fuel 1. Because the cost of
blending is small, prices combine nearly linearly. The
cost to create the blended fuel is $16.80 per barrel
($16.80  0.1304[13.25]  0.8696[17.33]). If the
price of fuel 1 were greater than $16.80, say $17.10,
Lisa Davies could create an arbitrage. She could buy
fuels 2 and 3 in the appropriate proportions,
Lakeﬁeld Corporation could blend them together,
and Davies could sell the blend at the price of fuel 1.
The proﬁt would be $0.30 per barrel minus any
blending and transaction costs. However, the actual
price of fuel 1 is $16.08, so this plan does not
represent an arbitrage opportunity.
The no-arbitrage pricing principle is simply a
generalization of the previous example. No arbitrage
means that the price of any fuel must be less than or
equal to the cost of any blend of fuels of equal or
better quality. As mentioned earlier, better means
larger API, lower viscosity, lower sulfur content, and
higher ﬂash point. In terms of linear properties,
better means lower density, lower linear viscosity,
lower sulfur content, and lower linear ﬂash point.
Any number of fuels (not just two) can be blended
together.
Davies would like to develop a system that auto-
matically checks the no-arbitrage pricing condition
for all of the fuels. If the condition is violated, she
would like to know the appropriate amounts of the
fuels to buy to create the arbitrage, the proﬁt per
barrel of the blended fuel, and the characteristics of
the blended fuel.
Table 4.21 Properties of Available Fuels Measured in Units That Combine Linearly
Fuel 1 
Fuel 2 
Fuel 3 
Fuel 4 
Fuel 5 
Fuel 6 
1% Sulfur
3% Sulfur 
0.7% Sulfur
Heating
1% Vacuum
2% Vacuum
Fuel Oil 
Fuel Oil 
Fuel Oil
Oil
Gas Oil
Gas Oil
Density 
0.996 
0.996 
0.996 
0.855 
0.904 
0.904 
Linear visc. 
1.819 
1.819 
1.819 
0.243 
1.170 
1.170 
Sulfur 
1.000 
3.000 
0.700 
0.200 
1.000 
2.000 
Linear ﬂash 
204.800 
204.800 
204.800 
260.400 
52.500 
52.500 
Price 
16.080 
13.250 
17.330 
24.100 
20.830 
20.100 
Fuel 7 
Fuel 8 
Fuel 9 
Fuel 10 
Fuel 11 
Fuel 12 
0.5% Vacuum
Straight Run
Straight Run
Kerosene
Diesel
Gas Oil 
(Low Sulfur)
(High Sulfur)
Jet Fuel
Fuel
Slurry
Density 
0.904 
0.928 
0.953 
0.797
0.850
1.114 
Linear visc. 
1.170 
1.678 
1.678 
.782 
.054 
1.716 
Sulfur 
0.500 
0.300 
2.750 
0.125 
0.200 
2.370 
Linear ﬂash 
52.500 
18.500 
18.500 
308.800 
161.700 
437.000 
Price 
21.460 
21.000 
20.000 
25.520 
24.300 
11.500 
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Questions
1.
Suppose that 0.3 barrel of fuel 2, 0.3 barrel of
fuel 3, and 0.4 barrel of fuel 4 are blended
together.What is the cost of the blended fuel?
What are the (linear) properties of the blended
fuel (i.e., density, linear viscosity, sulfur content,
and linear ﬂash point)?
2.
Using the data from Table 4.21, check whether
any of the fuels violate the no-arbitrage pricing
condition. If no fuel violates the condition,
which fuel’s price comes the closest to the 
no-arbitrage upper bound? If there is a violation,
give the explicit recipe.
3.
What modiﬁcations would you make to the
analysis to account for blending costs?
4.
What would be the important issues or steps
involved in creating a real system for this
problem? ■
224
Chapter 4
Linear Programming Models
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Case 4.4 Foreign Currency Trading
225
D
aily trading volume in the foreign exchange mar-
kets often exceeds $1 trillion. Participants trade
in the spot currency markets, forward markets, and
futures markets. In addition, currency options, cur-
rency swaps, and other derivative contracts are
traded. For simplicity, this case focuses on the spot
currency market only. A spot currency transaction is
simply an agreement to buy some amount of one
currency using another currency.14 For example, a
British company might need to pay a Japanese
supplier 150 million yen. Suppose that the spot
yen/pound rate is 134.33. Then the British company
could use the spot currency market to buy
150 million yen at a cost of 1,116,653 (150,000,000
134.33) British pounds. A sample of today’s cross-
currency spot rates is given in the ﬁle Currency
Rates.xlsx.
To continue the example, suppose the company
canceled the order from the supplier and wanted to
convert the 150 million yen back into British pounds.
If the pound/yen spot rate is 0.00743, the company
could use the 150 million yen to buy 1,114,500
(150,000,000 	 0.00743) pounds. Note that the
1,114,500 pounds is less than the original 1,116,653
pounds. The difference is the result of the bid-offer
spread: The price to buy yen (the bid price) is
greater than the price to sell yen (the offer price).
The bid-offer spread represents a transaction cost to
the company.
C A S E
4.4 FOREIGN CURRENCY TRADING
Occasionally, market prices may become “out of
line” in the sense that there are arbitrage opportuni-
ties. In this context, arbitrage means that there is a
set of spot currency transactions that creates
positive wealth but does not require any funds to
initiate—that is, it is a “money pump.” When such
pure arbitrage opportunities exist, supply and de-
mand forces will generally move prices to eliminate
the opportunities. Hence, it is desirable to quickly
identify arbitrage opportunities when they do exist
and to take advantage of them to the greatest extent
possible.
Questions
1.
Develop an LP model to determine whether
there are any arbitrage opportunities with the
spot currency rates given in the ﬁle. Note that
an arbitrage opportunity could involve several
currencies. If there is an arbitrage opportunity,
your model should specify the exact set of
transactions to achieve it.
2.
Find the cross-currency rates in a recent 
newspaper—for example, in the Wall Street
Journal—or on the Web at http://www.oanda.com/
convert/classic. Check the numbers for an
arbitrage opportunity. If you ﬁnd one, do you
think it represents a real arbitrage opportunity?
Why or why not? ■
14A spot transaction agreed to today is settled (i.e., the money
changes hands) two business days from today. By contrast, a three-
month forward transaction agreed to today is settled (approxi-
mately) three months from today.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

227
Network Models
C H A P T E R
RESTRUCTURING BASF NORTH 
AMERICA’S
DISTRIBUTION SYSTEM
A
quick look through Interfaces, the journal that chronicles management
science success stories from real applications, indicates that many of
these success stories involve network optimization, the subject of this
chapter. A typical example appears in Sery et al. (2001). The authors
describe their efforts to restructure BASF North America’s distribution
system. The BASF Group, with headquarters in Germany, is one of the
world’s leading chemical companies, with annual sales over $30 billion and
more than 100,000 employees worldwide. BASF offers a variety of chemical
and chemical-based products to customers in Europe, the NAFTA region,
South America, and Asia. You probably know the company from its catchy
slogan,“We don’t make a lot of the products you buy. We make a lot of the
products you buy better.” Its diverse product mix includes chemicals,
polymers, automotive coatings, colors, dyes, pharmaceuticals, nylon fibers, and
agricultural products.
In the mid-1990s, BASF examined its distribution of packaged goods in
the North America region and discovered that it shipped 1.6 billion pounds
of finished goods annually to customers from a network of 135 locations
at an annual cost, including transportation and warehousing, of nearly
$100 million. The majority (86) of the 135 locations were distribution
5
© FRANK RUMPENHORST/DPA/Landov
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

centers (DCs), although almost a billion pounds were shipped directly from plants to
customers. Unfortunately, there had never been any systematic attempt to optimize this
network configuration; it had just evolved over the years. The authors of the study
were asked to make recommendations that would (1) decrease logistics costs and
(2) increase customer service, defined as the percentage of shipments that reach the
customer on the same day or the next day. (This percentage was about 77% before the
study.) The authors developed a linear programming model that, when implemented,
was able to (1) reduce the number of DCs from 86 to 12; (2) reduce the annual trans-
port, facility, and inventory carrying costs by 6%; (3) achieve a one-time 9% improve-
ment in cash flows from a reduction in the working capital tied up in inventory; and
(4) increase the customer service measure to 90%. The redesign worked so well that
BASF later developed similar models for its European, Scandinavian, and Far East
distribution systems.
The article’s description of the study is a virtual textbook example of the modeling
process described in Chapter 1 of this book. The problem was first identified as fol-
lows:“Define the optimal number and location of warehouses and the corresponding
material flows needed to meet anticipated customer demand and required delivery ser-
vice times at the lowest overall cost.” The project team next performed the arduous
task of collecting the various demands and costs required for the optimization model.
Although we try to indicate “Where Do the Numbers Come From?” in the examples in
this book, the authors of the study describe just how difficult data collection can be,
particularly when the data is stored in a variety of legacy systems that use a wide range
of data definitions. Next, the authors developed a verbal statement of the model,
including all assumptions they made, which was then translated in a straightforward
manner into the network optimization model itself. The next step was to build a deci-
sion support system to implement the model. This user-friendly system allowed BASF
management to become comfortable with the model (and learn to trust it) by running
it repeatedly under different scenarios to answer all sorts of what-if questions. Finally,
the model’s recommendations were used to redesign the distribution system in North
America, and an honest evaluation of its effects—reduced costs and increased
customer service—was made. ■
228
Chapter 5
Network Models
5.1 INTRODUCTION
Many important optimization models have a natural graphical network representation. In
this chapter, we discuss some specific examples of network models. There are several rea-
sons for distinguishing network models from other LP models:
■
The network structure of these models allows them to be represented graphically in a
way that is intuitive to users. This graphical representation can then be used as an aid
in the spreadsheet model development. In fact, for a book at this level, the best argu-
ment for singling out network problems for special consideration is the fact that they
can be represented graphically.
■
Many companies have real problems, often extremely large, that can be represented
as network models. In fact, many of the best management science success stories
have involved large network models. For example, Delta Airlines developed a
network model to schedule its entire fleet of passenger airplanes. A few other real
applications of network-based models are listed throughout the chapter, but the list
is by no means exhaustive. A quick scan of the articles in the Interfaces journal
indicates that there are probably more network-based applications reported than any
other type.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

■
Specialized solution techniques have been developed specifically for network
models. Although we do not discuss the details of these solution techniques—and
they are not implemented in Excel’s Solver—they are important in real-world appli-
cations because they allow companies to solve huge problems that could not be
solved by the usual LP algorithms.
5.2 TRANSPORTATION MODELS
In many situations, a company produces products at locations called origins and ships
these products to customer locations called destinations. Typically, each origin has a
limited amount that it can ship, and each customer destination must receive a required
quantity of the product. Spreadsheet optimization models can be used to determine the
minimum-cost shipping plan for satisfying customer demands.
For now, we assume that the only possible shipments are those directly from an origin
to a destination. That is, no shipments between origins or between destinations are possi-
ble. This problem—generally called the transportation pr oblem—has been studied
extensively in management science. In fact, it was one of the first management science
models developed, more than a half century ago. The following is a typical example of a
small transportation problem.
5.2 Transportation Models
229
E X A M P L E
5.1 SHIPPING CARS FROM PLANTS TO REGIONS OF THE COUNTRY
T
he Grand Prix Automobile Company manufactures automobiles in three plants and
then ships them to four regions of the country. The plants can supply the amounts
listed in the right column of Table 5.1. The customer demands by region are listed in the
bottom row of this table, and the unit costs of shipping an automobile from each plant to
each region are listed in the middle of the table. Grand Prix wants to find the lowest-cost
shipping plan for meeting the demands of the four regions without exceeding the capacities
of the plants.
Table 5.1
Input Data for Grand Prix Example
Region 1
Region 2
Region 3
Region 4
Capacity
Plant 1
131
218
266
120
450
Plant 2
250
116
263
278
600
Plant 3
178
132
122
180
500
Demand
450
200
300
300
Objective
To develop a spreadsheet optimization model that finds the least-cost way of
shipping the automobiles from plants to regions, staying within plant capacities and meet-
ing regional demands.
WHERE DO THE NUMBERS COME FROM?
A typical transportation problem requires three sets of numbers: capacities (or supplies),
demands (or requirements), and unit shipping (and possibly production) costs. We discuss
each of these next.
■
The capacities indicate the most each plant can supply in a given amount of time—a
month, say—under current operating conditions. In some cases it might be possible to
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

increase the “base” capacities, by using overtime, for example. In such cases the model
could be modified to determine the amounts of additional capacity to use (and pay for).
■
The customer demands are typically estimated from some type of forecasting model
(as discussed in Chapter 14). The forecasts are often based on historical customer
demand data.
■
The unit shipping costs come from a transportation cost analysis—what does it really
cost to send a single automobile from any plant to any region? This is not an easy
question to answer, and it requires an analysis of the best mode of transportation
(such as railroad, ship, or truck). However, companies typically have the required
data. Actually, the unit “shipping” cost can also include the unit production cost at each
plant. However, if this cost is the same across all plants, as we are tacitly assuming
here, it can be omitted from the model.
Solution
The variables and constraints required for this model are listed in Table 5.2. The company
must decide exactly the number of autos to send from each plant to each region—a ship-
ping plan. Then it can calculate the total number of autos sent out of each plant and the
total number received by each region.
230
Chapter 5
Network Models
Table 5.2
Variables and Constraints for Transportation Model
Input variables
Plant capacities, regional demands, unit shipping costs
Decision variables (changing cells)
Number of autos sent from each plant to each region
Objective cell
Total shipping cost
Other calculated variables
Number sent out of each plant, number sent to each 
region
Constraints
Number sent out of each plant
Plant capacity
Number sent to each region
Region demand
Ú
…
In a transportation
problem all flows go
from left to right—
from origins to
destinations.You will
see more complex
network structures in
the next subsection.
Figure 5.1
Network
Representation of
Transportation
Model
Representing Transportation in a Network Model
A network diagram of this model appears in Figure 5.1. This diagram is typical of network
models. It consists of nodes and arcs. A node, indicated by a circle, generally represents a
geographical location. In this case the nodes on the left correspond to plants, and the nodes
on the right correspond to regions. An arc, indicated by an arrow, generally represents a
route for getting a product from one node to another. Here, the arcs all go from a plant node
to a region node—from left to right.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

5.2 Transportation Models
231
2
Shipping plan. Enter any trial values for the shipments from plants to regions in the
Shipping_plan range. These are the changing cells. Note that this rectangular range is
exactly the same shape as the range where the unit shipping costs are entered. This is a nat-
ural model design, and it simplifies the formulas in the following steps.
3
Numbers shipped from plants. To calculate the amount shipped out of each plant in
the range G13:G15, highlight this range and click on the summation () toolbar button.
4
Amounts received by regions. Similarly, calculate the amount shipped to each region
in the range C16:F16 by highlighting the range and clicking on the summation button.
5
Total shipping cost. Calculate the total cost of shipping power from the plants to the
regions in the Total_cost cell with the formula
SUMPRODUCT(C6:F8,Shipping_plan)
1There can even be lower limits, other than zero, on certain flows, but we don’t consider any such models here.
2From here on, we might not remind you about creating range names, but we will continue to list our suggested
range names on the spreadsheets.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
A
B
C
D
E
F
G
H
I
J
K
Grand Prix
e
g
n
a
R
le
d
o
m
names used:
Capacity
=Model!$I$13:$I$15
Unit shipping costs
Demand
=Model!$C$18:$F$18
5
1
$
F
$:3
1
$
C
$
!le
d
o
M
=
n
alP
_
g
nip
pih
S
o
T
Region 1
Region 2
Region 3
Region
1
2
$
B
$
!le
d
o
M
=
ts
o
c
_la
t
o
T
4
From
Plant
6
1
$
F
$:6
1
$
C
$
!le
d
o
M
=
d
e
vie
c
e
r
_la
t
o
T
$120
$266
$218
$131
1
Plant
1
$
G
$:3
1
$
G
$
!le
d
o
M
=
d
e
p
pih
s
_la
t
o
T
$278
$263
$116
$250
2
5
Plant 3
$178
$132
$122
$180
Shipping plan, and constraints on supply and demand
To
Region 1
Region 2
Region 3
Region 4 Total shipped
Capacity
From
Plant 1
150
0
0
300
450
<=
450
Plant 2
100
200
0
0
300
<=
600
Plant 3
200
0
300
0
500
<=
500
Total received
450
200
300
300
>=
>=
>=
>=
Demand
450
200
300
300
to minimize
Total cost
$176,050
Figure 5.2
Transportation Model
The problem data fit nicely on such a diagram. The capacities are placed next to the
plant nodes, the demands are placed next to the region nodes, and the unit shipping costs
are placed on the arcs. The decision variables are usually called flows. They represent the
amounts shipped on the various arcs. Sometimes (although not in this problem), there are
upper limits on the flows on some or all of the arcs. These upper limits, called arc capaci-
ties, can also be shown on the diagram.1
DEVELOPING THE SPREADSHEET MODEL
The spreadsheet model appears in Figure 5.2. (See the file Transportation 1.xlsx.) To
develop this model, perform the following steps.
1
Inputs.2 Enter the unit shipping costs, plant capacities, and region demands in the
blue cells.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

This formula sums all products of unit shipping costs and amounts shipped. You now see
the benefit of placing unit shipping costs and amounts shipped in similar-size rectangular
ranges—you can then use the SUMPRODUCT function.
USING SOLVER
Invoke Solver with the settings shown in Figure 5.3. As usual, check the Non-Negative
option and specify the Simplex LP method before optimizing.
232
Chapter 5
Network Models
It is typical in
transportation 
models, especially 
large models, that 
only a relatively few 
of the possible routes
are used.
Figure 5.3
Solver Dialog Box
for Transportation
Model
Discussion of the Solution
The Solver solution appears in Figure 5.2 and is illustrated graphically in Figure 5.4. The
company incurs a total shipping cost of $176,050 by using the shipments listed in Figure 5.4.
Except for the six routes shown, no other routes are used. Most of the shipments occur on
the low-cost routes, but this is not always the case. For example, the route from plant 2 to
region 1 is relatively expensive, and it is used. On the other hand, the route from plant 3 to
region 2 is relatively cheap, but it is not used. A good shipping plan tries to use cheap
routes, but it is constrained by capacities and demands.
Note that the available capacity is not all used. The reason is that total capacity is
1550, whereas total demand is only 1250. Even though the demand constraints are of the
“
” type, there is clearly no reason to send the regions more than they request because it
only increases shipping costs. Therefore, the optimal plan sends them the minimal
Ú
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

amounts they request and no more. In fact, the demand constraints could have been mod-
eled as “” constraints, and Solver would have reached exactly the same solution.
Sensitivity Analysis
There are many sensitivity analyses you could perform on the basic transportation model.
For example, you could vary any one of the unit shipping costs, capacities, or demands.
The effect of any such change in a single input is captured nicely in Solver’s sensitivity
report, shown in Figure 5.5. The top part indicates the effects of changes in the unit ship-
ping costs. The results here are typical. For all routes with positive flows, the correspond-
ing reduced cost is zero, whereas for all routes not currently being used, the reduced cost
indicates how much less the unit shipping cost would have to be before the company would
start shipping along that route. For example, if the unit shipping cost from plant 2 to region
3 decreased by more than $69, this route would become attractive.
5.2 Transportation Models
233
Figure 5.4
Graphical
Representation of
Optimal Solution
Final
Reduced
Allowable
Allowable
Cell
Name
Value
Cost
Coeﬃcien
Objecve
t
Increase
Decrease
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
A
B
C
D
E
F
G
H
Adjustable Cells
$C$13 Plant 1 Region 1
150
0
131
119
13
$D$13 Plant 1 Region 2
0
221
218
1E+30
221
$E$13 Plant 1 Region 3
0
191
266
1E+30
191
$F$13 Plant 1 Region 4
300
0
120
13
239
$C$14 Plant 2 Region 1
100
0
250
39
72
$D$14 Plant 2 Region 2
200
0
116
88
116
$E$14 Plant 2 Region 3
0
69
263
1E+30
69
$F$14 Plant 2 Region 4
0
39
278
1E+30
39
$C$15 Plant 3 Region 1
200
0
178
13
69
$D$15 Plant 3 Region 2
0
88
132
1E+30
88
$E$15 Plant 3 Region 3
300
0
122
69
194
$F$15 Plant 3 Region 4
0
13
180
1E+30
13
Constraints
Final
Shadow
Constraint
Allowable
Allowable
Cell
Name
Value
Price
R.H. Side
Increase
Decrease
$G$13 Plant 1 Total shipped
450
-119
450
100
150
$G$14 Plant 2 Total shipped
300
0
600
1E+30
300
$G$15 Plant 3 Total shipped
500
-72
500
100
200
$C$16 Total received Region 1
450
250
450
300
100
$D$16 Total received Region 2
200
116
200
300
200
$E$16 Total received Region 3
300
194
300
200
100
$F$16 Total received Region 4
300
239
300
150
100
Figure 5.5
Solver’s Sensitivity
Report for
Transportation
Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

The bottom part of this report is useful because of its shadow prices. For example,
plants 1 and 3 are currently shipping all of their capacity, so the company would benefit
from having more capacity at these plants. In particular, the report indicates that each extra
unit of capacity at plant 1 is worth $119, and each extra unit of capacity at plant 3 is worth
$72. However, because the allowable increase for each of these is 100, you know that after
an increase in capacity of 100 at either plant, further increases will probably be worth less
than the current shadow prices.
One interesting analysis that cannot be performed with Solver’s sensitivity report is to 
keep shipping costs and capacities constant and allow all of the demands to change by a
certain percentage (positive or negative). To perform this analysis, use SolverTable, with
the varying percentage as the single input. Then keep track of the total cost and any partic-
ular amounts shipped of interest. The key to doing this correctly is to modify the model
slightly, as illustrated in the previous chapter, before running SolverTable. The appropriate
modifications appear in the third worksheet of the finished Transportation 1.xlsx file.
Then run SolverTable, allowing the percentage change in all demands to vary from 20%
to 30% in increments of 5%, and keep track of total cost. As the table in Figure 5.6 shows,
the total shipping cost increases at an increasing rate as the demands increase. However, at
some point the problem becomes infeasible. As soon as the total demand is greater than the
total capacity, it is impossible to meet all demand.
234
Chapter 5
Network Models
The key to this
sensitivity analysis is 
to modify the model
slightly before running
SolverTable.
3
4
5
6
7
8
9
10
11
12
13
14
15
A
B
C
D
E
F
G
% change in demands (cell $I$10) values along side, output cell(s) along top
Total_cost
Increase
-20% $130,850
-15% $140,350
$9,500
-10% $149,850
$9,500
-5% $162,770
$12,920
0% $176,050
$13,280
5% $189,330
$13,280
10% $202,610
$13,280
15% $215,890
$13,280
20% $229,170
$13,280
25% Not feasible
30% Not feasible
Figure 5.6
Sensitivity Analysis
to Percentage
Changes in All
Demands
An Alternative Model
The transportation model in Figure 5.2 is a very natural one. In the graphical representation
in Figure 5.1, note that all arcs go from left to right, that is, from plants to regions.
Therefore, the rectangular range of shipments allows you to calculate shipments out of
plants as row sums and shipments into regions as column sums. In anticipation of later mod-
els in this chapter, however, where the graphical network can be more complex, we present
an alternative model of the transportation problem. (See the file Transportation 2.xlsx.)
First, it is useful to introduce some additional network terminology. Recall that flows
are the amounts shipped on the various arcs. The direction of the arcs indicates which way
the flows are allowed to travel. An arc pointed into a node is called an inflow, whereas an
arrow pointed out of a node is called an outflow. In the basic transportation model, all
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

outflows originate from suppliers, and all inflows go toward demanders. However, general
networks can have both inflows and outflows for any given node.
With this general structure in mind, the typical network model has one changing cell
per arc. It indicates how much (if any) to send along that arc in the direction of the arrow.
Therefore, it is often useful to model network problems by listing all of the arcs and their
corresponding flows in one long list. Then constraints can be indicated in a separate sec-
tion of the spreadsheet. Specifically, for each node in the network, there is a flow balance
constraint. These flow balance constraints for the basic transportation model are simply
the supply and demand constraints already discussed, but they can be more general for
other network models, as will be discussed in the next subsection.
The alternative model of the Grand Prix problem appears in Figure 5.7. The plant and
region indexes and the associated unit shipping costs are entered manually in the range
A5:C16. Each row in this range corresponds to an arc in the network. For example, row 12
corresponds to the arc from plant 2 to region 4, with unit shipping cost $278. Then the
changing cells for the flows are in column D. (If there were arc capacities, they could be
placed to the right of the flows.)
5.2 Transportation Models
235
Although this model 
is possibly less natural
than the original
model, it generalizes
better to other logis-
tics models in this
chapter.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
A
B
C
D
E
F
G
H
I
J
K
L
M
Grand Prix transporta on model: a more general network
e
g
n
a
R
n
oit
alu
m
r
o
f
names used:
Capacity
=Model!$I$6:$I$8
Network structure and
w
olF
s
w
olf
balance constraints
Demand
=Model!$I$12:$I$15
Origin
Des na on
Unit cost
Flow
Capacity
6
1
$
B
$:5
$
B
$
!le
d
o
M
=
n
oit
a
nits
e
D
st
nia
rts
n
o
c
1
1
131
150
Plant
Ou low
Capacity
Flow
=Model!$D$5:$D$16
1
2
218
0
1
450
<=
450
Inﬂow
=Model!$G$12:$G$15
1
3
266
0
2
300
<=
600
Origin
=Model!$A$5:$A$16
1
4
120
300
3
500
<=
500
Ou low
=Model!$G$6:$G$8
9
1
$
B
$
!le
d
o
M
=
ts
o
C
_la
t
o
T
0
0
1
0
5
2
1
2
2
2
116
200
Demand constraints
2
3
263
0
Region
Inﬂow
Demand
2
4
278
0
1
450
>=
450
3
1
178
200
2
200
>=
200
3
2
132
0
3
300
>=
300
3
3
122
300
4
300
>=
300
3
4
180
0
Objec ve to minimize
Total Cost
$176,050
Figure 5.7
Alternative Form of Transportation Model
The flow balance constraints are conceptually straightforward. Each cell in the
Outflow and Inflow ranges in column G contains the appropriate sum of flows. For exam-
ple, cell G6, the outflow from plant 1, represents the sum of cells D5 through D8, whereas
cell G12, the inflow to plant 1, represents the sum of cells D5, D9, and D13. Fortunately,
there is an easy way to enter these summation formulas.3 The trick is to use Excel’s built-
in SUMIF function, in the form SUMIF(CompareRange,Criteria,SumRange). For exam-
ple, the formula in cell G6 is
SUMIF(Origin,F6,Flow)
This formula compares the plant number in cell F6 to the Origin range in column A and
sums all flows where they are equal—that is, it sums all flows out of plant 1. This formula
3Try entering these formulas manually, even for a 3  4 transportation model, and you will see why the SUMIF
function is so handy.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

can be copied down to cell G8 to obtain the flows out of the other plants. For flows into
regions, the similar formula in cell G12 for the flow into region 1 is
SUMIF(Destination,F12,Flow)
and this can be copied down to cell G15 for flows into the other regions. In general, the
SUMIF function finds all cells in the first argument that satisfy the criterion in the second
argument and then sums the corresponding cells in the third argument. It is a very handy
function—and not just for network modeling.
Excel Function: SUMIF
The SUMIF function is useful for summing values in a certain r ange if cells in a r elated
range satisfy a given condition. It has the syntax 
SUMIF (compareRange,criterion,
sumRange), where compareRange and sumRang e are similar-size ranges. This formula
checks each cell in compareRange to see whether it satisfies the criterion. If it does, it adds
the corresponding value in sumRang e to the o verall sum. F or e xample, SUMIF(A12:
A23,1,D12:D23) sums all values in the range D12:D23 where the corresponding cell in the
range A12:A23 has the value 1.
This use of the SUMIF function, along with the list of origins, destinations, unit costs,
and flows in columns A through D, is the key to the model. The rest is straightforward. The
total cost is a SUMPRODUCT of unit costs and flows, and the Solver dialog box is set up
as shown in Figure 5.8.
236
Chapter 5
Network Models
Figure 5.8
Solver Dialog Box
for Alternative
Transportation
Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

This alternative model generalizes nicely to other network problems. Essentially, it
shows that all network models look alike. There is an additional benefit from this alterna-
tive model. Suppose that flows from certain plants to certain regions are not allowed.
(Maybe no roads exist.) It is not easy to disallow such routes in the original model. The
usual trick is to allow the “disallowed” routes but to impose extremely large unit shipping
costs on them. This works, but it is wasteful because it adds changing cells that do not
really belong in the model. However, the alternative network model simply omits arcs that
are not allowed. For example, if the route from plant 2 to region 4 is not allowed, you
simply omit the data in the range A12:D12. This creates a model with exactly as many
changing cells as allowable arcs. This additional benefit can be very valuable when the
number of potential arcs in the network is huge—even though the vast majority of them are
disallowed—which is exactly the situation in many large network models.
We do not necessarily recommend this more general network model for simple
transportation problems. In fact, it is probably less natural than the original model in
Figure 5.2. However, it paves the way for the more complex network problems 
discussed next.
■
5.2 Transportation Models
237
The alternative
network model not
only accommodates
more general net-
works, but it is more
efficient in that it 
has the fewest num-
ber of changing cells.
Depending on how you
treat the demand
constraints, you can get
several varieties of the
basic transportation
model.
MODELING ISSUES
1. The customer demands in typical transportation problems can be handled in one of
two ways. First, you can think of these forecasted demands as minimal requirements
that must be sent to the customers. This is how regional demands were treated here.
Alternatively, you could consider the demands as maximal sales quantities, the most
each region can sell. Then you would constrain the amounts sent to the regions to be
less than or equal to the forecasted demands. Whether the demand constraints are
expressed as “
” or “
” (or even “”) constraints depends on the context of the
problem—do the dealers need at least this many, do they need exactly this many, or
can they sell only this many?
2. If all the supplies and demands for a transportation problem are integers, the optimal
Solver solution automatically has integer-valued shipments. Explicit integer con-
straints are not required. This is a very important benefit. It means that the “fast”
simplex method can be used rather than much slower integer algorithms.
3. Shipping costs are often nonlinear (and “nonsmooth”) due to quantity discounts.
For example, if it costs $3 per item to ship up to 100 items between locations and
$2 per item for each additional item, the proportionality assumption of LP is violated
and the resulting transportation model is nonlinear. Shipping problems that involve
quantity discounts are generally quite difficult to solve.
4. Excel’s Solver uses the simplex method to solve transportation problems. There is a
streamlined version of the simplex method, called the transportation simplex method,
that is much more efficient than the ordinary simplex method for transportation
problems. Large transportation problems are usually solved with the transportation
simplex method. See Winston (2003) for a discussion of the transportation simplex
method.
5. LeBlanc and Galbreth (2007a, 2007b) discuss a large network model they developed
for a client. They indicate that our SUMIF method can be inefficient for really large
models. They recommend writing a macro in VBA to sum the appropriate flows in
and out of nodes. ■
Extending the basic Grand Prix transportation model is fairly easy, even when the cost
structure is considerably more complex. We illustrate one such extension in the following
example.
…
Ú
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Objective
To extend the previous Grand Prix transportation model to take into account
varying production costs, selling prices, and tax rates.
WHERE DO THE NUMBERS COME FROM?
We leave it to the cost accountants to derive the numbers in Table 5.3 and Table 5.4. This
is no easy task, particularly in a global setting, but the numbers should be available.
Solution
In addition to the variables required for the original transportation model in Example 5.1,
one extra set of calculations is required to find the after-tax profit per automobile produced
in a given plant and sold in a given region. Given these unit after-tax profits, it is straight-
forward to calculate the total after-tax profit from any production/shipping plan, and this
becomes the objective to maximize. The details follow next.
DEVELOPING THE SPREADSHEET MODEL
The completed spreadsheet model appears in Figure 5.9. (See the file Transportation 3.xlsx.)
Because the only differences from the previous example are in the monetary section, from
row 25 down, only the following two steps are needed to extend the model in Figure 5.2.
238
Chapter 5
Network Models
E X A M P L E
5.2 PRODUCTION AND SHIPMENT OF AUTOMOBILES
WITH VARYING TAX RATES
C
onsider again Grand Prix’s problem of shipping automobiles from three plants to four
regions. However, the problem is now extended in two directions. First, we assume that
Grand Prix not only ships the autos, but it manufactures them at the plants and sells them in
the various regions. Second, we assume that this problem takes place in a global context.
The effect is that the unit production costs vary by plant, the unit selling prices vary by
region, and the tax rates on profits vary according to the plant at which the autos are pro-
duced (regardless of where they are sold). The capacities of the plants, the demands of the
regions, and the unit shipping costs are the same as before, as shown earlier in Table 5.1. In
addition, the unit production costs and tax rates are given in Table 5.3, and the unit selling
prices in Table 5.4. For example, if plant 1 produces an auto and ships it to region 2, where
it is sold, the profit before taxes is $20,520  $14,350  $218  $5,952. This is taxed at
plant 1’s rate of 30%, so the after-tax profit is $5,952(1  0.3)  $4,166.40. The company
now needs to find a production and shipping plan that maximizes its after-tax profit.
Table 5.3 Plant Production Costs and Tax Rates for the Grand Prix Problem
Plant
Unit Production Cost
Tax Rate
1
$14,350
30%
2
$16,270
35%
3
$16,940
22%
Table 5.4 Selling Prices in Regions
Region
Unit Selling Price
1
$19,290
2
$20,520
3
$17,570
4
$18,320
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

5.2 Transportation Models
239
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
A
B
C
D
E
F
G
H
I
J
K
L
M
Grand Prix transportaon model with taxes
Input data
Range names used:
Unit shipping costs (shipping only)
Aer_tax_proﬁt =Model!$B$31
t
n
alP
o
T
 
tic
a
p
a
C
a
t
a
d
y
=Model!$I$16:$I$18
Region 1
Region 2
Region 3
Region 4
Unit cost
Tax rate
Demand
=Model!$C$21:$F$21
From
Plant 1
$131
$218
$266
$120
$14,350
30%
Shipping_plan
=Model!$C$16:$F$18
Plant 2
$250
$116
$263
$278
$16,270
35%
Total_received
=Model!$C$19:$F$19
Plant 3
$178
$132
$122
$180
$16,940
22%
Total_shipped
=Model!$G$16:$G$18
Unit selling prices at regions
$19,290
$20,520
$17,570
$18,320
Shipping plan, and constraints on supply and demand
To
Region 1
Region 2
Region 3
Region 4 Total shipped
Capacity
From
Plant 1
450
0
0
0
450
<=
450
Plant 2
0
0
300
300
600
<=
600
Plant 3
0
500
0
0
500
<=
500
Total received
450
500
300
300
>=
>=
>=
>=
Demand
450
200
300
300
Monetary outputs
Aer-tax proﬁt per unit produced in given plant and sold in given region
Region 1
Region 2
Region 3
Region 4
Plant 1
$3,366.30
$4,166.40
$2,067.80
$2,695.00
Plant 2
$1,800.50
$2,687.10
$674.05
$1,151.80
Plant 3
$1,694.16
$2,689.44
$396.24
$936.00
Objecve to maximize
Aer-tax proﬁt
$3,407,310
Figure 5.9
Spreadsheet Model for the Extended Grand Prix Problem
This is another exam-
ple of how the careful
planning of spread-
sheet layout simplifies
the development of
the model.
1
Unit after-tax profits. The after-tax profit is the unit selling price minus the produc-
tion cost minus the shipping cost, all multiplied by 1 minus the tax rate. Calculate this for
the plant 1, region 1 combination in cell C26 with the formula
=(C$11-$H7-C7)*(1-$I7)
and copy it to the range C26:F28 for the other combinations. Note how you can use a single
formula to fill this entire range. This takes careful modeling (entering the plant production cost
and tax rate data in columns, and the region selling price data in a row) and appropriate use of
absolute and relative addresses, but it is more efficient and certainly less likely to cause errors.
2
Total after-tax profit. Calculate the total after-tax profit in cell B31 with the formula
=SUMPRODUCT(C26:F28,Shipping_plan)
USING SOLVER
The Solver setup is practically the same as before, as shown in Figure 5.10. However, don’t
forget to check the Maximize option—you do not want to minimize after-tax profit.
Discussion of the Solution
The optimal solution shown in Figure 5.9 uses only four of the possible 12 routes, and, sur-
prisingly, these are not the four routes with the largest unit after-tax profits. In fact, the
route with the largest after-tax profit, from plant 1 to region 2, is not used at all. The reason
for this is that if this route were used to its fullest extent, region 1’s demand would have to
be satisfied from plant 2 or 3, and both of these routes have very low unit after-tax profits.
Of course, Solver figures this out for you.
Note also that the demand constraints cannot now be changed to “” constraints. In
the previous example, there was no incentive to use all plant capacity, but now there is. The
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

selling prices are large enough that every automobile sale adds to after-tax profit, so the
company sells as many as it can. Of course, this raises the question of how many automo-
biles each region can really sell. It might be more realistic to keep the lower bounds on
sales (the current demand constraints) but to impose upper limits on sales as well. We ask
you to explore this in one of the problems.
■
240
Chapter 5
Network Models
Figure 5.10
Solver Dialog Box
for the Extended
Grand Prix Model
P R O B L E M S
Solutions for problems whose numbers appear within a
colored box can be found in the Student Solutions Files.
Refer to this book’s preface for purchase information.
Skill-Building Problems
1.
In the original Grand Prix example, the total capacity of
the three plants is 1550, well above the total customer
demand. Would it help to have 100 more units of
capacity at plant 1? What is the most Grand Prix
would be willing to pay for this extra capacity? Answer
the same questions for plant 2 and for plant 3. Explain
why extra capacity can be valuable even though the
company already has more total capacity than it
requires.
2.
The optimal solution to the original Grand Prix
problem indicates that with a unit shipping cost of
$132, the route from plant 3 to region 2 is evidently
too expensive—no autos are shipped along this route.
Use SolverTable to see how much this unit shipping
cost would have to be reduced before some autos
would be shipped along this route.
3.
Suppose in the original Grand Prix example that the
routes from plant 2 to region 1 and from plant 3 to
region 3 are not allowed. (Perhaps there are no rail-
road lines for these routes.) How would you modify
the original model (Figure 5.2) to rule out these
routes? How would you modify the alternative model
(Figure 5.7) to do so? Discuss the pros and cons of
these two approaches.
4.
In the Grand Prix example with varying tax rates, the
optimal solution more than satisfies customer demands.
Modify the model so that regions have not only lower
limits on the amounts they require, but upper limits on
the amounts they can sell. Assume these upper limits are
50 autos above the required lower limits. For example,
the lower and upper limits for region 1 are 450 and 500.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Modify the model and find the optimal solution. How
does it differ from the solution without upper limits?
5.
In the Grand Prix example with varying tax rates, the
optimal solution uses all available plant capacity
and more than satisfies customer demands. Will this
always be the case? Experiment with the unit selling
prices and/or tax rates to see whether the company
ever uses less than its total capacity.
Skill-Extending Problems
6.
Here is a problem to challenge your intuition. In the
original Grand Prix example, reduce the capacity of
plant 2 to 300. Then the total capacity is equal to the
total demand. Reoptimize the model. You should find
that the optimal solution uses all capacity and exactly
meets all demands with a total cost of $176,050. Now
increase the capacity of plant 1 and the demand at
region 2 by 1 automobile each, and optimize again.
What happens to the optimal total cost? How can you
explain this “more for less” paradox?
7.
Continuing the previous problem (with capacity 300
at plant 2), suppose you want to see how much extra
capacity and extra demand you can add to plant 1 and
region 2 (the same amount to each) before the total
shipping cost stops decreasing and starts increasing.
Use SolverTable appropriately to find out. (You will
probably need to use some trial and error on the range
5.3 Assignment Models
241
of input values.) Can you explain intuitively what
causes the total cost to stop decreasing and start
increasing?
8.
Modify the original Grand Prix example as follows.
Increase the demands at the regions by 200 each, so
that total demand is well above total plant capacity.
However, now interpret these “demands” as “maxi-
mum sales,” the most each region can accommodate,
and change the “demand” constraints to become “”
constraints, not “” constraints. How does the optimal
solution change? Does it make realistic sense? If not,
how might you change the model to obtain a realistic
solution?
9.
Modify the original Grand Prix example as follows.
Increase the demands at the regions by 200 each, so
that total demand is well above total plant capacity.
This means that some demands cannot be supplied.
Suppose there is a unit penalty cost at each region for
not supplying an automobile. Let these unit penalty
costs be $600, $750, $625, and $550 for the four
regions. Develop a model to minimize the sum of ship-
ping costs and penalty costs for unsatisfied demands.
(Hint: This requires a trick. Introduce a fourth plant
with plenty of capacity, and set its “unit shipping
costs” to the regions equal to the unit penalty costs.
Then interpret an auto shipped from this fictitious
plant to a region as a unit of demand not satisfied.)
5.3 ASSIGNMENT MODELS
In this section, we examine a class of network models called assignment models.
Assignment models are used to assign, on a one-to-one basis, members of one set to members
of another set in a least-cost (or least-time) manner. The prototype assignment model is the
assignment of machines to jobs. For example, suppose there are four jobs and five machines.
Every pairing of a machine and a job has a given job completion time. The problem is to
assign the machines to the jobs so that the total time to complete all jobs is minimized.
To see how this is a network problem, recall the transportation problem of sending
goods from suppliers to customers. Now think of the machines as the suppliers, the jobs as
the customers, and the job completion times as the unit shipping costs. The capacity of any
machine represents the most jobs it can handle. The “demand” of any job is the number of
times it must be done, usually 1. Finally, there is an arc from every machine to every job it
can handle, and the allowable flows on these arcs are all 0 or 1—a particular machine is
either paired with a particular job (a flow of 1) or it isn’t (a flow of 0). Therefore, this
assignment problem can be modeled exactly like the Grand Prix transportation problem in
Example 5.1 by using the appropriate input values.
An example of this model appears in Figures 5.11 and 5.12. (See the file
Assignment.xlsx.) Here, four jobs must be completed by five machines. Machines 1, 3,
and 5 can handle at most one job apiece, whereas machines 2 and 4 can handle two jobs
apiece. The spreadsheet model in Figure 5.12 is identical to the transportation model dis-
cussed previously, except with different inputs. The only minor difference, as indicated in
the Solver dialog box in Figure 5.13, is that the demand constraints are “” constraints,
because each job must be completed exactly once.
Assignment models
are special cases of
transportation models
where all flows are 0
or 1.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

242
Chapter 5
Network Models
14
1
2
1
1
1
1
1
2
1
5
8
7
5
5
4
8
Machine 1
Job 1
Machine 2
Machine 3
Machine 4
Machine 5
Job 2
Job 3
Job 4
Note: Similar arcs exist out of machines 2, 3, and 4.
Figure 5.11
Network 
Representation of
Assignment of
Machines to Jobs
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
A
B
C
D
E
F
G
H
I
J
K
Assignment of jobs to machines
Times to perform jobs on various 
e
g
n
a
R
s
e
nih
c
a
m
 names used:
9
1
$
F
$:5
1
$
C
$
!le
d
o
M
=
st
n
e
m
n
giss
A
b
o
J
1
2
3
4
Jobs_on_machine
=Model!$G$15:$G$19
9
1
$I$:5
1
$I$
!le
d
o
M
=
ytic
a
p
a
c
_
e
nih
c
a
M
7
8
5
4
1
1
e
nih
c
a
M
0
2
$
F
$:0
2
$
C
$
!le
d
o
M
=
b
oj_
n
o
_
s
e
nih
c
a
M
5
6
2
1
2
2
3
7
8
3
9
Total_me
=Model!$B$25
4
2
4
6
10
5
5
5
4
8
Assignments, and constraints on machine capacies and job compleon requirements
Job
1
2
3
4
Jobs on machine
Machine capacity
Machine
1
0
0
0
0
0
<=
1
2
0
0
0
1
1
<=
2
3
0
0
1
0
1
<=
1
4
1
1
0
0
2
<=
2
5
0
0
0
0
0
<=
1
Machines on job
1
1
1
1
=
=
=
=
Required
1
1
1
1
Objecve to minimize
Total me
14
Figure 5.12
Spreadsheet Model of the Assignment Problem
The optimal solution in Figure 5.12 indicates, by the 1s and 0s in the changing cells,
which machines are assigned to which jobs. Specifically, machine 2 is assigned to job 4,
machine 3 is assigned to job 3, machine 4 is assigned to jobs 1 and 2, and machines 1 and
5 are not assigned to any jobs. With this optimal assignment, it takes 14 time units to com-
plete all jobs.
The following example is a somewhat different and less obvious type of assignment
problem.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

5.3 Assignment Models
243
Figure 5.13
Solver Dialog Box
for the Assignment
Model
E X A M P L E
5.3 ASSIGNING SCHOOL BUSES TO ROUTES AT SPRING VIEW
T
he city of Spring View is taking bids from six bus companies on the eight routes that
must be driven in the surrounding school district. Each company enters a bid of how
much it will charge to drive selected routes, although not all companies bid on all routes.
The data are listed in Table 5.5. (If a company does not bid on a route, the corresponding
entry is blank.) The city must decide which companies to assign to which routes with the
specifications that (1) if a company does not bid on a route, it cannot be assigned to that
route; (2) exactly one company must be assigned to each route; and (3) a company can be
assigned to at most two routes. The objective is to minimize the total cost of covering all
routes.
Table 5.5 Bids on Bus Routes
Company
Route 1
Route 2
Route 3
Route 4
Route 5
Route 6
Route 7
Route 8
1
8200
7800
5400
3900
2
7800
8200
6300
3300
4900
3
4800
4400
5600
3600 
4
8000
5000
6800
6700
4200 
5
7200
6400
3900
6400
2800
3000 
6
7000
5800
7500
4500
5600
6000
4200 
Objective
To use a network model to assign companies to bus routes so that each route
is covered at minimum cost to the city and no company is assigned to more than two
routes.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

WHERE DO THE NUMBERS COME FROM?
This is straightforward. The companies involved make the bids, and the city probably
decides that it isn’t physically possible (or safe) for any company to handle more than two
routes.
Solution
The variables and constraints for this model are given in Table 5.6. As in the machine-to-
job assignment model in Figure 5.12, the changing cells will all contain 0s or 1s. The 1s
will indicate which assignments are made.
You can model this problem in the “network” way. Although the rather large network
is not shown, you can imagine nodes for the bus companies on the left, nodes for the bus
routes on the right, and all arrows going from left to right. All flows are 0 or 1—a company
is either assigned to a bus route or it isn’t. The constraint that a company can be assigned
to at most two bus routes is handled by constraining the outflow from any company node
to be at most 2. To ensure that each bus route is covered by exactly one company, the
inflow to each bus route node is constrained to be 1.
244
Chapter 5
Network Models
All arcs go from com-
pany nodes to bus
route nodes, and the
allowable flows are
all 0 or 1.
Table 5.6 Variables and Constraints for the Assignment Model
Input variables
Bids for routes, maximum number of bus routes per company
Decision variables 
Assignments of companies to bus routes
(changing cells) 
Objective (target cell)
Total cost
Other calculated variables 
Number of bus routes assigned to each company, number of 
companies assigned to each bus route
Constraints
Number of bus routes assigned to each company
Maximum
number of routes per company
Number of companies assigned to each bus route  1
…
DEVELOPING THE SPREADSHEET MODEL
Because this is essentially a transportation model (with some disallowed arcs, the ones
where a company doesn’t bid on a route), you could mimic the transportation models in
Figure 5.2 and Figure 5.12, or you could mimic the more general model in Figure 5.7. For
efficiency, the latter is chosen here. This actually has two advantages. It doesn’t force you
to include changing cells for disallowed assignments, and it gets you ready for the more
general network model in the next section.
The model appears in Figure 5.14. (See the file Bus Routes.xlsx.) Because this model
is so similar to the Grand Prix transportation model in Figure 5.7, not all of the details are
repeated here. The key steps are as follows. (For help on the SUMIF function, revisit the
discussion of the alternative model in Example 5.1.)
1
Arc lists. The list of arcs (company–bus route pairs) in rows 8 to 38 corresponds to
the nonblank cells in Table 5.5. There is no point in including arcs that correspond to dis-
allowed assignments. Enter the data in columns A and B manually, referring to Table 5.5.
2
Inputs. Enter the costs from the (nonblank) cells in Table 5.5 in the range C8:C38.
Also, enter the maximum number of routes per company in cell B4.
3
Assignments. Enter any values in the Flow range. Although these will eventually be
0s and 1s to indicate which assignments are made, any values can be used initially. Solver
will eventually find the optimal values.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4
Inflows and outflows. In column G, we need outflows (numbers of routes assigned)
for company nodes and inflows (numbers of companies assigned) for bus route nodes. To
calculate these, enter the formulas
=SUMIF(Origin,F8,Flow)
and
=SUMIF(Destination,F16,Flow)
in cells G8 and G16, respectively, and copy them down their respective ranges.
5
Requirements on flows. Enter a link to cell B4 in each cell of the range I8:I13. This is
used to prevent any company from being assigned to more than two routes. Also, enter 1 in
each cell of the range I16:I23 to reflect that each route must be assigned to exactly one
company.
6
Total cost. Calculate the total cost to the city in cell B41 with the formula
=SUMPRODUCT(Cost,Flow)
USING SOLVER
The Solver setup should appear as in Figure 5.15. As usual, check the Non-Negative option
and select the Simplex LP method before optimizing.
5.3 Assignment Models
245
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
M
L
K
J
I
H
G
F
E
D
C
B
A
Assignment of bus companies to routes
Input data
Range names used:
Maximum routes per company
2
Companies_assigned
=Model!$I$25:$I$32
Cost
=Model!$C$17:$C$47
Network setup, ﬂows, and arc capacity 
w
olF
st
nia
rts
n
o
c
 balance constraints
Desnaon
=Model!$B$17:$B$47
Origin
Desnaon
Cost
Flow
Company
Routes assigned
Maximum allowed
Flow
=Model!$D$17:$D$47
1
2
8200
0
1
1
<=
2
Maximum_allowed
=Model!$K$17:$K$22
1
3
7800
1
2
2
<=
2
Origin
=Model!$A$17:$A$47
1
4
5400
0
3
1
<=
2
Routes_assigned
=Model!$I$17:$I$22
1
6
3900
0
4
0
<=
2
Total_cost
=Model!$B$50
2
1
7800
0
5
2
<=
2
2
2
8200
0
6
2
<=
2
2
4
6300
0
2
6
3300
1
Route
Companies assigned
Required
2
7
4900
1
1
1
=
1
3
2
4800
1
2
1
=
1
3
6
4400
0
3
1
=
1
3
7
5600
0
4
1
=
1
3
8
3600
0
5
1
=
1
4
3
8000
0
6
1
=
1
4
4
5000
0
7
1
=
1
4
5
6800
0
8
1
=
1
4
7
6700
0
4
8
4200
0
5
1
7200
0
5
2
6400
0
5
4
3900
1
5
5
6400
0
5
6
2800
0
5
8
3000
1
6
1
7000
1
6
2
5800
0
6
3
7500
0
6
4
4500
0
6
5
5600
1
6
7
6000
0
6
8
4200
0
39
40
41
Objecve to minimize
Total 
0
0
3
0
4
ts
o
c
Figure 5.14
Bus Route Assignment Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Discussion of the Solution
The optimal solution in Figure 5.14 indicates that the city should make the following
assignments: company 1 covers bus route 3, company 2 covers bus routes 6 and 7, company
3 covers bus route 2, company 5 covers bus routes 4 and 8, and company 6 covers bus
routes 1 and 5. The total cost to the city of this assignment is $40,300. Note that company
4 is not assigned to any bus routes. There is no constraint that every company must be
assigned to at least one bus route, and company 4 is evidently underbid by at least one
company for all bus routes. If the city wanted to require that all companies be assigned to
at least one bus route, you would simply add a lower bound of 1 on all of the outflows from
the company nodes (in rows 8 to 13). Of course, this would probably increase the total cost
to the city.
Sensitivity Analysis
One interesting sensitivity analysis is to see what effect the upper bound constraint on the
maximum routes has on the total cost. Presumably, if more bus routes per company are
allowed (assuming this is physically possible for the companies), the companies who tend
to bid lowest will be assigned to the bulk of the bus routes, and the total cost will probably
decrease. Using SolverTable, the analysis itself is straightforward with no modifications
to the model necessary. You should specify cell B4 as the single input cell, allow it to vary,
say, from 1 to 7 in increments of 1, and keep track of total cost. The resulting output
appears in Figure 5.16.
If each company can be assigned to only one route, there is no feasible solution. But
the reason for this is clear: There are eight routes to cover and only six companies. For larger
values of the maximum routes allowed, the total cost begins to decrease, but only until this
246
Chapter 5
Network Models
Figure 5.15
Solver Dialog Box
for the Bus Route
Assignment Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

input value reaches 3. From this point, the city achieves no additional flexibility by allow-
ing companies to travel more routes. Evidently, there is no single company or pair of com-
panies that is consistently underbidding all others.
■
5.3 Assignment Models
247
1
2
3
4
5
6
7
8
9
10
11
12
A
B
C
D
E
F
G
H
Oneway analysis for Solver model in Model worksheet
Max routes per company (cell $B$4) values along side, output cell(s) along top
Total_cost
1 Not feasible
2
40300
3
39500
4
39500
5
39500
6
39500
7
39500
The ﬁrst problem is clearly infeasible because 
there are only 6 companies and there are 8 routes.  
There is a cost savings from being allowed to 
assign 3 (rather than 2) routes to a company, but 
there is no incenve to assign more than 3 routes 
to any company.
Figure 5.16
Sensitivity to the
Maximum Number
of Routes
Assigning Managers at Heery International
LeBlanc et al. (2000) used an optimization model to assign managers to construction pro-
jects for Heery International. Heery contracts with the state of Tennessee for projects such
as hospitals, office buildings, state park facilities (hotels and cabins), higher-education
facilities (libraries, classrooms, and dormitories), armories, and prisons. The assignment
model is used for problems with up to 114 projects and 7 managers. As a result of the
model, Heery has managed its projects without replacing a manager who resigned and
management has reduced travel costs.
■
ADDITIONAL APPLICATIONS
P R O B L E M S
Skill-Building Problems
10. One possible solution method for the machine-to-job
assignment problem is the following heuristic proce-
dure. Assign the machine to job 1 that completes job 1
quickest. Then assign the machine to job 2 that,
among all machines that still have some capacity,
completes job 2 quickest. Keep going until a machine
has been assigned to all jobs. Does this heuristic
procedure yield the optimal solution for this problem?
If it does, see whether you can change the job times so
that the heuristic does not yield the optimal solution.
11. Modify the machine-to-job assignment model under
the assumption that only three of the four jobs must be
completed. In other words, one of the four jobs does
not have to be assigned to any machine. What is the
new optimal solution?
12. In the machine-to-job assignment problem, the current
capacities of the machines are 1, 2, 1, 2, and 1. If you
could increase one of these capacities by 1, which
would you increase? Why?
13. Modify the bus route assignment model, assuming
that company 1 decides to place bids on routes 7 and
8 (in addition to its current bids on other routes). The
bids on these two routes are $5200 and $3300. Does
the optimal solution change?
14. We modeled the bus route assignment problem with
the alternative form of the transportation model (as in
Figure 5.7). Model it instead with the standard form
(as in Figure 5.2). Discuss the pros and cons of these
two approaches for this particular example.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Skill-Extending Problems
15. In the optimal solution to the machine-to-job assign-
ment problem, jobs 1 and 2 are both assigned to
machine 4. Suppose there is an extra restriction that
jobs 1 and 2 must be assigned to different machines.
Change the model to accommodate this restriction and
find the new optimal solution.
16. In the optimal solution to the machine-to-job assign-
ment problem, jobs 3 and 4 are assigned to different
machines. Suppose there is an extra restriction that
these jobs must be assigned to the same machine.
Change the model to accommodate this restriction
and find the new optimal solution.
248
Chapter 5
Network Models
17. In the optimal solution to the bus route assignment
problem, company 2 is assigned to bus routes 6 and 7.
Suppose these two routes are far enough apart that it is
infeasible for one company to service both of them.
Change the model to accommodate this restriction and
find the new optimal solution.
18. When we (the authors) originally developed the bus
route assignment model, we included an arc capacity
constraint: Flow  1. After giving this further thought,
we deleted this constraint as being redundant. Why
could we do this? Specifically, why can’t one or more
of the flows found by Solver be greater than 1? (Hint:
Think in terms of flows out of and into the nodes in
the network diagram.)
5.4 OTHER LOGISTICS MODELS
The objective of many real-world network models is to ship goods from one set of loca-
tions to another set of locations at minimum cost, subject to various constraints. There are
many variations of these models. The simplest models include a single product that must
be shipped via one mode of transportation (truck, for example) in a particular period of
time. More complex models—and much larger ones—can include multiple products, mul-
tiple modes of transportation, and/or multiple time periods. We discuss several examples
of such problems in this section.
Basically, the general logistics problem is similar to the transportation problem except
for two possible differences. First, arc capacities are often imposed on some or all of the
arcs. These become simple upper bound constraints in the model. Second and more signif-
icant, inflows and outflows can be associated with any node. Nodes are generally catego-
rized as origins, destinations, and transshipment points. An origin is a location that starts
with a certain supply (or possibly a capacity for supplying). A destination is the opposite;
it requires a certain amount to end up there. A transshipment point is a location where
goods simply pass through.
The best way to think of these categories is in terms of net inflow and net outflow. The
net inflow for any node is defined as total inflow minus total outflow for that node. The net
outflow is the negative of this, total outflow minus total inflow. Then an origin is a node
with positive net outflow, a destination is a node with positive net inflow, and a transship-
ment point is a node with net outflow (and net inflow) equal to 0. It is important to realize
that inflows are sometimes allowed to origins, but their net outflows must be positive.
Similarly, outflows from destinations are sometimes allowed, but their net inflows must be
positive. For example, if Cincinnati and Memphis are manufacturers (origins) and Dallas
and Phoenix are retail locations (destinations), flow could go from Cincinnati to Memphis
to Dallas to Phoenix.
There are typically two types of constraints in logistics models (other than nonnegativ-
ity of flows). The first type represents the arc capacity constraints, which are simple upper
bounds on the arc flows. The second type represents the flow balance constraints, one for
each node. For an origin, this constraint is typically of the form Net Outflow  Original
Supply or possibly Net Outflow
Capacity. For a destination, it is typically of the form
Net Inflow
Demand or possibly Net Inflow  Demand. For a transshipment point, it is
of the form Net Inflow  0 (which is equivalent to Net Outflow  0).
It is easy to visualize these constraints in a graphical representation of the network by
examining the flows on the arrows leading into and out of the various nodes. We illustrate
a typical logistics model in the following example.
Ú
…
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

5.4 Other Logistics Models
249
FUNDAMENTAL INSIGHT
Flow Balance Constraints
All network optimization models have some form of
flow balance constraints at the various nodes of the
network. This flow balance r elates the amount that
enters the node to the amount that leaves the node.
In man y netw ork models, the simple structur e of
these flo w balance constraints guarantees that the
optimal solutions have integer values. It also enables
specialized network versions of the simplex method
to solve the huge netw ork models typically encoun-
tered in real logistics applications.
E X A M P L E
5.4 PRODUCING AND SHIPPING TOMATO PRODUCTS AT REDBRAND
T
he RedBrand Company produces a tomato product at three plants. This product
can be shipped directly to the company’s two customers or it can first be shipped to
the company’s two warehouses and then to the customers. Figure 5.17 is a network
representation of RedBrand’s problem. Nodes 1, 2, and 3 represent the plants (these are
the origins, denoted by S for supplier), nodes 4 and 5 represent the warehouses (these
are the transshipment points, denoted by T), and nodes 6 and 7 represent the customers
(these are the destinations, denoted by D). Note that some shipments are allowed among
plants, among warehouses, and among customers. Also, some arcs have arrows on both
ends. This means that flow is allowed in either direction.
Figure 5.17
Graphical
Representation of
Logistics Model
The cost of producing the product is the same at each plant, so RedBrand is concerned
with minimizing the total shipping cost incurred in meeting customer demands. The pro-
duction capacity of each plant (in tons per year) and the demand of each customer are
shown in Figure 5.17. For example, plant 1 (node 1) has a capacity of 200, and customer 1
(node 6) has a demand of 400. In addition, the cost (in thousands of dollars) of shipping a
ton of the product between each pair of locations is listed in Table 5.7, where a blank indi-
cates that RedBrand cannot ship along that arc. We also assume that at most 200 tons of the
product can be shipped between any two nodes. This is the common arc capacity.
RedBrand wants to determine a minimum-cost shipping schedule.
Objective
To find the minimum-cost way to ship the tomato product from suppliers to
customers, possibly through warehouses, so that customer demands are met and supplier
capacities are not exceeded.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

250
Chapter 5
Network Models
WHERE DO THE NUMBERS COME FROM?
The network configuration itself would come from geographical considerations—which
routes are physically possible (or sensible) and which are not. The numbers would
be derived as in the Grand Prix automobile example. (See Example 5.1 for further
discussion.)
Solution
The variables and constraints for RedBrand’s model are listed in Table 5.8. The key to the
model is handling the flow balance constraints. You will see exactly how to implement
these when we give step-by-step instructions for developing the spreadsheet model.
However, it is not enough, say, to specify that the flow out of plant 2 is less than or equal to
the capacity of plant 2. The reason is that there might also be flow into plant 2 (from
another plant). Therefore, the correct flow balance constraint for plant 2 is that the flow out
of it must be less than or equal to its capacity plus any flow into it. Equivalently, the net
outflow from plant 2 must be less than or equal to its capacity.
Table 5.7
Shipping Costs for RedBrand Example (in $1000s)
To node
From node 
1
2
3
4
5
6
7
1
5.0
3.0
5.0
5.0
20.0
20.0
2
9.0
9.0
1.0
1.0
8.0
15.0
3
0.4
8.0
1.0
0.5
10.0
12.0
4
1.2
2.0
12.0
5
0.8
2.0
12.0
6
1.0
7
7.0 
Table 5.8
Variables and Constraints for RedBrand Model
Input variables
Plant capacities, customer demands, unit shipping costs
on allowable arcs, common arc capacity
Decision variables (changing cells)
Shipments on allowed arcs
Objective cell
Total cost
Other calculated variables
Flows into and out of nodes
Constraints 
Flow on each arc  Common arc capacity
Flow balance at each node 
Other than arc 
capacity constraints,
the only constraints 
are flow balance 
constraints.
DEVELOPING THE SPREADSHEET MODEL
To set up the spreadsheet model, proceed as follows. (See Figure 5.18 and the file
RedBrand Logistics 1.xlsx. Also, refer to the network in Figure 5.17.)
1
Origins and destinations. Enter the node numbers (1 to 7) for the origins and desti-
nations of the various arcs in the range A8:B33. Note that the disallowed arcs are not
entered in this list.
2
Input data. Enter the unit shipping costs (in thousands of dollars), the common arc
capacity, the plant capacities, and the customer demands in the blue cells. Again, only the
nonblank entries in Table 5.7 are used to fill the column of unit shipping costs.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

5.4 Other Logistics Models
251
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
K
J
I
H
G
F
E
D
C
B
A
RedBrand shipping model
Inputs
Common arc capacity
200
Network structure, ﬂows, and arc capacity
e
d
o
N
st
nia
rts
n
o
c
balance constraints
Origin
n
Unit Cost
Flow
Arc Capacity
Plant constraints
t
n
alP
e
d
o
N
0
0
2
=
<
0
5
2
1
net
w
Plant capacity
0
0
2
=
<
0
8
1
1
0
0
2
=
<
0
8
1
3
3
1
0
0
3
=
<
0
0
3
2
0
0
2
=
<
0
5
4
1
0
0
1
=
<
0
0
1
3
0
0
2
=
<
0
5
5
1
1
6
20
0
<=
200
1
7
20
0
<=
200
Warehouse constraints
e
s
u
o
h
e
r
a
W
e
d
o
N
0
0
2
=
<
0
9
1
2
net
w
Required
0
=
0
4
0
0
2
=
<
0
9
3
2
0
=
0
5
0
0
2
=
<
0
2
1
1
4
2
2
5
1
0
<=
200
2
6
8
180
<=
200
Customer constraints
r
e
m
o
ts
u
C
e
d
o
N
0
0
2
=
<
0
5
1
7
2
net inﬂow
Customer demand
0
0
4
=
>
0
0
4
6
0
0
2
=
<
0
4.0
1
3
0
8
1
=
>
0
8
1
7
0
0
2
=
<
0
8
2
3
3
4
1
80
<=
200
3
5
0.5
200
<=
200
Range names used
3
6
10
0
<=
200
Arc_Capacity
=Model!$F$8:$F$33
3
7
12
0
<=
200
Customer_demand
=Model!$K$20:$K$21
4
5
1.2
0
<=
200
Customer_net_inﬂow
=Model!$I$20:$I$21
4
6
2
200
<=
200
n
=Model!$B$8:$B$33
3
3
$
D
$:8
$
D
$
!le
d
o
M
=
w
olF
0
0
2
=
<
0
2
1
7
4
5
4
0.8
0
<=
200
Origin
=Model!$A$8:$A$33
5
6
2
200
<=
200
Plant_capacity
=Model!$K$9:$K$11
5
7
12
0
<=
200
w
=Model!$I$9:$I$11
6
7
1
180
<=
200
Total_cost
=Model!$B$36
7
6
7
0
<=
200
Unit_Cost
=Model!$C$8:$C$33
w
=Model!$I$15:$I$16
to minimize
Total
0
6
2,3
$
ts
o
c
Figure 5.18
Logistics Model
We generally prefer
positive numbers on
the right sides of 
constraints.This is 
why we calculate net
outflows for origins 
and net inflows for 
destinations.
3
Flows on arcs. Enter any initial values for the flows in the range D8:D33. These are
the changing cells.
4
Arc capacities. To indicate a common arc capacity for all arcs, enter the formula
$B$4
in cell F8 and copy it down column F.
5
Flow balance constraints. Nodes 1, 2, and 3 are supply nodes, nodes 4 and 5 are
transshipment points, and nodes 6 and 7 are demand nodes. Therefore, set up the left sides
of the flow balance constraints appropriately for these three cases. Specifically, enter the
net outflow for node 1 in cell I9 with the formula
SUMIF(Origin,H9,Flow)-SUMIF(Destination,H9,Flow)
and copy it down to cell I11. This formula subtracts flows into node 1 from flows out of
node 1 to obtain net outflow for node 1. Next, copy this same formula to cells I15 and I16
for the warehouses. (Remember that, for transshipment nodes, the left side of the constraint
can be net outflow or net inflow, whichever you prefer. The reason is that if net outflow is
zero, net inflow must also be zero.) Finally, enter the net inflow for node 6 in cell I20 with
the formula
SUMIF(Destination,H20,Flow)-SUMIF(Origin,H20,Flow)
and copy it to cell I21. This formula subtracts flows out of node 6 from flows into node 6
to obtain the net inflow for node 6.
6
Total shipping cost. Calculate the total shipping cost (in thousands of dollars) in cell
B36 with the formula
SUMPRODUCT(Unit_cost,Flow)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

252
Chapter 5
Network Models
Figure 5.19
Solver Dialog Box
for Logistics Model
USING SOLVER
The Solver dialog box should be set up as in Figure 5.19. The objective is to minimize total
shipping costs, subject to the three types of flow balance constraints and the arc capacity
constraints.
Discussion of the Solution
The optimal solution in Figure 5.18 indicates that RedBrand’s customer demand can be sat-
isfied with a shipping cost of $3,260,000. This solution appears graphically in Figure 5.20.
Note in particular that plant 1 produces 180 tons (under capacity) and ships it all to plant 3,
not directly to warehouses or customers. Also, note that all shipments from the warehouses
go directly to customer 1. Then customer 1 ships 180 tons to customer 2. We purposely chose
Figure 5.20
Optimal Flows for
Logistics Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

5.4 Other Logistics Models
253
unit shipping costs (probably unrealistic ones) to produce this type of behavior, just to show
that it can occur. As you can see, the costs of shipping from plant 1 directly to warehouses or
customers are relatively large compared to the cost of shipping directly to plant 3. Similarly,
the costs of shipping from plants or warehouses directly to customer 2 are prohibitive.
Therefore, RedBrand ships to customer 1 and lets customer 1 forward some of its shipment
to customer 2.
Sensitivity Analysis
How much effect does the arc capacity have on the optimal solution? Currently, three of the
arcs with positive flow are at the arc capacity of 200. You can use SolverTable to see how sen-
sitive this number and the total cost are to the arc capacity.4 In this case the single input cell for
SolverTable is cell B4, which is varied from 150 to 300 in increments of 25. Two quantities are
designated as outputs: total cost and the number of arcs at arc capacity. As before, if you want
to keep track of an output that does not already exist, you can create it with an appropriate for-
mula in a new cell before running SolverTable. Specifically, you can enter the formula
COUNTIF(Flow,B4) in an unused cell. This formula counts the arcs with flow equal to arc
capacity. (See the finished version of the file for a note about this formula.)
Excel Function: COUNTIF
The COUNTIF function counts the number of values in a given r
ange that satisfy some
criterion. The syntax is 
COUNTIF(range,criterion). F or e xample, the formula 
COUNTIF(D8:D33,150) counts the number of cells in the r ange D8:D33 that contain
the value 150. This formula could also be enter
ed as COUNTIF(D8:D33,“150”).
Similarly, the formula COUNTIF(D8:D33,“100”) counts the number of cells in this
range with values greater than or equal to 100.5
The SolverTable output in Figure 5.21 is what you would expect. As the arc capacity
decreases, more flows bump up against it, and the total cost increases. But even when the
arc capacity is increased to 300, two flows are constrained by it. In this sense, even this
large an arc capacity costs RedBrand money.
4Note that Solver’s sensitivity report would not answer our question. This report is useful only for one-at-a-time
changes in inputs, and here we are simultaneously changing the upper limit for each flow. However, this report
(its bottom section) can be used to assess the effects of changes in plant capacities or customer demands.
5The COUNTIF and SUMIF functions are limited in that they allow only one condition, such as “10”. For
this reason, Microsoft added two new functions in Excel 2007, COUNTIFS and SUMIFS, that allow multiple
conditions. You can learn about them in online help.
3
4
5
6
7
8
9
10
11
A
B
C
D
E
F
G
Common arc capacity (cell $B$4) values along side, output cell(s) along top
Total_cost
Arcs_at_capacity
150
$4,120
5
175
$3,643
6
200
$3,260
3
225
$2,998
3
250
$2,735
3
275
$2,473
3
300
$2,320
2
Figure 5.21
Sensitivity to Arc
Capacity
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

254
Chapter 5
Network Models
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
O
N
M
L
K
J
I
H
G
F
E
D
C
B
A
RedBrand shipping model with two products compeng for arc capacity
Inputs
Common arc capacity
300
Network structure, ﬂows, and arc capacity constraints
Node balance constraints
Origin
Desnaon
Unit Cost
Flow product 1
Flow product 2
Total ﬂow
Arc Capacity
Plant constraints
1
2
0
0
<=
300
Node
Net oulow product 1
Net oulow product 2
Capacity product 1
Capacity product 2
0
0
2
0
0
2
=
<
0
4
1
180
1
0
0
3
=
<
0
0
3
140
160
3
3
1
0
0
1
0
0
3
=
<
0
0
1
300
2
0
0
3
=
<
0
2
0
0
2
5
4
1
0
0
1
0
0
1
=
<
0
0
1
100
3
0
0
3
=
<
0
0
0
5
5
1
1
6
20
0
0
0
<=
300
1
7
20
0
0
0
<=
300
Warehouse constraints
2
1
5
0
9
0
0
0
<=
300
Node
Net oulow product 1
Net oulow product 2
Required product 1
Required product 2
0
0
=
0
0
4
0
0
3
=
<
0
0
0
9
3
2
0
0
=
0
0
5
0
0
3
=
<
0
0
1
0
100
1
4
2
2
5
1
0
0
0
<=
300
2
6
8
200
100
300
<=
300
Customer constraints
2
7
15
0
0
0
<=
300
Node
Net inﬂow product 1
Net inﬂow product 2
Demand product 1
Demand product 2
0
0
2
0
0
4
=
>
200
400
6
0
0
3
=
<
0
0
0
0.4
1
3
0
4
1
0
8
1
=
>
140
180
7
0
0
3
=
<
0
0
0
8
2
3
3
4
1
0
180
180
<=
300
3
5
0.5
240
60
300
<=
300
3
6
10
0
0
0
<=
300
3
7
12
20
0
20
<=
300
4
5
1.2
0
0
0
<=
300
4
6
2
120
180
300
<=
300
4
7
12
0
0
0
<=
300
5
4
0.8
0
0
0
<=
300
5
6
2
240
60
300
<=
300
5
7
12
0
0
0
<=
300
6
7
1
160
140
300
<=
300
7
6
7
0
0
0
<=
300
Objecve to minimize
Total cost
$5,570
Figure 5.22
Logistics Model with Two Products
There are endless
variations of this 
basic minimum cost
network flow model,
corresponding to 
the many types of 
real-world logistics
problems.
Variations of the Model
There are many variations of the RedBrand shipping problem that can be handled by a
network model. We briefly consider two possible variations. First, suppose that RedBrand
ships two products along the given network. We assume that the unit shipping costs are the
same for both products (although this assumption could easily be relaxed), but the arc
capacity, which has been changed to 300, represents the maximum flow of both products
that can flow on any arc. In this sense, the two products are competing for arc capacity.
Each plant has a separate production capacity for each product, and each customer has a
separate demand for each product.
The spreadsheet model for this variation appears in Figure 5.22. (See the file RedBrand
Logistics 2.xlsx.) Very little in the original model needs to be changed. You need to (1) have
two columns of changing cells (columns D and E), (2) apply the previous logic to both
products separately in the flow balance constraints, and (3) apply the arc capacities to the
total flows in column F (which are the sums of flows in columns D and E). The modified
Solver dialog box is shown in Figure 5.23. Note that we have range-named blocks of cells for
the flow balance constraints. For example, the ranges K9:L11 and N9:O11 are named
Plant_net_outflow and Plant_capacity. These entire blocks can then be used to specify the
capacity constraints for both products with the single entry Plant_net_outflow 
Plant_capacity in the Solver dialog box. This is another example of planning the spread-
sheet layout so that the resulting model is as efficient and readable as possible.
A second variation of the model is appropriate for perishable goods, such as fruit.
(See the file RedBrand Logistics 3.xlsx.) We again assume that there is a single product, but
some percentage of the product that is shipped to warehouses perishes and cannot be sent to
customers. This means that the total inflow to a warehouse is greater than the total outflow
from the warehouse. This behavior can be modeled as shown in Figure 5.24. (The corre-
sponding Solver dialog box, not shown here, is the same as in the original RedBrand model.)
The shrinkage factor in cell B5, the percentage that does not spoil in the warehouses,
becomes a new input. It is then incorporated into the warehouse flow balance constraints by
entering the formula
SUMIF(Origin,H16,Flow)-$B$5*SUMIF(Destination,H16,Flow)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

5.4 Other Logistics Models
255
Figure 5.23
Solver Dialog Box
for Two-Product
Logistics Model
in cell I16 and copying to cell I17. This formula says that what goes out (the first term) is
90% of what goes in. The other 10% perishes. Of course, shrinkage results in a larger total
cost—about 20% larger—than in the original RedBrand model.
Interestingly, however, some units are still sent to both warehouses, and the entire
capacity of all plants is now used. Finally, you can check that a feasible solution exists
even for a shrinkage factor of 0% (where everything sent to warehouses disappears).
As you might guess, the solution then is to send everything directly from plants to
customers—at a steep cost.
■
1. Excel’s Solver uses the simplex method to solve logistics models. However, the simplex
method can be simplified dramatically for these types of models. The simplified ver-
sion of the simplex method, called the network simplex method, is much more efficient
than the ordinary simplex method. Specialized computer codes have been written to
implement the network simplex method, and all large logistics problems are solved by
using the network simplex method. This is fortunate because real logistics models tend
to be extremely large. See Winston (2003) for a discussion of this method.
2. If the given supplies and demands for the nodes are integers and all arc capacities
are integers, the logistics model always has an optimal solution with all integer
flows. Again, this is very fortunate for large problems—you get integer solutions “for
free” without having to use an integer programming algorithm. Note, however, that
this “integers for free” benefit is guaranteed only for the basic logistics model, as in
MODELING ISSUES
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

the original RedBrand model. When the model is modified in certain ways, such as
by adding a shrinkage factor, the optimal solution is no longer guaranteed to be
integer-valued. ■
256
Chapter 5
Network Models
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
K
J
I
H
G
F
E
D
C
B
A
RedBrand shipping model with shrinkage at warehouses
Inputs
Common arc capacity
200
Shrinkage factor
90%
Network formulaon
Node balance constraints
Origin
Desnaon
Unit Cost
Flow
Arc Capacity
Plant constraints
1
2
5
0
<=
200
Node
Plant net oulow
Plant capacity
1
3
3
200
<=
200
1
200
<=
200
1
4
5
0
<=
200
2
300
<=
300
1
5
5
0
<=
200
3
100
<=
100
1
6
20
0
<=
200
1
7
20
0
<=
200
Warehouse constraints
2
1
9
0
<=
200
Node Warehouse net oulow
Required
0
=
0
4
0
0
2
=
<
0
9
3
2
0
=
0
5
0
0
2
=
<
0
1
4
2
2
5
1
100
<=
200
2
6
8
200
<=
200
Customer constraints
2
7
15
0
<=
200
Node
Customer net inﬂow
Customer demand
3
1
0.4
0
<=
200
6
400
>=
400
3
2
8
0
<=
200
7
180
>=
180
3
4
1
0
<=
200
3
5
0.5
100
<=
200
3
6
10
200
<=
200
3
7
12
0
<=
200
4
5
1.2
0
<=
200
4
6
2
0
<=
200
4
7
12
0
<=
200
5
4
0.8
0
<=
200
5
6
2
180
<=
200
5
7
12
0
<=
200
6
7
1
180
<=
200
7
6
7
0
<=
200
Objecve to minimize
Total cost
$4,890
Figure 5.24
Logistics Model with Shrinkage
Distribution in Nu-kote International’s Network
Nu-kote International, a manufacturer of imaging supplies, used linear programming like
the model in this section to reduce costs in its global supply chain. Nu-kote’s successful
modeling projects, involving as many as 68,000 variables, were completed entirely within
Excel and met aggressive timelines—a tribute to the efficiency and user-friendliness of
Excel. Details of Nu-kote’s Excel modeling projects, which have resulted in over $1 mil-
lion in annual savings, can be found in LeBlanc et al. (2004), LeBlanc and Galbreth
(2007a), and LeBlanc and Galbreth (2007b).
■
ADDITIONAL APPLICATIONS
P R O B L E M S
Skill-Building Problems
19. Modify the original RedBrand problem so that all
flows must be from plants to warehouses and from
warehouses to customers. Disallow all other arcs.
How much does this restriction cost RedBrand,
relative to the original optimal shipping cost?
20. In the original RedBrand problem, suppose the plants
cannot ship to each other and the customers cannot
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

5.5 Shortest Path Models
257
5.5 SHORTEST PATH MODELS
In many applications, the objective is to find the shortest path between two points in a net-
work. Sometimes this problem occurs in a geographical context where, for example, the
objective is to find the shortest path on interstate freeways from Seattle to Miami. There
are also problems that do not look like shortest path problems but can be modeled in the
same way. We look at one possibility where the objective is to find an optimal schedule for
replacing equipment.
The typical shortest path problem is a special case of the network flow problem from
the previous section. To see why this is the case, suppose that you want to find the shortest
path between node 1 and node N in a network. To find this shortest path, you create a net-
work flow model where the supply for node 1 is 1, and the demand for node N is 1. All
other nodes are transshipment nodes. If an arc joins two nodes in the network, the
ship to each other. Modify the model appropriately
and reoptimize. How much does the total cost increase
because of these disallowed routes?
21. In the original RedBrand problem, the costs for ship-
ping from plants or warehouses to customer 2 were
purposely made high so that it would be optimal to
ship to customer 1 and then let customer 1 ship to
customer 2. Use SolverTable appropriately to do the
following. Decrease the unit shipping costs from
plants and warehouses to customer 1, all by the same
amount, until it is no longer optimal for customer 1 to
ship to customer 2. Describe what happens to the
optimal shipping plan at this point.
22. In the original RedBrand problem, we assume a con-
stant arc capacity, the same for all allowable arcs.
Modify the model so that each arc has its own arc
capacity. You can make up the required arc capacities.
23. Continuing the previous problem, make the problem
even more general by allowing upper bounds (arc
capacities) and lower bounds for the flows on the
allowable arcs. Some of the upper bounds can be very
large numbers, effectively indicating that there is no
arc capacity for these arcs, and the lower bounds can
be zero or positive. If they are positive, then they indi-
cate that some positive flow must occur on these arcs.
Modify the model appropriately to handle these upper
and lower bounds. You can make up the required
bounds.
24. Expand the RedBrand two-product spreadsheet model
so that there are now three products competing for the
arc capacity. You can make up the required input data.
25. In the RedBrand two-product problem, we assumed
that the unit shipping costs are the same for both
products. Modify the spreadsheet model so that each
product has its own unit shipping costs. You can
assume that the original unit shipping costs apply to
product 1, and you can make up new unit shipping
costs for product 2.
Skill-Extending Problems
26. How difficult is it to expand the original RedBrand
model? Answer this by adding a new plant, two new
warehouses, and three new customers, and modify the
spreadsheet model appropriately. You can make up the
required input data.
27. In the RedBrand problem with shrinkage, change the
assumptions. Now instead of assuming that there is
some shrinkage at the warehouses, assume that there
is shrinkage in delivery along each route. Specifically,
assume that a certain percentage of the units sent
along each arc perish in transit—from faulty refrigera-
tion, say—and this percentage can differ from one
arc to another. Modify the model appropriately to
take this type of behavior into account. You can
make up the shrinkage factors, and you can assume
that arc capacities apply to the amounts originally
shipped, not to the amounts after shrinkage. (Make
sure your input data permit a feasible solution. After
all, if there is too much shrinkage, it will be impossi-
ble to meet demands with available plant capacity.
Increase the plant capacities if necessary.)
28. Consider a modification of the original RedBrand
problem where there are N plants, M warehouses, and
L customers. Assume that the only allowable arcs are
from plants to warehouses and from warehouses to
customers. If all such arcs are allowable—all plants
can ship to all warehouses and all warehouses can ship
to all customers—how many changing cells are in the
spreadsheet model? Keeping in mind that Excel’s
Solver can handle at most 200 changing cells, give
some combinations of N, M, and L that will just barely
stay within Solver’s limit.
29. Continuing the previous problem, develop a sample
model with your own choices of N, M, and L that
barely stay within Solver’s limit. You can make up any
input data. The important point here is the layout and
formulas of the spreadsheet model.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

“shipping cost” is equal to the length of the arc. The “flow” through each arc in the net-
work (in the optimal solution) is either 1 or 0, depending on whether the shortest path
includes the arc. No arc capacities are required in the model. The value of the objective is
then equal to the sum of the distances of the arcs involved in the path.
258
Chapter 5
Network Models
Geographical Shortest Path Models
The following example illustrates the shortest path model in the context of a geographic
network.
FUNDAMENTAL INSIGHT
Shortest Path Problems 
as Network Flow Models
Shortest route problems can be modeled as a special
case of more general logistics models,using a “supply”
of 1 at the origin node and a “demand” of 1 at the
destination node. Because specialized algorithms can
solve these more general models very quickly, short-
est r oute pr oblems inherit this attractiv
e f eature.
This is a fa
vorite trick of management scientists.
They always try to model a specific problem as a spe-
cial case of a mor e general pr oblem that has been
well studied and can be solved relatively easily.
E X A M P L E
5.5 SHORTEST WALK ACROSS THE STATE
M
aude Jenkins, a 90-year-old woman, is planning to walk across the state, west to east,
to gain support for a political cause she favors.6 She wants to travel the shortest dis-
tance to get from city 1 to city 10, using the arcs (roads) shown in Figure 5.25. The numbers
on the arcs are miles. Arcs with double-headed arrows indicate that travel is possible in
both directions (with the same distance in both directions). What route should Maude take?
6This is based on a real 90-year-old woman who reportedly decided to walk across the country. We assume she
finished.
1
79
18
54
69
70
63
56
19
29
25
50
73
67
72
17
31
72
87
97
69
15
51
52
69
61
67
45
85
2
4
3
6
9
5
7
8
10
Figure 5.25
Network for the
Shortest Path
Problem
Objective
To specialize the general network flow model so that a shortest path from
node 1 to node 10 can be found.
WHERE DO THE NUMBERS COME FROM?
The distances on the arcs are presumably listed on state maps for the roads Maude is consid-
ering. Note, however, that in shortest path problems such as this, the objective is sometimes
total cost, not distance. Although the cost of an arc might be proportional to its distance, it
might not be. For example, a steep uphill route might be more “costly” than a flat stretch of
similar length. In such cases, the arc costs would be somewhat more difficult to obtain.
The “distances”in
shortest path models
are sometimes costs.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

5.5 Shortest Path Models
259
Solution
The variables and constraints for this model are listed in Table 5.9. This network model is
exactly like the general logistics model in the previous section. All you need to specify is
that node 1 has a supply of 1 (you can think of it as Maude herself), node 10 has a demand
of 1, and all other nodes are transshipment nodes.
Table 5.9 Variables and Constraints for Maude’s Shortest Path Model
Input variables
Network structure and arc distances
Decision variables (changing cells)
Flows on arcs (1 if arc is used, 0 otherwise)
Objective (target cell)
Total distance
Other calculated variables
Flows into and out of arcs
Constraints
Flow balance at each node
DEVELOPING THE SPREADSHEET MODEL
The completed model and associated Solver dialog box appear in Figures 5.26 and 5.27.
(See the file Shortest Path.xlsx.) Because this is so similar to the general logistics model,
most of the details are omitted. However, the following points are important.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
A
B
C
D
E
F
G
H
I
J
K
L
M
Shortest path model
Network structure and ﬂows
Flow balance 
e
g
n
a
R
st
nia
rts
n
o
c
 names used:
Origin
Desnaon
Distance
Flow
Node Net oulow
Required net oulow
Desnaon
=Model!$B$5:$B$39
9
3
$
C
$:5
$
C
$
!le
d
o
M
=
e
c
n
a
tsi
D
1
=
1
1
0
0
7
2
1
9
3
$
D
$:5
$
D
$
!le
d
o
M
=
w
olF
0
=
0
2
0
3
6
3
1
4
1
$
G
$:5
$
G
$
!le
d
o
M
=
w
olft
u
o
_
t
e
N
0
=
0
3
1
6
5
4
1
9
3
$
A
$:5
$
A
$
!le
d
o
M
=
nigir
O
0
=
0
4
0
5
2
3
2
4
1
$I$:5
$I$
!le
d
o
M
=
w
olft
u
o
_
t
e
n
_
d
e
riu
q
e
R
0
=
0
5
0
9
1
4
2
2
4
$
B
$
!le
d
o
M
=
e
c
n
a
tsid
_la
t
o
T
0
=
0
6
0
3
7
5
2
0
=
0
7
0
0
5
6
2
0
=
0
8
0
9
7
7
2
0
=
0
9
0
5
2
2
3
3
4
29
0
10
-1
=
-1
3
5
69
0
3
6
61
0
4
2
19
0
4
3
29
0
4
5
67
0
4
6
45
1
4
9
85
0
5
6
18
0
5
7
67
0
5
8
69
0
5
9
54
0
5
10
87
0
6
5
18
0
6
7
72
0
6
8
52
0
6
9
51
0
6
10
97
1
7
8
17
0
7
9
31
0
7
10
72
0
8
7
17
0
8
9
15
0
9
7
31
0
9
8
15
0
9
10
69
0
Objecve to minimize
Total distance
198
Figure 5.26
Shortest Path Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

260
Chapter 5
Network Models
Figure 5.27
Solver Dialog Box
for the Shortest
Path Model
1
Arc list. There is an arc listed in columns A and B for each arc in the graphical net-
work. If the arc goes in both directions, it is listed twice (2 to 4 and 4 to 2, for example)
with the same distance in both directions.
2
Net outflows. All types of nodes are listed in a single block in the flow balance con-
straint section. Node 1 is an origin with a supply of 1, and it has only outflows. Similarly,
node 10 is a destination with demand 1, and it has only inflows. The intermediate nodes are
all transshipment nodes. You can treat all of the nodes similarly by calculating the net
outflow from each. To do so, enter the formula
=SUMIF(Origin,F5,Flow)-SUMIF(Destination,F5,Flow)
in cell G5 and copy it down for the other nodes. For node 1, this net outflow is really just the
outflow, so it should be 1. For node 10, this net outflow is really just the negative of the
inflow, so it should be –1. For all intermediate nodes, the net outflow should be 0. This
explains the values in column I.
3
Total distance. The objective to minimize is total distance, calculated in cell B42 with
the formula
=SUMPRODUCT(Distance,Flow)
Discussion of the Solution
After Solver finds the optimal flows, which are 0s and 1s, it is easy to identify the shortest
path—just follow the 1s. According to Figure 5.26, Maude first goes from node 1 to node 4
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

5.5 Shortest Path Models
261
(see row 7), then she goes from node 4 to node 6 (see row 20), and finally she goes from
node 6 to node 10 (see row 31). Using this route from 1 to 10, Maude must walk 198 miles,
the sum of the distances on the three arcs she traverses.
Make sure you understand exactly how this model works. There are really two parts:
the total distance and the balance of inflows and outflows. For any solution of 0s and 1s in
the Flow column, the SUMPRODUCT for total distance simply sums the distances in col-
umn C corresponding to the arcs traversed. This accurately reflects the total distance
Maude walks.
For flow balance, consider any intermediate node. If Maude’s route goes through it,
such as with node 6, the two SUMIF functions in column G for this node both evaluate to
1—that is, one of the arcs leading into node 6 has a flow of 1, and one of the arcs leading
out of node 6 has a flow of 1. On the other hand, if Maude’s route doesn’t go through the
node, such as with node 3, the two SUMIF functions for this node both evaluate to 0—no
flow in and no flow out. Finally, the flow balance constraints for nodes 1 and 10 ensure that
exactly one arc leading out of node 1 has a flow of 1, and exactly one arc leading into node
10 has a flow of 1.
■
Equipment Replacement Models 
Although shortest path problems often involve traveling through a network, this is not
always the case. For example, when should you trade your car in for a new car? As a car
gets older, the maintenance cost per year increases, and it might become worthwhile to buy
a new car. If your goal is to minimize the average annual cost of owning a car (ignoring the
time value of money), then it is possible to set up a shortest path representation of this
problem. Actually, the method we discuss can be used in any situation where equipment
replacement is an issue. Of course, many people trade in a car because they like the feel of
a new car. This aspect is not modeled in the problem; only the financial aspects are
included. The following is an example of how equipment replacement can be modeled as a
shortest path problem.
All flows in a shortest
path model are either
0 or 1; a route is 
either used or it isn’t.
E X A M P L E
5.6 EQUIPMENT REPLACEMENT AT VANBUREN METALS
V
anBuren Metals is a manufacturing company that uses many large machines to work
on metals. These machines require frequent maintenance because of wear and tear,
and VanBuren finds that it is sometimes advantageous, from a cost standpoint, to replace
machines rather than continue to maintain them. For one particular class of machines, the
company has estimated the quarterly costs of maintenance, the salvage value from
reselling an old machine, and the cost to purchase a new machine.7 We assume that the
maintenance cost and the salvage value depend on the age of the current machine (at the
beginning of the quarter). However, we assume that the maintenance costs, the salvage val-
ues, and the purchase cost do not depend on time. In other words, we assume no inflation.
Specifically, we assume the following:
■
The purchase cost of a new machine is always $3530.
■
The maintenance cost of a machine in its first quarter of use is $100. For each suc-
ceeding quarter, the maintenance cost increases by $65. This reflects the fact that
machines require more maintenance as they age.
■
The salvage value of a machine after one quarter of use is $1530. After each suc-
ceeding quarter of use, the salvage value decreases by $110.
7One issue in these types of models is the time period to use. We assume that VanBuren uses quarters. Therefore,
the only times it considers purchasing new machines are at beginnings of quarters.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

262
Chapter 5
Network Models
VanBuren wants to devise a strategy for purchasing machines over the next five years.
As a matter of policy, the company never sells a machine that is less than one year old, and
it never keeps a machine that is more than three years old. Also, the machine in use at the
beginning of the current quarter is brand new.
Objective
To find the optimal replacement strategy by modeling the problem as an
equivalent shortest path problem.
WHERE DO THE NUMBERS COME FROM?
In general, a company would gather historical data on maintenance costs and salvage val-
ues for similar machines and fit appropriate curves to the data (probably using regression,
as discussed in Chapter 14).
Solution
The variables and constraints required for this machine replacement model appear in
Table 5.10. We claimed that this problem can be modeled as a shortest path model, which
is probably far from obvious. There are two keys to understanding why this is possible:
(1) the meaning of nodes and arcs, and (2) the calculation of costs on arcs. After you
understand this, the modeling details are exactly as in the previous example.
Table 5.10 Variables and Constraints for the Equipment Replacement Model
Input variables
Purchase cost, maintenance costs as a function of age, salvage values 
as a function of age
Decision variables 
Flows on arcs (1 if arc is used, 0 otherwise), which determine the
(changing cells)
replacement schedule
Objective (target cell)
Total (net) cost
Other output cells
Flows into and out of arcs
Constraints
Flow balance at each node
1
5
6
7
13
17
21
Figure 5.28
Selected Nodes and
Arcs for the Machine
Replacement
Network
An arc from any node
to a later node corre-
sponds to keeping a
machine for a certain
period of time and
then trading it in for a
new machine.
The network is constructed as follows. There is a node for each quarter, including the
current quarter and the quarter exactly five years (20 quarters) from now. (Remember that
VanBuren uses a five-year planning horizon.) These nodes are labeled 1 through 21, where
node 1 is the current quarter, node 2 is the next quarter, and so on. There is an arc from
each node to each later node that is at least 4 quarters ahead but no more than 12 quarters
ahead. (This is because VanBuren never sells a machine less than one year old, and never
keeps a machine more than three years.) Several of these arcs are shown in Figure 5.28.
(Many nodes and arcs do not appear in this figure.)
Consider the arc from node 9 to node 17, for example. “Using” this arc on the shortest
path—that is, putting a flow of 1 on it—corresponds to starting with a new machine in
quarter 9, keeping it for eight quarters, selling it, and purchasing another new machine at
the beginning of quarter 17. An entire strategy for the five-year period is a string of such
arcs. For example, with the path 1–9–17–21, VanBuren keeps the first machine for eight
quarters, trades it in for a second machine at the beginning of quarter 9, keeps the second
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

5.5 Shortest Path Models
263
machine for eight quarters, trades it in for a third machine at the beginning of quarter 17,
keeps the third machine for four quarters, and finally trades it in for a fourth machine at the
beginning of quarter 21.
Given the meaning of the arcs, the calculation of arc costs is a matter of careful book-
keeping. Again, consider the arc from node 9 to node 17. The cost on this arc is the total
maintenance cost for this machine during the eight quarters it is kept, minus the salvage
value of an eight-quarter-old machine sold in quarter 17, plus the cost of the replacement
machine purchased at the beginning of quarter 17. The total maintenance cost for this
machine is the maintenance cost of a machine in its first quarter of use, plus the mainte-
nance cost of a machine in its second quarter of use, plus the maintenance cost of a
machine in its third quarter of use, and so on. The first of these is $100, the second is $165,
the third is $230, and so on, for the eight quarters it is kept. You can check that the sum of
these eight costs is $2620. The salvage value at the end of quarter 17 is $1530  7($110)
 $760, and the cost of the replacement machine is $3530. Therefore, the (net) cost on this
arc is $2620  $760 	 $3530  $5390.
DEVELOPING THE SPREADSHEET MODEL
The information about arcs in the spreadsheet model is given in Figure 5.29, where rows
27 through 124 have been hidden. (See the file Machine Replacement.xlsx.) This part of
the model can be completed with the following steps:
An arc cost is a sum
of maintenance costs
minus a salvage value
plus the cost of a new
machine.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
125
126
127
128
129
130
A
B
C
D
E
F
G
H
I
J
K
L
M
N
O
P
Q
R
S
Machine replacement model - shortest path formulaon
e
g
n
a
R
st
u
p
n
I
 names used:
Purchase cost
3530
Desnaon
=Model!$B$14:$B$130
Maintenance 
0
3
1
$
S
$:4
1
$
S
$
!le
d
o
M
=
w
olF
ts
o
c
In ﬁrst quarter
100
Net_oulow
=Model!$V$14:$V$34
Increase per quarter
65
Origin
=Model!$A$14:$A$130
Salvage 
4
3
$
X
$:4
1
$
X
$
!le
d
o
M
=
d
e
riu
q
e
R
e
ula
v
Aer one quarter
1530
Total_cost
=Model!$V$36
Decrease per quarter
110
Network 
e
c
n
a
n
e
t
nia
M
s
cr
a
 costs in quarter of use:
Origin
Desnaon
Quarters to keep
1
2
3
4
5
6
7
8
9
10
11
12 Salvage value
Purchase cost
Total cost
Flow
1
5
4
100
165 230 295
0
0
0
0
0
0
0
0
1200
3530
3120
0
1
6
5
100
165 230 295 360
0
0
0
0
0
0
0
1090
3530
3590
0
1
7
6
100
165 230 295 360 425
0
0
0
0
0
0
980
3530
4125
1
1
8
7
100
165 230 295 360 425 490
0
0
0
0
0
870
3530
4725
0
1
9
8
100
165 230 295 360 425 490 555
0
0
0
0
760
3530
5390
0
1
10
9
100
165 230 295 360 425 490 555 620
0
0
0
650
3530
6120
0
1
11
10
100
165 230 295 360 425 490 555 620 685
0
0
540
3530
6915
0
1
12
11
100
165 230 295 360 425 490 555 620 685
750
0
430
3530
7775
0
1
13
12
100
165 230 295 360 425 490 555 620 685
750
815
320
3530
8700
0
2
6
4
100
165 230 295
0
0
0
0
0
0
0
0
1200
3530
3120
0
2
7
5
100
165 230 295 360
0
0
0
0
0
0
0
1090
3530
3590
0
2
8
6
100
165 230 295 360 425
0
0
0
0
0
0
980
3530
4125
0
15
19
4
100
165 230 295
0
0
0
0
0
0
0
0
1200
3530
3120
0
15
20
5
100
165 230 295 360
0
0
0
0
0
0
0
1090
3530
3590
0
15
21
6
100
165 230 295 360 425
0
0
0
0
0
0
980
3530
4125
0
16
20
4
100
165 230 295
0
0
0
0
0
0
0
0
1200
3530
3120
0
16
21
5
100
165 230 295 360
0
0
0
0
0
0
0
1090
3530
3590
0
17
21
4
100
165 230 295
0
0
0
0
0
0
0
0
1200
3530
3120
0
Figure 5.29
Arc Information in the Machine Replacement Model
The allowable arcs
are determined by the
company’s trade-in
policy.
1
Inputs. Enter the inputs for the purchase cost, maintenance costs, and salvage values
in the blue ranges.
2
Arcs. In the bottom section, columns A and B indicate the arcs in the network. Enter
these “origins” and “destinations” manually. Just make sure that the difference between
them is at least 4 and no greater than 12 (because of the company’s trade-in policy). Also,
make sure that the origin is at least 1 and the destination is no more than 21.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

3
Quarters to k eep. Calculate the differences between the values in columns B and
A in column C. These differences indicate how many quarters the machine is kept for
each arc.
4
Maintenance costs.
Calculate the quarterly maintenance costs in columns D
through O. First, you need to realize why there are so many columns. The maintenance
cost for any arc is the total maintenance cost for a machine until it is traded in. Because
the company can keep a machine for up to 12 quarters, 12 columns are required. For
example, for the arc from 1 to 5 in row 14, cell D14 contains the maintenance cost in the
first quarter of this period, cell E14 contains the maintenance cost in the second quarter of
this period, and so on. Fortunately, you can calculate all of these maintenance costs at
once by entering the formula
=IF(D$13>$C14,0,$B$6+$B$7*(D$13-1))
in cell D14 and copying it to the range D14:O130. The IF function ensures that no mainte-
nance costs for this machine are incurred unless the machine is still in use. Pay particular
attention to the way age is incorporated in this formula. The reference numbers in the
range D13:O13 indicate the quarter of use, 1 through 12. For example, consider the situa-
tion in cell F24. A new machine was purchased in quarter 2 and is now in its third quarter
of use. Therefore, its maintenance cost is $100 	 2($65)  $230.
5
Salvage values. In a similar way, calculate the salvage values in column P by entering
the formula
=$B$9-$B$10*(C14-1)
in cell P14 and copying down column P. For example, the salvage value in row 24 is for a
machine that is sold after its fifth year of use. This is $1530  4($110)  $1090.
6
Purchase cost. The purchase cost of a new machine never changes, so put an absolute
link to cell B4 in cell Q14, and copy it down column Q.
7
Total arc costs. Calculate the total costs on the arcs as total maintenance cost minus
salvage value plus purchase cost. To do this, enter the formula
=SUM(D14:O14)-P14+Q14
in cell R14, and copy it down column R.
8
Flows. Enter any flows on the arcs in column S. As usual, Solver will eventually find
flows that are equal to 0 or 1.
USING SOLVER
From this point, the model is developed exactly as in the shortest path model in
Example 5.5, with node 1 as the origin node and node 21 as the destination node. Because
the flow balance constraints, the total network cost, and Solver are implemented exactly as
before, the details are not repeated here (see Figure 5.30).
Discussion of the Solution
After using Solver to find the shortest path, you can follow the 1s in the Flow range to
identify the optimal equipment replacement policy. Although not all of the rows appear
264
Chapter 5
Network Models
Careful planning of
the spreadsheet layout
is important here.The
reference numbers in
row 13 allow you to
incorporate age in the
formulas.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

in Figure 5.29 (shown earlier), you can check in the finished version of the file that only
three arcs have a flow of 1: arcs 1–7, 7–14, and 14–21. This solution indicates that
VanBuren should keep the current machine for six quarters, trade it in for a new machine
at the beginning of quarter 7, keep the second machine for seven quarters, trade it in for a
new machine at the beginning of quarter 14, keep the third machine for seven quarters, and
finally trade it in for a new machine at the beginning of quarter 21. The total (net) cost of
this strategy is $13,575.
Although Solver finds the minimum-cost replacement strategy, this might be a good
time for you to try your own strategy, just to make sure you understand how the network
works. For example, see if you can enter the appropriate flows for the strategy that replaces
the machine in quarters 6, 11, 17, and 21. Your flows should automatically satisfy the flow
balance constraints, and your total cost should be $14,425. Of course, this is a suboptimal
solution; its cost is larger than the minimum cost found with Solver.
■
5.5 Shortest Path Models
265
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
U
V
W
X
Flow balance constraints
Node
Net oulow
Required
1
1
=
1
2
0
=
0
3
0
=
0
4
0
=
0
5
0
=
0
6
0
=
0
7
0
=
0
8
0
=
0
9
0
=
0
10
0
=
0
11
0
=
0
12
0
=
0
13
0
=
0
14
0
=
0
15
0
=
0
16
0
=
0
17
0
=
0
18
0
=
0
19
0
=
0
20
0
=
0
21
-1
=
-1
Total cost
$13,575
Figure 5.28
Constraints and
Objective for 
the Machine
Replacement Model
1.
There is no inflation in this model, which means that monetary values do not increase
over time. Inflation could certainly be built in, but you would need to estimate exactly
how inflation affects the costs and salvage values, and you would have to build this
behavior into the spreadsheet formulas in the model.
2.
As the model now stands, VanBuren is forced to resell the current machine and pur-
chase a new one at the end of the five-year period. This is because the cost of every
arc leading into the last node, node 21, includes a salvage value and a purchase cost.
This feature of the model is not as bad as it might seem. Every path from node 1 to
MODELING ISSUES
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

node 21 includes the purchase cost in quarter 21, so this cost has no effect on which
path is best. The effect of including the salvage value in arcs into node 21 is to penal-
ize strategies that end with old machines after five years. Regardless of how you
model the problem, you probably ought to penalize such strategies in some way. In
addition, VanBuren will probably use a rolling planning horizon—that is, it will
implement only short-term decisions from the model. The way you model the end of
the five-year horizon should have little effect on these early decisions.
■
266
Chapter 5
Network Models
Periodic Maintenance at Schindler Elevator
Schindler, the world’s largest escalator company and second-largest elevator company,
maintains tens of thousands of elevators and escalators throughout North America.
Thousands of technicians work each day to maintain, repair, and help in emergencies.
Blakeley et al. (2003) describe how they developed an automated route-scheduling and
planning system to optimize Schindler’s preventive maintenance operations. The system
uses a series of algorithms to assign maintenance work to technicians and route them to
where they are needed. The estimated savings from the optimization system is more than
$1 million annually.
■
ADDITIONAL APPLICATIONS
P R O B L E M S
Skill-Building Problems
30. In Maude’s shortest path problem, suppose all arcs in
the network are double-arrowed, that is, Maude can
travel along each arc (with the same distance) in either
direction. Modify the spreadsheet model appropriately.
Is her optimal solution still the same?
31. In Maude’s shortest path problem, suppose all arcs in
the current network from higher-numbered nodes to
lower-numbered nodes, such as from node 6 to node 5,
are disallowed. Modify the spreadsheet model and find
the shortest path from node 1 to node 10. Is it the same
as before? Should you have known the answer to this
question before making any changes to the original
model? Explain.
32. Continuing the previous problem, suppose again that
all arcs go in both directions, but suppose Maude’s
objective is to find the shortest path from node 1 to
node 7 (not node 10). Modify the spreadsheet model
appropriately and solve.
33. In the VanBuren machine replacement problem, we
assumed that the maintenance cost and salvage val-
ues are linear functions of age. Suppose instead
that the maintenance cost increases by 50% each
quarter and that the salvage value decreases by
10% each quarter. Rework the model with these
assumptions. What is the optimal replacement
schedule?
34. How difficult is it to add nodes and arcs to an existing
shortest path model? Answer by adding a new node,
node 11, to Maude’s network. Assume that node 11
is at the top of the network, geographically, with
double-arrowed arcs joining it to nodes 2, 5, and 7
with distances 45, 22, and 10. Assume that Maude’s
objective is still to get from node 1 to node 10. Does
the new optimal solution go through node 11?
35. In the VanBuren machine replacement problem, the
company’s current policy is to keep a machine at least
4 quarters but no more than 12 quarters. Suppose this
policy is instead to keep a machine at least 5 quarters
but no more than 10 quarters. Modify the spreadsheet
model appropriately. Is the new optimal solution the
same as before?
36. In the VanBuren machine replacement problem, the
company’s current policy is to keep a machine at
least four quarters but no more than 12 quarters.
Suppose instead that the company imposes no upper
limit on how long it will keep a machine; its only
policy requirement is that a machine must be kept at
least four quarters. Modify the spreadsheet model
appropriately. Is the new optimal solution the same as
before?
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

5.6 NETWORK MODELS IN THE AIRLINE INDUSTRY
We conclude this chapter with two network models that apply to the airline industry. (The
airline industry is famous for using management science in a variety of ways to help man-
age operations and save on costs.) Neither of these problems looks like a network at first
glance, but some creative thinking reveals underlying network structures. The first prob-
lem turns out to be an assignment model; the second is similar to the RedBrand logistics
model. Note that these two examples are considerably more difficult than any covered so
far in this chapter. They indicate that it is not always straightforward to translate a real-
world problem into a spreadsheet model.
5.6 Network Models in the Airline Industry
267
Skill-Extending Problems
37. In the VanBuren machine replacement problem,
suppose the company starts with a machine that is
eight quarters old at the beginning of the first quarter.
Modify the model appropriately, keeping in mind that
this initial machine must be sold no more than four
quarters from now.
38. We illustrated how a machine replacement problem
can be modeled as a shortest path problem. This is
probably not the approach most people would think of
when they first see a machine replacement problem. In
fact, most people would probably never think in terms
of a network. How would you model the problem?
Does your approach result in an LP model?
E X A M P L E
5.7 CREW SCHEDULING AT BRANEAST AIRLINES
B
raneast Airlines must staff the daily flights between New York and Chicago shown in
Table 5.11.8 Braneast’s crews live in either New York or Chicago. Each day, a crew
must fly one New York–Chicago flight and one Chicago–New York flight with at least one
hour of downtime between flights. For example, a Chicago-based crew can fly the 9–11
Chicago–New York flight and return on the 12–14 New York–Chicago flight. This incurs a
downtime of one hour. Braneast wants to schedule crews to cover all flights and minimize
the total downtime.
8All times in the spreadsheet model are represented as military time. For example, time 13 corresponds to 1 P.M.
Also, all times listed are Eastern Standard Time (EST).
Table 5.11 Flight Data for Braneast Problem
Flight
Leave Chicago
Arrive N.Y.
Flight
Leave N.Y.
Arrive Chicago
1
6 A.M.
8 A.M.
1
7 A.M.
9 A.M.
2
9 A.M.
11 A.M.
2
8 A.M.
10 A.M.
3
Noon
2 P.M.
3
10 A.M.
Noon
4
3 P.M.
5 P.M.
4
Noon
2 P.M.
5
5 P.M.
7 P.M.
5
2 P.M.
4 P.M.
6
7 P.M.
9 P.M.
6
4 P.M.
6 P.M.
7
8 P.M.
10 P.M.
7
7 P.M.
8 P.M.
Objective
To schedule crews without violating the one-hour downtime restriction so that
total downtime is minimized.
WHERE DO THE NUMBERS COME FROM?
The flight data are part of the airline’s overall flight schedule. The one-hour downtime
restriction is for safety reasons and is probably built into a union contract.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Solution
The important insight is that this can be set up as an assignment model. The variables and
constraints required are listed in Table 5.12. The discussion following this table describes
how the assignment model works.
268
Chapter 5
Network Models
Table 5.12 Variables and Constraints for the Crew Scheduling Model
Input Variables
Flight Schedule Data
Decision variables 
Flows on arcs (0–1 variables indicating assignments of crews to pairs 
(changing cells)
of flights)
Objective (target cell)
Total downtime
Other output cells
Downtimes for crews assigned to flights, flows in and out of nodes
Constraints
Flow balance
The network is constructed as follows. There are two sets of nodes, one for flights
departing from Chicago and one for flights departing from New York. There is an arc from
a Chicago-based node to a New York-based node if the Chicago flight leaves early, the New
York flight leaves later, and there is at least one hour of downtime if a crew is assigned to
this pair of flights. For example, flight 1 from Chicago leaves at 6 A.M. and arrives at 8 A.M.
in New York. Therefore, there is an arc from this flight’s node to the node of each New
York-based flight that leaves 9 A.M. or after. This includes the last five flights leaving from
New York (see Figure 5.31). All such arcs—those that pair an early flight out of Chicago
with a later flight out of New York (that then flies back to Chicago)—must be staffed by a
Chicago-based crew. A similar set of arcs go in the opposite direction, from New York to
Chicago and then back to New York, which must be staffed by a New York-based crew.
Chicago-based flights
New York-based flights
Chicago-based flights
New York-based flights
C1
C2
C3
C4
N5
N6
N7
N1
N2
N3
N4
N5
N6
N4
N3
C3
C4
C5
C6
C7
For example, C3 indicates the third Chicago-based
flight, N2 indicates the second New York-based flight.
Figure 5.31
Network for Airline
Crew Scheduling
Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Given this network structure, the model can now be developed. First, the flow on any
arc is 0 or 1. It is a 1 only if a crew is assigned to that pair of flights. Second, the “cost” on
any arc is the downtime for that pair of flights if a crew is assigned to it. For example, the
cost on the top arc in Figure 5.31 (flight 1 out of Chicago paired with flight 3 out of New
York) is two hours, because the Chicago flight gets in at 8 A.M. and the New York flight
leaves at 10 A.M. Third, each flight leaving from one city must be paired with exactly one
flight leaving the other city. This implies that the total flow out of any node must be 1, and
the total flow into any node must be 1. This fact explains why this is an assignment model.
Finally, it takes exactly seven crews, some based in Chicago and some based in New York,
to cover the flights. The solution to the model indicates how many Chicago-based crews
and New York-based crews are required.
DEVELOPING THE SPREADSHEET MODEL
After you understand the conceptual idea, the implementation in Excel is fairly straight-
forward. The completed spreadsheet model appears in Figure 5.32. (See the file Crew
Scheduling.xlsx.) The model is formed with the following steps:
5.6 Network Models in the Airline Industry
269
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
A
B
C
D
E
F
G
H
I
J
K
Crew scheduling model
Flight informaon
Chicago-NY 
Y
N
st
h
gilf
-Chicago ﬂights
Flight
Departs
Arrives
Flight
Departs
Arrives
9
7
1
N
8
6
1
C
0
1
8
2
N
1
1
9
2
C
2
1
0
1
3
N
4
1
2
1
3
C
4
1
2
1
4
N
7
1
5
1
4
C
6
1
4
1
5
N
9
1
7
1
5
C
8
1
6
1
6
N
1
2
9
1
6
C
0
2
9
1
7
N
2
2
0
2
7
C
Network 
w
olF
n
oit
alu
m
r
o
f
 balance constraints
Chicago-based crews
C Origin
N Desnaon
C Downme
C Flow
Node
Flow Out
Flow In Total ﬂow
Required
1
=
1
0
1
1
C
1
2
3
N
1
C
1
=
1
0
1
2
C
0
4
4
N
1
C
1
=
1
1
0
3
C
0
6
5
N
1
C
1
=
1
0
1
4
C
0
8
6
N
1
C
1
=
1
1
0
5
C
0
1
1
7
N
1
C
1
=
1
1
0
6
C
1
1
4
N
2
C
1
=
1
1
0
7
C
0
3
5
N
2
C
1
=
1
0
1
1
N
0
5
6
N
2
C
1
=
1
0
1
2
N
0
8
7
N
2
C
1
=
1
1
0
3
N
0
2
6
N
3
C
1
=
1
1
0
4
N
0
5
7
N
3
C
1
=
1
0
1
5
N
1
2
7
N
4
C
N6
1
0
1
=
1
NY-based 
1
=
1
1
0
7
N
s
w
e
rc
N Origin
C Desnaon
N Downme
N Flow
0
3
3
C
1
N
Range names used
5
$
B
$:2
3
$
B
$
!le
d
o
M
=
n
oit
a
nits
e
D
_
C
0
6
4
C
1
N
4
2
$
C
$:7
1
$
C
$
!le
d
o
M
=
e
m
it
n
w
o
D
_
C
1
8
5
C
1
N
8
8
2
$
D
$:7
1
$
D
$
!le
d
o
M
=
w
olF
_
C
0
0
1
6
C
1
N
2
$
A
$:7
1
$
A
$
!le
d
o
M
=
nigir
O
_
C
0
1
1
7
C
1
N
8
2
1
$
C
$:6
$
A
$
!le
d
o
M
=
elb
a
T
_
C
1
2
3
C
2
N
8
2
$
B
$:7
1
$
B
$
!le
d
o
M
=
n
oit
a
nits
e
D
_
N
0
5
4
C
2
N
5
$
C
$:2
3
$
C
$
!le
d
o
M
=
e
m
it
n
w
o
D
_
N
0
7
5
C
2
N
4
4
5
$
D
$:2
3
$
D
$
!le
d
o
M
=
w
olF
_
N
0
9
6
C
2
N
5
$
A
$:2
3
$
A
$
!le
d
o
M
=
nigir
O
_
N
0
0
1
7
C
2
N
4
2
1
$
G
$:6
$
E
$
!le
d
o
M
=
elb
a
T
_
N
0
3
4
C
3
N
6
5
$
B
$
!le
d
o
M
=
e
m
it
n
w
o
d
_la
t
o
T
0
5
5
C
3
N
0
3
$I$:7
1
$I$
!le
d
o
M
=
w
olf
_la
t
o
T
0
7
6
C
3
N
0
8
7
C
3
N
0
1
4
C
4
N
0
3
5
C
4
N
0
5
6
C
4
N
0
6
7
C
4
N
0
1
5
C
5
N
0
3
6
C
5
N
1
4
7
C
5
N
1
1
6
C
6
N
0
2
7
C
6
N
Total downme
20
Figure 5.32
The Airline Crew
Scheduling Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

1
Enter inputs. Enter the given flight information in the ranges B6:C12 and F6:G12.
Because this information will be used with lookup functions later on, the ranges A6:C12
and E6:G12 have been named C_Table and N_Table, respectively. The labels in columns A
and E serve only to identify the various flights.
2
Find feasible assignments. To fill in the Chicago-based crews section, find each early
flight leaving from Chicago that can be paired with a later flight leaving from New York so
that at least one hour of downtime occurs in between. (These correspond to the arcs in the
top section of Figure 5.31.) Then enter the flight codes of all such pairs of flights in columns
A and B. Do the same for the pairs that could be handled by New York-based crews. (These
correspond to the arcs in the bottom section of Figure 5.31.) Note that all this information is
entered manually—no formulas are involved.
3
Downtimes for feasible assignments. Calculate the downtime for each feasible pair
of flights by using lookup functions to extract the information from the flight schedules.
Specifically, enter the formula
=VLOOKUP(B17,N_Table,2)-VLOOKUP(A17,C_Table,3)
in cell C17 and copy it down for other flight pairs starting in Chicago. This subtracts the
beginning time of the second flight in the pair from the ending time of the first flight in the
pair. (Do you see why military time is used?) Similarly, enter the formula
=VLOOKUP(B32,C_Table,2)-VLOOKUP(A32,N_Table,3)
in cell C32 and copy it down for other flight pairs starting in New York.
4
Flows. Enter any flows in the C_Flow and N_Flow ranges in column D. Remember
that these will eventually be 0s and 1s, indicating that a crew is either assigned to a pair of
flights or it isn’t.
5
Flow balance constraints. There is a node in the network for each flight and a flow
balance constraint for each node—hence 14 flow balance constraints. However, things get a
bit tricky because each flight could be either the first or second flight in a given flight pair.
For example, consider flight C3. From Figure 5.31 (or Figure 5.32), flight C3 is the later
flight for two flight pairs (corresponding to rows 32 and 37 of the model), and it is the ear-
lier flight for two flight pairs (corresponding to rows 26 and 27 of the model). Now comes
the key observation for this particular model. Flight C3 must be flown exactly once, so
exactly one of these arrows must have flow 1, and the others must have flow 0. Therefore,
you should add this node’s total inflow to its total outflow and constrain this sum to be 1.9
To implement this, enter the formulas
=SUMIF(C_Origin,F17,C_Flow)
and
=SUMIF(C_Destination,F17,N_Flow)
in cells G17 and H17, and copy them to the range G18:H23 to take care of the flights leav-
ing from Chicago. Then enter the formulas
=SUMIF(N_Origin,F24,N_Flow)
and
=SUMIF(N_Destination,F24,C_Flow)
270
Chapter 5
Network Models
9Admittedly, this is not the usual flow balance constraint, but it works here. You might want to search for an alter-
native way of constructing the network.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

in cells G24 and H24, and copy them to the range G25:H30 to take care of the flights leav-
ing from New York. Finally, add these inflows and outflows in column I (in the Total_flow
range). As the spreadsheet model indicates (with equal signs and 1s in columns J and K),
these sums are constrained to be 1.
6
Total downtime. Calculate the total downtime in the Total_downtime cell with the
formula
=SUMPRODUCT(C_Downtime,C_Flow)
+SUMPRODUCT(N_Downtime,N_Flow)
USING SOLVER
The Solver dialog box should appear as in Figure 5.33. Note that the only constraints (other
than nonnegativity of the changing cells) are that the total flow into and out of each node
must be 1. This, plus the fact that network models with integer inputs automatically have
integer solutions, implies that the flows on all arcs will be 0 or 1.
5.6 Network Models in the Airline Industry
271
Figure 5.33
Solver Dialog Box
for Crew Scheduling
Model
3
4
5
6
7
8
9
10
11
12
A
B
C
D
E
F
G
H
I
J
K
Flight informaon
Chicago-NY 
Y
N
st
h
gilf
-Chicago 
la
nigir
O
st
h
gilf
 C1 ﬂight mes
Flight
Departs
Arrives
Flight
Departs
Arrives
Departs
Arrives
8
6
9
7
1
N
1
1
9
1
C
0
1
8
2
N
1
1
9
2
C
y
ale
D
2
1
0
1
3
N
4
1
2
1
3
C
 (hours) for ﬂight C1
3
4
1
2
1
4
N
7
1
5
1
4
C
6
1
4
1
5
N
9
1
7
1
5
C
8
1
6
1
6
N
1
2
9
1
6
C
0
2
9
1
7
N
2
2
0
2
7
C
Figure 5.34
Modified Input
Section to Allow
for a Delay
Discussion of the Solution
The optimal solution shown earlier in Figure 5.32 indicates that there should be three
Chicago-based crews and four New York-based crews. This is because there are three 1s in
the C_Flow range and four 1s in the N_Flow range. These 1s indicate the crew assign-
ments. For example, one Chicago-based crew flies the C1 and N3 flights, another flies the
C2 and N4 flights, and another flies the C4 and N7 flights. The total downtime for all seven
crews is 20 hours.
Sensitivity Analysis
The only inputs to Braneast’s model are the flight times, so we consider one possible sen-
sitivity analysis involving these flight times. Suppose the C1 flight from Chicago is
delayed by one or more hours. How will this affect the optimal solution? You need to vary
the input section, as shown in Figure 5.34. Specifically, enter the original flight times in
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

cells I6 and J6, enter a flight delay in cell I9, and formulas in cells B6 and C6. (The for-
mula in B6 is =I6+$I$9, which can be copied to C6.) After running SolverTable, allowing
the delay to vary from 0 to 3 in increments of 1 and keeping track of the total downtime
and the numbers of crews based in each city, you should obtain the results in Figure 5.35.
Unfortunately, there is a subtle problem that hasn’t been addressed. (Before reading on, see
if you can spot it.)
272
Chapter 5
Network Models
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
A
B
C
D
E
F
G
Oneway analysis for Solver model in Model (2) worksheet
Delay of ﬂight C1 (cell $I$9) values along side, output cell(s) along top
Total_downme
$B$59
$B$60
0
20
3
4
1
19
3
4
2
18
3
4
3
17
3
4
Note that cells B59 and B60 on the previous sheet contain the 
number of Chicago-based and New York-based crews. However, 
as explained in the text, we have "cheated" in this table. When 
the delay becomes 2 or 3 hours, there is a ﬂight pair (C1 to N3) 
that was previously feasible but is no longer feasible (because of 
the 1-hour downme restricon), and the opmal soluons are 
using it. (The soluon on the previous sheet is opmal for a delay 
of 3, but it violates the 1-hour downme.)
Figure 5.35
SolverTable Output
for Sensitivity to
Flight Delay
The problem is that when flight C1 is delayed, one or more flight pairings that had at
least one hour of downtime originally might no longer have this minimal required down-
time. In fact, the Solver solution for a delay of 3 hours schedules a crew to the pairing
C1–N3. But this is infeasible—the C1 flight gets into New York at time 11, and the N4
flight leaves New York at time 10. So the SolverTable solution reported for delays of 3
(and 2) corresponds to infeasible schedules. Unfortunately, there is no easy fix for running
this sensitivity analysis. Recall that the pairings (in columns A and B, rows 17 to 50 of
Figure 5.32) that have downtime of at least 1 were entered manually. To run this sensitiv-
ity analysis with SolverTable correctly, you would need to modify the original model so
that Solver gets to choose from all possible pairings, with the constraint that a pairing can
be chosen only if its downtime is at least 1. The model grows larger and somewhat more
complex, but it could be done.
■
We finish this section with a model that is realistic, complex, and not at all an obvious
network model. However, after using the network structure that lurks in the background,
the model simplifies tremendously. If you don’t believe us, just try modeling the problem
in any way other than as a network model.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

5.6 Network Models in the Airline Industry
273
E X A M P L E
5.8 SCHEDULING FLIGHTS AT TRICITIES AIRLINES
T
riCities Airlines flies several daily commuter flights to and from New York City,
Washington, D.C., and Boston. The company has been flying a fixed daily schedule of
flights, but it is now deciding whether to change this schedule. Each potential flight has
an estimated net revenue based on the typical number of passengers for the flight. (Look
ahead to Figure 5.37 for a listing of all potential flights and their net revenues.) The com-
pany owns four airplanes, and it does not anticipate buying any more. There is a fixed cost
of $1500 per plane per day that flies any flights. However, a plane that is not used does not
incur this fixed cost. We assume (although this could be relaxed) that there is no required
delay time on the ground; therefore, if a flight arrives in Boston at time 10, it can leave on
a new flight at time 10. (Time is again measured in military time.) Also, any plane that
arrives in a city after its last flight of the day has two options. It can sit overnight in that
city, or, at a cost of $500, it can be flown empty to another city overnight. The company’s
objective is to maximize its net profit per day, which equals net revenues from flights
flown, minus fixed costs of flying planes, minus overnight costs of flying empty.
Objective
To develop a network model for scheduling the airline’s flights, given its
available aircraft, to maximize net profit from the flights.
WHERE DO THE NUMBERS COME FROM?
In a real setting, the airline would first have to decide which flights, including flight times,
to include in the potential list of flights. This is presumably based on customer demands.
The financial inputs are obtained from accounting records. For example, the net revenue
for a flight is based on the number of passengers who typically take the flight, ticket prices,
personnel costs, and fuel costs. The fixed cost of operating a plane includes any costs that
do not depend directly on the amount of time the plane spends in the air.
Solution
We first discuss how this problem can be modeled as a network flow model, which is cer-
tainly not obvious. The trick is to have a node for each city/time combination. Because
flights are allowed on the half-hour, this means having nodes of the form Boston8,
Boston8.5, and so on, up toWashDC20 (assuming that the earliest flight leaves at time 8
and the latest flight arrives at time 20). There are three types of arcs. The most obvious
type is a flight arc. For example, if there is a flight from Boston at time 12.5 that arrives at
Washington, D.C., at time 14, then there is a flight arc from node Boston12.5 to node
WashDC14. The flow on such an arc represents the number of planes that fly this flight.
Because each flight can be flown at most once, a capacity of 1 is imposed on all such flight
arcs. The “cost” on a flight arc is the net revenue for flying the flight. (In this model, it is
more natural to use net revenues as the arc “costs,” so that the objective will be to maximize
net profit.)
The other arcs are less obvious. If a flight arrives in New York, say, at time 13, it
might sit on the ground until time 14.5, at which time it leaves for another city. This can
be modeled with the ground arcs NY13–NY13.5, NY13.5–NY14, and NY14–NY14.5.
In general, the flow on any ground arc represents the number of planes sitting on the
ground in that city for that half-hour period. These ground arcs have no capacities and
no costs.
Finally, it is important to relate one day to the next. Suppose that one or more planes
end up in New York at the end of the day, at time 20. They can either sit overnight in
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

New York, or they can be flown to another city, where they will be available at time 8 the
next morning. This behavior can be modeled with overnight arcs. The flow on an
overnight arc such as NY20–NY8 represents the number of planes that sit overnight in
New York. It has no capacity and a cost equal to the fixed cost of operating a plane. (By
attaching the fixed costs of operating planes to the overnight arcs, rather than to the
flight or ground arcs, there is no double-counting of fixed costs.) In contrast, the flow on
an overnight arc such as NY20–Boston8 represents the number of planes flown
overnight from New York to Boston. It has no capacity and a cost equal to the fixed cost
of operating a plane plus the cost of flying a plane empty overnight. Note that the total
flow on all overnight arcs equals the total number of planes being used—all planes being
used must be somewhere overnight. In fact, this total must be less than or equal to the
number of planes owned, four (because some of the planes might not be used at all).
A few of the nodes and arcs for this network are shown in Figure 5.36. The flight arcs
are the diagonal arcs, the ground arcs all point one step to the right, and the overnight arcs
go backward from right to left.
With this network, flow balance (inflow equals outflow) exists at every node. This indi-
cates conservation of planes. The same planes continue to circulate through the network day
after day. Of course, to obtain different schedules on different days of the week, the model
must be modified, and it becomes considerably more complex.
274
Chapter 5
Network Models
B8
B8.5
N8
N8.5
N14.5
N20
W8
W8.5
W14
W20
B12.5
B13.5
B20
Figure 5.36
Selected Nodes and
Arcs for Flights
Model
Table 5.13 Variables and Constraints for Flight Scheduling Model
Input variables
Planes owned, fixed cost per plane used, overnight cost for flying a 
plane empty, flight information about potential flights (including net 
revenues for flights)
Decision variables 
Flows (0-1 variables to indicate which flights are selected, when planes 
(changing cells)
are on the ground, when planes are flying overnight empty)
Objective (target cell)
Net profit
Other output cells
Net outflows on arcs, number of planes used
Constraints
Planes used  Planes owned
Flows (for flight arcs)  1
Net outflows (for all arcs)  0
With the preceding discussion in mind, the variables and constraints for the model are
listed in Table 5.13.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

DEVELOPING THE SPREADSHEET MODEL
The finished model is large, so it is shown in pieces. (See the file Flight Scheduling.xlsx.)
Figure 5.37 shows the potential flight schedule, plus the other inputs. Recall that TriCities
wants to select the appropriate subset of these flights to fly, which could be all of them.
(All monetary values are expressed in hundreds of dollars.) Note that the cost of flying a
plane empty overnight is a constant. (A simple modification would allow this cost to
depend on the origin and destination of the flight.)
The information on the three types of arcs appears in Figures 5.38, 5.39, and 5.40. The
flight arcs correspond exactly to the available flights in Figure 5.37. Note that each flight
arc has a capacity of 1. There are many ground arcs (note the hidden rows in Figure 5.39),
each extending one half-hour into the day, and their costs are all 0. Finally, there are only
nine ground arcs. Each has a fixed cost, and those that represent empty overnight flights
also have an overnight cost.
5.6 Network Models in the Airline Industry
275
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
J
I
H
G
F
E
D
C
B
A
Flight scheduling model
Input data
Range names used:
Planes 
4
d
e
n
w
o
Flight_desnaon
=Model!$B$37:$B$59
Fixed cost per 
5
1
e
n
alp
Flight_ﬂow
=Model!$D$37:$D$59
Overnight 
5
ts
o
c
Flight_net_revenue
=Model!$C$37:$C$59
Flight_origin
=Model!$A$37:$A$59
Flight informaon
Ground_desnaon
=Model!$B$63:$B$134
Flight Number
Origin
Desnaon
Departs
Arrives
Net Revenue
Ground_ﬂow
=Model!$D$63:$D$134
4
3
1
$
A
$:3
6
$
A
$
!le
d
o
M
=
nigir
o
_
d
n
u
o
r
G
5
2
9
8
Y
N
n
o
ts
o
B
7
5
3
1
1
1
1
$I$:7
3
$I$
!le
d
o
M
=
w
olft
u
o
_
t
e
N
0
3
5.0
1
5.9
Y
N
n
o
ts
o
B
2
2
3
8
6
5
1
$
B
$
!le
d
o
M
=
tif
o
r
p
_
t
e
N
9
3
4
1
5.2
1
C
D
h
s
a
W
n
o
ts
o
B
3
0
9
5
0
5
1
$
D
$
!le
d
o
M
=
d
e
n
w
o
_
r
e
b
m
u
N
4
2
5
1
5.3
1
C
D
h
s
a
W
n
o
ts
o
B
7
0
2
1
0
5
1
$
B
$
!le
d
o
M
=
d
e
s
u
_
r
e
b
m
u
N
4
2
5.4
1
5.3
1
Y
N
n
o
ts
o
B
1
7
6
1
6
4
1
$
B
$:8
3
1
$
B
$
!le
d
o
M
=
n
oit
a
nits
e
d
_
t
h
gin
r
e
v
O
5
3
5.7
1
6
1
C
D
h
s
a
W
n
o
ts
o
B
1
7
6
5
6
4
1
$
E
$:8
3
1
$
E
$
!le
d
o
M
=
w
olf
_
t
h
gin
r
e
v
O
9
2
5.7
1
5.6
1
Y
N
n
o
ts
o
B
3
3
1
7
6
4
1
$
A
$:8
3
1
$
A
$
!le
d
o
M
=
nigir
o
_
t
h
gin
r
e
v
O
8
2
1
1
5.9
n
o
ts
o
B
Y
N
6
6
1
4
3
1
5.3
1
2
1
n
o
ts
o
B
Y
N
2
4
8
3
8
1
5.4
1
3
1
C
D
h
s
a
W
Y
N
7
3
5
1
2
2
6
1
4
1
n
o
ts
o
B
Y
N
0
2
3
9
8
2
8
1
5.6
1
n
o
ts
o
B
Y
N
2
4
0
3
4
3
5.9
1
8
1
n
o
ts
o
B
Y
N
2
5
7
3
9
3
0
2
8
1
C
D
h
s
a
W
Y
N
7
7
6
9
5
1
0
2
5.8
1
n
o
ts
o
B
Y
N
2
1
2
6
2
1
1
1
9
Y
N
C
D
h
s
a
W
1
1
8
6
8
2
4
1
5.2
1
Y
N
C
D
h
s
a
W
5
9
1
9
3
1
5
1
3
1
Y
N
C
D
h
s
a
W
0
5
3
8
8
1
5.5
1
5.3
1
n
o
ts
o
B
C
D
h
s
a
W
0
8
4
9
3
3
5.5
1
4
1
Y
N
C
D
h
s
a
W
5
5
5
7
8
2
5.5
1
4
1
n
o
ts
o
B
C
D
h
s
a
W
1
4
0
9
9
1
5.6
1
5.4
1
n
o
ts
o
B
C
D
h
s
a
W
9
3
5
7
5
1
5.7
1
6
1
n
o
ts
o
B
C
D
h
s
a
W
0
1
7
2
Figure 5.37
Inputs for Flights Problem
The rest is straightforward. As usual, you need to fill out a table of flow balance 
constraints, as shown in Figure 5.41. (Note that many rows have been hidden.) There is a
constraint for each node—that is, each city/time combination. The typical formula for net
outflow in cell I37, which can be copied down column I, is
=SUMIF(Flight_origin,H37,Flight_flow)+SUMIF(Ground_origin,H37,Ground_flow)
+SUMIF(Overnight_origin,H37,Overnight_flow)
-(SUMIF(Flight_destination,H37,Flight_flow)
+SUMIF(Ground_destination,H37,Ground_flow)
+SUMIF(Overnight_destination,H37,Overnight_flow))
This looks complex, but it is simply the sum of outflows from the three types of arcs minus
the sum of inflows from the three types of arcs. Because there must be flow balance at each
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

node, each net outflow must be 0. (Also, keep in mind that all of the range names in this
model can be created quickly with the Create from Selection shortcut, provided that you
supply nice labels for headings.)
Figures 5.42 and 5.43 show the rest of the model and the Solver dialog box. To find
the number of planes used, sum the flows on all overnight arcs in cell B150 with the formula
=SUM(Overnight_flow)
276
Chapter 5
Network Models
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
125
126
127
128
129
130
131
132
133
134
D
C
B
A
Ground arcs
Ground origin
Ground desnaon
Ground cost
Ground ﬂow
1
0
5.8
n
o
ts
o
B
8
n
o
ts
o
B
1
0
9
n
o
ts
o
B
5.8
n
o
ts
o
B
1
0
5.9
n
o
ts
o
B
9
n
o
ts
o
B
0
0
0
1
n
o
ts
o
B
5.9
n
o
ts
o
B
0
0
5.0
1
n
o
ts
o
B
0
1
n
o
ts
o
B
0
0
1
1
n
o
ts
o
B
5.0
1
n
o
ts
o
B
1
0
5.1
1
n
o
ts
o
B
1
1
n
o
ts
o
B
1
0
2
1
n
o
ts
o
B
5.1
1
n
o
ts
o
B
1
0
5.2
1
n
o
ts
o
B
2
1
n
o
ts
o
B
0
0
3
1
n
o
ts
o
B
5.2
1
n
o
ts
o
B
0
0
5.3
1
n
o
ts
o
B
3
1
n
o
ts
o
B
0
0
4
1
n
o
ts
o
B
5.3
1
n
o
ts
o
B
0
0
5.4
1
n
o
ts
o
B
4
1
n
o
ts
o
B
0
0
5.5
1
C
D
h
s
a
W
5
1
C
D
h
s
a
W
0
0
6
1
C
D
h
s
a
W
5.5
1
C
D
h
s
a
W
0
0
5.6
1
C
D
h
s
a
W
6
1
C
D
h
s
a
W
0
0
7
1
C
D
h
s
a
W
5.6
1
C
D
h
s
a
W
0
0
5.7
1
C
D
h
s
a
W
7
1
C
D
h
s
a
W
1
0
8
1
C
D
h
s
a
W
5.7
1
C
D
h
s
a
W
1
0
5.8
1
C
D
h
s
a
W
8
1
C
D
h
s
a
W
1
0
9
1
C
D
h
s
a
W
5.8
1
C
D
h
s
a
W
1
0
5.9
1
C
D
h
s
a
W
9
1
C
D
h
s
a
W
1
0
0
2
C
D
h
s
a
W
5.9
1
C
D
h
s
a
W
Figure 5.39
Ground Arcs
136
137
138
139
140
141
142
143
144
145
146
E
D
C
B
A
Overnight arcs
Overnight origin
Overnight desnaon
Fixed cost
Overnight cost
Overnight ﬂow
2
0
5
1
8
n
o
ts
o
B
0
2
n
o
ts
o
B
0
5
5
1
8
Y
N
0
2
n
o
ts
o
B
0
5
5
1
8
C
D
h
s
a
W
0
2
n
o
ts
o
B
0
5
5
1
8
n
o
ts
o
B
0
2
Y
N
0
0
5
1
8
Y
N
0
2
Y
N
0
5
5
1
8
C
D
h
s
a
W
0
2
Y
N
0
5
5
1
8
n
o
ts
o
B
0
2
C
D
h
s
a
W
0
5
5
1
8
Y
N
0
2
C
D
h
s
a
W
2
0
5
1
8
C
D
h
s
a
W
0
2
C
D
h
s
a
W
Figure 5.40
Overnight Arcs
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
F
E
D
C
B
A
Flight arcs
Flight origin
Flight desnaon
Flight net revenue
Flight ﬂow
Flight capacity
1
=
<
1
5
2
9
Y
N
8
n
o
ts
o
B
1
=
<
1
0
3
5.0
1
Y
N
5.9
n
o
ts
o
B
1
=
<
1
9
3
4
1
C
D
h
s
a
W
5.2
1
n
o
ts
o
B
1
=
<
0
4
2
5
1
C
D
h
s
a
W
5.3
1
n
o
ts
o
B
1
=
<
1
4
2
5.4
1
Y
N
5.3
1
n
o
ts
o
B
1
=
<
1
5
3
5.7
1
C
D
h
s
a
W
6
1
n
o
ts
o
B
1
=
<
1
9
2
5.7
1
Y
N
5.6
1
n
o
ts
o
B
1
=
<
1
8
2
1
1
n
o
ts
o
B
5.9
Y
N
1
=
<
1
3
1
5.3
1
n
o
ts
o
B
2
1
Y
N
1
=
<
1
8
1
5.4
1
C
D
h
s
a
W
3
1
Y
N
1
=
<
1
2
2
6
1
n
o
ts
o
B
4
1
Y
N
1
=
<
1
8
2
8
1
n
o
ts
o
B
5.6
1
Y
N
1
=
<
1
4
3
5.9
1
n
o
ts
o
B
8
1
Y
N
1
=
<
1
9
3
0
2
C
D
h
s
a
W
8
1
Y
N
1
=
<
0
5
1
0
2
n
o
ts
o
B
5.8
1
Y
N
1
=
<
1
2
1
1
1
Y
N
9
C
D
h
s
a
W
1
=
<
1
8
2
4
1
Y
N
5.2
1
C
D
h
s
a
W
1
=
<
0
3
1
5
1
Y
N
3
1
C
D
h
s
a
W
1
=
<
0
8
1
5.5
1
n
o
ts
o
B
5.3
1
C
D
h
s
a
W
1
=
<
1
3
3
5.5
1
Y
N
4
1
C
D
h
s
a
W
1
=
<
0
8
2
5.5
1
n
o
ts
o
B
4
1
C
D
h
s
a
W
1
=
<
1
9
1
5.6
1
n
o
ts
o
B
5.4
1
C
D
h
s
a
W
1
=
<
0
5
1
5.7
1
n
o
ts
o
B
6
1
C
D
h
s
a
W
Figure 5.38
Flight Arcs
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

5.6 Network Models in the Airline Industry
277
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
102
103
104
105
106
107
108
109
110
111
H
I
J
K
Flow balance constraints
Node
Net oulow
Required
0
=
0
8
n
o
ts
o
B
0
=
0
5.8
n
o
ts
o
B
0
=
0
9
n
o
ts
o
B
0
=
0
5.9
n
o
ts
o
B
0
=
0
0
1
n
o
ts
o
B
0
=
0
5.0
1
n
o
ts
o
B
0
=
0
1
1
n
o
ts
o
B
0
=
0
5.1
1
n
o
ts
o
B
0
=
0
2
1
n
o
ts
o
B
0
=
0
5.2
1
n
o
ts
o
B
0
=
0
3
1
n
o
ts
o
B
0
=
0
5.3
1
n
o
ts
o
B
WashDC15.5
0
=
0
0
=
0
6
1
C
D
h
s
a
W
WashDC16.5
0
=
0
0
=
0
7
1
C
D
h
s
a
W
WashDC17.5
0
=
0
0
=
0
8
1
C
D
h
s
a
W
WashDC18.5
0
=
0
0
=
0
9
1
C
D
h
s
a
W
WashDC19.5
0
=
0
0
=
0
0
2
C
D
h
s
a
W
Figure 5.41
Flow Balance
Constraints for
Flights Model
148
149
150
151
152
153
154
155
156
D
C
B
A
Constraint on planes
Number 
r
e
b
m
u
N
d
e
s
u
 owned
4
=
<
4
Monetary values
Net 
6
5
4
s
e
u
n
e
v
e
r
Fixed 
0
6
sts
o
c
Overnight 
0
sts
o
c
Net 
6
9
3
tif
o
r
p
Figure 5.42
Rest of Flights Model
Figure 5.43
Solver Dialog Box
for Flights Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Then calculate the various monetary values with the usual SUMPRODUCT functions. For
example, the formula for total net revenue from flights is
=SUMPRODUCT(Flight_net_revenue,Flight_flow)
Finally, combine these into a profit objective in cell B156 with the formula
B153-B154-B155
The Solver dialog box follows easily—and is remarkably compact for such a large and
complex model.
Discussion of the Solution
The optimal solution can be seen primarily from Figures 5.38 and 5.40. The former indi-
cates that TriCities should fly only 17 of the potential 23 flights. The latter shows that no
overnight flights should be flown. It also shows that all four planes are used. Two of these
sit overnight in Boston, and the other two sit overnight in Washington, D.C. No overnight
flights are flown, evidently because the cost of doing so is too large. The daily profit from
this solution is $39,600.
Sensitivity Analysis
You could run many interesting sensitivity analyses. For example, what if TriCities had
more planes? To answer this, you can run SolverTable with cell B4 as the single input cell,
allowing it to vary from 4 to 8 in increments of 1, and keep track of the monetary values, as
well as the number of flights flown. (This latter output is calculated in cell B158 with the
formula =SUM(Flight_flow).) The results appear in Figure 5.44. As expected, profit and
the number of flights flown both increase when the company owns more planes, but this
analysis does not take the cost of purchasing more planes into account. TriCities would
need to trade off the cost of new planes with this increased profit.
278
Chapter 5
Network Models
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
A
B
C
D
E
F
G
Oneway analysis for Solver model in Model worksheet
Planes owned (cell $B$4) values along side, output cell(s) along top
$B$153
$B$154
$B$155
Net_proﬁt
$B$158
4
456
60
0
396
17
5
495
75
0
420
19
6
523
90
5
428
20
7
551
105
10
436
22
8
551
105
10
436
22
The ﬁrst four outputs above are monetary 
values from the previous sheet. The output in 
cell B158 is the number of ﬂights ﬂown.
Figure 5.44
Sensitivity to
Planes Owned
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

From Figure 5.44, you can see that TriCities still does not fly all 23 potential flights,
even with eight planes. Could it? You can answer this question easily by changing the
objective from maximizing profit to maximizing the number of flights flown (in cell B158)
and rerunning Solver. If you do so, you will find that the maximum is 23. Therefore,
TriCities could fly all 23 flights with eight planes, but the cost structure makes it more
profitable to fly only 22. The driving factor here is evidently the fixed cost per plane. When
TriCities owns eight planes, the optimal profit solution uses only seven of these planes.
A final sensitivity analysis involves empty overnight flights. When TriCities owns
seven planes, Figure 5.44 indicates (see cell E165) that it flies two empty overnight flights.
(These are both from Boston to Washington, D.C.) What happens to this solution if, as a
matter of company policy, empty overnight flights are not allowed? You can modify the
model in three ways to answer this question. First, you can impose a huge cost on
overnight flights, effectively ruling them out. Second, you can impose capacities of zero on
the overnight flight arcs (in Figure 5.40). Third, you can simply eliminate these arcs. By
using the first method, you obtain the results shown in Figure 5.45. The solution changes
fairly dramatically. Now TriCities uses only five of its seven planes, it flies only 19 (instead
of 22) flights, and its profit decreases from $43,600 to $42,000.
5.6 Network Models in the Airline Industry
279
148
149
150
151
152
153
154
155
156
157
158
D
C
B
A
Constraint on planes
Number 
r
e
b
m
u
N
d
e
s
u
 owned
7
=
<
5
Monetary values
Net 
5
9
4
s
e
u
n
e
v
e
r
Fixed 
5
7
sts
o
c
Overnight 
0
sts
o
c
Net 
0
2
4
tif
o
r
p
Flights 
9
1
n
w
olf
Figure 5.45
Model with
Overnight Flights
Disallowed
As stated previously, airlines are heavy users of management science. A quick look
through recent issues of the Interfaces journal confirms this. Here are some examples.
Virtually all of these examples describe optimization models that employ network and
integer programming algorithms.
Improving Fractional Aircraft Ownership Operations at Flexjet
Fractional aircraft ownership programs allow individuals to buy shares in a business jet at
a fraction of the cost of full ownership. The fractional aircraft market is the fastest growing
segment of the business aircraft market. Hicks et al. (2005) describe how they used large-
scale, mixed-integer, nonlinear optimization models to maximize the use of aircraft, crew,
and facilities for Flexjet’s fractional aircraft ownership operations. Since inception, the
system has generated savings in excess of $54 million with projected additional savings of
$27 million annually.
Optimizing Pilot Staffing and Training at Continental Airlines
Yu et al. (2004) describe how they developed the Crew ResourceSolver decision-support
system for Continental Airlines. This system employs advanced optimization modeling
ADDITIONAL APPLICATIONS
■
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

and solution techniques to solve large, complex pilot staffing and training problems. The
authors estimate that the system has saved Continental over $10 million annually.
UPS Optimizes Its Air Network
Armacost et al. (2004) describe how a team of operations research analysts at UPS and
Massachusetts Institute of Technology created a system to optimize the design of service
networks for delivering express packages. The system determines aircraft routes, fleet
assignments, and package routings to ensure overnight delivery at minimum cost. UPS
credits the system with savings in excess of $87 million between 2000 and 2002, and it
anticipates future savings to be in the hundreds of millions of dollars.
Optimizing On-Demand Aircraft Schedules 
for Fractional Aircraft Operators
Martin et al. (2003) describe how Bitwise Solutions developed a flexible, integrated
decision-support system to help fractional management companies (companies that man-
age fractional aircraft ownership programs) optimize their fleet schedules. The system
handles all aspects of fractional fleet management: reservations, scheduling, dispatch, air-
craft maintenance, and crew requirements. In November 2000, Raytheon Travel Air began
using the system and reported a $4.4 million savings in the first year of use.
Delta Optimizes Continuing-Qualification-Training 
Schedules for Pilots
The downturn in airline business after the terrorist attacks of September 11, 2001, forced air-
lines to modify their operations. Sohoni et al. (2003) describe modifications at Delta Airlines,
which had to reduce its workforce and modify its requirements for scheduling pilot training.
To minimize Delta’s costs and automate the scheduling process under a rigid planning time
line, the authors developed an optimization system that builds and assigns training schedules
based on individual pilot’s requirements. Delta expects to save $7.5 million in annual operat-
ing costs by using the system to schedule continuing qualification training for its pilots.
Crew Recovery at Continental Airlines
Due to unexpected events such as inclement weather, airline crews may not be in position to
service their remaining scheduled flights. Airlines must reassign crews quickly to cover open
flights and return them to their original schedules in a cost-effective manner that honors vari-
ous regulations. Yu et al. (2003) describe how they developed a decision-support system for
Continental Airlines to generate optimal or nearly optimal crew-recovery solutions. Since its
implementation, the system has dealt successfully with several disruptive events, including
snowstorms, a flood, and the 9/11 terrorist attacks. Continental estimates that the system was
responsible for savings of approximately $40 million for major disruptions alone.
■
280
Chapter 5
Network Models
P R O B L E M S
Skill-Building Problems
39. In the crew-scheduling problem, suppose (as in the
sensitivity analysis we discussed) that the first
Chicago flight, C1, is delayed by two hours—that is,
its departure and arrival times move up to 8 A.M. and
10 A.M., respectively. How does the model need to be
modified? What is the new optimal solution? Is it
the same as the solution indicated by SolverTable in
Figure 5.35? If not, why not?
40. The required downtime in the crew-scheduling
problem is currently assumed to be one hour. Suppose
instead that it is required to be two hours. How does the
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

5.7 Conclusion
281
model need to be modified? What is the new optimal
solution?
41. In the crew-scheduling problem, suppose that two
extra flights are added to the current list. The first
leaves Chicago at 11 A.M. and arrives in New York at
1 P.M. The second leaves New York at 6 P.M. and
arrives in Chicago at 8 P.M. (Remember that all quoted
times are EST.) Modify the model to incorporate these
two new flights. What is the new optimal solution?
42. In the flight-scheduling model, use SolverTable to
examine the effect of decreasing all net revenues by
the same percentage, assuming that the company
owns six planes. Let this percentage vary from 0% to
50% in increments of 10%. Discuss the changes that
occur in the optimal solution.
43. In the flight-scheduling model, use SolverTable to
examine the effect of increasing both the fixed cost per
plane and the overnight cost by the same percentage,
assuming that the company owns eight planes. Let this
percentage vary from 0% to 50% in increments of
10%. Discuss the changes that occur in the optimal
solution.
Skill-Extending Problems
44. One rather unrealistic assumption in the flight-
scheduling model is that a given plane can fly two
consecutive flights with no downtime. For example,
it could fly flight 5903 that gets into Washington, D.C.
at time 14 and then fly flight 7555 that leaves
Washington, D.C. at time 14. Modify the model so
that there must be at least one hour of downtime
between consecutive flights.
45. In the crew-scheduling model, there are exactly as
many flights departing from Chicago as departing
from New York. Suppose more flights are departing
from one city than from the other. How would you
model this? Illustrate by assuming that there is an
extra flight from Chicago that leaves at 11 A.M. and
arrives at New York at 1 P.M. (Remember that all
quoted times are EST.)
5.7 CONCLUSION
In this chapter, you have seen a number of management science problems that can be for-
mulated as network models. Often these problems are of a logistics nature—shipping
goods from one set of locations to another. However, you have also seen that problems that
do not involve shipping or traveling along a physical network can sometimes be formu-
lated as network models. Examples include the bus route assignment and machine replace-
ment problems.
Formulating a problem as a network model has at least two advantages. First, although
Excel’s Solver doesn’t employ them, fast special-purpose algorithms exist for various
forms of network models. These enable companies to solve extremely large problems that
might not be solvable with ordinary LP algorithms. Second, the graphical representation of
network models often makes them easier to visualize. When a problem can be visualized
graphically, it is often simpler to model (in a spreadsheet or otherwise) and ultimately to
optimize.
Summary of Key Management Science Terms
Term
Explanation
Page
Network models
Class of optimization models that can be represented 
228
graphically as a network; typically (but not always) involves 
shipping goods from one set of locations to another at 
minimum cost 
Nodes
Points in a network representation; often correspond to locations 
230
Arcs
Arrows in a network representation; often correspond to routes 
230
connecting locations 
Flows
Decision variables that represent the amounts sent along arcs 
231
Arc capacities
Upper bounds on flows on some or all arcs 
231
(continued)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Term
Explanation
Page
Flow balance constraints
Constraints that force the amount sent into a node to equal 
235
the amount sent out, except possibly for amounts that start out 
or end up at the node 
Assignment models
Class of optimization models where members of one set (like 
241
workers) must be assigned optimally to members of another 
set (like jobs)
Shortest path models
Network models where the goal is to get from an origin node 
257
to a destination node at minimal distance (or cost) 
Summary of Key Excel Terms
Term
Explanation
Excel
Page
SUMIF function
Sums values in one range 
=SUMIF(compareRange,
236
corresponding to cells in a 
criterion, sumRange) 
related range that satisfy a criterion
COUNTIF function
Counts values in one range that 
=COUNTIF(range,criterion)
253
satisfy a criterion
282
Chapter 5
Network Models
P R O B L E M S
Skill-Building Problems
46. The government is auctioning off oil leases at two
sites. At each site, 100,000 acres of land are to be auc-
tioned. Cliff Ewing, Blake Barnes, and Alexis Pickens
are bidding for the oil. Government rules state that no
bidder can receive more than 40% of the land being
auctioned. Cliff has bid $1000 per acre for site 1 land
and $2000 per acre for site 2 land. Blake has bid $900
per acre for site 1 land and $2200 per acre for site 
2 land. Alexis has bid $1100 per acre for site 1 land
and $1900 per acre for site 2 land.
a. Determine how to maximize the government’s
revenue with a transportation model.
b. Use SolverTable to see how changes in the
government’s rule on 40% of all land being
auctioned affect the optimal revenue. Why can the
optimal revenue not decrease if this percentage
required increases? Why can the optimal revenue
not increase if this percentage required decreases?
47. The 7th National Bank has two check-processing sites.
Site 1 can process 10,000 checks per day, and site 2
can process 6000 checks per day. The bank processes
three types of checks: vendor, salary, and personal.
The processing cost per check depends on the site, as
listed in the file P05_47.xlsx. Each day, 5000 checks
of each type must be processed. Develop a network
model to determine how to minimize the daily cost of
processing checks.
48. The Amorco Oil Company controls two oil fields.
Field 1 can produce up to 20 million barrels of oil per
day, and field 2 can produce up to 15 million barrels
of oil per day. At field 1, it costs $37.50 to extract and
refine a barrel of oil; at field 2 the cost is $41.20.
Amorco sells oil to two countries: United Kingdom
and Japan. The shipping costs per barrel are shown in
the file P05_48.xlsx. Each day, the United Kingdom is
willing to buy up to 10 million barrels at $65.80 per
barrel, and Japan is willing to buy up to 25 million
barrels at $68.40 per barrel. Determine how to maxi-
mize Amorco’s profit.
49. Touche Young has eight auditors. Each can work
up to 160 hours during the next month, during
which time six projects must be completed. The hours
required for each project and the amounts each auditor
can be billed for each project are given in the file
P05_49.xlsx. Note that more than one auditor can
work on a given project, in which case their hours add
to the total for the project. Determine how to
maximize total billings during the next month.
50. Five employees are available to perform four jobs. 
The time it takes each person to perform each job
is given in the file P05_50.xlsx. Determine the
assignment of employees to jobs that minimizes
the total time required to perform the four jobs. (A
blank indicates that a person cannot do that particular
job. Also, assume that no person can do more than one
job.)
51. Based on Machol (1970). A swimming coach is
putting together a relay team for the 400-meter relay.
Each swimmer must swim 100 meters of breaststroke,
Summary of Key Management Science Terms
(Continued)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

backstroke, butterfly, or freestyle, and each swimmer
can swim only one race. The coach believes that each
swimmer can attain the times given in the file
P05_51.xlsx. To minimize the team’s total time for the
race, which swimmers should swim which strokes?
52. A company is taking bids on four construction jobs.
Three contractors have placed bids on the jobs. Their
bids (in thousands of dollars) are given in the file
P05_52.xlsx. (A blank indicates that the contractor did 
not bid on the given job.) Contractor 1 can do only
one job, but contractors 2 and 3 can each do up to two
jobs. Determine the minimum cost assignment of
contractors to jobs.
53. A company manufactures widgets at two factories, one
in Memphis and one in Denver. The Memphis factory
can produce up to 150 widgets per day, and the Denver
factory can produce up to 200 widgets per day. The
company are shipped by air to customers in Los
Angeles and Boston. The customers in each city
require 130 widgets per day. Because of the deregula-
tion of airfares, the company believes that it might be
cheaper to first fly some widgets to New York or
Chicago and then fly them to their final destinations.
The costs of flying a widget are shown in the file
P05_53.xlsx.
a. Determine how to minimize the total cost of ship-
ping the required widgets to the customers.
b. Suppose the capacities of both factories are
reduced in increments of 10 widgets per day. Use
SolverTable to see how much the common reduc-
tion can be before the total cost increases, and how
much it must be before there is no feasible solution.
54. General Ford produces cars in Los Angeles and
Detroit and has a warehouse in Atlanta. The company
supplies cars to customers in Houston and Tampa.
The costs of shipping a car between various points
are listed in the file P05_54.xlsx, where a blank means
that a shipment is not allowed. Los Angeles can
produce up to 1100 cars, and Detroit can produce up
to 2900 cars. Houston must receive 2400 cars, and
Tampa must receive 1500 cars.
a. Determine how to minimize the cost of meeting
demands in Houston and Tampa.
b. Modify the answer to part a if shipments between
Los Angeles and Detroit are not allowed.
c. Modify the answer to part a if shipments between
Houston and Tampa are allowed at a cost of $75
per car.
55. Sunco Oil produces oil at two wells. Well 1 can pro-
duce up to 150,000 barrels per day, and well 2 can
produce up to 200,000 barrels per day. It is possible to
ship oil directly from the wells to Sunco’s customers
in Los Angeles and New York. Alternatively, Sunco
could transport oil to the ports of Mobile and
Galveston and then ship it by tanker to New York or
5.7 Conclusion
283
Los Angeles. Los Angeles requires 160,000 barrels per
day, and New York requires 140,000 barrels per day.
The costs of shipping 1000 barrels between various
locations are shown in the file P05_55.xlsx, where a
blank indicates shipments that are not allowed.
Determine how to minimize the transport costs in meet-
ing the oil demands of Los Angeles and New York.
56. Nash Auto has two plants, two warehouses, and three
customers. The plants are in Detroit and Atlanta, the
warehouses are in Denver and New York, and the cus-
tomers are in Los Angeles, Chicago, and Philadelphia.
Cars are produced at plants, then shipped to ware-
houses, and finally shipped to customers. Detroit can
produce 200 cars per week, and Atlanta can produce
160 cars per week. Los Angeles requires 80 cars per
week, Chicago requires 70, and Philadelphia requires
60. It costs $8,000 to produce a car at each plant. The
costs of shipping a car between various cities are listed
in the file P05_56.xlsx. Assume that during a week, at
most 75 cars can be shipped from a warehouse to any
particular city. Determine how to meet Nash’s weekly
demands at minimum cost.
57. Edsel Motors produces cars in Detroit and Dallas. The
Detroit plant can produce up to 8500 cars, and the
Dallas plant can produce up to 4000 cars. Producing a
car costs $2000 in Detroit and $1800 in Dallas. Cars
must be shipped to 12 cities. The costs of shipping a
car from each plant to each city and the city require-
ments are given in the file P05_57.xlsx. At most 1000
cars can be sent from a given plant to a given city.
Determine how to minimize the cost of meeting all
demands.
58. Each year, Data Corporal produces up to 5000 comput-
ers in Boston and up to 3500 computers in Charlotte.
There are customers in Los Angeles, New York, and
Seattle who must receive 2300, 3700, and 1300
computers, respectively. Producing a computer costs
$250 in Boston and $275 in Charlotte. Computers are
transported by plane and can be sent through Chicago.
The costs of sending a computer between pairs of cities
are shown in the file P05_58.xlsx.
a. Determine how to minimize the total (production
plus shipping) cost of meeting Data Corporal’s
annual demand. Why doesn’t it make sense to ship
any computers through Chicago?
b. Modify the model so that no more than 1250 com-
puters can be shipped between any two cities, and
find the optimal solution to this modified model.
Why are computers now shipped through Chicago?
59. It costs $300 to buy a lawn mower from a lawn supply
store. Assume that you can keep a lawn mower for at
most five years and that the estimated maintenance
cost each year of operation is as follows: year 1, $90;
year 2, $135; year 3, $175; year 4, $200; year 5, $250.
You have just purchased a new lawn mower. Assuming
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

that a lawn mower has no salvage value, determine the
strategy that minimizes the total cost of purchasing
and operating a lawn mower for the next 10 years.
60.. Suppose it costs $20,000 to purchase a new car. The
annual operating cost and resale value of a used car
are shown in the file P05_60.xlsx. Assume that you
presently have a new car. Determine a replacement
policy that minimizes your net costs of owning and
operating a car for the next six years.
61. At the beginning of year 1, a new machine must be
purchased. The cost of maintaining a machine,
depending on its age, is given in the file P05_61.xlsx.
The cost of purchasing a machine at the beginning of
each year is given in this same file. There is no trade-
in value when a machine is replaced. The goal is to
minimize the total (purchase plus maintenance) cost of
having a machine for five years. Determine the years
in which a new machine should be purchased.
62. Delko is considering hiring people for four types of jobs.
The company would like to hire the number of people
listed in the file P05_62.xlsx for each type of job. Delko
can hire four types of people. Each type is qualified to
perform two types of jobs, as shown in this same file. A
total of 20 type 1, 30 type 2, 40 type 3, and 20 type 4
people have applied for jobs. Determine how Delko can
maximize the number of employees assigned to suitable
jobs, assuming that each person can be assigned to at
most one job. (Hint: Set this up as a transportation
model where the “supplies” are the applicants.)
63. The town of Busville has three school districts. The
numbers of black students and white students in each
district are shown in the file P05_63.xlsx. The
Supreme Court requires the schools in Busville to be
racially balanced. Thus, each school must have exactly
300 students, and each school must have the same
number of black students. The distances between dis-
tricts are shown in the same file. Determine how to
minimize the total distance that students must be
bussed while still satisfying the Supreme Court’s
requirements. Assume that a student who remains in
his or her own district does not need to be bussed.
284
Chapter 5
Network Models
64. A truck must travel from New York to Los Angeles.
As shown in Figure 5.46, several routes are available.
The number associated with each arc is the number of
gallons of fuel required by the truck to traverse the arc.
Determine the route from New York to Los Angeles
that uses the minimum amount of gas.
65. You are trying to help the MCSCC (Monroe County
School Corporation) determine the appropriate high
school district for each housing development in
Bloomington. For each development, you are given the
number of students, the mean family income, the per-
centage of minorities, and the distance to each high
school (South and North). These data are listed in the
file P05_65.xlsx. In assigning the students, MCSCC
wants to minimize total distance traveled subject to the
following constraints:
■Each school must have at least 1500 students.
■The mean family income must be at least $85,000
for students of each school.
■Each school must have at least 10% minorities.
Determine an optimal assignment of students to
schools. Then provide a one-paragraph summary of
how the optimal solution changes as the required
minority percentage varies from 5% to 11%.
66. A school system has 16 bus drivers that must cover
12 bus routes. Each driver can cover at most one route.
The driver’s bids for the various routes are listed in
the file P05_66.xlsx. Each bid indicates the amount
the driver will charge the school system to drive that
route. How should the drivers be assigned to the routes
to minimize the school system’s cost? After you find
the optimal assignments, use conditional formatting so
that the cost the school system pays for each route is
highlighted in red and whenever the cheapest bid is
not used for a route, that bid is highlighted in green.
Skill-Extending Problems
67. Allied Freight supplies goods to three customers, who
each require 30 units. The company has two ware-
houses. In warehouse 1, 40 units are available, and in
warehouse 2, 30 units are available. The costs of
1800
400
1300
900
600
950
800
600
1200
1000
600
1100
400
900
Cleveland
Phoenix
Los Angeles
Salt Lake City
Nashville
St. Louis
New York
Dallas
Figure 5.46
Network for Truck
Problem
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

5.7 Conclusion
285
shipping one unit from each warehouse to each cus-
tomer are shown in the file P05_67.xlsx. There is a
penalty for each unsatisfied customer unit of
demand—with customer 1, a penalty cost of $90 is
incurred; with customer 2, $80; and with customer 3,
$110.
a. Determine how to minimize the sum of penalty and
shipping costs.
b. Use SolverTable to see how a change in the unit
penalty cost of customer 3 affects the optimal cost.
c. Use SolverTable to see how a change in the capac-
ity of warehouse 2 affects the optimal cost.
68. Referring to the previous problem, suppose that Allied
Freight can purchase and ship extra units to either
warehouse for a total cost of $100 per unit and that all
customer demand must be met. Determine how to
minimize the sum of purchasing and shipping costs.
69. Based on Glover and Klingman (1977). The govern-
ment has many computer files that must be merged
frequently. For example, consider the Survey of
Current Income (SCI) and the Consumer Price Service
(CPS) files, which keep track of family income and
family size. The breakdown of records in each file is
given in the file P05_69.xlsx. SCI and CPS files contain
other pieces of data, but the only variables common to
the two files are income and family size. Suppose that
the SCI and CPS files must be merged to create a file
that will be used for an important analysis of govern-
ment policy. How should the files be merged? The
government would like to lose as little information as
possible in merging the records. For example, merging
an SCI record for a family with income $25,000 and
family size 2 with a CPS record for a family with
income $26,000 and family size 2 results in a smaller
loss of information than if an SCI record for a family
with income $25,000 and family size 2 is merged with
a CPS record for a family with income $29,000 and
family size 3. Let the “cost” of merging an SCI record
with a CPS record be ISCI  ICPS 	 FSSCI  FSCPS
where ISCI and ICPS are the incomes from the SCI and
CPS records, and FSSCI and FSCPS are the family
sizes. Determine the least expensive way to merge the
SCI and CPS records.
70. There are 15 jobs that must be done by 10 employees.
Each job must be done by a single employee, and each
employee can do at most two jobs. The times (in min-
utes) for the employees to do the jobs are listed in the
file P05_70.xlsx, where blanks indicate disallowed
assignments.
a. Assuming that not all employees have to be
assigned, find the assignments that minimize the
total time to complete all jobs.
b. How much longer does it take to complete all jobs
if every employee must be assigned to at least one
job? With this modified model, use SolverTable to
see how the total time to complete all jobs varies as
the maximum number of jobs per employee is
allowed to vary from 2 to 5 in increments of 1.
71. Bloomington has two hospitals. Hospital 1 has four
ambulances, and hospital 2 has two ambulances.
Ambulance service is deemed adequate if there is only
a 10% chance that no ambulance will be available
when an ambulance call is received by a hospital. The
average length of an ambulance service call is 20 min-
utes. Given this information, queueing theory indicates
that hospital 1 can be assigned up to 4.9 calls per hour
and that hospital 2 can be assigned up to 1.5 calls per
hour. Bloomington has been divided into 12 districts.
The average number of calls per hour emanating from
each district is given in the file P05_71.xlsx. This file
also shows the travel time (in minutes) needed to get
from each district to each hospital. The objective is to
minimize the average travel time needed to respond to
a call. Determine the proper assignment of districts to
hospitals. (Note: A given district’s calls do not all have
to be assigned to the same hospital.)
72. In Problem 55, assume that before being shipped to
Los Angeles or New York, all oil produced at the wells
must be refined at either Galveston or Mobile. To
refine 1000 barrels of oil costs $5780 at Mobile and
$6250 at Galveston. Assuming that both Mobile and
Galveston have infinite refinery capacity, determine
how to minimize the daily cost of transporting and
refining the oil requirements of Los Angeles and 
New York.
73. Rework the previous problem under the assumption
that Galveston has a refinery capacity of 150,000
barrels per day and Mobile has a refinery capacity of
180,000 barrels per day.
74. Ewing Oil has oil fields in San Diego and Los
Angeles. The San Diego field can produce up to
500,000 barrels per day, and the Los Angeles field can
produce up to 400,000 barrels per day. Oil is sent from
the fields to a refinery, either in Dallas or in Houston.
(Assume that each refinery has unlimited capacity.) To
refine 1000 barrels costs $5700 at Dallas and $6000 at
Houston. Refined oil is shipped to customers in
Chicago and New York. Chicago customers require
400,000 barrels per day, and New York customers
require 300,000 barrels per day. The costs of shipping
100,000 barrels of oil (refined or unrefined) between
cities are shown in the file P05_74.xlsx.
a. Determine how to minimize the total cost of meet-
ing all demands.
b. If each refinery had a capacity of 380,000 barrels
per day, how would you modify the model in
part a?
75. At present, 40,000 long-distance calls must be routed
from New York to Los Angeles (L.A.), and 30,000
calls must be routed from Philadelphia to L.A. On
route to L.A. from Philadelphia or New York, calls are
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

286
Chapter 5
Network Models
sent through Indianapolis or Cleveland, then through
Dallas or Denver, and finally to L.A. The number of
calls that can be routed between any pair of cities is
shown in the file P05_75.xlsx. The phone company
wants to know how many of the 70,000 calls originat-
ing in New York and Philadelphia can be routed to
L.A. Set this up as a network flow model—that is,
specify the nodes, arcs, shipping costs, and arc capaci-
ties. Then solve it.
76. Eight students need to be assigned to four dorm rooms
at Faber College. Based on incompatibility measure-
ments, the cost incurred for any pair of students room-
ing together is shown in the file P05_76.xlsx. How
should the students be assigned to the four rooms to
minimize the total amount of incompatibility?
77. Based on Ravindran (1971). A library must build
shelving to shelve 200 4-inch-high books, 600 8-inch-
high books, and 500 12-inch-high books. Each book is
0.5 inch thick. The library has several ways to store
the books. For example, an 8-inch-high shelf can be
built to store all books of height less than or equal to
8 inches, and a 12-inch-high shelf can be built for the
12-inch books. Alternatively, a 12-inch-high shelf can
be built to store all books. The library believes it costs
$2300 to build a shelf and that a cost of $5 per square
inch is incurred for book storage. (Assume that the
area required to store a book is given by the height of
the storage area multiplied by the book’s thickness.)
Determine how to shelve the books at minimum
cost. (Hint: We agree that this is not a very realistic
problem in terms of how a library operates, but it is a
good modeling challenge. Create nodes 0, 4, 8, and 12,
and make the cost associated with the arc joining
nodes i and j equal to the total cost of shelving all
books of height greater than i and less than or equal to
j on a single shelf.)
78. In the original RedBrand problem (Example 5.4),
suppose that the company could add up to 100 tons of
capacity, in increments of 10 tons, to any single plant.
Use SolverTable to determine the yearly savings in
cost from having extra capacity at the various plants.
Assume that the capacity will cost $28,000 per ton
right now. Also, assume that the annual cost savings
from having the extra capacity will extend over
10 years, and that the total 10-year savings will be
discounted at an annual 10% interest rate. How much
extra capacity should the company purchase, and
which plant should be expanded? (Hint: Use the PV
function to find the present value of the total cost sav-
ing over the 10-year period. You can assume that the
costs occur at the ends of the respective years.)
79. Based on Jacobs (1954). The Carter Caterer Company
must have the following number of clean napkins
available at the beginning of each of the next four
days: day 1, 1500; day 2, 1200; day 3, 1800; day 4, 600.
After being used, a napkin can be cleaned by one of
two methods: fast service or slow service. Fast service
costs 50 cents per napkin, and a napkin cleaned via
fast service is available for use the day after it is last
used. Slow service costs 30 cents per napkin, and these
napkins can be reused two days after they are last
used. New napkins can be purchased for a cost of 
95 cents per napkin. Determine how to minimize the
cost of meeting the demand for napkins during the
next four days. (Note: There are at least two possible
modeling approaches, one network and one nonnet-
work. See if you can model it each way.)
80. Kellwood, a company that produces a single product,
has three plants and four customers. The three plants
will produce 3000, 5000, and 5000 units, respectively,
during the next time period. Kellwood has made
a commitment to sell 4000 units to customer 1,
3000 units to customer 2, and at least 3000 units to
customer 3. Both customers 3 and 4 also want to buy
as many of the remaining units as possible. The profit
associated with shipping a unit from each plant to each
customer is given in the file P05_80.xlsx. Determine
how to maximize Kellwood’s profit.
81. You have put four valuable paintings up for sale. Four
customers are bidding for the paintings. Customer 1
is willing to buy two paintings, but each other cus-
tomer is willing to purchase at most one painting.
The prices that each customer is willing to pay are
given in the file P05_81.xlsx. Determine how to
maximize the total revenue you receive from the sale
of the paintings.
82. Powerhouse produces capacitors at three locations:
Los Angeles, Chicago, and New York. Capacitors are
shipped from these locations to public utilities in five
regions of the country: northeast (NE), northwest
(NW), midwest (MW), southeast (SE), and southwest
(SW). The cost of producing and shipping a capacitor
from each plant to each region of the country is given
in the file P05_82.xlsx. Each plant has an annual pro-
duction capacity of 100,000 capacitors. Each year,
each region of the country must receive the following
number of capacitors: NE, 55,000; NW, 50,000; MW,
60,000; SE, 60,000; SW, 45,000. Powerhouse believes
that shipping costs are too high, and it is therefore
considering building one or two more production
plants. Possible sites are Atlanta and Houston. The
costs of producing a capacitor and shipping it to each
region of the country are given in the same file. It
costs $3 million (in current dollars) to build a new
plant, and operating each plant incurs a fixed cost (in
addition to variable shipping and production costs) of
$50,000 per year. A plant at Atlanta or Houston will
have the capacity to produce 100,000 capacitors per
year. Assume that future demand patterns and produc-
tion costs will remain unchanged. If costs are dis-
counted at a rate of 12% per year, how can
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

5.7 Conclusion
287
Powerhouse minimize the net present value (NPV) of
all costs associated with meeting current and future
demands?
83. Based on Hansen and Wendell (1982). During the
month of July, Pittsburgh resident Bill Fly must make
four round-trip flights between Pittsburgh and
Chicago. The dates of the trips are shown in the file
P05_83.xlsx. Bill must purchase four round-trip tickets.
Without a discounted fare, a round-trip ticket between
Pittsburgh and Chicago costs $500. If Bill’s stay in a
city includes a weekend, he gets a 20% discount on
the round-trip fare. If his stay is more than 10 days, he
receives a 30% discount, and if his stay in a city is at
least 21 days, he receives a 35% discount. However,
at most one discount can be applied toward the
purchase of any ticket. Determine how to minimize the
total cost of purchasing the four round-trip tickets.
(Hint: It might be beneficial to pair one half of
one round-trip ticket number with half of another
round-trip ticket.)
84. Three professors must be assigned to teach six
sections of finance. Each professor must teach two
sections of finance, and each has ranked the six time
periods during which finance is taught, as shown in
the file P05_84.xlsx. A ranking of 10 means that the
professor wants to teach at that time, and a ranking of
1 means that he or she does not want to teach at that
time. Determine an assignment of professors to
sections that maximizes the total satisfaction of the
professors.
85. Based on Denardo et al. (1988). Three fires have just
broken out in New York. Fires 1 and 2 each require
two fire engines, and fire 3 requires three fire engines.
The “cost” of responding to each fire depends on the
time at which the fire engines arrive. Let tij be the time
in minutes when the engine j arrives at fire i (if it is
dispatched to that location). Then the cost of respond-
ing to each fire is as follows: fire 1, 6t11 	 4t12; fire 2,
7t21 	 3t22; fire 3, 9t31 	 8t32 	 5t33. There are three
fire companies that can respond to the three fires.
Company 1 has three engines available, and companies
2 and 3 each have two engines available. The time (in
minutes) it takes an engine to travel from each com-
pany to each fire is shown in the file P05_85.xlsx.
a. Determine how to minimize the cost associated
with assigning the fire engines. (Hint: A network
with seven destination nodes is necessary.)
b. Would the formulation in part a still be valid if the
cost of fire 1 were 4t11 	 6t12?
Modeling Problems
86. A company produces several products at several
different plants. The products are then shipped to two
warehouses for storage and are finally shipped to one
of many customers. How would you use a network
flow model to help the company reduce its production
and distribution costs? Pay particular attention to
discussing the data you would need to implement a
network flow model.
87. You want to start a campus business to match compati-
ble male and female students for dating. How would
you use the models in this chapter to help you run
your business?
88. You have been assigned to ensure that each high
school in the Indianapolis area is racially balanced.
Explain how you would use a network model to help
attain this goal.
89. In the crew-scheduling model in Example 5.7, there
are only two cities. Suppose there are more than two
cities. Is it possible to modify the network approach
appropriately? Discuss how you would do it.
90. “It is essential to constrain all shipments in a trans-
portation problem to have integer values to ensure that
the optimal LP solution consists entirely of integer-
valued shipments.” Is this statement true or false?
Why?
91. What is the relationship between transportation mod-
els and more general logistics models? Explain how
these two types of linear optimization models are simi-
lar and how they are different.
92. Unlike the small logistics models presented here, real-
world logistics problems can be huge. Imagine the
global problem a company like FedEx faces each day.
Describe as well as you can the types of decisions and
constraints it has. How large (number of changing
cells, number of constraints) might such a problem be?
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

288
Chapter 5
Network Models
I
nternational Textile Company, Ltd., is a Hong
Kong–based firm that distributes textiles world-
wide. The company is owned by the Lao family.
Should the People’s Republic of China continue its
economic renaissance, the company hopes to use its
current base to expand operations to the mainland.
International Textile has mills in the Bahamas, Hong
Kong, Korea, Nigeria, and Venezuela, each weaving
fabrics out of two or more raw fibers: cotton, poly-
ester, and/or silk.The mills service eight company dis-
tribution centers located near the customers’
geographical centers of activity.
Because transportation costs historically have
been less than 10% of total expenses, management
has paid little attention to extracting savings through
judicious routing of shipments. Ching Lao is returning
from the United States, where he has just completed
his bachelor’s degree in marketing. He believes that
each year he can save International Textile hundreds
C A S E
5.1 INTERNATIONAL TEXTILE COMPANY, LTD.10
of thousands of dollars—perhaps millions—just by
better routing of fabrics from mills to distribution
centers. One glaring example of poor routing is the
current assignment of fabric output to the Mexico
City distribution center from Nigeria instead of from
Venezuela, less than a third the distance. Similarly, the
Manila center now gets most of its textiles from
Nigeria and Venezuela, although the mills in Hong
Kong itself are much closer.
Of course, the cost of shipping a bolt of cloth
does not depend on distance alone.Table 5.14
provides the actual costs supplied to Lao from com-
pany headquarters. Distribution center demands are
seasonal, so a new shipment plan must be made each
month. Table 5.15 provides the fabric requirements
for the month of March. International Textile’s mills
have varying capacities for producing the various
types of cloth.Table 5.16 provides the quantities that
apply during March.
10This case was written by Lawrence L. Lapin, San Jose State University.
Table 5.14 Shipping Cost Data (Dollars Per Bolt)
Distribution Center
Mill
Los Angeles
Chicago
London
Mexico City
Manila
Rome
Tokyo
New York
Bahamas
2
2
3
3
7
4
7
1
Hong Kong
6
7
8
10
2
9
4
8
Korea
5
6
8
11
4
9
1
7
Nigeria
14
12
6
9
11
7
5
10
Venezuela
4
3
5
1
9
6
11
4
Table 5.15 Fabric Demands for March (Bolts)
Distribution Center
Fabric
Los Angeles
Chicago
London
Mexico City
Manila
Rome
Tokyo
New York
Cotton
500
800
900
900
800
100
200
700
Polyester
1,000
2,000
3,000
1,500
400
700
900
2,500
Silk
100
100
200
50
400
200
700
200
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Case 5.1 International Textile Company, Ltd.
289
Table 5.16 March Production Capacities
(Bolts)
Production Capacity
Mill
Cotton
Polyester
Silk
Bahamas
1,000
3,000
0
Hong Kong
2,000
2,500
1,000
Korea
1,000
3,500
500
Nigeria
2,000
0
0
Venezuela
1,000
2,000
0
Lao wants to schedule production and
shipments in such a way that the most costly
customers are shorted when there is insufficient
capacity, and the least-efficient plants operate at
less than full capacity when demand falls below
maximum production capacity.
You have been retained by International to
assist Lao.
Questions
1.
Find the optimal March shipment schedule and
its total transportation cost for each of the
following:
a. cotton
b. polyester
c. silk
2.
The company will be opening a silk-making
department in the Nigeria mill. Although it
will not be completed for several months, a
current capacity of 1,000 bolts for that fabric
might be used during March for an added one-
time cost of $2,000. Find the new optimal
shipment schedule and the total cost for that
fabric. Should the Nigeria mill process silk in
March?
3.
Lao learns that changes might have to be made
to the March plans. If a new customer is
obtained, the cotton demand in Manila and in
Mexico City will increase by 10% at each loca-
tion. Meanwhile, a big New York customer might
cut back, which would reduce polyester demand
by 10% in both New York and Chicago. Find the
contingent optimal schedules and total costs
(a) for cotton and (b) for polyester.
4.
InternationalTextile loses a profit of $10 for each
bolt of cotton it falls short of meeting the distribu-
tion center’s demand. For polyester,the loss is
$20 per bolt; for silk,it is a whopping $50 per
bolt. By running the mills on overtime,the com-
pany can produce additional bolts at the addi-
tional costs shown inTable 5.17. Using only the
original data from Tables 5.14 through 5.16 and
the information in Table 5.17,determine new pro-
duction schedules to maximize overall profit for
successively (a) cotton,(b) polyester, and (c) silk.
Which fabrics and locations involve overtime
production,and what are the overtime quantities?
5.
Without making any calculations, offer Lao other
suggestions for reducing costs of transportation.
Table 5.17 Overtime Production Costs
Cost per Bolt
Mill
Cotton
Polyester
Silk
Bahamas
$10
$10
N.A.
Hong Kong
15
12
$25
Korea
5
8
22
Nigeria
6
N.A.
N.A.
Venezuela
7
6
N.A.
■
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

290
Chapter 5
Network Models
A
typical paper mill might produce 1200 tons of
paper per day to fill orders from 250 customers.
Sending 100 truckload shipments per day would not
be unusual for a mill served by 20 motor carriers.
The carriers will generally accept shipments to any
destination that they serve, subject to daily volume
commitments and equipment availability. Each carrier
has a different and somewhat complex rate struc-
ture. Given a pool of orders that must be shipped on
a given day, the mill’s problem is to assign truckloads
to carriers to minimize its total shipping cost.
Westvaco Company Overview
Each year, Westvaco sells more than $2 billion worth
of manufactured paper, paperboard, and specialty
chemicals. Production occurs at five domestic paper
mills and four chemical plants. In addition, Westvaco
has many converting locations, which manufacture
liquid packaging, envelopes, folding cartons, and
corrugated boxes. Some of Westvaco’s products
include the following:
■
Fine papers, often used in printing applications
(magazines and annual reports)
■
Bleached paperboard, used in packaging (milk and
juice cartons, freezer to oven entrees, and so
forth)
■
Kraft paper, used for corrugated boxes and deco-
rative laminates (such as Formica)
■
Chemicals, including activated carbon printing ink
resins
Transportation Function
The corporate transportation function has a dual
role at Westvaco. It supports the operating locations
by negotiating freight rates and service commitments
with rail, truck, and ocean carriers. In addition, it
serves as an internal consulting group for reviewing
operations in the field and making recommendations
on streamlining tasks, making organizational changes
to support changing customer requirements, and
supporting the implementation of new technology.
C A S E
5.2 OPTIMIZED MOTOR CARRIER SELECTION AT WESTVACO
Local traffic departments are responsible for
day-to-day operations of mills and plants, including
carrier assignments, dispatching, and switching lists
for the railroads.
Production Overview
The production cycle is summarized in Figure 5.47.
Customer Service:
Orders received
Scheduling: Orders
scheduled to meet
delivery date
Manufacturing: Orders
produced on
papermaking machines
Delivery: Order
delivered to customer
Distribution: Loads
assigned to truck carriers,
rail, and ocean vessels
Load Planning:
Less-than-truckload
quantities consolidated
Figure 5.47
Production Cycle Overview
Orders The majority of paper orders are for rolls,
where customers request a specific grade and size
of paper (diameter and width), amount (pounds, or
linear or square feet), and delivery date. The orders
typically range in width from 8 to 70 inches. With
greater emphasis on just-in-time production by
Westvaco’s customers, delivery dates are sometimes
specified in half-hour time windows. Orders that
arrive before or after the time window are not
accepted.
Scheduling After orders are received, they are
scheduled on paper machines up to 200 inches wide.
The paper business is heavily capital intensive: new
machines can cost more than $400 million each.
Machines usually run 24 hours a day and scheduling
is done to minimize waste while meeting shipping
date requirements. After production of a “parent”
roll, the orders are cut on a rewinder into the exact
order size.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Case 5.2 Optimized Motor Carrier Selection at Westvaco
291
Load Planning Each morning, a load planner must
review the previous day’s production to divide large
orders and consolidate less-than-truckload (LTL)
orders into truckload quantities. Special attention is
necessary to ensure that delivery requirements are
met for orders that are consolidated. Orders typically
weigh between 1000 and 150,000 pounds. A truck
can generally pull a trailer with 46,000 to 48,000
pounds of paper. Depending on the construction of
the trailer, this is the maximum weight limit that can
be loaded while remaining under federal weight limits.
Some care must also be taken to remain within axle
weight limits. The goal of the load planner is to maxi-
mize the weight on a trailer while determining a
route that minimizes the total number of miles trav-
eled per day, with no truck making more than four
stops (three stops plus the final destination).
Distribution This case focuses on the distribution
problem shown in the bold box in Figure 5.47.After
loads are planned, they are turned over to a trans-
portation planner to assign carriers to loads.The
planner has a contract for each carrier that gives the
rates to each destination served (state or zip code
range). The rates include a mileage charge, a stop-off
charge, and a minimum charge per truckload. The
transportation planner also has a list of the trailers
available for each carrier. The planner will select a
carrier for a given shipment based on the knowledge
of the best carriers for a given traffic lane, subject to
availability. Some carriers have minimum daily volume
commitments that must be met.
After the carrier is selected for a given load, the
planner updates the information in the mill’s main-
frame computer and displays this information in the
shipping area. The selected carrier’s trailer is spotted
and brought to the loading dock and loading com-
mences. The shipment information is then phoned
or faxed to the carrier.
A Sample Distribution Pr
oblem
Table 5.18
contains a scaled-down version of a typical distribu-
tion problem faced by a transportation planner at
Westvaco’s paper mill in Wickliffe, Kentucky. The
load planner has determined that 32 truckloads are
needed to distribute last night’s production. In the
shipping area, 33 drivers from six carriers are waiting
for their trucks to be loaded. One truck will not be
needed today. The carrier PSST has four trucks in
the shipping area, and Westvaco has a contractual
obligation to use all four of these trucks today. (In
practice, it would not be unusual for a transportation
planner to assign 25 truckloads to 20 carriers in a
single day.)
The mileage numbers in Table 5.18 represent the
total number of miles for the trip from Wickliffe to
the final destination, including any intermediate 
stops.The total charge is calculated as follows.
Suppose that the Roseville, Minnesota, trip is assigned
to carrier IRST. The cost to Westvaco would be
600(1.13) 	 3(75)  $903. (If the cost calculated this
way were less than IRST’s minimum truckload charge
of $400, the cost to Westvaco would be $400.) Stop-
off charges apply only to intermediate stops and not
the final destination. Four truckloads are needed to
go to Atlanta, Georgia.These truckloads can be
assigned to a single carrier, or they can be split among
several carriers. If carrier MRST is assigned one of
these truckloads, the cost is 612(0.87)  $532.
Question
For the distribution data shown in Table 5.18, what is
the least-cost assignment of truckloads to carriers
that meets the necessary requirements? What is the
cost of this distribution plan?
Epilogue
Carrier selection at Westvaco was done
manually (with pencil and paper!) by transportation
planners in the past. A side-by-side test of a spread-
sheet LP solution versus manual selection indicated
daily savings in the range of 3% to 6%, and so the
project was approved. With annual trucking costs of
about $15 million, the total savings with the new
approach have been significant. In addition to this
benefit, there have been a number of serendipitous
side effects. The optimization technique removes
the guesswork from carrier selection, especially
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

292
Chapter 5
Network Models
Table 5.18 Current Distribution Data for Westvaco Case Study
Carrier
Destination
State
Trips
Stops
Miles
ABCT
IRST
LAST
MRST
NEST
PSST
Atlanta
GA
4
0
612
*
0.88
1.15
0.87
0.95
1.05
Everett
MA
1
3
612
*
1.18
1.27
1.39
1.35
1.28
Ephrata
PA
3
0
190
*
3.42
1.73
1.71
1.82
2.00
Riverview
MI
5
0
383
0.79
1.01
1.25
0.96
0.95
1.11
Carson
CA
1
2
3063
*
0.80
0.87
*
1.00
*
Chamblee
GA
1
0
429
*
1.23
1.61
1.22
1.33
1.47
Roseville
MN
1
3
600
1.24
1.13
1.89
1.32
1.41
1.41
Hanover
PA
1
0
136
*
4.78
2.23
2.39
2.26
2.57
Sparks
NV
2
0
2439
*
1.45
*
1.20
*
*
Parsippany
NJ
1
1
355
*
1.62
1.36
1.39
1.03
1.76
Effingham
IL
5
0
570
0.87
0.87
1.25
0.87
0.90
1.31
Kearny
NJ
7
0
324
*
2.01
1.54
1.53
1.28
1.95
Minimum charge per truckload
350
400
350
300
350
300
Stop-off charge
50
75
50
35
50
50
Available pulls
4
8
7
7
3
4
Commitment
1
7
6
0
0
4
Note: Asterisks (*) indicate carrier does not travel to the destination; rates in dollars/mile.
on weekends, where revolving coverage added
significant variability to the carrier selection process.
The technique adds accountability to the transporta-
tion planner’s position and, tied to a reason code for
changing the carrier, offers a clear answer to manage-
ment questions regarding carrier selection. Finally,
the time savings have also been significant. The carrier
assignment portion of the transportation planner’s job
can be done much faster than before.11
■
11This case was co-authored with Dave Rimple, who identified and
implemented this project at Westvaco.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

293
Optimization Models 
with Integer Variables 
C H A P T E R  
U.S.AIR FORCE SP  ACE COMMAND’S LONG-TERM
INVESTMENT IN S     P                                       A
     CE SYSTEMS
T
he U.S. Air Force created Space Command in 1982 to enhance defense
in the United States through space superiority and to protect the coun-
try from weapons of mass destruction. Space Command spends billions of
dollars each year procuring and deploying launch vehicles and space systems
required for mission area tasks. Space Command included a space and mis-
sile optimization analysis (SAMOA) group to determine the best use of funds
to satisfy requirements over a 24-year time horizon. Brown et al. (2003)
describe their role within SAMOA to develop a strategic plan that was pre-
sented to Congress in 1999 as part of the military’s overall strategic plan.
The authors of the plan developed an integer programming model, similar to
the capital budgeting model in this chapter but much larger in scale, to
determine the best set of space projects to undertake over the planning
horizon. This plan tries to achieve the various missions of Space Command
as fully as possible while staying within budget. Like everything in the military,
the model has an acronym, SCOUT (space command optimizer of utility
toolkit).
The overall planning process within SAMOA is extremely complex. The
process consists of five steps: (1) mission area assessment, (2) mission needs
analysis, (3) mission solution analysis, (4) portfolio selection, and (5) refined
portfolio selection. The first three steps are essentially steps 1 and 2 of the
seven-step modeling process described in Chapter 1. They define the tasks
that Space Command needs to accomplish to achieve its missions, the
6
© JOSHUA GATES WEISBERG/EPA/Landov
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

current and future needs—over and above what already exists—to accomplish these
tasks, and the required data on candidate systems being considered. This data includes
(1) scores for how each system, or combination of systems, accomplishes various tasks;
(2) possible starting and ending times for the system (where the possible starting times
can be several years in the future, due to the time required for R&D); (3) expected sys-
tem costs, including development and operating costs over a multiyear period; (4) vari-
ous precedence relations and side constraints (for example, system B can’t be selected
unless project A is selected); (5) launch requirements and per-launch costs; and (6) bud-
getary restrictions.
The last two steps build the integer programming model and then refine it, based on
nonquantitative considerations such as political pressures. The model itself has a large
number of integer decision variables. There is a binary variable for each combination of
system and starting and ending years. For example, if a given system can be started any
year from 2005 until 2010 and then end 12 years later, there will be six binary variables,
one for each potential starting year. There are also integer variables for the number of
launches by each selected system each year. The constraints are mostly of the “logical”
type. For example, they enforce all precedence relations and side constraints, and they
allow a given system to be selected for only one start-end time combination. The
authors use a “penalty” type of objective.That is, the objective is total discounted penalty
dollars, with penalties for not completely achieving task performance and for violating
budget constraints. This allows solutions to violate constraints slightly (they can be
slightly over budget, say), which provides more flexibility. The discounting is done in the
usual financial sense, to make violations in the distant future less important.
The strategic master plan, the result of the SCOUT model and its refinements, was
submitted to Congress in 1999. The plan included planned investments totaling about
$310 billion. As the authors state, “This planning effort is the best-staffed and most
scrupulously managed example of optimization-based capital planning that we have ever
seen.” Since 1999, Space Command and several other military units have used SAMOA
to help create their strategic master plans. We recommend both this article and a some-
what more general article about military capital planning by Brown et al. (2004). They
are both excellent examples of how integer programming can be used to make impor-
tant and costly capital budgeting decisions. They also indicate the differences between
capital budgeting in the military versus capital budgeting in civilian organizations. ■
294
Chapter 6
Optimization Models with Integer Variables
6.1 INTRODUCTION
In this chapter, we show how many complex problems can be modeled using 0–1 variables
and other variables that are constrained to have integer values. A 0–1 variable is a decision
variable that must equal 0 or 1. Usually a 0–1 variable corresponds to an activity that either
is or is not undertaken. If the 0–1 variable corresponding to the activity equals 1, the activity
is undertaken; if it equals 0, the activity is not undertaken. A 0–1 variable is also called a
binary variable.
Optimization models in which some or all of the variables must be integers are known
as integer programming (IP) models.1 In this chapter, we illustrate many of the modeling
techniques that are needed to formulate IP models of complex situations. You should be
aware that any optimization software, including Excel’s Solver, typically has a much
1Many problems in the literature are described as mixed integer linear programming (MILP) models, which indi-
cates that some of the changing cells are constrained to be integers and others are not. Although we do use this
acronym, some of our models are of this type.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

harder time solving an IP problem than an LP problem. In fact, optimization software is
sometimes unable to solve an IP problem, even if the IP problem has an optimal solution.
The reason is that these problems are inherently difficult to solve, no matter what software
package is used. However, as you will see in this chapter, your ability to model complex
problems increases tremendously when you use binary variables.
IP models come in many forms. You saw examples in Chapter 4 where the decision
variables are naturally integer-valued. For example, when scheduling postal workers
(Example 4.2), it is natural to require the numbers of workers to be integers. In examples
like this, where you do not want certain decision variables to have fractional values, the
problems are basically LP models with integer constraints added at the last minute. In
many such examples, if you ignore the integer constraints, optimize with Solver, and then
round to the nearest integers, the resulting integer solution will probably be close to
optimal—although admittedly the rounded solution is sometimes not optimal.
The “integer” models in Chapter 4 are not the types of IP models discussed in this
chapter. If it were simply a matter of adding integer constraints to decision variables, such
as the numbers of workers, this chapter wouldn’t be necessary. However, many inherently
nonlinear problems can be transformed into linear models with the use of binary variables.
These are the types of models discussed here. The clever use of binary variables allows
you to solve many interesting and difficult problems that LP algorithms are incapable of
solving.
All the models we analyze in this chapter are, aside from binary or integer changing
cells, linear models. As in previous chapters, this means that the target cell is ultimately a
sum of products of constants and changing cells. The same goes for both sides of all con-
straints. In other words, the models in this chapter look much like the models in the previ-
ous three chapters. The only difference is that some of the changing cells are now
constrained to be binary or integer. Although the basic algorithm that Solver uses for such
models is fundamentally different—because of the binary or integer variables—it still
helps that the models are linear. They would present even more of a challenge to Solver if
they were nonlinear.
6.2 OVERVIEW OF OPTIMIZATION WITH INTEGER VARIABLES
When Excel’s Solver solves a linear model without integer constraints, it uses a very effi-
cient algorithm, the simplex method, to perform the optimization. As discussed in
Chapter 3, this method examines the “corner” points of the feasible region and returns the
best corner point as the optimal solution. The simplex method is efficient because it typi-
cally examines only a very small fraction of the hundreds, thousands, or even millions of
possible corner points before determining the best corner point.
The main difference between LP and IP models is that LP models allow fractional val-
ues, such as 0.137 and 5.3246, in the changing cells, whereas IP models allow only integer
values in integer-constrained changing cells. In fact, if changing cells are constrained to be
binary, the only allowable values are 0 and 1. This suggests that IP models should be easier
to solve. After all, there are many fewer integer values in a given region than there are con-
tinuous values, so searching through the integers should be quicker—especially if their
only possible values are 0 and 1. However, IP models are actually much more difficult to
solve than LP models. Although several solution methods have been suggested by
researchers—and new methods for specialized problems are still being developed—the
solution procedure used by Solver is called branch and bound. Although we do not go
into the details of the algorithms, we discuss briefly what Solver is doing. This way you
can appreciate some of the difficulties with IP models, and you might also understand
some of the messages you see in the status bar as Solver performs its optimization.
6.2 Overview of Optimization with Integer Variables
295
Except for binary or
integer constraints on
some changing cells, all
models in this chapter
are linear.
The branch and bound
algorithm is a general
approach to searching
through all of the pos-
sibly millions of solu-
tions in an efficient
manner.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Branch and Bound Algorithm
Consider a model with 100 changing cells, all constrained to be binary. Because there are
only two values for each binary variable—0 and 1—there are potentially 2100 feasible solu-
tions, although many of these might not satisfy all of the constraints. Unfortunately, 2100 is
an extremely large number, so it would take even a very fast computer a long time to check
each one of them. Therefore, the naive method of complete enumeration of all possible
solutions—look at each solution and select the best—is usually impractical. However,
implicit enumeration is often very practical. This approach examines only a fraction of
all 2100 potential solutions, hopefully a very small fraction, and in doing so, it guarantees
that solutions not examined have no chance of being optimal. To see how this works, sup-
pose you find a feasible solution with a profit of $500. If you can somehow guarantee that
each solution in a particular subset of solutions has profit less than $500, you can ignore
this entire subset because it cannot possibly contain the profit-maximizing solution.
This general idea is the essence of the branch and bound method used by Solver in IP
models. The branching part means that the algorithm systematically searches through the
set of all feasible integer solutions, creating branches, or subsets, of solutions as it goes.
For example, if x1 is a binary variable, one branch might have x1  0 and another branch
might have x1  1. Then if x2 is another binary variable, two branches might be created off
the x1  0 branch—one with x2  0 and one with x2  1. By forming enough branches, all
possible integer solutions are eventually examined.
The key, however, is the bounding part of the algorithm. Suppose, for the sake of argu-
ment, that the objective is to maximize profit. Also, suppose that partway through the solu-
tion procedure, the best feasible integer solution so far has a profit of $500. This is called
the incumbent solution—the best so far. Its profit represents a lower bound on the optimal
profit. That is, the optimal solution must have a profit of at least $500 because a feasible
solution with a profit of $500 has already been found. This is the easy part of the bounding
procedure. The best profit found so far is a lower bound on the optimal profit.
The hard part is finding suitable upper bounds. Suppose you are considering the
branch where x1  0 and x2  1. If you can somehow show that any solution that has x1  0
and x2  1 can have profit at most $490 (or any number less than the incumbent, $500),
then you can ignore this entire branch. Therefore, the goal is to find an upper bound for
each branch that (1) is easy to find in terms of computing time and (2) is as low as possi-
ble. Why should it be as low an upper bound as possible? Suppose the upper bound you
find for the x1  0 and x2  1 branch is instead $515. Then because the incumbent’s profit
is only $500, this branch might have some potential. That is, it might contain a solution
with profit greater than the incumbent. Therefore, you have to pursue it, which costs computer
296
Chapter 6
Optimization Models with Integer Variables
FUNDAMENTAL INSIGHT
Difficulty of Integ
er Programming 
Models
You might suspect that IP models are easier to solve
than LP models. After all, there are only a finite num-
ber of feasible integer solutions in an IP model,
whereas there are infinitely many feasible (integer and
noninteger) solutions in an LP model. However,
exactly the opposite is true. As stated previously, IP
models are much more difficult to solve than LP models.
All IP algorithms try to perform an efficient search
through the typically huge number of feasible integer
solutions.General-purpose algorithms such as branch
and bound can be very effective for modest-size prob-
lems, but they can fail (or take very long computing
times) on the large problems often faced in real appli-
cations. In such cases, analysts must develop special-
purpose optimization algorithms, or perhaps even
heuristics, to find good but not necessarily optimal
solutions.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

time. The lower the upper bounds you can produce, the quicker you can “prune” branches
and the faster the algorithm will be.
The procedures used to find good upper bounds for branches are beyond the level of
this book. Fortunately, Solver takes care of the details. However, you should now under-
stand some of the messages you will see in the status bar when you run Solver on IP mod-
els. For example, try running Solver on the cutting stock model in Example 6.7 with a
tolerance of 0% (see below). You will see plenty of these messages, where the incumbent
objective value and the current subproblem (or branch) quickly flash by. For this particular
cutting stock model, Solver quickly finds an incumbent solution that is optimal, but it must
examine literally thousands of branches before it can guarantee that the incumbent is opti-
mal. After a minute or two of computing, we had seen results for 10,000 branches, and there
was no end in sight.
The Solver Tolerance Setting
The Solver Options dialog box contains a Tolerance setting, which is relevant for integer-
constrained models. Excel’s default tolerance is 5%. In Excel 2010, this setting, listed as
Integer Optimality (%), is found under Solver Options in the dialog box shown in
Figure 6.1. (In earlier versions, it was also under Solver Options but in a slightly differ-
ent dialog box.) To explain the Tolerance option, we must first define the LP relaxation
of an IP model. This is the same model as the IP model, except that all integer constraints
are omitted. In particular, cells that are originally constrained to be binary are allowed
under the LP relaxation to have any fractional values between 0 and 1 (including 0 and 1).
The LP relaxation is typically easy to solve (using the simplex method), and it provides a
bound for the IP model. For example, consider a maximization problem where the optimal
solution to the LP relaxation has an optimal objective value of $48,214. Then the optimal
objective for the original integer-constrained problem can be no larger than $48,214, so
this value represents an upper bound for the original problem.
6.2 Overview of Optimization with Integer Variables
297
Figure 6.1
Solver Tolerance
Setting
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

A tolerance setting of 5% means that Solver stops as soon as it finds a feasible (inte-
ger) solution to the IP model that is within 5% of the current upper bound. Initially, the
optimal objective value of the LP relaxation serves as the upper bound. As Solver proceeds
to find solutions that satisfy the integer constraints, it keeps updating the upper bound. The
exact details need not concern you. The important point is that when Solver stops, it guar-
antees an integer solution that is within at least 5% of the optimal integer solution.
The implication is that if you set the tolerance to 0%, Solver will (in theory) run until
it finds the optimal integer solution. So why isn’t a tolerance setting of 0% always used?
The reason is that for many IP models, especially large models, it can take Solver a long
time to find the optimal solution (or guarantee that the best solution found so far is opti-
mal). On the other hand, a solution that is close to optimal—within 5%, say—can often
be found quickly. This explains why Frontline Systems, the developer of Solver, chose the
default tolerance setting of 5%.
We use a tolerance of 0% for all the models in this chapter, simply to guarantee an
optimal solution. Therefore, if you use the default tolerance of 5%, you might get a solu-
tion that is slightly worse than ours.
298
Chapter 6
Optimization Models with Integer Variables
To guarantee an opti-
mal integer solution,
change the Solver tol-
erance setting to 0%.
The disadvantage of
this approach is that
Solver can run consid-
erably longer on large
models.
FUNDAMENTAL INSIGHT
Recognizing the Optimal 
Integer Solution
IP algorithms such as brand and bound often find a
very good integer solution v ery quickly. So why do
they sometimes run so long?This is due to the implicit
enumeration aspect of the algorithms. They have diffi-
culty ruling out large n umbers of potential solutions
until they have searched all r egions of the solution
space. In other words, they have difficulty recognizing
that the y might ha ve f ound the optimal solution
because ther e ar e man y potential solutions the
y
haven’t yet explored.When you run Solver on a rea-
sonably large IP model, watch the status bar. Often a
very g ood incumbent solution,
the best solution
found so far, is found within seconds, but then Solver
spins its wheels f or minutes or even hours trying to
verify that this solution is optimal.
Solver Messages
Until now, the only Solver message you have probably seen is the final one that says an
optimal solution has been found. When you run Solver on some of the difficult problems in
this chapter, however, you might see a few other messages, such as those in Figures 6.2 and
6.3. These are due to Solver running a long time and bumping into the limits in the Options
dialog box in Figure 6.1. If you see one of these types of messages, you have two options.
First, you can change the options in Figure 6.1. (You would have to make this change
before the Solver run.) For example, you could increase the Max Subproblems setting to a
number greater than 5000. Second, you can simply click on Continue to let Solver run
Figure 6.2
Max Subproblems
Warning
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

longer. We recommend the second option. Actually, if you are tired of waiting and believe
the incumbent solution is good enough, you can also click on Stop, in which case Solver
gives you the option of saving the best solution so far.
6.3 CAPITAL BUDGETING MODELS
Perhaps the simplest binary IP model is the following capital budgeting example, which
illustrates the go/no-go nature of many IP models.
6.3 Capital Budgeting Models
299
Figure 6.3
Time Limit Warning
E X A M P L E
6.1 SELECTING INVESTMENTS AT TATHAM
T
he Tatham Company is considering seven investments. The cash required for each
investment and the net present value (NPV) each investment adds to the firm are listed
in Table 6.1. The cash available for investment is $15,000. Tatham wants to find the invest-
ment policy that maximizes its NPV. The crucial assumption here is that if Tatham wants
to take part in any of these investments, it must go all the way. It cannot, for example, go
halfway in investment 1 by investing $2500 and realizing an NPV of $8000. In fact, if par-
tial investments were allowed, you wouldn’t need IP; you could use LP.
Table 6.1
Data for the Capital Budgeting Example
Investment
Cash Required
NPV
1
$5,000
$16,000
2
$2,500
$8,000
3
$3,500
$10,000
4
$6,000
$19,500
5
$7,000
$22,000
6
$4,500
$12,000
7
$3,000
$7,500
Objective
To use binary IP to find the set of investments that stays within budget and
maximizes total NPV.
WHERE DO THE NUMBERS COME FROM?
The initial required cash and the available budget are easy to obtain. Obtaining the NPV
for each investment is undoubtedly harder. A time sequence of anticipated cash inflows
from the investments and a discount factor are required. Simulation might even be used  to
estimate these NPVs. In any case, financial analysts must provide the estimations of the
required NPVs.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Solution
The variables and constraints required for this model are listed in Table 6.2. The most
important part is that the decision variables must be binary, where a 1 means that an invest-
ment is chosen and a 0 means that it isn’t. These variables cannot have fractional values
such as 0.5, because partial investments are not allowed—the company has to go all the
way or not at all. Note that the binary restriction is shown in the second row of the table,
not the last row. This is done throughout the chapter. However, when you set up the Solver
dialog box, you must add explicit binary constraints in the Constraints section.
300
Chapter 6
Optimization Models with Integer Variables
Table 6.2
Variables and Constraints for the Capital Budgeting Model
Input variables
Initial cash required for investments, NPVs from 
investments, budget 
Decision variables (changing cells)
Whether to invest (binary variables) 
Objective (target cell)
Total NPV
Other calculated variables
Total initial cash required 
Constraints
Total initial cash required  Budget
DEVELOPING THE SPREADSHEET MODEL
To form the spreadsheet model, which is shown in Figure 6.4, proceed as follows. (See the
file Capital Budgeting 1.xlsx.)
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
M
L
K
J
I
H
G
F
E
D
C
B
A
Tatham capital budgeng model
Range names used:
Amount_invested
=Model!$B$14
Input data on potenal investments
Budget
=Model!$D$14
0
1
$
H
$:0
1
$
B
$
!le
d
o
M
=
sle
v
el_
t
n
e
m
ts
e
v
nI
7
6
5
4
3
2
1
t
n
e
m
ts
e
v
nI
Investment 
7
1
$
B
$
!le
d
o
M
=
V
P
N
_la
t
o
T
0
0
0,3
$
0
0
5,4
$
0
0
0,7
$
0
0
0,6
$
0
0
5,3
$
0
0
5,2
$
0
0
0,5
$
ts
o
c
0
0
5,7
$
0
0
0,2
1
$
0
0
0,2
2
$
0
0
5,9
1
$
0
0
0,0
1
$
0
0
0,8
$
0
0
0,6
1
$
V
P
N
NPV per investment dollar
3.20
3.20
2.86
3.25
3.14
2.67
2.50
Decisions: whether to invest
Investment 
0
0
1
0
0
1
1
sle
v
el
Budget constraint
Amount invested
Budget
$14,500
<=
$15,000
Objecve to maximize
Total 
0
0
0,6
4
$
V
P
N
Figure 6.4
Capital Budgeting Model
1
Inputs. Enter the initial cash requirements, the NPVs, and the budget in the shaded ranges.
2
0–1 values for investments. Enter any trial 0–1 values for the investments in the
Investment_levels range. Actually, you can even enter fractional values such as 0.5 in these
cells. Solver’s binary constraints will eventually force them to be 0 or 1.
3
Cash invested. Calculate the total cash invested in cell B14 with the formula
=SUMPRODUCT(B5:H5,Investment_levels)
Note that this formula sums the costs only for those investments with 0–1 variables equal
to 1. To see this, think how the SUMPRODUCT function works when one of its ranges is
a 0–1 range. It effectively sums the cells in the other range corresponding to the 1s.
4
NPV contribution. Calculate the NPV contributed by the investments in cell B17
with the formula
=SUMPRODUCT(B6:H6,Investment_levels)
Again, this sums only the NPVs of the investments with 0–1 variables equal to 1.
A SUMPRODUCT for-
mula, where one of the
ranges is a 0–1 range,
just sums the values in
the other range that
correspond to the Is.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

USING SOLVER
The Solver dialog box appears in Figure 6.5. The objective is to maximize the total NPV, sub-
ject to staying within the budget. However, the changing cells must be constrained to be 0–1.
Fortunately, Solver makes this simple, as shown in Figure 6.6. You add a constraint with
Investments_levels in the left box and choose the bin option in the middle box. The word
“binary” in the right box is then added automatically. Note that if all changing cells are binary,
you do not need to check the Non-Negative option (because 0 and 1 are certainly nonnega-
tive), but you should still choose the Simplex LP method if the model is linear, as it is here.2
6.3 Capital Budgeting Models
301
Solver makes it easy
to specify binary con-
straints, by clicking on
the bin option.
Figure 6.5
Solver Dialog Box
for the Capital
Budgeting Model
Figure 6.6
Specifying a Binary
Constraint
2 All the models in this chapter satisfy two of the three properties of linear models in Chapter 3: proportionality and
additivity. Even though they clearly violate the third assumption, divisibility, which precludes integer constraints,
they are still considered linear by Solver. Therefore, you should still choose the Simplex LP method.
Discussion of the Solution
The optimal solution in Figure 6.4 indicates that Tatham can obtain a maximum NPV of
$46,000 by selecting investments 1, 2, and 5. These three investments consume only $14,500
of the available budget, with $500 left over. However, this $500 is not enough—because of
the “investing all the way” requirement—to invest in any of the remaining investments.
If Tatham’s investments are ranked on the basis of NPV per dollar invested (see row 7
of Figure 6.4), the ranking from best to worst is 4, 1, 2, 5, 3, 6, 7. Using your economic
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

intuition, you might expect the investments to be chosen in this order—until the budget
runs out. However, the optimal solution does not do this. It selects the second-, third-, and
fourth-best investments, but it ignores the best. To understand why it does this, imagine
investing in the order from best to worst, according to row 7, until the budget allows no
more. By the time you have invested in investments 4, 1, and 2, you will have consumed
$13,500 of the budget, and the remainder, $1500, is not sufficient to invest in any of the
rest. This strategy provides an NPV of only $43,500. A smarter strategy, the optimal solu-
tion from Solver, gains you an extra $2500 in NPV.
Sensitivity Analysis
SolverTable can be used on models with binary variables exactly as you have used it in pre-
vious models.3 Here you can use it to see how the total NPV varies as the budget increases.
Select the Budget cell as the single input cell, allow it to vary from $15,000 to $25,000 in
increments of $1000, and keep track of the total NPV, the amount of the budget used, and
the binary variables. The results are given in Figure 6.7. Clearly, Tatham can achieve a
larger NPV with a larger budget, but as the numbers and the chart show, each extra $1000
of budget does not have the same effect on total NPV. The first $1000 increase to the bud-
get adds $3500 to total NPV, the next two $1000 increases add $4000 each, the next two
302
Chapter 6
Optimization Models with Integer Variables
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
A
B
C
D
E
F
G
H
I
J
Oneway analysis for Solver model in Model worksheet
Budget (cell $D$14) values along side, output cell(s) along top
Investment_levels_1
Investment_levels_2
Investment_levels_3
Investment_levels_4
Investment_levels_5
Investment_levels_6
Investment_levels_7
Amount_invested
Total_NPV
$15,000
1
1
0
0
1
0
0
$14,500
$46,000
$16,000
0
1
0
1
1
0
0
$15,500
$49,500
$17,000
1
1
1
1
0
0
0
$17,000
$53,500
$18,000
1
0
0
1
1
0
0
$18,000
$57,500
$19,000
0
1
1
1
1
0
0
$19,000
$59,500
$20,000
0
1
0
1
1
1
0
$20,000
$61,500
$21,000
1
1
0
1
1
0
0
$20,500
$65,500
$22,000
1
0
1
1
1
0
0
$21,500
$67,500
$23,000
1
0
0
1
1
1
0
$22,500
$69,500
$24,000
1
1
1
1
1
0
0
$24,000
$75,500
$25,000
1
1
0
1
1
1
0
$25,000
$77,500
0
10000
20000
30000
40000
50000
60000
70000
80000
90000
Budget ($D$14)
Sensivity of Total_NPV to Budget
Figure 6.7
Sensitivity to Budget
3As mentioned in Chapter 4, Solver’s sensitivity report is not even available for models with integer constraints because
the mathematical theory behind the report changes significantly when variables are constrained to be integers.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

$1000 increases add $2000 each, and so on. Note also how the selected investments vary a
lot as the budget increases. This somewhat strange behavior is due to the “lumpiness” of
the inputs and the all-or-nothing nature of the problem.
Effect of Solver Tolerance Setting
To illustrate the effect of the Solver Tolerance setting, compare the SolverTable results in
Figure 6.8 with those in Figure 6.7. Each is for the Tatham capital budgeting model, but
Figure 6.8 uses Solver’s default tolerance of 5%, whereas Figure 6.7 uses a tolerance of
0%. The three shaded cells in Figure 6.8 indicate lower total NPVs than the corresponding
cells in Figure 6.7. In these three cases, Solver stopped short of finding the true optimal
solutions because it found solutions within the 5% tolerance and then quit. (You might get
slightly different results. It depends on the starting solution in your model.)
6.3 Capital Budgeting Models
303
When the Tolerance
setting is 5% instead 
of 0%, Solver’s solution
might not be optimal,
but it will be close.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
A
B
C
D
E
F
G
H
I
J
Oneway analysis for Solver model in Model worksheet
Budget (cell $D$14) values along side, output cell(s) along top
Investment_levels_1
Investment_levels_2
Investment_levels_3
Investment_levels_4
Investment_levels_5
Investment_levels_6
Investment_levels_7
Amount_invested
Total_NPV
$15,000
1
1
0
0
1
0
0
$14,500
$46,000
$16,000
0
1
0
1
1
0
0
$15,500
$49,500
$17,000
1
1
1
1
0
0
0
$17,000
$53,500
$18,000
1
0
0
1
1
0
0
$18,000
$57,500
$19,000
0
1
1
1
1
0
0
$19,000
$59,500
$20,000
1
0
1
0
1
1
0
$20,000
$60,000
$21,000
1
1
0
1
1
0
0
$20,500
$65,500
$22,000
1
1
0
1
1
0
0
$20,500
$65,500
$23,000
0
1
0
1
1
1
1
$23,000
$69,000
$24,000
1
1
1
1
1
0
0
$24,000
$75,500
$25,000
1
1
0
1
1
1
0
$25,000
$77,500
This is with Solver's tolerance at 5%. The 
three gray cells are larger than on the 
previous sheet, which indicates that they 
are not opmal.
Figure 6.8
Results with
Tolerance at 5%
■
1.
The following modifications of the capital budgeting example can be handled easily.
You are asked to explore similar modifications in the problems.
■
Suppose that at most two projects can be selected. In this case, you should add a
constraint that the sum of the 0–1 variables for the investments is less than or
equal to 2. This constraint is satisfied if zero, one, or two investments are chosen,
but it is violated if three or more investments are chosen.
■
Suppose that if investment 2 is selected, then investment 1 must also be selected.
In this case, you should add a constraint saying that the 0–1 variable for invest-
ment 1 is greater than or equal to the 0–1 variable for investment 2. This con-
straint rules out the one possibility that is not allowed—where investment 2 is
selected but investment 1 is not.
■
Suppose that either investment 1 or investment 3 (or both) must be selected. In this
case, you should add a constraint that the sum of the 0–1 variables for investments
MODELING ISSUES
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

1 and 3 must be greater than or equal to 1. This rules out the one possibility that
is not allowed—where both of these 0–1 variables are 0, so that neither invest-
ment is selected.
2.
Capital budgeting models with multiple periods can also be handled. Figure 6.9
shows one possibility. (See the Capital Budgeting 2.xlsx file.) The costs in rows 5
and 6 are both incurred if any given investment is selected. Now there are two budget
constraints, one in each year, but otherwise the model is exactly as before. Note that
some investments can have a cost of 0 in year 1 and a positive cost in year 2. This
effectively means that these investments are undertaken in year 2 rather than year 1.
Also, it is easy to modify the model to incorporate costs in years 3, 4, and so on.
304
Chapter 6
Optimization Models with Integer Variables
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
A
B
C
D
E
F
G
H
I
J
K
L
Tatham two-period capital budgeng model
Range names used:
Amount_invested
=Model!$B$14:$B$15
Input data on potenal investments
Budget
=Model!$D$14:$D$15
B
$
!le
d
o
M
=
sle
v
el_
t
n
e
m
ts
e
v
nI
7
6
5
4
3
2
1
t
n
e
m
ts
e
v
nI
$10:$H$10
Year 1 
8
1
$
B
$
!le
d
o
M
=
V
P
N
_la
t
o
T
0
0
0,3
$
0
0
5,4
$
0
0
0,7
$
0
0
5,6
$
0
0
5,3
$
0
0
5,2
$
0
0
0,5
$
ts
o
c
Year 2 
0
$
0
0
5,1
$
0
0
5
$
0
$
0
0
0,2
$
0
0
5,1
$
0
0
0,2
$
ts
o
c
0
0
0,8
$
0
0
0,2
1
$
0
0
0,2
2
$
0
0
0,0
2
$
0
0
0,0
1
$
0
0
0,8
$
0
0
0,6
1
$
V
P
N
Decisions: whether to invest
Investment 
0
0
0
1
0
1
1
sle
v
el
Budget constraints
Amount invested
Budget
$14,000
<=
$14,000
$3,500
<=
$4,500
Objecve to maximize
Total 
0
0
0,4
4
$
V
P
N
Figure 6.9
A Two-Period Capital Budgeting Model
3.
If Tatham could choose a fractional amount of an investment, you could maximize its
NPV by deleting the binary constraint. The optimal solution to the resulting LP model
has a total NPV of $48,714. All of investments 1, 2, and 4, and 0.214 of investment 5 are
chosen.4 Note that there is no way to round the changing cell values from this LP solu-
tion to obtain the optimal IP solution. Sometimes the solution to an IP model without
the integer constraints bears little resemblance to the optimal IP solution.
4.
Any IP model involving 0–1 variables with only one constraint is called a knapsack
problem. Think of the problem faced by a hiker going on an overnight hike. For exam-
ple, imagine that the hiker’s knapsack can hold only 14 pounds, and she must choose
which of several available items to take on the hike. The benefit derived from each item
is analogous to the NPV of each project, and the weight of each item is analogous to
the cash required by each investment. The single constraint is analogous to the budget
constraint—that is, only 14 pounds can fit in the knapsack. In a knapsack problem, the
goal is to get the most value in the knapsack without overloading it.
■
4If you try this with the Capital Budgeting 1.xlsx file, delete the binary constraint, but don’t forget to constrain
the Investment_levels range to be nonnegative and less than or equal to 1.
Impact of Check Sequencing on NSF (Not Sufficient Funds) Fees
Apte et al. (2004) report an interesting application in the banking industry that can be mod-
eled very much like the classical knapsack problem. When a bank receives checks on a
customer’s account, it can process these in any order. If the total of these checks is greater
ADDITIONAL APPLICATIONS
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

6.3 Capital Budgeting Models
305
P R O B L E M S
Solutions for problems whose numbers appear within a
colored box can be found in the Student Solutions Files.
Refer to this book’s preface for purchase information.
Skill-Building Problems
1.
In the capital budgeting model in Figure 6.4, we sup-
plied the NPV for each investment. Suppose instead
that you are given only the streams of cash inflows
from each investment shown in the file P06_01.xlsx.
This file also shows the cash requirements and the
budget. You can assume that (1) all cash outflows
occur at the beginning of year 1, (2) all cash inflows
occur at the ends of their respective years, and (3) the
company uses a 10% discount rate for calculating
its NPVs. Which investments should the company
select?
2.
Solve the previous problem using the input data in the
file P06_02.xlsx.
3.
Solve Problem 1 with the extra assumption that the
investments can be grouped naturally as follows: 1–4,
5–8, 9–12, 13–16, and 17–20.
a. Find the optimal investments when at most one
investment from each group can be selected.
b. Find the optimal investments when at least one
investment from each group must be selected. (If
the budget isn’t large enough to permit this,
increase the budget to a larger value.)
4.
Solve the following modifications of the capital bud-
geting model in Figure 6.4. (Solve each part indepen-
dently of the others.)
a. Suppose that at most two of projects 1 through 5
can be selected.
b. Suppose that if investment 1 is selected, then
investment 3 must also be selected.
c. Suppose that at least one of investments 6 and 7
must be selected.
d. Suppose that investment 2 can be selected only if
both investments 1 and 3 are selected.
5.
In the capital budgeting model in Figure 6.4, investment
4 has the largest ratio of NPV to cash requirement, but it
is not selected in the optimal solution. How much NPV
will be lost if Tatham is forced to select investment 4?
Answer by solving a suitably modified model.
6.
As it currently stands, investment 7 in the capital bud-
geting model in Figure 6.4 has the lowest ratio of NPV
to cash requirement, 2.5. Keeping this same ratio, can
you change the cash requirement and NPV for invest-
ment 7 so that it is selected in the optimal solution?
Does this lead to any general insights? Explain.
7.
Suppose in the capital budgeting model in Figure 6.4
that each investment requires $2000 during year 2, and
only $5000 is available for investment during year 2.
a. Assuming that available money uninvested at the
end of year 1 cannot be used during year 2, what
combination of investments maximizes NPV?
b. Suppose that any uninvested money at the end of
year 1 is available for investment in year 2. Does
your answer to part a change?
8.
Expand and then solve the capital budgeting model in
Figure 6.4 so that 20 investments are now possible.
You can make up the data on cash requirements, NPVs,
and the budget, but use the following guidelines:
■The cash requirements and NPVs for the various
investments can vary widely, but the ratio of NPV
to cash requirement should be between 2.5 and 3.5
for each investment.
■The budget should allow somewhere between 5
and 10 of the investments to be selected.
Skill-Extending Problems
9.
The models in this chapter are often called combinator-
ial models because each solution is a combination of the
various 0–1 values, and only a finite number of such
combinations exist. For the capital budgeting model in
Figure 6.4, there are seven investments, so there are 
27  128 possible solutions (some of which are infeasi-
ble). This is a fairly large number, but not too large.
Solve the model without Solver by listing all 128 solu-
tions. For each, calculate the total cash requirement and
than the customer’s checking balance, the order in which the checks are processed can
affect the number of checks that cannot be honored. For each such check that bounces, the
bank charges the customer an NSF fee of about $20 on average. For example, suppose the
customer’s balance is $200, and checks in the amounts $150, $100, $75, and $25 are pre-
sented. If the bank processes them in low-to-high order, then there is only one NSF fee, for
the $150 check. However, if it processes them in high-to-low order, there is an NSF fee for
each of the three smallest checks. This is not a small problem. There is some evidence that
by using high-to-low order rather than the opposite, the banking industry stands to gain as
much as $1.5 billion annually in extra NSF fees. At the time of the article, banks were
involved in several lawsuits brought by customers who claimed that the deliberate use of
high-to-low order is an unfair practice.
■
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

total NPV for the model. Then manually choose the one
that stays within the budget and has the largest NPV.
10. Make up an example, as described in Problem 8, with
20 possible investments. However, do it so the ratios
of NPV to cash requirement are in a very tight range,
from 3.0 to 3.2. Then use Solver to find the optimal
306
Chapter 6
Optimization Models with Integer Variables
solution when the Solver tolerance is set to its default
value of 5%, and record the solution. Next, solve again
with the tolerance set to 0%. Do you get the same
solution? Try this on a few more instances of the
model, where you keep changing the inputs. The ques-
tion is whether the tolerance setting matters in these
types of “close call” problems.
6.4 FIXED-COST MODELS
In many situations, a cost is incurred if an activity is undertaken at any positive level. This
cost is independent of the level of the activity and is known as a fixed cost (or fixed charge).
Here are three examples of fixed costs:
■
The construction of a warehouse incurs a fixed cost that is the same whether the
warehouse is built with a low- or a high-capacity level.
■
A cash withdrawal from a bank incurs a fixed cost, independent of the size of the
withdrawal.
■
A machine that is used to produce several products must be set up for the production
of each product. Regardless of the batch size produced, the same fixed cost (lost pro-
duction due to the setup time) is incurred.
In these examples, a fixed cost is incurred if an activity is undertaken at any positive
level, whereas no fixed cost is incurred if the activity is not undertaken at all. Although it
might not be obvious, this feature makes the problem inherently nonlinear, which means
that a straightforward application of LP is not possible. However, a clever use of 0–1 vari-
ables can result in a model with linear constraints and a linear objective.
It is important to realize that the type of model discussed here and throughout the rest of
the chapter (except for Example 6.7) is fundamentally different from the previous capital bud-
geting model and the integer-constrained models in Chapter 4.YoudonotsimplycreateanLP
model and then add integer constraints. Instead, you use 0–1 variables to model the logic. The
logic in this section is that if a certain activity is done at any positive level, a fixed cost is
incurred. However, no fixed cost is incurred if the activity is not done at all. Your first instinct
might be to handle such logic with IF functions. However, Solver cannot handle IF functions
predictably. This is not really a weakness of Solver. These types of problems are inherently dif-
ficult. Fortunately, Solver is able to handle linear models with binary variables, so this is the
approach you should take whenever possible. The appropriate use of 0–1 variables allows you
to solve a whole new class of difficult problems. The following example is typical.
FUNDAMENTAL INSIGHT
Binary Variables for Modeling
Binary variables are often used to transform a nonlin-
ear model into a linear (integer) model. For example,
a fixed cost is not a linear function of the le
vel of
some activity; it is either incurred or it isn’t incurred.
This type of on-off beha vior is difficult f or nonlinear
solvers to handle . However, this behavior can often
be handled easil y when binar y variables ar e used to
make the model linear . Still, large models with man y
binary variables can be difficult to solve.One approach
is to solve the model without integer constraints and
then round fractional values to the near est integer 
(0 or 1). Unfortunately, this approach is typically not
very g ood because the r ounded solution is often
infeasible, and even if it is f easible, its objective value
can be considerably worse than the optimal objective
value.
Unless you use binary
variables to handle the
logic, fixed-cost models
are nonlinear and diffi-
cult to solve.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

6.4 Fixed-Cost Models
307
E X A M P L E
6.2 TEXTILE MANUFACTURING AT GREAT THREADS
T
he Great Threads Company is capable of manufacturing shirts, shorts, pants, skirts,
and jackets. Each type of clothing requires that Great Threads have the appropriate
type of machinery available. The machinery needed to manufacture each type of clothing
must be rented at the weekly rates shown in Table 6.3. This table also lists the amounts of
cloth and labor required per unit of clothing, as well as the selling price and the unit vari-
able cost for each type of clothing. In a given week, 4000 labor hours and 4500 square
yards (sq yd) of cloth are available. The company wants to find a solution that maximizes
its weekly profit.
Table 6.3
Data for the Great Threads Example
Rental Cost
Labor Hours
Cloth (sq yd)
Selling Price
Unit Variable Cost
Shirts
$1500
2.0
3.0
$35
$20
Shorts
$1200
1.0
2.5
$40
$10
Pants
$1600
6.0
4.0
$65
$25
Skirts
$1500
4.0
4.5
$70
$30
Jackets
$1600
8.0
5.5
$110
$35 
Objective
To develop a linear model with binary variables that can be used to maximize
the company’s profit, correctly accounting for fixed costs and staying within resource
availabilities.
WHERE DO THE NUMBERS COME FROM?
Except for the fixed costs, this is the same basic problem as the product mix problem
(Examples 3.1 and 3.2) in Chapter 3. Therefore, the same discussion there about input vari-
ables applies here. The fixed costs are the given rental rates for the machinery.
Solution
The variables and constraints required for this model are listed in Table 6.4. First, note that
the cost of producing x shirts during a week is 0 if x  0, but it is 1500  20x if x  0.
This cost structure violates the proportionality assumption (discussed in Chapter 3) that is
needed for a linear model. If proportionality were satisfied, the cost of making, say, 10
shirts would be double the cost of making 5 shirts. However, because of the fixed cost, the
total cost of making 5 shirts is $1600, and the cost of making 10 shirts is only $1700. This
violation of proportionality requires you to resort to 0–1 variables to obtain a linear model.
These 0–1 variables allow you to model the fixed costs correctly.
Table 6.4
Variables and Constraints for the Fixed-Cost Model
Input variables
Fixed rental costs, resource usages (labor hours, cloth) per unit of 
clothing, selling prices, unit variable costs, resource availabilities
Decision variables 
Whether to produce any of each type of clothing (binary), how much 
(changing cells)
of each type of clothing to produce
Objective (target cell)
Profit
Other calculated 
Resources used, upper limits on amounts to produce, total revenue, 
variables
total variable cost, total fixed cost
Constraints
Amount produced  Logical upper limit (capacity)
Resources used  Resources available 
Fixed costs imply that
the proportionality
assumption of linear
models no longer
holds.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

DEVELOPING THE SPREADSHEET MODEL
The spreadsheet model, shown in Figure 6.10, can be developed as follows. (See the file
Fixed Cost Manufacturing.xlsx.)
308
Chapter 6
Optimization Models with Integer Variables
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
K
J
I
H
G
F
E
D
C
B
A
Great Threads ﬁxed cost clothing model
Range names used:
Eﬀecve_capacity
=Model!$B$18:$F$18
Input data on products
Rent_equipment
=Model!$B$14:$F$14
Shirts
Shorts
Pants
Skirts
Jackets
Proﬁt
=Model!$B$29
Labor 
3
2
$
D
$:2
2
$
D
$
!le
d
o
M
=
elb
alia
v
a
_
e
cr
u
o
s
e
R
8
4
6
1
2
tin
u
/sr
u
o
h
Cloth (sq. 
3
2
$
B
$:2
2
$
B
$
!le
d
o
M
=
d
e
s
u
_
e
cr
u
o
s
e
R
5.5
5.4
4
5.2
3
tin
u
/).d
y
Units_produced
=Model!$B$16:$F$16
Selling 
0
1
1
$
0
7
$
5
6
$
0
4
$
5
3
$
tin
u
/
e
cir
p
Variable 
5
3
$
0
3
$
5
2
$
0
1
$
0
2
$
tin
u
/ts
o
c
Fixed cost for equipment
$1,500
$1,200
$1,600
$1,500
$1,600
Producon plan, constraints on capacity
Shirts
Shorts
Pants
Skirts
Jackets
Rent 
1
0
0
1
0
t
n
e
m
piu
q
e
Units 
1
3.9
7
3
0
0
2
5.5
6
9
0
d
e
c
u
d
o
r
p
<=
<=
<=
<=
<=
Eﬀecve 
0
0.0
0
5
0
0.0
0
0.0
0
0.0
0
8
1
0
0.0
ytic
a
p
a
c
Constraints on resources
Resource used
Available
Labor 
0
0
0
4
=
<
0
0.0
0
0
4
sr
u
o
h
0
0
5
4
=
<
0
0.0
0
5
4
h
t
olC
Monetary outputs
5
4
3,0
8
$
e
u
n
e
v
e
R
Variable 
1
3
9,2
2
$
ts
o
c
Fixed cost for equipment
$2,800
4
1
6,4
5
$
tif
o
r
P
Objecve to maximize
Figure 6.10
Fixed-Cost Clothing Model
1
Inputs. Enter the given inputs in the blue ranges.
2
Binary values for clothing types. Enter any trial values for the 0–1 variables for the
various clothing types in the Rent_equipment range. For example, if you enter a 1 in cell
C14, you are implying that the machinery for making shorts is rented and its fixed cost is
incurred.
3
Production quantities. Enter any trial values for the numbers of the various clothing
types produced in the Units_produced range. At this point, you could enter “illegal” val-
ues, such as 0 in cell B14 and a positive value in cell B16. (This is illegal because it implies
that the company produces some shirts but avoids the fixed cost of the machinery for
shirts.) However, Solver will eventually disallow such illegal combinations.
4
Labor and cloth used. In cell B22 enter the formula
=SUMPRODUCT(B5:F5,Units_produced)
to calculate total labor hours, and copy this to cell B23 for cloth.
5
Effective capacities. Now comes the tricky part of the model. You need to ensure
that if any of a given type of clothing is produced, its 0–1 variable equals 1. This ensures
that the model incurs the fixed cost of renting the machine for this type of clothing. You
could easily implement these constraints with IF statements. For example, to implement
the constraint for shirts, you could enter the following formula in cell B14:
=IF(B16>0,1,0)
However, Excel’s Solver is unable to deal with IF functions predictably. Therefore, you
should instead model the fixed-cost constraints as shown in Inequality (6.1).
Shirts produced  Maximum capacity  (0–1 variable for shirts)
(6.1)
Similar inequalities exist for the other types of clothing.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Here is the logic behind Inequality (6.1). If the 0–1 variable for shirts is 0, then the right-
hand side of the inequality is 0, which means that the left-hand side must be 0—no shirts can
be produced. That is, if the 0–1 variable for shirts is 0 so that no fixed cost for shirts is incurred,
Inequality (6.1) does not allow Great Threads to “cheat” and produce a positive number of
shirts. On the other hand, if the 0–1 variable for shirts is 1, the inequality is certainly true and
is essentially redundant. It simply states that the number of shirts produced must be no greater
than the maximum number that could be produced. Inequality (6.1) rules out the one case it
should rule out—namely, that Great Threads produces shirts but avoids the fixed cost.
To implement Inequality (6.1), you need a maximum capacity—an upper limit on the
number of shirts that could be produced. To obtain this, suppose the company puts all of its
resources into producing shirts. Then the number of shirts that can be produced is limited
by the smaller of
and
Therefore, the smaller of these—the most limiting—can be used as the maximum needed
in Inequality (6.1).
To Implement this logic, calculate the effective capacity for shirts in cell B18 with the
formula
=B14*MIN($D$22/B5,$D$23/B6)
Then copy this formula to the range C18:F18 for the other types of clothing.5 By the way,
this MIN formula causes no problems for Solver because it involves only input cells, not
changing cells.
6
Monetary values. Calculate the total sales revenue and the total variable cost by
entering the formula
=SUMPRODUCT(B8:F8,Units_produced)
in cell B26 and copying it to cell B27. Then calculate the total fixed cost in cell B28 with
the formula
=SUMPRODUCT(B10:F10,Rent_equipment)
Note that this formula sums the fixed costs only for those products with 0–1 variables
equal to 1. Finally, calculate the total profit in cell B29 with the formula
=B26-B27-B28
USING SOLVER
The Solver dialog box is shown in Figure 6.11. The objective is to maximize profit, subject to
using no more labor hours or cloth than are available and ensuring that production is less than
or equal to effective capacity. The key is that this effective capacity is 0 if the machinery for
a given type of clothing is not rented. As usual, you should check the Non-Negative option,
select the Simplex LP method, and set the tolerance to 0 (under Solver Options).
Available square yards of cloth

Square yards of cloth per shirt
Available labor hours

Labor hours per shirt
6.4 Fixed-Cost Models
309
The effect of binary
variables is to force
the model to incur the
fixed costs if positive
production levels are
used.
The point of these
ratios is to provide an
upper limit on produc-
tion of any product
when no natural upper
limit is available.
5Why not set the upper limit on shirts equal to a huge number like 1,000,000? The reason is that Solver works
most efficiently when the upper limit is as tight—that is, as low—as possible. A tighter upper limit means fewer
potential feasible solutions for Solver to search through. Here’s an analogy. If you were trying to locate a crimi-
nal, which would be easier: (1) if you were told that he was somewhere in Texas, or (2) if you were told he was
somewhere in Dallas?
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Although Solver finds the optimal solution automatically, you should understand the
effect of the logical upper bound constraint on production. It rules out a solution such as
the one shown in Figure 6.12. This solution calls for a positive production level of pants
but does not incur the fixed cost of the pants equipment. The logical upper bound con-
straint rules this out because it prevents a positive value in row 16 if the corresponding
binary value in row 14 is 0. In other words, if the company wants to produce some pants,
the constraint in Inequality (6.1) forces the associated binary variable to be 1, thus incur-
ring the fixed cost for pants.
Note that Inequality (6.1) does not rule out the situation you see for skirts in Figure
6.12, where the binary value is 1 and the production level is 0. However, Solver will never
choose this type of solution as optimal. Solver recognizes that the binary value in this case
can be changed to 0, so that no skirt equipment is rented and its fixed cost is not incurred.
Discussion of the Solution
The optimal solution in Figure 6.10 indicates that Great Threads should produce about 966
shorts and 379 jackets, but no shirts, pants, or skirts. The total profit is $54,614. Note that
the 0–1 variables for shirts, pants, and skirts are all 0, which forces production of these
products to be 0. However, the 0–1 variables for shorts and jackets, the products that are
produced, are 1. This ensures that the fixed cost of producing shorts and jackets is included
in the total cost.
It might be helpful to think of this solution as occurring in two stages. In the first
stage, Solver determines which products to produce—in this case, shorts and jackets only.
Then in the second stage, Solver determines how many shorts and jackets to produce. If
you know that the company plans to produce shorts and jackets only, you could then ignore
the fixed costs and determine the best production quantities with the same types of product
mix models discussed in Chapter 3. Of course, these two stages—deciding which products
310
Chapter 6
Optimization Models with Integer Variables
Figure 6.11
Solver Dialog Box 
for the Fixed-Cost
Model
There is no point to set-
ting a binary variable
equal to 1—and Solver
will never do it—unless
there is positive produc-
tion of that product.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

to produce and how many of each to produce—are interrelated, and Solver determines both
of them in its solution process.
The Great Threads management might not be too excited about producing shorts and
jackets only. Suppose the company wants to ensure that at least three types of clothing are
produced at positive levels. One approach is to add another constraint—namely, that the
sum of the 0–1 values in row 14 is greater than or equal to 3. You can check, however, that
when this constraint is added and Solver is run, the 0–1 variable for skirts becomes 1, but
no skirts are produced. Shorts and jackets are more profitable than skirts, so only shorts
and jackets are produced (see Figure 6.13). The new constraint forces Great Threads to
rent an extra piece of machinery (for skirts), but it doesn’t force the company to use it. To
force the company to produce some skirts, you also need to add a constraint on the value in
E16, such as E16100. Any of these additional constraints will cost Great Threads
money, but if, as a matter of policy, the company wants to produce more than two types of
clothing, this is its only option.
Sensitivity Analysis
Because the optimal solution currently calls for only shorts and jackets to be produced, an
interesting sensitivity analysis is to see how much incentive is required for other products to
be produced. One way to check this is to increase the selling price for a nonproduced product
such as skirts in a one-way SolverTable. We did this, keeping track of all binary variables and
profit, with the results shown in Figure 6.14. When the selling price for skirts is $85 or less,
6.4 Fixed-Cost Models
311
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
F
E
D
C
B
A
Great Threads ﬁxed cost clothing model
Input data on products
Shirts
Shorts
Pants
Skirts
Jackets
Labor 
8
4
6
1
2
tin
u
/sr
u
o
h
Cloth (sq. 
5.5
5.4
4
5.2
3
tin
u
/).d
y
Selling 
0
1
1
$
0
7
$
5
6
$
0
4
$
5
3
$
tin
u
/
e
cir
p
Variable 
5
3
$
0
3
$
5
2
$
0
1
$
0
2
$
tin
u
/ts
o
c
Fixed cost for equipment
$1,500
$1,200
$1,600
$1,500
$1,600
Producon plan, constraints on capacity
Shirts
Shorts
Pants
Skirts
Jackets
Rent 
1
1
0
1
0
t
n
e
m
piu
q
e
Units 
0
0.0
0
1
0
0
0.0
5
4
0
0.0
0
5
0
d
e
c
u
d
o
r
p
<=
<=
<=
<=
<=
Eﬀecve 
0
0.0
0
5
0
0.0
0
0
1
0
0.0
0
0.0
0
8
1
0
0.0
ytic
a
p
a
c
Constraints on resources
Resource used
Available
Labor 
0
0
0
4
=
<
0
0.0
0
0
4
sr
u
o
h
0
0
5
4
=
<
0
0.0
0
6
3
h
t
olC
Monetary outputs
0
5
2,0
6
$
e
u
n
e
v
e
R
Variable 
0
5
7,9
1
$
ts
o
c
Fixed cost for equipment
$4,300
0
0
2,6
3
$
tif
o
r
P
Objecve to maximize
Figure 6.12
An Illegal (and Nonoptimal) Solution
Because of fixed costs,
the optimal solution
might call for only a
small subset of prod-
ucts to be produced.
Only extra side con-
straints can force
more products to be
produced.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

the company continues to produce only shorts and jackets. However, when the selling price is
$90 or greater, the company stops producing shorts and jackets and produces only skirts. You
can check that the optimal production quantity of skirts is 1000 when the selling price of
skirts is any value $90 or above. The only reason that the profits in Figure 6.14 increase from
row 37 down is that the revenues from these 1000 skirts keep increasing.
A Model with IF Functions
In case you are still not convinced that the binary variable approach is required, and you
think IF functions could be used instead, take a look at last worksheet in the finished version
312
Chapter 6
Optimization Models with Integer Variables
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
I
H
G
F
E
D
C
B
A
Great Threads ﬁxed cost clothing model
Input data on products
Shirts
Shorts
Pants
Skirts
Jackets
Labor 
8
4
6
1
2
tin
u
/sr
u
o
h
Cloth (sq. 
5.5
5.4
4
5.2
3
tin
u
/).d
y
Selling 
0
1
1
$
0
7
$
5
6
$
0
4
$
5
3
$
tin
u
/
e
cir
p
Variable 
5
3
$
0
3
$
5
2
$
0
1
$
0
2
$
tin
u
/ts
o
c
Fixed cost for equipment
$1,500
$1,200
$1,600
$1,500
$1,600
Producon plan, constraints on capacity
Shirts
Shorts
Pants
Skirts
Jackets
Sum
Required
Rent 
3
=
>
3
1
1
0
1
0
t
n
e
m
piu
q
e
Units 
1
3.9
7
3
0
0
2
5.5
6
9
0
d
e
c
u
d
o
r
p
<=
<=
<=
<=
<=
Eﬀecve 
0
0.0
0
5
0
0.0
0
0
1
0
0.0
0
0.0
0
8
1
0
0.0
ytic
a
p
a
c
Constraints on resources
Resource used
Available
Labor 
0
0
0
4
=
<
0
0.0
0
0
4
sr
u
o
h
0
0
5
4
=
<
0
0.0
0
5
4
h
t
olC
Monetary outputs
5
4
3,0
8
$
e
u
n
e
v
e
R
Variable 
1
3
9,2
2
$
ts
o
c
Fixed cost for equipment
$4,300
4
1
1,3
5
$
tif
o
r
P
Objecve to maximize
Figure 6.13
The Great Threads Model with Extra Constraint
1
2
3
A
B
C
D
E
F
G
Oneway analysis for Solver model in Model worksheet
Selling price skirts (cell $E$8) values along side, output cell(s) along top
ment_1
ment_2
ment_3
ment_4
ment_5
4
5
6
7
Rent_Equipm
Rent_Equipm
Rent_Equipm
Rent_Equipm
Rent_Equipm
Proﬁt
$70
0
1
0
0
1
$54,614
$75
0
1
0
0
1
$54,614
$80
0
1
0
0
1
$54 614
7
8
9
10
11
$80
0
1
0
0
1
$54,614
$85
0
1
0
0
1
$54,614
$90
0
0
0
1
0
$58,500
$95
0
0
0
1
0
$63,500
$100
0
0
0
1
0
$68,500
Figure 6.14
Sensitivity of Binary
Variables to Unit
Revenue of Skirts
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

of the file. The resulting model looks the same as in Figure 6.11, but it incorporates the fol-
lowing changes:
■
The binary range is no longer part of the changing cells range. Instead, cell B14 con-
tains the formula =IF(B16>0,1,0), which is copied across to cell F14. Logically, this
probably appears more natural. If a production quantity is positive, a 1 is entered in
row 14, which means that the fixed cost is incurred.
■
The effective capacities in row 18 are modeled with IF functions. Specifically, cell
B18 contains the formula =IF(B16>0,MIN($D$22/B5,$D$23/B6),0), which is
copied across to cell F18. (Actually, this constraint isn’t even necessary now. Why?)
■
The Solver dialog box is now set up as shown in Figure 6.15. The Rent_equipment
range is not part of the changing cells range, and there is no binary constraint. The
GRG Nonlinear method is selected because the IF functions make the model nonlinear.
When we ran Solver on this modified model, we found inconsistent results, depending on
the initial production quantities entered in row 16. For example, when we entered initial
values all equal to 0, the Solver solution was exactly that—all 0s. Of course, this solution
is terrible because it leads to a profit of $0. However, when we entered initial production
quantities all equal to 100, Solver found the correct optimal solution, the same as in
Figure 6.10. Was this just lucky? To check, we tried another initial solution, where the pro-
duction quantities for shorts and jackets were 0, and the production quantities for shirts,
pants, and skirts were all 500. In this case, Solver found a solution where only skirts are
produced. Of course, we know this is not optimal.
The moral is that the IF-function approach is not the way to go. Its success depends
strongly on the initial values entered in the changing cells, and this requires you to make
very good guesses. In contrast, the binary approach ensures that you get the correct solu-
tion regardless of the initial values in the changing cells. ■
6.4 Fixed-Cost Models
313
Figure 6.15
Solver Dialog Box
When IF Functions
Are Used
You can try modeling
the logic with IF func-
tions, but, depending
on the initial values in
the changing cells,
Solver is likely to get
the wrong solution.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

The following example is similar to the Great Threads example in that there is a fixed
cost for any positive level of production of a given product. However, an additional
requirement states that if the company produces any of a given product, then (possibly
because of economies of scale) it must produce at least some minimal level such as 1000.
This is a typical example of a problem with either–or constraints: The company’s level of
production must either be 0 or at least 1000. In the next example, we show how the use of
binary variables allows you to model the either–or constraints in a linear manner.
314
Chapter 6
Optimization Models with Integer Variables
E X A M P L E
6.3 MANUFACTURING AT DORIAN AUTO
D
orian Auto is considering manufacturing three types of cars (compact, midsize, and
large) and two types of minivans (midsize and large). The resources required and the
profit contributions yielded by each type of vehicle are shown in Table 6.5. At present,
6500 tons of steel and 65,000 hours of labor are available. If any vehicles of a given type
are produced, production of that type of vehicle is economically feasible only if at least
a minimal number of that type are produced. These minimal numbers are also listed in
Table 6.5. Dorian wants to find a production schedule that maximizes its profit.
Table 6.5
Data for the Dorian Car Example
Vehicle Compact 
Midsize 
Large 
Midsize 
Large 
Type
Car
Car
Car
Minivan
Minivan
Steel (tons)/unit
1.5
3
5
6
8
Labor hours/unit
30
25
40
45
55
Minimum production (if any)
1000
1000
1000
200
200
Profit contribution/unit
$2,000
$2,500
$3,000
$5,500
$7,000
Objective
To use a binary model to determine which types of vehicles to produce (above
their minimal requirements), and in what quantities, to maximize profit.
WHERE DO THE NUMBERS COME FROM?
This is basically a product mix problem, similar to those in Chapter 3. Therefore, the
same comments about inputs discussed there apply here as well. The only new inputs in
this problem are the minimal production quantities. These might be policy decisions
determined by Dorian—management sees no reason to produce midsize minivans
unless it can produce at least 200 of them, say—but these policy decisions are undoubt-
edly based on costs. Presumably, the fixed costs of product design, manufacturing, and
marketing are prohibitive unless a minimal number of any vehicle type is produced.
Solution
The variables and constraints for the Dorian model are listed in Table 6.6. Dorian must
decide not only how many of each type of vehicle to produce, but also which types to pro-
duce. Of course, after it decides to produce midsize minivans, say, then it must produce at
least 200 of them. The constraints include the usual resource availability constraints. In addi-
tion, there are lower and upper limits on the production quantities of any vehicle type. The
lower limit is zero or the minimal production quantity, depending on whether that vehicle
type is produced. The upper limit is similar to the upper limit in the Great Thread’s fixed-cost
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

model in Example 6.2. That is, it is either zero, if the vehicle type is not produced at all, or it
is some suitable large number. As in Example 6.2, this large number can be the number of
that type of vehicle that could be produced if all of the steel and labor hours were devoted to
it alone.
6.4 Fixed-Cost Models
315
Table 6.6
Variables and Constraints for the Dorian Manufacturing Model
Input variables
Resources (steel and labor hours) consumed by each vehicle type, 
profit contribution for each vehicle type, minimal production quantity
for each vehicle type, resource availabilities
Decision variables 
Whether to produce any of each vehicle type (binary), units produced 
(changing cells)
of each vehicle type
Objective (target cell)
Profit
Other calculated 
Logical lower and upper bounds on production quantities, resources used
variables
Constraints
Production quantities  Logical lower bounds
Production quantities  Logical upper bounds
Resources used  Resources available
DEVELOPING THE SPREADSHEET MODEL
The example can be modeled with the following steps. (See Figure 6.16 and the file 
Either Or Manufacturing.xlsx.)
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
J
I
H
G
F
E
D
C
B
A
Dorian Auto producon model with either-or constraints
Inputs
Range names used:
Vehicle 
tc
a
p
m
o
C
e
p
y
t
 car
Midsize car
Large car
Midsize minivan
Large minivan
Logical_capacity
=Model!$B$19:$F$19
Steel 
B
$
!le
d
o
M
=
n
oitc
u
d
o
r
p
_
m
u
m
ini
M
8
6
5
3
5.1
tin
u
/)s
n
o
t(
$15:$F$15
Labor  
3
1
$
F
$:3
1
$
B
$
!le
d
o
M
=
m
u
m
ini
m
_
ts
a
el_
t
a
_
e
c
u
d
o
r
P
5
5
5
4
0
4
5
2
0
3
tin
u
/sr
u
o
h
Minimum producon (if 
7
2
$
B
$
!le
d
o
M
=
tif
o
r
P
0
0
2
0
0
2
0
0
0
1
0
0
0
1
0
0
0
1
)y
n
a
Resource_available
=Model!$D$23:$D$24
Proﬁt 
4
2
$
B
$:3
2
$
B
$
!le
d
o
M
=
d
e
s
u
_
e
cr
u
o
s
e
R
0
0
0,7
$
0
0
5,5
$
0
0
0,3
$
0
0
5,2
$
0
0
0,2
$
tin
u
/
n
oit
u
birt
n
o
c
Units_produced
=Model!$B$17:$F$17
Producon plan and bounds on producon quanes
Type of 
tc
a
p
m
o
C
r
a
c
 car
Midsize car
Large car
Midsize minivan
Large minivan
Produce at least 
1
1
0
0
1
m
u
m
ini
m
Minimum 
0
0
2
0
0
2
0
0
0
0
0
1
n
oitc
u
d
o
r
p
<=
<=
<=
<=
<=
Units 
3
7
4
0
0
2
0
0
0
0
0
1
d
e
c
u
d
o
r
p
<=
<=
<=
<=
<=
Logical 
3
1
8
3
8
0
1
0
0
7
6
1
2
y
tic
a
p
a
c
Constraints on resources
Resource used
Resource available
0
0
5
6
=
<
2
8
4
6
le
e
t
S
Labor 
0
0
0
5
6
=
<
0
0
0
5
6
sr
u
o
h
Objecve to maximize
1
9
0,9
0
4,6
$
tif
o
r
P
Figure 6.16 The Dorian Auto Production Model
1
Inputs. Enter the input data in the blue ranges.
2
Number of vehicles produced. Enter any trial values for the number of vehicles of
each type produced in the Units_produced range.
3
Binary v ariables f or minimum pr oduction. Enter any trial 0–1 values in the
Produce_at_least_minimum range. If a value in this range is 1, this means that Dorian must
produce at least the minimum number of the corresponding vehicle type. A value of 0 in
this range means that Dorian does not produce any of the corresponding vehicle type.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4
Lower limits on pr oduction. The either–or constraints are implemented with the
binary variables in row 13 and the inequalities indicated in rows 15 through 19. To obtain
the lower limits on production, enter the formula
=B7*B13
in cell B15 and copy it across row 15. This lower limit implies that if the binary variable in
row 13 is 1, then Dorian must produce at least the minimum number of that vehicle type.
However, if the binary variable is 0, then the lower bound in row 15 is 0 and is essentially
redundant—it just says that production must be nonnegative.
5
Upper limits on production. To obtain upper limits on production, enter the formula
B13*MIN($D$23/B5,$D$24/B6)
in cell B19 and copy it across row 19. Note that the MIN term in this formula is the maxi-
mum number of compact cars Dorian could make if it devoted all of its resources to com-
pact cars. (A similar upper limit was used in the Great Threads model in Example 6.2.) If
the binary variable in row 13 is 1, this upper limit is essentially redundant—production can
never be greater than this in any case. But if the binary variable is 0, this upper limit is 0,
which prevents Dorian from making any vehicles of this type.
To summarize the lower and upper limits, if the binary variable is 1, the production
limits become
Minimum production required  Production  Maximum production possible
On the other hand, if the binary variable is 0, the limits become
0  Production  0
Of course, these latter inequalities imply that production is 0. Exactly one of these cases
must hold for each car type, so they successfully implement the either–or constraints.
These lower and upper limits are the keys to the model.
6
Steel and labor used. Calculate the tons of steel and number of labor hours used in
the Resources_used range by entering the formula
=SUMPRODUCT(B5:F5,Units_produced)
in cell B23 and copying it to cell B24.
7
Profit. Calculate the profit in cell B27 with the formula
=SUMPRODUCT(B9:F9,Units_produced)
USING SOLVER
The completed Solver dialog box is shown in Figure 6.17. The objective is to maximize
profit, the changing cells are the production quantities and the binary variables, and the
constraints specify the production limits and resource availabilities. Note that the produc-
tion quantities are not constrained to be integers, although you could do so. Extra integer
constraints only make the model more difficult to optimize, and if the optimal number of
some vehicle type turns out to be 472.7, say, it is probably acceptable to round this up to
473 or down to 472.
Discussion of the Solution
The optimal solution in Figure 6.16 indicates, by the 0 values in row 13, that Dorian should
not produce any midsize or large cars. The number of 1s in this row, however, indicates
that Dorian must produce at least the minimum number (1000) of compact cars and the
316
Chapter 6
Optimization Models with Integer Variables
The trick is in getting
the constraints to 
allow what we want to
allow, but to disallow
“illegal” solutions.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

minimum number (200) of each type of minivan. More specifically, the company should
produce just enough compact cars and midsize minivans to meet the minimal production
quantities. These vehicle types are relatively profitable, given the resources they use.
However, they are evidently not as profitable as large minivans. The company should make
as many of these as it can, after producing the compact cars and midsize minivans, until it
runs out of labor hours.
This solution is certainly not intuitive. (For example, if large minivans are so prof-
itable, why doesn’t the company produce all large minivans and nothing else? Do you see
why?) Also, this solution appears to be very sensitive to the inputs. Although we do not
present any formal sensitivity analysis with SolverTable, we urge you to try different val-
ues for the minimal production quantities, the unit profit contributions, and/or the resource
availabilities. We found that even small changes in these can yield a very different optimal
production policy. For example, you can check that if the availability of steel decreases to
6000 tons, only compact cars and midsize minivans are produced, both above their mini-
mal levels, and no large minivans are produced. ■
6.4 Fixed-Cost Models
317
Figure 6.17 Solver
Dialog Box for the
Dorian Production
Model
Locating Distribution Centers
When Dow Consumer Products (a manufacturer of food-care products) acquired the
Texize home-care product lines of Morton Thiokol in 1985 to form DowBrands, Inc., the
distribution channels of the two organizations remained, for the most part, separate. Each
had its own district and regional distribution centers for storing and then shipping products
to the customer regions. This led to possible inefficiencies in a business where keeping
logistics costs low is the key to survival. Robinson et al. (1993), acting as consultants for
ADDITIONAL APPLICATIONS
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

DowBrands, modeled the problem as a fixed-cost network problem—which distribution
centers to keep open and which routes to use to satisfy which customers with which prod-
ucts. The study was highly successful and convinced DowBrands to close a significant
number of distribution centers to reduce costs. ■
318
Chapter 6
Optimization Models with Integer Variables
P R O B L E M S
Skill-Building Problems
11. How difficult is it to expand the Great Threads model
to accommodate another type of clothing? Answer by
assuming that the company can also produce sweat-
shirts. The rental cost for sweatshirt equipment is
$1100; the variable cost per unit and the selling
price are $15 and $45, respectively; and each
sweatshirt requires one labor hour and 3.5 square
yards of cloth.
12. Referring to the previous problem, if it is optimal for
the company to produce sweatshirts, use SolverTable
to see how much larger the fixed cost of sweatshirt
machinery would have to be before the company
would not produce any sweatshirts. However, if the
solution to the previous problem calls for no sweat-
shirts to be produced, use SolverTable to see how
much lower the fixed cost of sweatshirt machinery
would have to be before the company would start
producing sweatshirts.
13. In the Great Threads model, we didn’t constrain the
production quantities in row 16 to be integers, arguing
that any fractional values could be safely rounded to
integers. See whether this is true. Constrain these
quantities to be integers and then run Solver. Are the
optimal integer values the same as the rounded frac-
tional values in Figure 6.10?
14. In the optimal solution to the Great Threads model, the
labor hour and cloth constraints are both binding—the
company is using all it has.
a. Use SolverTable to see what happens to the opti-
mal solution when the amount of available cloth
increases from its current value. (You can choose
the range of input values to use.) Capture all of the
changing cells, the labor hours and cloth used, and
the profit as outputs in the table. The real issue here
is whether the company can profitably use more
cloth when it is already constrained by labor hours.
b. Repeat part a, but reverse the roles of labor hours
and cloth. That is, use the available labor hours as
the input for SolverTable.
15. In the optimal solution to the Great Threads model, no
pants are produced. Suppose Great Threads has an
order for 300 pairs of pants that must be produced.
Modify the model appropriately and use Solver to find
the new optimal solution. (Is it enough to put a
lower bound of 300 on the production quantity in cell
D16? Will this automatically force the binary value
in cell D14 to be 1? Explain.) How much profit
does the company lose because of having to produce
pants?
16. In the Dorian production model, the optimal solution
calls for the minimum number of compact cars and
midsize minivans to be produced, but for more than
the minimum number of large minivans to be pro-
duced. If the large minivans are evidently that prof-
itable, why doesn’t Dorian discontinue making
compact cars and midsize minivans and instead pro-
duce even more large minivans?
17. As the Dorian production model is currently stated,
each vehicle type has a minimum production level;
if this type is produced at all, its production quantity
must be at least this minimum. Suppose that for large
minivans, there is also a maximum production level of
400. If large minivans are produced, the production
level must be from 200 to 400. Modify the model as
necessary and use Solver to find the new optimal solu-
tion. How do you know that the current optimal solu-
tion is not optimal for the modified model?
18. The optimal solution to the Dorian production model
appears to be sensitive to the model inputs. For each
of the following inputs, create a one-way Solver Table
that captures all changing cells and the target cell as
outputs. You can choose the ranges of these inputs 
to make the results interesting. Comment on your 
results.
a. The steel available
b. The labor hours available
c. The unit profit contribution of large minivans
d. The minimum production level (currently 200) of
large minivans
e. The minimum production level (currently 1000) of
compact cars
19. If Solver could handle IF functions correctly, how
would you use them in the Dorian production example
to create an arguably more natural model—without
binary variables? Run Solver on your modified model.
Do you get the correct solution? (Note: You will have
to use the GRG Nonlinear method.)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Skill-Extending Problems
20. In the Great Threads model, you found an upper
bound on production of any clothing type by calculat-
ing the amount that could be produced if all of the
resources were devoted to this clothing type.
a. What if you instead used a very large value such as
1,000,000 for this upper bound? Try it and see
whether you get the same optimal solution.
b. Explain why any such upper bound is required.
Exactly what role does it play in the model devel-
oped in this section?
21.
In the last sheet of the file Fixed Cost Manufacturing.xlsx,
we illustrated one way to model the Great Threads
problem with IF functions that didn’t work. Try a
slightly different approach here. Eliminate the binary
variables in row 14 altogether, and eliminate the
upper bounds in row 18 and the corresponding upper
bound constraints in the Solver dialog box. (The only
constraints will now be the resource availability con-
straints.) However, use IF functions to calculate the
total fixed cost of renting equipment, so that if the
amount of any clothing type is positive, its fixed cost
6.5 Set-Covering and Location-Assignment Models
319
is added to the total fixed cost. Is Solver able to handle
this model? Does it depend on the initial values in the
changing cells? (Don’t forget to use the GRG
Nonlinear method.)
22. In the Dorian production model, suppose that the pro-
duction quantity of compact cars must either be less
than or equal to 100 (a small batch) or greater than or
equal to 1000 (a large batch). The same statements
hold for the other vehicle types as well, except that the
small and large batch limits for both sizes of minivans
are 50 and 200. Modify the model appropriately and
use Solver to find the optimal solution.
23. Suppose in the Dorian production model that no
minimum production limits are placed on the individ-
ual vehicle types. However, minimum production
limits are placed on all cars and on all minivans.
Specifically, if Dorian produces any cars, regardless 
of size, it must produce at least 1500 cars total.
Similarly, if the company produces any minivans, it
must produce at least 1000 minivans total. Modify the
model appropriately and use Solver to find the optimal
solution.
6.5 SET-COVERING AND LOCATION-ASSIGNMENT MODELS
Many companies have geographically dispersed customers that they must service in some
way. To do this, they create service center facilities at selected locations and then assign
each customer to one of the service centers. Various costs are incurred, including (1) fixed
costs of locating service centers in particular locations; (2) operating costs, depending on
the service centers’ locations; and (3) transportation costs, depending on the distances
between customers and their assigned service centers. In this section, we illustrate several
examples of this basic problem.
We first examine a particular type of location model called a set-covering model. In a
set-covering model, each member of a given set (set 1) must be “covered” by an acceptable
member of another set (set 2). The usual objective in a set-covering problem is to minimize
the number of members in set 2 that are needed to cover all the members in set 1. For
example, set 1 might consist of all cities in a county, and set 2 might consist of the cities
where a fire station is located. A fire station “covers” a city if the fire station is located, say,
within 10 minutes of the city. The goal is to minimize the number of fire stations needed to
cover all cities. Set-covering models have been applied to areas as diverse as airline crew
scheduling, truck dispatching, political redistricting, and capital investment. The following
example presents a typical set-covering model.
E X A M P L E
6.4 HUB LOCATION AT WESTERN AIRLINES
W
estern Airlines wants to design a hub system in the United States. Each hub is used
for connecting flights to and from cities within 1000 miles of the hub. Western runs
flights among the following cities: Atlanta, Boston, Chicago, Denver, Houston, Los
Angeles, New Orleans, New York, Pittsburgh, Salt Lake City, San Francisco, and Seattle.
The company wants to determine the smallest number of hubs it needs to cover all these
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

cities, where a city is covered if it is within 1000 miles of at least one hub. Table 6.7 lists
which cities are within 1000 miles of other cities.
320
Chapter 6
Optimization Models with Integer Variables
Table 6.7
Data for the Western Set-Covering Example
Cities Within 1000 Miles
Atlanta (AT)
AT, CH, HO, NO, NY, PI
Boston (BO)
BO, NY, PI
Chicago (CH)
AT, CH, NY, NO, PI
Denver (DE)
DE, SL
Houston (HO)
AT, HO, NO
Los Angeles (LA)
LA, SL, SF
New Orleans (NO)
AT, CH, HO, NO
New York (NY)
AT, BO, CH, NY, PI
Pittsburgh (PI)
AT, BO, CH, NY, PI
Salt Lake City (SL)
DE, LA, SL, SF, SE
San Francisco (SF)
LA, SL, SF, SE
Seattle (SE)
SL, SF, SE
Objective
To develop a binary model to find the minimum number of hub locations that
can cover all cities.
WHERE DO THE NUMBERS COME FROM?
Western has evidently made a policy decision that its hubs will cover only cities within a
1000-mile radius. Then the cities covered by any hub location can be found from a map.
(In a later sensitivity analysis, we explore how the solution changes when the coverage dis-
tance is allowed to vary.)
Solution
The variables and constraints for this set-covering model are listed in Table 6.8. The model
is straightforward. There is a binary variable for each city to indicate whether a hub is
located there. Then the number of hubs that cover each city is constrained to be at least 1.
There are no monetary costs in this version of the problem. The objective is simply to min-
imize the number of hubs.
Table 6.8
Variables and Constraints for the Set-Covering Model
Input variables
Cities within 1000 miles of one another
Decision variables (changing cells)
Locations of hubs (binary)
Objective (target cell)
Number of hubs
Other calculated variables
Number of hubs covering each city
Constraints
Number of hubs covering a city  1
DEVELOPING THE SPREADSHEET MODEL
The spreadsheet model for Western is shown in Figure 6.18. (See the file Locating Hubs
1.xlsx.) The model can be developed as follows:
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

A SUMPRODUCT of
two 0–1 ranges just
finds the number of
matches of 1s in
the two ranges. Here
it calculates the num-
ber of hubs that cover
a given city.
1
Inputs. Enter the information from Table 6.7 in the blue range. A 1 in a cell indicates
that the column city covers the row city, whereas a 0 indicates that the column city does not
cover the row city. For example, the three 1s in row 7 indicate that Boston, New York, and
Pittsburgh are the only cities within 1000 miles of Boston.
2
0–1 values for hub locations. Enter any trial 0–1 values in the Used_as_hub range to
indicate which cities are used as hubs. These are the changing cells.
3
Cities co vered by hubs.
Determine the number of hubs that cover each city.
Specifically, calculate the total number of hubs within 1000 miles of Atlanta in cell B25
with the formula
=SUMPRODUCT(B6:M6,Used_as_hub)
For any 0–1 values in the changing-cells range, this formula finds the number of hubs that
cover Atlanta. Then copy this to the rest of the Hubs_covered_by range. Note that a value
in the Hubs_covered_by range can be 2 or greater. This indicates that a city is within
1000 miles of multiple hubs.
4
Number of hubs.
Calculate the total number of hubs used in cell B39 with the
formula
=SUM(Used_as_hub)
6.5 Set-Covering and Location-Assignment Models
321
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
A
B
C
D
E
F
G
H
I
J
K
L
M
N
O
P
Q
Western Airlines hub locaon model
Input data: which cies are covered by which potenal 
e
g
n
a
R
s
b
u
h
 names used:
Potenal hub
Hubs_covered_by
=Model!$B$25:$B$36
9
3
$
B
$
!le
d
o
M
=
s
b
u
h
_la
t
o
T
E
S
F
S
L
S
IP
Y
N
O
N
A
L
O
H
E
D
H
C
O
B
T
A
ytiC
1
2
$
M
$:1
2
$
B
$
!le
d
o
M
=
b
u
h
_
s
a
_
d
e
s
U
0
0
0
1
1
1
0
1
0
1
0
1
T
A
0
0
0
1
1
0
0
0
0
0
1
0
O
B
0
0
0
1
1
1
0
0
0
1
0
1
H
C
0
0
1
0
0
0
0
0
1
0
0
0
E
D
0
0
0
0
0
1
0
1
0
0
0
1
O
H
0
1
1
0
0
0
1
0
0
0
0
0
A
L
0
0
0
0
0
1
0
1
0
1
0
1
O
N
0
0
0
1
1
0
0
0
0
1
1
1
Y
N
0
0
0
1
1
0
0
0
0
1
1
1
IP
1
1
1
0
0
0
1
0
1
0
0
0
L
S
1
1
1
0
0
0
1
0
0
0
0
0
F
S
1
1
1
0
0
0
0
0
0
0
0
0
E
S
Decisions: which cies to use as hubs
AT
BO
CH
DE
HO
LA
NO
NY
PI
SL
SF
SE
Used as hub
0
0
0
0
1
0
0
1
0
1
0
0
Constraints that each city must be covered by at least one hub
City
Hubs covered by
Required
1
=
>
2
T
A
1
=
>
1
O
B
1
=
>
1
H
C
1
=
>
1
E
D
1
=
>
1
O
H
1
=
>
1
A
L
1
=
>
1
O
N
1
=
>
1
Y
N
1
=
>
1
IP
1
=
>
1
L
S
1
=
>
1
F
S
1
=
>
1
E
S
Objecve to minimize
Total 
3
s
b
u
h
Note that there are mulple opmal soluons 
to this model, all of which require a total of 3 
hubs. You might get a diﬀerent soluon from 
the one shown here.
Figure 6.18
The Airline Hub Set-Covering Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

USING SOLVER
The Solver dialog box is shown in Figure 6.19. The objective is to minimize the total num-
ber of hubs, subject to covering each city by at least one hub and ensuring that the chang-
ing cells are binary. As usual, you should select the Simplex LP method.
322
Chapter 6
Optimization Models with Integer Variables
Figure 6.19
Solver Dialog Box 
for the Set-Covering
Model
Discussion of the Solution
Figure 6.20 is a graphical representation of the optimal solution, where the double ovals
indicate hub locations and the large circles indicate ranges covered by the hubs. (These large
circles are not drawn to scale. In reality, they should be circles of radius 1000 miles centered
at the hubs.) Three hubs—in Houston, New York, and Salt Lake City—are needed.6 Would
you have guessed this? The Houston hub covers Houston, Atlanta, and New Orleans. The
New York hub covers Atlanta, Pittsburgh, Boston, New York, and Chicago. The Salt Lake
City hub covers Denver, Los Angeles, Salt Lake City, San Francisco, and Seattle. Note that
Atlanta is the only city covered by two hubs; it can be serviced by New York or Houston.
Sensitivity Analysis
An interesting sensitivity analysis for Western’s problem is to see how the solution is
affected by the mile limit. Currently, a hub can service all cities within 1000 miles. What if
the limit were 800 or 1200 miles, say? To answer this question, data on actual distances
among all the cities must be collected. After you have a matrix of these distances, you can
build the 0–1 matrix, corresponding to the range B6:M17 in Figure 6.18, with IF functions.
6 Multiple optimal solutions exist for this model, all requiring three hubs, so you might obtain a different solution
from ours.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

The modified model appears in Figure 6.21. (See the file Locating Hubs 2.xlsx.) The typi-
cal formula in B24 is =IF(B8<=$B$4,1,0), which is then copied to the rest of the B24:M35
range.7 You can then run SolverTable, selecting cell B4 as the single input cell, letting it
vary from 800 to 1200 in increments of 100, and keeping track of where the hubs are
located and the number of hubs. The SolverTable results at the bottom show the effect of
the mile limit. When this limit is lowered to 800 miles, four hubs are required, but when it
is increased to 1100 or 1200, only two hubs are required. By the way, the solution shown
for the 1000-mile limit is different from the previous solution in Figure 6.18 (because of
multiple optimal solutions), but it still requires three hubs. ■
6.5 Set-Covering and Location-Assignment Models
323
Bos
Chi
Atl
NO
Hou
Sea
LA
SL
Den
SF
Pit
NY
Figure 6.20
Graphical Solution
to the Set-Covering
Model
1
2
3
4
5
6
7
8
9
A
B
C
D
E
F
G
H
I
J
K
L
M
N
Oneway analysis for Solver model in Model worksheet
Mile limit (cell $B$4) values along side, output cell(s) along top
AT
BO
CH
DE
HO
LA
NO
NY
PI
SL
SF
SE
Total_hubs
800
1
1
0
0
0
0
0
0
0
1
0
1
4
900
1
1
0
0
0
0
0
0
0
1
0
0
3
1000
1
1
0
0
0
0
0
0
0
1
0
0
3
1100
0
0
1
0
0
0
0
0
0
1
0
0
2
1200
0
0
1
0
0
1
0
0
0
0
0
0
2
Figure 6.21
Sensitivity to Mile Limit
7We have warned you about using IF functions in Solver models. However, the current use affects only the inputs
to the problem, not quantities that depend on the changing cells. Therefore, it causes no problems.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

324
Chapter 6
Optimization Models with Integer Variables
Locating Florida Disaster Recovery Centers
In 2001, the Federal Emergency Management Agency (FEMA) required every Florida
county to identify potential locations for disaster recovery centers (DRCs). Dekle et al.
(2005) describe a study sponsored by Alachua County in north-central Florida to identify
potential DRC sites. The authors developed a version of the set-covering model with a
two-stage approach. The first stage required each resident to be within 20 miles of the clos-
est DRC. It identified a solution with three DRC locations. The second stage then refined
this solution to relax the 20-mile requirement and include evaluation criteria not included
in stage 1. The final results provided significant improvements over the original FEMA
location criteria, and it maintained acceptable travel distances to the nearest DRC.
Selecting Receiver Locations for Automated Meter Reading
Gavirneni et al. (2004) developed and solved a set-covering model for Schlumberger, a
utility company. The company needed to deploy its receivers on utility poles so that all
wireless meters in the region can transmit their readings to at least one receiver. The
authors solved a large-scale model with 116,600 meters and 20,636 utility poles. ■
The following example is similar to a set-covering model, but it also has an assign-
ment component.
ADDITIONAL APPLICATIONS
E X A M P L E
6.5 LOCATING AND ASSIGNING SERVICE CENTERS AT UNITED COPIERS
U
nited Copiers sells and services copy machines to customers in 11 cities throughout
the country. The company wants to set up service centers in three of these cities.
After United Copiers chooses the location of the service centers, it must assign customers
in each city to one of the service centers. For example, if it decides to locate a service cen-
ter in New York and then assigns its Boston customers to the New York service center, a
service representative from New York will travel from Boston when services are
required there. The distances (in miles) between the cities are listed in Table 6.9. The
estimated annual numbers of trips to the various customers are listed in Table 6.10. What
Table 6.9
Distances for the Service Center Example
Los New 
San
Boston Chicago Dallas Denver Angeles Miami York
Phoenix
Pittsburgh
Francisco
Seattle
Boston
0
983
1815
1991
3036
1539
213
2664
792
2385
2612
Chicago
983
0
1205
1050
2112
1390
840
1729
457
2212
2052
Dallas
1815
1205
0
801
1425
1332
1604
1027
1237
1765
2404
Denver
1991
1050
801
0
1174
2041
1780
836
1411
1765
1373
Los Angeles
3036
2112
1425
1174
0
2757
2825
398
2456
403
1909
Miami
1539
1390
1332
2041
2757
0
1258
2359
1250
3097
3389
New York
213
840
1604
1780
2825
1258
0
2442
386
3036
2900
Phoenix
2664
1729
1027
836
398
2359
2442
0
2073
800
1482
Pittsburgh
792
457
1237
1411
2456
1250
386
2073
0
2653
2517
San Francisco
2385
2212
1765
1765
403
3097
3036
800
2653
0
817
Seattle
2612
2052
2404
1373
1909
3389
2900
1482
2517
817
0 
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

should United Copiers do to minimize the total annual distance traveled by its service
representatives?
Objective
To develop a linear model, using binary variables, that determines the loca-
tions of service centers and then assigns customers to these service centers to minimize the
total annual distance traveled.
WHERE DO THE NUMBERS COME FROM?
The distances come directly from a map. The numbers of annual trips could be estimated
in several ways. For example, the company could multiply the number of customers in
each city by the estimated number of trips required per year per customer. However, this
might overestimate the total number of trips because a single trip can service multiple cus-
tomers. More likely, the company would estimate the numbers of trips in Table 6.10
directly from historical records. Finally, the number of service centers to use, in this case
three, is probably a policy decision based on cost. However, this number is an obvious can-
didate for sensitivity analysis.
Solution
The variables and constraints for this location-assignment model are listed in Table 6.11.
The keys to this model are the binary decision variables and the logical constraints. For
each city, a binary variable is used to indicate whether a service center is located there.
Also, for each pair of cities, a binary variable is used to indicate whether a service center in
the first city is assigned to the customer in the second city. Using these binary variables,
the first two constraints in the table are straightforward: Three cities should include service
centers, and each city should be assigned to exactly one service center. The last constraint
in the table is less obvious. It states that the number of cities that can be serviced by a given
city is less than or equal to a logical capacity. As you will see below, this logical capacity
is either 0 or 11 (the number of cities).
6.5 Set-Covering and Location-Assignment Models
325
Table 6.10 Estimated Numbers of Annual Trips to Customers
Los New 
San
Boston
Chicago
Dallas
Denver
Angeles
Miami
York
Phoenix
Pittsburgh
Francisco
Seattle
885
760
1124
708
1224
1152
1560
1222
856
1443
612
Table 6.11 Variables and Constraints for the Service Center Model
Input variables
Distances between cities, annual number of trips to each city, 
number of service centers to locate
Decision variables 
Whether each city includes a service center (binary), whether a city 
(changing cells)
is assigned to a particular service center (binary)
Objective (target cell)
Total distance traveled annually
Other calculated variables
Number of service center locations chosen, number of service 
centers assigned to each customer, total distance traveled to 
each customer
Constraints
Number of service center locations chosen  3
Number of service centers assigned to each customer  1
Number of cities serviced by a given city  Logical capacity 
If you already knew
where the service cen-
ters were located, this
would just be an
assignment problem 
of the type discussed i
n the previous chapter.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

1
Inputs. Enter the given data in the blue ranges.
2
Service center location decisions.
Enter any trial 0–1 values in the Include_
service_center range. For example, a 1 in cell D19 means a service center is located in
Dallas, whereas a 0 in cell E19 means no service center is located in Denver.
3
Assignment decisions. Enter any 0–1 trial values in the Assignments range. For
example, a 1 in cell D26 means that Denver is serviced by the center in Dallas, whereas a
0 in cell D27 means that Los Angeles is not serviced by the center in Dallas. At this point,
you might ask what these mean if there is no service center in Dallas. This is where the
logical capacities are necessary, as explained shortly. For now, you can anticipate that if
there is a 1 in some column of the Assignments range, the corresponding city will eventu-
ally include a service center.
DEVELOPING THE SPREADSHEET MODEL
The spreadsheet can be developed with the following steps. (See Figure 6.22 and the file
Locating Service Centers.xlsx.)8
326
Chapter 6
Optimization Models with Integer Variables
8We used a slightly different model in the previous edition. It had 121 upper bound constraints for the large block
of binary variables. To our surprise, this model was too large for Excel 2010’s Solver because of its new limit of
100 constraints. Fortunately, the alternative shown here works fine.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
A
B
C
D
E
F
G
H
I
J
K
L
M
N
O
P
C
Locang service centers and assigning service centers to customer
s - an alternave way of m
odeling the logical constraint
Distances between cies
Boston
Chicago
Dallas
Denver
Los Angeles
Miami
New York
Phoenix
Pisburgh
San Francisco
Seale
2
1
6
2
5
8
3
2
2
9
7
4
6
6
2
3
1
2
9
3
5
1
6
3
0
3
1
9
9
1
5
1
8
1
3
8
9
0
n
o
ts
o
B
2
5
0
2
2
1
2
2
7
5
4
9
2
7
1
0
4
8
0
9
3
1
2
1
1
2
0
5
0
1
5
0
2
1
0
3
8
9
o
g
a
cih
C
Dallas
1815
1205
0
801
1425
1332
1604
1027
1237
1765
2404
Denver
1991
1050
801
0
1174
2041
1780
836
1411
1765
1373
Los Angeles
3036
2112
1425
1174
0
2757
2825
398
2456
403
1909
Miami
1539
1390
1332
2041
2757
0
1258
2359
1250
3097
3389
New York
213
840
1604
1780
2825
1258
0
2442
386
3036
2900
Phoenix
2664
1729
1027
836
398
2359
2442
0
2073
800
1482
Pisburgh
792
457
1237
1411
2456
1250
386
2073
0
2653
2517
San Francisco
2385
2212
1765
1765
403
3097
3036
800
2653
0
817
0
7
1
8
7
1
5
2
2
8
4
1
0
0
9
2
9
8
3
3
9
0
9
1
3
7
3
1
4
0
4
2
2
5
0
2
2
1
6
2
eltt
a
e
S
Locaons of service centers
Boston
Chicago
Dallas
Denver
Los Angeles
Miami
New York
Phoenix
Pisburgh
San Francisco
Seale
Service centers
Max centers
Include service center
0
0
1
0
0
0
1
0
0
1
0
3
<=
3
Assignments (1 if customers along side are ser
viced by service center along top, 0 otherwise)
Boston
Chicago
Dallas
Denver
Los Angeles
Miami
New York
Phoenix
Pisburgh
San Francisco
Seale
Total assignments
Required
Boston
0
0
0
0
0
0
1
0
0
0
0
1
=
1
Chicago
0
0
0
0
0
0
1
0
0
0
0
1
=
1
1
=
1
0
0
0
0
0
0
0
0
1
0
0
s
alla
D
1
=
1
0
0
0
0
0
0
0
0
1
0
0
r
e
v
n
e
D
Los 
1
=
1
0
1
0
0
0
0
0
0
0
0
0
s
ele
g
n
A
1
=
1
0
0
0
0
1
0
0
0
0
0
0
i
m
ai
M
New 
1
=
1
0
0
0
0
1
0
0
0
0
0
0
kr
o
Y
1
=
1
0
1
0
0
0
0
0
0
0
0
0
xin
e
o
h
P
1
=
1
0
0
0
0
1
0
0
0
0
0
0
h
g
r
u
b
sttiP
San 
1
=
1
0
1
0
0
0
0
0
0
0
0
0
o
c
sic
n
a
r
F
Seale
0
0
0
0
0
0
0
0
0
1
0
1
=
1
Number serviced by
0
0
2
0
0
0
5
0
0
4
0
<=
<=
<=
<=
<=
<=
<=
<=
<=
<=
<=
Logical 
0
1
1
0
0
1
1
0
0
0
1
1
0
0
ytic
a
p
a
c
Numbers of annual trips to customers, and total distances (1000s of
:
d
e
s
u
 s
e
m
a
n
 e
g
n
a
R
sr
e
m
o
t
s
u
c 
o
t ylla
u
n
n
a 
d
ele
v
a
rt )
s
eli
m
 
Annual trips
Total distance
Assignments
=Model!$B$23:$L$33
Boston
885
189
Max_centers
=Model!$O$19
Chicago
760
638
Include_service_cen =Model!$B$19:$L$19
0
4
2
1
1
s
alla
D
Total_assignments
=Model!$M$23:$M$33
7
6
5
8
0
7
r
e
v
n
e
D
Logical_capacity
=Model!$B$36:$L$36
Los 
3
9
4
4
2
2
1
s
ele
g
n
A
Number_serviced_by=Model!$B$34:$L$34
9
4
4
1
2
5
1
1
i
m
ai
M
Service_centers
=Model!$M$19
New 
0
0
6
5
1
kr
o
Y
Total_distance
=Model!$B$53
8
7
9
2
2
2
1
xin
e
o
h
P
0
3
3
6
5
8
h
g
r
u
b
sttiP
San Francisco
1443
0
Seale
612
500
Objecve to minimize (1000s of miles)
Total distance
5145
These distances are 0 because the 
opmal soluon locates service 
centers in these cies.
Figure 6.22
Spreadsheet Model for the Service Center Problem
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

6.5 Set-Covering and Location-Assignment Models
327
4
Number of ser vice centers. Calculate the number of service centers with the
formula
=SUM(Include_service_center)
in cell M19. This just sums the 0–1 range, so it equals the number of 1s.
5
Number of service centers assigned to each city . Calculate the number of service
centers assigned to each city with row sums in the Total_assignments range in column M.
That is, enter the formula
=SUM(B23:L23)
in cell M23 and copy it down to cell M33. These row sums will eventually be constrained
to equal 1 to ensure that exactly one service center is assigned to each city.
6
Total annual distances.
Calculate the total annual distance traveled (in 1000s of
miles) to each city by entering the formula
=B40*SUMPRODUCT(B5:L5,B23:L23)/1000
in cell C40 for Boston and copying it down to cell C50 for the other cities. Note that this
SUMPRODUCT includes a row of distances from Boston and a row of assignments to cus-
tomers in Boston. This row of assignments will eventually include only a single 1—only a
single service center will be assigned to customers in Boston. Therefore, this SUMPROD-
UCT will be the distance between Boston and the service center assigned to Boston. It is
multiplied by the annual trips to Boston (cell B40) to obtain the total annual distance trav-
eled to Boston, and it is divided by 1000 to convert to thousands of miles.
7
Logical capacities. You need to ensure that only existing service locations can be
assigned to customers. One way to ensure this is to calculate column sums of the binary
variables in row 34. For example, the 2 in cell D34 indicates that two cities are serviced by
Dallas (Dallas and Denver). Then create the logical capacities in row 36 by entering the
formula
=11*B19 
in cell B36 and copying it across row 36. The effect is that if a binary value in row 19 is 0,
then no cities can be serviced by the corresponding city. For example, this is the case for
Boston. However, if the binary value in row 19 is 1, then the logical capacity is 11, the
number of cities, and this capacity constraint is essentially irrelevant.
8
Total annual distance tra
veled. Calculate the total distance traveled annually 
(in 1000s of miles) in cell B53 with the formula
=SUM(C40:C50)
USING SOLVER
The completed Solver dialog box is shown in Figure 6.23. You should also set the Solver
tolerance to 0%. (There is no need to check the Non-Negative option because all changing
cells are binary and hence non-negative.) 
Discussion of the Solution
The optimal solution in Figure 6.22 indicates that United Copiers should locate service
centers in Dallas, New York, and San Francisco. Of course, each of these centers services
the customers in its own city. In addition, the Dallas center services customers in Denver;
the New York center services customers in Boston, Chicago, Miami, and Pittsburgh;
Always be careful to
convert to appropriate
units of measurement,
if necessary.A factor
such as 100 or 1000
in a formula is often
evidence of a measure-
ment conversion.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

and the San Francisco center services customers in Los Angeles, Phoenix, and Seattle. The
total distance traveled annually is slightly over 5.1 million miles.
Sensitivity Analysis
A natural sensitivity analysis is to see how the service center locations and the total annual
distance change as we vary the number of required service centers. This is straightforward
with SolverTable. You should use cell O19 as the single input cell, vary it from 1 to 11 in
increments of 1, and keep track of the binary values in row 19 and the target cell. The
results are shown in Figure 6.24. As you can see, service centers are typically located in
Dallas, New York, and San Francisco, but not always. In particular, if only one service cen-
ter is allowed, it should be located in Dallas, but if two service centers are allowed, they
should be located in New York and Phoenix. Of course, when there are more service cen-
ters, less traveling is required. At the extreme, if a service center is located in every city, no
traveling is required at all.
328
Chapter 6
Optimization Models with Integer Variables
Figure 6.23
Solver Dialog Box
for the Service
Center Model
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
A
B
C
D
E
F
G
H
I
J
K
L
M
Oneway analysis for Solver model in Model worksheet
Max centers (cell $O$19) values along side, output cell(s) along top
Boston
Chicago
Dallas
Denver
Los Angeles
Miami
New York
Phoenix
Pisburgh
San Francisco
Seale
Total_distance
1
0
0
1
0
0
0
0
0
0
0
0
15202
2
0
0
0
0
0
0
1
1
0
0
0
6901
3
0
0
1
0
0
0
1
0
0
1
0
5145
4
0
0
1
0
0
1
1
0
0
1
0
3695
5
0
0
1
0
1
1
1
0
0
1
0
2711
6
0
1
1
0
1
1
1
0
0
1
0
2072
7
0
1
1
1
1
1
1
0
0
1
0
1505
8
0
1
1
1
1
1
1
0
0
1
1
1005
9
0
1
1
1
1
1
1
1
0
1
1
519
10
0
1
1
1
1
1
1
1
1
1
1
189
11
1
1
1
1
1
1
1
1
1
1
1
0
Figure 6.24
Sensitivity to Number of Service Centers Allowed
■
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

The final example in this section is structurally similar to the service center location
model, but it arises in a slightly different business context.9
6.5 Set-Covering and Location-Assignment Models
329
E X A M P L E
6.6 MANUFACTURING AND DISTRIBUTING FERTILIZER AT GREEN GRASS
Like the previous
example, this example
is basically a fixed-cost
location-assignment
model. However, one
difference here is that
not all customers need
to be assigned.
T
he Green Grass Company manufactures and distributes a fertilizer product. The
company sells its product to high-volume customers in various U.S. cities where it
has manufacturing plants, but it can decide to operate only some of these plants in any
given month. The fixed monthly cost for operating any plant is $60,000, the plant
capacity for any operating plant is 2500 pounds per month, and the production cost at
any operating plant is $10.25 per pound. After the product is manufactured, it is
shipped to customers at a rate of $0.02 per pound per mile. The cities and the dis-
tances between them are listed in Table 6.12. The customers submit order sizes and
price bids to Green Grass, as listed in Table 6.13. For example, the customer in Boston
requires an order of 1430 pounds this month and is willing to pay $75,740 for it.
Green Grass can decide to fill this order or not. If not, you can assume that the cus-
tomer takes its business to another company. For the current month, Green Grass must
decide which plants to operate and which customers to service from which operating
plants to maximize its monthly profit.
9This example is based on a real problem Winston was asked to solve during a consulting experience with a major
U.S. manufacturing company.
Table 6.12 Distances Between Cities for the Green Grass Example
Boston
Chicago
Dallas
Denver
Los Angeles
Miami
New York
Phoenix
Boston
0
983
1815
1991
3036
1539
213
2664
Chicago
983
0
1205
1050
2112
1390
840
1729
Dallas
1815
1205
0
801
1425
1332
1604
1027
Denver
1991
1050
801
0
1174
2065
1780
836
Los Angeles
3036
2112
1425
1174
0
2757
2825
398
Miami
1539
1390
1332
2065
2757
0
1258
2359
New York
213
840
1604
1780
2825
1258
0
2442
Phoenix
2664
1729
1027
836
398
2359
2442
0 
Table 6.13 Orders and Price Bids for the Green Grass Example
Quantity
Price
Boston
1430
$75,740
Chicago
870
$44,370
Dallas
770
$46,320
Denver
1140
$87,780
Los Angeles
700
$43,850
Miami
830
$21,000
New York
1230
$74,850
Phoenix
1070
$83,980 
Objective
To develop a binary model to help Green Grass decide which manufacturing
plants to operate and which customer orders to fill from which operating plants.
WHERE DO THE NUMBERS COME FROM?
The distances in Table 6.12 are well known, and the customers can supply the data in
Table 6.13. Cost accountants can supply the fixed cost of operating a plant, the variable
production cost per pound, and the unit shipping cost per mile.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Solution
The variables and constraints for the Green Grass model are listed in Table 6.14. As in the
previous example, there are two sets of binary variables. The first set indicates which
plants are open for operation. The second set indicates which customers are supplied by
which plants. The first constraint in the table ensures that no customer is supplied by more
than one plant. However, it allows the possibility that the customer is not supplied by any
Green Grass plant. The second constraint ensures that no plant produces and ships more
than a logical capacity. This logical capacity is 0 if the plant is not opened at all, and it is
the 2500-pound limit if the plant is opened. With these changing cells and constraints, the
company must decide which plants to open and which customers to supply from which
open plants to maximize profit.
330
Chapter 6
Optimization Models with Integer Variables
Table 6.14 Variables and Constraints for the Green Grass Model
Input variables
Fixed cost of operating a plant, production cost per pound, 
shipping cost per pound per mile, plant capacities, 
distance matrix, customer order sizes, and price bids
Decision variables 
Which plants to open (binary), which customers to supply from 
(changing cells)
which open plants (binary)
Objective (target cell)
Monthly profit
Other calculated 
Pounds shipped out of each plant, logical capacity of each plant, 
variables
number of plants shipping to each customer, revenue minus 
production and shipping cost for each plant/customer pair, 
total fixed plant cost
Constraints
Plants supplying each customer  1
Pounds shipped out of each plant  Logical plant capacity
DEVELOPING THE SPREADSHEET MODEL
The completed spreadsheet model appears in Figure 6.25. (See the file Fixed Cost
Transportation.xlsx.) It can be developed with the following steps:
1
Inputs. Enter the inputs in the blue ranges.
2
Plant opening decisions. Enter any set of 0s and 1s in the Open_plant range. These
changing cells indicate which plants to open.
3
Assignment decisions. Enter any set of 0s and 1s in the Assignments range. Each
changing cell in this range indicates whether a particular plant supplies a particular
customer.
4
Plants supplying customers. Each customer can be supplied by at most one plant.
To see how many plants are supplying each customer, create row sums of the Assignments
range. That is, enter the formula
=SUM(B26:I26)
in cell J26 and copy it down to cell J33. Each such sum is just the number of 1s in that row
of the Assignments range.
5
Amounts produced at plants. We assume that if a plant is assigned to supply any
customer, its production for that customer equals the customer’s order requirement. Then
to calculate the total produced (and shipped out) for each plant, enter the formula
=SUMPRODUCT(B26:B33,$L$11:$L$18)
in cell B34 for the first plant and copy it across row 34 for the other plants.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

6
Logical plant capacities. If a plant is not open, its capacity is 0. If it is open, its
capacity is 2500. To calculate these effective plant capacities, enter the formula
=$B$7*B22
in cell B36 and copy it across row 36. The binary value in this formula reduces effective
capacity to 0 or keeps it at 2500. (Note that the logic used here is very similar to the logic
in the Great Threads fixed-cost model in Example 6.2. The only difference is that there is
now a natural capacity, 2500, in case the plant is opened. In the Great Threads example,
you had to calculate a suitable upper limit on production.)
7
Revenues and variable costs. It is useful to calculate a matrix of revenues and costs
for all pairs of cities. To calculate these, enter the formula
=B26*($M11-$L11*($B$4+$B$5*B11))
in cell B41 and copy it to the range B41:I48. The first term in this formula is the binary
assignment variable. If it is 0, no revenues or costs are incurred on this route because the
route isn’t used. However, if this binary value is 1, the formula subtracts costs from
revenue. (Be careful to check the measurement units in these types of calculations. The
production cost is pounds multiplied by cost per pound. The shipping cost is pounds mul-
tiplied by miles multiplied by cost per pound per mile.)
6.5 Set-Covering and Location-Assignment Models
331
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
M
L
K
J
I
H
G
F
E
D
C
B
A
Fixed cost logiscs model with customer bids for orders
Range names used:
Assignments
=Model!$B$26:$I$33
Inputs
Logical_capacity
=Model!$B$36:$I$36
Producon cost per pound
$10.25
Number_serviced_by
=Model!$J$26:$J$33
Shipping cost per pound per mile
$0.02
Open_plant
=Model!$B$22:$I$22
Monthly plant ﬁxed cost
$60,000
Pounds_shipped_out_of
=Model!$B$34:$I$34
Plant capacity (pounds)
2500
Total_monthly_proﬁt
=Model!$B$51
Distance matrix
Quanes required and prices bid by customers
Boston
Chicago
Dallas
Denver
e
cir
P
ytit
n
a
u
Q
xin
e
o
h
P
Y
N
i
m
ai
M
A
L
0
4
7,5
7
$
0
3
4
1
n
o
ts
o
B
4
6
6
2
3
1
2
9
3
5
1
6
3
0
3
1
9
9
1
5
1
8
1
3
8
9
0
n
o
ts
o
B
0
7
3,4
4
$
0
7
8
o
g
a
cih
C
9
2
7
1
0
4
8
0
9
3
1
2
1
1
2
0
5
0
1
5
0
2
1
0
3
8
9
o
g
a
cih
C
0
2
3,6
4
$
0
7
7
s
alla
D
7
2
0
1
4
0
6
1
2
3
3
1
5
2
4
1
1
0
8
0
5
0
2
1
5
1
8
1
s
alla
D
Denver
e
v
n
e
D
6
3
8
0
8
7
1
5
6
0
2
4
7
1
1
0
1
0
8
0
5
0
1
1
9
9
1
r
1140
$87,780
0
5
8,3
4
$
0
0
7
A
L
8
9
3
5
2
8
2
7
5
7
2
0
4
7
1
1
5
2
4
1
2
1
1
2
6
3
0
3
A
L
0
0
0,1
2
$
0
3
8
i
m
ai
M
9
5
3
2
8
5
2
1
0
7
5
7
2
5
6
0
2
2
3
3
1
0
9
3
1
9
3
5
1
i
m
ai
M
0
5
8,4
7
$
0
3
2
1
Y
N
2
4
4
2
0
8
5
2
1
5
2
8
2
0
8
7
1
4
0
6
1
0
4
8
3
1
2
Y
N
0
8
9,3
8
$
0
7
0
1
xin
e
o
h
P
0
2
4
4
2
9
5
3
2
8
9
3
6
3
8
7
2
0
1
9
2
7
1
4
6
6
2
xin
e
o
h
P
Which plants to open
Boston
Chicago
Dallas
Denver
LA
Miami
NY
Phoenix
Open 
1
t
n
alp
0
0
1
0
0
1
1
Which customers (along side) to ship to from which plants (along top)
Boston
Chicago
Dallas
Denver
LA
Miami
NY
Phoenix
Number supplied 
d
e
w
oll
A
y
b
1
n
o
ts
o
B
1
=
<
1
0
0
0
0
0
0
0
0
o
g
a
cih
C
1
=
<
1
0
1
0
0
0
0
0
0
s
alla
D
1
=
<
1
0
0
0
0
1
0
0
Denver
1
=
<
1
0
0
0
0
1
0
0
0
1
=
<
1
1
0
0
0
0
0
0
0
A
L
0
i
m
ai
M
1
=
<
0
0
0
0
0
0
0
0
1
=
<
1
0
1
0
0
0
0
0
0
Y
N
0
xin
e
o
h
P
1
=
<
1
1
0
0
0
0
0
0
Pounds shipped out 
0
7
7
1
0
0
1
2
0
0
0
1
9
1
0
0
0
3
4
1
f
o
<=
<=
<=
<=
<=
<=
<=
<=
Logical 
0
0
5
2
0
0
5
2
0
0
0
0
5
2
0
0
0
0
5
2
ytic
a
p
a
c
Monetary outputs
Matrix of revenue minus sum of producon and shipping cost for each customer (along side) and plant (along top) pair
Boston
Chicago
Dallas
Denver
LA
Miami
NY
Phoenix
0
$
0
$
0
$
0
$
0
$
0
$
0
$
3
8
0,1
6
$
n
o
ts
o
B
0
$
7
3
8,0
2
$
0
$
0
$
0
$
0
$
0
$
0
$
o
g
a
cih
C
0
$
0
$
0
$
0
$
2
9
0,6
2
$
0
$
0
$
0
$
s
alla
D
Denver
$0
$0
$0
$76,095
$0
$0
$0
$0
3
0
1,1
3
$
0
$
0
$
0
$
0
$
0
$
0
$
0
$
A
L
0
$
0
$
0
$
0
$
0
$
0
$
0
$
0
$
i
m
ai
M
0
$
3
4
2,2
6
$
0
$
0
$
0
$
0
$
0
$
0
$
Y
N
3
1
0,3
7
$
0
$
0
$
0
$
0
$
0
$
0
$
0
$
xin
e
o
h
P
Monthly ﬁxed cost
$240,000
Total monthly proﬁt
$110,464
Figure 6.25
Green Grass Production/Shipping Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

8
Fixed costs. Each 1 in the Open_plant range adds a fixed cost. To calculate the total
fixed cost, enter the formula
=B6*SUM(Open_plant)
in cell B50. This is the number of open plants multiplied by the fixed cost per plant.
9
Monthly profit. Calculate the monthly profit in cell B51 with the formula
=SUM(B41:I48)-B50
USING SOLVER
The Solver dialog box is shown in Figure 6.26. As usual, you should select the Simplex LP
method, but you do not need to check the Non-Negative option because all changing cells
are constrained to be binary, hence nonnegative. The last constraint ensures that each plant
produces nothing if it isn’t open, and no more than its capacity if it is open. The second
constraint ensures that each customer’s demand is satisfied by at most one plant. This
allows the possibility that a customer’s demand is not satisfied by Green Grass at all.
332
Chapter 6
Optimization Models with Integer Variables
Figure 6.26
Solver Dialog Box
for the Green Grass
Model
Discussion of the Solution
The optimal solution in Figure 6.25 indicates that the company should open four plants:
Boston (to supply the Boston customer), Denver (to supply the Denver and Dallas cus-
tomers), New York (to supply the New York and Chicago customers), and Phoenix (to sup-
ply the Phoenix and Los Angeles customers). In addition, the model indicates that Green
Grass should not supply the Miami customer at all. You can see the main reason for this if
you calculate the ratio of order size to price bid for each customer. Miami’s ratio is well
below the others. Therefore, it is evidently not profitable to supply the Miami customer.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Sensitivity Analysis
One possible sensitivity analysis is to see how much larger Miami’s price bid needs to be
before Green Grass supplies it. We tried this, varying Miami’s price bid and keeping track
of the row sum in cell J31 that indicates whether Miami is supplied. The results (after some
trial and error to find an interesting price bid range) appear in Figure 6.27. When the
Miami price bid increases to some value between $31,000 and $32,000, it becomes prof-
itable to supply Miami. (You can check, by rerunning Solver, that Miami is then supplied
by New York.)
6.5 Set-Covering and Location-Assignment Models
333
1
2
3
4
5
6
7
8
9
10
11
12
A
B
C
D
E
F
G
Oneway analysis for Solver model in Model worksheet
Miami bid price (cell $M$16) values along side, output cell(s) along top
Number_serviced_by_Miami
$28,000
0
$29,000
0
$30,000
0
$31,000
0
$32,000
1
$33,000
1
$34,000
1
$35,000
1
Figure 6.27
Sensitivity to
Miami’s Price Bid
Another possible sensitivity analysis is on the common plant capacity, currently
2500 pounds. The optimal solution in Figure 6.25 indicates that capacity is not currently a
constraining factor. Four of the plants are open, and all are operating well under capacity.
Therefore, an increase in the common capacity has absolutely no effect, and a slight
decrease (down to 2100, the highest plant production) also has no effect. However, any
decrease below 2100 should have an effect. This is explored in Figure 6.28, where the
common plant capacity is varied and the optimal total fixed cost and profit are outputs. As
you can see, if the capacity is below 2100, the total profit decreases. However, the total
fixed cost remains constant, at least for this range of capacities. This implies that all of
1
2
3
4
5
6
7
8
9
A
B
C
D
E
F
Oneway analysis for Solver model in Model worksheet
Plant capacity (cell $B$7) values along side, output cell(s) along top
Monthly ﬁxed cost
Total_monthly_proﬁt
1500
$240,000
$32,433
1750
$240,000
$32,433
2000
$240,000
$89,628
2250
$240,000
$110,464
2500
$240,000
$110,464
Figure 6.28
Sensitivity to
Common Plant
Capacity
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

these solutions keep four plants open. How does the optimal solution change? Although
the results in Figure 6.28 do not provide the answer, you can rerun Solver with any of these
capacities to find out. It turns out that the same four plants stay open but supply fewer cus-
tomers. For example, when the common capacity is 1500 or 1750, the four plants supply
only the customers in their respective cities.
If you run these sensitivity analyses with SolverTable, you will immediately notice the
longer computing times. These are difficult problems, even for Solver, and you won’t get the
immediate solutions you are accustomed to. Each problem has 272 possible binary solutions
(because there are 72 binary changing cells), which is an enormous number of potential
solutions for Solver to sort through with its branch and bound algorithm. Although a binary
model of this type and size is still well within Solver’s capabilities, this example should con-
vince you that not all management science optimization models are easy to solve. ■
334
Chapter 6
Optimization Models with Integer Variables
1.
We have assumed that all possible plant locations are in the same cities as the customers.
This is not necessary. There could be any number of customers at one set of locations
and any other number of plant locations at another set of locations. As long as the dis-
tances from each plant to each customer are known, the model changes hardly at all.
2.
We have assumed that the inputs in the range B4:B7 (see Figure 6.25) are constant,
the same for each plant or plant–customer pair. This is also not necessary. If these
inputs differ across plants or plant–customer pairs, more input values must be esti-
mated by the cost accountants, but modifications to the model itself are minimal.
3.
We currently assume that the plants in the various locations are already built, and it is
just a matter of which to open each month. Suppose instead that the company is expand-
ing and must decide where (or whether) to build new plants. Then there is a one-time
fixed cost of building each new plant, in addition to the fixed cost of opening an existing
plant in the example. Unfortunately, combining these costs is not a trivial matter. The
fixed cost of building must be amortized over some period of time so that it can be com-
bined correctly with the monthly revenues and costs in the current model.
■
MODELING ISSUES
P R O B L E M S
Skill-Building Problems
24. In the original Western set-covering model in
Figure 6.18, we used the number of hubs as the objec-
tive to minimize. Suppose instead that there is a fixed
cost of locating a hub in any city, where these fixed
costs can possibly vary across cities. Make up some
reasonable fixed costs, modify the model appropri-
ately, and use Solver to find the solution that mini-
mizes the sum of fixed costs.
25. In the original Western set-covering model in
Figure 6.18, we assumed that each city must be cov-
ered by at least one hub. Suppose that for added flexi-
bility in flight routing, Western requires that each city
must be covered by at least two hubs. How do the
model and optimal solution change?
26. Set-covering models such as the original Western
model in Figure 6.18 often have multiple optimal
solutions. See how many alternative optimal solutions
you can find. Of course, each must use three hubs
because  this is optimal. (Hint: Use various initial
values in the changing cells and then run Solver 
repeatedly.)10 
27. How hard is it to expand a set-covering model to ac-
commodate new cities? Answer this by modifying the
model in Figure 6.21. (See the file Locating Hubs
2.xlsx.) Add several cities that must be served: Memphis,
10One of our colleagues at Indiana University, Vic Cabot, now deceased, worked for years trying to develop a
general algorithm (other than trial and error) for finding all alternative optimal solutions to optimization models.
It turns out that this is a very difficult problem—and one that Vic never totally solved.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Dallas, Tucson, Philadelphia, Cleveland, and Buffalo. You
can look up the distances from these cities to each other
and to the other cities in a reference book (or on the
Web), or you can make up approximate distances.
a. Modify the model appropriately, assuming that
these new cities must be covered and are candi-
dates for hub locations.
b. Modify the model appropriately, assuming that
these new cities must be covered but are not
candidates for hub locations.
28. In the United Copiers service center model, we assumed
that the potential locations of service centers are the
same as existing customer locations. Change the model
so that the customer locations are the ones given, but the
only potential service center locations are in Memphis,
Houston, Cleveland, Buffalo, Minneapolis, St. Louis,
and Kansas City. You can look up the distances from
these cities to the customer cities in a reference book (or
on the Web), or you can make up approximate distances.
Use Solver to find the optimal solution.
29. In the United Copiers service center model, we used
total distance traveled as the objective to minimize.
Suppose in addition that there is an annual fixed cost of
locating a service center in any city, where this fixed
cost can vary across cities. There is also a cost per mile
of traveling. Modify the current model to make total
annual cost the objective to minimize. You can make up
reasonable fixed costs and unit traveling costs.
30. In the Green Grass shipping model, we assumed that
certain inputs (see the range B4:B7 in Figure 6.25) are
the same for all plants or plant–customer combina-
tions. Change this so that the unit production cost, the
monthly fixed cost, and the monthly capacity can vary
by plant, and the unit shipping cost can vary by
plant–customer combination. (You can make up data
that vary around the values in the B4:B7 range.) Use
Solver to find the new optimal solution.
31. In the optimal solution to the Green Grass shipping
model, the Miami customer’s order is not satisfied.
Suppose that Green Grass decides, as a matter of pol-
icy, to satisfy each customer’s order (at the customer’s
bid price). How much profit will the company lose
from this policy decision?
32. In the Green Grass shipping model, use SolverTable to
perform a sensitivity analysis on the fixed cost of
opening a plant, letting it vary over some reasonable
6.6 Cutting Stock Models
335
range that extends below and above the current value
of $60,000. Keep track of enough outputs so that you
can see the effect on the plants that are opened and the
customers whose orders are satisfied, as well as on the
total profit. Summarize your findings in words.
Skill-Extending Problems
33. In the United Copiers service center model, we assumed
that a customer is serviced totally by a single service
center. Suppose a customer can be serviced partly by
multiple service centers. For example, the customer in
Denver could get half of its service from Dallas and the
other half from San Francisco. In this case, you can
assume that half of Denver’s annual trips would be
made from Dallas reps and half by San Francisco reps.
Modify the model appropriately and then solve it with
Solver. How do you interpret the optimal solution?
(Hint: Allow the changing cells in the Assignments
range to be fractional values between 0 and 1.)
34. In the Green Grass shipping model, we assumed that
the plants are already built, so that in each month, the
only decision is whether to open particular plants 
(at a monthly fixed cost). Consider instead a general
location-shipping model of this type where the plants
are not yet built. The company must first decide where
to build plants, then how much to produce at the plants,
and finally which customers to service from them. The
problem is that the building costs are one-time costs,
whereas other costs are monthly. How can you recon-
cile these two types of costs? What should you use as
an objective to minimize? Illustrate your procedure on
the Green Grass example, where the plant opening
fixed costs are ignored—we assume that all plants that
are built will remain open—but building costs (which
you can make up) are given.
35. In the Green Grass shipping model, we currently
assume that if a customer’s order is satisfied, it must
be satisfied from a single plant. Suppose instead that it
can be satisfied from more than one plant. For exam-
ple, if the company decides to satisfy Dallas’s order, it
could ship part of this order from Denver and part
from Phoenix (or some other combination of open
plants). Continue to assume, however, that the com-
pany must satisfy either all or none of each customer’s
order. Modify the model appropriately and use Solver
to solve it. Does the solution change?
6.6 CUTTING STOCK MODELS
The final model we discuss in this chapter has found many real-world applications, espe-
cially in manufacturing. The model is relevant in situations where a product is produced in
a standard size, which must then be cut into one of several patterns to satisfy customer
orders. In contrast to the other models in this chapter, this cutting stock model does not
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

have binary variables, but it does have integer variables. The problem is relatively easy to
model, but it can be very time-consuming for Solver to solve. We warned you earlier that
IP models are inherently more difficult to solve than general LP problems. The model in
the following example illustrates that this is definitely the case.
336
Chapter 6
Optimization Models with Integer Variables
E X A M P L E  
6.7 CUTTING PAPER ROLLS AT RHEEM PAPER
T
he Rheem Paper Company produces rolls of paper of various types for its customers.
One type is produced in standard rolls that are 60 inches wide and (when unwound)
200 yards long. Customers for this type of paper order rolls that are all 200 yards long, but
can have any of the widths 12, 15, 20, 24, 30, or 40 inches. In a given week, Rheem waits
for all orders and then decides how to cut its 60-inch rolls to satisfy the orders. For exam-
ple, if there are five orders for 15-inch widths and two orders for 40-inch widths, Rheem
could satisfy the order by producing three rolls, cutting each of the first two into a 40-inch
and a 15-inch cut (with 5 inches left over) and cutting the third into four 15-inch cuts (with
one of these left over). Each week, Rheem must decide how to cut its rolls in the most eco-
nomical way to meet its orders. Specifically, it wants to cut as few rolls as possible.
Objective
To find a way of cutting paper rolls in various widths so as to satisfy all cus-
tomer orders and minimize the total number of rolls cut.
WHERE DO THE NUMBERS COME FROM?
The company knows the various widths its customers need, and it knows the orders for the
various widths in the current week.
Solution
Given the width of the rolls (60 inches) and the available widths (12, 15, 20, 24, 30, and
40), the first thing to do in this model is to “preprocess” the patterns that might be used.
For example, one reasonable pattern is to cut a roll into four 15-inch cuts. In fact, this is
perfect—there is no waste. Another pattern is to cut a roll into a 12-inch, a 15-inch, and a
24-inch cut, with 9 inches left over and unusable. The only patterns we consider (the
feasible patterns) are the ones with no leftover paper that could be used for customer
orders. For example, the pattern of a 12-inch cut and a 30-inch cut is not worth considering
because another 12-inch (or 15-inch) cut could be obtained from the remainder. There is no
model for determining all feasible patterns. You simply need to go through all the possibil-
ities in a systematic way. After all possible patterns have been listed, the problem is then to
decide how many rolls to cut into each pattern.
With this in mind, Table 6.15 lists the variables and constraints required for this
model.
Table 6.15 Table of Variables and Constraints for the Cutting Stock Model
Input variables
Width of roll, number of rolls of possible widths required by 
customers, list of patterns roll can be cut into (must be obtained 
manually)
Decision variables 
Number of rolls cut for each pattern (integer)
(changing cells)
Objective (target cell)
Number of rolls cut total
Other output cells
Number of each width obtained
Constraints
Number of each width obtained  Number of each width required
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

DEVELOPING THE SPREADSHEET MODEL
The spreadsheet model appears in Figure 6.29. (See the file Cutting Stock.xlsx .) To
develop it, follow these steps:
1
Inputs. Enter the roll width, the available widths, and the number of orders for each
width in the blue ranges. The orders in the Required range (row 42) will change from week
to week, but the same model can handle any values in this range.
2
Patterns. Enter the feasible patterns in columns B through G, starting in row 10. The
numbers in each row indicate how many of each width is in the pattern. For example, the
first pattern has five 12-inch cuts with no waste. You can calculate the waste in column H
by entering the formula
=$B$3-SUMPRODUCT(B$9:G$9,B10:G10)
and copying down. This waste column is useful as you try to list all feasible patterns.
Specifically, the waste must be nonnegative, and it must be no greater than 12, the smallest
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
A
B
C
D
E
F
G
H
I
J
K
Cung stock 
e
g
n
a
R
le
d
o
m
 names used:
Obtained
=Model!$B$40:$G$40
Width of roll
60   
2
4
$
G
$:2
4
$
B
$
!le
d
o
M
=
d
e
riu
q
e
R
s
e
h
c
ni
Rolls_cut
=Model!$K$10:$K$35
Widths available
12
15
20
24
30
40
Total_rolls_cut =Model!$B$45
Feasible ways of cung up a roll
Decisions
Paern
12
15
20
24
30
40
Waste
Paern
Rolls cut
0
1
0
0
0
0
0
0
5
1
0
2
9
0
0
0
0
1
3
2
0
3
4
0
0
0
1
0
3
3
2
1
4
0
0
0
1
0
0
3
4
0
5
6
0
0
0
0
2
2
5
1
6
1
0
0
0
1
1
2
6
0
7
6
0
1
0
0
0
2
7
0
8
3
0
0
0
0
3
1
8
0
9
9
0
0
1
0
1
1
9
1
0
1
3
0
1
0
0
1
1
0
1
0
1
1
8
0
0
0
2
0
1
1
1
0
2
1
4
0
0
1
1
0
1
2
1
9
3
1
0
0
0
2
0
0
1
3
1
0
4
1
8
1
0
0
0
0
1
4
1
1
5
1
0
0
0
0
0
4
0
5
1
1
6
1
0
1
0
0
0
1
2
0
6
1
0
7
1
6
0
0
1
0
2
0
7
1
4
8
1
0
0
1
0
0
2
0
8
1
2
9
1
5
0
0
0
2
1
0
9
1
2
0
2
1
0
0
1
1
1
0
0
2
0
1
2
5
1
0
0
0
1
0
1
2
2
2
2
0
0
0
0
3
0
0
2
2
1
3
2
0
1
0
1
0
1
0
0
3
2
7
4
2
0
1
0
0
1
0
0
4
2
0
5
2
6
0
1
1
0
0
0
5
2
4
6
2
0
0
2
0
0
0
0
6
2
Constraint on sasfying orders
12
15
20
24
30
40
Obtained
48
20
22
32
14
7
>=
>=
>=
>=
>=
>=
Required
48
19
22
32
14
7
Objecve to minimize
Total rolls cut
47
Width
Width
Figure 6.29
Cutting Stock Model
6.6 Cutting Stock Models
337
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

available width. (If the waste were 12 or greater, it would be possible to get another usable
cut from the pattern.) For this particular roll width and this particular set of available widths,
there are 26 feasible patterns. (You have to be careful when listing them. It is easy to miss
some.)
3
Decision variables. Enter any values into the Rolls_cut range. These are the decision
variables in this model. They indicate how many rolls to cut into the various patterns.
4
Widths obtained. Calculate the number of each width obtained by entering the
formula
=SUMPRODUCT(Rolls_cut,B10:B35)
in cell B40 and copying it to the rest of the Obtained range. For example, the value in cell
B40 is the number of rolls of width 12 inches obtained from all possible patterns.
5
Rolls cut. Calculate the number of rolls cut in cell B45 with the formula
=SUM(Rolls_cut)
USING SOLVER
Fill out the Solver dialog box as indicated in Figure 6.30. The objective is to minimize the
number of rolls produced, subject to meeting customer orders. Also, the number cut
according to each pattern must be an integer (but not binary). As usual, you should check
the Non-Negative option and choose the Simplex LP method.
Discussion of the Solution
The solution indicates that Rheem can meet its customer orders this week with 47 rolls, cut
as specified in rows 10 through 35. For example, 12 of the 47 rolls should be cut according
to pattern 4, each with three 12-inch rolls and one 24-inch roll. (There is at least one other
optimal solution with objective value 47 that you might find.) Note that there are two
338
Chapter 6
Optimization Models with Integer Variables
Figure 6.30
Solver Dialog Box
for the Cutting Stock
Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

sources of waste in this solution. First, there is the unusable waste from all leftover rolls
with width less than 12 inches. For example, there are two 1-inch rolls left over from the
two rolls cut into pattern 20. Second, there is some waste from the usable rolls that are not
needed in this week’s orders. Fortunately, it is minimal—only one 15-inch roll is left over.
Actually, if Rheem solves this model on a weekly basis, the model could easily incorporate
the inventory of usable leftover rolls from previous weeks.
Solver Tolerance Setting
Until now, we have suggested setting the Solver tolerance to 0%. This guarantees the opti-
mal solution. However, this example illustrates why the default tolerance setting is 5% (or
at least not 0%). If you set the tolerance to 0% and click on Solve, you will see that Solver
quickly gets to a solution that requires 47 rolls, but then it runs and runs and runs. (We got
tired of waiting, so we pressed the Ctrl+Break key combination to stop it prematurely.)
After some experimenting, we found that with the tolerance set at 2% or above, the solu-
tion is obtained almost instantaneously, but with the tolerance set at 1% or 0%, it runs
seemingly forever. This behavior is not at all uncommon in IP models. Solver often finds a
very good or even optimal solution very quickly, but then it takes a long time to verify that
it is optimal (or to find something slightly better). The moral is clear. If you set the toler-
ance to a low value and find that the Solver is taking forever without getting anywhere,
press Ctrl+Break to get out. By that time, you probably already have a very good or even
optimal solution. ■
6.6 Cutting Stock Models
339
We did not perform any sensitivity analysis on this model because there is no obvious sen-
sitivity analysis to perform. The only inputs are the roll width, the set of available widths,
and the order amounts. Although it would make sense to perform sensitivity analysis on
the order amounts, it would make more sense (in a realistic setting) to wait for next week’s
orders and simply solve the problem again. Note that the model is not set up to perform
sensitivity analysis (with SolverTable) on the roll width or the set of available widths. If
these change, the entire table of patterns must be recreated manually. For example, if the
roll width changes to 64 inches, patterns 2, 9, 11, 14, 16, and 23 are no longer in the list
(why not?), and several new patterns enter the list (what are they?).
■
MODELING ISSUES
P R O B L E M S
Skill-Building Problems
36. In the cutting stock example, we minimized the total
number of rolls cut. Do you get the same solution if
you minimize the total inches of waste? For example,
given the solution in Figure 6.29, this waste includes
2 inches from pattern 6, 12 inches from the extra
12-inch roll produced (in cell B40), and a couple of
others. Solve the problem with this objective.
37. Woodco sells 3-foot, 5-foot, and 9-foot pieces of lum-
ber. Woodco’s customers demand 25 3-foot boards,
20 5-foot boards, and 15 9-foot boards. Woodco meets
its demands by cutting up 17-foot boards. How can it
satisfy its customers’ demands with the least amount
of waste? Assume that all boards are the same width
and thickness.
Skill-Extending Problem
38. The Mayfree Appliance Company requires sheet metal
for its appliances. The company can purchase long
coils of sheet metal in two different widths: 65 inches
and 40 inches. The company must purchase the coils
by linear foot of length: $1.20 per foot for a 64-inch
coil and $1.00 per foot for a 40-inch coil. (This
implies that a square foot, say, of the wider coil is less
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

expensive.) Up to 4000 feet of the 65-inch coil is
available, and up to 6000 feet of the 40-inch coil is
available. There are manufacturing requirements for
six different widths: 50, 45, 40, 35, 20, and 10 inches.
Mayfree’s requirements are expressed as lengths of the
various widths. The company requires 1000 feet of 
50-inch width, 2500 feet of 45-inch width, 3000 feet
of 40-inch width, 2300 feet of 35-inch width, 
1300 feet of 20-inch width, and 2000 feet of 10-inch
width. Determine how much of each width coil Mayfree
should purchase and how it should cut the coils into
various widths to meet its requirements at minimal cost.
(Hint: First, list all patterns that can be cut from a 
65-inch coil, and do the same for a 40-inch coil. Then
have a changing cell for each pattern that designates the
number of linear feet to be cut in this pattern.)
340
Chapter 6
Optimization Models with Integer Variables
6.7 CONCLUSION
Three important points emerge from this chapter.
■
A wide variety of important problems can be modeled as IP problems with binary
variables. These can generally be identified as problems where at least some of the
activities (such as making a particular investment, opening a particular plant, or
supplying a customer from a particular plant) must be done or not done; there is no
in-between. Regular LP models cannot handle these problems; IP models with binary
variables often can.
■
Some IP models are simply LP models with integer constraints on the variables. For
example, you might constrain the number of refrigerators produced to be an integer.
These problems can often be solved by solving the associated LP model and then
rounding the solution to integer values. Although there is no guarantee that the
rounded solution is optimal, it is often close enough. In contrast, most of the problems
discussed in this chapter introduce binary decision variables that specify whether an
activity is done or not. If you ignore the binary constraints and only constrain these
variables to be between 0 and 1, it is generally impossible to find the optimal solution
by rounding.
■
The solution approach required for IP problems, especially those with 0–1 variables,
is inherently more difficult than the simplex method for LP problems. The relatively
small examples in this chapter might give the impression that a spreadsheet Solver can
handle IP models just as easily as it handles LP models, but this is definitely not the
case. In fact, even with the most sophisticated IP computer codes on the most power-
ful computers, there are IP problems—from real applications—that defy solution.
Analysts typically employ heuristic methods on these really difficult problems.
Summary of Key Management Science Terms
Term
Explanation
Page
Binary variables
Variables constrained to have values 1 or 0; usually used to indicate 
294
whether an activity is undertaken or not . Also called 0–1 variables
IP models
Optimization models where some or all of the decision variables 
294
are constrained to have integer values
Branch and bound algorithm
A general algorithm for searching through all integer solutions in an 
295
IP model
Complete enumeration
An exhaustive method of checking the objective value of every
296
feasible integer solution
Implicit enumeration
A clever way of checking that no feasible integer solution can possibly 
296
be better than the optimal solution, without explicitly looking at each 
feasible integer solution
Incumbent solution
The best feasible solution found so far
296
(continued)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Term
Explanation
Page
LP relaxation
The same linear model, but without the integer constraints
297
Fixed-cost models
Difficult-to-solve models where certain costs are fixed at some positive 
306
level if an activity is undertaken at any level, and are 0 otherwise 
Either–or constraints
Constraints where one of two mutually exclusive conditions must be satisfied 314
Set-covering models
Models where members of one set (such as ambulances) must be located 
319
so that they cover members of another set (such as city districts)
Location models
Models where items (such as branch offices) must be located to provide 
319
required services at minimal cost
Summary of Key Excel Terms
Term
Explanation
Excel
Page
Solver Tolerance setting
Setting that specifies whether 
Specify under Solver Options 
297
Solver will stop at a near-optimal 
(default 5% doesn’t guarantee 
integer solution or will continue 
optimality; 0% does)
to optimality
6.7 Conclusion
341
P R O B L E M S
Skill-Building Problems
39. Four projects are available for investment. The pro-
jects require the cash flows and yield the net present
values (in millions) shown in the file P06_39.xlsx. If
$6 million is available now for investment, find the
investment plan that maximizes NPV.
40. You are given a group of possible investment projects
for your company’s capital. For each project, you are
given the NPV the project would add to the firm, as
well as the cash outflow required by each project dur-
ing each year. Given the information in the file
P06_40.xlsx, determine the investments that maximize
the firm’s NPV. The firm has $30 million available
during each of the next five years. All numbers are in
millions of dollars.
41. You are moving from New Jersey to Indiana and have
rented a truck that can haul up to 1100 cubic feet of 
furniture. The volume and value of each item you are
considering moving on the truck are given in the file
P06_41.xlsx. Which items should you bring to Indiana?
42. NASA must determine how many of three types of
objects to bring on board the space shuttle. The weight
and benefit of each of the items are given in the file
P06_42.xlsx. If the space shuttle can carry up to
2600 pounds of items 1 through 3, how many of each
item should be taken on the space shuttle, assuming
that at least one of each is necessary?
43. Coach Night is trying to choose the starting lineup for
the basketball team. The team consists of seven play-
ers who have been rated on a scale of 1 (poor) to 3
(excellent) according to their ball handling, shooting,
rebounding, and defensive abilities. The positions that
each player is allowed to play and the players’ abilities
are listed in the file P06_43.xlsx. The five-player start-
ing lineup must satisfy the following restrictions:
■At least four members must be able to play guard
(G), at least two members must be able to play for-
ward (F), and at least one member must be able to
play center (C).
■The average ballhandling, shooting, and rebound-
ing level of the starting lineup must each be at
least 1.8.
■Either player 2 or player 3 (or both) must start.
Given these constraints, Coach Night wants to
maximize the total defensive ability of the starting
team. Use Solver to determine his starting team.
44. To graduate from Southeastern University with a
major in operations research (OR), a student must
complete at least two math courses, at least two
OR courses, and at least two computer courses. Some
courses can be used to fulfill more than one require-
ment: Calculus can fulfill the math requirement;
Operations Research can fulfill the math and OR
requirements; Data Structures can fulfill the computer
and math requirements; Business Statistics can fulfill
the math and OR requirements; Computer Simulation
can fulfill the OR and computer requirements;
Introduction to Computer Programming can fulfill the
computer requirement; and Forecasting can fulfill the
OR and math requirements. Some courses are prereq-
uisites for others: Calculus is a prerequisite for
Business Statistics; Introduction to Computer
Programming is a prerequisite for Computer
Simulation and for Data Structures; and Business
Statistics is a prerequisite for Forecasting. Determine
how to minimize the number of courses needed to
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

satisfy the major requirements. (Hint: Because
Calculus is a prerequisite for Business Statistics, for
example, you will need a constraint that ensures that
the changing cell for Calculus is greater than or equal
to the changing cell for Business Statistics.)
45. Based on Bean et al. (1987). Boris Milkem’s firm
owns six assets. The expected selling price (in millions
of dollars) for each asset is given in the file
P06_45.xlsx. For example, if asset 1 is sold in year 2,
the firm receives $20 million. To maintain a regular
cash flow, Milkem must sell at least $20 million of
assets during year 1, at least $30 million worth during
year 2, and at least $35 million worth during year 3.
Determine how Milkem can maximize his total rev-
enue from assets sold during the next three years.
46. The Cubs are trying to determine which of the follow-
ing free-agent pitchers should be signed: Rick
Sutcliffe (RS), Bruce Sutter (BS), Dennis Eckersley
(DE), Steve Trout (ST), or Tim Stoddard (TS). (Feel
free to substitute your own set of players for these
“old” guys.) The cost of signing each pitcher and the
predicted number of victories each pitcher will add to
the Cubs are listed in the file P06_46.xlsx. The Cubs
want to sign the pitchers who will add the most victo-
ries to the team. Determine who the Cubs should sign
based on the following restrictions:
■At most, $25 million can be spent.
■At most, two right-handed pitchers can be signed.
■The Cubs cannot sign both BS and RS.
47. Based on Sonderman and Abrahamson (1985). In
treating a brain tumor with radiation, physicians want
the maximum amount of radiation possible to bom-
bard the tissue containing the tumors. The constraint
is, however, that there is a maximum amount of radia-
tion that normal tissue can handle without suffering
tissue damage. Physicians must therefore decide
how to aim the radiation to maximize the radiation that
hits the tumor tissue subject to the constraint of not
damaging the normal tissue. As a simple example of
this situation, suppose six types of radiation beams
(beams differ in where they are aimed and their inten-
sity) can be aimed at a tumor. The region containing
the tumor has been divided into six regions: three
regions contain tumors and three contain normal tis-
sue. The amount of radiation delivered to each region
by each type of beam is shown in the file P06_47.xlsx.
If each region of normal tissue can handle at most 
60 units of radiation, which beams should be used to
maximize the total amount of radiation received by
the tumors?
48. Because of excessive pollution on the Momiss River,
the state of Momiss is going to build some pollution
control stations. Three sites are under consideration.
Momiss is interested in controlling the pollution levels
of two pollutants. The state legislature requires that at
least 80,000 tons of pollutant 1 and at least 60,000 tons
of pollutant 2 be removed from the river. The relevant
data for this problem are shown in the file P06_48.xlsx.
The last two rows indicate the number of tons of 
pollutants removed per ton treated.
a. Determine how to minimize the cost of meeting the
state legislature’s goals.
b. Use SolverTable to analyze how a change in the
requirement for pollutant 1 changes the optimal
solution. Do the same for pollutant 2.
49. A manufacturer can sell product 1 at a profit of $20
per unit and product 2 at a profit of $40 per unit. Three
units of raw material are needed to manufacture one
unit of product 1, and six units of raw material are
needed to manufacture one unit of product 2. A total
of 15,000 units of raw material are available. If any
product 1 is produced, a setup cost of $20,000 is
incurred; if any product 2 is produced, a setup cost of
$35,000 is incurred.
a. Determine how to maximize the manufacturer’s
profit.
b. If either of the products is not produced in the opti-
mal solution, use SolverTable to see how much this
product’s unit profit must be before it will be pro-
duced, and then use SolverTable again to see how
much this product’s fixed cost must be decreased
before it will be produced.
50. A company is considering opening warehouses in four
cities: New York, Los Angeles, Chicago, and Atlanta.
Each warehouse can ship 10,000 units per week. The
weekly fixed cost of keeping each warehouse open is
$40,000 for New York, $50,000 for Los Angeles,
$30,000 for Chicago, and $25,000 for Atlanta. Region
1 of the country requires 8000 units per week, region 2
requires 7000 units per week, and region 3 requires
4000 units per week. The costs (including production
and shipping costs) of sending one unit from a ware-
house to a region are shown in the file P06_50.xlsx.
The company wants to meet weekly demands at mini-
mum cost, subject to the preceding information and the
following restrictions:
■If the New York warehouse is opened, then the Los
Angeles warehouse must be opened.
■At most two warehouses can be opened.
■Either the Atlanta or the Los Angeles warehouse
must be opened.
51. Glueco produces three types of glue on two different
production lines. Each line can be used by up to 
20 workers at a time. Workers are paid $500 per week
on production line 1 and $900 per week on production
line 2. For a week of production, it costs $5000 to set
up production line 1 and $4000 to set up production
line 2. During a week on a production line, each
worker produces the number of units of glue shown in
the file P06_51.xlsx. Each week, at least 800 units of
342
Chapter 6
Optimization Models with Integer Variables
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

glue 1, at least 750 units of glue 2, and at least 100 units
of glue 3 must be produced. Determine how to mini-
mize the total cost of meeting weekly demands. Make
sure the number of workers assigned to each line is an
integer.
52. Fruit Computer produces two types of computers: Pear
computers and Apricot computers. The relevant data
are given in the file P06_52.xlsx. The equipment cost
is a fixed cost that is incurred if any of this type of
computer is produced. A total of 2000 chips and
1500 hours of labor are available.
a. Determine how Fruit can maximize its net profit.
b. Use SolverTable to analyze the effect on the opti-
mal solution of a change in the unit margin of Pear
computers. Do the same for the unit margin of
Apricot computers.
53. A product can be produced on four different machines.
Each machine has a fixed setup cost, variable produc-
tion cost per unit processed, and a production capacity,
given in the file P06_53.xlsx. A total of 2000 units of
the product must be produced. Determine how to mini-
mize the total cost.
54. Consider the Pigskin example (Example 3.3) from
Chapter 3. Find Pigskin’s optimal production policy if,
in addition to the given production and holding costs,
there is a fixed cost of $50,000 during any month in
which there is positive production. Assume now that
storage capacity is 20,000 footballs.
55. McPherson Publishers is considering publishing five
textbooks. The maximum number of copies of each
textbook that can be sold, the variable cost of produc-
ing each textbook, the selling price of each textbook,
and the fixed cost of a production run for each book
are given in the file P06_55.xlsx. For example, pro-
ducing 2000 copies of book 1 brings in a revenue of
(2000)(50)  $100,000 but costs 80,000  25(2000) 
$130,000.
a. Determine how McPherson can maximize its profit
if it can produce at most 10,000 books.
b. Use SolverTable to analyze the effect on the opti-
mal solution of a change in the demand for book 1.
Repeat for the demands for the other books.
56. Comquat owns four production plants at which com-
puter workstations are produced. Comquat can sell up
to 20,000 computers per year at a price of $3500 per
computer. For each plant, the production capacity, the
production cost per computer, and the fixed cost of
operating a plant for a year are given in the file
P06_56.xlsx. Determine how Comquat can maximize
its yearly profit from computer production.
57. Eastinghouse sells air conditioners. The annual
demand for air conditioners in each region of the
country is as follows: East, 100,000; South, 150,000;
Midwest, 110,000; and West, 90,000. Eastinghouse is
considering building its air conditioners in four differ-
ent cities: New York, Atlanta, Chicago, and Los
Angeles. The cost of producing an air conditioner in a
city and shipping it to a region of the country is given
in the file P06_57.xlsx. Any factory can produce up to
150,000 air conditioners per year. The annual fixed
cost of operating a factory in each city is given in the
same file. At least 50,000 units of the Midwest
demand for air conditioners must come from New
York, and at least 50,000 units of the Midwest demand
must come from Atlanta. Determine how Eastinghouse
can minimize the annual cost of meeting demand for
air conditioners.
58. During the next five periods, the demands listed in the
file P06_58.xlsx must be met on time. At the begin-
ning of period 1, the inventory level is 0. During each
period when production occurs, a setup cost of $2500
and a per-unit production cost of $20 are incurred. At
the end of each period, a per-unit holding cost of $10
is incurred. Determine the cost-minimizing production
schedule.
59. At a machine tool plant, five jobs must be completed
each day. The time it takes to do each job depends on
the machine used to do the job. If a machine is used 
at all, a setup time is required. The relevant times 
(in minutes) are given in the file P06_59.xlsx.
a. Determine how to minimize the sum of the setup
and machine operation times needed to complete
all jobs.
b. Use SolverTable to see how a change in the setup
time for machine 4 changes the optimal solution.
c. Use SolverTable to see how a change in the required
time for machine 1 to complete job 3 changes the
optimal solution.
60. Ford has four automobile plants. Each is capable of
producing the Focus, Mustang, or Crown Victoria, but
it can produce only one of these cars. The fixed cost
of operating each plant for a year and the variable
cost of producing a car of each type at each plant are
given in the file P06_60.xlsx. Ford faces the following
restrictions:
■Each plant can produce only one type of car.
■The total production of each type of car must be at
a single plant. For example, if any Mustangs are made
at plant 1, then all Mustangs must be made there.
■Each year, Ford must produce five million of each
type of car.
a. Determine how to minimize the annual cost of
producing these cars.
b. Use SolverTable to see how a change in the
demand for Mustangs changes the optimal
solution. 
c. Use SolverTable to see how the optimal solu-
tion is affected by a change in the variable cost
of producing a Focus at plant 4.
6.7 Conclusion
343
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

61. Heinsco produces tomato sauce at five different plants.
The tomato sauce is then shipped to one of three ware-
houses, where it is stored until it is shipped to one of
the company’s four customers. The following inputs
for the problem are given in the file P06_61.xlsx:
■The plant capacities (in tons)
■The cost per ton of producing tomato sauce at each
plant and shipping it to each warehouse
■The cost of shipping a ton of sauce from each
warehouse to each customer
■The customer requirements (in tons) of sauce
■The fixed annual cost of operating each plant and
warehouse
Heinsco must decide which plants and warehouses to
open, and which routes from plants to warehouses and
from warehouses to customers to use. All customer
demand must be met. A given customer’s demand can
be met from more than one warehouse, and a given
plant can ship to more than one warehouse.
a. Determine the minimum-cost method for meeting
customer demands.
b. Use SolverTable to see how a change in the capac-
ity of plant 1 affects the total cost.
c. Use SolverTable to see how a change in the cus-
tomer 2 demand affects the total cost.
d. Suppose that each customer’s demand must be met
from a single warehouse. Solve the problem with
this restriction.
62. Eight jobs need to be completed. Each job can be com-
pleted on any of six machines, and each machine can
complete any number of jobs. If a machine is assigned
to at least one job, the setup time listed in the file
P06_62.xlsx is required. (All times are in hours.) The
time required for each machine to complete each job
(excluding the setup time) is also listed in the same file.
How should the jobs be assigned to machines to mini-
mize the sum of setup times and job completion times?
63. Based on Walker (1974). The Smalltown Fire
Department currently has seven conventional ladder
companies and seven alarm boxes. The two closest
ladder companies to each alarm box are listed in the
file P06_63.xlsx. The town council wants to maximize
the number of conventional ladder companies that
can be replaced with “tower” ladder companies.
Unfortunately, political considerations dictate that a
conventional company can be replaced only if, after
replacement, at least one of the two closest companies
to each alarm box is still a conventional company.
Determine how to maximize the number of conven-
tional companies that can be replaced by tower 
companies.
64. State University must purchase 1100 computers from
three vendors. Vendor 1 charges $500 per computer
plus a total delivery charge of $5000. Vendor 2 charges
$350 per computer plus a total delivery charge of
$4000. Vendor 3 charges $250 per computer plus a
total delivery charge of $6000. Vendor 1 will sell the
university at most 500 computers, vendor 2, at most
900, and vendor 3, at most 400. The minimum order
from any vendor is 200 computers. Determine how to
minimize the cost of purchasing the needed computers.
65. At Blair General Hospital, six types of surgical opera-
tions are performed. The types of operations each sur-
geon is qualified to perform (indicated by an X) are
listed in the file P06_65.xlsx. Suppose that surgeons 1
and 2 dislike each other and cannot be on duty at the
same time. Determine the minimum number of sur-
geons required so that the hospital can perform all
types of surgery.
66. Eastinghouse ships 12,000 capacitors per month to its
customers. The capacitors can be produced at three
different plants. The production capacity, fixed
monthly cost of operation, and variable cost of produc-
ing a capacitor at each plant are given in the file
P06_66.xlsx. The fixed cost for a plant is incurred only
if the plant is used to make any capacitors. If a plant is
used at all, at least 3000 capacitors per month must be
produced at the plant. Determine how to minimize the
company’s monthly costs of meeting its customers’
demands.
67. Based on Liggett (1973). A court decision has stated
that the enrollment of each high school in Metropolis
must be at least 20% black. The numbers of black
students and white students in each of the city’s five
school districts are listed in the file P06_67.xlsx. The
distance (in miles) that a student in each district must
travel to each high school is shown in the same file.
School board policy requires that all students in a given
district must attend the same school. Assuming that
each school must have an enrollment of at least 150
students, determine how to minimize the total distance
that Metropolis students must travel to high school.
68. Based on Westerberg, Bjorklund, and Hultman (1977).
Newcor’s steel mill has received an order for 150 tons
of steel. The steel must be 5% carbon and 5% molyb-
denum by weight. The steel is manufactured by com-
bining three types of metal: steel ingots, scrap steel,
and alloys. Four individual steel ingots are available.
At most, one of each can be purchased. The weight (in
tons), cost per ton, and the carbon and molybdenum
content of each ingot are given in the file P06_68.xlsx.
Three types of alloys can be purchased. The cost per
ton and chemical makeup of each alloy are given in
the same file. Steel scrap can be purchased at a cost of
$100 per ton. Steel scrap contains 3% carbon and 
9% molybdenum. Determine how Newcor can mini-
mize the cost of filling its order.
69. Based on Boykin (1985). Chemco annually produces
359 million pounds of the chemical maleic anhydride.
344
Chapter 6
Optimization Models with Integer Variables
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

A total of four reactors are available to produce
maleic anhydride. Each reactor can be run on one 
of three settings. The cost (in thousands of dollars)
and pounds produced (in millions) annually for 
each reactor and each setting are given in the file
P06_69.xlsx. A reactor can be run on only one set-
ting for the entire year. Determine how Chemco can
minimize the cost of meeting its annual demand for
maleic anhydride.
70. Based on Zangwill (1992). Hallco runs a day shift and
a night shift. Regardless of the number of units pro-
duced, the only production cost during a shift is a
setup cost. It costs $8000 to run the day shift and
$4500 to run the night shift. Demand for the next two
days is as follows: day 1, 2000; night 1, 3000; day 2,
2000; night 2, 3000. It costs $1 per unit to hold a unit
in inventory for a shift.
a. Determine a production schedule that minimizes
the sum of setup and inventory costs. All demand
must be met on time. (Note: Not all shifts have to
be run.)
b. After listening to a seminar on the virtues of the
Japanese theory of production, Hallco has cut the
setup cost of its day shift to $1000 per shift and the
setup cost of its night shift to $3500 per shift. Now
determine a production schedule that minimizes the
sum of setup and inventory costs. All demand must
be met on time. Show that the decrease in setup
costs has actually raised the average inventory
level. Is this reasonable?
71. Based on Fitzsimmons and Allen (1983). The State
of Texas frequently audits companies doing business
in Texas. Because these companies often have head-
quarters located outside the state, auditors must be
sent to out-of-state locations. Each year, auditors
must make 500 trips to cities in the Northeast, 400
trips to cities in the Midwest, 300 trips to cities in the
West, and 400 trips to cities in the South. Texas is
considering basing auditors in Chicago, New York,
Atlanta, and Los Angeles. The annual cost of basing
auditors in any city is $100,000. The cost of sending
an auditor from any of these cities to a given region
of the country is given in the file P06_71.xlsx.
Determine how to minimize the annual cost of
conducting out-of-state audits.
Skill-Extending Problems
72. Suppose you own 11 bronze coins worth a total of $150,
11 silver coins worth a total of $160, and 11 gold coins
worth a total of $170. Develop a linear integer model to
find a combination of coins worth exactly $110.
73. Cousin Bruzie of radio station WABC schedules radio
commercials in 60-second blocks. This hour, the sta-
tion has sold time for commercials of 15, 16, 20, 25,
30, 35, 40, and 50 seconds. Determine the minimum
number of 60-second blocks of commercials that
must be scheduled to fit in all the current hour’s
commercials.
74. Based on Bean et al. (1988). Simon’s Mall has 
10,000 square feet of space to rent and wants to deter-
mine the types of stores that should occupy the mall.
The minimum number and maximum number of each
type of store (along with the square footage of each
type) are given in the file P06_74.xlsx. The annual
profit made by each type of store depends on how
many stores of that type are in the mall. This depen-
dence is given in the same file. For example, if two
department stores are in the mall, each department store
will earn $210,000 profit per year. Each store pays 5%
of its annual profit as rent to Simon’s. Determine how
Simon can maximize its rental income from the mall.
75. Indiana University’s Business School has two rooms
that seat 50 students, one room that seats 100 students,
and one room that seats 150 students. Classes are held
five hours a day. At present, the four types of requests
for rooms are listed in the file P06_75.xlsx. The busi-
ness school must decide how many requests of each
type to assign to each type of room. Suppose that
classes that cannot be assigned to a business school
room are assigned to another campus building.
Determine how to assign classes to minimize the num-
ber of hours students spend each week outside the
business building.
76. Based on Efroymson and Ray (1966). Stonecutters is a
new bakery chain that sells bread to customers
throughout the state of Indiana. Stonecutters is consid-
ering building bakeries in three locations: Evansville,
Indianapolis, and South Bend. Each bakery can bake
up to 900,000 loaves of bread each year. The cost of
building a bakery at each site is $5 million in
Evansville, $4 million in Indianapolis, and $4.5 mil-
lion in South Bend. To simplify the problem, we
assume that Stonecutters has only three customers.
Their demands each year are 700,000 loaves (cus-
tomer 1); 400,000 loaves (customer 2); and 300,000
loaves (customer 3). The total cost of baking and ship-
ping a loaf of bread to a customer is given in the file
P06_76.xlsx. Assume that future shipping and produc-
tion costs are discounted at a rate of 12% per year.
Assume that once built, a bakery lasts forever. How
would you minimize the company’s total cost of 
meeting demand, present and future?
77. On Monday morning, you have $3000 in cash on
hand. For the next seven days, the following cash
requirements must be met: Monday, $5000; Tuesday,
$6000; Wednesday, $9000; Thursday, $2000; Friday,
$7000; Saturday, $2000; Sunday, $3000. At the begin-
ning of each day, you must decide how much money
(if any) to withdraw from the bank. It costs $10 to
make a withdrawal of any size. You believe that the
6.7 Conclusion
345
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

opportunity cost of having $1 of cash on hand for a
year is $0.20. Assume that opportunity costs are
incurred on each day’s ending balance. Determine how
much money you should withdraw from the bank
during each of the next seven days.
78. Based on Eaton et al. (1985). Gotham City has been
divided into eight districts. The time (in minutes) it
takes an ambulance to travel from one district to
another is shown in the file P06_78.xlsx. The popula-
tion of each district (in thousands) is as follows: district 1,
40; district 2, 30; district 3, 35; district 4, 20; 
district 5, 15; district 6, 50; district 7, 45; district 8, 60.
Suppose Gotham City has n ambulance locations.
Determine the locations of ambulances that maximize
the number of people who live within two minutes of
an ambulance. Do this separately for n  1; n  2; 
n  3; n  4. (Hint: Set it up so that SolverTable can
solve all four problems simultaneously.)
79. Arthur Ross, Inc., must complete many corporate tax
returns during the period February 15 to April 15. This
year, the company must begin and complete the five
jobs shown in the file P06_79.xlsx during this eight-
week period. Arthur Ross employs four full-time
accountants who normally work 40 hours per week. If
necessary, however, they can work up to 20 hours of
overtime per week for which they are paid $100 per
hour. Determine how Arthur Ross can minimize the
overtime cost incurred in completing all jobs by 
April 15.
80. Based on Muckstadt and Wilson (1968). PSI believes
it will need the amounts of generating capacity (in
millions of kwh) shown in the file P06_80.xlsx during
the next five years. The company has a choice of
building (and then operating) power plants with the
capacities (in millions of kwh) and costs (in millions
of dollars) shown in the same file. Determine how to
minimize the total cost of meeting PSI’s generating
capacity requirements for the next five years.
81. Newsome Construction is considering erecting three
office buildings. The time (in years) required to com-
plete each of them and the number of workers required
to be on the job at all times are shown in the file
P06_81.xlsx. After a building is completed, it brings
in the following amount of rent per year: building 1,
$50,000; building 2, $30,000; building 3, $40,000.
Newsome faces the following constraints:
■During each year, 60 workers are available.
■At most, one building can be started during any
year.
■Building 2 must be completed by the end of year 4. 
Determine the maximum total rent that can be earned
by Newsome by the end of year 4.
82. Four trucks are available to deliver milk to five gro-
cery stores. The capacity and daily operating cost of
each truck are shown in the file P06_82xlsx. The
demand of each grocery store can be supplied by only
one truck, but a truck can deliver to more than one
grocery. The daily demands of each grocery are as
follows: grocery 1, 100 gallons; grocery 2, 200 gallons;
grocery 3, 300 gallons; grocery 4, 500 gallons; grocery 5,
800 gallons. Determine how to minimize the daily cost
of meeting the demands of the five groceries.
83. A county is going to build two hospitals. There are
nine cities in which the hospitals can be built. The
number of hospital visits per year made by people in
each city and the x-y coordinates of each city are listed
in the file P06_83.xlsx. The county’s goal is to mini-
mize the total distance that patients must travel to hos-
pitals. Where should it locate the hospitals? (Hint: You
will need to determine the distance between each pair
of cities. An easy way to do this is with lookup tables.)
84. It is currently the beginning of 2010. Gotham City is
trying to sell municipal bonds to support improve-
ments in recreational facilities and highways. The face
values of the bonds and the due dates at which princi-
pal comes due are listed in the file P06_84.xlsx. 
(The due dates are the beginnings of the years listed.)
The Gold and Silver Company (GS) wants to under-
write Gotham City’s bonds. A proposal to Gotham 
for underwriting this issue consists of the following: 
(1) an interest rate of 3%, 4%, 5%, 6%, or 7% for each
bond, where coupons are paid annually; and (2) an
upfront premium paid by GS to Gotham City. GS has
determined the set of fair prices for the bonds listed in
the same file. For example, if GS underwrites bond 2
maturing in 2013 at 5%, it would charge Gotham City
$444,000 for that bond. GS is allowed to use at most
three different interest rates. GS requires a profit of at
least $46,000, where its profit is equal to the sale price
of the bonds minus the face value of the bonds minus
the premium it pays to Gotham City. To maximize the
chance that GS will get Gotham City’s business, GS
wants to minimize the total cost of the bond issue to
Gotham City, which is equal to the total interest on the
bonds minus the premium paid by GS. For example, if
the year 2012 bond (bond 1) is issued at a 4% rate,
then Gotham City must pay two years of coupon inter-
est: 2(0.04)($700,000)  $56,000. What assignment
of interest rates to each bond and upfront premium
ensure that GS will make the desired profit (assuming
it gets the contract) and minimize the cost to Gotham
City?
85. Based on Spencer et al. (1990). When you lease 800
phone numbers from AT&T for telemarketing, AT&T
uses an optimization model to tell you where you
should locate calling centers to minimize your operat-
ing costs over a 10-year horizon. To illustrate the
model, suppose you are considering seven calling
center locations: Boston, New York, Charlotte, Dallas,
Chicago, Los Angeles, and Omaha. You know the
average cost incurred if a telemarketing call is made
346
Chapter 6
Optimization Models with Integer Variables
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

from any of these cities to any region of the country.
You also know the hourly wage that you must pay
workers in each city. This information is listed in the
file P06_85.xlsx. Assume that an average call requires
four minutes of labor. You make calls 250 days per
year, and the average number of calls made per day to
each region of the country is listed in the same file.
The cost of building a calling center in each possible
location is also listed in this file. Each calling center
can make up to 5000 calls per day. Given this informa-
tion, how can you minimize the discounted cost 
(at 10% per year) of running the telemarketing opera-
tion for 10 years? Assume all wage and calling costs
are paid at the ends of the respective years.
86. State University is scheduling 24 sections of a large
computer skills course in the Fall semester. There are
eight time slots for these sections, four on Monday/
Wednesday (MW) and four on Tuesday/Thursday
(TR). In each time slot, three sections are scheduled.
These are shown in the file P06_86.xlsx. The sec-
tions will be taught by six instructors. Instructors 1 to
3 must teach at least three sections and no more than
four sections each. Instructors 4 to 6 must teach at
least four sections and no more than five sections each.
The instructors have submitted their top four prefer-
ences for time slots, as shown in the file. Four points
are awarded for satisfying an instructor’s first prefer-
ence, three for second preference, two for third 
preference, and one for fourth preference. These
points appear in the file. For example, instructor 
1’s preferences are, in decreasing order, MW 9-10,
MW 11-noon, MW 1-2, and TR 11-noon. Find an
assignment of instructors to sections that maximizes
the points from satisfying preferences. Of course, no
instructor can teach more than one section in the
same time slot.
87. Hoosier Power needs to determine a capacity expan-
sion plan to meet Bloomington’s power needs for the
next 20 years. The current capacity is 5000 kwh. The
demand for the current year is 4000 kwh, and demand
is expected to increase by 1000 kwh in each succeed-
ing year. At the beginning of each year, Hoosier Power
must determine the amount of capacity to add, given
the following inputs:
■Any year in which capacity is added, a fixed cost
of $120,000 is incurred plus a cost of $120 per kwh
of capacity.
■At most 10,000 kwh of capacity can be added in a
single year.
■It costs $25 per year to maintain a unit of 
capacity.
■It costs $12 per year to produce a kwh.
■If production does not meet demand, a shortage
cost of $80 per kwh short is incurred.
Develop a linear integer model to help Hoosier Power
minimize its costs for the next 20 years.
88. Based on Angel et al. (2003). A fertilizer company is
trying to determine the cheapest fertilizer mix that
provides desired amounts of nutrients. The mix is
made by combining the following fertilizers: SSA,
SPO, GUR, TSP, KCI, FERT, and SPF. The mix can-
not contain both GUR and TSP. The percentage of
potassium (K), sulfur (S), calcium (Ca), sodium (Na)
and phosphorus (P) in each fertilizer is listed in the file
P06_88.xlsx. For example, a pound of SSA is 16% K
and 26% Na. The mix must contain at least 600 pounds
of K, 550 pounds of S, 750 pounds of Ca, 900 pounds
of Na, and 750 pounds of P. The mix cannot contain
both GUR and TSP, because if both are present in the
mix, the affect of other fertilizers is nullified. The cost
per pound (in cents) of each fertilizer is listed in the
same file. Develop a linear integer model to find the
minimum-cost fertilizer mixture that meets the stated
chemical requirements.
89. Sam is in his final year of college and is trying to
schedule his courses for the year. He has narrowed his
search to 16 courses, each of which is offered in at
least one time slot (out of a possible five time slots) in
each semester. The file P06_89.xlsx lists the courses
and when they are offered. For example, course C1 is
offered in time slots T4 and T5 during semester S1
and in time slot T3 in semester S2. The course also
lists the values Sam attaches to the various course/time
slot/semester combinations (on a 1 to 10 scale).
Assuming that Sam must take exactly five courses
each semester, find the combination that maximizes
the total value of the courses he takes. Of course, he
can’t take the same course more than once, and he
can’t take more than one course at the same time.
90. A medical supply company has customers in eight
cities. It is trying to decide how many salespeople it
needs to service these customers. Each salesperson
needs to be located in one of the eight cities and
needs to be assigned to a subset of the customers. For
example, the company might base a salesperson in
New York and have this person service customers in
New York, Boston, and Philadelphia. Each salesper-
son receives an annual salary of $50,000 and can
work as many as 230 days per year. This includes
days working with customers and days traveling to
and from customers. The file P06_90.xlsx contains
data on the annual travel costs (for example, $15,900
for a salesperson based in New York traveling for
customers in Orlando), the annual number of days of
work required for the customers, and the annual num-
ber of days traveling to and from customers. Find an
assignment that minimizes the total cost of salaries
and traveling. The solution should indicate the num-
ber of salespeople to employ, where they should be
based, and which cities they should serve. Assume
that customers in a given city must be serviced by a
single salesperson.
6.7 Conclusion
347
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

91. You are scheduling company interviews at the annual
university career fair. Five interview rooms are avail-
able. Interviews are conducted from 9 AM to 5 PM.
Each company wants all of its interviews conducted in
a single room. The time preferences for the companies
are listed in the file P06_91.xlsx. Develop a linear
integer model to determine whether five rooms are
sufficient to complete the interviews.
92. The file P06_92.xlsx lists the distances between
21 U.S. cities. You want to locate liver transplant
centers in a subset of these 21 cities.
a. Suppose you plan to build four liver transplant
centers and your goal is to minimize the maximum
distance a person in any of these cities has to travel
to a center. In which cities should the centers be
located?
b. How many centers are needed, and in which cities
should they be located, so that residents of all cities
are within 800 miles of a transplant center? (The
model must be linear.)
c. You know that a transplant center is sometimes
filled to capacity. With this in mind, you would like
everyone to be relatively close to two transplant
centers. How many centers are needed, and in
which cities should the centers be located, to ensure
that residents of all cities are within 800 miles of two
transplant centers? (Again, the model must be
linear.)
d. The same file also lists the number of people (in
millions) living in each city’s metropolitan area.
Where should you locate three transplant centers to
maximize the number of people within 800 miles
of a transplant center?
93. This problem is based on Motorola’s online method
for choosing suppliers. Suppose Motorola solicits bids
from five suppliers for eight products. The list price
for each product and the quantity of each product that
Motorola needs to purchase during the next year are
listed in the file P06_93.xlsx. Each supplier has sub-
mitted the percentage discount it will offer on each
product. These percentages are also listed in the file.
For example, supplier 1 offers a 7% discount on prod-
uct 1 and a 30% discount on product 2. The following
considerations also apply:
■There is an administrative cost of $5000 associated
with setting up a supplier’s account. For example,
if Motorola uses three suppliers, it incurs an
administrative cost of $15,000.
■To ensure reliability, no supplier can supply more
than 80% of Motorola’s demand for any product.
■A supplier must supply an integer amount of each
product it supplies.
Develop a linear integer model to help Motorola
minimize the sum of its purchase and administrative
costs.
94. Specialty Software  is considering 10 projects. The
years each project will be developed, the number of
programmers needed each year for each project, and
the revenue (exclusive of labor costs) from each pro-
ject are listed in the file P06_94.xlsx. For example,
project 1, if undertaken, will require 37 programmers
in each of the first four years. The company currently
employs 100 programmers. At the beginning of each
year, it can hire as many as 80 programmers. If any 
are hired in a given year, a training program must be
run at a cost of $5 million, regardless of the number
hired. Programmers are paid a salary of $50,000 per
year. 
a. How can Specialty Software maximize the net
profit from these projects? (Hint: First use IF
functions to create a matrix of programmers
required each year for each project.)
b. Assuming that 10% of all programmers quit at the
end of each year, how does the solution change?
(Don’t worry about noninteger numbers of workers.)
95. You are moving away from Bloomington and need to
load a truck. The items that will go on the truck must
all be packed in boxes. The size (in cubic feet) of each
item and each available box are listed in the file
P06_95.xlsx. For example, the first item requires
87 cubic feet, and the first box can hold 126 cubic feet
of stuff. Develop a linear integer model to find the
minimum amount of cubic feet needed to pack all
items in boxes.
96. Based on McBride and Zufryden (1988). A company
is trying to determine which of five possible products
to include in its product line. The fixed cost of
producing each product and the unit profit for each
product are listed in the file P06_96.xlsx. There are five
customer segments. The number of customers in each
segment and the utility each customer segment associ-
ates with each product are also listed in this file. If a
consumer believes that all available products have a
negative utility, this customer will buy nothing.
Otherwise, each customer will buy the available prod-
uct that has the largest utility. For example, if products
1, 2, and 3 are available, customer segment 4 will pur-
chase product 3. Determine which products the com-
pany should produce to maximize its profit, assuming
that it will produce exactly enough to meet customer
demand. (Hint: Use a binary changing cell for each
product and a binary changing cell for each customer
segment-product combination. To ensure that a cus-
tomer buys only the product with the largest utility,
include the following constraint for each combination
of product and customer segment:
Ucj xj  Uci xi 	 M (1 	 ycj) for each i, j, c
Here, Ucj is the utility for customer segment c buying
product j, xj is a binary for product j being offered, ycj
348
Chapter 6
Optimization Models with Integer Variables
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

6.7 Conclusion
349
is a binary for customer segment c buying product j,
and M is a large number (M equal to the largest prod-
uct utility will work). This constraint ensures that the
ycj binary can equal 1 only if the binary xj equals 1,
that is, customer segment c can buy product j only if it
is included in the product line. Note that if ycj is 0,
then this inequality is automatically satisfied.)
Modeling Problems
97. Suppose that you want to divide a state containing 
12 cities into five congressional districts. How might
you use IP to assign cities to districts?
98. An insurance company has hired you to determine
the number of sales divisions into which the country
should be divided. Each division will need a presi-
dent, a vice president, and a divisional staff. The time
needed to call on a client will depend on the distance
of the salesperson from the client. Discuss how you
would determine the optimal number of sales divisions
and the allocation of the company’s sales force to the
various divisions.
99. Ten different types of brownies are sold. You are think-
ing of developing a new brownie for sale. Brownies are
rated on the basis of five qualities: price, chocolate fla-
vor, chewiness, sweetness, and ease of preparation.
You want to group the 10 brownies on the market into
three clusters. Each cluster should contain brownies
that are relatively similar.
a. Why would this be useful to you?
b. How would you do it?
100. Telco, a national telemarketing firm, usually picks a
number of sites around the country from which it
makes its calls. As a service, AD&D’s telecommunica-
tion marketing department wants to help Telco choose
the number and location of its sites. How can IP be
used to approach this problem?
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

350
Chapter 6
Optimization Models with Integer Variables
T
his case deals with strategic planning issues for a
large company. The main issue is planning the
company’s production capacity for the coming year.
At issue is the overall level of capacity and the type
of capacity—for example, the degree of flexibility in
the manufacturing system. The main tool used to aid
the company’s planning process is a mixed integer
linear programming (MILP) model. A mixed integer
program has both integer and continuous variables.
Problem Statement
The Giant Motor Company (GMC) produces three
lines of cars for the domestic (U.S.) market: Lyras,
Libras, and Hydras. The Lyra is a relatively inexpen-
sive subcompact car that appeals mainly to first-time
car owners and to households using it as a second
car for commuting. The Libra is a sporty
compact car that is sleeker, faster, and roomier
than the Lyra.Without any options, the Libra costs
slightly more than the Lyra; additional options
increase the price. The Hydra is the luxury car of
the GMC line. It is significantly more expensive than
the Lyra and Libra, and it has the highest profit
margin of the three cars.
Retooling Options f
or Capacity
Expansion
Currently GMC has three manufacturing plants in
the United States. Each plant is dedicated to
producing a single line of cars. In its planning for the
coming year, GMC is considering the retooling of its
Lyra and/or Libra plants. Retooling either plant would
C A S E
6.1 GIANT MOTOR COMPANY
represent a major expense for the company. The
retooled plants would have significantly increased
production capacities. Although having greater fixed
costs, the retooled plants would be more efficient
and have lower marginal production costs—that is,
higher marginal profit contributions. In addition, the
retooled plants would be flexible—they would have
the capability of producing more than one line 
of cars.
The characteristics of the current plants and the
retooled plants are given in Table 6.16. The retooled
Lyra and Libra plants are prefaced by the word new.
The fixed costs and capacities in Table 6.16 are given
on an annual basis. A dash in the profit margin sec-
tion indicates that the plant cannot manufacture that
line of car. For example, the new Lyra plant would be
capable of producing both Lyras and Libras but not
Hydras. The new Libra plant would be capable of
producing any of the three lines of cars. Note, how-
ever, that the new Libra plant has a slightly lower
profit margin for producing Hydras than the Hydra
plant. The flexible new Libra plant is capable of pro-
ducing the luxury Hydra model but is not as efficient
as the current Hydra plant that is dedicated to Hydra
production.
The fixed costs are annual costs incurred by
GMC, independent of the number of cars produced
by the plant. For the current plant configurations, the
fixed costs include property taxes, insurance, pay-
ments on the loan that was taken out to construct
the plant, and so on. If a plant is retooled, the fixed
costs will include the previous fixed costs plus the
additional cost of the renovation. The additional
Table 6.16 Plant Characteristics
Lyra
Libra
Hydra
New Lyra
New Libra
Capacity (in 1000s)
1000
800
900
1600
1800
Fixed cost (in $millions)
2000
2000
2600
3400
3700
Profit Margin by Car Line (in $1000s)
Lyra
2
—
—
2.5
2.3
Libra
—
3
—
3.0
3.5
Hydra
—
—
5
—
4.8 
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Case 6.1 Giant Motor Company 
351
renovation cost will be an annual cost representing
the cost of the renovation amortized over a long
period.
Demand for GMC Cars
Short-term demand forecasts have been very reliable
in the past and are expected to be reliable in the
future. The demand for GMC cars for the coming
year is given in Table 6.17.
demand for Libras and 5% to demand for Hydras.
Similarly, 10% of unsatisfied demand for Libras is
diverted to demand for Hydras. For example, if the
demand for Lyras is 1,400,000 cars, then the unsatis-
fied demand will be 400,000 if no capacity is added.Out
of this unsatisfied demand,120,000 ( 400,000  0.3)
will materialize as demand for Libras, and 20,000 
( 400,000  0.05) will materialize as demand for
Hydras. Similarly, if the demand for Libras is
1,220,000 cars (1,100,000 original demand plus
120,000 demand diverted from Lyras), then the
unsatisfied demand for Lyras would be 420,000 if 
no capacity is added. Out of this unsatisfied demand,
42,000 ( 420,000  0.1) will materialize as demand
for Hydras. All other unsatisfied demand is lost to
competitors. The pattern of demand diversion is
summarized in Table 6.18.
Question
GMC wants to decide whether to retool the Lyra and
Libra plants.In addition,GMC wants to determine its
production plan at each plant in the coming year.
Based on the previous data,formulate a MILP model
for solving GMC’s production planning–capacity
expansion problem for the coming year. ■
A quick comparison of plant capacities and
demands in Table 6.16 and Table 6.17 indicates that
GMC is faced with insufficient capacity. Partially
offsetting the lack of capacity is the phenomenon of
demand diversion.If a potential car buyer walks
into a GMC dealer showroom wanting to buy a Lyra
but the dealer is out of stock, frequently the sales-
person can convince the customer to purchase the
better Libra car, which is in stock. Unsatisfied
demand for the Lyra is said to be diverted to the
Libra. Only rarely in this situation can the salesper-
son convince the customer to switch to the luxury
Hydra model.
From past experience, GMC estimates that
30% of unsatisfied demand for Lyras is diverted to
Table 6.17 Demand for GMC Cars
Demand (in 1000s)
Lyra
1400
Libra
1100
Hydra
800 
Table 6.18 Demand Diversion Matrix
Lyra
Libra
Hydra
Lyra
NA
0.3
0.05
Libra
0
NA
0.10
Hydra
0
0.0
NA 
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

352
Chapter 6
Optimization Models with Integer Variables
D
uring 2001, many European markets for
mobile phones reached saturation. Because of
this, mobile phone operators started to shift their
focus from growth and market share to cutting
costs. One way to do this is to reduce spending on
international calls. These calls are routed through
network operating companies called carriers. The
carriers charge per call-minute for each destina-
tion, and they often use a discount on total busi-
ness volume to price their services. A mobile
phone operator must decide how to allocate 
destinations to carriers.
V-Mobile, a mobile phone operator in Denmark,
must make such a decision for a T-month planning
horizon when it has C carriers to choose from, D
destinations for its customers’ calls, and there are I
price intervals for a typical carrier. (These intervals
define a carrier’s discount structure.) The inputs
include the following:
■The price per call-minute for destination d from
carrier c in price interval i in month t
■The (forecasted) number of call-minutes for
destination d in month t
■The lower and upper limits for carrier c in price
interval i
■The lower and upper limits on capacity (number
of call-minutes) for carrier c in month t
C A S E
6.2 SELECTING TELECOMMUNICATION CARRIERS TO OBTAIN
VOLUME DISCOUNTS11
■The penalty per call-minute (to discourage poor-
quality options) for carrier c to destination d in
month t
V-Mobile wants to find a least-cost way of routing its
call-minutes through the various carriers. Of course,
it hopes to take advantage of price discounts offered
by the carriers.
The file Carrier Selection.xlsxprovides
inputs for one version of V-Mobile’s problem. This
version has T  2, C  3, D  5, and I  3. The
decision variables (changing cells) should include
the following:
■The number of call-minutes routed through
carrier c to destination d in price interval i in
month t
■A binary variable for each carrier c and price
interval i combination that equals 1 if the total
call-minutes for this carrier (over all destinations
and months) falls in price interval i, and equals
0 otherwise.
Develop an optimization model that helps V-Mobile
allocate its international calls in a cost-efficient
manner. Then write a brief memo stating (1) how 
V-Mobile should implement your results for this
particular version of the problem, and (2) how the
model would need to be modified for other potential
problem parameters. ■
11This case is based on van de Klundert et al. (2005).
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

353
Nonlinear Optimization Models
C H A P T E R
POR  TFOLIO  OPTIMIZA     TION     AT GE
P
ortfolio optimization, one of the models discussed in this chapter, is big
business. This is illustrated in the article by Chalermkraivuth et al. (2005).
They describe how GE Asset Management Incorporated (GEAM), a wholly
owned subsidiary of General Electric Company (GE), manages investment
portfolios on behalf of various GE units and more than 200 unaffiliated clients
worldwide worth billions of dollars. GEAM manages portfolios of assets pro-
duced by various insurance businesses, and its investments are primarily in
corporate and government bonds. The authors developed a special-purpose
algorithm for finding optimal portfolios. Since 2003, their algorithm has been
used to optimize more than 30 portfolios valued at over $30 billion. They esti-
mate that,based on $100 billion of assets,the present value of potential bene-
fits from their approach is approximately $75 million over a five-year period.
As in most portfolio optimization problems,GEAM wants to find
portfolios that provide appropriate risk/return trade-offs (preferably higher
expected returns and lower risk). However,the insurance industry is more
complex than this: portfolio managers must choose the assets within a port-
folio so that their characteristics match those of the firms’ liabilities. They try
to do this in such a way that the bonds and other financial instruments in the
portfolio are“immunized” against changes in the interest rates—one main
source of risk in bond portfolios. This can be done through a well-developed
financial theory of matching the“duration” and“convexity” of the assets and
wavebreakmedia ltd/2010/Used under license from Shutterstock.com
7
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

liabilities within an acceptable tolerance.[See Luenberger (1997),for example,for a dis-
cussion of the financial theory.] Using this theory,the authors formulated a portfolio opti-
mization model using the variance of economic surplus as a measure of risk,where
economic surplus is the difference between the market value of assets and liabilities.
Unfortunately, most GEAM portfolios consist of a large number of securities, and
the risk measure is inherently nonlinear. This combination—a large model with inherent
nonlinearity—is extremely difficult for even the best commercial optimization software.
Therefore, the authors developed their own algorithm to locate the efficient frontier,
that is, the set of portfolios that provide the maximum expected return for a given level
of risk. This approach is typical in the management science field. If analysts encounter a
problem that is either too large or too difficult to solve with existing algorithms, they try
to develop a new algorithm, usually specific to the problem, which can do the job. In the
authors’ algorithm, they first find the point on the efficient frontier that maximizes the
expected return, without any regard for risk. The result is typically a very risky portfolio.
Then, in general, given a set of portfolios on the efficient frontier, they find a nearby port-
folio with slightly less risk and slightly less expected return than the previous one. To do
this, they approximate the nonlinear portfolio variance by a linear function. This approxi-
mation has two properties that recommend it: (1) it is a very good approximation in the
area of the previous optimal portfolio, and (2) it yields a linear programming model that
can be solved fairly quickly.
In the modern spirit of management science, the authors went one step further.
They not only developed an algorithm that could be used to solve GEAM’s large prob-
lems, but they also developed a Web-based implementation that is easy for their clients
to use. With this system, which has been in place for several years, users do not need to
install software on their desktops. They can instead interact via the Web, which provides
the user interface. The Web application processes user inputs and requests and displays
results. An optimization engine called MATLAB handles all of the heavy number crunch-
ing on a centralized application server, and the required data is stored and accessed from
an Oracle database. Obviously, this is a complex setup, and months went into its devel-
opment. But this is a small price to pay for the benefits the portfolio optimization model
provides to GE and its customers. ■
7.1 INTRODUCTION
In many complex optimization problems, the objective and/or the constraints are nonlinear
functions of the decision variables. Such optimization problems are called nonlinear
programming (NLP) problems. In this chapter, we discuss a variety of interesting
problems with inherent nonlinearities, from product pricing to portfolio optimization to
rating sports teams.
A model can become nonlinear for several reasons, including the following:
■
There are nonconstant returns to scale, which means that the effect of some input on
some output is nonlinear. For example, consider the effect of advertising on sales.
Advertising typically creates a saturation effect, so that beyond some level, extra
advertising dollars have very little effect on sales—much less than the effect of
initial advertising dollars. This violates the proportionality assumption of linear
models discussed in Chapter 3.
■
In pricing models, where the goal is to maximize revenue (or profit), revenue is price
multiplied by quantity sold, and price is typically the decision variable. Because
354
Chapter 7
Nonlinear Optimization Models
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

quantity sold is related to price through a demand function, revenue is really price
multiplied by a function of price, and this product is a nonlinear function of price.
For example, even if the demand function is linear in price, the product of price and
demand is quadratic in price because it includes a squared price term.
■
Analysts often try to find the model that best fits observed data. To measure the
goodness of the fit, they typically sum the squared differences between the observed
values and the model’s predicted values. Then they attempt to minimize this sum of
squared differences. The squaring introduces nonlinearity.
■
In one of the most used financial models, the portfolio optimization model, financial
analysts try to invest in various securities to achieve high return and low risk. The
risk is typically measured as the variance (or standard deviation) of the portfolio, and
it is inherently a nonlinear function of the decision variables (the investment
amounts).
As these examples illustrate, nonlinear models are common in the real world. In fact,
it is probably more accurate to state that truly linear models are hard to find. The real
world often behaves in a nonlinear manner, so when you model a problem with LP, you are
typically approximating reality. By allowing nonlinearities in your models, you can often
create more realistic models. Unfortunately, this comes at a price—nonlinear optimization
models are more difficult to solve.
7.2 BASIC IDEAS OF NONLINEAR OPTIMIZATION
When you solve an LP problem with Solver, you are guaranteed that the Solver solution is
optimal. When you solve an NLP problem, however, Solver  sometimes obtains a subopti-
mal solution. For example, if you use Solver to maximize the function in Figure 7.1, it
might have difficulty. For the function graphed in this figure, points A and C are called
local maxima because the function is larger at A and C than at nearby points. However,
only point A actually maximizes the function; it is called the global maximum. The prob-
lem is that Solver can get stuck near point C, concluding that C maximizes the function,
and not find point A. Similarly, points B and D are local minima because the function has a
lower value at B and D than at nearby points. However, only point D is a global minimum.
If you ask Solver to minimize this function, it might conclude—incorrectly—that point B is
optimal.
7.2 Basic Ideas of Nonlinear Optimization
355
Nonlinear models are
often more realistic
than linear models, but
they are also more
difficult to solve.
A local optimum is better than all nearby points. A global optimum is the best
point in the entire feasible region. For some NLP problems, Solver can get stuck at a
local optimum and never find the global optimum.
A
C
B
D
Figure 7.1
Function with Local
Maxima and
Minima
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Convex and Concave Functions
Fortunately, Solver is guaranteed to solve certain types of NLPs correctly. To describe
these NLPs, we need to define convex and concave functions. A function of one variable is
convex in a region if its slope (rate of change) in that region is always nondecreasing.
Equivalently, a function of one variable is convex if a line drawn connecting two points on
the curve never lies below the curve.1 Figures 7.2 and 7.3 illustrate two examples of con-
vex functions. In Figure 7.2, the function first decreases and then increases, but the slope is
always increasing, first becoming less and less negative and then becoming more and more
positive. In contrast, the function in Figure 7.3 is always decreasing, but again the slope is
constantly increasing: It is becoming less and less negative.
356
Chapter 7
Nonlinear Optimization Models
A function is convex if its slope is always nondecreasing.
A function is concave if its slope is always nonincreasing.
Line joining any two points
is above the curve.
Figure 7.2
A Convex Function
with a Global
Minimum
Line joining any two points
is above the curve.
Figure 7.3
A Decreasing Convex
Function
The following are common examples of convex functions, although they are by no
means the only functions that are convex:
y  cxa, where a  1, c  0 and x  0
y  cex, where c  0
Similarly, a function of one variable is concave in a region if its slope is always
nonincreasing. Equivalently, a function of one variable is concave if a line drawn connect-
ing two points on the curve never lies above the curve. Figures 7.4 and 7.5 illustrate typical
concave functions. The first has a global maximum and the second is increasing, but the
slopes of both are constantly decreasing.
1For functions of several variables, the precise definition of convexity is more difficult to state. However, the
geometric idea of convexity given here suffices for this book.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

The following are common examples of concave functions, where ln(x) denotes the
natural logarithm of x:
y  c ln(x), where c  0 and x  0
y  cxa, where 0  a  1, c  0 and x  0
Note that a linear function (y  ax  b) is both convex and concave because the slope
of a linear function is constant.
For a more intuitive way to think about convex and concave functions, imagine you
are walking up a hill. If you are on a stretch where the hill keeps getting steeper every step
you take, you are on the convex part of the hill. If it keeps getting less steep, you are on the
concave part of the hill. Alternatively, if you are walking down a hill and it is getting less
steep with every step you take, you are on the convex part of the hill; if it is getting
steeper, you are on the concave part. In either case (walking uphill or downhill), if the
steepness is not changing, you are on the linear part of the hill, which means it is both
convex and concave.2
It can be shown that the sum of convex functions is convex and the sum of concave
functions is concave. Also, if you multiply any convex function by a positive constant, the
result is still convex, and if you multiply any concave function by a positive constant,
the result is still concave. However, if you multiply a convex function by a negative con-
stant, the result is concave, and if you multiply a concave function by a negative constant,
the result is convex.
7.2 Basic Ideas of Nonlinear Optimization
357
Line joining any two points
is below the curve.
Figure 7.4
A Concave Function
with a Global
Maximum
Line joining any two points
is below the curve.
Figure 7.5
An Increasing
Concave Function
2As still one more way of distinguishing convex and concave functions, convex functions “hold water” (see
Figure 7.2), and concave functions don’t hold water (see Figure 7.4).
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Problems That Solvers Always Solve Correctly
As Figure 7.2 suggests, Solver performs well for a minimization problem if the objective
function is convex. This is because convex functions cannot have a local minimum that is
not the global minimum. Similarly, Figure 7.4 suggests that Solver performs well for a
maximization problem if the objective function is concave. These statements can be gener-
alized to the situation where there are many decision variables and constraints. In fact, if
the following conditions hold, Solver is guaranteed to find the global minimum or global
maximum if it exists.3 (There are actually more general conditions than these, but they are
beyond the level of this book.)
Conditions for Maximization Problems
Solver is guaranteed to find the global maximum (if it exists) if the following are both true:
1.
The objective function is concave or the logarithm of the objective function is
concave.
2.
The constraints are linear.
Conditions for Minimization Problems
Solver is guaranteed to find the global minimum (if it exists) if the following are both true:
1.
The objective function is convex.
2.
The constraints are linear.
Therefore, if the constraints are linear, you need only check for the appropriate
concavity or convexity of the objective function to assure that Solver will find the optimal
solution (instead of a local, nonglobal optimum).
When the Assumptions Do Not Hold
There are many problems for which the conditions outlined previously do not hold or can-
not be verified. Because there is then some doubt whether Solver’s solution is the optimal
solution, the best strategy is to (1) try several possible starting values for the changing
cells, (2) run Solver from each of these, and (3) take the best solution Solver finds.
For example, consider the following NLP:
Maximize (x  1)(x  2)(x  3)(x  4)(x  5)
(7.1)
Subject to:
x  1 and x  5
This is the function shown in Figure 7.1, where the graph extends from x  1 to x  5.
Obviously, this function equals 0 when x equals 1, 2, 3, 4, or 5. (Just substitute any of these
values for x into the function.) From the graph, you can see that the global maximum is
between x  1 and x  2, but that there is a local maximum between x  3 and x  4. The
spreadsheet in Figure 7.6 shows the results of using Solver to solve this problem. (See the
file Local Maxima Finished.xlsx.) The results in columns A and B indicate what hap-
pens when the starting value in the changing cell is x  1.5. Solver eventually finds x 
1.355567 with a corresponding objective value of 3.631432. (The objective in cell B11 is
358
Chapter 7
Nonlinear Optimization Models
Unfortunately, the
conditions listed here
are often difficult to
check without a solid
background in calculus.
When an objective
function has multiple
local optima, the
solution Solver finds
can depend on the
starting solution in the
changing cells.
3The following discussion assumes that your spreadsheet contains no IF, MAX, MIN, or ABS statements that
depend on changing cells. Current-generation spreadsheet Solvers are not equipped to deal with these functions,
and errors often occur if they are present.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

the product of the five numbers above it, and the constraints are B5  5 and B5  1.)
However, given the identical setup in columns D and E, but with a starting value of x 
3.5, Solver finds the local maximum x  3.543912 and its corresponding objective value of
1.418697. This second solution is not the correct solution to the problem in Equation (7.1),
but Solver finds it because of an unlucky starting value of x.
In general, if you try several starting combinations for the changing cells and Solver
obtains the same optimal solution in all cases, you can be fairly confident—but still not
absolutely sure—that you have found the optimal solution to the NLP. On the other hand,
if you try different starting values for the changing cells and obtain several different solu-
tions, then all you can do is keep the best solution you have found and hope that it is indeed
optimal.
7.2 Basic Ideas of Nonlinear Optimization
359
1
2
3
4
5
6
7
8
9
10
11
A
B
C
D
E
Funcon with local and global maxima
The funcon is: y=(x-1)(x-2)(x-3)(x-4)(x-5)
x
1.355567
x
3.543912
x-1
0.355567
x-1
2.543912
x-2
-0.64443
x-2
1.543912
x-3
-1.64443
x-3
0.543912
x-4
-2.64443
x-4
-0.45609
x-5
-3.64443
x-5
-1.45609
Product
3.631432
Product
1.418697
Figure 7.6
Function with Local
and Global Maxima
FUNDAMENTAL INSIGHT
Local Optima versus Global Optima
Nonlinear objective functions can beha ve in man y
ways that make them difficult to optimize. In partic-
ular, they can ha ve local optima that ar e not the
global optim um, and nonlinear optimization alg o-
rithms can get stuck at such local optima.
The
important property of linear objectives that makes
the simplex method so successful—namely, that the
optimal solution is a corner point—no longer holds
for nonlinear objectives. Now any point in the feasi-
ble region can conceivably be optimal.This not only
makes the search for the optimal solution more dif-
ficult, but it also mak es it m uch mor e difficult to
recognize whether a pr omising solution (a local
optimum) is indeed the global optimum. This is why
researchers ha ve spent so m
uch eff ort tr ying 
to obtain conditions that,
when true , guarantee 
that a local optimum is a global optim um. Unfortu-
nately, these conditions ar
e often difficult to 
check.
Multistart Option
There is a welcome new feature in Solver for Excel 2010, the Multistart option. As dis-
cussed earlier, a nonlinear model can have local optima in addition to the global optimum,
in which case the solution that Solver finds can depend on the starting solution. Because it
is difficult to know where to start, the Multistart option provides an automatic way of start-
ing from a number of starting solutions. It selects several starting solutions automatically,
runs the GRG nonlinear algorithm from each, and reports the best solution it finds. The
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

360
Chapter 7
Nonlinear Optimization Models
Figure 7.7
Multistart Option 
in Excel 2010
only downside to this option is that it takes longer, so if you know that no local optima are
not globally optimal, there is no need to use this option.
To use the Multistart option, select the GRG Nonlinear method in the Solver dialog
box, click on Options and then on the GRG Nonlinear tab. You can then check the Use
Multistart box, as shown in Figure 7.7. As an example, we tried Multistart on the model in
Figure 7.6. Regardless of the starting value in cell E5, Solver always found the globally
optimal solution, 1.355567.
The three options within the Multistart box can be useful. The Population Size is the
number of starting solutions chosen. It must be at least 10, and 100 is suggested. The
Random Seed determines whether the starting solutions are the same from one run to
the next. If it is 0, the starting solutions are selected randomly, but if it is positive, they are
always the same. (This might be useful when several users are testing the same model.)
Finally, if the Require Bounds on Variables box is checked, you must include explicit
lower and upper bound constraints on all changing cells. Although this can be a nuisance,
Solver’s online help indicates that the Multistart option works much better if such bounds
exist. In fact, the tighter the bounds are, the less searching Solver needs to perform. Note
that if this box is checked and you do not have explicit lower and upper bounds, you will
get the error message in Figure 7.8.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

7.3 PRICING MODELS
Setting prices on products and services is becoming a critical decision for many compa-
nies. A good example is pricing hotel rooms and airline tickets. To many airline customers,
ticket pricing appears to be madness on the part of the airlines (how can it cost less to fly
thousands of miles to London than to fly a couple of hundred miles within the United
States?), but there is a method to the madness. In this section, we examine several pricing
problems that can be modeled as NLPs.
7.3 Pricing Models
361
Figure 7.8
Error Message about
Lack of Bounds on
Variables
T
he Madison Company manufactures and retails a certain product. The company wants
to determine the price that maximizes its profit from this product. The unit cost of pro-
ducing and marketing the product is $50. Madison will certainly charge at least $50 for the
product to ensure that it makes some profit. However, there is a very competitive market
for this product, so that Madison’s demand falls sharply when it increases its price. How
should the company proceed?4
Objective
To use a demand function in a nonlinear model to find the price that
maximizes the company’s profit.
WHERE DO THE NUMBERS COME FROM?
Cost accountants should be able to supply the unit cost. Historical data on demands and
prices of the product are needed to estimate the demand function, as discussed next.
Solution
The variables and constraints for this model are listed in Table 7.1. The unit price drives
everything. Through a demand function, price determines demand, and these combine to
E X A M P L E
7.1 PRICING DECISIONS AT MADISON
4This example and the next two are based on Dolan and Simon (1996).
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

determine the revenue, cost, and profit. (We assume the company produces only what it
can sell—that is, it observes its demand and then produces exactly this much.) The only
constraint is that the company doesn’t want to charge a price less than its unit cost.
More specifically, if Madison charges P dollars per unit, then its profit is (P  50)D,
where D is the demand. The problem, however, is that D depends on P. As the price P
increases, the demand D decreases. Therefore, the first step is to estimate how D varies
with P—that is, to estimate the demand function. In fact, this is the first step in almost all
pricing problems. We illustrate two possibilities: a linear demand function of the form D
 a  bP, and a constant elasticity demand function of the form D  aPb.
Estimating the Demand Function
You might recall from microeconomics that the elasticity of demand is the percentage
change in demand caused by a 1% increase in price. The larger the (magnitude of) elas-
ticity, the more demand reacts to price changes. The advantage of the constant elasticity
demand function is that the elasticity remains constant over all points on the demand
curve. For example, the elasticity of demand is the same when the price is $60 as when
the price is $70. Actually, the exponent b in the constant elasticity demand function is
approximately equal to this constant elasticity. For example, if b  2.5, demand
decreases by about 2.5% when price increases by 1%. In contrast, the elasticity changes
for different price levels when the demand function is linear. Nevertheless, both forms
of demand functions are commonly used in economic models, and either could be used
here.
Regardless of the form of the demand function, the parameters of the function (a and
b) must be estimated before any price optimization can be performed. This can be done
with Excel trend lines. (Trend lines were introduced in Chapter 2 and are discussed in
more detail in Chapter 14.) Suppose that Madison can estimate two points on the
demand curve. (At least two are required. More than two can be used in the same way.)
Specifically, suppose the company estimates demand to be 400 units when price equals
$70 and 300 units when price equals $80. Then you can create a scatter chart of demand
versus price from these two points, select any point on the chart, and use Excel’s
Trendline tool with the option to list the equation of the trend line on the chart. For a lin-
ear demand curve, you should select the Linear Trendline option, and for the constant
elasticity demand curve, you should select the Power Trendline option. (The relevant
dialog box appears in Figure 7.9. To get to it, right-click on any point on the chart and
select Add Trendline.)
The results are presented in Figure 7.10, where both the linear estimate and the con-
stant elasticity estimate are shown. (When you do this, the constant for the constant elas-
ticity curve might appear as 4E+06. To get more significant digits, just click on the
equation and then use the Format menu and the Number tab to format the number appro-
priately.) Either of these trend line equations can be used as an estimate of the demand
function for the pricing model.
362
Chapter 7
Nonlinear Optimization Models
Table 7.1
Variables and Constraints for Madison’s Pricing Model
Input variables
Unit cost, demand function (or points on demand 
function)
Decision variables (changing cells)
Unit price to charge
Objective (target cell)
Profit
Other output variables
Revenue, cost
Constraints
Unit price  Unit cost
The elasticity of
demand measures the
sensitivity of demand
to changes in price.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

7.3 Pricing Models
363
Figure 7.9
Excel’s Add 
Trendline Dialog 
Box
1
2
A
B
C
D
E
F
G
H
I
J
K
L
M
N
O
P
Madison pricing model - ﬁnding demand funcons
2
3
4
5
6
7
8
9
10
11
12
13
Two points on the demand curve (as esmated by Madison)
Price
Demand
$70
400
$80
300
370
390
410
Linear demand curve
370
390
410
Constant elascity demand curve
13
14
15
16
17
18
19
20
21
22
23
y = -10x + 1100
250
270
290
310
330
350
370
$65
$70
$75
$80
$85
y = 3777177.547x-2.154
250
270
290
310
330
350
370
$65
$70
$75
$80
$85
Figure 7.10
Determining Parameters of Demand Functions 
DEVELOPING THE SPREADSHEET MODEL
Given a demand function, the pricing decision is straightforward, as shown in Figure 7.11.
(See the file Basic Pricing.xlsx.) Here we have used the constant elasticity demand curve.
(The model for linear demand is similar. The finished version of the file illustrates both
cases.) The model requires the following steps:
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

1
Inputs. The inputs for this model are the unit cost and the parameters of the demand
function found previously. Enter them as shown.
2
Price. Enter any trial value for price. It is the single changing cell.
3
Demand. Calculate the corresponding demand from the demand function by entering
the formula
=B7*Price2^C7
in cell B11. (To minimize range name conflicts, we used the names Price1, Unit_cost1, and
Profit1 for the linear demand model, and we used Price2, Unit_cost2, and Profit2 for the
constant elasticity model.)
4
Profit. Calculate the profit as unit contribution (price minus unit cost) multiplied by
demand with the formula
=(Price2-Unit_cost2)*B11
in cell B12.
USING SOLVER
The relevant Solver dialog box is shown in Figure 7.12. The objective is to maximize profit
subject to the constraint that price must be at least as large as unit cost, with price as the
only decision variable. However, you should choose the GRG Nonlinear method, not the
Simplex LP method. This model is nonlinear for two reasons. First, the demand function is
nonlinear in price because price is raised to a power. But even if the demand function were
linear, profit would still be nonlinear because it involves the product of price and demand,
and demand is a function of price. This nonlinearity can be seen easily with the data table
364
Chapter 7
Nonlinear Optimization Models
1
A
B
C
D
E
F
G
H
I
J
K
Madison pricing model with constant elascity demand funcon
Range names used:
1
2
3
4
5
6
7
8
9
Madison pricing model with constant elascity demand funcon
Range names used:
Price2
='Constant Elascity'!$B$10
Unit 
t
n
a
ts
n
o
C'=
2
tif
o
r
P
0
5
$
ts
o
c
 Elascity'!$B$12
Unit_cost2
='Constant Elascity'!$B$3
Parameters of constant elascity demand funcon (from ﬁrst sheet)
Constant
Elascity
3777178
-2.154
Pricing model
9
10
11
12
13
14
15
16
17
Pricing model
Price
$93.31
Demand
$215.33
Proﬁt
$9,326
Veriﬁcaon with a data table and corresponding chart
Price
Proﬁt
$9,326
$55
$3 363
Proﬁt versus Price
17
18
19
20
21
22
23
24
25
$55
$3,363
$60
$5,576
$65
$7,039
$70
$8,000
$75
$8,619
$80
$9,000
$85
$9,214
$90
$9,311
$95
$9 323
$1,000
$2,000
$3,000
$4,000
$5,000
$6,000
$7,000
$8,000
$9,000
$10,000
Proﬁt
25
26
27
28
$95
$9,323
$100
$9,275
$105
$9,184
$110
$9,064
$55 $60 $65 $70 $75 $80 $85 $90 $95 $100 $105 $110
Price
$0
Figure 7.11
Pricing Model with
Constant Elasticity
Demand
If you select the Simplex
LP method for any 
model in this chapter,
you will get an error
message.This is because
Solver automatically
recognizes that these
models are nonlinear.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

and corresponding chart in Figure 7.11. These show how profit varies with price—the rela-
tionship is clearly nonlinear. Profit increases to a maximum, and then declines slowly.
(This type of data table and chart are useful in nonlinear models with a single changing
cell. They show exactly how the objective changes as the changing cell changes. We
employ these data tables in other nonlinear examples whenever possible.)
Discussion of the Solution
Guessing the optimal price in this type of model is usually not easy. As the company
increases its price, it makes more money on each unit sold, but it sells fewer units.
Therefore, the trade-off is always between selling a few relatively high-priced units and sell-
ing a lot of relatively low-priced units. Complicating the matter is the fact that as price
increases, total cost decreases (because fewer units are demanded). In the present case, you
can see from the graph in Figure 7.11 that profit increases fairly quickly as price goes from
$55 to about $85. After this point, profit is almost unaffected by price (at least for the range
of prices shown), and any price from $85 to about $110 results in a profit within $200 of the
optimal profit. Of course, Solver does better than this; it finds the optimal price, $93.31.
Is the Solver Solution Optimal?
In general, there is no guarantee that profit is a concave function for all possible inputs to
this model. However, the graph in Figure 7.11 indicates that it is concave for the particular
inputs we have used and that the Solver solution is indeed optimal (because there is no
local maximum that isn’t a global maximum). In this case, the Multistart option was not
used. However, if you want to use it, you should add an upper bound constraint on price—
even a large one such as Price2  200.
Sensitivity Analysis
From an economic point of view, it should be interesting to see how the profit-maximizing
price varies with the elasticity of the demand function. To do this, use SolverTable with
7.3 Pricing Models
365
Figure 7.12
Solver Dialog Box
for the Pricing
Model
Pricing problems are
inherently nonlinear,
and the trade-off
between selling a lot
of units at a low price
and selling fewer units
at a higher price is
difficult to make.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

the elasticity in cell C7 as the single input cell, allowing it to vary from 2.4 to 1.8 in
increments of 0.1.5 (Note that when the range of input values is negative, the one with the
largest magnitude must be entered first in the SolverTable dialog box.) The results are
shown in Figure 7.13. When the demand is most elastic (at the top of the table), increases
in price have a greater effect on demand. Therefore, the company should not set the price
as high in this case. Interestingly, when demand is least elastic, the company should not
only charge a higher price, but this price results in a much higher profit. Would you have
guessed this?
■
366
Chapter 7
Nonlinear Optimization Models
1
2
3
4
5
6
7
8
9
10
11
A
B
C
D
E
F
Oneway analysis for Solver model in Constant Elascity worksheet
Price (cell $C$7) values along side, output cell(s) along top
Price2
Demand
Proﬁt2
-2.400
$85.71
$86.66
$3,095
-2.300
$88.46
$125.79
$4,838
-2.200
$91.67
$182.10
$7,587
-2.100
$95.45
$262.78
$11,945
-2.000
$100.00
$377.72
$18,886
-1.900
$105.56
$540.20
$30,011
-1.800
$112.50
$767.53
$47,970
Figure 7.13
Sensitivity to
Elasticity of
Demand
5Solver does provide a sensitivity report for nonlinear models. However, the mathematical theory behind this
report is significantly more complex than for linear models, so we present only SolverTable outputs in this
chapter.
E X A M P L E
7.2 PRICING WITH EXCHANGE RATE CONSIDERATIONS AT MADISON
W
e continue Example 7.1 but now assume that Madison manufactures its product in
the United States and sells it in the United Kingdom (UK). Given the prevailing
exchange rate in dollars per pound, Madison wants to determine the price in pounds it
should charge in the UK so that its profit in dollars is maximized. The company also wants
to see how the optimal price and the optimal profit depend on exchange rate fluctuations.
Objective
To use a nonlinear model to find the price in pounds that maximizes the profit
in dollars.
WHERE DO THE NUMBERS COME FROM?
The only new input in this model is the exchange rate, which is readily available. For
example, you can find exchange rates at http://www.oanda.com/convert/classic.
Solution
The model is shown in Figure 7.14. (See the file Pricing Globally.xlsx.) It is very similar
to the previous model, so we highlight only the new features. The exchange rate in cell B4
indicates the number of dollars required to purchase one pound. For example, with an
exchange rate of 1.52, it takes $1.52 to purchase one pound. Alternatively, 11.52  £0.658
is required to purchase one dollar. As this exchange rate decreases, you say that the dollar
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

gets stronger; as it increases, the dollar gets weaker. Note that you divide by the exchange
rate to convert dollars to pounds, and you multiply by the exchange rate to convert pounds
to dollars. With this in mind, the model development is straightforward.
DEVELOPING THE SPREADSHEET MODEL
The following steps are required:
1
Inputs. The inputs are the unit cost (in dollars), the exchange rate, and the parameters
of the company’s demand function for the UK market. These latter values would need to be
estimated exactly as discussed in the previous example. This examples uses “reasonable”
values for these parameters, as shown in row 10.
2
Unit cost in pounds. Although Madison’s unit cost occurs in the United States and is
expressed in dollars, it is convenient to express it in pounds. Do this in cell B6 with the
formula
=B3/B4
(This value is used to form a constraint on the price: the unit price in pounds must be no
less than the unit cost, measured in the same currency.)
3
Price, demand. As in the previous example, enter any price in cell B13 (which is
now in pounds), and calculate the demand in cell B14 from the demand function with the
formula
=B10*Price_Pounds^C10
4
Profit. The profit should be in dollars, so enter the formula
=(Price_Pounds*B4-B3)*B14
7.3 Pricing Models
367
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
A
B
C
D
E
F
G
H
I
Madison pricing problem in a UK market
Unit cost 
0
5
)
$
(
Range names used:
Exchange rate ($/£)
3
1
$
B
$
!le
d
o
M
=
s
d
n
u
o
P
_
e
cir
P
2
5.1
Proﬁt_Dollars
=Model!$B$15
Equivalent unit cost in 
6
$
B
$
!le
d
o
M
=
s
d
n
u
o
P
_
ts
o
C
tin
U
5
9
8.2
3
s
d
n
u
o
p
Parameters of demand funcon in UK market
Constant
Elascity
27556759.61
-2.4
Pricing model (ﬁnding the right price in £ to maximize proﬁt in $)
Price (£)
56.39
Demand (in 
3
1.7
2
7
1
)
K
U
Proﬁt 
2
2.3
8
6
1
6
)
$
(
Veriﬁcaon with a data table and corresponding chart
Price (£)
$B$13
61683.22
25
0.00
30
78548.36
35
108516.26
40
118142.30
45
118734.82
50
115257.75
55
110029.45
60
104174.92
65
98248.53
70
92519.94
75
87112.63
80
82073.86
0
20000
40000
60000
80000
100000
120000
140000
25
35
45
55
65
75
Proﬁt ($)
Price (£)
Proﬁt versus Price
Figure 7.14
The Pricing Model
in a Foreign Market
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

in cell B15. Note that the unit cost is already in dollars, but the UK price must be converted
to dollars.
USING SOLVER
The Solver dialog box (not shown here) is set up exactly as in Figure 7.12, except that the
constraint on price is now Price_Pounds  UnitCost_Pounds, so that pounds are compared
to pounds. In fact, the specification of this constraint is the only place where the value in
cell B6 enters the model.
Discussion of the Solution
The optimal solution, with an exchange rate of 1.52, says that Madison should charge  £56.39
per unit in the UK. This creates demand for about 1727 units. Each of these costs $50 to pro-
duce, and the dollar revenue from each of them is 56.39(1.52), or $85.71. The resulting profit
in dollars is approximately $61,683. The graph in Figure 7.14, created from a data table of
profit versus price, shows how profit declines on either side of the optimal price.
Is the Solver Solution Optimal?
As in the previous example, the objective is not necessarily a concave function of price for all
possible values of the input parameters. However, the graph in Figure 7.14 indicates that it is
concave for our particular input parameters and that the Solver solution is indeed optimal.
Therefore, the Multistart option is not necessary.
Sensitivity Analysis
What happens when the dollar gets stronger or weaker? You can use SolverTable with the
exchange rate as the single input, allowing it to vary from 1.75 to 2.25 in increments of
0.05, and keeping track of price, demand, and profit. The results in Figure 7.15 indicate
that as the exchange rate increases (the dollar weakens), Madison charges less in pounds
for the product but obtains a higher profit. The opposite is true when the dollar strengthens.
Are these results in line with your economic intuition? Note that when the dollar strength-
ens, pounds are not worth as much to a U.S. company. Therefore, when the pound revenue
is converted to dollars in the profit cell, the profit tends to decrease. But in this case, why
does the optimal price in pounds increase? We will say no more here—except that this
should be a good question for class discussion.
368
Chapter 7
Nonlinear Optimization Models
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
A
B
C
D
E
F
Oneway analysis for Solver model in Model worksheet
Exchange rate (cell $B$4) values along side, output cell(s) along top
Price_Pounds
Demand
Proﬁt_Dollars
1.30
65.93
1186.76
42384.44
1.35
63.49
1299.28
46402.71
1.40
61.22
1417.78
50634.87
1.45
59.11
1542.35
55084.01
1.50
57.14
1673.09
59753.24
1.55
55.30
1810.07
64645.52
1.60
53.57
1953.39
69763.83
1.65
51.95
2103.11
75111.06
1.70
50.42
2259.32
80690.01
1.75
48.98
2422.10
86503.51
1.80
47.62
2591.52
92554.26
1.85
46.33
2767.66
98844.95
1.90
45.11
2950.59 105378.26
1.95
43.96
3140.39 112156.76
2.00
42.86
3337.12 119183.02
Figure 7.15
Sensitivity of the
Optimal Solution to
the Exchange Rate
■
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Many products create add-ons to other products. For example, if you own a men’s
clothing store, you should recognize that when a person buys a suit, he often buys a shirt or
a tie. Failure to take this into account causes you to price your suits too high—and lose
potential sales of shirts and ties. The following example illustrates the idea.
7.3 Pricing Models
369
E X A M P L E
7.3 PRICING SUITS AT SULLIVAN’S
S
ullivan’s is a retailer of upscale men’s clothing. Suits cost Sullivan’s $320. The current
price of suits to customers is $350, which leads to annual sales of 300 suits. The
elasticity of the demand for men’s suits is estimated to be 2.5 and assumed to be constant
over the relevant price range. Each purchase of a suit leads to an average of 2.0 shirts and
1.5 ties being sold. Each shirt contributes $25 to profit, and each tie contributes $15 to
profit. Determine a profit-maximizing price for suits.
Objective
To use a nonlinear model to price men’s suits optimally, taking into account
the purchases of shirts and ties that typically accompany purchases of suits.
WHERE DO THE NUMBERS COME FROM?
The dollar figures are likely supplied by a cost accountant. The elasticity of demand can be
estimated from historical data on demands and prices, as discussed in Example 7.1.
Finally, the average numbers of shirts and ties sold with suit purchases are available from
historical data, assuming the company keeps track of such complementary purchases. (If
the company doesn’t keep track of such data, it should.)
Solution
The variables and constraints for this pricing model are listed in Table 7.2. As in the
previous two examples, you must first determine the demand function for suits. Although
this could be a linear function or some other form, we again assume a constant elasticity
function of the form D  aPb, where the exponent b is the elasticity. The solution from this
point is practically the same as the solution to Example 7.1 except for the profit function.
Each suit sold also generates demand for 2.0 shirts and 1.5 ties (on average), which
contributes 2.0(25)  1.5(15) extra dollars in profit. Therefore, it makes sense that the
profit-maximizing price for suits is lower than in the absence of shirts and ties. The com-
pany wants to generate more demand for suits so that it can reap the benefits from shirts
and ties. The only constraint is that the price of suits should be at least as large as the unit
cost of suits. (Is this constraint really necessary? We discuss this question shortly.)
Table 7.2
Variables and Constraints for the Suit Pricing Model
Input variables
Unit cost of suit, current price of suit, current demand for suits, 
elasticity of demand, ties and shirts purchased per suit, unit profits 
from a tie and a shirt
Decision variables 
Price to charge for a suit
(changing cells)
Objective (target cell)
Total profit
Other output 
Constant in demand function, demand for suits, 
variables
profit from suits alone, profit from ties and shirts
Constraints
Price of suit  Unit cost of suit (necessary?)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

DEVELOPING THE SPREADSHEET MODEL
The spreadsheet solution appears in Figure 7.16. (See the file Pricing with Add-Ons.xlsx.)
Instead of solving a single model, you will actually solve two: the one stated previously and
one where shirts and ties are ignored. This way you can see the effect that shirts and ties
have on the optimal price of suits. You could set this up as two distinct models, but a clever
use of SolverTable allows you to treat both cases in a single model. The following steps are
required.
370
Chapter 7
Nonlinear Optimization Models
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
A
B
C
D
E
F
G
H
I
J
Pricing complementary products
y
r
a
t
n
e
m
elp
m
o
C
stiu
S
 products
Range names used:
Current 
3
1
$
B
$
!le
d
o
M
=
e
cir
P
strih
S
s
eiT
0
5
3
$
e
cir
p
Current 
stin
U
0
0
3
d
n
a
m
e
d
 sold per suit
1.5
2.0
Proﬁt
=Model!$B$15
Unit 
tif
o
r
P
0
2
3
$
ts
o
c
 per unit
$15
$25
UnitCost
=Model!$B$6
Demand 
ytivitis
n
e
S
n
oitc
n
u
f
 factor for units sold per suit
0.1
5
4
5,9
2
5,7
8
6
t
n
a
ts
n
o
C
Elascity
-2.5
Decision taking complementary products into account
0
5.2
1
4
$
e
cir
P
9.8
9
1
d
n
a
m
e
D
Proﬁt from suits only
$18,402
Proﬁt from shirts and es
$14,423
Total 
6
2
8,2
3
$
tif
o
r
p
Veriﬁcaon with a data table and corresponding chart
Price
Proﬁt
$32,826
380
$32,363
390
$32,617
400
$32,765
410
$32,824
420
$32,806
430
$32,725
440
$32,590
450
$32,410
460
$32,193
470
$31,943
480
$31,667
$31,600
$31,800
$32,000
$32,200
$32,400
$32,600
$32,800
$33,000
$380 $390 $400 $410 $420 $430 $440 $450 $460 $470 $480
Proﬁt
Price
Proﬁt versus Price
Figure 7.16
The Pricing Model
with Complementary
Products
1
Inputs. Enter all inputs in the blue regions.
2
Constant for demand function. The demand function is of the form D  aPb. You
can find the constant a from the current demand and price for suits: 300  a(3502.5), so
that a  300	3502.5. Therefore, calculate this constant a in cell B9 with the formula
=B5/B4^B10
3
Sensitivity factor. The model treats both cases, when shirts and ties are ignored and
when they are not, by using SolverTable with a “sensitivity factor” as the input cell. When
this factor is 0, the complementary products are ignored; when it is positive, they are taken
into consideration. Enter 1 in the sensitivity factor cell E9 for now. In general, this factor
determines the average number of shirts and ties purchased with the purchase of a suit—this
factor is multiplied by the values in the E5:F5 range. When this factor is 1, you get the val-
ues in the statement of the problem. When it is 0, no shirts and ties are purchased with a suit.
4
Price, demand. Enter any price in cell B13, and calculate the corresponding demand
for suits in cell B14 with the formula
=B9*B13^B10
5
Profits. The total profit is the profit from suits alone, plus the extra profit from shirts
and ties that are purchased along with suits. Calculate the first of these in cell B15 with the
formula
As this example
illustrates, a clever
use of SolverTable
sometimes enables you
to solve multiple
problems at once.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

=(Price-Unit cost)*B14
and calculate the second in cell B16 with the formula
=E9*SUMPRODUCT(E5:F5,E6:F6)*B14
Then sum them to get the total profit in cell B17. Note that the sensitivity factor in cell E9
scales the extra profit, depending on how many ties and shirts per suit are sold. If the value
in cell E9 is 0, no shirts and ties are sold; if this value is 1, the numbers of shirts and ties
stated in the problem are sold.
USING SOLVER
The Solver setup, not shown here, is the same as in Example 7.1. The objective is to max-
imize profit, with the price of suits as the only changing cell. The only constraint is that
this price must be at least as large as the unit cost of suits.
Discussion of the Solution
The solution in Figure 7.16 uses a sensitivity factor of 1 in cell E9, which means that every
suit sale is accompanied (on average) by the sale of 2.0 shirts and 1.5 ties. This induces the
company to keep the suit price relatively low, at $412.50, so that it can sell a lot of suits and
therefore a lot of shirts and ties. In fact, you can see that the total profit is nearly evenly
divided between the profit from suits and the profit from shirts and ties.
To see the effect of complementary products, run SolverTable with cell E9 as the single
input cell, varied, say, from 0 to 2 (or any other upper limit you like) in increments of 0.5,
and keep track of price, demand, and profit. (See Figure 7.17). The SolverTable results
show that when the company ignores shirts and ties (or, equivalently, suits do not generate
any demand for shirts and ties), the optimal price is set high, at $533.33. However, as more
ties and shirts are purchased by purchasers of suits, the optimal price of suits decreases
fairly dramatically. As you would expect, as more shirts and ties are purchased with suits,
the company makes more profit—if it takes shirts and ties into account and prices suits
properly. Interestingly, if the sensitivity factor increases to 2, so that customers on average
buy 3 ties and 4 shirts with every suit, the company sets its price so that it just breaks
even on suits and makes all of its profit on ties and shirts. (If you are skeptical of this
result, read the “Is the Constraint Needed?” section that follows.)
7.3 Pricing Models
371
Figure 7.17
Effect of the
Sensitivity Factor 
on Pricing 
The potential sales
of complementary
products induces a
company to price its
main product lower
than if there were no
complementary
products.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
A
B
C
D
E
F
G
Oneway analysis for Solver model in Model worksheet
Sensivity factor (cell $E$9) values along side, output cell(s) along top
Price
$B$14
$B$15
$B$16
Proﬁt
0.0
$533.33
104.7
$22,328
$0
$22,328
0.5
$472.92
141.4
$21,616
$5,124
$26,741
1.0
$412.50
198.9
$18,402
$14,423
$32,826
1.5
$352.08
295.6
$9,483
$32,145
$41,628
2.0
$320.00
375.3
$0
$54,423
$54,423
Note that when sensivity factor is 
0, it is as if complementary 
products are ignored.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

For the situation in the problem statement, how much profit does the company lose if it
ignores shirts and ties? You can answer this by entering $533.33 in the Price cell, keeping
the sensitivity factor equal to 1. You will find that profit decreases from $32,826 to
$29,916, which is a drop of about 9%. This is the penalty for pricing in a way that ignores
shirts and ties.
Is the Solver Solution Optimal?
As in the preceding two examples, the graph in Figure 7.16, formed from a data table of
profit versus price, indicates that the Solver solution is optimal—there are no local maxima.
Therefore, the Multistart option is not necessary.
Is the Constraint Needed?
In pricing models, you hardly think twice before constraining the price to be at least as
large as the unit cost. However, it might make sense to price a product below cost if sales
of this product lead to sales—and profits—from other products. Therefore, we deleted
the constraint on price in the example and reran SolverTable. The results appear in
Figure 7.18. The only change is in row 25, where the sensitivity factor is 2. We now price
the suits below cost, just to sell more shirts and ties. In fact, the only reason we priced to
break even in this row before was the constraint—we didn’t allow a price below the unit
cost. When we allow this behavior, the profit increases from its earlier value of $54,423
to $55,210.
372
Chapter 7
Nonlinear Optimization Models
1
2
3
4
5
6
7
8
9
10
11
12
13
A
B
C
D
E
F
G
Oneway analysis for Solver model in Pricing below cost worksheet
Sensivity factor (cell $E$9) values along side, output cell(s) along top
Price
$B$14
$B$15
$B$16
Proﬁt
0.0
$533.33
104.7
$22,328
$0
$22,328
0.5
$472.92
141.4
$21,616
$5,124
$26,741
1.0
$412.50
198.9
$18,402
$14,423
$32,826
1.5
$352.08
295.6
$9,483
$32,145
$41,628
2.0
$291.67
473.2
-$13,408
$68,619
$55,210
Pricing below cost is indeed 
opmal in the last row.
Figure 7.18
Solution with
Pricing Below Cost
Allowed
Automobile and appliance dealers who profit from maintenance contracts could proba-
bly increase their profits significantly if they factored the profits from the maintenance
agreements into the determination of prices of their major products. That is, we suspect
that the prices of their major products are set too high—not from the customers’ standpoint
but from the dealers’. Probably the ultimate tie-in reduction in price is the fact that many
companies now provide free software. They are hoping, of course, that the receiver of free
software will later buy the tie-in product, which is the upgrade. ■
In many situations, there are peak-load and off-peak demands for a product. In such a
situation, it might be optimal for a producer to charge a larger price for peak-load service
than for off-peak service. The following example illustrates this situation.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Due to the relationships between the demand and price variables, it is not obvious what
FPL should do. The pricing decisions determine demand, and larger demand requires
7.3 Pricing Models
373
E X A M P L E
7.4 PEAK-LOAD PRICING AT FLORIDA POWER AND LIGHT
F
lorida Power and Light (FPL) faces demands during both peak-load and off-peak
times. FPL must determine the price per kilowatt hour (kwh) to charge during both
peak-load and off-peak periods. The daily demand for power during each period (in kwh)
is related to price as follows:
Dp  60  0.5Pp  0.1Po
(7.2)
Do  40  Po  0.1Pp
(7.3)
Here, Dp and Pp are demand and price during peak-load times, whereas Do and Po are
demand and price during off-peak times. Note that these are linear demand functions, not
the constant elasticity demand functions from the previous examples. (We do this for the
sake of variety. The model would not differ substantially with constant elasticity demand
functions.) Also, note from the signs of the coefficients that an increase in the peak-load
price decreases the demand for power during the peak-load period but increases the
demand for power during the off-peak period. Similarly, an increase in the price for the off-
peak period decreases the demand for the off-peak period but increases the demand for the
peak-load period. In economic terms, this implies that peak-load power and off-peak
power are substitutes for one another. In addition, it costs FPL $10 per day to maintain 1
kwh of capacity. The company wants to determine a pricing strategy and a capacity level
that maximize its daily profit.
Objective
To use a nonlinear model to determine prices and capacity when there are two
different daily usage patterns: peak load and off peak.
WHERE DO THE NUMBERS COME FROM?
As usual, a cost accountant should be able to estimate the unit cost of capacity. The real
difficulty here is estimating the demand functions in Equations (7.2) and (7.3). This
requires either sufficient historical data on prices and demands (for both peak-load and off-
peak periods) or educated guesses from management.
Solution
The variables and constraints for this model are listed in Table 7.3. The company must
decide on two prices and the amount of capacity to maintain. Because this capacity level,
once determined, is relevant for peak-load and off-peak periods, it must be large enough to
meet demands for both periods. This is the reasoning behind the constraint.
The capacity must be
at least as large as
the peak-load and
off-peak demands.
Actually, there is no
incentive for the
capacity to be larger
than the maximum
of these two demands.
Table 7.3
Variables and Constraints for the Peak-Load Pricing Model
Input variables
Parameters of demand functions, unit cost of capacity
Decision variables (changing cells)
Peak-load and off-peak prices, capacity
Objective (target cell)
Profit
Other output variables
Peak-load and off-peak demands, revenue, cost of 
capacity
Constraints
Demands  Capacity
The positive
coefficients of prices
in these demand
equations indicate 
substitute behavior.
A larger price for one
product tends to
induce customers to
demand more of the
other.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

larger capacity, which costs money. In addition, revenue is price multiplied by demand, so
it is not clear whether price should be low or high to increase revenue.
DEVELOPING THE SPREADSHEET MODEL
The spreadsheet model appears in Figure 7.19. (See the file Peak-Load Pricing.xlsx.) It
can be developed as follows:
1
Inputs. Enter the parameters of the demand functions and the cost of capacity in the
blue ranges.
2
Prices and capacity level. Enter any trial prices (per kwh) for peak-load and off-peak
power in the Prices range, and enter any trial value for the capacity level in the Capacity
cell. These are the three values FPL has control over, so they become the changing cells.
3
Demands. Calculate the demand for the peak-load period by substituting into
Equation (7.2). That is, enter the formula
=B6+SUMPRODUCT(Prices,C6:D6)
in cell B19. Similarly, enter the formula
=B7+SUMPRODUCT(Prices,C7:D7)
in cell C19 for the off-peak demand.
4
Copy capacity. To indicate the capacity constraints, enter the formula
=Capacity
in cells B21 and C21. The reason for creating these links is that the two demand cells in row
19 need to be paired with two capacity cells in row 21 so that the Solver constraints can be
specified appropriately. (Solver doesn’t allow a “two versus one” constraint such as B19:C19
 B15.)
374
Chapter 7
Nonlinear Optimization Models
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
A
B
C
D
E
F
G
H
I
Florida Power & Light peak-load pricing model
Input 
e
g
n
a
R
a
t
a
d
 names used:
Coeﬃcients of demand 
5
1
$
B
$
!
d
a
o
L
k
a
e
P
=
ytic
a
p
a
C
s
n
oitc
n
u
f
Constant
Peak price
Oﬀ-peak price
Common_Capacity
=PeakLoad!$B$21:$C$21
Peak-load demand
60
-0.5
0.1
Demands
=PeakLoad!$B$19:$C$19
Oﬀ-peak demand
40
0.1
-1
Prices
=PeakLoad!$B$13:$C$13
Proﬁt
=PeakLoad!$B$26
Cost of capacity/kwh
$10
Decisions
Peak-load
Oﬀ-peak
Prices
$70.31
$26.53
Capacity
27.50
Constraints on demand
Peak-load
Oﬀ-peak
Demand
27.50
20.50
<=
<=
Capacity
27.50
27.50
Monetary summary
Revenue
$2,477.30
Cost of capacity
$275.00
Proﬁt
$2,202.30
Figure 7.19
The Peak-Load Pricing Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

5
Monetary v alues. Calculate the daily revenue, cost of capacity, and profit in the
corresponding cells with the formulas
=SUMPRODUCT(Demands,Prices)
=Capacity*B9
and
=B24-B25
USING SOLVER
The Solver dialog box should be filled in as shown in Figure 7.20. The goal is to maximize profit
by setting appropriate prices and capacity and ensuring that demand never exceeds capacity.
You should also check the Non-Negative option (prices and capacity cannot be negative), and
you should select the GRG Nonlinear method. Again, this is because prices are multiplied by
demands, which are functions of prices, so that profit is a nonlinear function of the prices.
Discussion of the Solution
The Solver solution in Figure 7.19 indicates that FPL should charge $70.31 per kwh during
the peak-load period and $26.53 during the off-peak-load period. These prices generate
demands of 27.5 (peak load) and 20.5 (off peak), so that a capacity of 27.5 kwh is required.
The cost of this capacity is $275. When this is subtracted from the revenue of $2477.30,
the daily profit becomes $2202.30.
7.3 Pricing Models
375
Figure 7.20
Solver Dialog Box
for the Peak-Load
Pricing Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

To gain some insight into this solution, consider what happens if FPL changes the peak-
load price slightly from its optimal value of $70.31. If FPL decreases the price to $70, say,
you can check that the peak-load demand increases to 27.65 and the off-peak demand
decreases to 20.47. The net effect is that revenue increases slightly, to $2478.78. However,
the peak-load demand is now greater than capacity, so FPL must increase its capacity from
27.50 to 27.65. This costs an extra $1.50, which more than offsets the increase in revenue.
A similar chain of effects occurs if FPL increases the peak price to $71. In this case, peak-
load demand decreases, off-peak demand increases, and total revenue decreases. Although
FPL can get by with lower capacity, the net effect is slightly less profit. Fortunately, Solver
evaluates all of these trade-offs for you when it finds the optimal solution.
Is the Solver Solution Optimal?
All of the constraints in this example are linear, so they certainly meet the assumptions
for a maximization problem. Also, it can be shown that the objective (daily profit) is a
concave function of peak-load price, off-peak price, and capacity level—although this is
far from obvious. (It requires calculus to verify.) Algebraically, this objective function is
called quadratic, meaning that it is a sum of linear terms (such as Pp), squared terms
(such as Pp
2), and cross-product terms (such as PpPo). Not all quadratic functions are
concave, but there is a test to check whether a given quadratic function is concave.
(Although the details of this test are not presented here, we assure you that the quadratic
function for this example passes the test.) Therefore, the assumptions for a maximization
problem are satisfied, and the Solver solution (without the Multistart option) is guaran-
teed to be optimal.
Sensitivity Analysis
To gain even more insight, you can use SolverTable to see the effects of changing the unit
cost of capacity, allowing it to vary from $5 to $15 in increments of $1. The results appear
in Figure 7.21. They indicate that as the cost of capacity increases, the peak-load price
increases, the off-peak price stays constant, the amount of capacity decreases, and profit
decreases. The latter two effects are probably intuitive, but we challenge you to explain the
effects on price. In particular, why does the peak-load price increase, and why doesn’t the
off-peak price increase as well?
376
Chapter 7
Nonlinear Optimization Models
Varying the changing
cells slightly from their
optimal values
sometimes provides
insight into the
optimal solution.
Figure 7.21
Sensitivity to Cost
of Capacity
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
A
B
C
D
E
F
G
Oneway analysis for Solver model in Model worksheet
Cost of capacity (cell $B$9) values along side, output cell(s) along top
Prices_1
Prices_2
Capacity
Proﬁt
$5
$67.81
$26.53
28.75 $2,342.92
$6
$68.31
$26.53
28.50 $2,314.30
$7
$68.81
$26.53
28.25 $2,285.92
$8
$69.31
$26.53
28.00 $2,257.80
$9
$69.81
$26.53
27.75 $2,229.92
$10
$70.31
$26.53
27.50 $2,202.30
$11
$70.81
$26.53
27.25 $2,174.92
$12
$71.31
$26.53
27.00 $2,147.80
$13
$71.81
$26.53
26.75 $2,120.92
$14
$72.31
$26.53
26.50 $2,094.30
$15
$72.81
$26.53
26.25 $2,067.92
■
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

7.3 Pricing Models
377
Pricing Analysis at Merrill Lynch
In the late 1990s, Merrill Lynch and other full-service financial service firms were losing
business due to electronic trading and the commoditization of trading. Management
decided to offer investors more choices for doing business with Merrill Lynch. A cross-
functional team evaluated various alternatives, including pricing strategies, and
constructed models to assess individual client’s choice behavior. The results enabled
Merrill Lynch to change the financial services landscape and mitigate its revenue risk. By
the end of the year 2000, net new assets to the firm totaled $22 billion, and incremental
revenue had grown to $80 million.
■
ADDITIONAL APPLICATIONS
P R O B L E M S
Solutions for problems whose numbers appear within a
colored box can be found in the Student Solutions Files.
Refer to this book’s preface for purchase information.
Skill-Building Problems
1.
In Example 7.1, two points on the demand curve were
given (see Figure 7.10).
a. Suppose three additional points are estimated by
Madison: (1) demand of 460 when price is $65,
(2) demand of 355 when price is $75, and
(3) demand of 275 when price is $85. With these
new points and the original two points, estimate
and interpret the best-fitting linear demand curve;
do the same for the best-fitting constant elasticity
demand curve.
b. Calculate the mean absolute percentage error
(MAPE) for each of the two fits, linear and constant
elasticity, where each MAPE is the average of the
absolute percentage errors for the five points. On the
basis of MAPE, which curve provides the better fit?
2.
In Example 7.1, one demand function is linear and the
other is called a constant elasticity demand function.
Using data tables, show that the price elasticity in the
linear demand function is not constant in price, and
show that the price elasticity is constant in the constant
elasticity demand function.
3.
In the pricing model in Example 7.1 with the constant
elasticity demand function, the assumption is that all
units demanded are sold. Suppose the company has
the capacity to produce only 200 units. If demand is
less than capacity, all of demand is sold. If demand is
greater than or equal to capacity, only 200 units are
sold. Use Solver to find the optimal price and the
corresponding profit. Then use SolverTable to see how
sensitive these answers are to the production capacity,
letting it vary from 170 to 230 in increments of 10.
Discuss your findings relative to the original solution
in Example 7.1. In other words, what is the effect of
capacity on the optimal price and profit?
4.
Continuing the previous problem, create a two-way data
table similar to the one-way data table in Figure 7.11.
This time, however, allow price to vary down a column
and allow the capacity to vary across a row. Each cell of
the data table should capture the corresponding profit.
Explain how the values in the data table confirm the
findings from SolverTable in the previous problem.
5.
Continuing Problem 3 in a slightly different direction,
create a two-way SolverTable where the inputs are the
elasticity and the production capacity, and the outputs
are the optimal price and the optimal profit. (This
actually creates two tables, one for each output.)
Discuss your findings.
6.
In the exchange rate model in Example 7.2, suppose
the company continues to manufacture its product in
the United States, but now it sells its product in the
United States, the United Kingdom, and possibly other
countries. The company can independently set its price
in each country where it sells. For example, the price
could be $150 in the United States and £110 in the
United Kingdom. You can assume that the demand
function in each country is of the constant elasticity
form, each with its own parameters. The question is
whether the company can use Solver independently in
each country to find the optimal price in this country.
(You should be able to answer this question without
actually running any Solver model(s), but you might
want to experiment, just to verify your reasoning.)
7.
Change the exchange rate model in Example 7.2
slightly so that the company is now a UK manufactur-
ing company producing for a U.S. market. Assume
that the unit cost is now £75, the demand function
has the same parameters as before (although the price
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

for this demand function is now in dollars), and the
exchange rate is the same as before. Your Solver
solution should now specify the optimal price to
charge in dollars and the optimal profit in pounds.
8.
In the exchange rate model in Example 7.2, we found
that the optimal unit revenue, when converted to
dollars, is $85.71. Now change the problem so that the
company is selling in Japan, not the United Kingdom.
Assume that the exchange rate is 0.01157 ($/¥) and
that the constant in the demand function is
161,423,232,300, but everything else, including the
elasticity of the demand function, remains the same.
What is the optimal price in yen? What is the optimal
unit revenue when converted to dollars? Is it still
$85.71? Do you have an intuitive explanation for this?
9.
In the complementary-product pricing model in
Example 7.3, the elasticity of demand for suits is
currently 2.5. Use SolverTable to see how the
optimal price of suits and the optimal profit vary as
the elasticity varies from 2.7 to 1.8 in increments
of 0.1. Are the results intuitive? Explain.
10. In the complementary-product pricing model in
Example 7.3, the SolverTable results in Figure 7.18
indicate that the company can sometimes increase over-
all profit by selling suits below cost. How far might this
behavior continue? Answer by extending the
SolverTable to larger values of the sensitivity factor, so
that more and more shirts and ties are being purchased
per suit. Does there appear to be a lower limit on the
price that should be charged for suits? Might it reach a
point where the company gives them away? (Of course,
this would require an unrealistically large purchase of
shirts and ties, but is it mathematically possible?)
11. In the peak-load pricing model in Example 7.4, we
assumed that the capacity level is a decision variable.
Assume now that capacity has already been set at
30 kwh. (Note that the cost of capacity is now a sunk
cost, so it is irrelevant to the decision problem.)
Change the model appropriately and run Solver. Then
use SolverTable to see how sensitive the optimal
solution is to the capacity level, letting it vary over
some relevant range. Does it appear that the optimal
prices are set so that demand always equals capacity
for at least one of the two periods of the day?
12. In the peak-load pricing model in Example 7.4, the
demand functions have positive and negative
coefficients of prices. The negative coefficients
indicate that as the price of a product increases,
demand for that product decreases. The positive
coefficients indicate that as the price of a product
increases, demand for the other product increases.
a. Increase the magnitudes of the negative coefficients
from 0.5 and 1 to 0.7 and 1.2, and then
rerun Solver. Do the changes in the optimal solu-
tion go in the direction you would expect? Explain.
378
Chapter 7
Nonlinear Optimization Models
b. Increase the magnitudes of the positive coefficients
from 0.1 and 0.1 to 0.3 and 0.3, and then rerun
Solver. Do the changes in the optimal solution go
in the direction you would expect? Explain.
c. Make the changes in parts a and b simultaneously,
and then rerun Solver. What happens now?
Skill-Extending Problems
13. Continuing Problem 6, suppose the company is selling
in the United States, the United Kingdom, and
Japan. Assume the unit production cost is $50, and
the exchange rates are 1.52 ($/£) and 0.01157 ($/¥).
Each country has its own constant elasticity demand
function. The parameters for the United States are
19,200,000 and 2; the parameters for the United
Kingdom are 10,933,620 and 2.2; and the parame-
ters for Japan are 15,003,380,400 and 1.9. The
company has a production capacity of 3000.
Therefore, the company can sell only as many units, in
total, to all three countries as it can produce.
a. Develop a spreadsheet model that determines the
prices the company should charge and the numbers
of units it should sell in each of the three countries
to maximize its total profit in dollars. (Note that if
total demand is greater than capacity, the company
has to decide how much to sell in each country.
Therefore, the amounts to sell become changing
cells.)
b. When the capacity is 3000, is all of this capacity
used? Answer the same question if the capacity is
increased to 4000.
c. Discuss the customer behavior that might result
from the solution to the model in part a. If the
company sets its price in one country relatively low
compared to its price in another country, what
might customers do?
14. In the complementary-product pricing model in
Example 7.3, we have assumed that the profit per unit
from shirts and ties is given. Presumably this is
because the prices of these products have already been
set. Change the model so that the company must deter-
mine the prices of shirts and ties, as well the price of
suits. Assume that the unit costs of shirts and ties are,
respectively, $20 and $15. Continue to assume that, on
average, 2.0 shirts and 1.5 ties are sold along with
every suit (regardless of the prices of shirts and ties),
but that shirts and ties have their own separate demand
functions. These demands are for shirts and ties pur-
chased separately from suit purchases. Assume con-
stant elasticity demand functions for shirts and ties
with parameters 288,500 and 1.7 (shirts), and 
75,460 and 1.6 (ties). Assume the same unit cost 
and demand function for suits as in Example 7.3.
a. How much should the company charge for suits,
shirts, and ties to maximize the profit from all three
products?
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

b. The assumption that customers will always buy, on
average, the same number of shirts and ties per suit
purchase, regardless of the prices of shirts and ties,
is not very realistic. How might you change this
assumption, and change your model from part a
accordingly, to make it more realistic?
15. Continuing the previous problem (the model in part a)
one step further, assume that shirts and ties are also
7.4 Advertising Response and Selection Models
379
complementary. Specifically, assume that each time
a shirt is purchased (and is not accompanied by a
suit purchase), 1.3 ties, on average and regardless 
of the price of ties, are also purchased. Modify the
model from part a of the previous problem to find
the prices of suits, shirts, and ties to maximize
overall profit.
7.4 ADVERTISING RESPONSE AND SELECTION MODELS
In Chapter 4, we discussed an advertising allocation model (Example 4.1), where the
problem was basically to decide how many ads to place on various television shows to
reach the required number of viewers. One assumption of that model was that the “adver-
tising response”—that is, the number of exposures—is linear in the number of ads. This
means that if one ad gains, say, one million exposures, then 10 ads will gain 10 million
exposures. This is a questionable assumption at best. More likely, there is a decreasing
marginal effect at work, where each extra ad gains fewer exposures than the previous ad. In
fact, there might even be a saturation effect, where there is an upper limit on the number of
exposures possible and, after sufficiently many ads, this saturation level is reached.
In this section, we look at two related examples. In the first example, a company uses
historical data to estimate its advertising response function—the number of exposures it
gains from a given number of ads. This is a nonlinear optimization model. This type of
advertising response function is used in the second example to solve a nonlinear version of
the advertising selection problem from Chapter 4. Because the advertising response
functions are nonlinear, the advertising selection problem is also nonlinear.
E X A M P L E
7.5 ESTIMATING AN ADVERTISING RESPONSE FUNCTION
R
ecall that the General Flakes Company from Example 4.1 of Chapter 4 sells a brand
of low-fat breakfast cereal that appeals to people of all age groups and both genders.
The company has advertised this product in various media for a number of years and has
accumulated data on its advertising effectiveness. For example, the company has tracked
the number of exposures to young men from ads placed on a particular television show for
five different time periods. In each of these time periods, a different number of ads was
used. Specifically, the numbers of ads were 1, 8, 20, 50, and 100. The corresponding
numbers of exposures (in millions) were 4.7, 22.1, 48.7, 90.3, and 130.5. What type of
nonlinear response function might fit these data well?
Objective
To use nonlinear optimization to find the response function (from a given
class of functions) that best fits the historical data.
WHERE DO THE NUMBERS COME FROM?
The question here is how the company measures the number of exposures a given num-
ber of ads has achieved. In particular, what does the company mean by “exposures”? If
one person sees the same ad 10 times, does this mean 10 exposures? Is it the same
thing as 10 people seeing the same ad once each? Although we defer to the marketing
experts here, we suggest that one person seeing the same ad 10 times results in fewer
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

exposures than 10 people seeing the same ad once each. However the marketing
experts decide to count exposures, it should lead to the decreasing marginal effects
built into this example.
Solution
The chart in Figure 7.22 is a scatter chart of the historical data (with the dots connected).
The chart clearly indicates a nonlinear pattern, where extra ads have less effect than the
first few ads. Many mathematical functions have this basic shape, and we could use any of
them. However, we settle here for one of the simplest, a function of the form
f (n)  a(1  ebn)
(7.4)
Here, n is the number of ads placed, f (n) is the resulting number of exposures, a and b are
constants to estimate, and e is a special number approximately equal to 2.718. This
function has some nice properties: (1) it is 0 when n  0; (2) it increases at a decreasing
rate when b  0; and (3) it increases to a as n gets large. This latter property is the
saturation effect we mentioned previously. The only question, then, is which values of
a and b to use to match the historical data in Figure 7.22 as well as possible.
To do this, you can use a standard estimation procedure. Although the spreadsheet
details are given shortly, it is worth discussing the idea behind this procedure first.
Using the model in Equation (7.4) with any values of a and b, you predict the number
of exposures you would obtain for 1, 8, 20, 50, or 100 ads. Then you compare these to
the actual exposures observed, using a goodness-of-fit measure. The specific goodness-
of-fit measure used here is the sum of squared differences between actual and predicted
exposures. This measure has been used most frequently in estimation problems, so it is
used here. Specifically, you can use Solver to find the constants a and b that minimize
the sum of squar ed prediction errors. Of course, the squares make this a nonlinear
optimization model.
380
Chapter 7
Nonlinear Optimization Models
The function in
Equation (7.4) is
only one of several
nonlinear functions
that exhibit the type
of behavior (increasing
at a decreasing rate)
we want.
0
20
40
60
80
100
120
140
0
20
40
60
80
100
120
Exposures
Ads
Historical data
Figure 7.22
Graph of Historical Data
The squared
differences in the 
goodness-of-fit
measure make this a
nonlinear model.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

DEVELOPING THE SPREADSHEET MODEL
The completed spreadsheet model is shown in Figure 7.23. (See the file Advertising
Response.xlsx.) The model can be created with the following steps:
1
Inputs. Enter the historical data in the blue region. There are no other inputs.
2
Parameters of response function. Enter any values for the constants a and b of the
advertising response function in cells B4 and B5. These become the changing cells.
3
Predicted exposures. Use Equation (7.4), with the values of a and b in cells B4 and
B5, to calculate the predicted number of exposures for each number of ads. To do this, enter
the formula
=$B$4*(1-EXP(-$B$5*A9))
in cell C9, and copy it down to cell C13.
4
Squared errors. Calculate the squared difference between actual and predicted expo-
sures by entering the formula
=(B9-C9)^2
in cell D9 and copying it down to cell D13.
5
Objective to minimize. Minimizing the sum of squared errors is equivalent to mini-
mizing the root mean square error (RMSE), which is the square root of the average of the
squared errors. To use RMSE as the objective to minimize, enter the formula
=SQRT(AVERAGE(D9:D13))
7.4 Advertising Response and Selection Models
381
FUNDAMENTAL INSIGHT
Least Squares Estimation
In many situations, the goal is to fit a cur ve of a cer-
tain functional f orm to a set of obser
ved data.
Although goodness of fit can be measur ed in several
alternative ways, the most popular method is to use
the sum of squared prediction errors as the criterion
to minimize . The r esulting optimization pr oblem is
often unconstrained; you simply want the parameters
of the curve that provides the best fit. Because of the
squared prediction errors, this problem is inher ently
nonlinear, but it is usuall y very amenable to anal ysis.
Least squares estimation a ppears in man y areas. For
example, it is used later in this cha pter to estimate
football ratings and to estimate the beta of a stock,
and it is the basis for the regression analysis discussed
in Chapter 14.
RMSE is the square
root of the average of
the squared errors.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
A
B
C
D
E
F
G
H
I
Fing an adversing response curve
Parameters of response 
e
g
n
a
R
e
v
r
u
c
 names used:
5
$
B
$:4
$
B
$
!le
d
o
M
=
sr
e
t
e
m
a
r
a
P
2
0.5
5
1
t
n
a
ts
n
o
C
Coeﬃcient in 
4
1
$
D
$
!le
d
o
M
=
E
S
M
R
1
8
1
0.0
t
n
e
n
o
p
x
e
Historical data
Ads
Exposures
Predicted
Squared error
1
4.7
2.787
3.659
8
22.1
20.943
1.338
20
48.7
47.174
2.328
50
90.3
92.441
4.584
100
130.5
129.757
0.552
1.579
Root mean squared error, objecve to minimize
Figure 7.23
Estimation of Response Function
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

in cell D14. (One reason to use RMSE as the objective, rather than the sum of squared
errors, is that RMSE is a smaller number and is less likely to give Solver numerical
problems. In any case, you should get the same solution either way. Besides, RMSE has
historically been a popular measure to minimize.)
USING SOLVER
This is a particularly simple Solver setup. As Figure 7.24 indicates, the objective is to min-
imize RMSE by using cells B4 and B5 (jointly range-named Parameters) as the changing
cells. There are no constraints, not even nonnegativity constraints.6 An optimization model
with no constraints is called an unconstrained model. (Actually, as explained shortly, you
can add bounds on the changing cells for use with the Multistart option.)
Discussion of the Solution
The Solver solution in Figure 7.23 indicates that setting a  155.02 and b  0.0181 in
Equation (7.4) provides the best possible fit to the historical data. A glance at the Actual and
Predicted columns in rows 9 to 13 indicates that this fit is quite good. You can then see what
this version of Equation (7.4) looks like, as well as the number of exposures it would pre-
dict for other numbers of ads. You can do this numerically and graphically, as shown in
Figure 7.25. For example, the formula in cell B18 is =$B$4*(1-EXP(-$B$5*A18)), which is
copied down. You can then plot the values in columns A and B to obtain the curve in the fig-
ure. The response function increases at a decreasing rate and approaches a  155.02 as the
number of ads gets large.
Is the Solver Solution Optimal?
Verifying whether RMSE is a concave function of the two parameters a and b is difficult—
even for mathematicians. Therefore, the best approach is to use Solver’s Multistart option.
382
Chapter 7
Nonlinear Optimization Models
In an unconstrained
optimization model,
there are no infeasi-
ble points—all
points qualify.
Figure 7.24
Solver Dialog Box 
for the Estimation
Problem
6 Actually, by the increasing nature of the historical data and the form of the response function in Equation (7.4),
you would expect a and b to be nonnegative, but it is not necessary to constrain them to be nonnegative.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Recall that this works best if lower and upper bounds are imposed on the changing cells.
Although there are no obvious bounds for a and b, you can try 0.001 and 1 for a, and 50 and
250 for b. This leads to the solution in Figure 7.23. Alternatively, instead of using Multistart,
you could run Solver repeatedly from different starting solutions. You should see that Solver
finds the solution in Figure 7.23 for some starting solutions, but not for really “bad” ones.
This is typical of many nonlinear optimization models. Unless the starting solution is rea-
sonably close to the optimal solution, Solver can go to a completely wrong solution. This is
the reason why the Multistart option is such a welcome addition to Solver.
■
7.4 Advertising Response and Selection Models
383
0.000
20.000
40.000
60.000
80.000
100.000
120.000
140.000
160.000
0
10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180
Ads
Predicted exposures
Figure 7.25
Estimated Response
Function
We used the popular sum-of-squared-errors measure (or its RMSE equivalent) to find
the best-fitting response function. Another possibility is to use the sum (or average) of
the absolute errors. Still another possibility is to use the maximum of the absolute
errors. All of these have been used in estimation problems, and all lead to nonlinear
optimization models. They typically lead to similar, but not necessarily identical, solu-
tions. We used the sum-of-squared-errors measure because it has historically been the
most frequently used measure and leads to a smooth nonlinear model—the kind that
Solver handles best.
■
Now that you know how a company can estimate the advertising response function for
any type of ad to any group of customers, you can use this type of response function in an
advertising selection model.
MODELING ISSUES
E X A M P L E  
7.6 ADVERTISING SELECTION WITH NONLINEAR RESPONSE FUNCTIONS
I
n this example, we revisit the problem faced by the General Flakes Company in Example
4.1 of Chapter 4. The company must decide how many ads to place on each of several
television shows to meet exposure constraints for each of six groups of customers. (Refer
to Figure 7.26 and the file Advertising Selection.xlsx for the specific inputs.) The differ-
ence now is that each combination of television show and customer group has its own
In some nonlinear
models, such as
this one, Solver
finds the optimal
solution only if the
starting solution is
reasonably close
to the optimal
solution.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

advertising response function of the form in Equation (7.4). That is, there are constants a
and b of the response function for each such combination. (These constants appear in rows
5 to 10 and 14 to 19 of the file.) The company wants to find the selection of ads that mini-
mizes its total cost of meeting all exposure requirements.
Objective
To use a nonlinear model to find a minimum-cost way of meeting all exposure
requirements.
WHERE DO THE NUMBERS COME FROM?
We already discussed where many of the inputs come from in Example 4.1 of Chapter 4.
The new inputs, the parameters of the various response functions, come from fitting
response functions, exactly as in the previous example, for each combination of television
show and customer group. Of course, this assumes the company has enough historical data
to carry out this procedure. The numbers used here are for illustration only, although they
are reasonable.
Solution
The variables and constraints for this model are listed in Table 7.4. Except for the new inputs
from the advertising response functions, this table is exactly like the table for Example 4.1 of
Chapter 4.
384
Chapter 7
Nonlinear Optimization Models
In this model, each
customer group has
its own nonlinear
advertising response
function to each
television show.
Table 7.4
Variables and Constraints for the Advertising Model
Input variables
Cost per ad, minimal required exposures, parameters of 
advertising response functions
Decision variables (changing cells)
Numbers of ads to place on various types of shows
Objective (target cell)
Total advertising cost
Other output variables
Total exposures to each viewer group
Constraints
Actual exposures  Required exposures
DEVELOPING THE SPREADSHEET MODEL
The spreadsheet model is shown in Figure 7.26 and in the file Advertising Selection.xlsx.
The model can be developed with the following steps:
1
Inputs. Enter the inputs in the blue cells. These include the parameters of the adver-
tising response functions in rows 5 to 10 and 14 to 19. Again, these inputs would typically
be estimated from historical data.
2
Ads purchased. Enter any trial values of the numbers of ads purchased for the various
shows in row 25. These cells become the changing cells.
3
Exposures from each show to each group. Use the advertising response functions to
calculate the numbers of exposures to each customer group from each show. To do this,
enter the formula
=B5*(1-EXP(-B14*B$25))
in cell B29 and copy it to the range B29:I34. Note that row 25 must be kept absolute for
copying to work correctly, because the numbers of ads are always in row 25.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4
Total exposures to each group. Calculate the numbers of exposures to each group by
entering the formula
=SUM(B29:I29)
in cell B38 and copying it down to cell B43. This formula sums overexposures from the
various television shows.
5
Total cost. Calculate the total cost of advertising in cell B46 with the formula
=SUMPRODUCT(B21:I21,Number_ads_purchased)
USING SOLVER
The Solver dialog box is straightforward to complete, as illustrated in Figure 7.27. Just
remember to check the Non-Negative option, and use the GRG Nonlinear method because
of the nonlinear advertising response functions. Note that you could also constrain the
changing cells to be integers. This would make the model more difficult for Solver to
solve, but it would also make the solution more realistic. (However, you can check that it
doesn’t change the optimal solution by much.)
Discussion of the Solution
First, note that the constants in rows 5 to 10 of the advertising response functions indicate
the maximum numbers of exposures possible to each group from each show. The
coefficients in rows 14 to 19 indicate how fast the response functions approach these
7.4 Advertising Response and Selection Models
385
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
I
H
G
F
E
D
C
B
A
Adversing model with nonlinear response funcons
Constant in adversing response funcon for various groups for diﬀerent shows
Desperate Housewives
MNF
The Simpsons
Sports Center
The Real World
Lifeme movie
CNN
Law & Order SVU
Men 18-35
93.061
116.808
84.772
43.647
26.711
11.99
11.793
79.534
Men 36-55
61.129
76.527
61.528
47.749
19.655
10.281
9.982
89.217
Men >55
33.376
57.84
9.913
30.075
10.751
11.51
22.218
65.543
Women 18-35
105.803
40.113
66.998
22.101
42.451
29.403
8.236
72.145
Women 36-55
71.784
26.534
46.146
16.151
34.609
24.276
10.426
92.831
Women >55
56.828
17.209
8.887
9.101
8.46
31.149
23.105
71.321
Coeﬃcient of exponent in adversing response funcon for various groups for diﬀerent shows
Desperate Housewives
MNF
The Simpsons
Sports Center
The Real World
Lifeme movie
CNN
Law & Order SVU
Men 18-35
0.029
0.055
0.093
0.071
0.087
0.038
0.029
0.045
Men 36-55
0.084
0.050
0.085
0.094
0.018
0.090
0.054
0.051
Men >55
0.071
0.068
0.077
0.027
0.039
0.051
0.013
0.036
Women 18-35
0.035
0.063
0.069
0.074
0.060
0.012
0.039
0.035
Women 36-55
0.089
0.057
0.061
0.055
0.014
0.022
0.046
0.040
Women >55
0.010
0.033
0.078
0.078
0.035
0.050
0.072
0.030
Cost per 
0
4
1
8
5
1
3
1
9
0
8
0
0
1
0
4
1
d
a
Adversing plan
Desperate Housewives
MNF
The Simpsons
Sports Center
The Real World
Lifeme movie
CNN
Law & Order SVU
Number ads purchased
4.836
0.000
2.794
21.852
16.284
8.285
15.289
0.000
Exposures to each group from each show
Desperate Housewives
MNF
The Simpsons
Sports Center
The Real World
Lifeme movie
CNN
Law & Order SVU
Men 18-35
12.178
0.000
19.398
34.397
20.233
3.238
4.223
0.000
Men 36-55
20.408
0.000
13.006
41.627
4.994
5.403
5.610
0.000
Men >55
9.700
0.000
1.919
13.403
5.054
3.966
4.005
0.000
Women 18-35
16.476
0.000
11.747
17.714
26.472
2.783
3.699
0.000
Women 36-55
25.108
0.000
7.231
11.295
7.055
4.045
5.266
0.000
Women >55
2.683
0.000
1.740
7.446
3.675
10.564
15.420
0.000
Constraints on numbers of exposures
Range names used:
Actual exposures
Required 
3
4
$
B
$:8
3
$
B
$
!
1
t
e
e
h
S
=
s
e
r
u
s
o
p
x
e
_la
u
tc
A
s
e
r
u
s
o
p
x
e
Men 18-35
r
u
p
_
s
d
a
_
r
e
b
m
u
N
0
6
=
>
7
6
6.3
9
chased
=Sheet1!$B$25:$I$25
Men 36-55
3
4
$
D
$:8
3
$
D
$
!
1
t
e
e
h
S
=
s
e
r
u
s
o
p
x
e
_
d
e
riu
q
e
R
0
6
=
>
9
4
0.1
9
Men >55
6
4
$
B
$
!
1
t
e
e
h
S
=
ts
o
c
_la
t
o
T
8
2
=
>
8
4
0.8
3
Women 18-35
0
6
=
>
0
9
8.8
7
Women 36-55
0
6
=
>
0
0
0.0
6
Women >55
8
2
=
>
9
2
5.1
4
Objecve to minimize
Total 
5
3
5.5
5
5,1
$
ts
o
c
Note: All monetary values are in $1000s, and all exposures to 
ads are in millions of exposures.
Figure 7.26 Spreadsheet Model for Advertising Selection
Integer constraints can
be added, but they do
not affect the optimal
solution to a great
extent.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

maximum limits: When one of these coefficients increases, fewer ads are needed to
approach the saturation level. Together, these two sets of constants indicate which types of
ads are most effective to the various customer groups. Solver uses this information in its
intricate algorithm to decide how many ads to place on each show. Perhaps surprisingly, no
ads are placed on “Monday Night Football,” although many exposures to men under 55
would be achieved from these ads. Evidently these ads are too expensive, and exposures to
men in these groups can be achieved with cheaper ads on other shows. Note also that the
women in the 36 to 55 group are evidently the bottleneck group. (Check the differences
between the two sides of the exposure constraints.) To achieve the required exposures for
this group, many more ads are required than are needed to achieve the required exposures
to the other groups.
Is the Solver Solution Optimal?
It can be shown (with calculus) that this model satisfies the conditions necessary to ensure
a single local minimum. Therefore, the Solver solution is optimal. If you didn’t know this,
however, you could use the Multistart option.
Sensitivity Analysis
An interesting sensitivity analysis for this nonlinear model is to see how the optimal cost
varies if all of the required exposures change by the same percentage. If you did this in a
linear model (and there were no other constraints to worry about), the optimal cost would
change by the same percentage due to the proportionality property of linear models. For
example, if you increased the right-hand sides of all constraints by 10%, you would expect
the optimal cost to increase by 10% in a linear model. However, this is not true in a
nonlinear model, as Figure 7.28 indicates. Here you should change the model slightly so
that you can vary a single percentage. (See the Sensitivity worksheet in the finished ver-
sion of the file for details.) The values in column C indicate the percentage increase in total
386
Chapter 7
Nonlinear Optimization Models
Figure 7.27
Solver Dialog Box
for the Advertising
Selection Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

cost for a given percentage increase in total exposures. For example, to obtain a 40%
increase in exposures, the total cost must increase by 56.6%. This illustrates in a very real
way a consequence of nonlinearity.
■
7.4 Advertising Response and Selection Models
387
1
2
3
4
5
6
7
8
9
10
A
B
C
D
E
F
G
H
Oneway analysis for Solver model in Sensivity worksheet
Pct change in required exposures (cell $F$44) values along side, output cell(s) along top
Total_cost
Pct increase
0% $1,555.540
10% $1,762.090
13.3%
20% $1,977.880
27.2%
30% $2,203.260
41.6%
40% $2,435.570
56.6%
50% $2,674.540
71.9%
Figure 7.28
Sensitivity of Total
Cost to Percentage
Change in Exposures
Required
P R O B L E M S
Skill-Building Problems
16. In estimating the advertising response function in
Example 7.5, we indicated that the sum of squared
prediction errors or RMSE could be used as the
objective, and we used RMSE. Try using the sum of
squared prediction errors instead. Does Solver find the
same solution as in the example? Try running Solver
several times, each time from a different starting
solution in the changing cells, and report what
happens. Alternatively, use the Multistart option with
the bounds we suggested.
17. The best-fitting advertising response function in
Example 7.5 fits the observed data. This is because
we rigged the observed data to fall close to a curve
of the form in Equation (7.4). See what happens
when one of the observed points is an outlier—that
is, it doesn’t fit the pattern of the others.
a. Specifically, change the number of exposures
corresponding to 50 ads from 90.3 to 125, and
then rerun Solver. Do you get essentially the same
response function as before, or does this one outlier
exert a large influence on the estimated response
function?
b. Repeat part a, but now change the number of
exposures corresponding to 50 ads from 90.3 to 55.
18. In judging the fit of the estimated response function
in Example 7.5, you could use MAD (mean absolute
deviation) instead of RMSE. MAD is the average of
the absolute prediction errors.
a. When you run Solver with MAD as your objective,
do you get approximately the same estimated
response function as with RMSE?
b. Repeat part a, but do it with the outliers in parts a
and b of the previous problem. Report your results
in a brief memo.
19. Starting with the solution to the advertising selection
problem in Example 7.6, suppose the company, for
whatever reason, cannot place ads on “Sports Center.”
Make the appropriate changes in the model and rerun
Solver. Comment on the changes to the changing cells.
Then comment on the change to the total cost. In
particular, explain how the total cost can change
so much in the direction it changes.
20. The preceding problem indicates how fewer alterna-
tives can cause total cost to increase. This problem
indicates the opposite. Starting with the solution to the
advertising selection problem in Example 7.6, add a
new show, “The View,” which appeals primarily to
women. Use the following constants and coefficients
of exponents for the response functions to the various
customer groups for this show: 5, 7, 10, 15, 35, 35
(constants); and 0.03, 0.03, 0.03, 0.08, 0.08, 0.08
(coefficients of exponents). Assume that each ad on
“The View” costs $10,000. Make the appropriate
changes in the model and rerun Solver. Comment on
the changes to the changing cells. Then comment
on the change to the total cost. In particular, explain
how the total cost can change so much in the direction
it changes.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

388
Chapter 7
Nonlinear Optimization Models
Skill-Extending Problem
23. In Example 7.5, we implied that each of the five
observations was from one period of time, such
as a particular week. Suppose instead that each is
an average over several weeks. For example, the
4.7 million exposures corresponding to one ad might
really be an average over 15 different weeks where
one ad was shown in each of these weeks. Similarly,
the 90.3 million exposures corresponding to 50 ads
might really be an average over only three different
weeks where 50 ads were shown in each of these
weeks. If the observations are really averages over
different numbers of weeks, then simply summing
the squared prediction errors doesn’t seem appropriate.
For example, it seems more appropriate that an
average over 15 weeks should get five times as much
weight as an average over only three weeks. Assume
the five observations in the example are really aver-
ages over 15, 10, 4, 3, and 1 week(s), respectively.
Devise an appropriate fitting function, to replace sum
of squared errors or RMSE, and use it to find the 
best fit.
7.5 FACILITY LOCATION MODELS
Suppose you need to find a location for a facility such as a warehouse, a tool crib in a
factory, or a fire station. Your goal is to locate the facility to minimize the total distance
that must be traveled to provide required services. Facility location problems such as these
can usually be set up as NLP models. The following example is typical.
E X A M P L E  
7.7 WAREHOUSE LOCATION AT LAFFERTY
The Lafferty Company wants to locate a warehouse from which it will ship products to
four customers. The location (in the x-y plane) of the four customers and the number of
shipments per year needed by each customer are given in Table 7.5. (All coordinates are in
miles, relative to the point x  0 and y  0.) A single warehouse must be used to service
all of the customers. Lafferty wants to determine the location of the warehouse that
minimizes the total distance traveled from the warehouse to the customers.
Table 7.5
Data for the Lafferty Example
Customer
x-coordinate
y-coordinate
Shipments per Year
1
5
10
200
2
10
5
150
3
0
12
200
4
12
0
300
Objective
To find the warehouse location, using NLP, that minimizes the total annual
distance traveled from the warehouse to the customers.
21. In the solution to the advertising selection model in
Example 7.6, we indicated that the women 36 to 55
group is a bottleneck in the sense that the company
needs to spend a lot more than it would otherwise have
spent to meet the constraint for this group. Use
SolverTable to see how much this group’s exposure
constraint is costing the company. Vary the required
exposures to this group from 30 to 60 in increments
of 5, and keep track of the total advertising cost.
Comment on your results.
22. The advertising response function in Equation (7.4) 
is only one of several nonlinear functions that could 
be used to get the same “increasing at a decreasing
rate” behavior in Example 7.5. Another possibility is
the function f (n)  anb, where a and b are again 
constants to be determined. Using the same data as in
Example 7.5 and RMSE as the fitting criterion, find
the best fit to this type of function. In terms of RMSE,
which function appears to fit the data better, the one
here or the one in the example? Can you spot any
qualitative difference between the two types of 
functions?
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

WHERE DO THE NUMBERS COME FROM?
The data for this problem are self-explanatory. Of course, at the time the model is solved,
the annual shipments for the various customers are probably forecasts.
Solution
The variables and constraints for this model are listed in Table 7.6. There are no constraints
in this model, not even nonnegativity. The warehouse can be located at any x-y coordinate.
7.5 Facility Location Models
389
Table 7.6
Variables and Constraints for the Warehouse Location Problem
Input variables
Customer coordinates, annual customer shipments
Decision variables (changing cells)
Coordinates of warehouse location
Objective (target cell)
Total annual distance traveled to the customers from the 
warehouse
Other output variables
Distances from customers to warehouse
Constraints
None
DEVELOPING THE SPREADSHEET MODEL
To develop the spreadsheet model, use the following steps (see Figure 7.29 and the file
Warehouse Location.xlsm)7:
1
Inputs. Enter the given customer data in the shaded ranges.
2
Coordinates of war ehouse. Enter any trial values in the Location range for the x-y
coordinates of the warehouse.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
A
B
C
D
E
F
G
Laﬀerty facility locaon model
Customer data
X-coordinate
Y-coordinate
Annual shipments
Customer 
0
0
2
0
1
5
1
Customer 
0
5
1
5
0
1
2
Customer 
0
0
2
2
1
0
3
Customer 
0
0
3
0
2
1
4
Warehouse locaon
X-coordinate
Y-coordinate
Range names used:
9.314
5.029
Locaon
=Model!$B$11:$C$11
Total_annual_distance
=Model!$B$19
Customer distances from warehouse
Customer 
2
8
5.6
1
Customer 
6
8
6.0
2
Customer 
4
3
6.1
1
3
Customer 
1
0
7.5
4
Total annual distance
5456.540
Tesng opmality
Is this soluon opmal?  Test it yourself.  Click on the le buon to generate a "random" set of starng values for
the changing cells.  Then click on the right buon to run Solver.  Does it always take you to the same soluon?
Generate random values
Run Solver
Figure 7.29
The Facility 
Location Model
7 This file contains a macro, hence the .xlsm extension (“m” for macro). When you open the file, a message bar
should appear allowing you to enable the macro. The macro won’t function unless you enable it.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

3
Distances fr om war ehouse to customers.
Calculate the distances from the ware-
house to the customers in the range B14:B17. To do so, recall from the Pythagorean theo-
rem that the (straight-line) distance between the two points (a, b) and (c, d) is 
(c  a
)2  (d
  b)2
. Therefore, enter the formula
=SQRT(SUMXMY2(B5:C5,Location))
in cell B14 and copy it down to cell B17.
Excel Function: SUMXMY2
Microsoft realized that summing the squared differences between two ranges is common so
it provided the Excel function SUMXMY2 (read “sum of x minus y squared”). This function
has the syntax =SUMXMY2(xRange,yRange). For this example, it is equivalent to the longer
form (B5-$B$11)^2+(C5-$C$11)^2. You can then take the square root to get distance.
4
Total annual distance. The total annual distance traveled from the warehouse to meet
the demands of all customers is the sum over all customers of the distance from the
warehouse to the customer multiplied by the annual shipments for the customer. Therefore,
calculate the total annual distance traveled in cell B19 with the formula
=SUMPRODUCT(E5:E8,B14:B17)
USING SOLVER
The Solver setup for this model is shown in Figure 7.30. All you need to specify is that total
annual distance should be minimized and the Location range contains the changing cells.
There are no constraints, not even nonnegativity constraints. Also, because of the squares in
the straight-line distance formula, this model is nonlinear, so the GRG Nonlinear method
should be selected.
390
Chapter 7
Nonlinear Optimization Models
Figure 7.30
Solver Dialog Box
for the Warehouse
Location Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Discussion of the Solution
The Solver solution in Figure 7.29 is represented graphically in Figure 7.31. The
warehouse should be located at x  9.32 and y  5.03. Each year, a total of 5456.54 miles
will be traveled from the warehouse to the customers. This solution represents a compro-
mise. On the one hand, Lafferty would like to position the facility near customer 4 because
the most trips are made to customer 4. However, because customer 4 is fairly far from the
other customers, the warehouse is located in a more central position.
Sensitivity Analysis
One possible sensitivity analysis is to see how the optimal location of the warehouse
changes as the annual number of shipments to any particular customer increases. We
did this for customer 4 in Figure 7.32, using the number of shipments to customer 4
(cell E8) as the single input cell, allowing it to vary from 300 to 700 in increments of
50, and keeping track of the total annual distance and the warehouse location coordi-
nates. As expected, the total annual distance increases as the annual shipments to cus-
tomer 4 increase. Also, the warehouse gradually gets closer to customer 4. In fact, when
the number of annual shipments to customer 4 is 600 or above, the optimal location for
the warehouse is at customer 4.
Is the Solver Solution Optimal?
The Lafferty model has no constraints. Therefore, Solver is guaranteed to find an optimal
solution if the objective is a convex function of the coordinates of the warehouse. It can be
7.5 Facility Location Models
391
Customer 1
Customer 2
Customer 4
Warehouse
Customer 3
5
10
5
10
Figure 7.31
Graph of Solution
to the Warehouse
Location Example
As the number of
shipments to any
customer increases,
the optimal
warehouse location
gets closer to that
customer.
1
2
3
4
5
6
7
8
9
10
11
12
13
A
B
C
D
E
F
G
Oneway analysis for Solver model in Model worksheet
Shipments to 4 (cell $E$8) values along side, output cell(s) along top
Locaon_1
Locaon_2
Total_annual_distance
300
9.314
5.029
5456.540
350
9.634
4.877
5732.969
400
9.690
4.762
6000.839
450
9.680
4.510
6260.753
500
9.788
3.846
6501.694
550
12.000
0.000
6643.198
600
12.000
0.000
6643.199
650
12.000
0.000
6643.199
700
12.000
0.000
6643.199
Figure 7.32
Sensitivity Analysis
for Warehouse
Location
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

shown (with some difficulty) that the annual distance traveled is indeed a convex function
of the coordinates of the warehouse. Therefore, the Solver solution is optimal.
However, what if you do not know that the objective is a convex function of the
coordinates? Then you could use the Multistart option. Alternatively, you could try differ-
ent starting solutions in the Location range, run Solver on each of them, and see whether
they all take you to the same solution. For variety, we have made this easy for you in the
Warehouse Location.xlsm file (see Figure 7.29). We have written two short macros that
are automated by clicking buttons. You can click on the left button to randomly generate a
new starting location in the changing cells. Then you can click on the right button to run
Solver. They should always take you to the same solution.8
■
392
Chapter 7
Nonlinear Optimization Models
8If you would like to have similar macros for other NLP models, it is fairly easy. With the Warehouse
Location.xlsm file open, press the Alt+F11 key combination to see the Visual Basic screen. The code for the
macros is in the Module sheet for this file. Except for the line indicated in the code and the range name of
the changing cells, these macros can be used for other problems with no changes.
1.
The straight-line distance function used in the Lafferty example is relevant if the
company is shipping by air. However, if the company is shipping by road, you must
take into account that most roads are built in a north-south or east-west direction.
Then the relevant distance between points (a, b) and (c, d ) is a  c  b  d (the
sum of the absolute differences), and this objective should be used in place of the
square root objective. Because of absolute values, it is still nonlinear.
2.
Besides assuming straight-line distance, there are two other assumptions in the
Lafferty example: (1) exactly one warehouse will be built, and (2) this warehouse can
be built anywhere. In real-world facility location problems, it is often necessary to
modify these assumptions. First, it might be possible to build several warehouses.
Second, the possible locations might be restricted to a certain subset of geographical
locations. And third, the distances from all potential warehouse locations to
customers might be given by a distance matrix, rather than calculated from some
formula. In this situation, an IP model with binary variables is more suitable. There
is a 01 variable for each potential warehouse location (either build there or don’t)
and a 01 variable for each warehouse-customer pair (either supply that customer
from that warehouse or don’t). We ask you to model such a version of the warehouse
location problem in one of the problems.
■
MODELING ISSUES
P R O B L E M S
Skill-Building Problems
24. Modify the warehouse location model so that there is
an extra customer. This customer has 250 shipments
per year. Try placing this new customer at various
locations (see Figure 7.31 for guidance). For
example, try placing the customer way up to the
right, or way down to the left, or near a current
customer, and so on. For each such location, find
the optimal warehouse location. Discuss the effect
of this new customer and its location on the optimal
warehouse location.
25. Modify the warehouse location model so that
customers always travel in horizontal or vertical
directions. For example, this means that if a
customer’s coordinates are (5, 10) and a warehouse
is located at (7, 7), then the traveling distance is 
5  7  10  7  5.
26. Use SolverTable in the warehouse location model to
see the effect on the optimal solution of moving one
customer farther and farther away from the others.
Specifically, let customer 1’s coordinates be of the
form (5c, 10c), where the factor c is allowed to vary
The buttons in this file
let you experiment
with randomly gener-
ated starting values in
the changing cells.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

7.6 MODELS FOR RATING SPORTS TEAMS
Sports fans always wonder which team is best in a given sport. Was USC, LSU, or
Oklahoma number one during the 2003 NCAA football season? You might be surprised to
learn that Solver can be used to rate sports teams. We illustrate one method for doing this
in the following example.
7.6 Models for Rating Sports Teams
393
from 1 to 10 in increments of 1. Keep track of the
changing cells and the target cell.
Skill-Extending Problem
27. Modify the warehouse location model as suggested in
Modeling Issue 2. Specifically, assume that the same
four customers have the same annual shipments, but
now, there are only two possible warehouse locations,
each with distances to the various customers. (These
distances, along with other inputs, are in the file
P07_27.xlsx.) The company can build either or both
of these warehouses. The cost to build a warehouse is
$50,000. (You can assume that this cost has been
annualized. That is, the company incurs a building
cost that is equivalent to $50,000 per year.) If only
one warehouse is built, it will ship to all customers.
However, if both warehouses are built, then the com-
pany must decide which warehouse will ship to each
customer. There is a traveling cost of $1 per mile.
a. Develop an appropriate model to minimize total
annual cost, and then use Solver to optimize it.
Is this model an NLP or an IP model (or both)?
b. Use SolverTable with a single input, the traveling
cost per mile, to see how large this cost must be
before the company builds both warehouses rather
than just one.
E X A M P L E
7.8 RATING NFL TEAMS9
We obtained the results of the 256 regular-season NFL games from the 2009 season and
entered the data into a spreadsheet, shown at the bottom of Figure 7.33 (see the file NFL
Ratings.xlsx). (Some of these results are hidden in Figure 7.33 to conserve space.) The
teams are indexed 1 to 32, as shown at the top of the sheet. For example, team 1 is Arizon-
a, team 2 is Atlanta, and so on. The first game entered (row 6) is team 25 Pittsburgh versus
team 31 Tennessee, played at Pittsburgh. Pittsburgh won the game by a score of 13 to 10,
and the point spread (home team score minus visitor team score) is calculated in column J.
A positive point spread in column J means that the home team won; a negative point spread
indicates that the visiting team won. The goal is to determine a set of ratings for the 32
NFL teams that most accurately predicts the actual outcomes of the games played.
Objective
To use NLP to find the ratings that best predict the actual point spreads
observed.
WHERE DO THE NUMBERS COME FROM?
Sports fans thank heaven for the Web. The results of NFL games, as well as NBA, MLB,
and other sporting games, can be found on a number of Web sites. We got this data from
http://www.pro-football-reference.com/years/2009/games.htm. To see much more about
sports ratings, go to Jeff Sagarin’s page at http://www.usatoday.com/sports/sagarin.htm. Of
course, if you are an avid sports fan, you probably already know the good Web sites.
9The procedure used in this example is practically identical to the procedure used by the nationally syndicated
Jeff Sagarin to rate various sports teams. You can see his ratings at http://www.usatoday.com/sports/sagarin.htm.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Solution
We first need to explain the methodology used to rate teams. Suppose that a team plays at
home against another team. Then the prediction for the point spread of the game (home
team score minus visitor team score) is
Predicted point spread
 Home team rating  Visitor team rating  Home team advantage
The home team advantage is the number of points extra for the home team because of the
psychological (or physical) advantage of playing on its home field. Football experts claim
that this home team advantage in the NFL is about three points. However, the model will
estimate it, as well as the ratings.
The prediction error is defined as
Prediction error  Actual point spread  Predicted point spread
The model determines ratings that minimize the sum of squared prediction errors.10 To get
a unique answer to the problem, the ratings must be normalized—that is, the average rating
must be fixed at some nominal value. Because the well-known Sagarin ratings use a nom-
inal value in the mid-80s, a nominal value of 85 is used here. (Any nominal value could be
used to produce exactly the same relative ratings.) Then what do ratings of, say, 82 and 91
really mean? They mean that if two teams with these ratings play each other on a neutral
field, the higher rated team is predicted to win by 9 points.
394
Chapter 7
Nonlinear Optimization Models
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
L
K
J
I
H
G
F
E
D
C
B
A
Rang NFL teams in 
e
vitc
ej
b
O
9
0
0
2
 to minimize
Sum squared errors
42925.68
Rangs of teams
Index
Team 
g
nit
a
R
e
m
a
n
Results of games
Model predicons and errors
a
n
o
zir
A
1
 Cardinals
84.52
Week
Home team index
Vising team index
Home team score
Vising team score
Point spread
Predicted spread
Squared error
at
n
alt
A
2
 
6
3
5
1.3
1
8
6
2
6.6
3
0
1
3
1
1
3
5
2
1
4
8.9
8
s
n
o
cla
F
e
r
o
m
itla
B
3
 
3
4
7
5.3
4
9
8
9
3.5
2
1
7
9
1
7
1
2
1
5
7.2
9
s
n
e
v
a
R
olaff
u
B
4
 
0
9
1
0.4
5
3
6
4
8
1.9
8
2
0
8
2
6
2
9
2
1
9
0.3
8
slliB
a
nilo
r
a
C
5
 
0
9
8
2.1
3
5
3
1.7
6
7
1
3
2
2
3
1
2
1
6
7.8
8
sr
e
h
t
n
a
P
o
g
a
cih
C
6
 
6
2
4
2.6
1
2
0
3
0.8
1
4
1
4
2
8
3
6
1
3
1
1
8.9
7
sr
a
e
B
it
a
n
nic
niC
7
 
4
2
7
2
2
3
1
1
4
5.7
8
sla
g
n
e
B
-17
-3.9914
169.2248
d
n
ale
v
elC
8
 
3
0
4
4.6
8
3
7
9
2.7
2
8
1
7
2
5
4
1
1
0
2
1
9
8.6
7
s
n
w
o
r
B
s
alla
D
9
 
4
3
1
2
9
0
3
1
2
1.2
9
s
y
o
b
w
o
C
-13
-10.7773
4.9404
r
e
v
n
e
D
0
1
 
0
2
6
1
8
2
1
1
4
6.5
8
s
o
c
n
o
r
B
-4
1.4531
29.7368
tio
rt
e
D
1
1
 
8
3
0
1
4
2
5
1
0
5.0
7
s
n
oiL
-28
-0.0255
782.5752
n
e
e
r
G
2
1
 Bay 
9
9
3
2.4
7
3
6
1
6.4
1
6
5
1
1
2
6
2
1
1
6
2.2
9
sr
e
k
c
a
P
n
o
ts
u
o
H
3
1
 
2
1
7
0
1
7
1
8
9.6
8
s
n
a
x
e
T
-5
4.0810
82.4650
silo
p
a
n
aid
nI
4
1
 
4
3
0
2
8
1
8
1
6
8.0
9
stlo
C
-14
-13.0051
0.9898
elliv
n
o
s
k
c
aJ
5
1
 
5
1
4
6.8
5
1
3
5
9
5.4
1
2
2
1
4
1
5
1
4
1
1
4
4.8
7
sr
a
u
g
aJ
s
a
s
n
a
K
6
1
 City 
4
2
0
2
7
2
3
2
1
9
8.6
7
sf
eih
C
-4
-15.4002
129.9648
i
m
ai
M
7
1
 
0
2
2
8.1
0
2
4
6
0
2.5
1
1
4
2
5
2
4
9
1
1
2
6.6
8
s
nih
plo
D
at
o
s
e
n
ni
M
8
1
 
4
3
1
3
3
1
1
3
2
6
0.2
9
s
g
nikiV
-3
-2.6233
0.1419
w
e
N
9
1
 England 
3
1
0
1
3
2
6
1
2
2
1.6
9
st
oirt
a
P
-3
4.0281
49.3937
w
e
N
0
2
 Orleans 
8
4
2
2
0
2
4
2
2
3
6.5
9
st
nia
S
-26
-2.4978
552.3537
w
e
N
1
2
 York 
7
9
6
1
9
1
2
2
2
0
1.5
8
st
n
ai
G
-0.8015
60.8637
w
e
N
2
2
 York 
4
4
8
4.8
5
1
1
9
8
5.4
1
2
7
9
6
2
2
3
2
5
1.3
9
st
e
J
d
n
alk
a
O
3
2
 
1
3
6
2
3
7
2
2
3
0.5
7
sr
e
dia
R
-5
2.0329
49.4611
aih
ple
d
alih
P
4
2
 
6
0
0
1.0
8
2
8
6.2
1
3
1
0
1
3
2
9
2
8
2
2
6
9.0
9
s
elg
a
E
h
g
r
u
b
sttiP
5
2
 
7
2
3
1
8
1
1
1
2
4
6.6
8
sr
ele
e
tS
-14
-19.3880
29.0309
.tS
6
2
 Louis 
3
3
1
3
1
2
9
2
2
7.7
6
s
m
a
R
-2
9.1950
125.3272
n
a
S
7
2
 Diego 
4
2
2
5.2
2
2
4
5
2.3
8
0
2
8
2
5
2
2
1
6.2
9
sr
e
g
r
a
h
C
n
a
S
8
2
 Francisco 
3
9
3
7.7
4
6
0
9
0.6
3
1
0
2
3
3
0
3
4
2
4
2.5
8
sr
e
9
4
eltt
a
e
S
9
2
 
3
4
1
7
1
5
2
6
2
3
7.4
7
s
k
w
a
h
a
e
S
-4.6576
58.6381
a
p
m
a
T
0
3
 Bay 
1
3
4
2
7
2
1
2
7
1.9
7
sr
e
e
n
a
c
c
u
B
-7
6.8843
192.7725
e
e
s
s
e
n
n
e
T
1
3
 
4
6
7
5.1
0
1
5
1
2
9.0
1
1
2
6
7
2
8
0
1
2
9
1.2
8
s
n
atiT
n
o
tg
nih
s
a
W
2
3
 
1
3
7
1
1
5
1
3
4
1.0
8
s
nik
s
d
e
R
-14
-3.9098
101.8115
7
2
3
2
4
1
7
1
3
-4
-2.0744
3.7081
Home team 
6
3
7
1
2
1
6
2
3
7
1.2
e
g
at
n
a
v
d
a
-19
-22.3629
11.3090
1
3
4
2
5
1
3
1
3
-7
10.7173
313.9016
Constraint on average rang (any nominal value could be used)
5
7
1
1.4
1
7
2
4
2.6
1
0
2
4
1
4
3
6
1
4
2
3
Actual 
5
3
7
3.3
3
3
6
1.8
0
1
3
1
3
2
7
1
7
2
3
0.5
8
e
g
a
r
e
v
a
6
7
4
9.5
3
6
5
9
9.8
3
4
2
7
2
8
2
8
1
3
=
Nominal 
4
2
0
1
2
0
3
3
5
8
e
g
a
r
e
v
a
-24
-3.7551
409.8576
0
2
1
6.7
3
9
2
3
1.3
1
7
7
1
4
2
1
3
2
2
3
Range names used:
5
4
1
9
1
2
3
1
1
3
-7.4595
155.2387
Actual_average
=Model!$B$
3
2
3
0
1
3
2
3
1
4
-20
-8.4302
133.8610
1
3
0
1
4
1
1
3
8
3
$
B
$
!le
d
o
M
=
e
g
at
n
a
v
d
a
_
m
a
e
t
_
e
m
o
H
-21
-4.1673
283.3409
5
4
8
1.8
6
1
4
1
3
0.8
1
1
3
3
4
3
8
3
3
3
4
$
B
$
!le
d
o
M
=
e
g
a
r
e
v
a
_la
ni
m
o
N
5
5
0
0.0
5
4
7
0.3
3
0
2
3
2
5
2
7
3
6
3
$
C
$:5
$
C
$
!le
d
o
M
=
g
nit
a
R
5
2
9
1
6
9
2
3
6
3
$
C
$:5
$
A
$
!le
d
o
M
=
elb
a
T
g
nit
a
R
-6
-2.9075
9.5636
9
2
4
9.6
5
9
3
5
4.8
6
1
0
1
6
2
2
9
1
4
2
$
F
$
!le
d
o
M
=
sr
o
rr
e
_
d
e
r
a
u
q
s
_
m
u
S
Figure 7.33 The NFL Ratings Model
The ratings are chosen
so that the predicted
point spreads match
the actual point
spreads as closely as
possible.
10Why squared errors? Admittedly, you could minimize the sum of the absolute prediction errors, but minimiz-
ing the sum of squared errors has a long tradition in statistics.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

DEVELOPING THE SPREADSHEET MODEL
To produce the model in Figure 7.33, proceed as follows:
1
Input game data. If you want to determine the ratings for another NFL (or NBA or
MLB) season, you have to get the data from the Web. (We are fortunate to have an inside
contact—Winston’s best friend is Jeff Sagarin.)
2
Changing cells. Enter any value for the home field advantage and the 32 team ratings
in the Home_team_advantage and Rating ranges. These are the changing cells. Note that it
would be possible to use a given value for the home team advantage, such as 3, but the
model will let Solver choose the home team advantage that best fits the data.
3
Average rating. Enter the nominal average rating in cell B43, and average the ratings
in cell B41 with the formula
=AVERAGE(Rating)
4
Actual point spr eads. Enter the actual point spreads in column J as differences
between columns H and I.
5
Predictions. The data on games played refer to the team index numbers. This allows
you to use lookup functions to predict the point spreads. To do this, enter the formula
=Home_team_advantage+VLOOKUP(F6,RatingTable,3)-
VLOOKUP(G6,RatingTable,3)
in cell K6 for the first game, and copy it down column K for the rest of the games. The
VLOOKUP functions simply look up the ratings of the home and visiting teams. (The range
name RatingTable refers to the range A5:C36.)
6
Prediction errors. The objective is to minimize the sum of squared prediction errors.
Therefore, enter the formula
=(J6-K6)^2
in cell L6, and copy it down. Then sum the squared errors in cell F2.
USING SOLVER
The completed Solver dialog box is shown in Figure 7.34. The objective is to find the rat-
ings and home field advantage that minimize the sum of squared prediction errors. The
only constraint is to make the ratings average to the nominal rating. Because of the squared
errors, this is a nonlinear model, so the GRG Nonlinear method should be used. Also, there
is no need to check the Non-Negative option.
Discussion of the Solution
The solution in Figure 7.33 shows that a home team advantage of 2.17 provides the best fit,
at least for the 2009 season. To provide a better picture of the ratings, the teams are sorted
from best to worst in Figure 7.35. You might recall that New Orleans won the Super Bowl,
beating Indianapolis. The ratings ranked New Orleans number 2, almost 5-point favorites
over Indianapolis (based on regular-season games only). The ratings support the playoff
picture fairly well. The 12 playoff teams are shown with color shading. Most of the highly
rated teams made the playoffs, Arizona being the lowest ranked team to make it in. Of
course, the NFL has its own way of deciding which teams make the playoffs. It doesn’t just
go according to the Sagarin ratings.
Remember that the actual values of the ratings are not as important as the differences
between teams’ ratings. For example, if Green Bay plays Dallas at Green Bay, Green Bay
7.6 Models for Rating Sports Teams
395
The VLOOKUP
functions let you find
the ratings to use
for the predicted
point spread.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

396
Chapter 7
Nonlinear Optimization Models
Figure 7.34
Solver Dialog Box
for the NFL Ratings
Model
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
A
B
C
D
E
F
Sorted from best to worst
Index
Team name
Rang
19
New England Patriots
96.12
20
New Orleans Saints
95.63
Super Bowl Champion
22
New York Jets
93.15
3
Balmore Ravens
92.75
27
San Diego Chargers
92.61
12
Green Bay Packers
92.26
9
Dallas Cowboys
92.12
18
Minnesota Vikings
92.06
24
Philadelphia Eagles
90.96
14
Indianapolis Colts
90.86
Loser in Super Bowl
2
Atlanta Falcons
89.84
5
Carolina Panthers
88.76
7
Cincinna Bengals
87.54
13
Houston Texans
86.98
25
Pisburgh Steelers
86.64
17
Miami Dolphins
86.62
10
Denver Broncos
85.64
28
San Francisco 49ers
85.24
21
New York Giants
85.10
1
Arizona Cardinals
84.52
4
Buﬀalo Bills
83.09
31
Tennessee Titans
82.19
32
Washington Redskins
80.14
6
Chicago Bears
79.81
30
Tampa Bay Buccaneers
79.17
15
Jacksonville Jaguars
78.44
16
Kansas City Chiefs
76.89
8
Cleveland Browns
76.89
23
Oakland Raiders
75.03
29
Seale Seahawks
74.73
11
Detroit Lions
70.50
26
St. Louis Rams
67.72
All playoﬀ teams 
shown in green.
Figure 7.35
Sorted NFL Ratings
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

is predicted to win by 2.17  (92.26  92.12)  2.4 points. Of course, there is a consider-
able amount of uncertainty in any game. Although Green Bay is predicted to win by
2.4 points, the actual outcome could be much different.11
■
7.6 Models for Rating Sports Teams
397
1.
This model does not capture the effect of intangibles, such as injuries to key players.
If you were going to bet real money on NFL games, you might start with the ratings
from the model and then modify them in a subjective fashion to capture any inside
knowledge you have.
2.
The future predictive accuracy can be improved by giving more weight to more recent
games. To do this, you could multiply the squared error for a game k weeks ago by a
factor such as (0.95)k. As an indication of how this discounts the importance of past
games, this weighting gives a game from five weeks ago about 77% of the weight
given to this week’s game.
3.
Solver could also be used to find the set of ratings that minimizes the sum of absolute
prediction errors. This shouldn’t have much effect on the relative rankings.
■
MODELING ISSUES
11 If you were going to simulate NFL games based on these ratings, you would simulate a normally distributed
point spread with the mean equal to the predicted point spread and standard deviation equal to about 14 points.
Yes, there is this much variability in NFL games.
P R O B L E M S
Skill-Building Problems
28. The file P07_28.xlsx lists the scores of all NFL games
played during the 2008 season. Use this data set to
rank the NFL teams from best to worst.
29. Carry out the suggestion in Modeling Issue 3. That
is, find the ratings of the 2009 NFL teams using the
sum of absolute prediction errors as the criterion to
minimize. Discuss any differences in ratings from
this method and the method used in Example 7.8.
30. Carry out the suggestion in Modeling Issue 2. That
is, use a weighted sum of squared prediction errors,
where the weight on any game played k weeks ago
is 0.95k. You can assume that the ratings are being
made right after the final regular games of the season
(in week 17), so for these final games, k  0. Discuss
how the ratings change when early-season games are
discounted heavily.
31. The file P07_31.xlsx contains scores on all of the
regular-season games in the NBA for the 2009–2010
basketball season. Use the same procedure as in
Example 7.8 to rate the teams. Then sort the teams
based on the ratings. Do these ratings appear to be
approximately correct? (You might recall that the
Lakers beat the Celtics in the finals.) What does the
model estimate the home court advantage to be?
Skill-Extending Problems
32. By the time you are reading this, the 2010 NFL season
will have finished, and the results should be available
at  http://www.pro-football-reference.com/years/
2010/games.htm. Perform a Web query from the Data
ribbon to import the scores. (Paste this URL into the
Address box and then click on the yellow arrow next
to the game scores.) Then do whatever it takes to get
the data into the format of this example. Finally, use
Solver to find the ratings and home-field advantage for
the 2010 NFL season.
33. By the time you are reading this, the 2010–2011 NBA
season will have finished, and the results should be
available at  http://www.basketball-reference.com/
leagues/NBA_2010_games.html. Perform a Web
query from the Data ribbon to import the scores.
(Paste this URL into the Address box and then click
on the yellow arrow next to the game scores.) Then do
whatever it takes to get the data into the format of this
example. Finally, use Solver to find the ratings and
home-field advantage for the 2010–2011 NBA season.
34. The method for rating teams in Example 7.8 is based
on actual and predicted point spreads. This method
can be biased if some teams run up the score in a few
games. An alternative possibility is to base the ratings
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

7.7 PORTFOLIO OPTIMIZATION MODELS
Given a set of investments, how do financial analysts determine the portfolio that has the
lowest risk and yields a high expected return? This question was answered by Harry
Markowitz in the 1950s. For his work on this and other investment topics, he received the
Nobel Prize in economics in 1990. The ideas discussed in this section are the basis for most
methods of asset allocation used by Wall Street firms. Asset allocation models are used, for
example, to determine the percentage of assets to invest in stocks, gold, and Treasury bills.
Before proceeding, however, you need to learn some important formulas involving the
expected value and variance of sums of random variables; these formulas are the basis for
most asset allocation models.
Weighted Sums of Random Variables
Let Ri be the (random) return earned during a year on a dollar invested in investment i. For
example, if Ri  0.10, a dollar invested at the beginning of the year grows to $1.10 at the end
of the year, whereas if Ri  0.20, a dollar invested at the beginning of the year decreases in
value to $0.80. We assume that n investments are available. Let xi be the fraction of our money
invested in investment i. We assume that x1  x2  
 
 
  xn  1, so that all of our money is
invested. (To prevent shorting a stock—that is, selling shares we don’t own—we assume that
xi  0.) Then the annual return on our investments is given by the random variable Rp, where
Rp  R1x1  R2x2  
 
 
  Rnxn
(The subscript p stands for “portfolio.”)
Let i be the expected value (also called the mean) of Ri, let 2
i be the variance of Ri
(so that i is the standard deviation of Ri), and let ij be the correlation between Ri and Rj.
To do any work with investments, you must understand how to use the following formulas,
which relate the data for the individual investments to the expected return and the variance
of return for a portfolio of investments.
Expected value of Rp  1x1  2x2  
 
 
  nxn
(7.5)
Variance of Rp 1
2x1
2  2
2x2
2  
 
 
  n
2xn
2  
ij
ijijxixj
(7.6)
The latter summation in the variance formula is over all pairs of investments. The quanti-
ties in Equations (7.5) and (7.6) are extremely important in portfolio selection because of
the risk-return trade-off investors need to make. All investors want to choose portfolios
with high return, measured by the expected value in Equation (7.5), but they also want
portfolios with low risk, usually measured by the variance in Equation (7.6).
Because the true expected values (i’s), variances (i
2’s), and correlations (ij’s) are
never known, they must be estimated. If historical data is available, the following proce-
dure can be used:
1.
Estimate i by Xi, the sample average of returns on investment i over several
previous years. You can use Excel’s AVERAGE function to calculate Xi.
2.
Estimate i
2 by si
2, the sample variance of returns on investment i over several
previous years. You can use Excel’s VAR function to calculate si
2.
398
Chapter 7
Nonlinear Optimization Models
only on wins and losses. For each game, you observe
whether the home team wins. Then from the proposed
ratings, you predict whether the home team will win.
(You predict the home team will win if the home team
advantage plus the home team’s rating is greater than
the visitor team’s rating.) You want the ratings such
that the number of predictions that match the actual
outcomes is maximized. Try modeling this. Do you
run into difficulties? (Remember that Solver doesn’t
like IF functions.)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

3.
Estimate i by si, the sample standard deviation of returns on investment i. You can
calculate si with Excel’s STDEV function. (Alternatively, you can calculate si as the
square root of si
2.)
4.
Estimate ij by rij, the sample correlation between past returns on investments i and j.
You can calculate the rij’s by using Excel’s CORREL function.
You can now estimate the mean and variance of the return on a portfolio by replacing
each parameter in Equations (7.5) and (7.6) with its sample estimate. This yields
Estimated expected value of Rp  X1x1  X2x2      Xnxn
(7.7)
Estimated variance of Rp s1
2x1
2  s2
2x2
2      sn
2xn
2  
ij
rijsisjxixj
(7.8)
In keeping with common practice, the annual return on investments is expressed in decimal
form, so that a return of 0.10 on a stock means that the stock has increased in value by 10%.
Equation (7.8) can be rewritten slightly by using covariances instead of correlations.
The covariance between two stock returns is another measure of the relationship between
the two returns, but unlike a correlation, it is not scaled to be between 1 and 1.
Although a covariance is a somewhat less intuitive measure than a correlation, finan-
cial analysts use it so frequently that we use it here as well. If cij is the estimated covariance
between stocks i and j, then cij  rijsisj. Using this equation and the fact that the correlation
between any stock and itself is 1, we can also write cii  si
2 for each stock i. Therefore, an
equivalent form of Equation (7.8) is the following:
Estimated variance of Rp  
i,j
cijxixj
(7.9)
As shown in the portfolio optimization example, this allows you to calculate the
estimated portfolio variance very easily with Excel’s matrix functions.
Matrix Functions in Excel
Equation (7.8) or (7.9) for the variance of portfolio return looks intimidating, particularly
if there are many potential investments. Fortunately, there are two built-in Excel matrix
functions to simplify the work. In this section, we illustrate how to use Excel’s MMULT
(matrix multiplication) and TRANSPOSE functions. Then in the next section, we put these
to use in the portfolio selection model.
A matrix is a rectangular array of numbers. A matrix is an i  j matrix if it has i rows
and j columns. For example,
A  

is a 2  3 matrix, and
B  
is a 3  2 matrix. If the matrix has only a single row, it is a row vector. Similarly, if it has
only a single column, it is a column vector.
If matrix A has the same number of columns as matrix B has rows, then it makes sense
to calculate the matrix product of A and B, denoted AB. The entry in row i, column j of the
product AB is obtained by summing the products of the elements in row i of A with the cor-
responding elements in column j of B. If A is an i  k matrix and B is a k  j matrix, then
AB is an i  j matrix.
For example, if
A  

1
2
3
2
4
5
1
2
3
4
5
6
1
2
3
4
5
6
7.7 Portfolio Optimization Models
399
Covariances indicate
relationships
between variables,
but unlike correlations,
covariances are
affected by the units
in which the variables
are measured.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

and
B  	
then AB is the following 2  2 matrix:
AB 
	  
	
The Excel MMULT function performs matrix multiplication in a single step.
The spreadsheet in Figure 7.36 indicates how to multiply matrices of different sizes. (See
the file Matrix Multiplication.xlsx.) For example, to multiply matrix 1 by matrix 2 (which
is possible because matrix 1 has 3 columns, and matrix 2 has 3 rows), select the range
B13:C14, type the formula
=MMULT(B4:D5,B7:C9)
and press Ctrl+Shift+Enter (all three keys at once). Note that you should select a range
with 2 rows because matrix 1 has 2 rows, and you should select a range with 2 columns
because matrix 2 has 2 columns.
22
28
39
50
1(1)  2(3)  3(5)
1(2)  2(4)  3(6)
2(1)  4(3)  5(5)
2(2)  4(4)  5(6)
1
2
3
4
5
6
400
Chapter 7
Nonlinear Optimization Models
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
A
B
C
D
E
F
G
H
I
J
K
L
M
N
Matrix mulplicaon in Excel
Typical mulplicaon of two 
n
oit
a
cilpitlu
M
s
e
cirt
a
m
 of a matrix and a column
Matrix 
n
m
ulo
C
3
2
1
1
 1
2
3
5
4
2
4
Matrix 2
1
2
xirt
a
M
4
3
 1 mes Column 1, with formula =MMULT(B4:D5,I4:I6)
tc
ele
S
6
5
 range with 2 rows, 1 column, enter formula, press Ctrl-Shi-Enter
20
Matrix 1 mes Matrix 2, with formula 
6
3
)
9
C
:7
B,5
D
:4
B
(T
L
U
M
M
=
Select range with 2 rows, 2 columns, enter formula, press Ctrl-Shi-Enter.
22
28
Mulplicaon of a row and a matrix
w
o
R
0
5
9
3
 1
4
5
Mulplicaon of a quadrac form (row mes matrix mes column)
Row 1 mes Matrix 1, with formula =MMULT(I14:J14,B4:D5)
Matrix 
tc
ele
S
3
1
2
3
 range with 1 row, 3 columns, enter formula, press Ctrl-Shi-Enter
1
-
7
3
8
2
4
1
0
1
3
0
4
Mulplicaon of a row and a column
Transpose of Column 1 mes Matrix 3 mes Column 
w
o
R
1
 2
1
6
3
Formula is =MMULT(TRANSPOSE(I4:I6),MMULT(B17:D19,I4:I6))
Select range with 1 row, 1 column, enter formula, press Ctrl-Shi-Enter
Row 2 mes Column 1, with formula =MMULT(I22:K22,I4:I6)
tc
ele
S
3
2
1
 range with 1 row, 1 column, enter formula, press Ctrl-Shi-Enter
32
Notes on quadrac form example:
Two MMULT's are required because MMULT works on only two ranges at a me. 
TRANSPOSE is needed to change a column into a row.
Figure 7.36 Examples of Matrix Multiplication in Excel
The matrix multiplication in cell B24 indicates that (1) three matrices can be multi-
plied together by using MMULT twice, and (2) the TRANSPOSE function can be used to
convert a column vector to a row vector (or vice versa), if necessary. Here, you want
to multiply column 1 by the product of matrix 3 and column 1. However, column 1 is
3  1, and matrix 3 is 3  3, so column 1 times matrix 3 doesn’t work. Instead, you must
transpose column 1 to make it 1  3. Then the result of multiplying all three together is a
1  1 matrix (a number). You can calculate it by selecting cell B24, typing the formula
=MMULT(TRANSPOSE(I4:I6),MMULT(B17:D19,I4:I6))
and pressing Ctrl+Shift+Enter. MMULT is used twice in this formula because this function
can multiply only two matrices at a time.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Excel Function: MMULT
The MMULT and TRANSPOSE functions are useful for matrix operations. They are called
array functions because the y return results to an entir e range, not just a single cell. The
MMULT function multiplies two matrices and has the syntax =MMUL
T(range1,range2),
where r ange1 must have as many columns as r
ange2 has r ows. To use this function,
highlight a range that has as many r ows as range1 and as many columns as r ange2, type
the formula, and pr ess Ctrl+Shift+Enter. The r esulting formula will have curly br ackets
around it in the Excel Formula Bar. You should not type these curly brackets. Excel enters
them automatically to remind you that this is an array formula. 
The Portfolio Selection Model
Most investors have two objectives in forming portfolios: to obtain a large expected return
and to obtain a small variance (to minimize risk). The problem is inherently nonlinear
because variance is a nonlinear function of the investment amounts. The most common
way of handling this two-objective problem is to require a minimal expected return and
then minimize the variance subject to the constraint on the expected return. The following
example illustrates how to accomplish this in Excel.
7.7 Portfolio Optimization Models
401
E X A M P L E
7.9 PORTFOLIO SELECTION AT PERLMAN & BROTHERS
P
erlman & Brothers, an investment company, intends to invest a given amount of money
in three stocks. From past data, the means and standard deviations of annual returns
have been estimated as shown in Table 7.7. The correlations among the annual returns on
the stocks are listed in Table 7.8. The company wants to find a minimum-variance portfo-
lio that yields an expected annual return of at least 0.12.
Table 7.8
Estimated Correlations Among Stock Returns
Combination
Correlation
Stocks 1 and 2
0.6
Stocks 1 and 3
0.4
Stocks 2 and 3
0.7
Table 7.7
Estimated Means and Standard Deviations of Stock Returns
Stock
Mean
Standard Deviation
1
0.14
0.20
2
0.11
0.15
3
0.10
0.08
Objective
To use NLP to find the portfolio of the three stocks that minimizes the risk,
measured by portfolio variance, subject to achieving an expected return of at least 0.12.
WHERE DO THE NUMBERS COME FROM?
Financial analysts typically estimate the required means, standard deviations, and correla-
tions for stock returns from historical data, as discussed at the beginning of this section.
However, you should be aware that there is no guarantee that these estimates, based on his-
torical return data, are relevant for future returns. If analysts have new information about
the stocks, they should incorporate this new information into their estimates.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Solution
The variables and constraints for this model are listed in Table 7.9. One interesting aspect
of this model is that you do not have to specify the amount of money invested—it could be
$100, $1000, $1,000,000, or any other amount. The model determines the fractions of this
amount to invest in the various stocks, and these fractions are then relevant for any invest-
ment amount. The only requirement is that the fractions sum to 1, so that all of the money
is invested. Besides this, the fractions should be nonnegative to prevent shorting stocks.12
The expected return from the portfolio should also be at least as large as the specified mini-
mal required expected return.
402
Chapter 7
Nonlinear Optimization Models
The optimal solution
indicates the fractions
to invest in the various
securities, and these
fractions are relevant
regardless of the total
dollar amount invested.
Table 7.9
Variables and Constraints for the Portfolio Selection Model
Input variables
Estimates of means, standard deviations, and correlations for stock 
returns, minimum required expected portfolio return
Decision variables 
Fractions invested in the various stocks
(changing cells)
Objective (target
Portfolio variance (minimize)
cell)
Other output 
Covariances between stock returns, total fraction of money invested, 
variables
expected portfolio return
Constraints
Total fraction invested = 1
Expected portfolio return  Minimum required expected portfolio return
DEVELOPING THE SPREADSHEET MODEL
The following are the individual steps required (see Figure 7.37 and the file Portfolio
Selection.xlsx):
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
A
B
C
D
E
F
G
H
I
Porolio selecon model
Range names used:
Actual_return
=Model!$B$23
Stock input data
Fracons_to_invest
=Model!$B$15:$D$15
Stock 1
Stock 2
Stock 3
Porolio_variance
=Model!$B$25
Mean 
3
2
$
D
$
!le
d
o
M
=
n
r
u
t
e
r
_
d
e
riu
q
e
R
1.0
1
1.0
4
1.0
n
r
u
t
e
r
StDev of 
9
1
$
B
$
!le
d
o
M
=
d
e
ts
e
v
ni_la
t
o
T
8
0.0
5
1.0
2.0
n
r
u
t
e
r
k
c
o
tS
s
n
oit
ale
rr
o
C
 1
Stock 2
Stock 3
Covariances
Stock 1
Stock 2
Stock 3
Stock 
k
c
o
tS
4.0
6.0
1
1
 1
0.04
0.018
0.0064
Stock 
k
c
o
tS
7.0
1
6.0
2
 2
0.018
0.0225
0.0084
Stock 
k
c
o
tS
1
7.0
4.0
3
 3
0.0064
0.0084
0.0064
Investment decisions
Stock 1
Stock 2
Stock 3
Fracons to invest
0.500
0.000
0.500
Constraint on invesng everything
Total 
d
e
riu
q
e
R
d
e
ts
e
v
ni
 value
1
=
0
0.1
Constraint on expected porolio return
Actual return
Required return
0.12
>=
0.12
Porolio variance
0.0148
Porolio stdev
0.1217
Figure 7.37 The Portfolio Selection Model
12If you want to allow shorting, do not check the Non-Negative option in Solver.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

1
Inputs. Enter the inputs in the blue ranges. These include the estimates of means,
standard deviations, and correlations, as well as the minimal required expected return.
2
Fractions invested. Enter any trial values in the Fractions_to_invest range for the
fractions of the company’s money placed in the three investments. Then sum these with the
SUM function in cell B19.
3
Expected annual return. Use Equation (7.7) to compute the expected annual return
in cell B23 with the formula
=SUMPRODUCT(B5:D5,Fractions_to_invest)
4
Covariance matrix. Equation (7.9) should be used to calculate the portfolio variance.
To do this, you must first calculate a matrix of covariances. Using the general formula for
covariance, cij  rij si sj (which holds even when i  j because rii  1), you can calculate
these from the inputs using lookups. Specifically, enter the formula
=HLOOKUP($F9,$B$4:$D$6,3)*B9*HLOOKUP(G$8,$B$4:$D$6,3)
in cell G9, and copy it to the range G9:I11. (This formula is a bit tricky, so take a close look
at it. The term B9 captures the relevant correlation. The two HLOOKUP terms capture the
appropriate standard deviations.)
5
Portfolio variance. Although the mathematical details are not discussed here, it can
be shown that the summation in Equation (7.9) is really the product of three matrices: a row
of fractions invested, the covariance matrix, and a column of fractions invested. To calculate
it, enter the formula
=MMULT(Fractions_to_invest,MMULT(G9:I11,TRANSPOSE(Fractions_to_
invest)))
in cell B25 and press Ctrl+Shift+Enter. (Remember that Excel puts curly brackets around
this formula when you press Ctrl+Shift+Enter. You should not type these curly brackets.)
Note that this formula uses two MMULT functions. Again, this is because MMULT can
multiply only two matrices at a time. Therefore, you first multiply the last two matrices and
then multiply this product by the first matrix.
6
Portfolio standard de viation. Most financial analysts talk in terms of portfolio
variance. However, it is probably more intuitive to talk about portfolio standard deviation
because it is in the same units as the returns. Calculate the standard deviation in cell B26
with the formula
=SQRT(Portfolio_variance)
Actually, either cell B25 or B26 can be used as the objective cell to minimize. Minimizing
the square root of a function is equivalent to minimizing the function itself.
USING SOLVER
The completed Solver dialog box is shown in Figure 7.38. The constraints specify that the
expected return must be at least as large as the minimum required expected return, and all
of the company’s money must be invested. The changing cells are constrained to be non-
negative (to avoid short selling), but because of the squared terms in the variance formula,
the GRG Nonlinear method must be used.
Discussion of the Solution
The solution in Figure 7.37 indicates that the company should put half of its money in each
of stocks 1 and 3, and it should not invest in stock 2 at all. This might be somewhat sur-
prising, given that the ranking of riskiness of the stocks is 1, 2, 3, with stock 1 being the
7.7 Portfolio Optimization Models
403
The MMULT function
can multiply only two
matrices at a time.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

most risky but also having the highest expected return. However, the correlations play an
important role in portfolio selection, so it is not usually easy to guess the optimal portfolio
on the basis of the means and standard deviations of stock returns alone.
The portfolio standard deviation of 0.1217 can be interpreted in a probabilistic sense.
Specifically, if stock returns are approximately normally distributed, then the probability is
about 0.68 that the actual portfolio return will be within one standard deviation of the
expected return, and the probability is about 0.95 that the actual portfolio return will be
within two standard deviations of the expected return. Given that the expected return is
0.12, this implies a lot of risk—two standard deviations below this mean is a negative
return (or loss) of slightly more than 12%.
Is the Solver Solution Optimal?
The constraints for this model are linear, and it can be shown that the portfolio variance is
a convex function of the investment fractions. Therefore, the Solver solution is guaranteed
to be optimal.
Sensitivity Analysis
This model begs for a sensitivity analysis on the minimum required expected return. When
the company requires a larger expected return, it must incur a larger risk, as shown in
Figure 7.39. You can use SolverTable with cell D23 as the single input cell, allowing it to
vary from 0.10 to 0.14 in increments of 0.005. Note that values outside this range are of no
interest. Stock 3 has the lowest expected return, 0.10, and stock 1 has the highest expected
return, 0.14, so no portfolio can have an expected return outside of this range.
404
Chapter 7
Nonlinear Optimization Models
Figure 7.38
Solver Dialog Box
for the Basic
Portfolio Model
Guessing the best
allocation in portfolio
optimization models is
difficult because it
depends not only on
expected returns and
standard deviations
of returns, but also
on correlations
between returns.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

The results indicate that the company should put more and more into risky stock 1 as
the required expected return increases—and stock 2 continues to be unused. The accompa-
nying scatter chart (with the option to connect the dots) shows the risk-return trade-off. As
the company assumes more risk, as measured by portfolio standard deviation, the expected
return increases, but at a decreasing rate.
The curve in this chart is called the efficient frontier. Points on the efficient frontier can
be achieved by appropriate portfolios. Points below the efficient frontier can be achieved,
but they are not as good as points on the efficient frontier because they have a lower
expected return for a given level of risk. In contrast, points above the efficient frontier are
unachievable—the company cannot achieve an expected return this high for a given level
of risk. An investor typically chooses a point on the efficient frontier that is most appropri-
ate for his or her attitude toward risk.
■
7.7 Portfolio Optimization Models
405
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
A
B
C
D
E
F
G
H
Oneway analysis for Solver model in Model worksheet
Required return (cell $D$23) values along side, output cell(s) along top
Fracons_to_invest_1
Fracons_to_invest_2
Fracons_to_invest_3
Porolio_stdev
Actual_return
0.100
0.000
0.000
1.000
0.0800
0.100
0.105
0.125
0.000
0.875
0.0832
0.105
0.110
0.250
0.000
0.750
0.0922
0.110
0.115
0.375
0.000
0.625
0.1055
0.115
0.120
0.500
0.000
0.500
0.1217
0.120
0.125
0.625
0.000
0.375
0.1397
0.125
0.130
0.750
0.000
0.250
0.1591
0.130
0.135
0.875
0.000
0.125
0.1792
0.135
0.140
1.000
0.000
0.000
0.2000
0.140
0.080
0.090
0.100
0.110
0.120
0.130
0.140
0.150
0.05
0.07
0.09
0.11
0.13
0.15
0.17
0.19
0.21
Expected return
Standard deviaon of return (risk)
Risk versus Return
Figure 7.39
The Efficient
Frontier
Financial analysts
typically put risk on
the horizontal axis
and expected return
on the vertical axis in
this type of risk-return
chart.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

406
Chapter 7
Nonlinear Optimization Models
1.
Typical real-world portfolio selection problems involve a large number of potential
investments, certainly many more than three. This admittedly requires more input
data, particularly for the correlation matrix, but the basic model does not change at
all. In particular, the matrix formula for portfolio variance shows the power of using
Excel’s matrix functions. Without them, the formula for portfolio variance would be
a long involved sum.
2.
If Perlman is allowed to short a stock, the fraction invested in that stock should be
allowed to be negative. To implement this, you should eliminate the nonnegativity
constraints on the changing cells.
3.
An alternative objective is to minimize the probability that the portfolio loses money.
You are asked to explore this possibility in one of the problems.
4.
Sometimes analysts use a “scenario approach” to portfolio analysis as an alternative to
the approach used here. See the file Portfolio Scenario Finished.xlsx for an example
of how this works.
5.
There are no transactions costs in Perlman’s model. Suppose that for every $1
traded in stock 1 or 2, Perlman must pay $0.01, and for every dollar traded in stock
3, it must pay $0.005. Also, suppose the company begins with 10% of its money
invested in stock 1, 40% in stock 2, and 50% in stock 3. The file Portfolio
Transactions Finished.xlsx illustrates how the transactions costs (from buying and
selling) can be accounted for in the model.
■
MODELING ISSUES
Investment Decision Support for Bank Hapoalim Customers
Avriel et al. (2004) describe the Opti-Money decision support system for allocating assets
they developed for Bank Hapoalim, Israel’s largest bank. They solved a Markowitz-type
NLP model to produce optimal tailor-made investment portfolios in terms of asset classes.
In 2002, the bank held 133,000 consultation sessions with 63,000 customers in which
Opti-Money was used. The system obtained net income that was 88% higher in customer
accounts that used Opti-Money than in accounts where it was not used. In that same year,
the annual income for the bank directly attributed to Opti-Money exceeded $31 million.
■
ADDITIONAL APPLICATIONS
P R O B L E M S
Skill-Building Problems
35. For each of the following, answer whether it makes
sense to multiply the matrices of the given sizes. In
each case where it makes sense, demonstrate an
example in Excel, where you can make up the
numbers.
a. AB, where A is 3  4 and B is 4  1
b. AB, where A is 1  4 and B is 4  1
c. AB, where A is 4  1 and B is 1  4
d. AB, where A is 1  4 and B is 1  4
e. ABC, where A is 1  4, B is 4  4, and C is 4  1
f. ABC, where A is 3  3, B is 3  3, and C is 3  1
g. ATB, where A is  4  3 and B is 4  3, and AT
denotes the transpose of A
36. Add a new stock, stock 4, to the model in Example
7.9. Assume that the estimated mean and standard
deviation of return for stock 4 are 0.125 and 0.175,
respectively. Also, assume the correlations between
stock 4 and the original three stocks are 0.3, 0.5, and
0.8. Run Solver on the modified model, where the
required expected portfolio return is again 0.12. Is
stock in the optimal portfolio? Then run SolverTable
as in the example. Is stock 4 in any of the optimal
portfolios on the efficient frontier?
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

37. In the model in Example 7.9, stock 2 is not in the
optimal portfolio. Use SolverTable to see whether it
ever enters the optimal portfolio as its correlations
with stocks 1 and 3 vary. Specifically, use a two-way
SolverTable with two inputs, the correlations between
stock 2 and stocks 1 and 3, each allowed to vary from
0.1 to 0.9 in increments of 0.1. Capture as outputs the
three changing cells. Discuss the results. (Note: You
will have to change the model slightly. For example, if
you use cells B10 and C11 as the two SolverTable
input cells, you will have to ensure that cells C9 and
D10 change accordingly. This is easy. Just put formu-
las in these latter two cells.)
38. The stocks in Example 7.9 are all positively correlated.
What happens when they are negatively correlated?
Answer for each of the following scenarios. In each
case, two of the three correlations are the negatives of
their original values. Discuss the differences between
the optimal portfolios in these three scenarios.
a. Change the signs of the correlations between
stocks 1 and 2 and between stocks 1 and 3. (Here,
stock 1 tends to go in a different direction from
stocks 2 and 3.)
b. Change the signs of the correlations between
stocks 1 and 2 and between stocks 2 and 3. (Here,
stock 2 tends to go in a different direction from
stocks 1 and 3.)
c. Change the signs of the correlations between
stocks 1 and 3 and between stocks 2 and 3. (Here,
stock 3 tends to go in a different direction from
stocks 1 and 2.)
39. The file P07_39.xlsx contains historical monthly
returns for 27 companies. For each company, calculate
the estimated mean return and the estimated variance of
return. Then calculate the estimated correlations
between the companies’ returns. Note that “return” here
means monthly return. (Hint: Use StatTools’ Summary
Statistics capabilities.)
7.8 Estimating the Beta of a Stock
407
40. This problem continues using the data from the
previous problem. The file P07_40.xlsx includes all of
the previous data and contains fractions in row 3 for
creating a portfolio. These fractions are currently all
equal to 1/27, but they can be changed to any values
you like, as long as they continue to sum to 1. For any
such fractions, find the estimated mean, variance, and
standard deviation of the resulting portfolio return.
Skill-Extending Problems
41. Continuing the previous problem, find the portfolio
that achieves an expected monthly return of at least
0.01% and minimizes portfolio variance. Then use
SolverTable to sweep out the efficient frontier, as in
Example 7.9. Create a chart of this efficient frontier
from your SolverTable results. What are the relevant
lower and upper limits on the required expected
monthly return?
42. In many cases, the portfolio return is at least approxi-
mately normally distributed. Then Excel’s NORMDIST
function can be used to calculate the probability that
the portfolio return is negative. The relevant formula
is =NORMDIST(0,mean,stdev,1), where mean and
stdev are the expected portfolio return and the standard
deviation of portfolio return, respectively.
a. Modify the model in Example 7.9 slightly, and
then run Solver to find the portfolio that achieves
at least a 0.12 expected return and minimizes the
probability of a negative return. Do you get the
same optimal portfolio as before? What is the
probability that the return from this portfolio will
be negative?
b. Using the model in part a, proceed as in Example
7.9 to use SolverTable and create a chart of the
efficient frontier. However, this time, put the
probability of a negative return on the
horizontal axis.
7.8 ESTIMATING THE BETA OF A STOCK
For financial analysts, it is important to be able to predict the return on a stock from the
return on the market, that is, on a market index such as the S&P 500 index. Here, the return
on an investment over a time period is the percentage change in its value over the time
period. It is often hypothesized that
rs    rm  
(7.10)
where rs is the return on a stock during a time period, rm is the return on the market during the
same time period,  is a random error term, and  and  are constants that must be estimated.
The true value of  in Equation (7.10), which is never known but can only be estimated, is
called the beta of the stock. From Equation (7.10), you can see that an increase in the market
return of 1% increases the return on the stock by % (on average). Therefore,  is a measure
of the responsiveness of a stock’s return to changes in the market return. The returns on
stocks with large positive or negative s are highly sensitive to the business cycle.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Sharpe’s capital asset pricing model (CAPM) implies that stocks with large beta values
are riskier and therefore must yield higher returns than those with small beta values. This
implies that if you can estimate beta values more accurately than people on Wall Street, you
can better identify overvalued and undervalued stocks and make a lot of money.
How do people usually estimate the beta of a stock? Most often, they run a regression
analysis with the monthly return on the stock as the dependent variable and the monthly
return on the market as the explanatory variable. Because we have not yet covered regres-
sion analysis (see Chapter 14), we explore other methods for estimating betas in this sec-
tion. Specifically, we discuss four methods that (in conjunction with Solver) can be used to
estimate  and  in Equation (7.10). This requires a set of observations, where an observa-
tion lists both the market return and the return on the stock during a particular time period.
(We use monthly data.)
Let a and b denote potential estimates of the unknown parameters  and . Then for
month i, a prediction of the return on the stock is given by the equation
rˆsi  a  brmi
(7.11)
Here, rˆsi is the predicted stock return for period i, and rmi is the actual market return for
period i. The error for period i , labeled ei, is defined as
ei  rsi  rˆsi
(7.12)
That is, the error is the actual return of the stock minus the predicted return. If the
predictions were perfect, then all of the errors in Equation (7.12) would equal 0. However,
this is generally impossible, so the estimates a and b are chosen to make the errors close to
0. The following sections discuss four possible criteria for choosing these estimates.
Criterion 1: Sum of Squared Errors (Least Squares)
Here the objective is to minimize the sum of the squared errors over all observations, the
same criterion used elsewhere in this chapter. The sum of the squared errors is a convex
function of the estimates a and b, so Solver is guaranteed to find the (unique) estimates of
 and  that minimize the sum of squared errors. The main problem with the least squares
criterion is that outliers, points for which the error in Equation (7.12) is especially large,
exert a disproportionate influence on the estimates of  and .13
Criterion 2: Weighted Sum of Squared Errors
Criterion 1 gives equal weights to older and more recent observations. It seems reasonable
that more recent observations have more to say about the beta of a stock, at least for future
predictions, than older observations. To incorporate this idea, a smaller weight is attached
to the squared errors for older observations. Although this method usually leads to more
accurate predictions of the future than least squares, the least squares method has many
desirable statistical properties that weighted least squares estimates do not possess.
Criterion 3: Sum of Absolute Errors (SAE)
Instead of minimizing the sum of the squared errors, it makes sense to minimize the sum
of the absolute errors for all observations. This is often called the sum of absolute errors
(SAE) approach. This method has the advantage of not being greatly affected by outliers.
408
Chapter 7
Nonlinear Optimization Models
13This is the criterion most financial analysts use, and they implement it through regression, not optimization
per se. The regression approach enables them to see the important effects of stock volatility and correlation
with the market.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Unfortunately, less is known about the statistical properties of SAE estimates. Another
drawback to SAE is that there can be more than one combination of a and b that minimizes
SAE. However, SAE estimates have the advantage that they can be obtained with linear
programming.
Criterion 4: Minimax
A final possibility is to minimize the maximum absolute error over all observations. This
method might be appropriate for a highly risk-averse decision maker. (See Chapter 9 for a
discussion of risk aversion.) This minimax criterion can also be implemented using LP.
The following example illustrates how Solver can be used to obtain estimates of  and
 for these four criteria.
7.8 Estimating the Beta of a Stock
409
E X A M P L E
7.10 ESTIMATING BETAS OF PROMINENT COMPANIES
W
e obtained close to ten years of monthly closing price data for 27 company stocks,
along with data for the S&P 500 market index over the same months. (We got these
data from Yahoo!’s finance Web page. Fortunately, the downloaded data are automatically
adjusted for stock splits and dividends.) The data extend from December 1999 to June
2010. Do the betas for these stocks depend on the criterion used to estimate them? Are the
estimates the same if they are based on only the most recent three years of data, rather than
on all of the data?
Solution
The data are in the file Stock Beta.xlsx. There is one worksheet named Data that contains
the monthly closing prices and corresponding returns for all stocks and the S&P 500 mar-
ket index. (See Figure 7.40, where a number of rows have been hidden.) The calculations
are performed in a sheet named Model, as shown in Figure 7.41. For any selected com-
pany, the sheet is set up so that any of the four criteria can be used with either the most
recent three years of data or all of the data simply by changing the target cell in the Solver
dialog box. The following steps are required.
1
Calculate r eturns. The downloaded data from the Web are closing prices, not
returns. To calculate the returns (in Figure 7.40), enter the formula
=(B4-B5)/B5
in cell B135 on the Data sheet and copy down and across through cell AC260. (Note that
there are no returns for December 1999 because the closing prices from November 1999 are
not listed.)
2
Alpha, beta. (From here on, all instructions relate to the Model sheet, shown in
Figure 7.41.) Enter any values of alpha and beta in cells B4 and B5. These can be negative
or positive.
3
Copy returns. Copy the S&P 500 returns to column B of the Model sheet, and copy
the returns from any selected stock to column C of the Model sheet. Paste each as values.
4
Predictions. Predict the stock returns from Equation (7.11) by entering the formula
=Alpha+Beta*B10
in cell D10 and copying down.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

410
Chapter 7
Nonlinear Optimization Models
1
2
3
4
5
6
7
8
9
10
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
255
256
257
258
259
260
A
B
C
D
E
F
Monthly closing prices from Dec 1999 to Jun 2010
Month
S&P 500
AA
AAPL
AXP
BA
Jun-2010
1030.71
10.06
251.53
39.70
62.75
May-2010
1089.41
11.64
256.88
39.69
64.18
Apr-2010
1186.69
13.40
261.09
45.91
72.01
Mar-2010
1169.43
14.21
235.00
41.07
72.19
Feb-2010
1104.49
13.27
204.62
37.85
62.80
Jan-2010
1073.87
12.67
192.06
37.33
59.84
Dec-2009
1115.10
16.05
210.73
39.99
53.45
May-2000
1420.60
23.60
21.00
41.44
32.18
Apr-2000
1452.43
26.09
31.01
38.24
32.58
Mar-2000
1498.58
28.26
33.95
38.04
31.03
Feb-2000
1366.42
27.55
28.66
34.27
30.32
Jan-2000
1394.46
27.93
25.94
42.07
36.40
Dec-1999
1469.25
33.27
25.70
42.39
33.90
Monthly returns (% changes) from Jan 2000 to Jun 2010
Month
S&P 500
AA
AAPL
AXP
BA
Jun-2010
-0.0539
-0.1357
-0.0208
0.0003
-0.0223
May-2010
-0.0820
-0.1313
-0.0161
-0.1355
-0.1087
Apr-2010
0.0148
-0.0570
0.1110
0.1178
-0.0025
Mar-2010
0.0588
0.0708
0.1485
0.0851
0.1495
Feb-2010
0.0285
0.0474
0.0654
0.0139
0.0495
Jan-2010
-0.0370
-0.2106
-0.0886
-0.0665
0.1196
Jun-2000
0.0239
-0.0076
0.2471
-0.0345
0.0702
May-2000
-0.0219
-0.0954
-0.3228
0.0837
-0.0123
Apr-2000
-0.0308
-0.0768
-0.0866
0.0053
0.0500
Mar-2000
0.0967
0.0258
0.1846
0.1100
0.0234
Feb-2000
-0.0201
-0.0136
0.1049
-0.1854
-0.1670
Jan-2000
-0.0509
-0.1605
0.0093
-0.0075
0.0737
Figure 7.40
Stock Prices and
Returns
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
A
B
C
D
E
F
G
H
I
J
K
L
Esmaon model for McDonalds: 3-year period, sum of squared errors esmaon method
Possible 
s
a
t
e
B
s
e
vitc
ejb
o
 for various objecves for McDonald's
Parameters
3-year
All 
3
a
t
a
d
-year
All data
Alpha
0.0162
SSE
0.0615
0.4375
SSE
0.5323
0.7688
0
5
3
7.0
2
6
2
5.0
E
S
S
W
7
1
9
2.0
8
5
5
0.0
E
S
S
W
3
2
3
5.0
a
t
e
B
SAE
1.1722
5.6626
SAE
0.4647
0.7530
Weighng constant
0.995
MaxAE
0.0979
0.2141
MaxAE
0.3641
0.8327
Date
Mkt return
Stock return
Predicted
Error
SqError
AbsError
Weight
Range names used:
Jun-2010
-0.0539
-0.0150
-0.0125
-0.0024
0.00001
0.0024
1
Alpha
=Model!$B$4
May-2010
-0.0820
-0.0447
-0.0275
-0.0172
0.00030
0.0172
0.9950
Beta
=Model!$B$5
Apr-2010
0.0148
0.0580
0.0240
0.0340
0.00116
0.0340
0.9900
MaxAE_3
=Model!$E$7
Mar-2010
0.0588
0.0449
0.0475
-0.0026
0.00001
0.0026
0.9851
MaxAE_All
=Model!$F$7
Feb-2010
0.0285
0.0314
0.0313
0.0001
0.00000
0.0001
0.9801
SAE_3
=Model!$E$6
Jan-2010
-0.0370
-0.0002
-0.0035
0.0034
0.00001
0.0034
0.9752
SAE_All
=Model!$F$6
Dec-2009
0.0178
-0.0127
0.0256
-0.0383
0.00147
0.0383
0.9704
SSE_3
=Model!$E$4
Nov-2009
0.0574
0.0884
0.0467
0.0417
0.00174
0.0417
0.9655
SSE_All
=Model!$F$4
Oct-2009
-0.0198
0.0270
0.0056
0.0213
0.00045
0.0213
0.9607
WSSE_3
=Model!$E$5
Sep-2009
0.0357
0.0148
0.0352
-0.0204
0.00042
0.0204
0.9559
Aug-2009
0.0336
0.0304
0.0340
-0.0036
0.00001
0.0036
0.9511
Figure 7.41 The Beta Estimation Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

5
Errors, squared errors, and absolute errors. The error in any row is the actual stock
return minus the predicted stock return. Therefore, enter the formulas
=C10-D10
=E10^2
=ABS(E10)
in cells E10, F10, and G10, respectively, and copy these down.
6
Weights. (This is for the weighted sum of squares criterion only.) Enter a desired
weighting constant in cell B7. Then enter 1 in cell H10, enter the formula
=$B$7*H10
in cell H11, and copy this formula down column H. This makes each weight a constant
fraction of the previous weight, so that more recent data are weighted more heavily.
7
Objectives. To set up eight possible objectives in the range B117:C120, enter the
formulas
=SUM(F10:F45)
=SUMPRODUCT(F10:F45,H10:H45)
=SUM(G10:G45)
=MAX(G10:G45)
in cells E4 through E7, and enter similar formulas using all of the data in columns F to H
in cells F4 through F7.
USING SOLVER
The completed Solver dialog box should look similar to Figure 7.42, except that any of the
eight possible objective cells can be used as the target cell. There are no constraints, not
even nonnegativity constraints, and the GRG Nonlinear method should be chosen.
Discussion of the Solution
The solution in Figure 7.41 indicates that McDonald’s is not very sensitive to the market,
having a beta less than 1 for the sum of squared errors criterion when the most recent
three years of data are used. (The solution shown in the alpha and beta cells is for mini-
mizing the sum of squared errors for the previous three years.) If you change the objective,
the beta for McDonald’s ranges from about 0.36 to 0.53 across the four criteria (using the
weight 0.995 for weighted sum of squares) when the most recent three years of data are
used, and it ranges from about 0.74 to 0.83 when all of the data are used. These results are
shown in the top right of Figure 7.41, where each is the optimal beta for a different Solver
run, each using a different objective. Clearly, a stock’s beta can depend not only on which
optimality criterion is used but also on the time period selected.
To run this analysis for any other stock, copy its returns to column C of the Model sheet
and rerun Solver with one of the possible objectives. You will find that the betas for differ-
ent companies can vary widely.
Alternative Modeling Approaches
You might have noticed that we ignored one of our own warnings in this example.
Specifically, the SAE and minimax objectives depend on the ABS and MAX functions.
Does Solver provide the correct solution for these two criteria? The answer is not a definitive
7.8 Estimating the Beta of a Stock
411
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

yes, but it appears that the solutions are correct for the problems we solved. Basically, Solver
has difficulty with ABS and MAX functions when the objective or constraints are not suffi-
ciently smooth, but it appears that the objectives used here pass the smoothness test.
However, it is possible to develop alternative models for these two objectives that are linear.
The advantage, of course, is that the Simplex LP method can then be used, which means that
it is guaranteed to find the optimal solution. In the interest of space, a full discussion of these
alternative models is not presented here, but you can see them in the files Stock Beta 3
Alternative Finished.xlsx and Stock Beta 4 Alter native Finished.xlsx. The only draw-
back to these models is that they rely on modeling tricks that are not obvious.
■
412
Chapter 7
Nonlinear Optimization Models
Figure 7.42
Solver Dialog
Box for the Beta
Estimation Model 
P R O B L E M S
Skill-Building Problems
43. Given the data in the file Stock Beta.xlsx, estimate
the beta (and alpha) for Microsoft (MSFT). Do this for
each criterion and each period of time to obtain a table
analogous to that in the top right of Figure 7.41. What
do you conclude about Microsoft?
44. Repeat the previous problem, but analyze GE instead
of Microsoft.
7.9 CONCLUSION
A large number of real-world problems can be approximated well by linear models.
However, many problems are also inherently nonlinear. We have illustrated several such
problems in this chapter, including the important class of portfolio selection problems
where the risk, usually measured by portfolio variance, is a nonlinear function of the
decision variables. We have purposely neglected much of the mathematics behind
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

nonlinear optimization because of its technical difficulty. However, it is important for you
to realize that nonlinear models present many more hazards for spreadsheet Solvers (or any
other software) than linear models. Unless you can verify that the assumptions for a
minimization or maximization problem are satisfied—and this can be difficult to do—
there is no guarantee that Solver will converge to the optimal solution (or even converge at
all). The examples in this chapter were purposely kept small and relatively simple so that
Solver could handle them and produce optimal solutions. Larger and more complex non-
linear models are not always so accommodating and frequently require solution methods
well beyond the level of this book.
7.9 Conclusion
413
Summary of Key Management Science Terms
Term
Explanation
Page
Nonlinear 
Models with nonlinearities in the objective and/or the 
354
programming (NLP)
constraints
models
Global optimum
Solution that is guaranteed to be the optimal solution
355
Local optimum
Solution that is better than all nearby solutions, but might not 
355
be the best overall
Convex function
Function with a nondecreasing slope
356
Concave function
Function with a nonincreasing slope
356
Optimality guarantee 
No package, including Solver, can guarantee that the solution 
358
for NLP models
it stops at will be the global optimum unless certain
convexity/concavity conditions are satisfied
Multistart option
A new option in Solver for Excel 2010 that automatically optimizes
359
from a number of starting points and returns the best solution found
Demand function
A function that relates demand for a product to its price
361
Constant elasticity 
A demand function where elasticity (percent change in demand for 
362
demand function
a 1% change in price) is constant for any price
Minimizing sum of 
A popular method of fitting a curve of some form to a set of 
380
squared errors
points; the errors are the differences between observed and
predicted values
Unconstrained models 
An optimization model with no constraints 
382
Weighted sum of 
An important quantity in financial portfolio analysis; random  
398
random variables
variables are returns from investments, weights are fractions 
put in investments
Return, risk measures of 
Portfolio models try to maximize expected return and minimize 
398
portfolio models
variance of return (risk); formulas for these involve correlations 
or covariances among investment returns
Matrix 
A rectangular array of numbers; often useful for simplifying 
399
complex summation formulas
Efficient frontier 
Curve that shows the largest expected portfolio return possible 
405
for a given level of risk 
Beta of a stock
A value that indicates the responsiveness of a stock’s return to
407
changes in the return of the market
Sum of absolute errors 
An alternative criterion to sum of squared errors for making 
408
(SAE)
errors small
Minimax
An alternative criterion for making errors small, minimizes the
409
largest error
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

414
Chapter 7
Nonlinear Optimization Models
Summary of Key Excel Terms
Term
Explanation
Excel
Page
SUMXMY2 
Useful for calculating distance between 
=SUMXMY2(xRange,yRange)
390
function
two points
MMULT function
An array function that multiplies two 
Highlight result range, type 
399
matrices stored in Excel ranges
=MMULT(range1,range2), press 
Ctrl+Shift+Enter
P R O B L E M S
Skill-Building Problems
45. Suppose Ford currently sells 250,000 Ford Mustangs
annually. The unit cost of a Mustang, including the
delivery cost to a dealer, is $16,000. The current
Mustang price is $20,000, and the current elasticity of
demand for the Mustang is 1.5.
a. Determine a profit-maximizing price for a
Mustang. Do this when the demand function is
of the constant elasticity type. Do it when the
demand function is linear.
b. Suppose Ford makes an average profit of $800
from servicing a Mustang purchased from a Ford
dealer. (This is an average over the lifetime of the
car.) How do your answers to part a change?
46. Suppose the current exchange rate is 100 yen per
dollar. We currently sell 100 units of a product for
700 yen. The cost of producing and shipping the
product to Japan is $5, and the current elasticity of
demand is 3. Find the optimal price to charge for the
product (in yen) for each of the following exchange
rates: 60 yen/$, 80 yen/$, 100 yen/$, 120 yen/$, 140
yen/$, and 160 yen/$. Assume the demand function is
linear.
47. Another way to derive a demand function is to break
the market into segments and identify a low price, a
medium price, and a high price. For each of these
prices and market segments, we ask company experts
to estimate product demand. Then we use Excel’s
trend curve fitting capabilities to fit a quadratic func-
tion that represents that segment’s demand function.
Finally, we add the segment demand curves to derive
an aggregate demand curve. Try this procedure for
pricing a candy bar. Assume the candy bar costs $0.55
to produce. The company plans to charge between
$1.10 and $1.50 for this candy bar. Its marketing
department estimates the demands shown in the file
P07_47.xlsx (in thousands) in the three regions of the
country where the candy bar will be sold. What is the
profit-maximizing price, assuming that the same price
will be charged in all three regions?
48. Widgetco produces widgets at plants 1 and 2. It costs
125x12 dollars to produce x units at plant 1 and
235x13 dollars to produce x units at plant 2. Each
plant can produce up to 500 units. Each unit produced
can be sold for $10. At most 800 widgets can be sold.
Determine how Widgetco can maximize its profit.
49. If a monopolist produces q units, she can charge
400  4q dollars per unit. The variable cost is 
$60 per unit.
a. How can the monopolist maximize her profit?
b. If the monopolist must pay a sales tax of 5% of 
the selling price per unit, will she increase or
decrease production (relative to the situation with
no sales tax)?
c. Continuing part b, use SolverTable to see how a
change in the sales tax affects the optimal solution.
Let the sales tax vary from 0% to 8% in increments
of 0.5%.
50. It costs a company $12 to purchase an hour of labor
and $15 to purchase an hour of capital. If L hours
of labor and K units of capital are available, then 
0.05L23K13 machines can be produced. Suppose the 
company has $100,000 to purchase labor and capital.
a. What is the maximum number of machines it can
produce?
b. Use SolverTable to see how a change in the price
of labor changes the optimal solution.
c. Use SolverTable to see how a change in the price
of capital changes the optimal solution.
d. Use SolverTable to see how a change in the amount
of money available changes the optimal solution.
51. In the previous problem, what is the minimum-cost
method of producing 100 machines? (Ignore the
$10,000 budget constraint.)
52. The cost per day of running a hospital is 200,000 
0.5x2 dollars, where x is the number of patients served
per day. What number of patients served per day mini-
mizes the cost per patient per day of running the
hospital if the hospital’s daily capacity is 300 patients?
How does the solution change as the hospital’s
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

capacity increases? Let capacity increase from 300 to
500 in increments of 25.
53. Two firms are producing widgets. It costs the first firm
q1
2 dollars to produce q1 widgets and the second firm
0.5q2
2 dollars to produce q2 widgets. If a total of q
widgets are produced, consumers will pay 200  q
dollars for each widget. If the two manufacturers want
to collude in an attempt to maximize the sum of their
profits, how many widgets should each company
produce? (The model for this type of problem is
called a collusive duopoly model.)
54. A company manufactures two products. If it charges
price pi for product i, it can sell qi units of product i,
where q1  60  3p1  p2 and q2  80  2p2  p1. It
costs $5 to produce a unit of product 1 and $12 to pro-
duce a unit of product 2. How many units of each
product should the company produce, and what prices
should it charge, to maximize its profit?
55. A brewing company has $100,000 to spend on adver-
tising in four markets. The sales revenue (in thousands
of dollars) that can be created in each market by
spending xi thousand dollars in market i is given in the
file P07_55.xlsx.
a. To maximize its sales revenue, how much
money should the company spend in each market?
b. Use SolverTable to see how a change in the
advertising budget affects the optimal sales revenue.
56. Q&H Company advertises during soap operas and
football games. Each soap opera ad costs $50,000,
and each football game ad costs $100,000. If S soap
opera ads are purchased, they will be seen by 5S12
million men and 20S12 million women. If F football
ads are purchased, they will be seen by 17F12 million
men and 7F12 million women. The company wants at
least 40 million men and at least 60 million women to
see its ads.
a. Determine how to minimize Q&H’s cost of
reaching the required number of viewers.
b. How does this model violate the proportionality
and additivity assumptions of LP?
c. Suppose that the number of women (in millions)
reached by F football ads and S soap opera ads is
7F12  20S12  0.2(FS)12. Why might this be a
more realistic representation of the number of
women viewers seeing Q&H’s ads?
57. A beer company has divided Bloomington into
two territories. If the company spends x1 dollars on
promotion in territory 1, it can sell 60x1
12 cases of
beer there; and if it spends x2 dollars on promotion
in territory 2, it can sell 40x2
12 cases of beer there.
Each case of beer sold in territory 1 sells for $10
and incurs $5 in shipping and production costs.
Each case of beer sold in territory 2 sells for $9 and
incurs $4 in shipping and production costs. A total of
$5000 is available for promotion.
7.9 Conclusion
415
a. How can the beer company maximize its profit?
b. If an extra dollar could be spent on promotion, by
approximately how much would the company’s
profit increase? By how much would its revenue
increase?
c. Use SolverTable to see how a change in the price
of beer 1 affects the optimal solution. Do the same
for a change in the price of beer 2.
58. A firm is planning to spend $75,000 on advertising. It
costs $3000 per minute to advertise on television and
$1000 per minute to advertise on radio. If the firm
buys x minutes of television advertising and y minutes
of radio advertising, its revenue in thousands of dollars
is given by 0.3x2  0.4y2  0.8xy  5x  10y. How
can the firm maximize its revenue?
59. J&J has given you $12 million to spend on advertising
Huggys diapers during the next 12 months. At the
beginning of January, Huggys has a 30% market share.
During any month, 10% of the people who purchase
Huggys defect to brand X, and a fraction 0.2a12 of
customers who usually buy brand X switch to Huggys,
where a is the amount spent on advertising in millions
of dollars. For example, if you spend $4 million during
a month, 40% of brand X’s customers switch to
Huggys. Your goal is to maximize J&J’s average mar-
ket share during the next 12 months, where the aver-
age is computed from each month’s ending share.
Determine an appropriate advertising policy. (Hint:
Make sure you enter a nonzero trial value for each
month’s advertising expense or Solver might give you
an error message.)
60. Based on Kolesar and Blum (1973). Suppose that a
company must service customers lying in an area of
A square miles with n warehouses. Kolesar and Blum
showed that when the warehouse(s) are located
properly, the average distance between a warehouse
and a customer is (An)12. Assume that it costs the
company $60,000 per year to maintain a warehouse
and $400,000 to build a warehouse. Also, assume that
a $400,000 building cost is equivalent to incurring a
cost of $40,000 per year indefinitely. The company
fills 160,000 orders per year, and the shipping cost per
order is $1 per mile. If the company serves an area
of 100 square miles, how many warehouses should it
have?
61. A company has five factories. The x- and y-coordinates
of the location of each factory are given in the file
P07_61.xlsx. The company wants to locate a ware-
house at a point that minimizes the sum of the squared
distances of the plants from the warehouse. Where
should the warehouse be located?
62. Monroe County is trying to determine where to place
the county fire station. The locations of the county’s
four major towns are as follows: (10, 20), (60, 20),
(40, 30), and (80, 60) (see Figure 7.43). Town 1
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

averages 20 fires per year; town 2, 30 fires; town 3, 40
fires; and town 4, 25 fires. The county wants to build
the fire station in a location that minimizes the average
distance that a fire engine must travel to respond to a
fire. Because most roads run in either an east-west or a
north-south direction, the fire engine must do the
same. For example, if the fire station is located at (30,
40) and a fire occurs at town 4, the fire engine has to
travel 
80  30
  
 60  40
  70 miles to the fire.
a. Determine where the fire station should be located.
b. Use SolverTable to see how the optimal location of
the fire station changes as the number of fires at
town 3 changes.
416
Chapter 7
Nonlinear Optimization Models
each barrel can be sold for 80  x1 dollars. If the com-
pany extracts x2 million barrels during year 2, each
barrel can be sold for 85  x2 dollars. The cost of
extracting x1 million barrels during year 1 is 2x1
2 mil-
lion dollars, and the cost of extracting x2 million bar-
rels during year 2 is 3x2
2 million dollars. A total of
20 million barrels of oil are available, and at most
$250 million can be spent on extraction. Determine
how the company can maximize its profit (revenues
less costs) for the next two years.
66. Suppose that you are hiring a weather forecaster to
predict the probability that next summer will be rainy
or sunny. The following suggests a method that can
be used to ensure that the forecaster is accurate.
Suppose that the actual probability of next summer
being rainy is 0.6. (For simplicity, we assume that the
summer can only be rainy or sunny.) If the forecaster
announces a probability p that the summer will be
rainy, he receives a payment of 1  (1  p)2 if
the summer is rainy and a payment of 1  p2 if the
summer is sunny. Show that the forecaster will
maximize his expected profit by announcing that
the probability of a rainy summer is 0.6.
67. The cost of producing x units of a product during
a month is x12 dollars. Show that the minimum-
cost method of producing 40 units during the next two
months is to produce all 40 units during a single
month.
68. A company uses raw material to produce two
products. For $150, a unit of raw material can be
purchased and processed into four units of product
1 and two units of product 2. If x1 units of product
1 are produced, they can be sold at 250  x1 dollars
per unit. If x2 units of product 2 are produced, they
can be sold at 140  x2 dollars per unit. (Negative
prices are not permitted.) The company can choose
the number of units of raw material that are purchased
and processed. How can the company maximize its
profit?
Skill-Extending Problems
69. Most economies have a goal of maximizing the
average consumption per period. Assume that
during each year, an economy saves the same (to
be determined) percentage S of its production.
During a year in which the beginning capital level
is K, a quantity K12 of capital is produced. If the
economy saves a percentage S of its capital, then
during the current year it consumes (1  S)K units
of capital and, through savings, adds (SK)12 units of
capital. Also, during any year, 10% of all capital
present at the beginning of the year depreciates or
wears out.
Town 4
(80, 60)
Town 3
(40, 30)
Town 2
(60, 20)
Town 1
(10, 20)
20
40
60
80
100
20
40
60
80
100
Figure 7.43
Existing Locations for the Fire Station
Problem
63. Consider three investments. You are given the
following means, standard deviations, and
correlations for the annual return on these three
investments. The means are 0.12, 0.15, and 0.20.
The standard deviations are 0.20, 0.30, and 0.40.
The correlation between stocks 1 and 2 is 0.65,
between stocks 1 and 3 is 0.75, and between stocks
2 and 3 is 0.41. You have $10,000 to invest and can
invest no more than half of your money in any single
stock. Determine the minimum-variance portfolio
that yields an expected annual return of at least 0.14.
64. You have $1000 to invest in three stocks. Let R1 be the
random variable representing the annual return on $1
invested in stock i. For example, if Ri  0.12, then $1
invested in stock i at the beginning of a year is worth
$1.12 at the end of the year. The means are E(R1) 
0.14, E(R2)  0.11, and E(R3)  0.10. The variances
are Var R1  0.20, Var R2 0.08, and Var R3  0.18.
The correlations are r12  0.8, r13  0.7, and r23
0.9. Determine the minimum-variance portfolio that
attains an expected annual return of at least 0.12.
65. An oil company must determine how many barrels of
oil to extract during each of the next two years. If the
company extracts x1 million barrels during year 1,
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

a. What annual savings percentage S maximizes
the long-run average consumption level? Assume
that year 50 represents the long run, so that the
objective is the consumption level in year 50.
You can assume the initial capital is 1 (for some
appropriate measurement unit).
b. Use SolverTable to see how the optimal value of S
depends on the annual depreciation rate.
70. Each morning during rush hour, 10,000 people want
to travel from New Jersey to New York City. If a
person takes the commuter train, the trip lasts 
40 minutes. If x thousand people per morning drive to
New York, it takes 20  5x minutes to make the trip.
This problem illustrates a basic fact of life: If people
make their decisions individually, they will cause more
congestion than is actually necessary.
a. Show that if people make their decisions individu-
ally, an average of 4000 people will travel by road
from New Jersey to New York. Here you should
assume that people will divide up between the
trains and roads in a way that makes the average
travel time by road equal to the travel time by train.
When this “equilibrium” occurs, nobody has an
incentive to switch from the road to the train or
vice versa.
b. Show that the average travel time per person is
minimized if 2000 people travel by road.
71. Based on Grossman and Hart (1983). A salesperson
for Fuller Brush has three options: (1) quit, (2) put
forth a low effort level, or (3) put forth a high effort
level. Suppose for simplicity that each salesperson
will sell $0, $5000, or $50,000 worth of brushes. The
probability of each sales amount depends on the effort
level as described in the file P07_71.xlsx. If a sales-
person is paid w dollars, he or she regards this as a
“benefit” of w12 units. In addition, low effort costs the
salesperson 0 benefit units, whereas high effort costs
50 benefit units. If a salesperson were to quit Fuller
and work elsewhere, he or she could earn a benefit of
20 units. Fuller wants all salespeople to put forth a
high effort level. The question is how to minimize the
cost of encouraging them to do so. The company can-
not observe the level of effort put forth by a salesper-
son, but it can observe the size of his or her sales.
Thus, the wage paid to the salesperson is completely
determined by the size of the sale. This means that
Fuller must determine w0, the wage paid for sales of
$0; w5000, the wage paid for sales of $5000; and
w50,000, the wage paid for sales of $50,000. These
wages must be set so that the salespeople value the
expected benefit from high effort more than quitting
and more than low effort. Determine how to minimize
the expected cost of ensuring that all salespeople put
forth high effort. (This problem is an example of
agency theory.)
7.9 Conclusion
417
72. Kellpost Cereal Company sells four products: (1)
Special L (a low-calorie, high-nutrition cereal); (2)
Corn Bran (another low-calorie, high-nutrition cereal);
(3) Admiral Smacks (a sugary cereal pitched at the
children’s market); and (4) Honey Pops (another sweet
cereal pitched at the children’s market). Kellpost has
sufficient production capacity to produce a total of
10,000 boxes of cereal per month. For each of the past
16 months, Kellpost has kept track of the price and
sales of each product. (These data are listed in the file
P07_72.xlsx.) Market executives believe that Special
L and Corn Bran might be substitutes for each other,
as might be Admiral Smacks and Honey Pops. For
example, this means that an increase in the price of
Special L might raise the sales of Corn Bran. The vari-
able cost of bringing a box of each cereal to market is
as follows: Special L, $2.00; Corn Bran, $2.20;
Admiral Smacks, $2.30; Honey Pops, $2.40.
a. Use the given information to determine the price
for each cereal that will enable Kellpost to
maximize profits.
b. Now suppose that Kellpost can increase its
monthly production capacity. The cost (per year) of
doing this is $20,000 per thousand boxes of added
monthly capacity. Can you determine an optimal
capacity level?
73. Find the minimum perimeter rectangle having area
64 square feet. Can you generalize this result?
74. You are given that the two nonhypotenuse sides of
a right triangle add up to 10 inches. What is the
maximum area of the triangle? Can you generalize
this result?
75. A cylindrical soda can has a volume of 20 cubic inches.
What height and diameter minimize the surface area of
the can? Can you generalize this result?
76. City B is 10 miles downstream from city A. City A is
5 miles south of the river, and city B is 20 miles north
of the river. The river is two miles wide. Where should
a bridge be built across the river to make the travel dis-
tance between cities A and B as small as possible?
Can you generalize this result?
77. You can swim two miles per hour and run six miles per
hour. You are walking north along South Beach and see
someone drowning half a mile out in the ocean and
one mile north of you. What combination of running
and swimming is the quickest way to reach the
swimmer?
78. A triangle has a 5-inch side and a 12-inch side. To
maximize the area of the triangle what should the third
side be? Can you generalize this result?
79. Four items are for sale in the Dollar Value store. The
product and sum of their prices is $7.11. What is the
price of each item?
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

418
Chapter 7
Nonlinear Optimization Models
Modeling Problems
80. For the product mix examples (Examples 3.1 and 3.2
in Chapter 3), discuss where you think the assump-
tions of a linear model are most likely to break down.
How might an NLP model look in this situation?
81. For the oil blending example (Example 4.4 in Chapter
4), discuss where you think the assumptions of a linear
model are most likely to break down. How might an
NLP model look in this situation?
82. For the aggregate planning example (Example 4.3
in Chapter 4), is it likely that the cost per worker of
changing the size of the workforce during a month
would be constant (as we assumed)? How could an
NLP model account for a situation in which the cost
per worker of changing the size of the workforce is not
constant?
83. Consider the sports ratings model in section 7.6. If you
were going to give more recent games more weight, how
might you determine whether the weight given to a
game from k weeks ago should be, say, (0.95)k or (0.9)k?
84. Consider the sports ratings model in section 7.6. If you
were going to use the approach used there to forecast
future sports contests, what problems might you
encounter early in the season? How might you resolve
these problems?
85. UE is going to invest $400 million to acquire compa-
nies in the auto and/or electronics industry. How
would you apply portfolio optimization to determine
which companies should be purchased?
86. Your family owns a large farm that can grow wheat,
corn, cotton, alfalfa, barley, pears, and apples. Each
product requires a certain amount of labor each month
and a certain number of hours of machine time. You
have just studied portfolio optimization and want to
help your family run its farm. What would you do?
87. Your company is about to market a new golf club. You
have convened a focus group of 100 golfers and asked
them to compare your club to the clubs produced by
your competitors. You have found, for example, that
30 customers in the focus group would purchase your
club if you charged $120, 28 customers would pur-
chase your club if you charged $130, and so on. How
could you use this information to determine the price
at which your club should be sold?
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

C A S E  
K
ate Torelli, a security analyst for Lion-Fund, has
identified a gold mining stock (ticker symbol
GMS) as a particularly attractive investment. Torelli
believes that the company has invested wisely in new
mining equipment. Furthermore, the company has
recently purchased mining rights on land that has
high potential for successful gold extraction. Torelli
notes that gold has underperformed the stock
market in the last decade and believes that the time
is ripe for a large increase in gold prices. In addition,
she reasons that conditions in the global monetary
system make it likely that investors may once again
turn to gold as a safe haven in which to park assets.
Finally, supply and demand conditions have improved
to the point where there could be significant upward
pressure on gold prices.
GMS is a highly leveraged company, so it is a
risky investment by itself. Torelli is mindful of a
passage from the annual report of a competitor,
Baupost, which has an extraordinarily successful
investment record: “Baupost has managed a decade
of consistently profitable results despite, and perhaps
in some respect due to, consistent emphasis on
the avoidance of downside risk. We have frequently
carried both high cash balances and costly market
hedges. Our results are particularly satisfying when
considered in the light of this sustained risk aver-
sion.” She would therefore like to hedge the stock
purchase—that is, reduce the risk of an investment
in GMS stock.
Currently GMS is trading at $100 per share.
Torelli has constructed seven scenarios for the price
of GMS stock one month from now. These scenarios
and corresponding probabilities are shown in 
Table 7.10.
To hedge an investment in GMS stock,Torelli can
invest in other securities whose prices tend to move
in the direction opposite to that of GMS stock. In
particular, she is considering over-the-counter put
options on GMS stock as potential hedging instru-
ments. The value of a put option increases as the
price of the underlying stock decreases. For example,
consider a put option with a strike price of $100 and
a time to expiration of one month. This means that
the owner of the put has the right to sell GMS stock
at $100 per share one month in the future. Suppose
that the price of GMS falls to $80 at that time. Then
the holder of the put option can exercise the option
and receive $20 (100  80). If the price of GMS
falls to $70, the option would be worth $30 (100
 70). However, if the price of GMS rises to $100
or more, the option expires worthless.
Torelli called an options trader at a large
investment bank for quotes. The prices for three
(European-style) put options are shown in Table 7.11.
Torelli wants to invest $10 million in GMS stock and
put options.
Table 7.11 Put Option Prices (Today) for the
GMS Case Study
Put Put 
Put 
Option A
Option B
Option C
Strike price
90
100
110
Option price
$2.20
$6.40
$12.50
Questions
1.
Based on Torelli’s scenarios, what is the expected
return of GMS stock? What is the standard
deviation of the return of GMS stock?
2.
After a cursory examination of the put option
prices, Torelli suspects that a good strategy is to
buy one put option A for each share of GMS
stock purchased. What are the mean and
standard deviation of return for this strategy?
7.1 GMS STOCK HEDGING
Case 7.1 GMS Stock Hedging
419
Table 7.10 Scenarios and Probabilities for GMS Stock in One Month
Scenario 1
Scenario 2
Scenario 3
Scenario 4
Scenario 5
Scenario 6
Scenario 7
Probability
0.05
0.10
0.20
0.30
0.20
0.10
0.05
GMS stock price
150
130
110
100
90
80
70
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

420
Chapter 7
Nonlinear Optimization Models
3.
Assuming that Torelli’s goal is to minimize the
standard deviation of the portfolio return,
what is the optimal portfolio that invests all
$10 million? (For simplicity, assume that
fractional numbers of stock shares and put
options can be purchased. Assume that the
amounts invested in each security must be
nonnegative. However, the number of options
purchased need not equal the number of shares
of stock purchased.) What are the expected
return and standard deviation of return of this
portfolio? How many shares of GMS stock and
how many of each put option does this portfolio
correspond to?
4.
Suppose that short selling is permitted—that is,
the nonnegativity restrictions on the portfolio
weights are removed. Now what portfolio
minimizes the standard deviation of return?
(Hint: A good way to attack this problem is to
create a table of security returns, as indicated
in Table 7.12. Only a few of the table entries
are shown. To correctly compute the standard
deviation of portfolio return, you will need to
incorporate the scenario probabilities. If ri is
the portfolio return in scenario i, and pi is the
probability of scenario i, then the standard
deviation of portfolio return is


7
i1
pi(r
i  )2

where   
7
i1
piri is the expected portfolio
return.)
Table 7.12 Table of Security Returns
GMS Stock 
Put Option A
Put Option B
Put Option C
Scenario 1
100% 
2 
30% 
...
7
220%
■
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

421
Evolutionary Solver: An Alternative
Optimization Procedure
C H A P T E R
DEVELOPINGA
 N OPERA          TING-PLAN MODEL
AT SANTA FE RAILWAY
L
ike many other companies, Santa Fe Railway faces increasing demands for
customer service, cost pressures, and changing market conditions. This is
particularly true in its intermodal business area, in which traffic moves on
some combination of ship or truck and train. The company averaged almost
8% growth per year in intermodal traffic handled during the period from
1989 to 1996. This increased growth and changing patterns of customer
traffic created difficult problems for Santa Fe, as described in Gorman
(1998). The company needed to use its trains and rail lines efficiently from 
a cost standpoint, but it also had to provide customers with high-quality
service. In addition, the company had to be flexible to change its operating
plan quickly in response to changing customer traffic patterns.
Historically, Santa Fe’s service design was rather myopic. The service
designers tried their best to make incremental refinements to current
operations, but their thinking was based too much on historical procedures
and could not adapt sufficiently to changing customer needs. They eventually
decided to create an operating-plan model capable of building an operating
plan for the intermodal business unit from scratch, one that could best adapt
to the current and expected traffic patterns and would not be constrained
by traditional patterns or historical schedules. As inputs, this model required
© Soleg1974 | Dreamstime.com
8
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

customer service requirements, engineering capabilities, and physical plant
constraints. The outputs included a weekly train timetable, traffic-to-train assignments,
yard and railway line schedules, and equipment and locomotive flows.The objective was
to simultaneously allocate physical rail network resources to trains and allocate
scarce train space to traffic flows to minimize operating costs while meeting customer
requirements.
The operating-plan problem was decomposed into two problems: the train
timetable problem and the traffic assignment problem. The former prescribes which
trains will travel on which lines at which times. Given this information, the latter problem
prescribes which customer loads are assigned to which trains. Each problem is huge, and
much ingenuity was required to model and solve these problems. For the timetable
problem, the original model represented each hour of the week for every possible train
as a binary decision variable, where 1 indicates a train and 0 indicates no train.This
model was impossibly large, so the service design team reduced its size by specifying a
menu of allowable train routes (about 200) from which the model could choose. Even
this reduced problem was much too large for traditional integer programming algo-
rithms to solve, so the analysts did what is becoming more common in large optimiza-
tion models: they turned to newer, emerging types of algorithms. In particular, they tried
the genetic “survival of the fittest” algorithms discussed in this chapter, where they
mixed schedules from a given population of schedules to carry over the best
characteristics of these schedules to the next generation of schedules. Unfortunately,
genetic algorithms alone were painfully slow at producing useful populations of train
schedules for this large problem. Therefore, the authors combined genetic algorithms
with another type of algorithm, called tabu search, to speed up the process. (Tabu search
uses information from previous iterations to search in a promising direction. However, a
tabu list prohibits the algorithm from undoing recent changes to the schedule or revisit-
ing recent solutions.) This method of combining algorithms worked and enabled Santa Fe
to solve the timetable problem reasonably quickly. The company was then able to solve
the traffic assignment problem by a clever priority-based, shortest-path heuristic.
Santa Fe Intermodal used its operating-plan model to study many major changes in
rail operations: to predict train volumes based on long-term forecasts, to quantify the
impact of containerization of intermodal business on train operations, and to develop a
cost basis in contract negotiations for large amounts of incremental business. The model
has shown the potential to improve global service by 4% while reducing costs by 6%
over the previous operating plan. As R. Mark Schmidt, an analyst at Santa Fe, stated,
“Obviously, as with any major deviation from traditional processes, the acceptance of the
operating-plan model has been a gradual one. Recent successes of the model are building
confidences and as a result, the model is being interwoven into the intermodal service
design process at Santa Fe.” ■
422
Chapter 8
Evolutionary Solver: An Alternative Optimization Procedure
8.1 INTRODUCTION
In Chapters 3 through 7, we used Excel’s Solver to solve many interesting and important
problems. Unfortunately, there are many optimization problems where Solver’s Simplex
LP and GRG Nonlinear algorithms are unable to find optimal solutions. However, genetic
algorithms often perform well on optimization problems where Solver’s other algorithms
perform poorly. The purpose of this chapter is to illustrate some interesting models that
cannot be solved by the Solver algorithms discussed in previous chapters, at least not easily
or without tricks, but can be solved with genetic algorithms in a reasonably straightforward
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

manner. In short, the methods in this chapter enable you to solve a much wider range of
optimization models.
Fortunately, Solver for Excel 2010 includes the Evolutionary algorithm, which was
previously available only in Premium Solver (included with previous versions of the book).
Therefore, Premium Solver is no longer necessary. In fact, we were told by Frontline
Systems, the developer of Solver, that Solver for Excel 2010 is essentially the old Premium
Solver. The following summarizes the three algorithms included with Solver for Excel
2010. To avoid confusion, from here on we will refer to the three Solver algorithms avail-
able with Excel 2010 as Simplex LP Solver, GRG Nonlinear Solver, and Evolutionary
Solver.
■
Simplex LP Solver is used to solve linear models, including models where some or
all of the changing cells are restricted to be binary and/or integer.
■
GRG Nonlinear Solver is used to solve nonlinear models when the objective cell and
constraints are “smooth” functions of the changing cells.
■
Evolutionary Solver uses genetic algorithms to find good (close to optimal) solutions
to more difficult problems, including those where the objective cell and/or
constraints are “nonsmooth” functions of the changing cells.
Several times in previous chapters, we stated that the first two Solvers cannot handle
models with IF, MAX, MIN, and several other Excel functions. The problem is that such
models often contain nonsmooth functions in the objective cell and/or the constraint cells.
(Technically, a nonsmooth function has discontinuities or points where its derivatives do
not exist.) It is sometimes possible to make these models linear so that the Simplex LP
Solver can be used, but nonobvious tricks are usually necessary to do so. Fortunately, this
is not necessary with Evolutionary Solver, as illustrated in this chapter. Evolutionary
Solver uses a type of algorithm called a genetic algorithm, which is much more flexible.
Before discussing genetic algorithms and Evolutionary Solver, we review the strengths
and weaknesses of the Solvers used in previous chapters.
Recall that an optimization model is linear if the objective cell is a linear function of
the changing cells, the left and right sides of all constraints are linear functions of the
changing cells, and all changing cells are allowed to contain fractional values—that is,
there are no integer constraints. For such models, Simplex LP Solver is guaranteed to find
an optimal solution (if an optimal solution exists). We have discussed many linear models
in Chapters 3 through 5. Simplex LP Solver is an excellent method to use for any opti-
mization problem that can be set up as a linear model, provided that the model does not
exceed Solver’s size restrictions—up to 200 changing cells and 100 constraints (not count-
ing simple upper or lower bounds on changing cells). Most larger linear models are diffi-
cult to handle in a spreadsheet format. These larger models are often solved using a
modeling language such as LINGO, GAMS, or AMPL. With a modeling language, a user
can generate, say, 10,000 supply constraints for a transportation model with one line of
computer code. This makes it easy to compactly represent and solve large models. (We
should also mention that Frontline Systems has developed commercial large-scale Solvers
that are capable of solving very large spreadsheet models.)
In Chapter 6, we considered linear models where some or all of the changing cells are
constrained to be integers. In theory, Simplex LP Solver should be able to find optimal
solutions to these problems, but in practice it can take hours, days, or even weeks to find opti-
mal solutions to difficult, integer-constrained models. This is not necessarily a weakness of
Solver—integer-constrained models are inherently difficult for any optimization software
package—but there are algorithms other than the algorithm used by Solver that work bet-
ter for some integer models.
8.1 Introduction
423
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

In the previous chapter, we discussed nonlinear models and saw that GRG Nonlinear
Solver is capable of solving many of these. However, nonlinear models present two prob-
lems. First, as discussed in section 7.2 of Chapter 7, GRG Nonlinear Solver can get stuck
at a local maximum or a local minimum and never find the global maximum or minimum.
The function shown in Figure 7.1 illustrates this situation. In this example, GRG Nonlinear
Solver fails to find the global optimal solution for certain starting solutions. Fortunately, as
discussed in Chapter 7, GRG Nonlinear Solver for Excel 2010 has a Multistart option that
increases the chances of finding the global optimal solution in problems like this one.
Second, if a spreadsheet model uses IF, ABS, MAX, or MIN functions that depend on
any of the model’s changing cells, the model is typically nonsmooth, and GRG Nonlinear
Solver can have difficulty finding an optimal solution. One possibility that could be caused
by an IF function is illustrated in Figure 8.1. The context here is ordering a product with a
quantity discount, so that the order quantity is on the horizontal axis and the total cost
(ordering cost plus inventory holding cost) is on the vertical axis. The IF function specifies
that if the order quantity is less than A, one function specifies the total cost. If the order
quantity is between A and B, another function specifies the total cost. Finally, if the order
quantity is greater than B, a third function specifies the total cost. The resulting graph is
not only nonlinear, but it has discontinuities at A and B, where the total cost jumps from
one value to another. The overall cost-minimizing order quantity is to the right of B. If you
select an initial solution to the right of B, GRG Nonlinear Solver will locate the correct
optimal solution. However, if you start at a point to the left of B, GRG Nonlinear Solver
will almost certainly not find the optimal solution.
424
Chapter 8
Evolutionary Solver: An Alternative Optimization Procedure
Figure 8.1
A Cost Function
with Discontinuities
The point of this discussion is that although Simplex LP Solver and GRG Nonlinear
Solver can handle many models with no difficulty, they are not well suited to finding opti-
mal solutions for certain types of models. We now discuss a completely different solution
method that is sometimes more successful at solving these difficult problems.
The standard Solver
cannot handle
functions with
discontinuities 
reliably.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

8.2 INTRODUCTION TO GENETIC ALGORITHMS
In the early 1970s, John Holland of the University of Michigan realized that many features
espoused in the theory of natural evolution, such as survival of the fittest and mutation,
could be used to help solve difficult optimization problems.1 Because his methods were
based on behavior observed in nature, Holland coined the term genetic algorithm to describe
his algorithm. Simply stated, a genetic algorithm (GA) provides a method of intelligently
searching an optimization model’s feasible region for an optimal solution. Biological termi-
nology is used to describe the algorithm. The objective function is called a fitness function,
and a specification of values for all changing cells is called a chromosome. For most prob-
lems, a GA codes changing cells in binary notation. For example, 1001 represents
1(23)  0(22)  0(21)  1(20)  8  1  9
The following is a rough outline of how a GA might work. (There are various imple-
mentations of GAs, and the details vary from one implementation to another.) Suppose a
company must decide how many units of each of two products to order. Because of quantity
discounts, the function that represents total cost has discontinuities of the type observed in
Figure 8.1. Actually, the total cost is even more complex than in Figure 8.1 because there
are two products, not just one. However, the only requirement of the algorithm is that total
cost TC(Q1, Q2) can be calculated for any combination of the order quantities Q1 and Q2.
Suppose Q1 and Q2 must each be between 0 and 500. (In this discussion, we assume that the
model has no constraints other than lower bounds and upper bounds on each changing cell.
Later we discuss how a GA can handle other types of constraints.) Then the GA uses the
following steps:
1.
Generate a population. The GA randomly samples values of the changing cells
between the lower and upper bounds to generate a set of (usually at least 50) chro-
mosomes. The initial set of chromosomes is called the population. For example, two
members of the population might be
■
Chromosome 1: Q1  100 and Q2  400 (or in binary, Q1  001100100 and 
Q2  110010000)
■
Chromosome 2: Q1  300 and Q2  200 (or in binary, Q1  100101100 and 
Q2  011001000)
The initial population is constructed by randomly choosing points from the prob-
lem’s feasible region. (Note that nine binary digits are sufficient to represent any
order quantity from 0 to 500.)
2.
Create a new generation. Create a new generation of chromosomes in the hope of
finding an improvement. In the new generation, chromosomes with a smaller fitness
function (in a minimization problem) have a greater chance of surviving to the next
generation. Suppose in our example that chromosome 1 has a fitness value (total
cost) of $2560, and chromosome 2 has a fitness value of $3240. Then chromosome
1 should have a larger chance of surviving to the next generation. Crossover and
mutation are also used to generate chromosomes for the next generation.
a.
Crossover (fairly common) splices together two chromosomes at a prespecified
point. For example, if chromosomes 1 and 2 are combined by crossover and the
crossover point is between the fourth and fifth digits from the right, the resulting
chromosomes (in binary) are
■
New chromosome 1: Q1  100100100 and Q2  011000000 (or Q1  292
and Q2  192)
8.2 Introduction to Genetic Algorithms
425
In GA terms, a
chromosome is a
binary (0-1) represen-
tation of a potential
solution.
1Goldberg (1989), Davis (1991), and Holland (1992) are good references on genetic algorithms.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

■
New chromosome 2: Q1  001101100 and Q2  110011000 (or Q1  108
and Q2  408)
Note that the two original Q1s are used to create the two new Q1s and similarly
for the Q2s. For example, Q1 for the new chromosome 1 splices together the left
digits 10010 from Q1 of the original chromosome 2 and the right digits 0100
from Q1 of the original chromosome 1.
b. Mutation (very rare) randomly selects a digit and changes it from 0 to 1 or vice
versa. For example, if we mutate the left digit of Q1 in chromosome 2, the new
Q1 in chromosome 2 becomes Q1  000101100 (or Q1  44). As this example
indicates, mutation can provide a dramatic effect, leading to a completely differ-
ent location in the feasible region. Therefore, an occasional mutation is useful for
getting the algorithm “unstuck.”
3.
Stopping condition. At each generation, the best value of the fitness function in
the generation is recorded, and the algorithm repeats step 2. If no improvement in
the best fitness value is observed after many consecutive generations, the GA
terminates.
To handle a constraint such as Q1  Q2  700, the GA adds (in a minimization prob-
lem), M(Q1  Q2  700) to the fitness function, where M is a suitably large number such
as 1,000,000. Now any chromosome that violates the constraint has a high value of the
fitness function because the “penalty” M(Q1  Q2  700) greatly increases the value of
the new fitness function. This causes the GA to avoid chromosomes that violate the
constraint.
Strengths and Weaknesses of GAs
If you let a GA run long enough, it is guaranteed to find the solution to any optimization
problem. The problem is that the sun could explode before the GA finds the optimal solu-
tion. In general, you never know how long to run a GA. For the problems discussed in this
chapter, an optimal solution is usually found within five minutes or less, although timing
depends on the problem, and some experimentation is invariably necessary. Therefore, you
usually let Evolutionary Solver run for a few minutes and report the best solution found.
Unfortunately, you do not know if the best solution you have found is optimal, but it is usu-
ally a good solution—that is, very close to being optimal.
As a rule, GAs do very well in problems with few constraints (excluding bounds on
changing cells). In addition, the complexity of the objective cell does not bother a GA. For
example, a GA can easily handle MIN, MAX, IF, and ABS functions in spreadsheet mod-
els. This is the key advantage of GAs. On the other hand, GAs do not usually perform very
well on problems that have many constraints. For example, Simplex LP Solver has no
difficulty with the multiple-constraint linear models in Chapters 3 through 5, but GAs per-
form much more slowly on them.
8.3 INTRODUCTION TO EVOLUTIONARY SOLVER
GAs have been available for several years and have been implemented in several software
packages. However, they have been available as Excel add-ins only recently. In this chap-
ter, we use Evolutionary Solver developed by Frontline Systems and available as part of
Solver for Excel 2010. To get started with Evolutionary Solver, we examine a simple non-
linear function of a single variable.
426
Chapter 8
Evolutionary Solver: An Alternative Optimization Procedure
GAs have a particular
advantage on non-
smooth problems—
those with
discontinuities, for
example. However, they
are much less efficient
than traditional
algorithms such as
the simplex method
on “nice” problems.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

8.3 Introduction to Evolutionary Solver
427
E X A M P L E
8.1 MAXIMIZING A NONLINEAR FUNCTION WITH LOCAL MAXIMA
T
o see how Evolutionary Solver works, we consider a simple function that is difficult
for GRG Nonlinear Solver. This example, analyzed in Chapter 7, is a function of a sin-
gle variable x: f(x)  (x  1)(x  2)(x  3)(x  4)(x  5) for 1  x  5. The objective is
to maximize f(x) over this range. However, the graph of this function shown in Figure 8.2
indicates that there are two local maxima: one at around x  3.5 and the other at x  5. The
global maximum, the one we want, is near x  1.5. Can Evolutionary Solver find this
global maximum?
Funcon with local maxima
3
4
1
2
0
1
0
1
2
3
4
5
6
-2
-1
0
1
2
3
4
5
6
-3
-4
Objective
To illustrate how Evolutionary Solver works and to see how it can success-
fully find a global maximum for a function with several local maxima.
Solution
The model is particularly simple. (See Figure 8.3 and the file Local Maxima.xlsx.) To set
it up, enter any value in cell B5 (the only changing cell), enter the formula =B5-1 in cell
B6, copy this down to cell B10, and enter the formula =PRODUCT(B6:B10) in cell B11.
The objective is to maximize the value in cell B11 while constraining the value in cell B5
to be between 1 and 5.
1
2
3
4
5
6
7
8
9
10
11
A
B
C
D
Funcon with local maxima
The funcon is: y=(x-1)(x-2)(x-3)(x-4)(x-5)
x
1.355567
x-1
0.355567
x-2
-0.64443
x-3
-1.64443
x-4
-2.64443
x-5
-3.64443
Product
3.631432
Figure 8.3
Model for Evaluating
the Function
Figure 8.2
Function with
Local Maxima
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

If GRG Nonlinear Solver is used, the solution depends on the starting value in cell B6. If
this starting point is near 5, the Solver solution is 5, corresponding to the local maximum at
x  5. If the starting point is near 3.5, then the Solver solution is 3.54, corresponding to the
local maximum at x  3.54. Only if the starting point is sufficiently small does Solver cor-
rectly find the global maximum at x  1.356. This is disturbing. If you didn’t have a graph of
the function to lead you in the right direction, how would you know where to start? The
Multistart option discussed in the previous chapter is perfect for this type of problem with
multiple local maxima, but you can also use Evolutionary Solver, as discussed next.
USING EVOLUTIONARY SOLVER
Evolutionary Solver uses GAs to obtain “good” solutions. It begins with a population con-
taining, say, 100 sets of values—chromosomes—for the changing cells. For example, one
chromosome might be 3.778. (This would be coded in binary form by the algorithm.) This
chromosome represents the value of x in this example, but it generally represents a set of
values in the changing cells. Chromosomes that yield large objective values have more
chance of surviving to the next generation of chromosomes. Chromosomes that yield small
objective values have little chance of surviving to the next generation. Occasionally,
Evolutionary Solver drastically changes—mutates—the value of a changing cell. You usu-
ally stop Evolutionary Solver after a specified time period (such as one minute) or when
there has been no improvement in the objective cell value for a given amount of time. Here
is some general information about Evolutionary Solver:
■
Evolutionary Solver usually finds a good solution, but there is no guarantee that it
will find the best solution.
■
Evolutionary Solver is not very efficient at handling constraints. The best way to
handle constraints is to penalize a violation of a constraint. This is done by including
a numeric penalty as part of the objective. Penalties are not used in this example, but
they will be illustrated in a later example.
■
A good starting solution—the values you place in the changing cells—usually helps
Evolutionary Solver in its search for an optimal solution. However, the starting
solution is not absolutely critical to success.
■
Evolutionary Solver places more of a burden on you to specify certain parameters of
the algorithm. These parameters are specified in the Options dialog box, as will be
illustrated shortly. Unfortunately, these parameters are not very intuitive to most
users, and some experimentation is necessary to find the best settings of these para-
meters for any given model. Nevertheless, if you use the default settings or the set-
tings we suggest, they should work reasonably well.
■
Much of the solution process is driven by random numbers that direct the search.
Therefore, two people can get different solutions to the same problem. In fact, running
Evolutionary Solver a second time can possibly yield a different solution. You can set
a random seed parameter to ensure the same solution on two successive runs.
■
After Evolutionary Solver has found a good solution, you can use GRG Nonlinear
Solver to try to find a slightly better solution. If there is no improvement, you can prob-
ably infer that the solution found by Evolutionary Solver is optimal or close to optimal.
In general, use the following steps to implement Evolutionary Solver:
1
Open Solver. Open Solver in the usual way, from the Data ribbon.
2
Specify the objective cell, changing cells, and constraints. Do this in the usual way.
The only difference is that you should put lower and upper bounds on all changing cells—
in addition to any other constraints that might be in the model. 
428
Chapter 8
Evolutionary Solver: An Alternative Optimization Procedure
Evolutionary Solver
doesn’t handle con-
straints well. It is usu-
ally better to penalize
constraint violations
and include the penal-
ties in the objective.
Evolutionary Solver
uses random numbers
in its search; therefore,
two different runs
can lead to different
solutions.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

3
Select Evolutionary Solver. Click on the drop-down list of available algorithms to
select Evolutionary Solver (see Figure 8.4). This is the option used throughout this chapter,
but you can also experiment with GRG Nonlinear Solver, especially after Evolutionary
Solver finds a good solution.
8.3 Introduction to Evolutionary Solver
429
Figure 8.4
Selecting
Evolutionary Solver
Figure 8.5
Solver’s All Methods
Options
4
Solver Options. Click on the Options button and then the All Methods tab to see the
dialog box in Figure 8.5. The bottom section of this dialog box, relevant for all Solver algo-
rithms, allows you to change some limits to higher values. The main reason for doing so is
to keep Evolutionary Solver from repeatedly beeping at you as it reaches these limits.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Next, click on the Evolutionary tab to see the dialog box in Figure 8.6. These are the
settings that control Evolutionary Solver. The following information about them is
available in online help.
■
Convergence measures the rate of change of the objective. You can leave this at its
default value.
■
Mutation rate governs the frequency at which mutations are introduced into the pop-
ulation of solutions. Mutations shouldn’t be introduced too often, but by introducing
them every now and then, the GA gets a chance to explore a completely different
area of the feasible region. You can leave this setting at its default value (0.075), but
we have sometimes had success by increasing it to 0.25.
■
Population size is the number of candidate solutions (chromosomes) at any point in
time, and the default value of 100 should work well, although we sometimes increase
it to 150. Note that the initial population is chosen randomly, but it includes at least
one instance of the starting solution you specify in the changing cells.
■
Evolutionary Solver uses a random mechanism to perform its search, but you can
make it go through exactly the same calculations on two separate runs if you use the
same random seed (any integer) on each run. You can leave this box blank, in which
case Evolutionary Solver bases the seed on the system clock.
■
You should check the Require Bounds on Variables option. This forces you to enter
explicit upper and lower bounds on all changing cells, which aids Evolutionary
Solver in its search process.
■
Maximum Time without Improvement (measured in seconds) indicates the stopping
rule for the algorithm. If it doesn’t find a “meaningful” improvement in this amount
of time, it will stop and report the best solution so far.
430
Chapter 8
Evolutionary Solver: An Alternative Optimization Procedure
Figure 8.6
Solver’s
Evolutionary
Options
Some experimentation
with Evolutionary
Solver’s settings may
be necessary. No
single group of
settings works best on
every problem.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

5
Solve. Go back to the main Solver dialog box and click on Solve. You can watch
the progress of the solution process in the status bar of your screen. In particular, watch
the incumbent, which is the current best value of the objective cell. Typically, this value
decreases (for a minimization problem) rapidly at first, and then very slowly. If you sense
that it is going nowhere after a minute or two (and you are tired of waiting), you can press
the Esc key a few times to stop the process. (Don’t be impatient. Evolutionary Solver tends
to keep running for awhile even after you press Esc.) From there, you can either let the
process continue or accept the best solution to this point. Don’t be surprised if the solution
process takes much longer than you have experienced for Solver models in previous chap-
ters. GAs are not guaranteed to be fast, but they make up for it by being more flexible.
For this particular model, Evolutionary Solver gets to the solution shown earlier in
Figure 8.2 almost instantaneously. Then it runs for 30 seconds (the time specified in the
dialog box in Figure 8.6) without being able to find a better solution, at which time it
quits. Note that this solution is indeed the global optimal solution (refer to Figure 8.2),
and Evolutionary Solver finds it almost immediately, even when starting at a solution,
such as 3.5 or 4.9, that is close to a local but not global maximum. This is because
Evolutionary Solver looks all over the feasible region for potentially good solutions.
Therefore, Evolutionary Solver is not as likely to get stuck at a local optimum as GRG
Nonlinear Solver.
■
Limits on Changing Cells: Required?
In the Evolutionary Solver Options dialog box in Figure 8.6, we suggest checking the
Required Bounds on Variables box, which forces you to include constraints with lower and
upper bounds on the changing cells. Is it possible to leave this box unchecked and ignore
bounds on the changing cells? Evidently, the answer is yes, but it is not a good idea—the
GA will not work as well. Therefore, always check this box and always include bounds on
the changing cells in your list of constraints.
8.4 Nonlinear Pricing Models
431
If you sense that
Evolutionary Solver is
getting nowhere, press
the Esc key to stop it.
When using
Evolutionary Solver, it is
always a good idea to
add explicit upper-
bound and lower-
bound constraints on
the changing cells.
P R O B L E M S
Solutions for problems whose numbers appear within a
colored box can be found in the Student Solutions Files.
Refer to this book’s preface for purchase information.
Skill-Building Problems
1.
Modify the function in Example 8.1 so that it becomes
f(x)  (x1)(x2)(x3)(x 4)(x 5)(x 6)(x  7)
for 1  x  7. Plot a lot of points from 1 to 7 to see
what the graph of this function looks like. Then use
GRG Nonlinear Solver to find its maximum. Try the
following starting points (and don’t use the Multistart
option): 1, 3, 5, 6, and 6.9. Report what you find. Then
try Evolutionary Solver. Does it find the correct 
solution?
2.
Modify the function in Example 8.1 so that it becomes
f(x)  x sin(x) for 0  x  30. (Here, sin(x) is the sine
function from trigonometry. You can evaluate it with
Excel’s SIN function.) Plot a lot of points from 0 to 30
to see what the graph of this function looks like. Then
use GRG Nonlinear Solver to find its maximum. Try
the following starting points (and don’t use the
Multistart option): 1, 6, 15, 20, and 27. Report what
you find. Then try Evolutionary Solver. Does it find
the correct solution?
8.4 NONLINEAR PRICING MODELS
We examined several pricing models in the previous chapter. We now examine one more
such model, where customers of a certain product place less and less value on each suc-
ceeding item of the product. You will see that if the company selling the product sets a
constant price per item, it earns considerably less profit than if it uses a more imaginative
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

pricing scheme, called a two-part tariff. In this pricing scheme, each customer pays a
fixed amount each time she buys any amount of the product. In addition, she pays a vari-
able amount per item purchased.
432
Chapter 8
Evolutionary Solver: An Alternative Optimization Procedure
E X A M P L E
8.2 PRICING MENTHOS CANDY
S
uppose you sell Menthos candy. Most people value the first pack of Menthos they pur-
chase more than the second pack. They also value the second pack more than the third
pack, and so on. How can you take advantage of this when pricing Menthos? If you charge
a single price for each pack of Menthos, only a few people are going to buy more than one
or two packs. Alternatively, however, you can try the two-part tariff approach, where you
charge an “entry fee” to anyone who buys Menthos, plus a reduced price per pack pur-
chased. For example, if a reasonable single price per pack is $1.10, then a reasonable two-
part tariff might be an entry fee of $1.50 and a price of $0.50 per pack. This gives some
customers an incentive to purchase many packs of Menthos. Because the total cost of pur-
chasing n packs of Menthos is no longer a linear function of n—it is now piecewise
linear—the two-part tariff is a nonlinear pricing strategy.
As usual with pricing models, the key input is customer sensitivity to price. Rather
than having a single demand function, however, we now assume that each customer has a
unique sensitivity to price. To keep the example fairly small, we assume that four typical
customers from the four market segments for the product have been asked what they would
pay for each successive pack of Menthos, with the results listed in Figure 8.7. For example,
customer 1 is willing to pay $1.24 for the first pack of Menthos, $1.03 for the second pack,
and only $0.35 for the tenth pack. These four customers are considered representative of
the four market segments. If it costs $0.40 to produce a pack of Menthos, determine a
profit-maximizing single price and a profit-maximizing two-part tariff. Assume that the
four market segments have 10,000, 5000, 7500, and 15,000 customers, respectively, and
that the customers within a market segment all respond identically to price.
Piecewise linear
objectives, imple-
mented with IF logic,
are good candidates
for Evolutionary 
Solver.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
A
B
C
D
E
Pricing Menthos - single price model
Price sensivity of four types of customers
Price willing to pay (or marginal value of packs)
Pack #
Customer 1
Customer 2
Customer 3
Customer 4
1
1.24
0.92
1.27
1.49
2
1.03
0.85
1.11
1.24
3
0.89
0.69
0.96
1.10
4
0.80
0.58
0.85
0.97
5
0.77
0.50
0.73
0.81
6
0.66
0.43
0.63
0.71
7
0.59
0.36
0.51
0.63
8
0.51
0.32
0.45
0.53
9
0.42
0.26
0.39
0.42
10
0.35
0.22
0.32
0.35
Figure 8.7
Price Sensitivity of
Four Representative
Customers
Objective
To use Evolutionary Solver to find the best pricing strategies for customers
who value each succeeding unit of a product less than the previous unit.
WHERE DO THE NUMBERS COME FROM?
The price sensitivity data listed in Figure 8.7 would be the most difficult to find. However,
a well-studied technique in marketing research called conjoint analysis can be used to
estimate such data. See Green et al. (2001) for a nontechnical discussion of conjoint analysis.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Solution
You should first set up the single-price model. Then, with very little modification, you can
develop the two-part tariff model. The approach for each model is as follows.
For any pricing scheme, you need to calculate the customer’s cost if he purchases n
packs. Then you can compare this cost to the corresponding value in the appropriate col-
umn in Figure 8.7. As an example, suppose you charge a single price of $0.80 per pack. If
a customer of type 2 purchases three packs, the surplus value to this customer is the total
value to him of the three packs, $0.92  $0.85  $0.69  $2.46, minus the cost of the
packs, $2.40. Because the value is greater than the cost, a purchase of three packs is attrac-
tive to this customer. We assume that a customer of a given type will purchase the quantity
n that provides the largest surplus value. In simple terms, each customer buys the quantity
that provides the largest difference between value and cost. However, if a customer’s sur-
plus value is always negative, this customer won’t purchase any packs.
By knowing how many packs each customer segment will purchase at each price, you
can then maximize the company’s profit by setting the price accordingly.
DEVELOPING THE SINGLE-PRICE MODEL
The single-price model appears in Figure 8.8. (See the Single Price.xlsx file.) It can be
formed with the following steps:
8.4 Nonlinear Pricing Models
433
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
A
B
C
D
E
F
G
H
I
J
K
Pricing Menthos - single price model
Price sensivity of four types of
la
t
o
T
sr
e
m
o
ts
u
c
value of purchases
Price willing to pay (or marginal value of
la
t
o
T
)s
k
c
a
p
value from this many packs
Pack #
Customer 1
Customer 2
Customer 3
Customer 4
# of packs
Customer 1
Customer 2
Customer 3
Customer 4
1
1.24
0.92
1.27
1.49
1
1.24
0.92
1.27
1.49
2
1.03
0.85
1.11
1.24
2
2.27
1.77
2.38
2.73
3
0.89
0.69
0.96
1.10
3
3.16
2.46
3.34
3.83
4
0.80
0.58
0.85
0.97
4
3.96
3.04
4.19
4.80
5
0.77
0.50
0.73
0.81
5
4.73
3.54
4.92
5.61
6
0.66
0.43
0.63
0.71
6
5.39
3.97
5.55
6.32
7
0.59
0.36
0.51
0.63
7
5.98
4.33
6.06
6.95
8
0.51
0.32
0.45
0.53
8
6.49
4.65
6.51
7.48
9
0.42
0.26
0.39
0.42
9
6.91
4.91
6.90
7.90
10
0.35
0.22
0.32
0.35
10
7.26
5.13
7.22
8.25
Unit
0
4.0
$
ts
o
c
Total cost of packs
Surplus (value minus cost) from purchasing
# of packs
Cost
# of packs
Customer 1
Customer 2
Customer 3
Customer 4
Unit
9
6.0
7
4.0
2
1.0
4
4.0
1
0
8.0
1
0
8.0
$
e
cir
p
2
1.60
2
0.67
0.17
0.78
1.13
3
2.40
3
0.76
0.06
0.94
1.43
4
3.20
4
0.76
-0.16
0.99
1.60
5
4.00
5
0.73
-0.46
0.92
1.61
6
4.80
6
0.59
-0.83
0.75
1.52
7
5.60
7
0.38
-1.27
0.46
1.35
8
6.40
8
0.09
-1.75
0.11
1.08
9
7.20
9
-0.29
-2.29
-0.30
0.70
10
8.00
10
-0.74
-2.87
-0.78
0.25
Customer behavior
Range names used:
Customer 1
Customer 2
Customer 3
Customer 4
Proﬁt
=Model!$B$37
Max surplus
0.76
0.17
0.99
1.61
Unit_cost
=Model!$B$17
# purchased
4
2
4
5
Unit_price
=Model!$B$19
Market size (1000s)
10
5
7.5
15
Total purchased (1000s)
155
Proﬁt ($1000s)
62.000
Figure 8.8
Single-Price Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

1
Inputs. Enter the inputs in the blue ranges. Note that the large blue range is the price
sensitivity table from Figure 8.7.
2
Price. The only decision variable in this model is the single price charged for every
pack of Menthos sold. Enter any value in this Unit_price cell.
3
Total value table. The values in the shaded price sensitivity range are marginal val-
ues, the most each customer would pay for the next pack of Menthos. In the range H6:K15,
calculate the total value of n packs for each customer (for n from 1 to 10). First, enter the
formula
=B6
in cell H6 and copy it across row 6. Then enter the formula
=H6+B7
in cell H7 and copy it to the range H7:K15.
4
Total cost column. Using the single-price scheme, each customer must pay np for n
packs if the price is p. Calculate these amounts in the range E19:E28 by entering the
formula
=Unit_price*D19
in cell E19 and copying down.
5
Surplus table. This is the key to the model. You need to calculate the surplus for any
customer from buying n packs as the total value of n packs minus the total cost of n packs,
and you assume that the customer buys the number of packs with the largest surplus. This
makes sense economically. If a customer places more value on n packs than it costs to buy n
packs, then presumably the customer will consider purchasing n packs. But a customer will
not purchase n packs if they cost more than she values them. To calculate these surplus
values, enter the formula
=H6-$E19
in cell H19 and copy it to the range H19:K28.
6
Maximum surplus. Calculate the maximum surplus for each customer by entering the
formula
=MAX(H19:H28)
in cell B32 and copying it across row 32.
7
Packs purchased. For each customer, you need to find the number of packs that cor-
responds to the maximum surplus. This can be done best with Excel’s MATCH function.
Specifically, enter the formula
=IF(B32<0,0,MATCH(B32,H19:H28,0))
in cell B33 and copy it across row 33. This formula says that if the maximum surplus is nega-
tive, the customer will not purchase any packs at all. Otherwise, it matches the maximum
surplus to the entries in the range H19:H28 and returns the index of the cell where the match
occurs. In this example, the match for customer 1 occurs in the fourth cell of the range
H19:H28, so the MATCH function returns 4. (Note that the last argument of the MATCH
function is 0 if you want an exact match, as you do here.) Then calculate the total number of
packs purchased by all customers with the formula
=SUMPRODUCT(B34:E34,B33:E33)
in cell B36.
434
Chapter 8
Evolutionary Solver: An Alternative Optimization Procedure
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Excel Function: MATCH
The MATCH function, with the syntax MATCH(Value,Range,Type), returns the position (as
an integer) of the first match to Value in the given Range. For example, if Value is 6 and the
values in the given Range are 8, 7, 6, 5, 6, 5, 8, the MA TCH function returns 3. The Type
argument is usually set to 0, whic h returns an e xact match. Other options for the Type
parameter can be found in Excel’s online help.
8
Profit. Calculate the profit in cell B37 with the formula
=(Unit_price-Unit_cost)*B36
USING EVOLUTIONARY SOLVER
First, note that GRG Nonlinear Solver has trouble with this model because of the MAX, IF,
and MATCH functions. However, these functions present no difficulties to Evolutionary
Solver. It should be set up as shown in Figure 8.9, using the same values for the
Evolutionary options as in the previous example. Note that an upper limit of $1.50 has
been used for the unit price. This suffices because the most any customer will pay for any
pack of Menthos is $1.49.
8.4 Nonlinear Pricing Models
435
Figure 8.9
Solver Dialog Box
for the Single-Price
Model
Discussion of the Solution
Again, Evolutionary Solver converges to the solution in Figure 8.8 quickly and then tries
for a long time—unsuccessfully—to find a better solution. You can be fairly certain that
this solution is optimal, but this is not guaranteed. The single price of $0.80 produces a
profit of $62,000. It strikes the best balance for these four market segments. A lower price
would needlessly sacrifice revenue, whereas a higher price would cause at least one market
segment to buy fewer packs.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

DEVELOPING THE TWO-PART TARIFF MODEL
The two-part tariff model is so similar that you can make a copy of the Single Price.xlsx
file and then make the following modifications. (See Figure 8.10 and the Two-Part
Tariff.xlsx file.) The steps that are the same as before are omitted.
1
Decision variables. Now there are two decision variables—the fixed entry fee and
the variable cost per pack. Enter any values for these in cells B20 and B21.
2
Total cost column. The total cost of purchasing n packs is now the fixed entry fee plus
the variable cost times n. Calculate this in the range E19:E28 by entering the formula
=Fixed_price+Variable_price*D19
in cell E19 and copying it to the rest of the range.
3
Revenues. Calculate the amount paid by the customers in row 34 by entering the
formula
=IF(B33>0,Fixed_price+Variable_price*B33,0)
in cell B34 and copying it across. Note that the entry fee is evidently too high for customer
2, so she does not purchase any packs, and there is no corresponding revenue.
4
Profit. Calculate the profit in the Profit cell with the formula
=SUMPRODUCT(B34:E34:B35:E35)-Unit_cost*B37
The Evolutionary Solver setup is almost the same as before. However, you should now
select both the Fixed_price and Variable_price cells as changing cells, and you should put
upper limits on each of them, as shown in Figure 8.11. (We used $10 as an upper limit on
Fixed_price and $1.50 for Variable_price, reasoning that these would almost certainly be
large enough.)
436
Chapter 8
Evolutionary Solver: An Alternative Optimization Procedure
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
A
B
C
D
E
F
G
H
I
J
K
C
Pricing Menthos - two-part tariﬀmodel
Price sensivity of four typical
la
t
o
T
sr
e
m
o
ts
u
c
value of purchases
Price willing to pay (or marginal value of
la
t
o
T
)s
k
c
a
p
value from this many packs
Pack #
Customer 1
Customer 2
Customer 3
Customer 4
# of packs
Customer 1
Customer 2
Customer 3
Customer 4
1
1.24
0.92
1.27
1.49
1
1.24
0.92
1.27
1.49
2
1.03
0.85
1.11
1.24
2
2.27
1.77
2.38
2.73
3
0.89
0.69
0.96
1.10
3
3.16
2.46
3.34
3.83
4
0.80
0.58
0.85
0.97
4
3.96
3.04
4.19
4.80
5
0.77
0.50
0.73
0.81
5
4.73
3.54
4.92
5.61
6
0.66
0.43
0.63
0.71
6
5.39
3.97
5.55
6.32
7
0.59
0.36
0.51
0.63
7
5.98
4.33
6.06
6.95
8
0.51
0.32
0.45
0.53
8
6.49
4.65
6.51
7.48
9
0.42
0.26
0.39
0.42
9
6.91
4.91
6.90
7.90
10
0.35
0.22
0.32
0.35
10
7.26
5.13
7.22
8.25
Unit
0
4.0
$
ts
o
c
Total cost of packs
Surplus (value minus cost) from purchasing
# of packs
Cost
# of packs
Customer 1
Customer 2
Customer 3
Customer 4
Price parameters
1
3.70
1
-2.46
-2.78
-2.43
-2.21
Fixed
2
0
1.4
2
0
3.3
$
e
cir
p
-1.83
-2.33
-1.72
-1.37
Variable price
$0.40
3
4.50
3
-1.34
-2.04
-1.16
-0.67
4
4.90
4
-0.94
-1.86
-0.71
-0.10
5
5.31
5
-0.58
-1.77
-0.39
0.30
6
5.71
6
-0.32
-1.74
-0.16
0.61
7
6.11
7
-0.13
-1.78
-0.05
0.84
8
6.51
8
-0.02
-1.86
0.00
0.97
9
6.91
9
0.00
-2.00
-0.01
0.99
10
7.31
10
-0.05
-2.18
-0.09
0.94
Customer behavior
Range names used:
Customer 1
Customer 2
Customer 3
Customer 4
Fixed_price
=Model!$B$20
Max
0
0.0
s
ulp
r
u
s
-1.74
0.00
0.99
Proﬁt
=Model!$B$38
# purchased
9
0
8
9
Unit_cost
=Model!$B$17
Amount paid
6.910
0.000
6.509
6.910
Variable_price
=Model!$B$21
Market size (1000s)
10
5
7.5
15
Total purchased (1000s)
285
Proﬁt ($1000s)
107.567
Figure 8.10
Two-Part Tariff Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Discussion of the Solution
The solution in Figure 8.10 was found after about a minute. The solution indicates that
the company should charge all customers $3.30 plus $0.40 for each pack purchased.
This pricing scheme is too high for the second market segment, which doesn’t buy any
packs, but it entices segments 1, 3, and 4 to purchase many more packs than they pur-
chased with the single price of $0.80. (Check the price sensitivity columns for these
segments. Can you see why they are willing to purchase so many packs with this partic-
ular two-part tariff?) More important, it yields a profit of $107,567, about 73% more
than the profit from the single-price policy. The moral is clear—clever pricing schemes
can make companies significantly larger profits than the simple pricing schemes that are
typically used.
■
Other Forms of Nonlinear Pricing
There are many other forms of nonlinear pricing, such as the following:
■
Sell only single-item packs or packs with six items.
■
Charge one price for the first n packs and another price for the rest.
With Evolutionary Solver, it is easy to experiment with these types of nonlinear
pricing schemes and determine the profit earned by each of them. For example, if you
allow Menthos to be sold only in a one-pack or a six-pack, it turns out that you can earn a
profit of $97,175 by charging $5.39 for a six-pack and virtually any price for a one-pack.
Then you will sell three customer segments a six-pack and make $5.39  $2.40  $2.99
per customer. Similarly, the best form of the “charge one price for first n packs and another
price for remaining packs” scheme (where n is also a decision variable) is to sell up to four
packs at $1.28 and $0.40 for each additional pack. See the book by Dolan and Simon
(1996) for further discussion and applications of pricing models.
8.4 Nonlinear Pricing Models
437
Figure 8.11
Solver Dialog Box
for Two-Part Tariff
Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

8.5 COMBINATORIAL MODELS
Consider the following situations:
■
Xerox must determine where to place maintenance facilities. The more maintenance
facilities selected, the more copiers the company will sell due to better availability
of maintenance. How can the company locate maintenance facilities to maximize
total profit?
■
A gasoline company is loading three different products on a tanker truck with five
compartments. Each compartment can handle at most one product. How should the
company load the truck to come as close as possible to meeting its delivery
requirements?
■
Fox has 30 different ads of different lengths that must be assigned to 10 different 
two-minute commercial breaks. How should the company assign ads to maximize its
total ad revenue?
■
John Deere must schedule its production of lawn mowers over the next four weeks.
The company wants to meet its forecasted demands, keep production hours fairly
constant from week to week, and avoid model changeovers as much as possible. How
should the company schedule its production?
Each of these problems is a combinatorial optimization problem that requires a com-
pany to choose the best of many different combinations available. Although combinatorial
optimization problems can often be handled as Solver models with 0–1 changing cells, it is
often difficult to develop the constraints in a way that keeps the model linear. (You saw
examples of the tricks required in Chapter 6.) With Evolutionary Solver, however, 
it doesn’t matter whether the constraints or the objective are linear. The SUMIF and
COUNTIF functions are often useful in such problems. The two examples in this section
illustrate typical combinatorial optimization problems.
Loading Products on a Truck
The following example might appear simple when you first read it, but it is not. The num-
ber of possible solutions is enormous, and it can take a Solver, even Evolutionary Solver, a
long time to find an optimal (or nearly optimal) solution.
438
Chapter 8
Evolutionary Solver: An Alternative Optimization Procedure
Combinatorial problems
have only a finite num-
ber of feasible solutions.
However, they can still
be very difficult because
this finite number is
often enormous.
P R O B L E M S
Skill-Building Problems
3.
In Example 8.2, determine the best pricing policy if
quantity discounts with a single-price breakpoint are
used.
4.
In Example 8.2, determine the optimal pricing policy
if Menthos are sold in only a one-pack or a six-pack.
5.
Based on Schrage (1997). The file P08_05.xlsx lists
the size of the four main markets for Excel, Word, and
the bundle of Excel and Word. (We assume that
Microsoft is willing to sell Excel or Word separately,
and it is willing to sell a package with Excel and Word
only.) It also shows how much members of each group
are willing to pay for each product combination. How
can Microsoft maximize the revenue earned from
these products? You should consider the following
options:
■
No bundling, where Word and Excel are sold
separately
■
Pure bundling, where purchasers can buy only
Word and Excel together
■
Mixed bundling, where purchasers can buy Word
or Excel separately, or they can buy them as a
bundle
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

8.5 Combinatorial Models
439
E X A M P L E
8.3 LOADING A GAS STORAGE TRUCK
A
gas truck contains five compartments with the capacities listed in Table 8.1. Three
products must be shipped on the truck, and there can be only one product per com-
partment. The demand for each product, the shortage cost per gallon, and the maximum
allowable shortage for each product are listed in Table 8.2. How should the truck be loaded
to minimize the shortage costs?
Table 8.1
Truck Capacities
Compartment
Capacity (Gallons)
1
2700
2
2800
3
1100
4
1800
5
3400
Table 8.2
Demand and Shortage Data
Product
Demand
Max Shortage Allowed
Cost per Gallon Short
1
2900
900
$10
2
4000
900
$8
3
4900
900
$6 
Objective
To use Evolutionary Solver to find the combination of products to load in
compartments that minimizes the total shortage cost.
WHERE DO THE NUMBERS COME FROM?
The data would be based on the truck dimensions and presumably on contracts the com-
pany has with its customers.
Solution
The objective in this problem is to minimize the total shortage cost. The decision variables
indicate the type of product stored in each compartment and the amount of that product to
load in the compartment. The constraints must ensure that no compartment is overfilled
and that the maximum allowable shortage is not exceeded.
DEVELOPING THE SPREADSHEET MODEL
The completed model appears in Figure 8.12. (See the file Loading Truck.xlsx.) It can be
developed as follows:
1
Inputs. Enter the inputs from Tables 8.1 and 8.2 into the shaded ranges.
2
Decision variables. Enter any integer values (from 1 to 3) in the Product range and
any values (integer or noninteger) in the Amount range. These two ranges represent the
changing cells.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

3
Amounts stored total. To calculate the gallons of each product stored on the truck
from the values in the changing cells, you can use the SUMIF function. Specifically, enter
the formula
=SUMIF(Product,A21,Amount)
in cell B21. This formula sums the values in the Amount range for all rows where the prod-
uct index, 1, in cell A21 matches the index in the Product range. Therefore, it calculates the
total amount of product 1 stored on the truck. Copy this formula down for the other two
products.
4
Shortages. To calculate the shortages, enter the formula
=IF(B21<C21,C21-B21,0)
in cell D21 and copy it down. Note that shortages were discussed in previous chapters, but
they always required some tricks to keep the models linear. Now you can use straight-
forward IF functions, which present no difficulty for Evolutionary Solver.
5
Shortage violations. You could constrain the shortages to be less than the maximum
allowable shortages, but because the Evolutionary Solver works best with as few con-
straints as possible, there is a better approach. (This approach is used in the following
example as well.) You can calculate the amount by which each maximum storage con-
straint is violated (if at all) and then add these violations, multiplied by a suitably large
penalty, to the cost objective. Because the objective is to minimize total cost, Evolutionary
Solver tries to stay away from solutions where this penalty is positive. Therefore, it favors
solutions where the maximum storage constraints are satisfied. To implement this strategy,
calculate the maximum storage violations in column F by entering the formula
=IF(D21>E21,D21-E21,0)
440
Chapter 8
Evolutionary Solver: An Alternative Optimization Procedure
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
A
B
C
D
E
F
G
H
I
Storing gas products in compartments
Unit shortage costs and penalty cost for violang shortage 
e
g
n
a
R
st
nia
rts
n
o
c
 names used
1
$
C
$:3
1
$
C
$
!le
d
o
M
=
t
n
u
o
m
A
n
olla
g
/ts
o
C
tc
u
d
o
r
P
7
tic
a
p
a
C
0
0.0
1
$
1
y
=Model!$E$13:$E$17
7
1
$
B
$:3
1
$
B
$
!le
d
o
M
=
tc
u
d
o
r
P
0
0.8
$
2
8
2
$
B
$
!le
d
o
M
=
ts
o
c
_la
t
o
T
0
0.6
$
3
Shortage penalty
$100
Storing decisions
Compartment
Product
Amount
Capacity
1
2
2700.0
<=
2700
2
1
2800.0
<=
2800
3
2
1100.0
<=
1100
4
3
1677.8
<=
1800
5
3
3400.0
<=
3400
Shortages
Product
Amount Stored
Demand
Shortage
Max Shortage
Shortage Violaon
1
2800.0
2900
100.0
900
0.0
2
3800.0
4000
200.0
900
0.0
3
5077.8
4900
0.0
900
0.0
Costs and penales
Shortage cost
$2,600.00
Penalty cost
$0.00
Total cost
$2,600.00
Figure 8.12
Truck Loading Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

in cell F21 and copying it down. The solution shown in Figure 8.12 does not have any vio-
lations, but the values in column F would be positive if any shortages in column D were
greater than 900.
6
Costs. Calculate the total shortage cost in cell B26 with the formula
=SUMPRODUCT(B5:B7,D21:D23)
Then calculate the penalty cost from maximum shortage violations in B27 with the formula
=B9*SUM(F21:F23)
Note that a penalty of $100 per unit shortage above the maximum allowed was chosen. Any
large dollar value would suffice here. Finally, calculate the total cost in cell B28 by sum-
ming the values in cells B26 and B27.
USING EVOLUTIONARY SOLVER
The Solver setup for this model is straightforward, as shown in Figure 8.13. Unlike some
previous models, there are now natural lower limits and upper limits for the changing cells.
The Product range must be between 1 and 3 (and they must be integers) because there are
only three products. The Amount range must be between 0 and the given capacities of the
compartments.
Discussion of the Solution
The solution in Figure 8.12 shows that product 1 should be stored in compartment 2, prod-
uct 2 should be stored in compartments 1 and 3, and product 3 should be stored in com-
partments 4 and 5, the only compartments that end up with excess capacity. The demands
for products 1 and 2 are not quite met, and the total shortage cost is $2600, but the short-
ages are well below the maximum shortages allowed. Therefore, there is no penalty cost
for violating the maximum shortage constraints.
8.5 Combinatorial Models
441
This example illus-
trates how violations 
of constraints can be
incorporated into the
objective in the form
of penalties.
Figure 8.13
Solver Dialog Box
for the Truck
Loading Model
This model is not easy for Evolutionary Solver, in spite of its rather small size, and its
success depends a lot on the starting solution. For example, we tried one solution with all
3s in the Product range and all 1000s in the Amount range. It got to a solution with objec-
tive value $3200 fairly quickly, but then it spun its wheels for a long time and never
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

improved. In contrast, when we entered a random combination of 1, 2, and 3 in the Product
range and all 0s in the Amount range, the optimal solution was found very quickly.
Sensitivity Analysis with SolverTable
Nothing prevents you from using SolverTable on an Evolutionary Solver model—except
time. You fill in the SolverTable dialog box exactly as before. The only difference is that
Evolutionary Solver can take a lot of time to solve one problem, let alone a whole series of
problems. Also, to provide some assurance that it does not stop prematurely at a subopti-
mal solution for at least one of the problems, you need to experiment with the Evolutionary
Solver settings in the Options dialog boxes, because the appropriate settings are not always
obvious.
We tried a sensitivity analysis on the capacity of compartment 3 for this example,
allowing it to vary from 300 to 1100 in multiples of 200, and we obtained the results in
Figure 8.14. We are not really sure whether these results are optimal. (The equal objective
values for capacities of 700 and 900 are somewhat suspicious.) However, we ran this same
SolverTable several times, with different Solver option settings and different starting solu-
tions, and we usually obtained worse results than in Figure 8.14 on at least one problem.
This is not the fault of SolverTable or even the fault of Evolutionary Solver. This storage
problem, like many combinatorial problems, is difficult, and unless Evolutionary Solver is
allowed to run for a very long time, it can easily get stuck at a suboptimal solution fairly far
from the optimal solution. For this reason, we do not mention SolverTable again in this
chapter, but there is nothing to prevent you from trying it. You just need to be patient. 
442
Chapter 8
Evolutionary Solver: An Alternative Optimization Procedure
30
31
32
33
34
35
36
37
A
B
C
D
E
F
G
H
I
J
K
L
Sensivity of soluon to capacity of compartment 3
$B$13
$C$13
$B$14
$C$14
$B$15
$C$15
$B$16
$C$16
$B$17
$C$17
$B$28
300
3
2700.0
1
2800.0
2
300.0
3
1800.0
2
3392.5 $5,860.33
500
3
2700.0
1
2800.0
2
500.0
3
1800.0
2
3400.0 $4,200.00
700
3
2700.0
1
2800.0
2
669.5
3
1800.0
2
3400.0 $3,400.00
900
3
2700.0
1
2800.0
2
669.5
3
1800.0
2
3400.0 $3,400.00
1100
2
2700.0
1
2800.0
2
1100.0
3
1800.0
3
3399.1 $2,600.00
Figure 8.14
SolverTable Results for the Truck Loading Model
■
Finding a Good Production Schedule
Determining a monthly production schedule at a manufacturing facility such as a John
Deere manufacturing plant is very difficult. Many conflicting objectives must be balanced.
The following example illustrates how these competing objectives can be modeled.2
E X A M P L E
8.4 SCHEDULING PRODUCTION OF LAWN MOWERS AT EASYRIDE
E
asyRide, a lawn mower manufacturer, needs to set its weekly production schedule for
the next four weeks. The company produces seven models of lawn mowers. At the
beginning of each month, the company has reasonably accurate forecasts for the demand
of each model for the month. It also has forecasts for the portion of this demand from
customers who will drive to the plant to pick up their lawn mowers. The company has four
competing objectives regarding its production schedule.
■
Avoid costly model changeovers during each week as much as possible.
2This example is based on a model actually developed by John Deere, as described to the authors by John Deere
managers.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

■
Come as close as possible to producing the mowers demanded by customers during
week 1 (assuming the “pickup” customers, those who drive to the plant to pick up
their mowers, typically arrive during week 1).
■
Keep weekly production hours as constant as possible across weeks at each of the
three machining centers that the models go through.
■
Come as close as possible to producing as many mowers of each model as its
monthly forecasts require.
Objective
To use Evolutionary Solver to find a production schedule that achieves the
company’s goals as fully as possible.
WHERE DO THE NUMBERS COME FROM?
As in other production scheduling models we have discussed, the most crucial inputs are
the demand forecasts. The company presumably has a method for forecasting demands,
probably based on historical data and orders already on the books.
Solution
It is typically not possible to satisfy all of EasyRide’s objectives. Therefore, think of the
objectives as targets. If any solution falls short of the target, it is penalized—the farther
from the target, the larger the penalty. This is an especially useful technique when using
Evolutionary Solver, which thrives on messy objective functions but does less well with a
lot of constraints. Therefore, instead of using constraints, the deviations from targets are
penalized, and the objective to minimize is the total of the penalties.
The data for the problem appear in Figure 8.15 (see the file Lawnmower
Production.xlsx). Rows 5 and 6 indicate the forecasts of customer pickups and monthly
totals, and rows 10 through 12 indicate the number of hours required at each machine cen-
ter to produce a mower of each model. The unit penalty costs in rows 15 to 18 are not
really “givens.” They must be estimated by EasyRide to reflect trade-offs among the com-
peting objectives. They imply the following:
■
A changeover penalty of 200 is incurred for each model produced at any positive
level during a week. For example, if 3 models are produced the first week, 4 the
second, 3 the third, and 5 the fourth, the total changeover penalty is (3  4  3  5)
(200)  3000.
8.5 Combinatorial Models
443
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
A
B
C
D
E
F
G
H
Lawnmower producon model
Forecasts of demand
Model 1
Model 2
Model 3
Model 4
Model 5
Model 6
Model 7
2
1
2
1
3
2
0
3
5
1
0
2
0
3
s
p
u
k
ciP
0
8
0
6
0
8
5
1
1
0
0
1
0
9
0
1
1
la
t
o
T
Hours per mower required in the machine centers
Model 1
Model 2
Model 3
Model 4
Model 5
Model 6
Model 7
Center 
2
4
2
2
2
2
3
1
Center 
4
3
3
3
1
2
1
2
Center 
2
3
3
4
0
3
2
3
Unit penalty 
e
g
n
a
R
"
sts
o
c
"
 names used:
Model changeover
200
Producon
=Sheet1!$B$22:$H$25
Sasfy pickups
50
Total_penalty
=Sheet1!$B$46
Smooth producon
1
Meet forecasts
10
Figure 8.15
Inputs for the Lawn
Mower Production
Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

■
A pickup shortage penalty of 50 is incurred for each unit of pickup demand not satis-
fied during week 1. For example, if 20 units of model 1 are produced during week 1,
the pickup penalty for this model is (10)(50)  500 because 20 is 10 short of the
required 30.
■
A smoothing production penalty of 1 is incurred during each week at each machine
center per hour of deviation from the required weekly average at that center. Here,
the required weekly average is based on the production levels needed to meet
monthly forecasts. Their implementation will be explained shortly.
■
A meeting monthly forecasts penalty of 10 is incurred per unit of each model
produced above or below the monthly forecast. For example, if the total monthly
production of model 1 is 105 or 115 (a deviation of 5 below or 5 above the monthly
forecast), the penalty in either case is (5)(10)  50.
Again, these unit penalties are not givens, and they must be chosen carefully by
EasyRide, perhaps on the basis of a sensitivity analysis. Clearly, if one unit penalty is too
large, its corresponding objective tends to dominate the solution. In the same way, if a unit
penalty is too small, its corresponding objective is practically ignored. We have tried to
choose unit penalties that produce a reasonable solution, but you might want to experiment
with others.
DEVELOPING THE SPREADSHEET MODEL
The completed model appears in Figure 8.16. It can be developed with the following steps:
1
Production schedule. The decision variables are the weekly production levels of
each model. Enter any values for these in the Production range. (Refer to Figure 8.15 for
range names used.)
444
Chapter 8
Evolutionary Solver: An Alternative Optimization Procedure
The IF logic required
to implement penal-
ties of these types
makes the model
nonsmooth.Therefore,
such models are
perfect candidates for
Evolutionary Solver.
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
A
B
C
D
E
F
G
H
I
J
K
Weekly producon levels
Model 1
Model 2
Model 3
Model 4
Model 5
Model 6
Model 7
Models
Week 
7
4
1
4
1
9
2
0
3
9
1
1
2
1
3
1
Week 
3
0
0
0
2
4
1
8
9
6
0
2
Week 
3
2
3
0
1
5
0
0
0
9
7
3
Week 
3
4
3
6
4
0
3
4
0
0
0
4
Mowers produced
110
90
100
115
80
60
80
Deviaons from forecasts
0
0
0
0
0
0
0
Shortages for pickups
0
0
0
0
0
0
0
Average hours need per week to meet monthly forecasts
Center 
5
7
3
1
Center 
5
7.8
6
3
2
Center 
5.2
8
3
3
Hours used each week in each 
s
n
oit
aiv
e
D
r
e
t
n
e
c
 from hourly targets
Week 1
Week 2
Week 3
Week 
k
e
e
W
4
 1
Week 2
Week 3
Week 4
Center 
r
e
t
n
e
C
8
3
3
3
0
4
4
8
3
5
7
3
1
 1
0.00
9.00
28.00
37.00
Center 
r
e
t
n
e
C
3
0
4
0
6
3
5
4
3
7
6
3
2
 2
1.75
23.75
8.75
34.25
Center 
r
e
t
n
e
C
8
7
3
5
7
3
5
7
3
2
0
4
3
 3
19.50
7.50
7.50
4.50
Penalty costs
Model changeover
3200
Sasfy 
0
s
p
u
k
cip
Smooth producon
182
Meet forecasts
0
Total penalty
3382
300
350
400
450
Week 1
Week 2
Week 3
Week 4
Producon Hours
Producon Hours across Weeks
Center 1
Center 2
Center 3
Figure 8.16
Lawn Mower Production Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

2
Models produced. To calculate the number of different models produced each week
(which are needed for the model changeover objective), enter the formula
=COUNTIF(B22:H22,">0")
in cell I22 and copy it down.
3
Deviations from forecasts. To calculate the total monthy production levels for each
model and see how much they deviate from the monthly forecasts, enter the formulas
=SUM(B22:B25)
and
=ABS(B6-B26)
in cells B26 and B27 for model 1, and copy these across for the other models. (Recall that
ABS is Excel’s absolute value function.)
4
Pickup shortages. To see how much week 1 production of each model is short (if
any) of the pickup demand, enter the formula
=IF(B22<B5,B5-B22,0)
in cell B28 and copy it across.
5
Hourly smoothing. This is the trickiest objective. The production hours at each
machine center should remain as constant as possible across weeks. Although there are
undoubtedly other ways to implement this, we suggest the following approach. First,
calculate the weekly average hours required at each machine center if the company pro-
duces exactly enough in the month to meet monthly forecasts. To do this, enter the
formula
=SUMPRODUCT($B$6:$H$6,B10:H10)/4
in cell B31 for center 1 and copy it down for the other two centers. (Note that division by 4
is used to obtain a weekly average.) These weekly averages become the targets. Next, cal-
culate the actual hours used at each center each week in the range B37:E39. Unfortunately,
there is no way to enter a single formula and then copy it to the rest of the range. However,
you can try the following. Enter the formula
=SUMPRODUCT($B$22:$H$22,$B10:$H10)
in cell B37 and copy it down to cell B39. Then copy the range B37:B39 to the range
C37:E39. The resulting formulas for weeks 2 to 4 in columns C to E will not be quite
correct, but you can modify them easily. Specifically, change each 22 in the column C
formulas to 23, to 24 in column D, and to 25 in column E. The point is that when copying
is not possible, sometimes copying a formula and then modifying it is easier than entering
new formulas from scratch. Finally, calculate the deviations from targets in the range
H37:K39 by entering the formula
=ABS(B37-$B31)
in cell H37 and copying it to the rest of the range. (Here, copying is possible.)
6
Penalties. Calculate the various penalties in the range B42:B45 with the formulas
=B15*SUM(122:125)
=B16*SUM(B28:H28)
=B17*SUM(H37:K39)
8.5 Combinatorial Models
445
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

and
=B18*SUM(B27:H27)
Then calculate the total penalty as their sum in cell B46.
USING EVOLUTIONARY SOLVER
The Solver setup for this model appears in Figure 8.17. The objective is to minimize the
total of penalties, the changing cells are the production levels, and there are no constraints
other than lower and upper bounds and integer constraints on the production levels. As for
the upper bounds, 150 is fairly arbitrary. The largest monthly forecast for any model is 115,
but the company might want production to exceed this forecast. Therefore, you can build in
some “padding” with the upper limit of 150.
446
Chapter 8
Evolutionary Solver: An Alternative Optimization Procedure
Figure 8.17
Solver Setup for the
Lawn Mower
Production Model
After some experimenting, you will see that this is a difficult problem even for
Evolutionary Solver. Depending on the starting solution, it can take some time to find as
good a solution as the one in Figure 8.16. Therefore, it helps to enter large values in the
Solver Options dialog boxes for Max Time, Max Subproblems, Max Feasible Solutions, and
Maximum Time without Improvement (this latter setting under the Evolutionary tab).
Otherwise, Evolutionary Solver might quit prematurely at a solution far from optimal.
Another possible strategy is to drop the integer constraint by checking the box in Figure 8.18.
This will find a “good” noninteger solution relatively quickly. Then you can run the Solver
again, starting from this noninteger solution, with the box unchecked to find a good integer
solution.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Discussion of the Solution
The solution in Figure 8.16 represents the best compromise we could find. It produces all
seven models during week 1 to keep the pickup shortages low. In fact, it has no pickup
shortages. After that, it produces only three separate models each week to keep the
changeover penalties low. This solution produces exactly to the monthly forecasts. Finally,
all of this is done in a way to keep the production hours as constant as possible across
weeks. Even so, the chart in Figure 8.16, based on the data in the range B37:E39, shows
that the production hours still vary to some extent across weeks at each machine center. Of
course, if you change the unit penalties to reflect different priorities on the objectives and
then rerun Evolutionary Solver, you could get a much different solution. For example, if
EasyRide decides that pickup shortages are not such an important concern, it could reduce
the unit shortage penalty from 50 to, say, 25 or even 5. Then the production schedule might
change so that all seven models are not produced in week 1.
■
8.5 Combinatorial Models
447
Figure 8.18
Option to Ignore
Integer Constraints
P R O B L E M S
Skill-Building Problems
6.
In the truck-loading problem in Example 8.3, we
assumed that any product could be loaded into any
compartment. Suppose the following are not allowed:
product 1 in compartment 2, product 2 in compartment 1,
and product 3 in compartment 4. Modify the model
appropriately, and then use Evolutionary Solver to find
the new optimal solution. (Hint: Add a penalty to the
objective for violating these new constraints.)
7.
In the lawn mower production problem in Example 8.4,
the model changeover cost dominates in the optimal
objective value. Is this because we assumed such a
large unit penalty cost, 200, for each model
changeover? Explore this question by changing this
unit penalty cost to lower values such as 100 and 50 (or
even smaller). What happens to the optimal solution?
8.
In the lawn mower production problem in Example 8.4,
experiment with the penalty cost for unsatisfied pick-
ups in week 1. If this cost is sufficiently small, does
the company ever produce fewer than seven models 
in week 1 and allow some week 1 pickups to be 
unsatisfied?
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

8.6 FITTING AN S-SHAPED CURVE
Suppose a company wants to see how its revenue from sales is related to its sales force
effort. If R is revenue and E is sales force effort, marketing researchers have found that
the relationship between R and E is often well described by a function of the following
form:
R  a  
(b
d


a
E
)E
c
c

(8.1)
for suitable constants a, b, c, and d. This function can exhibit diminishing returns, where
each extra unit of E contributes less and less to R, or it can represent an S-shaped curve, as
in Figure 8.19. An S-shaped curve starts out flat, gets steep, and then flattens out. This
shape is appropriate if sales effort needs to exceed some critical value to generate signifi-
cant sales. The following example illustrates how Evolutionary Solver can be used to esti-
mate this type of curve.3
448
Chapter 8
Evolutionary Solver: An Alternative Optimization Procedure
100
120
140
160
vel
Sales Response Funcon
0
20
40
60
80
0
500
1000
1500
2000
2500
Sales lev
Sales force eﬀort (number of calls)
Figure 8.19
S-Shaped Sales
Response Curve
E X A M P L E
8.5 ESTIMATING THE SALES RESPONSE FUNCTION AT LYNTEX LABS
L
yntex Labs wants to estimate the sales response function that relates its revenue from
sales of a certain drug to the number of sales calls made. Company experts estimate
the revenue that would be obtained in the following five scenarios:
■
No sales effort is assigned to the drug.
■
Sales effort assigned to the drug is cut in half.
■
Sales force effort stays at the current level.
■
Sales force effort is increased by 50%.
■
Sales force effort saturates the market.
The resulting estimates appear in Table 8.3. Note that the current sales effort is 350,000
sales calls. Also, all sales revenue estimates are expressed relative to an index of 100, where
3The model in this section has smooth functions, and it can be solved successfully with GRG Nonlinear Solver if
the initial solution is not too far from the optimal solution. Alternatively, GRG Nonlinear Solver with the
Multistart option works great. However, we illustrate Evolutionary Solver as an alternative.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

100 represents the current level of sales revenue. For example, the experts estimate that if
sales effort is cut in half, sales revenue from the drug will decrease to 68% of the current
level. Lyntex assumes that its sales revenue function is of the form in Equation (8.1). It
wants to find the constants a, b, c, and d that provide the best fit to the values in Table 8.3.
8.6 Fitting an S-Shaped Curve
449
Objective
To use Evolutionary Solver to estimate the assumed S-shaped relationship
between revenue and sales force effort, as measured by the number of sales calls.
WHERE DO THE NUMBERS COME FROM?
The required data in Table 8.3 could be historical data, based on various levels of sales
force effort the company has used in the past, or, as suggested in the problem statement,
they could be educated guesses by people in the marketing department.
Solution
The model development is basically the same as for Example 7.5 from the previous chap-
ter. (See Figure 8.20 and the file Sales Response.xlsx.) The objective is again to find the
model parameters that minimize the sum of squared errors between the actual revenues and
the revenues predicted from the sales response function.
Table 8.3
Estimated Sales Revenues
Sales Calls (1000s)
Sales Revenue 
0
47
175
68
350
100
525
126
3500
152
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
A
B
C
D
E
F
G
H
Esmang the sales response funcon at Lyntex Labs
Assumed sales response funcon: 
Range names used:
Esmate sales level when x sales calls (in 1000s) are made is a+(b-a)xc/(d+xc
7
$
B
$
!
n
oit
a
m
its
E
=
a
)
7
$
C
$
!
n
oit
a
m
its
E
=
b
Model parameters
7
$
D
$
!
n
oit
a
m
its
E
=
_
c
d
c
b
a
7
$
E
$
!
n
oit
a
m
its
E
=
d
5
5
1
4
3
5
4
6
2.2
4
1
9.2
5
1
0
8
4.7
4
Sum_of_squared_errors
=Esmaon!$B$17
Esmates from management
Sales calls (1000s)
Sales level
Sales esmate
Error
0
47
47.480
-0.480
175
68
66.747
1.253
350
100
102.070
-2.070
525
126
124.327
1.673
3500
152
152.381
-0.381
Sum of squared errors
9.028
Figure 8.20
Sales Response Function Estimation
DEVELOPING THE SPREADSHEET MODEL
To develop the spreadsheet model, use the following steps:
1
Inputs. Enter the data in the blue region from Table 8.3.
2
Decision variables. The only decision variables are the constants a, b, c, and d of
the sales response function. Enter any values for these. [Note that we tried to give the
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

corresponding cells range names of a, b, c, and d. However, Excel doesn’t allow the range
name c. (It also doesn’t allow the range name r.) Instead, it changes this name to c_].
3
Predicted sales revenues. In column D, calculate the sales revenue levels (remember
that these are relative to 100) predicted from Equation (8.1). To do so, enter the formula
=a+((b-a)*B11^c_)/(d+B11^c_)
in cell D11 and copy it down to cell D15.
4
Prediction errors. For a good fit, the predictions in column D should match the
experts’ estimates in column C as closely as possible. As usual, a good way to do this is to
minimize the sum of squared differences between the two columns. First, calculate the
errors in column E by entering the formula
=C11-D11
in cell E11 and copying down. Then calculate the sum of squared errors in cell B17 with
the formula
=SUMSQ(E11:E15)
USING EVOLUTIONARY SOLVER
No IF, ABS, MAX, or MIN functions are used in this model, so you might try GRG
Nonlinear Solver, just as in the previous chapter. However, there might be local minima in
this model that are not globally optimal. Alternatively, you could try the Multistart option.
However, Evolutionary Solver is also a good choice because it searches the entire feasible
region and is less likely to get stuck at a local minimum. The only problem is to find a
decent starting solution and reasonable lower and upper limits for the changing cells. It is
difficult to tell, just by looking at Equation (8.1), what reasonable values for a, b, c, and d
might be. Must they be positive? How large can they be? The answers are certainly not
obvious.
Therefore, some analysis of Equation (8.1) is useful before turning to Evolutionary
Solver. First, note that when E  0, estimated sales R equals a. Therefore, a should be pos-
itive. Second, the fraction in Equation (8.1) approaches b – a as E gets large, so b is the
limiting value of R as E gets large. Third, Ec should increase when E increases, so that R
will increase with E. This occurs only if c is positive. Finally, to keep the denominator pos-
itive for all values of E, d must be positive.
If this quick analysis is not convincing, another strategy is to graph Equation (8.1) and
then watch how the graph changes as you manually change a, b, c, and d (see Figure 8.21).
450
Chapter 8
Evolutionary Solver: An Alternative Optimization Procedure
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
A
B
C
D
E
F
G
H
I
J
K
L
M
Graphing the sales response funcon
Model parameters
a
b
c
d
40.000
150.000
2.500
500000
Points on the graph
E
Actual R
Predicted R
0
47
40.000
175
68
89.235
350
100
130.299
525
126
141.930
3500
152
149.924
0
20
40
60
80
100
120
140
160
0
1000
2000
3000
4000
Sales level
Sales calls
Sales Level versus Sales Calls
Actual R
Predicted R
Figure 8.21
Graph of Sales Response Function
Even though this
model is smooth, its
nonlinearity makes it
difficult.The standard
nonlinear Solver can
get stuck at the wrong
solution, depending on
the starting solution.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Discussion of the Solution
The best solution found by Evolutionary Solver appears earlier in Figure 8.20.
Unfortunately, there is nothing very intuitive about these particular values of a, b, c, and d.
However, if you substitute them into row 4 of Figure 8.21, you will see that they provide a
very good fit. In other words, the sales response function with these parameters should pro-
vide very useful predictions of sales levels.
It is interesting to compare Evolutionary Solver with GRG Nonlinear Solver (without
using the Multistart option) for this smooth model. For example, we started each of them at
a fairly poor solution: a40, b100, c1, and d5000. (The sum of squared errors for
this solution is almost 18,000.) Evolutionary Solver found the solution in Figure 8.20
almost immediately. GRG Nonlinear Solver also found a solution almost immediately, but
it was the wrong solution. Its objective was about 190, well above the minimum value in
Figure 8.20. Again, this is because Evolutionary Solver does a more thorough job of
searching the entire feasible region and not getting stuck at a local minimum. (To be fair,
GRG Nonlinear Solver with the Multistart option also found the solution quickly, even
after starting from the poor solution.) 
■
8.6 Fitting an S-Shaped Curve
451
Figure 8.22
Solver Dialog Box
for Sales Response
Estimation
This chart is a scatter chart (where the dots are connected with lines) that plots the actual
sales (the experts’ estimates) in column C and the predicted values from the sales response
function in column D. By changing the constants in row 4 and seeing when the fit between
the two curves is fairly good, you can quickly see that a should be around 47, b should be
somewhere between 150 and 160, the exponent c should be somewhere 1.5 and 5, and the
constant d should be a large positive number. These are fairly wide ranges, but the only
goal at this point is to find reasonable lower and upper limits for Evolutionary Solver.
Using this (somewhat inexact) information, you should fill in the Solver dialog box as
shown in Figure 8.22.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

8.7 PORTFOLIO OPTIMIZATION
In the previous chapter, we discussed one approach to portfolio optimization. The objective
in that chapter was to minimize the portfolio variance subject to keeping the mean portfolio
return above some required level. This resulted in a nonlinear model (because of the squares
and product terms in the portfolio variance formula), but this nonlinear objective was suffi-
ciently smooth to permit using GRG Nonlinear Solver. Now we look at another possible
objective. This objective is not smooth, so Evolutionary Solver is necessary.
452
Chapter 8
Evolutionary Solver: An Alternative Optimization Procedure
P R O B L E M S
Skill-Building Problems
9.
You are given the following information concerning
how a change in sales force effort impacts sales:
■
A 50% cut in sales force effort reduces sales to
48% of its current value.
■
Sales force effort of 0 reduces sales to 15% of its
current value.
■
A 50% increase in sales force effort increases sales
by 20%.
■
A saturation of sales effort (a 10-fold increase)
increases sales by 35%.
Fit an S-shaped curve as described by Equation (8.1)
to these data.
10. The file P08_10.xlsx contains per capita data on
annual advertising and annual unit sales in different
regions of the country. Determine an S-shaped curve
as described by Equation (8.1) that can be used to
determine how advertising influences sales.
11. The adoption level of a new product often can be mod-
eled as an S-shaped curve called the Pearl (or logistic)
curve. The equation of this curve is
Y  
1 
L
aebt

where Y is the adoption level, L is an (unknown) upper
limit on adoptions, and a and b are parameters to be
estimated. The file P08_11.xlsx lists information on
U.S. cell phones since 1990 (which corresponds to
year 1). For this problem, define Y as the number of
cell phones per capita. As t increases, Y approaches
the limit L. Therefore, you can use this curve to esti-
mate the upper limit on U.S. cell phones per person.
Use Evolutionary Solver to estimate the eventual num-
ber of cell phones per person in the United States.
Skill-Extending Problem
12. Sales of a product over time often follow an S-shaped
curve. Two functions that yield S-shaped curves are
the Pearl (or logistic) curve
Y  
1 
L
aebt

and the Gompertz curve
Y  Lebekt
Here, Y is annual sales, t is time (in years), L is the
upper limit on sales, and a, b, and k are parameters to
be estimated. (Actually, L must also be estimated.)
The file P08_12.xlsx contains data for sales of a new
device. Use Evolutionary Solver to fit a Pearl and a
Gompertz curve to these data. Let t  0 correspond to
year 1. Which curve provides the better fit? (Hint: You
need to use reasonable bounds for the parameters for
each curve. For example, L  14.5 is reasonable.)
E X A M P L E
8.6 BEATING THE S&P INDEX AT E.T. BARNEY
E
. T. Barney, an investment company, wants to form a portfolio consisting of a number
of well-known stocks. The objective is to find the appropriate portfolio that, based on
historical data, has the largest probability of beating the S&P 500 market index. How
should the company proceed?4
Objective
To use Evolutionary Solver to find the portfolio that has the highest chance of
beating the S&P 500 Index.
4We have not seen this particular objective discussed in finance books or articles, but it is clear from discussions
with investors that the goal of “beating the market” is important. For an excellent discussion of investment mod-
els in general, read the book by Luenberger (1997).
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

WHERE DO THE NUMBERS COME FROM?
The historical returns from the stocks and the market index are widely available on the
Web. In fact, you can download more recent data if you like.
Solution
The file Beating S&P 500.xlsx contains monthly returns for a period of more than eight
years for 29 large companies. See the blue area in Figure 8.23. (Note that there are many
hidden rows and columns in this figure.) We decided to base the optimization on the earli-
est four years of data. Then we can see how the portfolio based on this data performs on the
most recent four-plus years of data. 
8.7 Portfolio Optimization
453
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
112
113
114
115
116
A
B
C
D
E
F
G
H
I
AB
AC
AD
AE
AF
AG
Maximizing the probabability of beang the S&P 500
Weights on stocks for porolio
MMM
AA
MO
AXP
AIG
BA
CAT
C
VZ
WMT
DIS
0.226844 0.247194
0
0.220331
0
0
0
0
0
0
0
Constraint on 
t
n
e
cr
e
P
st
h
gie
w
 of months beang S&P 500
Sum weights
Required
Old Pct
70.83%
1
=
1
Recent Pct
48.21%
Historical data on returns
Month
MMM
AA
MO
AXP
AIG
BA
CAT
C
VZ
WMT
DIS
S&P  500
Porolio Return
Beat S&P?
Feb-99
-0.0387
-0.0261
-0.1650
0.0548
0.1068
0.0311
0.0520
0.0481
-0.0396
0.0015
0.0662
-0.0323
-0.0100
Yes
Mar-99
-0.0448
0.0169
-0.0908
0.0870
0.0591
-0.0458
0.0081
0.0873
-0.1031
0.0715
-0.1156
0.0388
0.0384
No
Apr-99
0.2582
0.5114
-0.0041
0.1100
-0.0299
0.1952
0.4085
0.1752
0.1233
-0.0021
0.0202
0.0379
0.2067
Yes
May-99
-0.0305
-0.1136
0.1003
-0.0738
-0.0230
0.0385
-0.1477
-0.1149
-0.0501
-0.0732
-0.0828
-0.0250
-0.0574
No
Jun-99
0.0139
0.1251
0.0533
0.0769
0.0263
0.0460
0.0933
0.0752
0.1939
0.1332
0.0579
0.0544
0.0406
No
Jul-99
0.0115
-0.0323
-0.0734
0.0124
-0.0097
0.0313
-0.0175
-0.0591
-0.0148
-0.1244
-0.1053
-0.0320
0.0052
Yes
Aug-99
0.0807
0.0816
0.0049
0.0438
-0.0022
0.0015
-0.0339
-0.0028
-0.0422
0.0490
0.0067
-0.0063
0.0758
Yes
Sep-99
0.0166
-0.0384
-0.0750
-0.0182
-0.0616
-0.0591
-0.0321
-0.0096
0.0979
0.0744
-0.0628
-0.0286
-0.0273
Yes
Oct-99
-0.0104
-0.0211
-0.2286
0.1425
0.1841
0.0804
0.0150
0.2362
-0.0294
0.1838
0.0212
0.0625
0.0540
No
May-07
0.0687
0.1689
0.0316
0.0711
0.0371
0.0857
0.0820
0.0265
0.1402
-0.0021
0.0132
0.0325
0.0735
Yes
Jun-07
-0.0133
-0.0182
-0.0037
-0.0585
-0.0319
-0.0441
-0.0036
-0.0587
-0.0543
0.0108
-0.0367
-0.0178
-0.0285
No
Jul-07
0.0246
-0.0575
-0.0523
-0.0408
-0.0835
0.0757
0.0106
-0.0921
0.0454
-0.0449
-0.0334
-0.0320
-0.0152
Yes
Aug-07
0.0288
-0.0394
0.0443
0.0014
0.0283
-0.0619
-0.0385
0.0185
-0.0174
-0.0457
0.0182
0.0129
0.0126
No
Sep-07
0.0285
0.0709
0.0130
0.0128
0.0281
0.0857
0.0351
-0.0045
0.0573
0.0005
0.0235
0.0358
0.0476
Yes
Figure 8.23
Portfolio Optimization Model
DEVELOPING THE SPREADSHEET MODEL
You can create the model with the following steps:
1
Enter weights. As in the previous chapter, the portfolio is based on the fractions
(called weights) of each dollar invested in the various stocks. Enter any values for the
weights in the Weights range. These weights will eventually be constrained to be between
0 and 1. Then calculate the sum of the weights in cell B9 with the SUM function.
2
Portfolio returns. For the historical period, the period of the data, calculate the port-
folio returns by weighting the actual returns by the weights. To do this, enter the formula
=SUMPRODUCT(Weights,B13:AD13)
in cell AF13 and copy it down.
3
Beats S&P 500? The returns from the S&P 500 market index appear in column AE.
(These are given. As with the stock returns, they can be found on the Web.) For each
month, see whether the portfolio beats the S&P 500 by entering the formula
=IF(AF13>AE13,"Yes","No")
in cell AG13 and copying down.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4
Objective. Calculate the fraction of months during the earliest four years where the
portfolio beats the S&P 500. Do this in cell G8 with the formula
=COUNTIF(AG13:AG60,"Yes")/48
This is the objective to maximize. Note that it contains the COUNTIF function. This is the
feature that necessitates Evolutionary Solver. For comparison, calculate the similar frac-
tion for the most recent four-plus years in cell G9 with the formula
=COUNTIF(AG61:AG116,"Yes")/56
USING EVOLUTIONARY SOLVER
The Solver setup appears in Figure 8.24. You should constrain the sum of the weights to be
1 so that all of the money is invested, and you should constrain the weights to be between
0 and 1 so that the investment in each stock is a positive fraction of the total investment.
(You can allow negative weights if you want to permit short selling.)
454
Chapter 8
Evolutionary Solver: An Alternative Optimization Procedure
Figure 8.24
Solver Dialog Box
for the Portfolio
Optimization Model
Discussion of the Solution
There are several things to note about the optimal solution found in Figure 8.23. First, this
portfolio puts most of the weight on four companies: 3M (22.7%), Alcoa (24.7%), American
Express (22.0%), and Procter & Gamble (21.3%). The rest of the weight is divided among
four other companies, and the rest of the companies are not in the portfolio at all. Second, this
solution represents the portfolio that beats the S&P 500 most frequently in the optimization
period—that is, the earliest four years. Whenever an optimization is based on a historical
period, there is no guarantee that this solution will work as well in a later time period. The
calculation in cell G9 shows how well the portfolio does in the most recent four-plus years of
the data set. Clearly, it does not do as well. The portfolio beats the S&P 500 about 71% of the
time during the earliest four years, but only about 48% of the time during the most recent
four-plus years. Any time historical data is used to forecast what might happen in the future,
the implicit assumption is that historical patterns will repeat themselves. As many forecasters
have discovered to their dismay, this assumption is not always correct.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Finally, this is the best solution we found after experimenting with several random
number seeds and several starting solutions for the weights. Some of these converged to a
solution with an objective less than 75%, which is clearly suboptimal. This is due to the
randomness component built into GAs. Different runs can have varying levels of success
depending on the luck of the draw.
■
Is this method of portfolio optimization any better or worse than the variance-
minimizing method discussed in the previous chapter? The answer probably depends on
the investor’s attitude toward risk. There is no guarantee that the probability-maximizing
model in this chapter will achieve any particular expected return, although if it beats
the market index consistently, it seems that it should provide a decent return. Also, there
is no guarantee that this portfolio will provide an acceptable risk—measured by a small
variance. Nevertheless, this model might have an intuitive appeal to many investors. If you
can beat the S&P 500 consistently, you must be doing a good job.
8.8 Cluster Analysis
455
P R O B L E M S
Skill-Building Problems
13. Visit http://biz.yahoo.com/r/. Under Research Tools,
click on Historical Quotes, and then download the
monthly returns on at least four stocks for the preced-
ing 60 months. Use this data to determine the portfolio
that maximizes the chance of beating the S&P 500 for
these years. (Note that the ticker symbol for the S&P
500 is ^GSPC. Also, this Web site gives closing
prices, which you will need to convert to returns.)
14. Continuing the previous problem, determine the
portfolio that minimizes the chance that you will lose
money during any month, subject to a lower bound
constraint on your expected monthly return. (The
lower bound will depend on your data. It must not be
above the largest average return of your stocks. For
example, if you require the mean portfolio return to be
greater than 1% and all stocks average less than 1%,
the constraint can’t possibly be satisfied.)
8.8 CLUSTER ANALYSIS
Marketers often want to group objects into clusters of similar objects. For example, identi-
fying similar customers can help a company identify market segments. Identifying a
cluster of similar products can help a company identify its main competitors. Here are two
actual examples of how the United States is divided into clusters.5
■
Claritas divides each block of the United States into one of 62 clusters. These include
Blue Blood Estates, New Homesteaders, Middle America, God’s Country, and so on.
For example, Blue Blood Estates consists primarily of America’s richest suburbs.
(Over 1 in 10 residents of Blue Blood Estates is a millionaire.) This is valuable infor-
mation for marketers. For example, Blue Blood Estates residents consume imported
beer at a rate nearly three times the national average.
■
SRI clusters families based on their financial status and demographics. For example,
the cluster Bank Traditionalists consists of upper-middle-class families of larger than
average size with school-age children. This cluster is a natural prospecting ground
for life insurance salespeople.
The following example illustrates how Evolutionary Solver can be used to cluster
cities. The same method could be use to cluster people, products, or other entities.6
5The book by Johnson and Wichern (2002) has an excellent, although somewhat mathematically advanced, dis-
cussion of cluster analysis and the topic of the next section, discriminant analysis.
6This example is for illustration only. There are many software packages other than Excel that are much more
powerful for data mining tasks such as cluster analysis or discriminant analysis, the subject of the next example.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Objective
To use Evolutionary Solver to find four cities to be used as cluster centers and
to assign all other cities to one of these cluster centers.
WHERE DO THE NUMBERS COME FROM?
This basic demographic data on cities is widely available. Note that the data used here is
several years old.
Solution
The first problem is that if you use raw units, percentage African American and
Hispanic will drive everything because these values are more spread out than the other
demographic attributes. You can see this by calculating means and standard deviations
of the characteristics. (See Figure 8.26, which also includes correlations between the
attributes.) To remedy this problem, each demographic attribute should be standardized
by subtracting the attribute’s mean and dividing the difference by the attribute’s stan-
dard deviation. For example, the average city has 24.35% African Americans with a stan-
dard deviation of 18.11%. On a standardized basis, Atlanta is larger by (67 – 24.35)/
18.11  2.355 standard deviations on the African-American attribute than a typical city.
Working with standardized values for each attribute ensures that the analysis is unit-
free. To create the standardized values shown in Figure 8.25, enter the formula
=(C15-AVERAGE(C$15:C$63))/STDEV(C$15:C$63)
in cell I15 and copy it across to column N and down to row 63.
456
Chapter 8
Evolutionary Solver: An Alternative Optimization Procedure
E X A M P L E
8.7 CLUSTERING LARGE CITIES IN THE UNITED STATES
T
he file City Clusters.xlsx contains demographic data on 49 of the largest cities in the
United States. Some of the data appear in the shaded region of Figure 8.25. For
example, Atlanta is 67% African American, 2% Hispanic, and 1% Asian. It has a median
age of 31, a 5% unemployment rate, and a per-capita income of $22,000. The goal in this
example is to group these 49 cities into four clusters of cities that are demographically
similar. (You could then experiment with the number of clusters. For this discussion, the
number is fixed at four.) The basic idea is to choose a city to anchor, or center, each clus-
ter. Each city is then assigned to the nearest cluster center, where nearest is defined in
terms of the six demographic variables. The objective is to minimize the sum of the dis-
tances from each city to its cluster center.
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
A
B
C
D
E
F
G
H
I
J
K
L
M
N
City data
Standardized
Index
City
PctAfrAmer
PctHispanic PctAsian
MedianAge
UnempRate
PCIncome
PctAfrAmer
PctHispanic
PctAsian
MedianAge
UnempRate
PCIncome
1
Albuquerque
3
35
2
32
5
18
-1.179
1.239
-0.363
0.061
-0.751
-0.875
2
Atlanta
67
2
1
31
5
22
2.355
-0.764
-0.452
-0.440
-0.751
0.324
3
Ausn
12
23
3
29
3
19
-0.682
0.510
-0.273
-1.442
-1.495
-0.575
4
Balmore
59
1
1
33
11
22
1.913
-0.825
-0.452
0.562
1.480
0.324
5
Boston
26
11
5
30
5
24
0.091
-0.218
-0.093
-0.941
-0.751
0.924
6
Charloe
32
1
2
32
3
20
0.423
-0.825
-0.363
0.061
-1.495
-0.275
7
Chicago
39
20
4
31
9
24
0.809
0.328
8
Cincinna38 
                      1                      1               31                      8                     21              0.75
-0.183
-0.440
0.736
0.924
4
-0.825
-0.452
-0.440
0.364
0.024
9
Cleveland
47
5
1
32
13
22
1.251
-0.582
-0.452
0.061
2.224
0.324
10
Columbus
23
1
2
29
3
13
-0.074
-0.825
-0.363
-1.442
-1.495
-2.375
11
Dallas
30
21
2
30
9
22
0.312
0.389
-0.363
-0.941
0.736
0.324
12
Denver
13
23
2
34
7
23
-0.627
0.510
-0.363
1.063
-0.008
0.624
13
Detroit
76
3
1
31
9
21
2.852
-0.704
-0.452
-0.440
0.736
0.024
14
El Paso
3
69
1
29
11
13
-1.179
3.303
-0.452
-1.442
1.480
-2.375
15
Fort Worth
22
20
2
30
9
20
-0.130
0.328
-0.363
-0.941
0.736
-0.275
16
Fresno
9
30
13
28
13
16
-0.847
0.935
0.624
-1.942
2.224
-1.475
Figure 8.25
Demographic Data for Selected Cities
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

DEVELOPING THE SPREADSHEET MODEL
Now that all of the attributes have been standardized, you can develop the spreadsheet
model as follows. It is shown in two parts in Figures 8.27 and 8.28.
8.8 Cluster Analysis
457
7
8
9
10
11
12
13
14
15
16
17
18
19
A
B
C
D
E
F
G
PctAfrAmer
PctHispanic
PctAsian
MedianAge
UnempRate
PCIncome
One Variable Summary
Data Set #1
Data Set #1
Data Set #1
Data Set #1
Data Set #1
Data Set #1
Mean
24.35
14.59
6.04
31.878
7.020
20.918
Std. Dev.
18.11
16.47
11.14
1.996
2.689
3.334
PctAfrAmer
PctHispanic
PctAsian
MedianAge
UnempRate
PCIncome
Correlaon Table
Data Set #1
Data Set #1
Data Set #1
Data Set #1
Data Set #1
Data Set #1
PctAfrAmer
1.000
PctHispanic
-0.404
1.000
PctAsian
-0.317
0.000
1.000
MedianAge
0.010
-0.221
0.373
1.000
UnempRate
0.308
0.341
-0.001
-0.007
1.000
PCIncome
0.126
-0.298
0.374
0.480
0.014
1.000
Figure 8.26
Summary Data for Demographic Attributes
1
2
3
4
5
6
7
8
9
10
11
A
B
C
D
E
F
G
H
I
J
K
L
Clustering cies
Cluster centers and standardized values
Range names used
Column oﬀset:
9
10
11
12
13
14
City_index
=Model!$B$6:$B$9
Cluster center
City index
PctAfrAmer
PctHispanic PctAsian
MedianAge
UnempRate
PCIncome
Cluster_center
=Model!$A$6:$A$9
San Francisco
43
-0.737
-0.036
2.060
2.065
-0.380
3.024
LookupTable
=Model!$A$15:$N$63
Philadelphia
35
0.864
-0.522
-0.273
0.562
0.736
0.624
Sum_Distances
=Model!$B$11
4
3
a
h
a
m
O
-0.627
-0.704
-0.452
0.061
-0.751
-0.275
Long Beach
23
-0.571
0.571
0.714
-0.941
0.364
0.024
Sum Distances
77.578
Figure 8.27
Decision Variables and Objective Cell
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
P
Q
R
S
T
U
V
Distances to 
d
e
n
giss
A
sr
e
t
n
e
c
 to
To 1
To 2
To 3
To 4
Minimum
Index
Center
5.200
3.463
2.109
2.243
2.109
3
Omaha
5.487
2.371
3.083
3.646
2.371
2
Philadelphia
5.678
3.727
2.100
2.249
2.100
3
Omaha
5.193
1.367
3.472
3.616
1.367
2
Philadelphia
4.352
2.299
1.823
1.941
1.823
3
Omaha
4.897
2.517
1.295
2.941
1.295
3
Omaha
4.414
1.352
2.665
1.992
1.352
2
Philadelphia
4.998
1.280
1.873
2.306
1.280
2
Philadelphia
5.352
1.655
3.571
3.250
1.655
2
Philadelphia
7.044
4.356
2.747
3.581
2.747
3
Omaha
4.971
1.868
2.379
1.484
1.484
4
Long Beach
3.616
2.025
1.962
2.383
1.962
3
Omaha
6.013
2.320
3.828
3.885
2.320
2
Philadelphia
7.909
5.692
5.292
4.055
4.055
4
Long Beach
5.247
2.188
2.130
1.281
1.281
4
Long Beach
6.789
4.330
4.266
2.632
2.632
4
Long Beach
4.427
6.942
6.901
6.508
4.427
1
San Francisco
Figure 8.28
Other Calculations for Cluster Analysis
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

1
Lookup table. One key to the model is to have an index (1 to 49) for the cities so that
you can refer to them by index and then look up their characteristics with a VLOOKUP
function. Therefore, name the range A15:N63 as LookupTable.
2
Decision v ariables. The only changing cells appear in the City_index range of
Figure 8.27. They are the indexes of the four cities chosen as cluster centers. Enter any four
integers from 1 to 49 in these cells.
3
Corresponding cities and standardized attrib utes. You can find the names and
standardized attributes of the cluster centers with VLOOKUP functions. First, enter the
function
=VLOOKUP(B6,LookupTable,2)
in cell A6 and copy it to the range A6:A9. Then enter the formula
=VLOOKUP($B6,LookupTable,C$4)
in C6 and copy it to the range C6:H9. Note, for example, that the standardized PctAfrAmer
is the ninth column of the lookup table. This explains the column offset entries in row 4.
4
Distances to centers. The next step is to see how far each city is from each of the
cluster centers. Let zi be standardized attribute i for a typical city, and let ci be standardized
attribute i for a typical cluster center. You can measure the distance from this city to this
cluster center with the usual Euclidean distance formula
Distance 
i
(zic
i)2
where the sum is over all six attributes. These distances appear in columns P through S of
Figure 8.28. For example, the value in cell P15 is the distance from Albuquerque to the
first cluster center (San Francisco), the value in Q15 is the distance from Albuquerque to
the second cluster center (Philadelphia), and so on. These calculations can be performed in
several equivalent ways. Probably the quickest way is to enter the formula
=SQRT(SUMXMY2($I15:$N15,$C$6:$H$6))
in cell P15 and copy it to the range P15:S63. (The function SUMXMY2 calculates the dif-
ferences between the elements of the two range arguments and then sums the squares of
these differences—exactly what is required.) The copied versions in columns Q, R, and S
then have to be modified slightly. Each 6 in the second range argument needs to be
changed to 7 in column Q, to 8 in column R, and to 9 in column S.
5
Assignments to cluster centers. Each city is assigned to the cluster center that has
the smallest distance. Therefore, find the minimum distances in column T by entering the
formula
=MIN(P15:S15)
in cell T15 and copying it down. Then you can identify the cluster index (1 through 4) and
city name of the cluster center that yields the minimum with the MATCH function.
Specifically, enter the formula
=MATCH(T15,P15:S15,0)
in cell U15 and copy it down. For example, the 4.447 minimum distance for Albuquerque
corresponds to the second distance, so Albuquerque is assigned to the second cluster cen-
ter. Finally, to get the name of the second cluster center, you can use the INDEX function.
Enter the formula
458
Chapter 8
Evolutionary Solver: An Alternative Optimization Procedure
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

=INDEX(Cluster_center,U15,1)
in cell V15 and copy it down. This formula returns the name in the second row and first
(only) column of the Cluster_center range (in Figure 8.27).
Excel Function: INDEX
The function INDEX, using the syntax INDEX(Range,Row,Column), is usually used to
return the value in a given row and column of a specified range. For example,
INDEX(A5:C10,3, 2) returns the value in the third row and second column of the range
A5:C10, that is, the value in cell B7. If the given range is a single row, the row argument
can be omitted. If the given range is a single column, the column argument can be
omitted.
6
Sum of distances. The objective is to minimize the sum of distances from all cities to
the cluster centers to which they are assigned. Calculate this objective in cell B11 (in
Figure 8.27) with the formula
=SUM(T15:T63)
USING EVOLUTIONARY SOLVER
The Solver dialog box should be set up as shown in Figure 8.29. Because the changing
cells represent indexes of cluster centers, they must be integer-constrained, and suitable
lower and upper limits are 1 and 49 (the number of cities). This problem is considerably
more difficult to solve, so you should allow Evolutionary Solver plenty of time to search
through a lot of potential solutions.
8.8 Cluster Analysis
459
Figure 8.29
Solver Dialog Box
for Cluster Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Discussion of the Solution
The solution in Figure 8.27, which uses San Francisco, Philadelphia, Omaha, and Long
Beach, is the best we found. You might find a slightly different solution, depending on your
Solver settings and how long you let Solver run, but you should obtain a similar value in the
objective cell. If you look closely at the cities assigned to each cluster center, this solution
begins to make intuitive sense (see Figure 8.30). The San Francisco cluster consists of rich,
older, highly Asian cities. The Philadelphia cluster consists of highly African-American
cities with high unemployment rates. The Omaha cluster consists of average income cities
with few minorities. The Long Beach cluster consists of highly Hispanic cities with high
unemployment rates.
Why four clusters? You could easily try three clusters or five clusters. Note that when
the number of clusters increases, the sum of distances will certainly decrease. In fact, you
could obtain an objective value of 0 by using 49 clusters, one for each city, but this would
hardly provide much information. Therefore, to choose the “optimal” number of clusters,
the typical approach is to stop adding clusters when the sum of distances fails to decrease
by a substantial amount.
460
Chapter 8
Evolutionary Solver: An Alternative Optimization Procedure
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
W
X
Y
Z
AA
Clusters
Center:
San Francisco
Philadelphia
Omaha
Long Beach
Honolulu
Atlanta
Albuquerque
Dallas
San Francisco
Balmore
Ausn
El Paso
Seale
Chicago
Boston
Fort Worth
Cincinna 
Charloe
Fresno
Cleveland
Columbus
Houston
Detroit
Denver
Long Beach
Memphis
Indianapolis
Los Angeles
Miami
Jacksonville
Sacramento
New Orleans
Kansas City
San Antonio
NY
Las Vegas
San Diego
Oakland
Milwaukee
San Jose
Philadelphia
Minneapolis
Pisburgh
Nashville
St. Louis
Oklahoma City
Omaha
Phoenix
Portland
Toledo
Tucson
Tulsa
Virginia Beach
Figure 8.30
Clusters in the
Solver Solution
In cluster analysis, the
number of clusters is
typically unknown
ahead of time. Some
experimentation with
the number of clusters
is usually required.
P R O B L E M
Skill-Building Problem
15. The file P08_15.xlsx contains the following informa-
tion about the top 25 MBA programs (according to the
1997 Business Week Guide): percentage of applicants
accepted, percentage of accepted applicants who
enroll, mean GMAT score of enrollees, mean under-
graduate GPA of enrollees, annual cost of school (for
state schools, this is the cost for out-of-state students),
percentage of students who are minorities, percentage
of students who are non-U.S. residents, and mean
starting salary of graduates (in thousands of dollars).
Use these data to divide the top 25 schools into four
clusters. Then interpret your clusters.
■
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

8.9 DISCRIMINANT ANALYSIS
Discriminant analysis is a statistical tool used by analysts in marketing and other fields of
business. Although somewhat similar to cluster analysis, it is also quite different. In clus-
ter analysis, there are no predefined clusters. You look at the information on the different
members of the population (cities, products, or whatever) to see which members should be
clustered together because of similar characteristics. You do not even know the number of
clusters to use. In discriminant analysis, however, the clusters (usually called groups) are
predefined. For example, there might be two groups: users of a particular product and
nonusers. You collect data on a sample (often called a training sample ) of users and
nonusers—their income, their ages, and other possibly relevant data—and use this data to
classify the customers as users or nonusers. The analysis is successful if a large percentage
of the customers in the training sample are classified correctly. Of course, the group mem-
bership of each customer in the training sample is already known. Therefore, the real pur-
pose is to see whether a large percentage of customers outside of the training sample can
be classified correctly on the basis of their income, age, and other relevant variables.
Discriminant analysis has been used in many situations, including the following:
■
Based on gender, age, income, and residential location, classify a consumer as a user
or nonuser of a new breakfast cereal.
■
Based on income, type of residence, credit card debt, and other information, classify
a consumer as a good or bad credit risk.
■
Based on financial ratios, classify a company as a likely or unlikely candidate for
bankruptcy.
In general, discriminant analysis can be used to classify members of two or more groups.
We focus only on two-group discriminant analysis. In this case, the approach is to find a
weighted combination of the data for each member, called a discriminant score, and then to
classify the member into group 1 or group 2 depending on which side of a cutoff score the
member’s discriminant score falls. The problem is to find the appropriate weights for the dis-
criminant scores and the appropriate cutoff score that maximize the percentage of correct
classifications in the training sample. The following example illustrates the procedure.
8.9 Discriminant Analysis
461
In classification exam-
ples such as these, you
typically create an
optimization model on
a “training” data set
and then apply it to a
new data set to predict
group membership.
E X A M P L E
8.8 CLASSIFYING SUBSCRIBERS AND NONSUBSCRIBERS TO THE WALL
STREET JOURNAL
T
he file WSJ Subscribers.xlsx contains the annual income and size of investment port-
folio (both in thousands of dollars) for 84 people. It also indicates whether or not each
of these people subscribes to the Wall Street Journal. Using income and size of investment
portfolio, determine a classification rule that maximizes the number of people correctly
classified as subscribers or nonsubscribers.
Objective
To use Evolutionary Solver to find a function of income and investment that
does the best job of classifying subscribers and nonsubscribers.
WHERE DO THE NUMBERS COME FROM?
In a general discriminant analysis, you collect as much relevant financial and demographic
data as possible about the people (or companies) to be classified.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Solution
The model is actually simpler than the cluster analysis model. Using appropriate weights,
you create a discriminant score for each of the 84 customers. Then based on a cutoff score,
you classify each customer as a subscriber or nonsubscriber, and you tally the number of
correct classifications.
DEVELOPING THE SPREADSHEET MODEL
The model appears (with several data rows not shown) in Figure 8.31 and can be developed
as follows:
462
Chapter 8
Evolutionary Solver: An Alternative Optimization Procedure
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
A
B
C
D
E
F
G
H
I
J
K
Discriminant analysis
Weights for discriminant 
e
g
n
a
R
n
oitc
n
u
f
 names used:
f
o
t
u
C
t
m
A
ts
e
v
nI
e
m
o
c
nI
f
=Model!$B$8
-
7
1
$I$
!le
d
o
M
=
tc
e
rr
o
c
_
tc
P
0
5
9.0
4
9
0.0
Weights
=Model!$B$5:$C$5
Cutoﬀ value for classiﬁcaon
33.545
Customer 
n
oit
a
cifiss
alC
a
t
a
d
 matrix
Person
Income
InvestAmt
WSJSubscriber
Score
Classiﬁed as
(Actual along side, predicted along top)
o
N
s
e
Y
o
N
6.8
o
N
9.4
1
7.9
5
1
2
60.9
25.8
No
18.8
No
Yes
23
4
3
67.6
37.6
Yes
29.4
No
No
2
55
4
86.6
37.0
No
27.0
No
5
90.4
21.4
No
11.8
No
Percent correct classiﬁcaons
%
6
8.2
9
o
N
8.8
1
o
N
4.6
2
2.7
6
6
7
85.1
59.8
Yes
48.8
Yes
8
89.9
46.2
No
35.5
Yes
9
100.3
55.5
Yes
43.3
Yes
10
57.6
22.2
No
15.7
No
Figure 8.31
Discriminant Analysis Model
1
Customer data. Enter the customer data in the blue range. This includes the data on
the variables used for classification (income and investment amount), as well as an indica-
tion of which group each customer is in. These 84 customers represent the training sample,
so group membership (subscriber or nonsubscriber) for each of them is known.
2
Decision variables. The decision variables are the weights used to form discriminant
scores and the cutoff value for classification. Enter any values for these in the Weights and
Cutoff ranges.
3
Discriminant scores. Each discriminant score is a weighted combination of the per-
son’s income and investment amount. To calculate these in column E, enter the formula
=SUMPRODUCT(Weights,B12:C12)
in cell E12 and copy it down.
4
Classifications. A person is classified as a nonsubscriber if the person’s discriminant
score is below the cutoff value; otherwise, the person is classified as a subscriber.
Therefore, enter the formula
=IF(E12<Cutoff, "No","Yes")
in cell F12 and copy it down. (It could be done the opposite way, where people above the
cutoff are classified as subscribers, but the results would be equivalent.)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

5
Tallies. It is customary to tally the classifications in a classification matrix, as shown
in the range H12:J14. The easiest way to find these tallies is to use the COUNTIFS func-
tion (new in Excel 2007). Specifically, enter the formula
=COUNTIFS($D$12:$D$95,$H13,$F$12:$F$95,I$12)
in cell I13 and copy it to the range I13:J14. Then calculate the percent correctly classified
in cell I17 with the formula
=(I13+J14)/SUM(I13:J14)
This is the objective to minimize.
Excel Function: COUNTIFS
The function COUNTIFS, new to Excel 2007, enables you to count the number of values
that satisfy multiple criteria. The arguments come in pairs. The first member of each pair
is a range, and the second is a criterion. In the e xample above, there are two pairs. The
first r equires a matc h between the values in column D and one of the values in the
H13:H14 range. The second requires a match between column F and one of the values in
the I12:J12 range. For example, the value in cell I13 means that 23 of the data r ows have
Yes in column D and in column F.
USING EVOLUTIONARY SOLVER
First, note that Evolutionary Solver is required because of the IF and COUNTIFS functions
used to make and tally the classifications. The completed Solver dialog box appears in
Figure 8.32 and is straightforward except for the lower and upper limits on the changing
cells. There are no natural weights or cutoff values to use. However, the weights can
always be constrained to be between –1 and 1. (The reasoning is that if you solve the prob-
lem with weights equal to, say, –15 and 15, you can divide them and the resulting cutoff
score by 15 and obtain exactly the same classifications.) To obtain lower and upper limits
on the cutoff value, we first calculated the maximum sum of income and investment
amount for any customer, which is slightly less than 160. This means that the largest dis-
criminant score, using weights of 1, is no larger than 160, and the smallest discriminant
score, using weights of –1, is no less than –160. Therefore, there is no need to consider cut-
off values below –160 or above 160.
8.9 Discriminant Analysis
463
Figure 8.32
Solver Dialog Box
for Discriminant
Analysis Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Discussion of the Solution
The solution shown in Figure 8.31 is certainly not unique. Many other sets of weights and
cutoff values can obtain a 92.86% correct classification rate, and you will probably obtain
a different solution from ours. Note that only six of the 84 people are misclassified—four
subscribers are misclassified as nonsubscribers and two nonsubscribers are misclassified
as subscribers. Also, you can see from the weights that the classification is based primarily
on the investment amount, with very little weight placed on income. Because of the posi-
tive weight on the investment amount, people with large investment amounts tend to be
classified as subscribers. Therefore, a subscriber such as person 3 is misclassified because
his investment amount is abnormally small relative to other subscribers. On the other hand,
a nonsubscriber such as person 8 is misclassified because his investment amount is abnor-
mally large relative to other nonsubscribers.
In a real application, you would use this analysis for people other than the 84 in the
training sample. That is, you would calculate a discriminant score for each such person and
then classify each as a nonsubscriber if her discriminant score is less than the cutoff value.
However, the percentage correctly classified would typically be less—maybe considerably
less—than the 92.86% rate achieved in the training sample. The reason is that the opti-
mization procedure takes advantage of all the data for these particular 84 people to derive
the weights and the cutoff score. Unfortunately, there is no reason to believe that these will
work as well for another group of people.
■
464
Chapter 8
Evolutionary Solver: An Alternative Optimization Procedure
The classification
matrix, often called the
confusion matrix,
shows how well the
members of the train-
ing data set are classi-
fied. However, there is
no guarantee that the
model will classify
members of a new
data set as accurately.
P R O B L E M S
Skill-Building Problems
16. For data in the file P08_16.xlsx, develop a rule to
predict whether a person is likely to purchase your
lasagna product. What variables appear to be the
most useful?
17. For the data in the file P08_17.xlsx, develop a classifi-
cation rule to classify students as likely admits, likely
rejects, or borderline.
18. The file P08_18.xlsx contains information on the fol-
lowing items about 24 companies: EBITASS (earnings
before income and taxes, divided by total assets),
ROTC (return on total capital), and Group (1 for most
admired companies and 2 for least admired compa-
nies). Use these data to develop a rule that can be used
to classify a company as a most admired or least
admired company. Which variable appears to be most
important for this classification?
19. The term churn is common in marketing. It means that
a customer switches loyalty to another company. The
file P08_19.xlsx contains data on over 3000 customers
of a cell phone provider. Columns B through N pro-
vide information about the account and usage of each
customer, and column O indicates whether the cus-
tomer churned during the given period of time. Use
these data to develop a rule for predicting whether a
customer will churn. Can you make any (qualitative)
sense out of the discriminant function? Does this prob-
lem appear to be much harder for Evolutionary Solver
because of the large size of the data set?
8.10 THE TRAVELING SALESPERSON PROBLEM
One of the most studied management science problems (at least by academics) is called the
traveling salesperson problem. Although easy to state, the problem is very difficult to
solve. A salesperson must travel from his home base to a number of other cities, visiting
each city exactly once, and finally return to his home base. The goal is to find the route that
has the shortest total distance. Note that a potential solution is simple to describe. If we
index the home base as 0 and the cities to be visited as 1 through n, then any solution is a
permutation of the numbers 1 through n. For example, if n  8, a potential solution is 2, 5,
7, 1, 3, 8, 4, 6. The salesperson goes from 0 to 2, from 2 to 5, and so on, finishing by going
Because of its
combinatorial nature,
traveling salesperson
problems with even a
moderate number of
cities, such as 20 to
30, are quite difficult
to solve.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

from 6 back to 0. Because there are n! permutations of the numbers 1 through n, you might
think that checking each of them and choosing the best is easy. However, n! grows
extremely fast as n increases. For example, 8! is “only” 43,020, but 16! is close to 21 tril-
lion. This explosion in the number of permutations is what makes the problem so difficult.
Nevertheless, it is easy to model the problem in such a way that Evolutionary Solver
can be used to find good, and possibly even optimal, solutions. The following example
illustrates the method.
8.10 The Traveling Salesperson Problem
465
E X A M P L E
8.9 MINIMIZING A SALESPERSON’S DISTANCE TRAVELED
W
illie Lowman is a salesman who lives in Boston. He needs to visit each of the cities
listed in Figure 8.33 (see the file Traveling Salesperson.xlsx) and then return to
Boston. What route should Willie use to minimize the total distance traveled?
1
A
B
C
D
E
F
G
H
I
J
K
L
Traveling salesperson problem
2
3
4
5
6
7
8
9
10
Distance matrix
Boston
Chicago
Dallas
Denver
Los Angeles
Miami New York
Phoenix
Pisburgh
San Francisco
Seale
Boston
0
983
1815
1991
3036
1539
213
2664
792
2385
2612
Chicago
983
0
1205
1050
2112
1390
840
1729
457
2212
2052
Dallas
1815
1205
0
801
1425
1332
1604
1027
1237
1034
2404
Denver
1991
1050
801
0
1174
2057
1780
836
1411
1765
1373
Los Angeles
3036
2112
1425
1174
0
2757
2825
398
2456
403
1919
Miami
1539
1390
1332
2057
2757
0
1258
2359
1250
3097
3389
11
12
13
14
15
New York
213
840
1604
1780
2825
1258
0
2442
386
3036
2900
Phoenix
2664
1729
1027
836
398
2359
2442
0
2073
800
1482
Pisburgh
792
457
1237
1411
2456
1250
386
2073
0
2653
2517
San Francisco
2385
2212
1765
1034
403
3097
3036
800
2653
0
817
Seale
2612
2052
2404
1373
1919
3389
2900
1482
2517
817
0
Figure 8.33
Distance Matrix
Objective
To use Evolutionary Solver, with a special kind of constraint, to find the short-
est route that starts and ends in Boston and visits each of the other 10 cities exactly once.
WHERE DO THE NUMBERS COME FROM?
The numbers in this example could be found from a map. In general, the required data are the
distances from each city to each other city, where distance can be interpreted as a cost. For
example, if Willie is flying from city to city, the costs of the various flights is the more rele-
vant “distance” measure, and these costs are not necessarily proportional to the actual
distances.
Solution
This problem is surprisingly easy to model in a spreadsheet. You simply need a way to
specify that any potential solution is a permutation of the numbers 1 through 10.
Fortunately, Evolutionary Solver has a special type of constraint developed specifically for
this kind of problem that is called an alldifferent constraint. You constrain the indexes of
the cities visited to be between 1 and 10, and you also constrain them to be all different. Of
course, the only way this can occur is if they are a permutation of the numbers 1 through 10.
With this in mind, the model is straightforward.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

DEVELOPING THE SPREADSHEET MODEL
The completed model appears in Figure 8.34 and can be developed with the following
steps:
466
Chapter 8
Evolutionary Solver: An Alternative Optimization Procedure
1
A
B
C
D
E
F
G
H
I
J
K
L
Traveling salesperson problem
2
3
4
5
6
7
8
9
10
11
Distance matrix
Boston
Chicago
Dallas
Denver
Los Angeles
Miami New York
Phoenix
Pisburgh
San Francisco
Seale
Boston
0
983
1815
1991
3036
1539
213
2664
792
2385
2612
Chicago
983
0
1205
1050
2112
1390
840
1729
457
2212
2052
Dallas
1815
1205
0
801
1425
1332
1604
1027
1237
1034
2404
Denver
1991
1050
801
0
1174
2057
1780
836
1411
1765
1373
Los Angeles
3036
2112
1425
1174
0
2757
2825
398
2456
403
1919
Miami
1539
1390
1332
2057
2757
0
1258
2359
1250
3097
3389
New York
213
840
1604
1780
2825
1258
0
2442
386
3036
2900
11
12
13
14
15
16
17
18
19
20
New York
213
840
1604
1780
2825
1258
0
2442
386
3036
2900
Phoenix
2664
1729
1027
836
398
2359
2442
0
2073
800
1482
Pisburgh
792
457
1237
1411
2456
1250
386
2073
0
2653
2517
San Francisco
2385
2212
1765
1034
403
3097
3036
800
2653
0
817
Seale
2612
2052
2404
1373
1919
3389
2900
1482
2517
817
0
Indexes of 
e
t
u
o
R
s
eitic
 to travel
Range names used:
City
Index
Index
Distance
Distance_matrix
=Model!$B$5:$L$15
9
2
$
D
$:0
2
$
D
$
!le
d
o
M
=
e
t
u
o
R
0
0
n
o
ts
o
B
Chicago
1
6
213
Total_distance
=Model!$B$32
21
22
23
24
25
26
27
28
29
30
g
_
$ $
Dallas
2
8
386
Denver
3
1
457
Los Angeles
4
3
1050
Miami
5
10
1373
New York
6
9
817
Phoenix
7
4
403
Pisburgh
8
7
398
San Francisco
9
2
1027
Seale
10
5
1332
0
1539
30
31
32
0
1539
Total distance
8995
Figure 8.34
Traveling Salesperson Model
1
Distance matrix. Enter the distance matrix in the blue range.
2
Index cities. The cities need to be referenced by numerical indexes rather than names,
so enter appropriate indexes in the range B19:B29. These indexes are based on alphabetical
order, but any order could be used. Still, it is convenient to index the home city, Boston, as 0.
3
Specify route. Enter any route in the Route range. Note that 0 is entered in cells B19
and B30 because the route must start and end in Boston. However, the numbers in between
can be any permutation of the numbers 1 through 10. This Route range becomes the chang-
ing cell range.
4
Calculate distances. To calculate the distances on the various legs of the trip, you
can use the INDEX function to perform a lookup in the distance matrix. Specifically, enter
the formula
=INDEX(Distance_matrix,D19+1,D20+1)
in cell E20 and copy it down to cell E30. This formula looks up the appropriate dis-
tance in the distance matrix. (The 1s are necessary because the cities are indexed
from 0 to 10, not from 1 to 11.) Then calculate the total distance in cell B32 with the
SUM function.
In models such as this,
where a solution is a
list of indexes, the
INDEX and/or
VLOOKUP functions
are very handy.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

USING EVOLUTIONARY SOLVER
The Solver dialog box should be set up as shown in Figure 8.35. The objective is to mini-
mize the total distance traveled, subject to the constraints that all indexes on the route
(other than Boston’s) are between 1 and 10, and they must be all different. Specifying this
“AllDifferent” constraint is similar to specifying an integer or binary constraint. When you
choose Evolutionary Solver, a “dif” option is available when you add a constraint. (See
Figure 8.36.) It is useful in exactly this type of model, where the numbers in a permutation
must all be different.
8.10 The Traveling Salesperson Problem
467
Figure 8.35
Solver Dialog Box
with the AllDifferent
Constraint
Figure 8.36
Specifying an 
AllDifferent 
Constraint
Discussion of the Solution
The optimal solution appears in Figure 8.34. Willie should go from Boston to New York to
Pittsburgh to Chicago to Denver to Seattle to San Francisco to Los Angeles to Phoenix to
Dallas to Miami and finally to Boston. Essentially, Willie should travel around the country
in a counter clockwise manner. The distance of this route is 8995 miles. Is this solution
unique? It definitely is not. Willie could travel in a clockwise direction instead: Boston to
Miami to Dallas and so on. Because the distance matrix is symmetric, this clockwise route
is bound to have the same total distance as the counterclockwise route. 
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Other Uses for the AllDifferent Constraint
We introduced the alldifferent constraint in the context of the traveling salesperson prob-
lem, but it has applications in many other problems. Specifically, it can be used in any
model where the solution is defined by a permutation of integers from 1 to n. You are asked
to explore some possibilities in the problems.
■
468
Chapter 8
Evolutionary Solver: An Alternative Optimization Procedure
Sequence-Dependent Scheduling at Baxter International
Two of the problems discussed in this chapter, cluster analysis and the traveling salesper-
son problem, do not appear to have much in common. However, Moss et al. (2000)
describe how they used both of these methodologies to sequence products through produc-
tion at Baxter International, a large manufacturer of medical supplies. The problem is to
reduce setup costs and setup time. Each product in its intravenous (IV) class of products
requires a set of components to be present on the production line, and some of these com-
ponents are common to various products. When production of one product follows the pro-
duction of another product, components for the previous product not used by the new
product have to be repackaged and stored, and components required by the new product
but not used by the previous product have to be set up. Therefore, it makes sense to sched-
ule products that use common components next to one another. The authors attacked this
problem with cluster analysis (find clusters of products that are similar in terms of the
components they require) and the traveling salesperson problem (find a permutation of the
products to schedule through production). They estimate that their study saved Baxter
about $165,000 annually by reducing setup times. ■
ADDITIONAL APPLICATIONS
P R O B L E M S
Skill-Building Problems
20. An important problem in operations management is the
job sequencing problem. Actually, there are many
versions of this problem, but they all basically attempt
to find the proper sequencing of jobs on a machine.
Here is one version of the problem. There are 10 jobs to
perform on a single machine. Each job has a given
batch size (items to produce), and each item in the
batch takes a certain time to perform. Also, each job
(the whole batch) has a given due date. These data are
listed in the file P08_20.xlsx. The “lateness” of any job
is 0 if the job is finished on or before its due date, but it
is the finish time minus the due date otherwise. The
objective is to sequence the jobs to minimize the total
lateness. Use Evolutionary Solver to find an optimal
sequence of jobs.
21. The traveling salesperson problem is notoriously diffi-
cult when the number of cities is even of moderate
size. The file P08_21.xlsx contains two sheets, one
with a distance matrix for a 30-city problem and the
other with a distance matrix for a 45-city problem. See
whether Evolutionary Solver can successfully solve
these problems. How will you know if it is successful?
Skill-Extending Problems
22. Repeat Problem 20, but now assume there is a setup time
for changing from any job to another job, and this setup
time can depend on the jobs. For example, the setup time
when changing from job 2 to job 4 can be different from
the setup time when changing from job 3 to job 4. The
data from Problem 20, plus the setup times, are listed in
the file P08_22.xlsx. Use Evolutionary Solver to find an
optimal sequence of jobs.
23. You are operating a Web site to match up sellers and
buyers of a product. 35 sellers and 35 buyers have input
their reservation prices, as listed in the file P08_23.xlsx.
For example, buyer 1 is willing to pay up to $8 for an
item, and seller 1 is willing to accept $9 or more
for an item. This means that buyer 1 and seller
1 cannot be matched. Suppose the goal is to pair buy-
ers with sellers to maximize the sum of buyers’ and
sellers’ surplus. For example, if buyer 31 and seller 31
are matched, a deal can be made by splitting the differ-
ence with a price of $57. Then buyer 31 earns a sur-
plus of 60  57  $3, and seller 31 earns a surplus of
57  54  $3. What is the maximum sum of buyers’
and sellers’ surplus that can be obtained?
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

24. The 30 teams in the NBA are each assigned to one of
six divisions, where each division has five teams.
Suppose the goal is to assign the teams to divisions so
that the average distance among teams in the divisions
is minimized. In other words, the goal is to make the
assignments so that teams within a division are close
to one another. The file P08_24.xlsx contains dis-
tances between all NBA cities. (Actually, this was
before the Seattle SuperSonics switched to Oklahoma
City.) Use Evolutionary Solver to find an optimal
assignment of teams to divisions. Does it turn out that
your assignments to divisions are the same as the
NBA’s? (Hint: Arrange the 30 teams into six contigu-
ous blocks of five teams each. Each block will have
five team indexes. With an AllDifferent constraint, you
can ensure that the 30 team indexes are all different.
For each block, use lookups to find all distances
between pairs of teams in that block and average
these. Then average these averages over the six divi-
sions to obtain the objective value.)
8.11 Conclusion
469
8.11 CONCLUSION
This chapter contains cutting-edge material. The Simplex LP and GRG Nonlinear Solvers
have been available for several years to solve many linear, integer, and nonlinear problems.
However, they have not been able to solve the types of problems discussed in this chapter,
except possibly by employing tricks or by using a lucky initial solution. With Evolutionary
Solver now available to a large audience, a much wider variety of problems can be solved,
and the spreadsheet models are usually straightforward—they do not require tricks.
Evolutionary Solver is typically much slower than other Solver algorithms, especially for
linear models with many constraints, because it uses a totally different search procedure.
Because of this, we do not recommend that you try Evolutionary Solver unless your model
contains functions such as IF, COUNT, COUNTIF, SUMIF, MIN, MAX, and ABS that the
other Solvers cannot handle reliably. But if your model is formulated more naturally by
using such functions, or if you can think of no other way of formulating it, then
Evolutionary Solver can be very useful.
Summary of Key Management Science Terms
Term
Explanation
Page
Genetic algorithm (GA)
Optimization search procedure that mimics the theory of 
425
evolution, using crossovers, mutations, and the survival 
of the fittest
Penalties
Often used in Evolutionary Solver models to handle 
428
constraints; penalties are included in objective for 
violating constraints
Two-part tariff
One of several pricing schemes that can be used to 
432
increase revenue; includes a fixed price and a variable price
Surplus value 
Value to customer of purchasing product minus purchase cost;
433
(to customer)
assumption is that customer purchases the amount that 
maximizes surplus value
Combinatorial problems
Optimization problems where there are a finite number of 
438
feasible solutions (combinations); often difficult because this 
finite number is huge
Cluster analysis
General method of grouping people, products, cities, and so 
455
on, so that members within a cluster are similar and members 
in different clusters are dissimilar
(continued)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Summary of Key Management Science Terms
(Continued)
Term
Explanation
Page
Discriminant analysis
One (of several) methods used to classify people, products, cities,
461
and so on, into well-defined groups based on data about the members
Traveling salesperson 
Famously difficult management science problem; tries to find
464
problem
optimal route for a salesperson who starts and ends in a given 
city and visits all other cities exactly once
Summary of Key Excel Terms
Term
Explanation
Excel
Page
Evolutionary Solver
Solver’s implementation 
Start up Solver, choose
426
of GA (in Excel 2010 only)
Evolutionary item
Evolutionary Solver 
Various settings that control the
Choose Solver Options,
430
settings
way the GA works (see text for details)
then Evolutionary tab 
AllDifferent constraint Type of constraint available in 
One of several options for
465
Evolutionary Solver; useful for 
constraint type in Add
models where potential solutions are
Constraint dialog box
permutations of integers 1 through n
470
Chapter 8
Evolutionary Solver: An Alternative Optimization Procedure
P R O B L E M S
Skill-Building Problems
25. Fourteen jobs must be assigned to one of three
identical machines. The goal is to minimize the
total time needed to complete all 14 jobs. The machine
capacities and times needed for the jobs are given in
file P08_25.xlsx. For example, job 8 requires three
units of capacity on a machine for two hours. At any
given time, a machine has five units of capacity. How
should the jobs be assigned to machines to achieve the
earliest possible completion of all jobs?
26. Nine jobs need to be completed within eight weeks.
The number of weeks required to complete each
job is given in the file P08_26.xlsx. For example,
job 2 requires three weeks. Each job requires 40
hours of labor per week. Each week, 160 hours of
regular time labor are available. Up to 40 hours of
overtime labor can be purchased each week at a
cost of $10 per hour. Additional overtime hours
cost $20 per hour.
a. Determine how to minimize the overtime cost
incurred in completing the jobs within eight weeks.
b. The same file also lists the due date for each job.
For example, job 2 should be completed within six
weeks. A penalty of $500 is incurred for each day a
job is late. Determine how to minimize the sum of
overtime and due date penalties.
27. Eight students need to be assigned to four dorm
rooms (two students to a room) at State University.
Based on incompatibility measures, the “cost” incurred
if two students room together is shown in the file
P08_27.xlsx. How should these students be assigned to
rooms to minimize the total incompatibility?
28. The costs of producing product A, product B, or prod-
ucts A and B bundled together are $50, $90, and $140,
respectively. The file P08_28.xlsx lists the sizes of the
three market segments for these products and how
much each of the segments is willing to pay for
A alone, B alone, or the bundle. Under the assump-
tions that a market segment will buy the product
combination that yields the maximum nonnegative
surplus (value minus cost), and a segment will buy
no product if no product has a nonnegative surplus,
determine an optimal set of product prices. Should the
company offer all products for sale?
29. Cook County needs to build two hospitals. There are
nine cities where the hospitals can be built. The num-
ber of hospital visits made annually by the inhabitants
of each city and the x and y coordinates of each city
are listed in the file P08_29.xlsx. To minimize the
total distance that patients must travel to hospitals,
where should the hospitals be located? Solve the prob-
lem when people can travel in straight lines (“as the
crow flies”) between cities. Then solve it when people
must travel along a horizontal/vertical grid of roads.
(Hint: Use lookup functions to generate the distances
between each pair of cities.)
30. The file P08_30.xlsx contains quarterly revenue for
Nike for the years 1991 to 1998. It also contains
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

8.11 Conclusion
471
quarterly “indicator” variables Q1, Q2, and Q3. Here
Q1 is 1 for the first quarter of a fiscal year
(July–September) and 0 otherwise. Q2 and Q3 are
defined similarly for the second and third quarters of
the fiscal year (October–December and
January–March). The “Quarter #” variable is simply
the chronological number of the quarter, 1 to 32. The
goal is to build a quantitative model to explain the
variation in quarterly revenue. A reasonable model is
as follows:
Predicted Sales  abQuarter#cQ1dQ2eQ3
where a, b, c, d, and e are parameters to estimate.
a. Find the values of a, b, c, d, and e that best fit this
model.
b. What does your model say about the trend and
seasonal aspects of Nike sales? (Hint: The trend
effect is captured by the term involving Quarter #.
Seasonal effects may be interpreted relative to the
quarter, Q4, that we have omitted from the
analysis.)
31. Music radio WABC has commercials of the following
lengths (in seconds): 15, 15, 20, 25, 30, 35, 40, 57.
The commercials must be assigned to 60-second
breaks. What is the fewest number of breaks that are
needed to air all of the commercials?
32. A Wall Street firm is trying to package nine mortgages
for sale. The sizes of the mortgages (in thousands of
dollars) are listed in the file P08_32.xlsx. To be sold,
each package must consist of at least $1,000,000 in
mortgages. What is the largest number of packages
that can be created?
33. During the next 12 months, the amounts of electric
power needed (in thousands of kwh) are listed in the
file P08_33.xlsx. This power can be supplied using
four generators. The generating capacity (in thou-
sands of kwh), the operating cost, the startup cost,
and the shutdown cost (all costs in thousands of dol-
lars) are also listed in the same file. At the begin-
ning of month 1, generators 1 and 2 are in
operation. At the end of each month, it is possible to
either shut down an operating generator or start up a
shutdown generator. Find the strategy that mini-
mizes the cost of meeting demand for power during
the next 12 months.
34. Bus 99 serves towns 1 through 10. We assume that
town k is |k – j| miles from town j. The numbers of
people in the towns who want to take the bus each
hour are listed in the file P08_34.xlsx. Bus 99 will
make two stops and anyone who wants to take the bus
will walk to the closest bus stop.
a. If the goal is to minimize the total distance people
walk, where should the bus stop?
b. If the bus is allowed to make three stops, how
much will the total walking distance be reduced?
35. Ten data sets must be assigned for storage to one of
three disk drives. Each disk drive can store 25 GB
(about 25,000 MB). The sizes of the data sets (in MB)
are listed in the file P08_35.xlsx. When many people
access a disk drive, there is a significant reduction in the
speed at which the data are retrieved. To reduce the
number of people accessing a disk drive, the goal is to
make the data sets on each disk drive as different as
possible. To achieve this goal, penalties have been
assigned for assigning similar data sets to the same disk
drive. These penalties are isted in the same file. For
example, if data sets 9 and 10 are assigned to the same
drive, a penalty of 221 is incurred, whereas if disks 8
and 10 are assigned to the same drive, a penalty of only
35 is incurred. You can think of the penalty as the num-
ber of times two data sets are accessed at the same time.
Assign the data sets to disk drives to minimize total
penalties.
36. Xerox is trying to determine how many maintenance
centers are needed in the mid-Atlantic states. Xerox
earns $500 profit (excluding the cost of running
maintenance centers) on each copier sale. The sales
of copiers in each major market (Boston, New York,
Philadelphia, Washington, Providence, and Atlantic
City) depend on the proximity of the nearest
maintenance facility. If a maintenance facility is
within 100 miles of a city, sales will be high; if a
maintenance facility is within 150 miles of a city,
sales will be medium; otherwise, sales will be low.
The predicted annual sales (that is, the meaning of
low, medium, and high) are listed in the file
P08_36.xlsx. It costs $200,000 per year to place a
maintenance representative in a city. It is possible to
locate a representative in any city except for Atlantic
City and Providence. The distances between the cities
are listed in the same file. Where should maintenance
representatives be located?
Skill-Extending Problems
37. You are the Democratic campaign manager for the
state of Indiana. There are 15 fairly large cities in the
state of Indiana. The numbers of Democrats and
Republican voters in these cities (in thousands) are
listed in the file P08_37.xlsx. The Democrats control
the state legislature, so they can redistrict as they wish.
There will be eight congressional districts. Each city
must be assigned in its entirety to a single district.
Each district must contain between 150,000 and
250,000 voters. Use Evolutionary Solver to assign vot-
ers to districts in a way that maximizes the number of
districts that will vote Democratic. (Hint: The SUMIF
function is useful.)
38. A steel manufacturer needs to cool 17 pieces of steel.
The weight and due date for each piece are listed in
the file P08_38.xlsx. Processing and cooling a batch in
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

the furnace takes five minutes regardless of the weight
in the furnace. The furnace can handle up to 1000
pounds at a time. Jobs 6 and 7 (size 640 and 450,
respectively) must be completed on time. How can the
company minimize the total time the jobs are late?
39. Suppose you are the ad manager for Fox NFL football.
Thirty bids for ads on today’s game between the
Packers and the Colts have been submitted.
Information on these ads is given in the file
P08_39.xlsx. For example, ad 1 is 23 seconds in
length and will bring in $53,000 in revenues. During
the game, 14 one-minute slots are available for ads.
Determine how Fox can maximize the revenue earned
from game ads.
40. Assume that a consumer’s purchase decision on an
electric razor is based on four attributes, each of which
can be set at one of three levels (1, 2, or 3). Using con-
joint analysis (a type of analysis used in marketing
research), our analysts have divided the market into
five segments (labeled as customers 1, 2, 3, 4, and 5)
and have determined the “part-worth” that each cus-
tomer gives to each level of each attribute. These are
listed in the file P08_40.xlsx. Conjoint analysis usu-
ally assumes the customer buys the product yielding
the highest total part-worth. Currently there is a single
product in the market that sets all four attributes equal
to 1. You are going to sell two types of electric razors.
Design a product line that maximizes the number of
market segments that will buy your product. For
example, if you design a product that is level 2 of each
attribute, then customer 1 will not buy the product
because he values the current product at 1  4  4  4 
13 and values your product at 1  1  1  2  5.
Assume that in the case of a tie, the consumer does
not purchase your product.
41. An important problem in manufacturing is the assem-
bly line balancing problem. When setting up a manu-
facturing line, activities must be assigned to
workstations. The maximum time spent at a worksta-
tion is called the cycle time. Minimizing the cycle
time translates to maximizing the number of items that
can be produced each hour. Here is a typical assembly
line balancing problem that can be solved with the
Evolutionary Solver. Manufacture of a product con-
sists of 10 activities (A–J) that require the times (in
seconds) in the file P08_41.xlsx to complete. Certain
activities must be completed before others. These
precedence relations are also given in the same file.
For example, activity A cannot be performed on a
higher numbered workstation than activity B. Use
Evolutionary Solver to determine an assignment of
activities to workstations that minimizes the total cycle
time.
42. A common approach to clustering is called multidi-
mensional scaling (MDS). To apply MDS, we rank
each pair of objects we want to cluster from least simi-
lar (higher number) to most similar (lower number).
For example, in the file P08_42.xlsx, we compared the
similarity of 10 banks and found banks 5 and 10 to be
most similar and banks 9 and 10 to be least similar.
We now assign a location in the x-y plane to each
bank. The goal is to ensure that when we rank the dis-
tances between pair of banks, the ordering of these
distances matches (as closely as possible) the similar-
ity rankings of the banks.
a. Constrain each bank to have an x and y coordinate
between 1 and 1 and determine the “location”
of each bank. (Hint: Use Excel’s RANK function
to rank the distances from smallest to largest.)
b. How does this method lead to a natural clustering
of banks?
c. How could you determine whether you need more
than two dimensions to adequately locate the
banks?
43. Based on Meneses et al. (2004). A string is a list of
characters such as “1differ%”. The length of the string
is the number of characters in the string. The distance
between two strings is the number of positions in
which the two strings differ. For example, the distance
between the strings “1differ%” and “1dizzzr%” is 3.
Given a set of strings of the same length, the closest
string problem is to find a string of the same length
that minimizes the maximum distance between the
chosen string and the given list of strings. Consider the
following four strings: “median,” “differ,” “length,”
and “medium,” all with six characters. Find a closest
string to these strings. (Hint: There are many
alternative solutions.)
44. A company has nine jobs that must be assigned to
three ordered workstations. The file P08_44.xlsx lists
the times required for each job, which are independent
of the workstations they are assigned to. It also lists
precedence relationships between the jobs. For exam-
ple, job 2 is a precedent of job 5. This means that job 2
cannot be assigned to a higher-numbered workstation
than job 5. Note that job 6 has two precedents, jobs 3
and 4, which means that neither of jobs 3 and 4 can be
assigned to a higher-numbered workstation than job 6.
The cycle time of the system is the maximum time
load assigned to any workstation. Find an assignment
of jobs to workstations that minimizes the cycle time
without violating any of the precedence relationships.
45. Suppose you are the new supply manager at FedEx.
You need to choose three hubs for the company. Each
of 28 cities will send all of its outgoing packages to
one of the hubs. The packages will then be sent from
the hubs to their final destinations. The file
P08_45.xlsx lists the distances between cities and the
number of packages to be sent from each city to each
other city. Each hub, regardless of its location, can
472
Chapter 8
Evolutionary Solver: An Alternative Optimization Procedure
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

handle at most 1600 packages. Where should the hubs
be located (they must be located in three of the 29
cities), and which cities should be assigned to which
hubs, to minimize the total distance the shipments
travel?
Modeling Problems
46. The discussion at the beginning of section 8.8 men-
tions Claritas. If you were in the direct-mail business,
how would you use the information sold by Claritas to
improve your profitability?
47. How would you use cluster analysis to help test mar-
ket a consumer goods product?
48. Your company sells credit card services, and you are
concerned with churn. (Churn occurs when your cus-
tomers go to a different company.) Describe how you
could use discriminant analysis to learn what distin-
guishes the customers who switch to another company
from those who stay loyal to your company. How
might you use such a model?
49. Your company provides credit to customers. Some of
these customers default on their loans, with very nega-
tive implications for you. Describe how you could use
discriminant analysis to learn what distinguishes the
customers who default on their loans from those who
pay back their loans. How might you use such a
model?
8.11 Conclusion
473
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

C A S E
T
he MBA program at State University has approxi-
mately 260 incoming students each fall semester.
These students are divided into cohorts of approxi-
mately 65 students each, and the students in each
cohort sit through exactly the same set of fall
courses together. Much of the work in these courses
is done in teams. To ensure that the teams are com-
parable, the MBA Office tries to divide the students
in each cohort into 14 teams so that each team has
the following qualities:
■
Four or five members
■
At least one member with a CPA
■
At least one member with quantitative expertise
■
At least one female
■
At least one minority student
■
At least one international student
The file MBA Teams.xlsxindicates the charac-
teristics of the students in a particular cohort of this
year’s incoming class. Your job is to use the
Evolutionary Solver to see if you can create teams
that have all of the desired properties. It is not clear
whether this will be possible—for example, there
might not be enough minority students for each
team—so you should create penalties for failing to
meet the various goals, where the penalties can be
different for different goals. ■
8.1 ASSIGNING MBA STUDENTS TO TEAMS
474
Chapter 8
Evolutionary Solver: An Alternative Optimization Procedure
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

475
Decision Making under Uncertainty
C H A P T E R
DECIDING W
 
HETHER T O DEVELOP NEW DR    UGS
AT BAYER
T
he formal decision-making process discussed in this chapter is often used to
make difficult decisions in the face of much uncertainty,large monetary
values,and long-term consequences.Stonebraker (2002) chronicles one such
decision-making process he performed for Bayer Pharmaceuticals in 1999.
The development of a new drug is a time-consuming and expensive process that
is filled with risks along the way. A pharmaceutical company must first get the
proposed drug through preclinical trials,where the drug is tested on animals.
Assuming this stage is successful (and only about half are),the company can then
file an application with the Food and Drug Administration (FDA) to conduct
clinical trials on humans.These clinical trials have three phases.Phase 1 is designed
to test the safety of the drug on a small sample of healthy patients.Phase 2 is
designed to identify the optimal dose of the new drug on patients with the
disease.Phase 3 is a statistically designed study to prove the efficacy and safety of
the new drug on a larger sample of patients with the disease.Failure at any one of
these phases means that further testing stops and the drug is never brought to
Reicaden/www.shutterstock.com
9
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

market.Of course,this means that all costs up to the failure point are lost.If the drug makes it
through the clinical tests (and only about 25% of all drugs do so),the company can then apply
to the FDA for permission to manufacture and market its drug in the United States. Assuming
that FDA approves,the company is then free to launch the drug in the marketplace.
The study involved the evaluation of a new drug for busting blood clots called BAY 
57-9602,and it commenced at a time just prior to the first decision point:whether to conduct
preclinical tests.This was the company’s first formal use of decision making for evaluating a
new drug,so to convince the company of the worth of such a study,Stonebraker did exactly
what a successful management scientist should do.He formulated the problem and its
objectives;he identified risks,costs,and benefits;he involved key people in the organization to
help provide the data needed for the decision analysis;and,because much of the resulting data
consisted of educated guesses at best,he performed a thorough sensitivity analysis on the
inputs. Although we are not told in the article how everything turned out,the analysis did
persuade Bayer management to proceed in January 2000 with preclinical testing of the drug.
The article provides a fascinating look at how such a study should proceed. Because
there is so much uncertainty, the key is determining probabilities and probability distribu-
tions for the various inputs. First, there are uncertainties in the various phases of testing.
Each of these can be modeled with a probability of success. For example, the chance 
of making it through preclinical testing was assessed to be about 65% for BAY 57-9602,
although management preferred to use the more conservative benchmark of 50% (based 
on historical data on other drugs) for the decision analysis. Many of the other uncertain
quantities, such as the eventual market share, are continuous random variables. Because the
decision tree approach discussed in this chapter requires discrete random variables, usually
with only a few possible values, Stonebraker used a popular three-point approximation for
all continuous quantities. He asked experts to assess the 10th percentile, the 50th per-
centile, and the 90th percentile, and he assigned probabilities 0.3, 0.4, and 0.3 to these three
values. [The validity of such an approximation is discussed in Keefer and Bodily (1983).]
After getting all such estimates of uncertain quantities from the company experts,
the author examined the expected net present value (NPV) of all costs and benefits from
developing the new drug.To see which of the various uncertain quantities affected the
expected NPV most, he varied each such quantity, one at a time, from its 10th percentile
to its 90th percentile, leaving the other inputs at their base 50th percentile values.This
identified several quantities that the expected NPV was most sensitive to, including the
peak product share, the price per treatment in the United States, and the annual growth
rate.The expected NPV was not nearly as sensitive to other uncertain inputs, including
the product launch date and the production process yield.Therefore, in the final decision
analysis, Stonebraker treated the sensitive inputs as uncertain and the less sensitive inputs
as certain at their base values. He also calculated the risk profile from developing the drug.
This indicates the probability distribution of NPV, taking all sources of uncertainty into
account. Although this risk profile was not exactly optimistic (90% chance of losing money
using the conservative probabilities of success, 67% chance of losing money with the more
optimistic product-specific probabilities of success), this risk profile compared favorably
with Bayer’s other potential projects.This evaluation, plus the rigor and defensibility of the
study, led Bayer management to give the go-ahead on preclinical testing. ■
476
Chapter 9
Decision Making under Uncertainty
9.1 INTRODUCTION
This chapter provides a formal framework for analyzing decision problems that involve
uncertainty. Our discussion includes the following:
■
criteria for choosing among alternative decisions
■
how probabilities are used in the decision-making process
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

■
how early decisions affect decisions made at a later stage
■
how a decision maker can quantify the value of information
■
how attitudes toward risk can affect the analysis
Throughout, we employ a powerful graphical tool—a decision tree—to guide the analysis.
A decision tree enables a decision maker to view all important aspects of the problem at
once: the decision alternatives, the uncertain outcomes and their probabilities, the economic
consequences, and the chronological order of events. We show how to implement decision
trees in Excel by taking advantage of a very powerful and flexible add-in from Palisade
called PrecisionTree.
Many examples of decision making under uncertainty exist in the business world,
including the following:
■
Companies routinely place bids for contracts to complete a certain project within a fixed
time frame. Often these are sealed bids, where each company presents a bid for complet-
ing the project in a sealed envelope. Then the envelopes are opened, and the low bidder
is awarded the bid amount to complete the project. Any particular company in the bid-
ding competition must deal with the uncertainty of the other companies’ bids, as well as
possible uncertainty regarding their cost to complete the project if they win the bid. The
trade-off is between bidding low to win the bid and bidding high to make a larger profit.
■
Whenever a company contemplates introducing a new product into the market, there
are a number of uncertainties that affect the decision, probably the most important
being the customers’ reaction to this product. If the product generates high customer
demand, the company will make a large profit. But if demand is low—and, after all,
the vast majority of new products do poorly—the company could fail to recoup its
development costs. Because the level of customer demand is critical, the company
might try to gauge this level by test marketing the product in one region of the
country. If this test market is a success, the company can then be more optimistic that
a full-scale national marketing of the product will also be successful. But if the test
market is a failure, the company can cut its losses by abandoning the product.
■
Whenever manufacturing companies make capacity expansion decisions, they face
uncertain consequences. First, they must decide whether to build new plants. If they
don’t expand and demand for their products is higher than expected, they will lose
revenue because of insufficient capacity. If they do expand and demand for their
products is lower than expected, they will be stuck with expensive underutilized
capacity. Of course, in today’s global economy, companies also need to decide
where to build new plants. This decision involves a whole new set of uncertainties,
including exchange rates, labor availability, social stability, competition from local
businesses, and others.
■
Banks must continually make decisions on whether to grant loans to businesses or
individuals. As we all know, many banks made many very poor decisions, especially
on mortgage loans, during the years leading up to the financial crisis in 2008. They
fooled themselves into thinking that housing prices would only increase, never
decrease. When the bottom fell out of the housing market, banks were stuck with
loans that could never be repaid. 
■
Utility companies must make many decisions that have significant environmental and
economic consequences. For these companies it is not necessarily enough to conform to
federal or state environmental regulations. Recent court decisions have found companies
liable—for huge settlements—when accidents occurred, even though the companies
followed all existing regulations. Therefore, when utility companies decide, say, whether
to replace equipment or mitigate the effects of environmental pollution, they must take
into account the possible environmental consequences (such as injuries to people) as
9.1 Introduction
477
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

well as economic consequences (such as lawsuits). An aspect of these situations that
makes decision analysis particularly difficult is that the potential “disasters” are often
extremely unlikely; hence, their probabilities are difficult to assess accurately.
■
Sports teams continually make decisions under uncertainty. Sometimes these
decisions involve long-run consequences, such as whether to trade for a promising
but as yet untested pitcher in baseball. Other times these decisions involve short-run
consequences, such as whether to go for a fourth down or kick a field goal late in a
close football game. You might be surprised at the level of quantitative sophistication
in professional sports these days. Management and coaches typically do not make
important decisions by gut feel. They employ many of the tools in this chapter and
in other chapters of this book. 
9.2 ELEMENTS OF DECISION ANALYSIS
Although decision making under uncertainty occurs in a wide variety of contexts, all prob-
lems have three common elements: (1) the set of decisions (or strategies) available to the
decision maker, (2) the set of possible outcomes and the probabilities of these outcomes,
and (3) a value model that prescribes monetary values for the various decision-outcome
combinations. Once these elements are known, the decision maker can find an optimal deci-
sion, depending on the optimality criterion chosen.
Before moving on to realistic business problems, we discuss the basic elements of any
decision analysis for a very simple problem. We assume that a decision maker must choose
among three decisions, labeled D1, D2, and D3. Each of these decisions has three possible
outcomes, labeled O1, O2, and O3.
9.2.1 Payoff Tables
At the time the decision must be made, the decision maker does not know which outcome
will occur. However, once the decision is made, the outcome will eventually be revealed,
and a corresponding payoff will be received. This payoff might actually be a cost, in which
case it is indicated as a negative value. The listing of payoffs for all decision–outcome
pairs is called the payoff table.1 For our simple decision problem, this payoff table appears
in Table 9.1. For example, if the decision maker chooses decision D2 and outcome O3 then
occurs, a payoff of $30 is received.
478
Chapter 9
Decision Making under Uncertainty
1In situations where all monetary consequences are costs, it is customary to list these costs in a cost table. In this
case, all monetary values are shown as positive costs. 
A payoff table lists the payoff for each decision-outcome pair. Positive values corre-
spond to rewards (or gains) and negative values correspond to costs (or losses).
Table 9.1
Payoff Table for Simple Decision Problem
Outcome
O1
O2
O3
Decision
D1
10
10
10
D2
10
20
30
D3
30
30
80
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

This table shows that the decision maker can play it safe by choosing decision D1.
This provides a sure $10 payoff. With decision D2, rewards of $20 or $30 are possible, but
a loss of $10 is also possible. Decision D3 is even riskier; the possible loss is greater, and
the maximum gain is also greater. Which decision would you choose? Would your choice
change if the values in the payoff table were measured in thousands of dollars? The
answers to these questions are what this chapter is all about. There must be a criterion for
making choices, and this criterion must be evaluated so that the best decision can be
identified. As you will see, it is customary to use one particular criterion for decisions
involving moderate amounts of money.
Before proceeding, there is one very important point we need to emphasize: the
distinction between good decisions and good outcomes. In any decision-making problem
where there is uncertainty, the “best” decision can have less than optimal results—that is,
you can be unlucky. Regardless of which decision you choose, you might get an outcome
that, in hindsight, makes you wish we had made a different decision. For example, if you
make decision D3, hoping for a large reward, you might get outcome O1, in which case
you will wish you had chosen decision D1 or D2. Or if you choose decision D2, hoping to
limit possible losses, you might get outcome O3, in which case you will wish you had cho-
sen decision D3. The point is that decision makers must make rational decisions, based on
the information they have when the decisions must be made, and then live with the conse-
quences. Second-guessing these decisions, just because of bad luck with the outcomes, is
not appropriate.
9.2 Elements of Decision Analysis
479
A decision maker gets
to decide which row of
the payoff table she
wants. However, she
does not get to choose
the column.
FUNDAMENTAL INSIGHT
What Is a “Good” Decision?
In the context of decision making under uncer tainty,
a “good” decision is one that is based on the sound
decision-making principles discussed in this cha pter.
Because the decision m ust usuall y be made bef ore
uncertainty is r esolved, a good decision might ha ve
unlucky consequences.
However, decision mak ers
should not be criticized f or unlucky outcomes. They
should be criticized onl y if their anal ysis at the time
the decision has to be made is faulty.
9.2.2 Possible Decision Criteria
What do we mean when we call a decision the “best” decision? We will eventually settle on
one particular criterion for making decisions, but we first explore some possibilities. With
respect to Table 9.1, one possibility is to choose the decision that maximizes the worst
payoff. This criterion, called the maximin criterion, is appropriate for a very conservative
(or pessimistic) decision maker. The worst payoffs for the three decisions are the minimums
in the three rows: 10, 10, and 30. The maximin decision maker chooses the decision
corresponding to the best of these: decision D1 with payoff 10. Such a criterion tends to
avoid large losses, but it fails to even consider large rewards. Hence, it is typically too
conservative and is seldom used.
The maximin criterion finds the worst payoff in each row of the payoff table and
chooses the decision corresponding to the best of these.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

At the other extreme, the decision maker might choose the decision that maximizes
the best payoff. This criterion, called the maximax criterion, is appropriate for a risk taker
(or optimist). The best payoffs for the three decisions are the maximums in the three rows:
10, 30, and 80. The maximax decision maker chooses the decision corresponding to the
best of these: decision D3 with payoff 80. This criterion looks tempting because it focuses
on large gains, but its very serious downside is that it ignores possible losses. Because this
type of decision making could eventually bankrupt a company, the maximax criterion is
also seldom used.
480
Chapter 9
Decision Making under Uncertainty
The maximin and
maximax criteria make
sense in some situa-
tions, but they are
generally not used in
real decision-making
problems.
The maximax criterion finds the best payoff in each row of the payoff table and
chooses the decision corresponding to the best of these.
The expected monetary value, or EMV, for any decision is a weighted average of the
possible payoffs for this decision, weighted by the probabilities of the outcomes. Using
the EMV criterion, you choose the decision with the largest EMV. This is sometimes
called “playing the averages.”
9.2.3 Expected Monetary Value (EMV)
We have introduced the maximin and maximax criteria because (1) they are occasionally
used to make decisions, and (2) they illustrate that there are several “reasonable” criteria
for making decisions. In fact, there are other possible criteria that we will not discuss
(although a couple are explored in the problems). Instead, we now focus on a criterion that
is generally regarded as the preferred criterion in most decision problems. It is called the
expected monetary v alue, or EMV, criterion. To motivate the EMV criterion, we first
note that the maximin and maximax criteria make no reference to how likely the various
outcomes are. However, decision makers typically have at least some idea of these likeli-
hoods, and they ought to use this information in the decision-making process. After all, if
outcome O1 in our problem is extremely unlikely, then the pessimist who uses maximin is
being overly conservative. Similarly, if outcome O3 is quite unlikely, then the optimist who
uses maximax is taking an unnecessary risk.
The EMV approach assesses probabilities for each outcome of each decision and then
calculates the expected payoff from each decision based on these probabilities. This expected
payoff, or EMV, is a weighted average of the payoffs in any given row of the payoff table,
weighted by the probabilities of the outcomes. You calculate the EMV for each decision, then
choose the decision with the largest EMV. (Note that the terms expected payoff and mean
payoff are equivalent. We will use them interchangeably.)
Where do the probabilities come from? This is a difficult question to answer in general
because it depends on each specific situation. In some cases the current decision problem
is similar to those a decision maker has faced many times in the past. Then the probabili-
ties can be estimated from the knowledge of previous outcomes. If a certain type of
outcome occurred, say, in about 30% of previous situations, an estimate of its current prob-
ability might be 0.30.
However, there are many decision problems that have no parallels in the past. In such
cases, a decision maker must use whatever information is available, plus some intuition, to
assess the probabilities. For example, if the problem involves a new product decision, and
one possible outcome is that a competitor will introduce a similar product in the coming
year, the decision maker will have to rely on any knowledge of the market and the
competitor’s situation to assess the probability of this outcome. It is important to note that
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

this assessment can be very subjective. Two decision makers could easily assess the prob-
ability of the same outcome as 0.30 and 0.45, depending on their information and feelings,
and neither could be considered “wrong.” This is the nature of assessing probabilities
subjectively in real business situations. Still, it is important for the decision maker to
consult all relevant sources (historical data, expert opinions, government forecasts, and so
on) when assessing these probabilities. As you will see, they are crucial to the decision-
making process.
With this general framework in mind, let’s assume that a decision maker assesses the
probabilities of the three outcomes in Table 9.1 as 0.3, 0.5, and 0.2 if decision D2 is made,
and as 0.5, 0.2, 0.3 if decision D3 is made.2 Then the EMV for each decision is the sum of
products of payoffs and probabilities:
EMV for D1: 10 (a sure thing)
EMV for D2: 10(0.3)  20(0.5)  30(0.2)  13
EMV for D3: 30(0.5)  30(0.2)  80(0.3)  15
These calculations lead to the optimal decision: Choose decision D3 because it has the
largest EMV.
It is important to understand what the EMV of a decision represents—and what it
doesn’t represent. For example, the EMV of 15 for decision D3 does not mean that you
expect to gain $15 from this decision. The payoff table indicates that the result from D3 will
be a loss of $30, a gain of $30, or a gain of $80; it will never be a gain of $15. The EMV is
only a weighted average of the possible payoffs. As such, it can be interpreted in one of two
ways. First, imagine that this situation can occur many times, not just once. If decision D3
is used each time, then on average, you will make a gain of about $15. About 50% of the
time you will lose $30, about 20% of the time you will gain $30, and about 30% of the time
you will gain $80. These average to $15. For this reason, using the EMV criterion is some-
times referred to as “playing the averages.”
But what if the current situation is a one-shot
deal that will not occur many times in the future?
Then the second interpretation of EMV is still rele-
vant. It states that the EMV is a “sensible” criterion
for making decisions under uncertainty. This is
actually a point that has been debated in intellectual
circles for years—what is the best criterion for
making decisions? However, researchers have gen-
erally concluded that EMV makes sense, even for
one-shot deals, as long as the monetary values are
not too large. For situations where the monetary
values are extremely large, we will introduce
an alternative criterion in the last section of this
chapter. Until then, however, we will use EMV.
This is the gist of decision-making uncertainty.
You develop a payoff table, assess probabilities of
outcomes, calculate EMVs, and choose the decision
with the largest EMV. However, before proceeding
to examples, it is useful to introduce a few other
concepts: sensitivity analysis , decision tr ees, and
risk profiles.
9.2 Elements of Decision Analysis
481
2In a change from the previous edition of this book, we allow these probabilities to depend on the decision that is
made, which is often the case in real decision problems. 
What It Means to Be an EMV Maximiz
er
An EMV maximizer, by definition, is indifferent when
faced with the choice betw
een entering a gamble
that has a cer tain EMV and r eceiving a sur e dollar
amount in the amount of the EMV
. For example ,
consider a gamble where you flip a fair coin and win
$0 or $1000 depending on whether y ou get a head
or a tail. If you are an EMV maximizer, you are indif-
ferent between entering this gamble, which has EMV
$500, and r eceiving $500 f or sur e. Similarly, if the
gamble is betw een losing $1000 and winning $500,
based on the flip of the coin,
and you are an EMV
maximizer, you are indifferent between entering this
gamble, which has EMV $250, and paying a sur e
$250 to avoid the gamble. (This latter scenario is the
basis of insurance.)
FUNDAMENTAL INSIGHT
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

9.2.4 Sensitivity Analysis
Some of the quantities in a decision analysis, particularly the probabilities, are often
intelligent guesses at best. Therefore, it is important, especially in real-world business
problems, to accompany any decision analysis with a sensitivity analysis. Here we
systematically vary inputs to the problem to see how (or if) the outputs—the EMVs and the
best decision—change. For our simple decision problem, this is easy to do in a spreadsheet.
The spreadsheet model is shown in Figure 9.1. (See the file Simple Decision Problem.xlsx.)
482
Chapter 9
Decision Making under Uncertainty
Probabilies
1
2
3
4
5
6
7
8
9
10
11
A
B
C
D
E
F
Simple decision problem under uncertainty
Outcome
O1
O2
O3
EMV
Decision
D1
10
10
10
10
D2
-10
20
30
13
D3
-30
30
80
15
D2
0.3
0.5
0.2
D3
0.5
0.2
0.3
Figure 9.1
Spreadsheet Model
of a Simple Decision
Problem
Usually, the most
important information
from a sensitivity
analysis is whether
the optimal decision
continues to be optimal
as one or more inputs
change.
After entering the payoff table and probabilities, calculate the EMVs in column F as a
sum of products, using the formula
SUMPRODUCT(C6:E6,C10:E10)
in cell F6 and copying it down. (A link to the sure 10 for D1 is entered in cell F5.) Then it
is easy to change any of the inputs and see whether the optimal decision continues
to be D3. For example, you can check that if the probabilities for D3 change only slightly
to 0.6, 0.2, and 0.2, the EMV for D3 changes to 4. Now D3 is the worst decision and D2 is
the best, so it appears that the optimal decision is quite sensitive to the assessed probabili-
ties. As another example, if the probabilities remain the same but the last payoff for D2
changes from 30 to 45, then its EMV changes to 16, and D2 becomes the best decision.
Given a simple spreadsheet model, it is easy to make a number of ad hoc changes to
inputs, as we have done here, to answer specific sensitivity questions. However, it is often
useful to conduct a more systematic sensitivity analysis, as we will do this later in the
chapter. The important thing to realize at this stage is that a sensitivity analysis is not an
afterthought to the overall analysis; it is a key component of the analysis.
9.2.5 Decision Trees
The decision problem we have been analyzing is very basic. You make a decision, you then
observe an outcome, you receive a payoff, and that is the end of it. Many decision prob-
lems are of this basic form, but many are more complex. In these more complex problems,
you make a decision, you observe an outcome, you make a second decision, you observe a
second outcome, and so on. A graphical tool called a decision tree has been developed to
represent decision problems. Decision trees can be used for any decision problems, but
they are particularly useful for the more complex types. They clearly show the sequence of
events (decisions and outcomes), as well as probabilities and monetary values. The deci-
sion tree for the simple problem appears in Figure 9.2. This tree is based on one we drew
and calculated by hand. We urge you to try this on your own, at least once. However, later
in the chapter we will introduce an Excel add-in that automates the procedure.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

To explain this decision tree, we introduce a number of decision tree conventions that
have become standard.
9.2 Elements of Decision Analysis
483
10
13
15
−10
20
30
.3
.5
.2
D1
D2
D3
O1
O2
O3
15
−30
30
80
.5
.2
.3
O1
O2
O3
Figure 9.2
Decision Tree for
Simple Decision
Problem
Decision Tree Conventions
1.
Decision trees are composed of nodes (circles, squares, and triangles) and
branches (lines).
2.
The nodes represent points in time. A decision node (a square) represents
a time when the decision maker makes a decision. A probability node
(a circle) represents a time when the result of an uncertain outcome becomes
known. An end node (a triangle) indicates that the problem is completed—
all decisions have been made, all uncertainty has been resolved, and all 
payoffs and costs have been incurred. (When people draw decision trees
by hand, they often omit the actual triangles, as we have done in Figure 9.2.
However, we still refer to the right-hand tips of the branches as the end
nodes.)
3.
Time proceeds from left to right. This means that any branches leading into a
node (from the left) have already occurred. Any branches leading out of a node
(to the right) have not yet occurred.
4.
Branches leading out of a decision node represent the possible decisions; the
decision maker can choose the preferred branch. Branches leading out of proba-
bility nodes represent the possible outcomes of uncertain events; the decision
maker has no control over which of these will occur.
5.
Probabilities are listed on probability branches. These probabilities are 
conditional on the events that have already been observed (those to the left).
Also, the probabilities on branches leading out of any probability node must
sum to 1.
6.
Monetary values are shown to the right of the end nodes. (As we discuss
shortly, some monetary values are also placed under the branches where they
occur in time.)
7.
EMVs are calculated through a “folding-back” process, discussed next.
They are shown above the various nodes. It is then customary to mark the
optimal decision branch(es) in some way. We have marked ours with a
small notch.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

The decision tree in Figure 9.2 follows these conventions. The decision node comes first
(to the left) because the decision maker must make a decision before observing the uncertain
outcome. The probability nodes then follow the decision branches, and the probabilities
appear above their branches. (Actually, there is no need for a probability node after the D1
branch because its monetary value is a sure 10.) The ultimate payoffs appear next to the end
nodes, to the right of the probability branches. The EMVs above the probability nodes are for
the various decisions. For example, the EMV for the D2 branch is 13. The maximum of the
EMVs is for the D2 branch written above the decision node. Because it corresponds to D3,
we put a notch on the D3 branch to indicate that this decision is optimal.
This decision tree is almost a direct translation of the spreadsheet model in Figure 9.1.
Indeed, the decision tree is overkill for such a simple problem; the spreadsheet model
provides all of the required information. However, decision trees are very useful in
business problems. First, they provide a graphical view of the whole problem. This can be
useful in its own right for the insights it provides, especially in more complex problems.
Second, the decision tree provides a framework for doing all of the EMV calculations.
Specifically, it allows you to use the following folding-back procedure to find the EMVs
and the optimal decision.
484
Chapter 9
Decision Making under Uncertainty
Folding-Back Procedure
Starting from the right of the decision tree and working back to the left:
1. At each probability node, calculate an EMV—a sum of products of monetary
values and probabilities.
2. At each decision node, take a maximum of EMVs to identify the optimal decision.
This is exactly what we did in Figure 9.2. At each probability node, we calculated
EMVs in the usual way (sums of products) and wrote them above the nodes. Then at the
decision node, we took the maximum of the three EMVs and wrote it above this node.
Although this procedure entails more work for more complex decision trees, the same two
steps—taking EMVs at probability nodes and taking maximums at decision nodes—are
the only arithmetic operations required. In addition, the PrecisionTree add-in in the next
section does the folding-back calculations for you.
9.2.6 Risk Profiles
In our small example each decision leads to three possible monetary payoffs with various
probabilities. In more complex problems, the number of outcomes could be larger, maybe
considerably larger. It is then useful to represent the probability distribution of the monetary
values for any decision graphically. Specifically, we show a “spike” chart, where the spikes
are located at the possible monetary values, and the heights of the spikes correspond to the
probabilities. In decision-making contexts, this type of chart is called a risk profile. By
looking at the risk profile for a particular decision, you can see the risks and rewards
involved. By comparing risk profiles for different decisions, you can gain more insight into
their relative strengths and weaknesses.
The folding-back
process is a systematic
way of calculating
EMVs in a decision
tree and thereby
identifying the optimal
decision strategy.
The risk profile for a decision is a “spike” chart that represents the probability
distribution of monetary outcomes for this decision.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

The risk profile for decision D3 appears in Figure 9.3. It shows that a loss of $30 has
probability 0.5, a gain of $30 has probability 0.2, and a gain of $80 has probability 0.3. The
risk profile for decision D2 is similar, except that its spikes are above the values 10, 20,
and 30, and the risk profile for decision D1 is a single spike of height 1 over the value 10.
(The finished version of the Simple Decision Problem.xlsx file provides instructions for
constructing such a chart with Excel tools.)
9.2 Elements of Decision Analysis
485
0
0.1
0.2
0.3
0.4
0.5
0.6
−40
−20
0
20
40
60
80
100
Risk proﬁle for D3
Figure 9.3
Risk Profile for
Decision D3
Note that the EMV for any decision is a summary measure of the complete risk
profile—it is the mean of the corresponding probability distribution. Therefore, when you
use the EMV criterion for making decisions, you are not using all of the information in the
risk profiles; you are comparing only their means. Nevertheless, risk profiles can be useful
as extra information for making decisions. For example, a manager who sees too much risk
in the risk profile of the EMV-maximizing decision might choose to override this decision
and instead choose a somewhat less risky alternative.
We now apply all of these concepts to the following example.
A risk profile shows the
complete probability
distribution of mone-
tary outcomes, but you
typically use only its
mean, the EMV, for
making decisions.
E X A M P L E
9.1 BIDDING FOR A GOVERNMENT CONTRACT AT SCITOOLS
S
ciTools Incorporated, a company that specializes in scientific instruments, has been
invited to make a bid on a government contract. The contract calls for a specific
number of these instruments to be delivered during the coming year. The bids must be
sealed, so that no company knows what the others are bidding, and the low bid wins the
contract. SciTools estimates that it will cost $5000 to prepare a bid and $95,000 to supply
the instruments if it wins the contract. On the basis of past contracts of this type, SciTools
believes that the possible low bids from the competition, if there is any competition, and
the associated probabilities are those shown in Table 9.2. In addition, SciTools believes
there is a 30% chance that there will be no competing bids. What should SciTools bid to
maximize its EMV?
Objective
To develop a decision model that finds the EMV for various bidding strategies
and indicates the best bidding strategy.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

486
Chapter 9
Decision Making under Uncertainty
Table 9.2
Data for Bidding Example
Low Bid
Probability
Less than $115,000
0.2
Between $115,000 and $120,000
0.4
Between $120,000 and $125,000
0.3
Greater than $125,000
0.1
WHERE DO THE NUMBERS COME FROM?
The company has probably done a thorough cost analysis to estimate its cost to prepare a
bid and its cost to manufacture the instruments if it wins the contract. (Actually, even if
there is uncertainty in the manufacturing cost, the only value required for the decision
problem is the mean manufacturing cost.) The company’s estimates of whether, or how, the
competition will bid are probably based on previous bidding experience and some subjec-
tivity. This is discussed in more detail next.
Solution
Let’s examine the three elements of SciTools’s problem. First, SciTools has two basic
strategies: submit a bid or do not submit a bid. If SciTools submits a bid, then it must
decide how much to bid. Based on the cost to SciTools to prepare the bid and supply the
instruments, there is clearly no point in bidding less than $100,000—SciTools wouldn’t
make a profit even if it won the bid. (Actually, this isn’t totally true. Looking ahead to
future contracts, SciTools might make a low bid just to “get in the game” and gain experi-
ence. However, we won’t consider such a possibility here.) Although any bid amount over
$100,000 might be considered, the data in Table 9.2 suggest that SciTools might limit its
choices to $115,000, $120,000, and $125,000.3
The next element of the problem involves the uncertain outcomes and their probabili-
ties. We have assumed that SciTools knows exactly how much it will cost to prepare a bid
and how much it will cost to supply the instruments if it wins the bid. (In reality, these are
probably only estimates of the actual costs, and a follow-up study could perform a
sensitivity analysis on these quantities.) Therefore, the only source of uncertainty is the
behavior of the competitors—will they bid, and if so, how much? From SciTools’s stand-
point, this is difficult information to obtain. The behavior of the competitors depends on
(1) how many competitors are likely to bid and (2) how the competitors assess their costs
of supplying the instruments. Nevertheless, we assume that SciTools has been involved in
similar bidding contests in the past and can reasonably predict competitor behavior from
past competitor behavior. The result of such prediction is the assessed probability distribu-
tion in Table 9.2 and the 30% estimate of the probability of no competing bids.
The last element of the problem is the value model that transforms decisions and
outcomes into monetary values for SciTools. The value model is straightforward in this
example. If SciTools decides not to bid, its monetary value is $0—no gain, no loss. If it
makes a bid and is underbid by a competitor, it loses $5000, the cost of preparing the
bid. If it bids B dollars and wins the contract, it makes a profit of B minus $100,000—
that is, B dollars for winning the bid, minus $5000 for preparing the bid and $95,000 for
supplying the instruments. For example, if it bids $115,000 and the lowest competing
bid, if any, is greater than $115,000, then SciTools wins the bid and makes a profit of
$15,000.
3The problem with a bid such as $117,000 is that the data in Table 9.2 make it impossible to calculate the proba-
bility of SciTools winning the contract if it bids this amount. Other than this, however, there is nothing that rules
out such “in-between” bids.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Developing the Payoff Table
The corresponding payoff table, along with probabilities of outcomes, appears in Table 9.3.
At the bottom of the table, the probabilities of the various outcomes are listed. For example,
the probability that the competitors’ low bid is less than $115,000 is 0.7 (the probability of
at least one competing bid) multiplied by 0.2 (the probability that the lowest competing bid
is less than $115,000).
9.2 Elements of Decision Analysis
487
Table 9.3
Payoff Table for SciTools Bidding Example
Competitors’ Low Bid ($1000s)
No
bid
115
115, 120
120, 125
125
SciTools’ Bid
No
0
0
0
0
0
($1000s)
bid
115
15
5
15
15
15
120
20
5
5
20
20
125
25
5
5
5
25
Probability
0.3
0.7(0.2)  0.14
0.7(0.4)  0.28
0.7(0.3)  0.21 0.7(0.1)  0.07
It is sometimes possible to simplify a payoff table to better understand the essence of
the problem. In the present example, if SciTools bids, the only necessary information about
the competitors’ bid(s) is whether SciTools has the lowest bid. That is, SciTools really only
cares whether it wins the contract. Therefore, an alternative way of presenting the payoff
table is shown in Table 9.4. (See the file SciTools Bidding Decision 1.xlsx for these and
other calculations. However, we urge you to work this problem on a piece of paper with a
calculator, just for practice with the concepts.)
Table 9.4
Alternative Payoff Table for SciTools Bidding Example
Probability That
Monetary Value
SciTools Wins
SciTools Wins
SciTools Loses
No Bid
NA
0
0.00
SciTools’ Bid ($1000s)
115
15
5
0.86
120
20
5
0.58
125
25
5
0.37 
The Monetary Value columns of this table indicate the payoffs to SciTools, depending
on whether it wins or loses the bid. The rightmost column shows the probability that
SciTools wins the bid for each possible decision. For example, if SciTools bids $120,000,
then it wins the bid if there are no competing bids (probability 0.3) or if there are competing
bids and the lowest of these is greater than $120,000 [probability 0.7(0.3  0.1)  0.28].
In this case the total probability that SciTools wins the bid is 0.3  0.28  0.58.
Developing the Risk Profiles
Table 9.4 contains all the required information to obtain a risk profile for each of SciTools’s
decisions. Again, each risk profile indicates all possible monetary values and their correspond-
ing probabilities in a spike chart. For example, if SciTools bids $120,000, there are two mone-
tary values possible, a profit of $20,000 and a loss of $5000, and their probabilities are 0.58 and
0.42, respectively. The corresponding risk profile, shown in Figure 9.4, is a spike chart with two
spikes, one above $5000 with height 0.42 and one above $20,000 with height 0.58. On the
other hand, if SciTools decides not to bid, there is a sure monetary value of $0—no profit, no
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

loss. Therefore, the risk profile for the “no bid” decision, not shown here, has a single spike
above $0 with height 1.
Calculating EMVs
The EMVs for SciTools’s problem are listed in Table 9.5. As always, each EMV (other than
the EMV of $0 for not bidding) is a sum of products of monetary outcomes and probabili-
ties. These EMVs indicate that if SciTools uses the EMV criterion for making its decision,
it should bid $115,000. The EMV from this bid, $12,200, is the largest of the EMVs.
488
Chapter 9
Decision Making under Uncertainty
0.5
0.6
0.7
Risk proﬁle for $120K Bid
0
0.1
0.2
0.3
0.4
($10,000) ($5,000)
$0
$5,000
$10,000
$15,000
$20,000
$25,000
Figure 9.4
Risk Profile for a Bid
of $120,000
Figure 9.5
Decision Tree for
SciTools Bidding
Example
Table 9.5
EMVs for SciTools Bidding Example
Alternative
EMV Calculation
EMV
No bid
0(1)
$0
Bid $115,000
15,000(0.86)  (5000)(0.14)
$12,200
Bid $120,000
20,000(0.58)  (5000)(0.42)
$9500
Bid $125,000
25,000(0.37)  (5000)(0.63)
$6100 
As discussed previously, it is important to understand what an EMV implies and what
it does not imply. If SciTools bids $115,000, its EMV is $12,200. However, SciTools will
definitely not earn a profit of $12,200. It will earn $15,000 or it will lose $5000. The EMV
of $12,200 represents only a weighted average of these two possible values. Nevertheless,
it is the value that is used as the decision criterion. In words, if SciTools is truly an EMV
maximizer, it considers this gamble equivalent to a sure return of $12,200.
Developing the Decision Tree
The corresponding decision tree for this problem is shown in Figure 9.5. This is a direct
translation of the payoff table and EMV calculations. The company first makes a bidding
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

decision, then observes what the competition bids, if anything, and finally receives a
payoff. The folding-back process is equivalent to the calculations shown in Table 9.5.
There are often equivalent ways to structure a decision tree. One alternative for this
example appears in Figure 9.6. This tree shows exactly how the problem unfolds. The
company first decides whether to bid at all. If the company does not make a bid, the profit
is a sure $0. Otherwise, the company then decides how much to bid. Note that if the
company decides to bid, it incurs a sure cost of $5000, so this cost is placed under the Bid
branch. It is a common procedure to place the monetary values on the branches where they
occur in time, and we typically do so. Once the company decides how much to bid, it then
observes whether there is any competition. If there isn’t any, the company wins the bid for
sure and makes a corresponding profit. Otherwise, if there is competition, the company
eventually discovers whether it wins or loses the bid, with the corresponding probabilities
and payoffs. Note that these payoffs are placed below the branches where they occur in
time. Also, the cumulative payoffs are placed at the ends of the branches. Each cumulative
payoff is the sum of all payoffs on branches that lead to that end node.
9.2 Elements of Decision Analysis
489
It is common to place
monetary values 
below the branches
where they occur in
time.
Figure 9.6
Equivalent Decision
Tree for SciTools
Bidding Example
Folding Back the Decision Tree
The folding-back procedure is somewhat more complex than it was for the smaller tree in
Figure 9.5. To illustrate, the nodes in Figure 9.6 have been numbered for reference. The
EMVs above a selected few of these nodes are calculated as follows:
■
Node 7: EMV  20000(0.40)  (5000)(0.60)  $5000 (uses monetary values
from end nodes)
■
Node 4: EMV  20000(0.30)  (5000)(0.70)  $9500 (uses monetary value from
an end node and the EMV from node 7)
■
Node 2: EMV  max(12200, 9500, 6100)  $12,200 (uses EMVs from nodes 3,
4, and 5)
■
Node 1: EMV  max(0, 12200)  $12,200 (uses monetary value from an end node
and EMV from node 2)
The results are the same, regardless of whether you use the table of EMVs in Table 9.5, the
decision tree in Figure 9.5, or the decision tree in Figure 9.6, because they all calculate the
same EMVs in equivalent ways. In each case, the bottom line is that the company should bid
$115,000, with a resulting EMV of $12,200. Of course, this decision is not guaranteed to
produce a good outcome for the company. For example, the competition could bid less than
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

$115,000, in which case SciTools would lose $5000. Alternatively, the competition could
bid more than $120,000, in which case SciTools would be kicking itself for not bidding
$120,000 and gaining an extra $5000 in profit. Unfortunately, in problems with uncertainty,
there is virtually never a guarantee that the optimal decision will produce the best result.
The only guarantee is that the EMV-maximizing decision is the most rational decision,
given the information known when the decision must be made.
Sensitivity Analysis
The next step in the SciTools decision analysis is to perform a sensitivity analysis. You will
eventually see that PrecisionTree, an Excel add-in that helps automate the decision-making
process, has some powerful sensitivity analysis tools. However, it is also possible to use
Excel data tables. One example is shown in Figure 9.7. (See the finished version of the file
SciTools Bidding Decision 1.xlsx .) The EMVs are calculated in column G, exactly as
described previously. Then you can find the maximum of these in cell B21, and you can
use the following nested IF formula in cell B22 to find the decision from column B that
achieves this maximum:
INDEX(B16:B19,MATCH(B21,G16:G19,0))
This formula checks which EMV in column G matches the maximum EMV in cell B21
and returns the corresponding decision from column B. (This combination of the INDEX
and MATCH functions is often useful for finding the value that corresponds to a maximum
or minimum. For an explanation of this combination, see the Excel Tutorial.xlsx file that
accompanies this book.)
490
Chapter 9
Decision Making under Uncertainty
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
G
F
E
D
C
B
A
SciTools Bidding Example
Inputs
Cost to prepare a
0
0
0,5
$
dib
Range names used:
Cost to supply instruments
$95,000
BidCost
=Data!$B$4
PrNoBid
=Data!$B$7
Probability of no compeng
distribuon
5
$
B
$
!
a
t
a
D
=
ts
o
C
d
o
r
P
3.0
dib
Comp bid
(if they bid)
2.0
K
5
1
1
$
<
$115K to $120K
0.4
$120K to $125K
0.3
1.0
K
5
2
1
$
>
EMV analysis
Monetary outcomes
SciTools wins
SciTools loses
SciTools
Probabilies
wins
SciTools loses
EMV
No bid
NA
0
0
1
$0
SciTools'
0
0,5
1
1
$
diB
0
$15,000
-$5,000
0.86
0.14
$12,200
$120,000
$20,000
-$5,000
0.58
0.42
$9,500
$125,000
$25,000
-$5,000
0.37
0.63
$6,100
Maximum
0
2,2
1
$
V
M
E
0
Best
0
0,5
1
1
$
n
oisic
e
d
0
Data table for sensivity analysis
Probability of no compeng bid
Maximum EMV
Best decision
$12,200
$115,000
0.2
$11,800
$115,000
0.3
$12,200
$115,000
0.4
$12,600
$115,000
0.5
$13,000
$115,000
0.6
$14,200
$125,000
0.7
$16,900
$125,000
Figure 9.7
Sensitivity Analysis with a Data Table
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Once the formulas in cells B21 and B22 have been entered, the data table is easy. In
Figure 9.7 the probability of no competing bid is allowed to vary from 0.2 to 0.7. The data
table shows how the optimal EMV increases over this range. Also, its third column shows
that the $115,000 bid is optimal for small values of the input, but that a $125,000 bid
becomes optimal for larger values. The main point here is that if you set up a spreadsheet
model that links all of the EMV calculations to the inputs, it is easy to use data tables to
perform sensitivity analyses on selected inputs.
■
9.2 Elements of Decision Analysis
491
P R O B L E M S
Solutions for problems whose numbers appear within a
colored box can be found in the Student Solutions Files.
Refer to this book’s preface for purchase information.
Skill-Building Problems
1.
For the example in Simple Decision Problem.xlsx,
are there any probabilities that make the EMV
criterion equivalent to the maximin criterion? Are
there any probabilities that make the EMV criterion
equivalent to the maximax criterion? Explain.
2.
Using a data table in Excel, perform a sensitivity
analysis on the example in Simple Decision
Problem.xlsx. Specifically, keep the probabilities
in row 10 (for D2) as they are, but vary the probability
in cell C11 from 0 to 1 in increments of 0.05, and
keep the probabilities in cells D11 and E11 in the
same ratio as they are currently (2 to 3).
3.
In the SciTools example, make two changes: change
all references to $115,000 to $110,000, and change all
references to $125,000 to $130,000. Rework the EMV
calculations and the decision tree. What is the best
decision and its corresponding EMV?
4.
In the SciTools example, which decision would a
maximin decision maker choose? Which decision
would a maximax decision maker choose? Would you
defend either of these criteria for this particular
example? Explain.
5.
In the SciTools example, use a two-way data table to
see how (or whether) the optimal decision changes as
the bid cost and the company’s production cost change
simultaneously. Let the bid cost vary from $2000 to
$8000 in increments of $1000, and let the production
cost vary from $90,000 to $105,000 in increments of
$2500. Explain your results.
6.
In the SciTools example, the probabilities for the low
bid of competitors, given that there is at least one
competing bid, are currently 0.2, 0.4, 0.3, and 0.1.
Let the second of these be p, and let the others sum to
1  p but keep the same ratios to one another: 2 to 3
to 1. Use a one-way data table to see how (or whether)
the optimal decision changes as p varies from 0.1 to
0.7 in increments of 0.05. Explain your results.
Skill-Extending Problems
7.
For the example in Simple Decision Problem.xlsx,
we found that decision D3 is the EMV-maximizing
decision for the given probabilities. See whether you
can find probabilities that make decision D1 the
best. If the probabilities in row 10 (for D2) are the
same as the probabilities in row 11 (for D3), is it
possible for D2 to be the best decision? What if
these two rows are allowed to be different?
Qualitatively, how can you explain the results? That
is, which types of probabilities tend to favor the
various decisions? (Hint: To search for probabilities
where D2 is better than the other two decisions,
given that rows 10 and 11 are the same, you can use
Solver.)
8.
A decision d is said to be dominated by another deci-
sion D if, for every outcome, the payoff from D is
better than (or no worse than) the payoff from d.
a. Explain why you would never choose a dominated
decision using the maximin criterion, the maximax
criterion, or the EMV criterion.
b. Are any of the decisions in the example in Simple
Decision Problem.xlsx dominated by any others?
What about in the SciTools example?
9.
Besides the maximin, maximax, and EMV criteria,
there are other possible criteria for making decisions.
One possibility involves regret. The idea behind
regret is that if you make any decision and then some
outcome occurs, you look at that outcome’s column
in the payoff table to see how much more you could
have made if you had chosen the best payoff in that
column. For example, if the decision you make and
the outcome you observe lead to a $50 payoff, and if
the highest payoff in this outcome’s column is $80,
then your regret is $30. You regret looking back and
seeing how much more you could have made, if only
you had made a different decision. Therefore, you
calculate the regret for each cell in the payoff table
(as the maximum payoff in that column minus the
payoff in that cell), calculate the maximum regret in
each row, and choose the row with the smallest
maximum regret. This is called the minimax regret
criterion.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

492
Chapter 9
Decision Making under Uncertainty
9.3 THE PRECISIONTREE ADD-IN
Decision trees present a challenge for Excel. We must somehow take advantage of Excel’s
calculating capabilities (to calculate EMVs, for example) and its graphical capabilities (to
depict the decision tree). Fortunately, there is a powerful add-in, PrecisionTree, developed
by Palisade Corporation, that makes the process relatively straightforward. This add-in not
only enables you to draw and label a decision tree, but it performs the folding-back procedure
automatically and then allows you to perform sensitivity analysis on key input parameters.
The first thing you must do to use PrecisionTree is to “add it in.” We assume you have
already installed the Palisade DecisionTools suite. Then to run PrecisionTree, you have
two options:
■
If Excel is not currently running, you can launch Excel and PrecisionTree by clicking
on the Windows Start button and selecting the PrecisionTree item from the Palisade
Decision Tools group in the list of Programs.
■
If Excel is currently running, the first procedure will launch PrecisionTree on top of
Excel.
You will know that PrecisionTree is ready for use when you see its tab and the associ-
ated ribbon (shown in Figure 9.8). If you want to unload PrecisionTree without closing
Excel, you can do so from its Utilities dropdown list in the Tools group.
Figure 9.8
PrecisionTree Ribbon
The Decision Tree Model
PrecisionTree is quite easy to use—at least its most basic items are. We will lead you through
the steps for the SciTools example. Figure 9.9 shows the results of this procedure, just so that
you can see what you are working toward. (See the file SciTools Bidding Decision 2.xlsx.)
a. Apply this criterion to the example in Simple
Decision Problem.xlsx. Which decision do you
choose?
b. Repeat part a for the SciTools example.
c. In general, discuss potential strengths and
weaknesses of this decision criterion.
10. Referring to the previous problem, another possible
criterion is called expected regret. Here you calculate
the regret for each cell, take a weighted average of
these regrets in each row, weighted by the probabilities
of the outcomes, and choose the decision with the
smallest expected regret.
a. Apply this criterion to the SciTools example.
Which decision do you choose?
b. The expected regret criterion is actually equivalent
to the EMV criterion, in that they always lead to
the same decisions. Argue why this is true.
11. In the SciTools example, you might argue that there is
a continuum of possible low competitor bids (given
that there is at least one competing bid), not just four
possibilities. In fact, assume the low competitor bid in
this case is normally distributed with mean $118,000
and standard deviation $4500. Also, assume that
SciTools will still either not bid or bid $115,000,
$120,000, or $125,000. Use Excel’s NORMDIST
function to find the EMV for each alternative. Which
is the best decision now? Why can’t this be
represented in a decision tree?
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

However, we recommend that you work through the steps on your own, starting with a blank
spreadsheet.
9.3 The PrecisionTree Add-In
493
F
E
D
C
B
A
FALSE
0 0%
14
15
16
17
18
19
20
FALSE
0.0%
0
0
Bid?
12200
30.0%
30.0%
$20,000
15000
SciTools Bidding
No
No
20
21
22
23
24
25
26
TRUE
Compeng bid?
0
12200
80.0%
56.0%
$20,000
15000
70.0%
Win bid?
0
11000
$115K
Yes
Yes
26
27
28
29
30
31
20.0%
14.0%
0
-5000
TRUE
How much to bid?
-$5,000
12200
30.0%
0.0%
$25,000
20000
Yes
No
No
32
33
34
35
36
37
FALSE
Compeng bid?
0
9500
40.0%
0.0%
$25,000
20000
70.0%
Win bid?
0
5000
$120K
Yes
Yes
38
39
40
41
42
43
60.0%
0.0%
0
-5000
30.0%
0.0%
$30,000
25000
FALSE
Compeng bid?
0
6100
No
$125K
No
44
45
46
47
48
49
10.0%
0.0%
$30,000
25000
70.0%
Win bid?
0
-2000
90.0%
0.0%
0
-5000
Yes
Yes
No
49
0
5000
Figure 9.9
Completed Tree from PrecisionTree
Figure 9.10
Inputs for SciTools Bidding Example
1
2
3
4
E
D
C
B
A
SciTools Bidding Decision
Inputs
Range names used:
Cost to prepare a 
4
$
B
$
!le
d
o
M
=
ts
o
C
diB
0
0
0,5
$
dib
l i
$
id
d l!$ $
5
6
7
8
9
10
Cost to supply 
7
$
B
$
!le
d
o
M
=
diB
o
N
r
P
0
0
0,5
9
$
st
n
e
m
u
rts
ni
ProduconCost
=Model!$B$5
Probability of no compeng 
3.0
dib
Comp bid distribuon (if they bid)
SciTools's possible bids
   
0
0
0,5
1
1
$
2.0
K
5
1
1
$
<
$115K to $120K
0 4
$120 000
10
11
12
   $115K to $120K
0.4
$120,000
   $120K to 
0
0
0,5
2
1
$
3.0
K
5
2
1
$
   
1.0
K
5
2
1
$
>
BUILDING THE DECISION TREE
1
Inputs. Enter the inputs shown in columns A and B of Figure 9.10. (We have listed
the possible bids in column D so that they can be linked through formulas in the tree.)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

494
Chapter 9
Decision Making under Uncertainty
14
15
C
B
A
100.0%
0
SciTools Bidding
15
0
Figure 9.11
Beginnings of a New Tree
Figure 9.12
Dialog Box for
Adding a New
Decision Node and
Branches
3
Decision nodes and branches. From here on, keep the tree in Figure 9.9 in mind.
This is the finished product you eventually want. To obtain decision nodes and branches,
select the (only) triangle end node to open the dialog box in Figure 9.12. Click on the green
square to indicate that you want a decision node, and fill in the dialog box as shown. Then
click on the Branches (2) tab and supply labels for the branches under Name, as shown in
Figure 9.13. By default, you get two branches, which is what you want in this case.
However, if you wanted more than two branches, you would click on Add to get additional
branches. The tree expands as shown in Figure 9.14. Under the “Yes” branch, enter the
following link to the bid cost cell:
-BidCost
(Note that it is negative to reflect a cost.)
2
New tree. Click on the Decision Tree button on the PrecisionTree ribbon, and then
select cell A14 below the input section to start a new tree. You will immediately see a dia-
log box where, among other things, you can name the tree. Enter a descriptive name for the
tree, such as SciTools Bidding, and click on OK. You should now see the beginnings of a
tree, as shown in Figure 9.11.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

9.3 The PrecisionTree Add-In
495
Figure 9.13
Dialog Box for Adding or Labeling Branches
Figure 9.15
Tree with All Decision Nodes and Branches
Figure 9.14
Decision Tree with Decision Branches Labeled
14
15
16
17
18
19
C
B
A
TRUE
100.0%
0
0
Bid?
0
FALSE
0.0%
0
0
SciTools Bidding
Branch #1
Branch #2
14
15
C
B
A
TRUE
100.0%
0
0
No
15
16
17
18
19
0
0
Bid?
0
FALSE
0.0%
-$5,000
-5000
SciTools Bidding
Yes
14
15
D
C
B
A
TRUE
100.0%
0
0
No
16
17
18
19
20
21
22
23
Bid?
0
TRUE
0.0%
0
-5000
FALSE
How much to bid?
-$5,000
-5000
FALSE
0.0%
0
5000
SciTools Bidding
$115K
$120K
Yes
23
24
25
0
-5000
FALSE
0.0%
0
-5000
$125K
PrecisionTree Tip: Allowable Entries
On your computer screen, you will note the color-coding PrecisionTree uses. If you inves-
tigate any colored (nonblack) cells, you will see str ange formulas that PrecisionTree uses
for its own purposes. Y ou should not modify these formulas. Y ou should enter your own
probabilities and monetary values only in the cells with black font.
4
More decision branches. The top branch is completed; if SciTools does not bid, there is
nothing left to do. So click on the bottom end node (the triangle), following SciTools’s deci-
sion to bid, and proceed as in the previous step to add and label the decision node and three
decision branches for the amount to bid. (Again, refer to Figure 9.9.) The tree to this point
should appear as in Figure 9.15. Note that there are no monetary values below these decision
branches because no immediate payoffs or costs are associated with the bid amount decision.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

496
Chapter 9
Decision Making under Uncertainty
14
15
16
17
F
E
D
C
B
A
TRUE
100.0%
0
0
Bid?
0
SciTools Bidding
No
17
18
19
20
21
22
23
24
25
26
27
0
50.0%
0.0%
0
-5000
TRUE
Any compeng bid?
0
-5000
50.0%
0.0%
0
-5000
50.0%
Win bid?
0
-5000
50.0%
0.0%
0
-5000
$115K
No
Yes
Yes
No
28
29
30
31
32
33
FALSE
How much to bid?
-$5,000
-5000
FALSE
0.0%
0
-5000
FALSE
0.0%
0
-5000
$120K
$125K
Yes
Figure 9.16
Decision Tree with One Set of Probability Nodes and Branches
6
Copying probability nodes and branches. You could now repeat the same proce-
dure from the previous step to build probability nodes and branches following the other
bid amount decisions, but because they are structurally equivalent, you can save a lot of
work by using PrecisionTree’s copy and paste feature. Right-click on the leftmost proba-
bility node and click on Copy SubTree. Then right-click on either end node below it and
click on Paste SubTree. Do this again with the other end node. Decision trees can get very
“bushy,” but this copy and paste feature can make them much less tedious to construct.
7
Enter probabilities on pr obability branches. You should now have the decision
tree shown in Figure 9.17. It is structurally the same as the completed tree in Figure 9.9,
but the probabilities and monetary values on the probability branches are incorrect. Note
that each probability branch has a value above and below the branch. The value above is
the probability (the default values make the branches equally likely), and the value below
is the monetary value (the default values are 0). You can enter any values or formulas in
these cells (remember, the cells with black font only), exactly as you do in typical Excel
worksheets. As usual, it is a good practice to enter cell references, not numbers, whenever
possible. In addition, range names can be used instead of cell addresses.
PrecisionTree Tip: Sum of Probabilities
PrecisionTree does not enfor ce the rule that pr obabilities on br anches leading out of a
node must sum to 1. You must enforce this rule with appropriate formulas.
PrecisionTree Tip: Entering Monetary Values, Probabilities
A good pr actice is to calculate all of the monetary values and pr
obabilities that will be
needed in the decision tree in some other area of the spreadsheet. Then the values needed
next to the tree branches can be created with simple linking formulas.
We will get you started with the probability branches following the decision to bid
$115,000. First, enter the probability of no competing bid in cell D18 with the formula
PrNoBid
and enter its complement in cell D24 with the formula
1-D18
5
Probability nodes and branches. Using the same procedure (and using Figure 9.9
as a guide), create probability nodes extending from the “bid $115,000” decision. You
should have the skeleton in Figure 9.16.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Next, enter the probability that SciTools wins the bid in cell E22 with the formula
SUM(B10:B12)
and enter its complement in cell E26 with the formula
1-E22
(Remember that SciTools wins the bid only if the competition bids higher, and in this part
of the tree, SciTools is bidding $115,000.) For the monetary values, enter the formula
D9-ProductionCost
in the two cells, D19 and E23, where SciTools wins the contract. Note that the cost of the
bid was already subtracted in cell B29, so it should not be subtracted again. This would be
double-counting, which you should always avoid in decision trees.
8
Enter the other f ormulas on pr obability branches. Using the previous step and
Figure 9.9 as a guide, enter formulas for the probabilities and monetary values on the other
probability branches, those following the decision to bid $120,000 or $125,000.
PrecisionTree Tip: Copying Subtrees
Before taking advanta ge of Pr ecisionTree’s subtree copying capability , it is g enerally a
good idea to fill the subtree as much as possible (with labels, probabilities, and monetary
values). In this way, the copies will require less work. Note that formulas on the subtree are
copied in the usual Excel way (in terms of relative and absolute references), so that the for-
mulas on the copies often have to be adjusted slightly. In this example, you could have sped
up the process slightly by completing step 7 before copying. Then step 8 would entail only
a few formula adjustments on the copied subtrees.
9.3 The PrecisionTree Add-In
497
14
F
E
D
C
B
A
15
16
17
18
19
TRUE
100.0%
0
0
Bid?
0
50.0%
0.0%
0
-5000
SciTools Bidding
No
No
20
21
22
23
24
25
TRUE
Any compeng bid?
0
-5000
50.0%
0.0%
0
-5000
50.0%
Win bid?
0
-5000
50 0%
0 0%
$115K
Yes
Yes
26
27
28
29
30
31
.
.
0
-5000
FALSE
How much to bid?
-$5,000
-5000
50.0%
0.0%
0
-5000
Yes
No
No
32
33
34
35
36
37
FALSE
Any compeng bid?
0
-5000
50.0%
0.0%
0
-5000
50.0%
Win bid?
0
-5000
$120K
Yes
Yes
38
39
40
41
42
43
44
50.0%
0.0%
0
-5000
50.0%
0.0%
0
-5000
FALSE
Any compeng bid?
0
-5000
50.0%
0.0%
No
$125K
No
45
46
47
48
49
0
-5000
50.0%
Win bid?
0
-5000
50.0%
0.0%
0
-5000
Yes
Yes
No
Figure 9.17
Structure of Completed Tree
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Interpreting the Decision Tree
You are finished! The completed tree in Figure 9.9 shows the best strategy and its
associated EMV, as we discussed previously. In fact, a comparison of the decision tree in
Figure 9.6 that was created manually and the tree from PrecisionTree in Figure 9.9 indi-
cates virtually identical results. The best decision strategy is now indicated by the TRUE
and FALSE labels above the decision branches (rather than the notches we entered by
hand). Each TRUE corresponds to the optimal decision out of a decision node, whereas
each FALSE corresponds to a suboptimal decision. Therefore, you simply follow the
TRUE labels. In this case, the company should bid, and its bid amount should be $115,000.
Note that you do not have to perform the folding-back procedure manually.
PrecisionTree does this for you. Essentially, the tree is completed as soon as you finish
entering the relevant inputs. In addition, if you change any of the inputs, the tree reacts
automatically. For example, try changing the bid cost in cell B4 from $5000 to some large
value such as $20,000. You will see that the tree calculations update automatically, and the
best decision is then not to bid, with an associated EMV of $0.
PrecisionTree Tip: Values at End Nodes
You will notice that there are two values following each triangle end node. The bottom value is
the sum of all monetary values on branches leading to this end node. The top value is the prob-
ability of getting to this end node when the optimal strategy is used. This explains why many of
these probabilities are 0; the optimal strategy will never lead to these end nodes.
Policy Suggestion and Risk Profile for Optimal Strategy
Once the decision tree is completed, PrecisionTree has several tools you can use to gain
more information about the decision analysis. First, you can see a subtree (called a Policy
Suggestion) for the optimal decision. To do so, choose Policy Suggestion from
the Decision Analysis dropdown list and fill in the resulting dialog box as shown in
Figure 9.18. (You can experiment with other options.) The Policy Suggestion option shows
only the part of the tree that corresponds to the best decision, as shown in Figure 9.19.
498
Chapter 9
Decision Making under Uncertainty
To find the optimal
decision strategy in any
PrecisionTree tree,
follow the TRUE labels.
The Policy Suggestion
shows only the subtree
corresponding to the
optimal decision
strategy.
Figure 9.18
Dialog Box for
Information about
Optimal Decision
You can also obtain a graphical risk profile of the optimal decision by selecting Risk
Profile from the Decision Analysis dropdown list and filling in the resulting dialog box as
shown in Figure 9.20. (Again, you can experiment with the other options.) As the risk pro-
file in Figure 9.21 indicates, there are only two possible monetary outcomes if SciTools
bids $115,000. It either wins $15,000 or loses $5000, and the former is much more likely.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

9.3 The PrecisionTree Add-In
499
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
F
E
D
C
B
A
PrecisionTree Policy Suggestion - Optimal Decision Tree
Performed By:  Chris Albright
Date: Wednesday, February 06, 2008 8:08:58 PM
Model:
g' in [SciTools Bidding Decision 2 Finished.xlsx]Model
Bid?
12200
30.0%
30.0%
$20,000
15000
TRUE
Compeng bid?
0
12200
80.0%
56.0%
$20,000
15000
70.0%
Win bid?
0
11000
20.0%
14.0%
0
-5000
TRUE
How much to bid?
-$5,000
12200
SciTools Bidding
Yes
$115K
No
Yes
Yes
No
 Decision Tree 'SciTools Biddin
Figure 9.19
Subtree for Optimal Decision
Figure 9.20
Risk Profile Dialog
Box
Figure 9.21
Risk Profile of
Optimal Decision
60%
70%
80%
90%
Probabilies for Decision Tree 'SciTools Bidding'
Opmal Path of Enre DecisionTree
0%
10%
20%
30%
40%
50%
-10000
-5000
0
5000
10000
15000
20000
Probability
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

(The associated probabilities are 0.86 and 0.14, respectively.) This graphical information is
even more useful when there are a larger number of possible monetary outcomes. You can
see what they are and how likely they are.
Sensitivity Analysis
We have already stressed the importance of a follow-up sensitivity analysis to any decision
problem, and PrecisionTree makes this relatively easy to perform. Of course, you can enter
any values in the input cells and watch how the tree changes, but you can obtain more sys-
tematic information by clicking on PrecisionTree’s Sensitivity Analysis button. This
brings up the dialog box in Figure 9.22. Although it has a lot of options, it is easy to use
once you understand the ideas behind it. Here are the main options and how to use them.
500
Chapter 9
Decision Making under Uncertainty
It takes some practice
and experimenting to
get used to
PrecisionTree’s
sensitivity analysis
tools. However, they
are powerful and
worth learning.
Figure 9.22
Sensitivity Analysis
Dialog Box
■
The Analysis Type dropdown list allows you to vary one input (One-Way Sensitivity)
or two inputs (Two-Way Sensitivity) simultaneously.
■
The Starting Node dropdown list lets you choose any node in the tree, and the sensitivity
analysis is then performed for the EMV from that node to the right. In other words, it
assumes you have gotten to that node and are now interested in what will happen from
then on. The node selected in the figure, C29, is the leftmost node, so by selecting it, the
sensitivity analysis is on the EMV of the entire tree. This is the most common setting.
■
You add inputs to vary in the Inputs section. You can add as many as you like, and all
of the checked inputs are included in any particular sensitivity analysis. When you
add an input to this section, you can specify the range over which you want it to vary.
For example, you can vary it by plus or minus 10% in 10 steps from a selected base
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

value, as we did for the production cost in cell B5, or you can vary it from 0 to 0.6 in
12 steps, as we did for the probability of no competing bids in cell B7.
■
The Include Results checkboxes allow you to select up to four types of charts,
depending on the type of sensitivity analysis. (The bottom two options are disabled
for a two-way sensitivity analysis.) You can experiment with these options, but we
will illustrate our favorites shortly.
When you click on OK, PrecisionTree varies each of the checked inputs in the middle
section, one at a time if you select the One-Way option, and presents the results in new work-
sheets. By default, these new worksheets are placed in a new workbook. If you would rather
have them in the same workbook as the model, click on the PrecisionTree Utilities dropdown
arrow, select Application Settings, and select Active Workbook from the Replace Reports In
option. (This is a global setting. It will take effect for all future PrecisionTree analyses.)
Strategy Region Chart
Figure 9.23 illustrates a strategy region chart from a one-way analysis. This chart shows
how the EMV varies with the production cost for both of the original decisions (bid or
don’t bid). This type of chart is useful for seeing whether the optimal decision changes
over the range of the input variable. It does so only if the two lines cross. In this particular
graph it is clear that the “Bid” decision dominates the “No bid” decision over the selected
production cost range.
9.3 The PrecisionTree Add-In
501
In strategy region
charts, the primary
interest is in where 
(or whether) lines
cross.This is where
decisions change.
15000
20000
25000
ue
Strategy Region of Decision Tree 'SciTools Bidding'
Expected Value of Node 'Bid?' (B17)
With Variaon of Cost to supply instruments (B5)
-5000
0
5000
10000
$84,000
$86,000
$88,000
$90,000
$92,000
$94,000
$96,000
$98,000
$100,000
$102,000
$104,000
$106,000
Expected Valu
Cost to supply instruments (B5)
No
Yes
Figure 9.23
EMV Versus
Production Cost for
Each of Two
Decisions
Tornado Chart
A tornado chart shows how sensitive the EMV of the optimal decision is to each of the
selected inputs over the specified ranges. (See Figure 9.24.) The length of each bar shows
the change in the EMV in either direction, so inputs with longer bars have a greater effect on the
selected EMV. (If you checked the next-to-bottom checkbox in Figure 9.22, the lengths of the
bars would indicate percentage changes from the base value.) The bars are always arranged
from longest on top to shortest on the bottom—hence the name tornado chart. Here it is appar-
ent that production cost has the largest effect on EMV, and bid cost has the smallest effect.
Tornado charts and
spider charts indicate
which inputs the
selected EMV is most
sensitive to.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Spider Chart
Finally, a spider chart shows how much the optimal EMV varies in magnitude for vari-
ous percentage changes in the input variables. (See Figure 9.25.) The steeper the slope of
the line, the more the EMV is affected by a particular input. It is again apparent that the
production cost has a relatively large effect, whereas the other two inputs have relatively
small effects.
502
Chapter 9
Decision Making under Uncertainty
Producon Cost (B5)
Tornado Graph of Decision Tree 'SciTools Bidding'
Expected Value of Enre Model
2000
4000
6000
8000
10000
12000
14000
16000
18000
20000
22000
Prob No Compeng Bid (B7)
Bid Cost (B4)
Expected Value
Figure 9.24
Tornado Chart for
SciTools Example
Figure 9.25
Spider Chart for
SciTools Example
14000
16000
18000
20000
22000
Spider Graph of Decision Tree 'SciTools Bidding'
Expected Value of Enre Model
2000
4000
6000
8000
10000
12000
-150.0%
-100.0%
-50.0%
0.0%
50.0%
100.0%
150.0%
Expected Value
Change in Input (%)
Producon Cost (B5)
Prob No Compeng Bid (B7)
Bid Cost (B4)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Another Sensitivity Chart
Each time you click on the Sensitivity Analysis button, you can run a different sensitiv-
ity analysis. For example, you might want to choose cell C29 as the cell to analyze. This
is the optimal EMV for the problem, given that the company has decided to place a bid.
One interesting chart from this analysis is the strategy region chart in Figure 9.26. It
indicates how the EMV varies with the probability of no competing bid for each of the
three bid amount decisions. The $115,000 bid is best for most of the range, but when the
probability of no competing bid is sufficiently large (about 0.55), the $120,000 bid
becomes best (by a small margin.)
9.3 The PrecisionTree Add-In
503
Figure 9.26
Strategy Region
Chart for Another
EMV Cell
10000
12000
14000
16000
Strategy Region of Decision Tree 'SciTools Bidding'
Expected Value of Node 'How much to bid?' (C29)
With Variaon of Prob No Compeng Bid (B7)
-4000
-2000
0
2000
4000
6000
8000
-0.1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
Expected Value
Prob No Compeng Bid (B7)
$115K
$120K
$125K
Two-Way Sensitivity Chart
Another interesting option is to run a two-way analysis. This shows how the selected EMV
varies as each pair of inputs varies simultaneously. We analyzed the EMV in cell C29 with
this option, using the same inputs as before. A typical result is shown in Figure 9.27. For
each of the possible values of production cost and the probability of no competitor bid, this
chart indicates which bid amount is optimal. (By choosing cell C29, we are assuming
SciTools will bid; the only question is how much.) As you can see, the optimal bid amount
remains $115,000 unless the production cost and the probability of no competing bid are
both large. Then it becomes optimal to bid $120,000 or $125,000. This makes sense intu-
itively. As the probability of no competing bid increases and a larger production cost must
be recovered, it seems reasonable that SciTools should increase its bid.
We reiterate that a sensitivity analysis is always an important component of any real-
world decision analysis. If you had to construct decision trees by hand—with paper and
pencil—a sensitivity analysis would be very tedious, to say the least. You would have to
recalculate everything each time through. Therefore, one of the most valuable features of
the PrecisionTree add-in is that it enables you to perform sensitivity analyses in a matter of
seconds.
A one-way sensitivity
analysis varies only one
input at a time.A two-
way analysis varies two
inputs simultaneously.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

504
Chapter 9
Decision Making under Uncertainty
P R O B L E M S
Skill-Building Problems
12. In a tree built with PrecisionTree, there are two blue
values at each end node, the top one of which is a
probability. Why are so many of these probabilities 0
in the finished tree in Figure 9.9? What do the
remaining (positive) probabilities represent?
13. In the SciTools example, there are two equivalent
decision tree structures, shown in Figures 9.5 and 
9.6. Use PrecisionTree to create the first of these,
and verify that it yields the same EMVs and the
same optimal decision as the tree developed in
this section.
14. For the completed decision tree in Figure 9.9, the
monetary values in black are those you enter. The
monetary values in color are calculated automatically
by PrecisionTree. For this particular example, explain
exactly how these latter values are calculated
(remember the folding-back process) and what they
represent. These include the blue values at the end
nodes, the red values at the probability nodes, and the
green values at the decision nodes.
15. For the SciTools example, once you build the tree as in
Figure 9.9 and then run a one-way sensitivity analysis
with the dialog box filled in as in Figure 9.22, you
obtain three strategy charts. (Try it.) Explain exactly
what each of these charts represents. (For this problem,
you can ignore the tornado and spider charts.)
16. The tornado chart in Figure 9.24 and the spider chart
in Figure 9.25 show basically the same information in
slightly different forms. Explain in words exactly what
information they provide. (If necessary, consult
PrecisionTree’s online help.)
17. Explain in words what information a two-way
sensitivity chart, such as the one in Figure 9.27,
provides. Demonstrate how you could provide this
same information without PrecisionTree’s sensitivity
tools, using only data tables. (You can still use the tree
built with PrecisionTree.)
0.4
0.5
0.6
Strategy Region for Node 'How much to bid?'
0
0.1
0.2
0.3
$84,000
$86,000
$88,000
$90,000
$92,000
$94,000
$96,000
$98,000
$100,000
$102,000
$104,000
$106,000
Prob No Compeng Bid (B7)
Producon Cost (B5)
$115K
$120K
$125K
Figure 9.27
Two-Way Sensitivity
Analysis
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

9.4 BAYES’ RULE
The examples to this point have required a single decision. We now examine multistage
problems, where a decision maker must make at least two decisions that are separated in
time, such as when a company must first decide whether to buy information that will help
it make a second decision. In multistage decision problems there are typically alternating
sets of decision nodes and probability nodes. The decision maker makes a decision, some
uncertainty is resolved, the decision maker makes another decision, more uncertainty is
resolved, and so on. Before analyzing such problems, we must discuss one important prob-
ability issue.
In a multistage decision tree, all probability branches at the right of the tree are con-
ditional on outcomes that have occurred earlier, to their left. Therefore, the probabilities
on these branches are of the form P(A|B), read “A given B,” where A is an event corre-
sponding to a current probability branch, and B is an event that occurs before event A in
time. However, when gathering data for the problem, it is sometimes more natural to
assess conditional probabilities in the opposite order, that is, P(B|A). Whenever this is the
case, Bayes’ rule must be used to obtain the probabilities needed on the tree. Essentially,
Bayes’ rule is a mechanism for revising probabilities as new information becomes
available.
To develop Bayes’ rule, let A1 through An be any outcomes. Without any further infor-
mation, we believe the probabilities of the As are P(A1) through P(An). These are called
prior probabilities. We then have the possibility of gaining some information. There are
several information outcomes we might observe, a typical one of which is labeled B. We
assume the probabilities of B, given that any of the As will occur, are known. These
probabilities, labeled P(B|A1) through P(B|An), are often called likelihoods. Because an
information outcome might influence our thinking about the probabilities of the As,
we need to find the conditional probability P(Ai|B) for each outcome Ai. This is called the
posterior probability of Ai. This is where Bayes’ rule enters the picture. It states that we
can calculate posterior probabilities from the following formula.
9.4 Bayes’ Rule
505
The whole purpose of
Bayes’ rule is to revise
probabilities as new
information becomes
available.
Bayes’ Rule
(9.1)
P(At |
 B) =
P(B | At)P(At)
P(B |A1)P(A1) + Á + P(B | An)P(An)
Denominator of Bayes’ Rule (Law of Total Probability)
(9.2)
P(B) = P(B | A1)P(A1) + Á + P(B |A1)P(An)
In words, Bayes’ rule says that the posterior is the likelihood times the prior, divided
by a sum of likelihoods times priors. As a side benefit, the denominator in Bayes’ rule is
also useful in multistage decision trees. It is the probability P(B) of the information out-
come.
This formula is important in its own right. For B to occur, it must occur along with one
of the As. Formula 9.2) simply decomposes the probability of B into all of these possibili-
ties. It is sometimes called the law of total probability.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

In the case where there are only two As, labeled as A and Not A, Bayes’ rule takes the
following form:
506
Chapter 9
Decision Making under Uncertainty
Bayes’ Rule for Two Outcomes
(9.3)
P(A|B) =
P(B|A)P(A)
P(B|A)P(A) + P(B|Not A)P(Not An)
We illustrate the mechanics of Bayes’ rule in the following example. [See Feinstein
(1990) for a real application of this example.]
E X A M P L E
9.2 DRUG TESTING COLLEGE ATHLETES
I
f an athlete is tested for a certain type of drug use (steroids, say), the test result will
be either positive or negative. However, these tests are never perfect. Some drug-free
athletes test positive, and some drug users test negative. The former are called false
positives; the latter are called false negatives. Let’s assume that 5% of all athletes use
drugs, 3% of all tests on drug-free athletes yield false positives, and 7% of all tests on
drug users yield false negatives. Suppose a typical athlete is tested. If this athlete tests
positive, can you be sure that he is a drug user? If he tests negative, can you be sure he
does not use drugs?
Objective
To use Bayes’ rule to revise the probability of being a drug user, given the
positive or negative results of the test.
WHERE DO THE NUMBERS COME FROM?
The estimate that 5% of all athletes are drug users is probably based on a well-known national
average. The error rates from the tests are undoubtedly known from extensive experience with
the tests. (However, we are not claiming that the numbers used here match reality.)
Solution
Let D and ND denote that a randomly chosen athlete is or is not a drug user, and let T and
T indicate a positive or negative test result. (The outcomes D and ND correspond to A
and Not A in Equation (9.3), and either T or T corresponds to B.) The following
probabilities are given. First, because 5% of all athletes are drug users, you know that 
P(D)  0.05 and P(ND)  0.95. These are the prior probabilities. They represent the
chance that an athlete is or is not a drug user prior to the results of a drug test.
Second, from the information on the accuracy of the drug test, you know the condi-
tional probabilities P(T|ND)  0.03 and P(T|D)  0.07. In addition, a drug-free athlete
tests either positive or negative, and the same is true for a drug user. Therefore, you also
know the probabilities P(T|ND)  0.97 and P(T|D)  0.93. These four conditional
probabilities of test results given drug user status are the likelihoods of the test results.
Given these priors and likelihoods, you need to calculate posterior probabilities such
as P(D|T), the probability that an athlete who tests positive is a drug user, and
P(ND|T), the probability that an athlete who tests negative is drug free. They are called
posterior probabilities because they are assessed after the drug test results.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Using Bayes’ rule for two outcomes, Equation (9.3), you can calculate
and
In words, if the athlete tests positive, there is still a 38% chance that he is not a drug user, but
if he tests negative, you are virtually sure he is not a drug user. The denominators of these two
formulas are the probabilities of the test results. They can be calculated from Equation (9.2):
P(T)  0.93(0.05)  0.03(0.95)  0.075
and
P(T)  0.07(0.05)  0.97(0.95)  0.925
The first Bayes’ rule result might surprise you. After all, the test is reasonably accurate, so if
you observe a positive test result, you should be pretty sure that the athlete is a drug user,
right? The reason the first posterior probability is “only” 0.620 is that very few athletes in the
population are drug users—only 5%. Therefore, you need a lot of evidence to be convinced
that a particular athlete is a drug user, and a positive test result from a somewhat inaccurate
test is not enough evidence to be totally convincing. On the other hand, a negative test result
simply adds confirmation to what you already suspected—that a typical athlete is not a drug
user. This is why P(ND|T) is so close to 1.
A More Intuitive Calculation
If you have trouble understanding or implementing Bayes’ rule, you are not alone. At least one
study has shown that even trained medical specialists have trouble with this type of calculation
(in the context of tests for cancer). Most of us do not think intuitively about conditional prob-
abilities. However, there is an equivalent and more intuitive way to obtain the same result.
Imagine that there are 100,000 athletes. Because 5% of all athletes are drug users, we
assume that 5000 of these athletes use drugs and the other 95,000 do not. Now we administer
the test to all of them. We expect 3%, or 2850, of the nonusers to test positive (because the
false-positive rate is 3%), and we expect 93%, or 4650, of the drug users to test positive
(because the false-negative rate is 7%). Therefore, we observe a total of 2850  4650  7500
positives. If one of these 7500 athletes is chosen at random, what is the probability that a drug
user is chosen? It is clearly
P(D|T)  4650/7500  0.620
This is the same result we got using Bayes’ rule! So if you have trouble with Bayes’
rule using probabilities, you can use this alternative method of using counts. (By the way,
the 100,000 value is irrelevant. We could have used 10,000, 50,000, 1,000,000, or any other
convenient value.)
Spreadsheet Implementation of Bayes’ Rule
It is fairly easy to implement Bayes’ rule in a spreadsheet, as illustrated in Figure 9.28 for
the drug example. (See the file Bayes Rule.xlsx.4)
=
P(T-|ND)P(D)
P(T-|D)P(D) + P(T-|ND)P(ND) =
(0.97)(0.95)
(0.07)(0.05) + (0.97)(0.95) = 0.996
P(ND|T-)
=
P(T+|D)P(D)
P(T+|D)P(D) + P(T+|ND)P(ND) =
(0.93)(0.05)
(0.93)(0.05) + (0.03)(0.95) = 0.620
P(D | T+)
9.4 Bayes’ Rule
507
This alternative
procedure, using 
counts instead of
probabilities, is
equivalent to Bayes’
rule and is probably
more intuitive.
4The Bayes2 sheet in this file illustrates how Bayes’ rule can be used when there are more than two possible test
results and/or drug user categories.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

The given priors and likelihoods are listed in the ranges B5:C5 and B9:C10. You first
use Equation (9.2) to calculate the denominators for Bayes’ rule, the unconditional proba-
bilities of the two possible test results, in the range B14:B15. Because each of these is a
sum of products of priors and likelihoods, the formula in cell B14 is
SUMPRODUCT($B$5:$C$5,B9:C9)
and this is copied to cell B15. Then you use Equation (9.1) to calculate the posterior prob-
abilities in the range B20:C21. Because each of these is a product of a prior and a likeli-
hood, divided by a denominator, the formula in cell B20 is
B$5*B9/$B14
and this is copied to the rest of the B20:C21 range. The various 1s in the margins of
Figure 9.28 are row sums or column sums that must equal 1. They are shown only as
checks of the logic.
As we have noted, a positive drug test still leaves a 38% chance that the athlete is not
a drug user. Is this a valid argument for not requiring drug testing of athletes? We explore
this question in a continuation of the drug-testing example in the next section.
■
508
Chapter 9
Decision Making under Uncertainty
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
A
B
C
D
E
F
Illustraon of Bayes' rule using drug example
Prior probabilies of drug user status
User
Non-user
0.05
0.95
1
Likelihoods of test results, given drug user status
User
Non-user
Test posiv e
0.93
0.03
Test
Uncondional probabilies
 negave
0.07
0.97
1
1
of test results (denominators of Bayes' rule)
Test posive
0.075
Test negav e
0.925
1
Posterior probabilies of drug user status (Bayes' rule)
User
Non-user
Test posiv e
0.620
0.380
1
Test negav e
0.004
0.996
1
Figure 9.28
Bayes’ Rule for
Drug-Testing
Example
P R O B L E M S
Skill-Building Problems
18. For each of the following, use a one-way data table to
see how the posterior probability of being a drug user,
given a positive test, varies as the indicated input
varies. Write a brief explanation of your results.
a. Let the input be the prior probability of being a drug
user, varied from 0.01 to 0.10 in increments of 0.01.
b. Let the input be the probability of a false positive from
the test, varied from 0 to 0.10 in increments of 0.01.
c. Let the input be the probability of a false negative
from the test, varied from 0 to 0.10 in increments
of 0.01.
19. In the drug testing, assume there are three possible
test results: positive, negative, and inconclusive. For
a drug user, the probabilities of these outcomes are
0.65, 0.06, and 0.29. For a nonuser, they are 0.03,
0.72, and 0.25. Use Bayes’ rule to find a table of all
posterior probabilities. (The prior probability of
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

being a drug user is still 0.05.) Then answer the
following.
a. What is the posterior probability that the athlete is a
drug user, (1) given that her test results are positive,
(2) given that her test results are negative, and
(3) given that her drug results are inconclusive?
b. What is the probability of observing a positive test
result, a negative test result, or an inconclusive test
result?
20. Referring to the previous problem, find the same
probabilities through the counting argument explained
in this section. Start with 100,000 athletes and divide
them into the various categories.
21. Suppose you are a heterosexual white male and are
going to be tested to see if you are HIV positive.
Assume that if you are HIV positive, your test will
always come back positive. Assume that if you are not
HIV positive, there is still a 0.001 chance that your
test will indicate that you are HIV positive. In reality,
1 of 10,000 heterosexual white males is HIV positive.
Your doctor calls and says that you have tested HIV
positive. He is sorry but there is a 99.9% (10.001)
chance that you have HIV. Is he correct? What is the
actual probability that you are HIV positive?
Skill-Extending Problems
22. The terms prior and posterior are relative. Assume
that the drug test has been performed, and the outcome
is positive, which leads to the posterior probabilities in
row 20 of Figure 9.28. Now assume there is a second
test, independent of the first, that can be used as a
follow-up. Assume that its false-positive and false-
negative rates are 0.02 and 0.06.
a. Use the posterior probabilities from row 20 as
prior probabilities in a second Bayes’ rule
calculation. (Now prior means prior to the second
test.) If the athlete also tests positive in this second
test, what is the posterior probability that he is a
drug user?
b. We assumed that the two tests are independent.
Why might this not be realistic? If they are not
independent, what kind of additional information
would you need about the likelihoods of the test
results?
23. In the OJ Simpson trial it was accepted that OJ had
battered his wife. OJ’s lawyer tried to negate the
impact of this information by stating that in a one-
year period, only 1 out of 2500 battered women are
murdered, so the fact that OJ battered his wife does
not give much evidence that he was the murderer.
The prosecution (foolishly!) let this go unchallenged.
Here are the relevant statistics: In a typical year
6.25 million women are battered, 2500 are battered
and murdered, and 2250 of the women who were
battered and murdered were killed by the batterer.
How should the prosecution have refuted the
defense’s argument?
9.5 Multistage Decision Problems
509
9.5 MULTISTAGE DECISION PROBLEMS
In this section we investigate multistage decision problems. In many such problems the
first-stage decision is whether to purchase information that will help make a better second-
stage decision. In this case the information, if obtained, typically changes the probabilities
of later outcomes. To revise the probabilities once the information is obtained, you often
need to apply Bayes’ rule, as discussed in the previous section. In addition, you typically
want to learn how much the information is worth. After all, information usually comes at a
price, so you want to know whether the information is worth its price. This leads to an
investigation of the value of information, an important theme of this section.
We begin with a continuation of the drug-testing example from the previous section. If drug
tests are not completely reliable, should they be used? As you will see, it all depends on the “costs.”5
5It might also depend on whether there is a second type of test that could help confirm the findings of the first test.
However, we will not consider such a test.
6Again, see Feinstein (1990) for an enlightening discussion of this drug-testing problem at a real university.
E X A M P L E
9.3 DRUG TESTING COLLEGE ATHLETES
T
he administrators at State University are trying to decide whether to institute manda-
tory drug testing for athletes. They have the same information about priors and likeli-
hoods as in Example 9.2, but they now want to use a decision tree approach to see whether
the benefits outweigh the costs.6
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Objective
To use a multistage decision framework to see whether mandatory drug
testing can be justified, given a somewhat unreliable test and a set of “reasonable” mone-
tary values.
WHERE DO THE NUMBERS COME FROM?
We already discussed the source of the probabilities in Example 9.2. The monetary values
we need are discussed in detail here.
Solution
We have already discussed the uncertain outcomes and their probabilities. Now we need to
discuss the decision alternatives and the monetary values, the other two elements of a deci-
sion analysis. We will assume that there are only two alternatives: perform drug testing on
all athletes or don’t perform any drug testing. In the former case we assume that if an ath-
lete tests positive, this athlete is barred from athletics.
Assessing the Monetary Values
The “monetary” values are more difficult to assess. They include 
■
the benefit B from correctly identifying a drug user and barring this person from
athletics
■
the cost C1 of the test itself for a single athlete (materials and labor)
■
the cost C2 of falsely accusing a nonuser (and barring this person from athletics)
■
the cost C3 of not identifying a drug user and allowing this person to participate in
athletics
■
the cost C4 of violating a nonuser’s privacy by performing the test.
It is clear that only C1 is a direct monetary cost that is easy to measure. However, the
other “costs” and the benefit B are real, and they must be compared on some scale to
enable administrators to make a rational decision. We will do so by comparing everything
to the cost C1, to which we assign value 1. (This does not mean that the cost of testing an
athlete is necessarily $1; it just means that all other monetary values are expressed as mul-
tiples of C1.) Clearly, there is a lot of subjectivity involved in making these comparisons,
so sensitivity analysis on the final decision tree is a must.
Developing a Benefit-Cost Table
Before developing this decision tree, it is useful to form a benefit-cost table for both alter-
natives and all possible outcomes. Because we will eventually maximize expected net ben-
efit, all benefits in this table have a positive sign and all costs have a negative sign. These
net benefits are listed in Table 9.6. As before, let D and ND denote that a randomly chosen
athlete is or is not a drug user, and let T and T indicate a positive or negative test result.
The first two columns are relevant if no tests are performed; the last four are relevant when
510
Chapter 9
Decision Making under Uncertainty
Real decision problems
often involve
nonmonetary benefits
and costs.These must
be assessed, relative to
one another, before
rational decisions can
be made.
Table 9.6
Net Benefit for Drug-Testing Example
Don’t Test
Perform Test
Ultimate decision
D
ND
D and T
ND and T
D and T
ND and T
Bar from athletics
B
C2
BC1
(C1C2C4)
BC1
(C1C2C4)
Don’t bar from 
C3
0
(C1C3)
(C1C4)
(C1C3)
(C1C4)
athletics
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

testing is performed. For example, if a positive test is obtained for a nonuser and this ath-
lete is barred from athletics, there are three costs: the cost of the test (C1), the cost of
falsely accusing the athlete (C2), and the cost of violating the athlete’s privacy (C4). The
other entries are obtained similarly.
DEVELOPING THE DECISION TREE MODEL
The decision model, developed with PrecisionTree and shown in Figures 9.29 and 9.30, is
now fairly straightforward. (See the file Drug Testing Decision.xlsx.) You first enter all of
the benefits and costs in an input section. These, together with the Bayes’ rule calculations
from Example 9.2, appear at the top of Figure 9.29. Then you use PrecisionTree in the
usual way to build the tree in Figure 9.30 and enter the links to the values and probabilities.
9.5 Multistage Decision Problems
511
1
2
3
F
E
D
C
B
A
Drug testing decision
Benefits
Given probabilities
4
5
6
7
8
9
10
11
12
13
p
Idenfying
r
oir
P
5
2
r
e
s
u
probabilies
-user
Costs
Test
1
ts
o
c
Barring non-
la
n
oitid
n
o
C
0
5
r
e
s
u
probabilies of test results
Not idenfying
0
2
r
e
s
u
-user
Violaon of
3
0.0
3
9.0
e
vitis
o
P
2
y
c
a
vir
p
7
9.0
7
0.0
e
vit
a
g
e
N
Key probabilities
B
i
i i
13
14
15
16
17
18
19
20
21
5
0.0
r
e
s
U
r
P
Bayesian revision
la
n
oitid
n
o
c
n
U
7
0.0
e
vit
a
g
e
N
e
sla
F
r
P
probabilies of test results
5
7
0.0
e
vitis
o
P
3
0.0
e
vitis
o
P
e
sla
F
r
P
5
2
9.0
e
vit
a
g
e
N
Posterior probabilies
User
Non
0.05
0.95
User
Non
User
Non-user
0
8
3.0
0
2
6.0
e
vitis
o
P
6
9
9.0
4
0
0.0
e
vit
a
g
e
N
Figure 9.29
Inputs and Bayes’ Rule Calculations for Drug-Testing Example
It is important to understand the timing (from left to right) in this decision tree. If drug
testing is performed, the result of the drug test is observed first (a probability node). Each
test result leads to an action (bar from sports or don’t), and then the eventual benefit or cost
depends on whether the athlete uses drugs (again a probability node). You might argue that
the university never knows for certain whether the athlete uses drugs, but you must include
this information in the tree to get the correct benefits and costs. On the other hand, if no
drug testing is performed, there is no intermediate test result node or branch.
Make sure you understand which probabilities are used in the tree. In the lower part,
where no testing takes place, the probabilities are the prior probabilities. There is no test
information in this case. In the upper part, where the test is performed, the probabilities for
the user and nonuser branches are posterior probabilities, given the results of the test. The
reason is that by the time we get to these nodes, the results of the test have already been
observed. However, the probabilities for the test results are unconditional probabilities, the
denominators in Bayes’ rule. They are not conditional probabilities such as P(T|D)
because you condition only on information to the left of any given branch. In other words, by
the time you get to the test result branches, you do not yet know whether the athlete is a user.
Discussion of the Solution
Now we analyze the solution. First, we discuss the benefits and costs shown in Figure 9.29.
These were chosen fairly arbitrarily, but with some hope of reflecting reality. The largest
Bayes’ rule is required
because it yields
exactly those
probabilities that 
are needed in the
decision tree.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

cost is falsely accusing (and then barring) a nonuser. This is 50 times as large as the cost of
the test. The benefit of identifying a drug user is only half this large, and the cost of not
identifying a user is 40% as large as barring a nonuser. The violation of the privacy of a
nonuser is twice as large as the cost of the test. Based on these values, the decision tree
implies that drug testing should not be performed (and no athletes should be barred). The
EMVs for testing and for not testing are both negative, indicating that the costs outweigh
the benefits for each, but the EMV for not testing is slightly less negative.7
Sensitivity Analysis
What would it take to change this decision? We begin with the assumption, probably
accepted by most people in our society, that the cost of falsely accusing a nonuser (C2) is
the largest of the benefits and costs in the range B4:B10. In fact, because of possible legal
512
Chapter 9
Decision Making under Uncertainty
23
F
E
D
C
B
A
62 0%
0.0%
24
25
26
27
28
29
30
62.0%
0.0%
25
24
TRUE
Drug user?
0
-5.26
38.0%
0.0%
-52
-53
7.5%
Bar from athlecs?
Yes
Yes
Yes
No
30
31
32
33
34
35
36
0
-5.26
62.0%
0.0%
-20
-21
FALSE
Drug user?
0
-14.16
38.0%
0.0%
-2
-3
No
Yes
No
37
38
39
40
41
42
43
FALSE
Posive?
-1
-3.233
0.4%
0.0%
25
24
FALSE
Drug user?
0
-52.71
99.6%
0.0%
Yes
Yes
Yes
43
44
45
46
47
48
49
50
99.6%
0.0%
-52
-53
92.5%
Bar from athlecs?
0
-3.068
0.4%
0.0%
-20
-21
TRUE
Drug user?
0
3 07
No
No
No
Yes
50
51
52
53
54
55
56
0
-3.07
99.6%
0.0%
-2
-3
Test?
-1
5.0%
0.0%
25
25
Drug Tesng
Yes
No
57
58
59
60
61
62
63
FALSE
Drug user?
0
-46.25
95.0%
0.0%
-50
-50
TRUE
Bar from athlecs?
0
-1
5.0%
5.0%
No
Yes
No
63
64
65
66
67
68
5.0%
-20
-20
TRUE
Drug user?
0
-1
95.0%
95.0%
0
0
No
Yes
No
Figure 9.30
Decision Tree for Drug-Testing Example
7The university in the Feinstein (1990) study came to the same conclusion.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

costs, you might argue that C2 is more than 50 times the cost of the test. But if C2 increases,
the scales are tipped even further in the direction of not testing. On the other hand, if the
benefit B from identifying a user and the cost C3 for not identifying a user increase, then
testing might be the preferred alternative. We tried this, keeping C2 constant at 50. When B
and C3 both had value 45, no testing was still optimal, but when they both increased to
50—the same magnitude as C2—testing won out by a small margin. However, it would be
difficult to argue that B and C3 are of the same magnitude as C2.
Other than the benefits and costs, the only other input you might vary is the accuracy
of the test, measured by the error probabilities in cells B14 and B15. Presumably, if the test
makes fewer false positives and false negatives, testing might be a more attractive alterna-
tive. We tried this, keeping the benefits and costs the same as those in Figure 9.29 but
changing the error probabilities. Even when each error probability was decreased to 0.01,
however, the no-testing alternative was still optimal—by a fairly wide margin.
In summary, based on a number of reasonable assumptions and parameter settings,
this example has shown that it is difficult to make a case for mandatory drug testing.
■
9.5.1 The Value of Information
The drug-testing decision problem represents a typical multistage decision problem. You first
decide whether to obtain some information that could be useful—the results of a drug test. If
you decide not to obtain the information, you make a decision right away (bar the athlete or
don’t), based on prior probabilities. If you do decide to obtain the information, then you first
observe the information and then make the final decision, based on posterior probabilities.
The questions we ask now are: How much is the information worth, and if it costs a
given amount, should you purchase it? Presumably, information that will help you make
your ultimate decision should be worth something, but it might not be clear how much the
information is worth. In addition, even if the information is worth something, it might not
be worth as much as its actual price. Fortunately, the answers to these questions are
embedded in the decision tree itself.
We will find the values of two types of information: sample information and perfect
information. Sample information is the information from the experiment itself. For exam-
ple, it is the information from the (less than perfect) drug test. (It has become customary to
use the term sample information, and we will continue the practice here, but a more precise
term would be imperfect information.) Perfect information, on the other hand, is infor-
mation from a perfect test—that is, a test that will indicate with certainty which ultimate
outcome will occur. In the drug example, this would correspond to a test that never makes
mistakes. Admittedly, perfect information is almost never available at any price, but find-
ing its value is still useful because it provides an upper bound on the value of any informa-
tion. For example, if perfect information is valued at $2000, then no information can
possibly be worth more than $2000.
We will find the expected value of sample information, or EVSI, and the expected
value of perfect information, or EVPI. They are defined as follows:
9.5 Multistage Decision Problems
513
The EVSI is the most you would be willing to pay for the sample information.
The EVPI is the most you would be willing to pay for perfect information.
Formula for EVSI
EVSI  EMV with (free) sample information – EMV without information
(9.4)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

We first make one important general point about the value of information. Suppose there
is an ultimate decision to make. Before making this decision, you can obtain information, sup-
posedly to help you make the ultimate decision. But suppose you make the same ultimate
decision, regardless of the information you obtain—the same decision you would have made
in the absence of information. Can you guess the value of this information? It is zero. The
information cannot be worth anything if it never leads to a different decision than you would
have made without the information. The moral is that if you plan to pay something for infor-
mation, you are wasting your money unless this information influences your decision making.
514
Chapter 9
Decision Making under Uncertainty
Formula for EVPI
EVPI  EMV with (free) perfect information – EMV without information
(9.5)
Information that has
no effect on the
ultimate decision is
worthless.
FUNDAMENTAL INSIGHT
The Value of Information
The amount you should be willing to spend f or infor-
mation is the expected incr
ease in EMV y
ou can
obtain from having the information. If the actual price
of the information is less than or equal to this amount,
you should purchase it; otherwise, the information is
not worth its price.In addition,information that never
affects your decision is worthless,and it should not be
purchased at any price. Finally, the value of any infor-
mation can never be greater than the value of perfect
information that would eliminate all uncertainty.
We now see how Bayes’ rule can be used and the value of information can be evalu-
ated in a typical multistage decision problem.
EXAMPLE
9.4 MARKETING A NEW PRODUCT AT ACME
T
he Acme Company is trying to decide whether to market a new product. As in many
new-product situations, there is considerable uncertainty about whether the new
product will eventually succeed. Acme believes that it might be wise to introduce the prod-
uct in a regional test market before introducing it nationally. Therefore, the company’s first
decision is whether to conduct the test market.
Acme estimates that the net cost of the test market is $100,000. We assume this is mostly
fixed costs, so that the same cost is incurred regardless of the test-market results. If Acme
decides to conduct the test market, it must then wait for the results. Based on the results of the
test market, it can then decide whether to market the product nationally, in which case it will
incur a fixed cost of $7 million. On the other hand, if the original decision is not to run a test
market, then the final decision—whether to market the product nationally—can be made
without further delay. Acme’s unit margin, the difference between its selling price and its unit
variable cost, is $18. We assume this is relevant only for the national market.
Acme classifies the results in either the test market or the national market as great, fair,
or awful. Each of these results in the national market is accompanied by a forecast of total
units sold. These sales volumes (in 1000s of units) are 600 (great), 300 (fair), and 90 (awful).
In the absence of any test market information, Acme estimates that probabilities of the three
national market outcomes are 0.45, 0.35, and 0.20, respectively.
In addition, Acme has the following historical data from products that were intro-
duced into both test markets and national markets. 
■
Of the products that eventually did great in the national market, 64% did great in the
test market, 26% did fair in the test market, and 10% did awful in the test market.
This is clearly an
approximation of the
real problem. In the
real problem, there
would be a continuum
of possible outcomes,
not just three.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

■
Of the products that eventually did fair in the national market, 18% did great in the
test market, 57% did fair in the test market, and 25% did awful in the test market.
■
Of the products that eventually did awful in the national market, 9% did great in the
test market, 48% did fair in the test market, and 43% did awful in the test market.8
The company wants to use a decision tree approach to find the best strategy. It also wants
to find the expected value of the information provided by the test market.
Objective
To develop a decision tree to find the best strategy for Acme, to perform a sen-
sitivity analysis on the results, and to find EVSI and EVPI.
WHERE DO THE NUMBERS COME FROM?
The fixed costs of the test market and the national market are probably accurate estimates,
based on planned advertising and overhead expenses. The unit margin is just the difference
between the anticipated selling price and the known unit cost of the product. The sales
volume estimates are clearly approximations to reality, because the sales from any new
product would form a continuum of possible values. Here, the company has “discretized”
the problem into three possible outcomes for the national market, and it has estimated the
sales for each of these discrete outcomes. The conditional probabilities of national-market
results given test-market results are probably based on results from previous products that
went through test markets and then national markets.
Solution
We begin by discussing the three basic elements of this decision problem: the possible
strategies, the possible outcomes and their probabilities, and the value model. The possible
strategies are clear. Acme must first decide whether to run a test market. Then it must
decide whether to introduce the product nationally. However, it is important to realize that
if Acme decides to run a test market, it can base the national market decision on the results
of the test market. In this case its final strategy will be a contingency plan, where it con-
ducts the test market, then introduces the product nationally if it receives sufficiently posi-
tive test-market results but abandons the product if it receives sufficiently negative
test-market results. The optimal strategies from many multistage decision problems
involve similar contingency plans.
9.5 Multistage Decision Problems
515
8You can question why the company ever marketed products nationally after awful test-market results, but we
will assume that, for whatever reason, the company made a few such decisions—and that a few even turned out to
be winners.
In a contingency plan, later decisions can depend on earlier decisions and
information received.
FUNDAMENTAL INSIGHT
Making Sequential Decisions
Whenever you have a chance to make several
sequential decisions and you will learn useful
information between decision points, the decision
you make initially depends on the decisions you
plan to make in the future, and these depend on
the information you will learn in the meantime. In
other words, when you decide what to do initially,
you should look ahead to see what your future
options will be, and what your decision will be
under each option. Such a contingency plan is
typically superior to a myopic (short-sighted) plan
that doesn’t take into account future options in
the initial decision making.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Regarding the uncertain outcomes and their probabilities, we note that the given prior
probabilities of national-market results in the absence of test-market results will be needed
in the part of the tree where Acme decides not to run a test market. However, the historical
percentages we quoted are really likelihoods of test-market results, given national-market
results. For example, one of these is P(Great test market | Great national market)  0.64.
Such probabilities are the opposite of those needed in the tree. This is because the event to
the right of the given sign, “great national market,” occurs in time after the event to the left
of the given sign, “great test market.” This is a sure sign that Bayes’ rule is required.
The required posterior probabilities of national-market results, given test-market
results, are calculated directly from Bayes’ rule, Equation (9.1). For example, if NG, NF,
and NA represent great, fair, and awful national-market results, respectively, and if TG, TF,
and TA represent similar events for the test market, than one typical example of a posterior
probability calculation is
This is a reasonable result. In the absence of test market information, the probability
of a great national market is 0.45. However, after a test market with only fair results, the
probability of a great national market is revised down to 0.2836. The other posterior prob-
abilities are calculated similarly. In addition, the denominator in this calculation, 0.4125, is
the unconditional probability of a fair test market. Such test-market probabilities will be
needed in the tree.
Finally, the monetary values in the tree are straightforward. There are fixed costs of
test marketing or marketing nationally, which are incurred as soon as these go-ahead deci-
sions are made. From that point, if the company markets nationally, it observes the sales
volumes and multiplies them by the unit margin to obtain the selling profits.
Implementing Bayes’ Rule
The inputs and Bayes’ rule calculations are shown in Figure 9.31. (See file Acme
Marketing Decisions 1.xlsx.) You perform the Bayes’ rule calculations exactly as in the
=
0.26(0.45)
0.26(0.45) + 0.57(0.35) + 0.48(0.20) = 0.117
0.4125 = 0.2836
P(NG | TF) =
P(TF | NG)P(NG)
P(TF | NG)P(NG) + P(TF | NF)P(NF) + P(TF | NA)P(NA)
516
Chapter 9
Decision Making under Uncertainty
Bayes’ rule is required
whenever the
probabilities in the
statement of the
problem are in the
opposite order of 
those needed in the
tree.
1
2
3
4
A
B
C
D
E
F
G
H
I
J
K
L
M
N
Acme marketing decisions
Inputs
Fixed costs ($1000s)
5
6
7
8
9
10
11
12
13
14
15
16
17
Test
Naonal
0
0
1
t
e
k
r
a
m
0
0
0
7
t
e
k
r
a
m
Unit margin (either market)
$18
Possible quanes sold (1000s of units) in naonal market
0
0
6
t
a
e
r
G
0
0
3
ria
F
0
9
lu
f
w
A
Bayes' rule calculations
Prior probabilies of naonal market
la
n
oitid
n
o
c
n
U
stlu
s
e
r
 probabilies of test mkt results (denominators of Bayes' rule)
Great
Fair
Awful
Great
0.3690
0.45
0.35
0.20
Fair
0.4125
18
19
20
21
22
23
24
Awful
0.2185
Likelihoods of test market results (along side), given naonal market results (along top) from historical data
Great
Fair
Awful
Posterior probabilies of naonal mkt results (along top), given test mkt results (along side)
lu
f
w
A
ria
F
t
a
e
r
G
9
0.0
8
1.0
4
6.0
t
a
e
r
G
8
8
4
0.0
7
0
7
1.0
5
0
8
7.0
t
a
e
r
G
8
4.0
7
5.0
6
2.0
ria
F
7
2
3
2.0
6
3
8
4.0
6
3
8
2.0
ria
F
3
4.0
5
2.0
0
1.0
lu
f
w
A
Awful
0.2059
0.4005
0.3936
Figure 9.31
Inputs and Bayes’ Rule Calculations for Acme Marketing Example
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

drug example. To calculate the unconditional probabilities for test-market results, the
denominators for Bayes’ rule from Equation (9.2), enter the formula
SUMPRODUCT($B$17:$D$17,B21:D21)
in cell G16 and copy it down to cell G18. To calculate the posterior probabilities from
Equation (9.1), enter the formula
B$17*B21/$G16
in cell G22 and copy it to the range G22:I24.
DEVELOPING THE DECISION TREE MODEL
The tree is now straightforward to build and label, as shown in Figure 9.32. Note that the
fixed costs of test marketing and marketing nationally appear on the decision branches
9.5 Multistage Decision Problems
517
Figure 9.32
Decision Tree for Acme Marketing Example
26
F
E
D
C
B
A
Decision tree (all monetary values in $1000s)
27
28
29
30
31
32
33
34
FALSE
0.0%
0
0
FALSE
Naonal market?
0
74
45.0%
0.0%
$10,800
3800
TRUE
Natl mkt result
No
No
Great
35
36
37
38
39
40
41
42
-7000
74
35.0%
0.0%
$5,400
-1600
20.0%
0.0%
$1,620
-5380
Test market?
796.76
FALSE
0.0%
Acme
Yes
Fair
Awful
43
44
45
46
47
48
49
50
0
-100
36.9%
Naonal market?
0
2330.24
78.05%
28.8%
$10,800
3700
TRUE
Natl mkt result
-7000
2330.24
Great
No
Yes
Great
51
52
53
54
55
56
57
17.07%
6.3%
$5,400
-1700
4.88%
1.8%
$1,620
-5480
TRUE
Test mkt result
-100
796.76
TRUE
41.25%
0
-100
Yes
Fair
Awful
No
58
59
60
61
62
63
64
65
41.25%
Naonal market?
0
-100
28.36%
0.0%
$10,800
3700
FALSE
Natl mkt result
-7000
-1048.07
48.36%
0.0%
$5,400
-1700
Fair
Yes
Great
Fair
66
67
68
69
70
71
72
73
23.27%
0.0%
$1,620
-5480
TRUE
21.85%
0
-100
21.85%
Naonal market?
0
-100
20.59%
0.0%
$10,800
3700
Awful
Awful
No
Great
74
75
76
77
78
79
FALSE
Natl mkt result
-7000
-2075.65
40.05%
0.0%
$5,400
-1700
39.36%
0.0%
$1,620
-5480
Yes
Fair
Awful
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

where they occur in time, so that only the selling profits need to be placed on the probabil-
ity branches. For example, the formula for the selling profit in cell D33 is
$B$8*$B$11
Pay particular attention to the probabilities on the branches. The top group are the prior
probabilities from the range B17:D17. In the bottom group, the probabilities on the left
are unconditional probabilities of test-market results from the range G16:G18, and those
on the right are posterior probabilities of national-market results from the range
G22:I24. Again, this corresponds to the standard decision tree convention, where
all probabilities on the tree are conditioned on any events that have occurred to the left
of them.
Discussion of the Solution
To interpret this tree, note that each value just below each node name is an EMV. (These
are colored red or green in Excel.) For example, the 796.76 in cell B41 is the EMV for the
entire decision problem. It means that Acme’s best EMV from acting optimally is
$796,760. As another example, the 74 in cell D35 means that if Acme ever gets to that
point—there is no test market and the product is marketed nationally—the EMV is
$74,000. Actually, this is the expected selling profit minus the $7 million fixed cost, so the
expected selling profit, given that no information from a test market has been obtained, is
$7,074,000.
Acme’s optimal strategy is apparent by following the TRUE branches from left to
right. Acme should first run a test market. If the test-market result is great, the product
should be marketed nationally. However, if the test-market result is fair or awful, the prod-
uct should be abandoned. In these cases the prospects from a national market look bleak,
so Acme should cut its losses. (And there are losses. In these latter two cases, Acme has
already spent $100,000 on the test market and has nothing to show for it.)
Once you have done the work to build the tree, you can reap the benefits of
PrecisionTree’s tools. For example, its policy suggestion and risk profile outputs are given
in Figures 9.33 and 9.34. The policy suggestion shows only the part of the tree corre-
sponding to the optimal strategy. Note that there are two values at each end node. The
bottom number is the combined monetary value along this sequence of branches, and the
top number is the probability of this sequence of branches. This information leads directly
to probability distribution in the risk profile. For this optimal strategy, the only possible
518
Chapter 9
Decision Making under Uncertainty
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
F
E
D
C
B
A
PrecisionTree Policy Suggestion - Optimal Decision Tree
Performed By:  Chris Albright
Date: Wednesday, February 06, 2008 7:27:48 PM
Model: Decision Tree 'Acme' in [Acme Marketing Decisions Finished.xlsx]Model
Test market?
796.76
36.9%
Naonal market?
0
2330.24
78.05%
28.8%
$10,800
3700
TRUE
Natl mkt result
-7000
2330.24
17.07%
6.3%
$5,400
-1700
4.88%
1.8%
$1,620
-5480
TRUE
Test mkt result
100
796 76
Acme
Yes
Great
Yes
Great
Fair
Awful
19
20
21
22
23
24
25
26
27
-100
796.76
TRUE
41.25%
0
-100
41.25%
Naonal market?
0
-100
TRUE
21.85%
0
-100
21.85%
Naonal market?
0
-100
Fair
No
Awful
No
Figure 9.33
Policy Suggestion
(Optimal Strategy
Branches)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

monetary outcomes are a gain of $3,700,000 and losses of $100,000, $1,700,000, and
$5,480,000. Their respective probabilities are 0.288, 0.631, 0.063, and 0.018. Fortunately,
the large possible losses are unlikely enough that the EMV is still positive, $796,760.
You might argue that the large potential losses and the slightly higher than 70%
chance of some loss should persuade Acme to abandon the product right away—without a
test market. However, this is what “playing the averages” with EMV is all about. Because
the EMV of this optimal strategy is greater than 0, the EMV from abandoning the product
right away, Acme should go ahead with this optimal strategy if the company is indeed an
EMV maximizer. In section 9.6 we will see how this reasoning can change if Acme is
a risk-averse decision maker—as it might be with multimillion-dollar losses looming in
the future.
Sensitivity Analysis
There are several sensitivity analyses that can performed on this model. We investigate
how things change when the unit margin, currently $18, varies from $8 to $28. This could
change the decision about whether to run a test market or to market nationally.
We first analyze the overall EMV in cell B41, setting up the sensitivity dialog box as
in Figure 9.35. The resulting chart is shown in Figure 9.36. The chart indicates that for
small unit margins, it is better not to run a test market. The top line, at value 0, corresponds
to abandoning the product altogether, whereas the bottom line, at value 100, corresponds
to running a test market and then abandoning the product regardless of the results.
Similarly, for large unit margins, it is also best not to run a test market. Again, the top line
is 100 above the bottom line. However, the reasoning now is different. For large unit
margins, the company should market nationally regardless of test-market results, so there
is no reason to spend money on a test market. Finally, for intermediate unit margins, as in
the original model, the chart shows that it is best to run a test market. We hope you agree
that this one single chart provides a lot of information and insight.
By changing the cell to analyze in Figure 9.35, we can gain additional insight. For exam-
ple, if no test market is available, the EMV for deciding nationally right away, in cell C31, is
9.5 Multistage Decision Problems
519
Figure 9.34
Risk Profile of
Optimal Strategy
Probabilies for Decision Tree 'Acme'
Opmal Path of Enre DecisionTree
60%
70%
40%
50%
y
30%
40%
Probability
10%
20%
0%
6000
5000
4000
3000
2000
1000
0
1000
2000
3000
4000
-6
-5
-4
-3
-2
-1
1
2
3
4
Sensitivity analysis is
often important for 
the insights it provides.
It makes you ask,
“Why do these results
occur?”
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

520
Chapter 9
Decision Making under Uncertainty
Figure 9.36
Sensitivity Analysis
on Overall Profit
Strategy Region of Decision Tree 'Acme'
Expected Value of Node 'Test market?' (B41)
With Variaon of Unit margin (either market) (B8)
4000
4500
2500
3000
3500
1500
2000
Expected Value
No
Yes
0
500
1000
-500
0
$5
$10
$15
$20
$25
$30
Unit margin (either market) (B8)
Figure 9.35
Dialog Box for
Sensitivity
relevant. The resulting chart appears in Figure 9.37. Now it is a contest between getting zero
profit from abandoning the product and getting a linearly increasing profit from marketing
nationally. The breakpoint appears to be slightly below $18. If the unit margin is above this
value, Acme should market nationally; otherwise, it should abandon the product.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

You can also choose to analyze any of the EMVs in cells D45, D59, or D71. Each of
these is relevant in the case where the company has run the test market, has observed the
test-market results, and is about to decide whether to market nationally. For example, if you
choose D71 as the cell to analyze, you obtain the chart in Figure 9.38. It indicates that there
are indeed situations—where the unit margin is about $26 or more—when the company
should market nationally, even though the test market is awful. In contrast, the chart in
9.5 Multistage Decision Problems
521
Figure 9.37
Sensitivity Analysis
for Deciding
Nationally Right
Away
Strategy Region of Decision Tree 'Acme'
Expected Value of Node 'Naonal market?' (C31)
With Variaon of Unit margin (either market) (B8)
4000
5000
1000
2000
3000
-1000
0
Expected Value
No
Yes
-4000
-3000
-2000
-5000
4000
$5
$10
$15
$20
$25
$30
Unit margin (either market) (B8)
Figure 9.38
Sensitivity Analysis
for National
Decision after Awful
Test Market
Strategy Region of Decision Tree 'Acme'
Expected Value of Node 'Naonal market?' (D71)
With Variaon of Unit margin (either market) (B8)
0
1000
-1000
0
3000
-2000
Expected Value
No
Yes
-4000
-3000
-5000
$5
$10
$15
$20
$25
$30
Unit margin (either market) (B8)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Figure 9.39, where we analyze cell D45, indicates the opposite behavior. It shows that if
the unit margin is low enough—about $13.50 or less—the company should abandon the
product nationally, even though the test-market results are great. These are again very useful
insights.
Expected Value of Sample Information
The role of the test market in this example is to provide information in the form of more
accurate probabilities of national-market results. Information usually costs something,
as it does in Acme’s problem. Currently, the fixed cost of the test market is $100,000,
which is evidently not too much to pay because Acme’s best strategy is to run the test
market. However, you might ask how much this test market is really worth. This is the
expected value of sample information, or EVSI, and it is easy to obtain from the tree.
From Figure 9.32, the EMV from test marketing is $796,760, $100,000 of which is the
cost of the test market. Therefore, if this test market were free, the expected profit would
be $896,760. On the other hand, the EMV from not running a test market is $74,000 (see
cell C31 in the tree). From Equation (9.4), the difference is EVSI:
EVSI  $896,760  $74,000  $822,760
You can check that if you put any value less than 822.76 in the test-market fixed-cost cell
(cell B5), the decision to test-market will continue to be best.
Intuitively, running the test market is worth something because it changes the optimal
decision. With no test-market information, the best decision is to market nationally. (See
the top part of the tree in Figure 9.32.) However, with the test-market information, the ulti-
mate decision depends on the test-market results. Specifically, Acme should market
nationally only if the test-market result is great. This is what makes information worth
something—its outcome affects the optimal decision.
522
Chapter 9
Decision Making under Uncertainty
Figure 9.39
Sensitivity Analysis
for National
Decision after Great
Test Market
Strategy Region of Decision Tree 'Acme'
Expected Value of Node 'Naonal market?' (D45)
With Variaon of Unit margin (either market) (B8)
6000
8000
4000
6000
0
2000
Expected Value
No
Yes
-2000
0
-4000
$5
$10
$15
$20
$25
$30
Unit margin (either market) (B8)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Expected Value of Perfect Information
It took a lot of work to find EVSI. You had to assess various conditional probabilities, use
Bayes’ rule, and then build a fairly complex decision tree. In general, Acme might have
many sources of information it could obtain that would help it make its national decision;
the test market is just one of them. The question, then, is how much such information could
be worth. This is answered by EVPI, the expected value of perfect information. It provides
an upper bound on how much any information could be worth, and it is relatively easy to
calculate.
Imagine that Acme could purchase an envelope that has the true national-market
result—great, fair, or awful—written inside. Once opened, this envelope would remove all
uncertainty, and Acme could make an easy decision. (We assume that Acme can open the
envelope before having to make the national decision.) EVPI is what this envelope is worth.
To calculate it, you build the tree in Figure 9.40. The key here is that the nodes are reversed
in time. You first open the envelope to discover what is inside. This corresponds to the prob-
ability node. Then you make the final decision. Given the cost parameters, it is easy to see
that Acme should market nationally only if the contents of the envelope reveal that the
national market will be great. Otherwise, Acme should abandon the product right away.
9.5 Multistage Decision Problems
523
This perfect infor-
mation envelope is
obviously a fiction, but
it helps to explain how
perfect information
works.
D
C
B
A
1
2
3
4
5
FALSE
0.0%
0
0
45.0%
Natl mkt?
0
3800
TRUE
45.0%
Great
No
Yes
6
7
8
9
10
$3,800
3800
Natl mkt result
1710
TRUE
35.0%
0
0
EVPI
Yes
No
11
12
13
14
15
35.0%
Natl mkt?
0
0
FALSE
0.0%
($1,600)
-1600
TRUE
20.0%
Fair
Yes
No
16
17
18
19
20
0
0
20.0%
Natl mkt?
0
0
FALSE
0.0%
($5,380)
-5380
Awful
No
Yes
21
22
23
24
25
EVPI calculaon
EMV with free
0
1
7
1
IP
EMV with no
4
7
o
f
nI
6
3
6
1
IP
V
E
Figure 9.40
Decision Tree for
Evaluating EVPI
The EVPI calculation is now straightforward. If the envelope (perfect information) is
free, the tree in Figure 9.40 indicates that the EMV is $1,710,000. If there is no information,
the EMV is $74,000 (cell C31 of Figure 9.32). Therefore, from Equation (9.5),
EVPI  $1,710,000  $74,000  $1,636,000
No sample information, test market or otherwise, could possibly be worth more than
this. So if some hotshot market analyst offers to provide “extremely reliable” market
information to Acme for, say, $1.8 million, Acme knows this information cannot be worth
its cost.
■
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

524
Chapter 9
Decision Making under Uncertainty
P R O B L E M S
Skill-Building Problems
24. In deciding whether to perform mandatory drug
testing, we claimed that it is difficult to justify such
testing under reasonable conditions. Check this
yourself in the following questions.
a. Drug testing ought to be more attractive if the test
is more reliable. Keeping the costs the same as 
in the example, use PrecisionTree’s two-way
sensitivity tool to see whether the optimal decision
(test or not test) changes as the probability of a
false positive and the probability of a false negative
both change. You can let them vary through some
reasonable ranges. Explain the results.
b. Repeat part a, but first double the two monetary
values that make the test more attractive: the
benefit of identifying a user and the cost of not
identifying a user. How do your results differ from
those in part a?
c. In this part, keep the probabilities of false positives
and false negatives the same, but let the benefits
and costs vary. Specifically, let the benefit of
identifying a user and the cost of not identifying a
user be of the form 25a and 20a, where a is some
factor that you can vary. Similarly, let the cost of
barring a nonuser and the cost of violating privacy
be of the form 50b and 2b. The cost of the test is
still 1. (The idea is that large values of a and/or
small values of b will make the testing more
attractive.) Use PrecisionTree’s two-way sensitivity
tool to see whether the optimal decision (test or not
test) changes for a reasonable range of values of a
and b. Discuss your results.
25. In the drug testing decision, find and interpret EVSI
and EVPI. Here, “sample” information refers to the
information from the imperfect drug test, whereas
“perfect” information refers to completely reliable
information on whether the athlete uses drugs.
26. Explain in general why EVSI is the same, regardless
of the actual cost of the information. For example, in
the Acme problem EVSI is the same regardless of
whether the actual cost of the test market is $100,000,
$200,000, or any other value. Then explain how EVSI,
together with the actual cost of the information, leads
to the decision about whether to purchase the
information.
27. Following up on the previous problem, the expected
net gain from information is defined as the expected
amount gained by having access to the information, at
its given cost, as opposed to not having access to the
information. Explain how you would calculate this in
general. What is its value for the Acme problem?
28. Prior probabilities are often educated guesses at best,
so it is worth performing a sensitivity analysis on their
values. However, you must make sure that they are
varied so that all probabilities are nonnegative and
sum to 1. For the Acme problem, perform the
following sensitivity analyses on the three prior
probabilities and comment on the results.
a. Vary the probability of a great national market in a
one-way sensitivity analysis from 0 to 0.6 in
increments of 0.1. Do this in such a way that the
probabilities of the two other outcomes, fair and
awful, stay in the same ratio as they are currently,
7 to 4.
b. Vary the probabilities of a great and a fair national
market independently in a two-way sensitivity
analysis. You can choose the ranges over which
these vary, but you must ensure that the three prior
probabilities continue to be nonnegative and sum to
1. (For example, you couldn’t choose ranges where
the probabilities of great and fair are 0.6 and 0.5.)
29. In the Acme problem, perform a sensitivity analysis on
the quantity sold from a great national market (the
value in cell B11). Let this value vary over a range of
values greater than the current value of 600, so that a
great national market is even more attractive than
before. Does this ever change the optimal strategy? If
so, in what way?
30. Using trial and error on the prior probabilities in the
Acme problem, find values of them that make EVSI
equal to 0. These are values where Acme will make
the same decision, regardless of the test-market results
it observes. Comment on why the test market is
worthless for your particular prior probabilities.
Skill-Extending Problems
31. We related EVPI to the value of an envelope that
contains the true ultimate outcome. This concept can
be extended to “less than perfect” information. For
example, in the Acme problem suppose that the
company could purchase information that would
indicate, with certainty, that one of the following two
outcomes will occur: (1) the national market will be
great, or (2) the national market will not be great. Note
that outcome (2) doesn’t say whether the national
market will be fair or awful; it just says that it won’t
be great. How much should Acme be willing to pay
for such information?
32. The concept behind EVPI is that you purchase perfect
information (the envelope), then open the envelope to
see which outcome occurs, and then make an easy
decision. You do not, however, get to choose what
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

9.6 INCORPORATING ATTITUDES TOWARD RISK
Rational decision makers are sometimes willing to violate the EMV maximization crite-
rion when large amounts of money are at stake. These decision makers are willing to sac-
rifice some EMV to reduce risk. Are you ever willing to do so personally? Consider the
following scenarios.
■
You have a chance to enter a lottery where you will win $100,000 with probability
0.1 or win nothing with probability 0.9. Alternatively, you can receive $5000 for
certain. How many of you—truthfully—would take the certain $5000, even though
the EMV of the lottery is $10,000? Or change the $100,000 to $1,000,000 and the
$5000 to $50,000 and ask yourself whether you’d prefer the sure $50,000.
■
You can buy collision insurance on your expensive new car or not buy it. The insur-
ance costs a certain premium and carries some deductible provision. If you decide to
pay the premium, then you are essentially paying a certain amount to avoid a gamble:
the possibility of wrecking your car and not having it insured. You can be sure that the
premium is greater than the expected cost of damage; otherwise, the insurance com-
pany would not stay in business. Therefore, from an EMV standpoint you should not
purchase the insurance. But how many of you drive without this type of insurance?
These examples, the second of which is certainly realistic, illustrate situations where
rational people do not behave as EMV maximizers. Then how do they act? This question has
been studied extensively by many researchers, both mathematically and behaviorally.
Although there is still not perfect agreement, most researchers believe that if certain
basic behavioral assumptions hold, people are expected utility maximizers—that is, they
choose the alternative with the largest expected utility. Although we will not go deeply into the
subject of expected utility maximization, the discussion in this section presents the main ideas.
9.6 Incorporating Attitudes Toward Risk
525
information the envelope contains. In contrast, some-
times a company can pay, not to obtain information,
but to influence the outcome. Consider the following
version of the Acme problem. There is no possibility
of a test market, so that Acme must decide right away
whether to market nationally. However, suppose Acme
can pay to change the probabilities of the national
market outcomes from their current values, 0.45, 0.35,
and 0.20, to the new values p, (7/11)(1  p), and
(4/11)(1  p), for some p. (In this way, the probabili-
ties of fair and awful stay in the same ratio as before, 
7 to 4, but by making p large, the probability of a great
outcome increases.)
a. How much should Acme be willing to pay for the
change if p  0.6? If p  0.8? If p  0.95?
b. Are these types of changes realistic? Answer by
speculating on the types of actions Acme might be
able to take to make the probability of a great
national market higher. Do you think such actions
would cost more or less than what Acme should be
willing to pay for them (from part a)?
FUNDAMENTAL INSIGHT
Risk Aversion
When large amounts of mone y are at stake, most of
us are risk a verse, at least to some extent.W e are
willing to sacrifice some EMV to avoid risk.The exact
way this is done , using utility functions and expected
utility, can be difficult to implement in real situations,
but the idea is simple . If you are an EMV maximizer,
you ar e indiff erent betw een a gamble with a giv
en
EMV and a sur e dollar amount equal to the EMV of
the gamble.However,if you are risk averse,you prefer
the sure dollar amount to the gamble.That is, you are
willing to accept a sur e dollar amount that is some-
what less than the EMV of the gamble , just to a void
risk. The more EMV y ou are willing to giv e up, the
more risk averse you are.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

9.6.1 Utility Functions
We begin by discussing an individual’s utility function. This is a mathematical function
that transforms monetary values—payoffs and costs—into utility values. Essentially, an
individual’s utility function specifies the individual’s preferences for various monetary
payoffs and costs and, in doing so, it automatically encodes the individual’s attitudes
toward risk. Most individuals are risk averse, which means intuitively that they are willing
to sacrifice some EMV to avoid risky gambles. In terms of the utility function, this means
that every extra dollar of payoff is worth slightly less to the individual than the previous
dollar, and every extra dollar of cost is considered slightly more costly (in terms of utility)
than the previous dollar. The resulting utility functions are shaped as shown in Figure 9.41.
Mathematically, these functions are said to be increasing and concave. The increasing part
means that they go uphill—everyone prefers more money to less money. The concave part
means that they increase at a decreasing rate. This is the risk-averse behavior.
526
Chapter 9
Decision Making under Uncertainty
–8
–6
–4
–2
0
2
–5
0
5
Monetary Value ($ millions)
Utility
Figure 9.41
Risk-Averse Utility
Function
There are two aspects of implementing expected utility maximization in a real deci-
sion analysis. First, an individual’s (or company’s) utility function must be assessed. This
is a time-consuming task that typically involves many trade-offs. It is usually carried out
by experts in the field, and we do not discuss the details of the process here. Second, the
resulting utility function is used to find the best decision. This second step is relatively
straightforward. You substitute utility values for monetary values in the decision tree and
then fold back as usual. That is, you calculate expected utilities at probability branches and
take maximums (of expected utilities) at decision branches. We will look at a numerical
example later in this section.
9.6.2 Exponential Utility
As we have indicated, utility assessment is tedious. Even in the best of circumstances,
when a trained consultant attempts to assess the utility function of a single person, the
process requires the person to make a series of choices between hypothetical alternatives
involving uncertain outcomes. Unless the person has some training in probability, these
choices will probably be difficult to understand, let alone make, and it is unlikely that
the person will answer consistently as the questioning proceeds. The process is even more
difficult when a company’s utility function is being assessed. Because different company
executives typically have different attitudes toward risk, it can be difficult for these people
to reach a consensus on a common utility function.
For these reasons, classes of ready-made utility functions have been developed. One
important class is called exponential utility and has been used in many financial investment
decisions. An exponential utility function has only one adjustable numerical parameter,
called the risk tolerance, and there are straightforward ways to discover an appropriate
value of this parameter for a particular individual or company. So the advantage of using
an exponential utility function is that it is relatively easy to assess. The drawback is that
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

exponential utility functions do not capture all types of attitudes toward risk. Nevertheless,
their ease of use has made them popular.
An exponential utility function has the following form:
9.6 Incorporating Attitudes Toward Risk
527
Exponential utility
(9.6)
U(x) = 1 - e-x/R
Here x is a monetary value (a payoff if positive, a cost if negative), U(x) is the utility
of this value, and R  0 is the risk tolerance. As the name suggests, the risk tolerance mea-
sures how much risk the decision maker will accept. The larger the value of R, the less risk
averse the decision maker is. That is, a person with a large value of R is more willing to
take risks than a person with a small value of R. In the limit, a person with an extremely
large value of R is an EMV maximizer.
The risk tolerance for an exponential utility function is a single number that specifies
an individual’s aversion to risk. The higher the risk tolerance, the less risk averse the
individual is.
To assess a person’s (or company’s) exponential utility function, only one number, the
value of R, needs to be assessed. There are a couple of tips for doing this. First, it has been
shown that the risk tolerance is approximately equal to that dollar amount R such that the
decision maker is indifferent between the following two options:
■
Option 1: Obtain no payoff at all.
■
Option 2: Obtain a payoff of R dollars or a loss of R/2 dollars, depending on the flip
of a fair coin.
For example, if you are indifferent between a bet where you win $1000 or lose $500, with
probability 0.5 each, and not betting at all, your R is approximately $1000. From this
criterion it certainly makes intuitive sense that a wealthier person (or company) ought to
have a larger value of R. This has been found in practice.
A second tip for finding R is based on empirical evidence found by Ronald Howard, a
prominent decision analyst. Through his consulting experience with large companies, he
discovered tentative relationships between risk tolerance and several financial variables:
net sales, net income, and equity. [See Howard (1988).] Specifically, he found that R was
approximately 6.4% of net sales, 124% of net income, and 15.7% of equity for the compa-
nies he studied. For example, according to this prescription, a company with net sales of
$30 million should have a risk tolerance of approximately $1.92 million. Howard admits
that these percentages are only guidelines. However, they do indicate that larger and more
profitable companies tend to have larger values of R, which means that they are more will-
ing to take risks involving large dollar amounts.
We illustrate the use of the expected utility criterion, and exponential utility in partic-
ular, in the following example.
Finding the appropriate
risk tolerance value for
any company or indi-
vidual is not necessarily
easy, but it is easier
than assessing an
entire utility function.
E X A M P L E
9.5 DECIDING WHETHER TO ENTER RISKY VENTURES AT VENTURE
LIMITED
V
enture Limited is a company with net sales of $30 million. The company currently
must decide whether to enter one of two risky ventures or invest in a sure thing. The
gain from the latter is a sure $125,000. The possible outcomes for the less risky venture are
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

a $0.5 million loss, a $0.1 million gain, and a $1 million gain. The probabilities of these
outcomes are 0.25, 0.50, and 0.25, respectively. The possible outcomes of the more risky
venture are a $1 million loss, a $1 million gain, and a $3 million gain. The probabilities of
these outcomes are 0.35, 0.60, and 0.05, respectively. If Venture Limited must decide on
exactly one of these alternatives, what should it do?
Objective
To see how the company’s risk averseness, determined by its risk tolerance in
an exponential utility function, affects its decision.
WHERE DO THE NUMBERS COME FROM?
The outcomes for each of the risky alternatives probably form a continuum of possible
values. However, as in Example 9.4, the company has classified these into a few possibili-
ties and made intelligent estimates of the monetary consequences and probabilities of these
discrete possibilities.
Solution
We assume that Venture Limited has an exponential utility function. Also, based on
Howard’s guidelines, we assume that the company’s risk tolerance is 6.4% of its net sales,
or $1.92 million. (A sensitivity analysis on this parameter will be performed later on.) You
can substitute into Equation (9.6) to find the utility of any monetary outcome. For example,
the gain from the riskless alternative (in thousands of dollars) is 125, and its utility is
As another example, the utility of a $1 million loss is
These are the values we use (instead of monetary values) in the decision tree.
DEVELOPING THE DECISION TREE MODEL
Fortunately, PrecisionTree takes care of the details. After building a decision tree and
labeling it (with monetary values) in the usual way, click on the name of the tree (the
box on the far left of the tree) to open the dialog box shown in Figure 9.42. Then fill
in the information under the Utility Function tab as shown in the figure. This says to
use an exponential utility function with risk tolerance 1920, the value in cell B5. 
(As indicated in the spreadsheet, all monetary values are measured in $1000s.) It 
also indicates that expected utilities (as opposed to EMVs) should appear in the
decision tree.
The completed tree for this example is shown in Figure 9.43. (See the file 
Using Exponential Utility.xlsx.) You build it in exactly the same way as usual and link
probabilities and monetary values to its branches in the usual way. For example, there is a
link in cell C22 to the monetary value in cell B12. However, the expected values shown in
the tree (those shown in color on a computer screen) are expected utilities, and the optimal
decision is the one with the largest expected utility. In this case the expected utilities for the
riskless option, investing in the less risky venture, and investing in the more risky venture
U(-1000) = 1 - e-(-1000)/1920 = 1 - 1.6834 = -0.6834
U(125) = 1 - e-125/1920 = 1 - 0.9370 = 0.0630
528
Chapter 9
Decision Making under Uncertainty
Don’t worry about the
actual utility values
(for example, whether
they are positive or
negative). Only the
relative magnitudes
matter in terms of
decision making.
The tree is built 
and labeled (with
monetary values)
exactly as before.
PrecisionTree then
takes care of
calculating the
expected utilities.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

are 0.0630, 0.0525, and 0.0439, respectively. Therefore, the optimal decision is to take
the riskless option.
Discussion of the Solution
As indicated in the tree, the riskless option is best in terms of the expected utility crite-
rion; it has the largest expected utility. However, note that the EMVs of the three
9.6 Incorporating Attitudes Toward Risk
529
Figure 9.42
Dialog Box for
Specifying the
Exponential Utility
Criterion
1
E
D
C
B
A
U i
ti l
tilit
f
i k
t
1
2
3
4
5
6
Using exponential utility for a risky venture
Note: All monetary values are in $1000s.
Risk
0
2
9
1
e
c
n
a
r
elo
t
6
7
8
9
10
11
Gain from riskless
5
2
1
n
oit
p
o
Distribuons of loss/gain from risky ventures
Less risky
e
r
o
M
e
r
u
t
n
e
v
risky venture
b
o
r
P
e
ula
V
b
o
r
P
e
ula
V
e
m
o
ct
u
O
12
13
14
15
16
Bad
-
5
2.0
0
0
5
-1000
0.35
6.0
0
0
0
1
5.0
0
0
1
ria
F
5
0.0
0
0
0
3
5
2.0
0
0
0
1
d
o
o
G
0
0
4
5
7
1
s
V
M
E
17
18
19
20
21
22
TRUE
100.0%
125
0.0630
Which venture?
0.0630
25.0%
0.0%
500
0 2975
Ventures
Riskless
Bad
22
23
24
25
26
27
-500
-0.2975
FALSE
Outcome
0
0.0525
50.0%
0.0%
100
0.0508
25.0%
0.0%
Less risky
Fair
27
28
29
30
31
32
25.0%
0.0%
1000
0.4060
35.0%
0.0%
-1000
-0.6834
FALSE
Outcome
0
0.0439
Good
More risky
Bad
33
34
35
36
60.0%
0.0%
1000
0.4060
5.0%
0.0%
3000
0.7904
Fair
Good
Figure 9.43
Decision Tree for
Risky Venture
Example
A risk-averse decision
maker typically gives
up EMV to avoid
risk—when the stakes
are large enough.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

decisions are $125,000, $175,000, and $400,000. (The latter two of these are calculated
in row 15 as the usual SUMPRODUCT of monetary values and probabilities.) So from
an EMV point of view, the more risky venture is definitely best. In fact, the ordering of
the three alternatives using the EMV criterion is exactly the opposite of the ordering
using expected utility. But because Venture Limited is sufficiently risk averse and the
monetary values are sufficiently large, the company is willing to sacrifice $275,000 of
EMV to avoid risk.
Sensitivity Analysis
How sensitive is the optimal decision to the key parameter, the risk tolerance? You can
answer this by changing the risk tolerance and watching how the decision tree changes.
You can check that when the company becomes more risk tolerant, the more risky venture
eventually becomes optimal. In fact, this occurs when the risk tolerance increases to
approximately $2.210 million. In the other direction, of course, when the company
becomes less risk tolerant, the riskless decision continues to be optimal. (The “middle”
decision, the less risky alternative, is evidently not optimal for any value of the risk toler-
ance.) The bottom line is that the decision considered optimal depends entirely on the
attitudes toward risk of Venture Limited’s top management.
■
530
Chapter 9
Decision Making under Uncertainty
9.6.3 Certainty Equivalents
Now let’s change the problem slightly so that Venture Limited has only two options. It can
either enter the less risky venture or receive a certain dollar amount x and avoid the gamble
altogether. We want to find the dollar amount x so that the company is indifferent between
these two options. If it enters the risky venture, its expected utility is 0.0525, calculated ear-
lier. If it receives x dollars for certain, its utility is
To find the value x where the company is indifferent between the two options, set
equal to 0.0525, or 
, and solve for x. Taking natural loga-
rithms of both sides and multiplying by 1920, the result is
(Because of the units of measure, this is really $104,000.) This value is called the
certainty equivalent of the risky venture. The company is indifferent between entering
the less risky venture and receiving $104,000 to avoid it. Although the EMV of the less
risky venture is $175,000, the company acts as if it is equivalent to a sure $104,000. In
this sense, the company is willing to give up the difference in EMV, $71,000, to avoid a
gamble.
By a similar calculation, the certainty equivalent of the more risky venture is approxi-
mately $86,000. That is, the company acts as if this more risky venture is equivalent to a
sure $86,000, when in fact its EMV is a hefty $400,000. In this case, the company is
willing to give up the difference in EMV, $314,000, to avoid this particular gamble. Again,
the reason is that the company wants to avoid risk. You can see these certainty equivalents
in PrecisionTree by changing the Display box in Figure 9.42 to show Certainty Equivalent.
The resulting tree is shown in Figure 9.44. The certainty equivalents we just discussed
appear in cells C24 and C32. (Note that we rounded the values in the text to the nearest
$1000. The values in the figure are more exact.)
x = -1920 ln(0.9475) = 104
e-x/1920 = 0.9475
1 - e-x/1920
U(x) = 1 - e-x/1920
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

9.6 Incorporating Attitudes Toward Risk
531
17
18
19
20
D
C
B
A
TRUE
100.0%
125
125.0000
Which venture?
125.0000
Ventures
Riskless
Bad
21
22
23
24
25
25.0%
0.0%
-500
-500.0000
FALSE
Outcome
0
103.5447
50.0%
0.0%
Ventures
Riskless
Less risky
Bad
Fair
26
27
28
29
30
100
100.0000
25.0%
0.0%
1000
1000.0000
35.0%
0.0%
-1000
-1000.0000
Ventures
Riskless
Less risky
Bad
Fair
Good
More risky
Bad
31
32
33
34
35
FALSE
Outcome
0
86.2017
60.0%
0.0%
1000
1000.0000
5.0%
0.0%
Ventures
Riskless
Less risky
Bad
Fair
Good
More risky
Bad
Fair
36
3000
3000.0000
Good
Figure 9.44
Certainty Equivalents in Tree
E X A M P L E
9.4 MARKETING A NEW PRODUCT AT ACME (CONTINUED)
B
efore concluding this section, we take a last look at the Acme marketing decision from
the previous section. Suppose Acme decides to use expected utility as its criterion
with an exponential utility function? Is the EMV-maximizing decision still optimal?
Remember that this strategy first performed the test market and then marketed nationally
only if the test-market results were great.
Objective
To see how risk aversion affects Acme’s strategy.
Solution
There is very little work to do. You first enter a risk tolerance value in a blank cell. Then,
starting with the tree from Figure 9.32, fill out the dialog box in Figure 9.42, with a link to the
risk tolerance cell. (See the finished version of the file Acme Marketing Decisions 2.xlsxfor
the details.) It is then interesting to perform a sensitivity analysis on the risk tolerance.
We tried this, letting the risk tolerance vary from 1000 to 10,000 (remember that these are in
thousands of dollars) and seeing whether the decision to run a test market changes. The
results appear in Figure 9.45.
Do you understand why it is better to run the test market only if the risk tolerance is
sufficiently large? It is not really because of the cost of the test market. When the risk tol-
erance is small, the company is so risk averse that it never markets nationally—on any of
the “National market?” decision nodes. So information from the test market is worthless.
However, as R increases, the company becomes less risk averse and in some scenarios, its
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

best decision is to market nationally. In these cases, the information from the test market
can be worth its price. (If you don’t follow this reasoning, open the finished version of the
file, try large and small values of the risk tolerance, and see how the TRUEs and FALSEs
on the decision tree change.)
■
532
Chapter 9
Decision Making under Uncertainty
Strategy Region of Decision Tree 'Acme with risk aversion'
Expected Ulity of Node'Test market?' (B43)
With Variaon of Risk tolerance (B26)
-0.12
-0.1
-0.08
-0.06
-0.04
-0.02
0
0.02
0.04
0.06
0.08
0.1
0
1000
2000
3000
4000
5000
6000
7000
8000
9000
10000
11000
Expected Ulity
Risk tolerance (B26) 
No
Yes
Figure 9.45
Sensitivity to Risk Tolerance for Acme Decision
9.6.4 Is Expected Utility Maximization Used?
The previous discussion indicates that expected utility maximization is a fairly involved
task. The question, then, is whether the effort is justified. Theoretically, expected utility
maximization might be interesting to researchers, but is it really used in the business
world? The answer appears to be: not very often. For example, one article on the practice
of decision making [see Kirkwood (1992)] quotes Ronald Howard—the same person we
quoted previously—as having found risk aversion to be of practical concern in only 5%
to 10% of business decision analyses. This same article quotes the president of a Fortune
500 company as saying, “Most of the decisions we analyze are for a few million dollars.
It is adequate to use expected value (EMV) for these.”
P R O B L E M S
Skill-Building Problems
33. For the risky venture example, create a line chart that
includes three series—that is, three lines (or curves).
Each line should show the expected utility of a
particular decision for a sequence of possible risk
tolerance values. This chart should make it clear when
the more risky option becomes optimal and whether
the less risky option is ever optimal.
34. In the risky venture example, the more risky alternative,
in spite of its dominating EMV, is not preferred by a
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

decision maker with a risk tolerance of $1.92 million.
Now suppose everything stays the same except for the
best monetary outcome of the more risky alternative
(the value in cell D14). How much larger must this
value be for the decision maker to prefer the more
risky alternative? What is the corresponding EMV at
that point?
35. In the risky venture example, suppose there is no
riskless alternative; the only two possible decisions
are the less risky venture and the more risky venture.
Explore which of these is the preferred alternative for
a range of risk tolerances. Can you find a cutoff point
for the risk tolerance such that the less risky venture
is preferred for risk tolerances below the cutoff and
the more risky venture is preferred otherwise?
Skill-Extending Problems
36. Do the absolute magnitudes of the monetary outcomes
matter in the risky venture example? Consider the
following two possibilities. In each case, multiply all
monetary values in the example by a factor of A. (For
example, double them if A  2.) For each part, briefly
explain your findings.
a. Currently, an EMV maximizer would choose the
most risky venture. Would this continue to be the
case for any factor A?
b. Currently, an expected utility maximizer with a risk
tolerance of $1.92 million prefers the riskless
alternative. Would this continue to be the case for
any factor A greater than 1? What about when A
is less than 1? You can answer by using trial and
error on A.
c. Referring to the dialog box in Figure 9.42, there
is a Display dropdown list with three options:
expected value (EMV), expected utility, and
certainty equivalent. The latter is defined for any
gamble as the sure monetary amount a risk-averse
person would take as a trade for the risky gamble.
For example, you can check that the certainty
equivalent for the more risky alternative is
86.2017 (in thousands of dollars). Explain what
this really means by calculating the utility of
86.2017 manually and comparing it to the
expected utility from the more risky venture (as
shown on the tree). How does this explain why
the decision maker prefers the riskless alternative
to the more risky venture?
9.7 Conclusion
533
9.7 CONCLUSION
In this chapter we have discussed methods that can be used in decision-making problems
where uncertainty is a key element. Perhaps the most important skill you can gain from
this chapter is the ability to approach decision problems with uncertainty in a systematic
manner. This systematic approach requires you to list all possible decisions or strategies,
list all possible uncertain outcomes, assess the probabilities of these outcomes (possibly
with the aid of Bayes’ rule), calculate all necessary monetary values, and finally do the
necessary calculations to obtain the best decision. If large dollar amounts are at stake, you
might also need to perform a utility analysis, where the decision maker’s attitudes toward
risk are taken into account. Once the basic analysis has been completed, using best
guesses for the various parameters of the problem, you should perform a sensitivity
analysis to see whether the best decision continues to be best within a range of input
parameters.
Summary of Key Terms
Term
Explanation
Excel
Page
Equation
Payoff (or cost)
A table that lists the payoffs (or costs) 
478
table 
for all combinations of decisions 
and uncertain outcomes
Maximin criterion
The pessimist’s criterion; find the worst 
479
possible payoff for each decision, and
choose the decision with the best of these
(continued)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

534
Chapter 9
Decision Making under Uncertainty
Summary of Key Terms
(Continued)
Term
Explanation
Excel
Page
Equation
Maximax criterion
The optimist’s criterion; find the best 
480
possible payoff for each decision, and
choose the decision with the best of these
Expected monetary 
The weighted average of the possible 
480
value (EMV)
payoffs from a decision, weighted by
their probabilities
EMV criterion
Choose the decision with the 
480
maximum EMV
Decision tree
A graphical device for illustrating all 
482
of the aspects of the decision problem
and for finding the optimal decision
(or decision strategy)
Folding-back
Calculation method for decision tree; 
484
procedure
starting at the right, take EMVs at 
probability nodes, maximums of 
EMVs at decision nodes
Risk profile
Chart that represents the probability 
484
distribution of monetary outcomes for 
any decision
PrecisionTree 
Useful Excel add-in developed
Has its
492
by Palisade for building and
own ribbon
analyzing decision trees in Excel
PrecisionTree
Useful for seeing how the optimal 
Use PrecisionTree
501
strategy region chart
decision changes as selected
Sensitivity 
inputs vary
Analysis button
PrecisionTree
Useful for seeing which inputs
Use PrecisionTree 
501
tornado and 
affect a selected EMV 
Sensitivity Analysis
spider charts
the most
button
Bayes’ rule
Formula for updating probabilities
505
9.1
as new information becomes available; 
prior probabilities are transformed 
into posterior probabilities
Law of total
The denominator in Bayes’ rule,
505
9.2
probability
for calculating the (unconditional)
probability of an information outcome
Expected value of
The most the (imperfect) sample information
513
9.4
sample information 
(such as the results of a test market) would
(EVSI)
be worth
Expected value of
The most perfect information on some 
513
9.5
perfect information
uncertain outcome would be worth; 
(EVPI)
represents an upper bound on any EVSI
Contingency plan
A decision strategy where later decisions 
515
depend on earlier decisions and 
outcomes observed in the meantime
Expected utility
Choosing the decision that maximizes the 
526
maximization
expected utility; typically sacrifices 
EMV to avoid risk when large monetary 
amounts are at stake
Utility function
A mathematical function that encodes an 
526
individual’s (or company’s) attitudes 
toward risk
(continued)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

9.7 Conclusion
535
Term
Explanation
Excel
Page
Equation
Exponential utility
A popular class of utility functions, 
527
9.6
function, risk
where only a single parameter, the risk
tolerance
tolerance, has to be specified
Certainty equivalent
The sure dollar value equivalent to the
530
expected utility of a gamble
P R O B L E M S
Skill-Building Problems
37. The SweetTooth Candy Company knows it will need
10 tons of sugar six months from now to implement its
production plans. Jean Dobson, SweetTooth’s
purchasing manager, has essentially two options for
acquiring the needed sugar. She can either buy the
sugar at the going market price when she needs it,
six months from now, or she can buy a futures contract
now. The contract guarantees delivery of the sugar in
six months but the cost of purchasing it will be based
on today’s market price. Assume that possible sugar
futures contracts available for purchase are for five tons
or ten tons only. No futures contracts can be purchased
or sold in the intervening months. Thus, SweetTooth’s
possible decisions are to (1) purchase a futures contract
for ten tons of sugar now, (2) purchase a futures
contract for five tons of sugar now and purchase five
tons of sugar in six months, or (3) purchase all ten tons
of needed sugar in six months. The price of sugar
bought now for delivery in six months is $0.0851 per
pound. The transaction costs for five-ton and ten-ton
futures contracts are $65 and $110, respectively.
Finally, Ms. Dobson has assessed the probability
distribution for the possible prices of sugar six months
from now (in dollars per pound). The file P09_37.xlsx
contains these possible prices and their corresponding
probabilities.
a. Given that SweetTooth wants to acquire the needed
sugar in the least costly way, create a cost table that
specifies the cost (in dollars) associated with each
possible decision and possible sugar price in the
future.
b. Use PrecisionTree to identify the decision that
minimizes SweetTooth’s expected cost of meeting
its sugar demand.
c. Perform a sensitivity analysis on the optimal
decision, letting each of the three currency inputs
vary one at a time plus or minus 25% from its base
value, and summarize your findings. In response to
which of these inputs is the expected cost value
most sensitive?
38. Carlisle Tire and Rubber, Inc., is considering
expanding production to meet potential increases in
the demand for one of its tire products. Carlisle’s
alternatives are to construct a new plant, expand the
existing plant, or do nothing in the short run. The
market for this particular tire product may expand,
remain stable, or contract. Carlisle’s marketing
department estimates the probabilities of these market
outcomes as 0.25, 0.35, and 0.40, respectively. The file
P09_38.xlsx contains Carlisle’s estimated payoff (in
dollars) table.
a. Use PrecisionTree to identify the strategy that
maximizes this tire manufacturer’s expected profit.
b. Perform a sensitivity analysis on the optimal
decision, letting each of the monetary inputs vary
one at a time plus or minus 10% from its base
value, and summarize your findings. In response
to which monetary inputs is the expected profit
value most sensitive?
39. A local energy provider offers a landowner $180,000
for the exploration rights to natural gas on a certain
site and the option for future development. This
option, if exercised, is worth an additional $1,800,000
to the landowner, but this will occur only if natural
gas is discovered during the exploration phase. The
landowner, believing that the energy company’s
interest in the site is a good indication that gas is
present, is tempted to develop the field herself. To do
so, she must contract with local experts in natural gas
exploration and development. The initial cost for such
a contract is $300,000, which is lost forever if no gas
is found on the site. If gas is discovered, however, the
landowner expects to earn a net profit of $6,000,000.
The landowner estimates the probability of finding gas
on this site to be 60%.
a. Create a payoff table that specifies the landowner’s
payoff (in dollars) associated with each possible
decision and each outcome with respect to finding
natural gas on the site.
b. Use PrecisionTree to identify the strategy that
maximizes the landowner’s expected net earnings
from this opportunity.
c. Perform a sensitivity analysis on the optimal
decision, letting each of the inputs vary one at a
time plus or minus 25% from its base value, and
summarize your findings. In response to which
model inputs is the expected profit value most
sensitive?
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

40. Techware Incorporated is considering the introduction
of two new software products to the market. In
particular, the company has four options regarding
these two proposed products: introduce neither
product, introduce product 1 only, introduce product 2
only, or introduce both products. Research and
development costs for products 1 and 2 are $180,000
and $150,000, respectively. Note that the first option
entails no costs because research and development
efforts have not yet begun. The success of these
software products depends on the trend of the national
economy in the coming year and on the consumers’
reaction to these products. The company’s revenues
earned by introducing product 1 only, product 2
only, or both products in various states of the national
economy are given in the file P09_40.xlsx. The
probabilities of observing a strong, fair, or weak trend
in the national economy in the coming year are
assessed to be 0.30, 0.50, and 0.20, respectively.
a. Create a payoff table that specifies Techware’s net
revenue (in dollars) for each possible decision and
each outcome with respect to the trend in the
national economy.
b. Use PrecisionTree to identify the strategy that
maximizes Techware’s expected net revenue from
the given marketing opportunities.
c. Perform a sensitivity analysis on the optimal
decision, letting each of the inputs vary one at a
time plus or minus 25% from its base value, and
summarize your findings. In response to which
model inputs is the expected net revenue value
most sensitive?
41. Consider an investor with $10,000 available to invest.
He has the following options regarding the allocation
of his available funds: (1) he can invest in a risk-free
savings account with a guaranteed 3% annual rate
of return; (2) he can invest in a fairly safe stock, where
the possible annual rates of return are 6%, 8%, or
10%; or (3) he can invest in a more risky stock,
where the possible annual rates of return are 1%, 9%,
or 17%. Note that the investor can place all of his
available funds in any one of these options, or he can
split his $10,000 into two $5000 investments in any
two of these options. The joint probability distribution
of the possible return rates for the two stocks is given
in the file P09_41.xlsx.
a. Create a payoff table that specifies this investor’s
return (in dollars) in one year for each possible
decision and each outcome with respect to the two
stock returns.
b. Use PrecisionTree to identify the strategy that
maximizes the investor’s expected earnings in one
year from the given investment opportunities.
c. Perform a sensitivity analysis on the optimal
decision, letting the amount available to invest and
the risk-free return both vary, one at a time, plus or
minus 100% from their base values, and
summarize your findings. 
42. A buyer for a large department store chain must 
place orders with an athletic shoe manufacturer six
months prior to the time the shoes will be sold in 
the department stores. In particular, the buyer must
decide on November 1 how many pairs of the
manufacturer’s newest model of tennis shoes to order
for sale during the coming summer season. Assume
that each pair of this new brand of tennis shoes costs
the department store chain $45 per pair. Furthermore,
assume that each pair of these shoes can then be sold
to the chain’s customers for $70 per pair. Any pairs
of these shoes remaining unsold at the end of the
summer season will be sold in a closeout sale next
fall for $35 each. The probability distribution of
consumer demand for these tennis shoes during the
coming summer season has been assessed by market
research specialists and is provided in the file
P09_42.xlsx. Finally, assume that the department
store chain must purchase these tennis shoes from the
manufacturer in lots of 100 pairs.
a. Create a payoff table that specifies the contribution
to profit (in dollars) from the sale of the tennis
shoes by this department store chain for each
possible purchase decision and each outcome with
respect to consumer demand.
b. Use PrecisionTree to identify the strategy that
maximizes the department store chain’s expected
profit earned by purchasing and subsequently
selling pairs of the new tennis shoes.
c. Perform a sensitivity analysis on the optimal
decision, letting the three monetary inputs vary one
at a time over reasonable ranges, and summarize
your findings. In response to which model inputs is
the expected earnings value most sensitive?
43. Each day the manager of a local bookstore must decide
how many copies of the community newspaper to order
for sale in her shop. She must pay the newspaper’s
publisher $0.40 for each copy, and she sells the news-
papers to local residents for $0.75 each. Newspapers
that are unsold at the end of day are considered worth-
less. The probability distribution of the number of
copies of the newspaper purchased daily at her shop is
provided in the file P09_43.xlsx. Create a payoff table
that lists the profit from each order quantity (multiples
of 1000 only) and each demand, and use it to find the
order quantity that maximizes expected profit. Why is
this an easier approach than a decision tree for this
particular problem?
44. Two construction companies are bidding against one
another for the right to construct a new community
center building in Bloomington, Indiana. The first
construction company, Fine Line Homes, believes that
its competitor, Buffalo Valley Construction, will place
536
Chapter 9
Decision Making under Uncertainty
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

a bid for this project according to the distribution
shown in the file P09_44.xlsx. Furthermore, Fine Line
Homes estimates that it will cost $160,000 for its own
company to construct this building. Given its fine
reputation and long-standing service within the local
community, Fine Line Homes believes that it will
likely be awarded the project in the event that it and
Buffalo Valley Construction submit exactly the same
bids. Create a payoff table that lists the profit from
each Fine Line bid and each competing bid, and use it
to find the bid that maximizes Fine Line’s expected
profit. Why is this an easier approach than a decision
tree for this particular problem?
45. Suppose that you have sued your employer for damages
suffered when you recently slipped and fell on an icy
surface that should have been treated by your company’s
physical plant department. Specifically, your injury
resulting from this accident was sufficiently serious that
you, in consultation with your attorney, decided to sue
your company for $500,000. Your company’s insurance
provider has offered to settle this suit with you out of
court. If you decide to reject the settlement and go to
court, your attorney is confident that you will win the
case but is uncertain about the amount the court will
award you in damages. He has provided his assessment
of the probability distribution of the court’s award to you
in the file P09_45.xlsx. In addition, there are extra legal
fees of $10,000 you will have to pay if you go to court.
Let S be the insurance provider’s proposed out-of-court
settlement (in dollars). For which values of S will you
decide to accept the settlement? For which values of S
will you choose to take your chances in court? Assume
that you are seeking to maximize the expected net payoff
from this litigation.
46. One of your colleagues has $2000 available to invest.
Assume that all of this money must be placed in one
of three investments: a particular money market fund,
a stock, or gold. Each dollar your colleague invests in
the money market fund earns a virtually guaranteed
3% annual return. Each dollar he invests in the stock
earns an annual return characterized by the probability
distribution provided in the file P09_46.xlsx. Finally,
each dollar he invests in gold earns an annual return
characterized by the probability distribution given in
the same file.
a. If your colleague must place all of his available
funds in a single investment, which investment
should he choose to maximize his expected
earnings over the next year?
b. Suppose now that your colleague can place all of
his available funds in one of these three investments
as before, or he can invest $1000 in one alternative
and $1000 in another. Assuming that he seeks to
maximize his expected total earnings in one year,
how should he allocate his $2000?
47. Consider a population of 2000 individuals, 800 of
whom are women. Assume that 300 of the women in
this population earn at least $60,000 per year, and 200
of the men earn at least $60,000 per year.
a. What is the probability that a randomly selected
individual from this population earns less than
$60,000 per year?
b. If a randomly selected individual is observed to
earn less than $60,000 per year, what is the
probability that this person is a man?
c. If a randomly selected individual is observed to
earn at least $60,000 per year, what is the
probability that this person is a woman?
48. Yearly automobile inspections are required for
residents of the state of Pennsylvania. Suppose that
18% of all inspected cars in Pennsylvania have
problems that need to be corrected. Unfortunately,
Pennsylvania state inspections fail to detect these
problems 12% of the time. On the other hand, assume
that an inspection never detects a problem when there
is no problem. Consider a car that is inspected and is
found to be free of problems. What is the probability
that there is indeed something wrong that the
inspection has failed to uncover?
49. Consider again the landowner’s decision problem
described in Problem 39. Suppose now that, at a cost
of $90,000, the landowner can request that a soundings
test be performed on the site where natural gas is
believed to be present. The company that conducts the
soundings concedes that 30% of the time the test will
indicate that no gas is present when it actually is. When
natural gas is not present in a particular site, the
soundings test is accurate 90% of the time.
a. Given that the landowner pays for the soundings
test and the test indicates that gas is present, what
is the landowner’s revised estimate of the
probability of finding gas on this site?
b. Given that the landowner pays for the soundings
test and the test indicates that gas is not present,
what is the landowner’s revised estimate of the
probability of not finding gas on this site?
c. Should the landowner request the given soundings
test at a cost of $90,000? Explain why or why not.
If not, at what price (if any) would the landowner
choose to obtain the soundings test?
50. The chief executive officer of a firm in a highly
competitive industry believes that one of her key
employees is providing confidential information to the
competition. She is 90% certain that this informer is
the vice president of finance, whose contacts have been
extremely valuable in obtaining financing for the
company. If she decides to fire this vice president and
he is the informer, she estimates that the company will
gain $500,000. If she decides to fire this vice president
but he is not the informer, the company will lose his
9.7 Conclusion
537
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

expertise and still have an informer within the staff;
the CEO estimates that this outcome would cost her
company about $2.5 million. If she decides not to fire
this vice president, she estimates that the firm will lose
$1.5 million regardless of whether he actually is the
informer (because in either case the informer is still
with the company). Before deciding whether to fire
the vice president for finance, the CEO could order lie
detector tests. To avoid possible lawsuits, the lie
detector tests would have to be administered to all
company employees, at a total cost of $150,000.
Another problem she must consider is that the available
lie detector tests are not perfectly reliable. In particular,
if a person is lying, the test will reveal that the person
is lying 95% of the time. Furthermore, if a person is
not lying, the test will indicate that the person is not
lying 85% of the time.
a. To minimize the expected total cost of managing
this difficult situation, what strategy should the
CEO adopt?
b. Should the CEO order the lie detector tests for all
of her employees? Explain why or why not.
c. Determine the maximum amount of money that the
CEO should be willing to pay to administer lie
detector tests.
d. How sensitive are the results to the accuracy of the
lie detector test? Are there any “reasonable” values
of the error probabilities that change the optimal
strategy?
51. A customer has approached a bank for a $100,000 one-
year loan at a 12% interest rate. If the bank does not
approve this loan application, the $100,000 will be
invested in bonds that earn a 6% annual return. Without
additional information, the bank believes that there is a
4% chance that this customer will default on the loan,
assuming that the loan is approved. If the customer
defaults on the loan, the bank will lose $100,000. At
a cost of $1000, the bank can thoroughly investigate
the customer’s credit record and supply a favorable or
unfavorable recommendation. Past experience indicates
that in cases where the customer did not default on the
approved loan, the probability of receiving a favorable
recommendation on the basis of the credit investigation
was 0.80. Furthermore, in cases where the customer
defaulted on the approved loan, the probability of
receiving a favorable recommendation on the basis of
the credit investigation was 0.25.
a. What strategy should the bank follow to maximize
its expected profit?
b. Calculate and interpret the expected value of sample
information (EVSI) for this decision problem.
c. Calculate and interpret the expected value of
perfect information (EVPI) for this decision
problem.
d. How sensitive are the results to the accuracy of the
credit record recommendations? Are there any
“reasonable” values of the error probabilities that
change the optimal strategy?
52. A company is considering whether to market a new
product. Assume, for simplicity, that if this product is
marketed, there are only two possible outcomes: success
or failure. The company assesses that the probabilities of
these two outcomes are p and 1  p, respectively. If the
product is marketed and it proves to be a failure, the
company will have a net loss of $450,000. If the product
is marketed and it proves to be a success, the company
will have a net gain of $750,000. If the company
decides not to market the product, there is no gain or
loss. The company is also considering whether to survey
prospective buyers of this new product. The results of
the consumer survey can be classified as favorable,
neutral, or unfavorable. In similar cases where proposed
products were eventually market successes, the fractions
of cases where the survey results were favorable, neutral,
or unfavorable were 0.6, 0.3, and 0.1, respectively. In
similar cases where proposed products were eventually
market failures, the fractions of cases where the survey
results were favorable, neutral, or unfavorable were 0.1,
0.2, and 0.7, respectively. The total cost of administering
this survey is C dollars.
a. Let p  0.4. For which values of C, if any, would this
company choose to conduct the consumer survey?
b. Let p  0.4. What is the largest amount that this
company would be willing to pay for perfect
information about the potential success or failure
of the new product?
c. Let p  0.5 and C  $15,000. Find the strategy
that maximizes the company’s expected earnings in
this situation. Does the optimal strategy involve
conducting the consumer survey? Explain why or
why not.
53. The U.S. government is attempting to determine
whether immigrants should be tested for a contagious
disease. Assume that the decision will be made on a
financial basis. Furthermore, assume that each
immigrant who is allowed to enter the United States
and has the disease costs the country $100,000. Also,
each immigrant who is allowed to enter the United
States and does not have the disease will contribute
$10,000 to the national economy. Finally, assume
that x percent of all potential immigrants have the
disease. The U.S. government can choose to admit all
immigrants, admit no immigrants, or test immigrants
for the disease before determining whether they
should be admitted. It costs T dollars to test a person
for the disease, and the test result is either positive or
negative. A person who does not have the disease
always tests negative. However, 10% of all people
who do have the disease test negative. The
government’s goal is to maximize the expected net
financial benefits per potential immigrant.
538
Chapter 9
Decision Making under Uncertainty
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

a. If x  10, what is the largest value of T at which
the U.S. government will choose to test potential
immigrants for the disease?
b. How does your answer to the question in part a
change if x increases to 15?
c. If x  5 and T  $500, what is the government’s
optimal strategy?
d. If x  5, calculate and interpret the expected value
of perfect information (EVPI) for this decision
problem.
54. The senior executives of an oil company are trying to
decide whether to drill for oil in a particular field in
the Gulf of Mexico. It costs the company $600,000 to
drill in the selected field. Company executives believe
that if oil is found in this field its estimated value will
be $3,400,000. At present, this oil company believes
that there is a 45% chance that the selected field
actually contains oil. Before drilling, the company
can hire a geologist at a cost of $55,000 to prepare a
report that contains a recommendation regarding
drilling in the selected field. In many similar situations
in the past where this geologist has been hired, the
geologist has predicted oil on 75% of all fields that
have contained oil, and he has predicted no oil on 85%
of all fields that have not contained oil.
a. Assuming that this oil company wants to 
maximize its expected net earnings, use a decision
tree to determine its optimal strategy.
b. Calculate and interpret EVSI for this decision
problem. Experiment with the accuracy
probabilities of the geologist to see how EVSI
changes as they change.
c. Calculate and interpret EVPI for this decision
problem.
55. FineHair is developing a new product to promote hair
growth in cases of male pattern baldness. If FineHair
markets the new product and it is successful, the com-
pany will earn $1,000,000 in additional profit. If the
marketing of this new product proves to be unsuccess-
ful, the company will lose $350,000 in development
and marketing costs. In the past, similar products have
been successful 30% of the time. At a cost of $50,000,
the effectiveness of the new restoration product can be
thoroughly tested. In past tests on similar products, the
test predicted success on 70% of products that were
ultimately successful, and it predicted failure on 75%
of products that were ultimately failures.
a. Identify the strategy that maximizes FineHair’s
expected net earnings in this situation.
b. Calculate and interpret EVSI for this decision
problem.
c. Calculate and interpret EVPI for this decision
problem.
56. A product manager at Clean & Brite (C&B) wants to
determine whether her company should market a
new brand of toothpaste. If this new product
succeeds in the marketplace, C&B estimates that it
could earn $1,800,000 in future profits from the sale
of the new toothpaste. If this new product fails,
however, the company expects that it could lose
approximately $750,000. If C&B chooses not to
market this new brand, the product manager believes
that there would be little, if any, impact on the
profits earned through sales of C&B’s other
products. The manager has estimated that the new
toothpaste brand will succeed with probability 0.50.
Before making her decision regarding this toothpaste
product, the manager can spend $75,000 on a market
research study. Based on similar studies with past
products, C&B believes that the study will predict a
successful product, given that product would
actually be a success, with probability 0.75. It also
believes that the study will predict a failure, given
that the product would actually be a failure, with
probability 0.65.
a. To maximize expected profit, what strategy should
the C&B product manager follow?
b. Calculate and interpret EVSI for this decision
problem.
c. Calculate and interpret EVPI for this decision
problem.
57. Ford is going to produce a new vehicle, the Pioneer,
and wants to determine the amount of annual capacity
it should build. Ford’s goal is to maximize the profit
from this vehicle over the next 10 years. Each vehicle
will sell for $13,000 and incur a variable production
cost of $10,000. Building one unit of annual capacity
will cost $3000. Each unit of capacity will also cost
$1000 per year to maintain, even if the capacity is
unused. Demand for the Pioneer is unknown but mar-
keting estimates the distribution of annual demand to
be as shown in the file P09_57.xlsx. Assume that the
number of units sold during a year is the minimum of
capacity and annual demand.
a. Explain why a capacity of 1,300,000 is not a good
choice.
b. Which capacity level should Ford choose?
58. Pizza King (PK) and Noble Greek (NG) are
competitive pizza chains. PK believes there is a 25%
chance that NG will charge $6 per pizza, a 50% chance
NG will charge $8 per pizza, and a 25% chance that
NG will charge $10 per pizza. If PK charges price p1
and NG charges price p2, PK will sell 100  25(p2 
p1) pizzas. It costs PK $4 to make a pizza. PK is
considering charging $5, $6, $7, $8, or $9 per pizza.
To maximize its expected profit, what price should PK
charge for a pizza?
59. Many decision problems have the following simple
structure. A decision maker has two possible decisions,
1 and 2. If decision 1 is made, a sure cost of c is
9.7 Conclusion
539
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

incurred. If decision 2 is made, there are two possible
outcomes, with costs c1 and c2 and probabilities p and
1  p. We assume that c1  c  c2. The idea is that
decision 1, the riskless decision, has a moderate cost,
whereas decision 2, the risky decision, has a low cost
c1 or a high cost c2.
a. Find the decision maker’s cost table, that is, the
cost for each possible decision and each possible
outcome.
b. Calculate the expected cost from the risky decision.
c. List as many scenarios as you can think of that
have this structure. (Here’s an example to get you
started. Think of insurance, where you pay a sure
premium to avoid a large possible loss.)
60. A nuclear power company is deciding whether to
build a nuclear power plant at Diablo Canyon or at
Roy Rogers City. The cost of building the power
plant is $10 million at Diablo and $20 million at Roy
Rogers City. If the company builds at Diablo,
however, and an earthquake occurs at Diablo during
the next five years, construction will be terminated
and the company will lose $10 million (and will still
have to build a power plant at Roy Rogers City).
Without further expert information the company
believes there is a 20% chance that an earthquake
will occur at Diablo during the next five years. For
$1 million, a geologist can be hired to analyze the
fault structure at Diablo Canyon. She will predict
either that an earthquake will occur or that an
earthquake will not occur. The geologist’s past record
indicates that she will predict an earthquake on 95%
of the occasions for which an earthquake will occur
and no earthquake on 90% of the occasions for which
an earthquake will not occur. Should the power
company hire the geologist? Also, calculate and
interpret EVSI and EVPI.
61. Consider again Techware’s decision problem described
in Problem 40. Suppose now that Techware’s utility
function of net revenue x (measured in dollars), 
earned from the given marketing opportunities, is 
.
a. Find the decision that maximizes Techware’s
expected utility. How does this optimal decision
compare to the optimal decision with an EMV
criterion? Explain any difference between the two
optimal decisions.
b. Repeat part a when Techware’s utility function is
.
62. Consider again the bank’s customer loan decision
problem in Problem 51. Suppose now that the 
bank’s utility function of profit x (in dollars) is
. Find the strategy that
maximizes the bank’s expected utility in this case.
How does this optimal strategy compare to the optimal
decision with an EMV criterion? Explain any
difference between the two optimal strategies.
63. The Indiana University basketball team trails by two
points with eight seconds to go and has the ball. Should
it attempt a two-point shot or a three-point shot?
Assume that the Indiana shot will end the game and that
no foul will occur on the shot. Assume that a three-
point shot has a 30% chance of success, and a 
two-point shot has a 45% chance of success. Finally,
assume that Indiana has a 50% chance of winning in
overtime.
Skill-Extending Problems
64. George Lindsey (1959) looked at box scores of more
than 1000 baseball games and found the expected
number of runs scored in an inning for each on-base
and out situation to be as listed in the file P09_64.xlsx.
For example, if a team has a man on first base with
one out, it scores 0.5 run on average until the end of
the inning. You can assume throughout this problem
that the team batting wants to maximize the expected
number of runs scored in the inning.
a. Use this data to explain why, in most cases,
bunting with a man on first base and no outs is a
bad decision. In what situation might bunting with
a man on first base and no outs be a good
decision?
b. Assume there is a man on first base with one out.
What probability of stealing second makes an
attempted steal a good idea?
65. One controversial topic in basketball (college or any
other level) is whether to foul a player deliberately
with only a few seconds left in the game. Specifically,
consider the following scenario. With about 10
seconds left in the game, team A is ahead of team B
by three points, and team B is just about to inbound
the ball. Assume team A has committed enough fouls
so that future fouls result in team B going to the free-
throw line. If team A purposely commits a foul as
soon as possible, team B will shoot two foul shots (a
point apiece). The thinking is that this is better than
letting team B shoot a three-point shot, which would
be their best way to tie the game and send it into
overtime. However, there is a downside to fouling.
Team B could make the first free throw, purposely
miss the second, get the rebound, and score a two-
point shot to tie the game, or it even score a three-
point shot to win the game. Examine this decision,
using reasonable input parameters. It doesn’t appear
that this deliberate fouling strategy is used very often,
but do you think it should be used?
66. The following situation actually occurred in a 2009
college football game between Washington and
U(x) = 1 - e-x/150000
U(x) = 1 - e-x/50000
U(x) = 1 - e-x/350000
540
Chapter 9
Decision Making under Uncertainty
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Notre Dame. With about 3.5 minutes left in the game,
Washington had fourth down and one yard to go for
a touchdown, already leading by two points. Notre
Dame had just had two successful goal-line stands
from in close, so Washington’s coach decided not
to go for the touchdown and the virtually sure win.
Instead, Washington kicked a field goal, and Notre
Dame eventually won in overtime. Use a decision
tree, with some reasonable inputs, to see whether
Washington made a wise decision or should have gone
for the touchdown. Note the only “monetary” values
here are 1 and 0. You can think of Washington getting
$1 if they win and $0 if they lose. Then the EMV is
1*P(Win)  0*P(lose)  P(Win), so maximizing
EMV is equivalent to maximizing the probability of
winning.
67. Mr. Maloy has just bought a new $30,000 sport utility
vehicle. As a reasonably safe driver, he believes that
there is only about a 5% chance of being in an accident
in the coming year. If he is involved in an accident, the
damage to his new vehicle depends on the severity of
the accident. The probability distribution for the range
of possible accidents and the corresponding damage
amounts (in dollars) are given in the file P09_67.xlsx.
Mr. Maloy is trying to decide whether he is willing to
pay $170 each year for collision insurance with a $300
deductible. Note that with this type of insurance, he
pays the first $300 in damages if he causes an accident
and the insurance company pays the remainder.
a. Create a cost table that specifies the cost (in
dollars) associated with each possible decision and
type of accident.
b. Use PrecisionTree to identify the strategy that
minimizes Mr. Maloy’s annual expected cost.
c. Perform a sensitivity analysis on the optimal
decision with respect to the probability of an
accident, the premium, and the deductible amount,
and summarize your findings. (You can choose the
ranges to test.) In response to which of these three
inputs is the expected cost most sensitive?
68. The purchasing agent for a PC manufacturer is
currently negotiating a purchase agreement for a
particular electronic component with a given supplier.
This component is produced in lots of 1000, and the
cost of purchasing a lot is $30,000. Unfortunately,
past experience indicates that this supplier has
occasionally shipped defective components to its
customers. Specifically, the proportion of defective
components supplied by this supplier has the
probability distribution given in the file P09_68.xlsx.
Although the PC manufacturer can repair a defective
component at a cost of $20 each, the purchasing agent
learns that this supplier will now assume the cost of
replacing defective components in excess of the first
100 faulty items found in a given lot. This guarantee
may be purchased by the PC manufacturer prior to the
receipt of a given lot at a cost of $1000 per lot. The
purchasing agent wants to determine whether it is
worthwhile to purchase the supplier’s guarantee
policy.
a. Create a cost table that specifies the PC
manufacturer’s total cost (in dollars) of purchasing
and repairing (if necessary) a complete lot of
components for each possible decision and each
outcome with respect to the proportion of defective
items.
b. Use PrecisionTree to identify the strategy that
minimizes the expected total cost of achieving a
complete lot of satisfactory microcomputer
components.
c. Perform a sensitivity analysis on the optimal decision
with respect to the number of components per lot
and the three monetary inputs, and summarize your
findings. (You can choose the ranges to test.) In
response to which of these inputs is the expected cost
most sensitive?
69. A home appliance company is interested in marketing
an innovative new product. The company must decide
whether to manufacture this product in house or
employ a subcontractor to manufacture it. The file
P09_69.xlsx contains the estimated probability
distribution of the cost of manufacturing one unit
of this new product (in dollars) if the home appliance
company produces the product in house. This file also
contains the estimated probability distribution of the
cost of purchasing one unit of the product if from the
subcontractor. There is also uncertainty about demand
for the product in the coming year, as shown in the
same file. The company plans to meet all demand,
but there is a capacity issue. The subcontractor has
unlimited capacity, but the home appliance company
has capacity for only 5000 units per year. If it decides
to make the product in house and demand is greater
than capacity, it will have to purchase the excess
demand from an external source at a premium: $225 per
unit. Assuming that the company wants to minimize
the expected cost of meeting demand in the coming
year, should it make the new product in house or buy it
from the subcontractor? Do you need a decision tree,
or will a cost table with EMV calculations suffice?
(You can assume that neither the company nor the
subcontractor will ever produce more than demand.)
70. A grapefruit farmer in central Florida is trying to
decide whether to take protective action to limit
damage to his crop in the event that the overnight
temperature falls to a level well below freezing. He is
concerned that if the temperature falls sufficiently
low and he fails to make an effort to protect his
grapefruit trees, he runs the risk of losing his entire
crop, which is worth approximately $75,000. Based
9.7 Conclusion
541
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

on the latest forecast issued by the National Weather
Service, the farmer estimates that there is a 60%
chance that he will lose his entire crop if it is left
unprotected. Alternatively, the farmer can insulate
his fruit by spraying water on all of the trees in his
orchards. This action, which would likely cost the
farmer C dollars, would prevent total devastation but
might not completely protect the grapefruit trees
from incurring some damage as a result of the
unusually cold overnight temperatures. The file
P09_70.xlsx contains the assessed distribution of
possible damages (in dollars) to the insulated fruit in
light of the cold weather forecast. The farmer wants
to minimize the expected total cost of coping with
the threatening weather.
a. Find the maximum value of C below which the
farmer should insulate his crop to limit the damage
from the unusually cold weather.
b. Set C equal to the value identified in part a.
Perform sensitivity analysis to determine under
what conditions, if any, the farmer would be better
off not spraying his grapefruit trees and taking his
chances in spite of the threat to his crop.
c. Suppose that C equals $25,000, and in addition to
this protection, the farmer can purchase insurance
on the crop. Discuss possibilities for reasonable
insurance policies and how much they would be
worth to the farmer. You can assume that the
insurance is relevant only if the farmer purchases
the protection, and you can decide on the terms of
the insurance policy.
71. A retired partner from a large brokerage firm has 
one million dollars available to invest in particular
stocks or bonds. Each investment’s annual rate of
return depends on the state of the economy in the
coming year. The file P09_71.xlsx contains the
distribution of returns for these stocks and bonds as 
a function of the economy’s state in the coming year.
As this file indicates, the returns from stocks and
bonds in a fair economy are listed as X and Y. This
investor wants to allocate her one million dollars to
maximize her expected value of the portfolio one year
from now.
a. If X  Y  15%, find the optimal investment strat-
egy for this investor. (Hint: You could try a decision
tree approach, but it would involve a massive tree.
It is much easier to find an algebraic expression for
the expected final value of the investment when a
percentage p is put in stocks and the remaining
percentage is put in bonds. Given this expression,
the best value of p should be obvious.)
b. For which values of X (where 10%  X  20%)
and Y (where 12.5%  Y  17.5%), if any, will this
investor prefer to place all of her available funds in
stocks? Use the same method as in part a for each
combination of X and Y.
72. A city in Ohio is considering replacing its fleet of
gasoline-powered automobiles with electric cars. The
manufacturer of the electric cars claims that this
municipality will experience significant cost savings
over the life of the fleet if it chooses to pursue the
conversion. If the manufacturer is correct, the city will
save about $1.5 million dollars. If the new technology
employed within the electric cars is faulty, as some
critics suggest, the conversion to electric cars will cost
the city $675,000. A third possibility is that less
serious problems will arise and the city will break
even with the conversion. A consultant hired by the
city estimates that the probabilities of these three
outcomes are 0.30, 0.30, and 0.40, respectively. The
city has an opportunity to implement a pilot program
that would indicate the potential cost or savings
resulting from a switch to electric cars. The pilot
program involves renting a small number of electric
cars for three months and running them under typical
conditions. This program would cost the city $75,000.
The city’s consultant believes that the results of the
pilot program would be significant but not conclusive;
she submits the values in the file P09_72.xlsx, a
compilation of probabilities based on the experience
of other cities, to support her contention. For example,
the first row of her table indicates that given that a
conversion to electric cars actually results in a savings
of $1.5 million, the conditional probabilities that the
pilot program will indicate that the city saves money,
loses money, and breaks even are 0.6, 0.1, and 0.3,
respectively. What actions should the city take to
maximize its expected savings? When should it run
the pilot program, if ever? (Note: If you set up the
input section of your spreadsheet in the right way,
you will be able to perform all of the Bayes’ rule
calculations with a couple of copyable formulas.)
73. A manufacturer must decide whether to extend credit
to a retailer who would like to open an account with
the firm. Past experience with new accounts indicates
that 45% are high-risk customers, 35% are moderate-
risk customers, and 20% are low-risk customers. If
credit is extended, the manufacturer can expect to lose
$60,000 with a high-risk customer, make $50,000 with
a moderate-risk customer, and make $100,000 with a
low-risk customer. If the manufacturer decides not to
extend credit to a customer, the manufacturer neither
makes nor loses any money. Prior to making a credit
extension decision, the manufacturer can obtain a
credit rating report on the retailer at a cost of $2000.
The credit agency concedes that its rating procedure
is not completely reliable. In particular, the credit
rating procedure will rate a low-risk customer as a
moderate-risk customer with probability 0.10 and as a
high-risk customer with probability 0.05. Similarly,
the given rating procedure will rate a moderate-risk
customer as a low-risk customer with probability 0.06
542
Chapter 9
Decision Making under Uncertainty
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

and as a high-risk customer with probability 0.07.
Finally, the rating procedure will rate a high-risk
customer as a low-risk customer with probability 0.01
and as a moderate-risk customer with probability 0.05.
Find the strategy that maximizes the manufacturer’s
expected net earnings. (Note: If you set up the input
section of your spreadsheet in the right way, you will
be able to perform all of the Bayes’ rule calculations
with a couple of copyable formulas.)
74. A television network earns an average of $1.6 million
each season from a hit program and loses an average
of $400,000 each season on a program that turns out to
be a flop. Of all programs picked up by this network
in recent years, 25% turn out to be hits and 75% turn
out to be flops. At a cost of C dollars, a market
research firm will analyze a pilot episode of a prospec-
tive program and issue a report predicting whether the
given program will end up being a hit. If the program
is actually going to be a hit, there is a 90% chance that
the market researchers will predict the program to be a
hit. If the program is actually going to be a flop, there
is only a 20% chance that the market researchers will
predict the program to be a hit.
a. Assuming that C  $160,000, find the strategy that
maximizes the network’s expected profit.
b. What is the maximum value of C that the network
should be willing to pay the market research firm?
c. Calculate and interpret EVPI for this decision
problem.
75. A publishing company is trying to decide whether
to publish a new business law textbook. Based on
a careful reading of the latest draft of the manuscript,
the publisher’s senior editor in the business textbook
division assesses the distribution of possible payoffs
earned by publishing this new book. The file
P09_75.xlsx contains this probability distribution.
Before making a final decision regarding the
publication of the book, the editor can learn more
about the text’s potential for success by thoroughly
surveying business law instructors teaching at
universities across the country. Historical frequencies
based on similar surveys administered in the past are
also provided in this file.
a. Find the strategy that maximizes the publisher’s
expected payoff if the survey cost is $10,000.
b. What is the most that the publisher would be
willing to pay to conduct a new survey of business
law instructors?
c. Assuming that a survey could be constructed that
provides perfect information to the publisher, how
much would the company be willing to pay to
acquire and implement such a survey?
76. Sharp Outfits is trying to decide whether to ship some
customer orders now via UPS or wait until after the
threat of another UPS strike is over. If Sharp Outfits
decides to ship the requested merchandise now and
the UPS strike takes place, the company will incur
$60,000 in delay and shipping costs. If Sharp Outfits
decides to ship the customer orders via UPS and no
strike occurs, the company will incur $4000 in
shipping costs. If Sharp Outfits decides to postpone
shipping its customer orders via UPS, the company
will incur $10,000 in delay costs regardless of whether
UPS goes on strike. Let p represent the probability that
UPS will go on strike and impact Sharp Outfits’s
shipments.
a. For which values of p, if any, does Sharp Outfits
minimize its expected total cost by choosing to
postpone shipping its customer orders via UPS?
b. Suppose now that, at a cost of $1000, Sharp Outfits
can purchase information regarding the likelihood
of a UPS strike in the near future. Based on similar
strike threats in the past, the company assesses that
if there will be a strike, the information will predict
a strike with probability 0.75, and if there will not
be a strike, the information will predict no strike
with probability 0.85. Provided that p  0.15, what
strategy should Sharp Outfits pursue to minimize
its expected total cost?
c. Use the tree from part b to find the EVSI when 
p  0.15. Then use a data table to find EVSI for p
from 0.05 to 0.30 in increments of 0.05, and chart
EVSI versus p. 
d. Continuing part b, compute and interpret the EVPI
when p  0.15.
77. A homeowner wants to decide whether he should install
an electronic heat pump in his home. Given that the cost
of installing a new heat pump is fairly large, the
homeowner wants to do so only if he can count on being
able to recover the initial expense over five consecutive
years of cold winter weather. After reviewing historical
data on the operation of heat pumps in various kinds of
winter weather, he computes the expected annual costs
of heating his home during the winter months with and
without a heat pump in operation. These cost figures are
shown in the file P09_77.xlsx. The probabilities of
experiencing a mild, normal, colder than normal, and
severe winter are 0.2(1  x), 0.5(1  x), 0.3(1  x),
and x, respectively. In words, we let the last probability
vary, we let the other three be in the ratio 2 to 5 to 3, and
we force them to sum to 1.
a. Given that x  0.1, what is the most that the
homeowner is willing to pay for the heat pump?
b. If the heat pump costs $500, how large must x be
before the homeowner decides it is economically
worthwhile to install the heat pump?
c. Given that x  0.1, calculate and interpret EVPI
when the heat pump costs $500.
d. Repeat part c when x  0.15.
78. Sarah Chang is the owner of a small electronics
company. In six months, a proposal is due for an 
9.7 Conclusion
543
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

electronic timing system for the next Olympic Games.
For several years, Chang’s company has been
developing a new microprocessor, a critical
component in a timing system that would be superior
to any product currently on the market. However,
progress in research and development has been slow,
and Chang is unsure whether her staff can produce
the microprocessor in time. If they succeed in
developing the microprocessor (probability p1), there
is an excellent chance (probability p2) that Chang’s
company will win the $1 million Olympic contract.
If they do not, there is a small chance (probability p3)
that she will still be able to win the same contract
with an alternative but inferior timing system that has
already been developed. If she continues the project,
Chang must invest $200,000 in research and
development. In addition, making a proposal (which
she will decide whether to do after seeing whether the
R&D is successful) requires developing a prototype
timing system at an additional cost. This additional
cost is $50,000 if R&D is successful (so that she can
develop the new timing system), and it is $40,000 if
R&D is unsuccessful (so that she needs to go with the
older timing system). Finally, if Chang wins the
contract, the finished product will cost an additional
$150,000 to produce.
a. Develop a decision tree that can be used to solve
Chang’s problem. You can assume in this part of
the problem that she is using EMV (of her net
profit) as a decision criterion. Build the tree so
that she can enter any values for p1, p2, and p3 (in
input cells) and automatically see her optimal
EMV and optimal strategy from the tree.
b. If p2  0.8 and p3  0.1, what value of p1 makes
Chang indifferent between abandoning the project
and going ahead with it?
c. How much would Chang benefit if she knew for
certain that the Olympic organization would
guarantee her the contract? (This guarantee would
be in force only if she were successful in developing
the product.) Assume p1  0.4, p2  0.8, and 
p3  0.1.
d. Suppose now that this is a relatively big project for
Chang. Therefore, she decides to use expected
utility as her criterion, with an exponential utility
function. Using some trial and error, see which risk
tolerance changes her initial decision from “go
ahead” to “abandon” when p1  0.4, p2  0.8, and
p3  0.1.
79. The Ventron Engineering Company has just been
awarded a $2 million development contract by the
U.S. Army Aviation Systems Command to develop a
blade spar for its Heavy Lift Helicopter program. The
blade spar is a metal tube that runs the length of and
provides strength to the helicopter blade. Due to the
unusual length and size of the Heavy Lift Helicopter
blade, Ventron is unable to produce a single-piece
blade spar of the required dimensions using existing
extrusion equipment and material. The engineering
department has prepared two alternatives for
developing the blade spar: (1) sectioning or (2) an
improved extrusion process. Ventron must decide
which process to use. (Backing out of the contract at
any point is not an option.) The risk report has been
prepared by the engineering department. The
information from this report is explained next.
The sectioning option involves joining several
shorter lengths of extruded metal into a blade 
spar of sufficient length. This work will require
extensive testing and rework over a 12-month
period at a total cost of $1.8 million. Although this
process will definitely produce an adequate blade
spar, it merely represents an extension of existing
technology.
To improve the extrusion process, on the other
hand, it will be necessary to perform two steps: 
(1) improve the material used, at a cost of $300,000,
and (2) modify the extrusion press, at a cost of
$960,000. The first step will require six months of
work, and if this first step is successful, the second
step will require another six months of work. If both
steps are successful, the blade spar will be available at
that time, that is, a year from now. The engineers esti-
mate that the probabilities of succeeding in steps 1 and
2 are 0.9 and 0.75, respectively. However, if either step
is unsuccessful (which will be known only in six
months for step 1 and in a year for step 2), Ventron
will have no alternative but to switch to the sectioning
process—and incur the sectioning cost on top of any
costs already incurred.
Development of the blade spar must be completed
within 18 months to avoid holding up the rest of the
contract. If necessary, the sectioning work can be done
on an accelerated basis in a six-month period, but the
cost of sectioning will then increase from $1.8 million
to $2.4 million. The director of engineering, Dr. Smith,
wants to try developing the improved extrusion process.
He reasons that this is not only cheaper (if successful)
for the current project, but its expected side benefits for
future projects could be sizable. Although these side
benefits are difficult to gauge, Dr. Smith’s best guess is
an additional $2 million. (These side benefits are
obtained only if both steps of the modified extrusion
process are completed successfully.)
a. Develop a decision tree to maximize Ventron’s
EMV. This includes the revenue from this project,
the side benefits (if applicable) from an improved
extrusion process, and relevant costs. You don’t
need to worry about the time value of money;
that is, no discounting or net present values are
required. Summarize your findings in words in
the spreadsheet.
544
Chapter 9
Decision Making under Uncertainty
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

b. What value of side benefits would make Ventron
indifferent between the two alternatives?
c. How much would Ventron be willing to pay, right
now, for perfect information about both steps of
the improved extrusion process? (This information
would tell Ventron, right now, the ultimate success
or failure outcomes of both steps.)
80. Suppose an investor has the opportunity to buy the
following contract, a stock call option, on March 1.
The contract allows him to buy 100 shares of ABC
stock at the end of March, April, or May at a
guaranteed price of $50 per share. He can exercise this
option at most once. For example, if he purchases the
stock at the end of March, he can’t purchase more in
April or May at the guaranteed price. The current price
of the stock is $50. Each month, assume that the stock
price either goes up by a dollar (with probability 0.55)
or goes down by a dollar (with probability 0.45). If the
investor buys the contract, he is hoping that the stock
price will go up. The reasoning is that if he buys the
contract, the price goes up to $51, and he buys the
stock (that is, he exercises his option) for $50, he can
then sell the stock for $51 and make a profit of $1 per
share. On the other hand, if the stock price goes down,
he doesn’t have to exercise his option; he can just
throw the contract away.
a. Use a decision tree to find the investor’s optimal
strategy (that is, when he should exercise the
option), assuming he purchases the contract.
b. How much should he be willing to pay for such a
contract?
81. [Based on Balson et al. (1992).] An electric utility
company is trying to decide whether to replace its PCB
transformer in a generating station with a new and safer
transformer. To evaluate this decision, the utility needs
information about the likelihood of an incident, such as a
fire, the cost of such an incident, and the cost of replacing
the unit. Suppose that the total cost of replacement as a
present value is $75,000. If the transformer is replaced,
there is virtually no chance of a fire. However, if the
current transformer is retained, the probability of a fire is
assessed to be 0.0025. If a fire occurs, the cleanup cost
could be high ($80 million) or low ($20 million). The
probability of a high cleanup cost, given that a fire
occurs, is assessed at 0.2.
a. If the company uses EMV as its decision criterion,
should it replace the transformer?
b. Perform a sensitivity analysis on the key parameters
of the problem that are difficult to assess, namely,
the probability of a fire, the probability of a high
cleanup cost, and the high and low cleanup costs.
Does the optimal decision from part a remain
optimal for a wide range of these parameters?
c. Do you believe EMV is the correct criterion to use
in this type of problem involving environmental
accidents?
82. The ending of the game between the Indianapolis
Colts and the New England Patriots (NFL teams) in
Fall 2009 was quite controversial. With about two
minutes left in the game, the Patriots were ahead
34 to 28 and had the ball on their own 28-yard line
with fourth down and two yards to go. Their coach,
Bill Belichick, decided to go for the first down rather
than punt, contrary to conventional wisdom. They
didn’t make the first down, so that possession went to
the Colts, who then scored a touchdown to win by a
point. Belichick was harshly criticized by most of
the media, but was his unorthodox decision really a
bad one? 
a. Use a decision tree to analyze the problem. You
can make some simplifying decisions: (1) the
game would essentially be over if the Patriots
made a first down, and (2) at most one score
would occur after a punt or a failed first down
attempt. (Note that there are no monetary values.
However, you can assume the Patriots receive $1
for a win and $0 for a loss, so that maximizing
EMV is equivalent to maximizing the probability
that the Patriots win.)
b. Show that the Patriots should go for the first down
if p  1  q/r. Here, p is the probability the Patriots
make the first down, q is the probability the Colts
score a touchdown after a punt, and r is the
probability the Colts score a touchdown after the
Patriots fail to make a first down. What are your
best guesses for these three probabilities? Based on
them, was Belichick’s decision a good one?
83. Suppose you believe that the price of a particular stock
goes up each day with probability p and goes down
with probability 1-p. You also believe the daily price
changes are independent of one another. However,
you are not sure of the value of p. Based on your
current information, you believe p could be 0.40, 0.45,
0.50, or 0.55, with probabilities 0.15, 0.25, 0.35, and
0.25, respectively. Then you watch the stock price
changes for 25 days and observe 12 ups and 13 downs.
Use Bayes’ rule to find the posterior distribution of p.
Based on this posterior distribution, calculate the
probability that there will be at least 15 ups in the next
30 price changes. (Hint: Think in terms of the
binomial distribution.)
Modeling Problems
84.
Your company needs to make an important decision
that involves large monetary consequences. You have
listed all of the possible outcomes and the monetary
payoffs and costs from all outcomes and all potential
decisions. You want to use the EMV criterion, but you
realize that this requires probabilities and you see
no way to find the required probabilities. What can
you do?
9.7 Conclusion
545
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

85. If your company makes a particular decision in the
face of uncertainty, you estimate that it will either gain
$10,000, gain $1000, or lose $5000, with probabilities
0.40, 0.30, and 0.30, respectively. You 
(correctly) calculate the EMV as $2800. However, you
distrust the use of this EMV for decision-
making purposes. After all, you reason that you will
never receive $2800; you will receive $10,000, $1000,
or lose $5000. Discuss this reasoning.
86. In the previous question, suppose you have the option
of receiving a check for $2700 instead of making the
risky decision described. Would you make the risky
decision, where you could lose $5000, or would you
take the sure $2700? What would influence your
decision?
87. In a classic oil-drilling example, you are trying to
decide whether to drill for oil on a field that might
or might not contain any oil. Before making this
decision, you have the option of hiring a geologist
to perform some seismic tests and then predict
whether there is any oil or not. You assess that if there
is actually oil, the geologist will predict there is oil
with probability 0.85. You also assess that if there is
no oil, the geologist will predict there is no oil with
probability 0.90. Why will these two probabilities not
appear on the decision tree? Which probabilities will
be on the decision tree?
88. Your company has signed a contract with a good
customer to ship the customer an order no later than
20 days from now. The contract indicates that the
customer will accept the order even if it is late, but
instead of paying the full price of $10,000, it will be
allowed to pay 10% less, $9000, due to lateness. You
estimate that it will take anywhere from 17 to 22 days
to ship the order, and each of these is equally likely.
You believe you are in good shape, reasoning that the
expected days to ship is the average of 17 through 22,
or 19.5 days. Because this is less than 20, you will get
your full $10,000. What is wrong with your
reasoning?
89. You must make one of two decisions, each with
possible gains and possible losses. One of these
decisions is much riskier than the other, having much
larger possible gains but also much larger possible
losses, and it has a larger EMV than the safer decision.
Because you are risk averse and the monetary values
are large relative to your wealth, you base your
decision on expected utility, and it indicates that you
should make the safer decision. It also indicates that
the certainty equivalent for the risky decision is
$210,000, whereas its EMV is $540,000. What do
these two numbers mean? What do you know about
the certainty equivalent of the safer decision? 
90. A potentially huge hurricane is forming in the
Caribbean, and there is some chance that it might
make a direct hit on Hilton Head Island, South
Carolina, where you are in charge of emergency
preparedness. You have made plans for evacuating
everyone from the island, but such an evacuation is
obviously costly and upsetting for all involved, so the
decision to evacuate shouldn’t be made lightly.
Discuss how you would make such a decision. Is
EMV a relevant concept in this situation? How would
you evaluate the consequences of uncertain outcomes?
91. It seems obvious that if you can purchase information
before making an ultimate decision, this information
should generally be worth something, but explain
exactly why (and when) it is sometimes worth nothing.
92. Insurance companies wouldn’t exist unless customers
were willing to pay the price of the insurance and the
insurance companies were making a profit. So explain
how insurance is a win-win proposition for customers
and the company.
93. You often hear about the trade-off between risk and
reward. Is this trade-off part of decision making under
uncertainty when the decision maker uses the EMV
criterion? For example, how does this work in
investment decisions?
94. Can you ever use the material in this chapter to help
you make your own real-life decisions? Consider the
following. You are about to take an important and
difficult exam in one of your MBA courses, and
you see an opportunity to cheat. Obviously, from an
ethical point of view, you shouldn’t cheat, but from
a purely monetary point of view, could it also be the
wrong decision? To model this, consider the long-term
monetary consequences of all possible outcomes.
546
Chapter 9
Decision Making under Uncertainty
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

T
he Jogger Shoe Company is trying to decide
whether to make a change in its most popular
brand of running shoes. The new style would cost
the same to produce and be priced the same, but it
would incorporate a new kind of lacing system that
(according to its marketing research people) would
make it more popular.
There is a fixed cost of $300,000 for changing
over to the new style. The unit contribution to
before-tax profit for either style is $8. The tax rate is
35%. Also, because the fixed cost can be depreciated
and will therefore affect the after-tax cash flow, a
depreciation method is needed. You can assume it is
straight-line depreciation.
The current demand for these shoes is 190,000
pairs annually. The company assumes this demand
will continue for the next three years if the current
style is retained. However, there is uncertainty about
demand for the new style, if it is introduced. The
company models this uncertainty by assuming a
normal distribution in year 1, with mean 220,000
and standard deviation 20,000. The company also
assumes that this demand, whatever it is, will remain
constant for the next three years. However, if
demand in year 1 for the new style is sufficiently low,
the company can always switch back to the current
style and realize an annual demand of 190,000. The
company wants a strategy that will maximize the
expected net present value (NPV) of total cash flow
for the next three years, where a 15% interest rate is
used for the purpose of calculating NPV. ■
9.1 JOGGER SHOE COMPANY
Case 9.1 Jogger Shoe Company
547
C A S E
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

C A S E
T
he Westhouser Paper Company in the state of
Washington currently has an option to purchase
a piece of land with good timber forest on it. It is
now May 1, and the current price of the land is
$2.2 million. Westhouser does not actually need the
timber from this land until the beginning of July, but
its top executives fear that another company might
buy the land between now and the beginning of July.
They assess that there is a 5% chance that a
competitor will buy the land during May. If this does
not occur, they assess that there is a 10% chance that
the competitor will buy the land during June. If
Westhouser does not take advantage of its current
option, it can attempt to buy the land at the
beginning of June or the beginning of July, provided
that it is still available.
Westhouser’s incentive for delaying the purchase
is that its financial experts believe there is a good
chance that the price of the land will fall significantly
in one or both of the next two months. They assess
the possible price decreases and their probabilities
in Table 9.7 and Table 9.8. Table 9.7 shows the
probabilities of the possible price decreases during
May. Table 9.8 lists the conditional probabilities of the
possible price decreases in June, given the price
decrease in May. For example, it indicates that if the
price decrease in May is $60,000, then the possible
price decreases in June are $0, $30,000, and $60,000
with respective probabilities 0.6, 0.2, and 0.2.
If Westhouser purchases the land, it believes that
it can gross $3 million. (This does not count the
cost of purchasing the land.) But if it does not
purchase the land,Westhouser believes that it can
make $650,000 from alternative investments. What
should the company do?
Table 9.7
Distribution of Price Decrease in May
Price Decrease
Probability
$0
0.5
$60,000
0.3
$120,000
0.2
9.2 WESTHOUSER PAPER COMPANY
548
Chapter 9
Decision Making under Uncertainty
Table 9.8 Distribution of Price Decrease in June
Price Decrease in May
$0
$60,000
$120,000
June Decrease
Probability
June Decrease
Probability
June Decrease
Probability
$0
0.3
$0
0.6
$0
0.7
$60,000
0.6
$30,000
0.2
$20,000
0.2
$120,000
0.1
$60,000
0.2
$40,000
0.1
■
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

C A S E
B
iotechnical Engineering specializes in developing
new chemicals for agricultural applications. The
company is a pioneer in using the sterile-male pro-
cedure to control insect infestations. It operates
several laboratories around the world that raise
insects and expose them to extra-large doses of
radiation, making them sterile. As an alternative to
chlorinated hydrocarbon pesticides, such as DDT,
the sterile-male procedure has been used frequently
with a good track record of success, most notably
with the Mediterranean fruit fly (or Medfly).
That pest was controlled in California through
the release of treated flies on the premise that the
sterile male flies would compete with fertile wild
males for mating opportunities. Any female that has
mated with a sterile fly will lay eggs that do not hatch.
The California Medfly campaigns required about five
successive releases of sterile males—at intervals timed
to coincide with the time for newly hatched flies to
reach adulthood—before the Medfly was virtually
eliminated. (Only sterile flies were subsequently
caught in survey traps.) The effectiveness of the
sterile-male procedure was enhanced by the release
of malathion poisonous bait just a few days before
each release, cutting down on the number of viable
wild adults.
More recently, Biotechnical Engineering has had
particular success in using genetic engineering to
duplicate various insect hormones and pheromones
(scent attractants). Of particular interest is the
application of such methods against the Gypsy Moth,
a notorious pest that attacks trees. The company has
developed synthetic versions of both hormones and
pheromones for that moth. It has a synthetic sexual
attractant that male moths can detect at great
distances. Most promising is the synthetic juvenile
hormone.
The juvenile hormone controls moth meta-
morphosis, determining the timing for the trans-
formation of a caterpillar into a chrysalis and then into
an adult. Too much juvenile hormone wreaks havoc
with this process, causing caterpillars to turn into
freak adults that cannot reproduce.
Biotechnical Engineering has received a
government contract to test its new technology in
an actual eradication campaign. The company will
participate in a small-scale campaign against the
Gypsy Moth in the state of Oregon. Because the pest
is so damaging, Dr. June Scribner, the administrator in
charge, is considering using DDT as an alternative
procedure. Of course, that banned substance is only
available for government emergency use because of
the environmental damage it may cause. In addition
to spraying with DDT, two other procedures may be
employed: (1) using Biotechnical’s scent lure, followed
by the release of sterile males, and (2) spraying with
the company’s juvenile hormone to prevent larvae
from developing into adults. Dr. Scribner wants to
select the method that yields the best expected
payoff, described below.
Although both of the newer procedures are
known to work under laboratory conditions, there
is some uncertainty about successful propagation of
the chemicals in the wild and about the efficacy of
the sterile-male procedure with moths.
If the scent-lure program is launched at a cost of
$5 million, Biotechnical claims that it will have a fifty-
fifty chance of leaving a low number of native males
versus a high number. Once the results of that phase
are known, a later choice must be made to spray with
DDT or to release sterile males;the cost of the
sterilization and delivery of the insects to the countrsi
de is an additional $5 million. But if this two-phase
program is successful, the net present value of the
worth of trees saved is $30 million, including the
benefit of avoiding all other forms of environmental
damage. The indigenous moth population would be
destroyed, and a new infestation could occur only
from migrants. Biotechnical’s experience with other
eradication programs indicates that if the scent lure
leaves a small native male population, there is a 90%
chance for a successful eradication by using sterile
males;otherwise, there is only a 10% chance for
success by using sterile males. A failure results in
no savings.
9This case was written by Lawrence L. Lapin, San Jose State
University.
9.3 BIOTECHNICAL ENGINEERING9
Case 9.3 Biotechnical Engineering
549
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

550
Chapter 9
Decision Making under Uncertainty
The cost of synthesizing enough juvenile
hormone is $3 million. Biotechnical maintains that
the probability that the hormone can be effectively
disseminated is only 0.20. If it works, the worth of the
trees saved and environmental damage avoided will be
$50 million. This greater level of savings is possible
because of the permanent nature of the solution
because a successful juvenile hormone can then be
applied wherever the moths are known to exist,
virtually eliminating the pest from the environment.
But if the hormone does not work, the DDT must
still be used to save the trees.
DDT constitutes only a temporary solution,
and the worth of its savings in trees is far less than
the worth of either of the esoteric eradication
procedures—if they prove successful. To compare
alternatives, Dr. Scribner proposes using the net
advantage (crop and environmental savings, minus
cost) relative to where she would be were she to
decide to use DDT at the outset or were she to be
forced to spray with it later. (Regardless of the out-
come, Biotechnical will be reimbursed for all expendi-
tures. The decision is hers, not the company’s.)
Questions
1.
Under Biotechnical’s proposal, the selection
of DDT without even trying the other
procedures would lead to a neutral outcome
for the government, having zero payoff. Discuss
the benefits of Dr. Scribner’s proposed payoff
measure.
2.
Construct Dr. Scribner’s decision tree diagram,
using the proposed payoff measure.
3.
What action will maximize Dr. Scribner’s
expected payoff?
4.
Dr.Scribner is concerned about the assumed fifty-
fifty probability for the two levels of surviving
native males following the scent-lure program.
a. Redo the decision tree analysis to find what
action will maximize Dr.Scribner’s expected
payoff when the probability of low native males
is,successively,(1) 0.40 or (2) 0.60 instead.
b. How is the optimal action affected by the
probability level assumed for the low native
male outcome?
5.
Dr. Scribner is concerned about the assumed
0.20 probability for the dissemination success 
of the juvenile hormone.
a. Keeping all other probabilities and cash flows
at their original levels,redo the decision tree
analysis to find what action will maximize 
Dr.Scribner’s expected payoff when the
probability of juvenile hormone success is,
successively,(1) 0.15 or (2) 0.25 instead.
b. How is the optimal action affected by the
probability level assumed for the juvenile
hormone’s success?
6.
Dr. Scribner is concerned about the assumed
probability levels for the success of the sterile-
male procedure.
a. Keeping all other probabilities and cash flows
at their original levels, redo the decision tree
analysis to find what action will maximize
Dr. Scribner’s expected payoff when the
sterile-male success probabilities are instead
as follows:
(1) 80% for a low number of native males and
5% for a high number of native males
(2) 70% for a low number of native males and
15% for a high number of native males
b. How is the optimal action affected by the
probability level assumed for the success of
the sterile-male procedure?
7.
Dr. Scribner is concerned about the assumed
levels for the net present value of the worth of
trees saved and damage avoided. She believes
these amounts are only accurate within a range
of 10%.
a. Keeping all other probabilities and cash flows
at their original levels, redo the decision tree
analysis to find what action will maximize
Dr. Scribner’s expected payoff when the two
net present values are instead, successively,
(1) 10% lower or (2) 10% higher than origi-
nally assumed.
b. How is the optimal action affected by the
level assumed for the NPVs of the savings
from using one of the two esoteric Gypsy
Moth eradication procedures? ■
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

551
DEVELOPING BOARDING STRATEGIES 
AT AMERICA W
 EST
M
anagement science often attempts to solve problems that we all
experience. One such problem is the boarding process for airline flights.
As customers, we all hate to wait while travelers boarding ahead of us store
their luggage and block the aisles. But this is also a big problem for the airlines.
Airlines lose money when their airplanes are on the ground, so they have a
real incentive to reduce the turnaround time from when a plane lands until it
departs on its next flight. Of course, the turnaround time is influenced by
several factors, including passenger deplaning, baggage unloading, fueling, cargo
unloading, airplane maintenance, cargo loading, baggage loading, and passenger
boarding. Airlines try to perform all of these tasks as efficiently as possible, but
passenger boarding is particularly difficult to shorten. Although the airlines
want passengers to board as quickly as possible, they don’t want to use
measures that might antagonize their passengers.
One study by van den Briel et al. (2005) indicates how a combination
of management science methods, including simulation, was used to make
passenger boarding more efficient at America West Airlines. America West
(which merged with US Airways in 2006) was a major U.S. carrier based in
Phoenix, Arizona. It served more destinations nonstop than any other airline.
Image Source/Jupiter Images
Introduction to Simulation Modeling
C H A P T E R
10
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

The airline’s fleet consisted of Airbus A320s, Airbus A319s, Boeing 757s, Boeing 737s, and
Airbus A318s.
At the time of the study, airlines used a variety of boarding strategies, but the
predominant strategy was the back-to-front (BF) strategy where, after boarding first-
class passengers and passengers with special needs, the rest of the passengers are
boarded in groups, starting with rows in the back of the plane. As the authors suspected
(and most of us have experienced), this strategy still results in significant congestion.
Within a given section of the plane (the back, say), passengers storing luggage in over-
head compartments can block an aisle. Also, people in the aisle or middle seat often
need to get back into the aisle to let window-seat passengers be seated.The authors
developed an integer programming (IP) model to minimize the number of such aisle
blockages.The decision variables determined which groups of seats should be boarded
in which order. Of course, the BF strategy was one possible feasible solution, but it
turned out to be a suboptimal solution.The IP model suggested that the best solution
was an outside-in (OI) strategy, where groups of passengers in window seats board first,
then groups in the middle seats, and finally groups in aisle seats, with all of these groups
going essentially in a back-to-front order.
The authors recognized that their IP model was at best an idealized model of how
passengers actually behave. Its biggest drawback is that it ignores the inherent random-
ness in passenger behavior.Therefore, they followed up their optimization model with
a simulation model. As they state, “We used simulation to validate the analytical model
and to obtain a finer level of detail.” This validation of an approximate or idealized
analytical model is a common use for simulation.To make the simulation as realistic as
possible, they used two cameras, one inside the plane and one inside the bridge leading
to the plane, to tape customer behavior. By analyzing the tapes, they were able to
estimate the required inputs to their simulation model, such as the time between
passengers, walking speed, blocking time, and time to store luggage in overhead com-
partments. After the basic simulation model was developed, it was used as a tool to
evaluate various boarding strategies suggested by the IP model. It also allowed the
authors to experiment with changes to the overall boarding process that might be
beneficial. For example, reducing congestion inside the airplane is not very helpful if the
gate agent at the entrance to the bridge processes passengers too slowly.Their final
recommendation, based on a series of simulation experiments, was to add a second
gate agent (there had been only one before) and to board passengers in six groups
using an OI strategy.The simulation model suggested that this could reduce the board-
ing time by about 37%.
The authors’ recommendations were implemented first as a pilot project and then
systemwide.The pilot results were impressive, with a 39% reduction in boarding times.
By September 2003, the new boarding strategies had been implemented in 80% of
America West’s airports, with a decrease in departure delays as much as 60.1%. Besides
this obvious benefit to the airline, customers also appear to be happier. Now they can
easily understand when to queue up for boarding, and they experience less blocking after
they get inside the plane. ■
552
Chapter 10
Introduction to Simulation Modeling
10.1 INTRODUCTION
A simulation model is a computer model that imitates a real-life situation. It is like other
mathematical models, but it explicitly incorporates uncertainty in one or more input vari-
ables. When you run a simulation, you allow these random input variables to take on
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

various values, and you keep track of any resulting output variables of interest. In this way,
you are able to see how the outputs vary as a function of the varying inputs.
The fundamental advantage of a simulation model is that it provides an entire distrib-
ution of results, not simply a single bottom-line result. As an example, suppose an
automobile manufacturer is planning to develop and market a new model car. The com-
pany is ultimately interested in the net present value (NPV) of the profits from this car over
the next 10 years. However, there are many uncertainties surrounding this car, including
the yearly customer demands for it, the cost of developing it, and others. The company
could develop a spreadsheet model for the 10-year NPV, using its best guesses for these
uncertain quantities. It could then report the NPV based on these best guesses. However,
this analysis would be incomplete and probably misleading—there is no guarantee that the
NPV based on best-guess inputs is representative of the NPV that will actually occur. It is
much better to treat the uncertainty explicitly with a simulation model. This involves enter-
ing probability distributions for the uncertain quantities and seeing how the NPV varies as
the uncertain quantities vary.
Each different set of values for the uncertain quantities can be considered a scenario.
Simulation allows the company to generate many scenarios, each leading to a particular NPV.
In the end, it sees a whole distribution of NPVs, not a single best guess. The company can see
what the NPV will be on average, and it can also see worst-case and best-case results.
These approaches are summarized in Figures 10.1 and 10.2. Figure 10.1 indicates that
the deterministic (non-simulation) approach, using best guesses for the uncertain inputs, is
generally not the appropriate method. It leads to the “flaw of averages,” as we will discuss
later in the chapter. The problem is that the outputs from the deterministic model are often
not representative of the true outputs. The appropriate method is shown in Figure 10.2.
Here the uncertainty is modeled explicitly with random inputs, and the end result is a prob-
ability distribution for each of the important outputs.
10.1 Introduction
553
Figure 10.1
Inappropriate
Deterministic Model
Figure 10.2
Appropriate
Simulation Model
Simulation models are also useful for determining how sensitive a system is to
changes in operating conditions. For example, the operations of a supermarket could be
simulated. Once the simulation model has been developed, it could then be run (with suit-
able modifications) to ask a number of what-if questions. For example, if the supermarket
experiences a 20% increase in business, what will happen to the average time customers
must wait for service?
A huge benefit of computer simulation is that it enables managers to answer these
types of what-if questions without actually changing (or building) a physical system. For
example, the supermarket might want to experiment with the number of open registers to
see the effect on customer waiting times. The only way it can physically experiment with
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

more registers than it currently owns is to purchase more equipment. Then if it determines
that this equipment is not a good investment—customer waiting times do not decrease
appreciably—the company is stuck with expensive equipment it doesn’t need. Computer
simulation is a much less expensive alternative. It provides the company with an electronic
replica of what would happen if the new equipment were purchased. Then, if the simula-
tion indicates that the new equipment is worth the cost, the company can be confident that
purchasing it is the right decision. Otherwise, it can abandon the idea of the new equipment
before the equipment has been purchased.
Spreadsheet simulation modeling is quite similar to the other modeling applications in
this book. You begin with input variables and then relate these with appropriate Excel
formulas to produce output variables of interest. The main difference is that simulation
uses random numbers to drive the whole process. These random numbers are generated
with special functions that we will discuss in detail. Each time the spreadsheet recalcu-
lates, all of the random numbers change. This provides the ability to model the logical
process once and then use Excel’s recalculation ability to generate many different scenar-
ios. By collecting the data from these scenarios, you can see the most likely values of the
outputs and the best-case and worst-case values of the outputs.
In this chapter we begin by illustrating spreadsheet models that can be developed with
built-in Excel functionality. However, because simulation is becoming such an important tool
for analyzing real problems, add-ins to Excel have been developed to streamline the process of
developing and analyzing simulation models. Therefore, we then introduce @RISK, one of
the most popular simulation add-ins. This add-in not only augments the simulation capabili-
ties of Excel, but it also enables you to analyze models much more quickly and easily.
The purpose of this chapter is to introduce basic simulation concepts, show how sim-
ulation models can be developed in Excel, and demonstrate the capabilities of the @RISK
add-in. Then in the next chapter, armed with the necessary simulation tools, we will
explore a number of interesting and useful simulation models.
Before proceeding, you might ask whether simulation is really used in the business
world. The answer is a resounding yes. The chapter opener described an airline example,
and many other examples can be found online. For example, if you visit www.palisade.com,
you will see descriptions of interesting @RISK applications from companies that regu-
larly use this add-in. Simulation has always been a powerful tool, but it had limited use
for several reasons. It typically required specialized software that was either expensive or
difficult to learn, or it required a lot of tedious computer programming. Fortunately, in the
past two decades, spreadsheet simulation, together with Excel add-ins such as @RISK,
has put this powerful methodology in the hands of the masses—people like you and the
companies you are likely to work for. Many businesses now understand that there is no
longer any reason to ignore uncertainty; they can model it directly with spreadsheet
simulation.
10.2 PROBABILITY DISTRIBUTIONS FOR INPUT VARIABLES
In this section we discuss the building blocks of spreadsheet simulation models. All
spreadsheet simulation models are similar to the spreadsheet models from previous
chapters. They have a number of cells that contain values of input variables. The other cells
then contain formulas that embed the logic of the model and eventually lead to the output
variable(s) of interest. The primary difference between the spreadsheet models you have
developed so far and simulation models is that at least one of the input variable cells in a
simulation model contains random numbers. Each time the spreadsheet recalculates, the
random numbers change, and the new random values of the inputs produce new values of
554
Chapter 10
Introduction to Simulation Modeling
In spreadsheet
simulation models,
input cells can contain
random numbers.Any
output cells then vary
as these random inputs
change.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

the outputs. This is the essence of simulation—it enables you to see how outputs vary as
random inputs change.
Excel Tip: Recalculation Key
The easiest way to mak e a spr eadsheet recalculate is to pr ess the F9 key. This is often
called the “recalc” key. 
Technically speaking, input cells do not contain random numbers; they contain
probability distributions. In general, a probability distribution indicates the possible values
of a variable and the probabilities of these values. As a very simple example, you might
indicate by an appropriate formula (to be described later) that you want a probability dis-
tribution with possible values 50 and 100, and corresponding probabilities 0.7 and 0.3. If
you force the sheet to recalculate repeatedly and watch this input cell, you will see the
value 50 about 70% of the time and the value 100 about 30% of the time. No other values
besides 50 and 100 will appear.
When you enter a given probability distribution in a random input cell, you are describ-
ing the possible values and the probabilities of these values that you believe mirror reality.
There are many probability distributions to choose from, and you should always attempt to
choose an appropriate distribution for each specific problem. This is not necessarily an easy
task. Therefore, we address it in this section by answering several key questions:
■
What types of probability distributions are available, and why do you choose one
probability distribution rather than another in an actual simulation model?
■
Which probability distributions can you use in simulation models, and how do you
invoke them with Excel formulas?
In later sections we address one additional question: Does the choice of input probability
distribution really matter—that is, are the outputs from the simulation sensitive to this
choice?
10.2 Probability Distributions for Input Variables
555
FUNDAMENTAL INSIGHT
Basic Elements of Spr
eadsheet
Simulation
A spr eadsheet sim ulation model r
equires thr ee
elements: (1) a method for entering random quantities
from specified pr obability distributions in input cells,
(2) the usual types of Excel f
ormulas f or r elating
outputs to inputs,
and (3) the ability to mak
e the
spreadsheet r ecalculate man y times and ca
pture
the resulting outputs f or statistical anal ysis. Excel has
some capabilities for performing these steps, but Excel
add-ins such as @RISK provide much better tools for
automating the process.
10.2.1 Types of Probability Distributions
Imagine a toolbox that contains the probability distributions you know and understand. As
you obtain more experience in simulation modeling, you will naturally add probability distri-
butions to your toolbox that you can then use in future simulation models. We begin by
adding a few useful probability distributions to this toolbox. However, before adding any spe-
cific distributions, it is useful to provide a brief review of some important general character-
istics of probability distributions. These include the following distinctions:
■
Discrete versus continuous
■
Symmetric versus skewed
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

■
Bounded versus unbounded
■
Nonnegative versus unrestricted.
Discrete Versus Continuous
A probability distribution is discrete if it has a finite number of possible values.1 For
example, if you throw two dice and look at the sum of the faces showing, there are only 11
discrete possibilities: the integers 2 through 12. In contrast, a probability distribution
is continuous if its possible values are essentially some continuum. An example is the
amount of rain that falls during a month in Indiana. It could be any decimal value from 0
to, say, 15 inches.
The graph of a discrete distribution is a series of spikes, as shown in Figure 10.3.2 The
height of each spike is the probability of the corresponding value. 
556
Chapter 10
Introduction to Simulation Modeling
FUNDAMENTAL INSIGHT
Choosing Probability Distributions
for Uncertain Inputs
In sim ulation models,
it is impor tant to choose
appropriate probability distributions for all uncertain
inputs.These choices can str ongly affect the results.
Unfortunately, there are no “right answers.” You need
to choose the pr
obability distributions that best
encode your uncertainty, and this is not necessaril y
easy. However, the properties discussed in this sec-
tion pr ovide y ou with useful guidelines f or making
reasonable choices.
1Actually, it is possible for a discrete variable to have a countably infinite number of possible values, such as all
the nonnegative integers 0, 1, 2, and so on. However, this is not an important distinction for practical applications.
2This figure and several later figures have been captured from Palisade’s @RISK add-in.
Figure 10.3
A Typical Discrete
Probability
Distribution
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

In contrast, a continuous distribution is characterized by a density function, a smooth
curve as shown in Figure 10.4. There are two important properties of density functions.
First, the height of the density function above any value indicates the relative likelihood
of that value, and second, probabilities can be calculated as areas under the curve.
10.2 Probability Distributions for Input Variables
557
Figure 10.4
A Typical
Continuous
Probability
Distribution
The heights above a
density function are
not probabilities, but
they still indicate
relative likelihoods of
the possible values.
Sometimes it is convenient to treat a discrete probability distribution as continuous,
and vice versa. For example, consider a student’s random score on an exam that has 1000
possible points. If the grader scores each exam to the nearest integer, then even though the
score is really discrete with many possible integer values, it is probably more convenient to
model its distribution as a continuum. Continuous probability distributions are typically
more intuitive and easier to work with than discrete distributions in cases such as this,
where there are many possible values. In contrast, continuous distributions are sometimes
discretized for simplicity.
Symmetric Versus Skewed
A probability distribution can either be symmetric or skewed to the left or right. Figures 10.4,
10.5, 10.6 provide examples of each of these. You typically choose between a symmetric and
skewed distribution on the basis of realism. For example, if you want to model a student’s
score on a 100-point exam, you will probably choose a left-skewed distribution. This is
because a few poorly prepared students typically “pull down the curve.” On the other hand,
if you want to model the time it takes to serve a customer at a bank, you will probably choose
a right-skewed distribution. This is because most customers take only a minute or two, but
a few customers take a long time. Finally, if you want to model the monthly return on a
stock, you might choose a distribution symmetric around zero, reasoning that the stock return
is just as likely to be positive as negative and there is no obvious reason for skewness in either
direction.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Bounded Versus Unbounded
A probability distribution is bounded if there are values A and B such that no possible value
can be less than A or greater than B. The value A is then the minimum possible value, and
the value B is the maximum possible value. The distribution is unbounded if there are no
such bounds. Actually, it is possible for a distribution to be bounded in one direction but
not the other. As an example, the distribution of scores on a 100-point exam is bounded
between 0 and 100. In contrast, the distribution of the amount of damages Mr. Jones
558
Chapter 10
Introduction to Simulation Modeling
Figure 10.5
A Positively Skewed
Probability
Distribution
Figure 10.6
A Negatively Skewed
Probability
Distribution
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

submits to his insurance company in a year is bounded on the left by 0, but there is no
natural upper bound. Therefore, you might model this amount with a distribution that is
bounded by 0 on the left but is unbounded on the right. Alternatively, if you believe that no
damage amount larger than $20,000 can occur, you could model this amount with a
distribution that is bounded in both directions.
Nonnegative Versus Unrestricted
One important special case of bounded distributions is when the only possible values are
nonnegative. For example, if you want to model the random cost of manufacturing a new
product, you know for sure that this cost must be nonnegative. There are many other
such examples. In such cases, you should model the randomness with a probability
distribution that is bounded below by 0. This rules out negative values that make no
practical sense. 
10.2.2 Common Probability Distributions
Now that you know the types of probability distributions available, you can add some
common probability distributions to your toolbox. The file Probability Distributions.xlsx
was developed to help you learn and explore these. Each sheet in this file illustrates a
particular probability distribution. It describes the general characteristics of the distribu-
tion, indicates how you can generate random numbers from the distribution either with
Excel’s built-in functions or with @RISK functions, and it includes histograms of these
distributions from simulated data to illustrate their shapes.3
It is important to realize that each of the following distributions is really a family of
distributions. Each member of the family is specified by one or more parameters. For
example, there is not a single normal distribution; there is a normal distribution for each
possible mean and standard deviation you specify. Therefore, when you try to find an
appropriate input probability distribution in a simulation model, you first have to choose an
appropriate family, and then you have to select the appropriate parameters for that family.
Uniform Distribution
The uniform distribution is the “flat” distribution illustrated in Figure 10.7. It is bounded
by a minimum and a maximum, and all values between these two extremes are equally
likely. You can think of this as the “I have no idea” distribution. For example, a manager
might realize that a building cost is uncertain. If she can state only that, “I know the cost
will be between $20,000 and $30,000, but other than this, I have no idea what the cost
will be,” then a uniform distribution from $20,000 to $30,000 is a natural choice. However,
even though some people do use the uniform distribution in such cases, these situations are
arguably not very common or realistic. If the manager really thinks about it, she can prob-
ably provide more information about the uncertain cost, such as, “The cost is more likely
to be close to $25,000 than to either of the extremes.” Then some distribution other than
the uniform is more appropriate.
Regardless of whether the uniform distribution is an appropriate candidate as an input
distribution, it is important for another reason. All simulation software packages, including
Excel, are capable of generating random numbers uniformly distributed between 0 and 1.
These are the building blocks of most simulated random numbers, in that random numbers
from other probability distributions are generated from them.
10.2 Probability Distributions for Input Variables
559
Think of the
Probability
Distributions.xlsx
file as a “dictionary”
of the most commonly
used distributions.
Keep it handy for
reference.
3In later sections of this chapter, and all through the next chapter, we discuss much of @RISK’s functionality. For
this section, the only functionality we use is @RISK’s collection of functions, such as RISKNORMAL and
RISKTRIANG, for generating random numbers from various probability distributions. You can skim the details
of these functions for now and refer back to them as necessary in later sections.
A family of distribu-
tions has a common
name, such as “nor-
mal.” Each member of
the family is specified
by one or more numer-
ical parameters.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

In Excel, you can generate a random number between 0 and 1 by entering the formula
RAND()
in any cell. (The parentheses to the right of RAND indicate that this is an Excel function
with no arguments. These parentheses must be included.)
Excel Function: RAND
To generate a r andom number equally lik ely to be anywher e between 0 and 1, enter the
formula RAND() into any cell. Press the F9 key, or recalculate in any other way, to make
it change randomly.
In addition to being between 0 and 1, the numbers created by this function have two
properties that you would expect “random” numbers to have.
1. Uniform property. Each time you enter the RAND function in a cell, all numbers
between 0 and 1 have the same chance of occurring. This means that approximately
10% of the numbers generated by the RAND function will be between 0.0 and 0.1;
10% of the numbers will be between 0.65 and 0.75; 60% of the numbers will be
between 0.20 and 0.80; and so on. This property explains why the random numbers
are said to be uniformly distributed between 0 and 1.
2. Independence property. Different random numbers generated by =RAND() formu-
las are probabilistically independent. This implies that when you generate a random
number in cell A5, say, it has no effect on the values of any other random numbers
generated in the spreadsheet. For example, if one call to the RAND function yields a
large random number such as 0.98, there is no reason to suspect that the next call to
RAND will yield an abnormally small (or large) random number; it is unaffected by
the value of the first random number.
Excel T ip: Besides the RAND function, ther
e is one other function b
uilt into Excel
that generates random numbers, the RANDBETWEEN function. It tak es two integer argu-
ments, as in =RANDBETWEEN(1,6), and returns a random integer between these values
560
Chapter 10
Introduction to Simulation Modeling
Figure 10.7
The Uniform
Distribution
The RAND function is
Excel’s “building block”
function for generating
random numbers.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

(including the endpoints) so that all suc
h integers are equally lik ely. The function was
introduced in Excel 2007. (It was actually available in previous versions of Excel, but only
if the Analysis Toolpak add-in was loaded.)
To illustrate the RAND function, open a new workbook, enter the formula =RAND() in cell
A4, and copy it to the range A4:A503. This generates 500 random numbers. Figure 10.8
displays a possible set of values. However, when you try this on your PC, you will undoubt-
edly obtain different random numbers. This is an inherent characteristic of simulation—no
two answers are ever exactly alike. Now press the recalc (F9) key. All of the random
numbers will change. In fact, each time you press the F9 key or do anything to make your
spreadsheet recalculate, all of the cells containing the RAND function will change.
10.2 Probability Distributions for Input Variables
561
1
2
3
4
5
6
7
8
9
10
501
502
503
A
B
C
D
500 random numbers from RAND funcon
Random #
0.639741246
0.977449085
0.826336662
0.794236038
0.326052217
0.540446013
0.012582316
0.868540879
0.297930515
0.960969187
Figure 10.8
Uniformly
Distributed Random
Numbers Generated
by the RAND
Function
60
70
Histogram of Random #
50
30
40
Frequency
10
20
0
0.00
0.20
0.40
0.60
0.80
1.00
Figure 10.9
Histogram of the
500 Random
Numbers Generated
by the RAND
Function
A histogram of the 500 random numbers appears in Figure 10.9. (Again, if you try
this on your PC, the shape of your histogram will not be identical to the one shown in
Figure 10.9, because it will be based on different random numbers.) From property 1, you
would expect equal numbers of observations in the 10 categories. Obviously, the heights of
the bars are not exactly equal, but the differences are due to chance—not to a faulty
random number generator.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Technical Note: Pseudo-random Numbers
The “random” numbers generated by the RAND function (or by the random number gener-
ator in any simulation software package) are not really random. They are sometimes called
pseudo-random numbers. Each successive r andom number follows the pr evious random
number by a comple x arithmetic oper ation. If you happen to know the details of this
arithmetic operation, you can predict ahead of time exactly which random numbers will be
generated by the RAND function. This is quite different from using a “true” random mech-
anism, such as spinning a wheel, to get the next random number—a mechanism that would
be impractical to implement on a computer. Mathematicians and computer scientists have
studied many ways to pr
oduce r andom number s that have the two pr
operties we just
discussed, and the y have de veloped many competing r andom number g enerators such as
the RAND function in Excel. The tec hnical details need not concern you. The important
point is that these random number generators produce numbers that appear to be random
and are useful for simulation modeling.
It is simple to generate a uniformly distributed random number with a minimum and
maximum other than 0 and 1. For example, the formula
200100*RAND()
generates a number uniformly distributed between 200 and 300. (Make sure you see why.)
Alternatively, you can use the @RISK formula4
RISKUNIFORM(200,300)
You can take a look at this and other properties of the uniform distribution on the Uniform
sheet in the Probability Distributions.xlsx file. (See Figure 10.10.)
562
Chapter 10
Introduction to Simulation Modeling
4As we have done with other Excel functions, we capitalize the @RISK functions, such as RISKUNIFORM, in
the text. However, this is not necessary when you enter the formulas in Excel.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
A
B
C
D
E
F
G
H
Uniform distribuon
Characteriscs
Connuous
Symmetric
Bounded in both direcons
Not necessarily posive (depends on bounds)
Parameters
0
5
la
V
ni
M
0
0
1
la
V
x
a
M
elp
m
a
x
E
le
c
x
E
=MinVal + (MaxVal-MinVal)*RAND()
96.105704
@RISK
=RISKUNIFORM(MinVal,MaxVal)
96.880610
This is a ﬂat distribuon between two values, 
labeled here MinVal and MaxVal. Note that if 
MinVal=0 and MaxVal=1, then you can just use 
Excel's RAND funcon.
Figure 10.10 Properties of Uniform Distribution
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

FREEZING RANDOM NUMBERS
The automatic recalculation of random numbers can be useful sometimes and annoying at
other times. There are situations when you want the random numbers to stay fixed—that is,
you want to freeze them at their current values. The following three-step method does this.
1. Select the range that you want to freeze, such as A4:A503 in Figure 10.8.
2. Press Ctrl+c to copy this range.
3. With the same range still selected, select the Paste Values option from the Paste
dropdown menu on the Home ribbon. This procedure pastes a copy of the range
onto itself, except that the entries are now numbers, not formulas. Therefore, when-
ever the spreadsheet recalculates, these numbers do not change.
Each sheet in the Probability Distributions.xlsx file has a list of 500 random numbers that
have been frozen. The histograms in the sheets are based on the frozen random numbers.
However, we encourage you to enter “live” random numbers in column B over the frozen
ones and see how the histogram changes when you press F9.
10.2.3 Using @RISK to Explore Probability Distributions5
The Probability Distributions.xlsx file illustrates a few frequently used probability distribu-
tions, and it shows the formulas required to generate random numbers from these distribu-
tions. Another option is to use Palisade’s @RISK add-in, which allows you to experiment with
probability distributions. Essentially, it allows you to see the shapes of various distributions
and to calculate probabilities for them, all in a user-friendly graphical interface.
To run @RISK, click on the Windows Start button, go to the Programs tab, locate the
Palisades DecisionTools suite, and select @RISK. After a few seconds, you will see the
welcome screen, which you can close. At this point, you should have an @RISK tab and
corresponding ribbon. Select a blank cell in your worksheet, and then click on Define
Distributions on left of the @RISK ribbon (see Figure 10.11). You will see one of several
galleries of distributions, depending on the tab you select. For example, Figure 10.12
10.2 Probability Distributions for Input Variables
563
Figure 10.11 @RISK Ribbon
@RISK Function: RISKUNIFORM
To g enerate a r andom number fr om any uniform distrib
ution, enter the formula
=RISKUNIFORM(MinVal,MaxVal) in any cell. Her e, MinVal and MaxVal are the
minimum and maximum possible values. Note that if MinVal is 0 and MaxVal is 1, this
function is equivalent to Excel’s RAND function.
Random numbers that
have been frozen do
not change when you
press the F9 key.
5Palisade previously offered a stand-alone program called RISKview for exploring probability distributions, and
we discussed it in the previous edition. However, Palisade discontinued RISKview and instead incorporates its
functionality in @RISK.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

shows the gallery of continuous distributions. Highlight one of the distributions and click
on Select Distribution. For example, choose the uniform distribution with minimum 75 and
maximum 150. You will see the shape of the distribution and a few summary measures to
the right, as shown in Figure 10.13. For example, it indicates that the mean and standard
deviation of this uniform distribution are 112.5 and 21.65.
Everything in this window is interactive. Suppose you want to find the probability that a
value from this distribution is less than 95. You can drag the left-hand “slider” in the diagram
(the vertical line with the triangle at the top) to the position 95, as shown in Figure 10.13.
564
Chapter 10
Introduction to Simulation Modeling
Figure 10.12
Gallery of
Continuous
Distributions
Figure 10.13
@RISK Illustration
of Uniform
Distribution
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

You see immediately that the left-hand probability is 0.267. Similarly, if you want the proba-
bility that a value from this distribution is greater than 125, you can drag the right-hand slider
to the position 125 to see that the required probability is 0.3333. (Rather than sliding, you can
enter the numbers, such as 95 and 125, directly into the areas above the sliders.)
You can also enter probabilities instead of values. For example, if you want the value
such that there is probability 0.10 to the left of it—the 10th percentile—enter 10% in the
left space above the chart. You will see that the corresponding value is 82.5. Similarly, if
you want the value such that there is probability 0.10 to the right of it, enter 10% in the
right space above the chart, and you will see that the corresponding value is 142.5.
The Define Distributions window in @RISK is quick and easy. We urge you to use it
and experiment with some of its options. By the way, you can click on the third button
from the left at the bottom of the window to copy the chart into an Excel worksheet.
However, you then lose the interactive capabilities, such as moving the sliders.
Discrete Distribution
A discrete distribution is useful for many situations, either when the uncertain quantity is
not really continuous (the number of televisions demanded, for example) or when you
want a discrete approximation to a continuous variable. All you need to specify are the
possible values and their probabilities, making sure that the probabilities sum to 1.
Because of this flexibility in specifying values and probabilities, discrete distributions can
have practically any shape.
As an example, suppose a manager estimates that the demand for a particular brand of
television during the coming month will be 10, 15, 20, or 25, with respective probabilities
0.1, 0.3, 0.4, and 0.2. This typical discrete distribution is illustrated in Figure 10.14.
10.2 Probability Distributions for Input Variables
565
Figure 10.14
Discrete
Distribution (from
@RISK)
The interactive
capabilities of @RISK’s
Define Distributions
window, with its sliders,
make it perfect for
finding probabilities or
percentiles for any
given distribution.
The Discrete sheet of the Probability Distributions.xlsx file indicates how to work
with a discrete distribution. (See Figure 10.15.) As you can see, there are two quite differ-
ent ways to generate a random number from this distribution. We discuss the Excel way in
detail in section 10.4. For now, we simply mention that this is one case (of many) where it
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

is much easier to generate random numbers with @RISK functions than with built-in
Excel functions. Assuming that @RISK is loaded, all you need to do is enter the function
RISKDISCRETE with two arguments, a list of possible values and a list of their probabil-
ities, as in
RISKDISCRETE(B11:B14,C11:C14)
The Excel way, which requires cumulative probabilities and a lookup table, takes more
work and is harder to remember.
566
Chapter 10
Introduction to Simulation Modeling
@RISK’s way of
generating a discrete
random number is
much simpler and
more intuitive than
Excel’s method, which
requires cumulative
probabilities and a
lookup function.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
A
B
C
D
E
F
G
H
I
General discrete distribuon
Characteriscs
Discrete
Can be symmetric or skewed (or bumpy, i.e., basically any shape)
Bounded in both direcons
Not necessarily posive (depends on possible values)
Parameters
Lookup table required for Excel method
Values
Probabilies
CumProb
Value
0
1
0
1.0
0
1
15
0.3
0.1
15
20
0.4
0.4
20
25
0.2
0.8
25
elp
m
a
x
E
le
c
x
E
=VLOOKUP(RAND(),LookupTable,2)
10
@RISK
0
2
)s
b
o
r
P,s
e
ula
V
(
E
T
E
R
C
SI
D
K
SI
R
=
This can have any shape, depending 
on the list of possible values and their 
probabilies.
Figure 10.15 Properties of a Discrete Distribution
@RISK Function: RISKDISCRETE
To g enerate a r andom number fr om any discr ete pr obability distrib ution, enter the
formula =RISKDISCRETE(valRange,probRange) into any cell. Here valRange is the
range where the possible values ar e stored, and probRange is the r ange where their
probabilities are stored.
At this point, a relevant question is why a manager would choose this particular
discrete distribution. First, it is clearly an approximation. After all, if it is possible to have
demands of 20 and 25, it should also be possible to have demands between these values.
Here, the manager approximates a discrete distribution with many possible values—all
integers from 0 to 50, say—with a discrete distribution with a few well-chosen values. This
is common in simulation modeling. Second, where do the probabilities come from? They
are probably a blend of historical data (perhaps demand was near 15 in 30% of previous
months) and the manager’s subjective feelings about demand next month.
Normal Distribution
The normal distribution is the familiar bell-shaped curve that is the hallmark of much of
statistical theory. (See Figure 10.16.) It is useful in simulation modeling as a continuous
The selected input
distributions for any
simulation model
reflect historical data
and an analyst’s best
judgment as to what
will happen in the
future.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

input distribution. However, it is not always the most appropriate distribution. It is sym-
metric, which can be a drawback when a skewed distribution is more realistic. Also, it
allows negative values, which are not appropriate in many situations. For example, the
demand for televisions cannot be negative. Fortunately, this possibility of negative values
is often not a problem. Suppose you generate a normally distributed random number with
mean 100 and standard deviation 20. Then, as you might remember from statistics, there is
almost no chance of having values more than three standard deviations to the left of the
mean, and this rules out negative values for all practical purposes.
A tip-off that a normal distribution might be an appropriate candidate for an input
variable is a statement such as, “We believe the most likely value of demand is 100, and the
chances are about 95% that demand will be no more than 40 units on either of side of this
most likely value.” Because a normally distributed value is within two standard deviations
of its mean with probability 0.95, this statement translates easily to a mean of 100 and a
standard deviation of 20. This does not imply that a normal distribution is the only candi-
date for the distribution of demand, but the statement naturally leads to this distribution.
The Normal sheet in the Probability Distributions.xlsx file indicates how you can
generate normally distributed random numbers in Excel, either with or without @RISK.
(See Figure 10.17.) This is one case where an add-in is not really necessary. The formula
NORMINV(RAND(),Mean,Stdev)
always works. Still, this is not as easy to remember as @RISK’s formula
RISKNORMAL(Mean,Stdev)
10.2 Probability Distributions for Input Variables
567
Normally distributed
random numbers will
almost certainly be
within three standard
deviations of the mean.
Figure 10.16
Normal Distribution
(from @RISK)
@RISK Function: RISKNORMAL
To g enerate a normally distrib uted r andom number, enter the formula =RISKNOR-
MAL(Mean,Stdev) in any cell. Her e, Mean and Stdev are the mean and standar d
deviation of the normal distribution.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Triangular Distribution
The triangular distribution is somewhat similar to the normal distribution in that its den-
sity function rises to some point and then falls, but it is more flexible and intuitive than the
normal distribution. Therefore, it is an excellent candidate for many continuous input
variables. The shape of a triangular density function is literally a triangle, as shown in
Figure 10.18. It is specified by three easy-to-understand parameters: the minimum possible
value, the most likely value, and the maximum possible value. The high point of the triangle
568
Chapter 10
Introduction to Simulation Modeling
Figure 10.18
Triangular
Distribution (from
@RISK)
A triangular distribu-
tion is a good choice in
many simulation mod-
els because it can have
a variety of shapes and
its parameters are
easy to understand.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
A
B
C
D
E
F
G
H
Normal distribuon
Characteriscs
Connuous
Symmetric (bell-shaped)
Unbounded in both direcons
Is both posive and negave
Parameters
0
0
1
n
a
e
M
0
1
v
e
d
tS
elp
m
a
x
E
le
c
x
E
=NORMINV(RAND(),Mean,Stdev)
96.41946055
@RISK
=RISKNORMAL(Mean,Stdev)
90.3093316
This is the familiar bell-shaped curve, deﬁned by 
two parameters: the mean and the standard 
deviaon.
Figure 10.17 Properties of the Normal Distribution
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

is above the most likely value. Therefore, if a manager states, “We believe the most likely
development cost is $1.5 million, and we don’t believe the development cost could possibly
be less than $1.2 million or greater than $2.1 million,” the triangular distribution with these
three parameters is a natural choice. As in this numerical example, note that the triangular
distribution can be skewed if the mostly likely value is closer to one extreme than another.
Of course, it can also be symmetric if the most likely value is right in the middle.
The Triangular sheet of the Probability Distributions.xlsx file indicates how to gen-
erate random values from this distribution. (See Figure 10.19.) As you can see, there is no
way to do it with native Excel (at least not without a macro). However, it is easy with
@RISK, using the RISKTRIANG function, as in
RISKTRIANG(B10,B11,B12)
This function takes three arguments: the minimum value, the most likely value, and the
maximum value—in this order and separated by commas. You will see this function in
many of our examples. Just remember that it has an abbreviated spelling: RISKTRIANG,
not RISKTRIANGULAR.
10.2 Probability Distributions for Input Variables
569
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
A
B
C
D
E
F
G
H
I
J
Triangular distribuon
Characteriscs
Connuous
Can be symmetric or skewed in either direcon
Bounded in both direcons
Not necessarily posive (depends on bounds)
Parameters
0
5
ni
M
5
8
yle
kiLts
o
M
0
0
1
x
a
M
Excel
There is no easy way to do it except by wring a macro.
elp
m
a
x
E
K
SI
R
@
=RISKTRIANG(Min,MostLikely,Max)
62.61066937
The density of this distribuon is literally a triangle. The "top" of the 
triangle is above the most likely value, and the base of the triangle 
extends from the minimum value to the maximum value. It is 
intuive for nontechnical people because the three parameters are 
meaningful.
Figure 10.19 Properties of the Triangular Distribution
@RISK Function: RISKTRIANG
To generate a random number from a triangular distribution, enter the formula =RISK-
TRIANG (MinVal,MLVal,MaxVal) in any cell. Here, MinVal is the minimum possible
value, MLVal is the most likely value, and MaxVal is the maximum value.
Binomial Distribution
The binomial distribution is a discrete distribution that applies to a very specific situation:
when a number of independent and identical trials occur, and each trial results in a success
or failure. Then the binomial random number is the number of successes in these trials.
The two parameters of this distribution, n and p, are the number of trials and the probabil-
ity of success on each trial.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

As an example, suppose an airline company sells 170 tickets for a flight and estimates
that 80% of the people with tickets will actually show up for the flight. How many people
will actually show up? It is tempting to state that exactly 80% of 170, or 136 people, will
show up, but this neglects the inherent randomness. A more realistic way to model this
situation is to say that each of the 170 people, independently of one another, will show up
with probability 0.8. Then the number of people who actually show up is binomially
distributed with n  170 and p  0.8. (This assumes independent behavior across passen-
gers, which might not be the case, for example, if whole families either show up or don’t.)
This distribution is illustrated in Figure 10.20.
570
Chapter 10
Introduction to Simulation Modeling
A random number
from a binomial
distribution indicates
the number of
successes in a certain
number of identical
trials.
Figure 10.20
Binomial
Distribution (from
@RISK)
The Binomial sheet of the Probability Distributions.xlsx file indicates how to gener-
ate random numbers from this distribution. (See Figure 10.21.) Although it is possible to
do this with Excel using the built-in CRITBINOM function and the RAND function, it is
not very intuitive or easy to remember. Clearly, the @RISK way is preferable. In the airline
example, you would generate the number who show up with the formula
RISKBINOMIAL(170,0.8)
Note that the histogram in this figure is approximately bell-shaped. This is no accident.
When the number of trials n is reasonably large and p isn’t too close to 0 or 1, the binomial
distribution can be well approximated by the normal distribution.
@RISK Function: RISKBINOMIAL
To g enerate a r andom number fr om a binomial distrib
ution, enter the formula
=RISKBINOMIAL(NTrials,PSuccess) in any cell. Here, NTrials is the number of tri-
als, and PSuccess is the probability of a success on each trial.
A common question asked by students is which distribution to use for a given uncer-
tain quantity such as the price of oil, the demand for laptops, and so on. Admittedly, the
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

choices we make in later examples are sometimes for convenience. However, in real busi-
ness situations the choice is not always clear-cut, and it can make a difference in the
results. Stanford professor Sam Savage and two of his colleages discuss this choice in a
series of two articles on “Probability Management.” (These articles from February and
April 2006 are available online at http://lionhrtpub.com/orms/ORMS-archive.html.) They
argue that with the increasing importance of simulation models in today’s business world,
input distributions should not only be chosen carefully, but they should be kept and main-
tained as important corporate assets. They shouldn’t just be chosen in some ad hoc fashion
every time they are needed. For example, if the price of oil is an important input in many of
a company’s decisions, then experts within the company should assess an appropriate dis-
tribution for the price of oil and modify it as necessary when new information arises. The
authors even suggest a new company position, Chief Probability Officer, to control access
to the company’s probability distributions.
So as you are reading these two simulation chapters, keep Savage’s ideas in mind. The
choice of probability distributions for inputs is not easy, yet neither is it arbitrary.
The choice can make a difference in the results. This is the reason why you want as many
families of probability distributions in your toolbox as possible. You then have more
flexibility to choose a distribution that is appropriate for your situation. 
10.2 Probability Distributions for Input Variables
571
1
2
3
4
5
6
7
A
B
C
D
E
F
G
H
Binomial distribuon
Characteriscs
Discrete
Can be symmetric or skewed
Bounded below by 0, bounded above by Ntrials
Nonnegave
This distribuon is of the number of "successes" in a 
given number of idencal, independent trials, when the 
probability of success is constant on each trial.
7
8
9
10
11
12
13
14
15
Nonnegave
Parameters
0
7
1
slair
T
N
8.0
ss
e
c
c
u
S
P
elp
m
a
x
E
le
c
x
E
=CRITBINOM(NTrials,PSuccess,RAND()) 
139
15
16
17
@RISK
3
3
1
)ss
e
c
c
u
S
P,slair
T
N
(L
A
I
M
O
N
IB
K
SIR
=
This distribuon is of the number of "successes" in a 
given number of idencal, independent trials, when the 
probability of success is constant on each trial.
Figure 10.21 Properties of the Binomial Distribution
P R O B L E M S
Solutions for problems whose numbers appear within a
colored box can be found in the Student Solutions Files.
Refer to this book’s preface for purchase information.
Skill-Building Problems
1.
Use the RAND function and the Copy command to
generate a set of 100 random numbers.
a. What fraction of the random numbers are smaller
than 0.5?
b. What fraction of the time is a random number
less than 0.5 followed by a random number greater
than 0.5?
c. What fraction of the random numbers are larger
than 0.8?
d. Freeze these random numbers. However, instead of
pasting them over the original random numbers,
paste them onto a new range. Then press the F9
recalculate key. The original random numbers
should change, but the pasted copy should remain
the same.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

2.
Use Excel’s functions (not @RISK) to generate 1000
random numbers from a normal distribution with
mean 100 and standard deviation 10. Then freeze these
random numbers.
a. Calculate the mean and standard deviation of these
random numbers. Are they approximately what
you would expect?
b. What fraction of these random numbers are within
k standard deviations of the mean? Answer for 
k  1; for k  2; for k  3. Are the answers close
to what they should be (about 68% for k  1, about
95% for k  2, and over 99% for k  3)?
c. Create a histogram of the random numbers using
10 to 15 categories of your choice. Does this
histogram have approximately the shape you
would expect?
3.
Use @RISK to draw a uniform distribution from 400
to 750. Then answer the following questions.
a. What are the mean and standard deviation of this
distribution?
b. What are the 5th and 95th percentiles of this
distribution?
c. What is the probability that a random number from
this distribution is less than 450?
d. What is the probability that a random number from
this distribution is greater than 650?
e. What is the probability that a random number from
this distribution is between 500 and 700?
4.
Use @RISK to draw a normal distribution with mean
500 and standard deviation 100. Then answer the
following questions.
a. What is the probability that a random number from
this distribution is less than 450?
b. What is the probability that a random number from
this distribution is greater than 650?
c. What is the probability that a random number from
this distribution is between 500 and 700?
5.
Use @RISK to draw a triangular distribution with
parameters 300, 500, and 900. Then answer the
following questions.
a. What are the mean and standard deviation of this
distribution?
b. What are the 5th and 95th percentiles of this
distribution?
c. What is the probability that a random number from
this distribution is less than 450?
d. What is the probability that a random number from
this distribution is greater than 650?
e. What is the probability that a random number from
this distribution is between 500 and 700?
6.
Use @RISK to draw a binomial distribution that
results from 50 trials with probability of success 0.3
on each trial, and use it to answer the following
questions.
a. What are the mean and standard deviation of this
distribution?
b. You have to be more careful in interpreting @RISK
probabilities with a discrete distribution such as
this binomial. For example, if you move the left
slider to 11, you find a probability of 0.139 to the
left of it. But is this the probability of “less than
11” or “less than or equal to 11”? One way to
check is to use Excel’s BINOMDIST function. Use
this function to interpret the 0.139 value from
@RISK.
c. Using part b to guide you, use @RISK to find
the probability that a random number from this
distribution will be greater than 17. Check your
answer by using the BINOMDIST function
appropriately in Excel.
7.
Use @RISK to draw a triangular distribution with
parameters 200, 300, and 600. Then superimpose a
normal distribution on this drawing, choosing the
mean and standard deviation to match those from the
triangular distribution. (Click on the Add Overlay
button and then choose the distribution to
superimpose.)
a. What are the 5th and 95th percentiles for these two
distributions?
b. What is the probability that a random number from
the triangular distribution is less than 400? What is
this probability for the normal distribution?
c. Experiment with the sliders to answer questions
similar to those in part b. Would you conclude that
these two distributions differ most in the extremes
(right or left) or in the middle? Explain.
8.
We all hate to keep track of small change. By using
random numbers, it is possible to eliminate the
need for change and give the store and the customer
a fair deal. This problem indicates how it could
be done.
a. Suppose that you buy something for $0.20. How
could you use random numbers (built into the cash
register system) to decide whether you should pay
$1.00 or nothing? 
b. If you bought something for $9.60, how would
you use random numbers to eliminate the need for
change?
c. In the long run, why is this method fair to both the
store and the customers? Would you personally (as
a customer) be willing to abide by such a system?
Skill-Extending Problems
9.
A company is about to develop and then market a
new product. It wants to build a simulation model for
the entire process, and one key uncertain input is the
development cost. For each of the following scenarios,
choose an appropriate distribution together with its
572
Chapter 10
Introduction to Simulation Modeling
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

parameters, justify your choice in words, and use
@RISK to draw your chosen distribution.
a. Company experts have no idea what the
distribution of the development cost is. All they
can state is “we are 95% sure it will be at least
$450,000, and we are 95% sure it will be no more
than $650,000.”
b. Company experts can still make the same statement
as in part a, but now they can also state: “We
believe the distribution is symmetric, reasonably
bell-shaped, and its most likely value is about
$550,000.”
c. Company experts can still make the same statement
as in part a, but now they can also state: “We
believe the distribution is skewed to the right, and
its most likely value is about $500,000.”
10. Continuing the preceding problem, suppose that
another key uncertain input is the development time,
which is measured in an integer number of months.
For each of the following scenarios, choose an
appropriate distribution together with its parameters,
justify your choice in words, and use @RISK to draw
your chosen distribution.
a. Company experts believe the development time
will be from 6 to 10 months, but they have
absolutely no idea which of these will result.
b. Company experts believe the development time
will be from 6 to 10 months. They believe the
probabilities of these five possible values will
increase linearly to a most likely value at 8 months
and will then decrease linearly.
c. Company experts believe the development time
will be from 6 to 10 months. They believe that
8 months is twice as likely as either 7 months or
9 months and that either of these latter possibilities
is three times as likely as either 6 months or
10 months.
10.3 Simulation and the Flaw of Averages
573
10.3 SIMULATION AND THE FLAW OF AVERAGES
To help motivate simulation modeling in general, we present a simple example in this sec-
tion. It will clearly show the distinction between Figure 10.1 (a deterministic model with
best-guess inputs) and Figure 10.2 (an appropriate simulation model). In doing so, it will
illustrate a pitfall called the “flaw of averages” that you should always try to avoid.6
6As far as we know, the term “flaw of averages” was coined by Sam Savage, the same Stanford professor quoted
earlier.
E X A M P L E
10.1 ORDERING CALENDARS AT WALTON BOOKSTORE
I
n August, Walton Bookstore must decide how many of next year’s nature calendars to
order. Each calendar costs the bookstore $7.50 and sells for $10. After January 1, all
unsold calendars will be returned to the publisher for a refund of $2.50 per calendar.
Walton believes that the number of calendars it can sell by January 1 follows some proba-
bility distribution with mean 200. Walton believes that ordering to the average demand,
that is, ordering 200 calendars, is a good decision. Is it?
Objective
To illustrate the difference between a deterministic model with a best guess
for uncertain inputs and a simulation model that incorporates uncertainty explicitly.
WHERE DO THE NUMBERS COME FROM?
The monetary values are straightforward. The mean demand is probably an estimate based
on historical demands for similar calendars. 
Solution
A deterministic model appears in Figure 10.22. (See the file Walton Bookstore 1.xlsx.
Assuming the best guess for demand, Walton orders to this average value, and it appears
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

that the company’s best guess for profit is $500. (The formulas in cells B16:F16
are straightforward. Anticipating that the order quantity and demand will not always
be equal, they are B9, B5*MIN(B9,B12), B4*B12, B6*MAX(B12-B9,0), and
C16-D16E16.) Before reading further, do you believe that the average profit will be
$500 when uncertainty in demand is introduced explicitly (and the company still orders
200 calendars)? Think what happens to profit when demand is less than 200 and when it is
greater than 200. Are these two cases symmetric?
We now contrast this with a simulation model where the demand in cell B9 is replaced
by a random number. For this example, we assume that demand is normally distributed
with mean 200 and standard deviation 40, although these specific assumptions are not cru-
cial for the qualitative aspects of the example. All you need to do is enter the formula
ROUND(RISKNORMAL(200,40),0) in cell B9, where the ROUND function has been
used to round to the nearest integer. Now the model appears as in Figure 10.23.
The random demand in cell B9 is now live, as are its dependents in row 16, so each
time you press the F9 key, you get a new demand and associated profit. Do you get about
574
Chapter 10
Introduction to Simulation Modeling
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
A
B
C
D
E
F
Walton's bookstore - determinisc model
Cost data
Unit 
0
5.7
$
ts
o
c
Unit price
$10.00
Unit refund
$2.50
Uncertain quanty
Demand (average shown)
200
Decision variable
Order quanty
200
Proﬁt model
Demand
Revenue
Cost
Refund
Proﬁt
200
$2,000.00
$1,500.00
$0.00
$500.00
Figure 10.22
Deterministic Model
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
A
B
C
D
E
F
Walton's bookstore - simulaon model
Cost data
Unit 
0
5.7
$
ts
o
c
Unit price
$10.00
Unit refund
$2.50
Uncertain quanty (assumed normal with mean 200, stdev 40)
Demand (random)
263
Decision variable
Order quanty
200
Proﬁt model
Demand
Revenue
Cost
Refund
Proﬁt
263
$2,000.00
$1,500.00
$0.00
$500.00
Figure 10.23
Simulation Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

$500 in profit on average? Absolutely not! The situation isn’t symmetric. The largest profit
you can get is $500, which occurs about half the time, whenever demand is greater than
200. A typical such situation appears in the figure, where the excess demand of 63 is
simply lost. However, when demand is less than 200, the profit is less than $500, and it
keeps decreasing as demand decreases.
We ran @RISK with 1000 iterations (which will be explained in detail in section 10.5)
and found the resulting histogram of 1000 simulated profits shown in Figure 10.24. The
large spike on the right is due to the cases where demand is 200 or more and profit is $500.
All the little spikes to the left are where demand is less than 200 and profit is less than
$500, sometimes considerably less. You can see on the right that the mean profit, the
average of the 1000 simulated profits, is only about $380, well less than the $500
suggested by the deterministic model.
10.3 Simulation and the Flaw of Averages
575
Figure 10.24
Histogram of
Simulated Profits
The point of this simple example is that a deterministic model can be very misleading.
In particular, the output from a deterministic model that uses best guesses for uncertain
inputs is not necessarily equal to, or even close to, the average of the output from a simula-
tion. This is exactly what “the flaw of averages” means.
■
FUNDAMENTAL INSIGHT
The Flaw of Averages
If a model contains uncertain inputs,it can be very mis-
leading to build a deterministic model b
y using the
means of the inputs to predict an output. The resulting
output value can be considerabl y different—lower or
higher—than the mean of the output values obtained
from running a sim ulation with uncer tainty incorpo-
rated explicitly.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

10.4 SIMULATION WITH BUILT-IN EXCEL TOOLS
In this section, we show how spreadsheet simulation models can be developed and ana-
lyzed with Excel’s built-in tools without using add-ins. As you will see, this is certainly
possible, but it presents two problems. First, the @RISK functions illustrated in the
Probability Distributions.xlsx file are not available. You are able to use only Excel’s
RAND function and transformations of it to generate random numbers from various prob-
ability distributions. Second, there is a bookkeeping problem. Once you build an Excel
model with output cells linked to appropriate random input cells, you can press the F9 key
as often as you like to see how the outputs vary. However, there is no quick way to keep
track of these output values and summarize them. This bookkeeping feature is the real
strength of a simulation add-in such as @RISK. It can be done with Excel, usually with
data tables, but the summarization of the resulting data is completely up to the user—you.
Therefore, we strongly recommend that you use the “Excel-only” method described in this
section only if you don’t have an add-in such as @RISK.
To illustrate the Excel-only procedure, we continue analyzing the calendar problem from
Example 10.1. This general problem occurs when a company (such as a news vendor) must
make a one-time purchase of a product (such as a newspaper) to meet customer demands for a
certain period of time. If the company orders too few newspapers, it will lose potential profit
by not having enough on hand to satisfy its customers. If it orders too many, it will have news-
papers left over at the end of the day that, at best, can be sold at a loss. More generally, the
problem is to match supply to an uncertain demand, a very common problem in business. In
much of the rest of this chapter, we will discuss variations of this problem.
576
Chapter 10
Introduction to Simulation Modeling
E X A M P L E
10.2 SIMULATING WITH EXCEL ONLY AT WALTON BOOKSTORE
R
ecall that Walton Bookstore must decide how many of next year’s nature calendars to
order. Each calendar costs the bookstore $7.50 and sells for $10. After January 1, all
unsold calendars will be returned to the publisher for a refund of $2.50 per calendar. In this
version, we assume that demand for calendars (at the full price) is given by the probability
distribution shown in Table 10.1. Walton wants to develop a simulation model to help it
decide how many calendars to order.
Table 10.1 Probability Distribution of Demand for Walton Example
Demand
Probability
100
0.30
150
0.20
200
0.30
250
0.15
300
0.05 
Objective
To use built-in Excel tools—including the RAND function and data tables,
but no add-ins—to simulate profit for several order quantities and ultimately choose the
“best” order quantity.
WHERE DO THE NUMBERS COME FROM?
The numbers in Table 10.1 are the key to the simulation model. They are discussed in more
detail next.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Solution
We first discuss the probability distribution in Table 10.1. It is a discrete distribution with
only five possible values: 100, 150, 200, 250, and 300. In reality, it is clear that other values
of demand are possible. For example, there could be demand for exactly 187 calendars. In
spite of its apparent lack of realism, we use this discrete distribution for two reasons. First,
its simplicity is a nice feature to get you started with simulation modeling. Second, discrete
distributions are often used in real business simulation models. Even though the discrete
distribution is only an approximation to reality, it can still provide important insights into
the actual problem.
As for the probabilities listed in Table 10.1, they are typically drawn from historical
data or (if historical data are lacking) educated guesses. In this case, the manager of Walton
Bookstore has presumably looked at demands for calendars in previous years, and he has
used any information he has about the market for next year’s calendars to estimate, for
example, that the probability of a demand for 200 calendars is 0.30. The five probabilities
in this table must sum to 1. Beyond this requirement, they should be as reasonable and
consistent with reality as possible.
It is important to realize that this is really a decision problem under uncertainty.
Walton must choose an order quantity before knowing the demand for calendars.
Unfortunately, Solver cannot be used because of the uncertainty.7 Therefore, we develop a
simulation model for any fixed order quantity. Then we run this simulation model with
various order quantities to see which one appears to be best.
DEVELOPING THE SIMULATION MODEL
Now we discuss the ordering model. For any fixed order quantity, we show how Excel can
be used to simulate 1000 replications (or any other number of replications). Each replica-
tion is an independent replay of the events that occur. To illustrate, suppose you want to
simulate profit if Walton orders 200 calendars. Figure 10.25 illustrates the results obtained
by simulating 1000 independent replications for this order quantity. (See the file Walton
Bookstore 2.xlsx.) Note that there are many hidden rows in Figure 10.25. To develop this
model, use the following steps.
1
Inputs. Enter the cost data in the range B4:B6, the probability distribution of demand
in the range E5:F9, and the proposed order quantity, 200, in cell B9. Pay particular atten-
tion to the way the probability distribution is entered (and compare to the Discrete sheet in
the Probability Distributions.xlsx file). Columns E and F contain the possible demand
values and the probabilities from Table 10.1. It is also necessary (see step 2 for the reason-
ing) to have the cumulative probabilities in column D. To obtain these, first enter the value
0 in cell D5. Then enter the formula
F5+D5
in cell D6 and copy it to the range D7:D9.
2
Generate random demands.
The key to the simulation is the generation of the
customer demands in the range B19:B1018 from the random numbers generated by
the RAND function and the probability distribution of demand. Here is how it works.
The interval from 0 to 1 is split into five segments: 0.0 to 0.3 (length 0.3), 0.3 to 0.5
(length 0.2), 0.5 to 0.8 (length 0.3), 0.8 to 0.95 (length 0.15), and 0.95 to 1.0 (length 0.05).
Note that these lengths are the probabilities of the various demands. Then a demand is
10.4 Simulation with Built-In Excel Tools
577
7Palisade Corporation has another Excel add-in called RISKOptimizer that can be used for optimization in a sim-
ulation model. It is included in the suite that you own, but we will not discuss it here.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

associated with each random number, depending on which interval the random number
falls in. For example, if a random number is 0.5279, this falls in the third interval, so it is
associated with the third possible demand value, 200.
To implement this procedure, you use a VLOOKUP function based on the range
D5:F9 (named LookupTable). This table has the cumulative probabilities in column D and
the possible demand values in column E. In fact, the whole purpose of the cumulative
probabilities in column D is to allow the use of the VLOOKUP function. To generate the
simulated demands, enter the formula
VLOOKUP(RAND(),LookupTable,2)
in cell B19 and copy it to the range B20:B1018. This formula compares any RAND value
to the values in D5:D9 and returns the appropriate demand from E5:E9. (In the file, you
will note that random cells are colored green. This coloring convention is not required, but
we use it consistently to identify the random cells.)
This step is the key to the simulation, so make sure you understand exactly what it
entails. The rest is bookkeeping, as indicated in the following steps.
3
Revenue. Once the demand is known, the number of calendars sold is the smaller of
the demand and the order quantity. For example, if 150 calendars are demanded, 150 will
be sold. But if 250 are demanded, only 200 can be sold (because Walton orders only 200).
Therefore, to calculate the revenue in cell C19, enter the formula
Unit_price*MIN(B19,Order_quantity)
4
Ordering cost. The cost of ordering the calendars does not depend on the demand; it is
the unit cost multiplied by the number ordered. Calculate this cost in cell D19 with the formula
Unit_cost*Order_quantity
578
Chapter 10
Introduction to Simulation Modeling
simulaon
Simulaon
Distribuon
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
1016
1017
1018
A
B
C
D
E
F
G
H
I
J
Cost 
d
n
a
m
e
D
a
t
a
d
 
e
g
n
a
R
n
oit
u
birtsid
 names used:
Unit cost
$7.50
Cum Prob
Demand
Probability
LookupTable
=Model!$D$5:$F$9
Unit price
$10.00
0.00
100
0.30
Order_quanty
=Model!$B$9
Unit refund
$2.50
0.30
150
0.20
Unit_cost
=Model!$B$4
0.50
200
0.30
Unit_price
=Model!$B$5
Decision variable
0.80
250
0.15
Unit_refund
=Model!$B$6
Order quanty
200
0.95
300
0.05
Summary measures for 
 below
Average proﬁt
$193.63
95% conﬁdence interval for expected proﬁt
Stdev of proﬁt
$331.68
Lower limit
$173.07
Minimum proﬁt
-$250.00
Upper limit
$214.18
Maximum proﬁt
$500.00
 of proﬁt
y
c
n
e
u
q
e
r
F
e
ula
V
tif
o
r
P
d
n
u
f
e
R
ts
o
C
e
u
n
e
v
e
R
d
n
a
m
e
D
n
oit
a
cilp
e
R
1
100
$1,000
$1,500
$250
-$250
-250
316
5
8
1
5
2
1
5
2
1
$
5
2
1
$
0
0
5,1
$
0
0
5,1
$
0
5
1
2
9
9
4
0
0
5
0
0
5
$
0
$
0
0
5,1
$
0
0
0,2
$
0
0
2
3
4
100
$1,000
$1,500
$250
-$250
5
100
$1,000
$1,500
$250
-$250
998
200
$2,000
$1,500
$0
$500
999
200
$2,000
$1,500
$0
$500
1000
200
$2,000
$1,500
$0
$500
Figure 10.25 Walton Bookstore Simulation Model
This rather cumber-
some procedure for
generating a discrete
random number is not
necessary when you
use @RISK.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

5
Refund. If the order quantity is greater than the demand, there is a refund of $2.50
for each calendar left over; otherwise, there is no refund. Therefore, calculate the refund in
cell E19 with the formula
Unit_refund*MAX(Order_quantity-B19,0)
For example, if demand is 150, then 50 calendars are left over, and this MAX is 50, the
larger of 50 and 0. However, if demand is 250, then no calendars are left over, and this
MAX is 0, the larger of –50 and 0. (This calculation could also be accomplished with an IF
function instead of a MAX function.)
6
Profit. Calculate the profit in cell F19 with the formula
C19E19-D19
7
Copy to other rows. This is a “one-line” simulation, where all of the logic is captured
in a single row, row 19. For one-line simulations, you can replicate the logic with new ran-
dom numbers very easily by copying down. Copy row 19 down to row 1018 to generate
1000 replications.
8
Summary measures. Each profit value in column F corresponds to one randomly
generated demand. You usually want to see how these vary from one replication to another.
First, calculate the average and standard deviation of the 1000 profits in cells B12 and B13
with the formulas
AVERAGE(F19:F1018)
and
STDEV(F19:F1018)
Similarly, calculate the smallest and largest of the 1000 profits in cells B14 and B15 with
the MIN and MAX functions.
9
Confidence interval for mean pr ofit. Calculate a 95% confidence interval for the
mean profit in cells E13 and E14 with the formulas
B121.96*B13/SQRT(1000)
and
B121.96*B13/SQRT(1000)
(See the next section on confidence intervals for details.)
10 Distribution of simulated pr ofits. There are only three possible profits, $250,
$125, or $500 (depending on whether demand is 100, 150, or at least 200—see the follow-
ing discussion). You can use the COUNTIF function to count the number of times each of
these possible profits is obtained. To do so, enter the formula
COUNTIF($F$19:$F$1018,H19)
in cell I19 and copy it down to cell I21.
Checking Logic with Deterministic Inputs
It can be difficult to check whether the logic in your model is correct, because of the random
numbers. The reason is that you usually get different output values, depending on the partic-
ular random numbers generated. Therefore, it is sometimes useful to enter well-chosen fixed
values for the random inputs, just to see whether your logic is correct. We call these deter-
ministic checks. In the present example, you might try several fixed demands, at least one of
which is less than the order quantity and at least one of which is greater than the order quan-
tity. For example, if you enter a fixed demand of 150, the revenue, cost, refund, and profit
10.4 Simulation with Built-In Excel Tools
579
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

should be $1500, $1500, $125, and $125, respectively. Or if you enter a fixed demand of 250,
these outputs are $2000, $1500, $0, and $500. There is no randomness in these values; every
correct model should get these same values. If your model doesn’t get these values, there
must be a logic error in your model that has nothing to do with random numbers or simula-
tion. Of course, you should fix any such logical errors before reentering the random demand
and running the simulation.
You can make a similar check by keeping the random demand, repeatedly pressing the
F9 key, and watching the outputs for the different random demands. For example, if the
refund is not $0 every time demand exceeds the order quantity, you know you have a logi-
cal error in at least one formula. The advantage of deterministic checks is that you can
compare your results with those of other users, using agreed-upon test values of the ran-
dom quantities. You should all get exactly the same outputs. 
Discussion of the Simulation Results
At this point, it is a good idea to stand back and see what you have accomplished. First, in
the body of the simulation, rows 19 through 1018, you randomly generated 1000 possible
demands and the corresponding profits. Because there are only five possible demand
values (100, 150, 200, 250, and 300), there are only five possible profit values: $250,
$125, $500, $500, and $500. Also, note that for the order quantity 200, the profit is $500
regardless of whether demand is 200, 250, or 300. (Make sure you understand why.)
A tally of the profit values in these rows, including the hidden rows, indicates that there are
316 rows with profit equal to $250 (demand 100), 185 rows with profit equal to $125
(demand 150), and 499 rows with profit equal to $500 (demand 200, 250, or 300). The
average of these 1000 profits is $193.63, and their standard deviation is $331.68. (Again,
however, remember that your answers will probably differ from these because of different
random numbers.)
Typically, a simulation model should capture one or more output variables, such as
profit. These output variables depend on random inputs, such as demand. The goal is to
estimate the probability distributions of the outputs. In the Walton simulation the estimated
probability distribution of profit is
P(Profit  $250)  316/1000  0.316
P(Profit  $125)  185/1000  0.185
P(Profit  $500)  499/1000  0.499
The estimated mean of this distribution is $193.63 and the estimated standard deviation
is $331.68. It is important to realize that if the entire simulation is run again with dif-
ferent random numbers (such as the ones you might have generated on your PC), the
answers will probably be slightly different. This is the primary reason for the confi-
dence interval in cells E13 and E14. This interval expresses the remaining uncertainty
about the mean of the profit distribution. Your best guess for this mean is the average of
the 1000 profits you happened to observe. However, because the corresponding
confidence interval is somewhat wide, from $173.07 to $214.18, you are not at all sure
of the true mean of the profit distribution. You are only 95% confident that the true
mean is within this interval. If you run this simulation again with different random
numbers, the average profit might be somewhat different from the average profit you
observed, $193.63, and the other summary statistics will probably also be different.
(For illustration, we pressed the F9 key five times and got the following average profits:
$213.88, $206.00, $212.75, $219.50, and $189.50. So this is truly a case of “answers
will vary.”)
580
Chapter 10
Introduction to Simulation Modeling
For this particular
model, the output
distribution is also
discrete:There are 
only three possible
profits for an order
quantity of 200.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Notes about Confidence Intervals
It is common in computer simulations to estimate the mean of some distribution by the
average of the simulated observations. The usual practice is then to accompany this esti-
mate with a confidence interval, which indicates the accuracy of the estimate. You might
recall from statistics that to obtain a confidence interval for the mean, you start with the
estimated mean and then add and subtract a multiple of the standard error of the estimated
mean. If the estimated mean (that is, the average) is , the confidence interval is given in
the following formula.
X
10.4 Simulation with Built-In Excel Tools
581
The confidence 
interval provides a
measure of accuracy 
of the mean profit, as
estimated from the
simulation.
Confidence Interval for the Mean
X ; (Multiple * Standard Error of X)
Approximate 95% Confidence Interval for the Mean
X ; 2s/1n
Sample Size Determination
n = 4 * (Estimated standard deviation)2
B2
Standard Error of 
s/1n
X
The standard error of 
is the standard deviation of the observations divided by the
square root of n, the number of observations:
X
Here, s is the symbol for the standard deviation of the observations. You can obtain it
with the STDEV function in Excel.
The multiple in the confidence interval formula depends on the confidence level and
the number of observations. If the confidence level is 95%, for example, then the multiple
is usually very close to 2, so a good guideline is to go out two standard errors on either side
of the average to obtain an approximate 95% confidence interval for the mean.
To be more precise, if n is reasonably large, which is almost always the case in simula-
tions, the central limit theorem implies that the correct multiple is the number from the stan-
dard normal distribution that cuts off probability 0.025 in each tail. This is a famous number in
statistics: 1.96. Because 1.96 is very close to 2, it is acceptable for all practical purposes to use
2 instead of 1.96 in the confidence interval formula. (Note that you should use a different mul-
tiple if you want a 90% or a 99% confidence level rather than a 95% level.)
Analysts often plan a simulation so that the confidence interval for the mean of some
important output will be sufficiently narrow. The reasoning is that narrow confidence
intervals imply more precision about the estimated mean of the output variable. If the con-
fidence level is fixed at some value such as 95%, the only way to narrow the confidence
interval is to simulate more replications. Assuming that the confidence level is 95%, the
following value of n is required to ensure that the resulting confidence interval will have a
half-length approximately equal to some specified value B:
The idea is to choose
the number of itera-
tions large enough so
that the resulting 
confidence interval 
will be sufficiently 
narrow.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

This formula requires an estimate of the standard deviation of the output variable.
For example, in the Walton simulation the 95% confidence interval with n  1000 has
half-length ($214.18  $173.07)/2  $20.56. Suppose that you want to reduce this half-
length to $12.50—that is, you want B  $12.50. You do not know the exact standard
deviation of the profit distribution, but you can estimate it from the simulation as $331.68.
Therefore, to obtain the required confidence interval half-length B, you need to simulate
n replications, where
(When this formula produces a noninteger, it is common to round upward.) The
claim, then, is that if you rerun the simulation with 2817 replications rather than 1000
replications, the half-length of the 95% confidence interval for the mean profit will be
close to $12.50.
Finding the Best Order Quantity
You are not yet finished with the Walton example. So far, the simulation has been run for
only a single order quantity, 200. Walton’s ultimate goal is to find the best order quantity.
Even this statement must be clarified. What does “best” mean? As in Chapter 9, one possi-
bility is to use the expected profit—that is, EMV—as the optimality criterion, but other char-
acteristics of the profit distribution could influence the decision. You can obtain the required
outputs with a data table. Specifically, you use a data table to rerun the simulation for other
order quantities. This data table and a corresponding chart are shown in Figure 10.26. (This
is still part of the finished version of the Walton Bookstore 2.xlsx file.)
n = 4(328.04)2
12.502
L 2755
582
Chapter 10
Introduction to Simulation Modeling
17
18
19
20
21
22
23
24
25
26
27
28
29
K
L
M
N
O
P
Q
R
S
T
Data table for average proﬁt versus order quanty
Order quanty
Average proﬁt
$203.38
100
$250.00
125
$253.25
150
$263.25
175
$231.44
200
$192.50
225
$123.56
250
$49.00
275
-$60.63
300
-$206.25
-$300.00
-$200.00
-$100.00
$0.00
$100.00
$200.00
$300.00
100
125
150
175
200
225
250
275
300
Order Quan ty
Average proﬁt
Figure 10.26 Data Table for Walton Bookstore Simulation
To create this table, enter the trial order quantities shown in the range K20:K28, enter
the link B12 to the average profit in cell L19, and select the data table range K19:L28.
Then select Data Table from the What-If Analysis dropdown list, specifying that the
column input cell is B9. (See Figure 10.25.) Finally, construct a column chart of the aver-
age profits in the data table. Note that an order quantity of 150 appears to maximize the
average profit. Its average profit of $263.25 is slightly higher than the average profits from
nearby order quantities and much higher than the profit gained from an order of 200 or
more calendars. However, again keep in mind that this is a simulation, so that all of these
To optimize in
simulation models, try
various values of the
decision variable(s)
and run the simulation
for each of them.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

average profits depend on the particular random numbers generated. If you rerun the sim-
ulation with different random numbers, it is conceivable that some other order quantity
could be best. (Did you notice in the data table that the average profits in cells L19 and L24
are both based on an order quantity of 200? They are different because they are based on
different random numbers.)
Excel Tip: Calculation Settings with Data Tables
Sometimes you will create a data table and the values will be constant the whole way down.
This could mean you did something wrong, but more likely it is due to a calculation setting.
To check, go to the Formulas ribbon and click on the Calculation Options dropdown arrow.
If it isn’ t A utomatic (the default setting), you need to clic
k on the Calculate Now (or
Calculate Sheet) button or press the F9 key to make the data table calculate correctly. (The
Calculate Now and F9 k ey recalculate everything in your workbook. The Calculate Sheet
option recalculates only the active sheet.) Note that the A utomatic Except for Data Tables
setting is there for a reason. Data tables, especially those based on comple x simulations,
can take a lot of time to recalculate, and with the default setting, this recalculation occurs
every time anything changes in your workbook. So the A utomatic Except for Data T ables
setting is handy to prevent data tables from recalculating until you force them to by press-
ing the F9 key or clicking on one of the Calculate buttons.
Using a Data Table to Repeat Simulations
The Walton simulation is a particularly simple one-line simulation model. All of the
logic—generating a demand and calculating the corresponding profit—can be captured in
a single row. Then to replicate the simulation, you can simply copy this row down as far
as you like. Many simulation models are significantly more complex and require more
than one row to capture the logic. Nevertheless, they still result in one or more output
quantities (such as profit) that you want to replicate. We now illustrate another method of
replicating with Excel only that is more general (still using the Walton example). It uses a
data table to generate the replications. Refer to Figure 10.27 and the file Walton
Bookstore 3.xlsx.
Through row 19, this model is exactly like the previous model. That is, it uses the
given data at the top of the spreadsheet to construct a typical “prototype” of the simulation
in row 19. This time, however, do not copy row 19 down. Instead, form a data table in the
range A23:B1023 to replicate the basic simulation 1000 times. In column A, list the repli-
cation numbers, 1 to 1000. Next, enter the formula F19 in cell B23. This forms a link to
the profit from the prototype row for use in the data table. Then create a data table and
enter any blank cell (such as C23) as the column input cell. (No row input cell is necessary,
so its box should be left empty.) This tricks Excel into repeating the row 19 calculations
1000 times, each time with a new random number, and reporting the profits in column B of
the data table. (If you wanted to see other simulated quantities, such as revenue, for each
replication, you could add extra output columns to the data table.)
Excel Tip: How Data Tables Work
To understand this pr ocedure, you must under stand exactly how data tables work. When
you create a data table , Excel takes each value in the left column of the data table (her e,
column A), substitutes it into the cell designated as the column input cell, r ecalculates the
spreadsheet, and returns the output value (or values) you have requested in the top row of
the data table (suc h as pr ofit). It might seem silly to substitute eac h replication number
from column A into a blank cell suc h as cell C23, b ut this part is r eally irrelevant. The
important part is the recalculation. Each recalculation leads to a new random demand and
corresponding pr ofit, and these pr ofits ar e the quantities you want to k
eep tr ack of .
10.4 Simulation with Built-In Excel Tools
583
The key to simulating
many replications in
Excel (without an add-
in) is to use a data
table with any blank
cell as the column
input cell.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Of course, this means that you should not freeze the quantity in cell B19 before forming the
data table. The whole point of the data table is to use a dif ferent random number for each
replication, and this will occur only if the random demand in row 19 is “live.”
Using a Two-Way Data Table
You can carry this method one step further to see how the profit depends on the order
quantity. Here you use a two-way data table with the replication number along the side
and possible order quantities along the top. See Figure 10.28 and the file Walton
Bookstore 4.xlsx. Now the data table range is A23:J1023, and the driving formula in cell
A23 is again the link F19. The column input cell should again be any blank cell, and the
row input cell should be B9 (the order quantity). Each cell in the body of the data table
shows a simulated profit for a particular replication and a particular order quantity, and
each is based on a different random demand.
By averaging the numbers in each column of the data table (see row 14), you can see
that 150 again appears to be the best order quantity. It is also helpful to construct a column
chart of these averages, as in Figure 10.29. Now, however, assuming you have not frozen
anything, the data table and the corresponding chart will change each time you press the F9
key. To see whether 150 is always the best order quantity, you can press the F9 key and see
whether the bar above 150 continues to be the highest.
584
Chapter 10
Introduction to Simulation Modeling
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
1021
1022
1023
A
B
C
D
E
F
G
H
I
J
of Walton's
Simulaon
bookstore
Cost
d
n
a
m
e
D
a
t
a
d
e
g
n
a
R
n
oit
u
birtsid
names used:
Unit cost
$7.50
CumProb
DemandProbability
LookupTable
=Model!$D$5:$F$9
Unit
9
$
B
$
!le
d
o
M
=
ytit
n
a
u
q
_
r
e
d
r
O
0
3.0
0
0
1
0
0.0
0
0.0
1
$
e
cir
p
Unit
4
$
B
$
!le
d
o
M
=
ts
o
c
_
tin
U
0
2.0
0
5
1
0
3.0
0
5.2
$
d
n
u
f
e
r
0.50
200
0.30
Unit_price
=Model!$B$5
Decision variable
0.80
250
0.15
Unit_refund
=Model!$B$6
Order
5
0.0
0
0
3
5
9.0
0
0
2
ytit
n
a
u
q
Summary measures from simulaon below
Average
$189.13
95% conﬁdence interval for expected proﬁt
StDev
$327.89
Lower limit
$168.81
Minimum
-$250.00
Upper limit
$209.45
Maximum
$500.00
Demand
Revenue
Cost
Refund
Proﬁt
100
$1,000
$1,500
$250
-$250
Data
Simulaon
table for replicaons, each shows proﬁt from that replicaon
Replicaon
Proﬁt
-$250
1
-$250
2
$500
3
$500
4
-$250
998
$500
999
$500
1000
$500
Figure 10.27 Using a Data Table to Simulate Replications
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

10.4 Simulation with Built-In Excel Tools
585
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
1021
1022
1023
A
B
C
D
E
F
G
H
I
J
Simulaon of Walton's bookstore
Cost
Demand
data
e
g
n
a
R
n
oit
u
birtsid
names used:
Unit cost
$7.50
CumProb
Demand
Probability
LookupTable
=Model!$D$5:$F$9
Unit 
Order_quanty
0
3.0
0
0
1
0
0.0
0
0.0
1
$
e
cir
p
=Model!$B$9
Unit 
4
$
B
$
!le
d
o
M
=
ts
o
c
_
tin
U
0
2.0
0
5
1
0
3.0
0
5.2
$
d
n
u
f
e
r
0.50
200
0.30
Unit_price
=Model!$B$5
Decision variable
0.80
250
0.15
Unit_refund
=Model!$B$6
Order 
5
0.0
0
0
3
5
9.0
0
0
2
ytit
n
a
u
q
Summary measures of simulated proﬁts for each order quanty
Order quanty
100
125
150
175
200
225
250
275
300
Average proﬁt
$250.00
$261.13
$267.75
$237.44
$206.38
$118.69
$16.75
-$99.81
-$209.63
Stdev proﬁt
$0.00
$83.67
$169.54
$243.62
$327.49
$361.44
$429.60
$432.34
$442.74
Simulaon
Demand
Revenue
Cost
Refund
Proﬁt
100
$1,000
$1,500
$250
-$250
Data table showing proﬁt for replicaons with various order quanes
r
e
d
r
O
n
oit
a
cilp
e
R
quanty
($250.00)
100
125
150
175
200
225
250
275
300
1
$250
$313
$0
$250
-$250
375
625
125
375
2
$250
$313
$375
-$125
$125
0
-500
-250
-375
3
$250
$125
$375
$438
$500
375
250
-250
0
4
$250
$313
$0
$438
$500
375
250
-625
-750
998
$250
$313
$375
$438
$125
375
625
-625
-375
999
$250
$313
$0
$438
$500
375
250
500
375
1000
$250
$313
$375
$438
$500
562.5
-500
500
375
Figure 10.28 Using a Two-Way Data Table for the Simulation Model
-$100
$0
$100
$200
$300
100
125
150
175
200
225
250
275
300
Average Proﬁt 
-$300
-$200
-
100
125
150
175
200
225
250
275
300
Order Quanty
Figure 10.29
Column Chart of
Average Profits for
Different Order
Quantities
■
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

By now you should appreciate the usefulness of data tables in spreadsheet simulations.
They allow you to take a prototype simulation and replicate its key results as often as you
like. This method makes summary statistics (over the entire group of replications) and
corresponding charts fairly easy to obtain. Nevertheless, it takes some work to create the
data tables and charts. In the next section you will see how the @RISK add-in does a lot of
this work for you.
586
Chapter 10
Introduction to Simulation Modeling
P R O B L E M S
Skill-Building Problems
11. Suppose you own an expensive car and purchase auto
insurance. This insurance has a $1000 deductible,
so that if you have an accident and the damage is
less than $1000, you pay for it out of your pocket.
However, if the damage is greater than $1000, you
pay the first $1000 and the insurance pays the rest.
In the current year there is probability 0.025 that you
will have an accident. If you have an accident, the
damage amount is normally distributed with mean
$3000 and standard deviation $750.
a. Use Excel to simulate the amount you have to
pay for damages to your car. This should be a
one-line simulation, so run 5000 iterations by
copying it down. Then find the average amount
you pay, the standard deviation of the amounts
you pay, and a 95% confidence interval for the
average amount you pay. (Note that many of the
amounts you pay will be 0 because you have no
accidents.)
b. Continue the simulation in part a by creating a
two-way data table, where the row input is the
deductible amount, varied from $500 to $2000
in multiples of $500. Now find the average amount
you pay, the standard deviation of the amounts
you pay, and a 95% confidence interval for the
average amount you pay for each deductible
amount.
c. Do you think it is reasonable to assume that
damage amounts are normally distributed? What
would you criticize about this assumption?
What might you suggest instead?
12. In August of the current year, a car dealer is trying
to determine how many cars of the next model year to
order. Each car ordered in August costs $20,000. The
demand for the dealer’s next year models has the
probability distribution shown in the file P10_12.xlsx.
Each car sells for $25,000. If demand for next year’s
cars exceeds the number of cars ordered in August,
the dealer must reorder at a cost of $22,000 per car.
Excess cars can be disposed of at $17,000 per car.
Use simulation to determine how many cars to order
in August. For your optimal order quantity, find a 95%
confidence interval for the expected profit.
13. In the Walton Bookstore example, suppose that Walton
receives no money for the first 50 excess calendars
returned but receives $2.50 for every calendar after
the first 50 returned. Does this change the optimal
order quantity?
14. A sweatshirt supplier is trying to decide how
many sweatshirts to print for the upcoming NCAA
basketball championships. The final four teams have
emerged from the quarterfinal round, and there is
now a week left until the semifinals, which are then
followed in a couple of days by the finals. Each
sweatshirt costs $10 to produce and sells for $25.
However, in three weeks, any leftover sweatshirts
will be put on sale for half price, $12.50. The supplier
assumes that the demand for his sweatshirts during the
next three weeks (when interest in the tournament is
at its highest) has the distribution shown in the file
P10_14.xlsx. The residual demand, after the sweat-
shirts have been put on sale, has the distribution also
shown in this file. The supplier, being a profit maxi-
mizer, realizes that every sweatshirt sold, even at the
sale price, yields a profit. However, he also realizes
that any sweatshirts produced but not sold (even at the
sale price) must be thrown away, resulting in a $10
loss per sweatshirt. Analyze the supplier’s problem
with a simulation model.
Skill-Extending Problems
15. In the Walton Bookstore example with a discrete
demand distribution, explain why an order quantity
other than one of the possible demands cannot maxi-
mize the expected profit. (Hint: Consider an order of
190 calendars, for example. If this maximizes
expected profit, then it must yield a higher expected
profit than an order of 150 or 100. But then an order
of 200 calendars must also yield a larger expected
profit than 190 calendars. Why?)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

10.5 INTRODUCTION TO @RISK
Spreadsheet simulation modeling has become extremely popular in recent years, both in
the academic and corporate communities. Much of the reason for this popularity is due to
simulation add-ins such as @RISK. There are two primary advantages to using such an
add-in. First, an add-in gives you easy access to many probability distributions you might
want to use in your simulation models. You already saw in section 10.2 how the RISKDIS-
CRETE, RISKNORMAL, and RISKTRIANG functions, among others, are easy to use
and remember. Second, an add-in allows you to perform simulations much more easily
than is possible with Excel alone. To replicate a simulation in Excel, you typically need to
build a data table. Then you have to calculate summary statistics, such as averages, stan-
dard deviations, and percentiles, with built-in Excel functions. If you want graphs to
enhance the analysis, you have to create them. In short, you have to perform a number of
time-consuming steps for each simulation. Simulation add-ins such as @RISK perform
much of this work automatically.
Although we will focus only on @RISK in this book, it is not the only simulation add-
in available for Excel. Two worthy competitors are Crystal Ball, developed by
Decisioneering (www.decisioneering.com) and Risk Solver Platform, developed by
Frontline Systems, the developer of Solver (www.frontsys.com). Both Crystal Ball and
Risk Solver Platform have much of the same functionality as @RISK. However, the
authors have a natural bias for @RISK—we have been permitted by its developer, Palisade
Corporation (www.palisade.com), to provide the academic version free with this book. If it
were not included, you would have to purchase it from Palisade at a fairly steep price.
Indeed, Microsoft Office does not include @RISK, Crystal Ball, Risk Solver Platform, or
any other simulation add-in—you must purchase them separately.
10.5.1 @RISK Features
Here is an overview of some of @RISK’s features. We will discuss all of these in more
detail in this section.
1. @RISK contains a number of functions such as RISKNORMAL and RISKDIS-
CRETE that make it easy to generate observations from a wide variety of probability
distributions. You saw some of these in section 10.2.
2. You can designate any cell or range of cells in your simulation model as output
cells. When you run the simulation, @RISK automatically keeps summary measures
(averages, standard deviations, percentiles, and others) from the values generated in
these output cells across the replications. It also creates graphs such as histograms
based on these values. In other words, @RISK takes care of tedious bookkeeping
operations for you.
3. @RISK has a special function, RISKSIMTABLE, that allows you to run the
same simulation several times, using a different value of some key input variable
each time. This input variable is often a decision variable. For example, suppose
that you would like to simulate an inventory ordering policy (as in the Walton
Bookstore example). Your ultimate purpose is to compare simulation outputs
across a number of possible order quantities such as 100, 150, 200, 250, and 300.
If you use an appropriate formula involving the RISKSIMTABLE function, the
entire simulation is performed for each of these order quantities separately—with
one click of a button. You can then compare the outputs to choose the best order
quantity.
10.5 Introduction to @RISK
587
@RISK provides a
number of functions
for simulating from
various distributions,
and it takes care of all
the bookkeeping in
spreadsheet simula-
tions. Excel simulations
without @RISK require
much more work for
the user.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

This is the same
Walton Bookstore
model as before,
except that a
triangular distribution
for demand is used.
10.5.2 Loading @RISK
To build simulation models with @RISK, you need to have Excel open with @RISK added
in. The first step, if you have not already done so, is to install the Palisade DecisionTools
suite with the Setup program. Then you can load @RISK by clicking on the Windows Start
button, selecting the Programs group, selecting the Palisade DecisionTools group, and
finally selecting the @RISK item. If Excel is already open, this loads @RISK inside Excel.
If Excel is not yet open, this launches Excel and @RISK simultaneously.8 After @RISK is
loaded, you see an @RISK tab and the corresponding @RISK ribbon in Figure 10.30.9
588
Chapter 10
Introduction to Simulation Modeling
8We have had the best luck when we (1) close other applications we are not currently using, and (2) launch Excel and
@RISK together by starting @RISK. However, it is also possible to start @RISK after Excel is already running.
9If you have been using version 5.0 of @RISK, you will see only minor changes in the newer versions (5.5.1 or 5.7)
now available. However, if you have been using version 4.5, you will see major changes in the user interface.
Figure 10.30 @RISK Ribbon
10.5.3 @RISK Models with a Single Random Input Variable
In the remainder of this section we illustrate some of @RISK’s functionality by revisiting
the Walton Bookstore example. The next chapter demonstrates the use of @RISK in a
number of interesting simulation models. Throughout our discussion, you should keep one
very important idea in mind. The development of a simulation model is basically a two-
step procedure. The first step is to build the model itself. This step requires you to enter all
of the logic that transforms inputs (including @RISK functions such as RISKDISCRETE)
into outputs (such as profit). This is where most of the work and thinking go, exactly as in
models from previous chapters, and @RISK cannot do this for you. It is your job to enter
the formulas that link inputs to outputs appropriately. However, once this logic has been
incorporated, @RISK takes over in the second step. It automatically replicates your model,
with different random numbers on each replication, and it reports any summary measures
that you request in tabular or graphical form. Therefore, @RISK greatly decreases the
amount of busy work you need to do, but it is not a magic bullet.
We begin by analyzing an example with a single random input variable.
The majority of the
work (and thinking)
goes into developing
the model. Setting up
@RISK and then
running it are relatively
easy.
E X A M P L E
10.3 USING @RISK AT WALTON BOOKSTORE
R
ecall that Walton Bookstore buys calendars for $7.50, sells them at the regular price of
$10, and gets a refund of $2.50 for all calendars that cannot be sold. In contrast to
Example 10.2, assume now that Walton estimates a triangular probability distribution for
demand, where the minimum, most likely, and maximum values of demand are 100, 175,
and 300, respectively. The company wants to use this probability distribution, together
with @RISK, to simulate the profit for any particular order quantity, with the ultimate goal
of finding the best order quantity.
Objective
To learn about @RISK’s basic functionality by revisiting the Walton
Bookstore problem.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

WHERE DO THE NUMBERS COME FROM?
The monetary values are the same as before. The parameters of the triangular distribution of
demand are probably Walton’s best subjective estimates, possibly guided by its experience
with previous calendars. As in many simulation examples, the triangular distribution has been
chosen for simplicity. In this case, the manager would need to estimate only three quantities:
the minimum possible demand, the maximum possible demand, and the most likely demand.
Solution
We use this example to illustrate important features of @RISK. We first show how it helps
you to implement an appropriate input probability distribution for demand. Then we show
how it can be used to build a simulation model for a specific order quantity and generate
outputs from this model. Finally, we show how the RISKSIMTABLE function enables you
to simultaneously generate outputs from several order quantities so that you can choose the
optimal order quantity.
DEVELOPING THE SIMULATION MODEL
The spreadsheet model for profit is essentially the same model developed previously with-
out @RISK, as shown in Figure 10.31. (See the file Walton Bookstore 5.xlsx.) There are
only a few new things to be aware of.
10.5 Introduction to @RISK
589
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
A
B
C
D
E
F
G
H
I
J
Simulaon of Walton's Bookstore using
e
g
n
a
R
K
SI
R
@
names used:
Order_quanty
=Model!$B$9
Cost
d
n
a
m
e
D
a
t
a
d
distribuon - triangular
Unit_cost
=Model!$B$4
Unit
5
$
B
$
!le
d
o
M
=
e
cir
p
_
tin
U
0
0
1
m
u
m
ini
M
0
5.7
$
ts
o
c
Unit price
$10.00
Most
6
$
B
$
!le
d
o
M
=
d
n
u
f
e
r
_
tin
U
5
7
1
yle
kil
Unit refund
$2.50
Maximum
300
Decision variable
Order quanty
200
Simulaon
Demand
Revenue
Cost
Refund
Proﬁt
187
$1,870
$1,500
$33
$403
Summary measures of proﬁt from @RISK - based on 1000 iteraons
Minimum
-$235.00
Maximum
$500.00
Average
$337.50
Standard deviaon
$189.05
5th percenle
-$47.50
95th percenle
$500.00
P(proﬁt <= 300)
0.360
P(proﬁt > 400)
0.515
Figure 10.31 Simulation Model with a Fixed Order Quantity
1
Input distribution. To generate a random demand, enter the formula
ROUND(RISKTRIANG(E4,E5,E6),0)
in cell B13 for the random demand. This uses the RISKTRIANG function to generate a
demand from the triangular distribution. (As before, our convention is to color random
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

input cells green.) Excel’s ROUND function is used to round demand to the nearest inte-
ger. Recall from the discussion in section 10.3 that Excel has no built-in functions to gen-
erate random numbers from a triangular distribution, but this is easy with @RISK.
2
Output cell. When the simulation runs, you want @RISK to keep track of profit. In
@RISK’s terminology, you need to designate the Profit cell, F13, as an output cell. To do
this, select cell F13 and then click on the Add Output button on the @RISK ribbon. (See
Figure 10.30.) This adds RISKOUTPUT(“label”) to the cell’s formula. (Here, “label”
is a label that @RISK uses for its reports. In this case it makes sense to use “Profit” as the
label.) The formula in cell F13 changes from
C13E13-D13
to
RISKOUTPUT("Profit")C13E13-D13
The plus sign following RISKOUTPUT does not indicate addition. It is simply @RISK’s
way of indicating that you want to keep track of the value in this cell (for reporting
reasons) as the simulation progresses. Any number of cells can be designated in this way
as output cells. They are typically the “bottom line” values of primary interest. Our
convention is to color such cells gray for emphasis.
3
Summary functions.
There are several places where you can store @RISK
results. One of these is to use @RISK statistical functions to place results in your
model worksheet. @RISK provides several functions for summarizing output values.
Some of these are illustrated in the range B16:B23 of Figure 10.31. They contain the
formulas
RISKMIN(F13)
RISKMAX(F3)
RISKMEAN(F13)
RISKSTDDEV(F13)
RISKPERCENTILE(F13,0.05)
RISKPERCENTILE(F13,0.95)
RISKTARGET(F13,300)
and
1-RISKTARGET(F13,400)
The values in these cells are not meaningful until you run the simulation (so do not be
alarmed if they contain error symbols when you open the file). However, once the simula-
tion runs, these formulas capture summary statistics of profit. For example, RISKMEAN
calculates the average of the 1000 simulated profits, RISKPERCENTILE finds the value
such that the specified percentage of simulated profits are less than or equal to this value,
and RISKTARGET finds the percentage of simulated profits less than or equal to the spec-
ified value. Although these same summary statistics also appear in other @RISK reports, it
is handy to have them in the same worksheet as the model.
Running the Simulation
After you develop the model, the rest is straightforward. The procedure is always the same:
(1) specify simulation settings, (2) run the simulation, and (3) examine the results.
590
Chapter 10
Introduction to Simulation Modeling
The RISKOUTPUT
function indicates 
that a cell is an 
output cell, so that
@RISK will keep 
track of its values
throughout the
simulation.
These @RISK
summary functions
allow you to show
simulation results on
the same sheet as the
model. However, they
are totally optional.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

1
Simulation settings. You must first choose some simulation settings. To do so, the
buttons on the left in the Simulation group (see Figure 10.32) are useful. We typically do
the following: 
■
Set Iterations to a number such as 1000. (@RISK calls replications “iterations.”) Any
number can be used, but because the academic version of @RISK allows only 1000
uninterrupted iterations, we typically choose 1000.
■
Set Simulations to 1. In a later section, we will explain why you might want to
request multiple simulations.
■
Click on the “dice” button so that it becomes orange. This button is actually a toggle
for what appears in your worksheet. If it is orange, the setting is called “Monte
Carlo” and all random cells appear random (they change when you press the F9 key).
If it is blue, only the means appear in random input cells and the F9 key has no
effect. We prefer the Monte Carlo setting, but both settings have exactly the same
effect when you run the simulation.
■
Many more settings are available by clicking on the button to the left of the “dice”
button, but the ones we mentioned should suffice. In addition, more permanent set-
tings can be chosen from Application Settings under Utilities on the @RISK ribbon.
You can experiment with these, but the only one we like to change is the Place
Reports In setting. The default is to place reports in a new workbook. If you like the
reports to be in the same workbook as your model, you can change this setting to
Active Workbook.
10.5 Introduction to @RISK
591
Figure 10.32
Simulation Group
on @RISK Ribbon
@RISK TECHNICAL ISSUES: Latin Hypercube Sampling and Mersenne Twister
Generator
Two settings you shouldn’ t change are the Sampling T ype and Gener ator settings (avail-
able from the b utton to the left of the “dice” b
utton and then the Sampling tab). The
y
should r emain at the default Latin Hyper
cube and Mer senne T wister settings. The
Mersenne Twister is one algorithm, of many , for g enerating random numbers, and it has
been shown to have very good statistical pr operties. (Not all r andom number g enerators
do.) Latin Hypercube sampling is a more efficient way of sampling than the other option
(Monte Carlo) because it produces a more accurate estimate of the output distribution. In
fact, we wer e surprised how accur ate it is. In r epeated runs of this model, always using
different random numbers, we virtually always got a mean pr ofit within a fe w pennies of
$337.50. It turns out that this is the true mean profit for this input distribution of demand.
Amazingly, simulation estimates it corr
ectly—almost e xactly—on virtually e very run.
Unfortunately, this means that a conf
idence interval for the mean, based on @RISK’
s
outputs and the usual confidence interval formula (which assumes Monte Carlo sampling),
is much wider (mor e pessimistic) than it should be . Therefore, we do not e ven calculate
such confidence intervals from here on. 
2
Run the simulation. To run the simulation, simply click on the Start Simulation on
the @RISK ribbon. When you do so, @RISK repeatedly generates a random number for
Leave Latin Hyper-
cube sampling on.
It produces more
accurate results.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

each random input cell, recalculates the worksheet, and keeps track of all output cell
values. You can watch the progress at the bottom left of the screen. 
3
Examine the results. The big questions are (1) which results you want and (2) where
you want them. @RISK provides a lot of possibilities, and we mention only our favorites.
■
You can ask for summary measures in your model worksheet by using the @RISK
statistical functions, such as RISKMEAN, discussed earlier.
■
The quickest way to get results is to select an input or output cell (we chose the
profit cell, F13) and then click on the Browse Results button on the @RISK ribbon.
(See Figure 10.33.) This provides an interactive histogram of the selected value, as
shown in Figure 10.34. You can move the sliders on this histogram to see probabili-
ties of various outcomes. Note that the window you see from Browse Results is
temporary—it goes away when you click on Close. You can make a permanent
copy of the chart by clicking on the third button from the left (see the bottom of
Figure 10.34) and choosing one of the copy options.
592
Chapter 10
Introduction to Simulation Modeling
For a quick histogram
of an output or input,
select the output or
input cell and click on
@RISK’s Browse
Results button.
Figure 10.33
Results and Tools
Groups on @RISK
Ribbon
Figure 10.34
Interactive
Histogram of Profit
Output
@RISK Tip: Percentiles Displayed on Charts
When we displayed the c hart in F igure 10.34 the f irst time , it had the right slider on
500 but showed 5% to the right of it. By default, @RISK puts the sliders at the 5th and 95th
percentiles, so that 5% is on either side of them. F
or this e xample, 500 is indeed the 
95th percentile (why?), but the picture is a bit misleading because there is no chance of a
profit greater than 500. When we manually moved the right slider away from 500 and back
again, it displayed as in F igure 10.34, correctly indicating that ther e is no pr obability to
the right of 500.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

@RISK Tip: Saving Graphs and Tables
When you run a simulation with @RISK and then save your f ile, it asks whether you want
to save your graphs and tables. We suggest that you save them. This makes your file slightly
larger, but when you reopen it, the temporary graphs and tables, such as the histogram in
Figure 10.34, are still available. Otherwise, you will have to rerun the simulation.
■
You can click on the Summary button (again, see Figure 10.33) to see the temporary
window in Figure 10.35 with the summary measures for Profit. In general, this report
shows the summary for all designated inputs and outputs. By default, this Results
Summary window shows a mini histogram for each output and a number of numeri-
cal summary measures. However, it is easy to customize. If you right-click on this
table and choose Columns for Table, you can check or uncheck any of the options.
For most of the later screenshots in this book, we elected not to show the Graph and
Errors columns, but instead to show median and standard deviation columns.
10.5 Introduction to @RISK
593
For a quick (and cus-
tomizable) report of
the results, click on
@RISK’s Summary
button.
Figure 10.35 Summary Table of Profit Output
■
You can click on the Excel Reports button (again, see Figure 10.33) to choose from
a number of reports that are placed on new worksheets. This is a good option if you
want permanent (but non-interactive) copies of reports in your workbook. As an
example, Figure 10.36 shows (part of) the Detailed Statistics report you can request.
It has the same information as the summary report in Figure 10.35, plus a lot more.
Discussion of the Simulation Results
The strength of @RISK is that it keeps track of any outputs you designate and then allows
you to show the corresponding results as graphs or tables, in temporary windows or in
permanent worksheets. As you have seen, @RISK provides several options for displaying
results, and we encourage you to explore the possibilities. However, don’t lose sight of the
overall goal: to see how outputs vary as random inputs vary, and to generate reports that
tell the story most effectively. For this particular example, the results in Figures 10.31,
10.34, 10.35, and 10.36 allow you to conclude the following:
■
The smallest simulated profit (out of 1000) was $235, the largest was $500, the aver-
age was $337.50, and the standard deviation of the 1000 profits was $189.05. Of all
simulated profits, 5% were $47.50 or below, 95% were $500 or above, 36% were
less than or equal to $300, and 51.5% were larger than $400. (See Figure 10.31. These
results are also available from the summary table in Figure 10.35 or the detailed statis-
tics report in Figure 10.36. In particular, the bottom of the detailed statistics report, not
shown in the figure, allows you to ask for any percentiles or target values.)
If you want perma-
nent copies of the
simulation results,
click on @RISK’s 
Excel Reports 
buttons and check 
the reports you want.
They will be placed in
new worksheets.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

■
The profit distribution for this particular order quantity is extremely skewed to the
left, with a large bar at $500. (See Figure 10.34.) Do you see why? It is because
profit is exactly $500 if demand is greater than or equal to the order quantity, 200. In
other words, the probability that profit is $500 equals the probability that demand is
at least 200. (This probability is 0.4.) Lower demands result in decreasing profits,
which explains the gradual decline in the histogram from right to left.
USING RISKSIMTABLE
Walton’s ultimate goal is to choose an order quantity that provides a large average profit.
You could rerun the simulation model several times, each time with a different order quan-
tity in the order quantity cell, and compare the results. However, this has two drawbacks.
First, it takes a lot of time and work. The second drawback is more subtle. Each time you
run the simulation, you get a different set of random demands. Therefore, one of the order
quantities could win the contest just by luck. For a fairer comparison, it is better to test
each order quantity on the same set of random demands.
The RISKSIMTABLE function in @RISK enables you to obtain a fair comparison
quickly and easily. This function is illustrated in Figure 10.37. (See the file Walton
Bookstore 6.xlsx.) There are two modifications to the previous model. First, the order
quantities to test are listed in row 9. (We chose these as representative order quantities. You
could change, or add to, this list.) Second, instead of entering a number in cell B9, you
enter the formula
RISKSIMTABLE(D9:H9)
Note that the list does not need to be entered in the spreadsheet (although it is a good idea
to do so). You could instead enter the formula
RISKSIMTABLE({150,175,200,225,250})
594
Chapter 10
Introduction to Simulation Modeling
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
B
C
D
@RISK Detailed Stascs
Performed By:  Chris Albright
Date: Tuesday, September 29, 2009 11:54:02 AM
Name 
Proﬁt
Demand
Descripon 
Output
RiskTriang(E4,E5,E6)
Cell 
Model!F13
Model!B13
Minimum
-$235
102
Maximum
$500
295
Mean
$337
192
Std Deviaon
$189
41
Variance
35741.22
1702.818
Skewness
-0.9485486
0.2346369
Kurtosis
2.796431
2.401627
Errors
0
0
Mode
$500
175
5% Perc
-$48
127
10% Perc
$43
139
15% Perc
$103
147
20% Perc
$163
155
25% Perc
$208
161
30% Perc
$253
167
35% Perc
$290
172
Figure 10.36
@RISK Detailed
Statistics Report
The RISKSIMTABLE
function allows you 
to run several
simulations at 
once—one for each
value of some 
variable (often 
a decision variable).
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

where the list of numbers must be enclosed in curly brackets. In either case, the worksheet
displays the first member of the list, 150, and the corresponding calculations for this first
order quantity. However, the model is now set up to run the simulation for all order
quantities in the list.
To implement this, only one setting needs to be changed. As before, enter 1000 for
the number of iterations, but also enter 5 for the number of simulations. @RISK then runs
five simulations of 1000 iterations each, one simulation for each order quantity in the
list, and it uses the same 1000 random demands for each simulation. This provides a fair
comparison.
10.5 Introduction to @RISK
595
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
A
B
C
D
E
F
G
H
I
J
K
Simulaon of Walton's Bookstore using 
e
g
n
a
R
K
SI
R
@
 names used:
Order_quanty
=Model!$B$9
Cost 
d
n
a
m
e
D
a
t
a
d
 distribuon - triangular
Unit_cost
=Model!$B$4
Unit 
5
$
B
$
!le
d
o
M
=
e
cir
p
_
tin
U
0
0
1
m
u
m
ini
M
0
5.7
$
ts
o
c
Unit price
$10.00
Most 
6
$
B
$
!le
d
o
M
=
d
n
u
f
e
r
_
tin
U
5
7
1
yle
kil
Unit refund
$2.50
Maximum
300
Decision variable
Order quanes to try
Order quanty
150
150
175
200
225
250
Simulated quanes
Demand
Revenue
Cost
Refund
Proﬁt
253
$1,500
$1,125
$0
$375
Summary measures of proﬁt from @RISK - based on 1000 iteraons for each simulaon
5
4
3
2
1
n
oit
alu
m
iS
Order quanty
150
175
200
225
250
Minimum
-$235.00
-$110.00
-$235.00
-$360.00
-$485.00
Maximum
$500.00
$437.50
$500.00
$562.50
$625.00
Average
$337.50
$367.20
$337.51
$270.32
$175.00
Standard deviaon
$189.05
$121.86
$189.05
$247.05
$286.96
5th percenle
-$47.50
$77.50
-$47.50
-$172.50
-$297.50
95th percenle
$500.00
$437.50
$500.00
$562.50
$625.00
Figure 10.37 Model with a RISKSIMTABLE Function
@RISK Function: RISKSIMTABLE
To run se
veral simulations all at once
, enter the formula 
RISKSIMTABLE
(InputRange) in any cell. Her e, InputRange refers to a list of the values to be simu-
lated, such as various or der quantities. Befor e running the simulation, mak e sure the
number of simulations is set to the number of values in the InputRange list.
You can again get results from the simulation in various ways. Here are some possibilities. 
■
You can enter the same @RISK statistical functions in cells in the model worksheet,
as shown in rows 18–23 of Figure 10.37. The trick is to realize that each such func-
tion has an optional last argument that specifies the simulation number. For example,
the formulas in cells C20 and C22 are
RISKMEAN($F$13,C16)
and
RISKPERCENTILE($F$13,0.05,C16)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Remember that the results in these cells are meaningless (or show up as errors) until
you run the simulation.
■
You can select the profit cell and click on Browse Results to see a histogram of
profits, as shown in Figure 10.38. By default, the histogram shown is for the first
simulation, where the order quantity is 150. However, if you click on the red his-
togram button with the pound sign, you can select any of the simulations. As an
example, Figure 10.39 shows the histogram of profits for the fifth simulation,
where the order quantity is 250. (Do you see why these two histograms are so
different? When the order quantity is 150, there is a high probability of selling 
out; hence the spike on the right is large. But the probability of selling out with 
an order quantity of 250 is much lower; hence its spike on the right is much less
dominant.)
596
Chapter 10
Introduction to Simulation Modeling
Figure 10.38
Histogram of
Profit with Order
Quantity 150
Figure 10.39
Histogram of
Profit with Order
Quantity 250
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

■
You can click on the Summary button to get the results from all simulations shown in
Figure 10.40. (These results match those in Figure 10.37.)
■
You can click on Excel Reports to get any of a number of reports on permanent
worksheets. Specifically, Quick Reports is a good choice. This produces several
graphs and summary measures for each simulation, each on a different worksheet.
This provides a lot of information with almost no work!
For this particular example, the results in Figures 10.37–10.40 are illuminating. You can
see that an order quantity of 175 provides the largest mean profit. However, is this neces-
sarily the optimal order quantity? This depends on the company’s attitude toward risk.
Certainly, larger order quantities incur more risk (their histograms are more spread out,
their 5th and 95th percentiles are more extreme), but they also have more upside potential.
On the other hand, a smaller order quantity, while having a somewhat smaller mean, might
be preferable because of less variability. It is not an easy choice, but at least the simulation
results provide plenty of information for making the decision.
■
10.5 Introduction to @RISK
597
Figure 10.40 Summary Report for All Five Simulations
10.5.4 Some Limitations of @RISK
The academic version of @RISK has some limitations you should be aware of. (The com-
mercial version of @RISK doesn’t have these limitations. Also, the exact limitations could
change as newer academic versions become available.)
■
The simulation model must be contained in a single workbook with at most four
worksheets, and each worksheet is limited to 300 rows and 100 columns.
■
The number of @RISK input probability distribution functions, such as RISKNORMAL,
is limited to 100.
■
The number of unattended iterations is limited to 1000. You can request more than
1000, but you have to click a button after each 1000 iterations.
■
All @RISK graphs contain a watermark.
■
The Distribution Fitting tool can handle only 150 observations.
The first limitation shouldn’t cause problems, at least not for the fairly small models
discussed in this book. However, we strongly urge you to close all other workbooks when
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

you are running an @RISK simulation model, especially if they also contain @RISK
functions. @RISK does a lot of recalculation, both in your active worksheet and in all
other worksheets or workbooks that are open. So if you are experiencing extremely slow
simulations, this is probably the reason.
The second limitation can be a problem, especially in multiperiod problems. For exam-
ple, if you are simulating 52 weeks of a year, and each week requires two random inputs, you
are already over the 100-function limit. One way to get around this is to use built-in Excel
functions for random inputs rather than @RISK functions whenever possible. For example, if
you want to simulate the flip of a fair coin, the formula IF(RAND()0.5,"Heads","Tails")
works just as well as the formula IF(RISKUNIFORM(0,1)0.5,"Heads","Tails"), but
the former doesn’t count against the 100-function limit.
10.5.5 @RISK Models with Several Random Input Variables
We conclude this section with another modification of the Walton Bookstore example. To
this point, there has been a single random variable, demand. Often there are several
random variables, each reflecting some uncertainty, and you want to include each of these
in the simulation model. The following example illustrates how this can be done, and it
also illustrates a very useful feature of @RISK, its sensitivity analysis.
598
Chapter 10
Introduction to Simulation Modeling
To avoid potential
problems, close all
other workbooks when
running an @RISK
model.
E X A M P L E
10.4 ADDITIONAL UNCERTAINTY AT WALTON BOOKSTORE
A
s in the previous Walton Bookstore example, Walton needs to place an order for next
year’s calendar. We continue to assume that the calendars sell for $10 and customer
demand for the calendars at this price is triangularly distributed with minimum value, most
likely value, and maximum value equal to 100, 175, and 300. However, there are now two
other sources of uncertainty. First, the maximum number of calendars Walton’s supplier
can supply is uncertain and is modeled with a triangular distribution. Its parameters are
125 (minimum), 200 (most likely), and 250 (maximum). Once Walton places an order, the
supplier will charge $7.50 per calendar if he can supply the entire Walton order. Otherwise,
he will charge only $7.25 per calendar. Second, unsold calendars can no longer be returned
to the supplier for a refund. Instead, Walton will put them on sale for $5 apiece after
January 1. At that price, Walton believes the demand for leftover calendars is triangularly
distributed with parameters 0, 50, and 75. Any calendars still left over, say, after March 1,
will be thrown away. Walton again wants to use simulation to analyze the resulting profit
for various order quantities.
Objective
To develop and analyze a simulation model with multiple sources of uncer-
tainty using @RISK, and to introduce @RISK’s sensitivity analysis features.
WHERE DO THE NUMBERS COME FROM?
As in Example 10.3, the monetary values are straightforward, and the parameters of the tri-
angular distributions are probably educated guesses, possibly based on experience with
previous calendars.
Solution
As always, the first step is to develop the model. Then you can run the simulation with
@RISK and examine the results.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

DEVELOPING THE SIMULATION MODEL
The completed model is shown in Figure 10.41. (See the file Walton Bookstore 7.xlsx.)
The model itself requires a bit more logic than the previous Walton model. It can be devel-
oped with the following steps.
10.5 Introduction to @RISK
599
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
A
B
C
D
E
F
G
H
I
J
K
L
M
Simulaon of Walton's Bookstore using @RISK
Range names used:
Order_quanty
=Model!$B$10
Cost 
d
n
a
m
e
D
a
t
a
d
 distribuon: triangular
Regular_price
=Model!$B$6
Unit cost 
r
alu
g
e
R
0
5.7
$
1
 price
Sale price
Supply distribuon: triangular
Sale_price
=Model!$B$7
Unit cost 
4
$
B
$
!le
d
o
M
=
1
_
ts
o
c
_
tin
U
5
2
1
m
u
m
ini
M
0
0
0
1
m
u
m
ini
M
5
2.7
$
2
Regular price
$10.00
Most likely
175
50
Most likely
200
Unit_cost_2
=Model!$B$5
Sale 
0
5
2
m
u
m
ix
a
M
5
7
0
0
3
m
u
m
ix
a
M
0
0.5
$
e
cir
p
Decision variable
Order quanes to try
Order 
0
5
2
5
2
2
0
0
2
5
7
1
0
5
1
0
5
1
ytit
n
a
u
q
Simulated quanes
Maximum supply
Actual supply
Cost
Demand
Revenue
Le over
Demand
Revenue
Proﬁt
179
150
$1,125
164
$1,500
0
45
$0
$375
Summary measures of proﬁt from @RISK - based on 1000 iteraons for each simulaon
5
4
3
2
1
n
oit
alu
m
iS
Order 
0
5
2
5
2
2
0
0
2
5
7
1
0
5
1
ytit
n
a
u
q
0
0.0
5
$
m
u
m
ini
M
-$137.50
-$325.00
-$421.75
-$421.75
5
7.2
6
6
$
0
0.6
1
6
$
5
2.7
4
5
$
0
5.8
7
4
$
5
7.9
0
4
$
m
u
m
ix
a
M
6
9.8
9
3
$
9
2.6
9
3
$
4
9.5
9
3
$
2
8.0
9
3
$
7
3.1
6
3
$
e
g
a
r
e
v
A
Standard deviaon
$43.84
$92.83
$145.33
$176.12
$178.16
5th percenle
$265.00
$178.00
$57.25
$13.00
$15.75
95th percenle
$375.00
$459.25
$525.25
$577.50
$588.50
At regular price
At sale price
Figure 10.41 @RISK Simulation Model with Three Random Inputs
1
Random inputs. There are three random inputs in this model: the maximum supply
the supplier can provide Walton, the customer demand when the selling price is $10, and
the customer demand for sale-price calendars. Generate these in cells B14, E14, and H14
(using the ROUND function to obtain integers) with the RISKTRIANG function.
Specifically, the formulas in cells B14, E14, and H14 are
ROUND(RISKTRIANG(I5,I6,I7),0)
ROUND(RISKTRIANG (E5,E6,E7),0)
and
ROUND(RISKTRIANG (F5,F6,F7),0)
Note that the formula in cell H14 generates the random potential demand for calendars at
the sale price, even though there might not be any calendars left to put on sale.
2
Actual supply. The number of calendars supplied to Walton is the smaller of the
number ordered and the maximum the supplier is able to supply. Calculate this value in
cell C14 with the formula
MIN(B14,Order_quantity)
3
Order cost. Walton gets the reduced price, $7.25, if the supplier cannot supply the
entire order. Otherwise, Walton must pay $7.50 per calendar. Therefore, calculate the total
order cost in cell D14 with the formula (using the obvious range names)
IF(B14Order_quantity,Unit_cost_1,Unit_cost_2)*C14
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4
Other quantities. The rest of the model is straightforward. Calculate the revenue
from regular-price sales in cell F14 with the formula
Regular_price*MIN(C14,E14)
Calculate the number left over after regular-price sales in cell G14 with the formula
MAX(C14-E14,0)
Calculate the revenue from sale-price sales in cell I14 with the formula
Sale_price*MIN(G14,H14)
Finally, calculate profit and designate it as an output cell for @RISK in cell J14 with the
formula
RISKOUTPUT("Profit")F14I14-D14
You could also designate other cells (the revenue cells, for example) as output cells.
5
Order quantities. As before, enter a RISKSIMTABLE function in cell B10 so that
Walton can try different order quantities. Specifically, enter the formula
RISKSIMTABLE(D10:H10)
in cell B10.
Running the Simulation
As usual, the next steps are to specify the simulation settings (we chose 1000 iterations and
five simulations), and run the simulation. It is important to realize what @RISK does when
it runs a simulation when there are several random input cells. In each iteration, @RISK
generates a random value for each input variable independently. In this example, it gener-
ates a maximum supply in cell B14 from one triangular distribution, it generates a regular-
price demand in cell E14 from another triangular distribution, and it generates a sale-price
demand in cell H14 from a third triangular distribution. With these input values, it then cal-
culates profit. For each order quantity, it then iterates this procedure 1000 times and keeps
track of the corresponding profits.10
Discussion of the Simulation Results
Selected results are listed in Figure 10.41 (at the bottom), and the profit histogram for an
order quantity of 200 is shown in Figure 10.42. (The histograms for the other order quanti-
ties are similar to what you have seen before, with more skewness to the left and a larger
spike to the right as the order quantity decreases.) For this particular order quantity, the
results indicate an average profit of about $396, a 5th percentile of $57, a 95th percentile of
$525, and a distribution of profits that is again skewed to the left.
Sensitivity Analysis
We now demonstrate a feature of @RISK that is particularly useful when there are several
random input cells. This feature lets you see which of these inputs is most related to, or
correlated with, an output cell. To perform this analysis, select the profit cell, J14, and
click on the Browse Results button. You will see a histogram of profit in a temporary
window, as we have already discussed, with a number of buttons at the bottom of the win-
dow. Click on the red button with the pound sign to select a simulation. We chose #3,
where the order quantity is 200. Then click on the “tornado” button (the fifth button from
600
Chapter 10
Introduction to Simulation Modeling
On each iteration,
@RISK generates a
new set of random
inputs and calculates
the corresponding
output(s).
10It is also possible to correlate the inputs, as we demonstrate in the next section.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

the left) and choose Correlation Coefficients. This produces the chart in Figure 10.43.
(The Regression option produces similar results, but we believe the Correlation option is
easier to understand.)
This figure shows graphically and numerically how each of the random inputs
correlates with profit: the higher the magnitude of the correlation, the stronger the rela-
tionship between that input and profit. In this sense, you can see that the regular-price
demand has by far the largest effect on profit. The other two inputs, maximum supply
and sale-price demand, are nearly uncorrelated with profit, so they are much less impor-
tant. Identifying important input variables is important for real applications. If a random
input is highly correlated with an important output, then it is probably worth the time
and money to learn more about this input and possibly reduce the amount of uncertainty
involving it.
■
10.5 Introduction to @RISK
601
Figure 10.42
Histogram of
Simulated Profits for
Order Quantity 200
Figure 10.43
Tornado Graph for
Sensitivity Analysis
A tornado chart
indicates which of the
random inputs have
large effects on an
output.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

602
Chapter 10
Introduction to Simulation Modeling
P R O B L E M S
Skill-Building Problems
16. If you add several normally distributed random
numbers, the result is normally distributed, where
the mean of the sum is the sum of the individual
means, and the variance of the sum is the sum of the
individual variances. (Remember that variance is the
square of standard deviation.) This is a difficult result
to prove mathematically, but it is easy to demonstrate
with simulation. To do so, run a simulation where
you add three normally distributed random numbers,
each with mean 100 and standard deviation 10. Your
single output variable should be the sum of these three
numbers. Verify with @RISK that the distribution
of this output is approximately normal with mean
300 and variance 300 (hence, standard deviation
).
17. In Problem 11 from the previous section, we stated
that the damage amount is normally distributed.
Suppose instead that the damage amount is
triangularly distributed with parameters 500, 1500,
and 7000. That is, the damage in an accident can
be as low as $500 or as high as $7000, the most
likely value is $1500, and there is definite skewness
to the right. (It turns out, as you can verify in
@RISK, that the mean of this distribution is $3000,
the same as in Problem 11.) Use @RISK to simulate
the amount you pay for damage. Run 5000 itera-
tions. Then answer the following questions. In
each case, explain how the indicated event would
occur.
a. What is the probability that you pay a positive
amount but less than $750?
b. What is the probability that you pay more than
$600?
c. What is the probability that you pay exactly $1000
(the deductible)?
18. Continuing the previous problem, assume, as in
Problem 11, that the damage amount is normally
distributed with mean $3000 and standard deviation
$750. Run @RISK with 5000 iterations to simulate
the amount you pay for damage. Compare your results
with those in the previous problem. Does it appear to
matter whether you assume a triangular distribution or
a normal distribution for damage amounts? Why isn’t
this a totally fair comparison? (Hint: Use @RISK’s
Define Distributions tool to find the standard deviation
for the triangular distribution.)
19. In Problem 12 of the previous section, suppose that
the demand for cars is normally distributed with
mean 100 and standard deviation 15. Use @RISK
to determine the “best” order quantity—in this case,
the one with the largest mean profit. Using the
statistics and/or graphs from @RISK, discuss
whether this order quantity would be considered
best by the car dealer. (The point is that a decision
maker can use more than just mean profit in making
a decision.)
20. Use @RISK to analyze the sweatshirt situation in
Problem 14 of the previous section. Do this for the
discrete distributions given in the problem. Then do
it for normal distributions. For the normal case,
assume that the regular demand is normally
distributed with mean 9800 and standard deviation
1300 and that the demand at the reduced price is
normally distributed with mean 3800 and standard
deviation 1400.
Skill-Extending Problems
21. Although the normal distribution is a reasonable input
distribution in many situations, it does have two
potential drawbacks: (1) it allows negative values,
even though they may be extremely improbable, and
(2) it is a symmetric distribution. Many situations are
modeled better with a distribution that allows only
positive values and is skewed to the right. Two of these
that have been used in many real applications are the
gamma and lognormal distributions. @RISK enables
you to generate observations from each of these distri-
butions. The @RISK function for the gamma distribu-
tion is RISKGAMMA, and it takes two arguments, as
in RISKGAMMA(3,10). The first argument, which
must be positive, determines the shape. The smaller it
is, the more skewed the distribution is to the right; the
larger it is, the more symmetric the distribution is.
The second argument determines the scale, in the
sense that the product of it and the first argument
equals the mean of the distribution. (The mean in this
example is 30.) Also, the product of the second argu-
ment and the square root of the first argument is the
standard deviation of the distribution. (In this example,
it is 
.) The @RISK function for the
lognormal distribution is RISKLOGNORM. It has
two arguments, as in RISKLOGNORM(40,10).
These arguments are the mean and standard deviation
of the distribution. Rework Example 10.2 for the fol-
lowing demand distributions. Do the simulated outputs
have any different qualitative properties with these
skewed distributions than with the triangular distribu-
tion used in the example?
a. Gamma distribution with parameters 2 and 85
b. Gamma distribution with parameters 5 and 35
c. Lognormal distribution with mean 170 and
standard deviation 60
13(10) = 17.32
1300 = 17.32
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

10.6 THE EFFECTS OF INPUT DISTRIBUTIONS ON RESULTS
In section 10.2, we discussed input distributions. The randomness in input variables causes
the variability in the output variables. We now briefly explore whether the choice of input
distribution(s) makes much difference in the distribution of an output variable such as
profit. This is an important question. If the choice of input distributions doesn’t matter
much, then you do not need to agonize over this choice. However, if it does make a
difference, then you have to be more careful about choosing the most appropriate input
distribution for any particular situation. Unfortunately, it is impossible to answer the ques-
tion definitively. The best we can say in general is, “It depends.” Some models are more
sensitive to changes in the shape or parameters of input distributions than others. Still, the
issue is worth exploring.
We discuss two types of sensitivity analysis in this section. First, we check whether
the shape of the input distribution matters. In the Walton Bookstore example, we assumed
a triangularly distributed demand with some skewness. Are the results basically the same if
a symmetric distribution such as the normal distribution is used instead? Second, we check
whether the independence of input variables that have been assumed implicitly to this
point is crucial to the output results. Many random quantities in real situations are not inde-
pendent; they are positively or negatively correlated. Fortunately, @RISK enables you to
build correlation into a model. We analyze the effect of this correlation.
10.6.1 Effect of the Shape of the Input Distribution(s)
We first explore the effect of the shape of the input distribution(s). As the following exam-
ple indicates, if parameters that allow for a fair comparison are used, the shape can have a
relatively minor effect.
10.6 The Effects of Input Distributions on Results
603
E X A M P L E
10.5 EFFECT OF DEMAND DISTRIBUTION AT WALTON’S
W
e continue to explore the demand for calendars at Walton Bookstore. We keep the
same unit cost, unit price, and unit refund for leftovers as in Example 10.3.
However, in that example we assumed a triangular distribution for demand with parame-
ters 100, 175, and 300. Assuming that Walton orders 200 calendars, is the distribution of
profit affected if a normal distribution of demand is used instead?
Objective
To see whether a triangular distribution with some skewness gives the same
profit distribution as a normal distribution for demand.
WHERE DO THE NUMBERS COME FROM?
The numbers here are the same as in Example 10.3. However, as discussed next, the
parameters of the normal distribution are chosen to provide a fair comparison with the
triangular distribution used earlier.
Solution
It is important in this type of analysis to make a fair comparison. When you select a normal
distribution for demand, you must choose a mean and standard deviation for this distribu-
tion. Which values should you choose? It seems only fair to choose the same mean and
For a fair comparison
of alternative input
distributions, the
distributions should
have (at least
approximately) equal
means and standard
deviations.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

standard deviation that the triangular distribution has. To find the mean and standard devi-
ation for a triangular distribution with given minimum, most likely, and maximum values,
you can take advantage of @RISK’s Define Distributions tool. Select any blank cell, click
on the Define Distributions button, select the triangular distribution, and enter the parame-
ters 100, 175, and 300. You will see that the mean and standard deviation are 191.67 and
41.248, respectively. Therefore, for a fair comparison you should use a normal distribution
with mean 191.67 and standard deviation 41.248. In fact, @RISK allows you to see a com-
parison of these two distributions, as in Figure 10.44. To get this chart, click on the Add
Overlay button, select the normal distribution from the gallery, and enter 191.67 and
41.248 as its mean and standard deviation.
604
Chapter 10
Introduction to Simulation Modeling
Figure 10.44
Triangular and
Normal
Distributions for
Demand
DEVELOPING THE SIMULATION MODEL
The logic in this model is almost exactly the same as before. (See Figure 10.45 and the file
Walton Bookstore 8.xlsx.) However, a clever use of the RISKSIMTABLE function allows
you to run two simulations at once, one for the triangular distribution and one for the
corresponding normal distribution. The following two steps are required.
1
RISKSIMTABLE function. It is useful to index the two distributions as 1 and 2. To
indicate that you want to run the simulation with both of them, enter the formula
RISKSIMTABLE({1,2})
in cell B11. Note that when you enter actual numbers in this function, rather than cell
references, you must put curly brackets around the list.
2
Demand. When the value in cell B11 is 1, the demand distribution is triangular.
When it is 2, the distribution is normal. Therefore, enter the formula
ROUND(IF(B111,RISKTRIANG(E4,E5,E6),RISKNORMAL(H4,H5)),0)
in cell B15. The effect is that the first simulation will use the triangular distribution, and
the second will use the normal distribution.
Look for ways to use
the RISKSIMTABLE
function. It can really
improve efficiency
because it runs several
simulations at once.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Running the Simulation
The only @RISK setting to change is the number of simulations. It should now be set to 2,
the number of values in the RISKSIMTABLE formula. Other than this, you run the simu-
lation exactly as before.
Discussion of the Simulation Results
The comparison is shown numerically in Figure 10.46 and graphically in Figure 10.47. As
you can see, there is more chance of really low profits when the demand distribution is
normal, but each simulation results in the same maximum profit. Both of these statements
make sense. The normal distribution, being unbounded on the left, allows for very low
demands, and these occasional low demands result in very low profits. On the other side,
Walton’s maximum profit is $500 regardless of the input distribution (provided that it
allows demands greater than the order quantity). This occurs when Walton’s sells all it
orders, in which case excess demand has no effect on profit. Note that the mean profits for
the two distributions differ by only about $5.
10.6 The Effects of Input Distributions on Results
605
Simulaon of Walton's Bookstore using @RISK - two possible demand 
e
g
n
a
R
s
n
oit
u
birtsid
 names used:
Order_quanty =Model!$B$9
Cost 
d
n
a
m
e
D
a
t
a
d
 distribuon 1 - triangular
Demand distribuon 2 - normal
Unit_cost
=Model!$B$4
Unit 
n
a
e
M
0
0
1
m
u
m
ini
M
0
5.7
$
ts
o
c
5
$
B
$
!le
d
o
M
=
e
cir
p
_
tin
U
7
6.1
9
1
Unit 
ts
o
M
0
0.0
1
$
e
cir
p
 
6
$
B
$
!le
d
o
M
=
d
n
u
fe
r
_
tin
U
8
4
2.1
4
v
e
d
tS
5
7
1
yle
kil
Unit 
0
0
3
m
u
m
ix
a
M
0
5.2
$
d
n
u
fe
r
Decision variable
Order 
0
0
2
ytit
n
a
u
q
Demand distribuon to use
1
Formula is =RiskSimtable({1,2})
Simulated quanes
Demand
Revenue
Cost
Refund
Proﬁt
179
$1,790
$1,500
$53
$343
Summary measures of proﬁt from @RISK - based on 1000 iteraons for each simulaon
2
1
n
oit
alu
m
iS
Minimum
-$235.00
-$595.00
0
0.0
0
5
$
0
0.0
0
5
$
m
u
m
ix
a
M
2
8.2
4
3
$
8
4.7
3
3
$
e
g
a
r
e
v
A
Standard 
Distribuon
Triangular
Normal
devia on
$189.10
$201.77
5th percenle
-$47.50
-$70.00
95th percenle
$500.00
$500.00
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
A
B
C
D
E
F
G
H
I
J
K
L
M
Figure 10.45 @RISK Model for Comparing Two Input Distributions
Figure 10.46 Summary Results for Comparison Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

It is probably safe to conclude that the profit distribution in this model is not greatly
affected by the choice of demand distribution, at least not when (1) the candidate input
distributions have the same mean and standard deviation, and (2) their shapes are not too
dissimilar. We would venture to guess that this general conclusion about insensitivity of
output distributions to shapes of input distributions can be made in many simulation
models. However, it is always worth checking, as we have done here, especially when
there is a lot of money at stake.
■
606
Chapter 10
Introduction to Simulation Modeling
Figure 10.47 Graphical Results for Comparison Model
FUNDAMENTAL INSIGHT
Shape of the Output Distribution
Predicting the sha pe of the output distribution fr om
the shape(s) of the input distribution(s) is difficult. For
example, normally distributed inputs don’ t necessarily
produce normally distributed outputs.It is also difficult
to predict how sensitive the shape of the output distri-
bution is to the sha pe(s) of the input distribution(s).
For example , normally and triangularl y distributed
inputs (with the same means and standar d deviations)
are likely to lead to similar output distributions,
but
there could be differences,say,in the tails of the output
distributions.In any case,you should examine the entire
output distribution carefully, not just a few of its sum-
mary measures.
10.6.2 Effect of Correlated Input Variables
Until now, all of the random numbers generated with @RISK functions have been proba-
bilistically independent. This means, for example, that if a random value in one cell is
much larger than its mean, the random values in other cells are completely unaffected.
They are no more likely to be abnormally large or small than if the first value had been
average or below average. Sometimes, however, independence is unrealistic. In such cases,
the random numbers should be correlated in some way. If they are positively correlated,
then large numbers will tend to go with large numbers, and small with small. If they are
negatively correlated, then large will tend to go with small and small with large. As an
example, you might expect daily stock price changes for two companies in the same
industry to be positively correlated. If the price of one oil company increases, you might
expect the price of another oil company to increase as well. @RISK enables you to build in
this correlated behavior with the RISKCORRMAT function, as we illustrate in the follow-
ing continuation of the Walton example.
Input variables in real-
world problems are
often correlated, which
makes the material in
this section particularly
important.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

10.6 The Effects of Input Distributions on Results
607
E X A M P L E
10.6 CORRELATED DEMANDS FOR TWO CALENDARS AT WALTON’S
S
uppose that Walton Bookstore must order two different calendars. To simplify the
example, we assume that the calendars each have the same unit cost, unit selling price,
and unit refund value as in previous examples. Also, we assume that each has a triangularly
distributed demand with parameters 100, 175, and 300. However, we now assume they are
“substitute” products, so that their demands are negatively correlated. This simply means
that if a customer buys one, the customer is not likely to buy the other. Specifically, we
assume a correlation of 0.9 between the two demands. How do these correlated inputs
affect the distribution of profit, as compared to the situation where the demands are uncor-
related (correlation 0) or very positively correlated (correlation 0.9)?
Objective
To see how @RISK enables us to simulate correlated demands, and to see the
effect of correlated demands on profit.
WHERE DO THE NUMBERS COME FROM?
The only new input here is the correlation. It is probably negative because the calendars are
substitute products, but it is a difficult number to estimate accurately. This is a good candi-
date for a sensitivity analysis.
Solution
The key to building in correlation is @RISK’s RISKCORRMAT (correlation matrix)
function. To use this function, you must include a correlation matrix in the model,
as shown in the range J5:K6 of Figure 10.48. (See the file Walton Bookstore 9.xlsx.) 
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
K
J
I
H
G
F
E
D
C
B
A
Simulaon of Walton's Bookstore using @RISK - correlated demands
Cost data - same for each product
Demand distribuon for each product- triangular
Correlaon matrix between demands
Unit 
tc
u
d
o
r
P
0
0
1
m
u
m
ini
M
0
5.7
$
ts
o
c
 1 Product 2
Unit 
ts
o
M
0
0.0
1
$
e
cir
p
 
tc
u
d
o
r
P
5
7
1
yle
kil
 1
1
-0.9
Unit 
tc
u
d
o
r
P
0
0
3
m
u
m
ix
a
M
0
5.2
$
d
n
u
fe
r
 2
-0.9
1
Decision variables
Possible correlaons to try
Order quanty 
0
0
2
1
-0.9
0
0.9
Order quanty 
0
0
2
2
Range names used:
Simulated quanes
Order_quanty_1 =Model!$B$9
0
1
$
B
$
!le
d
o
M
=
2
_
ytit
n
a
u
q
_
r
e
d
r
O
tif
o
r
P
d
n
u
fe
R
ts
o
C
e
u
n
e
v
e
R
d
n
a
m
e
D
Product 
4
$
B
$
!le
d
o
M
=
ts
o
c
_
tin
U
5
2
4
$
5
2
$
0
0
5,1
$
0
0
9,1
$
0
9
1
1
Product 
5
$
B
$
!le
d
o
M
=
e
cir
p
_
tin
U
8
2
3
$
8
5
$
0
0
5,1
$
0
7
7,1
$
7
7
1
2
6
$
B
$
!le
d
o
M
=
d
n
u
fe
r
_
tin
U
3
5
7
$
3
8
$
0
0
0,3
$
0
7
6,3
$
7
6
3
sla
t
o
T
Summary measures of proﬁt from @RISK - based on 1000 iteraons
Simulaon
1
2
3
Correlaon
-0.9
0
0.9
0
5.2
7
2
$
m
u
m
ini
M
-$245.00
-$425.00
0
0.0
0
0,1
$
0
0.0
0
0,1
$
0
0.0
0
0,1
$
m
u
m
ix
a
M
4
0.5
7
6
$
4
0.5
7
6
$
4
0.5
7
6
$
e
g
a
r
e
v
A
Standard deviaon
$157.59
$262.33
$365.23
5th percenle
$392.50
$205.00
-$80.00
95th percenle
$925.00
$1,000.00
$1,000.00
Note RISKSIMTABLE 
funcon in cell J6.
Figure 10.48 Simulation Model with Correlations
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

A correlation matrix must always have 1s along its diagonal (because a variable is always
perfectly correlated with itself) and the correlations between variables elsewhere. Also, the
matrix must be symmetric, so that the correlations above the diagonal are a mirror image
of those below it. (You can enforce this by entering the formula J6 in cell K5.
Alternatively, @RISK allows you to enter the correlations only below the diagonal, or only
above the diagonal, and it then infers the mirror images.)
To enter random values in any cells that are correlated, you start with a typical @RISK
formula, such as
RISKTRIANG(E4,E5,E6)
Then you add an extra argument, the RISKCORRMAT function, as follows:
RISKTRIANG(E4,E5,E6,RISKCORRMAT(J5:K6,1))
The first argument of the RISKCORRMAT function is the correlation matrix range. The
second is an index of the variable. In this example, the first calendar demand has index 1
and the second has index 2.
@RISK Function: RISKCORRMAT
This function enables you to corr elate two or mor e input variables in an @RISK model.
The function has the form RISKCORRMAT(CorrMat,Index), where CorrMat is a matrix
of correlations and Index is an index of the variable being correlated to others. For exam-
ple, if there are three correlated variables, Index is 1 for the first variable, 2 for the second,
and 3 for the thir d. The RISKCORRMA T function is not enter ed by itself . Rather, it is
entered as the last ar
gument of a r
andom @RISK function, suc
h as RISKTRI-
ANG(10,15,30,RISKCORRMAT(CorrMat,2)).
DEVELOPING THE SIMULATION MODEL
Armed with this knowledge, the simulation model in Figure 10.48 is straightforward and
can be developed as follows.
1
Inputs. Enter the inputs in the blue ranges in columns B and E.
2
Correlation matrix. For the correlation matrix in the range J5:H6, enter 1s on the
diagonal, and enter the formula
J6
in cell K5 (or leave cell K5 blank). Then enter the formula
RISKSIMTABLE(I9:K9)
in cell J6. This allows you to simultaneously simulate negatively correlated demands,
uncorrelated demands, and positively correlated demands.
3
Order quantities. Assume for now that the company orders the same number of each
calendar, 200, so enter this value in cells B9 and B10. However, the simulation is set up so
that you can experiment with any order quantities in these cells, including unequal values.
4
Correlated demands. Generate correlated demands by entering the formula
ROUND(RISKTRIANG(E4,E5,E6,RISKCORRMAT(J5:K6,1)),0)
in cell B14 for demand 1 and the formula
ROUND(RISKTRIANG(E4,E5,E6, RISKCORRMAT(J5:K6,2)),0)
in cell B15 for demand 2. The only difference between these is the index of the variable
being generated. The first has index 1; the second has index 2.
608
Chapter 10
Introduction to Simulation Modeling
The RISKCORRMAT
function is “tacked 
on” as an extra
argument to a typical
random @RISK
function.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

5
Other formulas. The other formulas in rows 14 and 15 are identical to ones devel-
oped in previous examples, so they aren’t presented again here. The quantities in row 16
are simply sums of rows 14 and 15. Also, the only @RISK output we designated is the
total profit in cell F16, but you can designate others as output cells if you like.
Running the Simulation
You should set up and run @RISK exactly as before. For this example, set the number of
iterations to 1000 and the number of simulations to 3 (because three different correlations
are being tested).
Discussion of the Simulation Results
Selected numerical and graphical results are shown in Figures 10.49 and 10.50. You will
probably be surprised to see that the mean total profit is the same, regardless of the corre-
lation. This is no coincidence. In each of the three simulations, @RISK uses the same ran-
dom numbers but “shuffles” them in different orders to get the correct correlations. This
means that averages are unaffected. (The idea is that the average of the numbers 30, 26,
and 48 is the same as the average of the numbers 48, 30, and 26.)
10.6 The Effects of Input Distributions on Results
609
Figure 10.49 Summary Results for Correlated Model
Figure 10.50 Graphical Results for Correlated Model
However, the correlation has a definite effect on the distribution of total profit. You
can see this in Figure 10.49, for example, where the standard deviation of total profit
increases as the correlation goes from negative to zero to positive. This same increase in
variability is apparent in the histograms in Figure 10.50. Do you see intuitively why this
increase in variability occurs? It is basically the “Don’t put all of your eggs in one basket”
effect. When the correlation is negative, high demands for one product tend to cancel low
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

demands for the other product, so extremes in profit are rare. However, when the correla-
tion is positive, high demands for the two products tend to go together, as do low demands.
These make extreme profits on either end much more likely.
This same phenomenon would occur if you simulated an investment portfolio contain-
ing two stocks. When the stocks are positively correlated, the portfolio is much riskier
(more variability) than when they are negatively correlated. Of course, this is the reason for
diversifying a portfolio.
■
610
Chapter 10
Introduction to Simulation Modeling
We illustrated the RISKCORRMAT function for triangularly distributed values. However,
it can be used with any of @RISK’s distributions by tacking on RISKCORRMAT as a last
argument. You can even mix them. For example, assuming CMat is the range name for a 
2  2 correlation matrix, you could enter the formulas
RISKNORMAL(10,2,RISKCORRMAT(CMat,1))
and
RISKUNIFORM(100,200,RISKCORRMAT(CMat,2))
into any two cells. When you run the simulation, @RISK generates a sequence of nor-
mally distributed random numbers based on the first formula and another sequence of
uniformly distributed random numbers based on the second formula. Then it shuffles
them in some complex way until their correlation is approximately equal to the specified
correlation in the correlation matrix. ■
MODELING ISSUES
With the
RISKCORRMAT
function, you can
correlate random
numbers from any
distributions.
FUNDAMENTAL INSIGHT
Correlated Inputs
When you enter random inputs in an @RISK sim ula-
tion model and then run the sim ulation, each iteration
generates independent values for the random inputs. If
you kno w or suspect that some of the inputs ar
e 
positively or negatively correlated,you should build this
correlation structure into the model explicitly with the
RISKCORRMAT function.This function might not change
the mean of an output, but it can definitel y affect the
variability and shape of the output distribution.
P R O B L E M S
Skill-Building Problems
22. The Fizzy Company produces six-packs of soda cans.
Each can is supposed to contain at least 12 ounces
of soda. If the total weight in a six-pack is less than
72 ounces, Fizzy is fined $100 and receives no sales
revenue for the six-pack. Each six-pack sells for
$3.00. It costs Fizzy $0.02 per ounce of soda put in
the cans. Fizzy can control the mean fill rate of its
soda-filling machines. The amount put in each can
by a machine is normally distributed with standard
deviation 0.10 ounce.
a. Assume that the weight of each can in a six-pack
has a 0.8 correlation with the weight of the other
cans in the six-pack. What mean fill quantity
maximizes expected profit per six-pack? Try
mean fill rates from 12.00 to 12.35 in increments
of 0.05.
b. If the weights of the cans in the six-pack are
probabilistically independent, what mean fill
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

quantity maximizes expected profit per six-pack?
Try the same mean fill rates as in part a.
c. How can you explain the difference in the answers
to parts a and b?
23. When you use @RISK’s correlation feature to
generate correlated random numbers, how can you
verify that they are correlated? Try the following.
Use the RISKCORRMAT function to generate two
normally distributed random numbers, each with mean
100 and standard deviation 10, and with correlation
0.7. To run a simulation, you need an output variable,
so sum these two numbers and designate the sum as
an output variable. Now run @RISK with 500
iterations. Click on @RISK’s Excel Reports button
and check the Simulation Data option to see the actual
simulated data.
a. Use Excel’s CORREL function to calculate the
correlation between the two input variables. It
should be close to 0.7. Then create a scatterplot of
these two input variables. The plot should indicate
a definite positive relationship.
b. Are the two input variables correlated with the
output? Use Excel’s CORREL function to find
out. Interpret your results intuitively.
24. Repeat the previous problem, but make the correlation
between the two inputs equal to –0.7. Explain how the
results change.
25. Repeat Problem 23, but now make the second input
variable triangularly distributed with parameters 50,
100, and 500. This time, verify not only that the
correlation between the two inputs is approximately
0.7, but also that the shapes of the two input distribu-
tions are approximately what they should be: normal
for the first and triangular for the second. Do this
by creating histograms in Excel. The point is that
you can use @RISK’s RISKCORRMAT function
to correlate random numbers from different
distributions.
26. Suppose you are going to invest equal amounts in
three stocks. The annual return from each stock is nor-
mally distributed with mean 0.01 (1%) and standard
deviation 0.06. The annual return on your portfolio,
the output variable of interest, is the average of the
three stock returns. Run @RISK, using 1000 itera-
tions, on each of the following scenarios.
a. The three stock returns are highly correlated. The
correlation between each pair is 0.9.
b. The three stock returns are practically independent.
The correlation between each pair is 0.1.
c. The first two stocks are moderately correlated. The
correlation between their returns is 0.4. The third
stock’s return is negatively correlated with the
other two. The correlation between its return and
each of the first two is 0.8.
d. Compare the portfolio distributions from @RISK
for these three scenarios. What do you conclude?
e. You might think of a fourth scenario, where the
correlation between each pair of returns is a large
negative number such as 0.8. But explain
intuitively why this makes no sense. Try to run the
simulation with these negative correlations and see
what happens.
27. The effect of the shapes of input distributions on the
distribution of an output can depend on the output
function. For this problem, assume there are 10 input
variables. The goal is to compare the case where these
10 inputs each have a normal distribution with mean
1000 and standard deviation 250 to the case where
they each have a triangular distribution with
parameters 600, 700, and 1700. (You can check with
@RISK’s Define Distributions window that even
though this triangular distribution is very skewed, it
has the same mean and approximately the same
standard deviation as the normal distribution.) For
each of the following outputs, run two @RISK
simulations, one with the normally distributed inputs
and one with the triangularly distributed inputs, and
comment on the differences between the resulting
output distributions. For each simulation run 10,000
iterations.
a. Let the output be the average of the inputs.
b. Let the output be the maximum of the inputs.
c. Calculate the average of the inputs. Then the output
is the minimum of the inputs if this average is less
than 1000; otherwise, the output is the maximum
of the inputs.
Skill-Extending Problems
28. The Business School at State University currently has
three parking lots, each containing 155 spaces. Two
hundred faculty members have been assigned to each
lot. On a peak day, an average of 70% of all lot 1
parking sticker holders show up, an average of 72%
of all lot 2 parking sticker holders show up, and an
average of 74% of all lot 3 parking sticker holders
show up.
a. Given the current situation, estimate the probability
that on a peak day, at least one faculty member
with a sticker will be unable to find a spot. Assume
that the number who show up at each lot is indepen-
dent of the number who show up at the other two
lots. Compare two situations: (1) each person can
park only in the lot assigned to him or her, and (2)
each person can park in any of the lots (pooling).
(Hint: Use the RISKBINOMIAL function.)
b. Now suppose the numbers of people who show
up at the three lots are highly correlated (correla-
tion 0.9). How are the results different from those
in part a?
10.6 The Effects of Input Distributions on Results
611
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

10.7 CONCLUSION
Simulation has traditionally not received the attention it deserves in management science
courses. The primary reason for this has been the lack of easy-to-use simulation software.
Now, with Excel’s built-in simulation capabilities, plus powerful and affordable add-ins such
as @RISK, simulation is receiving its rightful emphasis. The world is full of uncertainty,
which is what makes simulation so valuable. Simulation models provide important insights
that are missing in models that do not incorporate uncertainty explicitly. In addition, simula-
tion models are relatively easy to understand and develop. Therefore, we suspect that
simulation models (together with optimization models) will soon be the primary emphasis of
many management science courses—if they are not already. In this chapter we have illustrated
the basic ideas of simulation, how to perform simulation with Excel built-in tools, and how
@RISK greatly enhances Excel’s basic capabilities. In the next chapter we will build on this
knowledge to develop and analyze simulation models in a variety of business areas.
612
Chapter 10
Introduction to Simulation Modeling
Summary of Key Management Science Terms
Term
Explanation
Excel
Pages
Simulation model
Model with random inputs that affect one or 
552
more outputs, where the randomness is modeled 
explicitly
Probability
Specification of the possible values and their proba-
555
distributions for
bilities for random input variables; these distributions
input variables
must be specified in any simulation model
Uniform distribution
The flat distribution, where all values in a bounded
559
continuum are equally likely
Discrete
A general distribution where a discrete number of 
565
distribution
possible values and their probabilities are specified
Triangular
Literally a triangle-shaped distribution, specified by
568
distribution
a minimum value, a most likely value, and a 
maximum value
Latin hypercube
An efficient way of simulating random numbers for a
591
sampling
simulation model, where the results are more
accurate than with other sampling methods
Correlated inputs
Random quantities, such as returns from stocks in the
610
same industry, that tend to go together (or
possibly go in opposite directions from one another)
Key Excel Terms
Term
Explanation
Excel
Pages
F9 key
The “recalc” key, used to make a spreadsheet 
recalculate
Press the F9 key
555
RAND function
Excel’s built-in random number generator; generates
RAND()
560
uniformly distributed random numbers between 0 and 1
RANDBETWEEN
Excel’s built-in function for generating equally 
RANDBETWEEN
560
function
likely random integers over an indicated range
(min,max)
Freezing random
Changing “volatile” random numbers into 
Copy range,
563
numbers
“fixed” numbers
paste it onto itself 
with the Paste 
Values option
(continued)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

10.7 Conclusion
613
Term
Explanation
Excel
Pages
@RISK random
A set of functions, including RISKNORMAL
RISKNORMAL
563–570
functions
and RISKTRIANG, for generating random
(mean,stdev)
numbers from various distributions
or =RISKTRIANG 
(min,mostlikely,max),
for example
Replicating with
Useful when an add-in such as @RISK is not available
Develop simulation
583
Excel only
model, use a data table
with any blank column
input cell to replicate
one or more outputs
@RISK
A useful simulation add-in developed by Palisade
@RISK ribbon
587
RISKSIMTABLE
Used to run an @RISK simulation model for several
RISKSIMTABLE
587
function
values of some variable, often a decision variable
(list)
RISKOUTPUT
Used to indicate that a cell contains an output that
RISKOUTPUT 
590
function
will be tracked by @RISK
("Profit")
Revenue-Cost,
for example
RISKCORRMAT
Used in @RISK to correlate two or more 
RISKNORMAL
610
function
random input variables
(100,10, 
RISKCORRMAT
(CorrMat,2)), 
for example 
P R O B L E M S
Skill-Building Problems
29. Six months before its annual convention, the American
Medical Association must determine how many rooms
to reserve. At this time, the AMA can reserve rooms
at a cost of $150 per room. The AMA believes the
number of doctors attending the convention will be
normally distributed with a mean of 5000 and a
standard deviation of 1000. If the number of people
attending the convention exceeds the number of rooms
reserved, extra rooms must be reserved at a cost of
$250 per room.
a. Use simulation with @RISK to determine the num-
ber of rooms that should be reserved to minimize
the expected cost to the AMA. Try possible values
from 4100 to 4900 in increments of 100.
b. Redo part a for the case where the number attend-
ing has a triangular distribution with minimum
value 2000, maximum value 7000, and most likely
value 5000. Does this change the substantive
results from part a?
30. You have made it to the final round of the show Let’s
Make a Deal. You know that there is a $1 million prize
behind either door 1, door 2, or door 3. It is equally
likely that the prize is behind any of the three doors.
The two doors without a prize have nothing behind
them. You randomly choose door 2. Before you see
whether the prize is behind door 2, host Monty Hall
opens a door that has no prize behind it. Specifically,
suppose that before door 2 is opened, Monty reveals
that there is no prize behind door 3. You now have the
opportunity to switch and choose door 1. Should you
switch? Simulate this situation 1000 times. For each
replication use an @RISK function to generate the
door that leads to the prize. Then use another @RISK
function to generate the door that Monty will open.
Assume that Monty plays as follows: Monty knows
where the prize is and will open an empty door, but he
cannot open door 2. If the prize is really behind door
2, Monty is equally likely to open door 1 or door 3. If
the prize is really behind door 1, Monty must open
door 3. If the prize is really behind door 3, Monty
must open door 1.
31. A new edition of a very popular textbook will be pub-
lished a year from now. The publisher currently has
2000 copies on hand and is deciding whether to do
another printing before the new edition comes out. The
publisher estimates that demand for the book during
the next year is governed by the probability distribu-
tion in the file P10_31.xlsx. A production run incurs a
fixed cost of $10,000 plus a variable cost of $15 per
book printed. Books are sold for $130 per book. Any
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

demand that cannot be met incurs a penalty cost of
$20 per book, due to loss of goodwill. Up to 500 of
any leftover books can be sold to Barnes and Noble
for $35 per book. The publisher is interested in maxi-
mizing expected profit. The following print-run sizes
are under consideration: 0 (no production run) to
16,000 in increments of 2000. What decision would
you recommend? Use simulation with 1000 replica-
tions. For your optimal decision, the publisher can be
90% certain that the actual profit associated with
remaining sales of the current edition will be between
what two values?
32. A hardware company sells a lot of low-cost, high-
volume products. For one such product, it is equally
likely that annual unit sales will be low or high. If
sales are low (60,000), the company can sell the
product for $10 per unit. If sales are high (100,000),
a competitor will enter and the company will be able
to sell the product for only $8 per unit. The variable
cost per unit has a 25% chance of being $6, a 50%
chance of being $7.50, and a 25% chance of being $9.
Annual fixed costs are $30,000.
a. Use simulation to estimate the company’s expected
annual profit.
b. Find a 95% interval for the company’s annual
profit, that is, an interval such that about 95% of
the actual profits are inside it.
c. Now suppose that annual unit sales, variable cost,
and unit price are equal to their respective expected
values—that is, there is no uncertainty. Determine
the company’s annual profit for this scenario.
d. Can you conclude from the results in parts a and c
that the expected profit from a simulation is equal
to the profit from the scenario where each input
assumes its expected value? Explain.
33. W. L. Brown, a direct marketer of women’s clothing,
must determine how many telephone operators to
schedule during each part of the day. W. L. Brown
estimates that the number of phone calls received each
hour of a typical eight-hour shift can be described by
the probability distribution in the file P10_33.xlsx.
Each operator can handle 15 calls per hour and costs
the company $20 per hour. Each phone call that is not
handled is assumed to cost the company $6 in lost
profit. Considering the options of employing 6, 8, 10,
12, 14, or 16 operators, use simulation to determine
the number of operators that minimizes the expected
hourly cost (labor costs plus lost profits).
34. Assume that all of a company’s job applicants must
take a test, and that the scores on this test are normally
distributed. The selection ratio is the cutoff point used
by the company in its hiring process. For example, a
selection ratio of 20% means that the company will
accept applicants for jobs who rank in the top 20% of
all applicants. If the company chooses a selection ratio
of 20%, the average test score of those selected will be
1.40 standard deviations above average. Use
simulation to verify this fact, proceeding as follows.
a. Show that if the company wants to accept only the
top 20% of all applicants, it should accept
applicants whose test scores are at least 0.842
standard deviation above average. (No simulation
is required here. Just use the appropriate Excel
normal function.)
b. Now generate 1000 test scores from a normal
distribution with mean 0 and standard deviation 1.
The average test score of those selected is the aver-
age of the scores that are at least 0.842. To deter-
mine this, use Excel’s DAVERAGE function. To do
so, put the heading Score in cell A3, generate the
1000 test scores in the range A4:A1003, and name
the range A3:A1003 Data. In cells C3 and C4,
enter the labels Score and 0.842. (The range
C3:C4 is called the criterion range.) Then calculate
the average of all applicants who will be hired
by entering the formula =DAVERAGE(Data,
"Score", C3:C4) in any cell. This average should
be close to the theoretical average, 1.40. This
formula works as follows. Excel finds all observa-
tions in the Data range that satisfy the criterion
described in the range C3:C4 (Score0.842). Then
it averages the values in the Score column (the
second argument of DAVERAGE) corresponding
to these entries. See online help for more about
Excel’s database “D” functions.
c. What information would the company need to
determine an optimal selection ratio? How could it
determine the optimal selection ratio?
35. Lemington’s is trying to determine how many Jean
Hudson dresses to order for the spring season.
Demand for the dresses is assumed to follow a normal
distribution with mean 400 and standard deviation
100. The contract between Jean Hudson and
Lemington’s works as follows. At the beginning of the
season, Lemington’s reserves x units of capacity.
Lemington’s must take delivery for at least 0.8x
dresses and can, if desired, take delivery on up to x
dresses. Each dress sells for $160 and Hudson charges
$50 per dress. If Lemington’s does not take delivery
on all x dresses, it owes Hudson a $5 penalty for each
unit of reserved capacity that is unused. For example,
if Lemington’s orders 450 dresses and demand is for
400 dresses, Lemington’s will receive 400 dresses and
owe Jean 400($50)  50($5). How many units of
capacity should Lemington’s reserve to maximize its
expected profit?
36. Dilbert’s Department Store is trying to determine how
many Hanson T-shirts to order. Currently the shirts
are sold for $21, but at later dates the shirts will be
offered at a 10% discount, then a 20% discount, then
a 40% discount, then a 50% discount, and finally a
614
Chapter 10
Introduction to Simulation Modeling
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

60% discount. Demand at the full price of $21 is
believed to be normally distributed with mean 1800
and standard deviation 360. Demand at various
discounts is assumed to be a multiple of full-price
demand. These multiples, for discounts of 10%, 20%,
40%, 50%, and 60% are, respectively, 0.4, 0.7, 1.1, 2,
and 50. For example, if full-price demand is 2500,
then at a 10% discount customers would be willing to
buy 1000 T-shirts. The unit cost of purchasing T-shirts
depends on the number of T-shirts ordered, as shown
in the file P10_36.xlsx. Use simulation to determine
how many T-shirts the company should order. Model
the problem so that the company first orders some
quantity of T-shirts, then discounts deeper and deeper,
as necessary, to sell all of the shirts.
Skill-Extending Problems
37. The annual return on each of four stocks for each of
the next five years is assumed to follow a normal
distribution, with the mean and standard deviation for
each stock, as well as the correlations between stocks,
listed in the file P10_37.xlsx. You believe that the
stock returns for these stocks in a given year are
correlated, according to the correlation matrix given,
but you believe the returns in different years are
uncorrelated. For example, the returns for stocks 1 and
2 in year 1 have correlation 0.55, but the correlation
between the return of stock 1 in year 1 and the return
of stock 1 in year 2 is 0, and the correlation between
the return of stock 1 in year 1 and the return of stock 2
in year 2 is also 0. The file has the formulas you might
expect for this situation in the range C20:G23. You
can check how the RISKCORRMAT function has
been used in these formulas. Just so that there is an
@RISK output cell, calculate the average of all returns
in cell B25 and designate it as an @RISK output.
(This cell is not really important for the problem, but
it is included because @RISK requires at least one
output cell.)
a. Using the model exactly as it stands, run @RISK
with 1000 iterations. The question is whether
the correlations in the simulated data are close
to what they should be. To check this, go to
@RISK’s Report Settings and check the Input
Data option before you run the simulation. This
gives you all of the simulated returns on a new
sheet. Then calculate correlations for all pairs of
columns in the resulting Inputs Data Report sheet.
(StatTools can be used to create a matrix of all
correlations for the simulated data.) Comment on
whether the correlations are different from what
they should be.
b. Recognizing that this is a common situation
(correlation within years, no correlation across
years), @RISK allows you to model it by adding
a third argument to the RISKCORRMAT function:
the year index in row 19 of the P10_37.xlsx
file. For example, the RISKCORRMAT part of the
formula in cell C20 becomes RISKNORMAL
($B5,$C5, RISKCORRMAT($B$12:$E$15,
$B20,C$19)). Make this change to the formulas in
the range C20:G23, rerun the simulation, and redo
the correlation analysis in part a. Verify that the
correlations between inputs are now more in line
with what they should be.
38. It is surprising (but true) that if 23 people are in the
same room, there is about a 50% chance that at least
two people will have the same birthday. Suppose you
want to estimate the probability that if 30 people are
in the same room, at least two of them will have the
same birthday. You can proceed as follows.
a. Generate random birthdays for 30 different people.
Ignoring the possibility of a leap year, each person
has a 1/365 chance of having a given birthday
(label the days of the year 1 to 365). You can use
the RANDBETWEEN function to generate
birthdays.
b. Once you have generated 30 people’s birthdays,
how can you tell whether at least two people have
the same birthday? One way is to use Excel’s
RANK function. (You can learn how to use this
function in Excel’s online help.) This function
returns the rank of a number relative to a given
group of numbers. In the case of a tie, two numbers
are given the same rank. For example, if the set of
numbers is 4, 3, 2, 5, the RANK function returns
2, 3, 4, 1. (By default, RANK gives 1 to the largest
number.) If the set of numbers is 4, 3, 2, 4, the
RANK function returns 1, 3, 4, 1.
c. After using the RANK function, you should be
able to determine whether at least two of the 30
people have the same birthday. What is the
(estimated) probability that this occurs?
39. United Electric (UE) sells refrigerators for $400 with
a one-year warranty. The warranty works as follows.
If any part of the refrigerator fails during the first year
after purchase, UE replaces the refrigerator for an
average cost of $100. As soon as a replacement is
made, another one-year warranty period begins for the
customer. If a refrigerator fails outside the warranty
period, we assume that the customer immediately
purchases another UE refrigerator. Suppose that the
amount of time a refrigerator lasts follows a normal
distribution with a mean of 1.8 years and a standard
deviation of 0.3 year.
a. Estimate the average profit per year UE earns from
a customer.
b. How could the approach of this problem be used to
determine the optimal warranty period?
40. A Flexible Savings Account (FSA) plan allows you to
put money into an account at the beginning of the
10.7 Conclusion
615
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

calendar year that can be used for medical expenses.
This amount is not subject to federal tax. As you pay
medical expenses during the year, you are reimbursed
by the administrator of the FSA until the money is
exhausted. From that point on, you must pay your
medical expenses out of your own pocket. On the
other hand, if you put more money into your FSA than
the medical expenses you incur, this extra money is
lost to you. Your annual salary is $80,000 and your
federal income tax rate is 30%.
a. Assume that your medical expenses in a year are
normally distributed with mean $2000 and standard
deviation $500. Build an @RISK model in which
the output is the amount of money left to you after
paying taxes, putting money in an FSA, and paying
any extra medical expenses. Experiment with the
amount of money put in the FSA, using a
RISKSIMTABLE function.
b. Rework part a, but this time assume a gamma
distribution for your annual medical expenses. Use
16 and 125 as the two parameters of this
distribution. These imply the same mean and
standard deviation as in part a, but the distribution
of medical expenses is now skewed to the right,
which is probably more realistic. Using simulation,
see whether you should now put more or less
money in an FSA than in the symmetric case in
part a.
41. At the beginning of each week, a machine is in 
one of four conditions: 1  excellent; 2  good; 
3  average; 4  bad. The weekly revenue earned by
a machine in state 1, 2, 3, or 4 is $100, $90, $50, or
$10, respectively. After observing the condition of the
machine at the beginning of the week, the company
has the option, for a cost of $200, of instantaneously
replacing the machine with an excellent machine. The
quality of the machine deteriorates over time, as
shown in the file P10_41.xlsx. Four maintenance
policies are under consideration:
■Policy 1: Never replace a machine.
■Policy 2: Immediately replace a bad machine.
■Policy 3: Immediately replace a bad or average
machine.
■Policy 4: Immediately replace a bad, average, or
good machine.
Simulate each of these policies for 50 weeks (using at
least 250 iterations each) to determine the policy that
maximizes expected weekly profit. Assume that the
machine at the beginning of week 1 is excellent.
42. Simulation can be used to illustrate a number of
results from statistics that are difficult to understand
with nonsimulation arguments. One is the famous
central limit theorem, which says that if you sample
enough values from any population distribution and
then average these values, the resulting average will
be approximately normally distributed. Confirm this
by using @RISK with the following population
distributions (run a separate simulation for each):
(a) discrete with possible values 1 and 2 and
probabilities 0.2 and 0.8; (b) exponential with mean
1 (use the RISKEXPON function with the single
argument 1); (c) triangular with minimum, most likely,
and maximum values equal to 1, 9, and 10. (Note that
each of these distributions is very skewed.) Run each
simulation with 10 values in each average, and run
1000 iterations to simulate 1000 averages. Create a
histogram of the averages to see whether it is indeed
bell-shaped. Then repeat, using 30 values in each
average. Are the histograms based on 10 values
qualitatively different from those based on 30?
43. In statistics we often use observed data to test a
hypothesis about a population or populations. The
basic method uses the observed data to calculate a test
statistic (a single number). If the magnitude of this test
statistic is sufficiently large, the null hypothesis is
rejected in favor of the research hypothesis. As an
example, consider a researcher who believes teenage
girls sleep longer than teenage boys on average. She
collects observations on n  40 randomly selected girls
and n  40 randomly selected boys. (Each observation
is the average sleep time over several nights for a
given person.) The averages are 
hours for
the girls and 
hours for the boys. The
standard deviation of the 40 observations for girls is
s1  0.5 hour; for the boys it is s2  0.7 hour. The
researcher, consulting a statistics textbook, then
calculates the test statistic
Based on the fact that 2.206 is “large,” she claims that
her research hypothesis is confirmed—girls do sleep
longer than boys.
You are skeptical of this claim, so you check it out
by running a simulation. In your simulation you assume
that girls and boys have the same mean and standard
deviation of sleep times in the entire population, say, 7.7
and 0.6. You also assume that the distribution of sleep
times is normal. Then you repeatedly simulate observa-
tions of 40 girls and 40 boys from this distribution and
calculate the test statistic. The question is whether the
observed test statistic, 2.206, is “extreme.” If it is larger
than most or all of the test statistics you simulate, then the
researcher is justified in her claim; otherwise, this large a
statistic could have happened easily by chance, even if
the girls and boys have identical population means. Use
@RISK to see which of these possibilities occurs.
44. A technical note in the discussion of @RISK indicated
that Latin Hypercube sampling is more efficient
than Monte Carlo sampling. This problem allows you
X1 - X2
2s2
1/40 + s2
2/40
=
7.9 - 7.6
10.25/40 + 0.49/40 = 2.206
X2 = 7.6
X1 = 7.9
616
Chapter 10
Introduction to Simulation Modeling
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

to see what this means. The file P10_44.xlsx gets
you started. There is a single output cell, B5. You
can enter any random value in this cell, such as
RISKNORMAL(500,100). There are already @RISK
statistical formulas in rows 9–12 to calculate summary
measures of the output for each of 10 simulations. On
the @RISK ribbon, click on the button to the left of
the “dice” button to bring up the Simulation Settings
dialog box, click on the Sampling tab, and make
sure the Sampling Type is Latin Hypercube. Run 10
simulations with at least 1000 iterations each, and then
paste the results in rows 9–12 as values in rows 17–20.
Next, get back in Simulations Settings and change the
Sampling Type to Monte Carlo, run the 10 simulations
again, and paste the results in rows 9–12 as values into
rows 23–26. For each row, 17–20 and 23–26, summa-
rize the 10 numbers in that row with AVERAGE and
STDEV. What do you find? Why do we say that Latin
Hypercube sampling is more efficient? (Thanks to
Harvey Wagner at University of North Carolina for
suggesting this problem.)
45. We are continually hearing reports on the nightly news
about natural disasters—droughts in Texas, hurricanes
in Florida, floods in California, and so on. We often
hear that one of these was the “worst in over 30 years,”
or some such statement. Are natural disasters getting
worse these days, or does it just appear so? How might
you use simulation to answer this question? Here is
one possible approach. Imagine that there are N areas
of the country (or the world) that tend to have, to some
extent, various types of weather phenomena each year.
For example, hurricanes are always a potential
problem for Florida, and fires are always a potential
problem in southern California. You might model the
severity of the problem for any area in any year by a
normally distributed random number with mean 0 and
standard deviation 1, where negative values are
interpreted as good years and positive values are
interpreted as bad years. (We suggest the normal
distribution, but there is no reason other distributions
couldn’t be used instead.) Then you could simulate
such values for all areas over a period of several years
and keep track, say, of whether any of the areas have
worse conditions in the current year than they have
had in the past several years, where “several” could be
10, 20, 30, or any other number of years you want to
test. What might you keep track of? How might you
interpret your results?
Modeling Problems
46.
You are making several runs of a simulation model,
each with a different value of some decision variable
(such as the order quantity in the Walton calendar
model), to see which decision value achieves the
largest mean profit. Is it possible that one value beats
another simply by random luck? What can you do to
minimize the chance of a “better” value losing out to
a “poorer” value? 
47.
If you want to replicate the results of a simulation
model with Excel functions only, not @RISK, you
can build a data table and let the column input cell be
any blank cell. Explain why this works.
48.
Suppose you simulate a gambling situation where you
place many bets. On each bet, the distribution of your
net winnings (loss if negative) is highly skewed to the
left because there are some possibilities of really large
losses but not much upside potential. Your only simu-
lation output is the average of the results of all the
bets. If you run @RISK with many iterations and look
at the resulting histogram of this output, what will it
look like? Why?
49.
You plan to simulate a portfolio of investments over a
multiyear period, so for each investment (which could
be a particular stock or bond, for example), you need
to simulate the change in its value for each of the
years. How would you simulate these changes in a
realistic way? Would you base it on historical data?
What about correlations? Do you think the changes
for different investments in a particular year would be
correlated? Do you think changes for a particular
investment in different years would be correlated? Do
you think correlations would play a significant role in
your simulation in terms of realism? 
50.
Big Hit Video must determine how many copies of
a new video to purchase. Assume that the company’s
goal is to purchase a number of copies that maximizes
its expected profit from the video during the next year.
Describe how you would use simulation to shed light
on this problem. Assume that each time a video is
rented, it is rented for one day.
51.
Many people who are involved in a small auto acci-
dent do not file a claim because they are afraid their
insurance premiums will be raised. Suppose that City
Farm Insurance has three rates. If you file a claim,
you are moved to the next higher rate. How might you
use simulation to determine whether a particular
claim should be filed?
52.
A building contains 1000 lightbulbs. Each bulb lasts
at most five months. The company maintaining the
building is trying to decide whether it is worthwhile to
practice a “group replacement” policy. Under a group
replacement policy, all bulbs are replaced every T
months (where T is to be determined). Also, bulbs are
replaced when they burn out. Assume that it costs
$0.05 to replace each bulb during a group replacement
and $0.20 to replace each burned-out bulb if it is
replaced individually. How would you use simulation
to determine whether a group replacement policy is
worthwhile?
10.7 Conclusion
617
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

53.
Why is the RISKCORRMAT function necessary?
How does @RISK generate random inputs by default,
that is, when RISKCORRMAT is not used?
54.
Consider the claim that normally distributed inputs in
a simulation model are bound to lead to normally dis-
tributed outputs. Do you agree or disagree with this
claim? Defend your answer.
55.
It is very possible that when you use a correlation
matrix as input to the RISKCORRMAT function in an
@RISK model, the program will inform you that this
is an invalid correlation matrix. Provide an example of
an obviously invalid correlation matrix involving at
least three variables, and explain why it is invalid.
56.
When you use a RISKSIMTABLE function for a
decision variable, such as the order quantity in the
Walton model, explain how this provides a “fair”
comparison across the different values tested.
57.
Consider a situation where there is a cost that is either
incurred or not. It is incurred only if the value of some
random input is less than a specified cutoff value.
Why might a simulation of this situation give a very
different average value of the cost incurred than a
deterministic model that treats the random input as
fixed at its mean? What does this have to do with the
“flaw of averages”?
618
Chapter 10
Introduction to Simulation Modeling
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

C A S E
E
gress, Inc., is a small company that designs,
produces, and sells ski jackets and other coats.
The creative design team has labored for weeks over
its new design for the coming winter season. It is
now time to decide how many ski jackets to produce
in this production run. Because of the lead times
involved, no other production runs will be possible
during the season. Predicting ski jacket sales months
in advance of the selling season can be quite tricky.
Egress has been in operation for only three years,
and its ski jacket designs were quite successful in two
of those years. Based on realized sales from the last
three years, current economic conditions, and
professional judgment, 12 Egress employees have
independently estimated demand for their new
design for the upcoming season.Their estimates are
listed in Table 10.2.
10.1 SKI JACKET PRODUCTION
Case 10.1 Ski Jacket Production
619
Table 10.2 Estimated Demands
14,000
16,000
13,000
8000
14,000
5000
14,000
11,000
15,500
8000
10,500
15,000 
Table 10.3 Monetary Values
Variable production cost per unit (C):
$80
Selling price per unit (S):
$100
Salvage value per unit (V):
$30
Fixed production cost (F):
$100,000
To assist in the decision on the number of units
for the production run, management has gathered
the data in Table 10.3. Note that S is the price Egress
charges retailers.Any ski jackets that do not sell
during the season can be sold by Egress to discoun-
ters for V per jacket.The fixed cost of plant and
equipment is F. This cost is incurred regardless of
the size of the production run.
Questions
1.
Egress management believes that a normal
distribution is a reasonable model for the
unknown demand in the coming year. What
mean and standard deviation should Egress use
for the demand distribution?
2.
Use a spreadsheet model to simulate 1000
possible outcomes for demand in the coming
year. Based on these scenarios, what is the
expected profit if Egress produces Q  7800 ski
jackets? What is the expected profit if Egress
produces Q  12,000 ski jackets? What is the
standard deviation of profit in these two cases?
3.
Based on the same 1000 scenarios, how many
ski jackets should Egress produce to maximize
expected profit? Call this quantity Q.
4.
Should Q equal mean demand or not? Explain.
5.
Create a histogram of profit at the production
level Q. Create a histogram of profit when the
production level Q equals mean demand.What is
the probability of a loss greater than $100,000
in each case? ■
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

C A S E
M
anagement of Ebony, a leading manufacturer of
bath soap, is trying to control its inventory
costs.The weekly cost of holding one unit of soap in
inventory is $30 (one unit is 1000 cases of soap).The
marketing department estimates that weekly demand
averages 120 units, with a standard deviation of 15
units, and is reasonably well modeled by a normal
distribution. If demand exceeds the amount of soap
on hand, those sales are lost—that is, there is no
backlogging of demand.The production department
can produce at one of three levels: 110, 120, or 130
units per week.The cost of changing the production
level from one week to the next is $3000.
Management would like to evaluate the following
production policy. If the current inventory is less
than L  30 units, they will produce 130 units in the
next week. If the current inventory is greater than 
U  80 units, they will produce 110 units in the next
week. Otherwise, Ebony will continue at the previous
week’s production level.
Ebony currently has 60 units of inventory on
hand. Last week’s production level was 120.
Questions
1.
Develop a simulation model for 52 weeks of
operation at Ebony. Graph the inventory of
soap over time.What is the total cost (inventory
cost plus production change cost) for the
52 weeks?
2.
Run the simulation for 500 iterations to
estimate the average 52-week cost with values
of U ranging from 30 to 80 in increments of 10.
Keep L  30 throughout.
3.
Report the sample mean and standard deviation
of the 52-week cost under each policy. Using the
simulated results, is it possible to construct 
valid 95% confidence intervals for the average
52-week cost for each value of U? In any case,
graph the average 52-week cost versus U.What
is the best value of U for L  30?
4.
What other production policies might be useful
to investigate? ■
10.2 EBONY BATH SOAP
620
Chapter 10
Introduction to Simulation Modeling
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

621
Simulation Models
C H A P T E R
MERRILL L       YNCH IMPR       OVES LIQUIDITY RISK
MANA    GEMENT FOR REV      OLVING CREDIT LINES
T
he Merrill Lynch banking group comprises several Merrill Lynch affiliates,
including Merrill Lynch Bank USA (ML Bank USA). (Its parent company is
Bank of America.) ML Bank USA has assets of more than $60 billion (as of
June 30, 2005 when the following article was written, closer to $70 billion by
2010). The bank acts as an intermediary, accepting deposits from Merrill
Lynch retail customers and using the deposits to fund loans and make
investments. One way ML Bank USA uses these assets is to provide revolving
credit lines to institutional and large corporate borrowers. Currently, it has a
portfolio of about $13 billion in credit-line commitments with more than
100 companies.When it makes these commitments, it must be aware of the
liquidity risk, defined as the ability to meet all cash obligations when due. In
other words, if a borrower asks for funds as part of its revolving credit-line
agreement, the bank must have the funds available to honor the request,
typically on the same day the request is made. This liquidity requirement
© AP Photo/Mary Altaffer
11
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

poses a huge risk to the bank. The bank must keep enough cash or liquid investments
(i.e., investments that can be converted to cash quickly) in reserve to honor its
customers’ requests whenever they occur. If the bank knew when, and in what quantities,
these requests would occur, it could manage its cash reserves more prudently, essentially
holding a smaller amount in liquid investments for credit requests and investing the rest
in other more illiquid and profitable investments.
Duffy et al. (2005) discuss their role as members of Merrill Lynch’s Banking Group
and Management Science Group in developing a model to manage the liquidity risk for
ML Bank USA’s revolving credit lines. The revolving credit lines give borrowers access to
a specified amount of cash on demand for short-term funding needs in return for a fee
paid to the bank.The bank also earns an interest rate on advances that compensates it
for the liquidity and other risks it takes. These credit lines are therefore profitable for
the bank, but they are not the borrowers’ primary sources of funding. Customers
typically use these credit lines to retire maturing commercial paper (available at cheaper
interest rates) during the process of rolling it over (i.e., attempting to reissue new
commercial paper notes), and/or when their credit rating falls. The essence of the
problem is that when a customer’s credit ratings (measured by the Moody rating scale,
for example) fall, the customers are less likely to obtain funds from cheaper sources such
as commercial paper, so they then tend to rely on their credit lines from ML Bank USA
and other banks. This poses problems for ML Bank USA. It must honor its commitments
to the borrowers, as spelled out in the credit-line agreements, but customers with low
credit ratings are the ones most likely to default on their loans.
Two other aspects of the problem are important. First, the credit-line agreements
often have a “term-out” option, which allows the borrower to use funds for an additional
period after expiration, typically for one year. A customer that is experiencing financial
difficulties and has seen its credit rating fall is the type most likely to use its term-out
option. Second, movements in credit ratings for customers in the same industry or even
in different industries tend to be positively correlated because they can all be affected by
movements in their industry or the overall economy. This increases the liquidity risk for
ML Bank USA because it increases the chance that poor economic conditions will lead
many customers to request additional credit.
The authors built a rather complex simulation model to track the demand for usage
of these credit facilities. The model simulates monthly credit-line usage for each
customer over a five-year period. During this period, some credit lines are renewed,
some expire and are not renewed, and some customers exercise their term-out options.
The model has several significant features: (1) It models the probabilistic changes in
credit ratings for its customers, where a customer’s credit rating can move from one
level to another level in a given month with specified probabilities; (2) these probabilities
are chosen in such a way that movements in credit ratings are positively correlated
across customers; and (3) expert-system business rules are used to determine whether
the company will renew or terminate expiring lines of credit and whether customers will
exercise their term-out options. For example, a typical rule is that the bank does not
renew a credit line if the borrower’s credit rating is below a certain threshold.
The authors developed a user-friendly Excel-based system to run their model.
It actually invokes and executes the simulation behind the scenes in a simulation package
called Arena. Users of the system can change many of the parameters of the model, such
as the business-rule cutoffs, to customize the simulation.
The model has helped ML Bank USA manage its revolving credit lines.The output of
the model provides a scientific and robust measure of liquidity risk that the bank has
confidence in—and therefore uses.The model has led to two tangible financial benefits.
First, the model reduced the bank’s liquidity requirement from 50% to 20% of
outstanding commitments, thus freeing up about $4 billion of liquidity for other
622
Chapter 11
Simulation Models
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

11.1 INTRODUCTION
In the previous chapter we introduced most of the important concepts for developing and
analyzing spreadsheet simulation models. We also discussed many of the features available
in the powerful simulation add-in, @RISK, that you receive with this book. Now we apply
the tools to a wide variety of problems that can be analyzed with simulation. For conve-
nience, we group the applications into four general areas: (1) operations models, (2) finan-
cial models, (3) marketing models, and (4) games of chance. The only overriding theme in
this chapter is that simulation models can yield important insights in all of these areas. You
do not need to cover all of the models in this chapter or cover them in any particular order.
You can cover the ones of most interest to you in practically any order.
11.2 OPERATIONS MODELS
Whether we are discussing the operations of a manufacturing or a service company, there
is likely to be uncertainty that can be modeled with simulation. In this section we look at
examples of bidding for a government contract (uncertainty in the bids by competitors),
warranty costs (uncertainty in the time until failure of an appliance), and drug production
(uncertainty in the yield and timing).
11.2.1 Bidding for Contracts
In situations where a company must bid against competitors, simulation can often be used
to determine the company’s optimal bid. Usually the company does not know what its
competitors will bid, but it might have an idea about the range of the bids its competitors
will choose. In this section we show how to use simulation to determine a bid that maxi-
mizes the company’s expected profit.
profitable illiquid investments. Second, during the first 21 months after the system
was implemented, the bank’s portfolio expanded from $8 billion in commitments and
80 customers to $13 billion and more than 100 customers.The bank continues to
use the model for its long-range planning. ■
E X A M P L E
11.1 BIDDING FOR A GOVERNMENT CONTRACT
T
he Miller Construction Company must decide whether to make a bid on a construction
project. Miller believes it will cost the company $10,000 to complete the project (if it
wins the contract), and it will cost $350 to prepare a bid. However, there is uncertainty
about each of these. Upon further reflection, Miller assesses that the cost to complete the
project has a triangular distribution with minimum, most likely, and maximum values
$9000, $10,000, and $15,000. Similarly, Miller assesses that the cost to prepare a bid has a
triangular distribution with parameters $300, $350, and $500. (Note the skewness in these
distributions. Miller recognizes that cost overruns are much more likely than cost under-
runs.) Four potential competitors are going to bid against Miller. The lowest bid wins the
contract, and the winner is then given the winning bid amount to complete the project.
Based on past history, Miller believes that each potential competitor will bid, indepen-
dently of the others, with probability 0.5. Miller also believes that each competitor’s bid
11.2 Operations Models
623
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

will be a multiple of its (Miller’s) most likely cost to complete the project, where this mul-
tiple has a triangular distribution with minimum, most likely, and maximum values 0.9,
1.3, and 1.8, respectively. If Miller decides to prepare a bid, its bid amount will be a multi-
ple of $500 in the range $10,500 to $15,000. The company wants to use simulation to
determine which strategy to use to maximize its expected profit.
Objective
To simulate the profit to Miller from any particular bid, and to see which bid
amount is best.
WHERE DO THE NUMBERS COME FROM?
We already discussed this type of bidding problem in Chapter 9. The new data required
here are the parameters of the distributions of Miller’s costs, those of the competitors’
bids, and the probability that a given competitor will place a bid. Triangular distributions
are chosen for simplicity, although Miller could try other types of distributions. The para-
meters of these distributions are probably educated guesses, possibly based on previous
contracts and bidding experience against these same competitors. The probability that a
given competitor will place a bid can be estimated from these same competitors’ bidding
history.
Solution
The logic is straightforward. You first simulate the number of competitors who will bid
and then simulate their bids. Then for any bid Miller makes, you see whether Miller wins
the contract, and if so, what its profit is.
DEVELOPING THE SIMULATION MODEL
The simulation model appears in Figure 11.1. (See the file Contract Bidding.xlsx.) It can
be developed with the following steps. (Note that this model does not check the possibil-
ity of Miller not bidding at all. But this case is easy. If Miller opts not to bid, the profit is
a certain $0.)
1
Inputs. Enter the inputs in the blue cells.
2
Miller’s bid. You can test all of Miller’s possible bids simultaneously with the
RISKSIMTABLE function. To set up for this, enter the formula
RISKSIMTABLE(D16:M16)
in cell B16. As with all uses of this function, the spreadsheet shows the simulated values
for the first bid, $10,500. However, when you run the simulation, you see outputs for all of
the bids.
3
Miller’s costs. Generate Miller’s cost to prepare a bid in cell B19 with the formula
RISKTRIANG(B5,C5,D5)
Then copy this to cell B20 to generate Miller’s cost to complete the project.
4
Competitors and their bids. First, generate the random number of competitors who
bid. This has a binomial distribution with four trials and probability of “success” equal to
0.5 for each trial, so enter the formula
RISKBINOMIAL(B8,B9)
in cell B21. Then generate random bids for the competitors who bid in row 23 by entering
the formula
624
Chapter 11
Simulation Models
Recall that the
RISKSIMTABLE
function allows you to
run a separate
simulation for each
value in its list.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

IF(B22$B$21,RISKTRIANG($B$12,$B$13,$B$14)*$C$6,"")
in cell B23 and copying across. This generates a random bid for all competitors who bid,
and it enters a blank for those who don’t. (Remember that the random value is the multiple
of Miller’s most likely cost to complete the project.) Calculate the smallest of these 
(if there are any) in cell B24 with the formula
IF(B211,MIN(B23:E23),"")
Of course, Miller will not see these other bids until it has submitted its own bid.
5
Win contract? See whether Miller wins the bid by entering the formula
IF(OR(B16B24,B210),1,0)
in cell B26. Here, 1 means that Miller wins the bid, and 0 means a competitor wins the bid.
Of course, if there are no competing bids, Miller wins for sure. Then designate this cell as
an @RISK output cell. Recall that to designate a cell as an @RISK output cell, you select
the cell and then click on the Add Output button on @RISK’s ribbon. You can then label
this output appropriately. We used the label Wins Bid.
6
Miller’s profit. If Miller submits a bid, the bid cost is lost for sure. Beyond that, the
profit to Miller is the bid amount minus the cost of completing the project if the bid is won.
Otherwise, Miller makes nothing. So enter the formula
IF(B261,B16-B20,0)–B19
in cell B27. Then designate this cell as an additional @RISK output cell. (We named it
Profit.)
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
M
L
K
J
I
H
G
F
E
D
C
B
A
Bidding for a contract
Inputs
Miller's costs, triangular distributed
Min
Most likely
Max
Cost to prepare a 
0
0
5
$
0
5
3
$
0
0
3
$
dib
Cost to complete project
$9,000
$10,000
$15,000
Number of potenal competors
4
Probability a given competor bids
0.5
Parameters of triangular distribuons for each competor's bid (expressed as mulple of Miller's most likely cost to complete project)
9.0
ni
M
Most 
3.1
yle
kil
8.1
x
a
M
Possible bids for Miller
Miller's 
0
0
0,5
1
$
0
0
5,4
1
$
0
0
0,4
1
$
0
0
5,3
1
$
0
0
0,3
1
$
0
0
5,2
1
$
0
0
0,2
1
$
0
0
5,1
1
$
0
0
0,1
1
$
0
0
5,0
1
$
0
0
5,0
1
$
dib
Simulaon
Miller's cost to prepare a bid
$365
Miller's cost to complete project
$10,332
Number of compeng bids
2
Competor 
4
3
2
1
x
e
d
ni
Competors' 
4
5
3,3
1
$
0
3
1,3
1
$
s
dib
Minimum competor bid
$13,354
Miller wins bid? (1 if yes, 0 if no)
1
Miller's proﬁt
-$197
Figure 11.1
Bidding Simulation Model
11.2 Operations Models
625
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Running the Simulation
Set the number of iterations to 1000, and set the number of simulations to 10 because there
are 10 bid amounts Miller wants to test.
Discussion of the Simulation Results
The summary results appear in Figure 11.2. For each simulation—that is, each bid
amount—there are two outputs: 1 or 0 to indicate whether Miller wins the contract and
Miller’s profit. The only interesting results for the 0–1 output are in the Mean column,
which shows the fraction of iterations that resulted in 1s. So you can see, for example, that
if Miller bids $12,000 (simulation #4), the probability of winning the bid is estimated to be
0.581. This probability clearly decreases as Miller’s bid increases.
626
Chapter 11
Simulation Models
Figure 11.2
Summary Results for Bidding Simulation
In terms of net profit, if you concentrate only on the Mean column, a bid amount of
$13,000 (simulation #6) is the best. But as the other numbers in this figure indicate, the
mean doesn’t tell the whole story. For example, if Miller bids $13,000, it could win the bid
but still lose a considerable amount of money because of cost overruns. The histogram of
profit in Figure 11.3 indicates this more clearly. It shows that in spite of the positive mean,
most outcomes are negative.
So what should Miller do? If it doesn’t bid at all, its profit is a certain $0. If Miller is
an expected profit maximizer, then the fact that several of the means in Figure 11.2 are pos-
itive indicates that bidding is better than not bidding, with a bid of $13,000 being the best
bid. However, potential cost overruns and the corresponding losses are certainly a concern.
Depending on Miller’s degree of risk aversion, the company might decide to (1) not bid at
all, or (2) bid higher than $13,000 to minimize its worse loss. Still, we would caution
Miller not to be too conservative. Rather than focusing on the Min (worst case) column in
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Figure 11.2, we would suggest focusing on the 5% column. This shows nearly how bad
things could get (5% of the time it would be worse than this), and this 5th percentile
remains fairly constant for higher bids. ■
Figure 11.3
Histogram of Profit
with $13,000 Bid
11.2.2 Warranty Costs
When you buy a new product, it usually carries a warranty. A typical warranty might
state that if the product fails within a certain period such as one year, you will receive a
new product at no cost, and it will carry the same warranty. However, if the product fails
after the warranty period, you have to bear the cost of replacing the product. Due to
random lifetimes of products, we need a way to estimate the warranty costs (to the
manufacturer) of a product. The next example illustrates how this can be accomplished
with simulation.
E X A M P L E
11.2 WARRANTY COSTS FOR A CAMERA
T
he Yakkon Company sells a popular camera for $400. This camera carries a warranty
such that if the camera fails within 1.5 years, the company gives the customer a new
camera for free. If the camera fails after 1.5 years, the warranty is no longer in effect.
Every replacement camera carries exactly the same warranty as the original camera, and
the cost to the company of supplying a new camera is always $225. Use simulation to esti-
mate, for a given sale, the number of replacements under warranty and the NPV of profit
from the sale, using a discount rate of 8%.
Objective
To use simulation to estimate the number of replacements under warranty and
the total NPV of profit from a given sale.
WHERE DO THE NUMBERS COME FROM?
The warranty information is a policy decision made by the company. The hardest input to
estimate is the probability distribution of the lifetime of the product. We discuss this next.
11.2 Operations Models
627
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Solution
The only randomness in this problem concerns the time until failure of a new camera.
Yakkon could estimate the distribution of time until failure from historical data. This
would probably indicate a right-skewed distribution, as shown in Figure 11.4. If you look
through the list of distributions available in @RISK under Define Distributions, you will
see several with this same basic shape. The one shown in Figure 11.4 is a commonly used
distribution called the gamma distribution. We will use a gamma distribution in this exam-
ple, although other choices such as the triangular are certainly possible.
628
Chapter 11
Simulation Models
The gamma
distribution is a
popular distribution,
especially when you
want a right-skewed
distribution of a
nonnegative quantity.
You can learn about
distributions from
@RISK’s Define
Distribution window.
Figure 11.4
Right-Skewed
Gamma
Distribution
Selecting a Gamma Distribution
The gamma distribution is characterized by two parameters,  and . These determine its
shape and location. It can be shown that the mean and standard deviation are    and

. Alternatively, for any desired values of the mean and standard deviation, these 
= 1ab
equations can be solved for  and , which leads to   2/2 and   2/. So, for
example, if you want a gamma distribution with mean 2.5 and standard deviation 1 (which
in this example would be based on camera lifetime data from the past), you should choose
  2.52/12  6.25 and   12/2.5  0.4. These are the values shown in Figure 11.4 and
the ones used for this example. The values in the figure (from @RISK) imply that the prob-
ability of failure before 1.5 years is about 0.15, so that the probability of failure out of war-
ranty is about 0.85.
DEVELOPING THE SIMULATION MODEL
The simulation model appears in Figure 11.5. (See the file Warranty Costs.xlsx.) The
particular random numbers in this figure indicate an example (a rather unusual one)
where there are two failures within warranty. However, because the lifetime of the second
replacement (cell D17) is greater than 1.5, the company incurs only two replacement
costs, as shown in cells B19 and C19. The model can be developed with the following
steps.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

1
Inputs. Enter the inputs in the blue cells.
2
Parameters of gamma distribution. As discussed previously, if you enter a desired
mean and standard deviation (in cells B5 and B6), you have to calculate the parameters of
the gamma distribution. Do this by entering the formulas
B5^2/B6^2
and
B6^2/B5
in cells B7 and B8.
3
Lifetimes and times of failures. Generate at most five lifetimes and corresponding
times of failures. (Why only five? You could generate more, but it is extremely unlikely
that this same customer would experience more than five failures within warranty, so
five suffices.) As soon as a lifetime is greater than 1.5, the warranty period, no further
lifetimes are required; instead, “NA” can be recorded in row 17. With this in mind, enter
the formulas
RISKGAMMA(B7,B8)
IF(B17B10,RISKGAMMA(B7,B8),"NA")
and
IF(C17"NA","NA",IF(C17$B$10,RISKGAMMA($B$7,$B$8), "NA"))
in cells B17, C17, and D17, and copy the latter formula to cells E17 and F17. These for-
mulas guarantee that once “NA” is recorded in a cell, all cells to its right will also contain
“NA.” To get the actual times of failures, relative to time 0 when the customer originally
purchases the camera, enter the formulas
B17
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
F
E
D
C
B
A
Warranty costs for camera
Inputs
Parameters of me to failure distribuon of any new camera (Gamma)
Desired 
5.2
n
a
e
m
Desired 
1
v
e
d
ts
Implied 
0
5
2.6
a
h
pla
Implied 
0
0
4.0
a
t
e
b
Warranty 
5.1
d
oir
e
p
Cost of new camera (to customer)
$400
Replacement cost (to company)
$225
Discount 
%
8
e
t
a
r
Simulaon of new camera and its replacements (if any)
5
4
3
2
1
a
r
e
m
a
C
A
N
A
N
4
7
6.2
0
5
8.0
0
3
3.1
e
m
it
e
fiL
Time of 
A
N
A
N
4
5
8.4
0
8
1.2
0
3
3.1
e
r
uliaf
Cost to 
0
0
0
5
2
2
5
2
2
y
n
a
p
m
o
c
Discounted 
0
0.0
0
0.0
0
0.0
5
2.0
9
1
1
1.3
0
2
ts
o
c
Failures within 
2
yt
n
a
rr
a
w
NPV of proﬁt from customer
($218.35)
Figure 11.5
Warranty
Simulation Model
11.2 Operations Models
629
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

and
IF(C17"NA","NA",B18	C17)
in cells B18 and C18, and copy the latter across row 18. These values will be used for the
NPV calculation because this requires the exact timing of cash flows.
@RISK Function: RISKGAMMA
To generate a random number from the gamma distribution, use the RISKGAMMA function
in the form RISKGAMMA(alpha,beta). The mean and standard deviation of this distrib-
ution are    and . 
Equivalently,   2/2 and   2/.
4
Costs and discounted costs.
In row 19, enter the replacement cost ($185) or 0,
depending on whether a failure occurs within warranty, and in row 20 discount these costs
back to time 0, using the failure times in row 18. To do this, enter the formulas
IF(B17B10,B12,0)
and
IF(C17"NA",0,IF(C17$B$10,$B$12,0))
in cells B19 and C19, and copy this latter formula across row 19. Then enter the formula
IF(B190,B19/(1	$B$13)^B18,0)
in cell B20 and copy it across row 20. This formula uses the well-known fact that the
present value of a cash flow at time t is the cash flow multiplied by 1/(1 	 r)t, where r is
the discount rate.
5
Outputs. Calculate two outputs, the number of failures within warranty and the NPV
of profit, with the formulas
COUNTIF(B19:F19,"0")
and
B11–B12–SUM(B20:F20)
in cells B22 and B23. Then designate these two cells as @RISK output cells. Note that the
NPV is the margin from the sale (undiscounted) minus the sum of the discounted costs
from replacements under warranty.
Running the Simulation
The @RISK setup is typical. Run 1000 iterations of a single simulation (because there is
no RISKSIMTABLE function).
Discussion of the Simulation Results
The @RISK summary statistics and histograms for the two outputs appear in Figures 11.6,
11.7, and 11.8. They show a fairly clear picture. About 85% of the time, there are no fail-
ures under warranty and the company makes a profit of $175, the margin from the camera
sale. However, there is about a 12.9% chance of exactly one failure under warranty, in
which case the company’s NPV of profit will be an approximate $50 loss (before dis-
counting). Additionally, there is about a 2.1% chance that there will be even more failures
under warranty, in which case the loss will be even greater. Note that in our 1000 iterations,
the maximum number of failures under warranty was three, and the maximum net loss was
$416.44. On average, the NPV of profit was $138.43.
These results indicate that Yakkon is not suffering terribly from warranty costs. However,
there are several ways the company could decrease the effects of warranty costs. First, it could
increase the price of the camera. Second, it could decrease the warranty period, say, from 1.5
years to 1 year. Third, it could change the terms of the warranty. For example, it could stipulate
s = 1ab
630
Chapter 11
Simulation Models
Excel’s NPV function
can be used only for
cash flows that occur
at the ends of the
respective years.
Otherwise, you have 
to discount cash 
flows manually.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Figure 11.8
Histogram of
NPV of Profit
Figure 11.7
Histogram of
Number of Failures
Figure 11.6
Summary Statistics for Warranty Model
11.2 Operations Models
631
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

that if the camera fails within a year, the customer gets a new camera for free, whereas if the
time to failure is between 1 and 1.5 years, the customer pays some pro rata share of the
replacement cost. Finally, it could try to sell the customer an extended warranty—at a hefty
price. We ask you to explore these possibilities in the problems. ■
11.2.3 Drug Production with Uncertain Yield
In many manufacturing settings, products are produced in batches, and the usable yields
from these batches are uncertain. This is particularly true in the drug industry. The follow-
ing example illustrates how a drug manufacturer can take this uncertainty into account
when planning production.
632
Chapter 11
Simulation Models
E X A M P L E
11.3 TRYING TO MEET AN ORDER DUE DATE AT WOZAC
T
he Wozac Company is a drug manufacturer. Wozac has recently accepted an order from
its best customer for 8000 ounces of a new miracle drug, and Wozac wants to plan its
production schedule to meet the customer’s promised delivery date of December 1, 2010.
There are three sources of uncertainty that make planning difficult. First, the drug must be
produced in batches, and there is uncertainty in the time required to produce a batch, which
could be anywhere from 5 to 11 days. This uncertainty is described by the discrete distribu-
tion in Table 11.1. Second, the yield (usable quantity) from any batch is uncertain. Based on
historical data, Wozac believes the yield can be modeled by a triangular distribution with
minimum, most likely, and maximum values equal to 600, 1000, and 1100 ounces, respec-
tively. Third, all batches must go through a rigorous inspection once they are completed.
The probability that a typical batch passes inspection is only 0.8. With probability 0.2, the
batch fails inspection, and none of it can be used to help fill the order. Wozac wants to use
simulation to help decide how many days prior to the due date it should begin production.
Table 11.1 Distribution of Days to Complete a Batch
Days
Probability
5
0.05
6
0.10
7
0.20
8
0.30
9
0.20
10
0.10
11
0.05
Objective
To use simulation to determine when Wozac should begin production for this
order so that there is a high probability of completing it by the due date.
WHERE DO THE NUMBERS COME FROM?
The important inputs here are the probability distributions of the time to produce a batch,
the yield from a batch, and the inspection result. The probabilities we have assumed would
undoubtedly be based on previous production data. For example, the company might have
observed that about 80% of all batches in the past passed inspection. Of course, a discrete
distribution is natural for the number of days to produce a batch, and a continuous distrib-
ution is appropriate for the yield from a batch.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Solution
The idea is to simulate successive batches—their days to complete, their yields, and
whether they pass inspection—and keep a running total of the usable ounces obtained so
far. IF functions can then be used to check whether the order is complete or another batch
is required. You need to simulate only as many as batches as are required to meet the order,
and you should keep track of the days required to produce all of these batches. In this way
you can “back up” to see when production must begin to meet the due date. For example,
if the simulation indicates that the order takes 96 days to complete, then production must
begin on August 27, 2010, 96 days before the due date. (For simplicity, you can assume
that production occurs seven days a week.)
DEVELOPING THE SIMULATION MODEL
The completed model appears in Figure 11.9. (See the file Drug Production.xlsx.) It can
be developed as follows.
40
16
8/15/10
0.845
40
16
8/15/10
0 845
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
L
K
J
I
H
G
F
E
D
C
B
A
Planning producon of a drug
Input secon
Amount required (ounces)
8000
Promised delivery date
12/01/10
Distribuon of days needed to produce a batch (discrete)
Days
Probability
5
0.05
6
0.10
7
0.20
8
0.30
9
0.20
10
0.10
11
0.05
Distribuon of yield (ounces) from each batch (triangular)
Min
Most likely
Max
600
1000
1100
Probability of passing inspecon
0.8
Simulaon model
Summary measures
Batch
Days
Yield
Pass?
CumYield
Enough?
Batches required
12
t
o
N
7.5
0
8
s
e
Y
7.5
0
8
7
1
 yet
Days to complete
92
t
o
N
3.9
1
7
1
s
e
Y
6.3
1
9
6
2
 yet
Day to start
8/31/10
t
o
N
1.8
5
6
2
s
e
Y
9.8
3
9
6
3
 yet
t
o
N
4.1
0
6
3
s
e
Y
3.3
4
9
9
4
 yet
@Risk summary outputs
t
o
N
5.4
4
3
4
s
e
Y
1.3
4
7
8
5
 yet
Max batches reqd
20
t
o
N
5.4
4
3
4
o
N
7.2
7
9
8
6
 yet
t
o
N
5.4
4
0
5
s
e
Y
0.0
0
7
8
7
 yet
Avg days reqd
94
8/29/10
t
o
N
8.8
0
0
6
s
e
Y
4.4
6
9
8
8
 yet
Min days reqd
59
10/3/10
9
10
942.5
Yes
6951.3
Not yet
Max days reqd
160
6/24/10
10
6
1030.5
No
6951.3
Not yet
5th perc days reqd
72
9/20/10
11
9
766.9
Yes
7718.2
Not yet
95th perc days reqd
121
8/2/10
12
7
882.0
Yes
8600.3
Yes
13
Probability of meeng due date for several starng dates
14
7/15/10
0.991
15
8/1/10
0.954
  
 
 
 
 
 
  
 
  
  
 
 
 
 
 
 
  
  
 
  
 
   
 
 
 
 
 
 
 
 
41
42
43
44
45
46
47
48
49
.
17
9/1/10
0.469
18
9/15/10
0.120
19
20
21
22
23
24
25
Assumpons:
The drug is produced in similar-sized batches, although the yield in each
batch is random. Also, the number of days to produce a batch is
random. Each batch is inspected, and if it doesn't pass in specon, none
of that batch can be used.
Figure 11.9
Drug Production Simulation Model
11.2 Operations Models
633
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

1
Inputs. Enter all of the inputs in the blue cells.
2
Batch indexes. You do not know ahead of time how many batches will be required to
fill the order. There should be enough rows in the simulation to cover the worst case that is
likely to occur. After some experimentation it is apparent that 25 batches are almost surely
enough. Therefore, enter the batch indexes 1 through 25 in column A of the simulation sec-
tion. (If 25 were not enough, you could always add more rows.) The idea, then, is to fill the
entire range B25:F49 with formulas. However, you can use appropriate IF functions in
these formulas so that if enough has already been produced to fill the order, blanks are
inserted in the remaining cells. For example, the scenario shown in Figure 11.9 is one
where 12 batches were required, so blanks appear below row 36.
3
Days for batches. Simulate the days required for batches in column B. To do this,
enter the formulas
RISKDISCRETE(B9:B15,C9:C15)
and
IF(OR(F25"Yes",F25""),"",RISKDISCRETE($B$9:$B$15,$C$9:$C$15))
in cell B25 and B26, and copy the latter formula down to cell B49. Note how the IF func-
tion enters a blank in this cell if either of two conditions is true: the order was just com-
pleted in the previous batch or it has been completed for some time. Similar logic appears
in later formulas.
4
Batch yields. Simulate the batch yields in column C. To do this, enter the formulas
RISKTRIANG(B19,C19,D19)
and
IF(OR(F25"Yes",F25""),"",RISKTRIANG($B$19,$C$19,$D$19))
in cells C25 and C26, and copy the latter formula down to cell C49.
5
Pass inspection? Check whether each batch passes inspection with the formulas
IF(RAND()B21,"Yes","No")
and
IF(OR(F25"Yes",F25""),"",IF(RAND()$B$21,"Yes","No"))
in cells D25 and D26, and copy the latter formula down to cell D49. Note that you could
use @RISK’s RISKUNIFORM(0,1) function instead of RAND(), but there is no real
advantage to doing so. They are essentially equivalent. (Besides, the academic version of
@RISK imposes an upper limit of 100 @RISK input functions per model, so it is often a
good idea to substitute built-in Excel functions when possible.)
6
Order filled? To keep track of the cumulative usable production and whether the
order has been filled in columns E and F, first enter the formulas
IF(D25"Yes",C25,0)
and
IF(E25B4,"Yes","Not yet ")
in cells E25 and F25 for batch 1. Then enter the general formulas
IF(OR(F25"Yes",F25""),"",IF(D26"Yes",C26	E25,E25))
and
634
Chapter 11
Simulation Models
You can use Excel’s
RAND function inside
an IF function to
simulate whether 
some event occurs.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

IF(OR(F25"Yes",F25""),"",IF(E26$B$4, "Yes","Not yet "))
in cells E26 and F26, and copy them down to row 49. Note that the entry in column F is
“Not yet” if the order is not yet complete. In the row that completes the order, it changes to
“Yes,” and then it is blank in succeeding rows.
7
Summary measures. Calculate the batches and days required in cells I24 and I25
with the formulas
COUNT(B25:B49)
and
SUM(B25:B49)
These are the two cells used as output cells for @RISK, so designate them as such. Also,
calculate the day the order should be started to just meet the due date in cell I26 with the
formula
B5–I25
This formula uses date subtraction to find an elapsed time. (Again, the assumption is that
production occurs every day of the week.)
This completes the simulation model development. The other entries in columns H
through J are explained shortly.
Date subtraction in
Excel allows you to
calculate the number
of days between two
given dates.
FUNDAMENTAL INSIGHT
Dealing with Uncertain Timing
Many simulations that model a pr ocess over multiple
time periods m ust deal with uncer
tain timing of
events, such as when the man ufacturing of an or der
will finish,which year sales of a new product will begin,
and many others. Essentially, the spreadsheet model
must generate random n umbers that determine the
timing and then pla y out the e vents.This can require
tricky IF functions and possibl
y other functions.
However, the har d w ork often in volves getting the
logic cor rect f or the first period or tw
o. Then this
logic can be copied do wn for the other periods. In
other words, some time spent on developing the first
row or two can result in a very powerful model.
Running the Simulation
Set the number of iterations to 1000 and the number of simulations to 1, and then run the
simulation as usual.
Discussion of the Simulation Results
After running the simulation, you can obtain the histograms of the number of batches
required and the number of days required in Figures 11.10 and 11.11.
How should Wozac use this information? The key questions are (1) how many batches
will be required and (2) when production should start. To answer these questions, it is help-
ful to use several of @RISK’s statistical functions. Recall that these functions can be
entered directly into the Excel model worksheet. (Also, recall that they provide useful
information only after the simulation has been run.) These functions provide no new infor-
mation you don’t already have from other @RISK windows, but they allow you to see (and
manipulate) this information directly in the spreadsheet.
For the first question, enter the formula
RISKMAX(I24)
11.2 Operations Models
635
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

in cell I29. (Refer to Figure 11.9.) It shows that the worst case from the 1000 iterations, in
terms of batches required, is 20 batches. (If this maximum were 25, you would add more
rows to the simulation model and run the simulation again.)
You can answer the second question in two ways. First, you can calculate summary
measures for days required and then back up from the due date. This is done in the range
I31:J35. The formulas in column I are
INT(RISKMEAN(I25))
RISKMIN(I25)
636
Chapter 11
Simulation Models
Figure 11.10
Histogram of
Batches Required
Figure 11.11
Histogram of
Days Required
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

RISKMAX(I25)
RISKPERCENTILE(I25,0.05)
and
RISKPERCENTILE(I25,0.95)
(The first uses the INT function to produce an integer.) You can then subtract each of
these from the due date to obtain the potential starting dates in column J. Wozac should
realize the pros and cons of these starting dates. For example, if the company wants to
be 95% sure of meeting the due date, it should start production on August 2. In contrast,
if Wozac starts production on September 20, there is only a 5% chance of meeting the
due date.
Alternatively, you can get a more direct answer to the question by using @RISK’s
RISKTARGET function. This allows you to find the probability of meeting the due date
for any starting date, such as the trial dates in the range H38:H42. To do it, enter the
formula
RISKTARGET(I25,$B$4–H38)
in cell I38 and copy it down. This function returns the fraction of iterations where the (ran-
dom) value in the first argument is less than or equal to the (fixed) value in the second
argument. For example, you can see that 84.5% of the iterations have a value of days
required less than or equal to 108, the number of days from August 15 to the due date.
What is our recommendation to Wozac? We suggest going with the 95th percentile—
begin production on August 2. Then there is only a 5% chance of failing to meet the due
date. But the table in the range H38:I42 also provides useful information. For each poten-
tial starting date, Wozac can see the probability of meeting the due date.
■
11.2.4 Deming’s Funnel Experiment
Edwards Deming was an American statistician whose views on quality management revo-
lutionized the way companies do business across the world. Deming has been given much
of the credit for Japan’s spectacular post–World War II economic recovery. He traveled
around the United States giving a famous four-day seminar on quality management. After
attending his seminar, many U.S. companies (including Xerox, GM, and Ford) reorganized
their businesses to reflect Deming’s management philosophy as embraced in his famous
14 points. For example, GM’s Saturn plant is run almost completely in accordance with
Deming’s 14 points. We strongly recommend Deming’s book Out of the Crisis (1986). It
contains some great insights.
An important component of Deming’s seminar was his famous funnel experiment.
The funnel experiment is designed to show how businesses often greatly overadjust
“stable” processes. We illustrate how it works in the following example.
Using @RISK
summary functions
such as RISKMEAN,
RISKPERCENTILE,
and others enables 
you to capture
simulation results 
in the same work-
sheet as the simu-
lation model.These
functions do not
provide relevant 
results until the
simulation is run.
11.2 Operations Models
637
E X A M P L E
11.4 TAMPERING WITH A STABLE PROCESS
S
uppose that you are in the business of drilling a tiny hole in the exact center of a square
piece of wood. In the past, the holes you have drilled were, on average, in the center of
the wood, and the x- and y-coordinates each had a standard deviation of 0.1 inch. Also, the
drilling process has been stable—that is, the holes average being in the center of the
square, and the deviations from the center of the square (measured in both the x- and
y-coordinates) follow a normal distribution with mean 0 and standard deviation 0.1 inch.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

638
Chapter 11
Simulation Models
This means, for example, that the x-coordinate is within 0.1 inch of the center for 68%
of the holes, the x-coordinate is within 0.2 inch of the center for 95% of the holes, and
the x-coordinate is within 0.3 inch of the center for 99.7% of the holes. This describes the
inherent variability in the drilling process. Unless you change the hole-drilling process,
you must accept this amount of variation.
Now suppose that you drill a hole and its x- and y-coordinates are x  0.1 and y  0
[where the center of the square has coordinates (0, 0)]. A natural reaction is to reduce the
x-setting of the drill by 0.1 to correct for the fact that the x-coordinate was too high. Then
if the next hole has coordinates x  
0.2 and y  0.1, you might try to increase the
x-coordinate by 0.2 and decrease the y-coordinate by 0.1. Deming’s funnel experiment shows
that this method of continually readjusting a stable process—he calls it “tampering”—actually
increases the variability of the coordinates of the position where the hole is drilled. In other
words, tampering generally makes a process worse!
To illustrate the effects of tampering, Deming placed a funnel above a target on the
floor and dropped small balls through the funnel in an attempt to hit the target. As he
demonstrated, many balls did not hit the target. His goal, therefore, was to make the balls
fall as close to the target as possible. Deming proposed four rules for adjusting the posi-
tioning of the funnel.
■
Rule 1. Never move the funnel. (Don’t tamper.)
■
Rule 2. After each ball is dropped, move the funnel—relative to its previous
position—to compensate for any error. To illustrate, suppose the target has coordi-
nates (0, 0), and the funnel begins directly over the target. If the ball lands at
(0.5, 0.1) on the first drop, we compensate by repositioning the funnel at (0 
 0.5,
0 
 0.1)  (
0.5, 
0.1). If the second drop has coordinates (1, 
2), we then reposi-
tion the funnel at (
0.5 
 1, 
0.1 
 (
2))  (
1.5, 1.9).
■
Rule 3. Move the funnel—relative to its original position at (0, 0)—to compensate for
any error. For example, if the ball lands at (0.5, 0.1) on the first drop, we compensate
by repositioning the funnel at (0 
 0.5, 0 
 0.1)  (
0.5, 
1). If the second drop has
coordinates (1, –2), we then reposition the funnel at (0 
 1, 0 
 (
2))  (
1, 2).
■
Rule 4. Always reposition the funnel directly over the last drop. Therefore, if the first
ball lands at (0.5, 1), we position the funnel at (0.5, 1). If the second drop has coordi-
nates (1, 2), we position the funnel at (1, 2). (This rule might be followed, for exam-
ple, by an automobile manufacturer’s painting department. With each new batch of
paint, they attempt to match the color of the previous batch—regardless of whether
the previous color was correct.)
Do you believe any of these latter three rules outperform rule 1, the “leave it alone”
rule? Is so, read on—you might be surprised.
Objective
To use simulation to see the effect of tampering with a stable process, as
opposed to leaving it alone.
WHERE DO THE NUMBERS COME FROM?
Obviously, we made up the numbers for this experiment (the standard deviations).
However, any stable manufacturing process has parameters that can be measured by
watching the process over time. In fact, this is exactly what control charts, a staple of most
manufacturing companies, are designed to do.
Solution
To see how these rules work, we assume that the x-coordinate on each drop is normally dis-
tributed with mean equal to the x-coordinate of the funnel position and standard deviation
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

of 1. A similar statement holds for the y-coordinate. Also, we assume that the x- and y-
coordinates are selected independently of one another. These assumptions describe the
inherent variability in the process of dropping the balls.
To see how the rules work, let F0, X0, and F1 be, respectively, the x-coordinates of the
funnel position on the previous drop, the outcome of the previous drop, and the repositioned
funnel position for the next drop. Then rule 1 never repositions, so that F1  F0. Rule 2
repositions relative to the previous funnel position, so that F1  F0 
 X0. Rule 3 repositions
relative to the original position (at 0), so that F1  0 
 X0  
 X0. Finally, rule 4 reposi-
tions at the previous drop, so that F1  X0. Similar equations hold for the y-coordinate.
For the simulation model, we simulate 45 consecutive drops of the ball from each of
the four rules. Our single output measure is the (straight-line) distance of the final drop
from the target. A rule is presumably a good one if the mean distance is small and the stan-
dard deviation of this distance is also small.
DEVELOPING THE SIMULATION MODEL
Given the repositioning equations for the rules, the simulation model is straightforward. In
fact, we can use a RISKSIMTABLE function to test all four rules simultaneously. The
completed model appears in Figure 11.12. (See the file Funnel Experiment.xlsx.) It can
be developed with the following steps:
1
Rule. Enter the formula
=RISKSIMTABLE({ 1, 2, 3, 4})
11.2 Operations Models
639
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
47
48
49
50
51
A
B
C
D
E
F
G
H
I
J
K
Deming's funnel experiment
Range names used:
3
$
B
$
!le
d
o
M
=
elu
R
1
elu
R
Funnel posioned at:
Drop lands at:
Drop
Xpos
Ypos
Xdrop
Ydrop
1
0
0
-0.11
0.05
2
0.00
0.00
0.11
0.04
3
0.00
0.00
0.00
-0.03
4
0.00
0.00
-0.03
-0.01
5
0.00
0.00
-0.07
0.03
6
0.00
0.00
0.10
-0.09
7
0.00
0.00
-0.04
0.08
8
0.00
0.00
0.11
0.06
Distance of ﬁnal drop from target
0.052
9
0.00
0.00
-0.01
0.08
10
0.00
0.00
-0.11
0.03
41
0.00
0.00
0.06
0.20
42
0.00
0.00
0.04
0.01
43
0.00
0.00
-0.10
-0.09
44
0.00
0.00
-0.01
0.07
45
0.00
0.00
0.04
-0.03
Explanaon of rules:
Rule 1: Never move the funnel
Rule 2: Move the funnel, relave to its previous 
posion, to compensate for the previous error.
Rule 3: Move the funnel, relave to its original posion, 
to compensate for the previous error.
Rule 4: Reposion the funnel over the previous drop.
Figure 11.12 The Funnel Experiment Simulation Model
in cell B3 to indicate that we want to simulate all four rules. Recall that if individual values
are listed in RISKSIMTABLE, they must be enclosed in curly brackets. No curly brackets
are used if the list is referenced by a range address.
2
Position funnel. Enter 0 in cells B7 and C7 to indicate that the original funnel posi-
tion is above the target at (0,0). Then implement the positioning equations by entering the
formula
=IF(Rule=1,0,IF(Rule=2,B7-D7,IF(Rule=3,-D7,D7)))
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

640
Chapter 11
Simulation Models
in cell B8 and copying it to the range B8:C51. Note how this formula references the loca-
tion of the previous drop. The IF function captures the logic for all four rules.
3
Simulate drops. Simulate the positions of the drops by entering the formula
=RISKNORMAL(B7,1)
in cell D7 and copying it to the range D7:E51. This says that the ball’s drop position is nor-
mally distributed with mean equal to the funnel’s position and standard deviation 1.
4
Distance. Calculate the final distance from the target in cell K14 with the formula
SQRT(SUMSQ(D51:E51))
Here we have used the SUMSQ function to get the sum of squares for the distance formula.
Then designate this cell as an @RISK output cell.
Running the Simulation
We set the number of iterations to 1000 and the number of simulations to 4 (because of
simulating the four rules simultaneously). Selected summary measures for the final dis-
tance from the target for all four rules are shown in Figure 11.13. We also show histograms
of this distance for rules 1, 2, and 3 in Figures 11.14, 11.15, and 11.16. (The histogram for
rule 4 isn’t shown because it is practically identical to the one for rule 3.)
Figure 11.14
Histogram of
Distance from
Target for Rule 1
Figure 11.13
Summary Results
for All Rules
Discussion of the Sim
ulation Results
These results prove Deming’s point about tampering. Rule 2 might not appear to be much
worse than rule 1, but its mean distance and standard deviation of distances are both about
45% higher than for rule 1. Rules 3 and 4 are disastrous. Their mean distances are more than
six times larger than for rule 1, and their standard deviations are also much larger. (The reason
is that the drops for rule 3 tend to swing back and forth—first to the left, then to the right,
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

then to the left, and so on—and the swings tend to increase through time. In contrast, the drops
for rule 4 tend to drift away from the target over time.) The moral of the story, as Deming
preached, is that you should not tamper with a stable process. If the process is not behaving as
desired, then fundamental changes to the process are required, not a lot of tinkering.
■
11.2 Operations Models
641
P R O B L E M S
Solutions for problems whose numbers appear within a
colored box can be found in the Student Solutions Files.
Refer to this book’s preface for purchase information.
Skill-Building Problems
1.
If the number of competitors in Example 11.1 doubles,
how does the optimal bid change?
2.
In Example 11.1, the possible profits vary from
negative to positive for each of the 10 possible bids
examined.
a. For each of these, use @RISK’s RISKTARGET
function to find the probability that Miller’s profit
is positive. Do you believe these results should
have any bearing on Miller’s choice of bid?
b. Use @RISK’s RISKPERCENTILE function to find
the 10th percentile for each of these bids. Can you
explain why the percentiles have the values you
obtain?
3.
Referring to Example 11.1, if the average bid for each
competitor stays the same, but their bids exhibit less
variability, does Miller’s optimal bid increase or
decrease? To study this question, assume that each
competitor’s bid, expressed as a multiple of Miller’s
cost to complete the project, follows each of the
following distributions.
a. Triangular with parameters 1.0, 1.3, and 2.4
b. Triangular with parameters 1.2, 1.3, and 2.2
c. Use @RISK’s Define Distributions window to
check that the distributions in parts a and b have
the same mean as the original triangular
distribution in the example, but smaller standard
deviations. What is the common mean? Why is it
not the same as the most likely value, 1.3?
Figure 11.15
Histogram of
Distance from
Target for Rule 2
Figure 11.16
Histogram of
Distance from
Target for Rule 3
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

11.3 FINANCIAL MODELS
There are many financial applications where simulation can be applied. Future cash flows,
future stock prices, and future interest rates are some of the many uncertain variables finan-
cial analysts must deal with. In every direction they turn, they see uncertainty. In this section
we analyze a few typical financial applications that can benefit from simulation modeling.
11.3.1 Financial Planning Models
Many companies, such as GM, Eli Lilly, Procter & Gamble, and Pfizer, use simulation in
their capital budgeting and financial planning processes. Simulation can be used to model
the uncertainty associated with future cash flows. In particular, simulation can be used to
answer questions such as the following:
■
What are the mean and variance of a project’s net present value (NPV)?
■
What is the probability that a project will have a negative NPV?
642
Chapter 11
Simulation Models
4.
See how sensitive the results in Example 11.2 are to
the following changes. For each part, make the change
indicated, run the simulation, and comment on any
differences between your outputs and the outputs in
the example.
a. The cost of a new camera is increased to $300.
b. The warranty period is decreased to one year.
c. The terms of the warranty are changed. If the
camera fails within one year, the customer gets 
a new camera for free. However, if the camera 
fails between 1 year and 1.5 years, the customer
pays a pro rata share of the new camera, increasing
linearly from 0 to full price. For example, if it fails
at 1.2 years, which is 40% of the way from 1 to
1.5, the customer pays 40% of the full price.
d. The customer pays $50 up front for an extended
warranty. This extends the warranty to three years.
This extended warranty is just like the original, so
that if the camera fails within three years, the
customer gets a new camera for free.
5.
In Example 11.2, the gamma distribution was used to
model the skewness to the right of the lifetime
distribution. Experiment to see whether the triangular
distribution could have been used instead. Let its
minimum value be 0, and choose its most likely
and maximum values so that this triangular
distribution has approximately the same mean and
standard deviation as the gamma distribution in the
example. (Use @RISK’s Define Distributions window
and trial and error to do this.) Then run the simulation
and comment on similarities or differences between
your outputs and the outputs in the example.
6.
In Example 11.3, we commented on the 95th
percentile on days required in cell I35 and the
corresponding date in cell J35. If the company 
begins production on this date, then it is 95% sure 
to complete the order by the due date. We found 
this date to be August 2. Do you always get this
answer? Find out by (1) running the simulation 10
more times, each with 1000 iterations, and finding 
the 95th percentile and corresponding date in each,
and (2) running the simulation once more, but with
10,000 iterations. Comment on the difference 
between simulations (1) and (2) in terms of 
accuracy. Given these results, when would you
recommend that production should begin?
7.
In Example 11.3, suppose you want to run five
simulations, where the probability of passing inspection
is varied from 0.6 to 1.0 in increments of 0.1. Use the
RISKSIMTABLE function appropriately to do this.
Comment on the effect of this parameter on the key
outputs. In particular, does the probability of passing
inspection have a large effect on when production
should start? (Note: When this probability is low, it
might be necessary to produce more than 25 batches,
the maximum built into the model. Check whether this
maximum should be increased.)
8.
In the simulation of Deming’s funnel experiment, the
@RISK outputs show how tampering leads to poor
results, at least in terms of the mean and standard
deviation of the distance of the final drop from the
target. However, the results we presented don’t show
how the tampering rules, particularly rules 3 and 4, go
wrong. To get a better idea of this, create two scatter
charts, one of the x-coordinate in column D versus
the drop number in column A, and one of the y-
coordinate in column E versus the x-coordinate in
column D. (You could also create a third scatter chart,
of the y-coordinate versus the drop number, but it
would be about the same as the first.) Use the chart
subtype that “connects the dots” for each scatter chart.
To go from one rule to another, enter a number from 1
to 4 in cell B3, not a formula. Then press the F9 key
several times to see how the scatter charts change.
Describe how the drops seem to evolve over time
according to the various rules.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

■
What are the mean and variance of a company’s profit during the next fiscal year?
■
What is the probability that a company will have to borrow more than $2 million
during the next year?
The following example illustrates how simulation can be used to evaluate an investment
opportunity.
E X A M P L E
11.5 DEVELOPING A NEW CAR AT GF AUTO
G
eneral Ford (GF) Auto Corporation is developing a new model of compact car. This
car is assumed to generate sales for the next five years. GF has gathered information
about the following quantities through focus groups with the marketing and engineering
departments.
■
Fixed cost of developing car. This cost is assumed to $700 million. The fixed cost
is incurred at the beginning of year 1, before any sales are recorded.
■
Margin per car. This is the unit selling price minus the variable cost of producing a
car. GF assumes that in year 1, the margin will be $4000. Every other year, GF
assumes the margin will decrease by 4%.1
■
Sales. The demand for the car is the uncertain quantity. In its first year, GF assumes
sales—number of cars sold—will be triangularly distributed with parameters 50,000,
75,000, and 85,000. Every year after that, the company assumes that sales will
decrease by some percentage, where this percentage is triangularly distributed with
parameters 5%, 8%, and 10%. GF also assumes that the percentage decreases in
successive years are independent of one another.
■
Depreciation and taxes. The company will depreciate its development cost on a
straight-line basis over the lifetime of the car. The corporate tax rate is 40%.
■
Discount rate. GF figures its cost of capital at 10%.
Given these assumptions, GF wants to develop a simulation model that will evaluate its
NPV of after-tax cash flows for this new car over the five-year time horizon.
Objective
To simulate the cash flows from the new car model, from the development
time to the end of its life cycle, so that GF can estimate the NPV of after-tax cash flows
from this car.
WHERE DO THE NUMBERS COME FROM?
There are many inputs to this problem. As we indicated, they are probably obtained from
experts within the company and from focus groups of potential customers.
Solution
This model is like most financial multiyear spreadsheet models. The completed model
extends several years to the right, but most of the work is for the first year or two. From
that point, you can copy to the other years to complete the model.
1The margin decreases because the company assumes variable costs tend to increase through time, whereas sell-
ing prices tend to remain fairly constant through time.
11.3 Financial Models
643
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

DEVELOPING THE SIMULATION MODEL
The simulation model for GF appears in Figure 11.17. (See the file New Car
Development.xlsx.) It can be formed as follows.
644
Chapter 11
Simulation Models
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
G
F
E
D
C
B
A
New car simulaon
Inputs
Parameters of triangular distribuons
Fixed development 
ts
o
M
ni
M
0
0
0,0
0
0,0
0
7
$
ts
o
c
 likely
Max
Year 1 
r
a
e
Y
0
0
0,4
$
n
oit
u
birt
n
o
c
 1 sales
50000
75000
85000
Annual decrease in contribuon
4%
Annual decay rate
5%
8%
10%
Tax 
%
0
4
e
t
a
r
Discount 
%
0
1
e
t
a
r
Simulaon
End of 
5
4
3
2
1
r
a
e
y
Unit 
1
5
3
6
5
6
6
3
1
6
3
1
8
6
6
8
5
3
2
7
4
7
4
8
7
s
ela
s
Unit 
7
9
3,3
$
9
3
5,3
$
6
8
6,3
$
0
4
8,3
$
0
0
0,4
$
n
oit
u
birt
n
o
c
Revenue minus variable cost
$313,896,351
$277,855,417
$246,300,063
$217,169,920
$191,445,402
0
0
0,0
0
0,0
4
1
$
0
0
0,0
0
0,0
4
1
$
0
0
0,0
0
0,0
4
1
$
0
0
0,0
0
0,0
4
1
$
0
0
0,0
0
0,0
4
1
$
n
oit
aic
e
r
p
e
D
Before tax 
2
0
4,5
4
4,1
5
$
0
2
9,9
6
1,7
7
$
3
6
0,0
0
3,6
0
1
$
7
1
4,5
5
8,7
3
1
$
1
5
3,6
9
8,3
7
1
$
tif
o
r
p
Aer tax 
1
4
2,7
6
8,0
3
$
2
5
9,1
0
3,6
4
$
8
3
0,0
8
7,3
6
$
0
5
2,3
1
7,2
8
$
0
1
8,7
3
3,4
0
1
$
tif
o
r
p
Cash 
1
4
2,7
6
8,0
7
1
$
2
5
9,1
0
3,6
8
1
$
8
3
0,0
8
7,3
0
2
$
0
5
2,3
1
7,2
2
2
$
0
1
8,7
3
3,4
4
2
$
w
olf
NPV of cash 
2
3
6,0
3
6,2
9
$
s
w
olf
Figure 11.17 GF Auto Simulation Model
1
Inputs. Enter the various inputs in the blue cells.
2
Unit sales. Generate first-year sales in cell B12 with the formula
RISKTRIANG(E5,F5,G5)
Then generate the reduced sales in later years by entering the formula
B12*(1–RISKTRIANG($E$6,$F$6,$G$6))
in cell C12 and copying it across row 12. Note that each sales figure is a random fraction
of the previous sales figure.
3
Contributions. Calculate the unit contributions in row 13 by entering the formulas
B5
and
B13*(1–$B$6)
in cells B13 and C13, and copying the latter across. Then calculate the contributions in row
14 as the product of the corresponding values in rows 12 and 13.
4
Depreciation. Calculate the depreciation each year in row 15 as the development
cost in cell B4 divided by 5. This is exactly what “straight-line depreciation” means.
5
Before-tax and after-tax profits. To calculate the before-tax profit in any year, sub-
tract the depreciation from total contribution, so each value in row 16 is the difference
between the corresponding values in rows 14 and 15. The reason is that depreciation isn’t
taxed. To calculate the after-tax profits in row 17, multiply each before-tax profit by one
Depreciation is
subtracted to get
before-tax profit, but 
it is then added back
after taxes have been
deducted.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

minus the tax rate in cell B7. Finally, each cash flow in row 18 is the sum of the corre-
sponding values in rows 15 and 17. Here depreciation is added back to get the cash flow.
6
NPV. Calculate the NPV of cash flows in cell B20 with the formula

B4	NPV(B8,B18:F18)
and designate it as an @RISK output cell (the only output cell). Here, we are assuming that
the development cost is incurred right now, so that it isn’t discounted, and that all other
cash flows occur at the ends of the respective years. This allows the NPV function to be
used directly.
Running the Simulation
Set the number of iterations to 1000 and the number of simulations to 1, and then run the
simulation as usual.
Discussion of the Simulation Results
After running @RISK, you obtain the histogram in Figure 11.18. These results are some-
what comforting, but also a cause of concern for GF. On the bright side, the mean NPV is
about $31.5 million, and there is some chance that the NPV could go well above that
figure, even up to almost $150 million. However, there is also a dark side, as shown by
the two sliders in the histogram. One slider has been placed over an NPV of 0. As the
histogram indicates, there is about a 71% chance of a positive NPV, but there is about a
29% chance of it being negative. The second slider has been positioned at its default 5th
percentile setting. Financial analysts often call this percentile the value at risk at the
5% level, or VAR 5%, because it indicates nearly the worst possible outcome. From this
simulation, you can see that GF’s VAR 5% is approximately a $67.6 million loss.
Figure 11.18
Histogram of NPV
The value at risk at the 5% level, or VAR 5%, is the 5th percentile of a distribution,
and it is often used in financial models. It indicates nearly the worst possible outcome.
11.3 Financial Models
645
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

What is most responsible for this huge variability in NPV, the variability in first-year
sales or the variability in annual sales decreases? This can be answered with @RISK’s
tornado chart. (See Figure 11.19.) To get this chart, click on the tornado button below the
histogram shown in Figure 11.18 and select the Correlation option. This chart answers the
question emphatically. Variability in first-year sales is by far the largest influence on NPV.
It correlates almost perfectly with NPV. The annual decreases in sales are not unimportant,
but they have much less effect on NPV. If GF wants to get a more favorable NPV
distribution, it should do all it can to boost first-year sales—and make the first-year sales
distribution less variable.
646
Chapter 11
Simulation Models
Financial analysts
typically look at VAR
5% to see how bad—
or more precisely,
almost how bad—
things could get.
Figure 11.19
Tornado Chart
for NPV
Before finishing this example, we revisit the flaw of averages. What if GF used a
deterministic model to estimate NPV? Would the results match those from the simulation?
We tried this two ways, once by entering the most likely values of the inputs instead of the
random numbers, and once by entering the means instead of the random numbers. The
results appear in Figure 11.20. (The mean of a triangular distribution is the average of its
three parameters. These means appear in cells H5 and H6.) Now there are no random num-
bers in rows 12 and 24, only most likely values or means. The difference between the two
NPVs is huge. In this case, the NPV by using means is very close to the mean NPV from
the simulation, about $31 million. But if the company used most likely values for the
inputs in its deterministic model, which certainly seems sensible, the NPV would be off by
a factor of more than two, another variation of the flaw of averages. Besides this problem,
neither deterministic model provides even a hint that the company has about a 29% chance
of a negative NPV.2
A tornado chart lets
you see which random
inputs have the most
effect on a specified
output.
If you create a
deterministic model
using the most likely
values of the uncer-
tain inputs, you can
possibly get an output
value that is nowhere
near the mean of 
that output.
2It turns out that the NPV in this model is linear in the two random inputs. When an output is linear in the inputs,
the deterministic model using means of inputs always gives the correct mean output, so that the flaw of averages
in the form from the previous chapter does not occur. Even so, a deterministic model still provides no indication
of how bad or how good things could get.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

11.3.2 Cash Balance Models
All companies track their cash balance over time. As specific payments come due,
companies sometimes need to take out short-term loans to keep a minimal cash balance.
The following example illustrates one such application.
FUNDAMENTAL INSIGHT
The Mean Isn’t Everything
Many discussions of simulation focus on the mean of
some output variable . This mak es sense , given the
importance of EMV for decision making, as discussed
in Chapter 9.After all,EMV is just the mean of a mon-
etary output. However, analysts in many areas, includ-
ing finance , are often at least as inter
ested in the
extreme values of an output distribution. For exam-
ple, the VAR 5% discussed in this example indicates
nearly how bad things could get if unlucky outcomes
occur. If large amounts of money are at stake, particu-
larly potential losses, companies might not want to
play the averages by focusing only on the mean. They
should be a
ware of potential disasters as w
ell.
Of course, simulation also shows the bright side, the
extremes on the right that could occur if lucky out-
comes occur. Managers shouldn’t be so conser vative
that they focus only on the negativ e outcomes and
ignore the upside potential.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
H
G
F
E
D
C
B
A
New car determinisc models
Inputs
Parameters of triangular distribuons
Fixed development 
ts
o
M
ni
M
0
0
0,0
0
0,0
0
7
$
ts
o
c
 likely
Max
Mean
Year 1 
r
a
e
Y
0
0
0,4
$
n
oit
u
birt
n
o
c
 1 sales
50000
75000
85000
70000
Annual decrease in contribuon
4%
Annual decay rate
5%
8%
10%
7.67%
Tax 
%
0
4
e
t
a
r
Discount 
%
0
1
e
t
a
r
Using most likely values for uncertain inputs
End of 
5
4
3
2
1
r
a
e
y
Unit 
9
2
7
3
5
2
0
4
8
5
0
8
4
3
6
0
0
0
9
6
0
0
0
5
7
s
ela
s
Unit 
7
9
3,3
$
9
3
5,3
$
6
8
6,3
$
0
4
8,3
$
0
0
0,4
$
n
oit
u
birt
n
o
c
Revenue minus variable cost
$300,000,000
$264,960,000
$234,012,672
$206,679,992
$182,539,769
0
0
0,0
0
0,0
4
1
$
0
0
0,0
0
0,0
4
1
$
0
0
0,0
0
0,0
4
1
$
0
0
0,0
0
0,0
4
1
$
0
0
0,0
0
0,0
4
1
$
n
oit
aic
e
r
p
e
D
Before tax 
9
6
7,9
3
5,2
4
$
2
9
9,9
7
6,6
6
$
2
7
6,2
1
0,4
9
$
0
0
0,0
6
9,4
2
1
$
0
0
0,0
0
0,0
6
1
$
tif
o
r
p
Aer tax 
1
6
8,3
2
5,5
2
$
5
9
9,7
0
0,0
4
$
3
0
6,7
0
4,6
5
$
0
0
0,6
7
9,4
7
$
0
0
0,0
0
0,6
9
$
tif
o
r
p
Cash 
1
6
8,3
2
5,5
6
1
$
5
9
9,7
0
0,0
8
1
$
3
0
6,7
0
4,6
9
1
$
0
0
0,6
7
9,4
1
2
$
0
0
0,0
0
0,6
3
2
$
w
olf
NPV of cash 
7
8
6,0
0
5,5
6
$
s
w
olf
Using means for uncertain inputs
End of 
5
4
3
2
1
r
a
e
y
Unit 
8
7
8
0
5
3
0
1
5
5
8
7
6
9
5
3
3
6
4
6
0
0
0
0
7
s
ela
s
Unit 
7
9
3,3
$
9
3
5,3
$
6
8
6,3
$
0
4
8,3
$
0
0
0,4
$
n
oit
u
birt
n
o
c
Revenue minus variable cost
$280,000,000
$248,192,000
$219,997,389
$195,005,685
$172,853,040
0
0
0,0
0
0,0
4
1
$
0
0
0,0
0
0,0
4
1
$
0
0
0,0
0
0,0
4
1
$
0
0
0,0
0
0,0
4
1
$
0
0
0,0
0
0,0
4
1
$
n
oit
aic
e
r
p
e
D
Before tax 
0
4
0,3
5
8,2
3
$
5
8
6,5
0
0,5
5
$
9
8
3,7
9
9,9
7
$
0
0
0,2
9
1,8
0
1
$
0
0
0,0
0
0,0
4
1
$
tif
o
r
p
Aer tax 
4
2
8,1
1
7,9
1
$
1
1
4,3
0
0,3
3
$
3
3
4,8
9
9,7
4
$
0
0
2,5
1
9,4
6
$
0
0
0,0
0
0,4
8
$
tif
o
r
p
Cash 
4
2
8,1
1
7,9
5
1
$
1
1
4,3
0
0,3
7
1
$
3
3
4,8
9
9,7
8
1
$
0
0
2,5
1
9,4
0
2
$
0
0
0,0
0
0,4
2
2
$
w
olf
NPV of cash 
9
0
9,5
6
5,1
3
$
s
w
olf
Figure 11.20 Deterministic Models
11.3 Financial Models
647
■
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

648
Chapter 11
Simulation Models
E X A M P L E
11.6 MAINTAINING A MINIMAL CASH BALANCE AT ENTSON
T
he Entson Company believes that its monthly sales during the period from November
of the current year to July of next year are normally distributed with the means and
standard deviations given in Table 11.2. Each month Entson incurs fixed costs of
$250,000. In March taxes of $150,000 and in June taxes of $50,000 must be paid.
Dividends of $50,000 must also be paid in June. Entson estimates that its receipts in a
given month are a weighted sum of sales from the current month, the previous month, and
two months ago, with weights 0.2, 0.6, and 0.2. In symbols, if Rt and St represent receipts
and sales in month t, then
Rt  0.2St–2 	 0.6St–1 	 0.2St
(11.1)
The materials and labor needed to produce a month’s sales must be purchased one month
in advance, and the cost of these averages to 80% of the product’s sales. For example, if
sales in February are $1,500,000, then the February materials and labor costs are
$1,200,000, but these must be paid in January.
Table 11.2 Monthly Sales (in Thousands of Dollars) for Entson
Nov.
Dec.
Jan.
Feb.
Mar.
Apr.
May
Jun.
Jul.
Mean
1500
1600
1800
1500
1900
2600
2400
1900
1300
Standard Deviation 70
75
80
80
100
125
120
90
70
At the beginning of January, Entson has $250,000 in cash. The company wants to
ensure that each month’s ending cash balance never falls below $250,000. This means that
Entson might have to take out short-term (one-month) loans. For example, if the ending
cash balance at the end of March is $200,000, Entson will take out a loan for $50,000,
which it will then pay back (with interest) one month later. The interest rate on a short-term
loan is 1% per month. At the beginning of each month, Entson earns interest of 0.5% on its
cash balance. The company wants to use simulation to estimate the maximum loan it will
need to take out to meet its desired minimum cash balance. Entson also wants to analyze
how its loans will vary over time, and it wants to estimate the total interest paid on these
loans.
Objective
To simulate Entson’s cash flows and the loans the company must take out to
meet a minimum cash balance.
WHERE DO THE NUMBERS COME FROM?
Although there are many monetary inputs in the problem statement, they should all be
easily accessible. Of course, Entson chooses the minimum cash balance of $250,000 as a
matter of company policy.
Solution
There is a considerable amount of bookkeeping in this simulation, so it is a good idea to
list the events in chronological order that occur each month. We assume the following:
■
Entson observes its beginning cash balance.
■
Entson receives interest on its beginning cash balance.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

■
Receipts arrive and expenses are paid (including payback of the previous month’s
loan, if any, with interest).
■
If necessary, Entson takes out a short-term loan.
■
The final cash balance is observed, which becomes next month’s beginning cash balance.
DEVELOPING THE SIMULATION MODEL
The completed simulation model appears in Figure 11.21. (See the file Cash Balance.xlsx.)
It requires the following steps.
1
Inputs. Enter the inputs in the blue cells. Note that loans are simulated (in row 42)
only for the period from January to June of next year. However, sales figures are required
(in row 28) in November and December of the current year to generate receipts for January
and February. Also, July sales are required for next year to generate the material and labor
costs paid in June.
2
Actual sales. Generate the sales in row 28 by entering the formula
RISKNORMAL(B6,B7)
in cell B28 and copying across.
3
Beginning cash balance. For January of next year, enter the cash balance with the
formula
B19
in cell D31. Then for the other months enter the formula
D43
in cell E31 and copy it across row 31. This reflects that the beginning cash balance for one
month is the final cash balance from the previous month.
4
Incomes. Entson’s incomes (interest on cash balance and receipts) are entered in
rows 32 and 33. To calculate these, enter the formulas
$B$24*D31
and
SUMPRODUCT($B$14:$D$14,B28:D28)
in cells D32 and D33 and copy them across rows 32 and 33. This latter formula, which is
based on Equation (11.1), multiplies the fixed weights in row 14 by the relevant sales and
adds these products to calculate receipts.
5
Expenses. Entson’s expenses (fixed costs, taxes and dividends, material and labor
costs, and payback of the previous month’s loan) are entered in rows 35 through 39.
Calculate these by entering the formulas
D9
D10
$B$17*E28
D42
and
D42*$B$23
11.3 Financial Models
649
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

in cells D35, D36, D37, E38, and E39, respectively, and copying these across rows 35
through 39. (For the loan payback, we are assuming that no loan payback is due in
January.)
6
Cash balance bef ore loan. Calculate the cash balance before the loan (if any) by
entering the formula
SUM(D31:D33)–SUM(D35:D39)
in cell D41 and copying it across row 41.
7
Amount of loan.
If the value in row 41 is below the minimum cash balance
($250,000), Entson must borrow enough to bring the cash balance up to this minimum.
Otherwise, no loan is necessary. Therefore, enter the formula
MAX($B$20–D41,0)
in cell D42 and copy it across row 42. (You could use an IF function, rather the MAX
function, to accomplish the same result.)
8
Final cash balance. Calculate the final cash balance by entering the formula
D41	D42
in cell D43 and copying it across row 43.
9
Maximum loan, total interest. Calculate the maximum loan from January to June in
cell B45 with the formula
650
Chapter 11
Simulation Models
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
A
B
C
D
E
F
G
H
I
J
Entson cash balance simulaon
Inputs
Distribuon of monthly sales (normal)
Nov
Dec
Jan
Feb
Mar
Apr
May
Jun
Jul
0
0
3
1
0
0
9
1
0
0
4
2
0
0
6
2
0
0
9
1
0
0
5
1
0
0
8
1
0
0
6
1
0
0
5
1
n
a
e
M
St 
0
7
0
9
0
2
1
5
2
1
0
0
1
0
8
0
8
5
7
0
7
v
e
D
Monthly ﬁxed 
0
5
2
0
5
2
0
5
2
0
5
2
0
5
2
0
5
2
ts
o
c
Tax, dividend 
0
0
1
0
0
0
5
1
0
0
s
e
s
n
e
p
x
e
Receipts in any month are of form: A*(sales from 2 months ago)+B*(previous month's sales)+C*(current month's sales), where:
A
B
C
0.2
0.6
0.2
Cost of materials and labor for next month, spent this month, is a percentage of product's sales from next month, where the percentage is:
80%
Inial cash in January
250
Minimum cash balance
250
Monthly interest rates
Interest rate on loan
1.0%
Interest rate on cash
0.5%
Simulaon
Nov
Dec
Jan
Feb
Mar
Apr
May
Jun
Jul
Actual sales
1572.558
1449.428
1862.074
1604.554
1777.390
2796.194
2290.963
1890.610
1274.369
Cash, receipts
Beginning cash 
0
0
0.0
5
2
0
0
0.0
5
2
0
0
0.0
5
2
0
9
6.1
3
3
0
9
1.4
7
2
0
0
0.0
5
2
e
c
n
ala
b
Interest on cash 
0
5
2.1
0
5
2.1
0
5
2.1
8
5
6.1
1
7
3.1
0
5
2.1
e
c
n
ala
b
6
8
6
8
3
9.1
1
3
2
6
6
2
7
8
3.1
9
4
2
9
6
7
3
8
5.6
4
9
1
1
2
1
5
2
6.0
9
6
1
7
4
9
0
4
0.8
2
7
1
3
6
3
3
8
5.6
5
5
1
st
pie
c
e
R
Costs
Fixed 
0
5
2
0
5
2
0
5
2
0
5
2
0
5
2
0
5
2
sts
o
c
Tax, dividend 
0
0
1
0
0
0
5
1
0
0
s
e
s
n
e
p
x
e
Material, labor 
5
9
4.9
1
0
1
8
8
4.2
1
5
1
0
7
7.2
3
8
1
5
5
9.6
3
2
2
2
1
9.1
2
4
1
3
4
6.3
8
2
1
s
e
s
n
e
p
x
e
Loan payback 
0
0
0.0
5
6
4.6
8
2
8
4
5.6
0
0
1
2
8
9.2
6
8
0
0
0.0
0
0
0.0
)la
pic
nir
p
(
Loan payback 
0
0
0.0
5
6
8.2
5
6
0.0
1
0
3
6.8
0
0
0.0
0
0
0.0
)ts
e
r
e
t
ni(
Cash balance before 
0
9
6.1
3
3
0
9
1.4
7
2
n
a
ol
-612.982
-756.548
-36.465
904.365
Loan amount (if 
0
0
0.0
5
6
4.6
8
2
8
4
5.6
0
0
1
2
8
9.2
6
8
0
0
0.0
0
0
0.0
)y
n
a
Final cash 
5
6
3.4
0
9
0
0
0.0
5
2
0
0
0.0
5
2
0
0
0.0
5
2
0
9
6.1
3
3
0
9
1.4
7
2
e
c
n
ala
b
Maximum loan
1006.548
Total intest on loans
21.560
 
 
 
  
All monetaryvaluesarein$1000s.
Figure 11.21
Cash Balance
Simulation Model
The loan amounts are
determined by the
random cash inflows
and outflows and the
fact that Entson’s
policy is to maintain a
minimum cash
balance.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

MAX(D42:I42)
Then calculate the total interest paid on all loans in cell B46 with the formula
SUM(E39:J39)
10
Output range. In the usual way, designate cells B45 and B46 as output cells. Also,
designate the entire range of loans, D42:I42, as an output range. To do this, highlight this
range and click on the @RISK Add Output button. It will ask you for a name of the output.
We suggest “Loans.” Then a typical formula in this range, such as the formula for cell E42,
will be
RISKOUTPUT("Loans",2) 	 MAX($B$20–E41,0)
This indicates that cell E42 is the second cell in the Loans output range.
Running the Simulation
Set the number of iterations to 1000 and the number of simulations to 1. Then run the
simulation in the usual way.
Discussion of the Simulation Results
After running the simulation, you will obtain the summary results in Figure 11.22. They
indicate that the maximum loan varies considerably, from a low of about $461,000 to a
high of about $1,534,000. The average is about $952,500. You can also see that Entson is
spending close to $20,000 on average in interest on the loans, although the actual amounts
vary considerably from one iteration to another.
An @RISK output 
range, as opposed to 
a single output cell,
allows you to obtain a
summary chart that 
shows the whole 
simulated range at 
once.This range is 
typically a time series.
Figure 11.22
Summary Measures
for Cash Balance
Simulation
You can also gain insights from the summary trend chart of the series of loans, shown
in Figure 11.23. To obtain this chart, click on the third button at the bottom of the Results
Summary window shown in Figure 11.22. (This button is also available in any histogram
window.) This chart clearly shows how the loans vary over time. The middle line is the
expected loan amount. The inner bands extend to one standard deviation on either side of
the mean, and the outer bands extend to the 5th and 95th percentiles. (@RISK lets you cus-
tomize these bands in a number of ways by right-clicking on the chart.) You can see that
the largest loans are required in March and April.
Is it intuitively clear why the required loans peak in March and April? After all, why
should Entson need money in months when its sales tend to be relatively high? There are
two factors working here. First, Entson has to pay its costs early. For example, it has to pay
80% of its April sales for labor and material expenses in March. Second, most of its
receipts arrive late. For example, 80% of its receipts from sales in March are not received
until after March. Therefore, the answer to the question is that the timing and amounts of
loans are fairly complex. Of course, this is why Entson goes to the trouble of building a
simulation model.
11.3 Financial Models
651
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

11.3.3 Investment Models
Individual investors typically want to choose investment strategies that meet some pre-
specified goal. The following example is typical. Here, a person wants to meet a retirement
goal, starting at an early age.
652
Chapter 11
Simulation Models
0.4
0.6
0.8
1
1.2
1.4
5% -95%
-0.2
0
0.2
0.4
0.6
0.8
1
1.2
1.4
Jan
Feb
Mar
Apr
May
Jun
Values in Thousands
Loan amount from Jan to Jun
+/- 1 Std.Dev.
Mean
Figure 11.23
Summary Chart of
Loans over Time
E X A M P L E
11.7 INVESTING FOR RETIREMENT
A
ttorney Sally Evans has just begun her career. At age 25, she has 40 years until retirement,
but she realizes that now is the time to start investing. She plans to invest $1000 at the
beginning of each of the next 40 years. Each year, she plans to put fixed percentages—the same
each year—of this $1000 into stocks, Treasury bonds (T-bonds), and Treasury bills (T-bills).
However, she is not sure which percentages to use. (We call these percentages investment
weights.) She does have historical annual returns from stocks, T-bonds, and T-bills from 1946
to 2007. These are listed in the file Retirement Planning.xlsx. This file also includes inflation
rates for these years. For example, for 1993 the annual returns for stocks, T-bonds, and T-bills
were 9.99%, 18.24%, and 2.90%, respectively, and the inflation rate was 2.75%. Sally would
like to use simulation to help decide what investment weights to use, with the objective of
achieving a large investment value, in today’s dollars, at the end of 40 years.
Objective
To use simulation to estimate the value of Sally’s future investments, in
today’s dollars, from several investment strategies in T-bills, T-bonds, and stocks.
WHERE DO THE NUMBERS COME FROM?
Historical returns and inflation rates, such as those quoted here, are widely available on
the Web.
Solution
The most difficult modeling aspect is settling on a way to use historical returns and infla-
tion factors to generate future values of these quantities. We suggest using a scenario
approach. You can think of each historical year as a possible scenario, where the scenario
You can simulate 
future scenarios by
randomly choosing 
past scenarios, giving
higher probabilities to
more recent scenarios.
■
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

specifies the returns and inflation factor for that year. Then for any future year, you ran-
domly choose one of these scenarios. It seems intuitive that more recent scenarios ought to
have a greater chance of being chosen. To implement this idea, you can give a weight (not
to be confused with the investment weights) to each scenario, starting with weight 1 for
2007. Then the weight for any year is a damping factor multiplied by the weight from the
next year. For example, the weight for 1996 is the damping factor multiplied by the weight
for 1997. To change these weights to probabilities, you can divide each weight by the sum
of all the weights. The damping factor illustrated here is 0.98. Others could be used
instead, and it is not clear which produces the most realistic results. (This is an important
question for financial research.)
The other difficult part of the solution is choosing “good” investment weights. This
is really an optimization problem: find three weights that add to 1 and produce the
largest mean final cash. Palisade has another software package, RiskOptimizer, that
solves this type of optimization-simulation problem. However, the example illustrates
several sets of weights, where some percentage is put into stocks and the remainder is
split evenly between T-bonds and T-bills, and see which does best. You can try other sets
if you like.
DEVELOPING THE SIMULATION MODEL
The historical data and the simulation model (each with some rows hidden) appear in
Figures 11.24 and 11.25. (Again, see the Retirement Planning.xlsx file.) It can be devel-
oped as follows.
1
Inputs. Enter the data in the blue regions of Figures 11.24 and 11.25.
2
Weights. The investment weights used for the model are in rows 10 through 12. (For
example, the first set puts 80% in stocks and 10% in each of T-bonds and T-bills.) You can
simulate all three sets of weights simultaneously with a RISKSIMTABLE and VLOOKUP
combination as follows. First, enter the formula
RISKSIMTABLE({1,2,3})
in cell I16. Then enter the formula
VLOOKUP($I$16,LTable1,2)
Without a package 
like RiskOptimizer,
you cannot find the 
“best” set of inves-
tment weights, but 
the simulation model
lets you experiment
with various sets of 
weights.
3
4
5
6
7
8
9
58
59
60
61
62
63
64
65
66
67
A
B
C
D
E
F
G
Historical data and probabilies
Year
T-Bills
T-Bonds
Stocks
Inﬂaon
ProbWts
Probability
1946
0.0035
-0.0010
-0.0807
0.1817
0.2916
0.0082
1947
0.0050
-0.0263
0.0571
0.0901
0.2976
0.0083
1948
0.0081
0.0340
0.0550
0.0271
0.3036
0.0085
1949
0.0110
0.0645
0.1879
-0.0180
0.3098
0.0087
1950
0.0120
0.0006
0.3171
0.0579
0.3161
0.0089
1999
0.0439
-0.0825
0.2089
0.0270
0.8508
0.0238
2000
0.0537
0.1666
-0.0903
0.0340
0.8681
0.0243
2001
0.0573
0.0557
-0.1185
0.0160
0.8858
0.0248
2002
0.0180
0.1512
-0.2198
0.0159
0.9039
0.0253
2003
0.0180
0.0038
0.2841
0.0227
0.9224
0.0258
2004
0.0218
0.0449
0.1070
0.0268
0.9412
0.0264
2005
0.0431
0.0287
0.0485
0.0339
0.9604
0.0269
2006
0.0488
0.0196
0.1563
0.0324
0.9800
0.0274
2007
0.0548
0.0488
0.1021
0.0285
1.0000
0.0280
Sums -->
35.7115
1.0000
Figure 11.24
Historical Data,
Inputs, and
Probabilities
11.3 Financial Models
653
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

in cell J16 and copy it to cells K16 and L16. Then modify the formulas in these latter two
cells, changing the last argument of the VLOOKUP to 3 and 4, respectively. For example,
the formula in cell L16 should end up as
VLOOKUP($I$16,LTable1,4)
The effect is that you can run three simulations, one for each set of weights in rows 10
through 12.
3
Probabilities. Enter value 1 in cell F66. Then enter the formula
$J$4*F66
in cell F65 and copy it up to cell F5. Sum these values with the SUM function in cell F67.
Then to convert them to probabilities (numbers that add to 1), enter the formula
F5/$F$67
654
Chapter 11
Simulation Models
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
56
57
58
59
60
61
62
63
I
J
K
L
M
N
O
P
Q
Inputs
Damping factor
0.98
Range names used
Yearly 
2
1
$
L
$:0
1
$I$
!le
d
o
M
=
1
elb
a
T
L
0
0
0,1
$
t
n
e
m
ts
e
v
ni
Planning 
6
6
$
E
$:5
$
A
$
!le
d
o
M
=
2
elb
a
T
L
sr
a
e
y
0
4
n
o
zir
o
h
Weights
=Model!$J$16:$L$16
Alternave sets of weights to test
Index
T-Bills
T-Bonds
Stocks
1
0.10
0.10
0.80
2
0.20
0.20
0.60
3
0.30
0.30
0.40
Weights used
Index
T-Bills
T-Bonds
Stocks
1
0.10
0.10
0.80
Output from simulaon below
Final cash (today's dollars)
$46,215
Simulaon model
2
3
4
5
Future year
Beginning cash
Scenario
T-Bills
T-Bonds
Stocks
Inﬂaon
Ending cash
Deﬂator
1
$1,000
1958
1.0154
0.9390
1.4336
1.0176
1342
0.983
2
2342
1991
1.0560
1.1930
1.3055
1.0306
2973
0.954
3
3973
1988
1.0635
1.0967
1.1681
1.0442
4571
0.913
4
5571
2003
1.0180
1.0038
1.2841
1.0227
6849
0.893
5
7849
1981
1.1471
1.0185
0.9509
1.0894
7671
0.820
6
8671
1976
1.0508
1.1675
1.2384
1.0481
10514
0.782
33
113803
1984
1.0985
1.1543
1.0627
1.0395
122389
0.246
34
123389
1995
1.0560
1.2348
1.3720
1.0250
163697
0.240
35
164697
1973
1.0693
0.9889
0.8534
1.0880
146340
0.220
36
147340
1990
1.0781
1.0618
0.9683
1.0611
145665
0.207
37
146665
1998
1.0516
1.1492
1.2834
1.0160
182862
0.204
38
183862
1988
1.0635
1.0967
1.1681
1.0442
211533
0.196
39
212533
1992
1.0351
1.0805
1.0767
1.0290
228031
0.190
40
229031
2007
1.0548
1.0488
1.1021
1.0285
250111
0.185
Column oﬀset for lookup2
Figure 11.25 Retirement Simulation Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

in cell G5 and copy it down to cell G66. Note how the probabilities for more recent years
are considerably larger. When scenarios are selected randomly, recent years will have a
greater chance of being chosen. (The SUM formula in cell G67 confirms that the probabil-
ities sum to 1.)
4
Scenarios. Moving to the model in Figure 11.25, the goal is to simulate 40 scenarios in
columns K through O, one for each year of Sally’s investing. To do this, enter the formulas
RISKDISCRETE($A$5:$A$66,$G$5:$G$66)
and
1	VLOOKUP($K24,LTable2,L$22)
in cells K24 and L24, and copy this latter formula to the range M24:O24. Then copy all of
these formulas down to row 63. Make sure you understand how the RISKDISCRETE and
VLOOKUP functions combine to achieve the goal. (Also, check the list of range names
used at the top of Figure 11.25.) The RISKDISCRETE randomly generates a year from col-
umn A, using the probabilities in column G. Then the VLOOKUP captures the data from
this year. (You add 1 to the VLOOKUP to get a value such as 1.08, rather than 0.08.) This is
the key to the simulation. (By the way, do you see why Excel’s RANDBETWEEN function
isn’t used to generate the years in column K? The reason is that this function makes all pos-
sible years equally likely, and the goal is to make more recent years more likely.)
5
Beginning, ending cash. The bookkeeping part is straightforward. Begin by entering
the formula
J5
in cell J24 for the initial investment. Then enter the formulas
J24*SUMPRODUCT(Weights,L24:N24)
and
$J$5	P24
in cells P24 and J25 for ending cash in the first year and beginning cash in the second year.
The former shows how the beginning cash grows in a given year. You should think it
through carefully. The latter implies that Sally reinvests her previous money, plus she
invests an additional $1000. Copy these formulas down columns J and P.
6
Deflators. You eventually need to deflate future dollars to today’s dollars. The proper
way to do this is to calculate deflators (also called deflation factors). Do this by entering
the formula
1/O24
in cell Q24. Then enter the formula
Q24/O25
in cell Q25 and copy it down. The effect is that the deflator for future year 20, say, in cell
Q43, is 1 divided by the product of all 20 inflation factors up through that year. (This is
similar to discounting for the time value of money, but the relevant discount rate, now the
inflation rate, varies from year to year.)
7
Final cash. Calculate the final value in today’s dollars in cell K19 with the formula
P63*Q63
Then designate this cell as an @RISK output cell.
11.3 Financial Models
655
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Running the Simulation
Set the number of iterations to 1000 and the number of simulations to 3 (one for each set of
investment weights to be tested). Then run the simulation as usual.
Discussion of the Simulation Results
Summary results appear in Figure 11.26. The first simulation, which invests the most heav-
ily in stocks, is easily the winner. Its mean final cash, slightly more than $153,000 in
today’s dollars, is much greater than the means for the other two sets of weights. The first
simulation also has a much larger upside potential (its 95th percentile is close to $360,000),
and even its downside is slightly better than the others: Its 5th percentile is the best, and its
minimum is only slightly worse than the minimum for the other sets of weights.
656
Chapter 11
Simulation Models
Figure 11.26
Summary Results
for Retirement
Simulation
Nevertheless, the histogram for simulation 1 (put 80% in stocks), shown in Figure 11.27,
indicates a lot of variability—and skewness—in the distribution of final cash. As in Example
11.5, the concept of value at risk (VAR) is useful. Recall that VAR 5% is defined as the 5th
percentile of a distribution and is often the value investors worry about. Perhaps Sally should
rerun the simulation with different investment weights, with an eye on the weights that
increase her VAR 5%. Right now it is slightly more than $40,000—not too good considering
that she invests $40,000 total. She might not like the prospect of a 5% chance of ending up
with no more than this. We also encourage you to try running this simulation with other
investment weights, both for the 40-year horizon and (after modifying the spreadsheet model
Figure 11.27
Histogram of Final
Cash with 80% in
Stocks
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

slightly) for shorter time horizons such as 10 or 15 years. Even though the stock strategy
appears to be best for a long horizon, it is not necessarily guaranteed to dominate for a shorter
time horizon. ■
11.3.4 Simulating Stock Prices and Options
In this section, we illustrate how @RISK can be used to simulate stock prices. Then we
show how to analyze derivative securities such as call options with simulation.
Modeling the Price of a Stock
Anenormousamountofresearchhasbeendevotedtodiscoveringthewaystockpriceschange.
Although few agree on the best model of stock price changes, one popular model states that
price changes follow a lognormal distribution. Essentially, this means that the logarithm of a
stock’s price at any time is a normally distributed random variable. To be more specific, the
stockpriceptatanytime t inthefutureisrelatedtothecurrentprice p0 bytheformula
pt  p0 exp [( 
 0.52)t 	 Zt]
(11.2)
Here,  is the mean percentage growth rate of the stock;  is the standard deviation of the
growth rate, usually called the volatility; and Z is a normal random variable with mean 0
and standard deviation 1. Both  and  are expressed as decimals, such as   0.06 for a
6% mean growth rate, and all quantities are measured with respect to a common unit of
time, such as a year. Another way of stating Equation (11.2) is to relate the price at time t,
pt, to the price s time periods ago, pt
s:
pt  pt
s exp [( 
 0.52)s 	 Zs]
(11.3)
Essentially, the t inside the brackets in Equation (11.2) is replaced by s in Equation (11.3).
This is because the two prices in the latter equation are separated by a period of length s.
The spreadsheet in Figure 11.28 illustrates how to estimate the parameters µ and  in
Equation (11.2) from monthly returns. (See the file Stock Returns.xlsx.) You first enter
the observed closing prices of the stock in column B. The corresponding monthly returns
(percentage changes) are calculated in column C. For example, the formula in cell C6 is
=(B6–B5)/B5
11.3 Financial Models
657
The model indicated 
by Equation (11.2) or
(11.3) is called the
lognormal model of
price changes.This
model is commonly
used by financial
analysts.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
A
B
C
D
E
Esmang mean and standard deviaon of stock returns
Historical data
Month
Closing
Return
1+Return
Ln(1+Return)
0
$25.00
1
$24.70
-0.01200
0.98800
-0.01207
2
$23.70
-0.04049
0.95951
-0.04133
3
$22.90
-0.03376
0.96624
-0.03434
4
$22.81
-0.00393
0.99607
-0.00394
5
$22.89
0.00351
1.00351
0.00350
6
$22.56
-0.01442
0.98558
-0.01452
7
$23.94
0.06117
1.06117
0.05937
8
$24.37
0.01796
1.01796
0.01780
9
$24.99
0.02544
1.02544
0.02512
10
$26.09
0.04402
1.04402
0.04308
11
$26.14
0.00192
1.00192
0.00191
12
$26.90
0.02907
1.02907
0.02866
Monthly values
Mean
0.61%
StDev
2.88%
Annual values
Mean
7.33%
StDev
9.99%
Figure 11.28
Calculating Mean
and Standard
Deviation of Stock
Returns
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

The return of –0.012 corresponds to a decrease of 1.2%. You then add 1 to each return
in column C to obtain column D, and you take the natural logarithms of the numbers in
column D to obtain column E. For example, the formula in cell E6 is
=LN(D6)
The average of the numbers in column E, calculated in cell E19 with the AVERAGE
function, represents the mean monthly growth rate. Similarly, the standard deviation calcu-
lated in cell E20 represents the standard deviation of the monthly growth rate. (It can be
calculated with the STDEV or the STDEVP function with slightly different results; we
used the latter.) To obtain the mean yearly growth rate in cell E22, you multiply the mean
monthly growth rate by 12. To obtain the standard deviation of the yearly growth rate in
cell E23, you multiply the monthly standard deviation by 12
. As you can see, the esti-
mate of the mean yearly growth rate of the stock price is 7.33%. The standard deviation of
the growth rate is 9.99%.
Now that you know how analysts find the mean and standard deviation of a stock’s
growth rate, you can use Equation (11.2) or (11.3) and simulation to value certain deriva-
tive securities.3
Valuing a European Call Option
A European option on a stock gives the owner of the option the right to buy (if the option
is a call option) or sell (if the option is a put option) 100 shares of a stock on a particular
date for a particular price.4 The price at which an option holder can buy or sell the stock is
called the exercise price (or strike price) of the option. The date by which the option must
be used (or “exercised”) is called the exercise date.
For example, suppose that a stock is currently selling for $50 and you purchase a call
option with an exercise price of $56 and a three-month exercise date. What will you earn
from this option? If T represents the exercise date and pT represents the price of the stock
at time T, you will earn $0 if pT  56, and you will earn 100 (PT 
 56) if pT  56. Here is
the reasoning. If pT  56, you have the option, if you want to use it, of buying 100 shares
of stock for more than they are worth. This would be an irrational thing to do, so you will
let your option expire—without ever using it. In this case, you are “out of the money.” On
the other hand, if pT  56, you could buy 100 shares at the option price of $56, sell them
for the current price of pT , and make a profit of 100 (pT 
 56) dollars. In this case, you are
“in the money.”
We have omitted one thing, however. You must pay for the option in the first place.
The question is, what is a fair price for such an option? Because option trading is a multi-
billion-dollar business, this is an important question. Black and Scholes (1973) were the
first to derive a formula for pricing options. Shortly after that, Cox et al. (1979) derived a
different but equivalent method for pricing options. We use their method, which is based
on the following extremely important result.
Option Pricing Result 
The price of an option on a nondividend-paying stock must be the expected discounted
value of the cash flows from an option on a stock having the same standard deviation as the
stock on which the option is written and growing at the risk-free rate of interest. Here,
discounting is done continuously at the risk-free rate. (If the stock pays dividends, the
658
Chapter 11
Simulation Models
3Derivative securities get their name because their value is derived from the value of an underlying security such
as a stock. A wide variety of derivative securities are available in the market. We discuss some of the simplest
ones.
4Options are usually for 100 shares of the stock, so we will follow this convention here.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

risk-free rate should be replaced by the difference between the risk-free rate and the divi-
dend rate in what follows.)
One surprising implication of this result is that the price of the option does not depend
on the mean growth rate of the stock itself, only on the risk-free rate and the standard devi-
ation of the growth rate of the stock.
The following example illustrates how @RISK can be used to estimate the price of a
European option.
11.3 Financial Models
659
E X A M P L E
11.8 PRICING A EUROPEAN CALL OPTION
A
share of AnTech stock currently sells for $42. A European call option with an expira-
tion date of six months and an exercise price of $40 is available. The stock has an
annual standard deviation of 20%. The stock price has tended to increase at a rate of 15%
per year. The risk-free rate is 10% per year. What is a fair price for this option?
Objective
To use simulation to find the price of a European call option.
WHERE DO THE NUMBERS COME FROM?
All of this information is publicly available. The mean and standard deviation would probably
be found as in Figure 11.28 from historical stock price data. Interestingly, however, financial
analysts often infer the standard deviation of the stock’s returns from the known price of an
option on it. They call this standard deviation the implied volatility. Essentially, they “back
into” the standard deviation that must have caused the option price to be what it is.
Solution
According to the result of Cox et al., you need to know the mean of the cash flow from this
option, discounted to time 0, assuming that the stock price increases at the risk-free rate.
Therefore, you can simulate many six-month periods, each time finding the discounted
cash flow of the option. The average of these discounted cash flows represents an estimate
of the true mean—that is, it estimates the fair price of the option.
DEVELOPING THE SIMULATION MODEL
The spreadsheet model is fairly simple, as shown in Figure 11.29. (See the file European
Call.xlsx.) It can be formed as follows:
1
Inputs. Enter the inputs in the blue cells. Note that the exercise date is expressed
in years. Also, note that the mean growth rate of the stock has been entered in cell B6.
However, as noted earlier, this value is not required in the model. (It is common to refer to
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
E
D
C
B
A
Pricing a European call opon with simulaon
Input 
e
g
n
a
R
n
oitc
e
s
 names used:
Current 
4
$
B
$
!le
d
o
M
=
e
cir
p
_
t
n
e
rr
u
C
2
4
$
e
cir
p
Exercise 
9
$
B
$
!le
d
o
M
=
n
oit
a
r
u
D
0
4
$
e
cir
p
Mean annual 
5
$
B
$
!le
d
o
M
=
e
cir
p
_
e
sicr
e
x
E
%
5
1
n
r
u
t
e
r
6
$
B
$
!le
d
o
M
=
n
r
u
t
e
r
_la
u
n
n
a
_
n
a
e
M
%
0
2
ytilit
alo
V
Risk-free 
8
$
B
$
!le
d
o
M
=
e
t
a
r
_
e
e
rf
_
k
siR
%
0
1
e
t
a
r
7
$
B
$
!le
d
o
M
=
ytilit
alo
V
5.0
n
oit
a
r
u
D
Simulaon secon
Stock price in 6 months (growing at risk-free rate)
$35.15
Opon cash ﬂow at 
0
0.0
$
n
oit
a
ni
m
r
e
t
Discounted value of 
0
0.0
$
n
oit
p
o
Value of opon (average of discounted value)
$475.94
Figure 11.29
Determining the
Price of a European
Call Option
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

the standard deviation of stock returns as the volatility and the time until the exercise date
as the duration.)
2
Simulated stock price at exer cise date. Using Equation (11.2) with µ replaced by
the risk-free rate, simulate the stock price in six months by entering the formula
=Current_price*EXP((Risk_free_rate-0.5*Volatility^2)*Duration
+Volatility*RiskNormal(0,1)*SQRT(Duration)) 
in cell B12.
3
Cash flow from option. Calculate the cash flow from the option by entering the
formula
=100*MAX(B12-Exercise_price,0)
in cell B13. This says that if the future price in cell B12 is greater than the exercise price
in cell B5, you make the difference; otherwise, you never exercise the option and make
nothing. Note that you multiply by 100 because the option is for 100 shares of the stock.
4
Discount the cash flow. Discount the cash flow in cell B14 with the formula
=EXP(-Duration*Risk_free_rate)*B13
This represents the NPV of the cash flow (if any) realized at the exercise date. Because the
price of the option is the average of this discounted value, you should designate it as an
@RISK output cell.
5
Average of output cell. You can take advantage of @RISK’s RISKMEAN function
to obtain the eventual price of the option on the spreadsheet itself. To do this, enter the
formula
=RISKMEAN(B14)
in cell B16.
Running the Simulation
Because this is a small simulation model and you want an accurate average in cell B16,
you can afford to run a lot of iterations. Therefore, set the number of iterations to 10,000
and the number of simulations to 1. After running @RISK, the value $475.94 appears in
cell B16. According to the result of Cox et al., this average is an estimate of the fair price
for the option. It turns out (from the Black-Scholes formula) that $475.94 is very close to
the correct price for this option. In other words, the simulation got it almost exactly right.
This surprised us initially. After all, from basic statistical inference, it is difficult to
estimate a mean exactly. The estimated mean is usually surrounded by 95% confidence
limits to indicate the level of accuracy. However, the effect of using Latin Hypercube sam-
pling is that means can be estimated much more accurately. With 10,000 iterations, the cor-
rect answer is evidently obtained to within a few pennies!
■
We now extend the previous example by simulating a portfolio that includes a com-
pany’s stock and a call option on that stock.
660
Chapter 11
Simulation Models
E X A M P L E
11.9 RETURN ON A PORTFOLIO WITH A STOCK
AND AN OPTION ON THE STOCK
S
uppose the investor buys 100 shares of AnTech stock at the current price and one call
option on this stock for $475.94, the fair price found in the previous example. Use sim-
ulation to find the return on the investor’s portfolio as of the exercise date.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Objective
To use simulation to evaluate a portfolio containing the stock and a call option
on the stock.
WHERE DO THE NUMBERS COME FROM?
Although simulation was used in the previous example to find the price of the option, this
price is quoted publicly, as is the price of the stock.
Solution
The purpose of this simulation is totally different from the previous example. This time,
the purpose is to simulate the behavior of a portfolio. Therefore, you should now let the
stock price grow at its mean rate, not the risk-free rate, to generate the stock price in six
months. The rest is basically bookkeeping.
DEVELOPING THE SIMULATION MODEL
The spreadsheet model appears in Figure 11.30. (See the file OptionPortfolio.xlsx.) The
model can be developed as follows:
11.3 Financial Models
661
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
E
D
C
B
A
Return on a porolio with stock and a call opon on the stock
Input 
e
g
n
a
R
n
oitc
e
s
 names used:
Current 
4
$
B
$
!le
d
o
M
=
e
cir
p
_
t
n
e
rr
u
C
2
4
$
e
cir
p
Exercise 
9
$
B
$
!le
d
o
M
=
n
oit
a
r
u
D
0
4
$
e
cir
p
Mean annual 
5
$
B
$
!le
d
o
M
=
e
cir
p
_
e
sicr
e
x
E
%
5
1
n
r
u
t
e
r
6
$
B
$
!le
d
o
M
=
n
r
u
t
e
r
_la
u
n
n
a
_
n
a
e
M
%
0
2
ytilit
alo
V
Risk-free 
2
1
$
B
$
!le
d
o
M
=
e
cir
p
_
n
oit
p
O
%
0
1
e
t
a
r
1
1
$
B
$
!le
d
o
M
=
d
e
s
a
h
cr
u
p
_
s
n
oit
p
O
5.0
n
oit
a
r
u
D
Shares 
8
$
B
$
!le
d
o
M
=
e
t
a
r
_
e
e
rf
_
k
siR
0
0
1
d
e
s
a
h
cr
u
p
Opons 
0
1
$
B
$
!le
d
o
M
=
d
e
s
a
h
cr
u
p
_
s
e
r
a
h
S
1
d
e
s
a
h
cr
u
p
Opon 
7
$
B
$
!le
d
o
M
=
ytilit
alo
V
4
9.5
7
4
$
e
cir
p
Simulaon secon
Stock price in 6 months (growing at stock's rate)
$41.19
Cash ﬂow at terminaon for opon
$118.53
Ending porolio 
6
0.7
3
2,4
$
e
ula
v
Investment 
4
9.5
7
6,4
$
ts
o
c
Porolio return
-9.39%
Summary measures from @RISK (based on 10,000 iteraons)
Mean return
9 4%
23
24
25
26
27
28
29
Mean return
9.4%
Stdev of 
%
5.5
2
n
r
u
t
e
r
Min return
-49.0%
Max 
%
0.0
4
1
n
r
u
t
e
r
5th percenle of return
-24.0%
95th percenle of 
%
4.6
5
n
r
u
t
e
r
Probability of a posive 
1
9
5.0
n
r
u
t
e
r
Figure 11.30
Simulating a
Portfolio Return
Containing a Call
Option
1
Inputs. Enter the values in the shaded range. These are the same as before, but they
now include the known price of the call option. The number of shares purchased and the
number of options purchased are also included. This adds some flexibility to the model.
2
Future stock price. Generate the random stock price in six months in cell B15 with
the formula
=Current_price*EXP((Mean_annual_return-0.5*Volatility^2)*Duration 
+Volatility*RiskNormal(0,1)*SQRT(Duration))
This again uses Equation (11.2), but it uses the stock’s mean growth rate, not the risk-free
rate, for .
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

3
Option cash flo w. Calculate the cash flow from the option exactly as before by
entering the formula
=100*MAX(B15-Exercise_price,0)
in cell B16.
4
Portfolio value. In six months, the portfolio will be worth the value of the stock plus
the cash flow from the option. Calculate this in cell B18 with the formula
=SUMPRODUCT(B10:B11,B15:B16)
Then in cells B19 and B20, calculate the amount paid for the portfolio and its return (the
percentage change) with the formulas
=Shares_purchased*Current_price+Options_purchased*Option_price
and
=(B18-B19)/B19
Then designate cell B20 as an @RISK output cell.
5
@RISK summary statistics. You can again show the basic summary results from
@RISKonthespreadsheetbyusingitsRISKMEAN,RISKSTDDEV,RISKMIN,RISKMAX,
RISKPERCENTILE, and RISKTARGET functions. For example, the formulas in cells B27
and B29 are
=RISKPERCENTILE(B20,0.05)
and
=1-RISKTARGET(B20,0)
USING @RISK
After running @RISK for 10,000 iterations, we obtain the values in the range B23:B29 of
Figure 11.30. The mean return from this portfolio is about 9.4%, but there is considerable
variability. There is a 5% chance that it will lose at least 24%, and there is a 5% chance 
that it will gain at least 56.4%. The probability that it will provide a positive return is 
about 0.59.
If you have any intuition for financial portfolios, you have probably noticed that this
investor is “putting all her eggs in one basket.” If the stock price increases, she gains by
owning the shares of stock, and she also gains from holding the options (because she is
more likely to be “in the money”). However, if the price of the stock decreases, she loses
money on her shares of stock, and her options are worthless. A safer strategy is to hedge
her bets. She can purchase 100 shares of the stock and purchase one put option on the
stock. A put option allows her to sell shares of stock for the exercise price at the exercise
date. With a put option, the investor hopes the stock price will decrease because she can
then sell her shares at the exercise price and immediately buy them back at the decreased
stock price, thus earning a profit. Therefore, a portfolio consisting of shares of stock and
put options on the stock covers the investor in both directions. It has less upside potential,
but it decreases the downside risk.
■
Valuing a More Exotic Call Option
The European call option is fairly simple. A variety of other derivative securities are cur-
rently available. In fact, their variety and complexity are what make them attractive—and
dangerous for the unsuspecting investor. We illustrate one variation of the basic call
662
Chapter 11
Simulation Models
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

option, an Asian option. Its payoff depends, not on the price at expiration of the underly-
ing stock, but on the average price of the stock over the lifetime of the option. That is, if
the exercise price of the option is pe, and the average price of the stock over the lifetime
of the option is pavg, then the payoff at the expiration date from the option is the larger of
pavg 
 pe and 0.
To price an Asian option (or any number of other exotic options), you again find the
expected discounted value of the cash flow from the option, assuming that the stock grows
at the risk-free rate. The following example illustrates how to approximate this expected
value with simulation.
11.3 Financial Models
663
E X A M P L E
11.10 PRICING AN ASIAN OPTION
C
onsider a stock currently priced at $100 per share. Its mean annual return is 15%, and
the standard deviation of its annual return is 30%. What is the value of an Asian option
that expires in 52 weeks (one year) with an exercise price of $110? Assume that the risk-
free rate is 9%.
Objective
To use simulation to estimate the price of a more exotic call option.
WHERE DO THE NUMBERS COME FROM?
Again, all of the given data is publicly available.
Solution
To value this option, base pavg on the average of the weekly (simulated) stock prices,
assuming that the stock price grows at the risk-free rate. This requires you to generate
weekly stock prices from Equation (11.3), using s  1/52. That is, you simulate any
week’s price from the previous week’s price. These two prices are separated by a week, or
1/52 of a year, which means that you should use s  1/52 in Equation (11.3).
DEVELOPING THE SIMULATION MODEL
The spreadsheet model appears in Figure 11.31. (See the file Asian Option.xlsx.) The
model can be developed as follows:
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
55
56
57
I
H
G
F
E
D
C
B
A
Pricing an Asian call opon with simulaon
Input 
ylk
e
e
W
n
oitc
e
s
 prices (growing at risk-free rate)
Range names used:
Current 
d
e
t
alu
m
iS
k
e
e
W
0
0
1
$
e
cir
p
 price
Current_price
=Model!$B$4
Exercise 
9
$
B
$
!le
d
o
M
=
n
oit
a
r
u
D
0
0.0
0
1
$
0
0
1
1
$
e
cir
p
Mean annual 
5
$
B
$
!le
d
o
M
=
e
cir
p
_
e
sicr
e
x
E
2
2.1
1
1
$
1
%
5
1
n
r
u
t
e
r
6
$
B
$
!le
d
o
M
=
n
r
u
t
e
r
_la
u
n
n
a
_
n
a
e
M
4
9.4
1
1
$
2
%
0
3
ytilit
alo
V
Risk-free 
8
$
B
$
!le
d
o
M
=
e
t
a
r
_
e
e
rf
_
k
siR
1
2.1
1
1
$
3
%
0.9
e
t
a
r
7
$
B
$
!le
d
o
M
=
ytilit
alo
V
1
7.9
1
1
$
4
0.1
n
oit
a
r
u
D
5
$116.78
Simulaon secon
6
$113.28
Average of weekly prices
$115.065
7
$111.90
Opon cash ﬂow at 
2
5.4
1
1
$
8
8
6
4.6
0
5
$
n
oit
a
ni
m
r
e
t
Discounted value of 
2
8.0
1
1
$
9
7
7
8.2
6
4
$
n
oit
p
o
10
$105.90
Value of opon (average of discounted value)
$458.10
11
$113.57
12
$111.50
13
$114.62
50
$101.17
51
$104.43
52
$103.31
Figure 11.31 Determining the Price of an Asian Option
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

1
Inputs. Enter the inputs in the blue range. As in the valuation of the European call
option, the mean growth rate of the stock is entered in cell B6 even though it is not used in
the simulation.
2
Weekly prices. Enter the initial price (week 0) in cell E5 with the formula
=Current_price
Then to generate each weekly price from the previous one, enter the formula
=E5*EXP((Risk_free_rate-0.5*Volatility^2)*(1/52)
+Volatility*RiskNormal(0,1)*SQRT(1/52))
in cell E6 and copy it to the range E7:E57. Again, this is based on Equation (11.3) with
s  1/52.
3
Discounted value of option. Enter the formulas
=AVERAGE(E5:E57)
=100*MAX(B12-Exercise_price,0)
and
=EXP(-Duration*Risk_free_rate)*B13
in cells B12, B13, and B14. These are exactly as in the European call option example,
except that the payoff in cell B13 is based on the average in cell B12, not on the ending
price of the stock. Then designate cell B14 as the @RISK output cell, because the price of
the option is estimated by the average value in this cell.
4
Average of output cell. To show the main @RISK summary measure in the spread-
sheet itself, enter the formula
=RISKMEAN(B14)
in cell B16.
Running the Simulation
After running @RISK for 10,000 iterations, the value in cell B16 is $458.10. This is the
estimated price of this Asian option. (The actual market price of this particular option is
about $468, pretty close to the estimate. You could have gotten a slightly more accurate
estimate of the actual price by running more iterations with @RISK.)
■
664
Chapter 11
Simulation Models
P R O B L E M S
Skill-Building Problems
9.
Rerun the new car simulation from Example 11.5, but
now introduce uncertainty into the fixed development
cost. Let it be triangularly distributed with parameters
$600 million, $650 million, and $850 million. (You
can check that the mean of this distribution is $700
million, the same as the cost given in the example.)
Comment on the differences between your output and
those in the example. Would you say these differences
are important for the company?
10. Rerun the new car simulation from Example 11.5, but
now use the RISKSIMTABLE function appropriately
to simulate discount rates of 5%, 7.5%, 10%, 12.5%,
and 15%. Comment on how the outputs change as the
discount rate decreases from the value used in the
example, 10%.
11. In the cash balance model from Example 11.6, the
timing is such that some receipts are delayed by one
or two months, and the payments for materials and
labor must be made a month in advance. Change the
model so that all receipts are received immediately,
and payments made this month for materials and
labor are 80% of sales this month (not next month).
The period of interest is again January through June.
Rerun the simulation, and comment on any
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

differences between your outputs and those from the
example.
12. In the cash balance model from Example 11.6, is the
$250,000 minimum cash balance requirement really
“costing” the company very much? Answer this by
rerunning the simulation with minimum required cash
balances of $50,000, $100,000, $150,000, and
$200,000. Use the RISKSIMTABLE function to run
all simulations at once. Comment on the outputs from
these simulations. In particular, comment on whether
the company appears to be better off with a lower
minimum cash balance.
13. Run the retirement model from Example 11.7 with a
damping factor of 1.0 (instead of 0.98), again using
the same three sets of investment weights. Explain in
words what it means, in terms of the simulation, to
have a damping factor of 1. Then comment on the
differences, if any, between your simulation results
and those in the example.
14. The simulation output from Example 11.7 indicates
that an investment heavy in stocks produces the best
results. Would it be better to invest entirely in stocks?
Answer this by rerunning the simulation. Is there any
apparent downside to this strategy?
15. Modify the model from Example 11.7 so that you use
only the years 1975 to 2007 of historical data. Run the
simulation for the same three sets of investment
weights. Comment on whether your results differ in
any important way from those in the example.
16. Referring to the retirement example in Example 11.7,
rerun the model for a planning horizon of 10 years;
15 years; 25 years. For each, which set of investment
weights maximizes the VAR 5% (the 5th percentile) of
final cash in today’s dollars? Does it appear that a
portfolio heavy in stocks is better for long horizons but
not for shorter horizons?
17. A European put option allows an investor to sell a
share of stock at the exercise price on the exercise data.
For example, if the exercise price is $48, and the stock
price is $45 on the exercise date, the investor can sell
the stock for $48 and then immediately buy it back
(that is, cover his position) for $45, making $3 profit.
But if the stock price on the exercise date is greater
than the exercise price, the option is worthless at that
date. So for a put, the investor is hoping that the price
of the stock decreases. Using the same parameters as
in Example 11.8, find a fair price for a European put
option. (Note: As discussed in the text, an actual put
option is usually for 100 shares.)
18. Modify Example 11.9 so that the portfolio now con-
tains 100 shares of stock and one put option on the
stock with the same parameters as in the example.
You can assume that the price of an option is $81.
Discuss in a brief memo how this portfolio differs
from the portfolio in the example.
Skill-Extending Problems
19. Change the new car simulation from Example 11.5 as
follows. It is the same as before for years 1 through
5, including depreciation through year 5. However,
the car might sell through year 10. Each year after
year 5, the company examines sales. If fewer than
45,000 cars were sold that year, there is a 50%
chance the car won’t be sold after that year. Modify
the model and run the simulation. Keep track of two
outputs: NPV (through year 10) and the number of
years of sales.
20. Based on Kelly (1956). You currently have $100. Each
week you can invest any amount of money you
currently have in a risky investment. With probability
0.4, the amount you invest is tripled (e.g., if you invest
$100, you increase your asset position by $300), and,
with probability 0.6, the amount you invest is lost.
Consider the following investment strategies:
■Each week, invest 10% of your money.
■Each week, invest 30% of your money.
■Each week, invest 50% of your money.
Use @RISK to simulate 100 weeks of each strategy
1000 times. Which strategy appears to be best in terms
of the maximum growth rate? (In general, if you can
multiply your investment by M with probability p and
lose your investment with probability q  1 
 p, you
should invest a fraction [p(M – 1) – q]/(M – 1) of your
money each week. This strategy maximizes the expected
growth rate of your fortune and is known as the Kelly
criterion.) (Hint: If an initial wealth of I dollars grows to
F dollars in 100 weeks, the weekly growth rate, labeled
r, satisfies F  (1 	 r)100*I, so that r  (F/I)1/100 – 1.)
21. Amanda has 30 years to save for her retirement. At the
beginning of each year, she puts $5000 into her
retirement account. At any point in time, all of
Amanda’s retirement funds are tied up in the stock
market. Suppose the annual return on stocks follows a
normal distribution with mean 12% and standard
deviation 25%. What is the probability that at the end
of 30 years, Amanda will have reached her goal of
having $1,000,000 for retirement? Assume that if
Amanda reaches her goal before 30 years, she will
stop investing. (Hint: Each year you should keep track
of Amanda’s beginning cash position—for year 1, this
is $5000—and Amanda’s ending cash position. Of
course, Amanda’s ending cash position for a given
year is a function of her beginning cash position and
the return on stocks for that year. To estimate the
probability that Amanda meets her goal, use an IF
statement that returns 1 if she meets her goal and
0 otherwise.)
11.3 Financial Models
665
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

22. In the financial world, there are many types of
complex instruments called derivatives that derive
their value from the value of an underlying asset.
Consider the following simple derivative. A stock’s
current price is $80 per share. You purchase a
derivative whose value to you becomes known a
month from now. Specifically, let P be the price of the
stock in a month. If P is between $75 and $85, the
derivative is worth nothing to you. If P is less than
$75, the derivative results in a loss of 100*(75-P)
dollars to you. (The factor of 100 is because many
derivatives involve 100 shares.) If P is greater than
$85, the derivative results in a gain of 100*(P-85)
dollars to you. Assume that the distribution of the
change in the stock price from now to a month from
now is normally distributed with mean $1 and
standard deviation $8. Let EMV be the expected
gain/loss from this derivative. It is a weighted average
of all the possible losses and gains, weighted by their
likelihoods. (Of course, any loss should be expressed
as a negative number. For example, a loss of $1500
should be expressed as -$1500.) Unfortunately, this is
a difficult probability calculation, but EMV can be
estimated by an @RISK simulation. Perform this
simulation with at least 1000 iterations. What is your
best estimate of EMV?
23. Suppose you currently have a portfolio of three stocks,
A, B, and C. You own 500 shares of A, 300 of B, and
1000 of C. The current share prices are $42.76,
$81.33, and $58.22, respectively. You plan to hold this
portfolio for at least a year. During the coming year,
economists have predicted that the national economy
will be awful, stable, or great with probabilities 0.2,
0.5, and 0.3. Given the state of the economy, the
returns (one-year percentage changes) of the three
stocks are independent and normally distributed.
However, the means and standard deviations of these
returns depend on the state of the economy, as
indicated in the file P11_23.xlsx.
a. Use @RISK to simulate the value of the portfolio
and the portfolio return in the next year. How likely
is it that you will have a negative return? How likely
is it that you will have a return of at least 25%?
b. Suppose you had a crystal ball where you could
predict the state of the economy with certainty. The
stock returns would still be uncertain, but you
would know whether your means and standard
deviations come from row 6, 7, or 8 of the
P11_23.xlsx file. If you learn, with certainty, that
the economy is going to be great in the next year,
run the appropriate simulation to answer the same
questions as in part a. Repeat this if you learn that
the economy is going to be awful. How do these
results compare with those in part a?
24. If you own a stock, buying a put option on the stock
will greatly reduce your risk. This is the idea behind
portfolio insurance. To illustrate, consider a stock that
currently sells for $56 and has an annual volatility of
30%. Assume the risk-free rate is 8%, and you esti-
mate that the stock’s annual growth rate is 12%.
a. Suppose you own 100 shares of this stock. Use
simulation to estimate the probability distribution
of the percentage return earned on this stock during
a one-year period.
b. Now suppose you also buy a put option (for $238)
on the stock. The option has an exercise price of
$50 and an exercise date one year from now. Use
simulation to estimate the probability distribution
of the percentage return on your portfolio over a
one-year period. Can you see why this strategy is
called a portfolio insurance strategy?
c. Use simulation to show that the put option should,
indeed, sell for about $238.
25. For the data in the previous problem, the following is
an example of a butterfly spread: sell two calls with an
exercise price of $50, buy one call with an exercise
price of $40, and buy one call with an exercise price of
$60. Simulate the cash flows from this portfolio.
26. A stock currently sells for $69. The annual growth rate
of the stock is 15%, and the stock’s annual volatility is
35%. The risk-free rate is currently 5%. You have
bought a six-month European put option on this stock
with an exercise price of $70.
a. Use @RISK to value this option.
b. Use @RISK to analyze the distribution of
percentage returns (for a six-month horizon) for the
following portfolios:
■Portfolio 1: Own 100 shares of the stock.
■Portfolio 2: Own 100 shares of the stock and
buy the put described in part a.
Which portfolio has the larger expected return?
Explain why portfolio 2 is known as portfolio
insurance.
27. A knockout call option loses all value at the instant the
price of the stock drops below a given “knockout
level.” Determine a fair price for a knockout call option
when the current stock price is $20, the exercise price
is $21, the knockout price is $19.50, the mean annual
growth rate of the stock is 12%, the annual volatility is
40%, the risk-free rate is 10%, and the exercise date
is one month from now (where you can assume there
are 21 trading days in the month and 250 in a year).
28. Suppose an investor has the opportunity to buy the fol-
lowing contract (a stock call option) on March 1. The
contract allows him to buy 100 shares of ABC stock at
the end of March, April, or May at a guaranteed price
of $50 per share. He can exercise this option at most
once. For example, if he purchases the stock at the
end of March, he cannot purchase more in April or
May at the guaranteed price. If the investor buys the
contract, he is hoping that the stock price will go up.
666
Chapter 11
Simulation Models
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

11.4 Marketing Models
667
The reasoning is that if he buys the contract, the price
goes up to $51, and he buys the stock (that is, he exer-
cises his option) for $50, he can then sell the stock for
$51 and make a profit of $1 per share. Of course, if the
stock price goes down, he doesn’t have to exercise his
option; he can just throw the contract away.
Assume that the stock price change each month
is normally distributed with mean 0 and standard
deviation 2. The investor uses the following strategy.
At the end of March, he exercises the option only if
the stock price is above $51.50. At the end of April, he
exercises the option (assuming he hasn’t exercised it
yet) only if the price is above $50.75. At the end of
May, he exercises the option (assuming he hasn’t
exercised it yet) only if the price is above $50.00.
(This isn’t necessarily his best strategy, but it is a rea-
sonable one.) Simulate 250 replications of this strategy
and answer the following:
a. Estimate the probability that he will exercise his
option.
b. Estimate his net profit with this strategy. (This
doesn’t include the price of the contract.)
c. Estimate the probability that he will net over $300.
d. Estimate the worth of this contract to him.
11.4 MARKETING MODELS
There are plenty of opportunities for marketing departments to use simulation. They face
uncertainty in the brand-switching behavior of customers, the entry of new brands into the mar-
ket, customer preferences for different attributes of products, the effects of advertising on sales,
and so on. We examine some interesting marketing applications of simulation in this section.
11.4.1 Models of Customer Loyalty
What is a loyal customer worth to a company? This is an extremely important question for
companies. (It is an important part of customer relationship management, or CRM, cur-
rently one of the hottest topics in marketing.) Companies know that if customers become
dissatisfied with the company’s product, they are likely to switch and never return.
Marketers refer to this customer loss as churn. The loss in profit from churn can be large,
particularly because long-standing customers tend to be more profitable in any given year
than new customers. The following example uses a reasonable model of customer loyalty
and simulation to estimate the worth of a customer to a company. It is based on the excel-
lent discussion of customer loyalty in Reichheld (1996).
E X A M P L E
11.11 THE LONG-TERM VALUE OF A CUSTOMER AT CCAMERICA
C
CAmerica is a credit card company that does its best to gain customers and keep their
business in a highly competitive industry. The first year a customer signs up for service
typically results in a loss to the company because of various administrative expenses.
However, after the first year, the profit from a customer is typically positive, and this profit
tends to increase through the years. The company has estimated the mean profit from a typical
customer to be as shown in column B of Figure 11.32. For example, the company expects to
lose $40 in the customer’s first year but to gain $87 in the fifth year—provided that the cus-
tomer stays loyal that long. For modeling purposes, we assume that the actual profit from a
customer in the customer’s nth year of service is normally distributed with mean shown in
Figure 11.32 and standard deviation equal to 10% of the mean. At the end of each year, the
customer leaves the company, never to return, with probability 0.15, the churn r ate.
Alternatively, the customer stays with probability 0.85, the retention rate. The company wants
to estimate the NPV of the net profit from any such customer who has just signed up for ser-
vice at the beginning of year 1, at a discount rate of 15%, assuming that the cash flow occurs
in the middle of the year.5 It also wants to see how sensitive this NPV is to the retention rate.
5This assumption makes the NPV calculation slightly more complex, but it is probably more realistic than the
usual assumption that cash flows occur at the ends of the years.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

668
Chapter 11
Simulation Models
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
B
A
Year
Mean Proﬁt(if sll here)
1
($40.00)
2
$66.00
3
$72.00
4
$79.00
5
$87.00
6
$92.00
7
$96.00
8
$99.00
9
$103.00
10
$106.00
11
$111.00
12
$116.00
13
$120.00
14
$124.00
15
$130.00
16
$137.00
17
$142.00
18
$148.00
19
$155.00
20
$161.00
21
$161.00
22
$161.00
23
$161.00
24
$161 00
34
35
36
37
38
39
40
24
$161.00
25
$161.00
26
$161.00
27
$161.00
28
$161.00
29
$161.00
30
$161.00
Figure 11.32
Mean Profit as a
Function of Years as
Customer
Objective
To use simulation to find the NPV of a customer and to see how this varies
with the retention rate.
WHERE DO THE NUMBERS COME FROM?
The numbers in Figure 11.32 are undoubtedly averages, based on the historical records of
many customers. To build in randomness for any particular customer, we need a probabil-
ity distribution around the numbers in this figure. We arbitrarily chose a normal distribu-
tion centered on the historical average and a standard deviation of 10% of the average.
These are educated guesses. Finally, the churn rate is a number very familiar to marketing
people, and it can also be estimated from historical customer data.
Solution
The idea is to keep simulating profits (or a loss in the first year) for the customer until the
customer churns. We simulate 30 years of potential profits, but this could be varied.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

11.4 Marketing Models
669
DEVELOPING THE SIMULATION MODEL
The simulation model appears in Figure 11.33. (See the file Customer Loyalty.xlsx.) It
can be developed with the following steps.
1
Inputs. Enter the inputs in the blue cells.
2
Retention rate. Although an 85% retention rate was given in the statement of the
problem, it is useful to investigate retention rates from 75% to 95%, as shown in column D.
To run a separate simulation for each of these, enter the formula
RISKSIMTABLE(D4:D8)
in cell B4.
3
Timing of chur n. In column C, use simulation to discover when the customer
churns. This column will contain a sequence of No values, followed by a Yes, and then a
sequence of blanks (or all No values if the customer never churns). To generate these, enter
the formulas
IF(RAND()1–B4,"Yes","No")
and
IF(OR(C11"",C11"Yes"),"",IF(RAND()1–$B$4,"Yes","No"))
in cells C11 and C12, and copy the latter formula down column C. Study these formulas
carefully to see how the logic works. Note that they do not rely on @RISK functions.
Excel’s RAND function can be used any time you want to simulate whether or not an event
occurs.
4
Actual and discounted profits. Profits (or a loss in the first year) occur as long as
there is not a blank in column C. Therefore, simulate the actual profits by entering the
formula
IF(C11"",RISKNORMAL(B11,$B$6*ABS(B11)),0)
As usual, Excel’s 
RAND function can 
be used inside an 
IF statement to 
determine whether 
a given event occurs.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
38
39
40
J
I
H
G
F
E
D
C
B
A
Customer loyalty model in the credit card industry
n
oit
n
e
t
e
R
st
u
p
n
I
 rates to try
Retenon 
5
7.0
5
7.0
e
t
a
r
Discount 
0
8.0
5
1.0
e
t
a
r
Stdev as % of 
5
8.0
%
0
1
n
a
e
m
0.90
0.95
Simulaon
Outputs
Year
Mean Proﬁt(if sll here)
Quits at end of year?
Actual proﬁt
Discounted proﬁt
NPV
$348.86
1
($40.00)
No
($45.70)
($42.61)
Years loyal
10
2
$66.00
No
$64.32
$52.15
3
$72.00
No
$71.70
$50.55
Means
4
$79.00
No
$86.56
$53.07
Simulaon
Retenon rate
NPV
Years loyal
5
$87.00
No
$86.34
$46.04
1
0.75
$101.47
4.08
6
$92.00
No
$100.87
$46.77
2
0.80
$129.03
4.86
7
$96.00
No
$101.92
$41.09
3
0.85
$185.57
6.80
8
$99.00
No
$99.72
$34.96
4
0.90
$251.28
9.59
9
$103.00
No
$123.92
$37.77
5
0.95
$365.89
15.77
10
$106.00
Yes
$109.67
$29.07
0
0.0
$
0
0.0
$
0
0.1
1
1
$
1
1
0
0.0
$
0
0.0
$
0
0.1
6
1
$
8
2
0
0.0
$
0
0.0
$
0
0.1
6
1
$
9
2
0
0.0
$
0
0.0
$
0
0.1
6
1
$
0
3
Figure 11.33 Customer Loyalty Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

in cell D11 and copying it down. (The absolute value function, ABS, is required in
case any of the cash flows are negative. A normal distribution cannot have a negative
standard deviation.) Then discount these appropriately in column E by entering the
formula
D11/(1	$B$5)^(A11–0.5)
in cell E11 and copying it down. Note how the exponent of the denominator accounts for
the cash flow in the middle of the year.
5
Outputs. Keep track of two outputs, the total NPV and the number of years the cus-
tomer stays with the company. Calculate the NPV in cell H10 by summing the discounted
values in column E. (They have already been discounted, so the NPV function is not
needed.) To find the number of years the customer is loyal, count the number of No values
plus the number of Yes values, that is, all non-blanks. Calculate this in cell H11 with the
formula
COUNTIF(C11:C40,"No")	COUNTIF(C11:C40,"Yes")
Finally, designate both of cells H10 and H11 as @RISK output cells.
Running the Simulation
Set the number of iterations to 1000 and the number of simulations to 5 (one for each
potential retention rate). Then run the simulation as usual. (Actually, we ran 5000 itera-
tions for each simulation, just to get more stable results.)
Discussion of the Simulation Results
Summary results for all five retention rates and the histogram for an 85% retention rate
appear in Figures 11.34 and 11.35. The histogram indicates that there is a 14.4% chance
that the NPV will be negative, whereas the chance that it will be above $300 is 27.3%. You
can also see from the summary measures that the mean NPV and the mean number of years
loyal are quite sensitive to the retention rate.
To follow up on this observation, you can use the RISKMEAN function to capture the
means in columns I and J of the model sheet and then create a line chart of them as a func-
tion of the retention rate. (See Figure 11.36.) This line chart shows the rather dramatic
effect the retention rate can have on the value of a customer. For example, if it increases
from the current 85% to 90%, the mean NPV increases by about 35%. If it increases from
670
Chapter 11
Simulation Models
Careful discounting is
required if cash flows
occur in the middle 
of a year.
Figure 11.34 Summary Results for Customer Loyalty Model
Varying the retention 
rate can have a large
impact on the value 
of a customer.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

85% to 95%, the mean NPV increases by about 97%. In the other direction, if the retention
rate decreases from 85% to 80%, the mean NPV decreases by about 30%. This is why
credit card companies are so anxious to keep their customers.
■
The following example is a variation of the previous example. We now investigate the
effect of offering a customer an incentive to remain loyal.
11.4 Marketing Models
671
Figure 11.35
Histogram of NPV
for an 85%
Retention Rate
50
100
150
200
250
300
350
400
NPV
Years loyal
0
50
100
150
200
250
300
350
400
0.70
0.75
0.80
0.85
0.90
0.95
1.00
Retenon rate
Sensivity to Retenon Rate
Sensivity to Retenon Rate
NPV
Years loyal
Figure 11.36
Sensitivity of
Outputs to the
Retention Rate
E X A M P L E
11.12 THE VALUE OF A FREE MAINTENANCE AGREEMENT
C
ompanies value loyal customers, and they sometimes go to great lengths to keep
their customers loyal. This example investigates whether one such plan is worth its
cost. We consider a nationwide company called Jamesons, which sells electronic appli-
ances. Specifically, we will focus on sales of DVD players. To attract customers, the
company is considering giving customers a free maintenance agreement with each
purchase of a DVD player. The unit profit without free maintenance is currently $20.
The company believes this will decrease to $16 with free maintenance. Their thinking is
that about 4% of customers will actually use the free maintenance, and for each such
customer, the company will lose about $100. Hence the average decrease in profit per
purchaser is about $4.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

672
Chapter 11
Simulation Models
Prior to this year, 50,000 customers were loyal to Jamesons and 100,000 customers
were loyal to their competitors. (Loyalty is defined in terms of where the customer
bought his or her last DVD player.) There are a number of uncertain quantities, and we
assume they are all triangularly distributed. Their parameters (minimum, most likely,
and maximum) are as follows. (1) The percentage of the 150,000 customers who pur-
chase a DVD player in any given year has parameters 20%, 25%, and 40%. (2) The
annual percentage change in unit profit has parameters 3%, 5%, and 6%. (3) In any year,
the percentage of Jamesons’ loyal customers who remain loyal has parameters 56%,
60%, and 66% if there is no free maintenance, and they increase to 60%, 64%, and 70%
with free maintenance. (4) Similarly, the percentage of the competitors’ loyal customers
who switch to Jamesons has parameters 27%, 30%, and 34% if there is no free mainte-
nance, and they increase to 32%, 35%, and 39% with free maintenance. These inputs are
listed in the file Free Maintenance.xlsx and are shown in Figure 11.37.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
F
E
D
C
B
A
Free maintenance agreement - is it worth it?
Common inputs
Loyal customers in previous year
To our 
0
0
0
0
5
d
n
a
r
b
To their 
0
0
0
0
0
1
d
n
a
r
b
Percentage of potenal customers who purchase in any year (triangular distribuon)
%
0
2
m
u
m
ini
M
Most 
%
5
2
yle
kil
%
0
4
m
u
m
ix
a
M
Annual percentage growth in proﬁt contribuon (triangular distribuon)
%
3
m
u
m
ini
M
Most 
%
5
yle
kil
%
6
m
u
m
ix
a
M
Discount 
%
0
1
e
t
a
r
Inputs that depend on policy
Not free
Free
Unit 
6
1
$
0
2
$
tif
o
r
p
Percentage of our loyal customers who remain loyal (triangular distribuon)
%
0
6
%
6
5
m
u
m
ini
M
Most likely
60%
64%
25
26
27
28
29
30
31
Most likely
60%
64%
%
0
7
%
6
6
m
u
m
ix
a
M
Percentage of their loyal customers who switch to us (triangular distribuon)
%
2
3
%
7
2
m
u
m
ini
M
Most 
%
5
3
%
0
3
yle
kil
%
9
3
%
4
3
m
u
m
ix
a
M
Figure 11.37
Inputs for Free
Maintenance
Example
Jamesons is hoping that the decrease in unit profit from the free maintenance agree-
ment will be more than offset by the higher loyalty percentages. Using a 15-year plan-
ning horizon, does the NPV of profits with a 10% discount rate confirm the company’s
hopes?
Objective
To use simulation to see whether it makes sense for Jamesons to give a free
maintenance agreement to DVD player purchasers.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

11.4 Marketing Models
673
WHERE DO THE NUMBERS COME FROM?
In the previous example we discussed the switching rates, which would be estimated from
extensive customer data. The other data in the problem statement are straightforward to
obtain.
Solution
The solution strategy is to compare two simulations, one without free maintenance and
one with it. Because they are so similar, you can use RISKSIMTABLE to run both sim-
ulations. We make one assumption that is common in marketing but might not be intu-
itive. We assume that only purchasers in a given year have any chance of switching
loyalty in the next year. For example, if a customer is loyal to Jamesons and doesn’t pur-
chase a DVD player in a given year, this customer is automatically loyal to Jamesons in
the next year.
DEVELOPING THE SIMULATION MODEL
The completed simulation model appears in Figure 11.38. (Again, see the first finished
version of the file Free Maintenance.xlsx.) It can be developed with the following steps.
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
Q
P
O
N
M
L
K
J
I
H
G
F
E
D
C
B
A
Simulaon
Index of 
1
n
oit
alu
m
is
Year
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
Percentage loyal to us who purchase
24.0%
25.7%
31.2%
25.8%
31.1%
29.7%
26.3%
25.0%
21.7%
30.0%
27.0%
23.4%
23.0%
31.5%
26.7%
22.1%
Percentage loyal to them who purchase
25.6%
30.7%
22.9%
22.6%
25.9%
33.4%
25.0%
34.5%
30.3%
34.3%
32.0%
23.3%
25.0%
28.6%
35.9%
21.0%
Percentage who stay loyal to us
63.8%
58.3%
59.3%
61.1%
59.7%
64.8%
56.8%
59.5%
59.3%
64.2%
58.2%
57.5%
58.4%
59.4%
61.8%
Percentage who switch loyalty to us
30.1%
30.1%
28.8%
29.6%
31.5%
27.6%
29.6%
29.5%
30.1%
30.9%
33.1%
30.4%
27.2%
32.4%
32.3%
Customers loyal to 
6
5
6
5
2
5
3
3
5
0
0
0
0
5
s
u
4
55537
56292
56890
59521
59446
62649
65090
67113
68341
67329
66526
65739
68804
Customers loyal to 
0
0
0
0
1
m
e
h
t
0
96648
93436
94463
93708
93110
90479
90554
87351
84910
82887
81659
82671
83474
84261
81196
Purchases of our product
13719
17672
14350
17506
16907
15645
14875
13611
19515
18092
15974
15461
20970
17532
15184
Percentage change in unit proﬁt
4.93%
4.90%
4.43%
4.69%
5.27%
3.72%
3.61%
4.99%
4.76%
4.72%
4.64%
4.78%
4.74%
4.92%
Unit proﬁt 
$20.00
$20.99
$22.01
$22.99
$24.07
$25.34
$26.28
$27.23
$28.59
$29.95
$31.36
$32.82
$34.39
$36.02
$37.79
Proﬁt 
8
3,4
7
2
$
n
oit
u
birt
n
o
c
1 $370,853 $315,912 $402,460 $406,921 $396,411 $390,929 $370,609 $557,925 $541,845 $500,993 $507,420 $721,155 $631,471 $573,808
3
4,3
1
2,3
$
V
P
N
0
Figure 11.38 Free Maintenance Simulation Model
1
Inputs. Enter the given data in the blue cells.
2
Maintenance decision. The current “no free maintenance” policy is labeled simu-
lation #1 and the proposed “free maintenance” policy is labeled simulation #2, so enter
the formula
RISKSIMTABLE({1,2})
in cell B34.
3
Percentages who pur chase. We assume that each year a random percentage of
Jamesons’ loyal customers and a random percentage of the competitors’ loyal customers
purchase a DVD player. Each of these is generated from the triangular distribution in rows
9–11 (see Figure 11.37), so enter the formula
RISKTRIANG($B$9,$B$10,$B$11)
in the range B37:Q38.
4
Percentage who stay or become loyal. Each year a random percentage of the cus-
tomers previously loyal to Jamesons remain loyal, and a random percentage of the com-
petitors’ previously loyal customers switch loyalty to Jamesons. Also, the distributions of
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

these random percentages depend on the company’s maintenance policy. Therefore, enter
the formula
IF($B$341,RISKTRIANG($B$24,$B$25,$B$26),RISKTRIANG($C$24,$C$25,$C$26))
in cell C39, enter the formula
IF($B$341,RISKTRIANG($B$29,$B$30,$B$31),RISKTRIANG($C$29,$C$30,$C$31))
in cell C40, and copy these across their rows.
5
Numbers of loyal customers. Create links to cells B5 and B6 in cells B41 and B42.
Then, remembering that only purchasers in a given year can switch loyalty, calculate the
number of customers loyal to Jamesons in year 1 with the formula
B41*((1-B37)	B37*C39)	B42*B38*C40
in cell C41 and copy it across row 41. Similarly, calculate the number of customers loyal to
the competitors in year 1 with the formula
B42*((1-B38)	B38*(1-C40))	B41*B37*(1-C39)
in cell C42 and copy it across row 42. These are basic bookkeeping formulas. Jamesons’
loyal customers are those who (1) were loyal and didn’t purchase, (2) were loyal, purchased,
and stayed loyal, and (3) weren’t loyal, purchased, and switched loyalty. Similar logic holds
for the competitors’ loyal customers.
6
Purchasers at Jamesons. Calculate the number of purchasers at Jamesons in year 1
with the formula
C37*C41
in cell C43 and copy it across row 41.
7
Monetary outcomes. These are straightforward. Start by entering the formula
IF($B$341,B21,C21)
for unit profit in year 1 in cell C45. Then enter the formulas
RISKTRIANG($B$14,$B$15,$B$16)
C45*(1	D44)
and
C45*C43
in cells D44, D45, and C46, respectively, and copy them across their rows. Finally, calcu-
late the NPV with the formula
NPV(B18,C46:Q46)
in cell B48.
Running the Simulation
Set up @RISK to run 1000 iterations and 2 simulations, one for each maintenance decision
to be tested. Then run the simulation as usual.
Discussion of the Simulation Results
The summary measures for the two simulations appear in Figure 11.39. Using the current
inputs, the free maintenance initiative does not look good. Every measure, except possibly
the standard deviation, is worse with the free maintenance agreement than without it.
674
Chapter 11
Simulation Models
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Evidently, the increase in loyal customers does not compensate for the decrease in unit
profit. If Jamesons is reasonably confident about the inputs for this model, it should scrap
the free maintenance idea. However, it might want to perform some sensitivity analysis on
the decrease in unit profit or the increase in loyalty percentages (or both) to see when the
free maintenance agreement starts looking attractive. We tried two possibilities. First, if the
decrease in unit profit is only $2, not $4, and everything else remains the same, the two
mean NPVs are very close, so the free maintenance agreement might be worth trying.
Second, if the decrease in unit profit remains at $4, but all of the input percentages in the
ranges C24:C26 and C29:C31 increase by five percentage points, the mean NPV with the
free maintenance agreement is still considerably lower than the mean NPV without it.
Evidently, the company can’t take this big a hit in its profit margin unless it can convince a
lot more customers to stay or become loyal.
There is an interesting modeling issue in this example. For each of the random quanti-
ties, we have generated a new random value each year. Would it be better to generate one
random number from each triangular distribution and use it for each year? Would it make
a difference in the results? The modified simulation appears in Figure 11.40. (You can see
the details in the second finished version of the Free Maintenance.xlsx file.) The only ran-
dom quantities are in the range B35:B39. As is evident in the rows below, these random
numbers are used for each of the years. The summary measures from this simulation
appear in Figure 11.41. If we are interested in comparing the mean NPV with no free main-
tenance versus free maintenance, we get about the same comparison in either model. The
main difference between Figures 11.39 and 11.41 is the variability. Are you surprised that
the models with more random numbers in Figure 11.39 have much smaller standard devia-
tions than those in Figure 11.41? Evidently, there is an averaging effect. When different
random numbers are used for each year, the highs and lows tend to cancel out, resulting in
lower variability in NPV.
11.4 Marketing Models
675
Figure 11.39
Summary Measures
for Comparing Two
Decisions
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
Q
P
O
N
M
L
K
J
I
H
G
F
E
D
C
B
A
Simulaon
Index of 
1
n
oit
alu
m
is
Percentage loyal to us who purchase each year
23.3%
Percentage not loyal to us who purchase each year
26.4%
Percentage growth each 
%
7.5
r
a
e
y
Percentage who stay loyal each 
%
6.3
6
%
6.8
5
r
a
e
y
Percentage who switch to us each year
30.1%
36.4%
Year
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
Percentage loyal to us who 
%
3.3
2
%
3.3
2
%
3.3
2
%
3.3
2
%
3.3
2
%
3.3
2
%
3.3
2
%
3.3
2
%
3.3
2
%
3.3
2
%
3.3
2
%
3.3
2
%
3.3
2
%
3.3
2
%
3.3
2
%
3.3
2
e
s
a
h
cr
u
p
Percentage loyal to them who purchase
26.4%
26.4%
26.4%
26.4%
26.4%
26.4%
26.4%
26.4%
26.4%
26.4%
26.4%
26.4%
26.4%
26.4%
26.4%
26.4%
Percentage who stay loyal to 
%
6.8
5
%
6.8
5
%
6.8
5
%
6.8
5
%
6.8
5
%
6.8
5
%
6.8
5
%
6.8
5
%
6.8
5
%
6.8
5
%
6.8
5
%
6.8
5
%
6.8
5
%
6.8
5
%
6.8
5
s
u
Percentage who switch loyalty to 
%
1.0
3
%
1.0
3
%
1.0
3
%
1.0
3
%
1.0
3
%
1.0
3
%
1.0
3
%
1.0
3
%
1.0
3
%
1.0
3
%
1.0
3
%
1.0
3
%
1.0
3
%
1.0
3
%
1.0
3
s
u
Customers loyal to us
50000
53119
55690
57808
59554
60992
62178
63155
63960
64623
65170
65620
65991
66297
66549
66757
Customers loyal to 
0
0
0
0
1
m
e
h
t
0
96881
94310
92192
90446
89008
87822
86845
86040
85377
84830
84380
84009
83703
83451
83243
Purchases of our product
12376
12975
13469
13875
14210
14487
14714
14902
15056
15184
15289
15375
15446
15505
15554
Percentage change in unit 
%
1
7.5
%
1
7.5
%
1
7.5
%
1
7.5
%
1
7.5
%
1
7.5
%
1
7.5
%
1
7.5
%
1
7.5
%
1
7.5
%
1
7.5
%
1
7.5
%
1
7.5
%
1
7.5
tif
o
r
p
Unit proﬁt 
$20.00
$21.14
$22.35
$23.63
$24.98
$26.40
$27.91
$29.51
$31.19
$32.97
$34.86
$36.85
$38.95
$41.18
$43.53
Proﬁt 
8
4,2
8
3
$
1
2
9,4
5
3
$
5
2
8,7
2
3
$
2
2
0,1
0
3
$
2
2
3,4
7
2
$
2
2
5,7
4
2
$
n
oit
u
birt
n
o
c
6 $410,686 $439,678 $469,613 $500,637 $532,891 $566,517 $601,653 $638,437 $677,011
7
8,7
1
0,3
$
V
P
N
7
Figure 11.40 Modified Simulation Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Regardless of which version is more realistic (and an argument can be made for either),
an advantage of the model with only a few random numbers is that you can use @RISK’s
tornado chart to see which source of randomness is most highly correlated with NPV. This
tornado chart appears in Figure 11.42. (It is for simulation #2 with free maintenance agree-
ment, but the chart for simulation #1 is virtually the same.) Perhaps surprisingly, it is not the
switching behavior that drives NPV; it is driven more by the percentage of customers who
purchase. As this example illustrates, it is sometimes an advantage to keep the models
simple. Key insights are then more apparent than when there is more complexity. ■
11.4.2 Marketing and Sales Models
We conclude this marketing section with a model of marketing and selling condos. The
main issue is the timing of sales, and we demonstrate how a deterministic model of this
timing can provide very misleading results.
676
Chapter 11
Simulation Models
Figure 11.41
Summary Results
for Modified Model
Figure 11.42
Tornado Chart
for NPV
E X A M P L E
11.13 MARKETING AND SELLING CONDOS
T
he Blackstone Development Company has just finished building 120 high-end condos,
each priced at $300,000. Blackstone has hired another company, Pletcher Marketing, to
market and sell these condos. Pletcher will incur all of the marketing and maintenance costs,
assumed to be $800 per unsold condo per month, and it will receive a 10% commission
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

11.4 Marketing Models
677
($30,000) from Blackstone at the time of each condo sale. Because Blackstone wants these
condos to be sold in a timely manner, it has offered Pletcher a $200,000 bonus at the end of
the first year if at least half of the condos have been sold, and an extra $500,000 bonus at
the end of the second year if all of the condos have been sold. Pletcher estimates that it can
sell five condos per month on average, so that it should be able to collect the bonuses.
However, Pletcher also realizes that there is some uncertainty about the number of sales
per month. How should this uncertainty be modeled, and will the resulting simulation
model give different qualitative results than a deterministic model where exactly five con-
dos are sold per month?
Objective
To develop a simulation model that allows us to see how the uncertain timing
affects the monetary outcomes for Pletcher, and to compare this simulation model to a
deterministic model with no uncertainty about the timing of sales.
WHERE DO THE NUMBERS COME FROM?
The inputs are straightforward from Blackstone’s agreement with Pletcher. The only diffi-
culty is determining an appropriate probability model for the timing of sales, which we dis-
cuss next.
Solution
To make a fair comparison between a deterministic model with five sales per month and a
simulation model with uncertainty in the timing of sales, we need a discrete distribution for
monthly sales that has mean 5. One attractive possibility is to use the Poisson distribution.
It is a commonly used discrete distribution with only one parameter, the mean. The
Poisson distribution has one theoretical drawback in that it allows all nonnegative integers
to occur, but this has no practical effect. As shown in Figure 11.43, the Poisson distribution
with mean 5 has virtually no probability of values larger than, say, 15.
Figure 11.43
Poisson Distribution
with Mean 5
DEVELOPING THE SIMULATION MODEL
The deterministic model is very straightforward and is not shown here. By selling a sure
five condos per month, Pletcher sells all condos by the end of year 2, receives both
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

678
Chapter 11
Simulation Models
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
O
A
B
A
A
A
Z
Y
X
O
N
M
L
C
B
A
Markeng and selling condos
Number to 
0
2
1
lle
s
Monthly markeng, maintenance cost
$800
Commission per condo sale
$30,000
Bonus if at least half sold in year 1
$200,000
Extra bonus if all sold in 2 years
$500,000
Discount rate 
%
8.0
)ylh
t
n
o
m
(
Simulaon model
Distribuon of demand for condos each month (Poisson distributed)
Mean demand per 
5
h
t
n
o
m
0
4
7
2
6
2
5
2
4
2
3
2
4
1
3
1
2
1
1
1
2
1
h
t
n
o
M
Demand this month
5
3
8
4
2
6
1
12
5
4
Number remaining to be sold
120
115
69
61
57
55
21
20
8
3
0
0
Number sold this month
5
3
8
4
2
6
1
12
5
3
Maintenance 
0
$
0
0
4,2
$
0
0
4,6
$
0
0
0,6
1
$
0
0
2,9
3
$
0
0
0,4
4
$
0
0
6,5
4
$
0
0
8,8
4
$
0
0
6,9
8
$
0
0
0,2
9
$
ts
o
c
Revenue from 
0
0
0,0
9
$
0
0
0,0
5
1
$
0
0
0,0
6
3
$
0
0
0,0
3
$
0
0
0,0
8
1
$
0
0
0,0
6
$
0
0
0,0
2
1
$
0
0
0,0
4
2
$
0
0
0,0
9
$
0
0
0,0
5
1
$
s
ela
s
Bonus at end of year 
0
0
0,0
0
2
$
1
Bonus at end of year 2
$0
Net 
0
0
0,0
9
$
0
0
6,7
4
1
$
0
0
6,3
5
3
$
0
0
0,4
1
$
0
0
8,0
4
1
$
0
0
0,6
1
$
0
0
4,4
7
2
$
0
0
2,1
9
1
$
0
0
4
$
0
0
0,8
5
$
e
u
n
e
v
e
r
Months to sell 
6
2
t
u
o
Total 
0
0
0,0
0
2
$
s
u
n
o
b
Figure 11.44 Condo Selling Simulation Model
bonuses, and realizes an NPV (including bonuses) of $2,824,333. However, this is not very
realistic. The steps for creating a more realistic simulation model follow. (See Figure
11.44, with several hidden columns, and the file Selling Condos.xlsx.) Note that because
of the uncertain timing of sales, we cannot say when all 120 condos will be sold. It could
be before 24 months or well after 24 months. Therefore, we model it through 40 months.
By experimenting, we found that all 120 condos will almost surely be sold in 40 months.
1
Inputs. Enter the inputs in the blue ranges.
2
Random demands. Generate the random demands for condos (the number of people
who would like to buy) by entering the formula
IF(B160,RISKPOISSON($B$12),"")
in cell B15 and copying across to month 40. The IF function checks whether there are still
any condos available in that month. If there aren’t, a blank is recorded. Similar logic
appears in many of the other formulas.
3
Number remaining and sold. In cell B16, enter a link to cell B3. In cell B17, find
the number sold as the minimum of supply and demand with the formula
IF(B160,MIN(B16,B15),"")
In cell C16, find the number remaining to be sold with the formula
IF(B160,B16-B17,0)
Then copy the formulas in cells C16 and B17 across. Note that a 0, not a blank, is recorded in
row 16 after all condos have been sold. This makes all the other IF functions work correctly.
4
Monetary values. Enter the formulas
IF(B160,$B$4*(B16-B17),"")
IF(B160,$B$5*B17,"")
and
IF(B160,SUM(B19:B21)-B18,"")
in cells B18, B19, and B22, and copy these across. For the bonuses, enter the formulas
IF(SUM(B17:M17)B3/2,B6,0)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

and
IF(SUM(B17:Y17)B3,B7,0)
in cells M20 and Y21. These capture the all-or-nothing nature of the bonuses.
5
Outputs. Three interesting outputs are the number of months required to sell out, the
total bonus earned, and the NPV of the cash flows, including bonuses. Calculate these in
cells B24–B26 with the formulas
COUNTIF(B16:AO16,"0")
M20	Y21
and
NPV($B$8,B22:AO22)
Then designate them as @RISK output cells.
Running the Simulation
Set @RISK to run 1000 iterations for a single simulation. Then run the simulation in the
usual way.
Discussion of the Simulation Results
Recall that the deterministic model sells out in 24 months, receives both bonuses, and
achieves an NPV of about $2.82 million. As you might guess, the simulation model
doesn’t do this well. The main problem is that there is a fairly good chance that one or
both bonuses will not be received. Histograms of the three outputs appear in Figures
11.45 through 11.47. The first shows that although 24 months is the most likely number
of months to sell out, there was at least one scenario where it took only 17 months and
another where it took 32 months. The second histogram shows the four possibilities for
bonuses: receive neither, receive one or the other, or receive both. Unfortunately for
Pletcher, the first three possibilities are fairly likely; the probability of receiving both
bonuses is only about 0.38. Finally, the shape of the NPV histogram, with three separate
11.4 Marketing Models
679
Figure 11.45
Histogram of
Months to Sell Out
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

680
Chapter 11
Simulation Models
Figure 11.46
Histogram of Total
Bonus Received
Figure 11.47
Histogram of NPV
peaks, is influenced heavily by the bonuses or lack of them. On average, the NPV is
only about $2.39 million, much less than estimated by the deterministic model. This is
still one more example—a dramatic one—of the flaw of averages. ■
P R O B L E M S
Skill-Building Problems
29. Suppose that Coke and Pepsi are fighting for the cola
market. Each week each person in the market buys
one case of Coke or Pepsi. If the person’s last
purchase was Coke, there is a 0.90 probability that
this person’s next purchase will be Coke; otherwise,
it will be Pepsi. (You can assume that there are only
two brands in the market.) Similarly, if the person’s
last purchase was Pepsi, there is a 0.80 probability
that this person’s next purchase will be Pepsi;
otherwise, it will be Coke. Currently half of all
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

11.4 Marketing Models
681
people purchase Coke, and the other half purchase
Pepsi. Simulate one year (52 weeks) of sales in the
cola market and estimate each company’s average
weekly market share and each company’s ending
market share in week 52. Do this by assuming that
the total market size is fixed at 100,000 customers.
(Hint: Use the RISKBINOMIAL function. However,
if your model requires more RISKBINOMIAL
functions than the number allowed in the academic
version of @RISK, remember that you can instead
use the CRITBINOM function to generate binomially
distributed random numbers. This takes the form
CRITBINOM(ntrials,psuccess,RAND()).)
30. Seas Beginning sells clothing by mail order. An
important question is when to strike a customer from
the company’s mailing list. At present, the company
strikes a customer from its mailing list if a customer
fails to order from six consecutive catalogs. The
company wants to know whether striking a customer
from its list after a customer fails to order from four
consecutive catalogs results in a higher profit per
customer. The following data are available:
■If a customer placed an order the last time she
received a catalog, then there is a 20% chance she
will order from the next catalog.
■If a customer last placed an order one catalog ago,
there is a 16% chance she will order from the next
catalog she receives.
■If a customer last placed an order two catalogs ago,
there is a 12% chance she will order from the next
catalog she receives.
■If a customer last placed an order three catalogs
ago, there is an 8% chance she will order from the
next catalog she receives.
■If a customer last placed an order four catalogs
ago, there is a 4% chance she will order from the
next catalog she receives.
■If a customer last placed an order five catalogs ago,
there is a 2% chance she will order from the next
catalog she receives.
It costs $2 to send a catalog, and the average profit per
order is $30. Assume a customer has just placed an
order. To maximize expected profit per customer,
would Seas Beginning make more money canceling
such a customer after six nonorders or four nonorders?
31. Based on Babich (1992). Suppose that each week each
of 300 families buys a gallon of orange juice from
company A, B, or C. Let pA denote the probability that
a gallon produced by company A is of unsatisfactory
quality, and define pB and pC similarly for companies
B and C. If the last gallon of juice purchased by a
family is satisfactory, the next week they will purchase
a gallon of juice from the same company. If the last
gallon of juice purchased by a family is not
satisfactory, the family will purchase a gallon from a
competitor. Consider a week in which A families have
purchased juice A, B families have purchased juice B,
and C families have purchased juice C. Assume that
families that switch brands during a period are
allocated to the remaining brands in a manner that is
proportional to the current market shares of the other
brands. For example, if a customer switches from
brand A, there is probability B/(B 	 C) that he will
switch to brand B and probability C/(B 	 C) that he
will switch to brand C. Suppose that the market is
currently divided equally: 10,000 families for each of
the three brands.
a. After a year, what will the market share for each firm
be? Assume pA  0.10, pB  0.15, and pC  0.20.
(Hint: You will need to use the RISKBINOMIAL
function to see how many people switch from A 
and then use the RISKBINOMIAL function again
to see how many switch from A to B and from A
to C. However, if your model requires more
RISKBINOMIAL functions than the number
allowed in the academic version of @RISK,
remember that you can instead use the 
CRITBINOM function to generate binomially
distributed random numbers. This takes the form
CRITBINOM(ntrials,psuccess,RAND()).)
b. Suppose a 1% increase in market share is worth
$10,000 per week to company A. Company A
believes that for a cost of $1 million per year it can
cut the percentage of unsatisfactory juice cartons in
half. Is this worthwhile? (Use the same values of
pA, pB, and pC as in part a.)
Skill-Extending Problems
32. The customer loyalty model in Example 11.11 assumes
that once a customer leaves (becomes disloyal), that
customer never becomes loyal again. Assume instead
that there are two probabilities that drive the model,
the retention rate and the rejoin rate, with values 0.75
and 0.15, respectively. The simulation should follow a
customer who starts as a loyal customer in year 1.
From then on, at the end of any year when the
customer was loyal, this customer remains loyal for
the next year with probability equal to the retention
rate. But at the end of any year the customer is
disloyal, this customer becomes loyal the next year
with probability equal to the rejoin rate. During the
customer’s nth loyal year with the company, the
company’s mean profit from this customer is the nth
value in the mean profit list in column B. Keep track
of the same two outputs as in the example, and also
keep track of the number of times the customer
rejoins.
33. We are all aware of the fierce competition by mobile
phone service companies to get our business. For
example, AT&T is always trying to attract Verizon’s
customers, and vice versa. Some even give away prizes
to entice us to sign up for a guaranteed length of time.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

11.5 SIMULATING GAMES OF CHANCE
We realize that this is a book about business applications. However, it is instructive (and
fun) to see how simulation can be used to analyze games of chance, including sports
contests. Indeed, many analysts refer to Monte Carlo simulation, and you can guess where
that name comes from—the gambling casinos of Monte Carlo.
11.5.1 Simulating the Game of Craps
Most games of chance are great candidates for simulation because they are, by their very
nature, driven by randomness. In this section we examine one such game that is extremely
popular in the gambling casinos: the game of craps. In its most basic form, the game of
682
Chapter 11
Simulation Models
This example is based on one such offer. We assume
that a mobile provider named Syncit is willing to give a
customer a free laptop computer, at a cost of $300 to
Syncit, if the customer signs up for a guaranteed two
years of service. During that time, the cost of service to
the customer is a constant $60 per month, or $720
annually. After two years, we assume the cost of
service increases by 2% annually. We assume that in
any year after the guaranteed two years, the probability
is 0.7 that the customer will stay with Syncit. This
probability is the retention rate. We also assume that if
a customer has switched to another mobile service,
there is always a probability of 0.1 that the customer
will (without any free laptop offer) willingly rejoin
Syncit. The company wants to see whether this offer
makes financial sense in terms of NPV, using a 10%
discount rate. It also wants to see how the NPV varies
with the retention rate. Simulate a 15-year time
horizon, both with and without the free offer, to
estimate the difference. (For the situation without the
free offer, assume the customer has probability 0.5 of
signing up with Syncit during year 1.)
34. Suppose that GLC earns a $2000 profit each time a
person buys a car. We want to determine how the
expected profit earned from a customer depends on the
quality of GLC’s cars. We assume a typical customer
will purchase 10 cars during her lifetime. She will
purchase a car now (year 1) and then purchase a car
every five years—during year 6, year 11, and so on.
For simplicity, we assume that Hundo is GLC’s only
competitor. We also assume that if the consumer is
satisfied with the car she purchases, she will buy her
next car from the same company, but if she is not
satisfied, she will buy her next car from the other
company. Hundo produces cars that satisfy 80% of its
customers. Currently, GLC produces cars that also
satisfy 80% of its customers. Consider a customer
whose first car is a GLC car. If profits are discounted
at 10% annually, use simulation to estimate the value
of this customer to GLC. Also estimate the value of a
customer to GLC if it can raise its customer
satisfaction rating to 85%, to 90%, or to 95%. You can
interpret the satisfaction value as the probability that a
customer will not switch companies.
35. The Mutron Company is thinking of marketing a new
drug used to make pigs healthier. At the beginning of
the current year, there are 1,000,000 pigs that could
use the product. Each pig will use Mutron’s drug or a
competitor’s drug once a year. The number of pigs is
forecast to grow by an average of 5% per year.
However, this growth rate is not a sure thing. Mutron
assumes that each year’s growth rate is an independent
draw from a normal distribution, with probability 0.95
that the growth rate will be between 3% and 7%.
Assuming it enters the market, Mutron is not sure
what its share of the market will be during year 1, so it
models this with a triangular distribution. Its worst-
case share is 20%, its most likely share is 40%, and its
best-case share is 70%. In the absence of any new
competitors entering this market (in addition to itself),
Mutron believes its market share will remain the same
in succeeding years. However, there are three potential
entrants (in addition to Mutron). At the beginning of
each year, each entrant that has not already entered the
market has a 40% chance of entering the market. The
year after a competitor enters, Mutron’s market share
will drop by 20% for each new competitor who
entered. For example, if two competitors enter the
market in year 1, Mutron’s market share in year 2 will
be reduced by 40% from what it would have been with
no entrants. Note that if all three entrants have entered,
there will be no more entrants. Each unit of the drug
sells for $2.20 and incurs a variable cost of $0.40.
Profits are discounted by 10% annually.
a. Assuming that Mutron enters the market, use
simulation to find its NPV for the next 10 years
from the drug.
b. Again assuming that Mutron enters the market, it
can be 95% certain that its actual NPV from the
drug is between what two values?
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

craps is played as follows. A player rolls two dice and observes the sum of the two sides
turned up. If this sum is 7 or 11, the player wins immediately. If the sum is 2, 3, or 12, the
player loses immediately. Otherwise, if this sum is any other number (4, 5, 6, 8, 9, or 10),
that number becomes the player’s point. Then the dice are thrown repeatedly until the sum
is the player’s point or 7. In case the player’s point occurs before a 7, the player wins. But
if a 7 occurs before the point, the player loses. The following example uses simulation to
determine the properties of this game.
E X A M P L E
11.14 ESTIMATING THE PROBABILITY OF WINNING AT CRAPS
J
oe Gamble loves to play craps at the casinos. He suspects that his chances of winning are
less than fifty-fifty, but he wants to find the probability that he wins a single game of craps.
Objective
To use simulation to find the probability of winning a single game of craps.
WHERE DO THE NUMBERS COME FROM?
There are no input numbers here, only the rules of the game.
Solution
The simulation is of a single game. By running this simulation for many iterations, you can
find the probability that Joe wins a single game of craps. If his intuition is correct (and
surely it must be, or the casino could not stay in business), this probability is less than 0.5.
DEVELOPING THE SIMULATION MODEL
The simulation model is for a single game. (See Figure 11.48 and the file Craps.xlsx.)
There is a subtle problem here: The number of tosses of the dice necessary to determine the
outcome of a single game is unknown. Theoretically, the game could continue forever, with
the player waiting for his point or a 7. However, it is extremely unlikely that more than, say,
1
2
3
4
5
6
7
8
9
10
11
12
13
14
42
43
44
A
B
C
D
E
F
G
H
I
J
Craps Simulaon
Simulated tosses
Toss
Die 1
Die 2
Sum
Win on this toss?
Lose on this toss?
Connue?
Summary results from simulaon
1
6
2
8
0
0
Yes
Win? (1 if yes, 0 if no)
1
2
5
6
11
0
0
Yes
Number of tosses
8
3
4
2
6
0
0
Yes
4
4
1
5
0
0
Yes
Pr(winning)
0.491
5
2
1
3
0
0
Yes
Expected number of tosses
3.364
6
5
4
9
0
0
Yes
7
3
6
9
0
0
Yes
8
6
2
8
1
0
No
9
3
4
7
10
6
3
9
38
4
3
7
39
2
6
8
40
1
1
2
Figure 11.48 Simulation of Craps Game
11.5 Simulating Games of Chance
683
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

40 tosses are necessary in a single game. (This can be shown by a probability argument not
presented here.) Therefore, you can simulate 40 tosses and use only those that are necessary
to determine the outcome of a single game. The steps required are as follows.
1
Simulate tosses. Simulate the results of 40 tosses in the range B5:D44 by entering
the formula
RANDBETWEEN(1,6)
in cells B5 and C5 and the formula
SUM(B5:C5)
in cell D5. Then copy these to the range B6:D44. (Recall that the RANDBETWEEN
function was new in Excel 2007. It generates a random integer between the two speci-
fied values such that all values are equally likely, so it is perfect for tossing a die. You
could also use @RISK’s RISKINTUNIFORM function, which works exactly like
RANDBETWEEN.)
Excel Function: RANDBETWEEN
The function RANDBETWEEN, in the form RANDBETWEEN(N1,N2), generates a ran-
dom integer from N1 to N2, with each possibility being equally likely.
@RISK Function: RISKINTUNIFORM
The @RISK function RISKINTUNIFORM in the form RISKINTUNIFORM(N1,N2) works
exactly like Excel’s RANDBETWEEN function.
2
First toss outcome. Determine the outcome of the first toss with the formulas
IF(OR(D57,D511),1,0)
IF(OR(D52,D53,D512),1,0)
and
IF(AND(E50,F50),"Yes","No")
in cells E5, F5, and G5. Note that the OR condition checks whether Joe wins right away (in
which case a 1 is recorded in cell E5). Similarly, the OR condition in cell F5 checks
whether he loses right away. In cell G5, the AND condition checks whether both cells E5
and F5 are 0, in which case the game continues. Otherwise, the game is over.
3
Outcomes of other tosses. Assuming the game continues beyond the first toss, Joe’s
point is the value in cell D5. Then he is waiting for a toss to have the value in cell D5 or 7,
whichever occurs first. To implement this logic, enter the formulas
IF(OR(G5"No",G5""),"",IF(D6$D$5,1,0))
IF(OR(G5"No",G5""),"",IF(D67,1,0))
and
IF(OR(G5"No",G5""),"",IF(AND(E60,F60), "Yes","No"))
in cells E6, F6, and G6, and copy these to the range E7:G44. The OR condition in each for-
mula checks whether the game just ended on the previous toss or has been over for some
time, in which case blanks are entered. Otherwise, the first two formulas check whether
Joe wins or loses on this toss. If both of these return 0, the third formula returns Yes (and
the game continues). Otherwise, it returns No (and the game has just ended).
684
Chapter 11
Simulation Models
As in many 
spreadsheet simulation
models, the concepts 
in this model are 
simple.The key is 
careful bookkeeping.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4
Game outcomes. Keep track of two aspects of the game in @RISK output cells:
whether Joe wins or loses and how many tosses are required. To find these, enter the formulas
SUM(E5:E44)
and
COUNT(E5:E44)
in cells J5 and J6, and designate each of these as an @RISK output cell. Note that both
functions, SUM and COUNT, ignore blank cells.
5
Simulation summary . Although you can get summary measures in the various
@RISK results windows after you run the simulation, it is useful to see some key summary
measures right on the model sheet. To obtain these, enter the formula
RISKMEAN(J5)
in cell J8 and copy it to cell J9. As the labels indicate, the RISKMEAN in cell J8, being an
average of 0s and 1s, is just the fraction of iterations where Joe wins. The average in cell J9
is the average number of tosses until the game’s outcome is determined.
Running the Simulation
Set the number of iterations to 10,000 (partly for variety and partly to obtain a very accu-
rate answer) and the number of simulations to 1. Then run the simulation as usual.
Discussion of the Simulation Results
After running @RISK, the summary results in cells J8 and J9 of Figure 11.48 (among
others) are available. Our main interest is in the average in cell J8. It represents the best
estimate of the probability of winning, 0.493. (It can be shown with a probability argument
that the exact probability of winning in craps is indeed 0.493.) You can also see that
the average number of tosses needed to determine the outcome of a game was about 3.4.
(The maximum number of tosses ever needed on these 10,000 iterations was 39.) ■
11.5.2 Simulating the NCAA Basketball Tournament
Each year the suspense reaches new levels as “March Madness” approaches, the time of
the NCAA Basketball Tournament. Which of the 64 teams in the tournament will reach the
“Sweet Sixteen,” which will go on to the prestigious “Final Four,” and which team will be
crowned champion? The excitement at Indiana University is particularly high, given the
strong basketball tradition here, so it has become a yearly tradition at IU (at least for the
authors) to simulate the NCAA Tournament right after the 64-team field has been
announced. We share that simulation in the following example. (We make two quick notes.
First, everyone who watches basketball knows about IU’s recent basketball problems. We
hope the Hoosiers are now on the upswing. Second, we will have to change our simulation
slightly in future years. It looks like the number of teams in the tournament will be signif-
icantly larger than 64.)
Recall that the mean 
(or average) of a 
sequence of 0s and 
1s is the fraction of 
1s in the sequence.
This can typically be
interpreted as a
probability.
Perhaps surprisingly,
the probability of 
winning in craps is 
0.493, only slightly 
less than 0.5.
E X A M P L E
11.15 MARCH MADNESS
A
t the time this example was written, the most recent NCAA Basketball Tournament
was the 2010 tournament, won by Duke University over the big surprise of the tour-
nament, Butler University. Of course, on the Sunday evening when the 64-team field was
11.5 Simulating Games of Chance
685
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

announced, we did not know which team would win.6 All we knew were the pairings
(which teams would play which other teams) and the team ratings, based on Jeff Sagarin’s
nationally syndicated rating system. We show how to simulate the tournament and keep a
tally of the winners.
Objective
To simulate the 64-team NCAA basketball tournament and keep a tally on the
number of times each team wins the tournament.
WHERE DO THE NUMBERS COME FROM?
As soon as you learn the pairings for the next NCAA tournament, you can visit Sagarin’s
site at www.usatoday.com/sports/sagarin.htm#hoop for the latest ratings.
Solution
We need to make one probabilistic assumption. From that point, it is a matter of “playing
out” the games and doing the required bookkeeping. To understand this probabilistic
assumption, suppose team A plays team B and Sagarin’s ratings for these teams are, say,
85 and 78. Then Sagarin predicts that the actual point differential in the game (team A’s
score minus team B’s score) will be the difference between the ratings, or 7.7 We take this
one step further. We assume that the actual point differential is normally distributed with
mean equal to Sagarin’s prediction, 7, and standard deviation 10. (Why 10? This is an esti-
mate based on an extensive analysis of historical data.) Then if the actual point differential
is positive, team A wins. If it is negative, team B wins.
DEVELOPING THE SIMULATION MODEL
We provide only an outline of the simulation model. You can see the full details in the file
March Madness Men 2010.xlsm . Remember that an .xlsm file contains macros. When
you open it, you need to enable the macros. (This file includes the data for the 2010
tournament, but you can easily modify it for future tournaments by following the direc-
tions on the sheet. We have also included the March Madness Women 2010.xlsm file.
The women’s tournament was won by the University of Connecticut.) The entire simula-
tion is on a single Model sheet. Columns A through C list team indexes, team names, and
Sagarin ratings. If two teams are paired in the first round, they are placed next to one
another in the list. Also, all teams in a given region are listed together. (The regions are
color-coded.) Columns K through Q contain the simulation. The first-round results are at
the top, the second-round results are below these, and so on. Winners from one round are
automatically carried over to the next round with appropriate formulas. Selected portions
of the Model sheet appear in Figures 11.49 and 11.50. We now describe the essential
features of the model.
1
Teams and ratings.
We first enter the teams and their ratings, as shown in 
Figure 11.49. Most of the teams shown here were in the East region in the 2010 tournament.
Kentucky played East Tennessee State in the first round, Texas played Wake Forest, and
so on.
686
Chapter 11
Simulation Models
We model the point
spread as normally
distributed, with mean
equal to the difference
between the Sagarin
ratings and standard
deviation 10.
6Actually, 65 teams are announced, and an early playoff game occurs to see which of two lowly rated teams gets
to play a #1 seed. This has no effect on the simulation because neither lowly ranked team has much chance of
winning against the #1 seed. 
7In general, there is also a home-court advantage, but we assume all games in the tournament are on “neutral”
courts, so that there is no advantage to either team.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

2
Simulate rounds. Jumping ahead to the fourth-round simulation in Figure 11.50, we
capture the winners from the previous round 3 and then simulate the games in round 4. The
key formulas are in columns N and O. For example, the formulas in cells N126 and O126 are
VLOOKUP(L126,LTable,3)–VLOOKUP(L127,LTable,3)
and
RISKNORMAL(N126,10)
The first of these looks up the ratings of the two teams involved (in this case, Kentucky and
Missouri) and subtracts them to get the predicted point spread. The second formula simu-
lates a point spread with the predicted point spread as its mean. The rest of the formulas do
the appropriate bookkeeping. You can view the details in the file.
3
Outputs. As shown by the boxed-in cells in Figure 11.50, seven cells have been des-
ignated as @RISK output cells: the index of the winner, the indexes of the two finalists,
and the indexes of the four semifinalists (the Final Four teams). However, the results we
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
A
B
C
D
E
F
G
H
I
J
Simulaon of NCAA men's 2010 basketball tournament, using Sagarin rangs
Final Sagarin rangs of teams
Index
Team
Rang
1
Kentucky
91.51
2
East Tennessee St
72.79
3
Texas
87.83
4
Wake Forest
83.67
5
Temple
87.35
6
Cornell
82.54
7
Wisconsin
87.74
8
Woﬀord
78.59
9
Marquee
86.07
10
Washington
84.07
11
New Mexico
86.08
12
Montana
76.69
13
Clemson
85.67
14
Missouri
86.15
15
West Virginia
90.74
16
Morgan St
73.65
6
4.2
9
e
k
u
D
7
1
18
Arkansas PB/Winthrop
68.97
19
California
85.36
20
Louisville
84.32
21
Texas A&M
86.97
22
Utah St
84.16
23
Purdue
88.58
6
3.2
8
a
n
eiS
4
2
25
Notre Dame
84.22
26
Old Dominion
83.93
East regional
South regional
Assumpon: The actual point spread for each 
game is normally distributed with mean equal to 
diﬀerence between Sagarin rangs, standard 
deviaon 10.
Figure 11.49 Teams and Sagarin Ratings
11.5 Simulating Games of Chance
687
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

688
Chapter 11
Simulation Models
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
K
L
M
N
O
P
Q
Results of Round 4
Game
Indexes
Teams Predicted
Simulated
Index of winner
Winner
1
1
Kentucky
5.36
4.01
1
Kentucky
 
14
Missouri
1
19
California
-3.29
10.81
19
California
 
27
Baylor
1
33
Kansas
7.82
3.76
33
Kansas
 
47
Ohio St
1
53
Butler
-0.27
2.60
53
Butler
 
59
Pisburgh
Semiﬁnals
Game
Indexes
Teams Predicted
Simulated
Index of winner
Winner
1
1
Kentucky
6.15
-2.73
19
California
19
California
2
33
Kansas
10.11
2.41
33
Kansas
53
Butler
Finals
Game
Indexes
Teams Predicted
Simulated
Index of winner
Winner
1
19
California
-10.85
-30.43
33
Kansas
33
Kansas
Winner
33
Figure 11.50 NCAA Basketball Simulation Model (Last Three Rounds Only)
really want are tallies, such as the number of iterations where Kentucky (or any other team)
wins the tournament. This takes some planning. In the @RISK Excel Reports dialog box,
if you check the Simulation Data option, you get a sheet called Data that lists the values
of all @RISK output cells for each of the iterations. (We used 1000 iterations.) Then
COUNTIF functions can be used to tally the number of wins (or finalist or semifinalist
appearances) for each team, right in the original Model sheet.
Some of these tallies appear in Figure 11.51. For example, the formula in cell U5 is
COUNTIF('Data'!$I$8:$I$1007,S5)
In this case, the range I8:I1007 of the Data sheet contains the indexes of the 1000 win-
ners, so this formula simply counts the number of these that are index 1.8 As you can
see, the top-rated team in the South region, Duke, won the tournament in 131 of the
1000 iterations and reached the Final Four 367 times. In contrast, the lowly rated
East Tennessee State (and a few others) did not make the Final Four in any of the
1000 iterations.
The Simulation Data
report in @RISK lists 
the outputs from each
iteration of the 
simulation, which 
allows us to tally the
winners.
8Unfortunately, each time you rerun the simulation, the Data sheet is deleted and then recreated, which invalidates
the references in the tally formulas. Therefore, we created a macro to update these formulas. You can run the
macro by clicking on the button at the top of the worksheet.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

P R O B L E M S
Skill-Building Problems
36. A martingale betting strategy works as follows. You
begin with a certain amount of money and repeatedly
play a game in which you have a 40% chance of
winning any bet. In the first game, you bet $1. From
then on, every time you win a bet, you bet $1 the next
time. Each time you lose, you double your previous
bet. Currently you have $63. Assuming you have
unlimited credit, so that you can bet more money than
you have, use simulation to estimate the profit or loss
you will have after playing the game 50 times.
37. The game of Chuck-a-Luck is played as follows: You
pick a number between 1 and 6 and toss three dice. If
your number does not appear, you lose $1. If your
number appears x times, you win $x. On the average,
use simulation to find the average amount of money
you will win or lose on each play of the game.
38. You have $5 and your opponent has $10. You flip a
fair coin and if heads comes up, your opponent pays
you $1. If tails comes up, you pay your opponent $1.
The game is finished when one player has all the
money or after 100 tosses, whichever comes first. Use
simulation to estimate the probability that you end up
with all the money and the probability that neither of
you goes broke in 100 tosses.
Skill-Extending Problems
39. Assume a very good NBA team has a 70% chance of
winning in each game it plays. During an 82-game
season what is the average length of the team’s longest
winning streak? What is the probability that the team has
a winning streak of at least 16 games? Use simulation to
answer these questions, where each iteration of the
simulation generates the outcomes of all 82 games.
40. You are going to play the Wheel of Misfortune Game
against the house. The wheel has 10 equally likely
numbers: 5, 10, 15, 20, 25, 30, 35, 40, 45 ,and 50. The
goal is to get a total as close as possible to 50 points
without exceeding 50. You go first and spin the wheel.
Based on your first spin, you can decide whether you
want to spin again. (You can spin no more than twice.)
After you are done, it is the house’s turn. If your total
is more than 50, the house doesn’t need a turn; it wins
automatically. Otherwise, the house spins the wheel.
11.5 Simulating Games of Chance
689
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
S
T
U
V
W
Tally of winners, ﬁnalists, and semiﬁnalists
Index
Team
Winner
Finalist Semiﬁnalist
1
Kentucky
75
159
277
2
East Tennessee St
0
0
0
8
6
7
1
4
s
a
x
e
T
3
4
Wake Forest
3
7
15
8
6
2
2
0
1
elp
m
e
T
5
5
4
0
lle
n
r
o
C
6
7
Wisconsin
14
47
98
1
1
0
d
r
o
ff
o
W
8
9
Marquee
7
17
59
10
Washington
0
6
17
11
New Mexico
8
24
62
0
0
0
a
n
a
t
n
o
M
2
1
8
2
7
2
n
o
s
m
elC
3
1
8
3
6
1
7
ir
u
o
ssi
M
4
1
15
West Virginia
70
148
264
16
Morgan St
0
0
0
7
6
3
1
3
2
1
3
1
e
k
u
D
7
1
18
Arkansas PB/Winthrop
0
0
0
Figure 11.51
Tally of Tournament
Winners
■
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

690
Chapter 11
Simulation Models
After its first spin, it can spin the wheel again if it
wants. (The house can also spin no more than twice.)
Then the winner is determined, where a tie goes to
you. Use simulation to estimate your probability of
winning the game if you and the house both use best
strategies. What are the best strategies?
41. Consider the following card game. The player and
dealer each receive a card from a 52-card deck. At the
end of the game the player with the highest card wins;
a tie goes to the dealer. (You can assume that Aces
count 1, Jacks 11, Queens 12, and Kings 13.) After the
player receives his card, he keeps the card if it is 7 or
higher. If the player does not keep the card, the player
and dealer swap cards. Then the dealer keeps his
current card (which might be the player’s original
card) if it is 9 or higher. If the dealer does not keep his
card, he draws another card. Use simulation with at
least 1000 iterations to estimate the probability that the
player wins. (Hint: See the file Sampling Without
Replacement.xlsx to see a clever way of simulating
cards from a deck so that the same card is never dealt
more than once.)
42. Based on Morrison and Wheat (1984). When his team
is behind late in the game, a hockey coach usually
waits until there is one minute left before pulling the
goalie out of the game. Using simulation, it is
possible to show that coaches should pull their goalies
much sooner. Suppose that if both teams are at full
strength, each team scores an average of 0.05 goal per
minute. Also, suppose that if you pull your goalie you
score an average of 0.08 goal per minute and your
opponent scores an average of 0.12 goal per minute.
Suppose you are one goal behind with five minutes
left in the game. Consider the following two
strategies:
■Pull your goalie if you are behind at any point in
the last five minutes of the game; put him back in if
you tie the score.
■Pull your goalie if you are behind at any point in
the last minute of the game; put him back in if you
tie the score.
Which strategy maximizes your probability of winning
or tying the game? Simulate the game using 10-second
increments of time. Use the RISKBINOMIAL
function to determine whether a team scores a goal in
a given 10-second segment. This is reasonable because
the probability of scoring two or more goals in a 
10-second period is near zero.
43. You are playing Andy Roddick in tennis, and you have
a 42% chance of winning each point. (You are good!)
a. Use simulation to estimate the probability you will
win a particular game. Note that the first player to
score at least four points and have at least two
more points than his or her opponent wins the
game.
b. Use simulation to determine your probability of
winning a set. Assume that the first player to win
six games wins the set if he or she is at least two
games ahead; otherwise, the first player to win
seven games wins the set. (We substitute a single
game for the usual tiebreaker.)
c. Use simulation to determine your probability of
winning a match. Assume that the first player to
win three sets wins the match.
11.6 AN AUTOMATED TEMPLATE FOR @RISK MODELS
As explained in the third edition of Albright’s VBA for Modelers book, the macro language
for Excel, VBA, can also be used to automate @RISK. We took advantage of this to create
an automated template that you can use for any of your simulations. The template appears
in Figure 11.52. (See the file Simulation Template.xlsm.) The text boxes provide the
motivation and instructions. There are two basic ideas. First, you often have particular
inputs you would like to vary in a sensitivity analysis. Once you specify these in the Inputs
section, the program will run a separate simulation for each combination of the input val-
ues. In the example shown, it would run 1  2  3  6 simulations. Second, you typically
have outputs that you want to summarize in certain ways. The Outputs section lets you
specify the summary measures you want for each of your outputs. The program then lists
the results on separate worksheets.
This template is not a magic bullet. It is still up to you to develop the logic of the sim-
ulation. However, you no longer have to worry about RISKSIMTABLE functions or statis-
tical functions such as RISKMEAN. The program takes care of these automatically, using
your entries in the Inputs and Outputs sections. To see how the template can be used, we
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
A
B
C
D
E
F
G
H
I
J
K
Simulaon Template
Number of iteraons
s
e
ula
V
st
u
p
n
I
 to test
5
1
t
u
p
nI
B
A
2
t
u
p
nI
0
0.1
5
7.0
0
5.0
3
t
u
p
nI
etc.
Tables requested
Outputs
Mean
Stdev
Min
Max
Percenles
Targets
6,5
5
9.,0
5.,5
0.
s
e
Y
s
e
Y
s
e
Y
s
e
Y
1
t
u
p
t
u
O
o
N
o
N
o
N
o
N
o
N
s
e
Y
2
t
u
p
t
u
O
4
5
0.0
o
N
o
N
s
e
Y
s
e
Y
3
t
u
p
t
u
O
etc.
Simulaon
Overview:
This ﬁle contains macros that run @RISK and generate requested tables 
of results for (1) any allowed number of iteraons, (2) any number of 
(nonrandom) inputs in the blue cells, (3) any  values of these inputs you 
want to test, and (4) any number of outputs in the gray cells. The Model 
sheet should be set up exactly as this. In parcular, you shouldn't 
rename any of the bright yellow cells, and you should keep the headings 
in the light yellow cells right below the Tables requested label. To see 
completed versions of this template, open and run World Series 
Simulaon.xlsm or Newsvendor Simulaon.xlsm.
Inputs:
Enter as many inputs (with appropriate labels)  as 
you'd like in column A, any values for them in 
column B, and values you'd like to test starng in 
column D. (Insert rows for more inputs if 
necessary.) The program will run a simulaon for 
each combinaon of these input values.
Outputs:
Enter as many outputs (with appropriate labels) as 
you'd like in column A, and corresponding formulas 
(based on the simulaon) in column B. (Insert rows
for more outputs if necessary.) Then request the 
stats you'd like for the various outputs starng in 
column D.
Simulaon model:
Develop the simulaon here. It should be 
dependent on the inputs above in column 
B, and the outputs above in column B 
should be dependent on it.
Figure 11.52 Simulation Template
11.7 Using TopRank with @RISK for Powerful Modeling
691
have included two simulations based on it. They are included in the files World Series
Simulation.xlsm and Newsvendor Simulation.xlsm. (Again, remember that you must
enable the macros when you open any of these .xlsm files.)
11.7 USING TOPRANK WITH @RISK FOR POWERFUL MODELING
In this section, we illustrate how another Palisade Decision Tools add-in, TopRank, can be
used together with @RISK as a very powerful modeling combination. As you have seen,
@RISK introduces uncertainty explicitly into a spreadsheet model by allowing several
inputs to have probability distributions. Then it simulates random values from these.
However, if a model has many inputs, it is often a good idea to determine which inputs
have large effects on a key output variable. Those that have a relatively minor effect can be
treated as nonrandom, with best guesses used as their values. You can then focus on the
more important input variables and model them, with probability distributions, in an
appropriate manner.
TopRank is a what-if tool that allows you to see which of many inputs have large
effects on an output variable. You first develop a spreadsheet model in the usual way,
using best-guess values for all inputs. You then use TopRank to vary each of the inputs
through a designated range, while holding the other inputs constant. TopRank reports the
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

corresponding variation of any selected output. You can then see, usually through one of
several charts, which inputs are most critical. At this point, you can either conclude the
analysis or switch to @RISK and model the key inputs with appropriate probability dis-
tributions.
The following example, which illustrates how TopRank and @RISK can work in tan-
dem, is an extremely important one. Simulation in the business world is often used to ana-
lyze potential products. The profitability of a new product is highly uncertain because it
depends on many uncertain quantities. Many companies we have worked with (including
General Motors and Eli Lilly) begin the analysis of every new product by determining the
uncertain quantities that can affect the profitability of the product. This analysis is often the
deciding factor in whether the product is developed and marketed.
692
Chapter 11
Simulation Models
E X A M P L E
11.16 NEW PRODUCT DEVELOPMENT AT SIMTEX
S
imTex, a pharmaceutical company, is in the early stages of developing a new drug
called Biathnon. As with most new drugs, the future of Biathnon is highly uncertain.
For example, its introduction into the market could be delayed, pending tests by the Food
and Drug Administration (FDA). Also, its market could be diminished by a potential rival
product from SimTex’s competition. SimTex has identified the following key inputs that
will affect Biathnon’s future profitability:
■
Number of years after product is developed until it is produced (due to potential FDA
delays)
■
Number of years the product sells
■
Initial cost incurred in developing the product
■
Salvage value obtained from equipment after production of the product has been
discontinued
■
Fixed production cost incurred during years in which the product is manufactured
■
Unit cost of producing the product
■
Unit price of the product
■
Initial demand for the product during the first year it is sold
■
Annual percentage growth in demand for the product
■
Percentage of demand for the product that is lost to the competition
■
Discount rate used to discount cash flows from the product
These are the inputs to a profitability model for Biathnon. A natural question is how
changes in the inputs affect the key output—the NPV of Biathnon over its lifetime. How
can SimTex use TopRank and @RISK to analyze this NPV?
Objective
To use TopRank to identify the inputs that affect NPV most, and then to use
@RISK to model these inputs with probability distributions.
WHERE DO THE NUMBERS COME FROM?
Most of the inputs in the preceding list are difficult to estimate. However, this is exactly
why TopRank is being used: to see how sensitive NPV is to the various input values. Then
the company can spend more energy trying to estimate the inputs that really matter.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Solution
The first step is to develop a profitability model for Biathnon’s NPV as a function of the
various inputs. For this first step, you can use best guess values for the inputs.
DEVELOPING THE BASIC MODEL
This model appears in Figure 11.53. (See the file New Product 1.xlsx.9) The particular
assumptions are spelled out in the text box, the inputs are listed in rows 4 to 14, and the
model is developed in rows 18 to 29. The details are as follows:
11.7 Using TopRank with @RISK for Powerful Modeling
693
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
A
B
C
D
E
F
G
H
AE
AF
AG
AH
AI
Model of new product by SimTex 
e
g
n
a
R
st
u
p
n
I
 names used:
Years 
1
2
$
B
$
!le
d
o
M
=
h
t
w
o
r
g
_
d
n
a
m
e
d
_la
u
n
n
A
2
d
e
y
ale
d
Product lifeme
12
Annual_ﬁxed_cost
=Model!$B$17
Development cost
$120,000
Development_cost
=Model!$B$15
Salvage value
$20,000
Discount_rate
=Model!$B$23
Annual ﬁxed cost
$6,000
Inial_demand
=Model!$B$20
Unit 
2
2
$
B
$
!le
d
o
M
=
s
ela
s
_
ts
o
L
2
$
ts
o
c
Unit 
4
1
$
B
$
!le
d
o
M
=
e
m
it
e
fil_
tc
u
d
o
r
P
5
$
e
cir
p
Inial demand
20000
Salvage_value
=Model!$B$16
Annual demand growth
10%
Unit_cost
=Model!$B$18
Lost 
9
1
$
B
$
!le
d
o
M
=
e
cir
p
_
tin
U
%
0
2
s
ela
s
Discount rate
10%
Years_delayed
=Model!$B$13
Financial model (shown for any number of years the product might live)
2
1
0
r
a
e
Y
3
4
5
6
29
30
Development cost
$120,000
Producing product?
No
No
No
Yes
Yes
Yes
Yes
No
No
Fixed 
0
$
0
$
0
0
0,6
$
0
0
0,6
$
0
0
0,6
$
0
0
0,6
$
0
$
0
$
ts
o
c
Total 
0
0
0
2
6
6
2
0
0
2
4
2
0
0
0
2
2
0
0
0
0
2
0
0
d
n
a
m
e
d
SimTex's 
0
0
6
9
2
1
2
0
6
3
9
1
0
0
6
7
1
0
0
0
6
1
0
0
d
n
a
m
e
d
Variable 
0
$
0
$
2
9
5,2
4
$
0
2
7,8
3
$
0
0
2,5
3
$
0
0
0,2
3
$
0
$
0
$
ts
o
c
0
$
0
$
0
8
4,6
0
1
$
0
0
8,6
9
$
0
0
0,8
8
$
0
0
0,0
8
$
0
$
0
$
e
u
n
e
v
e
R
Salvage 
0
$
0
$
0
$
0
$
0
$
0
$
0
$
0
$
e
ula
v
Net proﬁt
-$120,000
$0
$0
$42,000
$46,800
$52,080
$57,888
$0
$0
NPV of proﬁt
$284,237
Assumpons:
1.  Development costs occur at the end of year 0.
2.  It takes some years (speciﬁed in cell B4) unl producon begins.  
Inial demand, ﬁxed costs, variable costs, and revenues begin in this 
year.
3.  The product is produced for the lifeme speciﬁed in cell B5. At the 
end of the product lifeme, the salvage value is obtained.
4.   All revenues, costs occur at the ends of the respecve years.  The 
NPV is discounted back to the beginning of year 1.
Figure 11.53 The Basic SimTex Model
1
Timing. The key to this model is the timing in row 20—whether Biathnon is being
produced in any year. To allow for general (even noninteger) values in cells B4 and B5,
enter the formula
=IF(AND(B18>Years_delayed,B18<=Years_delayed+Product_lifetime),''Yes'',''No'')
in cell B20 and copy it across row 20. For example, with the inputs used in this base-case
model, Biathnon is produced only in years 3 to 14, so these are the only years (from year 1
on) that contribute to NPV.
9This example has been split into three separate files—one for the base model, one for the TopRank model, and
one for the @RISK model.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

2
Financials and other formulas. The formulas in the other cells are then straightfor-
ward. For year 1 (column C), the formulas in rows 21 to 27 are
=IF(C20=''Yes'',Annual_fixed_cost,0) 
=IF(AND(B20=''No'',C20=''Yes''),Initial_demand,IF(C20=''Yes'',B22*(1+Annual_
demand_growth),0))
=IF(C22=0,0,C22*(1-Lost_sales))
=IF(C23=0,0,C23*Unit_cost)
=IF(C23=0,0,C23*Unit_Price)
=IF(AND(C20=''Yes'',D20=''No''),Salvage_value,0)
and
=-C19-C21-C24+C25+C26
The second of these formulas (in cell C22) might require some explanation. The first
IF checks whether production occurs this year but not the previous year. If so, this must be
the first year of production, so that the demand is the initial demand. Otherwise, the second
IF checks whether production is still occurring. If so, then demand is the previous year’s
demand plus the growth percentage. Similarly, the formula for salvage value in cell C26
checks whether production occurs this year but not next year. If so, then this must be the
year when the salvage value is obtained.
3
NPV. Calculate the NPV (discounted to the beginning of year 0) in cell B29 with the
formula
=NPV(Discount_rate,C27:AF27)+B27
Note that the fixed cost in cell B27 is not discounted.
Now that the model has been developed, you could use trial and error (or data tables)
to see how the NPV reacts to changes in the inputs. However, TopRank does this for you.
Actually, it can be used in a number of ways. We discuss only one of them, although it
appears to us to be the most useful.
USING TOPRANK
To use TopRank, all you need to modify is the input section.10 Instead of entering constants
in the input cells, you should enter TopRank’s RISKVARY function. This function has the
syntax
=RISKVARY(base,minimum,maximum,rangetype,steps,distribution)
where
■
base is the base case (best guess) for the input.
■
minimum is the smallest possible value for the input.
■
maximum is the largest possible value for the input.
■
rangetype is 0, 1, or 2 and determines the way minimum and maximum should be
entered (even though 0 is the default value, we use rangetype 2—see the TopRank
manual for more details).
■
steps is the number of values from minimum to maximum to use for this input.
■
distribution is an optional argument that we omit.
694
Chapter 11
Simulation Models
10 This discussion assumes that TopRank is open within Excel. It can be opened exactly like @RISK, from the
Start button of Windows.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

You should set up the input section for TopRank as shown in Figure 11.54. (See the
file New Product 2.xlsx.) All entries in columns C to E are constants (not formulas). For
example, for the development cost in row 6, the base case is $120,000, but the development
costs should vary from 90% to 150% of this base case—that is, from $108,000 to
$180,000. To implement this, enter the formula
=RISKVARY(D4,C4*D4,E4*D4,2,8)
in cell B4 and copy it down to cell B14. This formula tells TopRank to vary this input from
its minimum to its maximum in eight steps. (The next-to-last argument, 2, implies that the
second and third arguments are the actual minimum and maximum.)
11.7 Using TopRank with @RISK for Powerful Modeling
695
3
4
5
6
7
8
9
10
11
12
13
14
A
B
C
D
E
Inputs
Actual
Low
Base
High
Years delayed
2.12
50%
2
300%
Product lifeme
7.75
50%
12
200%
Development cost
$168,539
90%
$120,000
150%
Salvage value
$23,116
0%
$20,000
150%
Annual ﬁxed cost
$5,751
80%
$6,000
125%
Unit 
%
0
5
1
2
$
%
0
5
4
0.2
$
ts
o
c
Unit 
%
5
2
1
5
$
%
0
6
1
4.3
$
e
cir
p
Inial demand
18149.54
30%
20000
120%
Annual demand growth
9%
50%
10%
120%
Lost 
%
0
0
2
%
0
2
%
0
%
0
1
s
ela
s
Discount rate
16%
60%
10%
200%
Figure 11.54
Inputs for the 
SimTex Model
Figure 11.55
TopRank Ribbon
To use TopRank, proceed in four steps, very much as in @RISK: (1) use the Analysis
Settings button (see the TopRank ribbon in Figure 11.55) to make various settings; (2) use
the Add Output button to select one or more output cells; (3) use the Report Settings button
to indicate the outputs you want and the Utilities dropdown list to indicate where you
want them to be placed; and (4) use the Run What-if Analysis button to perform the
calculations.
For step (1), you can accept all of the default settings. For step (2), highlight the NPV
cell (B29) and click on the Add Output button. For step (3), click on the Report Settings
button. We suggest checking the Tornado Graph, Spider Graph, and Sensitivity Graphs
options, although you can experiment with the other options. Then if you want the results
to be placed in the same workbook as the model (as we do), click on the Utilities dropdown
arrow and then on Application Settings, where you can choose the option to place the
reports in the Active Workbook. (These Application Settings will then apply to all future
TopRank models unless you change them.) Finally, run the analysis in step (4) by clicking
on the Run What-if Analysis button. TopRank varies each input cell from its minimum to
its maximum, using the number of steps you specified and keeping the other inputs at their
base levels, and keeps track of all the NPVs.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Perhaps the best way to understand the TopRank results is through the tornado
chart in Figure 11.56. Each bar in the chart indicates the variation in NPV as an indi-
vidual input varies from its minimum to its maximum. For example, NPV decreases by
about 70% and increases by about 147% (from its base-case value) when product
lifetime varies from its minimum (6 years) to its maximum (24 years). Because the
longer bars are always on the top and the shortest are always on the bottom, the inputs
at the top of the chart are always the most important ones. In this case, the five most
important inputs are product lifetime, unit price, initial demand, discount rate, and unit
production cost.
Clearly, if SimTex is going to simulate the product’s NPV, it should spend most of its
time accurately assessing the probability distributions of these five key inputs. In contrast,
the tornado chart indicates that annual fixed cost and salvage value have very little effect
on NPV. Therefore, little effort should be spent trying to estimate their values accurately—
the base-case values suffice.
Before proceeding to a simulation, we mention two other chart types available in
TopRank: spider charts and sensitivity charts. A spider chart for the SimTex model appears
in Figure 11.57. (We altered the original spider chart to make it less cluttered. Specifically,
we right-clicked on the chart, then on Select Data, and removed all but the five most impor-
tant inputs from the tornado chart.) This chart is fairly straightforward. For each of the five
inputs shown, a curve shows the percentage change in NPV as a function of the percentage
change in the input (over the range specified for the input).
From this spider chart you learn, not surprisingly, that changes in unit price, unit cost,
and initial demand result in linear changes in NPV. Also, a 1% increase in unit price results
in a larger percentage increase in NPV than does a 1% percentage increase in initial
696
Chapter 11
Simulation Models
Product_lifeme (B5)
Unit_price (B10)
Inial_demand (B11)
Discount_rate (B14)
Unit_cost (B9)
Lost sales (B13)
Tornado Graph of NPV of proﬁt
Impact by Input
-100000
0
100000
200000
300000
400000
500000
600000
700000
800000
Lost_sales (B13)
Years_delayed (B4)
Annual_demand_growth (B12)
Year / Base (D18)
Development_cost (B6)
Value of NPV of proﬁt
Figure 11.56
TopRank Tornado
Chart
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

demand. (Can you see why?) As the discount rate increases, NPV decreases, but the rate of
decrease slows; after a while, increases in the discount rate cannot decrease NPV much
further. Increases in product lifetime appear to increase product NPV in a slightly nonlinear
fashion.
The final TopRank chart type, a sensitivity chart, is similar to a spider chart, except that
it shows one input only. Also, it shows actual values rather than percentage changes. For
example, a graph of NPV versus product lifetime appears in Figure 11.58.
Running an @RISK Simulation
The sensitivity analysis with TopRank has indicated that the five key drivers of NPV are
product lifetime, unit price, unit cost, initial product demand, and discount rate. You can
now run an @RISK simulation of this model to estimate the distribution of NPV earned
from Biathnon. You keep all inputs other than the five key inputs fixed at their base values,
11.7 Using TopRank with @RISK for Powerful Modeling
697
50%
100%
150%
200%
hange
Spider Graph of NPV of proﬁt 
Product_lifeme (B5)
-150%
-100%
-50%
0%
-80%
-60%
-40%
-20%
0%
20%
40%
60%
80%
100%
120%
Output % C
Input % Change
Unit_cost (B9)
Unit_price (B10)
Inial_demand (B11)
Discount_rate (B14)
Figure 11.57
TopRank Spider
Chart
800000
Sensivity Graph
NPV of proﬁt vs Product_lifeme 
500000
600000
700000
f proﬁt
200000
300000
400000
Value of NPV o
0
100000
-8
-6
-4
-2
0
2
4
6
8
10
12
14
Value of Product_lifeme
Figure 11.58 TopRank Sensitivity Chart
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

and you use @RISK functions for the key inputs. Actually, you should use random func-
tions for product lifetime, unit price, unit cost, and initial demand. In contrast, you can
vary discount rate systematically with a RISKSIMTABLE function.11
Which probability distributions should be used to model the product lifetime, unit
price, unit cost, and initial demand inputs? There are several ways to proceed in general.
First, if there is a lot of historical data on any input, you can use the fitting capabilities of
@RISK to fit a distribution to the historical data. It is unlikely that SimTex has relevant
historical data that pertain to this new product, so this approach doesn’t look promising
here. Second, you can use @RISK’s Model window to examine shapes of potential candi-
date distributions. Finally, you can choose a simple distribution that management under-
stands and then assess its parameters.
The latter approach has been used here with a triangular distribution for each of the
random inputs. The use of triangular distributions is common at many companies such as
General Motors and Eli Lilly, primarily because it makes no assumption that the distribu-
tion of the uncertain quantity is symmetric about the mean or most likely value. In fact, the
use of the triangular distribution at GM to model uncertain quantities in the analysis of new
products grew directly out of deterministic Tornado Chart analysis.
To assess a triangular distribution for any input, all you need are minimum, most
likely, and maximum values for the input. You can use the same values of these that were
used in the TopRank analysis. They are shown in columns E to G of Figure 11.59. (See the
file New Product 3.xlsx.) Then you can enter the usual @RISK formulas in random input
cells. For example, the formula in cell B5 is
=RISKTRIANG(E5,F5,G5)
698
Chapter 11
Simulation Models
11The discount rate used in a typical new product analysis is usually a corporate rate of 10% to 15% and is
obtained from the CAPM (Capital Asset Pricing Model). Riskier projects should be discounted at a higher rate
than the corporate rate, and less risky projects should be discounted at a lower rate than the corporate rate.
3
4
5
6
7
8
9
10
11
12
13
14
A
B
C
D
E
F
G
H
Inputs
Actual
Parameters for triangular distribuons
Years 
ts
o
M
m
u
m
ini
M
m
o
d
n
a
r
n
o
n
2
d
e
y
ale
d
 likely Maximum
Product lifeme
16.39
triangular
6
12
24
Development cost
$120,000
nonrandom
Salvage value
$20,000
nonrandom
Annual ﬁxed cost
$6,000
nonrandom
Unit 
0
0.3
$
0
0.2
$
0
0.1
$
r
alu
g
n
airt
6
7.2
$
ts
o
c
Unit 
5
2.6
$
0
0.5
$
0
0.3
$
r
alu
g
n
airt
4
7.4
$
e
cir
p
Inial demand
11095
triangular
6000
20000
24000
Annual demand growth
10%
nonrandom
Lost 
elb
a
t
m
is
k
siR
m
o
d
n
a
r
n
o
n
%
0
2
s
ela
s
 values for discount rate
Discount rate
6%
use risksimtable
6%
10%
15%
20%
Figure 11.59
Parameters for
Triangular
Distributions and
Discount Rates
Next, you can model various discount rates in cell B14 with a RISKSIMTABLE func-
tion in the usual way, using the discount rates in the range E14:H14. This allows you to try
a discount rate appropriate for a less risky project (6%), a project of average risk (10%),
and a project of higher risk (15% or 20%). Finally, you should designate the NPV as the
single @RISK output cell.
You can now run @RISK in the usual way, using 1000 iterations and four simulations
(one for each discount rate). Selected results appear in Figure 11.60. If the project is
assessed to be less risky than the company’s typical project (justifying a 6% discount rate),
the project has a mean NPV (often called the risk-adjusted project NPV) of $380,672,
whereas if the project is so risky that it deserves a 20% discount rate, the risk-adjusted
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

NPV is only $34,376. Even if the project is extremely risky, it is still worth doing because
it has a positive risk-adjusted NPV.
Note that the standard deviations are fairly large, and there is a possibility that the
NPV will be negative. However, given the positive means and high upside potential, most
companies would be willing to accept this amount of risk and go ahead with the product.
■
11.8 Conclusion
699
Figure 11.60
Selected @RISK 
Results
FUNDAMENTAL INSIGHT
Identifying Key Inputs
Not all inputs are equally important in terms of their
effect on an output. It is essential to identify the k ey
inputs, those that produce the largest changes in the
output when they vary over their anticipated ranges.
An ad d-in such as TopRank helps identify the k
ey
inputs, although this could also be accomplished with
Excel data tables.If an input is identified as being rela-
tively unimportant, it is probably safe to set this equal
to a best guess in the model.
However, the uncer-
tainty in the key inputs should be modeled explicitl y
with random functions in a simulation model.
11.8 CONCLUSION
We claimed in the previous chapter that spreadsheet simulation, especially together with an
add-in like @RISK, is a very powerful tool. After seeing the examples in this chapter, you
should now appreciate how powerful and flexible simulation is. Unlike Solver optimization
models, where you often make simplifying assumptions to achieve linearity, say, you can
allow virtually anything in simulation models. All you need to do is relate output cells to
input cells with appropriate formulas, where any of the input cells can contain probability
distributions to reflect uncertainty. The results of the simulation then show the distribution
of any particular output. It is no wonder that companies such as GM, Eli Lilly, and many
others are increasingly relying on simulation models to analyze their corporate operations.
Summary of Key Terms
Term
Explanation
Excel
Page
Gamma distribution
Right-skewed distribution of nonnegative 
628
values useful for many quantities such as 
the lifetime of an appliance
RISKGAMMA 
Implements the gamma distribution 
RISKGAMMA
630
function
in @RISK
(alpha,beta)
(continued)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

700
Chapter 11
Simulation Models
Summary of Key Terms
(Continued)
Term
Explanation
Excel
Page
Value at risk at the 5%
Fifth percentile of distribution of some output,
645
level (VAR 5%)
usually a monetary output; indicates nearly
the worst possible outcome
Churn
When customers stop buying a product or
667
service and switch to a competitor’s offering
RANDBETWEEN
Generates a random integer between two limits,
RANDBETWEEN
684
function
where each is equally likely
(1,6), for example
TopRank
Used for deterministic what-if analysis, 
Use TopRank ribbon
691
to see which inputs affect an output most
RISKVARY 
Used with TopRank to specify that 
RISKVARY (base, minimum, 
694
function
an input should be varied over 
maximum, rangetype, steps, 
some range
distribution)
P R O B L E M S
Skill-Building Problems
44. You now have $3000. You will toss a fair coin four
times. Before each toss you can bet any amount of
your money (including none) on the outcome of the
toss. If heads comes up, you win the amount you bet.
If tails comes up, you lose the amount you bet. Your
goal is to reach $6000. It turns out that you can
maximize your chance of reaching $6000 by betting
either the money you have on hand or $6000 minus
the money you have on hand, whichever is smaller.
Use simulation to estimate the probability that you
will reach your goal with this betting strategy.
45. You now have $10,000, all of which is invested in a
sports team. Each year there is a 60% chance that the
value of the team will increase by 60% and a 40%
chance that the value of the team will decrease by
60%. Estimate the mean and median value of your
investment after 50 years. Explain the large difference
between the estimated mean and median.
46. Suppose you have invested 25% of your portfolio in
four different stocks. The mean and standard deviation
of the annual return on each stock are shown in the file
P11_46.xlsx. The correlations between the annual
returns on the four stocks are also shown in this file.
a. What is the probability that your portfolio’s annual
return will exceed 20%?
b. What is the probability that your portfolio will lose
money during the year?
47. A ticket from Indianapolis to Orlando on Deleast
Airlines sells for $150. The plane can hold 100 people.
It costs Deleast $8000 to fly an empty plane. Each
person on the plane incurs variable costs of $30 (for
food and fuel). If the flight is overbooked, anyone who
cannot get a seat receives $300 in compensation. On
average, 95% of all people who have a reservation
show up for the flight. To maximize expected profit,
how many reservations for the flight should Deleast
book? (Hint: The function RISKBINOMIAL can be
used to simulate the number who show up. It takes two
arguments: the number of reservations booked and the
probability that any ticketed person shows up.)
48. Based on Marcus (1990). The Balboa mutual fund has
beaten the Standard and Poor’s 500 during 11 of the
last 13 years. People use this as an argument that you
can beat the market. Here is another way to look at it
that shows that Balboa’s beating the market 11 out of
13 times is not unusual. Consider 50 mutual funds,
each of which has a 50% chance of beating the market
during a given year. Use simulation to estimate the
probability that over a 13-year period the best of the
50 mutual funds will beat the market for at least 11 out
of 13 years. This probability turns out to exceed 40%,
which means that the best mutual fund beating the
market 11 out of 13 years is not an unusual occurrence
after all.
49. You have been asked to simulate the cash inflows to a
toy company for the next year. Monthly sales are
independent random variables. Mean sales for the
months January through March and October through
December are $80,000, and mean sales for the months
April through September are $120,000. The standard
deviation of each month’s sales is 20% of the month’s
mean sales. Model the method used to collect monthly
sales as follows:
■During each month a certain fraction of new sales
will be collected. All new sales not collected
become one month overdue.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

11.8 Conclusion
701
■During each month a certain fraction of one-month
overdue sales is collected. The remainder becomes
two months overdue.
■During each month a certain fraction of two-month
overdue sales is collected. The remainder is written
off as bad debt.
You are given the information in the file P11_49.xlsx
from past months. Using this information, build a
simulation model that generates the total cash inflow
for each month. Develop a simple forecasting model
and build the error of your forecasting model into the
simulation. Assuming that there are $120,000 of one-
month-old sales outstanding and $140,000 of two-
month-old sales outstanding during January, you are
95% sure that total cash inflow for the year will be
between what two values?
50. Consider a device that requires two batteries to
function. If either of these batteries dies, the device
will not work. Currently there are two new batteries
in the device, and there are three extra new batteries.
Each battery, once it is placed in the device, lasts a
random amount of time that is triangularly
distributed with parameters 15, 18, and 25 (all
expressed in hours). When any of the batteries in the
device dies, it is immediately replaced by an extra if
an extra is still available. Use @RISK to simulate the
time the device can last with the batteries currently
available.
51. Consider a drill press containing three drill bits. The
current policy (called individual replacement) is to
replace a drill bit when it fails. The firm is considering
changing to a block replacement policy in which all
three drill bits are replaced whenever a single drill bit
fails. Each time the drill press is shut down, the cost is
$100. A drill bit costs $50, and the variable cost of
replacing a drill bit is $10. Assume that the time to
replace a drill bit is negligible. Also, assume that the
time until failure for a drill bit follows an exponential
distribution with a mean of 100 hours. This can be
modeled in @RISK with the formula RISKEXPON
(100). Determine which replacement policy (block or
individual replacement) should be implemented.
52. Appliances Unlimited (AU) sells refrigerators. Any
refrigerator that fails before it is three years old is
replaced for free. Of all refrigerators, 3% fail during
their first year of operation; 5% of all one-year-old
refrigerators fail during their second year of operation;
and 7% of all two-year-old refrigerators fail during
their third year of operation.
a. Use simulation to estimate the fraction of all
refrigerators that will have to be replaced.
b. It costs $500 to replace a refrigerator, and AU sells
10,000 refrigerators per year. If the warranty period
were reduced to two years, how much per year in
replacement costs would be saved?
53. The annual demand for Prizdol, a prescription drug
manufactured and marketed by the NuFeel Company,
is normally distributed with mean 50,000 and standard
deviation 12,000. Assume that demand during each of
the next 10 years is an independent random number
from this distribution. NuFeel needs to determine how
large a Prizdol plant to build to maximize its expected
profit over the next 10 years. If the company builds a
plant that can produce x units of Prizdol per year, it
will cost $16 for each of these x units. NuFeel will
produce only the amount demanded each year, and
each unit of Prizdol produced will sell for $3.70. Each
unit of Prizdol produced incurs a variable production
cost of $0.20. It costs $0.40 per year to operate a unit
of capacity.
a. Among the capacity levels of 30,000, 35,000,
40,000, 45,000, 50,000, 55,000, and 60,000 units
per year, which level maximizes expected profit?
Use simulation to answer this question.
b. Using the capacity from your answer to part a,
NuFeel can be 95% certain that actual profit for the
10-year period will be between what two values?
54. A company is trying to determine the proper capacity
level for its new electric car. A unit of capacity provides
the potential to produce one car per year. It costs
$10,000 to build a unit of capacity and the cost is
charged equally over the next five years. It also costs
$400 per year to maintain a unit of capacity (whether or
not it is used). Each car sells for $14,000 and incurs a
variable production cost of $10,000. The annual demand
for the electric car during each of the next five years is
believed to be normally distributed with mean 50,000
and standard deviation 10,000. The demands during
different years are assumed to be independent. Profits
are discounted at a 10% annual interest rate. The
company is working with a five-year planning horizon.
Capacity levels of 30,000, 40,000, 50,000, 60,000, and
70,000 are under consideration. You can assume that the
company never produces more than demand, so there is
never any inventory to carry over from year to year.
a. Assuming that the company is risk neutral, use
simulation to find the optimal capacity level.
b. Using the answer to part a, there is a 5% chance
that the actual discounted profit will exceed what
value, and there is a 5% chance that the actual
discounted profit will be less than what value?
c. If the company is risk averse, how might the
optimal capacity level change?
55. The DC Cisco office is trying to predict the revenue it
will generate next week. Ten deals may close next
week. The probability of each deal closing and data on
the possible size of each deal (in millions of dollars)
are listed in the file P11_55.xlsx. Use simulation to
estimate total revenue. Based on the simulation, the
company can be 95% certain that its total revenue will
be between what two numbers?
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

702
Chapter 11
Simulation Models
Skill-Extending Problems
56. A common decision is whether a company should buy
equipment and produce a product in house or
outsource production to another company. If sales
volume is high enough, then by producing in house,
the savings on unit costs will cover the fixed cost of
the equipment. Suppose a company must make such a
decision for a four-year time horizon, given the
following data. Use simulation to estimate the
probability that producing in house is better than
outsourcing.
■If the company outsources production, it will have
to purchase the product from the manufacturer for
$18 per unit. This unit cost will remain constant for
the next four years.
■The company will sell the product for $40 per unit.
This price will remain constant for the next four
years.
■If the company produces the product in house, it
must buy a $400,000 machine that is depreciated
on a straight-line basis over four years, and its cost
of production will be $7 per unit. This unit cost
will remain constant for the next four years.
■The demand in year 1 has a worst case of 10,000
units, a most likely case of 14,000 units, and a best
case of 16,000 units.
■The average annual growth in demand for years
2–4 has a worst case of 10%, a most likely case of
20%, and a best case of 26%. Whatever this annual
growth is, it will be the same in each of the years.
■The tax rate is 40%.
■Cash flows are discounted at 12% per year.
57. Consider an oil company that bids for the rights to
drill in offshore areas. The value of the right to drill in
a given offshore area is highly uncertain, as are the
bids of the competitors. This problem demonstrates
the “winner’s curse.” The winner’s curse states that the
optimal bidding strategy entails bidding a substantial
amount below the company’s assumed value of the
product for which it is bidding. The idea is that if the
company does not bid under its assumed value, its
uncertainty about the actual value of the product will
often lead it to win bids for products on which it loses
money (after paying its high bid). Suppose Royal
Conch Oil (RCO) is trying to determine a profit-
maximizing bid for the right to drill on an offshore oil
site. The actual value of the right to drill is unknown,
but it is equally likely to be any value between $10
million and $110 million. Seven competitors will bid
against RCO. Each bidder’s (including RCO’s)
estimate of the value of the drilling rights is equally
likely to be any number between 50% and 150% of the
actual value. Based on past history, RCO believes that
each competitor is equally likely to bid between 40%
and 60% of its value estimate. Given this information,
what fraction (within 0.05) of RCO’s estimated value
should it bid to maximize its expected profit? (Hint:
You can use the RISKUNIFORM function to model
the actual value of the field and the competitors’ bids.)
58. Suppose you begin year 1 with $5000. At the
beginning of each year, you put half of your money
under a mattress and invest the other half in
Whitewater stock. During each year, there is a 50%
chance that the Whitewater stock will double, and
there is a 50% chance that you will lose half of your
investment. To illustrate, if the stock doubles during
the first year, you will have $3750 under the mattress
and $3750 invested in Whitewater during year 2. You
want to estimate your annual return over a 30-year
period. If you end with F dollars, your annual return is
(F/5000)1/30 – 1. For example, if you end with
$100,000, your annual return is 201/30 – 1  0.105, or
10.5%. Run 1000 replications of an appropriate
simulation. Based on the results, you can be 95%
certain that your annual return will be between which
two values?
59. Mary Higgins is a freelance writer with enough spare
time on her hands to play the stock market fairly
seriously. Each morning she observes the change in
stock price of a particular stock and decides whether
to buy or sell, and if so, how many shares to buy or
sell. Assume that on day 1, she has $100,000 cash to
invest and that she spends part of this to buy her first
500 shares of the stock at the current price of $50 per
share. From that point on, she follows a fairly simple
“buy low, sell high” strategy. Specifically, if the price
has increased three days in a row, she sells 25% of her
shares of the stock. If the price has increased two days
in a row (but not three), she sells 10% of her shares. In
the other direction, if the price has decreased three
days in a row, she buys up to 25% more shares,
whereas if the price has decreased only two days in a
row, she buys up to10% more shares. The reason for
the “up to” proviso is that she cannot buy more than
she has cash to pay for. Assume a fairly simple model
of stock price changes, as described in the file
P11_59.xlsx. Each day the price can change by as
much as $2 in either direction, and the probabilities
depend on the previous price change: decrease,
increase, or no change. Build a simulation model of
this strategy for a period of 75 trading days. (You can
assume that the stock price on each of the previous
two days was $49.) Choose interesting @RISK output
cells, and then run @RISK for at least 1000 iterations
and report your findings.
60. You are considering a 10-year investment project. At
present, the expected cash flow each year is $10,000.
Suppose, however, that each year’s cash flow is
normally distributed with mean equal to last year’s
actual cash flow and standard deviation $1000. For
example, suppose that the actual cash flow in year 1 is
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

$12,000. Then year 2 cash flow is normal with mean
$12,000 and standard deviation $1000. Also, at the
end of year 1, your best guess is that each later year’s
expected cash flow will be $12,000.
a. Estimate the mean and standard deviation of the
NPV of this project. Assume that cash flows are
discounted at a rate of 10% per year.
b. Now assume that the project has an abandonment
option. At the end of each year you can abandon
the project for the value given in the file
P11_60.xlsx. For example, suppose that year
1 cash flow is $4000. Then at the end of year 1,
you expect cash flow for each remaining year to be
$4000. This has an NPV of less than $62,000, so
you should abandon the project and collect $62,000
at the end of year 1. Estimate the mean and
standard deviation of the project with the
abandonment option. How much would you pay
for the abandonment option? (Hint: You can
abandon a project at most once. So in year 5, for
example, you abandon only if the sum of future
expected NPVs is less than the year 5 abandonment
value and the project has not yet been abandoned.
Also, once you abandon the project, the actual cash
flows for future years are zero. So in this case the
future cash flows after abandonment should be zero
in your model.)
61. Play Things is developing a new Hannah Montana
doll. The company has made the following
assumptions:
■The doll will sell for a random number of years
from 1 to 10. Each of these 10 possibilities is
equally likely.
■At the beginning of year 1, the potential market for
the doll is one million. The potential market grows
by an average of 5% per year. The company is 95%
sure that the growth in the potential market during
any year will be between 3% and 7%. It uses a
normal distribution to model this.
■The company believes its share of the potential
market during year 1 will be at worst 20%, most
likely 40%, and at best 50%. It uses a triangular
distribution to model this.
■The variable cost of producing a doll during year
1 has a triangular distribution with parameters $8,
$10, and $12.
■The current selling price is $20.
■Each year, the variable cost of producing the doll
will increase by an amount that is triangularly
distributed with parameters 4.5%, 5%, and 6.5%.
You can assume that once this change is generated,
it will be the same for each year. You can also
assume that the company will change its selling
price by the same percentage each year.
■The fixed cost of developing the doll (which is
incurred right away, at time 0) has a triangular
distribution with parameters $4, $6, and $12
million.
■Right now there is one competitor in the market.
During each year that begins with four or fewer
competitors, there is a 20% chance that a new
competitor will enter the market.
■Year t sales (for t  1) are determined as follows.
Suppose that at the end of year t – 1, n competitors
are present (including Play Things). Then during
year t, a fraction 0.9 – 0.1n of the company’s loyal
customers (last year’s purchasers) will buy a doll
from Play Things this year, and a fraction 
0.2 – 0.04n of customers currently in the market
who did not purchase a doll last year will purchase
a doll from Play Things this year. Adding these two
provides the mean sales for this year. Then the
actual sales this year is normally distributed with
this mean and standard deviation equal to 7.5% of
the mean.
a. Use @RISK to estimate the expected NPV of this
project.
b. Use the percentiles in @RISK’s output to find an
interval such that you are 95% certain that the
company’s actual NPV will be within this interval.
62. An automobile manufacturer is considering whether
to introduce a new model called the Racer. The
profitability of the Racer depends on the following
factors:
■The fixed cost of developing the Racer is
triangularly distributed with parameters $3, $4, and
$5, all in billions.
■Year 1 sales are normally distributed with mean
200,000 and standard deviation 50,000. Year 2 sales
are normally distributed with mean equal to actual
year 1 sales and standard deviation 50,000. Year 3
sales are normally distributed with mean equal to
actual year 2 sales and standard deviation 50,000.
■The selling price in year 1 is $25,000. The year
2 selling price will be 1.05[year 1 price 	 $50
(% diff1)] where % diff1 is the number of
percentage points by which actual year 1 sales
differ from expected year 1 sales. The 1.05 factor
accounts for inflation. For example, if the year 1
sales figure is 180,000, which is 10 percentage
points below the expected year 1 sales, then the
year 2 price will be 1.05[25,000 	 50(–10)] 
$25,725. Similarly, the year 3 price will be
1.05[year 2 price 	 $50(% diff2)] where % diff2
is the percentage by which actual year 2 sales differ
from expected year 2 sales.
■The variable cost in year 1 is triangularly
distributed with parameters $10,000, $12,000, and
$15,000, and it is assumed to increase by 5% each
year.
Your goal is to estimate the NPV of the new car during
its first three years. Assume that the company is able
11.8 Conclusion
703
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

704
Chapter 11
Simulation Models
to produce exactly as many cars as it can sell. Also,
assume that cash flows are discounted at 10%.
Simulate 1000 trials to estimate the mean and standard
deviation of the NPV for the first three years of sales.
Also, determine an interval such that you are 95%
certain that the NPV of the Racer during its first three
years of operation will be within this interval.
63. It costs a pharmaceutical company $40,000 to produce
a 1000-pound batch of a drug. The average yield from
a batch is unknown but the best case is 90% yield (that
is, 900 pounds of good drug will be produced), the
most likely case is 85% yield, and the worst case is
70% yield. The annual demand for the drug is
unknown, with the best case being 22,000 pounds, the
most likely case 18,000 pounds, and the worst case
12,000 pounds. The drug sells for $60 per pound and
leftover amounts of the drug can be sold for $8 per
pound. To maximize annual expected profit, how
many batches of the drug should the company
produce? You can assume that it will produce the
batches only once, before demand for the drug is
known.
64. A truck manufacturer produces the Off Road truck.
The company wants to gain information about the
discounted profits earned during the next three years.
During a given year, the total number of trucks sold in
the United States is 500,000 	 50,000G – 40,000I,
where G is the number of percentage points increase
in gross domestic product during the year and I is the
number of percentage points increase in the consumer
price index during the year. During the next three
years, Value Line has made the predictions listed in
the file P11_64.xlsx. In the past, 95% of Value Line’s
G predictions have been accurate within 6%, and 95%
of Value Line’s I predictions have been accurate
within 5%. You can assume that the actual G and I
values are normally distributed each year.
At the beginning of each year, a number of competitors
might enter the trucking business. The probability
distribution of the number of competitors that will
enter the trucking business is also given in the same
file. Before competitors join the industry at the
beginning of year 1, there are two competitors. During
a year that begins with n competitors (after competitors
have entered the business, but before any have left, and
not counting Off Road), Off Road will have a market
share given by 0.5(0.9)n. At the end of each year, there
is a 20% chance that any competitor will leave the
industry. The selling price of the truck and the
production cost per truck are also given in the file.
Simulate 1000 replications of the company’s profit for
the next three years. Estimate the mean and standard
deviation of the discounted three-year profits, using a
discount rate of 10% and Excel’s NPV function. Do the
same if the probability that any competitor leaves the
industry during any year increases to 50%.
65. Suppose you buy an electronic device that you operate
continuously. The device costs you $300 and carries a
one-year warranty. The warranty states that if the
device fails during its first year of use, you get a new
device for no cost, and this new device carries exactly
the same warranty. However, if it fails after the first
year of use, the warranty is of no value. You plan to
use this device for the next six years. Therefore, any
time the device fails outside its warranty period, you
will pay $300 for another device of the same kind.
(We assume the price does not increase during the six-
year period.) The time until failure for a device is
gamma distributed with parameters   2 and  
0.5. (This implies a mean of one year.) Use @RISK to
simulate the six-year period. Include as outputs (1)
your total cost, (2) the number of failures during the
warranty period, and (3) the number of devices you
own during the six-year period.
66. Rework the previous problem for a case in which the
one-year warranty requires you to pay for the new
device even if failure occurs during the warranty
period. Specifically, if the device fails at time t,
measured relative to the time it went into use, you
must pay $300t for a new device. For example, if the
device goes into use at the beginning of April and fails
nine months later, at the beginning of January, you
must pay $225. The reasoning is that you got 9/12 of
the warranty period for use, so you should pay that
fraction of the total cost for the next device. As before,
however, if the device fails outside the warranty
period, you must pay the full $300 cost for a new
device.
67. Based on Hoppensteadt and Peskin (1992). The
following model (the Reed–Frost model) is often used
to model the spread of an infectious disease. Suppose
that at the beginning of period 1, the population
consists of five diseased people (called infectives) and
95 healthy people (called susceptibles). During any
period there is a 0.05 probability that a given infective
person will encounter a particular susceptible. If an
infective encounters a susceptible, there is a 0.5
probability that the susceptible will contract the
disease. An infective lives for an average of 10 periods
with the disease. To model this, assume that there is a
0.10 probability that an infective dies during any given
period. Use @RISK to model the evolution of the
population over 100 periods. Use your results to
answer the following questions. [Hint: During any
period there is probability 0.05(0.50)  0.025 that an
infective will infect a particular susceptible. Therefore,
the probability that a particular susceptible is not
infected during a period is (1 – 0.025)n, where n is the
number of infectives present at the end of the previous
period.]
a. What is the probability that the population will die
out?
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

b. What is the probability that the disease will die
out?
c. On the average, what percentage of the population
is infected by the end of period 100?
d. Suppose that people use infection “protection”
during encounters. The use of protection reduces
the probability that a susceptible will contract the
disease during a single encounter with an infective
from 0.50 to 0.10. Now answer parts a through c
under the assumption that everyone uses
protection.
68. Chemcon has taken over the production of Nasacure
from a rival drug company. Chemcon must build a plant
to produce Nasacure by the beginning of 2010. Once the
plant is built, the plant’s capacity cannot be changed.
Each unit sold brings in $10 in revenue. The fixed cost
(in dollars) of producing a plant that can produce x units
per year of the drug is 5,000,000 	 10x. This cost is
assumed to be incurred at the end of 2010. In fact, you
can assume that all cost and sales cash flows are incurred
at the ends of the respective years. If a plant of capacity
x is built, the variable cost of producing a unit of
Nasacure is 6 – 0.1(x – 1,000,000)/100,000. For
example, a plant capacity of 1,100,000 units has a
variable cost of $5.90. Each year a plant operating cost
of $1 per unit of capacity is also incurred. Based on a
forecasting sales model from the previous 10 years,
Chemcon forecasts that demand in year t, Dt, is related
to the demand in the previous year, Dt–1, by the equation
Dt  67,430 	 0.985Dt–1 	 et where et is normally
distributed with mean 0 and standard deviation 29,320.
The demand in 2009 was 1,011,000 units. If demand for
a year exceeds production capacity, all demand in excess
of plant capacity is lost. If demand is less than capacity,
the extra capacity is simply not used. Chemcon wants to
determine a capacity level that maximizes expected
discounted profits (using a discount rate of 10%) for the
time period 2010 through 2019. Use simulation to help it
do so.
69. The Tinkan Company produces one-pound cans for
the Canadian salmon industry. Each year the salmon
spawn during a 24-hour period and must be canned
immediately. Tinkan has the following agreement with
the salmon industry. The company can deliver as many
cans as it chooses. Then the salmon are caught. For
each can by which Tinkan falls short of the salmon
industry’s needs, the company pays the industry a $2
penalty. Cans cost Tinkan $1 to produce and are sold
by Tinkan for $2 per can. If any cans are left over, they
are returned to Tinkan and the company reimburses
the industry $2 for each extra can. These extra cans are
put in storage for next year. Each year a can is held in
storage, a carrying cost equal to 20% of the can’s
production cost is incurred. It is well known that the
number of salmon harvested during a year is strongly
related to the number of salmon harvested the previous
year. In fact, using past data, Tinkan estimates that the
harvest size in year t, Ht (measured in the number of
cans required), is related to the harvest size in the
previous year, Ht–1, by the equation Ht  Ht–1et where
et is normally distributed with mean 1.02 and standard
deviation 0.10.
Tinkan plans to use the following production strategy.
For some value of x, it produces enough cans at the
beginning of year t to bring its inventory up to 
,
where 
is the predicted harvest size in year t.
Then it delivers these cans to the salmon industry. 
For example, if it uses x  100,000, the predicted
harvest size is 500,000 cans, and 80,000 cans are
already in inventory, then Tinkan produces and delivers
520,000 cans. Given that the harvest size for the
previous year was 550,000 cans, use simulation to help
Tinkan develop a production strategy that maximizes
its expected profit over the next 20 years. Assume that
the company begins year 1 with an initial inventory of
300,000 cans.
70. You are unemployed, 21 years old, and searching for a
job. Until you accept a job offer, the following
situation occurs. At the beginning of each year, you
receive a job offer. The annual salary associated with
the job offer is equally likely to be any number
between $20,000 and $100,000. You must
immediately choose whether to accept the job offer. If
you accept an offer with salary $x, you receive $x per
year while you work (assume you retire at age 70),
including the current year. Assume that cash flows are
discounted so that a cash flow received one year from
now has a present value of 0.9. You decide to accept
the first job offer that exceeds w dollars.
a. Use simulation to determine the value of w (within
$10,000) that maximizes the expected NPV of
earnings you will receive the rest of your working
life.
b. Repeat part a, but now assume that you get a 3%
raise in salary every year after the first year you
accept the job.
71. A popular restaurant in Indianapolis does a brisk
business, filling virtually all of its seats from 6 P.M.
until 9 P.M. Tuesday through Sunday. Its current
annual revenue is $2.34 million. However, it does not
currently accept credit cards, and it is thinking of
doing so. If it does, the bank will charge 4% on all
receipts during the first year. (To keep it simple,
you can ignore taxes and tips and focus only on the
receipts from food and liquor.) Depending on
receipts in year 1, the bank might then reduce its
fee in succeeding years, as indicated in the file
P11_71.xlsx. (This would be a one-time reduction,
at the end of year 1 only.) This file also contains
parameters of the two uncertain quantities, credit card
usage (percentage of customers who will pay with
credit cards) and increased spending (percentage
HN
t
x + HN
t
11.8 Conclusion
705
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

706
Chapter 11
Simulation Models
increase in spending by credit card users, presumably
on liquor but maybe also on more expensive food).
The restaurant wants to simulate a five-year horizon.
Its base case is not to accept credit cards at all, in
which case it expects to earn $2.34 million in revenue
each year. It wants to use simulation to explore other
options, where it will accept credit cards in year 1
and then discontinue them in years 2–5 if the bank
fee is less than or equal to some cutoff value. For
example, one possibility is to accept credit cards in
year 1 and then discontinue them only if the bank fee
is less than or equal to 3%. You should explore the
cutoffs 2% to 4% in increments of 0.5%. Which
policy provides with the largest mean increase in
revenue over the five-year horizon, relative to never
using credit cards?
72. The Ryder Cup is a three-day golf tournament
played every other year with 12 of the best
U.S. golfers against 12 of the best European golfers.
They play 16 team matches (each match has two
U.S. golfers against two European golfers) on
Friday and Saturday, and they play 12 singles
matches (each match has a single U.S. golfer
against a European golfer) on Sunday. Each match
is either won or tied. A win yields 1 point for the
winning team and 0 points for the losing team. A tie
yields 0.5 point for each team. A team needs
14.5 points to win the Cup. If each team gets
14 points, the tournament is a tie, but the preceding
winner gets to keep the Cup. In 1999, the U.S. was
behind 10 points to 6 after the team matches. To
win the Cup, the U.S. needed at least 8.5 points on
Sunday, a very unlikely outcome, but they pulled off
the miracle and won. Use simulation to estimate the
probability of the U.S. scoring at least 8.5 points in
the 12 singles matches, assuming all golfers in the
tournament are essentially equal. Proceed as
follows.
a. Use simulation to estimate the probability, call it h
(for half), that a given match ends in a tie. To do
this, you can assume that any of the 18 holes is
tied with probability 0.475 and won with
probability 0.525. (These are the historical
fractions of holes that have been tied and won in
singles matches in the past few Ryder Cups.) Note
that each match is “match play,” so the only thing
that counts on each hole is whether a golfer has
fewer strokes than the other golfer—winning a
hole by one stroke is equivalent to winning the
hole by two or more strokes in match play. The
player winning the most holes wins the match,
unless they tie.
b. Run another simulation, using the estimated
probability h as an input, to estimate the
probability that the U.S. will score at least
8.5 points in the 12 singles matches.
73. Based on Bukiet et al. (1997). Many Major League
teams (including Oakland, Boston, LA Dodgers, and
Toronto) use mathematical models to evaluate baseball
players. A common measure of a player’s offensive
effectiveness is the number of runs generated per
inning (RPI) if a team were made up of nine identical
copies of this player. For example, which team would
score more runs: a team with nine copies of Ichiro
Suzuki or a team with nine copies of Manny Ramirez?
We can use simulation to answer this question. Let’s
consider a simplified baseball game in which each
plate appearance results in one of six outcomes:
■
Out: Runners do not advance.
■
Walk: Runners advance if forced.
■
Single: Runner on first moves to second. All other
runners score.
■
Double: Runner on first moves to third. All other
runners score.
■
Triple: All runners on base score.
■
Home Run: All runners and batter score.
A team gets three outs per inning. You are given the
data in the file P11_73.xlsx on Ichiro Suzuki and
Manny Ramirez from the 2004 season. Use simulation
to determine which hitter is more valuable according
to the RPI criterion.
74. In this version of “dice blackjack,” you toss a single
die repeatedly and add up the sum of your dice tosses.
Your goal is to come as close as possible to a total of 7
without going over. You may stop at any time. If your
total is 8 or more, you lose. If your total is 7 or less,
the “house” then tosses the die repeatedly. The house
stops as soon as its total is 4 or more. If the house
totals 8 or more, you win. Otherwise, the higher total
wins. If there is a tie, the house wins. Consider the fol-
lowing strategies:
■
Keep tossing until your total is 3 or more.
■
Keep tossing until your total is 4 or more.
■
Keep tossing until your total is 5 or more.
■
Keep tossing until your total is 6 or more.
■
Keep tossing until your total is 7 or more.
For example, suppose you keep tossing until your total
is 4 or more. Here are some examples of how the
game might go:
■
You toss a 2 and then a 3 and stop for total of 5.
The house tosses a 3 and then a 2. You lose
because a tie goes to the house.
■
You toss a 3 and then a 6. You lose.
■
You toss a 6 and stop. The house tosses a 3 and
then a 2. You win.
■
You toss a 3 and then a 4 for total of 7. The house
tosses a 3 and then a 5. You win.
Note that only 4 tosses need to be generated for the
house, but more tosses might need to be generated for
you, depending on your strategy. Develop a simulation
and run it for at least 1000 iterations for each of the
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

strategies listed previously. For each strategy, what are
the two values so that you are 95% sure that your
probability of winning is between these two values?
Which of the five strategies appears to be best?
75. It is now May 1 of year 0, and GM is deciding whether
to produce a new car. The following information is
relevant.
■
The fixed cost of developing the car is incurred on
January 1 of year 1 and is assumed to follow a tri-
angular distribution with smallest possible cost
$300 million, most likely cost $400 million, and
largest possible cost $700 million. The fixed cost
is depreciated on a straight-line base during years 2
to 5. The tax rate is 40%.
■
The car will first come to market during year 2 and
is equally likely to sell for 6, 7, or 8 years.
■
The market size during year 2 will be between
20,000 and 90,000 cars. There is a 25% chance that
the market size will be less than or equal to 50,000
cars, a 50% chance that it will be less than or equal
to 70,000 cars, and a 75% chance that it will be
less than or equal to 80,000 cars. After year 2, the
market size is assumed to grow by 5% per year.
■
The market share during year 2 is assumed to fol-
low a triangular distribution with most likely value
40%. There is a 5% chance that market share will
be 20% or less and a 5% chance that it will be 50%
or more. The market share during later years will
remain unchanged unless R&D makes a design
improvement.
■
There is a 50% chance that R&D will make a design
improvement during year 3, a 20% chance that it
will make a design improvement during year 4, and
a 30% chance that no design improvement will
occur. There will be at most one design improve-
ment. During the year (if any) in which a design
improvement occurs, GM’s market share will
increase to 50% above its current value. For exam-
ple, suppose GM’s market share at the beginning of
year 3 is 30%. If a design improvement occurs dur-
ing year 3, its market share during year 3 and all
later years will be 45%.
■
The car sells for $15,000 each year.
■
The cost of producing the first x cars is 10,000x0.9
dollars. This builds a learning curve into the cost
structure.
■
During year 2 and later years, cash flows are
assumed to occur midyear.
■
GM discounts its cash flows at 15% per year.
Use simulation to model GM’s situation. Based on the
simulation output, GM can be 95% sure that the NPV
generated by the car is between what two values?
Should GM produce this car? Explain why or why not.
What are the two key drivers of the car’s NPV? (Hint:
The way the uncertainty about the market size in
year 2 is stated suggests using the Cumul distribution,
implemented with the RISKCUMUL function. Look
it up in @RISK’s online help.)
76. It is January 1 of year 0, and Lilly is considering
developing a new drug called Dialis. We are given the
following information
■
On March 15 of year 0, Lilly incurs a fixed cost
that is assumed to follow a triangular distribution
with best case $10 million, most likely case $35
million, and worst case $50 million. This cost will
be depreciated on a straight-line basis during
years 1 to 6.
■
The product will be sold during years 1 to 6. In
years 1 and 2, the product will be sold only in the
United States, but starting in year 3, Lilly might
sell the product overseas. The year 1 market size in
the United States is assumed to be between
500,000 and 3,000,000 units. A market size of
1,000,000 units is assumed to be twice as likely as
a market size of 700,000, and a market size of
2,000,000 units is assumed to be three times as
likely as a market size of 700,000.
■
Lilly’s year 1 market share is assumed to follow a
triangular distribution with worst case 10%, most
likely case 20%, and best case 30%. Lilly assumes
that its market share will remain the same unless a
competitor enters the market.
■
The growth rate in market size in later years is
assumed to be the same each year. In year 1, it is
assumed to follow a triangular distribution with
worst case 5% annual growth, most likely case
12% annual growth, and best case 14% annual
growth.
■
A single competitor might enter the market. Each
year, the competitor has a 30% chance of entering
the market, assuming it has not already entered.
The year after entering the market, a competitor
causes a permanent loss of 40% of Lilly’s market
share. For example, suppose the competitor enters
in year 2, and Lilly’s share was 20%. Then in the
years 3 to 6, its market share will be 12%.
■
At the beginning of year 3, Lilly will decide
whether to sell Dialis overseas. If no competitor
has entered the market by the end of year 2, there is
a 70% chance that Lilly will sell the product over-
seas. If a competitor has entered the market by the
end of year 2, there is only a 30% chance that Lilly
will sell the product overseas. Lilly’s market share
overseas will equal its market share in the United
States. It estimates that the overseas market is 25%
of world sales for drugs of this type. (The other
75% is U.S. sales.)
■
Each year the product sells for $120 and incurs a
unit cost of $80.
■
Cash flows are discounted at 15% annually, and
profits are taxed at 40%.
■
Cash flows for years 1 to 6 take place midyear.
11.8 Conclusion
707
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Use simulation to model Lilly’s situation. Based on
the simulation output, Lilly can be 95% sure the NPV
for this project is between what two numbers? Would
you go ahead with this project? Explain why or why
not. (Hint: The way the uncertainty about the market
size in year 1 is stated suggests using the General
distribution, implemented with the RISKGENERAL
function. Look it up in @RISK’s online help.)
77. It is January 1 of year 0, and Merck is trying to deter-
mine whether to continue development of a new drug.
The following information is relevant. You can assume
that all cash flows occur at the ends of the respective
years.
■
Clinical trials (the trials where the drug is tested
on humans) are equally likely to be completed in
year 1 or 2.
■
There is an 80% chance that clinical trials will
succeed. If these trials fail, the FDA will not allow
the drug to be marketed.
■
The cost of clinical trials is assumed to follow a
triangular distribution with best case $100 million,
most likely case $150 million, and worst case $250
million. Clinical trial costs are incurred at the end
of the year clinical trials are completed.
■
If clinical trials succeed, the drug will be sold for
five years, earning a profit of $6 per unit sold.
■
If clinical trials succeed, a plant will be built during
the same year trials are completed. The cost 
of the plant is assumed to follow a triangular distri-
bution with best case $1 billion, most likely case
$1.5 billion, and worst case $2.5 billion. The plant
cost will be depreciated on a straight-line basis
during the five years of sales.
■
Sales begin the year after successful clinical trials.
Of course, if the clinical trials fail, there are no
sales.
■
During the first year of sales, Merck believe sales
will be between 100 million and 200 million units.
Sales of 140 million units are assumed to be three
times as likely as sales of 120 million units, and
sales of 160 million units are assumed to be twice
as likely as sales of 120 million units.
■
Merck assumes that for years 2 to 5 that the drug is
on the market, the growth rate will be the same
each year. The annual growth in sales will be
between 5% and 15%. There is a 25% chance that
the annual growth will be 7% or less, a 50% chance
that it will be 9% or less, and a 75% chance that it
will be 12% or less.
■
Cash flows are discounted 15% per year, and the
tax rate is 40%.
Use simulation to model Merck’s situation. Based on
the simulation output, would you recommend that
Merck continue developing? Explain your reasoning.
What are the three key drivers of the project’s NPV?
(Hint: The way the uncertainty about the first year sales
is stated suggests using the General distribution,
implemented with the RISKGENERAL function.
Similarly, the way the uncertainty about the annual
growth rate is stated suggests using the Cumul distribu-
tion, implemented with the RISKCUMUL function.
Look these functions up in @RISK’s online help.)
78. Nucleon is trying to determine whether to produce a
new drug that makes pigs healthier. The product will
be sold in years 1 to 5. The following information is
relevant:
■
A fixed cost is incurred on January 1 of year 0 and
will be between $1 billion and $5 billion. There is
a 20% chance the fixed cost will be less than or
equal to $2 billion, a 60% chance that it will be less
than or equal to $3 billion, and a 90% chance that it
will be less than or equal to $4 billion. The fixed
cost is depreciated on a straight-line basis during
years 1 to 5.
■
The weighted average cost of capital is 15%. This
is the rate Nucleon uses for discounting cash flows.
■
The market size in year 1 is 10 million pigs.
■
During each of years 2 to 5, the market size will
grow at the same rate. This growth rate is assumed
to follow a triangular distribution with best case
15%, most likely case 6%, and worst case 1%.
■
The selling price is always $100 per unit, and the
unit cost of production is always $16 per unit.
■
In year 1, the average number of units of the drug
sold for each pig will be between 1 and 2, with 1.3
and 1.7 being equally likely, and 1.5 being twice as
likely as 1.3.
■
There are three potential competitors. During each
of years 1 to 5, a competitor who has not entered
the market has a 60% chance of entering the
market.
■
The year after a competitor enters the market, the
average units sold per pig of the Nucleon drug
drops by 20% for each competitor entering. For
example, suppose that sales per pig are 1.5 units in
year 1. If two competitors enter the market in
year 1, Nucleon sales per pig drop to 0.9 in year 2.
■
All cash flows other than the fixed cost on January 1
of year 0 are incurred midyear.
Use simulation to model Nucleon’s situation. Based on
the simulation output, would you go ahead with this
project? Explain why or why not? What are the three
key drivers of the project’s NPV? (Hint: The way the
uncertainty about the fixed cost is stated suggests
using the Cumul distribution, implemented with the
RISKCUMUL function. Similarly, the way the uncer-
tainty about the units sold per pig in year 1 is stated
suggests using the General distribution, implemented
with the RISKGENERAL function. Look these func-
tions up in @RISK’s online help.)
708
Chapter 11
Simulation Models
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

79. Suppose you are using an underwater probe to search for
a sunken ship. At any time in the search, your probe is
located at some point (x,y) in a grid, where the distance
between lines in the grid is some convenient unit such as
100 meters. The sunken ship is at some unknown
location on the grid, (X,Y). If your probe is at (x,y), you
will move it to one of the eight nearby grid points
(x
1,y
1), (x
1,y), (x
1,y	1), (x,y
1), (x,y	1),
(x	1,y
1), (x	1,y), or (x	1,y	1), with probability 1/8
each, for the next search. If you start at (0,0) and the ship
is at (5,2), use simulation to estimate the probability that
you will find the ship in 100 moves or fewer.
Modeling Problems
80. We have separated the examples in this chapter into
operations, finance, marketing, and sports categories.
List at least one other problem in each of these cate-
gories that could be attacked with simulation. For
each, identify the random inputs, possible probability
distributions for them, and any outputs of interest.
81. Suppose you are an HR (human resources) manager at
a big university, and you sense that the university is
becoming too top-heavy with full professors. That is,
there do not seem to be as many younger professors at
the assistant and associate levels as there ought to be.
How could you study this problem with a simulation
model, using current and/or proposed promotions, hir-
ing, firing, and retirement policies?
82. You are an avid basketball fan, and you would like to
build a simulation model of an entire game so that you
could compare two different strategies, such as man-
to-man versus zone defense. Is this possible? What
might make this simulation model difficult to build?
83. Suppose you are a financial analyst and your company
runs many simulation models to estimate the prof-
itability of its projects. If you had to choose just two
measures of the distribution of any important output
such as net profit to report, which two would you
choose? Why? What information would be missing if
you reported only these two measures? How could
they be misleading?
84. Software development is an inherently risky and uncer-
tain process. For example, there are many examples of
software that couldn’t be “finished” by the scheduled
release date—bugs still remained and features weren’t
ready. (Many people believe this was the case with
Office 2007.) How might you simulate the development
of a software product? What random inputs would be
required? Which outputs would be of interest? Which
measures of the probability distrib-utions of these out-
puts would be most important?
85. Health care is continually in the news. Can (or should)
simulation be used to help solve, or at least study,
some of the difficult problems associated with health
care? Provide at least two examples where simulation
might be useful.
11.8 Conclusion
709
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

C A S E
Y
our next-door neighbor, Scott Jansen, has a 12-
year-old daughter, and he intends to pay the
tuition for her first year of college six years from
now.The tuition for the first year will be $17,500.
Scott has gone through his budget and finds that he
can invest $200 per month for the next six years.
Scott has opened accounts at two mutual funds.The
first fund follows an investment strategy designed to
match the return of the S&P 500.The second fund
invests in short-term Treasury bills. Both funds have
very low fees.
Scott has decided to follow a strategy in which
he contributes a fixed fraction of the $200 to each
fund. An adviser from the first fund suggested that in
each month he should invest 80% of the $200 in the
S&P 500 fund and the other 20% in the T-bill fund.
The adviser explained that the S&P 500 has averaged
much larger returns than the T-bill fund. Even though
stock returns are risky investments in the short run,
the risk should be fairly minimal over the longer 
six-year period. An adviser from the second fund
recommended just the opposite: invest 20% in the
S&P 500 fund and 80% in T-bills, because treasury bills
are backed by the United States government. If you
follow this allocation, he said, your average return
will be lower, but at least you will have enough to
reach your $17,500 target in six years.
Not knowing which adviser to believe, Scott has
come to you for help.
Questions
1. The file Investing for College.xlsxcontains
261 monthly returns of the S&P 500 and
Treasury bills from January 1970 through
September 1991. (If you can find more recent
data on the Web, feel free to use it.) Suppose
that in each of the next 72 months (six years), it
is equally likely that any of the historical returns
will occur. Develop a spreadsheet model to
simulate the two suggested investment strategies
over the six-year period. Plot the value of each
strategy over time for a single iteration of the
simulation.What is the total value of each
strategy after six years? Do either of the
strategies reach the target?
2. Simulate 1000 iterations of the two strategies
over the six-year period. Create a histogram of
the final fund values. Based on your simulation
results, which of the two strategies would you
recommend? Why?
3. Suppose that Scott needs to have $19,500 to pay
for the first year’s tuition. Based on the same
simulation results, which of the two strategies
would you recommend now? Why?
4. What other real-world factors might be
important to consider in designing the
simulation and making a recommendation? ■
11.1 COLLEGE FUND INVESTMENT
710
Chapter 11
Simulation Models
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

C A S E
A
n investor is considering the purchase of zero-
coupon U.S.Treasury bonds. A 30-year zero-
coupon bond yielding 8% can be purchased today for
$9.94.At the end of 30 years, the owner of the bond
will receive $100.The yield of the bond is related to
its price by the following equation:
Here, P is the price of the bond, y is the yield of the
bond, and t is the maturity of the bond measured in
years. Evaluating this equation for t  30 and y 
0.08 gives P  9.94.
The investor is planning to purchase a bond
today and sell it one year from now. The investor is
interested in evaluating the return on the investment
in the bond. Suppose, for example, that the yield of
the bond one year from now is 8.5%.Then the price
of the bond one year later will be $9.39 [100/(1 
0.085)29].The time remaining to maturity is t  29
because one year has passed.The return for the year
is –5.54% [ (9.39 – 9.94)/9.94].
In addition to the 30-year-maturity zero-coupon
bond, the investor is considering the purchase of
zero-coupon bonds with maturities of 2, 5, 10, or
20 years. All of the bonds are currently yielding 8.0%.
(Bond investors describe this as a flat yield curve.)
The investor cannot predict the future yields of the
bonds with certainty. However, the investor believes
that the yield of each bond one year from now can
be modeled by a normal distribution with mean 8%
and standard deviation 1%.
Questions
1. Suppose that the yields of the five zero-coupon
bonds are all 8.5% one year from today.What
are the returns of each bond over the period?
2. Using a simulation with 1000 iterations,
estimate the expected return of each bond
over the year. Estimate the standard deviations
of the returns.
3. Comment on the following statement: “The
expected yield of the 30-year bond one year
from today is 8%. At that yield, its price would
be $10.73.The return for the year would be 8% 
[ (10.73 – 9.94)/9.94].Therefore, the average
return for the bond should be 8% as well. A
simulation isn’t really necessary. Any difference
between 8% and the answer in Question 2 must
be due to simulation error.” ■
P =
100
(1 + y)t
11.2 BOND INVESTMENT STRATEGY
Case 11.2 Bond Investment Strategy
711
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

713
Inventory Models
C H A P T E R
INVENT       OR  Y DECISIONS IN DELL           ’S SUPPL    Y CHAIN
D
ell is the largest computer-systems company based on estimates of
global market share, and it is also the fastest growing of the major
computer-systems companies competing in the business, education, govern-
ment, and consumer markets. Dell’s key to success is its strategy of bypassing
retailers and selling its products directly to customers. Inventory manage-
ment is extremely important to a company such as Dell. It not only incurs
the usual costs for holding inventory—loss of interest from capital tied up in
inventory and storage costs—but it also incurs huge costs from obsoles-
cence. Because of the rapid changes in technology, many computer compo-
nents lose from 0.5 to 2.0% of their value per week, so that a supply chain
filled with yesterday’s technology is practically worthless. Although Dell was
aware of the costs of holding too much inventory, it didn’t employ the types
of mathematical models discussed in this chapter for managing its inventory
until 1999, when it hired a group from the University of Michigan to study
the problem. The results of this study appear in Kapuscinski et al. (2004).
Due to direct sales, Dell actually carries very little inventory. It assembles
computer systems at its manufacturing plants in Austin,Texas, and ships them
to customers in just a few days. Therefore, the plants carry virtually no inven-
tory of finished goods. The inventory of computer components held at Dell’s
suppliers is a different story. Many of its suppliers are located in Southeast
Asia. Because transportation of components from Asia to Texas can take any-
where from a week to a month, Dell requires its suppliers to keep inventory
Gerry Broome/AP Photo
12
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

on hand in revolvers, small warehouses located within a few miles of Dell’s assembly plants
in Austin. Each revolver is shared by several suppliers who pay rents for using them. The
key problem is to reduce inventory at the revolvers, while maintaining an adequate ser-
vice level. (Dell’s service level is about 98.8%, meaning that the components it needs are
available about 98.8% of the time.) Dell shares its data on demand forecasts and actual
demands with its suppliers and provides guidelines on how to manage their inventory lev-
els at the revolvers. The authors recommended using an (R, Q) ordering policy at the
revolvers for one particular important component (called XDX in the paper to conceal
its identity). This means that when inventory of XDX reaches the reorder point R, the
supplier orders an amount Q.
When this type of ordering policy is discussed later in this chapter, you will see that
the difficult part is finding the appropriate reorder point R. During the time it takes an
order to arrive at the revolver, called the lead time, Dell experiences demand for the com-
ponent. To guard against stockouts in case this lead time demand is larger than expected,
R contains some safety stock. The amount of safety stock to hold depends on several fac-
tors: (1) the variance of demand during lead time, (2) the variance of the length of the
lead time, and (3) the desired service levels. The first two of these are caused by uncer-
tainty, whereas the third is based on costs. The authors performed a careful study of the
causes of uncertainty. They broke demand into two parts: the aggregate demand for com-
puter systems and the percentage of this aggregate demand for particular components
such as XDX. Another source of uncertainty, at least to the suppliers, is the “pull” vari-
ance. This occurs when multiple suppliers supply the same component in their revolvers.
Dell doesn’t “pull” from these suppliers at a uniform rate. It might use supplier A’s compo-
nents for a few days and then use supplier B’s for a few days. The authors examined how
each of these sources of uncertainty affects the amount of safety stock (and hence excess
inventory) prescribed by the model and suggested how better forecasting methods and
information sharing can lead to improved results.
In terms of service level, the authors used a critical fractile analysis to determine an
optimal service level. This critical fractile, also discussed later in this chapter, is a ratio of
the cost of having too little inventory (for example, lost profit from a canceled order and
increased shipping cost for not having a component when needed) to the cost of having
too much inventory (for example, cost of capital tied up in excess inventory and price
erosion from having obsolescent components).
The authors’ recommendations went into effect in 1999 and (to our knowledge) are
still being implemented. They estimated that Dell could reduce the current inventory
from 10.5 days by about 38%. (Dell thinks of inventory in terms of days of supply rather
than units on hand.) By removing approximately four days of safety-stock inventory,
they estimate that the NPV of savings in XDX passing through the revolvers is about
$43 million. Of course, as the authors’ system is used for other important components,
the savings will only increase. ■
714
Chapter 12
Inventory Models
12.1 INTRODUCTION
Inventory management is one of the most important decisions faced by many companies.
These companies include not only retailers that stock products for sale to customers like
you, but also companies that supply other companies. They all face two competing pressures.
The first is the pressure to have enough inventory on hand. The most obvious reason for
this is that they do not want to run out of products that customers demand. Another promi-
nent reason, however, is the fixed cost of ordering or producing, as discussed throughout
this chapter. If a fixed cost is incurred each time the company orders from its supplier, or a
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

fixed cost is incurred each time a manufacturer produces a batch, where this cost does not
depend on the order or batch size, the company has an incentive to place large orders or
produce large batches to minimize its annual fixed costs.1
The second pressure related to inventory management is the pressure to carry as little
inventory as possible. The most obvious reasons for this are the cost of storing items and
the interest costs involved in tying up money in inventory. If the company has to pay cash
for items that end up sitting on the shelf for long periods of time, it loses potential interest
on this money that could be invested elsewhere. Storage space is sometimes an issue as
well. Some companies simply do not have the space to store as much inventory as they
might like. For example, there is fierce competition for shelf space in supermarkets.
These two competing pressures are at the heart of most inventory models. Companies
want to order enough, but they do not want to order too much. The balance is typically not
easy to find, so they need models to determine the best ordering (or production) policy. An
inventory problem can usually be broken up into two parts: (1) how much to order on each
ordering opportunity and (2) when to order. When customer demand is assumed to be
known, the resulting models are called deterministic models. If customer demand is known
and the order quantity has been determined, then specifying when the orders should be
placed is relatively easy. A more realistic situation occurs when customer demand is uncer-
tain. In this case, the decision on when to place orders becomes more difficult. Orders
should be placed early enough so that the chance of running out before they arrive is fairly
small. These more difficult problems require probabilistic inventory models.
Inventory management as an academic subject falls somewhere between management
science and operations management. (We have been told that many instructors who use this
book for a management science class do not cover this chapter because it is covered in the
operations management course.) However, inventory management has long held an impor-
tant place in management science, both in theory and in practice. There is plenty of evidence
to support this claim. For example, a quick scan of Interfaces articles indicates there are
many real applications of inventory management and supply chain management. To name a
few, three articles by Billington et al. (2004), Guide et al. (2005), and Laval et al. (2005)
describe supply chain management at Hewlett-Packard; de Kok et al. (2005) describe how
Philips Electronics synchronizes its supply chain to minimize the so-called “bullwhip”
effect; Troyer et al. (2005) discuss inventory management and order fulfillment at Deere’s
Commercial and Consumer Equipment Division; and Bangash et al. (2004) discuss inventory
requirements planning at Lucent Technologies. (Four of these articles appeared in the prize-
winning issues of Interfaces.) So regardless of whether inventory management is discussed
in a management science course or an operations management course, this topic is extremely
important for today’s global organizations. Inventory management also uses a variety of
management science tools, many of which are described in this chapter.
12.2 CATEGORIES OF INVENTORY MODELS
Researchers have analyzed many inventory models, both deterministic and probabilistic.
We discuss only the most basic of these models, which have been used extensively in real
applications. We begin by discussing several important issues and introducing some termi-
nology.2 Keep in mind, however, that the possible number of real-world situations that
12.2 Categories of Inventory Models
715
1Some companies order products from vendors, whereas other companies produce the products they need. They
both face similar inventory decisions. Throughout most of the chapter, we focus on companies that order from
vendors, and we talk about order quantities, but similar models apply to companies that produce. They must
decide on production quantities, often called batch sizes.
2Entire books, such as Cachon and Terwiesch (2009), discuss the general topic of matching supply with demand
in much more depth than we provide here.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

require inventory management is virtually unlimited. We list only some of the factors that
are common to these situations.
Deterministic versus Probabilistic Models
We have already mentioned the distinction between deterministic and probabilistic inven-
tory models. In deterministic models, all inputs to the problem, particularly customer
demand, are assumed to be known when the decisions are made. In reality, a company
must always forecast future demands with some type of forecasting model. The outputs of
this forecasting model might include a mean demand and a standard deviation of demand.
In deterministic models, however, only the mean is used, and any information about the
uncertainty, such as the standard deviation, is ignored. This makes the resulting models
simpler, but usually less realistic. Probabilistic models use this information about uncer-
tainty explicitly. They are typically more difficult to analyze, but they tend to produce bet-
ter decisions, especially when the level of uncertainty is high.
External versus Internal Demand
A second factor in inventory modeling is whether demand for the product is generated
externally or internally. External demand (or independent demand) occurs when the com-
pany that sells the product cannot directly control the extent or the timing of customer
demand. For example, a retailer who orders products from a supplier and then waits to see
how many customers request these products faces external demand. In these situations, we
usually assume that ordering decisions are influenced by, but do not affect, customer
demand.
In contrast, internal demand (or dependent demand) occurs in most assembly and
manufacturing processes. Consider, for example, a company that manufactures laptop
computers. The external demand is for the finished product, but the internal demand is for
the components that go into the finished product. After the company forecasts the number
of laptops its customers will demand, say, in the next month, it must then determine an
appropriate production schedule for producing them. This production schedule will neces-
sitate having inventories of the laptop’s component parts and subassemblies on hand at the
right time. In short, the production schedule determines, in large part, the inventory
required for all of the individual parts and subassemblies. The coordination of all of
these—ensuring that everything is on hand when it is needed—is a complex problem that
we do not discuss in this book. However, it is a big part of supply chain management, a
topic that is receiving more attention than ever from both academics and practitioners. The
supply chain needs to ensure that the parts and subassemblies are available at the right time
and the right place (and at the cheapest cost) for manufacturers to compete in today’s busi-
ness environment.
Ordering versus Production
A third factor in inventory modeling is whether the company orders the products from a
supplier or produces them internally. If the products are ordered, then there is typically an
order lead time, the time elapsed from when the order is placed until it arrives. In ordering
models, there is also usually a fixed cost (also called a setup or ordering cost) each time
an order is placed, where this cost is independent of the order quantity. In contrast, if prod-
ucts are produced internally, there is also a lead time, the time it takes to produce a batch of
items. This time is determined by a production rate, such as 10 units per hour, and possibly
by a setup time, the fixed time necessary to set up any machinery to produce a specific type
716
Chapter 12
Inventory Models
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

of product. As in ordering models, there can also be a setup cost each time a batch is pro-
duced, where this cost is independent of the batch size.
Continuous versus Periodic Review
A fourth factor in inventory modeling is whether inventory is reviewed continuously or
periodically. In continuous review models, the inventory is monitored continually and
orders can be placed at any time. Typically, there is a reorder point—a specific inventory
level—so that when the inventory on hand reaches this reorder point, an order is placed
immediately. This could happen Wednesday afternoon, Friday morning, or any other time.
In contrast, in periodic review models, there is some standard time, such as every Monday
morning, when the inventory is reviewed and ordering decisions are made. Except possibly
for emergency orders, these are the only times when orders are placed. Continuous review
models can certainly be implemented, given today’s computerized access to inventory lev-
els in real time, and these models can result in lower annual costs than periodic review
models. However, when a company stocks many products (hundreds or even thousands), it
is often more convenient to order these, say, only on Monday mornings.
Single-Product versus Multiple-Product Models
A final factor in inventory modeling concerns the number of products involved. Models
that consider only a single product are conceptually and mathematically simpler, so we ini-
tially analyze single-product models. However, most companies have many different prod-
ucts that must be considered simultaneously. If the company orders these items from a
supplier, it may be wise to synchronize the orders in some way to minimize ordering costs.
We look at one such synchronization model in section 12.4.
12.3 TYPES OF COSTS IN INVENTORY MODELS
Companies face a number of costs when they manage inventories. Although the types of
costs vary depending on the company and the situation, the following costs are typical.
Ordering (or Setup) Cost
We have already mentioned the ordering (or setup) cost. This is the fixed cost incurred
every time an order is placed or a batch is produced, independent of the amount ordered or
produced. This ordering cost includes the cost of paperwork and billing each time an order
is placed and could include other costs as well, such as paying a truck driver to deliver the
order to the company’s warehouse. If the product is produced rather than ordered, this cost
can include the cost to set up equipment.
Unit Purchasing (or Production) Cost
The unit purchasing (or production) cost is the cost for each additional unit purchased or
produced (often referred to as the variable cost). For example, to order 100 units, the com-
pany might have to pay a setup cost of $500 plus $3 per unit, for a total of $800. Here, $3
is the unit purchasing cost. If the company produces the product, the unit production cost
includes the cost of raw materials and the labor cost for each unit produced. Sometimes the
unit purchasing cost is not constant but changes according to a quantity discount schedule.
We consider a quantity discount model in section 12.4.
12.3 Types of Costs in Inventory Models
717
The setup cost is inde-
pendent of the order
(or production batch)
size.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Holding (or Carrying) Cost
The holding (or carrying) cost is the cost that motivates the company to keep less inven-
tory on hand. This cost generally has two components, the financial holding cost and the
nonfinancial holding cost. The nonfinancial holding cost is usually the cost of storing the
product. For example, this might be the cost of renting warehouse space. The financial
holding cost is the opportunity cost of having money tied up in inventory when that money
could instead be earning interest in other investments. There can be other holding costs,
such as spoilage, insurance, and overhead, which vary according to the amount and type of
inventory on hand.
Shortage (or Penalty) Cost
It is often important to measure the cost of running out of inventory. This shortage (or
penalty) cost is a difficult cost to measure. For one thing, it depends on how the company
handles shortages. At one extreme, there are lost sales models, where any demands that
occur when inventory is zero are lost; these customers take their business elsewhere. At the
other extreme, there are complete backlogging models, where demands that occur when
inventory is zero are satisfied as soon as a new order arrives.3 Both of these models—or
any in between, called partial backlogging models—have negative effects for the com-
pany. There is lost revenue, loss of goodwill, and possibly expedited shipments with higher
costs. Unfortunately, it can be difficult to put a dollar value on the “cost” of running out of
inventory. An alternative is to specify a service level, such as meeting at least 95% of the
demand on time.
Revenue
Finally, there is the selling price of the product and the resulting revenue to the company.
In many situations, the revenue is a fixed amount that is not affected by any ordering deci-
sions. This occurs when the selling price remains constant and the company intends to sat-
isfy all demand eventually. In such cases, the total revenue can be added to the relevant
costs, but it does not affect any ordering or production decisions. On the other hand, there
are times, such as in lost sales models, when the selling price affects ordering decisions.
Here, the shortage cost depends on the amount of revenue lost by not having enough inven-
tory on hand, and this clearly depends on the selling price.
12.4 ECONOMIC ORDER QUANTITY (EOQ) MODELS
We first examine a class of models called economic order quantity (EOQ) models. These
are the most basic of all the inventory planning models. Developed originally in 1915 by
F. W. Harris of Westinghouse Corporation, they are also among the earliest management
science models. Despite their simplicity, numerous companies have applied these models,
and they  continue to play a prominent role in inventory management.
We begin by studying the most basic EOQ model. Then we examine several interest-
ing variations of this basic model. All of these models make the following assumptions:
■
A company orders a single product from a supplier and sells this product to its
customers.
718
Chapter 12
Inventory Models
A large part of the
holding cost is the cost
of capital tied up in
inventory.
3We also say the excess demand is backordered. Both terms, backlog and backorder, mean that these orders are
kept on the books and are satisfied when additional shipments arrive.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

■
Orders can be placed at any time (continuous review).
■
There is a constant, known demand rate for the product, usually expressed in units
per year (annual demand).
■
There is a constant, known lead time for delivery of the product from the supplier.
■
There is a fixed ordering cost each time the product is ordered, independent of the
size of the order.
■
The price the company charges for the product is fixed.
■
The annual holding cost is proportional to the average amount of inventory on hand.
The constant demand rate means, for example, that if the yearly demand is 52,000
units, then each week’s demand is approximately 1000 units—there are no peaks or valleys
during the year. The known lead time means that if the company places an order on
Monday and the lead time is three days, then the order arrives, with certainty, on Thursday.
We discuss the holding cost in more detail shortly.
The Basic EOQ Model
The most basic EOQ model adds the following two assumptions.
■
No stockouts are allowed; that is, the company never allows itself to run out of
inventory.
■
The unit cost of purchasing the product from the supplier is constant. In particular,
no quantity discounts are available.
These assumptions have important implications.
Because the demand rate and lead time are assumed
to be known, the company can ensure that it always
has enough on hand to meet demand on time. The
main decision is whether to order small amounts
frequently or to order large amounts infrequently.
The former results in large fixed costs and small
holding costs (less inventory on hand), whereas the
latter results in the opposite. The EOQ analysis bal-
ances these two competing forces.
We now analyze this basic EOQ model in the
following example.
12.4 Economic Order Quantity (EOQ) Models
719
A crucial assumption of
the basic EOQ model
is that demand occurs
at a constant known
rate through time.
FUNDAMENTAL INSIGHT
Importance of EOQ
The basic EOQ model and its variations are among the
simplest models discussed in this book, and they have
been known for close to a century. However, they cap-
ture the essence of man y companies’ pr oblems, and
they are still in wide use today. As with most models for
managing inventory, they balance the costs of or dering
too frequently and not ordering frequently enough.
E X A M P L E
12.1 ORDERING CAMERAS AT MACHEY’S
M
achey’s Department Store sells 1200 cameras per year, and the demand pattern
throughout the year is very steady. The store orders its cameras from a regional
warehouse, and it usually takes one week for the cameras to arrive after an order has been
placed. Each time an order is placed, an ordering cost of $125 is incurred. The store pays
$100 for each camera and sells them for $130 apiece. There is no physical storage cost, but
the store’s annual cost of capital is estimated at 8% per year—that is, it can earn 8% on any
excess cash it invests. The store wants to determine how often it should order cameras,
when it should place orders, and how many cameras it should order in each order.
Objective
To determine when to order and how much to order so that the store never runs
out of cameras and profit is maximized.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

WHERE DO THE NUMBERS COME FROM?
Throughout this chapter, you can refer back to sections 12.2 and 12.3 for a general discus-
sion of the inputs to these inventory problems. For this reason, there is no “Where Do the
Numbers Come From?” section in later examples.
Solution
We first discuss some basic quantities and relationships. Let D  1200 be the annual
demand. Because demand occurs steadily through the year, Machey’s places an order
every time its inventory gets sufficiently low. Therefore, there are really two decisions to
make: (1) when to order, and (2) how much to order. The first of these is straightforward.
Because the lead time is one week, and the demand in a week is D52, or about 23,
Machey’s should place an order when its inventory drops to 23 cameras. This way, the
order will arrive just as inventory runs out.
The second decision concerns the amount of each order. Let Q be the quantity ordered
each time an order is placed. This is the primary decision variable. After Q is determined,
the number of orders per year is given by
Number of orders per year  DQ
(12.1)
Equivalently, the time between orders (measured as a fraction of a year) is QD. For exam-
ple, if Q  300, Machey’s places DQ  4 orders per year, and the time between orders is
QD  0.25 year (three months). A graph of the company’s inventory through time
appears in Figure 12.1. The key aspect in this figure is that the inventory level jumps up to
Q whenever an order arrives and decreases linearly (due to demand) until the next order
arrives.
720
Chapter 12
Inventory Models
Figure 12.1
Inventory Level for
the Basic EOQ Model
Inventory
level
Time
Slope: D
Place order
Q/D
L
Q
The problem is to find an order quantity Q that maximizes Machey’s annual profit.
There are several components of the annual profit. First, each time Machey’s places an
order, it incurs a fixed ordering cost, labeled K. For this example, K  $125. Because DQ
orders are placed per year, the annual ordering cost is
Annual ordering cost  KDQ
(12.2)
In addition to this, Machey’s pays a variable cost, labeled c, for each camera it pur-
chases. Here, c  $100. Because the annual demand is D  1200 and all demand must be
met, the annual variable cost is cD  $120,000. Note that this cost does not depend on Q.
Similarly, the company’s revenue from each camera, labeled r, is r  $130, so its annual
revenue is rD. This is also unaffected by the order quantity Q.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Now consider the annual holding cost. There is no cost for physically storing the cam-
eras, but Machey’s loses money from potential investments by having excess cash tied up
in inventory. If i denotes Machey’s annual cost of capital, where i  0.08 (8%), it can be
shown from a net present value argument that the relevant annual holding cost is i multi-
plied by the average monetary value of inventory, where this average is over the entire year.
Because the inventory decreases linearly from Q to 0 between orders, the average level of
inventory at a typical point in time is (Q  0)2  Q2, which implies that the average
monetary value of inventory is cQ2. Therefore, the annual holding cost from money tied
up in inventory is
Annual financial holding cost  icQ2
(12.3)
[In general, if there is also a storage cost of s dollars per unit held in storage per year, the
total annual holding cost is (s  ic)Q2. In the inventory literature, the combined unit
holding cost,(s  ic), is usually labeled h.]
A spreadsheet can now be developed to optimize Machey’s annual profit.
DEVELOPING THE SPREADSHEET MODEL
The spreadsheet model appears in Figure 12.2. (See the file Basic EOQ.xlsx.) In the inter-
est of space, we do not list the individual steps for developing this model. All of the for-
mulas are based directly on Equations (12.1), (12.2), and (12.3). For example, the annual
holding cost, determined by Equation (12.3), is calculated in cell B18 with the formula
Annual_interest_rate*Unit_purchasing_cost*Order_quantity/2
Note that the only changing cell is the Order_quantity cell. It drives all of the quantities
below it except for the annual purchase cost and the annual revenue, which do not depend
on the order quantity. (They could actually be omitted from the model, although Machey’s
would then not be able to see its overall profit.) Also, note that the lead time is included
in the spreadsheet model, although it is never used in any formulas. Its only role is to
12.4 Economic Order Quantity (EOQ) Models
721
Figure 12.2
The Basic EOQ
Model
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
E
D
C
B
A
Machey's EOQ model
e
g
n
a
R
st
u
p
n
I
 names used:
Fixed ordering 
8
$
B
$
!le
d
o
M
=
d
n
a
m
e
d
_la
u
n
n
A
5
2
1
$
ts
o
c
Annual interest 
5
$
B
$
!le
d
o
M
=
e
t
a
r
_
ts
e
r
e
t
ni_la
u
n
n
A
%
8
e
t
a
r
Unit purchasing 
1
2
$
B
$
!le
d
o
M
=
tif
o
r
p
_la
u
n
n
A
0
0
1
$
ts
o
c
Selling price per 
4
$
B
$
!le
d
o
M
=
ts
o
c
_
g
nir
e
d
r
o
_
d
e
xiF
0
3
1
$
tin
u
Annual 
2
1
$
B
$
!le
d
o
M
=
ytit
n
a
u
q
_
r
e
d
r
O
0
0
2
1
d
n
a
m
e
d
Lead me in 
3
1
$
B
$
!le
d
o
M
=
r
a
e
y
_
r
e
p
_
sr
e
d
r
O
2
5
/
1
sr
a
e
y
Selling_price_per_unit
=Model!$B$7
Ordering model
Unit_purchasing_cost
=Model!$B$6
Order 
5
6.3
9
1
ytit
n
a
u
q
Orders per 
0
2.6
r
a
e
y
Time between orders (days)
58.90
Monetary values
Annual ﬁxed ordering 
5
7
7
$
ts
o
c
Annual holding 
d
e
tc
eff
A
5
7
7
$
ts
o
c
 by order quanty
Annual purchasing cost
$120,000
Annual 
d
e
tc
effa
n
U
0
0
0,6
5
1
$
e
u
n
e
v
e
r
 by order quanty
Annual 
1
5
4,4
3
$
tif
o
r
p
Alternave EOQ formula
193.65
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

determine when to order. You already saw that Machey’s should place an order when its
inventory drops to 23 cameras.
USING SOLVER
The Solver setup (not shown) is particularly simple. The objective is to maximize annual
profit with a single changing cell, the order quantity cell. There are no constraints other than
nonnegativity of the order quantity. (If you like, you can also constrain the order quantity to
be an integer. However, this is not really necessary. For all practical purposes, it suffices to
round the Solver solution to the nearest integer.) Also, GRG Nonlinear Solver should be
used, because the decision variable Q appears in the denominator of Equation (12.2) for the
annual ordering cost. This makes the model nonlinear.
Discussion of the Solution
The Solver solution specifies that Machey’s should order about 194 cameras each time it
orders. This results in about six orders per year or about one order every 59 days. Note
that the annual ordering cost and the annual financial holding cost for this optimal solu-
tion are equal. This is no coincidence. It always occurs in the basic EOQ model. Because
the annual purchasing cost and revenue do not depend on the order quantity, the problem
is essentially a trade-off between too many orders (high fixed ordering costs) and too
much inventory (high holding costs). Calculus can be used to show that Solver always
chooses the order quantity that makes these two costs equal. You can experiment with the
order quantity to see how this works. For example, if you enter 197 in cell B11, the annual
holding cost will be larger than the annual fixed ordering cost, and the annual profit will
be smaller than before. In the other direction, if you enter 190 in cell B11, the annual
fixed ordering cost will be larger than the annual holding cost, but again, the total profit
will be smaller than before. The optimal ordering quantity, the EOQ, achieves just the
right balance.
EOQ Formula
A feature of some nonlinear models, including this EOQ model, is that they have no con-
straints and can be solved with calculus—without the need for Solver. Although the details
are not given here, the calculus solution, shown in cell B23 of Figure 12.2, is that the opti-
mal order quantity satisfies
Q  2KDh

(12.4)
where in general, h is the combined unit holding cost, in this case ic. The advantage of
this well-known “square-root formula” is that it provides immediate insight into the
effects of changes in inputs. For example, the effect of quadrupling the annual demand is
to double the optimal order quantity. The disadvantage of this formula is that it holds only
under the assumptions in this section. If a company wants to modify the EOQ model to
meet any special circumstances, it is better to develop a flexible spreadsheet model and
then use Solver.
■
EOQ Models with Quantity Discounts
The next example illustrates one of many possible variations of the basic EOQ model.
In this variation, the company placing the order can obtain quantity discounts from its
supplier.
722
Chapter 12
Inventory Models
This famous EOQ (or
square root) formula
is found by using cal-
culus to minimize the
total annual cost (or
maximize the total
annual profit). It indi-
cates exactly how the
optimal order quan-
tity is related to the
key inputs.
Using the optimal
order quantity, the
annual fixed cost 
of ordering and the 
annual holding cost 
are always equal in 
the basic EOQ model.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

12.4 Economic Order Quantity (EOQ) Models
723
E X A M P L E
12.2 ORDERING THUMB DRIVES WITH QUANTITY DISCOUNTS AT AJ TAYLOR
T
he accounting firm of AJ Taylor buys USB thumb drives from a distributor of PC sup-
plies. The firm uses approximately 5000 drives per year at a fairly constant rate. The
distributor offers the following quantity discount. If fewer than 500 drives are ordered, the
cost per drive is $30. If at least 500 but fewer than 800 drives are ordered, the cost per
drive is $28. If at least 800 drives are ordered, the cost per drive is $26. The fixed cost of
placing an order is $100. The company’s cost of capital is 10% per year, and there is no
storage cost. The firm wants to find the optimal order quantity and the corresponding total
annual cost.
Objective
To find the order quantity that minimizes the total annual cost of ordering in
the face of quantity discounts.
Solution
The model is nonlinear for the same reason as in the basic EOQ model. There is now an
additional source of nonlinearity; namely, the unit cost is a nonlinear function of the order
quantity because of the quantity discount schedule. In the previous edition, we suggested a
clever use of SolverTable for the three regions of quantity discounts. (This solution is still
available in the file EOQ with Quantity Discounts Old Finished.xlsx .) However, we
present a more straightforward approach here, using GRG Nonlinear Solver with the
Multistart option discussed in Chapter 7.
DEVELOPING THE SPREADSHEET MODEL
The completed model appears in Figure 12.3. (See the file EOQ with Quantity
Discounts.xlsx.) The key points are the following:
1
Purchase cost function. Enter the parameters of the purchase cost function in the
range A10:B12. This range has been named Lookup_Table and can be used to find the unit
purchase cost for any order quantity.
Figure 12.3
The EOQ Model
with Quantity
Discounts
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
H
G
F
E
D
C
B
A
AJ Taylor's EOQ model with quanty discounts
e
g
n
a
R
st
u
p
n
I
 names used:
Fixed ordering 
a
m
e
d
_la
u
n
n
A
0
0
1
$
ts
o
c
nd
=Model!$B$6
Annual interest 
5
$
B
$
!le
d
o
M
=
e
t
a
r
_
ts
e
r
e
t
ni_la
u
n
n
A
%
0
1
e
t
a
r
Annual 
4
$
B
$
!le
d
o
M
=
ts
o
c
_
g
nir
e
d
r
o
_
d
e
xiF
0
0
0
5
d
n
a
m
e
d
Lookup_Table
=Model!$A$10:$B$12
Purchase cost funcon
Order_quanty
=Model!$B$15
Lower limit
Unit cost
Orders_per_year
=Model!$B$16
4
2
$
B
$
!le
d
o
M
=
ts
o
c
_la
u
n
n
a
_la
t
o
T
0
3
$
0
0
2
$
B
$
!le
d
o
M
=
ts
o
c
_
e
s
a
h
cr
u
p
_
tin
U
8
2
$
0
0
5
6
2
$
0
0
8
Ordering model
Order 
0
0.0
0
8
ytit
n
a
u
q
Orders per 
5
2.6
r
a
e
y
Time between orders (days)
58.40
Monetary values
Unit purchase 
6
2
$
ts
o
c
Annual ﬁxed ordering cost
$625
Annual holding 
0
4
0,1
$
ts
o
c
Annual purchasing cost
$130,000
Total annual 
5
6
6,1
3
1
$
ts
o
c
$120,000
$130,000
$140,000
$150,000
$160,000
400
425
450
475
500
525
550
575
600
625
650
675
700
725
750
775
800
825
850
875
900
Order quanty
Total annual cost vs Order quanty
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

2
Unit purchase cost. For any order quantity in cell B15, find the relevant unit pur-
chase cost by entering the formula
=VLOOKUP(Order_quantity,Lookup_Table,2)
in cell B20. Note that this returns the correct cost even at the breakpoints. For example, if
the order quantity is 800, as in the figure, the unit purchase cost is $26, as it should be.
3
Basic EOQ. Given the unit purchase cost in cell B20, develop the rest of the EOQ
model exactly as in the previous example. (This time, however, note that there is no reve-
nue. Everything is in terms of costs, so that the objective is to minimize.)
USING SOLVER
Solver should be set up as shown in Figure 12.4. Note that an upper bound of 2000 has
been placed on the order quantity, although any large value could be used. Also, because
the quantity discounts lead to a nonsmooth objective, it is a good idea to use the Multistart
option, as discussed in Chapter 7. Alternatively, Evolutionary Solver could be used, but it
doesn’t appear to be necessary. GRG Nonlinear Solver with the Multistart option finds the
optimal solution quickly.
724
Chapter 12
Inventory Models
Figure 12.4
Solver Dialog Box
for the Quantity
Discount Model
Discussion of the Solution
The Solver solution indicates that the company should order just enough units, 800, to
achieve the lowest unit purchase cost. You can check that if the order quantity is only 799,
the total annual cost increases by about $10,000, due mostly to the much larger annual
purchasing cost. In the other direction, if the order quantity increases to 801, the 
annual purchasing cost doesn’t change at all (why?), but the net effect of a slightly smaller
annual fixed ordering cost and a slightly larger annual holding cost is a slightly larger
total annual cost.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Additional insight is provided by the graph of total annual cost versus order quantity
in Figure 12.3. (This is based on a data table of cell B24 versus cell B15. See the finished
version of the file for details.) Within any quantity discount region, the curve increases
almost imperceptibly, but at quantity discount breakpoints, it decreases abruptly. This is
the nonsmooth feature mentioned earlier. This graph (along with the associated data table)
clearly indicates why 800 is the optimal order quantity.
■
EOQ Models with Shortages Allowed
A key assumption in the basic EOQ model is that the company decides, as a matter of pol-
icy, not to allow any shortages. Because the demand rate and the lead time are known, the
ordering can be done so that an order arrives just as the inventory level reaches zero. This
means that it is possible to prevent shortages from occurring. However, it might be in the
company’s best interests to allow a few shortages if the penalty for a shortage is not too
large. As discussed in section 12.2, this opens up a wide range of possible models.
First, are shortages backlogged or are these demands lost? And what about the penalty
cost for a shortage? Does the penalty relate only to the number of units short per year or
also to the amount of time the shortages last? After all, a customer might be twice as
unhappy if she has to wait two days instead of one day for her demand to be satisfied.
Whatever type of shortage cost is assumed, the practical difficulty is then assessing a spe-
cific dollar value for this cost. For example, what is the cost of having a customer wait at
all? What is the cost of having a customer wait three days?
The following example illustrates a complete backlog model where the penalty cost is
charged per unit short per amount of time short. In this case, the annual penalty cost is a con-
stant p multiplied by the product of the average number of units backlogged and the average
amount of time a customer has to wait for a backlogged unit. The constant p is the penalty
cost charged for each customer who has to wait one unit of time for one backlogged item.
12.4 Economic Order Quantity (EOQ) Models
725
Even though the order
quantity is Q, the
maximum inventory
level is only Qb
because part of the
order is used to satisfy
backlogged demand.
E X A M P L E
12.3 ORDERING AUDIO CDS AT GMB WITH SHORTAGES ALLOWED
G
MB is a mail-order distributor of audio CDs that sells approximately 50,000 CDs per
year. Each CD is packaged in a jewel case that GMB buys from a supplier. The fixed
cost of placing an order for jewel cases is $200. GMB pays $0.50 for each jewel case, and
its cost of capital is 10%. The cost of storing a jewel case for one year is $0.50. GMB
believes it can afford to run out of jewel cases from time to time, reasoning that this simply
makes the time between customer orders and customer deliveries a bit longer. It knows that
there is some cost of doing this—impatient customers can take their business elsewhere—
but it is not sure what dollar amount p to attach to this cost. It decides to use a trial value of
p  $52, reasoning that this value implies a $1 penalty for each extra week a customer has
to wait because of a backlogged jewel case. GMB wants to develop a spreadsheet model to
find the optimal order quantity, the optimal amount to backlog, and the optimal annual
cost. It also wants to see how sensitive these quantities are to the unit shortage cost p.
Objective
To find the order quantity and the maximum shortage allowed that minimize
total annual cost, and to see how sensitive the solution is to the unit shortage cost.
Solution
As in the basic EOQ model, the first step is to develop the components of the total annual
cost. The key is the saw-toothed graph shown in Figure 12.5. Now there are two decision
variables: Q, the order quantity, and b, the maximum amount backlogged. Each cycle has
length QD, the time to deplete Q units at demand rate D. But now a cycle has two parts.
There are several rea-
sonable ways to evalu-
ate the cost of not
satisfying customer
demand on time. Each
results in a slightly
different model.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

During time (Q  b)D (the time required to deplete the first Q  b units), there is posi-
tive inventory and demands are met on time. During the last section of each cycle of length
bD (the time it takes to delete b units), the inventory is negative, which means that short-
ages exist. The order for Q units is placed so that it arrives precisely when the inventory
level reaches b. When this order arrives, b units are used immediately to satisfy back-
logged demand and the other Q  b units go into on-hand inventory. Therefore, right after
any order arrives, there are Q  b units in inventory. Note that if there is an order lead time
of L, the order should be placed when the inventory level is DL units above its lowest point,
b. This is exactly analogous to the basic EOQ model, because DL is the amount of
demand during the lead time.
The total cost function, a function of both Q and b, is now fairly straightforward. The
annual setup cost is KDQ , the same as before, because there are DQ orders per year.
The annual purchase cost is cD because all demand is eventually satisfied. (The model in
this section uses a constant unit purchasing cost; no quantity discounts are available.) The
annual financial holding cost is again the interest rate times half of the purchase cost of an
order, icQ2.
To find the annual storage cost, refer to Figure 12.5. The storage cost per order cycle
is the unit storage cost s multiplied by the average inventory when inventory is positive,
(Q  b)2, multiplied by the amount of time during a cycle when inventory is positive,
(Q  b)D. To obtain the annual storage cost, the cost per cycle is multiplied by the num-
ber of cycles per year, DQ, to obtain
Annual storage cost  s[(Q  b)2][(Q  b)D](DQ)  s(Q  b)2(2Q) (12.5)
Again referring to Figure 12.5, the average shortage cost per cycle is p multiplied by
the average amount short when the inventory level is negative, b2, multiplied by the
amount of time during a cycle when inventory is negative, bD. Multiplying the shortage
cost per cycle by the number of cycles per year, DQ, gives
Annual shortage cost  p(b2)(bD)(DQ)  pb2(2Q)
(12.6)
DEVELOPING THE SPREADSHEET MODEL
The spreadsheet model for GMB appears in Figure 12.6. (See the file EOQ with
Shortages.xlsx.) Many of the details are omitted, because all formulas are based directly
on the cost equations shown previously. For example, the formula in cell B21 for the
annual shortage cost is
Shortage_cost_per_unit_per_year*Maximum_backlog^2/(2*Order_quantity)
This follows directly from Equation (12.6).
726
Chapter 12
Inventory Models
Inventory
level
Time
Place order here
Q/D
L
Q – b
(Q – b)/D
 b/D
–b
Q
Figure 12.5
The EOQ Model
with Shortages
Allowed
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

USING SOLVER
The Solver setup is also straightforward. The objective is to minimize the total annual cost,
with cells B12 and B13 as the changing cells, using GRG Nonlinear Solver. (You could
also constrain the changing cells to be integers, but this is not really necessary—you can
always round noninteger solutions to integers with little effect on costs.)
Discussion of the Solution
The solution indicates that GMB should order 6057 units each time it orders and should
plan its ordering so that there is a backlog of about 58 units when an order arrives. For
example, if the order lead time is one week (152 year), then because the demand during
lead time is DL  50,00052  962, GMB should place an order when the inventory level
reaches 962  58  904. That way, the backlog will be 58 units by the time the order
arrives. The optimal policy indicates that about eight orders will be placed per year. The
total annual cost is $28,302. However, only $3302 of this is affected by the ordering policy.
The other $25,000 is the total purchase cost, which is incurred regardless of the timing or
quantity of orders.
To see the effect of the unit shortage cost p on the optimal solution, you can run
SolverTable with cell B8 as the single input cell, varied from $10 to $110 in increments
of $20, and designate the order quantity, the maximum backlog, and the annual cost as
outputs. The results appear in Figure 12.7. The entries in this table show that Q and the
total annual cost are fairly insensitive to p. However, as indicated in the accompanying
chart, the maximum backlog b is quite sensitive to p, especially when p is small. This
makes sense. Why should GMB worry about making customers wait if it believes the
penalty for making them wait is very low? This information should make GMB more
comfortable, knowing that its estimate of p is not that crucial, at least not in terms of
total annual cost.
12.4 Economic Order Quantity (EOQ) Models
727
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
F
E
D
C
B
A
GMB's EOQ model with shortages allowed
e
g
n
a
R
st
u
p
n
I
 names used:
Fixed ordering 
a
m
e
d
_la
u
n
n
A
0
0
2
$
ts
o
c
nd
=Model!$B$9
Storage cost per unit per 
6
$
B
$
!le
d
o
M
=
e
t
a
r
_
ts
e
r
e
t
ni_la
u
n
n
A
0
5.0
$
r
a
e
y
Annual interest 
4
$
B
$
!le
d
o
M
=
ts
o
c
_
g
nir
e
d
r
o
_
d
e
xiF
%
0
1
e
t
a
r
Unit purchasing 
3
1
$
B
$
!le
d
o
M
=
g
olk
c
a
b
_
m
u
m
ix
a
M
0
5.0
$
ts
o
c
Shortage cost per unit per 
2
1
$
B
$
!le
d
o
M
=
ytit
n
a
u
q
_
r
e
d
r
O
2
5
$
r
a
e
y
Annual 
5
1
$
B
$
!le
d
o
M
=
r
a
e
y
_
r
e
p
_
sr
e
d
r
O
0
0
0
0
5
d
n
a
m
e
d
Shortage_cost_per_unit_per_year
=Model!$B$8
Ordering model
Storage_cost_per_unit_per_year
=Model!$B$5
Order 
4
1
$
B
$
!le
d
o
M
=
sr
e
d
r
o
_
n
e
e
w
t
e
b
_
e
m
iT
5.6
5
0
6
ytit
n
a
u
q
Maximum 
3
2
$
B
$
!le
d
o
M
=
ts
o
c
_la
u
n
n
a
_la
t
o
T
7.7
5
g
olk
c
a
b
Time between 
7
$
B
$
!le
d
o
M
=
ts
o
c
_
g
nis
a
h
cr
u
p
_
tin
U
1
2
1.0
sr
e
d
r
o
Orders per 
3.8
r
a
e
y
Monetary values
Annual setup cost 
$1,651
Annual ﬁnancial holding 
1
5
1
$
ts
o
c
Annual storage 
5
8
4,1
$
ts
o
c
Annual shortage 
4
1
$
ts
o
c
Annual purchasing 
0
0
0,5
2
$
ts
o
c
Total annual 
2
0
3,8
2
$
ts
o
c
Figure 12.6
Optimal Solution with Shortages Allowed
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Reducing the Setup Cost
There has been a lot of talk in recent years about striving for zero inventory. The argument
is that the less inventory a company carries, the more efficiently it is operating its busi-
ness.4 The question is whether this argument can be justified from an economic point of
view, at least in the context of the EOQ models we have been discussing. To this point, the
main reason for carrying more inventory has been the fixed setup cost K. If K is large, it is
economical to order in larger quantities, which means that the average inventory level is
large. So if this is true, what incentive is there for a company to strive for zero inventory?
One possible answer to this question is to reconsider whether the setup cost is really
fixed. Is a company automatically stuck with some value of K, or is it possible to reduce
this value of K and thereby justify smaller order quantities and smaller inventory levels?
This is an interesting modeling question. How can the cost of reducing K be modeled
mathematically?
One researcher, Evan Porteus, proposed a model where a company can make a one-
time investment to reduce the value of K (Porteus, 1985). Specifically, if the company’s cur-
rent setup cost is K0, he assumes that by investing f(K) dollars, the company can reduce the
setup cost from K0 to K, where K  K0. Having a smaller value of K implies a lower total
annual cost, but this reduction must be weighed against the one-time investment required to
reduce the setup cost. Also, the optimal amount of setup cost reduction must be determined.
728
Chapter 12
Inventory Models
Figure 12.7
Sensitivity to Unit
Shortage Cost
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
A
B
C
D
E
F
G
H
I
Oneway analysis for Solver model in Model worksheet
Unit shortage cost (cell $B$8) values along side, output cell(s) along top
Order_quanty
Maximum_backlog
Total_annual_cost
$10
6165.2
293.6
$28,244
$30
6075.7
99.6
$28,292
$50
6057.5
60.0
$28,302
$70
6049.8
42.9
$28,306
$90
6045.4
33.4
$28,308
$110
6042.7
27.3
$28,310
0
50
100
150
200
250
300
350
$10
$30
$50
$70
$90
$110
Unit shortage cost ($B$8)
Sensivity of Maximum_backlog to Unit shortage cost
4See the article by Zangwill (1992) for a discussion of the merits of keeping inventory low.
■
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Therefore, K becomes a decision variable along with the order quantity Q in the basic EOQ
model. (The model in this section does not allow quantity discounts or shortages.)
There are two modeling problems here. The first is to choose a reasonable form for the
function f(K). The second is to find a way to turn a one-time investment cost, f(K), into an
equivalent annual cost, so that the cost of reducing the setup cost is comparable to the
annual operating costs we have been discussing. For the first problem, Porteus assumes
that the investment required to reduce the setup cost from K0 to K is of the form
f(K)  a0  a1 ln(K)
for some constants a0 and a1. (Here, ln is the natural logarithm.) This form is not as strange
as it might look. It implies that each 10% decrease in K costs a fixed dollar amount. (The
10% figure is chosen for convenience; the same argument can be used for any other per-
centage.) Specifically, it can be shown that the cost of reducing K by 10% is a1 ln(0.9) 
0.1054a1 dollars, regardless of whether the reduction is from $300 to $270, $30 to $27,
$3 to $2.70, or any other 10% change. This constant cost per 10% decrease is a reasonable
property for f(K) to have.
The f(K) function can then be fully specified—that is, a0 and a1 can be determined—
from two given inputs: the initial setup cost K0 and the cost of a 10% reduction in K. To
illustrate, suppose that the initial setup cost is K0  $500, and it takes a one-time invest-
ment of $1000 to reduce this by 10%. Then 0.1054a1  1000 can be solved to obtain 
a1  9491. Also, because it costs zero dollars to stay at level K0, f(K0)  0, which
implies that
0  a0  a1 ln(K0)  a0  9491 ln(500)  a0  58,984
or
a0  58,984
The second problem is to convert a one-time investment, f(K), into an equivalent
annual cost. This can be done with a standard NPV argument, not presented here. The
equivalent annual cost is f(K)i dollars. In words, if the company were to pay f(K)i dollars
at the beginning of each year forever, this would be equivalent in NPV terms to a one-time
payment of f(K) dollars. Putting all of this together, the total annual cost to the company is
f(K)i plus the annual operating cost from any of the previous models. In addition to any
previous decision variables, such as Q, K must be chosen, subject to the constraint K  K0.
The following example illustrates the procedure.
12.4 Economic Order Quantity (EOQ) Models
729
If the one-time cost is
f(K), and i is the
annual interest rate,
the equivalent annual
cost is the product
f(K)i.
E X A M P L E
12.4 REDUCING THE SETUP COST AT COMPSERVE
T
he CompServe Company stocks expensive laser printers. The annual demand for this
product is 300 units. The cost from CompServe’s supplier is $1000 per printer, the cost
of capital is 10%, and the storage cost per printer per year is $30. CompServe currently
incurs a setup cost of $800 per order, but it believes that by streamlining its ordering and
delivery operations, it can reduce this value and thereby achieve smaller inventory levels.
Specifically, CompServe estimates that each 10% reduction in setup cost will require a
$1500 investment. However, preliminary analysis shows that reducing the setup cost below
$50 is physically impossible, regardless of the amount invested. Should the company
invest in setup cost reductions, and if so, how does this affect its ordering policy?
Objective
To check, in the context of the basic EOQ model, whether it is cost-effective
to make a one-time investment in setup cost reduction.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Solution
The first step is to find the parameters a0 and a1 of the investment cost function f(K) by
using the information on the original setup cost, $800, and the cost per 10% setup cost
reduction, $1500. Then all annual costs can be expressed in terms of the decision variables
K and Q, and Solver can be used to optimize. The details are explained next.
DEVELOPING THE SPREADSHEET MODEL
The spreadsheet solution shown in Figure 12.8 is very similar to the solution for the basic
EOQ model. (See the file EOQ with Setup Reduction.xlsx.) The key steps are the following.
730
Chapter 12
Inventory Models
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
E
D
C
B
A
CompServe's EOQ model with possible setup cost reducon
e
g
n
a
R
st
u
p
n
I
 names used:
Inial setup 
9
$
B
$
!le
d
o
M
=
d
n
a
m
e
d
_la
u
n
n
A
0
0
8
$
ts
o
c
Minimal setup cost 
7
$
B
$
!le
d
o
M
=
e
t
a
r
_
ts
e
r
e
t
ni_la
u
n
n
A
0
5
$
elb
a
v
eih
c
a
Storage cost per unit per 
s
o
c
_
p
u
t
e
s
_
ni_
n
oitc
u
d
e
r
_
f
o
_
ts
o
C
0
3
$
r
a
e
y
t
=Model!$B$10
Annual interest 
4
$
B
$
!le
d
o
M
=
ts
o
c
_
p
u
t
e
s
_laitinI
%
0
1
e
t
a
r
Unit purchasing 
0
0,1
$
ts
o
c
0
3
1
$
B
$
!le
d
o
M
=
t
p
e
cr
e
t
nI
Annual 
5
$
B
$
!le
d
o
M
=
elb
a
v
eih
c
a
_
ts
o
c
_
p
u
t
e
s
_la
m
ini
M
0
0
3
d
n
a
m
e
d
Cost of reducon in setup 
0
5,1
$
ts
o
c
0
8
1
$
B
$
!le
d
o
M
=
ytit
n
a
u
q
_
r
e
d
r
O
Orders_per_year
=Model!$B$20
Parameters of setup cost reducon funcon
Setup_cost_aer_reducon
=Model!$B$17
4
1
$
B
$
!le
d
o
M
=
e
p
olS
8
6
1
5
9
t
p
e
cr
e
t
nI
Slope
-14237
Storage_cost_per_unit_per_year
=Model!$B$6
Total_annual_cost
=Model!$B$28
Analysis using the Solver
Unit_purchasing_cost
=Model!$B$8
Setup cost aer 
4
9.3
0
1
$
n
oitc
u
d
e
r
Order 
9.1
2
ytit
n
a
u
q
Time between 
6
4
3.0
sr
e
d
r
o
Orders per 
9
8.2
r
a
e
y
Monetary values
One-me investment to reduce setup cost
$29,054
Equivalent annual cost to reduce setup cost
$2,905
Annual setup 
2
4,1
$
ts
o
c
4
Annual holding 
2
4,1
$
ts
o
c
4
Annual purchasing 
0
0,0
0
3
$
ts
o
c
0
Total annual 
5
7,5
0
3
$
ts
o
c
3
Figure 12.8
Solution to the Setup
Cost Reduction
Example
1
Parameters of setup cost reduction function. Calculate the parameters a0 and a1 of
the setup cost reduction function in cells B13 and B14 using the procedure outlined previ-
ously. Specifically, calculate the slope a1 with the formula
=Cost_reduction_in_setup_cost/LN(0.9)
Then calculate a0 with the formula
=-Slope*LN(Initial_setup_cost)
This formula ensures that the cost of making no setup cost reduction is 0.
2
Cost of reducing setup cost. Enter the one-time investment in setup cost reduction
in cell B23 with the formula
=Intercept+Slope*LN(Setup_cost_after_reduction)
Then enter the equivalent annual cost in cell B24 with the formula
=B23*Annual_interest_rate
USING SOLVER
The rest of the model is exactly like the basic EOQ model. The objective to minimize is the
annual total cost in cell B28, with cells B17 and B18 as the changing cells. Cell B17 must
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

be less than or equal to cell B4 and greater than or equal to cell B5. As usual in EOQ
models, GRG Nonlinear Solver should be used. (You could also constrain the order quan-
tity to be an integer, but it is not really necessary.)
Discussion of the Solution
As Figure 12.8 indicates, CompServe should first invest $29,054 to reduce the setup cost
from $800 to $103.94. Then its optimal order quantity is about 22 printers, and the total
annual cost, including the investment in setup cost reduction, is $305,753. Of course, only
$5753 of this is affected by the decision variables. The other $300,000 is the unavoidable
annual purchase cost.
Has setup cost reduction worked? If this example is solved with the basic EOQ model,
using the original $800 setup cost, you can check that the optimal order quantity is 61
units, and the annual cost (not counting the $300,000 purchase cost) is approximately
$7900. When setup cost reduction is allowed, the company reduces its setup cost from
$800 to slightly over $100, and the ordering quantity drops sharply to 22 units. Instead of
ordering about five times a year (30061), it now orders almost 14 times a year (30022).
Also, the annual cost decreases by over $2000. Because the company’s initial investment
of almost $29,000 is equivalent to about $2900 per year, the savings in annual ordering and
holding costs is about $4900. In addition, there may be other intangible benefits from hold-
ing less inventory, as Zangwill (1992) and many other authors have noted.
■
Synchronizing Orders for Several Products
Until now, all models have considered a single product. If the company orders several
products, it could calculate the EOQ for each product and order them according to sep-
arate schedules. However, there might be economies, particularly reduced setup costs,
from synchronizing the orders so that several products are ordered simultaneously.
This should be particularly attractive for products that come from the same supplier.
Then, for example, the same truck can deliver orders for several products, thereby
reducing the setup cost involved with the delivery. We develop a model in this section
that takes advantage of synchronization, and we compare it to the “individual EOQs”
policy that uses no synchronization. Although this model can be developed for any
number of products, we keep things relatively simple by assuming that there are only
two products.
12.4 Economic Order Quantity (EOQ) Models
731
E X A M P L E
12.5 SYNCHRONIZED ORDERING AT SLEEPEASE
S
leepease, a retailer of bedding supplies, orders king-size and queen-size mattresses
from a regional supplier. There is a fairly constant demand for each of these products.
The annual demand for queens is 2200; the demand for kings is 250. The unit purchasing
costs for queen-size and king-size mattresses are $100 and $120, and the company’s cost to
store either of these for one year is $15. Sleepease’s ordering cost is based primarily on the
fixed cost of delivering a batch of mattresses. This ordering cost is $500 if either queens or
kings are ordered separately, but the ordering cost is only $650 if both are ordered together.
Sleepease’s cost of capital is 10%. The company wants to know whether synchronizing
orders is better than not synchronizing them, and if so, it wants to find the best synchro-
nized ordering policy.
Objective
To find the optimal synchronized ordering policy, and to compare it to the
EOQ policy where orders for the two are not synchronized.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Solution
The only real cost benefit from synchronization is reduced setup costs. Let K1  $500 be
the setup cost for ordering queens alone, and define K2  $500 similarly for kings. When
both products are ordered simultaneously, denote the setup cost for the order by K12 
$650. The important point is that K12 is less than K1  K2. This reflects the economy of
scale achieved when both products are ordered together rather than individually. All other
parameters (s, c, D, and i) are defined as before, except that each product has its own values
of s, c, and D.
To model this problem, consider the graph in Figure 12.9. This depicts a synchroniza-
tion policy where queens are ordered three times as often as kings. In general, let t1 and t2,
respectively, be the time between orders of queens and kings, and let T be the cycle time,
defined as the larger of t1 and t2. (In the graph, t2  t1, so T  t2.) Also, let n1 and n2,
respectively, be the number of times queens and kings are ordered during a cycle. (In the
graph, n1  3 and n2  1.) Then under a synchronization model, n1 and n2 are both posi-
tive integers, and at least one of them equals 1. (Actually, they could both be 1, in which
case queens and kings are always ordered together.)
For the optimization model, it is convenient to let T, n1, and n2 be the decision
variables—that is, the changing cells in the spreadsheet. The order quantities Q1 and Q2
are then determined from these values as follows. First, it is apparent that t1, the time
between orders of queens, is Tn1. Similarly, t2  Tn2. Therefore, given t1 and t2, the
order quantities Q1 and Q2 must be Q1  D1t1 and Q2  D2t2 (because each Q must
decrease to 0 in time t at rate D).
To develop the total annual cost, the purchasing and holding costs are exactly as
before (for each product). Now concentrate on the setup cost. During an ordering cycle of
length T, both products are ordered together exactly once, for a setup cost of K12. Then
product j (for j  1 or j  2) is ordered nj  1 times by itself, for a setup cost of Kj(nj  1).
(For at least one of the two products, this latter term is 0. For example, it is 0 for product 2
in Figure 12.9.) The number of cycles per year is 1T, so the total annual setup cost is
Annual setup cost  [K12  (n11)K1(n21)K2]T
(12.7)
DEVELOPING THE SPREADSHEET MODEL
The spreadsheet model appears in Figure 12.10. (See the file EOQ with Synchr onized
Ordering.xlsx.) The top part of the spreadsheet shows the analysis for the synchronized
ordering policy. It can be formed as follows:
732
Chapter 12
Inventory Models
Figure 12.9
EOQ with
Synchronization
Slope: D2
Slope: D1
T = t2
t1
Inventory
level
Time
Q2
Q1
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

1
Inputs. Enter the inputs in rows 4, 5, 8, and 9. As usual, note that the combined
holding costs in the range E8:E9 are storage costs plus the interest rate multiplied by the
purchasing costs.
2
Orders per cycle and cycle time. Enter any trial values in the cells B14, B15, and B17.
The values in cells B14 and B15 correspond to n1 and n2; the value in cell B17 corresponds to T.
3
Timing of orders.
Calculate the times between orders, t1 and t2, in the range
C14:C15 by entering the formula
=Cycle_time/B14
in cell C14 and copying it down. Then calculate the orders per year in the range D14:D15
as the reciprocals of the values in C14:C15.
4
Order quantities. Calculate the order quantity for queens in cell E14 with the formula
=F8*C14
and copy this to cell E15 for the kings. Again, this expresses the order quantity as the
annual demand multiplied by the time between orders.
5
Annual setup cost. Calculate the annual setup cost in cell B20 with the formula
=(Joint_setup_cost+SUMPRODUCT(Orders_per_cycle-1,B8:B9))/Cycle_time
This follows directly from Equation (12.7). (Note how the term Orders_per_cycle-1 is used
inside the SUMPRODUCT function. It takes the values in the Orders_per_cycle range, sub-
tracts 1 from each of them, and multiplies these by the values in the B8:B9 range.)
6
Other costs. Calculate the other costs exactly as in previous EOQ models, except
that now the holding and purchasing costs must be summed over the two products, queens
and kings.
USING SOLVER
The objective is to minimize the annual cost, using cells B14, B15, and B17 as the chang-
ing cells. The constraints are that cell B17 should be nonnegative and cells B14 and B15
12.4 Economic Order Quantity (EOQ) Models
733
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
I
H
G
F
E
D
C
B
A
Synchronized Ordering of Two Products
Inputs
Range names used:
Interest 
7
1
$
B
$
!le
d
o
M
=
e
m
it
_
elc
y
C
%
0
1
e
t
a
r
Joint setup 
4
$
B
$
!le
d
o
M
=
e
t
a
r
_
ts
e
r
e
t
nI
0
5
6
$
ts
o
c
Joint_setup_cost
=Model!$B$5
Product
Setup cost 
(individual)
Storage cost
Purchasing 
cost
Combined 
holding cost
Annual 
demand
Orders_per_cycle
=Model!$B$14:$B$15
5
1
$
E
$:4
1
$
E
$
!le
d
o
M
=
s
eitit
n
a
u
q
_
r
e
d
r
o
_
d
e
zin
o
r
h
c
n
y
S
0
0
2
2
5
2
$
0
0
1
$
5
1
$
0
0
5
$
s
n
e
e
u
Q
3
2
$
B
$
!le
d
o
M
=
ts
o
c
_la
u
n
n
a
_la
t
o
T
0
5
2
7
2
$
0
2
1
$
5
1
$
0
0
5
$
s
g
niK
Opmal synchronized policy
Product
Orders per cycle
Time between 
orders
Orders per 
year
Synchronized 
order quanes
5
8
2
7.7
0
3
1.0
2
s
n
e
e
u
Q
5
6
9.3
9
5
2.0
1
s
g
niK
Cycle 
9
5
2.0
e
m
it
Costs aﬀected by ordering policy
Annual setup cost
$4,438
Annual holding cost
$4,438
Annual purchasing cost
$250,000
Total annual cost
$258,876
Opmal policy with no synchronizaon (using individual EOQs)
Product
Separate EOQs
Time between 
orders
Orders per 
year
Annual setup 
costs
Annual 
holding costs
8
0
7,3
$
8
0
7,3
$
4.7
5
3
1.0
7
9
2
s
n
e
e
u
Q
9
9
2,1
$
9
9
2,1
$
6.2
5
8
3.0
6
9
s
g
niK
7
0
0,5
$
7
0
0,5
$
sla
t
o
T
Annual purchasing cost
$250,000
Total annual cost
$260,014
Figure 12.10
Solution to the
Synchronized
Ordering Example
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

should be integers and greater than or equal to 1 (to ensure that Sleepease orders each
product a positive integer number of times per cycle). As usual, GRG Nonlinear Solver
must be used.
Discussion of the Solution
The optimal solution in Figure 12.10 indicates that there are about four cycles every year
(because cycle time is about 1/4 year). Queens are ordered twice every cycle, and kings are
ordered only once. The total annual cost (not counting the purchasing cost) from this syn-
chronized ordering policy is $8876. For comparison, the bottom part of the spreadsheet in
Figure 12.10 shows the unsynchronized policy from using individual EOQs. In this policy,
queens and kings are both ordered slightly less frequently than before, but because the
orders are not synchronized, there are more ordering times per year. By comparing setup
and holding costs, you can see that this unsynchronized policy costs about 12.7% more
than the best synchronized policy ($10,014 versus $8876). In addition, there is an impor-
tant noneconomic advantage of synchronizing orders—the ordering process is easier to
manage.
Would you have guessed that queens would be ordered more frequently than
kings? The reason is that the number of orders per year for either product is DQ.
From the EOQ square-root formula, the optimal number of orders per year is propor-
tional to the square root of D. Now, kings and queens have very similar setup costs K
(if ordered separately) and holding costs h. Therefore, their relative ordering frequen-
cies are determined by their demand rates, and queens have a much larger demand
rate. Therefore, it makes sense to order queens more frequently. (The analysis would
not be this straightforward if kings and queens had different values for all three para-
meters K, D, and h).
■
More Than Two Products
Virtually the same spreadsheet could be used for more than two products, provided that
we make a simplifying assumption. This assumption is that a setup cost reduction is
available only when the company places an order for all of the products simultaneously.
Unfortunately, it is probably more realistic to assume that there is a setup cost reduction
when any subset of products is ordered simultaneously. To illustrate, suppose that there
are four products, product 1 is ordered once per cycle, products 2 and 3 are ordered twice
per cycle, and product 4 is ordered four times per cycle (see Figure 12.11). When all four
products are ordered together at the beginning of a cycle, there is definitely a setup cost
reduction, but there is probably also some setup cost reduction when products 2, 3, and
4 are ordered together in the middle of a cycle. If we allow this possibility, however, and
then try to optimize over all possible synchronizations, the problem becomes difficult to
model in a spreadsheet. Therefore, we do not pursue this multiple-product model any
further here.
734
Chapter 12
Inventory Models
Figure 12.11
Another Way to
Synchronize
Beginning of cycle
End of cycle
Order product 4 only
Order products 2, 3, 4
Order products 1, 2, 3, 4
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

12.4 Economic Order Quantity (EOQ) Models
735
P R O B L E M S
Solutions for problems whose numbers appear within a 
colored box can be found in the Student Solutions Files.
Refer to this book’s preface for purchase information.
Skill-Building Problems
1.
In the basic EOQ model in Example 12.1, suppose that
the fixed cost of ordering is $500. Use Solver to find
the new optimal order quantity. How does it compare
to the optimal order quantity in the example? Could
you have predicted this from Equation (12.4)?
2.
If the lead time in Example 12.1 changes from one
week to two weeks, how is the optimal policy
affected? Does the optimal order quantity change?
3.
In the quantity discount model in Example 12.2, the
minimum total annual cost is obtained by ordering
enough to achieve the smallest unit purchasing cost.
Evidently, the larger unit purchasing costs for smaller
order quantities make them unattractive. Could an
order quantity below 400 ever be best? Could an order
quantity between 500 and 800 ever be best? To answer
these questions, assume that there is no price break at
all. Specifically, assume that the unit purchase cost is
always $26. What is the optimal order quantity with
this assumption? How does this help answer the pre-
ceding questions?
4.
In the quantity discount model in Example 12.2, sup-
pose you want to see how the optimal order quantity
and the total annual cost vary as the fixed cost of order-
ing varies. Use SolverTable to perform this analysis,
allowing the fixed cost of ordering to vary from $25 to
$200 in increments of $25. Indicate the optimal order-
ing policy for each fixed cost of ordering.
5.
The quantity discount model in Example 12.2 uses one
of two possible types of discount structures. It assumes
that if the company orders 600 units, say, each unit
costs $28. This provides a big incentive to jump up to a
higher order quantity. For example, the total purchasing
cost of 499 units is 499($30)  $14,970, whereas the
total cost of 500 units is only 500($28)  $14,000.
Change the discount structure so that the first 499 units
cost $30 apiece, the next 300 units cost $28 apiece, and
any units from 800 on cost $26 apiece. Now the cost of
500 units is 499($30)  $28  $14,998. Modify the
model to incorporate this structure, and find the opti-
mal order quantity. (Hint: First, find the purchase cost
per order with an IF formula. Then the annual holding
cost is the annual interest rate times the purchase cost
per order divided by 2.)
6.
In Example 12.3, SolverTable was used to show what
happens when the unit shortage cost varies. As the
table indicates, the company orders more and allows
more backlogging as the unit shortage cost decreases.
Redo the SolverTable analysis, this time trying even
smaller unit shortage costs. Explain what happens
when the unit shortage cost is really small. Do you
think a company would ever consider a really small
shortage cost? Why or why not? Then redo the
SolverTable analysis again, this time trying even larger
unit shortage costs. How do the results in this case
compare to the results from the basic EOQ model with
no shortages allowed?
7.
Example 12.4 illustrates why a company might invest
to reduce its setup cost. It all depends on how much
this investment costs, as specified (in the model) by
the cost of a 10% reduction in the setup cost. Use
SolverTable to see how the results change as this cost
of a 10% reduction varies. You can choose the range
for this cost that makes the results “interesting.”
Within your range, does the lower limit on setup cost
($50) ever become a binding constraint?
8.
Modify the synchronized ordering model in Example
12.5 slightly so that you can use a two-way SolverTable
on the fixed costs. Specifically, enter a formula in cell
B9 so that the fixed cost of ordering kings alone is equal
to the fixed cost of ordering queens alone. Then let the
two inputs for SolverTable be the fixed cost of ordering
queens alone and the joint fixed cost of ordering both
kings and queens together. Let these vary over a reason-
able range, but make sure that the first input is less than
the second, and the second input is less than twice the
first. (Otherwise, the model wouldn’t be realistic.)
Capture the changing cells and the sum of annual setup
and holding costs as SolverTable outputs. Describe your
findings in a brief report.
Skill-Extending Problems
9.
In the basic EOQ model in Example 12.1, suppose that
the fixed cost of ordering and the unit purchasing
cost are both multiplied by the same factor f. Use
SolverTable to see what happens to the optimal order
quantity and the corresponding annual fixed order cost
and annual holding cost as f varies from 0.5 to 5 in
increments of 0.25. Could you have discovered the
same results algebraically, using Equations (12.2)
through (12.4)?
10. In the basic EOQ model, revenue is often omitted from
the model. The reasoning is that all demand will be sold
at the given selling price, so revenue is a fixed quantity
that is independent of the order quantity. Change that
assumption as follows. Make selling price a decision
variable, which must be between $110 and $150. Then
assume that annual demand is a nonlinear function of
the selling price p: Annual Demand  497000p1.24.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

12.5 PROBABILISTIC INVENTORY MODELS
In most situations, companies that make ordering and production decisions face uncer-
tainty about the future. Probably the most common and important element of uncertainty is
customer demand, but there can be others. For example, there can be uncertainty in the
amount of lead time between placement and receipt of an order. A company that faces
uncertainty has three basic options. First, it can use best guesses for uncertain quantities
and proceed according to one of the deterministic models in the previous section (or
according to one of the many other deterministic models that exist in the literature).
Second, it can develop an analytical (nonsimulation) model to deal with the uncertainty.
The advantage of such a model is that you can calculate bottom line results, such as
expected cost, and then use Solver to optimize. The disadvantage is that these analytical
models tend to be mathematically complex. The third possibility is to develop a simula-
tion model. The advantage of a simulation model is that it is relatively easy to develop,
regardless of the complexity of the problem. The disadvantage is that it can be difficult, or
at least time-consuming, to find optimal ordering policies from a simulation.5
We already examined one probabilistic inventory model in Chapter 10, the newsven-
dor model. The essence of a newsvendor model is that a company must place an order for
some product exactly once and then wait to see how large the demand is. If the demand is
larger than expected, the company loses sales it could have made. If the demand is smaller
than expected, the company must dispose of the excess items or sell them at a marked-
down price. This presents a classical trade-off between ordering too few and ordering too
many. Simulation was used in Chapter 10 to analyze this problem. This section illustrates
how it can be solved analytically.
Besides the newsvendor model, we also examine a continuous review model where a
company orders a product repeatedly through time. The model is basically the same EOQ
model as in the previous section but with one important difference. Now the demand dur-
ing any period of time is uncertain, and only its probability distribution is known. This is
more realistic, but it complicates the analysis. We assume that the company uses an (R,Q)
ordering policy, which is used by many companies. This continuous review policy is deter-
mined by two numbers, R and Q. The value R is the reorder point. When the company’s
inventory level drops to R, an order is placed. The order quantity Q specifies the amount to
order each time an order is placed.
736
Chapter 12
Inventory Models
(This implies a constant elasticity of approximately
1.24 for the demand curve.) Modify the model in
Example 12.1 as necessary and then use Solver to find
the optimal selling price and order quantity. What are
the corresponding demand and profit? Which appears
to affect profit more in this model, order quantity or
selling price?
11. In the quantity discount model in Example 12.2, the
minimum total annual cost is region 3 is clearly the
best. Evidently, the larger unit purchase costs in the
other two regions make these two regions unattractive.
When would a switch take place? To answer this ques-
tion, change the model slightly. First, change the fixed
cost of ordering to $40. Second, keep the unit cost in
region 3 at $26, but change the unit costs in regions 1
and 2 to $26  2k and $26  k, where you can let k
vary. (Currently, k is $2.) Use SolverTable with k var-
ied over some appropriate range to see how small k
must be before it is optimal to order from region 1 or
2. What region is the optimal ordering quantity in if
there is no price break at all (k  0). How do you rec-
oncile this with your SolverTable findings?
5Fortunately, this is less true now than it used to be. Palisade, for example, has developed a software package
called RISKOptimizer that uses a genetic algorithm to optimize a specified output in a simulation model. This
software is included with the Palisade suite that is available with the book. We refer to Winston (1999) for a dis-
cussion of simulation models that use RISKOptimizer.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Newsvendor Model
The newsvendor model is one of the simplest probabilistic inventory models, but it is
also a very important one.6 It occurs whenever a company must place a one-time order for
a product and then wait to see the demand for the product. The assumption is that after
this demand occurs, the product is no longer valuable. This could be the case for a daily
newspaper (who wants yesterday’s newspaper?), a calendar (who wants a 2010 calendar
after 2010?), a fashion product that tends to go out of style after the current “season”
(what woman wants last year’s dress styles?), and so on. Given the single chance to order,
the company needs to balance the cost of ordering too much versus the cost of not order-
ing enough.
To put this problem in a fairly general setting, let cover and cunder, respectively, be the
cost of having one more unit or one fewer unit on hand than demand. For example, if
demand turns out to be 100 units, cover is the cost if 101 units are ordered, whereas cunder is
the cost if 99 units are ordered. Each of these is a per unit cost, so if say, 110 units are
ordered, the cost is 10cover, whereas if 90 units are ordered, the cost is 10cunder. The example
discussed shortly indicates how cover and cunder can be found from given monetary inputs.
For now, assume they are known.
Now let D be the random demand. We assume that D has a cumulative probability dis-
tribution F(x), so that for any potential demand x, F(x) is the probability P(D  x) that D is
less than or equal to x. In general, this distribution needs to be estimated, probably from his-
torical data on demands for this product or similar products. Then the best order quantity
balances the cost of understocking times the probability of understocking with the cost of
overstocking times the probability of overstocking. As an example, suppose the unit cost
of understocking, cunder, is four times as large as the unit cost of overstocking, cover. Then it
seems reasonable (and it can be proved) that the probability of understocking should be
one-quarter as large as the probability of overstocking. If Q is the order quantity, the proba-
bility of overstocking is P(D  Q)  F(Q), and the probability of understocking is one
minus this, 1F(Q).7 Because the probability of understocking should be one-quarter as
large as the probability of overstocking, we set 1  F(Q)  (14)F(Q) and solve for F(Q) to
obtain F(Q)  45.
A similar argument for any values of cover and cunder leads to the following equation
that the optimal order quantity Q must satisfy:
(12.8)
The fraction on the right side of this equation is called the critical fractile. This fraction
determines the optimal order quantity through an examination of the demand distribution.
For example, if the cost of understocking is four times as large as the cost of overstocking,
the critical fractile is 4/5, so there is an 80% chance that demand is less than or equal to the
optimal order quantity value. For any particular demand distribution, you can then appeal
to @RISK, built-in Excel functions, tables in books, or some other means to find the opti-
mal Q. We illustrate the procedure in the following continuation of the Walton Bookstore
calendar example from Chapter 10.
F(Q) =
cunder
cover + cunder
12.5 Probabilistic Inventory Models
737
6The article by Pfeifer et al. (2001) contains an interesting discussion of three alternative methods to analyze the
newsvendor problem: decision trees, simulation, and the critical fractile analysis discussed here. Although the
authors provide pros and cons of each method, they appear to prefer simulation.
7Strictly speaking, this requires that D be a continuous random variable, which we assume here. However, a simi-
lar argument works when D is discrete.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

738
Chapter 12
Inventory Models
E X A M P L E
12.6 ORDERING CALENDARS AT WALTON BOOKSTORE
R
ecall that Walton Bookstore buys calendars for $7.50, sells them at the regular price of
$10, and gets a refund of $2.50 for all calendars that cannot be sold. As in Example
10.3 of Chapter 10, Walton estimates that demand for the calendar has a triangular
distribution with minimum, most likely, and maximum values equal to 100, 175, and 300,
respectively. How many calendars should Walton order to maximize expected profit?
Objective
To use critical fractile analysis to find the optimal order quantity.
Solution
There are two steps in this analysis. First, you must identify the unit costs of overstocking
and understocking, cover and cunder, so that you can calculate the critical fractile in Equation
(12.8). Second, you must find the order quantity that achieves this critical fractile.
To find the unit cost of overstocking, assume that demand is 200 (any value would do),
and Walton orders 201 calendars. This means one calendar will be left over. Because the
calendar costs $7.50 and the eventual refund is only $2.50, the cost of this extra calendar is
cover  $5. In other words, Walton loses $5 for each calendar that can’t be sold. In the other
direction, if 199 calendars are ordered, there is an opportunity cost of not being able to sat-
isfy customer 200. This cost is the profit margin per calendar, $10  $7.50, so that cunder 
$2.50. Therefore, the critical fractile is 2.50(5  2.50)  13.
Now you need to find the value such that the probability of demand being less than or
equal to this value is 13. You can find this value easily by using @RISK’s Define
Distribution window (see Figure 12.12). You first choose the appropriate distribution 
(triangular with parameters 100, 175, and 300) and then enter 33.3% above the chart. The
corresponding value is the corresponding order quantity. In this case, it is approximately 171.
(See the file Newsvendor.xlsx.)
Discussion of the Solution
Unfortunately, the critical fractile method provides only the optimal order quantity. For
this example, it indicates that an order for 171 calendars achieves the best balance between
Figure 12.12
Finding the Optimal
Order Quantity with
@RISK
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

overstocking and understocking. Specifically, the probability of understocking is then 2/3,
and the probability of understocking is 13. The method does not provide the distribution
of Walton’s net profit, or even its expected net profit, from using this order quantity (at
least not without a more complex analysis that is beyond the scope of this book). This is
exactly the type of information that simulation can provide, as illustrated in Example 10.3
of Chapter 10. In short, simulation enables you to see how net profit is distributed for a
given order quantity, but it isn’t well suited to finding the optimal order quantity. Critical
fractile analysis is exactly the opposite in that it enables you to find the optimal order quan-
tity fairly easily, but it doesn’t provide the distribution of net profit. Further analysis of net
profit for this order quantity is best left to simulation.
In spite of its shortcomings, critical fractile analysis does allow you to see how the
optimal order quantity depends on (1) the relative values of cover and cunder, and (2) the
shape of the demand distribution. For example, suppose the selling price increases from
$10 to $15. This doesn’t affect the cost of overstocking, but it increases the cost of
understocking to $7.50, the new profit margin. As you would expect, this provides an
incentive for Walton to order more calendars than before to avoid running out and losing
sales. This is exactly what happens. The new critical fractile is 7.50(5  7.50)  0.6,
which you can enter in @RISK’s Define Distribution window. You can check that the
corresponding order quantity is now 200, the probability of understocking is only 0.4,
and the probability of overstocking is 0.6. As another example, suppose the selling price
remains at $10, but Walton receives only $1 for leftover calendars. Then the understock-
ing cost is unaffected, but the overstocking cost increases to $6.50, the difference
between Walton’s unit cost and the salvage value. This provides an incentive to order
fewer calendars. The critical fractile is now 2.50(6.50  2.50)  0.278, the optimal
order quantity decreases to about 165, the probability of understocking is 0.722, and the
probability of overstocking is 0.278.
You can also easily  see how the optimal order quantity depends on the shape of the
demand distribution. Suppose, for example, that the demand distribution is normal with the
same mean and standard deviation, 191.67 and 41.248, as the triangular distribution we
just analyzed. Then you can still find the optimal order quantity from @RISK just by
choosing a different distribution. As you can check, this apparently has very little affect on
the optimal order quantity, which increases only to about 174.
■
12.5 Probabilistic Inventory Models
739
A Newsvendor Tackles the Newsvendor Model
Koschat et al. (2003) describe a real newsvendor problem experienced by Time Inc. Time is
the largest publisher of consumer magazines in the United States, with such titles as People,
Sports Illustrated, Time, Fortune, and many others. Time Inc. has three problems: (1) how
many issues of each magazine to print, (2) how to distribute these to its wholesalers around
the country, and (3) how to distribute the magazines from the wholesalers to the many retail-
ers that sell them. Until the time of the study (1998), these decisions were made in an infor-
mal manner, using the (sometimes biased and unscientific) judgments of the parties
involved. The authors discuss how they analyzed and then implemented the allocation of
magazines from publisher to wholesalers to retailers by using the principles discussed here
for general newsvendor problems. However, they also state that the problems faced by Time
Inc. are too complex, due to data requirements and political pressures, to be solved entirely
by management science models. Expert judgment and some amount of compromise were
required to make the study successful. Still, the authors estimate that their study has gener-
ated incremental profits in excess of $3.5 million annually.
■
ADDITIONAL APPLICATIONS
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

The critical fractile analysis discussed here is in terms of the newsvendor model,
where a company orders exactly once. As discussed in the chapter opener about Dell’s sup-
ply chain, this same critical fractile analysis can be used to determine an optimal service
level for a company. As you will see, service levels play an important role in the (R,Q)
ordering policies discussed next.
The (R,Q) Ordering Policy
The previous subsection analyzed a one-time ordering decision, which is relevant for a
product such as a newspaper or a fashion item that quickly goes out of style. We now exa-
mine an ordering decision for a product with sales that continue into the indefinite future.
As with the EOQ model, we assume that demand is more or less constant through time—no
upward or downward trends, and no seasonality—but that it is random. That is, the proba-
bility distribution of demand in any month, say, is always the same, but the actual demands
in different months can be different because of randomness. As with the deterministic EOQ
model, the company must make two decisions: when to order and how much to order. We
assume that it uses a popular type of policy, called an (R,Q) policy, where R is the reorder
point and Q is the order quantity. Under this policy, the company continually monitors its
inventory. When inventory drops to R or below, the company places an order for Q units.
When a company chooses the reorder point R, it must take into account the effects of run-
ning out of inventory. If the company believes shortages are very expensive or undesirable, it
should choose a relatively large value of R. This leads to a relatively large level of safety
stock, the expected amount of inventory left over—the cushion—by the time the next order
arrives. On the other hand, if shortages are not con-
sidered too expensive or undesirable, the company
can afford to use a lower value of R, with a smaller
resulting level of safety stock. As in the newsvendor
model, we show how to determine an appropriate
trade-off between leftovers and shortages.
To specify an (R,Q) policy, we must also deter-
mine the appropriate order quantity Q. It turns out
that the choices of R and Q can be made almost
independently. The choice of R depends largely on
how shortage costs (or customer service) are mea-
sured, whereas the choice of Q depends mostly on
the same cost factors considered in the determinis-
tic EOQ models. Specifically, the company wants
to order enough to avoid frequent fixed ordering
costs but as little as possible to avoid excessive
holding costs. Fortunately, it is possible to develop
a Solver model that determines Q and R simultane-
ously, as illustrated in the following example.
740
Chapter 12
Inventory Models
FUNDAMENTAL INSIGHT
Ordering with Uncertain Demand
When future demand is uncer tain and can be f ore-
casted only approximately, a company has to deter-
mine the trade-off betw een ordering too much (and
having excess inventory costs) and ordering too little
(and having shortage costs and a lo w service level).
This often results in safety stock, the extra inventory
that is used as a cushion in case demand during lead
time is gr eater than expected. In today’s computer-
ized world,where companies share more information
about inventories and demands with their suppliers,
better f orecasting and cooperation betw
een the
members of the supply chain can often reduce safety
stock and the resulting cost.
E X A M P L E
12.7 ORDERING CAMERAS WITH UNCERTAIN DEMAND AT MACHEY’S
I
n Example 12.1, we considered Machey’s department store, which sells, on average, 1200
cameras per year. The store pays a setup cost of $125 per order, and the holding cost is $8
per camera per year. It takes one week for an order to arrive after it is placed. In that example,
the optimal order quantity Q was found to be 194 cameras. Now we assume that the annual
demand is normally distributed with mean 1200 and standard deviation 70. Machey’s wants
to know when to order and how many cameras to order at each ordering opportunity.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Objective
To find the (R,Q) policy that minimizes the company’s expected annual cost.
Solution
Suppose the company places an order for Q cameras every time its inventory level drops to
R. Our goal is to find optimal values of Q and R. Two aspects of this model are critical to
its solution: demand during lead time and the cost of running out of inventory.
Demand During Lead Time and Safety Stock
The most critical probabilistic quantity is the amount of demand during an order lead time.
To illustrate, suppose that Machey’s uses R  30 as the reorder point. This means that 
it places an order as soon as the inventory level drops to 30 cameras. This order arrives
one week later. If the demand during this lead time is 25 cameras, say, then no shortage
will occur, and 5 cameras will remain when the order arrives. However, if the demand dur-
ing this period is 35 cameras, then there will be a shortage of 5 cameras by the time the
order arrives. Therefore, the demand during lead time, in conjunction with the choice of R,
determines the extent of shortages. Before we can continue, we need to analyze this quan-
tity in some detail.
Let DAD be the annual demand, and let DLD be the demand during an order lead time
of length L. (For clarity, we use subscripts AD for annual demand and LD for lead time
demand.) From the statement of the problem, DAD is normally distributed with mean 
AD  1200 and standard deviation AD  70. By making appropriate probability assump-
tions, it can be shown that DLD is also normally distributed, and its mean and standard devi-
ation are LD  LAD and LD  LAD. Because the lead time is one week (L  152),
Machey’s expected demand during lead time is LD  (152)(1200)  23 cameras, and the
standard deviation of demand during lead time is LD  152
(70)  9.7 cameras.
Given these values, you might think that Machey’s should set its reorder point R equal
to 23, the mean demand during lead time. But then there would be a 50–50 chance of
stocking out before the order arrives (because the probability that a normal random vari-
able is greater than its mean is 0.5). What if the company instead sets R equal to one
standard deviation above the mean—that is, R  23  9.7  33? Then the probability of a
stockout is P(DLD  33). This can be found with the NORMDIST function in Excel. (It
can also be found with @RISK, but we take advantage of Excel functions here.) The syn-
tax for this function is NORMDIST(x, , , 1). It returns the probability that a normal ran-
dom variable with mean  and standard deviation  is less than or equal to a specified
value x. Therefore, P(DLD  33), the probability of a stockout, can be calculated with the
formula 1NORMDIST (33,23,9.7,1), which is approximately 0.15 (see Figure 12.13).
In general, suppose that Machey’s decides to set R equal to k standard deviations above
the mean, where k is a multiplier that must be determined. That is, it uses the reorder level
R  LD  kLD  LD  safety stock 
(12.9)
12.5 Probabilistic Inventory Models
741
probability
1–NORMDIST(33, 23, 9.7, 1)
23
33
Figure 12.13
Probability Under a
Normal Distribution
The key to choosing
the appropriate 
reorder point R is the
distribution of demand
that occurs during an
order lead time.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

In effect, the multiplier k becomes the decision variable. Usually k is positive (as we
require in this section). The term kLD then becomes the safety stock. To summarize the
reasoning, Machey’s expects an amount LD to be demanded during the one-week lead
time. However, because shortages are undesirable, it orders when the inventory level is
kLD above LD. Therefore, it expects the inventory level to be kLD, a positive value,
when the order arrives. This value, the safety stock, is its cushion against larger-than-
expected demand during lead time. But although the company plans for this safety stock
to exist, there is no guarantee that it will exist. The previous probability calculation with
k  1 shows that there is about a 15% chance that the safety stock of 10 units will be
depleted before the order arrives. In this case, a stockout occurs. The objective is to choose
k and the order quantity Q in an optimal manner.
Finding the Expected Costs
We now develop an expression for Machey’s expected total
annual cost as a function of the order quantity Q and k. In the following discussion, we
refer to an order cycle, which begins each time an order arrives and ends just before the
next order arrives (see Figure 12.14).
742
Chapter 12
Inventory Models
R
Place 
order
Place 
order
Order cycle
Figure 12.14
Depiction of an
Order Cycle
A company can try to
attach a dollar figure
to shortages, or it can
instead specify a ser-
vice level such as the
fraction of demand
satisfied with on-hand
inventory. However, the
appropriate service
level is ultimately
determined by costs.
First, consider the annual setup and holding costs. If an order quantity Q is used, it
takes an expected amount of time QAD to deplete this inventory. (Remember that AD is
the expected annual demand. It plays the same role as D in the deterministic EOQ models.)
Therefore, there are an expected ADQ order cycles per year, so the expected annual
setup cost is KADQ. For the holding cost, consider any order cycle. The lowest inventory
level during a cycle is expected to be kLD, the safety stock. The highest inventory level
occurs when the order arrives and the expected inventory jumps up to Q  kLD.
Therefore, the expected average inventory level during a typical cycle is [kLD  (Q 
kLD)]2; this is multiplied by the unit holding cost h to obtain the expected annual hold-
ing cost. (Note that we are now using the letter h to refer to the unit holding cost.
Comparing to the EOQ section, h  s  ic.) Simplifying the algebra slightly leads to the
following expressions for expected annual setup and holding costs:
Expected annual setup cost  KADQ
(12.10)
Expected annual holding cost  h(Q2  kLD)
(12.11)
where (for Machey’s) K  $125, h  $8, AD  1200, LD  9.7, and Q and k must be
determined.
Two Ways to “Cost” Shortages
We now consider two alternative models of “costing”
shortages. Neither of these models is clearly superior to the other, so Machey’s must
decide which model is more in line with the company’s goals. Model 1 assumes that there
is a shortage cost of p per unit short. In this model, a cycle with a shortage of five units is
five times as costly as a cycle with a shortage of only one unit. For example, suppose
Machey’s uses model one with p  $10. If the average number of shortages during each of
its order cycles is two, and there are 13 order cycles during the year, then its annual short-
age cost is $260.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Model 2 gets around the difficult problem of assessing dollar shortage costs by instead
specifying a service level. Specifically, it requires that the fraction of demand that can be
met from on-hand inventory must be at least s, where s is a number between 0 and 1. This
fraction is often called the fill rate. For example, if Machey’s uses model 2 with s  0.98,
then it chooses its ordering policy so that at least 98% of all customer demand can be met
from on-hand inventory. That is, it tries to achieve a fill rate of 98%.
Before Machey’s problem can be modeled on a spreadsheet, we need formulas for the
shortage cost (or service level) for these two shortage-costing models.
Expected Shortage Cost for Model 1
In model 1, Machey’s assesses a shortage cost of
p per unit short during any order cycle. Therefore, to evaluate the expected annual shortage
cost, the expected number of shortages per order cycle is required. Let E(B) be the
expected number of units short during a typical order cycle. Then the expected shortage
cost during this cycle is pE(B), and the expected annual shortage cost is the expected short-
age cost per cycle multiplied by the expected number of cycles per year, ADQ. This
leads to the following expected total annual shortage cost:
Model 1 expected annual shortage cost  pE(B)ADQ
(12.12)
The problem is to find an expression for E(B). This expected value is related to a well-
known quantity called the normal loss function. Fortunately, this can be calculated with
built-in Excel functions. The formula for E(B) is8
E(B)  [n(k)  kP(Z  k)]LD
(12.13)
Here, n(k) is the standard normal density function evaluated at k, and Z is a standard
normal random variable. (Recall that standard normal implies mean 0 and standard devia-
tion 1.) We now show how to implement model 1 for the camera example.
DEVELOPING THE SPREADSHEET FOR MODEL 1
We assume that Machey’s decides to use model 1 with p  $10 as the unit shortage cost.
The spreadsheet solution appears in Figure 12.15. (See the file Ordering Cameras 1.xlsx.)
It can be developed as follows:
1
Inputs. Enter the inputs in the blue range.
2
Lead time demand. Calculate the mean and standard deviation of lead time demand
in cells B12 and B13 with the formulas
=Lead_time*Expected_annual_demand
and
=SQRT(Lead_time)*Stdev_of_annual_demand
(Admittedly, the file contains a lot of range names to make the formulas more readable, but
you can create all of them in one step with the Create from Selection shortcut.)
3
Decision variables. Enter any values in cells B16 and B17 for the order quantity Q
and the multiplier k. These are the changing cells.
4
Safety stock and r eorder point. The decision variables determine the safety stock
and the reorder point. Calculate them in cells B18 and B19 with the formulas
=Multiple_k*Stdev_lead_time_demand
12.5 Probabilistic Inventory Models
743
8This is one of the few times in this book where you will have to take our word for it. The derivation of this for-
mula is beyond the level of this book. Also, it depends on demand being normally distributed.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

and
=Mean_lead_time_demand+Safety_stock
5
Expected backorders. Use Equation (12.13) to calculate the expected number of
backorders per order cycle, E(B), in cell B20 with the formula
=Stdev_lead_time_demand*(NORMDIST(Multiple_k,0,1,0)-Multiple_k*(1-
NORMSDIST(Multiple_k)))
Note that this formula uses two related functions, NORMDIST and NORMSDIST. The
first of these takes four arguments: a value, the mean, the standard deviation, and 0 or 1.
When the fourth argument is 1, the function returns a cumulative (left-hand tail) probabil-
ity, but when this argument is 0, it returns the value of the density function. Here it is used
with a fourth argument equal to 0 to evaluate the standard normal density at value k. The
second function, the NORMSDIST function, takes only one argument, a value. (The “S” in
NORMSDIST stands for standard normal.) It returns the probability to the left of this
value under the standard normal curve. To obtain the probability to the right of the value k,
you need to subtract the NORMSDIST probability from 1 (see Figure 12.16).
6
Expected annual costs. Use Equations (12.10) to (12.12) to calculate the expected
annual setup, holding, and shortage costs in cells B22 to B24 with the formulas
744
Chapter 12
Inventory Models
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
E
D
C
B
A
Opmal (R,Q) ordering policy for model 1
e
g
n
a
R
st
u
p
n
I
 names used:
Setup cost per order
$125
Expected_annual_demand
=Model!$B$6
Holding cost per unit per year
$8
Expected_shortage_per_cycle
=Model!$B$20
Expected annual demand
1200
F
7
2
$
B
$
!le
d
o
M
=
e
t
a
r
_lli
Stdev of annual demand
70
Holding_cost_per_unit_per_year
=Model!$B$5
Lead 
8
$
B
$
!le
d
o
M
=
e
m
it
_
d
a
e
L
2
9
1
0.0
e
m
it
Shortage cost per unit short
$10
Mean_lead_me_demand
=Model!$B$12
7
1
$
B
$
!le
d
o
M
=
k
_
elpitlu
M
Lead me demand
Order_quanty
=Model!$B$16
Mean lead me demand
23.077
Reorder_point
=Model!$B$19
Stdev lead me 
8
1
$
B
$
!le
d
o
M
=
k
c
o
ts
_
yt
e
fa
S
7
0
7.9
d
n
a
m
e
d
Setup_cost_per_order
=Model!$B$4
Ordering policy
Shortage_cost_per_unit_short
=Model!$B$9
Order 
3
1
$
B
$
!le
d
o
M
=
d
n
a
m
e
d
_
e
m
it
_
d
a
el_
v
e
d
tS
6.8
9
1
ytit
n
a
u
q
Mulple 
7
$
B
$
!le
d
o
M
=
d
n
a
m
e
d
_la
u
n
n
a
_
f
o
_
v
e
d
tS
2
1.1
k
Safety 
5
2
$
B
$
!le
d
o
M
=
ts
o
c
_la
u
n
n
a
_la
t
o
T
8.0
1
k
c
o
ts
Reorder 
9.3
3
t
nio
p
Expected shortage per cycle
0.65
Annual setup 
5
5
7
$
ts
o
c
Annual holding cost
$881
Annual shortage cost
$39
Total annual 
5
7
6,1
$
ts
o
c
Fill 
%
7
6.9
9
e
t
a
r
Figure 12.15
Optimal Solution
for Model 1
NORMDIST(k, 0, 1, 0)
(height)
1– NORMSDIST(k) 
(area)
k
Figure 12.16
NORMDIST and
NORMSDIST 
Functions
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

=Setup_cost_per_order*Expected_annual_demand/Order_quantity
=Holding_cost_per_unit_per_year*(Safety_stock+Order_quantity/2)
and
=Shortage_cost_per_unit_short*Expected_shortage_per_cycle*Expected_annual_
demand/Order_quantity
Then calculate the expected total annual cost in cell B25 by summing the costs in cells B22
to B24. (Ignore the fill rate in cell B27 for now. It will be used shortly in the discussion of
Model 2.)
USING SOLVER
The objective is to minimize the expected total annual cost. The only constraints are non-
negativity constraints on the changing cells, B16 and B17. As usual, GRG Nonlinear
Solver must be used. This model is nonlinear in both Q and k.
Discussion of the Solution
The interpretation of the Solver solution in Figure 12.15 is that Machey’s should wait until
the inventory level drops to approximately 34 cameras and then place an order for 199 cam-
eras. The expected number of backorders is E(B)  0.65, so that the expected shortage cost
during any order cycle is pE(B)  $6.50. Multiplying this by the expected number of cycles
per year (1200/198.6) gives the expected annual shortage cost of approximately $39.
Note that the optimal order quantity, 199, is very close to the optimal EOQ, 194, from
Example 12.1. This is despite the fact that demand is now random, not assumed known as
before. This explains why companies often use the simple EOQ formula to determine the
order quantity, even when demand is random.
Service Level Constraint for Model 2
Model 2 uses a service level constraint instead of a dollar shortage cost. To model this con-
straint, we need an expression for the fill rate, the fraction of demand met directly from
existing inventory. Note that Q items are ordered each cycle, and the expected shortage per
cycle is E(B), which was evaluated in model 1. Therefore, the expected fraction of demand
met on time is 1  E(B)Q, and the model 2 service level constraint becomes:
1  E(B)Q  s
(12.14)
(Note that the letter s now denotes the service level, not the unit storage cost.)
DEVELOPING THE SPREADSHEET FOR MODEL 2
The spreadsheet for model 2 appears in Figure 12.17. (See the file Ordering Cameras
2.xlsx.) It assumes a service level where at least 99% (s  0.99) of customer demands must
be satisfied with existing inventory. This model is very similar to the one shown in
Figure 12.15, so only the changes are listed.
1
Required ser vice le vel. There is no unit shortage cost input. Instead, enter the
required service level (fill rate) in cell D22.
2
Actual service level. Use the left side of Inequality (12.14) to calculate the expected
fraction of demand met with existing inventory in cell B22 with the formula
=1-Expected_shortage_per_cycle/Order_quantity
12.5 Probabilistic Inventory Models
745
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

3
Expected total annual cost. The total cost now includes only the setup and holding
costs (which are the same as before).
USING SOLVER
The objective is again to minimize the expected total annual cost, but now there is the ser-
vice level constraint in row 22. There is no longer a shortage cost to penalize shortages.
Instead, the company requires that 99% of all demand be met from existing inventory.
Discussion of the Solution
Compared to the solution for model 1, the solution in Figure 12.17 has a slightly larger
order quantity Q and a significantly lower multiplier k. Therefore, this model specifies that
Machey’s should order a bit more on each order, and it should hold less safety stock—that
is, it should let its inventory drop lower before ordering. Why are the solutions from the
two models different? One way to understand the difference is to substitute the optimal
values of Q and k from model 1 into the spreadsheet for model 2. If you do this, you will
find that Q and k from model 1 lead to a service level (in cell B22) of 0.997 in model 2.
This large service level, larger than the 0.99 required, can be attained only with increased
safety stock. Evidently, the unit penalty cost of $10 in model 1 is equivalent to a required
service level of 0.997 in model 2. Alternatively, if the service level is 0.99 in model 2, the
equivalent model 1 unit penalty cost is considerably less than $10.
746
Chapter 12
Inventory Models
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
G
F
E
D
C
B
A
Opmal (R,Q) ordering policy for model 2
Inputs
Range names used:
Setup cost per 
2
2
$
B
$
!le
d
o
M
=
e
t
a
r
_llif
_la
u
tc
A
5
2
1
$
r
e
d
r
o
Holding cost per unit per 
6
$
B
$
!le
d
o
M
=
d
n
a
m
e
d
_la
u
n
n
a
_
d
e
tc
e
p
x
E
8
$
r
a
e
y
Expected annual 
9
1
$
B
$
!le
d
o
M
=
elc
y
c
_
r
e
p
_
e
g
a
tr
o
h
s
_
d
e
tc
e
p
x
E
0
0
2
1
d
n
a
m
e
d
Stdev of annual 
5
$
B
$
!le
d
o
M
=
r
a
e
y
_
r
e
p
_
tin
u
_
r
e
p
_
ts
o
c
_
g
nidlo
H
0
7
d
n
a
m
e
d
Lead 
8
$
B
$
!le
d
o
M
=
e
m
it
_
d
a
e
L
2
9
1
0.0
e
m
it
Mean_lead_me_demand
=Model!$B$11
Lead me demand
6
1
$
B
$
!le
d
o
M
=
k
_
elpitlu
M
Mean lead me 
5
1
$
B
$
!le
d
o
M
=
ytit
n
a
u
q
_
r
e
d
r
O
7
7
0.3
2
d
n
a
m
e
d
Stdev lead me 
8
1
$
B
$
!le
d
o
M
=
t
nio
p
_
r
e
d
r
o
e
R
7
0
7.9
d
n
a
m
e
d
Required_ﬁll_rate
=Model!$D$22
Ordering policy
7
1
$
B
$
!le
d
o
M
=
k
c
o
ts
_
yt
e
fa
S
Order 
4
$
B
$
!le
d
o
M
=
r
e
d
r
o
_
r
e
p
_
ts
o
c
_
p
u
t
e
S
0.0
0
2
ytit
n
a
u
q
Mulple 
2
1
$
B
$
!le
d
o
M
=
d
n
a
m
e
d
_
e
m
it
_
d
a
el_
v
e
d
tS
7
4.0
k
Safety 
7
$
B
$
!le
d
o
M
=
d
n
a
m
e
d
_la
u
n
n
a
_
f
o
_
v
e
d
tS
6.4
k
c
o
ts
Reorder 
6
2
$
B
$
!le
d
o
M
=
ts
o
c
_la
u
n
n
a
_la
t
o
T
7.7
2
t
nio
p
Expected shortage per 
0
0.2
elc
y
c
Service level constraint
Actual ﬁll rate
Required ﬁll rate
0.990
>=
0.99
Annual setup 
0
5
7
$
ts
o
c
Annual holding 
7
3
8
$
ts
o
c
Total annual 
7
8
5,1
$
ts
o
c
Figure 12.17
Optimal Solution
for Model 2
It is usually easier for
a company to specify
a service level, but any
such service level is
really equivalent to
some unit shortage
cost.
This is an important concept. Machey’s managers probably favor model 2 because a
service level constraint is easier to estimate than a unit shortage cost. However, any particu-
lar service level in model 2 is really equivalent to an appropriate unit shortage cost in
model 1. To find the equivalent unit shortage cost p for any required service level s, you
can use SolverTable on model 1. You first calculate the fill rate as in model 2, as shown in
Figure 12.17 in cell B27. You then run SolverTable to see how the fill rate varies with the
unit shortage cost (see Figure 12.18). Note that Solver is actually minimizing total
expected annual cost, but it is reporting the fill rate. You can see, for example, that a fill
rate of 99% is equivalent to a unit shortage cost somewhere between $4 and $5. Similarly,
a fill rate of 98% is equivalent to a unit shortage cost of approximately $1. The point is that
when a company specifies a required fill rate, this is really equivalent to specifying a
corresponding unit shortage cost.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Random Lead Times  
Throughout this section, we have assumed that the lead time for orders is a known quantity.
It is fairly easy to modify the analysis for the case where the lead time L is random. This
is important, because uncertain lead times for ordering in real applications are not
uncommon—suppliers are often unable to deliver according to a precise schedule.
When L is random, the first step is to estimate its mean and standard deviation (prob-
ably from historical lead time data), which are denoted by L and L. Given these values,
the expected demand during lead time becomes
LD  L AD
and the standard deviation of demand during lead time becomes
LD  L2AD
 2AD
2L

The first of these is the expected lead time, expressed as a fraction of a year, multiplied by
the expected annual demand. The second formula is less intuitive, but as expected, it
includes both the uncertainty in annual demand and the uncertainty in lead time.
For example, suppose as before that AD  1200 and AD  70. However, instead of
L being fixed at 152, suppose that it is uncertain with mean L  152 and L  1104,
so that the standard deviation of the lead time is half a week. Then LD is still 23.077 units 
[ (152)(1200)], but the standard deviation of demand during lead time is
LD  (152)
702 
12002(
1104)
2  15.079
This is considerably larger than LD  9.7 when L was known with certainty. Intuitively, the
extra uncertainty about the lead time adds to the uncertainty about the demand during lead time.
After using these formulas to obtain LD and LD, the optimal (R,Q) can be found
exactly as in the nonrandom lead time case. For example, you can run Solver for model 2
using LD  15.079 in cell B12. (Nothing else needs to be changed.) The order quantity
hardly changes, the safety stock increases from 4.6 to 11.2, the reorder point increases
from 27.7 to 34.3, and the expected total annual cost increases from $1587 to $1640. In
short, when the lead time is uncertain, a company needs to order earlier, which means
larger safety stock and higher inventory holding costs.
■
12.5 Probabilistic Inventory Models
747
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
A
B
C
D
E
F
G
H
I
Oneway analysis for Solver model in Model worksheet
Unit shortage cost (cell $B$9) values along side, output cell(s) along top
Fill_rate
$1
98.03%
$2
98.06%
$3
98.38%
$4
98.93%
$5
99.21%
$6
99.38%
$7
99.49%
$8
99.57%
$9
99.63%
$10
99.67%
$11
99.71%
$12
99.74%
$13
99.76%
$14
99.78%
$15
99.80%
0.97
0.975
0.98
0.985
0.99
0.995
1
$1
$2
$3
$4
$5
$6
$7
$8
$9 $10 $11 $12 $13 $14 $15
Unit shortage cost ($B$9)
Sensivity of Fill_rate to Unit shortage cost
Figure 12.18
Equivalent Shortage
Costs and Fill Rates
for the Camera 
Example
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

748
Chapter 12
Inventory Models
P R O B L E M S
Skill-Building Problems
12. As stated in Example 12.6, the critical fractile analysis
is useful for finding the optimal order quantity, but it
doesn’t (at least by itself) show the probability distrib-
ution of net profit. Use @RISK, as in Chapter 10, to
explore this distribution. Actually, do it twice, once
with the triangular demand distribution and its optimal
order quantity and once with the normal demand dis-
tribution and its optimal order quantity. What can you
say about the resulting distributions of net profit?
What can you say about the resulting expected net
profits? Could you use @RISK to confirm that these
order quantities are indeed optimal? Explain how.
13. Consider each change to the monetary inputs (the pur-
chase cost, the selling price, and the salvage price) one
at a time in Example 12.6. For each such change,
either up or down, describe how the cost of under-
stocking and the cost of overstocking change, how the
critical fractile changes, and how the optimal order
quantity changes. Are these changes all intuitive?
14. You saw in Example 12.6 that the optimal order quan-
tities with the triangular and normal demand distribu-
tions are very similar (171 versus 174). Perhaps this is
because these two distributions, with the parameters
used in the example, have similar shapes. Explore
whether this similarity in optimal order quantities con-
tinues as the triangular distribution gets more skewed
in one direction or the other. Specifically, keep the
same minimum and maximum values (100 and 300),
but let the most likely value vary so that the triangular
distribution is more or less skewed in one direction or
the other. For each most likely value, use @RISK’s
Define Distributions tool to find the optimal order
quantity and compare this to optimal order quantity for
a normal demand distribution with the same mean and
standard deviation as the triangular distribution with
the given most likely value. (In other words, you
should pair each triangular distribution with a normal
distribution so that they have the same means and
standard deviations.) Comment on your results in a
brief report.
15. Change the model in the file Ordering Cameras
2.xlsx slightly to allow a random lead time with a
given mean and standard deviation. If the mean lead
time is two weeks, and the standard deviation of lead
time is half a week, find the optimal solution if the
company desires a fill rate of 98.5%. Explain exactly
how the company would implement this solution.
16. In the first (R,Q) model in Example 12.7, the one with
a shortage cost, we let both Q and the multiple k be
changing cells. However, we stated that the optimal Q
depends mainly on the fixed ordering cost, the holding
cost, and the expected annual demand. This implies
that a good approximation to the optimal Q is the EOQ
from Equation (12.4), replacing D with the expected
annual demand and s  ic with the given unit holding
cost. Check how good this approximation is by using
this EOQ formula to obtain Q and then using Solver
with a single changing cell—the multiple k—to opti-
mize the expected total annual cost. How close are the
results to those in Example 12.7?
17. In both (R,Q) models, the one with a shortage cost 
and the one with a service level constraint, we set up
Solver so that the multiple k is constrained to be 
nonnegative. The effect is that the reorder point R will
be no less than the mean demand during lead time, 
and the expected safety stock will be nonnegative.
This seems reasonable, but is it always optimal?
Experiment with the service level in the file Ordering
Cameras 2.xlsx. Change the Solver settings to allow
the multiple k to be negative; that is, don’t constrain it
to be nonnegative. For lower service levels, is it ever
optimal to have k negative? Comment briefly why this
might or might not be the case and explain the impli-
cations for the company.
18. In Example 12.7, we discussed the equivalence
between the model with shortage costs and the model
with a service level constraint. We also showed how to
illustrate this equivalence with SolverTable. Extend
the SolverTable in the Ordering Cameras 1.xlsx file,
with the unit shortage cost as the single input varied
from $1 to $15 in increments of $1. As outputs, keep
track of the order quantity, the safety stock, the reorder
point, the fraction of demand met with existing inven-
tory, and the expected annual setup, holding, and
shortage costs. Discuss whether these go in the direc-
tion you would expect. Also, discuss how these results
relate the two models, one with shortage costs and the
other with a service level constraint. (What is equiva-
lent to what?)
Skill-Extending Problems
19. We claimed that the critical fractile formula, Equation
(12.8), is appropriate because the optimal Q should
satisfy cunder (1  F(Q))  cover F(Q), that is, the cost
of understocking times the probability of understock-
ing should equal the cost of overstocking times the
probability of overstocking. Assume that Q satisfies
this equation [which is equivalent to Equation (12.8)].
Use a probability argument to show why Q  1 and
Q1 are both worse than Q in terms of expected cost.
20. The first (R,Q) model in this section assumes that the
total shortage cost is proportional to the amount of
demand that cannot be met from on-hand inventory.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Similarly, the second model assumes that the service
level constraint is in terms of the fill rate, the fraction
of all customer demand that can be met with on-hand
inventory. Consider the following variations of these
models. The first, labeled model 3, assumes that a
shortage cost is incurred on every order cycle that
experiences a stockout. This cost is independent of
the size of the stockout. The second model, labeled
model 4, prescribes a service level constraint but now
on the fraction of order cycles that experience no
stockouts.
a. In each of these new models, you need to calculate
the probability of a stockout during an order cycle.
This is the probability that the demand during lead
time is greater than the safety stock. Assuming that
demand during lead time is normally distributed,
12.6 Ordering Simulation Models
749
how can this probability be calculated? (Hint: Use
the NORMDIST or NORMSDIST function.)
b. Given your method in part a, solve the model from
Example 12.7 when the cost of having a shortage
in any cycle is $100, and all other parameters are as
before. What are the optimal reorder point and the
safety stock level?
c. Continuing part b, what model 4 service level con-
straint is this $100 stockout cost equivalent to?
21. Turn the previous problem around. Now assume that
the store’s service level requirement obligates it to
meet customer demand on 99% of all order cycles. In
other words, use model 4. What (R,Q) policy should it
use? Then find the model 3 cost parameter (the cost
per cycle with a shortage) that is equivalent to this ser-
vice level.
12.6 ORDERING SIMULATION MODELS
Analytical models such as those in the previous section are useful and often provide impor-
tant insights. Unfortunately, they can also often lead to dead ends. As problems become
more complex, the required mathematical models become too difficult for most managers to
comprehend. In fact, mathematical models do not even exist for many realistic problems.
Therefore, it is useful to turn to simulation, where virtually anything is allowed. Simulation
allows you to combine assumptions about uncertain quantities and ordering policies and
then play out the events as they occur through time. We already illustrated a newsvendor
simulation model in Chapter 10 for ordering Walton Bookstore’s calendars. The following
example illustrates a somewhat more ambitious ordering simulation. It describes a type of
ordering policy, an (s, S) policy, that is commonly used in periodic review situations.
E X A M P L E
12.8 SIMULATING ORDERING POLICIES AT HOME REPAIR
H
ome Repair is a large hardware retail store that often has to place orders for hammers.
The fixed cost for placing an order is $500, independent of the size of the order. The
unit cost per hammer is $20. Home Repair estimates that the cost of holding a hammer in
inventory for one week is $3. The company defines its inventory position at the beginning
of any week as the number of hammers in inventory, plus any that have already been
ordered but have not yet arrived, minus any backorders. The company’s ordering policy is
an (s, S) policy, a periodic review policy used by many companies. This policy, defined by
two numbers s and S, where s  S, specifies that if the inventory position at the beginning of
the week is at level x, and x is less than or equal to s, exactly enough hammers are ordered
to bring the inventory position up to S; that is, Home Repair orders S  x hammers.
Otherwise, if the inventory position is greater than s, no order is placed that week. If an
order is placed, it arrives after a lead time of one, two, or three weeks with probabilities 0.7,
0.2, and 0.1, respectively.
The weekly demand for hammers is uncertain, but it can be described by a normal dis-
tribution with mean 300 and standard deviation 75. The company’s policy is to satisfy all
demand in the week it occurs. If weekly demand cannot be satisfied completely from on-
hand inventory, an emergency order is placed at the end of the week for the shortage. This
order arrives virtually instantaneously but at a steep cost of $35 per hammer.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

It is currently the beginning of week 1, and the current inventory of hammers, includ-
ing any that may have just arrived, is 600. No other orders are on the way. Home Repair
wants to simulate several (s, S) policies to see which does best in terms of total cost over
the next 48 weeks.9
Objective
To use simulation to analyze costs when the company uses an (s,S) ordering policy.
Solution
We use @RISK to simulate a 48-week period and keep track of the total costs for this
period for each of several (s, S) policies. There is no way to optimize over all possible 
(s, S) policies (except by using a package such as Palisade’s RISKOptimizer), but it is pos-
sible to test a number of representative policies and choose the best of these.
DEVELOPING THE SIMULATION MODEL
The simulation model is shown in Figures 12.19 and 12.20, with a number of hidden rows
in the latter figure. (See the file Order Simulation.xlsx.) It is mostly a matter of careful
bookkeeping, as described in the following steps:
750
Chapter 12
Inventory Models
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
A
B
C
D
E
F
G
H
I
Evaluang an ordering policy
Costs
Range names used:
Fixed order 
6
1
$
B
$
!le
d
o
M
=
ih
s
_
y
c
n
e
g
r
e
m
E
0
0
5
$
ts
o
c
Variable order 
c
_
r
e
d
r
o
_
d
e
xiF
0
2
$
ts
o
c
o=Model!$B$13
Inventory holding 
5
1
$
B
$
!le
d
o
M
=
dlo
h
_
y
r
o
t
n
e
v
nI
3
$
ts
o
c
Emergency shipment 
ylk
e
e
w
_
n
a
e
M
5
3
$
ts
o
c
_ =Model!$B$25
Order_up_to_le=Model!$B$36
Distribuon of order lead me
Reorder_point_=Model!$B$35
# of 
_
ylk
e
e
w
_
v
e
d
tS
ytilib
a
b
o
r
P
s
k
e
e
w
d=Model!$B$26
r
e
d
r
o
_
elb
air
a
V
7.0
1
_=Model!$B$14
2
0.2
3
0.1
Distribuon of demand in a week - Normal (rounded to nearest integer)
Mean weekly demand
300
Stdev weekly demand
75
Ordering policies to try
Other inputs
Policy
s
S
Assumpons:
A company uses an ordering policy determined by two integers s (reorder point) and S (order up to quanty).  At the beginning of each 
week, right aer any shipments have arrived, its inventory posion is examined. This includes on-hand inventory plus any that has been 
ordered but has not yet arrived.  If the inventory posion is greater than s, no order is placed. But if it is less than or equal to s, an order is 
placed to bring the inventory posion up to S, and this order arrives aer a random lead me of 1 to 3 weeks. All demand is sasﬁed on 
me -- one way or the other.  Either it is sasﬁed from onhand inventory, or if demand in any week is greater than on-hand inventory, the 
demand is met by an emergency shipment (at a high cost).
28
29
30
31
32
33
34
35
36
Other inputs
Policy
s
S
Inial 
0
0
5
0
0
2
1
0
0
6
y
r
o
t
n
e
v
ni
Due in week 
0
0
5
0
5
3
2
0
2
Due in week 
0
5
7
0
5
3
3
0
3
4
500
750
Order parameters
5
400
1000
Policy 
0
0
0
1
0
0
6
6
1
x
e
d
ni
Reorder point 
0
5
2
1
0
0
5
7
0
0
2
s
Order up to level 
0
5
2
1
0
0
7
8
0
0
5
S
Figure 12.19 Inputs for the Simulation Model
9Why 48 weeks, not 52? There are two random inputs for each week in the model, plus one for the
RISKSIMTABLE function, and the maximum number of random inputs allowed by the academic version of
@RISK is 100. Therefore, 48 weeks gets us slightly under the limit.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

1
Inputs. Enter the inputs in the blue ranges in Figure 12.19. These include the various
costs, the parameters of the demand distribution, the current inventory situation, and possi-
ble combinations of s and S to test. (You can try other, or more, pairs if you like.) Note that
the values in cells B30 and B31 are 0 because of the assumption that no orders are cur-
rently on the way. However, the model is developed so that it can respond to nonzero val-
ues in these cells. These values correspond to orders placed before week 1 but not due in
until after week 1.
2
Ordering policy. As usual, it is a good idea to use a RISKSIMTABLE function so
that you can test all of the selected ordering policies simultaneously. To do this, enter the
formula
=RISKSIMTABLE(E29:E36)
in cell B34. Then enter the formulas
=VLOOKUP(B34,E29:G36,2)
and
=VLOOKUP(B34,E29:G36,3)
in cells B34 and B35 to capture the values of s and S that are used in the simulation.
3
Beginning inventory. Moving to the simulation model in Figure 12.20, the strategy
is the same as in most multiperiod models. You fill in the logic for the first few weeks and
then copy down. Begin with column B, which contains the beginning on-hand inventory,
right after any order has arrived. For week 1, this is the initial 600 hammers, so enter the
formula
=B29
in cell B44. For later weeks, you have to sum the final inventory from the previous week
and the amount due in, if any, from previous orders. To do this, enter the formulas
=H44+B30+SUMIF($F$44:F44,A45,$E$44:E44) 
=H45+B31+SUMIF($F$44:F45,A46,$E$44:E45)
and
=H46+SUMIF($F$44:F46,A47,$E$44:E46)
12.6 Ordering Simulation Models
751
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
87
88
89
90
91
A
B
C
D
E
F
G
H
I
J
K
L
M
Summary measures from 48-week simulaon below
Fixed order
Var order
Holding
Emergency
Total
Cost 
0
5,1
1
$
sla
t
o
t
0
$186,000
$22,650
$164,500
$384,650
Simulaon
Week
Begin on-hand
Due in later
Inv posion
Amt ordered
Week order arrives
Demand
End on-hand
Emerg orders
Fixed order
Variable order
Holding Emergency
5
3,1
$
0
$
0
$
0
0
0
3
0
0
3
A
N
0
0
0
6
0
0
0
6
1
0
$0
0
$
0
5
4
$
0
$
0
$
0
0
0
0
3
A
N
0
0
0
3
0
0
0
3
2
0
0,0
1
$
0
0
5
$
0
0
3
0
0
0
3
4
0
0
5
0
0
0
3
0
$0
$10,500
5
0,1
$
0
$
0
$
0
0
0
2
0
0
3
A
N
0
0
0
5
0
0
0
5
4
0
$0
0
0,6
$
0
0
5
$
0
0
1
0
0
0
3
6
0
0
3
0
0
2
0
0
0
2
5
0
$300
$3,500
0
$
0
5
4
$
0
$
0
$
0
0
0
0
3
A
N
0
0
0
3
0
0
0
3
6
0
0,0
1
$
0
0
5
$
0
0
3
0
0
0
3
8
0
0
5
0
0
0
7
0
$0
$10,500
5
0,1
$
0
$
0
$
0
0
0
2
0
0
3
A
N
0
0
0
5
0
0
0
5
8
0
$0
0
0,6
$
0
0
5
$
0
0
1
0
0
0
3
0
1
0
0
3
0
0
2
0
0
0
2
9
0
$300
$3,500
0
$
0
5
4
$
0
$
0
$
0
0
0
0
3
A
N
0
0
0
3
0
0
0
3
0
1
0
0,0
1
$
0
0
5
$
0
0
3
0
0
0
3
2
1
0
0
5
0
0
0
1
1
0
$0
$10,500
5
0,1
$
0
$
0
$
0
0
0
2
0
0
3
A
N
0
0
0
5
0
0
0
5
2
1
0
$0
5
0,1
$
0
$
0
$
0
0
0
2
0
0
3
A
N
0
0
0
5
0
0
0
5
4
4
0
$0
0
0,6
$
0
0
5
$
0
0
1
0
0
0
3
6
4
0
0
3
0
0
2
0
0
0
2
5
4
0
$300
$3,500
0
$
0
5
4
$
0
$
0
$
0
0
0
0
3
A
N
0
0
0
3
0
0
0
3
6
4
0
0,0
1
$
0
0
5
$
0
0
3
0
0
0
3
8
4
0
0
5
0
0
0
7
4
0
$0
$10,500
5
0,1
$
0
$
0
$
0
0
0
2
0
0
3
A
N
0
0
0
5
0
0
0
5
8
4
0
$0
Inventory and order quanes, and lead me 
sts
o
C
n
oit
a
m
r
o
f
ni
Figure 12.20 Simulation of a 48-Week Period
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

in cells B45 to B47. This last formula is general, so copy it down to the other weeks. Note
how the SUMIF function is used. It sums all previous orders from column E that are due in
at the beginning of the current week listed in column A. For example, in week 4, it looks
for any due dates in the range F44:F46 that equal 4 and sums the corresponding order
quantities.
4
Due in later. In column C, record the amounts already ordered but not yet in, so that
you can calculate the inventory position in column D. Do this by entering the formulas
=SUM(B30:B31) 
=B31+SUMIF($F$44:F44, ''>''&A45,$E$44:E44)
and
=SUMIF($F$44:F45, ''>''&A46,$E$44:E45)
in cells C44 to C46, and copy this latter formula down. The SUMIF function is used essen-
tially as in the previous step, but now you need conditions (the middle argument) such as
“1”. To do this in Excel, you must put the greater-than sign in quotes, followed by an
ampersand (&), and then a cell reference.
5
Inventory position. The inventory position is the amount on hand plus the amount
due in, so enter the formula
=SUM(B44:C44)
in cell D44 and copy it down.
6
Order. Following the logic of the (s, S) ordering policy, calculate the order quantity
in cell E44 with the formula
=IF(D44<=Reorder_point_s,Order_up_to_level_S-D44,0)
and copy it down. Then to see when this order arrives (if there is an order), enter the
formula
=IF(E44>0,A44+RISKDISCRETE($B$20:$B$22,$C$20:$C$22),''NA'')
in cell F44 and copy it down.
7
Demand. Generate random demands in column G (rounded to the nearest integer) by
entering the formula
=ROUND(RISKNORMAL(Mean_weekly_demand,Stdev_weekly_demand),0)
in cell G44 and copying it down.
8
End inventory and emer gency orders. If customer demand is less than on-hand
inventory, ending inventory is the difference; otherwise it is 0. Therefore, enter the formula
=MAX(B44-G44,0)
in cell H44 and copy it down. Similarly, there are emergency orders only if customer
demand is greater than on-hand inventory, so enter the formula
=MAX(G44-B44,0)
in cell I44 and copy it down.
9
Weekly costs. The weekly costs are straightforward. Calculate them for week 1 in
cells J44 to M44 with the formulas
=IF(E44>0,Fixed_order_cost,0)
=Variable_order_cost*E44
752
Chapter 12
Inventory Models
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

=Inventory_holding_cost*(B44+H44)/2
and
=Emergency_shipment_cost*I44
and copy these down. Note that the holding cost in any week is based on the average of the
beginning and ending inventories for that week. An alternative would be to base it on the
ending inventory only.
10 Summary measures. Calculate the total costs of the various types in row 40 and des-
ignate them as @RISK output cells. For example, the formula in cell B40 is (remember
that the text inside the RISKOUTPUT function is for labeling purposes only)
=RISKOUTPUT("Fixed order")+SUM(J44:J91)
It is important to look carefully at the completed model before running @RISK. Press
the F9 key a few times to get new random numbers and check whether all of the logic, par-
ticularly in columns B and C, is working the way it should. It is easy to make errors, espe-
cially in the timing of order arrivals, in a model as complex as this one, and there is no
sense in running @RISK on a model that contains logical errors.
USING @RISK
@RISK should be run exactly as in Chapters 10 and 11, after setting the number of itera-
tions to 1000 (each simulates a 48-week period) and the number of simulations to 8 (one
for each combination of s and S to be tested).
Discussion of the Solution
After running @RISK and copying selected outputs back to Excel, you should obtain
results similar to those in Figure 12.21. (As always in simulation, your results will differ
12.6 Ordering Simulation Models
753
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
A
B
C
D
E
F
G
H
I
Selected @Risk results for total cost (based on 1000 iteraons)
Simulaon
1
2
3
4
5
6
7
8
Reorder point 
0
0
7
0
0
5
0
0
6
0
0
4
0
0
5
0
5
3
0
5
3
0
0
2
s
Order up to level S
500
500
750
750
1000
1000
1250
1250
4
5,6
5
3
$
m
u
m
ini
M
1
$346,636
$332,586
$332,629
$336,452
$337,006
$342,045
$352,927
3
6,1
6
4
$
m
u
m
ix
a
M
1
$461,590
$449,048
$434,125
$440,090
$428,283
$442,806
$433,077
0
8,7
0
4
$
n
a
e
M
7
$396,686
$388,237
$377,528
$386,467
$378,010
$389,556
$389,416
9
6,7
1
$
v
e
d
tS
4
$17,880
$17,376
$16,219
$16,119
$14,616
$14,294
$12,736
Percenles
5%
$379,683
$367,872
$360,366
$351,501
$361,507
$355,731
$366,751
$369,032
10%
$385,767
$374,292
$366,243
$357,424
$365,954
$360,370
$372,600
$373,472
15%
$390,089
$378,259
$369,913
$361,177
$369,392
$363,303
$374,931
$376,345
20%
$392,433
$381,535
$373,376
$364,091
$372,813
$365,366
$377,605
$378,301
25%
$395,282
$383,945
$376,643
$366,386
$375,644
$367,662
$379,454
$380,381
30%
$397,931
$386,667
$378,936
$369,053
$378,042
$369,904
$381,326
$382,360
35%
$400,430
$389,063
$381,226
$370,620
$380,419
$371,498
$383,589
$384,160
40%
$403,193
$391,708
$383,837
$372,539
$382,118
$373,231
$385,236
$386,014
45%
$404,980
$394,116
$386,104
$374,636
$383,733
$375,473
$387,063
$387,605
50%
$407,125
$396,182
$388,043
$376,629
$385,544
$377,171
$388,766
$389,251
55%
$409,715
$398,894
$390,382
$379,321
$387,704
$379,055
$390,895
$390,870
60%
$411,953
$400,674
$392,656
$381,418
$389,840
$380,830
$393,128
$392,815
65%
$414,161
$403,225
$395,063
$383,588
$391,606
$382,909
$395,246
$394,595
70%
$416,864
$405,801
$397,014
$385,753
$394,092
$384,988
$396,851
$396,166
75%
$419,694
$407,837
$399,292
$388,581
$396,653
$387,438
$399,263
$398,066
80%
$422,451
$411,396
$402,091
$391,168
$399,818
$390,259
$401,548
$400,286
85%
$425,846
$415,285
$405,793
$394,226
$403,551
$393,795
$404,327
$402,137
90%
$431,667
$420,808
$410,319
$399,249
$407,570
$396,837
$407,913
$405,411
95%
$438 017
$427 398
$417 541
$404 318
$414 381
$404 064
$414 486
$410 237
120
95%
$438,017
$427,398
$417,541
$404,318
$414,381
$404,064
$414,486
$410,237
Figure 12.21 Selected Results from @RISK
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

slightly from ours because of different random numbers.) The two shaded cells correspond
to the smallest average 48-week total costs among all pairs of s and S. Home Repair might
prefer the policy with s  500 and S  750 (at least among these particular policies). This
policy has the smallest average total cost, it has the smallest 5th percentile, it has the small-
est median (50th percentile), and its 95th percentile is close to the smallest. Even with this
ordering policy, however, there is still considerable variability—from about $333,000 for
the best of the 1000 iterations to about $434,000 for the worst.
Admittedly, this simulation model is not particularly easy. The random lead times
require some tricky logic. However, an analytical (nonsimulation) model of a situation as
complex as Home Repair’s would be totally out of the question for all but the most mathe-
matically clever analysts. Simulation brings such complex models within your grasp. In
addition, the modeling process itself often yields insights, such as why one ordering policy
is better than another, that would not be apparent otherwise.
■
754
Chapter 12
Inventory Models
P R O B L E M S
Skill-Building Problems
22. Change the ordering simulation in Example 12.8 so
that the lead time can be 1, 2, 3, or 4 weeks with prob-
abilities 0.5, 0.2, 0.2, and 0.1, respectively. Also,
assume that based on previous orders, orders of sizes
350, 0, and 400 are scheduled to arrive at the begin-
nings of weeks 2, 3, and 4, respectively. Simulate the
same (s, S) policies as in the example.
23. Change the ordering simulation so that emergency
orders are never made. If demand in any week is
greater than supply, the excess demand is simply lost.
Simulate the same (s, S) policies as in the example.
Skill-Extending Problem
24. Change the ordering simulation so that emergency orders
are never made. Instead, assume that all excess demand
is backlogged, so the emergency cost should be replaced
by a unit penalty cost for shortages. You can use the
value $10. Now the inventory position is the amount on
hand, plus the amount on order, minus the backlog.
Simulate the same (s, S) policies as in the example.
12.7 SUPPLY CHAIN MODELS
One of today’s hottest areas of interest, both for academics and business managers, is sup-
ply chain management. This refers to the entire process of getting materials from suppliers,
transforming them into finished products, and ultimately getting the finished products to
customers. With current computer technology and enterprise resource planning (ERP)
software packages available from companies such as SAP, companies are able to interact
with their customers and suppliers in a much more integrated manner, thus making their
supply chains more efficient than ever before. Efficient supply chains have become a
requirement in most industries. Without them, companies cannot compete successfully.
There are numerous interesting and difficult management science problems under the
(very wide) supply chain umbrella. (For example, take a look at the July–August 2000,
November–December 2003, and July–August 2007 issues of Interfaces. These are all spe-
cial issues devoted entirely to supply chain management applications.) We consider one of
these in the following example. This is a problem faced by many companies in the fashion
industry. When they introduce a new fashion, they are never sure whether it will sell well
or not. Therefore, a reasonable strategy is to produce a limited amount early and see how
things go. If the product sells well early, they can produce more later on—subject to capac-
ity restrictions. If the product does poorly early, they can cut their losses short.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

12.7 Supply Chain Models
755
E X A M P L E
12.9 PLANNING PRODUCTION OF BLOUSES AT SHIRTTAILS
S
hirtTails is a clothing manufacturer that operates its own chain of discount retail stores.
At the beginning of November 2011, ShirtTails is trying to plan its production of a new
blouse that is worn primarily in the warmer months. Based on production constraints from
other products, the company knows it has two opportunities to produce this blouse—in
November 2011 and later in April 2012. The production capacity (for this blouse) is 1200
in November. In April, the capacity will increase to 2500. By April, demand for the
blouses produced in November will be known. Using this information, ShirtTails will then
be able to plan its production in April.
The unit cost of producing a blouse is $12, and the selling price will be $14. These
remain constant. There is a $1 holding cost per blouse still in inventory after the pre-April
demand. By November 2012, any remaining blouses in inventory will be sold at a mark-
down price of $4. (This is because ShirtTails plans to introduce a new blouse the next
year.) Demand for the blouses before April is not known with any certainty, but ShirtTails
believes it should be somewhere between 100 and 1000. After April, the demand for
blouses is expected to be anywhere from 3 to 7.5 times as large as the demand before April.
What production plan should the company use to maximize the expected profit from
these blouses?
Objective  To develop an optimization model that specifies production quantities of
blouses in two time periods, where the second production quantity can be based on
demand information from the first period.
Solution
You first need to recognize that a production plan is really a contingency plan. This means
that the company will determine a production quantity in November, but it will not commit
to a production quantity in April until after it observes the pre-April demand. In other
words, the contingency plan will specify a single production quantity in November and a
production quantity in April for each pre-April demand that might be observed.
Before solving anything numerically, specific probability distributions of demand are
required. We will eventually try several, but we initially assume “unimodal” symmetric
discrete distributions—essentially the discrete analog of a normal distribution where the
probabilities increase and then decrease. We spell out the details shortly.
Finally, we point out explicitly that this is not a simulation model, despite the uncer-
tainty. The plan is to calculate an expected profit for any given production plan and then
use Evolutionary Solver (as in Chapter 8) to maximize this expected profit.
DEVELOPING THE SPREADSHEET MODEL
The completed model appears in Figures 12.22 and 12.23. (See the file Fashion
Production.xlsx.) It can be developed with the following steps:
1
Inputs. Enter the inputs in the blue ranges in Figure 12.22. These include the given
costs, the capacities, and the probability distributions we are initially assuming. Regarding
these distributions, rows 13 and 14 indicate the distribution of pre-April demand, which
can be any value from 100 to 1000 in increments of 100. Note that the probabilities
increase gradually and then decrease—the unimodal property. The table in rows 18 to 27
then specifies the distribution of post-April demand, given the pre-April demand. For
example, if pre-April demand is 400 (in column E), then post-April demand will be one of
the values in the range E18:E27, with the corresponding probabilities in column L (which
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

are also unimodal). Note that the demands in each column of the bottom table range
from 3 times to 7.5 times the demand in row 13, as described in the statement of the
problem. Of course, this implies that the two periods have highly correlated demands. If
pre-April demand is high, post-April demand is also likely to be high. (There is no
requirement that the probabilities in row 14 be the same as those in column L. In fact,
there is no necessary connection between these two sets of probabilities. We made them
equal for illustration only.)
2
Production plan. Moving to the optimization model in Figure 12.23, enter any pro-
duction quantities in cell B30 and row 32. For example, the particular values in the figure
(the optimal values) imply that ShirtTails will produce 600 blouses in November. Then if
pre-April demand is 400 (column E), it will produce 1600 more blouses in April. In con-
trast, if pre-April demand is 600 or more (columns G–K), it will produce at capacity, 2500,
in April.
3
Production cost. The total production cost is proportional to the total number of
blouses produced. Calculate it in row 35 by entering the formula
=Unit_production_cost*(Early_production+B32)
in cell B35 and copying it across.
4
Holding cost. The holding cost depends only on the November production quantity
and pre-April demand. Calculate it in row 37 by entering the formula
=Holding_cost*MAX(Early_production-B13,0)
in cell B37 and copying it across.
756
Chapter 12
Inventory Models
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
A
B
C
D
E
F
G
H
I
J
K
L
Two-stage producon for a fashion product
Inputs
Unit producon cost
$12
constant through both periods
Selling 
t
n
a
ts
n
o
c
4
1
$
e
cir
p
 through both periods
Markdown 
r
o
f
4
$
e
cir
p
 any items le over aer later period
Holding 
d
e
g
r
a
h
c
1
$
ts
o
c
 per unit in inventory aer early period
Overcapacity penalty
$500,000
Early 
0
0
2
1
ytic
a
p
a
c
Later 
0
0
5
2
ytic
a
p
a
c
Demand during early period
0
0
0
1
0
0
9
0
0
8
0
0
7
0
0
6
0
0
5
0
0
4
0
0
3
0
0
2
0
0
1
e
ula
V
5
0.0
5
0.0
5
0.0
0
1.0
5
2.0
5
2.0
0
1.0
5
0.0
5
0.0
5
0.0
ytilib
a
b
o
r
P
Distribuon of demand during later period (probabilies at right assumed valid for each column separately)
Mulple of early demand
Probability
3
300
600
900
1200
1500
1800
2100
2400
2700
3000
0.05
3.5
350
700
1050
1400
1750
2100
2450
2800
3150
3500
0.05
4
400
800
1200
1600
2000
2400
2800
3200
3600
4000
0.05
4.5
450
900
1350
1800
2250
2700
3150
3600
4050
4500
0.10
5
500
1000
1500
2000
2500
3000
3500
4000
4500
5000
0.25
5.5
550
1100
1650
2200
2750
3300
3850
4400
4950
5500
0.25
6
600
1200
1800
2400
3000
3600
4200
4800
5400
6000
0.10
6.5
650
1300
1950
2600
3250
3900
4550
5200
5850
6500
0.05
7
700
1400
2100
2800
3500
4200
4900
5600
6300
7000
0.05
7.5
750
1500
2250
3000
3750
4500
5250
6000
6750
7500
0.05
Later demand (one column for each possible early demand)
Use the Scenario Manager (under What-If Analysis on the Data 
ribbon) to view models that incorporate diﬀerent types of 
probabilies.  When any of these scenarios is "shown," you'll 
see the opmal producon policy for that scenario.
Figure 12.22 Inputs for the Fashion Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

5
Sales revenue. The total sales revenue (not including markdown sales) depends on
both production quantities and both pre-April and post-April demand. Therefore, there is a
whole matrix of these quantities, one for each possible combination of demands.
Fortunately, these can be calculated with one copyable formula. To do so, enter the formula
=Selling_price*MIN(B$13+B18,Early_production+B$32)
in cell B39 and copy it to the range B39:K48. Note that the first argument of the MIN is the
total demand. The second argument is the total production. ShirtTails sells the smaller of
these two quantities at the $14 price.
6
Expected sales revenue. For each possible pre-April demand—that is, each column
from B to K—you need to calculate the expected total sales revenue, where the expected
value is over the distribution of post-April demand. To do this, enter the formula
=SUMPRODUCT(B39:B48,$L$18:$L$27)
in cell B49 and copy it across row 49. For example, if you are told that pre-April demand
is 400 (column E), your best guess for total sales revenue is $29,960.
7
Markdown revenue. The calculation of markdown revenue is similar to the previous
two steps. First, enter the formula
=Markdown_price*MAX((Early_production+B$32)-(B$13+B18),0)
12.7 Supply Chain Models
757
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
A
B
C
D
E
F
G
H
I
J
K
Producon decisions
Early producon
600
Later 
0
0
5
2
0
0
5
2
0
0
5
2
0
0
5
2
0
0
5
2
0
5
1
2
0
0
6
1
0
5
0
1
0
0
5
0
n
oitc
u
d
o
r
p
Costs, revenues for all scenarios
Producon cost
$7,200
$13,200
$19,800
$26,400
$33,000
$37,200
$37,200
$37,200
$37,200
$37,200
Holding 
0
$
0
$
0
$
0
$
0
$
0
0
1
$
0
0
2
$
0
0
3
$
0
0
4
$
0
0
5
$
ts
o
c
Sales revenue
$5,600
$11,200
$16,800
$22,400
$28,000
$33,600
$39,200
$43,400
$43,400
$43,400
$6,300
$12,600
$18,900
$25,200
$31,500
$37,800
$43,400
$43,400
$43,400
$43,400
$7,000
$14,000
$21,000
$28,000
$35,000
$42,000
$43,400
$43,400
$43,400
$43,400
$7,700
$15,400
$23,100
$30,800
$38,500
$43,400
$43,400
$43,400
$43,400
$43,400
$8,400
$15,400
$23,100
$30,800
$38,500
$43,400
$43,400
$43,400
$43,400
$43,400
$8,400
$15,400
$23,100
$30,800
$38,500
$43,400
$43,400
$43,400
$43,400
$43,400
$8,400
$15,400
$23,100
$30,800
$38,500
$43,400
$43,400
$43,400
$43,400
$43,400
$8,400
$15,400
$23,100
$30,800
$38,500
$43,400
$43,400
$43,400
$43,400
$43,400
$8,400
$15,400
$23,100
$30,800
$38,500
$43,400
$43,400
$43,400
$43,400
$43,400
$8,400
$15,400
$23,100
$30,800
$38,500
$43,400
$43,400
$43,400
$43,400
$43,400
Expected sales revenues
$8,015
$14,980
$22,470
$29,960
$37,450
$42,560
$43,190
$43,400
$43,400
$43,400
Markdown revenue
$800
$1,200
$1,800
$2,400
$3,000
$2,800
$1,200
$0
$0
$0
$600
$800
$1,200
$1,600
$2,000
$1,600
$0
$0
$0
$0
$400
$400
$600
$800
$1,000
$400
$0
$0
$0
$0
$200
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
$0
Expected markdown revenues
$110
$120
$180
$240
$300
$240
$60
$0
$0
$0
Expected values
Producon cost
$31,500
Holding 
5
0
1
$
ts
o
c
Sales revenue
$36,101
Markdown revenue
$185
1
8
6,4
$
tif
o
r
P
Figure 12.23 The Optimization Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

in cell B51 and copy it to the range B51:K60. These cells show the markdown revenue for
each demand combination. Then calculate the expected markdown revenues, given pre-
April demand, by entering the formula
=SUMPRODUCT(B51:B60,$L$18:$L$27)
in cell K61 and copying it across row 61.
8
Expected revenues, costs, and profits. At this point, rows 35, 37, 49, and 61 contain
revenues and costs for each possible value of pre-April demand. To get overall expected
values, you must “SUMPRODUCT” these with the row of pre-April demand probabilities.
For example, calculate the overall expected sales revenue in cell B66 with the formula
=SUMPRODUCT(B49:K49,B14:K14)
The others are calculated similarly, and the expected profit is the sum of expected revenues
minus the sum of expected costs. These are the values ShirtTails can expect as it looks
ahead from November 2011—that is, before any demands have been observed.
USING SOLVER
Solver should be set up as shown in Figure 12.24. The objective cell is the expected profit,
the changing cells are the production quantities, and they must be constrained to be within
capacity. Of course, the production quantities must also be nonnegative. Note that
Evolutionary Solver is used because of the various MAX and MIN functions in the cell
formulas. Recall that the other Solvers have problems with such functions, whereas
Evolutionary Solver handles them nicely.
758
Chapter 12
Inventory Models
Figure 12.24
Solver Dialog Box
for the Fashion
Model
Discussion of the Solution
The solution in Figure 12.23 is fairly intuitive. ShirtTails could produce up to 1200 units in
November, but it holds production to 600 because it is not sure whether these blouses will
be popular. After observing the pre-April demand, the company then produces more or
less, depending on the success of the blouses to that point. If pre-April demand is its mini-
mum value, 100, then there are already 500 of these “dogs” left in inventory, and the
company does not produce any more. But if pre-April demand is sufficiently large, the
company recognizes that it has a hot item and produces to capacity in April.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

We continue this example by seeing how the shape of the demand distribution affects
the optimal production plan. The distribution we have been using assumes a most likely
demand in the middle, with less likely demand values on either side—the unimodal prop-
erty. We investigate two other possibilities, shown in Figures 12.25 and 12.26. We call the
12.7 Supply Chain Models
759
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
63
64
65
66
67
68
A
B
C
D
E
F
G
H
I
J
K
L
Demand during early period
0
0
0
1
0
0
9
0
0
8
0
0
7
0
0
6
0
0
5
0
0
4
0
0
3
0
0
2
0
0
1
e
ula
V
5
2.0
0
1.0
5
0.0
5
0.0
5
0.0
5
0.0
5
0.0
5
0.0
0
1.0
5
2.0
ytilib
a
b
o
r
P
Distribuon of demand during later period (probabilies at right assumed valid for each column separately)
Mulple of early demand
Probability
3
300
600
900
1200
1500
1800
2100
2400
2700
3000
0.25
3.5
350
700
1050
1400
1750
2100
2450
2800
3150
3500
0.10
4
400
800
1200
1600
2000
2400
2800
3200
3600
4000
0.05
4.5
450
900
1350
1800
2250
2700
3150
3600
4050
4500
0.05
5
500
1000
1500
2000
2500
3000
3500
4000
4500
5000
0.05
5.5
550
1100
1650
2200
2750
3300
3850
4400
4950
5500
0.05
6
600
1200
1800
2400
3000
3600
4200
4800
5400
6000
0.05
6.5
650
1300
1950
2600
3250
3900
4550
5200
5850
6500
0.05
7
700
1400
2100
2800
3500
4200
4900
5600
6300
7000
0.10
7.5
750
1500
2250
3000
3750
4500
5250
6000
6750
7500
0.25
Producon decisions
Early producon
450
Later 
0
0
5
2
0
0
5
2
0
0
5
2
2
5
3
2
3
5
9
1
1
5
5
1
4
5
1
1
1
5
7
2
5
3
0
n
oitc
u
d
o
r
p
Expected values
Producon cost
$22,478
Holding 
2
2
1
$
ts
o
c
Sales revenue
$26,178
Markdown revenue
$13
1
9
5,3
$
tif
o
r
P
Later demand (one column for each possible early demand)
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
63
64
65
66
67
68
A
B
C
D
E
F
G
H
I
J
K
L
Demand during early period
0
0
0
1
0
0
9
0
0
8
0
0
7
0
0
6
0
0
5
0
0
4
0
0
3
0
0
2
0
0
1
e
ula
V
0
1.0
0
1.0
0
1.0
0
1.0
0
1.0
0
1.0
0
1.0
0
1.0
0
1.0
0
1.0
ytilib
a
b
o
r
P
Distribuon of demand during later period (probabilies at right assumed valid for each column separately)
Mulple of early demand
Probability
3
300
600
900
1200
1500
1800
2100
2400
2700
3000
0.10
3.5
350
700
1050
1400
1750
2100
2450
2800
3150
3500
0.10
4
400
800
1200
1600
2000
2400
2800
3200
3600
4000
0.10
4.5
450
900
1350
1800
2250
2700
3150
3600
4050
4500
0.10
5
500
1000
1500
2000
2500
3000
3500
4000
4500
5000
0.10
5.5
550
1100
1650
2200
2750
3300
3850
4400
4950
5500
0.10
6
600
1200
1800
2400
3000
3600
4200
4800
5400
6000
0.10
6.5
650
1300
1950
2600
3250
3900
4550
5200
5850
6500
0.10
7
700
1400
2100
2800
3500
4200
4900
5600
6300
7000
0.10
7.5
750
1500
2250
3000
3750
4500
5250
6000
6750
7500
0.10
Producon decisions
Early producon
586
Later 
0
0
5
2
0
0
5
2
0
0
5
2
0
0
5
2
2
3
2
2
8
8
7
1
4
6
3
1
4
8
7
5
7
3
0
n
oitc
u
d
o
r
p
Expected values
Producon cost
$26,885
Holding 
3
4
1
$
ts
o
c
Sales revenue
$30,991
Markdown revenue
$107
0
7
0,4
$
tif
o
r
P
Later demand (one column for each possible early demand)
Figure 12.25 Results for a U-Shaped Probability Distribution
Figure 12.26 Results for Equally Likely Probabilities
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

first of these “U-shaped” because the probabilities are large on either end but decrease in
the middle. This is reasonable if ShirtTails believes the blouse will be either very popular
or very unpopular. The second distribution, in Figure 12.26, has equal probabilities for all
demand values. This equally likely case is reasonable if ShirtTails has no idea how popular
the blouses will be. In comparison with the unimodal scenario, there are some clear differ-
ences between the optimal solutions. The equally likely scenario calls for less production
in November, generally less production in April, and a somewhat lower expected profit.
This pattern is even more evident with the U-shaped scenario, which has the lowest pro-
duction levels and the lowest expected profit.
These differences make intuitive sense. With a unimodal distribution, the company has
the most assurance of what demand is likely to be, and it can plan accordingly. Planning is
more difficult with the equally likely “no idea” distribution, and it is even more difficult
with the U-shaped distribution. With this latter distribution, the company isn’t sure whether
to produce a lot in case demand is strong or to produce very little in case demand is weak. It
stands to lose no matter what it does! Of course, the company cannot simply choose one dis-
tribution over another because one produces a larger expected profit. It should choose the
distribution most in line with its realistic assessment of future demand.
■
Excel Tip: Scenario Manager
As the text box in Figure 12.22 indicates, we used Excel’s Scenario feature to save each of
the three scenarios under the names Unimodal, U-shaped, and Equally Likely. This feature
is useful if you want to store several named scenarios in a single workbook. To do so, enter
key input values in your spreadsheet that constitute a scenario, including the probabilities
and the values in the red cells after running Solver. Then use the Scenario Manager under
What-If Analysis on the Data ribbon. This gives you a chance to name a scenario and des-
ignate the cells (unfortunately called Changing Cells, b ut not at all the same concept as
Solver’s Changing Cells) that include the key inputs. If you ever want to view this scenario
later on, just use the Scenario Mana ger, select the scenario you want fr om the list of sce-
narios, and click on View.
The following example illustrates inventory management in a multiechelon setting, that is,
in a setting where inventory is held at multiple locations. Although many versions of this
general problem exist in both academic articles and in real companies, we illustrate the sit-
uation where a central warehouse holds and distributes inventory to several retailers, each of
which has uncertain demand. The problem is complicated, as it usually is in real situations,
by ordering lead times, and the way inventory should be managed is far from obvious.
760
Chapter 12
Inventory Models
E X A M P L E
12.10 MANAGING INVENTORY AT LEE SUPPLY
Lee Supply has three retail stores that are supplied by a central warehouse. For this exam-
ple, the focus is on a single product sold at the stores. At the beginning of each week, each
store requests a quantity of this product from the warehouse, and such shipments arrive at
the beginning of the following week (one-week lead time). Similarly, at the beginning of
each week, the warehouse orders a quantity of this product from an overseas manufac-
turer, and such shipments arrive in three weeks (three-week lead time). Weekly demands
at each retailer are independent, normally distributed, random variables, and any demands
that cannot be met from on-hand inventory are backordered and satisfied as soon as pos-
sible. The means and standard deviations of demand can vary across retailers, but they are
constant through time. All ordering policies are characterized by an order-up-to quantity
Q, where each retailer and the warehouse can have a different Q. For a retailer, this works
as follows. At the beginning of a week, the retailer checks the beginning inventory (after
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

the arrival of the order from the previous week and after satisfying any backorders from
the previous week) and subtracts the mean demand. This difference is its expected inven-
tory by the end of the week. It then places an order large enough to raise this difference to
Q. For example, if Q 180, the beginning inventory is 150, and the mean demand is 140,
the retailer will place an order for 180(150140) 170 items from the warehouse.
Depending on its own on-hand inventory, the warehouse might or might not be able to sat-
isfy all retailer requests. If it has enough on hand, it satisfies the requests completely.
However, if it doesn’t have enough on hand, it allocates proportionally. For example, sup-
pose the three retailer requests are for 150, 200, and 100 items, and the warehouse has
only 360 items on hand, or 80% of the total requested. Then each retailer gets 80% of its
request (rounded to the nearest integer). Finally, the ordering policy for the warehouse,
again determined by an order-up-to quantity Q, works as follows. The warehouse calcu-
lates the sum of its current and pipeline inventory (the latter being shipments on the way
from the manufacturer) and subtracts the total it is about to send to the retailers this week.
Then it orders enough to raise this difference to Q. The company would like to choose the
four Q values to minimize the average total inventory in the system over time, while assur-
ing that there is a large probability of having a high fill rate (the percentage of demand
met on time). How should it proceed?
Objective
To develop a simulation model that allows the company to evaluate the total
system inventory and the fill rate for any values of the order-up-to quantities, and then to
choose “good” values of these quantities.
Solution
We use simulation because of the complexity of the problem. Even so, the modeling requires
some careful planning. The approach is to simulate one year (52 weeks) of ordering and
demands, starting with given inventories on hand or in the pipeline at the beginning of week 1.
Then the two outputs to keep track of are (1) the average (over all weeks) of the total inventory
on hand or in the pipeline at all locations, and (2) the fill rate, the percentage of all demands that
are not backordered. Once the model is developed, a search for “good” Q values can be made.
DEVELOPING THE SPREADSHEET MODEL
The model appears in Figures 12.27 and 12.28. You can develop the logic of the simulation
with the following steps.
1
Inputs. Enter the inputs in the blue cells. These include the pipeline values in rows 8
and 9, the on-hand inventory in row 13, and the means and standard deviations of demand
in rows 17 and 18.
2
Order-up-to quantities. Enter any order-up-to quantities, the decision variables, in
row 22.
3
Beginning inventories. The beginning inventories for week 1 in row 34, columns
B–G, are the given inputs. (Note that columns F and G are pipeline inventories, items due
in one week and two weeks, respectively.) For weeks 2 on, the beginning inventories at the
retailers are the ending inventories plus amounts sent the previous week from the ware-
house. So enter the formula
=K34+R34
in cell B35, and copy it across to column D and down all rows. Note that if there is a back-
order (a negative inventory), this formula accounts for it correctly by subtracting from the
amount sent from the warehouse. For the warehouse, enter the formulas
12.7 Supply Chain Models
761
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

762
Chapter 12
Inventory Models
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
A
B
C
D
E
F
Simulaon of a mulechelon supply network
Lead mes (weeks)
Manufacturer to warehouse
3
Warehouse to retailer
1
Inventory currently in pipeline to warehouse
Arriving next week
200
Arriving in two weeks
100
Current inventories at retailers and warehouse
R1
R2
R3
W
130
240
175
400
Distribuon of weekly demands (assumed normal and rounded) at retailers
R1
R2
R3
Mean 
0
5
1
0
0
2
0
0
1
d
n
a
m
e
d
200
Stdev of demand
20
40
30
Order-up-to-quanes (decision variables) at retailers and warehouse
R1
R2
R3
W
143
273
233
2941
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
A
B
C
D
E
F
G
H
I
J
K
L
M
N
O
P
Q
R
S
T
U
V
W
X
Outputs from simulaon
Overall ﬁll rate
96.61%
Avg system inventory
612.6
Summary stats of outputs
P(ﬁll rate < 95%)
0.191
≈
0.200
Mean avg system inventory
595.6
Simulaon
Beginning R inventories
W inventories
OQs
Amounts sent to Rs
OQ R demands
Ending R inventories
Backorders
System
Week
R1
R2
R3
W
W1
W2
R1
R2
R3
R1
R2
R3
W
R1
R2
R3
R1
R2
R3
R1
R2
R3
inventory
1
130
240
175
400
200
100
108
234
169
85
183
132
2755
100
173
173
30
67
2
0
0
0
1245
2
115
250
134
200
100
2755
123
224
210
44
80
75
199
90
190
171
25
60
-37
0
0
37
499
3
69
140
38
101
2755
199
169
334
306
21
42
38
101
93
210
143
-24
-70
-105
24
70
105
247
4
-3
-28
-67
2755
199
101
241
502
411
241
502
411
1154
120
159
183
-123
-187
-250
120
159
183
-98
5
118
315
161
1800
101
1154
120
159
183
120
159
183
462
96
219
163
22
96
-2
0
0
2
594
6
142
255
181
1439
1154
462
96
219
163
96
219
163
478
101
209
167
41
46
14
0
0
0
578
7
137
265
177
2115
462
478
101
209
167
101
209
167
477
67
170
129
70
95
48
0
0
0
579
Figure 12.27 Model Inputs and Order-Up-To Quantities
Figure 12.28 Inventory Simulation
=E34-SUM(K34:M34)+F34
=G34
and
=N34
in cells E35, F35, and G35, and copy these down. The first subtracts the amount sent to the
retailers but adds the order due in this week.
4
Retailer order quantities. Given the order-up-to policy by each retailer, enter the formula
=MAX(B$22-(B34-B$17),0)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

in cell H34, copy it to cells I34 and J34, and copy these down. The reason for the MAX is
that if the retailer’s inventory position, after subtracting the expected demand, is already at
or above the order-up-to quantity, no order is placed.
5
Amounts sent to retailers. The total requested by the retailers is compared to the on-
hand inventory at the warehouse. If there is enough, the requests are satisfied. If not, they
are satisfied proportionally. To implement this logic, enter the formula
=IF(SUM($H34:$J34)<=$E34,H34,ROUND(H34/SUM($H34:$J34)*$E34,0))
in cell K34, copy it to cells L34 and M34, and copy these down. (The ROUND function
ensures that integer amounts are sent.)
6
Warehouse order quantity. Given the order-up-to policy by the warehouse, enter the
formula
=MAX($E$22-(SUM(E34:G34)-SUM(K34:M34)),0)
in cell N34 and copy it down. Again the MAX is for the case where the warehouse net
inventory (including pipeline inventory but subtracting shipments to retailers) is already at
or above the order-up-to quantity. Then no order is placed.
7
Retailer demand. To generate the normally distributed demands, enter the formula
=ROUND(NORMINV(RAND( ),B$17,B$18),0)
in cell O34, copy it to cells P34 and Q34, and copy these down. Again, the ROUND func-
tion ensures integer demands. Also, the “Excel way” of generating normally distributed
random values, rather than RISKNORMAL, has been used. Otherwise, the 52-week simu-
lation would use more @RISK functions than are allowed in the academic version.
8
Ending r etailer in ventories. To calculate the ending retailer inventories (before
warehouse requests at the beginning of this week arrive), enter the formula
=B34-O34
in cell R34, copy it to S34 and T34, and copy these down. Note that a negative value in any
of these cells indicates the amount backordered.
9
Backorders. Finding the backorders for a retailer in a given week is tricky. If the
retailer’s beginning inventory is nonnegative and demand is greater than this, then the
excess demand is backordered. However, if the retailer’s beginning inventory is negative,
indicating that it cannot completely satisfy the previous week’s backorders, then all
demand this week will be backordered. To implement this logic, enter the formula
=IF(B34<0,O34,IF(O34>B34,O34-B34,0))
in cell U34, copy it to V34 and W34, and copy these down. Then find the fill rate over all
52 weeks with the formula
=1-SUM(U34:W85)/SUM(O34:Q85)
in cell B25. The ratio of sums is total backorders divided by total demands, so one minus
this is the fraction of demand satisfied on time.
10 System inventory. System inventory in any week is defined as the sum of beginning
inventories at the retailers, plus warehouse inventory on hand or in the pipeline, so enter
the formula
=SUM(B34:G34)
in cell X34 and copy it down. Then average these values in cell B26.
12.7 Supply Chain Models
763
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

11 @RISK summary measures. Designate cells B25 and B26 as @RISK output cells.
Then summarize then in cells B29 and B30 with the formulas
=RISKTARGET(B25,0.95)
and
=RISKMEAN(B26)
The first of these finds the probability that the overall fill rate is less than or equal to a tar-
get value, 95%. The order-up-to quantities should be chosen to make this rather small (we
chose 0.2), while making the mean in cell B30 as small as possible.
USING @RISK AND RISK OPTIMIZER
You now have two options. First, you can run @RISK (for 1000 iterations, say) with any
chosen values for the order-up-to quantities. You will then see the key outputs in rows 25,
26, 29, and 30. However, it is fairly difficult to guess order-up-to quantities that achieve a
given probability, such as 0.2, in cell B29 and make the mean average system inventory in
cell B30 small. Therefore, your second option is to use RISKOptimizer, a companion
Palisade add-in to @RISK. We tried this, setting up RISKOptimizer to minimize the mean
in cell B30 while constraining the probability in cell B29 to be less than or equal to 0.2. As
with Solver, RISKOptimizer provides a dialog box for setting up the optimization model
(see Figure 12.29), but it has more options because of the simulation context. We will not
pursue the details here, except to say that RISKOptimizer is a very powerful tool in con-
junction with @RISK simulations, and that it leads to the order-up-to quantities in
Figure 12.28. Note that total weekly expected demand at the retailers is 450, but to ensure
that 95% of the demand is met on time with fairly high probability (0.8), the total system
inventory has to average around 595. You can probably guess the reasons: uncertainty in
demand, complicated by lead times in deliveries. The result is the large level of safety
stock held in this model—and by most companies.
764
Chapter 12
Inventory Models
Figure 12.29
RISKOptimizer
Model Definition
Dialog Box
■
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

12.8 CONCLUSION
We have examined a variety of inventory/ordering models in this chapter. The general
theme is the balance companies try to find between competing costs. If they order frequent,
small quantities, they keep inventory low, but they incur large fixed ordering costs. In con-
trast, if they order infrequent, large quantities, they minimize ordering costs, but they incur
large holding costs. The basic EOQ model and its many variations are able to achieve the
right balance between these costs. These EOQ models are relatively straightforward and
find many uses in today’s business world. However, as we introduce complications that real
companies face, such as multiple products, uncertain demand, uncertain delivery lead times,
and complex supply chain considerations, the models can become extremely difficult. In
this case, simulation is often the best alternative; sometimes, it is the only alternative.
Summary of Key Management Science Terms
Term
Explanation
Page
Deterministic inventory 
Model where all inputs, including demands and lead times, are 
715
model
assumed to be known
Probabilistic inventory 
Model where demands (and possibly other inputs) are uncertain 
715
model
and must be estimated with probability distributions
Lead time
The time between placement of an order and receiving it
716
Setup cost (or ordering cost)
Fixed cost of placing an order, independent of the size of the order
716
Continuous review model
Model where order can be placed at any point in time
717
Reorder point
Inventory level that triggers an order to replenish stock
717
Periodic review model
Model where order is placed only at discrete points in time, 
717
such as the beginning of a week
Holding (or carrying) cost
Cost of holding inventory; could be cost of physical storage 
718
or cost of money tied up in inventory
Shortage (or penalty) cost
Cost of not having enough on hand to meet customer demand; 
718
could be a dollar cost or a loss of goodwill
Economic order quantity 
Commonly used models that find the order quantity that trades 
718
(EOQ) models
off setup cost versus holding cost (plus possibly other costs), 
typified by the famous square root formula
(continued)
12.8 Conclusion
765
P R O B L E M
Skill-Building Problem
25. The problem in Example 12.9 assumes that the heaviest
demand occurs in the second (post-April) phase of sell-
ing. It also assumes that capacity is higher in the second
production opportunity than in the first. Suppose the sit-
uation is reversed, so that the higher capacity and most
of the demand occur in the first phase. Make some rea-
sonable assumptions for the resulting input parameters,
and then solve for the optimal production plan. Do you
get qualitatively different results? Which situation
would you rather face if you were ShirtTails?
26. The multiechelon inventory model in Example 12.10
requires about 595 items of on-hand or pipeline inven-
tory, on average, to satisfy the fill rate constraint, even
though the mean total demand per week is only 450.
See how this changes as the amount of uncertainty
decreases. Specifically, make the standard deviations
of demand smaller and then run RISKOptimizer (with
exactly the same settings). You can make the standard
deviations as small as you like. Does the mean total
system inventory get closer to 450?
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Summary of Key Management Science Terms
(Continued)
Term
Explanation
Page
Probabilistic inventory 
Models where demand and possibly other inputs such as lead times 
736
models
are treated as random variables
Newsvendor model
General probabilistic inventory model where only one order is placed 
737
and the decision maker wants to avoid ordering too little or too much
Critical fractile
Optimal order quantity in a newsvendor model; derived by balancing 
737
the costs of ordering too little and ordering too much
Safety stock
Extra inventory held in case demand during lead time is larger than 
740
expected
(R,Q) ordering policy
Continuous review ordering policy that orders Q when inventory 
740
level falls to R
Normal loss function
Function that enables us to calculate the expected shortage during 
743
an order cycle, assuming normally distributed demand
Inventory position
Inventory on hand, plus any ordered, minus back orders
749
Supply chain models
Wide variety of models that model the process of getting goods 
754
from suppliers, manufacturing or assembling them, and distributing 
them to customers
766
Chapter 12
Inventory Models
P R O B L E M S
Skill-Building Problems
27. A bakery that orders cartons of bread mix has used an
EOQ model to determine that an order quantity of 90
cartons per order is economically optimal. The bakery
needs 150 cartons per month to meet demand. It takes
L days for the bakery’s supplier to deliver an order.
When should the bakery place its orders when L  2,
when L  5, and when L  10? (Assume that the bak-
ery and its supplier both work seven-day weeks and
that there are 30 days per month.)
28. Consider the basic EOQ model. We want to know the
sensitivity of (1) the optimal order quantity, (2) the
sum of the annual order cost and the annual holding
cost (not including the annual purchase cost cD), and
(3) the time between orders to various parameters of
the problem.
a. How do (1), (2), and (3) change if the setup cost K
decreases by 10%?
b. How do (1), (2), and (3) change if the annual
demand doubles?
c. How do (1), (2), and (3) change if the cost of capi-
tal increases by 10%? (For this part, assume that
the storage cost s is zero.)
d. How do (1), (2), and (3) change if the changes in
parts a, b, and c all occur simultaneously?
29. Based on Baumol (1952). Money in your savings
account earns interest at a 3% annual rate. Each time
you go to the bank, you waste 15 minutes in line, and
your time is worth $10 per hour. During each year, you
need to withdraw $10,000 to pay your bills.
a. How often should you go to the bank?
b. Each time you go to the bank, how much money
should you withdraw?
c. If your need for cash increases, will you go to the
bank more often or less often?
d. If the interest rate increases, will you go to the
bank more often or less often?
e. If the bank adds more tellers, will you go to the
bank more often or less often?
30. The efficiency of an inventory system is often mea-
sured by the turnover ratio. (TR), defined by
TR 
a. Does a high turnover ratio indicate an efficient
inventory system?
b. If the EOQ model is being used, determine TR in
terms of K, D, h, and Q.
c. Suppose that D increases. Show that TR will also
increase. Does this make intuitive sense?
31. A consulting firm is trying to determine how to mini-
mize the annual costs associated with purchasing high-
quality paper for its printers. Each time an order is
placed, an ordering cost of $50 is incurred. The price
per ream of printer paper depends on Q, the number of
reams ordered, as shown in the file P12_31.xlsx. The
annual holding cost is 20% of the dollar value of
inventory. During each month, the consulting firm uses
80 reams of printer paper. Determine the optimal order
quantity and the number of orders placed each year.
32. The Gilette Company buys a product using the price
schedule given in the file P12_32.xlsx. The company
Cost of goods sold per year
Average value of on-hand inventory
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

12.8 Conclusion
767
estimates the unit holding cost at 10% of the purchase
price and the ordering cost at $100 per order. Gilette’s
annual demand is 1500 units.
a. Determine how often the company should order.
b. Determine the optimal order quantity.
c. At what price should the company order?
33. Each year, Shopalot Stores sells 10,000 cases of soda.
The company is trying to determine how many cases to
order each time it orders. It costs $150 to process each
order, and the cost of carrying a case of soda in inven-
tory for one year is 20% of the purchase price. The soda
supplier offers Shopalot the schedule of quantity dis-
counts shown in the file P12_33.xlsx, where Q is the
number of cases per order. Each time an order is placed,
how many cases of soda should the company order?
34. The manager of a hardware store decides to use the
EOQ with shortages model to determine the ordering
policy for tape measures. Using economic considera-
tions, the manager determines that she should use an
order quantity of Q  30 and have a maximum
shortage of b  3. The lead time for her supplier to
deliver an order is L working days, where there are six
working days in a week. (Essentially, you can ignore
Sundays.) The weekly demand is for 20 tape mea-
sures. What reorder point should the manager use if
L  3; if L  5; if L  10? (Hint: The manager should
plan her orders so that the inventory level is b when
an order arrives.)
35. A car dealer must pay $20,000 for each car purchased.
The annual holding cost is estimated to be 25% of the
dollar value of inventory. The dealer sells an average
of 500 cars per year. He is willing to backlog some
demand but estimates that if he is short one car for one
year, he will lose $20,000 worth of future profits. Each
time the dealer places an order for cars, the ordering
cost is $10,000. Determine the dealer’s optimal order-
ing policy. What is the maximum shortage that will
occur? Assume it costs $5000 to store a car for a year
(this is in addition to the holding cost above).
36. Reconsider Example 12.1. Each time Machey’s orders
cameras, it incurs a $125 ordering cost. Assume that
Machey’s could make an investment to decrease this
ordering cost. Suppose that any 10% decrease costs a
fixed amount, C dollars. Using i  0.10 and Solver,
experiment with different values of C to see how
Machey’s optimal order quantity is affected. Assume
the minimum possible ordering cost is $35.
37. The particular logarithmic function proposed in
Example 12.4 is just one possibility for the cost of a
setup cost reduction. Referring to the previous prob-
lem, suppose instead that Machey’s has only three
possibilities. The company can either leave the setup
cost as it is, spend C1 dollars to reduce the setup cost
to $100, or spend C2 dollars to reduce it to $75.
Analyze these possibilities for various values of C1
and C2 to see which is optimal in terms of total annual
cost.
38. Chicago Mercy Hospital needs to order drugs that are
used to treat heart attack victims. Annually, 500 units
of drug 1 and 800 units of drug 2 are used. The unit pur-
chasing cost for drug 1 is $150 per unit, and the unit
cost of purchasing drug 2 is $300. It costs $20 to store a
unit of each drug for a year. When only drug 1 is
ordered, an order for drug 1 costs $400. When only
drug 2 is ordered, an order for drug 2 costs $600. If
both drugs are ordered at the same time, the cost of
placing an order is $800. Chicago Mercy’s annual cost
of capital is 18%. Determine a cost-minimizing order-
ing policy.
39. Software EG, a retail company, orders two kinds of
software from TeleHard Software. Annually, Software
EG sells 800 units of product 1 and 400 units of prod-
uct 2. The unit purchasing cost is $30 per unit of prod-
uct 1 and $25 per unit of product 2. It costs $5 to store
a unit of either product for a year. The cost of placing
an order for either product separately or both products
together is $100. Software EG’s annual cost of capital
is 14%. Determine a cost-minimizing ordering policy.
40. Customers at Joe’s Office Supply Store demand an
average of 6000 desks per year. Each time an order is
placed, an ordering cost of $300 is incurred. The
annual holding cost for a single desk is 25% of the
$200 cost of a desk. One week elapses between the
placement of an order and the arrival of the order. In
parts a to d, assume that no shortages are allowed.
a. Each time an order is placed, how many desks
should be ordered?
b. How many orders should be placed each year?
c. Determine the total annual costs (excluding pur-
chasing costs) of meeting the customers’ demands
for desks.
d. If the lead time is five weeks, what is the reorder
point? (One year equals 52 weeks.)
e. How do the answers to parts a and b change if
shortages are allowed and a cost of $80 is incurred
if Joe’s is short one desk for one year?
41. A camera store sells an average of 100 cameras per
month. The cost of holding a camera in inventory for a
year is 30% of the price the camera shop pays for the
camera. It costs $120 each time the camera store
places an order with its supplier. The price charged per
camera depends on the number of cameras ordered, as
specified in the file P12_41.xlsx. Each time the cam-
era store places an order, how many cameras should it
order?
42. A hospital must order the drug Porapill from the man-
ufacturer of the drug. It costs $500 to place an order.
Annual demand for the drug is normally distributed
with mean 10,000 and standard deviation 3000, and
it costs $5 to hold one unit in inventory for one year.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

768
Chapter 12
Inventory Models
(A unit is a standard container for the drug.) Orders
arrive one month after being placed. Assume that all
shortages are backlogged.
a. What (R,Q) policy should the company use if it
wants to meet 95% of all customer demand from
existing inventory?
b. Suppose the company could pay C dollars per year
to decrease its lead time per order from one month
to half a month. What is the most it would be will-
ing to pay to do this (and still have a 95% service
level)?
43. Suppose the annual demand for Soni DVD players at
an appliance store is normally distributed with mean
150 and standard deviation 45. When the store orders
these DVD players from its supplier, it takes an
amount of time L for the order to arrive, where L is
measured as a fraction of a year. In each of the follow-
ing, find the mean LD and the standard deviation LD
of the demand during lead time.
a. Assume that L is known to be 3/52, that is,
three weeks.
b. Assume that L is uncertain, with mean 3/52 and
standard deviation 1/52.
44. In the previous problem, assume that it costs $300 to
place an order. The holding cost per DVD player held
in inventory per year is $15. The cost each time a cus-
tomer orders a DVD player that is not in stock is
estimated at $40. (All demand is backlogged.)
a. Find the optimal ordering policy for parts a and b
of the previous problem (when lead time is known
for certain and when it is not).
b. How much more is the expected annual holding
cost when L is random than when it is known with
certainty? Why is this cost greater in the random
case?
45. How do your answers to part a of the previous prob-
lem change if, instead of incurring a $40 penalty cost
for each shortage, the store has a service level require-
ment of meeting 95% of all customer demands on
time? In each case (L known with certainty and L ran-
dom) what penalty cost p is this service level require-
ment equivalent to?
46. Chicago’s Treadway Tires Dealer must order tires
from its national warehouse. It costs $10,000 to place
an order. Annual tire sales are normally distributed
with mean 20,000 and standard deviation 5000. It
costs $10 per year to hold a tire in inventory, and the
lead time for delivery of an order is normally distrib-
uted with mean three weeks and standard deviation
one week. Assume that all shortages are backlogged.
a. Find the (R,Q) policy the company should use to
meet a service level where 96% of all demand is
met with on-hand inventory.
b. Assume that the company could pay C dollars per
year to decrease the variability in lead times to
essentially 0. That is, the lead time would then be a
certain three weeks. What is the most it would be
willing to pay (and still meet the service level in
part a)?
47. A hospital orders its blood from a regional blood bank.
Each year, the hospital uses an average of 1040 pints
of type O blood. Each order placed with the regional
blood bank incurs a cost of $250. The lead time for
each order is five days. It costs the hospital $20 to hold
one pint of blood in inventory for a year. The stockout
cost per pint is estimated to be $50. Annual demand
for type O blood is normally distributed with standard
deviation 43.26 pints.
a. Determine the optimal order quantity, reorder
point, and safety stock level. Assume that 365 days
equal one year and that all demand is backlogged.
b. What service level requirement (from model 2) is
equivalent to this $50 stockout cost?
48. A firm experiences demand with a mean of 100 units
per day. Lead time demand is normally distributed
with mean 1000 units and standard deviation 200
units. It costs $6 to hold one unit for one year. If the
firm wants to meet 90% of all demand on time, what is
the expected annual cost of holding safety stock?
Assume that each order costs $50.
49. A department store is trying to decide how many JP
Desksquirt II printers to order. Because JP is about to
come out with a new model in a few months, the store
will order only a limited number of model IIs. The
cost per printer is $200, and each printer is sold for
$230. If any model IIs are still in stock when the next
model comes out, they will be sold for $150 apiece. If
a customer wants a model II, and there are none left,
the store will special order the printer at an extra cost
(to the store) of $25. These printers are not in great
demand. The store estimates that the number of model
IIs that will be demanded during the next few months
(before the next model comes out) is equally likely to
be any value from 10 to 20, inclusive. According to
the critical fractile method for a newsvendor model,
how many printers should the store order?
50. Every four years, Blockbuster Publishers revises its
textbooks. It has been three years since the best-selling
book The Joy of Excel has been revised. At present,
2000 copies of the book are in stock, and Blockbuster
must determine how many copies of the book to print
for the next year. The sales department believes that
sales during the next year are governed by a triangular
distribution with parameters 4000, 6000, and 9000.
Each copy of Joy sold during the next year brings the
publisher revenue of $35. Any copies left at the end of
the next year cannot be sold at full price but can be
sold for $5 to a chain of bookstores. The cost of a
printing of the book is $50,000 plus $15 per book
printed.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

12.8 Conclusion
769
a. Use simulation to help the publisher decide how
many copies of Joy to print.
b. How does your answer change if 4000 copies are
currently in stock?
51. Lowland Appliance replenishes its stock of 52-inch
flat-screen TVs three times a year. Each order takes
1/9 of a year to arrive. Annual demand for these TVs
follows a normal distribution with a mean of 990 and
a standard deviation of 40. Assume that the cost of
holding a TV in inventory for a year is $100. Assume
that Lowland begins with 500 of these TVs in inven-
tory, the cost of a shortage is $150, and the cost of
placing an order is $500.
a. Suppose that whenever inventory is reviewed, and
the inventory level is I, an order for 480I of these
TVs is placed. Use simulation to estimate the aver-
age annual cost of this policy. Such a policy is
called an order-up policy.
b. Use simulation to estimate the average annual cost
for order-up policies when Lowland orders up to
200, 400, 600, and 800 of these TVs.
52. Computco sells high-end computer workstations. The
demand for its workstations during a month follows a
normal distribution, with a mean of 400 and standard
deviation of 100. Each time an order is placed, costs of
$600 per order and $1500 per workstation are
incurred. Workstations are sold for $2800, and if
Computco does not have a workstation in stock, the
customer will buy one from a competitor. At the end
of each month, a holding cost of $75 per workstation
is incurred. Orders are placed at the end of each
month, and they arrive at the beginning of the next
month. Four ordering policies are under consideration:
■Policy 1: Place an order for 900 workstations
whenever the end-of-month inventory is 50 or less.
■Policy 2: Place an order for 600 workstations
whenever the end-of-month inventory is 200 or
less.
■Policy 3: Place an order for 1000 workstations
whenever end-of-month inventory is 400 or less.
■Policy 4: Place an order for 1200 workstations
whenever end-of-month inventory is 500 or less.
Using simulation, run 1000 iterations of an appropriate
model to determine which ordering policy maximizes
expected profit for a two-year period. To get a more
accurate idea of expected profit, you can credit
Computco with a salvage value of $1500 for each
workstation left at the end of the last month. Assume
that 400 workstations are in inventory at the beginning
of the first month.
Skill-Extending Problems
53. Based on Ignall and Kolesar (1972). Dominic’s Pizza
Parlor receives 30 calls per hour for delivery of pizza.
It costs Dominic’s $10 to send out a truck to deliver
pizzas. Each minute a customer spends waiting for a
pizza costs the pizza parlor an estimated $0.20 in lost
future business.
a. How often should Dominic’s send out a truck?
b. What would the answer be if a truck could carry
only five pizzas?
54. Suppose that instead of ordering the amount Q speci-
fied by the EOQ formula, the order quantity 0.8Q is
used. Show that the sum of the annual ordering cost
and the annual holding cost increases by 2.5%.
55. In terms of K, D, and h, what is the average length of
time that an item spends in inventory before being used
to meet demand? Explain how this result can be used to
characterize a fast-moving or slow-moving item.
56. A drugstore sells 30 bottles of antibiotics per week.
Each time it orders antibiotics, there is a fixed order-
ing cost of $10 and a cost of $10 per bottle. Assume
that the store’s cost of capital is 10%, there is no stor-
age cost, and antibiotics spoil and cannot be sold if
they spend more than one week in inventory. When the
drugstore places an order, how many bottles of antibi-
otics should it order?
57. During each year, CSL Computer Company needs to
train 27 service representatives. It costs $12,000 to run a
training program, regardless of the number of students
being trained. Service reps earn a monthly salary of
$1500, so CSL does not want to train them before they
are needed. Each training session takes one month.
a. State the assumptions needed for the EOQ model
to be applicable.
b. How many service reps should be in each training
group?
c. How many training programs should CSL under-
take each year?
d. How many trained service reps will be available
when each training program begins?
58. A hospital orders its thermometers from a hospital
supply firm. The cost per thermometer depends on the
order quantity Q, as shown in the file P12_58.xlsx.
The annual holding cost is 25% of the purchasing cost.
Let Q80 be the optimal EOQ order quantity if the cost
per thermometer is $0.80, and let Q79 be defined simi-
larly if the cost per thermometer is $0.79.
a. Explain why Q79 will be larger than Q80.
b. Explain why the optimal order quantity must be
Q79, Q80, or 100.
c. If Q80  100, explain why the optimal order quan-
tity must be Q79.
d. If Q80  100 and Q79  100, explain why the opti-
mal order quantity must be Q80 or 100.
e. If Q80  100 and Q79  100, explain why the opti-
mal order quantity must be Q79.
59. In the previous problem, suppose that the cost per order
is $1, and the monthly demand is 50 thermometers.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

770
Chapter 12
Inventory Models
What is the optimal order quantity? What is the small-
est discount the supplier could offer that would still be
accepted by the hospital?
60. Suppose that instead of measuring shortage in terms 
of cost per shortage per year, a cost of P dollars is
incurred for each unit the firm is short. This cost does
not depend on the length of time before the backlogged
demand is satisfied. Determine a new expression for
the annual shortage cost as a function of Q and b, and
solve GMB’s problem (Example 12.3) with this way of
costing shortages for reasonable values of P. (What
values of P do you think are reasonable?)
61. The penalty cost p used in the shortage model is usu-
ally difficult to estimate. As an alternative, a company
might use a service-level constraint, such as, “95% of
all demand must be met from on-hand inventory.”
Solve Problem 35 with this constraint instead of the
$20,000 penalty cost. Now the problem is to minimize
the total annual ordering and holding costs subject to
meeting the service-level constraint.
62. A newspaper has 500,000 subscribers who pay $4 per
month for the paper. It costs the company $200,000 to
bill all its customers. Assume that the company can
earn interest at a rate of 20% per year on all revenues.
Determine how often the newspaper should bill its
customers. (Hint: Consider unpaid subscriptions as the
inventoried good.)
63. A firm knows that the price of the product it is order-
ing is going to increase permanently by X dollars. It
wants to know how much of the product it should
order before the price increase goes into effect. Here is
one approach to this problem. Suppose the firm places
one order for Q units before the price increase goes
into effect.
a. What extra holding cost is incurred by ordering Q
units now?
b. How much in purchasing costs is saved by ordering
Q units now?
c. What value of Q maximizes purchasing cost sav-
ings less extra holding costs?
d. Suppose that the annual demand is 1000 units, the
holding cost per unit per year is $7.50, and the
price of the item is going to increase by $10. How
large an order should the firm place before the
price increase goes into effect?
64. Based on Riccio et al. (1986). The borough of Staten
Island has two sanitation districts. In district 1, street
litter piles up at an average rate of 2000 tons per week,
and in district 2, it piles up at an average rate of 1000
tons per week. Each district has 500 miles of streets.
Staten Island has 10 sanitation crews and each crew
can clean 50 miles per week of streets. To minimize
the average level of the total amount of street litter in
the two districts, how often should each district be
cleaned? Assume that litter in a district grows at a
constant rate until it is picked up, and assume that
pickup is instantaneous. (Hint: Let pi equal the aver-
age number of times that district i is cleaned per week.
Then p1  p2  1.)
65. A company inventories two items. The relevant data
are shown in the file P12_65.xlsx. Determine the opti-
mal inventory policy if no shortages are allowed and if
the average investment in inventory is not allowed to
exceed $700. If this constraint could be relaxed by $1,
by how much would the company’s annual costs
decrease?
66. An exchange curve can be used to display the trade-
offs between the average investment in inventory and
the annual ordering cost. To illustrate the usefulness of
a trade-off curve, suppose that a company must order
two products with the attributes shown in the file
P12_66.xlsx.
a. Draw a curve that displays annual order cost on the
horizontal axis and average inventory investment
on the vertical axis.
b. Currently, the firm orders each product 10 times
per year. Demonstrate that this is a suboptimal
ordering policy.
c. Suppose management limits the company’s average
inventory investment to $10,000. Use the exchange
curve to determine the best ordering policy.
67. A company currently has two warehouses. Each ware-
house services half the company’s demand, and the
annual demand serviced by each warehouse is nor-
mally distributed with mean 10,000 and standard devi-
ation 1000. The lead time for meeting demand is 1/10
year. The company wants to meet 95% of all demand
on time. Assume that each warehouse uses the EOQ
formula to determine its order quantity and that this
leads to Q  2000 for each warehouse.
a. How much safety stock must be held at each
warehouse?
b. Show that if the company had only one warehouse,
it would hold less safety stock than it does when it
has two warehouses.
c. A young MBA argues, “By having one central
warehouse, I can reduce the total amount of safety
stock needed to meet 95% of all customer demands
on time. Therefore, we can save money by having
only one central warehouse instead of several
branch warehouses.” How might this argument be
rebutted?
68. In most of the Walton Bookstore examples in
Chapter 10, we assumed that there was a single prod-
uct. Suppose instead that a company sells two com-
peting products. Sales of either product tend to take
away sales from the other product. That is, the
demands for the two products are negatively corre-
lated. The company first places an order for each
product. Then during a period of time, there is
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

12.8 Conclusion
771
demand D1 for product 1 and demand D2 for product 2.
These demands are normally distributed with means
1000 and 1200 and standard deviations 250 and 350.
The correlation between D1 and D2 is r, where r is a
negative number between 1 and 0. The unit cost of
each product is $7.50, the unit price for each product
is $10, and the unit refund for any unit of either
product not sold is $2.50. The company must decide
how many units of each product to order. Use
@RISK to help the company by experimenting
with different order quantities. Try this for r 0.3,
r  0.5, and r 0.7. What recommendation can
you give about the “best” order quantities as the
demands become more highly correlated (in a
negative direction)?
69. Work the previous problem when the demands are
positively correlated, as they might be with products
such as peanut butter and jelly. Now use r  0.3,
r  0.5, and r  0.7 in your simulations.
70. A highly perishable drug spoils after three days. A
hospital estimates that it is equally likely to need
between one and nine units of the drug daily. Each
time an order for the drug is placed, a fixed cost of
$200 is incurred as well as a purchase cost of $50 per
unit. Orders are placed at the end of each day and
arrive at the beginning of the following day. It costs no
money to hold the drug in inventory, but a cost of $100
is incurred each time the hospital needs a unit of the
drug and does not have any available. The following
three policies are under consideration:
■
If the day’s ending inventory is less than 5 units,
order enough to bring the next day’s beginning
inventory up to 10 units.
■
If the day’s ending inventory is less than 3 units,
order enough to bring the next day’s beginning
inventory up to 7 units.
■
If the day’s ending inventory is less than 8 units,
order enough to bring the next day’s beginning
inventory up to 15 units.
Use simulation to compare these policies with regard
to expected daily costs, expected number of units short
per day, and expected number of units spoiling each
day. Assume that the hospital begins day 1 with five
new units of the drug on hand. (Hint: You will need to
keep track of the age distribution of the units on hand
at the beginning of each day. Assume that the hospital
uses a FIFO [first in, first out] inventory policy. The
trick is to get formulas that relate the age of each unit
of the drug you have at the beginning of the day to the
age of each unit you have at the end of the day.)
Modeling Problems
71. A trucking firm must decide at the beginning of the
year on the size of its trucking fleet. If on a given day
the firm does not have enough trucks, the firm will
have to rent trucks from a rental company. Discuss
how you would determine the optimal size of the
trucking fleet?
72. A computer manufacturer produces computers for 40
different stores. To monitor its inventory policies, the
manufacturer needs to estimate the mean and stan-
dard deviation of its weekly demand. How might it
do this?
73. Based on Brout (1981). Planner’s Peanuts sells 100
products. The company has been disappointed with the
high level of inventory it keeps of each product and its
low service level (percentage of demand met on time).
Describe how you would help Planner’s improve its
performance on both these objectives. Pay close atten-
tion to the data you would need to collect and how the
data would be used.
74. Austin (1977) conducted an extensive inventory analy-
sis for the United States Air Force. He found that for
over 250,000 items the annual holding cost was
assumed to equal 32% of the item’s purchase price. He
also found that when an order was placed for most
items, a fixed cost of over $200 was incurred. The Air
Force held one month of safety stock for each item.
Given this limited information, discuss how the Air
Force could improve its inventory policies. (Hopefully,
it has done so since the study was performed.)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

C A S E
R
iders of the subway system in the city of Metropo-
lis must pay for the ride by purchasing a token.
The same token can also be used to ride the buses in
Metropolis. A single token is good for a trip to any
destination served by the system. (Tokens are also
used by millions of commuters for bridge, tunnel, and
highway tolls in many areas of the country.)
Late in 2010, Metropolis transit officials
announced that they were seeking a fare increase
from $1.50 to $2.00. Later negotiations with politi-
cians in the state capital reduced the requested
increase to $1.75. It usually takes a few weeks
between the announcement of a fare increase and the
time that the increase goes into effect. Knowing that
an increase will occur gives users of mass transit an
opportunity to mitigate the effect of the increase by
hoarding tokens—that is, by purchasing a large supply
of tokens before the fare increase goes into effect.
There is a clear motivation for hoarding
tokens–namely, the purchase of tokens before a fare
increase offers a savings over purchasing the same
tokens at a higher price after the change in fare.Why
wouldn’t riders want to purchase a very large supply
of tokens? The reason is the inventory cost that
arises because of the time value of money.10 The
larger the supply that is hoarded, the longer the time
until the tokens are used. Purchasing the supply of
tokens represents an immediate cost, but the benefit
is only realized over a longer period of time.
Thus, there is a trade-off between the immediate
cost and the prolonged benefit.The optimal number
of tokens to hoard balances these two effects to
maximize the present value of the net benefit of the
hoarding strategy.
Suppose that the current price of subway tokens
is p1  $1.50 and the fare is due to rise to p2 
$1.75. Suppose that you use the subway to commute
2 times per day, 5 days per week, 50 weeks per year.
Also, suppose that you can purchase (or hoard) any
number of tokens before the price increase takes
effect.You will use the hoarded tokens during your
normal usage of the mass transit system.After your
hoard runs out, you will start purchasing tokens each
day at the higher price. Suppose that your cost of
capital is 15% per year. This means that you can bor-
row money to purchase your token supply, but the
interest cost on the borrowed money is 15% per
year.11
Questions
1.
What is the optimal number of tokens to hoard?
2.
What is the present value of the savings over
not hoarding at all?
3.
Suppose that the optimal quantity to hoard is Q.
What is the present value of the savings if you
decide to hoard only 0.8Q? ■
12.1 SUBWAY TOKEN HOARDING
11Using 250 commuting days per year, you can assume that the
daily interest cost is 0.05592% (1.15(1/250)1).
10We are assuming that the hoarded tokens will be used by the
hoarder for rides on the mass transit system, not for the immediate
sale to other riders. In fact, such sales are illegal in Metropolis.
772
Chapter 12
Inventory Models
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

C H A P T E R
13
Queueing Models
REDUCING WORK-IN-PROGRES S LEVEL S AT
WOODWARD AIRCRAFT ENGINE SY         STEMS
T
he previous chapter was all about inventory management, where
companies try to achieve the correct balance between holding too much
inventory and not holding enough inventory to meet demands. A type of
inventory that is particularly important in the manufacturing industry is
called work-in-process (WIP) inventory. As its name implies, this is inventory
that is partway through the manufacturing process and is not yet a ﬁnished
good. Manufacturing companies try to keep WIP low, for reasons of space
and ﬁnancial concerns, but they need a certain amount of WIP to keep their
processes running smoothly. Srinivasan et al. (2003) discuss a study they per-
formed at Woodward Aircraft Engine Systems to achieve appropriate levels
of WIP. Woodward is a leading producer of fuel-control systems and com-
ponents for aircraft and industrial engines and turbines. With headquarters
in Fort Collins, Colorado, Woodward serves a global market and has about
5500 employees. Their Rockford, Illinois, plant manufactures a large variety
of products at low volumes, some as low as 100 per year. As these products
are manufactured, they ﬂow through cells, groups of machines that perform
similar operations, and the various products require different routings
through these cells depending on their speciﬁcations. The company knows
(or forecasts) its demands for the various products, so it knows how many
of each product it needs to manufacture per time period, the throughput, to
meet demands. The problem is to determine the amount of WIP required to
achieve the desired throughputs.
Tonis Valing/Used under license from Shutterstock.com 
773
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

774
Chapter 13
Queueing Models
The authors model the manufacturing system as a closed queueing network (CQN).
A queueing network is a sequence of cells or machines that partially completed products
must pass through as they are being manufactured into ﬁnished products. Products
typically form a queue in front of the machines on their routings, and congestion is very
possible, especially when certain machines are bottlenecks. A closed queueing network
means that there are a constant number of partially completed products of a given type in
the network at all times.This type of model is often used when a new product of a given
type is introduced into the network as soon as a part of that type ﬁnishes and leaves the
network. Researchers have done much analytical work in the area of queueing networks,
and various approximations exist for calculating performance measures of CQNs.
At Woodward, there are essentially two decision variables for any given product
type. The ﬁrst is the batch size, the number of parts on a pallet. A given batch goes
through the manufacturing process, that is, through its routing of cells and machines, as a
unit. At any machine along the route, there can be a setup time and a processing time
per unit. Therefore, larger batch sizes are sometimes beneﬁcial for reducing setups. The
second decision variable is the number of batches in the system at any point in time.
Because the overall system is modeled as a CQN, this number of batches (for any given
product type) is constant. Together, these two decision variables determine the amount
of WIP in the system at all times. The problem is to adjust these two decision variables,
for all product types, so that the throughputs of all products match the demands for
them as closely as possible. The authors developed an approximate algorithm, using
results from the vast queueing literature, to do this. Then they implemented this algo-
rithm in Excel with a user-friendly interface so that Woodward employees could use it
easily to answer various what-if questions.
Although the details of the algorithm are quite complex, they rely on a very basic
formula, called Little’s formula, which is discussed in this chapter. Little’s formula states
that the expected number of parts in a system is equal to the arrival rate of parts to the
system multiplied by the average time a part spends in the system. Little’s formula can be
applied in an amazing variety of situations; the only trick is to see how it applies. In
Woodward’s situation, the number of parts in the system is ﬁxed because of the CQN
assumption; it is the number of pallets of a given product type in the system at all times.
The arrival rate of parts to the system is the throughput of a given product type. The
reasoning is that the rate at which products leave the system, the throughput rate, must
equal the rate at which new products of this type enter the system. Finally, the average
time a part spends in the system is known in manufacturing as the cycle time: the time it
takes to manufacture a typical product. So Little’s law relates cycle time to throughput
and the number of pallets to use.
The authors’ algorithm and spreadsheet implementation have helped Woodward
immensely by enabling the company to reduce its WIP inventory from about three
weeks of inventory to less than one week of inventory. As Director of Manufacturing,
Steven J. Ebbing, states, “The spreadsheet software tool presented in this paper has
enabled a smooth ﬂow of products through the various operations in the cells at
Woodward, with signiﬁcant reduction in WIP levels. The what-if analysis is invaluable for
setting WIP levels for different products as well as for individual machines.” ■
13.1 INTRODUCTION
A basic fact of life is that we all spend a great deal of time waiting in lines (queues). We
wait in line at a bank, at a supermarket, at a fast-food restaurant, at a stoplight, and so on.
Actually, people are not the only entities that wait in queues. Televisions at a television
repair shop, other than the one(s) being repaired, are essentially waiting in line to be
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

repaired. Also, when messages are sent through a computer network, they often must wait
in a queue before being processed.
Mathematically, it does not really matter whether the entities waiting are people or
televisions or computer messages. The same type of analysis applies to all of these. The
purpose of such an analysis is generally twofold. The ﬁrst objective is to examine an exist-
ing system to quantify its operating characteristics. For example, if a fast-food restaurant
currently employs 12 people in various jobs, the manager might be interested in determin-
ing the amount of time a typical customer must wait in line or how many customers are
typically waiting in line. The second objective is to learn how to make a system better. The
manager might ﬁnd, for example, that the fast-food restaurant would do better, from an
economic standpoint, by employing only 10 workers and deploying them in a different
manner.
The ﬁrst objective, analyzing the characteristics of a given system, is difﬁcult from a
mathematical point of view. The two basic modeling approaches are analytical and
simulation. The analytical approach searches for mathematical formulas that describe the
operating characteristics of the system, usually in “steady state.” The mathematical mod-
els are typically too complex to solve unless simplifying (and sometimes unrealistic)
assumptions are made. For example, at a supermarket, customers typically join one of
several lines (probably the shortest), possibly switch lines if they see that another line is
moving faster, and eventually get served by one of the checkout people. Although this
behavior is common—and is simple to describe in words—it is very difﬁcult to analyze
analytically.
With the second approach, simulation, much more complex systems can be analyzed
without making many simplifying assumptions. However, the drawback to queueing simu-
lation is that it usually requires specialized software packages or trained computer pro-
grammers to implement.
In this chapter, we employ both the analytical approach and simulation. For the for-
mer, we discuss several well-known queueing models that describe some—but certainly
not all—queueing situations in the real world. These models illustrate how to calculate
such operating characteristics as the average waiting time per customer, the average num-
ber of customers in line, and the fraction of time servers are busy. These analytical models
generally require simplifying assumptions, and even then they can be difﬁcult to under-
stand. Therefore, we also discuss queueing simulations. Unfortunately, queueing simula-
tions are not nearly as straightforward as the simulations discussed in previous chapters. It
is necessary to generate random times between customer arrivals and random service times
and then “play out” the events. This playing out of events is far from easy in a spreadsheet.
We provide only a taste of what can be done—and show why commercial software pack-
ages are usually used instead of spreadsheets.
The second objective in many queueing studies is optimization, where the goal is to
ﬁnd the “best” system. Of course, to ﬁnd the best system, each of several competing sys-
tems must be analyzed, either analytically or by simulation. But beyond this, difﬁcult
choices must be made. For example, if the fast-food restaurant wants to decide how many
employees to hire for various times of day, it must analyze the trade-off between more
employees (better service, higher wages) and fewer employees (worse service, lower
wages). The cost of extra employees is fairly easy to quantify—the marginal cost of one
extra employee is the wage rate. However, estimating the “cost” of making a customer wait
an extra two minutes in line, for instance, is difﬁcult. In terms of immediate out-of-pocket
costs, it costs the restaurant nothing. However, it can have long-range implications: fewer
customers will bring their business to this restaurant. To ﬁnd the optimal number of
employees, the restaurant must estimate the dollar cost of having customers wait in line.
Only by estimating this cost can it make an economic choice between the cost of waiting
and the cost of more efﬁcient service.
13.1 Introduction
775
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

The examples in this chapter highlight these two objectives. We show how to ﬁnd
important characteristics, such as expected waiting times, of speciﬁc systems, and (to a
lesser extent) we illustrate how to search for economically optimal systems.
This chapter is very different from earlier chapters because of the nature of queueing
systems. The models in previous chapters could almost always be developed from “ﬁrst
principles.” By using relatively simple formulas involving functions such as SUM,
SUMPRODUCT, IF, and so on, it was fairly straightforward to convert inputs into outputs.
This is no longer possible with queueing models. The inputs are typically mean customer
arrival rates and mean service times. The required outputs are typically mean waiting times
in queues, mean queue lengths, the fraction of time servers are busy, and possibly others.
Deriving the formulas that relate the inputs to the outputs is mathematically very difﬁcult,
well beyond the level of this book. Therefore, many times in this chapter you will have to
take our word for it. Nevertheless, the models we illustrate are very valuable for the impor-
tant insights they provide.
776
Chapter 13
Queueing Models
13.2 ELEMENTS OF QUEUEING MODELS
We begin by listing some of the features of queueing systems that distinguish one system
from another. Almost all queueing systems are alike in that customers enter a system, pos-
sibly wait in one or more queues, get served, and then depart.1 This general description of
a queueing system—customers entering, waiting in line, and being served—hardly sug-
gests the variety of queueing systems that exist. We now discuss some of the key features
and their variations.
Characteristics of Arrivals
First, the customer arrival process must be speciﬁed. This includes the timing of arrivals as
well as the types of arrivals. Regarding timing, specifying the probability distribution of
interarrival times, the times between successive customer arrivals, is most common.
These interarrival times might be known—that is, nonrandom. For example, the arrivals at
some doctors’ ofﬁces are scheduled fairly precisely. Much more commonly, however,
interarrival times are random with a probability distribution. In real applications, this prob-
ability distribution must be estimated from observed customer arrival times. Also, this dis-
tribution can vary through time. For example, the rate of arrivals to McDonald’s is
certainly higher around noon than in the middle of the afternoon.
Regarding the types of arrivals, there are at least two issues. First, customers can
arrive one at a time or in batches—carloads, for example. The simplest system is when
customers arrive one at a time, an assumption made in all of the models in this chapter.
Second, customers can all be essentially alike, or they can be separated into priority
classes. At a computer center, for example, certain jobs might receive higher priority
and run ﬁrst, whereas the lower-priority jobs might be sent to the back of the line and
run only after midnight. Throughout this chapter, all customers are assumed to have the
same priority.
Another issue is whether (or how long) customers will wait in line. A customer might
arrive to the system, see that too many customers are waiting in line, and decide not to
The formulas that
relate queueing inputs
to queueing outputs
are difficult to derive
mathematically.A few
of these formulas are
presented, but they are
not derived.
Interarrival times are
the times between
successive customer
arrivals.
We assume customers
arrive one at a time
and all have the same
priority.
1From here on, we refer to the entities requesting service as customers, regardless of whether they are actually
people. Also, we refer to servers performing service on these customers, regardless of the type of work being per-
formed and whether the servers are people, machines, or other types of technology.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

enter the system at all. This is called balking. A variation of balking occurs when the
choice is made by the system, not the customer. In this case, we assume there is a waiting
room size so that if the number of customers in the system equals the waiting room size,
newly arriving customers are not allowed to enter the system. We call this a limited waiting
room system. Another type of behavior, called reneging, occurs when a customer already
in line becomes impatient and leaves the system before starting service. Systems with
balking and reneging are difﬁcult to analyze, so no such systems are considered in this
chapter. However, we do discuss limited waiting room systems.
Service Discipline
When customers enter the system, they might have to wait in line until a server becomes
available. In this case, the service discipline must be speciﬁed. The service discipline is the
rule that states which customer, from all who are waiting, goes into service next. The most
common service discipline is ﬁrst-come-ﬁrst-served (FCFS), where customers are served
in the order of their arrival. All of the models in this chapter use the FCFS discipline.
However, other service disciplines are possible, including service-in-random-order (SRO),
last-come-ﬁrst-served (LCFS), and various priority disciplines (if there are customer
classes with different priorities). For example, a type of priority discipline used in some
manufacturing plants is called the shortest-processing-time (SPT) discipline. In this case,
the jobs that are waiting to be processed are ranked according to their eventual processing
(service) times, which are assumed to be known. Then the job with the shortest processing
time is processed next.
One other aspect of the waiting process is whether there is a single line or multiple
lines. For example, most banks now have a single line. An arriving customer joins the end
of the line. When any teller ﬁnishes service, the customer at the head of the line goes to
that teller. In contrast, most supermarkets have multiple lines. When a customer goes to a
checkout counter, she must choose which of several lines to enter. Presumably, she will
choose the shortest line, but she might use other criteria in her decision. After she joins a
line, she might decide to move to another line that seems to be moving faster.
Service Characteristics
In the simplest systems, each customer is served by exactly one server, even when the
system contains multiple servers. For example, when you enter a bank, you are eventually
served by a single teller, even though several tellers are working. The service times
typically vary in some random manner, although constant (nonrandom) service times are
sometimes possible. When service times are random, the probability distribution of a typi-
cal service time must be speciﬁed. This probability distribution can be the same for all cus-
tomers and servers, or it can depend on the server and/or the customer. As with interarrival
times, service time distributions must typically be estimated from service time data in real
applications.
In a situation like the typical bank, where customers join a single line and are then
served by the ﬁrst available teller, the servers (tellers) are said to be in parallel (see
Figure 13.1). A different type of service process is found in many manufacturing settings.
For example, various types of parts (the “customers”) enter a system with several types of
machines (the “servers”). Each part type then follows a certain machine routing, such as
machine 1, then machine 4, and then machine 2. Each machine has its own service time
distribution, and a typical part might have to wait in line behind any or all of the machines
on its routing. This type of system is called a queueing network. The simplest type of
queueing network is a series system, where all parts go through the machines in numerical
13.2 Elements of Queueing Models
777
We always assume a
FCFS discipline.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

order: ﬁrst machine 1, then machine 2, then machine 3, and so on (see Figure 13.2). We
examine mostly parallel systems in this chapter. However, we discuss the simulation of a
series system toward the end of the chapter.
778
Chapter 13
Queueing Models
Customers in line
Servers
Figure 13.1
Queueing System
with Servers in
Parallel
Customers waiting in line
Servers
Figure 13.2
Queueing System
with Servers in
Series
Short-Run versus Steady-State Behavior
If you run a fast-food restaurant, you are particularly interested in the queueing behavior
during your peak lunchtime period. The customer arrival rate during this period increases
sharply, and you probably employ more workers to meet the increased customer load. In
this case, your primary interest is in the short-run behavior of the system—the next hour or
two. Unfortunately, short-run behavior is the most difﬁcult to analyze, at least with analyti-
cal models. Although we show in section 13.6 that short-run behavior can be approxi-
mated analytically, analysts usually resort to simulation to understand what happens in the
short run.
But where is the line drawn between the short run and the long run? The answer
depends on how long the effects of initial conditions persist. In the restaurant example, the
initial conditions are determined by the number of customers already in line at the begin-
ning of the lunch period—say, at 11:30. Suppose the restaurant manager is interested in the
average number of customers waiting in line over a two-hour peak period. The question
then is how much this average is affected by the number of customers in line at 11:30.
Speciﬁcally, do the effects of the initial conditions get washed out in a period as long as
two hours?
Ultimately, the only way to answer this question is with empirical evidence. A lunch
period starting with no people in line at 11:30 might be compared to one where 10 people
are already in line at 11:30. If the average levels of congestion over the entire two-hour
lunch period are approximately the same in each case, then the initial conditions at 11:30
evidently make little difference, and a long-run analysis is permitted. However, if the lunch
period that starts with many people in line is never able to overcome this initial load—that
is, it tends to stay crowded—then the initial conditions are important, and a short-run
analysis is required.
Analytical models are best suited for studying long-run behavior. This type of analysis
is called steady-state analysis and is the focus of much of the chapter. One requirement
for steady-state analysis is that the parameters of the system remain constant for the entire
time period. In particular, the arrival rate must remain constant. In the restaurant example,
Steady-state analysis is
relevant for the long
run, but the “long run”
can sometimes be as
short as an hour or
two.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

if the objective is to study a two-hour peak lunchtime period where the arrival rate is
signiﬁcantly larger than normal, and if steady-state analysis is used, then the results of this
two-hour analysis do not apply to the rest of the day, when the arrival rate is much lower. If
the parameters of the system change from one time period to another, a separate steady-
state analysis is required for each time period. Alternatively, simulation can be used, where
constant parameters such as the arrival rate are not required.
Another requirement for steady-state analysis is that the system must be stable. This
means that the servers must serve fast enough to keep up with arrivals—otherwise, the
queue can theoretically grow without limit. For example, in a single-server system where
all arriving customers join the system, the requirement for system stability is that the
arrival rate must be less than the service rate. If the system is not stable, the analytical mod-
els discussed in this chapter cannot be used. Again, however, simulation can be used,
which does not require system stability.
13.3 The Exponential Distribution
779
Unless a system is
stable, queue lengths
will eventually increase
without bound.
FUNDAMENTAL INSIGHT
The Limitations of Steady-State Results
Most queueing results (other than those from simula-
tion) are for steady state.These are based on rather
restrictive assumptions, such as a constant ar
rival
rate and a constant ser vice rate. Such results are at
best a pproximate if shor t-run r esults ar e r equired
(how busy will a stor e be in the next hour) and the
parameters ar e changing thr ough time (the ar rival
rate is much lower in midmorning than at noon, say).
The problem with steady-state results is that they are
relevant onl y when the eff ects of initial conditions
have been washed out by the passage of time,and this
can take awhile. Fortunately, short-run results can be
found, either from an approximation such as the one
in section 13.6 or from simulation.
13.3 THE EXPONENTIAL DISTRIBUTION
Queueing systems generally contain uncertainty. Speciﬁcally, times between customer
arrivals (interarrival times) and customer service times are generally modeled as random
variables. The most common probability distribution used to model these uncertain quan-
tities is the exponential distribution. Many queueing models can be analyzed in a fairly
straightforward manner, even on a spreadsheet, if exponentially distributed interarrival
times and service times are assumed. This exponential assumption provides a lot in terms
of simpliﬁed analysis, but it is very strong. Therefore, understanding the exponential
distribution and some of its ramiﬁcations for queueing applications is important.
A random variable X has an exponential distribution with parameter  (with   0) if
the density function for X has the form
f(x)  ex
for x  0
( is the Greek letter lambda. Its use is standard in the queueing literature.) The graph of
this function appears in Figure 13.3. (We obtained this graph from @RISK, as discussed in
Chapter 10.) In contrast to the normal distribution, the exponential distribution is not bell-
shaped, and it is heavily skewed to the right. Because this density decreases continually
from left to right, its most likely value is at 0. This means that X is more likely to be near 0
than any other value. Equivalently, if you collect many observations from an exponential
distribution and draw a histogram of the observed values, you should expect it to resemble
the smooth curve in Figure 13.3, with the tallest bars to the left.
The mean and standard deviation of this distribution are easy to remember. They are
both equal to the reciprocal of the parameter . For example, an exponential distribution
with parameter   0.1 has both mean and standard deviation equal to 10.
The mean and
standard deviation of
an exponential
distribution are both
equal to the reciprocal
of the parameter .
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

The random variable X is always expressed in some time unit, such as minutes. For
example, X might be the number of minutes it takes to serve a customer. Now, suppose that
the mean service time is three minutes. Then 1  3, so that   13. For this reason, 
can be interpreted as a rate—in this case, one customer every three minutes (on average).
Of course, the value of  depends on the unit of time. For example, if the unit of time
is switched from minutes to hours,  changes from 13 (one every three minutes) to
60(13)  20 (20 every hour). The corresponding mean is then 1  120 hour.
The Memoryless Property
The property that makes the exponential distribution so useful in queueing models (and in
many other management science models) is called the memoryless property, which can
be stated as follows. Let x and h be any positive numbers that represent amounts of time.
Then if X is exponentially distributed, the following equation holds:
P(X  x  h  X  x)  P(X  h)
(13.1)
The probability on the left is a conditional probability, the probability that X is greater than
x  h, given that it is greater than x. The memoryless property states that this conditional
probability is the same as the unconditional probability that X is greater than h. This impor-
tant property can be interpreted in several contexts.
First, suppose that X is the time, measured in hours, until failure of some item such as
a light bulb. Now consider two light bulbs with the same exponential distribution of time to
failure. The only difference is that the ﬁrst light bulb has already survived x  20 hours,
whereas the second light bulb is brand new. Suppose you want the probabilities that light
bulbs 1 and 2 will survive at least h  5 additional hours. The memoryless property says
that these probabilities are the same for the two light bulbs. In other words, the light bulb
that has been in use for 20 hours has the same chance of surviving at least 5 more hours
as the brand new light bulb. For this reason, the memoryless property is sometimes called
the no wear-out property.
As a second example, suppose that X is the time, measured in minutes, until the next
customer arrival. Suppose it is currently 3:00 P.M., and the previous arrival occurred at
2:57 P.M. Then X is certainly greater than three minutes. Given this information, what is the
probability that the next arrival will occur after 3:05 P.M.? (Here x  3 and h  5, measured
780
Chapter 13
Queueing Models
Figure 13.3
Typical Exponential
Distribution
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

in minutes.) This is the same as the probability that the next arrival would occur after
3:05 P.M. if there were an arrival right now, at 3:00 P.M. That is, as far as the future (after
3:00 P.M.) is concerned, you can forget how long it has been since the last arrival and
assume that an arrival just occurred, at 3:00 P.M. This example illustrates why the property
is called the memoryless property.
These examples indicate why the exponential distribution is attractive from a mathe-
matical point of view. If a process is observed at any time, all exponential times (interar-
rival times and service times, say) essentially “start over” probabilistically—you do not
have to know how long it has been since various events (the last arrival or the beginning of
service) occurred. The exponential distribution is the only continuous probability distribu-
tion with this property. On the negative side, however, this strong memoryless property
makes the exponential distribution inappropriate for many real applications. In the light
bulb example, you might dismiss the exponential assumption immediately on the grounds
that light bulbs do wear out—a light bulb that has been in continuous use for 20 hours 
is not as good as a brand new one. Nevertheless, the ultimate test of appropriateness 
is whether sample data ﬁt an exponential curve. We illustrate how to check this in the
following example.
13.3 The Exponential Distribution
781
E X A M P L E
13.1 ESTIMATING INTERARRIVAL AND SERVICE TIME DISTRIBUTIONS AT A BANK
A
bank manager would like to use an analytical queueing model to study the congestion
at the bank’s automatic teller machines (ATMs). A simple model of this system
requires that the interarrival times (times between customer arrivals to the machines) and
service times (times customers spend with the machines) are exponentially distributed.
During a period of time when business is fairly steady, several employees gather data on
interarrival times and service times. The data are listed in Figure 13.4 (with several rows
hidden). The bank manager wants to know, based on these data, whether it is reasonable to
assume exponentially distributed interarrival times and service times. In each case, the
manager also wants to know the appropriate value of .
Objective
To test the appropriateness of the exponential distribution for interarrival time
and service time data at ATMs.
WHERE DO THE NUMBERS COME FROM?
The bank might have some type of electronic tracking device to measure interarrival times
and service time. Otherwise, it can have employees collect the data with stopwatches.
Solution
To see whether these times are consistent with the exponential distribution, you can create
histograms of the interarrival times and the service times. (See the ﬁle Exponential
Fit.xlsx.) The histograms appear in Figures 13.5 and 13.6. The histogram of interarrival
times appears to be consistent with the exponential density in Figure 13.3. Its highest bar is
at the left, and the remaining bars fall off gradually from left to right. On the other hand,
the histogram of the service times is not shaped like the exponential density. Its highest bar
is not the one farthest to the left but instead corresponds to the second category.
Considering the way automatic teller machines operate, this is not surprising. Some mini-
mum time is required to process any customer, regardless of the task, so that the most
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

782
Chapter 13
Queueing Models
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
101
102
103
104
105
106
107
108
109
A
B
C
D
Interarrival mes and service mes at a bank (in seconds)
Averages of data below
Interarrival Time
Service Time
25.3
22.3
Customer
Interarrival Time
Service Time
1
8
11
2
33
20
3
9
16
4
11
8
5
5
12
6
24
17
7
4
41
8
46
7
9
25
19
10
10
43
94
3
11
95
14
16
96
17
30
97
17
24
98
3
31
99
42
59
100
112
22
101
17
40
102
5
11
Figure 13.4
Interarrival and
Service Times for 
the ATM Example
50
60
70
Histogram of Interarrival Time
0
10
20
30
40
0.00
20.00
40.00
60.00
80.00
100.00
120.00
140.00
160.00
Frequency
Figure 13.5
Histogram of Interarrival Times for the ATM Example
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

likely times are not close to 0. Therefore, the exponential assumption for interarrival times
is reasonable, but it is questionable for service times.2
In either case, if the manager decides to accept the exponential assumption, the
parameter  is the rate of arrivals (or services) and is estimated by the reciprocal of
the average of the observed times. For interarrival times, this estimate of  is the reciprocal
of the average in cell B5 of Figure 13.4: 125.3  0.0395—that is, one arrival every
25.3 seconds. For service times, the estimated  is the reciprocal of the average in cell 
C5: 122.3  0.0448—that is, one service every 22.3 seconds.
■
The Poisson Process Model
When the interarrival times are exponentially distributed, we often state that “arrivals
occur according to a Poisson process.” There is a close relationship between the exponen-
tial distribution, which measures times between events such as arrivals, and the Poisson
distribution, which counts the number of events in a certain length of time. The details of
this relationship are beyond the level of this book, so we do not explore this topic any fur-
ther here. However, if customers arrive at a bank according to a Poisson process with rate
one every three minutes, this implies that the interarrival times are exponentially distrib-
uted with parameter   13.
13.3 The Exponential Distribution
783
Exponentially
distributed interarrival
times are often more
realistic than
exponentially
distributed service
times.
25
30
35
40
Histogram of Service Time
0
5
10
15
20
25
0.00
10.00
20.00
30.00
40.00
50.00
60.00
70.00
Frequency
Figure 13.6
Histogram of Service Times for the ATM Example
2There are formal statistical procedures for testing whether an exponential ﬁt is reasonable, but this “eye-balling”
method often sufﬁces.
If arrivals occur
according to a Poisson
process, this implies
that the interarrival
times are exponentially
distributed.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

784
Chapter 13
Queueing Models
P R O B L E M S
Solutions for problems whose numbers appear within a
colored box can be found in the Student Solutions Files.
Refer to this book’s preface for purchase information.
Skill-Building Problems
1.
An extremely important concept in queueing models is
the difference between rates and times. If  represents
a rate (customers per hour, say), then argue why 1 is
a time and vice versa.
2.
Explain the basic relationship between the exponential
distribution and a Poisson process. Also, explain how
the exponential distribution and the Poisson distribu-
tion are fundamentally different. (Hint: What type of
data does each describe?)
3.
You can easily generate random numbers in a spread-
sheet that have an exponential distribution with a given
mean. For example, to generate 200 such numbers
from an exponential distribution with   13, enter
the formula 3*LN(RAND()) in cell A4 and copy it
to the range A5:A203. Then select the A4:A203 range,
choose the Copy command, and choose the Paste
Special command with the Values option. (This
freezes the random numbers, so that they don’t change
each time the spreadsheet recalculates.) Explore the
properties of these numbers as follows.
a. Find the average of the 200 numbers with the
AVERAGE function. What theoretical value should
this average be close to?
b. Find the standard deviation of the 200 numbers
with the STDEV function. What theoretical value
should this standard deviation be close to?
c. Create a histogram of the random numbers,
using about 15 categories, each of length 1,
where the ﬁrst category extends from 0 to 1.
Does the histogram have the shape you would
expect?
d. Suppose you collected the data in column A by
timing arrivals at a store. The value in cell A4 is the
time (in minutes) until the ﬁrst arrival, the value in
cell A5 is the time between the ﬁrst and second
arrivals, the value in cell A6 is the time between the
second and third arrivals, and so on. How might you
convince yourself that the interarrival times for this
store are indeed exponentially distributed? What is
your best guess for the arrival rate (customers per
minute)?
Skill-Extending Problem
4.
Do exponentially distributed random numbers have
the memoryless property? Here is one way to ﬁnd out.
Generate many exponentially distributed random
numbers with mean 3, using the formula in the previous
problem. Find the fraction of them that are greater
than 1. This estimates the probability P(X  1). Now
ﬁnd all random numbers that are greater than 4.
Among these, ﬁnd the fraction that are greater than 5.
This estimates the probability P(X  4  1|X  4).
According to the memoryless property, these two
estimates should be nearly equal. Are they? Try to do
this without freezing the random numbers, so that you
can get repeated estimates of the two probabilities by
pressing the F9 key.
13.4 IMPORTANT QUEUEING RELATIONSHIPS
As stated earlier, the calculations required in queueing models are neither simple nor obvi-
ous. Fortunately, however, there are several very useful and general relationships that hold
for a wide variety of queueing models. We brieﬂy discuss them here so that they can be
used in the queueing models in later sections.
We typically calculate two general types of outputs in a queueing model: time aver-
ages and customer averages. Typical time averages are3
■
L, the expected number of customers in the system
■
LQ, the expected number of customers in the queue
■
LS, the expected number of customers in service
■
P(all idle), the probability that all servers are idle
■
P(all busy), the probability that all servers are busy
3These quantities appear several times throughout this chapter, and we will continue to use this notation.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

If you were going to estimate the quantity LQ, for example, you might observe the sys-
tem at many time points, record the number of customers in the queue at each time point,
and then average these numbers. In other words, you would average this measure over
time. Similarly, to estimate a probability such as P(all busy), you would observe the system
at many time points, record a 1 each time all servers are busy and a 0 each time at least one
server is idle, and then average these 0s and 1s.
In contrast, typical customer averages are
■
W, the expected time spent in the system (waiting in line or being served)
■
WQ, the expected time spent in the queue
■
WS, the expected time spent in service
To estimate the quantity WQ, for example, you would observe many customers, record
the time in queue for each customer, and then average these times over the number of cus-
tomers observed. Now you are averaging over customers.
Little’s Formula
Little’s formula is a famous formula that relates time averages and customer averages in
steady state. This formula was ﬁrst discovered by John D.C. Little.4 The formula is easy to
state. Consider any queueing system. Let  be the average rate at which customers enter
this system, let L be the expected number of customers in the system, and let W be the
expected time a typical customer spends in the system. Then Little’s formula can be
expressed as
L  W
(13.2)
It can also be stated in terms of LQ and WQ or in terms of LS and WS. That is, two alter-
native versions of Little’s formula are
LQ  WQ
(13.3)
and
LS  WS
(13.4)
The reasoning behind any version of Little’s
formula is actually very simple. For example, to see
why Equation (13.3) is true, consider a long time
period of length T. During this period, about T
customers are expected to enter the system (from
the deﬁnition of  as a rate), and each of these waits
in queue for an expected time WQ. Therefore, the
expected total number of customer minutes spent in
queue is TWQ. On the other hand, the expected
number of customers in the queue at any time dur-
ing this period is LQ, so the total number of cus-
tomer minutes spent in the queue can also be
calculated as LQT. Setting TWQ equal to LQT and
canceling T results in Equation (13.3). Strictly
speaking, this argument is valid only for an
extremely large time T, which is why Little’s
13.4 Important Queueing Relationships
785
Little’s formula relates
time averages, such 
as L, to customer
averages, such as W. If
you can find one of
these, then Little’s
formula gives you the
value of the other one.
4The original result was published in Little (1961). Numerous extensions of the basic result have been published
since, including Brumelle (1971), Stidham (1974), and Heyman and Stidham (1980). It is now known that Little’s
formula holds in an amazingly wide variety of queueing systems.
FUNDAMENTAL INSIGHT
The Wide Applicability of Little’
s Formula
Little’s formula is one of the most general rules in
queueing and is analog
ous to the famous rule
,
Distance  Rate * Time, in that it relates the average
number in a system to the average arrival rate to the
system and the a verage time spent in the system. To
apply Little’s formula (or understand ho w someone
else has a pplied it), you must ﬁrst understand what
the “system” is. This system can be an overall system,
or it can be a subsystem of a larger system,
such as
the waiting line (but not the ser vice area) of a bank.
After you understand what the system is,you can use
Little’s formula to calculate one of the thr ee quanti-
ties in the formula from the other two.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

formula is a steady-state result. When simulation is used for relatively small values of time
T, Little’s formula holds only approximately.
Typically, analytical methods are used to ﬁnd one of the L values and then Little’s for-
mula is used to ﬁnd the corresponding W. Alternatively, L can be found from W. For exam-
ple, suppose the arrival rate to a single-server queueing system is 30 customers per hour
(  30). Also, suppose you know (probably from an analytical model) that the expected
number of customers in the system is L  2.5. Then Equation (13.2) implies that a typical
customer spends an expected time W  L  2.530  0.0833 hour  5 minutes in the
system. If you also know that the average number of customers in the queue is LQ  1.8,
Equation (13.3) implies that a typical customer’s expected time in the queue is WQ  LQ 
1.830  0.06 hour  3.6 minutes.
Other Relationships
Two other formulas relate these quantities. First, all customers are either in service or in
the queue, which leads to the following equation.
L  LQ  LS
(13.5)
In the example from the previous paragraph, Equation (13.5) implies that LS  2.5  1.8 
0.7. (For a single-server system this means that exactly one customer is in service 70% of
the time and no customers are in service 30% of the time.)
A second useful formula is the following:
W  WQ  WS
(13.6)
Equation (13.6) holds because the time spent in the system is the time spent in the queue
plus the time spent in service, and WS is the expected time in service. In the numerical
example, Equation (13.6) implies that the expected time a typical customer spends in ser-
vice is 5.0  3.6  1.4 minutes.
One ﬁnal important queueing measure is called the server utilization. The server uti-
lization, denoted by U, is deﬁned as the long-run fraction of time a typical server is busy.
In a multiple-server system, where there are s identical servers in parallel, server utilization
is deﬁned as
U  LSS
That is, it is the expected number of busy servers divided by the number of servers. For
example, if s  3 and LS  2.55, then U  0.85. In this case, the expected number of busy
servers is 2.55, and each of the three servers is busy about 85% of the time.
786
Chapter 13
Queueing Models
Server utilization is the
fraction of time a
typical server is busy.
P R O B L E M S
Skill-Building Problems
5.
Assume that parts arrive at a machining center at a rate
of 60 parts per hour. The machining center is capable
of processing 75 parts per hour—that is, the mean time
to machine a part is 0.8 minute. If you are watching
these parts exiting the machine center, what exit rate
do you observe, 60 or 75 per hour? Explain.
6.
Little’s formula applies to an entire queueing system
or to a subsystem of a larger system. For example,
consider a single-server system composed of two sub-
systems. The ﬁrst subsystem is the waiting line, and
the second is the service area, where service actually
takes place. Let  be the rate that customers enter the
system and assume that   60 per hour.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

13.5 ANALYTICAL STEADY-STATE QUEUEING MODELS
In this section, we discuss several analytical models for queueing systems. As stated
earlier, these models cannot be developed without a fair amount of mathematical
background—more than is assumed in this book. Therefore, we must rely on the queueing
models that have been developed in the management science literature—and there are lit-
erally hundreds or even thousands of these. We will illustrate only the most basic models,
and even for these, we provide only the key formulas. In some cases, we even automate
these formulas with macros. This enables you to focus on the aspects of practical concern:
(1) the meaning of the assumptions and whether they are realistic, (2) the relevant input
parameters, (3) interpretation of the outputs, and possibly (4) how to use the models for
economic optimization.
The Basic Single-Server Model
We begin by discussing the most basic single-server model, labeled the MM1 model.
This shorthand notation, developed by Kendall, implies three things. The ﬁrst M implies
that the distribution of interarrival times is exponential.5 The second M implies that the dis-
tribution of service times is also exponential. Finally, the “1” implies that there is a single
server. Customarily,  denotes the arrival rate, and µ denotes the service rate. (Here, µ is
the Greek letter mu.) This means that 1 is the mean time between arrivals and 1µ is the
mean service time per customer. The model in this section is sometimes called the classi-
cal MM1 queueing model, which means that all customer arrivals join the system and
stay until they are eventually served.
The mathematical derivation of the steady-state results for an MM1 queueing sys-
tem is rather involved, so we simply list the results, which are surprisingly simple. First,
we deﬁne  (the Greek letter rho) by   µ. This is called the trafﬁc intensity, which is
a very useful measure of the congestion of the system. In fact, the system is stable only
if   1. If   1, so that   µ, then arrivals occur at least as fast as the server can handle
13.5 Analytical Steady-State Queueing Models
787
a. If the expected number of customers waiting in line
is 2.5, what does Little’s formula applied to the
ﬁrst subsystem tell you?
b. Let  be the service rate of the server (in customers
per hour). Assuming that   (so that the server
can serve customers faster than they arrive), argue
why the rate into the second subsystem must be .
Then, letting   80 per hour, what does Little’s
formula applied to the second subsystem tell you
about the expected number of customers in
service?
7.
Consider a bank where potential customers arrive at
rate of 60 customers per hour. However, because of
limited space, one out of every four arriving customers
ﬁnds the bank full and leaves immediately (without
entering the bank). Suppose that the average number
of customers waiting in line in the bank is 3.5. How
long will a typical entering customer have to wait in
line? (Hint: In Little’s formula,  refers only to cus-
tomers who enter the system.)
Skill-Extending Problem
8.
Consider a fast-food restaurant where customers enter
at a rate of 75 per hour, and three servers are working.
Customers wait in a single line and go, in FCFS
fashion, to the ﬁrst of the three servers who is avail-
able. Each server can serve one customer every two
minutes on average. If you are standing at the exit,
counting customers as they leave the restaurant, at
what rate will you see them leave? On average, how
many of the servers are busy?
5The M actually stands for Markov, a technical term that is synonymous with the exponential distribution. You 
can also think of it as an acronym for memoryless.
Kendall’s notation, such
as MM1, allows us
to describe a variety of
queueing systems with
a few well-chosen
symbols.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

them; in the long run, the queue becomes inﬁnitely large—that is, it is unstable. Therefore,
we must assume that   1 to obtain steady-state results.
Assuming that the system is stable, let pn be the steady-state probability that there are
exactly n customers in the system (waiting in line or being served) at any point in time.
This probability can be interpreted as the long-run fraction of time when there are n cus-
tomers in the system. For example, p0 is the long-run fraction of time when there are no
customers in the system, p1 is the long-run fraction of time when there is exactly one cus-
tomer in the system, and so on. These steady-state probabilities can be found from the fol-
lowing steady-state equation:
pn  (1  ) n
n  0
(13.7)
From the deﬁnition of expected value, the expected number of customers in the system, L,
is the sum over all n of n multiplied by pn. It can be shown that this sum reduces to
(13.8)
where the last two expressions are equivalent. Then W, WQ, and LQ can be found from
Little’s formula and the fact that 1 is the expected time in service:
W  L,
WQ  W  1µ,
LQ  WQ
(13.9)
Two other results are worth noting. First, the server utilization U is the fraction of time
the server is busy. This fraction is 1  p0  , so that the server utilization is equal to the
trafﬁc intensity:
U  
(13.10)
For example, if   40 per hour and µ  60 per hour, then U    23, so that the server is
busy 23 of the time and is idle 13 of the time. Second, it is possible to derive the following
explicit expression for the distribution of time spent by a typical customer in the queue:
P(Time in queue  t)  eµ(1)t
for any t  0
(13.11)
The following example illustrates these results.
L =
r
1 - r =
l
m - l
788
Chapter 13
Queueing Models
The formulas
presented here are not
necessarily intuitive,
and it takes a fair
amount of
mathematics to derive
them rigorously.
However, you can still
use them.
13.2 QUEUEING AT A POSTAL BRANCH
T
he Smalltown postal branch employs a single clerk. Customers arrive at this postal
branch according to a Poisson process at a rate of 30 customers per hour, and the aver-
age service time is exponentially distributed with mean 1.5 minutes. All arriving customers
enter the branch, regardless of the number already waiting in line. The manager of the
postal branch would ultimately like to decide whether to improve the system. To do this,
she ﬁrst needs to develop a queueing model that describes the steady-state characteristics
of the current system.
Objective
To model the postal branch’s system as an MM1 queue and then use the
analytical formulas in Equations (13.7) to (13.11) to ﬁnd the system’s steady-state
characteristics.
WHERE DO THE NUMBERS COME FROM?
The branch manager needs to proceed as in Example 13.1 to estimate the arrival rate and
the mean service rate (and verify that the resulting distributions are at least approximately
exponential).
E X A M P L E
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Solution
To begin, you must choose a common unit of time and then express the arrival and service
rates ( and µ) in this unit. You could measure time in seconds, minutes, hours, or any
other convenient time unit, as long as you are consistent. For this example, minutes are
used as the unit of time. Then, because one customer arrives every two minutes,   12.
Also, because the mean service time is 1.5 minutes, the service rate is its reciprocal—that
is, µ  11.5  0.667. Then the trafﬁc intensity is
    (12)(23)  0.75
Because this is less than 1, the system is stable and steady state will occur.
USING THE SPREADSHEET MODEL TEMPLATE
To implement the formulas for the MM1 model, we developed an MM1 template ﬁle.
(See Figure 13.7 and the ﬁle MM1 Template.xlsx.) We do not provide step-by-step
instructions because we expect that you will use this as a template rather than enter the for-
mulas yourself. However, the following points are important.
1
All you need to enter are the inputs in cells B4 through B6. Note that the rates in cells
B5 and B6 are relative to the time unit you specify in cell B4.
2
You can enter numbers for the rates in cells B5 and B6, or you can base these on
observed data. (Example 13.1 illustrated the estimation of arrival and service rates from
observed data.)
3
The value of L in cell B15 is calculated from Equation (13.8). Then the values in cells
B5, B15, and B17 are related by the Equation (13.2) version of Little’s formula, L  W;
the values in cells B5, B16, and B18 are related by Equation (13.3), LQ  WQ; and the
13.5 Analytical Steady-State Queueing Models
789
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
A
B
C
D
E
F
G
H
I
M/M/1 queue
Inputs
Unit of 
e
t
u
ni
m
e
m
it
Arrival 
e
t
u
ni
m
/sr
e
m
o
ts
u
c
0
0
5.0
e
t
a
r
Service 
e
t
u
ni
m
/sr
e
m
o
ts
u
c
7
6
6.0
e
t
a
r
Outputs
Direct outputs from 
n
oit
u
birtsi
D
st
u
p
ni
 of number in system
Distribuon of me in queue
Mean me between arrivals
2.000
minutes
n (customers)
P(n in system)
t (in minutes)
P(wait > t)
Mean me per service
1.500
minutes
0
0.250
2.000
0.537
Traﬃc 
8
8
1.0
1
0
5
7.0
ytis
n
e
t
ni
2
0.141
Summary measures
3
0.105
Expected number in system
3.000
customers
4
0.079
Expected number in queue
2.250
customers
5
0.059
Expected me in system
6.000
minutes
6
0.044
Expected me in queue
4.500
minutes
7
0.033
Server 
5
2
0.0
8
%
0.5
7
n
oit
a
zilit
u
9
0.019
10
0.014
11
0.011
12
0.008
13
0.006
14
0.004
15
0.003
16
0.003
17
0.002
18
0.001
19
0.001
20
0.001
21
0.001
22
0.000
Enter desired inputs in blue cells and 
everything  recalculates automacally.
Figure 13.7
Template for the MM1 Queue
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

value in cell B18 is calculated from WQ  W – 1µ. From Equation (13.10), the server uti-
lization in cell B19 is the same as the trafﬁc intensity in cell B12.
4
The steady-state probabilities in column F are based on Equation (13.7). You can copy
these down as far as you like, until the probabilities are negligible.
5
The waiting time probability in cell I11 is calculated from Equation (13.11). You can
enter any time t in cell H11 to obtain the probability that a typical customer will wait in the
queue at least this amount of time. Alternatively, you can enter other values of t in cells
H12, H13, and so on, and then copy the formula in cell I11 down to calculate other waiting
time probabilities.
Discussion of the Results
From Figure 13.7, you can see, for example, that when the arrival rate is 0.5 and the service
rate is 0.667, the expected number of customers in the queue is 2.25 and the expected time
a typical customer spends in the queue is 4.5 minutes. However, cells F11 and I11 indicate
that 25% of all customers spend no time in the queue, and 53.7% spend more than 2 min-
utes in the queue. Also, just for illustration, cell F15 indicates that the steady-state proba-
bility of having exactly four customers in the system is 0.079. Equivalently, there are
exactly four customers in the system 7.9% of the time.
The branch manager can experiment with other arrival rates or service rates in cells B5
and B6 to see how the various output measures are affected. One particularly important
insight can be obtained through a data table, as shown in Figure 13.8. The current server uti-
lization is 0.75, and the system is behaving fairly well, with short waits in queue on average.
The data table, however, shows how bad things can get when the service rate is just barely
above the arrival rate, so that the trafﬁc intensity is just barely below 1. (The single output
for this data table is the expected time in queue, from cell B18, and the column input cell is
the service rate cell, B6.) The corresponding chart shows that the expected time in queue
increases extremely rapidly as the service rate gets closer to the arrival rate. Whatever else
the branch manager learns from this model, she now knows that she does not want a service
rate close to the arrival rate, at least not for extended periods of time.
790
Chapter 13
Queueing Models
The traffic intensity
determines the amount
of congestion in the
system.
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
K
L
M
N
O
P
Q
R
S
T
U
Data table for expected me in queue, by varying the service rate
Service rate
Queue me
4.500
0.505
198.020
0.510
98.039
0.515
64.725
0.520
48.077
0.525
38.095
0.530
31.447
0.535
26.702
0.540
23.148
0.545
20.387
0.550
18.182
0.555
16.380
0.560
14.881
0.565
13.615
0.570
12.531
0.575
11.594
0.580
10.776
0.585
10.055
0.590
9.416
0.595
8.846
0.600
8.333
0.000
50.000
100.000
150.000
200.000
250.000
0.500
0.520
0.540
0.560
0.580
0.600
Expected Time in Queue
Service Rate
Expected Time in Queue versus Service Rate
Figure 13.8
Effect of Varying Service Rate
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

It is important to realize that the entire analysis depends on the fact that the arrival rate
remains constant at one every two minutes, on average. Therefore, the results in Figure 13.7
are valid only for the period of time when this arrival rate is in effect. If the arrival rate sud-
denly changes, as it might during the lunch period or the 5:00 P.M. rush, then a new steady-
state analysis must be performed with the new arrival rate.
■
The Basic Multiple-Server Model
Many service facilities such as banks and postal branches employ multiple servers.
Usually, these servers work in parallel, so that each customer goes to exactly one server for
service and then departs. In this section, we analyze the simplest version of this multiple-
server parallel system, labeled the MMs model. Again, the ﬁrst M means that interar-
rival times are exponentially distributed. The second M means that the service times for
each server are exponentially distributed. (We also assume that each server is identical to
the others, in the sense that each has the same mean service time.) Finally, the s in MMs
denotes the number of servers. (If s  1, the MMs and MM1 models are identical. In
other words, the MM1 system is a special case of the MMs system.)
If you think about the multiple-server facilities you typically enter, such as banks, post
ofﬁces, and supermarkets, you recognize that there are two types of waiting line conﬁgura-
tions. The ﬁrst, usually seen at supermarkets, is where each server has a separate line. Each
customer must decide which line to join (and then either stay in that line or switch later
on). The second, seen at most banks and post ofﬁces, is where there is a single waiting line,
from which customers are served in FCFS order. We examine only the second type because
it is arguably the more common system in real-world situations. It is also much easier to
analyze mathematically.
There are three inputs to this system: the arrival rate , the service rate (per server) µ,
and the number of servers s. To ensure that the system is stable, we must also assume that
the trafﬁc intensity, now given by   (sµ), is less than 1. In words, the arrival rate 
must be less than the maximum service rate s (which is achieved when all s servers are
busy). If the trafﬁc intensity is not less than 1, the length of the queue eventually increases
without bound.
Stability in MMs model:   (sµ)  1
The steady-state analysis for the MMs system is more complex than for the MM1
system. As before, let pn be the probability that there are exactly n customers in the system,
waiting or in service. Then it turns out that all of the steady-state quantities can be
expressed in terms of p0, which can be calculated from the rather complex formula in
Equation (13.12). Then the other quantities can be calculated from p0, as indicated in
Equations (13.13) to (13.17).
(13.12)
pn 
(13.13)
P(All servers busy) 
(13.14)
(sr)sp0
s!(1 - r)
(sr)np0
n!
  if 1 … n … s
(sr)np0
s!sn-s   if n 7 s
p0 =
1
a
s-1
n=0
(sr)n
n!
+
(sr)s
s!(1 - r)
13.5 Analytical Steady-State Queueing Models
791
The MM1 system
gets very congested,
with long waiting
times, when the arrival
rate is just barely less
than the service rate.
The MMs system
assumes that all
customers wait in a
single line and are
served in FCFS order.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

LQ  P(All servers busy) 
(13.15)
WQ  LQ,
W  WQ  1µ,
L  W
(13.16)
P(Wait in queue  t)  P(All servers busy)esµ(1  )t
for any t  0
(13.17)
These formulas are admittedly complex, so we have implemented them, with the use of a
macro, in a template ﬁle. The following example illustrates the process.
r
1 - r
792
Chapter 13
Queueing Models
13.3 QUEUEING AT COUNTY BANK
C
ounty Bank has several branch locations. At one of these locations, customers arrive at
a Poisson rate of 150 per hour. The branch employs six tellers. Each teller takes, on
average, two minutes to serve a customer, and service times are exponentially distributed.
Also, all tellers perform all tasks, so that customers can go to any of the six tellers.
Customers who arrive and ﬁnd all six tellers busy join a single queue and are then served
in FCFS fashion. As a ﬁrst step, the bank manager wants to develop a queueing model of
the current system. Then he wants to ﬁnd the “best” number of tellers, given that tellers are
paid $12 per hour.
Objective
To develop an MMs queueing model for the bank and examine its steady-
state properties, and then to ﬁnd the number of tellers that is best from an economic point
of view.
WHERE DO THE NUMBERS COME FROM?
The same comments as in Example 13.2 apply here. Of course, the $12 ﬁgure is just the
current hourly wage rate.
Solution
As with the MM1 system, we have created a template ﬁle that calculates p0 from
Equation (13.12), using a macro, and then implements the formulas in Equations (13.13) to
(13.17). (See the ﬁle MMs Template.xlsm and Figure 13.9.)
USING THE SPREADSHEET MODEL TEMPLATE
All you need to do is enter the inputs in cells B4 to B7 and then click on the button. This
button runs the macro that calculates p0 in cell B16, and then the formulas in the other cells
all recalculate automatically. For this example, the necessary inputs are the unit of time
(hour), the arrival rate (150), the service rate per server (30), and the number of servers (6).
We invite you to look at the formulas in the various cells to check that they do indeed
implement Equations (13.13) to (13.17). As with the MM1 template, you can copy the
probability distribution in columns E and F as far down as you like, until the probabilities
are negligible, and you can enter any time t in cell H12 to get the corresponding waiting
time probability in cell I12.
Discussion of the Results
From Figure 13.9 you can see that when there are six tellers and the trafﬁc intensity is
0.833, the expected number of customers in the system is 7.94, and the expected time a typ-
ical customer spends in the system is 0.053 hour (about 3.2 minutes). Also, about 41% of all
arriving customers can go immediately into service, whereas about 32% of all customers
The template file uses
a macro to calculate
the probability that the
system is empty. Built-
in formulas then
calculate all other
steady-state measures.
Don't forget to enable
the macro when you
open the file.
E X A M P L E
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

must wait more than 0.02 hour (about 1.2 minutes) in the queue. Finally, you can ﬁnd the
expected fraction of time each teller is busy as LSs. We ﬁnd LS, the expected number of
busy tellers, from LS  L  LQ  7.938  2.938  5. Then the expected fraction of time
each teller is busy is LSs  56  0.833. If this number doesn’t ring a bell, it should—it
is the server utilization in cell B13. This is no coincidence. The server utilization in an
MMs system, calculated as the arrival rate divided by the maximum service rate, is
always the expected fraction of time a typical server is busy. That is, the trafﬁc intensity is
equal to the server utilization U.
Economic Analysis
We now turn to the economic analysis. There is a cost and a beneﬁt from adding a teller.
The cost is the wage rate paid to the extra teller, $12 per hour. The beneﬁt is that customers
wait less time in the bank. Note that adding an extra teller makes both W and WQ decrease
by the same amount. This is because W equals WQ plus the expected service time per cus-
tomer, and this expected service time does not change with extra tellers. This means that
extra tellers decrease only the expected time in line, not the time in service. (The latter
would decrease only if we made each teller faster, rather than adding tellers.) To see how
WQ changes, try entering 7 and then 8 for the number of tellers in cell B7 of Figure 13.9
and clicking on the button for each change. You should observe that the value of WQ
changes from 0.0196 hour (with six tellers) to 0.0054 hour (with seven tellers) to 0.0019
hour (with eight tellers). Because the arrival rate is 150 customers per hour, these waiting
times translate to 2.94, 0.81, and 0.28 customer-hours spent waiting in line each hour. (Just
multiply each expected waiting time in queue by 150.)
13.5 Analytical Steady-State Queueing Models
793
Figure 13.9
Template for the MMs Queue
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
I
H
G
F
E
D
C
B
A
M/M/s Queue
Inputs
Unit of 
r
u
o
h
e
m
it
Arrival 
r
u
o
h
/sr
e
m
o
ts
u
c
0
5
1
e
t
a
r
Service rate per 
r
u
o
h
/sr
e
m
o
ts
u
c
0
3
r
e
v
r
e
s
Number of 
6
sr
e
v
r
e
s
Outputs
Direct outputs from 
n
oit
u
birtsi
D
st
u
p
ni
 of number in system
Distribuon of me in queue
Mean me between arrivals
0.007
hours
n (customers)
P(n in system)
t (in hours)
P(wait > t)
Mean me per 
2
2
3.0
0
2
0.0
5
4
0
0.0
0
sr
u
o
h
3
3
0.0
e
civ
r
e
s
Traﬃc 
6
2
2
0.0
1
3
3
8.0
ytis
n
e
t
ni
2
0.0564
Summary measures
3
0.0940
P(system 
5
7
1
1.0
4
5
0
0.0
)yt
p
m
e
P(all servers 
5
7
1
1.0
5
%
8.8
5
)y
s
u
b
Expected number in system
7.938
customers
6
0.0979
Expected number in queue
2.938
customers
7
0.0816
Expected me in system
0.053
hours
8
0.0680
Expected me in queue
0.020
hours
9
0.0567
Percentage who don't wait in 
2
7
4
0.0
0
1
%
2.1
4
e
u
e
u
q
11
0.0394
12
0.0328
13
0.0273
14
0.0228
15
0.0190
16
0.0158
17
0.0132
18
0.0110
19
0.0092
20
0.0076
21
0.0064
22
0.0053
Aer entering inputs in blue cells, click on the buon below to run the 
macro that calculates P(0), the value in cell B16. Everything else recalculates 
automacally. Do not rearrange cells in this template -- this might cause the 
macro to stop behaving correctly.
Calculate steady-state quanes
The server utilization
in an MMs
system—the fraction
of time each server is
busy—is equal to the
traffic intensity.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

The real problem is to evaluate the cost of waiting in line. This is not an out-of-pocket
cost for the bank, but it does represent an indirect cost: Customers who experience long
waits might take their business elsewhere. In any case, the key to the trade-off is assessing
a unit cost, cQ, per customer-hour spent waiting in the queue. If the manager can assess this
unit cost, then the total expected cost per hour of customer waiting is cQWQ. The reason-
ing is that an expected  customers arrive per hour, and each waits an expected time WQ in
the queue. This waiting cost can then be traded off against the cost of hiring extra tellers.
We provide another template in the ﬁle MMs Optimizing Template.xlsm that helps
solve the problem (see Figure 13.10). You now need to provide the arrival rate, the service
rate per server, the wage rate per server, and the unit waiting cost per customer per unit
time in line. You should not enter the number of servers as an input. Instead, the macro—
run by clicking on the button—calculates selected summary measures of the system for
several choices of the number of servers. Speciﬁcally, for each number of servers, the
macro does the same calculations as in the MMs template to calculate the value of WQ in
row 17. Then the cost of wages in row 18 is the wage rate multiplied by the number of
servers, the queueing cost in row 19 is cQWQ, and the total cost in row 20 is the sum of
these two costs.
To optimize, the macro begins by using the smallest number of tellers required to keep
the system stable. In this case, six tellers are required, as seen in cell B10. Then it keeps
adding a teller and calculating the total expected cost for that number of tellers—total
wages plus total expected waiting cost—until the total expected cost starts to increase.
Given the inputs in Figure 13.10, where the manager assesses customer waiting time at
$8 per hour, the total expected cost when there are six tellers is $95.90. It then decreases
794
Chapter 13
Queueing Models
Figure 13.10 A Template for Queueing Optimization
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
I
H
G
F
E
D
C
B
A
M/M/s Queue - A Template for Opmizing
Inputs
Unit of 
r
u
o
h
e
m
it
Arrival 
r
u
o
h
/sts
u
c
0
5
1
e
t
a
r
Service rate per 
r
u
o
h
/sts
u
c
0
3
r
e
v
r
e
s
Wage rate per server
$12.00
$/hour
Cost per customer for me in queue
$8.00
$/hour
Minimum number of servers
6
Outputs
Number of 
8
7
6
sr
e
v
r
e
s
Server 
5
2
6.0
4
1
7.0
3
3
8.0
n
oit
a
zilit
u
P(system 
6
0
0.0
6
0
0.0
5
0
0.0
)yt
p
m
e
Percentage who wait in queue
0.588
0.324
0.167
Expected me in queue
0.0196
0.0054
0.0019
Wages paid per hour
$72.00
$84.00
$96.00
Queueing cost per hour
$23.50
$6.48
$2.23
Total cost per 
3
2.8
9
$
8
4.0
9
$
0
5.5
9
$
r
u
o
h
Direcons:
1. Enter the inputs in cells B4 through B8.
2. Click on the buon below.
Starng with the minimum number of servers in column B, the macro keeps 
increasing the number of servers unl the total cost in row 20 increases.  
Then the next to last total cost must be the minimum.
Note: You can start with a table from a previous run in rows 13-20 (in which 
case the macro will erase it before calculang the new table), or you can 
start with no table in these rows.
Calculate steady-state quanes
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

to $90.48 with seven tellers, and then it increases to $98.23 with eight tellers. Because the
total expected cost would only continue to increase with more than eight tellers, the macro
quits with eight, implying that seven tellers is best.
This procedure requires a value for cQ in cell B8. Because this value is probably very
difﬁcult for a bank manager to assess, you can use an alternative indirect approach. You
can ﬁnd ranges for cQ where a speciﬁc number of servers is economically optimal. To
do this, ﬁrst enter the largest reasonable value of cQ in cell B8 and run the macro. For
example, if the manager knows he would never value customer waiting time at more than
$25 per hour, enter $25 in cell B8. Running the macro with this cQ gives the results in
Figure 13.11. They imply that a choice of eight tellers is optimal when cQ  25. They also
imply that no more than eight tellers would ever be optimal for any smaller value of cQ.
(Make sure you understand why this is true.) Given the output in Figure 13.11, you can
now ask, when are six tellers better than seven? The total cost comparison, using the values
of WQ in row 17, shows that six tellers are better than seven when
6($12)  cQ(150)(0.0196)  7($12)  cQ(150)(0.0054)
This reduces to cQ  $5.64. Similarly, seven tellers are better than eight when
7($12)  cQ(150)(0.0054)  8($12)  cQ(150)(0.0019)
This reduces to cQ  $22.57. These results imply that it is best to use six tellers when 
cQ  $5.64. Otherwise, if cQ  $22.57, it is best to use seven tellers. Finally, for cQ
between $22.57 and $25, it is best to use eight tellers.
13.5 Analytical Steady-State Queueing Models
795
Figure 13.11 Output Useful for Sensitivity Analysis on the Unit Waiting Cost
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
I
H
G
F
E
D
C
B
A
M/M/s Queue - A Template for Opmizing
Inputs
Unit of 
r
u
o
h
e
m
it
Arrival 
r
u
o
h
/sts
u
c
0
5
1
e
t
a
r
Service rate per 
r
u
o
h
/sts
u
c
0
3
r
e
v
r
e
s
Wage rate per server
$12.00
$/hour
Cost per customer for me in queue
$25.00
$/hour
Minimum number of servers
6
Outputs
Number of 
9
8
7
6
sr
e
v
r
e
s
Server 
6
5
5.0
5
2
6.0
4
1
7.0
3
3
8.0
n
oit
a
zilit
u
P(system 
7
0
0.0
6
0
0.0
6
0
0.0
5
0
0.0
)yt
p
m
e
Percentage who wait in queue
0.588
0.324
0.167
0.081
Expected me in queue
0.0196
0.0054
0.0019
0.0007
Wages paid per hour
$72.00
$84.00
$96.00
$108.00
Queueing cost per hour
$73.44
$20.26
$6.97
$2.52
Total cost per hour
$145.44
$104.26
$102.97
$110.52
Direcons:
1. Enter the inputs in cells B4 through B8.
2. Click on the buon below.
Starng with the minimum number of servers in column B, the macro keeps 
increasing the number of servers unl the total cost in row 20 increases.  
Then the next to last total cost must be the minimum.
Note: You can start with a table from a previous run in rows 13-20 (in which 
case the macro will erase it before calculang the new table), or you can 
start with no table in these rows.
Calculate steady-state quanes
One of the most
difficult aspects of an
economic analysis of a
queueing system is
assessing the cost of
making a customer
wait in line.
■
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

A Comparison of Models
Here is a question many of you have probably pondered while waiting in line. Would you
rather go to a system with one fast server or a system with several slow servers? In the lat-
ter case, we assume that only one waiting line forms, so that you can’t get unlucky by join-
ing the “wrong” line. The solution to the question is fairly straightforward, now that you
know how to obtain outputs for MM1 and MMs models. In the following example, we
make the comparison numerically. For a fair comparison, we assume that (1) the arrival
rate is the same for both systems, and (2) the service rate µfast for the single fast server is
equal to sµslow, where µslow is the service rate for each of the s slow servers.
796
Chapter 13
Queueing Models
E X A M P L E
13.4 COMPARING ONE FAST SERVER TO SEVERAL SLOW SERVERS
W
hich system has the better steady-state characteristics such as L, W, LQ, and WQ: a
single-server system where the single server can serve 30 customers per hour or a 
ﬁve-server system where each of the servers can serve six customers per hour? For each
system, we assume that customers arrive according to a Poisson process at rate 25 per hour.
Objective
To see whether customers should prefer a system with one fast server or a
system with several slower servers.
WHERE DO THE NUMBERS COME FROM?
You can use any representative inputs for the comparison. In fact, it would be useful to try
others, just to see whether the qualitative results discussed next continue to hold.
Solution
First, note that the two models are comparable in the sense that µfast  sµslow because µfast 
30, s  5, and µslow  6. Equivalently, the trafﬁc intensity is 56 for each. The results in
Figures 13.12 and 13.13 answer our question. (They were formed from the MM1
Template.xlsx and MMs Template.xlsm ﬁles simply by changing the inputs.) As you can
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
A
B
C
D
E
F
G
H
I
M/M/1 queue
Inputs
Unit of 
r
u
o
h
e
m
it
Arrival 
r
u
o
h
/sr
e
m
o
ts
u
c
5
2
e
t
a
r
Service 
r
u
o
h
/sr
e
m
o
ts
u
c
0
3
e
t
a
r
Outputs
Direct outputs from 
n
oit
u
birtsi
D
st
u
p
ni
 of number in system
Distribuon of me in queue
Mean me between arrivals
0.040
hours
n (customers)
P(n in system)
t (in hours)
P(wait > t)
Mean me per service
0.033
hours
0
0.167
2.000
0.000
Traﬃc 
9
3
1.0
1
3
3
8.0
ytis
n
e
t
ni
2
0.116
Summary measures
3
0.096
Expected number in system
5.000
customers
4
0.080
Expected number in queue
4.167
customers
5
0.067
Expected me in system
0.200
hours
6
0.056
Expected me in queue
0.167
hours
7
0.047
Server 
9
3
0.0
8
%
3.3
8
n
oit
a
zilit
u
Enter desired inputs in blue cells and 
everything  recalculates automacally.
Figure 13.12 MM1 System with a Single Fast Server
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

see, the comparison is not entirely clear-cut. The MM1 system has a smaller L but a
larger LQ. Similarly, it has a smaller W but a larger WQ. In addition, the MM1 system is
worse in that it has a smaller percentage of customers who experience no waiting in line
(16.7% versus 38.0%) and a larger percentage who must wait in line at least 0.25 hour
(23.9% versus 17.8%). The basic conclusion is that if you hate to wait in a queue, you
should prefer the system with multiple slow servers. However, when it is your turn to be
served, you clearly prefer the system with the single fast server. In this latter system, you
spend less total time in the system, but more of it is spent waiting in line.
■
The Effect of the Trafﬁc Intensity
We have mentioned that for an MM1 or MMs system to be stable, the trafﬁc intensity
must be less than 1. In words, the system must be able to service the customers faster than
they arrive; otherwise, the queue length eventually grows without limit. It is interesting to see
what happens to a system when the trafﬁc intensity gets closer and closer to 1 but stays less
than 1. As the following continuation of the County Bank example shows, the effects can be
disastrous. We already saw this phenomenon for a single-server system in Example 13.2. It is
worth seeing again, this time in a multiple-server setting. In fact, this is arguably the most
important lesson from this chapter.
13.5 Analytical Steady-State Queueing Models
797
Perhaps surprisingly,
the choice between
these two systems is
not entirely clear-cut.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
I
H
G
F
E
D
C
B
A
M/M/s Queue
Inputs
Unit of 
r
u
o
h
e
m
it
Arrival 
r
u
o
h
/sr
e
m
o
ts
u
c
5
2
e
t
a
r
Service rate per 
r
u
o
h
/sr
e
m
o
ts
u
c
6
r
e
v
r
e
s
Number of 
5
sr
e
v
r
e
s
Outputs
Direct outputs from 
n
oit
u
birtsi
D
st
u
p
ni
 of number in system
Distribuon of me in queue
Mean me between arrivals
0.040
hours
n (customers)
P(n in system)
t (in hours)
P(wait > t)
Mean me per 
1
6
5.0
0
2
0.0
9
9
0
0.0
0
sr
u
o
h
7
6
1.0
e
civ
r
e
s
Traﬃc 
1
1
4
0.0
1
3
3
8.0
ytis
n
e
t
ni
2
0.0857
Summary measures
3
0.1191
P(system 
0
4
2
1.0
4
0
1
0.0
)yt
p
m
e
P(all servers 
4
3
0
1.0
5
%
0.2
6
)y
s
u
b
Expected number in system
7.267
customers
6
0.0861
Expected number in queue
3.101
customers
7
0.0718
Expected me in system
0.291
hours
8
0.0598
Expected me in queue
0.124
hours
9
0.0498
Percentage who don't wait in 
5
1
4
0.0
0
1
%
0.8
3
e
u
e
u
q
Aer entering inputs in blue cells, click on the buon below to run the 
macro that calculates P(0), the value in cell B16. Everything else recalculates 
automacally. Do not rearrange cells in this template -- this might cause the 
macro to stop behaving correctly.
Calculate steady-state quanes
Figure 13.13 MMs System with Several Slow Servers
FUNDAMENTAL INSIGHT
The Effect of the Trafﬁc Intensity
Queueing models are all about waiting lines and con-
gestion. One of the most fundamental insights about
queueing systems is that congestion incr
eases in a
very nonlinear manner as the trafﬁc intensity gets
closer to 1. More speciﬁcally, as the arrival rate gets
closer and closer to the maxim um rate at which the
system can ser vice customers, waiting lines gr ow
extremely ra pidly. Therefore, real systems ha ve to
have some mechanism,
such as turning customers
away or ad ding more servers, to reduce congestion
to an acceptable level.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

798
Chapter 13
Queueing Models
E X A M P L E
13.5 INCREASINGLY LONG LINES AT COUNTY BANK
O
ver a period of time, the County Bank branch ofﬁce from Example 13.3 has been
experiencing a steady increase in the customer arrival rate. This rate has increased
from the previous value of 150 customers per hour to 160, then to 170, and it is still
increasing. During this time, the number of tellers has remained constant at six, and the
mean service time per teller has remained constant at two minutes. The bank manager has
seen an obvious increase in bank congestion. Is this reinforced by the MMs model?
What will happen if the arrival rate continues to increase?
Objective
To see what happens to congestion in a multiple-server system when the traf-
ﬁc intensity gets close to 1.
WHERE DO THE NUMBERS COME FROM?
The numbers here are all hypothetical, just to illustrate an effect.
Solution
Because sµ has stayed constant at value 6(30)  180, the trafﬁc intensity, (s), has
climbed from 150180  0.833 to 160180  0.889 to 170180  0.944, and it is still
climbing. To have a stable system,  must stay below 180, but what about values of 
slightly below 180? We recalculated the spreadsheet in Figure 13.13 for several values of 
and obtained the results in Table 13.1. (W and WQ are expressed in minutes.) Although
each column of this table represents a stable system, the congestion is becoming unbear-
able. When   178, the expected line length is over 80 customers, and a typical customer
must wait about a half hour in line. The situation is twice as bad when   179.
A multiple-server
system with a traffic
intensity just barely
below 1 behaves very
badly—customers
must wait long times
in line.
Table 13.1 Effects of Increasing Arrival Rate
Customer Arrival Rate ()
150
160
170
175
178
179
Trafﬁc intensity
0.833
0.889
0.944
0.972
0.989
0.994
L
7.94
11.04
20.14
38.18
92.21
182.22
LQ
2.94
5.71
14.47
32.35
86.28
176.25
W
3.18
4.14
7.11
13.09
31.08
61.08
WQ
1.18
2.14
5.11
11.09
29.08
59.08
If you remember
nothing else from this
chapter, remember
that congestion in a
system becomes
unbearable as the
traffic intensity gets
close to 1.
The conclusion should be clear to the bank manager. Something must be done to alle-
viate the congestion—probably adding extra tellers—and the bank will no doubt take such
measures if it wants to stay in business. However, the point of the example is that systems
moving toward the borderline of stability become extremely congested. As the results in
the table indicate, there is a huge difference between a system with a trafﬁc intensity of 0.9
and a system with a trafﬁc intensity of 0.99. (This phenomenon is sometimes exempliﬁed
in today’s airports in a very real and painful way.)
■
Other Exponential Models
The basic MMs model and its special case, the MM1 model, represent only two of the
hundreds or even thousands of analytical queueing models that researchers have studied.
Some of these are relatively simple extensions of the models we have discussed, and others
are much more complex. Two of the relatively simple extensions are the limited waiting
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

room and limited source models. Both of these continue to assume exponential interar-
rival times and service times. In the limited waiting room model, we start with the basic
MMs (or MM1) model but assume that arrivals are turned away when the number
already in the queue is at some maximum level. For example, we might prescribe that at
most 10 customers can wait in line. If a customer arrives and 10 customers are already in
line, then this new customer must go elsewhere (to another bank branch, say).
In the limited source model, we assume that there are only a ﬁnite (fairly small) num-
ber of customers in the entire population. The usual context is that the “customers” are
machines. Then an “arrival” means that a machine breaks down and arrives to a repair cen-
ter. A “service” means a machine repair. The unique aspect of this type of system is that the
arrival rate to the repair center depends on the number of machines already there. When
most of the machines are in repair, the arrival rate to the repair center is necessarily low—
there are not very many machines left to break down because most of them are already bro-
ken down. Conversely, when the number in the repair shop is low, the arrival rate to the
repair shop is higher because most machines are candidates for breakdowns.
One interesting aspect of both systems is that stability is not an issue. That is, there is
no need to require that a trafﬁc intensity be less than 1 to ensure stability. The reason is that
only a ﬁnite number of customers (or machines) are allowed in the system. Therefore, it is
impossible for the congestion in the system to grow without bound. As a result, steady
state always occurs, regardless of the relationship between the arrival rate and the service
rate. This doesn’t mean that these systems necessarily have low degrees of congestion. It
just means that their queue length cannot grow without bound.
In the interest of space, we do not discuss examples of these two types of systems.
However, we have included templates for them in the ﬁles Limited Queue Template.xlsm
and Limited Source Template.xlsm, and several of the problems allow you to explore
these templates.
Erlang Loss Model
All of the results so far are possible because of the exponential distribution and its mem-
oryless property. If the exponential assumption is dropped, for either interarrival times or
service times, the mathematical derivations become much more difﬁcult, and “nice”
results are scarce. In this section, we discuss one of the better-known results for non-
exponential systems. Actually, we continue to assume a Poisson arrival process—that is,
exponentially distributed interarrival times—but we drop the exponential service time
requirement. This is important because many real-world service time distributions are
deﬁnitely not exponential.
The model in this section is called the Erlang loss model. 6 The reason for the term
loss is that there is no waiting room at all; customers who arrive when all servers are busy
are lost to the system. (They are forced to go elsewhere.) As usual,  is the arrival rate, µ is
the service rate per server (so that 1µ is the mean service time), and s is the number of
servers. Then the steady-state distribution is speciﬁed by pn, 0 	 n 	 s, where pn is again
the probability of exactly n customers in the system, and n cannot be greater than s because
no queueing is allowed.
The probability ps is of particular interest because it is the probability that all s servers
are busy, so it represents the fraction of arrivals that are lost to the system. Therefore, the
effective arrival rate—the rate at which customers actually enter the system—is (1 – ps),
the usual arrival rate multiplied by the probability that an arrival is able to enter the system.
13.5 Analytical Steady-State Queueing Models
799
Stability is not an issue
when the number of
customers allowed in
the system is finite.
6This model is named after A. K. Erlang, one of the pioneer researchers in queueing theory. Erlang studied
queueing in telephone systems in the early 1900s.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

This is the arrival rate needed in Little’s formula to relate L and W. To do this, ﬁrst note that
all time spent in the system is service time (no queueing), so W  1µ. Then Little’s for-
mula reduces to
L  (1ps)W  (1  ps)µ
Of course, LQ and WQ are irrelevant for this system because no customers are allowed to
wait in a queue.
A rather remarkable mathematical result states that the steady-state probabilities for
this system depend on the service time distribution only through the mean service time,
1µ. That is, the form of the service time distribution does not matter; it could be exponen-
tial or anything else, as long as it has mean 1µ. This means that the steady-state distribu-
tion can be calculated as if the service times were exponential. We illustrate the procedure
in the following example.
800
Chapter 13
Queueing Models
In the Erlang loss
model, the steady-state
distribution depends on
the service time
distribution only
through its mean.
Luckily, the service
times do not have to
be exponentially
distributed to get
results.This would
probably be an
unrealistic assumption
for this example.
E X A M P L E
13.6 REQUESTS FOR FIRE ENGINES
S
uppose that a ﬁre department receives an average of 24 requests for ﬁre engines each
hour, and that these requests occur according to a Poisson process. Each request causes
a ﬁre engine to be unavailable for an average of 20 minutes. To have at least a 99% chance
of being able to respond to a request, how many ﬁre engines should the ﬁre department
have?
Objective
To use the Erlang loss model to ﬁnd an appropriate number of ﬁre engines so
that one is almost always available.
WHERE DO THE NUMBERS COME FROM?
The arrival rate and the mean service time should be available from historical data. Note
that for the service time distribution, only the mean, 20 minutes, is required. The Erlang
loss model is then relevant, regardless of how the actual service times vary around this
mean—they could all be close to 20 minutes or they could vary widely around 20 minutes.
Solution
To model this as a queueing problem, think of the requests for ﬁre engines as customers and
the ﬁre engines as servers. Then the key aspect of the problem is that there is no queueing
for service. If a request occurs when at least one ﬁre engine is available, an available ﬁre
engine services this request. (We assume that each request is serviced by a single ﬁre
engine.) However, if no ﬁre engine is available, this request is not serviced at all—it is lost.
Therefore, this problem is essentially like the MMs model with a waiting room size of 0,
where s is the number of ﬁre engines (a value to be determined). The only difference is that
we are not assuming exponentially distributed service times. All we are told is that the mean
service time is 20 minutes. Because there is probably some minimum time that all service
times must exceed, the exponential assumption almost certainly does not apply, so it is more
realistic to assume nonexponentially distributed service times. However, the mathematical
result mentioned previously makes this a moot point; only the mean service time matters.
USING THE SPREADSHEET MODEL TEMPLATE
The main focus here is on ps, the fraction of arriving requests that see no available ﬁre
engines. The ﬁre department wants this fraction to be no greater than 0.01. We have developed
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

a template to calculate this and other steady-state quantities. (See the ﬁle Erlang Loss
Template.xlsm and Figure 13.14.) As usual, all you need to do is enter the inputs in the
shaded range and then click on the macro button to calculate the various quantities. We
make the following comments about this template.
1
The service rate is entered as an input as usual. For this example, it is three per hour
because each service request requires 20 minutes on average. Again, there is no require-
ment that the service times be exponential with this rate; the only requirement is the rate
itself.
2
The macro calculates the steady-state distribution in columns E and F (using rather
complex formulas) and reports the last of these in cell B12. This is the fraction of arrivals
lost. The effective arrival rate, L, and W can then be calculated with simple formulas in
cells B13 to B15, as discussed earlier.
Discussion of the Results
To ensure that the ﬁre department achieves its goal of meeting at least 99% of all requests,
the number of ﬁre engines in cell B7 must be varied until the percentage of lost requests in
cell B12 is no more than 1%. We did this by trial and error; the results appear in Table 13.2.
As these results show, the required number of ﬁre engines is 15. Using this value, which
appears in Figure 13.14, the arrival rate of requests that can be serviced is 23.782. This is
the arrival rate of all requests, 24, multiplied by the probability that at least one ﬁre engine
is available, 1  0.0091. Also, you can see from cell B14 that the expected number of
requests that are being serviced at any time, L, is 7.927.
13.5 Analytical Steady-State Queueing Models
801
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
A
B
C
D
E
F
G
H
I
Erlang Loss Model
Inputs
Unit of 
r
u
o
h
e
m
it
Arrival 
r
u
o
h
/sr
e
m
o
ts
u
c
4
2
e
t
a
r
Service 
r
u
o
h
/sr
e
m
o
ts
u
c
3
e
t
a
r
Number of 
5
1
sr
e
vr
e
s
Outputs
Summary 
y
d
a
e
t
S
s
e
r
u
s
a
e
m
-state probabilies
Percentage of requests 
)
n
(
P
n
%
1
9.0
ts
ol
Entering arrival rate
23.782
customers/hour
0
0.000
Expected number in system
7.927
customers
1
0.003
Expected me in system
0.333
hours
2
0.011
3
0.029
4
0.058
5
0.092
6
0.123
7
0.141
8
0.141
9
0.125
10
0.100
11
0.073
12
0.049
13
0.030
14
0.017
15
0.009
Direcons:
1. Enter the inputs in cells B4 through B7.
2. Click on the buon below.
Calculate steady-state quanes
Figure 13.14 The Erlang Loss Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

General Multiple-Server Model7
Another interesting variation of the MMs model is to allow nonexponential interarrival
andor service times. Then we use the letter G (for general) instead of M. Speciﬁcally, the
GGs model allows any interarrival time distribution and any service time distribution.
This more general model is important for two reasons. First, data on interarrival times or
service times often indicate that the exponential distribution is not appropriate. (This is
especially true for service times in real applications.) Second, summary measures such as
W or WQ can be sensitive to the form of the interarrival time and service time distributions.
Therefore, MMs models, even those that use the appropriate mean interarrival time 
and mean service time, can give misleading results when the actual distributions are not
exponential.
The bad news is that obtaining exact analytical results for the GGs model is
extremely difﬁcult. The good news is that there is an approximation to this model that
gives sufﬁciently accurate results and can be implemented fairly easily in a spreadsheet.
This approximation is attributed to two researchers, Allen and Cunneen, and is referred to
as the Allen-Cunneen approximation (Tanner, 1995, p. 218). We illustrate it in the follow-
ing example.
802
Chapter 13
Queueing Models
Table 13.2 Outputs for the Fire Engine Example
Number of Fire Engines
Percentage of Requests Lost
12
5.1%
13
3.1
14
1.7
15
0.9
16
0.5
Access to Emergency Services on the Phone
The Erlang loss model was originally developed for the telephone industry many years
ago, but it is still relevant today. Ramaswami et al. (2005) discuss a problem faced by
AT&T customers who seek emergency service by dialing 911. The problem is that many of
them couldn’t get through because of trafﬁc congestion at the carrier’s switches (the tech-
nology that provides dial tones). Network engineers had analyzed the situation by tradi-
tional queueing methods, and they had concluded that there was no reason for congestion
because the arrival rates were not very large relative to the service rates. However, the
authors of the article probed deeper. It seems that there are two classes of customers, those
who talk on the phone and those who use the phone to connect to the Internet. Although
this latter group is a small fraction of all callers, their “calls” last a much longer time. The
authors analyzed a revised version of the Erlang loss model, one that deals with these two
classes of customers, and they were able to attribute the failure of emergency calls to get
through to the long Internet sessions. By understanding the source of the problem, they
were able to recommend solutions. ■
ADDITIONAL APPLICATIONS
7This subsection is somewhat more advanced and can be omitted without any loss in continuity.
■
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

13.5 Analytical Steady-State Queueing Models
803
E X A M P L E
13.7 REVISITING COUNTY BANK WITH NONEXPONENTIAL TIMES
T
he bank manager in Example 13.3 doubts that the exponential distribution provides a
good approximation to the actual interarrival times and service times. Therefore, he col-
lects data on successive interarrival times and service times on 127 consecutive customers.
He then calculates the means and standard deviations of these, with the results shown in
rows 5 and 6 of Figure 13.15. (See the Data sheet of the ﬁle GGs Template.xlsx.) Are these
data consistent with exponential interarrival times and service times? If not, how much do
summary measures such as WQ and LQ change if the Allen-Cunneen approximation is used
instead of the MMs model? We again assume that there are six tellers at the bank.
Data (in minutes) during peak periods
Summary of data below
Interarrival mes
Service mes
Mean
0.0064
0.0364
Stdev
0.0069
0.0543
Squared CV
1.1364
2.2243
Data
Customer
Interarrival mes
Service mes
1
0.0028
0.0037
2
0.0043
0.0096
3
0.0015
0.0330
4
0.0098
0.0012
5
0.0235
0.0376
6
0.0090
0.0127
7
0.0025
0.0521
8
0.0021
0.0156
124
0.0048
0.0267
125
0.0046
0.0395
126
0.0051
0.0058
127
0.0039
0.0181
Figure 13.15
Data for Estimating
Parameters of
Distributions
Objective
To see how an approximation to the general multiple-server model can be
implemented, and to see how sensitive steady-state measures are to the forms of the inter-
arrival and service time distributions.
WHERE DO THE NUMBERS COME FROM?
As in Example 13.1, the manager probably needs to have employees use stopwatches to
collect the data.
Solution
First, note that the estimated arrival rate from the data is the reciprocal of the average
interarrival time. The reciprocal of the value in cell B5 indicates an arrival rate of about 155
customers per hour. Similarly, the reciprocal of the average service time in cell C5 indicates
a service rate (per server) of about 27 customers per hour. These are nearly the same rates
used in Example 13.3, but are these times exponentially distributed?
One useful measure of a probability distribution of positive quantities is the squared
coefﬁcient of variation, deﬁned as the squared ratio of the standard deviation to the mean
and denoted by scv.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Squared coefﬁcient of variation
scv  (standard deviationmean)2
You might recall that the standard deviation of the exponential distribution equals the
mean, so that scv  1 for the exponential distribution. Analysts often characterize a distri-
bution as being more or less variable than an exponential distribution by seeing whether its
scv is greater than or less than 1. Intuitively, the reason is that if the mean is ﬁxed at some
value, then scv increases as the standard deviation increases. So if a nonexponential distri-
bution is compared to an exponential distribution, both of which have the same mean, the
nonexponential will exhibit more variability than the exponential if its scv is greater than 1,
and it will be less variable if its scv is less than 1. This scv measure is critical because it is
not only required by the Allen-Cunneen approximation, but it also has a big impact on the
behavior of the queueing system.
USING THE SPREADSHEET MODEL TEMPLATES
The scv values for the bank data appear in row 7 of Figure 13.15. For example, the formula
in cell B7 is =(B6B5)^2. You can see that the interarrival times are slightly more variable
and the service times are considerably more variable than they would be for exponentially
distributed times. This suggests that the MMs model might give misleading results. You
can check this by comparing the MMs results with the GGs results. To obtain the
MMs results, enter the reciprocals of the averages in row 4 of Figure 13.15 as inputs
to the MMs Template.xlsm ﬁle to obtain Figure 13.16. In particular, LQ  13.790 and 
WQ  0.089 (about 5.3 minutes per customer).
In contrast, the Allen-Cunneen approximation appears in Figure 13.17. This is from
another template ﬁle, GGs Template.xlsx, that implements this approximation. Its inputs
include not only the arrival and service rates (the reciprocals of the mean times) but also
the scv values for indicating variability. As indicated in the ﬁgure, these inputs in the
shaded cells can be entered as numbers or as links to summary measures from data, as has
been done here. (Compare cells B7 and B8 of Figure 13.17 to row 7 of Figure 13.15, for
example.) Then the approximation uses rather complex formulas in rows 11 through 20,
804
Chapter 13
Queueing Models
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
I
H
G
F
E
D
C
B
A
M/M/s Queue
Inputs
Unit of 
r
u
o
h
e
m
it
Arrival 
r
u
o
h
/sr
e
m
o
ts
u
c
7
1
4.5
5
1
e
t
a
r
Service rate per server
27.491
customers/hour
Number of 
6
sr
e
v
r
e
s
Outputs
Direct outputs from 
n
oit
u
birtsi
D
st
u
p
ni
 of number in system
Distribuon of me in queue
Mean me between arrivals
0.006
hours
n (customers)
P(n in system)
t (in hours)
P(wait > t)
Mean me per 
9
9
6.0
0
2
0.0
1
1
0
0.0
0
sr
u
o
h
6
3
0.0
e
civ
r
e
s
Traﬃc 
1
6
0
0.0
1
2
4
9.0
ytis
n
e
t
ni
2
0.0172
Summary measures
3
0.0324
P(system 
8
5
4
0.0
4
1
0
0.0
)yt
p
m
e
P(all servers 
8
1
5
0.0
5
%
5.4
8
)y
s
u
b
Expected number in system
19.443
customers
6
0.0488
Expected number in queue
13.790
customers
7
0.0460
Expected me in system
0.125
hours
8
0.0434
Expected me in queue
0.089
hours
9
0.0409
Percentage who don't wait in 
5
8
3
0.0
0
1
%
5.5
1
e
u
e
u
q
Aer entering inputs in blue cells, click on the buon below to run the 
macro that calculates P(0), the value in cell B16. Everything else recalculates 
automacally. Do not rearrange cells in this template -- this might cause the 
macro to stop behaving correctly.
Calculate steady-state quanes
Figure 13.16 Results from MMs Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

which we do not list here, to obtain the approximate summary measures in cells B17
through B20. (Note that no macro is required.)
Discussion of the Results
Comparing the MMs results in Figure 13.16 to the GGs approximation in
Figure 13.17, you can see that the values of LQ and WQ have changed considerably from
the MMs model. They are now LQ  23.177 and WQ  0.149 (or about 8.9 minutes
per customer). The reason is that congestion in a queueing system typically increases as
the interarrival time and service time distributions exhibit more variability, even if they
retain the same means. In particular, the large value of scv for the service time distribu-
tion causes considerably longer queue lengths and waiting times in the queue than in a
comparable exponential system. In short, if the bank manager uses the MMs model in
this situation, he will obtain overly optimistic results about the level of congestion in
the system.
The Allen-Cunneen approximation is evidently not well known, but it is important for
the insights it can provide. You saw in the example that, as the variability increases in the
interarrival times or the service times, the congestion tends to increase. On the other side,
this approximation allows you to see how much better a system might behave if the vari-
ability could be reduced. For example, suppose the bank has the same means as in the
example, but it is somehow able to schedule the arrivals at exactly one customer every
1155.417 hour—no uncertainty whatsoever in the arrival times. The results appear in
Figure 13.18. (The only change you have to make is to enter 0 in cell B7.) The change in
the outputs is rather dramatic. The values of WQ and LQ were 0.149 and 23.177 in the
example. Now they have decreased to 0.099 and 15.340. This is one more example of how
variability is the enemy in queueing systems.
13.5 Analytical Steady-State Queueing Models
805
Figure 13.17 The Allen–Cunneen Approximation
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
A
B
C
D
E
F
G
G/G/s template using the Allen-Cunneen approximaon
Inputs
Arrival 
7
1
4.5
5
1
e
t
a
r
Service rate per server
27.491
Number of 
6
sr
e
v
r
e
s
scv for interarrival mes
1.136
scv for service mes
2.224
Calculaons of intermediate quanes
Rao of arrival rate to service rate
5.653
Server 
2
4
9.0
n
oit
a
zilit
u
A Poisson 
0
6
7.0
ytit
n
a
u
q
Erlang C-
6
4
8.0
n
oitc
n
u
f
Important outputs
Expected wait in queue
0.149
Expected queue length
23.177
Expected wait in system
0.186
Expected number in system
28.830
Enter numbers here, or (as in this ﬁle) 
enter links to summary data from 
observed interarrival and service 
mes on another sheet.
The approximaon is valid only when 
the ulizaon in cell B12 is less than 
1.  Otherwise, it gives meaningless 
outputs.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

806
Chapter 13
Queueing Models
Figure 13.18
Queueing System
with No Variability
in the Arrival Times
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
A
B
C
D
E
F
G
G/G/s template using the Allen-Cunneen approximaon
Inputs
Arrival 
7
1
4.5
5
1
e
t
a
r
Service rate per server
27.491
Number of 
6
sr
e
v
r
e
s
scv for interarrival mes
0.000
scv for service mes
2.224
Calculaons of intermediate quanes
Rao of arrival rate to service rate
5.653
Server 
2
4
9.0
n
oit
a
zilit
u
A Poisson 
0
6
7.0
ytit
n
a
u
q
Erlang C-
6
4
8.0
n
oitc
n
u
f
Important outputs
Expected wait in queue
0.099
Expected queue length
15.340
Expected wait in system
0.135
Expected number in system
20.993
Enter numbers here, or (as in this ﬁle) 
enter links to summary data from 
observed interarrival and service 
mes on another sheet.
The approximaon is valid only when 
the ulizaon in cell B12 is less than 
1.  Otherwise, it gives meaningless 
outputs.
FUNDAMENTAL INSIGHT
Variation Is the Enem
y
Everything else being equal, increased variation in the
times between arrivals andor service times typically
leads to more congestion in the system.If arrivals can
be scheduled to occur at r egularly spaced inter vals,
or if ser vice times can be made less variable , there
will tend to be fewer periods when long waiting lines
develop. For example, imagine a doctor who sched-
ules appointments every 15 minutes and always takes
about 12 to 15 min utes per patient. There would be
no waiting!
P R O B L E M S
Skill-Building Problems
9.
A fast-food restaurant has one drive-through window.
On average, 40 customers arrive per hour at the
window. It takes an average of one minute to serve a
customer. Assume that interarrival and service times
are exponentially distributed.
a. On average, how many customers are waiting in line?
b. On average, how long does a customer spend at the
restaurant (from time of arrival to time service is
completed)?
c. What fraction of the time are more than three cars
in line? (Here, the line includes the car, if any,
being serviced.)
10. The Decision Sciences Department is trying to deter-
mine whether to rent a slow or a fast copier. The
department believes that an employee’s time is worth
$15 per hour. The slow copier rents for $4 per hour,
and it takes an employee an average of 10 minutes to
complete copying. The fast copier rents for $15 per
hour, and it takes an employee an average of six min-
utes to complete copying. On average, four employees
per hour need to use the copying machine. (Assume
the copying times and interarrival times to the copying
machine are exponentially distributed.) Which
machine should the department rent to minimize
expected total cost per hour?
11. The MM1 Template.xlsx ﬁle is now set up so that you
can enter any integer in cell E11 and the correspond-
ing probability of that many in the system appears in
cell F11. Change this setup so that columns E and F
specify the distribution of the number in the queue
rather than the system. That is, set it up so that if you
enter an integer in cell E11, the formula in cell F11
gives the probability of that many customers in the
queue. (Hint: You don’t even need to understand the
current formula in cell F11. You only need to under-
stand the relationship between the number in the
queue and the number in the system. If n are in the
system, how many are in the queue?)
12. The MM1 Template.xlsx ﬁle is now set up so that
when you enter any time value in cell H11, the for-
mula in cell I11 gives the probability that the wait in
■
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

13.5 Analytical Steady-State Queueing Models
807
queue will be greater than this amount of time.
Suppose that you would like the information to go the
other direction. That is, you would like to specify a
probability, such as 0.05, in cell I11 and obtain the
corresponding time in cell H11. Try doing this as fol-
lows with Excel’s Goal Seek tool. Use the ToolsGoal
Seek menu items to get to a dialog box. Then in this
dialog box, enter I11 as the Set cell, enter the desired
probability such as 0.05 in the By Value box, and enter
H11 as the changing cell. Use this procedure to answer
the following. In an MM1 queue where customers
are entering at rate 50 per hour and the mean service
time is one minute, ﬁnd the number of minutes t such
that there is a 5% chance of having to wait in the
queue more than t minutes.
13. Expand the MM1 Template.xlsx ﬁle so that the
steady-state probability distribution of the number in
the system is shown in tabular form and graphically.
That is, enter values 0, 1, and so on (up to some upper
limit you can choose) in the range from cell E11 down
and copy the formula in cell F11 down accordingly.
Then create a column chart using the data in columns
E and F.
14. For an MM1 queueing system, L  (µ  ).
Suppose that  and µ are both doubled. How does L
change? How does W change? How does WQ change?
How does LQ change? (Remember the basic queueing
relationships, including Little’s formula.)
15. Suppose that you observe a sequence of interarrival
times, such as 1.2, 3.7, 4.2, 0.5, 8.2, 3.1, 1.7, 4.2, 0.7,
0.3, and 2.0. For example, 4.2 is the time between the
arrivals of customers 2 and 3. If you average these,
what parameter of the MMs model are you estimat-
ing? Use these numbers to estimate the arrival rate .
If instead these numbers were observed service times,
what would their average be an estimate of, and what
would the corresponding estimate of µ be?
16. In the MMs model, where µ is the service rate per
server, explain why   µ is not the appropriate condi-
tion for steady state, but   sµ is.
17. Expand the MMs Template.xlsm ﬁle so that the steady-
state probability distribution of the number in the sys-
tem is shown in tabular form and graphically. That is,
enter values 0, 1, and so on (up to some upper limit you
can choose) in the range from cell E12 down and copy
the formula in cell F12 down accordingly. Then create
a column chart using the data in columns E and F.
18. Each airline passenger and his luggage must be
checked to determine whether he is carrying weapons
onto the airplane. Suppose that at Gotham City
Airport, 2.6 passengers per minute arrive, on average.
Also, assume that interarrival times are exponentially
distributed. To check passengers for weapons, the air-
port must have a checkpoint consisting of a metal
detector and baggage X-ray machine. Whenever a
checkpoint is in operation, two employees are
required. These two employees work simultaneously
to check a single passenger. A checkpoint can check
an average of three passengers per minute, where the
time to check a passenger is also exponentially distrib-
uted. Under the assumption that the airport has only
one checkpoint, answer the following questions.
a. Why is an MM1, not an MM2, model relevant
here?
b. What is the probability that a passenger will have
to wait before being checked for weapons?
c. On average, how many passengers are waiting in
line to enter the checkpoint?
d. On average, how long will a passenger spend at the
checkpoint (including waiting time in line)?
19. A supermarket is trying to decide how many cash reg-
isters to keep open. Suppose an average of 18 cus-
tomers arrive each hour, and the average checkout
time for a customer is four minutes. Interarrival times
and service times are exponentially distributed, and
the system can be modeled as an MMs system. (In
contrast to the situation at most supermarkets, we
assume that all customers wait in a single line.) It
costs $20 per hour to operate a cash register, and a cost
of $0.25 is assessed for each minute the customer
spends in the cash register area (in line or being
served). How many registers should the store open to
minimize the expected hourly cost?
20. A small bank is trying to determine how many tellers to
employ. The total cost of employing a teller is $100 per
day, and a teller can serve an average of 60 customers
per day. On average, 50 customers arrive per day at the
bank, and both service times and interarrival times are
exponentially distributed. If the delay cost per customer
day is $100, how many tellers should the bank hire?
21. In this problem, assume that all interarrival and service
times are exponentially distributed.
a. At present, the ﬁnance department and the market-
ing department each has its own typists. Each typist
can type 25 letters per day. Finance requires that an
average of 20 letters per day be typed, and market-
ing requires that an average of 15 letters per day be
typed. For each department, determine the average
length of time that elapses between a request for a
letter and completion of the letter.
b. Suppose that the two typists are grouped into a typ-
ing pool; that is, each typist is now available to
type letters for either department. For this arrange-
ment, calculate the average length of time between
a request for a letter and completion of the letter.
c. Comment on the results of parts a and b.
d. Under the pooled arrangement, what is the proba-
bility that more than 0.2 day will elapse between a
request for a letter and start of the letter?
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

22. MacBurger’s is attempting to determine how many
servers to have available during the breakfast shift. On
average, 100 customers arrive per hour at the restau-
rant. Each server can handle an average of 50 cus-
tomers per hour. A server costs $8 per hour, and the
cost of a customer waiting in line for one hour is $20.
Assuming that an MMs model is applicable, deter-
mine the number of servers that minimizes the
expected sum of hourly delay and service costs.
23. On average, 100 customers arrive per hour at the
Gotham City Bank. The average service time for each
customer is one minute. Service times and interarrival
times are exponentially distributed. The manager wants
to ensure that no more than 1% of all customers will
have to wait in line for more than ﬁve minutes. If the
bank follows the policy of having all customers join a
single line, how many tellers must the bank hire?
The following four problems are optional. They are
based on the limited queue and limited source models in
the Limited Queue Template.xlsm and Limited Source
Template.xlsm ﬁles.
24. A service facility consists of one server who can serve
an average of two customers per hour (service times
are exponential). An average of three customers per
hour arrive at the facility (interarrival times are
assumed to be exponential). The system capacity is
three customers: two waiting and one being served.
a. On average, how many potential customers enter
the system each hour?
b. What is the probability that the server is busy at a
typical point in time?
25. On average, 40 cars per hour are tempted to use the
drive-through window at the Hot Dog King
Restaurant. (We assume that interarrival times are
exponentially distributed.) If a total of more than four
cars are in line (including the car at the window), a car
will not enter the line. It takes an average of four
minutes (exponentially distributed) to serve a car.
a. What is the average number of cars waiting for the
drive-through window (not including the car at the
window)?
b. On average, how many cars will be served per hour?
c. You have just joined the line at the drive-through
window. On average, how long will it be before
you receive your food?
26. A laundromat has ﬁve washing machines. A typical
machine breaks down once every ﬁve days. A repair-
man can repair a machine in an average of 2.5 days.
Currently, three repairmen are on duty. The owner of
the laundromat has the option of replacing them with a
superworker, who can repair a machine in an average of
56 of a day. The salary of the superworker equals the
pay of the three regular employees. Breakdown and
service times are exponential. Should the laundromat
replace the three repairers with the superworker?
27. The limited source model can often be used to approxi-
mate the behavior of a computer’s CPU ( central pro-
cessing unit). Suppose that 20 terminals (assumed to
always be busy) feed the CPU. After the CPU responds
to a user, the user takes an average of 80 seconds before
sending another request to the CPU (this is called the
think time). The CPU takes an average of two seconds
to respond to any request. On average, how long will a
user have to wait before the CPU acts on the user’s
request? How will your answer change if there are 30
terminals? What if there are 40 terminals? Of course,
you must make appropriate assumptions about the
exponential distribution to answer this question.
Skill-Extending Problems
28. Consider an airport where taxis and customers arrive
(exponential interarrival times) with respective rates
of one and two per minute. No matter how many other
taxis are present, a taxi will wait. If an arriving
customer does not ﬁnd a taxi, the customer immedi-
ately leaves.
a. Model this system as an MM1 queue. (Hint:
Think of the taxis as the “customers.”)
b. Find the average number of taxis that are waiting
for a customer.
c. Suppose all customers who use a taxi pay a $10
fare. During a typical hour, how much revenue will
the taxis receive?
29. A bank is trying to determine which of two machines
to rent for check processing. Machine 1 rents for
$10,000 per year and processes 1000 checks per hour.
Machine 2 rents for $15,000 per year and processes
1600 checks per hour. Assume that machines work
eight hours a day, ﬁve days a week, 50 weeks a year.
The bank must process an average of 800 checks per
hour, and the average check processed is for $100.
Assume an annual interest rate of 20%. Then deter-
mine the cost to the bank (in lost interest) for each
hour that a check spends waiting for and undergoing
processing. Assuming that interarrival times and ser-
vice times are exponentially distributed, which
machine should the bank rent?
30. A worker at the State Unemployment Ofﬁce is respon-
sible for processing a company’s forms when it opens
for business. The worker can process an average of
four forms per week. In 2010, an average of 1.8 com-
panies per week submitted forms for processing, and
the worker had a backlog of 0.45 week. In 2011, an
average of 3.9 companies per week submitted forms
for processing, and the worker had a ﬁve-week back-
log. The poor worker was ﬁred but later sued to get her
job back. The court said that because the amount of
work submitted to the worker had approximately
doubled, the worker’s backlog should also have dou-
bled. Because her backlog increased by more than a
factor of 10, she must have been slacking off, so the
808
Chapter 13
Queueing Models
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

13.6 Approximating Short-Run Behavior Analytically
809
state was justiﬁed in ﬁring her. Use queueing theory to
defend the worker. (This is based on an actual case.)
31. For the MM1 queueing model, why do the following
results hold? (Hint: Remember that 1 is the mean
service time. Then think how long a typical arrival
must wait in the system or in the queue.)
a. W  (L  1)
b. WQ  L
32. Referring to Problem 18, suppose the airline wants to
determine how many checkpoints to operate to mini-
mize operating costs and delay costs over a 10-year
period. Assume that the cost of delaying a passenger
for one hour is $10 and that the airport is open every
day for 16 hours per day. It costs $1 million to pur-
chase, staff, and maintain a metal detector and bag-
gage X-ray machine for a 10-year period. Finally,
assume that each passenger is equally likely to enter a
given checkpoint, so that the “effective” arrival rate to
any checkpoint is the total arrival rate divided by the
number of checkpoints. (Assume that each checkpoint
has its own waiting line.)
33. The manager of a bank wants to use an MMs queue-
ing model to weigh the costs of extra tellers against the
cost of having customers wait in line. The arrival rate is
60 customers per hour, and the average service time is
four minutes. The cost of each teller is easy to gauge at
the $11.50 per hour wage rate. However, because esti-
mating the cost per minute of waiting time is difﬁcult,
the bank manager decides to hire the minimum number
of tellers so that a typical customer has probability 0.05
of waiting more than ﬁve minutes in line.
a. How many tellers will the manager use, given this
criterion?
b. By deciding on this many tellers as “optimal,” the
manager is implicitly using some value (or some
range of values) for the cost per minute of waiting
time. That is, a certain cost (or cost range) would
lead to the same number of tellers as suggested in
part a. What is this implied cost (or cost range)?
34. On average, 100 customers arrive per hour at Gotham
City Bank. It takes a teller an average of two minutes to
serve a customer. Interarrival and service times are
exponentially distributed. The bank currently has four
tellers working. The bank manager wants to compare the
following two systems with regard to the average number
of customers present in the bank and the probability that
a customer will spend more than eight minutes in line.
■
System 1: Each teller has his or her own line (and
no moving between lines is permitted). Arriving
customers are equally likely to choose any teller.
■
System 2: All customers wait in a single line for
the ﬁrst available teller.
If you were the bank manager, which system would
you prefer?
35. Consider the following two queueing systems.
■
System 1: An MM1 system with arrival rate 
and service rate 3µ
■
System 2: An MM3 system with arrival rate 
and each server working at rate µ
Which system will have the smaller W and L?
The following problems are optional. They are based
on the limited queue model in the Limited Queue
Template.xlsm ﬁle.
36. Two one-barber shops sit side by side in Dunkirk
Square. Each shop can hold a maximum of four people,
and any potential customer who ﬁnds a shop full will
not wait for a haircut. Barber 1 charges $15 per haircut
and takes an average of 15 minutes to complete a hair-
cut. Barber 2 charges $11 per haircut and takes an aver-
age of 10 minutes to complete a haircut. On average, 10
potential customers arrive per hour at each barber shop.
Of course, a potential customer becomes an actual
customer only if he or she ﬁnds that the shop is not 
full. Assuming that interarrival times and haircut 
times are exponential, which barber will earn more
money?
37. The small mail-order ﬁrm Sea’s Beginning has one
phone line. An average of 60 people per hour call in
orders, and it takes an average of one minute to handle a
call. Time between calls and time to handle calls are
exponentially distributed. If the phone line is busy, Sea’s
Beginning can put up to c  1 people on hold. If c  1
people are on hold, a caller gets a busy signal and calls a
competitor. Sea’s Beginning wants only 1% of all callers
to get a busy signal. How many people should it be able
to put on hold, that is, what is the required value of c?
13.6 APPROXIMATING SHORT-RUN BEHAVIOR ANALYTICALLY
Until now, we have focused on steady-state results. These are typically long-run results
where the parameters of the system, including the arrival rate, service rate, and number of
servers, remain constant. However, in many situations, these parameters vary through time,
so that steady-state results do not apply. Here are some examples.
■
A fast-food restaurant is likely to experience a much larger arrival rate during the
time from noon to 1:30 P.M. than during other hours of the day. Also, the number of
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

810
Chapter 13
Queueing Models
servers might also vary during the day, with more servers available during the 
busier periods.
■
Because most heart attacks occur during the morning, a coronary care unit experi-
ences more arrivals during the morning.
■
Most voters vote either before or after work, so a polling place tends to be less busy
during the middle of the day.
When the parameters deﬁning the queueing system vary over time, the system is nonsta-
tionary. For example, consider a fast-food restaurant that opens at 6:00 in the morning
and closes at midnight. We are interested in the probability distribution of the number of
customers present at all times between opening and closing, given that the arrival rate and
the number of servers change throughout the day. We call these transient probability
distributions because they depend on the time of day. For example, the probability of
having at least six customers in line might be greater at noon than in the middle of the
afternoon.
Many analysts approximate transient distributions with steady-state distributions. For
example, if they are interested in the distribution of line lengths during the peak lunchtime
period from, say, 11:30 A.M. until 1:00 P.M., they approximate the arrival rate for this period
and use it in the MMs steady-state model to see how the lunchtime period behaves. But
do steady-state results, which are appropriate for the long run, apply to a period of 1.5 hours?
This is a difﬁcult question to answer because it depends on a number of factors. However,
many analysts never bother to check; they just apply the steady-state results and hope for
the best. In most cases, the only viable alternative has been to create a simulation model of
the short run, as discussed in the next section. However, the downside to this is that it
requires an analyst to write a fairly complex computer program (or learn a simulation
software package).
Fortunately, as pointed out in Winston (2004), there is another alternative for approxi-
mating transient behavior of queues. Although the details are somewhat messy, this
approach can be implemented in a spreadsheet in a very natural way, as we discuss shortly.
The only assumptions we require are the following:
1.
The arrival rate, the service rate, and the number of servers can depend on time, so
they can be written as (t), (t), and s(t), where t stands for time.
2.
The probability of an arrival during a short period of time (a second, say) is propor-
tional to the arrival rate, (t), at that time. That is, if 
t is a short period of time, the
probability of an arrival during the interval from t to t  
t is approximately equal to
(t)
t. Also, the probability of more than one arrival during this short interval is
essentially zero.
3.
Similarly, the probability of a service completion during a short interval from t to
t  
t is approximately equal to bn(t)(t)
t, where bn(t) is the number of busy
servers when there are n customers in the system at time t. Again, the probability of
more than one service completion during this short interval is essentially zero.
4.
Arrivals and service completions during different periods of time are probabilistically
independent of one another.
Although it is not obvious, these are equivalent to the exponential assumptions made
in the MM1 and MMs models, except that we then required the arrival rate, the service
rate, and the number of servers to remain constant through time. Now we are essentially
continuing with the memoryless assumption of the exponential distribution, but we are
allowing the input parameters to vary over time.
The method works as follows. Let pn(t) be the probability that n customers are in the
system at time t. We start with the distribution at time 0, which is presumably known. For
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

example, if there are no customers in the system at time 0, then p0(0)  1 and pn(0)  0 for
n  0. Alternatively, if ﬁve customers are already in the system at time 0, then p5(0)  1
and pn(0)  0 for n  5. Starting with the known distribution at time 0, we then use a
bootstrap approach to calculate pn(t) for times t that are multiples of some short interval 
t.
For example, 
t might be one second or ﬁve seconds. We ﬁnd pn(
t) from pn(0), pn(2
t)
from pn(
t), pn(3
t), from pn(2
t), and so on. In other words, we pull ourselves up by our
bootstraps.
The logic for calculating these probabilities is fairly straightforward. Suppose, for
example, that the goal is to ﬁnd the probability of having n customers in the system at time
t  
t. Then, ignoring events that have negligible probabilities (two or more events, either
arrivals or service completions, in a short time interval), there are only three ways this can
happen: (1) there were n  1 customers in the system at time t and an arrival occurred in
the interval of length 
t, (2) there were n  1 customers in the system at time t and a ser-
vice completion occurred in the interval of length 
t, or (3) there were n customers in the
system at time t and no arrivals or service completions occurred in the interval of length 
t.
Using the preceding assumptions, this allows us to write
pn(t  
t)  (t)
tpn1(t)  bn1(t)(t)
tpn1(t)  [1  ((t)  bn(t)(t))
t]pn(t)
(A slight variation of this is required for n  0 and for n  N, where N represents the maxi-
mum number allowed in the system. See Winston [2004] for details.)
Admittedly, this equation is intimidating, but it is perfectly suited for spreadsheet cal-
culations. All we need to specify are (1) the arrival rate function, (t); (2) the service rate
function, (t); (3) the number of servers, s(t), at time t; and (4) some small interval of time,

t. (Note that the function bn(t), the number of busy servers, is typically the smaller of n
and s(t).) To spare you some of the details, we implemented the procedure in the ﬁle
Transient Queue Template.xlsm, which we discuss in the following example.
13.6 Approximating Short-Run Behavior Analytically
811
E X A M P L E
13.8 ANALYSIS OF LUNCHTIME RUSH
A
small fast-food restaurant is trying to model its lunchtime rush period. The restaurant
opens at 11 A.M., and all customers wait in one line to have their orders ﬁlled by a
single server. The arrival rate per hour varies considerably from one half-hour period
to the next, as shown in Table 13.3. The restaurant can serve an average of 50 people
per hour, and service times are assumed to be exponentially distributed. Management
wants to approximate the probability distribution of customers in the store from 11 A.M.
through 2 P.M.
Table 13.3 Arrival Rate
Time Period
Hourly Arrival Rate
11:00–11:30
30
11:30–Noon
40
Noon–12:30
50
12:30–1:00
60
1:00–1:30
35
1:30–2:00
25
Objective
To approximate the time-varying distribution of customers during the three-
hour lunchtime rush period.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

WHERE DO THE NUMBERS COME FROM?
The data collection process wouldn’t be much different in this example from what it was in
previous examples. However, each rate in Table 13.3 should be based on observations dur-
ing that particular half-hour period. For example, if the manager observes 14, 10, 15, 14,
16, 22, 13, 12, 19, and 15 arrivals from 11:00 to 11:30 on 10 consecutive days, he should
average these (and then multiply by 2 to convert it to an hourly rate) to approximate the
ﬁrst arrival rate in the table.
Solution
The ﬁle Transient Queue Template.xlsm has an input section you must ﬁll in, and it has
an output section, along with several output charts, that are created by a macro. You run
this macro by clicking on a button. The input section is shown in Figure 13.19. As the text
boxes indicate, you can enter any arrival rates, service rates, and numbers of servers over
any periods of time. You must also enter the number of customers initially present in the
system, which we assume to be 0 in this example.
After you enter the inputs and click on the button, the macro uses the bootstrap
approach described earlier to calculate the probability distribution for each ﬁve-second
interval (
t5 seconds). Some of the results appear in Figure 13.20. (Thousands of rows
are not shown in the ﬁgure. There are a lot of ﬁve-second intervals in a three-hour period.)
Actually, only summary measures of these distributions, not the probabilities themselves,
appear in the output. For example, the expected number in the queue and the standard devi-
ation of the number in the queue appear in cells P34 and Q34 for the ﬁve-second interval
starting at 11:01:15.
For comparison, the macro also calculates similar summary measures based on the
steady-state formulas. (These are prefaced by “SS.”) Each of these uses the input parame-
ters for its half-hour period. For example, the steady-state results are constant during the
812
Chapter 13
Queueing Models
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
A
B
C
D
E
F
G
H
I
Inputs
Inial number of customers in system
0
Clock 
k
c
olC
e
t
a
R
e
m
it
 me
Rate per server
Number of servers
Total rate
11:00 
0
0:1
1
0
3
M
A
 AM
50
1
50
11:30 
0
0:2
0
4
M
A
 PM
NA
NA
NA
12:00 PM
50
12:30 PM
60
1:00 PM
35
1:30 PM
25
2:00 PM
NA
Enter the inial number of customers in the system 
above. Then enter the hourly arrival rates below. 
The mes in column B don't have to be equally 
spaced and can extend down as far as you like. The 
last me you enter is the "ending" me for the 
model. Each rate in column C should be the arrival 
rate for that me unl the next me. E.g., the ﬁrst 
rate below, 30, indicates that customer arrive at rate 
30 per hour during the period from 11:00AM ll 
11:30AM. 
Enter the service rates and numbers of servers below in 
columns G and H. (Column I, the total rate, is for 
informaonal purposes only. It is the product of 
columns G and H, which you can compare to the arrival 
rates.) The me intervals don't need to be the same as 
for the arrival rates to the le, but the starng and 
ending mes should be the same. The rates are 
interpreted exactly as arrival rates. E.g., the data below 
indicate that from 11:00AM ll 2:00PM, 1 server is 
serving at rate 50 customers per hour.
Figure 13.19 Inputs for Lunchtime Rush
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

ﬁrst half-hour; they are based on an arrival rate of 30 per hour. As the note in the text box
indicates, these steady-state results are reported only for half-hour periods where the sys-
tem is stable; otherwise they are left blank. (Note that the system is not stable from noon
until 1:00 because the arrival rate is not less than the service rate during this period.)
The numerical output is too “dense” to make much sense to management, so several
charts are also provided by the macro. These include charts of (1) the expected number in
the system, (2) the expected number in the queue, (3) the probability that all servers are
busy, and (4) the probability that all servers are idle. Each is shown as a function of time.
For example, Figure 13.21 shows how the expected number in the queue varies through
time. It also shows upper and lower limits (plus or minus one standard deviation from the
expected value line), so you can see where the actual queue length is likely to be at any
point in time. (Remember the rule of thumb that the actual value has about a 23 chance of
being within one standard deviation of the mean.) Finally, the chart includes the steady-
state solutions for comparison. These are the horizontal lines, but they appear only in time
periods where the system is stable.
Discussion of the Results
The outputs from this ﬁle can be very useful—and very revealing. First, during periods
where the arrival rate is at least as large as the service rate, steady-state results tell us
nothing—they don’t exist for such periods. In contrast, the transient results show how the
queue grows during such periods (and then decreases as the arrival rate declines). Second,
even when the arrival rate is less than the service rate so that steady-state results exist, the
steady-state results can be very different from the transient results. For example,
13.6 Approximating Short-Run Behavior Analytically
813
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
K
L
M
N
O
P
Q
R
S
T
U
V
W
X
Y
Outputs
Clock me
ExpL
StdevL
LowerL
UpperL
ExpQ
StdevQ
LowerQ
UpperQ
PrEmpty
PrWait
SSExpL
SSExpQ
SSPrEmpty
SSPrWait
11:00:00 AM
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
1.0000
0.0000
1.5
0.9 0.39999998
0.6
11:00:05 AM
0.042
0.200
0.000
0.241
0.000
0.000
0.000
0.000
0.9583
0.0417
1.5
0.9 0.39999998
0.6
11:00:10 AM
0.080
0.278
0.000
0.359
0.002
0.042
0.000
0.043
0.9213
0.0787
1.5
0.9 0.39999998
0.6
11:00:15 AM
0.117
0.336
0.000
0.453
0.005
0.071
0.000
0.076
0.8883
0.1117
1.5
0.9 0.39999998
0.6
11:00:20 AM
0.151
0.383
0.000
0.534
0.009
0.098
0.000
0.108
0.8587
0.1413
1.5
0.9 0.39999998
0.6
11:00:25 AM
0.182
0.424
0.000
0.606
0.014
0.125
0.000
0.139
0.8321
0.1679
1.5
0.9 0.39999998
0.6
11:00:30 AM
0.212
0.459
0.000
0.671
0.021
0.150
0.000
0.170
0.8081
0.1919
1.5
0.9 0.39999998
0.6
11:00:35 AM
0.241
0.491
0.000
0.732
0.027
0.174
0.000
0.201
0.7864
0.2136
1.5
0.9 0.39999998
0.6
11:00:40 AM
0.268
0.520
0.000
0.788
0.034
0.198
0.000
0.232
0.7667
0.2333
1.5
0.9 0.39999998
0.6
11:00:45 AM
0.293
0.547
0.000
0.840
0.042
0.220
0.000
0.262
0.7488
0.2512
1.5
0.9 0.39999998
0.6
11:00:50 AM
0.317
0.572
0.000
0.889
0.050
0.242
0.000
0.292
0.7324
0.2676
1.5
0.9 0.39999998
0.6
11:00:55 AM
0.340
0.596
0.000
0.936
0.058
0.263
0.000
0.321
0.7174
0.2826
1.5
0.9 0.39999998
0.6
11:01:00 AM
0.362
0.618
0.000
0.980
0.066
0.283
0.000
0.349
0.7036
0.2964
1.5
0.9 0.39999998
0.6
11:01:05 AM
0.383
0.639
0.000
1.022
0.074
0.303
0.000
0.377
0.6909
0.3091
1.5
0.9 0.39999998
0.6
11:01:10 AM
0.404
0.659
0.000
1.062
0.083
0.322
0.000
0.405
0.6791
0.3209
1.5
0.9 0.39999998
0.6
11:01:15 AM
0.423
0.678
0.000
1.101
0.091
0.340
0.000
0.432
0.6682
0.3318
1.5
0.9 0.39999998
0.6
For each 5-second interval, the program calculates the probability distribuon of the line length 
(number of customers in the system) and uses it to calculate the summary measures below. 
ExpL and StdevL are the mean and standard deviaon of the line length, and LowerL and UpperL 
are, respecvely, 1 standard deviaon below the mean and 1 standard deviaon above the 
mean. ExpQ, StdevQ, LowerQ, and UpperQ are similar measures for the number in the queue. 
(If LowerL or LowerQ would be negave, they are replaced by 0.) PrEmpty is the probability of 
no one in the system, and PrWait is the probability that all servers are busy, so that an arriving 
customer must wait. All of these measures are graphed versus me in the charts below. For 
comparison, the steady-state (SS) measures are also calculated (for each 5-second interval) and 
are shown in yellow in the charts. If the traﬃc intensity for any me interval is >= 1, then there 
is no steady state, and that secon of the graphs is missing.
Figure 13.20 Numerical Outputs for Lunchtime Rush
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

the steady-state results for the period from 1:00 to 2:00 indicate very short queue lengths,
whereas the transient results indicate much larger queue lengths. The reason is very sim-
ple. The steady-state results fail to account for the customers who are still in line at 1:00.
These customers, who are left over from the rush the hour before, are the reason the system
doesn’t converge to steady state during the next hour. Therefore, the steady-state results
give the manager an overly optimistic picture of the hour from 1:00 to 2:00. In contrast, the
transient results take this leftover congestion into account, so they give the manager a
much more realistic view of this last hour.
Keep in mind that this approach is not simulation. No random numbers are involved,
and nothing will change if you press the F9 key. However, because we calculate the proba-
bility distributions only on every ﬁve-second interval, the results are only approximately
correct. We could make them more exact by using a one-second interval, say, but this
would require ﬁve times as many calculations (and rows of output). Because not too much
can happen in a ﬁve-second interval, this time interval should yield sufﬁciently accurate
results in most situations.
■
814
Chapter 13
Queueing Models
10 000
12.000
14.000
16.000
18.000
20.000
Expected queue length
0.000
2.000
4.000
6.000
8.000
10.000
11:00:00 AM
11:08:35 AM
11:17:10 AM
11:25:45 AM
11:34:20 AM
11:42:55 AM
11:51:30 AM
12:00:05 PM
12:08:40 PM
12:17:15 PM
12:25:50 PM
12:34:25 PM
12:43:00 PM
12:51:35 PM
1:00:10 PM
1:08:45 PM
1:17:20 PM
1:25:55 PM
1:34:30 PM
1:43:05 PM
1:51:40 PM
ExpQ
LowerQ
UpperQ
SSExpQ
Figure 13.21 Chart of Expected Line Length
P R O B L E M S
38. In the lunchtime rush example, we assumed that the
system starts empty and idle at 11 A.M. Assume now
that the restaurant opens earlier than 11 A.M., but we are
still interested only in the period from 11 A.M. to 2 P.M.
How does the initial number of customers present at
11 A.M. affect the results? Run the model six times,
varying the initial number of customers from 0 to 10 in
increments of 2. (You will need to run the macro for
each of these.) Write a short report on your ﬁndings.
39. In the lunchtime rush example, the arrival rate
changed fairly gradually throughout the period of
interest. Assume now that the arrival rate ﬁrst
increases and then decreases in a more abrupt manner.
Speciﬁcally, replace the arrival rates in the example by
the following: 15, 20, 70, 85, 30, and 20. Note that the
sum of these rates is the same as the sum of the rates
in the example, so that we expect the same total num-
ber of arrivals, but now they are more concentrated in
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

13.7 QUEUEING SIMULATION MODELS
A popular alternative to using the analytical models from the previous two sections is to
develop queueing simulations. There are several advantages to using simulation. Probably
the most important advantage is that you are not restricted to the assumptions required by
the standard analytical queueing models. These models typically require that interarrival
times and service times are exponentially distributed, customers wait in a single queue
and are served in FCFS fashion, all servers are identical in terms of their service time dis-
tributions, there are no customer types with higher priority than others, and so on.8 When
you use simulation, anything goes. If you want nonexponential service times, they are
easy to build in. If you want customers to wait in several lines, one behind each server,
and even allow them to switch queues (as they might in a supermarket), simulation can
handle it. If you want higher-priority customers to be able to “bump” lower-priority cus-
tomers out of service, this is no problem with simulation. Just about any queueing situa-
tion can be simulated.
A second advantage of queueing simulation is that you get to see the action through
time. Simulation outputs typically include not only summary measures such as the average
queue length for some period of time, but they can also include time series graphs of
important quantities such as the number of servers busy or the number of customers wait-
ing in line. In this way, you can see how queues build from time to time. In addition, you
can run a simulation many times, each time using different random numbers, to see how
one day might differ from another.
The downside of queueing simulation is that it has traditionally required a clever
computer programmer, a specialized software package, or both. Generating all of the ran-
dom quantities (interarrival times and service times, say) required by a simulation is easy.
The difﬁcult part is essentially a bookkeeping problem. Imagine that you are given a list
of customer arrival times and their corresponding service times, and you must then “play
out” the events as they would then occur through time. Say customer 17 arrives at 9:47,
sees that four customers are ahead of her in line, and all three of the servers in the system
are currently busy with customers. How do you know when customer 17 will enter ser-
vice and with which server? This is the biggest challenge in a queueing simulation—
keeping track of the state of the system as events occur through time. Special queueing
software packages are available to do all of the bookkeeping for you, but this software is
often expensive and far from trivial to master. Therefore, some people write their own pro-
grams, in C, Visual Basic, or some other language to keep track of the events. Unfortunately,
even good programmers sometimes struggle when writing queueing simulations. There are
13.7 Queueing Simulation Models
815
the noon to 1 P.M. hour. Compare the results with these
arrival rates to the results in the example. Write a short
report on your ﬁndings.
Skill-Extending Problem
40. Using the arrival rates from the lunchtime rush exam-
ple, it seems sensible to vary the number of servers so
that more servers work during the busy hours. In par-
ticular, suppose management wants to have an average
of three servers working (in parallel) in any half-hour
period, but the number working can vary across peri-
ods. Also, assume that each server has a service rate of
16 customers per hour. Experiment with ways to
deploy the servers, assuming that at least one server
must be working each half-hour period. For example,
at one extreme, you could have three servers working
each half-hour period. At the other extreme, you could
have a single server working all but one of the half-
hour periods, and 13 servers working during the other
half-hour period. Defend the deployment you think
works best in a brief report.
8There are analytical models for many “nonstandard” queueing systems, but they are mathematically too complex
for most users to understand.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

numerous details to get straight. One “small” error
can make a queueing simulation behave very dif-
ferently than intended.
We realize that most of you are not program-
mers. You want the insights that a simulation can
provide, but you do not want to develop the simula-
tions yourself. Therefore, we have developed two
fairly general simulation models that you can run.
Each is based on a program, written in Excel’s VBA
programming language, that runs in the background
and does all of the simulation bookkeeping. All you
need to do is enter the appropriate input parameters
and click on a button. The outputs then appear auto-
matically.
The ﬁrst simulation model we examine is a varia-
tion of the MMs queueing model from section 13.5.
(See the ﬁle Multiserver Simulation.xlsm .)
Customers arrive at a service center according to a
Poisson process (exponential interarrival times), they
wait (if necessary) in a single queue, and then they
are served by the ﬁrst available server. The simula-
tion model is different in the following respects from
the analytical MMs model:
■
The service times are not necessarily exponentially distributed. The ﬁle allows three
options: (1) constant (nonrandom) service times, (2) exponentially distributed service
times, and (3) gamma-distributed service times. This latter option uses the gamma dis-
tribution, which is typically shaped as in Figure 13.22. Because its mode is not neces-
sarily 0, as with the exponential distribution, it is often more realistic for service times.
By allowing three different service time distributions, you can see how different
amounts of variability in the service times affect outputs such as waiting times.
816
Chapter 13
Queueing Models
FUNDAMENTAL INSIGHT
The Value of Queueing Simulation
By now,you probably realize how mathematically difﬁ-
cult queueing anal ysis can be , especially f or under-
standing short-run behavior. Queueing simulations are
valuable because they allow you to analyze short-run
or long-run behavior under a variety of conditions for
which analytical solutions are not available.In addition,
each “iteration” of a queueing sim ulation provides a
snapshot of what might occur in a giv
en period of
time, such as a da y. That is, it allows you to see ho w
the waiting line can increase and decrease through the
day. Also, different iterations of the sim ulation allow
you to see ho w one da y can diff er drasticall y from
another in terms of congestion.The only downside to
queueing simulation is that you either have to write a
computer pr ogram to implement the logic or y
ou
have to master a simulation software package.
Figure 13.22
Typical Gamma
Distribution
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

■
The waiting room is of limited size, where this size is an input parameter. If the
queue is already this long and another customer arrives, this new customer is not
allowed to enter the system. Of course, you can enter a large value for this input, in
which case it is unlikely that any customers will be turned away.
■
The simulated run time is another user input. You might want to run a simulation for
100 hours (of simulated time) or only 10 minutes. By varying the run time, you can
see how long-run behavior differs from short-run behavior. In addition, there is a
warm-up time input. The simulation always starts empty and idle—no customers in
the system—which might not be very realistic if you want to simulate a peak period,
say, that starts with some customers already in the system. Therefore, the purpose
of the warm-up period is to allow the system to get to a “typical” busy state. No sta-
tistics are collected during the warm-up period. Statistics are collected only during
the run-time period. As an example, suppose a bank opens at 9:00 A.M., empty and
idle, and you are interested in the period from 11:30 A.M. until 1:30 P.M. Then the
warm-up period would be of length 2.5 hours, and the run time would be of length 
2 hours.
■
Every time you run the simulation, you are asked for a random number seed. The
actual number you enter is not important. The important part is that if you enter the
same seed for two different runs, you get the same stream of random numbers. This
is often useful for comparing different systems under similar conditions (the same
interarrival times and the same service times, say). Alternatively, if you enter differ-
ent seeds for two different runs, you get a different stream of random numbers on
each run. This is useful for seeing how much the system behavior can vary from one
run to the next.
These last two points enable some very important insights into queueing systems in
general. An analytical model such as the MMs model provides summary measures, typi-
cally means, in steady state. It might say, for example, that the mean time in queue per cus-
tomer is 4.85 minutes. But if you simulate such a system for two hours, say, and average
the times in queue for the simulated customers, will the average be 4.85 minutes? The
answer is a very deﬁnite no. First, the average might not be the steady-state value because
two hours might not be long enough to “get into” steady state. Second, different runs using
different random numbers will typically provide different averages. You might be sur-
prised to see how much they can vary.
We now illustrate how the simulation works by revisiting the County Bank queueing
situation (see Examples 13.3 and 13.7) with simulation.
13.7 Queueing Simulation Models
817
E X A M P L E
13.9 SIMULATING QUEUEING AT COUNTY BANK
C
ounty Bank has already used analytical models to obtain steady-state measures of
queueing behavior. However, it wonders whether these provide very realistic estimates
of what occurs during a two-hour peak period at the bank. During this peak period, arrivals
occur according to a Poisson process of two per minute, there are six tellers employed, and
each service time has a mean length of 2.7 minutes. The standard deviation of service
times is estimated at 1.5 minutes, and a histogram of historical service times has a shape
much like the shape in Figure 13.22, so that a gamma distribution appears to be reasonable.
What insights can the bank manager obtain from simulation?
Objective
To simulate the bank’s queueing system for a two-hour peak period so that we
can compare its actual behavior to the steady-state behavior predicted by MMs and
GGs analytical models.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

WHERE DO THE NUMBERS COME FROM?
The only new input here is the standard deviation of service times. As with the rest of the
inputs, it can be estimated from observed data on service times.
Solution
For comparison, we ﬁrst show results from the analytical models of section 13.5. If you use
the analytical MMs model (ignoring the fact that service times are not really exponen-
tially distributed), you obtain the results in Figure 13.23. (The value in cell B6 is 12.7, the
reciprocal of the mean service time.) For example, the mean wait in queue is WQ  3.33
minutes. If you use the analytical GGs model with the Allen-Cunneen approximation,
you obtain the results in Figure 13.24. [The values in cells B5 and B8 are 12.7 and
(1.52.7)2. The value in cell B7 is 1 because the exponential distribution has coefﬁcient of
variation 1.] The value of WQ is now 2.18. Evidently, the gamma distribution, which has a
much lower coefﬁcient of variation, results in less time in the queue.
818
Chapter 13
Queueing Models
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
I
H
G
F
E
D
C
B
A
M/M/s Queue
Inputs
Unit of 
r
u
o
h
e
m
it
Arrival 
r
u
o
h
/sr
e
m
o
ts
u
c
2
e
t
a
r
Service rate per server
0.37037
customers/hour
Number of 
6
sr
e
v
r
e
s
Outputs
Direct outputs from 
n
oit
u
birtsi
D
st
u
p
ni
 of number in system
Distribuon of me in queue
Mean me between arrivals
0.500
hours
n (customers)
P(n in system)
t (in hours)
P(wait > t)
Mean me per 
7
3
7.0
0
2
0.0
1
2
0
0.0
0
sr
u
o
h
0
0
7.2
e
civ
r
e
s
Traﬃc 
6
1
1
0.0
1
0
0
9.0
ytis
n
e
t
ni
2
0.0313
Summary measures
3
0.0564
P(system 
1
6
7
0.0
4
2
0
0.0
)yt
p
m
e
P(all servers 
2
2
8
0.0
5
%
0.4
7
)y
s
u
b
Expected number in system
12.061
customers
6
0.0740
Expected number in queue
6.661
customers
7
0.0666
Expected me in system
6.031
hours
8
0.0599
Expected me in queue
3.331
hours
9
0.0540
Percentage who don't wait in 
6
8
4
0.0
0
1
%
0.6
2
e
u
e
u
q
Aer entering inputs in blue cells, click on the buon below to run the 
macro that calculates P(0), the value in cell B16. Everything else recalculates 
automacally. Do not rearrange cells in this template -- this might cause the 
macro to stop behaving correctly.
Calculate steady-state quanes
Figure 13.23 Results from the MMs Model
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
A
B
C
D
E
F
G
G/G/s template using the Allen-Cunneen approximaon
Inputs
Arrival 
0
0
0.2
e
t
a
r
Service rate per server
0.370
Number of 
6
sr
e
v
r
e
s
scv for interarrival mes
1.000
scv for service mes
0.309
Calculaons of intermediate quanes
Rao of arrival rate to service rate
5.400
Server 
0
0
9.0
n
oit
a
zilit
u
A Poisson 
8
7
7.0
ytit
n
a
u
q
Erlang C-
0
4
7.0
n
oitc
n
u
f
Important outputs
Expected wait in queue
2.179
Expected queue length
4.359
Expected wait in system
4.879
Expected number in system
9.759
Enter numbers here, or (as in this ﬁle) 
enter links to summary data from 
observed interarrival and service 
mes on another sheet.
The approximaon is valid only when 
the ulizaon in cell B12 is less than 
1.  Otherwise, it gives meaningless 
outputs.
Figure 13.24
Results from the
GGs Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

USING THE SPREADSHEET SIMULATION MODEL
When you open the ﬁle Multiserver Simulation.xlsm, you see the Explanation sheet in
Figure 13.25. By clicking on the button, you see a couple of dialog boxes where you can
enter the required inputs. These appear in Figures 13.26 and 13.27. Note that the ﬁrst of
these asks you for a random number seed.
The simulation results appear in Figure 13.28. Again, we do not discuss all of the
details, but when the simulation runs it does the following:
■
Starts with an empty and idle system—no customers are in the bank.
■
Keeps simulating customer arrivals and service times, and keeps playing out the events
but doesn’t keep track of any customer statistics for the ﬁrst 120 minutes, the warm-up
period. It keeps track of statistics only for the next 120 minutes, the run time. (In gen-
eral, the warmup and run-time periods can be different lengths.)
13.7 Queueing Simulation Models
819
Mulserver Queueing System
This applicaon simulates a mul-server queueing system, such as at a bank, where arriving customers wait in a single line 
for the ﬁrst available server. The system starts in the "empty and idle" state and runs for a user-speciﬁed amount of me. 
The user must specify the arrival rate, the service rate per server, the number of (idencal) servers, and the maximum 
number of customers allowed in the system. (If a customer arrives when the system is full, this customer leaves.) The 
service me distribuon can be constant (no randomness), exponenal, or gamma (in which case the standard deviaon of 
the service me must also be supplied). The user also needs to specify a warmup me and a run me. The simulaon 
occurs during both of these mes, but stascs are collected only during the run me.
You can easily run several simulaons with the same or diﬀerent inputs. Each analysis is shown, along with its inputs, in a
separate Report sheet: Report_1, Report_2, and so on. For each run, you are asked for new inputs in a pair of dialog boxes. 
For  convenience, the "default" values shown in these dialog boxes aer the ﬁrst run are those from the previous run, 
which you can then modify as you like.
We suggest that you store this ﬁle somewhere safe and then, as you run simulaons, save your modiﬁed ﬁles under 
diﬀerent names. That way, you can always start with this original version.
Run the simulaon
Figure 13.25
Explanation Sheet
Figure 13.26
First Input Dialog
Box
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

■
If a customer arrives, and 10 customers are already in line, this customer is turned
away (or, if you like, the customer decides not to wait). If you want to ensure that no
one is turned away, you can choose a large value for this input.
■
Reports the summary measures for this run, as shown in Figure 13.28.
820
Chapter 13
Queueing Models
Figure 13.27
Second Input Dialog
Box
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
C
B
A
Mulple Server Queueing Simulaon
Inputs
Time 
e
t
u
ni
m
tin
u
Customer arrival 
e
t
u
ni
m
/sr
e
m
o
ts
u
c
0
0
0.2
e
t
a
r
Mean me between 
e
t
u
ni
m
0
0
5.0
sla
virr
a
Number of 
6
sr
e
v
r
e
s
Service me 
a
m
m
a
G
n
oit
u
birtsid
Mean service 
s
e
t
u
ni
m
0
0
7.2
e
m
it
Stdev of service 
s
e
t
u
ni
m
0
0
5.1
s
e
m
it
Service rate for 
e
t
u
ni
m
/sr
e
m
o
ts
u
c
2
2
2.2
m
e
ts
y
s
Maximum allowed in 
sr
e
m
o
ts
u
c
0
1
e
u
e
u
q
Simulaon warmup 
s
e
t
u
ni
m
0
2
1
e
m
it
Simulaon run 
s
e
t
u
ni
m
0
2
1
e
m
it
Random number 
1
1
1
d
e
e
s
Simulaon Outputs
Average me in queue per 
s
e
t
u
ni
m
6
0.1
r
e
m
o
ts
u
c
Maximum me a customer was in queue
4.23
minutes
Average number of customers in queue
1.86
Maximum number in 
0
1
e
u
e
u
q
Average me in system per 
s
e
t
u
ni
m
6
8.3
r
e
m
o
ts
u
c
Maximum me a customer was in system
9.45
minutes
Average number of customers in system
6.88
Maximum number in 
6
1
m
e
ts
y
s
Fracon of me each server is 
%
4.3
8
y
s
u
b
Number of customers processed
223
Number of customers turned away
2
Fracon of customers turned away
0.9%
Figure 13.28
Simulation Results
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Discussion of the Results
The outputs in Figure 13.28 should be self-explanatory. During the two-hour period, 223
customers entered the bank, and two were turned away. Each teller was busy, on average,
83.4% of the time, the average customer waited in the queue for 1.06 minutes, the average
length of the queue was 1.86, the maximum queue length was 10, and so on. You also
obtain a graph of the queue length distribution, as shown in Figure 13.29. Each bar repre-
sents the percentage of simulated time the queue length was equal to any particular value.
For example, the bar on the left shows that there was no queue at all about 48% of the time.
Clearly, the average time in queue, 1.06 minutes, is much smaller than WQ from the
MMs and GGs models. Which is the “correct” value for County Bank’s two-hour
peak period? This is not an easy question to answer. The 1.06 value from the simulation
depends to a great extent on the random numbers that happened to be generated. To illus-
trate this, we ran the simulation several more times, each with a different random number
seed, and we obtained values ranging from slightly under 0.7 to slightly over 2.1. This
shows the bank manager that the average time in queue during any day’s two-hour peak
period depends on the day. Some days she will get lucky, and other days she won’t. This
variability from day to day—that is, from run to run—is one of the most important insights
you can gain from simulation. (For your convenience, we have included another version of
the simulation in the ﬁle Multiserver Simulation Multiple Runs.xlsm that lets you spec-
ify the number of runs you want and shows selected results for each run. This allows you
to make a comparison across days.)
Besides the variability from day to day, the simulation results can depend on the length
of the run time, and they can be affected by the limited queue size. For example, we ran the
simulation for 10,000 minutes. The average time in queue did not change much, but hun-
dreds of customers were turned away. Then we changed the maximum queue size to 100
and ran the simulation again for 10,000 minutes. The average time in queue was now much
larger (over two minutes), and no customers were turned away. This illustrates that if all
customers are allowed to enter the system, the average time in queue increases, whereas if
many are turned away, the average time in queue, for those who enter, is much smaller.
■
The next example uses the same simulation model (still the Multiserver
Simulation.xlsm ﬁle) but with different inputs. Speciﬁcally, it illustrates the effect on
waiting for different service time distributions, all with the same mean. For a given mean,
the exponential distribution has the most variability, the constant distribution has the least
(none), and the gamma distribution is typically in the middle. You will see whether this
ordering carries over to average times in the queue.
13.7 Queueing Simulation Models
821
The simulation results
can vary widely from
one run to the next,
due to different
random numbers.This
often reflects
accurately what occurs
in the real world.
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
I
H
G
F
E
D
C
B
A
Probability distribuon of number in queue
Number in queue
% of me
0
47.42%
1
12.28%
2
9.29%
3
6.92%
4
6.15%
5
5.95%
6
4.88%
7
2.56%
8
1.89%
9
0.60%
10
0.27%
0.00%
5.00%
10.00%
15.00%
20.00%
25.00%
30.00%
35.00%
40.00%
45.00%
50.00%
0
1
2
3
4
5
6
7
8
9
10
Percent of Time
Number in Queue
Distribuon of Number in Queue
Figure 13.29 Queue Length Distribution
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

822
Chapter 13
Queueing Models
E X A M P L E
13.10 QUEUEING FOR HELP AT HYTEX
H
yTex is a software company that offers technical support for its customers over the
phone. The demand for help is fairly constant throughout the day, with calls arriving
at a rate of approximately 10 per minute. HyTex keeps 35 technical support lines open at
all times, and it takes 3.5 minutes, on average, to answer a customer’s question. Customers
who call when all technical support people are busy face two possible situations. If there
are fewer than 20 customers already on hold (the phone version of waiting in line), then a
new caller is also put on hold. But if 20 customers are already on hold, a new caller gets 
a busy signal and must hang up. The service times—the times to answer customers’
questions—are highly variable. HyTex wants to know how much it is suffering because of
this variability.
Objective
To use simulation to analyze the affect of the shape of the service time distri-
bution on customer waiting times.
WHERE DO THE NUMBERS COME FROM?
These inputs are estimated from the extensive call data available. However, a subtle issue
concerns the arrival rate of 10 per minute. Estimating the arrival rate of all calls is not easy
because of the difﬁculty associated with tracking calls that receive a busy signal and are
therefore lost.
Solution
This example is important because it illustrates how we can use a simulation model as a
tool to study system behavior with various input parameters.
Selection of Inputs
If the service times are highly variable, a histogram of them might resemble an exponential
distribution—that is, a lot of short calls but a few really long ones. Therefore, we ﬁrst sim-
ulate the system with exponential service times. The arrival rate is 10, the mean service
time is 3.5, the number of servers is 35, and the maximum allowable queue size is 20. With
these parameters, we used a warm-up period of 1000 minutes and a run-time period of
2000 minutes for each simulation (you can think of this as several days strung together),
and we made ﬁve runs with different random number seeds. We then changed the service
time distribution to a gamma distribution with mean 3.5 and standard deviation 2.8. (This
distribution has a squared coefﬁcient of variation 0.64, so it is not as variable as the expo-
nential distribution, which has squared coefﬁcient of variation 1.) Finally, we changed the
service time distribution to be constant with value 3.5. For both the gamma and constant
distributions, we made ﬁve runs, using the same seeds as in the exponential runs. (If you
want to mimic our results, you should use the seeds 111, 222, 333, 444, and 555.)
Discussion of the Results
Selected results appear in Table 13.4. For each simulation run, two quantities are listed: the
average time in queue for the customers who did not receive busy signals, and the fraction
of callers who received busy signals and were therefore lost. If you look only at the aver-
age times in queue, the results sometimes go in the opposite direction from what was pre-
dicted. The most variable distribution, the exponential, sometimes has the smallest times,
whereas the least variable distribution, the constant, always has the largest times. However,
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

there is a reason for this. These averages are only for the customers who were able to enter
the system. As the percentages of lost callers indicate, many more callers were lost with
the exponential than with the constant distribution, with the gamma distribution in the mid-
dle. (Over a period of 2000 minutes, with an arrival rate of 10 per minute, the system sees
about 20,000 callers. An extra 1% lost therefore translates to about 200 callers—not an
insigniﬁcant number.) With highly variable service times, customers do not wait quite as
long in the queue because there are not as many customers to wait—many of them cannot
get through at all.
So you see once again that variability is the enemy. HyTex hates to have unhappy cus-
tomers, and customers who receive busy signals are probably the unhappiest. The com-
pany should try to reduce the variability of service times, even if it cannot reduce the mean
service time. If this is not possible, there are two other possible remedies: (1) hire more
technical support people, andor (2) rent more trunk lines, so that more customers can be
put on hold.
■
Simulating a Series System with Blocking
Outputs from one queue are often inputs to another queue. This is particularly true in many
manufacturing environments, where a part has to pass through several stations in succes-
sion. At each station, a machine does a certain operation and then passes the part to the
next station. After the part has gone through each station, it goes into ﬁnished product
inventory. If each part has to pass through station 1, then station 2, and so on, the system is
called a series system. One possible series system appears in Figure 13.30. This system has
three stations. Stations 1 and 3 each have a single machine (labeled M1 and M3), whereas
station 2 has two machines (labeled M2,1 and M2,2). Each part has to be processed at M1,
then at M2,1 or M2,2, and then at M3. There can also be limited buffers (spaces for queue-
ing) in front of the stations. In the ﬁgure, there is no limit to the queue size in front of station
1 (which we will always assume), but there is room for only three parts in front of station 2
and room for only four parts in front of station 3. These limited buffers can create blocking.
As an example, suppose the buffers in front of station 2 are all full and a part ﬁnishes
processing at station 1. Then this part is blocked, which means that it cannot move from
machine M1, and this prevents other parts from entering M1 for processing. There can even
be a cascading effect, where blocking of a part at M2,1 or M2,2 eventually causes blocking
at M1. This blocking can have a serious negative effect on overall operations.
We developed a simulation, again written in VBA, for this type of system. (See the ﬁle
Series Simulation.xlsm.) This simulation allows up to 10 stations in series with any num-
ber of machines per station and any numbers of buffers in front of the stations (after station
1, which always has unlimited buffers). Parts arrive to station 1 with a given arrival rate.
We allow two possibilities: (1) a constant (nonrandom) arrival process, where parts arrive
according to a precise nonrandom schedule; and (2) a Poisson arrival process, where times
13.7 Queueing Simulation Models
823
Table 13.4 Comparison of Models
Average Time in Queue
Percentage of Callers Lost
Seed
Exponential
Gamma
Constant
Exponential
Gamma
Constant
111
0.92
0.84
0.92
4.8
3.6
3.0
222
0.81
0.80
0.85
4.1
3.1
2.3
333
0.81
0.81
0.87
4.0
3.4
2.8
444
0.80
0.82
0.88
4.7
3.5
2.8
555
0.77
0.75
0.82
3.8
2.9
2.4
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

between arrivals are exponentially distributed. Similarly, the processing (service) times for
the different stations can differ, and each can have either a constant (nonrandom) distribu-
tion or an exponential distribution. The simulation starts in the empty and idle state, there
can be a warm-up period where no statistics are collected, and then the simulation runs for
a prescribed number of minutes.
Guessing how this type of system might behave is very difﬁcult. In fact, this is the
whole purpose of the simulation. It allows a manufacturer to analyze many what-if scenar-
ios, without actually making changes to the physical system. We illustrate how this might
work in the following example.
824
Chapter 13
Queueing Models
E X A M P L E
13.11 PROCESSING PARTS AT STREAMLINING
T
he Streamlining Company manufactures various types of automobile parts. Its factory
has several production lines, all versions of the series system in Figure 13.30, with
varying numbers of stations and machines. In an effort to improve operations, the company
wants to gain some insights into how average throughput times and other output measures
are affected by various inputs. (The throughput time is the elapsed time from when a part
enters the system until it ﬁnishes processing at all stations.) Speciﬁc questions of interest
include the following:
■
Is it better to have a single fast machine at each station or multiple slower machines?
■
How much does the variability of the arrival process to station 1 affect outputs? What
about the variability of processing times at machines?
■
The company has experimented with 0 buffers and has found that the resulting block-
ing can be disastrous. It now wants to create some buffers (which entails a signiﬁcant
cost). Where should it place the buffers?
Objective
To use simulation to learn how the inputs to the system, including the conﬁg-
uration of buffers, affect such output measures as throughput times.
WHERE DO THE NUMBERS COME FROM?
The company should use reasonable inputs for the simulation, based on historical observa-
tions. However, the whole point of the simulation is to use it as a tool: to learn how outputs
are affected by varying inputs.
Solution
The simulation model in the ﬁle Series Simulation.xlsm allows you to experiment as
much as you like by changing inputs, running the simulation, and examining the outputs.
Buffers
Buffers
Arrivals
Finished
M1
M3
M2,1
M2,2
Station 1
Station 2
3-station system with multiple machines at station 2
Station 3
Figure 13.30
A Series System with
Possible Blocking
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

The inputs section appears in Figure 13.31.9 Note that 1 is the code for constant interarrival
or processing times, whereas 2 is the code for exponentially distributed times. Also, cell
B14 is black to indicate that the number of buffers in front of station 1 is always unlimited.
When you run the simulation, you obtain outputs such as those in Figure 13.32. (These are
for the inputs in Figure 13.31.) Perhaps the most important part of the outputs is in the
range B18:B21. For this particular run, you can see that the average part took 7.457 min-
utes to get through the system. Only 28.09% of this was in processing. The rest was spent
in queues or being blocked at station 1 or 2. In addition, you can see at the top of the out-
put that 10,090 parts were completed during the run-time period (some of which entered
the system during the warm-up period), and 16 parts were left uncompleted at the end of
the run time.
13.7 Queueing Simulation Models
825
9The only dialog box in this application is for a random number seed; the other inputs must be entered manually.
However, when you change the number of stations in cell B8, the shaded input range in rows 11 to 14 automati-
cally resizes to accommodate the number of stations.
1
F
E
D
C
B
A
Inputs for simulaon
1
2
3
4
5
6
7
Inputs for simulaon
Arrival process of parts to staon 1:
Distribuon (1 for constant, 2 for exponenal)
2
Arrival rate to staon 1 (parts/minute)
1.00
Conﬁguraon of process (ﬁll in the blue cells):
Enter inputs in all of the blue 
cells, then click on the buon to run 
the simulaon.
Run the simulaon
8
9
10
11
12
13
Number of staons (<= 
3
)
0
1
3
2
1
n
oit
a
tS
Number of parallel machines at staons
1
1
1
Distribuon of processing me for each machine at 
staon (1 for constant, 2 for exponenal)
2
2
2
Mean processing me (minutes) per machine
0.7
0.7
0.7
14
15
16
17
18
p
g
(
) p
Number of buﬀers in front of 
5
5
s
n
oit
a
ts
Simulaon mes (minutes)
Warmup me (no stascs collected)
1000
Run me 
10000
Figure 13.31
Inputs Section
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
E
D
C
B
A
Simulaon Outputs
Number of items processed
10090
Number le at closing
16
Part averages 
e
m
iT
)tr
a
p
/
s
e
t
u
ni
m
(
 averages
Average me in 
e
g
a
r
e
v
A
s
e
u
e
u
q
 queue lengths
Staon 
n
oit
a
tS
0
0
4.2
1
 
2
4.2
1
Staon 
n
oit
a
tS
5
6
5.1
2
 
8
5.1
2
Staon 
n
oit
a
tS
2
0
3.1
3
 
1
3.1
3
Total in all staons
5.267
Percent me processing
Average mes being 
n
oit
a
tS
d
e
k
c
olb
 
%
0
7.9
6
1
Staon 
n
oit
a
tS
6
5
0.0
1
 
%
8
3.1
7
2
Staon 
n
oit
a
tS
9
3
0.0
2
 
%
6
6.0
7
3
Total in all staons
0.095
Percent me blocked
Average throughput me
7.457
Staon 
%
5
6.5
1
Percent me in queue
70.63%
Staon 
%
5
9.3
2
Percent me being blocked
1.28%
Percent me being processed
28.09%
Figure 13.32
Simulation 
Outputs
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Turning to Streamlining’s questions, we ﬁrst examine the trade-off between fast and
slow machines. The outputs in Figure 13.33 are typical. (These results were obtained by
making multiple runs and copying the outputs from each run to a summary sheet. For each
set of inputs, we made three runs with random number seeds 111, 222, and 333.) For all of
these runs, the arrival rate is one part per minute and the mean service rate is 10.6 parts
per minute at each station. In the ﬁrst set of runs, there is a single fast machine at each
station. Each machine has an exponential processing time with mean 0.6 minute. In the
second set of runs, we triple the number of machines at each station and also triple the
mean processing time for each machine to achieve equivalent slow machines.
The use of three runs per conﬁguration indicates that different random numbers can
produce slightly different results. However, if average throughput time is of primary inter-
est, the fast machines are clearly better. Even so, the results are probably not clear-cut to a
manufacturer. For example, manufacturing companies typically like high utilization of
their machines. The slow machines have much higher utilization than the fast ones. The
826
Chapter 13
Queueing Models
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
H
G
F
E
D
C
B
A
Inputs (all use arrival rate of 1, exponenal interarrival mes, 3 staons, warmup me of 1000, run me of 10000)
3
2
1
3
2
1
n
oit
a
tS
Number of parallel machines at 
3
3
3
1
1
1
s
n
oit
a
ts
Distribuon of processing me for each machine at 
staon (1 for constant, 2 for exponenal)
2
2
2
2
2
2
Mean processing me (minutes) per machine
0.6
0.6
0.6
1.8
1.8
1.8
Number of buﬀers in front of 
5
5
5
5
s
n
oit
a
ts
Counts of parts
Run 1
Run 2
Run 3
Run 1
Run 2
Run 3
Number of items 
7
6
0
0
1
4
4
0
0
1
4
9
0
0
1
9
6
0
0
1
5
4
0
0
1
8
9
0
0
1
d
e
ss
e
c
o
r
p
Number le at 
1
1
5
4
1
5
2
7
g
nis
olc
Part averages (minutes/part)
Average me in queues
Staon 
0
9
6.0
4
8
5.0
6
2
5.0
8
3
1.1
7
5
0.1
8
7
9.0
1
Staon 
6
9
4.0
3
3
5.0
0
3
5.0
4
6
8.0
6
1
9.0
3
1
9.0
2
Staon 
7
9
4.0
6
8
4.0
0
0
5.0
7
2
8.0
1
0
8.0
2
2
8.0
3
Total in all 
3
8
6.1
4
0
6.1
5
5
5.1
9
2
8.2
4
7
7.2
3
1
7.2
s
n
oit
a
ts
Average mes being blocked
Staon 
8
3
0.0
3
4
0.0
0
4
0.0
9
1
0.0
3
2
0.0
1
2
0.0
1
Staon 
9
2
0.0
1
3
0.0
2
3
0.0
5
1
0.0
7
1
0.0
7
1
0.0
2
Total in all 
6
6
0.0
4
7
0.0
1
7
0.0
4
3
0.0
0
4
0.0
7
3
0.0
s
n
oit
a
ts
Average throughput 
1
5
1.7
5
7
0.7
2
2
0.7
3
6
6.4
4
1
6.4
9
4
5.4
e
m
it
Percent me in 
%
4
5.3
2
%
6
6.2
2
%
5
1.2
2
%
7
6.0
6
%
2
1.0
6
%
5
6.9
5
e
u
e
u
q
Percent me being 
%
3
9.0
%
5
0.1
%
2
0.1
%
2
7.0
%
7
8.0
%
2
8.0
d
e
k
c
olb
Percent me being 
%
3
5.5
7
%
9
2.6
7
%
3
8.6
7
%
1
6.8
3
%
1
0.9
3
%
3
5.9
3
d
e
ss
e
c
o
r
p
Time averages
Average queue lengths
Staon 
0
7.0
9
5.0
3
5.0
5
1.1
6
0.1
9
9.0
1
Staon 
0
5.0
4
5.0
3
5.0
7
8.0
2
9.0
2
9.0
2
Staon 
0
5.0
9
4.0
1
5.0
3
8.0
0
8.0
3
8.0
3
Percent me processing
Staon 
%
3
3.0
6
%
7
5.0
6
%
0
1.0
6
%
4
0.0
6
%
4
2.0
6
%
9
7.9
5
1
Staon 
%
4
3.0
6
%
5
5.0
6
%
7
4.1
6
%
8
0.0
6
%
8
2.0
6
%
0
2.1
6
2
Staon 
%
9
1.1
6
%
6
1.0
6
%
8
5.0
6
%
9
1.1
6
%
8
1.0
6
%
1
6.0
6
3
Percent me blocked
Staon 
%
8
9.0
%
0
1.1
%
3
0.1
%
7
8.1
%
3
3.2
%
9
0.2
1
Staon 
%
8
6.0
%
9
7.0
%
1
8.0
%
2
5.1
%
2
7.1
%
9
6.1
2
Figure 13.33 Fast Versus Slow Machines with Low Utilization
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

fast machines tend to process the parts quickly, but then the parts are often passed to a
queue. So it comes down to a trade-off between a lot of time in processing or a lot of time
in queues.
This conﬁguration might be described as low utilization . Parts arrive at rate 1 per
minute, and each mean processing time (for the fast machines) is only 0.6 minute.
Figure 13.34 shows the same type of results when the utilization is much higher. Here the
mean processing times for the fast machines have been increased to 0.9 (and tripled for the
slow machines). The buffer sizes have also been increased to 10. This system is a disaster—
take a look at the average throughput times and the average times spent in queue in front of
station 1, for example—but it does indicate a very interesting result. In terms of average
throughput time, the slow machines are now better by quite a margin. Can you see why
intuitively? The reason is that when utilization is high, one long processing time on a
13.7 Queueing Simulation Models
827
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
H
G
F
E
D
C
B
A
Inputs (all use arrival rate of 1, exponenal interarrival mes, 3 staons, warmup me of 1000, run me of 10000)
3
2
1
3
2
1
n
oit
a
tS
Number of parallel machines at 
3
3
3
1
1
1
s
n
oit
a
ts
Distribuon of processing me for each machine at 
staon (1 for constant, 2 for exponenal)
2
2
2
2
2
2
Mean processing me (minutes) per machine
0.9
0.9
0.9
2.7
2.7
2.7
Number of buﬀers in front of 
0
1
0
1
0
1
0
1
s
n
oit
a
ts
Counts of parts
Run 1
Run 2
Run 3
Run 1
Run 2
Run 3
Number of items 
4
7
0
0
1
0
5
9
9
6
7
0
0
1
5
6
9
9
2
2
9
9
2
6
9
9
d
e
ss
e
c
o
r
p
Number le at 
3
2
8
0
1
3
5
4
4
1
3
3
1
3
6
1
g
nis
olc
Part averages (minutes/part)
Average me in queues
Staon 
9
5
2.6
4
3
7
5.9
2
1
2
9.1
4
9
4
2.2
2
1
1
7
6.0
4
9
3
5.5
0
1
1
Staon 
8
0
7.5
4
0
1.5
9
1
2.6
0
4
8.5
5
7
3.5
7
6
0.6
2
Staon 
8
5
2.4
5
6
6.3
7
9
1.4
2
7
3.4
6
9
9.3
7
4
3.4
3
Total in all 
5
2
2.6
5
3
4
3.8
3
7
3
3.2
5
1
6
4.2
3
1
2
4
0.0
5
2
5
9.5
1
1
s
n
oit
a
ts
Average mes being blocked
Staon 
5
6
2.0
3
2
2.0
6
0
3.0
8
0
1.0
0
9
0.0
4
1
1.0
1
Staon 
7
3
1.0
6
1
1.0
6
5
1.0
4
5
0.0
7
4
0.0
5
5
0.0
2
Total in all 
2
0
4.0
0
4
3.0
2
6
4.0
3
6
1.0
7
3
1.0
9
6
1.0
s
n
oit
a
ts
Average throughput 
9
9
7.4
6
4
7
6.6
4
0
5
8.0
6
0
6
1.5
3
1
0
8
7.2
5
4
4
6.8
1
1
e
m
it
Percent me in 
%
7
7.6
8
%
5
1.2
8
%
1
0.6
8
%
0
0.8
9
%
1
8.4
9
%
3
7.7
9
e
u
e
u
q
Percent me being 
%
2
6.0
%
3
7.0
%
6
7.0
%
2
1.0
%
6
2.0
%
4
1.0
d
e
k
c
olb
Percent me being 
%
1
6.2
1
%
2
1.7
1
%
3
2.3
1
%
8
8.1
%
3
9.4
%
3
1.2
d
e
ss
e
c
o
r
p
Time averages
Average queue lengths
Staon 
4
6.6
4
7
8.9
2
8
2.2
4
2
7.2
2
1
7
0.1
4
9
3.6
0
1
1
Staon 
6
7.5
8
0.5
7
2.6
2
8.5
4
3.5
4
0.6
2
Staon 
9
2.4
5
6.3
3
2.4
6
3.4
6
9.3
3
3.4
3
Percent me processing
Staon 
%
9
5.3
9
%
2
4.2
9
%
8
3.3
9
%
0
2.9
8
%
2
4.9
8
%
8
5.8
8
1
Staon 
%
7
8.1
9
%
7
9.0
9
%
2
3.3
9
%
1
0.9
8
%
3
2.9
8
%
1
2.0
9
2
Staon 
%
0
8.1
9
%
7
2.9
8
%
8
6.0
9
%
6
6.0
9
%
4
0.9
8
%
1
6.9
8
3
Percent me blocked
Staon 
%
5
5.5
%
8
6.4
%
3
4.6
%
8
7.0
1
%
6
9.8
%
9
3.1
1
1
Staon 
%
1
9.2
%
0
4.2
%
1
3.3
%
3
4.5
%
4
6.4
%
8
4.5
2
Figure 13.34 Fast versus Slow Machines with High Utilization
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

fast machine—which is always a possibility with an exponential distribution—can back up
the whole system for a long time. If there are multiple machines, however, parts can “move
around” a machine experiencing a long processing time, and the whole system is not as
affected. You might have guessed this before running the simulation, but simulation 
conﬁrms it.
Streamlining’s next question concerns the variability of arrival and processing times.
Here we examine a three-station process, with one machine at each station and ﬁve buffers
in front of stations 2 and 3. Parts arrive at a rate of one per minute, and the average service
time is 0.7 minute at each machine. Figure 13.35 lists some results. In columns B and C,
interarrival times and processing times are exponential. In columns D and E, interarrival
times are constant and processing times are exponential. This might be realistic if the com-
pany releases one part to the line every minute according to a nonrandom schedule. In
columns F and G, interarrival times are exponential and processing times are constant.
Finally, both are constant in column H. We made two runs for each of the random cases. Of
course, only one run is necessary for the nonrandom case. By this time, these results should
not come as a surprise. The more the company can do to decrease variability, the better the
manufacturing process will operate.
Finally, we analyze the affect of buffers and their placement. We now assume a 10-
station process with a single machine at each station. The parts arrive at the rate of one 
per minute, each machine has a mean processing time of 0.5 minute, and all times are
828
Chapter 13
Queueing Models
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
H
G
F
E
D
C
B
A
Constant versus exponenal interarrival or service mes
Each run has arrival rate 1, 3 staons with 1 machine each, mean service me 0.7, 5 buﬀers at staons 2 and 3, warmup me 1000, and run me 10000
Both const
Count of parts
Run 1
Run 2
Run 1
Run 2
Run 1
Run 2
Run 1
Number of items processed
10090
10039
10004
9999
10098
10042
10000
Number le at 
6
1
g
nis
olc
8
4
5
3
2
2
Part averages (minutes/part)
Average me in queues
Staon 
0
0
0.0
8
3
8.0
9
8
7.0
1
3
6.0
7
8
5.0
5
3
9.2
0
0
4.2
1
Staon 
0
0
0.0
0
0
0.0
0
0
0.0
6
2
0.1
7
1
0.1
5
6
5.1
5
6
5.1
2
Staon 
0
0
0.0
0
0
0.0
0
0
0.0
8
4
0.1
5
6
0.1
4
4
2.1
2
0
3.1
3
Total in all 
0
0
0.0
8
3
8.0
9
8
7.0
4
0
7.2
0
7
6.2
4
4
7.5
7
6
2.5
s
n
oit
a
ts
Average mes being blocked
Staon 
0
0
0.0
0
0
0.0
0
0
0.0
5
1
0.0
3
1
0.0
2
6
0.0
6
5
0.0
1
Staon 
0
0
0.0
0
0
0.0
0
0
0.0
9
1
0.0
8
1
0.0
7
3
0.0
9
3
0.0
2
Total in all 
0
0
0.0
0
0
0.0
0
0
0.0
4
3
0.0
1
3
0.0
0
0
1.0
5
9
0.0
s
n
oit
a
ts
Average throughput me
7.457
7.941
4.799
4.837
2.889
2.939
2.100
Percent me in 
%
0
0.0
%
2
5.8
2
%
9
2.7
2
%
1
9.5
5
%
3
6.5
5
%
3
3.2
7
%
3
6.0
7
e
u
e
u
q
Percent me being blocked
1.28%
1.25%
0.65%
0.71%
0.00%
0.00%
0.00%
Percent me being processed
28.09%
26.42%
43.72%
43.39%
72.71%
71.48%
100.00%
Time averages
Average queue lengths
Staon 
0
0.0
4
8.0
0
8.0
3
6.0
9
5.0
5
9.2
2
4.2
1
Staon 
0
0.0
0
0.0
0
0.0
3
0.1
2
0.1
7
5.1
8
5.1
2
Staon 
0
0.0
0
0.0
0
0.0
5
0.1
7
0.1
5
2.1
1
3.1
3
Percent me processing
Staon 
%
1
0.0
7
%
0
3.0
7
%
9
6.0
7
%
4
9.9
6
%
6
1.9
6
%
7
2.0
7
%
0
7.9
6
1
Staon 
%
1
0.0
7
%
0
3.0
7
%
9
6.0
7
%
3
0.0
7
%
8
5.0
7
%
7
2.0
7
%
8
3.1
7
2
Staon 
%
1
0.0
7
%
0
3.0
7
%
9
6.0
7
%
0
9.9
6
%
1
0.0
7
%
6
1.0
7
%
6
6.0
7
3
Percent me blocked
Staon 
%
0
0.0
%
0
0.0
%
0
0.0
%
8
4.1
%
0
3.1
%
6
2.6
%
5
6.5
1
Staon 
%
0
0.0
%
0
0.0
%
0
0.0
%
4
9.1
%
2
8.1
%
4
7.3
%
5
9.3
2
Exp arrivals, Exp services
Const arrivals, Exp services
Exp arrivals, Const services
Figure 13.35 Constant versus Exponential Times
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

exponentially distributed. You might expect that when parts arrive only half as fast as the
machines can process them, there should not be much congestion. This is not true, espe-
cially if buffers are severely limited. We made several runs, starting with 0 buffers in the
system and gradually adding buffers. Selected results for average throughput times appear
in Figure 13.36. When there are no buffers, blocking kills the system. This might not be
evident from the percentages listed, because each part spends only a small amount of time
being blocked. But there is almost always blocking somewhere in the system, and the
effect is that a long queue eventually builds in front of station 1.
Suppose Streamlining has enough funds to build exactly one buffer somewhere. Where
should the buffer be placed? We made nine runs, placing the single buffer in front of each
station, with the results in rows 19 to 22. Clearly, the single buffer should be placed in the
middle of the line, in front of station 6. Placing it at the front or the back of the line does vir-
tually no good. The reason is probably not intuitive, at least not until we provide the clue.
The basic problem with this serial system is the interdependence among stations. A long
processing time at one station can have negative effects throughout the entire line. Upstream
stations (to the left) become blocked, and downstream stations (to the right) become starved
for parts to process. Placing a buffer in the middle of the line does the most to break the line
into two less dependent subsystems. This effect can be seen by continuing to add buffers
one at a time. When there are two buffers, one should be placed about a third of the way
13.7 Queueing Simulation Models
829
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
K
J
I
H
G
F
E
D
C
B
A
Eﬀect on throughput of adding buﬀers
For each run, arrival process has rate 1, exponenal interarrival mes, warmup me 1000, and run me 10000
Staon inputs are as follows, with only the buﬀers in row 10 changing from one run to the next
Staon
1
2
3
4
5
6
7
8
9
10
Number of parallel machines at staons
1
1
1
1
1
1
1
1
1
1
Distribuon of processing me for each machine at 
staon (1 for constant, 2 for exponenal)
2
2
2
2
2
2
2
2
2
2
Mean processing me (minutes) per machine
0.5
0.5
0.5
0.5
0.5
0.5
0.5
0.5
0.5
0.5
Number of buﬀers in front of staons
0
0
0
0
0
0
0
0
0
No buﬀers
Average throughput 
2
0
3.7
3
8
e
m
it
Percent me in 
%
1
1.9
9
e
u
e
u
q
Percent me being 
%
3
4.0
d
e
k
c
olb
Percent me being 
%
7
4.0
d
e
ss
e
c
o
r
p
Exactly 1 buﬀer in system
At 2
At 3
At 4
At 5
At 6
At 7
At 8
At 9
At 10
Average throughput 
3
8
7.1
8
7
8
3
1.6
3
7
4
3
0.9
8
6
1
2
0.6
4
6
3
2
3.7
3
6
0
9
7.5
4
6
5
1
4.8
6
6
3
6
1.7
1
7
7
8
8.4
7
7
e
m
it
Percent me in 
%
3
1.9
9
%
5
0.9
9
%
6
9.8
9
%
8
8.8
9
%
5
8.8
9
%
5
8.8
9
%
8
8.8
9
%
5
9.8
9
%
6
0.9
9
e
u
e
u
q
Percent me being 
%
1
4.0
%
2
4.0
%
5
4.0
%
9
4.0
%
2
5.0
%
4
5.0
%
4
5.0
%
2
5.0
%
8
4.0
d
e
k
c
olb
Percent me being 
%
6
4.0
%
3
5.0
%
9
5.0
%
3
6.0
%
3
6.0
%
1
6.0
%
8
5.0
%
3
5.0
%
6
4.0
d
e
ss
e
c
o
r
p
Exactly 2 buﬀers in system
At 2,10
At 3,9
At 4,8
At 5,7
Both at 6
Average throughput 
3
9
6.2
4
5
8
3
2.1
4
4
0
1
7.0
7
4
5
7
5.7
7
5
6
8
3.0
1
7
e
m
it
Percent me in 
%
4
6.8
9
%
4
3.8
9
%
3
4.8
9
%
6
7.8
9
%
9
9.8
9
e
u
e
u
q
Percent me being 
%
9
5.0
%
0
7.0
%
6
6.0
%
5
5.0
%
7
4.0
d
e
k
c
olb
Percent me being 
%
7
7.0
%
6
9.0
%
1
9.0
%
9
6.0
%
4
5.0
d
e
ss
e
c
o
r
p
Exactly 3 buﬀers in system
At 2,6,10
At 3,6,9
At 4,6,8
At 5,6,7
Average throughput 
5
0
1.4
2
3
3
5
9.2
7
2
1
6
3.4
4
3
5
4
5.9
7
4
e
m
it
Percent me in 
%
4
7.7
9
%
9
2.7
9
%
6
8.7
9
%
6
4.8
9
e
u
e
u
q
Percent me being 
%
2
9.0
%
6
0.1
%
6
8.0
%
4
6.0
d
e
k
c
olb
Percent me being 
%
4
3.1
%
4
6.1
%
9
2.1
%
0
9.0
d
e
ss
e
c
o
r
p
Many buﬀers in system
1 at each
2 at each
5 at each 20 at each
Average throughput 
6
8
9.9
7
9
9.9
9
9
3.0
1
7
8
7.2
1
e
m
it
Percent me in 
%
2
0.0
5
%
8
5.9
4
%
9
8.6
4
%
8
6.9
4
e
u
e
u
q
Percent me being 
%
0
0.0
%
9
4.0
%
3
1.5
%
2
3.1
1
d
e
k
c
olb
Percent me being 
%
8
9.9
4
%
2
9.9
4
%
9
9.7
4
%
1
0.9
3
d
e
ss
e
c
o
r
p
Figure 13.36 Buffers and Their Placement
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

down the line, and the other should be placed about two-thirds of the way down, breaking
the line into three approximately equal sections. Similarly, when there are three buffers,
they should be placed to break the line into four approximately equal sections.
The bottom section of Figure 13.36 indicates the saturation effect of adding more
buffers. The company gets a lot from its money from the ﬁrst few buffers, but after the ﬁrst
few, blocking becomes a minor problem and more buffers fail to make much of an
improvement. If buffers entail signiﬁcant costs, Streamlining must trade off these costs
against lower average throughput times and possibly other considerations.
■
830
Chapter 13
Queueing Models
Improving Car Body Production at PSA Peugeot Citroen
In 1998, the new CEO of PSA Peugeot Citroen, the French carmaker, decided to set ambi-
tious targets for growth, innovation, and proﬁtability. To meet these targets, PSA decided to
focus on the car-body shops, the bottlenecks at its plants. An R&D team conducted a man-
agement science study of car-body production, using a number of analytic tools, including a
simulation model of series-parallel systems. They used this simulation to analyze a number
of different conﬁgurations of manufacturing stations and buffers in the manufacturing line,
and they were able to persuade PSA to implement the best of these conﬁgurations. They
estimate that their study contributed $130 million to the bottom line in 2001 alone, with
minimal capital investment and no compromise in quality.
■P
ADDITIONAL APPLICATIONS
P R O B L E M S
Skill-Building Problems
41. The Smalltown Credit Union experiences its greatest
congestion on paydays from 11:30 A.M. until 1:00 P.M.
During these rush periods, customers arrive according
to a Poisson process at rate 2.1 per minute. The credit
union employs 10 tellers for these rush periods, and
each takes 4.7 minutes to service a customer.
Customers who arrive to the credit union wait in a
single queue, if necessary, unless 15 customers are
already in the queue. In this latter case, arriving
customers are too impatient to wait, and they leave the
system. Simulate this system to ﬁnd the average wait
in queue for the customers who enter, the average
number in queue, the percentage of time a typical
teller is busy, and the percentage of arrivals who do
not enter the system. Try this simulation under the
following conditions and comment on your results.
For each condition, make three separate runs, using
a different random number seed on each run.
a. Try a warm-up time of two hours. Then try no
warm-up time. Use exponentially distributed
service times for each.
b. Try exponentially distributed service times. Then
try gamma-distributed service times, where the
standard deviation of a service time is 2.4 minutes.
Use a warm-up period of one hour for each.
c. Try 10 tellers, as in the statement of the problem. Then
try 11, then 12. Use exponentially distributed service
times and a warm-up period of one hour for each.
d. Why might the use of a long warm-up time bias the
results toward worse system behavior than would
actually be experienced? If you could ask the pro-
grammer of the simulation to provide another option
concerning the warm-up period, what would it be?
(Hint: The real rush doesn’t begin until 11:30.)
42. How long does it take to reach steady state? Use simu-
lation, with the Multiserver Simulation.xlsm ﬁle, 
to experiment with the effect of warm-up time and run
time on the key outputs. For each of the following,
assume a ﬁve-server system with a Poisson arrival rate
of one per minute and gamma-distributed service
times with mean 4.0 minutes and standard deviation
3.1 minutes. For each part, make three separate runs,
using a different random number seed on each run.
a. Use a warm-up time of 0 and a run time of 
30 minutes.
b. Use a warm-up time of 0 and a run time of 
180 minutes.
c. Use a warm-up time of 120 minutes and a run time
of 30 minutes.
d. Use a warm-up time of 120 minutes and a run time
of 180 minutes.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

e. Repeat parts a to d when the mean and standard
deviation of service times are 4.8 and 4.2 minutes,
respectively. (This should produce considerably
more congestion.)
43. Given the model in the Multiserver Simulation.xlsm
ﬁle, what unit cost parameters should be used if we are
interested in “optimizing” the system? Choose represen-
tative inputs and unit costs, and then illustrate how to use
the simulation outputs to estimate total system costs.
44. Simulate the system in Problem 10. Make any assump-
tions about the warm-up time and run time you believe
are appropriate. Try solving the problem with expo-
nentially distributed copying times. Then try it with
gamma-distributed copying times, where the standard
deviation is 3.2 minutes. Do you get the same recom-
mendation on which machine to purchase?
45. In Example 13.4 of section 13.5, we examined
whether an MM1 system with a single fast server is
better or worse than an MMs system with several
slow servers. Keeping the same inputs as in the exam-
ple, use simulation to see whether you obtain the same
type of results as with the analytical models. Then
repeat, using gamma-distributed service times with
standard deviation six minutes.
46. A telephone-order sales company must determine
how many telephone operators are needed to staff the
phones during the 9-to-5 shift. It is estimated that an
average of 480 calls are received during this time
period and that the average call lasts for six minutes.
There is no queueing. If a customer calls and all oper-
ators are busy, this customer receives a busy signal 
and must hang up. If the company wants to have at
most one chance in 100 of a caller receiving a busy
signal, how many operators should be hired for the 
9-to-5 shift? Base your answer on an appropriate sim-
ulation. Does it matter whether the service times are
exponentially distributed or gamma distributed?
Experiment to ﬁnd out.
13.8 Conclusion
831
47. US Airlines receives an average of 500 calls per hour
from customers who want to make reservations, where
the times between calls follow an exponential distribu-
tion. It takes an average of three minutes to handle
each call. Each customer who buys a ticket contributes
$100 to US Airlines proﬁt. It costs $15 per hour to
staff a telephone line. Any customer who receives a
busy signal will purchase a ticket from another airline.
How many telephone lines should US Airlines have?
Base your answer on an appropriate simulation.
Does it matter whether the service times are exponen-
tially distributed or gamma distributed? Experiment
to ﬁnd out.
Skill-Extending Problems
48. Consider a series system of the type in the Series
Simulation.xlsm ﬁle. There are two stations. Each sta-
tion has three machines, and the mean processing time
for each machine is 3.1 minutes. Parts arrive to station
1 at a Poisson rate of 0.8 per minute. The processing
times at one station are constant; at the other, they are
exponentially distributed. Where would you rather
have the constant processing times—at station 1 or
station 2? Does the answer depend on the number of
buffers in front of station 2? Experiment to ﬁnd out.
49. A company’s warehouse can store up to four units of a
good. Each month, an average of 10 orders for the
good are received. The times between the receipts of
successive orders are exponentially distributed. When
an item is used to ﬁll an order, a replacement item is
immediately ordered, and it takes an average of one
month for a replacement item to arrive. If no items are
on hand when an order is received, the order is lost.
Use simulation to estimate the fraction of all orders
that will be lost due to shortage. (Hint: Let the storage
space for each item be a “server” and think about what
it means for a server to be busy. Then decide on an
appropriate deﬁnition of “service time.”)
13.8 CONCLUSION
This chapter has presented two basic approaches for analyzing queueing systems. The ﬁrst
is the analytical approach, where the goal is to ﬁnd formulas (or possibly algorithms,
implemented with macros) to calculate steady-state performance measures of the system.
The second is the simulation approach, where the random elements of the system are
generated and then the events are played out as they occur through time. The advantage of
the analytical approach is that, at least for the simplest models, it provides summary
measures such as LQ and WQ that are relatively simple to interpret. Also, by using template
ﬁles for these systems, it is easy to vary the inputs to see how the outputs change. The main
disadvantage of the analytical approach is that the mathematics becomes extremely
complex unless simplifying assumptions are made, some of which can be unrealistic. For
example, service times are typically assumed to be exponentially distributed, an unrealistic
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

assumption in many real applications. Also, the arrival rate typically must remain constant
through time to ﬁnd steady-state results (unless the approximate approach in section 13.6
is used).
The simulation approach provides much more ﬂexibility. Also, simulation lets you
“see” how the system behaves and how queues can build up through time. The disadvan-
tage of queueing simulation is that it is not well suited to spreadsheets. You have two basic
choices: buy (and learn) specialized queueing software packages or write your own queue-
ing simulation in a procedural language such as VBA. Neither possibility is very attractive.
However, the two general queueing simulation models we have provided in the
Multiserver Simulation.xlsm and the Series Simulation.xlsm ﬁles allow you to experi-
ment with many system conﬁgurations to see how inputs and inherent randomness affect
system outputs. The insights gained can be extremely valuable.
Summary of Key Management Science Terms
Term
Explanation
Page
Analytical queueing 
Models where outputs such as expected waiting time
775
models
in queue can be calculated directly from inputs such as
arrival rate and service rate
Queueing simulation 
Models where the events in a queueing process 
775
model
play out over time, using simulated random
numbers and careful bookkeeping
Interarrival times
Times between successive arrivals
776
Parallel system
Queueing system, such as at a bank, where each
777
customer must be served by exactly one of (usually 
equivalent) servers
Steady-state analysis 
Analysis of the long run, where the effects of initial
778
conditions have been washed out
Stable system
A system where the queue doesn’t grow inﬁnitely 
779
large in the long run
Exponential distribution,
A popular distribution for queueing systems, 
779
memoryless property
characterized by the memoryless property, where the 
future, given the current state, is independent of the past
Poisson process model
Series of events, such as customer arrivals, where 
783
times between events are exponentially distributed
Time averages
Averages, such as average queue length, taken over time
784
Customer averages
Averages, such as average waiting time, taken over 
784
customers
Little’s formula
Important formula that relates time averages to 
785
customer averages
Server utilization
Average fraction of time a typical server is busy
786
MM1 and MMs
Simplest and most common analytical queueing 
787
models
models, where interarrival times and service times are 
exponentially distributed, and there is either a single 
server or multiple servers in parallel
Trafﬁc intensity
A measure of congestion; typically, the arrival rate 
787
divided by the maximum service rate
Limited waiting room
Models where customers are turned away if the 
798
models
number of customers in the system is already at some 
maximum level
832
Chapter 13
Queueing Models
(continued)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Term
Explanation
Page
Limited source models
Models where a ﬁnite number of customers are in the 
799
population, so that the arrival rate depends on how 
many of them are currently in service
Erlang loss model
Model where no customer arrivals are allowed when 
799
all servers are busy
GGs model
General multiserver model, where interarrival times 
802
and service times are allowed to have any probability 
distributions
Squared coefﬁcient of 
Measure of variability: squared ratio of standard 
803
variation
deviation to mean
Transient probability
Short-run distribution of the state of the system, 
810
distribution
particularly useful when parameters of the system 
change over time
Summary of Key Excel Terms
Term
Explanation
Excel
Page
Queueing templates
Ready-made spreadsheet ﬁles
See the
789, 796, etc.
that implement complex 
MM1 Template.xlsx ﬁle,
queueing models, often with 
for example
behind-the-scenes macros
13.8 Conclusion
833
P R O B L E M S
Skill-Building Problems
50. Referring to the multistation serial system in the
Series Simulation.xlsm ﬁle, let si and 1µi be the
number of machines and the mean processing time at
station i. Then the mean processing rate at station i is
siµi. You might expect the system to operate well only
if each siµi is greater than , the arrival rate to station
1. This problem asks you to experiment with the
simulation to gain some insights into congestion.
For each of the following parts, assume a Poisson
arrival rate of   1 per minute, and assume that
processing times are exponentially distributed. Each
part should be answered independently. For each,
you should discuss the most important outputs from
your simulation.
a. Each station has si  1 and the µis are constant
from station to station. There are 100 (essentially
unlimited) buffers in front of all stations after sta-
tion 1. Each processing time has mean 1µi  0.6
minute and there are three stations.
b. Same as part a, except that there are 10 stations.
c. Same as part a, except that each processing time
has mean 0.9 minute.
d. Same as part c, except that there are 10 stations.
e. Repeat parts a to d but now assume there are only
two buffers in front of each station.
51. Repeat the previous problem, but now assume that
si  3 at each station. Change the µis so that the prod-
ucts siµi are the same as in the previous problem.
52. Continuing Problem 50, you might expect that the sys-
tem will be only as good as the station with the small-
est value of siµi (called the bottleneck station). This
problem asks you to experiment with the simulation to
gain some insights into bottlenecks. For each of the
following parts, assume a Poisson arrival rate of   1
per minute, and assume that processing times are
exponentially distributed. Each station has si  1 and
there are ﬁve stations. Each station, except for the
bottleneck station, has a processing time mean of 1µi 
0.6 minute. The bottleneck station has mean 0.9
minute. Each part should be answered independently.
For each, you should discuss the most important out-
puts from your simulation.
a. Suppose there are 100 (essentially unlimited)
buffers in front of all stations after station 1. Run the
simulation when station 1 is the bottleneck. Repeat
when it is station 2; station 3; station 4; station 5.
b. Repeat part a when there are only two buffers in
front of each station after station 1.
c. Suppose station 3 is the bottleneck station and you
have 4 buffers to allocate to the whole system.
Experiment to see where they should be placed.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

53. On average, 50 customers arrive per hour at a small
post ofﬁce. Interarrival times are exponentially distrib-
uted. Each window can serve an average of 25 cus-
tomers per hour. Service times are exponentially
distributed. It costs $25 per hour to open a window,
and the post ofﬁce values the time a customer spends
waiting in line at $15 per customer hour. To minimize
expected hourly costs, how many postal windows
should be opened?
54. On average, 300 customers arrive per hour at a huge
branch of Bank 2. It takes an average of two minutes
to serve each customer. It costs $10 per hour to keep a
teller window open, and the bank estimates that it will
lose $50 in future proﬁts for each hour that a customer
waits in line. How many teller windows should Bank 2
open?
55. Ships arrive at a port facility at an average rate of two
ships every three days. On average, it takes a single crew
one day to unload a ship. Assume that interarrival and
service times are exponential. The shipping company
owns the port facility as well as the ships using that
facility. The company estimates that it costs $1000 per
day for each day that a ship spends in port. The crew ser-
vicing the ships consists of 100 workers, each of whom
is paid an average of $30 per day. A consultant has rec-
ommended that the shipping company hire an additional
40 workers and split the employees into two equal-size
crews of 70 each. This would give each crew an average
unloading or loading time of 1.5 days. Which crew
arrangement would you recommend to the company?
56. A printing shop receives an average of one order per
day. The average length of time required to complete
an order is half a day. At any given time, the print shop
can work on at most one job. Interarrival times and
service times are exponentially distributed.
a. On average, how many jobs are present in the print
shop?
b. On average, how long will a person who places an
order have to wait until it is ﬁnished?
c. What is the probability that an order will begin
work within two days of its arrival?
57. On average, 40 jobs arrive per day at a factory. The
time between arrivals of jobs is exponentially distrib-
uted. The factory can process an average of 42 jobs
per day, and the time to process a job is exponentially
distributed.
a. On average, how long does it take before a job is
completed (measured from the time the job arrives
at the factory)?
b. What fraction of the time is the factory idle?
c. What is the probability that work on a job will
begin within two days of its arrival at the factory?
58. At the Franklin Post Ofﬁce, patrons wait in a single
line for the ﬁrst open window. On average, 100
patrons enter the post ofﬁce per hour, and each
834
Chapter 13
Queueing Models
window can serve an average of 45 patrons per hour.
The post ofﬁce estimates a cost of $0.10 for each
minute a patron waits in line and believes that it costs
$20 per hour to keep a window open. Interarrival times
and service times are exponential.
a. To minimize the total expected hourly cost, how
many windows should be open?
b. If the post ofﬁce’s goal is to ensure that at most 5%
of all patrons will spend more than ﬁve minutes in
line, how many windows should be open?
59. The manager of a large group of employees must decide
whether she needs another photocopying machine. The
cost of a machine is $40 per eight-hour day regardless
of whether the machine is in use. On average, four peo-
ple need to use the copying machine per hour. Each per-
son uses the copier for an average of 10 minutes.
Interarrival times and copying times are exponentially
distributed. Employees are paid $8 per hour, and we
assume that a waiting cost is incurred when a worker is
waiting in line or is using the copying machine. How
many copying machines should be rented?
60. The Newcoat Painting Company has for some time
been experiencing high demand for its automobile
repainting service. Because it has had to turn away
business, management is concerned that the limited
space available to store cars awaiting painting has cost
them in lost revenue. A small vacant lot next to the
painting facility has recently been made available for
rental on a long-term basis at a cost of $10 per day.
Management believes that each lost customer costs $20
in proﬁt. Current demand is estimated to be 21 cars per
day with exponential interarrival times (including those
turned away), and the facility can service at an expo-
nential rate of 24 cars per day. Cars are processed on a
FCFS basis. Waiting space is now limited to 9 cars but
can be increased to 20 cars with the lease of the vacant
lot. Newcoat wants to determine whether the vacant lot
should be leased. Management also wants to know the
expected daily lost proﬁt due to turning away cus-
tomers if the lot is leased. Only one car can be painted
at a time. Try using the Limited Queue Template.xlsm
ﬁle for an analytical solution and the Multiserver
Simulation.xlsm ﬁle for a simulation solution.
61. On average, 90 patrons arrive per hour at a hotel lobby
(interarrival times are exponential) waiting to check in.
At present there are ﬁve clerks, and patrons wait in a
single line for the ﬁrst available clerk. The average
time for a clerk to service a patron is three minutes
(exponentially distributed). Clerks earn $10 per hour,
and the hotel assesses a waiting time cost of $20 for
each hour that a patron waits in line.
a. Compute the expected cost per hour of the current
system.
b. The hotel is considering replacing one clerk with
an Automatic Clerk Machine (ACM). Management
estimates that 20% of all patrons will use an ACM.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

An ACM takes an average of one minute to service
a patron. It costs $48 per day (one day equals eight
hours) to operate an ACM. Should the hotel install
the ACM? Assume that all customers who are will-
ing to use the ACM wait in a separate queue.
Skill-Extending Problem
62. The mail order ﬁrm of L. L. Pea receives an average
of 200 calls per hour, where times between calls are
exponentially distributed. It takes an L. L. Pea operator
an average of three minutes to handle a call. If a caller
gets a busy signal, L. L. Pea assumes that he or she will
call a competing mail-order company, and L. L. Pea
will lose an average of $30 in proﬁt. The cost of keep-
ing a phone line open is $9 per hour. How many opera-
tors should L. L. Pea have on duty? Use simulation to
answer this question. Does the answer depend on
whether the service times are exponentially distributed?
Modeling Problems
63. Bloomington Hospital knows that insurance compa-
nies are going to reduce the average length of stay of
many types of patients. How can queueing models be
used to determine how changes in insurance policies
will inﬂuence the hospital?
64. Excessive delays have recently been noted on New
York City’s 911 system. Discuss how you would use
queueing models to improve the performance of the
911 system.
65. Suppose that annually an average of  library patrons
want to borrow a book. A patron borrows the book for
an average of 1 years. Suppose we observe that the
book is actually borrowed an average of R times per
year. Explain how we can estimate , which is an
unobservable quantity. (Hint: Let U be the expected
number of times per year a patron wants to borrow the
book and the book is out. Note that   R  U.)
66. Based on Quinn et al. (1991). Winter Riggers handles
approximately $400 million in telephone orders per
13.8 Conclusion
835
year. Winter Riggers’ system works as follows. Callers
are connected to an agent if one is available.
Otherwise, they are put on hold (if a trunk line is avail-
able). A customer can hang up at any time and leave
the system. Winter Riggers would like to efﬁciently
manage the telephone system (lines and agents) used
to process these orders. Of course, orders are very sea-
sonal and depend on the time of day.
a. What decisions must Winter Riggers make?
b. What would be an appropriate objective for Winter
Riggers to minimize (or maximize)? What difﬁcul-
ties do you see in specifying the objective?
c. What data would Winter Riggers need to keep
track of to improve its efﬁciency?
67. Zerox has 16 service centers throughout the United
States. Zerox is trying to determine how many techni-
cians it should assign to each service center. How
would you approach this problem?
68. Based on Kolesar et al. (1974). Metropolis PD
Precinct 88 must determine the minimum number of
police cars required to meet its needs for the next
24 hours. An average call for service requires 30 min-
utes. The number of calls the police department
expects to receive during each hour is shown in the ﬁle
P13_68.xlsx. The Metropolis PD standard of service is
that there should be a 90% chance that a car is avail-
able to respond to a call. For each of the following,
discuss how you might ﬁnd a solution.
a. Suppose that patrol ofﬁcer teams assigned to a car
work an 8-hour shift beginning at 12 A.M., 8 A.M.,
or 4 P.M. Ofﬁcers get an hour off for a meal. This
hour can be anytime between the second and ﬁfth
hour of their shift. The precinct wants to know how
many teams are needed to meet daily demand.
b. Suppose that patrol ofﬁcer teams assigned to a car
begin their 8-hour shifts at 12 A.M., 8 A.M., 12 P.M.,
4 P.M., and 8 P.M. An hour off for meals may be
taken anytime during a shift. The precinct again
wants to know how many teams are needed to meet
daily demand.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

836
Chapter 13
Queueing Models
C A S E
T
he Catalog Company is a mail- and phone-order
company that sells generic brands of houseware
items and clothing. Approximately 95% of customer
orders are received by phone; the remaining 5% are
received in the mail. Phone orders are accepted at
Catalog Company’s toll-free 800 number, 800-SAVE-
NOW. The number is available nine hours per day
(8 A.M. to 5 P.M.), ﬁve days a week.
Sarah Walters, a recent graduate of Columbia
Business School, has just been hired by Catalog to
improve its operations. Sarah would like to impress
her boss, Ben Gleason, the president of Catalog
Company, with some ideas that would quickly
improve the company’s bottom line. After spending a
week learning about Catalog’s operations, Sarah feels
that a substantial impact can be made by a closer
evaluation of the phone order system.
Currently, Catalog employs a single full-time
operator to take orders over the phone. Sarah won-
ders whether additional operators should be hired
to take phone orders. Ben feels that Sarah’s time
might be better spent studying the catalog mailing
lists. Ben reasons that the mailing lists are where
customers are generated, and improving the list will
bring in more revenue. And besides, Ben says,
“Catalog’s phone operator, Betty Wrangle, seems to
be doing nothing more than half of the time that I
walk by. Hiring more operators to do nothing will
just waste more money.” Although Sarah knows the
mailing lists are important, she thinks that a study of
the mailing lists will take far more time than a quick
evaluation of the phone order system.
Forging ahead, Sarah discovers the following
information about the phone order system. The
phone operator, Betty Wrangle, is paid $9 per hour
in wages and beneﬁts. The average cost to Catalog
for a completed 800 number call is $1.50. With only
one phone line, any incoming calls that arrive when
Betty is on the phone to another customer get a
busy signal. The cost of the phone line is $40 per
month.The phone company can immediately add up
to four additional phone lines using the same 800
number, each at a cost of $40 per month per line.
Catalog’s phone system is such that it cannot be
upgraded in the near future to allow incoming calls
to be placed on hold. The average proﬁt on an order
13.1 CATALOG COMPANY PHONE ORDERS
(not including the cost of the operator or phone
call) is 40% of the amount of the order. For example,
an order of $100 brings a proﬁt of $40 to Catalog.
Sarah decided that additional information
needed to be collected about the frequency of
incoming calls, the length of the calls, and so on.
After talking to the phone company, Sarah learned
that she could borrow equipment for one day that
could detect when a call was coming in, even when
Betty was on the phone. The caller would still get a
busy signal and be lost, but Sarah would know that a
call had been attempted. Sarah collected almost nine
hours of data the next day; these data are presented
in the ﬁle Catalog Orders.xlsx. Sarah believes
that most of the callers who receive a busy signal
take their business elsewhere and are totally lost to
Catalog. Sarah does not feel that extending the
hours of operation of the 800 number would be
beneﬁcial because the hours of operation are
printed prominently in all of the catalogs.
The ﬁrst call arrives 0.036 hour into the day. It
takes Betty 0.054 hour to process the call and
record the order for $65.21 worth of merchandise.
Callers 5 and 6 get busy signals when they call,
because Betty was still processing caller 4. Because
calls 5 and 6 were lost, no call length information was
available and no orders were placed. Data collection
was stopped at call number 80.
Questions
Use the complete information in the ﬁle Catalog
Orders.xlsxto answer the following questions:
1.
Approximately what fraction of the time is Betty
idle? Is Ben’s estimate correct?
2.
Approximately how many calls are lost in an
average hour due to a busy signal?
3.
Use the data to estimate the average arrival rate
of all attempted calls to Catalog. Give an approxi-
mate 95% conﬁdence interval for the estimate.
Plot a frequency histogram of interarrival times.
Does the distribution of interarrival times
appear to be exponential?
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Case 13.1 Catalog Company Phone Orders
837
4.
Use the data to estimate the average service
rate of all completed calls. Give an approximate
95% conﬁdence interval for the estimate. Plot a
frequency histogram of service times. Does the
service time distribution appear to be exponen-
tial? Give an approximate 95% conﬁdence inter-
val for the average revenue per call.
5.
Would you recommend that Catalog acquire
additional phone lines and operators? If so, how
many? If not, why not? Justify your answer in
enough detail so that Ben Gleason would be
convinced of your recommendation.
■
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

838
Chapter 13
Queueing Models
C A S E
P
aciﬁc National Bank is a medium-size bank with
21 branches in the San Francisco Bay Area. Until
very recently, Paciﬁc did not operate its own ATMs;
instead, it relied on an outside vendor to operate
them. Ninety percent of the ATM customers
obtained cash advances with non-Paciﬁc credit cards,
so the ATMs did little to directly improve Paciﬁc’s
own banking business. Operations Vice President
Nancy Meisterhaus wants to change that, by having
Paciﬁc offer a broader mix of banking services with
its own machines tied into its own data-processing
network.
The industry consensus is that the ATM appeals
to customers in much the same way as the super-
market express line: It minimizes the amount of wait-
ing. But for Paciﬁc, the 24-hour ATM would also have
the broader appeal of providing essential banking
services at all hours, reaching a segment of the mar-
ket not currently served. Historically, customers who
ﬁnd standard banking hours inconvenient have been
lost to Paciﬁc, so the ATM will increase the bank’s
market share.
Besides attracting more customers and servicing
existing customers better, the ATM operation should
offer substantial cost advantages. Fewer human
tellers would be required for the same volume of
transactions as before. The per transaction cost of
the machine, which does need some human attention
for restocking and maintenance, should be substan-
tially less. But even if that were not so, its 24-hour
readiness would be extremely expensive to duplicate
with human tellers, who would have to be given
extra protection for dangerous late-night work.
Ms.Meisterhaus selected theWalnut Creek ofﬁce
as the test branch for a captive ATM.Customers from
that branch were recruited to sign up for a Paciﬁc
ATM card. All residents within the neighboring ZIP
codes were offered an incentive to open free checking
accounts at Paciﬁc when they also signed up for the
card. After a critical mass ofATM card holders was
established—but before the banking ATM was
installed—statistics were kept. The arrival times in
Table 13.5 were determined for various times of
the week.
13.2 PACIFIC NATIONAL BANK10
The bank opens at 10 A.M. and closes at 3 P.M.,
except on Friday, when it closes at 6 P.M. Past study
shows that, over each period, customers arrive ran-
domly at a stable mean rate, so the assumption of a
Poisson process is valid. The mean time required to
complete customer transactions is two minutes, and
the individual service times have a frequency distribu-
tion with a pronounced positive skew, so an exponen-
tial distribution is a reasonable approximation to
reality.
Tellers all work part-time and cost $10 per bank
hour. Paciﬁc’s experience has established that there
will be a signiﬁcant drop-off in clientele soon after a
bout when customers suffer lengthy delays in getting
teller access. The supplier of the ATM equipment
claims that other banks of comparable size have
experienced a 30% diversion of regular business
away from human tellers to the ATM, which pro-
duced a further 20% expansion beyond the previous
level of overall client transactions—all absorbed by
the ATM, half of it outside regular banking hours.
The supplier also maintains that ATM trafﬁc is fairly
uniform, except between 11 P.M. and 6 A.M., when it is
negligible. Ms. Meisterhaus believes that the ATM
busy-period arrivals will constitute a single Poisson
process.
Industry experience is that the mean service
time at an ATM is one-half minute, with an
exponential distribution serving as an adequate
approximation to the unknown positively skewed
unimodal distribution that actually applies.
Ms. Meisterhaus believes that once the ATM is
installed the Walnut Creek human tellers will be left
with a greater proportion of the more involved and
Table 13.5 Customer Arrivals at the Walnut
Creek Ofﬁce—Before ATM 
Installation
Daily Average 
Number 
Period
of Arrivals
(1) Monday–Friday 10 A.M.–12 P.M.
155
(2) Monday–Friday 12–1 P.M.
242
(3) Monday–Friday 1–3 P.M.
290
(4) Friday 3–6 P.M.
554
10This case was written by Lawrence L. Lapin, San Jose State
University. 
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Case 13.2 Paciﬁc National Bank
839
lengthy transactions, raising their mean service time
to 2.5 minutes.
Ms. Meisterhaus knows that much of the evalua-
tion of the ATM operations will be a queueing exer-
cise. Her knowledge of this subject is a bit rusty, so
she has retained you to assist her.
Questions
1.
Assume that Paciﬁc National Bank remains with
human tellers only.
a. For each time period in Table 13.5, determine
the minimum number of tellers needed on
station to service the customer stream.
b. Assume that the number of tellers found in
part a is used. For each time period, deter-
mine the mean customer waiting time.
c. For each time period, determine the mean
customer waiting time when the number of
tellers is one more than found in part a.
2.
Past experience shows that the drop-off in clien-
tele due to waiting translates into an expected
NPV in lost future proﬁts of $0.10 per minute.
For each time period in Table 13.5, determine
the average hourly queueing system cost (server
cost  waiting cost), assuming that the bank
uses the following service arrangement:
a. The minimum number of human tellers
necessary to service the arriving customers
b. One teller more than was found in part a of
Question 1
3.
Suppose that the ATM is installed and that cus-
tomers themselves decide whether to use
human tellers or to use the ATM, and that two
queues form independently for each. Finally,
assume that a 10% trafﬁc increase is generated
by the ATM within each open time period and
that all of it is for the ATM.
a. For each period in Table 13.5, determine 
the mean arrival rate at the human teller 
windows.
b. Do the same with regard to the mean arrival
rate at the ATM.
c. Find the minimum number of human tellers
required to be on station during each time
period.
4.
Assume that the number of human tellers used
is one more than that found in part c of
Question 3. Determine for Ms. Meisterhaus the
mean customer waiting time during each open
period in Table 13.5 for those customers who
seek the following:
a. Human tellers
b. Access to the ATM
5.
The hourly cost of maintaining and operating the
ATM is $5. Increased customer trafﬁc results in
additional bank proﬁt estimated to be $0.20 per
transaction. Determine for Ms. Meisterhaus the
net hourly queueing system cost, reﬂecting any
proﬁt increase, for operating with the ATM for
each of the four periods identiﬁed in Table 13.5.
Use the mean waiting times from Question 4.
6.
Consider the complete 24-hour, 7-day picture.
Incorporate whatever information you need
from Questions 1 through 5 and your solutions,
plus any additional information in the case and
any necessary assumptions, to compare the net
cost of operation with and without the ATM.
Then give your overall recommendation to
Ms. Meisterhaus.
■
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

C H A P T E R
14
Regression and Forecasting Models
REVENUE MANAGEMENT AT HARRAH’S
CHEROKEE CASINO & HOTEL
R
eal applications of forecasting are almost never done in isolation.They
are typically one part—a crucial part—of an overall quantitative solution
to a business problem.This is certainly the case at Harrah’s Cherokee
Casino & Hotel in North Carolina, as explained in an article by Metters et al.
(2008). This particular casino uses revenue management (RM) on a daily 
basis to increase its revenue from its gambling customers. As customers call
to request reservations at the casino’s hotel, the essential problem is to de-
cide which reservations to accept and which to deny. The idea is that there
is an opportunity cost from accepting early requests from lower-valued 
customers because higher-valued customers might request the same rooms
later on.
Monkeybusinessimages/Dreamstime.com
841
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

As the article explains, there are several unique features about casinos, and this
casino in particular, that make a quantitative approach to RM successful. First, the detailed
behaviors of customers can be tracked, via electronic cards they use while placing bets in
the electronic gambling machines, so that the casino can create a large database of individ-
ual customers’ gambling patterns. This allows the casino to segment the customers into
different groups, based on how much they typically bet in a given night. For example, one
segment might contain all customers who bet between $500 and $600 per night. When a
customer calls for a room reservation and provides his card number, the casino can im-
mediately look up his information in the database and see which segment he is in.
A second reason for the successful use of RM is that customers differ substantially
in the price they are willing to pay for the same commodity, a stay at the casino’s hotel.
Actually, many don’t pay anything for the room or the food—these are frequently com-
plimentary from the casino—but they pay by losing money at gambling. Some customers
typically gamble thousands of dollars per night while others gamble much less. (This is
quite different from the disparities in other hotels or in air travel, where a business trav-
eler might pay twice as much as a vacationer, but not much more.) Because some cus-
tomers are much more valuable than others, there are real opportunity costs from
treating all customers alike.
A third reason for the success of RM at this casino is that the casino can afford to
hold out for the best-paying customers until the last minute.The reason is that a signiﬁcant
percentage of the customers from all segments wait until the last minute to make their
reservations. In fact, they often make them while driving, say, from Atlanta to the casino.
Therefore, the casino can afford to deny requests for reservations to lower-valued cus-
tomers made a day or two in advance, knowing that last-minute reservations, very possibly
from higher-valued customers, will ﬁll up the casino’s rooms. Indeed, the occupancy rate is
virtually always 98% or above.
The overall RM solution includes (1) data collection and customer segmentation,
as explained above, (2) forecasting demand for reservations from each customer
segment, (3) a linear programming (LP) optimization model that is run frequently to
decide which reservations to accept, and (4) a customer relationship management
model to entice loyal customers to book rooms on nights with lower demand.The
forecasting model is very similar to the Winters’ exponential smoothing model dis-
cussed later in this chapter. Speciﬁcally, the model uses the large volume of historical
data to forecast customer demand by each customer segment for any particular night
in the future.These forecasts include information about time-related or seasonal pat-
terns (weekends are busier, for example) and any special events that are scheduled.
Also, the forecasts are updated daily as the night in question approaches.These fore-
casts are then used in an LP optimization model to determine which requests to 
approve. For example, the LP model might indicate that, given the current status of 
bookings and three nights to go, requests for rooms on the speciﬁed night should be
accepted only for the four most valuable customer segments.As the given night ap-
proaches and the number of booked rooms changes, the LP model is rerun many times
and provides staff with the necessary information for real-time decisions. (By the way,
a customer who is refused a room at the casino is often given a free room at another
nearby hotel.After all, this customer can still be valuable enough to offset the price 
of the room at the other hotel.)
It is difﬁcult to measure the effect of this entire RM system because it has always
been in place since the casino opened. But there is no doubt that it is effective. Despite
the fact that it serves no alcohol and has only electronic games, not the traditional
gaming tables, the casino has nearly full occupancy and returns a 60% proﬁt margin on
gross revenue—double the industry norm. ■
842
Chapter 14
Regression and Forecasting Models
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

14.1 INTRODUCTION
Many decision-making applications depend on a forecast of some quantity. Here are
several examples:
■
When a service organization, such as a fast-food restaurant, plans its staffing 
over some time period, it must forecast the customer demand as a function of
time. This might be done at a very detailed level, such as the demand in succes-
sive quarter-hour periods, or at a more aggregate level, such as the demand in 
successive weeks.
■
When a company plans its ordering or production schedule for a product, it must
forecast the customer demand for this product so that it can stock appropriate
quantities—neither too much nor too little.
■
When an organization plans to invest in stocks, bonds, or other ﬁnancial instruments,
it typically attempts to forecast movements in stock prices and interest rates.
■
When government representatives plan policy, they attempt to forecast movements in
macroeconomic variables such as inﬂation, interest rates, and unemployment.
Many forecasting methods are available, and all practitioners have their favorites. To
say the least, there is little agreement among practitioners or theoreticians as to the best
forecasting method. The methods can generally be divided into three groups: (1) judg-
mental methods, (2) regression methods, and (3) extrapolation methods. The ﬁrst of
these is basically nonquantitative and is not discussed here.
Regression models, also called causal models, forecast a variable by estimating its re-
lationship with other variables. For example, a company might use a regression model to
estimate the relationship between its sales and its advertising level, the population income
level, the interest rate, and possibly others. The technique of regression is extremely popu-
lar, due to its ﬂexibility and power. Regression can estimate relationships between time se-
ries variables or cross-sectional variables (those that are observed at a single point in time),
and it can estimate linear or nonlinear relationships.
Extrapolation methods, also called time series methods, use past data of a time
series variable—and nothing else—to forecast future values of the variable. Many extrapo-
lation methods are available, including the two we discuss here: moving averages and
exponential smoothing. All extrapolation methods search for patterns in the historical se-
ries and then attempt to extrapolate these patterns into the future. Some try to track long-
term upward or downward trends and then project these. Some try to track the seasonal
patterns (sales up in November and December, down in other months, for example) and
then project these.
Much academic research has been devoted to forecasting methods in the past few
decades, and with the advances in computing power, many of the methods described in the
academic literature have been implemented in software packages. Interestingly, however,
there is not complete agreement, even among academics, that we can obtain better forecasts
today than we could, say, in 1970. An article by Franses (2004) describes a survey of 
76 members of the editorial boards of academic journals associated with forecasting. The
survey asked several questions about the status of forecasting methods today versus a few
decades ago. Most of the respondents believe that the advances in theory and software have
resulted in better forecasts, but they are not unanimous in this opinion. They appear to rec-
ognize that quantitative forecasting methods can go only so far. Many of the respondents
believe that the opinions of experts in the subject area should be used to complement the
forecasts from software packages. In other words, they don’t believe that human judgment
should be omitted from the forecasting process.
14.1 Introduction
843
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Regression analysis and time series analysis are both very broad topics, with many en-
tire books and thousands of research articles devoted to them. We can only scratch the sur-
face of these topics in a single chapter. However, a little can go a long way. By the time you
have read this chapter, you will be able to apply some very powerful techniques.
14.2 OVERVIEW OF REGRESSION MODELS
Regression analysis is the study of relationships between variables. It is one of the most
useful tools for a business analyst because it applies to so many situations. Some potential
uses of regression analysis in business address the following questions:
■
How do wages of employees depend on years of experience, years of education, and
gender?
■
How does the current price of a stock depend on its own past values, as well as the
current and past values of a market index?
■
How does a company’s current sales level depend on its current and past advertising
levels, the advertising levels of its competitors, the company’s own past sales levels,
and the general level of the market?
■
How does the unit cost of producing an item depend on the total quantity of items
that have been produced?
■
How does the selling price of a house depend on such factors as the square footage of
the house, the number of bedrooms in the house, and perhaps others?
Each of these questions asks how a single variable, such as selling price or employee
wages, depends on other relevant variables. If you can estimate this relationship, you can
better understand how the world operates and also do a better job of predicting the variable
in question. For example, you can understand how a company’s sales are affected by its
advertising and also use the company’s records of current and past advertising levels to pre-
dict future sales.
Regression analysis can be categorized in several ways. One categorization is based on
the type of data being analyzed. There are two basic types: cross-sectional data and time
series data. Cross-sectional data are usually data gathered from approximately the same
period of time from a cross section of a population. The housing and wage examples
mentioned previously are typical cross-sectional studies. The ﬁrst concerns a sample of
houses, presumably sold during a short period of time, such as houses sold in Blooming-
ton, Indiana, during the ﬁrst quarter of 2011. The second concerns a sample of employees
observed at a particular point in time, such as a sample of automobile workers observed at
the beginning of 2010. In contrast, time series studies involve one or more variables that are
observed at several, usually equally spaced, points in time. The stock price example men-
tioned previously ﬁts this description. The price of a particular stock and possibly the price
of a market index are observed at the beginning of every week, say, and regression can then
be used to explain the movement of the stock’s price through time.
A second categorization of regression analysis involves the number of explanatory
variables in the analysis. First, we must introduce some terms. In every regression study,
the goal is to explain or predict a particular variable. This is called the dependent variable
(or the response variable) and is often denoted generically as Y. To help explain or predict
the dependent variable, one or more explanatory variables are used. These variables are
also called independent variables or predictor variables, and they are often denoted
generically as Xs. If there is a single explanatory variable, the analysis is called simple
regression. If there are several explanatory variables, it is called multiple regression.
844
Chapter 14
Regression and Forecasting Models
Regression is capable
of dealing with cross-
sectional data and
time series data.
Regression uses one or
more explanatory
variables to explain a
single dependent
variable.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

There are important differences between simple and multiple regression. The primary
difference, as the name implies, is that simple regression is simpler. The calculations are
simpler, the interpretation of output is somewhat simpler, and fewer complications can
occur. We will begin with a simple regression example to introduce the ideas of regression.
Then we will move on to the more general topic of multiple regression, of which simple 
regression is a special case.
You will learn how to estimate regression equations that describe relationships be-
tween variables. You will also learn how to interpret these equations, explain numerical
measures that indicate the goodness-of-ﬁt of the estimated equations, and describe how to
use the regression equations for prediction.1
The Least-Squares Line
The basis for regression is a fairly simple idea. If you create a scatterplot of one variable Y
versus another variable X, you obtain a swarm of points that indicates any possible
relationship between these two variables. (The terms scatterplot, scatter chart, and XY
chart are all used to describe the same thing. We use scatterplot in this chapter.) To quan-
tify this relationship, you try to ﬁnd the best-ﬁtting line (or curve) through the points in the
graph. But what does “best-ﬁtting” really mean?
Consider the scatterplot in Figure 14.1. The line shown is one possible ﬁt. It appears to
be a reasonably good ﬁt, but a numerical measure of goodness-of-ﬁt is needed so that this
ﬁt can be compared with the ﬁts of other possible lines.
14.2 Overview of Regression Models
845
1The terms prediction and forecasting are practically synonyms. Some analysts reserve the term forecasting for
future values of a time series variable and use the term prediction for any type of variable, time series or other-
wise. However, we do not make this distinction.
10
20
A
B
X0
30
40
50
Positive
residual
Negative
residual
Height of line above X0 is 
predicted (fitted) value for X0
60
70
0
20
40
60
80
100
120
140
0
Scatterplot of Y vs X
Figure 14.1
Scatterplot with
Proposed Regression
Line
A residual is a prediction error. It is the difference between an observed Y and the
predicted Y from the regression line.
The measure commonly used is the sum of squared residuals. Here, a residual is de-
ﬁned as the vertical distance from a point to the line, as illustrated for points A and B. If the
point is above the line (point A), the residual is positive; if the point is below the line (point B),
the residual is negative. The most commonly used measure of goodness-of-ﬁt is the sum of
squared residuals. Intuitively, a good ﬁt should have a small sum of squared residuals. In
fact, the goal in regression is to ﬁnd the line with the minimum sum of squared residuals,
where the minimum is over all possible lines. This is called the least-squares line and is the
line found by regression. (Why are the residuals squared? One reason is to make them all
positive. Another is to severely penalize large residuals. The most compelling reason, how-
ever, is that this is the way it has been done by statisticians for many years.)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

The details of the procedure used to ﬁnd the least-squares line are beyond the scope of
this book. The procedure is basically a calculus problem. Fortunately, it is done automati-
cally by regression software. You can rely on this software to ﬁnd the least-squares line,
and then you can interpret the results.
Prediction and Fitted Values
After you ﬁnd the least-squares line, you can use it for prediction. Geometrically, this is
easy. Given any value of X, you predict the corresponding value of Y to be the height of the
line above this X. This is shown in Figure 14.1 for the value X0. The predicted Y value is
called the ﬁtted value.
846
Chapter 14
Regression and Forecasting Models
The least-squares regression line minimizes the sum of squared residuals.
Relationship between residuals and ﬁtted values
Residual  Actual value  Fitted value
(14.1)
A ﬁtted value is a predicted value of Y found by substituting given Xs into the re-
gression equation.
In contrast, the height of any point is the actual value of Y for this point. This implies
the following important relationship. It states that the residual for any point is the differ-
ence between the observed value of Y and the predicted value of Y.
In general, you estimate the least-squares line as a regression equation relating Y to one
or more Xs. For example, this equation might be Y  5  3X. To predict Y for any given
value of X, you substitute this value of X into the regression equation. The result is the ﬁt-
ted value of Y. For example, with the proposed equation, if X  2, the ﬁtted (predicted)
value of Y is 5  3(2)  11. If you happen to know that the actual value of Y for this point
is 13, then the residual is positive: 13  11  2. On the other hand, if the actual value is 8,
the residual is negative: 8  11  3.
Measures of Goodness-of-Fit
Besides the sum of squared residuals, other measures of goodness-of-fit typically are
quoted in regression analyses. We brieﬂy describe these here and discuss them in more de-
tail in subsequent sections.
Standard Error of Estimate
The sum of squared residuals is measured in squared units of the Y variable. For example,
if Y is sales in dollars, the sum of squared residuals is in squared dollars. It is more mean-
ingful to obtain a related measure in dollars. The resulting measure is called the standard
error of estimate. This measure is obtained by averaging and then taking the square root,
as shown in the following formula. In this formula, n is the number of observations, and k
is the number of explanatory variables in the regression equation. (There are technical rea-
sons for dividing by n – k – 1, not by n, but we will not pursue them here. Just remember
that the software automatically divides by n – k – 1.)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

The standard error of estimate is useful because it provides an estimate of the magnitude
of the prediction errors you are likely to make. For example, if the standard error of estimate
is $150, then as a ballpark estimate, you expect your predictions to be off by about $150.
More precisely, the standard error of estimate behaves like a standard deviation. Therefore,
from the well-known empirical rule of statistics, you expect about 23 of your predictions to
be no greater than $150 (one standard error) in magnitude, and you expect about 95% of
your predictions to be no greater than $300 (two standard errors) in magnitude.
Multiple R and R-Square
Another goodness-of-ﬁt measure is called the multiple R, deﬁned as the correlation between
the actual Y values and the ﬁtted Y values. In general, a correlation is a number between 1
and 1 that measures the goodness-of-ﬁt of the linear relationship between two variables. A
correlation close to 1 or 1 indicates a tight linear ﬁt, whereas a correlation close to 0
tends to indicate no linear ﬁt—usually a shapeless swarm of points. In regression, you want
the ﬁtted Y values to be close to the actual Y values, so you want a scatterplot of the actual
values versus the ﬁtted values to be close to a 45° line, with the multiple R close to 1.
14.2 Overview of Regression Models
847
Formula for standard error of estimate
Standard error of estimate 
(14.2)
2Sum of squared residuals>(n - k - 1)
The standard error of
estimate is a measure
of the magnitude of
the prediction errors
you are likely to make,
based on the regres-
sion equation.
Formula for Multiple R
Multiple R  Correlation between actual Ys and ﬁtted Ys
(14.3)
Formula for R-square
R-square  (multiple R)2
 Percentage of variation of Y explained by the regression
(14.4)
How large should multiple R be to indicate a “good” ﬁt? This is difﬁcult to answer
directly, other than to say “the larger, the better.” However, if you square the multiple R,
you get a measure that has a more direct interpretation. This measure is known simply
as R-square. It represents the percentage of the variation of the Y values explained by the
Xs included in the regression equation. For example, if multiple R is 0.8, then R-square is
0.64, which means that 64% of the variation of Y has been explained by the regression. The
idea is that the Xs included in the regression are presumably related to Y, so that they help
explain why the Y values vary as they do. Naturally, you want the Xs to explain as much of
this variation as possible, so you want R-square values as close to 1 as possible.
Although R-square is probably the most frequently quoted measure in regression
analyses, some caution is necessary. First, R-square values are often disappointingly low.
Some variables in the business world (and other areas) are simply not easy to explain, par-
ticularly those in behavioral areas. Regressions in these areas sometimes have R-squares in
the 10% to 20% range. This does not necessarily mean that these regressions are useless.
After all, explaining 20% of the variation in some variable is better than not explaining
anything at all. Second, R-squares can sometimes be inﬂated by adding Xs to the equation
that do not really belong. This is due to the mathematical property that R-square can only
increase, never decrease, when extra Xs are added to an equation. In general, you should
avoid the temptation to build large equations with many Xs just to pump up R-square. It is
The R-square value can
never decrease as
more explanatory vari-
ables are added to the
regression equation.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

usually preferable to include only a few well-chosen Xs and omit those that yield only mar-
ginal increases in R-square. Finding the right set of Xs, however, is not easy. In fact, it is
probably the biggest challenge to the analyst and takes a good deal of experience.
14.3 SIMPLE REGRESSION MODELS
In this section, we discuss how to estimate the regression equation for a dependent variable
Y based on a single explanatory variable X. (The common terminology is that “Y is regressed
on X.”) This is the equation of the least-squares line passing through the scatterplot of Y
versus X. Because we are estimating a straight line, the regression equation is of the form
Y  a  bX, where, as in basic algebra, a is called the intercept and b is called the slope.
848
Chapter 14
Regression and Forecasting Models
Regression-Based Trend Models
A special case of simple regression is when the only explanatory variable is time, usually
labeled t (rather than X). In this case, the dependent variable Y is a time series variable, such
as a company’s monthly sales, and the purpose of the regression is to see whether this de-
pendent variable follows a trend through time. If there is a linear trend, the equation for Y
has the form Y  a  bt. If b  0, then Y tends to increase by b units every time period,
whereas if b  0, then Y tends to decrease by b units every time period. Alternatively, if
there is an exponential trend, the equation for Y has the form Y  aebt. In this case, the
variable Y changes by a constant percentage each time period, and this percentage is ap-
proximately equal to the coefﬁcient in the exponent, b. For example, if b  0.025, then
Y increases by about 2.5% per period, whereas if b  0.025, Y decreases by about 2.5%
per period.
With a linear trend line, the variable changes by a constant amount each period.
With an exponential trend line, the variable changes by a constant percentage each
period.
Equation for simple regression
Y  a  bX
(14.5)
The following example illustrates how easily trends can be estimated with Excel.
E X A M P L E
14.1 FORECASTING SALES AT BEST CHIPS
T
he Best Chips Company produces and sells potato chips throughout the country. Its
sales have been growing steadily over the past 10 years, as shown in Figure 14.2 and
the ﬁle Exponential Growth.xlsx.2 (Note that we have indexed the years so that year 1 cor-
responds to 2000.) The company wants to predict its sales for the next couple of years,
assuming that the upward trend it has observed in the past 10 years will continue in the
future. How should the company proceed?
Objective
To ﬁt linear and exponential trend lines to the company’s historical sales data
and to use the better of these trend lines to predict future sales.
It is customary to
index time from 1 to
the number of time
periods.
2We omit the “Where Do the Numbers Come From?” sections in this chapter because the data sources should be
obvious.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Excel Tool: Creating a Scatterplot with Excel
To create a scatterplot in Excel, select the two series of data and then select a Scatter c hart of
some type from the Insert ribbon. By default, the range on the left will be on the horizontal axis,
and the range on the right will be on the vertical axis. If this isn’t what you want, select the chart
and use the Select Data Source option on the Chart Tools Design ribbon to switch the roles of
the two series. This is the key step. You can experiment with other options, but they are mainly
for formatting the c hart. (If you want to use the StatT ools add-in, which will be used in other
examples shortly, it is even easier to create one or more scatterplots.)
Fitting a Linear Trend Line
To superimpose a linear trend line on any scatterplot, right-click on any point on the
chart and then select the Add Trendline menu item. This brings up the dialog box in
14.3 Simple Regression Models
849
1
2
3
4
5
6
7
8
9
10
11
12
A
B
Historical data
Year
Sales
1
$1,345,000
2
$1,352,000
3
$1,463,000
4
$1,511,000
5
$1,610,000
6
$1,649,000
7
$1,713,000
8
$1,850,000
9
$2,051,000
10
$2,203,000
Figure 14.2
Historical Sales at
Best Chips
$1,200,000
$1,400,000
$1,600,000
$1,800,000
$2,000,000
$2,200,000
$2,400,000
1
2
3
4
5
6
7
8
9
10
Year (1 = 2000)
Sales versus Year
Figure 14.3
Time Series Plot
of Sales
Solution
A good place to start any regression analysis is with a scatterplot of Y versus X, where X is
time in this example. See Figure 14.3. Sales are clearly increasing over time, but it is not
absolutely clear whether they are increasing at a constant rate, which would favor a linear
trend line, or at an increasing rate, which would favor an exponential trend line. Therefore,
you can try ﬁtting both of these.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Figure 14.4. You can select any of six types of trend lines. For now, select the default
Linear option. Also, check the Display Equation on Chart option. (You can also elect to
display the R-square value if you like.) The result appears in Figure 14.5.
850
Chapter 14
Regression and Forecasting Models
Figure 14.4
Dialog Box for
Adding a Trendline
y = 92,091x + 1,168,200
$1,200,000
$1,400,000
$1,600,000
$1,800,000
$2,000,000
$2,200,000
$2,400,000
1
2
3
4
5
6
7
8
9
10
Year (1 = 2000)
Sales versus Year
Figure 14.5
Plot with Superim-
posed Linear Trend
Line
Excel Tool: Add Trendline
It is easy to f it any of several types of trend lines to a scatterplot of some variable ver sus
time. To do so, right-clic k on any point on the c hart and select Add T rendline from the
menu. This brings up a dialog box where you can select one of several types of trend lines.
In addition, you can elect to display an equation of the trend line and/or the R-square value
on the chart. This equation and/or the R-square value appear in a text box. You can select
this text box and move it, change its font size, or change its number format as you like.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

14.3 Simple Regression Models
851
This ﬁgure shows the best-ﬁtting straight line to the points, and it indicates that the
equation of this straight line is y  92,091x  1,168,200. Here, y corresponds to sales and
x corresponds to year.3 The most important part of this equation is the coefﬁcient of x,
92,091. It implies that sales are increasing by $92,091 per year—if the linear trend line pro-
vides a good ﬁt to the data.
Fitting an Exponential Trend Line
To obtain an exponential trend line, you go through the same procedure except that you se-
lect the Exponential option in Figure 14.4. The resulting curve appears in Figure 14.6. The
equation for the curve is y  1,227,762e0.0541x. The most important part of this equation is
the coefﬁcient in the exponent, 0.0541. It implies that sales are increasing by approxi-
mately 5.4% per year. In general, the coefﬁcient in the exponent of an exponential trend
line equation, when expressed as a percentage, indicates the approximate percentage by
which the series changes each period. Note that if this coefﬁcient were negative, such as
0.0325, the series would be decreasing by approximately 3.25% each period (and the
plot would be trending downward). (We say “approximate” because the exact rate is eb  1
when the coefﬁcient in the exponent is b. For example, when b  0.0541, the exact rate is
e0.0541  1  0.0556, or 5.56%.)
y = 1,227,762.1725e0.0541x
$1,200,000
$1,400,000
$1,600,000
$1,800,000
$2,000,000
$2,200,000
$2,400,000
1
2
3
4
5
6
7
8
9
10
Year (1 = 2000)
Sales versus Year
Figure 14.6
Plot with Superim-
posed Exponential
Trend Line
3Although we like to use the variable t to denote time, Excel uses the variable x in its trend-line equations.
The coefficient of time
in the linear trend line
equation represents
the change in the vari-
able per time period.
The coefficient of time
in the exponent of the
exponential trend line
equation represents
the (approximate)
percentage change in
the variable per time
period.
Measuring the Goodness-of-Fit
Which of these trend lines provides the better ﬁt? You can proceed in two ways. First,
you can eyeball it. Looking at the superimposed trend lines in Figures 14.5 and 14.6, it
appears that the exponential ﬁt is slightly better. However, the typical way to measure ﬁts
to a trendline through time is to calculate the historical predictions from each curve and the
corresponding absolute percentage errors (APEs). You can ﬁnd the predictions by plugging
the year indexes (1 to 10) into the trend-line equations. You can then calculate the APE for
each year from the following equation:
Absolute percentage error
(14.6)
APE = |Actual sales - Predicted sales|
Actual sales
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

852
Chapter 14
Regression and Forecasting Models
A useful measure of the goodness-of-ﬁt of any trend line through time is MAPE, the
mean absolute percentage error. It is the average of the APE values calculated from
Equation (14.6).
A measure of goodness-of-ﬁt is then the average of these APE values, denoted by
MAPE (mean absolute percentage error).4 This measure is quite intuitive. For example, if
it is 2.1%, you know that the predicted values for the historical period are off—too low or
too high—by 2.1% on average.
4You will see this measure and two other measures of forecast errors when you study time series forecasting in
more detail in sections 14.5 to 14.7.
All of this is implemented in Figure 14.7. To create the predictions, APEs, and
MAPEs, proceed as follows:
1
Predictions. Calculate the predictions from the linear trend line by entering the
formula
1168200+92091*A3
in cell D3 and copying it down to cell D14. (Note that cells D13 and D14 then contain the
predictions for two future years. There is no way to know how good these future predictions
are until you observe their actual sales.) Similarly, calculate the predictions from the expo-
nential trend line by entering the formula
=1227762*EXP(0.0541*A3)
in cell E3 and copying it down to cell E14. Note that you calculate e to some power in Excel
with Excel’s EXP function.
1
A
B
C
D
E
F
G
Historical data
Predicons
Absolute percentage errors
1
2
3
4
5
6
7
8
Historical data
Year
Sales
Linear
Exponenal
Linear
Exponenal
1
$1,345,000
$1,260,291
$1,296,013
6.30%
3.64%
2
$1,352,000
$1,352,382
$1,368,059
0.03%
1.19%
3
$1,463,000
$1,444,473
$1,444,110
1.27%
1.29%
4
$1,511,000
$1,536,564
$1,524,388
1.69%
0.89%
5
$1,610,000
$1,628,655
$1,609,129
1.16%
0.05%
6
$1 649 000
$1 720 746
$1 698 581
4 35%
3 01%
Predicons
Absolute percentage errors
8
9
10
11
12
13
14
6
$1,649,000
$1,720,746
$1,698,581
4.35%
3.01%
7
$1,713,000
$1,812,837
$1,793,005
5.83%
4.67%
8
$1,850,000
$1,904,928
$1,892,678
2.97%
2.31%
9
$2,051,000
$1,997,019
$1,997,893
2.63%
2.59%
10
$2,203,000
$2,089,110
$2,108,956
5.17%
4.27%
3
9
1,6
2
2,2
$
1
0
2,1
8
1,2
$
1
1
8
4
9,9
4
3,2
$
2
9
2,3
7
2,2
$
2
1
15
16
MAPE
3.14%
2.39%
Figure 14.7
Evaluating the
Goodness-of-Fit of
Each Trend Line
Excel Function: EXP
The formula EXP(value) is equivalent to the special number e raised to the power value.
(Here, e is approximately equal to 2.718.) For example, e2.5 can be calculated in Excel with
the formula EXP(2.5), which evaluates to 12.1825. The EXP function is sometimes called
the antilog function.
2
APE values. Calculate all of the APE values at once by entering the formula
=ABS($B3-D3)/$B3
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

14.3 Simple Regression Models
853
in cell F3 and copying it to the range F3:G12. This follows directly from Equation (14.6)
and Excel’s ABS (absolute value) function.
3
MAPE values. Calculate the MAPE for each trend line by entering the formula
=AVERAGE(F3:F12)
in cell F16 and copying it to cell G16.
Discussion of the Results
The MAPE values conﬁrm that the exponential trend line is slightly better than the linear
trend line. The exponential trend line is off, on average, by 2.39%, whereas the similar
ﬁgure for the linear trend line is 3.14%. The exponential trend line implies that sales are
increasing by slightly more than 5% per year. The predictions in cells E15 and E16 pro-
ject this 5% increase to the next two years. Again, however, you can’t tell how good these
future predictions are until you observe actual sales in the next two years.
Technical Note: Estimating an Exponential Trend Line with Regression
Excel actually uses regression to estimate the exponential trend line. However, regression
always estimates linear equations of the form Y  a  bX. Therefore, to estimate an
equation of the form Y  aebt, a logarithmic transformation is required. Taking loga-
rithms of both sides and using the rules of logarithms leads to ln(Y)  ln(a)  bt, which
is linear in time t. [The dependent variable is now ln(Y).] Excel actually makes this trans-
formation behind the scenes when it estimates the exponential trend line, but it hides the
details from you.
Caution about Exponential Trend Lines
Exponential trend lines are often used in predicting sales and other economic quantities.
However, we urge caution with such predictions. It is difﬁcult for any company to sustain
a given percentage increase year after year. For example, we used this same procedure
on quarterly sales at the computer chip giant Intel, starting in 1986. Through 1996, Intel
sales rose at a staggering rate of approximately 27% per year, and the corresponding
exponential ﬁt was quite good. However, since that time, Intel’s sales have gone up much
more slowly, and in some quarters, they actually decreased. If we had used the exponential
trend line through 1996 to forecast sales after 1996, we would have overpredicted by
huge amounts.
■
Using an Explanatory Variable Other Than Time
You are not restricted to using time as the explanatory variable in simple regression. Any
variable X that is related to the dependent variable Y is a candidate. The following example
illustrates one such possibility. It shows how you can still take advantage of Excel’s Add
Trendline option, even though the resulting trend line is not what you usually think of with
trend—a trend through time.
E X A M P L E
14.2 ESTIMATING TOTAL COST FOR A SINGLE PRODUCT
C
onsider a company that produces a single product. For each of the past 16 months, the
company has kept track of the number of units produced as well as the total cost of
production. These data appear in Figure 14.8 and in the ﬁle Cost Regression 1.xlsx. What
does simple regression imply about the relationship between these two variables? How can
it be used to predict future production costs for months 17 and 18, where only the planned
values of Units Produced are known?
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

854
Chapter 14
Regression and Forecasting Models
Objective
To use simple regression to estimate the relationship between Units Produced
and Total Cost, and to use this relationship to predict future total costs.
Solution
When you try to relate two variables with regression, it is always a good idea to create a
scatterplot of the two variables ﬁrst, just to see whether there is any relationship worth pur-
suing. This can be done with Excel’s chart tools in the usual way, or it can be done easily
with Palisade’s StatTools add-in. We will rely on StatTools for the rest of the statistical
analysis in this chapter, so this is a good place to start.
Excel Add-In: StatTools from Palisade
The StatTools add-in implements many statistical procedures, including regression analysis
and forecasting. It is part of the P alisade DecisionTools suite you pr obably already in-
stalled for the use of @RISK and/or PrecisionTools in previous chapters. As with the other
add-ins in the suite , you can load StatT ools from the Windows Start button, selecting All
Programs, and then StatT ools from the Palisade DecisionTools group. If Excel is not 
already running, this will launch Excel.
StatTools is very easy to use. There is one basic thing you need to know: To get started
with any statistical analysis on any Excel data set, you must ﬁrst use Data Set Manager
from the StatTools ribbon (see Figure 14.9) to designate a StatTools data set. The idea is
that StatTools can analyze data only after it has been designated as a StatTools data set.
You need to do this only once per data set, although a given Excel ﬁle can have multiple
StatTools data sets. To do so for this example, put the cursor on any cell in the data set, se-
lect Data Set Manager, click on Yes (that you want a new StatTools data set), and ﬁll out
the resulting dialog box as in Figure 14.10. Usually, you can accept the defaults in this di-
alog box and click directly on OK. However, you can change the name of the data set to
something more meaningful than the default Data Set #1, and you can override the data
set range. We did the latter, so that only data through year 16 (row 17) is part of the data
set. The future years, with blank data for Total Cost, shouldn't be part of the data set used
for regression.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
A
B
C
D
E
F
G
Month
Units Produced
Total Cost
Month
Units Produced
Total Cost
1
500
$131,000
17
400
2
600
$135,000
18
800
3
400
$104,000
4
300
$76,000
5
800
$186,000
6
900
$190,100
7
600
$150,000
8
400
$98,000
9
300
$78,000
10
200
$60,000
11
400
$108,000
12
600
$152,000
13
700
$158,000
14
500
$134,380
15
300
$86,000
16
200
$60,000
Figure 14.8
Cost and Production
Data for a Single
Product
A scatterplot of Y ver-
sus X is always a good
place to start in any
regression analysis.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

14.3 Simple Regression Models
855
Once you have designated a StatTools data set, again the ﬁrst step in any analysis, you
can then create a scatterplot from the Summary Graphs dropdown list. This leads to the
dialog box in Figure 14.11, where you can select the Y and X variables. (Actually, you can
select multiple Ys and Xs. You will then get a scatterplot of each Y-X pair.) You can also
control where the results go (for the scatterplot procedure or any of the other StatTools pro-
cedures) by clicking on the “double-check” button at the bottom. This leads to the dialog
box in Figure 14.12, where you can select from the four Placement options shown. (We tend
to favor either the Active Workbook option, which places the results on a new worksheet,
or the Query for Starting Cell option, where you can designate where you want the results
to start. You can experiment with these options.)
The resulting scatterplot for this example appears in Figure 14.13. This plot indicates
a clear linear relationship, where Total Cost increases as Units Produced increases. Although
this chart was created with StatTools, it (like other StatTools charts) is a regular Excel
chart, so you can modify it just as you can modify any other Excel chart. In particular, you
can superimpose a trend line along with the equation of the line and the R-square value, as
shown in the ﬁgure.
Figure 14.9
StatTools Ribbon
Figure 14.10
StatTools Data Set
Manager
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Discussion of the Results
The equation of the straight line has a slope, 198.47, and an intercept, 23,643. For this
example, both numbers have a natural interpretation. The slope corresponds to the unit
variable cost of production. Each extra unit produced contributes an estimated $198.47 to
total cost. The intercept corresponds to the ﬁxed cost of production. The estimate of the
ﬁxed cost is $23,643, regardless of the production level.
856
Chapter 14
Regression and Forecasting Models
Figure 14.11
Scatterplot Dialog
Box
Figure 14.12
Results Placement
Options in StatTools
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

As discussed previously, the R-square value is the percentage of variation of Total Cost
explained by Units Produced. In this case, Units Produced explains slightly more than 97%
of the variation in Total Cost; only about 3% of this variation is left unexplained. Alterna-
tively, multiple R, the square root of R-square, is the correlation between the actual Total
Cost values and the ﬁtted Total Cost values, as predicted by the regression equation. In this
case, multiple R is 
.
Although the Add Trendline option leads to a quick regression equation, the Stat-
Tools regression procedure can be used to find the fitted values, the residuals, and the
standard error of estimate. In addition, it can be used to find predictions and 95% pre-
diction limits for the new data in months 17 and 18, where X but not Y is known.5 There
are two steps, where the first is required only if you want to make future predictions.
1. Designate the data for future months as a second StatTools data set with the Data
Set Manager. We called it Data for Prediction, and it is the range E1:G3 (see
Figure 14.8).
2. Select Regression from the StatTools Regression and Classification dropdown
list, and fill in the resulting dialog box as shown in Figure 14.14. There are a
number of options in this dialog box. The options you will select most often are
the following: 
■
Select Multiple as the Regression Type. There is no Simple option; you use
Multiple for a single X or multiple Xs.
■
Make sure you select the appropriate data set from the Data Set dropdown list
(in case you have defined multiple data sets). 
■
Select a single dependent variable in the D list and one or more explanatory
(independent) variables in the I list.
■
To see a chart of the residuals, along with a list of ﬁtted values and residuals, select
at least one of the optional graphs. We usually choose the third, Residuals vs Fitted
Values.
■
If you have a data set to be predicted, as in this example, check the bottom op-
tion and select the appropriate data set to be predicted.
10.9717 = 0.9858
14.3 Simple Regression Models
857
y = 198.47x + 23643
R² = 0.9717
0
50000
100000
150000
200000
250000
0
100
200
300
400
500
600
700
800
900
1000
Total Cost / Data for Regression
Units Produced / Data for Regression
Scaerplot of Total Cost vs Units Produced of Data for Regression
Figure 14.13
Scatterplot of Total
Cost versus Units
Produced with Line
Superimposed
5In the previous edition, we used Excel’s built-in Analysis Toolpak add-in for much of the regression analysis and
moved to StatTools only when it was necessary later in the chapter. You can certainly continue to use the Analy-
sis Toolpak (which hasn’t been updated for close to two decades), but StatTools is so much better that we decided
to use it throughout.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

The regression results appear in Figures 14.15 and 14.16, and the future predictions
appear in Figure 14.17. There is a lot of information here, but the good news is that the 
regression output from StatTools includes the same items, mostly even in the same format,
as the regression output from any other statistical package. The most important aspects of
the output are the following:
■
The estimated regression line is speciﬁed by the values in the Coefﬁcients column of
Figure 14.15. In particular, the value in cell B19 implies that each additional unit
produced adds about $198 to total cost.
■
The large R-square and multiple R values at the top of Figure 14.15 conﬁrm exactly
what the scatterplot indicates—that a very strong linear relationship exists between
Total Cost and Units Produced.
■
The standard error of estimate at the top of Figure 14.15 indicates that the prediction
errors based on this regression equation will be in the neighborhood of $7000—many
prediction errors will be less than this value and a few will be more. This large an
error might sound like a lot, but it is not all that large compared to the magnitudes of
total costs, which are often well over $100,000.
858
Chapter 14
Regression and Forecasting Models
Figure 14.14
Regression Dialog
Box
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

14.3 Simple Regression Models
859
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
A
B
C
D
E
F
Graph Data
Total Cost
Fit
Residual
1
131000
122876.2
8123.8
2
135000
142722.8
-7722.8
3
104000
103029.6
970.4
4
76000
83183.0
-7183.0
5
186000
182416.0
3584.0
6
190100
202262.6
-12162.6
7
150000
142722.8
7277.2
8
98000
103029.6
-5029.6
9
78000
83183.0
-5183.0
10
60000
63336.5
-3336.5
11
108000
103029.6
4970.4
12
152000
142722.8
9277.2
13
158000
162569.4
-4569.4
14
134380
122876.2
11503.8
15
86000
83183.0
2817.0
16
60000
63336.5
-3336.5
-15000.0
-10000.0
-5000.0
0.0
5000.0
10000.0
15000.0
0.0
50000.0
100000.0
150000.0
200000.0
250000.0
Residual
Fit
Scaerplot of Residual vs Fit
Figure 14.16
Fitted Values and
Residuals
7
8
9
10
11
12
13
14
15
16
17
18
19
A
B
C
D
E
F
G
rr
E
t
S
d
e
ts
ujd
A
elpitlu
M
 of 
Summary
R
R
-Square
Esmate
0.9858
0.9717
0.9697
7261.71
Degrees of
Sum of 
Mean of 
ANOVA Table
Freedom
Squares
Squares
Explained
1
25381116403
25381116403
481.3192
< 0.0001
Unexplained
14
738253596.9
52732399.78
Standard
Regression Table
r
e
p
p
U
r
e
w
o
L
r
o
rr
E
Constant
23643.26
4716.87
5.0125
0.0002
13526.58
33759.94
Units Produced
198.47
9.05
21.9390
< 0.0001
179.06
217.87
R-Square
F-Rao
p-Value
t
t
n
eiciff
e
o
C
-Value
p-Value
Conﬁdence Interval 95%
Figure 14.15 Simple Regression Output
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

860
Chapter 14
Regression and Forecasting Models
■
The scatterplot of residuals versus ﬁtted values in Figure 14.16 is a diagnostic tool
used to see if there are peculiar points or patterns. The shapeless swarm seen here is
an indication that no regression assumptions are violated. This plot is based on the
data below it. You can check that each ﬁtted value can be found by plugging its X
into the regression equation, and each residual is the difference between the actual
Total Cost value and the predicted (ﬁtted) value.
■
The predictions in Figure 14.17 are also found by plugging the known X values into
the regression equation, but no residuals are possible because the actual Total Cost
values are not yet known for these months. Instead, StatTools provides the limits for
a 95% prediction interval around each prediction. Essentially, if you make a lot of
predictions based on a regression equation, about 95% of the actual Y values will be
inside their respective 95% prediction intervals. 
■
1
2
3
E
F
G
H
I
Month
Units Produced
Total Cost LowerLimit95
UpperLimit95
17
400
103029.6
86898.3
119161.0
18
800
182416.0
165211.8
199620.2
Figure 14.17
Prediction of Future
Values
P R O B L E M S
Solutions for problems whose numbers appear within a
colored box can be found in the Student Solutions Files.
Refer to this book’s preface for purchase information.
Skill-Building Problems
1.
The ﬁle P14_01.xlsx contains the monthly number of
airline tickets sold by a travel agency. 
a. Does a linear trend appear to ﬁt these data well? 
If so, estimate and interpret the linear trend model
for this time series. Also, interpret the R2 and se
values.
b. Provide an indication of the typical forecast error
generated by the estimated model in part a.
c. Is there evidence of some seasonal pattern in these
sales data? If so, characterize the seasonal pattern.
2.
The ﬁle P14_02.xlsx contains the daily closing prices
of Walmart stock for a one-year period. Does a linear
or exponential trend ﬁt these data well? If so, estimate
and interpret the best trend model for this time series.
Also, interpret the R2 and se values.
3.
The ﬁle P14_03.xlsx contains monthly data on produc-
tion levels and production costs during a four-year pe-
riod for a company that produces a single product. Use
simple regression on all of the data to see how Total
Cost is related to Units Produced. Use the resulting
equation to predict total cost in month 49, given that the
proposed production level for that month is 450 units.
Do you see anything wrong with the analysis? How
should you modify your analysis if your main task is to
ﬁnd an equation useful for predicting future costs, and
you know that the company installed new machinery
at the end of month 18? Write a concise memo to
management that describes your ﬁndings.
4.
The ﬁle P14_04.xlsx lists the monthly sales for a com-
pany (in millions of dollars) for a 10-year period.
a. Fit an exponential trend line to these data.
b. By what percentage do you estimate that the com-
pany will grow each month?
c. Why can’t a high rate of exponential growth con-
tinue for a long time?
d. Rather than an exponential curve, what type of
curve might better represent the growth of a new
technology?
5.
Management of a home appliance store wants to 
understand the growth pattern of the monthly sales 
of a new technology device over the past two years.
The managers have recorded the relevant data in the
ﬁle P14_05.xlsx. Have the sales of this device been
growing linearly over the past 24 months? By
examining the results of a linear trend line, explain
why or why not.
6.
Do the sales prices of houses in a given community
vary systematically with their sizes (as measured in
square feet)? Answer this question by estimating a
simple regression equation where the sales price of the
house is the dependent variable, and the size of the
house is the explanatory variable. Use the sample data
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

given in P14_06.xlsx. Interpret your estimated equa-
tion, the associated R-square value, and the associated
standard error of estimate.
7.
The ﬁle P14_07.xlsx contains monthly values of the
U.S. national debt (in dollars) from 1993 to early
2010. Fit an exponential growth curve to these data.
Write a short report to summarize your ﬁndings. If the
U.S. national debt continues to rise at the exponential
rate you ﬁnd, approximately what will its value be at
the end of 2020?
8.
The ﬁle P14_08.xlsx contains ﬁve years of monthly
data on sales (number of units sold) for a particular
company. The company suspects that except for ran-
dom noise, its sales are growing by a constant percent-
age each month and will continue to do so for at least
the near future.
a. Explain brieﬂy whether the plot of the series visu-
ally supports the company’s suspicion.
b. By what percentage are sales increasing each
month?
c. What is the MAPE for the forecast model in part b?
In words, what does it measure? Considering its
magnitude, does the model seem to be doing a
good job?
d. In words, how does the model make forecasts for
future months? Speciﬁcally, given the forecast
value for the last month in the data set, what simple
arithmetic could you use to obtain forecasts for the
next few months?
Skill-Extending Problems
9.
We have discussed linear and exponential trend lines.
Another popular choice is a power trend line, also
called a constant elasticity trend line. This trend line
has the form y  axb, and it has the property that when
14.4 Multiple Regression Models
861
x increases by 1%, y changes by a constant percent-
age. In fact, this constant percentage is approximately
equal to the exponent b (which could be positive or
negative). The power trend line is often cited in the
economics literature, where, for example, x might be
price and y might be demand. Fortunately, it can be
found through Excel’s Trendline tool; the power trend
line is just another option. Estimate and interpret a
power trend line for the data on demand and price of a
commodity listed in the ﬁle P14_09.xlsx. In particular,
if price increases by 1%, what do you expect to hap-
pen to demand? Calculate the MAPE for this power
trend line. Would you say it indicates a good ﬁt?
10. Sometimes curvature in a scatterplot can be ﬁt
adequately (especially to the naked eye) by several
trend lines. We discussed the exponential trend line,
and the power trend line is discussed in the previous
problem. Still another fairly simple trend line is the
parabola, a polynomial of order 2 (also called a
quadratic). For the demand-price data in the ﬁle
P14_10.xlsx, ﬁt all three of these types of trend lines
to the data, and calculate the MAPE for each.
Which provides the best ﬁt? (Hint: Note that a polyno-
mial of order 2 is still another of Excel’s Trend line
options.)
11. The management of a technology company is trying to
determine the variable that best explains the variation
of employee salaries using a sample of 52 full-time
employees; see the ﬁle P14_11.xlsx. Estimate simple
linear regression equations to identify which of the
following has the strongest linear relationship with
annual salary: the employee’s gender, age, number
of years of relevant work experience prior to employ-
ment at the company, number of years of employment
at the company, or number of years of post secondary
education. Provide support for your conclusion.
14.4 MULTIPLE REGRESSION MODELS
When you try to explain a dependent variable Y with regression, there are often a multitude
of explanatory variables to choose from. In this section, we explore multiple regression,
where the regression equation for Y includes a number of explanatory variables, the Xs.
The general form of this equation is shown in the box. Geometrically, this equation repre-
sents a hyperplane through a scatter of points in (k  1)-dimensional space (k Xs and one Y).
However, unless k  1 or k  2, this hyperplane is impossible to draw. Nevertheless, it is
helpful to keep the image of a plane passing through a set of points in mind as you study
multiple regression.
Multiple regression equation
Y  a  b1X1  b2X2    bkXk
(14.7)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

In Equation (14.7), a is again the Y-intercept, and b1 through bk are the slopes. Collec-
tively, a and the bs are called the regression coefﬁcients. Each slope coefﬁcient is the ex-
pected change in Y when that particular X increases by one unit and the other Xs in the
equation remain constant. For example, b1 is the expected change in Y when X1 increases
by one unit and the other Xs in the equation, X2 through Xk, remain constant. The intercept a
is typically less important. Literally, it is the expected value of Y when all of the Xs equal 0.
However, this makes sense only if it is practical for all of the Xs to equal 0, which is rarely
the case.
862
Chapter 14
Regression and Forecasting Models
The regression coefﬁcients are the intercept and slopes of the regression equation.
We illustrate these ideas in the following extension of Example 14.2.
E X A M P L E
14.3 ESTIMATING TOTAL COST FOR SEVERAL PRODUCTS
S
uppose the company in Example 14.2 now produces three different products, A, B, and
C. The company has kept track of the number of units produced of each product and the
total production cost for the past 15 months. These data appear in Figure 14.18 and in the
ﬁle Cost Regression 2.xlsx. What does multiple regression say about the relationship be-
tween these variables? How can multiple regression be used to predict future production
costs?
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
A
B
C
D
E
Month
Units A
Units B
Units C
Total Cost
1
696
819
895
$58,789
2
627
512
925
$50,276
3
122
323
814
$43,703
4
313
981
670
$50,857
5
340
884
356
$46,397
6
462
599
673
$46,731
7
269
302
737
$40,328
8
343
495
878
$42,368
9
986
191
592
$44,617
10
555
314
467
$40,515
11
908
593
749
$55,546
12
595
115
458
$36,856
13
557
369
160
$35,697
14
271
550
457
$40,130
15
878
750
983
$59,929
Figure 14.18
Cost and Production
Data for Multiple
Products
Objective
To use multiple regression to estimate the relationship between units produced
of three products and the total production cost, and to use this relationship to predict future
total costs.
Solution
The dependent variable Y is again Total Cost, but there are now three potential Xs, Units A,
Units B, and Units C. It is not necessary to use all three of these, but we do so here. In fact,
it is again a good idea to begin with scatterplots of Y versus each X to see which Xs 
are indeed related to Y. You can do this in one step with StatTools, selecting Total Cost as
the Y variable and Units A, B, and C as the X variables. A typical scatterplot appears in
Figure 14.19. This scatterplot—and the ones for products A and C are similar—indicates a
fairly strong linear relationship between Total Cost and Units B.
A useful first step in
multiple regression is
to create a scatterplot
of Y versus each of
the Xs.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

14.4 Multiple Regression Models
863
0
10000
20000
30000
40000
50000
60000
70000
0
200
400
600
800
1000
1200
Total Cost / Data for Regression
Units B / Data for Regression
Scaerplot of Total Cost vs Units B of Data for Regression
Figure 14.19
Scatterplot of Total Cost versus Units B
When there are multiple Xs, you cannot estimate the multiple regression equation by
using Excel’s Trendline option as you did with simple regression. However, you can still
use StatTools, exactly as in the previous example. As before, ﬁrst deﬁne StatTools data sets
for the regression data (months 1 to 15) and for the prediction data set (months 16 and 17).
Then ﬁll in the StatTools Regression dialog box as shown in Figure 14.20.
Discussion of the Results
The resulting output appears in Figures 14.21 to 14.23. Again, we will not explain all of
this output, but we will focus on the highlights. The most important part is the regression
equation itself, which is implied by the values in the B18:B21 range:
Predicted Total Cost  20,261  12.802Units A  17.691Units B  15.230Units C
The interpretation is much like that in simple regression. Each coefﬁcient of a Units vari-
able can be interpreted as a variable cost. For example, each extra unit of product B con-
tributes about $17.69 to total cost. The constant term, 20,261, is again the estimated ﬁxed
cost of production. This cost is incurred regardless of the level of production.
The other important outputs are R-square, multiple R, the standard error of estimate,
the ﬁtted values, and the residuals:
■
The R-square value is the percentage of variation of Total Cost explained by the
combination of all three explanatory variables. You can see that these three Units
variables explain about 94.6% of the variation in Total Cost—a fairly high 
percentage.
■
The multiple R, the square root of R-square, is the correlation between the actual Ys
and ﬁtted values. Because R-square is large, the multiple R is also large: 0.973. This
high value implies that the points in a scatterplot (not shown) of actual Y values
versus ﬁtted values are close to a 45° line.
When there are multi-
ple independent vari-
ables, Excel’s Trendline
option cannot be used
to find the regression
equation.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

864
Chapter 14
Regression and Forecasting Models
Figure 14.20
Dialog Box for Mul-
tiple Regression
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
A
B
C
D
E
F
G
rr
E
t
S
d
e
ts
ujd
A
elpitlu
M
 of 
Summary
R
R
-Square
Esmate
0.9726
0.9459
0.9312
1980.505
Degrees of
Sum of 
Mean of 
ANOVA Table
Freedom
Squares
Squares
Explained
3
754480290.6
251493430.2
64.1172
< 0.0001
Unexplained
11
43146416.96
3922401.542
Standard
Regression Table
r
e
p
p
U
r
e
w
o
L
r
o
rr
E
Constant
20261.273
1968.133
10.2947
< 0.0001
15929.442
24593.103
Units A
12.802
2.083
6.1466
< 0.0001
8.218
17.386
Units B
17.691
2.137
8.2784
< 0.0001
12.988
22.395
Units C
15.230
2.346
6.4907
< 0.0001
10.065
20.394
R-Square
F-Rao
p-Value
t
t
n
eiciff
e
o
C
-Value
p-Value
Conﬁdence Interval 95%
Figure 14.21 Multiple Regression Output
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

14.4 Multiple Regression Models
865
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
A
B
C
D
E
F
Graph Data
Total Cost
Fit
Residual
1
58789
57291.1
1497.9
2
50276
51433.5
-1157.5
3
43703
39934.4
3768.6
4
50857
51827.3
-970.3
5
46397
45674.7
722.3
6
46731
47022.4
-291.4
7
40328
40272.1
55.9
8
42368
46781.2
-4413.2
9
44617
45279.0
-662.0
10
40515
40033.7
481.3
11
55546
53783.4
1762.6
12
36856
36888.1
-32.1
13
35697
36356.7
-659.7
14
40130
40420.7
-290.7
15
59929
59740.6
188.4
-5000.0
-4000.0
-3000.0
-2000.0
-1000.0
0.0
1000.0
2000.0
3000.0
4000.0
5000.0
0.0
10000.0
20000.0
30000.0
40000.0
50000.0
60000.0
70000.0
Residual
Fit
Scaerplot of Residual vs Fit
Figure 14.22 Fitted Values and Residuals
1
2
3
G
H
I
J
K
L
M
Month
Units A
Units B
Units C
Total Cost LowerLimit95
UpperLimit95
16
450
660
540
45922.4
41312.7
50532.0
17
350
520
720
44906.8
40308.1
49505.5
Figure 14.23 Predictions of Future Values
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

866
Chapter 14
Regression and Forecasting Models
■
The standard error of estimate has exactly the same interpretation as before. It is a
ballpark estimate of the magnitude of the prediction errors you are likely to make,
based on the regression equation. Here, this value is about $1981—not too bad
considering that the total costs vary around $50,000.
■
As before, the ﬁtted values in Figure 14.22 are found by substituting each set of Xs
into the regression equation, and the residuals are the differences between actual 
total costs and ﬁtted values. As indicated by the standard error of estimate, most 
of the residuals are no more than about $2000 in magnitude, and quite a few are 
considerably less than this. Also, the scatterplot of residuals versus ﬁtted values in
Figure 14.22 is a shapeless swarm, a promising indication that no regression assump-
tions have been violated.
■
The predictions of future values in Figure 14.23 are found by plugging the known X
values into the regression equation. As before, StatTools provides a 95% prediction
interval for each of these predictions.
■
StatTools provides outputs with more decimal places than shown in the ﬁgures. We
believe it is a good idea to round these. Don’t be fooled into thinking that regression
can be accurate to 10 decimal places (or however many) just because the software
shows this many decimal places. It is not that exact a science, especially not with
data from the business world.
A Note about Adjusted R-square
You are probably wondering what the adjusted R-square value means in the multiple
regression output. Although it has no simple interpretation like R-square (percentage of
variation explained), it is useful for comparing regression equations. The problem with
R-square is that it can never decrease when extra explanatory variables are added to a regres-
sion equation. However, there ought to be some penalty for adding variables that don’t re-
ally belong. This is the purpose of adjusted R-square, which acts as a monitor. If you add
one or more extra explanatory variables to an already existing equation, adjusted R-square
can decrease. If this occurs, it is evidence that the extra variables don’t really belong in the
equation and should probably be deleted.
■
Incorporating Categorical Variables
The goal of regression analysis is to ﬁnd good explanatory variables that explain some 
dependent variable Y. Often these explanatory variables are quantitative, such as the Units
Produced variables in the two previous examples. However, there are often useful qualita-
tive categorical variables that help explain Y, such as gender (male or female), region of
country (east, south, west, or north), quarter of year (Q1, Q2, Q3, or Q4), and so on. Because
regression works entirely with numbers, categorical variables must typically be trans-
formed into numeric variables that can be used in a regression equation. This is usually
done by creating dummy variables, also called 0–1 variables or indicator variables. For
any categorical variable, you create a dummy variable for each possible category. Its value
is 1 for each observation in that category, and it is 0 otherwise.
The interpretation of
regression output for
multiple regression is
similar to that for sim-
ple regression. In par-
ticular, R-square, multi-
ple R, the standard
error of estimate, the
fitted values, and the
residuals mean exactly
the same thing in
both cases.
If adjusted R-square
decreases when extra
explanatory variables
are added to a regres-
sion equation, these
variables are not useful
and should probably
be deleted.
A dummy variable for any category equals 1 for all observations in that category and
0 for all observations not in that category.
For example, the variable Gender has two possible values, Male and Female, so you
can create two dummy variables, Male and Female. Male equals 1 for all males and 0 for
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

14.4 Multiple Regression Models
867
all females, whereas Female equals 1 for all females and 0 for all males. As another exam-
ple, if the variable Quarter has possible values Q1, Q2, Q3, and Q4, you can create four
dummy variables, one for each quarter. For example, the dummy variable Quarter1 equals
1 for all quarter 1 observations and 0 for all other observations.
There is one technical rule you must follow when using dummy variables in regres-
sion. If a categorical variable has m categories, you should use only m – 1 of the m possi-
ble dummy variables in the regression equation. You can omit any one of the dummies,
which becomes the reference (or base) category. You then interpret the regression coefﬁ-
cients of the included dummies with respect to the reference category. For example, if Y is
salary, and if you include the dummy variable Male in the equation, the reference category
is female. If the coefﬁcient of Male turns out to be, say, $2000, the interpretation is that, all
else being equal, males average $2000 more in salary than females. If you had included
Female instead of Male in the equation, the coefﬁcient of Female would be –$2000, mean-
ing again that females average $2000 less than males. The point is that one dummy must be
omitted, and it doesn’t matter which one you omit.
The following example, another extension of Example 14.2, illustrates the use of
dummy variables.
FUNDAMENTAL INSIGHT
Which Explanatory Variables to Use
Regression outputs contain a lot of n umbers and
graphs, and it can be difﬁcult to learn what the y all
mean. However, the biggest challenge in using regres-
sion, especially with the abundance of data in toda y’s
world, is discovering the best set of explanatory vari-
ables to include in a regression equation. Besides the
variables in the original data set,
you can cr eate
dummy variables, nonlinear functions of the original
variables (such as logarithms), lagged versions of the
original variables, and others. It takes some experi-
ence with regression, and with the problem at hand,
to find a g ood set of explanator y variables. It also
takes a willingness to experiment. There is almost
never one best regression equation; there are usually
several that are useful.
For a categorical vari-
able with m categories,
include only m1 of
the corresponding
dummy variables in the
regression equation.
Any one of them can
be omitted.
E X A M P L E
14.4 ESTIMATING PRODUCTION COSTS AT THREE COMPANY PLANTS
S
uppose the company in Example 14.2 produces a single product at three different manu-
facturing plants. As in that example, the company wants to regress total cost on units
produced, but it suspects that the relationship between these variables might differ across
plants. It has monthly data from the past 16 months for each of the plants, some of which
appear in Figure 14.24. (See the ﬁle Cost Regression 3.xlsx.) How can the company use
dummy variables to estimate the relationship between Total Cost and Units Produced for
all three plants simultaneously?
Objective
To use dummy variables for plants to estimate a single regression equation
relating total cost to units produced for all three plants.
Solution
StatTools has a utility that can be used to create the required dummy variables for plants.
Then you can use its multiple regression procedure in the same way as before to estimate
the regression equation that includes the dummies.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

868
Chapter 14
Regression and Forecasting Models
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
A
B
C
D
Month
Plant
Units Produced
Total Cost
1
1
800
$190,600
1
2
500
$142,200
1
3
200
$46,400
2
1
400
$99,700
2
2
800
$194,300
2
3
300
$74,400
3
1
300
$82,800
3
2
700
$171,100
3
3
200
$50,100
4
1
400
$104,300
4
2
600
$158,600
4
3
200
$52,100
5
1
600
$148,800
5
2
800
$201,500
5
3
600
$132,000
6
1
300
$81,500
6
2
600
$155,900
6
3
200
$45,300
7
1
500
$129,100
7
2
700
$179,000
7
3
400
$86,600
8
1
400
$105,500
Figure 14.24
Cost Data for Three
Plants
Creating the Dummy Variables and Running the Regression
One way to create dummy variables for the plants is with IF formulas. For example, you
could use the following formula (copied down) to create the dummy variable for Plant 1:
=IF(B2=1,1,0)
However, it is easier to use StatTools. To do so, select Dummy from the StatTools Data
Utilities dropdown list and ﬁll out the resulting dialog box as shown in Figure 14.25. This
will create a separate dummy variable for each category of the Plant variable, that is, for
each plant. (You will be warned that these new variables are being added to the data set.
Click OK on the warning.) The resulting data appear as shown in Figure 14.26, with the
dummies in columns E–G.
Then the StatTools multiple regression can be used, with Total Cost as Y and Units
Produced and any two of the three Plant dummies as the Xs. (We chose the dummies for
plants 2 and 3, using plant 1 as the reference category.) The regression output is shown in
Figure 14.27.
Discussion of the Results
The regression equation implied by this output is literally:
Predicted Total Cost  22,852  12,972Plant2  15,045Plant3 
 204.15 Units Produced
However, it is more intuitive to think of this as three separate equations, one for each plant.
For plant 1, the reference category, the dummies Plant2 and Plant3 are 0, so the equa-
tion reduces to
Predicted Total Cost (plant 1)  22,852  204.15 Units Produced
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

14.4 Multiple Regression Models
869
1
2
3
4
5
6
A
B
C
D
E
F
G
Month
Plant
Units Produced
Total Cost
Plant = 1
Plant = 2
Plant = 3
1
1
800
$190,600
1
0
0
2
1
400
$99,700
1
0
0
3
1
300
$82,800
1
0
0
4
1
400
$104,300
1
0
0
5
1
600
$148 800
1
0
0
6
7
8
9
10
11
5
1
600
$148,800
1
0
0
6
1
300
$81,500
1
0
0
7
1
500
$129,100
1
0
0
8
1
400
$105,500
1
0
0
9
1
300
$81,700
1
0
0
10
1
800
$185,100
1
0
0
Figure 14.26
Original Data with
Dummy Variables
Added
Figure 14.25
Dummy Variable 
Dialog Box
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
A
B
C
D
E
F
G
rr
E
t
S
d
e
ts
ujd
A
elpitlu
M
 of 
Summary
R
R
-Square
Esmate
0.9974
0.9948
0.9945
3525.06
Degrees of
Sum of 
Mean of 
ANOVA Table
Freedom
Squares
Squares
Explained
3
1.05525E+11
35175003210
2830.7523
< 0.0001
Unexplained
44
546745160.2
12426026.37
Standard
Regression Table
r
e
p
p
U
r
e
w
o
L
r
o
rr
E
Constant
22851.94
1607.29
14.2177
< 0.0001
19612.65
26091.22
Units Produced
204.15
2.69
75.9382
< 0.0001
198.73
209.56
Plant = 2
12971.97
1278.61
10.1454
< 0.0001
10395.11
15548.84
Plant = 3
-15045.29
1262.50
-11.9171
< 0.0001
-17589.69
-12500.89
R-Square
F-Rao
p-Value
t
t
n
eiciff
e
o
C
-Value
p-Value
Conﬁdence Interval 95%
Figure 14.27
Regression Output with Dummy Variables Included
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

For plant 2, the dummy Plant2 is 1 and the dummy Plant3 is 0, so the equation 
reduces to
Predicted Total Cost (plant 2)  (22,852  12,972)  204.15Units Produced
Finally, for plant 3, the dummy Plant2 is 0 and the dummy Plant3 is 1, so the equation
reduces to
Predicted Total Cost (plant 3)  (22,852  15,045)  204.15Units Produced
You can see from these equations that the coefﬁcient of Units Produced is 204.15 for
each plant. Therefore, if any of the plants produces an extra unit, its total cost is expected
to increase by about $204. The only difference between the equations is their intercepts.
Speciﬁcally, if plants 1 and 2 produce the same numbers of units, plant 2’s total cost is
expected to be $12,972 higher than plant 1’s. Similarly, if plants 1 and 3 produce the same
numbers of units, plant 3’s total cost is expected to be $15,045 lower than plant 1’s. In this
sense, the coefﬁcients of the dummy variables allow you to compare each plant to the ref-
erence plant. You can also compare nonreference plants to one another. If plants 2 and 3
produce the same numbers of units, plant 2’s total cost is expected to be ($12,972 
$15,045) higher than plant 3’s.
Geometrically, the regression analysis produces three parallel lines for the three plants,
as shown in Figure 14.28. Each of the lines has the same slope, 204.15, but they have
different intercepts. By including the dummy variables as separate terms in the regression
equation, you are forcing the regression to estimate parallel lines, so that the effect of Units
Produced on Total Cost is the same for each plant. If you believe this effect differs across
plants—that is, you believe the variable costs for the three plants might not be the same—
you must include extra explanatory variables, called interaction variables, to the regression
equation. However, we will not pursue this topic here.
870
Chapter 14
Regression and Forecasting Models
$150,000
$200,000
$250,000
Plant1
$0
$50,000
$100,000
0
200
400
600
800
1000
Plant1
Plant2
Plant3
Figure 14.28
Estimation of Three
Parallel Regression
Lines
■
A Caution about Regression Assumptions
In this brief introduction to regression, we have discussed only the basic elements of re-
gression analysis, and we have omitted many of the technical details that can be found in
more complete statistics books. In particular, we have not discussed what can go wrong if
various statistical assumptions behind regression analysis are violated. Although there is
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

not room here for a complete discussion of these assumptions and their ramiﬁcations, we
brieﬂy state a few cautions you should be aware of.
Multicollinearity
In the best of worlds, the explanatory variables, the Xs, should provide nonoverlapping in-
formation about the dependent variable Y. They should not provide redundant information.
However, sometimes redundancy is difﬁcult to avoid. For example, in trying to explain em-
ployee salaries, three potential explanatory variables are age, years of seniority with this
company, and years of experience with this type of job. These three variables are likely to
be highly correlated with one another (as well as with salary), and it is not clear whether all
three should be included in a regression equation for salary.
When you do include Xs that are highly correlated with one another, you introduce a
problem called multicollinearity. The problem is that when Xs are highly correlated with
one another, it is virtually impossible to sort out their separate inﬂuences on Y. This inabil-
ity to sort out separate effects can even lead to “wrong” signs on the regression coefﬁcients.
For example, if age, years of seniority, and years of experience are all entered in an equa-
tion for salary, it is possible that one of the three regression coefﬁcients will be negative,
even though all three variables are positively correlated to salary. Therefore, the presence
of multicollinearity makes regression equations difﬁcult to interpret. Fortunately, however,
multicollinearity is not a problem if you are concerned only with prediction of new Ys.
Nonlinear Relationships
If scatterplots of Y versus the various Xs indicate any nonlinear relationships, a linear rela-
tionship will almost certainly lead to a poor ﬁt and poor predictions. Fortunately, as with
the exponential trend line, there are often nonlinear transformations of Y and/or the Xs that
“straighten out” the scatterplots and allow you to use linear regression. We will not discuss
such transformations here. We simply warn you that if the scatterplots of the original vari-
ables do not appear to be linear, you should not blindly proceed to estimate a linear
relationship.
Nonconstant Error Variance
One assumption of regression is that the variation of the Y values above any values of the
Xs is the same, regardless of the particular values of the Xs chosen. Sometimes this as-
sumption is clearly violated. For example, if Y is a household’s annual amount spent on 
vacations and X is the household’s annual income, it is very possible that the variation of 
Y values for low-income households is considerably less than that for high-income
households. The low-income households don’t have much to spend on vacations, so their
vacation spending is likely to be tightly bunched at low values. In contrast, the high-income
households have a lot to spend, but they might or might not elect to spend it on vacations.
Typically, nonconstant error variance appears in a scatterplot as a fan-shaped swarm of
points. We simply alert you to this possibility and suggest that you obtain expert help if you
spot an obvious fan shape.
Autocorrelation of Residuals
Autocorrelation means that a variable’s values are correlated with its own previous values.
This typically occurs in time series variables. For example, regression might be used to
forecast monthly sales. If the residuals are autocorrelated, then an overprediction in
January is likely to be followed by an overprediction in February, and an underprediction
in June is likely to be followed by an underprediction in July. It is not difﬁcult to detect
14.4 Multiple Regression Models
871
Multicollinearity makes
it difficult to interpret
individual regression
coefficients, but it
does not have a
negative effect on
predictions.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

autocorrelation of residuals (although we will not discuss the measures for doing so), but it
is much more difﬁcult to deal with autocorrelation appropriately. Again, you should con-
sult an expert if you believe your time series analysis is subject to autocorrelation.
872
Chapter 14
Regression and Forecasting Models
FUNDAMENTAL INSIGHT
Cautions about Regr
ession
Regression is a very powerful method for discovering
relationships between variables, and with the soft-
ware available in today’s world, it is very easy to use.
Unfortunately, it is also v ery easy to use incor rectly.
Many people are not aware of the assumptions behind
the regression model, how to check whether these
assumptions hold,or how to modify the analysis if the
assumptions do not hold. This has led to many incor-
rect interpretations of r egression output. Like most
powerful tools, regression is easy to misuse if y ou
don’t understand some of the theor y behind it. Be-
cause this theory is fairly complex, don’t be afraid to
ask a statistical expert for help if you are conducting
an important regression analysis.
P R O B L E M S
Skill-Building Problems
12. Suppose you are an analyst for a company that pro-
duces four products, and you are trying to decide how
much of each product to produce next month. To
model this decision problem, you need the unit vari-
able production cost for each product. After some dig-
ging, you ﬁnd the historical data on production levels
and costs in the ﬁle P14_12.xlsx. Use these data to ﬁnd
estimates of the unit costs you need. You should also
ﬁnd an estimate of the ﬁxed cost of production. Will
this be of any use to you in deciding how much of
each product to produce? Why or why not?
13. A trucking company wants to predict the yearly main-
tenance expense (Y ) for a truck using the number of
miles driven during the year (X1) and the age of the
truck (X2, in years) at the beginning of the year. The
company has gathered the data given in the ﬁle
P14_13.xlsx. Note that each observation corresponds
to a particular truck. Estimate a multiple regression
equation using the given data. Interpret each of the
estimated regression coefﬁcients. Also, interpret the
standard error of estimate and the R-square value for
these data.
14. An antique collector believes that the price received
for a particular item increases with its age and with the
number of bidders. The ﬁle P14_14.xlsx contains data
on these three variables for 32 recently auctioned com-
parable items. Estimate a multiple regression equation
using the given data. Interpret each of the estimated
regression coefﬁcients. Is the antique collector correct
in believing that the price received for the item in-
creases with its age and with the number of bidders?
Interpret the standard error of estimate and the 
R-square value for these data.
15. Stock market analysts are continually looking for re-
liable predictors of stock prices. Consider the prob-
lem of modeling the price per share of electric utility
stocks (Y). Two variables thought to influence this
stock price are return on average equity (X1) and an-
nual dividend rate (X2). The stock price, returns on
equity, and dividend rates on a randomly selected
day for 16 electric utility stocks are provided in the
file P14_15.xlsx. Estimate a multiple regression
equation using the given data. Interpret each of the
estimated regression coefficients. Also, interpret the
standard error of estimate and the R-square value for
these data.
16. The manager of a commuter rail transportation system
was recently asked by her governing board to deter-
mine which factors have a signiﬁcant impact on the
demand for rides in the large city served by the trans-
portation network. The system manager collected data
on variables thought to be possibly related to the num-
ber of weekly riders on the city’s rail system. The ﬁle
P14_16.xlsx contain these data.
a. What do you expect the signs of the coefﬁcients of
the explanatory variables in this multiple regres-
sion equation to be? Why? (Answer this before
running the regression.)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

b. Estimate a multiple regression equation using the
given data. Interpret each of the estimated regres-
sion coefﬁcients. Are the signs of the estimated
coefﬁcients consistent with your expectations in
part a?
c. What proportion of the total variation in the num-
ber of weekly riders is not explained by this esti-
mated multiple regression equation?
17. Consider the enrollment data for Business Week’s
top U.S. graduate business programs in the ﬁle
P14_17.xlsx. Use the data in the MBA Data sheet 
to estimate a multiple regression equation to assess
whether there is a relationship between the total num-
ber of full-time students (Enrollment) and the follow-
ing explanatory variables: (a) the proportion of female
students, (b) the proportion of minority students, and
(c) the proportion of international students enrolled at
these business schools.
a. Interpret the coefﬁcients of the estimated regres-
sion equation. Do any of these results surprise
you? Explain.
b. How well does the estimated regression equation
ﬁt the given data?
18. Suppose that a regional express delivery service com-
pany wants to estimate the cost of shipping a package
(Y) as a function of cargo type, where cargo type in-
cludes the following possibilities: fragile, semifragile,
and durable. Costs for 15 randomly chosen packages
of approximately the same weight and same distance
shipped, but of different cargo types, are provided in
the ﬁle P14_18.xlsx.
a. Estimate a regression equation using the given
sample data, and interpret the estimated regression
coefﬁcients.
b. According to the estimated regression equation,
which cargo type is the most costly to ship? Which
cargo type is the least costly to ship?
c. How well does the estimated equation ﬁt the given
sample data? How might the ﬁt be improved?
d. Given the estimated regression equation, predict
the cost of shipping a package with semifragile
cargo.
Skill-Extending Problems
19. The owner of a restaurant in Bloomington, Indiana,
has recorded sales data for the past 19 years. He has
also recorded data on potentially relevant variables.
The data are listed in the ﬁle P14_19.xlsx.
a. Estimate a simple regression equation involving
annual sales (the dependent variable) and the size
of the population residing within 10 miles of the
restaurant (the explanatory variable). Interpret 
R-square for this regression.
14.4 Multiple Regression Models
873
b. Add another explanatory variable—annual adver-
tising expenditures—to the regression equation in
part a. Estimate and interpret this expanded equa-
tion. How does the R-square value for this multiple
regression equation compare to that of the simple
regression equation estimated in part a? Explain
any difference between the two R-square values.
How can you use the adjusted R-squares for a com-
parison of the two equations?
c. Add one more explanatory variable to the multiple
regression equation estimated in part b. In particu-
lar, estimate and interpret the coefﬁcients of a mul-
tiple regression equation that includes the previous
year’s advertising expenditure. How does the in-
clusion of this third explanatory variable affect the
R-square, compared to the corresponding values
for the equation of part b? Explain any changes in
this value. What does the adjusted R-square for the
new equation tell you?
20. Does the rate of violent crime acts vary across differ-
ent regions of the United States? Answer this with the
(somewhat old) 1999 data in the ﬁle P14_20.xlsx as
requested below.
a. Estimate an appropriate regression model to ex-
plain the variation in violent crime rate across the
four given regions of the United States. Interpret
the estimated equation. Rank the four regions from
highest to lowest according to their mean violent
crime rate. Could you have done this without re-
gression? Explain.
b. How would you modify the regression model in
part a to account for possible differences in the vi-
olent crime rate across the various subdivisions of
the given regions? Estimate your revised regres-
sion equation and interpret your ﬁndings. Rank the
nine subdivisions from highest to lowest according
to their mean violent crime rate.
21. The ﬁle P14_21.xlsx contains data on over 200 movies
that came out in 2006 and 2007. Create a new variable
Total Revenue that is the sum of Total US Gross, Inter-
national Gross, and US DVD Sales. How well can this
new variable be predicted from the data in columns
C–F? For Distributor, relabel the categories so that
there are only two: Large Distributor and Small Dis-
tributor. The former is any distributor that had at least
12 movies in this period, and the latter is all the rest.
For Genre, relabel the categories to be Comedy,
Drama, Adventure, Action, Thriller/Suspense, and
Other. (Other includes Black Comedy, Documentary,
Horror, Musical, and Romantic Comedy.) Interpret the
coefﬁcients of the estimated regression equation. How
would you explain the results to someone in the movie
business? Do you think that predictions of total
revenue from this regression equation will be very
accurate? Why?
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

14.5 OVERVIEW OF TIME SERIES MODELS
To this point, we have discussed regression as a method of forecasting. Because of its ﬂexi-
bility, regression can be used equally well for time series variables and for cross-sectional
variables. From here on, however, we focus exclusively on time series variables, and we
discuss nonregression approaches to forecasting. All of these approaches fall under the
general umbrella of extrapolation methods.
With an extrapolation method, you form a time series plot of the variable Y that
you want to forecast, analyze any patterns inherent in this time series plot, and extrapolate
these patterns into the future. You do not use any other variables—the Xs from the previous
section—to forecast Y; you use only past values of Y to forecast future values of Y. The idea
is that history tends to repeat itself. Therefore, if you can discover the patterns in the his-
torical data, you ought to obtain reasonably good forecasts by projecting these historical
patterns into the future.
Before examining speciﬁc extrapolation techniques, we discuss the types of patterns
that are common in time series data. We also brieﬂy discuss the measures that are typically
used to judge how well forecasting methods track the historical data.
Components of Time Series
A time series variable Y typically contains one or more components. These components are
called the trend component, the seasonal component, the cyclic component, and the ran-
dom (or noise) component. We provide a brief discussion of these components here.
We start with a very simple time series in which every observation is the same, as
shown in Figure 14.29. The graph in this ﬁgure shows time t on the horizontal axis and the
observation value Y on the vertical axis. We assume that Y is measured at regularly spaced
intervals, usually days, weeks, months, quarters, or years. The value of Y in period t is de-
noted as Yt. As indicated in the ﬁgure, the individual points are usually joined by straight
lines to make any patterns in the time series more apparent. Because all observations in this
series are equal, the resulting plot is a horizontal line. We refer to this series as the base se-
ries. Then we build more interesting times series from this base series.
Trend Component
If the observations increase or decrease regularly over time, we say that the time series has
a trend. The graphs in Figure 14.30 illustrate several possible trends. We already discussed
the linear trend in Figure 14.30a and the exponential trend in Figure 14.30b in section 14.3.
The curve in Figure 14.30c is an S-shaped trend. As an example, this type of trend curve is
874
Chapter 14
Regression and Forecasting Models
1
Yt
t
2
3
4
5
6
7
Figure 14.29
The Base Series
A trend implies a
consistent upward or
downward movement
of the series over time.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

appropriate for a new product that takes a while to catch on, then exhibits a rapid increase
in sales as the public becomes aware of it, and ﬁnally tapers off to a fairly constant level.
The curves in Figure 14.30 all represent upward trends. Of course, there are downward
trends of the same types.
Seasonal Component
Many time series have a seasonal component. For example, a company’s sales of swim-
ming pool equipment increase every spring, then stay relatively high during the summer,
and then drop off until next spring, at which time the yearly pattern repeats itself. An im-
portant aspect of the seasonal component is that it tends to be predictable from one year to
the next. That is, the same seasonal pattern tends to repeat itself every year.
In Figure 14.31, we show two possible seasonal patterns. Figure 14.31a shows nothing
but the seasonal component. That is, if there were no seasonal variation, this would be the
base series from Figure 14.29. In Figure 14.31b, we show a seasonal pattern superimposed
on an upward-sloping trend line.
Cyclic Component
The third component of a time series is the cyclic component. By studying past movements
of many business and economic variables, it becomes apparent that business cycles affect
many variables in similar ways. For example, during a recession, housing starts generally
go down, unemployment goes up, stock prices go down, and so on. But when the recession
is over, all of these variables tend to move in the opposite direction.
14.5 Overview of Time Series Models
875
Yt
t
Yt
t
Yt
t
(a) Linear trend
(b) Exponential trend
(c) S-shaped trend
Figure 14.30 Series with Trends
Yt
t
Yt
t
(a) Seasonal component only
(b) Seasonal component with trend
Figure 14.31
Series with
Seasonality
In a seasonal pattern,
some seasons are
regularly higher than
others each year.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

We know that the cyclic component exists for many time series because it is visible as
the periodic swings in the levels of the time series graphs. However, the cyclic component
is harder to predict than the seasonal component. The reason is that seasonal variation is
much more regular. For example, swimming pool supplies sales always start to increase
during the spring. Cyclic variation, on the other hand, is more irregular because the busi-
ness cycle does not always have the same length. A further distinction is that the length of
a seasonal cycle is generally one year, whereas the length of a business cycle is generally
much longer than one year.
The graphs in Figure 14.32 illustrate the cyclic component of a time series. In Fig-
ure 14.32a, cyclic variation is superimposed on the base series from Figure 14.29. In Figure
14.32b, this same cyclic variation is superimposed on the series from Figure 14.31b. The
resulting graph has trend, seasonal variation, and cyclic variation.
Random (Noise) Component
The ﬁnal component in a time series is called the random component, or simply noise.
This unpredictable component gives most time series graphs their irregular, zigzag appear-
ance. Usually, a time series can be determined only to a certain extent by its trend, seasonal,
and cyclic components. Then other factors determine the rest. These other factors might be
inherent randomness, unpredictable shocks to the system, the unpredictable behavior of
human beings who interact with the system, and others.
Figures 14.33 and 14.34 show the affect that noise can have on a time series graph. The
graph on the left of each ﬁgure shows the random component only, superimposed on the base
series. Then on the right of each ﬁgure, the random component is superimposed on the graph
of trend with seasonal component from Figure 14.31b. The difference between Figure 14.33
876
Chapter 14
Regression and Forecasting Models
Yt
t
Yt
t
(a) Cyclic component only
(b) Cyclic component with seasonality
      and trend
Figure 14.32
Series with Cyclic
Component
Yt
t
Yt
t
(a) Noise only
(b) Noise superimposed on trend 
      and seasonal components
Figure 14.33
Series with Noise
By definition, noise is
unpredictable. It often
makes trends and sea-
sonal patterns more
difficult to recognize.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

and Figure 14.34 is the relative magnitude of the noise. When it is small, as in Figure 14.33,
the other components emerge fairly clearly; they are not disguised by the noise. But if the
noise is large in magnitude, as in Figure 14.34, the noise can make it difﬁcult to distinguish
the other components.
Measures of Forecast Error
When you use any extrapolation method, you build a model to track the observed histori-
cal data, and then you use this model to forecast future values of the data. The only way you
can judge whether the future forecasts are likely to be any good is to measure how well the
model tracks the historical data. Time series analysts typically use several measures. We
present three of the most popular measures in this section.
As before, let Yt be the observed value in time period t. Given any forecasting model, let
Ft be the “one-period-ahead” forecast of Yt made at time t  1. For example, for monthly
data, if t corresponds to August, then Ft is the forecast of August’s value made one month
before, in July. Also, let Et be the corresponding forecast error, Et Yt Ft. If Et is positive,
the forecast is too low, whereas if Et is negative, the forecast is too high. You want the Ets to
be small, so that the forecasts of the historical data track the actual data closely.
The three measures of forecasting accuracy typically used are MAE (mean absolute
error), RMSE (root mean square error), and MAPE (mean absolute percentage error).
These are given by the following formulas, where N is the number of historical periods for
which the model provides forecasts.
Formula for MAE
(14.8)
Formula for RMSE
RMSE 
(14.9)
Formula for MAPE
(14.10)
MAPE =
a
N
t=1
|Et>Yt|
N
a
N
t=1
E2
t
N
MAE =
a
N
t=1
|Et|
N
14.5 Overview of Time Series Models
877
Yt
t
Yt
t
(a) Noise only
(b) Noise superimposed on trend 
      and seasonal components
Figure 14.34
Series with More
Noise
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

RMSE is similar to a standard deviation in that the errors are squared; because of the
square root, its units are the same as those of the original variable. MAE is similar to RMSE
except that absolute values of errors are used instead of squared errors. MAPE (the same
measure we introduced in section 14.3) is probably the easiest measure to understand be-
cause it does not depend on the units of the original variable; it is always stated as a per-
centage. For example, the statement that the forecasts are off on average by 2% has a clear
meaning, even if you do not know the units of the variable being forecasted.
Depending on the forecasting software used, one or more of these measures will typically
be reported. Fortunately, models that make any one of these measures small tend to make the
others small as well, so that you can choose whichever measure you want to focus on.
One caution is in order, however. The measures MAE, RMSE, or MAPE are used to
see how well the forecasting model tracks historical data. But even if these measures are
small, there is no guarantee that future forecasts will be accurate. As stated previously,
extrapolation methods all make the implicit assumption that history will repeat itself. How-
ever, history does not always repeat itself. When this is the case, a model that closely tracks
historical data can yield poor forecasts of the future. In addition, there is a danger of track-
ing a historical series too closely. Tracking every little up and down is pointless if these
movements represent random noise that will not repeat in the future.
878
Chapter 14
Regression and Forecasting Models
FUNDAMENTAL INSIGHT
Limitations of Extra
polation Methods
All extrapolation forecasting methods, such as the
moving averages and exponential smoothing methods
discussed next, make the crucial assumption that his-
torical patterns are likely to repeat themselves. If an
unexpected shock occurs, such as a disruption in oil
supplies from the Mid East or a gr ound-breaking dis-
covery in biotechnolog y, extrapolation methods can
fail miserably in the period after the shock.
In addi-
tion, extrapolation methods can be too ﬁnely tuned. If
they are optimized to follow all of the ups and downs
of a time series,they might just be learning patterns of
noise, patterns that are unlikely to continue in the fu-
ture.This is why smoothed forecasts that follow the
basic underlying patterns are usually preferred.
14.6 MOVING AVERAGES MODELS
Perhaps the simplest and one of the most frequently used extrapolation methods is the
method of moving averages. Very simply, the forecast for any period with this method is
the average of the observations from the past few periods. To implement the moving aver-
ages method, you must ﬁrst choose a span, the number of terms in each moving average.
Let’s say that the data are monthly and a span of six months is used. Then the forecast 
of next month’s value is the average of the previous six months’ values. For example, you
average the January to June values to forecast July, you average the February to July values
to forecast August, and so on. This is the reason for the term moving averages.
A good forecasting
model typically makes
all three measures of
forecast errors small.
The larger the span,
the smoother the fore-
cast series will be.
The span in the moving averages method is the number of observations in each
average.
The role of the span is important. If the span is large—say, 12 months—then many ob-
servations go into each average, and extreme values have relatively little effect on the aver-
ages. The resulting series of forecasts will be much smoother than the original series. (For
this reason, the moving average method is called a smoothing method.) In contrast, if the
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

span is small—say, three months—then extreme observations have a larger effect on the
averages, and the forecast series will be much less smooth. In the extreme, if the span is one
month, there is no smoothing effect at all. The method simply forecasts next month’s value
to be the same as this month’s value.
What span should you use? This requires some judgment. If you believe the ups and
downs in the series are random noise, then you do not want future forecasts to react too
quickly to these ups and downs, and you should use a relatively large span. But if you want
to track most of the ups and downs—under the belief that these ups and downs are pre-
dictable—then you should use a smaller span. You should not be fooled, however, by a
graph of the forecast series—that is, a graph of the averages—superimposed on the origi-
nal series. This graph will almost always look better when a small span is used, because the
forecast series will appear to track the original series better. But this does not mean it will
provide better future forecasts. Again, tracking random ups and downs closely is pointless
if the ups and downs represent unpredictable noise.
The following example illustrates the use of moving averages on a series of weekly sales.
We continue to take advantage of the StatTools add-in, which includes procedures for creating
time series graphs and implementing moving averages and exponential smoothing methods. 
14.6 Moving Averages Models
879
E X A M P L E
14.5 FORECASTING WEEKLY SALES OF HARDWARE AT LEE’S
L
ee’s is a local discount store that sells a variety of merchandise, much like Kmart,
Walmart, and Target. In particular, Lee’s sells a full line of hardware. The company has
kept track of weekly total dollar sales of hardware items for the past 104 weeks. These data ap-
pear in the ﬁle Hardware Sales.xlsx. Lee’s is planning to use moving averages, with an ap-
propriate span, to forecast future weekly hardware sales. Does this appear to be a good idea?
Objective
To judge the effectiveness of the moving averages method, with different
spans, to forecast weekly hardware sales at Lee’s.
Solution
A time series graph of weekly sales appears in Figure 14.35. You can create this easily from
Excel’s built-in charting tools (as a line chart), or you can use the StatTools time series
graph procedure, available under the Time Series and Forecasting drop-down list. We did
0
500
1000
1500
2000
2500
3000
3500
1
4
7
10
13
16
19
22
25
28
31
34
37
40
43
46
49
52
55
58
61
64
67
70
73
76
79
82
85
88
91
94
97
100
103
Time Series of Sales / Weekly Data
Figure 14.35
Time Series Plot 
of Hardware Sales
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

the latter (after remembering that the ﬁrst step is always to designate a StatTools data set).
This series appears to meander, with no obvious trend or seasonality. Evidently, sales of
hardware at Lee’s are relatively constant throughout each year. This type of series is a good
candidate for moving averages. However, it is not clear which span to use. We tried spans
of 3, 6, and 12 weeks. Spans of 3 and 6 give similar results, whereas a span of 12 gives less
good results. We illustrate the calculations for a span of 3; you can check the calculations
for the other spans in the ﬁnished version of Hardware Sales.xlsx.
DEVELOPING THE SPREADSHEET MODEL
Using a span of 3, the forecast for week 4 is the average of the observed sales in weeks 1 to
3, the forecast for week 5 is the average of the observed sales in weeks 2 to 4, and so on.
The calculations are straightforward in Excel. However, they can be performed much more
quickly by using the forecasting procedure in StatTools. To do so, select Forecast from the
Time Series and Forecasting dropdown list on the StatTools ribbon. This leads to a dialog
box with three tabs in the lower section. The Time Scale tab shown in Figure 14.36 is used
to identify the type of data (annual, monthly, and so on) and the starting date (or index).
The Graphs to Display tab shown in Figure 14.37 allows you to check which graphs you
want in the output. (We typically choose the ﬁrst and third.) Finally, the important Forecast
880
Chapter 14
Regression and Forecasting Models
Figure 14.36
Time Scale Tab in
Forecasting Dialog
Box
Figure 14.37
Graphs to Display
Tab in Forecasting
Dialog Box
A series that mean-
ders, with no obvious
trend or seasonality, is
a good candidate for
moving averages.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Settings tab shown in Figure 14.38 allows you to select the forecasting method and any 
of its parameters, in this case the span for moving averages. You can also select the num-
ber of future forecasts, and you can elect to “hold out” a number of observations at the end
of the series for testing. (We won’t use this latter option, but if you choose a holdout period,
the forecasting model is built with the data before the holdout period and is then tested on
the holdout data, where the Y values are known.)
Discussion of the Results
The forecasting output consists of three parts: the detailed calculations, summary measures of
the forecast errors, and any graphs you request. The detailed calculations are shown in Figure
14.39 (with some hidden rows). You can check the formulas in the Forecast and Error columns
to verify that each forecast is the average of the three observations above it (starting with the
14.6 Moving Averages Models
881
Figure 14.38
Forecast Settings 
Tab in Forecasting
Dialog Box
Figure 14.39
Moving Averages
Calculations
61
62
63
64
65
66
67
68
69
158
159
160
161
162
163
164
165
166
167
168
169
A
B
C
D
Forecasng Data
Sales
Forecast
Error
1
$1526.00
2
$1929.00
3
$1704.00
4
$1423.00
$1719.67
-$296.67
5
$1430.00
$1685.33
-$255.33
6
$1410.00
$1519.00
-$109.00
7
$1478.00
$1421.00
$57.00
8
$1698.00
$1439.33
$258.67
97
$2152.00
$1993.67
$158.33
98
$1069.00
$1987.67
-$918.67
99
$1306.00
$1759.00
-$453.00
100
$1302.00
$1509.00
-$207.00
101
$2361.00
$1225.67
$1135.33
102
$1658.00
$1656.33
$1.67
103
$1903.00
$1773.67
$129.33
104
$1702.00
$1974.00
-$272.00
105
$1754.33
106
$1786.44
107
$1747.59
108
$1762.79
To forecast future
values with moving
averages, use previous
forecasts when actual
values are not
available.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

fourth observation) and each error is actual sales minus the forecast. The ﬁnal four forecasts
are those requested for the next four weeks. Again, each of these is an average of three values,
but previous forecasts are used when the actual observations aren’t available.
The two requested graphs are shown in Figures 14.40 and 14.41. The superimposed se-
ries of forecasts in Figure 14.40 indicates that the forecasts track the general ups and downs
of the sales series fairly well, although the forecast series is smoother than the sales series.
This is exactly what you want. The difference between these two series is probably unpre-
dictable noise, which is impossible (and undesirable) to track exactly.
It is also useful to examine the series of forecast errors in Figure 14.41. This series
appears to be a random series of ups and downs—again exactly what you want. If the series
882
Chapter 14
Regression and Forecasting Models
0.00
500.00
1000.00
1500.00
2000.00
2500.00
3000.00
3500.00
1
5
9
13
17
21
25
29
33
37
41
45
49
53
57
61
65
69
73
77
81
85
89
93
97
101
105
Week
Forecast and Original Observaons
Sales
Forecast
-1500.00
-1000.00
-500.00
0.00
500.00
1000.00
1500.00
1
4
7
10
13
16
19
22
25
28
31
34
37
40
43
46
49
52
55
58
61
64
67
70
73
76
79
82
85
88
91
94
97
100
103
Week
Forecast Errors
Figure 14.40
Forecasts with Span 
3 Superimposed
Figure 14.41 Forecast Errors with Span 3
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

of forecast errors indicated some sort of pattern, such as an upward trend or a spike every
fourth week, the forecasting method would be missing something, and you would need to
try another forecasting method to take this pattern into account. The current series of fore-
cast errors shows no such pattern, so the moving averages method is evidently doing about
as good a job as possible in tracking the sales series.
The summary in Figure 14.42 provides more evidence on how well the moving aver-
ages forecasts are doing. As you can see, the forecasts with span 3 are off, on average, by
about $278 (from MAE) or about 13.9% (from MAPE), and you can check (with additional
StatTools runs, which are included in the ﬁnished version of the ﬁle) that the errors are only
worse with spans of 6 or 12. These errors are fairly sizable, and it isn’t clear whether the
forecasts will be of much help to Lee’s management. However, more accurate forecasts
may not be possible because of the high level of noise in the sales series.
■
14.6 Moving Averages Models
883
Figure 14.42
Summary Measures
of Forecast Errors
8
9
10
11
12
13
14
15
A
B
Forecasng Constant
Span
3
Moving Averages
Mean Abs Err
$278.11
Root Mean Sq Err
$358.31
Mean Abs Per% Err
13.93%
P R O B L E M S
Skill-Building Problems
22. The ﬁle P14_22.xlsx contains the daily closing prices
of American Express stock for a one-year period.
a. Using a span of 3, forecast the price of this stock
for the next trading day with the moving averages
method. How well does this method with span 3
forecast the known observations in this series?
b. Repeat part a with a span of 10.
c. Which of these two spans appears to be more
appropriate? Justify your choice.
23. The closing value of the Dow Jones Industrial Average
for each trading day during a one-year period is
provided in the ﬁle P14_23.xlsx.
a. Using a span of 2, forecast the price of this index on
the next trading day with the moving averages method.
How well does the moving averages method with
span 2 forecast the known observations in this series?
b. Repeat part a with a span of 5; with a span of 15.
c. Which of these three spans appears to be most
appropriate? Justify your choice.
24. The ﬁle P14_24.xlsx contains the daily closing prices
of Walmart stock during a one-year period. Use the
moving averages method with a carefully chosen span
to forecast this time series for the next three trading
days. Defend your choice of the span used.
25. The Consumer Conﬁdence Index (CCI) attempts to
measure people’s feelings about general business
conditions, employment opportunities, and their own
income prospects. The ﬁle P14_25.xlsx contains the
annual average values of the CCI. Use the moving
averages method with a carefully chosen span to
forecast this time series in the next two years. Defend
your choice of the span used.
26. The closing value of the AMEX Airline Index for each
trading day during a one-year period is given in the
ﬁle P14_26.xlsx.
a. How well does the moving averages method track
this series when the span is 4; when the span is 12?
b. Using the more appropriate span, forecast the
closing value of this index on the next trading day
with the moving averages method.
Skill-Extending Problem
27. The ﬁle P14_27.xlsx contains total monthly U.S. retail
sales data. While holding out the ﬁnal six months of
observations for validation purposes, use the method
of moving averages with a carefully chosen span to
forecast U.S. retail sales in the next year. Comment on
the performance of your model. What makes this time
series more challenging to forecast?
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

14.7 EXPONENTIAL SMOOTHING MODELS
The main criticism of the moving averages method is that it puts equal weight on each
value in a typical moving average. Many people would argue that if next month’s forecast
is to be based on the previous 12 months’ observations, say, then more weight ought to be
placed on the more recent observations. Exponential smoothing is a method that addresses
this criticism. It bases its forecasts on a weighted average of past observations, with more
weight put on the more recent observations. In addition, most businesspeople can under-
stand exponential smoothing, at least conceptually. Therefore, this method ﬁnds wide-
spread use in the business world, particularly when frequent and automatic forecasts of
many items are required.
There are several versions of exponential smoothing. The most basic is called simple
exponential smoothing. It is relevant when there is no pronounced trend or seasonality in
the series. If there is a trend but no seasonality, then Holt’s method is applicable. If, in ad-
dition, there is seasonality, then Winters’ method can be used. This does not exhaust the
list of exponential smoothing models—researchers have invented many other variations—but
these are the most common models. We discuss simple exponential smoothing in some
detail. Then we provide a brief account of Holt’s and Winters’ methods. Fortunately, all of
these methods are implemented in StatTools.
884
Chapter 14
Regression and Forecasting Models
Simple exponential smoothing is appropriate when there is no trend or seasonality.
Holt’s method is appropriate when there is trend but no seasonality. Winters’ method
is appropriate when there is seasonality (and possibly trend as well).
The level of the series is an estimate of where the series would be if it were not for
random noise.
Simple Exponential Smoothing
Simple exponential smoothing is appropriate for a series with no obvious trend or seasonal
component. An example is the hardware sales data from Example 14.5, which meanders
through time but doesn’t really have any consistent upward or downward trend. In fact, we
reexamine this series in this section.
We ﬁrst introduce two new terms. Every exponential model has at least one smooth-
ing constant, which is always a number between 0 and 1. Simple exponential smoothing
has a single smoothing constant denoted by  (alpha). Its role is discussed shortly. The
second new term is Lt, the level of the series at time t. Essentially, the level is where the
series would be at time t if there were no random noise. Lt is not observable, so it must
be estimated.
The simple exponential smoothing method is deﬁned by the following equation. It
states that the estimated level at time t, right after observing Yt, is a weighted average of the
current observation Yt and the previous estimated level, Lt1. The current observation has
weight  and the previous level has weight 1  .
Formula for simple exponential smoothing
Lt  Yt  (1  )Lt1
(14.11)
To forecast, you use the most recently calculated level and project it into all future pe-
riods. For example, for monthly data, if the most recently observed value is for June, you
Exponential smoothing
forecasts put more
weight on recent
observations.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

calculate the level for June from Equation (14.11) and then use this level as a forecast for
July, August, and so on. Then one month later, after you have observed July’s value, you
calculate the level for July, again using Equation (14.11), and then use this updated level as
a forecast for August, September, and so on. The idea in simple exponential smoothing is
that you believe the series is not really going anywhere. So as soon as you estimate where
the series ought to be in period t (if it were not for random noise), you forecast that this is
where it will also be in any future period.
The smoothing constant  is analogous to the span in moving averages. There are two
ways to see this. The ﬁrst way is to rewrite Equation (14.11) using the fact that the forecast
error, Et, made in forecasting Yt at time t  1 is Et  Yt  Ft  Yt  Lt1. Algebra then
leads to the following formula:
Equivalent formula for simple exponential smoothing
Lt  Lt1  Et
(14.12)
Equation (14.12) states that the next estimate of the level is adjusted from the previous
estimate by adding a multiple of the most recent forecast error. This makes intuitive sense.
If the previous forecast was too high, then Et is negative, so the estimate of the level is ad-
justed downward. The opposite is true if the previous forecast was too low. However, Equa-
tion (14.12) says that the adjustment is not the entire magnitude of Et, but only a fraction
of it. If  is small, say,   0.1, the adjustment is minor; if  is close to 1, the adjustment
is large. Therefore, if you want to react quickly to movements in the series, choose a large
; otherwise, choose a small .
Another way to see the effect of  is to substitute repeatedly into Equation (14.11) for
Lt. After some algebra, it is possible to verify that Lt satisﬁes the following formula, where
the sum in this formula extends back to the ﬁrst observation at time t  1.
Another equivalent formula for simple exponential smoothing
Lt  Yt  (1)Yt1  (1)2Yt2  (1)3Yt3  . . .
(14.13)
Equation (14.13) indicates that the exponentially smoothed forecast is a weighted av-
erage of previous observations, just as we promised. Furthermore, because 1   is less
than 1, the weights on the Ys decrease from time t backward. Therefore, if  is close to 0,
so that 1 is close to 1, the weights decrease very slowly. In this case, observations from
the distant past continue to have a large inﬂuence on the next forecast. This means that the
graph of the forecasts will be relatively smooth, just as with a large span in the moving av-
erages method. But when  is close to 1, the weights decrease rapidly, and only very re-
cent observations have much inﬂuence on the next forecast. In this case, forecasts react
quickly to sudden changes in the series, and the forecast series isn’t much smoother than
the original series.
Whichvalueof shouldyouuse?Althoughthereisnouniversallyacceptedanswertothis
question, many practitioners recommend a value around 0.1 or 0.2. Others recommend experi-
menting with different values of  until a measure such as RMSE or MAPE is minimized.
Some software packages, including StatTools, even have an optimization feature that ﬁnds this
optimal value of . But as we discussed in general for extrapolation methods, the value of 
that tracks the historical series most closely does not necessarily guarantee the most accurate
future forecasts.
The following example uses the same hardware sales series as in Example 14.5 to see
whether simple exponential smoothing can improve on the forecasts made by moving
averages.
14.7 Exponential Smoothing Models
885
The smaller the
smoothing constant,
the smoother the
forecast series will be.
Typically, a smoothing
constant from 0.1 to
0.2 is used.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

886
Chapter 14
Regression and Forecasting Models
E X A M P L E
14.6 FORECASTING HARDWARE SALES AT LEE’S
I
n the previous example, you saw that the moving averages method was able to provide only
fair forecasts of weekly hardware sales at Lee’s. Using the best of three potential spans, its
forecasts were still off by about 13.9% on average. The company would now like to try sim-
ple exponential smoothing to see whether this method, with an appropriate smoothing con-
stant, can outperform the moving averages method. How should the company proceed?
Objective
To see whether simple exponential smoothing with an appropriate smoothing
constant can provide more accurate forecasts of weekly hardware sales than the moving
averages forecasts.
Solution
You already saw in Example 14.5 that the hardware sales series meanders through time,
with no apparent trends or seasonality. Therefore, this series is a good candidate for simple
exponential smoothing. This is no guarantee that the method will provide accurate fore-
casts, but at least it cannot be ruled out as a promising forecasting method.
DEVELOPING THE SPREADSHEET MODEL
Using Equation 14.11, it is fairly easy to implement simple exponential smoothing with
copyable Excel formulas, but as with moving averages, it is much easier to use StatTools.
In fact, you can use the same settings in the forecasting dialog box as with moving aver-
ages. The only exception is in the Forecast Settings section. As shown in Figure 14.43, you
should check the Exponential Smoothing (Simple) option and enter a value of alpha on the
right. (We chose 0.1.) Alternatively, you can check the Optimize Parameters option, in
which case StatTools ﬁnds the value of alpha that minimizes RMSE.
Discussion of the Results
The simple exponential smoothing calculations are shown in Figure 14.44. You can check
that Equation 14.11 is implemented in the Level column and that each forecast is the previous
level. (It is common to use the ﬁrst observation as the ﬁrst level.) Note that the last level is
Figure 14.43
Forecast Settings for
Simple Exponential
Smoothing
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

used for all future forecasts. Again, this is done because the assumption behind simple
exponential smoothing is that the series is not really going anywhere.
Figure 14.45 shows the graph of the series with forecasts superimposed with   0.1;
Figure 14.46 shows it with   0.3. As you can see, the forecast series is smoother with the
smaller smoothing constant. In this sense, a small value of  in exponential smoothing corre-
sponds to a large span in moving averages. If you want the forecasts to react less to random
ups and downs of the series, you should choose a smaller value of . This is the reasoning be-
hind the common practice of choosing a small smoothing constant such as 0.1 or 0.2.
Summary measures of the forecast errors are shown in Figure 14.47. The values shown
in column B are for an alpha of 0.1. However, a nice feature of the StatTools output is that
you can change the value of alpha in cell B9 and everything updates automatically. We took
advantage of this to create a data table for the summary measures for various values of
alpha. Two conclusions can be drawn from these summary measures. First, the summary
measures decrease slightly as the smoothing constant increases, but then they begin to in-
crease. Second, the best of these results is virtually the same as the best moving averages
results. The best forecasts with each method have MAPEs in the 13% to 14% range. Again,
this is due to the relatively large amount of noise inherent in the sales series. In cases like
this, you might be able to track the ups and downs of the historical series more closely with
a larger smoothing constant, but this would almost surely not result in better future fore-
casts. The bottom line is that noise, by deﬁnition, is not predictable.
14.7 Exponential Smoothing Models
887
A small smoothing
constant  corresponds
to a large span in
moving averages. Each
produces a relatively
smooth forecast series.
61
62
63
64
65
66
67
68
161
162
163
164
165
166
167
168
169
A
B
C
D
E
Forecasng Data
Sales
Level
Forecast
Error
1
$1526.00
$1526.00
2
$1929.00
$1566.30
$1526.00
$403.00
3
$1704.00
$1580.07
$1566.30
$137.70
4
$1423.00
$1564.36
$1580.07
-$157.07
5
$1430.00
$1550.93
$1564.36
-$134.36
6
$1410.00
$1536.83
$1550.93
-$140.93
7
$1478.00
$1530.95
$1536.83
-$58.83
100
$1302.00
$1780.02
$1833.14
-$531.14
101
$2361.00
$1838.12
$1780.02
$580.98
102
$1658.00
$1820.11
$1838.12
-$180.12
103
$1903.00
$1828.40
$1820.11
$82.89
104
$1702.00
$1815.76
$1828.40
-$126.40
105
$1815.76
106
$1815.76
107
$1815.76
108
$1815.76
Figure 14.44
Simple Exponential
Smoothing Forecasts
with Smoothing
Constant 0.1
Figure 14.45
Forecast Series 
with Smoothing
Constant 0.1
0.00
500.00
1000.00
1500.00
2000.00
2500.00
3000.00
3500.00
1
5
9
13
17
21
25
29
33
37
41
45
49
53
57
61
65
69
73
77
81
85
89
93
97
101
105
Week
Forecast and Original Observaons
Sales
Forecast
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Holt’s Method for Trend
The simple exponential smoothing method generally works well if there is no obvious
trend in the series. But if there is a trend, this method consistently lags behind it. For ex-
ample, if the series is constantly increasing, simple exponential smoothing forecasts will be
consistently low. Holt’s method rectiﬁes this by dealing explicitly with trend. In addition to
the level of the series Lt and its smoothing constant , Holt’s method includes a trend term,
Tt, and a corresponding smoothing constant  (beta). The interpretation of Lt is exactly as
before. The interpretation of Tt is that it represents an estimate of the change in the series
from one period to the next.
After observing all of the data through time period t and calculating the most recent esti-
mates of level and trend, Lt and Tt, the forecast of the next value of the series, at time t  1, is
Lt  Tt. Similarly, the forecast of the value at time t  2 is Lt  2Tt, the value at t  3 is Lt 
3Tt, and so on. Each future forecast tacks on an additional Tt to the previous forecast.
Holt’s method has two deﬁning equations, one for Lt and one for Tt. These are similar
to Equation (14.11) and are as follows:
Formulas for Holt’s exponential smoothing method
Lt  Yt  (1 )(Lt1  Tt1)
(14.14)
Tt  (Lt  Lt1)  (1  )Tt1
(14.15)
888
Chapter 14
Regression and Forecasting Models
0.00
500.00
1000.00
1500.00
2000.00
2500.00
3000.00
3500.00
1
5
9
13
17
21
25
29
33
37
41
45
49
53
57
61
65
69
73
77
81
85
89
93
97
101
105
Week
Forecast and Original Observaons
Sales
Forecast
Figure 14.46
Forecast Series 
with Smoothing
Constant 0.3
Figure 14.47
Summary Measures
of Forecast Errors
7
8
9
10
11
12
13
14
15
16
17
18
A
B
C
D
E
F
G
Data table for sensitivity to smoothing constant
Forecasng Constant
Alpha
MAE
RMSE
MAPE
Level (Alpha)
%
8
3.5
1
0
6.1
8
3
$
8
8.7
0
3
$
0
0
1.0
0.1
$307.88
$381.60
15.38%
0.2
$279.35
$353.45
14.05%
Simple Exponenal
0.3
$268.44
$346.30
13.47%
Mean Abs Err
%
1
3.3
1
2
6.7
4
3
$
6
6.6
6
2
$
4.0
8
8.7
0
3
$
Root Mean Sq Err
%
6
4.3
1
2
4.3
5
3
$
7
8.0
7
2
$
5.0
0
6.1
8
3
$
Mean Abs Per% Err
%
0
7.3
1
0
2.2
6
3
$
1
1.7
7
2
$
6.0
%
8
3.5
1
0.7
$286.38
$373.41
14.08%
0.8
$299.06
$386.97
14.65%
0.9
$315.82
$403.10
15.46%
■
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Equation (14.14) is reasonable because Lt1  Tt1 is where the series should be
at time t (except for noise), based on information up to period t  1. Similarly, Equa-
tion (14.15) is reasonable because Lt  Lt1 is an estimate of the most recent trend.
The following example briefly describes how StatTools can be used to implement
Holt’s method on a time series with trend.
14.7 Exponential Smoothing Models
889
E X A M P L E
14.7 FORECASTING QUARTERLY SALES AT A PHARMACEUTICAL COMPANY
T
he ﬁle Pharmaceutical Sales.xlsx contains quarterly sales data for a large pharma-
ceutical company from ﬁrst quarter 2001 through fourth quarter 2010 (in millions of
dollars). The time series graph in Figure 14.48 indicates a fairly consistent upward trend,
with a relatively small amount of noise. Can Holt’s method be used to provide reasonably
accurate forecasts of this series?
Objective
To use Holt’s exponential smoothing model to track the trend in the pharma-
ceutical company’s quarterly sales data.
Solution
Holt’s method can be implemented with StatTools almost exactly as with simple exponen-
tial smoothing. The only change is to ﬁll out the Forecast Settings as shown in Figure 14.49.
Once you select Exponential Smoothing (Holt’s) as the method, you can select two
smoothing constants. Alternatively, you can check the Optimize Parameters option to ﬁnd
the smoothing constants that minimize RMSE, as has been done here.
0
1000
2000
3000
4000
5000
6000
7000
8000
9000
Q1-01
Q2-01
Q3-01
Q4-01
Q1-02
Q2-02
Q3-02
Q4-02
Q1-03
Q2-03
Q3-03
Q4-03
Q1-04
Q2-04
Q3-04
Q4-04
Q1-05
Q2-05
Q3-05
Q4-05
Q1-06
Q2-06
Q3-06
Q4-06
Q1-07
Q2-07
Q3-07
Q4-07
Q1-08
Q2-08
Q3-08
Q4-08
Q1-09
Q2-09
Q3-09
Q4-09
Q1-10
Q2-10
Q3-10
Q4-10
Time Series of Sales
Figure 14.48 Quarterly Pharmaceutical Sales
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Discussion of the Results
As usual, the StatTools output for Holt’s method consists of three sections: summary data,
detailed data, and charts. The summary data appear in Figure 14.50. They indicate that the
best smoothing constants are 0.574 (for level) and 0.0 (for trend). These produce the error
measures shown. For example, MAPE is 4.40%. Although the smoothing constants shown
here minimize RMSE, you can experiment with other smoothing constants in cells B9 and
B10. For example, if you set both smoothing constants equal to 0.2, you will see that
RMSE increases to 349.54 and MAPE increases to 5.56%. Clearly, the choice of smooth-
ing constants does make a difference.6
The detailed data section, shown in Figure 14.51 (with some hidden rows), is where
Equations (14.14) and (14.15) are implemented. You can look at the formulas in this section
to gain a better technical understanding of Holt’s method. In particular, note how the future
forecasts in rows 103 to 110 project the ending level and trend in row 102 into the future.
The chart of the series with superimposed forecasts appears in Figure 14.52. The pro-
jected forecasts appear at the right. You can see that the forecasts track the series well, and
the future projections follow the clear upward trend. The chart in Figure 14.53 shows the
series of forecast errors. If the forecast method is working well, this chart should be
890
Chapter 14
Regression and Forecasting Models
Figure 14.49
Forecast Settings 
for Holt’s Method
Figure 14.50
StatTools Summary
Data
8
9
10
11
12
13
14
15
16
A
B
Forecasng Constants (Opmized)
Level (Alpha)
0.574
Trend (Beta)
0.000
Holt's Exponenal
Mean Abs Err
237.06
Root Mean Sq Err
280.59
Mean Abs Per% Err
4.40%
6The fact that the optimal smoothing constant for trend is 0 does not mean that there is no trend. It means that the
initial guess of trend, which is 131.13 per quarter, is never updated.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

14.7 Exponential Smoothing Models
891
Figure 14.51 Holt’s Method Calculations
62
63
64
65
66
67
68
69
70
99
100
101
102
103
104
105
106
107
108
109
110
A
B
C
D
E
F
Forecasng Data
Sales
Level
Trend
Forecast
Error
Q1-2001
3062.00
3062.00
131.13
Q2-2001
3304.00
3256.79
131.13
3193.13
110.88
Q3-2001
3179.00
3267.95
131.13
3387.92
-208.92
Q4-2001
3557.00
3489.76
131.13
3399.08
157.92
Q1-2002
3663.00
3645.07
131.13
3620.88
42.12
Q2-2002
3644.00
3700.29
131.13
3776.19
-132.19
Q3-2002
3628.00
3714.61
131.13
3831.41
-203.41
Q4-2002
3813.00
3826.94
131.13
3845.73
-32.73
Q1-2010
7842.00
7874.38
131.13
7918.05
-76.05
Q2-2010
7893.00
7940.90
131.13
8005.50
-112.50
Q3-2010
7543.00
7768.25
131.13
8072.03
-529.03
Q4-2010
8307.00
8133.44
131.13
7899.37
407.63
Q1-2011
8264.57
Q2-2011
8395.69
Q3-2011
8526.82
Q4-2011
8657.94
Q1-2012
8789.07
Q2-2012
8920.19
Q3-2012
9051.32
Q4-2012
9182.44
0.00
1000.00
2000.00
3000.00
4000.00
5000.00
6000.00
7000.00
8000.00
9000.00
10000.00
Q1-2001
Q3-2001
Q1-2002
Q3-2002
Q1-2003
Q3-2003
Q1-2004
Q3-2004
Q1-2005
Q3-2005
Q1-2006
Q3-2006
Q1-2007
Q3-2007
Q1-2008
Q3-2008
Q1-2009
Q3-2009
Q1-2010
Q3-2010
Q1-2011
Q3-2011
Q1-2012
Q3-2012
Forecast and Original Observaons
Sales
Forecast
Figure 14.52 Time Series with Forecasts from Holt’s Method Superimposed
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

random, with no apparent patterns. The only suspicious pattern evident here is that the
zigzags appear to be increasing in magnitude through time. Perhaps a more sophisticated
forecasting method could deal with this pattern, but we do not pursue it here. For our pur-
poses, Holt’s method seems to be doing very well with this data set. It tracks the historical
data closely, and it accurately projects the upward trend.
■
Winters’ Method for Seasonality
When a time series exhibits obvious seasonality, such as swimming pool supply sales that
are always higher in the spring and summer than in the rest of the year, none of the
extrapolation methods discussed to this point do a good job. They all miss the seasonal
ups and downs. Various methods have been proposed to deal with seasonality. One possi-
bility is to use regression with dummy variables for the seasons. Another possibility is to
deseasonalize the series ﬁrst, then use one of the methods we have discussed to forecast
the deseasonalized series, and ﬁnally reseasonalize the forecasts.7 We do not discuss these
possibilities here, but we do mention that many time series listed in newspapers, maga-
zines, and government reports actually list deseasonalized data—that is, they have already
manipulated the data to remove any seasonality, presumably so that trends can be identi-
ﬁed more clearly.
Winters’ method is a direct extension of Holt’s exponential smoothing model. Like
Holt’s method, Winters’ method estimates a level Lt and a trend Tt, using smoothing con-
stants  and . These have the same interpretation as before. In addition, there is a seasonal
factor St for each season, where a “season” is usually a month or a quarter. Each seasonal
factor represents the percentage by which that season is typically above or below the aver-
age for all seasons. For example, if the seasonal factor for June is 1.35, then a typical June
892
Chapter 14
Regression and Forecasting Models
-600.00
-400.00
-200.00
0.00
200.00
400.00
600.00
800.00
Q1-2001
Q3-2001
Q1-2002
Q3-2002
Q1-2003
Q3-2003
Q1-2004
Q3-2004
Q1-2005
Q3-2005
Q1-2006
Q3-2006
Q1-2007
Q3-2007
Q1-2008
Q3-2008
Q1-2009
Q3-2009
Q1-2010
Q3-2010
Forecast Errors
Figure 14.53 Series of Forecast Errors from Holt’s Method
Winters’ exponential
smoothing method is
only one of several
popular methods 
for dealing with
seasonality.
In addition to the level
and trend terms,
Winters’ method
requires a whole series
of seasonal factors,
one for each season.
7This is the purpose of the Deseasonalize option in the dialog box in Figure 14.36.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

value is 35% higher than the average for all months. Or if the seasonal factor for February
is 0.75, then a typical February value is 25% lower than the average for all months. With
Winters’ method, these seasonal factors are continually updated as more values of the time
series are observed, using still another smoothing constant  (gamma) and another smooth-
ing equation similar to Equations (14.11), (14.14), and (14.15). Due to their complexity, we
do not present the smoothing equations for Winters’ method here.
To see how forecasting works with Winters’ method, suppose you have observed data
up through June of some year, and you have used these data to calculate the most recent
level Lt, the most recent trend Tt, and the updated seasonal factors. Then the forecast for
July is (Lt  Tt)SJuly, the forecast for August is (Lt  2Tt)SAugust, and so on. In other words,
you proceed exactly as with Holt’s method, except that you multiply each forecast by the
relevant seasonal factor.
Fortunately, you can again use StatTools to perform the calculations, as illustrated in
the following example.
14.7 Exponential Smoothing Models
893
E X A M P L E
14.8 FORECASTING QUARTERLY SOFT DRINK SALES
T
he data in the Soft Drink Sales.xlsx ﬁle represent quarterly sales (in millions of dol-
lars) for a large soft drink company from quarter 1 of 1996 through quarter 1 of 2011.
As you might expect, there has been an upward trend in sales during this period, and there
is also a fairly regular seasonal pattern, as shown in Figure 14.54. Sales in the warmer quar-
ters, 2 and 3, are consistently higher than in the colder quarters, 1 and 4. How well can Win-
ters’ method track this upward trend and seasonal pattern?
Objective
To use Winters’ exponential smoothing method to track the upward trend and
regular seasonal pattern in the company’s quarterly soft drink sales.
Figure 14.54 Quarterly Soft Drink Sales
0
1000
2000
3000
4000
5000
6000
7000
Q1-96
Q3-96
Q1-97
Q3-97
Q1-98
Q3-98
Q1-99
Q3-99
Q1-00
Q3-00
Q1-01
Q3-01
Q1-02
Q3-02
Q1-03
Q3-03
Q1-04
Q3-04
Q1-05
Q3-05
Q1-06
Q3-06
Q1-07
Q3-07
Q1-08
Q3-08
Q1-09
Q3-09
Q1-10
Q3-10
Q1-11
Time Series of Sales
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Solution
We keep this discussion brief because the procedure required for Winters’ method is practi-
cally the same as for the other exponential smoothing methods. The dialog box for forecast
settings should be ﬁlled in as shown in Figure 14.55. When Winters’ method is chosen, an
extra smoothing constant (for seasonality) appears. As usual, you can choose the smooth-
ing constants or optimize them. (After some experimenting, we chose the values shown in
the ﬁgure.)
894
Chapter 14
Regression and Forecasting Models
Figure 14.55
StatTools Forecast
Settings for Winters’
Method
Figure 14.56
StatTools Summary
Data
8
9
10
11
12
13
14
15
16
17
A
B
Forecasng Constants
Level (Alpha)
0.500
Trend (Beta)
0.200
Season (Gamma)
0.100
Winters' Exponenal
Mean Abs Err
146.69
Root Mean Sq Err
192.17
Mean Abs Per% Err
4.41%
Discussion of the Results
The StatTools output for Winters’ method is very similar to the Holt’s method output. The
summary section in Figure 14.56 shows that a MAPE of 4.41% is obtained with the chosen
smoothing constants. Again, you can manually try other smoothing constants in the range
B9:B11 to see how sensitive the summary measures are to the smoothing constants.
The detailed data section in Figure 14.57 implements the exponential smoothing equa-
tions for Winters’ method. Note in particular the seasonality factors in column E. They re-
main almost constant from year to year and they indicate a clear pattern, where sales in
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

quarters 1 and 4 are always below average, and sales in quarters 2 and 3 are always above
average.
The chart in Figure 14.58 indicates how well Winters’ method (with these smoothing
constants) tracks the sales pattern through time. It even picks up the slight decrease in the
upward trend in more recent years and projects this pattern into the future. If Holt’s method
were used on this data set, it would identify the upward trend, but it would completely miss
the seasonal pattern.
14.7 Exponential Smoothing Models
895
63
64
65
66
67
68
69
70
119
120
121
122
123
124
125
126
127
128
129
130
131
132
A
B
C
D
E
F
G
Forecasng Data
Sales
Level
Trend
Season
Forecast
Error
Q1-1996
1807.37
2046.27
49.93
0.88
Q2-1996
2355.32
2140.57
49.93
1.10
2306.50
48.82
Q3-1996
2591.83
2463.29
49.93
1.05
2304.80
287.03
Q4-1996
2236.39
2319.32
49.93
0.96
2423.36
-186.97
Q1-1997
1549.14
1753.91
49.93
0.88
2092.64
-543.50
Q2-1997
2105.79
1913.79
49.93
1.10
1984.80
120.99
Q3-1997
2041.32
1940.09
49.93
1.05
2066.19
-24.87
Q4-2009
5036.00
5222.75
49.93
0.96
4950.88
85.12
Q1-2010
4534.61
5133.99
49.93
0.88
4657.10
-122.49
Q2-2010
5836.17
5304.05
49.93
1.10
5704.00
132.17
Q3-2010
5818.28
5529.74
49.93
1.05
5633.35
184.93
Q4-2010
5070.42
5258.44
49.93
0.96
5380.16
-309.74
Q1-2011
4497.47
5091.95
49.93
0.88
4688.63
-191.16
Q2-2011
5657.73
Q3-2011
5462.71
Q4-2011
5054.31
Q1-2012
4673.87
Q2-2012
5877.48
Q3-2012
5672.85
Q4-2012
5246.88
Q1-2013
4850.27
Figure 14.57 Winters’ Method Calculations
0.00
1000.00
2000.00
3000.00
4000.00
5000.00
6000.00
7000.00
Q1-1996
Q4-1996
Q3-1997
Q2-1998
Q1-1999
Q4-1999
Q3-2000
Q2-2001
Q1-2002
Q4-2002
Q3-2003
Q2-2004
Q1-2005
Q4-2005
Q3-2006
Q2-2007
Q1-2008
Q4-2008
Q3-2009
Q2-2010
Q1-2011
Q4-2011
Q3-2012
Forecast and Original Observaons
Sales
Forecast
Figure 14.58 Time Series with Forecasts from Winters’ Method Superimposed
■
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

896
Chapter 14
Regression and Forecasting Models
P R O B L E M S
Skill-Building Problems
28. You have been assigned to forecast the number of air-
craft engines ordered each month by Commins Engine
Company. At the end of February, the forecast is that
100 engines will be ordered during April. During
March, 120 engines are ordered. Using   0.3, deter-
mine a forecast (at the end of March) for the number
of orders placed during April. Answer the same ques-
tion for May. Use simple exponential smoothing.
29. Simple exponential smoothing with   0.3 is being
used to forecast sales of digital cameras at Lowland
Appliance. Forecasts are made on a monthly basis.
After August camera sales are observed, the forecast
for September is 100 cameras.
a. During September, 120 cameras are sold. After ob-
serving September sales, what do you forecast for
October camera sales? For November camera sales?
b. June sales were recorded as 10 cameras; however,
100 cameras were actually sold in June. After cor-
recting for this error, develop a forecast for October
camera sales.
30. The ﬁle P14_30.xlsx contains the quarterly numbers
of applications for home mortgage loans at a branch
ofﬁce of Northern Central Bank.
a. Create a time series chart of the data. Based on
what you see, which of the exponential smoothing
models do you think will provide the best forecast-
ing model? Why?
b. Use simple exponential smoothing to forecast these
data, using a smoothing constant of 0.1.
c. Repeat part b, but search for the smoothing constant
that makes RMSE as small as possible. Does it make
much of an improvement over the model in part b?
31. The ﬁle P14_31.xlsx contains the monthly number of
airline tickets sold by the CareFree Travel Agency.
a. Create a time series chart of the data. Based on
what you see, which of the exponential smoothing
models do you think will provide the best forecast-
ing model? Why?
b. Use simple exponential smoothing to forecast these
data, using a smoothing constant of 0.1.
c. Repeat part b, but search for the smoothing con-
stant that makes RMSE as small as possible. Does
it make much of an improvement over the model
in part b?
32. The ﬁle P14_32.xlsx contains yearly data on the pro-
portion of Americans under the age of 18 living below
the poverty level.
a. Create a time series chart of the data. Based on
what you see, which of the exponential smoothing
models do you think will provide the best forecast-
ing model? Why?
b. Use simple exponential smoothing to forecast these
data, using a smoothing constant of 0.1.
c. Repeat part b, but search for the smoothing con-
stant that makes RMSE as small as possible. Create
a chart of the series with the forecasts superim-
posed from this optimal smoothing constant. Does
it make much of an improvement over the model in
part b?
d. Write a short report to summarize your results.
Considering the chart in part c, would you say the
forecasts are “good”?
33. The ﬁle P14_33.xlsx contains weekly data for the S&P
500 stock index from August 2008 to August 2010,
adjusted for dividends and stock splits.
a. Create a time series plot of the adjusted closing
prices. Does it look like moving averages and/or
simple exponential smoothing will perform well on
this series?
b. Run moving averages on the adjusted closing
prices, experimenting with the span. Which span
appears to work best? Report the MAE, RMSE,
and MAPE values, and show a graph of the series
with the forecasts superimposed, for the best span.
c. Run simple exponential smoothing on the adjusted
closing prices, experimenting with the smoothing
constant. Which smoothing constant appears to work
best? Report the MAE, RMSE, and MAPE values,
and show a graph of the series with the forecasts su-
perimposed, for the best smoothing constant.
34. TOD Chevy is using Holt’s method to forecast weekly
car sales. Currently, the level of the series is estimated
to be 50 cars per week, and the trend is estimated to be
six cars per week. During the current week, 30 cars are
sold. After observing the current week’s sales, forecast
the number of cars sold one week from now; two weeks
from now; three weeks from now. Use     0.3.
35. The University Credit Union is open Monday through
Saturday. Winters’ method is being used (with all
smoothing constants equal to 0.5) to predict the num-
ber of customers entering the bank each day. After in-
corporating the arrivals on Monday, October 16, the
seasonal indexes are: Monday, 0.90; Tuesday, 0.70;
Wednesday, 0.80; Thursday, 1.1; Friday, 1.2; Saturday,
1.3. Also, the current estimates of level and trend are
200 and 1. On Tuesday, October 17, 182 customers
enter the bank. At the close of business on October 17,
forecast the number of customers who will enter the
bank on each of the next six business days.
36. Consider the American Express closing price data in
the ﬁle P14_22.xlsx.
a. Create a time series chart of the data. Based on
what you see, which of the exponential smoothing
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

models do you think will provide the best forecast-
ing model? Why?
b. Use Holt’s exponential smoothing to forecast these
data, using the smoothing constants     0.1.
c. Repeat part b, searching for the smoothing con-
stants that make RMSE as small as possible. Does
it make much of an improvement over the result in
part b?
37. The ﬁle P14_37.xlsx contains monthly retail sales of
U.S. liquor stores.
a. Is seasonality present in these data? If so, charac-
terize the seasonality pattern.
b. Use Winters’ method to forecast this series with
smoothing constants     0.1 and   0.3.
Does the forecast series seem to track the seasonal
pattern well? What are your forecasts for the next
12 months?
38. The ﬁle P14_38.xlsx contains monthly time series data
for total U.S. retail sales of building materials (which
includes retail sales of building materials, hardware
and garden supply stores, and mobile home dealers).
a. Is seasonality present in these data? If so, charac-
terize the seasonality pattern.
b. Use Winters’ method to forecast this series with
smoothing constants     0.1 and   0.3.
Does the forecast series seem to track the seasonal
pattern well? What are your forecasts for the next
12 months?
Skill-Extending Problems
39. A version of simple exponential smoothing can be used
to predict the outcome of sporting events. To illustrate,
consider pro football. We ﬁrst assume that all games
are played on a neutral ﬁeld. Before each day of play,
we assume that each team has a rating. For example, if
the rating for the Bears is 10 and the rating for the
Bengals is 6, you would predict the Bears to beat the
Bengals by 10  6  4 points. Suppose that the Bears
play the Bengals and win by 20 points. For this game,
you underpredicted the Bears’ performance by
20  4  16 points. The best  for pro football is 
  0.10. After the game, you therefore increase the
Bears’ rating by 16(0.1)  1.6 and decrease the
Bengals’ rating by 1.6 points. In a rematch, the Bears
14.8 Conclusion
897
would be favored by (10  1.6)  (6  1.6) 
7.2 points.
a. How does this approach relate to the equation 
Lt  Lt1  Et?
b. Suppose that the home ﬁeld advantage in pro foot-
ball is 3 points; that is, home teams tend to
outscore visiting teams by an average of 3 points a
game. How could the home ﬁeld advantage be
incorporated into this system?
c. How could you determine the best  for pro football?
d. How might you determine ratings for each team at
the beginning of the season?
e. Suppose you try to apply the previous method to
predict pro football (16-game schedule), college
football (11-game schedule), college basketball
(30-game schedule), and pro basketball (82-game
schedule). Which sport would probably have the
smallest optimal ? Which sport would probably
have the largest optimal ?
f. Why would this approach probably yield poor fore-
casts for Major League Baseball?
40. Holt’s method assumes an additive trend. For example,
a trend of 5 means that the level will increase by
ﬁve units per period. Suppose there is actually a multi-
plicative trend. This means that if the current estimate
of the level is 50, and the current estimate of the trend
is 1.2, you would predict demand to increase by 20%
per period. So you would forecast the next period’s de-
mand to be 50(1.2) and forecast the demand two peri-
ods in the future to be 50(1.2)2. If you want to use a
multiplicative trend in Holt’s method, you should use
the following equations:
Lt  Yt  (1)U
Tt  V  (1)Tt1
a. What should U and V be to make this a sensible
forecasting method?
b. Suppose you are working with monthly data and
month 12 is December, month 13 is January, and so
on. Also suppose that the level and trend, right
after observing December’s value, are L12  100
and T12  1.2, respectively. Then you observe
Y13  200. At the end of month 13, what is the
forecast for month 14? For month 15? Assume
   0.2.
14.8 CONCLUSION
This book includes numerous examples where numeric input data for a spreadsheet model
is required. In real situations, the data is often obtained through regression or an extrapola-
tion forecasting method. In this chapter, we have discussed regression and some of the
more popular extrapolation methods for time series forecasting. These are important tools
in any management scientist’s toolkit. In fact, they are becoming required tools for just
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

about any business analyst because virtually all business analysts need to relate variables,
discover trends and seasonal patterns, and make forecasts. Fortunately, the basic tools we
have presented are reasonably easy to understand and use, especially given the built-in ca-
pabilities of Excel and the available statistical add-ins for Excel. These tools are extremely
widespread, ﬂexible, and powerful. We suspect that most of you will use them at some
point in your careers.
Summary of Key Management Science Terms
Term
Explanation
Page
Regression models
Statistical models that estimate an equation to relate one 
843
variable to one or more explanatory variables
Extrapolation 
Statistical models that relate a time series variable to previous 
843
(time series) models
values of that same variable
Dependent variable
The variable being explained in a regression model, 
844
typically denoted by Y
Explanatory variables
The variables used to explain the dependent variable in a 
844
regression model, typically denoted by Xs (also called 
independent or predictor variables)
Simple regression
A regression model with a single explanatory variable
844
Multiple regression
A regression model with multiple explanatory variables
844
Least-squares line
The regression line that minimizes the sum of squared 
845
residuals; the resulting line from a typical regression analysis
Residual
The difference between an actual Y value and the value 
845
predicted by the regression equation
Fitted value
A predicted value of Y, as predicted by the regression equation
846
Standard error of 
Essentially, the standard deviation of the residuals; an estimate 
846
estimate
of the magnitude of prediction errors made from the 
regression equation
Multiple R
The correlation between the actual Ys and the ﬁtted Ys
847
R-square
The percentage of variation of the Ys explained by the regression
847
Linear trend
A trend, usually through time, where a variable changes by 
848
a constant amount each time period
Exponential trend
A trend, usually through time, where a variable changes 
848
by a constant percentage each time period
Dummy variables
0–1 variables that are used in regression equations to encode 
866
a categorical variable such as Gender or Quarter
Regression coefﬁcients
The estimated intercept and slope terms in a regression output that 
862
deﬁne the regression equation
Multicollinearity
Occurs when Xs are highly correlated with one another; makes 
871
interpretation of the regression coefﬁcients difﬁcult
Autocorrelation of residuals
Occurs when nearby residuals are correlated with one another, 
871
usually with time series data 
Extrapolation methods
Forecasting methods where past patterns of a time series variable 
874
are discovered and extrapolated into the future
Time series components
The items, including trend, seasonality, cyclic behavior, and 
874
noise, that produce the patterns observed in most time
series variables
MAE, RMSE, MAPE 
Three popular measures of forecast errors in time series analysis
878
898
Chapter 14
Regression and Forecasting Models
(continued)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Term
Explanation
Page
Moving averages method 
A forecasting method where the forecast for any period is the 
878
average of the several most recent periods
Span
The number of terms in each average in moving averages; 
878
larger spans produce a smoother forecast series
Exponential smoothing 
A forecasting method where the forecast for any period is a 
884
method
weighted average of previous periods, with more recent periods 
getting more weight
Smoothing constants 
One or more constants, all between 0 and 1, that drive the 
884
exponential smoothing equation(s); lower values produce a 
smoother forecast series
Simple exponential 
Version of exponential smoothing appropriate when there is no 
884
smoothing
obvious trend or seasonality
Holt’s method
Version of exponential smoothing appropriate when there is a trend 
884
but no obvious seasonality
Winters’ method
Version of exponential smoothing appropriate when there is 
884
seasonality and possibly a trend
Summary of Key Excel Terms
Term
Explanation
Excel
Page
Creating a scatterplot 
Useful for identifying a relationship 
Create a scatter chart from 
849
between two variables
Insert ribbon (can also use 
StatTools add-in)
Superimposing 
Useful for identifying a linear or 
Create a scatterplot, then use the
850
a trend line 
exponential trend through a scatterplot
Trendline tool
EXP function
Used to raise the special number e to a 
=EXP(value)
852
power; also called the antilog function
StatTools add-in 
A powerful and easy-to-use statistical 
Has its own ribbon
854
add-in developed by Palisade
Analysis ToolPak 
A statistical add-in that comes with 
Use Data Analysis from Data ribbon 857
Excel; useful for regression and 
several other statistical procedures
Creating a time 
Useful for seeing how a time series 
Create a line chart from 
876
series graph
variable behaves through time
Insert ribbon (can also use 
StatTools add-in)
14.8 Conclusion
899
P R O B L E M S
Skill-Building Problems
41. Many companies manufacture products that are at
least partially produced using chemicals (e.g., paint,
gasoline, and steel). In many cases, the quality of the
ﬁnished product is a function of the temperature and
pressure at which the chemical reactions take place.
Suppose that a particular manufacturer wants to
model the quality (Y) of a product as a function of
the temperature (X1) and the pressure (X2) at which it is
produced. The ﬁle P14_41.xlsx contains data obtained
from a carefully designed experiment involving these
variables. Note that the assigned quality score can
range from a minimum of 0 to a maximum of 100 for
each manufactured product.
a. Estimate a multiple regression equation that
includes the two given explanatory variables.
Does the estimated equation ﬁt the data well?
b. Add an interaction term between temperature and
pressure (the product of these two variables) and run
the regression again. Does the inclusion of the
interaction term improve the model’s goodness of ﬁt?
c. Interpret each of the estimated coefﬁcients in the
two equations. How are they different? How do
you interpret the coefﬁcient for the interaction term
in the second equation?
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

42. A power company located in southern Alabama wants to
predict the peak power load (i.e., the maximum amount
of power that must be generated each day to meet
demand) as a function of the daily high temperature (X).
A random sample of 25 summer days is chosen, and the
peak power load and the high temperature are recorded
each day. The ﬁle P14_42.xlsx contains these
observations.
a. Create a scatterplot for these data. Comment on the
observed relationship between Y and X.
b. Estimate an appropriate regression equation to
predict the peak power load for this power
company. Interpret the estimated regression
coefﬁcients.
c. Analyze the estimated equation’s residuals. 
Do they suggest that the regression equation is
adequate? If not, return to part b and revise your
equation. Continue to revise the equation until the
results are satisfactory.
d. Use your ﬁnal equation to predict the peak power
load on a summer day with a high temperature of
100 degrees.
43. Management of a home appliance store would like 
to understand the growth pattern of the monthly sales
of Blu-ray disc players over the past two years.
Managers have recorded the relevant data in the ﬁle
P14_43.xlsx. 
a. Create a scatterplot for these data. Comment on the
observed behavior of monthly sales at this store
over time.
b. Estimate an appropriate regression equation to
explain the variation of monthly sales over the
given time period. Interpret the estimated
regression coefﬁcients.
c. Analyze the estimated equation’s residuals. Do
they suggest that the regression equation is
adequate? If not, return to part b and revise your
equation. Continue to revise the equation until the
results are satisfactory.
44. A small computer chip manufacturer wants to forecast
monthly ozperating costs as a function of the number
of units produced during a month. The company has
collected the 16 months of data in the ﬁle P14_44.xlsx.
a. Determine an equation that can be used to predict
monthly production costs from units produced. Are
there any outliers?
b. How could the regression line obtained in part a
be used to determine whether the company was
efﬁcient or inefﬁcient during any particular month?
45. The beta of a stock is found by running a regression
with the monthly return on a market index as the
explanatory variable and the monthly return on the
stock as the dependent variable. The beta of the stock
is then the slope of this regression line.
a. Explain why most stocks have a positive beta.
900
Chapter 14
Regression and Forecasting Models
b. Explain why a stock with a beta with absolute
value greater than one is more volatile than the
market index and a stock with a beta less than one
(in absolute value) is less volatile than the market
index.
c. Use the data in the ﬁle P14_45.xlsx to estimate the
beta for each of the four companies listed:
Caterpillar, Goodyear, McDonald’s, and Ford. Use
the S&P 500 as the market index.
d. For each of these companies, what percentage of
the variation in its returns is explained by the
variation in the market index? What percentage is
unexplained by variation in the market index?
e. Verify (using Excel’s COVAR and VARP functions)
that the beta for each company is given by
Also, verify that the correlation between each
company’s returns and the market’s returns is the
square root of R2.
46. The ﬁle P14_46.xlsx contains the amount of money
spent advertising a product (in thousands of dollars)
and the number of units sold (in millions) for eight
months.
a. Assume that the only factor inﬂuencing monthly
sales is advertising. Fit the following two curves to
these data: linear (Y  a  bX) and power
(Y  aXb). Which equation best ﬁts the data?
b. Interpret the best-ﬁtting equation.
c. Using the best-ﬁtting equation, predict sales
during a month in which $60,000 is spent on
advertising.
47. When potential workers apply for a job that requires
extensive manual assembly of small intricate parts,
they are initially given three different tests to measure
their manual dexterity. The ones who are hired are
then periodically given a performance rating on a 0 to
100 scale that combines their speed and accuracy in
performing the required assembly operations. The ﬁle
P14_47.xlsx lists the test scores and performance rat-
ings for a randomly selected group of employees. It
also lists their seniority (months with the company) at
the time of the performance rating.
a. Run the regression of Performance Rating versus
all four explanatory variables. List the equation, the
R-square value, and the standard error of estimate.
Do all of the regression coefﬁcients have the signs
you would expect? Brieﬂy explain.
b. Referring to the equation in part a, if a worker
(outside of the 80 in the sample) has 15 months
of seniority and test scores of 57, 71, and 63, give
a prediction and an approximate 95% prediction
interval for this worker’s Performance Rating
score.
Covariance between Company and Market
Variance of Market
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

14.8 Conclusion
901
c. Arguably, the three test measures provide overlap-
ping (redundant) information. It might be sensible
to regress Performance Rating versus only two ex-
planatory variables, Seniority and Average Test,
where Average Test is the average of the three test
scores, that is, Average Test  (Test1  Test2 
Test3)3. Run this regression and report the same
measures as in part a: the equation itself, R-square,
and the standard error of estimate. Can you argue
that this equation is just as good as the equation in
part a? Explain brieﬂy.
48. Callaway Golf is trying to determine how the price of
a set of clubs affects the demand for clubs. The ﬁle
P14_48.xlsx contains the price of a set of clubs
(in dollars) and the monthly sales (number of
sets sold).
a. Assume the only factor inﬂuencing monthly sales
is price. Fit the following two curves to these data:
linear (Y  a  bX) and exponential (Y  aebX).
Which equation best ﬁts the data?
b. Interpret your best-ﬁtting equation. 
c. Using the best-ﬁtting equation, predict sales during
a month in which the price is $470.
49. The ﬁle P14_49.xlsx lists the average salary for each
Major League Baseball team from 2004 to 2009, along
with the number of team wins in each of these years.
a. Rearrange the data so that there are four long
columns: Team, Year, Salary, and Wins. There
should be 6*30 values for each. 
b. Create a scatterplot of Wins (Y) versus Salary (X).
Is there any indication of a relationship between
these two variables? Is it a linear relationship?
c. Run a regression of Wins versus Salary. What does
it say, if anything, about teams buying their way to
success?
50. Let Yt be the sales during month t (in thousands of dol-
lars) for a photography studio, and let Pt be the price
charged for portraits during month t. The data are in
the ﬁle P14_50.xlsx.
a. Use regression to ﬁt the following model to these
data: Yt  a  b1Pt  b2Yt1. This says that current
sales are related to current price and sales in the
previous month. (Hint: You won’t be able to use
the ﬁrst month’s data because there is no value for
the previous month’s sales.)
b. If the price of a portrait during month 21 is $30,
what would you predict for sales in month 21?
51. The Baker Company wants to develop a budget to 
predict how overhead costs vary with activity levels.
Management is trying to decide whether direct labor
hours (DLH) or units produced is the better measure
of activity for the ﬁrm. Monthly data for the preceding
24 months appear in the ﬁle P14.51.xlsx. Use regres-
sion analysis to determine which measure, DLH or
Units (or both), should be used for the budget. How
would the regression equation be used to obtain the
budget for the ﬁrm’s overhead costs?
Skill-Extending Problems
52. The auditor of Kiely Manufacturing is concerned
about the number and magnitude of year-end adjust-
ments that are made annually when the ﬁnancial state-
ments of Kiely Manufacturing are prepared. Speciﬁ-
cally, the auditor suspects that the management of
Kiely Manufacturing is using discretionary write-offs
to manipulate the reported net income. To check this,
the auditor has collected data from 25 ﬁrms that are
similar to Kiely Manufacturing in terms of manufac-
turing facilities and product lines. The cumulative
reported third-quarter income and the ﬁnal net income
reported are listed in the ﬁle P14_52.xlsx for each of
these 25 ﬁrms. If Kiely Manufacturing reported a
cumulative third-quarter income of $2,500,000 and a
preliminary net income of $4,900,000, should the
auditor conclude that the relationship between cumu-
lative third-quarter income and the annual income for
Kiely Manufacturing differs from that of the 25 ﬁrms
in this sample? Why or why not?
53. The ﬁle P14_53.xlsx contains monthly data on con-
sumer revolving credit (in millions of dollars) through
credit unions.
a. Use these data to forecast consumer revolving
credit through credit unions for the next 12 months.
Do it in two ways. First, ﬁt an exponential trend to
the series. Second, use Holt’s method with
optimized smoothing constants.
b. Which of these two methods appears to provide the
best forecasts? Answer by comparing their MAPE
values.
54. The belief that larger majorities for an incumbent pres-
ident in a presidential election help the incumbent’s
party increase its representation in the House and Sen-
ate is called the coattail effect. The ﬁle P14_54.xlsx
gives the percent by which each president since 1948
won the election and the number of seats in the House
and Senate gained (or lost) during each election. Are
these data consistent with the idea of presidential coat-
tails? (Source: Wall Street Journal, September 10,
1996)
55. The auditor of Kaefer Manufacturing uses regression
analysis during the analytical review stage of the
ﬁrm’s annual audit. The regression analysis attempts
to uncover relationships that exist between various ac-
count balances. Any such relationship is subsequently
used as a preliminary test of the reasonableness of
the reported account balances. The auditor wants to
determine whether a relationship exists between the
balance of accounts receivable at the end of the month
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

902
Chapter 14
Regression and Forecasting Models
and that month’s sales. The ﬁle P14_55.xlsx contains
data on these two accounts for the last 36 months.
It also shows the sales levels two months prior to
month 1.
a. Is there any statistical evidence to suggest a rela-
tionship between the monthly sales level and
accounts receivable?
b. Referring to part a, would the relationship be de-
scribed any better by including this month’s sales
and the previous month’s sales (called lagged sales)
in the equation for accounts receivable? What
about adding the sales from more than a month ago
to the equation? For this problem, why might it
make accounting sense to include lagged sales vari-
ables in the equation? How do you interpret their
coefﬁcients?
c. During month 37, which is a ﬁscal year-end month,
sales were $1,800,000. The reported accounts
receivable balance was $3,000,000. Does this
reported amount seem consistent with past
experience? Explain.
56. (Based on an actual court case in Philadelphia.) In the
1994 congressional election, the Republican candidate
outpolled the Democratic candidate by 400 votes
(excluding absentee ballots). The Democratic candi-
date outpolled the Republican candidate by 500 absen-
tee votes. The Republican candidate sued (and won),
claiming that vote fraud must have played a role in the
absentee ballot count. The Republican’s lawyer ran a
regression to predict (based on past elections) how the
absentee ballot margin could be predicted from the
votes tabulated on voting machines. Selected results
are given in the ﬁle P14_56.xlsx. Show how this re-
gression could be used by the Republican to support
his claim of vote fraud. (Hint: Does the 1994 observa-
tion fall outside the general pattern? That is, in statisti-
cal terms, is it an outlier?)
57. Confederate Express is attempting to determine how
its monthly shipping costs depend on the number of
units shipped during a month. The ﬁle P14_57.xlsx
contains the number of units shipped and total
shipping costs for the past 15 months.
a. Use regression to determine a relationship between
units shipped and monthly shipping costs.
b. Plot the errors for the predictions in order of time
sequence. Is there any unusual pattern?
c. Suppose there was a trucking strike during months
11 to 15, and we believe that this might have inﬂu-
enced shipping costs. How could the answer to
part a be modiﬁed to account for the effects of the
strike? After accounting for the effects of the
strike, does the unusual pattern in part b disappear?
(Hint: Use a dummy variable.)
58. The ﬁle P14_58.xlsx contains monthly cost accounting
data on overhead costs, machine hours, and direct
material costs. This problem will help you explore the
meaning of R2 and the relationship between R2 and
correlations.
a. Create a table of correlations between the individual
variables.
b. If you ignore the two explanatory variables
Machine Hours and Direct Material Cost and
predict each Overhead Cost as the mean of
Overhead Cost, then a typical “error” is Overhead
Cost minus the mean of Overhead Cost. Find the
sum of squared errors using this form of prediction,
where the sum is over all observations.
c. Now run three regressions: (1) Overhead Cost
(OHCost) versus Machine Hours, (2) OHCost
versus Direct Material Cost, and (3) OHCost
versus both Machine Hours and Direct Material
Cost. (The first two are simple regressions, the
third is a multiple regression.) For each, find 
the sum of squared residuals, and divide this
by the sum of squared errors from part b. What
is the relationship between this ratio and the
associated R2 for that equation? (Now do you 
see why R2 is referred to as the percentage of
variation explained?)
d. For the ﬁrst two regressions in part c, what is the
relationship between R2 and the corresponding
correlation between the dependent and explanatory
variable? For the third regression it turns out that
the R2 can be expressed as a complicated function
of all three correlations in part a. That is, the
function involves not just the correlations between
the dependent variable and each explanatory
variable, but also the correlation between the
explanatory variables. Note that this R2 is not just
the sum of the R2 values from the ﬁrst two
regressions in part c. Why do you think this is true,
intuitively? However, R2 for the multiple regression
is still the square of a correlation—namely, the
correlation between the observed and predicted
values of OHCost. Verify that this is the case for
these data.
59. The Wilhoit Company has observed that there is a
linear relationship between indirect labor expense
and direct labor hours. Data for direct labor hours
and indirect labor expense for 18 months are given
in the ﬁle P14_59.xlsx. At the start of month 7, all
cost categories in the Wilhoit Company increased by
10%, and they stayed at this level for months 7
through 12. Then at the start of month 13, another
10% across-the-board increase in all costs occurred,
and the company operated at this price level for
months 13 through 18.
a. Plot the data. Verify that the relationship between
indirect labor expense and direct labor hours is
approximately linear within each six-month period.
Use regression (three times) to estimate the slope
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

14.8 Conclusion
903
and intercept during months 1 through 6, during
months 7 through 12, and during months 13
through 18.
b. Use regression to ﬁt a straight line to all 18 data
points simultaneously. What values of the slope
and intercept do you obtain?
c. Perform a price level adjustment to the data and
re-estimate the slope and intercept using all 18
data points. Assuming no cost increases for month
19, what is your prediction for indirect labor
expense if there are 35,000 direct labor hours in
month 19?
d. Interpret your results. What causes the difference in
the linear relationship estimated in parts b and c?
60. Pernavik Dairy produces and sells a wide range of
dairy products. Because a government regulatory
board sets most of the dairy’s costs and prices, most of
the competition between the dairy and its competitors
takes place through advertising. The controller of Per-
navik has developed the sales and advertising levels
for the past 52 weeks. These appear in the ﬁle
P14_60.xlsx. Note that the advertising levels for the
three weeks prior to week 1 are also listed. The con-
troller wonders whether Pernavik is spending too
much money on advertising. He argues that the com-
pany’s contribution-margin ratio is about 10%. That is,
10% of each sales dollar goes toward covering ﬁxed
costs. This means that each advertising dollar has to
generate at least $10 of sales or the advertising is not
cost-effective. Use regression to determine whether
advertising dollars are generating this type of sales re-
sponse. (Hint: The sales value in any week might be
affected not only by advertising this week but also by
advertising levels in the past one, two, or three weeks.
These are called lagged values of advertising. Try re-
gression models with lagged values of advertising in-
cluded, and see whether you get better results.)
61. The ﬁle P14_61.xlsx contains ﬁve years of monthly
data for a company. The ﬁrst variable is Time (1–60).
The second variable, Sales1, has data on sales of a
product. Note that Sales1 increases linearly throughout
the period, with only a minor amount of noise. (The
third variable, Sales2, will be used in the next prob-
lem.) For this problem, use the Sales1 variable to see
how the following forecasting methods are able to
track a linear trend.
a. Forecast this series with the moving averages
method with various spans such as 3, 6, and 12.
What can you conclude?
b. Forecast this series with simple exponential
smoothing with various smoothing constants such
as 0.1, 0.3, 0.5, and 0.7. What can you conclude?
c. Repeat part b with Holt’s method, again for various
smoothing constants. Can you do much better than
in parts a and b?
62. The Sales2 variable in the ﬁle from the previous prob-
lem was created from the Sales1 variable by multiply-
ing by monthly seasonal factors. Basically, the sum-
mer months are high and the winter months are low.
This might represent the sales of a product that has a
linear trend and seasonality.
a. Repeat parts a to c from the previous problem to
see how well these forecasting methods can deal
with trend and seasonality.
b. Use Winters’ method, with various values of the
three smoothing constants, to forecast the series.
Can you do much better? Which smoothing con-
stants work well?
c. What can you conclude from your ﬁndings in
parts a and b about forecasting this type of series?
63. The ﬁle P14_63.xlsx contains data on a motel chain’s
revenue and advertising.
a. Use these data and multiple regression to make pre-
dictions of the motel chain’s revenues during the next
four quarters. Assume that advertising during each of
the next four quarters is $50,000. (Hint: Try using
advertising, lagged by one period, as an explanatory
variable. See the Problem 60 for an explanation of a
lagged variable. Also, use dummy variables for the
quarters to account for possible seasonality.)
b. Use simple exponential smoothing to make predic-
tions for the motel chain’s revenues during the next
four quarters. Experiment with the smoothing
constant.
c. Use Holt’s method to make forecasts for the motel
chain’s revenues during the next four quarters.
Experiment with the smoothing constants.
d. Use Winters’ method to determine predictions for
the motel chain’s revenues during the next four
quarters. Experiment with the smoothing constants.
e. Which forecasts from parts a to d would you ex-
pect to be the most reliable?
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

C A S E
H
owie’s Bakery is one of the most popular bakeries
in town,and the favorite at Howie’s is French
bread.Each day of the week,Howie’s bakes a number
of loaves of French bread,more or less according to a
daily schedule. To maintain its ﬁne reputation, Howie’s
gives to charity any loaves not sold on the day they are
baked. Although this occurs frequently,it is also com-
mon for Howie’s to run out of French bread on any
given day—more demand than supply.In this case,no
extra loaves are baked that day;the customers have to
go elsewhere (or come back to Howie’s the next day)
for their French bread. Although French bread at
Howie’s is always popular,Howie’s stimulates demand
by running occasional 10% off sales.
Howie’s has collected data for 20 consecutive
weeks, 140 days in all. These data are listed in the ﬁle
Howies Bakery.xlsx. The variables are Day 
(Monday–Sunday), Supply (number of loaves baked
that day), OnSale (whether French bread is on sale
that day), and Demand (loaves actually sold that day).
Howie’s wants to see whether regression can be
used successfully to estimate Demand from the
other data in the ﬁle. Howie reasons that if these
other variables can be used to predict Demand, then
he might be able to determine his daily supply (num-
ber of loaves to bake) in a more cost-effective way.
How successful is regression with these data? Is
Howie correct that regression can help him deter-
mine his daily supply? Is any information missing that
would be useful? How would you obtain it? How
would you use it? Is this extra information really
necessary? ■
14.1 DEMAND FOR FRENCH BREAD AT HOWIE’S BAKERY
904
Chapter 14
Regression and Forecasting Models
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

C A S E
W
agner Printers performs all types of printing,
including custom work, such as advertising
displays, and standard work, such as business cards.
Market prices exist for standard work, and Wagner
Printers must match or better these prices to get the
business. The key issue is whether the existing market
price covers the cost associated with doing the work.
On the other hand, most of the custom work must be
priced individually. Because all custom work is done
on a job-order basis,Wagner routinely keeps track of
all the direct labor and direct materials costs associ-
ated with each job. However, the overhead for each
job must be estimated. The overhead is applied to
each job using a predetermined (normalized) rate
based on estimated overhead and labor hours. After
the cost of the prospective job is determined, the
sales manager develops a bid that reﬂects both the ex-
isting market conditions and the estimated price of
completing the job.
In the past, the normalized rate for overhead has
been computed by using the historical average of
overhead per direct labor hour. Wagner has become
increasingly concerned about this practice for two
reasons. First, it hasn’t produced accurate forecasts
of overhead in the past. Second, technology has
changed the printing process, so that the labor con-
tent of jobs has been decreasing, and the normalized
rate of overhead per direct labor hour has steadily
been increasing. The ﬁle Wagner Printers.xlsx
shows the overhead data that Wagner has collected
for its shop for the past 52 weeks.The average
weekly overhead for the last 52 weeks is $54,208,
and the average weekly number of labor hours
worked is 716. Therefore, the normalized rate for
overhead that will be used in the upcoming week is
about $76 (54,208716) per direct labor hour.
Questions
1.
Determine whether you can develop a more
accurate estimate of overhead costs.
2.
Wagner is now preparing a bid for an important
order that may involve a considerable amount of
repeat business. The estimated requirements for
this project are 15 labor hours,8 machine hours,
$150 direct labor cost,and $750 direct material
cost.Using the existing approach to cost estima-
tion, Wagner has estimated the cost for this job as
$2040 (150  750  (76  15)).Given the
existing data,what cost would you estimate for
this job? ■
14.2 FORECASTING OVERHEAD AT WAGNER PRINTERS
Case 14.2 Forecasting Overhead at Wagner Printers
905
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

C A S E
T
he Indiana University Credit Union Eastland
Plaza branch was having trouble getting the
correct stafﬁng levels to match customer arrival
patterns. On some days, the number of tellers was
too high relative to the customer trafﬁc, so that
tellers were often idle. On other days, the opposite
occurred; long customer waiting lines formed be-
cause the relatively few tellers could not keep up
with the number of customers. The credit union
manager, James Chilton, knew that there was a prob-
lem, but he had little of the quantitative training he
believed would be necessary to ﬁnd a better stafﬁng
solution. James ﬁgured that the problem could be
broken down into three parts. First, he needed a
reliable forecast of each day’s number of customer
arrivals. Second, he needed to translate these fore-
casts into stafﬁng levels that would make an adequate
trade-off between teller idleness and customer
waiting. Third, he needed to translate these stafﬁng
levels into individual teller work assignments—who
should come to work when.
The last two parts of the problem require analy-
sis tools (queueing and scheduling) that we will not
pursue here. However, you can help James with the
ﬁrst part—forecasting. The ﬁle Credit Union
Arrivals.xlsxlists the number of customers enter-
ing this credit union branch each day of the past year.
It also lists other information: the day of the week,
whether the day was a staff or faculty payday, and
whether the day was the day before or after a holi-
day. Use this data set to develop one or more fore-
casting models that James could use to help solve his
problem. Based on your model(s), make any recom-
mendations about stafﬁng that appear reasonable. ■
14.3 ARRIVALS AT THE CREDIT UNION
906
Chapter 14
Regression and Forecasting Models
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

15-1
Project Management
C H A P T E R
SCHEDULING THE                                                                                                                             N                   EW-PR ODUCT
DEVELOPMENT PR     OCESS AT DOW
AGROSCIENCES
D
ow AgroSciences, a wholly owned subsidiary of The Dow Chemical
Company, is in the business of developing new agricultural products. It
subjects product candidates to tests covering safety, efficacy, and environmental
impact as well as other tests to validate the biology and confirm that the prod-
ucts will do well in the business market. To beat the competition to market,
the company is under pressure to do its testing and use its resources as effi-
ciently as possible. The development schedule is the key. At any time, around
30 products can be going through testing, each of which consists of tens to
hundreds of tasks that must be performed. The scheduling of these tasks must
take the following data into account: (1) the net present value (NPV) of the
cash flows each candidate is expected to generate, depending on its launch
date, (2) the costs of tasks in the development process, (3) the technical prece-
dence relationships for tasks, (4) the durations of the tasks, (5) the probability
that the candidate will fail a task, resulting in the cancellation of the develop-
ment process for that candidate, (6) resource requirements and capacities, and
others. Many of the required inputs are uncertain, so that probability distribu-
tions are needed to model them correctly.
Bassett et al. (2004) describe a simulation-based optimization model they
developed to help generate good schedules in this complex environment.
© CORBIS
15
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Unlike the rather simple project scheduling examples described in this chapter, the situa-
tion at Dow AgroSciences is much larger and considerably more complex. First, there
are several projects in process at a given time, not a single project, and they are all com-
peting for scarce resources such as line-item budgets. Second, some tasks can fail for
some projects, in which case, these projects do not continue in the development process
and therefore free up resources for other projects. Third, precedence relationships are
only partly fixed. There are often fixed precedence relationships of the type discussed in
this chapter, where, for example, task C cannot start until tasks A and B are finished.
However, other precedence relationships can be introduced for strategic reasons. For
example, suppose tasks E and F can begin at the same time, but there is a probability that
task E will fail. Then it might be better to allow task F to start only when task E is suc-
cessfully completed.The reason is that if task E fails, the cost of performing task F will be
saved.Also, the schedule can impose precedence relationships across projects to reduce
the simultaneous use of scarce resources. Finally, due to the seasonal nature of agricul-
tural products, a delay of one month that causes a product to miss the growing season
might be just as costly as a delay of 10 months.
The authors first tried to formulate their problem as an integer programming (IP)
model, as has often been done in the project scheduling literature. However, they found
that the size and complexity of the problem made the resulting IP model too difficult to
solve in a reasonable amount of time.Therefore, they turned to simulation and heuristic
methods for optimizing, using precedence relationships as decision variables. For any
proposed solution, that is, any set of precedence relationships within and across projects,
they simulate the development of these projects over a multiyear period. The simulation
output contains the value of the objective they want to maximize, expected NPV. They
then experiment with several heuristic methods, including the genetic algorithms dis-
cussed in Chapter 8, to find solutions with larger values of the objective. Of course, each
new solution must be simulated to find its value of the objective. There is no guarantee
that this methodology will find an optimal solution, but it appears to produce very good
solutions in an acceptable amount of computing time.
The authors implemented their solution method in a system with an Excel-based
user-friendly front end. In the background, the system uses a simulation package,
AweSim, plus the authors’ own C++ computer code, to implement the simulation and
heuristic algorithms. Dow AgroSciences put this system into practice via their Six Sigma
project in Research and Development. From 1998 to 2004, the company verified savings
of several million dollars based on the schedules determined by the system. As Beth
Swisher, Manager of R&D Effectiveness at Dow AgroSciences, states,“I feel comfortable
stating that more than one million dollars have been saved due to our possession of the
technology. In addition to these ‘hard’ savings, the improved understanding of the overall
new-product development process across all the functions in the company has been
invaluable.” ■
15-2 Chapter 15
Project Management
15.1 INTRODUCTION
All organizations have ongoing activities, and they have projects. The distinction is that a
project has a beginning, an end, and one or more well-defined goals. The project could be
the development of a software program, the building of a house or an office building, the
development of a new drug, a marketing campaign for a new product, and many others.
Typically, a team of employees is assigned to a project, and one member of the team is des-
ignated as the project manager. The team is assigned to complete the project within a cer-
tain time, within a certain budget, and within certain specifications. At some point in the
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

future, the team will complete the project (or deem it a failure), and the project’s life cycle
will be finished. The purpose of this chapter is to discuss ways to manage projects suc-
cessfully. This is an extremely important topic for real organizations. There can be serious
consequences when a project is not finished on time, runs over budget, or fails to meet
specifications.
As an academic discipline, project management is discussed in management, opera-
tions management, and management science. The discussion in management tends to
focus on the “soft” skills necessary to manage projects successfully. The project manager
must be an effective leader, and team members must communicate successfully, agree on
goals, cooperate, report progress clearly, and so on. Although the importance of these peo-
ple skills is clear, it is not the focus of this chapter. 
Management science (and operations management) tends to focus on the quantitative
tools that have been developed to manage projects. These go under the twin acronyms of
PERT (Program Evaluation and Review Technique) and CPM (Critical Path Method).
These methods were developed independently about a half-century ago. PERT was devel-
oped jointly by the U.S. Navy, Lockheed, and the consulting firm of Booz, Allen, and
Hamilton in their work on the Polaris nuclear missile. CPM was developed at DuPont and
Remington-Rand to improve the construction of new production facilities and the shut-
down of existing facilities. The main difference between PERT and CPM is that CPM was
developed for projects with a set of commonly performed tasks, where the task times are
fairly well known. In contrast, PERT was developed for projects with tasks where scien-
tists had little experience and could not estimate their times with much certainty. In short,
the CPM model did not include uncertainty in task times, but the PERT model did.
Over the years, the two methods have tended to merge, so that people now often speak
of PERT/CPM models. In either case, the emphasis is on a project that starts at some point
and ends some time later. The project consists of a number of tasks that must be completed
for the project to be completed. These tasks have durations (the time it takes to complete
them, assumed known for CPM, random for PERT), they typically cost money, and they
often require nonfinancial resources such as people and facilities. They also have prece-
dence relationships. For example, task G might not be able to start until tasks B, D, and F
are finished. These precedence relationships put constraints on what can be done when. In
addition, limited resources can place constraints on the tasks that can be done simultane-
ously. A well-established methodology has been developed to analyze such projects. It
involves various charts and some reasonably simple calculations. We explain how it works
in this chapter. As you will see, most of it can be accomplished in Excel. However, you
should be aware that there is another package in the Microsoft Office family called
Microsoft Project.1 This powerful package is devoted exclusively to managing projects.
Of course, power usually implies complexity, and Project is very complex. We discuss
it briefly at the end of the chapter. However, a thorough discussion of the Project software
is well beyond the scope of this book. The calculations discussed in this chapter are
performed in Excel.
Projects have three dimensions: time, resources, and scope.2 The usual discussion of
PERT/CPM focuses primarily on the time dimension. How long will the project take to
complete if everything goes according to schedule, which tasks form bottlenecks that pre-
vent the project from being completed earlier, and which tasks have some slack, in the
sense that they can be delayed to some extent without delaying the project? These ques-
tions are the usual focus of PERT/CPM models, and we too focus primarily on the time
15.1 Introduction
15-3
CPM usually implies
known activity times,
and PERT usually
implies uncertain
activity times.
1We tend to think of Microsoft Office as including Excel, Word, Access, PowerPoint, Outlook, and a few others,
which make up the package you get when you purchase Office. However, Microsoft includes other packages,
such as Project, when it discusses its “Office family.” Unfortunately, you have to purchase these other packages
separately.
2Some people add a fourth dimension, quality. However, quality can be encompassed within scope.
The focus of most
PERT/CPM discussions
is time, but resource
usage (money, people,
facilities, and so on) is
also very important.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

dimension. However, we also discuss the resource dimension. The tasks in a project
almost always compete for resources, whether dollars or nonfinancial resources, and no
real project management application can afford to ignore these resources. For example,
one version of the problem we analyze is the crashing problem. In this problem, you
decide how to spend money optimally to speed up (crash) the completion of the project.
For example, if you find that the project will not be completed until 16 weeks from now,
but you have a deadline of 14 weeks from now, you need to find a way to crash critical
tasks to save a couple of weeks. 
The third dimension, scope, is the most difficult to model quantitatively. Scope
involves the deliverable itself—what it is intended to do and what features it should
include. For example, if the purpose of the project is to deliver a new version of Excel, the
software developers at Microsoft have to control scope. It is all too easy to keep adding
features, refining existing features, and generally adding to the scope. (This is undoubtedly
why Microsoft’s software products often come out later than originally advertised. And
Microsoft is certainly not alone.) If the project manager doesn’t keep a constant eye on
scope cr eep, the project can easily run over budget and/or fail to meet its deadline.
Unfortunately, scope is not easy to model, so we do not discuss it any further here.
This chapter provides an introduction to project management. In particular, it dis-
cusses the basic deterministic CPM model, where task times are assumed to be known, and
it uses simulation to analyze a version of the PERT model, where task times are assumed
to be random. However, the opener to this chapter indicates how complex project manage-
ment can be in the real world. A company such as Dow AgroSciences often needs to jug-
gle many projects simultaneously, the timing of eventual revenues needs to be considered,
possible failures in testing at some stage along the way can terminate projects and result in
lost costs, extra precedence relationships can be introduced to manage costs and other
resources, and so on. The problems can quickly become complex, which is all the more
reason to employ management science techniques to solve them, as companies such as
Dow AgroSciences have learned to their benefit.
Before continuing, we note that many entire books are devoted to project manage-
ment, and the material we include here is typically found in two or three chapters of such
books. This material is certainly an important aspect of project management, but it is not
the only aspect. Other aspects include selecting the project in the first place, setting
goals and specifications for the project, properly managing people involved in the pro-
ject (including adequate communication), monitoring the progress of the project (and
making changes to the original plan when necessary), knowing when to “pull the plug”
on a project that is not making adequate progress, and others. All of these aspects are
important for determining whether a real-world project is successful or not, and the fail-
ure to manage them properly is the reason why so many projects have been unsuccessful.
[One notable failure occurred in the 1990s, when Health Care Financing Administration,
the agency that administers Medicare, spent at least $50 million developing a Medicare
Transactions system that never became a reality. This failure of this project is described
in Friel (2000).] If you are interested in learning more about project management, we
recommend the following books: Klastorin (2004), Marchewka (2006), and Gido &
Clements (2006).
15.2 THE BASIC CPM MODEL
In this section, we describe the basic CPM procedure for finding the length of time
required to complete a project. This approach assumes that we know (1) the activities that
comprise the project, (2) the precedence relationships among activities, and (3) the time
15-4 Chapter 15
Project Management
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

required to complete each activity.3 This time, called the activity duration, is assumed to
be known with certainty. However, even when we relax this assumption in a later section
and assume there is a probability distribution for each activity duration, the same basic pro-
cedure explained here can still be used as part of a simulation model.
To proceed, we need a list of the activities that make up the project. The project is
complete when all of the activities have been completed. Each activity has a set of activi-
ties called its immediate predecessors that must be completed before the activity begins.
It also has a set of activities called its immediate successors that cannot start until it has
finished. (The word immediate is sometimes omitted.) A project network diagram is usu-
ally used to represent the precedence relationships among activities. Two types of dia-
grams do this, activity-on-node (AON) networks and activity-on-arc (AOA) networks, and
proponents of each type have rather strong feelings. We favor AON networks because we
believe they are more intuitive, so we do not discuss AOA networks in this book.
In the AON representation of a project, there is a node for each activity. Then there is an
arc from node i to node j if node i is an immediate predecessor of node j. To illustrate this,
consider a project that consists of five activities, labeled A, B, C, D, and E. Activities A and
B can start immediately. Activity C cannot start until activity B is finished, activity D cannot
start until activity A is finished, and activity E cannot start until activities A and C are both
finished. The project is finished when all activities are finished.
The precedence relationships are listed in Table 15.1 and the AON network appears in
Figure 15.1. Table 15.1 also includes the duration for each activity. In an AON network,
these durations are placed next to the nodes. In addition, there is typically a Start node and
a Finish node in the diagram. These indicate the start and the finish of the project. Note that
activity E illustrates the meaning of the term immediate predecessor. Clearly, activity B is
also a predecessor of activity E—it must be finished before activity E can start—but it is
not an immediate predecessor because it will be finished before another predecessor of
activity E, activity C, can even begin. 
15.2 The Basic CPM Model
15-5
3Activities are also called tasks in the project-management literature. The two terms, activities and tasks, 
are synonymous.
AON networks use
nodes for activities and
arcs to indicate prece-
dence relationships.
6
12
3
8
10
Start
A
D
C
B
E
Finish
Figure 15.1
AON Network for a
Five-Activity Project
Table 15.1 Data for a Five-Activity Project
Immediate
Immediate
Node
Predecessor(s)
Successor(s)
Duration
A
None
D, E
8
B
None
C
10
C
B
E
3
D
A
None
12
E
A, C
None
6
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

The rules for drawing an AON network are as follows:
■
Include a node for each activity and place its duration next to the node.
■
Include an arc from node i to node j only if node i is an immediate predecessor of
node j.
■
Include a Start and a Finish node with zero durations. There is an arc from the Start
node to each node that has no predecessors. These activities can all start immedi-
ately. There is an arc into the Finish node from each node that has no successors.
When all of these activities have been finished, the project is finished.
Two problems are typically analyzed in project scheduling. In the first, discussed in this
subsection, the goals are to find the time to complete the project and locate the bottleneck
activities. In the second, discussed in the next section, the goal is to find cost-efficient ways to
complete the project within a given deadline. In each of these problems, a key concept is a
bottleneck activity, called a critical activity. This is an activity that prevents the project from
being completed any sooner. More precisely, a critical activity is an activity that, if its dura-
tion increases, the time to complete the project necessarily increases. The set of critical activ-
ities is called the critical path. The critical path is important for practical reasons. It identifies
the activities that should be expedited (or at least monitored closely) because this will have a
beneficial effect on the overall project time. In contrast, if an activity is not on the critical
path, then speeding it up will not have any beneficial effect on the overall project time.
15-6 Chapter 15
Project Management
There are several ways to model project scheduling. The way we describe in this
section is called the traditional approach because of its widespread use in the project-
scheduling field. This approach has the advantages that it can easily be implemented in a
spreadsheet, and it can be extended to simulate projects with random durations in a natural
way, as discussed in section 15.4. However, another approach is sometimes used that
involves a network optimization with Solver, much like the ones discussed in Chapter 5.
Specifically, you should be able to convince yourself that the critical path through a
project network such as the one in Figure 15.1 is the longest path from the Start node to the
Finish node, using the durations as “distances.” If the project network is not too complex,
this longest path can be determined easily. For example, there are three paths from Start to
Finish in Figure 15.1: Start--A--D--Finish, Start--A--E--Finish, and Start--
B--C--E--Finish. The lengths of these paths are 8  12  20, 8  6  14, and
10  3  6  19, respectively. Therefore, the critical path is the longest path, Start--
A--D--Finish, the critical activities are A and D, the time to complete the project is 20,
and all activities other than A and D have some slack.
Although this “longest path through a network” approach is appealing and can be
implemented fairly easily with Solver, it doesn’t generalize easily to the case where the
activity durations are random. Therefore, we do not pursue this approach here. Instead, we
use the traditional approach discussed next.
We first require some basic insights. Let ESj be the earliest time activity j can start, and
let EFj be the earliest time activity j can finish. Clearly, the earliest an activity can finish is
the earliest time it can start plus its duration. For example, if the earliest activity D can start
is time 8, and its duration is 12, then the earliest D can finish is time 20. In general, if dj is
the duration of activity j, we have
EFj  ESj dj
(15.1)
An activity is critical if, by increasing its duration, the time to complete the project
increases. The critical path is the set of critical activities.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Now, if activity i is an immediate predecessor of activity j, activity j cannot start until
activity i finishes. In fact, activity j cannot start until all of its immediate predecessors have
finished, so the earliest time activity j can start is the maximum of the earliest finish times
of its immediate predecessors:
ESj  max(EFi)
(15.2)
Here, the maximum is over all immediate predecessors i of activity j.
Equations (15.1) and (15.2) can be used to find the earliest start times and earliest fin-
ish times of all activities, beginning with the fact that the earliest start time for the Start
node is 0—it can start right away. A by-product of these calculations is the project com-
pletion time. It is the earliest start time of the Finish node:
Project completion time  ESFinish node
(15.3)
The reason is that when the Finish node is reached, the entire project is complete.
This calculation of the earliest start and finish times through Equations 15.1 to 15.3 is
usually called the forward pass of the CPM algorithm. The reason for this term is that the
calculations are performed in “forward” chronological order of the activities.
To find the critical activities and the critical path, two other equations are required.
Let LSj and LFj be the latest time activity j can start and the latest time it can finish
without increasing the pr oject completion time . Again, analogous to Equation (15.1),
we have
LSj  LFj  dj
(15.4)
(The equation is written in this form because you find LFj first and then use it to find LSj.)
Now suppose activity j is an immediate successor of activity i. Then activity i must
be finished before activity j can start. In fact, a bit of thought should convince you that
the latest time activity i can finish is the minimum of the latest start times of all its
successors:
LFi  min(LSj)
(15.5)
Here, the minimum is over all immediate successors j of activity i. 
For example, suppose activity F has two successors, G and H, and you somehow find
that the latest start times for G and H are 26 and 30. In this case, the bottleneck, at least for
this part of the network, is activity G. The latest it can start without delaying the project is
26; activity H can start later. Therefore, activity G’s predecessor, activity F, has to be fin-
ished no later than time 26.
You can use Equations (15.4) and (15.5) to calculate the latest start times and latest
finish times for all activities, beginning with the fact that the latest finish time for the
Finish node is the project completion time. (Make sure you see why this is true.) This set
of calculations is called the backward pass of the CPM algorithm because you work
through the activities in “backward” chronological order. Then you can calculate the slack
of each activity j as the difference between the latest start time and the earliest start time of
activity j:
Slack of activity j  LSj  ESj
(15.6)
The idea behind slack is simple. If an activity has any positive slack, this activity has
some room to maneuver—it could start a bit later without delaying the project. In fact, its
duration could increase by the amount of its slack without delaying the project. However,
if an activity has zero slack, any increase in its duration necessarily delays the project.
Therefore, the critical path consists of activities with zero slack.
15.2 The Basic CPM Model
15-7
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

The following example illustrates how to implement this method.
15-8 Chapter 15
Project Management
The earliest start time and earliest finish time for any activity are the earliest the
activity can start or finish, given precedence relationships and durations. The latest
start time and latest finish time for any activity are the latest the activity can start or
finish without delaying the project as a whole. The slack of any activity is the amount
of time the activity can be delayed beyond its earliest start time without delaying the
project as a whole. An activity is critical only if its slack is 0.
E X A M P L E
15.1 CREATING AN OFFICE LAN
A
n insurance company has decided to construct a local area network (LAN) in one of
its large offices so that its employees can share printers, files, and other conveniences.
The project consists of 15 activities, labeled A through O, as listed in Table 15.2. This table
indicates the immediate predecessors and immediate successors of each activity, along
with each activity’s expected duration. (At this point these durations are assumed known.)
Note that activity A is the only activity that can start right away, and activity O is the last
activity to be completed. This table implies the AON network in Figure 15.2. The company
wants to know how long the project will take to complete, and it also wants to know which
activities are on the critical path. 
Table 15.2 Data on LAN Activities
Immediate Immediate 
Description
Activity
Predecessor(s)
Successor(s)
Duration (days)
Perform needs analysis
A
None
B
10
Develop specifications
B
A
C, D
6
Select server
C
B
E, G
6
Select software
D
B
F, G
12
Select cables
E
C
F
4
Purchase equipment
F
D, E
H, I
3
Develop user manuals
G
C, D
J
6
Wire offices
H
F
L
12
Set up server
I
F
K
3
Develop training program
J
G
M
14
Install software
K
I
L
4
Connect network
L
H, K
M, N
3
Train users
M
J, L
O
8
Test and debug system
N
L
O
12
Get management acceptance
O
M, N
None
4
Objective
To develop a spreadsheet model of the LAN project so that we can calculate
the time required to complete the project and identify the critical activities.
WHERE DO THE NUMBERS COME FROM?
The computer systems people should be able to obtain the data in the first four columns of
Table 15.2. They would know what needs to be done and in which order. However, the data
in the last column, the durations, are probably guesses at best. There is usually uncertainty
regarding activity times, due to workers not showing up, unavailable components, software
The lists of activities
and their immediate
predecessors in such a
table are enough to
determine the list of
immediate successors.
Try listing the succes-
sors on your own.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

bugs, and so on. We ignore this uncertainty here, but we will deal with it explicitly in
section 15.4, when we discuss simulation of a project.
Solution
To implement the method, you use Equations (15.1) and (15.2) to find the earliest start
and finish times of all activities, Equation (15.3) to find the project completion time,
Equations (15.4) and (15.5) to find the latest start and finish times, and finally Equation
(15.6) to find the slacks and hence the critical activities.
DEVELOPING THE SPREADSHEET MODEL
The completed spreadsheet model is shown in Figure 15.3 (see the file Project Scheduling.
xlsx) and can be developed with the following steps:
1
Input data. Enter the predecessors, successors, and durations in the shaded range.
Note how we have entered data for the Start and Finish nodes in rows 5 and 21.
2
Earliest start and f inish times. Here you implement the forward pass of the algo-
rithm with Equations (15.1) and (15.2). To implement Equation (15.1), enter the formula
=B25+E5
in cell C25 and copy it down to cell C41. To implement Equation (15.2), begin by entering
0 in cell B25. This is because the Start node can begin immediately. Then every other ear-
liest start time is the maximum of the earliest finish times of its predecessors. Unfortunately,
there is no way to enter a single formula and copy it down. You need to specialize each for-
mula to each activity’s particular predecessors. For example, the formulas for activities D
and G, in cells D29 and D32, are
=C27
and
=MAX(C28:C29)
This is because activity D has a single predecessor, whereas activity G has two predeces-
sors. The other formulas in column B are similar. 
3
Project completion time. The project completion time is given in Equation (15.3) as
the earliest start time of the Finish node. Record it in cell B43 with the formula
=B41
15.2 The Basic CPM Model
15-9
A
Start
Finish
D
F
10
12
6
12
6
6
14
4
4
4
8
3
12
3
3
B
C
J
M
E
K
H
I
G
L
N
O
Figure 15.2
AON Diagram for LAN Project
Each earliest start
time is the maximum
of the earliest
finish times of its
predecessors.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4
Latest start and finish times. Next, implement the backward pass of the algorithm
with Equations (15.4) and (15.5). To implement Equation (15.4), enter the formula
=E25-E5
in cell D25 and copy it down to cell D41. To implement Equation (15.5), begin by entering
the formula
=B43
in cell E41. By definition, the latest the Finish node can start (or finish because it has 0
duration) is the project completion time. For the other activities, use Equation (15.5) to cal-
culate the latest finish times. Again, there is no way to copy one formula to all cells; it
depends on each activity’s particular successors. For example, the formulas for activities D
and G, in cells E29 and E32, are
=MIN(D31:D32)
and
=D35
This is because activity D has two successors, whereas activity G has only a single succes-
sor. The other formulas in column D are similar. 
15-10 Chapter 15
Project Management
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
K
J
I
H
G
F
E
D
C
B
A
Oﬃce LAN project - ﬁnding project me and crical path 
Data on acvity network
n
oit
a
r
u
D
sr
o
ss
e
c
c
u
S
sr
o
ss
e
c
e
d
e
r
P
le
b
a
L
ytivitc
A
Dummy Start 
0
A
e
n
o
N
tr
a
tS
e
d
o
n
Perform needs 
0
1
B
tr
a
tS
A
sis
yla
n
a
Develop 
6
D
,C
A
B
s
n
oit
a
cific
e
p
s
Select 
6
G
,E
B
C
r
e
v
r
e
s
Select 
2
1
G
,F
B
D
e
r
a
w
tf
o
s
Select 
4
F
C
E
s
elb
a
c
Purchase 
3
I,
H
E,
D
F
t
n
e
m
piu
q
e
Develop user 
6
J
D
,C
G
sla
u
n
a
m
Wire 
2
1
L
F
H
s
e
ciff
o
Set up 
3
K
F
I
r
e
v
r
e
s
Develop training 
4
1
M
G
J
m
a
r
g
o
r
p
Install 
4
L
I
K
e
r
a
w
tf
o
s
Connect 
3
N
,
M
K,
H
L
k
r
o
w
t
e
n
Train 
8
O
L,J
M
sr
e
s
u
Test & debug 
2
1
O
L
N
m
e
ts
y
s
Get management 
4
h
siniF
N
,
M
O
e
c
n
a
t
p
e
c
c
a
Dummy Finish 
0
e
n
o
N
O
h
siniF
e
d
o
n
Acvity start and ﬁnish mes
Acvity
Earliest start me
Earliest ﬁnish me
Latest start me
Latest ﬁnish me
Slack
0
0
0
0
tr
a
tS
0
0
1
0
0
1
0
A
0
6
1
0
1
6
1
0
1
B
2
4
2
8
1
2
2
6
1
C
0
8
2
6
1
8
2
6
1
D
2
8
2
4
2
6
2
2
2
E
0
1
3
8
2
1
3
8
2
F
2
6
3
0
3
4
3
8
2
G
0
3
4
1
3
3
4
1
3
H
5
9
3
6
3
4
3
1
3
I
2
0
5
6
3
8
4
4
3
J
5
3
4
9
3
8
3
4
3
K
Acvies with 0 slack are on crical, i.e., they 
are on the crical path. Therefore, the crical 
path is A-B-D-F-H-L-N-O. The duraons of the 
noncrical acvies, C, E, G, I, J, K, and M, could 
be increased slightly without aﬀecng the 
project compleon me.
37
38
39
40
41
42
43
0
6
4
3
4
6
4
3
4
L
2
8
5
0
5
6
5
8
4
M
0
8
5
6
4
8
5
6
4
N
0
2
6
8
5
2
6
8
5
O
2
6
2
6
2
6
2
6
h
siniF
Project compleon 
2
6
e
m
it
Figure 15.3
Spreadsheet Model of LAN Project
Each latest finish time
is the minimum of the
latest start times of its
successors.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

5
Slacks. Using Equation (15.6), enter the formula
=D26-B26
in cell F26 and copy it down to cell F40 to calculate the slacks.
Discussion of the Solution
The solution in Figure 15.3 indicates that the LAN can be completed in 62 days—but no
less—if the various activities are started within their earliest and latest start time ranges.
You can see, for example, that activity B, which is critical, must start at time 10. However,
activity C, which is noncritical, can start at any time from 16 to 18. The critical activities
are the ones with zero slack: A, B, D, F, H, L, N, and O. (Refer to the AON network in
Figure 15.2 to see this path.) If any of the activities on this path is delayed, the project
completion time will necessarily increase.
To convince yourself of the difference between critical and noncritical activities, try
increasing the duration of any critical activity such as activity D by one day. You will see
that the project completion time increases by one day as well. However, try increasing the
duration of any noncritical activity such as activity C by any amount up to its slack. You
will see that the project completion time does not increase at all.
This solution can be displayed in a Gantt chart, as shown in Figure 15.4. This popu-
lar type of chart is essentially a time line of when activities start and finish. For example,
the horizontal bar for wiring the office indicates that this activity starts 31 days from now
and is completed 12 days later. (Keep in mind that the current time is day 0.) From the bars
farthest to the right, you can see that the project is completed 62 days from now. You can
15.2 The Basic CPM Model
15-11
A Gantt chart shows
the time line of the
project.
Develop training program
Install soware
Connect network
Train users
Test & debug system
Get management acceptance
Gan Chart
0
10
20
30
40
50
60
70
Perform needs analysis
Develop speciﬁcaons
Select server
Select soware
Select cables
Purchase equipment
Develop user manuals
Wire oﬃces
Set up server
Day
Figure 15.4
Gantt Chart for the LAN Project
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

create this Gantt chart, using the data shown in Figure 15.5, as explained in the following
Excel Tip.
Excel Tip: Creating a Gantt Chart
To create a Gantt chart as in Figure 15.4, enter the data in Figure 15.5—the names of the
activities, their start times, and their durations—in a three-column range. Highlight this
range, click on the Insert tab, and select a stacked horizontal bar chart (the second subtype in
the Bar category). You can accept the rest of the default chart settings, except to get rid of the
legend. The resulting chart will have two adjacent bars for each activity, one on the left for the
start time and one on the right for the duration. Right-click on one of the start time bars and
select Format Data Series. Then change the Fill to None. This effectively hides the start time
bars and shows only the appropriately placed duration bars.
According to this Excel Tip, start times and durations are required for the Gantt chart.
You could use any start times within the earliest and latest start time ranges. The start times
shown in Figure 15.5 are the earliest start times, but you can try your own values in column
B of Figure 15.3 to see how the Gantt chart changes. Just remember that you have choices
only for the noncritical activities: C, E, G, I, J, K, and M. The start times for the critical
activities cannot be changed, at least not without increasing the overall project time.
■
15-12 Chapter 15
Project Management
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
G
F
E
D
C
B
A
Data for Gan chart
Acvity
Start me
Duraon
Perform needs analysis
0
10
Develop speciﬁcaons
10
6
Select server
16
6
Select soware
16
12
Select cables
22
4
Purchase equipment
28
3
Develop user manuals
28
6
Wire oﬃces
31
12
Set up server
31
3
Develop training 
4
1
4
3
m
a
r
g
o
r
p
Install soware
34
4
Connect network
43
3
Train 
8
8
4
sr
e
s
u
Test & debug 
2
1
6
4
m
e
ts
y
s
Get management acceptance
58
4
The noncrical acvies can have start mes 
anywhere within their earliest to latest start me 
ranges. There is no such ﬂexibility for the crical 
acvies.
Figure 15.5
Data for the Gantt Chart
The bars in the
Gantt chart for non-
critical activities can
be adjusted slightly.
The bars for critical
activities are fixed.
MODELING ISSUES
1.
The CPM algorithm we used to find the project completion time and the critical path
is only one of several possible methods for finding these. In Problems 6 and 7, we
indicate two alternatives, both of which employ Solver. The CPM algorithm is proba-
bly the most popular method, and it extends nicely to other situations, particularly
projects with random activity times. However, the Solver models also have their
strengths, especially when the goal is to optimize some sort of cost or reward.
2.
The types of precedence relationships we have used are sometimes called finish-to-
start relationships. For example, task B cannot start until task A finishes. These are
the most common types of precedence relationships, but they are not the only types.
Three other possible types are start-to-start relationships (task B cannot start until
task A has started), finish-to-finish relationships (task B cannot finish until task A has
finished), and start-to-finish relationships (task B cannot finish until task A has
started). Problem 8 asks you to explore the first of these. ■
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

15.2 The Basic CPM Model
15-13
P R O B L E M S
Solutions for problems whose numbers appear within a
colored box can be found in the Student Solutions Files.
Refer to this book’s preface for purchase information.
Skill-Building Problems
1.
Use a one-way data table to see how sensitive the pro-
ject completion time in the LAN project is to the dura-
tion of activity D (selecting software). Let the duration
vary from 10 to 16 days in increments of one day.
2.
Repeat the previous problem, but now keep track of
the following outputs in your data table: the project
completion time and the slack for each activity. As the
duration of activity D changes, do any critical activi-
ties become noncritical? Do any noncritical activities
become critical?
3.
Use a two-way data table to see how sensitive the
project completion time in the LAN project is to the
duration of activities E and H (selecting cables and
wiring offices). Let the durations of these activities
vary from 3 to 6 days and from 10 to 16 days, respec-
tively, in increments of one day each.
4.
In the LAN project, activities C and D can be done con-
currently. Suppose instead that activity C is an immedi-
ate predecessor of activity D. (Perhaps they use the same
employees, and these employees can perform only one
activity at a time.) How does the AON diagram change?
How much does the project completion time increase?
What is the new critical path? (You can assume that
activity E is still an immediate successor of activity C.
That is, it doesn’t need to wait for activity D to finish.)
5.
The data in Figure 15.5 for the Gantt chart uses the 
earliest start times for all activities. These could
actually be anywhere between the earliest and latest
start times without affecting the project completion
time. Enter formulas in the start time cells (column B
of Figure 15.5) using Excel’s RAND function, which
allows these start times to be anywhere between the
earliest and latest start times. Then press the F9 key a
few times. The bars for the noncritical activities should
slide to the left or right in their allowable ranges, but
the project completion time shouldn’t change. 
6.
How difficult is it to add new activities to an existing
project scheduling model? Answer this question by
assuming that there are two other activities, labeled P
and Q. Activity P moves selected employees to tempo-
rary offices while installation occurs, and activity Q
moves them back after installation is finished. Activity P
has immediate predecessors D and E, immediate succes-
sor H, and duration three days. Activity Q has immedi-
ate predecessor L, immediate successor O, and duration
three days. Find the new project completion time. Does
the critical path change because of the new activity?
Skill-Extending Problems
7.
We have illustrated the traditional CPM algorithm
for finding the project length and the critical path. An
alternative method is sometimes used. It sets up a
Solver model for finding a feasible solution to a set of
constraints, and there is no objective to maximize or
minimize. Let dj be the duration of activity j, and let tj
be the start time of activity j. Let the tjs be the chang-
ing cells in the Solver model. There is a constraint for
each arc in the AON network. Specifically, if there is
an arc from activity i to activity j, then there is a con-
straint tj  ti  di. This states that activity j cannot start
until its predecessor, activity i, finishes. Develop this
Solver model for the LAN project, making sure that
there is no objective cell in the Solver dialog box. (Just
delete whatever is in the Set Objective box.) Then run
Solver to find the project completion time. Can you tell
from the solution which activities are critical?
8.
Expanding on the previous problem, there is a third
possible approach for finding the project length and
the critical path. We already stated that the critical
path is the longest path from the Start node to the
Finish node. Using the same approach used in Chapter 5
to find the shortest path through a network, find the
project length and the critical path for the LAN pro-
ject. (Hint: The only necessary modification to the
shortest path method is to maximize, not minimize.)
9.
The “Modeling Issues” section described three alterna-
tive types of precedence relationships besides the
usual finish-to-start relationship. The following ques-
tions ask you to explore the first of these alternatives
for the LAN project.
a. Start-to-start relationships are sometimes useful
for activities that can run parallel to one another.
Suppose that there is a start-to-start relationship
between activities J (developing training program)
and M (training users). Specifically, activity M
cannot start until activity J has started. In general,
do the CPM formulas for earliest start times need
to be changed when there are start-to-start relation-
ships? What about the formulas for latest finish
times? Redo the CPM calculations with this new
relationship.
b. Repeat part a, but now generalize even a bit more.
Assume that activity M cannot start until three
weeks after activity J starts. This is a delayed start-
to-start relationship.
c. Getting the correct logic for earliest start and latest
finish formulas for the relationships in parts a and b
can be a bit tricky. As an alternative, modify the
Solver model from Problem 7 for these relationships.
This should be more straightforward. Do you get the
same results as in parts a and b? (You should.)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

15.3 MODELING ALLOCATION OF RESOURCES
The basic CPM model presented in the previous section is concerned solely with timing.
Given the known durations, the activities are scheduled so that the project is completed as
soon as possible. In this section, we discuss another aspect of project scheduling, the allo-
cation of resources. The activities in a project always consume resources, including money,
people, and possibly others. When we say that an activity has a duration of 10 days, we are
implicitly assuming that certain resources have been allocated to this activity. For example,
it might be that five engineers, working at $300 per day per engineer, can complete the
activity in 10 days. It is possible, however, that if more or fewer than five engineers were
assigned to the activity (or maybe they were paid more or less than $300 per day), the
activity would be finished sooner or later than 10 days. These are trade-offs that must
typically be made when scheduling a project.
If you suspect that this is a multiobjective optimization problem, discussed in
Chapter 16, you are absolutely correct. There are typically three primary objectives: (1) to
finish the project quickly, (2) to consume as few resources as possible (especially, to mini-
mize costs), and (3) to produce a high-quality project. Because of these three objectives,
there are many potential optimization models for project scheduling, and the academic
research in this area has explored many of them, including some that are quite complex. We
set our sights considerably lower here. We first indicate how a project manager can at least
monitor resource usage. This is not actually optimization, but optimization models could be
built upon it. We then discuss one of the most popular optimization models for project
scheduling, called crashing. In the crashing model, it is possible to shorten the activity
durations by spending extra money on them—that is, it is possible to crash the activities.
The problem is to spend as little extra money as possible to complete the project within a
given deadline. (We say “extra” because money is presumably already being spent to
achieve the given activity durations. Now we want to spend extra money to speed them up.)
Monitoring the Use of Resources
Almost all projects require money and people. Therefore, we focus on these two resources
here. Of course, other resources such as facilities or equipment could also be monitored. The
following extension of the LAN project example from the previous section illustrates how
the money and people devoted to the project can be monitored over time in Excel.
Admittedly, this is somewhat tedious. A software package that is devoted to project schedul-
ing, such as Microsoft Project, has much better tools for monitoring resource usage.
15-14 Chapter 15
Project Management
E X A M P L E
15.2 MONITORING RESOURCES FOR THE LAN PROJECT
R
ecall from Example 15.1 that an insurance company is creating a LAN for one of its
large offices. In that example, we provided activity durations for the 15 activities 
in the project, and we showed that with these durations, the project can be completed in
62 days. We now make some assumptions about the money and people resources that are
implicit in these activity durations. First, we assume that the various activities require dif-
ferent technical expertise, which comes from five groups of people: engineering, systems,
purchasing, installers, and training. To achieve the durations used in Example 15.1, we
assume the numbers of people required per day for the various activities are those shown in
Table 15.3. For example, to perform the needs analysis in 10 days, six engineers are
required per day. Note that connecting the network is the only activity that requires two
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

different types of people: three systems people and five installers for each of the three days
this activity takes to complete. Also, note that the last activity, getting management accep-
tance, doesn’t show any people requirements. In reality, this activity is probably the
responsibility of the project manager, who is busy throughout the entire project. (Almost
all projects have a project manager.)
In addition to these people, the various activities require money. It certainly costs
money to pay the people, and there are probably other costs as well. We assume the costs
per day for the various activities are those shown in Table 15.4. The company wants to see
how its people and money are used over time. Also, because some of the activities have
some slack, the company wants to see how the resource usages are affected by adjusting
the starting times of the noncritical activities.
Objective
To create time series charts of the money and people usages, and to see how
these are affected by the starting times of the noncritical activities.
15.3 Modeling Allocation of Resources
15-15
Table 15.3 People Required per Day for Various Activities
Activity
Duration Engineering
Systems Purchasing
Installers Training
Perform needs analysis
10
6
Develop specifications
6
8
Select server
6
5
Select software
12
7
Select cables
4
3
Purchase equipment
3
4
Develop user manuals
6
5
Wire offices
12
8
Set up server
3
4
Develop training 
14
9
program
Install software
4
6
Connect network
3
3
5
Train users
8
8
Test and debug system
12
5
Get management 
acceptance
4
Table 15.4 Costs per Day for the Various Activities
Activity
Cost per Day
Perform needs analysis
$500
Develop specifications
$500
Select server
$400
Select software
$400
Select cables
$400
Purchase equipment
$300
Develop user manuals
$300
Wire offices
$450
Set up server
$400
Develop training program
$300
Install software
$400
Connect network
$450
Train users
$300
Test and debug system
$400
Get management acceptance
$250
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

WHERE DO THE NUMBERS COME FROM?
The numbers of people required per day, shown in Table 15.3, are probably based on
technical considerations of the activities. In fact, these numbers are probably chosen
first, and activity durations are then based on them. For example, the company might
estimate that it takes eight installers to wire the offices properly, and if eight installers are
used per day, the wiring can then be completed in 12 days. The costs in Table 15.4 are
based on the wage rates of the various types of people, plus any other expenses required
to perform the activities.
Solution
The solution appears in the file Project Monitoring.xlsx. To monitor daily costs, you can
proceed as follows. (See Figures 15.6, 15.7, and 15.8, where Figure 15.7 includes several
hidden columns.) You first perform the same CPM calculations as in Example 15.1. These
appear in Figure 15.6, along with the given costs per day. You then create a table of daily
15-16 Chapter 15
Project Management
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
G
F
E
D
C
B
A
Oﬃce LAN project - monitoring costs
Data on acvity network
n
oit
a
r
u
D
sr
o
ss
e
c
c
u
S
sr
o
ss
e
c
e
d
e
r
P
le
b
a
L
ytivitc
A
Dummy Start 
ts
o
C
0
A
e
n
o
N
tr
a
tS
e
d
o
n
 per day
Perform needs 
0
0
5
$
0
1
B
tr
a
tS
A
sis
yla
n
a
Develop 
0
0
5
$
6
D
,C
A
B
s
n
oit
a
cific
e
p
s
Select 
0
0
4
$
6
G
,E
B
C
r
e
v
r
e
s
Select 
0
0
4
$
2
1
G
,F
B
D
e
r
a
w
tf
o
s
Select 
0
0
4
$
4
F
C
E
s
elb
a
c
Purchase 
0
0
3
$
3
I,
H
E,
D
F
t
n
e
m
piu
q
e
Develop user 
0
0
3
$
6
J
D
,C
G
sla
u
n
a
m
Wire 
0
5
4
$
2
1
L
F
H
s
e
ciff
o
Set up server
0
0
4
$
3
K
F
I
Develop training 
0
0
3
$
4
1
M
G
J
m
a
r
g
o
r
p
Install 
0
0
4
$
4
L
I
K
e
r
a
w
tf
o
s
Connect 
0
5
4
$
3
N
,
M
K,
H
L
k
r
o
w
t
e
n
Train 
0
0
3
$
8
O
L,J
M
sr
e
s
u
Test & debug 
0
0
4
$
2
1
O
L
N
m
e
ts
y
s
Get management 
0
5
2
$
4
h
siniF
N
,
M
O
e
c
n
a
t
p
e
c
c
a
Dummy Finish 
0
e
n
o
N
O
h
siniF
e
d
o
n
Acvity start and ﬁnish mes
Acvity
Earliest start me
Earliest ﬁnish me
Latest start me
Latest ﬁnish me
Slack
0
0
0
0
tr
a
tS
0
0
1
0
0
1
0
A
0
6
1
0
1
6
1
0
1
B
2
4
2
8
1
2
2
6
1
C
0
8
2
6
1
8
2
6
1
D
30
31
32
33
34
35
36
37
38
39
40
41
42
43
2
8
2
4
2
6
2
2
2
E
0
1
3
8
2
1
3
8
2
F
2
6
3
0
3
4
3
8
2
G
0
3
4
1
3
3
4
1
3
H
5
9
3
6
3
4
3
1
3
I
2
0
5
6
3
8
4
4
3
J
5
3
4
9
3
8
3
4
3
K
0
6
4
3
4
6
4
3
4
L
2
8
5
0
5
6
5
8
4
M
0
8
5
6
4
8
5
6
4
N
0
2
6
8
5
2
6
8
5
O
2
6
2
6
2
6
2
6
h
siniF
Project me
62
Figure 15.6
CPM Calculations for the LAN Project
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

costs, as shown in Figure 15.7. To do this, the starting times for the activities in column B
are required. This figure uses the earliest starting times for illustration. The file actually
contains a second similar table that uses the latest starting times, just for comparison. 
Then you can fill in the table by entering the formula
=IF(AND($B47<C$46,$B47+$E6>=C$46),$G6,0)
in cell C47 and copying it to the rest of the table. This formula checks whether the day in
row 46 is within the duration of the activity. If it is, the formula records the daily cost; oth-
erwise, it records 0. Then you can sum the daily costs in row 62.
After you have the total daily costs in row 62, you can create a chart of these costs
through time, as shown in Figure 15.8. Here are several notes about this chart:
■
We used a scatter chart of cost (row 62) versus day (row 46). You can experiment
with other chart types, such as a line chart, but don’t go overboard with fancy charts. The
point is to indicate the variation in daily cost through time as clearly as possible.
15.3 Modeling Allocation of Resources
15-17
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
L
B
K
B
F
E
D
C
B
A
Daily costs using earliest starng mes
Day
Acvity
Starng me
1
2
3
4
61
62
0
0
0
0
5
0
0
5
0
0
5
0
0
5
0
A
0
0
0
0
0
0
0
1
B
0
0
0
0
0
0
6
1
C
0
0
0
0
0
0
6
1
D
0
0
0
0
0
0
2
2
E
0
0
0
0
0
0
8
2
F
0
0
0
0
0
0
8
2
G
0
0
0
0
0
0
1
3
H
0
0
0
0
0
0
1
3
I
0
0
0
0
0
0
4
3
J
0
0
0
0
0
0
4
3
K
0
0
0
0
0
0
3
4
L
0
0
0
0
0
0
8
4
M
0
0
0
0
0
0
6
4
N
0
5
2
0
5
2
0
0
0
0
8
5
O
Total cost for each day
$500
$500
$500
$500
$250
$250
Figure 15.7
Daily Costs for the LAN Project (Using Earliest Start Times)
Figure 15.8
Time Series of Daily Costs
$1,000
$1,200
$1,400
Daily Costs
$0
$200
$400
$600
$800
0
10
20
30
40
50
60
70
Day
Daily cost (EST)
Daily cost (LST)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

■
We actually chart two series in Figure 15.8: one where all activities begin at their ear-
liest start times (EST) and one where they all start at their latest start times (LST).
There are some differences between the two, and the project manager needs to judge
how important these differences are. For example, if his goal is to smooth out daily
costs as much as possible, each of these series appears to be about equally smooth.
■
Regardless of which starting times are used (either the earliest start times, the latest
start times, or any times in between), the project manager can see from this chart
where the cost requirements peak (somewhere in the middle of the project) and
where they are lowest (at the beginning and the end of the project). This is exactly
the type of information such a chart is intended to provide.
You can develop a time series chart of people usage in essentially the same way,
as indicated in Figures 15.9, 15.10, and 15.11. The first of these again shows the CPM
calculations, along with the data on people usage per day. Figure 15.10 (with many
hidden columns) shows the daily usage of engineers, assuming that all activities start
at their earliest start times. There is a similar table for the other types of people (sys-
tems, purchasing, installers, and training), and in each of these, you could replace the
earliest start times with the latest start times or any times in between. The typical for-
mula in cell C48 is
=IF(AND($B48<C$47,$B48+$E6>=C$47),$G6,0)
15-18 Chapter 15
Project Management
Figure 15.9
CPM Calculations for the LAN Project
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
K
J
I
H
G
F
E
D
C
B
A
Oﬃce LAN project - monitoring people
Data on acvity network
s
e
cr
u
o
s
e
R
n
oit
a
r
u
D
sr
o
ss
e
c
c
u
S
sr
o
ss
e
c
e
d
e
r
P
le
b
a
L
ytivitc
A
 (# of people) used per day
Dummy Start 
g
ninia
r
T
sr
ella
ts
nI
g
nis
a
h
cr
u
P
s
m
e
ts
y
S
g
nir
e
e
nig
n
E
0
A
e
n
o
N
tr
a
tS
e
d
o
n
Perform needs 
6
0
1
B
tr
a
tS
A
sis
yla
n
a
Develop 
8
6
D
,C
A
B
s
n
oit
a
cific
e
p
s
Select 
5
6
G
,E
B
C
r
e
v
r
e
s
Select 
7
2
1
G
,F
B
D
e
r
a
w
tf
o
s
Select 
3
4
F
C
E
s
elb
a
c
Purchase 
4
3
I,
H
E,
D
F
t
n
e
m
piu
q
e
Develop user 
6
J
D
,C
G
sla
u
n
a
m
5
Wire 
8
2
1
L
F
H
s
e
ciff
o
Set up 
4
3
K
F
I
r
e
v
r
e
s
Develop training 
4
1
M
G
J
m
a
r
g
o
r
p
9
Install 
6
4
L
I
K
e
r
a
w
tf
o
s
Connect 
5
3
3
N
,
M
K,
H
L
k
r
o
w
t
e
n
Train 
,J
M
sr
e
s
u
L
O
8
8
Test & debug 
5
2
1
O
L
N
m
e
ts
y
s
Get management 
4
h
siniF
N
,
M
O
e
c
n
a
t
p
e
c
c
a
Dummy Finish 
0
e
n
o
N
O
h
siniF
e
d
o
n
Acvity start and ﬁnish mes
Acvity
Earliest start me
Earliest ﬁnish me
Latest start me
Latest ﬁnish me
Slack
0
0
0
0
tr
a
tS
0
0
1
0
0
1
0
A
0
6
1
0
1
6
1
0
1
B
2
4
2
8
1
2
2
6
1
C
0
8
2
6
1
8
2
6
1
D
2
8
2
4
2
6
2
2
2
E
0
1
3
8
2
1
3
8
2
F
2
6
3
0
3
4
3
8
2
G
0
3
4
1
3
3
4
1
3
H
5
9
3
6
3
4
3
1
3
I
2
0
5
6
3
8
4
4
3
J
5
3
4
9
3
8
3
4
3
K
0
6
4
3
4
6
4
3
4
L
2
8
5
0
5
6
5
8
4
M
N
46
58
46
58
0
39
40
41
42
43
N
46
58
46
58
0
0
2
6
8
5
2
6
8
5
O
2
6
2
6
2
6
2
6
h
siniF
Project me
62
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

which is then copied to the rest of the table. The chart in Figure 15.11 is again a scatter
chart of the usage of each type of people versus day. (Remember that this chart is based on
the earliest start times. To see how usages vary with start times, you could enter different
start times in column B of Figure 15.10.)
We are making an important assumption in these people usage calculations. For exam-
ple, the chart shows that 12 systems people are required in days 17 through 22. Actually,
five of these are required for selecting the server, and seven are required for selecting the
software. But what if fewer than 12 systems people are available on days 17 through 22?
Then the current schedule is clearly infeasible. There are two options: (1) one of these two
activities could be postponed, hence lengthening the time of the project, or (2) some extra
15.3 Modeling Allocation of Resources
15-19
Figure 15.10 Engineers Required per Day for the LAN Project (Using Earliest Start Times)
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
L
B
K
B
F
E
D
C
B
A
Resources consumed using earliest starng mes
Engineering
Day
Acvity
Starng me
1
2
3
4
61
62
0
0
6
6
6
6
0
A
0
0
0
0
0
0
0
1
B
0
0
0
0
0
0
6
1
C
0
0
0
0
0
0
6
1
D
0
0
0
0
0
0
2
2
E
0
0
0
0
0
0
8
2
F
0
0
0
0
0
0
8
2
G
0
0
0
0
0
0
1
3
H
0
0
0
0
0
0
1
3
I
0
0
0
0
0
0
4
3
J
0
0
0
0
0
0
4
3
K
0
0
0
0
0
0
3
4
L
0
0
0
0
0
0
8
4
M
0
0
0
0
0
0
6
4
N
0
0
0
0
0
0
8
5
O
Total for each 
0
0
6
6
6
6
y
a
d
10
12
14
Resource Usage
0
2
4
6
8
0
10
20
30
40
50
60
70
Day
Engineering
Systems
Purchasing
Installers
Training
Figure 15.11 Time Series of People Usages
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

systems people could be hired (or borrowed from another project). In any case, the value of
such a chart is that it shows potential infeasibilities in the current schedule, so that alterna-
tive schedules can be pursued. 
In a practical sense, charts such as these are monitored throughout the lifetime of the
project. As we all know from experience, cost estimates often change (they usually
increase) as the project unfolds, and estimates of other resource requirements can change
as well. Therefore, the project manager needs to monitor requirements continually to
ensure that they stay within allowable limits.
■
Crashing the Activities
The objective in many project-scheduling analyses is to find a minimum-cost method of
reducing activity times to meet a deadline. The term crashing the activities is often used to
mean reducing the activity times. Of course, it typically costs money to crash activities—
hiring extra workers, using extra equipment, using overtime, and so on—so the problem
becomes one of crashing just the right activities in just the right amounts to meet a deadline
at minimum cost. We now illustrate how Solver can be used to solve this problem.
15-20 Chapter 15
Project Management
E X A M P L E
15.3 MEETING A DEADLINE FOR THE LAN PROJECT
F
rom the CPM calculations in Example 15.1, the insurance company knows that if the
LAN activities continue to take as long as listed in Table 15.2, the entire project will
take 62 working days to complete. However, the project manager is under pressure to fin-
ish the job in 56 working days. He estimates that each activity could be crashed by a cer-
tain amount at a certain cost. Specifically, he estimates the cost per day of activity
time reduction and the maximum possible days of reduction for each activity, as shown in
Table 15.5. For example, activity A’s duration could be reduced from 10 days to 9 days at
cost $600, or it could be reduced from 10 days to 8 days at cost $1200. (It is even possible
to have a fractional reduction, such as from 10 days to 8.5 days at cost $900.) On the other
hand, note that three of the activities cannot be crashed at all, probably due to technical
considerations. How can the deadline be met at minimum cost?
Table 15.5 Crashing Inputs
Maximum
Description
Activity
Cost per Day
Reduction
Perform needs analysis
A
$600
2
Develop specifications
B
$600
1
Select server
C
$480
1
Select software
D
$480
3
Select cables
E
$480
1
Purchase equipment
F
-
0
Develop user manuals
G
$360
1
Wire offices
H
$540
4
Set up server
I
-
0
Develop training program
J
$360
4
Install software
K
$480
1
Connect network
L
-
0
Train users
M
$360
2
Test and debug system
N
$480
3
Get management acceptance
O
$300
1
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Objective
To use a Solver model to decide how much to crash each activity so that the
deadline is met at minimum cost.
WHERE DO THE NUMBERS COME FROM?
The numbers in Table 15.5 are not necessarily easy to obtain. The project manager proba-
bly has some idea of the minimum possible time to perform any activity, regardless of the
amount spent. For example, wiring offices takes a minimal amount of time, regardless of
how many people are working on it. He probably also has a good idea of what it would take
to expedite any activity—extra workers, for example—and the corresponding cost.
Solution
The required Solver model follows almost immediately from the project scheduling model
in Figure 15.3 discussed previously. You need to make only a few changes, as summarized
in the following list and in Table 15.6.
■
There are now changing cells to indicate how much crashing to perform.
■
There are two constraints: an activity cannot be crashed by more than the allowable
limits, and the deadline must be met.
■
The objective is to minimize the crashing costs. The project length is not the objec-
tive; it is part of the deadline constraint.
15.3 Modeling Allocation of Resources
15-21
Table 15.6 Variables and Constraints for the Crashing Model
Input variables
Activity durations (before crashing), precedence 
relationships, crashing data, deadline
Decision variables (changing cells)
Crashing amounts of activities
Objective (target cell)
Total crashing cost
Other calculated variables
Project length
Constraints
Precedence constraints
Crashing amount  Maximum reduction 
Project length  Deadline
DEVELOPING THE SPREADSHEET MODEL
The spreadsheet model is shown in Figure 15.12. (See the Project Crashing.xlsx file.)
Because much of this model is identical to the previous project-scheduling model, we dis-
cuss only the modifications.
1
Input data. In the shaded ranges, enter the three extra inputs: the per-day crashing
costs, the upper limits on crashing, and the deadline.
2
Reductions. Enter any initial values for the changing cells in column I for the reduc-
tions in activity durations. 
3
Durations. Calculate the durations after crashing in column E by subtracting the
reductions in column I from the original durations, which have been moved to column G.
Note that these modified durations in column E are then used, via the same CPM calcula-
tions as before, to find the project time in cell B45.
4
Crashing cost. To calculate the total cost of crashing, enter the formula
=SUMPRODUCT(Crash_amount,Cost_per_day)
in cell B47.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

USING EVOLUTIONARY SOLVER
The Solver dialog box appears in Figure 15.13. Note that Evolutionary Solver (discussed
in Chapter 8) has been selected. We have introduced a subtle nonlinearity into this model
that would be easy to miss. For any crashing amounts in the changing cells, the new dura-
tions are calculated in column E, and these are used to calculate the project completion
15-22 Chapter 15
Project Management
Figure 15.12 The Crashing Model (With a Suboptimal Solution)
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
M
L
K
J
I
H
G
F
E
D
C
B
A
Oﬃce LAN project - crashing to meet a deadline
Data on acvity network
Crashing secon
n
oit
a
r
u
D
sr
o
ss
e
c
c
u
S
sr
o
ss
e
c
e
d
e
r
P
le
b
a
L
ytivitc
A
Dummy Start node
Start
None
A
0
Original duraon
Crash amount
Max crash
Cost per day
Perform needs analysis
0
0
6
$
2
=
<
0
0.2
0
1
0
0.8
B
tr
a
tS
A
Develop 
0
0
6
$
1
=
<
0
0.1
6
0
0.5
D
,C
A
B
s
n
oit
a
cific
e
p
s
Select 
0
8
4
$
1
=
<
0
0.0
6
0
0.6
G
,E
B
C
r
e
v
r
e
s
Select 
0
8
4
$
3
=
<
0
0.0
2
1
0
0.2
1
G
,F
B
D
e
r
a
w
tf
o
s
Select 
0
8
4
$
1
=
<
0
0.0
4
0
0.4
F
C
E
s
elb
a
c
Purchase 
0
=
<
0
0.0
3
0
0.3
I,
H
E,
D
F
t
n
e
m
piu
q
e
Develop user 
0
6
3
$
1
=
<
0
0.0
6
0
0.6
J
D
,C
G
sla
u
n
a
m
Wire 
0
4
5
$
4
=
<
0
0.2
2
1
0
0.0
1
L
F
H
s
e
ciff
o
Set up 
0
=
<
0
0.0
3
0
0.3
K
F
I
r
e
v
r
e
s
Develop training 
0
6
3
$
4
=
<
0
0.0
4
1
0
0.4
1
M
G
J
m
a
r
g
o
r
p
Install 
0
8
4
$
1
=
<
0
0.0
4
0
0.4
L
I
K
e
r
a
w
tf
o
s
Connect 
0
=
<
0
0.0
3
0
0.3
N
,
M
K,
H
L
k
r
o
w
t
e
n
Train users
0
6
3
$
2
=
<
0
0.0
8
0
0.8
O
L,J
M
Test & debug 
0
8
4
$
3
=
<
0
0.0
2
1
0
0.2
1
O
L
N
m
e
ts
y
s
Get management 
0
0
3
$
1
=
<
0
0.1
4
0
0.3
h
siniF
N
,
M
O
e
c
n
a
t
p
e
c
c
a
Dummy Finish 
0
e
n
o
N
O
h
siniF
e
d
o
n
Acvity start and ﬁnish mes
Acvity
Earliest start me
Earliest ﬁnish me
Latest start me
Latest ﬁnish me
Slack
Range names used
a
d
_
r
e
p
_
ts
o
C
0
0
0
0
tr
a
tS
y
=Model!$M$6:$M$20
n
u
o
m
a
_
h
s
a
r
C
0
8
0
8
0
A
t
=Model!$I$6:$I$20
7
4
$
B
$
!le
d
o
M
=
ts
o
c
_
g
nih
s
a
r
C
0
3
1
8
3
1
8
B
5
4
$
D
$
!le
d
o
M
=
e
nild
a
e
D
2
1
2
5
1
9
1
3
1
C
2
$
K
$:6
$
K
$
!le
d
o
M
=
h
s
a
rc
_
x
a
M
0
5
2
3
1
5
2
3
1
D
0
5
4
$
B
$
!le
d
o
M
=
e
m
it
_
tc
ejo
r
P
2
5
2
1
2
3
2
9
1
E
0
8
2
5
2
8
2
5
2
F
0
1
3
5
2
1
3
5
2
G
0
8
3
8
2
8
3
8
2
H
3
4
3
1
3
1
3
8
2
I
0
5
4
1
3
5
4
1
3
J
3
8
3
4
3
5
3
1
3
K
0
1
4
8
3
1
4
8
3
L
0
3
5
5
4
3
5
5
4
M
0
3
5
1
4
3
5
1
4
N
0
6
5
3
5
6
5
3
5
O
6
5
6
5
6
5
6
5
h
siniF
42
43
44
45
46
47
Deadline constraint
Project 
e
nild
a
e
D
e
m
it
6
5
=
<
6
5
Crashing cost
$3,180
Figure 15.13
Evolutionary Solver
Dialog Box for the
Crashing Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

time, using the same logic for earliest start and finish times as before. (Actually, the latest
start and finish times are not required. They are used only to calculate the slacks.)
The problem is that some of the formulas in the earliest start time column use the
MAX function, which introduces nonlinearity into the model. In fact, it makes the model
nonsmooth—the same problem discussed with IF functions in the backlogging aggregate
planning model in Chapter 4. This requires Evolutionary Solver, as discussed in Chapter 8.
(The Project Crashing.xlsx file is set up for Evolutionary Solver.) 
An Alternative Linear Model
A linear version of the crashing model is also available, and we have included it for your
convenience in the file Project Crashing Linear.xlsx (see Figure 15.14). In this model,
precedence relationships are handled through constraints. The start times of the various
activities in row 4 are changing cells. (The reductions in durations in row 7 are also chang-
ing cells.) Denote the starting time of activity i by ti and its duration by di. Then if activity
j is an immediate successor of activity i, you need to add the constraint tj  ti  di (or alter-
natively, tj  ti  di), which ensures that activity j cannot start until after activity i finishes.
There is one such constraint for each arc in the AON network, and they are implemented in
rows 15 to 35. The project time is the start time of the Finish node (found in cell T4), and
the total cost of crashing is a simple SUMPRODUCT of rows 7 and 12. The resulting
linear model guarantees a very quick Solver solution because the simplex method can be
used. It is also a somewhat more flexible model because it can be generalized for other
versions of the basic CPM model. 
15.3 Modeling Allocation of Resources
15-23
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
A
B
C
D
E
F
G
H
I
J
K
L
M
N
O
P
Q
R
S
T
U
V
W
X
Oﬃce LAN project - crashing to meet a deadline: a linear model
5
3
$
U
$:5
1
$
U
$
!le
d
o
M
=
s
e
m
it
_
tr
a
ts
_
ni_
ffi
D
h
siniF
O
N
M
L
K
J
I
H
G
F
E
D
C
B
A
tr
a
tS
ytivitc
A
Start 
5
3
$
W
$:5
1
$
W
$
!le
d
o
M
=
n
oit
a
r
u
D
6
5
3
5
3
4
5
4
0
4
6
3
1
3
3
3
8
2
5
2
5
2
1
2
5
1
5
1
9
0
0
s
e
m
it
Max_reducon
=Model!$E$9:$S$9
Original 
9
3
$
B
$
!le
d
o
M
=
e
m
it
_
tc
ejo
r
P
4
2
1
8
3
4
4
1
3
2
1
6
3
4
2
1
6
6
0
1
n
oit
a
r
u
d
Reducon
1
0
0
2
0
0
0
0
0
0
0
0
0
2
1
Reducon
=Model!$E$7:$S$7
4
$
T
$:4
$
D
$
!le
d
o
M
=
s
e
m
it
_
tr
a
tS
=
<
=
<
=
<
=
<
=
<
=
<
=
<
=
<
=
<
=
<
=
<
=
<
=
<
=
<
=
<
Maximum reducon
2
1
1
3
1
0
1
4
0
4
1
0
2
3
1
Duraon aer 
3
0
1
8
3
4
4
1
3
2
1
6
3
4
0
1
6
6
9
n
oitc
u
d
e
r
Cost per day 
0
0
3
0
8
4
0
6
3
0
8
4
0
6
3
0
4
5
0
6
3
0
8
4
0
8
4
0
8
4
0
0
6
0
0
6
d
e
h
s
a
rc
Incident matrix (from AON diagram)
Start
A
B
C
D
E
F
G
H
I
J
K
L
M
N
O
Finish
Diﬀ in start mes
Duraon
Start
A
-1
1
0
>=
0
A
B
-1
1
9
>=
9
B
C
-1
1
6
>=
6
B
D
-1
1
6
>=
6
C
E
-1
1
6
>=
6
C
G
-
1
1
10
>=
6
D
F
-1
1
10
>=
10
D
G
-1
1
10
>=
10
E
F
-1
1
4
>=
4
F
H
-1
1
3
>=
3
F
I
-
3
=
>
8
1
1
G
J
-
6
=
>
6
1
1
H
L
-
2
1
=
>
2
1
1
1
I
K
-
3
=
>
3
1
1
J
M
-
4
1
=
>
4
1
1
1
K
L
-
4
=
>
4
1
1
L
M
-
3
=
>
5
1
1
L
N
-
3
=
>
3
1
1
M
O
-
8
=
>
8
1
1
N
O
-
0
1
=
>
0
1
1
1
O
Finish
-1
1
3
>=
3
Deadline constraint
Project me
Deadline
56
<=
56
Total cost of crashing
2820
Figure 15.14 The Linear Crashing Model
Discussion of the Solution
According to the optimal solution in Figure 15.12, the durations for activities D and N
should be reduced by two days each, and the durations for activities A and O should be
reduced by one day each. The total cost of this strategy is $2820, and it allows the project
to be completed in the required 56 days. Note that none of the originally noncritical activ-
ities is crashed. These activities were not bottlenecks in the first place, so it doesn’t make
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

much sense to crash these activities. (We do not imply that noncritical activities are never
crashed. They could eventually become critical as other activities are crashed and then
become candidates for crashing. However, this is not the case here.) 
Sensitivity Analysis
Project crashing is ultimately a trade-off between time and cost. We have minimized the
crashing cost for a given time deadline. This is another perfect opportunity to use
SolverTable to see how the crashing cost depends on the deadline. We show this trade-off in
Figure 15.15, where the deadline is varied from 45 days to the original 62 days in increments
of a day. (Note that we used the linear version of the model in the file Project Crashing
Linear.xlsx to create this table. The Evolutionary Solver model takes too long for use with
SolverTable.) Given the limits on the amounts of reduction in the activity durations, you can
see that a deadline of 47 days or fewer is impossible to meet. For longer deadlines, the table
shows the optimal crashing costs. We also calculated the changes in these costs in column C.
Although a longer deadline always costs less, the changes are clearly not constant. For exam-
ple, it costs only $300 to reduce the completion time from 62 days to 61 days, but it costs
$960 to reduce the completion time from 49 days to 48 days. ■
15-24 Chapter 15
Project Management
Figure 15.15 Trade-Off Between Deadline and Crashing Cost
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
A
B
C
D
E
F
G
H
I
J
Oneway analysis for Solver model in Model worksheet
Deadline (cell $D$39) values along side, output cell(s) along top
$B$41
Change
1
45 Not feasible
46 Not feasible
47 Not feasible
48
9420
49
8460
960
50
7560
900
51
6660
900
52
5760
900
53
4860
900
54
4020
840
55
3420
600
56
2820
600
57
2220
600
58
1740
480
59
1260
480
60
780
480
61
300
480
0
2000
4000
6000
8000
10000
48
49
50
51
52
53
54
55
56
57
58
59
60
61
Deadline ($D$39)
Sensivity of $B$41 to Deadline
MODELING ISSUES
1.
The crashing cost functions we have used are linear in the amount of reduction—
each day of reduction (for a given activity) costs the same amount. This is probably
unrealistic. Each extra day of reduction typically costs more than the previous day.
However, if the nonlinear relationship between amount of reduction and cost can be
specified (probably by estimating it from historical data), Evolutionary Solver should
be able to solve the problem with very little modification to the model. Alternatively,
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

the linear model in Project Crashing Linear.xlsx could be modified to have a non-
linear objective. Then GRG Nonlinear Solver could be used.
2.
There might only be discrete crashing opportunities available. For example, there
might be two types of equipment that can be purchased to reduce some activity’s
duration, each involving a certain cost and leading to a certain reduction. This kind
of discrete choice can be handled with binary (0–1) variables as in Chapter 6. ■
Scheduling Multiple Projects
Many organizations have limited labor resources and multiple projects that can (or must)
be completed. Selecting the projects to undertake is a very important problem for any com-
pany. The company must select a portfolio of projects that is consistent with its overall
goals and strategy, provides desired diversification, maintains adequate cash flows, does
not exceed resource availabilities, and does not exceed a reasonable level of risk.
In this section, we illustrate one possible model for project portfolio selection. In this
model, we assume that each potential project has a worker requirement over some duration
and a deadline. If the project is completed by the deadline, the company receives a reward;
otherwise, it receives no reward. We use Evolutionary Solver to determine the projects to
undertake and the optimal start time for each project undertaken. To simplify the example,
we consider each project as a single activity rather than as a series of activities (as in other
sections of this chapter). 
15.3 Modeling Allocation of Resources
15-25
E X A M P L E
15.4 SCHEDULING PROJECTS AT TIMBURTON
T
imburton Construction has 10 projects that it can (if desired) complete within the next
10 months. Each project earns a certain revenue when it is completed, but only if it is
completed within the next 10 months. Otherwise, the project earns no revenue. The num-
ber of workers needed each month, the number of months needed to complete each project,
and the revenue earned from each completed project are listed in Table 15.7. We assume
that after the company begins working on a project, it must work on the project during con-
secutive months until the project is completed. Timburton has 220 workers available each
month. How can it maximize the revenue earned during the next 10 months?
Objective
To find starting times for the projects so that total revenue is maximized and
worker utilization each month is no greater than worker availability. 
Table 15.7 Worker Requirements and Revenues
Workers per
Project
Month
Months
Revenue
1
74
5
4800
2
98
2
3330
3
91
3
4100
4
95
4
6840
5
59
2
1650
6
81
3
3880
7
84
4
6380
8
78
3
4200
9
95
3
4860
10
58
5
5220
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

WHERE DO THE NUMBERS COME FROM?
The setup here is a simplified version of what might happen in a real company. In reality,
each project would probably be composed of well-defined tasks, each of which would
require workers (and maybe other resources) over some duration. As for the revenues, the
all-or-nothing nature we are assuming here might be built into contracts for the project,
where the company is paid by a client only if it completes the client’s project by a certain
deadline. Of course, these deadlines could differ across projects. This generalization could
easily be incorporated into our model.
Solution
The completed model is in the file Scheduling Multiple Projects.xlsx (see Figure 15.16).
We assume that each project can be started at the beginning of any month from 1 to 10.
Each changing cell indicates the month a project starts. For example, a changing cell value
of 4 for project 5 means that project 5 is started at the beginning of month 4. We also allow
each project’s changing cell to equal 11. This means that the company does not undertake
the project at all. To develop the model, proceed according to the following steps:
1
Inputs. Enter the inputs in the blue ranges.
2
Project schedule. Enter any start times in the range F7:F16. Then calculate the finish
times in column G by entering the formula
=F7+C7-1
15-26 Chapter 15
Project Management
Figure 15.16 Model for Scheduling Multiple Projects
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
K
J
I
H
G
F
E
D
C
B
A
Scheduling mulple (overlapping) projects
Ranges names used:
6
1
$
F
$:7
$
F
$
!le
d
o
M
=
tr
a
tS
0
1
e
nild
a
e
D
Workers available per 
5
3
$
B
$
!le
d
o
M
=
t
e
g
r
a
T
0
2
2
h
t
n
o
m
Project
Workers/month
Months
Revenue
Start
Finish
Earned
0
5
1
1
1
0
0
8
4
5
4
7
1
0
3
3
3
0
1
9
0
3
3
3
2
8
9
2
0
0
1
4
0
1
8
0
0
1
4
3
1
9
3
0
4
8
6
7
4
0
4
8
6
4
5
9
4
0
5
6
1
5
4
0
5
6
1
2
9
5
5
0
8
8
3
3
1
0
8
8
3
3
1
8
6
0
4
1
1
1
0
8
3
6
4
4
8
7
0
0
2
4
3
1
0
0
2
4
3
8
7
8
0
6
8
4
8
6
0
6
8
4
3
5
9
9
0
2
2
5
5
1
0
2
2
5
5
8
5
0
1
Projects (along side) worked on in various months (along top)
1
2
3
4
5
6
7
8
9
10
0
0
0
0
0
0
0
0
0
0
1
1
1
0
0
0
0
0
0
0
0
2
1
1
1
0
0
0
0
0
0
0
3
0
0
0
1
1
1
1
0
0
0
4
0
0
0
0
0
1
1
0
0
0
5
0
0
0
0
0
0
0
1
1
1
6
0
0
0
0
0
0
0
0
0
0
7
0
0
0
0
0
0
0
1
1
1
8
0
0
1
1
1
0
0
0
0
0
9
0
0
0
0
0
1
1
1
1
1
0
1
Workers 
9
8
1
9
8
1
6
8
1
0
9
1
0
9
1
2
1
2
2
1
2
7
1
2
7
1
2
7
1
2
d
e
s
u
Worker capacity 
0
0
?
d
e
d
e
e
c
x
e
0
0
0
0
0
0
0
0
Total revenue 
0
8
0
4
3
d
e
n
r
a
e
Penalty for exceeding capacity
0
Objecve to 
0
8
0
4
3
e
zi
m
ix
a
m
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

in cell G7 and copying it down. Note the effect of subtracting 1. The projects finish at the
ends of the months in column G. For example, using the values in Figure 15.16, project 4
starts in month 4 and finishes at the end of month 7, for a duration of four months.
3
Revenues. The revenue for a project is obtained only if the project is finished by the
deadline, so enter the formula
=IF(G7<=Deadline,D7,0)
in cell H7 and copy it down. (This is one of several places where IF functions are required.
This explains why Evolutionary Solver is required.)
4
Worker utilization. The table in the middle of the model uses 0–1 values to indicate
which months workers are used or not used by the various projects. To fill it in, enter the
formula
=IF(AND($F7<=B$19,B$19<=$G7),1,0)
in cell B20 and copy it to the range B20:K29. Then to find the number of workers used
each month, enter the formula
=SUMPRODUCT($B$7:$B$16,B20:B29)
in cell B30 and copy it across row 30. This formula is based on the assumption that each
project uses the same number of workers for its entire duration. (It wouldn’t be difficult
to change this assumption so that worker utilization could change during the project’s
duration.)
5
Penalties. As discussed in Chapter 8, Evolutionary Solver does better with penalties
for violating constraints than with explicit constraints. Therefore, check in row 31 whether
each month’s worker availability is violated with the formula
=IF(B30>$B$4,1,0)
in cell B31, copied across row 31. Then calculate a total penalty for worker constraint vio-
lations in cell B34 with the formula
=100000*SUM(B31:K31)
(Any suitably large constant could be used here. It should be large relative to the magni-
tudes of the revenues.)
6
Objective. Sum the revenues in column H to obtain the total revenue earned in cell
B33, and calculate the objective to maximize in cell B35 with the formula
=B33-B34
The penalty for violating constraints is subtracted from the “real” objective.
USING EVOLUTIONARY SOLVER
The setup for Evolutionary Solver is shown in Figure 15.17. Note that there are no explicit
constraints on worker availabilities because these have been incorporated as penalties in
the objective. The only explicit constraints are that the start times must be integers between
1 and the deadline plus 1. (Again, the interpretation of a start time equal to 11 is that this
project isn’t undertaken at all.)
Discussion of the Solution
It took us a number of tries, using various starting solutions in the changing cells and vari-
ous Evolutionary Solver settings, to obtain the solution shown in Figure 15.16. This is evi-
dently a difficult combinatorial problem, even though there are only 10 changing cells,
15.3 Modeling Allocation of Resources
15-27
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

each with only 11 possible values. (Keep in mind that this implies 1011 possible solutions,
a very large number.) Don’t be surprised if you obtain a solution with a slightly smaller
objective than we obtained. In fact, there may even be a slightly better solution than ours.
In any case, our solution indicates that the company can complete all but two of the proj-
ects within the deadline without violating worker availability in any month. To achieve
this, it has to stagger the starting times of the projects so that they don’t overlap too much.
You can see that the maximum number of projects ever in process at any time is three. If
you compare the worker requirements in the input section to the number of workers avail-
able each month, 220, the solution makes sense—four projects never “fit” in a single
month, but some combinations of three projects do fit.
■
15-28 Chapter 15
Project Management
Figure 15.17
Evolutionary Solver
Dialog Box
P R O B L E M S
Skill-Building Problems
10. Suppose, after doing the analysis in Example 15.2, the
project manager sees a problem with the current setup.
Activity C, selecting the server, requires five systems peo-
ple, and activity D, selecting the software, requires seven
systems people. The problem is that these two activities
are scheduled concurrently, even though it turns out that
four of the five systems people for activity C and four of
the seven systems people for activity D are the same peo-
ple. Assuming that a given person can work on only one
activity at a time, some changes need to be made.
a. One possible change is to assign two of the four
people in common to activity C and the other two
to activity D. Now three people will be assigned to
activity C and five people will be assigned to activ-
ity D. Unfortunately, with fewer people assigned,
the durations of these activities will increase from
6 days to 9 days for activity C and from 12 days to
14 days for activity D. How much will these
changes delay the project?
b. Another possible change is to make activity D a suc-
cessor to activity C, so that the four common people
can continue to be assigned to both activities. How
should the AON diagram for the project be redrawn?
How much will this change delay the project?
c. What other changes might you suggest?
11. In the Monitoring Costs sheet of the Project
Monitoring.xlsx file, we created two tables of daily
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

costs, one where all activities start at their earliest start
times and one where they start at their latest start times.
Then we created a single chart for both of these. As an
alternative, do the following. Delete the bottom table
(the one that uses latest start times). For the top table,
give the user three choices: (1) the start times in column
B can be the earliest start times, (2) the start times can
be halfway between the earliest and latest start times,
and (3) the start times can be the latest start times.
Implement this so that the user can input a 1, 2, or 3 in
some (currently unused) cell to make the choice. Based
on this input, the appropriate start times should appear in
the table (from the use of IF formulas), and the chart
should show the associated daily costs graphically.
(If you know how, you could also let the user make
the choice from one of three radio buttons.)
12. In the LAN crashing model in Example 15.3, suppose
that activity D is now an immediate successor to activity
C, that is, activity D cannot begin until activity C is fin-
ished. Everything else stays the same. (However, note
that activity B is no longer an immediate predecessor of
activity D, and activity G is no longer an immediate
successor of activity C.) Modify both the Project
Crashing.xlsx and Product Crashing Linear.xlsx files
and run the appropriate Solver on each of them to meet
a deadline of 58 days. Do you get the same schedule
from each of them? (The idea is that the linear model, if
set up correctly, should find the optimal solution easily,
but Evolutionary Solver might have some trouble get-
ting the exact optimal solution.)
13. Modify the multiple project-scheduling model in
Example 15.4 so that each project has its own due
date. These due dates are listed in the file
P15_13.xlsx. Assume no revenue is earned unless a
project is completed by its due date. Assuming that the
objective is still to maximize total revenue, when
should each project be started?
14. Given the due dates in the previous problem, how
would you maximize the number of projects com-
pleted on time? (The difference here is that you are
ignoring revenues.)
15. Suppose the projects in Example 15.4 are apartment
units and the profit is the monthly rent earned from
each apartment unit. Assume that rent is paid each
month (through month 10) beginning with the month
after the project is completed. How can the profit
earned during the next 10 months be maximized?
16. In the model in Example 15.4, suppose each project
consists of two activities and the second activity for
each project cannot begin until the first activity is
completed. Assuming the two activities for a given
project could require different numbers of employees,
how would you modify the model developed in
Example 15.4? (You can make up any reasonable
activity times and employee requirements.)
15.3 Modeling Allocation of Resources
15-29
17. In the crashing model in Example 15.3, we assumed
that the cost per day crashed is constant. This is often
unrealistic. For example, it might cost $300 to
decrease the duration of an activity from 10 days to 9
days, but it might cost $450 to reduce it from 9 days to
8 days. One possible way to model this is to assume
that the crashing cost, c(d), for reducing the duration
by d days is a quadratic: c(d)  cd2 for some constant
c  0. This function produces the “increasing cost per
day” behavior frequently seen. To try it out in
Example 15.3, suppose the crashing cost for activity
H, wiring offices, exhibits this quadratic behavior,
with c  300. Then, for example, the cost of reducing
the duration of activity H from 12 days to 9 days is
c(3)  300(3)2  $2700. Modify the Project 
Crashing Linear.xlsx model to accommodate this
quadratic function, and then optimize to meet a dead-
line of 54 days. (You can still assume that activity H
can be crashed by a maximum of 4 days.) Now you
must use GRG Nonlinear Solver.
Skill-Extending Problems
18. In the Monitoring People sheet of the Project 
Monitoring.xlsx file, we created five tables of daily
costs, one for each type of people, and we created
a chart for all of these. In each table, the start times
were the earliest start times. As an alternative, do
the following. Delete the bottom four tables. For the top
table, give the user three choices for the start times:
(1) the start times in column B can be the earliest start
times, (2) the start times can be halfway between the
earliest and latest start times, and (3) the start times can
be the latest start times. Also, let the user choose one
type of people to monitor: engineering, systems, pur-
chasing, installers, or training. You can decide on the
user interface for making these choices. Based on these
choices, the appropriate start times should appear in
column B of the table, the body of the table should
show daily usages of the type of people selected, and
the chart should show these daily usages graphically.
(Hint: In the formulas in the body of the table, you will
need to refer to one of the columns in the range
G6:K20. One useful way to do so is with Excel’s OFF-
SET function. For example, you could offset everything
with respect to cell F5 or any other convenient “anchor”
cell. Look up the OFFSET function in online help.)
19. Starting with a project schedule where some activities
are noncritical, is it ever optimal to crash any of these
noncritical activities to meet a given deadline? The
idea is that as you keep crashing to meet a tighter and
tighter deadline, a noncritical activity could conceiv-
ably become critical, and then you might want to crash
it. Experiment with the LAN project model to see if
you can ever make this occur. Feel free to change the
maximum reductions for the activities and/or their
crashing costs per day.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

15.4 MODELS WITH UNCERTAIN ACTIVITY TIMES
In section 15.2, we discussed how to calculate the required time to complete a project that
consists of several activities. We also saw that the critical path consists of the bottleneck
activities, those activities that cannot be delayed without delaying the project as a whole.
In that section, we assumed that the individual activity times are known with certainty. We
now make the more realistic assumption that the activity times are random with given
probability distributions, and we find the distribution of the time needed to complete the
project. Because of randomness, we can no longer identify the critical path. We can only
determine the probability that any activity is critical. 
To illustrate this latter statement, suppose that activities A and B can begin immedi-
ately. Activity C can then begin as soon as activities A and B are both completed, and the
project is completed as soon as activity C is completed (see Figure 15.18). Activity C is
clearly on the critical path, but what about A and B? Suppose that the expected activity
times of A and B are 10 and 12, respectively. If you use these expected times and ignore
any uncertainty about the actual times—that is, if you proceed as in section 15.2—then
activity B is definitely a critical activity because its duration is definitely longer than activ-
ity A’s duration. However, suppose there is some positive probability that A can have dura-
tion 12 and B can have duration 11. Under this scenario, A is a critical activity. Therefore,
you cannot say in advance which of the activities, A or B, will be critical. However, you
can use simulation to see how likely it is that each of these activities is critical. You can
also see how long the entire project is likely to take.
15-30 Chapter 15
Project Management
When activity times
are random, you typi-
cally cannot say for
certain whether a
given activity will be
on the critical path.
E X A M P L E
15.5 LAN PROJECT WITH UNCERTAIN ACTIVITY TIMES
W
e again analyze the LAN project from Example 15.1, but we now assume that the
activity durations are uncertain, with given probability distributions. The company
realizes that the actual activity times can vary due to unexpected delays, worker illnesses,
and so on. Assuming that the company has a deadline of 60 days, it wants to use simulation
to see (1) how long the project is likely to take, (2) how likely it is that the project will be
completed by the deadline, and (3) which activities are likely to be critical.
Objective
To simulate the time to complete the LAN project, and to estimate the proba-
bility that any given activity will be part of the critical path.
WHERE DO THE NUMBERS COME FROM?
All of the data are the same as in Example 15.1 except for the probability distributions for
activity times. We discuss these in some detail here.
Start
Finish
A
C
B
Figure 15.18
A Simple Project
Network
We illustrate the procedure in the following example, which is the same example that we
have been discussing (without crashing). We repeat the story here for your convenience.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Solution
The probability distributions for the uncertain activity times must be chosen first. Then you
can calculate the length of the project and identify the activities on the critical path, given
any randomly generated activity times.
The PERT Distribution
As always, there are several reasonable candidate probability distributions for the random
activity times. Here we illustrate a distribution that is popular in project scheduling, called
the PERT distribution. As shown in Figure 15.19, it is a curved version of the triangular dis-
tribution. Like the triangular distribution, the PERT distribution is specified by three para-
meters that the company should be able to estimate from past experience: a minimum value,
a most likely value, and a maximum value. The distribution in the figure uses the values 4, 5,
and 12 for these three values, which implies a mean of 6.4 We use this distribution for activ-
ity B. Its random activity time can be generated with @RISK using the formula
=RISKPERT(4,5,12)
Similarly, for the other activities, we chose parameters for the PERT distribution that led
to the same means as the durations we used in Example 15.1. (In reality, it would be done
the other way around. The contractor would estimate the minimum, most likely, and max-
imum parameters for the various activities, and the means would then follow from these.
However, we want to keep the means the same as the activity times in Example 15.1 for
comparison.)
15.4 Models with Uncertain Activity Times
15-31
4 This distribution is named after the acronym PERT (Program Review and Evaluation Technique), which is syn-
onymous with project scheduling in an uncertain environment. Its mean is always a weighted average of its three
parameters, with the most likely value getting four times as much weight as the other two. In this case, the mean
is [1(4)4(5)1(12)](141)6.
Figure 15.19
PERT Distribution
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

@RISK Function: RISKPERT
To generate a random number with @RISK from the PERT distribution, a curved version of
the triangular distribution, enter the formula =RISKPERT(Min,Most likely,Max).
DEVELOPING THE SIMULATION MODEL
You can again use the same basic CPM model to calculate the earliest start and finish
times, the latest start and finish times, and the slacks for each of the activities, exactly as in
section 15.2. This method allows you to calculate the total project time for any fixed values
of the activity times—that is, for any iteration of the simulation. By looking at the slacks
for any iteration, you can see which activities are critical for that iteration (because an
activity is critical only if its slack is 0).
The model is a direct extension of the model in Example 15.1, as shown in 
Figure 15.20 (see the Project Simulation.xlsx file), so we describe only the new steps
necessary:
1
Inputs. Enter the information about precedence relationships and the parameters of
the PERT activity time distributions in the blue cells. As discussed previously, we actually
chose the minimum, most likely, and maximum values to achieve the same mean durations
as in Example 15.1. Note that some of these distributions are symmetric about the most
likely value, whereas others are skewed.
2
Activity times. Generate random activity times in column I by entering the formula
=RISKPERT(E6,F6,G6)
in cell I6 and copying it down. Of course, the durations for the fictitious Start and Finish
nodes, in cells I5 and I21, are nonrandom and equal to 0.
3
Critical activities. To see whether an activity is critical, enter the formula
=IF(F26=0,1,0)
15-32 Chapter 15
Project Management
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
N
M
L
K
J
I
H
G
F
E
D
C
B
A
Oﬃce LAN project - simulaon with random acvity mes
Data on acvity network
ts
o
M
ni
M
sr
o
ss
e
c
c
u
S
sr
o
ss
e
c
e
d
e
r
P
le
b
a
L
ytivitc
A
 likely
Max
Implied mean
Duraon
Dummy Start node
Start
None
A
0
Perform needs 
6
0
7.0
1
0
1
6
1
9
8
B
tr
a
tS
A
sis
yla
n
a
Develop 
3
9
0.8
6
2
1
5
4
D
,C
A
B
s
n
oit
a
cific
e
p
s
Select 
7
1
4.5
6
7
6
5
G
,E
B
C
r
e
v
r
e
s
Select 
9
3
3.3
1
2
1
6
1
3
1
4
G
,F
B
D
e
r
a
w
tf
o
s
Select 
9
5
1.4
4
5
4
3
F
C
E
s
elb
a
c
Purchase 
6
3
6.3
3
4
3
2
I,
H
E,
D
F
t
n
e
m
piu
q
e
Develop user 
5
4
3.6
6
8
6
4
J
D
,C
G
sla
u
n
a
m
Wire 
0
4
8.1
1
2
1
8
1
1
1
0
1
L
F
H
s
e
ciff
o
Set up 
0
0
0.3
3
3
3
3
K
F
I
r
e
v
r
e
s
Develop training 
1
2
2.3
1
4
1
6
1
4
1
2
1
M
G
J
m
a
r
g
o
r
p
Install 
5
2
2.3
4
5
4
3
L
I
K
e
r
a
w
tf
o
s
Connect 
3
6
3.3
3
4
3
2
N
,
M
K,
H
L
k
r
o
w
t
e
n
Train 
0
0
0.8
8
8
8
8
O
L,J
M
sr
e
s
u
Test & debug 
8
8
0.0
1
2
1
2
2
1
1
6
O
L
N
m
e
ts
y
s
Get management 
1
0
9.3
4
5
4
3
h
siniF
N
,
M
O
e
c
n
a
t
p
e
c
c
a
Dummy Finish 
e
n
o
N
O
h
siniF
e
d
o
n
0
Acvity start and ﬁnish mes
Acvity
Earliest start me
Earliest ﬁnish me
Latest start me
Latest ﬁnish me
Slack
On crical path?
Pr(crical)
Summary stascs from @RISK for project compleon me
5
4.4
5
m
u
m
ini
M
0
0.0
0
0.0
0
0.0
0
0.0
tr
a
tS
7
6.5
7
m
u
m
ix
a
M
2
7
9.0
1
0
0.0
1
7.0
1
0
0.0
1
7.0
1
0
0.0
A
3
8.2
6
n
a
e
M
2
7
9.0
1
0
0.0
0
8.8
1
1
7.0
1
0
8.8
1
1
7.0
1
B
d
r
a
d
n
a
tS
8
5
1.0
0
6
7.3
8
9.7
2
6
5.2
2
2
2.4
2
0
8.8
1
C
 deviaon
3.75
s
elit
n
e
cr
e
P
3
3
8.0
1
0
0.0
4
1.2
3
0
8.8
1
4
1.2
3
0
8.8
1
D
6
9.6
5
%
5
9
5
1.0
0
6
7.3
4
1.2
3
8
9.7
2
7
3.8
2
2
2.4
2
E
3
1.8
5
%
0
1
5
2
7.0
1
0
0.0
7
7.5
3
4
1.2
3
7
7.5
3
4
1.2
3
F
1
1.0
6
%
5
2
5
7
2.0
0
6
3.1
4
8.9
3
0
5.3
3
8
4.8
3
4
1.2
3
G
4
6.2
6
%
0
5
5
2
7.0
1
0
0.0
1
6.7
4
7
7.5
3
1
6.7
4
7
7.5
3
H
8
2.5
6
%
5
7
0
0
0.0
0
1
6.5
9
3.4
4
9
3.1
4
7
7.8
3
7
7.5
3
I
6
5.7
6
%
0
9
5
7
2.0
0
6
3.1
6
0.3
5
4
8.9
3
0
7.1
5
8
4.8
3
J
7
2.9
6
%
5
9
0
0
0.0
0
1
6.5
1
6.7
4
9
3.4
4
0
0.2
4
7
7.8
3
K
st
e
g
r
a
T
5
2
7.0
1
0
0.0
8
9.0
5
1
6.7
4
8
9.0
5
1
6.7
4
L
 (days)
7
3
2.0
0
6
2
8
2.0
0
6
3.1
6
0.1
6
6
0.3
5
0
7.9
5
0
7.1
5
M
6
2
4.0
2
6
8
1
7.0
1
0
0.0
6
0.1
6
8
9.0
5
6
0.1
6
8
9.0
5
N
0
0
0.1
1
0
0.0
7
9.4
6
6
0.1
6
7
9.4
6
6
0.1
6
O
7
9.4
6
7
9.4
6
7
9.4
6
7
9.4
6
h
siniF
Project compleon me
64.97
Parameters of PERT distribuons
The @RISK stascal measures in 
columns H and K are meaningless unl 
you run the simulaon.
Figure 15.20 The LAN Project Simulation Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

in cell G26 and copy it down. This records a 1 for any activity with 0 slack—that is, for any
critical activity. However, if you press the F9 key to generate new random durations, you
will see that the critical activities can change from one iteration to another. It is convenient
to calculate averages of these 0–1 values in column H. To do so, enter the formula
=RISKMEAN(G26)
in cell H26 and copy it down. Initially, the values in this column are meaningless.
However, after running the simulation, they indicate the fraction of iterations that result in
1. This fraction is an estimate of the probability that the activity is critical.
4
Summary measures. Enter @RISK statistical functions in column K for the project
completion time. For example, enter
=RISKMEAN(B43)
in cell K27 and
=RISKPERCENTILE($B$43,J30)
in cell K30.
Running the Simulation
You should set the number of iterations to 1000 and the number of simulations to 1, and
then run the simulation in the usual way.
Discussion of the Simulation Results
After running the simulation, you can request the histogram of project times shown in
Figure 15.21. Recall from Example 15.1 that when the activity times are not random, the
project time is 62 days. Now it varies from a low of 54.45 days to a high of 75.67 days,
with an average of 62.83 days.5 Because the company is interested in the probability of fin-
ishing the project within 60 days, we moved the left slider in the graph to 60. This indicates
that there is only about a 23.7% chance of achieving the deadline. In the other direction,
you can see that there is about a 5% chance that the project will take longer than 69.27 days.
This is certainly not good news for the company, and it might have to resort to the crashing
discussed in the previous section.
15.4 Models with Uncertain Activity Times
15-33
Figure 15.21
Histogram of
Project Completion
Time
5It can be shown mathematically that the expected project time is always greater than when the expected activity
times are used to calculate the project time (as in Example 15.1). In other words, an assumption of certainty
always leads to an (overly optimistic) underestimation of the true expected project time.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

The @RISK averages of 0–1 values in the range H26:H40 of Figure 15.20 indicate the
fraction of iterations where each activity was critical. Several of these fractions, notably
for activities A, B, and O, are very close (or equal) to 1. This means that these activities are
almost always (or always) critical. Evidently, only very unusual values for the random
durations can make these activities noncritical. Similarly, activities I and K are never criti-
cal; their fractions are equal to 0. The fractions for the other activities are less extreme.
Any one of them could easily be on the critical path. Therefore, there is no single critical
path. It depends completely on the random durations that happen to be observed.
One last observation is that the 0–1 values in column G are “all or nothing.” That is, if
the slack changes from 0 to a very small positive number such as 0.00023, then the 0–1
variable in column G changes from 0 to 1 and indicates that the corresponding activity is
noncritical. This evidently happened in the few iterations where activities A and B were
not critical. They were still very close to being critical.
■
15-34 Chapter 15
Project Management
MODELING ISSUES
The traditional PERT approach to project scheduling with uncertain activity times does not
involve simulation. Instead, it starts with a minimum, most likely, and maximum estimate
of each activity’s time (just as we did with the PERT distribution). Then it uses formulas to
find the mean and standard deviation of each activity time distribution, and finally it uses
an approximate method to calculate the mean and standard deviation of the time to com-
plete the project. This method has been in use for many years, and it is found in many text-
books on project management. However, we favor the simulation approach used here
because it has the following benefits over the traditional approach: (1) it is more straight-
forward and easier to understand, (2) it permits any distributions for the activity times, not
just the PERT distributions we used, (3) it provides estimates of the probabilities that the
various activities are critical, and (4) it even allows you to build correlation (with the
RISKCORRMAT function) into the activity times. In short, the simulation approach is
more flexible, and it can be implemented easily with Excel and @RISK. ■
P R O B L E M S
Skill-Building Problems
20. In the model in Example 15.5, suppose bonuses and
penalties are incurred for earliness or lateness.
Specifically, suppose a bonus of $2000 is received if the
project is completed within 60 days, an extra bonus of
$1000 is received if the project is completed within
58 days, and a penalty of $1000 is incurred for every full
day past a project completion of 64 days. (For example,
if the project is completed in 66.7 days, the penalty is
$2000—two full days late.) Modify the model appropri-
ately, and then run the simulation to find the distribution
of the net monetary outcome (negative if a penalty, posi-
tive if a bonus). What is the expected value of this net
amount? What is the probability of a $3000 total bonus?
What is the probability of a penalty of at least $4000?
21. We indicated in Example 15.5 that the mean project
length from the simulation is greater than the project
length of 62 days from substituting the mean activity
durations (the ones used in earlier sections). Note that
the PERT distributions we used in the example, with
the exception of activity D, are either symmetric around
the most likely value or skewed to the right. Could this
skewness to the right lead to the rather large mean pro-
ject length from the simulation? Experiment with the
parameters of the PERT distributions in the example,
always keeping the same mean durations. For example,
you could change the parameters of activity A from 8,
9, 16 to 7, 10, 13 (to make it symmetric) or to 4, 11, 12
(to make it skewed to the left). Each of these has the
same mean, 10, and there are many other combinations
that have mean 10 that you could try. Run the simulation
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

with a few such combinations. What effect does it have
on the mean project length from the simulation? Does
the mean project length continue to be greater than 62?
What effect does it have on the percentiles of the simu-
lation, such as the 5th or 95th percentiles? Do you con-
clude that the shapes of the input distributions, given
that they keep the same means, have much effect on the
distribution of project length?
Skill-Extending Problems
22. You saw in Chapter 10 how to introduce correlation
into an @RISK simulation with RISKCORRMAT
functions. We implicitly assumed that the activity
durations in Example 15.5 are probabilistically inde-
pendent. However, it is very possible that some of
them would be correlated in a real situation.
Specifically, assume activities A and B are positively
correlated with correlation 0.7. Also, assume that
activities G and J are positively correlated with corre-
lation 0.6. Modify the model appropriately and rerun
the simulation. What differences, if any, do you see in
the outputs?
23. Most of the literature in project scheduling with
uncertain activity times advocates the use of the beta
distribution for activity times. This is a continuous
distribution with four parameters: a minimum, a maxi-
mum, and two parameters 1 and 2 that control the
shape of the distribution. (@RISK calls this the
generalized beta, or BetaGeneral, distribution because
the “standard” beta distribution has minimum 0 and
maximum 1.) It turns out that the PERT distribution we
have been using is a special case of the generalized
beta distribution. However, it has only three parame-
ters: a minimum, a most likely value, and a maximum.
To understand this better, try the following. Click on
the Windows Start button, Programs, Palisade Decision
Tools, Online Manuals, and finally Distribution
Function Summary to open a PDF help file. Click on
its bookmark tab to see a list of distribution functions
and click on the PERT (Beta) bookmark. There you
can see how the 1 and 2 parameters are found from
the minimum, most likely, and maximum parameters of
the PERT distribution. Specifically, they are chosen so
that the mean of the PERT distribution is (min  4 ml
 max)6, where ml is the most likely value. You can
also click on the Beta (Generalized) bookmark to see
its properties. Now use this information from online
help as follows. Suppose the parameters of a PERT dis-
tribution are 4, 5, and 12. What is the mean of this dis-
tribution? What are the corresponding values of 1 and
2 for the equivalent beta distribution? According to
the online help for the generalized beta distribution, its
mean is min  [1(1  2)] (max  min). Does this
evaluate to the same mean that you got for the PERT
distribution? Finally, select the PERT distribution
with parameters 4, 5, and 12 from @RISK’s Define
Distributions window, and look at its shape and
properties. Then select the equivalent BetaGeneral
distribution with the parameters you found earlier.
Does it have the same shape and properties as the
PERT distribution? It should—they are equivalent.
15.5 A Brief Look at Microsoft Project
15-35
15.5 A BRIEF LOOK AT MICROSOFT PROJECT
The preceding sections have shown how to implement the various features of project
scheduling in Excel. Excel is a tremendously flexible tool, so with some creativity, it is
possible to implement virtually all of the aspects of project management in a spreadsheet.
However, a number of software packages are devoted entirely to project management.
These packages are not necessarily as flexible as Excel, but they tend to be very good at
their intended purpose: project management.6 MS Project is actually part of the Microsoft
Office family of software, but it must be purchased separately from Office. It is arguably
one of the most popular project-management software packages and is used by many com-
panies to manage their projects.
The good news is that MS Project is a powerful software package for managing pro-
jects. The bad news is that, as with other powerful software packages, it takes some time
and practice to learn the many features of the package. There is no way we can provide
more than a brief introduction to its capabilities. Nevertheless, it is not too difficult to get
started, as we discuss briefly here.
When you open MS Project, you can ask to create a new project. This takes you
through a wizard that asks you a few questions, such as when the project can start, and even-
tually shows you a blank spreadsheet-like window. This is where you can list the project
tasks and their durations, as shown in Figure 15.22 for the LAN project we have been
6The academic version of MS Project is no longer available with the fourth edition of the book. 
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

discussing. (MS Project allows you to save your work in an mpp file. The file for this project
is LAN Project.mpp.) Note that the start time for each project is 1/30/2006 (the day this
section was originally written), and the finish times are automatically entered as the start
times plus the durations.7 Note also that MS Project does not require Start and Finish nodes,
although you can add these (with 0 durations) if you like.
The next step is to enter the immediate predecessors of the tasks in the Predecessors
column. These appear in the next-to-last column of Figure 15.23. For example, the prede-
cessors of activity 6 (purchase equipment) are activities 3 and 4, and they are entered as
“3,4” in the Predecessors column. (Note that we have now specified that the project can
start on 9/1/2006, and working is permitted on weekends.) As soon as this information on
durations and immediate predecessors is entered, MS Project does the required CPM cal-
culations behind the scenes. By right-clicking in the gray row at the top of the window, you
can ask for various columns of information to be inserted. As Figure 15.23 indicates, we
asked for the early start and finish times, the late start and finish times, the free and total
slacks, and the immediate successors. You do not need to do anything to create these
columns; all you need to do is ask for them. Note that MS Project shows each Start time
15-36 Chapter 15
Project Management
7By default, Project skips over the weekends. For example, note that the first activity, with duration 10 days, goes
from Monday through Friday and then the next Monday through the next Friday. However, it is possible to
change a setting so that work is performed over weekends, as we do in later figures.
Figure 15.22
Tasks for the LAN
Project
Figure 15.23 Tasks and Precedence Relations for LAN Project
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

(third column) as the Early Start time by default. However, we know that tasks with slack
can start anywhere between their early and late start times.
Technical Note: Free and Total Slacks
The quantity we have called slac k is often called total slac k. A task’ s total slack is the
amount of time the task can be delayed before the project finish date is delayed. For exam-
ple, task 3, selecting the server, has a total slack of 2 days. It can start as early as Sunday,
9/17/2006, but if it is delayed by 2 days and doesn’ t start until the following Tuesday, the
project as a whole will not be delayed. There is also another slack called the free slack. A
task’s free slack is defined as the amount of time a task can be delayed without delaying its
successor tasks. For example, note that task 3’s successors, tasks 5 and 7, have early start
times Satur day, 9/23/2006 and F riday, 9/29/2006. T ask 3’ s early f inish time is F riday,
9/22/2006, so if task 3 is delayed at all, the early start time of one of its successors, task 5,
will be delayed. This explains the free slack of 0 for task 3. However, this free slack for task
3 is probably less relevant than its total slack because task 5 itself has slack and can there-
fore be delayed without delaying the project. 
MS Project automatically creates a fairly large number of charts that you can view. We
show two of them in Figures 15.24 and 15.25. The Gantt chart in Figure 15.24 is essentially
the same as the one we constructed in Excel except that the order of tasks from top to
bottom is reversed. (You can hover the cursor over any of these bars to see more information
about the associated tasks.) The AON project diagram, part of which appears in
Figure 15.25, shows the precedence relationships, as well as the start and finish times, the
durations, and information about resources used (which we haven’t specified for this
15.5 A Brief Look at Microsoft Project
15-37
Figure 15.24 Gantt Chart for the LAN Project
Figure 15.25 Network Diagram for the LAN Project
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

project). Although it is not visible in this black and white drawing, the critical activities and
noncritical activities appear in different colors on a computer screen.
In addition, you can request many reports. One possibility (not shown here) lists
information about the activities on the critical path. Of course, MS Project figures out
which activities are on the critical path. All you need to do is ask for the report.
MS Project is a very powerful and feature-rich software package; however, it does have
some drawbacks. First, it has no built-in optimizer (such as Solver) to perform any optimiza-
tion, such as crashing to meet a deadline. Second, it assumes a deterministic world, where the
durations of the activities are known with certainty. Of course, you can change any durations
manually to see how the project as a whole is affected, but you cannot run a simulation with
random durations, as we did with @RISK. In spite of these drawbacks, MS Project and other
project management software packages play a prominent role at many organizations, and we
wouldn’t be surprised if some of you end up using one of these packages in your jobs.
15.6 CONCLUSION
As we have indicated in this chapter, project management is an area all in itself. This is due
to the importance of managing large and costly projects in most organizations. Many entire
books have been written about the various aspects of project management, and the topics
we have covered here form only a relatively small percentage of the material in these
books. Nevertheless, you have seen that management science offers a number of tools that
are useful in scheduling and allocating resources to projects. Among others, these tools
include (1) the CPM calculations used to determine the length of a project and its critical
path, (2) optimization models for crashing activities to meet a deadline at minimum cost,
and (3) simulation models for determining how the length of a project is affected by
uncertain task times. Finally, you have seen that a number of software packages, such as
MS Project, are devoted entirely to project management. Although these packages lack
some of the features available with Excel, notably optimization and simulation, they can be
very effective for managing the timing and required resources of real-world projects.
15-38 Chapter 15
Project Management
Summary of Key Management Science Terms
Term
Explanation
Page 
CPM
Critical Path Method, used to analyze projects with known activity times
15-3
PERT
Program and Evaluation Review Technique, used to analyze projects with 
15-3
random activity times
Duration
Time to complete an activity in a project
15-5
Immediate predecessor
Activity that must be completed before a given activity can begin
15-5
Immediate successor
Activity that can’t start until a given activity is completed
15-5
Critical activity
Activity whose delay will necessarily delay the completion of the project
15-6
Critical path
Set of all critical activities, also called the bottleneck path
15-6
Slack
Amount a noncritical activity can be delayed without delaying the project
15-7
Earliest and latest 
Earliest and latest times an activity can start and finish, given the 
15-8
starting times
precedence relationships in the project
Earliest and latest  
Earliest and latest times an activity can start and finish without delaying 
15-8
finish times
the project
Gantt chart
Chart that shows the schedule of activities
15-11
Crashing
Reducing activity times (at a cost) to meet a deadline
15-14
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

15.6 Conclusion
15-39
P R O B L E M S
Skill-Building Problems
24. A company has a project that consists of 11 activities,
described in the file P15_24.xlsx. Draw an AON pro-
ject network and then find the critical path and the
minimum number of days required to complete this
project. Also, create the associated Gantt chart.
25. Before a new product can be introduced at Kehls, the
activities shown in the file P15_25.xlsx must be com-
pleted, where all times are in weeks.
a. Draw the AON project network and determine a
critical path and the minimum number of weeks
required before the new product can be introduced.
b. The duration of each activity can be reduced by up to
two weeks at the following cost per week: A, $80; B,
$60; C, $30; D, $60; E, $40; F, $30; G, $20. (Assume
that activity H cannot be crashed.) Determine how to
minimize the cost of getting the product into the
stores for the peak Christmas sales period, assuming
that it is now 12 weeks before this period begins.
26. The promoters of a rock concert in Indianapolis must
perform the tasks shown in the file P15_26.xlsx before
the concert can be held. (All durations are in days.) Draw
the AON project network. Then find the critical path and
the minimum number of days needed to prepare for the
concert, and create the associated Gantt chart.
27. Consider the (simplified) list of activities and prede-
cessors that are involved in building a house, as shown
in the file P15_27.xlsx.
a. Draw an AON project network and find the critical
path and the minimum number of days needed to
build the house. Also, create the associated Gantt
chart.
b. Suppose that by hiring additional workers, the
duration of each activity can be reduced. The costs
per day of reducing the duration of the activities
are also given in the file P15_27.xlsx. Find the
strategy that minimizes the cost of completing the
project within 20 days.
28. A company is planning to manufacture a product that
consists of three parts, labeled A, B, and C. The com-
pany anticipates that it will take five weeks to design
the three parts and determine the way in which these
parts must be assembled to make the final product.
Then the company estimates that it will take four
weeks to make part A, five weeks to make part B, and
three weeks to make part C. The company must test
part A after it is completed, and the testing takes two
weeks. The assembly line process will then proceed as
follows: assemble parts A and B (two weeks) and then
attach part C (one week). Then the final product must
undergo one week of testing. Draw the AON project
network. Then find the critical path and the minimum
amount of time needed to complete the project, and
create the associated Gantt chart.
29. Horizon Cable is about to expand its cable TV offer-
ings in Smalltown by adding MTV and other stations.
The activities listed in the file P15_29.xlsx must be
completed before the service expansion can be com-
pleted. Draw the AON project network and find the
critical path and the minimum number of weeks
needed to complete the project. Also, create the
associated Gantt chart.
30. When an accounting firm audits a corporation, the first
phase of the audit involves obtaining knowledge of the
business. This phase of the audit requires the activities
listed in the file P15_30.xlsx.
a. Draw the AON project network and determine the
critical path and the minimum number of days
needed to complete the first phase of the audit.
Also, create the associated Gantt chart.
Summary of Key Excel Terms
Term
Explanation
Excel
Page
Gantt chart
Way to show activity durations through 
See Excel Tip
15-12
time in a meaningful way
PERT distribution
Useful for simulating activity times
Use RISKPERT function in @RISK
15-32
Microsoft Project
Separate from Excel, but a useful package 
15-35
for analyzing multiactivity projects
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

b. Assume that the first phase must be completed
within 30 days. The duration of each activity can
be reduced by incurring the costs listed in the same
file. Find the strategy that minimizes the cost of
meeting this deadline.
31. The city of Bloomington is about to build a new water
treatment plant. After the plant is designed (D), we can
select the site (S), the building contractor (C), and the
operating personnel (P). After the site is selected, we can
erect the building (B). We can order the water treatment
machine (W) and prepare the operations manual (M)
only after the contractor is selected. We can begin train-
ing (T) the operators when both the operations manual
and operating personnel selection are completed. When
the treatment plant and the building are finished, we can
install the treatment machine (I). After the treatment
machine is installed and operators are trained, we can
obtain an operating license (L). Assume that the time (in
months) needed to complete each activity is normally
distributed, with the means and standard deviations
given in the file P15_31.xlsx. Use simulation to estimate
the probability that the project will be completed in (a)
under 50 days and (b) more than 55 days. Also estimate
the probabilities that B, I, and T are critical activities.
32. To build Indiana University’s new law building, the
activities in the file P15_32.xlsx must be completed
(all times are in months). Assume that all activity
times are normally distributed with the means and
standard deviations given in the file.
a. Estimate the probability that the project will take
less than 30 months to complete.
b. Estimate the probability that the project will take
more than three years to complete.
c. For each of the activities A, B, C, and G, estimate
the probability that it is a critical activity.
33. To complete an addition to the Business Building, the
activities in the file P15_33.xlsx must be completed
(all times are in months). Assume that all activity
times are normally distributed with the means and
standard deviations given in the file. The project is
completed after Room 111 has been destroyed and the
main structure has been built. 
a. Estimate the probability that it will take at least
three years to complete the addition.
b. For each activity, estimate the probability that it
will be a critical activity.
34. Tom Jacobs, an independent contractor, has agreed to
build a new room on an existing house. He plans to
begin work on Monday morning, June 1. The main
concern is when he will complete the project, given
that he works only on weekdays. The work proceeds
in stages, labeled A through J, as summarized in the
table in the file P15_34.xlsx. Three of these activities,
wiring, plumbing, and duct work, will be done by sep-
arate independent subcontractors.
15-40 Chapter 15
Project Management
a. How long will the project take to complete, given
the activity times (durations) in the table? Which
are the critical activities?
b. Use a one-way data table to see how sensitive the
project completion time is to the duration of activ-
ity H (hanging dry wall). Let the duration vary
from 2 to 8 days in increments of 0.5 day.
c. Use a two-way data table to see how sensitive the
project completion time is to the duration of activi-
ties E and F (electrical wiring and plumbing). Let
the durations of each of these activities vary from 2
to 6 days in increments of 0.5 day.
d. Tom is currently subcontracting the electrical
wiring, plumbing, and duct work. This explains
why these three activities can be performed
simultaneously. Suppose instead that Tom plans to
do the first two of these by himself, and he can work
on only one activity at a time—electrical wiring and
then plumbing. Modify the critical path model
appropriately. How much does the project comple-
tion time increase? What is the new critical path?
e. Continuing part d, where electrical wiring must be
done before plumbing, suppose Tom must com-
plete the project within a deadline of 17 days. You
are given the crashing data in the file P15_34.xlsx.
What should he do?
f. How difficult is it to add new activities to an exist-
ing project scheduling model? Answer this ques-
tion by assuming that Tom must also install
bookshelves in the room, and these can be installed
only after the drywall has been hung. It typically
takes 2.5 days to install the bookshelves. However,
he has been instructed to make these bookshelves
from a special type of wood, which must be custom
ordered. He can place the order right away, and it is
likely to take 10 working days to arrive. In addi-
tion, he has been instructed to install a wet bar in
the room. This cannot be started until the plumbing
and electrical wiring are finished, and this wet bar
takes an estimated 3.5 days to finish. Find the new
project completion time. Does the critical path
change because of the new activities?
35. In the previous problem, all of Tom’s activities have
fixed durations. Now assume they have PERT distribu-
tions with the parameters listed in the file P15_35.xlsx. 
a. Use @RISK to simulate this project. What is the
mean length of time required to complete the pro-
ject? What is the probability that it will be com-
pleted within 20 days? What is the probability that
it will require more than 23 days to complete?
b. Are there activities that are always (or almost
always) critical? Are there activities that are never
(or almost never) critical? For each other activity,
what is the probability that it is critical?
c. For any activities that are never (or almost never)
critical, you might expect that the durations of
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

these activities are not highly correlated with the
total project time. Use @RISK’s sensitivity analy-
sis, with the correlation option, to see whether this
is the case. What correlations between the inputs
and the output do you find? Can you explain why
they turn out as they do?
Skill-Extending Problems
36. Real-world projects often have milestones where costs
are incurred or payments are received. Usually the
costs are incurred relatively early, and the payments
are received relatively late. Because of the time value
of money, it is advantageous to incur the costs as late
as possible and receive the payments as early as possi-
ble. Consider the AON diagram in Figure 15.26. As
before, the circles denote activities, the arrows denote
precedence relationships, and the numbers next to the
circles are durations (in months). The diamonds denote
milestones, and the number next to each milestone
denotes the cost incurred (if negative) or the payment
received (if positive) when that milestone is reached.
The problem is to maximize the NPV of all cash flows
(payments minus costs) by choosing the starting times
of the activities appropriately. Develop a Solver model
to do so, using an annual discount rate of 10%. (For dis-
counting purposes, you can assume that if a milestone is
reached after, say, 10 months of work, then the cost or
payment is incurred at the end of month 10.)
37. Based on LeBlanc et al. (2000). A construction com-
pany has eight project managers and has 14 projects
scheduled for the next 12 weeks. Each project must be
assigned a project manager. The start and finish week
for each project as well as the hours per week each
project manager would need to spend on a project are
given in file P15_37.xlsx. For example, project 1 starts
at the beginning of week 4 and finishes at the end of
15.6 Conclusion
15-41
week 10, for a duration of seven weeks. Also note that
if manager 2 is assigned to project 1, he will work
50 hours per week on the project. In assigning man-
agers, the company has a policy of not allowing a
manager to work more than 70 hours a week. Given
this constraint and the fact that all projects must be
done, the company wants to minimize the total number
of weeks during which managers work more than 50
or less than 30 hours. (Note that, given the data for the
problem, working fewer than 30 hours in a week
means not working that week at all.) How would you
assign managers to projects? (Hint: This problem is
conceptually fairly simple, but the bookkeeping is
difficult. Here is one possibility. Let the changing cells
be a column of indexes of the managers assigned to
the various projects. For example, the changing cell
for project 1 is 4 if we assign manager 4 to project 1.
Based on the values in these changing cells, use a
lookup function to find the number of hours used by
each project. For example, again assuming manager 4
is assigned to project 1, this lookup should return 38
for project 1. Now create a table with weeks along the
top and projects along the side. Each entry in the table
should indicate how many hours are spent on each
project each week. IF functions work here. Finally,
create one more table with weeks along the top and
managers along the side and use SUMIF functions,
based on the data in the previous table, to calculate the
number of hours each manager is working each week.
As you can probably guess, you will need to use
Evolutionary Solver if you set it up this way. Also, you
might have to let Evolutionary Solver run for a long
time. This is not an easy problem.)
38. Consider a project with six activities. The CPM
method has already been implemented, with the results
shown in the file P15_38.xlsx. (All times are in
months.) This file also shows the number of workers
Milestone 1
(Start)
A
B
C
D
E
Milestone 2
Milestone 3
Milestone 4
(Finish)
2 months
8 months
4 months
8 months
3 months
-$4000
$9000
$3000
-$5000
Figure 15.26
AON Diagram for 
a Project with
Milestones
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

of type A, the number of workers of type B, and the
material costs per month for each of the activities.
Workers of type A receive $1600 per month, and
workers of type B receive $2400 per month.
a. Create a table and then an associated line chart that
shows the monthly cash flows through the end of the
project when each activity is started at its earliest
start time and when it is started at its latest start time.
That is, two series should be plotted on the chart.
b. Suppose the company in charge of this project
wants to find the start times for the activities so that
the NPV of the cash flows is minimized, using an
annual discount rate of 10%. Create a Solver model
to do this. The only constraints are that the start
times must be within their earliest and latest start
time ranges.
39. One problem with our Excel implementation of the
CPM method is that the maximum and minimum for-
mulas for the earliest start time and the latest finish
times have to be tailored to the specific AON network.
15-42 Chapter 15
Project Management
That is, you can’t enter formulas for a typical activity
and then copy them down for the other activities.
However, there is a clever way of doing this if you are
willing to use some advanced Excel functions.8 This
method is illustrated in the file P15_39.xlsx for the
LAN project from Example 15.1. The text box in this
file explains a few things about the new formulas,
including the fact that they deliberately create circular
references.
a. Use online help to learn exactly what the formulas
for the earliest start times and latest finish times are
doing and why one formula fits all for each. Then
explain in words how they work.
b. Implement this method for the project in
Figure 15.27. You can make up any durations for
the activities.
8We thank Cliff Ragsdale, a fellow textbook author, for discovering
this method.
A
D
F
B
H
I
E
C
G
Start
Finish
J
K
M
O
T
U
V
L
N
Q
S
P
R
Figure 15.27 The AON Project Network
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

16-1
Multiobjective Decision Making
C H A P T E R
EVALU ATING AND    P RIORITIZING 
PR   OJECTS A     T NASA
M
ore public pressure than ever before is on NASA to justify its choice of
projects to undertake. There is demand for accountability, pressure to
cut costs, and an increasing number of potential projects to choose from. In
the past, a committee of 15 members from NASA met once a year to review
the 30 to 50 proposals submitted by contractors and divisions with the
Kennedy Space Center. The five voting members (the decision makers, or
DMs) gave each proposal a score from 1 to 10, the scores were averaged
over the five DMs, and the top scoring proposals were selected until the
budget was exceeded. Because the process was viewed as intuitive, manage-
ment expressed concern about its subjectivity and consistency. It wanted to
replace this process with a more comprehensive and structured process.
Tavana (2003) describes the system he developed to meet these needs. He
calls it consensus-ranking organizational-support system (CROSS).
The selection of projects at NASA is clearly a multiobjective decision-
making problem. As Tavana describes, there are a number of stakeholders
for each project. Essentially, they are the different departments within
NASA—including Safety, Systems Engineering, Reliability, and others—and
each has its own criteria for a successful project. For example, Safety might
be concerned about eliminating the possibility of death or serious injury,
Systems Engineering might be concerned about eliminating reliance on iden-
tified obsolete technology, and Reliability might be concerned about increas-
ing the mean time between failures. CROSS uses AHP (Analytic Hierarchy
Process, discussed later in this chapter) to obtain the information each DM
© Nosepress | Dreamstime.com 
16
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

needs to obtain a score for each project. It then combines the DMs’ scores to get an
overall consensus ranking of projects. Finally, it uses this consensus ranking, along with
project costs and the overall budget, to select the projects to be funded.
More specifically, the system first asks each DM to use AHP to evaluate the impor-
tance of the various stakeholders. For example, one DM might give Safety an importance
weight of 0.5, whereas another might give Safety a weight of 0.4. In the next step, each
stakeholder is asked to use AHP to evaluate the importance of its various criteria. This
leads to a set of weights for each stakeholder-criterion combination. The stakeholders
are also asked to estimate the probability that each potential project will be successful in
satisfying each criterion. The system uses these probabilities to adjust the previous
weights. Next, all of the weights from AHP are used to calculate a project-success factor
for each project, as assessed by each DM, and these factors are used to obtain each
DM’s rankings of the projects. Finally, the system attempts to reach consensus in the
rankings using another (non-AHP) methodology.
The system is now being used successfully to select NASA projects. As a measure of
its perceived quality,71 projects were submitted during the first two years of implementa-
tion of CROSS.Using this system,the DMs chose 21 projects of the 71,and management
subsequently approved all 21 choices. ■
16-2 Chapter 16
Multiobjective Decision Making
16.1 INTRODUCTION
In many of your classes, you have probably discussed how to make good decisions.
Usually, you assume that the correct decision optimizes a single objective, such as profit
maximization or cost minimization. In most situations you encounter in business and life,
however, more than one relevant objective exists. For example, when you graduate, many
of you will receive several job offers. Which should you accept? Before deciding which
job offer to accept, you might consider how each job “scores” on several objectives, such
as salary, interest in work, quality of life in the city you will live in, and nearness to family.
In this situation, combining your multiple objectives into a single objective is difficult.
Similarly, in determining an optimal investment portfolio, you want to maximize expected
return, but you also want to minimize risk. How do you reconcile these conflicting objec-
tives? In this chapter, we discuss three tools, goal programming, trade-off curves, and the
Analytic Hierarchy Process, that decision makers can use to solve multi-objective prob-
lems. We show how to implement all three of these tools in a spreadsheet.
FUNDAMENTAL INSIGHT
Optimizing with Multiple Objectiv
es
When there are multiple objectives, you can proceed
in several fundamental ways. First, you can prioritize
your objectiv es. This is done in g oal pr ogramming,
where the highest priority objective is optimized first,
then the second, and so on. Second, you can optimize
one objective while constraining the others to be no
worse than specified values. This approach is used to
find trade-off cur ves between the objectiv es. Finally,
you can attempt to weight the objectives to measure
their importance relative to one another.This is the
approach taken b y the Analytic Hierarchy Process.
All of these a pproaches have their critics, but they
can all be used to mak e difficult decision pr oblems
manageable.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

16.2 GOAL PROGRAMMING
In many situations, a company wants to achieve several objectives. Given limited
resources, it may prove impossible to meet all objectives simultaneously. If the company
can prioritize its objectives, then goal programming can be used to make good decisions.
The following media selection problem is typical of the situations in which goal program-
ming is useful. This example presents a variation of the advertising model discussed in
Chapters 4 and 7.
16.2 Goal Programming
16-3
E X A M P L E
16.1 DETERMINING AN ADVERTISING SCHEDULE AT LEON BURNIT
T
he Leon Burnit Ad Agency is trying to determine a TV advertising schedule for a
client. The client has three goals (listed here in descending order of importance) con-
cerning whom it wants its ads to be seen by:
■
Goal 1: at least 65 million high-income men (HIM)
■
Goal 2: at least 72 million high-income women (HIW)
■
Goal 3: at least 70 million low-income people (LIP)
Burnit can purchase several types of TV ads: ads shown on live sports shows, on game
shows, on news shows, on sitcoms, on dramas, and on soap operas. At most $700,000 total
can be spent on ads. The advertising costs and potential audiences (in millions of viewers)
of a one-minute ad of each type are shown in Table 16.1. As a matter of policy, the client
requires that at least two ads each be placed on sports shows, news shows, and dramas.
Also, it requires that no more than 10 ads be placed on any single type of show. Burnit
wants to find the advertising plan that best meets its client’s goals.
Table 16.1
Data for the Advertising Example
Ad Type 
HIM
HIW
LIP
Cost 
Sports show
7
4
8
$120,000
Game show
3
5
6
$40,000
News
6
5
3
$50,000
Sitcom
4
5
7
$40,000
Drama
6
8
6
$60,000
Soap opera
3
4
5
$40,000
Objective
To use goal programming to meet the company’s goals of reaching various
target audiences as much as possible, while staying within an advertising budget.
WHERE DO THE NUMBERS COME FROM?
As in previous advertising models, the company needs to estimate the number of viewers
reached by each type of ad, and it needs to know the cost of each ad. Beyond this, however,
management determines the goals. They can set whatever goals they believe are in the
company’s best interests, and they can prioritize these goals.
Solution
The variables and constraints for this advertising model are shown in Table 16.2. Most of
this is the same as in optimization models in previous chapters. However, the objective is
not obvious, and the table includes “deviations from goals” and “balances for goals.” You
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

need to see how these fit into the goal programming methodology. You get there one step
at a time. You first check whether the company can meet all of its goals simultaneously. To
do so, set up a linear programming (LP) model with no objective. You simply want to see
whether any solution satisfies all of the constraints, including the goals.
DEVELOPING THE LP MODEL
The LP model that checks whether all goals can be met can be developed as follows. (See
Figure 16.1 and the LP Model sheet of the file Advertising Goals.xlsx.)
16-4 Chapter 16
Multiobjective Decision Making
Table 16.1
Variables and Constraints for the Advertising Model
Input variables
Advertising data (potential audiences and cost for each type of ad), 
advertising budget, goals (lower limits) on various target audiences
Decision variables 
Numbers of ads of various types, deviations from goals
(changing cells)
Objective (target cell)
Multiple (see text)
Other output cells
Total cost of ads, balances for goals
Constraints
Ads on sports shows  2
Ads on news shows  2
Ads on dramas  2
Ads on any type of show  10
Total cost of ads  Advertising budget
Meet goals as well as possible
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
J
I
H
G
F
E
D
C
B
A
LP model - possible to meet all goals?
Exposures to various groups per unit of adversing
Range names used:
Sports ad
Game show ad
News show ad
Sitcom ad
Drama ad
Soap opera ad
Budget
='LP Model'!$D$22
High-income men
7
3
6
4
6
3
Exposures
='LP Model'!$B$26:$B$28
High-income women
4
5
5
5
8
4
Goal
='LP Model'!$D$26:$D$28
Low-income people
8
6
3
7
6
5
Maximum_ads_allowed
='LP Model'!$B$19:$G$19
Minimum_ads_required
='LP Model'!$B$15:$G$15
P
L'=
d
e
s
a
h
cr
u
p
_
r
e
b
m
u
N
0
4
0
6
0
4
0
5
0
4
0
2
1
tin
u
/ts
o
C
 Model'!$B$17:$G$17
Total_cost
='LP Model'!$B$22
Adversing plan
Sports ad
Game show ad
News show ad
Sitcom ad
Drama ad
Soap opera ad
Minimum ads required
2
0
2
0
2
0
<=
<=
<=
<=
<=
<=
Number purchased
2.000
0.000
2.000
4.000
3.333
0.000
<=
<=
<=
<=
<=
<=
Maximum ads allowed
10
10
10
10
10
10
Budget constraint
Total 
t
e
g
d
u
B
ts
o
c
$700
<=
$700
Goals for numbers of exposures
la
o
G
s
e
r
u
s
o
p
x
E
High-income 
5
6
=
>
0
0
0.2
6
n
e
m
High-income 
2
7
=
>
7
6
6.4
6
n
e
m
o
w
Low-income 
0
7
=
>
0
0
0.0
7
elp
o
e
p
Note: All monetary values are in $1000s, and all 
exposures to ads are in millions of exposures. 
Use Solver, with no objecve, to 
see whether all 
constraints, including goals, can 
Figure 16.1
Feasibility of Meeting All Goals
1
Inputs. Enter all inputs in the blue ranges.
2
Numbers of ads. Enter any trial values for the numbers of ads in the Number_purchased
range.
3
Total cost. Calculate the total amount spent on ads in cell B22 with the formula
=SUMPRODUCT(B11:G11,Number_purchased)
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4
Exposures obtained. Calculate the number of people (in millions) in each group that
the ads reach in the Exposures range. Specifically, enter the formula
=SUMPRODUCT(B7:G7,Number_purchased)
in cell B26 for the HIM group, and copy this to the rest of the Exposures range for the other
two groups.
USING SOLVER
The completed Solver dialog box is shown in Figure 16.2. At this point, there is no objec-
tive to maximize or minimize. The goal at this point is to find any solution that meets all of
the constraints. When you click on Solve, you get the message that there is no feasible
solution because it is impossible to meet all of the client’s goals and stay within the budget.
To see how large the budget must be to meet all goals, you can run SolverTable with the
Budget cell as the single input cell, varied from 700 to 850, and any cells as the output
cells. (We chose the numbers of exposures cells as output cells.) The results appear in
Figure 16.3. They show that unless the budget is greater than $750,000, it is impossible to
meet all of the client’s goals.
16.2 Goal Programming
16-5
Figure 16.2
Solver Dialog Box
for Finding a
Feasible Solution
1
2
3
4
5
6
7
8
9
10
11
A
B
C
D
E
F
Oneway analysis for Solver model in LP Model worksheet
Budget (cell $D$22) values along side, output cell(s) along top
Exposures_1
Exposures_2
Exposures_3
$700 Not feasible
$725 Not feasible
$750 Not feasible
$775
65.000
72.000
70.000
$800
65.000
72.000
70.000
$825
65.000
72.000
70.000
$850
65.000
72.000
70.000
Figure 16.3
Checking How 
Large the Budget
Must Be
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Now that you know that a $700,000 budget is not sufficient to meet all of the client’s
goals, you can use goal programming to see how close Burnit can come to these goals. First,
we introduce some terminology. The upper limits and lower limits on the ads of each type
and the budget constraints are considered hard constraints in this model. This means that
they cannot be violated under any circumstances. The goals on exposures, on the other hand,
are considered soft constraints. The client certainly wants to satisfy these goals but is will-
ing to come up somewhat short—in fact, it must because of the limited budget. In goal pro-
gramming models, the soft constraints are prioritized. You first try to satisfy the goals with
the highest priority (in this case, HIM exposures). If there is still any room to maneuver, you
then try to satisfy the goals with the next highest priority (HIW exposures). If there is still
room to maneuver, you move on to the goals with the third highest priority, and so on.
DEVELOPING THE GOAL PROGRAMMING MODEL
In general, goal programming requires several consecutive Solver runs, one for each pri-
ority level. However, the model can be set up so that you can make these consecutive runs
with only minor modifications from one run to the next. The procedure is illustrated in
Figure 16.4. (See the GP Model sheet of the file Advertising Goals.xlsx.) To develop this
model, first make a copy of the original LP Model sheet shown earlier in Figure 16.1. Then
modify it using the following steps:
16-6 Chapter 16
Multiobjective Decision Making
Hard constraints
must be satisfied. Soft
constraints can be
violated to some
extent. In goal pro-
gramming, the soft con-
straints are prioritized.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
J
I
H
G
F
E
D
C
B
A
Goal programming model
Exposures to various groups per unit of adversing
Range names used:
Sports ad
Game show ad
News show ad
Sitcom ad
Drama ad
Soap opera ad
Already_obtained
='GP Model'!$D$32:$D$34
High-income men
7
3
6
4
6
3
Amt_over_goal
='GP Model'!$D$26:$D$28
High-income women
4
5
5
5
8
4
Amt_under_goal
='GP Model'!$C$26:$C$28
Low-income people
8
6
3
7
6
5
Balance
='GP Model'!$E$26:$E$28
Budget
='GP Model'!$D$22
P
G
'=
r
e
d
n
u
_
n
oit
aiv
e
D
0
4
0
6
0
4
0
5
0
4
0
2
1
tin
u
/ts
o
C
 Model'!$B$32:$B$34
Exposures
='GP Model'!$B$26:$B$28
Adversing plan
Goal
='GP Model'!$G$26:$G$28
Sports ad
Game show ad
News show ad
Sitcom ad
Drama ad
Soap opera ad
HIM_deviaon
='GP Model'!$B$32
Minimum ads required
2
0
2
0
2
0
HIW_deviaon
='GP Model'!$B$33
<=
<=
<=
<=
<=
<=
LIP_deviaon
='GP Model'!$B$34
Number purchased
2.000
0.000
5.000
2.250
2.000
0.000
Maximum_ads_allowed
='GP Model'!$B$19:$G$19
<=
<=
<=
<=
<=
<=
Minimum_ads_required
='GP Model'!$B$15:$G$15
Maximum ads allowed
10
10
10
10
10
10
Number_purchased
='GP Model'!$B$17:$G$17
Total_cost
='GP Model'!$B$22
Budget constraint
Total 
t
e
g
d
u
B
ts
o
c
$700
<=
$700
Goals for numbers of exposures
Exposures Amt under goal
Amt over 
la
o
G
e
c
n
ala
B
la
o
g
High-income men
65.000
0
0
65.000
=
65
High-income women
60.250
11.75
0
72.000
=
72
Low-income people
58.750
11.25
0
70.000
=
70
Deviaons from goals (amounts below goals, or 0 if currently meeng goal)
Deviaon under
Already obtained
HIM deviaon
0.000
<=
65.000
HIW deviaon
11.750
<=
72.000
LIP deviaon
11.250
<=
70.000
Note: All monetary values are in $1000s, and all 
exposures to ads are in millions of exposures. 
Inially, enter large values in these cells 
(such as the original goals). Then, as high 
priority goals are met or parally 
met, enter the actual deviaons obtained 
here (one at a me).
Figure 16.4
Minimizing Deviation for Highest Priority (HIM) Goal
1
New changing cells.
The exposure constraints are no longer shown as hard con-
straints. Instead, you need to introduce changing cells in the Amt_under_goal and
Amt_over_goal ranges to indicate the amounts under or over each goal. These are the
“deviations from goals” mentioned in Table 16.2. Enter any values in these ranges. (We
entered 0s to get started.) Note that in the Solver solution, at least one of these two types of
deviations will always be 0 for each goal—the solution will either be below the goal or
above the goal, but not both.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

2
Balance equations. To tie these new changing cells to the rest of the model, you cre-
ate “balances” in column E that must logically equal the goals in column G. To do this, enter
the formula
=B26+C26-D26
in cell E26 and copy it down. The balance equation for each group specifies that the actual
number of exposures, plus the number under the goal, minus the number over the goal, must
equal the goal.
3
Constraints on de viations under. The client is concerned only with too few expo-
sures, not with too many. Therefore, you should set up constraints on the “under” deviations
in rows 32 to 34. On the left side, in column B, enter links to the Amt_under_goals range by
entering the formula
=C26
in cell B32 and copying down.
4
Highest priority goal. The first Solver run tries to achieve the highest priority goal
(HIM exposures). To do so, you should minimize cell B32, the amount under the HIM goal.
Do this as shown in Figure 16.4. Then set up the Solver dialog box as shown in Figure 16.5.
The constraints include the hard constraints, the balance constraint, and the Deviation_under
 Already_obtained constraint. Note that the goals themselves have been entered in the
Already_obtained range. Therefore, the Deviation_under  Already_obtained constraint at
this point is essentially redundant—the “under” deviations cannot possibly be greater than
the goals themselves. This constraint is included because it becomes important in later
Solver runs, which then require only minimal modifications. The solution from this Solver
run is shown in Figure 16.4. It shows that Burnit can satisfy the HIM goal completely.
However, the other two goals are not satisfied because their “under” deviations are positive.
16.2 Goal Programming
16-7
Figure 16.5
Solver Dialog Box 
for the Highest
Priority Goal
The deviations are the
key to goal program-
ming.They indicate
how far below or 
above the goals the
current solution is.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

5
Second highest priority goal. Now we come to the key aspect of goal programming.
After a high priority goal is satisfied as fully as possible, you move on to the next highest
priority goal. However, you do not want to lose what you already gained with the high pri-
ority goal. Therefore, constrain its under deviation to be no greater than what has already
been achieved. In this case, a deviation of 0 was already achieved in step 4, so enter 0 in cell
D32 for the upper limit of the HIM under deviation. Then run Solver again, changing only
one thing in the Solver dialog box—make cell B33 the target cell. Effectively, you are con-
straining the under deviation for the HIM group to remain at 0, and then minimizing the
under deviation for the HIW group. The solution from this second Solver run appears in
Figure 16.6. As promised, the HIM goal has not suffered at all, but the solution is now a lit-
tle closer to the HIW goal than before. It was under by 11.75 before, and now it is under by
only 11. The lowest priority goal (for the LIP group) essentially comes along for the ride in
this step; it could either improve or get worse. It happened to get worse, moving from under
by 11.25 to under by 18.
16-8 Chapter 16
Multiobjective Decision Making
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
J
I
H
G
F
E
D
C
B
A
Goal programming model
Exposures to various groups per unit of adversing
Range names used:
Sports ad
Game show ad
News show ad
Sitcom ad
Drama ad
Soap opera ad
Already_obtained
='GP Model'!$D$32:$D$34
High-income men
7
3
6
4
6
3
Amt_over_goal
='GP Model'!$D$26:$D$28
High-income women
4
5
5
5
8
4
Amt_under_goal
='GP Model'!$C$26:$C$28
Low-income people
8
6
3
7
6
5
Balance
='GP Model'!$E$26:$E$28
Budget
='GP Model'!$D$22
P
G
'=
r
e
d
n
u
_
n
oit
aiv
e
D
0
4
0
6
0
4
0
5
0
4
0
2
1
tin
u
/ts
o
C
 Model'!$B$32:$B$34
Exposures
='GP Model'!$B$26:$B$28
Adversing plan
Goal
='GP Model'!$G$26:$G$28
Sports ad
Game show ad
News show ad
Sitcom ad
Drama ad
Soap opera ad
HIM_deviaon
='GP Model'!$B$32
Minimum ads required
2
0
2
0
2
0
HIW_deviaon
='GP Model'!$B$33
<=
<=
<=
<=
<=
<=
LIP_deviaon
='GP Model'!$B$34
Number purchased
2.000
0.000
5.000
0.000
3.500
0.000
Maximum_ads_allowed
='GP Model'!$B$19:$G$19
<=
<=
<=
<=
<=
<=
Minimum_ads_required
='GP Model'!$B$15:$G$15
Maximum ads allowed
10
10
10
10
10
10
Number_purchased
='GP Model'!$B$17:$G$17
Total_cost
='GP Model'!$B$22
Budget constraint
Total 
t
e
g
d
u
B
ts
o
c
$700
<=
$700
Goals for numbers of exposures
Exposures Amt under goal
Amt over 
la
o
G
e
c
n
ala
B
la
o
g
High-income men
65.000
0
0
65.000
=
65
High-income women
61.000
11
0
72.000
=
72
Low-income people
52.000
18
0
70.000
=
70
Deviaons from goals (amounts below goals, or 0 if currently meeng goal)
Deviaon under
Already obtained
HIM deviaon
0.000
<=
0.000
HIW deviaon
11.000
<=
72.000
LIP deviaon
18.000
<=
70.000
Note: All monetary values are in $1000s, and all 
exposures to ads are in millions of exposures. 
Inially, enter large values in these cells 
(such as the original goals). Then, as high 
priority goals are met or parally 
met, enter the actual deviaons obtained 
here (one at a me).
Figure 16.6
Minimizing Deviation for Second Priority Goal
6
Lowest priority goal. You can probably guess the last step by now. You minimize cell
B34, the deviation for the LIP group, while ensuring that the two higher priority goals
are achieved as fully as in steps 4 and 5. As the model is set up, only two changes are
necessary—enter 11 in cell D33 and change the Solver objective cell to cell B34. When you
run Solver this time, however, you will find no room left to maneuver. The solution remains
exactly the same as in Figure 16.6. This occurs frequently in goal programming models.
After satisfying the first goal or two as fully as possible, there is often no room to improve
later goals.
Discussion of the Solution
To summarize Burnit’s situation, the budget of $700,000 allows it to satisfy the client’s
HIM goal, miss the HIW goal by 11 million, and miss the LIP goal by 18 million. Given
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

the priorities on these three goals, this is the best possible solution. Note that all of the hard
constraints are satisfied, as they must be. For example, no more than 10 ads of any type are
used, and the budget is not exceeded. Note also that the amounts over the goals are all 0.
This is not guaranteed to happen, but it did in this example.
Sensitivity Analysis
Sensitivity analysis should be a part of goal programming just as it is for previous mod-
els we have discussed. However, there is no quick way to do it. SolverTable works on
only a single objective, whereas goal programming requires a sequence of objectives.
Therefore, if you want to see how the solution to Burnit’s model changes with different
budgets, say, you need to go through the preceding steps several times and keep track of
the results manually. This is certainly possible, but it is tedious.
Effect of Changing Priorities
With three goals, six orderings of the goals are possible. The goal programming solutions
corresponding to these orderings are listed in Figure 16.7. Row 4 corresponds to the order-
ing used in the example. Clearly, the solution can change if the priorities of the goals
change. For example, if you give the HIW goal the highest priority (rows 6 and 7), none of
the goals is achieved completely. (Problem 1 asks you to verify the details.)
16.2 Goal Programming
16-9
1
2
3
4
5
6
7
8
9
A
B
C
D
E
F
G
H
I
J
K
L
Results from changing priories
Priority 1
Priority 2
Priority 3
HIM deviaon HIW deviaon LIP deviaon Sports ad Game show ad News show ad
Sitcom ad Drama ad Soap opera ad
HIM
HIW
LIP
0
11
18
2
0
5
0
3.5
0
HIM
LIP
HIW
0
11.75
11.25
2
0
5
2.25
2
0
HIW
HIM
LIP
3
6
12
2
0
2
0
6
0
HIW
LIP
HIM
3
6
12
2
0
2
0
6
0
LIP
HIM
HIW
1.956
9.304
0
2
0
3.043
4.696
2
0
LIP
HIW
HIM
3
7.333
0
2
0
2
4
3.333
0
Figure 16.7 Effect of Changing Priorities
1.
The results for the Burnit model are based on allowing the numbers of ads to have
noninteger values. They could easily be constrained to integer values, and the solution
method would remain exactly the same. However, the goals might not be met as fully
as before because of the extra integer constraints.
2.
Each priority level in the Burnit model contains exactly one goal. It is easy to general-
ize to the case where a given priority level can have multiple goals, each modeled with
a certain deviation from a target. When you run Solver for this priority level, you use a
weighted average of these deviations as the objective to minimize, where the decision
maker can choose appropriate weights.
3.
All of the deviations in the objectives of the Burnit model are under deviations. However,
it is certainly possible to include over deviations as objectives. For example, if the budget
constraint were treated as a soft constraint, you would try to minimize its over deviation
to stay as little over the budget as possible. It is even possible for both the under and over
deviations of some goal to be included as objectives. This occurs in situations where you
want to come as close as possible to some target value—neither under nor over.
MODELING ISSUES
■
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

4.
The use of changing cells for the under and over deviations might not be intuitive, but it
serves two purposes. First, it provides exactly the information needed for the objectives
in goal programming. Second, it keeps the model linear. If you used an IF function
instead (without the under and over cells) to capture the under deviations, the model
would be nonlinear and nonsmooth, and Evolutionary Solver would be necessary. ■
16-10 Chapter 16
Multiobjective Decision Making
P R O B L E M S
Solutions for problems whose numbers appear within a
colored box can be found in the Student Solutions Files.
Refer to this book’s preface for purchase information.
Skill-Building Problems
1.
For each set of priorities of goals, solve the Burnit
problem and verify that the values in Figure 16.7 are
correct.
2.
Gotham City must determine how to allocate ambu-
lances during the next year. It costs $5000 per year to
run an ambulance. Each ambulance must be assigned
to one of two districts. Let xi be the number of ambu-
lances assigned to district i, i  1, 2. The average time
(in minutes) it takes for an ambulance to respond to a
call from district 1 is 40  3x1; for district 2, the time
is 50  4x2. Gotham City has three goals (listed in
order of priority):
■
Goal 1: At most $100,000 per year should be spent
on ambulance service.
■
Goal 2: Average response time in district 1 should
be at most five minutes.
■
Goal 3: Average response time in district 2 should
be at most five minutes.
a. Use goal programming to determine how many
ambulances to assign to each district.
b. How does your answer change if goal 2 has
the highest priority, then goal 3, and then goal 1?
3.
Fruit Computer Company is ready to make its annual
purchase of computer chips. Fruit can purchase chips
(in lots of 100) from three suppliers. Each chip’s qual-
ity is rated as excellent, good, or mediocre. During the
coming year, Fruit needs 5000 excellent chips, 3000
good chips, and 1000 mediocre chips. The characteris-
tics of the chips purchased from each supplier are
shown in the file P16_03.xlsx. Each year, Fruit has
budgeted $28,000 to spend on chips. If Fruit does not
obtain enough chips of a given quality, it can special-
order additional chips at $10 per excellent chip, $6 per
good chip, and $4 per mediocre chip. Fruit assesses a
penalty of $1 for each dollar it goes over the annual
budget (in payments to suppliers). Determine how Fruit
can minimize the penalty associated with meeting the
annual chip requirements. Also use goal programming
to determine a purchasing strategy. Let the budget con-
straint have the highest priority, followed in order by the
restrictions on excellent, good, and mediocre chips.
4.
Hiland Appliance must determine how many TVs and
Blu-Ray disc players to stock. It costs Hiland $1000 to
purchase a TV and $400 to purchase a Blu-Ray player.
A TV requires three square yards of storage space, and
a Blu-ray disc player requires one square yard. The sale
of a TV earns Hiland a profit of $150, and each Blu-ray
disc player sale earns a profit of $100. Hiland has set
the following goals (listed in order of importance):
■
Goal 1: A maximum of $60,000 can be spent on
purchasing TVs and Blu-ray disc players.
■
Goal 2: Highland should earn at least $7,000 profit
from the sale of TVs and Blu-ray disc players.
■
Goal 3: TVs and Blu-ray disc players should not
use up more than 200 square yards of storage
space.
Use a goal programming model to determine how
many TVs and Blu-ray disc players Hiland should
order. How can you modify the model if Hiland’s
second goal is to have a profit of exactly $7,000?
5.
Each week, Stockco produces two products. Relevant
information for each product is shown in the file
P16_05.xlsx. Stockco has a goal of $4800 in weekly
profit and incurs a $1 penalty for each dollar it falls
short of this goal. A total of 3200 hours of labor are
available. A $2 penalty is incurred for each hour of
overtime (labor over 3200 hours) used, and a $1
penalty is incurred for each hour of available labor that
is unused. Marketing considerations require that at
least 700 units of product 1 be produced and at least
1000 units of product 2 be produced. For each unit
(of either product) by which production falls short of
demand, a penalty of $5 is assessed.
a. Determine how to minimize the total penalty
incurred by Stockco.
b. Suppose the company sets (in order of importance)
the following goals:
■
Goal 1: Make the required profit.
■
Goal 2: Avoid underuse of labor.
■
Goal 3: Meet demand for product 1.
■
Goal 4: Meet demand for product 2.
■
Goal 5: Do not use any overtime.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Use goal programming to determine an optimal pro-
duction schedule.
6.
Based on Steuer (1984). Deancorp produces sausage
by blending beef head, pork chuck, mutton, and water.
The cost per pound, fat per pound, and protein per
pound for these ingredients are listed in the file
P16_06.xlsx. Deancorp needs to produce 1000 pounds
of sausage and has set the following goals, listed in
order of priority:
■
Goal 1: Sausage should consist of at least 15%
protein.
■
Goal 2: Sausage should consist of at most 8% fat.
■
Goal 3: Cost per pound of sausage should not
exceed $0.06.
Use a goal programming model to determine the com-
position of sausage.
7.
Based on Welling (1977). The Touche Young account-
ing firm must complete three jobs during the next
month. Job 1 will require 500 hours of work, job 2
will require 300 hours, and job 3 will require 100
hours. At present, the firm consists of five partners, 
five senior employees, and five junior employees, each
of whom can work up to 40 hours per week. The dol-
lar amount (per hour) that the company can bill
depends on the type of accountant assigned to each
job, as shown in the file P16_07.xlsx. (The “X” indi-
cates that a junior employee does not have enough
experience to work on job 1.) All jobs must be com-
pleted. Touche Young has also set the following goals,
listed in order of priority:
■
Goal 1: Monthly billings should exceed $74,000.
■
Goal 2: At most one partner should be hired.
■
Goal 3: At most three senior employees should be
hired.
■
Goal 4: At most one junior employee should be
hired.
Use goal programming to help Touche solve its problem.
8.
There are four teachers in the Faber College Business
School. Each semester, 200 students take each of the
following courses: Marketing, Finance, Production,
and Statistics. The “effectiveness” of each teacher in
teaching each course is given in the file P16_08.xlsx.
Each teacher can teach a total of 200 students during
the semester. The dean has set a goal of obtaining an
average teaching effectiveness level of at least 6 in
each course. Deviations from this goal in any course
are considered equally important. Determine the
semester’s teaching assignments.
9.
The city of Bloomington has 17 neighborhoods. The
number of high school students in each neighborhood
and the time required to drive from each neighborhood
to each of the city’s two high schools (North and
South) are listed in the file P16_09.xlsx. The
Bloomington Board of Education needs to determine
16.2 Goal Programming
16-11
how to assign students to high schools. All students in
a given neighborhood must be assigned to the same
high school. The Board has set (in order of priority,
from highest to lowest) the following goals:
■
Goal 1: Ensure that the difference in enrollment at
the two high schools differs by at most 50.
■
Goal 2: Ensure that average student travel time is at
most 13 minutes.
■
Goal 3: Ensure that at most 4% of the students
must travel at least 25 minutes to school.
a. Determine an optimal assignment of students to
high schools.
b. If the enrollment at the two high schools can differ
by at most 100 (a change in goal 1), how does your
answer change?
Skill-Extending Problems
10. Based on Lee and Moore (1974). Faber College is
admitting students for the class of 2007. Data on its
applicants are shown in the file P16_10.xlsx. Each row
indicates the number of in-state or out-of-state appli-
cants with a given SAT score who plan to be business
or nonbusiness majors. For example, 1900 of its in-
state applicants have a 700 SAT score, and 1500 of
these applicants plan to major in business. Faber has
set four goals for this class, listed in order of priority:
■
Goal 1: The entering class should include at least
5000 students.
■
Goal 2: The entering class should have an average
SAT score of at least 640.
■
Goal 3: The entering class should consist of at least
25% out-of-state students.
■
Goal 4: At least 2000 members of the entering
class should not be business majors.
Use goal programming to determine how many appli-
cants of each type to admit. Assume that all applicants
who are admitted will decide to attend Faber.
11. During the next four quarters, Wivco faces the follow-
ing demands for globots: quarter 1, 13; quarter 2, 14;
quarter 3, 12; quarter 4, 15. Globots can be produced
by regular-time labor or by overtime labor. Production
capacity (number of globots) and production costs
during the next four quarters are shown in the file
P16_11.xlsx. Wivco has set the following goals in
order of importance:
■
Goal 1: Each quarter’s demand should be met on
time.
■
Goal 2: Inventory at the end of each quarter should
not exceed three units.
■
Goal 3: Total production cost should be no greater
than $250.
Use a goal programming model to determine Wivco’s
production schedule for the next four quarters.
Assume that at the beginning of the first quarter, one
globot is in inventory.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

12. Lucy’s Music Store at present employs five full-time
employees and three part-time employees. The normal
workload is 40 hours per week for full-time employees
and 20 hours per week for part-time employees. Each
full-time employee is paid $6 per hour for work up to
40 hours per week and can sell five recordings per
hour. A full-time employee who works overtime is paid
$10 per hour. Each part-time employee is paid $3 per
hour and can sell three recordings per hour. It costs
Lucy $6 to buy a recording, and each recording sells
for $9. Lucy has weekly fixed expenses of $500. She
has established the following weekly goals, in order of
priority:
■
Goal 1: Sell at least 1600 recordings per week.
■
Goal 2: Earn a profit of at least $2200 per week.
■
Goal 3: Full-time employees should work at most
100 hours of overtime.
■
Goal 4: To promote a sense of job security, the
number of hours by which each full-time employee
fails to work 40 hours should be minimized.
Use a goal programming model to determine how
many hours per week each employee should work.
13. Based on Taylor and Keown (1984). Gotham City is
trying to determine the type and location of recre-
ational facilities to build during the next decade. Four
types of facilities are under consideration: golf
courses, swimming pools, gymnasiums, and
tennis courts. Six sites are under consideration. If a
golf course is built, it must be built at either site 1 or
site 6. Other facilities can be built at sites 2 through
5. The amounts of available land (in thousands of
square feet) at sites 2 through 5 are given in the file
P16_13.xlsx. The cost of building each facility (in
thousands of dollars), the annual maintenance cost (in
thousands of dollars) for each facility, and the land
(in thousands of square feet) required for each facility
are also given in the same file. The number of user-days
(in thousands) for each type of facility, also shown in
this file, depends on where it is built.
a. Consider the following set of priorities:
■
Priority 1: The amount of land used at each site
should be no greater than the amount of land
available.
■
Priority 2: Construction costs should not exceed
$1.2 million.
■
Priority 3: User-days should exceed 200,000.
■
Priority 4: Annual maintenance costs should not
exceed $200,000.
For this set of priorities, use goal programming to
determine the type and location of recreation facili-
ties in Gotham City.
b. Consider the following set of priorities:
■
Priority 1: The amount of land used at each site
should be no greater than the amount of land
available.
16-12 Chapter 16
Multiobjective Decision Making
■
Priority 2: User-days should exceed 200,000.
■
Priority 3: Construction costs should not exceed
$1.2 million.
■
Priority 4: Annual maintenance costs should not
exceed $200,000.
For this set of priorities, use goal programming to
determine the type and location of recreation facili-
ties in Gotham City.
14. A small aerospace company is considering eight
projects:
■
Project 1: Develop an automated test facility.
■
Project 2: Bar code all inventory and machinery.
■
Project 3: Introduce a CAD/CAM system.
■
Project 4: Buy a new lathe and deburring system.
■
Project 5: Institute an FMS (Flexible
Manufacturing System).
■
Project 6: Install a LAN (Local Area Network).
■
Project 7: Develop an AIS (Artificial Intelligence
Simulation).
■
Project 8: Set up a TQM (Total Quality
Management) program.
Each project has been rated on five attributes: return
on investment (ROI), cost, productivity improvement,
workforce requirements, and degree of technological
risk. These ratings are given in the file P16_14.xlsx.
The company has set the following five goals (listed in
order of priority):
■
Goal 1: Achieve an ROI of at least $3250.
■
Goal 2: Limit cost to $1300.
■
Goal 3: Achieve a productivity improvement of at
least 6.
■
Goal 4: Limit workforce use to 108.
■
Goal 5: Limit technological risk to a total of 4.
Use goal programming to determine which projects
should be undertaken.
15. A new president has just been elected and has set the
following economic goals (listed from highest to
lowest priority):
■
Goal 1: Balance the budget (this means revenues
are at least as large as costs).
■
Goal 2: Cut spending by at most $150 billion.
■
Goal 3: Raise at most $550 billion in taxes from
the upper class.
■
Goal 4: Raise at most $350 billion in taxes from
the lower class.
Currently the government spends $1 trillion per year.
Revenue can be raised in two ways: through a gas tax
and through an income tax. You must determine G, the
per-gallon tax rate (in cents); T1, the tax rate charged
on the first $30,000 of income; T2, the tax rate charged
on any income earned over $30,000; and C, the cut in
spending (in billions). If the government chooses G,
T1, and T2, then we assume that the revenue given in
the file P16_15.xlsx (in billions of dollars) is raised.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Of course, the tax rate on income over $30,000 must
be at least as large as the tax rate on the first $30,000
of income. Use goal programming to help the
president meet his goals.
16. The HAL computer must determine which of eight
research and development (R&D) projects to undertake.
For each project, four quantities are of interest: (1) the
net present value (NPV, in millions of dollars) of the
project; (2) the annual growth rate in sales generated
by the project; (3) the probability that the project will
succeed; and (4) the cost (in millions of dollars) of the
project. The relevant information is given in the file
P16_16.xlsx. HAL has set the following four goals:
■
Goal 1: The total NPV of all chosen projects
should be at least $200 million.
■
Goal 2: The average probability of success for all
projects chosen should be at least 0.75.
■
Goal 3: The average growth rate of all projects
chosen should be at least 15%.
■
Goal 4: The total cost of all chosen projects should
be at most $1 billion.
For the following sets of priorities, use (integer) goal
programming to determine the projects that should be
selected.
a. Goal 2, Goal 4, Goal 1, Goal 3.
b. Goal 1, Goal 3, Goal 4, Goal 2.
17. Based on Klingman and Phillips (1984). The Marines
need to fill three types of jobs in two cities (Los
Angeles and Chicago). The numbers of jobs of each
type that must be filled in each city are shown in the
file P16_17.xlsx. The Marines available to fill these
jobs have been classified into six groups according to
the types of jobs each person is capable of doing, the
16.3 Pareto Optimality and Trade-off Curves
16-13
type of job each person prefers, and the city in which
each person prefers to live. The data for each of these
six groups are also listed in this file. The Marines have
the following three goals, listed from highest priority
to lowest priority:
■
Goal 1: Ensure that all jobs are filled by qualified
workers.
■
Goal 2: Ensure that at least 8000 employees are
assigned to the jobs they prefer.
■
Goal 3: Ensure that at least 8000 employees are
assigned to their preferred cities.
Determine how the Marines should assign their work-
ers. (Note: You may allow fractional assignments of
workers.)
18. Based on Vasko et al. (1987). Bethlehem Steel can fill
orders using five different types of steel molds. Up to
three different molds of each type can be purchased.
Each individual mold can be used to fill up to 100
orders per year. Six different types of orders must be
filled during the coming year. The waste (in tons)
incurred if a type of mold is used to fill an order is
shown in the file P16_18.xlsx (where an “x” indicates
that a type of mold cannot be used to fill an order).
The number of each order type that must be filled
during the coming year is also shown in this file.
Bethlehem Steel has the following two goals, listed
in order of priority.
■
Goal 1: Because molds are very expensive,
Bethlehem wants to use at most five molds.
■
Goal 2: Bethlehem wants to have at most 600 tons
of total waste.
Use goal programming to determine how Bethlehem
should fill the coming year’s orders.
16.3 PARETO OPTIMALITY AND TRADE-OFF CURVES
In a multiobjective problem with no uncertainty, it is common to search for Pareto optimal
solutions. We assume that the decision maker has exactly two objectives and that the set of
feasible points under consideration must satisfy a prescribed set of constraints.
First, we need to define some terms. A solution (call it A) to a multiobjective problem
is called Pareto optimal if no other feasible solution is at least as good as A with respect to
every objective and strictly better than A with respect to at least one objective. A related
concept is domination. A feasible solution B dominates a feasible solution A to a multi-
objective problem if B is at least as good as A on every objective and is strictly better than
A on at least one objective. From this definition, it follows that Pareto optimal solutions are
feasible solutions that are not dominated.
If the “score” of all Pareto optimal solutions is graphed in the x–y plane with the x-axis
score being the score on objective 1 and the y-axis score being the score on objective 2, the
graph is called a trade-off curve. It is also called the efficient frontier. To illustrate, sup-
pose that the set of feasible solutions for a multiobjective problem is the shaded region
bounded by the curve AB and the axes in Figure 16.8. If the goal is to maximize both
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

objectives 1 and 2, then the curve AB is the set of Pareto optimal points. All points below
the AB curve are dominated by points on the curve.
As another illustration, suppose the set of feasible solutions for a multiple-objective
problem is all shaded points in the first quadrant bounded from below by the curve AB in
Figure 16.9. If the goal is to maximize objective 1 and minimize objective 2, then the curve
AB is the set of Pareto optimal points. In this case, all points to the left of the curve are
dominated by points on the curve.
Finding a Trade-off Curve
To find a trade-off curve, you can proceed according to the following steps.
1.
Choose an objective, say objective 1, and determine its best attainable value V1. For
the solution attaining V1, find the value of objective 2 and label it V2. Then (V1, V2) is
a point on the trade-off curve.
2.
For values V of objective 2 that are better than V2, solve the optimization problem in
step 1 with the additional constraint that the value of objective 2 is at least as good as
V. Varying V (over values of V preferred to V2) yields other points on the trade-off
curve.
3.
Step 1 located one endpoint of the trade-off curve. Now determine the best value
of objective 2 that can be attained, to obtain the other endpoint of the trade-off 
curve.
We illustrate the concept of Pareto optimality (and how to determine Pareto optimal
solutions) with the following example.
16-14 Chapter 16
Multiobjective Decision Making
Dominated 
solutions
Objective 1
Objective 2
B
A
Figure 16.8
Trade-off Curve for
Maximizing Two
Objectives
Dominated 
solutions
Objective 1
Objective 2
B
A
Figure 16.9
Trade-off Curve
for Maximizing
Objective 1 and
Minimizing 
Objective 2
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Objectives
To find the trade-off curve between pollution and profit by solving a number
of LP problems.
WHERE DO THE NUMBERS COME FROM?
The required data here is basically the same as in the product mix problems from Chapter 3.
Of course, the company also needs to find how much pollution each product is responsible
for, which requires some scientific investigation.
Solution
The model itself is a straightforward version of the product mix models from Chapter 3.
The objective is to find the product mix that stays within the lower and upper production
limits, uses no more labor or raw material than are available, keeps pollution low, and
keeps profit high. None of the formulas in the spreadsheet model (see Figure 16.10 and the
file Pollution Tradeoff.xlsx) presents anything new, so we focus instead on the solution
procedure.
Referring to the general three-step procedure for finding the trade-off curve, let profit
be objective 1 and pollution be objective 2. To obtain one endpoint of the curve (step 1),
you maximize profit and ignore pollution. That is, you maximize the Profit cell and delete
the constraint indicated in row 26 from the Solver dialog box. You can check that the solu-
tion has profit $20,089 and pollution level 9005.1 (This is not the solution shown in the fig-
ure.) At the other end of the spectrum (step 3), you minimize the pollution in cell B26 and
ignore any constraint on profit. You can check that this solution has pollution level 3560
and profit $8360. In other words, profit can get as high as $20,089 by ignoring pollution or
as low as $8360, and pollution can get as low as 3560 or as high as 9005. These establish
the extremes. Now you can search for points in between (step 2).
16.3 Pareto Optimality and Trade-off Curves
16-15
E X A M P L E
16.2 MAXIMIZING PROFIT AND MINIMIZING POLLUTION AT CHEMCON
C
hemcon plans to produce eight products. The profit per unit, the labor and raw mater-
ial used per unit produced, and the pollution emitted per unit produced are given in
Table 16.3. This table also includes lower and upper limits on production that Chemcon
has imposed. Currently 1300 labor hours and 1000 units of raw material are available.
Chemcon’s two objectives are to maximize profit and minimize pollution produced.
Chemcon wants to graph the trade-off curve for this problem.
Table 16.3 Data for the Chemcon Example
Product
1
2
3
4
5
6
7
8
Labor hrs/unit
5
5
1
4
3.5
4
2
3.5
Raw material/unit
3
4.5
5
5
4.5
2
3.5
3
Pollution/unit
25
29
35
26
17
25
28
6
Profit/unit
53
69
73
69
51
49
71
40
Min production
0
30
0
10
20
50
30
0
Max production
190
110
140
140
190
190
110
150
Get the two extreme
points on the trade-
off curve by maximiz-
ing profit, ignoring
pollution, and then
minimizing pollution,
ignoring profit.
1Actually, this is not quite true, as one user pointed out. If you maximize profit and ignore pollution, the result-
ing pollution level is 8980. To find the maximum possible pollution level, you need to maximize pollution. The
resulting pollution level is 9005. Surprisingly, the profit from this solution is less than the maximum profit,
$20,089.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Fortunately, SolverTable is the perfect tool. According to step 2, you need to con-
strain pollution to various degrees and see how large profit can be. This is indicated in
Figure 16.10, where the objective is to maximize profit with an upper limit on pollution.
(You could get the same effect by minimizing pollution and putting a lower limit on profit.)
The only upper limits on pollution you need to consider are those between the extremes,
3560 and 9005. Therefore, you can use SolverTable with the setup shown in Figure 16.11.
Note that we have used the option to enter nonequally spaced inputs: 3560, 4000, 4500,
16-16 Chapter 16
Multiobjective Decision Making
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
L
K
J
I
H
G
F
E
D
C
B
A
Chemcon proﬁt versus polluon model
Input data
Range names used:
6
2
$
B
$
!le
d
o
M
=
n
oit
ullo
p
_la
u
tc
A
8
7
6
5
4
3
2
1
tc
u
d
o
r
P
Labor hours/unit
5
5
1
4
3.5
4
2
3.5
Max_producon
=Model!$B$17:$I$17
Raw material/unit
3
4.5
5
5
4.5
2
3.5
3
Min_producon
=Model!$B$13:$I$13
Polluon_upper_bound
=Model!$D$26
Polluon/unit
25
29
35
26
17
25
28
6
Proﬁt
=Model!$B$29
2
2
$
D
$:1
2
$
D
$
!le
d
o
M
=
elb
alia
v
a
_
s
e
cr
u
o
s
e
R
0
4
$
1
7
$
9
4
$
1
5
$
9
6
$
3
7
$
9
6
$
3
5
$
tin
u
/tif
o
r
P
Resources_used
=Model!$B$21:$B$22
Producon plan
Units_produced
=Model!$B$15:$I$15
8
7
6
5
4
3
2
1
tc
u
d
o
r
P
Min producon
0
30
0
10
20
50
30
0
<=
<=
<=
<=
<=
<=
<=
<=
Units produced
0.0
30.0
0.0
10.0
21.1
50.0
48.6
150.0
<=
<=
<=
<=
<=
<=
<=
<=
Max producon
190
110
140
140
190
190
110
150
Constraints on resources
Resources used
Resources available
Labor hours
1086.0
<=
1300
Raw material
1000.0
<=
1000
Constraint on polluon
Actual polluon
Polluon upper bound
5000.0
<=
5000
Objecve to maximize
Proﬁt
$15,738
Figure 16.10 The Chemcon Model
Figure 16.11
SolverTable 
Dialog Box
Get other points on
the trade-off curve by
maximizing profit,
constraining pollution
with varying upper
bounds.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

and so on, ending with 9005. Alternatively, equally spaced inputs could be used. All that
is required is a representative set of values between the extremes. The results appear in
Figure 16.12.
Discussion of the Solution
These results show that as you allow more pollution, profit increases. Also, the product
mix shifts considerably. Product 8, a low polluter with a low profit margin, eventually
leaves the mix when pollution is allowed to increase, which makes sense. It is less clear
why the level of product 6 increases so dramatically. Product 6 is only a moderate polluter
and has a moderate profit margin, so the key is evidently that it requires low levels of labor
and raw materials. The trade-off curve is created as a scatter chart (with the points con-
nected) directly from columns J and K of the table. This curve appears in Figure 16.13. It
16.3 Pareto Optimality and Trade-off Curves
16-17
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
A
B
C
D
E
F
G
H
I
J
K
Oneway analysis for Solver model in Model worksheet
Polluon upper bound (cell $D$26) values along side, output cell(s) along top
Units_produced_1
Units_produced_2
Units_produced_3
Units_produced_4
Units_produced_5
Units_produced_6
Units_produced_7
Units_produced_8
Actual_polluon
Proﬁt
3560
0.0
30.0
0.0
10.0
20.0
50.0
30.0
0.0
3560.0
$8,360
4000
0.0
30.0
0.0
10.0
20.0
50.0
30.0
73.3
4000.0
$11,293
4500
0.0
30.0
0.0
10.0
22.4
50.0
30.0
150.0
4500.0
$14,480
5000
0.0
30.0
0.0
10.0
21.1
50.0
48.6
150.0
5000.0
$15,738
5500
0.0
30.0
0.0
10.0
20.0
50.0
72.9
123.3
5500.0
$16,336
6000
0.0
30.0
0.0
10.0
20.0
50.0
96.7
95.6
6000.0
$16,916
6500
0.0
30.0
0.0
10.0
20.0
60.5
110.0
73.0
6500.0
$17,474
7000
0.0
30.0
0.0
10.0
20.0
84.3
110.0
57.1
7000.0
$18,006
7500
0.0
30.0
0.0
10.0
20.0
108.1
110.0
41.3
7500.0
$18,537
8000
0.0
30.0
0.0
10.0
20.0
131.9
110.0
25.4
8000.0
$19,069
8500
0.0
30.0
0.0
10.0
20.0
155.7
110.0
9.5
8500.0
$19,601
9005
0.0
30.0
0.0
10.0
20.0
190.0
98.6
0.0
8980.0
$20,089
Figure 16.12 SolverTable Results
$15,000 
$17,000 
$19,000 
$21,000 
t
Trade-oﬀ of Proﬁt versus Polluon
$5,000 
$7,000 
$9,000 
$11,000 
$13,000 
3000
4000
5000
6000
7000
8000
9000
Proﬁt
Polluon
Figure 16.13
Trade-off Curve
for Profit versus
Pollution
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

indicates that profit indeed increases as Chemcon allows more pollution, but at a decreas-
ing rate. For example, when pollution is allowed to increase from 4000 to 4500, Chemcon
can make an extra $3187 in profit. However, when pollution is allowed to increase from
8000 to 8500, the extra profit is only $532. All points below the curve are dominated—for
a given level of pollution, the company can achieve a larger profit—and all points above
the curve are unattainable. ■
Trade-off curves are not limited to linear models. The following example illustrates a
trade-off curve in a situation where the objective is a nonlinear function of the changing
cells.
16-18 Chapter 16
Multiobjective Decision Making
E X A M P L E
16.3 TRADE-OFFS BETWEEN EXPOSURES TO MEN AND
WOMEN AT LEON BURNIT
T
his example is a modification of the Burnit advertising example in Example 16.1. Now
we assume that Burnit’s client is concerned only with two groups of people, men and
women. Also, the number of exposures to these groups is now a nonlinear square root
function of the number of ads placed of any particular type. This implies a marginal
decreasing effect of ads—each extra ad of a particular type reaches fewer extra people than
the previous ad of this type.2
The data for this problem appear in Tables 16.4 and 16.5. The first of these specifies
the proportionality constants for the square root exposure functions. For example, if five
ads are placed in sports shows, this will achieve 155  33.541 million exposures to
men, but only 55  11.180 million exposures to women. Evidently, what works well
for men does not work so well for women, and vice versa. Given a budget of $1.5 million,
find the trade-off curve for exposures to men versus exposures to women.
Table 16.4 Proportionality Constants for Square Root Exposure Functions
Sports Show
Game Show
News Show
Sitcom
Drama
Soap Opera 
Men
15
3
7
7
8
1
Women
5
5
6
10
9
4
Table 16.5 Data on Ads for the Burnit Example
Sports
Game
News
Show
Show
Show
Sitcom
Drama
Soap Opera
Cost/ad ($1000s)
120
40
50
40
60
20
Lower limit
2
0
2
0
2
0
Upper limit
10
5
10
5
10
5
Objective
To find the trade-off curve for exposures to men versus exposures to women
by solving a number of NLP problems.
2The square root function is an alternative to the exponential advertising response function we used in
Example 7.5 of Chapter 7. Each increases at a decreasing rate.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

WHERE DO THE NUMBERS COME FROM?
We have discussed these same types of numbers in previous examples. Specifically, the
parameters in Table 16.4 can be estimated from historical data, exactly as described in
Example 7.5 of Chapter 7.
Solution
Again, the model itself is straightforward, as shown in Figure 16.14. (See the file 
Advertising Tradeoff.xlsx.) You calculate the exposures achieved in rows 22 and 23 by
entering the formula
=B8*SQRT(B$17)
in cell B22 and copying it to the range B22:G23. You then sum these in cells B30 and B33,
and calculate the total cost in the usual way with the SUMPRODUCT function.
For the three-step trade-off curve procedure, let exposures to men be objective 1 and
exposures to women be objective 2. For step 1, you maximize exposures to men and ignore
women. That is, you do not include the constraint in row 30 in the Solver dialog box. You
can check that the corresponding solution achieves 89.515 million exposures to men and
79.392 million exposures to women. Reversing the roles of men and women (step 3), you
can check that if you maximize exposures to women and ignore men, the solution achieves
89.220 million exposures to women and only 84.899 million exposures to men.
All other points on the trade-off curve are between these two extremes, and they can
again be found easily with SolverTable. You now set up Solver to maximize exposures
to men, and you include the lower limit constraint on exposures to women in the Solver
dialog box. (Do you see why it is a lower limit constraint in this example, whereas it was
16.3 Pareto Optimality and Trade-off Curves
16-19
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
J
I
H
G
F
E
D
C
B
A
Burnit nonlinear adversing model
Proporonality constants for exposure funcons
Range names used:
Sports ad
Game show ad
News show ad
Sitcom ad
Drama ad
Soap opera ads
Budget
=Model!$D$26
Exposures to men
15
3
7
7
8
1
Exposures_to_men
=Model!$B$33
Exposures to women
5
5
6
10
9
4
Exposures_to_women
=Model!$B$30
Maximum_ads_allowed
=Model!$B$19:$G$19
Cost/ad ($1,000s)
120
40
50
40
60
20
Minimum_ads_required
=Model!$B$15:$G$15
Number_purchased
=Model!$B$17:$G$17
Adversing plan
Total_cost
=Model!$B$26
Sports ad
Game show ad
News show ad
Sitcom ad
Drama ad
Soap opera ad
Women_lower_bound
=Model!$D$30
Minimum ads required
2
0
2
0
2
0
<=
<=
<=
<=
<=
<=
Number purchased
2.000
5.000
5.387
5.000
8.177
5.000
<=
<=
<=
<=
<=
<=
Maximum ads allowed
10
5
10
5
10
5
Exposures obtained
Sports ad
Game show ad
News show ad
Sitcom ad
Drama ad
Soap opera ad
6
3
2.2
7
7
8.2
2
2
5
6.5
1
7
4
2.6
1
8
0
7.6
3
1
2.1
2
n
e
M
4
4
9.8
7
3
7.5
2
1
6
3.2
2
6
2
9.3
1
0
8
1.1
1
1
7
0.7
n
e
m
o
W
Budget constraint
Total 
t
e
g
d
u
B
ts
o
c
1500.000
<=
1500
Constraint on minimal exposures to women
Exposures to women
Women lower bound
89.219
>=
89.219
Objecve to maximize
Exposures to men
84.934
Assumpon: The number of exposures (in millions) to each 
group is proporonal to the square root of the number of ads 
of a parcular type shown. 
Figure 16.14 The Advertising Trade-off Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

an upper limit constraint in the previous example? There the objective was to make pollu-
tion low. Here the objective is to make exposures to women high.) The lower limit cell
(D30) becomes the single input cell for SolverTable, which can vary from (slightly greater
than) 79.392 to (slightly less than) 89.220 with suitable values in between. The results
appear in table form in Figure 16.15 and in graphical form in Figure 16.16.
16-20 Chapter 16
Multiobjective Decision Making
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
A
B
C
D
E
F
G
H
I
Oneway analysis for Solver model in Model worksheet
Women lower bound (cell $D$30) values along side, output cell(s) along top
Number_purchased_1
Number_purchased_2
Number_purchased_3
Number_purchased_4
Number_purchased_5
Number_purchased_6
Exposures_to_women
Exposures_to_men
79.393
4.839
1.744
6.072
5.000
5.508
0.776
79.393
89.515
80
4.715
1.835
6.100
5.000
5.620
0.928
80.000
89.506
81
4.503
1.994
6.143
5.000
5.807
1.215
81.000
89.449
82
4.280
2.163
6.178
5.000
5.997
1.555
82.000
89.336
83
4.048
2.347
6.204
5.000
6.186
1.954
83.000
89.156
84
3.801
2.538
6.220
5.000
6.383
2.421
84.000
88.900
85
3.540
2.745
6.228
5.000
6.578
2.969
85.000
88.554
86
3.262
2.976
6.217
5.000
6.777
3.604
86.000
88.096
87
2.964
3.225
6.189
5.000
6.979
4.357
87.000
87.500
88
2.600
3.580
6.173
5.000
7.269
5.000
88.000
86.713
89
2.057
4.276
6.207
5.000
7.863
5.000
89.000
85.478
89.219
2.000
5.000
5.387
5.000
8.177
5.000
89.219
84.934
Figure 16.15 SolverTable Results for the Advertising Trade-off Model
88
89
90
o men
Trade-oﬀ of Men versus Women
84
85
86
87
78
80
82
84
86
88
90
Exposures t
Exposures to women
Figure 16.16
Trade-off Curve
for the Advertising
Example
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Discussion of the Solution
As you look down the table (or to the right in the chart), more exposures to women are
required, which has an increasingly negative effect on exposures to men. Not surprisingly,
the corresponding solutions place more ads in the shows watched predominantly by
women (game shows, dramas, and soaps) and fewer ads in sports and news shows. The
upper limit placed on sitcom ads prevents you from seeing how the number of sitcom ads
would change if it were not constrained. It would probably change fairly dramatically,
given that these ads are relatively cheap and they tend to reach more women than men.
Technical Note
We ran into two problems that you might experience. First, depending on the starting solu-
tion, one of the changing cells might become slightly negative (due to numerical roundoff),
in which case the SQRT function is undefined, and you get an error message. To remedy
this, you can add a constraint such as Ads>=0.0001. Second, when we ran SolverTable, it
indicated “no feasible solution” to the problem in row 49 of Figure 16.15, although we
know there is a feasible solution. This can sometimes occur with nonlinear models,
depending on the starting solution used. SolverTable uses the solution from the previous
problem as the starting solution for the next problem. This seems reasonable, but it can
produce this error. If it does, try running the Solver on this particular problem again with
your own initial solution (such as all 0s). This is what we did to get the values in row 49.
■
16.3 Pareto Optimality and Trade-off Curves
16-21
1.
A trade-off curve is useful because it gives the ultimate decision maker many undomi-
nated solutions to choose from. However, it does not specify a “best” solution. The
decision maker still has to make the difficult decision of which solution from the
trade-off curve to implement. This can be done subjectively or with the help of a
multiattribute utility function. However, estimating these types of functions is difficult,
so their use in real-world applications has been limited.
2.
These trade-off models can be generalized to a situation where there are more than
two objectives by constructing trade-off curves between each pair of objectives. ■
MODELING ISSUES
P R O B L E M S
Skill-Building Problems
19. Widgetco produces two types of widgets. Each widget
is made of steel and aluminum and is assembled with
skilled labor. The resources used and the per-unit
profit contribution (ignoring cost of overtime labor
purchased) for each type of widget are given in the
file P16_19.xlsx. At present, 200 pounds of steel,
300 pounds of aluminum, and 300 hours of labor are
available. Extra overtime labor can be purchased for
$10 per hour. Construct a trade-off curve between
the objectives of maximizing profit and minimizing
overtime labor.
20. Plantco produces three products. Three workers work
for Plantco, and the company must determine which
product(s) each worker should produce. The number
of units each worker would produce if he or she spent
the whole day producing each type of product is given
in the file P16_20.xlsx. The company is also interested
in maximizing the happiness of its workers. The
amount of happiness “earned” by a worker who
spends the entire day producing a given product is
also given in this file. Construct a trade-off curve
between the objectives of maximizing total units
produced daily and total worker happiness.
21. If a company spends a on advertising (measured in
thousands of dollars) and charges a price of p dollars
per unit, then it can sell 1000  10p  20a12 units of
the product. The cost per unit of producing the product
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

is $6. Construct a trade-off curve between the objec-
tives of maximizing profit and maximizing the number
of units sold.
22. GMCO produces three types of cars: compact,
medium, and large. The variable cost per car and pro-
duction capacity (per year) for each type of car are
given in the file P16_22.xlsx. The annual demand for
each type of car depends on the prices of the three
types of cars, also given in this file. In this latter table,
PC is the price charged for a compact car (in thousands
of dollars). The variables PM and PL are defined simi-
larly for medium and large cars. Suppose that each
compact car gets 30 mpg, each medium car gets 25
mpg, and each large car gets 18 mpg. GMCO wants to
keep the planet pollution free, so in addition to maxi-
mizing profit, it wants to maximize the average miles
16-22 Chapter 16
Multiobjective Decision Making
per gallon attained by the cars it sells. Construct a
trade-off curve between these two objectives.
23. In the capital budgeting example from Chapter 6 (see
Example 6.1), we maximized NPV for a given budget.
Now find a trade-off curve for NPV versus budget.
Specifically, minimize the amount invested, with a
lower bound constraint on the NPV obtained. What
lower bounds should you use? Do you get the same
trade-off curve as in Figure 6.4?
24. The portfolio optimization example from Chapter 7 (see
Example 7.9) found the efficient frontier by minimizing
portfolio variance, with a lower bound constraint on the
expected return. Do it the opposite way. That is, calculate
the efficient frontier by maximizing the expected return,
with an upper bound on the portfolio standard deviation.
Do you get the same results as in Example 7.9?
16.4 THE ANALYTIC HIERARCHY PROCESS (AHP)
When multiple objectives are important to a decision maker, choosing between alternatives
can be difficult. For example, if you are choosing a job, one job might offer the highest
starting salary but rate poorly on other objectives such as quality of life in the city where
the job is located and the nearness of the job to your family. Another job offer might rate
highly on these latter objectives but have a relatively low starting salary. In this case, it can
be difficult for you to choose between job offers. The Analytic Hierar chy Pr ocess
(AHP), developed originally by Thomas Saaty, is a powerful tool that can be used to make
decisions in situations where multiple objectives are present. We present an example to
illustrate such a case.3 (Note: Matrix notation and matrix multiplication are used in this
section. You may need to review the discussion of matrices in section 7.7.)
E X A M P L E
16.4 USING AHP TO SELECT A JOB
J
ane is about to graduate from college and is trying to determine which job to accept. She
plans to choose among the offers by determining how well each job offer meets the fol-
lowing four objectives:
■
Objective 1: High starting salary
■
Objective 2: Quality of life in city where job is located
■
Objective 3: Interest of work
■
Objective 4: Nearness of job to family
Objective
To use the AHP method to help Jane select a job that is best in terms of the
various job criteria.
WHERE DO THE NUMBERS COME FROM?
As discussed shortly, Jane must make a number of trade-offs during the implementation of
AHP. In this case, the decision maker supplies the data.
3The leading software package for implementing AHP is Expert Choice, developed by Expert Choice Inc.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Solution
To illustrate how AHP works, suppose that Jane is facing three job offers and must deter-
mine which offer to accept. In this example, there are four objectives, as listed previously.
For each objective, AHP generates a weight (by a method to be described shortly). By con-
vention, the weights are always chosen so that they sum to 1. Suppose that Jane’s weights
are w1  0.5115, w2  0.0986, w3  0.2433, and w4  0.1466. These weights indicate that
a high starting salary is the most important objective, followed by interest of work, near-
ness to family, and quality of life.
Next, suppose that Jane determines (again by a method to be described shortly) how
well each job “scores” on each objective. For example, suppose these scores are those
listed in Table 16.6. You can see from this table that job 1 best meets the objective of a high
starting salary, but scores worst on all other objectives. Note that the scores of the jobs on
each objective are normalized, which means that for each objective, the sum of the scores
of the jobs on that objective is 1.
Given the weights for the objectives and the scores shown in Table 16.6, Jane can now
determine which job offer to accept. Specifically, for each job, she calculates an overall
score that is a weighted sum of the scores for that job, using the w’s as weights. For exam-
ple, the overall score for job 1 weights the scores in the first row of Table 16.6:
Job 1 score  0.5115(0.5714)  0.0986(0.1593)  0.2433(0.0882)  0.1466(0.0824)
 0.3415
16.4 The Analytic Hierarchy Process (AHP)
16-23
Table 16.6 Job Scores on Objectives in the AHP Example
Salary
Quality of Life 
Interest of Work 
Nearness to Family 
Job 1
0.5714
0.1593
0.0882
0.0824
Job 2
0.2857
0.2519
0.6687
0.3151
Job 3
0.1429
0.5889
0.2431
0.6025
AHP is essentially a
process of rating the
importance of each
objective and then
rating how well each
possible decision 
meets each objective.
The result is a score
for each possible
decision, with higher
scores preferred.
Similarly, the overall scores for jobs 2 and 3 are obtained by weighting the scores in the
second and third rows of Table 16.6:
Job 2 score  0.5115(0.2857)  0.0986(0.2519)  0.2433(0.6687)  0.1466(0.3151)
 0.3799
Job 3 score  0.5115(0.1429)  0.0986(0.5889)  0.2433(0.2431)  0.1466(0.6025)
 0.2786
Because the overall score for job 2 is the largest, AHP suggests that Jane should accept this
job.
The following discussion on how AHP actually works is technical and is not really
necessary for using the method. We have included the file Choosing Jobs with VBA.xlsm
that implements AHP as a decision support system with macros. We urge you to try it out,
especially if you are currently making a job decision. You don’t need to understand the
details behind AHP to run the application. You simply need to make a number of pairwise
comparisons, as indicated in a number of dialog boxes. However, if you really do want to
understand how AHP works, then read on. By the way, the term criterion is commonly
used instead of objective when discussing AHP. The file Choosing Jobs with VBA.xlsm
uses this term consistently.
Pairwise Comparison Matrices
To obtain the weights for the various objectives, you begin by forming a matrix A, known
as the pairwise comparison matrix. The entry in row i and column j of A, labeled aij, indicates
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

how much more (or less) important objective i is than objective j to the decision maker.
“Importance” is measured on an integer-valued scale from 1 to 9, with each number having
the interpretation shown in Table 16.7. The phrases in this table, such as “strongly more
important than,” are suggestive only. They simply indicate discrete points on a continuous
scale that can be used to compare the relative importance of any two objectives.
For example, if a13  3, then objective 1 is slightly more important to Jane than
objective 3. If aij  4, a value not in the table, then objective i is somewhere between
slightly and strongly more important than objective j. If objective i is less important to Jane
than objective j, the reciprocal of the appropriate index is used. For example, if objective i
is slightly less important than objective j, then aij  13. Finally, for all objectives i, the
convention is to set aii  1.
For consistency, it is necessary to set aji  1aij. For example, if a13  3, then it is
necessary to have a31  13. This simply states that if objective 1 is slightly more impor-
tant than objective 3, then objective 3 is slightly less important than job 1. It is usually eas-
ier to determine all aij’s that are greater than 1 and then use the relationship aji  1aij to
determine the remaining entries in the pairwise comparison matrix.
To illustrate, suppose that Jane has identified the following pairwise comparison
matrix for her four objectives:
A 

The rows and columns of A each correspond to Jane’s four objectives: salary, quality of
life, interest of work, and nearness to family. Considering the first row, for example, she
believes that salary is more important, in various degrees, than quality of life, interest of
work, and nearness to family.
The entries in this matrix have built-in pairwise consistency because we require aij 
1aij for each i and j. However, they might not be consistent when three (or more) alterna-
tives are considered simultaneously. For example, Jane claims that salary is strongly more
important than quality of life (a12  5) and that salary is very slightly more important than
interesting work (a13  2). But she also says that interesting work is very slightly more
important than quality of life (a32  2). The question is whether these ratings are all con-
sistent with one another. They are not, at least not exactly. It can be shown that some of
Jane’s pairwise comparisons are slightly inconsistent. When a person is asked to make a
number of pairwise comparisons, slight inconsistencies are common and fortunately do
not cause serious difficulties. An index that can be used to measure the consistency of
Jane’s preferences is discussed later in this section.
Determining the Weights
Although the ideas behind AHP are fairly intuitive, the mathematical reasoning required to
derive the weights for the objectives is advanced. Therefore, we simply describe how it is done.
4
12
2
1
2
12
1
12
5
1
2
2
1
15
12
14
16-24 Chapter 16
Multiobjective Decision Making
Table 16.7 Interpretation of Values in the Pairwise Comparison Matrix
Value of aij
Interpretation 
1
Objectives i and j are equally important.
3
Objective i is slightly more important than j.
5
Objective i is strongly more important than j.
7
Objective i is very strongly more important than j.
9
Objective i is absolutely more important than j.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Starting with the pairwise comparison matrix A, you find the weights for Jane’s four
objectives using the following two steps:
1.
For each of the columns of A, divide each entry in the column by the sum of the
entries in the column. This yields a new matrix (call it Anorm, for “normalized”) in
which the sum of the entries in each column is 1. For Jane’s pairwise comparison
matrix, this step yields
Anorm 

2.
Estimate wi, the weight for objective i, as the average of the entries in row i of Anorm.
For Jane’s matrix this yields
w1 
 0.5115
0.5128  0.5000  0.5000  0.5333

4
0.5333
0.0667
0.2667
0.1333
0.5000
0.1250
0.2500
0.1250
0.5000
0.1000
0.2000
0.2000
0.5128
0.1026
0.2564
0.1282
16.4 The Analytic Hierarchy Process (AHP)
16-25
w2 
 0.0986
w3 
 0.2433
w4 
 0.1466
Intuitively, why does w1 approximate the weight for objective 1 (salary)? Here is the
reasoning. The proportion of weight that salary is given in pairwise comparisons of each
objective to salary is 0.5128. Similarly, 0.50 represents the proportion of total weight that
salary is given in pairwise comparisons of each objective to quality of life. Therefore, each
of the four numbers averaged to obtain w1 represents a measure of the total weight attached
to salary. Averaging these numbers should give a good estimate of the proportion of the
total weight given to salary.
Determining the Score of Each Decision Alternative on Each Objective
Now that the weights for the various objectives have been determined, the next step is
to determine how well each job scores on each objective. To determine these scores,
you use the same scale described in Table 16.7 to construct a pairwise comparison
matrix for each objective. Consider the salary objective, for example. Suppose that Jane
assesses the following pairwise comparison matrix. We denote this matrix as A1
because it reflects her comparisons of the three jobs with respect to the first objective,
salary.
A1 

The rows and columns of this matrix correspond to the three jobs. For example,
the first row means that Jane believes job 1 is superior to job 2 (and even more supe-
rior to job 3) in terms of salary. To find the relative scores of the three jobs on salary,
the same two-step procedure as previously discussed is applied to the salary pairwise
4
2
1
2
1
12
1
12
14
0.1282  0.2000  0.1250  0.1333

4
0.2564  0.2000  0.2500  0.2667

4
0.1026  0.1000  0.1250  0.0667

4
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

comparison matrix A1. That is, you first divide each column entry by the column sum
to obtain
A1,norm 

Then you average the numbers in each row to obtain the vector of scores for the three jobs
on salary, denoted by S1:
S1 

That is, the scores for jobs 1, 2, and 3 on salary are 0.5714, 0.2857, and 0.1429. In terms of
salary, job 1 is clearly the favorite.
Next, these calculations are repeated for Jane’s other objectives. Each of these objec-
tives requires a pairwise comparison matrix, which we denote as A2, A3, and A4. Suppose
that Jane’s pairwise comparison matrix for quality of life is
A2 

Then the corresponding normalized matrix is
A2,norm 

and by averaging,
S2 

Here, job 3 is the clear favorite. However, this does not have much impact because Jane
puts relatively little weight on quality of life.
For interest of work, suppose the pairwise comparison matrix is
A3 

Then the same types of calculations show that the scores for jobs 1, 2, and 3 on interest of
work are
S3 

Finally, suppose the pairwise comparison matrix for nearness to family is
A4 

In this case, the scores for jobs 1, 2, and 3 on nearness to family are
S4 

0.0824
0.3151
0.6025
17
12
1
14
1
2
1
4
7
0.0882
0.6687
0.2431
13
3
1
17
1
13
1
7
3
0.1593
0.2519
0.5889
0.2000
0.2000
0.6000
0.1111
0.2222
0.6667
0.1667
0.3333
0.5000
13
13
1
12
1
3
1
2
3
0.5714
0.2857
0.1429
0.5714
0.2857
0.1429
0.5714
0.2857
0.1429
0.5714
0.2857
0.1429
16-26 Chapter 16
Multiobjective Decision Making
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Determining the Best Alternative
Let’s summarize what has been determined so far. Jane first assesses a pairwise compari-
son matrix A that measures the relative importance of each of her objectives to one another.
From this matrix, she obtains a vector of weights that summarizes the relative importance
of the objectives. Next, Jane assesses a pairwise comparison matrix Ai for each objective i.
This matrix measures how well each job compares to other jobs with regard to this
objective. For each matrix Ai, she obtains a vector of scores Si that summarizes how the
jobs compare in terms of achieving objective i.
The final step is to combine the scores in the Si vectors with the weights in the w
vector. Actually, this has already been done. Note that the columns of Table 16.6 are the Si
vectors just obtained. If you form a matrix S of these score vectors and multiply this matrix
by w, you obtain a vector of overall scores for each job, as shown here:
Sw 
 	



These are the same overall scores listed earlier. As before, the largest of these overall
scores is for job 2, so AHP suggests that Jane should accept this job. Job 1 follows closely
behind, with job 3 somewhat farther behind.
Checking for Consistency
As mentioned earlier, any pairwise comparison matrix can suffer from inconsistencies. We
now describe a procedure to check for inconsistencies. We illustrate this on the A matrix
and its associated vector of weights w. The same procedure can be used on any of the Ai
matrices and their associated weights vector Si.:
1.
Calculate Aw. For the example,
Aw 

	



2.
Find the ratio of each element of Aw to the corresponding weight in w and average
these ratios. For the example, this calculation is
 4.0477
3.
Calculate the consistency index (labeled CI) as
CI 
where n is the number of objectives. For the example this is CI 
4.0
4
47

7
1
 4
  0.0159.
4.
Compare CI to the random index (labeled RI) in Table 16.8 for the appropriate value of n.
(Step 2 result)  n

n  1

2
0
.
.
0
5
7
1
7
15
4
  
0
0
.
.
3
0
9
9
5
8
8
6
  
0
0
.
.
9
2
8
4
9
3
4
3
  
0
0
.
.
5
1
9
4
3
6
3
6


4
2.0774
0.3958
0.9894
0.5933
0.5115
0.0986
0.2433
0.1466
4
12
2
1
2
12
1
12
5
1
2
2
1
15
12
14
0.3415
0.3799
0.2786
0.5115
0.0986
0.2433
0.1466
0.0824
0.3151
0.6025
0.0882
0.6687
0.2431
0.1593
0.2519
0.5889
0.5714
0.2857
0.1429
16.4 The Analytic Hierarchy Process (AHP)
16-27
Table 16.8 Random Indices for Consistency Check for the AHP Example
n
2
3
4
5
6
7
8
9
10
RI
0
0.58
0.90
1.12
1.24
1.32
1.41
1.45
1.51
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

To be a perfectly consistent decision maker, each ratio in step 2 should equal n. This
implies that a perfectly consistent decision maker has CI  0. The values of RI in
Table 16.8 give the average value of CI if the entries in A were chosen at random (subject to
the constraints that aij’s must equal 1, and aij  1aji). If the ratio of CI to RI is sufficiently
small, the decision maker’s comparisons are probably consistent enough to be useful. Saaty
suggested that if CIRI  0.10, the degree of consistency is satisfactory, whereas if
CIRI 
 0.10, serious inconsistencies exist and AHP may not yield meaningful results. In
Jane’s example, CIRI  0.01590.90  0.0177, which is much less than 0.10. Therefore,
Jane’s pairwise comparison matrix A does not exhibit any serious inconsistencies. (You can
check that the same is true of her other pairwise comparison matrices A1 through A4.)
DEVELOPING THE SPREADSHEET MODEL
We now show how to implement AHP on a spreadsheet. (See Figure 16.17 and the file 
Choosing Jobs.xlsx.)
16-28 Chapter 16
Multiobjective Decision Making
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
A
B
C
D
E
F
G
H
I
J
K
L
Job selecon using analycal hierarchy process
Pairwise comparisons among 
d
e
zila
m
r
o
N
s
e
vitc
ej
b
o
 
st
h
gie
W
xirt
a
m
Salary
Life quality
Work interest
Near family
Salary
1
5
2
4
0.5128
0.5000
0.5000
0.5333
0.5115
Life quality
1/5
1
1/2
1/2
0.1026
0.1000
0.1250
0.0667
0.0986
Work interest
1/2
2
1
2
0.2564
0.2000
0.2500
0.2667
0.2433
Near family
1/4
2
1/2
1
0.1282
0.2000
0.1250
0.1333
0.1466
Pairwise comparisons among jobs on 
d
e
zila
m
r
o
N
y
r
ala
s
 
s
e
r
o
c
S
xirt
a
m
Job 1
Job 2
Job 3
Job 
4
1
7
5.0
4
1
7
5.0
4
1
7
5.0
4
1
7
5.0
4
2
1
1
Job 
7
5
8
2.0
7
5
8
2.0
7
5
8
2.0
7
5
8
2.0
2
1
2
/
1
2
Job 
9
2
4
1.0
9
2
4
1.0
9
2
4
1.0
9
2
4
1.0
1
2
/
1
4
/
1
3
Pairwise comparisons among jobs on quality of 
d
e
zila
m
r
o
N
e
fil
 
s
e
r
o
c
S
xirt
a
m
Job 1
Job 2
Job 3
Job 
3
9
5
1.0
0
0
0
2.0
1
1
1
1.0
7
6
6
1.0
3
/
1
2
/
1
1
1
Job 
9
1
5
2.0
0
0
0
2.0
2
2
2
2.0
3
3
3
3.0
3
/
1
1
2
2
Job 
9
8
8
5.0
0
0
0
6.0
7
6
6
6.0
0
0
0
5.0
1
3
3
3
Pairwise comparisons among jobs on interest of 
d
e
zila
m
r
o
N
k
r
o
w
 
s
e
r
o
c
S
xirt
a
m
Job 1
Job 2
Job 3
Job 
2
8
8
0.0
9
6
7
0.0
8
6
9
0.0
9
0
9
0.0
3
/
1
7
/
1
1
1
Job 
7
8
6
6.0
3
2
9
6.0
4
7
7
6.0
4
6
3
6.0
3
1
7
2
Job 
1
3
4
2.0
8
0
3
2.0
8
5
2
2.0
7
2
7
2.0
1
3
/
1
3
3
Pairwise comparisons among jobs on nearness to 
d
e
zila
m
r
o
N
yli
m
a
f
 
s
e
r
o
c
S
xirt
a
m
Job 1
Job 2
Job 3
Job 
4
2
8
0.0
0
7
8
0.0
9
6
7
0.0
3
3
8
0.0
7
/
1
4
/
1
1
1
Job 
1
5
1
3.0
3
4
0
3.0
7
7
0
3.0
3
3
3
3.0
2
/
1
1
4
2
Job 
5
2
0
6.0
7
8
0
6.0
4
5
1
6.0
3
3
8
5.0
1
2
7
3
Determining best job
Matrix of 
d
e
t
h
gie
W
s
e
r
o
c
s
 scores
Salary
Life quality
Work interest
Near family
Job 1
0.5714
0.159
0.088
0.082
0.3415
Job 2
0.2857
0.252
0.669
0.315
0.3799
Job 3
0.1429
0.589
0.243
0.602
0.2786
Job 2 has the 
highest score
Figure 16.17 The AHP Job Selection Model
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

1
Inputs. Enter the pairwise comparison matrices in the shaded ranges. (Note that you
can enter fractions such as 1/7 in cell C24, and have them appear as fractions by formatting
the cells with the Fraction option.)
2
Normalized matrix. Calculate the normalized matrix for the first pairwise compari-
son matrix in the range G5:J8. This can be done quickly as follows. Starting with the cursor
in cell G5, highlight the range G5:J8. Then type the formula
=B5/SUM(B$5:B$8)
and press Control+Enter (both keys at once). We introduced this really useful shortcut in an
earlier chapter as a quick way to enter the same formula in an entire range.
3
Weights of objectives. In the range L5:L8, calculate the weights for each objective.
Again, do this the quick way. Starting with the cursor in cell L5, highlight the range L5:L8.
Then type the formula
=AVERAGE(G5:J5)
and press Control+Enter.
4
Scores for jobs on objecti ves. Repeat the same calculations in steps 2 and 3 for the
other pairwise comparison matrices to obtain the normalized matrices in columns G through
I and scores vectors in column L.
5
Overall job scores. In the range B37:E39, form a matrix of job scores on the various
objectives. To get the score vector in the range L12:L14 into the range B37:B39, for exam-
ple, highlight this latter range, type the formula
=L12
and press Control+Enter. Do likewise for the other three scores vectors in column L. Then
to obtain the overall job scores (from the matrix product Sw), highlight the range G37:G39,
type the formula
=MMULT(B37:E39,L5:L8)
and press Control+Shift+Enter. (Remember that Control+Shift+Enter is used to enter a
matrix function. In contrast, Control+Enter is equivalent to copying a formula to a high-
lighted range.) Again you can see that job 2 is the most preferred of the three jobs.
Calculating the Consistency Index 
We now show how to compute the consistency index CI for each of the pairwise compari-
son matrices. (See Figure 16.18, which is also part of the file AHPJobs.xlsx. Note that
columns G through K have been hidden to save space. These contain the normalized matri-
ces from step 2 in the previous section.) The following steps are relevant for the first pair-
wise comparison matrix. The others are done in analogous fashion.
1
Product of comparison matrix and v ector of weights (or scor es). Calculate the
product of the first pairwise comparison matrix and the weights vector in the range N5:N8
by highlighting this range, typing
=MMULT(B5:E8,L5:L8)
and pressing Ctrl+Shift+Enter.
2
Ratios. In cell O5, calculate the ratio of the two cells to its left with the formula
=N5/L5
and copy this to the range O6:O8.
16.4 The Analytic Hierarchy Process (AHP)
16-29
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

3
Consistency index. Calculate the consistency index CI in cell O9 with the formula
=(AVERAGE(O5:O8)–4)/3
Then in cell O10, calculate the ratio of CI to RI (for n  4) with the formula
=O9/0.90
(The 0.90 comes from Table 16.8 earlier in the chapter. For the other four pairwise com-
parison matrices in Figure 16.18, you should use n  3 and RI  0.58.)
As Figure 16.18 illustrates, all of the pairwise comparison matrices are sufficiently
consistent—the CIRI ratio for each is well less than 0.10.
■
16-30 Chapter 16
Multiobjective Decision Making
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
A
B
C
D
E
F
L
M
N
O
Job selecon using analycal hierarchy process
Pairwise comparisons among 
s
oit
a
R
tc
u
d
o
r
P
st
h
gie
W
s
e
vitc
ejb
o
Salary
Life quality
Work interest
Near family
Salary
1
5
2
4
0.5115
2.0774
4.0611
Life quality
1/5
1
1/2
1/2
0.0986
0.3958
4.0161
Work interest
1/2
2
1
2
0.2433
0.9894
4.0672
Near family
1/4
2
1/2
1
0.1466
0.5933
4.0459
CI
0.0159
Pairwise comparisons among jobs on 
s
e
r
o
c
S
y
r
ala
s
CI/RI
0.0176
Job 1
Job 2
Job 3
Job 
3
3
4
1
7.1
4
1
7
5.0
4
2
1
1
Job 
3
1
7
5
8.0
7
5
8
2.0
2
1
2
/
1
2
Job 
3
6
8
2
4.0
9
2
4
1.0
1
2
/
1
4
/
1
3
CI
0
Pairwise comparisons among jobs on quality of 
s
e
r
o
c
S
e
fil
CI/RI
0.0000
Job 1
Job 2
Job 3
Job 
3
3
2
0.3
5
1
8
4.0
3
9
5
1.0
3
/
1
2
/
1
1
1
Job 
1
4
4
0.3
7
6
6
7.0
9
1
5
2.0
3
/
1
1
2
2
Job 
3
4
9
0.3
2
2
2
8.1
9
8
8
5.0
1
3
3
3
CI
0.0270
Pairwise comparisons among jobs on interest of 
s
e
r
o
c
S
k
r
o
w
CI/RI
0.0465
Job 1
Job 2
Job 3
Job 
8
1
0
0.3
8
4
6
2.0
2
8
8
0.0
3
/
1
7
/
1
1
1
Job 
9
3
1
0.3
4
5
1
0.2
7
8
6
6.0
3
1
7
2
Job 
4
5
0
0.3
6
0
3
7.0
1
3
4
2.0
1
3
/
1
3
3
CI
0.0035
Pairwise comparisons among jobs on nearness to 
s
e
r
o
c
S
yli
m
af
CI/RI
0.0061
Job 1
Job 2
Job 3
Job 
5
0
0
0.3
3
7
4
2.0
4
2
8
0.0
7
/
1
4
/
1
1
1
Job 
9
1
0
0.3
0
6
4
9.0
1
5
1
3.0
2
/
1
1
4
2
Job 
5
3
0
0.3
6
9
0
8.1
5
2
0
6.0
1
2
7
3
CI
0.0010
Determining best job
CI/RI
0.0017
Figure 16.18 Checking for Consistency
1.
In Jane’s job selection example, suppose that quality of life depends on two subob-
jectives: recreational facilities and educational facilities. Then we need a pairwise
comparison matrix to calculate the proportion of the quality of life score that is deter-
mined by recreational facilities and the proportion that is determined by educational
facilities. Next, we need to determine how each job scores (separately) on recre-
ational facilities and educational facilities. Then we can again determine a quality of
life score for each job and proceed with AHP as before. Using this idea, AHP can
MODELING ISSUES
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

handle a hierarchy of objectives and subobjectives—hence the term “hierarchy” in
the name of the procedure.
2.
Although the finished version of the Choosing Jobs.xlsx file can be used as a tem-
plate for other AHP problems, it is clear by now that typical users would not want to
go to all this trouble to create a spreadsheet model, certainly not from scratch. If you
intend to make any real decisions with AHP, you will want to acquire special-purpose
software such as Expert Choice. Alternatively, you can use the file Choosing Jobs
with VBA.xlsm mentioned earlier. ■
16.4 The Analytic Hierarchy Process (AHP)
16-31
Automated Manufacturing Decisions Using AHP
Weber (1993) reports the successful use of AHP in deciding which of several technologies
to purchase for automated manufacturing. As he discusses, these decisions can have sev-
eral types of impacts: quantitative financial (such as purchase cost), quantitative nonfinan-
cial (such as throughput, cycle time, and scrap, which are difficult to translate directly into
dollars), and qualitative (such as product quality and manufacturing flexibility, which are
also difficult to translate into dollars). When the decision maker is trying to rate the differ-
ent technologies along nonmonetary criteria, then he or she should use the method dis-
cussed in this section. (For example, how much more do you prefer technology 1 to
technology 2 in the area of product quality?) However, he advises that when quantitative
financial data are available (for example, technology 1 costs twice as much as technology
2), then this objective information should be used in the AHP preference matrices. Weber
developed a software package called AutoMan to implement the AHP method. This soft-
ware has been purchased by more than 800 customers since its first release in 1989.
AHP in Saudi Arabia
Bahurmoz (2003) designed and implemented a system based on AHP to select the best
candidates to send overseas to do graduate studies and eventually become teachers at the
Dar Al-Hekma women’s college in Saudi Arabia.
Other Applications of AHP
AHP has been used by companies in many areas, including accounting, finance, market-
ing, energy resource planning, microcomputer selection, sociology, architecture, and polit-
ical science. See Zahedi (1986), Golden et al. (1989), and Saaty (1988) for a discussion of
applications of AHP. ■
ADDITIONAL APPLICATIONS
P R O B L E M S
Skill-Building Problems
25. Each professor’s annual salary increase is determined by
his or her performance in three areas: teaching, research,
and service to the university. The administration has
assessed the pairwise comparison matrix for these objec-
tives as shown in the file P16_25.xlsx. The administra-
tion has compared two professors with regard to their
teaching, research, and service over the past year. The
pairwise comparison matrices are also shown in this file.
a. Which professor should receive a bigger raise?
b. Does AHP indicate how large a raise each professor
should be given?
c. Check the pairwise comparison matrix for
consistency.
26. Your company is about to purchase a new PC. Three
objectives are important in determining which com-
puter you should purchase: cost, user friendliness, and
software availability. The pairwise comparison matrix
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

for these objectives is shown in the file P16_26.xlsx.
Three computers are being considered for purchase.
The performance of each computer with regard to each
objective is indicated by the pairwise comparison
matrices also shown in this file.
a. Which computer should you purchase?
b. Check the pairwise comparison matrices for
consistency.
27. You are ready to select your mate for life and have
determined that physical attractiveness, intelligence,
and personality are key factors in selecting a satisfac-
tory mate. Your pairwise comparison matrix for these
objectives is shown in the file P16_27.xlsx. Three
people (Chris, Jamie, and Pat) are begging to be your
mate. (This problem attempts to be gender-neutral.)
Your view of these people’s attractiveness, intelli-
gence, and personality is given in the pairwise com-
parison matrices also shown in this file.
a. Who should you choose as your lifetime mate?
b. Evaluate all pairwise comparison matrices for
consistency.
28. In determining where to invest your money, two
objectives, expected rate of return and degree of risk,
are considered to be equally important. Two invest-
ments (1 and 2) have the pairwise comparison matri-
ces shown in the file P16_28.xlsx.
a. How would you rank these investments?
b. Now suppose another investment (investment 3)
is available. The pairwise comparison matrices
for these investments are also shown in this file.
(Observe that the entries in the comparison matri-
ces for investments 1 and 2 have not changed.)
How would you now rank the investments?
Contrast your ranking of investments 1 and 2
with your answer from part a.
29. You are trying to determine which MBA program to
attend. You have been accepted at two schools:
Indiana and Northwestern. You have chosen three
attributes to use in helping you make your decision:
cost, starting salary for graduates, and ambience of
school (can we party there?). Your pairwise compari-
son matrix for these attributes is shown in the file
P16_29.xlsx. For each attribute, the pairwise compari-
son matrix for Indiana and Northwestern is also shown
in this file. Which MBA program should you attend?
16-32 Chapter 16
Multiobjective Decision Making
30. You are trying to determine which of two secretarial
candidates (John or Sharon) to hire. The three objec-
tives that are important to your decision are personal-
ity, typing ability, and intelligence. You have assessed
the pairwise comparison matrix for the three objec-
tives in the file P16_30.xlsx. The score of each
employee on each objective is also shown in this file.
If you follow the AHP method, which employee
should you hire?
Skill-Extending Problems
31. A consumer is trying to determine which type of
frozen dinner to eat. She considers three attributes 
to be important: taste, nutritional value, and price.
Nutritional value is considered to be determined by
cholesterol and sodium level. Three types of dinners
are under consideration. The pairwise comparison
matrix for the three attributes is shown in the file
P16_31.xlsx. Among the three frozen dinners, the
pairwise comparison matrix for each attribute is also
shown in this file. To determine how each dinner
rates on nutrition, you will need the pairwise com-
parison matrix for cholesterol and sodium also
shown in this file. Which frozen dinner would the
consumer prefer? (Hint: The nutrition score for a
dinner equals the score of the dinner on sodium 
multiplied by the weight for sodium plus the score
for the dinner on cholesterol multiplied by the
weight for cholesterol.)
32. Based on Lin et al. (1984). You have been hired by
Arthur Ross to determine which of the following
accounts receivable methods should be used in an
audit of the Keating Five and Dime Store: analytic
review (method 1), confirmations (method 2), or test
of subsequent collections (method 3). The three crite-
ria used to distinguish among the methods are reliabil-
ity, cost, and validity. The pairwise comparison matrix
for the three criteria is shown in the file P16_32.xlsx.
The pairwise comparison matrices of the three
accounting methods for the three criteria are shown in
this file. Use AHP to determine which auditing proce-
dure should be used. Also check the first pairwise
comparison matrix for consistency.
16.5 CONCLUSION
Whenever you face a problem with multiple competing objectives, as is the case in many
real-world problems, you are forced to make trade-offs among these objectives. This is
usually a very difficult task, and not all management scientists agree on the best way to
proceed. When the objectives are very different in nature, no method can disguise the
inherent complexity of comparing “apples to oranges.” Although one method, finding
Pareto optimal solutions and drawing the resulting trade-off curve, locates solutions that
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

are not dominated by any others, you still face the problem of choosing one of the (many)
Pareto optimal solutions to implement. The other two methods discussed in this chapter,
goal programming and AHP, make trade-offs and ultimately locate an “optimal” solution.
These methods have their critics, but when they are used carefully, they have the potential
to help solve some difficult and important real-world problems.
Summary of Key Management Science Terms
Term
Explanation
Page
Goal programming
Optimization method that prioritizes multiple objectives 
16-3
(goals); tries to achieve higher priority goals before 
considering lower priority goals
Hard constraint
A constraint that must be satisfied
16-6
Soft constraint
A constraint you would like to satisfy but don’t absolutely have
16-6
to satisfy 
Pareto optimal solution
Solution that is not dominated, that is, no other solution 
16-13
is at least as good on all objectives and better on at least 
one objective
Trade-off curve, Efficient 
Curve showing Pareto optimal solutions, used primarily 
16-13
frontier
to show the trade-offs between two competing objectives
Analytical Hierarchy 
Method used to find best decision when a decision maker faces 
16-22
Process (AHP)
multiple criteria; requires a series of pairwise comparisons 
between criteria and between alternative decisions for 
each criterion
16.5 Conclusion
16-33
P R O B L E M S
Skill-Building Problems
33. The Pine Valley Board of Education must hire teachers
for the coming school year. The types of teachers and
the salaries that must be paid are given in the file
P16_33.xlsx. For example, 20 teachers who are quali-
fied to teach history and science have applied for jobs,
and each of these teachers must be paid an annual salary
of $21,000. Each teacher who is hired teaches the two
subjects he or she is qualified to teach. Pine Valley
needs to hire 35 teachers qualified to teach history, 30
teachers qualified to teach science, 40 teachers qualified
to teach math, and 32 teachers qualified to teach
English. The board has $1.4 million to spend on teach-
ers’ salaries. A penalty cost of $1 is incurred for each
dollar the board goes over budget. For each teacher by
which Pine Valley’s goals are unmet, the following
costs are incurred (because of the lower quality of edu-
cation): science, $30,000; math, $28,000; history,
$26,000; and English, $24,000. Determine how the
board can minimize its total cost due to unmet goals.
34. Stockco fills orders for three products for a local ware-
house. Stockco must determine how many of each
product should be ordered at the beginning of the
current month. This month, 400 units of product 1,
500 units of product 2, and 300 units of product 3 will
be demanded. The cost and space taken up by one unit
of each product are shown in the file P16_34.xlsx. If
Stockco runs out of stock before the end of the month,
the stockout costs also shown in this file are incurred.
Stockco has $17,000 to spend on ordering products
and has 3700 square feet of warehouse space. A $1
penalty is assessed for each dollar spent over the bud-
get limit, and a $10 cost is assessed for every square
foot of warehouse space needed.
a. Determine Stockco’s optimal ordering policy.
b. Suppose that Stockco has set the following goals,
listed in order of priority:
■Goal 1: Spend at most $17,000.
■Goal 2: Use at most 3700 square feet of ware-
house space.
■Goal 3: Meet demand for product 1.
■Goal 4: Meet demand for product 2.
■Goal 5: Meet demand for product 3.
Develop a goal programming model for Stockco.
35. BeatTrop Foods is trying to choose one of three com-
panies to merge with. Seven factors are important in
this decision:
■Factor 1: Contribution to profitability
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

■Factor 2: Growth potential
■Factor 3: Labor environment
■Factor 4: R&D ability of company
■Factor 5: Organizational fit
■Factor 6: Relative size
■Factor 7: Industry commonality
The pairwise comparison matrix for these factors is
shown in the file P16_35.xlsx. The three contenders
for merger have the pairwise comparison matrices for
each factor also shown in this file.
Use AHP to determine the company that BeatTrop
should merge with.
36. Productco produces three products. Each product
requires labor, lumber, and paint. The resource
requirements, unit price, and variable cost (exclusive
of labor, lumber, and paint) for each product are given
in the file P16_36.xlsx. At present, 900 labor hours,
1550 gallons of paint, and 1600 board feet of lumber
are available. Additional labor can be purchased at $6
per hour. Additional paint can be purchased at $2 per
gallon. Additional lumber can be purchased at $3 per
board foot. For the following two sets of priorities,
use goal programming to determine an optimal
production schedule. For set 1:
■Priority 1: Obtain profit of at least $10,500.
■Priority 2: Purchase no additional labor.
■Priority 3: Purchase no additional paint.
■Priority 4: Purchase no additional lumber.
For set 2:
■Priority 1: Purchase no additional labor.
■Priority 2: Obtain profit of at least $10,500.
■Priority 3: Purchase no additional paint.
■Priority 4: Purchase no additional lumber.
Skill-Extending Problems
37. A hospital outpatient clinic performs four types of
operations. The profit per operation, as well as the
minutes of X-ray time and laboratory time used, are
given in the file P16_37.xlsx. The clinic has 500
private rooms and 500 intensive care rooms. Type
1 and type 2 operations require a patient to stay in an
intensive care room for one day, whereas type 3 and
type 4 operations require a patient to stay in a private
room for one day. Each day, the hospital is required
to perform at least 100 operations of each type. The
hospital has set the following goals (listed in order
of priority):
■Goal 1: Earn a daily profit of at least $100,000.
■Goal 2: Use at most 50 hours daily of X-ray time.
■Goal 3: Use at most 40 hours daily of laboratory
time. 
Use goal programming to determine the types of
operations that should be performed.
16-34 Chapter 16
Multiobjective Decision Making
38. Jobs at Indiana University are rated on three factors:
■Factor 1: Complexity of duties
■Factor 2: Education required
■Factor 3: Mental and/or visual demands
For each job at IU, the requirement for each factor
has been rated on a scale of 1 to 4, with a 4 in factor
1 representing high complexity of duty, a 4 in factor
2 representing high educational requirement, and a 4 in
factor 3 representing high mental and/or visual
demands. IU wants to determine a formula for grading
each job. To do this, it will assign a point value to the
score for each factor that a job requires. For example,
suppose that level 2 of factor 1 yields a point total of 
10, level 3 of factor 2 yields a point total of 20, and
level 3 of factor 3 yields a point total of 30. Then a job
with these requirements has a point total of 10  20 
30  60. A job’s hourly salary equals half its point
total. IU has two goals (listed in order of priority) in set-
ting up the points given to each level of each job factor.
■Goal 1: When increasing the level of a factor by 1,
the points should increase by at least 10. For exam-
ple, level 2 of factor 1 should earn at least 10 more
points than level 1 of factor 1. Goal 1 is to mini-
mize the sum of deviations from this requirement.
■Goal 2: For the benchmark jobs referred to in the
file P16_38.xlsx, the actual point total for each job
should come as close as possible to the point total
listed in the table. Goal 2 is to minimize the sum of
the absolute deviations of the point totals from the
desired scores.
Use goal programming to find appropriate point totals.
What salary should a job with skill levels of 3 for each
factor be paid?
39. You are trying to determine which city to live in.
New York and Chicago are under consideration. Four
objectives will determine your decision: housing cost,
cultural opportunities, quality of schools and universi-
ties, and crime level. The weight for each objective is
in the file P16_39.xlsx. For each objective (except for
quality of schools and universities), New York and
Chicago scores are also given in this file. Suppose that
the score for each city on the quality of schools and
universities depends on two things: a score on public
school quality and a score on university quality. The
pairwise comparison matrix for public school and
university quality is also shown in this file. To see how
each city scores on public school quality and univer-
sity quality, use the pairwise comparison matrices also
shown in this file. You should be able to derive a score
for each city on the quality of schools and universities
objective. Then use AHP to determine where you
should live.
40. At Lummins Engine Corporation, production employees
work 10 hours per day, four days per week. Each day of
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

the week, at least the following number of employees
must be working: Monday through Friday, seven employ-
ees; Saturday and Sunday, three employees. Lummins
has set the following goals, listed in order of priority:
■Goal 1: Meet employee requirements with 
11 workers.
■Goal 2: The average number of weekend days off
per employee should be at least 1.5 days.
■Goal 3: The average number of consecutive days
off an employee gets during the week should not
exceed 2.8 days.
Use goal programming to determine how to schedule
Lummins employees.
41. You are the mayor of Gotham City and you must
determine a tax policy for the city. Five types of taxes
are used to raise money:
■Property taxes. Let p be the property tax rate.
■A sales tax on all items except food, drugs, and
durable goods. Let s be the sales tax rate.
■A sales tax on durable goods. Let d be the durable
goods sales tax rate.
■A gasoline sales tax. Let g be the gasoline sales tax
rate.
■A sales tax on food and drugs. Let f be the sales tax
on food and drugs.
The city consists of three groups of people: low
income (LI), middle income (MI), and high income
(HI). The amount of revenue (in millions of dollars)
raised from each group by setting a particular tax at a
1% level is given in the file P16_41.xlsx. For example,
a 3% tax on durable good sales will raise 360 million
dollars from low-income people. Your tax policy must
satisfy the following restrictions:
■Restriction 1: The tax burden on MI people cannot
exceed $2.8 billion.
■Restriction 2: The tax burden on HI people cannot
exceed $2.4 billion.
■Restriction 3: The total revenue raised must exceed
the current level of $6.5 billion.
■Restriction 4: s must be between 1% and 3%.
Given these restrictions, the city council has set the
following three goals (listed in order of priority):
■Goal 1: Limit the tax burden on LI people to 
$2 billion.
■Goal 2: Keep the property tax rate under 3%.
■Goal 3: If their tax burden becomes too high, 20%
of the LI people, 20% of the MI people, and 40%
of the HI people may consider moving to the sub-
urbs. Suppose that this will happen if their total tax
burden exceeds $1.5 billion. To discourage this
exodus, goal 3 is to keep the total tax burden on
these people below $1.5 billion.
Use goal programming to determine an optimal tax
policy.
16.5 Conclusion
16-35
42. Based on Sartoris and Spruill (1974). Wivco produces
two products, which it sells for both cash and credit.
Revenues from credit sales will not have been received
but are included in determining profit earned during
the current six-month period. Sales during the next six
months can be made either from units produced during
the next six months or from beginning inventory.
Relevant information about products 1 and 2 is as
follows.
■During the next six months, at most 150 units of
product 1 can be sold on a cash basis, and at most
100 units of product 1 can be sold on a credit
basis. It costs $35 to produce each unit of product
1, and each sells for $40. A credit sale of a unit of
product 1 yields $0.50 less profit than a cash sale
(because of delays in receiving payment). Two
hours of production time are needed to produce
each unit of product 1. At the beginning of the
six-month period, 60 units of product 1 are in
inventory.
■During the next six months, at most 175 units of
product 2 can be sold on a cash basis, and at most
250 units of product 2 can be sold on a credit basis.
It costs $45 to produce each unit of product 2, and
each sells for $52.50. A credit sale of a unit of
product 2 yields $1.00 less profit than a cash sale.
Four hours of production time are needed to pro-
duce each unit of product 2. At the beginning of the
six-month period, 30 units of product 2 are in
inventory.
■During the next six months, Wivco has 1000 hours
for production available. At the end of the next
six months, Wivco incurs a 10% holding cost on
the value of ending inventory (measured relative to
production cost). An opportunity cost of 5% is also
assessed against any cash on hand at the end of the
six-month period.
a. Develop and solve an LP model that yields Wivco’s
maximum profit during the next six months. What
is Wivco’s ending inventory position? Assuming an
initial cash balance of $0, what is Wivco’s ending
cash balance?
b. Because an ending inventory and cash position of
$0 is undesirable (for ongoing operations), Wivco
is considering other options. At the beginning of
the six-month period, Wivco can obtain a loan
(secured by ending inventory) that incurs an interest
cost equal to 5% of the value of the loan. The maxi-
mum value of the loan is 75% of the value of the
ending inventory. The loan will be repaid one year
from now. Wivco has the following goals (listed in
order of priority):
■
Goal 1: Make the ending cash balance of Wivco
come as close as possible to $75.
■
Goal 2: Make profit come as close as possible
to the profit level obtained in part a.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

■
Goal 3: At any time, Wivco’s current ratio is
defined to be
Current ratio 
Assuming initially that current liabilities equal
$150, six months from now Wivco’s current ratio
will equal
Current ratio 
where CB is the ending cash balance, AR is the
value of accounts receivable, and EI is the value
of the ending inventory. Six months from now,
Wivco wants the current ratio to be as close as
possible to 2.
Use goal programming to determine Wivco’s produc-
tion and financial strategy.
Modeling Problems
43. How might you use goal programming to help
Congress balance the budget?
44. A company is considering buying up to five other
businesses. Given knowledge of the company’s view
of the trade-off between risk and return, how could
trade-off curves be used to determine the companies
that should be purchased?
CR  AR  EI

150  Size of loan
Wivco’s assets

Wivco’s liabilities
16-36 Chapter 16
Multiobjective Decision Making
45. How would you use AHP to determine the greatest
sports record of all time? (Many believe it is Joe
DiMaggio’s 56-game hitting streak.)
46. You are planning to renovate a hospital. How would
you use AHP to help determine what improvements to
include in the renovation?
47. You are planning to overhaul a hospital computer
system. How would you use AHP to determine the
type of computer system to install?
48. You have been commissioned to assign 100 remedial
education teachers to the 40 schools in the St. Louis
School System. What are some objectives you might
consider in assigning the teachers to schools?
49. You have been hired as a consultant to help design a new
airport in northern Indiana that will supplant O’Hare as
Chicago’s major airport. Discuss the objectives you con-
sider important in designing and locating the airport.
50. In the Indiana MBA program we need to divide a class
of 60 students into 10 six-person teams. In the interest
of diversity, we have the following goals (listed in
descending order of importance):
■At least one woman per team
■At least one member of a minority per team
■At least one student with a financial or accounting
background per team
■At least one engineer per team
Explain how you could use the material in this chapter
to develop a model to assign students to teams.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

C A S E
P
lay Time Toy faces a highly seasonal pattern of
sales. In the past, Play Time has used a seasonal
production schedule, where the amount produced
each month matches the sales for that month. Under
this production plan, inventory is maintained at a
constant level. The production manager, Thomas
Lindop, is proposing a switch to a level, or constant,
production schedule. This schedule would result in
significant savings in production costs but would
have higher storage and handling costs, fluctuating
levels of inventories, and implications for financing.
Jonathan King, president of Play Time Toy, has been
reviewing pro forma income statements, cash bud-
gets, and balance sheets for the coming year under
the two production scenarios. Table 16.9 shows the
pro forma analysis under seasonal production, and
Table 16.10 shows the pro forma analysis under level
production.
16.1 PLAY TIME TOY COMPANY
Case 16.1 Play Time Toy Company
16-37
Table 16.9 Seasonal Production
Annual net profit
237
Play Time Toy Company
Projected for 2011
Actual
Dec 2010
Jan
Feb
Mar
Apr
May
June
July
Aug
Sept
Oct
Nov
Dec
Total
Production 
850
108
126
145
125
125
125
145
1,458
1,655
1,925
2,057
1,006
9000
(sales value)
Inventory 
813
813
813
813
813
813
813
813
813
813
813
813
813
(sales value)
INCOME 
STATEMENT
Jan
Feb
Mar
Apr
May
June
July
Aug
Sept
Oct
Nov
Dec
Total
Net sales
108
126
145
125
125
125
145
1,458
1,655
1,925
2,057
1,006
9,000
Cost of goods sold
Materials and
70
82
94
81
81
81
94
950
1,079
1,254
1,340
656
5,865
regular wages 
Overtime wages
0
0
0
0
0
0
0
61
91
131
151
0
435
Gross profit
38
44
51
44
44
44
51
447
486
539
565
350
2,700
Operating expenses
188
188
188
188
188
188
188
188
188
188
188
188
2,256
Inventory cost
0
0
0
0
0
0
0
0
0
0
0
0
0
Profit before 
(150)
(144)
(137)
(144)
(144)
(144)
(137)
259
298
351
377
162
444
interest and taxes
Net interest 
10
2
1
1
2
2
2
3
7
18
19
19
86
payments
Profit before taxes
(160)
(146)
(138)
(146)
(146)
(147)
(140)
256
290
333
359
144
358
Taxes
(55)
(50)
(47)
(50)
(50)
(50)
(48)
87
99
113
122
49
122
Net profit
(106)
(97)
(91)
(96)
(97)
(97)
(92)
169
192
220
237
95
237
Projected for 2011
BALANCE Actual 
SHEET
Dec 2010
Jan
Feb
Mar
Apr
May
June
July
Aug
Sept
Oct
Nov
Dec
Cash
175
782
1,365
1,116
934
808
604
450
175
175
175
175
175
Accts receivable
2,628
958
234
271
270
250
250
270
1,603
3,113
3,580
3,982
3,063
Inventory
530
530
530
530
530
530
530
530
530
530
530
530
530
Net P/E
1,070
1,070
1,070
1,070
1,070
1,070
1,070
1,070
1,070
1,070
1,070
1,070
1,070
Total Assets
4,403
3,340
3,199
2,987
2,804
2,658
2,454
2,320
3,378
4,888
5,355
5,757
4,838
Accts payable
255
32
38
44
38
38
38
44
437
497
578
617
302
Notes payable
680
0
0
0
0
0
0
0
408
1,600
1,653
1,656
966
Accrued taxes
80
25
(24)
(151)
(232)
(282)
(363)
(411)
(324)
(256)
(143)
(21)
(4)
Long term debt
450
450
450
450
450
450
425
425
425
425
425
425
400
Equity
2,938
2,832
2,736
2,644
2,548
2,452
2,355
2,263
2,431
2,623
2,843
3,080
3,175
Total liability 
4,403
3,340
3,199
2,987
2,804
2,658
2,454
2,320
3,378
4,888
5,355
5,757
4,838
and equity
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

16-38 Chapter 16
Multiobjective Decision Making
Greg Cole, chief financial officer of Play Time,
prepared the two tables. He explained that the pro
forma analyses in Tables 16.9 and 16.10 take fully into
account the 11% interest payments on the
unsecured loan from Bay Trust Company and the
3% interest received from its cash account. An inter-
est charge of 11%/12 on the balance of the loan at
the end of a month must be paid the next month.
Similarly, an interest payment of 3%/12 on the cash
balance at the end of a month is received in the
next month.
The inventory available at the end of
December 2010 is $530,000 (measured in terms of
cost to produce). Mr. Cole assumed that this inven-
tory represents a sales value of $530,0000.651667
 $813,300.
Table 16.10 Level Production
Annual net profit
373
Play Time Toy Company
Projected for 2011
Actual 
Dec 2010
Jan
Feb
Mar
Apr
May
June
July
Aug
Sept
Oct
Nov
Dec
Total
Production 
850 
750 
750 
750 
750 
750 
750 
750 
750 
750 
750 
750 
750 
9000
(sales value) 
Inventory 
813 
1455 
2079 
2684 
3309 
3934 
4559 
5164 
4456 
3551 
2376 
1069 
813 
(sales value) 
INCOME
STATEMENT
Jan F
eb 
Mar 
Apr 
May 
June 
July 
Aug 
Sept 
Oct 
Nov 
Dec 
Total 
Net sales
108 
126 
145 
125 
125 
125 
145 
1,458 
1,655 
1,925 
2,057 
1,006 
9,000 
Cost of goods sold 
Materials and 
70 
82 
94 
81 
81 
81 
94 
950 
1,079 
1,254 
1,340 
656 
5,865
regular wages
Overtime wages
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
Gross profit
38 
44 
51 
44 
44 
44 
51 
508 
576 
671 
717 
350 
3,135 
Operating expenses
188 
188 
188 
188 
188 
188 
188 
188 
188 
188 
188 
188 
2,256 
Inventory cost
0 
2 
6 
10 
13 
17 
20 
16 
11 
4 
0 
0 
100 
Profit before interest
(150) 
(147) 
(143) 
(154) 
(158) 
(161) 
(158) 
304 
377 
478 
529 
162 
779
and taxes
Net interest 
10 
3 
2 
5 
10 
15 
21 
26 
32 
37 
31 
22 
214
payments 
Profit before taxes
(160) 
(149) 
(146) 
(159) 
(168) 
(177) 
(179) 
277 
346 
441 
498 
141 
565 
Taxes
(55) 
(51) 
(50) 
(54) 
(57) 
(60) 
(61) 
94 
118 
150 
169 
48 
192 
Net profit
(106) 
(99) 
(96) 
(105) 
(111) 
(117) 
(118) 
183 
228 
291 
329 
93 
373 
BALANCE Actual
Projected for 2011
SHEET Dec 
2010
Jan 
Feb 
Mar 
Apr 
May 
June 
July 
Aug 
Sept 
Oct 
Nov 
Dec 
Cash 
175 
556 
724 
175 
175 
175 
175 
175 
175 
175 
175 
175 
175 
Accts receivable 
2,628 
958 
234 
271 
270 
250 
250 
270 
1,603 
3,113 
3,580 
3,982 
3,063 
Inventory 
530 
948 
1,355 
1,749 
2,157 
2,564 
2,971 
3,365 
2,904 
2,314 
1,549 
697 
530 
Net P/E 
1,070 
1,070 
1,070 
1,070 
1,070 
1,070 
1,070 
1,070 
1,070 
1,070 
1,070 
1,070 
1,070 
Total Assets 
4,403 
3,533 
3,383 
3,265 
3,672 
4,059 
4,466 
4,880 
5,752 
6,672 
6,374 
5,924 
4,838 
Accts payable 
255 
225 
225 
225 
225 
225 
225 
225 
225 
225 
225 
225 
225 
Notes payable 
680 
0 
0 
108 
704 
1,259 
1,900 
2,493 
3,087 
3,693 
2,953 
2,005 
836 
Accrued taxes 
80 
25 
(25) 
(155) 
(240) 
(297) 
(389) 
(450) 
(355) 
(269) 
(119) 
50 
66 
Long term debt 
450 
450 
450 
450 
450 
450 
425 
425 
425 
425 
425 
425 
400 
Equity 
2,938 
2,832 
2,734 
2,637 
2,533 
2,422 
2,305 
2,187 
2,370 
2,599 
2,890 
3,218 
3,311 
Total liability 
4,403 
3,533 
3,383 
3,265 
3,672 
4,059 
4,466 
4,880 
5,752 
6,672 
6,374 
5,924 
4,838 
and equity 
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Case 16.1 Play Time Toy Company 
16-39
The inventory and overtime costs in Tables 16.9
and 16.10 are based on the cost information devel-
oped by Mr. Lindop. This information is summarized
in Table 16.11.
Mr. Cole further explained how the cost infor-
mation was used in the pro forma analyses. For
example, in Table 16.9, the production in August is
$1,458,000. The overtime cost in August is therefore
calculated to be $61,000 ( 0.15 	 (1,458,000 
1,049,000)). Play Time uses LIFO (last-in, first-out)
accounting, so overtime costs are always charged in
the month that they occur.4 The annual overtime
cost for the seasonal production plan is $435,000. In
Table 16.10, under level production, finished goods
worth $5,164,000 are in inventory at the end of July.
The inventory cost for the month is $20,000 
( 0.0712 	 (5,164,000  1,663,000)). The annual-
inventory cost for the level production plan is
$100,000.
Mr. Lindop felt that a minimum of $813,300 of
inventory (measured in terms of sales value, or
$530,000 measured in terms of cost to produce)
must be kept on hand at the end of each month. This
inventory level represents a reasonable safety stock,
which is required because orders do not occur
uniformly during a month.
Mr. King was impressed at the possible
increase in profit from $237,000 under the seasonal
production plan to $373,000 under level production.
While studying the pro forma projections, Mr. King
realized that some combination of the two produc-
tion plans might be even better. He asked Mr. Lindop
to try to find a production plan with a higher profit
than the seasonal and level plans.
Mr. Lindop proceeded to develop a spreadsheet-
based LP model to maximize annual net profit.
Question
Note: Mr. Lindop’s model is contained in the file.
Play Time.xlsx.The spreadsheet is ready to be
optimized, but it has not been optimized yet.
1.
Run the optimization model in this file.
What is the optimal production plan? What is
the optimal annual net profit? How does this
optimal production plan compare to the
seasonal and level production plans?
2.
Suppose that Play Time’s bankers will not extend
any credit over $1.9 million—in other words,
the loan balance in any month cannot exceed
$1.9 million. Modify the spreadsheet model to
take into account this restriction. What is the
optimal production plan in this case? What is
the optimal annual net profit?
3.
Annual profit is a measure of reward for Play
Time Toy. The maximum loan balance is a
measure of risk for the bank. Construct a trade-
off curve between optimal annual profit and the
maximum loan balance. ■
Table 16.11 Play Time Cost Information
■
Gross margin. The cost of goods sold (excluding overtime costs) is 65.1667% of sales under any production schedule.
Materials costs are 30% of sales. All other nonmaterial costs, including regular wages but excluding overtime wages, are
35.1667% of sales.
■
Overtime cost. Running at capacity but without using any overtime, the plant can produce $1,049,000 of monthly sales.
Units produced in excess of this capacity in a month incur an additional overtime cost of 15% of sales. (The monthly pro-
duction capacity of the plant running on full overtime is $2,400,000 of sales. Since November has the maximum level of
projected sales at $2,057,000, the capacity on full overtime should never pose a problem.)
■
Inventory cost. The plant has a limited capacity to store finished goods. It can store $1,663,000 worth of sales at the
plant. Additional units must be moved and stored in rented warehouse space. The cost of storage, handling, and insurance
of finished goods over this capacity is 7% of the sales value of the goods per year, or 7%/12 per month.
4This assumes that overtime production is used only to satisfy
current demand and not to build up inventory.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Altschuler, S., D. Batavia, J. Bennett, R. Labe, B. Liao,
R. Nigam, and J. Oh. “Pricing Analysis for Merrill
Lynch Integrated Choice.” Interfaces 32, no. 1 (2002):
5–19.
Angel, A., L. Taladriz, and R. Weber. “Soquimich Uses a
System Based on Mixed-Integer Linear Programming
and Expert Systems to Improve Customer Service.”
Interfaces 33, no. 4 (2003): 41–52.
Apte, A., U. Apte, R. Beatty, I. Sarkar, and J. Semple. “The
Impact of Check Sequencing on NSF (Not-Sufficient
Funds) Fees.” Interfaces 34, no. 2 (2004): 97–105.
Armacost, A., C. Barnhart, K. Ware, and A. Wilson. “UPS
Optimizes Its Air Network.” Interfaces 34, no. 1 (2004):
15–25.
Austin, L. “Project EOQ: A Success Story in Implementing
Academic Research.” Interfaces 7, no. 4 (1977): 1–14.
Avriel, M., H. Pri-Zan, R. Meiri, and A. Peretz. “Opti-
Money at Bank Hapoalim: A Model-Based Investment
Decision-Support System for Individual Customers.”
Interfaces 34, no. 1 (2004): 39–50.
Babich, P. “Customer Satisfaction: How Good Is Good
Enough?” Quality Progress 25 (Dec. 1992): 65–68.
Bahurmoz, A. “The Analytic Hierarchy Process at Dar 
Al-Hekma, Saudi Arabia.” Interfaces 33, no. 4 (2003):
70–78.
Balson, W., J. Welsh, and D. Wilson. “Using Decision
Analysis and Risk Analysis to Manage Utility
Environmental Risk.” Interfaces 22, no. 6 (1992):
126–139.
Bangash, A., R. Bollapragada, R. Klein, N. Raman,
H. Shulman, and D. Smith. “Inventory Requirements
Planning at Lucent Technologies.” Interfaces 34, no. 5
(2004): 342–352.
Bassett, M., L. L. Gardner, and K. Steele. “Dow
AgroSciences Uses Simulation-Based Optimization
to Schedule the New-Product Development Process.”
Interfaces 34, no. 6 (2004): 426–437. 
Baumol, W. “The Transactions Demand for Cash: An
Inventory Theoretic Approach.” Quarterly Journal
of Economics 16 (1952): 545–556.
Bean, J., C. Noon, and G. Salton. “Asset Divestiture at
Homart Development Company.” Interfaces 17, no. 1
(1987): 48–65.
———, S. Ryan, and G. Salton. “Selecting Tenants in a
Shopping Mall.” Interfaces 18, no. 2 (1988): 1–10.
Benninga, S. Numerical Methods in Finance. Cambridge,
MA: MIT Press, 1989.
Billington, C., G. Callioni, B. Crane, J. Ruark, J. Rapp,
T. White, and S. Willems. “Accelerating the Profitability
of Hewlett-Packard’s Supply Chains.” Interfaces 34,
no. 1 (2004): 59–72.
Black, F., and M. Scholes. “The Pricing of Options and
Corporate Liabilities.” Journal of Political Economy 81
(1973): 637–654.
Blakeley, F., B. Bozkaya, B. Cao, W. Hall, and
J. Knolmajer. “Optimizing Periodic Maintenance
Operations for Schindler Elevator Corporation.”
Interfaces 33, no. 1 (2003): 67–79.
Borison, A. “Oglethorpe Power Corporation Decides about
Investing in a Major Transmission System.” Interfaces
25, no. 2 (1995): 25–36.
Boykin, R. “Optimizing Chemical Production at
Monsanto.” Interfaces 15, no. 1 (1985): 88–95.
Brams, S., and A. Taylor. The Win-Win Solution. New York:
Norton, 2000.
Brout, D. “Scientific Management of Inventory on a Hand-
Held Calculator.” Interfaces 11, no. 6 (1981): 57–69.
Brown, G., J. Keegan, B. Vigus, and K. Wood.
“The Kellogg Company Optimizes Production,
Inventory, and Distribution.” Interfaces 31, no. 6 (2001):
1–15.
———, R. Dell, and A. Newman. “Optimizing Military
Capital Planning.” Interfaces 34, no. 6 (2004): 415–425.
———, R. Dell, H. Holtz, and A. Newman. “How US Air
Force Space Command Optimizes Long-Term
Investment in Space Systems.” Interfaces 33, no. 4
(2003): 1–14. 
Brumelle, S. “On the Relation between Customer and Time
Averages in Queues.” J. of Applied Probability 8 (1971):
508–520.
Bukiet, B., H. Rusty, and J. Palacios, “A Markov Chain
Model of Baseball,” Operations Research 45, no. 1
(1997): 14–23.
Butler, J., A. Chebeskov, J. Dyer, T. Edmunds, J. Jia,
and V. Oussanov. “The United States and Russia
Evaluate Plutonium Disposition Options with
Multiattribute Utility Theory.” Interfaces 35, no. 1
(2005): 88–101.
Cachon, G., and C. Terwiesch. Matching Supply with
Demand: An Introduction to Operations Management,
2nd edition. New York: McGraw-Hill, 2009.
Callen, J. “DEA: Partial Survey and Applications for
Managerial Accounting.” Journal of Management
Accounting Research 3 (1991): 35–56.
907
REFERENCES
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

908
References
Carino, H., and C. Lenoir. “Optimizing Wood Procurement
in Cabinet Manufacturing.” Interfaces 18, no. 2 (1988):
11–19.
Caulkins, J., E. Kaplan, P. Lurie, T. O’Connor, and S. Ahn.
“Can Difficult-to-Reuse Syringes Reduce the Spread of
HIV Among Injection Drug Users?” Interfaces 28, no. 3
(1998): 23–33.
Chalermkraivuth, K. C., S. Bollapragada, M. C. Clark,
J. Deaton, L. Kiaer, J. P. Murdzek, W. Neeves, B. J.
Scholz, and D. Toledano. “GE Asset Management,
Genworth Financial, and GE Insurance Use a
Sequential-Linear-Programming Algorithm to Optimize
Portfolios.” Interfaces 35, no. 5 (2005): 370–380.
Charnes, A., and W. W. Cooper. “Generalization of the
Warehousing Model.” Operational Research Quarterly
6 (1955): 131–172.
———, W. W. Cooper, and R. O. Ferguson. “Optimal
Estimation of Executive Compensation by Linear
Programming.” Management Science 1, no. 2 (1955):
131–151.
Clemen, R., and R. Kwit. “The Value of Decision Analysis
at Eastman Kodak Company, 1990–1999.” Interfaces
31, no. 5 (2001): 74–92.
Cox, J., S. Ross, and M. Rubinstein. “Option Pricing:
A Simplified Approach.” Journal of Financial
Economics 7 (1979): 229–263.
Dantzig, G. “The Diet Problem.” Interfaces 20, no. 4
(1990): 43–47.
Davis, L. Handbook of Genetic Algorithms. New York: 
Van Nostrand Reinhold (1991).
de Kok, T., F. Janssen, J. van Doremalen, E. van Wachem,
M. Clerkx, and W. Peeters. “Philips Electronics
Synchronizes Its Supply Chain to End the Bullwhip
Effect.” Interfaces 35, no. 1 (2005): 37–48.
Dekle, J., M. Lavieri, E. Martin, H. Emir-Farinas, and
R. Francis. “A Florida County Locates Disaster
Recovery Centers.” Interfaces 35, no. 2 (2005): 113–139.
Deming, E. Out of the Crisis. Cambridge, MA: MIT Center
for Advanced Engineering Study, 1986.
Denardo, E., U. Rothblum, and A. Swersey.
“Transportation Problem in Which Costs Depend on
Order of Arrival.” Management Science 34 (1988):
774–784.
DeWitt, C., L. Lasdon, A. Waren, D. Brenner, and
S. Melhem. “OMEGA: An Improved Gasoline Blending
System for Texaco.” Interfaces 19, no. 1 (1989):
85–101.
Dobson, G., and S. Kalish. “Positioning and Pricing
a Product Line.” Marketing Science 7 (1988): 107–126.
Dolan, R., and H. Simon, Power Pricing. New York:
The Free Press, 1996.
Duffy, T., M. Hatzakis, W. Hsu, R. Labe, B. Liao, X. Luo,
J. Oh, A. Setya, and L. Yang. “Merrill Lynch Improves
Liquidity Risk Management for Revolving Credit
Lines.” Interfaces 35, no. 5 (2005): 353–369.
Dunning, D., S. Lockfort, Q. Ross, P. Beccue, and
J. Stonebraker. “New York Power Authority Uses
Decision Analysis to Schedule Refueling of Its Indian
Point 3 Nuclear Power Plant.” Interfaces 31, no. 5
(2001): 121–135.
Eaton, D., M. Daskin, D. Simmons, B. Bulloch, and
G. Jasma. “Determining Emergency Medical Service
Vehicle Deployment in Austin, Texas.” Interfaces 15,
no. 1 (1985): 96–108.
Efroymson, M., and T. Ray. “A Branch and Bound
Algorithm for Factory Location.” Operations Research
14 (1966): 361–368.
Evans, J. “The Factored Transportation Problem.”
Management Science 30 (1984): 1021–1024.
Feinstein, C. “Deciding Whether to Test Student Athletes
for Drug Use.” Interfaces 20, no. 3 (1990): 80–87.
Fitzsimmons, J., and L. Allen. “A Warehouse
Location Model Helps Texas Comptroller Select 
Out-of-State Audit Offices.” Interfaces 13, no. 5 (1983):
40–46.
Fleischmann, M., J. van Nunen, and B. Grave. “Integrating
Closed-Loop Supply Chains and Spare-Parts
Management at IBM.” Interfaces 33, no. 6 (2003):
44–56.
Franklin, A., and E. Koenigsberg. “Computer School
Assignments in a Large District.” Operations Research
21 (1973): 413–426.
Franses, P. “Do We Think We Make Better Forecasts
Than in the Past? A Survey of Academics.” Interfaces
34, no. 6 (2004): 466–468.
Friel, B. “Medicare Transactions: A $50 Million Lesson
in Project Management.” Government Executive
(April 2000).
Gaballa, A., and W. Pearce. “Telephone Sales Manpower
Planning at Qantas.” Interfaces 9, no. 3 (1979): 1–9.
Garvin, W. W. Introduction to Linear Programming.
New York: McGraw-Hill, 1960.
Gavirneni, S., D. Morrice, and P. Mullarkey. “Simulation
Helps Maxager Shorten Its Sales Cycle.” Interfaces 34,
no. 1 (2004): 87–96.
———, L. Clark, and G. Pataki. “Schlumberger Optimizes
Receiver Location for Automated Meter Reading.”
Interfaces 34, no. 3 (2004): 208–214.
Gendron, B. “Scheduling Employees in Quebec’s Liquor
Stores with Integer Programming.” Interfaces 35, no. 5
(2005): 402–410.
Gido, J., and G. Clements. Successful Project Management,
3rd edition. Mason, OH: Thomson South-Western (2006).
Glassey, R., and V. Gupta. “A Linear Programming
Analysis of Paper Recycling.” Studies in Mathematical
Programming. Ed. H. Salkin and J. Saha. New York:
North-Holland, 1978.
Glover, F., and D. Klingman. “Network Applications in
Industry and Government.” AIIE Transactions 9 (1977):
363–376.
Goldberg, D. Genetic Algorithms in Search Optimization
and Machine Learning. Boston: Addison-Wesley, 1989.
Golden, B., E. Wasil, and P. Harker. The Analytic Hierarchy
Process. New York: Springer-Verlag, 1989.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

References
909
Gorman, M. “Santa Fe Railway Uses an Operating-Plan
Model to Improve Its Service Design.” Interfaces 28,
no. 4 (1998): 88–103.
Green, P., A. Krieger, and Y. Wind. “Thirty Years of
Conjoint Analysis: Reflections and Prospects.”
Interfaces 31, no. 3 (2): (2001): S56–S73.
Grossman, S., and O. Hart. “An Analysis of the Principal
Agent Problem.” Econometrica 51 (1983): 7–45.
Guide, V. D., L. Muyldermans, and L. van Wassenhove.
“Hewlett-Packard Company Unlocks the Value Potential
from Time-Sensitive Returns.” Interfaces 35, no. 4
(2005): 281–293.
Hansen, P., and R. Wendell. “A Note on Airline
Commuting.” Interfaces 11, no. 12 (1982): 85–87.
Heady, E., and A. Egbert. “Regional Planning of Efficient
Agricultural Patterns.” Econometrica 32 (1964): 374–386.
Heyman, D., and S. Stidham. “The Relation between
Customer and Time Averages in Queues.” Operations
Research 28 (1980): 983–984.
Hicks, R., R. Madrid, C. Milligan, R. Pruneau, M. Kanaley,
Y. Dumas, B. Lacroix, J. Desrosiers, and F. Soumis.
“Bombardier Flexjet Significantly Improves Its
Fractional Aircraft Ownership Operations.” Interfaces
35, no. 1 (2005): 49–60.
Holland, J. Adaptation in Natural and Artificial Systems.
Ann Arbor, MI: University of Michigan Press, 1975.
Holland, J. Adaptation in Natural and Artificial Systems.
Cambridge, MA: MIT Press, 1992.
Hoppensteadt, F., and C. Peskin. Mathematics in Medicine
and the Life Sciences. New York: Springer-Verlag, 1992.
Howard, R. “Decision Analysis: Practice and Promise.”
Management Science 34, no. 6 (1988): 679–695.
Huerter, J., and W. Swart. “An Integrated Labor-Management
System for Taco Bell.” Interfaces 28, no. 1 (1998): 75–91.
Ignall, E., and P. Kolesar. “Operating Characteristics of a
Simple Shuttle under Local Dispatching Rules.”
Operations Research 20 (1972): 1077–1088.
Jacobs, W. “The Caterer Problem.” Naval Logistics
Research Quarterly 1 (1954): 154–165.
Johnson, R., and D. Wichern. Applied Multivariate
Statistical Analysis, 5th ed. Upper Saddle River, NJ:
Prentice Hall, 2002.
Kahn, J., M. Brandeau, and J. Dunn-Mortimer. “OR
Modeling and AIDS Policy: From Theory to Practice.”
Interfaces 28, No. 3 (1998): 3–22.
Kalvaitishi, R., and A. Posgay. “An Application of Mixed
Integer Programming in the Direct Mail Industry.”
Management Science 20, no. 5 (1974): 788–792.
Kapuscinski, R., R. Zhang, P. Carbonneau, R. Moore, and
B. Reeves. “Inventory Decisions in Dell’s Supply
Chain.” Interfaces 34, no. 3 (2004): 191–205.
Keefer, D., and S. Bodily. “Three-Point Approximations for
Continuous Random Variables.” Management Science
29, no. 5 (1983): 595–609.
Keisler, J., W. Buehring, P. McLaughlin, M. Robershotte, and
R. Whitfield. “Allocating Vendor Risks in the Hanford
Waste Cleanup.” Interfaces 34, no. 3 (2004): 180–190.
Kekre, S., U. Rao, J. Swaminathan, and J. Zhang.
“Reconfiguring a Remanufacturing Line at Visteon,
Mexico.” Interfaces 33, no. 6 (2003): 30–43.
Kelly, J. “A New Interpretation of Information Rate.” Bell
System Technical Journal 35 (1956): 917–926.
Kimbrough, S., and F. Murphy. “A Study of the
Philadelphia Knowledge Economy,” Interfaces 35, no. 3
(2005): 248–259.
Kirkwood, C. “An Overview of Methods for Applied
Decision Analysis.” Interfaces 22, no. 6 (1992): 28–39.
Klastorin, T. Project Management: Tools and Trade-Offs.
New York: Wiley, 2004.
Klingman, D., and N. Phillips. “Topological and
Computations Aspects of Preemptive Multicriteria
Military Personnel Assignment Problems.” Management
Science 30, no. 11 (1984): 1362–1375.
Kolesar, P., and E. Blum, “Square Root Laws for Fire
Engine Response Distances.” Management Science 19
(1973): 1368–1378.
———, T. Crabill, K. Rider, and W. Walker. “A Queueing
Linear Programming Approach to Scheduling Police
Patrol Cars.” Operations Research 23 (1974): 1045–1062.
Koschat, M., G. Berk, J. Blatt, N. Kunz, M. LePore, and
S. Blyakher. “Newsvendors Tackle the Newsvendor
Problem.” Interfaces 33, no. 3 (2003): 72–84.
Lancaster, L. “The Evolution of the Diet Model in
Managing Food Systems.” Interfaces 22, no. 5 (1992):
59–68.
Lanzenauer, C., E. Harbauer, B. Johnston, and D.
Shuttleworth. “RRSP Flood: LP to the Rescue.”
Interfaces 17, no. 4 (1987): 27–40.
Laval, C., M. Feyhl, and S. Kakouros. “Hewlett-Packard
Combined OR and Expert Knowledge to Design Its
Supply Chains.” Interfaces 35, no. 3 (2005): 238–247.
LeBlanc, L., D. Randels, Jr., and K. Swann. “Heery
International’s Spreadsheet Optimization Model for
Assigning Managers to Construction Projects.”
Interfaces 30, No. 6, (2000): 95–106.
———, J. Hill, G. Greenwell, and A. Czesnat. “Nu-kote’s
Spreadsheet Linear Programming Models for
Optimizing Transportation.” Interfaces 34, No. 2,
(2004): 139–146.
——— and M. Galbreth. “Designing Large-Scale Supply
Chain Linear Programs in Spreadsheets.”
Communications of the ACM 50, no. 8, (2007a): 59–64.
——— and M. Galbreth. “Implementing Large-Scale
Optimization Models in Excel Using VBA.” Interfaces
37, no. 4, (2007b): 370–382.
Lee, S., and L. Moore. “Optimizing University Admissions
Planning.” Decision Sciences 5 (1974): 405–414.
Liggett, R. “The Application of an Implicit Enumeration
Algorithm to the School Desegregation Problem.”
Management Science 20 (1973): 159–168.
Lin, W., T. Mock, and A. Wright. “The Use of AHP as an
Aid in Planning the Nature and Extent of Audit
Procedures.” Auditing: A Journal of Practice and
Theory 4, no. 1 (1984): 89–99.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

910
References
Lindsey, G., “Statistical Data Useful for the Operation of a
Baseball Team.” Operations Research 7, no. 2 (1959):
197–207.
Little, J. D. C. “A Proof for the Queueing Formula 
L  W.” Operations Research 9 (1961): 383–387.
Love, R., and J. Hoey. “Management Science Improves
Fast-Food Operations.” Interfaces 20, no. 2 (1990):
21–29.
Luenberger, D. Investment Science. Cambridge: Oxford
University Press, 1997.
Machol, R. “An Application of the Assignment Problem.”
Operations Research 18 (1970): 745–746.
Magoulas, K., and D. Marinos-Kouris. “Gasoline Blending
LP.” Oil and Gas Journal (July 1988): 44–48.
Makuch, W., J. Dodge, J. Ecker, D. Granfors, and G. Hahn.
“Managing Consumer Credit Delinquency in the US
Economy: A Multi-Billion Dollar Management Science
Application.” Interfaces 22, no. 1 (1992): 90–109.
Marchewka, J. Information Technology Project
Management, 2nd edition. New York: Wiley, 2006.
Marcus, A. “The Magellan Fund and Market Efficiency.”
Journal of Portfolio Management (Fall 1990): 90–109.
Martin, C., D. Jones, and P. Keskinocak. “Optimizing On-
Demand Aircraft Schedules for Fractional Aircraft
Operators.” Interfaces 33, no. 5 (2003): 22–35.
McBride, R., and F. Zufryden. “An Integer Programming
Approach to the Product Line Selection Problem.”
Marketing Science 7, no. 2 (1988): 126–139.
Meneses, C., Z. Lu, C. Oliveria, and P. Pardalos. “Optimal
Solutions for the Closest-String Problem via Integer
Programming.” Informs Journal on Computing 16, no. 4
(2004): 419–429.
Merrick, J., J. R. van Dorp, T. Mazzuchi, J. Harrald,
J. Spahn, and M. Grabowski. “The Prince William
Sound Risk Assessment.” Interfaces 32, no. 6 (2002):
25–40.
Metters, R., C. Queenan, M. Ferguson, L. Harrison,
J. Higbie, S. Ward, B. Barfield, T. Farley, H. A.
Kuyumcu, and A. Duggasani. “The Killer Application
of Revenue Management: Harrah’s Cherokee Casino &
Hotel.” Interfaces 38, no. 3 (2008): 161–175.
Miser, H. “Avoiding the Corrupting Lie of a Poorly Stated
Problem.” Interfaces 23, no. 6 (1993): 114–119.
Morrison, D., and R. Wheat. “Pulling the Goalie
Revisited.” Interfaces 16, no. 6 (1984): 28–34.
Moss, S., C. Dale, and G. Brame. “Sequence-Dependent
Scheduling at Baxter International.” Interfaces 30, no. 2
(2000): 70–80.
Muckstadt, J., and R. Wilson. “An Application of Mixed
Integer Programming Duality to Scheduling Thermal
Generating Systems.” IEEE Transactions on Power
Apparatus and Systems (1968): 1968–1978.
Norton, R. “A New Tool to Help Managers.” Fortune,
May 30, 1994, 135–140.
———. “Which Offices or Stores Perform Best? A New
Tool Tells.” Fortune, October 31, 1994.
Owens, D., M. Brandeau, and C. Sox. “Effect of Relapse to
High-Risk Behavior on the Costs and Benefits of a
Program to Screen Women for Human Immunodeficiency
Virus.” Interfaces 28, no. 3 (1998): 52–74.
Paltiel, A., and K. Freedberg. “The Cost-Effectiveness of
Preventing Cytomegalovirus Disease in AIDS Patients.”
Interfaces 28, no. 3 (1998): 34–51.
Patchong, A., T. Lemoine, and G. Kern. “Improving Car
Body Production at PSA Peugeot Citroen.” Interfaces 33,
no. 1 (2003): 36–49.
Pfeifer, P., S. Bodily, R. Carraway, D. Clyman, and S. Frey.
“Preparing Our Students to be Newsvendors.” Interfaces
31, no. 6 (2001): 112–122.
Porteus, E. “Investing in Reduced Setups in the EOQ Model.”
Management Science 31, no. 8 (1985): 998–1010.
Quinn, P., B. Andrews, and H. Parsons. “Allocating
Telecommunications Resources at L. L. Bean, Inc.”
Interfaces 21, no. 1 (1991): 75–91.
Ramaswami, V., D. Poole, S. Ahn, S. Byers, and A. Kaplan.
“Ensuring Access to Emergency Services in the
Presence of Long Internet Dial-Up Calls.” Interfaces 35,
no. 5 (2005): 411–422.
Ravindran, A. “On Compact Book Storage in Libraries.”
Opsearch 8 (1971): 245–252.
Reichheld, F. The Loyalty Effect. Cambridge, MA: Harvard
Business School Press, 1996.
Riccio, L., J. Miller, and A. Little. “Polishing the Big
Apple.” Interfaces 16, no. 1 (1986): 83–88.
Robichek, A., D. Teichroew, and M. Jones. “Optimal Short-
Term Financing Decisions.” Management Science 12
(1965): 1–36.
Robinson, P., L. Gao, and S. Muggenborg. “Designing an
Integrated Distribution System at DowBrands, Inc.”
Interfaces 23, no. 3 (1993): 107–117.
Rohn, E. “A New LP Approach to Bond Portfolio
Management.” Journal of Financial and Quantitative
Analysis 22 (1987): 439–467.
Rothstein, M. “Hospital Manpower Shift Scheduling by
Mathematical Programming.” Health Services Research
(1973).
Saaty, T. The Analytic Hierarchy Process. New York:
McGraw-Hill, 1988.
Sartoris, W., and M. Spruill. “Goal Programming and
Working Capital Management.” Financial Management
3 (1974): 67–74.
Schindler, S., and T. Semmel. “Station Staffing at Pan
American World Airways.” Interfaces 23, no. 3 (1993):
91–106.
Schrage, L. Optimization Modeling Using LINDO. Dubai,
UAE: ITP Publishing, 1997.
Schultmann, F., B. Engels, and O. Rentz. “Closed-Loop
Supply Chains for Spent Batteries.” Interfaces 33, no. 6
(2003): 57–71.
Sery, S., V. Presti, and D. E. Shobrys. “Optimization Models
for Restructuring BASF North America’s Distribution
System.” Interfaces 31, no. 3 (2001): 55–65.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

References
911
Sexton, T., S. Sleeper, and R. Taggart. “Improving Pupil
Transportation in North Carolina.” Interfaces 24, no. 1
(1994): 87–103.
Sherman, H. D., and G. Ladino. “Managing Bank
Productivity Using Data Envelopment Analysis (DEA).”
Interfaces 25, no. 2 (1995): 60–80.
Silver, E., D. Pyke, and R. Peterson. Inventory Management
and Production Planning and Scheduling, 3rd ed. New
York: Wiley, 1998.
Smith, S. “Planning Transistor Production by Linear
Programming.” Operations Research 13 (1965):
132–139.
So, K., C. Tang, and R. Zavala. “Models for Improving
Team Productivity at the Federal Reserve Bank.”
Interfaces 33, no. 2 (2003): 25–36.
Sohoni, M., T. G. Bailey, K. Martin, H. Carter, and E.
Johnson. “Delta Optimizes Continuing-Qualification-
Training Schedules for Pilots.” Interfaces 33, no. 5
(2003): 57–70.
Sonderman, D., and P. Abrahamson. “Radiotherapy Design
Using Mathematical Programming.” Operations
Research 33, no. 4 (1985): 705–725.
Spencer, T., A. Brigandi, D. Dargon, and M. Sheehan.
“AT&T’s Telemarketing Site Selection System Offers
Customer Support. Interfaces 20, no. 1 (1990): 83–96.
Spengler, T., and M. Schroter. “Strategic Management of
Spare Parts in Closed-Loop Supply Chains—A Sytem
Dynamics Approach.” Interfaces 33, no. 6 (2003): 7–17.
Srinivasan, M., S. Ebbing, and A. Swearingen. “Woodward
Aircraft Engine Systems Sets Work-in-Process Levels
for High-Variety, Low-Volume Products.” Interfaces 33,
no. 4 (2003): 61–69.
Steuer, R. “Sausage Blending Using Multiple Objective
Programming.” Management Science 30 (1984):
1376–1384.
Stidham, S. “A Last Word on L  W.” Operations
Research 22 (1974): 417–421.
Stonebraker, J. “How Bayer Makes Decisions to Develop
New Drugs.” Interfaces 32, no. 6 (2002): 77–90.
Tanner, M. Practical Queueing Analysis. Berkshire,
England: McGraw-Hill International (UK) Ltd., 1995.
Tavana, M. “CROSS: A Multicriteria Group-Decision-
Making Model for Evaluating and Prioritizing
Advanced-Technology Projects at NASA.” Interfaces
33, no. 3 (2003): 40–56.
Taylor, B., and A. Keown. “Planning Urban Recreational
Facilities with Goal Programming.” Journal of
Operational Research Society 29, no. 8 (1984): 751–758.
Thomas, J. “Linear Programming Models for Production
Advertising Decisions.” Management Science 17, no. 8
(1971): B474–B484.
Troyer, L., J. Smith, S. Marshall, E. Yaniv, S. Tayur, M.
Barkman, A. Kaya, and Y. Liu. “Improving Asset
Management and Order Fulfillment at Deere &
Company’s C&CE Division.” Interfaces 35, no. 1
(2005): 76–87.
Tyagi, R., P. Kalish, K. Akbay, and G. Munshaw. “GE
Plastics Optimizes the Two-Echelon Global Fulfillment
Network at Its High Performance Polymers Division.”
Interfaces 34, no. 5 (2004): 359–366.
van de Klundert, J. J. Kuipers, F. Spieksma, and M.
Winkels. “Selecting Telecommunication Carriers to
Obtain Volume Discounts.” Interfaces 35, no. 2 (2005):
124–132.
van den Briel, M., R. Villalobos, and G. Hogg. “America
West Airlines Develops Efficient Boarding Strategies.”
Interfaces 35, no. 3 (2005): 191–201.
van der Heijden, M., A. van Harten, M. Ebben, Y. Saanen,
E. Valentin, and A. Verbraeck. “Using Simulation to
Design an Automated Underground System for
Transporting Freight Around Schiphol Airport.”
Interfaces 32, no. 4 (2002): 1–19.
Vasko, F., J. Wolfe, and K. Stott. “Optimal Selection of
Ingot Sizes via Set Covering.” Operations Research 35,
no. 3 (1987): 346–353.
Volkema, R. “Managing the Process of Formulating
the Problem.” Interfaces 25, no. 3 (1995): 81–87.
Walkenbach, J. Excel Charts. New York: Wiley, 2002.
Walker, W. “Using the Set Covering Problem to Assign Fire
Companies to Firehouses.” Operations Research 22
(1974): 275–277.
Weber, S. “A Modified Analytic Hierarchy Process for
Automated Manufacturing Decisions.” Interfaces 23,
no. 4 (1993): 75–84.
Welling, P. “A Goal Programming Model for Human
Resource Allocation in a CPA Firm.” Accounting,
Organizations and Society 2 (1977): 307–316.
Westerberg, C., B. Bjorklund, and E. Hultman. “An
Application of Mixed Integer Programming in a
Swedish Steel Mill.” Interfaces 7, no. 2 (1977): 39–43.
Winston, W. Decision Making Under Uncertainty with
RISKOptimizer. Palisade Corporation, 1999.
———. Operations Research: Applications and Algorithms.
4th ed. Belmont, CA: Duxbury Press, 2003.
———. Introduction to Probability Models, 4th ed.
Belmont, CA: Brooks/Cole–Thomson Learning, 2004.
Yu, G., J. Pachon, B. Thengvall, D. Chandler, and A.
Wilson. “Optimizing Pilot Planning and Training for
Continental Airlines.” Interfaces 34, no. 4 (2004):
253–264.
———, M. Arguello, G. Song, S. McCowan, and A. White.
“A New Era for Crew Recovery at Continental
Airlines.” Interfaces 33, no. 1 (2003): 5–22.
Zahedi, F. “The Analytic Hierarchy Process—A Survey of
the Method and Its Applications.” Interfaces 16, no. 4
(1986): 96–108.
Zangwill, W. “The Limits of Japanese Production Theory.”
Interfaces 22, no. 5 (1992): 14–25.
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

913
0–1 variables, 294, 866
A
Absolute addresses, 29
Absolute percentage error (APE), 851
Activity-on-arc (AOA), 15-5
Activity-on-node (AON), 15-5
Additivity, 95
Adjusted R-square, 866
Advertising models, 135–145
advertising response function, 379–383
with nonlinear response functions,
383–387
Aggregate planning models, 152–162
Aircraft schedules, 280
Airline crew recovery, 280
Airline models
crew scheduling, 267–272
flight scheduling, 273–280
Algebraic models, 72
vs. spreadsheet models, 118–121
AllDifferent constraints, 465
Allen-Cunneen approximation, 802–806
Allocation of resources modeling
crashing the activities, 15-20–15-25
monitoring use of resources, 
15-14–15-20
scheduling multiple projects, 
15-25–15-28
AMARCO, Inc., 212–214
American Office Systems, Inc., 215–219
America West Airlines, 551–552
Analysis ToolPak add-in, 857
Arc capacities, 231
Arcs, 230
Array functions, 174
Asset allocation, 398
Assignment models, 241–247
Autocorrelation of residuals, 871–872
B
Backlogging, 158, 160–162, 718
Backordering, 158
Balking, 777
BASF North America, 227–228
Bayer Pharmaceuticals, 475–476
Bayes’ Rule, 505–508
Benefit-cost tables, 510–511
Binary variables, 294, 306
Binding constraints, 82, 83
Binomial distributions, 569–571
Biotechnical Engineering, 549–550
Blending constraints, 169
Blending models, 163–170
Bond investment strategy, 711
Bond portfolio optimization, 186
Bounded probability distributions, 558–559
Branch and bound algorithms, 144,
295–297
Breakeven analysis, 31–39
Butterfly spread, 666
C
Calculation settings with data tables, 583
Capital asset pricing model (CAPM),
55, 408
Carrying costs, 718
Cash balance models, 647–652
Categorical variables, 866
Causal forecasting models, 843
Cell comments, 34, 66
Certainty equivalents, 530
Changing cells, 36, 69, 146, 183
Chromosomes, 425
Churn, 464, 667
Clearing denominators, 170
Closed queueing networks (CQN), 774
Cluster analysis, 455–460
College fund investment, 710
Collusive duopoly models, 415
Column vector, 399
Combinatorial models, 438–447
Complete enumeration, 296
Concave functions, 356
Conditional Formatting tool, 51
Confidence interval for the mean, 581
Conjoint analysis, 432
Constant elasticity demand function, 362
Constraints, 69
AllDifferent, 465
binding, 82, 83
blending, 169
effect on objective, 86
either-or, 314
flow balance, 235, 249
in groups, 80
integer, 143–144, 157
nonbinding, 82, 83
nonnegativity, 69
Continental Airlines, 279–280
Contingency plans, 515
Continuous probability distributions, 556
Continuous review model, 717
Contract bidding, 623–627
Control charts, 638
Convergence, 430
Convex functions, 356
Correlated inputs, 610
Cost projections, 26–31
Cost table, 478
COUNTIF function, 253
COUNTIFS function, 463
Covariance matrix, 403
Covariances, 399
CPM. See Critical path model (CPM)
model
Craps game, 682–685
Crashing activities, 15-4, 15-14
CRITBINOM, 681
Critical activities, 15-6
Critical fractile, 737
Critical path model (CPM) model, 
15-4–15-12
Critical paths, 15-6
Curve fitting, 45
Customer averages, 784
Customer loyalty models, 667–676
Cutting stock models, 335–339
Cyclic component, 874, 875–876
D
Damping factors, 653
Data envelopment analysis (DEA),
188–194
banking industry, 194
hospital industry, 188–194
school bus transportation, 194
Data tables
calculation settings with, 583
one-way, 35–36
repeating simulations, 583
two-way, 42–44, 584–586
DEA. See Data envelopment
analysis (DEA)
Decision making under uncertainty
elements of, 478–491
introduction to, 476–478
Decision support systems (DSS), 118–121
Decision trees, 482–484
Decision variables, 22, 69
Delta Airlines, 280
Demand during lead time, 741
Demand forecasting, 904
Demand function, estimating, 362
Deming, Edwards, 637
Density function, 557
Dependent demand, 716
Dependent variable, 844
Descriptive models, 4–6
Deterministic checks, 579
Deterministic inventory models, 715, 716
Discontinuities, 424
Discount factor, 55
Discrete distributions, 565–566
Discriminant analysis, 461–464
INDEX
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

914
Index
Divisibility, 95
Dow AgroSciences, 15-1
Dow Consumer Products, 317–318
Drug production with uncertain yield,
632–637
Dual-objective optimization models,
139–141
Dummy variables, 866
Duration, 15-5
Dynamic scheduling models, 151
E
Earliest finish time, 15-8
Earliest start time, 15-8
Ebony Bath Soap, 620
Economic order quantity (EOQ) models,
718–734
basic model, 719
more than two products, 734
order synchronization, 731–734
with quantity discounts, 722–725
reducing setup cost, 728–729, 728–731
with shortages allowed, 725–728
Efficiency (with DEA), 192–194
Efficient frontier, 405
Either-or constraints, 314
Elasticity of demand, 362
EMV. See Expected monetary value
(EMV)
EMV criterion, 480
EMV maximizers, 481
Enumeration, 296
EOQ models. See Economic order quantity
(EOQ) models
Equipment replacement models, 261–266
Erlang loss models, 799
Evolutionary Solver, 423
introduction to, 426–431
portfolio optimization and, 452–455
settings for, 430
with SolverTable, 442
EVPI. See Expected value of perfect
information (EVPI)
EVSI. See Expected value of sample
information (EVSI)
Excel
calculation settings with data tables, 583
charts in, 29–31
creating time series graphs, 876
CTRL+Enter shortcut, 147
F9 recalc key, 555
Formula Auditing tool, 37–39
Goal Seek tool, 36–37
Paste Special Transpose, 173
recalculation (F9) key, 555
roundoff errors, 104
row and column sums shortcut, 156
scatterplots and, 849
Scenario Manager, 760
Excel add-ins
Analysis ToolPak, 18, 857
Evolver, 18
NeuralTools, 18
PrecisionTree, 18, 492–504
@RISK, 17
RISKOptimizer, 18
Solver, 17, 70, 128
Evolutionary algorithm, 423
nonsmooth functions and, 160
tolerance settings in, 149
SolverTable, 17, 87
StatTools, 17–18, 854
TopRank, 18, 691–699
Excel functions
array, 174
COUNTIF, 253
COUNTIFS, 463
CRITBINOM, 681
EXP, 852
IF, 24
INDEX, 459
MATCH, 435
matrix, 399
MMULT, 400–401
NPV, 58
RAND, 560
RANDBETWEEN, 560
SUMIF, 235–237
SUMPRODUCT, 44, 77–78
SUMXMY2, 390
TRANSPOSE, 173, 174, 400
VLOOKUP, 42
Excel tools
Add Trendline, 850
Conditional Formatting, 51
Trendline, 47, 362
Exchange rate considerations, 366–377
Exercise date, 658
Exercise price, 658
Expected monetary value (EMV), 480, 646
Expected payoff, 480
Expected utility, 525
Expected utility maximization, 526
Expected value of perfect information
(EVPI), 513, 523
Expected value of sample information
(EVSI), 513, 522
EXP function, 852
Explanatory variables, 844
other than time, 853–860
Exponential curves, 47
Exponential distribution, memoryless
property, 779
Exponential smoothing methods, 884–895
Exponential trend, 848
Exponential trend lines, 853
Exponential utility, 526–527
Exponential utility functions, 527
External demand, 716
Extrapolation models. See also Time series
models, 843, 874
limitations of, 878
moving averages models, 878–883
F
F9 key, 555
Facility location models, 388–393
Feasible regions, 70
Feasible solutions, 70
Financial holding costs, 718
Financial models, 177–186
cash balance models, 647–652
financial planning, 642–647
investment models, 652–657
stock prices and options simulation,
657–664
Finish-to-finish relationships, 15-12
Finish-to-start relationships, 15-12
First-come-first-served (FCFS), 777
Fitness functions, 425
Fitted values, 846
Fixed cost models, 306–318
Flaw of averages, 573–575
Flow balance constraints, 235, 249
Flows, 231
Folding-back procedures, 484
Forecast error, measures of, 877–878
Forecasting models, 843
Foreign currency trading, 225
Formula Auditing tool, 37–39
Free slack, 15-37
Freezing random numbers, 563
fx button, 42
G
Games of chance simulations
game of craps, 682–685
NCAA basketball tournaments, 685–689
Gamma distribution, 628
Gantt chart, 15-11
General Electric Company (GE), 67,
353–354
Genetic algorithms (GA), 425
penalties, 428
strengths and weaknesses of, 426
GE Plastics (GEP), 67
G/G/s models, 802
Giant Motor Company (GMC), 350–351
Global maximum, 355
Global minimum, 355
Global optimum, 355, 359
Gold mining stock (GMS) hedging,
419–420
Goodness-of-fit, measures of, 380, 846
Graphical solutions, 72–74
H
Heuristic, 151
Holding costs, 718
Holland, John, 425
Holt’s exponential smoothing method for
trend, 884, 888–892
Hospital efficiency, 188–194
I
IF functions, 312–314
Immediate predecessors, 15-5
Immediate successors, 15-5
Implicit enumeration, 296
Incumbent solutions, 296
Independent demand, 716
Independent variables, 844
INDEX function, 459
Indicator variables, 866
Inefficiency (in DEA), 192–194
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Index
915
Infeasibility, 97–99
Infeasible solutions, 70
Inflows, 234
Information, value of, 513, 514
Initial conditions, 778
Input distributions, 603–610
Inputs, 4, 22
Input variables
probability distributions for, 
554–571
Integer constraints, 143–144, 157
Integer programming (IP) models, 294
capital budgeting, 299–305
cutting stock models, 335–339
difficulty of, 296
fixed-cost, 306–318
location-assignment models, 324–334
LP relaxation of, 297
set-covering models, 319–324
Interarrival times, 776
Interfaces journal, 14
Internal demand, 716
International Textile Company, Ltd.,
288–289
Inventory models
categories of, 715–717
cost types in, 717–718
economic order quantity (EOQ) models,
718–734
introduction to, 714–715
ordering simulation models, 749–754
probabilistic models
newsvendor model, 737–740
(R,Q) ordering policy, 740–747
supply chain models, 754–764
Inventory position, 749
Investment models, 652–657
J
Jogger Shoe Company, 547
Judgmental forecasting models, 843
K
Kellogg Company, 133–134
Kendall’s notation, 787
Knockout call options, 666
L
Lakefield Corporation, 220–224
Last-come-first-served (LCFS), 777
Latest finish time, 15-8
Latest start time, 15-8
Latin hypercube sampling, 591
Law of total probability, 505
Lead time, 716, 747
Least-squares estimation, 381, 408
Least-squares regression line, 846
Level, of series, 884
Likelihoods, 505
Limited source models, 799
Limited waiting room models, 777
Linear programming models, 68
advertising models, 135–145
aggregate planning, 152–162
blending, 163–170
data envelopment analysis (DEA),
188–194
financial, 177–186
pension funds, 182–186
production processess, 171–176
properties of, 94–97
scaling and, 96–97
worker scheduling, 145–151
Linear trend, 848
Little’s formula, 785–786
Local maxima, 355
Local minimum, 355
Local optimum, 355, 359
Location-assignment models, 324
Logistics models, other, 248–256
LP relaxation, 297
M
MAE (mean absolute error), 878
MAPE. See Mean absolute percentage
error (MAPE)
Marketing models
customer loyalty, 667–676
marketing and sales models, 676–680
Markowitz, Harry, 398
MATCH function, 435
Mathematical models, 3
Mathematical programming models, 94
Matrix/matrices, 399
Matrix product, 399
Maximax criterion, 480
Maximin criterion, 479
Maximization problems, conditions for, 358
Maximum time without improvement, 430
Mean absolute percentage error (MAPE),
49, 852, 878
Mean payoff, 480
Measures of forecast error, 877–878
Memoryless property, 780
Merrill Lynch, 377, 621–623
Mersenne twister, 591
Microsoft Project, 15-35–15-38
Minimax criterion, 409
Minimization problems, conditions for, 358
Minimizing sum of squared errors, 380
Mixed integer linear programming (MILP)
model, 350–351
M/M/1 model, 787–791
M/M/s model, 791–796
MMULT functions, 400–401
Morton Thiokol, 317–318
Motor carrier selection, 290–292
Moving averages method, 878–883
Multicollinearity, 871
Multiperiod production models, 108–117
Multiple optimal solutions, 149
Multiple-product models, 717
Multiple R, 847
Multiple ranges, selecting, 89
Multiple regression, 844
Multiple regression models, 861–872
Multistage decision problems, 509–524
Multistart option, 359–361
Mutation rate, 430
Mutations, 426
N
NCAA basketball tournament simulation,
685–689
Net present value (NPV), 55
Network models
airline industry and, 267–280
assignment models, 241–247
introduction, 228–229
other logistic models, 248–256
shortest path models, 257–266
transportation models, 229–240
Network simplex method, 255
Newsvendor models, 737–740
No-arbitrage pricing principle, 223
Nodes, 230
Noise in forecasting, 876–877
Nonbinding constraints, 82, 83
slack, 82
Nonconstant error variance, 871
Nonfinancial holding costs, 718
Nonlinear pricing models, 431–438
Nonlinear programming (NLP) models
basic ideas of, 355–361
facility location models, 388–393
introduction to, 354–355
optimality guarantee for, 358
portfolio optimization models, 398–406
pricing models, 361–377
sports teams rating models, 393–397
stock beta estimating, 407–412
Nonlinear relationships, 871
Nonnegativity constraints, 69
Nonsmooth functions, 160
Normal distributions, 566–568
Normal loss function, 743
NPV function, 58
O
Objective cells, 69, 183
Objective functions, 69
One-way data tables, 36
Operations simulation models
bidding for contracts, 623–627
drug production with uncertain yield,
632–637
warranty costs, 627–632
Operations research (OR), 2
Optimality guarantee, 358
Optimal solutions, 70, 149
Optimization models, 4, 6–8, 54
dual-objective, 139–141
with integer variables, 294–299
introduction to, 67–121
nonlinear programming models (NLP),
354–355
Option pricing result, 658–659
OR. See Operations research (OR)
Ordering, 716
Ordering costs, 716, 717–718
Outflows, 234
Overhead forecasting, 905
P
Pacific National Bank, 838–839
Palisade Decision Tools Suite, 17
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

916
Index
Parallel queueing systems, 777
Partial backlogging, 718
Payoff tables, 478–479
Penalties, 428
Penalty costs, 718
Pension fund models, 182–186
Perfect information, 513
Periodic reviews, 717
PERT, 15-32
PERT distribution, 15-31–15-34
Piecewise linear, 432
Poisson process model, 783
Population size, 430
Porteus, Evan, 728
Portfolio optimization models, 398–406
Evolutionary Solver and, 452–455
return measures, 398
risk measures of, 398
Portfolio standard deviation, 403
Portfolio variance, 403
Posterior probabilities, 505
Power curves, 47
PrecisionTree add-in, 492–504
allowable entries, 495
copying subtrees, 497
entering monetary values, 
probabilities, 496
spider charts, 501
strategy region chart, 501
tornado charts, 501
values at end nodes, 498
Prediction and fitted values, 846
Prediction errors, 845
Predictor variables, 844
Present value, 55
Price and demand, estimating relationship
between, 45–55
Pricing analysis, 377
Pricing models, 361–377
exchange rate considerations, 366–377
Prior probabilities, 505
Probabilistic inventory models, 715, 716
Probability distributions
common types, 559–562
types of, 555–556
for uncertain inputs, 556
Production costs, 717
Production process modeling, 171–176
Product mix models
advertising models and, 136–137
two-variable, 70–83
Project management
allocation of resources, 15-14–15-28
CPM model, 15-4–15-12
crashing activities, 15-4, 15-14
introduction to, 15-2–15-4
PERT distribution, 15-31–15-34
uncertain activity times, models with,
15-30–15-34
Proportionality, 95
Pseudo-random numbers, 562
Q
Quantity discounts and demand
uncertainty, 40–45
Queueing models
analytical steady-state, 787–806
characteristics of arrivals, 776–777
exponential distribution, 779–784
important relationships, 783–786
introduction to, 4–8, 774–776
service characteristics, 777–778
service discipline, 777
simulation models, 815–830
series systems with blocking, 823–830
Queueing networks, 777
R
RANDBETWEEN function, 560
RAND function, 560
Random (noise) component, 874, 
876–877
Random numbers
freezing, 563
Random seeds, 430
Random variables, weighted sums of,
398–399
Range names, 33, 66
pasting, 33
shortcuts, 137
Ranges
selecting multiples, 87
Reduced costs, 85
Reference (base) category, 867
Regression assumptions, 870–871
Regression-based trend models, 848–853
Regression coefficients, 862
Regression models, 843
introduction to, 843–844
least-squares line, 845–846
overview of, 844–848
prediction and fitted values, 846
simple, 848–860
trend models, 848
Relative addresses, 29
Reneging, 777
Reorder point, 717
Replicating with Excel only, 583
Residuals, 845, 846
Response variables, 844
Retention rate, 667
Risk, 525–532
@RISK add-in, 17
automated template for, 690–691
features of, 587
introduction to, 587–601
Latin hypercube and Mersenne twister
settings, 591
limitations of, 597–598
loading, 588
models with several random input
variables, 598–601
models with single random input
variables, 588–597
probability distributions and, 563
RISKBINOMIAL, 570
RISKCORRMAT, 610
RISKDISCRETE, 566
RISKGAMMA, 630
RISKNORMAL, 567, 617
RISKOUTPUT, 590
RISKPERT, 15-31–15-32
RISKSIMTABLE, 587, 594–597
RISKTARGET, 637
RISKTRIANG, 569
RISKUNIFORM, 563
saving graphs and tables, 593
TopRank add-in and, 691–699
Risk aversion, 525, 526
RISKCORRMAT, 610
RISKGAMMA, 630
Risk index, 203
Risk measures, 398
RISKNORMAL, 567
RISKPERT, 15-31–15-32
Risk profiles, 484–485
RISKSIMTABLE, 594–597
RISKTARGET, 637
Risk tolerance, 526–527
RISKTRIANG, 569
RISKUNIFORM, 563
RISKVARY, 694
RMSE. See Root mean square error
(RMSE)
Rolling planning horizons approach, 116
aggregate planning model and, 158–162
Root mean square error (RMSE), 381, 878
Roundoff errors, 104
Row vector, 399
(R,Q) ordering policy, 740–747
R-square, 847–848
R-square, adjusted, 866
S
SAE. See Sum of absolute errors (SAE)
Safety stock, 740, 741
Sales models, 676–680
Sample information, 513
Sample size determination, 581
Santa Fe Railway, 421–422
Saturation effect, 830
Scaling in optimization models, 96–97
Scatterplots, 845
with Excel, 849
Scenario approach, 406
Scope creep in projects, 15-4
Screen splitting, 57
Seasonal component, 874, 875
Sensitivity analysis, 70, 83–94, 482
Sequential decisions, 515
Series systems, 777
with blocking, 823–830
Server utilization, 786
Service discipline, 777
Service-in-random-order (SRO), 777
Service level constraints, 745
Set-covering models, 319–324
Setup costs, 716, 717
Seven-step modeling process, 8–14
Shadow prices, 85
Shortage costs, 718, 742
Shortest path models, 257–266
Shortest-processing-time (SPT), 777
Short-run behavior, 778
analytical approximation of, 809–814
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Index
917
Simple exponential smoothing, 884
equivalent formulas for, 885
Simple regression, 844
Simplex method, 70
geometry of, 74
Simulation models, 9, 775
financial models
cash balance models, 647–652
financial planning, 642–647
investment models, 652–657
stock prices and options simulation,
657–664
flaw of averages, 573–575
games of chance simulations
game of craps, 682–685
NCAA basketball tournaments,
685–689
introduction to, 552–554
marketing models
customer loyalty, 667–676
marketing and sales, 676–680
operations models
bidding for contracts, 623–627
Deming’s funnel experiment, 637–641
drug production with uncertain yield,
632–637
warranty costs, 627–632
probabilty distributions for input
variables, 554–571
using built-in Excel tools, 576–586
Skewed probability distributions, 557–558
Slack in constraint, 82
Slack in CPM models, 15-8
Smoothing constants, 884
Smoothing methods, 878
Solver add-in, 70, 79–83
Evolutionary, 423
GRG Nonlinear method, 364
integer constraints, 143
messages from, 81
Multistart option, 359–361
nonsmooth functions and, 160
tolerance settings in, 149
SolverTable add-in
roundoff with, 106
with Evolutionary Solver, 442
sensitivity reports and, 87
Span in moving averages, 878
Spider charts, 502
Splitting screen, 57
Sports teams rating models, 393–397
Spreadsheet modeling, 74–78
breakeven analysis, 31–39
cost projections, 26–31
inequality and equality labels in, 80
introduction to, 22–27
layout and documentation, 26
vs. algebraic models, 118–121
Squared coefficient of variation, 803
S-shaped curves, fitting, 448–452
S-shaped trend, 874
Stable queueing systems, 779
Standard error of estimate, 846–847
Standard errors of –X, 581
Start-to-finish relationships, 15-12
Start-to-start relationships, 15-12
StatTools, 17–18, 854
Steady-state analysis, 778
Stock beta estimation, 407–412
Stock prices and options simulation
Asian options, 662–664
European call options, 657–660
portfolio returns with stocks and options,
660–662
stock prices, 657–658
Strategy region charts, 501
Strike price, 658
Subway token hoarding, 772
SUMIF function, 235–237
Sum of absolute errors (SAE), 408
Sum of squared prediction errors, 383, 408
minimization of, 380
weighted, 408
Sum of squared residuals, 845
SUMPRODUCT, 44
SUMXMY2 function, 390
Supply chain models, 754–764
Surplus values, 433
Symmetric probability distributions,
557–558
T
Tabu search, 422
Tampering, 638
Telecommunication discounts, 352
Texaco OMEGA linear programming
model, 170
Text boxes, 66
Time averages, 784
Time series graphs, 876
Time series models, 843
components of, 874
cyclic components of, 875–876
overview, 874–883
random (noise) components, 876–877
seasonal components of, 875
trend component, 874–875
Time value of money, 55–60
TopRank add-in
key inputs, 699
@RISK and, 691–699
RISKVARY, 694
Tornado charts, 501
Total slack, 15-37
Trade-off curves, 141
Traffic intensity, 787, 797–799
Training samples, 461
Transient probability distributions, 810
Transportation models, 229–240, 234–237
Transportation simplex method, 237
TRANSPOSE function, 173, 400
Transshipment points, 248
Traveling salesperson models, 464–468
Trend component, 874
Trend line, superimposing, 850
Trendline tool, 47
Trend models, regression-based, 848–853
Triangular distribution, 568–569
Two-part tariffs, 432
Two-variable product mix model, 70–83
algebraic model for, 72
graphical solutions for, 72–74
spreadsheet models for, 74–78
Two-way data tables, 42–44, 584–586
Two-way sensitivity charts, 503–504
U
Unbounded solutions, 97–99
Unbounded probability distributions,
558–559
Uncertain demand, ordering with, 740
Uncertain timing, dealing with, 635
Unconstrained models, 382
Uniform distribution, 559
Unit purchasing cost, 717
Unit shipping costs, 230
Unrestricted probability distributions, 559
U.S. Air Force Space Command, 293–294
Utility functions, 526
V
Value at risk at the 5% level (VAR 5%), 645
Variable costs, 717
VLOOKUP, 42
W
Waiting line models. See Queueing models
Warranty costs, 627–632
Weighted sum of random variables,
398–399
Weighted sums of squared errors, 408
Westhouser Paper Company, 548
Westvaco, 290–292
Winter’s exponential smoothing method for
seasonality, 892–896
Worker scheduling models, 145–151
Work-in-process (WIP) inventory, 
773–774
X
X (predictor variable), 844
Y
Y (response variable), 844
Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).
Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

