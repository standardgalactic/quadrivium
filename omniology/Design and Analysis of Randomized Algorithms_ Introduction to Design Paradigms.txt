
Texts in Theoretical Computer Science
An EATCS Series
Editors:  W. Brauer  G. Rozenberg  A. Salomaa
On behalf of the European Association
for Theoretical Computer Science (EATCS)
Advisory Board:  G. Ausiello   M. Broy   C.S. Calude
A. Condon   D. Harel   J. Hartmanis   T. Henzinger
J. Hromkovic   N. Jones   T. Leighton   M. Nivat
C. Papadimitriou   D. Scott
°

This page intentionally left blank

J. Hromkovic
123
Design and Analysis
of Randomized
Algorithms
With 23 Figures
Introduction to Design Paradigms
°

ACM Computing Classification (1998): F.2, F.1, G.2
ISBN-10  3-540-23949-9  Springer Berlin Heidelberg New York
ISBN-13  978-3-540-23949-9  Springer Berlin Heidelberg New York
This work is subject to copyright. All rights are reserved, whether the whole or part of the material is concerned,
specifically the rights of translation, reprinting, reuse of illustrations, recitation, broadcasting, reproduction on microfilm
or in any other way, and storage in data banks. Duplication of this publication or parts thereof is permitted only under
the provisions of the German Copyright Law of September 9, 1965, in its current version, and permission for use must
always be obtained from Springer. Violations are liable for prosecution under the German Copyright Law.
Springer is a part of Springer Science+Business Media
springeronline.com
© Springer-Verlag Berlin Heidelberg 2005
Printed in Germany
The use of general descriptive names, registered names, trademarks, etc. in this publication does not imply, even in the
absence of a specific statement, that such names are exempt from the relevant protective laws and regulations and therefore
free for general use.
Cover design: KünkelLopka, Heidelberg
Typesetting: Camera ready by author
Production:  LE-TeX Jelonek, Schmidt & Vöckler GbR, Leipzig
Printed on acid-free paper          45/3142/YL - 5 4 3 2 1 0
Author
Prof. Dr. Juraj Hromkovic
ETH Zentrum, RZ F2
Department of Computer Science
Swiss Federal Institute of Technology
8092 Zürich, Switzerland
juraj.hromkovic@inf.ethz.ch
Library of Congress Control Number: 2005926236
Series Editors
Prof. Dr. Wilfried Brauer
Institut für Informatik der TUM
Boltzmannstrasse 3
85748 Garching, Germany
Brauer@informatik.tu-muenchen.de
Prof. Dr. Grzegorz Rozenberg
Leiden Institute of Advanced Computer Science
University of Leiden
Niels Bohrweg 1
2333 CA Leiden, The Netherlands
rozenber@liacs.nl
Prof. Dr. Arto Salomaa
Turku Centre for Computer Science
Lemminkäisenkatu 14 A
20520 Turku, Finland
asalomaa@utu.fi
Illustrations
Ingrid Zámecniková
°
°

To my teachers
O. Dem´aˇcek
P. ˇDuriˇs
R. Hammerov´a
B. Rovan
V. ˇSimˇciskov´a
E. Toman

This page intentionally left blank

As soon as man is,
man has to look for
to be.
And as one is looking for
to be,
one has to be oneself
and not someone else,
as very often is the case.
Jan Werich

This page intentionally left blank

Preface
Only after dogma has died,
science begins.
Galileo Galilei
Randomization has become a standard approach in algorithm design. Eﬃ-
ciency and simplicity are the main features of randomized algorithms that
often made randomization a miraculous springboard for solving complex prob-
lems in various applications. Especially in the areas of communication, cryp-
tography, data management, and discrete optimization, randomization tends
to be an indispensable part of the development of software systems. We know
several situations and algorithmic tasks for which any deterministic approach
leads to so much computer work that it is impossible to perform it in prac-
tice, but for which randomized methods can be successfully applied. This huge
gain of going from an intractable amount of computer work1 (computational
complexity) to short computations of randomized algorithms is paid for by
the risk of computing a wrong output. But the probability of executing an
erroneous computation of a randomized algorithm can often be reduced to
below the probability of winning the ﬁrst prize in a lottery in the ﬁrst at-
tempt. This means that one pays for saving a huge amount of computing time
with a very small loss in the degree of reliability. How to orchestrate such
huge quantitative jumps in computational complexity by small relaxations of
reliability (correctness) constraints and why such big gains for small “prices”
are at all possible are the topics of this book.
Despite many spectacular and surprising results and successful applica-
tions of randomized algorithms, the basic concepts of randomization are not
suﬃciently broadcasted in academic education. One of the main reasons for
this unpleasant circumstance is that simple explanations and transparent pre-
sentations of the discoveries in randomized computing are missing in text-
books for introductory courses that could be available even to non-scientists
and beginners. This is usually the situation when principal contributions and
concepts of a particular scientiﬁc discipline are not recognized as paradigms
in the broad community, and are even considered to be too diﬃcult to be pre-
sented in basic courses. The aim of this textbook is to close this gap. We focus
1Requiring, for instance, billions of years on the fastest computers.

X
Preface
on a transparent explanation of the paradigms of the design of randomized
algorithms. This ﬁrst book of our series on the design and analysis of ran-
domized algorithms provides a readable introduction to this topic, giving an
exhaustive, technical survey of the best and most important results achieved.
Providing an accessible ticket to randomization we would like to encourage
colleagues not working in the area of randomization to present some random-
ized concepts in their courses, or even give courses specialized on randomized
algorithm design. In this way we would like to contribute to speeding up the
inclusion of paradigmatic results on randomized computing in the educational
mainstream of computer science.
The didactic method of this book is similar to that in our textbook Theo-
retical Computer Science. The main strategies are called “simplicity,” “trans-
parency,” and “less is sometimes more.” Especially in this ﬁrst book in the
series, clarity takes priority over the presentation of the current state of re-
search and development. When a transparent argument of a weaker result can
bring across the idea succinctly, then we will opt for it instead of presenting a
strong but technically demanding and confusing argument of the best known
result. Throughout this book, we work systematically, taking small steps to
travel from the simple to the complicated, and so avoid any interruption in
thoughts. We are far from trying to present too many results. Instead, we take
the time and space to explain what we want to explain in detail, and also in
the general context of our scientiﬁc discipline. We also dedicate time to the
development of informal ideas, and ways of thinking in this area.
I would like to express my deepest thanks to Dirk Bongartz, Hans-
Joachim B¨ockenhauer, and Manuel Wahle for carefully reading the whole
manuscript and for their numerous comments and suggestions. Very special
thanks go to Bagdat Aslan and Manuel Wahle for their technical help on this
manuscript. The excellent cooperation with Alfred Hofmann and Ingeborg
Mayer of Springer is gratefully acknowledged. Last but not least I would like
to cordially thank Ingrid Z´ameˇcnikov´a for her illustrations and Tanja for her
collection of citations.
Aachen,
January 2005
Juraj Hromkoviˇc

Contents
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.1
What Is Randomness and Does There Exist
True Randomness? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.2
Randomness as a Source of Eﬃciency –
an Exemplary Application . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
1.3
Concept of the Book . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
1.4
To the Student . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
1.5
To the Teacher . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
2
Fundamentals. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
2.1
Objectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
2.2
Elementary Probability Theory. . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
2.3
Models of Randomized Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . 37
2.4
Classiﬁcation of Randomized Algorithms . . . . . . . . . . . . . . . . . . . 51
2.5
Classiﬁcation of Randomized Algorithms
for Optimization Problems. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
2.6
Paradigms of the Design of Randomized Algorithms . . . . . . . . . 87
2.7
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96
3
Foiling the Adversary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101
3.1
Objectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101
3.2
Hashing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102
3.3
Universal Hashing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
3.4
Online Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116
3.5
Randomized Online Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
3.6
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128
4
Fingerprinting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131
4.1
Objectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131
4.2
Communication Protocols . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133
4.3
The Substring Problem. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139

XII
Contents
4.4
Veriﬁcation of Matrix Multiplication . . . . . . . . . . . . . . . . . . . . . . . 141
4.5
Equivalence of Two Polynomials . . . . . . . . . . . . . . . . . . . . . . . . . . . 144
4.6
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149
5
Success Ampliﬁcation and Random Sampling . . . . . . . . . . . . . . 153
5.1
Objectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153
5.2
Eﬃcient Ampliﬁcation by Repeating
Critical Computation Parts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154
5.3
Repeated Random Sampling and Satisﬁability. . . . . . . . . . . . . . . 166
5.4
Random Sampling and Generating Quadratic Nonresidues . . . . 174
5.5
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181
6
Abundance of Witnesses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183
6.1
Objectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183
6.2
Searching for Witnesses for Primality Testing . . . . . . . . . . . . . . . 184
6.3
Solovay-Strassen Algorithm for Primality Testing . . . . . . . . . . . . 192
6.4
Generation of Random Primes . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202
6.5
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206
7
Optimization and Random Rounding . . . . . . . . . . . . . . . . . . . . . . 209
7.1
Objectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 209
7.2
Relaxation to Linear Programming . . . . . . . . . . . . . . . . . . . . . . . . 210
7.3
Random Rounding and MAX-SAT. . . . . . . . . . . . . . . . . . . . . . . . . 216
7.4
Combining Random Sampling and Random Rounding . . . . . . . . 222
7.5
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225
A
Fundamentals of Mathematics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 227
A.1 Objectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 227
A.2 Algebra and Number Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228
A.3 Combinatorics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 256
A.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 264
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 267
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 271

1
Introduction
To doubt everything or to believe everything –
these are two equally easy solutions,
because both of them relieve us of the necessity of thinking.
Jules Henri Poincar´e
1.1 What Is Randomness and Does There Exist
True Randomness?
The notion of “randomness” is one of the most fundamental and most dis-
cussed terms in science. Following the deﬁnition used in dictionaries, an event
is considered to be random when it happens unpredictably. An object is called
random, when it is created without any plan. The fundamental question is
whether randomness really exists, or whether we use this term only to model
objects and events with unknown lawfulness. Philosophers and scientists have
disputed the answer to this question since ancient times. Democritos believed
that
the randomness is the unknown,
and that the nature is determined
in its fundamentals.
Thus, Democritos asserted that order conquers the world and this order is
governed by unambiguous laws. Following Democritos’s opinion, one uses the
notion of “randomness” only in the subjective sense in order to veil one’s
inability to truly understand the nature of events and things. Hence the exis-
tence of the notion of randomness is only a consequence of the incompleteness
of our knowledge. To present his opinion transparently, Democritos liked to
use the following example. Two men agreed on sending their slaves to bring
water at the same time in order to cause the slaves to meet. The slaves really
met at the source and said, “Oh, this is randomness that we have met.”
In contrast to Democritos, Epikurus claimed that
the randomness is objective,
it is the proper nature of events.
Thus, Epikurus claimed that there exists a true randomness that is com-
pletely independent of our knowledge. Epikurus’s opinion was that there exist
processes whose development is ambiguous rather than unambiguous, and an

2
1 Introduction
unpredictable choice from the existing possibilities is what we call random-
ness.
One could simply say, “Epikurus was right because there are games of
chance, such as rolling dice or roulette, that can have diﬀerent outcomes,
and the results are determined by chance. Unfortunately, the story is not
so simple, and discussing gambling one gets the support for the opinion of
Democritos rather than for Epikurus’s view on the nature of events. Rolling
dice is a very complex activity, but if one knows the direction, the speed
and the surface on which a die is tossed, then it may be possible to compute
and predict the result. Obviously, the movement of the hand controlled by
the human brain is too complex to allow us to estimate the values of all
important parameters. But we may not consider the process of rolling a die as
an objectively random process only because it is too complex for us to predict
the outcome. The same is true of roulette and other games of chance. Physics
also often uses random models to describe and analyze physical processes
that are not inherently or necessarily random (and are sometimes clearly
deterministic), but which are too complex to have a realistic possibility of
modeling them in a fully deterministic way. It is interesting to note that based
on this observation even Albert Einstein accepted the notion of randomness
only in relation to an incomplete knowledge, and strongly believed in the
existence of clear, deterministic laws for all processes in nature.1
Before the 20th century, the world view of people was based on causal-
ity and determinism. The reasons for that were, ﬁrst, religion, which did not
accept the existence of randomness in a world created by God2, and, later,
the optimism created by the success of natural sciences and mechanical en-
gineering in the 19th century, which gave people hope that everything could
be discovered, and everything discovered could be explained by deterministic
causalities of cause and resulting eﬀect.3
This belief in determinism also had emotional roots, because people con-
nected randomness (and even identiﬁed it) with chaos, uncertainty, and un-
predictability, which were always related to fear; and so the possibility of
random events was not accepted. To express the strongly negative connota-
tion of randomness in the past, one can consider the following quotation of
Marcus Aurelius:
There are only two possibilities,
either a big chaos conquers the world,
or order and law.
1“God does not roll dice” is a famous quotation of Albert Einstein. The equally
famous reply of Niels Bohr is, “The true God does not allow anybody to prescribe
what He has to do.”
2Today we know that this strong interpretation is wrong and that the existence
of true randomness does not contradict the existence of God.
3Take away the cause, and the eﬀect must cease.

1.1 Randomness as a Source of Eﬃciency – an Exemplary Application
3
Because randomness was undesirable, it may not be surprising that philoso-
phers and researchers performed their investigations without allowing the ex-
istence of random events in their concepts or even tried to prove the nonexis-
tence of randomness by focusing on deterministic causalities. Randomness was
in a similarly poor situation with Galileo Galilei, who claimed that the earth
is not a ﬁxed center of the whole universe. Though he was able to prove his
claim by experimental observations, he did not have any chance to convince
people about it because they were very afraid of such a reality. Life in the
medieval world was very hard, and so people clung desperately to the very
few assurances they had. And the central position of the earth in the universe
supported the belief that the poor man is at the center of God’s attention.
The terrible fear of losing this assurance was the main reason for the situa-
tion, with nobody willing to verify the observations of Galileo Galilei. And
the “poor” randomness had the same trouble gaining acceptance4.
Finally, scientiﬁc discoveries in the 20th century (especially in physics and
biology) returned the world to Epikurus’s view on randomness. The mathe-
matical models of evolutionary biology show that random mutations of DNA
have to be considered a crucial instrument of evolution. The essential reason
for accepting the existence of randomness was one of the deepest discoveries
in the history of science: the theory of quantum mechanics. The mathemat-
ical model of the behavior of particles is related to ambiguity, which can be
described in terms of random events. All important predictions of this the-
ory were proved experimentally, and so some events in the world of particles
are considered as truly random events. For accepting randomness (or random
events) it was very important to overcome the restricted interpretation of ran-
domness, identifying it with chaos and uncertainty. A very elegant, modern
view on randomness is given by the Hungarian mathematician Alfr´ed R´enyi:
Randomness and order do not contradict each other;
more or less both may be true at once.
The randomness controls the world
and due to this in the world there are order and law,
which can be expressed in measures of random events
that follow the laws of probability theory.
For us, as computer scientists, it is important to realize that there is also
another reason to deal with randomness than “only” the modeling of natural
processes. Surprisingly, this reason was already formulated 200 years ago by
the great German poet Johann Wolfgang von Goethe as follows:
The tissue of the world
is built from necessities and randomness;
the intellect of men places itself between both
4One does not like to speak about emotions in the so-called exact (hard) sciences,
but this is a denial of the fact that the emotions of researchers (the subjects in the
research) are the aggregates of the development and the progress.

4
1 Introduction
and can control them;
it considers the necessity
as the reason of its existence;
it knows how randomness can be
managed, controlled, and used...
In this context Johann Wolfgang von Goethe is the ﬁrst “computer scientist”,
who recognized randomness as a useful source for performing some activi-
ties. The use of randomness as a resource of an unbelievable, phenomenal
eﬃciency is the topic of this book. We aim to convince the reader that it
can be very proﬁtable to design and implement randomized algorithms and
systems instead of completely deterministic ones. This realization is nothing
other than the acceptance of nature as teacher. It seems to be the case that
nature always uses the most eﬃcient and simplest way to achieve its goal,
and that randomization of a part of the control is an essential concept of
nature’s strategy. Computer science practice conﬁrms this point of view. In
many everyday applications, simple randomized systems and algorithms do
their work eﬃciently with a high degree of reliability, and we do not know
any deterministic algorithms that would do the same with a comparable eﬃ-
ciency. We even know of examples where the design and use of deterministic
counterparts of some randomized algorithms is beyond physical limits. This
is also the reason why currently one does not relate tractability (practical
solvability) with the eﬃciency of deterministic algorithms, but with eﬃcient
randomized algorithms.
To convince the reader of the enormous usefulness of randomization, the
next section presents a randomized protocol that solves a concrete commu-
nication task within communication complexity that is substantially smaller
than the complexity of the best possible deterministic protocol.
We close this section by calling attention to the fact that we did not give
a ﬁnal answer to the question of whether or not true randomness exists, and
it is very improbable that science will be able to answer this question in the
near future. The reason for this pessimism is that the question about the
existence of randomness lies in the very fundamentals of science, i.e., on the
level of axioms, and not on the level of results. And, on the level of axioms
(basic assumptions), even the exact sciences like mathematics and physics
do not have any generally valid assertion, but only assumptions expressed
in the form of axioms. The only reason to believe in axioms is that they
fully correspond to our experience and knowledge. An example of an axiom
of mathematics (viewed as a formal language of science) is that our way of
thinking is correct, and so all our formal arguments are reliable. Starting with
the axioms, one builds the building of science very carefully, in such a way
that all results achieved are true provided the axioms are valid. If an axiom

1.2 Randomness as a Source of Eﬃciency – an Exemplary Application
5
is shown to be not generally valid, one has to revise the entire theory built
upon it5.
Here, we allow ourselves to believe in the existence of randomness, and not
only because the experience and knowledge of physics and evolutionary theory
support this belief. For us as computer scientists, the main reason to believe
in randomness is that randomness can be a source of eﬃciency. Randomness
enables us to reach aims incomparably faster, and it would be very surprising
for us if nature left this great possibility unnoticed.
1.2 Randomness as a Source of Eﬃciency –
an Exemplary Application
The aim of this section is to show that randomized algorithms can be essen-
tially more eﬃcient than their deterministic counterparts.
Let us consider the following scenario. We have two computers RI and RII
(Figure 1.1) that are very far apart6. At the beginning both have a database
with the same content. In the meantime the contents of these databases dy-
namically developed in such a way that one now tries to perform all changes
simultaneously in both databases with the aim of getting the same database,
with complete information about the database subject (for instance, genome
sequences), in both locations. After some time, we want to check whether this
process is successful, i.e., whether RI and RII contain the same data.
RI
RII
communication
x = x1 . . . xn
y = y1 . . . yn
Fig. 1.1.
Let n be the size of the database in bits. For instance, n can be approx-
imately n = 1016, which is realistic for biological applications. Our goal is
to design a communication protocol between RI and RII that is able to de-
termine whether the data saved on both computers is the same or not. The
complexity of the communication protocol is the number of bits that have to
5Disproving the general validity of an axiom should not be considered a
“tragedy.” Such events are part of the development of science and they are often
responsible for the greatest discoveries. The results built upon the old, disproved ax-
iom usually need not be rejected; it is suﬃcient to relativize their validity, because
they are true in frameworks where the old axiom is valid.
6For instance, one in Europe and one in America.

6
1 Introduction
be exchanged between RI and RII in order to solve this decision problem, and
we obviously try to minimize this complexity.
One can prove that every deterministic communication protocol solving
this task must exchange at least n bits7 between RI and RII, i.e., there exists
no deterministic protocol that solves this task by communicating n−1 or lower
bits. Sending n = 1016 bits and additionally assuring that all arrive safely8 at
the other side is a practically nontrivial task, so one would probably not do
it in this way.
A reasonable solution can be given by the following randomized protocol.
Let x = x1x2 . . . xn ∈{0, 1}∗, xi ∈{0, 1} for all i = 1, . . ., n. We denote by
Number(x) =
n

i=1
2n−i · xi
the natural number whose binary representation is the string x.
R = (RI, RII) (Randomized Protocol for Equality)
Initial situation: RI has a sequence x of n bits, x = x1 . . . xn, and RII has a
sequence y of n bits y = y1 . . . yn.
Phase 1: RI chooses uniformly9 a prime p from the interval [2, n2] at random.
Phase 2: RI computes the integer
s = Number(x) mod p
and sends the binary representations of s and p to RII.
{Observe that s ≤p < n2 and so each of these integers can be
represented by

log2 n2
bits.}
Phase 3: After reading s and p, RII computes the number
q = Number(y) mod p.
If q ̸= s, then RII outputs “x ̸= y”.
If q = s, then RII outputs “x = y”.
Now we analyze the work of R = (RI, RII). First, we look at the complexity
measured in the number of communication bits, and then we analyze the
reliability (error probability) of the randomized protocol R = (RI, RII).
The only communication of the protocol involves submitting the binary
representations of the positive integers s and p. As we have already observed,
s ≤p < n2; hence the length of the message is at most10
7This means that sending all data of RI to RII for the comparison is an optimal
communication strategy.
8without ﬂipping a bit
9This means that every prime from the interval [2, n2] has the same probability
of being chosen.
10Every positive integer m can be represented by ⌈log2(m + 1)⌉bits.

1.2 Randomness as a Source of Eﬃciency – an Exemplary Application
7
2 · ⌈log2 n2⌉≤4 · ⌈log2 n⌉.
For n = 1016, the binary length of the message is at most 4·16·⌈log2 10⌉= 256.
This is a very short message that can be safely transferred.
Now we show not only that for most inputs (initial situations) the ran-
domized strategy works, but also show that the probability of providing the
right answer is high for every input. Let us ﬁrst recognize that the random-
ized protocol may err11. For instance, if x = 01111 and y = 10110, i.e.,
Number(x) = 15 and Number(y) = 22, then the choice of the prime 7 from
the set {2, 3, 5, 7, 11, 13, 17, 19, 23} yields the wrong answer, because
15 mod 7 = 1 = 22 mod 7.
To analyze the error probability for any input (x, y), with x = x1 . . . xn, and
y = y1 . . . yn, we partition the set
PRIM

n2
= {p is a prime | p ≤n2}
into two subsets (Figure 1.2). The ﬁrst subset contains the bad primes, where
a prime p is bad for (x, y) if the random choice of p results in the wrong
output of the protocol R. The second subset of PRIM

n2
is the complemen-
tary subset to the subset of bad primes and we call the primes in this subset
good for (x, y) because the choice of any of them results in the right answer
for the input (x, y).
bad
primes
for (x, y)
good primes for
the input (x, y)
all primes ≤n2
Fig. 1.2.
Since every prime in PRIM

n2
has the same probability of being chosen,
the error probability12 for the input (x, y) is
the number of bad primes for (x, y)
Prim (n2)
,
11In the sense that the randomized protocol outputs “x = y” for diﬀerent x and
y.
12Here we work with an informal understanding of the notion of probability. The
exact deﬁnition of probability and related notions will be presented in the next
chapter, and we will then repeat this argument formally.

8
1 Introduction
where Prim

n2
denotes the cardinality of Prim

n2
. The famous Prime
Number Theorem says that
lim
m→∞
Prim (m)
m/ ln m = 1,
and we know that
Prim (m) >
m
ln m
for all positive integers m > 67. Hence, we have
Prim

n2
>
n2
2 ln n
for all n ≥9. Our aim is now to show that
for any input (x, y), the number of bad primes for (x, y) is at most
n −1,
i.e., that the number of primes that are bad for (x, y) is essentially smaller
than n2/2 ln n.
Analyzing the error probability, we distinguish two possibilities with re-
spect to the real relation between x and y.
(i) Let x = y.
Then one has
Number(x) mod p = Number(y) mod p
for all primes p, i.e., these are no bad primes for the input (x, y). Therefore
RII outputs “x = y” with certainty, i.e., the error probability is equal to
0 in this case.
(ii) Let x ̸= y.
One gets the wrong answer “x = y” only if RI has chosen a prime p such
that
s = Number(x) mod p = Number(y) mod p.
In other words, p is a bad prime for (x, y) when
Number(x) = x′ · p + s and Number(y) = y′ · p + s
for some nonnegative integers x′ and y′.
A consequence is that
Number(x) −Number(y) = x′ · p −y′ · p = (x′ −y′) · p,
i.e., that
p divides the number |Number(x) −Number(y)|.

1.2 Randomness as a Source of Eﬃciency – an Exemplary Application
9
Thus, the protocol R outputs the wrong answer “x = y” only if the chosen
prime p divides the number |Number(x)−Number(y)|. This way, we have
the following new deﬁnition of bad primes:
a prime p is bad for (x, y) iﬀ
p divides the number w = |Number(x) −Number(y)|.
Thus, to estimate the error probability, it is suﬃcient to estimate how
many primes from the Prim

n2
∼n2/ ln n2 primes divide the number
w. Since the length of the binary representations of x and y is equal to n,
w = |Number(x) −Number(y)| < 2n.
Obviously13, we can factorize w to get
w = pi1
1 · pi2
2 · . . . · pik
k ,
where p1 < p2 < . . . < pk are primes and i1, i2, . . ., ik are positive integers.
Our aim is to prove that
k ≤n −1.
We prove it by contradiction. Assume k ≥n. Then,
w = pi1
1 · pi2
2 · . . . · pik
k ≥p1 · p2 · . . . · pn > 1 · 2 · 3 · . . . · n = n! > 2n,
which contradicts the fact that w < 2n. In this way we have proved
that w has at most n −1 diﬀerent prime factors. Since every prime in
{2, 3, . . ., n2} has the same probability of being chosen, the probability of
choosing a bad prime p dividing w is at most
n −1
Prim (n2) ≤
n −1
n2/ ln n2 ≤ln n2
n
for all n ≥9.
Thus the error probability of R for an input (x, y) with x ̸= y is at most
ln n2
n
,
which is at most
0.36892 · 10−14
for n = 1016.
An error probability of this size is no real risk, but let us assume that
a pessimist is not satisﬁed with this error probability and wants to have an
error probability below all physical limits. In such a case one can execute the
work of the protocol R ten times, always with an independent, new choice of
a prime.
13We know from number theory that every positive integer has a unique factor-
ization.

10
1 Introduction
Protocol R10
Initial situation: RI has n bits x = x1 . . . xn and RII has n bits y = y1 . . . yn.
Phase 1: RI chooses 10 uniformly random primes
p1, p2, . . ., p10
from {2, 3, . . ., n2}.
Phase 2: RI computes
si = Number(x) mod pi
for i = 1, 2, . . ., 10 and sends the binary representations of
p1, p2, . . ., p10, s1, s2, . . ., s10
to RII.
Phase 3: Upon receiving p1, p2, . . ., p10, s1, s2, . . ., s10 RII computes
qi = Number(y) mod pi
for i = 1, 2, . . ., 10.
If there exists an i ∈{1, 2, . . ., 10} such that qi ̸= si, then RII outputs
“x ̸= y”.
Else (if qj = sj for all j ∈{1, 2, . . ., 10}) RII outputs “x = y”.
We observe that the communication complexity of R10 is 10 times larger
than that of R. But, for n = 1016, the message consists of at most 2560 bits,
which is no issue for discussion.
What is the gain with respect to error probability?
If x = y, then we again have the situation that the protocol R10 provides
the right answer “x = y” with certainty, i.e., the error probability is equal to
0.
However, if x ̸= y, R10 outputs the wrong answer “x = y” only if all
10 chosen primes belong to the maximal n −1 bad primes that divide the
diﬀerence w = |Number(x)−Number(y)|. Since the 10 bad primes are chosen
in 10 independent experiments, the error probability is at most14

n −1
Prim (n2)
10
≤
ln n2
n
10
= 210 · (ln n)10
n10
.
For n = 1016, the error probability is smaller than
0.4717 · 10−141.
14Why the probability of independently choosing two bad primes is equal to the
multiplication of the probabilities of choosing a bad prime is carefully explained in
Section 2.3.

1.3 Concept of the Book
11
If one takes into account the fact that the number of microseconds since the
Big Bang is a number of 24 digits, and that the number of protons in the
known universe is a number of 79 digits, an event with a probability below
10−141 is a real wonder. Note also that in the case where a deterministic
protocol communication of 1016 bits would be executable, the costs speak
clearly in favor of the implementation of the above randomized protocol.
We can learn a lot from the construction of the protocol R10 that consists
of independent repetitions of R. We see that the error probability of a ran-
domized algorithm A can be substantially pushed down by executing several
independent runs of A. In cases such as the above communication protocol,
even a few repetitions result in an enormous decrease in error probability.
We have observed that using randomization one can gain phenomenally in
the eﬃciency by paying a very small price in reliability. Here we call atten-
tion to the fact that in practice randomized algorithms with very small error
probability can be even more reliable than their best deterministic counter-
parts. What do we mean by this? Theoretically, all deterministic algorithms
are absolutely correct, and randomized algorithms may err. But the nature of
the story is that deterministic programs are not absolutely reliable because
during their runs on a computer a hardware error may occur and then they
may produce wrong results. Clearly, the probability of the occurrence of a
hardware error grows proportionally with the running time of the program.
Therefore a fast randomized algorithm can be more reliable than a slow de-
terministic algorithm. For instance, if a randomized algorithm computes a
result in 10 seconds with an error probability 10−30, then it is more reliable
than a deterministic algorithm that computes the result in one week. Another
good example is our randomized protocol R for Equality. For n = 1016, the
protocol R has to communicate 256 bits only and the error probability is at
most 0.4·10−14. On the other hand, every deterministic protocol has to safely
communicate at least 1016 bits and the probability of ﬂipping some of them
because of a hardware error is essentially larger than the error probability of
R.
1.3 Concept of the Book
The aim of this book is to provide an elementary course on the design and
analysis of eﬃcient randomized algorithms. We focus not on giving an overview
of the deepest contributions to this area, but on a transparent presentation of
the most successful design methods and concepts, and we try to contribute to
understanding why randomized approaches can be essentially more eﬃcient
than their best deterministic counterparts. In this way, we aim to contribute
to capturing formal methods as instruments for problem solving and to de-
veloping a feeling for the computer scientist’s way of thinking.
The only presumed background for reading this textbook is a basic knowl-
edge of introductory courses, such as “programming,” “algorithms and data

12
1 Introduction
structures” and introduction to the “theory of computation.” Thus, we assume
that the reader is familiar with terms such as computing task (or problem),
decision problem, optimization problem, algorithm, and complexity of algo-
rithms. We use the formal deﬁnitions of these basic terms, and the same nota-
tion as that presented in our textbook Theoretical Computer Science [Hro03].
From mathematics, we assume some elementary knowledge of combinatorics
and linear algebra. All other concepts and assertions of probability theory,
algebra, and number theory are either presented whenever they are needed or
surveyed in the Appendix.
The book is divided into eight chapters, including this introduction. In
order to support the iterative way of teaching, these chapters are organized
as follows. Every chapter opens with a section “Objectives,” in which the mo-
tivations, teaching objectives, and relations to topics of the previous chapters
are presented. The core of the chapter is dedicated to the formalization, de-
velopment, and application of the ideas presented in the “Objectives.” For
every essential development and achievement, we will pinpoint its relevance
to our objectives. We end each chapter with a short summary and outlook.
Here the major highlights of the chapter are informally summarized, and the
chapter’s relevance to other parts of the book is once again reviewed.
Chapter 2 provides the fundamentals. One learns here what randomized
algorithms are, and how to design and analyze them. The core of Chapter 2
begins with Section 2.2, with elementary fundamentals of probability theory,
reduced to a simple kernel that is suﬃcient for our purposes. In Section 2.4
we explain what randomized algorithms are and how to model and analyze
them by means of probability theory. Section 2.5 presents the fundamental
classiﬁcation of randomized algorithms with respect to their error probabili-
ties.15 Section 2.5 shows how to model and classify randomized algorithms in
the areas of discrete optimization, where we usually do not speak about error
probability but about a probability of getting a good approximation of an op-
timal solution. From a contextual point of view Section 2.5 is central to this
textbook. Here we introduce the most successful and recognized paradigms of
the design of randomized algorithms such as “Fooling an Adversary,” “Finger-
printing,” “Ampliﬁcation,” “Random Sampling,” “Abundance of Witnesses,”
and “Random Rounding.” In this way, we start not only to build the method-
ology and the machinery for the design of eﬃcient and simple randomized
algorithms, but also to capture the nature of the fascinating computational
power of randomization in many applications. The paradigms introduced here
determine the structure of this book because each of the following chapters
(apart from the Appendix) is devoted to the study of one of these paradigms.
Chapter 3 provides a deeper insight into the application of the method of
fooling an adversary, which is also called the method of eliminating worst-case
15More precisely, with respect to the speedup of reducing the error probability
with the number of independently executed runs of the randomized algorithm on
the same input.

1.3 Concept of the Book
13
problem instances. Here, one views a randomized algorithm as a probability
distribution over a set of deterministic algorithms (strategies). The crucial
point is creating a set of deterministic strategies such that, for any problem
instance, most of these strategies eﬃciently compute the correct result16. This
can be possible even when there does not exist any eﬃcient deterministic
algorithm for solving the problem17 considered. First, we make this approach
transparent by presenting hashing, where universal hashing is nothing other
than an application of the method of fooling an adversary. A deeper insight
into the power of this method is given by applying it in the area of online
algorithms.
The ﬁngerprinting method is successfully applied several times in Chap-
ter 4. The idea of this method is to solve equivalence problems in such a way
that instead of trying to compare full complex representations of given ob-
jects one compares rather their randomly chosen partial representations called
ﬁngerprints. The design of our randomized protocol presented in Section 2.2
can also be viewed as an application of this design paradigm. In Section 4.2
we apply ﬁngerprinting in order to solve other communication problems that
can be viewed as generalizations of the equality problem. Section 4.3 uses our
motivation example once again in order to design an eﬃcient randomized al-
gorithm for searching for a string (pattern) in a longer string (text). Section
4.4 shows how one can apply ﬁngerprinting in order to verify the correctness
of the multiplication of two matrices in a more eﬃcient way than the matrix
multiplication.18 In Section 4.5 we generalize the idea of Section 4.4 in order
to develop a polynomial randomized algorithm for deciding the equivalence of
two polynomials. This application of ﬁngerprinting is of special importance,
because a deterministic polynomial algorithm for this decision problem is not
known.
Because ampliﬁcation and random sampling are often combined, or even
indistinguishably mixed, we present them together in Chapter 5. The paradigm
of success probability ampliﬁcation is common to all randomized algorithms
and it says that one can increase the success probability of any randomized
algorithm by several independent runs of the algorithm on the same input.
Section 5.2 shows a more clever application of this paradigm by repeating
only some critical parts of a computation instead of repeating all the random
runs. Random sampling enables us to create objects with some required prop-
erties by a simple random choice from a set of objects, despite the fact that
one does not know how to eﬃciently construct such objects in the determin-
istic way. In Section 5.3 we combine ampliﬁcation with random sampling in
order to successfully attack the NP-complete satisﬁability problem. Section
16This means that some of these strategies are allowed to compute wrong results
on some inputs.
17I.e., a deterministic algorithm that is correct and eﬃcient on any input.
18I.e., one can verify whether A · B = C for three matrices A, B, and C without
computing A · B.

14
1 Introduction
5.4 shows an application of random sampling for eﬃciently generating non-
quadratic residua, which one does not know how to generate deterministically
in polynomial time.
Chapter 6 is devoted to the method of abundance of witnesses, which can
be viewed as the deepest paradigm of randomization. A witness is additional
information to an input, whose knowledge makes a hard problem eﬃciently
solvable. The idea of this method is to generate such witnesses at random.
The art of successfully applying this method lies in searching for a suitable
kind of witness for the given problem. Here we present a part of such a search
for a convenient deﬁnition of witnesses for primality testing, which results in
the design of eﬃcient randomized primality testing algorithms.
Chapter 7 is devoted to the design of randomized approximation algo-
rithms for the NP-hard maximum satisﬁability problem (MAX-SAT). We
show how one can round a real solution of the relaxed version of MAX-SAT
at random in such a way that a good approximation of an optimal solution
to the original discrete optimization problem can be expected.
Appendix A provides some fundamentals of mathematics suﬃcient for the
purposes of the previous chapters. The mathematics is viewed here as a formal
language and as a machinery (sets of instruments and methods) for designing,
modeling and analyzing randomized algorithms, and it is also presented in
this way. Section A.2 provides a short, concise introduction to fundamentals
of group theory and number theory. Section A.3 presents some basic facts and
methods of combinatorics.
1.4 To the Student
This textbook has been written primarily for you. The aim of this book is not
only to introduce and explain some basic methods for the design of eﬃcient
randomized algorithms, but also to inspire you for the study of theoretical
computer science. In the previous sections of this chapter we have attempted
to convince you that randomization is a fascinating area of computer science,
because due to randomization one can eﬃciently perform things that were not
considered possible before, and so one can enjoy work on a topic that oﬀers a
lot of exciting surprises.
But to teach an exciting topic is not suﬃcient to ﬁll the lecture room
with many interested students. A good didactic presentation of the topic for
the success of a course is at least as important as the attractiveness of the
subject. Therefore, our presentation of this topic is based on the following
three concepts:
(i) Simplicity and transparency
We explain simple notions, concepts, and methods in simple terms. We
avoid the use of unnecessary mathematical abstractions by attempting to
be as concrete as possible. Through this we develop an introduction to the

1.4 To the Student
15
design of randomized algorithms on elementary mathematical knowledge.
Presenting complicated arguments or proofs, we ﬁrst explain the ideas in a
simple and transparent way, and then provide the formal, detailed proofs.
Sections and theorems marked with a “∗” are more involved and technical.
Undergraduates are advised to skip these parts when reading the material
for the ﬁrst time.
Clarity takes priority over the presentation of the best known results.
When a transparent argument of a weaker result can bring across the
idea succinctly, we opt for it instead of presenting a strong but technically
demanding and confusing argument of the best known result.
Throughout this book, we work systematically, taking small steps to jour-
ney from the simple to the complicated. We avoid any interruption in
thoughts.
(ii) Less is sometimes more, or a context-sensitive presentation
Many study guides and textbooks falsely assume that the ﬁrst and fore-
most aim is the delivery of a quantum of information to the reader. Hence,
they often go down the wrong track: maximum knowledge in minimum
time, presented in minimal space. This haste usually results in the presen-
tation of a great amount of individual results, thus neglecting the context
of the entire course. The philosophy behind this book is diﬀerent. We
would like to build and inﬂuence the student’s way of thinking. Hence, we
are not overly concerned about the amount of information, and are pre-
pared to sacriﬁce 10% to 20% of the teaching material. In return we ded-
icate more time to the informal ideas, motivations, connections between
practice and theory, and, especially, to internal contexts of the presented
research area. We place special emphasis on the creation of new terms.
The notions and deﬁnitions do not appear out of the blue, as seemingly so
in some lectures using the formal language of mathematics. The formally
deﬁned terms are always an approximation or an abstraction of intuitive
ideas. The formalization of these ideas enables us to make accurate state-
ments and conclusions about certain objects and events. They also allow
for formal and direct argumentation. We strive to explain our choice of the
formalization of terms and models used, and to point out the limitations
of their usage. To learn to work on the level of terms creation (basic deﬁ-
nitions) is very important, because most of the essential progress happens
exactly at this level.
(iii) Support of iterative teaching
The strategy of this book is also tailored to cultivate repetitive recon-
sideration of presented concepts. As already mentioned, every chapter
opens with a section “Objectives” in which the objectives are presented
in an informal way and in the context of knowledge from the previous
chapters. Every essential development in the main body of a chapter is
accomplished with a discussion about its importance in the context of
already presented knowledge. The conclusion of each chapter informally
summarizes its major highlights and weighs its contribution on a contex-

16
1 Introduction
tual level. As usual, the learning process is supported by exercises. The
exercises are not allocated to special subsections, but are distributed in
the text, with our recommendation to work through them immediately
after you have encountered them while reading the book. They help learn
how to successfully apply presented concepts and methods and to deepen
your understanding of the material.
But the most important point is that this textbook is self-contained, with
all formal and informal details presented in the lectures, and so one can
use it for a complete review of all explanations given in the teacher’s
lecture. In fact, one can master the subject of this book by only reading
it (without attending the lecture).
1.5 To the Teacher
The aim of this textbook is to support you in creating an introductory course
on randomized algorithms. The advantage of this book is that it provides a lot
of space for informal development of concepts and ideas, which unfortunately
are often presented only orally in lectures, and are not included in the written
supporting materials. Therefore, if the teacher followed this book in her or his
lecture, the student would have the possibility to review the complete lecture,
or a part of it as many times as she or he wanted. Additionally, the students
are not required to write all technical details presented during the lecture,
and can concentrate on the explanations given by the teacher.
Finally, we allow ourselves to formulate four rules which can be very helpful
in inducting a successful course on any topic. All have been very well known
for many years (there is no original idea of ours behind them), but teachers
often forget about their consistent application, which is the main problem
with education quality.
(i) Make sure that your students can review the topic of your lectures any
time and as often as they need to. For instance, you can save the entire
presentation on the Internet or write (use) detailed supporting materials.
(ii) Provide with your lectures, especially if you have many students in the
course, one more public discussion hour per week. In this additional hour
students may ask anything related to topics already presented. Typically
they ask for more careful repetitions of some complex parts of the lecture
or for alternative explanations. Anonymous, written questions should be
allowed also.
(iii) Do not save time when one needs to develop concepts and ideas on an
informal level or to create new terms. This often underestimated part of
the lecture is at least as important as the correct, detailed presentation
of results and their proofs. Exactly telling the development of ideas in a
scientiﬁc discipline in a broad context essentially contributes to a deeper
understanding of the subject and motivates the student to deal with the
topic.

1.5 To the Teacher
17
(iv) Organize small groups for exercises. Take care in choosing exercises for
homework in order to ﬁx and deepen the understanding of the actual topic
of your lecture. The solutions of the homework have to be made public
before meeting the students for exercises in order to prevent the exercises
from becoming a presentation of correct solutions. Alternative solutions
and the most frequent mistakes have to be discussed. All homework has
to be individually corrected and given back to the students.

This page intentionally left blank

2
Fundamentals
At the end of the work
we learn only
with what we should have begun.
Blaise Pascal
2.1 Objectives
The aim of this chapter is to provide the fundamental basis for the design of
randomized algorithms.
Section 2.2 begins with an introduction to the fundamental concepts of
probability theory, and we deﬁne there key terms such as elementary events,
events, probability space, random variables, and the expectation of a random
variable. Our presentation is restricted to ﬁnite probability spaces, because on
the one hand they are suﬃcient for our purposes (for modeling randomized
computations considered in this textbook), and on the other hand we avoid
the presentation of unnecessary, opaque abstractions of measure theory.
In Section 2.3 we learn how to use probability spaces for modeling random-
ized algorithms. Special attention is called to the choice of random variables
for analyzing the eﬃciency and the error probability of designed randomized
algorithms.
The fundamental classiﬁcation of randomized algorithms with respect to
their error probability is introduced in Section 2.4. Basically, we distinguish
between Las Vegas algorithms, that never err (their error probability is equal
to 0), and Monte Carlo algorithms that possess a positive error probability.
Monte Carlo algorithms are further partitioned into three classes with respect
to the speed of reducing their error probability by independently repeating
randomized computations of the algorithms on the same input.
Section 2.5 is devoted to the modeling of randomized algorithms for solving
discrete optimization problems. Here, one considers a special classiﬁcation of
randomized algorithms that follows the goals of discrete optimization and is
based on the concept of approximation algorithms.
The topic of Section 2.6 is central to this textbook. Here, the most im-
portant and recognized paradigms and methods for the design of randomized
algorithms are presented. In this way we start here our ﬁrst attempt to pro-
vide a deeper insight into the reasons why randomized algorithms can be
essentially faster than their best deterministic counterparts.

20
2 Fundamentals
Finally, Section 2.7 summarizes the most important concepts and ideas
presented in this chapter.
2.2 Elementary Probability Theory
If an event is an inevitable consequence of another event, then one speaks
of causality or determinism. As already mentioned in the introduction, there
may exist events that are not completely determinable. Probability theory was
developed to model and analyze situations and experiments with ambiguous
outcomes. Simple examples of such experiments are tossing a coin or rolling
a 6-sided die. If there is no (apparent) possibility of predicting the outcome
of such experiments, one speaks of random events. When modeling a prob-
abilistic experiment, one considers all possible outcomes of the experiment,
called elementary events. From a philosophical point of view it is important
that these elementary events are atomic. Atomic means that an elementary
event cannot be viewed as a collection of other even more elementary events of
the experiments, and so one elementary event excludes any other elementary
event. The set of all elementary events of an experiment is called the sample
space of the experiment.
For the tossing of a coin, the elementary events are “head” and “tail”. For
the rolling of a 6-sided die the elementary events are “1”, “2”, “3”, “4”, “5”,
and “6”.
An event is a set of elementary events (i.e., a subset of the set1 of elemen-
tary events). For instance, {2, 4, 6} is an event of die rolling that corresponds
to rolling an even number. Since elementary events can be also considered
events, we represent elementary events as one element sets.
In the following we consider only experiments with ﬁnitely many elemen-
tary events to increase the transparency of the next deﬁnition. Our aim now
is to develop a reasonable theory that assigns a probability to every event.
This aim was not easy to achieve. Probability theory took almost 300 years to
advance from the works of Pascal, Fermat, and Huygens in the middle of the
17th century to the currently accepted axiomatic deﬁnition of probability by
Kolmogorov. Limiting the set S of elementary events to a ﬁnite set is helpful
for overcoming the technicalities associated with a possible uncountability of
S in the general deﬁnition of Kolmogorov2. The basic idea is to deﬁne the
probability of an event E as
the ratio between the sum of probabilities of (favorable) ele-
mentary events involved in E to the sum of the probabilities of
all possible elementary events.
(2.1)
1of the sample space
2These technicalities arise for a correct handling of sets of elementary events that
are not countable.

2.2 Elementary Probability Theory
21
Fixing the probability of events in this way, one standardizes the proba-
bility values, in the sense that probability 1 corresponds to a certain event3
and probability 0 corresponds to an impossible (empty4) event.
Another important point is that the probabilities of elementary events
unambiguously determine the probabilities of all events.
For symmetric experiments such as tossing a coin, one wants to assign the
same probability to all elementary events.
Let Prob(E) be the probability of an event E. In our model, the result of
the experiment must be one of the elementary events; hence we set
Prob(S) = 1
for the sample set S of all elementary events. Then, for the rolling of a die,
we have
Prob({2, 4, 6}) = Prob({2}) + Prob({4}) + Prob({6})
Prob(S)
= Prob({2}) + Prob({4}) + Prob({6})
= 1
6 + 1
6 + 1
6 = 1
2,
i.e., the probability of getting an even number is exactly 1/2. Following the
concept (2.1) of measuring probability, we obtain
Prob(A ∪B) = Prob(A) + Prob(B)
Prob(S)
= Prob(A) + Prob(B)
for all disjoint events A and B. These considerations result in the following
axiomatic deﬁnition of probability. Let, for any set A,
P(A) = {B | B ⊆A}
be the power set of A.
Deﬁnition 2.2.1. Let S be the sample space of a probability experiment. A
probability distribution on S is every function
Prob : P(S) →[0, 1]
that satisﬁes the following conditions (probability axioms):
(i) Prob({x}) ≥0 for every elementary event x,
(ii) Prob(S) = 1, and
(iii) Prob(A ∪B) = Prob(A) + Prob(B) for all events A, B ⊆S with A ∩B =
∅.
3to the event S consisting of all elementary events
4called also null event

22
2 Fundamentals
The value Prob(A) is called the probability of the event A. The pair
(S, Prob) is called a probability space. If
Prob({x}) = Prob({y}) = 1
|S|
for all x, y ∈S, Prob is called the uniform probability distribution on
S.
Observe, that exactly the condition (iii) of Deﬁnition 2.2.1 is the formal-
ization of our informal concept (2.1) of probability.
Exercise 2.2.2. Prove that the following properties hold for every probability
space (S, Prob):
(i) Prob(∅) = 0.
(ii) Prob(S −A) = 1 −Prob(A) for every A ⊆S.
(iii) Prob(A) ≤Prob(B), for all A, B ⊆S with A ⊆B.
(iv) Prob(A ∪B) = Prob(A) + Prob(B) −Prob(A ∩B)
≤Prob(A) + Prob(B) for all A, B ⊆S.
(v) Prob(A) = 
x∈A Prob(x) for all A ⊆S.
We observe that all properties from 2.2.2 correspond to our intuition, and
hence to the informal concept (2.1) of probability.
Thus the addition of probabilities corresponds to the idea that the
probability of several pairwise exclusive (disjoint) events is the sum of
the probabilities of these events.
Exercise 2.2.3. In fact, the condition (v) of Exercise 2.2.2 is an exact formu-
lation of the notion of probability with respect to (2.1). Hence, one can take
the conditions (i) and (ii) of Deﬁnition 2.2.1 and (v) of Exercise 2.2.2 in order
to get an alternative deﬁnition of probability distribution. Prove that such a
deﬁnition of probability distribution on S is equivalent to Deﬁnition 2.2.1.
Example 2.2.4. Let us consider the sample space
S3 = {(x, y, z) | x, y, z ∈{head, tail}}
of the experiment of tossing three coins. We account for the order of tossing
the coins, i.e., an elementary event (x1, x2, x3) describes the outcome of the
experiment where xi is the result of the i-th coin tossing. Assuming a “fair”
tossing of “fair” coins, one has
Prob({a}) =
1
|S3| = 1
8
for each elementary event a ∈S3.

2.2 Elementary Probability Theory
23
How high is the probability of getting at least one head? The corresponding
event is
HEAD = {(head, head, head), (head, head, tail), (head, tail, head),
(tail, head, head), (head, tail, tail), (tail, head, tail),
(tail, tail, head)}.
Hence,
Prob(HEAD) =

a∈HEAD
Prob({a}) = 7 ·
1
|S3| = 7
8.
To estimate Prob(HEAD) in an easier way, one can consider the complemen-
tary event
S3 −HEAD = {(tail, tail, tail)}
to S3. Based on the fact
Prob(S3 −HEAD) =
1
|S3| = 1
8
one immediately gets (see also (ii) of Exercise 2.2.2)
Prob(HEAD) = Prob(S3 −(S3 −HEAD)) =
= 1 −Prob(S3 −HEAD) = 1 −1
8 = 7
8,
because HEAD = (S3 −(S3 −HEAD)).
⊓⊔
Exercise 2.2.5. Let n and k be integers, n ≥k ≥0. Let us consider the ex-
periment of tossing n coins and let (Sn, Prob) be the corresponding probability
space, where
(i) Sn = {(x1, x2, . . ., xn) | xi ∈{head, tail}}, and
(ii) Prob is a uniform probability distribution on Sn.
(i) How large is the probability to get “head” exactly k times?
(ii) How large is the probability to get “head” at least (at most) k times?
Exercise 2.2.6. As already observed, condition (iii) of Deﬁnition 2.2.1 (or
condition (v) of Exercise 2.2.2) is the kernel of the deﬁnition of a probability
distribution on a sample space S. Condition (i) requiring Prob({x}) ≥0
for every x ∈S is natural, because we no not have any interpretation for
negative probabilities. But condition (ii) is not necessary. Why did we decide
to introduce (ii)? What drawbacks could appear if (ii) were not part of the
deﬁnition of probability distribution ?
We agreed above that the addition of probabilities corresponds to the
fundamental idea that the probability of several pairwise exclusive (disjoint)
events is the sum of the probabilities of these events. Now, we prove the
following fundamental question:

24
2 Fundamentals
To what does the multiplication of probabilities correspond?
Consider two probabilistic experiments that are independent in the sense
that the result of an experiment has no inﬂuence on the result of the other
experiment. An example of such a situation is the rolling of a die twice. It does
not matter, whether one rolls two dice at once or whether one uses the same
die twice, because the results do not inﬂuence each other. For instance, the
elementary event “3” of the ﬁrst roll does not have any inﬂuence on the result
of the second roll. We know that Prob({i}) = 1
6 for both experiments, and
for all i ∈{1, 2, . . ., 6}. Consider now joining both probabilistic experiments
into one probabilistic experiment. The set of elementary events of this joint
experiment is
Q2 = {(i, j) | i, j ∈{1, 2, . . ., 6}}
where, for an elementary event (i, j) of Q2, i is the result of the ﬁrst roll and
j is the result of the second roll. What is the fair probability distribution Prob2
over Q2, that can be determined from the basic experiment({1, 2, . . ., 6}, Prob)?
We consider our hypothesis that
the probability of an event consisting of two fully independent
events is equal to the product of the probabilities of these events,
so that
Prob2({(i, j)}) = Prob({i}) · Prob({j}) = 1
6 · 1
6 = 1
36
for all i, j ∈{1, 2, . . ., 6}. We verify the correctness of this hypothesis for our
example. The sample space Q2 contains exactly 36 elementary events, and
each of these elementary events is equally probable. Hence
Prob2({(i, j)}) = 1
36
for all (i, j) ∈Q2.
Exercise 2.2.7. Let k be a positive integer. Let (S, Prob) be a probability
space where Prob is a uniform probability distribution over the sample space
S = {0, 1, 2, . . ., 2k −1}. Create (S, Prob) from k coin tossing experiments.
The above example conﬁrms our intuition (hypothesis), but it does not
suﬃce for fully realizing exactly why the term of independency of two events is
so strongly related to the product of their probabilities. To be really convinced
about the truthfulness (validity) of our hypothesis, we introduce the notion
of conditional probabilities.
The notions deﬁned above are suitable and useful when looking at an
experiment only once, namely at the very end. But sometimes one can obtain
partial information about the outcome of an experiment by some intermediate
observation. For instance, we ﬂip three coins one after the other and look at the
result of the ﬁrst coin ﬂipping. Knowing this result one can ask for estimating

2.2 Elementary Probability Theory
25
the probability of getting at least two heads in the whole experiment. Or,
somebody tells us that the result (x, y, z) contains at least one head and
knowing this fact, we have to estimate the probability that (x, y, z) contains
at least two heads. The tasks of this kind result in the following deﬁnition of
conditional probability, which is an important instrument in the analysis of
probabilistic experiments.
Deﬁnition 2.2.8. Let (S, Prob) be a probability space. Let A and B be events
(A, B ⊆S), and let Prob(B) ̸= 0.
The conditional probability of the event A given that the event B occurs
(with certainty) is
Prob(A|B) = Prob(A ∩B)
Prob(B)
.
We also say Prob(A|B) is the probability of A given B.
Observe that the deﬁnition of conditional probability is natural,5 because
(i) A ∩B consists of all elementary events that are in both A and B, and
(ii) B happens with certainty, i.e., no elementary event from A−B can occur.6
Thus, when dividing Prob(A ∩B) by Prob(B), one normalizes the probabil-
ities of all elementary events in B, because

e∈B
Prob({e})
Prob(B) =
1
Prob(B) ·

e∈B
Prob({e})
=
1
Prob(B) · Prob(B) = 1.
The intuitive meaning of conditional probabilities we try to formalize is
that
the sample space S is exchanged for the sample space B ⊆S, because
B now contains all elementary events that may appear (no elementary
event from S −B can occur). Thus, the conditional probability of A
given B is the ratio of the probability of the event A∩B and the event
B.
One can consider the exchange of S for B as follows. Every elementary
event s ∈S has probability Prob({s}) in the probability space (S, Prob).
When S is exchanged for a B ⊂S, and B occurs with certainty, one has to
take a new probability space (B, ProbB) as the model of the experiment. This
means one has to ﬁx the probability ProbB({s}) for each s ∈B. How do we
do it in the sense of our informal concept of conditional probability? The only
requirements are
5i.e., it corresponds to our intuition about the meaning of independence
6Observe that A = (A ∩B) ∪(A −B).

26
2 Fundamentals
(i) ProbB(B) = 1, and
(ii) the ratios between the probabilities of arbitrary two elementary events
from B ⊆S may not change,7 i.e.,
Prob({a})
Prob({b}) = ProbB({a})
ProbB({b})
for all a, b ∈B with Prob({b}) ̸= 0.
Deﬁnition 2.2.8 forces us to take
ProbB({s}) = Prob({s} | B) = Prob({s})
Prob(B)
for every s ∈B, and so
ProbB({a})
ProbB({b}) =
Prob({a})
Prob(B)
Prob({b})
Prob(B)
= Prob({a})
Prob({b})
for all a, b ∈B with Prob({b}) ̸= 0.
Exercise 2.2.9. Let (S, Prob) be a probability space. Let B ⊆S, Prob(B) ̸=
0, and let
ProbB(A) = Prob(A|B)
for all A ⊆B be a function from P(B) to [0, 1]. Prove that (B, ProbB) is a
probability space.
Example 2.2.10. Consider the experiment of ﬂipping three coins. To model it
we used the probability space (S3, Prob), where
S3 = {(x, y, z) | x, y, z ∈{head, tail}}
and Prob is the uniform probability distribution on S3. Let A be the event
that the outcome involves at least two heads and let B the event that the
result of the experiment contains at least one tail. Obviously,
A = {(head, head, head), (head, head, tail), (head, tail, head), (tail, head, head)}
and so
Prob(A) = 4
8 = 1
2.
Since S −B = {(head, head, head)}, we have Prob(S −B) = 1
8, and so
Prob(B) = Prob(S −(S −B)) = 1 −1
8 = 7
8.
Since A∩B = {(head, head, tail), (head, tail, head), (tail, head, head)}, we have
7with respect to the ratios in the probability space (S, Prob)

2.2 Elementary Probability Theory
27
Prob(A ∩B) = 3
8.
From Deﬁnition 2.2.8 of conditional probability we obtain
Prob(A|B) =
def.
Prob(A ∩B)
Prob(B)
=
3
8
7
8
= 3
7.
Let us check whether this corresponds to our intuition of conditional proba-
bility. If one knows that B occurs with certainty, then the sample space S3
is reduced to B, because the elementary events from S3 −B cannot occur.
Since all elementary events in S3 have the same probability, the elementary
events of B have to have the same probability too. In this way, we get a new
probability space (B, ProbB) with
ProbB({x}) =
1
|B| = 1
7
for every elementary event x ∈B. We extend the deﬁnition of ProbB for all
C ⊆B by
ProbB(C) =

s∈C
ProbB({s}) .
We observe that ProbB satisﬁes the conditions (i), (ii), and (iii) of Def-
inition 2.2.1, and so (B, ProbB) is a probability space. If one wants to
study the occurrence of A in (B, ProbB), then one has to reduce A to
AB = A ∩B, because no y ∈A −B is an elementary event in B. Clearly,
ProbB(AB) = ProbB(A ∩B) is the probability of the occurrence of an elemen-
tary event from A in the probability space (B, ProbB), and so the conditional
probability of A given B. Let us estimate ProbB(A ∩B) in (B, ProbB). Since
|A ∩B| = 3, we have
ProbB(A ∩B) =

x∈A∩B
ProbB({x}) = 1
7 + 1
7 + 1
7 = 3
7.
We see that Prob(A|B) = ProbB(A ∩B).
⊓⊔
Our hypothesis is that the probability of the occurrence of two indepen-
dent8 events is the product of the probabilities of these events. Let us set this
hypothesis in a formal deﬁnition and check whether it really corresponds to
our interpretation of independence.
Deﬁnition 2.2.11. Let (S, Prob) be a probability space. Two events A, B ⊆S
are independent, if
Prob(A ∩B) = Prob(A) · Prob(B) .
8The occurrence of one of these events does not have any inﬂuence on the prob-
ability of the other event.

28
2 Fundamentals
Example 2.2.12. Consider once again the experiment of ﬂipping three coins.
Let
A = {(head, head, head), (head, head, tail), (head, tail, head), (head, tail, tail)}
be the event that the result of the ﬁrst coin ﬂipping is “head”. Clearly,
Prob(A) =
4
|S3| = 4
8 = 1
2.
Let
B = {(head, tail, head), (head, tail, tail), (tail, tail, head), (tail, tail, tail)}
be the event that the outcome of the second coin ﬂipping is “tail”. Obviously,
Prob(B) =
4
|S3| = 4
8 = 1
2.
Since A ∩B = {(head, tail, head), (head, tail, tail)}, we have
Prob(A ∩B) = 2
8 = 1
4 = 1
2 · 1
2 = Prob(A) · Prob(B) .
Now, with respect to Deﬁnition 2.2.11 we can say that A and B are indepen-
dent. Observe, that this exactly corresponds to our interpretation of indepen-
dence because the result of the ﬁrst coin ﬂipping does not have any inﬂuence
on the result of the second coin ﬂipping, and vice versa.
⊓⊔
The following assertion relates independence and conditional probability
to each other. This way, one has got a new deﬁnition of the independence of
two events.
Lemma 2.2.13. Let (S, Prob) be a probability space. Let A, B ⊆S and let
Prob(B) ̸= 0. Then, A and B are independent if and only if
Prob(A|B) = Prob(A) .
Proof. We prove the equivalence by proving the two corresponding implica-
tions.
(i) Assume A and B are independent and Prob(B) ̸= 0. From Deﬁni-
tion 2.2.11, we have
Prob(A ∩B) = Prob(A) · Prob(B)
and consequently
Prob(A|B) =
def.
Prob(A ∩B)
Prob(B)
= Prob(A) · Prob(B)
Prob(B)
= Prob(A) .

2.2 Elementary Probability Theory
29
(ii) Assume Prob(A|B) = Prob(A) and Prob(B) ̸= 0. Then,
Prob(A) = Prob(A|B) =
def.
Prob(A ∩B)
Prob(B)
.
Multiplying this equality by Prob(B) one obtains
Prob(A ∩B) = Prob(A) · Prob(B) ,
and so A and B are independent.
⊓⊔
Imagine that the assertion of Lemma 2.2.13 captures exactly our intuitive
interpretation of the independence of two events.
If A and B are independent, then the occurrence of B with cer-
tainty does not change the probability of A.
We were able to transparently show, why for two independent events A and
B, the equality
Prob(A ∩B) = Prob(A) · Prob(B)
must hold. It is a direct consequence of the equality
Prob(A|B) = Prob(A) ,
which truly reﬂects our imagination of the term of independence of two events
A and B.
Exercise 2.2.14. Let (S3, Prob) be the probability space of the experiment
of ﬂipping three coins.
(i) Let A be the event that the number of heads is even. Does there exist an
event B ⊂S3 such that A and B are independent?
(ii) Let D be the event that either the result of the second coin ﬂipping is tail
or the result of the third coin ﬂipping is tail. Find all events C such that
C and D are independent.
Exercise 2.2.15. Let (S, Prob) be a probability space, and let A and B be
two events having positive probabilities. Prove the following equalities:9
(i) Prob(A ∩B) = Prob(B) · Prob(A|B),
(ii) Prob(A|B) = Prob(A) · Prob(B|A)
Prob(B)
, and
(iii) Prob(A|B) =
Prob(A)·Prob(B|A)
Prob(A)·Prob(B|A)+Prob(S −A)·Prob(B|S −A).
9The equality (ii) is known as Bayes’ Theorem.

30
2 Fundamentals
Exercise 2.2.16. Let (S, Prob) be a probability space. Prove, for all events
A1, A2, . . ., An ⊆S, such that
Prob(A1) ̸= 0, Prob(A1 ∩A2) ̸= 0, . . .,
Prob(A1 ∩A2 ∩. . . ∩An−1) ̸= 0,
the following equality
Prob(A1 ∩A2 ∩. . . ∩An) = Prob(A1) · Prob(A2|A1) ·
· Prob(A3|A1 ∩A2) · . . .
· Prob(An|A1 ∩A2 ∩. . . ∩An−1) .
Next, we deﬁne a term that is crucial for the analysis of random experi-
ments. In this book it will become a powerful instrument for analyzing ran-
domized algorithms.
Let IR denote the set of real numbers.
Deﬁnition 2.2.17. Let S be a ﬁnite10 sample space of a probabilistic experi-
ment. Every function X from S to IR is called a (discrete) random variable
on S.
This means that by determining (choosing) an X, one associates a real
number with every elementary event of S (outcome of the experiment). The
main point is that we have a choice of the random variable, and we use it in
order to express what is of our interest. For instance, we will later consider a
probability space as a probability distribution over all computations (runs) of
a randomized algorithm on a ﬁxed given input. When one wants to investigate
the eﬃciency of this randomized algorithm on this input, then it is convenient
to choose a random variable that assigns its length to any computation. Us-
ing this random variable, one can calculate the “expected” complexity of the
randomized algorithm on the given input as the weighted average value of this
random variable, where the weights are given by the probabilities of particular
computations. Another convenient choice for a random variable is to assign
1 to every computation calculating the correct output, and 0 to all computa-
tions with a wrong result. In this way one can investigate the probability11 of
computing the correct result for the given input.
When S is ﬁnite (countable), then the set
IRX = {x ∈IR | ∃s ∈S, such that X(s) = x}
is ﬁnite (countable) for any random variable from S to IR.
10To exchange “ﬁnite” for “countable” in this deﬁnition does not change anything
for the terms deﬁned.
11Again, this probability is the weighted average value of the random variable,
where the weights are given by the probabilities of the elementary events (compu-
tations).

2.2 Elementary Probability Theory
31
Deﬁnition 2.2.18. Let (S, Prob) be a probability space and let X be a random
variable on S. For every z ∈IR, we deﬁne the event X = z as
Event(X = z) = {s ∈S | X(s) = z}.
The function fX : IR →[0, 1], deﬁned by
fX(z) = Prob(Event(X = z))
for all z ∈IR, is called the probability density function of the random
variable X.
The distribution function of X is a function DisX : IR →[0, 1], deﬁned
by
DisX(z) = Prob(X ≤z) =

y≤z
y∈IRX
Prob(Event(X = y)) .
In order to shorten our notation in what follows, we use the notation X = z
instead of Event(X = z), and consequently the notation Prob(X = z) is used
instead of Prob(Event(X = z)).
Lemma 2.2.19. Let (S, Prob) be a probability space and let X be a random
variable on S. Then, for every z ∈IR,
(i) Prob(X = z) ≥0,
(ii) 
y∈IRX Prob(X = y) = 1, and
(iii) fX(z) = Prob(X = z) =

s∈S
X(s)=z
Prob({s}).
Proof. The property (i) is obvious, because X = z is an event in S. The
property (iii) directly follows from the deﬁnition of fX and from the fact,
that Prob is a probability distribution over S (see (v) in Exercise 2.2.2). The
property (ii) is a direct consequence of (iii), because

y∈IRX
Prob(X = y) =
(iii)

y∈IRX

s∈S
X(s)=y
Prob({s}) =

s∈S
Prob({s}) = 1.
⊓⊔
An interesting consequence of Lemma 2.2.19 is that by the choice of a
random variable X on a sample space S of a probability space (S, Prob), one
creates a new probability space (IRX, FX), where
IRX = {x ∈IR | ∃s ∈S with X(s) = x}
and
FX(B) =

y∈B
fX(y)
for all B ⊆IRX.

32
2 Fundamentals
Exercise 2.2.20. Let (S, Prob) be a probability space and let X be a random
variable on S. Prove that (IRX, FX) is a probability space.
Example 2.2.21. Consider the experiment of rolling three dice. The outcome
of rolling one die is one of the numbers 1, 2, 3, 4, 5 and 6. We consider “fair”
dice, so every outcome from {1, 2, 3, 4, 5, 6} has the same probability. Thus,
the experiment is described by the probability space (S, Prob) with
S = {(a, b, c) | a, b, c ∈{1, 2, 3, 4, 5, 6}}
and
Prob({s}) = 1
63 =
1
216
for all s ∈S.
Consider the random variable X, deﬁned by
X((a, b, c)) = a + b + c,
i.e., as the sum of the values of all three dice. For instance, X((2, 5, 1)) =
2 + 5 + 1 = 8. The probability of the event X = 5 is
Prob(X = 5) =

s∈S
X(s)=5
Prob({s})
=

a+b+c=5
a,b,c∈{1, ...,6}
Prob({(a, b, c)})
= Prob({(1, 1, 3)}) + Prob({(1, 3, 1)})
+Prob({(3, 1, 1)}) + Prob({(1, 2, 2)})
+Prob({(2, 1, 2)}) + Prob({(2, 2, 1)})
= 6 ·
1
216 = 1
36.
Let Y be the random variable deﬁned by
Y ((a, b, c)) = max{a, b, c} for every (a, b, c) ∈S.
Let us calculate the probability of the event Y = 3, i.e., the highest outcome
in the experiment is 3.
Prob(Y = 3) =

s∈S
Y (s)=3
Prob({s}) =

max{a,b,c}=3
a,b,c∈{1, ...,6}
Prob({(a, b, c)})
=

b,c∈{1,2}
Prob({(3, b, c)}) +

a,c∈{1,2}
Prob({(a, 3, c)})
+

a,b∈{1,2}
Prob({(a, b, 3)}) +

c∈{1,2}
Prob({(3, 3, c)})

2.2 Elementary Probability Theory
33
+

b∈{1,2}
Prob({(3, b, 3)}) +

a∈{1,2}
Prob({(a, 3, 3)})
+Prob({(3, 3, 3)})
=
4
216 +
4
216 +
4
216 +
2
216 +
2
216 +
2
216 +
1
216
= 19
216.
⊓⊔
Exercise 2.2.22. Estimate the probability density function DisX and the
distribution function fY for the random variables X and Y from Example
2.2.21.
Next, we deﬁne the independency of two random variables as a natural
generalization of the interdependence of two events.
Deﬁnition 2.2.23. Let (S, Prob) be a probability space, and let X and Y be
two random variables on S. We introduce the notation
Event(X = x and Y = y) = Event(X = x) ∩Event(Y = y) .
We say that the random variables X and Y are independent if, for all
x, y ∈IR,
Prob(X = x and Y = y) = Prob(X = x) · Prob(Y = y) .
To illustrate the notation of the independence of random variables, we
consider the experiment of rolling three dice with the random variables X
and Y deﬁned by
X((a, b, c)) =
	
1 a is even
0 a is odd
and
Y ((a, b, c)) = b
for all (a, b, c) ∈S.
Clearly,
Prob(X = 1) = 1
2 = Prob(X = 0)
and
Prob(Y = i) = 1
6
for all i ∈{1, . . ., 6}. Then, for all i ∈{1, . . ., 6}
Prob(X = 1 and Y = i) = Prob
	
(a, i, c)



a is even, and
c ∈{1, . . ., 6}

= 18
216 = 1
12 = 1
2 · 1
6
= Prob(X = 1) · Prob(Y = i) .

34
2 Fundamentals
Since the same equality holds for the case X = 0, we can conclude that X
and Y are independent.12
The simplest and most useful characterization of the distribution of a
random variable is the weighted average of the values it takes on. This average
value is called the expected value in what follows. Our motivation for the study
of the expected value of random variables is in applying it as an instrument
for analyzing the eﬃciency and reliability of randomized algorithms.
Deﬁnition 2.2.24. Let (S, Prob) be a probability space and let X be a random
variable on S. The expectation of X (or the expected value of X) is
E[X] =

x∈IRX
x · Prob(X = x) ,
if this sum is ﬁnite13 or converges absolutely.
The following lemma provides another possibility of calculating the expec-
tation E[X] of a random variable X.
Lemma 2.2.25. Let (S, Prob) be a ﬁnite probability space and let X be a
random variable on S. Then,
E[X] =

s∈S
X(s) · Prob({s}) .
Proof. For any random variable X on S
E[X] =
def.

x∈IRX
x · Prob(X = x)
=

x∈IRX
x ·

s∈S
X(s)=x
Prob({s})
{since Event(X = x) = {s ∈S | X(s) = x}}
=

x∈IRX

s∈S
X(s)=x
x · Prob({s})
=

x∈IRX

s∈S
X(s)=x
X(s) · Prob({s})
=

s∈S
X(s) · Prob({s})
{since X is a function on S, i.e., for every s ∈S there exists exactly
one x ∈IR with X(s) = x}
⊓⊔
12This may not be surprising, because the value of X((a, b, c)) depends on the
outcome of the ﬁrst die rolling only and the value of Y depends on the outcome of
the second die rolling only.
13If S is ﬁnite, then this sum must be ﬁnite, too.

2.2 Elementary Probability Theory
35
Exercise 2.2.26. Let (S, Prob) be a probability space and let X and Y be
two random variables on S such that X(s) ≤Y (s) for all s ∈S. Prove that
E[X] ≤E[Y ] .
In the analysis of randomized algorithms we frequently use a special type
of random variable, called indicator variable. A random variable X is called an
indicator variable, if it takes only values 0 and 1, i.e., if X is a function from
S to {0, 1}. An indicator variable X on S partitions S into two subclasses.
One class contains all elementary events s with X(s) = 1 and the other one
contains all elementary events u with X(u) = 0. For instance, if S is the set
of all runs (computations) of a randomized algorithm on a given input, then
one can mark all runs s with the correct output by X(s) = 1 and all runs u
with a wrong result by X(u) = 0. In general, for any event A ⊆S, one can
take an indicator variable XA, such that
A = {s ∈S | XA(s) = 1} = Event(XA = 1) , and
S −A = {s ∈S | XA(s) = 0} = Event(XA = 0) .
Then,
E[XA]
=
Lem.2.2.25

s∈S
XA(s) · Prob({s})
=

s∈A
XA(s) · Prob({s}) +

s∈S−A
XA(s) · Prob({s})
=

s∈A
1 · Prob({s}) +

s∈S−A
0 · Prob({s})
=

s∈A
Prob({s})
=
Prob(A) .
We have proved the following assertion.
Lemma 2.2.27. Let (S, Prob) be a probability space. For every indicator vari-
able XA on S with A={s ∈S |XA(s) = 1},
E[XA] = Prob(A) ,
i.e., the expectation of XA is equal to the probability of the event A.
For any random variable X on S and any function g : IR →IR, the function
Z = g(X) deﬁned by
Z(s) = g(X(s)) for all s ∈S,
is a random variable on S, too. For instance, if for given a, b ∈IR,

36
2 Fundamentals
g(y) = a · y + b
for every y ∈IR, then
Z(s) = g(X(s)) = a · X(s) + b,
and
E[Z] = E[a · X + b] =

x∈IRX
(a · x + b) · Prob(X = x)
= a ·

x∈IRX
x · Prob(X = x) + b ·

x∈IRX
Prob(X = x)
= a · E[X] + b.
The property
E[a · X + b] = a · E[X] + b
of random variables is called weak linearity of expectation.
Often one needs random variables that are a combination of several random
variables.
Deﬁnition 2.2.28. Let (S, Prob) be a probability space. Let X1, X2, . . ., Xn
be random variables on S. We denote by
X1 + X2 + . . . + Xn
or by n
i=1 Xi the random variable Z = n
i=1 Xi deﬁned by
Z(s) = X1(s) + X2(s) + . . . + Xn(s) =
n

i=1
Xi(s)
for all s ∈S. We denote by
X1 · X2 · . . . · Xn
or by n
i=1 Xi the random variable Y deﬁned by
Y (s) = Y1(s) · Y2(s) · . . . · Yn(s) =
n

i=1
Yi(s)
for all s ∈S.
The following property of the expectation of X1 + X2 + . . . + Xn is often
applied in the analysis of randomized systems.
Lemma 2.2.29. Let (S, Prob) be a probability space and let X and Y be two
random variables on S. Then
E[X + Y ] = E[X] + E[Y ] .

2.3 Models of Randomized Algorithms
37
Proof. Let Z denote the random variable X + Y . Then
E[X + Y ] = E[Z] =

s∈S
Z(s) · Prob({s})
{by Lemma 2.2.25}
=

s∈S
(X(s) + Y (s)) · Prob({s})
{by deﬁnition of Z = X + Y }
=

s∈S
X(s) · Prob({s}) +

s∈S
Y (s) · Prob({s})
= E[X] + E[Y ]
{by Lemma 2.2.25}
⊓⊔
The property
E[X + Y ] = E[X] + E[Y ]
of random variables is called linearity of expectation.
Exercise 2.2.30. Prove that
E[X1 + X2 + . . . + Xn] = E[X1] + E[X2] + . . . + E[Xn]
for all random variables X1, X2, . . ., Xn on a sample space S.
Exercise 2.2.31. Let (S, Prob) be a probability space and let X and Y be two
diﬀerent random variables on S. Let Z = min{X, Y } be the random variable
deﬁned by Z(s) = min{X(s), Y (s)} for every s ∈S. Prove or disprove the
following claim:
E[Z] = min{E[X] , E[Y ]}.
2.3 Models of Randomized Algorithms
The goal of this section is to show how randomized algorithms can be modeled
by means of probability spaces, and how the concept of random variables can
be used for analyzing randomized computations.
Randomized algorithms are a special case of stochastic algorithms. A
stochastic algorithm can be viewed as an algorithm that is partially controlled
by a random process. A stochastic algorithm is allowed to ﬂip a “fair” coin
whenever needed, and the outcome of the coin ﬂipping is used to decide in
which way the algorithm will continue in its work. The quality of a stochastic
algorithm is usually measured in the running time and in the degree of reli-
ability (correctness). The meaning of the term “degree of reliability” can be

38
2 Fundamentals
interpreted in diﬀerent ways. For instance, one can consider a probability dis-
tribution over all feasible inputs, and then measure the degree of reliability as
the probability of getting the correct result on a randomly chosen input. This
means that one can accept a stochastic algorithm that behaves “poorly” (it
runs for too long, or incorrectly) on some input instances when the algorithm
is “good” (eﬃcient, and correct with high probability) for most inputs. The
randomized algorithms are a special case of stochastic algorithms in the sense
that randomized algorithms are not allowed to behave poorly on any input
instance.
The design of randomized algorithms is subject to the very strong
requirement, that the randomized algorithms work eﬃciently and cor-
rectly with high probability on every input, i.e., that they are reliable
for each input data.
Because of the requirement of eﬃciently computing the correct result with
a reasonable probability for each input, one has to investigate the behavior of
a randomized algorithm on any feasible input. Therefore, it does not make any
sense to consider here probability distributions on input sets. The only source
of randomness under consideration is the randomized control of the algorithm
itself. In what follows, we consider two models of randomized algorithms.
THE FIRST MODEL
This model is the simpler of the two models presented here, and it considers
a randomized algorithm A as a probability distribution over a ﬁnite collection
A1, A2, . . ., An of deterministic strategies algorithms14. This means that for
any input w, A chooses an Ai at random and lets Ai work on w. This way there
are exactly n computations of A on n, each one given by the computation of
an algorithm from {A1, A2, . . ., An} on w. In what follows, we also use the
term “a run of A on w” for each of the n computations of Ai on w for
i = 1, . . ., n. Thus, we model the experiment of the work of A on an input w
as the probability space
(SA,w, Prob),
where SA,w = {A1, A2, . . ., An} and Prob is a probability distribution over
SA,w.
14We prefare to use the term strategy because usually one understands an al-
gorithm as a program that works correctly on any input. But here, we consider a
strategy as a program that may fail for some particular inputs. To fail can mean
computing a wrong output or working too long. Later we will call randomized al-
gorithms, based on strategies that may fail in the second sense only (i.e., to be
not eﬃcient on any input), Las Vegas algorithms. Randomized algorithms that are
allowed to err (i.e., to produce wrong outputs) will be called Monte Carlo algorithms.

2.3 Models of Randomized Algorithms
39
Typically, Prob is a uniform probability distribution. We usually prefer to
consider
SA,w = {C1, C2, . . ., Cn}
as the set of all runs (computations) of A on w, where Ci is the computation
of the i-th deterministic algorithm on w. Given Ai and w, the computation
of Ci is unambiguously determined and therefore formally it does not matter
whether one consider SA,w as {A1, A2, . . ., An} or as {C1, C2, . . ., Cn}. We
prefer the latter because we in fact investigate the concrete computations
C1, . . ., Cn, and not the general descriptions of the algorithms A1, . . ., An, in
this random experiment.15
This modeling is transparently presented in Figure 2.1. For a given input
w the randomized algorithm A chooses the i-th deterministic algorithm with
probability Prob({Ai}) for i = 1, . . ., n at the beginning, and the rest of the
computation is completely deterministic.
A1
A2
A3
An
C1
C2
C3
Cn
. . .
TA,w
Prob({A1})
Prob({An})
Fig. 2.1.
As indicated in Figure 2.1, the particular runs {C1, C2, . . ., Cn} of A on
w can be of diﬀerent lengths. Let Time(Ci) denote the length (the time
complexity) of the computation Ci. If one wants to study the eﬃciency of A
on w, one can consider the random variable16 Z : SA,w →IN deﬁned by
Z(Ci) = Time(Ci) for i = 1, . . ., n.
Then one can measure the eﬃciency of the work of A on w by the expected
time complexity of A on w, deﬁned by
15of the work of A on w
16In fact, one can directly use Time as the name of this random variable.

40
2 Fundamentals
Exp-TimeA(w) = E[Z] =
n

i=1
Prob({Ci}) · Z(Ci)
=
n

i=1
Prob({Ci}) · Time(Ci) .
Since we are striving for an assured upper bound on the expected time
complexity on any input of a length n, we deﬁne the expected time complexity
of A in the worst-case manner.
The expected time complexity of a randomized algorithm A is the
function Exp-TimeA : IN →IN, deﬁned by
Exp-TimeA(n) = max{Exp-TimeA(w) | the length17of w is n}
for all n ∈IN.
If one strives for a strong upper bound on the time complexity of every
run of a randomized algorithm, one considers the time complexity of a
randomized algorithm A as the function TimeA(n) : IN →IN, deﬁned by
TimeA(n) = max{Time(C) | C is a run of A on an
input of length n}.
If one wants to measure the “reliability” of a randomized algorithm A on
an input w, the one can consider the indicator variable X : SA,w →{0, 1},
deﬁned by
X(Ci) =
	1 if Ci computes the correct result on wi
0 if Ci computes a wrong result on wi
for i = 1, . . ., n. Then,
E[X] =
n

i=1
X(Ci) · Prob({Ci}) .
=

X(Ci)=1
1 · Prob({Ci}) +

X(Ci)=0
0 · Prob({Ci})
= Prob(Event(X = 1))
= the probability that A computes the right result.
The value E[X] is called the success probability of A on w. The value
1 −E[X] is called the error probability of A on w, denoted ErrorA(w).
17How one measures the input length is determined by concrete applications. For
instance, the input length can be considered to be the number of symbols used
for the representation of the input or, more roughly, the number of the elements
(numbers, vertices of a graph, . . . ) included in the input object.

2.3 Models of Randomized Algorithms
41
The error probability of A is deﬁned in the worst-case manner as the
function
ErrorA(n) = max{ErrorA(w) | the length of w is n}
from IN to IN.
In this way ErrorA provides the guarantee that the error probability is at
most ErrorA(n) on every input of length n.
Observe that our deﬁnitions of time complexity measures assume that all
runs of A are ﬁnite,18 i.e., that A is not allowed to take an inﬁnite computation.
In general, randomized algorithms are allowed to have inﬁnite computations.
In that case one measures the expected time19 complexity over the ﬁnite
computations of A only, and calculates the probability of running an inﬁnite
computation, which is then added to the error probability (i.e., the occurrence
of an inﬁnite computation is considered to be an error).
In what follows we present two examples of randomized algorithms that
can be successfully modeled and analyzed by the formalism described above.
Example 2.3.32. First, we consider the randomized protocol designed in Sec-
tion 1.2 for the comparison of two strings x and y of length n. At the beginning,
this protocol R uniformly chooses a prime p from the set20 PRIM

n2
at ran-
dom. If Cp denotes the run of the protocol R given by the prime p on an input
(x, y), then one can model the work of R on (x, y) by the probability space
(SR,(x,y), Prob), where
(i) SR,(x,y) = {Cp | p ∈PRIM

n2
}, and
(ii) Prob is a uniform probability distribution on SR,(x,y).
Considering the notation Cp one has a bijection between PRIM

n2
and
SR,(x,y), and so we may directly use the probability space
(PRIM

n2
, Prob)
for modeling the work of R on (x, y).
It does not make any sense here to investigate the expected communication
complexity of R because all runs of R on (x, y) have the same21 complexity,
4 · ⌈log2 n⌉.
We have already ﬁxed in Section 1.3 that, for any input (x, y) with x = y,
the error probability is 0, and so we do not need to investigate it.
18In the ﬁrst model this is naturally satisﬁed because one always assumes, that
deterministic algorithms terminate on any input.
19the time complexity is not considered in such a case
20Remember that for any positive integer m, PRIM (m) denotes the set of all
primes smaller than or equal to m.
21All natural numbers smaller than n2 can be represented by ⌈log2 n2⌉bits. The
protocol ﬁxes the length of the binary representations of numbers submitted to
2 · ⌈log2 n⌉, and so the length of the message is independent of p and x mod p.

42
2 Fundamentals
To investigate the error probability of R on (x, y) for x ̸= y in the given
formal framework, we choose the indication variable X deﬁned by
X(Cp) =
	1 if p is “good”22 for (x, y)
0 if p is “bad” for (x, y).
Since
Prob(Cp) =
1
Prim (n2) for all p ∈PRIM

n2
,
and we have proved in Section 1.3 that
the number of bad primes for any input (x, y) with x ̸= y is at most
n −1,
one obtains
E[X] =

p ∈PRIM(n2)
X(Cp) · Prob({Cp})
=

p ∈PRIM(n2)
X(Cp) ·
1
Prim (n2)
=
1
Prim (n2) ·

p is good
X(Cp)
≥
1
Prim (n2) · (Prim

n2
−(n −1))
= 1 −
n −1
Prim (n2).
In this way we bound the error probability of R on (x, y) by
ErrorR((x, y)) = 1 −E[X]
≤
n −1
Prim (n2) ≤2 · ln n
n
{since Prim

n2
≥n2/ ln n2 for
all n ≥9}
for all n ≥9.
Let us now consider the modiﬁed protocol R2 that chooses two primes, p
and q, at random, and accepts an input (x, y) if and only if
(x mod p = y mod p) and (x mod q = y mod q).
(2.2)
A computation Cp,q of R2 consists of submitting
p, q, (x mod p), and (x mod q)
22Remember that p is “good” for (x, y) iﬀthe computation Cp produces the
correct output for (x, y)

2.3 Models of Randomized Algorithms
43
from RI to RII, and of the comparing of x mod p with y mod p and x mod q
with y mod q by RII. Analyzing the error probability of R2, we choose the
indicator variable Y deﬁned as follows:
Y (Cp,q) =
	
1 if p or q is good for (x, y)
0 if both p and q are bad for (x, y)
for all Cp,q ∈SR2,(x,y) = {Cr,s | r, s ∈PRIM

n2
}.
Analyzing in the probability space (SR2,(x,y), Prob2), we obtain
E[Y ] =

Cp,q ∈SR2,(x,y)
Y (Cp,q) · Prob2({Cp,q})
=

p,q ∈PRIM(n2)
Y (Cp,q) ·
1
(Prim (n2))2
= Prob2(Event(Y = 1))
= 1 −Prob2(Event(Y = 0))
= 1 −Prob2(Event(p and q are bad))
= 1 −Prob(p is bad) · Prob(q is bad)
{Because p and q were chosen independently each of
each other.}
≥1 −

n −1
Prim (n2)
2
≥1 −4 · (ln n)2
n2
for suﬃciently large n. Since E[Y ] is the success probability of the computation
of R2 on (x, y) with x ̸= y (i.e., of the event Event(Y = 1) that R2 outputs
the right answer), the error probability of R2 on (x, y) is
ErrorR2((x, y)) = 1 −E[Y ] ≤4 · (ln n)2
n2
.
⊓⊔
Exercise 2.3.33. Consider the probabilistic experiment given by the protocol
R2. Deﬁne two indicator variables X1 and X2, where X1 = 1 if and only if
the ﬁrst prime p is good for (x, y) and X2 = 1 if and only if the second prime
q is good for (x, y). Prove that X1 and X2 are independent. Can X1 and X2
be used to deﬁne the random variable Y used above?
Exercise 2.3.34. Let k be a positive integer, k ≥2. Model the work of the
protocol Rk choosing k primes from PRIM

n2
at random, and estimate the
error probability of Rk.

44
2 Fundamentals
Example 2.3.35. Consider the optimization problem MAX-SAT.23 Given a for-
mula Φ in CNF, one has to ﬁnd an assignment to the variables of Φ such that
the maximum possible number of clauses of Φ is satisﬁed. This problem is
NP-hard, and so we weaken our requirement to ﬁnd an optimal solution to
the requirement to ﬁnd a solution that satisﬁes a reasonably large proportion
of clauses with high probability. This enables us to design the following simple
and eﬃcient algorithm for MAX-SAT.
Algorithm RSAM (Random Sampling)
Input: A formula Φ = F1 ∧F2 ∧. . . ∧Fm in CNF over a set {x1, x2, . . ., xn}
of Boolean variables.
Step 1: Choose an assignment (α1, α2, . . ., αn) ∈{0, 1}n to x1, x2, . . ., xn at
random with
Prob(αi = 1) = Prob(αi = 0) = 1
2
for all i = 1, . . ., n.
Output: (α1, α2, . . ., αn).
Thus, the algorithm RSAM simply generates a random assignment to the
variables of Φ and takes it as the output. For any input the time complexity of
RSAM is the length of the output. Since every algorithm for MAX-SAT must
produce a feasible solution of this length, an asymptotically faster algorithm
than RSAM does not exist.
Each output of the algorithm RSAM is an assignment to the variables of
the given formula Φ, and so is a feasible solution for the problem instance Φ.
In this sense there are no incorrect computations, and so we need not deal
with error probability here.
We will measure the goodness of the algorithm RSAM as the ratio of the
number of satisﬁed clauses to the number of all clauses. To do that, we deﬁne,
for any input Φ = F1 ∧F2 ∧. . .∧Fm, m indicator variables Z1, Z2, . . ., Zm by
Zi(α) =
	
1 if the clause Fi is satisﬁed by α
0 if the clause Fi is not satisﬁed by α
for every α ∈{0, 1}n. Clearly, the considered probability space is
({0, 1}n, Prob),
where Prob is a uniform probability distribution over {0, 1}n. Further, we
consider the random variable
Z =
m

i=1
Zi,
23The formal deﬁnition of MAX-SAT is given in Example 2.5.64 (Section 2.5).

2.3 Models of Randomized Algorithms
45
which counts the number of satisﬁed clauses. So, we are interested in learning
E[Z]. Because of the linearity of expectation, one has
E[Z] = E
 m

i=1
Zi

=
m

i=1
E[Zi] .
To complete our calculation, we need to estimate E[Zi]. Since Zi is an
indicator variable, the expectation E[Zi] is the probability that Fi is satisﬁed.
Let, for i = 0, . . ., m,
Fi = li1 ∨li2 ∨. . . ∨lik
where lijs are k literals over k diﬀerent24 variables. The clause is not satisﬁed
if and only if all k literals are not satisﬁed. The probability that a literal
is not satisﬁed by a random assignment is exactly 1/2. Since the random
choice of a Boolean value of a variable is independent of the random choices
of assignments to all other variables, and no pair of literals of Fi is over the
same variable, the probability that none of the literals of Fi is satisﬁed is
exactly
1
2
k
= 1
2k .
Hence, the probability of satisfying Fi is
E[Zi] = 1 −1
2k .
Since every clause consists of at least one literal (i.e., k ≥1), we obtain
E[Zi] ≥1
2
for all i ∈{1, . . ., m}. Thus,
E[Z] =
m

i=1
E[Zi] ≥
m

i=1
1
2 = m
2 ,
and so one expects that a random assignment α to the variables of a given
formula satisﬁes at least half the clauses. Observe that our derivation of the
lower bound E[Zi] ≥m
2 was very rough because one can expect that most of
the clauses contain more than one literal. For instance, if all clauses contain
at least 3 literals, then we would obtain E[Zi] ≥7
8 for all i = 1, . . ., m, and
so the expectation would be that at least 7
8 of the clauses are satisﬁed.
⊓⊔
Exercise 2.3.36. Let us modify the algorithm RSAM as follows.
Input: A formula Φ = F1 ∧F2 ∧. . . ∧Fm over {x1, x2, . . ., xn} in CNF.
24If this is not the case, one can simplify this clause.

46
2 Fundamentals
Step 1: Choose uniformly an assignment (α1, α2, . . ., αn) to x1, x2, . . ., xn at
random.
Step 2: Compute the number r(α1, α2, . . ., αn) of clauses that are satisﬁed by
(α1, α2, . . ., αn).
Step 3: If r(α1, α2, . . ., αn) ≥
m
2 , then output (α1, α2, . . ., αn), else repeat
Step 1.
If this algorithm halts, then we have the assurance that it outputs an assign-
ment satisfying at least half the clauses. Estimate the expected value of the
number of executions of Step 1 of the algorithm (i.e., the expected running
time of the algorithm).
Exercise 2.3.37. Let us choose t assignments of the variables of a given for-
mula Φ at random. How large is the probability that the best one of these t
assignments satisﬁes at least half the clauses of Φ?
THE SECOND MODEL
Sometimes it is more natural to represent a randomized algorithm as a nonde-
terministic algorithm with a probability distribution for every nondeterminis-
tic choice. To simplify the matter, one usually considers random choices from
only two possibilities, each with probability 1/2. In general, one can describe
all computations (runs) of a randomized algorithm A on an input w by the
so-called computation tree25 TA,w of A on w (Figure 2.2).
TA,w
1
2
1
2
1
2
1
2
1
2
1
2
1
2
1
2
1
2
1
2
1
2
1
3
1
4
1
4
2
3
Fig. 2.2.
The vertices of the tree are labeled by the conﬁgurations of A. Every path
from the root to a leaf in this tree corresponds to a computation of A on w.
25This tree is in fact the same as a computation tree of a nondeterministic algo-
rithm, except for the labeling of the edges [Hro04].

2.3 Models of Randomized Algorithms
47
Each edge of the tree is labeled by a value from [0, 1] that determines the
probability of its choice from the given conﬁguration.
Taking the sample space SA,w as the set of all runs (computations) of
A on w, one creates the probability space (SA,w, Prob) by calculating the
probability Prob(C) of any computation C ∈SA,w as the product of all labels
(probabilities) of the edges of the corresponding path. Since every splitting of a
computation (every random choice from at least two possibilities) is controlled
by a probability distribution, the above deﬁned function Prob from SA,w to
[0, 1] is a probability distribution26 on SA,w.
Clearly, the second model is a generalization of the ﬁrst model. Because of
the simplicity and transparency of the ﬁrst model of randomized algorithms
one prefers, if possible, to use the ﬁrst way of modeling a randomized al-
gorithm. The second model is used for describing algorithms in which one
repeatedly makes a random choice after some deterministic parts of com-
putations. The well known randomized Quicksort is a representative of the
description of randomized algorithms in terms of the second model.
Example 2.3.38. We consider the problem of sorting the elements of a given set
A by comparisons of pairs of elements only, assuming there is a linear order
on all elements which are allowed to appear in the input. The well known
randomized Quicksort can be described as the following recursive procedure.
Algorithm RQS(A)
Input: A set A of elements with a given linear order.
Step 1: If A = {b} (i.e., |A| = 1), then output “b”.
If |A| ≥2, then choose an element a ∈A at random.
Step 2: Set
A< := {b ∈A | b < a}
A> := {c ∈A | c > a}
Step 3: output “RQS(A<), a, RQS(A>)”
Obviously, the algorithm RQS(A) ﬁnishes its work with a sorted sequence
of elements, and so there is no computation with a wrong output, i.e., the
error probability is 0 for every input.
On the other hand, we observe that the complexities of diﬀerent computa-
tions measured by the number of the executed comparisons of pairs of elements
can essentially diﬀer. Step 2 of RQS(A) forces exactly |A| −1 comparisons,
because every element in A −{a} has to be compared with the pivot element
a. Observe that RQS(A) has exponentially many27 diﬀerent computations on
A. If RQS always chooses the smallest or the largest element of the set to
be sorted, then any of the resulting computations has exactly n −1 recursive
calls, and the number of executed comparisons is
26This claim can be easily veriﬁed by induction on the depth of SA,w.
27in |A|

48
2 Fundamentals
n−1

i=0
i = n · (n −1)
2
∈O

n2
.
However when RQS always chooses the median as a pivot, then the classical
analysis of this “divide and conquer” strategy provides the recurrence
TimeRQS(n) ≤2 · TimeRQS
n
2

+ n −1,
whose solution is TimeRQS(n) ∈O(n · log n). The corresponding computation
has only log2 n recursive calls. Since one can still show that, for the recurrence
T (n) ≤T (n
8 ) + T (7
8 · n) + n −1,
T (n) ∈O(n · log n), RQS will behave well also if the size of |A<| very roughly
approximates |A>|. But this happens with probability at least 3/4, because
at least 6/8 = 3/4 of the elements are good choices. This is the reason for our
hope that the algorithm RQS behaves very well on average. In what follows,
we carefully analyze the expected complexity of RQS.
We have observed that the computation tree of RQS on an input is not
only very large (especially its breadth), but that it is also very irregular. The
depths (lengths) of the paths range from log2 n to n −1, and consequently
the corresponding computations have very diﬀerent execution probabilities. If
one considers the probability space (SRQS(A), Prob)28 and chooses the random
variable X deﬁned by
X(C) = the number of comparisons in C
for every computation C ∈SRQS(A), then one can use X to calculate the
expected complexity of RQS, which is E[X]. But because of the size and
irregularity of the computation tree TRQS(A), the analysis of E[X] is not only
nontrivial, but also requires a lot of eﬀort. Our next goal is to show that a
suitable choice of random variables is determinig not only the success of the
algorithm analysis, but also the hardness of the analysis.
Let s1, s2, . . ., sn be the output of RQS(A), i.e., let si be the ith smallest
element in A. We deﬁne the indicator variables Xij by
Xij(C) =
	 1 if si and sj were compared in the run C
0 if si and sj were not compared in C
for all i, j ∈{1, . . ., n}, i < j. Obviously, the random variable T deﬁned by
T (C) =
n

i=1

j>i
Xij(C)
28where Prob is not a uniform probability distribution over SRQS

2.3 Models of Randomized Algorithms
49
counts the total number of comparisons, and so E[T ] = Exp-TimeRQS(A).
Due to linearity of expectation we have
E[T ] = E
⎡
⎣
n

i=1

j>i
Xij
⎤
⎦=
n

i=1

j>i
E[Xij] .
(2.3)
In order to estimate E[T ], it remains to estimate the expectations E[Xij]
for all i, j ∈{1, . . ., n}, i < j. Let pij denote the probability that si and sj
are compared in an execution of RQS(A). Since Xij is an indicator variable,
we have29
E[Xij] = pij · 1 + (1 −pij) · 0 = pij,
(2.4)
and so it remains to estimate pij. In which computations are si and sj com-
pared? Only in those in which one of the elements si and sj is chosen as a pivot
at random by RQS(A) before any of the elements si+1, si+2, . . ., sj−1 between
si and sj have been chosen as a pivot (Figure 2.3). Namely, if the ﬁrst pivot of
the set {si, si+1, . . ., sj} is an element from the set Middle = {si+1, . . ., sj−1},
then si is put into A< and sj is put into A>, and so si and sj cannot be com-
pared in the rest of the computation. On the other hand, if si [or sj] is chosen
as the ﬁrst pivot element of the set {si, . . ., sj}, then si [sj] is compared with
all elements from Middle ∪{sj} [ or Middle ∪{si}], and so with sj [si].
s1
si−1
si
si+1 si+2
sj−1
sj
sj+1
sn
. . .
. . .
. . .
Left
Middle
Right
Fig. 2.3.
Each of the elements of A has the same probability of being chosen as the
ﬁrst pivot. If an element from Left or Right (Figure 2.3) is chosen, then si
and sj are put into the same set A> or A<, and so this choice does not have
any inﬂuence on whether si and sj will be compared later or not. Thus, we
may model this situation as a probabilistic experiment of uniformly choosing
an element from Middle ∪{si, sj} at random. Hence,
pij =
|{si, sj}|
|Middle ∪{si, sj}| =
2
j −i + 1.
(2.5)
Let Har (n) = n
k=1
1
k be the nth Harmonic number.30 Inserting (2.5) into
(2.3) we obtain
29see Lemma 2.2.27.
30For some estimations of Har (n), see Section A.3.

50
2 Fundamentals
E[T ] =
(2.3)
(2.4)
n

i=1

j>i
pij
=
(2.5)
n

i=1

j>i
2
j −i + 1
≤
n

i=1
n−i+1

k=1
2
k
{substituting k = j −i + 1}
≤2 ·
n

i=1
n

k=1
1
k
= 2 ·
n

i=1
Har (n)
= 2 · n · Har (n)
{Exercise A.3.67}
= 2 · n · ln n + Θ(n).
In this way we have showed that Exp-TimeRQS(n) ∈O(n · log n), and so
randomized Quicksort is an eﬃcient algorithm for sorting.
⊓⊔
Exercise 2.3.39. Construct the computation tree TRQS,A for an A with |A| =
5.
Exercise 2.3.40. Consider the following problem. Given a set A of elements
with a linear order and a positive integer k, k ≤|A|, ﬁnd the k-th smallest
element of A. Obviously, one can solve this problem by sorting A and then
taking the k-th smallest element. But one knows that the complexity of sorting
by comparisons is in Θ(n · log n) and so this naive approach is too costly for
searching for the k-th position in the sorted sequence only.
Therefore we propose the following algorithm RSEL (random select) for
this problem.
Algorithm RSEL(A, k)
Input: A = {a1, a2, . . ., an}, n ∈IN −{0}, and an integer k satisfying 1 ≤
k ≤n.
Step 1:
if n = 1 then
output “a1”;
else
choose uniformly an i ∈{1, 2, . . ., n} at random;

2.4 Classiﬁcation of Randomized Algorithms
51
Step 2: Compute
A< := {b ∈A | b < ai};
A> := {c ∈A | c > ai};
Step 3:
if |A<| > k then
RSEL(A<, k);
else if |A<| = k −1 then
output “ai”;
else
RSEL(A>, k −|A<| −1);
Clearly, the algorithm RSEL(A, k) computes the correct output in each run.
Show that Exp-TimeRSEL(A, k) ∈O(n).
In this section we have introduced two ways of modeling randomized al-
gorithms. It is important to say that the choice of the model is ﬁrst of all
the question of transparency. We have already observed that the ﬁrst model
is a special case of the second one. But analyzing a randomized algorithm
on a ﬁxed input, one can also represent the second model by the ﬁrst one.
One simply generates a suﬃciently large sequence of random bits at the very
beginning of the computation. Then each such random sequence determines a
run of the algorithm on the given input. Obviously, it does not matter when
the random bits are used (viewed), whether in the beginning or later one af-
ter each other during the computation. But this representation of the second
model by the ﬁrst model is not uniform31 and so we do not see any possi-
bility of expressing any randomized algorithm described by the second model
in terms of the ﬁrst model as a probability distribution over a ﬁnite set of
deterministic algorithms.
2.4 Classiﬁcation of Randomized Algorithms
The aim of this section is to introduce the fundamental and generally accepted
classiﬁcation of randomized algorithms. This classiﬁcation is based on the kind
and size of the error probability of randomized algorithms, and has nothing
to do with their design methodology. Clearly, the error probability can be
viewed as a measure of the practicality of designed algorithms, and we will
see that the main point of the classiﬁcation is not only based on measuring the
absolute size of the error probability, but is related mainly to the number of
repetitions of independent runs of the algorithms on the same input necessary
and suﬃcient in order to essentially reduce the probability of a wrong output.
In other words, this classiﬁcation focuses on the speed of the error probability
reduction with the number of repeated runs.
31Usually the length of these random sequences grows with the input length, and
so the number of all possible (over all inputs) random sequences in unbounded.

52
2 Fundamentals
The classiﬁcation of randomized algorithms is not the same for all diﬀerent
computing tasks. The meaning of a “wrong output” may vary under diﬀerent
circumstances. For solving a decision problem or for computing a function,
the error probability is really the probability of computing a wrong result. On
the other hand, when designing algorithms for optimization problems, it is not
always reasonable to consider a feasible non-optimal solution as an unwanted
result or even as an error. A feasible solution whose quality is not too far from
that of an optimal solution can be very much appreciated.
Here we start with the standard classiﬁcation of randomized algorithms
for decision problems and for computing functions. After that we present the
classiﬁcation of randomized algorithms for optimization problems separately
in Section 2.5.
LAS VEGAS ALGORITHMS
Las Vegas algorithms are randomized algorithms that guarantee that every
computed output is correct. This means that wrong results (outputs) are
forbidden in this model. In the literature one can ﬁnd two diﬀerent models of
Las Vegas algorithms. These models diﬀer in whether or not the answer “?”
with the meaning “I do not know” (“In this run I was unable to compute the
right solution”) is allowed.
First, let us consider the case that the answer “?” is not allowed. In what
follows, A(x) always denotes the output of the algorithm A on a given input
x.
Deﬁnition 2.4.41. A randomized algorithm A is called a Las Vegas algo-
rithm computing a function F if, for any input x (any argument x of F),
Prob(A(x) = F(x)) = 1.
For Las Vegas algorithms according to Deﬁnition 2.4.41, we always inves-
tigate the expected complexity (for instance, the expected time complexity
Exp-TimeA(n)). Here, one has to expect that the runs of the algorithm on an
input are of diﬀerent lengths, because if all runs of the algorithm on any given
input would have approximately the same length, then one could construct an
equally eﬃcient deterministic algorithm for this task, that simply simulates
one ﬁxed run32 of the randomized algorithm.
Exemplary illustrations of this concept of Las Vegas algorithms are the
randomized Quicksort and the randomized algorithm RSEL that were pre-
sented in the previous section. In both these algorithms we have essential
diﬀerences between the worst-case complexity and the expected complexity.
But the crucial point is that the expected complexity is very close to the
complexity of the most eﬃcient runs.
Now, let us consider the second way of deﬁning Las Vegas algorithms.
32It does matter which one, because all runs are eﬃcient.

2.4 Classiﬁcation of Randomized Algorithms
53
Deﬁnition 2.4.42. Let A be a randomized algorithm that allows the answer
“?”. We say that A is a Las Vegas algorithm for a function F if, for every
input x,
(i) Prob(A(x) = F(x)) ≥1/2, and
(ii) Prob(A(x) = “?”) = 1 −Prob(A(x) = F(x)) ≤1/2.
We observe that the condition (ii) excludes the occurrence of a wrong
output, i.e., one gets either the right output or the output “?”. In condition
(i) we require that a Las Vegas algorithm computes the correct value F(x)
with a probability greater than or equal to 1/2. The constant 1/2 is not
crucial for this deﬁnition, and can be exchanged for an arbitrary ε satisfying
0 < ε < 1. The reason for this is that for every ε ≤1/2 one can increase the
success probability (the probability of computing F(x)) to greater than 1/2
by executing a constant many independent runs of the algorithm on x.
Exercise 2.4.43. Let ε, δ be real numbers, 0 < ε < δ < 1. Let A be a
randomized algorithm that computes a function F with
Prob(A(x) = F(x)) ≥ε and Prob(A(x) = “?”) = 1 −Prob(A(x) = F(x)) .
Let, for every k ∈IN, k ≥2, Ak be the randomized algorithm that for any
input x executes k independent runs of A on x. The output of Ak is “?” if and
only if all k runs of A on x ﬁnished with the output “?”. In all other cases the
algorithm Ak computes the right result F(x). Estimate the smallest k such
that Prob(Ak(x) = F(x)) ≥δ.
In what follows, we present a Las Vegas algorithm allowing the output
“?”, and then we compare these two models of Las Vegas algorithms.
Example 2.4.44. We consider again the model of communication protocols.
We have two computers RI and RII. The input of RI consists of ten strings,
x1, x2, . . ., x10 ∈{0, 1}n, and RII also has ten strings, y1, y2, . . ., y10 ∈{0, 1}n.
The task is to estimate whether there is a j ∈{1, . . ., 10} such that
xj = yj.
If such a j exists, then the protocol has to accept the input ((x1, . . ., x10),
(y1, . . ., y10)), and if not, the input has to be rejected. As usual, the complex-
ity is measured in the number of exchanged bits. One can prove that every
deterministic protocol solving this task must allow a communication of 10n
bits. Hence, no protocol can do better than to send the whole input of RI of
10n bits to RII, and then let RII to perform the comparison.
Now, we design a Las Vegas protocol that solves the task with commu-
nication complexity of n + O(log n). We observe that the (communication)
protocol from Section 1.3 is not a Las Vegas protocol. It is true that we may
use the idea of generating a prime p at random, but we are required33 to verify
the correctness of the hypothesis proposed by the equality of the remainders
modulo p.
33because the answer of a Las Vegas protocol must be correct with certainty

54
2 Fundamentals
Protocol LV10
Initial situation: RI has ten strings, x1, x2, . . ., x10, xi ∈{0, 1}n for all i =
1, . . ., 10, and RII has ten strings, y1, y2, . . ., y10, yi ∈{0, 1}n for all
i = 1, . . ., 10.
Phase 1: RI uniformly chooses 10 primes, p1, p2, . . ., p10, from PRIM

n2
at
random.
Phase 2: RI computes
si = Number(xi) mod pi
for i = 1, 2, . . ., 10 and sends
p1, p2, . . ., p10, s1, s2, . . ., s10
to RII.
Phase 3: RII computes
qi = Number(yi) mod pi
for i = 1, 2, . . ., 10, and computes si and qi for all i ∈{1, 2, . . ., 10}.
If si ̸= qi for all i ∈{1, 2, . . ., 10}, then RII knows with certainty that
xi ̸= yi for all i ∈{1, 2, . . ., 10} and outputs “0” (“reject”).
Else, let j be the smallest integer from {1, . . ., 10}, such that
sj = qj.
Then RII sends the whole string yj and j to RI.
Phase 4 RI compares xj with yj bit by bit.
If xj = yj, then RI outputs “1” (“accept”).
If xj ̸= yj, then RI outputs “?”.
{Observe that RI really does not known the right answer in this case,
because there can exist a k > j such that sk = qk. But the protocol does
not try to check whether xk = yk in such a case.}
First, we analyze the worst-case complexity of LV10. The maximal possible
communication consists of sending
p1, p2, . . ., p10, s1, s2, . . ., s10
from RI to RII, and of sending
yj and j
from RII to RI.
All the numbers p1, p2, . . ., p10, s1, s2, . . ., s10 are smaller than n2, and so
every of them can be represented by 2⌈log2 n⌉bits. The integer j can be
represented by 4 bits, and sending the whole yj costs n bits. Altogether, the
communication complexity is
n + 40⌈log2 n⌉+ 4 = n + O(log n) .
Now we will show that LV10 is a Las Vegas protocol. We distinguish two cases
with respect whether the input has to be accepted or rejected.

2.4 Classiﬁcation of Randomized Algorithms
55
(i) Let ((x1, . . ., x10), (y1, . . ., y10)) be an input with xi ̸= yi for all i ∈
{1, . . ., 10}.
We have already learned34 that, for every i ∈{1, . . ., 10}, the probability
that a randomly chosen pi ∈PRIM

n2
satisﬁes
Number(xi) mod pi ̸= Number(yi) mod pi
(i.e., the probability that the claim xi ̸= yi was justiﬁed by pi) is at least
1 −2 ln n
n
.
Since p1, p2, . . ., p10 were chosen independently, the probability that
Number(xi) mod pi ̸= Number(yi) mod pi
for all i ∈{1, . . ., 10} is at least

1 −2 ln n
n
10
.
Hence,
Prob

LV10 ((x1, . . ., x10), (y1, . . ., y10)) = 0

≥

1 −2 ln n
n
10
=
10

i=0
(−1)i ·
10
i

·
2 ln n
n
i
= 1 +
5

l=1
10
2l

·
2 ln n
n
2l
−
5

m=1

10
2m −1

·
2 ln n
n
2m−1
{the sum was partitioned into positive and
negative elements}
= 1 +
5

i=1
10
2i

·
2 ln n
n
2i
−
4

i=0
 10
2i + 1

·
2 ln n
n
2i+1
.
(2.6)
For all i = 1, 2, 3, 4 and all n ≥15,
10
2i

·
2 ln n
n
2i
≥
 10
2i + 1

·
2 ln n
n
2i+1
.
(2.7)
Omitting the positive numbers
34in Section 1.3

56
2 Fundamentals
10
2i

·
2 ln n
n
2i
−
 10
2i + 1

·
2 ln n
n
2i+1
from (2.6) for i = 1, 2, 3, 4, one obtains
Prob

LV10 ((x1, . . ., x10), (y1, . . ., y10)) = 0

≥1 −
10
1

· 2 ln n
n
+
10
10

·
2 ln n
n
10
≥1 −20 ln n
n
≥1
2
for suﬃciently large35 n.
In the complementary case, when there exists a j such that
Number(xj) mod pj = Number(yj) mod pj,
the computation ends with the answer “?”, because xj ̸= yj (i.e., the
protocol cannot conﬁrm the hypothesis “xj = yj” in Phase 4).
Thus, for all inputs that have to be rejected, the conditions (i) and (ii) of
Deﬁnition 2.4.42 are satisﬁed, and so the protocol LV10 behaves as a Las
Vegas protocol on inputs that have to be rejected.
(ii) Let ((x1, . . ., x10), (y1, . . ., y10)) be an input that has to be accepted, and
let j be the smallest number from {1, . . ., 10} such that
xj = yj.
Obviously,
Number(xj) mod pj = Number(yj) mod pj
for all primes p, and so for pj, too. Therefore, LV10 compares the strings
xj and yj in Phase 4 and accepts the input if and only if36
Number(xi) mod pi ̸= Number(yi) mod pi
for all i ∈{1, 2 . . ., j −1}. We denote this positive event by Ej. If j = 1, it
is obvious that the input is accepted by LV10 with certainty. Now, consider
the case j > 1. In part (i) of our analysis, we have already proved that
the probability of the event Ej is at least

1 −2 ln n
n
j−1
≥1 −2(j −1) · ln n
n
35In fact, the probability of getting the correct answer tends to 1 with growing n,
and this is more than what one requires in the deﬁnition of Las Vegas algorithms.
36Remember that LV10 compares the substrings xj and yj if and only if sj = qj
and j is the smallest number with this property.

2.4 Classiﬁcation of Randomized Algorithms
57
for suﬃciently large n. This expression has its minimum for j = 10, and
so
Prob

LV10 ((x1, . . ., x10), (y1, . . ., y10)) = 1

≥1 −18 ln n
n
,
which is larger than 1/2 for all n ≥189.
In the complementary case, when there exists an l < j such that
Number(xl) mod pl = Number(yl) mod pl,
the protocol LV10 ends with the output “?”, because xl ̸= yl is ﬁxed37 in
Phase 4.
In this way we have proved that LV10 is a Las Vegas protocol.
⊓⊔
Exercise 2.4.45. Modify the Las Vegas protocol LV10 in such a way that in-
stead of choosing ten primes p1, . . ., p10 at random one chooses only one prime
p ∈PRIM

n2
at random. Then, one computes the remainders s1, . . ., s10,
q1, . . ., q10 as
si = Number(xi) mod p and qi = Number(yi) mod p.
In this way, the protocol saves 18 · ⌈log2 n⌉communication bits. Explain why
our analysis of the success probability of LV10 works without any change also
for the modiﬁed protocol, despite the exchange of p1, . . ., p10 for an only one
prime p.
If one achieves the appreciated situation (as in Example 2.4.44) that a Las
Vegas algorithm A computes the right result F(x) with a probability tending
to 1 with growing |x|, then one speaks of Las Vegas∗algorithms.
We deﬁned above two models of Las Vegas algorithms. Do they essentially
diﬀer? Is it possible to transform a Las Vegas algorithm with respect to Deﬁ-
nition 2.4.41 into a Las Vegas algorithm with respect to Deﬁnition 2.4.42, and
vice versa? These are the main questions we are dealing with in what follows.
First, we show how to convert the model where the answer “?” is allowed
into the model where all outputs must be the correct results. Let A be a Las
Vegas algorithm that is allowed to output “?” with a bounded probability.
We modify A to an algorithm A′ by starting a new run on the same input
whenever A would output “?”. This strategy is depicted in Figure 2.4. If TA,w
is the computation tree of A on w, then one obtains the computation tree
TA′,w of all computations of A′ on w by hanging the tree TA,w at all leaves of
TA,w with the output “?”, etc. The drawback of this transformation is that
the new algorithm A′ contains inﬁnite computations.38 On the other hand,
we have the assurance that the algorithm A′ ends with the correct result if it
halts.
37We assume that l is the smallest integer from {1, 2, . . ., 10}, such that xl ≡
yl
(mod pl).
38One does not know of any conversion of Las Vegas algorithms with output “?”
into Las Vegas algorithms without the output “?” that would avoid inﬁnite runs.

58
2 Fundamentals
“?”
“?”
“?”
TA,w
TA,w
TA,w
TA,w
T ′
A,w
Fig. 2.4.
How high is the probability that A′ halts? This probability is high because
it tends to 1 with growing running time. Why is it so? Let TimeA(w) be
the worst-case complexity of A, i.e., the depth of TA,w. This means that the
probability that A′ stops with outputting the right result in time TimeA(w) is
at least 1/2. The probability of successfully ﬁnishing the work in 2·TimeA(w)
is already at least 3/4, because A′ starts new runs of A on w for every leaf
of TA,w with the output “?”. This means that after time k · TimeA(w) the
algorithm A′ computes the correct result with probability at least
1 −1
2k ,
because 2−k is an upper bound on the probability of getting the output “?”
in k independent runs of A on w.
How large is the expected value of the time complexity Exp-TimeA′(n) of
A′? We claim that
Exp-TimeA′(n) ∈O(TimeA(n)) .
In what follows, we prove this claim. Without loss of generality one may
assume that all computations of A on w with the output “?” have the maximal
length TimeA(w), and so all these computations have the same length. Let,
for all i ∈IN −{0},
Seti = {C ∈SA′,w | (i −1) · TimeA(w) < Time(C) ≤i · TimeA(w)}
be the set of all computations that end (halt) exactly39 in the ith run of A.
Clearly, SA′,w = ∞
i=1 Seti and Setr ∩Sets = ∅for r ̸= s. Above, we have
39those computations of A′ that contain (i −1) starts of A on w

2.4 Classiﬁcation of Randomized Algorithms
59
already observed that

C∈
k
i=1
Seti
Prob({C}) ≥1 −1
2k
for all k ∈IN −{0}. A direct consequence of this fact is that

C∈Seti
Prob({C}) ≤
1
2i−1
(2.8)
for all integers i ≥1.
Thus, we obtain
Exp-TimeA′(n) =
def.

C∈SA′,w
TimeA′(C) · Prob({C})
=
∞

i=1

C∈Seti
TimeA′(C) · Prob({C})
≤
∞

i=1

C∈Seti
i · TimeA(w) · Prob({C})
{since TimeA′(C) ≤i · TimeA(w)
for every C ∈Seti}
=
∞

i=1
i · TimeA(w) ·

C∈Seti
Prob({C})
≤
(2.8)
∞

i=1
i · TimeA(w) ·
1
2i−1
= TimeA(w) ·
∞

i=1
i
2i−1
= TimeA(w) · 2 ·
∞

i=1
i
2i
= 2 · TimeA(w) ·

1
2 + 1
2 + 3
8 + 4
16 +
∞

i=5
i
2i

< 6 · TimeA(w)
{since ∞
i=5
i
2i < 1}
.
Exercise 2.4.46. Use the method described above to modify the algorithm
LV10 from Example 2.4.44 in such a way40 that the output “?” does not
occur. Then, analyze the expected communication complexity of your Las
Vegas protocol with forbidden “?”.
40In the way described above, for instance.

60
2 Fundamentals
Exercise 2.4.47. Modify the algorithm LV10 from Example 2.4.44 as follows.
The ﬁrst three phases remain unchanged. If in Phase 4 RI ﬁxes41 that xj ̸= yj,
then (instead of ﬁnishing with “?”) it sends this knowledge42 to RII. Now RII
looks for an l > j, such that sl = ql. If such an l does not exist, then RII
rejects the input (outputs “0”) with certainty. If such an l exists, then RII
sends the whole string yl to RI which compares yl and xl. If xl = yl, then RI
accepts the input. If xl ̸= yl, then RI sends this information to RII, and RII
looks again for another candidate for the equality, and so on. In the worst-case
the protocol compares all pairs (xm, ym), with sm = qm. All computations of
this algorithm are ﬁnite, and it is obvious that this algorithm computes the
correct answer in every computation. Analyze the expected communication
complexity of this protocol.
We observe that Las Vegas algorithms with respect to the ﬁrst model
(Deﬁnition 2.4.41) are a special case of Las Vegas algorithms with respect to
the second model (Deﬁnition 2.4.42). Despite this, there are reasons to try to
convert a Las Vegas algorithm always providing the correct result into a Las
Vegas algorithm that may output “?”. A situation of this kind is depicted in
Figure 2.5. One considers a computation tree TA,w that contains many short
(eﬃcient) computations, but also a few relatively long (possibly inﬁnite) ones.
For instance, the short computations run in linear time, and the long ones
in cubic time. In the case when a computation runs longer than the length
of the eﬃcient computations (i.e., when one may consider that the running
computation is one of the very long computations), one can decide to stop this
computation and to output “?”. What bound on time complexity for stopping
a computation can one take without losing the guarantee that the resulting
algorithm is a Las Vegas algorithm with respect to Deﬁnition 2.4.42?
Our goal is to show that
2 · Exp-TimeA(w)
is a suﬃcient upper bound for stopping the work of the algorithm. We prove
this by contradiction. Assume
Prob(B(w) = “?”) > 1
2.
(2.9)
Setting
SA,w(“?”) = {C ∈SA,w | Time(C) > 2 · Exp-TimeA(w)} ⊂SA,w,
one can reformulate (2.9) as

C∈SA,w(“?”)
Prob({C}) > 1
2.
(2.10)
41recognizes
42One bit is enough for this.

2.4 Classiﬁcation of Randomized Algorithms
61
2 · Exp-TimeA(w)
TA,w
Fig. 2.5.
Set
SA,w(F(w)) = SA,w −SA,w(“?”).
Following the deﬁnition of SA,w(“?”), we have
Time(C) ≥2 · Exp-TimeA(w) + 1 for all C ∈SA,w((“?”).
(2.11)
Hence,
Exp-TimeA(w)
=

C∈SA,w
TimeA(C) · Prob({C})
=

C∈SA,w(“?”)
TimeA(C) · Prob({C})
+

C∈SA,w(F (w))
TimeA(C) · Prob({C})
>
(2.11)

C∈SA,w(“?”)
(2 · Exp-TimeA(w) + 1) · Prob({C}) + 0
=
(2 · Exp-TimeA(w) + 1) ·

C∈SA,w(“?”)
Prob({C})
>
(2.10)
(2 · Exp-TimeA(w) + 1) · 1
2 = Exp-TimeA(w) + 1
2.
In this way we have obtained Exp-TimeA(w) > Exp-TimeA(w) + 1
2, which is
obviously a contradiction. Hence, the negation of (2.9) (and also of (2.10)) is
true.

62
2 Fundamentals
The idea behind the proof above is the simple combinatorial fact saying
that it is impossible that more than half the elements of a subset of IN are
larger than the doubled average.43
Exercise 2.4.48. Modify the randomized Quicksort by stopping all compu-
tations longer than 16 · n · log2 n with the output “?”. Give an upper bound
on the probability of the output “?”.
Exercise 2.4.49. Consider the randomized algorithm RSEL(A, k) from Ex-
ercise 2.3.40. What upper bound on the computation length is suﬃcient for
assuring the probability of getting the output “?” below 2−k for a positive in-
teger k? Consider the case when one stops every computation running longer
than 6 · n · log2 n steps, and outputs “?”. Is the resulting algorithm a Las
Vegas∗algorithm with respect to Deﬁnition 2.4.42?
Exercise 2.4.50. Consider the following communication task for the com-
puters RI and RII. RI has 2n bits, x1, x2, . . ., x2n, and RII has an integer
j ∈{1, . . ., 2n}. RI does not know any bit of the input of RII, and RII does
not have any information about the input of RI. We allow the submission of
one message from RI to RII only,44 and after that we require that RII provides
the bit xj as its output. The complexity of such a protocol is the length of
the only binary message communicated.
(i) Prove that every deterministic protocol for this task must allow messages
of length 2n.
(ii) Does there exist a Las Vegas protocol that is allowed to output “?” and
that solves this task within complexity n + 1?
ONE-SIDED-ERROR MONTE CARLO ALGORITHMS
This type of randomized algorithms is considered for decision problems only.
Usually a decision problem is given by a pair (Σ, L) where, for every given
string x ∈Σ∗, one has to decide whether or not x is in the language L ⊆Σ∗.
The idea here is to allow errors only for inputs from L. This means that, for
every x ∈Σ∗−L , one requires that a one-sided-error randomized algorithm
outputs the correct answer “0” (“x /∈L”) with certainty, and that only for
inputs from L may the algorithm err with a bounded probability. This concept
of one-sided-error algorithms can be formally expressed as follows.
Deﬁnition 2.4.51. Let A be a randomized algorithm and let (Σ, L) be a de-
cision problem. We say that A is an one-sided-error Monte Carlo algo-
rithm for L, 1MC algorithm for short, if45
43If more than half the numbers are larger than 2 · average + ε for an arbitrary
small ε > 0, then one cannot compensate for this contribution to the average, not
even by setting all the remainding numbers to 0.
44Protocols with this property are called one-way protocols.
45Remember, that the output 1 means acceptance (yes) and the output 0 repre-
sents rejection (no).

2.4 Classiﬁcation of Randomized Algorithms
63
(i) for every x ∈L, Prob(A(x) = 1) ≥1
2, and
(ii) for every x /∈L, Prob(A(x) = 0) = 1.
The exemplary randomized protocol R from Section 1.2 is an appropriate
illustration of Deﬁnition 2.4.51. If Σ = {0, 1} and
L = Lunequal = {(x, y) | x, y ∈{0, 1}n, x ̸= y, n ∈IN},
the designed protocol R accepts the language Lunequal. If x = y (i.e., when
(x, y) /∈Lunequal), then the protocol R outputs46 “equal” (i.e., “(x, y) /∈
Lunequal”) with certainty. If x ̸= y, then R accepts (x, y) by outputting “x ̸= y”
with a probability at least 1 −2·ln n
n
.
Similarly, as in the case of Las Vegas algorithms, we introduce the ∗-
notation. A 1MC algorithm is a 1MC∗algorithm, when
(i’) for every x ∈L, Prob(A(x) = 1) tends to 1 with growing |x|.
Obviously, the protocol R for Lunequal is a 1MC∗algorithm.
The reason to consider the 1MC algorithms as the most practical ones after
Las Vegas algorithms is that their error probability is exponentially decreasing
with the number of computation repetitions (independent runs on the same
input).
Let us explain this in detail. Following condition (i) of Deﬁnition 2.4.51,
for every x ∈L, the error probability of any 1MC algorithm for L is at most
1/2. Following condition (ii) of Deﬁnition 2.4.51, for every y /∈L, the error
probability is equal to 0. Let
α1, α2, . . ., αk, αi ∈{0, 1} for i = 1, . . ., k,
be the k outputs of k independent runs of a 1MC algorithm A on an input z.
If there exists a j ∈{1, . . ., k} such that
αj = 1,
then we know with certainty47 that x ∈L. Only if
α1 = α2 = . . . = αk = 0,
(i.e., in the complementary case) one takes the answer “0”. This output can
be wrong when x ∈L. Since, for every z ∈L,
Prob(A(z) = 0) ≤1
2,
we obtain that the probability of having A(z) = 0 in all k independent runs
of A on z is
46rejects
47From condition (ii) of Deﬁnition 2.4.51, a 1MC algorithm can never output “1”
(“accept”) for an input z /∈L.

64
2 Fundamentals
(Prob(A(z) = 0))k ≤
1
2
k
= 2−k.
Hence, we see why 1MC algorithms are very much appreciated in many ap-
plications. Executing k repetitions of the work of a 1MC algorithm A on the
same input
(i) the complexity grows only k times (i.e., in a linear way), and
(ii) the error probability tends to 0 with exponential speed in k.
In what follows, we denote by Ak the 1MC algorithm that consists of k
independent runs of a 1MC algorithm A on any input, and that accepts an
input if and only if at least one of the runs accepts this input. We keep in our
mind that the error probability of Ak is the error probability of A to k, and
so Ak is a 1MC algorithm if A is a 1MC algorithm.
BOUNDED-ERROR MONTE CARLO ALGORITHMS
This large class of randomized algorithms is deﬁned in such a way that
(i) a constant48 number of independent computation repetitions on the same
input is always suﬃcient for reducing the error probability below a given
constant δ, and
(ii) any relaxation of the requirement of the following deﬁnition of bounded-
error Monte Carlo algorithms can cause a situation in which the execution
of polynomially49 many computations on the same input does not suﬃce
to reduce the error probability below a given constant δ.
Deﬁnition 2.4.52. Let F be a function. We say that a randomized algorithm
A is a bounded-error Monte Carlo algorithm for F , 2MC algorithm50
for short, if
there exists a real number ε, 0 < ε ≤1/2 such that, for every input
x of F,
Prob(A(x) = F(x)) ≥1
2 + ε.
(2.12)
We call attention to the fact that the upper bound 1
2 −ε on the error
probability determined by a ﬁxed ε > 0 independent of inputs is the core
of Deﬁnition 2.4.52. Only this guaranted distance ε to the probability 1/2
for any input assures the existence of an eﬃcient way for reducing the error
probability to an arbitrarily small given δ. Note that the requirement (2.12)
does not hinder us to viewing Las Vegas algorithms and one-sided-error Monte
48with respect to the input length, but not with respect to δ
49in the input size
50the notation 2MC comes from two-sided-error Monte Carlo, which is an alter-
native name of bounded-error Monte Carlo in the literature.

2.4 Classiﬁcation of Randomized Algorithms
65
Carlo algorithms as special cases of bounded-error Monte Carlo algorithms.
If A is a 1MC algorithm (or a Las Vegas algorithm), then the algorithm A2
computes the correct result with a probability at least 3/4, and so A2 satisﬁes
the requirement (2.12).
In this sense one can view all up till now presented randomized algorithms
as bounded-error Monte Carlo algorithms. We note that the randomized pro-
tocol from our motivation example in Section 1.2 is a 1MC∗algorithm for
Lunequal, but not a 1MC algorithm for the complementary language
L = Lequal = {(x, y) | x, y ∈{0, 1}∗, x = y}.
On the other hand, it is obvious that the randomized protocol R is a 2MC
algorithm for Lequal.
Our next goal is to analyze the speed of reduction of the error probability
of 2MC algorithms with respect to the number of computation repetitions on
the same input. For any 2MC algorithm A and any positive integer t, let At
denote the following randomized algorithm:
2MC Algorithm At
Input: x
Step 1: Perform t independent runs of A on x and save the t computed results
α1, α2, . . ., αt.
Step 2: if there is an α that appears at least ⌈t
2⌉times in the sequence
α1, α2, . . ., αt,
then
output “α”
else51
output “?”
Let ε > 0 be a constant, such that, for all feasible inputs x,
Prob(A(x) = F(x)) ≥1
2 + ε.
For every input x, let
p = p(x) = Prob(A(x) = F(x)) = 1
2 + εx for an εx ≥ε
be a short notation for the success probability of A on x.
Clearly, At computes a wrong result or “?” only if the correct result was
not computed at least ⌈t/2⌉times in the t independent runs of A on x.
51A reasonable alternative way of determining the output of At would be to
take the most frequently occurring result in α1, α2, . . ., αt as the ﬁnal output. The
following analysis works also for this possibility.

66
2 Fundamentals
In what follows, we analyze, for all i < ⌈t/2⌉, the probability pri(x) that
At computes the correct result in exactly i runs. In order to bound the error
probability of At we are interested in deriving good upper bounds on pri(x)
for all i < ⌈t/2⌉. The following holds:
pri(x) =
t
i

· pi · (1 −p)t−i
{There are exactly
t
i

ways of estimating the i positions with the
correct result F(x) in the sequence of t results. For each position,
p = p(x) is the probability of computing the correct result F(x)
and 1 −p is the probability of computing a wrong result. Then pi
is the probability of computing the correct result exactly i times
on i ﬁxed positions, and (1−p)t−i is the probability of computing
a wrong result on all t −i remaining positions.}
=
t
i

· (p · (1 −p))i · (1 −p)t−2i
{Since t ≥2i, we have,
(1 −p)t−i = (1 −p)i · (1 −p)t−2i}
=
t
i

·
1
2 + εx

·
1
2 −εx
i
·
1
2 −εx
2·( t
2 −i)
{Since p = 1
2 + εx and 1 −p = 1
2 −εx}
=
t
i

·
1
4 −ε2
x
i
·
1
2 −εx
2 t
2 −i
<
t
i

·
1
4 −ε2
x
i
·
1
2 −εx

·
1
2 + εx
 t
2 −i
{Since 1
2 −εx < 1
2 + εx}
=
t
i

·
1
4 −ε2
x
i
·
1
4 −ε2
x
 t
2 −i
=
t
i

·
1
4 −ε2
x
 t
2
≤
t
i

·
1
4 −ε2
 t
2
{Since εx ≥ε for every input x .
}
Since At computes the correct result F(x) on x if and only if at least ⌈t/2⌉
runs of A have computed the correct result F(x), one obtains for every input
x the following lower bound on the success probability of At:
Prob(At(x) = F(x)) = 1 −
⌊t
2 ⌋

i=0
pri(x)

2.4 Classiﬁcation of Randomized Algorithms
67
> 1 −
⌊t
2 ⌋

i=0
t
i

·
1
4 −ε2
x
 t
2
= 1 −
1
4 −ε2
x
 t
2
·
⌊t
2 ⌋

i=0
t
i

> 1 −
1
4 −ε2
x
 t
2
· 2t
≥1 −

1 −4 · ε2
x
 t
2
≥1 −

1 −4 · ε2 t
2 .
We observe that the upper bound
(1 −4 · ε2)t/2
on the error probability of At tends to 0 with growing t. Thus, if one looks
for a k such that
Prob(Ak(x) = F(x)) ≥1 −δ,
for a chosen constant δ, it is suﬃcient to take
k ≥
2 · ln δ
ln(1 −4 · ε2).
(2.13)
Thus, if δ and ε are considered52 ﬁxed constants, then the number k of
computation repetitions is also a constant (with respect to the inputs). Hence,
we can conclude
TimeAk(n) ∈O(TimeA(n)) .
A consequence of this observation is that if A is asymptotically faster than
any deterministic algorithm computing F, then Ak with an error probability
below a chosen δ is also more eﬃcient than any deterministic algorithm.
Exercise 2.4.53. Modify the 2MC algorithm At to a randomized algorithm
A′
t in such a way that A′
t takes the most frequent result as the output. What
is the error probability of this modiﬁed algorithm A′
t?
UNBOUNDED-ERROR MONTE CARLO ALGORITHMS
Clearly, a randomized algorithm cannot be used for computing a function
F when the error probability is not less than 1/2. If the error probability
is at least 1/2, then a wrong result may be produced as frequently as the
correct result, and even then the execution of several independent runs of the
52From Deﬁnition 2.4.52 of 2MC algorithms, ε is always a ﬁxed constant with
respect to inputs.

68
2 Fundamentals
algorithm on the same input cannot help in recognizing which of the outputs is
the correct result. Consequently, general randomized algorithms must require
that error probability be less than 1/2.
Deﬁnition 2.4.54. Let F be a function. We say that a randomized algorithm
A is a (unbounded-error)53 Monte Carlo algorithm computing F, an
MC algorithm, for short, if, for every input x of F,
Prob(A(x) = F(x)) > 1/2.
The most interesting question for us now is:
What is the diﬀerence between bounded-error Monte Carlo algo-
rithms and unbounded-error ones?
For 2MC algorithms, one forces the error probability to have a universal
ﬁxed distance from 1/2 for any input. For an MC algorithm, it may hap-
pen, that the distance between the error probability and 1/2 tends to 0 with
growing input size |x|. For instance, a randomized algorithm A can have a
uniform choice from 2|x| deterministic strategies for any input x. If most of
them (i.e., at least 2|x|−1 + 1 many) provide the correct result, then A is an
MC algorithm. Hence, one allows that
Prob(A(x) = F(x)) = 1
2 +
1
2|x| > 1
2.
Thus, the distance εx =
1
2|x| between the error probability and 1/2 tends to 0
with an exponential speed in |x|.
Now we pose the following principal question:
How many independent runs of A on x are necessary in order to
get
Prob(Ak(x) = F(x)) > 1 −δ
for a ﬁxed chosen constant δ?
Since the analysis of the error probability of the 2MC algorithm At with
respect to εx is valid without any change for MC algorithms, one has
Prob(At(x) = F(x)) ≥1 −

1 −4 · ε2
x
 t
2 .
To achieve Prob(Ak(x) = F(x)) ≥1−δ, one obtains the following lower bound
on the number of independent runs of A:
53The term “unbounded-error” is not used in the sense that the error probability
is unbounded, but in the sense that there is no bound on error probability assuring
a universal distance from 1/2 for every input.

2.4 Classiﬁcation of Randomized Algorithms
69
k = k(|x|) ≥
2 · ln δ
ln(1 −4 · ε2x)
=
2 · ln δ
ln(1 −4 · 2−2·|x|)
{Since εx = 2−|x|}
≥
2 · ln δ
−2−2·|x|
{Since ln(1 −y) ≤−y for 0 < y < 1
(Lemma A.3.62)}
= (−2 · ln δ) · 22·|x|.
In this way, we obtain
TimeAk(x) ≥(−2 · ln δ) · 22·|x| · TimeA(x) .
Hence, the running time of Ak is exponential in input length |x|, even for the
case where A is very fast.
Note that this consideration does not imply that no MC algorithm is ap-
plicable. For instance, if εx =
1
log2 |x|, then few54 (not exponentially many)
repetitions of the computation on x are suﬃcient in order to get a useful
algorithm for the computing task considered.
Exercise 2.4.55. Let A be an MC algorithm that, for every input x, com-
putes the correct result F(x) with probability 1
2 + εx, where εx depends on
|x|. Let δ be a constant, 0 < δ < 1/2. How many repetitions k = k(|x|) of the
work of A on x are necessary to achieve Prob(Ak(x) = F(x)) ≥1 −δ, if
(i) εx =
1
|x|,
(ii) εx =
1
log2 |x| ?
Exercise 2.4.56. Let A be a randomized algorithm computing a function F
with Prob(A(x) = F(x)) ≥1/3 for every argument x of F. Assume that one
is aware of the fact that Prob(A(x) = α) ≤1/4 for every wrong result α (i.e.,
that the probability of computing any speciﬁc wrong result is at most 1/4).
Can this knowledge be used to design a useful randomized algorithm for F?
Example 2.4.57. Consider the following randomized communication protocol
between two computers RI and RII for recognizing the language Lunequal.
Protocol UMC
Initial situation: RI has n bits x = x1x2 . . . xn, RII has n bits y = y1y2 . . . yn,
n ∈IN −{0}.
54Obviously, a constant number of repetitions is not suﬃcient, but a low degree
polynomial number of repetitions may be acceptable.

70
2 Fundamentals
{This is the same initial situation as in our motivation example in Sec-
tion 1.2 (Figure 1.1)}
The input (x, y) has to be accepted if and only if x ̸= y.
Phase 1: RI uniformly chooses a number j ∈{1, 2, . . ., n} at random and
sends
j and the bit xj
to RII.
Phase 2: RII compares xj with yj.
If xj ̸= yj, RII accepts the input (x, y).
{In this case, RII is sure that x ̸= y, i.e., that (x, y) ∈Lunequal.}
If xj = yj, then RII accepts (x, y) with probability 1
2 −
1
2n, and rejects
(x, y) with probability 1
2 +
1
2n.
The communication complexity of UMC is exactly
⌈log2(n + 1)⌉+ 1
bits in each computation, and so UMC is always very eﬃcient.
Now we show that UMC is a Monte Carlo protocol. As usual, we handle
the two cases (x, y) ∈Lunequal and (x, y) /∈Lunequal separately.
(i) Let (x, y) /∈Lunequal, i.e., x = y.
In this case UMC has exactly 2n computations Cil for i ∈{1, 2, . . ., n} and
l ∈{0, 1}, where Cil is the computation in which RI chooses the number i
at random in Phase 1 and RII outputs “l” (with the usual meaning, l = 1
for acceptance and l = 0 for rejection).
Thus we have a probability space (SUMC,(x,y), Prob) with
SUMC,(x,y) = {Cil | 1 ≤i ≤n, l ∈{0, 1}}
and
Prob({Ci0}) = 1
n ·
1
2 + 1
2n

and
Prob({Ci1}) = 1
n ·
1
2 −1
2n

(2.14)
for all i ∈{1, 2, . . ., n}.
Obviously,
A0 = {Ci0 | 1 ≤i ≤n}
is the event that UMC outputs the correct answer “reject” (“x = y”).
Hence,

2.4 Classiﬁcation of Randomized Algorithms
71
Prob(A0)
=
Prob(UMC rejects (x, y))
=
n

i=1
Prob({Ci0})
=
(2.14)
n

i=1
1
n ·
1
2 + 1
2n

=
n · 1
n
1
2 + 1
2n

=
1
2 + 1
2n > 1
2.
(ii) Let (x, y) ∈Lunequal, i.e., (x ̸= y).
Then there exists a j ∈{1, 2, . . ., n}, such that xj ̸= yj. Without loss
of generality we assume that only one j, with xj ̸= yj, exists, clearly the
worst case for our analysis. Then we have the computation Cj that accepts
(x, y) with certainty (note that Prob({Cj}) = 1/n) and exactly 2(n −1)
computations Cil for i ∈{1, 2, . . ., n} −{j}, l ∈{0, 1}, where Cil is the
computation in which RI chooses the number i in Phase 1 at random and
RII outputs “l” in Phase 2. Thus, our probability space is
(SUMC,(x,y), Prob)
with
SUMC,(x,y) = {Cj} ∪{Cil | 1 ≤i ≤n, i ̸= j, l ∈{0, 1}}
and
Prob({Cj}) = 1
n,
Prob({Ci0}) = 1
n
1
2 + 1
2n

, and
(2.15)
Prob({Ci1}) = 1
n
1
2 −1
2n

for all i ∈{1, 2, . . ., n}.
Obviously
A1 = {Cj} ∪{Ci1 | 1 ≤i ≤n, i ̸= j}
is the event that UMC computes the correct answer “accept” (“x ̸= y′′).
Thus,
Prob(A1)
=
Prob(UMC accepts (x, y))
=
Prob({Cj}) +
n

i=1
i̸=j
Prob({Ci1})

72
2 Fundamentals
=
(2.15)
1
n +
n

i=1
i̸=j
1
n
1
2 −1
2n

=
1
2n + 1
2n +
n−1

i=1
 1
2n −
1
2n2

=
1
2n +
n

i=1
1
2n −
n−1

i=1
1
2n2
=
1
2n + 1
2 −n −1
2n2
=
1
2 +
1
2n2
{Since
1
2n −n−1
2n2 =
1
2n2 }
>
1
2.
⊓⊔
Exercise 2.4.58. One observes that the protocol UMC is based on a nonde-
terministic protocol that simply guesses the position j where x and y diﬀer,
and then veriﬁes if its guess was correct (i.e., if really xj ̸= yj). We have
converted this nondeterministic protocol into an MC protocol by assigning
some probabilities to nondeterministic decisions about acceptance and rejec-
tion in situations in which the protocol does not know the right answer.55 The
idea is to accept with probability less than, but close to, 1/2, and to reject
with the complementary probability.56 The probability to accept in this un-
certain situation must be so close, from below, to 1/2 that one computation
accepting with certainty brings the overall probability of acceptance above
1/2. Can one apply this idea for converting any nondeterministic algorithm
to an equivalent57 MC algorithm of the same eﬃciency?
2.5 Classiﬁcation of Randomized Algorithms
for Optimization Problems
In Section 2.4 we gave a fundamental classiﬁcation of randomized algorithms
for solving decision problems and for computing functions. If one considers
optimization problems, then there is no essential reason to classify random-
ized optimization algorithms in the way described above. This is because if
one executes k runs of a randomized algorithm for an optimization problem,
55This is the situation where a nondeterministic algorithm rejects its input (in
our case, where j has been chosen and xj = yj).
56i.e., larger than, but close to, 1/2
57i.e., computing the same problem

2.5 Classiﬁcation of Randomized Algorithms for Optimization Problems
73
then the ﬁnal output is simply considered the best output of the k outputs
computed in the k particular runs, and so one does not need to try to obtain
an output that appears as the result in at least half the number of runs. Thus,
one does not identify the right output with the frequency of its occurrence
in a sequence of runs of the randomized algorithm, but simply takes the best
one with respect to the objective function (optimization goal). For instance,
if a randomized optimization algorithm A computes an optimal solution only
for an input x with probability at least
1
|x|,
it does not mean that A is not useful. One can execute |x| independent runs
of A on x and then take the best output. What is then the probability of
success? Since the probability of computing no optimal solution in one run is
at most
1 −1
|x|,
the probability that A|x| does not ﬁnd any optimal solution in |x| independent
runs is at most58

1 −1
|x|
|x|
< 1
e.
In this way one obtains a constant probability 1−e−1 of computing an optimal
solution.
Exercise 2.5.59. Show that |x|·log2 |x| computation repetitions are suﬃcient
to guarantee the convergence of
Prob

A|x|·log2 |x| computes an optimal solution

to 1 with growing |x|.
This way, the complexity of the new algorithm A|x| is only |x| times the
complexity of A, and so when A is a polynomial-time algorithm, A|x| is a
polynomial-time algorithm, too.
Moreover, when dealing with optimization problems, the task is not nec-
essarily to ﬁnd an optimal solution, but one is usually satisﬁed with a feasible
solution whose cost (quality) does not diﬀer too much from the cost (quality)
of an optimal solution. In such a case one can be looking for the probability
of ﬁnding a relatively good situation, which leads to another classiﬁcation of
randomized algorithms. In what follows, we introduce a classiﬁcation suitable
for randomized optimization algorithms. Since we need this classiﬁcation only
in Chapter 7, one can omit reading this section now and come back to it before
starting the study of Chapter 7.
58See Lemma A.3.60.

74
2 Fundamentals
First of all we need to give a deﬁnition (a formal description) of optimiza-
tion problems and to introduce the concept of approximation algorithms. In
this way one obtains a reasonable framework in which randomized algorithms
can be classiﬁed.
Solving an optimization problem cannot in general be considered as com-
puting a function. Solving an optimization problem corresponds more or less
to computing a relation R in the sense that, for a given x, it is suﬃcient to
ﬁnd a y such that (x, y) ∈R. The reason for this point of view is that there
can exist many optimal solutions for an input x, and we are satisﬁed with
any one of them. If one is satisﬁed even with any “good”, but not necessarily
optimal, solution, then one has one more reason for regarding an optimization
problem as the computing of a relation. We start with a formal deﬁnition of
an optimization problem.
Deﬁnition 2.5.60. An optimization problem is a 6-tuple U = (ΣI, ΣO,
L, M, cost, goal), where
(i) ΣI is an alphabet called the input alphabet.
(ii) ΣO is an alphabet called the output alphabet.
(iii) L ⊆Σ∗
I is the language of feasible inputs (as inputs one allows only
words that have a reasonable interpretation).
An x ∈L is called a problem instance of U.
(iv) M is a function from L to P(Σ∗
O), and for each x ∈L, the set M(x) is
the set of feasible solutions for x.
(v) cost is a function cost : 
x∈L(M(x) × {x}) →IR+, called the cost func-
tion.
(vi) goal ∈{minimum, maximum} is the objective.
A feasible solution α ∈M(x) is called optimal for the problem instance
x of U if
cost(α, x) = OptU (x) = goal{cost(β, x) | β ∈M(x)}.
We say that an algorithm A solves U if, for any x ∈L,
(i) A(x) ∈M(x)

A(x) is a feasible solution for the problem instance x of
U

, and
(ii) cost(A(x), x) = goal{cost(β, x) | β ∈M(x)}.
If goal = minimum, U is called a minimization problem,
if goal = maximum, U is called a maximization problem.
To understand why we deﬁne optimization problems this way, let us take
a look at the above formal deﬁnition of an optimization problem as a 6-
tuple U = (ΣI, ΣO, L, M, cost, goal). The input alphabet ΣI has the same
meaning as the input alphabet of decision problems, i.e., ΣI is used for the
representation of input instances of U. Analogously, the output alphabet ΣO
is used for representing the outputs (feasible solutions). The language L ⊆Σ∗
I

2.5 Classiﬁcation of Randomized Algorithms for Optimization Problems
75
is the set of correct representations of problem instances. We assume that no
word from LC = Σ∗
I −L will occur as an input. This means that we focus
on determining the complexity of the optimization, and not on solving the
decision problem (ΣI, L).
A problem instance x usually speciﬁes a set of constraints, and M(x) is
the set of objects (feasible solutions for x) that satisfy these constraints. In the
typical case the problem instance x also determines the cost(α, x) for every
solution α ∈M(x). The task is to ﬁnd an optimal solution in the set M(x) of
feasible solutions for x. The typical diﬃculty of solving U lies in the fact that
the set M(x) has such a large cardinality that it is practically59 impossible
to generate all feasible solutions from M(x) in order to pick the best one.
To make the speciﬁcation of optimization problems transparent, we often
omit the speciﬁcation of ΣI and ΣO, and the speciﬁcation of coding the data
over ΣI and ΣO. We assume simply that the typical data such as integers,
graphs, and formulae are represented in the usual60 way described above.
This also simpliﬁes the situation in that we can now address these objects
directly instead of working with their formal representations. Therefore, one
can transparently describe an optimization problem by specifying
•
the set L of problem instances,
•
the constraints given by any problem instance x ∈L and the corresponding
set M(x) for any x ∈L,
•
the cost function, and
•
the goal.
Example 2.5.61. Traveling Salesman Problem (TSP)
TSP
Input: A weighted complete graph (G, c), where G = (V, E), V = {v1, . . . , vn}
for an n ∈IN −{0}, and c : E →IN −{0}.
{More precisely, an input is a word x ∈{0, 1, #}∗that codes61(represents)
a weighted complete graph (G, c).}
Constraints: For any problem instance (G, c), M(G, c) is the set of all Hamil-
tonian cycles of G. Each Hamiltonian cycle can be represented as a se-
quence vi1, vi2, . . . , vin, vi1 of vertices, where (i1, i2, . . . , in) is a permuta-
tion of (1, 2, . . . , n).
{A strictly formal representation of M(G, c) is the set of all words
y1#y2# . . . #yn ∈{0, 1, #}∗= Σ∗
O where yi ∈{0, 1}+ for i = 1, 2, . . ., n,
with
{Number(y1) , Number(y2) , . . . , Number(yn)} = {1, 2, . . ., n},
and Number(y1) = 1.}
59in an eﬃcient way
60see Chapter 2 in [Hro03]
61See [Hro03] for possible string representations of graphs.

76
2 Fundamentals
Costs: For every Hamiltonian cycle H = vi1, vi2, . . . , vin, vi1 ∈M(G, c),
cost((vi1, . . . , vin, vi1), (G, c)) =
n

j=1
c

{vij, vi(j
mod n)+1}

,
i.e., the cost of every Hamiltonian cycle is the sum of the weights of all
its edges.
Goal: minimum.
For the problem instance of TSP in Figure 2.6, we have
cost((v1, v2, v3, v4, v5, v1) , (G, c)) = 8 + 1 + 7 + 2 + 1 = 19 and
cost((v1, v5, v3, v2, v4, v1), (G, c)) = 1 + 1 + 1 + 1 + 1 = 5.
The Hamiltonian cycle v1, v5, v3, v2, v4, v1 is the only optimal solution for
this problem instance of TSP.
⊓⊔
v1
1
1
1
1
1
2
2
3
v2
7
8
v3
v4
v5
Fig. 2.6.
Exercise 2.5.62. Prove, for any integer n ≥2m, that
|M((G, c)) | = (n −1)!/2
for any graph G with n vertices.
A vertex cover of a graph G = (V, E) is any set U of vertices of G (i.e.,
U ⊆E) such that every edge from E is incident62 to at least one vertex from U.
For example, the set {v2, v4, v5} is a vertex cover of the graph in Figure 2.7
because each edge of this graph is incident to at least one of there three
vertices. The set {v1, v2, v3} is not a vertex cover of the graph in Figure 2.7
because the edge {v4, v5} is not covered by any of the vertices v1, v2, and v3.
62An edge is incident to a vertex if this vertex is one of the two endpoints of this
edge, i.e., the edge {u, v} is incident to the vertices u and v.

2.5 Classiﬁcation of Randomized Algorithms for Optimization Problems
77
Exercise 2.5.63. The minimum vertex cover problem, MIN-VCP, is
a minimization problem, where one searches for a vertex cover of minimal
cardinality for a given graph G.
(i) Estimate the set of all vertex covers of the graph in Figure 2.7.
(ii) Give a formal speciﬁcation of MIN-VCP as a 6-tuple. Use the alphabet
{0, 1, #} to represent the input instances and the feasible solutions.
v1
v2
v3
v4
v5
Fig. 2.7.
Example 2.5.64. The maximum satisﬁability problem (MAX-SAT)
Let X = {x1, x2, . . .} be the set of Boolean variables. The set of all literals
over X is LitX = {x, x | x ∈X}, where x is the negation of x for every variable
x. The values 0 and 1 are called Boolean values (constants). A clause is any
ﬁnite disjunction over literals (for instance, x1 ∨x3 ∨x4 ∨x7). A (Boolean)
formula F is in conjunctive normal form (CNF) if F is a ﬁnite conjunction
of clauses. A formula F is in k-conjunctive normal form (kCNF) for a positive
integer k if every clause of F consists of at most k literals. A formula F is
in EkCNF for a positive integer k if every clause of F consists of exactly k
literals over k diﬀerent variables.
An example of a formula over X in CNF is
Φ = (x1 ∨x2) ∧(x1 ∨x2 ∨x3) ∧x2 ∧(x2 ∨x3) ∧x3 ∧(x1 ∨x3).
The maximum satisﬁability problem, MAX-SAT, is to ﬁnd an input assign-
ment to the variables of a given formula in CNF such that the number of
satisﬁed clauses is maximized.
MAX-SAT
Input: A formula Φ = F1 ∧F2 ∧· · · ∧Fm over X in CNF, where Fi is a clause
for i = 1, . . . , m, m ∈IN −{0}.
Constraints: For every formula Φ over a set {xi1, xi2, . . . , xin} of n Boolean
variables, the set of feasible solutions is

78
2 Fundamentals
M(Φ) = {0, 1}n.
{Every α = α1 . . . αn ∈M(Φ), αj ∈{0, 1} for j = 1, . . . , n, represents an
assignment where the value αj is assigned to the variable xij .}
Costs: For every formula Φ and any α ∈M(Φ), cost(α, Φ) is the number of
clauses of Φ satisﬁed by α.
Goal: maximum.
For the formula Φ described above, Table 2.1 presents all eight assignments
to the variables x1, x2, and x3 and we can easily observe that the assignments
001, 011, and 101 satisfy ﬁve clauses each, and are hence optimal solutions
for Φ.
Table 2.1.
x1 x2 x3 x1 ∨x2 x1 ∨x2 ∨x3 x2 x2 ∨x3 x3 x1 ∨x3 # of satisﬁed clauses
0
0
0
0
1
1
0
0
1
3
0
0
1
0
1
1
1
1
1
5
0
1
0
1
1
0
1
0
1
4
0
1
1
1
1
0
1
1
1
5
1
0
0
1
1
1
0
0
1
4
1
0
1
1
1
1
1
1
0
5
1
1
0
1
1
0
1
0
1
4
1
1
1
1
0
0
1
1
0
3
If the set of feasible inputs is restricted to formulas in kCNF for a positive
integer k, we speak of the MAX-kSAT problem. If one allows only formulas
in EkCNF as inputs, then one speaks of the MAX-EkSAT problem.
Example 2.5.65. Integer linear programming (ILP)
Given a system of linear equations and a linear function over variables of
this linear equation system, the task is to ﬁnd a solution to the system of
equations such that the value of the linear function is minimized. ILP can be
phrased as an optimization problem as follows:
ILP
Input: An m × n matrix
A = [aij]i=1,...m,j=1,...,n
and two vectors
b = (b1, . . . , bm)T and c = (c1, . . . , cn)
for n, m ∈IN −{0}, where aij, bi, cj are integers for i = 1, . . . , m and
j = 1, . . . , n.

2.5 Classiﬁcation of Randomized Algorithms for Optimization Problems
79
Constraints: M(A, b, c) = {X = (x1, . . . , xn)T ∈INn | AX = b}.
{M(A, b, c) is the set of all solutions (vectors) that satisfy the system
AX = b of linear equations determined by A and b.}
Costs: For every X = (x1, . . . , xn) ∈M(A, b, c),
cost(X, (A, b, c)) = c · X =
n

i=1
cixi.
Goal: minimum.
The most discrete optimization problems of our interest are NP-hard, and
so one does not hope to solve them in polynomial time. Because of this,
we introduce the concept of approximation algorithms for solving hard op-
timization problems. The idea is to jump from exponential time complexity
to a polynomial-time complexity by weakening the requirements. Instead of
forcing the computation of an optimal solution, we are satisﬁed with an “al-
most optimal” or “nearly optimal” solution. What the term “almost optimal”
means is deﬁned below.
Deﬁnition 2.5.66. Let U = (ΣI, ΣO, L, M, cost, goal) be an optimization
problem.
We say that A is a consistent algorithm for U if, for every x ∈L, the
output A(x) of the computation of A on x is a feasible solution for x (i.e.,
A(x) ∈M(x)).
Let A be a consistent algorithm for U. For every x ∈L, we deﬁne the
approximation ratio, RatioA(x), of A on x as
RatioA(x) = max
	cost(A(x))
OptU(x) , OptU(x)
cost(A(x))

,
where OptU(x) is the cost of an optimal solution for the instance x of U.
For any positive real number δ > 1, we say that A is a δ-approximation
algorithm for U if
RatioA(x) ≤δ
for every x ∈L.
First, we illustrate the concept of approximation algorithms for the min-
imum vertex cover problem. The idea is to eﬃciently ﬁnd a matching63 in
a given graph G, and then to take all vertices incident to the edges of the
matching as a vertex cover.
63A matching in G = (V, E) is a set M ⊆E of edges such that there is no
vertex incident to more than one edge from M. A matching is maximal if for every
e ∈E −M, the set M ∪{e} is not a matching in G.

80
2 Fundamentals
Algorithm VCA
Input: A graph G = (V, E).
Phase 1. C := ∅;
{During the computation, C is always a subset of V , and at the end of
the computation C is a vertex cover of G.}
A := ∅;
{During the computation, A is always a subset of E (a matching in G),
and when the computation has ﬁnished, A is a maximal matching.}
E′ := E;
{During the computation, the set E′ ⊆E contains exactly the edges that
are not covered by the actual C. At the end of the computation, E′ = ∅.}
Phase 2. while E′ ̸= ∅do
begin
take an arbitrary edge {u, v} from E′;
C := C ∪{u, v};
A := A ∪{{u, v}};
E′ := E′ −{all edges incident to u or v};
end
Output: C
Consider a possible run of the algorithm VCA on the graph in Fig-
ure 2.8(a). Let {b, c} be the ﬁrst edge chosen by VCA. Then,
C = {b, c}, A = {{b, c}}, and E′ = E −{{b, a}, {b, c}, {c, e}, {c, d}},
as depicted in Figure 2.8(b). If the second choice of an edge from E′ by VCA
is the edge {e, f} (Figure 2.8(c)), then
C = {b, c, e, f}, A = {{b, c}, {e, f}}, and E′ = {{d, h}, {d, g}, {h, g}}.
If the last choice of VCA is the edge {d, g}, then
C = {b, c, e, f, d, g}, A = {{b, c}, {e, f}, {d, g}}, and E′ = ∅.
Hence, C is a vertex cover with cost 6. We observe that {b, e, d, g} is the
optimal vertex cover, and this optimal vertex cover cannot be achieved by
any choice of edges by the algorithm VCA.
Exercise 2.5.67. Find a choice of edges in the second phase of VCA such
that the resulting vertex cover C contains all vertices of G in Figure 2.8(a).
We show that the algorithm VCA is a 2-approximation algorithm for
MIN-VCP and TimeVCA(G) ∈O(|E|) for any instance G = (V, E).
The claim
TimeVCA(G) ∈O(|E|)
is obvious because every edge from E is manipulated exactly once in VCA.

2.5 Classiﬁcation of Randomized Algorithms for Optimization Problems
81
a
a
a
a
b
b
b
b
c
c
c
c
d
d
d
d
e
e
e
e
f
f
f
f
g
g
g
g
h
h
h
h
(a)
(b)
(c)
(d)
Fig. 2.8.
Since E′ = ∅at the end of any computation, VCA computes a vertex cover
in G (i.e., VCA is a consistent algorithm for MIN-VCP).
To prove
RatioVCA(G) ≤2
for every graph G, we observe that
(i) |C| = 2 · |A|, and
(ii) A is a matching in G.
To cover the |A| edges of the matching A, one has to take at least |A|
vertices. Since A ⊆E, the cardinality of any vertex cover of G is at least |A|,
i.e.,
OptMIN-VCP(G) ≥|A|.
Hence
|C|
OptMIN-VCP(G) =
2 · |A|
OptMIN-VCP(G) ≤2.
Exercise 2.5.68. Construct, for any positive integer n, a graph Gn, such
that the optimal vertex cover has cardinality n and the algorithm VCA can
compute a vertex cover of cardinality 2n.
Whether or not the guarantee of an approximation ratio of 2 is suﬃcient
depends on particular applications. Usually one tries to achieve smaller ap-
proximation ratios, which requires much more demanding algorithmic ideas.
On the other hand, one measures the approximation ratio of an algorithm in
the worst-case manner, so a 2-approximation algorithm can provide solutions
of essentially better approximation ratios than 2 for typical problem instances.
One of the main goals of applying randomization in the area of discrete
optimization is to improve the approximation ratio. Thus, one has to design

82
2 Fundamentals
randomized approximation algorithms that produce feasible solutions whose
cost (quality) is not very far from the optimal cost with a high probability. In
the analysis of such randomized algorithms one considers the approximation
ratio as a random variable.64 Then the aim is either
(1) to estimate the expected value E[Ratio] (or at least to prove a reasonable
upper bound for it), or
(2) to guarantee that an approximation ratio δ is achieved with probability
at least 1/2.
These two diﬀerent aims lead to the following two concepts of deﬁning ran-
domized approximation algorithms.
Deﬁnition 2.5.69. Let U = (ΣI, ΣO, L, M, cost, goal) be an optimization
problem. For any positive real δ > 1, a randomized algorithm A is called
a randomized E[δ]-approximation algorithm for U if
(i) Prob(A(x) ∈M(x)) = 1, and
(ii) E[RatioA(x)] ≤δ
for every x ∈L.
Deﬁnition 2.5.70. Let U = (ΣI, ΣO, L, M, cost, goal) be an optimization
problem. For any positive real δ > 1, a randomized algorithm A is called
a randomized δ-approximation algorithm for U if
(i) Prob(A(x) ∈M(x)) = 1, and
(ii) Prob(RatioA(x) ≤δ) ≥1/2
for every x ∈L.
The algorithm RSEL designed in Example 2.3.35 for MAX-SAT is clearly
a randomized E[2]-approximation algorithm for U.
Let us investigate how much the two proposed classes (concepts) of ran-
domized approximation algorithms really diﬀer. First of all, we claim that
these two classes are diﬀerent in the strongly formal sense, that a random-
ized E[δ]-approximation algorithm for U is not necessarily a randomized δ-
approximation algorithm for U, and vice versa.
To recognize this, consider a randomized algorithm A that has exactly 12
runs, C1, C2, . . ., C12, on an input x, and all runs have the same probability.
Let RatioA,x(Ci) be the approximation ratio of the output of Ci. Let us assume
that
RatioA,x(Ci) = 2 for i = 1, 2, . . ., 10 and RatioA,x(Cj) = 50 for j ∈{11, 12}.
Then,
64This means that Ratio is here considered as a function that assigns to each run
of a randomized algorithm the approximation ratio of the result of this run.

2.5 Classiﬁcation of Randomized Algorithms for Optimization Problems
83
E[RatioA,x] = 1
12 · (10 · 2 + 2 · 50) = 10.
On the other hand,
Prob(RatioA,x ≤2) = 10 · 1
12 = 5
6 ≥1
2.
If the above holds for all input instances x of U, then A is a randomized 2-
approximation algorithm for U, but not a randomized E[2]-approximation65
algorithm for U. If one chooses RatioA,x(C11) as a very large number (instead
of RatioA,x(C11) = 50), then one can increase the gap between the most
“frequent” approximation ratio and the expected approximation ratio to an
arbitrarily large extent.
For the opposite direction, we consider a randomized algorithm B that
has 1999 runs on any input x, and all these runs are of the same probability.
Assume that 1000 of these runs lead to results with approximation ratio 11
and that the remaining 999 runs compute an optimal solution (i.e., 999 runs
have approximation ratio 1). Then, E[RatioB] is slightly greater than 6, but
B is not a randomized δ-approximation algorithm for any δ < 11.
Now, it is interesting to observe that even the algorithm66 B2 is a ran-
domized 1-approximation algorithm. Thus, the algorithm B is not so bad
with respect to the second class (Deﬁnition 2.5.70), as it could appear at ﬁrst
glance. Additionally, δ is not too large when compared with E[RatioB].
Is it even possible to show a general statement that B is always a
randomized δ-approximation algorithm for a δ ≥2 · E[RatioB]?
The answer is yes because (as already mentioned) for every random variable
X, the probability of getting a value less than or equal to 2 · E[X] is at least
1/2. This observation oﬀers the following claim.
Lemma 2.5.71. Let δ > 0 be a real number, and let U be an optimiza-
tion problem. For any randomized algorithm B, if B is a randomized E[δ]-
approximation algorithm for U, then B is a randomized γ-approximation al-
gorithm for U for γ = 2 · E[δ].
The following example is not only another illustration of the two concepts
of randomized approximation algorithms, but it also deepens our understand-
ing of the relation between these two concepts.
Example 2.5.72. Consider the MAX-EkSAT problem for k ≥3 and the al-
gorithm RSAM presented in Example 2.3.35 that simply generates a random
assignment to the variables of a given formula. For each instance
F = F1 ∧F2 ∧. . . ∧Fm
65only a randomized E[10]-approximation algorithm for U
66Remember that B2 consists of two independent runs of the algorithm B on the
same input.

84
2 Fundamentals
of MAX-EkSAT (with Fi in kCNF for i = 1, . . ., m), we have deﬁned for
i = 1, . . ., m the random variable Zi as the indicator variable for satisfying
Fi. We have shown that
E[Zi] = 1 −1
2k
is the probability that a random assignment satisﬁes Zi. The random variable
ZF =
m

i=1
Zi
counts the number of satisﬁed clauses in every run of RSEL, and applying
linearity of expectation we have proved that
E[ZF ] =
m

i=1
E[Zi] = m ·

1 −1
2k

.
(2.16)
Since the cost of an optimal solution is bounded by m, for every instance F
of MAX-EkSAT one obtains67
E[RatioRSEL(F)] ≤OptMAX-EkSAT(F)
E[ZF ]
≤
m
E[ZF ]
≤
m
m · (1 −2−k) =
2k
2k −1.
Thus, the algorithm RSEL is a randomized E

2k/(2k −1)

-approximation
algorithm for MAX-EkSAT.
Our next aim is to apply (2.16) in order to show that RSEL is a randomized
2k−1/(2k−1−1)-approximation algorithm for MAX-EkSAT. First, we observe
that
E[ZF ] = m · (1 −1/2k)
also says that m · (1 −1/2k) is the average number68 of satisﬁed clauses over
all assignments to the variables of F. The number m·(1−1/2k) is the average
of m and m · (1 −2/2k) = m · (1 −1/2k−1). Hence, the number m · (1 −1/2k)
lies in the middle between n and m·(1−1/2k−1) on the real axis (Figure 2.9).
To complete our argument we need to show that at least half the assign-
ments satisfy at least m · (1 −1/2k−1) clauses. Again, the combinatorial idea
says that if more than half the clauses satisfy fewer than m · (1 −1/2k−1)
clauses, then one cannot achieve the average value m · (1 −2−k), even if all
remaining assignments satisfy all m clauses (Figure 2.9).
If one wants to verify this claim by counting, denote
67Observe that RatioRSEL(F) = OptMAX-E kSAT(F)·(1/ZF ) is a random variable,
where OptMAX-E kSAT(F) is a constant for a given, ﬁxed F, and F is ﬁxed in our
analysis (in our probability space).
68Because all assignments have the same probability of being chosen.

2.5 Classiﬁcation of Randomized Algorithms for Optimization Problems
85
0
m · (1 −2−k+1) m · (1 −2−k)
m
Fig. 2.9.
(i) by l the number of assignments that satisfy fewer than m · (1 −1/2k−1)
clauses, and
(ii) by u = 2n−l the number of assignments that satisfy at least m·(1−1/2k−1)
clauses.
Then,
E[ZF ] ≤1
2n · (l · [m · (1 −2−k+1) −1] + u · m).
(2.17)
The inequalities (2.16) and (2.17) imply that
m · (1 −2−k) ≤1
2n (l ·

m · (1 −2−k+1) −1

+ u · m),
and so
2n · m · (1 −2−k) ≤l ·

m · (1 −2−k+1) −1

+ u · m,
which can be true for u > l only.
⊓⊔
Exercise 2.5.73. Let c be a real number and let X be a random variable in a
probability space (S, Prob). Let Y be a random variable deﬁned by Y = c·1/X,
i.e.,
Y (s) = c ·
1
X(s)
for all s ∈S. Prove that
E[Y ] = c ·
1
E[X].
Example 2.5.74. Consider the MAX-CUT problem deﬁned as follows. The
instances of MAX-CUT are (unweighted) graphs. For any given graph G =
(V, E), a pair (V1, V2) is a cut of G if
V1 ∪V2 = V and V1 ∩V2 = ∅,
and every cut is considered as a feasible solution for the MAX-CUT problem.
The cost of a cut (V1, V2) is the number of edges between the vertices from
V1 and the vertices from V2, i.e.,
cost(V1, V2) = |E ∩(V1 × V2)|.
The objective is to ﬁnd a cut with the maximal possible cost. We show that a
random choice of cut results in a randomized E[2]-approximation algorithm.

86
2 Fundamentals
Algorithm RC (Random Cut)
Input: A graph G = (V, E).
Step 1: V1 = ∅, V2 = ∅.
Step 2:
for every vertex v ∈V do
assign v to V1 or to V2 at random (with the same probabilities)
Output: The cut (V1, V2).
For every edge e = {u, v} ∈E, we deﬁne the indicator variable Xe as
Xe(C) =
⎧
⎪
⎪
⎨
⎪
⎪
⎩
0 if the output of C is the cut (V1, V2) and both u, v ∈V1 or
both u, v ∈V2,
1 if e lies in the cut (V1, V2) computed in C, i.e., if u ∈V1 and
v ∈V2 or vice versa
for every run C of RC. Since Xe is an indicator variable, we have
E[Xe] = 1 · Prob(Xe = 1) + 0 · Prob(Xe = 0) = Prob(Xe = 1) ,
and so E[Xe] is the probability of the event Xe = 1. Clearly, for every edge
e = {u, v}
Prob

X{u,v} = 1

= Prob(u ∈V1 ∧v ∈V2) + Prob(u ∈V2 ∧v ∈V1)
= Prob(u ∈V1) · Prob(v ∈V2)
+Prob(u ∈V2) · Prob(v ∈V1)
= 1
2 · 1
2 + 1
2 · 1
2 = 1
2
and so
E[Xe] = 1
2.
Let X = 
e∈E Xe be the random variable counting the number of edges
between V1 and V2. Due to linearity of expectation, one obtains
E[X] =

e∈E
E[Xe] = 1
2 · |E|.
Since |E| ≥OptMAX-CUT(G) and RatioRC(G) is the random variable
OptMAX-CUT(G) · 1
X ,
one obtains
E[RatioRC(G)] = OptMAX-CUT(G)
E[X]
≤
|E|
E[X] = 2.
Thus we have shown that RC is a randomized E[2]-approximation algorithm
for MAX-CUT.
⊓⊔
Exercise 2.5.75. Is it possible to show for a δ < 4 that RC is a randomized
δ-approximation algorithm?

2.6 Paradigms of the Design of Randomized Algorithms
87
2.6 Paradigms of the Design of Randomized Algorithms
In the previous sections we have already indicated that randomized algorithms
may be essentially more eﬃcient than their deterministic counterparts, and
so randomization can be a source of unbelievable eﬃciency. The fundamental
questions attending us during the course on randomization are the following:
•
What is the nature of (the reasons for) the success of randomiza-
tion?
•
Do there exist robust design methods for randomized algorithms
that are helpful in the search for an eﬃcient randomized algorithm
for a given problem?
In this section we introduce the fundamentals of the most famous concepts and
methods for the design of randomized algorithms, and provide the initial ideas
that explain the power of randomization this way. The following chapters of
this book are devoted to an involved study and applications of these particular
methods.
FOILING THE ADVERSARY
The method of foiling the adversary, also called the method of avoiding the
worst-case problem instances, lies behind the design of any randomized al-
gorithm. One considers the design of an algorithm as a game between two
players. One player is the designer, who tries to design an eﬃcient algorithm
for a given problem, and the other player is an adversary, who for any designed
algorithm tries to construct an input on which the algorithm does not work ef-
ﬁciently or even correctly. This is the typical game for designing and analyzing
deterministic algorithms, where the classic adversary argument establishes a
lower bound on the complexity of a given algorithm by constructing an input
instance on which the algorithm fares poorly. It corresponds to our view of
complexity as worst-case complexity, which means that only those algorithms,
that run eﬃciently on every input69 are considered to be eﬃcient. An adver-
sary has an advantage in this game because the designer has ﬁrst to present
his algorithm and, knowing the algorithm, it is not often diﬃcult to ﬁnd a
hard problem instance for the algorithm. This game can essentially change
when the designer designs a randomized algorithm A (instead of a determin-
istic one). For sure, an adversary learns the designed randomized algorithm
too, but one does not know which of the possible runs of the algorithm A will
be chosen at random. While an adversary may still be able to construct an
input that is hard for one run, or a small fraction of runs of A, it is diﬃcult
to devise a single input that is likely to defeat most of the runs of A.
69For instance, the time complexity of a deterministic algorithm is deﬁned as
Time(n) = max{Time(C) | C is a computation on an input of length n}.

88
2 Fundamentals
Learning this game and switching to the ﬁrst model of randomized algo-
rithms, one can recognize the main idea for the design of randomized algo-
rithms. It may happen for a problem U that on the one hand there exists
a hard problem instance for each deterministic algorithm solving U, but on
the other hand, for every instance x of U, there are suﬃciently many deter-
ministic algorithms that work correctly and eﬃciently on x. If one designs a
randomized algorithm as a probability distribution over a convenient set of
deterministic algorithms, then this algorithm works correctly and eﬃciently
on every problem instance with high probability.70
As we have already mentioned, this design paradigm is common for all
randomized algorithms. We illustrate this by considering two examples of
randomized algorithms already presented. First we consider the randomized
protocol R comparing the data on two computers RI and RII. This protocol
corresponds to a uniform probability distribution over Prim

n2
deterministic
protocols Pq for all q ∈PRIM

n2
. Each of these protocols is eﬃcient on all
inputs and works correctly on most of the inputs. But, for some inputs (x, y)
with x ̸= y, it may compute the wrong answer “x = y”. The crucial fact is
that, for every input (x, y), at least
Prim

n2
−(n −1) ≥1 −2 · ln n
n
of the protocols Pq provide the correct answer. Taking a random choice of a
protocol for a given input (x, y), one achieves a high probability of getting the
right answer. Here, it is interesting to mention that one can prove even more
than that every deterministic protocol solving this problem has a hard input
(x, y) on which it must exchange |x| communication bits. It is true that every
deterministic protocol for this task has a high communication complexity on
most inputs71. Thus, it is provable that the designed randomized protocol R
for Lequal is exponentially more eﬃcient than any deterministic protocol for
Lequal, and this holds not only with respect to the worst-case complexity, but
also with respect to the average complexity of all inputs of the same size.
In the case of the design of the randomized communication protocol R,
the aim was to ﬁnd a set of eﬃcient deterministic protocols, each of them
working correctly on almost all inputs. Designing the randomized Quicksort,
one is looking for a set of deterministic strategies such that
(i) each of these strategies works correctly on every input, and
(ii) each strategy proceeds eﬃciently on most inputs.
Let A = {a1, a2, . . ., an} be the set to be sorted. If one considers A as
an unsorted sequence a1, a2, . . ., an, a possible strategy could be to take the
element a1 as a pivot. This strategy in the framework of the “divide and
70i.e., there is no hard input for this algorithm, and so no adversary has a chance
to defeat this algorithm.
71Most inputs require the exchange of at least n −1 bits.

2.6 Paradigms of the Design of Randomized Algorithms
89
conquer” method leads to the following recurrence for estimating the number
of comparisons executed.
Time(1) = 0
Time(n) = n −1 + Time(|A<|) + Time(|A>|) .
If an adversary takes the input a1, . . ., an with a1 > a2 > . . . > an, then
A> = ∅and the complexity of the work on this input is in Θ(n2). Clearly,
an adversary can construct a hard input for every deterministic strategy of
choosing a pivot (without precomputation72). The kernel of the success of the
randomized Quicksort lies in the fact that each strategy of choosing a pivot
leads to complexity in O(n · log n) for most of the inputs.
Exercise 2.6.76. Let T : IN →IN be a function that satisﬁes the following
recurrence.
T (1) = 0
T (n) = n −1 + T
 n
10
 
+ T
! 9
10 · n
"
Prove that T (n) ∈O(n · log n). A consequence of this fact is that, from the
asymptotical point of view, at least 8/10 = 4/5 of the elements of A are good
pivots. How many elements in A are good pivots?
We show the power of the paradigm of foiling the adversary in Chap-
ter 3 by outlining possible contributions of randomization for hashing (data
management) and for online problems (optimization procedures without any
knowledge about the future).
ABUNDANCE OF WITNESSES
The method of abundance of witnesses is especially suitable for solving deci-
sion problems. Generally, a decision problem is a task of deciding whether a
given input73 has a special property of interest or not. For instance, taking
positive integers as possible inputs, one can ask whether a given n is prime or
not. In our example for the motivation in Section 1.2, the inputs were pairs
(x, y), and the task was to decide whether x ̸= y or x = y.
One can describe the application of the method of abundance of witnesses
for solving a decision problem U as follows. Assume that we do not have
any eﬃcient deterministic algorithm for this problem, or that there does not
even exist any eﬃcient deterministic algorithm solving U. The ﬁrst step of
72If one uses some comparisons for estimating a pivot, then one can assure a
reasonable ratio between |A<| and |A>|, and there is no hard input then for the
pivot precomputed in a reasonable way.
73more precisely, the object represented by this input

90
2 Fundamentals
the application of the method of abundance of witnesses is to search for a
suitable deﬁnition of witnesses. A witness has to be an additional information
(represented by a string) to a given input x, that helps to eﬃciently prove
that x has the required property (or does not have the required property).
For instance, a factor m of a given positive integer n is a witness of the fact
“n is prime.” In the design of the randomized protocol R for Lunequal, a prime
p is a witness of the fact74 “x ̸= y” if
Number(x) mod p ̸= Number(y) mod p.
If one has got such a prime p for free, then one can prove the fact “x diﬀers
from y” by an eﬃcient communication. Obviously, in reality is no one giving
us a witness for free, and in many cases there is no possibility of eﬃciently
computing a witness by a deterministic procedure (if this were possible, then
one would have an eﬃcient deterministic algorithm for the original problem).
To design an eﬃcient randomized algorithm one needs for every input a set
of witness candidates that contain reasonably many witnesses. Considering our
communication protocol R, PRIM

n2
is the set of candidates for witnessing
“x ̸= y” for any input (x, y). For every input (x, y) with x ̸= y, at least
n2
ln n2 −
(n −1) candidates from the approximately
n2
ln n2 candidates in PRIM

n2
are
witnesses of “x ̸= y”.
Hence, the probability of uniformly choosing a witness from the set
PRIM

n2
of witness candidates at random is at least
n2
ln n2 −(n −1)
n2
ln n2
≥1 −ln n2
n
.
This is very promising because the probability is very close to 1. But even if
the probability of choosing a witness at random would be only 1/2, we would
be satisﬁed. In such a case it is suﬃcient to perform several random choices,
because the probability of getting a witness grows very fast with the number
of random attempts.
Now, one can be surprised that, despite of the high abundance of witnesses,
we are not able to eﬃciently ﬁnd a witness in a deterministic way. A possibility
would be to systematically search in the set of all candidates in such a way
that a witness has to be found in a short time. The core of the problem is that,
for any input, the distribution of witnesses among candidates for witnessing
may be completely diﬀerent. Thus, if one ﬁxes a search strategy in the set of
candidates, an adversary can always ﬁnd input for which this strategy does
not work eﬃciently.
Consider the protocol R. Here, one can even prove that there is no strategy
that eﬃciently ﬁnds a witness for any input (x, y). To give a transparent
example, consider the simple strategy that tries to look on all primes from
PRIM

n2
in order, from the smallest prime to the largest one.
74of the diﬀerence between x and y

2.6 Paradigms of the Design of Randomized Algorithms
91
Obviously, one must ﬁnd a witness after at most n tests, because there are
at most n −1 non-witnesses among the candidates. Unfortunately n probes
means communication complexity n · 4 · log2 n, which is more than we are
willing to accept. Why is there no assurance of ﬁnding a witness after a few
probes? The explanation is that in order to ﬁnd a witness our strategy needs
k + 1 probes for any input (x, y) with
Number(x) −Number(y) = p1 · p2 · . . . · pk,
where k =
n
2(log2 n)2 and p1 < p2 < . . . < pk are the smallest primes.
One can easily imagine that, for any other order of primes in PRIM

n2
,
one can ﬁnd inputs (x, y) for which too many probes are necessary to obtain
a witness.
The art of applying the method of abundance of witnesses is in the search
for a promising deﬁnition of a witness for the property to be veriﬁed, and in
an appropriate choice of the set of candidates for witnessing. Hence, a useful
speciﬁcation of witnesses has to satisfy the following conditions:
(i) If one has a witness for an input, then one can eﬃciently prove that the
input has the required property (or does not have the required property).
(ii) If one has a witness candidate for an input x, then one can eﬃciently
verify whether or not the candidate is a witness of the claim “x has the
required property”.
(iii) The set of candidates for an input contains many witnesses. One aims to
have a constant ratio between the cardinality of the subset of witness and
the cardinality of the set of all candidates.
If (i), (ii), and (iii) hold, then we have the guarantee that a random choice
of a candidate provides a good basis for the design of an eﬃcient randomized
algorithm solving the given problem.
The method of abundance of witnesses can be applied to computing func-
tions, too. If F is a function and x is an argument of F, a witness for x
can be considered as additional information y such that, knowing (x, y), one
can compute F(x) more eﬃciently than without y.75 But in this book we
restrict our attention on designing randomized algorithms by the method of
abundance of witnesses to solving decision problems only. In Chapter 6 we
show the power of this design paradigm by designing eﬃcient randomized
algorithms for primality testing.
FINGERPRINTING
Fingerprinting (also called Freivalds’ technique) can be viewed as a special
case of the method of abundance of witnesses for solving equivalence problems.
75For instance, the quadratic roots for an integer a ∈{2, . . ., n −1} modulo
n build a witness for factorizing n. Although one does not know any polynomial-
time algorithm for factorization of integers, having this witness we can factorize n
eﬃciently.

92
2 Fundamentals
An instance of an equivalence problem consists of two complete representa-
tions of two objects, and the task is to decide whether or not these two repre-
sentations describe the same object. For example, an instance of the problem
of equivalence of two polynomials is to decide whether the two polynomials
(x1−2x2)2·(x1+x3)3·(x2−x3) and (x5
1−7x4
1x2
2+6x2x3)·(x2−x3+x1)2 represent
the same polynomial. Our protocol R for Lunequal also solves an equivalence
problem, because the task is to decide for any input (x, y) whether x = y or
x ̸= y.
The idea of ﬁngerprinting is to view witnesses as mappings that map the
complex, full, and hardly comparable descriptions of objects in some partial
descriptions. On the one hand, we require that these partial descriptions be
short and easy to compare. On the other hand, the partial descriptions have
to be representative, in the sense, that, though their incompleteness, they
save the most essential characteristics of the objects represented. Compar-
ing partial descriptions determined by a randomly chosen mapping instead
of comparing full, complex descriptions has to be a way of solving a given
equivalence problem correctly with high probability.
A good way to transparently present the ﬁngerprinting method is the
following schema.
Schema of the Fingerprinting Method
Objective: To decide the equivalence of two objects O1 and O2 with complex
representations.
Phase 1: Let M be a “suitable” set of mappings that map the full represen-
tation of the objects considered to some partial representations of these
objects.
Choose a mapping h from M at random.
Phase 2: Compute h(O1) and h(O2).
The partial representation h(Oi) of Oi is called the ﬁngerprint of Oi for
i = 1, 2.
Phase 3: Compare the ﬁngerprints h(O1) and h(O2).
if h(O1) = h(O2) then
output “O1 and O2 are equivalent”;
else
output “O1 and O2 are not equivalent”;
In the randomized protocol R for Lequal, the objects O1 and O2 were two
large numbers of n bits (n = 1016). The set M was speciﬁed as
{hp | hp(m) = m mod p for all m ∈IN, p is a prime, p ≤n2}.
For a randomly chosen prime p,
hp(O1) = O1 mod p and hp(O2) = O2 mod p
were the ﬁngerprints of O1 and O2.

2.6 Paradigms of the Design of Randomized Algorithms
93
The kernel of ﬁngerprinting is that hp(Oi) is an essentially shorter rep-
resentation of the number Oi than its full binary representation, and so the
comparison of hp(O1) and hp(O2) can be substantially more eﬃcient than
directly comparing O1 and O2. But this gain is achievable only due to in-
completeness of the representation hp(Oi) of Oi, and so one has to take the
possibility of an error into account. The set M is the set of candidates for wit-
nesses of the non-equivalence of O1 and O2 (i.e., if “O1 ̸= O2”). If, for every
pair of diﬀerent objects O1 and O2, there are many76 witnesses of “O1 ̸= O2”
in M, then one can reduce the error probability to an arbitrarily small value.
The art of applying the ﬁngerprinting method for the design of randomized
algorithms lies in a suitable choice of the set M. On the one hand, the ﬁnger-
prints should be as short as possible in order to assure an eﬃcient comparison.
On the other hand, the ﬁngerprints have to involve as much information about
their objects as possible77 in order to reduce the probability of losing the in-
formation about the characteristics of O1 and O2 in which they diﬀer.
Thus, searching for a suitable set M, one takes care at the trade-oﬀbe-
tween the degree of “compression” from O to h(O) and the error probabil-
ity. Designing the randomized protocol R for Lequal by the ﬁngerprinting
method, we were able to achieve an exponential representation reduction,
namely |h(O)| ∈O(log2 |O|), and we paid for this big gain with an error
probability tending to O with growing |O| only. This is an exemplary success
of ﬁngerprinting, because one can hardly expect more than an exponential
reduction of complexity for negligible error probability.
Further elegant and strong applications of ﬁngerprinting are presented in
Chapter 4.
RANDOM SAMPLING
A random sample from an object set is often representative of the whole set.
Sometimes it is not easy to deterministically construct objects with some given
properties (or satisfying some special constraints) despite the known fact that
there are many such objects in a set. One or a few random samples from this
set provide, with a high probability, an object having the required properties.
As an illustration one can also consider the random generation of witnesses.
One is unable to eﬃciently generate a witness deterministically, but one can
get a witness by a random choice from a set of candidates that contains many
witnesses. In this way, one may view the design of the randomized protocol
R as an application of the method of random sampling, too.
A special case of random sampling is the so-called probabilistic method,
based on the following two facts.
76relative to |M|
77This requirement is responsible for the term “ﬁngerprinting”, because ﬁnger-
prints are considered unambiguous identiﬁcations of men.

94
2 Fundamentals
Fact 1: For every random variable X, there is a value that is not smaller
than the expectation E[X], and there is a value that is not larger than
E[X].
Fact 2: If a randomly chosen object of a universe78 has a property with
positive probability, then there exists an object having this property.
Although these two facts are trivial observations, they may have surpris-
ingly strong applications. We have applied them in order to design a simple
randomized algorithm for MAX-SAT, based on the fact that the expected
number of clauses satisﬁed by a random assignment is at least half the total
number of clauses. If one considers MAX-EkSAT for a positive integer k, then
the expected number of satisﬁed clauses is 2k/(2k −1)·m for any formula of m
clauses. In this case, Fact 1 says that there exists an assignment that satisﬁes
2k/((2k −1) · m) clauses of any given formula of m clauses. We showed in
Example 2.5.72 that few random samples suﬃces to get with high probability
an assignment that satisﬁes m · (2k−1/(2k−1 −1)) clauses from m clauses.
More applications of the method of random sampling are presented in
Chapter 5, where we even design an eﬃcient randomized algorithm for an
algebraic problem that is not known to be in P.
AMPLIFICATION
The paradigm of the ampliﬁcation of the success probability says nothing else
than one can increase the success probability (the probability of computing the
correct result) by repeating independent computations on the same input. The
classiﬁcation of randomized algorithm presented is based on this paradigm,
and we have learned how much ampliﬁcation is helpful to diﬀerent classes of
randomized algorithms.
There are also circumstances under which repeating entire runs of the
randomized algorithm on the same input does not help very much, or even
does not help at all. But repetitions of some critical parts of the computation
only79 may be helpful in such cases. A part of a computation may be viewed
as critical when the success probability is essentially decreased in this part
relative to other parts of the computation. This more involved version of the
ampliﬁcation method will be presented in Chapter 5 for the problem of ﬁnding
a minimum cut in a graph.
RANDOM ROUNDING
One uses the method of random rounding in combination with the method of
relaxation to linear programming to solve optimization problems. The method
of relaxation ﬁrst relaxes a hard discrete optimization problem to an eﬃciently
78set of objects
79instead of repeating complete runs

2.6 Paradigms of the Design of Randomized Algorithms
95
solvable problem instance of linear programming by increasing the size of
the solution space (more precisely, by removing some constraints80 on the
variables domains). For instance, integer linear programming and 0/1-linear
programming are NP-hard problems, but allowing real solutions (i.e., remov-
ing the requirement that the values of the elements of the solutions must
be integers or Boolean values) one gets the problem of linear programming
which is solvable in polynomial time. Solving the relaxed problem instance,
one obtains a solution that is not necessarily a feasible solution of the original
discrete problem. To get a feasible solution of the original problem, one can
try to round the real values of the computed solution of the relaxed problem
instance. The hope is that the solution obtained by rounding is of a good qual-
ity, because the computed solution of the relaxed problem instance is optimal
for the real domain.
One can sometimes view random rounding as a special case of random
sampling. Instead of picking up samples from a set S by uniform probabil-
ity distribution over S, one applies the relaxation method in order to com-
pute another probability distribution over S, and then uses this probability
distribution for random sampling in S. We illustrate this view on random
rounding in Chapter 7 by designing a randomized approximation algorithm
for MAX-SAT.
GENERAL OBSERVATIONS
We introduced above some basic paradigms for the design of randomized al-
gorithms, and we aim to present them as successful methods for designing
randomized algorithms for concrete problems in the following chapters. We
call attention to the fact these design methods do not partition the class of
randomized algorithms into disjoint subclasses. More often than not, the con-
trary is true. Usually, several of the above design methods are behind the
design of a randomized algorithm. The best illustration of this statement is
the randomized protocol R. It is based on ﬁngerprinting (as a special case of
the method of abundance of witnesses) as well as on the method of foiling the
adversary and random sampling. Ampliﬁcation can be additionally used to
increase the success probability (to decrease the error probability). However,
we relate the design of the protocol R, without any doubt, to ﬁngerprinting,
because this method is essential for the design idea.
This is the approach we will use in the following chapters. For every design
paradigm, we present randomized algorithms, for whose design this paradigm
is the most helpful instrument.
80This constraints deletion is called relaxation.

96
2 Fundamentals
2.7 Summary
Probability theory is the language and the basic instrument for modeling and
analyzing randomized algorithms. In the name of transparency, in this intro-
ductory course we restrict our attention to ﬁnite probability spaces. Modeling
a random (probabilistic) experiment begins with ﬁxing the sample space S
of all possible outcomes (results) of the experiment. Every element of S is
considered an elementary event in the sense that in this model no elemen-
tary event can be viewed as a collection of even smaller ones, i.e., elementary
events are the atoms of the model, and so each elementary event (outcome of
the experiment) excludes the others. An event is an arbitrary subset of the
sample space S of all elementary events. After ﬁxing S, one determines the
probabilities of particular elementary events.81 The probability of any A is
then determined by the sum of the probabilities of all elementary events in A.
The notion82 of conditional probability was introduced in order to get an
instrument for analyzing experiments in which one has partial information
about the outcome of the experiment before it is ﬁnished. In this framework
such a partial information alway corresponds to an event B that occurs with
certainty. The conditional probability of an event A when an event B occurs
with certainty (i.e., the probability of A given B) is the probability of the
event A ∩B in a new probability space, where B is the sample space of all
possible elementary events. The probability distribution on B is unambigu-
ously determined by the requirement that, for any two elementary events from
B, the ratio of their probabilities in the new probability space is the same as
in the original probability space.
We say that two events A and B are independent if the probability of A
is equal to the probability of A given B. Thus, the meaning of independence
is that the occurrence of B with certainty does not have any inﬂuence on the
probability of A, and vice versa. A consequence of this concept of independence
and, in fact, an equivalent deﬁnition of independence of A and B is that A
and B are independent if and only if the probability of A ∩B is equal to the
product of the probabilities of A and B.
Other fundamental instruments for the analysis of probabilistic experi-
ments are the concepts of random variables as functions from the sample space
to IR, and the expectation of a random variable as the weighted83 average of
the values of the random variable.
For randomized algorithms, one requires eﬃciency and correctness with
high probability for every input. Therefore the behavior of a given randomized
algorithm has to be analyzed on every input. For a given randomized algorithm
A and an input x, we consider the set SA,x of all computations (runs) of A on
81This must be done in a way such that the sum over the probabilities of all
elementary events is equal to 1.
82concept
83where the weights are determined by the probabilities of having the correspond-
ing values of the random variables

2.7 Summary
97
x as the sample space. If one chooses the random variable (called the indicator
variable in this case) that assigns 1 to any run with the correct output and 0
to any run with a wrong output, then the expectation of this random variable
is exactly the probability that A computes the correct output for the input x.
This probability is called the success probability of A on x. The probability of
the complementary event (i.e., of the event that A computes a wrong output
on x) is called the error probability of A on x. If one takes a random variable
that assigns to every computation its complexity, then the expectation of this
random variable equals the expected complexity of A on x.
Whenever possible, we view a randomized algorithm as a probability distri-
bution over a set of deterministic algorithms. In general, one can view random-
ized algorithms as nondeterministic algorithms with a probability distribution
over each nondeterministic computation splitting.
We classify randomized algorithms with respect to the speed at which
their error probabilities are reduced by executing independent runs of the
algorithm on the same input. Las Vegas algorithms are the most convenient
ones, because they never produce a wrong output. We consider two versions of
them. In the ﬁrst version all computations end with the correct result, and in
the second version the output “?” (“I don’t know”) is allowed with bounded
probability. In the ﬁrst version, we always consider (analyze) the expected
complexity.
One-sided-error Monte Carlo algorithms are considered only for decision
problems, i.e., for problems of deciding whether or not a given input has the
required property. For any input having the property, one forces the random-
ized algorithm to recognize this fact with a probability of at least 1/2 (or
with a probability of at least ϵ for an ϵ > 0). A strong requirement is that,
for every input without this property, the algorithm rejects this input with
certainty (i.e., in all runs). A positive consequence of this requirement is that
the error probability of one-sided-error Monte Carlo algorithms tends to 0
with exponential speed in the number of independent runs executed.
A bounded-error Monte Carlo algorithm is a randomized algorithm for
which there exists a constant ϵ such that, for every input x, the algorithm
computes the correct output with probability at least 1/2 + ϵ. The crucial
point is the requirement of a ﬁxed, constant84 distance ϵ from 1/2 for the error
probability that assures that constantly85 many run executions are suﬃcient
for reducing the error probability to an arbitrarily small given constant. If
one relaxes this requirement to the constraint that the success probability is
greater than 1/2 for every input (i.e., if for diﬀerent inputs the distance of
the success probability to 1/2 may be diﬀerent, and may converge to 1/2 with
input length), then exponentially86 many runs may be necessary to reduce the
error probability below a given constant. The randomized algorithms with this
84independent of the input
85The number of the executed runs on the same input is, in this sense, a constant.
86in the input length

98
2 Fundamentals
relaxed constraint in the success probability are called unbounded-error Monte
Carlo algorithms, or simply (general) Monte Carlo algorithms. This algorithm
class has a large expressive power because all nondeterministic polynomial-
time algorithms can be simulated by polynomial-time Monte Carlo algorithms.
The classiﬁcation presented is suitable for solving decision and equivalence
problems, and for computing functions. Solving optimization problems, one
usually does not search for a unique correct solution, but one is satisﬁed with
any of the possibly many optimal solutions, or even with a nonoptimal solution
with a reasonable quality. This quality is measured by the approximation
ratio, which may be viewed as a random variable. One may be interested in
analyzing the expectation of the approximation ratio, or in guaranteeing an
approximation ratio with probability at least 1/2.
Presenting several examples, we have seen that randomized algorithms
may be more eﬃcient than their best known, or even the best possible, de-
terministic counterparts. In our exemplary motivation for the study of ran-
domization in Section 1.2, we showed that the gap between determinism and
randomization can be of exponential size. The general robust ideas behind
randomization are called here paradigms of the design of randomized algo-
rithms. The most important, recognized paradigms are “foiling the adver-
sary,” “abundance of witnesses,” “ﬁngerprinting,” “random sampling,” “ran-
dom rounding,” and “ampliﬁcation.”
The paradigm “foiling the adversary,” also called “the method of avoiding
worst-case inputs,” can be recognized behind the design of every randomized
algorithm. The idea is to overcome the situation where, for each determinis-
tic algorithm, there exist hard inputs (on which the algorithm does not run
eﬃciently or correctly) in the following way. One ﬁnds a set of deterministic
algorithms (strategies) such that, for each instance of the problem considered,
most of these algorithms compute the correct result eﬃciently. Then, the ran-
domized algorithm is simply designed as a probability distribution over this
set of deterministic algorithms.
The method of “abundance of witnesses” is especially suitable for solving
decision problems. A witness y for an input x is information with which one
can compute the correct output for x more eﬃciently than without. If one has
suﬃciently many witnesses for every instance x of the problem, then one can
try to get a witness by choosing an element for a set of witness candidates
at random. If there is an abundance of witnesses in the set of candidates,
and the witnesses are randomly distributed in this candidate set, there is no
possibility of eﬃciently constructing a witness in the deterministic way. But a
random sample from the set of candidates leads to a witness with reasonable
probability.
The method of random sampling helps construct objects having a special
property when one knows that there are many such objects; but, because of
their random distribution in the set of all objects of the type considered, one
is unable to ﬁnd or to construct such an object eﬃciently in a deterministic
way. Because of the abundance of such objects, a random choice is an ideal

2.7 Summary
99
way of creating objects having some desired properties. In fact, one applies
this paradigm for creating a witness to each application of the method of
abundance of witnesses.
The paradigm of “ampliﬁcation” says that one can increase the success
probability of a randomized algorithm by executing several independent runs
of the algorithm on the same input. In fact, we use this paradigm for classify-
ing randomized algorithms with respect to the speed of the error probability
reduction in the number of executed runs.
The method of “random rounding” is applied to solving hard optimization
problems. First, one relaxes an NP-hard discrete optimization problem to an
eﬃciently solvable problem like linear programming, and then one rounds the
real optimal solution of the relaxed problem instance to get a feasible solution
of the original optimization problem.
Karp was the ﬁrst computer scientist who explicitly formulated the para-
digms of the design of randomized algorithms in his milestone article [Kar91].
The most exhaustive source of randomization in algorithmics is the excellent
book of Motwani and Raghavan [MR95]. Several parts of this book are too
diﬃcult to be read by non-specialists, and so we recommend this source as
an advanced course, deepening the knowledge provided in our textbook. A
simple introduction to applying randomization for solving hard problems is
presented in Chapter 5 of the textbook [Hro03]. Pardalos, Rajasekaran, Reif,
and Rolim edited an extensive handbook [PRRR00] on randomized computing
with many excellent contributions by leading researchers in this area. The
bestseller on algorithmics by Cormen, Leiserson, Rivest, and Stein [CLRS01]
(the ﬁrst edition [CLR90] by Cormen, Leiserson, and Rivest) provides also
several nicely presented contributions to the design of randomized algorithms.
For further reading we also warmly recommend the textbooks of Brassard
and Bradley [BB96], Sch¨oning [Sch01], and Wegener [Weg03] (the last two
in German). A fascinating source about the famous PCP Theorem, which
provides a fascinating endorsement of the power of randomized computing, is
the book edited by Mayr, Pr¨omel, and Steger [MPS98].
An excellent, transparent introduction to probability theory is provided in
the German textbook [SS01] by Schickinger and Steger. We also warmly rec-
ommend, for the fundamentals of discrete mathematics, the book by Graham,
Knuth, and Patashnik [GKP94], the successful textbook by Ross [Ros00], and
the introductory German bestseller by Steger [Ste01].

This page intentionally left blank

3
Foiling the Adversary
A rival disclosing your faults
is more useful to you
than a friend trying to hide them.
Leonardo da Vinci
3.1 Objectives
The method of foiling the adversary lies behind all randomized algorithms.
The aim of this chapter is to present its applications in situations in which it
is crucial in the algorithm design process. This is the case exactly for problems
for which
(i) every deterministic algorithm (strategy) has some worst-case instances at
which the algorithm is not able to eﬃciently compute the correct output,
(ii) but there exists a class of deterministic algorithms such that, for every
problem instance, most algorithms of this class eﬃciently compute the
correct result.
If (ii) holds, then, for any given input instance, one can pick an algorithm
from the class at random, and expect to get the correct result eﬃciently
with reasonable probability. Because of the point of view presented above this
method is also called the method of avoiding the worst-case inputs. We
speak preferably about foiling the adversary because one can view the entire
process of algorithm design as a game between the algorithm designer and
her/his adversary. The goal of the designer is to design an eﬃcient algorithm
for a given problem. The task of the adversary is to investigate any algorithm
presented by the designer in order to ﬁnd instances at which this algorithm
behaves poorly. This is a typical game for analyzing algorithms or for proving
lower bounds on the amount of computing resources necessary to solve a
given problem. In situations where the adversary is successful in constructing
hard inputs for any given deterministic algorithm, the designer can try to
beat the adversary by designing a randomized algorithm. Then the task of
the adversary becomes harder than in the deterministic case. Though the
adversary can learn the designed randomized algorithm, she/he does not know
which of the possible runs will be chosen at random. And ﬁnding an input
that is hard for all, or at least for many, runs is a much more complex task
than ﬁnding a hard problem instance for a speciﬁc run.

102
3 Foiling the Adversary
The art of applying the method of foiling the adversary lies in
ﬁnding a suitable set of deterministic algorithms (strategies) such that,
for any problem instance, most algorithms eﬃciently compute the cor-
rect result.
To give transparent presentations of successful applications of this method,
we consider hashing and online algorithms. In the case of hashing, one can
easily observe that, for each hash function, one can ﬁnd a set of data records
(keys), such that the distribution of data in the hash table is very unsatisfac-
tory. This is transparently shown in Section 3.2. In Section 3.3 it is shown that
one can ﬁnd a set H of hash functions (hashing strategies) such that, for each
set S of data records, a randomly chosen hash function from H distributes
the actual data records of S very well in the hash table with high probabil-
ity. Section 3.4 introduces the online problems. Solving an online problem,
one gets only part of the problem instances, and is required to process it.
After the completion of this partial task, the following part of the problem
instance is made available, etc. The crucial point is that the decision made
while working on an available part of the input must be executed, and may
not be changed after reaching subsequent parts. As we will document later,
these kinds of tasks are very natural in practice, especially in scheduling and
logistics. This is an ideal situation for the adversary who always waits for the
decisions of an online algorithm on an input part and, after decisions have
failed, creates the next part of the input. Therefore it is not surprising that
for many online problems deterministic algorithms do not have any chance
of ﬁnding a reasonably good1 solution for the entire task. This can happen
even for optimization problems for which deterministic algorithms are able
to provide good solutions eﬃciently, assuming that the entire input instance
is available from the very beginning of the computation. Section 3.5 shows
that by applying randomization (especially the design paradigm of foiling the
adversary) one can guarantee reasonably good solutions to online problems
for which no comparably good solution can be assured by deterministic algo-
rithms working in unbounded time.
3.2 Hashing
Hashing is a method of dynamic data management. The considered data
records have unique names, and one uses the names to request them. The
unique name of a data record is called the key (of that data record) and the
whole data management is determined by the keys, i.e., the lengths and the
contents of the data records do not have any inﬂuence on data management.
Because of this, we identify data records with their keys, and work only with
the keys in what follows.
1close to an optimal solution

3.2 Hashing
103
Dynamic data management consists of executing a sequence of the follow-
ing three dictionary operations:
•
Search (T, k): Search for the key (data record) k in the data structure T .
•
Insert (T, k): Insert the new key (data record) k in the data structure T .
•
Delete (T, k): Delete the key (data record) k in the data structure T .
Our aim is to ﬁnd a dynamic data structure such that these three opera-
tions can be eﬃciently performed. Basic courses on data structures and algo-
rithms usually introduce AVL-trees and B-trees. These dynamic data struc-
tures enable us to execute any of these three kinds of operations in
Θ(log n)
time, and this holds in the worst case as well as in the average case.
U (universe)
S
T (hash table)
h
0
data records with h(x) = 0 . . .
1
data record with h(x) = 1 . . .
2
data records with h(x) = 2 . . .
i
data records with h(x) = i . . .
m−1 data records with h(x) = m−1 . . .
Fig. 3.1.
The ﬁrst goal of hashing is to reduce the expected complexity to O(1). We
assume we have memory T with direct access2 to each memory cell of T . The
memory cells are called slots, and T is called a hash table (Figure 3.1) or
direct address table. The size |T | is the number of slots of T and we ﬁx the
notation
|T | = m
for a positive integer m for the rest of this chapter. We set
T = {0, 1, 2, . . ., m −1},
2One is able to examine any memory cell (position) of T in time O(1).

104
3 Foiling the Adversary
where 0, 1, 2, . . ., m −1 are the names of the slots. The whole scenario is
depicted in Figure 3.1). We have a large set U, called the universe, that
contains all possible keys.3 Usually, |U| ≫|T |, and so it is impossible to
embed the whole universe U in T . But this is not bad because U does not
correspond to any actual set of data records (keys), it is only the set of all
keys that may occur in an application. Thus, instead of trying to manage U,
we aim to save an actual set S of keys (data records) in T . The set S is given
by a considered application and its size is usually comparable with |T | = m.
In what follows, we always consider U as a large ﬁnite subset {0, 1, 2, . . ., d}
of IN, or even U = IN. Our task is to save a set S ⊆U of actual keys (data
records) in T . The main point is that we cannot inﬂuence the choice of S,
and we do not have any preliminary information about S. The set S is given
completely by a considered application (by a user), and we are not able to
predict anything about it. Typically, S is approximately as large as T , and
we ﬁx
|S| = n
for the rest of this chapter. The task is to determine a mapping
h : U →T = {0, 1, . . ., m −1}
such that the set S ⊆U is “well dispersed” in T . To be “well dispersed” means
that the elements of S are uniformly distributed in the slots {0, 1, . . ., m −1}
of T ; in the ideal case each slot has approximately
|S|
|T | = n
m
keys of S. If a slot b has l keys of S, we build a linear list of l keys (data records)
and use a pointer from the slot b to this list (as depicted in Figure 3.2) to
make this list available. The consequence is that the search for a key in the
list costs at most time l, and in the average case time l/2. Hence it is clear
that the maximal4 number of keys assigned to a slot is decisive for the com-
plexity of the execution of dictionary operations Search (T, k), Insert (T, k),
and Delete (T, k).
Once again we call attention to the fact that we do not have the possibility
of choosing h as a mapping from S to T . We have to choose h without any
knowledge of S. Moreover, the set S may substantially change during data
management by applying the operations Insert (T, k) and Delete (T, k).
The function h from U to T is called a hash function. Since U and T
are given, and S is ﬁrst unknown, and we cannot inﬂuence its choice, the only
instrument we have in this game is the choice of the hash function h from U
to T . We pose the following requirements on h:
(i) h can be eﬃciently computed,
3all possible names of data records
4over all i ∈{0, 1, . . ., m −1}

3.2 Hashing
105
T
U
S
h
a1
a1
a2
a2
a3
a3
a4
a4
a5
a5
0
1
2
i
m−1
Fig. 3.2.
(ii) h maps most data sets S ⊆U to T in such a way, that, for all i ∈
{0, 1, . . ., m −1}, the cardinality of the set
T (i) = {a ∈S | h(a) = i}
is in O(|S|/|T |).
Note, that the choice of the hash function h can also be viewed as an appli-
cation of ﬁngerprinting.5 From this point of view, an h(a) ∈{0, 1, . . ., m −1}
is a ﬁngerprint of a possibly larger key (number) a. The requirement (ii) says
besides other things, that the ﬁngerprint h(a) saves so much essential infor-
mation about a that using h(a) one can distinguish a from almost all other
keys in S for most sets S (or that using h(a) one can distinguish a from most
other keys in the universe).
It is important to observe that one cannot strengthen the requirement (ii)
for the choice of h by requiring a uniform distribution of S in T for every set
S ⊆U. For every hash function h : U →T and every slot i ∈{0, 1, . . ., m−1},
there exists the set
Uh,i = {a ∈U | h(a) = i},
all of whose elements are mapped by h to the slot i of T . Hence, for any
actual key set S ⊆Uh,i, or S consisting primarily of elements of Uh,i, the
hash function h does not provide any good distribution of the keys in T .
In order to fulﬁll at least (ii), one has to have at least a hash function h
that uniformly distributes all keys of the universe U in T . This is nothing else
than forcing, that, for every i ∈{0, 1, . . ., m −1},
Prob(h(x) = i) = 1
m
(3.1)
5See Section 2.6 for more details.

106
3 Foiling the Adversary
for every randomly chosen element6 x of U. An example of such a hash function
is the function hm : U →T , deﬁned by
hm(x) = x mod m.
Exercise 3.2.1. Let U be a ﬁnite set, |U| = r · m for a positive integer r.
Estimate the number of functions h : U →T that satisfy the property (3.1).
Our ﬁrst aim is to show that all functions satisfying (3.1) fulﬁll the re-
quirement (ii), too. Let Pn(U) = {S ⊆U | |S| = n} for any opsitive integer
n.
Lemma 3.2.2. Let U = IN be the universe, and let T = {0, 1, . . ., m −1},
m ∈IN −{0, 1}. Let n be a positive integer, and let h : U →T be a hash
function that satisﬁes (3.1). Then, for every slot l of T ,
(i) the expected number of elements of a random S ∈Pn(U) assigned to the
slot l (i.e., the number of elements x of S with h(x) = l) is smaller than
n
m + 1
(ii) and, if n = m, then
Prob(more than one key from a random S ∈Pn(U) is in the l-th slot) < 1
2.
Proof. We consider the experiment of choosing n elements (keys) of U at
once in order to obtain a random set S ⊆U with |S| = n. One can model this
experiment by the probability space (Pn(U), Prob), where
Pn(U) = {S ⊆U | |S| = n}
and Prob is the uniform probability distribution over Pn(U). We use the
notation S = {s1, s2, . . ., sn}, where s1, . . ., sn is the n-tuple of randomly
chosen keys from U.
For all i, j ∈{1, . . ., n}, i < j, and all l ∈{0, 1, . . ., m −1}, we consider
the random variable Xl
ij, deﬁned by
Xl
ij(S) =
	1 if h(si) = h(sj) = l
0 else.
If h(si) = h(sj) = l, then we say that si and sj have a collision in the
l-th slot. Since Xl
ij is an indicator variable, the expectation E

Xl
ij

is the
probability that h(si) = h(sj) = l (i.e., that both si and sj are assigned to
the l-th slot). But this is nothing other than
6i.e., the sample space considered here is the universe U, and the probability
distribution over U is the uniform one.

3.2 Hashing
107
Prob(h(si) = l ∧h(sj) = l) = Prob(h(si) = l) · Prob(h(sj) = l)
=
(3.1)
1
m · 1
m =
1
m2 .
(3.2)
Now, we estimate the expected number of collisions for each slot l in T . The
indicator variable
Xl =

1≤i<j≤n
Xl
ij =
n

i=1
n

j=i+1
Xl
ij
counts the number of collisions in the l-th slot. Applying the linearity of
expectation and inserting (3.2), we obtain
E

Xl
= E
⎡
⎣

1≤i<j≤n
Xl
ij
⎤
⎦
=

1≤i<j≤n
E

Xl
ij

=
(3.2)

1≤i<j≤n
1
m2
=
n
2

m2 = n(n −1)
2m2
<
n2
2 · m2
(3.3)
for every l ∈{0, 1, . . ., m −1}. For n = m, one obtains
E

Xl
< 1
2,
i.e., the probability that more than one key of S is assigned to the l-th slot of
T is smaller than 1/2.
Next, we use (3.3) to estimate the expected number of keys from S assigned
to the l-th slot for an arbitrary n > m. If exactly k elements of S are assigned
to the l-th slot, then one has exactly
k
2

= k · (k −1)
2
collisions in the l-th slot. Setting E

Xl
= k·(k−1)
2
, one obtains
n2
2m2 > E

Xl
=
(3.3)
n · (n −1)
2 · m2
= k · (k −1)
2
> (k −1)2
2
,
and so
k < n
m + 1.
⊓⊔

108
3 Foiling the Adversary
Exercise 3.2.3. Assume that the assumptions of Lemma 3.2.2 are satisﬁed.
Estimate the expected number of collisions in all slots of T .
Exercise 3.2.4. Let S be a randomly chosen group of persons. How large has
S to be in order to assure
Prob(two persons from S were born on the same day) ≥1
2?
To answer this question, consider the indicator variable X deﬁned by
X(S) =
	
1 if there are two persons in S with the same birthday
0 else
and assume that the birthdays are uniformly distributed over the year.
Estimate E[X] as a function of |S|.
Exercise 3.2.5. Assume U, T , and S and Xl
ij, and Xl for 1 ≤i < j ≤n, and
0 ≤l ≤m −1 have the same meaning as in the proof of Lemma 3.2.2. Deﬁne
a new random variable MAX : Pn(U) →{0, 1} by
MAX(S) = max{X0(S), X1(S), . . ., Xm−1(S)}.
Estimate E[MAX] and explain its meaning.
Lemma 3.2.2 assures that the expected7 complexity of the execution of any
dictionary operation is in O
 n
m

, and so in O(1) for n ∈O(m). This holds
because the expected number of keys assigned to any slot of T is less than
n
m + 1. Remember that the expectation is considered as the average over all
possible sets S.
In Lemma 3.2.2 we assumed U = IN. If |U| is a ﬁnite multiple of |T | and
one tries to ﬁx S by n consecutive random choices of an element of U, we have
the following problem. Let x with h(x) = i for an i ∈T be the ﬁrst element
chosen. If (3.1) holds, then



{a ∈U −{x} | h(a) = i}



 <



{b ∈U −{x} | h(b) = j}



 = |U|
m
for all j ∈{0, 1, . . ., m−1}−{i}. Hence, the probability of getting an element
y with h(y) = i in the random choice of the second element from U −{x} is
less than 1/m. If |U| ≫|S| ≥|T |, one may take 1/m as a good approximation
of Prob(h(a) = s | a ∈U −A) for every s ∈T and every set A with |A| < |S|.
Another way to overcome this diﬃculty is considered in the following exercise.
Exercise 3.2.6. Consider the following random generation of S ⊆U. We
consider the experiment of n consecutive random choices of elements from U
in the way in which each chosen element is returned to U before the next
7with respect to a randomly chosen set S of n elements

3.3 Universal Hashing
109
random choice, i.e., one has n random choices from the complete universe U.
In this way one allows the choosing of the same element several times. The
result of this random experiment is a set
S ∈
n
#
r=1
Pr(U).
Estimate the probability of generating a set of cardinality n (i.e., the proba-
bility that no element has been chosen more than once). Formulate and prove
an assertion similar to Lemma 3.2.2 for a random choice of a set S from a
ﬁnite universe U.
3.3 Universal Hashing
In the previous section we have shown that
(i) for every hash function h, there exist “bad” sets S (for instance, a set
S ⊆Uh,i = {a ∈U | h(a) = i})), and (on the other hand)
(ii) every hash function satisfying (3.1) successfully distributes the keys of a
random set S (and so the most subsets of the universe U) in T .
Though the fact (ii) may evoke optimism, one has to note that the choice
of data (keys) from the universe is very far from being random according to
the uniform distribution. For instance, when the data records of employees
of an institute contain a bit for the sex indicator, and almost all persons
working in the institute are women, then one cannot model and represent this
bit by a random choice. Also, the birthdays are not uniformly distributed over
the year, and problems can occur when considering age. Therefore we aim to
improve the hashing strategy.
Considering facts (i) and (ii), we have an exemplary situation calling for
applying the method of foiling the adversary. For every choice of h (i.e., for
every deterministic hashing), (i) says that the adversary can construct arbi-
trarily bad inputs S. On the other hand (ii) says that there are many hash
functions that assure the best possible distribution for most inputs S. Fol-
lowing the idea of foiling the adversary, one has to choose a hash function at
random from a set of hash functions such that every input set S is uniformly
distributed in T with high probability.
Hence, we need a set H of hash functions from which one can uniformly
choose h at random. This means that our probability space is
(H, ProbH),
and H should be created in such a way that (H, ProbH) is good for every
possible S. In searching for H, we follow an analogy to condition (3.1) saying
that two randomly chosen keys x and y from U are mapped by h on the same
slot with probability at most

110
3 Foiling the Adversary
1
m.
Here, we require for each pair of keys x, y ∈U, x ̸= y, that the set H has the
property
ProbH(h(x) = h(y)) ≤1
m.
(3.4)
This leads to the following deﬁnition:
Deﬁnition 3.3.7. Let H be a ﬁnite set of hash functions from U to T =
{0, 1, . . ., m −1}. The set H is called universal if for each pair of elements
x, y from U, x ̸= y,
|{h ∈H | h(x) = h(y)}| ≤|H|
m
holds, i.e., at most every m-th hash function from H maps x and y to the
same slot of T .
We immediately observe that every universal set of hash functions satisﬁes
condition (3.4) in the probability space (H, ProbH). The next theorem shows
that each universal set of hash functions corresponds to our main goal to
guarantee a uniform distribution of S in T for every subset S of U.
Theorem 3.3.8. Let S ⊆U be an arbitrary set of keys, |S| = n. Let H be a
universal class of hash functions from U to T = {0, 1, . . ., m −1}.
Then, for every x ∈S and a randomly chosen h ∈H the expected cardi-
nality of the set Sx(h) = {a ∈S | a ̸= x, h(a) = h(x)} is at most
|S|
|T | = n
m.
Proof. Let S be an arbitrary subset of U, with |S| = n. Consider the prob-
ability space (H, ProbH). Let, for all x, y ∈S, x ̸= y, Zx,y be the indicator
variable deﬁned by
Zx,y(h) =
	
1 if h(x) = h(y)
0 if h(x) ̸= h(y).
Since Zx,y is an indicator variable, applying (3.4) we obtain
E[Zx,y] = ProbH(h(x) = h(y)) ≤
(3.4)
1
m.
(3.5)
The random variable
Zx =

y∈S,y̸=x
Zx,y
counts the number of elements in Sx(h) for every x ∈S. Due to the linearity
of expectation we obtain

3.3 Universal Hashing
111
E[Zx] =

y∈S
y̸=x
E[Zxy] ≤
(3.5)

y∈S
y̸=x
1
m = |S| −1
m
< n
m
for every key x ∈S.
⊓⊔
The assertion of Theorem 3.3.8 says that the expected number of keys in
any slot of T is smaller than 1 + n
m. Therefore, the concept of universal sets
of hash functions is an instrument for solving the problem of dynamic data
management, assuming there exist universal sets of hash functions. The next
step is to show that we have not introduced an “empty” concept.
Lemma 3.3.9. Let U be a ﬁnite set. The class
HU,T = {h | h : U →T }
of all functions from U to T is universal.
Proof. The number of all functions in HU,T is8
m|U|,
and each of these functions has the same probability of being chosen. Let
H(x, y, i) = {h | h : U →T and h(x) = i = h(y)}
for all x, y ∈U, x ̸= y, and all i ∈T . Clearly,9
|H(x, y, i)| = m|U|−2.
What we need is to estimate the cardinality of the set
H(x, y) = {h : U →T | h(x) = h(y)}.
Observe that
H(x, y) =
m−1
#
i=0
H(x, y, i)
and H(x, y, i) ∩H(x, y, j) = ∅for all i ̸= j, i, j ∈T . Therefore,
|H(x, y)| =
m−1

i=0
|H(x, y, i)| =
m−1

i=0
m|U|−2 = m|U|−1 = |HU,T |
m
for all x, y ∈U, x ̸= y. From Deﬁnition 3.3.7, HU,T is a universal set of hash
functions.
⊓⊔
8One has to assign one of the m values from T to each element of U.
9The functions in H(x, y, i) have a ﬁxed value i for the arguments x and y, and
so |H(x, y, i)| equals the number of functions from U −{x, y} to T.

112
3 Foiling the Adversary
Exercise 3.3.10. Let us consider the set
M = {h : U →T | h fulﬁlls (3.1)}.
Is M a universal set of hash functions?
Now, we are sure that the concept of universality is not empty, but unfortu-
nately this does not mean that one has a guarantee of a successful application.
There are at least two reasons why we cannot use HU,T in real applications.
(1) HU,T is too large10 to be able to perform a random choice of an h from
HU,T eﬃciently.
(2) Most functions from HU,T can be viewed as random mappings in the
sense11 that they do not have any essentially shorter description than their
full table representation. Such functions are not eﬃciently computable.
The reasons (1) and (2) explaining why one is not satisﬁed with HU,T help
us formulate what one really wants. We would like to have a universal class
H of hash functions such that
(i) H is small (at most polynomial in |U|), and
(ii) every hash function from H is very eﬃciently computable.
In what follows, we show that the above formulated wishes are satisﬁable.
Consider U = {0, 1, 2, . . ., p −1} for a prime p. For any natural numbers
a, b ∈U, we deﬁne the linear hash function ha,b : U →T by
ha,b(x) = ((ax + b) mod p) mod m
for every x ∈U. Since we compute modulo m, it is obvious that ha,b really
maps elements from U to T . Let
Hp
lin = {ha,b | a ∈{1, 2, . . ., p −1} and b ∈{0, 1, . . ., p −1}}
be a set of hash functions. Obviously,
|Hp
lin| = p · (p −1).
Theorem 3.3.11.∗
For any prime p, the class Hp
lin is a universal class of
hash functions from U = {0, . . ., p −1} to T = {0, 1, . . ., m −1}.
Proof. Let x and y by arbitrary distinct elements from U. We have to show
that
|{ha,b | ha,b ∈Hp
lin and ha,b(x) = ha,b(y)}| ≤|Hp
lin|
m
= p · (p −1)
m
.
10Observe that U is already very large, and so m|U| is usually substantially larger
than the number of protons in the known universe.
11See the concept of Kolmogorov complexity as presented in [Hro03].

3.3 Universal Hashing
113
To achieve this goal, we start with the investigation of the linear functions
h′
a,b(x) = (ax + b) mod p
in ZZp. The algebra (ZZp, ⊕mod p, ⊙mod p) is a ﬁeld because p is a prime.12
Let
r = h′
a,b(x) = (ax + b) mod p and s = h′
a,b(y) = (ay + b) mod p
(3.6)
be the remainders modulo p after applying the linear mapping h′
a,b on x and
y. We show in indirect way that x ̸= y implies r ̸= s. Clearly,
r −s ≡ax −ay ≡a · (x −y) (mod p).
(3.7)
If r = s, then
a · (x −y) ≡0 (mod p).
Since c · d = 0 in a ﬁeld implies that c = 0 or d = 0, we obtain that
a ≡0 (mod p) or (x −y) ≡0 (mod p)
hold.13 The element a ∈{1, . . ., p −1} is smaller than p, and so cannot be
divisible by p. Hence, the only possibility is that x −y ≡0 (mod p). Since
x, y ∈{1, . . ., p −1}, we obtain x = y.
Since we assumed x ̸= y, r and s must be diﬀerent. Hence, we have proved
that for any ﬁxed diﬀerent keys x, y ∈U, every14 function h
′
a,b unambiguously
determines a pair (r, s) from U ×U, with r ̸= s. In other words, we have proved
that the function fx,y, deﬁned by
fx,y(a, b) = ((ax + b) mod p, (ay + b) mod p) = (h′
a,b(x), h′
a,b(y)),
is a mapping from (U −{0}) × U to {(r, s) | r, s ∈U, r ̸= s} (Figure 3.3).
We claim that fx,y is a bijection.15 Since
|(U −{0}) × U| = (p −1) · p = |{(r, s) | r, s ∈U, r ̸= s}|,
it is suﬃcient to show that one of the functions fx,y or f −1
x,y is injective.
We show that f −1
x,y is injective. Let r and s belong to U, r ̸= s. Since one
computes in a ﬁeld ZZp, the linear equalities (3.6) for known values of x, y, r,
and s have the following unique solution in ZZp:
a =
(3.7)
(r −s) · (x −y)−1 mod p
12ZZp is a ﬁeld if and only if p is a prime. This assertion is a direct consequence
of Theorem A.2.27.
13In other words, if a prime p divides a · (x −y), then, following the Fundamental
Theorem of Arithmetics (Theorem A.2.3), p must divide a or (x −y).
14h
′
a,b for all a ∈{1, . . ., p −1} and b ∈{0, . . ., p −1}
15i.e., fx,y and f −1
x,y are injective functions

114
3 Foiling the Adversary
fx,y
(a, b)
(r, s)
(U −{0}) × U
{(r, s) | r, s ∈U, r ̸= s}
Fig. 3.3.
and
b = (r −ax) mod p,
where (x −y)−1 is the unique inverse of the element x −y with respect to
⊙mod p in ZZp. Therefore the mapping f −1
x,y deﬁned by
f −1
x,y(r, s) = (a, b) = ((r −s) · (x −y)−1 mod p, (r −ax) mod p)
is an injective function, too.
Since the random choice of ha,b (i.e., the random choice of (a, b)) unam-
biguously determines the pair
(r, s) = (h′
a,b(x), h′
a,b(y)) = ((ax + b) mod p, (ay + b) mod p),
the number of hash functions in
Hp
lin(x, y) = {ha,b ∈Hp
lin | ha,b(x) = ha,b(y)}
is equal to the cardinality of the set
M(x, y) = {(r, s) ∈U × U | r ̸= s and r ≡s (mod m)},
and so
|Hp
lin(x, y)| = |M(x, y)|.
(3.8)
The number of elements in U is p, and U can be partitioned into the remainder
classes modulo m. Each of these remainder classes has at most
$ p
m
%
≤(p + m −1)
m
= (p −1)
m
+ 1
elements. This means that, for every ﬁxed r, there are at most
(p −1)
m
elements s in U, with
r ≡s (mod m) and r ̸= s.
In this way, we obtain16
16The element r can be chosen from p elements of U.

3.3 Universal Hashing
115
|M(x, y)| ≤p · (p −1)
m
(3.9)
for all pairs (x, y) ∈U × U, with x ̸= y, and so
|Hp
lin(x, y)| =
(3.8)
|M(x, y)| ≤
(3.9)
p · (p −1)
m
= |Hp
lin|
m
for all (x, y) ∈U, with x ̸= y.
⊓⊔
Exercise 3.3.12. In Theorem 3.3.11 we have chosen U = {0, 1, . . ., p−1} for
a prime p. Assume that U = {0, 1, . . ., l} for an arbitrary positive integer l,
and choose a prime p such that p > l. Is the set Hp
lin still a universal set of
hash functions?
Next, we give another useful example of a universal set of hash functions.
For this purpose we consider another appropriate representation of keys. For
every prime m and every positive integer r, we deﬁne
U(m, r) = {x = (x0, x1, . . ., xr) | 0 ≤xi ≤m −1 for i = 1, . . ., r} = T r+1
for T = {0, 1, . . ., m −1}.
For every vector α = (α0, α1, . . ., αr) ∈T r+1, we deﬁne the hash function
hα : U(m, r) →T by
hα(x0, x1, . . ., xr) =
 r

i=0
αi · xi

mod m
for all (x0, x1, . . ., xr) ∈U(m, r). Let
Vec = {hα | α ∈T r+1}.
Lemma 3.3.13. Vec is a universal set of hash functions from the universe
U(m, r) to T .
Proof. Since |T r+1| = mr+1,
|Vec| = mr+1.
Let x = (x0, x1, . . ., xr) and y = (y0, y1, . . ., yr) be two arbitrary diﬀerent
elements from U(m, r). We have to show that the number of hash functions
hα from Vec with the property hα(x) = hα(y) is at most
mr = |Vec|
m .
Since the vectors x and y are diﬀerent, they diﬀer in at least one position.
To simplify the notation we assume without loss of generality that x0 ̸= y0.
The following holds:

116
3 Foiling the Adversary
hα(x) = hα(y)
for an α ∈T r+1 if and only if
r

i=0
αi · xi ≡
r

i=0
αi · yi (mod m),
which is equivalent to
α0 · (x0 −y0) ≡
r

i=1
αi · (yi −xi) (mod m).
(3.10)
Since m is a prime, the algebra (ZZm, ⊕mod m, ⊙mod m) is a ﬁeld. Hence, for
every element from ZZm −{0}, there exists a unique inverse with respect to
⊙mod p. Since x0 −y0 ̸= 0, there exists an inverse (x0 −y0)−1 for x0 −y0.
Multiplying both sides of the equality (3.10) by (x0 −y0)−1, one obtains
α0 ≡
 r

i=1
αi · (yi −xi)

· (x0 −y0)−1 (mod m).
In this way α0 is unambiguously determined by x, y and α1, α2, . . ., αr, and
|{hα ∈Vec | hα(x) = hα(y)}| ≤mr = mr+1
m
= |Vec|
m .
⊓⊔
We observe that Vec is an appropriate set of hash functions because of the
following.
(i) Every hash function hα from Vec is completely determined by α, and α
corresponds exactly to the number of keys in U(m, r). Hence, hα can be
eﬃciently generated at random.
(ii) The function hα is eﬃciently computable for every α, namely in linear
time with respect to the length of its argument.
Exercise 3.3.14.∗Our last example of a universal class of hash functions is
based on the fact that T = {0, 1, . . ., m −1} for a prime m. Consider m = pa
for a prime p and a positive integer a ≥2. For such an m, does there exist a
universal class of hash functions?
3.4 Online Algorithms
The computing problems considered until now are the classical tasks for which,
for any given input (question), one has to compute an output (answer). But in
practice one also has to deal with the following tasks. One obtains only part of

3.4 Online Algorithms
117
the input, and is forced to process this part. After one has solved it, one gets
another part of the input that also has to be immediately processed. The input
may be arbitrarily long. These kinds of tasks are called online problems,
and the algorithms solving online problems are called online algorithms.
The fundamental question posed in this framework is the following:
How good can an online algorithm (that does not know the future17)
be in comparison to an algorithm that knows the whole input (the
future) from the very beginning?
What the adjective “good” in this context means depends on the measure
used to estimate the quality of produced solutions. Hence, one has a similar
situation when dealing with optimization problems. We simply compare the
costs of solutions computed by an online algorithm with the costs of corre-
sponding optimal solutions.
In order to highlight the interest in online problems, we present two simple
examples. Consider a hospital, with surgeons, each with an ambulance. In the
case of a medical call, a surgeon has to drive to the patient’s ﬂat or place of
accident to help. After some time, some surgeons will be distributed in the city
and some may still be in the hospital. In the case of another call, the hospital
center has to decide which surgeon has to drive to the new patient.18 Clearly,
the center has to take this decision without knowledge of the future (sources
and the order of forthcoming calls). Though the center aims to make decisions
that optimize some cost measure. For example, one can try to minimize the
sum of the lengths of all distances driven by the ambulances, or the sum
of waiting times of the patients, or the maximal waiting time of a patient,
or a cost measure that appropriately combines several simple cost measures.
A similar type of tasks can be considered by a police station, or by a taxi
company, or by many other customer services. The most challenging problem
is determining whether or not one has a real chance of making reasonable
decisions with respect to the unknown future, i.e., whether or not there exists
an online strategy that produces decisions that are not too poor in comparison
to results produced by an optimal algorithm that knows the future (the whole
input).
Another class of frequently occurring online problems is the class of
scheduling problems. Typically, one considers a factory with a number of dif-
ferent machines. From time to time, requests come in that can be viewed as a
sequence of some tasks. The execution of every task requires the reservation of
a machine type for a certain period of time. The factory has to decide about
the scheduling of the machines, i.e., about assigning machines for some time
intervals to the tasks. Usually, one aims to minimize the makespan that is
the time of completion of all tasks. One can also be interested in maximizing
the average load of the machines or in minimizing the average waiting time
17the input parts that are still not available
18for instance, the surgeon who is closest to the new patient

118
3 Foiling the Adversary
of all customers. Tasks of this type appear not only in factories, but also in
the hardware management of a computer, especially of a parallel computer or
an interconnection network. The running processes continuously request some
hardware resources, such as the CPU, data storage, communication channels,
memory, etc. The computing system has to determine the scheduling of com-
puter hardware without any knowledge of future requests.
In what follows we deﬁne the competitive ratio of online algorithms in
order to get a reasonable measure of their quality.
Deﬁnition 3.4.15. Let U = (ΣI, ΣO, L, M, cost, goal) be an optimization
problem, that can be viewed as an online problem.19 An algorithm A is an
online algorithm for U if, for every input x = x1x2 . . . xn ∈L, the following
conditions are satisﬁed:
(i) For all i ∈{1, . . ., n}, x1x2 . . . xi is a feasible input.
(ii) A(x) ∈M(x), i.e., A always computes a feasible solution.
(iii) For all i ∈{1, . . ., n}, A(x1x2 . . . xi) is part20 of A(x), i.e., the decisions
made for the preﬁx x1x2 . . . xi of x cannot be changed any more.
For every input x ∈L, the competitive ratio compA(x) of A on x is
the number
compA(x) = max
	OptU(x)
costA(x), costA(x)
OptU(x)

,
where OptU(x) denotes the cost of an optimal solution for the instance x of
the problem U.
Let δ ≥1 be a real number. We say that A is a δ-competitive algorithm
for U if
compA(x) ≤δ
for all x ∈L.
Deﬁnition 3.4.16. Let δ > 1 be a real number. We say that an online problem
U is δ-hard if there does not exist any d-competitive online algorithm for U
with d < δ.
Note that, in contrast with approximation algorithms, we do not take care
on the complexity of online algorithms. We focus primarily on comparing
what is achievable without knowing the future and with full knowledge of the
future.
19For instance, an optimization problem can be viewed as an online problem,
when each preﬁx y of every input x can be viewed as a problem instance, and one
is required to provide a solution for y that has to remain unchanged as part of
the solution for the whole input x. We say “for instance” because sometimes it is
reasonable to view inputs as two dimensional objects, and then the notion of a preﬁx
is not unambiguous.
20To avoid a too complex, opaque formalism, we try not to formally specify what
the term “part” means for the formal output representation.

3.4 Online Algorithms
119
Example 3.4.17. Here, we introduce the so-called paging problem. Let us con-
sider a computer with fast, small direct access memory called Cache and
large, slow main memory called Main. The size of the Cache is bounded by
k pages of data, and the Main contains all the data. One has fast, direct ac-
cess only on data in the Cache. If one wants to access data that is not in the
Cache, the corresponding pages have ﬁrst to be loaded from Main into the
Cache. If the Cache is full and one needs to place new pages there, then ﬁrst
some old pages have to be removed from the Cache in order to create free
space. Removing data (pages) from the Cache can be performed by sending
the corresponding pages back to Main, or simply by erasing them. In what
follows, we consider direct access to the Cache for free and for a cost of 1 for
the exchange of two pages between the Cache and Main (or for erasing a page
in the Cache and moving a new page from Main to the Cache).
Let us consider an initial situation, where the ﬁrst k pages s1, s2, . . ., sk
reside in the Cache, and Main contains the remaining pages sk+1, sk+2, . . ., sn
for an n ≫k. An instance of the paging problem is a sequence i1, i2, . . ., im of
integers from {1, 2, . . ., n} that determines the requirement to read the pages
si1, si2, . . ., sim in the given order. In the case of the online version of the
problem, one at ﬁrst gets only i1, without any knowledge of the forthcoming
requests. If si1 is not in the Cache, then a page has to be removed from the
Cache, and the page si1 has to be loaded from Main to the Cache.
Hence, the online algorithm has to decide which page of the Cache has to
be removed without knowing which pages will be required later. This is an
ideal situation for the adversary, who can be very mean by simply requesting
exactly the removed page in the following step.
We aim to show that there is no d-competitive online algorithm for the
paging problem for any d < k, i.e., that the paging problem is k-hard for
caches of size k. To create a hard input for a given online algorithm, we use
the mean adversary.
Let A be an arbitrary online algorithm solving the paging problem for a
Cache of size k. The adversary starts with request k + 1. Since the Cache
contains the pages s1, s2, . . ., sk, A must exchange a page for sk+1. Assume
that A decides to remove the page sj1 for a j1 ∈{1, . . ., k}. Then, the next
request of the mean adversary is j1. Now A has to load the page sj1 back
to the Cache and remove a page sj2 for a j2 ∈{1, . . ., k + 1} −{j1}. Next,
the adversary requests the last removed page, sj2, and so on. In this way the
input
xA = k + 1, j1, j2, . . ., jk−1
is created. The input xA is hard for A, because A has to perform k exchange
operations between the Cache and Main during the processing of xA, i.e.,
cost(A(xA)) = k.
Now, we show that there is a solution for the input xA that forces only
one page exchange. Let i be a number from {1, 2, . . ., k} −{j1, j2, . . ., jk−1}.
The optimal strategy for xA is to exchange si for sk+1 in the Cache in the

120
3 Foiling the Adversary
ﬁrst step. After that, the Cache contains all the pages, sj1, sj2, . . ., sjk−1, that
are required in the next k −1 steps. Thus, we obtain
compA(xA) = cost(A(xA))
Opt(xA)
= k
1 = k
for every deterministic online algorithm A for the paging problem, and so the
paging problem is k-hard21 (Cache-size hard).
⊓⊔
Exercise 3.4.18. Let A be an arbitrary online algorithm for the paging prob-
lem. Find inﬁnitely many inputs yA of the paging problem with the property
compA(yA) ≥k.
Hence, the ﬁrst fundamental question related to online problems is the
question of whether or not there exists a possibility of solving them with a
reasonable competitive ratio. If this is possible, then one can start to look
for an eﬃcient online algorithm for the online problem considered. Exam-
ple 3.4.17 shows that there are online problems that cannot be reasonably
solved by deterministic online strategies. In such cases one can pose the ques-
tion of whether randomization can help. The following section is devoted to
the attempt of answering this question for a speciﬁc scheduling problem.
3.5 Randomized Online Algorithms
As observed in Section 3.4, exactly the online formulations of a computing task
provide the adversary the ability to construct hard problem instances for each
strategy. Similarly, as in the case of hashing, the randomization can be very
helpful. Though the adversary knows the designed randomized algorithm, it
does not know which random decision will be taken. In other words, if one has
suﬃciently many suitable deterministic strategies for every problem instance,
then, for any given input, it suﬃces to randomly choose a deterministic strat-
egy. This way one can get a reasonable expected competitive ratio for each
input. Then, there are no hard instances for the randomized algorithm, and so
the adversary does not have any chance of beating the randomized strategy.
In what follows, we ﬁrst deﬁne the concept of randomized online algo-
rithms22 and then document its power by investigating a special online prob-
lem.
21Note, that it cannot be worse, because k is the input length.
22Again we restrict ourselves to one-dimensional input representations of consid-
ered problems, because taking multidimensional inputs (which may be natural for
some problems) makes the formalism of the following deﬁnition too complex, and
hardly understandable. For problems with a natural two-dimensional input repre-
sentation, one can usually easily recognize which parts of the input can be considered
as meaningfull preﬁxes.

3.5 Randomized Online Algorithms
121
Deﬁnition 3.5.19. Let U = (ΣI, ΣO, L, M, cost, goal) be an online optimiza-
tion problem. A randomized algorithm A is a randomized online algorithm
for U if, for every input x1x2 . . . xn ∈L and every i ∈{1, . . ., n −1},
(i) the output of every run of A on x1x2 . . . xi is a feasible solution for the
instance x1x2 . . . xi of the problem U, and
(ii) for every input (C(x1 . . . xi), xi+1), where C(x1 . . . xi) is a feasible solution
for the instance x1 . . . xi of U (i.e., C(x1 . . . xi) ∈M(x1 . . . xi)), all runs
of A compute a feasible solution for the instance x1x2 . . . xi+1 of U and
all these feasible solutions involve C(x1 . . . xi) as a partial solution.
For every problem instance x, let SA,x be the set of all computations of A on
x, and let ProbA,x be the corresponding probability distribution on SA,x. Let
Zx be the random variable in (SA,x, ProbA,x) deﬁned by
Zx(C) = compC(x)
for each computation C ∈SA,x. We deﬁne the expected competitive ratio
of A on x as
Exp-CompA(x) = E[Zx] .
Let δ be a real number. We say, that the randomized algorithm A is a
E[δ]-competitive algorithm for U if
Exp-CompA(x) ≤δ
for every x ∈L.
Let h : IN →IR≥1 be a function. We say that A is an Exp (h)-
competitive algorithm for U if
Exp-CompA(x) ≤h(|x|)
for each x ∈L.
Our next aim is to show that there is an online problem such that apply-
ing randomization one can get a competitive ratio approaching 1 with input
length, but this approximation ratio is not achievable by any deterministic
online strategy.
We consider the following scheduling problem. There are m diﬀerent ma-
chine types, M1, M2, . . ., Mm, one piece of each type being available. Each fea-
sible job consists of m tasks, A1, A2, . . ., Am, and can be represented by a per-
mutation (i1, i2, . . ., im) of (1, 2, . . ., m). The meaning of job (i1, i2, . . ., im)
is as follows:
(i) The tasks must be performed in the order A1, A2, . . ., Am (one cannot
start with work on Ai+1 before work on Ai has ﬁnished).
(ii) For every j ∈{1, 2, . . ., m}, task Aj must be performed on machine Mij.
(iii) The execution of a task on its machine costs exactly one time unit.

122
3 Foiling the Adversary
If one has m pairwise diﬀerent machines and d tasks, we speak of the
so-called Unit (m, d) Job problem. For every positive integer d, we denote by
Unit (d) Job the problem
∞
#
m=1
Unit (m, d) Job.
A feasible solution of an instance of Unit (m, d) Job corresponds to a distri-
bution of the tasks to the machines in discrete time. More precisely, a machine
and a time unit are assigned to every task of every job in such a way that in
each time unit each machine is assigned to at most one task. The cost of a
feasible solution is the number of time units used in this solution in order to
completely execute all jobs.
In what follows, we consider the simplest Unit (2) Job version of this
scheduling problem. To present our considerations in a transparent way, we
develop a geometric representation of the problem instances. Let
α = (i1, . . ., im) and β = (j1, . . ., jm)
be an instance of Unit (m, 2) Job for a positive integer m. We consider an
m × m grid, Gridm(α, β), in which, for all integers k, l ∈{1, . . ., m}, the k-th
row is labeled jk and the l-th column is labeled il. The square (cell) (k, l) is
the intersection of the row ik with the column jl. The square (k, l) is called
an obstacle (or a collision) iﬀil = jk, i.e., iﬀthe same machine is asked
to perform the il-th task of δ and the jk-th task of β. These squares are de-
picted in Figure 3.4(a) as hatched squares. Figure 3.4(a) shows Grid9(α, β)
for α = (1, 2, 3, 4, 5, 6, 7, 8, 9) and β = (1, 3, 2, 6, 5, 4, 8, 7, 9). The motivation
to introduce the term obstacle (collision) is as follows. Assume that the exe-
cutions of the ﬁrst l −1 tasks of job α and of the ﬁrst k −1 tasks of job β
have ﬁnished. Now, if il ̸= jk, one can continue by executing the l-th task of
α on the il-th machine Mil and the k-th task of β on the jk-th machine Mjk
in parallel.
But, if
il = jk,
then both tasks require the same machine Mil. Therefore, one of these tasks
must be postponed until the other one is ﬁnished on Mil.
We assign the graph Gm(α, β) = (V, E) to any grid Gridm(α, β) as follows:
(i) V consists of the vertices of the grid Gridm(α, β), and
(ii) E contains
•
all vertical and all horizontal edges of Gridm(α, β), and
•
all diagonal edges of the grid squares between the upperleft corner
and the lower-right corner of the square for the squares that are not
obstacles.

3.5 Randomized Online Algorithms
123
1
1
1
1
2
2
2
2
3
3
3
3
4
4
4
4
5
5
5
5
6
6
6
6
7
7
7
7
8
8
8
8
9
9
9
9
(a)
(b)
Fig. 3.4.
Figure 3.5(b) shows the graph G9(α, β) for the Grid9(α, β). We observe
that every feasible solution for an instance (α, β) corresponds to a path in
Gm(α, β) that leads from the upper left corner of the grid to the lower right
corner of the grid, and uses only edges going to the right or down. Each edge
of this path corresponds to one time unit. If the edge is diagonal, it means
that both jobs are executed in parallel, and so none of them is delayed. A
vertical edge corresponds to the situation where the ﬁrst job is not executed
(i.e., the ﬁrst job is delayed), and so only the second job is performed in this
time unit. In this case we say that the ﬁrst job has got a delay. Analogously,
a horizontal edge corresponds to the situation in which only the ﬁrst job is
executed and the second one is delayed.
Obviously, an optimal solution corresponds to the shortest path from the
upper left corner to the lower right corner of the graph. The bold edges in
Figure 3.5(a) and Figure 3.5(b) build a path that represents an optimal solu-
tion for the problem instance considered. In this solution there are 6 delays,
that are uniformly distributed over both jobs. Hence, the cost of this optimal
solution is
m + 6/2 = 9 + 3 = 12.
The geometric (graphic) representation of problem instances teaches us
that the optimization problem Unit (2) Job is eﬃciently solvable by computing
the shortest path between the two corners of the graph Gm(α, β). But we are
interested in the online version of this problem. Here, one obtains only the ﬁrst
elements of the permutations (the ﬁrst tasks of the jobs) and the next element
will not be known before all its previous tasks in this job have been performed.
To analyze this online problem, we introduce the following terminology.

124
3 Foiling the Adversary
Let (α, β) be an instance of Unit (m, 2) Job for a positive integer m. Let
S be a path23 in Gm(α, β). The number delα(S) of the vertical edges in S
is called the delay of the ﬁrst job α in S and the number delβ(S) of the
horizontal edges in S is called the delay of the second job β in S. The
delay of S, for short delay (S), is the maximum of delα(S) and delβ(S). If
S corresponds to a ﬁnite feasible solution for (α, β), then clearly24
delay (S) = delα(S) = delβ(S) ,
and so
cost(S) = m + delay (S) = m + delα(S) + delβ(S)
2
.
(3.11)
Let OptJob(α, β) denote the cost of the optimal solutions for the problem
instance (α, β).
In what follows, we show that using deterministic online algorithms one
cannot guarantee solutions with costs arbitrarily close to the optimal cost. We
start with a simple observation.
Observation 3.5.20. Let m be a positive integer. Every instance (α, β) of
Unit (m, 2) Job contains exactly m conﬂicts, and each column and each row
of the grid Gridm(α, β) contains exactly one conﬂict.
Proof. Every integer k ∈{1, 2, . . ., m} appears exactly once in each of the
permutations α and β.
Lemma 3.5.21. Let m be a positive integer divisible by 8 (m mod 8 = 0).
For every online algorithm A for the Unit (m, 2) Job problem, there exists an
instance I = ((1, 2, . . ., m), β) such that
cost(A(I)) ≥m + m
8 .
Proof. Let A be an arbitrary online algorithm for the Unit (2) Job problem.
We aim to prove Lemma 3.5.21 by showing that the adversary can place the
obstacles (i.e., can choose β) in such a way that at least half the edges reached
before column
 m
2 + 1

or row
 m
2 + 1

are not diagonal edges. This would
mean that
del(1,2, ...,m)(A(I)) + delβ(A(I)) ≥m
4 ,
and so (from (3.11))
delay (A(I)) ≥m
8 .
The permutation β starts with 1 in order to place a conﬂict (an obstacle)
in the square (1, 1). Hence, A cannot start with a diagonal edge. After A
has used a diagonal edge, the path has always reached, for the ﬁrst time,
23a schedule for the input (α, β)
24since S leads from the upper left corner to the lower right corner of a square

3.5 Randomized Online Algorithms
125
a new row and a new column. The adversary places the next obstacle on
the square at the intersection of this column and this row. The adversary
can work in this way until half the jobs have been executed, because it can
use elements 1, 2, . . ., m/2 for β for its purpose. If A makes vertical steps,25
then the adversary uses elements m, m −1, m −2, . . ., m/2 + 1 for β at the
corresponding positions.
⊓⊔
The following lemma shows that every instance of Unit (m, 2) Job can
be solved in m + √m time units, and so that the Unit (2) Job problem is

1 + 1
8 −ε

-hard for any ε > 0.
Lemma 3.5.22. Let m be a positive integer. For every instance I of the
Unit (m, 2) Job problem,
OptJob(I) ≤m +
√m

.
Proof. To simplify the proof, we show it for m = k2 only. Let I be an arbi-
trary instance of Unit (m, 2) Job. We visualize the proof idea by our graphic
representation. For every i = 0, 1, . . ., √m we denote by Di the i-th diagonal
of the grid Gridm(I) that goes from position26 (0, i) to position (m −i, m),
and we denote by D−i the diagonal from position (i, 0) to position (m, m−i),
as depicted in Figure 3.5.
√m
√m
√m
√m
(0, 0)
D−j
j
j
(m, m)
Fig. 3.5.
For every i ∈{−√m, −√m + 1, . . ., 0, 1, . . ., √m} we consider the follow-
ing deterministic strategy, A(Di), to assign the machines. The strategy A(Di)
ﬁrst uses i (horizontal27/vertical28) grid edges in order to reach the starting
position of the diagonal Di. Then A(Di) runs via the diagonal edges of the
diagonal Di. If this path hits an obstacle, then A(Di) goes around it by taking
25independently of the content of β
26The upper left corner vertex is at position (0, 0).
27if i is nonnegative
28if i is negative

126
3 Foiling the Adversary
one horizontal and one vertical edge. When A(Di) has reached the endpoint
of the diagonal Di, then it runs via the i (vertical/horizontal) grid edges to
the corner (m, m).
The cost of the solution achieved by this strategy is exactly
m + i + the number of obstacles on Di,
because the length29 of Di is exactly m −i, and A(Di) needs i steps to reach
the starting point of Di and i steps to reach the corner (m, m) from the end
of the diagonal. Hence,
i + the number of obstacles on Di
is the delay of the solution computed by A(Di).
Since the number of all obstacles is exactly m (Observation 3.5.20), the
sum of all delays over all 2 · √m + 1 solutions computed by the diagonal
strategies is at most
m +
√m

i=−√m
|i| = m + 2 ·
√m

i=1
i = m + √m · (√m + 1).
Because we take 2 · √m + 1 solutions into account, the average delay over all
solutions is
m + √m · (√m + 1)
2 · √m + 1
≤√m + 1
2.
Thus, there exists an i ∈{−√m, . . ., √m} such that the solution computed
by the strategy A(Di) has at most √m delays, and so the cost of this solution
is at most m + √m.
⊓⊔
Lemma 3.5.21 and 3.5.22 together imply the following theorem.
Theorem 3.5.23. For every real ε > 0, the Unit (2) Job problem is
 9
8 −ε

-
hard.
Proof. From Lemma 3.5.21 we have that, for each deterministic online algo-
rithm A, there exists an input instance I such that
cost(A(I)) ≥9
8 · m.
From Lemma 3.5.22, we have
OptJob(I) ≤m + √m.
Hence,
compA(I) = cost(A(I))
OptJob(I) ≤
9
8 · m
m + ⌈√m⌉≤9
8 ·
1
1 +
1
√m
.
⊓⊔
29the number of diagonal edges

3.5 Randomized Online Algorithms
127
Exercise 3.5.24. Let k be a positive integer, Show that, for every m =
k+1
2

,
there exists an instance I of Unit (m, 2) Job such that
(i)
OptJob(I) ≥m + & m
2 −1
2, and
(ii)∗OptJob(I) ≥m + √m.
Though the Unit (2) Job problem can be solved in a simple and eﬃcient
way, it cannot be solved optimally, or almost optimally, by any deterministic
online algorithm. This claim is independent of the complexity of online algo-
rithms. But the proof of Lemma 3.5.22 already provides an idea as to how we
can expect to approach optimal costs. Let us simply consider a randomized
online algorithm as a uniform probability distribution over the 2 · √m + 1
diagonal strategies A(Di).
Algorithm DIAG
Input: An instance I of Unit (m, 2) Job for a positive integer m.
Step 1: Choose uniformly an i ∈{−⌈√m⌉, −⌈√m⌉+ 1, . . ., ⌈√m⌉}.
Step 2: Compute the solution for I by the deterministic online strategy A(Di).
Theorem 3.5.25. DIAG is a randomized online algorithm for the Unit (2) Job
problem with
Exp-CompDIAG(I) ≤1 +
1
√m +
1
2 · m
for every instance I of Unit (m, 2) Job.
Proof. In the proof of Lemma 3.5.22 we have shown that, for any instance I
of Unit (m, 2) Job, the expected30 delay over all 2·√m+1 diagonal strategies
considered is at most
⌈√m⌉+ 1
2.
A consequence is that the expected cost of a solution over all 2 · √m + 1
diagonal strategies is at most
m + ⌈√m⌉+ 1
2.
Since OptJob(I) ≥m for all instances of Unit (m, 2) Job, we obtain
Exp-CompDIAG(I) = expected cost
OptJob(I)
≤m + √m + 1
2
m
= 1 +
1
√m +
1
2 · m.
⊓⊔
30A very formal proof of this fact would start by deﬁning a random variable X
that counts the number of obstacles in the randomly chosen diagonals, and continue
by applying ⌈√m⌉
i=−⌈√m⌉X(Di) ≤m from Observation 3.5.20

128
3 Foiling the Adversary
Exercise 3.5.26. Consider the Unit (3) Job problem. Estimate the hardness
of this problem for deterministic online algorithms and generalize the ran-
domized algorithm DIAG for instances of the Unit (3) Job problem.
3.6 Summary
In this chapter we have shown that a random choice of an algorithm from
a suitable class of deterministic algorithms can lead to successful processing
of problems for which no deterministic algorithm alone is able to solve the
problem eﬃciently or with a required solution quality. The method of avoiding
the worst-case inputs is usually called the method of foiling the adversary,
because the algorithm design can be viewed as a game between an algorithm
designer and her/his adversary, who tries to construct hard input instances
for every algorithm designed. The art of successfully applying this method lies
in searching for a suitable set of deterministic strategies. The term “suitable”
means that, for every problem instance I, most of the algorithms of this
class behave well31 on I despite the fact that none of them is able to behave
reasonably on all feasible inputs. If one knows that this is possible, then one
tries to ﬁnd a class of such algorithms, with a cardinality that is as small as
possible in order to guarantee an eﬃcient execution of the random choice from
this class.
In the case of hashing, we call such classes of hash functions universal.
We have seen that one can construct universal sets of hash functions, whose
cardinality is acceptable for applications.
Online algorithms are algorithms that have to process a given request with-
out having any information of future requests. Without knowing the future,
it is very hard to compete against algorithms that have complete informa-
tion about future requests, i.e., about the whole input. In the case of online
problems, the adversary is in a very good position because it can construct
hard instances by waiting for the decision of the online algorithm and then
determining the next part of the input. By considering the Unit-Job problem
we have shown that there are hard32 problem instances for every deterministic
online algorithm, but there is a randomized online algorithm with very good
behavior for every feasible input.
A detailed study of hashing strategies is contained in most textbooks on al-
gorithms and data structures. Here, we recommend the books of Cormen, Leis-
erson, Rivest and Stein [CLRS01], Ottmann and Widmayer [OW02], Sch¨oning
[Sch01], Gonnet, [Gon84], and Knuth [Knu73]. The concept of universal hash-
ing has been proposed by Carter and Wegman [CW79]. Further improvements
31compute eﬃciently the correct result, or whatever one can expect from an al-
gorithm
32in the sense that the algorithm is not able to compute a solution whose cost is
very close to the optimal cost

3.6 Summary
129
of this concept are presented by Fredman, Koml´os, and Szemer´edi [FKS84]
and Dietzfelbinger, Karlin, Mehlhorn, Meyer auf der Heide, Rohnert, and Tar-
jan [DKM+94].
The most comprehensive sources on online algorithms are the books of Fiat
and Woeginger [FW98] and Borodin and El-Yaniv [BEY98]. The randomized
online algorithm presented in Section 3.5 is a simpliﬁed version of an algorithm
for job scheduling by Hromkoviˇc, Steinh¨ofel, and Widmayer [HSW01].

This page intentionally left blank

4
Fingerprinting
A dwarf will be a dwarf
even if he stands on the top of a mountain,
a giant will stay a giant
even standing at the bottom of the deepest valley.
Democritus
4.1 Objectives
This chapter is devoted to applications of the ﬁngerprinting method. We in-
troduced this method in Section 2.6 as an approach for solving equivalence
problems. The basic idea is to compare two (full) representations of some ob-
jects by the ﬁngerprints of these representations. An important point is that
one has several diﬀerent ways for making ﬁngerprints. For instance, in the
randomized protocol R in Section 1.2, computing modulo p for each prime
p < n2 is a way of getting ﬁngerprints (i.e., a kind of ﬁngerprinting). The
method of creating ﬁngerprints is chosen at random from a ﬁnite set of possi-
bilities. The main idea behind this is that, for any two diﬀerent objects, most
ways of creating ﬁngerprints save the diﬀerences between the two objects.
Thus, in general, we pose the following two requirements for ﬁngerprints.
(i) The ﬁngerprints have to be simple and short in order to assure the pos-
sibility of being able to compare them eﬃciently. To achieve this, the
ﬁngerprints may be not only compressed representations of given objects,
but even incomplete representations of them.
(ii) Despite its bounded size, the ﬁngerprint of an object has to contain as
much essential information about the object as possible.
Hence, the basis of any application of the ﬁngerprinting method is a set
M of functions, each of them considered as a way of ﬁngerprinting. More
precisely, each element of M is a mapping from the given, full representation
of the considered objects to their ﬁngerprints. Our aim is to ﬁnd a set M,
such that for any two diﬀerent objects O1 and O2 there are suﬃciently many
mappings f with f(O1) ̸= f(O2). Because of this, one considers ﬁngerprinting
as a special case of the method of abundance of witnesses. The set M can be
viewed as the set of witness candidates for proving O1 ̸≡O2, and a mapping
h ∈M is a witness of (O1) ̸≡(O2) if h(O1) ̸= h(O2).
The art of applying the method of ﬁngerprinting lies in a suitable choice of
M. On the one hand, one aims to have ﬁngerprints as representative as possi-

132
4 Fingerprinting
ble, and so assure a large number of witnesses among the witness candidates.
On the other hand, we wish to have ﬁngerprints as short as possible in order
to guarantee their eﬃcient comparison. Obviously, these two aims contradict
each other. Small ﬁngerprints also mean a small set of ﬁngerprints, and so the
situation where several diﬀerent objects are mapped to the same ﬁngerprint
may occur more often (Figure 4.1).
the set of objects
the set of ﬁngerprints
h ∈M
Fig. 4.1.
Hence, the crucial point in applying ﬁngerprints lies in searching for a
reasonable compromise between the eﬃciency of the ﬁngerprints comparison
(the size of ﬁngerprints) and the abundance of witnesses in M. The objective of
this chapter is to present searching for a suitable set M for some fundamental
equivalence problems in a transparent way, and to provide the ﬁrst experience
in applying the ﬁngerprinting method.
This chapter is organized as follows. In Section 4.2 we ﬁrst generalize the
concept of comparing two long strings (from Section 1.2) to decide whether a
given long string is in a set of strings, and then to decide whether or not two
string sets are disjoint. The second important goal of Section 4.2 is to show
how to amplify the success probability by an improved choice of M, i.e., to
show how to perform ampliﬁcation in a way diﬀerent from the execution of
independent runs of a randomized algorithm on the same input (Section 2.6).
The idea is to signiﬁcantly decrease the error probability by an acceptable
increase in the size of ﬁngerprints. In Section 4.3 we apply this kind of ﬁnger-
printing once again in order to design an eﬃcient randomized algorithm for
the so-called substring problem.
In Section 4.4 we show how to eﬃciently verify the equality A · B = C
for three (n × n) matrices, A, B, and C, in time O

n2
by the ﬁngerprint-
ing method. This application of ﬁngerprinting is extended to a randomized
polynomial-time algorithm for testing the equivalence of two polynomials.

4.2 Communication Protocols
133
Note, that there is no deterministic polynomial-time algorithm known for this
equivalence problem.
4.2 Communication Protocols
In our initial example presenting the power of randomization in Section 1.2,
we considered two computers RI and RII that were asked to verify whether
the contents of their memories are identical. These contents were considered
binary strings of length n, for an n ∈IN. Next, we will consider some gener-
alizations of this equivalence problem.
First, assume that RI has a string x ∈{0, 1}n and that RII has a set
U = {u1, u2, . . ., uk} of strings ui ∈{0, 1}n for i = 1, . . ., k. The computer
RII does not know any bit of the string x, and RI does not have any knowledge
of U. The computers have to ﬁnd out whether or not x ∈U. One can prove
that deterministically this is not possible to do more eﬃciently than by sending
the whole x from RI to RII, which ﬁnally checks whether x ∈U or x /∈U.
Designing a randomized protocol for this communication task, we show that
the same idea that is used for the comparison of two strings can again be
applied. The question is, for which cardinalities of U does this approach still
provide an eﬃcient communication protocol.
We propose the following randomized protocol PSet that uses the set
M = {hp | p ∈PRIM

n2
}
of ways of ﬁngerprinting.
PSet
Initial situation: RI has a string x ∈{0, 1}n. RII has k diﬀerent strings
u1, u2, . . ., uk ∈{0, 1}n. Let U = {u1, u2, . . ., uk}. The two computers
RI and RII have to decide whether x ∈U or x /∈U.
Phase 1: RI uniformly chooses a prime p ∈PRIM

n2
at random.
Phase 2: RI computes the number
s = Number(x) mod p
and sends s and p to RII.
Phase 3: After receiving s and p, the computer RII computes the numbers
qi = Number(ui) mod p
for i = 1, . . ., k.
If s ∈{q1, q2, . . ., qk}, then RII outputs “s ∈U”.
If s /∈{q1, q2, . . ., qk}, then RII “s /∈U”.

134
4 Fingerprinting
Clearly, the communication complexity of the protocol PSet is 4·⌈log2 n⌉, i.e.,
the same as that of protocol P from Section 1.2.
In what follows, we analyze the error probability of PSet. As usual, we
distinguish two cases.
(i) Let x ∈U.
Then there exists a j ∈{1, . . ., k} such that x = uj. Similarly, as for the
protocol P in Section 1.2, we have
Number(x) = Number(uj) (mod m)
for all m ∈IN −{0}, and so PSet outputs “x ∈U” with certainty, i.e., the
error probability is 0 in this case.
(ii) Let x /∈U.
Let SPSet,x = {Pr | r ∈PRIM

n2
} be the set of all Prim

n2
runs of
PSet on x. Let Ai be the event1 that
Number(x) mod r = Number(ui) mod r
for each i ∈{1, . . ., k}. Obviously,
A =
k#
i=1
Ai
is the event that PSet outputs the wrong answer “x ∈U”. Hence, Prob(A)
is the error probability of PSet on x.
Analyzing our exemplary protocol in Section 1.2, we have shown that
Prob(Ai) ≤
n −1
Prim (n2) ≤2 · ln n
n
(4.1)
for every integer i ∈{1, . . ., k}. In this way, we obtain
ErrorPSet(x, U) = Prob(A)
= Prob
 k#
i=1
Ai

≤
k

i=1
Prob(Ai)
≤
(4.1)
k

i=1
2 · ln n
n
= k · 2 · ln n
n
.
(4.2)
1Thus, Ai = {Pm | m ∈PRIM 
n2
and s = qi in the run Pm}.

4.2 Communication Protocols
135
A direct consequence is that
ErrorPSet(x, U) ≤1
2
for k ≤
n
4·ln n.
Hence, PSet is a one-sided-error Monte Carlo protocol for deciding the
membership of x to U for k ≤n/(4 · ln n).
Exercise 4.2.1. Apply the ampliﬁcation method in order to enable a random-
ized test of x ∈U for larger sets U. Estimate the maximal possible cardinality
of U for which the achieved error probability still approaches 0 with growing
n when the communication complexity is
(i) in O(log n · log log n),
(ii) in O

(log n)d
for any constant d ∈IN,
(iii) polylogarithmic.
Now, we consider another generalization of this communication task, where
one has to decide whether or not two sets of strings are disjoint. This task is
called the disjointness problem in what follows. The following randomized
protocol again uses M = {hp | p ∈PRIM

n2
} as the set of ﬁngerprinting
ways.
Protocol PDisj
Initial Situation: Computer RI has a set V = {v1, v2, . . ., vl} ⊆{0, 1}n and
computer RII has a set U = {u1, u2, . . ., uk} ⊆{0, 1}n for some positive
integers l and k. Neither computer knows the data of the other. The
computers RI and RII have to decide whether V ∩U = ∅or V ∩U ̸= ∅.
Phase 1: RI chooses a prime p ∈PRIM

n2
at random.
Phase 2: RI computes the numbers
si = Number(vi) mod p
for 1, 2, . . ., l, and sends
p, s1, s2, . . ., sl
to RII.
Phase 3: After receiving p, s1, s2, . . ., sl, the computer RII computes the num-
bers
qm = Number(um) mod p
for all m = 1, 2, . . ., k.
If {s1, s2, . . ., sl} ∩{q1, q2, . . ., qk} ̸= ∅, RII outputs “U ∩V ̸= ∅”.
If {s1, s2, . . ., sl} ∩{q1, q2, . . ., qk} = ∅, RII outputs “U ∩V = ∅”.

136
4 Fingerprinting
Clearly, the communication complexity of PDisj is
(l + 1) · 2 · ⌈log2 n⌉.
If k < l, then one can exchange the roles of RI and RII, and so remain within
the communication complexity of (k + 1) · 2 · ⌈log2 n⌉bits.
In what follows, we investigate the error probability of the protocol PDisj.
Lemma 4.2.2. PDisj is a 1MC∗protocol for the disjointness problem of two
sets U, V ⊆{0, 1}n for
|U| · |V | = o(n/ ln n) .
Proof. In the analysis of the error probability of PDisj we handle separately
the two possibilities U ∩V ̸= ∅and U ∩V = ∅.
(i) Let U ∩V ̸= ∅.
Then there exist i ∈{1, . . ., l} and j ∈{1, . . ., k} such that vi = uj.
Hence, si = qj for all primes p, and so PDisj outputs “U ∩V ̸= ∅” with
certainty.
(ii) Let U ∩V = ∅.
Let, for i ∈{1, . . ., l}, Bi be the event that si ∈{q1, q2, . . ., qk} through
the fact vi /∈{u1, . . ., uk}. In (4.2) we have calculated
Prob(Bi) ≤k · 2 · ln n
n
(4.3)
for all i ∈{1, . . ., l}. Clearly,
B =
l#
i=1
Bi
is the event that PDisj provides the wrong answer “U ∩V ̸= ∅”. Hence,
ErrorPDisj(V, U) = Prob(B)
= Prob
 l#
i=1
Bi

≤
l

i=1
Prob(Bi)
≤
(4.3)
l

i=1
k · 2 · ln n
n
= l · k · 2 · ln n
n
.
Thus, the error probability tends to 0 with growing n, if
l · k = o(n/ ln n) .

4.2 Communication Protocols
137
Hence, PDisj is a 1MC∗protocol for the disjointness problem for l · k =
o(n/ ln n).
⊓⊔
Exercise 4.2.3. Let U, V ⊆{0, 1}n and let |U| ∈O

n3
, and |V | ∈O

n2
.
How many independent runs of PDisj are necessary (i.e., how large is the
necessary communication complexity) to successfully decide the disjointness
problem for U and V with an error probability tending to 0 with growing n?
What happens when U, V ∈Θ(2
√n)?
Exercise 4.2.4. The disjointness problem for an instance (U, V ) can be solved
by a deterministic protocol by sending the complete data of one computer to
the other. In this way, the communication complexity is n·|U| or n·|V |, but it
is never necessary to exchange more than 2n bits. Explain why 2n bits always
suﬃce. Do there exist cardinalities of U and V such that the randomized
protocol PDisj is not better than an optimal deterministic protocol?
Exercise 4.2.5. Transform the protocol PDisj to a Las Vegas protocol. How
large is its expected communication complexity?
So far, we have always ampliﬁed the success probability2 by executing
independent runs on the same input. Analyzing the protocol R for the equality
problem in Section 1.2 we have recognized that for every input (x, y) with
x ̸= y, there are at most n −1 bad3 primes. Following the proof of this fact
we see that this upper bound on the number of bad primes does not depend
on considering PRIM

n2
as a basis for choosing primes. For instance, this
means that when exchanging PRIM

n2
for PRIM

n3
it remains true that
there are at most n −1 bad primes in PRIM

n3
, but the number of good
primes has increased substantially. And this is very good news, because the
consequence is an essential increase in the success probability. Thus, let us
consider the following protocols d-R for all integers d ≥2.
Protocol d-R
Initial Situation: Computer RI has an x ∈{0, 1}n and computer RII has a
y ∈{0, 1}n.
Phase 1: RI uniformly chooses a prime p from the set
PRIM

nd
= {p | p ≤nd is a prime}
at random.
Phase 2: RI computes the number
s = Number(x) mod p
and sends s and p to RII.
2It does not matter whether one views the success as computing the correct
output or as an eﬃcient computation of the correct output.
3Remember that a bad prime is a prime that is no witness of “x ̸= y”.

138
4 Fingerprinting
Phase 3: After receiving s and p, RII computes the number
q = Number(y) mod p.
If q ̸= s, then RII outputs “x ̸= y”.
If q = s, then RII outputs “x = y”.
Since s and p are smaller than nd, the communication complexity of d-R is
bounded by
2 · ⌈log2 nd⌉≤2 · d · ⌈log2 n⌉.
Obviously, for all inputs (x, y) with x = y the error probability is (as
before) equal to 0.
For inputs (x, y) with x ̸= y, the error probability is equal to
the number of bad primes for (x, y) in PRIM

nd
|PRIM (nd) |
,
i.e., at most
n −1
Prim (nd) ≤
n
nd/ ln nd = d · ln n
nd−1
for all suﬃciently large n.
Observe that the result of our analysis is very appreciative because the
communication complexity grows only linearly in d, but the error probability
tends to 0 with exponential speed with respect to d.
Exercise 4.2.6. Apply this success ampliﬁcation method to the protocols
PSet and PDisj, and estimate the error probability as a function of n, d, and
the cardinalities of U and V .
Exercise 4.2.7. Compare the ampliﬁcation method of executing independent
runs with the method of increasing the size of the set of witness candidates
(the set of ﬁngerprinting methods). How many communication bits are needed
by each of these methods in order to get an error probability tending to 0 with
growing n? By what size is the error probability reducible by these methods
when an upper bound c(n) on the number of communication bits is given?
Exercise 4.2.8. Consider a network of l computers R1, R2, . . ., Rl in which
each computer is directly connected via a communication link to each other.
Let k be a positive integer. Assume that each Ri possesses a set Si ⊆{0, 1}n,
where |Si| ≤k for all i ∈{1, 2, . . ., l}. Design and analyze a randomized
communication protocol for deciding whether or not 'l
i=1 Si is empty. The
communication complexity is measured as the number of bits communicated
via all links between the l computers.
Exercise 4.2.9. Let us consider the following communication task. RI has
got a sequence x1, x2, . . ., xn of strings, xi ∈{0, 1}n for i = 1, 2, . . ., n. RII

4.3 The Substring Problem
139
has got a sequence y1, y2, . . ., yn of strings, yi ∈{0, 1}n for i = 1, 2, . . ., n. The
question is whether there exists a j ∈{1, 2, . . ., n} such that xj = yj. One can
prove that any deterministic protocol solving this task has a communication
complexity of at least n2. Design a Las Vegas protocol that solves this problem
with expected communication complexity in O(n · log n).
4.3 The Substring Problem
An important class of algorithmic problems are the tasks of pattern recogni-
tion that frequently occur in text processing and graphics. Typical tasks are
the recognition of patterns in a complex scenario or the classiﬁcation of objects
with respect to a set of given patterns. Here we consider the simplest basic
task of this kind – the substring problem. Given a pattern x = x1x2 . . . xn and
a text y = y1y2 . . . ym as strings over an alphabet Σ (xi ∈Σ for i = 1, . . ., n
and yj ∈Σ for j = 1, . . ., m), the task is to decide whether or not x is a
substring4 of y. Moreover, if x is a substring of y, then one has to compute
the smallest index r such that
x1x2 . . .xn = yr . . .yr+n−1.
This task is of interest not only in text processing, but occurs frequently as
one of the basic tasks of molecular biology.
In what follows, we simplify the matter by choosing Σ = {0, 1}. Let, for
every k ∈{1, . . ., m −1} and every r ∈{1, . . ., m −k + 1},
y(r, k) = yryr+1 . . .yr+k−1
be the substring of y of length k that begins at the r-th bit position of y. For
given x = x1x2 . . .xn and y = y1y2 . . .ym, a naive deterministic algorithm
compares x with all substrings y(r, n) for r = 1, 2, . . ., m −n + 1 in order
to ﬁnd x in y. This naive algorithm executes O(n + m) operations over the
symbols of Σ = {0, 1}. Note that there exist faster deterministic algorithms
that run in the optimal time O(n + m) = O(m). In what follows we present a
simple Las Vegas algorithm for this task. Let f : IN × IN →IN be a mapping.
Algorithm STRING (f)
Input: Two strings x = x1x2 . . .xn and y = y1y2 . . .ym over {0, 1}, n ≤m.
Step 1: Choose uniformly a prime p from PRIM (f(n, m)) at random.
Step 2: Compute
Fingerp(x) := Number(x) mod p.
4Remember that a string x is called a substring (or a subword) of a string y, if
y = uxv for some strings u and v.

140
4 Fingerprinting
Step 3: Compute, sequentially,
Fingerp(y(r, n)) := Number(y, (r, n)) mod p
for all r ∈{1, 2, . . ., m −n + 1}, and check whether
Fingerp(y(r, n)) = Fingerp(x) .
For every j ∈{1, 2, . . ., m−n+1} such that Fingerp(y(j, n)) = Fingerp(x),
compare y(j, n) and x.
If y(j, n) = x, then halt and output “j”.
Else continue computing Fingerp(y(j + 1, n)).
If no r with y(r, n) = x has been found, output “∅”.
Clearly, STRING (f) is a Las Vegas algorithm, because STRING (f) al-
ways computes the correct output.
In what follows, we analyze the expected time complexity of STRING (f).
Here, we count one time unit for the comparison of two ﬁngerprints and n time
units for the bit-by-bit comparison of x and y(r, n). Hence, the time complexity
is measured in the number of operations in ZZp, or in bit comparisons.
Clearly, one can compute Fingerp(x) and Fingerp(y(1, n)) in time O(|x|) =
O(n). We show now that one can compute all ﬁngerprints
Fingerp(y(r, n)) for r = 1, . . ., m −n + 1
in an overall time of O(m). This is possible because
Number(y(r + 1, n)) = 2 ·

Number(y(r, n)) −2n−1 · yr

+ yr+n,
and so one can compute Fingerp(y(r + 1, n)) from Fingerp(y(r, n)) as follows:
Fingerp(y(r+1, n)) =

2 ·

Fingerp(y(r, n)) −(2n−1 ·yr) mod p

+yr+n

mod p.
Hence, O(1) operations over the ﬁeld ZZp are suﬃcient for computing the
ﬁngerprint Fingerp(y(r + 1, n)) from the ﬁngerprint Fingerp(y(r, n)).
Let (x, y) be an input where x is not a substring of y. Next we give an
upper bound on the expected time complexity of STRING (f) on (x, y). Let
(PRIM (f(n, m)) , Prob) be the corresponding probability space, where Prob
is the uniform probability distribution over all primes not greater that f(n, m).
Let, for r = {1, . . ., m −n + 1},
Ar be the event that Fingerp(x) = Fingerp(y(r, n)) .
In the same way as for the protocol in Section 1.2, one can show that
Prob(Ar) ≤
n −1
Prim (f(n, m)) ≤n · ln(f(n, m))
f(n, m)
.
Then the expected time complexity of STRING (f) is

4.4 Veriﬁcation of Matrix Multiplication
141
Exp-TimeSTRING(f)((x, y)) = O(m) +
m−n+1

r=1
(1 + Prob(Ar) · n)
{The complexity O(m) is suﬃcient to
compute Fingerp(x) in step 2 and, as
shown above, the complexity O(m) is
also suﬃcient to compute all ﬁnger-
prints Fingerp(y(r, n)).}
≤O(m) +
m−n+1

r=1
n · ln(f(n, m))
f(n, m)
· n
≤O(m) + m · n2 · ln(f(n, m))
f(n, m)
.
Choosing f(n, m) = n2m · ln(n2m), one obtains
Exp-TimeSTRING(n2m·ln(n2m))(x, y) ∈O(m) .
We close our analysis by observing that the expected time complexity of
STRING (f) on inputs (x, uxv) cannot be larger than the expected complexity
on inputs in which the pattern does not occur in the text.
Exercise 4.3.10. Let (x, y) be an input with y(j, n) = x, and let j be the
smallest number from {1, 2, . . ., m −n + 1} with this property. Give a de-
tailed analysis of the expected time complexity of STRING

n2m · ln(n2m)

on (x, y).
4.4 Veriﬁcation of Matrix Multiplication
The multiplication of two matrices over a ﬁeld IF is one of the most basic
mathematical tasks.5 The execution of the school algorithm for matrix multi-
plication needs O

n3
arithmetical operations over IF. Based on the “divide
and conquer” design method, Strassen developed an O

nlog2 7
-algorithm for
matrix multiplication. A further development of this design idea provided a
sequence of several improvements, and the currently best known algorithm
for matrix multiplication runs in time O

n2.376
.
The task considered here is a little bit simpler than matrix multiplication.
Given three (n × n)-matrices A, B, and C over a ﬁeld IF, one has to decide
whether
A · B = C
5It is well known that the complexity of matrix multiplication is asymptotically
the same as the complexity of computing an inverse matrix, and that it is strongly
related the complexity of solving a system of linear equations.

142
4 Fingerprinting
i.e., whether A · B is the same matrix as C. A naive deterministic approach
to solve this equivalence problem is based on computing A · B, and then com-
paring the result with C. The complexity of this approach is asymptotically
the same as the complexity of multiplying the matrices A and B. Our aim is
to apply the ﬁngerprinting method to design a randomized O

n2
-algorithm
for this equivalence problem. The idea is to take ﬁngerprints as vectors and
to consider the set
M = {fα : IFn×n →IFn | fα(A) = A · α and α ∈{0, 1}n},
where IFn×n is the set of all (n×n)-matrices over IF, and IFn is the set of all n-
dimensional vectors6 (α1, α2, . . ., αn)⊤over IF. Taking the set M as the base
of the ﬁngerprinting method, one obtains the following algorithm discovered
by Freivalds for the veriﬁcation of the matrix multiplication.
Algorithm FREIVALDS
Input: Three (n × n)-matrices, A, B, and C over a ﬁeld IF.
Step 1: Choose uniformly a vector α ∈{0, 1}n at random.
Step 2: Compute the vectors
β := A · (B · α)
γ := C · α
Step 3:
if β = γ then output “A · B = C”,
if β ̸= γ then output “A · B ̸= C”.
To compute β, one has to perform two multiplications of an (n×n)-matrix
with an n-dimensional vector. To compute γ, it is suﬃcient to perform one
multiplication of an (n×n) matrix C with a vector α. The comparison between
β and γ can be performed in linear time, and so the overall complexity of the
algorithm FREIVALDS is in O

n2
.
In what follows, we show that FREIVALDS is a 1MC algorithm for the
equivalence problem considered.
If A · B = C, then
A · B · α = C · α
for all α ∈{0, 1}n. Hence, FREIVALDS provides the correct answer with
certainty.
To analyze the case when A · B ̸= C we use the following lemma.
Lemma 4.4.11. Let A, B, and C be (n × n)-matrices over a ﬁeld IF, such
that A · B ̸= C. Then at least 2n−1 vectors α from {0, 1}n are witnesses of
“A · B ̸= C” in the sense that
A · B · α ̸= C · α.
6(n × 1)-matrices over IF

4.4 Veriﬁcation of Matrix Multiplication
143
Proof. If A · B ̸= C, the matrix
D = A · B −C
contains at least one element diﬀerent from 0. This means that it is suﬃcient
to show that, for at least half the vectors7 α from {0, 1}n, the vectors
D · α = δ = (δ1, δ2, . . ., δn)
are diﬀerent from the 0-vector, assuming D is not a 0-matrix.
Let D = [dij]i,j=1,2, ...,n. Let i ∈{1, 2, . . ., n} be an index such that the
i-th row di of D is not a 0-vector. Let dis1, dis2, . . ., disl, l ≥1, be all elements
from di that are diﬀerent from 0. Obviously, it is suﬃcient to show that δi ̸= 0
for at least 2n−1 vectors α.
Observe that
δi =
n

j=1
dij · αj =
l

k=1
disk · αsk.
Clearly,
δi = 0
⇔
l

k=1
disk · αsk = 0
⇔
αs1 = −1
dis1
·
l

k=2
disk · αsk.
This means that the value of αs1 is unambiguously determined by the values
of the remaining elements of α. Hence, there exist at most 2n−1 vectors α
such that δi = 0 in δ = D · α.
⊓⊔
Lemma 4.4.11 assures that at least half the vectors from {0, 1}n are wit-
nesses of the diﬀerence between A · B and C. Therefore, the error probability
of FREIVALDS on any input (A, B, C) with A·B ̸= C is at most 1/2. Hence,
FREIVALDS is a 1MC algorithm for the veriﬁcation of the matrix multipli-
cation.
Exercise 4.4.12. Let p be a prime. Let ZZp be the ﬁnite ﬁeld of p elements
with the operations ⊕mod p and ⊙mod p. Let A, B, and C be (n×n)-matrices
over ZZp such that A · B ̸= C. How many vectors from (ZZp)n are witnesses
of this inequality? What is the eﬀect of exchanging {0, 1}n for (ZZp)n on the
error probability of our algorithm, and how does one pay for the reduction of
the error probability? Why does one not try to reduce the error probability
in the case of an inﬁnite ﬁeld IF by choosing a vector from IFn at random
instead of a random choice from {0, 1}n?
72n−1 many

144
4 Fingerprinting
4.5 Equivalence of Two Polynomials
In this section we consider an equivalence problem for which no deterministic
polynomial-time algorithm is known, and that can be solved eﬃciently by the
method of ﬁngerprinting. The problem is to decide the equivalence of two
polynomials of several variables over a ﬁnite ﬁeld ZZp for a prime p. Two
polynomials P1(x1, . . ., xn) and P2(x1, . . ., xn) are said to be equivalent over
ZZp, if for all (α1, . . ., αn) ∈(ZZp)n
P1(α1, . . ., αn) ≡P2(α1, . . ., αn) (mod p).
One does not know any polynomial-time algorithm for this problem. A
naive observer may deny this by pointing out that the comparison of two
polynomials is easy because it is done simply by comparing the coeﬃcients
of the corresponding terms. We know that two polynomials P1 and P2 are
identical iﬀthe coeﬃcients of P1 are the same as those of P2. But the real
problem is that in order to perform this coeﬃcient comparison, one has to
transform the polynomials to their normal form ﬁrst. The normal form of a
polynomial of n variables x1, x2, . . ., xn and a degree8 d is
d

i1=0
d

i2=0
. . .
d

in=0
ci1,i2, ...,in · xi1
1 · xi2
2 · . . . · xin
n .
However, the input polynomials for our equivalence test may be in an arbitrary
form, for instance, as
P(x1, x2, x3, x4, x5, x6) = (x1 + x2)10 · (x3 −x4)7 · (x5 + x6)20.
Applying the binomial formula
(x1 + x2)n =
n

k=0
n
k

· xk
1 · xn−k
2
,
it is obvious that P(x1, x2, x3, x4, x5, x6) can have 10 · 7 · 20 = 1400 terms
with nonzero coeﬃcients. Thus the normal form of a polynomial can be ex-
ponentially longer than its representation, and hence, in general, one cannot
compute the normal form from a given form in polynomial time.9 If one wants
to be eﬃcient, one has to ﬁnd a way of comparing two polynomials without
creating their normal forms.
To do this we use a very simple strategy that is based on the concept of
Freivalds, presented in Section 4.4. One can view the application of the ﬁn-
gerprinting method for comparing A·B with C in Section 4.4 in the following
way:
8The degree of a polynomial of several variables is the maximum degree of all
variables.
9Note the similarity to the situation when one wants to compare the matrices
A · B and C without computing A · B.

4.5 Equivalence of Two Polynomials
145
(i) A · B and C are two linear functions fAB and fC from IFn to IFn, where
fAB(α) = (A · B) · α and fC(α) = C · α, and
(ii) an argument α ∈IFn for fAB and fC is a witness of AB ̸= C if fAB(α) ̸=
fC(α).
If one applies this idea for the comparison of two polynomials, one obtains
the following deﬁnition of witnesses. For two polynomials P1(x1, . . ., xn) and
P2(x1, . . ., xn), α = (α1, . . ., αn) ∈(ZZp)n is a witness of
P1(x1, . . ., xn) ̸≡P2(x1, . . ., xn)
if
P1(α1, . . ., αn) mod p ̸= P2(α1, . . ., αn) mod p.
In the language of ﬁngerprinting,
hα(Pi) = Pi(α1, . . ., αn) mod p
is the ﬁngerprint of Pi for i = 1, 2. This way, one obtains the following algo-
rithm.
Algorithm AQP
Input: A prime p and two polynomials P1 and P2 over ZZp in n variables
x1, . . ., xn, n ∈IN −{0}, with a maximal degree of d, d ∈IN.
Step 1: Choose uniformly an α = (α1, . . ., αn) ∈(ZZp)n at random.
Step 2: Compute the ﬁngerprints
hα(P1) = P1(α1, . . ., αn) mod p, and
hα(P2) = P2(α1, . . ., αn) mod p.
Step 3:
if hα(P1) = hα(P2) then
output “P1 ≡P2”
else
output “P1 ̸≡P2”
The complexity of the algorithm AQP is clearly in O(m · log2 d) with re-
spect to the operations over ZZp, where m is the length of the representation
of the input (P1, P2).
Now we analyze the error probability of the algorithm AQP. If P1 and P2
are equivalent over ZZp, then
P1(α1, . . ., αn) ≡P2(α1, . . ., αn) (mod p)
for all (α1, α2, . . ., αn) ∈(ZZp)n. Hence, the error probability for inputs
(P1, P2) with P1 ≡P2 is equal to 0.

146
4 Fingerprinting
Let P1 and P2 be two polynomials that are not equivalent over ZZp. In
what follows, we aim to show that if p ≥2nd, then the error probability of
AQP is less than 1/2.
The question of whether
P1(x1, . . ., xn) ≡P2(x1, . . ., xn)
is equivalent to the question of whether
Q(x1, . . ., xn) = P1(x1, . . ., xn) −P2(x1, . . ., xn) ≡0.
This means that if P1 and P2 are not equivalent, the polynomial Q is not
identical to 0 (zero polynomial). Now, we show that the number of roots of a
polynomial Q ̸≡0 over n variables and of a degree d is bounded. This means
that there are suﬃciently many witnesses α ∈(ZZp)n with
Q(α) ̸≡0 (mod p), i.e., P1(α) ̸≡P2(α) (mod p).
We start with the well known theorem about the number of roots of polyno-
mials over one variable.
Theorem 4.5.13. Let d be a nonnegative integer. Every polynomial P(x) of
a singe variable x over any ﬁeld and of degree d has either at most d roots or
is equal to 0 everywhere.10
Proof. We prove Theorem 4.5.13 by induction with respect to the degree d.
(i) Let d = 0. Then P(x) = c for a constant c. If c ̸= 0, then P(x) does not
have any root.
(ii) Assume that Theorem 4.5.13 holds for d −1, d ≥1. Now, we prove it for
d.
Let P(x) ̸≡0 and let a be a root of P. Then
P(x) = (x −a) · P ′(x)
where P ′(x) =
P (x)
(x−a) is a polynomial of degree d −1. From the induction
hypothesis P ′(x) has at most d −1 roots. Therefore P(x) has at most d
roots.
⊓⊔
Now we are ready to prove that there are suﬃciently many witnesses11
of the nonequivalence of diﬀerent P1 and P2 over ZZp for a suﬃciently large
prime p.
10i.e., is a zero polynomial
11nonroots of Q(x1, . . . , xn) = P1(x1, . . . , xn) −P2(x1, . . . , xn)

4.5 Equivalence of Two Polynomials
147
Theorem 4.5.14. Let p be a prime, and let d and n be positive integers. Let
Q(x1, . . . , xn) ̸≡0 be a polynomial over ZZp in n variables x1, . . . , xn, where
each variable has degree of at most d in Q. Then, Q has at most
n · d · pn−1
roots.
Proof. We prove Theorem 4.5.14 by induction with respect to the number n
of variables in Q.
(i) Let n = 1. Then Theorem 4.5.13 implies that Q(x1) has at most
d = n · d · pn−1 (for n = 1)
roots.
(ii) Assume that the assertion of Theorem 4.5.14 is true for n−1, n ∈IN−{0}.
We prove it for n. We can express Q as
Q(x1, x2, . . . , xn) = Q0(x2, . . . xn) + x1 · Q1(x2, . . . , xn) + . . .
+ xd
1 · Qd(x2, . . . , xn)
=
d

i=0
xi
1 · Qi(x2, . . . , xn)
for some polynomials
Q0(x2, . . . xn), Q1(x2, . . . , xn), . . . , Qd(x2, . . . , xn)
in the n −1 variables x2, . . ., xn.
If
Q(α1, α2, . . . , αn) ≡0 mod p
for an α = (α1, . . . , αn) ∈(ZZp)n, then either
(a) Qi(α2, . . . , αn) ≡0 mod p for all i = 0, 1, . . . , d, or
(b) there exists a j ∈{0, 1, . . ., d} with Qi(α2, . . . , αn) ̸= 0 mod p, and
α1 is a root of the polynomial
Q(x1) = Q0(α2, . . . αn) + x1 · Q1(α2, . . . , αn) + . . .
+ xd
1 · Qd(α2, . . . , αn)
in the variable x1.
Now we count the number of roots in the cases (a) and (b) separately.
(a) Since Q(x1, . . . , xn) ̸≡0, there exists a k ∈{0, 1, . . ., d} such that
Qk(x2, . . . , xn) ̸≡0.
The induction hypothesis implies that the number of roots of Qk is at
most

148
4 Fingerprinting
(n −1) · d · pn−2.
Hence, there are at most (n−1)·d·pn−2 elements α = (α2, . . . , αn) ∈
(ZZp)n−1 such that
Qi(α) ≡0 mod p
for all i ∈{0, 1, 2, . . ., d}. Since the value α1 of x1 does not have
any inﬂuence on the condition (a), α1 can be chosen arbitrarily from
{0, 1, . . ., p −1}. Thus there are at most
p · (n −1) · d · pn−2 = (n −1) · d · pn−1
elements α = (α1, α2, . . . , αn) ∈(ZZp)n that have the property (a).
(b) Since Q(x1) ̸≡0, the polynomial Q has at most d roots12 (i.e., at most
d values α1 ∈ZZp, with Q(α1) ≡0 mod p). Therefore, there are at
most
d · pn−1
values13 α = (α1, α2, . . . , αn) ∈(ZZp)n, that satisfy the property (b).
Combining (a) and (b), Q(x1, . . . , xn) has at most
(n −1) · d · pn−1 + d · pn−1 = n · d · pn−1
roots.
⊓⊔
Corollary 4.5.15. Let p be a prime, and let n and d be positive integers. For
every polynomial Q(x1, . . . , xn) ̸≡0 over ZZp of degree at most d, the number
of witnesses of “Q ̸≡0” is at least

1 −n · d
p

· pn.
Proof. The number of elements in (ZZp)n is exactly pn and Theorem 4.5.14
implies that at most n · d · pn−1 of them are not witnesses. Hence, the number
of witnesses is at least
pn −n · d · pn−1 =

1 −n · d
p

· pn.
⊓⊔
Thus the probability of choosing uniformly a witness of “Q ̸≡0” at random
from pn elements of (ZZp)n is at least

1 −n · d
p

.
12Theorem 4.5.14
13Note that the values α1, α2, . . . , αn can be chosen arbitrarily.

4.6 Summary
149
For p > 2nd, the probability of choosing a witness is at least 1/2. By executing
several independent random choices from (ZZp)n, the probability of ﬁnding at
least one witness of Q ̸≡0 (i.e., of P1(x1, . . . , xn) ̸≡P2(x1, . . . , xn)) can be
brought arbitrarily close to 1.
Exercise 4.5.16.∗Extend the algorithm AQP to decide the equivalence of
two polynomials over inﬁnite ﬁelds, too.
Exercise 4.5.17. Consider the communication protocol R presented in Sec-
tion 1.2 for the comparison of two binary strings (of the contents of two
databases). Let p be a prime and let a = a1a2 . . . an, ai ∈{0, 1} for
i = 1, . . ., n, be a binary string. Consider the polynomial Pa of a singe variable
x deﬁned over ZZp as follows.
Pa(x) =
n

i=1
aixi−1.
Apply the idea of algorithm AQP on order to design a 1MC protocol for the
comparison of two n bit strings a = a1a2 . . . an and b = b1b2 . . . bn. What
eﬀect does the choice of p have on the error probability and on the communi-
cation complexity? Compare the results with the complexity and the success
probability of the protocol R from Section 1.2.
4.6 Summary
The ﬁngerprinting method can be viewed as a special case of the method of
the abundance of witnesses. It is a robust technique for designing eﬃcient ran-
domized algorithms for the comparison of representations of two objects (i.e.,
for solving equivalence problems). It sometimes happens that one is not able
to eﬃciently decide whether or not two object representations (descriptions)
represent the same object. The reasons for the hardness of these equivalence
tasks often lies in the size of the representations of the objects of the object
class considered or in the fact that the representations used are unaﬀordable
for eﬃcient comparison. Deciding the equivalence of two polynomials given in
an “arbitrary” representation is an exemplary problem for successful applica-
tion of ﬁngerprinting. Since the transformation of a polynomial representation
into the normal form can exponentially increase the representation size, ﬁn-
gerprinting is the only known eﬃcient way to solve this problem. The basic
idea of ﬁngerprinting is to compare ﬁngerprints of the given representations
of some objects in order to decide about the equivalence of these representa-
tions. A ﬁngerprint of a representation of an object is a short and possibly
incomplete representation of this object. To get a short representation (a ﬁn-
gerprint), and so make an eﬃcient comparison possible, we have to pay with
the incompleteness of the representation, and so with the possibility of making

150
4 Fingerprinting
a wrong decision. This strongly reminds us of hashing, where the ﬁngerprints
of the keys determine the distribution of data from an actual set S of data
records in a discrete direct access memory T . The art of applying the method
of ﬁngerprinting lies in the choice of a set M of ﬁngerprinting methods, such
that
for every pair of diﬀerent objects of the set of objects considered, a
random choice of a ﬁngerprinting method from M provides a witness of
the diﬀerence between these two objects with a reasonable probability.14
The power of this method was impressively demonstrated by the protocol
R for the comparison of two strings in Section 1.2. In Section 4.2, we have
extended this concept in order to design randomized protocols for decision
problems such as the membership of a string in a set of strings and the dis-
jointness problem for two sets of strings. We have seen that ﬁngerprinting can
be successfully applied to small input sets. Along the way we have learned a
new15 way of reducing the error probability to arbitrarily close to 0. The main
idea is to allow larger ﬁngerprints, and in this way to decrease the number of
witnesses among the witness candidates (the ﬁngerprinting methods) for any
input.
In Section 4.3 we presented another application of randomized string com-
parison that resulted in the design of an eﬃcient16 randomized algorithm for
the substring problem.
In Section 4.4 we saw that one can compare representations of matrices
given in the form of a product of several matrices without executing matrix
multiplications. For the matrix representation A · B (as the product of two
matrices A and B), we determine the ﬁngerprint A · (B · α) by choosing a
vector α at random. The gain in complexity corresponds to the diﬀerence
between matrix multiplication and the multiplication of a matrix by a vector.
We can view this approach as regarding matrices (for instance, given as the
product A · B, or even as the product of several matrices) as mappings from
a set of vectors to a set of vectors, and considering ﬁngerprints determined
by a vector α as the values of these mappings for the argument α. It may
be surprising that a simple computation of the function value for a given
argument can result in a successful application of the ﬁngerprinting method.
In Section 4.5 we saw that this simple and elegant approach of Freivalds works
for the equivalence problem of two polynomials, too. The reason for success
in this case is that the number of roots of polynomials of several variables is
not too large when compared with the number of all arguments, and so one
can apply ﬁngerprinting to eﬃciently test whether or not a given polynomial
14In other words, a large part of the ﬁngerprinting ways of M maps the two given
object representations to diﬀerent ﬁngerprints, and so proves the diﬀerence between
these two objects.
15diﬀerent from executing several independent runs on the same input
16even in the design of an optimal algorithm, because a running time cannot lay
asymptotically below the input length

4.6 Summary
151
is the zero polynomial. Then, it is suﬃcient to observe that two polynomials
are identical if and only if their diﬀerence is the zero polynomial.
The most transparent examples of the application of ﬁngerprinting can
be found in the theory of communication complexity, overviews of which are
given in the monographs of Kushilevitz and Nisan [KN97] and Hromkoviˇc
[Hro97]. Mehlhorn and Schmidt [MS82] applied this method to ﬁx the maxi-
mal possible diﬀerence between deterministic communication and Las Vegas
communication. The concept of comparing two mappings by simply evaluating
them on a random argument is due to Freivalds [Fre77]. But one cannot suc-
cessfully apply this concept for any equivalence problem. For instance, given
two representations of two Boolean functions that diﬀer in one of the 2n pos-
sible arguments, one cannot straightforwardly apply the Freivalds technique.
But it is possible to eﬃciently transform some Boolean function representa-
tions to polynomials over an appropriate ﬁeld, and so to reduce the problem
of Boolean function comparison to the presented comparison of two polyno-
mials. A detailed and transparent presentation of this involved application of
ﬁngerprinting is given in the excellent textbook by Sipser [Sip97] and also in
[Hro03]. Further nontrivial applications of ﬁngerprinting are presented in the
monograph by Motwani and Raghavan [MR95].

This page intentionally left blank

5
Success Ampliﬁcation and Random Sampling
It is not possible to wait for inspiration,
and even inspiration alone is not suﬃcient.
Work and more work is necessary.
Man blessed by genius can create nothing really great,
not even anything mediocre,
if he does not toil as hard as a slave.
Piotr Ilyich Tschaikovsky
5.1 Objectives
This chapter is devoted to two paradigms of the design of randomized algo-
rithms, namely the ampliﬁcation of success probability by repeating runs on
the same input and random sampling. The reasons for presenting both these
methods in one chapter are their similarity and their equally balanced com-
bination in several applications. Thus, for some randomized algorithms, it is
not possible to determine which of these two methods is primarily responsible
for success.
In Chapter 2 we called attention to the fact that ampliﬁcation is a method
for reducing the error probability below an arbitrarily given small constant ϵ >
0. We underlined the importance of this observation by classifying randomized
algorithms with respect to the speed of error probability reduction with the
number of computation repetitions on the same input. In this chapter we
aim to present algorithms for which ampliﬁcation does not only increase the
success probability, but directly stamps the process of the algorithm design.
Moreover, we do not want only to follow the naive approach of repeating the
whole computation on the same input, but also to introduce a more advanced
technique that prefers to repeat only some computation parts or to repeat
diﬀerent parts diﬀerently many times. The idea is to pay more attention to
computation parts in which the probability of making mistakes is greater than
in other ones.
With random sampling we aim to document the power of this method
by designing eﬃcient randomized algorithms solving problems for which no
deterministic polynomial-time algorithm has up to now been discovered.1
This chapter is organized as follows. Section 5.2 introduces the above men-
tioned generalized version of the ampliﬁcation method. This method is used
1and maybe for which no eﬃcient deterministic algorithms exist at all

154
5 Success Ampliﬁcation and Random Sampling
to design randomized algorithms solving the minimum cut problem for multi-
graphs. In Section 5.3 we combine ampliﬁcation with random sampling in
order to design a practicable one-sided-error Monte Carlo algorithm for the
well known, NP-hard 3-satisﬁability (3SAT) problem. Though this algorithm
runs in exponential time, it is much faster than algorithms running in O(2n)
time and it can be successfully applied for relatively large instances of 3SAT.
In Section 5.3 we present an application of random sampling that results in a
Las Vegas polynomial-time algorithm for a number-theoretic problem, which
is not known to be in P. Hence, this randomized algorithm is the only eﬃ-
cient way known for solving this problem. Altogether this chapter presents im-
pressive examples documenting the superiority of randomized algorithms over
their best known deterministic counterparts. As usual, we ﬁnish the chapter
by summarizing the most important ideas and results presented.
5.2 Eﬃcient Ampliﬁcation by Repeating Critical
Computation Parts
The aim of this section is to introduce the method of ampliﬁcation of the
success probability as a method for the design of randomized algorithms,
and not only (as considered until now) as a technique for error probability
reduction of algorithms already designed. For this purpose we consider the
following minimization problem MIN-CUT.
MIN-CUT
Input: A multigraph G = (V, E, c), where c : E →IN −{0} determines the
multiplicity of the edges of G.
Constraints: The set of all feasible solutions for G is the set
M(G) = {(V1, V2) | V1 ∪V2 = V, V1 ∩V2 = ∅}
of all cuts of G.
Costs: For every cut (V1, V2) ∈M(G),
cost((V1, V2), G) =

e∈S(V1,V2)
c(e),
where S(V1, V2) = {{x, y} ∈E | x ∈V1 and y ∈V2}
{i.e., cost((V1, V2), G) is equal to the number of edges between V1 and V2}
Goal: minimum
The best known deterministic algorithm for MIN-CUT runs in time
O

|V | · |E| · log
|V |2
|E|

,

5.2 Eﬃcient Ampliﬁcation by Repeating Critical Computation Parts
155
which, in the worst case2, is in O

n3
for n = |V |. Our goal is to design an
eﬃcient randomized algorithm for MIN-CUT. This algorithm is based on the
graph operation Contract(G, e) that, for a given multigraph G = (V, E)
and an edge e = {x, y} ∈E, contracts the edge e. The contraction of e =
{x, y} ∈E means that
•
the vertices x and y are replaced by a new vertex ver(x, y),
•
the multi-edge e = {x, y} is removed (contracted) in this way (we do not
allow any self loop),
•
each edge {r, s} with an r ∈{x, y} and s /∈{x, y} is replaced by a new
edge {ver(x, y) , s}, and
•
all remaining parts of G remain unchanged.
Visualizing Contract(G, e), one simply collapses the vertices x and y into one
new vertex. We denote the resulting graph by G/{e}.
Figure 5.1 shows three contraction operations consecutively executed on
the multigraph G depicted in Figure 5.1(a). First, one executes the opera-
tion Contract(G, {x, y}). The resulting multigraph G/{x, y} is depicted in
Figure 5.1(b). The next step is the contraction of the edge {u, z}, and the re-
sulting multigraph (G/{x, y})/{u, z} is depicted in Figure 5.1(c). Finally. one
contracts the edge {ver(x, y) , v} and obtains the multigraph of two vertices3
ver(x, y, v) and ver(u, z) depicted in Figure 5.1(d).
Observe that, given a collection of edges F ⊆E, the eﬀect of contracting
the edges in F does not depend on the order of contractions. For instance, the
multigraph (G/{u, z})/{x, y} is the same as (G/{x, y})/{u, z} in Figure 5.1.
Therefore we simplify the notation and use G/F for the resulting multigraph.
This way, G/{{x, y}, {u, z}, {x, v}} is a short representation of the multigraph
in Figure 5.1(d).
The design idea for the following naive randomized algorithm for MIN-CUT
is very simple. One contracts randomly chosen edges until one gets a multi-
graph with exactly two vertices ver(V1) and ver(V2). Obviously, V1 ∪V2 = V
and V1 ∩V2 = ∅. Hence, (V1, V2) is a cut of G, and the number of edges be-
tween the two vertices ver(V1) and ver(V2) corresponds to the cost of the cut
(V1, V2).
In our example, the multigraph in Figure 5.1(d) corresponds to the cut
({x, y, v}, {u, z}) with a cost of 4. In other words, one can view the contraction
of an edge {x, y} as saying that the vertices x and y must be on the same
side of the cut approached and so as restricting the set of all cuts to the cuts
with x and y on one side. In this way the set of possible cuts is monotonically
reduced until it contains only one cut.
2if |E| ∈Ω(|V |2)
3To be precise, one has to write ver(ver(x, y) , v) instead of ver(x, y, v). But we
prefer the shorter representation because, in what follows, the only important matter
is that the vertices x, y, and v are joined to one vertex. To simplify the notation, we
even use ver(V ′) for the vertex created by the union of the vertices in V ′.

156
5 Success Ampliﬁcation and Random Sampling
x
y
z
z
u
u
v
v
v
(a)
(b)
(c)
(d)
ver(x, y)
ver(x, y)
ver(u, z)
ver(u, z)
ver(x, y, v)
Fig. 5.1.
One can formally describe this approach for solving MIN-CUT as follows.
Let E(G) denote the set of edges of a multigraph G.
Algorithm CONTRACTION
Input: A connected4 multigraph G = (V, E, c)
Step 1: Set label (v) := {v} for every vertex v ∈V .
Step 2:
while G has more than two vertices do
begin
choose an edge e = {x, y} ∈E(G);
G := Contract(G, e);
Set label (z) := label (x) ∪label (y)
4One can determine in time O(|E|) whether or not a multigraph is connected,
and so ﬁnd a minimal cut of cost 0 for any disconnected multigraph.

5.2 Eﬃcient Ampliﬁcation by Repeating Critical Computation Parts
157
for the new vertex z = ver(x, y);
end
Step 3:
if G = ({u, v}, E(G)) for a multiset E(G) then
output “(label (u) , label (v))” and “ cost = |E(G)|”
Theorem 5.2.1. The algorithm CONTRACTION is a randomized polynomial-
time algorithm that computes a minimal cut of a given multigraph G of n
vertices with probability at least
2
n · (n −1).
Proof. Clearly, the algorithm CONTRACTION computes a cut of G, and
so a feasible solution for MIN-CUT. The algorithm executes exactly n −1
edge contractions for a multigraph of n vertices, and each contraction can be
executed in O(n) steps. Hence, the time complexity of CONTRACTION is in
O

n2
.
In what follows, we aim to show that the algorithm CONTRACTION
ﬁnds a minimal cut with probability at least
2
n·(n−1). Let G = (V, E, c) be a
multigraph, and let Cmin = (V1, V2) be a minimal cut of G with cost(Cmin) = k
for a natural number k. Let E(Cmin) denote the set of edges in Cmin.
In order to prove the lower bound
2
n·(n−1) on the success probability, we
show that the probability of computing exactly the cut Cmin is at least
2
n·(n−1).
First, we observe that
G has at least
n·k
2
edges, i.e., |E(G)| ≥n·k
2 ,
because the minimality of Cmin with cost(Cmin) = k implies that every vertex
of G has a degree of at least k.
The second important observation is that
the algorithm CONTRACTION computes Cmin if and only if no edge
from E(Cmin) has been contracted.
Our aim is to study the probability of this event.
The algorithm consists of n −2 contractions. Let SCon,G be the set of
all possible computations of the algorithm CONTRACTION on G. In the
probability space (SCon,G, Prob) we investigate the events
Eventi = {all computations from SCon,G in which no edge
of E(Cmin) is contracted in the i-th contraction step}
for i = 1, 2, . . ., n −2. The event that Cmin is the output of the algorithm is
exactly the event
n−2
(
i=1
Eventi.

158
5 Success Ampliﬁcation and Random Sampling
Now, we apply the concept of conditional probabilities (Exercise 2.2.16) in
order to calculate the probability of this event.
Prob
n−2
(
i=1
Eventi

= Prob(Event1) · Prob(Event2 | Event1)
·Prob(Event3 | Event1 ∩Event2) · . . .
·Prob
⎛
⎝Eventn−2



n−3
(
j=1
Eventj
⎞
⎠
(5.1)
To prove Theorem 5.2.1, we have to estimate lower bounds on
Prob
⎛
⎝Eventi



i−1
(
j=1
Eventj
⎞
⎠
for i = 1, . . ., n −2.
Since G has at least n·k
2
edges and the algorithm makes a random choice
for edge contraction,
Prob(Event1) = |E| −|E(Cmin)|
|E|
= 1 −k
|E|
≥1 −k
k·n
2
= 1 −2
n.
(5.2)
In general, the multigraph G/Fi created after i −1 random contractions
has exactly n −i + 1 vertices. If
Fi ∩E(Cmin) = ∅(i.e.,
i−1
(
j=1
Eventj happens),
then Cmin is also a minimal cut of G/Fi. Consequently, every vertex in G/Fi
has still to have a degree of at least k, and so G/Fi has at least
k · (n −i + 1)
2
edges. Therefore,
Prob
⎛
⎝Eventi



i−1
(
j=1
Eventj
⎞
⎠≥|E(G/Fi) −E(Cmin)|
|E(G/Fi)|
≥1 −
k
k·(n−i+1)
2
(5.3)
= 1 −
2
(n −i + 1)

5.2 Eﬃcient Ampliﬁcation by Repeating Critical Computation Parts
159
for i = 2, . . ., n −1. Inserting (5.3) in (5.1), one obtains
Prob
⎛
⎝
n−2
(
j=1
Eventj
⎞
⎠≥
n−2

i=1

1 −
2
n −i + 1

=
3

l=n
l −2
l

=
2
n · (n −1) =
1
n
2
.
⊓⊔
Exercise 5.2.2. Modify the algorithm CONTRACTION in the following way.
Instead of choosing an edge at random, choose two vertices x and y randomly
and join them into one vertex. Construct multigraphs of n vertices, for which
the probability that the modiﬁed algorithm ﬁnds a minimal cut is exponen-
tially small in n.
Theorem 5.2.1 assures that the probability of discovering a particular min-
imal cut in one run is at least
2
n · (n −1) > 2
n2 .
Executing n2/2 independent runs of the algorithm and taking the best out-
put from all computed outputs, one does not obtain a minimal cut with a
probability of at most

1 −2
n2
 n2
2
< 1
e.
Hence, the complementary probability of computing a minimal cut by n2/2
runs of the algorithm is at least
1 −1
e.
The complexity of the algorithm CONTRACTIONn2/2 is in
O

n4
.
Thus, we need O

n4
time to compute an optimal solution with a constant
probability, and the best known deterministic algorithm computes an optimal
solution in time O

n3
with certainty. The gain of our eﬀort is negative, and
one can ask whether it is reasonable to use randomization in this case. But
it is not so bad as it seems to be at ﬁrst glance. The too high complexity
is caused by the naive application of the ampliﬁcation method, in which one
increases the success probability by repeating entire runs of the algorithm.

160
5 Success Ampliﬁcation and Random Sampling
In this case, this standard application of ampliﬁcation is not clever because
the probability of contracting an edge from Cmin grows with the number of
contractions executed. For the ﬁrst contractions, this probability5 is only
2
n,
2
n −1,
2
n −2,
2
n −3,
2
n −4, . . . ,
but for the last edge contractions, it is even as much as 2/3. A very natural
idea is to simply give up the last6 random contractions because the created
multigraph G/F, is small enough to be searched for a minimal cut in a de-
terministic way. In what follows, we describe the algorithm based on this
idea. The size of G/F will still remain a free parameter of the algorithm. Let
l : IN →IN be a monotonic function such that 1 ≤l(n) < n for every n ∈IN.
Algorithm DETRAN(l)
Input: A multigraph G = (V, E, c) of n edges, n ∈IN, n ≥3.
Step 1: Perform the algorithm CONTRACTION on G in order to get a multi-
graph G/F of l(n) vertices.
Step 2: Apply the best known deterministic algorithm on G/F to compute
an optimal cut D of G/F.
Output: D
First, we analyze the inﬂuence of the exchange of CONTRACTION for
DETRAN(l) on
(i) the ampliﬁcation of the success probability, and
(ii) the increase of the complexity7.
In this analysis we consider l as a free parameter, i.e., the result of the analysis
depends on l.
Lemma 5.2.3. Let l : IN →IN be a monotonic growing function with 1 ≤
l(n) < n. The algorithm DETRAN(l) works in time
O

n2 + (l(n))3
,
and it ﬁnds an optimal solution with probability at least
l(n)
2

n
2
 .
5How many contractions have to be considered as the last ones will be analyzed
in what follows.
6of the events E1, E2, E3, . . .
7The increase of time complexity is the cost we pay for the increase of the success
probability.

5.2 Eﬃcient Ampliﬁcation by Repeating Critical Computation Parts
161
Proof. First we analyze the complexity of DETRAN(l). In step 1, n −l(n)
contractions are performed, and each contraction can be executed in time
O(n). Hence, step 1 can be executed in
O((n −l(n)) · n) = O

n2
time. The above mentioned deterministic algorithm can compute an optimal
cut of G/F in time O

(l(n))3
. Altogether, the complexity of DETRAN(l) is
in
O

n2 + (l(n))3
.
Next we analyze the success probability of DETRAN(l). As in the proof
of Theorem 5.2.1, let Cmin be a minimal cut of G. We prove a lower bound
on the success probability of DETRAN(l) by proving a lower bound on the
probability of having Cmin in the multigraph G/F after executing step 1. The
corresponding event is
n−l(n)
(
i=1
Eventi.
Applying (5.1), (5.2), and (5.3), one obtains the following lower bound on
the probability of this event, and so also on the probability of computing a
minimal:
Prob
⎛
⎝
n−l(n)
(
i=1
Eventi
⎞
⎠≥
n−l(n)

i=1
(1 −
2
n −i + 1)
=
n−2
i=1 (1 −
2
n−i+1)
n−2
j=n−l(n)+1(1 −
2
n−j+1)
=
1
(n
2)
1
(l(n)
2 )
=
l(n)
2

n
2
 .
This completes the proof.
⊓⊔
Since
n2
(l(n))2 ≥
n
2

l(n)
2
,
n2
(l(n))2 independent runs of DETRAN(l) provide a randomized algorithm that
works in time
O

(n2 + (l(n))3) ·
n2
(l(n))2

= O

n4
(l(n))2 + n2 · l(n)

(5.4)
and computes a minimal cut of G with probability at least
1 −1
e.

162
5 Success Ampliﬁcation and Random Sampling
The best8 possible choice of l with respect to the time complexity is
l(n) =

n2/3 
,
and making this choice one obtains the following result.
Theorem 5.2.4. The algorithm DETRAN
-
n2/3.
n2/⌊n2/3⌋works in time
O

n8/3
and computes a minimal cut with probability at least
1 −e−1.
Now, we have a randomized algorithm that is asymptotically faster than
any known deterministic algorithm, and whose error probability can be pushed
arbitrarily9 low. Though we are not satisﬁed with the designed randomized
algorithm. The design strategy is too simple and rough for really capturing the
growing error probability of an edge contraction with the number of contrac-
tions executed. The algorithm DETRAN(l) prohibits the execution of the last
random contractions with high error probabilities by computing determinis-
tically in its ﬁnal part, and so increases the success probability. Hence, fewer
runs of DETRAN(l) suﬃce for getting a constant probability of computing a
minimal cut.
If one observes the increase
2
n,
2
n −1,
2
n −2,
2
n −3, . . . , 2
3
of the error probabilities of the sequence of random contractions, the idea of
using fewer run repetitions at the beginning and more at the end of the al-
gorithm CONTRACTION may appear appropriate. We visualize this idea in
what follows. The algorithm CONTRACTION needs n2 runs of O

n2
com-
plexity to assure a minimal cut with a constant probability. This corresponds
to Figure 5.2, where one lets n2 computations of CONTRACTION run in par-
allel. If the complexity of each computation is in O

n2
, then the complexity
of the entire work is the area of the rectangle of the size n2 × O

n2
, and so
O

n4
.
Next, we consider the following implementation of our new idea (Fig-
ure 5.3). We start by executing only two independent runs in parallel. Af-
ter some random edge contractions, when the error probability of choosing a
wrong edge10 has grown substantially, we split each of the two computations
8To minimize the expression (5.4), one has to take an l such that
n4
(l(n))2 = n2·l(n).
9The failure probability tends to 0 with exponential speed with respect to the
number of repetitions of DETRAN-
n2/3.
n2/⌊n2/3⌋.
10an edge of Cmin

5.2 Eﬃcient Ampliﬁcation by Repeating Critical Computation Parts
163
n2 runs
. . .
. . .
O
n2
length
Fig. 5.2.
. . .
O
n2
depth
O
n2
leaves
Fig. 5.3.
into two independent runs. After some further contractions we again double
the number of runs, and so on. At the very end we also have O

n2
runs (as
in Figure 5.2, too) and we take the best cut of the computed cuts. Hence, the
strategy is to use at the end as many runs as in the naive approach of the
algorithm CONTRACTION, but to use only a few at the beginning (when
the probability of choosing an edge from Cmin is small). The crucial point for

164
5 Success Ampliﬁcation and Random Sampling
the complexity analysis of this strategy is estimating the number of random
contractions between doubling the number of runs executed in parallel. We
double the number of runs always after the number of vertices has been re-
duced by a factor of 1/
√
2 after the last doubling. Since the number of all
random contractions is n −2, the number of runs (leaves of the tree in Fig-
ure 5.3) is really 2log√
2(n−2) ∈O

n2
. Observing Figure 5.3 we see that the
complexity of this strategy is the sum of the lengths of all tree edges of the two
trees in Figure 5.3. In contrast to the area of the ﬁgure rectangle11, the trees
look light, and so one can expect a substantially smaller complexity. Moreover,
if one realizes that the number of edges in the complete binary tree of O

n2
leaves is in O

n2 · log2 n2
and that the length of the edges decreases with the
number of parallel runs, then one can hope for a complexity in O

n2 log n

.
To recognize that the success probability of this strategy is large enough is a
little bit more complicated. Before doing this, we give a formal presentation
of the algorithm.
Algorithm REPTREE(G)
Input: A multigraph G = (V, E, c), |V | = n, n ∈IN, n ≥3.
Procedure:
if n ≤6 then
compute a minimal cut deterministically
else
begin
h := ⌈1 +
n
√
2⌉;
Perform two independent runs of CONTRACTION in order to
get two multigraphs G/F1 and G/F2 of size h;
REPTREE(G/F1);
REPTREE(G/F2)
end
output the smaller of the two cuts computed by
REPTREE(G/F1) and REPTREE(G/F2)
Theorem 5.2.5.∗
The algorithm REPTREE works in time
O

n2 · log n

and ﬁnds a minimal cut with a probability of at least
1
Ω(log2 n).
Proof. First we analyze the time complexity of REPTREE. The depths of
the binary trees in Figure 5.3 correspond to the number of recursion calls of
11which is in O
n4

5.2 Eﬃcient Ampliﬁcation by Repeating Critical Computation Parts
165
REPTREE. Since the size of a given multigraph is reduced by the multiplica-
tive factor 1/
√
2 in each stage of the algorithm, the number of recursion calls
is at most
log√
2 n ∈O(log2 n) .
Since the original algorithm CONTRACTION works in time O

n2
on any
multigraph of n vertices, we can roughly bound the time of reducing a multi-
graph G of size m to a multigraph G/F of size ⌈1 + m
√
2⌉by O

m2
. Hence,
we obtain the following recurrence for TimeREPTREE:
TimeREPTREE(n) ∈O(1) for n ≤6, and
TimeREPTREE(n) = 2 · TimeREPTREE
!
1 + n
√
2
"
+ O

n2
.
(5.5)
One can easily check that
TimeREPTREE(n) = Θ(n2 · log2 n).
In what follows, we estimate a lower bound on the success probability of the
algorithm REPTREE. Once again, we do this by analyzing the probability
of computing a speciﬁc minimal cut Cmin with |E(Cmin)| = k for a positive
integer k.
First, we pose the following question. Let pl be the probability that the
multigraph G/Fi (i = 1, 2) of size

1 + (l/
√
2)

still contains Cmin, assuming
that the multigraph G/F of l vertices has contained Cmin before the computa-
tion split into two runs leading to G/F1 and G/F2. How large is pl? Following
the analysis of the algorithm DETRAN, we have
pl ≥

1+
l
√
2

2

l
2

=
$
1 +
l
√
2
%
·
$
1 +
l
√
2
%
−1

l · (l −1)
≥1
2.
Let Prob(n) be the probability that REPTREE ﬁnds a minimal set of a
multigraph of n vertices. Then, for i = 1, 2,
pl · Prob
!
1 +
l
√
2
"
is a lower bound on the conditional probability that REPTREE computes
Cmin by the reduction from G/F to G/Fi and then by the recursive call
REPTREE(G/Fi), assuming G/F has contained Cmin. Since REPTREE
starting from G/F executes two runs of CONTRACTION with outputs G/F1
and G/F2,

1 −pl · Prob
!
1 +
l
√
2
"2
is an upper bound on the conditional probability that REPTREE does not
ﬁnd Cmin assuming G/F has contained Cmin. Hence, we obtain the following
recurrence for Prob(n):

166
5 Success Ampliﬁcation and Random Sampling
Prob(2) = 1, and
Prob(l) ≥1 −

1 −pl · Prob
!
1 +
l
√
2
"2
≥1 −

1 −1
2 · Prob
!
1 +
l
√
2
"2
(5.6)
One can show that each function Prob satisfying the recurrence (5.6) is in
Θ(
1
log2 n).
⊓⊔
Exercise 5.2.6. Prove that the solution of the recurrence (5.5) is a function
in Θ(n2 · log n).
Exercise 5.2.7. Prove that each function Prob satisfying the recurrence (5.6)
is a function that fulﬁlls Prob(n) ≥
1
Ω(log2 n).
Exercise 5.2.8.∗Analyze the success probability and the time complexity of
the versions of the algorithm REPTREE, for which one takes the following
size reduction between two splits of the computation:
(i) from l to
- l
2
.
(ii) from l to
√
l
(iii) from l to
l
log2 l
(iv) from l to l −
√
l.
A consequence of Theorem 5.2.5 is that O(log2 n) repetitions of the al-
gorithm REPTREE are suﬃcient in order to compute a minimal cut with a
constant probability. Already O

(log2 n)2
repetitions suﬃce to reduce the
non-success probability to a function tending to 0 with growing n and one
can consider this algorithm applicable. The complexity of REPTREE(log2 n)2
is in
O

n2 · (log2 n)3
which is substantially better than the complexity O

n3
of the best deter-
ministic algorithm and the complexity O

n8/3
of the randomized algorithm
DETRAN

⌊n2/3⌋

n2/⌊n2/3⌋.
Hence, the idea of repeating diﬀerent parts diﬀerently many times can be
very fruitful.
5.3 Repeated Random Sampling and Satisﬁability
Here we combine ampliﬁcation and random sampling with local search in order
to design a randomized algorithm that can solve the 3-satisﬁability problem12
12Remember that the instances of 3SAT are formulas in 3CNF, and the task is
to decide whether or not a given formula is satisﬁable.

5.3 Repeated Random Sampling and Satisﬁability
167
(3SAT) for instances of nontrivial size in acceptable time. 3SAT is a known
NP-hard problem, and we call attention to the fact that until now no random-
ized polynomial-time algorithm with a bounded error has been discovered for
any NP-hard problem. Our experience with general13 polynomial-time com-
putations point to the commonly accepted conjecture that NP-hard problems
are also hard for randomized polynomial time and so one does not hope for
exponential gaps in the time complexity between determinism and randomiza-
tion14. Therefore in the case of the NP-hard 3SAT problem, we aim to design
a practicable exponential randomized algorithm. Table 5.1 shows that the de-
sign of exponential algorithms can be a reasonable and worthy objective. The
values 10, 50, 100, and 300 in the ﬁrst row represent the input sizes, and the
ﬁrst column contains the running times considered. The particular items in
the table give the number of corresponding computer operations. If a number
is too large, we provide its number of digits only.
Table 5.1.
n
f(n)
10
50
100
300
n!
≈3.6 · 106 (65 digits) (158 digits) (625 digits)
2n
1024
(16 digits) (31 digits)
(91 digits)
2n/2
32
≈33 · 106 (16 digits)
(46 digits)
(1.2)n
≈6.19
9100
≈8.2 · 107
(24 digits)
10 · 2
√n
≈30
≈1345
10240
≈1.64 · 106
n2 · 2
√n
895
≈336158
1.024 · 107 ≈1.48 · 1011
n6
106
1.54 · 1010
1012
≈7.29 · 1014
If one considers approximately 1016 operations as the boundary of practi-
cally doable, then one observes that algorithms with a running time like n! or
2n are already not applicable for small input sizes. But algorithms with 2n/2
time complexity are useful for problem instances of size 100 and, for a time
complexity of (1.2)n, one can go still further. Algorithms with an exponen-
tial time complexity such as 10 · 2
√n or n2 · 2
√n can be successfully applied
for relatively large problem instances (Table 5.1), and are even faster than
polynomial-time algorithms with a time complexity of n6 for n ≤300. More-
over, these exponential algorithms run on inputs of size less than 300 in a few
13General is meant in the sense of unrestricted computing models that represent
algorithms.
14The most impressive presentation of the computational power of randomization
relative to determinism can be found by restricted frameworks of simple models of
computation such as ﬁnite automata, pushdown automata, communication proto-
cols, etc.

168
5 Success Ampliﬁcation and Random Sampling
seconds, something that cannot be said about an n6-algorithm on inputs of
size 100.
The aim of this section is to design a 1MC algorithm for 3CNF that works
in time
O

|F| · n
3
2 ·
4
3
n
for each formula in 3CNF over n variables.15 This running time is not achiev-
able by pure random sampling. If F is satisﬁable, but there are only a few
assignments satisfying F, then one would need in average Ω(2n) random sam-
ples to ﬁnd one of these satisfying assignments.
Exercise 5.3.9. Let F be a formula of n variables that is satisﬁed by exactly
k assignments to its variables. How many random samples from the set {0, 1}n
are necessary in order to ﬁnd an assignment satisfying F with a probability
of at least 1/2?
The idea of the design of the algorithm is simple. We repeat at most
O
√n ·
4
3
n
times
the following procedure. Choose one of the 2n assignments from {0, 1}n at
random and perform at most 3 · n steps of local search in order to ﬁnd an
assignment satisfying F. One step of local search consists of ﬂipping one bit
of the current assignment. Which particular bit is ﬂipped is partially decided
at random. A detailed description of the algorithm follows.
Algorithm SCH ¨ONING
Input: A formula F in 3CNF over n Boolean variables.
Step 1:
NUMBER := 0;
ATMOST :=

20 ·
√
3πn · ( 4
3)n
;
FOUND := FALSE;
{The variable NUMBER counts the number of random samples
executed. ATMOST gives the upper bound on the number of ran-
dom samples we are willing to perform. FOUND indicates whether
or not an assignment satisfying F was already found.}
Step 2:
while NUMBER < ATMOST and FOUND = FALSE do
begin
NUMBER := NUMBER + 1;
Generate at random an assignment α ∈{0, 1}n;
if F is satisﬁed by α then FOUND := TRUE;
15|F| denotes the length of the formula F, i.e., the input length. Clearly, n ≤|F|.

5.3 Repeated Random Sampling and Satisﬁability
169
M := 0;
while M < 3 · n and FOUND = FALSE do
begin
M := M + 1;
Find a clause C that is not satisﬁed by α.
{Since α does not satisfy F, such a clause must exist. If there
are several such clauses, it does not matter which one is
chosen.}
Pick one of the literals of C at random, and ﬂip the value of
its variable in order to get a new assignment α.
{Observe that α now satisﬁes the clause C.}
if α satisﬁes F then FOUND := TRUE;
end
end
Step 3:
if FOUND = TRUE then
output “F is satisﬁable”
else
output “F is not satisﬁable”.
The main diﬃculty is to show that random sampling with an enclosed
short, randomized local search has s substantially higher probability of success
(of ﬁnding an assignment satisfying F, assuming F is satisﬁable) than the pure
random sampling.
Theorem 5.3.10.∗
The algorithm SCH¨ONING is a 1MC algorithm for the
3SAT-problem that runs in time
O

|F| · n3/2 ·
4
3
n
for any instance F of n variables.
Proof. First, we analyze the time complexity in the worst case. Step 1 can
be performed in time O

n2 · log2 n

by repeated squaring16, and step 3 re-
quires only O(1) operations. The random sampling accompanied with the
local search described above is executed at most
!
20 ·
√
3πn ·
4
3
n"
times. Each local search consists of at most 3 · n steps, and each step can be
performed in time17 O(|F|). Hence, the time complexity of the second step
(and so the time complexity of the whole algorithm) is in
16see Appendix, Section A.2
17A formula F can be evaluated in time O(|F|) for every given assignment. During
the evaluation procedure, one ﬁxes which clauses are satisﬁed and which ones are
not.

170
5 Success Ampliﬁcation and Random Sampling
O

|F| · n
3
2 ·
4
3
n
.
In order to show that SCH¨ONING is a 1MC algorithm for 3SAT, we
analyze its failure probability. As usual, we distinguish two cases with respect
to the satisﬁability of F.
Let F be not satisﬁable. Then, the algorithm SCH¨ONING does not ﬁnd
any assignment that satisﬁes F and outputs the correct answer “F is not
satisﬁable” with certainty.
Let F be satisﬁable. To prove a lower bound on the success probability of
SCH¨ONING, we proceed in a way similar to that in Section 5.2; namely we
analyze the probability of ﬁnding a certain assignment α∗that satisﬁes F. Let
p be the probability that the algorithm SCH¨ONING ﬁnds α∗by a random
sample followed by at most 3·n steps of the local search described above. Our
ﬁrst aim is to show that
p ≥
1
2 ·
√
3πn ·
3
4
n
.
(5.7)
We start by partitioning the set {0, 1}n of all assignments of F into n + 1
classes with respect to their distances to α∗. Let α and β be two assignments.
We deﬁne the distance Dist (α, β) between α and β as the number of bits in
which they diﬀer (i.e., as the number of ﬂip operations necessary to get from
α to β, or vice versa). For every j = 0, 1, 2, . . ., n we deﬁne the j-th class as
Class (j) = {β ∈{0, 1}n | Dist (α∗, β) = j}.
These n + 1 classes are pairwise disjoint and so they build a partitioning of
{0, 1}n. Clearly,
Class (0) = {α∗},
and
|Class (j)| =
n
j

for j = 0, 1, . . ., n. The kernel of our analysis is to investigate the execution of
the local search as a run (movement) between these classes, i.e., to mimic the
local search by a sequence of corresponding classes. To visualize this we use
the graph in Figure 5.4. The vertex i of this graph corresponds to the class
Class(i) for i = 0, 1, . . ., n, and we say that the algorithm is situated in the
vertex i of the current assignment, α is in Class(i). Our goal is to achieve
the vertex 0. Every local step18 changes exactly one bit of the assignment,
and so corresponds to the movement to one of the two neighboring vertices.
Hence, executing a local step one can approach the vertex 0 by decreasing the
distance by exactly 1, or one increases the distance to the vertex 0 by 1. The
only exceptions are vertices 0 and n. One can move from vertex n only in the
18performed by ﬂipping a bit of the current assignment

5.3 Repeated Random Sampling and Satisﬁability
171
0
1
1
i
n−1
n−2
n
≥1
3
≥1
3
≥1
3
≥1
3
≥1
3
≥1
3
≤1
3
≤2
3
≤2
3
≤2
3
≤2
3
≤2
3
. . .
. . .
. . .
. . .
Fig. 5.4.
direction of vertex 0 and we do not want to leave vertex 0 anymore.19 Now,
we are claiming that, for j = 1, 2, . . ., n −1,
the probability of moving from vertex j to vertex j −1 in one
local search step is at least 1
3.
(5.8)
This can be shown as follows. Let α be the current assignment from
Class (j) and let C be a clause that is not satisﬁed by α. The clause C contains
at most 3 literals and so C depends on at most 3 variables. The assignment
α does not satisfy any of these literals. Since α∗satisﬁes F, and so C, too,
α∗must diﬀer from α in at least one of these variables of C. The algorithm
SCH¨ONING chooses one of these variables for ﬂipping at random, and so one
has probability of at least 1/3 to approach α∗(i.e., to decrease the distance
to α∗by 1). Hence, the complementary probability20 of moving away from α∗
(of increasing the distance from α∗by 1) is at most 2/3.
In what follows, we analyze for all i, j, with i ≤j ≤n, the probability qj,i
that the algorithm SCH¨ONING starting in the class Class(j) (in the vertex
j) reaches α∗(the vertex 0) in exactly j + 2 · i local steps, or more precisely
in j + i steps toward α∗and i steps in the opposite direction (i.e., toward the
vertex n). Since
j + 2 · i ≤3 · n,
such a run of the algorithm is possible. To establish a lower bound on qj,i, we
describe the movement of the algorithm during the j +2·i steps on the graph
in Figure 5.4 by a word (string) in {+, −}j+2·i. A move toward α∗(from the
left to the right in Figure 5.4) is represented by +, and a move in the opposite
direction (from the right to the left in Figure 5.4) is represented by −. The
number of words over {+, −} of length j + 2 · i with exactly i −symbols is
j + 2 · i
i

.
But not every one of these strings corresponds to a possible computation from
vertex j to vertex 0 in exactly j + 2 · i steps. Only those words correspond to
possible runs for which every suﬃx contains at least as many + symbols as
19If the algorithm achieves vertex 0, then it halts.
20As already observed, there is no possibility of remaining in the class Class (j).

172
5 Success Ampliﬁcation and Random Sampling
−symbols. The number of such words is at least one third21 of the number
of strings from {+, −}j+2·i with exactly i + j symbols + and so there are at
least
1
j + 2i ·
j + 2 · i
i

(5.9)
such words. Let w be an arbitrary word of this set. The word w can be viewed
as the representation of the event Event(w) containing all computations22
whose movement in the graph is described by w. Since the symbol + occurs
with a probability of at least 1/3 and the −symbol occurs with a probability
of at most 2/3,
Prob(Event(w)) ≥
1
3
j+i
·
2
3
i
(5.10)
for each w of the string set considered. Combining (5.9) and (5.10), we obtain
qj,i ≥
1
j + 2i ·
j + 2 · i
i

·
1
3
j+i
·
2
3
i
.
(5.11)
For j = 0, 1, 2, . . ., n, let qj be the probability of reaching α∗from an
α ∈Class (j) in at most 3 · n local steps. Since j + 2 · i ≤3 · n for all
0 ≤i ≤j ≤n, one obtains
qj ≥
j

i=0
qj,i
(5.12)
for each j ∈{1, 2, . . ., n}. Note that q0 = 1. Inserting (5.11) in (5.12), we
obtain
qj ≥
j

i=0

1
j + 2i ·
j + 2 · i
i

·
1
3
j+i
·
2
3
i
> 1
3 ·
3 · j
j

·
1
3
2·j
·
2
3
j
{We took the element with i = j of the sum
as a lower bound for the whole sum.}
Inserting the Stirling formula (Section A.3)
r! =
√
2πr
r
e
r
·

1 +
1
12r + O
 1
r2

∼
√
2πr ·
r
e
r
,
21We show in Lemma A.3.69 that the number of such words is exactly

j + 2i −1
i

−

j + 2i −1
i −1

=

j + 2i
i

·
1
j + 2i.
22as elementary events

5.3 Repeated Random Sampling and Satisﬁability
173
we obtain
qj ≥1
3 ·
(3 · j)!
(2 · j)! · j! ·
1
3
2·j
·
2
3
j
≥1
3 ·
√2π · 3j ·
 3·j
e
3·j
√2π · 2j ·
 2·j
e
2·j · √2πj ·
 j
e
j ·
1
3
2·j
·
2
3
j
= 1
3 ·
√
3
2 · √πj · 33·j
22·j ·
1
3
2·j
·
2
3
j
=
1
2 · √3πj ·
1
2
j
.
(5.13)
Since the random samples (initial assignments) are chosen uniformly, the car-
dinalities of the classes Class (j) determine the probability pj, that a random
sample is in Class(j), i.e.,
pj =
n
j

/2n.
(5.14)
Thus, we obtain
p = Prob

SCH¨ONING ﬁnds α∗by a random sample fol-
lowed by a local search of at most 3n steps

≥
n

j=0
pj · qj.
(5.15)
Inserting (5.13) and (5.14) into (5.15), we get
p >
n

j=0
1
2
n
·
n
j

·

1
2 · √3πj ·
1
2
j
≥
1
2 ·
√
3πn
·
1
2
n
·
n

j=0
n
j

·
1
2
j
=
1
2 ·
√
3πn ·
1
2
n
·

1 + 1
2
n
{One can write
n
j

·
 1
2
j as
n
j

·
 1
2
j ·1n−j and then apply
the binomial formula.}
=
1
2 ·
√
3πn ·
3
4
n
= /p.
(5.16)
Thus, the probability that the algorithm does not ﬁnd any assignment satis-
fying F by one random sample followed by the considered local search is at
most
1 −/p.

174
5 Success Ampliﬁcation and Random Sampling
Therefore, the error probability after t independent attempts of the algorithm
is at most23
(1 −/p)t ≤e−/p·t.
(5.17)
Taking t = ATMOST = 20 ·
√
3πn ·
 4
3
n and together with (5.16) inserting it
into (5.17), one obtains
ErrorSCH ¨ONING(F) ≤(1 −/p)t ≤e−10 < 5 · 10−5.
Thus, we have proved that the algorithm SCH¨ONING is a one-sided-error
Monte Carlo algorithm for 3SAT.
⊓⊔
We have seen that a clever execution of random sampling can essentially
help reduce the number of random samples. The idea presented here can also
be extended for the kSAT problem for an arbitrary, ﬁxed positive integer k.
Exercise 5.3.11. Extend the algorithm SCH¨ONING for 4SAT. Observe that
the lower bound on the probability of moving toward α∗in a local step de-
creases to 1/4 in this case. How many repetitions of random sampling followed
by a local search are necessary to get a constant success probability?
Exercise 5.3.12.∗Prove, for every positive integer k ≥5, that the concept
of Sch¨oning provides a 1MC-algorithm for kSAT that works in time
O

|F| · P(n) ·

2 −2
k
n
for a polynomial P.
5.4 Random Sampling and Generating Quadratic
Nonresidues
In Section 5.3 we indicated that it is not realistic to try to design bounded-
error randomized polynomial-time algorithms for NP-hard problems. But this
is far from the claim that there do not exist any randomized polynomial-time
algorithms for problems that cannot be solved in deterministic polynomial
time. The world between the class P of decision problems solvable in deter-
ministic polynomial time and the class of NP-hard problems can be very rich
of problems of distinct diﬃculty. There are several problems for which
(i) one does not know any deterministic polynomial-time algorithm, and
(ii) there are no proofs presenting their NP-hardness.
23Lemma A.3.59

5.4 Random Sampling and Generating Quadratic Nonresidues
175
A problem of this kind and of enormous theoretical as well as practical
importance is the factorization of natural numbers. Though the best known
deterministic algorithms for the factorization run in exponential time, most
researchers believe that factorization is not NP-hard. Since we consider the
class of problems solvable by bounded-error randomized polynomial-time al-
gorithms instead of the class P as the class of practically solvable problems,
the research focuses on the design of eﬃcient randomized algorithms for prob-
lems outside of P, but not NP-hard. One does not know any randomized
polynomial-time algorithm for factorization,24 but there are other problems
with properties (i) and (ii) for which eﬃcient randomized algorithms were
discovered. An example already presented is the 1MC algorithm for the com-
parison of two polynomials that is based mainly on the ﬁngerprinting method.
Here, we go even further and design an eﬃcient Las Vegas algorithm for a
problem with properties (i) and (ii).
In what follows, we consider the problem of generating a quadratic non-
residue modulo p for a given prime p. A quadratic residue in the ﬁeld25 ZZp
is any element a ∈ZZp such that
a = x2 mod p
for an x ∈ZZp.
A quadratic nonresidue is any number b ∈ZZp such that
d2 ̸≡b (mod p)
for all d ∈ZZp, i.e., every element of ZZp that is not a quadratic residue. The
problem of our current interest is the following one:
Generation of a quadratic nonresidue
Input: A prime p > 2.
Output: A quadratic nonresidue modulo p.
Usually one considers this problem for primes that are several hundreds of
digits long. Hence, it is not possible to check all26 elements of ZZp, whether
they are quadratic residues or not. Note that the size of the input p is the
length ⌈log2(p + 1)⌉of its binary representation and so |ZZp| = p is exponen-
tial in input size.
24Note that we do know of a polynomial-time quantum algorithm for factorization.
Currently we are not able to build a quantum computer working with more than a
few bits, but quantum computing can be viewed as a generalization of randomized
computations, and this viewpoint opens a lot of interesting questions about the
limits of physically based computers.
25Note that ZZp is a ﬁeld iﬀp is a prime (a direct consequence of Theorem A.2.27).
26their number is larger than the number of protons in the known universe.

176
5 Success Ampliﬁcation and Random Sampling
It is also remarkable that the “dual” problem of generating a quadratic
residue is trivial. It takes an arbitrary element x of Zp and computes the
quadratic residue x2 mod p. Moreover, 1 is a quadratic residue for every prime
p.
Exercise 5.4.13. Determine all quadratic nonresidues for
(i) p = 5,
(ii) p = 11,
(iii) p = 17.
We aim to show that by applying random sampling one can solve this
problem eﬃciently. One takes a few samples from {1, 2, . . ., p−1} at random,
and there is a quadratic nonresidue among these samples with a reasonably
high probability. To convince the reader that this very simple idea really
works, we have to prove the following two facts:
(A) For every prime p and every a ∈ZZp, one can eﬃciently decide (in a deter-
ministic way) whether a is a quadratic residue or a quadratic nonresidue
modulo p.
(B) For every prime p exactly half of the elements of ZZp −{0} are quadratic
nonresidues, i.e., a random27 sample from {1, 2, . . ., p −1} provides a
quadratic nonresidue with probability 1/2.
First, we present Euler’s criterion in order to prove (A). In what follows
we also use the symbol −1 to denote p −1 as the inverse element to 1 with
respect to ⊕mod p in Zp. All notions and results of the number theory used
in what follows are presented in detail in Section A.2.
Theorem 5.4.14. Euler’s Criterion
Let p, with p > 2, be a prime. For every a ∈{1, 2, . . ., p −1},
(i) if a is a quadratic residue modulo p, then
a(p−1)/2 ≡1 (mod p),
and
(ii) if a is a quadratic nonresidue modulo p, then
a(p−1)/2 ≡p −1 (mod p).
Proof. Following Fermat’s Little Theorem (Theorem A.2.28)
ap−1 ≡1 (mod p),
i.e.,
ap−1 −1 ≡0 (mod p)
(5.18)
27with respect to the uniform distribution

5.4 Random Sampling and Generating Quadratic Nonresidues
177
for all a ∈{1, 2, . . ., p −1}.
Since p > 2 and p is odd, there is a28 p′ ≥1 such that
p = 2 · p′ + 1.
(5.19)
Inserting (5.19) into (5.18), one obtains
ap−1 −1 = a2·p′ −1 = (ap′ −1) · (ap′ + 1) ≡0 (mod p).
(5.20)
If a product of two integers is divisible by a prime, then one of the factors
must be divisible29 by p. Therefore (5.20) implies
a(p−1)/2 −1 ≡0 (mod p) or a(p−1)/2 + 1 ≡0 (mod p),
and so
a(p−1)/2 ≡1 (mod p) or a(p−1)/2 ≡−1 (mod p).
In this way we have established that
a(p−1)/2 mod p ∈{1, p −1}
(5.21)
for every a ∈{1, 2, . . ., p −1}. Now, we are ready to prove (i) and (ii).
(i) Let a be a quadratic residue modulo p.
Then there exists an x ∈ZZp such that
a ≡x2 (mod p).
Since Fermat’s Little Theorem implies30 xp−1 ≡1 (mod p), we obtain
a(p−1)/2 ≡

x2(p−1)/2 ≡xp−1 ≡1 (mod p).
(ii) Let a be a quadratic nonresidue modulo p.
Following (5.21) it is suﬃcient to show that
a(p−1)/2 mod p ̸= 1.
Since (ZZ∗
p, ⊙mod p) is a cyclic group,31 there exists a generator g of ZZ∗
p.
Since a is a quadratic nonresidue, a must be an even power of g, i.e.,
a = g2·l+1 mod p
for an integer l ≥0. Hence,
28p′ = (p −1)/2
29This is a direct consequence of the Fundamental Theorem of Arithmetics about
the unambiguousity of factorization (Theorem A.2.3).
30Theorem A.2.28
31Recall that ZZp −{0} = ZZ∗
p for every prime p.

178
5 Success Ampliﬁcation and Random Sampling
a(p−1)/2 ≡

g2·l+1(p−1)/2 ≡gl·(p−1) · g(p−1)/2 (mod p).
(5.22)
The Fermat’s Little Theorem implies gp−1 mod p = 1, and so
gl·(p−1) ≡

gp−1l ≡1l ≡1 (mod p).
(5.23)
Inserting (5.23) into (5.22), we obtain
a(p−1)/2 ≡g(p−1)/2 (mod p).
Since g is a generator of (ZZ∗
p, ⊙mod p), the order of g is p, and so
g(p−1)/2 mod p ̸= 1.
Thus, a(p−1)/2 mod p ̸= 1, too and, following (5.21), we obtain
a(p−1)/2 mod p = −1 = p −1.
⊓⊔
Euler’s Criterion provides a simple way for testing whether an element
a ∈{1, 2, . . ., p −1} is a quadratic residue or not. It is suﬃcient to compute
the number
a(p−1)/2.
We know that this number can be computed in O(log2 p) operations32 over
ZZp by the method of repeated squaring (Section A.2). In this way, the proof
of (A) is completed.
The following theorem proves assertion (B).
Theorem 5.4.15. For every odd prime33 p, exactly half of the nonzero ele-
ments of ZZp are quadratic residues modulo p.
Proof. Let
Quad (p) = {12 mod p, 22 mod p, . . ., (p −1)2 mod p}
be the set of all quadratic nonresidues in ZZ∗
p. Since every element from ZZ∗
p =
{1, 2, . . ., p −1} is either a quadratic residue or a quadratic nonresidue, it is
suﬃcient to show that
|Quad (p)| = (p −1)
2
.
(5.24)
We prove the equality (5.24) by separately proving the inequalities34
|Quad (p)| ≤(p −1)
2
and |Quad (p)| ≥(p −1)
2
.
32in O
(log2 p)3
binary operations
33i.e., for every prime o ≥3
34Note that for solving our problem by random sampling, it is suﬃcient to prove
the inequality |Quad (p)| ≤(p−1)
2
.

5.4 Random Sampling and Generating Quadratic Nonresidues
179
(i) For every x ∈{1, 2, . . ., p −1},
(p −x)2 = p2 −2 · p · x + x2 = p · (p −2 · x) + x2 ≡x2 (mod p).
Therefore,
|Quad (p)| ≤(p −1)
2
.
(ii) For the opposite inequality, it is suﬃcient to show that the congruence
x2 ≡y2 (mod p)
(5.25)
has at most one solution y ∈{1, 2, . . ., p−1} diﬀerent from x. Without loss
of generality, we assume y > x, i.e., y = x + i for an i ∈{1, 2, . . ., p −2}.
Since
y2 = (x + i)2 = x2 + 2 · i · x + i2,
the congruence (5.25) implies
2 · i · x + i2 = i · (2 · x + i) ≡0 (mod p).
Since ZZp is a ﬁeld,35 and i ̸≡0 (mod p),
2 · x + i ≡0 (mod p).
(5.26)
Since i = −(2x) is the only solution36 of the congruence (5.26),
|Quad (p)| ≥(p −1)
2
.
⊓⊔
Now, we are ready to present our algorithm for generating a quadratic
nonresidue in Zp for any given prime p.
Algorithm NQUAD
Input: A prime p.
Step 1: Choose uniformly an a ∈{1, 2, . . ., p −1} at random.
Step 2: Compute
A := a(p−1)/2 mod p
by the method of repeated squaring.
35More precisely, if the product of two elements in a ﬁeld is 0, then one of the
elements must be 0, too. But here one can argue in a simplier way without using
algebra. If a product of two integers is divisible by a prime p, then one of the factors
must be divisible by p (Corollary A.2.4).
36Every element i of the group (ZZp, ⊕mod p) has exactly one inverse element
with respect to ⊕mod p. If 2x < p, then i = p −(2·x). If 2·xp, then i = −(2·x −p).

180
5 Success Ampliﬁcation and Random Sampling
Step 3:
if A = p −1 then
output “a”
else
output “?”
The above proved claims (A) and (B) imply that
(i) NQUAD does not make any error37, and
(ii) NQUAD ﬁnds38 a quadratic nonresidue with the probability 1/2.
Hence, NQUAD is a Las Vegas algorithm for generating a quadratic non-
residue. Its running time is in O(log2 p) when taking one time unit for exe-
cuting an operation over ZZp and in O

(log2 p)3
when counting the number
of binary operations.
Exercise 5.4.16. Modify the algorithm NQUAD in such a way that it always
halts39 with a quadratic nonresidue (i.e., the answer “?” never appears). Ana-
lyze the expected running time of your modiﬁed NQUAD and prove that the
probability of executing an inﬁnite computation is 0.
Exercise 5.4.17. Let p be a prime and let k ≤log2 p be a positive integer.
Design an eﬃcient Las Vegas algorithm that computes k pairwise distinct
quadratic nonresidues modulo p.
We have shown above that the problem of generating quadratic non-
residues is not hard because it can be solved eﬃciently by a randomized
algorithm. The main reason for this success is that half the elements of
{1, 2, . . ., p −1} are quadratic nonresidues. Hence, one could think that it
is possible to ﬁnd a quadratic nonresidue in ZZp −{0} eﬃciently by a suit-
able deterministic search in {1, 2, . . ., p −1}. Unfortunately, until now no one
has been able to discover a deterministic polynomial-time strategy for ﬁnding
a quadratic nonresidue modulo p in {1, 2, . . ., p −1}. If there does not ex-
ist any eﬃcient deterministic algorithm for this task, one could say that the
distribution of quadratic nonresidues in {1, 2, . . ., p −1} can be considered
random40 (chaotic). On the other hand, we have to mention that there is an
indication for the existence of some structure (order) in Zp. It is well known
that if the famous extended Riemann’s Hypothesis holds, then Zp must con-
tain a quadratic nonresidue among its O

(log2 p)2
smallest elements, i.e., a
quadratic nonresidue can be found deterministically by simply checking all
these smallest elements of Zp.
37This is a direct consequence of the Euler’s criterion (Theorem 5.4.14).
38This is a consequence of claim (B) (Theorem 5.4.15).
39if it halts at all
40Recall the discussion about the random distribution of witnesses in the set of
witness candidates.

5.5 Summary
181
5.5 Summary
In this chapter we have presented ampliﬁcation not only as a method for
reducing the error probability of already designed randomized algorithms,
but also as a method that can be the core of algorithm design. The design
of randomized algorithms for the MIN-CUT problem exempliﬁes this point
of view on ampliﬁcation. We have seen that it can be promising to exchange
some parts of randomized computations having high error probability with
deterministic ones. Repeating diﬀerent parts of a randomized computation
diﬀerently many times with respect to their success probability may also save
a lot of computer work, and so be very helpful. Both these approaches lead
to the design of randomized algorithms for the MIN-CUT problem that are
more eﬃcient than any naive application of ampliﬁcation based on repeating
the entire computations on a given input.
Some exponential algorithms are not only successfully applicable for realis-
tic input sizes, but, for some applications, even more eﬃcient than polynomial-
time algorithms whose running time is bounded by a polynomial of a higher
degree. Therefore it is meaningful to try to design algorithms with running
time in O(p(n) · cn) for a polynomial p and a constant c < 2. Combining ran-
dom sampling with local search we have designed an eﬃcient randomized algo-
rithm for 3SAT that, for any satisﬁable formula, ﬁnds a satisfying assignment
with probability at least Ω

(n1/2) · (4/3)n−1
. Executing O(n · (4/3)n) in-
dependent runs of this algorithm, one gets a Monte Carlo algorithm for 3SAT.
The essential point of this algorithm design is that pure random sampling can-
not assure success probability greater than 2−n. Extending random sampling
by a suitable local search increases the success probability to n−1/2 · (3/4)−n.
There are computing tasks for which on the one hand no deterministic
polynomial-time algorithms are known, and, on the other hand, no one is
able to prove that these problems are NP-hard. This world between P and
NP-hardness is the central area for applying randomization. Famous exam-
ples of problems in this world are factorization of integers, equivalence of
two polynomials, and the generation of quadratic nonresidues. An eﬃcient
one-sided-error Monte Carlo algorithm for the equivalence of two polynomials
has been presented in Chapter 4. Here, applying random sampling, we have
even designed an eﬃcient Las Vegas algorithm for generating a quadratic non-
residue. The method of random sampling is especially successful in situations
where one searches for an object with some special properties in a set of ob-
jects, in which the objects of interest are randomly distributed and there is
an abundance of them. It may also happen that the objects of our interest
are not randomly distributed in the set of all objects (i.e., the set has some
structure), but we are not able to recognize the order of their distribution.
Also, in this case of our poor knowledge, applying random sampling is the
best we can do.
Further successful applications of the methods of random sampling and
ampliﬁcation are presented in the comprehensive textbook of Motwani and

182
5 Success Ampliﬁcation and Random Sampling
Raghavan [MR95]. Karger [Kar93] designed the algorithm CONTRACTION
for MIN-CUT, and the most eﬃcient version was developed by Karger and
Stein [KS93]. The exponential randomized algorithm for 3SAT is due to
Sch¨oning [Sch99]. The Las Vegas algorithm for generating quadratic non-
residues was used by Adleman, Manders, and Miller [AMM77] as a subroutine
for computing roots of quadratic residues.

6
Abundance of Witnesses
The greatest obstacle in ﬁnding the truth
is not the lie itself,
but that which seems to be the truth.
Arthur Schopenhauer
6.1 Objectives
The method of abundance of witnesses is a real jewel of the design of random-
ized algorithms. Not only because its applications typically require involved
considerations related to nontrivial discoveries of computer science and math-
ematics, but also, and especially, because of its relation to the fundamental
question of whether or not randomization can be more eﬃcient than the de-
terministic computation mode.
A witness for an input x is additional information, and with its knowledge
computing the output for x is substantially more eﬃcient than without this
information. To apply the paradigm of abundance of witnesses, one needs, for
every problem instance, a set of candidates for a witness, in which there is an
abundance1 of witnesses. Then, it suﬃces simply to choose an element from
the set of candidates at random and one obtains a witness with a reasonable
probability. The question of whether, for a given computing task, randomized
algorithms can work faster than any deterministic algorithm is strongly related
to the question of whether the witnesses are randomly distributed in the set of
candidates. If there is an order in the set of candidates, and one can eﬃciently
compute this order from the given problem instance, then one can ﬁnd a
witness eﬃciently in a deterministic way, too. Only if this is impossible for any
kind of witnesses, can the randomized algorithms be essentially more eﬃcient
than their deterministic counterparts. Whether a distribution of witnesses in
a set of candidates is truly random or not is very hard to decide. It may also
happen that there is a structure in the distribution of witnesses, but nobody
is able to recognize it. Even if one believes in the existence of an order on the
set of candidates but is unable to ﬁnd it, it is proﬁtable to apply the method
of abundance of witnesses. In this way one can eﬃciently solve problems even
though she or he was not successful in discovering the nature of the problem
1This usually means that the ratio between the cardinality of the set of candidates
and the number of witnesses in the set is a constant.

184
6 Abundance of Witnesses
considered. A good example of this is primality testing. Initially, for hundreds
of years no one knew a method2 better than trying to divide a given integer
n by all integers less than or equal to √n. In the middle of the 1970s the
ﬁrst eﬃcient randomized algorithms for primality testing were developed, but
we had to wait another 25 years to discover a deterministic polynomial-time
algorithm.
The aim of this chapter is to explain some basic ideas of and approaches to
eﬃcient randomized primality testing. All eﬃcient randomized algorithms for
primality testing are based on the method of abundance of witnesses, and so
for a long time the central open question in this area was whether, for all kinds
of witnesses, the witnesses are indeed randomly distributed in the candidate
set or whether one is only unable to ﬁnd an existing order in their distribution.
In 2002 a deﬁnition of witnesses was discovered with the property that if p is
composite, then there must always be a witness of p’s compositeness among
the smallest candidates. This discovery resulted in a deterministic algorithm
for primality testing running in time O

(log2 n)11
. Though this fascinating
result is of enormous theoretical importance, this deterministic algorithm is
no competitor for the fast randomized algorithms in current applications.
In contrast with the natural and easily discovered kinds of witnesses used
in the presentation of applications of ﬁngerprinting3 in Chapter 4, the search
for witnesses suitable for primality testing is a little bit more complicated.
To provide an accessible start to this search, we begin in Section 6.2 with a
few simple ideas that are not suﬃcient for getting an eﬃcient primality test
for all odd integers, but at least for getting most of them. Based on these
ideas, we develop in Section 6.3 a randomized algorithm for primality testing
that already works for all odd integers. In Section 6.4 we show how one can
generate large random primes.
The fundamentals of algebra and number theory presented in the appendix
are of key importance for understanding of the topic of this chapter. Especially
useful are Fermat’s Little Theorem (Theorem A.2.28), the Chinese Remainder
Theorem (Theorem A.2.34), and Lagrange’s Theorem (Theorem A.2.48).
6.2 Searching for Witnesses for Primality Testing
Here we are trying to solve primality testing, which is the following decision
problem. For a given positive integer n, decide whether n is a prime of a
composite number. Our aim is to design an eﬃcient, randomized algorithm
for primality testing. Since the input length of n is the length ⌈log2(n + 1)⌉
of its binary representation, we aim to design an algorithm running in time
2Observe that the input size of a positive integer n is ⌈log2(n + 1)⌉, and so √n
is exponential in input size.
3Remember that the method of ﬁngerprinting can be viewed as a special case of
the method of abundance of witnesses and so when applying ﬁngerprinting one may
speak about witnesses.

6.2 Searching for Witnesses for Primality Testing
185
O((log2 n)c) for a small constant c. A small polynomial degree c is a real
necessity here, because we have to work for security reasons with primes of
several hundreds of digits in practice.4
The usual way of deﬁning primes is the following one:
A positive integer n is a prime if and only of it does not have any
factor (any nontrivial divisor), i.e., if and only if it is not divisible by
any number from {2, 3, . . ., n −1}.
This deﬁnition provides us the following simple method for testing primal-
ity.
Algorithm NAIV
Input: A number n ∈IN −{0, 1, 2}.
I := 2
PRIME := TRUE
while I < n and PRIME = TRUE do
begin
if n mod I = 0 then PRIME := FALSE;
I := I + 1
end
if PRIME = TRUE then
output “n is a prime
else
output “n is composite”
We immediately observe that the algorithm NAIV can be improved as
follows. Instead of testing all integers from {2, 3, . . ., n −1} for divisibility of
n, it suﬃces to consider the integers from {2, 3, . . ., ⌊√n⌋}. This is a direct
consequence of the fact that n = p · q implies that the smallest integer of p
and q must be smaller or equal to √n. But also after this improvement the
running time of the algorithm is at least √n = 2(log2 n)/2, and so exponential
in input size. For realistic inputs n of values about 10500, the complexity is
incomparably larger than the number of protons in the known universe.
Therefore, we aim to design a randomized algorithm, instead of a determin-
istic one for primality testing. Our design strategy is based on the paradigm
of abundance of witnesses, and so
we are searching for a kind of witness that is suitable for an eﬃcient
proof of the assertion that “n is composite”.
Recall the following requirements for a suitable deﬁnition of witnesses:
4In the area of secret communication, especially in cryptographic applications
such as online banking or e-commerce.

186
6 Abundance of Witnesses
(i) A witness of the fact “n is composite” has to oﬀer a possibility of eﬃciently
proving this fact.
(ii) Every candidate for a witness must be eﬃciently checkable, whether or
not it is a witness.
(iii) The set of candidates must be speciﬁed in such a way that there is an
abundance of witnesses in the set of candidates.
First, let us observe that every kind of witness satisfying (i), (ii), and (iii)
assures the design of an eﬃcient randomized algorithm. We do not force that
the distribution of witnesses in the set of candidates has to be random. The
opposite is true; we are happy to discover an order on the set of candidates
that could be helpful for eﬃciently creating a witness deterministically. In
such a case, the method of abundance of witnesses would even lead to an
eﬃcient deterministic algorithm.
Let PRIM denote the set of all primes. The simplest idea would be to say:
“number a ∈{2, . . ., n −1} is a witness of the fact “n /∈PRIM” if
and only if a divides n.”
Clearly, this deﬁnition of a witness fulﬁlls the constraints (i) and (ii). For
many integers n, the constraint (iii) on the abundance of witnesses is fulﬁlled,
too. But, for numbers n = p·q for two primes p and q, there are only two such
witnesses of the fact “n /∈PRIM”. The probability of choosing one of them
from the set {2, 3, . . ., n −1} at random is only 2/(n −2) and the expected
number of random samples for getting a witness is in Ω(n). Therefore, this
deﬁnition of a witness is not suitable.
The next attempt to ﬁnd a good kind of witness is based on Fermat’s
Little Theorem (Theorem A.2.28).
For every prime p and every a ∈{1, 2, . . ., p −1},
ap−1 mod p = 1.
Observe that this is no deﬁnition of primes, but only an implication, that
says what has to be fulﬁlled by each prime. Though Fermat’s Little Theorem
has been used for the design of randomized primality testing. The idea was
to deﬁne a kind of witness as follows:
A number a ∈{1, 2, . . ., n −1} is a witness of the fact “n /∈PRIM”
if and only if
an−1 mod n ̸= 1.
Since one can eﬃciently compute the value an−1 mod n by repeated squar-
ing (Section A.2), this kind of witness satisﬁes the constraints (i) and (ii). Most
composite numbers have a lot of witnesses of this kind, and so this concept
of witnesses was used even for generating large primes.5 Unfortunately this
5Currently, one calls the randomized primality testing based on the little Fer-
mat’s Theorem a pseudotesting of primality.

6.2 Searching for Witnesses for Primality Testing
187
simple primality testing does not work for all positive integers. There even
exist numbers n such that n is not prime, but
an−1 mod n = 1 for all a ∈{1, . . ., n −1}.
(6.1)
For such composite numbers there is no witness of “n /∈PRIM”. The com-
posite numbers satisfying (6.1) are called Carmichael numbers. The smallest
Carmichael numbers are 561 = 3·11·17, 1105 = 5·13·17, and 1729 = 7·13·19.
Other bad news is that there are inﬁnitely many Carmichael numbers.
Thus, there is no way out other than to continue in our search for a suitable
kind of witness. Obviously, it is suﬃcient to deal with odd integers n > 2,
because the even integers greater than 2 are composite and divisibility by 2
can be checked easily. To perform the ﬁrst successful step in the search for
good kinds of witnesses, we consider some diﬀerent possibilities for deﬁning
primes. It is well known6 that
n is a prime ⇔(ZZn −{0}, ⊙mod p) is a group7
(6.2)
or equivalently
n is a prime ⇔(ZZn, ⊕mod p, ⊙mod p) is a ﬁeld.
Unfortunately, a naive testing of the properties of these algebraic structures,
and so of determining whether an algebra is a group or a ﬁeld, requires the
same amount of work as the naive primality test. The usefulness of these
characterizations of primes is in their leading us to the following new, useful
deﬁnition of primes.
Theorem 6.2.1. Let p > 2 be an odd integer. Then
p is a prime ⇔a
(p−1)
2
mod p ∈{1, p −1} for all a ∈ZZp −{0}.
Proof. We prove the particular implications separately.
(i) Let p be a prime.
Since p > 2 and p is odd, one can write p as
p = 2 · p′ + 1
for an p′ = (p−1)
2
≥1. Following the little Fermat’s Theorem we have
ap−1 ≡1 (mod p)
(6.3)
for all a ∈ZZp −{0}. Since
ap−1 = a2·p′ =

ap′ −1

·

ap′ + 1

+ 1,
6Theorem A.2.27
7Theorem A.2.27

188
6 Abundance of Witnesses
(6.3) implies

ap′ −1

·

ap′ + 1

≡0 (mod p).
Since p is a prime, p must divide

ap′ −1

or

ap′ + 1

, and so
ap′ −1 ≡0 (mod p)
or
ap′ + 1 ≡0 (mod p).
(6.4)
Inserting p′ = (p−1)
2
in (6.4), we obtain
a
(p−1)
2
≡1 (mod p)
or
a
(p−1)
2
≡−1 ≡p −1 (mod p).
(ii) Let p > 2 be an odd integer such that
c
(p−1)
2
mod p ∈{1, p −1} for all c ∈ZZp −{0}.
We prove by contradiction that p is a prime. Let p = a · b be a composite
number. From our assumption,
a
(p−1)
2
mod p ∈{1, −1} and b
(p−1)
2
mod p ∈{1, −1}.
Since ⊙mod p is commutative,
(a · b)
(p−1)
2
mod p = a
(p−1)
2
· b
(p−1)
2
mod p ∈{1, −1}.
(6.5)
Since a · b = p, we have
0 = p mod p = p
(p−1)
2
mod p = (a · b)
(p−1)
2
,
which contradicts (6.5).
⊓⊔
This new deﬁnition of primes leads to the following deﬁnition of witnesses.
Let n be an odd integer, n ≥3. A number a ∈{1, 2, . . ., n−1}
is a witness of the fact “n /∈PRIM”, if and only if
a(n−1)/2 mod n /∈{1, n −1}.
(6.6)
Clearly, this kind of witness satisﬁes the conditions (i) and (ii). The fol-
lowing theorem shows that this deﬁnition of witnesses assures the abundance
of witnesses for at least every second odd integer greater than 2.
Theorem 6.2.2. For every positive integer n with an odd (n −1)/2 (i.e., for
n ≡3 (mod 4)),

6.2 Searching for Witnesses for Primality Testing
189
(i) if n is a prime, then
a(n−1)/2 mod n ∈{1, n −1}
for all a ∈{1, . . ., n −1}, and
(ii) if n is composite, then
a(n−1)/2 mod n /∈{1, n −1}
for at least half of the elements a from {1, 2, . . ., n −1}.
Proof. The assertion (i) has already been proved in Theorem 6.2.1. Hence, it
remains to show (ii).
Let n be a composite number such that n ≡3 (mod 4). Our task is to
show that at least half of the elements from {1, 2, . . ., n −1} are witnesses of
the fact “n /∈PRIM”.
Let
WITNESS = {a ∈{1, . . ., n −1} | a(n−1)/2 mod n /∈{1, n −1}}
be the set of all witnesses of “n /∈PRIM”, and let
EULER = {a ∈{1, . . ., n −1} | a(n−1)/2 mod n ∈{1, n −1}}
be the complementary set of non-witnesses. The elements in EULER are called
Eulerian numbers and we prefer this term to the term non-witnesses in what
follows. Our proof strategy is to show that there exists an injective (one-to-
one) mapping hb from EULER to WITNESS that directly implies
|EULER| ≤|WITNESS|.
WITNESS
EULER
a
hb
hb(a)
Fig. 6.1.
Assume that b is an element from the set WITNESS, for which there exists
a multiplicative inverse b−1 in the group (ZZ∗
n, ⊙mod n). If such a b exists, one
could deﬁne hb by
hb(a) = a · b mod n.
Next, we will show that hb is an injective mapping from EULER to
WITNESS.

190
6 Abundance of Witnesses
For every a ∈EULER, hb(a) = a · b is not in EULER, and so is in
WITNESS, because
(a · b)
(n−1)
2
mod n =

a
(n−1)
2
mod n

·

b
(n−1)
2
mod n

= ± b
(n−1)
2
mod n /∈{1, n −1}
{Since a
(n−1)
2
mod n ∈{1, n −1} and
b ∈WITNESS}
Thus, we have proved that hb is a mapping from EULER to WITNESS.
To show that hb is injective, one has to prove
for all a1, a2 ∈EULER, a1 ̸= a2 implies hb(a1) ̸= hb(a2).
We prove this in an indirect way. Assume hb(a1) = hb(a2), i.e., assume
a1 · b ≡a2 · b (mod n).
(6.7)
Multiplying the congruence (6.7) from the right by b−1, we obtain
a1 = a1 · b · b−1 mod n = a2 · b · b−1 mod n = a2.
To complete the proof we have still to show that there exists8 an element
b ∈WITNESS ∩ZZ∗
n. We do this for
n = p · q
for two nontrivial factors p and q with GCD (p, q) = 1. The case n = pd for a
prime p and a positive integer d ≥2 is left as an exercise to the reader.9
Since it is clearer to search for b in ZZp×ZZq instead of searching in ZZn, we
apply the Chinese Remainder Theorem. Remember that, for every a ∈ZZn,
the pair
(a mod p, a mod q)
is the representation of a in ZZp × ZZq. If a is a Eulerian number, we know
that
a(n−1)/2 mod p · q ∈{1, n −1},
which implies that
either a(n−1)/2 = k · p · q + 1 or a(n−1)/2 = k · p · q + n −1
(6.8)
for a k ∈IN. A direct consequence of (6.8) is either
8The fact b ∈ZZ∗
n is equivalent to saying that b has a multiplicative inverse with
respect to ⊙mod p. The proof of this observation is given in Theorem A.2.30.
9Note that one can eﬃciently check whether or not n can be expressed as pd for
a prime p, and so one can solve primality testing for such an n without searching
for witnesses.

6.2 Searching for Witnesses for Primality Testing
191
a
(n−1)
2
mod p = a
(n−1)
2
mod q = 1
or
a
(n−1)
2
mod p = (n −1) mod p = (p · q −1) mod p = p −1 and
a
(n−1)
2
mod q = (n −1) mod q = (p · q −1) mod q = q −1.
Hence,
either (1, 1) or (p −1, q −1) = (−1, −1)
is the representation of a
(n−1)
2
mod n in ZZp × ZZq for every a ∈EULER.
Therefore, we choose
(1, q −1) = (1, −1)
as the representation of b in ZZp × ZZq. We show that b has the required
properties. The representation of b(n−1)/2 mod n in ZZp × ZZq is
(b
(n−1)
2
mod p, b
(n−1)
2
mod q) = (1
(n−1)
2
mod p, (−1)
(n−1)
2
mod q) = (1, −1),
because (n −1)/2 is odd.10 Hence, b is not a Eulerian number, and so b ∈
WITNESS.
To complete the proof, we show that
b−1 = b.
Since (1, 1) is the neutral element with respect to the multiplication in ZZp ×
ZZq,
(1, q −1) ⊙p,q (1, q −1) = (1 · 1 mod p, (q −1) · (q −1) mod q) = (1, 1)
implies that b is inverse to itself. This completes the proof of Theorem 6.2.2.
⊓⊔
Exercise 6.2.3. Find a suitable b in the proof of Theorem 6.2.2 if n is a power
of a prime.
Exercise 6.2.4. Let n be a positive integer. Design a deterministic algorithm
that eﬃciently decides whether or not n is a power of a prime.
Exercise 6.2.5. Execute a search for a non-Eulerian number b in the proof
of Theorem 6.2.2 without applying the Chinese Remainder Theorem.
The assertion of Theorem 6.2.2 suggests the following algorithm for pri-
mality testing.
10This is the only place in the proof where we apply this assumption of Theo-
rem 6.2.2.

192
6 Abundance of Witnesses
SSSA (Simpliﬁed Solovay-Strassen Algorithm)
Input: An odd integer n with n ≡3 (mod 4).
Step 1: Choose uniformly an a ∈{1, 2, . . ., n −1} at random.
Step 2: Compute A := a(n−1)/2 mod n.
Step 3:
if A ∈{1, −1} then
output “n ∈PRIM” {reject}
else
output “n /∈PRIM” {accept}
Theorem 6.2.6. SSSA is a polynomial-time 1MC algorithm for the recogni-
tion of composite numbers n with n mod 4 = 3.
Proof. The value of A can be eﬃciently computed by repeated squaring.11 The
fact that SSSA is a 1MC algorithm is a direct consequence of Theorem 6.2.2.
If p is a prime, then (i) of Theorem 6.2.2 assures that there is no witness of
p /∈PRIM, and so the algorithm SSSA answers “n ∈PRIM” with certainty.
If p is composite, then (ii) of Theorem 6.2.2 assures that
Prob

SSSA outputs “n /∈PRIM′′
≥1
2.
⊓⊔
Observe, that SSSA is not a 1MC algorithm for recognizing primes because
it can be wrong by indicating prime for a composite number.
Corollary 6.2.7. For any positive integer n with n ≡3 (mod 4), SSSA is
a polynomial-time bounded-error randomized algorithm for the recognition of
primes (for accepting the set PRIM).
6.3 Solovay-Strassen Algorithm for Primality Testing
In Section 6.2 we have a kind of witness, that provides an eﬃcient randomized
algorithm for primality testing for all positive integers n with n ≡3 (mod 4).
This section aims to extend this kind of witness in a way that results in a
randomized primality testing for all odd integers.
First, we observe that an a ∈{1, 2, . . ., n −1} with GCD (a, n) ̸= 1 is
also a witness of the fact “n /∈PRIM”, and that GCD (a, n) can be eﬃciently
computed by the Euclidean algorithm (Section A.2). This could suggest the
following extension of the deﬁnition (6.6) of witnesses:
A number a ∈{1, 2, . . ., n −1} is a witness of the fact
“n /∈PRIM” for an odd positive integer n if
(i) GCD (a, n) > 1, or
(ii) GCD (a, n) = 1 and a(n−1)/2 mod n /∈{1, n −1}.
(6.9)
11see Section A.2

6.3 Solovay-Strassen Algorithm for Primality Testing
193
Exercise 6.3.8. Let n be a composite number, n ≡3 (mod 4). Prove that
at least half the elements of ZZ∗
n = {a ∈ZZn −{0} | GCD (a, n) = 1} are
witnesses (with respect to (6.9)) of “n /∈PRIM”.
{Hint: A possible way of proving this is by showing that all non-witnesses in
ZZ∗
n are in a proper subgroup of (ZZ∗
n, ⊙mod n).}
Clearly, the kind (6.9) of witnesses is at least as suitable as the kind (6.6)
for any n with n ≡3 (mod 4). Unfortunately, (6.9) does not guarantee the
abundance of witnesses for Carmichael numbers, and so we cannot use this
kind of witness for the design of a randomized algorithm for primality testing
for all odd, positive integers.
Exercise 6.3.9.∗Let n be a composite number, that is not a Carmichael
number. Prove that at least half the elements of ZZn −{0} are witnesses (with
respect to (6.9)) of the fact “n /∈PRIM”.
To improve the witness kind (6.9) we introduce the following two terms.
Deﬁnition 6.3.10. Legendre Symbol
For any prime p > 2 and any positive integer a with GCD (a, p) = 1 the
Legendre symbol for a and p is
Leg
0
a
p
1
=
2
1 if a is a quadratic residue modulo p,
−1 if a is a quadratic nonresidue modulo p.
The following assertion is a direct consequence of the Euclidean Criterion
(Theorem 5.4.14).
Lemma 6.3.11. For every prime p > 2 and every positive integer a with
GCD (a, p) = 1,
Leg
3a
p
4
= a
(p−1)
2
mod p.
Observe that due to Lemma 6.3.11 the Legendre symbols are eﬃciently
computable.
The following deﬁnition extends the Legendre symbol from primes to com-
posite numbers.
Deﬁnition 6.3.12. Jacobi Symbol
Let
n = pk1
1 · pk2
2 · . . . · pkl
l
be the factorization of an odd integer n ≥3, where p1 < p2 < . . . < pl are
primes and k1, k2, . . ., kl are positive integers for a positive integer l.
For all positive integers a with GCD (a, n) = 1, the Jacobi symbol of a
and n is
Jac
 a
n

=
l
i=1

Leg
3 a
pi
4ki
=
l
i=1

a
pi−1
2
mod pi
ki
.

194
6 Abundance of Witnesses
Observation 6.3.13. For all positive integers a and n satisfying the assump-
tions of Deﬁnition 6.3.10,
Jac
0 a
n
1
∈{1, −1}.
Proof. The Jacobi symbols are products of Legendre symbols and all Legendre
symbols are from {1, −1}.
⊓⊔
Note that working with Jacobi symbols, we really consider −1 a negative
integer, and not n −1 in ZZn.
Knowing the factorization of n, one can eﬃciently compute the Jacobi
symbol Jac
 a
n

for any a ∈ZZ∗
n. But for using Jacobi symbols in a deﬁnition
of witnesses of compositeness, one needs to design an eﬃcient algorithm for
computing Jacobi symbols without knowing the factorization12 of n. One such
possibility is provided by the following lemma that formulates the basic rules
of working with Jacobi symbols.
Lemma 6.3.14. Let n be an odd integer greater than 3, and let a, b be natural
numbers with GCD (a, n) = GCD (b, n) = 1. Then,
(i) Jac
 a·b
n

= Jac
 a
n

· Jac
 b
n

,
(ii) Jac
 a
n

= Jac
 b
n

for all a, b with a ≡b (mod n),
(iii) Jac
 a
n

= (−1)
a−1
2
· n−1
2
· Jac
 n
a

for all odd a,
(iv) Jac
 1
n

= 1, and Jac
 n−1
n

= (−1)
(n−1)
2
,
(v) Jac
 2
n

= −1 for all n with n mod 8 ∈{3, 5}, and
Jac
 2
n

= 1 for all n with n mod 8 ∈{1, 7}.
Proof. Here, we prove the properties (i) and (ii). The proofs of the other
properties are left as exercises.
(i) Let n = pk1
1 · pk2
2 · . . . · pkl
l
for pairwise diﬀerent, odd primes p1, p2, . . ., pk.
Because of the commutativity of ⊕mod pi, we have
Jac
3a · b
n
4
=
def.
l
i=1

(a · b)
(pi−1)
2
mod pi
ki
=
l
i=1

a
(pi−1)
2
mod pi

·

b
(pi−1)
2
mod pi
ki
=
l
i=1

a
(pi−1)
2
mod pi
ki
·
l
i=1

b
(pi−1)
2
mod pi
ki
=
def.
Jac
0 a
n
1
· Jac
3 b
n
4
.
This completes the proof of (i).
12More precisely, without knowing whether n is a prime or not.

6.3 Solovay-Strassen Algorithm for Primality Testing
195
(ii) Following the deﬁnition of Jacobi symbols, we see that it is suﬃcient to
show
Leg
3a
p
4
= Leg
3 b
p
4
for every prime p and all a, b with GCD (a, p) = GCD (b, p) = 1 and
a ≡b (mod p).
Since a ≡b (mod p), one can express a and b as follows:
a = p · r + z and b = p · s + z
(6.10)
for appropriate r, s, z ∈IN, z < p. Then, one can write
Jac
3a
p
4
=
a
(p−1)
2
mod p
=
(6.10)
(p · r + z)
(p−1)
2
mod p
=
(p−1)/2

i=0
(p −1)/2
i

· (p · r)
p−1
2
−i · zi mod p
=
z(p−1)/2 mod p
{Because all other members of the
sum are divisible by p · r.}
Analogously, applying (6.10) one obtains
Jac
3 b
p
4
= z(p−1)/2 mod p
and so
Leg
3a
p
4
= Leg
3 b
p
4
.
⊓⊔
Exercise 6.3.15. Prove the properties (iii), (iv), and (v) of Jacobi symbols
presented in Lemma 6.3.14.
Lemma 6.3.14 provides us an eﬃcient method for computing of Jacobi
symbols without knowing the factorization of n. The following recursive pro-
cedure is one of the provided possibilities.
Algorithm JACOBI[a, n]

196
6 Abundance of Witnesses
Input: An odd integer n ≥3, and a positive integer a with GCD (a, n) = 1.
Procedure: JACOBI[a, n]
begin
if a = 1 then
JACOBI[a, n] := 1;
if a = 2 and n mod 8 ∈{3, 5} then
JACOBI[a, n] := −1;
if a = 2 and n mod 8 ∈{1, 7} then
JACOBI[a, n] := 1;
if a is odd then
JACOBI[a, n] := JACOBI[2, n] · JACOBI[a/2, n];
if a > n then
JACOBI[a, n] := JACOBI[a mod n, n]
else
JACOBI[a, n] := (−1)
a−1
2
· n−1
2
· JACOBI[n mod a, a]
end
We observe that every recursive call of JACOBI[ ] reduces one of the
arguments at least by one half13, and so O(log2 n) recursive calls are suﬃ-
cient to compute Jac
 a
n

. The computation related to a recursive call can
be executed by O(1) arithmetical operations or by O

(log2(a + n))2
binary
operations. Hence, the algorithm JACOBI[a, n] can be performed by at most
O

(log2(a + n))3
binary operations.
Now we are ready to introduce a new deﬁnition of witnesses of composite-
ness. The idea is to say that an a with
Jac
0 a
n
1
̸= a
(n−1)
2
mod n
witnesses the fact “n /∈PRIM”.
Deﬁnition 6.3.16. Let n be an odd integer, n ≥3. A number a ∈{1, 2, . . ., n−
1} is called a Jac-witness of the fact14 “n /∈PRIM” if
(i) GCD (a, n) ̸= 1, or
(ii) Jac
 a
n

̸= a
(n−1)
2
mod n.
The following assertion says that, for every odd, positive, composite integer
n, one can guarantee an abundance of Jac-witnesses of n’s compositeness.
Theorem 6.3.17. For every odd integer n, n ≥3, the following holds:
(a) If n is a prime, then
Jac
0 a
n
1
= Leg
0 a
n
1
= a
(n−1)
2
mod n
for all a ∈{1, 2, . . ., n −1}.
13similarly as with the Euclidean algorithm
14of the compositness of n

6.3 Solovay-Strassen Algorithm for Primality Testing
197
(b) If n is composite, then
Jac
0 a
n
1
̸= a
(n−1)
2
mod n
for at least half the elements a ∈{1, 2 . . ., n −1} with the property
GCD (a, n) = 1 (i.e., for at least half the elements a ∈ZZ∗
n).
Proof. The claim (a) is a direct consequence of the deﬁnition of Jacobi symbols
and the Eulerian Criterion.
It remains to prove the claim (b).
Let n be an odd, composite integer, n ≥3. Our set of witness candidates
is {1, 2, . . ., n −1} = ZZn −{0}. The Jac-witnesses of “n /∈PRIM” according
to Deﬁnition 6.3.16(i) are all elements from {1, 2, . . ., n −1} −ZZ∗
n. If one
denotes the set of all non-Jac-witnesses by
Witn = {a ∈ZZ∗
n | Jac
0 a
n
1
= a
(n−1)
2
mod n},
then
ZZ∗
n −Witn
is the set of Jac-witnesses of “n /∈PRIM” with respect to Deﬁnition 6.3.16(ii).
Our aim is to show that
|Witn| ≤|ZZ∗
n|/2,
(6.11)
and so that
|{1, 2, . . ., n −1} −Witn| ≥|Witn|.
In order to prove (6.11), we use an algebraic technique based on Lagrange’s
Theorem (Theorem A.2.48). We aim to show that
(Witn, ⊙mod n) is a proper subgroup of (ZZ∗
n, ⊙mod n).
(6.12)
Lagrange’s Theorem says that the cardinality of any subgroup of a group
divides the cardinality of the group. Hence, (6.11) is a direct consequence of
(6.12).
First, we show that (Witn, ⊙mod n) is a group. Following Theorem A.2.40
it is suﬃcient to show that Witn is closed according to ⊙mod n. Let a and b
be two elements from Witn. From Lemma 6.3.14(i) we have
Jac
3a · b
n
4
= Jac
0 a
n
1
· Jac
3 b
n
4
=

a
(n−1)
2
mod n

·

b
(n−1)
2
mod n

{Since a, b ∈Witn}
= (a · b)
(n−1)
2
mod n,
and so a · b ∈Witn.

198
6 Abundance of Witnesses
The hardest part of the proof is to show that Witn is a proper subset
ofZZ∗
n. Hence, we are searching for an element a ∈ZZ∗
n −Witn. Let
n = pi1
1 · pi2
2 · . . . · pik
k
be the factorization of n, where ij are positive integers for j = 1, . . ., k and
2 < p1 < p2 < . . . < pk are primes. We set
q = pi1
1 and m = pi2
2 · pi3
3 · . . . · pik
k
in order to search for an a ∈ZZ∗
n −Witn in ZZq × ZZm instead of searching
directly in ZZn. Let g be the generator of the cyclic group (ZZ∗
q, ⊙mod q). We
make the choice of a by the following recurrences:
a ≡g (mod q)
a ≡1 (mod m).
Hence, we choose a as
(g, 1) in ZZq × ZZm.
If m = 1, then we simply take a = g.
First, we show that a ∈ZZ∗
n, i.e., that GCD (a, n) = 1. Therefore, we have
to show that
none of the primes p1, p2, . . ., pk divides the num-
ber a.
(6.13)
We prove (6.13) in an indirect way. If p1 divides a, then the equality15
g = a mod pi1
1
contradicts the assumption that g is a generator of ZZ∗
q.
If, for an r ∈{2, . . ., k}, pr divides a, then a = pr · b for a positive integer
b. The congruence a ≡1 (mod m) implies
a = m · x + 1
for a natural number x. Hence,
a = pr · b = m · x + 1 = pr · (m/pr) · x + 1,
which implies16
pr divides 1.
Since pr > 1, the prime pr cannot divide 1 and so pr does not divide a.
Thus, we have proved a ∈ZZ∗
n.
Finally, we have to prove that
a /∈Witn.
Now, we distinguish two possibilities, namely i1 = 1 and i1 ≥2.
15This equality follows from the congruence a ≡g (mod q) for q = pi1
1 .
16Exercise A.2.6 (if pr divides x and y, and x = y + z, then pr must divide z, too)

6.3 Solovay-Strassen Algorithm for Primality Testing
199
(1) Let i1 = 1.
We compute the Jacobi symbol for a and n and the number a
(n−1)
2
mod n
in order to show that they are diﬀerent.
For the following calculation it is important to remember that
n = p1 · m, m > 1 and GCD (p1, m) = 1.
Jac
0 a
n
1
=
def .
k

j=1

Jac
3 a
pi
4ij
= Jac
3 a
p1
4
·
k

j=2

Jac
3 a
pj
4ij
{since i1 = 1}
= Jac
3 a
p1
4
·
k

j=2

Jac
3 1
pj
4ij
{because of a ≡1 (mod m) and Lemma 6.3.14(ii)}
= Jac
3 a
p1
4
{Lemma 6.3.14(iv)}
= Jac
3 g
p1
4
{becuase of a ≡g (mod p1) and Lemma 6.3.14(ii)}
= Leg
3 g
p1
4
{since p1 is a prime}
= −1
{because a generator g of ZZ∗
p1 cannot be a quadratic
residue modulo p1.}
Hence, we proved that
Jac
0 a
n
1
= −1.
Since a ≡1 (mod m), we obtain
a
(n−1)
2
mod m = (a mod m)
(n−1)
2
mod m
= 1
(n−1)
2
mod m
= 1.
(6.14)
Now, the equality a
(n−1)
2
mod n = −1 for n = q · m cannot hold because
a(n−1)/2 mod n = −1 implies17
17If n = q · m and d mod n = −1 for a d ∈IN, then d = l · n −1 = k · q · m −1
for a k ∈IN. Then, it is obvious that d ≡−1 (mod m).

200
6 Abundance of Witnesses
a
(n−1)
2
mod m = −1 (= m −1 in ZZ∗
m),
which contradicts (6.14).
Hence, we have proved
−1 = Jac
0 a
n
1
̸= a
(n−1)
2
mod n
and so
a ∈ZZ∗
n −Witn.
(2) Let i1 ≥2.
We prove a /∈Witn in an indirect way.
Assume a ∈Witn. This assumption implies
a
(n−1)
2
mod n = Jac
0 a
n
1
∈{1, −1},
and so
an−1 mod n = 1.
Since n = q · m, we also have
an−1 mod q = 1.
Since g = a mod q, we obtain
1 = an−1 mod q = (a mod q)n−1 mod q = gn−1 mod q.
(6.15)
Since g is a generator of the cyclic group (ZZ∗
q, ⊙mod q), the order of g is
|ZZ∗
q|. From (6.15) we have that the order of g must divide n −1, i.e.,
|ZZ∗
q| divides n −1.
(6.16)
Since q = pi1
1 for an i1 ≥2, and
ZZ∗
q = {x ∈ZZq | GCD (x, q) = 1} = {x ∈ZZq | p1 does not divide x}
and the number of elements of ZZq that are a multiple of p1 is exactly
|ZZq|/p1, one obtains
|ZZ∗
q| = |ZZq| −|ZZq|/p1 = pi1
1 −pi1−1
1
= p1 ·

pi1−1
1
−pi1−2
1

.
Hence,
p1 divides |ZZ∗
q|.
(6.17)
But (6.16) and (6.17) together imply that
p1 divides n −1.
(6.18)
Since n = pi1
1 · m, we have obtained

6.3 Solovay-Strassen Algorithm for Primality Testing
201
p1 divides n and p1 divides n −1.
Since no prime can divide both18 n −1 and n, our assumption a ∈Witn
cannot hold, and we obtain
a /∈Witn.
⊓⊔
Theorem 6.3.17 shows that the Jac-witnesses are a suitable kind of wit-
nesses of randomized primality testing. The following algorithm is a straight-
forward application of the method of abundance of witnesses for the Jac-
witnesses.
Algorithm Solovay-Strassen
Input: An odd integer n, n ≥3.
Step 1: Choose uniformly an a from {1, 2, . . ., n −1} at random.
Step 2: Compute GCD (a, n).
Step 3:
if GCD (a, n) ̸= 1 then
output (“n /∈PRIM”) {accept}
Step 4: Compute Jac
 a
n

and a
(n−1)
2
mod n
Step 5:
if Jac
 a
n

= a
(n−1)
2
mod n then
output (“n ∈PRIM”) {reject}
else
output (“n /∈PRIM”) {accept}.
Theorem 6.3.18. The Solovay-Strassen algorithm is a polynomial-time one-
sided-error Monte Carlo algorithm for the recognition of composite numbers.
Proof. First, we analyze the time complexity of the algorithm. Since a < n,
one can measure the complexity of all operations over a and n with re-
spect to the representation length ⌈log2(n + 1)⌉of the input n. Computing
GCD (a, n) in step 2 costs at most O

(log2 n)3
binary operations. The value
a(n−1)/2 mod n can be computed in O

(log2 n)3
binary operations,19 too.
The algorithm JACOBI computes Jac
 a
n

in O

(log2 n)3
binary operations.
The cost of the comparison in step 5 is linear in log2 n, and so the overall
complexity of the algorithm is in O

(log2 n)3
.
Next, we analyze the success probability of the Solovay-Strassen algorithm.
18If a prime p divides both n −1 and n, then the equality n = (n −1) + 1 would
imply that p divides 1.
19If one applies the best known algorithm for multiplication of large integers, the
the value a(n−1)/2 mod n can even be computed in time O
(log2 n)2 · log log log n
.

202
6 Abundance of Witnesses
If n is a prime, there does not exist any witness of “n /∈PRIM” (Theo-
rem 6.3.17(a)), and so the algorithm outputs the answer “n ∈PRIM” (“re-
ject”) with certainty.
If n is composite, Theorem 6.3.17(b) assures that at least half the elements
of {1, 2, . . ., n −1} are Jac-witnesses of “n /∈PRIM”. Therefore, the Solovay-
Strassen algorithm gives the right answer “n /∈PRIM” with probability at
least 1/2.
⊓⊔
Since the Solovay-Strassen algorithm is a 1MC algorithm, a constant20
number of repetitions of its work on the same input is suﬃcient in order to
reduce the error probability21 to an arbitrarily small chosen ϵ > 0. Hence, the
algorithm is practical and used in many applications.
6.4 Generation of Random Primes
One of the most frequent tasks in the modern cryptography is the following:
For a given positive integer l, generate a random prime of the binary
length l.
Typically, the given binary length l is of the order of hundreds. Hence, the
number of primes of the length l is larger that the number of protons in the
known universe. Clearly, one cannot solve this task by generating all primes of
length l and than choosing one of them at random. The strategy used simply
generates a random integer of length l and then applies a randomized primality
test in order to check whether or not the generated number is a prime. This
approach works due to the Primality Theorem (Theorem A.2.9), that assures
an abundance22 of primes among natural numbers. If one uniformly generates
an integer of length l at random and repeats this procedure until a prime is
generated, then the prime generated can be considered random with respect
to the uniform probability distribution over all primes of length l.
In what follows, we present an algorithm for the generation of random
primes. This algorithm has two inputs, l and k. The number l is the length
of primes we are looking for and the number k is the number of independent
runs of the Solovay-Strassen algorithm performed on every generated number
in order to check whether or not it is a prime.
PRIMEGEN (l, k)
Input: Positive integers l and k, l ≥3.
20with respect to the input size
21Recall, that the error probability of 1MC algorithms tends to 0 with an expo-
nential speed in the number of runs executed.
22For a randomly chosen number n, the probability that n is a prime is approxi-
mately 1/ ln n.

6.4 Generation of Random Primes
203
Step 1:
X := “still not found”;
I := 0;
Step 2:
while X := “still not found” and I < 2 · l2 do
begin
generate a bit sequence a1, a2, . . ., al−2 at random
and compute
n := 2l−1 +
l−2

i=1
ai · 2i + 1
{Hence, n is a random integer of length l}
Perform k independent runs of the Solovay-Strassen algorithm on
n;
if at least one output is “n /∈PRIM” then
I := I + 1
else
begin
X := already found;
output “n”
end;
end;
Step 3:
if I = 2 · l2 then
output “I was unable to ﬁnd a prime.”
Theorem 6.4.19. The algorithm PRIMEGEN (l, l) is a bounded-error algo-
rithm for generating primes that works in time polynomial in l.
Proof. First, we analyze the time complexity of the randomized algorithm
PRIMEGEN (l, k) for l = k. Though the input length is 2 · ⌈log2(l + 1)⌉, we
measure the complexity in l, because the output length is l.
The algorithm performs at most 2 · l2 attempts to generate a number and
to test it. The random generation itself runs in linear time in l, and one run of
the Solovay-Strassen algorithm can require O

l3
binary operations. Hence,
the worst-case running time of PRIMEGEN (l, l) is in O

l5
.
We begin the analysis of the success probability of PRIMEGEN(l, l) by
estimating the probability that PRIMEGEN (l, l) answers “I was unable to
ﬁnd a prime”. This unwanted event can occur only if none of the 2·l2 randomly
generated numbers is a prime23, and for every one of these generated numbers,
the Solovay-Strassen primality test proves in l runs that the given number is
23Recall, that the Solovay-Strassen algorithm must output “n ∈PRIM” if n is a
prime.

204
6 Abundance of Witnesses
composite. Since the probability, that a random number of length l is a prime,
is at least24
1
ln n >
1
2 · l,
the probability of generating no prime in one attempt is at most
1 −
1
2 · l.
(6.19)
Let
wl ≥1 −1
2l
be the probability, that l runs of the Solovay-Strassen primality test succeed
in proving “n /∈PRIM” for a given, composite n of length l. Hence, we obtain
Prob(PRIMEGEN(l, l) = “I was unable to ﬁnd a prime”)
<
(6.19)

1 −
1
2 · l

· wl
2·l2
<

1 −
1
2 · l
2·l2
=

1 −
1
2 · l
2·ll
<
1
e
l
= e−l.
Clearly, e−l tends to 0 with growing l, and e−l <
1
4 for all l ≥2. For
l ≥100, e−l is substantially smaller than 10−40.
Next, we analyze the probability of the second unwanted event, that
PRIMEGEN (l, l) outputs a composite number n as a prime.25 The algorithm
PRIMEGEN (l, l) produces a composite number n only if
(i) all numbers generated before26 n were composite, and this fact was proved
in PRIMEGEN (l, l) for each of these numbers by at most l runs of the
Solovay-Strassen algorithm, and
(ii) n is composite, but PRIMEGEN (l, l) does not succeed in proving n’s
compositeness in l runs of the Solovay-Strassen algorithm.
Since n can be the i-th randomly generated number for i = 1, 2, . . ., 2 · l2,
denote by pi the probability that the wrong answer n is the i-th generated
number. The lower bound (6.19) implies
24due to the Prime Number Theorem (Theorem A.2.9)
25i.e., the probability of a wrong output (error probability).
26If n is the i-th generated number, then we mean the ﬁrst i−1 numbers generated.

6.4 Generation of Random Primes
205
p1 ≤

1 −
1
2 · l

· 1
2l ,
since 2−l is a lower bound on the probability that “n /∈PRIM” was not proved
in l runs of the Solovay-Strassen primality test.
For all i = 2, 3, . . ., 2 · l2,
pi ≤
3
1 −
1
2 · l

· wl
4i−1
·

1 −
1
2 · l

· 1
2l ,
where

1 −
1
2·l

· wl
i−1 is an upper bound on the probability that the ﬁrst
i −1 generated numbers are composite and that this fact was successfully
recognized. Thus, we obtain
ErrorPRIMEGEN(l,l)(l) ≤p1 +
2·l2

j=2
pj
≤

1 −
1
2 · l

· 1
2l +
+
2·l2−1

i=1
3
1 −
1
2 · l

· wl
4i
·

1 −
1
2 · l

· 1
2l
≤

1 −
1
2 · l

· 1
2l ·
⎛
⎝
2·l2−1

i=1

1 −
1
2 · l
i
+ 1
⎞
⎠
≤

1 −
1
2 · l

· 1
2l · 2 · l2
≤
l2
2l−1 .
Clearly,
the
value
l2 · 2−(l−1)
tends
to
0
with
growing
l,
and
ErrorPRIMEGEN(5,5)(5) ≤1/5. For l ≥100,
ErrorPRIMEGEN(l,l)(l) ≤l2 · 2−(l−1) ≤1.58 · 10−26.
⊓⊔
In order to increase the success probability of PRIMEGEN (l, k), we have
probably chosen a too large k, that essentially increases the time complex-
ity. The following exercises provide to the reader an opportunity of thinking
about an appropriate trade-oﬀbetween the amount of work and the success
probability.
Exercise 6.4.20. Analyze the time complexity and the success probability of
PRIMEGEN (l, k) for the following values of k:

206
6 Abundance of Witnesses
(i) k = 2 · ⌈log2 l⌉,
(ii) k = 2 · (⌈log2 l⌉)2, and
(iii) k = ⌈
√
l⌉.
Exercise 6.4.21. The number 2 · l2 of attempts to generate a random prime
in PRIMEGEN(l, k) may be too large. Which choice of the number of at-
tempts would you prefer in order to reduce the worst-case complexity of
PRIMEGEN (l, k) on the one hand, but still assure a high success probability
on the other hand?
Exercise 6.4.22. Modify PRIMEGEN (l, k) in such a way that it must run
until it outputs a number n. This means that one forbids the output “I was
unable to ﬁnd a prime,” and so there exist inﬁnite runs of PRIMEGEN (l, k).
Analyze the expected running time and the error probability of such a modi-
ﬁcation of PRIMEGEN (l, k).
6.5 Summary
Abundance of witnesses as a method for the design of eﬃcient randomized
algorithms uncovers the deepest roots of the nature of the power of random-
ization. If for a hard computing problem there are only sets of candidates for
a witness in which the witnesses are randomly distributed, then randomized
algorithms can solve the problem eﬃciently despite the fact that the problem
cannot be eﬃciently solved by any deterministic algorithm. The art of apply-
ing the method of abundance of witnesses lies in the search for a suitable kind
of witness. Simple kinds of witnesses were considered in Chapter 4, where we
applied ﬁngerprinting as a special case of the method of abundance of wit-
nesses for several tasks. In this chapter we presented a part of the story of
searching for kinds of witnesses suitable for randomized primality testing. We
call attention to the fact that one can test primality in deterministic polyno-
mial time, recently shown by Agrawal, Kayal and Saxena [AKS02], and that
the design of this deterministic algorithm can also be viewed as a search for a
kind of witness. But here one does not look for an abundance of witnesses. One
looks for a set of candidates in which one can determine a “small” subset27
that contains at least one witness with certainty. Since the designed determin-
istic primality test runs in O

(log2 n)10
, it is not considered a real competitor
for the known eﬃcient randomized algorithms in current applications.
Primality testing is one of the fundamental problems of mathematics and
computer science. For 2000 years, whether or not one could test primality of
n faster than trying to divide n by all numbers smaller or equal to √n was an
open question. In the 17th century, Fermat, with his Fermat’s Little Theorem,
ﬁrst brought to attention the possibility of an eﬃcient primality test. This
primality test does not work for all numbers, especially not for Carmichael
27The cardinality of the subset should be polynomial in input size.

6.5 Summary
207
numbers. The Carmichael numbers were discovered by Carmichael [Car12],
and the proof that there exist inﬁnitely many Carmichael numbers was given
by Alford, Granville, and Pomerance [AGP92]. At ﬁrst, the development of
algorithmics and complexity theory brought an essential progress in attacking
this fundamental problem. Pratt [Pra75] has proved that primality testing is
in NP. The Solovay-Strassen algorithm presented here, designed by Solovay
and Strassen [SS77], is one of the ﬁrst eﬃcient randomized and practicable
algorithms for primality testing. A transparent explanation of the development
of ideas leading to its design is given by Strassen [Str96]. In 1976, Miller
showed that the validity of the Extended Riemann Hypothesis implies the
existence of an eﬃcient deterministic algorithm for primality testing. Rabin
[Rab76, Rab80] modiﬁed28 Miller in order to design an eﬃcient randomized
algorithm. Both the above mentioned algorithms are one-sided-error Monte
Carlo algorithms. To improve on them, Adleman and Huang [AH87] designed a
polynomial-time Las Vegas algorithm for primality testing. In 1983 Adleman,
Pomerance, and Rumely even discovered a deterministic primality test that
runs in super-polynomial time (log2 n)O(log log log n). The biggest break was
achieved in 2002 when Agrawal, Kayal, and Saxena [AKS02] discovered a
deterministic primality test running in time O

(log2 n)12
. The design of this
algorithm is considered to be one of the most important achievements of
algorithmics.
For a more involved study of primality testing we recommend the text-
books of Motwani and Raghavan [MR95], Cormen, Leiserson, Rivest, and
Stein [CLRS01], and Hromkoviˇc [Hro03]. The fascinating story of the devel-
opment of algorithms for primality testing is presented in a correspondingly
fascinating way by Dietzfelbinger [Die04].
28Rabin exchanged the assumption of the validity of the Extended Riemann Hy-
pothesis in Miller’s algorithm for randomization.

This page intentionally left blank

7
Optimization and Random Rounding
Improvisation certainly
is the touch-stone of spirit.
Moli´ere
7.1 Objectives
Integer linear programming (ILP) and 0/1-linear programming (0/1-LP) are
known NP-hard optimization problems. On the other hand, the linear pro-
gramming problem (LP) is solvable in polynomial time. Interestingly, all three
problems, ILP, 0/1-LP, and LP, are speciﬁed by the same kind of linear con-
straints and have the same kind of linear objectives. The only diﬀerence is in
requiring integer solutions for ILP and Boolean solutions for 0/1-LP, while
the basic problem of linear programming is considered over real1 numbers.
How is it possible that there are such large diﬀerences in the computational
complexities of these problems, while they look so similar? The reason is that
the constraints requiring integer or Boolean solutions cannot be formulated as
linear equations, and so ILP and 0/1-LP leave the area of linear constraints in
this sense. The linearity of LP is really substantial, because the set of feasible
solutions of a system of linear inequalities (of an instance of LP) builds a
polytype.2 To search for an optimum with respect to a linear function in a
polytype is not so hard, because one can reach an optimum by applying a
local search starting from an arbitrary vertex of the polytype and moving
along the edges of the polytype.3
This strong similarity between the eﬃciently solvable LP and the NP-hard
ILP and 0/1-LP is used in order to design eﬃcient approximation algorithms.
First, one expresses an instance of a discrete optimization problem as an
instance of ILP or 0/1-LP. Usually, this can be done very easily, because the
constraints of many hard optimization problems are naturally expressible in
1i.e., without any restriction on the type of input values
2a convex, multidimensional object
3This is exactly what the famous Simplex algorithm does. The Simplex algorithm
runs very fast on almost all instances of LP. But there exist artiﬁcial LP instances
requiring exponentially many local improvements during the execution of the local
search to reach an optimum.

210
7 Optimization and Random Rounding
the form of linear equations (or inequalities).4 The second step is called the
relaxation to linear programming. Here, one does not take the constraints
requiring integer or Boolean solutions into account, and eﬃciently solves the
given problem instance as an instance of LP. The third and ﬁnal step is
devoted to the conversion of the computed optimal solution5 for LP to a
reasonably good, feasible solution to the original problem instance. One of the
possible conversion strategies is random rounding, which we aim to present in
this chapter.
This chapter is organized as follows. In Section 7.2 we introduce the
method of relaxation to linear programming and show how one can get ap-
proximation algorithms by applying this method.
In Section 7.3 we combine the method of relaxation to LP with ran-
dom rounding in order to design a randomized approximation algorithm for
MAX-SAT. We shall see that this algorithm in incomparable with the random
sampling algorithm for MAX-SAT presented in Section 2.5 (Exercise 2.5.72),
where the incomparability is considered with respect to the quality (approxi-
mation ratio) of computed solutions. In Section 7.4 we merge these two ran-
domized approximation algorithms for MAX-SAT and obtain a randomized
algorithm whose expected approximation ratio is at most 4/3 for any given
formula in CNF.
Finally, Section 7.5 provides a short summary of the most important ideas
of the chapter and a survey of related results and recommended sources for
more involved study of this topic.
7.2 Relaxation to Linear Programming
The relaxation to linear programming is one of the most frequently applied
methods for designing algorithms for NP-hard, discrete optimization prob-
lems. The basic schema of this method can be described as follows.
Schema of the Relaxation to Linear Programming
Input: An instance I of an optimization problem U
(1) Reduction:
Express I as an instance ILP(I) of ILP (or 0/1-LP).
(2) Relaxation:
Consider ILP(I) as an instance Rel-LP(I) of LP (i.e., do not take the con-
straints requiring integer or Boolean solutions into account), and compute
an optimal solution α for Rel-LP(I) by a method of linear programming.
4Due to this linear programming problems became the paradigmatic problems
of combinatorial optimization and operations research.
5Which is not necessarily a feasible (integer or Boolean) solution to the original
problem instance.

7.2 Relaxation to Linear Programming
211
{It is important to observe, that the cost of α is a bound on the achievable
optimal cost of the original problem instance I, i.e., that
cost(α) = OptLP(Rel-LP(I)) ≤OptU (I)
if U is a minimization problem, and
cost(α) = OptLP(Rel-LP(I)) ≥OptU (I)
if U is a maximization problem).
The reason for this is that the constraints of Rel-LP(I) are a proper
subset of the constraints of ILP(I) (and so of I). Therefore the set
M(ILP(I)) of feasible solutions for I is a subset of the set M(Rel-LP(I))
of feasible solutions for Rel-LP(I).}
(3) Solving the original problem:
Use α in order to compute a feasible solution β for I that is of a suﬃciently
high quality (i.e., optimal or a good approximation of an optimal solution).
{Though one is often unable to eﬃciently compute an optimal solution
for I, and so to estimate the cost OptU (I), the approximation ration
of β can be upper bounded by comparing cost(α) = OptLP(Rel-LP(I))
with cost(β).}
Parts (1) and (2) of the schema are executable in polynomial time. There-
fore, part (3) corresponds to an NP-hard problem if one forces to compute an
optimal solution.6 If one aims to design an approximation algorithm only, one
can search for a strategy by executing step (3), which runs in polynomial time
and guarantees a reasonable approximation ratio for every problem instance.
To illustrate the method of relaxation to linear programming, we give a few
examples of reductions to ILP and then present the design of an approximation
algorithm.
The problem of linear programming is one of the fundamental optimization
problems in mathematics. Its importance lies especially in the fact that many
real situations and frameworks can be well modeled by LP and in the fact
that many diﬀerent optimization problems can be expressed in terms of LP.
A general version of LP that accepts equations as well as inequalities is as
follows:
For every problem instance A = [aji]j=1, ...,m, i=1, ...,n, b = (b1, . . ., bm)T ,
c = (c1, . . ., cn), M1, M2 ⊆{1, . . ., m}, M1 ∩M2 = ∅, n, m ∈IN −{0},
minimize the linear function fc(x1, . . ., xn) =
n

i=1
ci · xi
6This does not exclude the possibility of eﬃciently computing optimal solutions
for several speciﬁc instances.

212
7 Optimization and Random Rounding
under the linear constraints7
n

i=1
aji · xi = bj for j ∈M1,
n

i=1
asi · xi ≥bs for s ∈M2, and
n

i=1
ari · xi ≤br for r ∈{1, 2, . . ., m} −(M1 ∪M2).
If x = (x1, x2, . . ., xn)T is considered over real numbers, then one can
solve this problem in polynomial time.8 If one adds the additional nonlinear
constraints xi ∈{0, 1} or xi ∈ZZ, one obtains the NP-hard problems 0/1-LP
and ILP.
In what follows we present a few examples of the reduction and the relax-
ation of a few discrete optimization problems.
Example 7.2.1. The minimum vertex cover problem (MIN-VC)
Remember that an instance of MIN-VC is a graph G = (V, E). A feasible
solution is any vertex set U ⊆V such that each edge from E has at least one
end point in U. The objective is to minimize the cardinality of U.
Let V = {v1, v2, . . ., vn}. One can represent a feasible solution U by a
Boolean vector (x1, x2, . . ., xn) ∈{0, 1}n, where
xi = 1 ⇔vi ∈U.
This representation of feasible solutions enables us to express an instance
G = (V, E) of MIN-VC as the following instance ILP(G) of 0/1-LP:
Minimize
n

i=1
xi
(7.1)
under the |E| linear constraints
xi + xj ≥1 for every edge {vi, vj} ∈E
(7.2)
and the n nonlinear constraints
xi ∈{0, 1} for i = 1, 2, . . ., n.
(7.3)
7We know that each LP instance can be reduced to normal forms that allow either
only equations or only inequalities. This can be done eﬃciently by introducing new
variables, but it is a topic of operations research, and we omit the presentation of
such details here.
8It was an open question for a long time whether or not LP is solvable in poly-
nomial time (see Section 7.5).

7.2 Relaxation to Linear Programming
213
If one relaxes (7.3) to the 2 · n linear constraints
xi ≥0 and xi ≤1 for i = 1, 2, . . ., n,
(7.4)
one obtains the instance Rel-LP(G) of LP.
⊓⊔
Exercise 7.2.2. Consider the weighted MIN-VC, where every vertex has been
assigned a positive integer weight, and the task is to minimize the overall
weight of the vertex cover. Express this optimization problem as 0/1-LP.
Example 7.2.3. The knapsack problem (MAX-KP)
An instance I of MAX-KP is given by a sequence of 2 · n + 1 positive
integers I = w1, w2, . . ., wn, c1, c2, . . ., cn, b for a positive integer n. The idea
is to consider n objects, where for i = 1, 2, . . ., n, wi is the weight of the i-th
object and ci is the cost of the i-th object. One has a knapsack whose weight
capacity is bounded by b and the aim is to pack some objects in the knapsack
in such a way that the weight of the knapsack content is not above b and the
overall cost of objects in the knapsack is maximized. Again, one can describe
any feasible solution by a vector (x1, x2, . . ., xn) ∈{0, 1}n, where
xi = 1 ⇔the i-th object is in the knapsack.
Then, an instance I of MAX-KP can be expressed as the following instance
ILP(I) of 0/1-LP:
Maximize
n

i=1
ci · xi
under the linear constraint
n

i=1
wi · xi ≤b,
and the n nonlinear constraints
xi ∈{0, 1} for i = 1, . . ., n.
If one exchanges the constraints xi ∈{0, 1} by the following 2 · n linear
constraints
xi ≤1 and xi ≥0 for i = 1, 2, . . ., n,
then one obtains the corresponding relaxed instance Rel-LP(I) of LP.
⊓⊔
Exercise 7.2.4. The maximum matching problem is to ﬁnd a matching of
maximum cardinality in a given graph G. Express any instance of this problem
as an instance of 0/1-LP.

214
7 Optimization and Random Rounding
Example 7.2.5. The set cover problem (MIN-SC)
An instance of MIN-SC is a pair (X, F), where X = {a1, . . ., an} and
F = {S1, S2, . . ., Sm}, Si ⊆X for i = 1, . . ., m. A feasible solution is any set
S ⊆F, such that X = 
S∈S S. This task is to minimize the cardinality of S.
Similarly as in Exercise 7.2.1 and Exercise 7.2.3 one can represent a feasible
solution S by a Boolean vector (x1, x2, . . ., xm) ∈{0, 1}m, such that
xi = 1 ⇔Si ∈S.
We introduce the notation
Index(k) = {d ∈{1, . . ., m} | ak ∈Sd}
for k = 1, 2, . . ., n. Then, one can express (X, F) as the following instance of
0/1-LP:
Minimize
m

i=1
xi
under the n linear constraints

j∈Index(k)
xj ≥1 for k = 1, 2, . . ., n
and under the m nonlinear constraints
xi ∈{0, 1} for i = 1, 2, . . ., m.
⊓⊔
Exercise 7.2.6. What do MIN-VC and MIN-SC have in common? Can one
consider one of these problems as a special case of the other?
We have seen that some optimization problems can be expressed as in-
stances of ILP in a very natural way. Hence, part (1) of the schema of the
relaxation to LP is usually the simplest one. As already observed, part (2) can
be eﬃciently performed.9 The development of eﬃcient algorithms for LP is a
part of operations research. Since the details of their design are not directly
related to our considerations and aims, we omit the details of the execution of
part (2). From our point of view, the most creative part of the design of ap-
proximation algorithms by the method of the relaxation to LP is part (3), for
which one does not have any universal, or at least robust, approach working
for a large class of optimization problems. We ﬁnish this section by presenting
an example that shows that sometimes even simple rounding can help.
Example 7.2.7. Consider the MIN-VC problem that we already expressed as
0/1-LP in Exercise 7.2.1.
9Though the corresponding algorithms and their analyses are highly nontrivial.

7.2 Relaxation to Linear Programming
215
Let α = (α1, α2, . . ., αn) ∈[0, 1]n be an optimal solution for the relaxed
instance Rel-LP(G), which is determined by (7.1), (7.2), and (7.4). Clearly, an
αi /∈{0, 1} (from [0, 1]) does not have any interpretation for MIN-VC. Hence,
we have to create a β = (β1, β2, . . ., βn) ∈{0, 1}n from α. Let us do this by
simply rounding the αi’s in the following way:
βi = 1 ⇔αi ≥1
2.
Next, we show that this algorithm following the schema of the relaxation
to LP is a 2-approximation algorithm.
From the constraints (7.2) we see that the optimal solution α for Rel-LP(G)
must satisfy the inequality
αi + αj ≥1
for every edge {vi, vj} ∈E. Hence,
αi ≥1
2 or αj ≥1
2,
and so rounding αi and αj one obtains
βi = 1 or βj = 1.
Therefore, at least one of the vertices vi and vj is in the resulting10 vertex
cover, and so the edge {vi, vj} is covered. Thus, we have shown that β is a
feasible solution for G.
Since one rounds to the closest value from {0, 1},
βi ≤2 · αi,
and so
cost(β) =
n

i=1
βi ≤2 ·
n

i=1
αi = 2 · cost(α) .
(7.5)
Since the set of feasible solutions for the instance ILP(G) of 0/1-LP (and
so for G as an instance of MIN-VC) is a subset of the set of feasible solutions
for Rel-LP(G) as an instance of LP,
cost(α) = OptLP(Rel-LP(G)) ≤OptMIN-VC(G) .
(7.6)
In this way one ﬁnally obtains
Ratio(G) =
def.
cost(β)
OptMIN-VC(G) ≤
(7.5)
(7.6)
2 · cost(α)
cost(α)
= 2.
⊓⊔
10described by β.

216
7 Optimization and Random Rounding
Exercise 7.2.8. Let k be a positive integer. Consider MIN-SC(k) as the fol-
lowing restricted version of MIN-SC. The instances of MIN-SC(k) are usual
instances (X, F) of MIN-SC with the additional restriction that each element
x ∈X is contained in at most k sets from F. Apply the method of the relax-
ation to LP in order to design a k-approximation algorithm for MIN-SC(k).
{Hint: Observe that MIN-SC(2) and MIN-VC are the same optimization prob-
lems.}
7.3 Random Rounding and MAX-SAT
The aim of this section is to combine the method of the relaxation to linear
programming with random rounding in order to design a randomized approx-
imation algorithm for MAX-SAT. At least for formulas with short clauses,
the expected number of satisﬁed clauses should be larger than the number
of clauses satisﬁed by the solutions produced by the naive RSAM algorithm
from Exercise 2.3.35 that simply generates a random11 assignment.
Before presenting the new algorithm, we show how to express an instance
of MAX-SAT as an instance of 0/1-LP. Let
Φ = F1 ∧F2 ∧. . . ∧Fm
be a formula over the set {x1, x2, . . ., xn} of Boolean variables, where Fi is
a clause for i = 1, 2, . . ., m, n, m ∈IN −{0}. Let Set(Fi) be the set of all
literals12 in Fi. We denote by Set+(Fi) the set of all variables that occur in
Fi in the positive setting (without negation), and by Set−(Fi) the set13 of all
variables whose negations occur in Fi. We assume Set+(Fi) ∩Set−(Fi) = ∅,
because in the opposite case Fi is always satisﬁed, and we do not need to
consider such clauses in the instances of MAX-SAT.
We denote by In+(Fi) and In−(Fi) the set14 of indices of the variables in
Set+(Fi) and Set−(Fi), respectively. Using this notation one can express the
instance Φ of MAX-SAT as the following instance LP(Φ) of 0/1-LP:
Maximize
m

j=1
zj
under the m linear constraints

i∈In+(Fj)
yi +

i∈In−(Fj)
(1 −yi)
≥
zj for j = 1, 2, . . ., m
(7.7)
and the n + m constraints
11with respect to the uniform probability distribution
12If, for instance, Fi = x1 ∨x3 ∨x7 ∨x8, then Set(Fi) = {x1, x3, x7, x8}.
13For Fi = x1 ∨x3 ∨x7 ∨x8, Set+(Fi) = {x1, x8} and Set−(Fi) = {x3, x7}.
14For Fi = x1 ∨x3 ∨x7 ∨x8, In+(Fi) = {1, 8} and In−(Fi) = {3, 7}.

7.3 Random Rounding and MAX-SAT
217
yi ∈{0, 1} for i = 1, . . ., n, and
(7.8)
zj ∈{0, 1} for j = 1, . . ., m.
For i = 1, 2, . . ., n, the variable yi overtakes the role of the Boolean variable
xi in this representation. The idea of this representation LP(Φ) of Φ is that
zj can have the value 1 only if15 at least one variable from Set+(Fj) has been
assigned the value 1 or at least one variable from Set−(Fj) has been assigned
the value 0 (i.e., only if Fj is satisﬁed). Thus, the objective function m
j=1 zj
counts the number of satisﬁed clauses.
The relaxed version Rel-LP(Φ) of LP(Φ) can be obtained from LP(Φ) by
exchanging the n + m constraints (7.8) by the following 2 · n + 2 · m linear
constraints:
yi ≥0, yi ≤1 for i = 1, . . ., n, and
(7.9)
zj ≥0, zj ≤1 for j = 1, . . ., n.
Let α(u) for every u ∈{y1, y2, . . ., yn, z1, z2, . . ., zm} be the value of u in
an optimal solution for the instance Rel-LP(Φ) of LP. Since the set of feasible
solutions of 0/1-LP(Φ) is a subset16 of the feasible solutions of Rel-LP(Φ),
the following is true:
m
j=1 α(zj) is an upper bound on the number of clauses that
can be satisﬁed by any assignment to the variables of Φ.
(7.10)
To produce an assignment to the variables x1, x2, . . ., xn, one can round
the values α(y1), α(y2), . . ., α(yn) of the optimal solution
(α(y1), . . ., α(yn), α(z1), . . ., α(zm))
of Rel-LP(Φ). How to round is explained in the following presentation of the
designed algorithm.
Algorithm RRR (Relaxation with Random Rounding)
Input: A formula Φ = F1 ∧F2 ∧. . . ∧Fm over X = {x1, . . ., xn} in CNF,
n, m ∈IN −{0}.
Step 1: Reduce the instance Φ of MAX-SAT to the instance 0/1-LP(Φ) of
0/1-LP with the constraints (7.7) and (7.8).
Step 2: Relax 0/1-LP(Φ) to the instance Rel-LP(Φ) with the constraints (7.7)
and (7.9), and solve Rel-LP(Φ) eﬃciently.
Let (α(y1), α(y2), . . ., α(ym), α(z1), α(z2), . . ., α(zm)) be the computed
optimal solution for Rel-LP(Φ).
15because of the j-th constraints of (7.7)
16The constraints (7.8) strengthen the constraints (7.9).

218
7 Optimization and Random Rounding
Step 3:
Choose, uniformly, n values γ1, . . ., γn from the interval [0, 1] at random.
for i = 1 to n do
if γi ∈[0, α(yi)] then
βi := 1
else
βi := 0.
Output: RRR(Φ) = (β1, β2, . . ., βn)
Hence, α(yi) is the probability that xi takes the value 1. The main diﬀer-
ence with the random sampling algorithm RSAM is that RSAM takes its ran-
dom choice with respect to the uniform probability distribution over {0, 1}n
while RRR chooses an assignment with respect to the probability distribution
determined by α(y1), α(y2), . . ., α(yn).
We start our analysis of RRR by giving a lower bound on the probability
that RRR satisﬁes a clause of k literals.
Lemma 7.3.9. Let k be a positive integer and let Fj by a clause of k lit-
erals in Φ. Let α(y1), . . ., α(yn), α(z1), . . ., α(zm) be the optimal solution of
Rel-LP(Φ) computed by RRR(Φ).
Then the probability that the assignment RRR(Φ) satisﬁes the clause Fj
is at least

1 −

1 −1
k
k
· α(zj).
Proof. Since one considers the clause Fj independently of other clauses, one
can assume without loss of generality that it contains only uncomplemented
variables, and that it can be expressed17 as
Fj = x1 ∨x2 ∨. . . ∨xk.
From the j-th constraint in (7.7) of Rel-LP(Φ), we have
y1 + y2 + . . . + yk ≥zj.
(7.11)
The clause Fj remains unsatisﬁed if and only if all the variables x1, x2, . . ., xk
are set to zero. Since the random rounding in step 3 of RRR runs indepen-
dently for each variable, this occurs with the probability
k

i=1
(1 −α(yi)).
Complementary, Fj is satisﬁed with the probability
17This way we avoid double indexing and additional notation for negated vari-
ables.

7.3 Random Rounding and MAX-SAT
219
1 −
k

i=1
(1 −α(yi)).
(7.12)
Under the constraints (7.11), the function (7.12) is minimized when
α(yi) = α(zj)
k
for i = 1, 2, . . ., k. In this way we obtain
Prob(Fj is satisﬁed) ≥1 −
k

i=1

1 −α(zj)
k

.
(7.13)
The lower bound (7.13) on the probability of satisfying Fj can be viewed
as a function of one variable α(zj) ∈[0, 1]. To complete the proof it suﬃces
to show that, for every positive integer k,
fk(r) = 1 −

1 −r
k
k
≥

1 −

1 −1
k
k
· r = gk(r)
(7.14)
for all r ∈[0, 1] (and so for every α(zj)). Next, we show that the relation
between the functions g(r) and f(r) is as shown in Figure 7.1.
1
0
1 −
1 −1
k
k
f(r)
g(r)
Fig. 7.1.
Since fk is a concave function and gk is a linear function, it is suﬃcient to
show (Figure 7.1) that

220
7 Optimization and Random Rounding
fk(0) = gk(0) and fk(1) = gk(1).
Clearly,
fk(0) = 1 −(1 −0)k = 0 = gr(0) and fk(1) = 1 −

1 −1
k
k
= gk(1).
Inserting r = α(zj) into (7.14) and combining (7.13) with (7.14) one obtains
the assertion of Lemma 7.3.9.
⊓⊔
Theorem 7.3.10. The algorithm RRR runs in polynomial time and it is
(i) a randomized E
0
e
(e−1)
1
-approximation algorithm for MAX-SAT and
(ii) a randomized E
0
kk
(kk−(k−1)k)
1
-approximation algorithm for MAX-EkSAT.
Proof. First we analyze the time complexity of the algorithm RRR. The re-
duction in step 1 can be performed in linear time. The instance Rel-LP(Φ) of
LP can be solved in polynomial time. Step 3 can be executed in linear time.
Following (7.10), in order to show that RRR is an E[d]-approximation
algorithm it suﬃces to show that the expected number of satisﬁed clauses is
at least
d−1 ·
m

j=1
α(zj).
Our probability space18 is ({0, 1}n, Prob), where
Prob({(δ1, δ2, . . ., δn)}) =
n

i=1
qj,
where
qi = α(yi)
if
δi = 1 and
qi = 1 −α(yi)
if
δi = 0.
for i = 1, 2, . . ., n. For δ = (δ1, . . ., δn) and j = 1, 2, . . ., m we consider the
random variable Zj deﬁned by
Zj(δ) =
	
1 if δ satisﬁes the clause Fj
0 if δ does not satisfy the clause Fj.
Since Zj is an indicator variable, E[Zj] is the probability that the output
RRR(Φ) of RRR satisﬁes the clause Fj. Therefore, Lemma 7.3.9 provides
E[Zj] ≥

1 −

1 −1
k
k
· α(zj)
(7.15)
18We identify each computation of RRR with its output.

7.3 Random Rounding and MAX-SAT
221
if Fj consists of k literals. Let us consider the random variable
Z =
m

j=1
Zj
that counts the number of satisﬁed clauses. If all clauses consist of exactly k
literals,19 the linearity of expectation provides the following lower bound on
E[Z]:
E[Z]
=
m

j=1
E[Zj]
≥
(7.15)
m

j=1

1 −

1 −1
k
k
· α(zj)
≥

1 −

1 −1
k
k
·
m

j=1
α(zj).
(7.16)
Since OptMAX-SAT(Φ)
≤
(7.10)
m
j=1 α(zj), we obtain
E[RatioRRR(Φ)]
=
OptMAX-EkSAT(Φ)
E[Z]
≤
(7.9)
(7.10)
m
j=1 α(zj)

1 −

1 −1
k
k
· m
j=1 α(zj)
=

1 −

1 −1
k
k−1
=
kk
kk −(k −1)k .
Hence, we have proved claim (ii).
Since

1 −1
k
k ≤e−1 for all k ∈IN −{0}, we have
1 −

1 −1
k
k
≥1 −1
e
(7.17)
for all positive integers k. Inserting (7.17) into (7.16), we obtain
E[Z] ≥

1 −1
e

·
m

j=1
α(zj).
Therefore
19if Φ is an instance of MAX-EkSAT

222
7 Optimization and Random Rounding
E[RatioRRR(Φ)] = OptMAX-SAT(Φ)
E[Z]
≤

1 −1
e
−1
=
e
e −1.
⊓⊔
We note that the algorithm RRR has a special, very appreciative property
with respect to the success probability ampliﬁcation by repeated runs. One
does not need to repeat the complete runs of RRR. Once the ﬁrst two steps of
RRR are executed, and so the probability space ({0, 1}n, Prob) is determined,
it suﬃces to execute several independent random choices in this probability
space. Thus, the most expensive step 2 is executed only once, independently
of the number of assignments one wants to generate at random.
Exercise 7.3.11. Let Φ be a formula consisting of m = 3 · d clauses, where
d clauses are of the length 2, the next d clauses are of length 3, and the last
d clauses consist of 4 literals. Estimate a lower bound for the expectation
E[RatioRRR(Φ)].
7.4 Combining Random Sampling and Random
Rounding
Now, we have two diﬀerent algorithms for MAX-SAT. On the one hand the
algorithm RSAM based on random sampling, and on the other hand the al-
gorithm RRR designed in Section 7.3 by the relaxation method and random
rounding. Since 2 >
e
e−1, the algorithm RSAM with E[RatioRSAM(Φ)] ≤2 for
every formula Φ provides in general a weaker guarantee that the algorithm
RRR with E[RatioRRR(Φ)] <
e
e−1.
Surprisingly, if one looks at the behavior of these algorithms more carefully,
one sees that the naive algorithm RSAM is better for problem instances with
long clauses. Since
2k
2k −1 <
kk
kk −(k −1)k
for k ≥3, RSAM assures a better upper bound on the expected approxi-
mation ratio for MAX-EkSAT instances than RRR. Hence, one can consider
RSAM and RRR as incomparable algorithms for MAX-SAT, because for some
formulas RSAM can provide better results than RRR, and vice versa.
Exercise 7.4.12. Find an inﬁnite set of input instances of MAX-SAT for
which the expected solutions computed by RSAM are better than the expected
solutions computed by RRR.
Exercise 7.4.13. Find an inﬁnite set of instances of MAX-SAT such that one
can expect better results from RRR than from RSAM.

7.4 Combining Random Sampling and Random Rounding
223
Exercise 7.4.14. Let k be a positive integer, k ≥3. Find instances Φ of
MAX-EkSAT such that
E[RatioRRR(Φ)] < E[RatioRSAM(Φ)] .
Because of the incomparability of RSAM and RRR, a very natural idea
is to combine these algorithms into one algorithm by running them indepen-
dently in parallel and then taking the better of the two solutions computed.
Next, we show that the resulting algorithm has an expected approximation
ratio of at most 4/3.
Algorithm COMB
Input: A formula Φ = F1 ∧F2 ∧. . . ∧Fm in CNF over a set X of Boolean
variables.
Step 1: Compute an assignment β for X by the algorithm RSAM (i.e., β :=
RSAM (Φ)).
Step 2: Compute an assignment γ for X by the algorithm RRR (i.e., γ :=
RRR (Φ)).
Step 3:
if β satisﬁes more clauses of Φ than γ then
output (β)
else
output (γ).
Theorem 7.4.15. The algorithm COMB is a polynomial-time, randomized
E
 4
3

-approximation algorithm for MAX-SAT.
Proof. Since both RSAM and RRR work in polynomial time, COMB is a
polynomial-time algorithm, too.
Now, we analyze the expected approximation ratio of COMB. Let Φ =
F1 ∧. . .∧Fm be a formula over X = {x1, . . ., xn}. Let (SRSAM,Φ, ProbRSAM)
be the probability space for the analysis of RSAM, where SRSAM,Φ is the set of
all 2n computations of RSAM on Φ and ProbRSAM is the uniform probability
distribution over SRSAM,Φ. Let (SRRR,Φ, ProbRRR) be the probability space for
the analysis of the work of RRR, where SRRR,Φ is the set of all 2n computations
of RRR on Φ and ProbRRR is the probability distribution determined by
the optimal solution for Rel-LP(Φ) computed in the second step of RRR.
Obviously,
(SRSAM,Φ × SRRR,Φ, Prob),
with
Prob({(C, D)}) = ProbRSAM({C}) · ProbRRR({D})
for all (C, D) ∈SRSAM,Φ × SRRR,Φ is the probability space20 for the analysis
of the work of COMB on Φ. Let us consider the following random variables.
20For simplicity we view the computations of COMB as pairs (C, D), where C is
a run of RSAM and D is a run of RRR.

224
7 Optimization and Random Rounding
For all (C, D) ∈SRSAM,Φ × SRRR,Φ, let
Y ((C, D)) be the number of clauses satisﬁed by β as the output of C
and let
Z((C, D)) be the number of clauses satisﬁed by the output γ of D.
Hence, Y counts the number of clauses satisﬁed by the output of a run of
RSAM, and Z counts the number of clauses satisﬁed by the assignment com-
puted by a run of RRR. We introduce a new random variable U = max{Y, Z},
deﬁned by
U((C, D)) = max{Y ((C, D)), Z((C, D))}
for all computations (C, D) of COMB.
Hence, U counts the number of clauses satisﬁed by the output of a run
(C, D) of the algorithm COMB. Since
max{Y ((C, D)), Z((C, D))} ≥Y ((C, D)) + Z((C, D))
2
for all (C, D) ∈SRSAM,Φ × SRRR,Φ, we have
E[U] ≥E[Y ] + E[Z]
2
.
(7.18)
From the analysis of RRR, we know that no assignment can satisfy more
than m
j=1 α(zj) clauses.
Following (7.18), it is suﬃcient to show that
E[Y ] + E[Z]
2
≥3
4 ·
m

j=1
α(zj).
(7.19)
To show this, we investigate the probability of satisfying every particular
clause with respect to its length. For each integer k ≥1, let C(k) be the set of
clauses from {F1, F2, . . ., Fm} that consist of exactly k literals. Lemma 7.3.9
implies that
E[Z] ≥

k≥1

Fj∈C(k)

1 −

1 −1
k
k
· α(zj).
(7.20)
Since α(zj) ∈[0, 1], the analysis of RSAM provides the following lower
bound on E[Y ]:
E[Y ] =

k≥1

Fj∈C(k)

1 −1
2k

≥

k≥1

Fj∈C(k)

1 −1
2k

· α(zj).
(7.21)
Hence, we obtain

7.5 Summary
225
E[U]
≥
(7.18)
E[Y ] + E[Z]
2
≥
(7.20)
(7.21)
1
2 ·

k≥1

Fj∈C(k)

1 −1
2k

+

1 −

1 −1
k
k
· α(zj)
≥
1
2 · 3
2 ·

k≥1

Fj∈C(k)
α(zj)
{Since (1−2−k)+(1−(1−k−1)k) ≥3
2 for all positvie
integers k.}
=
3
4 ·
m

j=1
α(zj).
Therefore,
E[RatioCOMB(Φ)] = OptMAX-SAT(Φ)
E[U]
≤
m
j=1 α(zj)
3
4 · m
j=1 α(zj)
= 4
3.
⊓⊔
Exercise 7.4.16. Implement the algorithm COMB and test it for real
MAX-SAT instances. Try to estimate the average approximation ratio with
respect to your input data.
7.5 Summary
The relaxation to linear programming is a robust method for designing ap-
proximation algorithms for hard optimization problems as well as for com-
puting bounds on the costs of optimal solutions. The kernel of this method is
that many problems can be naturally expressed as instances of the NP-hard
integer linear programming and 0/1-linear programming, and that the basic
problem of linear programming is eﬃciently computable. Based on these facts,
one obtains the following schema for applying this method.
1. Reduction
A given instance of an optimization problem is expressed as an instance
of ILP or 0/1-LP.

226
7 Optimization and Random Rounding
2. Relaxation
The instance of ILP or 0/1-LP is relaxed to an instance of LP21 by re-
moving the nonlinear constraints of the domain of the output values. The
instance of LP is eﬃciently solved.
3. Solving the original problem instance
The optimal solution of the relaxed LP instance is used to create a feasi-
ble solution for the original problem instance. The cost of the computed
optimal solution for the relaxed LP instance is a bound on the achievable
cost of the feasible solutions for the original problem instance.
While, today, parts 1 and 2 of this schema can be performed by standard,
eﬃcient algorithms, part 3 may require that we apply distinct concepts and
methods, and it is a matter of investigation for various concrete optimization
problems.
In this book we presented two techniques for implementing part 3 of the
schema. First, we used simple rounding for the minimum vertex cover problem,
and got a polynomial-time 2-approximation algorithm for MIN-VC in this way.
In Section 7.3 we applied random rounding to design a randomized,
polynomial-time E[e/(e −1)]-approximation algorithm for MAX-SAT. If one
executes this algorithm and the algorithm RSAM22 on the same MAX-SAT
instance in parallel, and then takes the better of the two computed assign-
ments, one obtains a E[4/3]-approximation algorithm for MAX-SAT.
The most involved source for the study of the design of approximation al-
gorithms by the relaxation to linear programming is the textbook by Vazirani
[Vaz01]. A detailed introduction to the application of this method is presented
in [Hro03], too. There are many good textbooks on linear programming. For
computer scientists, we warmly recommend the excellent, classical book by
Papadimitriou and Steiglitz [PS82].
The famous Simplex algorithm for solving instances of linear programming
was discovered by Dantzig [Dan49] in 1947. Klee and Minty [KM72] were the
ﬁrst researchers who constructed LP instances on which the Simplex algorithm
does not work eﬃciently.23 The long stated open problem about the existence
of a polynomial-time algorithm for LP was solved by Khachian [Kha94] in
1979 in a positive sense.
An excellent source for the study of MAX-SAT is the book [MPS98] edited
by Mayr, Pr¨omel, and Steger.
21All constraints of the relaxed instance are linear equations or inequalities.
22which is based on a simple application of the method of random sampling
23i.e., in exponential time

A
Fundamentals of Mathematics
Chance favors only those
whose spirit has been prepared already,
those unprepared cannot see the hand
stretched out to them by fortune.
Louis Pasteur
A.1 Objectives
In computer science, one views mathematics on the one hand as a language
for precise text formulations with an unambiguous interpretation, and on the
other hand as a collection of instruments for analyzing and solving various
situations and tasks. Mathematics is a living language that continuously grows
and creates new notions and models that enable us to describe more and more
about our world and to argue more and more in depth.
Methods of mathematics are developing intensively in order to master
further real-world problems. The history of mathematics is full of impulses
coming from other scientiﬁc disciplines, engineering and practice. Computer
science has a very special relationship with mathematics. It does not only pose
requirements and wishes for developing new terms and new formal methods
and does not only use mathematics as its basic instrument. Computer science
in its own interest also takes a very active part in the development of math-
ematics by formulating new formal concepts, by creating new fundamental
terms, and by discovering essential, deep facts of pure mathematical nature.
The famous PCP Theorem and the deterministic polynomial-time primality
test are only two of the well-known examples. Also the design of randomized
algorithms, and so the content of this book, can be assigned to mathematics
as well as to computer science.
Our introduction to randomization is built on elementary notions and
instruments of probability theory. Therefore, we started this book with an
introduction to probability theory. But, in diﬀerent parts of this textbook,
we also need methods and knowledge of other areas of mathematics, such as
combinatorics, graph theory, algebra, and number theory. The objective of
this appendix is to present the most frequently used results and concepts of
mathematics applied here, and so to make this textbook self-contained.
In this short appendix we do not aim to provide an involved introduction
to several areas of mathematics. We give detailed explanations and proof for
only those results that can contribute to the understanding of the design of

228
A Fundamentals of Mathematics
randomized algorithms and are helpful in developing corresponding ideas and
approaches. Some assertions, though needed in our arguments, we present
without proofs if the proofs do not have any strong relation to the design and
analysis of randomized algorithms.
Section A.2 is devoted to number theory and algebra, which are crucial
for success in ﬁnding eﬃcient randomized algorithms. The content of this
section is especially important for the design of algorithms for the number-
theoretical problems in Chapters 4, 5, and 6. The Fundamental Theorem of
Arithmetics, Fermat’s Little Theorem, the Chinese Remainder Theorem, the
Euclidean algorithm, and Lagrange’s Theorem are the most frequently applied
discoveries of algebra and number theory used as powerful instruments in the
design of randomized algorithms. Therefore, the derivation of these results is
carefully explained and presented in detail. Also, the Prime Number Theorem
(one of the most fundamental discoveries of mathematics) is one of the most
frequently applied results of mathematics. In spite of its high importance, we
omit its proof. We do this not only because of the high complexity of its proof,
but mainly because the techniques of the proof are not relevant to any of the
ideas developed in our applications.
Section A.3 brieﬂy presents a few combinatorial arguments that are applied
to the analysis of the algorithms designed here.
A.2 Algebra and Number Theory
We use the following notion for the sets considered here:
IN = {0, 1, 2, . . .} is the set of all natural numbers,
ZZ is the set of all integers,
ZZn = {0, 1, 2, . . ., n −1} is the ﬁnite set of all natural numbers smaller
than n,
QI is the set of rational numbers,
IR is the set of all real numbers,
QI + is the set of positive rational numbers, and
IR+ is the set of positive real numbers.
Let a and k be natural numbers, and let d be a positive integer.
If
a = k · d,
then we say that1
d divides a and write d | a.
If a = k · d and, additionally, k ≥1, then we say that
a is a multiple of d.
1It is an agreement that every positive integer divides the number 0.

A.2 Algebra and Number Theory
229
If d | a, we also say that d is a divisor of a. For every positive integer a,
we call the numbers 1 and a trivial divisors of a. All divisors of a except 1
and a itself are called factors of a. For instance, 2, 3, 4, 6, 8, and 12 are the
factors of 24.
Deﬁnition A.2.1. A prime is any positive integer p > 1 that does not have
any factor (i.e., 1 and p are the only divisors of p).
An integer b that is not a prime (i.e., b = a · c for some a, c > 1) is called
composite.
The smallest primes are 2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, . . .. Primes play
an important role in number theory and algebra, and so also in the design
of randomized algorithms. The ﬁrst crucial and useful property of primes is
that tall positive integers greater than 1 can be represented as a product of
primes. Here, one considers a single prime as a product of primes, too.
Observation A.2.2. Every n ∈IN −{0, 1} can be represented as a product
of primes.
Proof. We prove this assertion by induction. Clearly, the prime 2 has to be
considered a product of primes.
Assume that every natural number (except 0 and 1) smaller than n, n ≥3,
can be represented as a product of primes. We aim to show that n can be
represented as a product of primes, too.
If n is a prime, then we have already the desired representation.
If n is composite, then
n = p · q,
where p and q are factors of n. Since both p and q are smaller than n, the
induction hypothesis says that p and q can be represented as products of
primes. Hence, n = p · q can be represented as a product of primes.
⊓⊔
In what follows we present the products of primes in the form
n = pi1
1 · pi2
2 · . . . · pik
k ,
(A.1)
where p1 < p2 < . . . < pk are primes and i1, i2, . . ., ik are positive integers.
The following theorem says that every positive integer n has a unique represen-
tation of this form. We also call this form, n = pi1
1 ·. . .·pik
k , the factorization
of n.
Theorem A.2.3. The Fundamental Theorem of Arithmetics
Every integer n, n ≥2, can be uniquely represented as a product of primes
n = pi1
1 · pi2
2 · . . . · pik
k ,
where p1 < p2 < . . . < pk are primes and i1, i2, . . ., ik ∈IN−{0}, k ∈IN−{0}.

230
A Fundamentals of Mathematics
Proof. The fact that n can be expressed as a product of primes has already
been shown in Observation A.2.2. Next, we have to prove that the decompo-
sition of n into a product of primes is unique up the the rearrangement of
factors (i.e., that the factorization of n is unique). We prove this for every
integer n ≥2 in an indirect way.
Let m be the smallest integer from IN −{0, 1} such that
m = p1 · p2 · . . . · pr = q1 · q2 · . . . · qk,
(A.2)
where p1 ≤p2 ≤. . . ≤pr and q1 ≤q2 ≤. . . ≤qk are primes and these two
representations are diﬀerent (i.e., r = k and pb = qb for b = 1, . . ., k does not
hold).
We distinguish three cases.
(i) r = 1 or k = 1.
The case r = k = 1 cannot occur, because it would mean m = p1 = q1 for
p1 ̸= q1.
The case r = 1 and k > 1 also cannot occur, because it contradicts to the
assumption that p1 is a prime. Analogously, k = 1 and r ≥2 contradicts
the primality of q1.
(ii) There exists an l ∈{1, . . ., r} and an s ∈{1, . . ., k} such that pl = qs and
r > 1, k > 1.
In this case, the number
m/pl = p1 · p2 · . . . · pl−1 · pl+1 · pr = q1 · q2 · . . . · qs−1 · qs+1 · qk
has two diﬀerent factorizations. Since m/pl < m, this is a contradiction
to the assumption that m is the smallest number without a unique fac-
torization.
(iii) {p1, p2, . . ., pr} ∩{q1, q2, . . ., qk} = ∅and r > 1, k > 1.
Without loss of generality, we assume that p1 < q1. Consider the number
m′ = m −(p1q2q3 . . . qs).
(A.3)
Substituting the two representations (A.2) of m for m into (A.3), we may
write the integer m′ in either of the two forms
m′ = (p1p2 . . . pr) −(p1q2 . . . qs) = p1(p2p3 . . . pr −q2q3 . . . qs)
(A.4)
and
m′ = (q1q2 . . . qs) −(p1q2 . . . qs) = (q1 −p1) · (q2q3 . . . qs).
(A.5)
Since p1 < q1, (A.3) and (A.5) together imply that
2 ≤m′ < m.
From our assumption, m′ must have a unique factorization. The equation
(A.4) implies that the prime p1 is a factor of m′. Since in case (iii) one

A.2 Algebra and Number Theory
231
assumes p1 /∈{q2, q3, . . ., qs}, from representation (A.5) of m′, we have
that p1 is a factor of q1 −p1. Hence, there is an integer a ≥1, such that
q1 −p1 = p1 · a.
Therefore,
q1 = p1 · a + p1 = p1 · (a + 1),
which contradicts to the fact that q1 is a prime.
Thus, in all three cases (i), (ii), and (iii) the assumption about the exis-
tence of a positive integer with at least two diﬀerent factorizations leads
to a contradiction, and so the assertion of Theorem A.2.3 holds.
⊓⊔
The Fundamental Theorem of Arithmetics assures the following divisibility
property, which is often applied in this book.
Corollary A.2.4. Let p be a prime, and let a, b be positive integers. If
p | a · b,
then
p | a or p | b.
Proof. Again, we give an indirect proof. Assume that p | a · b, and that p is a
factor of neither a nor b. Hence, the factorizations of a and b do not contain
p, and so the corresponding factorization of a · b does not contain p.
Since p divides a · b, there exists a positive integer t such that
a · b = p · t.
Clearly, the product of p and the factorization of t is also a factorization of
a · b, and this factorization of a · b contains the prime p.
Thus, we have two diﬀerent factorizations of a · b, which contradicts the
Fundamental Theorem of Arithmetics.
⊓⊔
Exercise A.2.5. Prove the following assertion. For all positive integers a, b,
and c, if c divides the product a · b, then there exist two positive integers c1
and c2 such that
c = c1 · c2, c1 | a and c2 | b.
Exercise A.2.6. Prove the following assertion. Let a, b, c, and d be arbitrary
positive integers. If a = b + c and d divides both a and b, then d divides c,
too.
Exercise A.2.7. Prove the following assertion. Let p be a prime. Then there
exists no positive integer n such that p divides both n and n −1.

232
A Fundamentals of Mathematics
One of the ﬁrst questions that arose concerning primes was whether there
are inﬁnitely many diﬀerent primes or whether the cardinality of the class of
primes is an integer. The following assertion answers this ﬁrst, simple question
about primes.
Theorem A.2.8. There are inﬁnitely many primes.
Proof. We present the original proof of Euclid as an indirect proof.
Assume there are ﬁnitely many diﬀerent primes, say p1, p2, . . ., pn for a
positive integer n. Any other number is composite, and so must be divisible
by at least one of the primes p1, p2, . . ., pn. Consider the speciﬁc number
a = p1 · p2 · . . . · pn + 1.
Since a > pi for every i ∈{1, 2, . . ., n}, a must be composite, and so at least
one of the primes must divide a. Clearly2 this is impossible and so we have a
contradiction. Hence, we have proved that there are inﬁnitely many primes.
⊓⊔
Note that the proof of Theorem A.2.8 does not provide any method for con-
structing an arbitrarily large sequence of primes. If p1, p2, . . ., pn are primes,
the the number a = p1 · p2 · · · . . . · pn + 1 does not need to be a prime. For
instance, for p1 = 2, p2 = 3, p3 = 5, p4 = 7, p5 = 11, and p6 = 13, the number
a = 30031 = 2 · 3 · 5 · 7 · 11 · 13 + 1 = 59 · 509
is composite. Moreover, if a is a prime and p1, p2, . . ., pn are the n smallest
primes, then a does not need to be the (n+1)-th smallest prime. For instance,
7 = 2 · 3 + 1
and 7 is the fourth smallest prime, not the third one. The only right conclusion
of the proof of Theorem A.2.8 is that there must exist a prime p greater than
pn and smaller than or equal to a. Therefore, once can search in the interval
(pn, a] for the (n + 1)-th smallest prime.
A large eﬀort in number theory was devoted to ﬁnding a simple mathemati-
cal formula for eﬃciently generating the sequence of all primes. Unfortunately,
these attempts have not succeeded up to the present time, and it is question-
able whether such a formula exists. On the other hand, another important
question,
How many primes are contained in {1, 2, . . ., n]?
2Let there be a j ∈{1, . . ., n} such that pj | a. Obviously, pj divides the product
p1 · p2 · . . . · pj−1 · pj · pj+1 · . . . · pn. Following Exercise A.2.6, if pj divides both a
and p1 · . . . · pn, and a = p1 · . . . · pn + 1, then pj must divide 1, too.

A.2 Algebra and Number Theory
233
has been answered to some extent. The investigation of the density of primes
in IN is of special importance for the design of randomized algorithms and
systems. The following Prime Number Theorem is one of the most fundamen-
tal discoveries of mathematics, with an enormous impact and many relations
outside number theory.
In what follows we denote by Prim (n) the cardinality of the set PRIM (n)
of all primes in {1, 2 . . ., n}.
Theorem A.2.9. Prime Number Theorem
lim
n→∞
Prim (n)
n/ ln n
= 1.
In other words, the Prime Number Theorem says that the density
(Prim (n))/n
of the primes among the ﬁrst n positive integers tends to
1/ ln n
as n increases. Table A.1 shows that 1/ ln n is a good “approximation” of
Prim (n) /n already for “small” n (for which one is able to compute PRIM (n)
exactly by a computer).
Table A.1.
n Prim (n) /n 1/ ln n Prim(n)
n/ ln n
103
0.168
0.145
1.159
106
0.0885
0.0724
1.084
109
0.0508
0.0483
1.053
We call attention to the fact, that, for n ≥100, it is even provable that
1 ≤Prim (n)
n/ ln n
≤1.23,
(A.6)
and these bounds for Prim (n) are in fact, what we primarily use in the anal-
ysis of error probability in this book.
Obviously, for every natural number a and every positive integer d, one
can express a by means of d as follows:
a = k · d + r for all k, r ∈IN and r < d.
Clearly, the number k is the largest integer, for which k ·d ≤a, and we denote
k as a div d. The number r is the remainder of the division of a by d. For

234
A Fundamentals of Mathematics
given a and d the representation k · d + r is unique, i.e., the numbers k and
r are unambiguously determined. Let us prove this claim. Assume, that one
has the following two representations of a:
k1 · d + r1 = a = k2 · d + r2,
where r1, r2 ∈{0, 1, . . ., d −1}, r2 ≥r1. Subtracting r1 and k2 · d from both
sides of this equation results in
k1 · d −k2 · d = r2 −r1
and so in
(k1 −k2) · d = r2 −r1.
Hence, d must be divide r2 −r1. Since (r2 −r1) ∈{0, 1, . . ., d −1}, one has
r2 −r1 = 0 and so r1 = r2.
Therefore
(k1 −k2) · d = 0.
Since d > 0, we obtain
k2 −k1 = 0, and so k1 = k2.
Let a be a positive integer, and let d be a natural number. Let r and k be
the unambiguously determined numbers with
a = k · d + r and r < d.
In what follows we denote r by a mod d. As already noted, the number k is
denoted by a div d.
For all natural numbers a and b and any positive integer d, the equation
a mod d = b mod d
is denoted by the following Gauss’ congruence relation.
a ≡b
(mod d).
Observation A.2.10. For all positive integers a, b, and d, a ≥b, the following
claims are all equivalent:
(i) a ≡b (mod d),
(ii) d divides a −b,
(iii) a = b + k · d for a k ∈IN.
Proof. We prove the implications (i) ⇒(ii), (ii) ⇒(iii), and (iii) ⇒(i), which
together prove the equivalence claimed.

A.2 Algebra and Number Theory
235
(a) (i) ⇒(ii)
From the deﬁnition of a ≡b (mod d), there exists a z ∈IN, such that
z = a mod d = b mod d.
In other words,
a = l · d + z and b = l′ · d + z
for some l, l′ ∈IN. Then,
a −b = l · d + z −(l′ · d + z) = l · d −l′ · d = (l −l′) · d.
Hence, d divides a −b.
(b) (ii) ⇒(iii)
If d divides a −b, then
a −b = k · d
for some natural number k. Adding b to both sides of this equality we
directly obtain
a = k · d + b.
(c) (iii) ⇒(ii)
Let a = b + k · d for a natural number k. As we already have learned, one
can express a and b as follows:
a = l · d + z1 and b = l′ · d + z2
for suitable l, l′, z1, z2 ∈IN, z1 < d, z2 < d.
Inserting these expressions in a = b + k · d, we obtain
l · d + z1 = l′ · d + z2 + k · d = (l′ + k) · d + z2,
and so z1 = z2 due to the existence of unique numbers a mod d and
a div d.
⊓⊔
Deﬁnition A.2.11. For all positive integers a and b, the greatest common
divisor of a and b is
GCD (a, b) = max{d ∈IN | d divides both a and b}.
The lowest common multiple of a and b is
LCM (a, b) = min{c ∈IN | a divides c and b divides c}.
By convention GCD (0, 0) = LCM (0, 0) = 0.
Exercise A.2.12. Prove that for all positive integers a and b,
a · b = GCD (a, b) · LCM (a, b) .

236
A Fundamentals of Mathematics
The Fundamental Theorem of Arithmetics directly implies the following
assertion.
Observation A.2.13. Let
a = p1 · . . . · pr · q1 · . . . · qs and b = p1 · . . . · pr · h1 · . . . · hm
be factorizations of a and b, a, b ∈IN−{0, 1}, where {q1, . . ., qs}∩{h1, . . ., hm} ̸=
∅. Then,
GCD (a, b) = p1 · . . . · pr
and
LCM (a, b) = p1 · . . . · pr · q1 · . . . · qs · h1 · . . . · hm.
Exercise A.2.14. Prove the assertion of Observation A.2.13.
Computing the factorization of a number is a hard algorithmic task, and
so we are frequently required to eﬃciently estimate GCD (a, b) without know-
ing the factorizations of a and b. An eﬃcient computation of GCD (a, b) is
provided by Euclid’ algorithm, which is based on the following assertions.
Lemma A.2.15. Let a, b, d ∈IN, d > 0.
(i) If d | a and d | b, then
d | (a · x + b · y)
for all x, y ∈ZZ.
(ii) If a | b and b | a, then a = b.
Proof. First, we prove (i), and then, (ii).
(i) If d | a and d | b, then
a = n · d and b = m · d
for suitable natural numbers n and m. Let x and y be arbitrary integers.
Then,
a · x + b · y = n · d · x + m · d · y = d · (n · x + m · y),
and so d divides the number a · x + b · y.
(ii) The fact a | b implies a ≤b. Analogously, b ≤a follows from the fact b | a.
Therefore, a = b.
⊓⊔
The following properties of GCD (a, b) are direct consequences of Deﬁni-
tion A.2.11.
Observation A.2.16. For all positive integers a, b, and k,
(i) GCD (a, b) = GCD (b, a),
(ii) GCD (a, k · a) = a,

A.2 Algebra and Number Theory
237
(iii) GCD (a, 0) = a, and
(iv) if k | a and k | b, then k | GCD (a, b).
Exercise A.2.17. Prove that GCD as an operator is associative, i.e., prove
that, for all natural numbers a, b, and c,
GCD (a, GCD (b, c)) = GCD (GCD (a, b) , c) .
The most important property of GCD (a, b) for its eﬃcient computation is
presented in the following lemma.
Lemma A.2.18. For all a, b ∈IN, b > 0,
GCD (a, b) = GCD (b, a mod b) .
Proof. We shall prove that GCD (a, b) and GCD (b, a mod b) divide each
other, and so by Lemma A.2.15(ii) they must be equal.
(i) First, we show that GCD (a, b) divides GCD (b, a mod b).
From the deﬁnition of GCD, GCD (a, b) | a and GCD (a, b) | b must be
true. We know that we can unambiguously express a with respect to d as
follows:
a = (a div b) · b + a mod b,
(A.7)
where a div b ∈IN. Hence,
a mod b = a −(a div b) · b,
i.e., a mod b is a linear combination3 of a and b. From Lemma A.2.15(i),
GCD (a, b) divides a −(a div b) · b, and so
GCD (a, b) | a mod b.
This, together with the obvious fact
GCD (a, b) | b,
implies (see Observation A.2.16(iv), if not clear) that
GCD (a, b) | GCD (b, a mod b) .
(ii) We prove GCD (b, a mod b) divides GCD (a, b).
Obviously,
GCD (b, a mod b) | b and GCD (b, a mod b) | (a mod b).
Since
a = (a div b) · b + a mod b,
3xa + yb for x = 1 and y = −(a div b)

238
A Fundamentals of Mathematics
a is a linear combination of b and a mod b, and so
GCD (b, a mod b) | a
by Lemma A.2.15(i). The facts
GCD (b, a mod b) | b and GCD (b, a mod b) | a
together imply that (see Observation A.2.16(iv))
GCD (b, a mod b) | GCD (a, b) .
⊓⊔
Lemma A.2.15 directly implies the correctness of the following recursive
algorithm computing GCD (a, b) for arbitrary natural numbers a and b.
Euclid’s Algorithm
Input: two natural numbers
Recursive Procedure EUCLID(a, b):
if b = 0 then
output “a”
else
EUCLID(b, a mod b)
Obviously, Euclid’s algorithm cannot recurse indeﬁnitely, because the sec-
ond argument strictly decreases in each recursive call. More precisely, the
larger of two arguments is at least halved in each recursive step. Hence, the
number of recursive calls is at most O(log2 b).
Thus, we have got an eﬃcient algorithm for computing the greatest com-
mon divisor of two natural numbers. The following example illustrates how
fast Euclid’s algorithm works for a = 127500136 and b = 12750.
EUCLID(127500136, 12750) = EUCLID(12750, 136)
= EUCLID(136, 102)
= EUCLID(102, 34)
= EUCLID(34, 0)
= 34.
An important characterization4 of the greatest common divisor of two
natural numbers is given by the following theorem.
4equivalent deﬁnition of GCD.

A.2 Algebra and Number Theory
239
Theorem A.2.19. For all positive integers a and b, let
Comb (a, b) = {a · x + b · y | x, y ∈ZZ}
be the set of all linear combinations of a and b. Then,
GCD (a, b) = min{d ∈Comb (a, b) | d ≥1},
i.e., GCD (a, b) is the smallest positive integer n in Comb (a, b).
Proof. Let h = min{d ∈Comb (a, b) | d ≥1}, and let
h = a · x + b · y
for some x, y ∈ZZ. We prove that h = GCD (a, b) by proving the inequalities
h ≤GCD (a, b) and h ≥GCD (a, b) separately.
(i) First we prove that h divides a as well as b, and so h | GCD (a, b), too.
From the deﬁnition of a mod b, we have
a mod h = a −⌊a/h⌋· h
= a −⌊a/h⌋· (a · x + b · y)
{since h = a · x + b · y}
= a · (1 −⌊a/h⌋· x) + b · (−⌊a/h⌋· y),
and so a mod h is a linear combination of a and b. Since h is the lowest
positive linear combination of a and b and a mod h < h, we obtain
a mod h = 0, i.e., h divides a.
The same argument with b provides
b mod h = 0, i.e., h divides b.
Thus,
h ≤GCD (a, b) .
(ii) We show that h ≥GCD (a, b).
Since GCD (a, b) divides both a and b, GCD (a, b) must divide every linear
combination a · u + b · v for u, v ∈ZZ. Hence, GCD (a, b) divides every
element of Comb (a, b). Since h ∈Comb (a, b),
GCD (a, b) | h, i.e., GCD (a, b) ≤h.
⊓⊔
For the study of number-theoretic problems, algebra is of enormous im-
portance. In algebra one investigates algebraic structures called algebras. An
algebra is a pair (S, F), where

240
A Fundamentals of Mathematics
(i) S is a set of elements.
(ii) F is a set of mappings that map arguments or tuples of arguments from
S to S. More precisely, F is a set of operations on S, and an operation
f ∈F is a mapping from Sm to S for a nonnegative integer m. A function
f : Sm →S is called an m-ary operation on S.
This deﬁnition of an algebra does not say anything else than that we are
not interested in structures that are not closed according to the operations
considered (i.e., we are not interested in mappings producing results outside
S for arguments from S).
In what follows, we prefer the simpliﬁed notation (S, f1, f2, . . ., fk) to the
notation (S, {f1, f2, . . ., fk}) to represent algebras. For some operations f and
g, we shall use the notation · and +, respectively, if f can be considered to be
a version of multiplication and g can be considered to be a version of addition.
In this case, we write x · y instead of f(x, y) and x + y instead of g(x, y).
In relation to number theory, we are especially interested in ﬁnite struc-
tures with a multiplication modulo n or an addition modulo n, for a positive
integer n.
Deﬁnition A.2.20. A group is an algebra (S, ∗) for which the following is
true:
(i) ∗is a binary (2-ary) operation.
(ii) ∗is associative, i.e., for all x, y, z ∈S
(x ∗y) ∗z = x ∗(y ∗z).
(iii) There exists an element e ∈S such that
e ∗x = x = x ∗e
for every element x ∈S. The element e is called the neutral element
according to ∗in S.
(iv) For each x ∈S, there exists an element i(x) ∈S such that
i(x) ∗x = e = x ∗i(x).
The element i(x) is called the neutral element of x according to ∗.
A group is said to be commutative if
x ∗y = y ∗x
for all x, y ∈S.
In what follows, if ∗is considered to be multiplication, the neutral element
is denoted by 1. If ∗is considered to be addition, the neutral element is denoted
by 0.

A.2 Algebra and Number Theory
241
Example A.2.21. We show that (ZZ, +) is a commutative group. The structure
(ZZ, +) is an algebra, since the addition of two integers is an integer. The
addition is a binary operation, which is associative and commutative. The
neutral element with respect to + in ZZ is 0, because
0 + x = x = x + 0
for all x ∈ZZ. For every x ∈ZZ, i(x) = −x is the inverse element for x,
because
x + (−x) = 0.
The pair (ZZ, ·) is an algebra, but not a group. Though the multiplica-
tion operation · is associative and commutative, and 1 is the neutral element
according to · in ZZ, each element of ZZ, except 1, does not have an inverse
element.
Exercise A.2.22. Show that for every positive integer n, the algebraic struc-
ture (ZZn, ⊕mod n) is a commutative group.
Exercise A.2.23. Prove the following claims:
(i) (ZZ7, ⊙mod 7) is not a group,
(ii) (ZZ7 −{0}, ⊙mod 7) is a commutative group, and
(iii) (ZZ12 −{0}, ⊙mod 12) is not a group.
A subset of ZZn of special interest in number theory is the set
ZZ∗
n = {d ∈ZZn | GCD (d, n) = 1}.
Exercise A.2.24. Show that the following algebras are groups:
(i) (ZZ∗
5, ⊙mod 5),
(ii) (ZZ∗
9, ⊙mod 9),
(iii) (ZZ∗
12, ⊙mod 12).
Exercise A.2.25. Prove that each commutative group has exactly one neu-
tral element and that, for every group (A, ∗) and all a, b, c ∈A, the following
holds:
(i) a = i(i(a)),
(ii) a ∗b = c ∗b implies a = c and
b ∗a = b ∗c implies a = c,
(iii) a ̸= b ⇔a ∗c ̸= b ∗c ⇔c ∗a ̸= c ∗b.
Deﬁnition A.2.26. Let (S, ∗) be a group with the neutral element e. For every
a ∈S and every j ∈ZZ, we deﬁne the j-th power of a as follows:
(i) a0 = e, a1 = a, and a−1 = i(a),
(ii) aj+1 = a ∗aj for all j ≥1, and
(iii) a−j = (i(a))j for every positive integer j.

242
A Fundamentals of Mathematics
An element g of S is called a generator of the group (S, ∗) if
S = {gi | i ∈ZZ}.
If a group has a generator, the group is called cyclic.
The group (ZZ∗
5, ⊙mod 5) is cyclic. A generator of this group is the element
2, because
21 = 2 and 2 mod 5 = 2
22 = 4 and 4 mod 5 = 4
23 = 8 and 8 mod 5 = 3
24 = 16 and 16 mod 5 = 1
and ZZ∗
5 = {1, 2, 3, 4}.
One can use the notion of “group” in order to provide an equivalent deﬁ-
nition of primes.
Theorem A.2.27. For every positive integer p, p ≥2,
p is a prime ⇔(ZZp −{0}, ⊙mod p) is a group.
Proof. We show this equivalence by proving the two corresponding implica-
tions separately.
(i) We prove, for every prime p, that the algebra (ZZp −{0}, ⊙mod p) is a
group.
Clearly, ⊙mod p is an associative and commutative operation, and 1 is
the neutral element according to ⊙mod p in ZZp −{0}. It remains to show
that there exists an inverse element a−1 for every a ∈ZZp −{0}.
Let a be an arbitrary element from ZZp −{0} = {1, 2, . . ., p−1}. We show
that one of the elements of {1, 2, . . ., p−1} must be inverse to a. Consider
the following multiples of a:
m1 = 1 · a,
m2 = 2 · a, . . .,
mp−1 = (p −1) · a.
Our aim is to show that one of these multiples modulo p must be the
neutral element 1. First, we prove that
mi mod p ̸= mj mod p
for all i ̸= j. We prove it by contradiction. Let
mr ≡ms (mod p)
for two diﬀerent r, s ∈{1, 2, . . ., p −1}, r > s. The prime p divides the
number
mr −ms = (r −s) · a.

A.2 Algebra and Number Theory
243
Following Corollary A.2.4, the prime p must divide (r−s) or a. But this is
impossible, because 0 < r −s < p and 0 < a < p. Hence, we have proved
that the numbers
m1 mod p,
m2 mod p, . . .,
mp−1 mod p
are pairwise diﬀerent, and so
{1 ⊙mod p a, 2 ⊙mod p a, . . ., (p −1) ⊙mod p a} = {1, 2, . . ., p −1}.
Hence, there exists a b ∈{1, 2, . . ., p −1} such that
b ⊙mod p a = 1, i.e., a−1 = b.
Since we have proved the existence of an inverse element for every a ∈
{1, 2, . . ., p −1}, we can conclude that (ZZp −{0}, ⊙mod p) is a group.
(ii) We have to prove that if (ZZp−{0}, ⊙mod p) is a group, then p is a prime.
Let us do this in an indirect way. Let p be composite. Then,
p = b · d
for some b, d ∈{2, 3, . . ., p −1}. Then,
b ⊙mod p d = 0.
Therefore, (ZZp −{0}, ⊙mod p) is not an algebra, because the multiplica-
tion modulo p maps two elements from ZZp −{0} to an element outside
of ZZp −{0}.
⊓⊔
The above presented proof idea (part (i)) of Theorem A.2.27 can also be
applied to prove the so-called Fermat’s Little Theorem. This theorem is the
starting point for solving several number-theoretic problems, especially for the
design of eﬃcient randomized algorithms for primality testing.
Theorem A.2.28. Fermat’s Little Theorem
For every prime p and every number a ∈ZZ∗
p = {d ∈ZZp | GCD (d, p) =
1},
ap−1 mod p = 1,
i.e., ap−2 is the inverse element of a according to ⊙mod p.
Proof. Let p be a prime, and let a be an arbitrary element from ZZ∗
p. Consider
again the following p −1 multiples of a:
m1 = 1 · a, m2 = 2 · a, . . ., mp−1 = (p −1) · a.
In the proof of Theorem A.2.27 we have already shown that the numbers

244
A Fundamentals of Mathematics
m1 mod p, m2 mod p, . . ., mp−1 mod p
are pairwise diﬀerent, and so
|{m1 mod p, m2 mod p, . . ., mp−1 mod p}| = p −1.
(A.8)
Since a < p and r < p for every r ∈{1, 2, . . ., p−1}, the prime p cannot divide
the number mr = r ·a. Hence, mr mod p ̸= 0 for all r ∈{1, 2, . . ., p−1}. This
observation and (A.8) together imply
{m1 mod p, m2 mod p, . . ., mp−1 mod p} = {1, 2, . . ., p −1}.
(A.9)
Now, let us consider the number
p−1

i=1
mi = (1 · a) · (2 · a) · . . . · ((p −1) · a) = 1 · 2 · . . . · (p −1) · ap−1. (A.10)
Then (A.9) implies the congruence
1 · 2 · . . . · (p −1) · ap−1 ≡1 · 2 · . . . · (p −1) (mod p),
which is equivalent to
1 · 2 · . . . · (p −1) · ap−1 −1 · 2 · . . . · (p −1) ≡0 (mod p),
and so is equivalent to
(1 · 2 · . . . · (p −1)) ·

ap−1 −1

≡0 (mod p).
(A.11)
Since p does not divide5 the number 1 · 2 · . . . · (p −1), (A.11) implies6 that p
must divide ap−1 −1, and so
ap−1 −1 ≡0 (mod p),
which is equivalent to
ap−1 ≡1 (mod p).
⊓⊔
The Fermat’s Little Theorem says that it may be of interest to compute
the number
ap−1 mod p
for a given positive integer p and a number a ∈{1, 2, . . ., p −1}, because
ap−1 mod n ̸= 1 proves the fact “p /∈PRIME”.
5All factors of the number 1 · 2 · . . . · (p −1) are smaller than p.
6because of the Fundamental Theorem of Arithmetics (and more precisely, be-
cause of Corollary A.2.4)

A.2 Algebra and Number Theory
245
For an eﬃcient computation of ap−1 mod p, one is not allowed to perform
(p −2) multiplications by a because in this way the number of executed
operations would be exponential in ⌈log2 p⌉. If one has to compute ab mod p
for a b = 2k, then one can do this eﬃciently in the following way:
a2 mod p = a · a mod p,
a4 mod p = (a2 mod p) · (a2 mod p) mod p,
a8 mod p = (a4 mod p) · (a4 mod p) mod p,
...
a2k mod p = (a2k−1 mod p)2 mod p.
In general, let
b =
k

i=1
bi · 2i−1
(i.e., b = Number(bkbk−1 . . . b1)) for a k ∈IN −{0} and bi ∈{0, 1} for i =
1, . . . , k. Then,
ab = ab1·20 · ab2·21 · ab3·22 . . . · abk·2k−1.
To calculate ab mod p, one ﬁrst computes the numbers ai = a2i−1
mod p
for all i = 1, 2, . . ., k by repeated squaring. Then, one multiplies modulo p all
numbers ai, for which bi = 1, i.e., one computes
k

i=1
bi=1
ai.
Hence, for computing ap−1 mod p, it is suﬃcient to perform 2⌈log2 p⌉mul-
tiplications over ZZp, i.e., over the numbers of the binary length ⌈log2 p⌉. If one
applies the school algorithm for executing multiplications, then O

(log2 p)3
binary operations suﬃce to compute ap−1 mod p.
The structure (ZZ∗
n, ⊙mod n) is crucial for our applications. The following
two assertions provide important information about ZZ∗
n.
Theorem A.2.29. For all positive integers n, (Z∗
n, ⊙mod n) is a commuta-
tive group.
Proof. First, we have to show that Z∗
n is closed according to the operation
⊙mod n. Let a and b be two arbitrary elements of Z∗
n, i.e., GCD (a, n) =
GCD (b, n) = 1. Since
Comb (a · b, n) ⊆Comb (a, n) ∩Comb (b, n) ,
and so 1 ∈Comb (a · b, n), Theorem A.2.19 implies
GCD (a · b, n) = 1.

246
A Fundamentals of Mathematics
Therefore, a · b mod n is in Z∗
n, and so (Z∗
n, ⊙mod n) is an algebra.
Clearly, 1 is the neutral element according to ⊙mod n in Z∗
n, and the
operation ⊙mod n is an associative and commutative operation.
It remains to show that, for every a ∈Z∗
n, there exists an inverse element
a−1 with respect to ⊙mod n. To do this, it is suﬃcient to show that
|{a ⊙mod n 1, a ⊙mod n 2, . . ., a ⊙mod n (n −1)}| = n −1,
which directly implies that
1 ∈{a ⊙mod n 1, . . ., a ⊙mod n (n −1)}.
We prove this by contradiction. Assume that there exist two numbers i, j ∈
{1, 2, . . ., n −1}, i > j, such that
a ⊙mod n i = a ⊙mod n j, i.e., a · i ≡a · j (mod n).
This means that
a · i = n · k1 + z and a · j = n · k2 + z
for suitable numbers k1, k2 and z < n. Then
a · i −a · j = n · k1 −n · k2 = n · (k1 −k2),
and so
a · (i −j) = n · (k1 −k2), i.e., n divides a · (i −j).
Since GCD (a, n) = 1, the number n divides i −j. But this is not possible
because i −j < n.
Hence, every element a ∈ZZ∗
n has a multiplicative inverse a−1 according
to ⊙mod n, and so (ZZ∗
n, ⊙mod n) is a group. Since ⊙mod n is commutative,
(ZZ∗
n, ⊙mod n) is a commutative group.
⊓⊔
The next theorem shows that ZZ∗
n contains exactly those elements of ZZn
that possess inverse elements according to ⊙mod n.
Theorem A.2.30. For all positive integers n,
ZZ∗
n = {a ∈ZZn | there exists an a−1 ∈ZZn, such that a ⊙mod n a−1 = 1}.
Proof. The relation Z∗
n ⊆{a ∈ZZn | ∃a−1 ∈ZZn} is a direct consequence of
the fact that (ZZ∗
n, ⊙mod n) is a group.
It remains to show that
{a ∈ZZn | ∃a−1 ∈ZZn} ⊆Z∗
n = {a ∈ZZn | GCD (a, n) = 1}.
This means that we have to show that the existence of a−1 for an a ∈ZZn
implies that GCD (a, n) = 1.

A.2 Algebra and Number Theory
247
Let a be an arbitrary element from ZZn such that a−1 ∈ZZn. Since a·a−1 ≡
1 (mod n), we have
a · a−1 = k · n + 1
(A.12)
for a natural number k. We consider the following linear combination of a and
n from Comb (a, n):
a · x + n · y = a · a−1 + n · (−k) =
(A.12)
k · n + 1 −k · n = 1
for x = a−1 and y = −k. Consequently, 1 is in Comb (a, n), and so Theo-
rem A.2.19 implies
GCD (a, n) = min{d ∈Comb (a, n) | d ≥1} = 1.
⊓⊔
The following important discovery about ZZ∗
n is given without proof, which
is too long and technical and not needed for understanding of the design and
analysis of randomized algorithms.
Theorem A.2.31. Let n be a positive integer. The group (ZZ∗
n, ⊙mod n) is
cyclic if and only if
n ∈{2, 4, pk, 2 · pk | p ∈PRIME −{2}, k ∈IN −{0}}.
⊓⊔
An important instrument of number theory is the Chinese Remainder The-
orem. This theorem is very useful for the study of ZZn for n /∈PRIME, because
it provides a well structured representation of the elements of ZZn. This rep-
resentation is in many cases more transparent and more convenient than the
standard representation of ZZn, and so it enables the construction of ZZn in
a transparent way. Let m = m1 · m2 · . . . mk, where GCD (mi, mj) = 1 for all
i ̸= j. Then, the ﬁrst simple version of the Chinese Remainder Theorem says
that the function
F(m) = (m mod m1, m mod m2, . . ., m mod mk)
from ZZm to ZZm1 × ZZm2 × . . . × ZZmk is a bijection, and so ZZm1 × ZZm2 ×
. . . × ZZmk is another representation of ZZn.
Theorem A.2.32. Chinese Remainder Theorem, ﬁrst version
Let
m = m1 · m2 · . . . · mk,
where k ∈IN −{0}, mi ∈IN −{0, 1} for i = 1, 2, . . ., k, and
GCD (mi, mj) = 1

248
A Fundamentals of Mathematics
for all i, j ∈{1, 2, . . ., k}, i ̸= j. Then, for each sequence of k numbers
r1 ∈ZZm1, r2 ∈ZZm2, . . ., rk ∈ZZmk,
(i.e., for every element (r1, r2, . . ., rk) ∈ZZm1 × ZZm2 × . . . × ZZmk), there is
a unique r ∈ZZm such that
r ≡ri (mod mi)
for i = 1, 2, . . ., k.
Proof. First, we show that there exists at least one r with this property.
Since GCD (mi, mj) = 1 for all distinct i and j from {1, 2, . . ., k}, we have
GCD
 m
ml
, ml

= 1 for all l ∈{1, 2, . . ., k}.
Hence, following Theorem A.2.30, the element m/mi has an inverse element
ni with respect to ⊙mod mi in ZZmi. We consider the number
ei = ni · m
mi
= m1 · m2 · . . . · mi−1 · ni · mi+1 · . . . · mk.
Since m/mi ≡0 (mod mj) for all j ∈{1, . . ., k} −{i}, we have
ei ≡0 (mod mj)
for all is diﬀerent from j.
If ni is the inverse element of m/mi in ZZmi, then
ei mod mi = ni · m
mi
mod mi = 1.
If, for each (r1, r2, . . ., rk) ∈ZZm1 ×ZZm2 ×. . .×ZZmk, the number r is chosen
as
r ≡
 k

i=1
ri · ei

(mod m),
then, clearly,
r ≡ri (mod mi)
(A.13)
for all i ∈{1, 2, . . ., k}.
It remains to show that there exists at most one r ∈ZZm that fulﬁlls all k
congruences (A.13).
Assume that there are two numbers x and y from ZZn such that
y ≡x ≡ri (mod mi)
for all i ∈{1, 2, . . ., k}. Then,

A.2 Algebra and Number Theory
249
x −y ≡0 (mod mi), i.e., mi | (x −y)
for all i ∈{1, 2, . . ., k}. Since m = m1 · m2 · . . . · mk and GCD (mi, mj) = 1
for all i ̸= j, we obtain that
m divides x −y.
Since x −y < m, we have x −y = 0, and so x = y.
⊓⊔
The second version of the Chinese Remainder Theorem does not provide
only a bijection between Zm and ZZm1 ×. . .×ZZmk, but it additionally makes
it possible to simulate the operations in Zm by some operations in ZZm1 ×
. . . × ZZmk. If such a simulation is possible, we speak about an isomorphism
between the algebraic structures considered.
Deﬁnition A.2.33. Let A = (A, f1, . . ., fk) and B = (B, g1, . . ., gk) be two
algebras, where fi and gi are di-ary operations, di ∈IN for i = 1, . . ., k. We
say that A and B are isomorphic if there exists a bijection H : A →B such
that, for all a1, a2, . . ., adi ∈A,
H(fi(a1, a2, . . ., adi)) = gi(H(a1), H(a2), . . ., H(adi))
for all i ∈{1, 2, . . ., k}.
Since, for all applications in this textbook, it is suﬃcient to consider the
isomorphism between ZZn and ZZp × ZZq for some n = p · q, GCD (p, q) = 1,
we present a second, simpliﬁed version of the Chinese Remainder Theorem.
Theorem A.2.34. Chinese Remainder Theorem, second version
Let n = p · q and GCD (p, q) = 1. Let ⊕p,q and ⊙p,q be two operations on
ZZp × ZZq, deﬁned by
(a1, a2) ⊕p,q (b1, b2) = ((a1 + b1) mod p, (a2 + b2) mod q)
and
(a1, a2) ⊙p,q (b1, b2) = ((a1 · b1) mod p, (a2 · b2) mod q)
for all (a1, a2), (b1, b2) ∈ZZp × ZZq.
Then, the algebras (ZZn, ⊕mod m, ⊙mod m) and (ZZp×ZZq, ⊕p,q, ⊙p,q) are
isomorphic.
Proof. In the ﬁrst version of the Chinese Remainder Theorem, we have already
proved that the mapping h : ZZn →ZZp × ZZq deﬁned by
h(a) = (a mod p, a mod q)
is a bijection.
It remains to show that

250
A Fundamentals of Mathematics
h(a ⊕mod n b) = h(a) ⊕p,q h(b) and h(a ⊙mod n b) = h(a) ⊙p,q h(b)
for all a, b ∈ZZn. All a, b ∈ZZn can be expressed as follows:
a = a′
1 · p + a1 = a2′ · q + a2
b = b1′ · p + b1 = b2′ · q + b2
for suitable a1′, a1, a2′, a2, b1′, b1, b2′, b2 with a1 < p, a2 < q, b1 < p and b2 < q.
Therefore h(a) = (a1, a2) and h(b) = (b1, b2). Now, for all a, b ∈ZZn, we
have
h(a ⊕mod n b) = h((a + b) mod n)
= ((a + b) mod p, (a + b) mod q)
= ((a1 + b1) mod p, (a2 + b2) mod q)
= (a1, a2) ⊕p,q (b1, b2)
= h(a) ⊕p,q h(b)
and
h(a ⊙mod n b) = h((a · b) mod n)
= ((a · b) mod p, (a · b) mod q)
= ((a1
′ · b1
′ · p2 + (a1 · b1
′ + a1
′ · b1) · p + a1 · b1) mod p,
(a2′ · b2′ · q2 + (a2′ · b2 + a2 · b2′) · q + a2 · b2) mod q)
= ((a1 · b1) mod p, (a2 · b2) mod p)
= (a1, a2) ⊙p,q (b1, b2)
= h(a) ⊙p,q h(b).
⊓⊔
Exercise A.2.35. Formulate and prove the general second version of the Chi-
nese Remainder Theorem for m = m1 · m2 · . . . · mk with GCD (mi, mj) = 1
for all i, j ∈{1, . . ., k} with i ̸= j.
The last important and frequently used instrument we would like to in-
troduce here is Lagrange’s Theorem, which says that the cardinality of any
subgroup of a ﬁnite group divides the cardinality of the group. To prove this
claim, we ﬁrst need some new notions and a few technical lemmas.
Deﬁnition A.2.36. Let (A, ∗) be a group with a neutral element 1. For each
a ∈A, the order of a is deﬁned by
order (a) = min{r ∈IN −{0} | ar = 1}
if there exists at least one r with ar = 1.
If ai ̸= 1 for all i ∈IN −{0}, then we set order (a) = ∞.

A.2 Algebra and Number Theory
251
Lemma A.2.37. Let (A, ∗) be a ﬁnite group. Then, every element a ∈A is
of a ﬁnite order (more precisely, order (a) ∈{1, 2, . . ., |A|}).
Proof. Let a be an arbitrary element of A. Consider the |A| + 1 elements
a0, a1, . . ., a|A|
from A. Clearly, there exist i, j ∈{1, . . ., |A| + 1}, 0 ≤i < j ≤|A|, such that
0 ≤i < j ≤|A| and
ai = aj.
Consequently,
1 = ai ·

a−1i = aj ·

a−1i = aj−i,
and so
order (a) ≤j −i ∈{1, 2, . . ., |A|}.
⊓⊔
Deﬁnition A.2.38. Let (A, ∗) be a group. An algebra (H, ∗) is a subgroup
of (A, ∗) if
(i) H ⊆A, and
(ii) (H, ∗) is a group.
For instance, (ZZ, +) is a subgroup of (QI , +) and ({1}, ⊙mod 5) is a sub-
group of (ZZ∗
5, ⊙mod 5).
Lemma A.2.39. Let (H, ∗) be a subgroup of a group (A, ∗). Then, the neutral
elements of both groups are the same.
Proof. Let eH be the neutral element of (H, ∗) and let eA be the neutral
element of (A, ∗). Since eH is the neutral element of (H, ∗),
eH ∗eH = eH.
(A.14)
Since eA is the neutral element of (A, ∗) and eH ∈A, we have
eA ∗eH = eH.
(A.15)
Since the right sides of the equations (A.14) and (A.15) are the same, we
obtain
eH ∗eH = eA ∗eH.
(A.16)
Let e−1
H
be the inverse element of eH according to ∗in A. Multiplying
(A.16) with e−1
H from the right side, we ﬁnally obtain
eH = eH ∗eH ∗e−1
H
=
(A.16)
eA ∗eH ∗e−1
H = eA.
⊓⊔

252
A Fundamentals of Mathematics
The next theorem says that, for proving (H, ◦) is a subgroup of a ﬁnite
group (A, ◦) for an H ⊆A, it suﬃces to show that H is closed under ◦.
Theorem A.2.40. Let (A, ◦) be a ﬁnite group. Every algebra (H, ◦) with H ⊆
A is a subgroup of (A, ◦).
Proof. Let H ⊆A and let (H, ◦) be an algebra. To prove that (H, ◦) is a
subgroup of (A, ◦), it is suﬃcient to show that (H, ◦) is a group. We do this
by showing that eA is the neutral element of (H, ◦), and that each b ∈H
possesses an inverse element b−1 in H.
Let b be an arbitrary element of H. Since b ∈A and A is ﬁnite, order (b) ∈
IN −{0} and
border(b) = eA.
Since H is closed under ◦, the element bi is in H for every positive integer i,
and so
eA = border(b) ∈H,
too. Since
eA ◦d = d
for every d ∈A and H ⊆A, the element eA is also the neutral element of
(H, ◦).
Since border(b)−1 ∈H for every b ∈H and
eA = border(b) = b ◦border(b)−1,
border(b)−1 is the inverse element of b in (H, ◦).
⊓⊔
Note that the assumption of Theorem A.2.40 that A is ﬁnite is essential
because the assertion does not need to be true for inﬁnite groups. For instance,
(IN, +) is an algebra and IN ⊆ZZ, but (IN, +) is not a group.
Exercise A.2.41. Let (H, ◦) and (G, ◦) be subgroups of a group (A, ◦). Prove,
that (H ∩G, ◦) is a subgroup of (A, ◦), too.
Lemma A.2.42. Let (A, ◦) be a group with a neutral element e. Let, for every
a ∈A of a ﬁnite order,
H(a) = {e, a, a2, . . ., aorder(a)−1}.
The structure (H(a), ◦) is the smallest subgroup of (A, ◦) that contains the
element a.
Proof. First, we prove that H(a) is closed under ◦. Let ai and aj be two
arbitrary elements of H(a).
If i + j < order (a) then, clearly,
ai ◦aj = ai+j ∈H(a).

A.2 Algebra and Number Theory
253
If i + j > order (a), then
ai ◦aj = ai+j = aorder(a) ◦ai+j−order(a)
= e ◦ai+j−order(a) = ai+j−order(a) ∈H(a).
Following the deﬁnition of H(a), e ∈H(a). For every element ai ∈H(a),
e = aorder(a) = ai ◦aorder(a)−i,
and so aorder(a)−i is the inverse element of ai. Hence, (H(a), ◦) is a group.
Since every algebra (G, ◦) with a ∈G containing a must7 contain the
whole set H(a), the group (H(a), ◦) is the smallest subgroup of (A, ◦) that
contains a.
⊓⊔
Deﬁnition A.2.43. Let (H, ◦) be a subgroup of a group (A, ◦). For every
b ∈A, we deﬁne the sets
H ◦b = {h ◦b | h ∈H} and b ◦H = {b ◦h | h ∈H}.
The set H ◦b is called the right coset of H in (A, ◦), and b ◦H is called the
left coset of H in (A, ◦). If H ◦b = b ◦H, then H ◦b is called a coset of H
in (A, ◦).
For instance, B7 = {7 · a | a ∈ZZ} is a subgroup of (ZZ, +). Then, for
i = 0, 1, . . ., 6,
B7 + i = i + B7 = {7 · a + i | a ∈ZZ} = {b ∈ZZ | b mod 7 = i}
are cosets of B7 in (ZZ, +). Observe that the class {B7 + i | i ∈{0, 1, . . ., 6}}
is a partition of ZZ in seven disjoint classes.
Observation A.2.44. If (H, ◦) is a subgroup of a commutative group (A, ◦),
then all right (left) cosets of H in (A, ◦) are cosets.
Another important fact about the cosets of a ﬁnite H is that their cardi-
nality is equal to the cardinality of H.
Theorem A.2.45. Let (H, ◦) be a subgroup of a group (A, ◦). Then,
(i) H ◦h = H for every h ∈H.
(ii) For all b, c ∈A,
either H ◦b = H ◦c or H ◦b ∩H ◦c = ∅.
(iii) If H is ﬁnite, then
|H ◦b| = |H|
for all b ∈A.
7Since G is closed under ◦.

254
A Fundamentals of Mathematics
Proof. We prove these three assertions separately in the given order. Let e be
the neutral element of (A, ◦) and (H, ◦).
(i) Let h ∈H. Since H is closed under ◦, a ◦h ∈H, and so
H ◦h ⊆H.
Since (H, ◦) is a group, h−1 is in H. Let b be an arbitrary element of H.
Then,
b = b ◦e = b ◦(h−1 ◦h)
5
67
8
e
= (b ◦h−1)
5
67
8
∈H
◦h ∈H ◦h,
and so
H ⊆H ◦h.
Hence, H ◦h = H.
(ii) Assume H ◦b ∩H ◦c ̸= ∅for some b, c ∈A. Then there exist a1, a2 ∈H,
such that
a1 ◦b = a2 ◦c.
This implies
c = a−1
2
◦a1 ◦b,
where a−1
2
∈H. Therefore,
H ◦c = H ◦(a−1
2
◦a1 ◦b) = H ◦(a−1
2
◦a1) ◦b.
(A.17)
Since a−1
2
and a1 belong to H, the element a−1
2
◦a1 also belongs to H.
Due to the claim (i), we obtain
H ◦(a−1
2
◦a1) = H.
(A.18)
Inserting (A.18) into (A.17), we ﬁnally obtain
H ◦c = H ◦(a−1
2
◦a1) ◦b = H ◦b.
(iii) Let H be ﬁnite, and let b ∈A. Since H ◦b = {h ◦b | h ∈H}, we
immediately have
|H ◦b| ≤|H|.
Let H = {h1, h2, . . ., hk} for a k ∈IN. We have to show that
|{h1 ◦b, h2 ◦b, . . ., hk ◦b}| ≥k.
We prove this by contradiction. Let
hi ◦b = hj ◦b
(A.19)
for some i, j ∈{1, 2, . . ., k}, i ̸= j. Since (A, ◦) is a group, b−1 ∈A.
Applying (A.19), one obtains

A.2 Algebra and Number Theory
255
hi = hi◦e = hi◦(b◦b−1) = (hi◦b)◦b−1
=
(A.19)
(hj◦b)◦b−1 = hj·(b◦b−1) = hj,
which contradicts to the assumption hi ̸= hj. Thus,
|H ◦b| = |H|.
⊓⊔
A direct consequence of Theorem A.2.45 is that one can partition the set
A of every group (A, ◦) having a proper subgroup (H, ◦) into pairwise disjoint
subsets of A, which are the left (right) cosets of H in (A, ◦).
Theorem A.2.46. Let (H, ◦) be a subgroup of a group (A, ◦). Then, the class
{H ◦b | b ∈A} is a partition of A.
Proof. The claim (ii) of Theorem A.2.45 shows that H ◦b ∩H ◦c = ∅or
H ◦b = H ◦c. So, it remains to show that
A ⊆
#
b∈A
H ◦b.
But this is obvious because the identity e of (A, ◦) is also the identity of (H, ◦),
and so
b = e ◦b ∈H ◦b
for every b ∈A.
⊓⊔
Deﬁnition A.2.47. Let (H, ◦) be a subgroup of a group (A, ◦). We deﬁne the
index of H in (A, ◦) by
IndexH(A) = |{H ◦b | b ∈A}|,
i.e., as the number of diﬀerent right cosets of H in (A, ◦).
The aim of the last part of this section is to present the following theorem,
which provides a powerful instrument for proving that there are not too many
“bad” elements8 (or elements with a special property) in A.
Theorem A.2.48. Lagrange’s Theorem
For every subgroup (H, ◦) of a ﬁnite group (A, ◦),
|A| = IndexH(A) · |H|,
i.e., |H| divides |A|.
8Bad elements may, for instance, be non-witnesses among the candidates in an
application of the method of abundance of witnesses.

256
A Fundamentals of Mathematics
Proof. Theorem A.2.46 implies that A can be partitioned into IndexH(A)
right cosets, and Theorem A.2.45 says that all right cosets are of the same
cardinality.
⊓⊔
Corollary A.2.49. Let (H, ◦) be a proper algebra of a ﬁnite group (A, ◦).
Then,
|H| ≤|A|/2.
Proof. Theorem A.2.40 guarantees that every algebra (H, ◦) of a ﬁnite group
(A, ◦) is a subgroup of (A, ◦). Thus, for (H, ◦), Lagrange’s Theorem holds.
Since H ⊂A,9 IndexH(A) ≥2 and so
|H| ≤|A|/2.
⊓⊔
Corollary A.2.49 is the frequently used argument in the design of random-
ized algorithms by the method of abundance of witnesses. In order to show
that the number on non-witnesses in the set of candidates is limited,10 it is
suﬃcient to show that
(i) all non-witnesses are elements of an algebra (H, ◦),
(ii) the algebra (H, ◦) is a subgroup of a group (A, ◦), where A is the subset
of the set of witness candidates, and
(iii) there exists an element a ∈A −H, i.e., H ⊂A.
A.3 Combinatorics
The aim of this section is to introduce a few fundamental concepts of combina-
torics, focusing on those most frequently applied in the analysis of randomized
algorithms. Here, we often do so without proofs and list the most important
combinatorial equations. The starting point is to have a set of objects distin-
guishable from each other.
Deﬁnition A.3.50. Let n be a positive integer. Let S = {a1, a2, . . ., an} be
a set of n objects (elements). A permutation of n objects a1, a2, . . ., an is an
ordered arrangement of the objects of S.
A permutation can be viewed as an injective mapping π from S to S. This
way, one can represent a permutation as the following vector:
(π(a1), π(a2), . . ., π(an)).
For instance, if S = {a1, a2, a3}, then there are the following six diﬀerent ways
to arrange the three objects a1, a2, a3:
9i.e., |H| < |A|
10at most half the candidates.

A.3 Combinatorics
257
(a1, a2, a3), (a1, a3, a2), (a2, a1, a3), (a2, a3, a1), (a3, a1, a2), (a3, a2, a1).
To denote permutations, the simpliﬁed notation
(i1, i2, . . ., in)
is often used instead of (ai1, ai2, . . ., ain).
Lemma A.3.51. For every positive integer n, the number n! of diﬀerent per-
mutations of n objects is
n! = n · (n −1) · (n −2) · . . . · 2 · 1 =
n

i=1
i.
Proof. One can generate all permutations in the following way. The ﬁrst object
in a permutation may be chosen in n diﬀerent ways (i.e., from the n diﬀerent
objects). Once the ﬁrst object has been chosen, the second object may be
chosen in n −1 diﬀerent ways (i.e., from the n −1 remaining objects), and so
on.
⊓⊔
By arrangement, we set 0! = 1.
Deﬁnition A.3.52. Let k and n be non-negative integers, k ≤n. A com-
bination of k objects from n objects is a selection of k objects without
regard to the order (i.e., every subset of A of k elements is a combination).
For example, a combination of four objects of the set {a1, a2, a3, a4, a5} is
any of the following sets:
{a1, a2, a3, a4}, {a1, a2, a3, a5}, {a1, a2, a4, a5}, {a1, a3, a4, a5}, {a2, a3, a4, a5}.
Lemma A.3.53. Let n and k be non-negative integers, k ≤n. The number
n
k

of combinations of k objects from n objects is
n
k

= n · (n −1) · (n −2) · . . . · (n −k + 1)
k!
=
n!
k! · (n −k)!.
Proof. As in the proof of Lemma A.3.51, we have n possibilities for the choice
of the ﬁrst element, n −1 ways of choosing the second element, and so on.
Hence, there are
n · (n −1) · (n −2) · . . . · (n −k + 1)
ways of choosing k objects from n objects when order is taken into account.
But any order of the same k elements provides the same set of k elements.
Hence,
n
k

= n · (n −1) · (n −2) · . . . · (n −k + 1)
k!
.
⊓⊔

258
A Fundamentals of Mathematics
We observe that
n
0

=
n
n

= 1.
A direct consequence of
n
k

=
n!
k! · (n −k)!
is that
n
k

=

n
n −k

.
Exercise A.3.54. Prove the following equation. For all non-negative integers
k and n, k ≤n,
n
k

=
n −1
k −1

+
n −1
k

.
The values
n
k

are also well known as the binomial coeﬃcients from
the following theorem.
Theorem A.3.55. Newton’s Theorem11
For every positive integer n and every real number x,
(1 + x)n =
n
0

+
n
1

· x +
n
2

· x2 + . . . +

n
n −1

· xn−1 +
n
n

· xn
=
n

i=0
n
i

· xi.
Exercise A.3.56. Prove Newton’s Theorem.
Lemma A.3.57. For every positive integer n,
n

k=0
n
k

= 2n.
Proof. To prove Lemma A.3.55, it is suﬃcient to set x = 1 in Newton’s
Theorem.
Another combinatorial argument is that, for each k ∈{0, 1, . . ., n},
n
k

is
the number of all k-element subsets of an n-element set. Thus,
n

k=0
n
k

counts the number of all subsets of a set of n elements. On the other hand,
every set of n elements has exactly 2n diﬀerent subsets. Hence, both sides of
the equation correspond to the number of subsets of an n-element set.
⊓⊔
11a special case of the well known Binomial Theorem.

A.3 Combinatorics
259
Lemma A.3.58. For any positive integer n
n
2

=
n

l=3
l
l −2.
Proof. Since
n
2

=
 n
n−2

, one directly obtains
n
2

=
n · (n −1) · . . . · 4 · 3
(n −2) · (n −1) · . . . · 2 · 1 =
n−2

i=1
i + 2
i
=
n

l=3
l
l −2.
⊓⊔
We use e to denote
lim
n→∞

1 + 1
n
n
.
Note that e ≈2.7182 . . . is the base of the natural logarithm and that one
can approximate e with arbitrary precision by applying the formula
ex = 1 + x + x2
2! + x3
3! + . . . =
∞

i=0
xi
i! .
The following lemmas present the most frequently used inequalities here
involving e.
Lemma A.3.59. For all t, n ∈IR+,
(i)

1 + t
n
n ≤et,
(ii)

1 + 1
n
t·n ≤et.
Lemma A.3.60. For every n ∈IR+, n ≥1,

1 −1
n
n
< 1
e.
Exercise A.3.61. Prove the assertions of Lemma A.3.59 and Lemma A.3.60.
The following result is often applied when working with the natural loga-
rithm.
Lemma A.3.62. For every x ∈(0, 1),
−x
1 −x ≤ln(1 −x) ≤−x.
Proof. The natural logarithm is a concave function. Therefore, the gradient
(diﬀerence quotient) of the transversal (secant line) going through the points
1 −x and 1 is upper bounded by the tangent gradient at the point 1 −x and
lower bounded by the tangent gradient at the point 1. Hence,
1 ≤ln(1) −ln(1 −x)
1 −(1 −x)
= −ln(1 −x)
x
≤
1
1 −x.
(A.20)
Multiplying (A.20) by −x, one obtains the assertion of the lemma.
⊓⊔

260
A Fundamentals of Mathematics
A useful instrument for working with permutations and combinations is
the following Stirling formula:
n! =
√
2πn ·
n
e
n
·

1 +
1
12 · n + O
 1
n2

.
One can apply the Stirling formula in order to prove the following inequalities.
Lemma A.3.63. For all n, k ∈IN, n ≥k ≥0,
(i)
 n
k
k ≤
n
k

≤
 n·e
k
k,
(ii)
n
k

∼nk
k! for suﬃciently large n.
Exercise A.3.64. Prove Lemma A.3.63.
Exercise A.3.65. Prove that
n
k

≤nk
k!
for all non-negative integers n and k, k ≤n.
Exercise A.3.66. Let n be an odd positive integer. Apply the Stirling for-
mula in order to approximate
 n
n/2

.
For every positive integer n, the n-th Harmonic number Har (n) is
deﬁned by the following series
Har (n) =
n

i=1
1
n = 1 + 1
2 + 1
3 + . . . + 1
n.
First, we observe that Har (n) tends to inﬁnity with increasing n. The
simplest way to see this is to partition the terms of Har (n) into inﬁnitely
many groups of cardinality 2k for k = 1, 2, . . ..
1
1
5678
Group 1
+
1
2 + 1
2
5 67 8
Group 2
+
1
4 + 1
5 + 1
6 + 1
7
5
67
8
Group 3
+
1
8 + 1
9 + 1
10 + 1
11 + 1
12 + 1
13 + 1
14 + 1
15
5
67
8
Group 4
+
. . .
Both terms in group 2 are between 1/4 and 1/2, and so the sum of that group
is between 2 · (1/4) = 1/2 and 2 · (1/2) = 1. All four terms in group 3 are
between 4 ·(1/8) = 1/2 and 4·(1/4) = 1. In general, for every positive integer
k, all 2k+1 terms of group k are between 2−k and 2−k+1, and hence the sum
of the terms of group k is between

A.3 Combinatorics
261
1
2 = 2k−1 · 2−k and 1 = 2k−1 · 2−k+1.
This grouping procedure shows us that if n is in group k, then
Har (n) ≥k
2 and Har (n) ≤k.
Consequently,
⌊log2 n⌋
2
+ 1
2 < Har (n) ≤⌊log2 n⌋+ 1
for all positive integers n.
The following exercise provides a more precise approximation of Har (n).
Exercise A.3.67.∗
Prove that
Har (n) = ln n + O(1)
for every positive integer n.
Analyzing the complexity of algorithms (especially of those designed by
the “divide and conquer” method) one often reduces the analysis to solving a
speciﬁc recurrence. The typical recurrences are of the form
T (n) = a · T
n
c

+ f(n),
where a and c are positive integers and f is a function from IN to IR+. In
what follows we provide a general solution of this recurrence if f(n) ∈Θ(n).
Theorem A.3.68. Master Theorem
Let a, b, and c be positive integers. Let
T (1) = 0,
T (n) = a · T
n
c

+ b · n.
Then,
T (n) =
⎧
⎨
⎩
O(n)
if a < c,
O(n · log n) if a = c,
O

nlogc n
if c < a.
Proof. For simplicity, we assume n = ck for some positive integer k. A multiple
application of the recurrence provides the following expression for T (n):
T (n) = a · T
n
c

+ b · n
= a ·
0
a · T
 n
c2

+ b · n
c
1
+ b · n
= a2 · T
 n
c2

+ b · n ·
a
c + 1


262
A Fundamentals of Mathematics
= ak · T (1) + b · n ·
k−1

i=0
a
c
i
= b · n ·
⎛
⎝
(logc n)−1

i=0
a
c
i
⎞
⎠.
Now we distinguish the three cases according to the relation between a and c.
(i) Let a < c. Then,
logc n−1

i=0
a
c
i
≤
∞

i=0
a
c
i
=
1
1 −a
c
∈O(1) .
Hence, T (n) ∈O(n).
(ii) Let a = c. Obviously,
logc n−1

i=0
a
c
i
=
logc n−1

i=0
1 = logc n ∈O(log n) .
So, we obtain T (n) ∈O(n · log n).
(iii) Let a > c. Then,
T (n) = b · n ·
logc n−1

i=0
a
c
i
= b · n ·

1 −( a
c )logc n
1 −a
c

=
b
a
c −1 · n ·
a
c
logc n
−1

=
b
a
c −1 · n ·
alogc n
n
−1

∈O

alogc n
= O

nlogc a
.
⊓⊔
We close this section with a combinatorial lemma, that one needs for the
analysis of the algorithm SCH¨ONING in Section 5.3. For all natural numbers,
let Word (i, j) denote the set of all strings (words) over the alphabet {0, 1}
of length j + 2i > 0, j > 0, that have the following properties:
(i) The number of symbols 1 is exactly j + i (i.e., the number of 0s is exactly
i), and

A.3 Combinatorics
263
(ii) every suﬃx of the string contains more 1s than 0s.
Lemma A.3.69. Let i and j be non-negative integers, 0 < j. Then,
|Word (i, j) | =
j + 2i
i

·
j
j + 2i.
(A.21)
Proof. We prove this assertion by induction with respect to n = j + 2i.
(i) We prove the claim for n ≤3.
First, consider the case i = 0. Then the set Word (0, j) contains only the
word 1j for every j ∈IN −{0}, and, correspondingly,
j
0

· j
j = 1.
Consequently, (A.21) holds for n ∈{1, 2}, because property (ii) forces
i = 0 in these cases.
If n = 3, then either i = j = 1, or (i = 0 and j = 3). So, it remains to
solve the case i = j = 1. We immediately see that Word (1, 1) = {011}
and, correspondingly,
3
1

· 1
3 = 1.
(ii) Let n > 3.
Assuming that (A.21) is true for all sets Word (l, r) with r + 2l < n, we
have to prove that (A.21) holds for all sets Word (i, j) with j + 2i = n. To
be able to apply the induction hypothesis, we consider two possibilities
with respect to the ﬁrst symbol of the words in Word (i, j).
From the induction hypothesis, the number of words in Word (i, j) begin-
ning with the symbol 1 is exactly12
|Word (i, j −1) | =
j −1 + 2i
i

·
j −1
j −1 + 2i.
(A.22)
The number of words in Word (i, j) that start with 0 is, by the induction
hypothesis, exactly
|Word (i −1, j + 1) | =
j + 1 + 2(i −1)
i −1

·
j + 1
j + 1 + 2(i −1).
(A.23)
Now, we distinguish two cases, namely j = 1 and j > 1.
(ii).1 Let j = 1.
Because of the property (ii), no word in Word (i, j) can begin with 1.
Hence,
12Observe that this case is possible only if j > 1.

264
A Fundamentals of Mathematics
|Word (i, 1) |
=
|Word (i −1, 2) |
=
(A.23)
2 + 2(i −1)
i −1

·
2
2(i −1) + 2
=
 2i
i −1

· 1
i =
(2i)!
(i −1)! · (i + 1)! · 1
i
=
(2i)! · (2i + 1)
i! · (i + 1)! · (2i + 1) =
2i + 1
i

·
1
2i + 1
=
j + 2i
i

·
1
j + 2i
{because j = 1}
.
Thus, (A.21) holds for j = 1.
(ii).2 Let j > 1.
From (A.22) and (A.23), we have
|Word (i, j) | = |Word (i, j −1) | + |Word (i −1, j + 1) |
=
j −1 + 2i
i

·
j −1
2i + j −1
+
j + 1 + 2(i −1)
i −1

·
j + 1
2(i −1) + j + 1
=
j −1 + 2i
j −1 + i

j −1
2i + j −1
+
j + 2i −1
i −1

·
j + 1
2i + j −1
=
j
2i + j ·
j + 2i
j + i

·
 (j −1)(j + i)
j · (2i + j −1) +
(j + 1) · i
j · (2i + j −1)

=
j
2i + j ·
j + 2i
j + i

=
j + 2i
i

·
j
j + 2i.
Thus, the induction hypothesis holds for every j > 1, too.
⊓⊔
A.4 Summary
In this appendix, the fundamentals of number theory, algebra, and combina-
torics were presented. We also gave proofs of some claims if the proof details
were useful for the understanding of the design of algorithms here.

A.4 Summary
265
Here, we view mathematics as a collection of instruments for solving var-
ious problems. In what follows we list once more the most important and
frequently applied mathematical discoveries.
The Prime Number Theorem shows the density of primes among positive
integers, namely how many primes are among the n smallest positive integers.
This is important to know, because in several applications we consider the
set PRIM (n) of primes smaller than or equal to n as the set of candidates
for a witness (or as a kind of ﬁngerprinting), and then one needs to know
the number of candidates for analysis of the error probability. Moreover, the
Prime Number Theorem is used for designing an algorithm for the generation
of random primes.
Lagrange’s Theorem is also an instrument for analyzing randomized algo-
rithms, based on the method of abundance of witnesses. In order to bound
the number of non-witnesses among the candidates, we search for a group
(A, ◦) such that A is a subset of the set of candidates and all non-witnesses
are included in a proper subgroup of (A, ◦). In this way one can show that
the number of non-witnesses is at most half the number of candidates. We
have applied this approach to the analysis of the Solovay-Strassen algorithm
for primality testing.
The Chinese Remainder Theorem provides a structured representation of
elements of ZZn for composite integers n. This is important because, for com-
posite n, the set ZZn −{0} is not a group (a ﬁeld). For instance, we used this
representation to ﬁnd an element outside a subgroup of non-witnesses, and so
to show that this subgroup in a proper subgroup of the group of candidates
considered.
Fermat’s Little Theorem is the starting point for the search for a suitable
kind of witness for primality testing, as well as for proving Euler’s Criterion,
which is the base for the design of the eﬃcient Las Vegas algorithm for gen-
erating quadratic non-residues.
The combinatorial relations presented above are especially useful for the
analysis of randomized algorithms and for the study of probability success
ampliﬁcation by executing several independent runs on the same input.
For an excellent introduction to discrete mathematics, we warmly recom-
mend the textbooks by Graham, Knuth, and Patashnik [GKP94], Yan [Yan00],
Johnsonbaugh [Joh97], and the German textbook by Steger [Ste01].

This page intentionally left blank

References
[AGP92]
W. Alford, A. Granville, and C. Pomerance. There are inﬁnitely many
Carmichael numbers.
In University of Georgia Mathematics Preprint
Series. 1992.
[AH87]
L. Adleman and M. Huang. Recognizing primes in random polynomial
time. In Proc. 19th ACM STOC, pages 482–469. ACM, 1987.
[AKS02]
M. Agrawal, N. Kayal, and N. Saxena. Primes in P. Manuscript, 2002.
[AMM77]
L. Adleman, K. Manders, and G. Miller. On taking roots in ﬁnite ﬁelds.
In Proc. 18th IEEE FOCS, pages 151–163. IEEE, 1977.
[BB96]
G. Brassard and P. Bradley. Fundamentals of Algorithmics. Prentice
Hall, 1996.
[BEY98]
A Borodin and R. El-Yaniv. Online Computation and Competitive Anal-
ysis. Cambridge University Press, 1998.
[Car12]
R. Carmichael. On composite numbers p which satisfy the Fermat con-
gruence ap−1 ≡1. American Mathematical Monthly, 19:22–27, 1912.
[CLR90]
T. Cormen, C. Leiserson, and R. Rivest.
Introduction to Algorithms.
MIT Press and McGraw-Hill, 1990.
[CLRS01] T. Cormen, C. Leiserson, R. Rivest, and C. Stein. Introduction to Algo-
rithms. MIT Press and McGraw-Hill, 2001.
[CW79]
J. Carter and M. Wegman. Universal classes of hash functions. Journal
of Computer and System Sciences, 18:143–154, 1979.
[Dan49]
G. Dantzig. Programming of independant activities, ii. Mathematical
model. Econometrics, 17:200–211, 1949.
[Die04]
M. Dietzfelbinger. Primality testing in polynomial time: From random-
ized algorithms to “Primes is in P”. In Lecture Notes in Computer Sci-
ence 3000. Springer, 2004.
[DKM+94] M. Dietzfelbinger, A. Karlin, K. Mehlhorn, F. Meyer auf der Heide,
H. Rohnert, and R. Tarjan Rohnert. Dynamic perfect hashing: Upper
and lower bounds. SIAM Journal on Computing, 23:738–761, 1994.
[FKS84]
M. Fredman, J. Koml´os, and E. Szemer´edi. Storing a parse table with
o(1) worst case access time. Journal of the ACM, 31:538–544, 1984.
[Fre77]
R. Freivalds. Probabilistic machines can use less running time. In Proc.
of IFIP Congress, Information Processing, 77:839–842. North-Holland,
1977.

268
References
[FW98]
A. Fiat and G. Woeginger. Online Algorithms. The State of the Art. In
Lecture Notes in Computer Science 1492. Springer, 1998.
[GKP94]
R. Graham, D. Knuth, and O. Patashnik.
Concrete Mathematics.
Addison-Wesley, 1994.
[Gon84]
G. Gonnet.
Handbook of Algorithms and Data Structures.
Addison-
Wesley, 1984.
[Hro97]
J. Hromkoviˇc.
Communication Complexity and Parallel Computing.
Springer, 1997.
[Hro03]
J. Hromkoviˇc. Algorithmics for Hard Problems. Springer, 2nd edition,
2003.
[Hro04]
J. Hromkoviˇc. Theoretical Computer Science. Springer, 2004.
[HSW01]
J. Hromkoviˇc, A. Steinh¨ofel, and P. Widmayer.
Job shop scheduling
with unit length tasks: bounds and algorithms. In Proc. of ICTCS 2001,
Lecture Notes in Computer Science, pages 90–106. Springer, 2001.
[Joh97]
R. Johnsonbaugh.
Discrete Mathematics.
Prentice Hall, 4th edition,
1997.
[Kar91]
R. Karp. An introduction to randomized algorithms. Discrete Applied
Mathematics, 34:165–201, 1991.
[Kar93]
D. Karger. Global min-cuts in RNC and other ramiﬁcations of a simple
min-cut algorithm. In ACM–SIAM Symposium on Discrete Algorithms,
volume 4, pages 21–30, 1993.
[Kha94]
L. Khachian. A polynomial algorithm for linear programming. In Doklady
Akad. Nauk USSR 224, volume 5, pages 1093–1096. 1979 (in Russian),
Translation Soviet. Math. Doklady 20, 191–194.
[KM72]
V. Klee and G. Minty. How good is the simplex algorithm? In Inequalities
III, pages 159–175. Academic Press, 1972.
[KN97]
E. Kushilevitz and N. Nisan. Communication Complexity. Cambridge
University Press, 1997.
[Knu73]
D. Knuth. Sorting and Searching. Vol 3 of The Art of Computer Pro-
gramming. Addison-Wesley, 1973.
[KS93]
D. Karger and C. Stein. An θ(n2) algorithm for minimum cuts. In Proc.
ACM STOC, pages 757–765. ACM, 1993.
[MPS98]
E. Mayr, M. Pr¨omel, and A. Steger. Lectures on Proof Veriﬁcation and
Approximation Algorithms. In Lecture Notes in Computer Science 1967.
Springer, 1998.
[MR95]
R. Motwani and P. Raghavan. Randomized Algorithms. Cambridge Uni-
versity Press, 1995.
[MS82]
K. Mehlhorn and E. Schmidt. Las Vegas is better than determinism in
VLSI and distributed computing. In Proc. of 14th ACM STOC, ACM,
pages 330–337, 1982.
[OW02]
T. Ottmann and P. Widmayer. Algorithmen und Datenstrukturen. Spek-
trum Akademischer Verlag, 4th edition, 2002. in German.
[Pra75]
V. Pratt. Every prime has a succint certiﬁcate. SIAM Journal on Com-
puting, 4(3):214–220, 1975.
[PRRR00] P. Pardalos, S. Rajasekaran, J. Reif, and J. Rolim, editors. Handbook of
Randomized Computing. Kluwer, 2000.
[PS82]
C. Papadimitriou and K. Steiglitz. Combinatorial Optimization: Algo-
rithms and Complexity. Prentice Hall, 1982.

References
269
[Rab76]
M. Rabin. Probabilistic algorithms. In J. Traub, editor, Algorithms and
Complexity: Recent Results and New Directions, pages 21–39. Academic
Press, 1976.
[Rab80]
M. Rabin. Probabilistic algorithm for primality testing. Journal of Num-
ber Theory, 12:128–138, 1980.
[Ros00]
S. Ross. Introduction to Probability Models. Academic Press, 2000.
[Sch99]
U. Sch¨oning.
A probabilistic algorithm for kSAT and constraint sat-
isfaction problems. In Proc. 40th IEEE FOCS, pages 410–414. IEEE,
1999.
[Sch01]
U. Sch¨oning.
Algorithmik.
Spektrum Akademischer Verlag, 2001.
in
German.
[Sip97]
M. Sipser. Introduction to the Theory of Computation. PWS Publishing
Company, 1997.
[SS77]
R. Solovay and V. Strassen. A fast Monte Carlo for primality. SIAM
Journal of Computing, pages 84–85, 1977.
[SS01]
T. Schickinger and A. Steger. Diskrete Strukturen, Vol 2, Wahrschein-
lichkeitstheorie und Statistik. Springer, 2001. in German.
[Ste01]
A. Steger.
Diskrete Strukturen, Vol 1, Kombinatorik–Graphentheorie–
Algebra. Springer, 2001. in German.
[Str96]
V. Strassen.
Zufalls-Primzahlen und Kryptographie.
In I. Wegener,
editor, Highlights aus der Informatik, pages 253–266. Springer, 1996. in
German.
[Vaz01]
V. Vazirani. Approximation Algorithms. Springer, 2001.
[Weg03]
I. Wegener. Komplexit¨atstheorie. Springer, 2003. in German.
[Yan00]
S. Yan. Number Theory for Computing. Springer, 2000.

This page intentionally left blank

Index
0/1-LP
209, 216
CNF
77
ILP
78, 209
kCNF
77
LP
209
MAX-CUT
85
MAX-KP
213
MAX-SAT
77, 210, 216
MIN-CUT
154
MIN-SC
214
MIN-VC
212, 214
MIN-VCP
77
TSP
75
abundance
of Jac-witnesses
196
abundance of witnesses
89–91, 183
method of
89
Adleman
182, 207, 267
adversary
87
Agrawal
206, 207, 267
Alford
207, 267
algebra
229, 239
algorithm
1MC
62
1MC∗
63
2MC
64
MC
68, 72
nondeterministic
72
algorithms
Las Vegas
52
Las Vegas∗
57
ampliﬁcation
138, 153, 160, 166, 181
method
94
of the success probability
94, 154
approximation algorithm
79
randomized
210
randomized δ
82
randomized E[δ]
82
approximation ratio
79
avoiding the worst-case problem
instances
87
Big Bang
11
Boolean functions
151
Borodin
129, 267
Bradley
99, 267
Brassard
99, 267
Carmichael
187, 207, 267
Carmichael numbers
187, 207
Carter
128, 267
causality
2
Chinese Remainder Theorem
ﬁrst version
247
second version
249
communication complexity
134, 138
communication protocol
5
competitive algorithm
118
competitive ratio
118
expected
121
composite
229
computation
38
computation repetitions
65
conditional probability
25, 27, 28
conjunctive normal form (CNF)
77
Cormen
99, 128, 207, 267
coset
253

272
Index
Dantzig
226, 267
data management
102
data record
102
Democritos
1
determinism
2
dictionary operations
103
Dietzfelbinger
129, 207, 267
distribution function
31
divisor
229
divisors
trivial
229
dynamic data management
102, 111
Einstein
2
El-Yaniv
129, 267
Epikurus
1
equivalence problem
92
error probability
68
Euclid’s Algorithm
238
Eulerian numbers
189
Euler’s criterion
176, 178
event
20, 21
certain
21
elementary
20
evolution
3
expectation
34
expected value
34
experiment
25, 38
probabilistic
20
symmetric
21
Extended Riemann Hypothesis
207
factorization
175, 229
factors
229
feasible solutions
75
Fermat
20, 206
Fermat’s Little Theorem
243
Fiat
129, 268
ﬁngerprint
92, 105, 131, 132, 142, 145
ﬁngerprinting
92, 93, 105, 131, 144
foiling the adversary
87, 101, 102
Fredman
129, 267
Freivalds
151, 267
Freivalds’ technique
91
Fundamental Theorem of Arithmetics
229
Galileo Galilei
3
Gauss’ congruence
234
generator
of the group
242
Goethe
4
Gonnet
128, 268
Graham
99, 265, 268
Granville
207, 267
greatest common divisor
235
group
240
Hamiltonian cycle
75
harmonic number
260
hash function
104–106, 109, 115
linear
112
hash table
103
hashing
102, 103, 128
Hromkoviˇc
129, 151, 268
Huang
207, 267
Huygens
20
independence
27, 28
of random variables
33
independent
28, 33
independent runs
65, 68
indicator variable
35
integers
228
Jac-witness
196, 197, 201
Jacobi symbol
193, 194
Johnsonbaugh
265
Karger
182, 268
Karlin
129, 267
Karp
268
Kayal
206, 207, 267
key
102
Khachian
226, 268
Klee
226, 268
knapsack problem
213
Knuth
99, 128, 265, 268
Kolmogorov
20
Koml´os
129, 267
Kushilevitz
151, 268
Lagrange’s Theorem
255
Las Vegas
151
Las Vegas algorithm
52, 57, 60
Legendre Symbol
193
Leiserson
99, 128, 207, 267
linear programming
209, 211, 226
0/1-
209

Index
273
integer
78
relaxation to
94, 210
linearity of expectation
37
weak
36
local search
166
lowest common multiple
235
Manders
182, 267
Marcus Aurelius
2
Master Theorem
261
mathematics
227
maximization problem
74
Mayr
99, 226, 268
Mehlhorn
129, 151, 267, 268
method
ampliﬁcation
159
ﬁngerprinting
92, 131
of avoiding the worst-case inputs
101
of foiling the adversary
101, 109
of random rounding
94
of random sampling
93
of relaxation to linear programming
210, 211
Meyer auf der Heide
129
Miller
182, 207, 267
minimization problem
74
Minty
226, 268
Monte Carlo algorithm
(unbounded-error)
68
bounded-error
64
one-sided-error
62
Motwani
99, 151, 181, 207, 268
natural numbers
228
neutral element
240
Newton’s Theorem
258
Nisan
151, 268
nondeterministic algorithm
46
number theory
229
observation
24
online algorithm
117
randomized
121
online algorithms
117
online problems
117
optimization
117, 209
problem
74, 75
order
251
Ottmann
128, 268
paging
119
Papadimitriou
268
Pardalos
99, 268
Pascal
20
Patashnik
99, 265, 268
pattern recognition
139
Pomerance
207, 267
Pratt
207, 268
primality testing
184, 192, 206, 207
randomized
201
prime
187, 229
Prime Number Theorem
8, 233
probabilistic method
93
probabilities
addition of
22
multiplication of
24
product of the
27
probability
22
density function
31
error
41
of an event
21, 22
probability distribution
21, 22
probability space
22
probability theory
20
Pr¨omel
99, 226, 268
protocol
69, 133
Las Vegas
53
randomized
41
quadratic nonresidue
175, 180
quadratic residue
176
Quicksort
47
randomized
88
R´enyi
3
Rabin
207, 269
Raghavan
99, 151, 182, 207, 268
Rajasekaran
99, 268
random
1, 2
random bits
51
random events
20
random rounding
210, 216, 222
random sample
93
random sampling
93, 153, 166, 168,
174, 181, 222
random variable
30, 31
randomized algorithm
37, 38, 40, 46,
51

274
Index
classiﬁcation of
51, 72
randomized control
38
randomness
1–5
true
1, 4
rational numbers
228
real numbers
228
reduction
212
Reif
99, 268
relaxation
212
relaxation to linear programming (LP)
210, 216, 225
reliability
11
Rivest
99, 128, 207, 267
Rohnert
129
Rolim
99, 268
Ross
99, 269
Rumely
207
run
38
runs
independent
58
sample space
20, 21
satisﬁability
maximum
77
Saxena
206, 207, 267
scheduling
121
Schickinger
99, 269
Schmidt
151, 268
Sch¨oning
99, 128, 182, 269
set cover
214
Simplex algorithm
226
Sipser
151, 269
slots
103
Solovay
207, 269
Steger
99, 226, 265, 268, 269
Steiglitz
268
Stein
99, 128, 182, 207, 267, 268
Steinh¨ofel
129, 268
Stirling formula
260
stochastic algorithms
37
Strassen
207, 269
substring problem
139
success probability
40
success probability ampliﬁcation
222
Szemer´edi
129
Tarjan
129, 267
technique
Freivalds
151
text processing
139
Theorem
Chinese Remainder
247
time complexity
expected
39
of a randomized algorithm
40
Traub
269
universal set
of hash functions
110, 111, 115
universe
11, 104
Vazirani
226, 269
vertex cover
76
minimum
77
Wegener
99, 269
Wegman
128, 267
Widmayer
128, 129, 268
witness
90, 145, 183, 186, 206
Woeginger
129, 268
worst-case complexity
87
Yan
265, 269

Monographs in Theoretical Computer Science • An EATCS Series
K. Jensen
Coloured Petri Nets
Basic Concepts, Analysis Methods
and Practical Use, Vol. 1
2nd ed.
K. Jensen
Coloured Petri Nets
Basic Concepts, Analysis Methods
and Practical Use, Vol. 2
K. Jensen
Coloured Petri Nets
Basic Concepts, Analysis Methods
and Practical Use, Vol. 3
A. Nait Abdallah
The Logic of Partial Information
Z. Fülöp, H.Vogler
Syntax-Directed Semantics
Formal Models Based
on Tree Transducers
A. de Luca, S. Varricchio
Finiteness and Regularity
in Semigroups and Formal Languages
E. Best, R. Devillers, M. Koutny
Petri Net Algebra
S.P. Demri, E.S. Orlowska
Incomplete Information:
Structure, Inference, Complexity
J.C.M. Baeten, C.A. Middelburg
Process Algebra with Timing
L.A. Hemaspaandra, L. Torenvliet
Theory of Semi-Feasible Algorithms
E. Fink, D. Wood
Restricted-Orientation Convexity
Zhou Chaochen, M. R. Hansen
Duration Calculus
A Formal Approach to Real-Time
Systems
M. Große-Rhode
Semantic Integration
of Heterogeneous Software
Specifications

Texts in Theoretical Computer Science • An EATCS Series
J. L. Balcázar, J. Díaz, J. Gabarró
Structural Complexity I
M. Garzon
Models of Massive Parallelism
Analysis of Cellular Automata
and Neural Networks
J. Hromkovic
Communication Complexity
and Parallel Computing
A. Leitsch
The Resolution Calculus
A. Salomaa
Public-Key Cryptography
2nd ed.
K. Sikkel
Parsing Schemata
A Framework for Specification
and Analysis of Parsing Algorithms
H. Vollmer
Introduction to Circuit Complexity
A Uniform Approach
W. Fokkink
Introduction to Process Algebra
K. Weihrauch
Computable Analysis
An Introduction
J. Hromkovic
Algorithmics for Hard Problems
Introduction to Combinatorial
Optimization, Randomization,
Approximation, and Heuristics
2nd ed.
S. Jukna
Extremal Combinatorics
With Applications
in Computer Science
C.S. Calude
Information and Randomness
An Algorithmic Perspective, 2nd ed.
J. Hromkovic
Theoretical Computer Science
Introduction to Automata,
Computability, Complexity,
Algorithmics, Randomization,
Communication and Cryptography
K. Schneider
Verification of Reactive Systems
Formal Methods and Algorithms
S. Ronchi Della Rocca, L. Paolini
The Parametric Lambda Calculus
A Metamodel for Computation
Y. Bertot, P. Castéran
Interactive Theorem Proving
and Program Development
Coq'Art: The Calculus
of Inductive Constructions
L. Libkin
Elements of Finite Model Theory
M. Hutter
Universal Artificial Intelligence
Sequential Decisions
Based on Algorithmic Probability
G. Påun, G. Rozenberg,  A. Salomaa
DNA Computing
New Computing Paradigms
2nd corr. printing
J. Hromkovic, R. Klasing, A. Pelc,
P. Ruzicka†, W. Unger
Dissemination of Information
in Communication Networks
Broadcasting, Gossiping, Leader
Election, and Fault-Tolerance
 °
 °
 °
 °
 ° °

Texts in Theoretical Computer Science • An EATCS Series
P. Clote, E. Kranakis
Boolean Functions
and Computation Models
L. A. Hemaspaandra, M. Ogihara
The Complexity Theory Companion
W. Kluge
Abstract Computing Machines
A Lambda Calculus Perspective
R. Kurki-Suonio
A Practical Theory
of Reactive Systems
Incremental Modeling
of Dynamic Behaviors
J. Hromkovic
Design and Analysis of Randomized
Algorithms
Introduction to Design Paradigms
 °

