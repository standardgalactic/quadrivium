International Series in
Operations Research & Management Science
GiorgioÂ Giorgi
BienvenidoÂ JimÃ©nez
VicenteÂ Novo
Basic 
Mathematical 
Programming 
Theory

International Series in Operations Research &
Management Science
Founding Editor
Frederick S. Hillier
Volume 344
Series Editor
Camille C. Price, Department of Computer Science, Stephen F. Austin State
University, Nacogdoches, TX, USA
Associate Editor
Joe Zhu, Foisie Business School, Worcester Polytechnic Institute, Worcester, MA,
USA
Editorial Board
Emanuele Borgonovo, Department of Decision Sciences, Bocconi University,
Milan, Italy
Barry L. Nelson, Department of Industrial Engineering & Management Sciences,
Northwestern University, Evanston, IL, USA
Bruce W. Patty, Veritec Solutions, Mill Valley, CA, USA
Michael Pinedo, Stern School of Business, New York University, New York, NY,
USA
Robert J. Vanderbei, Princeton University, Princeton, NJ, USA

Giorgio Giorgi Â· Bienvenido JimÃ©nez Â·
Vicente Novo
Basic Mathematical
Programming Theory

Giorgio Giorgi
Department of Economics and Management
University of Pavia
Pavia, Italy
Vicente Novo
Department of Applied Mathematics
National University of Distance Education
Madrid, Spain
Bienvenido JimÃ©nez
Department of Applied Mathematics
National University of Distance Education
Madrid, Spain
ISSN 0884-8289
ISSN 2214-7934 (electronic)
International Series in Operations Research & Management Science
ISBN 978-3-031-30323-4
ISBN 978-3-031-30324-1 (eBook)
https://doi.org/10.1007/978-3-031-30324-1
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature
Switzerland AG 2023
This work is subject to copyright. All rights are solely and exclusively licensed by the Publisher, whether
the whole or part of the material is concerned, speciï¬cally the rights of translation, reprinting, reuse
of illustrations, recitation, broadcasting, reproduction on microï¬lms or in any other physical way, and
transmission or information storage and retrieval, electronic adaptation, computer software, or by similar
or dissimilar methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication
does not imply, even in the absence of a speciï¬c statement, that such names are exempt from the relevant
protective laws and regulations and therefore free for general use.
The publisher, the authors, and the editors are safe to assume that the advice and information in this book
are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or
the editors give a warranty, expressed or implied, with respect to the material contained herein or for any
errors or omissions that may have been made. The publisher remains neutral with regard to jurisdictional
claims in published maps and institutional afï¬liations.
This Springer imprint is published by the registered company Springer Nature Switzerland AG
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland

For Elena, Elisa, Marcello and Lucia
Giorgio Giorgi
For my wife Elena and my children Roberto,
Cristina and Elena
Bienvenido JimÃ©nez
For my grandchildren Leo, Vega, Eva and
Sara
Vicente Novo

Preface
It is quite superï¬‚uous to stress that mathematical optimization is a corner-
stone of not only several scientiï¬c subjects, such as Economic Analysis, Opera-
tions Research, Management Sciences, Engineering, Chemistry, Physics, Statistics,
Computer Science, but also Biology and other Social Sciences. The subject of (static)
optimization, called also mathematical programming, is, besides its various appli-
cations, one of the most important and wide branches of modern mathematics, with
deep and beautiful theoretical results. The present book is concerned with the main
theoretical questions on optimality and duality theory of mathematical programming
problems in the Euclidean space Rn. Also in order of limiting the dimension of the
book, we have decided to devote our efforts only to expose the basic mathematical
tools and results concerning the most treated mathematical programming problems
formulated in a ï¬nite-dimensional setting. We wish to make clear that it would
be desirable that the student or the researcher interested in these questions would
complete his knowledge by learning also the basic questions on the various algo-
rithmic methods and on the most important particular applications of mathematical
programming problems.
It is however our opinion that the student or researcher interested in learning
the fundamental facts of mathematical programming, before being acquainted with
the various algorithms and numerical questions, must possess the basic mathemat-
ical notions and the basic theoretical background used in analyzing optimization
problems.
As it happens for any book, also the present one reï¬‚ects the tastes of its authors. We
have been compelled to make choices, as some subjects of Mathematical Program-
ming have grown at an exponential rate (e.g., Linear Programming) and it would
be impossible to cover in a single volume every aspect of mathematical program-
ming theory. Consequently, we have left out certain important subjects, such as,
for example, Complementarity Theory, Discrete Optimization, Stochastic Program-
ming, Semi-inï¬nite Programming, Bilevel Programming, and Fractional Program-
ming. Also, set-valued optimization problems are not treated in the present book.
vii

viii
Preface
However, the last chapter is concerned with an introduction to vector optimization
problems, but only in ï¬nite dimensions (as done for the scalar case), that is the
multiobjective case.
The text assumes no previous experience in optimization theory and the treatment
of the various topics is largely self-contained. The prerequisites are the basic tools of
differential calculus for functions of several variables, the basic notions of topology
in Rn and of Linear Algebra. Some of these concepts are recalled in Chap. 1. We
do not claim any originality on the structure of this book; however, we hope that the
gradual and self-contained treatment of the subjects will reveal to be a â€œfriendlyâ€
approach to the non-experienced reader. We have accompanied several theoretical
results with examples and we have often made reference to papers and books, in
order to give further information to the curious and willing reader. The list of works
in the bibliographical references is quite long.
The book addresses not only to both undergraduate and postgraduate students
interested in mathematical programming problems but also to those professionals
who use in their jobs optimization methods and wish to learn more theoretical aspects
of these questions. We hope that it can be useful in courses of optimization, operations
research, economic analysis, and in other courses where optimization theory and
methods are investigated. The book is organized into 11 chapters.
Chapter 1 includes background material on classical analysis and linear algebra,
together with some basic deï¬nitions and properties concerning optimization prob-
lems. We present also the main types of optimization problems that will be studied
in the next chapters.
Chapter 2 is concerned with the fundamental facts of convex analysis, a subject
which is at the heart of optimization theory. We give particular attention to the
theorems of the alternative for linear systems. One of the most used and known results
of this type, from which all other theorems of the alternative for linear systems can be
obtained, is the famous Theorem (or Lemma) of Farkas (or of Farkas-Minkowski).
However, some excellent books on optimization theory present an unsatisfactory
proof of this theorem, as it is given for granted that a polyhedral cone is a closed set.
But this is, in a certain sense, just equivalent to the statement of Farkasâ€™ theorem.
In the same chapter, we give also the main deï¬nitions and properties of some local
cone approximations used in optimization theory.
Chapter 3 provides an overview of convex functions and generalized convex
functions, with emphasis on their most important properties regarding optimality
conditions. Generalized convexity and generalized monotonicity of functions have
attracted several researchers, both in mathematics and in other professional disci-
plines: the Working Group of Generalized Convexity (WGGC) is a section of the
Mathematical Programming Society (since 2010 named Mathematical Optimization
Society). The chapter concludes with some theorems of the alternative for nonlinear
systems.
Chapter 4 treats optimality conditions for an unconstrained optimization problem,
denoted by (P1) for a constrained optimization problem with a set constraint (or
abstract constraint), denoted by (P2), and for a â€œclassicalâ€ constrained optimization
problem, denoted by (P3); in other words, (P3) is an optimization problem with

Preface
ix
only equality constraints. These problems have been called â€œclassicalâ€ constrained
optimization problems, as they were studied for the ï¬rst time by J. L. Lagrange in
the second half of the 18th century.
Chapter 5 treats a â€œmodernâ€ constrained optimization problem, i.e., a constrained
minimization problem with inequality constraints, problem denoted by (P4). The
basic necessary and sufï¬cient ï¬rst-order and second-order optimality conditions
are given (Fritz John conditions and Karush-Kuhn-Tucker conditions). A special
attention is devoted to the question of constraint qualiï¬cations: various constraint
qualiï¬cations are presented, together with their inclusion properties. Other formula-
tions of (P4) are taken into consideration and several simple numerical examples are
discussed.
Chapter 6 treats constrained optimization problems with mixed constraints, i.e.,
with both equality and inequality constraints, problems denoted by (P5). We have
preferred to treat separately these types of problems, as the related optimality condi-
tions have some particular features. Also for these problems, ï¬rst-order conditions
and second-order conditions are discussed with a certain wideness and the question of
constraint qualiï¬cations is extensively treated, with various constraint qualiï¬cations
proposed and analyzed. The chapter concludes with some insights on a constrained
optimization problem with both equality and inequality constraints and with a set
constraint, problem denoted by (P6), and on asymptotic optimality conditions for
(P5).
Chapter 7 is concerned with sensitivity analysis for problem (P5) a subject usually
not treated in textbooks on optimization theory, but important for its economic and
ï¬nancial applications and also for computational questions. We follow mainly the
classical approach of Fiacco (1983).
Chapter 8 is concerned with optimality conditions for a convex programming
problem of the type (P4) expressed in terms of saddle points conditions, and with
Lagrangian duality. From a historical point of view, optimality conditions via saddle
points are important, as one of the aims of the pioneering paper of Kuhn and Tucker
(1951) was to extend to the nonlinear (convex) case the duality and saddle points
results previously obtained for the linear case (Linear Programming). As for what
concerns duality theory, we have chosen to give some basic insights on the so-
called â€œLagrangian dualityâ€, because this approach is equivalent (at least for convex
programming) to Fenchelâ€™s approach which uses conjugate functions. We brieï¬‚y
treat also the general approach to duality which makes reference to the â€œminimax
theoryâ€.
Chapter 9 is concerned with Linear Programming and Quadratic Programming.
Linear programming problems are treated with reference to their fundamental formal
properties, therefore with no mention to the famous â€œsimplex methodâ€ of G. B.
Dantzig, nor to other more modern algorithmic questions. For these last aspects, we
have given in the bibliographical references some suggestions. The same holds true
for quadratic programming problems, which are important for some applications
in Finance, Econometrics and Statistics. A special attention has been devoted to
duality theory, both for linear programming problems and for quadratic programming
problems.

x
Preface
Chapter 10 is an introduction to nonsmooth optimization. The term â€œnonsmooth
analysisâ€ is due to the Canadian mathematician F. H. Clarke; the related theory begins
with the necessity to treat, within convex optimization problems, non-necessarily
differentiable functions. The basic contributions to this case are the works of Fenchel
(1953), Moreau (1963), and the celebrated book Convex Analysis by Rockafellar
(1970). Subsequently, Clarke (1983) extended the domain of nonsmooth analysis
from convex to locally Lipschitz functions. The ï¬rst and second sections of Chap. 10
are, respectively, concerned with nonsmooth convex optimization problems and
with nonsmooth locally Lipschitz optimization problems. The third and last section
is concerned with an axiomatic approach to nonsmooth analysis and nonsmooth
optimization, due to Elster and Thierfelder (1985, 1988a, b, 1989).
The ï¬nal Chap. 11 is an introduction to vector optimization problems, but only in
ï¬nite dimensions, that is the multiobjective case. Necessary and sufï¬cient optimality
conditions are given, together with the so-called â€œweighted sum methodâ€.
Pavia, Italy
Madrid, Spain
December 2022
Giorgio Giorgi
Bienvenido JimÃ©nez
Vicente Novo
Acknowledgements This work, for the second and third authors, was partially supported by Minis-
terio de Ciencia e InnovaciÃ³n and Agencia Estatal de InvestigaciÃ³n (Spain) under the project with
reference PID2020-112491GB-I00/AEI/10.13039/501100011033.

Contents
1
Basic Notions and Deï¬nitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.2
Basic Notions of Analysis and Linear Algebra . . . . . . . . . . . . . . . .
2
1.3
Basic Deï¬nitions and Properties of Optimization Problems . . . . .
9
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
22
2
Elements of Convex Analysis. Linear Theorems
of the Alternative. Tangent Cones . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
23
2.1
Elements of Convex Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
23
2.2
Theorems of the Alternative for Linear Systems . . . . . . . . . . . . . .
41
2.3
Tangent Cones . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
47
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
52
3
Convex Functions and Generalized Convex Functions . . . . . . . . . . . .
53
3.1
Convex Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
53
3.2
Generalized Convex Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
64
3.3
Optimality Properties of Convex and Generalized Convex
Functions. Nonlinear Theorems of the Alternative . . . . . . . . . . . . .
74
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
81
4
Unconstrained Optimization Problems. Set-Constrained
Optimization Problems. Classical Constrained Optimization
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
83
4.1
Unconstrained Optimization Problems
. . . . . . . . . . . . . . . . . . . . . .
83
4.2
Set-Constrained Optimization Problems . . . . . . . . . . . . . . . . . . . . .
96
4.3
Optimization Problems with Equality Constraints
(â€œClassical Constrained Optimization Problemsâ€) . . . . . . . . . . . . .
102
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
121
5
Constrained Optimization Problems with
Inequality Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
123
5.1
First-Order Conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
123
5.2
Constraint Qualiï¬cations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
137
xi

xii
Contents
5.3
Second-Order Conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
141
5.4
Other Formulations of the Problem. Some Examples . . . . . . . . . .
147
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
167
6
Constrained Optimization Problems with Mixed Constraints . . . . . .
169
6.1
First-Order Conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
169
6.2
Constraint Qualiï¬cations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
184
6.3
Second-Order Conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
201
6.4
Problems with a Set Constraint. Asymptotic Optimality
Conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
215
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
222
7
Sensitivity Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
225
7.1
General Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
225
7.2
Sensitivity Results for Right-Hand Side Perturbations . . . . . . . . .
236
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
242
8
Convex Optimization: Saddle Points Characterization
and Introduction to Duality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
243
8.1
Convex Optimization: Saddle Points Characterization . . . . . . . . .
243
8.2
Introduction to Duality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
254
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
273
9
Linear Programming and Quadratic Programming . . . . . . . . . . . . . .
275
9.1
Linear Programming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
275
9.2
Duality for Linear Programming . . . . . . . . . . . . . . . . . . . . . . . . . . . .
289
9.3
Quadratic Programming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
301
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
315
10
Introduction to Nonsmooth Optimization Problems . . . . . . . . . . . . . .
317
10.1
The Convex Case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
318
10.2
The Lipschitz Case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
337
10.3
The Axiomatic Approach of K.-H. Elster and J. Thierfelder
to Nonsmooth Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
367
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
379
11
Introduction to Multiobjective Optimization . . . . . . . . . . . . . . . . . . . . .
383
11.1
Optimality Notions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
384
11.2
The Weighted Sum Method and Relations with
Proper Efï¬ciency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
399
11.3
Optimality Conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
403
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
429
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
431

Chapter 1
Basic Notions and Deï¬nitions
1.1
Introduction
It is well-known that the central problem of mathematical programming is that of
minimizing or maximizing a given numerical function of several variables, where the
variables are free to move over the whole domain of the function or (more usually)
are constrained by a system of constraints.
Mathematical programming, called also nonlinear programming, can be viewed
as that ï¬eld of optimization theory which treats static and ï¬nite-dimensional opti-
mization problems. It seems that the term â€œmathematical programmingâ€ was ï¬rst
introduced by the American economist Robert Dorfman in 1949, as a generaliza-
tion of the term â€œlinear programmingâ€, introduced by the American mathematician
George B. Dantzig a couple of years before. The term â€œnonlinear programmingâ€
appears for the ï¬rst time in 1951 in the title of the famous pioneering paper of Kuhn
and Tucker [1]. Mathematical programming problems are at the heart of many theo-
retic and applied sciences: indeed, these problems occur in different contexts, such as
for example, economic analysis, operations research, management sciences, games
theory, statistics, physics, engineerings, etc. Mathematical programming problems
have attracted a wide interest also because of their applications in many practical
questions arising in industry, commerce, government and military questions.
In the present text-book we shall be concerned with the basic aspects of optimality
conditions and duality conditions related to a mathematical programming problem.
We have preferred to point out the basic ideas on the mathematical structure of
these problems, rather than on the various algorithmic techniques, available in many
excellent books treating numerical optimization.
Â© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al., Basic Mathematical Programming Theory, International Series
in Operations Research & Management Science 344,
https://doi.org/10.1007/978-3-031-30324-1_1
1

2
1
Basic Notions and Deï¬nitions
1.2
Basic Notions of Analysis and Linear Algebra
In this section we recall some basic notions of Analysis and Linear Algebra, which
will be useful to understand several notions developed in the next chapters. In order
to deepen the concepts expounded here, the reader is referred to the texts quoted in
the Bibliographical References.
General concepts of basic topology on Rn
Given a vector (point) in Rn
x = [x1, x2, . . . , xn]âŠ¤,
we denote by âˆ¥xâˆ¥its Euclidean norm:
âˆ¥xâˆ¥=

(x1)2 + (x2)2 + Â· Â· Â· + (xn)n.
A neighborhood U(x0), or also N(x0), of x0 âˆˆRn is given by an open ball of a
given radius Îµ > 0 :
U(x0) =

x âˆˆRn :
x âˆ’x0 < Îµ

.
When it is useful to specify the radius Îµ, we shall write UÎµ(x0), NÎµ(x0), U(x0, Îµ),
N(x0, Îµ), etc.
In any case we have
U(x0) = x0 + U(0), with 0 âˆˆRn.
A point x0 is an interior point of a set S âŠ‚Rn if x0 âˆˆS and there exists a neigh-
borhood U(x0) contained in S.
The set S âŠ‚Rn is open if all its points are interior points. The set S âŠ‚Rn is closed
if its complementary set is open (equivalently: if it contains all its boundary points
or if it contains all its accumulation points). The boundary of S, denoted by âˆ‚S or
bd(S), is the set of points x for which UÎµ(x) contains a point in S and a point not in
S, for all Îµ > 0.
The interior of a set S âŠ‚Rn is given by all its interior points, i.e., if we denote
the interior of S by int(S),
int(S) = {x âˆˆS : âˆƒU(x) âŠ‚S} .
The closure of S, denoted by cl(S) or also by Â¯S, is given by the intersection of
all closed sets which contain S. It holds
cl(S) = âˆ©
Îµ>0(S + UÎµ(0)).

1.2 Basic Notions of Analysis and Linear Algebra
3
In other words, cl(S) consists of S and all boundary points of S, i.e. cl(S) =
S âˆªbd(S).
The algebraic sum of two sets S1, S2 of Rn is deï¬ned as
S1 + S2 =

x1 + x2 : x1 âˆˆS1, x2 âˆˆS2

.
The multiplication of a set S âŠ‚Rn by a real number or real scalar Î± is deï¬ned as
Î±S = {Î±x : x âˆˆS} .
We have the following calculus rules:
Î±(S1 + S2) = Î±S1 + Î±S2,
(Î± + Î²)S âŠ‚Î±S + Î²S.
Let be given a set S âŠ‚Rn and an element x âˆˆS; we shall write S + x, instead of
S + {x} . Moreover, we shall write S1 âˆ’S2 to denote the operation S1 + (âˆ’1)S2.
Differentiability
Letbegivenafunction f : X âŠ‚Rn â†’R.Then f issaidtobe(FrÃ©chet)differentiable
at x0 âˆˆint(X), if there exists a vector âˆ‡f (x0) âˆˆRn such that
f (x) = f (x0) + âˆ‡f (x0)âŠ¤(x âˆ’x0) + o(
x âˆ’x0),
for all x âˆˆX.
The Landau symbol (â€œsmall oâ€) o(t) means that
lim
tâ†’0
o(t)
t
= 0.
The vector âˆ‡f (x0) is the gradient of f at x0; its elements are given by the n
partial derivatives of f, evaluated at x0 :
âˆ‚f
âˆ‚xi
(x0), i = 1, . . . , n.
We observe that if, in the above deï¬nition, x = x0 + Î»v, with âˆ¥vâˆ¥= 1, then
o(
x âˆ’x0) = o(Î»).
We accept the following deï¬nition of twice differentiability. A function f : X âŠ‚
Rn â†’R, differentiable at x0 âˆˆint(X), is said to be twice differentiable at x0 if
each component of âˆ‡f : X â†’Rn is differentiable at x0. Then, there exists a square
matrix, denoted âˆ‡2 f (x0) or also H f (x0), of order n, such that
f (x) = f (x0) + âˆ‡f (x0)âŠ¤(x âˆ’x0) + 1
2(x âˆ’x0)âŠ¤âˆ‡2 f (x0)(x âˆ’x0) + o
 x âˆ’x0
2 
,

4
1
Basic Notions and Deï¬nitions
for all x âˆˆX.
The matrix âˆ‡2 f (x0) is the Hessian matrix of f evaluated at x0; its elements are
given by the second-order partial derivatives of f, evaluated at x0 :
âˆ‚2 f
âˆ‚xiâˆ‚x j
(x0), i, j = 1, . . . , n.
The function f is differentiable on the open set X âŠ‚Rn, respectively, twice dif-
ferentiable on the open set X âŠ‚Rn, if it is differentiable, respectively, twice dif-
ferentiable, at every point x âˆˆX. If the ï¬rst-order partial derivatives of f are also
continuous, we say that f is continuously differentiable or also that f belongs to the
C 1-class and shall write f âˆˆC 1. If f âˆˆC 1, then f is differentiable (the vice-versa
does not hold).
If all second-order partial derivatives of f are also continuous, we say that f is
twice-continuously differentiable and shall write f âˆˆC 2. If f âˆˆC 2, then f is twice
differentiable (the vice-versa does not hold). Obviously, twice continuous differen-
tiability is more easy to check than twice differentiability, however several results on
optimization theory hold under the assumption of twice differentiability. If a function
f is twice differentiable (and, even more, if f is twice-continuously differentiable),
then its Hessian matrix âˆ‡2 f (x) is symmetric (Schwarz theorem), i. e.
âˆ‚2 f
âˆ‚xiâˆ‚x j
(x) =
âˆ‚2 f
âˆ‚x jâˆ‚xi
(x),
for all i, j = 1, . . . , n, i Ì¸= j.
A vector function h =

h1, . . . , h p
	âŠ¤: X âŠ‚Rn â†’Rp is differentiable at x0 âˆˆ
int(X) if each component hi : X â†’R, i = 1, . . . , p, is differentiable at x0. In this
case we can build the matrix
Jh(x0) â‰¡âˆ‡h(x0) =

âˆ‡h1(x0), . . . , âˆ‡h p(x0)
	
of order (n, p), called the Jacobian matrix of h at x0. We draw the readerâ€™s attention
on the fact that many authors deï¬ne the Jacobian matrix as a matrix whose rows are
the gradients of the functions hi(x), i = 1, . . . , p.
Now, let be given f : X âŠ‚Rn â†’Rm and g : Rm â†’Rp, both differentiable, and
consider the composite function h = g â—¦f : X â†’Rp, deï¬ned by means of the com-
position operation h(x) = g( f (x)). This function will be differentiable and it holds
(â€œchain ruleâ€):
âˆ‡h(x0) = âˆ‡f (x0)âˆ‡g( f (x0)).
We recall Taylorâ€™s formula for twice-continuously differentiable functions.
(a) Let f : X â†’R be a C 2-function on the open set X âŠ‚Rn and let be U(x0) âŠ‚X.
Then, for any x âˆˆU(x0) we have

1.2 Basic Notions of Analysis and Linear Algebra
5
f (x) = f (x0) + âˆ‡f (x0)âŠ¤(x âˆ’x0) + 1
2(x âˆ’x0)âŠ¤âˆ‡2 f (x0)(x âˆ’x0) + o
 x âˆ’x0
2 
,
for x â†’x0.
(Taylorâ€™s formula with remainder in Peanoâ€™s form).
(b) Let f : X â†’R be a C 2-function on the open set X âŠ‚Rn and let be U(x0) âŠ‚X.
Then, for any x âˆˆU(x0) we have
f (x) = f (x0) + âˆ‡f (x0)âŠ¤(x âˆ’x0) + 1
2(x âˆ’x0)âŠ¤âˆ‡2 f (Â¯x)(x âˆ’x0),
where Â¯x = x0 + Î¸(x âˆ’x0), with Î¸ âˆˆ(0, 1).
(Taylorâ€™s formula with remainder in Lagrangeâ€™s form).
Putting h = x âˆ’x0, Taylorâ€™s formula with remainder in Peanoâ€™s form becomes
f (x0 + h) = f (x0) + âˆ‡f (x0)âŠ¤h + 1
2hâŠ¤âˆ‡2 f (x0)h + o(âˆ¥hâˆ¥2)
and putting h = tv, with t âˆˆ(âˆ’Îµ, Îµ) and v âˆˆRn, âˆ¥vâˆ¥= 1,
f (x0 + tv) = f (x0) + tâˆ‡f (x0)âŠ¤v + t2
2 vâŠ¤âˆ‡2 f (x0)v + o(t2).
Systems of linear equations
Let be given a vector a âˆˆRn, a Ì¸= 0, and a scalar Î² âˆˆR. The set
H(a, Î²) =

x âˆˆRn : aâŠ¤x = Î²

is a hyperplane in Rn. The vector a is called the normal to the hyperplane H(a, Î²).
Note that a hyperplane is a level set of a non-identically zero linear function.
Let be given a (real) matrix A of order (m, n), with m â‰¦n non-zero row vectors,
and a vector b âˆˆRm. The solutions of the linear system
Ax = b
are given by the intersection of m hyperplanes. If the set of solutions is not empty,
it will be a linear manifold (a linear subspace if b = 0 âˆˆRm), with dimension n âˆ’
rk(A), where rk(A) denotes the rank of matrix A.
Let the row vectors of A be linearly independent, i.e. matrix A has full rank. It is
then possible (maybe by reordering the rows of A) to decompose A into the form
A = (AB, AN)
with AB square non-singular matrix of order m. Correspondingly, vector x âˆˆRn will
be partitioned as

6
1
Basic Notions and Deï¬nitions
x =
 xB
xN

,
where xB is called vector of basic variables and xN is the vector of non-basic
variables.
Then, the original system Ax = b has now the form
ABxB + AN xN = b
from which
xB = (AB)âˆ’1(b âˆ’AN xN).
Systems of nonlinear equations and Implicit Function Theorem
In the general case, the vector equation h(x) = b is not formed by linear equations.
Nevertheless, if the Jacobian matrix of h has full rank at a point x0 which solves the
equation h(x0) = 0, it is possible to get some important solvability results. These
results are contained in the following classical version of the Implicit Function Theo-
rem. In essence, this theorem gives sufï¬cient conditions for the existence of a function
that locally expresses a set of basic variables in terms of non basic variables, i.e. a
nonlinear version of what previously seen for the linear case.
Implicit Function Theorem
Let h : X âŠ‚Rn â†’Rm (m < n) be C 1 on the open set X and let x0 âˆˆX be a solution
of h(x) = 0. Let âˆ‡h(x0) be of full rank, i.e. rk(âˆ‡h(x0) = m, decomposed as (after
a possible reordering of the variables)
âˆ‡h(x0) =
 âˆ‡Bh(x0)
âˆ‡Nh(x0)

,
where âˆ‡Bh(x0) is a non-singular square matrix of order m. Then, there exists a
neighborhood U of x0
N âˆˆRnâˆ’m where the system h(x) = 0 deï¬nes â€œimplicitlyâ€ a
system of functions of the type xB = H(xN). More precisely:
(a) There exists a unique function H : Rnâˆ’m â†’Rm, deï¬ned in a neighborhood U
of x0
N, of C 1 class in this neighborhood.
(b) It holds h(H(xN), xN) = 0, for all xN in the said neighborhood U.
(c) H(xN) = xB for all xN in the said neighborhood U.
(d) It holds
âˆ‡H(x0
N) = âˆ’(âˆ‡Nh(x0))(âˆ‡Bh(x0))âˆ’1.
There are also weaker versions of this theorem; in particular, it is possible to
consider differentiable functions, instead of C 1 functions. See, e.g., Halkin [2].

1.2 Basic Notions of Analysis and Linear Algebra
7
Quadratic forms
Let be given a (real) symmetric matrix A of order n. The related quadratic form
Q : Rn â†’R is deï¬ned as
Q(x) = xâŠ¤Ax, x âˆˆRn.
The above quadratic form (and its related matrix A) is classiï¬ed as follows.
(a) Q is positive (negative) deï¬nite if Q(x) > 0 (Q(x) < 0), for all x âˆˆRn, x Ì¸= 0.
(b) Q is positive (negative) semideï¬nite if Q(x) â‰§0 (Q(x) â‰¦0), for all x âˆˆRn.
(c) Q is indeï¬nite if there exist two vectors x1, x2 âˆˆRn such that Q(x1) > 0 and
Q(x2) < 0.
Obviously the quadratic form xâŠ¤Ax (i.e. the symmetric matrix A which charac-
terized the said quadratic form) is positive (negative) deï¬nite (semideï¬nite) if and
only if âˆ’A is negative (positive) deï¬nite (semideï¬nite).
We have the following two criteria which establish the sign of a quadratic form.
Theorem 1.1 The quadratic form Q(x) = xâŠ¤Ax (the real symmetric matrix A) is:
(a) Positive (negative) deï¬nite if and only if all eigenvalues of A (which are real,
being A symmetric) are positive (negative).
(b) Positive (negative) semideï¬nite if and only if all eigenvalues of A are nonnegative
(nonpositive) and at least one eigenvalue of A is zero.
(c) Indeï¬nite if and only if A has at least one positive eigenvalue and least one
negative eigenvalue.
In order to introduce the next criterion (â€œSylvester criterionâ€), we recall that, given
a matrix A, of order (m, n), we have the following deï¬nitions.
Theminors of order k of A,1 â‰¦k â‰¦min(m, n),areall thosedeterminants formed
by k rows and k columns of A. It is shown that we have
 m
k
 n
k

minors of order k. We recall that
n
k

=
n!
k!(n âˆ’k)!.
Now, let A be a square matrix of order n.
The principal minors of A of order k, 1 â‰¦k â‰¦n, are all those determinants
formed by k rows of A and the corresponding k columns. It is shown that we have
n
k


8
1
Basic Notions and Deï¬nitions
principal minors of order k.
The leading principal minors or North-West principal minors of A of order k,
1 â‰¦k â‰¦n, are all those determinants formed by the ï¬rst k rows and the ï¬rst k
columns of A. Obviously, we have n leading principal minors:
|a11| = a11,




a11
a12
a21
a22




 ,






a11
a12
a13
a21
a22
a23
a31
a32
a33






, . . . , |A| .
Theorem 1.2 (Sylvester criterion for quadratic forms) Let be given the quadratic
form Q(x) = xâŠ¤Ax. Then Q(x) (i.e. the symmetric matrix A) is:
(i) Positive deï¬nite if and only if all leading principal minors of A are positive.
(ii) Negative deï¬nite if and only if all leading principal minors of A alternate in
sign, beginning with a11 < 0.
(iii) Positive semideï¬nite if and only if all principal minors of A are nonnegative
and |A| = 0.
(iv) Negative semideï¬nite if and only if all principal minors of A of odd order are
nonpositive, of even order are nonnegative, and |A| = 0.
(v) Indeï¬nite on the residual cases.
Note that if a symmetric matrix A is positive (negative) semideï¬nite and |A| Ì¸=
0, then A is positive (negative) deï¬nite, since A cannot have in this case, a zero
eigenvalue.
In many applications of real quadratic forms we are interested in determining the
sign of a quadratic form Q(x) when x âˆˆRn must belong to some subset of Rn. In
particular, an important case is when x must belong to the set of nonzero solutions
of a homogeneous linear system of the form
Bx = 0,
where B is a matrix of order (m, n), with m < n and rk(B) = m. Let us consider
the following â€œbordered matrixâ€, square of order m + n :
M =
 0
B
BâŠ¤
A

.
Theorem 1.3 Let be rk(B) = m and, without loss of generality, suppose that the ï¬rst
m columns of B are linearly independent. Then Q(x) = xâŠ¤Ax is positive deï¬nite
on the set of nonzero solutions of Bx = 0 if and only if the leading principal minors
of M, of order 2m + 1, . . . , m + n, have the sign of (âˆ’1)m:
(âˆ’1)mÎ”h > 0, âˆ€h = 2m + 1, . . . , m + n,
where Î”h is the h-th leading principal minor of M.

1.3 Basic Deï¬nitions and Properties of Optimization Problems
9
Q(x) = xâŠ¤Ax is negative deï¬nite on the same set if and only if the sign of Î”h
alternate, for h = 2m + 1, . . . , m + n, beginning with the sign of (âˆ’1)m+1.
See, e.g., Debreu [3].
Corollary 1.4 If m = 1, i.e. we have one constraint of the type bâŠ¤x = 0, with b1 Ì¸=
0, the previous conditions become:
(a) Q(x) is positive deï¬nite on the set of nonzero solutions of bâŠ¤x = 0 if and only if
Î”3 =






0
b1
b2
b1 a11 a12
b2 a21 a22






< 0, . . . , |M| > 0.
(b) Q(x) is negative deï¬nite on the same set of (a) if and only if
Î”3 =






0
b1
b2
b1 a11 a12
b2 a21 a22






> 0, Î”4 =








0
b1
b2
b3
b1 a11 a12 a13
b2 a21 a22 a23
b3 a31 a32 a33








< 0, etc.
We point out that the assumption in Theorem 1.3 stating that the ï¬rst m columns
of B give the rank of B (if necessary, renumber the variables) is essential to obtain
necessary and sufï¬cient conditions for checking the sign of a constrained quadratic
form. In absence of the said assumption, we have only sufï¬cient conditions. Consider,
e.g., Q : R3 â†’R, x = (x1, x2, x3) âˆˆR3,
Q(x) = (x1)2 + (x2)2 âˆ’(x3)2,
which is positive deï¬nite on x3 = 0 (i.e. here bâŠ¤= [0, 0, 1]). Yet we have
Î”3 =






0 0 0
0 1 0
0 0 1






= 0.
1.3
Basic Deï¬nitions and Properties of Optimization
Problems
Any non-empty set S of real numbers that is bounded above has a least upper bound
bâˆ—, i.e. bâˆ—is an upper bound for S and bâˆ—â‰¦b for every upper bound b of S; bâˆ—
is called the supremum of S and we write bâˆ—= sup(S). If bâˆ—âˆˆS, then bâˆ—is the
maximum of S and we write bâˆ—= M = max(S).
Any non-empty set S of real numbers that is bounded below has a greatest lower
bound aâˆ—, i.e. aâˆ—is a lower bound for S and aâˆ—â‰§a for every lower bound a of S;

10
1
Basic Notions and Deï¬nitions
aâˆ—is called the inï¬mum of S and we write aâˆ—= inf(S). If aâˆ—âˆˆS, then aâˆ—is the
minimum of S and we write aâˆ—= m = min(S).
If S âŠ‚R is not bounded above, we write sup(S) = +âˆand if S is not bounded
below, we write inf(S) = âˆ’âˆ. One usually deï¬nes sup(âˆ…) = âˆ’âˆand inf(âˆ…) =
+âˆ.
Obviously, with S âŠ‚Rn and f : S â†’R, we have that the inï¬mum value of f is
aâˆ—= inf
xâˆˆS f (x) = inf { f (x) : x âˆˆS} ;
the minimum value of f is
m = min
xâˆˆS f (x) = min { f (x) : x âˆˆS} ;
the supremum value of f is
bâˆ—= sup
xâˆˆS
f (x) = sup { f (x) : x âˆˆS} ;
the maximum value of f is
M = max
xâˆˆS f (x) = max { f (x) : x âˆˆS} .
In the following we will consider a minimization problem or a maximization
problem of the form
(P) :
min
xâˆˆS f (x) or max
xâˆˆS f (x),
where f : Rn â†’R is a real-valued function, called the objective function, and S âŠ‚
Rn is a subset of the domain of f, dom( f ). The case S = dom( f ) is not excluded.
The set S is called also the feasible set or feasible region or opportunity set. When S
is an open set (e.g. when S = Rn) or, more generally, when for the optimal point x0 it
holds x0 âˆˆint(S), we speak of unconstrained mathematical programming problem.
We suppose in any case that S Ì¸= âˆ….
We recall some basic deï¬nitions.
Deï¬nition 1.5 A point x0 âˆˆS is called a global minimum point or global minimizer
for problem (P) or for the function f on S (respectively: a global maximum point
or global maximizer for problem (P) or for the function f on S) if
f (x0) â‰¦f (x), âˆ€x âˆˆS
(resp. f (x0) â‰§f (x), âˆ€x âˆˆS).
We note the following facts.
â€¢ Global minimizers (global maximizers) need not exist, as one can see by consid-
ering the following examples.

1.3 Basic Deï¬nitions and Properties of Optimization Problems
11
(a) Minimize the function f (x) = 1/x2 over S = R \ {0} .
(b) Minimize the function f (x) = eâˆ’x2 over S = R.
(c) Minimize the function f (x) = x over S = {x âˆˆR : x > 0} .
â€¢ Global minimizers (global maximizers) need not be unique. One example is the
function f (x) = (x2 âˆ’1)2, with S = R, which has two global minimizers: x0 =
Â±1. A more extreme example is the function f (x) = k, k âˆˆR, for which every
point x âˆˆR is a global minimizer and a global maximizer.
The value m = y0 = f (x0), with x0 a global minimizer (the value M = y0 =
f (x0), with x0 a global maximizer) of f over S , is also said to be the global
minimum (resp. the global maximum) of f over S. The set of global minimizers
(global maximizers) is sometimes denoted by
arg min
xâˆˆS
f (x)

arg max
xâˆˆS
f (x)

.
It is easy but important to note that the minimizers of a function f on S coincide
with the maximizers of âˆ’f on S; we simply write
min
xâˆˆS f (x) = max
xâˆˆS âˆ’f (x),
whereas for the minimum value m = f (x0) and for the maximum value M =
âˆ’f (x0), we have the obvious relation
m = âˆ’M.
In order to avoid unnecessary and trivial repetitions, we shall be mainly concerned
in the sequel with minimization problems, being the results related to maximization
problems easily obtainable from the previous ones.
Deï¬nition 1.6 A point x0 âˆˆS is called a local minimizer or local minimum point
for problem (P) or for the function f on S if there exists a neighborhood N(x0) of
x0 such that x0 is a global minimizer of the problem
min
xâˆˆSâˆ©N(x0) f (x).
In other words, x0 âˆˆS is a local minimizer or a local minimum point for f on S,
if there exists Îµ > 0 such that
f (x0) â‰¦f (x),
for all x âˆˆS such that
x âˆ’x0 â‰¦Îµ.
Slightly strengthening the above deï¬nitions, we obtain the following ones.

12
1
Basic Notions and Deï¬nitions
Deï¬nition 1.7 A point x0 âˆˆS is called a strict local minimizer for problem (P) or
for the function f on S, if
f (x0) < f (x), âˆ€x Ì¸= x0, x âˆˆS âˆ©N(x0).
In other words, with respect to Deï¬nition 1.6, we replace the weak inequality â‰¦
by the strict inequality < (and in this case we consider x Ì¸= x0, x âˆˆS âˆ©N(x0)).
Deï¬nition 1.8 A point x0 âˆˆS is called a strict global minimizer for problem (P)
or for the function f on S, if
f (x0) < f (x), âˆ€x Ì¸= x0, x âˆˆS.
Remark 1.9 (a) If x0 is a global minimum point, then x0 is of course a local mini-
mum point. If x0 is a strict local (or also global) minimum point, then x0 is of course
also a local (or global) minimum point.
(b) The isolated points of S are both minimizers and maximizers, at least in the local
sense, of f : S â†’R.
(c) If there exists for (P) a strict global minimizer x0, then x0 is obviously the unique
strict global minimizer. However, note that it may exist inï¬nite global minimizers
(not in a strict sense!). For example, the function f (x) = sin x, x âˆˆR, presents
inï¬nite global minimizers at x0 = 3
2Ï€ Â± 2kÏ€ and inï¬nite global maximizers at x00 =
Ï€
2 Â± 2kÏ€. None of these points is, respectively, a strict global minimizer (a strict
global maximizer), as at all these points the value of the function is âˆ’1 (respectively:
1). On the other hand, everyone of the said points is, respectively, a strict local
minimizer (a strict local maximizer).
(d) It may also exist inï¬nite strict local minimizers (which however are not global
ones): for example, the function f (x) = x sin x,
x âˆˆR, has inï¬nite strict local
minimizers and inï¬nite strict local maximizers, which are not global ones.
Deï¬nition 1.10 A point x0 âˆˆS is called an isolated local minimizer for (P) if there
exists a neighborhood N(x0) of x0 such that x0 is the unique local minimizer for
f (x) in the said neighborhood N(x0) or in N(x0) âˆ©S.
Notethat everyisolatedlocal minimizer is astrict local minimizer, but theconverse
does not hold in general. As an example, consider the (rather pathological) function
f (x) =

2x2 + x2 sin
 1
x

if x âˆˆR, x Ì¸= 0,
0
if x = 0.
This function has a strict local minimizer at x0 = 0 (which is at the same time
the unique global minimizer of f ), but there exists a sequence of (isolated!) local
minimizers converging to zero. Thus the minimizer x0 = 0 is not isolated.
Deï¬nition 1.11 A point x0 âˆˆS is a strict local minimizer (or a minimum point) of
order p âˆˆN for (P), if there are a neighborhood N(x0) and a constant k > 0 such
that, it holds

1.3 Basic Deï¬nitions and Properties of Optimization Problems
13
f (x) â‰§f (x0) + k
x âˆ’x0p , âˆ€x âˆˆS âˆ©N(x0).
If p = 1, the point x0 is more commonly called a strong local minimizer for (P)
or also a sharp local minimizer. If p = 2 some authors speak of â€œquadratic growth
conditionâ€. We observe that if x0 is a strict local minimizer of order p, then it is also
a strict local minimizer of order r for all r > p. Moreover, it is clear that any strict
local minimizer of order p is a strict local minimizer. However, not every strict local
minimizer is a strict local minimizer of order p for some p.
For example, deï¬ne f : [0, +âˆ) â†’R as follows
f (x) = x
1
x for x > 0,
f (0) = 0
and let S = [0, +âˆ) . Then x0 = 0 is a strict local minimizer that is not a strict local
minimizer of order p for any p âˆˆN.
Existence of Minimizers
First recall that the lower limit of a sequence of real numbers {zk} is deï¬ned as
lim inf
kâ†’âˆzk = lim
kâ†’âˆinf
â„“â‰§k zâ„“.
This is equivalent to deï¬ning lim inf
kâ†’âˆzk as the smallest possible limit of convergent
subsequences of {zk}. Note that, in contrast to the usual notion of limit of a sequence,
every sequence has a lower limit (the sequence (infâ„“â‰§k zâ„“)kâˆˆN is increasing, and
therefore its limit exists).
Similarly for the deï¬nition of the upper limit of a sequence of real numbers {zk} :
lim sup
kâ†’âˆ
zk = lim
kâ†’âˆsup
â„“â‰§k
zâ„“.
It can be proved that
lim sup
kâ†’âˆ
zk â‰§lim inf
kâ†’âˆzk
and that a sequence {zk} in R converges to a limit Â¯z âˆˆR if and only if
lim sup
kâ†’âˆ
zk = lim inf
kâ†’âˆzk = Â¯z.
The above notions can be given directly with reference to a real-valued function
f : X âŠ‚Rn â†’R. If x0 âˆˆX, x0 is an accumulation point for X, we have
lim inf
xâ†’x0
f (x) =
sup
U(x0)
inf
xâˆˆU(x0)\{x0}
f (x)
lim sup
xâ†’x0
f (x) =
inf
U(x0)
sup
xâˆˆU(x0)\{x0}
f (x).

14
1
Basic Notions and Deï¬nitions
Deï¬nition 1.12 A function f : X âŠ‚Rn â†’R is said to be lower semi-continuous
on X if for every x âˆˆX and every sequence {xk} âŠ‚X converging to x we have
f (x) â‰¦lim inf
kâ†’âˆ
f (xk).
A function f : X âŠ‚Rn â†’R is said to be upper semi-continuous on X if (and
only if) âˆ’f is lower semi-continuous on X, i.e. for every x âˆˆX and every sequence
{xk} âŠ‚X converging to x we have
lim sup
kâ†’âˆ
f (xk) â‰¦f (x).
Thus, for a lower semi-continuous function, whenever we have a sequence {xk}
converging to x, the sequence of values { f (xk)} cannot have a limit smaller than
f (x). Similarly for an upper semi-continuos function.
Deï¬nition 1.12 can be restated in the following terms: f : X âŠ‚Rn â†’R is lower
semi-continuous on X if for every x0 âˆˆX (x0 accumulation point for X)
f (x0) â‰¦lim inf
xâ†’x0
f (x).
(Similarly for upper semi-continuous functions).
We point out that several authors do not take into consideration, in the above
relation, a deleted neighborhood U(x0) \

x0
, but simply a neighborhood U(x0).
Under this assumption, f : X âŠ‚Rn â†’R is lower semi-continuous on X if for every
x0 âˆˆX
f (x0) = lim inf
xâ†’x0
f (x).
A lower semi-continuous function (an upper semi-continuous function) need not
be a continuous function; indeed, it holds the vice-versa, as stated by the following
basic result.
Theorem 1.13 A function f : X âŠ‚Rn â†’R is continuous on X if and only if it is
both lower semi-continuous and upper semi-continuous on X.
Example 1.14 (a) The function f : R â†’R deï¬ned by
f (x) =
 x2
if x > 0,
x2 âˆ’1 if x < 0
is lower semi-continuous, but not continuous.
(b) The function f : R â†’R deï¬ned by
f (x) =
sin(1/x) if x Ì¸= 0,
âˆ’1
if x = 0

1.3 Basic Deï¬nitions and Properties of Optimization Problems
15
is lower semi-continuous, but not continuous.
(c) The function f : R â†’R deï¬ned by
f (x) =
â§
â¨
â©
1
if x > 0,
0
if x = 0,
âˆ’1 if x < 0
is not lower semicontinuous (nor continuous).
(d) If fi : Rnâ†’R, i âˆˆI, is any family of continuous functions, then the function
f (x) = sup
iâˆˆI
fi(x)
is lower semi-continuous (note that it is not required that the family is ï¬nite!).
Remark 1.15 An alternative equivalent deï¬nition of lower semi-continuity is the
following one.
(a) A function f : X âŠ‚Rnâ†’R is lower semi-continuous on X if (and only if) its
lower level set
levâ‰¦Î± f =

x âˆˆX : f (x) â‰¦Î±

is relatively closed in X for every Î± âˆˆR. In other words: whenever Î± âˆˆR and
xk âˆˆlevâ‰¦Î± f is a sequence that converges to some x âˆˆX, we have that x âˆˆ
levâ‰¦Î± f. Because this characterization does not rely directly on sequences but
rather on the notion of closedness, it can, in some situations, be less cumbersome
to handle.
Other equivalent characterizations of lower semi-continuity of f : X âŠ‚Rnâ†’R
are:
(b) The set
lev>Î± f = {x âˆˆX : f (x) > Î±}
is relatively open in X for every Î± âˆˆR.
(c) The epigraph of f :
epi( f ) =

(x, Î¶) : x âˆˆX, Î¶ âˆˆR, f (x) â‰¦Î¶

is relatively closed in X Ã— R.
The importance of semi-continuous functions lies in a generalization of the well-
known Weierstrass Theorem.
Deï¬nition 1.16 Assume that the set S âŠ‚Rn of problem (P) is nonempty and let
f âˆ—= inf
xâˆˆS f (x) ( f âˆ—may be âˆ’âˆ).
A minimizing sequence for (P), i.e. for the problem

16
1
Basic Notions and Deï¬nitions
min
xâˆˆS f (x),
is a sequence {xk} âŠ‚S satisfying
lim
kâ†’âˆf (xk) = f âˆ—.
That is, a minimizing sequence is a sequence such that the function values of
which converge to the minimal (inï¬mal) value of f. A minimizing sequence always
exists. Note that this does not say anything about the convergence of the sequence

xk
itself. For example, the sequence
xk = (2k + 1)Ï€ + 1/k
is a minimizing sequence for the function f (x) = cos x.
Theorem 1.17 (Generalized Weierstrass Theorem) Assume that
S âŠ‚Rn
is
nonempty, closed and bounded (i.e. compact) and let be f : S â†’R.
(a) If f is lower semi-continuous on S, it admits at least one global minimizer
xâˆ—âˆˆS.
(b) If f is upper semi-continuous on S, it admits at least one global maximizer
xâˆ—âˆ—âˆˆS.
Proof We prove only part (a). Since f is upper semi-continuous if and only if âˆ’f is
lower semi-continuous. Let {xk} âŠ‚S be a minimizing sequence for the optimization
problem (P). Because S is closed and bounded, it follows that the sequence {xk}
admits a sub-sequence, say {Â¯xk} âŠ‚S, converging to some point xâˆ—âˆˆS (Heine-Borel
Theorem). Thus the deï¬nitions of xk, Â¯xk, and xâˆ—, and the lower semi-continuity of
f imply that
inf
xâˆˆS f (x) = f âˆ—= lim
kâ†’âˆf (xk) = lim
kâ†’âˆf (Â¯xk) = lim inf
kâ†’âˆ
f (Â¯xk) â‰§f (xâˆ—),
which shows that f (xâˆ—) â‰¦f (x) for every x âˆˆS. In other words, xâˆ—is a global
minimizer of f on S.
â–¡
Corollary 1.18 (Weierstrass Theorem) Assume that S âŠ‚Rn is closed and bounded
and that f : S â†’R is continuous on S. Then, there exists xâˆ—âˆˆS such that f (xâˆ—) â‰¦
f (x), âˆ€x âˆˆS, and there exists xâˆ—âˆ—âˆˆS such that f (xâˆ—âˆ—) â‰§f (x), âˆ€x âˆˆS.
In order to obtain an existence result that is also applicable to an optimization
problem where the feasible set S âŠ‚Rn is not bounded, we have to introduce another
deï¬nition.

1.3 Basic Deï¬nitions and Properties of Optimization Problems
17
Deï¬nition 1.19 A function f : X âŠ‚Rn â†’R is called coercive, if every sequence
{xk} âŠ‚X, with
xk â†’âˆ, satisï¬es f (xk) â†’âˆ.
Theorem 1.20 Assume that in problem (P) the feasible set S âŠ‚Rn is nonempty and
closed, and that f : S â†’R is lower semi-continuous and coercive. Then problem
(P) admits at least one global minimizer xâˆ—.
Proof Let {xk} âŠ‚S be a minimizing sequence of the optimization problem. Then the
sequence{ f (xk)}doesnotdivergetoâˆ,andthereforethecoercivityof f impliesthat
the sequence {xk} is bounded. Thus it admits a sub-sequence {Â¯xk} âŠ‚S converging
to some point xâˆ—âˆˆRn. Because S is closed, it follows that, actually xâˆ—âˆˆS. Thus
we have (as above) that
inf
xâˆˆS f (x) = f âˆ—= lim
kâ†’âˆf (xk) = lim
kâ†’âˆf (Â¯xk) = lim inf
kâ†’âˆ
f (Â¯xk) â‰§f (xâˆ—),
which shows that xâˆ—is a global minimizer of f on S.
â–¡
In the sequel we shall be mainly concerned with the following mathematical
programming problems (or optimization problems): (P1), (P2), (P3), (P4) and (P5).
(1) Unconstrained minimization problems
(P1) :
min f (x), subject to x âˆˆS âŠ‚Rn,
where f : Rn â†’R and S is an open set or, more generally, where for the optimal
point x0 it holds x0 âˆˆint(S). In other words, we are looking for those optimal
points x0 of f (x) which are interior to S. We note that in this case the deï¬nition
of local minimizer for (P1) can be rewritten in the form
f (x0) â‰¦f (x), âˆ€x âˆˆU(x0),
being obviously always possible to choose U(x0) such that U(x0) âŠ‚S.
(2) Constrained minimization problems with a set constraint (or abstract
constraint)
(P2) :
min f (x), subject to x âˆˆS âŠ‚Rn,
where f : Rn â†’R and S is not necessarily open or not necessarily the optimal
point x0 is interior to S. We recall that the function f is called the objective
function and the set S âŠ‚Rn is called the feasible set or constraint set. We shall
assume S Ì¸= âˆ…; however, many authors adopt the convention that if S = âˆ…, then
minxâˆˆS f (x) = infxâˆˆS f (x) = +âˆ.

18
1
Basic Notions and Deï¬nitions
(3) â€œClassicalâ€ constrained minimization problems, i.e. minimization problems
with only equality constraints
(P3) :
â§
â¨
â©
min f (x)
subject to: h j(x) = 0, j = 1, . . . , p,
x âˆˆX âŠ‚Rn,
where X âŠ‚Rn is an open set contained in the domains of the functions involved
in (P3), f and each h j, j = 1, . . . , p < n, are real-valued function deï¬ned on
Rn. The set
K3 =

x âˆˆX : h j(x) = 0, j = 1, . . . , p < n

is the feasible set for (P3) and f is the objective function. The restriction p < n
is made in order to avoid that the feasible set shrinks to only isolated points or
to the empty set.
This type of constrained minimization problem is called â€œclassicalâ€, as its anal-
ysis and related solution go back to the work of J. L. Lagrange (1736â€“1813). For
some related historical questions see, e.g., the book of Giorgi and Kjeldsen [4].
(4) Constrained minimization problems with only inequality constraints
(P4) :
â§
â¨
â©
min f (x)
subject to: gi(x) â‰¦0, i = 1, . . . , m,
x âˆˆX âŠ‚Rn,
where X âŠ‚Rn is an open set contained in the domains of the functions involved
in (P4), f and each gi, i = 1, . . . , m, are real-valued function deï¬ned on Rn.
The set
K4 =

x âˆˆX : gi(x) â‰¦0, i = 1, . . . , m

is the feasible set for (P4) and f is the objective function. In contraposition
with (P3), (P4) is a type of â€œmodernâ€ constrained minimization problem or
nonlinear programming problem, as these problems have been systematically
analyzed starting from the second half of the 20th century.
We note that our formulation is sufï¬ciently general for our purposes: for exam-
ple, a maximization problem can be transformed (as already remarked) into a
minimization problem:
max f (x) = min(âˆ’f (x)).
If we have a constraint of the type gi(x) â‰§0, we can equivalently write
âˆ’gi(x) â‰¦0, and if we have a constraint of the type Ï†i(x) â‰¦bi, we can equiva-
lently write gi(x) â‰¦0, where gi(x) â‰¡Ï†i(x) âˆ’bi. Also the nonnegativity con-
straint on vector x could be transformed into: âˆ’x1 â‰¦0, . . . , âˆ’xn â‰¦0, even if
this procedure is not too useful.

1.3 Basic Deï¬nitions and Properties of Optimization Problems
19
(5) Constrained minimization problems with mixed constraints or general non-
linear programming problems
(P5) :
â§
âªâªâ¨
âªâªâ©
min f (x)
subject to: gi(x) â‰¦0, i = 1, . . . , m,
h j(x) = 0, j = 1, . . . , p < n,
x âˆˆX âŠ‚Rn,
where X âŠ‚Rn is an open set contained in the domains of the functions involved
in (P5), f , gi, i âˆˆM = {1, . . . , m} and h j, j âˆˆP = {1, . . . , p < n} are real-
valued functions deï¬ned on Rn. In this case the feasible set is given by
K5 =

x âˆˆX : gi(x) â‰¦0, âˆ€i âˆˆM; h j(x) = 0, âˆ€j âˆˆP

,
and f is the objective function for (P5).
If in the above problems the objective function and the constraints are at least dif-
ferentiable, we speak of differentiable or smooth mathematical programming prob-
lems, otherwise of nonsmooth mathematical programming problems. If the objective
function and the inequality constraints are convex functions, the equality constraints
are afï¬ne functions and X âŠ‚Rn is a convex set, then we speak of convex program-
ming problems (see Chap. 8). We shall be concerned also with some important
particular cases of the above problems:
(A) The Linear Programming Problem, usually written, for a minimization problem,
in the form
â§
â¨
â©
min câŠ¤x
Ax â‰§b
x â‰§0,
where c, x âˆˆRn, A is a (real) matrix of order (m, n) and b âˆˆRm. Here the
inequality signs are meant to denote componenwise inequality. The constraint
x â‰§0 is usually called â€œnonnegativity constraintâ€. If the problem is a maximiza-
tion one, it is usually written as
â§
â¨
â©
max câŠ¤x
Ax â‰¦b
x â‰§0.
(B) The Quadratic Programming Problem, under linear constraints, usually written,
for a minimization problem, in the form

min 1
2 xâŠ¤Qx + pâŠ¤x
subject to: Ax â‰§b, x â‰§0,

20
1
Basic Notions and Deï¬nitions
where Q is a symmetric matrix of order n, p âˆˆRn, x âˆˆRn, A is a (real) matrix
of order (m, n) and b âˆˆRm.
Problems (A) and (B) are quite important, above all for economic applications.
There are also other special and important types of mathematical programming
problems we however shall not treat in the present book, e.g.:
â€¢ The fractional programming problem, usually written, for a minimization problem,
in the form

min a(x)
b(x)
subject to : gi(x) â‰¦0, i = 1, . . . , m,
where a(x), b(x) and every gi(x) are real-valued functions on Rn and b(x) > 0,
âˆ€x âˆˆdom(b).
Also this type of mathematical programming problem has several interesting appli-
cations.
â€¢ The semi-inï¬nite programming problem, usually written, for a minimization prob-
lem, in the form

min f (x)
subject to : gÎ±(x) â‰¦0, Î± âˆˆI,
where f (x) and gÎ±(x) are real-valued functions deï¬ned on Rn and I is an arbitrary
index set. Also this type of mathematical programming problems has received a
growing attention owing to its interesting applications.
Finally, we give here some hints on vector optimization problems, in ï¬nite dimen-
sions, called also multiobjective optimization problems. For example
(V min) :

V min f (x) =

f1(x), f2(x), . . . , fq(x)
	âŠ¤
subject to: x âˆˆS âŠ‚Rn.
In multiobjective optimization problems the objectives often conï¬‚ict with each
other and consequently the concepts of optimality seen for the scalar case are not
directly suitable for the vector case, even if there are techniques of scalarization,
in order to transform a vector problem into a scalar problem. These techniques,
however, work under suitable assumptions.
Of course, if there exists a feasible point x0 âˆˆS which minimizes all the com-
ponents of the vector objective function simultaneously, it provides a solution to the
problem. Such a point is usually called an utopia solution or utopia point, but this kind
of solution seldom exists and we are obliged to introduce other solution concepts.
These new concepts of optimality for the vector case were introduced, within Eco-
nomic Analysis, by the English economist Francis Ysidro Edgeworth (1845â€“1926)
in 1881 and by the Italian economist and sociologist Vilfredo Pareto (1848â€“1923) in
1896.

1.3 Basic Deï¬nitions and Properties of Optimization Problems
21
First, we remark that if we have a scalar function f : Rn â†’R, the deï¬nition of
(global) minimum point x0 for f over S âŠ‚Rn is, as previously seen,
f (x0) â‰¦f (x), âˆ€x âˆˆS.
This is equivalent to require that there exists no x âˆˆS such that
f (x0) > f (x).
If we wish to extend the concept of optimal point to problem (V min), the said
equivalence is no longer valid, but this second way is the right way to introduce the
concepts of optimal points for the vector case. More precisely, we have the following
formal deï¬nitions.
Deï¬nition 1.21 A feasible point x0 âˆˆS is said to be an efï¬cient solution (or Pareto
optimal solution) for (V min) if there exists no x âˆˆS such that
fi(x) â‰¦fi(x0), i = 1, . . . , q,
with at least one strict inequality.
If we denote by Rq
+ the nonnegative orthant of Rq, i.e. all vectors of Rq with
nonnegative elements, and by Rq
âˆ’the nonpositive orthant of Rq, i.e. all vectors of
Rq with nonpositive elements, the previous deï¬nition can be rewritten as
f (x) âˆ’f (x0) /âˆˆRq
âˆ’\ {0} .
Deï¬nition 1.22 A feasible point x0 âˆˆS is said to be a weak efï¬cient solution (or a
weakly efï¬cient solution) for (V min) if there exists no x âˆˆS such that
fi(x) < fi(x0), i = 1, . . . , q,
i. e., with S f =

x âˆˆRn : fi(x) < fi(x0), i = 1, . . . , q

,
S f âˆ©S = âˆ…,
i. e.
f (x) âˆ’f (x0) /âˆˆint(Rq
âˆ’), âˆ€x âˆˆS.
If the previous deï¬nitions are veriï¬ed in N(x0) âˆ©S, where N(x0) is a suitable
neighbourhood of x0, then x0 is said, respectively, a local efï¬cient solution and a local
weak efï¬cient solution. Note that in the scalar case (q = 1), the above deï¬nitions
collapse to the ordinary deï¬nitions of a global (or local) minimum point. Note,
moreover, that (local) efï¬ciency implies (local) weak efï¬ciency.
Of course other ordering cones, not necessarily coincident with Rq
âˆ’or Rq
+, can
be considered. For example, if K is a convex cone in Rq, containing the origin and

22
1
Basic Notions and Deï¬nitions
pointed (i.e. (x âˆˆK, x Ì¸= 0) â‡’âˆ’x /âˆˆK), then x0 âˆˆS is said to be a K-efï¬cient
point or K-minimal point for f : S âŠ‚Rn â†’Rq if there exists no x âˆˆS such that
f (x0) âˆˆf (x) + K \ {0} ,
a weak K-minimal point, if there exists no x âˆˆS such that
f (x0) âˆˆf (x) + int(K).
It can be proved that the order relation â€œinducedâ€ by the cone K veriï¬es the
reï¬‚exive, antisymmetric and transitive properties. For the deï¬nition of cone and
convex cone, see Chap. 2. These subjects will be developed in Chap. 11.
We point out that in the present book we do not intend to discuss the important
subjects concerning the various algorithms or numerical methods available to solve
or to get an approximate solution of the various mathematical programming problems
described above. We intend to express the basic optimality conditions referred to the
said problems, conditions which are, beyond their intrinsic interest, a fundamental
tool for developing the related numerical algorithms.
References
1. H.W. Kuhn, A.W. Tucker, Nonlinear programming, in Proceedings of the Second Berkeley Sym-
posium on Mathematical Statistics and Probability, ed. by J. Neyman (University of California
Press, Berkeley, 1951), pp. 481â€“492. Reprinted in Giorgi and Kjeldsen (2014)
2. H. Halkin, Implicit functions and optimization without continuous differentiability. SIAM J.
Control Optim. 12, 229â€“236 (1974)
3. G. Debreu, Deï¬nite and semideï¬nite quadratic forms. Econometrica 20, 285â€“300 (1952)
4. G. Giorgi, T.H. Kjeldsen, Traces and Emergence of Nonlinear Programming (BirkhÃ¤user, Basel
and New York, 2014)

Chapter 2
Elements of Convex Analysis. Linear
Theorems of the Alternative. Tangent
Cones
2.1
Elements of Convex Analysis
Mathematical programming theory is strictly connected with Convex Analysis. We
giveinthepresentsectionthemainconceptsanddeï¬nitionsregardingconvexsetsand
convex cones. Convex functions and generalized convex functions will be discussed
in the next chapter.
Geometrically, a set S âŠ‚Rn is convex if the line segment joining any two points
in the set lies entirely in the set. We recall that the (closed) line segment joining the
points x1 and x2 of S, denoted as

x1, x2
, is given by

x1, x2
=

Î»x1 + (1 âˆ’Î»)x2 : 0 â‰¦Î» â‰¦1

=

x1 + Î»(x2 âˆ’x1) : 0 â‰¦Î» â‰¦1

.
The open line segment is denoted as (x1, x2) and is given by
(x1, x2) =

Î»x1 + (1 âˆ’Î»)x2 : 0 < Î» < 1

.
We have the following basic deï¬nitions.
Deï¬nition 2.1 A nonempty set S âŠ‚Rn is convex if for any two points x1, x2 âˆˆS,
we have

x1, x2
âŠ‚S. A set S âŠ‚Rn is strictly convex if
Î»x1 + (1 âˆ’Î»)x2 âˆˆint(S), for all x1, x2 âˆˆS, x1 Ì¸= x2, for all Î» âˆˆ(0, 1).
Note that, unlike a convex set, the boundary of a strictly convex set cannot contain
any segment. The empty set âˆ…is considered to be convex; any singleton (i.e. a set
containing just one single point) is convex.
We recall now some basic deï¬nitions concerning various types of combinations
of vectors of Rn.
Â© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al., Basic Mathematical Programming Theory, International Series
in Operations Research & Management Science 344,
https://doi.org/10.1007/978-3-031-30324-1_2
23

24
2
Elements of Convex Analysis. Linear Theorems of the Alternative. Tangent Cones
Let x1, x2, . . . , xk be vectors of Rn. A linear combination of the vectors x1,
x2, . . . , xk is any expression of the form
k

i=1
Î±ixi
(2.1)
where each Î±i âˆˆR.
When k
i=1 Î±i = 1, the linear combination (2.1) is called afï¬ne combination of
the vectors x1, x2, . . . , xk.
When it holds that each Î±i â‰§0, the linear combination (2.1) is called convex conic
combination or nonnegative combination of the vectors x1, x2, . . . , xk.
When in (2.1) it holds that each Î±i â‰§0 and k
i=1 Î±i = 1, the expression (2.1) is
called a convex combination of the vectors x1, x2, . . . , xk.
Deï¬nition 2.2 A set K âŠ‚Rn is a cone with vertex at the origin if
x âˆˆK â‡’Î»x âˆˆK, âˆ€Î» > 0.
Many authors, however, do include the vertex in the cone by letting Î» â‰§0 in the
above deï¬nition. It may be useful to accept both deï¬nitions, in order to have more
ï¬‚exibility in the various cases and problems encountered in treating this topic. A
cone K âŠ‚Rn which is also convex is calledâ€¦a convex cone! It is easy to prove that
a cone K âŠ‚Rn is convex if and only if
x, y âˆˆK â‡’x + y âˆˆK.
Indeed, if K is convex, we have x + y = 2
 1
2 x + 1
2 y
	
where 1
2 x + 1
2 y âˆˆK, being
K convex and 2
 1
2 x + 1
2 y
	
âˆˆK, being K a cone. Conversely, if x, y âˆˆK, then we
haveÎ»x, (1 âˆ’Î»)y âˆˆK,âˆ€Î» âˆˆ[0, 1]since K isacone,andthereforeÎ»x + (1 âˆ’Î»)y âˆˆ
K, i.e. K is a convex set.
Note that the deï¬nition of cone in Rn is an abstract and multi-dimensional gen-
eralization of the well-known ice-cream cone. A cone K âŠ‚Rn may be open, closed
or neither open nor closed. Examples of cones are:
K1 =

(x, y) âˆˆR2 : x â‰§0, y â‰§0

;
K2 =

(x, y) âˆˆR2 : 0 â‰¦y < x

;
K3 =

(x, y) âˆˆR2 : x â‰§0, y = x

;
K4 =

(x, y) âˆˆR2 : x = 0

âˆª

(x, y) âˆˆR2 : y = 0

;
K5 =

x âˆˆRn : Ax = 0

, with A matrix of order (m, n).
Note that K1, K2, K3 and K5 are convex cones.
If K1 and K2 are convex cones, also K1 âˆ©K2 and K1 + K2 are convex cones.
Every linear subspace of Rn is a closed convex cone.

2.1 Elements of Convex Analysis
25
Now, let S be a nonempty subset of Rn.
â€¢ The collection of all linear combinations of vectors of S is said to be the linear
space generated by S or linear span of S or also linear hull of S and denoted by
lin(S) or span(S);
lin(S) =

 k

i=1
Î±ixi : each xi âˆˆS, each Î±i âˆˆR, k âˆˆN

.
It can be proved that lin(S) is the smallest linear space of Rn containing S.
â€¢ The collection of all afï¬ne combinations of vectors of S is called afï¬ne hull of S
and denoted by aff(S):
aff(S) =

 k

i=1
Î±ixi : each xi âˆˆS, each Î±i âˆˆR,
k

i=1
Î±i = 1, k âˆˆN

.
It can be proved that aff(S) is the smallest afï¬ne subspace of Rn containing S. If
aff(S) = Î± + L, where L is a linear subspace of Rn, then the dimension of the
afï¬ne hull of S is given by the dimension of L. The dimension of S is given by
the dimension of its afï¬ne hull.
â€¢ The collection of all convex conic combinations of vectors of S is called the convex
conic hull of S or convex cone generated by S or convex cone spanned by S and
denoted by cone(S):
cone(S) =

 k

i=1
Î±ixi : each xi âˆˆS, each Î±i â‰§0, k âˆˆN

.
Some authors (e.g. Bazaraa and Shetty [1]) require that the coefï¬cients Î±i, i =
1, . . . , k, are not all zero, i.e. k
i=1 Î±i > 0. It can be proved that cone(S) is the
smallest convex cone of Rn containing S (equivalently: it is the intersection of all
convex cones in Rn containing S).
â€¢ The collection of all convex combinations of vectors of S is called the convex hull
of S and denoted by conv(S) or co(S):
conv(S) =

 k

i=1
Î±ixi : each xi âˆˆS, each Î±i â‰§0,
k

i=1
Î±i = 1, k âˆˆN

.
It can be proved that conv(S) is the smallest convex set of Rn containing S;
equivalently: conv(S) is the intersection of all convex sets in Rn containing S (see
the next Theorem 2.4).
We note that if S is a nonempty subset of Rn, we have

26
2
Elements of Convex Analysis. Linear Theorems of the Alternative. Tangent Cones
S âŠ‚conv(S) âŠ‚aff(S) âŠ‚lin(S);
S âŠ‚conv(S) âŠ‚cone(S) âŠ‚lin(S).
Moreover:
(a) S âŠ‚Rn is a linear subspace of Rn if and only if S = lin(S).
(b) S âŠ‚Rn is an afï¬ne set of Rn if and only if S = aff(S).
(c) S âŠ‚Rn is a convex set of Rn if and only if S = conv(S).
(d) S âŠ‚Rn is a convex cone with vertex at 0 âˆˆS if and only if S = cone(S).
Let us prove (c). The proofs of the other properties are similar and left to the
reader.
Theorem 2.3 A nonempty set S âŠ‚Rn is convex if and only if every convex combi-
nation of elements of S lies in S.
Proof The sufï¬ciency of the condition is obvious from the deï¬nition. We prove
the necessity by induction on the number of elements of S occurring in the convex
combination. When k = 2, the condition follows from the deï¬nition. Assuming that
every convex combination of k or fewer points of S yields a point of S, we consider
a combination of k + 1 points. Let x = k+1
i=1 Î»ixi, where Î»i â‰§0 and k+1
i=1 Î»i = 1,
and xi âˆˆS for all i. If Î»k+1 = 1, then x = xk+1, which belongs to S and there is
nothing further to prove. Suppose that Î»k+1 < 1. In this case k
i=1 Î»i = 1 âˆ’Î»k+1 >
0 and we have
x =
 k

i=1
Î»i
  k

i=1
Î»ixi/
k

i=1
Î»i

+ Î»k+1xk+1.
By the induction hypothesis, the point
y =
 k

i=1
Î»ixi/
k

i=1
Î»i

belongs to S. Thus, x = (1 âˆ’Î»k+1)y + Î»k+1xk+1 is a convex combination of two
points in S and so x âˆˆS.
â–¡
It is important to note that the intersection of any collection of convex sets is a
convex set, while the union of two (or more) convex sets is not convex in general.
The complement of a convex set need not be convex, For any two convex sets X and
Y of Rn, their sum X + Y is convex.
For any Î± âˆˆR and a convex set S âŠ‚Rn, the set Î±S is convex.
Now we prove that conv(S) is given by the intersection of all convex sets which
contain S.

2.1 Elements of Convex Analysis
27
Theorem 2.4 For any set S âŠ‚Rn we have that
conv(S) =
â§
â¨
â©x âˆˆRn : x =
m

i=1
Î»i xi, each xi âˆˆS, each Î»i â‰§0,
m

i=1
Î»i = 1, m âˆˆN
â«
â¬
â­
is equal to the set T âŠ‚Rn given by the intersection of all convex sets wich
contain S.
Proof Let x = m
i=1 Î»ixi, with

x1, . . . , xm
âŠ‚S, {Î»1, . . . , Î»m} âŠ‚R+ and m
i=1
Î»i = 1. By Theorem 2.3 the point x obviously belongs to any convex set containing
S and therefore also the set T, i.e. conv(S) âŠ‚T. Conversely let x = r
i=1 Î±ixi
and y = s
i=1 Î²i yi, where Î±i â‰§0, r
i=1 Î±i = 1, and Î²i â‰§0, s
i=1 Î²i = 1 be two
elements of conv(S). Then, for any Î», 0 â‰¦Î» â‰¦1,
z â‰¡Î»x + (1 âˆ’Î»)y = Î»
r

i=1
Î±ixi + (1 âˆ’Î»)
s

i=1
Î²i yi
is an element of conv(S), since each coefï¬cient belongs to the interval [0, 1] and
Î»
r

i=1
Î±i + (1 âˆ’Î»)
s

i=1
Î²i = Î» + 1 âˆ’Î» = 1.
Then conv(S) is a convex set containing S and so T âŠ‚conv(S). Therefore
conv(S) = T .
â–¡
A sharper result in Rn is the following Theorem of Carathedory:
Theorem 2.5 (Caratheodory) The convex hull of S âŠ‚Rn is precisely the set of all
convex combinations of at most (n + 1) elements of S.
The notation â€œcone(S)â€ is widely used, however some authors use other notations:
for example Jeter [2] uses the notation coni(S), whereas Dhara and Dutta [3]) use
the notation cone(co(S)) to denote the convex cone generated by S. We remark that
cone(S) need not be a closed set, even if S âŠ‚Rn is compact. However, it can be
proved that cone(S) is closed in special cases, such as when S is ï¬nite. We speak
in this case of ï¬nite cone or ï¬nitely generated cone, i.e. the closed convex cone
generated by a ï¬nite set C =

a1, a2, . . . , am
of vectors of Rn :
cone(C) =

x âˆˆRn : x =
m

i=1
Î±iai, Î±i â‰§0, i = 1, . . . , m

.
The vectors a1, a2, . . . , am of Rn are said to be the generators of cone(C). The
proof that a ï¬nitely generated cone is closed is basic in proving the well-known
Farkas Theorem (or Farkas Lemma); see the next section of the present chapter.

28
2
Elements of Convex Analysis. Linear Theorems of the Alternative. Tangent Cones
Another important convex cone is the following one:
K =

x âˆˆRn : Bx â‰¦0

,
where B is a matrix of order (m, n). This cone is called a polyhedral (convex) cone.
The Minkowski-Weyl Theorem states that a cone is polyhedral if and only if it is
ï¬nitely generated. See, e.g., Bertsekas [4], Bertsekas et al. [5], Florenzano and Le
Van [6], Hiriart-Urruty and LemarÃ©chal [7], Rockafellar [8]).
In the literature it is often introduced the conic hull of S âŠ‚Rn or radial hull of
S, as the smallest cone (not necessarily convex!) which contains S. Unfortunately
this cone is almost always denote by cone(S), which can generate some confusions
and misunderstandings. As this cone is given by the union of all rays starting form
the origin and passing through the elements x âˆˆS, we propose the notation ray(S) :
ray(S) =

y : y = Î»x, x âˆˆS, Î» â‰§0

.
Some authors require Î» > 0 and some authors use the notation R+(S). The basic
relation between cone(S) and ray(S) is given by the following result.
Theorem 2.6 If S âŠ‚Rn is a nonempty convex set, then
cone(S) = ray(S).
Proof As ray(S) is a cone, it is sufï¬cient to show that ray(S) is convex; then the
result is at hand by the deï¬nitions of ray(S) and cone(S). Let x1, x2 âˆˆray(S); then
there exist two points y1, y2 âˆˆS and numbers Î»1, Î»2 âˆˆR+ such that
x1 = Î»1y1, x2 = Î»2y2.
For any Î¼1, Î¼2 â‰§0, Î¼1 + Î¼2 = 1, we put
x = Î¼1x1 + Î¼2x2 = Î¼1Î»1y1 + Î¼2Î»2y2
(2.2)
and consider two cases.
(1) Î¼1Î»1 + Î¼2Î»2 > 0.
We put
Î¾1 =
Î¼1Î»1
Î¼1Î»1 + Î¼2Î»2
; Î¾2 = 1 âˆ’
Î¼1Î»1
Î¼1Î»1 + Î¼2Î»2
and note that Î¾1 â‰§0, Î¾2 â‰§0, Î¾1 + Î¾2 = 1. It follows from (2.2) and convexity
of S :
x = (Î¼1Î»1 + Î¼2Î»2) (Î¾1y1 + Î¾2y2) âˆˆray(S).
(2) Î¼1Î»1 + Î¼2Î»2 = 0.
It follows Î¼1Î»1 = Î¼2Î»2 = 0 and hence x = 0 âˆˆray(S).
â–¡

2.1 Elements of Convex Analysis
29
Moreover, it holds, with S âŠ‚Rn : cone(S) = ray(conv(S)) = conv(ray(S)).
It is sometimes also useful to consider cones and convex cones generated by a set
S âŠ‚Rn, with reference to a point x0 âˆˆS. Let x0 âˆˆS, with S a nonempty subset of
Rn. Then ray(S, x0) is the smallest cone which contains S âˆ’x0 and cone(S, x0) is
the smallest convex cone which contains S âˆ’x0, i.e., with x0 âˆˆS,
ray(S, x0) = ray(S âˆ’x0) =

y : y = Î»(x âˆ’x0), x âˆˆS, Î» â‰§0

;
cone(S, x0) = cone(S âˆ’x0).
These cones are also called, respectively, the cone generated by S at x0 (or from
x0) and the convex cone generated by S at x0 (or from x0). The cone ray(S, x0) is
called by Palata [9] the projection cone of S at x0. This cone may be viewed as a
(very) rough approximation of the set S in a neighborhood of x0 âˆˆS. In the next
section we shall consider other more â€œreï¬nedâ€ local cone approximations of the set
S at x0 âˆˆS.
We now recall some topological properties related to convex sets.
Theorem 2.7 (i) If S âŠ‚Rn is a convex set, then int(S) is convex.
(ii) If S âŠ‚Rn is a convex set, then cl(S) is convex.
Proof (i) For two points x1, x2 âˆˆint(S), consider two neighborhoods UÎµ1(x1) and
UÎµ2(x2) that belong entirely to S. Let Î» âˆˆ[0, 1] ; being S convex we have
Î»UÎµ1(x1) + (1 âˆ’Î»)UÎµ2(x2) âŠ‚S.
Obviously the relation appearing in the left-hand side of the last relation can be
rewritten in the form
Î»

x1 + UÎµ1(0)
	
+ (1 âˆ’Î»)(x2 + UÎµ2(0)) =
= (Î»x1 + (1 âˆ’Î»)x2) + (Î»UÎµ1(0) + (1 âˆ’Î»)UÎµ2(0)).
So, we have found a neighborhood of Î»x1 + (1 âˆ’Î»)x2 which lies in S, i.e. this
point belongs to the interior of S. The set int(S) is therefore convex.
(ii) The convexity of the closure of S follows at once from its deï¬nition:
cl(S) = âˆ©
Îµ>0(S + UÎµ(0)),
being the neighborhood UÎµ(0) a convex set.
â–¡
Theorem 2.8 If S âŠ‚Rn is an open set, then conv(S) is open.
Proof Since S is open, S âˆ©âˆ‚(conv(S)) = âˆ…. But S âŠ‚conv(S), so we must have
S âŠ‚int(conv(S)). Furthermore, the previous theorem implies that int(conv(S)) is

30
2
Elements of Convex Analysis. Linear Theorems of the Alternative. Tangent Cones
convex, so conv(S) âŠ‚int(conv(S)). On the other hand, int(conv(S)) âŠ‚conv(S), so
conv(S) = int(conv(S)) and hence conv(S) is open.
â–¡
Note that the convex hull of a closed set need not be closed. However, contrary
to what happens for cone(S), we have the following result.
Theorem 2.9 If S âŠ‚Rn is a compact set, then conv(S) is compact.
Deï¬nition 2.10 The dimension of a convex set S âŠ‚Rn, denoted dim(S), is the
dimension of the afï¬ne hull of S.
Deï¬nition 2.11 The convex hull of a ï¬nite set of points is called a polytope; if
S =

x1, . . . , xk+1
and dim(S) = k, then conv(S) is called k-dimensional simplex
and the points x1, . . . , xk+1 are called vertices of the simplex.
From Theorem 2.9 we have that a polytope is closed, bounded and convex. A
zero-dimensional simplex is a point, a one-dimensional simplex is a line segment
and a two-dimensional simplex is a triangle.
We point out that we can have convex sets in Rn with empty interior (we recall
that the empty set âˆ…is convex by deï¬nition). For example, consider a line segment
in R2 or a circular disk in R3. It is therefore useful to introduce the notion of relative
interior of a convex set.
Deï¬nition 2.12 Let be given a set S âŠ‚Rn. The set
relint(S) = {x âˆˆS : âˆƒU(x) such that U(x) âˆ©aff(S) âŠ‚S}
is the relative interior of S. A point x0 âˆˆrelint(S) is called a relative interior point
of S.
A set S âŠ‚Rn is said to be relatively open if relint(S) = S. We note that if S âŠ‚Rn
has maximal dimension, i.e. if aff(S) = Rn, then the sets int(S) and relint(S) coin-
cide. If S is a singleton, then relint(S) = S. The notion of relative interior is partic-
ularly important when referred to convex sets. Furthermore, we have the following
result.
Theorem 2.13 Let S âŠ‚Rn be a nonempty convex set; then relint(S) Ì¸= âˆ….
Proof Consider a nonempty convex set S âŠ‚Rn. Without loss of generality assume
that 0 âˆˆS. Then aff(S) is a subspace containing S. Let us assume that aff(S) is a
subspace of dimension m. If m = 0, then S and aff(S) contain only one point and the
result holds. Hence we now consider m > 0. We can always ï¬nd linearly independent
vectors a1, . . . , am in S such that aff(S) = span{a1, . . . , am}. Indeed, if this would
not be possible, then one would always be able to ï¬nd linearly independent vectors
b1, . . . , br, r < m, such that S âŠ‚span{b1, . . . , br}. This however contradicts the
fact that aff(S) has dimension m. Now observe that the set conv{0, a1, . . . , am} âŠ‚S
has a nonempty interior relative to aff(S). Thus we have that relint(S) Ì¸= âˆ….
â–¡

2.1 Elements of Convex Analysis
31
The following result is known as line segment principle and gives further infor-
mation on the closure and relative interior of a convex set.
Theorem 2.14 Let S âŠ‚Rn be a nonempty convex set. Consider x âˆˆrelint(S) and
y âˆˆcl(S). Then any point of the form Î»y + (1 âˆ’Î»)x âˆˆrelint(S) for 0 â‰¦Î» < 1.
Proof For simplicity let us consider S to be a full dimensional set, i.e. aff(S) = Rn.
Hence relint(S) = int(S); we have to show that for any given Î» âˆˆ[0, 1) there exists
Îµ > 0 such that
Î»y + (1 âˆ’Î»)x + ÎµU(0) âŠ‚S.
Since y âˆˆcl(S), it is easy to see that for any Îµ > 0 there exists x âˆˆS such that
y âˆˆx + U(0). Thus y âˆˆS + ÎµU(0) for any Îµ > 0. Therefore we have
(1 âˆ’Î»)x + Î»y + ÎµU(0) âŠ‚(1 âˆ’Î»)x + Î»(S + ÎµU(0)) + ÎµU(0).
This can be re-arranged to show that
(1 âˆ’Î»)x + Î»y + ÎµU(0) âŠ‚(1 âˆ’Î»)

x + Îµ(1 + Î»)
(1 âˆ’Î») U(0)

+ Î»S.
Since x âˆˆint(S), we have for sufï¬ciently small Îµ > 0,

x + Îµ(1 + Î»)
(1 âˆ’Î») U(0)

âŠ‚S.
Thus we have
(1 âˆ’Î»)x + Î»y + ÎµU(0) âŠ‚(1 âˆ’Î»)S + Î»S âŠ‚S.
This proves the result.
â–¡
Moreover, we have that, if S âŠ‚Rn is a nonempty convex set, it holds:
(a) cl(relint(S)) = cl(S);
(b) relint(cl(S)) = relint(S).
We will now discuss separation theorems between convex sets, which play a
central role in mathematical programming. We recall that a hyperplane in Rn is a set
of the form
H =

x âˆˆRn : aâŠ¤x = Î±

,
where a âˆˆRn is a nonzero vector and Î± âˆˆR. The vector a is called the normal to
the hyperplane. The related (closed) half-spaces determined by the hyperplane H
are given by
H âˆ’=

x âˆˆRn : aâŠ¤x â‰¦Î±

;

32
2
Elements of Convex Analysis. Linear Theorems of the Alternative. Tangent Cones
H + =

x âˆˆRn : aâŠ¤x â‰§Î±

.
We accept the following deï¬nitions.
Deï¬nition 2.15 Two nonempty sets S1 and S2 of Rn are said to be:
(a) Separable or weakly separable, if there exists a hyperplane H = {x âˆˆRn :
aâŠ¤x = Î±}, a Ì¸= 0, Î± âˆˆR, such that
sup
xâˆˆS1

aâŠ¤x

â‰¦Î± â‰¦inf
xâˆˆS2

aâŠ¤x

.
In other words, it must exist a hyperplane H, such that
S1 âŠ‚H âˆ’, S2 âŠ‚H +,
i.e. S1 is contained in one of the closed half-spaces determined by H and S2
lies in the opposite closed half-space. The hyperplane H is called separating
hyperplane (between S1 and S2).
(b) Properly separable, if they are separable and there exists at least a point z âˆˆ
S1 âˆªS2, such that
aâŠ¤z Ì¸= Î±.
In other words, S1 and S2 are properly separable if they are separable and it holds
inf
xâˆˆS1

aâŠ¤x

< sup
xâˆˆS2

aâŠ¤x

.
(c) Strongly separable, if there exists a vector a Ì¸= 0, and a real scalar Î± such that
sup
xâˆˆS1

aâŠ¤x

< Î± < inf
xâˆˆS2

aâŠ¤x

.
It appears that strong separations implies proper separation and proper separation
implies (weak) separation. We point out that there are in the literature other kinds of
separationandalsoother denominations (for example, strongseparationis sometimes
called stable separation or also perfect separation).
The following result will be useful to prove the basic separations theorems we
will consider. We leave its proof to the reader.
Lemma 2.16 The two nonempty sets S1, S2 âŠ‚Rn are separable, respectively, prop-
erlyseparable,stronglyseparableifandonlyifthesets{0}and S1 âˆ’S2 areseparable,
respectively, properly separable, strongly separable.
First we formulate a result concerning strong separability.

2.1 Elements of Convex Analysis
33
Theorem 2.17 Let S1 and S2 be nonempty convex sets in Rn with S1 âˆ©S2 = âˆ…. If S1
is compact (i.e. closed and bounded) and S2 is closed, then there exists a hyperplane
that strongly separates S1 and S2.
Proof On the grounds of the assumptions, the set S1 âˆ’S2 is closed and convex and
it holds 0 /âˆˆS1 âˆ’S2. We have to prove that {0} and S1 âˆ’S2 are strongly separable.
Hence, we look for a point a âˆˆS1 âˆ’S2 such that
âˆ¥aâˆ¥â‰¦âˆ¥xâˆ¥, âˆ€x âˆˆS1 âˆ’S2.
This point exists (and it is uniquely determined). Moreover, we have a Ì¸= 0. Since
for a given point x âˆˆS1 âˆ’S2 and for a given number Î», with 0 < Î» < 1, we have
Î»x + (1 âˆ’Î»)a = a + Î»(x âˆ’a) âˆˆS1 âˆ’S2,
it follows
âˆ¥aâˆ¥2 âˆ¥a + Î»(x âˆ’a)âˆ¥2 â‰¦âˆ¥aâˆ¥2 + 2Î»aâŠ¤(x âˆ’a) + Î»2 âˆ¥x âˆ’aâˆ¥2
and hence
2aâŠ¤(x âˆ’a) + Î» âˆ¥x âˆ’aâˆ¥2 â‰§0.
As this inequality holds for all Î» âˆˆ(0, 1), we get
aâŠ¤(x âˆ’a) â‰§0,
i.e.
aâŠ¤x â‰§âˆ¥aâˆ¥2 .
In addition, we put Î± = 1
2 âˆ¥aâˆ¥2 , so we have
aâŠ¤0 = 0 < Î± âˆ¥aâˆ¥2 â‰¦aâŠ¤x
for all x âˆˆS1 âˆ’S2, i.e. the sets {0} and S1 âˆ’S2 are strongly separable and therefore
also S1 and S2 are strongly separable.
â–¡
As an immediate corollary we have the following result.
Corollary 2.18 Let S be a closed convex set in Rn and let y âˆˆRn be any point
outside of S, i.e. y /âˆˆS. Then there exists a hyperplane H =

x : aâŠ¤x = Î±

which
separates S and {y} strongly:
aâŠ¤x < Î± < aâŠ¤y, âˆ€x âˆˆS.
If S âŠ‚Rn is any nonempty convex set (not necessarily closed) and if y âˆˆRn is
a boundary point of S, it is natural to conjecture that y can be (weakly) separated

34
2
Elements of Convex Analysis. Linear Theorems of the Alternative. Tangent Cones
from S by a hyperplane passing through y. This conjecture is correct and the related
hyperplane is called a supporting hyperplane to S at y. Indeed, we have the following
result (â€œsupporting hyperplane theoremâ€).
Theorem 2.19 Let S be any nonempty convex set in Rn and let y âˆˆRn be a boundary
point of S. Then, there exists at least one supporting hyperplane to S at y, i.e. there
exists a âˆˆRn, a Ì¸= 0, such that
aâŠ¤x â‰¦aâŠ¤y, âˆ€x âˆˆS.
Proof Let Â¯S be the closure of S. Then Â¯S is convex by Theorem 2.7. Since y is a
boundary point for S and S is convex, y is also a boundary point for Â¯S. Take any
sequence

yk
, k = 1, 2, . . . , lying outside Â¯S and converging to y as k â†’+âˆ.
Since yk /âˆˆÂ¯S and Â¯S is closed and convex, by Theorem 2.17 (more precisely by its
corollary), there is a vector ak such that (ak)âŠ¤x < (ak)âŠ¤yk, for all x âˆˆÂ¯S. Without
loss of generality we might assume that
ak = 1 for each k, so that

ak
is a
sequence moving in the unit sphere of Rn. Since a unit sphere is compact,

ak
has
a convergent subsequence, we denote again by

ak
, such that
(ak)âŠ¤x < (ak)âŠ¤yk, âˆ€x âˆˆÂ¯S.
(2.3)
If we let the limit of ak, as k â†’+âˆ, be the vector a, we get, taking the
limit in (2.3),
aâŠ¤x â‰¦aâŠ¤y, âˆ€x âˆˆS.
â–¡
We are now ready to prove the (weak) separation theorem, essentially due to H.
Minkowski.
Theorem 2.20 Let S1 and S2 be two nonempty convex sets in Rn. If S1 and S2 are
disjoint, then there exists a hyperplane that separates them, that is, there exist a
vector a âˆˆRn, a Ì¸= 0, and a real scalar Î± such that
aâŠ¤x â‰¦Î± â‰¦aâŠ¤y, âˆ€x âˆˆS1, âˆ€y âˆˆS2.
Proof Let X = S1 âˆ’S2. Then X is convex and 0 /âˆˆX. The set cl(X) is also convex
by Theorem 2.7. If 0 /âˆˆcl(X), then {0} and cl(X) can be strongly separated according
to Theorem 2.17 (Corollary 2.18). If 0 is a boundary point for X, then {0} and cl(X)
can be separated by Theorem 2.19 (â€œsupporting hyperplane theoremâ€). In any case,
there exists a vector a âˆˆRn, a Ì¸= 0, such that aâŠ¤x â‰¦aâŠ¤0 = 0, âˆ€x âˆˆX. Therefore
we can assert that there exists Î± âˆˆR such that
aâŠ¤x â‰¦Î± â‰¦aâŠ¤y, âˆ€x âˆˆS1, âˆ€y âˆˆS2.
â–¡
More generally, the result of Theorem 2.20 holds under the assumption 0 /âˆˆ
int(S1 âˆ’S2).
Now we are able to formulate a theorem on proper separation.

2.1 Elements of Convex Analysis
35
Theorem 2.21 (Proper separation theorem) Two nonempty convex sets S1 and S2 in
Rn can be properly separated if and only if relint(S1) âˆ©relint(S2) = âˆ….
Proof Deï¬ne the convex set X = S1 âˆ’S2. It follows that relint(X) = relint(S1 âˆ’
S2) = relint(S1) âˆ’relint(S2). Thus relint(S1) âˆ’relint(S2) = âˆ…and 0 /âˆˆrelint(X)
are equivalent statements. Consequently, we have to prove that the sets {0} and
X are properly separable if and only if 0 /âˆˆrelint(X).
Suppose that the origin and X are properly separated by a hyperplane H such that
0 âˆˆH âˆ’and X âŠ‚H +. We claim that 0 /âˆˆrelint(X). If 0 âˆˆH, then relint(X) âŠ‚H +,
so that 0 /âˆˆrelint(X). Otherwise, 0 âˆˆH and there exists a point x âˆˆX \ H. If we
had 0 âˆˆrelint(X), there would exist a point y âˆˆX such that 0 âˆˆ(x, y), giving the
contradiction y âˆˆS1 âˆ©H âˆ’âˆ’= âˆ…, where
H âˆ’âˆ’=

x âˆˆRn : aâŠ¤x < Î±

.
This proves the claim.
Conversely, suppose that 0 /âˆˆrelint(X). Write
L â‰¡aff(X) = u0 + span

u1, . . . , uk
where

ui
, i = 1, . . . , k, are linearly independent vectors. If 0 /âˆˆL, then

ui
,
i = 0, . . . , k are linearly independent and we can extend it to a basis

ui
, i =
0, . . . , n âˆ’1, of Rn. Then the hyperplane H â‰¡u0 + span

u1, . . . , unâˆ’1
does not
containtheorigin,soitproperlyseparates{0}and X.If0 âˆˆL,weapplyTheorem2.20
within the vector space L to the sets {0} and relint(X), and obtain a hyperplane P in
L separating {0} and X such that relint(X) âŠ‚P+. We may assume that 0 âˆˆP; other-
wise the translation of P so that it passes through the origin also satisï¬es the same sep-
aration properties. Extending P to the hyperplane H = span

P, uk+1, . . . , unâˆ’1
,
it is evident that H properly separates {0} and X.
â–¡
As a consequence of the theorem on strong separability we have an interesting
characterization of closed convex sets of Rn.
Theorem 2.22 A closed convex set S âŠ‚Rn is given by the intersection of all closed
half-spaces that contain S.
Proof The intersection D of all closed half-spaces that contain S is obviously a
closed convex set and it holds S âŠ‚D. We now prove the opposite inclusion D âŠ‚S
by an indirect proof. Let be given a point x0 âˆˆD with x0 /âˆˆS, so the sets S and

x0
are strongly separable, i.e. there exist a vector a Ì¸= 0 and a number Î± such that
aâŠ¤x < Î± < aâŠ¤x0, âˆ€x âˆˆS.
Therefore, it will exist a closed half-space

x âˆˆRn : aâŠ¤x â‰¦Î±


36
2
Elements of Convex Analysis. Linear Theorems of the Alternative. Tangent Cones
which surely contains the set S, but not the point x0, i.e. x0 /âˆˆD, in contradiction
with the assumptions.
â–¡
In order to get other applications of the separation theorems, we now present the
notion of polar cone of a set S âŠ‚Rn, of bipolar cone, and point out their main
properties.
Deï¬nition 2.23 Let S âŠ‚Rn be any set; then the (negative) polar cone of S is given
by
Sâˆ—=

y âˆˆRn : yâŠ¤x â‰¦0, âˆ€x âˆˆS

.
The bipolar cone of S is deï¬ned by
Sâˆ—âˆ—= (Sâˆ—)âˆ—=

x âˆˆRn : xâŠ¤y â‰¦0, âˆ€y âˆˆSâˆ—
.
Some authors call dual cone of S the positive polar cone:
S+ =

y âˆˆRn : yâŠ¤x â‰§0, âˆ€x âˆˆS

.
However, there is not uniformity of deï¬nitions in the literature.
We accept the deï¬nition âˆ…âˆ—= Rn. Obviously, any polar cone (and hence any
bipolar cone), being given by
Sâˆ—= âˆ©
xâˆˆS

y âˆˆRn : yâŠ¤x â‰¦0

,
is the intersection of closed half-spaces and therefore it is a closed and convex cone,
with 0 âˆˆSâˆ—.
From the deï¬nition it follows at once that
Sâˆ—= (cl(S))âˆ—= (conv(S))âˆ—= (cone(S))âˆ—.
If L âŠ‚Rn is a linear subspace, the polar cone of L is given by the orthogonal
complement of L, i.e.
LâŠ¥=

y âˆˆRn : yâŠ¤x = 0, âˆ€x âˆˆL

.
The following theorem gathers the main properties of polar cones.
Theorem 2.24 For any sets S âŠ‚Rn, S1, S2 âŠ‚Rn, the following properties hold.
(a) S1 âŠ‚S2 â‡’(S2)âˆ—âŠ‚(S1)âˆ—.
(b) (S1 âˆªS2)âˆ—= (S1)âˆ—âˆ©(S2)âˆ—.
(c) (S1)âˆ—âˆª(S2)âˆ—âŠ‚(S1 âˆ©S2)âˆ—.
(d) S âŠ‚Sâˆ—âˆ—.
(e) S = Sâˆ—âˆ—if S is a nonempty closed convex cone. Therefore if L is a linear subspace
of Rn, we have L = (LâŠ¥)âŠ¥= LâŠ¥âŠ¥.

2.1 Elements of Convex Analysis
37
(f) Sâˆ—= (cl(cone(S)))âˆ—(if S Ì¸= âˆ…) and therefore Sâˆ—âˆ—= cl(cone(S)).
(g) Sâˆ—= Sâˆ—âˆ—âˆ—.
(h) (S1 âˆ©S2)âˆ—= cl(cone((S1)âˆ—âˆª(S2)âˆ—)) = cl((S1)âˆ—+ (S2)âˆ—), if S1 and S2 are
closed convex cones.
Proof The ï¬rst four properties are quite immediate consequences of the deï¬nitions
of polar and bipolar cones. We prove property (e), called also â€œbipolar theoremâ€: if
S âŠ‚Rn is a closed convex cone, then S = Sâˆ—âˆ—. From the deï¬nition of Sâˆ—we see that
if x âˆˆS, then xâŠ¤y â‰¦0 for all y âˆˆSâˆ—; this proves that S âŠ‚Sâˆ—âˆ—. Suppose that the
reverse inclusion Sâˆ—âˆ—âŠ‚S is not true, and pick a point x âˆˆSâˆ—âˆ—\ S. It follows from the
strong separation theorem (Theorem 2.17) that there exists a nonzero vector a âˆˆRn
such that
aâŠ¤x > aâŠ¤z, âˆ€z âˆˆS.
(2.4)
Ontheonehand,setting z = 0 in (2.4)givesaâŠ¤x > 0;ontheotherhand,if z âˆˆS is
a ï¬xed point, then tz âˆˆS for all t > 0 and (2.4) gives aâŠ¤x > aâŠ¤tz or aâŠ¤z < (aâŠ¤x)/t.
Letting t â†’+âˆ, we obtain
aâŠ¤z â‰¦0, âˆ€z âˆˆS,
which implies that a âˆˆSâˆ—. However, since x âˆˆSâˆ—âˆ—, we must have aâŠ¤x â‰¦0, which
contradicts the fact aâŠ¤x > 0 proved above.
Property (f ) follows from (e), being Sâˆ—âˆ—= cl(cone(S))âˆ—âˆ—= cl(cone(S)).
As Sâˆ—is a non-empty closed convex cone, we have from property (e), also Sâˆ—âˆ—âˆ—=
(Sâˆ—)âˆ—âˆ—= Sâˆ—, i.e. property (g).
Property (h) is obtained from properties (b), (e) and (f ), being
(S1 âˆ©S2)âˆ—= ((S1)âˆ—âˆ—âˆ©(S2)âˆ—âˆ—)âˆ—= ((S1)âˆ—âˆª(S2)âˆ—)âˆ—âˆ—= cl(cone((S1)âˆ—âˆª(S2)âˆ—)).
The proof of the proposition
cone((S1)âˆ—âˆª(S2)âˆ—) = (S1)âˆ—+ (S2)âˆ—
is left to the reader.
â–¡
We remark that it could be proved that property (e) of Theorem 2.24 holds if and
only if S is a closed convex cone. Moreover, the same property can be given in the
following weaker form (called sometimes â€œpolar cone theoremâ€): for any nonempty
cone S âŠ‚Rn, we have
Sâˆ—âˆ—= cl(conv(S)).
Therefore
(Sâˆ—)âˆ—âˆ—= (cl(conv(S)))âˆ—,
and hence

38
2
Elements of Convex Analysis. Linear Theorems of the Alternative. Tangent Cones
Sâˆ—= (cl(conv(S)))âˆ—.
If 0 âˆˆS1 âˆ©S2, it holds
(S1 + S2)âˆ—= Sâˆ—
1 âˆ©Sâˆ—
2.
We now brieï¬‚y recall again a special class of convex cones, called polyhedral
cones. First we introduce the notion of polyhedral sets. Polyhedral sets of Rn are
formed by the intersection of a ï¬nite number of closed half-spaces. Thus a typical
polyhedral set P can be represented as follows.
P =

x âˆˆRn : (ai)âŠ¤x âˆ’bi â‰¦0, i = 1, . . . , m

,
where ai âˆˆRn and bi âˆˆR. It turns out that polyhedral sets are closed convex sets
and that alternatively they can be written in the form
P =

x âˆˆRn : Ax â‰¦b

,
where A is a matrix of order (m, n) and b âˆˆRm.
A polyhedral cone C âŠ‚Rn is represented as
C =

x âˆˆRn : Ax â‰¦0

,
i.e. C is a polyhedral set where b = 0 âˆˆRm. Obviously, polyhedral cones are closed
convex cones. For this type of cones the following properties hold.
If C, C1, C2 âŠ‚Rn are polyhedral cones, then:
(a) C = Câˆ—âˆ—.
(b) Câˆ—is a polyhedral cone.
(c) C1 + C2 and C1 âˆ©C2 are polyhedral cones.
(d) (C1 + C2)âˆ—= Câˆ—
1 âˆ©Câˆ—
2.
(e) (C1 âˆ©C2)âˆ—= Câˆ—
1 + Câˆ—
2.
Properties (d) and (e) are also called â€œmodularity theoremâ€.
In addition, we recall again the notion of ï¬nitely generated cone or ï¬nite cone.
Deï¬nition 2.25 A convex cone C âŠ‚Rn is said to be ï¬nitely generated if it is gen-
erated by a ï¬nite set of vectors of Rn, i.e. if it has the form
C =

x âˆˆRn : x =
m

i=1
Î¼iai, Î¼i â‰§0, i = 1, . . . , m

.
The vectors a1, . . . , am of Rn are said to be the generators of the cone C. We
point out that if a1, . . . , am âˆˆRn are the columns of a matrix A, of order (n, m) and
Î¼ = (Î¼1, . . . , Î¼m)âŠ¤, a ï¬nitely generated cone can be written as

2.1 Elements of Convex Analysis
39
C =

x âˆˆRn : x = AÎ¼, Î¼ âˆˆRm, Î¼ â‰§0

.
(2.5)
We have two important results related to ï¬nitely generated cones, results previ-
ously mentioned.
Theorem 2.26 Let C âŠ‚Rn be a ï¬nitely generated cone given by
C =

z âˆˆRn : z =
m

i=1
Î¼iai, Î¼i â‰§0, i = 1, . . . , m

with A matrix of order (n, m). Then C is a closed convex cone.
Proof The facts that C is a cone with vertex at the origin 0 âˆˆC and that it is convex
are obvious. Let us rewrite C as a nonnegative linear combination of the columns A j
of A :
C =
â§
â¨
â©z âˆˆRn : z =
m

j=1
Î¼ j A j, Î¼ j â‰§0, j = 1, . . . , m
â«
â¬
â­.
We will show that the cone C is closed by an induction argument based on the
number of the columns A j, j = 1, . . . , k. When k = 1, C is either the origin 0 âˆˆRn
or a half-line and is therefore closed. Now suppose that for k > 1 the cone generated
by the vectors A1, . . . , Akâˆ’1 is closed:
Ckâˆ’1 =
â§
â¨
â©z : z =
kâˆ’1

j=1
Î¼ j A j, Î¼ j â‰§0
â«
â¬
â­
is closed. We have to show that the cone
Ck =
â§
â¨
â©z : z =
k

j=1
Î¼ j A j, Î¼ j â‰§0
â«
â¬
â­
is closed too. There are two cases.
(1) First, suppose that Ck contains the vectors âˆ’A1, âˆ’A2, . . . , âˆ’Ak. Then Ck is a
linear subspace of dimension not exceeding k, so it is closed.
(2) Assume that at least one of the vectors âˆ’A1, âˆ’A2, . . . , âˆ’Ak does not belong
to Ck, say âˆ’Ak /âˆˆCk (renumber if necessary). Then, every y âˆˆCk can be rep-
resented as y = Â¯y + Î±Ak, Î± â‰§0, where Â¯y âˆˆCkâˆ’1. To show that Ck is closed,
suppose that Â¯z is a limit point. Then, there exists a sequence {zn} âŠ‚Ck such that
zn â†’Â¯z as n â†’âˆ, where zn has the form
zn = Â¯yn + Î±n Ak, Î±n â‰§0, with Â¯yn âˆˆCkâˆ’1.

40
2
Elements of Convex Analysis. Linear Theorems of the Alternative. Tangent Cones
If the sequence {Î±n} is bounded, we can assume, without loss of generality, that
the sequence converges to a limit Î±, and consequently Â¯z âˆ’Î±Ak âˆˆCkâˆ’1, where
this last set is closed. Indeed,
Â¯z âˆ’Î±Ak = lim
nâ†’âˆ(zn âˆ’Î±n Ak) = lim
nâ†’âˆÂ¯yn â‰¡Â¯y âˆˆCkâˆ’1,
since Ckâˆ’1 is closed. We conclude that
Â¯z = Â¯y + Î±Ak âˆˆCk.
Thus, if the sequence {Î±n} is bounded, then the set Ck is closed.
We now assume that Î±n â†’âˆfor n â†’âˆ. Then, since {zn} converges, it is a
bounded sequence. Hence (Î±n)âˆ’1zn â†’0 as n â†’âˆ. It follows that (Î±n)âˆ’1 Â¯yn +
Ak â†’0 as n â†’âˆ. Therefore limnâ†’âˆ(Î±n)âˆ’1 Â¯yn = âˆ’Ak. But since Ckâˆ’1 is
closed, this means that âˆ’Ak âˆˆCkâˆ’1, which is a contradiction.
â–¡
Theorem 2.27 (Minkowski-Weyl Theorem). A cone C âŠ‚Rn is polyhedral if and
only if it is a ï¬nitely generated cone.
Note that from the Minkowski-Weyl theorem we obtain at once that a ï¬nitely
generated cone is closed. However, also the said theorem has not a trivial proof.
We now compute the polar of the ï¬nitely generated cone C âŠ‚Rn given by (2.5):
Câˆ—=

y âˆˆRn : yâŠ¤x â‰¦0, âˆ€x âˆˆC

=

y âˆˆRn : yâŠ¤AÎ¼ â‰¦0, âˆ€Î¼ â‰§0

=

y âˆˆRn : AâŠ¤y â‰¦0

,
i.e. the polar of a ï¬nitely generated cone is a polyhedral cone. Moreover, we can
assert that the angles between the vectors y âˆˆCâˆ—and the column vectors of A are
not smaller than 90â—¦. For what concerns the bipolar cone of C we have
Câˆ—âˆ—=

x âˆˆRn : xâŠ¤y â‰¦0, âˆ€y âˆˆCâˆ—
=

x âˆˆRn : xâŠ¤y â‰¦0, âˆ€y such that AâŠ¤y â‰¦0

=

x âˆˆRn : AâŠ¤y â‰¦0 â‡’xâŠ¤y â‰¦0

.
The equality between the cones C and Câˆ—âˆ—(according to Theorem 2.24(e) since
C is a closed convex cone), together with what obtained above, mean that, given a
matrix A and a vector b, the condition
AâŠ¤y â‰¦0 â‡’bâŠ¤y â‰¦0
is equivalent to
âˆƒÎ¼ â‰§0 : AÎ¼ = b.

2.2 Theorems of the Alternative for Linear Systems
41
This is the statement of the well-known Farkasâ€™ theorem or Farkasâ€™ lemma. This
theorem is one of the most quoted and used theorem of the alternative for linear
systems. The next section is concerned with several theorems of the alternative for
linear systems.
2.2
Theorems of the Alternative for Linear Systems
The general structure of a theorem of the alternative is the following one. A theorem
of the alternative is a result concerning the following proposition: between two given
systems of linear (or also nonlinear) relatione, say a â€œprimalâ€ system S and a â€œdualâ€
system Sâˆ—, one and only one of them admits solutions. In other words: S admits
solutions if and only if Sâˆ—does not admit solutions (equivalently: Sâˆ—admits solutions
if and only if S does not admit solutions).
The theorem of the alternative of Farkas can therefore be expressed in the follow-
ing form, which puts into evidence the â€œalternativeâ€ between two linear systems.
Theorem 2.28 Let be given a matrix A of order (m, n) and a vector b âˆˆRm. Then
the system
S1 â‰¡

Ax = b; x â‰§0

admits solutions x âˆˆRn if and only if the system
Sâˆ—
1 â‰¡

yâŠ¤A â‰§0; yâŠ¤b < 0

does not admit solutions y âˆˆRm.
Remark 2.29 Obviously system Sâˆ—
1 in Theorem 2.28 can be equivalently written in
the form
Sâˆ—
1 â‰¡

yâŠ¤A â‰¦0; yâŠ¤b > 0

.
Moreover, S1 and Sâˆ—
1 of Theorem 2.28 can be equivalently written as
S1 â‰¡

xâŠ¤AâŠ¤= bâŠ¤; x â‰§0

;
Sâˆ—
1 â‰¡

AâŠ¤y â‰§0; bâŠ¤y < 0

.
Another equivalent formulation of Farkasâ€™ theorem (not in an â€œalternative formâ€)
is the following one, previously given at the end of the last section:
A necessary and sufï¬cient condition for S1 to have solutions x âˆˆRn is the validity
of the implication
yâŠ¤A â‰§0 â‡’yâŠ¤b â‰§0
or, equivalently,

42
2
Elements of Convex Analysis. Linear Theorems of the Alternative. Tangent Cones
yâŠ¤A â‰¦0 â‡’yâŠ¤b â‰¦0.
Finally, note that for b = 0 Farkasâ€™ theorem becomes trivial.
The following result is a simple formal variant of Farkasâ€™ theorem and generated
a ï¬rst list of theorems of the alternative for linear systems.
Theorem 2.30 Let be given the positive integers m1, m2, m3, n1, n2; the matrices
Ai j of order (mi, n j), i = 1, 2, 3; j = 1, 2; the vectors bi âˆˆRmi, i = 1, 2, 3. The
system
â§
âªâªâ¨
âªâªâ©
A11x1 + A12x2 â‰¦b1
A21x1 + A22x2 = b2
A31x1 + A32x2 â‰§b3
x1 âˆˆRn1, x2 âˆˆRn2, x1 â‰§0,
(2.6)
admits solutions x1, x2 if and only if the system
â§
âªâªâ¨
âªâªâ©
(y1)âŠ¤A11 + (y2)âŠ¤A21 + (y3)âŠ¤A31 â‰§0
(y1)âŠ¤A12 + (y2)âŠ¤A22 + (y3)âŠ¤A32 = 0
(y1)âŠ¤b1 + (y2)âŠ¤b2 + (y3)âŠ¤b3 < 0
y1 âˆˆRm1, y2 âˆˆRm2, y3 âˆˆRm3, y1 â‰§0, y3 â‰¦0,
does not admit solutions y1, y2, y3.
Proof The above result comes out at once from Farkasâ€™ theorem: we put x2 = v1 âˆ’
v2, with v1 â‰§0, v2 â‰§0 and then we transform inequalities into equalities by means
of the â€œslack vectorsâ€ s1 â‰§0, s2 â‰§0. System (2.6) can be therefore rewritten in the
form
â¡
â£
A11
A12
âˆ’A12
I
0
A21
A22
âˆ’A22
0
0
A31
A32
âˆ’A32
0 âˆ’I
â¤
â¦
â¡
â¢â¢â¢â¢â£
x1
v1
v2
s1
s2
â¤
â¥â¥â¥â¥â¦
=
â¡
â£
b1
b2
b3
â¤
â¦
(2.7)
with x1 â‰§0, v1 â‰§0, v2 â‰§0, s1 â‰§0, s2 â‰§0. Applying to (2.7) Farkasâ€™ theorem we
obtain the thesis.
â–¡
From Theorem 2.30 it is possible to obtain easily a ï¬rst list of theorems of the
alternative. In the following list we use the short convention
Sk â‰¡{. . . };
Sâˆ—
k â‰¡{. . . },
in order to specify that the â€œprimalâ€ system Sk admits solutions if and only if the
â€œdualâ€ system Sâˆ—
k does not admit solutions.
(1) S2 â‰¡{Ax = b}; Sâˆ—
2 â‰¡

yâŠ¤A = 0; yâŠ¤b Ì¸= 0

.

2.2 Theorems of the Alternative for Linear Systems
43
Notethatthisresultgivesnecessaryandsufï¬cientconditionsfortheexistenceof
solutions of a non-homogeneous system of linear equations: system S2 admits
solutions if and only if it holds yâŠ¤b = 0 for any vector y such that yâŠ¤A = 0.
This result is sometimes called the Fredholm theorem of the alternative.
(2) (Theorem of the alternative of Gale [10]).
S3 â‰¡

Ax â‰¦b

; Sâˆ—
3 â‰¡

yâŠ¤A = 0; y â‰§0; yâŠ¤b < 0

.
(3) S4 â‰¡

Ax â‰¦b; x â‰§0

; Sâˆ—
4 â‰¡

yâŠ¤A â‰§0; y â‰§0; yâŠ¤b < 0

.
(4) (Theorem of the alternative of Ky Fan).
S5 â‰¡

Ax â‰¦b1; Bx = b2
;
Sâˆ—
5 â‰¡

(y1)âŠ¤A + (y2)âŠ¤B = 0; y1 â‰§0; (y1)âŠ¤b1 + (y2)âŠ¤b2 < 0

.
(5) S6 â‰¡

Ax â‰¦b1; Bx = b2; x â‰§0

;
Sâˆ—
6 â‰¡

(y1)âŠ¤A + (y2)âŠ¤B â‰§0, y1 â‰§0, (y1)âŠ¤b1 + (y2)âŠ¤b2 < 0

.
(6) S7 â‰¡

Ax + Bz = b; x â‰§0

; Sâˆ—
7 â‰¡

yâŠ¤A â‰§0; yâŠ¤B = 0; yâŠ¤b < 0

.
(7) S8 â‰¡

Ax + Bz â‰¦b; x â‰§0

; Sâˆ—
8 â‰¡

yâŠ¤A â‰§0; yâŠ¤B = 0; yâŠ¤b < 0; y â‰§0

.
(8) S9 â‰¡

Cx â‰§c

; Sâˆ—
9 â‰¡

yâŠ¤C = 0; y â‰§0; yâŠ¤c > 0

.
(9) S10 â‰¡

Cx â‰§c; x â‰§0

; Sâˆ—
10 â‰¡

yâŠ¤C â‰¦0; y â‰§0; yâŠ¤c > 0

.
(10) S11 â‰¡

Cx â‰§c; Bx = b; x â‰§0

;
Sâˆ—
11 â‰¡

(y1)âŠ¤C + (y2)âŠ¤B â‰¦0; y1 â‰§0; (y1)âŠ¤c + (y2)âŠ¤b > 0

.
(11) S12 â‰¡

Cx + Dz â‰§c; x â‰§0

; Sâˆ—
12 â‰¡

yâŠ¤C â‰¦0; yâŠ¤D = 0; y â‰§0; yâŠ¤c > 0

.
(12) S13 â‰¡

Ax â‰§0; bâŠ¤x < 0

; Sâˆ—
13 â‰¡

yâŠ¤A = b; y â‰§0

.
(This result is nothing but Farkasâ€™ theorem, where the â€œprimalâ€ and the â€œdualâ€
problems have been interchanged).
(13) S14 â‰¡

Ax â‰§0; x â‰§0; bâŠ¤x < 0

; Sâˆ—
14 â‰¡

yâŠ¤A â‰¦b; y â‰§0

.
(14) S15 â‰¡

Cx â‰¦0; Dx = 0; câŠ¤x < 0

; Sâˆ—
15 â‰¡

yâŠ¤C + vâŠ¤D + câŠ¤= 0; y â‰§0

.
(15) S16 â‰¡

Cx + Dz = 0; aâŠ¤x + bâŠ¤z > 0; z â‰§0

;
Sâˆ—
16 â‰¡

yâŠ¤C + aâŠ¤= 0; yâŠ¤D + bâŠ¤â‰¦0

.
Another important theorem of the alternative for linear systems (important for
its applications in obtaining optimality conditions for mathematical programming
problems) is Motzkinâ€™s theorem of the alternative.
Theorem 2.31 (Motzkin) Let be given (real) matrices A, B and H of appropriate
dimensions. Then, exactly one of the following systems has a solution:
(i) Ax < 0; Bx â‰¦0; Hx = 0;
(ii) uâŠ¤A + vâŠ¤B + wâŠ¤H = 0; u â‰§0, u Ì¸= 0; v â‰§0.
Proof It is easy to show that both (i) and (ii) cannot have a solution. Suppose
uâŠ¤A + vâŠ¤B + wâŠ¤H = 0 for some u â‰§0, u Ì¸= 0, v â‰§0, w unrestricted in sign.
Then, for every vector x we have uâŠ¤Ax + vâŠ¤Bx + wâŠ¤Hx = 0. If Bx â‰¦0, then
vâŠ¤Bx â‰¦0 and if Hx = 0, then wâŠ¤Hx = 0. Thus uâŠ¤Ax â‰§0. Since u â‰§0, u Ì¸= 0,
Ax < 0 cannot hold.

44
2
Elements of Convex Analysis. Linear Theorems of the Alternative. Tangent Cones
Suppose now that (i) has no solution. Then the system
â§
âªâªâ¨
âªâªâ©
Ax + eÎ¸ â‰¦0, Î¸ > 0
Bx â‰¦0
Hx â‰¦0
âˆ’Hx â‰¦0
has no solution (the vector e is the summation vector, i.e. e = [1, 1, . . . , 1]âŠ¤). This
last system can be written in the form
â¡
â¢â¢â£
A
e
B
0
H
0
âˆ’H
0
â¤
â¥â¥â¦
 x
Î¸
!
â‰¦0, (0, . . . , 0, 1)
" x
Î¸
#
> 0.
From Farkasâ€™ theorem, there exists a vector (u, v, w1, w2)âŠ¤â‰§0 such that
â¡
â¢â¢â£
A
e
B
0
H
0
âˆ’H
0
â¤
â¥â¥â¦
âŠ¤â›
âœâœâ
u
v
w1
w2
â
âŸâŸâ =
â›
âœâœâœâ
0
...
0
1
â
âŸâŸâŸâ .
This can be rewritten as
uâŠ¤A + vâŠ¤B + (w1 âˆ’w2)H = 0, uâŠ¤e = 1.
Letting wâŠ¤= (w1 âˆ’w2)âŠ¤, we have completed the proof of (ii).
â–¡
We remark that in Theorem 2.31 matrices B and H may be missing. If H in
Theorem 2.31 is missing, we have the two â€œalternative systemsâ€:
(1)
Ax < 0; Bx â‰¦0;
(2)
uâŠ¤A + vâŠ¤B = 0; u â‰§0, u Ì¸= 0; v â‰§0.
Antosiewicz [11] proves that the previous statement is equivalent to the following
one: either
(a) Ax â‰¦0, Ax Ì¸= 0; Bx â‰¦0 has a solution, or
(b) uâŠ¤A + vâŠ¤B = 0; u > 0; v â‰§0 has a solution, but never both.
If in (1) and (2) B is missing, we obtain the theorem of the alternative of Gordan:
â€¢ either Ax < 0 has a solution, or
â€¢ uâŠ¤A = 0, u â‰§0, u Ì¸= 0 has a solution, but never both.

2.2 Theorems of the Alternative for Linear Systems
45
If in (a) and (b) B is missing, we obtain the theorem of the alternative of Stiemke:
either Ax â‰¦0, Ax Ì¸= 0 has a solution, or
uâŠ¤A = 0, u > 0 has a solution, but never both.
Therefore, Gordanâ€™s theorem and Stiemkeâ€™s theorem are equivalent statements.
Obviously the ï¬rst statement of Gordanâ€™s theorem can be equivalently restated as
Ax > 0.
ThisleadstothefollowinggeometricversionofGordanâ€™stheorem:let S beasubspace
of Rn. Then one and only one of the following assertions is true:
I. S contains a positive vector.
II. SâŠ¥contains a nonnegative nonzero vector (SâŠ¥is the orthogonal complement
of S).
From Stiemkeâ€™s theorem, Nikaido [12] obtains the following result, due to A. W.
Tucker, and called also â€œkey theoremâ€.
Theorem 2.32 For any given matrix A of order (m, n) the systems
Ax â‰§0 and AâŠ¤y = 0, y â‰§0
possess solutions x and y such that
Ax + y > 0.
From this result, as shown by Mangasarian [13], it is possible to obtain several
theorems of the alternative, among which the theorems of Gordan, Stiemke, Farkas,
Motzkin and other ones, such as, for example the following ones.
â€¢ The theorem of the alternative of Slater: let A, B, C and D be given matrices (C
and D may be missing). Then either
Ax < 0; Bx â‰¦0, Bx Ì¸= 0; Cx â‰¦0; Dx = 0
has a solution x or
uâŠ¤A + vâŠ¤B + wâŠ¤C + zâŠ¤D = 0,
u â‰§0, u Ì¸= 0; v â‰§0; w â‰§0 or u â‰§0; v > 0; w â‰§0
has a solution u, v, w, z, but never both.
â€¢ The theorem of the alternative of Tucker: let B, C and D be given matrices (C and
D may be missing). Then either
Bx â‰¦0, Bx Ì¸= 0; Cx â‰¦0; Dx = 0
has a solution x, or

46
2
Elements of Convex Analysis. Linear Theorems of the Alternative. Tangent Cones
vâŠ¤B + wâŠ¤C + zâŠ¤D = 0, v > 0, w â‰§0
has a solution v, w, z, but never both.
â€¢ The theorem of the alternative of Ville: either the system
S â‰¡

Ax < 0, x â‰§0

has a solution x, or the system
Sâˆ—â‰¡

yâŠ¤A â‰§0, y â‰§0, y Ì¸= 0

has a solution y, but never both.
Note that system S can be equivalently written as
S â‰¡

Ax < 0, x â‰§0, x Ì¸= 0

or also as
S â‰¡{Ax < 0, x > 0} .
It turns out that all the theorems of the alternative described in the present section
(and many other ones) are in fact equivalent statements.
In addition, we point out another result, due to A. W. Tucker, which is useful in
obtaining duality theorems for linear programming problems.
Theorem 2.33 Let be given a square skew-symmetric matrix L (i. e. LâŠ¤= âˆ’L).
Then the system
Lw â‰§0, w â‰§0
admits a solution w such that
Lw + w > 0.
Proof By Tuckerâ€™s key theorem (Theorem 2.32), applied to matrix (LâŠ¤, I), where
I has the same order of L, there are solutions x and y of
" L
I
#
x â‰§0, (LâŠ¤, I)y = 0, y â‰§0,
" L
I
#
x + y > 0.
If we let u = (y1, . . . , yn)âŠ¤, v = (yn+1, . . . , y2n)âŠ¤, y = (y1, . . . , y2n)âŠ¤, the
above relations become
Lx â‰§0, x â‰§0, LâŠ¤u + v = 0, u â‰§0, v â‰§0,

2.3 Tangent Cones
47
Lx + u > 0, x + v > 0.
In view of LâŠ¤= âˆ’L, the third relation entails Lu = v. Therefore, by letting
w = x + u, we have
Lw = Lx + Lu = Lx + v â‰§0,
Lw + w = (Lx + v) + (x + u) = (Lx + u) + (x + v) > 0.
This completes the proof.
â–¡
2.3
Tangent Cones
In mathematics the approximation of sets by means of other sets with a simpler
structure plays an important role, especially in optimization theory. In connection
with the development of Convex Analysis the interest focused on the approximation
of a given set S âŠ‚Rn around a given point x0 âˆˆS (or also x0 âˆˆcl(S)) with cones
or with convex cones. Since the vertex of the various approximating cones K(S, x0)
is usually at the origin of Rn, more precisely the approximating cone of a set S at
x0 âˆˆS is given by the translation K(S, x0) + x0.
There are various notions of local approximating cone; here we shall mention only
the following ones. We begin with a cone introduced by the French mathematician
Bouligand at the beginning of the 30â€™ies of the XX century, cone usually called
contingent cone or Bouligand tangent cone. For surveys of the various approximating
cones introduced in the literature, see, e.g., Aubin and Frankowska [14], Bazaraa and
Shetty [1], Giorgi et al. [15].
Deï¬nition 2.34 A sequence

xk
âŠ‚Rn \

x0
with xk â†’x0, is called tangentially
convergent in the direction y âˆˆRn to the point x0 if
lim
kâ†’+âˆ
xk âˆ’x0
xk âˆ’x0 = y
and we write xk
yâ†’x0.
Obviously any convergent sequence xk â†’x0 (with xk Ì¸= x0 for all k) contains
at least a tangentially convergent subsequence. The set of all directions y for which
there exists a feasible sequence

xk
âŠ‚S, with S âŠ‚Rn, tangentially convergent to
x0 âˆˆS, form a cone which is a local cone approximation at x0 of the set S.
Deï¬nition 2.35 Let S âŠ‚Rn and x0 âˆˆS; the cone
T (S, x0) =

Î»y âˆˆRn : âˆƒ{xk} âŠ‚S, xk
yâ†’x0, Î» â‰§0


48
2
Elements of Convex Analysis. Linear Theorems of the Alternative. Tangent Cones
is called Bouligand tangent cone or contingent cone to the set S at the point x0. If
x0 is an isolated point of S, we put T (S, x0) = {0}.
Other equivalent characterizations of T (S, x0) are the following ones:
T (S, x0) =

 y âˆˆRn : âˆƒ{xk} âŠ‚S, lim
kâ†’+âˆxk = x0, âˆƒ{Î»k} âŠ‚R+,
such that y = lim
kâ†’+âˆÎ»k(xk âˆ’x0)

;
T (S, x0) =

y âˆˆRn : âˆƒyk â†’y, âˆƒtk â†’0+ such that x0 + tk yk âˆˆS

;
T (S, x0) =

y âˆˆRn : âˆƒ{xk} âŠ‚S, xk â†’x0, âˆƒtk â†’0+ such that xkâˆ’x0
tk
â†’y

;
T (S, x0) =

y âˆˆRn : âˆ€N(y), âˆ€Î» > 0, âˆƒt âˆˆ(0, Î»), âˆƒÂ¯y âˆˆN(y) such that x0 + t Â¯y âˆˆS

.
The notation tk â†’0+ means that tk â†’0 and tk > 0 for all k.
Note that T (S, x0) is indeed a cone, closed but not necessarily convex, with
0 âˆˆT (S, x0). We note also that:
(i) T (S, x0) depends only on the structure of S in a neighborhood of x0, that is
T (S, x0) = T (S âˆ©U(x0), x0),
where U(x0) is any neighborhood of x0 (the notion of â€œBouligand tangent coneâ€
is therefore an â€œinï¬nitesimal notionâ€; this holds true also for the other approxi-
mating cones).
(ii) If x0 âˆˆint(S), then T (S, x0) = Rn.
(iii) T (S, x0) = T ( Â¯S, x0), where Â¯S = cl(S).
(iv) T (S1, x0) âŠ‚T (S2, x0), if S1 âŠ‚S2.
The fact that T (S, x0) is not necessarily convex appears, e.g., from the following
example.
Example 2.36 Consider the set
S =

(x1, x2) âˆˆR2 : x1x2 = 0, x1 â‰§0, x2 â‰§0

.
Take x0 = 0 âˆˆS. Then T (S, x0) = S, which is not a convex set.
Example 2.37 As T (S, x0) = Rn if x0 âˆˆint(S), we see that the deï¬nition of
Bouligand tangent cone is indeed meaningful when x0 is a point of the boundary of
S. Also in this evenience, it may be that T (S, x0) does not contain the set S. For
example, if x0 = (0, 0)âŠ¤,
S1 =

(x1, x2) âˆˆR2 : x2 â‰§(x1)2
and S2 =

(x1, x2) âˆˆR2 : x2 =
*
|x1|

,

2.3 Tangent Cones
49
then T (S1, x0) = {(x1, x2) âˆˆR2 : x2 â‰§0} and T (S2, x0) = {(x1, x2) âˆˆR2 : x1 =
0, x2 â‰§0}.
Example 2.38 If we have m < n functions h1, . . . , hm, continuously differentiable
on Rn, let us consider the set
S =

x âˆˆRn : h j(x) = 0, j = 1, . . . , m

.
Let x0 âˆˆS be such that the gradients âˆ‡h1(x0), . . . , âˆ‡hm(x0), are linearly inde-
pendent; then T (S, x0) is the subspace

y âˆˆRn : âˆ‡h j(x0)âŠ¤y = 0, j = 1, . . . , m

.
This can be proved with the help of the Implicit Function Theorem (see
Theorem 4.38).
Theorem 2.39 Let S be a nonempty set in Rn and let x0 âˆˆS. Then
T (S, x0) = âˆ©
Îµ>0 cl

Î»(x âˆ’x0) : x âˆˆS âˆ©UÎµ(x0), Î» > 0

.
Proof Note that the set y = Î»(x âˆ’x0), Î» > 0, x âˆˆS, is what we have called â€œcone
generated by S âˆ’x0â€: ray(S, x0). Let us suppose that the point x0 is not an isolated
point, otherwise the property would be trivial. For a given number Îµ > 0 and a given
convergent sequence

xk
âŠ‚S \

x0
, with xk â†’x0, it holds obviously the relation
xk âˆ’x0
xk âˆ’x0 âˆˆ

Î»(x âˆ’x0) : x âˆˆS âˆ©UÎµ(x0), Î» > 0

for sufï¬ciently large k âˆˆN. Let this sequence be in particular sequentially conver-
gent, with xk
yâ†’x0, so vector y belongs (together with the related contingent cone
T (S, x0)) to the closure of all these cones and hence also to their intersection.
Conversely, let y Ì¸= 0 (we can choose y such that âˆ¥yâˆ¥= 1), with y belonging to
the said intersection, so this vector belongs also to the closure of every single cone.
For every Îµ = 1/k, with k âˆˆN sufï¬ciently large, there exists therefore a vector yk =
Î»k(xk âˆ’x0), with Î»k > 0, xk âˆˆS âˆ©U1/k(x0) and xk Ì¸= x0, such that
yk âˆ’y
 <
1/k. The expression
xk âˆ’x0
xk âˆ’x0 =
yk
yk
converges therefore to y, i.e. xk
yâ†’x0, and hence vector y belongs to T (S, x0). â–¡

50
2
Elements of Convex Analysis. Linear Theorems of the Alternative. Tangent Cones
Corollary 2.40 T (S, x0) is a closed cone.
Theorem 2.41 Let S âŠ‚Rn be a convex set and let x0 âˆˆS; then
T (S, x0) = cl

cone(S âˆ’x0)
	
= cl

ray(S âˆ’x0)
	
.
Under the said assumption T (S, x0) is therefore a closed convex cone.
Proof First we shall show that T (S, x0) âŠ‚cl(ray(S âˆ’x0)). For this, let us consider
v âˆˆT (S, x0). Then, there exists a sequence {xn} âŠ‚S, xn â†’x0, and Î»n > 0 such
that
v = lim
nâ†’âˆÎ»n(xn âˆ’x0).
Again observe that Î»n(xn âˆ’x0) âŠ‚ray(S âˆ’x0). This shows that T (S, x0) âŠ‚
cl(ray(S âˆ’x0)) = cl(cone(S âˆ’x0), being S a convex set. In order to prove the
desired result we now need to prove the opposite inclusion. In this part of the proof
the assumption of the convexity of S will play its role. Let us consider a sequence of
the following form
xn = x0 + 1
n (x âˆ’x0),
when x âˆˆS. It is easy to see that xn can also be represented as
xn = 1
n x + (1 âˆ’1
n )x0.
Since S is a convex set, we see that xn âˆˆS. So we have
xn âˆ’x0 = 1
n
x âˆ’x0 â†’0,
as n â†’âˆ. This shows that xn â†’x0. Also, from the expression of xn, we can
show that n(xn âˆ’x0) = x âˆ’x0. Taking the limit as n â†’âˆ, we see that x âˆ’x0 âˆˆ
T (S, x0). Since T (S, x0) is a cone and ray(S âˆ’x0) is the smallest cone containing
S âˆ’x0,wehavethatray(S âˆ’x0) âŠ‚T (S, x0).Sinceweknowthat T (S, x0)isclosed,
we conclude that cl

ray(S âˆ’x0)
	
âŠ‚T (S, x0). Being S convex, it holds ray(S âˆ’
x0) = cone(S âˆ’x0) and we deduce that T (S, x0) is a closed and convex cone.
â–¡
Note that the inclusion T (S, x0) âŠ‚cl

ray(S âˆ’x0)

holds without the assumption
that S is a convex set.
Deï¬nition 2.42 The normal cone N(S, x0) to a convex set S âŠ‚Rn at x0 âˆˆS is
deï¬ned as
N(S, x0) =

v âˆˆRn : vâŠ¤(x âˆ’x0) â‰¦0, âˆ€x âˆˆS

.
In other words N(S, x0) is the polar cone of the convex set (S âˆ’x0), x0 âˆˆS.

2.3 Tangent Cones
51
It turns out that the Bouligand tangent cone and the normal cone at x0 âˆˆS of the
convex set S âŠ‚Rn are polar cones of each other, i.e.
T (S, x0) = (N(S, x0))âˆ—=

w âˆˆRn : wâŠ¤v â‰¦0, âˆ€v âˆˆN(S, x0)

;
N(S, x0) = (T (S, x0))âˆ—=

v âˆˆRn : vâŠ¤w â‰¦0, âˆ€w âˆˆT (S, x0)

.
Other local cone approximations of a set S âŠ‚Rn at x0 âˆˆS are the following ones.
Deï¬nition 2.43 Let S âŠ‚Rn and x0 âˆˆS; the cone
A(S, x0) =

y âˆˆRn : âˆƒÎ´ > 0, âˆƒa path Î± : [0, Î´) â†’Rn such that
Î±(t) âˆˆS âˆ€t âˆˆ(0, Î´), Î±(0) = x0, and lim
tâ†’0+
Î±(t)âˆ’Î±(0)
t
= y

is called cone of attainable directions to S at x0 or Kuhn-Tucker tangent cone to S
at x0.
ThisconewasusedbyKuhnandTucker[16]intheirpioneeringpaperonnonlinear
programming. It can be proved that A(S, x0) is a closed cone (see, e.g., Peterson [17])
and that
A(S, x0) âŠ‚T (S, x0).
Other equivalent expressions of A(S, x0) are, for example, the following ones.
A(S, x0) =

y âˆˆRn : âˆ€N(y), âˆƒÎ» > 0, âˆ€t âˆˆ(0, Î»), âˆƒÂ¯y âˆˆN(y), such that x0 + t Â¯y âˆˆS

;
A(S, x0) =

y âˆˆRn : âˆ€{tk} âŠ‚R+, tk â†’0+, âˆƒyk â†’y, such that x0 + tk yk âˆˆS

.
Deï¬nition 2.44 Let S âŠ‚Rn and x0 âˆˆS; the cone
F(S, x0) =

y âˆˆRn : âˆƒÂ¯Î» > 0 such that x0 + ty âˆˆS, âˆ€t âˆˆ

0, Â¯Î»

is called cone of feasible directions to S at x0 or also radial cone to S at x0.
Remark 2.45 Note that F(S, x0) is a cone containing the origin but it is neither
open nor closed. It need not be convex and it holds
F(S, x0) âŠ‚A(S, x0) âŠ‚T (S, x0).
If S âŠ‚Rn is a convex set, then F(S, x0), A(S, x0) and T (S, x0) are all convex
cones and it holds
cl(F(S, x0)) = A(S, x0) = T (S, x0) = cl

cone(S âˆ’x0)
	
= cl

ray(S âˆ’x0)
	
.

52
2
Elements of Convex Analysis. Linear Theorems of the Alternative. Tangent Cones
Therefore note that if S is convex, F(S, x0) consists of the vectors y = Î±(x âˆ’x0),
with Î± > 0 and x âˆˆS.
If S is a convex polyhedron, then
T (S, x0) = cone(S âˆ’x0) = ray(S âˆ’x0).
From a geometric point of view, we can say that if y âˆˆRn is a feasible direction
at x0 with respect to S âŠ‚Rn, then we can move starting from x0 along a straight
line by a certain range of step to x0 + ty âˆˆS. The geometric meanings of attainable
and tangent directions are that, besides a straight line, x0 can be approached by a
continuous path and a sequence of points belonging to S, respectively.
References
1. M.S. Bazaraa, C.M. Shetty, Foundations of Optimization, Lecture Notes in Economic and
Mathematics Systems, vol. 122 (Springer, Berlin, 1976)
2. M. Jeter, Mathematical Programming. An Introduction to Optimization (Marcel Dekker, New
York, 1986)
3. A. Dhara, J. Dutta, Optimality Conditions in Convex Optimization. A Finite-Dimensional View
(CRC Press, Boca Raton, London, New York, 2012)
4. D.P. Bertsekas, Nonlinear Programming, 2nd edn. (Athena Scientiï¬c, Belmont, Mass, 1999)
5. D.P. Bertsekas, A. Nedic, A.E. Ozdaglar, Convex Analysis and Optimization (Athena Scien-
tiï¬c, Belmont, Mass, 2003)
6. M. Florenzano, C. Le Van, Finite Dimensional Convexity and Optimization (Springer, Berlin,
2001)
7. J.-B. Hiriart-Urruty, C. Lemarechal, Convex Analysis and Minimization Algorithms, vol. I, II
(Springer-Verlag, Berlin and New York, 1993)
8. R.T. Rockafellar, Convex Analysis (Princeton University Press, Princeton, 1970)
9. J. Palata, A survey of conical approximations used in optimization. Optimization 20, 147â€“161
(1989)
10. D. Gale, The Theory of Linear Economic Models (McGraw-Hill Book Company, New York,
1960)
11. H.A. Antosiewicz, A theorem of the alternative for pair of matrices. Pac. J. Math. 5, 641â€“642
(1955)
12. H. Nikaido, Convex Structures and Economic Theory (Academic, New York, 1968)
13. O.L. Mangasarian, Nonlinear Programming (McGraw-Hill Book Company, New York, 1969)
14. J.P. Aubin, H. Frankowska, Set-Valued Analysis (BirkhÃ¤user, Boston, 1990)
15. G. Giorgi, A. Guerraggio, J. Thierfelder, Mathematics of Optimization: Smooth and Nons-
mooth Case (Elsevier, Amsterdam, 2004)
16. H.W. Kuhn, A.W. Tucker, Nonlinear programming, in Proceedings of the Second Berkeley
Symposium on Mathematical Statistics and Probability, ed. by J. Neyman (University of
California Press, Berkeley, 1951), pp. 481â€“492. Reprinted in Giorgi and Kjeldsen (2014)
17. D.W. Peterson, A review of constraint qualiï¬cations in ï¬nite-dimensional spaces. SIAM Rev.
15, 639â€“654 (1973)

Chapter 3
Convex Functions and Generalized
Convex Functions
3.1
Convex Functions
Similarly to convex sets, convex and concave functions play a central role in mathe-
matical programming theory. Geometrically, a real-valued function deï¬ned on a con-
vex set X âŠ‚Rn is convex (concave) if the line segment connecting any two points on
the surface generated by the function nowhere lies below (above) the surface itself.
More formally, we have the following basic deï¬nition.
Deï¬nition 3.1 The function f : X âŠ‚Rn â†’R, X nonempty convex set, is said to
be convex on X if, for any two points x1, x2 âˆˆX, it holds
f (Î»1x1 + Î»2x2) â‰¦Î»1 f (x1) + Î»2 f (x2),
for all scalars Î»1 â‰§0, Î»2 â‰§0, with Î»1 + Î»2 = 1, i.e. for all x1, x2 âˆˆX it holds
f (Î»x1 + (1 âˆ’Î»)x2) â‰¦Î»f (x1) + (1 âˆ’Î») f (x2), âˆ€Î» âˆˆ[0, 1] .
(3.1)
Obviously it is equivalent to require that the inequality in (3.1) holds for all
Î» âˆˆ(0, 1). The function f is called strictly convex on X when, for any two points
x1, x2 âˆˆX, x1 Ì¸= x2, it holds
f (Î»x1 + (1 âˆ’Î»)x2) < Î»f (x1) + (1 âˆ’Î») f (x2), âˆ€Î» âˆˆ(0, 1).
(3.2)
A function f : X â†’R (X âŠ‚Rn nonempty convex set) is said to be concave
(resp. strictly concave) on X if and only if âˆ’f is convex (resp. strictly convex) on
X. In other words, the above inequalities (3.1) and (3.2) are reversed.
In what follows, in order to avoid useless repetitions, we shall refer in general only
to convex functions. The reader will remark that the set X âŠ‚Rn must be convex, in
order that the left-hand side of (3.1) and (3.2) makes sense. Note that a real-valued
Â© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al., Basic Mathematical Programming Theory, International Series
in Operations Research & Management Science 344,
https://doi.org/10.1007/978-3-031-30324-1_3
53

54
3
Convex Functions and Generalized Convex Functions
function may be simultaneously convex and concave (e.g. any function of the type
f (x) = ax, a âˆˆRn, a Ì¸= 0; see further), but a function cannot be simultaneously
strictly convex and strictly concave. Examples of strictly convex functions on R are
f (x) = x2 and f (x) = ex; the function f (x) = log x is a typical strictly concave
function on int(R+). The function f (x) = x3 is neither convex nor concave. The
function f (x) = sin x is alternatively convex and concave and, therefore, it is neither
convex nor concave on R. A more elaborated example of convex functions in Rn is
one of the following examples.
Example 3.2 The quadratic function
Ï•(x) = xâŠ¤Bx + pâŠ¤x
where B is a symmetric matrix of order n and p, x âˆˆRn (p Ì¸= 0), is convex on Rn
if and only if the matrix B is positive semideï¬nite. Indeed, we have
Ï•(Î»x + (1 âˆ’Î»)y) = Î»2xâŠ¤Bx + 2Î»(1 âˆ’Î»)xâŠ¤By + (1 âˆ’Î»)2yâŠ¤By + Î»pâŠ¤x + (1 âˆ’Î»)pâŠ¤y
= Î»Ï•(x) + (1 âˆ’Î»)Ï•(y) âˆ’Î»(1 âˆ’Î»)(x âˆ’y)âŠ¤B(x âˆ’y)
and for all Î» âˆˆ[0, 1] we have
Î»(1 âˆ’Î»)(x âˆ’y)âŠ¤B(x âˆ’y) â‰§0
if and only if B is positive semideï¬nite. This and the deï¬nition of convex functions
imply the assertion of the example.
It is obvious that for a quadratic function Ï• to be strictly convex on Rn it is
necessary and sufï¬cient that the matrix B be positive deï¬nite.
Similarly to what was said for convex sets, we have the following result.
Theorem 3.3 A function f : X âŠ‚Rn â†’R (X nonempty convex set) is convex on
X if and only if, with x1, . . . , xk any collection of elements of X, it holds
f (Î»1x1 + Â· Â· Â· + Î»kxk) â‰¦Î»1 f (x1) + Â· Â· Â· + Î»k f (xk),
for all Î»1, . . . , Î»k â‰§0, with Î»1 + Â· Â· Â· + Î»k = 1.
The above inequality is known as Jensen inequality for convex functions. Obvi-
ously, similar inequalities hold for strictly convex functions, for concave functions,
and for strictly concave functions.
A class of convex functions that plays an important role in optimization is given
by those functions called sublinear functions.
Deï¬nition 3.4 A function f : Rn â†’R is called a sublinear function if, for all
x, y âˆˆRn,

3.1 Convex Functions
55
(i)
f (x + y) â‰¦f (x) + f (y) (subadditive property);
(ii)
f (Î»x) = Î»f (x), âˆ€Î» > 0 (positive homogeneity property).
Note that for x = 0 we have f (0) = 0. It is possible to prove the following result.
Theorem 3.5 Let f : Rn â†’R be a convex function that is positively homogeneous.
Then f is a sublinear function.
Weï¬rst recall thebasicproperties of convexandconcavefunctions of onevariable,
properties useful also for characterizing convex and concave functions of several
variables. We have the following propositions.
Let Ï• : I âŠ‚R â†’R be a function deï¬ned on an open interval I.
(1) Let Ï• be differentiable on I; then Ï• is convex (concave) on I if and only if Ï•â€²(x)
is increasing (decreasing) on I.
(2) Let Ï• be twice-differentiable on I; then Ï• is convex (concave) on I if and only
if Ï•â€²â€²(x) â‰§0 (Ï•â€²â€²(x) â‰¦0) for all x âˆˆI.
(3) If Ï• is differentiable on I, then Ï• is strictly convex (strictly concave) on I if and
only if Ï•â€²(x) is strictly increasing (strictly decreasing) on I.
(4) If Ï• is twice-differentiable on I, then Ï• is strictly convex (strictly concave) on I
if Ï•â€²â€²(x) > 0 (Ï•â€²â€²(x) < 0) for all x âˆˆI. Note that here we have only a sufï¬cient
condition.
Now we describe several equivalent characterizations of convex functions of sev-
eral variables.
Theorem 3.6 Let X âŠ‚Rn be a nonempty convex set and let f : X â†’R. The follo-
wing properties are equivalent:
(a) The function f is convex on X.
(b) For every x âˆˆX and every y âˆˆRn, the function gx,y(t) â‰¡f (x + ty) is convex
on the set T (x, y) = {t : t âˆˆR, x + ty âˆˆX} .
(c) For every x1, x2 âˆˆX, the function hx1,x2(Î») â‰¡f (Î»x1 + (1 âˆ’Î»)x2) is convex on
the interval [0, 1] .
(d) The set (â€œepigraph of f â€)
epi( f ) =

(x, Î±) : (x, Î±) âˆˆX Ã— R, f (x) â‰¦Î±

is convex.
(e) Let X âŠ‚Rn be convex and open. For every x0 âˆˆX there exists u0 âˆˆRn such
that
f (x) âˆ’f (x0) â‰§(u0)âŠ¤(x âˆ’x0), âˆ€x âˆˆX.
Proof (a) â‡’(b). It is easy to see that the set T (x, y) is convex (it is an interval!).
Let t1, t2 âˆˆT (x, y) and Î» âˆˆ(0, 1). Being f convex, it holds
gx,y(tÎ») = f (x + tÎ»y) = f (Î»(x + t1y) + (1 âˆ’Î»)(x + t2y)
â‰¦Î»f (x + t1y) + (1 âˆ’Î») f (x + t2y) = Î»gx,y(t1) + (1 âˆ’Î»)gx,y(t2),

56
3
Convex Functions and Generalized Convex Functions
with tÎ» = Î»t1 + (1 âˆ’Î»)t2.
(b) â‡’(c). For every x1, x2 âˆˆX and Î» âˆˆ(0, 1) it holds
hx1,x2(Î») = f (Î»x1 + (1 âˆ’Î»)x2) = f (x2 + Î»(x1 âˆ’x2)) = gx2,x1âˆ’x2(Î»).
From the convexity of gx2,x1âˆ’x2(Î»), it results at once the convexity of hx1,x2.
(c) â‡’(d). Let (x1, z1), (x2, z2) âˆˆepi( f ) and Î» âˆˆ(0, 1). From the convexity of
hx1,x2 it holds
hx1,x2(Î») â‰¦Î»hx1,x2(1) + (1 âˆ’Î»)hx1,x2(0) = Î»f (x1) + (1 âˆ’Î») f (x2) â‰¦Î»z1 + (1 âˆ’Î»)z2,
i.e.
f (Î»x1 + (1 âˆ’Î»)x2) â‰¦Î»z1 + (1 âˆ’Î»)z2,
which proves that
Î»(x1, z1) + (1 âˆ’Î»)(x2, z2) âˆˆepi( f ).
(d) â‡’(a). Let be x1, x2 âˆˆX and Î» âˆˆ(0, 1). As (x1, f (x1)) and (x2, f (x2)) are
elements of epi( f ) and this set is convex, it results that
Î»(x1, f (x1)) + (1 âˆ’Î»)(x2, f (x2))
is an element of epi( f ). Therefore,
f (Î»x1 + (1 âˆ’Î»)x2) â‰¦Î»f (x1) + (1 âˆ’Î») f (x2).
(d) â‡’(e). Let be x0 âˆˆX. It results that (x0, f (x0)) belongs to the boundary of
the convex set epi( f ). From the supporting hyperplane theorem (see Theorem 2.19),
it results that there exists (v, v0) Ì¸= 0 such that
vâŠ¤x + v0z â‰§vâŠ¤x0 + v0 f (x0)
(3.3)
for every (x, z) âˆˆepi( f ).
We can see that v0 > 0 : if it would be v0 = 0, it would result vâŠ¤(x âˆ’x0) = 0,
which implies v = 0 and hence (v, v0) = 0, absurd. If v0 < 0, then by choosing z
sufï¬ciently large, we could obtain
vâŠ¤x + v0z < vâŠ¤x0 + v0 f (x0),
in contradiction with inequality (3.3), previously proved. Now, from inequality (3.3),
with v0 > 0, by choosing z = f (x) and with u0 = 1
v0 v, we obtain
f (x) âˆ’f (x0) â‰§(u0)âŠ¤(x âˆ’x0).

3.1 Convex Functions
57
(e) â‡’(a). Let be x1, x2 âˆˆX and Î» âˆˆ(0, 1). By multiplying the inequality
f (x1) âˆ’f (x0) â‰§(u0)âŠ¤(x1 âˆ’x0)
and the inequality
f (x2) âˆ’f (x0) â‰§(u0)âŠ¤(x2 âˆ’x0)
respectively, by Î» and (1 âˆ’Î»), we obtain
Î»f (x1) + (1 âˆ’Î») f (x2) âˆ’f (x0) â‰§(u0)âŠ¤(Î»x1 + (1 âˆ’Î»)x2 âˆ’x0).
By choosing x0 = Î»x1 + (1 âˆ’Î»)x2, from the previous inequality it results that
f is convex.
â–¡
It is useful to remark that vector u0 of characterization (e) is called a subgradient
of f (x) at x0 âˆˆX (see, e.g. Rockafellar [1] and see Sect. 10.1). The set of all
subgradients of f (x) at x0 âˆˆX is called the subdifferential of f (x) at x0 and denoted
by âˆ‚f (x0).
To motivate the geometric interpretation of these concepts we consider the convex
function f (x) = |x| , x âˆˆR. Note that at the origin (point of non-differentiability)
we may draw an inï¬nite number of non-vertical tangent lines which are in fact non-
vertical supporting hyperplanes to the epigraph of f (x). The slope of each of these
lines is in fact a subgradient of f (x) at x0 = 0. Non-subdifferentiability can however
occur on the boundary of the domain of a convex function, where a vertical supporting
hyperplane to its epigraph may exist. Consider, e.g. the function f : [0, 1] â†’[0, 1]
deï¬ned by f (x) = âˆ’âˆšx. This function is clearly convex, however âˆ‚f (0) = âˆ…. We
may, therefore, restate characterization (e) of Theorem 3.6 as:
â€¢ Let f be a real-valued function on an open convex set X âŠ‚Rn. Then f is convex
on X if and only if it has a subgradient at each point x0 âˆˆX.
From the above characterization, we get that a real-valued convex function on an
open convex subset X of Rn is subdifferentiable on X. See also Bazaraa and Shetty
[2], p. 92 or Bazaraa, Sherali, and Shetty [3]. We shall revert on these questions in
Chap. 10.
Theorem 3.7 (Equivalent characterizations of differentiable convex functions) Let
X âŠ‚Rn be an open convex set and f : X â†’R differentiable on X. The following
statements are equivalent:
(a)
f is convex on X.
(b) For every x âˆˆX and y âˆˆRn the derivative gâ€²
x,y(t) = yâŠ¤âˆ‡f (x + ty) is increas-
ing on T (x, y).
(c) For
every
x1, x2 âˆˆX
the
derivative
hâ€²
x1,x2(Î») = (x1 âˆ’x2)âŠ¤âˆ‡f (Î»x1 +
(1 âˆ’Î»)x2) is increasing on [0, 1] .

58
3
Convex Functions and Generalized Convex Functions
(d) For all x1, x2 âˆˆX it holds
f (x1) âˆ’f (x2) â‰§(x1 âˆ’x2)âŠ¤âˆ‡f (x2).
(e) For all x1, x2 âˆˆX it holds
f (x1) âˆ’f (x2) â‰¦(x1 âˆ’x2)âŠ¤âˆ‡f (x1).
(f) For all x1, x2 âˆˆX it holds
(x1 âˆ’x2)âŠ¤(âˆ‡f (x1) âˆ’âˆ‡f (x2)) â‰§0.
Proof (a) â‡”(b). From the previous theorem it results that f is convex on X if and
only if gx,y is convex on T (x, y), which is equivalent to the fact that the derivative
gâ€²
x,y(t) = yâŠ¤âˆ‡f (x + ty) is increasing on T (x, y).
(a) â‡”(c). Again from the previous theorem, it results that f is convex on X if
and only if hx1,x2 is convex on [0, 1] , which is equivalent to the fact that the derivative
hâ€²
x1,x2(Î») = (x1 âˆ’x2)âŠ¤âˆ‡f (Î»x1 + (1 âˆ’Î»)x2) of hx1,x2 is increasing on [0, 1] .
(c) â‡’(d). As hâ€²
x1,x2(Î») is increasing on [0, 1] , it results for every Î» âˆˆ[0, 1] ,
hâ€²
x1,x2(0) â‰¦hâ€²
x1,x2(Î»)
and, therefore,
(x1 âˆ’x2)âŠ¤âˆ‡f (x2) â‰¦(x1 âˆ’x2)âŠ¤âˆ‡f (Î»x1 + (1 âˆ’Î»)x2).
From Taylorâ€™s formula (ï¬rst-order expansion) we get
f (x1) âˆ’f (x2) = (x1 âˆ’x2)âŠ¤âˆ‡f (Î¸x1 + (1 âˆ’Î¸)x2),
0 â‰¦Î¸ â‰¦1.
The result follows from the last two inequalities, with Î» = Î¸.
(d) â‡’(e). For every x1, x2 âˆˆX we can write
f (x1) âˆ’f (x2) = âˆ’( f (x2) âˆ’f (x1)) â‰¦âˆ’(x2 âˆ’x1)âŠ¤âˆ‡f (x1),
i.e.
f (x1) âˆ’f (x2) â‰¦(x1 âˆ’x2)âˆ‡f (x1).
(e) â‡’( f ). By summing the following two inequalities
f (x1) âˆ’f (x2) â‰¦(x1 âˆ’x2)âˆ‡f (x1);
f (x2) âˆ’f (x1) â‰¦âˆ’(x1 âˆ’x2)âˆ‡f (x2),

3.1 Convex Functions
59
we have the desired result.
( f ) â‡’(c). For any x1, x2 âˆˆX and any Î»1, Î»2 âˆˆ[0, 1] , with Î»1 < Î»2, we can
write
hâ€²
x1,x2(Î»2) âˆ’hâ€²
x1,x2(Î»1) = (x1 âˆ’x2)âŠ¤âˆ‡f (Î»2x1 + (1 âˆ’Î»2)x2)
âˆ’(x1 âˆ’x2)âŠ¤âˆ‡f (Î»1x1 + (1 âˆ’Î»1)x2).
Let us denote y1 = Î»1x1 + (1 âˆ’Î»1)x2 and y2 = Î»2x1 + (1 âˆ’Î»2)x2. It results
that y1, y2 âˆˆX and that
y1 âˆ’y2 = (Î»1 âˆ’Î»2)(x1 âˆ’x2).
Therefore,
hâ€²
x1,x2(Î»2) âˆ’hâ€²
x1,x2(Î»1) =
1
Î»1 âˆ’Î»2
(y1 âˆ’y2)âŠ¤(âˆ‡f (y2) âˆ’âˆ‡f (y1))
=
1
Î»2 âˆ’Î»1
(y2 âˆ’y1)âŠ¤(âˆ‡f (y2) âˆ’âˆ‡f (y1)) â‰§0,
and hence hâ€²
x1,x2(Î») is increasing on [0, 1].
â–¡
We are now concerned with the characterization of twice-continuously differen-
tiable convex functions, i.e. functions belonging to the C 2 class.
Theorem 3.8 Let f be C 2 on the open convex set X âŠ‚Rn. Then f is convex on X
if and only if its Hessian matrix âˆ‡2 f (x) is positive semideï¬nite for every x âˆˆX.
Proof (1) Let âˆ‡2 f (x) be positive semideï¬nite for all x âˆˆX. By Taylorâ€™s formula
(second-order expansion) we can write
f (x1) âˆ’f (x2) = (x1 âˆ’x2)âŠ¤âˆ‡f (x2) + 1
2(x1 âˆ’x2)âŠ¤âˆ‡2 f (xÎ¸)(x1 âˆ’x2),
with xÎ¸ = Î¸x1 + (1 âˆ’Î¸)x2, Î¸ âˆˆ(0, 1).
Being âˆ‡2 f (x) positive semideï¬nite for all x âˆˆX, we have
f (x1) âˆ’f (x2) â‰§(x1 âˆ’x2)âŠ¤âˆ‡f (x2), âˆ€x1, x2 âˆˆX.
(2) Let f be convex on X. We have (Theorem 3.7) that gâ€²
x,y(t) = yâŠ¤âˆ‡f (x + ty) is
increasing on T (x, y) = {t : t âˆˆR, x + ty âˆˆX} . Being f âˆˆC 2(X), also gx,y
is twice differentiable on T (x, y). It holds, therefore, that gâ€²â€²
x,y(t) â‰§0 for all
t âˆˆT (x, y), i.e.
yâŠ¤âˆ‡2 f (x + ty)y â‰§0
for all t âˆˆT (x, y). In particular, for t = 0 âˆˆT (x, y), we get

60
3
Convex Functions and Generalized Convex Functions
yâŠ¤âˆ‡2 f (x)y â‰§0
for all y âˆˆRn and for all xâˆˆX, i.e. âˆ‡2 f (x) is positive semideï¬nite for all x âˆˆX.
â–¡
The previous results can be easily transferred to the case of concave functions (of
several variables).
For what concerns strictly convex functions we have the following results.
Theorem 3.9 Let be f : X âŠ‚Rn â†’R, with X nonempty convex set. The following
statements are equivalent:
(a)
f is strictly convex on X, i.e.
f (Î»x1 + (1 âˆ’Î»)x2) < Î»f (x1) + (1 âˆ’Î») f (x2), âˆ€x1, x2 âˆˆX, x1 Ì¸= x2, âˆ€Î» âˆˆ(0, 1).
(b) For any x âˆˆX and y âˆˆRn, y Ì¸= 0, the function gx,y(t) = f (x + ty) is strictly
convex on the interval T (x, y) = {t âˆˆR : x + ty âˆˆX} .
(c) The function hx1,x2(Î») = f (Î»x1 + (1 âˆ’Î»)x2) is strictly convex on the interval
[0, 1] .
Theorem 3.10 Let f : X âŠ‚Rn â†’R be differentiable on the open convex set X.
The following statements are equivalent:
(a)
f is strictly convex on X.
(b)
f (x1) âˆ’f (x2) > (x1 âˆ’x2)âŠ¤âˆ‡f (x2), âˆ€x1, x2 âˆˆX, x1 Ì¸= x2.
(c)
f (x1) âˆ’f (x2) < (x1 âˆ’x2)âŠ¤âˆ‡f (x1), âˆ€x1, x2 âˆˆX, x1 Ì¸= x2.
(d) (x1 âˆ’x2)âŠ¤
âˆ‡f (x1) âˆ’âˆ‡f (x2)

> 0, âˆ€x1, x2 âˆˆX, x1 Ì¸= x2.
Theorem 3.11 Let f : X âŠ‚Rn â†’R be C 2 on the open convex set X. Then f is
strictly convex on X if âˆ‡2 f (x) is positive deï¬nite for all x âˆˆX.
We note that Theorem 3.11 gives only sufï¬cient conditions for f âˆˆC 2 to be
strictly convex. Indeed, if we consider, for example, the function f (x) = x4, x âˆˆR,
or also f (x) = (x1)4 + (x2)4, x âˆˆR2, we can see that these functions are strictly
convex on R (on R2) but the second-order derivative evaluated at x = 0 (the Hessian
matrix evaluated at 0 âˆˆR2) is zero (is the zero matrix). A weaker sufï¬cient condition
for the strict convexity of C 2-functions is (see, e.g. Fenchel [4]).
TheHessianmatrixâˆ‡2 f (x)ispositivesemideï¬niteforall x âˆˆX anddet(âˆ‡2 f (x))
Ì¸= 0 on all segments contained in X.
However, note that for quadratic functions
Ï•(x) = xâŠ¤Bx + pâŠ¤x
the positive deï¬niteness of the matrix B is necessary and sufï¬cient for Ï• to be strictly
convex (see the last lines of Example 3.2).
We give now a necessary condition for the convexity of a function deï¬ned on a
nonempty convex set X âŠ‚Rn. This condition will be useful in characterizing a class
of generalized convex functions: the class of quasiconvex functions.

3.1 Convex Functions
61
Theorem 3.12 Let X âŠ‚Rn be a nonempty convex set and f : X âŠ‚Rn â†’R be
convex on X. Then the lower level set
levâ‰¦Î± f =

x âˆˆX : f (x) â‰¦Î±

is convex for all Î± âˆˆR.
Proof Let x1, x2 âˆˆX and Î» âˆˆ[0, 1] . As X is a convex set, it results xÎ» â‰¡Î»x1 +
(1 âˆ’Î»)x2 âˆˆX. From the convexity of f we obtain
f (xÎ») â‰¦Î»f (x1) + (1 âˆ’Î») f (x2) â‰¦Î»Î± + (1 âˆ’Î»)Î± = Î±.
Being Î± âˆˆlevâ‰¦Î± f, this shows the convexity of levâ‰¦Î± f, for every Î± âˆˆR (we
recall that the empty set âˆ…is convex by deï¬nition).
â–¡
As we have remarked, the proposition of Theorem 3.12 is only a necessary condi-
tion for the convexity of f : X â†’R (X âŠ‚Rn convex set). Consider, for example, the
function f (x) = log x, x âˆˆR, x > 0, which is not convex (it is strictly concave!),
but which satisï¬es the condition of Theorem 3.12. It is the same for f (x) = x3,
x âˆˆR, for f (x) = min(x, 2x), x âˆˆR, etc.
A similar result holds obviously for concave functions: the upper level set
levâ‰§Î± f =

x âˆˆX : f (x) â‰§Î±

is convex for all Î± âˆˆR.
Theorem 3.13 Let X âŠ‚Rn be an open convex set. If f : X â†’R is convex on X,
then f is continuous on X.
Proof We prove the theorem in three steps.
Step1.If f isconvexon X and x1, . . . , xk âˆˆX andÎ»1, . . . , Î»k â‰§0andk
j=1 Î» j =
1, then (Jensen inequality)
f
â›
â
k
	
j=1
Î» jx j
â
â â‰¦
k
	
j=1
Î» j f (x j).
Step 2. For each x âˆˆX, there exists a Î² > 0 such that x Â± Î²ei âˆˆX, for i =
1, . . . , n, where ei is the unit vector. Call these vectors z1, . . . , z2n. Let be Mx =
max

f (z1), . . . , f (z2n)

.Since x liesintheinterioroftheconvexhullof z1, . . . , z2n,
there exists tx > 0 such that U(x, tx) =

y : âˆ¥y âˆ’xâˆ¥â‰¦tx

also lies in the con-
vex hull of z1, . . . , z2n. Then, for any y satisfying âˆ¥y âˆ’xâˆ¥â‰¦tx it holds that
y = 2n
j=1 Î» jz j for some appropriate Î»1, . . . , Î»2n â‰§0 and 2n
j=1 Î» j = 1 and so
f (y) = f
â›
â
2n
	
j=1
Î» jz j
â
â â‰¦
2n
	
j=1
Î» j f (z j) â‰¦Mx.

62
3
Convex Functions and Generalized Convex Functions
Step 3. Without loss of generality, we assume that f (0) = 0 and we want to prove
that f (x) is continuous at x = 0. For any Îµ > 0, we must exhibit a Î´ > 0 such that if
âˆ¥yâˆ¥< Î´ then âˆ’Îµ â‰¦f (y) â‰¦Îµ. Let t > 0 and M be chosen so that âˆ¥yâˆ¥â‰¦t implies
f (y) â‰¦M (from Step 2). Now let be Î´ = tÎµ/M. Let y satisfy âˆ¥yâˆ¥< Î´. Also, we
can assume that M > Îµ and write
y =

1 âˆ’Îµ
M

0 +
 Îµ
M
  M
Îµ y

.
Since
Â± M
Îµ y
 = M
Îµ âˆ¥yâˆ¥< t, it follows that f

Â± M
Îµ y

â‰¦M. Therefore,
f (y) â‰¦

1 âˆ’Îµ
M

f (0) +
 Îµ
M

f
 M
Îµ y

â‰¦0 + Îµ
M M = Îµ.
We also have
0 =
Îµ
M
1 + Îµ
M

âˆ’M
Îµ y

+
1
1 + Îµ
M
y,
and so
0 = f (0) â‰¦
Îµ
M
1 + Îµ
M
f

âˆ’M
Îµ y

+
1
1 + Îµ
M
f (y) â‰¦
Îµ
M
1 + Îµ
M
M +
f (y)
1 + Îµ
M
.
Therefore, f (y) â‰§âˆ’Îµ and so âˆ’Îµ â‰¦f (y) â‰¦Îµ.
â–¡
From the previous theorem, it appears that if f is convex on X âŠ‚Rn, X convex
but not necessarily open, and if f has discontinuity points, these points are on the
boundary of X. Consider the following example:
X =

x âˆˆR, x â‰§0

,
f : X â†’R deï¬ned as
f (x) =
 x2, for x > 0,
1,
for x = 0.
It results that f is convex on X, with a discontinuity point at x = 0.
For what concerns the differentiability of convex functions, we report the follo-
wing results (see, e.g. Fenchel [4]).
Theorem 3.14 If f : X âŠ‚Rn â†’R is convex on the open convex set X, then f is
differentiable with continuous partial derivatives (i.e. f âˆˆC 1) everywhere on X,
except for a set of measure zero (in Lebesgueâ€™s sense).
Hence a convex function f : X âŠ‚Rn â†’R, X open convex set, may be non-
differentiable at some points x âˆˆX. Consider, e.g. the convex function f (x) = |x| ,
x âˆˆR, obviously non-differentiable at x = 0.

3.1 Convex Functions
63
Theorem 3.15 Let X âŠ‚Rn be a convex set and f : X â†’R be convex on X. Then
(a)
f is bounded on every compact subset Y âŠ‚int(X).
(b)
f is bounded from below on every bounded subset Y âŠ‚int(X).
An afï¬ne function is obviously both convex and concave (but not in the strict
sense!) on a convex set X âŠ‚Rn. Also the vice-versa holds, as shown by the following
(a bit less trivial) result.
Theorem 3.16 Let X âŠ‚Rn be a convex set and let be f : X â†’R. If f is both
convex and concave on X, then f is linear afï¬ne on X, i.e.
f (Î¼x1 + (1 âˆ’Î¼)x2) = Î¼f (x1) + (1 âˆ’Î¼) f (x2),
for any x1, x2 âˆˆX and any Î¼ âˆˆR such that Î¼x1 + (1 âˆ’Î¼)x2 âˆˆX.
Proof Being f both convex and concave on X, it results, for any x1, x2 âˆˆX and for
all Î» âˆˆ[0, 1] ,
f (Î»x1 + (1 âˆ’Î»)x2) = Î»f (x1) + (1 âˆ’Î») f (x2).
Let now Î¼ âˆˆR such that x = Î¼x1 + (1 âˆ’Î¼)x2 âˆˆX and let be x0 = 1
2(x1 + x2).
If we choose Î» sufï¬ciently small such that the inequality Î» |2Î¼ âˆ’1| < 1 is veriï¬ed,
it results that 0 < Î»Î¼ + (1 âˆ’Î»)/2 < 1 and hence
Î»(Î¼f (x1) + (1 âˆ’Î¼) f (x2)) + (1 âˆ’Î») f (x0)
=

Î»Î¼ + 1 âˆ’Î»
2

f (x1) +

Î»(1 âˆ’Î¼) + 1 âˆ’Î»
2

f (x2)
= f

Î»Î¼ + 1 âˆ’Î»
2

x1 +

Î»(1 âˆ’Î¼) + 1 âˆ’Î»
2

x2

= Î»f (x) + (1 âˆ’Î») f (x0).
From here, we derive the desired property f (x) = Î¼f (x1) + (1 âˆ’Î¼) f (x2).
â–¡
We have seen that if f : X âŠ‚Rn â†’R is convex on the convex set X, then f
is continuous on int(X). We remark again that f may be non-differentiable on
int(X), however, convex functions possess some nice properties concerning direc-
tional derivatives.
Let f be a real-valued function deï¬ned on an open set X âŠ‚Rn. The (one-sided)
directional derivative of f at x0 âˆˆX in the direction of y âˆˆRn, denoted Df (x0, y)
or also Dy f (x0), or f â€²(x0, y), etc., is given by
Df (x0, y) = lim
Î»â†’0+
f (x0 + Î»y) âˆ’f (x0)
Î»
,
if the limit exists (+âˆand âˆ’âˆbeing allowed as limits).

64
3
Convex Functions and Generalized Convex Functions
Note that
âˆ’Df (x0, âˆ’y) = lim
Î»â†’0âˆ’
f (x0 + Î»y) âˆ’f (x0)
Î»
.
If Df (x0, y) = âˆ’Df (x0, âˆ’y), then f is said to be a two-sided directional deriva-
tive at x0 in the direction of y, i.e. the limit
lim
Î»â†’0
f (x0 + Î»y) âˆ’f (x0)
Î»
exists (ï¬nite or not).
If f has a two-sided directional derivative in all directions at x0, then f is said
to be GÃ¢teaux differentiable at x0. We recall that if f : Rn â†’R is differentiable
at x0, then f is GÃ¢teaux differentiable at x0, with ï¬nite derivative, for all y âˆˆRn.
Moreover,
Df (x0, y) = âˆ‡f (x0)âŠ¤y.
We have the following basic results (see, e.g. Delfour [5], Rockafellar [1], Roberts
and Varberg [6], Ruszczynski [7]).
Theorem 3.17 Let f : X âŠ‚Rn â†’R be a convex function on the convex set X.
Then, for every x âˆˆX and every y âˆˆRn, the directional derivative Df (x, y) exists
(ï¬nite or inï¬nite). If x âˆˆint(X), then Df (x, y) is ï¬nite for all y âˆˆRn. Moreover,
Df (x, y) is a positively homogeneous convex function of y, with
âˆ’Df (x, âˆ’y) â‰¦Df (x, y).
We can summarize in the following proposition what was previously asserted.
â€¢ Let f : X âŠ‚Rn â†’R be a convex function on the open convex set X; then:
(a) f admits ï¬nite one-sided directional derivatives for all directions y âˆˆRn at any
point x âˆˆX. Therefore, f admits left- and right-sided partial derivatives at any
point x âˆˆX.
(b) At all points x âˆˆX, where there exists the gradient âˆ‡f (x), then f is continu-
ously differentiable.
We shall revert on these questions in Chap. 10.
3.2
Generalized Convex Functions
Several generalizations of the classical concept of a convex function have been intro-
duced in the literature; under the name of â€œgeneralized convex functionsâ€ we mean
functions that are not convex but that retains some of the nice properties and char-
acteristics of convex functions. For good accounts of generalized convex functions

3.2 Generalized Convex Functions
65
one may consult the books quoted in the References, e.g. Bertsekas [8], Cambini and
Martein [9], Hadjisavvas et al. [10].
We have seen in Theorem 3.12 that a necessary (but not sufï¬cient) conditions for
f : X âŠ‚Rn â†’R to be convex on the convex set X âŠ‚Rn, is:
â€¢ The lower level set
levâ‰¦Î± f =

x âˆˆX : f (x) â‰¦Î±

is convex for all Î± âˆˆR.
This property becomes one of the characterizations of the class of quasiconvex
functions.
Deï¬nition 3.18 Let be given f : X âŠ‚Rn â†’R and deï¬ned on the convex set X.
Then f is said to be quasiconvex on X if
f (Î»x1 + (1 âˆ’Î»)x2) â‰¦max

f (x1), f (x2)

, for all x1, x2 âˆˆX, for all Î» âˆˆ[0, 1] .
Obviously, the above relation is equivalent to:
f (x2) â‰¦f (x1) â‡’f (Î»x1 + (1 âˆ’Î»)x2) â‰¦f (x1), âˆ€x1, x2 âˆˆX, âˆ€Î» âˆˆ[0, 1] .
The function f : X âŠ‚Rn â†’R is quasiconcave on the convex set X if and only
if âˆ’f is quasiconvex on X.
Theorem 3.19 Let X âŠ‚Rn be a nonempty convex set and let f : X â†’R. The follo-
wing statements are equivalent:
(a)
f is quasiconvex on X.
(b) For any x âˆˆX and any y âˆˆRn the function gx,y(t) = f (x + ty) is quasiconvex
on the interval
T (x, y) = {t : t âˆˆR, x + ty âˆˆX} .
(c) For any x1, x2 âˆˆX the function hx1,x2(Î») = f (Î»x1 + (1 âˆ’Î»)x2) is quasiconvex
on [0, 1] .
(d) For any Î± âˆˆR the lower level set
levâ‰¦Î± f =

x âˆˆX : f (x) â‰¦Î±

is convex.
Proof (a) â‡’(b) â‡’(c). The proof is similar to the one for the corresponding impli-
cations in Theorem 3.6.
(c) â‡’(d). Let x1, x2 âˆˆlevâ‰¦Î± f and Î» âˆˆ[0, 1] . From the quasiconvexity of
hx1,x2(Î») it results
hx1,x2(Î») â‰¦max

hx1,x2(1), hx1,x2(0)

,

66
3
Convex Functions and Generalized Convex Functions
i.e.
f (Î»x1 + (1 âˆ’Î»)x2) â‰¦max

f (x1), f (x2)

â‰¦Î±
and, therefore, Î»x1 + (1 âˆ’Î»)x2 âˆˆlevâ‰¦Î± f, i. e. levâ‰¦Î± f is a convex set. Recall that
âˆ…is convex by deï¬nition.
(d) â‡’(a). Let x1, x2 âˆˆX and Î» âˆˆ[0, 1] and let Î± = max

f (x1), f (x2)

. As
x1, x2 âˆˆlevâ‰¦Î± f , and levâ‰¦Î± f is a convex set, it results that (Î»x1 + (1 âˆ’Î»)x2) âˆˆ
levâ‰¦Î± f, that is
f (Î»x1 + (1 âˆ’Î»)x2) â‰¦Î±,
i.e. f is quasiconvex on X.
â–¡
Now we characterize the class of differentiable quasiconvex functions.
Theorem 3.20 Let f : X âŠ‚Rn â†’R be differentiable on the open convex set X.
Then the following statements are equivalent:
(a)
f is quasiconvex on X.
(b) x1, x2 âˆˆX, f (x1) â‰¦f (x2) â‡’(x1 âˆ’x2)âŠ¤âˆ‡f (x2) â‰¦0.
(c) x1, x2 âˆˆX, (x1 âˆ’x2)âŠ¤âˆ‡f (x2) > 0 â‡’f (x1) > f (x2).
(d) x1, x2 âˆˆX, f (x1) < f (x2) â‡’(x1 âˆ’x2)âŠ¤âˆ‡f (x2) â‰¦0.
Proof (a) â‡’(b). Let f be quasiconvex on X, i.e. for any x1, x2 âˆˆX, the function
hx1,x2(Î») = f (Î»x1 + (1 âˆ’Î»)x2), Î» âˆˆ[0, 1] ,
is quasiconvex on [0, 1] . Let be f (x1) â‰¦f (x2). It results
hx1,x2(Î») â‰¦max

hx1,x2(1), hx1,x2(0)

= hx1,x2(0),
which shows that hx1,x2 has at Î» = 0 a global maximum point on [0, 1] . Being f
differentiable on the open and convex set X, it results that hx1,x2 is differentiable on
[0, 1] and, therefore, it must be
hâ€²
x1,x2(0) â‰¦0
i.e.
(x1 âˆ’x2)âŠ¤âˆ‡f (x2) â‰¦0.
(b) â‡’(a). Let x1, x2 âˆˆX with f (x1) â‰¦f (x2). It is sufï¬cient to prove that hx1,x2
has at Î» = 0 a global maximum point on [0, 1] . Let us absurdly suppose that this
property does not hold; it results then that the set
A =

Î» : Î» âˆˆ(0, 1), hx1,x2(Î») > hx1,x2(0)

is nonempty. Moreover, as hx1,x2 is differentiable, it results that it is continuous and
that A is open. It follows that Î»0 = sup(A) /âˆˆA and hence hx1,x2(Î»0) â‰¦hx1,x2(0).

3.2 Generalized Convex Functions
67
Now we show that hx1,x2 is constant on A. As Î» âˆˆA, it results hx1,x2(Î») > hx1,x2(0)
and, therefore, f (x2) < f (xÎ»), with xÎ» = Î»x1 + (1 âˆ’Î»)x2. From the assumption
we obtain
(x2 âˆ’xÎ»)âŠ¤âˆ‡f (xÎ») â‰¦0.
Similarly, as f (x1) â‰¦f (x2) < f (xÎ»), we get
(x1 âˆ’xÎ»)âŠ¤âˆ‡f (xÎ») â‰¦0.
The last two inequalities can be written in the form
(1 âˆ’Î»)(x1 âˆ’x2)âŠ¤âˆ‡f (xÎ») â‰¦0
and
âˆ’Î»(x1 âˆ’x2)âŠ¤âˆ‡f (xÎ») â‰¦0,
from which we get
hâ€²
x1,x2(Î») = (x1 âˆ’x2)âŠ¤âˆ‡f (xÎ») = 0,
which shows that hx1,x2 is constant on A. Therefore, it results
lim
Î»â†’Î»0, Î»âˆˆA hx1,x2(Î») > hx1,x2(0) â‰§hx1,x2(Î»0),
which is absurd, being hx1,x2 continuous at Î»0.
(b) â‡”(c). Trivial.
(b) â‡”(d). Property (d) follows immediately from (b). For the converse, see [11].
â–¡
Another useful class of generalized convex functions, originally introduced by O.
L. Mangasarian for differentiable functions, is the class of pseudoconvex functions.
Deï¬nition 3.21 Let X âŠ‚Rn be an open set and let f : X â†’R be differentiable on
X. Then f is pseudoconvex on X if
x1, x2 âˆˆX, (x1 âˆ’x2)âŠ¤âˆ‡f (x2) â‰§0 â‡’f (x1) â‰§f (x2),
or equivalently,
x1, x2 âˆˆX,
f (x1) < f (x2) â‡’(x1 âˆ’x2)âŠ¤âˆ‡f (x2) < 0.
The function f : X â†’R is pseudoconcave on X if and only if âˆ’f is pseudoconvex
on X.
In order to compare pseudoconvex functions with other classes of generalized
convex functions, it is convenient to assume that X âŠ‚Rn is open and convex.

68
3
Convex Functions and Generalized Convex Functions
Deï¬nition 3.22 Let be f : X âŠ‚Rn â†’R, with X nonempty convex set. Then f is
said to be semistrictly quasiconvex on X if
f (Î»x1 + (1 âˆ’Î»)x2) < max

f (x1), f (x2)

for every x1 Ì¸= x2 âˆˆX, with f (x1) Ì¸= f (x2) and for every Î» âˆˆ(0, 1).
It can be proved that Deï¬nition 3.22 is equivalent to: for every x1, x2 âˆˆX, one
has
f (x1) < f (x2) â‡’f (Î»x1 + (1 âˆ’Î»)x2) < f (x2), âˆ€Î» âˆˆ(0, 1).
We have to point out that in the literature semistrictly quasiconvex functions are
also called strictly quasiconvex functions and that also other denominations have
been used.
Theorem 3.23 Let X âŠ‚Rn beanonemptyconvexsetand f : X â†’Rbesemistrictly
quasiconvex on X and lower semi-continuous on X. Then f is quasiconvex on X.
Proof Let x1, x2 âˆˆX and let us suppose that it holds f (x1) â‰¦f (x2). If f (x1) <
f (x2), the thesis is immediate. If f (x1) = f (x2), we have to prove that
f (x) â‰¦max

f (x1), f (x2)

= f (x1) = f (x2),
for every x of the segment (x1, x2) =

x : x = Î»x1 + (1 âˆ’Î»)x2, Î» âˆˆ(0, 1)

. Let
us absurdly suppose the opposite case. It results that the set
A =

x âˆˆ

x1, x2
: f (x) > f (x1)

is nonempty. From the semistrict quasiconvexity of f, it results, therefore, that for
every x of the segment

x1, x2
=

x : x = Î»x1 + (1 âˆ’Î»)x2, Î» âˆˆ[0, 1]

and for
every y âˆˆA \ {x} , we have f (x) < f (y). On the other hand, from the lower semi-
continuity of f, it results that A is open relatively to the segment (x1, x2) and,
therefore, there exist y1, y2 âˆˆA, with y1 Ì¸= y2. Hence it results f (y1) < f (y2) and
f (y1) > f (y2), which is absurd.
â–¡
Remark 3.24 We note that in Theorem 3.23 if the assumption on lower semi-
continuity is missing, the implication does not hold. For instance, the function
f (x) =
1
if x = 0,
0
if x Ì¸= 0,
is semistrictly quasiconvex, but not quasiconvex. Obviously, there are functions
which are quasiconvex, but not semistrictly quasiconvex (for example a monotone
function on R, which is constant on some open interval).
We now point out the relationships among the classes of convex and generalized
convex functions previously introduced.

3.2 Generalized Convex Functions
69
Theorem 3.25 Let X âŠ‚Rn be a nonempty convex set and let be f : X â†’R.
(i) If f is strictly convex on X, then f is convex on X.
(ii) If f is convex on X, then f is semistrictly quasiconvex on X; if f is semistrictly
quasiconvex on X and it is also lower semi-continuous on X, then f is quasi-
convex on X.
Proof Implication (i) and the ï¬rst implication of (ii) follow directly from the deï¬-
nitions. The second implication of (ii) is the thesis of Theorem 3.23.
â–¡
Theorem 3.26 Let X âŠ‚Rn be an open convex set and let f : X â†’R be differen-
tiable on X.
(i) If f is convex on X, then f is pseudoconvex on X.
(ii) If f is pseudoconvex on X, then f is semistrictly quasiconvex on X and hence
also quasiconvex on X.
Proof (i) Let x1, x2 âˆˆX, with f (x1) < f (x2). Being f convex (and differentiable)
on X, by Theorem 3.7 we have
f (x1) âˆ’f (x2) â‰§(x1 âˆ’x2)âŠ¤âˆ‡f (x2)
and hence
(x1 âˆ’x2)âŠ¤âˆ‡f (x2) < 0,
which proves that f is pseudoconvex.
(ii) Let us prove ï¬rst that if f is pseudoconvex on X, then f is semistrictly
quasiconvex on X. Assume, on the contrary that f is not semistrictly quasiconvex.
Then, there exist x1, x2 âˆˆX, x1 Ì¸= x2, and Â¯z âˆˆ(x1, x2) such that
f (Â¯z) â‰§f (x2) > f (x1).
(3.4)
By pseudoconvexity of f we have
(x1 âˆ’Â¯z)âŠ¤âˆ‡f (Â¯z) < 0.
(3.5)
As Â¯z âˆˆ(x1, x2) one has Â¯z = Î»x1 + (1 âˆ’Î»)x2 for some Î» âˆˆ(0, 1), and so
x1 âˆ’Â¯z = x1 âˆ’Î»x1 âˆ’(1 âˆ’Î»)x2 = (1 âˆ’Î»)(x1 âˆ’x2).
Also, Â¯z = x2 + Î»(x1 âˆ’x2), i.e. x2 âˆ’Â¯z = âˆ’Î»(x1 âˆ’x2). Therefore,
x1 âˆ’Â¯z = âˆ’(1 âˆ’Î»)(x2 âˆ’Â¯z)/Î».
From here, using (3.5), we obtain
(x2 âˆ’Â¯z)âŠ¤âˆ‡f (Â¯z) > 0.

70
3
Convex Functions and Generalized Convex Functions
As limtâ†’0+ 
f

Â¯z + t(x2 âˆ’Â¯z)

âˆ’f (Â¯z)

/t = (x2 âˆ’Â¯z)âŠ¤âˆ‡f (Â¯z) > 0, there exists
Î¼ âˆˆ(0, 1) such that Ë†z = Î¼Â¯z + (1 âˆ’Î¼)x2 âˆˆ(Â¯z, x2) and f (Ë†z) > f (Â¯z), and so f (Ë†z) >
f (Â¯z) â‰§f (x2) by (3.4). Again by pseudoconvexity of f applied to the pairs (Ë†z, x2)
and (Ë†z, Â¯z), we have
(x2 âˆ’Ë†z)âŠ¤âˆ‡f (Ë†z) < 0 and (Â¯z âˆ’Ë†z)âŠ¤âˆ‡f (Ë†z) < 0.
(3.6)
From Ë†z = Î¼Â¯z + (1 âˆ’Î¼)x2, reasoning as above, we get Â¯z âˆ’Ë†z = âˆ’(1 âˆ’Î¼)(x2 âˆ’
Ë†z)/Î¼, but this equality is incompatible with (3.6). Thus f is semistrictly quasi-
convex. Since a differentiable function is continuous, it follows, from Theorem 3.23,
that f is also a quasiconvex function.
â–¡
The next result is due mainly to Crouzeix and Ferland [12].
Theorem 3.27 Let X âŠ‚Rn be an open convex set and let f : X â†’R be differentia-
bleandquasiconvexon X.Then f is pseudoconvexon X if andonlyif everystationary
point x0 of f, i.e. any point x0 âˆˆX with âˆ‡f (x0) = 0, is a global minimum point of
f over X.
Corollary 3.28 Let X âŠ‚Rn be an open convex set and let f : X â†’R be differen-
tiable on X, with âˆ‡f (x) Ì¸= 0, âˆ€x âˆˆX. Then f is pseudoconvex on X if and only if
f is quasiconvex on X.
The above inclusion relationships are all strict. For example,
â€¢ f (x) = |x| , x âˆˆR, is convex, but not strictly convex.
â€¢ f (x) =
x2
1+x2 , x âˆˆR, is pseudoconvex, but not convex. A more important exam-
ple of a pseudoconcave function which is not concave is the probability density
function of a standardized random variable with a normal (Gaussian) distribution:
f (x) =
1
âˆš
2Ï€
eâˆ’x2
2 .
â€¢ f (x) = x3, x âˆˆR, is semistrictly quasiconvex (and also quasiconvex), but not
pseudoconvex.
â€¢
f (x) =
 0
if 0 â‰¦x â‰¦1
âˆ’(x âˆ’1)2 if 1 â‰¦x â‰¦2,
is quasiconvex, but not semistrictly quasiconvex.
There are also conditions (necessary or sufï¬cient, or both) for quasiconvexity and
pseudoconvexity of C 2-functions. We report only the following ones.
Theorem 3.29 The following equivalent conditions are necessary for the C 2-
function f : X âŠ‚Rn â†’R to be quasiconvex on the open convex set X.

3.2 Generalized Convex Functions
71
(a) x âˆˆX, yâŠ¤âˆ‡f (x) = 0 â‡’yâŠ¤âˆ‡2 f (x)y â‰§0.
(b) x âˆˆX and the equation

âˆ‡2 f (x) âˆ’Î»I
âˆ‡f (x)
âˆ‡f (x)âŠ¤
0
 = 0,
of degree (n âˆ’1) in Î», has nonnegative roots.
Theorem 3.30 Thefollowingequivalentconditionsaresufï¬cientfortheC 2-function
f : X âŠ‚Rn â†’R to be pseudoconvex on the open convex set X.
(i) x âˆˆX, y Ì¸= 0, yâŠ¤âˆ‡f (x) = 0 â‡’yâŠ¤âˆ‡2 f (x)y > 0.
(ii) The matrix

âˆ‡2 f (x) + Î»âˆ‡f (x)âˆ‡f (x)âŠ¤
is positive deï¬nite for Î» sufï¬ciently large, for all x âˆˆX.
The following results give the necessary and sufï¬cient conditions for the quasi-
convexity and pseudoconvexity of a C 2-function on the open convex set X âŠ‚Rn.
Theorem 3.31 Assume that f : X âŠ‚Rn â†’R is a C 2-function on the open convex
set X. Then:
(i)
f is pseudoconvex on X if and only if:
(a) x âˆˆX, yâŠ¤âˆ‡f (x) = 0 â‡’yâŠ¤âˆ‡2 f (x)y â‰§0, and
(b) x âˆˆX, âˆ‡f (x) = 0 â‡’f achieves its minimum at x.
(ii)
f is quasiconvex on X if and only if:
(aâ€²) The previous condition (a) holds, and
(bâ€²) x âˆˆX, âˆ‡f (x) = 0 â‡’âˆ€h âˆˆRn the function Ï•(t) = f (x + th) is quasicon-
vex.
There are many other deï¬nitions of generalized convex functions, more or less
useful and meaningful. We mention only the preinvex functions and the invex func-
tions.
Deï¬nition 3.32 A function f : X âŠ‚Rn â†’R, X nonempty convex set, is said to
be preinvex on X, when there exists a vector-valued function Î· : X Ã— X â†’X, such
that
f (x2 + Î»Î·(x1, x2)) â‰¦Î»f (x1) + (1 âˆ’Î») f (x2), âˆ€x1, x2 âˆˆX, âˆ€Î» âˆˆ[0, 1] .
It is immediate to note that convex functions are a particular case of preinvex
functions, when we make the substitution Î·(x1, x2) = x1 âˆ’x2. There are functions
that are preinvex, but not convex. For example, consider the function f : R â†’R
deï¬ned by f (x) = âˆ’|x| . Then f is not convex, but is preinvex, with Î· given by
Î·(x, y) =
â§
â¨
â©
x âˆ’y if x â‰¦0, y â‰¦0,
x âˆ’y if x â‰§0, y â‰§0,
y âˆ’x otherwise.

72
3
Convex Functions and Generalized Convex Functions
Preinvex functions keep some interesting properties of convex functions: for
example, every local minimum point of a preinvex function is a global minimum
point and nonnegative linear combinations of preinvex functions are preinvex (for
this last property, referred to convex functions, see the next Theorem 3.34).
Deï¬nition 3.33 A function f : X âŠ‚Rn â†’R differentiable on the open convex set
X is said to be invex on X, if there exists a vector-valued function Î· : Rn Ã— Rn â†’Rn
such that
f (x1) âˆ’f (x2) â‰§(Î·(x1, x2))âŠ¤âˆ‡f (x2), âˆ€x1, x2 âˆˆX.
Also here it is evident that differentiable convex functions are a particular case
of invex functions. These functions have been introduced by Hanson [13] and called
â€œinvexâ€ by Craven [14]. This term is a contraction of the terms â€œinvariantâ€ and
â€œconvexâ€. Indeed, if we operate a certain transformation on a convex function, this
transformation will destroy convexity, but the â€œtransformedâ€ function will be surely
invex.
In the next chapter we shall see a nice characterization of the class of invex
functions. It is easy to prove that if a differentiable function is preinvex on the open
convex set X âŠ‚Rn, then it is invex on X. Indeed, if f : X â†’R is differentiable on
X and x1, x2 âˆˆX, from the deï¬nition of preinvex functions it follows
f (x2 + Î»Î·(x1, x2)) âˆ’f (x2)
Î»
â‰¦f (x1) âˆ’f (x2), âˆ€Î» âˆˆ(0, 1] .
Taking the limit for Î» â†’0+ we obtain
f (x1) âˆ’f (x2) â‰§(Î·(x1, x2))âŠ¤âˆ‡f (x2).
It will appear in the next chapter that pseudoconvex functions are invex, but there
exist invex functions that are not pseudoconvex. Moreover, there exist invex functions
that are not quasiconvex and there exist quasiconvex functions that are not invex. See,
e.g. Mishra and Giorgi [15].
The criteria of positive deï¬niteness and positive semideï¬niteness of the Hessian
matrix are â€œoperativeâ€ criteria for establishing strict convexity and convexity of a
function f : Rn â†’R of class C 2. These criteria, however, sometimes may be noisy
to apply. For example, the function
f (x, y, z) = ex2+y2+z2 + (x + y + 1) + 3z2
is convex on R3, by a simple application of the next theorem, but its Hessian is a
mess. Fortunately, there are other ways than the use of the Hessian matrix to show
that a function is convex. The following theorem shows that convex functions can
be combinated in a variety of ways to produce other convex functions.

3.2 Generalized Convex Functions
73
Theorem 3.34 (a) If f1, f2, . . . , fk are convex functions on a convex set S âŠ‚Rn,
then
f (x) = f1(x) + f2(x) + Â· Â· Â· + fk(x)
is convex on S. Moreover, if at least one fi is strictly convex on S, then the sum
f is strictly convex.
(b) If f is convex (resp. strictly convex) on a convex set S âŠ‚Rn, and Î± âˆˆR is a
positive scalar, then Î±f is convex (resp. strictly convex) on S. Therefore, the
linear combination, with positive coefï¬cients, of convex functions is a convex
function.
(c) If f is a convex function (resp. a strictly convex function) deï¬ned on the convex
set S âŠ‚Rn, and if g is an increasing (resp. a strictly increasing) convex function
deï¬ned on the range of f , then the composite function g â—¦f is convex (resp.
strictly convex) on S.
Proof (a) To show that any ï¬nite sum of convex functions on S is convex on S, it
sufï¬ces to show that the sum f1 + f2 of two convex functions on S is again convex
on S. If y, z âˆˆS and Î» âˆˆ[0, 1] , then
f1(Î»y + (1 âˆ’Î»)z) + f2(Î»y + (1 âˆ’Î»)z)
â‰¦Î»f1(y) + (1 âˆ’Î») f1(z) + Î»f2(y) + (1 âˆ’Î») f2(z)
= Î»( f1(y) + f2(y)) + (1 âˆ’Î»)( f1(z) + f2(z)).
Hence, f1 + f2 is convex on S. Moreover, it is clear from this computation that if
either f1 or f2 is strictly convex, then f1 + f2 is strictly convex.
(b) This result follows by an argument similar to the one used in (a).
(c) If y, z âˆˆS and Î» âˆˆ[0, 1] , then
f (Î»y + (1 âˆ’Î»)z) â‰¦Î»f (y) + (1 âˆ’Î») f (z),
since f is convex on S. Consequently, since g is an increasing, convex function on
the range of f (x), it follows that
g( f (Î»y + (1 âˆ’Î»)z)) â‰¦g(Î»f (y) + (1 âˆ’Î») f (z)) â‰¦Î»g( f (y)) + (1 âˆ’Î»)g( f (z)).
Thus, the composite function g â—¦f is convex on S. If f is strictly convex and
g is strictly increasing, the ï¬rst inequality in the preceding computation is strict for
y Ì¸= z and Î» âˆˆ(0, 1), so g â—¦f is strictly convex on S.
â–¡
Example 3.35 The function
f (x1, x2, x3) = e(x1)2+(x2)2+(x3)2
is strictly convex on R3 (it follows from Theorem 3.34(c)).
The function

74
3
Convex Functions and Generalized Convex Functions
f (x) =
k
	
i=1
cie(ai)âŠ¤x,
with a1, . . . , ak vectors of Rn and c1 > 0, . . . , ck > 0, is convex on Rn (it follows
from Theorem 3.34(b)).
It must be noted that, contrary to convex functions, the sum of quasiconvex func-
tions is not in general a quasiconvex function. For example, let be
f (x) = x3;
g(x) = âˆ’x, x âˆˆR,
which are both quasiconvex (and quasiconcave) functions, but their sum f (x) +
g(x) = x3 âˆ’x is not quasiconvex (nor quasiconcave). The same holds true for the
sum of pseudoconvex functions.
Therearealsoresultsconcerningthecompositionofgeneralizedconvexfunctions.
We quote only the following one.
Theorem 3.36 Let f be a quasiconvex (resp. a semistrictly quasiconvex) function on
the convex set S âŠ‚Rn and let g be an increasing (resp. strictly increasing) function
deï¬ned on the range of f . Then the composite function g â—¦f is quasiconvex (resp.
semistrictly quasiconvex) on S.
3.3
Optimality Properties of Convex and Generalized
Convex Functions. Nonlinear Theorems of the
Alternative
We postpone to the next chapter the optimality properties of convex and generalized
convex functions in the differentiable case. Here we give some general optimality
properties that hold also without differentiability assumptions. We denote by
Xâˆ—
f â‰¡arg min
xâˆˆX
f (x)
the set of optimal (global) solutions of the problem min f (x), x âˆˆX âŠ‚Rn,
f : X â†’R.
Theorem 3.37 (a) Let f : X âŠ‚Rn â†’R be convex on the convex set X. Then, if
x0 âˆˆX is a local minimizer of f, then x0 is a global minimizer of f.
(b) If f : X âŠ‚Rn â†’R is strictly convex on the convex set X and if x0 âˆˆX is a
local minimizer of f, then x0 is the unique (strict) global minimizer of f.
Proof (a) Let y be any point of X. Consider Â¯Î» > 0 and sufï¬ciently close to 1. Then
we have that (x0 is the local minimizer in question)

3.3 Optimality Properties of Convex and Generalized Convex â€¦
75
Â¯Î»x0 + (1 âˆ’Â¯Î»)y âˆˆX,
since X convex. Moreover, Â¯Î»x0 + (1 âˆ’Â¯Î»)y âˆˆU(x0), and being x0 a local minimizer
and using the convexity of f , we have
f (x0) â‰¦f (Â¯Î»x0 + (1 âˆ’Â¯Î»)y) â‰¦Â¯Î» f (x0) + (1 âˆ’Â¯Î») f (y).
From here,
(1 âˆ’Â¯Î») f (x0) â‰¦(1 âˆ’Â¯Î») f (y),
and as (1 âˆ’Â¯Î») > 0, we derive that
f (x0) â‰¦f (y).
But y is any point of X :, therefore, x0 is a global minimizer for f on X.
(b) Absurdly, let us suppose that there exist two distinct (global) minimizers xâˆ—
and xâˆ—âˆ—. Being f strictly convex, we would have
f
 1
2 xâˆ—+ 1
2 xâˆ—âˆ—
< 1
2 f (xâˆ—) + 1
2 f (xâˆ—âˆ—) = f (xâˆ—).
which is absurd, because ( 1
2 xâˆ—+ 1
2 xâˆ—âˆ—) âˆˆX and by assumption xâˆ—is a global mini-
mizer for f on X.
â–¡
Theorem 3.38 If f : X âŠ‚Rn â†’R is convex on the convex set X, then the set
Xâˆ—
f â‰¡arg minxâˆˆX f (x) is a convex set. If f is strictly convex on X, then Xâˆ—
f contains
at most one point.
Proof If Xâˆ—
f = âˆ…, then Xâˆ—
f is convex by deï¬nition. Let be Xâˆ—
f Ì¸= âˆ…and let be x1, x2 âˆˆ
X two global minimizers for f on X :
f (x1) â‰¦f (x), âˆ€x âˆˆX;
f (x2) â‰¦f (x), âˆ€x âˆˆX.
We have to show that it holds
f (Î»x1 + (1 âˆ’Î»)x2) â‰¦f (x), âˆ€x âˆˆX, âˆ€Î» âˆˆ[0, 1] .
Indeed, we have, for any x âˆˆX and for any Î» âˆˆ[0, 1] :
f (Î»x1 + (1 âˆ’Î»)x2) â‰¦Î»f (x1) + (1 âˆ’Î») f (x2) â‰¦Î»f (x) + (1 âˆ’Î») f (x) = f (x).
The second assertion of the theorem is an assertion (b) of Theorem 3.37.
â–¡
Under suitable assumptions, the previous results hold also for some generalized
convex functions.

76
3
Convex Functions and Generalized Convex Functions
Theorem 3.39 Let X âŠ‚Rn be a convex set, let f : X â†’R and let x0 âˆˆX be a
local minimum point of f on X. If f is semistrictly quasiconvex on X, then x0 is a
global minimum point of f on X.
Proof As x0 âˆˆX is a local minimum point of f (x), there exists Îµ > 0 such that
f (x0) â‰¦f (x), âˆ€x âˆˆX âˆ©UÎµ(x0). Let us suppose that there exists Â¯x âˆˆX such that
f (Â¯x) < f (x0). From the semistrict quasiconvexity of f it follows
f (Î»Â¯x + (1 âˆ’Î»)x0) < f (x0)
for all Î» âˆˆ(0, 1) for which Î»Â¯x + (1 âˆ’Î»)x0 âˆˆX âˆ©UÎµ(x0). Now, if we choose Î» âˆˆ
(0, 1) smaller than Îµ/
Â¯x âˆ’x0 , it results easily that Î»Â¯x + (1 âˆ’Î»)x0 âˆˆX âˆ©UÎµ(x0),
which contradicts the assumption that x0 is a local minimum point of f on X.
Therefore, it results that f (x) â‰§f (x0), âˆ€x âˆˆX, i.e. x0 is a global minimum point
of f on X.
â–¡
Obviously, the thesis of the above theorem holds also under the assumption that
f is pseudoconvex on X. The thesis is no longer true under the assumption of
quasiconvexity of f. For example, the function f : R â†’R deï¬ned by
f (x) =
â§
â¨
â©
x + 1 if x â‰¦âˆ’1,
0
if âˆ’1 < x < 1,
x âˆ’1 if x â‰§1,
is quasiconvex and has at x0 = 0 a local minimum point which is not global.
However, if a quasiconvex function f : X âŠ‚Rn â†’R, X convex set, has a strict
local minimum point at x0, then the following result holds.
Theorem 3.40 Let f : X âŠ‚Rn â†’R be quasiconvex on the convex set X. If x0 âˆˆX
is a strict local minimum point of f on X, then x0 is also a strict global minimum
point of f on X.
Proof Suppose that x0 âˆˆX is a strict local minimum point of f on X, i.e. there
exists N(x0) such that
f (x0) < f (x), âˆ€x âˆˆN(x0) âˆ©X, x Ì¸= x0.
(3.7)
If x0 is not a strict global minimum point of f, then there exists Â¯x âˆˆX, Â¯x Ì¸= x0,
such that
f (Â¯x) â‰¦f (x0).
By the quasiconvexity of f, we have
f (Î»Â¯x + (1 âˆ’Î»)x0) â‰¦f (x0), âˆ€Î» âˆˆ[0, 1] .
But for sufï¬ciently small Î» it follows that x = Î»Â¯x + (1 âˆ’Î»)x0 âˆˆN(x0) âˆ©X,
contradicting (3.7).
â–¡

3.3 Optimality Properties of Convex and Generalized Convex â€¦
77
We may mention here that if a local minimum point x0 of a quasiconvex function
f is not a global minimum point, then f is constant on the intersection of some
neighborhood N(x0) and the line segment between x0 and any global minimum
point. See Ponstein [11].
Theorem 3.41 Let X âŠ‚Rn be a nonempty convex set and let f : X â†’R be quasi-
convex on X. The set Xâˆ—
f = arg min
xâˆˆX
f (x) is a convex set.
Proof As we can write, with x0 any point of Xâˆ—
f ,
arg min
xâˆˆX
f (x) =

x : x âˆˆX âŠ‚Rn, f(x) â‰¦f (x0)

the result is evident from one of the characterizations of quasiconvex functions (see
Theorem 3.19(d)).
â–¡
It is known that a necessary and sufï¬cient condition for x0 to be a global minimum
point of a function f : Rn â†’R over a set S âŠ‚Rn, is that x0 is a global ray minimum
point of f over S. That is, for every vector y âˆˆRn, x0 is a global minimum point on

x âˆˆRn : x + Î»y, Î» â‰§0

âˆ©S.
Similarly, a necessary condition that x0 be a local minimum point of f over S is
that x0 be a local ray minimum pointoverS, i.e. for every vector y âˆˆRn there exists
Î»0(y) such that
f (x0 + Î»y) â‰§f (x0),
whenever 0 < Î» < Î»0(y) and x0 + Î»y âˆˆS.
We may say that a local minimum point over S is a local ray minimum point over
S. But a local ray minimum point need not be a local minimum point, as the following
example, due to G. Peano, shows. Consider the function f : R2 â†’R deï¬ned by
f (x1, x2) = (x1 âˆ’(x2)2)(x1 âˆ’2(x2)2).
The point x0 = (0, 0) is a local ray minimum over the plane, but not a local
minimum point for f. However, for quasiconvex functions on the convex set S âŠ‚Rn,
the necessary conditions become sufï¬cient.
Theorem 3.42 If f : S âŠ‚Rn â†’R is quasiconvex on the convex set S, then any
local ray minimum point of f over S is a local minimum point of f over S.
See Thompson and Parke [16].
Nonlinear Theorems of the Alternative
Many theorems of the alternative for nonlinear systems are available in the mathema-
tical literature. These theorems usually hold under various convexity or generalized
convexity assumptions on the functions involved and some of them are formulated in
an inï¬nite-dimensional topological setting. We mention only the following theorems.

78
3
Convex Functions and Generalized Convex Functions
Theorem 3.43 Let X âŠ‚Rn be a nonempty convex set, f : X â†’Rm a vector-valued
convex function (i. e. each component fi, i = 1, . . . , m, is a convex function on X)
and g : X â†’Rk a linear afï¬ne vector-valued function. If the system
x âˆˆX,
f (x) < 0, g(x) = 0
has no solution, then there exist vectors u âˆˆRm
+ and v âˆˆRk, with (u, v) Ì¸= 0, such
that
uâŠ¤f (x) + vâŠ¤g(x) â‰§0, âˆ€x âˆˆX.
Proof The set of Rm+k
Y =

xâˆˆX

(y, z) : y âˆˆRm, z âˆˆRk, y > f (x), z = g(x)

is a convex set and 0 /âˆˆY, as it is easy to verify. From the separation theorem it results
that there exist u âˆˆRm and v âˆˆRk, with (u, v) Ì¸= 0, such that
uâŠ¤y + vâŠ¤z â‰§0, âˆ€(y, z) âˆˆY.
Moreover, it must be u â‰§0; indeed, if ui < 0 for some index i, then, by choosing
yi sufï¬ciently large, we should contradict the above inequality. Therefore, for any
Îµ > 0 and any x âˆˆX, we have ( f (x) + Îµe, g(x)) âˆˆY, where e = [1, 1, . . . , 1]âŠ¤,
and hence
uâŠ¤f (x) + vâŠ¤g(x) + ÎµuâŠ¤e â‰§0
or
uâŠ¤f (x) + vâŠ¤g(x) â‰§âˆ’ÎµuâŠ¤e, âˆ€x âˆˆX.
It results
Î´ = inf
xâˆˆX(uâŠ¤f (x) + vâŠ¤g(x)) â‰§0.
Indeed, if inf
xâˆˆX(uâŠ¤f (x) + vâŠ¤g(x)) = âˆ’Î´ < 0, we get, by picking Îµ such that
ÎµuâŠ¤e < Î´, thet
inf
xâˆˆX(uâŠ¤f (x) + vâŠ¤g(x)) = âˆ’Î´ < âˆ’ÎµuâŠ¤e,
which is a contradiction to the fact that uâŠ¤f (x) + vâŠ¤g(x) â‰§âˆ’ÎµuâŠ¤e, âˆ€x âˆˆX. Hence
inf
xâˆˆX(uâŠ¤f (x) + vâŠ¤g(x)) â‰§0.
â–¡
If we observe that for an m-dimensional vector function f, deï¬ned on  âŠ‚Rn,
we have

3.3 Optimality Properties of Convex and Generalized Convex â€¦
79
{ f (x) < 0 has a solution x âˆˆ} â‡’

f (x) â‰¦0, f (x) Ì¸= 0, has a solution x âˆˆ

â‡’

f (x) â‰¦0 has a solution x âˆˆ

and

f (x) â‰¦0 has no solution x âˆˆ

â‡’

f (x) â‰¦0, f (x) Ì¸= 0, has no solution x âˆˆ

â‡’{ f (x) < 0 has no solution x âˆˆ}
then, the following corollary is a direct consequence of Theorem 3.43.
Corollary 3.44 Let X âŠ‚Rn be a nonempty convex set, let f1 : X â†’Rm1, f2 : X â†’
Rm2, f3 : X â†’Rm3, be vector-valued convex functions on X and g : X â†’Rk a
linear afï¬ne vector-valued function. If the system
x âˆˆX, f1(x) < 0, f2(x) â‰¦0, f2(x) Ì¸= 0, f3(x) â‰¦0, g(x) = 0
has no solution, then there exist u1 âˆˆRm1, u2 âˆˆRm2, u3 âˆˆRm3 and v âˆˆRk such that
u1, u2, u3 â‰§0, (u1, u2, u3, v) Ì¸= 0,
(u1)âŠ¤f1(x) + (u2)âŠ¤f2(x) + (u3)âŠ¤f3(x) + vâŠ¤g(x) â‰§0, âˆ€x âˆˆX.
From the previous theorem, it is possible to obtain a generalization to the nonlinear
case of Gordanâ€™s theorem of the alternative. The following result is due to Fan et al.
[17].
Theorem 3.45 Let X âŠ‚Rn be a nonempty convex set and let f : X â†’Rm be a
vector-valued convex function. Then, either
(a)
f (x) < 0 has a solution x âˆˆX,
or
(b) uâŠ¤f (x) â‰§0, âˆ€x âˆˆX, for some u âˆˆRm
+, u Ì¸= 0,
but never both.
Proof If the system described sub (a) has a solution, obviously (b) cannot hold. If
(a) has no solution, then by Theorem 3.43 we have at once that (b) has a solution. â–¡
Another useful theorem of the alternative for nonlinear systems is presented by
Berge and Ghouila-Houri [18]. See also Stoer and Witzgall [19].
Theorem 3.46 Let be given the convex functions f0(x), f1(x), . . . , f p(x) deï¬ned
on Rn and the linear afï¬ne functions h1(x), h2(x), . . . , hm(x), also deï¬ned on Rn.
If the system
â§
â¨
â©
f0(x) < 0,
fk(x) â‰¦0, k = 1, . . . , p,
h j(x) â‰¦0,
j = 1, . . . , m,

80
3
Convex Functions and Generalized Convex Functions
admits no solution, but there exists x0 âˆˆRn such that it holds (â€œSlater constraint
qualiï¬cationâ€)
 fk(x0) < 0, k = 1, . . . , p,
h j(x0) â‰¦0,
j = 1, . . . , m,
then there exist multipliers y1 â‰§0, . . . , yp â‰§0, u1 â‰§0, . . . , um â‰§0, such that
f0(x) +
p
	
k=1
yk fk(x) +
m
	
j=1
u jh j(x) â‰§0, âˆ€x âˆˆRn.
The theorem of Farkas is easily obtained from Theorem 3.46. It is immediate to
see that the following systems
(S1) :
Ax = b, x â‰§0
and
(S2) :
AâŠ¤u â‰§0, bâŠ¤u < 0
cannot admit both solutions. It remains to prove that if (S2) does not admit solu-
tion, then (S1) admits solution. Let us rewrite (S2) by putting f0(u) â‰¡bâŠ¤u < 0 and
âˆ’AâŠ¤u â‰¦0. From Theorem 3.46 there exists x âˆˆRn
+ such that bâŠ¤u âˆ’xâŠ¤AâŠ¤u =
uâŠ¤(b âˆ’Ax) â‰§0, for every u âˆˆRm, and, therefore, we have b âˆ’Ax = 0, i.e. (S1)
admits solution.
Another general approach to nonlinear theorems of the alternative is due to Gian-
nessi [20]. The following result is a particular case of a more general theorem, proved
by the said author.
Theorem 3.47 Let be Ï• : Rn â†’R and g : Rn â†’Rm.
(i) Assume that Ï• and g be linear afï¬ne. Then the following system
(S3) :
Ï•(x) > 0
g(x) â‰§0
is impossible if and only if there exist Î¸ âˆˆR and Î» âˆˆRm such that
(Sâˆ—
3) :
Î¸Ï•(x) + Î»âŠ¤g(x) â‰¦0, âˆ€x âˆˆRn
Î¸ â‰§0, Î» â‰§0, (Î¸, Î») Ì¸= 0,
where the ï¬rst inequality of (Sâˆ—
3) must be veriï¬ed in a strict sense if Î¸ = 0.
(ii) Assume that Ï• and g are concave, and that there exists Ë†x âˆˆR such that g(Ë†x) > 0.
Then (S3) is impossible if there exists Î» âˆˆRm
+, such that
Ï•(x) + Î»âŠ¤g(x) â‰¦0, âˆ€x âˆˆRn.

References
81
(iii) Assume that Ï• and g are concave. (S3) is impossible if and only if there exist
Î¸ âˆˆR and Î» âˆˆRm such that
Î¸Ï•(x) + Î»âŠ¤g(x) â‰¦0, âˆ€x âˆˆRn,
with Î¸ â‰§0, Î» â‰§0, (Î¸, Î») Ì¸= 0, and

x âˆˆRn : Ï•(x) > 0, g(x) â‰§0, Î»âŠ¤g(x) = 0

= âˆ…,
when Î¸ = 0.
Also from Theorem 3.47 it is possible to get easily Farkasâ€™ theorem. Let us rewrite
Farkasâ€™ theorem in the form
(S1) â‰¡

Ax â‰§0, aâŠ¤x < 0

and
(Sâˆ—
1) â‰¡

zâŠ¤A = a, z â‰§0

.
Set Ï•(x) = âˆ’aâŠ¤x and g(x) = Ax. Theorem 3.47 (point (i)) can be applied. At
Î¸ = 0, (Sâˆ—
3) becomes Î» â‰§0, Î»âŠ¤Ax < 0, âˆ€x âˆˆRn, which is obviously impossible.
At Î¸ = 1, (Sâˆ—
3) becomes Î» â‰§0, âˆ’aâŠ¤x + Î»âŠ¤Ax â‰¦0, âˆ€x âˆˆRn, which holds if and
only if Î» â‰§0, âˆ’aâŠ¤x + Î»âŠ¤Ax = 0, which is equivalent to (Sâˆ—
1).
References
1. R.T. Rockafellar, Convex Analysis (Princeton University Press, Princeton, 1970)
2. M.S. Bazaraa, C.M. Shetty, Foundations of Optimization, Lecture Notes in Economic and
Mathematics Systems, vol. 122 (Springer, Berlin, 1976)
3. M.S. Bazaraa, H.D. Sherali, C.M. Shetty, Nonlinear Programming. Theory and Algorithms,
3rd edn. (Wiley Interscience, New York, 2006)
4. W. Fenchel, Convex Cones, Sets and Functions, Lecture Notes (Princeton University, Princeton,
1953)
5. M. Delfour, Introduction to Optimization and Hadamard Semidifferential Calculus, 2nd edn.
(SIAM, Philadelphia, 2020)
6. A.W. Roberts, D.E. Varberg, Convex Functions (Academic, New York, 1973)
7. A. Ruszczynski, Nonlinear Optimization (Princeton University Press, Princeton, 2006)
8. D.P. Bertsekas, Convex Optimization Theory (Athena Scientiï¬c, Belmont, Mass, 2009)
9. A. Cambini, L. Martein, Generalized Convexity and Optimization. Theory and Applications
(Springer, Berlin, 2009)
10. N. Hadjisavvas, S. Komlosi, S. Schaible (eds.), Handbook of Generalized Convexity and Gene-
ralized Monotonicity (Springer, New York, 2005)
11. J. Ponstein, Seven kinds of convexity. SIAM Rev. 9, 115â€“119 (1967)
12. J.P. Crouzeix, J.A. Ferland, Criteria for quasi-convexity and pseudo-convexity: Relationships
and comparisons. Math. Program. 23, 193â€“205 (1982)
13. M.A. Hanson, On sufï¬ciency of the Kuhn-Tucker conditions. J. Math. Anal. Appl. 80, 545â€“550
(1981)

82
3
Convex Functions and Generalized Convex Functions
14. B.D. Craven, Duality for generalized convex fractional programs, in Generalized Concavity in
Optimization and Economics, eds. by S. Schaible, W.T. Ziemba (Academic, New York, 1981),
pp. 473â€“489
15. S.K. Mishra, G. Giorgi, Invexity and Optimization (Springer, Berlin, 2008)
16. W.A. Thompson, D.W. Parke, Some properties of generalized concave functions. Oper. Res.
21, 305â€“313 (1973)
17. K. Fan, I. Glicksberg, A.J. Hoffman, Systems of inequalities involving convex functions. Proc.
Amer. Math. Soc. 8, 617â€“622 (1957)
18. C. Berge, A. Ghouila-Houri, Programming, Games and Transportation Networks (Wiley, New
York, 1965)
19. J. Stoer, C. Witzgall, Convexity and Optimization in Finite Dimensions, I (Springer, New York,
1971)
20. F. Giannessi, Constrained Optimization and Image Space Analysis. Vol. 1: Separation of Sets
and Optimality Conditions (Springer, New York, 2005)

Chapter 4
Unconstrained Optimization Problems.
Set-Constrained Optimization Problems.
Classical Constrained Optimization
Problems
4.1
Unconstrained Optimization Problems
In this section we shall treat problem (P1), i.e.
(P1) :
min f (x),
subject to x âˆˆS âŠ‚Rn,
where f : Rn â†’R and S is an open set (for example, S = Rn) or, more generally,
where for the optimal point x0 it holds x0 âˆˆint(S). In other words, we assume that the
optimal points of (P1) are interior to S. A ï¬rst basic result is given by the following
necessary optimality conditions.
Lemma 4.1 Let x0 âˆˆint(S) be a local minimizer for (P1) and let f admit its ith
partial derivative evaluated at x0; then it holds
âˆ‚f
âˆ‚xi
(x0) = 0.
Proof Being x0 a local minimizer for (P1), it holds f (x0) â‰¦f (x), âˆ€x âˆˆU(x0).
Obviously, this inequality holds, a fortiori, with respect to the ith component of x0:
f (x0 + tei) â‰§f (x0),
for each t âˆˆN(0), where N(0) is a (uni-dimensional) neighborhood of t = 0 and ei
is the ith elementary vector of Rn, i.e. ei = [0, 0, . . . , 1, . . . , 0]âŠ¤, with 1 as its ith
element. It follows that
f (x0 + tei) âˆ’f (x0)
t
â‰§0, for t > 0,
â‰¦0, for t < 0.
Â© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al., Basic Mathematical Programming Theory, International Series
in Operations Research & Management Science 344,
https://doi.org/10.1007/978-3-031-30324-1_4
83

84
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems â€¦
By letting t â†’0, the ï¬rst member becomes âˆ‚f
âˆ‚xi (x0), which exists by assumption,
and, therefore, âˆ‚f
âˆ‚xi (x0) = 0.
â–¡
As an immediate consequence, we have the following celebrated result, due to P.
Fermat.
Theorem 4.2 (Fermat Theorem) If x0 âˆˆint(S) is a local solution for problem (P1)
and if f admits the gradient âˆ‡f (x0), then it holds
âˆ‡f (x0) = 0.
Remark 4.3 The points x0 âˆˆint(S) such that âˆ‡f (x0) = 0 are usually called sta-
tionary points or critical points. Obviously, Theorem 4.2 holds also if x0 âˆˆint(S)
is a local maximizer for the objective function f. Therefore, all those points, which
are unconstrained local minimum points or maximum points, are stationary points
(if all partial derivatives exist at these points).
This condition is only a necessary condition; consider, e.g. the function f (x) =
x3, x âˆˆR. It results f â€²(0) = 0, but the point x0 = 0 is not a minimizer, nor a maxi-
mizer for f ; as it is well-known, x0 is an inï¬‚ection point.
We have, therefore, no information on the â€œnatureâ€ of stationary points; we have
an information on all points which are not stationary, i.e. such that âˆ‡f (x0) Ì¸= 0: they
cannot be (local) unconstrained minimum nor maximum points for (P1).
The previous remark demands the introduction of further assumptions in order to
get some information on the nature of stationary points. We begin by introducing the
following second-order necessary optimality conditions for (P1).
Theorem 4.4 Let x0 âˆˆint(S) be a local minimum point for (P1) and let f : Rn â†’R
be twice-continuously differentiable on N(x0) âŠ‚S. Then, x0 is a stationary point
for f and moreover, âˆ‡2 f (x0) is positive semideï¬nite.
Proof Being x0 a stationary point, we have for all vectors y âˆˆRn and for all scalars
t > 0, sufï¬ciently small,
0 â‰¦f (x0 + ty) âˆ’f (x0) = âˆ‡f (x0)âŠ¤(ty) + 1
2(ty)âŠ¤âˆ‡2 f (x0)(ty) + o(âˆ¥tyâˆ¥2)
= 1
2t2yâŠ¤âˆ‡2 f (x0)y + o(âˆ¥tyâˆ¥2).
Because this last expression cannot be negative, it follows that the Hessian matrix
âˆ‡2 f (x0) is positive semideï¬nite.
â–¡
Obviously, if x0 âˆˆint(S) is an unconstrained local maximum point for (P1), it
will hold that âˆ‡2 f (x0) is negative semideï¬nite.
Again, if we consider the function f (x) = x3, x âˆˆR, we see that f â€²(0) = 0 and
f â€²â€²(0) = 0, which conï¬rms that the conditions of Theorem 4.4 are only necessary
optimality conditions. We give now sufï¬cient second-order optimality conditions for
(P1).

4.1 Unconstrained Optimization Problems
85
Theorem 4.5 Let x0 âˆˆint(S)beastationarypointfor f ,let f betwice-continuously
differentiable on N(x0) âŠ‚S, and let âˆ‡2 f (x0) be positive deï¬nite. Then x0 is a strict
local minimum point of f for (P1).
Proof As in the proof of the previous theorem, we start from the relation
f (x0 + ty) âˆ’f (x0) = âˆ‡f (x0)âŠ¤(ty) + 1
2(ty)âŠ¤âˆ‡2 f (x0)(ty) + o(âˆ¥tyâˆ¥2) =
= 1
2t2yâŠ¤âˆ‡2 f (x0)y + o(âˆ¥tyâˆ¥2).
For all y âˆˆRn \ {0} and for all t > 0 sufï¬ciently small, the ï¬rst addendum of the
last expression is positive. It follows that also f (x0 + ty) âˆ’f (x0) > 0 and hence
x0 is a strict local minimum point of f over S.
â–¡
Obviously, if âˆ‡f (x0) = 0 and âˆ‡2 f (x0) is negative deï¬nite, x0 âˆˆint(S) is a strict
local maximum point of f over S. Note, moreover, that the conditions of Theorem 4.5
are only sufï¬cient optimality conditions; indeed, consider, e.g. the function f (x) =
x4, x âˆˆR. Here x0 = 0 is a minimum point of f (it is the unique strict minimum
point), but f â€²â€²(x0) = 0. The same is true for the function, deï¬ned on R2, f (x, y) =
x4 + y4, with respect to the point x0 = (0, 0)âŠ¤.
Deï¬nition 4.6 Let x0 âˆˆint(S) and let be âˆ‡f (x0) = 0. If, for every neighborhood
N(x0) of x0 there exist points x âˆˆS such that f (x) > f (x0) and points x âˆˆS such
that f (x) < f (x0), then x0 is called a saddle point of f on S. More generally, a
stationary point x0 âˆˆint(S) is a saddle point if it is neither a local minimum point
for f on S, nor a local maximum point.
On the grounds of what previously expounded, we have the following result.
Theorem 4.7 Let f be twice-continuously differentiable on U(x0) âŠ‚S and let be
âˆ‡f (x0) = 0. If âˆ‡2 f (x0) is indeï¬nite, then x0 is a saddle point for f on S.
The origin of the name â€œsaddle pointâ€ stems from the fact that in some cases the
form of the surface generated (in R3) by a function f : R2 â†’R in a neighborhood
of a saddle point, looks like a saddle for horses. It is the case, for example, of the
function
f (x, y) = x2 âˆ’y2.
Its unique stationary point is the origin of R2. Moreover,
âˆ‡2 f (x, y) =
 2
0
0 âˆ’2

.
If we consider the restriction y = 0 then f (x, 0) = x2 and we see that the origin of
R2 is a minimizer for this last function; if we consider the restriction x = 0, then

86
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems â€¦
f (0, y) = âˆ’y2 and now we see that the origin of R2 is a maximizer for this function.
Therefore,
f (0, 0) = min
xâˆˆR f (x, 0) = max
yâˆˆR f (0, y).
Hence, (0, 0) is a saddle point for f.
However, Deï¬nition 4.6 contains also other cases for the occurrence of a saddle
point. We may have a saddle point also if at a stationary point of x0 âˆˆint(S) the
Hessian matrix âˆ‡2 f (x0) is positive semideï¬nite (or negative semideï¬nite). Consider,
e.g. the function f : R2 â†’R deï¬ned as
f (x, y) = x2 âˆ’y4.
The origin of R2 is a stationary point for f and we have
âˆ‡2 f (0, 0) =
 2 0
0 0

,
which is positive semideï¬nite.
However, f (x, 0) = x2 has at x0 = 0 a minimum point, whereas f (0, y) = âˆ’y4
has at y0 = 0 a maximum point. Hence (0, 0) is a saddle point for f.
Let us consider the function f : R2 â†’R given by
f (x, y) = x2 âˆ’y3.
The origin of R2 is a stationary point for f and we have
âˆ‡2 f (0, 0) =
 2 0
0 0

.
For every scalar m âˆˆR, the function f (x, mx) = x2 âˆ’m3x3 has at x0 = 0 a
minimum point, whereas the function f (0, y) = âˆ’y3 has at y0 = 0 an inï¬‚ection
point. Hence, (0, 0) is not a minimum point nor a maximum point: it is a saddle
point.
Finally, we remark that this concept of saddle point must not be confused with
the concept of saddle point of the Lagrangian Function that will be introduced in
Chap. 8.
Remark 4.8 We have previously remarked, in Chap. 3, that if x0 âˆˆint(S) is a sta-
tionary point for f and is a local ray minimum point with respect to any direction
starting from x0, then x0 need not be a local minimum point for f. The following
example, due to G. Peano, conï¬rms the said assertion. The function
f (x, y) = (y âˆ’x2)(y âˆ’2x2)

4.1 Unconstrained Optimization Problems
87
has a stationary point at (0, 0), with f (0, 0) = 0. The origin is a local ray minimum
point over the plane, but not a local minimum point, as on every neighborhood of
(0, 0) there are points where f is positive and points where f is negative. Hence
(0, 0) is a saddle point.
Summing up:
Let x0 âˆˆint(S) be a stationary point for (P1) and let f be twice-continuously
differentiable on a neighborhood N(x0).
â€¢ If âˆ‡2 f (x0) is positive (resp. negative) semideï¬nite, we cannot exclude that x0
is a local minimum point for (P1) (resp. a local maximum for a maximization
problem). The â€œsemideï¬niteâ€ case is, in a sense, an â€œindeterminate caseâ€ and
further investigations are needed to try to specify the â€œnatureâ€ of the stationary
point.
â€¢ If âˆ‡2 f (x0) is positive deï¬nite (resp. negative deï¬nite) we can conclude that x0 is
a local strict minimizer for (P1) (resp. a local strict maximizer for a maximization
problem).
â€¢ If âˆ‡2 f (x0) is indeï¬nite, we can exclude that x0 is a local minimizer or a local
maximizer for f. In this case x0 is a saddle point.
Remark 4.9 Under the assumption of Theorem 4.5, it is possible to obtain a more
precise and sharper result. See, e.g. Hestenes [1, 2]. Indeed, if at a point x0 âˆˆint(S),
we have
âˆ‡f (x0) = 0, hâŠ¤âˆ‡2 f (x0)h > 0, âˆ€h âˆˆRn, h Ì¸= 0,
then there exists a neighborhood N(x0) of x0 and a positive number m such that
f (x) â‰§f (x0) + m
x âˆ’x02 , âˆ€x âˆˆN(x0).
In other words, x0 is a strict local minimizer of order 2 for (P1). See Sect. 1.3.
Furthermore, always under the assumptions of Theorem 4.5, it is possible to assert
that x0 is an isolated strict local minimizer for (P1) :
Theorem 4.10 Let f be a C 2-function and let x0 âˆˆint(S) satisfy the relation
âˆ‡f (x0) = 0; moreover, let âˆ‡2 f (x0) be positive deï¬nite. Then x0 is a locally unique
critical point and thus an isolated strict local minimizer for (P1).
Proof Assume to the contrary that there is a sequence xk â†’x0, xk Ì¸= x0, of critical
points xk, i.e. âˆ‡f (xk) = 0. Then by the Taylor expansion formula, we have
0 = âˆ‡f (xk) âˆ’âˆ‡f (x0) = âˆ‡2 f (x0)(xk âˆ’x0) + o(
xk âˆ’x0).
Dividing by
xk âˆ’x0 yields
0 = âˆ‡2 f (x0) xk âˆ’x0
xk âˆ’x0 + o(1).

88
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems â€¦
The bounded sequence
xkâˆ’x0
âˆ¥xkâˆ’x0âˆ¥has a convergent subsequence, we continue to
denote by the same notation, such that
xk âˆ’x0
xk âˆ’x0 â†’Â¯y, with âˆ¥Â¯yâˆ¥= 1.
Taking the limit for k â†’âˆin the above equality, we have
0 = âˆ‡2 f (x0) Â¯y
and thus
Â¯yâŠ¤âˆ‡2 f (x0) Â¯y = 0,
contradicting the positive deï¬niteness of âˆ‡2 f (x0).
â–¡
The function, already considered in Chap. 1,
f (x) =

2x2 + x2 sin 1
x if x âˆˆR, x Ì¸= 0,
0
if x = 0
has a strict (global) minimizer at x0 = 0, which, however, is not isolated. Indeed,
this function is not C 2 at x0 = 0 and Theorem 4.5 is, therefore, not applied.
We anticipate that the usual second-order sufï¬cient conditions for constrained
problems do not guarantee in general that the optimal point is isolated. See Example
6.45 and Theorem 6.46.
Example 4.11 Specify the type to which belong the stationary points of the function
f (x1, x2) = 3(x1)3 âˆ’x1 + (x2)3 âˆ’3(x2)2 âˆ’1.
We have
âˆ‚f
âˆ‚x1
= 9(x1)2 âˆ’1;
âˆ‚f
âˆ‚x2
= 3(x2)2 âˆ’6x2.
So, we have the system

(x1)2 = 1
9
3x2(x2 âˆ’2) = 0
which generates four stationary points:
A

âˆ’1
3, 0

; B
 1
3, 0

; C

âˆ’1
3, 2

; D
 1
3, 2

.
Then we have
âˆ‚2 f
âˆ‚x2
1
= 18x1;
âˆ‚2 f
âˆ‚x1âˆ‚x2
=
âˆ‚2 f
âˆ‚x2âˆ‚x1
= 0;
âˆ‚2 f
âˆ‚x2
2
= 6x2 âˆ’6,

4.1 Unconstrained Optimization Problems
89
âˆ‡2 f (x) =
 18x1
0
0
6x2 âˆ’6

.
(1)
âˆ‡2 f (âˆ’1
3, 0) =
âˆ’6
0
0
âˆ’6

.
This matrix is negative deï¬nite, hence, the point A is an unconstrained strict
local maximizer for f.
(2)
âˆ‡2 f ( 1
3, 0) =
 6
0
0 âˆ’6

.
This matrix is indeï¬nite; therefore, the point B is a saddle point for f.
(3)
âˆ‡2 f (âˆ’1
3, 2) =
âˆ’6 0
0
6

.
We have the same conclusions of the previous point 2): C is a saddle point
for f.
(4)
âˆ‡2 f ( 1
3, 2) =
 6 0
0 6

.
This matrix is positive deï¬nite; the point D is, therefore, an unconstrained strict
local minimizer for f.
Example 4.12 Let be
f (x, y) = x2 âˆ’Î±xy + y2, Î± âˆˆR.
The system âˆ‡f (x, y) = 0 is given by

âˆ‚f
âˆ‚x = 2x âˆ’Î±y = 0
âˆ‚f
âˆ‚y = âˆ’Î±x + 2y = 0.
For Î± Ì¸= Â±2 the unique solution is the origin of R2, which is, therefore, the unique
stationary point. Then we have
âˆ‡2 f (x, y) =
 2
âˆ’Î±
âˆ’Î±
2

= âˆ‡2 f (0, 0).
This matrix is positive deï¬nite if 4 âˆ’Î±2 > 0, i.e. if |Î±| < 2; positive semideï¬nite
if Î± = Â±2; indeï¬nite if |Î±| > 2.
If Î± = 2, the function becomes

90
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems â€¦
f (x, y) = x2 âˆ’2xy + y2 = (x âˆ’y)2
which obviously has inï¬nite (global) minimizers on the straight line y = x.
If Î± = âˆ’2, the function becomes
f (x, y) = x2 + 2xy + y2 = (x + y)2
which obviously has inï¬nite (global) minimizers on the straight line y = âˆ’x.
Moreover:
If âˆ’2 < Î± < 2, the function has a strict minimizer at (0, 0). In fact, this point is
the unique global minimizer, as in this case the function is strictly convex.
If |Î±| > 2, the point (0, 0) is a saddle point.
Example 4.13 Let us consider the function f : R2 â†’R deï¬ned by
f (x, y) = log(2x âˆ’y) + xy.
We note that the domain of f is an open subset of R2: dom( f ) = {(x, y) âˆˆR2 :
y < 2x}. Then we have
âˆ‚f
âˆ‚x =
2
2x âˆ’y + y; âˆ‚f
âˆ‚y = âˆ’
1
2x âˆ’y + x.
Hence
âˆ‚f
âˆ‚y = 0 â‡’x =
1
2x âˆ’y .
By substituting this relation into âˆ‚f
âˆ‚x we get
âˆ‚f
âˆ‚x = 2x + y
and, therefore, âˆ‚f
âˆ‚x = 0 for y = âˆ’2x.
Then, for x =
1
2xâˆ’y we have
1
4x = x and so âˆ‚f
âˆ‚x = 0 for 1 âˆ’4x2 = 0, i.e. for
x = Â± 1
2. Therefore, âˆ‚f
âˆ‚y = 0 for y = âˆ“1.
We have only one stationary point A( 1
2, âˆ’1), as B(âˆ’1
2, 1) does not belong to
dom( f ).
Then we have
âˆ‚2 f
âˆ‚x2 = âˆ’
4
(2x âˆ’y)2 ;
âˆ‚2 f
âˆ‚y2 = âˆ’
1
(2x âˆ’y)2 ;
âˆ‚2 f
âˆ‚xâˆ‚y = âˆ‚2 f
âˆ‚yâˆ‚x =
2
(2x âˆ’y)2 + 1.
âˆ‡2 f (A) =
âˆ’1
3
2
3
2
âˆ’1
4

.

4.1 Unconstrained Optimization Problems
91
Being
		âˆ‡2 f (A)
		 = âˆ’2 < 0, we conclude that A( 1
2, âˆ’1) is a saddle point for f.
Example 4.14 (a) Find the unconstrained minimizers, maximizers, and saddle
point (if any) of
f (x, y) = x(y âˆ’x)2.
We have
âˆ‚f
âˆ‚x = (y âˆ’x)2 âˆ’2x(y âˆ’x) = (y âˆ’x)(y âˆ’3x);
âˆ‚f
âˆ‚y = 2x(y âˆ’x).
Hence all stationary points are all those points on the straight line y = x.
âˆ‚2 f
âˆ‚x2 = 6x âˆ’4y; âˆ‚2 f
âˆ‚y2 = 2x;
âˆ‚2 f
âˆ‚xâˆ‚y = âˆ‚2 f
âˆ‚yâˆ‚x = 2y âˆ’4x.
âˆ‡2 f (x, y) =
 6x âˆ’4y 2y âˆ’4x
2y âˆ’4x
2x

.
âˆ‡2 f (x, x) =
 2x âˆ’2x
âˆ’2x 2x

.
The Hessian matrix âˆ‡2 f (x, x) is, therefore, positive semideï¬nite for x > 0, neg-
ative semideï¬nite for x < 0 and both positive and negative semideï¬nite for x = 0
(in this last case âˆ‡2 f (x, x) = the zero matrix).
We compute the difference between the values of the function and the values of
the function on its stationary points:
f = f (x, y) âˆ’f (x, x) = f (x, y) = x(y âˆ’x)2.
Therefore,
(1) For x > 0 all stationary points are local minimizers.
(2) For x < 0 all stationary points are local maximizers.
(3) At x = (0, 0) there is a saddle point.
(b) Find the unconstrained minimizers, maximizers, and saddle point (if any) of
f (x, y) = y2(y2 + x2 âˆ’2x).
We have
âˆ‚f
âˆ‚x = 2y2(x âˆ’1); âˆ‚f
âˆ‚y = 2y(2y2 + x2 âˆ’2x).
In consequence, the following are stationary points:
A(1,

1/2); B(1, âˆ’

1/2); C(k, 0), k âˆˆR.

92
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems â€¦
The Hessian matrix is
âˆ‡2 f (x, y) =

2y2
4y(x âˆ’1)
4y(x âˆ’1)
12y2 + 2x2 âˆ’4x

.
Hence
âˆ‡2 f (A) = âˆ‡2 f (B) =
 1 0
0 4

.
Therefore, A and B are local minimum points. For the point C we have
âˆ‡2 f (C) =
0
0
0
2k2 âˆ’4k

.
This matrix is semideï¬nite. We have
f = y2(y2 + x2 âˆ’2x) âˆ’f (C) = f (x, y).
The sign of this difference depends, therefore, from the sign of g(x, y) = y2 +
x2 âˆ’2x. As g(x, y) = 0 represents a circumference centered at P(1, 0) and with
radius r = 1, we conclude:
C(k, 0), for k < 0 are all minimum points;
C(k, 0), for 0 < k < 2 are all maximum points;
C(k, 0), for k > 2 are all minimum points;
C(0, 0) is a saddle point;
C(2, 0) is a saddle point.
The results of Theorem 4.5 give sufï¬cient conditions for (unconstrained) local
optimality related to problem (P1). If we wish to obtain global solutions for (P1) we
have to make reference to some convexity (or generalized convexity) assumptions on
f. If f : Rn â†’R is convex on the convex set S âŠ‚Rn, we have seen in the previous
chapter that:
â€¢ Every local minimizer of f (if existing) is also a global minimizer (Theorem 3.37).
â€¢ The set of all minimizers of f (necessarily global minimizers) form a convex set
(Theorem 3.38).
We now add a differentiability assumption on f. The following result is an immediate
consequence of deï¬nitions and properties seen in the previous chapter.
Theorem 4.15 Let f in (P1) be differentiable on the open convex set S âŠ‚Rn.
(i) Let f be convex on S; then the point x0 âˆˆS is a global minimum point for (P1)
if and only if âˆ‡f (x0) = 0.
(ii) Let f bestrictlyconvexon S;thepoint x0 âˆˆS is theuniquestrict global minimum
point for (P1) if and only if âˆ‡f (x0) = 0.
(iii) Let f be pseudoconvex on S; the point x0 âˆˆS is a global minimum point for
(P1) if and only if âˆ‡f (x0) = 0.

4.1 Unconstrained Optimization Problems
93
Example 4.16 Let us consider the function
f (x, y) = (x âˆ’y)2 + 3(x âˆ’y).
We have
âˆ‚f
âˆ‚x = 2(x âˆ’y) + 3; âˆ‚f
âˆ‚y = âˆ’2(x âˆ’y) âˆ’3.
The stationary points of f are all points that belong to the straight line y = x + 3
2.
Then we have
âˆ‚2 f
âˆ‚x2 = 2; âˆ‚2 f
âˆ‚y2 = 2;
âˆ‚2 f
âˆ‚xâˆ‚y = âˆ‚2 f
âˆ‚yâˆ‚x = âˆ’2.
âˆ‡2 f (x, y) =
 2
âˆ’2
âˆ’2
2

,
The elements of the Hessian matrix are constant quantities, hence âˆ‡2 f (x, y) is
positive semideï¬nite on the whole R2. This means that f is a convex function on
R2: all its stationary points y = x + 3
2 are global minimizers for f .
Let us observe that f = g â—¦â„“, where â„“(x, y) = x âˆ’y is linear and g(x) = x2 +
3x has a global minimizer at x0 = âˆ’3
2 .
Example 4.17 Let us consider the function
f (x1, x2, x3) = âˆ’(x1)2 âˆ’2(x2)2 âˆ’3(x3)2 + 1
2 x1x2 âˆ’1
2 x2x3.
It results that the unique stationary point is the zero vector xâˆ—= [0, 0, 0]âŠ¤. The
Hessian matrix is
âˆ‡2 f (x) =
â¡
â£
âˆ’2
1
2
0
1
2
âˆ’4
âˆ’1
2
0
âˆ’1
2
âˆ’6
â¤
â¦.
Also here âˆ‡2 f (x) is made of numbers, i.e. of constant quantities. Its leading
principal minors are
1 = âˆ’2;
2 = 31
4 ; 3 = det(âˆ‡2 f (x)) = âˆ’46.
Therefore, âˆ‡2 f (x) is negative deï¬nite on R3. This means that f is a strictly
concave function. Therefore, xâˆ—= [0, 0, 0]âŠ¤is the unique strict global maximizer
for f.
Example 4.18 Let us consider the quadratic function
F(x) = xâŠ¤Ax + 2aâŠ¤x + Î±

94
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems â€¦
with A square symmetric matrix of order n. We have that stationary points are given
by the solutions (if they exist) of the linear system
âˆ‡F(x) = 2Ax + 2a = 0.
(1) If A is non-singular, there is a unique stationary point given by x0 = âˆ’Aâˆ’1a.
Being âˆ‡2F(x) = 2A, we conclude that:
â€¢ If A is positive deï¬nite, then x0 is the unique strict global minimizer for F.
â€¢ If A is negative deï¬nite, then x0 is the unique strict global maximizer for F.
â€¢ If A is indeï¬nite, then x0 is a saddle point for F.
(2) If A is singular, then F admits stationarypoints if andonlyif rk(A) = rk(A; âˆ’a).
Let us suppose that this condition is veriï¬ed. Then, we can conclude that:
â€¢ If A is indeï¬nite, all stationary points are saddle points.
â€¢ If A is positive semideï¬nite, then F is a convex function and hence all its
stationary points are global minimizers.
â€¢ If A is negative semideï¬nite, then F is a concave function and hence all its
stationary points are global maximizers.
Example 4.19 (The least-squares method) Let be given n pairs of data (xi, yi),
i = 1, . . . , n, where xi and yi are mutually interconnected (for example, xi is the
price of the ith good and yi is the related demand, in a competitive market). The
problem is to ï¬nd a curve (â€œcurve ï¬tting problemâ€), for example a straight line
of equation y = ax + b, which ï¬ts â€œat bestâ€ the distribution of the points (xi, yi),
i = 1, . . . , n, in the plane. When a straight line is chosen, we speak of â€œlinear least-
squares problemâ€ ; this problem is a widely used statistical tool: the method is used
to ï¬t data to a function that is linear in the model parameters to be estimated.
In our problem we have to ï¬nd the coefï¬cients a and b of the equation y = ax + b,
in such a way that the corresponding line is â€œas much as possible closeâ€ to the given
n pairs. In the least-squares method it is chosen as a measure of the said distance the
smallest possible sum of squares of deviations of the observed data yi from the value
y of the said equation, in correspondence with xi:
n

i=1
[(axi + b) âˆ’yi]2 .
Inother words, wearelookingfor thosevalues ofa, b whichminimizethefunction
F(a, b) =
n

i=1
[(axi + b) âˆ’yi]2 .
We have

4.1 Unconstrained Optimization Problems
95
âˆ‚F
âˆ‚a = 2
n

i=1
(axi + b âˆ’yi)xi; âˆ‚F
âˆ‚b = 2
n

i=1
(axi + b âˆ’yi).
We have that âˆ‡a,bF(a, b) = 0 when it holds
a n
i=1(xi)2 + b n
i=1 xi = n
i=1 xi yi
a n
i=1 xi + bn = n
i=1 yi.
The determinant of the coefï¬cient matrix of the last system is
 = n
n

i=1
(xi)2 âˆ’
 n

i=1
xi
2
,
i.e.
 = n2
n
i=1(xi)2
n
âˆ’
n
i=1 xi
n
2
,
i.e.
 = n2 
M(X2) âˆ’[M(X)]2
= n2Ïƒ 2(X),
where M(X) is the mean value of the random variable X, which assumes the distinct
values x1, . . . , xn, all with the same probability 1
n , X2 is the square of the said random
variable and Ïƒ 2(X) is the variance of X.
If the values x1, . . . , xn are not all the same, it will be  > 0. Then, the above
system admits one solution:
aâˆ—=
n
i=1 xi yi âˆ’(n
i=1 yi)M(X)
nÏƒ 2(X)
;
bâˆ—= (n
i=1 yi)M(X2) âˆ’(n
i=1 xi yi)M(X)
nÏƒ 2(X)
.
Being
âˆ‡2F(a, b) = 2
â¡
â¢â¢â£
n
i=1
(xi)2
n
i=1
xi
n
i=1
xi
n
â¤
â¥â¥â¦,
it results that âˆ‡2F(a, b) is everywhere positive deï¬nite, hence (aâˆ—, bâˆ—) is the global
strict minimizer of F(a, b).
We have introduced in Chap. 3 the notion of invex functions (see Deï¬nition
3.33). A differentiable function f : Rn â†’R is invex if there exists a vector function
Î·(x, y) âˆˆRn such that

96
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems â€¦
f (y) âˆ’f (x) â‰§Î·(x, y)âŠ¤âˆ‡f (x), for all x, y âˆˆRn.
(4.1)
Clearly, differentiable convex functions satisfy (4.1), with Î·(x, y) = y âˆ’x. It
may exist more than one Î· which satisï¬es (4.1) for a given function f. The class of
invex functions has a nice characterization, given in the following result (see, e.g.
Ben-Israel and Mond [3], and Craven and Glover [4]).
Theorem 4.20 The differentiable function f : Rn â†’R is invex if and only if every
stationary point is a global minimum point.
Proof Clearly, if f is invex, then âˆ‡f (x) = 0 implies f (y) â‰§f (x), âˆ€y.
Assume now that
âˆ‡f (x) = 0 â‡’[ f (y) â‰§f (x), âˆ€y âˆˆRn].
If âˆ‡f (x) = 0, take Î·(x, y) = 0. If âˆ‡f (x) Ì¸= 0, take
Î·(x, y) = [ f (y) âˆ’f (x)]
âˆ‡f (x)âŠ¤âˆ‡f (x)âˆ‡f (x).
â–¡
As a consequence, if f has no stationary points, then f is invex. Although pseudo-
convex functions are invex, this is not the case for quasiconvex functions. The class
of invex functions and the class of (differentiable) quasiconvex functions have only
a partial overlapping. For example, f (x) = x3, x âˆˆR, is quasiconvex but not invex,
since its stationary point x = 0 is not a global minimum point for f. The function
f (x1, x2) = (x1)3 + x1 âˆ’10(x2)3 âˆ’x2, (x1, x2) âˆˆR2,
is invex, since it has no stationary points, but it is not quasiconvex. Take x = (0, 0),
y1 = 2, y2 = 1. we have f (y) âˆ’f (x) < 0 but (y âˆ’x)âŠ¤âˆ‡f (x) > 0, so f is not
quasiconvex.
4.2
Set-Constrained Optimization Problems
In this section we take into consideration problem (P2), i.e.
(P2) :
min f (x), x âˆˆS âŠ‚Rn,
where f : Rn â†’R and S is not necessarily open (for example, S is a closed set) or,
more generally, the optimal point x0 âˆˆS is not necessarily interior to S. The set S is
also called a set constraint for (P2) or an abstract constraint. The function f is the
objective function of (P2). This problem may, therefore, be considered a ï¬rst type of

4.2 Set-Constrained Optimization Problems
97
constrained optimization problem and hence the optimality results of the previous
section are no longer valid for the present case. A ï¬rst easy necessary optimality
condition for (P2) is given in the following result.
Theorem 4.21 Let f : Rn â†’R be differentiable on an open set A âŠ‚Rn containing
the set S and let x0 âˆˆS be a local minimum point of f on S (i.e. for problem (P2)).
Then
âˆ‡f (x0)âŠ¤y â‰§0, âˆ€y âˆˆF(S, x0),
(4.2)
where F(S, x0) is the cone of feasible directions of S at x0 (see Deï¬nition 2.44). If
x0 is a local maximum point of f over S, then
âˆ‡f (x0)âŠ¤y â‰¦0, âˆ€y âˆˆF(S, x0).
Proof Being y a feasible direction, there will exist Â¯Î± > 0 such that x0 + Î±y âˆˆS,
âˆ€Î± âˆˆ[0, Â¯Î±] . Since f is differentiable on A, it will hold
f (x0 + Î±y) âˆ’f (x0) = Î±âˆ‡f (x0)âŠ¤y + o(âˆ¥Î±yâˆ¥).
If, absurdly, we have âˆ‡f (x0)âŠ¤y < 0, for Î± > 0 and sufï¬ciently small, it would
hold
Î±âˆ‡f (x0)âŠ¤y + o(âˆ¥Î±yâˆ¥) < 0.
and hence f (x0 + Î±y) < f (x0), contrary to the assumptions.
â–¡
Relation (4.2) can be rewritten in the form
âˆ’âˆ‡f (x0) âˆˆ(F(S, x0))âˆ—.
Moreover, note that if x0 âˆˆint(S), Theorem 4.21 recovers the Fermat theorem
(Theorem 4.2), since in this case any direction y âˆˆRn is feasible (i.e. F(S, x0) = Rn)
and hence, for all y âˆˆRn, we have
âˆ‡f (x0)âŠ¤y â‰§0 and âˆ‡f (x0)âŠ¤(âˆ’y) â‰§0,
which implies that âˆ‡f (x0) = 0.
Example 4.22 Let us consider the function f : R2 â†’R given by
f (x) = (x1)2 âˆ’x1 + x2 + x1x2
and let be S = R2
+, i.e. S =

(x1, x2) âˆˆR2 : x1 â‰§0, x2 â‰§0

.
The minimum point of f on S is x0 =
 1
2, 0
âŠ¤. Hence x0 /âˆˆint(S). Let us note
that
âˆ‚f
âˆ‚x1
= 2x1 âˆ’1 + x2;
âˆ‚f
âˆ‚x2
= 1 + x1.

98
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems â€¦
Therefore, âˆ‡f (x0)âŠ¤=

0, 3
2

Ì¸= 0, which shows that the Fermat rule is not valid
in the present case. The cone of feasible directions of S at x0 is given by the vector
[y1, y2]âŠ¤, y1 âˆˆR, y2 â‰§0. We have

0, 3
2
  y1
y2

= 3
2 y2 â‰§0, âˆ€y2 â‰§0.
There exist also second-order necessary optimality conditions related to
Theorem 4.21.
Theorem 4.23 Let f : Rn â†’R be C 2 on the open set A âŠ‚Rn containing the set
S and let x0 âˆˆS be a local minimum point for (P2). Then, for all y âˆˆF(S, x0) it
holds:
(i) âˆ‡f (x0)âŠ¤y â‰§0;
(ii) If âˆ‡f (x0)âŠ¤y = 0, then yâŠ¤âˆ‡2 f (x0)y â‰§0.
Proof Relation (i) is nothing but Theorem 4.21. Being f a C 2-function, we have
f (x0 + Î±y) = f (x0) + Î±âˆ‡f (x0)âŠ¤y + 1
2Î±2yâŠ¤âˆ‡2 f (x0)y + o(âˆ¥Î±yâˆ¥2).
If âˆ‡f (x0)âŠ¤y = 0, it will hold
f (x0 + Î±y) âˆ’f (x0) = 1
2Î±2yâŠ¤âˆ‡2 f (x0)y + o(âˆ¥Î±yâˆ¥2).
If yâŠ¤âˆ‡2 f (x0)y < 0, for Î± sufï¬ciently small it will hold
Î±2yâŠ¤âˆ‡2 f (x0)y + o(âˆ¥Î±yâˆ¥2) < 0
and hence also f (x0 + Î±y) < f (x0), contrary to the assumptions.
The last part of the theorem is obvious.
â–¡
If we consider again Example 4.22, we see that
âˆ‡f (x0)âŠ¤y = 3
2 y2 = 0 for y2 = 0,
and
âˆ‡2 f (x0) =
 2 1
1 0

.
Therefore,
yâŠ¤âˆ‡2 f (x0)y = [y1, 0]
2 1
1 0
  y1
0

= 2(y1)2 â‰§0.

4.2 Set-Constrained Optimization Problems
99
The difï¬culty related to Theorem 4.21 is that its necessary condition may be
vacuous because there may be no feasible directions, other than zero, and hence
Theorem 4.21 has in this case no content. Consider, e.g. the set
S =

(x1, x2) âˆˆR2 : (x1)2 + (x2)2 âˆ’1 = 0

.
Then, the only feasible direction at any point of S is just the zero vector. Hence,
regardless of the objective function f and the point x0 âˆˆS, we have that (4.2) is
satisï¬ed. It is, therefore, convenient to introduce a necessary optimality condition
for (P2) sharper than the one of Theorem 4.21.
Theorem 4.24 Let f : Rn â†’R be differentiable on the open set A âŠ‚Rn containing
the set S and let x0 âˆˆS be a local minimum point of f on S. Then it holds
âˆ‡f (x0)âŠ¤y â‰§0, âˆ€y âˆˆT (S, x0),
(4.3)
where T (S, x0) is the Bouligand tangent cone to S at x0 (see Deï¬nition 2.35).
Proof Let be y Ì¸= 0 any direction of T (S, x0) and without loss of generality, let us
suppose âˆ¥yâˆ¥= 1. There will exist, therefore, a feasible sequence

xk
âŠ‚S, with
xk
yâ†’x0. As the quotients
f (xk) âˆ’f (x0)
xk âˆ’x0
= âˆ‡f (x0)âŠ¤(xk âˆ’x0) + o(
xk âˆ’x0)
xk âˆ’x0)

,
for k sufï¬ciently large, are nonnegative, being x0 a local minimum point for (P2),
and converge to âˆ‡f (x0)âŠ¤y, the thesis is proved.
â–¡
We note that (4.3) can be rewritten in the form
âˆ’âˆ‡f (x0) âˆˆ(T (S, x0))âˆ—.
Guignard [5] obtained the relation
âˆ’âˆ‡f (x0) âˆˆ(P(S, x0))âˆ—,
where P(S, x0) = cl(conv(T (S, x0))). However, this condition is equivalent to (4.3),
as, for any cone C âŠ‚Rn we have Câˆ—= cl(conv(C))âˆ—.
If S âŠ‚Rn in problem (P2) is a convex set, then it holds
(T (S, x0))âˆ—= N(S, x0),
where N(S, x0) is the normal cone to S at x0 (see Deï¬nition 2.42) and hence we can
write
âˆ’âˆ‡f (x0) âˆˆN(S, x0),

100
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems â€¦
relation that some authors write as
0 âˆˆâˆ‡f (x0) + N(S, x0)
or also as
âˆ‡f (x0)âŠ¤(x âˆ’x0) â‰§0, âˆ€x âˆˆS.
(4.4)
Now, if f is pseudoconvex on the convex set S (i.e. x, x0 âˆˆS, âˆ‡f (x0)âŠ¤(x âˆ’
x0) â‡’f (x) âˆ’f (x0) â‰§0), then (4.4) is a necessary and sufï¬cient condition for
x0 âˆˆS to be a global minimum point for f on S.
We have also ï¬rst-order sufï¬cient local optimality conditions for (P2) :
Theorem 4.25 Let us consider a point x0 âˆˆS in problem (P2). If
âˆ‡f (x0)âŠ¤y > 0, âˆ€y âˆˆT (S, x0) \ {0} ,
(4.5)
then x0 is a strict local minimum point for (P2).
Proof We suppose absurdly that x0 âˆˆS is not a strict local minimizer of f on S.
Then there exists for every index k âˆˆN a point xk âˆˆS âˆ©U 1
k (x0), with xk Ì¸= x0
and f (xk) â‰¦f (x0). The feasible sequence

xk
converges to x0 and contains a
tangentially convergent subsequence (see Deï¬nition 2.34). Without loss of generality
we can denote by

xk
this last subsequence for which we have xk
yâ†’x0. We have,
therefore, y âˆˆT (S, x0) \ {0} , but the quotients
f (xk) âˆ’f (x0)
xk âˆ’x0
= âˆ‡f (x0)âŠ¤(xk âˆ’x0) + o(
xk âˆ’x0)
xk âˆ’x0)

converge to âˆ‡f (x0)âŠ¤y â‰¦0, contrary to the assumptions.
â–¡
We note that for the validity of relation (4.5), the cone T (S, x0) must contain no
straight line, i.e. it must be a so-called â€œpointed coneâ€.
Moreover (see Hestenes [1, 2]), it can be proved that (4.5) gives a stronger result:
if (4.5) is satisï¬ed, then there exist a neighborhood N(x0) and a positive number m
such that
f (x) â‰§f (x0) + m
x âˆ’x0 , âˆ€x âˆˆS âˆ©N(x0).
In other words, x0 is a strong local minimizer or sharp local minimizer for (P2).
There are also second-order optimality conditions for (P2), related to Theorems
4.24 and 4.25.
Theorem 4.26 Let in (P2) the objective function f be twice-continuously differen-
tiable on an open set A âŠ‚Rn containing S and let x0 âˆˆS be a local minimum point
for f on S. If âˆ‡f (x0) = 0, then
yâŠ¤âˆ‡2 f (x0)y â‰§0, âˆ€y âˆˆT (S, x0).

4.2 Set-Constrained Optimization Problems
101
Proof Let be y Ì¸= 0 any vector of T (S, x0). Without loss of generality we assume
âˆ¥yâˆ¥= 1. There will exist a feasible sequence

xk
âŠ‚S with xk
yâ†’x0. On the
grounds of the assumptions the quotients
f (xk) âˆ’f (x0)
xk âˆ’x02
=
1
2(xk âˆ’x0)âŠ¤âˆ‡2 f (x0)(xk âˆ’x0) + o(
xk âˆ’x02)
xk âˆ’x0)
2
for sufï¬ciently large k âˆˆN are nonnegative and converge to 1
2 yâŠ¤âˆ‡2 f (x0)y.
â–¡
Theorem 4.27 Let be given problem (P2), with f twice-continuously differentiable
on the open set A âŠ‚Rn containing S. If, for x0 âˆˆS it holds âˆ‡f (x0) = 0 and
yâŠ¤âˆ‡2 f (x0)y > 0, âˆ€y âˆˆT (S, x0) \ {0} ,
then x0 is a strict local minimum point for f on S.
Proof The proof is indirect; let us assume that x0 is not a strict local minimum for f
on S. Then there will exist for each index k âˆˆN a point xk âˆˆS âˆ©U 1
k (x0), with xk Ì¸=
x0 and f (xk) â‰¦f (x0). The feasible sequence

xk
converges to x0 and contains a
tangentially convergent subsequence, we shall denote again by

xk
: xk
yâ†’x0. It
holds y âˆˆT (S, x0) \ {0} , but the quotients
f (xk) âˆ’f (x0)
xk âˆ’x02
=
1
2(xk âˆ’x0)âŠ¤âˆ‡2 f (x0)(xk âˆ’x0) + o(
xk âˆ’x02)
xk âˆ’x0)
2
converge to 1
2 yâŠ¤âˆ‡2 f (x0)y â‰¦0, contrary to the assumptions.
â–¡
Remark 4.28 Following Hestenes [2], the thesis of Theorem 4.27 can be reformu-
lated in the following way: there exists a neighborhood N(x0) and a constant m > 0
such that
f (x) â‰§f (x0) + m
x âˆ’x02 , âˆ€x âˆˆN(x0) âˆ©S.
Moreover, if the set S is a polyhedral convex set, then Theorems 4.26 and 4.27
can be reformulated in the following more general results:
(1) (Necessity). If x0 âˆˆS is a local minimum point for (P2), then âˆ‡f (x0)âŠ¤y â‰§0
for all y âˆˆT (S, x0) and
yâŠ¤âˆ‡2 f (x0)y â‰§0
for all y âˆˆT (S, x0) such that âˆ‡f (x0)âŠ¤y = 0.
(2) (Sufï¬ciency). If x0 âˆˆS is such that âˆ‡f (x0)âŠ¤y â‰§0 for all y âˆˆT (S, x0) and
yâŠ¤âˆ‡2 f (x0)y > 0

102
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems â€¦
for all y âˆˆT (S, x0) \ {0} such that âˆ‡f (x0)âŠ¤y = 0, then there exist N(x0) and
m > 0 such that
f (x) â‰§f (x0) + m
x âˆ’x02 , âˆ€x âˆˆN(x0) âˆ©S.
We point out ï¬nally that Hestenes [2] has further generalized Theorems 11 and
12 by means of the lower supporting functions for f at x0 âˆˆS as follows.
A function F : Rn â†’R having the same differentiability properties of f at x0
and satisfying the relations
F(x) â‰¦f (x) on S, F(x0) = f (x0), âˆ‡F(x0) = 0
is called a lower support function for f at x0. Hestenes [2] proves the following
result.
â€¢ Let x0 âˆˆS and suppose that there exists y âˆˆT (S, x0), y Ì¸= 0, such that
âˆ‡f (x0)âŠ¤y = 0.
(4.6)
Suppose further that for each vector y Ì¸= 0, y âˆˆT (S, x0) satisfying relation (4.6),
there is a lower support function F such that
yâŠ¤âˆ‡2F(x0)y > 0.
Then there are a neighborhood N(x0) and a constant m > 0 such that
f (x) â‰§f (x0) + m
x âˆ’x02 , âˆ€x âˆˆN(x0) âˆ©S.
Note that in the previous result it is not required that F to be the same for every
y Ì¸= 0, y âˆˆT (S, x0), satisfying relation (4.6).
4.3
Optimization Problems with Equality Constraints
(â€œClassical Constrained Optimization Problemsâ€)
In the present section we shall treat the so-called â€œclassicalâ€ constrained optimization
problems, i.e. optimization problems with only equality constraints. We consider,
therefore, problem (P3):
(P3) :
â§
â¨
â©
min f (x)
subject to: h j(x) = 0,
j = 1, . . . , p < n,
x âˆˆX âŠ‚Rn,

4.3 Optimization Problems with Equality Constraints â€¦
103
where X âŠ‚Rn is an open set contained in the domains of the functions involved
in (P3), f : X â†’R is differentiable on X and every h j : X â†’R, j = 1, . . . , p, is
continuously differentiable on X. The feasible set of (P3) is denoted by
K3 =

x âˆˆX : h j(x) = 0,
j = 1, . . . , p < n

,
where h j, j = 1, . . . , p, are the constraints or constraint functions of the problem
( f is the objective function).
The restriction p < n is imposed in order to avoid that the feasible set shrinks
to only isolated points or to the empty set. We have called (P3) a â€œclassicalâ€ con-
strained optimization problem, as it was treated by J. L. Lagrange since 1759 (J. L.
Lagrange: â€œRecherches sur la mÃ©thode de maximis et minimisâ€, Miscellanea Tau-
rinensia, 1759, t. 1, 18â€“32. Reprinted in Giorgi and Kjeldsen [6]). Subsequently
Lagrange reconsidered his method (within a more general class of problems, called
Calculus of Variations) in his famous book â€œMÃ©canique Analytiqueâ€ (Paris, 1788.
Complete Edition, joining the notes of the 3rd Edition, revised, corrected, and anno-
tated by Joseph Bertrand, and those of the 4th Edition published under the direction of
Gaston Darboux, Albert Blanchard, Paris, 1965). This method, now called Lagrange
Multipliers Rule, is one of the main cornerstones of optimization theory and is the
basis of the modern developments of mathematical programming theory.
In rough words, the method of Lagrange converts the constrained problem (P3)
into an unconstrained one, by means of a suitable function, called â€œLagrangian func-
tionâ€ and then it uses the rules of unconstrained optimization problems to compute
the solutions of problem (P3). For some historical considerations see, e.g. Prekopa
[9], Bussotti [7], and Giorgi and Kjeldsen [6].
When in (P3) we have n = 2 and p = 1 (one constraint and two variables) it can be
sometimes useful the so-called â€œexplicitation methodâ€, i.e. to express one variable as
a function of the other one, in the constraint, and then to make the substitution into the
objective function. The problem becomes, therefore, an unconstrained optimization
problem. It must be paid attention to the fact that the domain of the new objective
function may change, owing to the â€œintroductionâ€ of the constraint functions. We
illustrate it with a couple of examples.
Example 4.29 Find the extremum values of
f (x1, x2) = x1x2
on the feasible set
K3 =

(x1, x2) âˆˆR2 : 2x1 + x2 âˆ’1 = 0

.
We have, from the constraint,
x2 = 1 âˆ’2x1.

104
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems â€¦
Therefore, the objective function becomes
g(x1) â‰¡g(x) = x âˆ’2x2.
We have gâ€²(x) = 1 âˆ’4x, from which we deduce that x0 = 1
4 is the global max-
imizer of g and hence, being x2 = 1 âˆ’2x, we have x2 = 1
2. Therefore, P( 1
4, 1
2) is
the global maximum point of f on K3.
Example 4.30 Find the extremum values of
f (x, y, z) = âˆ’x + x2 + y2 + y(z + x âˆ’1)
on the feasible set
K3 =

(x, y, z) âˆˆR3 : x2 + y2 = 1; x + y + z = 1

.
From the ï¬rst constraint we have y2 = 1 âˆ’x2, from which x âˆˆ[âˆ’1, 1]. From the
second constraint we have z = 1 âˆ’x âˆ’y. Then f takes the form
g(x) = âˆ’x + x2 + 1 âˆ’x2 âˆ’1 + x2 = x2 âˆ’x,
with x âˆˆ[âˆ’1, 1] ; gâ€²(x) = 2x âˆ’1.
We have, therefore, four points to consider:
P1 = (âˆ’1, 0, 2); f (P1) = 2.
P2 =

1
2,
âˆš
3
2 , 1âˆ’
âˆš
3
2
 
; P3 =

1
2, âˆ’
âˆš
3
2 , 1+
âˆš
3
2
 
; f (P2) = f (P3) = âˆ’1
4.
P4 = (1, 0, 0); f (P4) = 0.
Hence P1 is the constrained global maximum point, P2 and P3 are the constrained
global minimum points and P4 is a local constrained maximum point.
Always for the case n = 2, p = 1, it may be useful also the geometrical method
which is based on the level sets or level lines of the objective function:
lev=Î± f =

(x, y) âˆˆR2 : f (x, y) = Î±

,
where Î± âˆˆR. Next we illustrate the method with an example.
Example 4.31 Find the extremum values of
f (x, y) = 3x + 4y
on the feasible set
S =

(x, y) âˆˆR2 : (x âˆ’5)2 + (y âˆ’3)2 â‰¦4

.

4.3 Optimization Problems with Equality Constraints â€¦
105
Fig. 4.1 Example 4.31.
Feasible set, level lines,
minimum (a) and maximum
(b)
The feasible set is drawn in Fig. 4.1, it is a circle of radius 2 centered at (5, 3).
The level curves are of the form
3x + 4y = c,
c âˆˆR.
They are parallel lines to the line 3x + 4y = 0 and f increases in the direction (3, 4).
So the minimum is achieved at the point A and the maximum at the point B, where the
parallel lines are tangents to the circumference (x âˆ’5)2 + (y âˆ’3)2 = 4. At a point
of tangency, the tangent line is perpendicular to the radius at the point of contact.
So, if we consider the perpendicular line to 3x + 4y = 0 through the center of the
circumference, that is the line 4(x âˆ’5) âˆ’3(y âˆ’3) = 0, the points A and B are the
solutions of the system
 (x âˆ’5)2 + (y âˆ’3)2 = 4
4(x âˆ’5) âˆ’3(y âˆ’3) = 0.
Solving this system we obtain A =
 19
5 , 7
5

and B =
 31
5 , 23
5

.
A second possibility to obtain the points A and B is as follows:
A = (5, 3) âˆ’2
5(3, 4) and B = (5, 3) + 2
5(3, 4).
Let us observe that 1
5(3, 4) is a unit vector in the direction (3, 4) and 2 is the radius
of the circumference.
A third possibility to ï¬nd A and B is based on algebraic considerations. For each
c the line 3x + 4y = c from the family of level lines cuts the circumference at two
points, at only one (A or B) or at none. Therefore, the values of c to obtain A and B are
those for which the system
 (x âˆ’5)2 + (y âˆ’3)2 = 4
3x + 4y = c
has only one solution. Chang-
ing to the variables u = x âˆ’5, v = y âˆ’3, the system becomes
 u2 + v2 = 4
3u + 4v = Î±,

106
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems â€¦
where Î± = c âˆ’27. From the second equation v = Î±âˆ’3u
4
, and substituting in the ï¬rst
equation, it results 25u2 âˆ’6Î±u + Î±2 âˆ’64 = 0. This equation in u has only one solu-
tion if its discriminant is zero, that is,  = b2 âˆ’4ac = 36Î±2 âˆ’100(Î±2 âˆ’64) = 0.
This gives Î± = Â±10, and so c = 27 Â± 10, u = 6Î±
50 = Â± 6
5, v = Â± 8
5, x = 5 Â± 6
5 and
y = 3 Â± 8
5, and with this values we obtain the same points A and B as above.
The reader is invited to solve the problem of Example 4.29 with the geometrical
method. We recall that the relation x1x2 = Î±, Î± âˆˆR, Î± Ì¸= 0, generates a family of
equilateral hyperbolas. Other examples where the geometrical method is useful are
Examples 4.35, 5.30, and 5.33 and the problems at the end of Chap. 5.
The above methods are in general no longer useful when (P3) has more than
two variables and more than one constraint. In the general case, it is the Lagrange
Multipliers Rule that must be adopted. For the readerâ€™s convenience we begin to treat
problem (P3) again under the assumption of p = 1, n = 2. Subsequently we shall
treat the general case.
Theorem 4.32 Let be in problem (P3) n = 2 and p = 1, i.e. f : X âŠ‚R2 â†’R and
h : X âŠ‚R2 â†’R, with X open set of R2. Let f be differentiable on X and h be
continuously differentiable on X. Let (x0, y0) âˆˆK3 =

(x, y) âˆˆR2 : h(x, y) = 0

be a local minimum point of f on K3 and let be âˆ‡h(x0, y0) Ì¸= 0. Then, there exists
a unique scalar Î» âˆˆR, called â€œLagrange multiplierâ€, such that
âˆ‡f (x0, y0) + Î»âˆ‡h(x0, y0) = 0.
(4.7)
Proof Consider, without loss of generality, the case âˆ‚h
âˆ‚y (x0, y0) Ì¸= 0. Owing to the
Implicit Function Theorem (Chap. 1, p. 6), there exists a neighborhood U(x0), where
h(x, y) deï¬nes implicitly a function y = Ï•(x) such that
y0 = Ï•(x0); Ï•â€²(x) = âˆ’âˆ‚h/âˆ‚x
âˆ‚h/âˆ‚y .
In this neighborhood we have also z = f (x, y) = f (x, Ï•(x)) = F(x).
It must hence hold
Fâ€²(x0) = f â€²(x0, Ï•(x0)) = 0.
But, owing to the â€œchain ruleâ€ on differentiability of composite functions, we have
also
Fâ€²(x) = âˆ‚f
âˆ‚x + âˆ‚f
âˆ‚y Ï•â€²(x).
Hence
Fâ€²(x) = âˆ‚f
âˆ‚x + âˆ‚f
âˆ‚y

âˆ’âˆ‚h/âˆ‚x
âˆ‚h/âˆ‚y

.
Therefore, at the point (x0, y0) it will hold

4.3 Optimization Problems with Equality Constraints â€¦
107
Fig. 4.2 Geometric
interpretation of Theorem
4.32. f decreases in the
direction âˆ’âˆ‡f (x0) and x0 is
a local minimum of f , one
has âˆ‡f (x0) + Î»âˆ‡h(x0) = 0
with Î» âˆˆR (in this case
Î» = âˆ’1
2)
âˆ‚f
âˆ‚x âˆ’
âˆ‚f
âˆ‚y /âˆ‚h
âˆ‚y
 âˆ‚h
âˆ‚x = 0.
On the other hand we have the following obvious identity:
âˆ‚f
âˆ‚y âˆ’
âˆ‚f
âˆ‚y /âˆ‚h
âˆ‚y
 âˆ‚h
âˆ‚y = 0.
If we put
âˆ’
âˆ‚f
âˆ‚y /âˆ‚h
âˆ‚y = Î»

,
we have the ï¬nal result.
â–¡
A geometric interpretation of this theorem is given in Fig. 4.2.
Remark 4.33 (i) Obviously it is equivalent to write the thesis of Theorem 4.32 in
the form
âˆ‡f (x0, y0) âˆ’Î»âˆ‡h(x0, y0) = 0,
as no sign restriction is made on the multiplier Î».
(ii) The necessary optimality conditions of Theorem 4.32 are obviously the same
also for a constrained maximization problem
(Pâ€²
3) :
max
xâˆˆK3 f (x).
In other words the necessary optimality conditions expressed by means of the
Lagrange Multipliers Rule makes no distinction between minimization problems
and maximization problems.
(iii) The function
L (x, y, Î») = f (x, y) + Î»h(x, y)
(or, equivalently, L (x, y, Î») = f (x, y) âˆ’Î»h(x, y)) is called Lagrangian function
or shortly, Lagrangian. We note that the thesis of Theorem 4.32 leads to ï¬nd the sta-
tionary points of the Lagrangian function. In this sense, the constrained optimization

108
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems â€¦
problem in question is treated by means of an unconstrained one, where the function
involved is the Lagrangian function.
Under the assumptions of Theorem 4.32, if Î» Ì¸= 0, the vectors âˆ‡f (x0, y0) and
âˆ‡h(x0, y0) are, therefore, proportional. The thesis of Theorem 4.32 can be rewritten
as
âˆ‡xL (x0, y0, Î») = 0,
whereas the relation
âˆ‡Î»L (x0, y0, Î») = 0
is equivalent to the feasibility of the pair (x0, y0), i.e. h(x0, y0) = 0.
We wish to stress that Theorem 4.32 gives only necessary optimality condi-
tions and that the â€œnatureâ€ of the constrained optimal points is not conserved by
the Lagrangian function L ( Â· , Î»). What can be said is that, if the assumptions of
Theorem 4.32 are satisï¬ed and (Â¯x, Â¯y) is a constrained optimal point for (P3), then
this point is a stationary point of the Lagrangian. For example, Â¯x = 1 is the minimum
point of f (x) = x3 under the constraint h(x) = x + 1 = 0 (and also the maximum
point, as in this rather â€œpathologicalâ€ case the feasible set intersects with the objec-
tive function at one point) with multiplier Î» = âˆ’3, but Â¯x is not a minimum point of
L (x, Â¯Î») on R.
Always for the case n = 2 and p = 1 we now give the second-order sufï¬cient
optimality conditions. These conditions will be proved next, for the general case.
Theorem 4.34 Let f (x, y) and h(x, y) be twice-continuously differentiable on the
open set X âŠ‚R2. Let (x0, y0) âˆˆK3, with
K3 =

(x, y) âˆˆR2 : h(x, y) = 0

,
and let (x0, y0, Î») satisfy relation (4.7). If the quadratic form
zâŠ¤âˆ‡2
x,yL (x0, y0, Î»)z
is positive deï¬nite

resp. negative deï¬nite

for all z âˆˆR2, z Ì¸= 0, such that
âˆ‡h(x0, y0)âŠ¤z = 0,
(4.8)
then (x0, y0) is a strict local minimum point of f on K3 [resp. a strict local maximum
point of f on K3].
We recall that on the grounds of Corollary 1.4, the above quadratic form is positive
deï¬nite

resp. negative deï¬nite

on the constraint (4.8) if, for the following bordered
matrix
 =

0
âˆ‡h(x0, y0)âŠ¤
âˆ‡h(x0, y0)
âˆ‡2
x,yL (x0, y0, Î»)


4.3 Optimization Problems with Equality Constraints â€¦
109
it holds det() < 0

resp. det() > 0

.
Example 4.35 Find, by the method of Lagrange multipliers, the minimizers and/or
maximizers, if any, of the function
f (x, y) = x + y
on the feasible set K3 =

(x, y) âˆˆR2 : x2 + 2y2 âˆ’6 = 0

.
We write the Lagrangian function in the form
L (x, y, Î») = x + y âˆ’Î»(x2 + 2y2 âˆ’6).
The conditions of Theorem 4.32 and the feasibility conditions are:
â§
âªâ¨
âªâ©
âˆ‚L
âˆ‚x = 1 âˆ’Î»2x = 0
âˆ‚L
âˆ‚y = 1 âˆ’Î»4y = 0
x2 + 2y2 âˆ’6 = 0.
From the ï¬rst two equations we have
Î» = 1
2x = 1
4y â‡’x = 2y.
From the third equation we have
4y2 + 2y2 = 6 â‡’y2 = 1 â‡’y = Â±1.
We have, therefore, the two triplets
A = (2, 1, 1
4); B = (âˆ’2, âˆ’1, âˆ’1
4).
Then we have
âˆ‡2
x,yL (x, y, Î») =
 âˆ’2Î»
0
0
âˆ’4Î»

.
Now we consider the bordered matrix
 =

0
âˆ‡h(x)âŠ¤
âˆ‡h(x)
âˆ‡2
x,yL (x, y, Î»)

,
i.e.
 =
â¡
â£
0
2x
4y
2x
âˆ’2Î»
0
4y
0
âˆ’4Î»
â¤
â¦.
At A = (2, 1, 1
4) we have

110
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems â€¦
Fig. 4.3 Example 4.35
 =
â¡
â£
0
4
4
4 âˆ’1
2
0
4
0
âˆ’1
â¤
â¦.
As det() = 24 > 0, the point (2, 1) is a constrained strict local maximum point.
At B = (âˆ’2, âˆ’1, âˆ’1
4) we have
 =
â¡
â£
0
âˆ’4 âˆ’4
âˆ’4
1
2
0
âˆ’4
0
1
â¤
â¦.
As det() = âˆ’24 < 0, the point (âˆ’2, âˆ’1) is a constrained strict local minimum
point.
Moreover, as the feasible set is closed and bounded and the objective function is
continuous on R2, really the points founded are constrained global extremum points.
This example is illustrated in Fig. 4.3.
Example 4.36 Find, by the method of Lagrange multipliers, the minimizers and/or
maximizers, if any, of
f (x, y) = x2 + y2
on the feasible set
K3 =

(x, y) âˆˆR2 : y2 âˆ’log(5 âˆ’x2) = 0

.
First of all, it must be x âˆˆ(âˆ’
âˆš
5,
âˆš
5). We write the Lagrangian function in the
form
L (x, y, Î») = x2 + y2 + Î»y2 âˆ’Î» log(5 âˆ’x2).
The conditions of Theorem 4.32 and the feasibility conditions are:

4.3 Optimization Problems with Equality Constraints â€¦
111
â§
âªâ¨
âªâ©
âˆ‚L
âˆ‚x = 2x + Î» 2x
5âˆ’x2 = 10xâˆ’2x3+2Î»x
5âˆ’x2
= 0
âˆ‚L
âˆ‚y = 2y + 2Î»y = 2y(1 + Î») = 0
âˆ‚L
âˆ‚Î» = y2 âˆ’log(5 âˆ’x2) = 0.
From the second equation we have y = 0 or Î» = âˆ’1.
(1) Let be Î» = âˆ’1. From the ï¬rst equation we have
10x âˆ’2x3 âˆ’2x = 0 â‡’2x(4 âˆ’x2) = 0,
from which x = 0 or x = âˆ’2 or x = 2.
(a) x = 0 â‡’y2 = log 5 â‡’y = Â±

log 5. We have, therefore, two â€œcandidate
pointsâ€:
A = (0,

log 5 );
B = (0, âˆ’

log 5 ),
with Î» = âˆ’1.
(b) x = 2 â‡’y2 = log 1 â‡’y = 0.
(c) x = âˆ’2 â‡’y = 0. We have two other â€œcandidate pointsâ€:
C = (âˆ’2, 0); D = (2, 0),
with Î» = âˆ’1.
(2) Let be y = 0 (and Î» any). From the third equation we have log(5 âˆ’x2) = 0 â‡’
x = Â±2. from the ï¬rst equation we ï¬nd again Î» = âˆ’1 and, therefore, we ï¬nd
again the points C and D.
We note that also in the present example the feasible set is closed and bounded.
Therefore, we have no necessity to use the second-order sufï¬cient conditions. We
have
f (A) = log 5 â‰ƒ0.699; f (B) = log 5; f (C) = 4; f (D) = 4.
Therefore, we have that C and D are constrained global maximizers (not strict
global maximizers!) and A and B are constrained global minimizers.
We are now ready to state the results for a general problem (P3) :
(P3) :
â§
â¨
â©
min f (x)
subject to: h j(x) = 0, âˆ€j = 1, . . . , p < n,
x âˆˆX âŠ‚Rn,
where X âŠ‚Rn is an open set contained in the domains of the functions involved
in (P3), f : X â†’R is differentiable on X and every h j : X â†’R, j = 1, . . . , p, is
continuously differentiable on X. We recall that the set
K3 =

x âˆˆX : h j(x) = 0, j = 1, . . . , p

is the feasible set of (P3).

112
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems â€¦
Deï¬nition 4.37 Let be x0 âˆˆK3; the cone
L(x0) =

y âˆˆRn : âˆ‡h j(x0)âŠ¤y = 0, j = 1, . . . , p

is called the linearizing cone of K3 at x0.
Obviously, as L(x0) is the solution set of a homogeneous linear the system, is a
linear space, therefore, a closed and convex set.
Theorem 4.38 Let x0 âˆˆK3; it holds
T (K3, x0) âŠ‚L(x0).
If the Jacobian matrix âˆ‡h(x0), of order (n, p), has full rank (i.e. rk(âˆ‡h(x0)) =
p), then
T (K3, x0) = L(x0).
Proof Let us consider a direction y âˆˆT (K3, x0), y Ì¸= 0, and without loss of gener-
ality let us suppose âˆ¥yâˆ¥= 1. Then there exists a feasible sequence

xk
âŠ‚K3, with
xk
yâ†’x0. The quotients
h(xk) âˆ’h(x0)
xk âˆ’x0
= âˆ‡h(x0)âŠ¤(xk âˆ’x0) + o(
xk âˆ’x0)
xk âˆ’x0
then converge to âˆ‡h(x0)âŠ¤y = 0. Therefore, y âˆˆL(x0).
To prove the second part of the theorem, let us assume that the Jacobian matrix
âˆ‡h(x0) has full rank. From the Implicit Function Theorem (Chap. 1, p. 6), it is
possible to express the system h(x) = 0 in a neighborhood of the point x0, by means
of p basic variables, i.e. with the notation used in the said theorem, to write
xB = H(xN).
The derivatives at the point x0 of the vector-valued function H : Rnâˆ’p â†’Rp
have the following representation:
âˆ‡H(x0
N) = âˆ’(âˆ‡Nh(x0))(âˆ‡Bh(x0))âˆ’1.
For a given vector
y =
 yB
yN

âˆˆL(x0),
the relation
âˆ‡h(x0)âŠ¤y = âˆ‡Bh(x0)âŠ¤yB + âˆ‡Nh(x0)âŠ¤yN = 0
is, therefore, equivalent to

4.3 Optimization Problems with Equality Constraints â€¦
113
yB = âˆ‡H(x0
N)âŠ¤yN.
Let us suppose yN Ì¸= 0 (otherwise we have also yB = 0 and the result would be
trivial). Without loss of generality, suppose âˆ¥yâˆ¥= 1. Then, there exists a sequence

xk
N

of non-basic variables which converges tangentially in the direction yN to the
point x0
N. Therefore, also the corresponding sequence of basic variables

xk
B

, with
xk
B = H(xk
N) converges to x0
B = H(x0
N). The sequence

xk
=
 xk
B
xk
N
"
=
 H(xk
N)
xk
N
"
is, therefore, feasible and tangentially convergent in the direction
y
âˆ¥yâˆ¥to the point x0,
being
xk
N âˆ’x0
N
xk
N âˆ’x0
N
 â†’y
and
H(xk
N) âˆ’H(x0
N)
xk
N âˆ’x0
N

â†’âˆ‡H(x0
N)âŠ¤yN = yB.
Therefore, it holds y âˆˆT (K3, x0).
â–¡
The previous result is a modern version of a classical result: the Theorem of
Lyusternik (see, e.g. Ioffe and Tikhomirov [8]).
We are now in a position to prove the general version of Theorem 4.32, i. e. the
â€œLagrange Multipliers Ruleâ€ for problem (P3).
Theorem 4.39 Let x0 âˆˆK3 be a local minimum point of (P3) and let the gradients
âˆ‡h1(x0), . . . , âˆ‡h p(x0) be linearly independent. Then, there exists a unique vector
of multipliers v1, . . . , vp âˆˆR such that
âˆ‡f (x0) +
p

j=1
v jâˆ‡h j(x0) = 0.
(4.9)
Proof As the gradients âˆ‡h j(x0), j = 1, . . . , p, are linearly independent, the Jaco-
bian matrix âˆ‡h(x0) has full rank and hence, on the grounds of the previous theorem,
it holds T (K3, x0) = L(x0). From Theorem 4.24 we have, therefore,
âˆ‡f (x0)âŠ¤y â‰§0, âˆ€y âˆˆL(x0).
As L(x0) is a linear subspace of Rn, the previous relation holds as an equality,
i.e.
âˆ‡f (x0)âŠ¤y = 0, âˆ€y âˆˆRn such that âˆ‡h(x0)âŠ¤y = 0.

114
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems â€¦
This means (recall also the theorem of the alternative of Motzkin, Theorem 2.31)
that the vector âˆ‡f (x0) is given by the linear combination of the column vectors
âˆ‡h1(x0), . . . , âˆ‡h p(x0) of the Jacobian matrix âˆ‡h(x0). This is just the thesis of the
theorem.
â–¡
As already said, the scalars v j âˆˆR, j = 1, . . . , p, are called â€œLagrange multipli-
ersâ€ and the function
L (x, v) = f (x) + vâŠ¤h(x) or also L (x, v) = f (x) âˆ’vâŠ¤h(x)
is called â€œLagrangian functionâ€. Obviously relation (4.9) holds also if x0 âˆˆK3 is a
local maximum point of (P3). The conditions
âˆ‡xL (x0, v) = 0; âˆ‡vL (x0, v) = 0
are, therefore, ï¬rst-order necessary conditions for x0 to be a local minimizer (or local
maximizer) for (P3).
A point x0 âˆˆK3 for which âˆ‡h(x0) has full rank is called a regular point for
(P3), which, in this case it is also called a â€œregular problemâ€. We point out that
when the constraints h j(x), j = 1, . . . , p, are all linear afï¬ne, there is no need to
assume the linear independence of the gradients at x0. See the section on constraint
qualiï¬cations in Chap. 6.
If x0 âˆˆK3 is not a regular point, it is possible to obtain the following ï¬rst-order
necessary optimality conditions for (P3), conditions attributed to C. Caratheodory
(1935) and which anticipate, for classical constrained optimization problems, the
Fritz John Theorem for problems (P4) and (P5). See Chaps. 5 and 6.
Theorem 4.40 (Caratheodory) Let x0 âˆˆK3 be a local minimum point for (P3).
Then, there exist multipliers v0, v1, . . . , vp âˆˆR, not all zero, such that
v0âˆ‡f (x0) +
p

j=1
v jâˆ‡h j(x0) = 0.
Proof If âˆ‡h(x0) has full rank, i.e. x0 is regular, i.e. rk(âˆ‡h(x0)) = p, then Theorem
4.39 applies with v0 = 1. If rk(âˆ‡h(x0)) < p, i.e. the vectors âˆ‡h1(x0), . . . , âˆ‡h p(x0)
are linearly dependent, there will exist multipliers, not all zero, v1, . . . , vp âˆˆR such
that
v1âˆ‡h1(x0) + Â· Â· Â· + vpâˆ‡h p(x0) = 0.
It is, therefore, sufï¬cient to choose v0 = 0.
â–¡
Remark 4.41 In the above result the situation v0 = 0 points out the â€œnon regularityâ€
of the problem, whereas a non zero multiplier v0 can be present in both regular
problems and non-regular problems. In other words, we have the implications

4.3 Optimization Problems with Equality Constraints â€¦
115
(P3) regular problem â‡’v0 Ì¸= 0.
v0 = 0 â‡’(P3) non-regular problem.
Indeed, if we write the Lagrangian function at x0 âˆˆK3 in the form
L (x0, v) = f (x0) âˆ’vâŠ¤h(x0),
we have that relation (4.9) is (âˆ‡h(x0) is the Jacobian matrix, of order (n, p)):
âˆ‡h(x0)v = âˆ‡f (x0).
From a well-known theorem on systems of linear equations, this system has a
solution v âˆˆRp if and only if (Theorem of RouchÃ©-Capelli)
rk(âˆ‡h(x0)) = rk(âˆ‡h(x0); âˆ‡f (x0)).
It is possible that the two ranks coincide even if rk(âˆ‡h(x0)) < p (for example, if
âˆ‡f (x0) = 0), and regardless of the fact that x0 is or not an optimal point for (P3)!.
Example 4.42 Consider the problem

min(x2 + y2)
subject to: (x âˆ’1)3 âˆ’y2 = 0.
By using, e.g. the level sets method, it is seen that the solution is at the point (1, 0).
This point is not regular, as âˆ‡h(1, 0) = (0, 0)âŠ¤. The Lagrange conditions (4.7) are
not veriï¬ed at x0 = [1, 0]âŠ¤. However, we have, with v0 = 0,
v0âˆ‡f (x0, y0) + v1âˆ‡h(x0, y0) = 0,
with v1 âˆˆR, v1 Ì¸= 0, relation which satisï¬es the thesis of Theorem 4.40.
We now give the second-order optimality conditions for optimization problems
with equality constraints.
Theorem 4.43 Let f : X â†’R and every h j : X â†’R, j = 1, . . . , p, be twice-
continuously differentiable on the open set X âŠ‚Rn.
(i) Let x0 âˆˆK3 be a local minimizer

resp. a local maximizer

of f on K3 and let
x0 be a regular point. Then, besides relation (4.9), it holds
yâŠ¤âˆ‡2
xL (x0, v)y â‰§0

resp. â‰¦0

for all y âˆˆRn such that
yâŠ¤âˆ‡h j(x0) = 0, j = 1, . . . , p.

116
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems â€¦
(ii) Let x0 âˆˆK3. If relation (4.9) is satisï¬ed by the pair (x0, v) and if
yâŠ¤âˆ‡2
xL (x0, v)y > 0

resp. < 0

for all y âˆˆRn, y Ì¸= 0, such that
yâŠ¤âˆ‡h j(x0) = 0, j = 1, . . . , p,
(4.10)
then x0 is a strict local minimizer

resp. a strict local maximizer

for f on K3.
Proof (i) This result is a direct consequence of Theorem 4.26. Being x0 a regular
point it will hold
âˆ‡xL (x0, v) = 0.
Moreover, x0 is a local minimizer

resp. local maximizer

in K3 of L ( Â· , v).
Therefore, we have
yâŠ¤âˆ‡2
xL (x0, v)y â‰§0

resp. â‰¦0

for all y âˆˆT (K3, x0). But, thanks to Theorem 4.38, T (K3, x0) = L(x0) and the
thesis follows.
(ii) This result is a direct consequence of Theorem 4.27. Being (4.9) satisï¬ed and
being, for all x âˆˆK3,
L (x, v) = f (x),
if
yâŠ¤âˆ‡2
xL (x0, v)y > 0

resp. < 0

for all y âˆˆT (K3, x0) \ {0} , then L (x0, v) <

resp. >

L (x, v), âˆ€x Ì¸= x0, x âˆˆK3.
This is equivalent to state that x0 is a strict local minimum point (resp. local maxi-
mum point) of f on K3. Being T (K3, x0) âŠ‚L(x0), we can substitute in the above
inequality T (K3, x0) with L(x0). See also the end lines of Remark 4.44.
â–¡
Remark 4.44 Following Hestenes [2], it is possible to assert that conditions (ii) of
the previous theorem guarantee that x0 is a strict local minimizer

resp. maximizer

of order 2 for (P3).
We recall (see Chap. 1) that in order to check the second-order sufï¬cient optimality
conditions (ii) of the previous theorem, we can consider the bordered matrix, of order
(p + n),
M(x0, v) =

0
âˆ‡h(x0)âŠ¤
âˆ‡h(x0) âˆ‡2
xL (x0, v)

.
If the leading principal minors of M(x0, v), of order 2p + 1, . . . , p + n, have
the sign of (âˆ’1)p, then the quadratic form yâŠ¤âˆ‡2
xL (x0, v)y is positive deï¬nite on
the set (4.10). If the leading principal minors of M(x0, v), of order 2p + 1, . . . , p +
n, alternate in sign, beginning with the sign of (âˆ’1)p+1, then the quadratic form

4.3 Optimization Problems with Equality Constraints â€¦
117
yâŠ¤âˆ‡2
xL (x0, v)y isnegativedeï¬niteontheset (4.10).Notethatiftheaboveconditions
on M(x0, v) are satisï¬ed, then the gradients âˆ‡h1(x0), . . . , âˆ‡h p(x0) are linearly
independent and hence T (K3, x0) = L(x0).
We have also sufï¬cient conditions for global optimality.
Theorem 4.45 Let x0 âˆˆK3 and let the pair (x0, v) satisfy relation (4.9). If L (x, v)
is pseudoconvex, with respect to x, on the open convex set X âŠ‚Rn, then x0 is a
global minimizer of f on K3. If L (x, v) is pseudoconcave in x, then x0 is a global
maximizer of f on K3.
Proof If L (x, v) is pseudoconvex, with respect to x, we have, for all x âˆˆX,
(x âˆ’x0)âŠ¤âˆ‡L (x0, v) â‰§0 â‡’L (x, v) â‰§L (x0, v).
But being (4.9) satisï¬ed, we have, âˆ€x âˆˆK3 :
(x âˆ’x0)âŠ¤âˆ‡L (x0, v) = 0 â‡’f (x) + vâŠ¤h(x) â‰§f (x0) + vâŠ¤h(x0),
i.e. , âˆ€x âˆˆK3 :
f (x) â‰§f (x0).
â–¡
We recall that if f is convex and the Lagrangian function is given in the form
L (x, v) = f (x) + p
j=1 v jh j(x), then L (x, v) is convex (with respect to x) if
every h j is a convex function and all multipliers are positive. If all constraints are
linear afï¬ne (i.e. h j(x) = (a j)âŠ¤x âˆ’b j, j = 1, . . . , p) and the objective function
is convex

resp. concave

, then the Lagrangian function is convex

resp. concave

regardless of the sign of the multipliers. We can, therefore, give the following result.
Theorem 4.46 Suppose f be convex

resp. concave

on the convex set X âŠ‚Rn and
suppose h1, . . . , h p be linear afï¬ne. Then x0 âˆˆK3, such that the pair (x0, v) satisfy
relation (4.9), is a global minimizer

resp. a global maximizer

of f on K3.
Example 4.47 Find the minimizers and/or the maximizers, if any, of
f (x) = 5x1 + 2x2 âˆ’x3
on the feasible set
K3 =

(x1, x2, x3) âˆˆR3 : x1x2 = 3; x1x3 = 1

.
We write the Lagrangian function in the form
L (x, v) = 5x1 + 2x2 âˆ’x3 + v1(3 âˆ’x1x2) + v2(1 âˆ’x1x3).

118
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems â€¦
The system âˆ‡x,vL (x, v) = 0 is
â§
âªâªâªâªâ¨
âªâªâªâªâ©
5 âˆ’v1x2 âˆ’v2x3 = 0
2 âˆ’v1x1 = 0
âˆ’1 âˆ’v2x1 = 0
3 âˆ’x1x2 = 0
1 âˆ’x1x3 = 0.
We have: x2 = 3
x1 ; x3 = 1
x1 ; v1 = 2
x1 ; v2 = âˆ’1
x1 = âˆ’x3. The ï¬rst equation
becomes then
5 âˆ’2
x1
Â· 3
x1
+ 1
x1
Â· 1
x1
= 0,
i.e.
5 âˆ’
5
(x1)2 = 0.
We have, therefore,
x1 = Â±1; x2 = Â±3; x3 = Â±1; v1 = Â±2; v2 = âˆ“1.
Therefore, the two vectors
A = (1, 3, 1; 2, âˆ’1); B = (âˆ’1, âˆ’3, âˆ’1; âˆ’2, 1).
The bordered matrix M(x, v) is
M(x, v) =
â¡
â¢â¢â¢â¢â£
0
0
âˆ’x2
âˆ’x1
0
0
0
âˆ’x3
0
âˆ’x1
âˆ’x2
âˆ’x3
0
âˆ’v1
âˆ’v2
âˆ’x1
0
âˆ’v1
0
0
0
âˆ’x1
âˆ’v2
0
0
â¤
â¥â¥â¥â¥â¦
.
Being n = 3 and p = 2, we have to compute only the leading principal minors
of M of order 2p + 1 = 5, i.e. det(M). For A we have det(M(x1, v1)) = 10 and
for B we have det(M(x2, v2)) = âˆ’10. As det(M(x1, v1)) has the sign of (âˆ’1)2,
it results that the constrained quadratic form is positive deï¬nite and hence x1 =
[1, 3, 1]âŠ¤is a constrained strict local minimizer. As det(M(x2, v2)) has the sign of
(âˆ’1)3, it results that the constrained quadratic form is negative deï¬nite and hence
x2 = [âˆ’1, âˆ’3, âˆ’1]âŠ¤is a constrained strict local maximizer.
Example 4.48 Factorize the integer number 8 into three positive (not necessarily
integer) factors, such that the sum of the inverses of the said factors is minimal.
In other words, we have the problem

4.3 Optimization Problems with Equality Constraints â€¦
119
min
 1
x1
+ 1
x2
+ 1
x3
"
subject to: x1x2x3 = 8.
We use the Lagrangian multipliers method. The Lagrangian function is
L (x, v) = 1
x1
+ 1
x2
+ 1
x3
+ v(x1x2x3 âˆ’8)
and the related ï¬rst-order conditions are
âˆ‡xL (x, v) =
â›
â
âˆ’(x1)âˆ’2
âˆ’(x2)âˆ’2
âˆ’(x3)âˆ’2
â
â + v
â›
â
x2x3
x3x1
x1x2
â
â =
â›
â
0
0
0
â
â .
Obviously v Ì¸= 0; we obtain the equation
1
v = (x1)2x2x3 = x1(x2)2x3 = x1x2(x3)2.
We ï¬nd the solution x1 = x2 = x3 = 2, with the related multiplier v =
1
16. We
have
âˆ‡2
xL (x, v) =
â›
â
2(x1)âˆ’3
vx3
vx2
vx3
2(x2)âˆ’3
vx1
vx2
vx1
2(x3)âˆ’3
â
â .
For x0 = [2, 2, 2]âŠ¤and v =
1
16 we have
âˆ‡2
xL (x, v) = 1
8
â›
â
2 1 1
1 2 1
1 1 2
â
â .
This matrix is positive deï¬nite everywhere (and not only on the set âˆ‡h(x0)âŠ¤y =
0). Therefore, the point x0 = [2, 2, 2]âŠ¤is a constrained global minimum point, as f
is a strictly convex function on int(R3
+).
Example 4.49 Find the minimizers and/or maximizers, if any, of
f (x) = x2 + y2 + z2
subject to: x + 2y + z = 1; 2x âˆ’y âˆ’3z = 4.
We write the Lagrangian function in the form
L (x, v) = x2 + y2 + z2 âˆ’v1(x + 2y + z âˆ’1) âˆ’v2(2x âˆ’y âˆ’3z âˆ’4).
We write the system

120
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems â€¦
â§
âªâ¨
âªâ©
âˆ‚L
âˆ‚x = 2x âˆ’v1 âˆ’2v2 = 0
âˆ‚L
âˆ‚y = 2y âˆ’2v1 + v2 = 0
âˆ‚L
âˆ‚z = 2z âˆ’v1 + 3v2 = 0.
We obtain from the ï¬rst two equations v1 = 2x
5 + 4y
5 ; v2 = 4x
5 âˆ’2y
5 . By insert-
ing these expressions in the third equation we get x âˆ’y + z = 0. This expression,
together with the two linear constraints, determines a linear system of three equations
in three unknowns. We obtain the (unique) solution
x = 16
15, y = 1
3, z = 11
15.
We observe that the objective function f (x) = x2 + y2 + z2 is a strictly con-
vex function (it is the sum of strictly convex functions). Since the constraints are
both linear afï¬ne, the Lagrangian function is, therefore, (strictly) convex. Hence the
point
 16
15, 1
3, 11
15
âŠ¤is the unique constrained strict global minimizer of the objective
function.
Example 4.50 (Variational characterization of the eigenvalues of a symmetric
matrix A of order n) Let us consider the Rayleigh quotient
R(x) = xâŠ¤Ax
âˆ¥xâˆ¥2 ,
where x âˆˆRn \ {0} and A is a symmetric matrix of order n. This function is homo-
geneous of zero degree: it holds, for t > 0, x Ì¸= 0,
R(tx) = (tx)âŠ¤A(tx)/ âˆ¥txâˆ¥2 = t2xâŠ¤Ax/t2 âˆ¥xâˆ¥2 = R(x).
Therefore, in order to compute the minimum and the maximum of R(x) for
x âˆˆRn \ {0} , if they exist, it is sufï¬cient to compute the minimum and the maximum
of R(x) on the unit sphere
U =

x âˆˆRn : âˆ¥xâˆ¥= 1

.
Note that we have a continuous function xâŠ¤Ax on a compact set and, therefore,
the Weierstrass theorem applies. Let us denote
m = min {R(x) : x âˆˆU} ; M = max {R(x) : x âˆˆU} .
Let us order the eigenvalues of A (which are all real!) in the following way:
Î»1 â‰§Î»2 â‰§Â· Â· Â· â‰§Î»n.
We want to prove the following proposition.

References
121
â€¢ If A is a symmetric matrix, of order n, with eigenvalues Î»1 â‰§Î»2 â‰§Â· Â· Â· â‰§Î»n, then
max
xÌ¸=0 R(x) = max
xâˆˆU R(x) = Î»1;
min
xÌ¸=0 R(x) = min
xâˆˆU R(x) = Î»n.
We use the Lagrangian multipliers theorem, where the objective function is
f (x) = xâŠ¤Ax and x âˆˆU can be expressed as h(x) = xâŠ¤x âˆ’1 = 0. We write
the Lagrangian function L (x, Î») in the form
L (x, Î») = f (x) âˆ’Î»h(x) = xâŠ¤Ax âˆ’Î»(xâŠ¤x âˆ’1).
The gradient of L with respect to x is
âˆ‡xL (x, Î») = 2Ax âˆ’2Î»x.
Therefore, the condition âˆ‡xL (x, Î») = 0 becomes
Ax = Î»x, x âˆˆU.
The maximum and minimum points of R(Â·) on U (points which surely exist) are to
be looked for among the n orthonormal eigenvectors v1, v2, . . . , vn of the matrix
A, eigenvectors corresponding to the eigenvalues Î»1, Î»2, . . . , Î»n. Let us compute
the value which R(Â·) assumes in correspondence of an eigenvector v j âˆˆU :
R(v j) = (v j)âŠ¤Av j = (v j)âŠ¤(Î» jv j) = Î» j(v j)âŠ¤v j = Î» j,
as (v j)âŠ¤v j = 1. We conclude that R(Â·) reaches its maximum value for x = v1 and
its minimum value for x = vn. We ï¬nd, as a corollary, the well-known criterion
(see Chap. 1) for stating the sign of a (real) quadratic form Q(x) = xâŠ¤Ax, where
the eigenvalues of A have been ordered in the following way: Î»1 â‰§Î»2 â‰§Â· Â· Â· â‰§Î»n.
â€¢ Q(x) is positive deï¬nite if and only if Î»n > 0.
â€¢ Q(x) is positive semideï¬nite if and only if Î»n â‰§0.
â€¢ Q(x) is negative deï¬nite if and only if Î»1 < 0.
â€¢ Q(x) is negative semideï¬nite if and only if Î»1 â‰¦0.
â€¢ Q(x) is indeï¬nite if and only if Î»n < 0 < Î»1.
References
1. M.R. Hestenes, Calculus of Variations and Optimal Control Theory (Wiley, New York, 1966)
2. M.R. Hestenes, Optimization Theory. The Finite Dimensional Case (Wiley, New York, 1975)
3. A. Ben-Israel, B. Mond, What is invexity? J. Austral. Math. Soc. Ser. B 28, 1â€“9 (1986)

122
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems â€¦
4. B.D. Craven, B.M. Glover, Invex functions and duality. J. Aust. Math. Soc. Ser. A 39, 1â€“20
(1985)
5. M. Guignard, Generalized Kuhn-Tucker conditions for mathematical programming problems
in a Banach space. SIAM J. Control 7, 232â€“241 (1969)
6. G. Giorgi, T.H. Kjeldsen, Traces and Emergence of Nonlinear Programming (BirkhÃ¤user, Basel
and New York, 2014)
7. P. Bussotti, On the genesis of the Lagrange multipliers. J. Optim. Theory Appl. 117, 453â€“459
(2003)
8. A.D. Ioffe, V.M. Tichomirov, Theory of Extremal Problems (North Holland, Amsterdam, 1979)
9. A. Prekopa, On the development of optimization theory. Amer. Math. Mon. 87, 527â€“542 (1980)

Chapter 5
Constrained Optimization Problems
with Inequality Constraints
5.1
First-Order Conditions
In the present chapter, we are concerned with constrained optimization problems
with inequality constraints, i.e. with problem (P4).
(P4) :
â§
â¨
â©
min f (x)
subject to: gi(x) â‰¦0, i = 1, . . . , m,
x âˆˆX âŠ‚Rn,
where X is an open set contained in the domains of the functions involved in (P4),
f and each gi, i = 1, . . . , m, are real-valued functions deï¬ned on Rn. The function
f is the objective function of (P4), gi, i = 1, . . . , m, are the constraints and the set
K4 =

x âˆˆX : gi(x) â‰¦0, i = 1, . . . , m

is the feasible set of (P4).
In the last century, just before the Second World War, it became apparent that there
are many optimization problems which involve constraints in the form of inequalities,
instead of in the form of equalities, or involve constraints in the form of both inequali-
ties and equalities. The transition from â€œclassicalâ€ constrained optimization problems
to â€œmodernâ€ constrained optimization problems (i.e. with constraints expressed by
inequalities) requested almost 180 years! This, above all due to the fact that, whereas
the constrained classical optimization problems are substantially treated by means
of a standard result of Mathematical Analysis, i.e. the Implicit Function Theorem,
the modern constrained optimization problems require results from Convex Analysis
and Linear Algebra, topics developed mainly during the 20th century.
It was during the Second World War, in the USA, and a few years before its begin-
ning, in the Soviet Union, that a new chapter in the theory of constrained optimization
was developed: the Linear Programming theory by the American mathematician G.
Â© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al., Basic Mathematical Programming Theory, International Series
in Operations Research & Management Science 344,
https://doi.org/10.1007/978-3-031-30324-1_5
123

124
5
Constrained Optimization Problems with Inequality Constraints
B. Dantzig and by the Russian mathematician L. V. Kantorovich (Nobel prize in
Economic Science in 1975, together with T. C. Koopmans). In 1951, in the USA,
mathematicians H. W. Kuhn and A. W. Tucker developed the Lagrange multipliers
rule with reference to convex and nonconvex (nonlinear) programming problems
with inequality constraints. Some years before [3], the mathematician Fritz John had
published a paper on the same subject (perhaps the ï¬rst published paper on these
problems), obtaining some weaker optimality conditions with respect to the ones of
Kuhn and Tucker. But, prior to F. John and Kuhn and Tucker, in 1939 W. Karush
in his Masterâ€™s Thesis at the University of Chicago, had obtained optimality condi-
tions for (P4), similar to the ones of Kuhn and Tucker. Thus, these conditions are
now known as Karush-Kuhn-Tucker conditions. The thesis of Karush was neglected
for several years and has been entirely published only in 2014. See Giorgi and
Kjeldsen [4].
For our purposes, the formulation of (P4) is sufï¬ciently general. We recall that the
maximization problem max f (x), x âˆˆK4, is equivalent to min {âˆ’f (x)} , x âˆˆK4.
Obviously, it holds
f (x0) â‰¡max f (x) = âˆ’min {âˆ’f (x)} .
Moreover, if we have some inequalities of the type gk(x) â‰§0, obviously, these
ones are equivalent to âˆ’gk(x) â‰¦0. If we have some constraints of the type gk(x) â‰¦
bk, it is possible to write them as Ï•k(x) â‰¦0, with Ï•k(x) = gk(x) âˆ’bk. Also the
constraints x1 â‰§0, . . . , xn â‰§0 (i.e. x â‰§0, x âˆˆRn) may be rewritten in the form
âˆ’x1 â‰¦0
âˆ’x2 â‰¦0
...
âˆ’xn â‰¦0,
even if this procedure is often not convenient.
Given x0 âˆˆK4, the constraints gi for which it holds gi(x0) = 0 are called active
constraints (or binding constraints or effective constraints) at x0. Those constraints
for which at x0 âˆˆK4, we have gi(x0) < 0, are called non-active constraints (or
non-binding constraints or non-effective constraints) at x0. For x0 âˆˆK4, the set
I (x0) =

i âˆˆ{1, . . . , m} : gi(x0) = 0

is the set of indices of those constraints which are active at x0. It is also called set of
the active constraints at x0.
The active constraints have a special meaning: they restrict feasible corrections
around a feasible point. If a constraint gi is non-active at a feasible point x0 (i.e.
gi(x0) < 0) it is possible to move from x0 a bit in any direction without violating

5.1 First-Order Conditions
125
this constraint. So, in a sense, at least locally, non-active constraints are not important
with respect to optimality criteria for (P4).
Example 5.1 Let be, with x = (x1, x2) âˆˆR2,
g1(x) = x2 âˆ’(x1)2 â‰¦0;
g2(x) = x1 âˆ’1 â‰¦0;
g3(x) = âˆ’x1 â‰¦0;
g4(x) = âˆ’x2 â‰¦0.
At x0 = (0, 0)âŠ¤, we have I (x0) = {1, 3, 4} ; at x0 = (1, 0)âŠ¤, we have I (x0) =
{2, 4} ; at x0 =
 7
8, 1
2
âŠ¤, we have I (x0) = âˆ….
So, if I (x0) = âˆ…, problem (P4) becomes an unconstrained optimization problem
and this case is therefore not relevant to what treated in the present chapter.
Let us now make the assumption that all the functions involved in (P4) are (at
least) differentiable on the open set X âŠ‚Rn.
Deï¬nition 5.2 Let be x0 âˆˆK4; the set (polyhedral cone)
L(x0) =

y âˆˆRn : âˆ‡gi(x0)âŠ¤y â‰¦0, âˆ€i âˆˆI (x0)

is called linearizing cone of K4 at x0 (or also cone of locally constrained directions
of K4 at x0).
The set
Lo(x0) =

y âˆˆRn : âˆ‡gi(x0)âŠ¤y < 0, âˆ€i âˆˆI (x0)

is called cone of interior locally constrained directions of K4 at x0 or cone of descent
directions of K4 at x0.
Obviously, L(x0) Ì¸= âˆ…because 0 âˆˆL(x0). Actually, L(x0) is a polyhedral cone
and thus it is closed and convex. On the other hand, Lo(x0) is an open convex cone,
being Lo(x0) = int(L(x0)). Therefore, cl(Lo(x0)) = L(x0) if and only if Lo(x0) Ì¸=
âˆ…. Geometrically, each vector y âˆˆLo(x0) has a negative projection on the gradients
of active inequality constraints. This implies that moving from x0 along y within a
certain range of steps will not violate the constraint. Hence, y is a feasible direction,
i.e. y âˆˆF(K4, x0). L(x0) and Lo(x0) provide analytic representations of the local
approximation of K4 at x0.
Theorem 5.3 Let x0 âˆˆK4; then it holds
Lo(x0) âŠ‚F(K4, x0) âŠ‚A(K4, x0) âŠ‚T (K4, x0) âŠ‚L(x0),
where F(K4, x0), A(K4, x0), and T (K4, x0) are, respectively, the cone of feasible
directions to K4 at x0, the cone of attainable directions to K4 at x0, and the cone of
tangent directions or Bouligand tangent cone or contingent cone to K4 at x0.

126
5
Constrained Optimization Problems with Inequality Constraints
Proof If I (x0) = âˆ…, then x0 âˆˆint(K4) and it holds trivially Lo(x0) = F(K4, x0) =
A(K4, x0) = T (K4, x0) = L(x0) = Rn. Let us suppose therefore that I (x0) Ì¸= âˆ….
Let be y âˆˆLo(x0), and without loss of generality, let be âˆ¥yâˆ¥= 1. First we prove that
Lo(x0) âŠ‚F(K4, x0). We need to show that there exists Î´0 > 0 such that x0 + Î´y âˆˆ
K4, âˆ€Î´ âˆˆ[0, Î´0] . When i /âˆˆI (x0), we have, thanks to the continuity of gi,
gi(x0 + Î´y) < 0,
when Î´ is sufï¬ciently small. When i âˆˆI (x0), for Î´ > 0 and sufï¬ciently small, we
have
gi(x0 + Î´y) = gi(x0) + Î´âˆ‡gi(x0)âŠ¤y + o(t).
Consequently, gi(x0 + Î´y) < gi(x0) = 0, for Î´ > 0 sufï¬ciently small. There-
fore, y âˆˆF(K4, x0) and Lo(x0) âŠ‚F(K4, x0). From the deï¬nitions of F(K4, x0),
A(K4, x0) and T (K4, x0) it is easy to check that F(K4, x0) âŠ‚A(K4, x0) âŠ‚T (K4,
x0) (see Remark 2.45). Finally, we prove that T (K4, x0) âŠ‚L(x0). Let be y âˆˆ
T (K4, x0), with y Ì¸= 0 and, without loss of generality, with âˆ¥yâˆ¥= 1. There will exist
therefore a feasible sequence

xk
âŠ‚K4, with xk
yâ†’x0. Then, for every i âˆˆI (x0),
the quotients
gi(xk) âˆ’gi(x0)
		xk âˆ’x0		
= âˆ‡gi(x0)âŠ¤(xk âˆ’x0) + o(
		xk âˆ’x0		)
		xk âˆ’x0		
converge to âˆ‡gi(x0)âŠ¤y â‰¦0. Then y âˆˆL(x0).
â–¡
Theorem 5.3 shows that L(x0) can be slightly larger (if not equal to) F(K4, x0),
A(K4, x0) and T (K4, x0). We note, moreover, that it holds (see Theorem 2.24, prop-
erties of polar cones):
(L(x0))âˆ—âŠ‚(T (K4, x0))âˆ—âŠ‚(A(K4, x0))âˆ—âŠ‚(F(K4, x0))âˆ—âŠ‚(Lo(x0))âˆ—.
Corollary 5.4 If Lo(x0) Ì¸= âˆ…, then it holds
cl(Lo(x0)) = T (K4, x0) = L(x0).
Proof Let be y âˆˆL(x0), i.e.
âˆ‡gi(x0)âŠ¤y â‰¦0, âˆ€i âˆˆI (x0).
Now we choose a vector y0 âˆˆLo(x0) Ì¸= âˆ…, i.e. a vector y0 such that
âˆ‡gi(x0)âŠ¤y < 0, âˆ€i âˆˆI (x0).
For all Î» > 0, we have therefore

5.1 First-Order Conditions
127
âˆ‡gi(x0)âŠ¤(y + Î»y0) = âˆ‡gi(x0)âŠ¤y + Î»âˆ‡gi(x0)y0 < 0, âˆ€i âˆˆI (x0).
Hence, y + Î»y0 âˆˆLo(x0). Consequently, it holds y âˆˆcl(Lo(x0)) and therefore
we obtain the inclusion L(x0) âŠ‚cl(Lo(x0)), from which we obtain the thesis, on
the grounds of the previous theorem and taking into account the fact that both cones
T (K4, x0) and L(x0) are closed.
â–¡
We shall see that the condition Lo(x0) Ì¸= âˆ…is known as â€œCottle Constraint Qual-
iï¬cationâ€, a condition that really is due to Arrow, Hurwicz, and Uzawa [1].
We can now obtain the ï¬rst important result concerning necessary optimality con-
ditions for (P4), i.e. the Fritz John conditions. Perhaps this result is the ï¬rst published
theorem [3] regarding optimality conditions for a mathematical programming prob-
lem with inequality constraints. Though this result is usually treated without many
comments and with little emphasis in several books on optimization theory, recent
works by Bertsekas [5] and Bertsekas and Ozdaglar [6] bring a new light on the Fritz
John Theorem. These authors speak of â€œenhanced Fritz John conditionsâ€, as their
conditions are useful also in view of theoretic and algorithmic developments. We
shall revert to the main results of Bertsekas and Ozdaglar in the next chapter. We
now give the classical version of the Fritz John theorem.
Theorem 5.5 (Fritz John Theorem) Let x0 âˆˆK4 be a local minimum point for (P4).
Then there exist multipliers u0 â‰§0, u1 â‰§0, . . . , um â‰§0, not all zero, such that
u0âˆ‡f (x0) +
m

i=1
uiâˆ‡gi(x0) = 0,
uigi(x0) = 0,
âˆ€i = 1, . . . , m.
Proof Let x0 âˆˆK4 be a local minimum point for (P4). Then we have (Theorem
4.24):
âˆ‡f (x0)âŠ¤y â‰§0, âˆ€y âˆˆT (K4, x0) âŠƒLo(x0).
We have also âˆ‡f (x0)âŠ¤y â‰§0 for all vectors y such that âˆ‡gi(x0)âŠ¤y < 0, i âˆˆI (x0).
In other words, the system of linear inequalities
âˆ‡f (x0)âŠ¤y < 0; âˆ‡gi(x0)âŠ¤y < 0, i âˆˆI (x0),
does not admit solutions y âˆˆRn. Thanks to Gordanâ€™s theorem of the alternative
(see Chap. 2, p. 44), it results that there exist multipliers ui â‰§0, i âˆˆ{0} âˆªI (x0),
nonnegative and not all zero, such that
u0âˆ‡f (x0) +

iâˆˆI (x0)
uiâˆ‡gi(x0) = 0.
By choosing ui = 0, âˆ€i /âˆˆI (x0), we obtain the thesis.
â–¡

128
5
Constrained Optimization Problems with Inequality Constraints
The conditions uigi(x0) = 0, i = 1, . . . , m, are called complementary slackness
conditions. Note that if I (x0) = âˆ…, we have the result âˆ‡f (x0) = 0, i.e. x0 is a
stationary point for f . Note that only the multipliers u0, ui, i âˆˆI (x0), are required to
be not all zero. If u0 = 0, the necessary optimality conditions expressed by Theorem
5.5 become useless, as in this case, the role played by the objective function vanishes.
It is therefore important to have conditions which assure u0 Ì¸= 0, i.e. without loss of
generality, u0 = 1. The conditions which assure, in Theorem 5.5, u0 = 1, are called
â€œconstraint qualiï¬cationsâ€ and have for (P4) the role that the â€œregularity conditionsâ€
have for the â€œclassicalâ€ constrained optimization problem (P3).
The result, contained in the proof of Theorem 5.5: Let x0 âˆˆK4 be a local minimum
point for (P4); then the system

âˆ‡f (x0)âŠ¤y < 0
âˆ‡gi(x0)âŠ¤y < 0, i âˆˆI (x0),
has no solution y âˆˆRn, is also known as Abadie linearization lemma (Abadie [7]).
Its geometric meaning is clear: if x0 is a local solution of (P4), there does not exist
a direction y âˆˆRn along which it is possible to remain in the feasible set and at the
same time to decrease the objective function.
The complementary slackness conditions emphasize that both ui and gi(x0) can-
not hold with a strict inequality at the same time. Hence,
gi(x0) < 0 â‡’ui = 0;
gi(x0) = 0 â‡’ui â‰§0;
ui > 0 â‡’gi(x0) = 0.
If, for all i âˆˆI (x0), we have ui > 0, we say that the strict complementary slack-
ness conditions hold at x0, i.e.
gi(x0) = 0 â‡”ui > 0.
These conditions are important for some questions regarding second-order opti-
mality conditions and for some questions of sensitivity analysis (see Chap. 7).
Example 5.6 Let us consider the problem
â§
â¨
â©
min f (x1, x2) = x1 + x2
subject to: âˆ’(x1)3 + x2 â‰¦0,
âˆ’x2 â‰¦0.
It is easy to see (by geometric considerations) that the solution of the problem is the
point x0 = (0, 0)âŠ¤. The Fritz John conditions for this problem are:
u0
1
1

+ u1
âˆ’3(x1)2
1

+ u2
 0
âˆ’1

=
0
0

;

5.1 First-Order Conditions
129
u1(âˆ’(x1)3 + x2) = 0;
u2(âˆ’x2) = 0;
u0 â‰§0, u1 â‰§0, u2 â‰§0, not all zero.
At x0 = (0, 0)âŠ¤, we have
u0
 1
1

+ u1
0
1

+ u2
 0
âˆ’1

=
0
0

,
i.e.
u0 + u1 Â· 0 + u2 Â· 0 = 0
u0 + u1 âˆ’u2 = 0,
from which it results that u0 = 0 (and u1 = u2 that can be chosen > 0).
In their pioneering paper of 1951 Kuhn and Tucker [8] introduced a condition,
called â€œconstraint qualiï¬cationâ€ (indeed, it was already introduced by Karush in 1939
in his Master Thesis) in order to avoid that, in the Fritz John conditions, we have (as
in Example 2) u0 = 0. There are many constraint qualiï¬cations, ranking from simple
ones, easy to check, to sophisticated ones, more general but less easy to check. A
problem (P4), where a constraint qualiï¬cation holds, is therefore called â€œqualiï¬edâ€.
Constraint qualiï¬cations usually are conditions regarding only the constraints and not
also the objective function. We consider for problem (P4) a very general constraint
qualiï¬cation, due to Guignard [9] and Gould and Tolle [10]. We shall see in the next
chapter that this constraint qualiï¬cation is, in a certain sense, the weakest among the
other constraint qualiï¬cations proposed for (P4) or for (P5).
Let x0 âˆˆK4. We say that the Guignard-Gould-Tolle constraint qualiï¬cation holds
if
(L(x0))âˆ—= (T (K4, x0))âˆ—,
(5.1)
which can be equivalently expressed as
L(x0) = (T (K4, x0))âˆ—âˆ—,
or also as
L(x0) = P(K4, x0) â‰¡cl(conv(T (K4, x0))).
In order to obtain the celebrated Kuhn-Tucker conditions or, better, Karush-Kuhn-
Tucker conditions, we need a simple previous result. Following Gould and Tolle [10,
11], we introduce for (P4) the cone of gradients:
B(x0) =
â§
â¨
â©y âˆˆRn : y =

iâˆˆI (x0)
uiâˆ‡gi(x0), ui â‰§0, âˆ€i âˆˆI (x0)
â«
â¬
â­.

130
5
Constrained Optimization Problems with Inequality Constraints
Note that the cone of gradients is a ï¬nitely generated cone and hence it is closed
and convex (see Theorem 2.26). It is easy to show that B(x0) and L(x0) are polar
cones of each other.
Lemma 5.7 Let x0 âˆˆK4. Then it holds
B(x0) = (L(x0))âˆ—
and
L(x0) = (B(x0))âˆ—.
Proof Obviously, we prove only the ï¬rst equality. The inclusion B(x0) âŠ‚(L(x0))âˆ—
is obvious: consider any y âˆˆL(x0) and thus yâŠ¤âˆ‡gi(x0) â‰¦0, âˆ€i âˆˆI (x0). Thus, for
ui â‰§0, i âˆˆI (x0), we have 
iâˆˆI (x0) ui yâŠ¤âˆ‡gi(x0) â‰¦0. This shows that B(x0) âŠ‚
(L(x0))âˆ—. The opposite inclusion is a direct consequence of Farkasâ€™ theorem (see
Theorem 2.28).
â–¡
We are now able to prove, under assumption (5.1), the celebrated Karush-Kuhn-
Tucker conditions for (P4), perhaps the most important theorem for this kind of
mathematical programming problems.
Theorem 5.8 (Karush-Kuhn-Tucker) Let x0 âˆˆK4 be a local solution of (P4) and let
(5.1)beveriï¬ed,i.e.letbeveriï¬edtheGuignard-Gould-Tolleconstraintqualiï¬cation.
Then, there exist multipliers (â€œKarush-Kuhn-Tucker multipliersâ€) u1, . . . , um, such
that
âˆ‡f (x0) +
m

i=1
uiâˆ‡gi(x0) = 0,
(5.2)
uigi(x0) = 0, i = 1, . . . , m,
(5.3)
ui â‰§0, i = 1, . . . , m.
(5.4)
Proof We have proved in Theorem 4.24, that if x0 âˆˆK4 is a local solution of (P4),
then
âˆ’âˆ‡f (x0) âˆˆ(T (K4, x0))âˆ—.
But if (5.1) holds, then we can write the above relation as
âˆ’âˆ‡f (x0) âˆˆ(L(x0))âˆ—
and, on the grounds of Lemma 5.7,
âˆ’âˆ‡f (x0) âˆˆB(x0).
Consequently, there exist multipliers ui â‰§0, i âˆˆI (x0), such that

5.1 First-Order Conditions
131
Fig.
5.1 Geometric
interpretation
of
the
Karush-Kuhn-Tucker
conditions:
âˆ’âˆ‡f (x0) =
u1âˆ‡g1(x0) + u2âˆ‡g2(x0) with u1, u2 â‰§0, g3 is not active at x0. f decreases in the direction
âˆ’âˆ‡f (x0) and f attains a local minimum at x0
âˆ’âˆ‡f (x0) =

iâˆˆI (x0)
uiâˆ‡gi(x0).
(5.5)
Now, taking ui = 0 for all i /âˆˆI (x0), the thesis of the theorem is proved.
â–¡
By using the Lagrangian function (here perhaps it is better to speak of Lagrange-
Kuhn-Tucker function)
L (x, u) = f (x) +
m

i=1
uigi(x),
the conditions (5.2)â€“(5.3)â€“(5.4) of Theorem 5.8 can be rewritten in the form
âˆ‡xL (x0, u) = 0;
uigi(x0) = 0, i = 1, . . . , m;
ui â‰§0, i = 1, . . . , m.
Note that for I (x0) = âˆ…, the Karush-Kuhn-Tucker conditions collapse to the sta-
tionarity condition âˆ‡f (x0) = 0. If I (x0) Ì¸= âˆ…, relation (5.5) says that the steepest
descent direction (i.e. negative gradient) of the objective function, âˆ’âˆ‡f (x0), is a
conic combination of the gradients of the active constraint functions (see Fig. 5.1).
This means that in general the active constraints could be violated if we move x0
along a descent direction of f at x0.
We insist on the fact that the Karush-Kuhn-Tucker theorem (and also the Fritz
John theorem) gives necessary optimality conditions, but not sufï¬cient ones.

132
5
Constrained Optimization Problems with Inequality Constraints
Example 5.9 Consider the problem

min(x1 + x2)
subject to: âˆ’(x1)2 âˆ’(x2)2 + 2 â‰¦0.
The point x0 = (1, 1)âŠ¤veriï¬es the Karush-Kuhn-Tucker conditions with u1 = 1
2,
but x0 is not a local optimum for the problem.
We now give for (P4) some sufï¬cient ï¬rst-order optimality conditions, based on the
Karush-Kuhn-Tucker conditions.
Theorem 5.10 Let x0 âˆˆK4, let f be pseudoconvex on the open convex set X âŠ‚Rn,
and let every constraint gi, i âˆˆI (x0), be quasiconvex on X. Let x0 verify the Karush-
Kuhn-Tucker conditions (5.2)â€“(5.3)â€“(5.4). Then x0 is a solution of (P4).
Proof Being gi, i âˆˆI (x0), a quasiconvex function on X âŠ‚Rn, we have, for every
i âˆˆI (x0) and for every x âˆˆK4 :
gi(x) â‰¦gi(x0) = 0 â‡’(x âˆ’x0)âŠ¤âˆ‡gi(x0) â‰¦0.
Being the multiplier ui â‰§0, i âˆˆI (x0), it will hold, for every x âˆˆK4 :

iâˆˆI (x0)
ui(x âˆ’x0)âŠ¤âˆ‡gi(x0) â‰¦0.
As ui = 0, âˆ€i /âˆˆI (x0), it holds
(x âˆ’x0)âŠ¤âˆ‡gi(x0) â‰¦0.
m

i=1
ui(x âˆ’x0)âŠ¤âˆ‡gi(x0) â‰¦0, âˆ€x âˆˆK4.
From relation (5.2) of the Karush-Kuhn-Tucker conditions, we obtain
(x âˆ’x0)âŠ¤

âˆ‡f (x0) +
m

i=1
uiâˆ‡gi(x0)

= 0,
i.e.
(x âˆ’x0)âŠ¤âˆ‡f (x0) +
m

i=1
(x âˆ’x0)âŠ¤uiâˆ‡gi(x0) = 0.
Hence, it will hold, as m
i=1 ui(x âˆ’x0)âŠ¤âˆ‡gi(x0) â‰¦0, âˆ€x âˆˆK4,
(x âˆ’x0)âŠ¤âˆ‡f (x0) â‰§0, âˆ€x âˆˆK4.

5.1 First-Order Conditions
133
But, being f pseudoconvex on X, we have
f (x) â‰§f (x0), âˆ€x âˆˆK4.
â–¡
We note that the quasiconvexity of the objective function f, together with the
quasiconvexity of every constraint gi, i âˆˆI (x0), does not imply that the Karush-
Kuhn-Tucker conditions are sufï¬cient for x0 to be a global minimum point for (P4).
Consider, e.g. the problem
â§
â¨
â©
min(1 âˆ’x)3, x âˆˆR
subject to: x âˆ’2 â‰¦0,
âˆ’x â‰¦0.
The objective function is quasiconvex (and quasiconcave), the point x0 = 1 satisï¬es
the Karush-Kuhn-tucker conditions with u1 = 0, u2 = 0, but the minimum occurs
at x = 2.
A more general sufï¬cient optimality condition for (P4), under the assumptions
on x0, the objective function f and every constraint gi, i âˆˆI (x0), contained in
Theorem 5.10, is:
(x âˆ’x0)âŠ¤âˆ‡xL (x0, u) â‰§0, âˆ€x âˆˆK4,
(5.6)
uigi(x0) = 0, i = 1, . . . , m.
Condition (5.6) is called by Mangasarian [12] â€œminimum principleâ€ optimality
condition. The above assertion is quite obvious, on the grounds of the proof of
Theorem 5.10. The same is true if we assume, instead of the pseudoconvexity of
f and the quasiconvexity of gi, i âˆˆI (x0), that the Lagrangian function L (x, u) is
pseudoconvex, with respect to x, on the open convex set X âŠ‚Rn. This condition
is neither stronger nor weaker than the previous ones, as we recall that the sum
of pseudoconvex or quasiconvex functions is not necessarily a pseudoconvex nor a
quasiconvex function.
It is also possible to obtain sufï¬cient optimality conditions for (P4), starting from
the Fritz John conditions, but under rather strong assumptions.
Theorem 5.11 Let x0 âˆˆK4; let f be convex and every gi, i âˆˆI (x0), be strictly
convexontheopenconvexset X âŠ‚Rn.If(x0, u0, u)satisï¬estheFritzJohnconditions
of Theorem 5.5, then x0 is a solution of (P4).
Proof Since we have
u0âˆ‡f (x0) +

iâˆˆI (x0)
uiâˆ‡gi(x0) = 0,
with u0 â‰§0, ui â‰§0, i âˆˆI (x0), not all zero, it follows from Gordanâ€™s theorem of
the alternative that the system

134
5
Constrained Optimization Problems with Inequality Constraints

zâŠ¤âˆ‡f (x0) < 0
zâŠ¤âˆ‡gi(x0) < 0, i âˆˆI (x0),
(5.7)
has no solution z âˆˆRn. Consequently, the system

f (x) âˆ’f (x0) < 0
gi(x) âˆ’gi(x0) â‰¦0, i âˆˆI (x0)
(5.8)
has no solution x âˆˆX, for it did have a solution Ë†x âˆˆX, then Ë†x Ì¸= x, and
0 > f (Ë†x) âˆ’f (x0) â‰§(Ë†x âˆ’x0)âŠ¤âˆ‡f (x0)
by convexity of f , and
0 â‰§gi(Ë†x) âˆ’gi(x0) > (Ë†x âˆ’x0)âŠ¤âˆ‡gi(x0), i âˆˆI (x0),
by strict convexity of every gi, i âˆˆI (x0). This contradicts (5.7) if we set z = Ë†x âˆ’x0.
Recalling that gi(x0) = 0, i âˆˆI (x0), we have from (5.8) that
f (x0) > f (x)
gi(x) â‰¦0, i âˆˆI (x0)
gi(x) â‰¦0, i /âˆˆI (x0)
has no solution x âˆˆX. Since g(x0) â‰¦0, x0 is in K4 and hence x0 solves (P4).
â–¡
A similar result will be given for (P5) in the next chapter, but with weaker assump-
tions (see Theorem 6.10).
It is also possible to get ï¬rst-order sufï¬cient optimality conditions for (P4) in
absence of convexity or generalized convexity assumptions on the functions involved
in the problem. We obtain however only local optimality conditions and under rather
strong assumptions. The following result is due to John [3]; see Stoer and Witzgall
[13].
Theorem 5.12 Let x0 âˆˆK4 verify the Fritz John conditions of Theorem 5.5, with
multipliers u0, ui, i = 1, . . . , m. If
rk
â¡
â¢â£
u0
âˆ‚f
âˆ‚x1 (x0) u1
âˆ‚g1
âˆ‚x1 (x0) Â· Â· Â· um
âˆ‚g1
âˆ‚x1 (x0)
...
...
...
...
u0
âˆ‚f
âˆ‚xn (x0) u1
âˆ‚gm
âˆ‚xn (x0) Â· Â· Â· um
âˆ‚gm
âˆ‚xn (x0)
â¤
â¥â¦= n,
then x0 is a local minimum point for (P4).
We shall give the proof of this result in the next chapter, with reference to
problem (P5).

5.1 First-Order Conditions
135
Another ï¬rst-order sufï¬cient optimality condition for (P4) is obtained by means
of invex functions (Deï¬nition 3.33).
Theorem 5.13 Let x0 âˆˆK4 and let the objective function f and the constraints
gi, i = 1, . . . , m, be invex functions, with respect to a same vector-valued function
Î·(x1, x2), on the open set X âŠ‚Rn. If x0 satisï¬es the Karush-Kuhn-Tucker conditions
(5.2)â€“(5.3)â€“(5.4) of Theorem 5.8, then x0 is a solution of (P4).
Proof For any x âˆˆK4, we have
f (x) âˆ’f (x0) â‰§Î·(x, x0)âŠ¤âˆ‡f (x0) = âˆ’Î·(x, x0)âŠ¤
m

i=1
uiâˆ‡gi(x0),
by the Karush-Kuhn-Tucker conditions. Then we have
âˆ’Î·(x, x0)âŠ¤
m

i=1
uiâˆ‡gi(x0) â‰§âˆ’
 m

i=1
uigi(x) âˆ’
m

i=1
uigi(x0)

,
being ui â‰§0, âˆ€i and being every gi invex with respect to a common function Î·.
The right-hand side of the last expression, thanks to the complementary slackness
conditions, is given by
âˆ’
m

i=1
uigi(x) â‰§0,
being ui â‰§0, âˆ€i and gi(x) â‰¦0, âˆ€x âˆˆK4. So, we have, for every x âˆˆK4,
f (x) â‰§f (x0),
i.e. x0 is a solution of (P4).
â–¡
It is interesting to know when a ï¬nite collection of functions is made of invex func-
tions, with respect to a common vector-valued function Î·. The answer is contained
in a result of MartÃ­nez-Legaz [14], we report for the readerâ€™s convenience.
Theorem 5.14 Let f1, .., f p be differentiable functions deï¬ned on an open subset
X of Rn. The following statements are equivalent:
(i) The functions f1, .., f p are invex with respect to the same Î·.
(ii) The functions p
i=1 Î»i fi, Î»1 â‰§0, . . . , Î»p â‰§0, are invex with respect to the
same Î·.
(iii) The functions p
i=1 Î»i fi, Î»1 â‰§0, . . . , Î»p â‰§0, are invex.
(iv) For every Î»1 â‰§0, . . . , Î»p â‰§0, every stationary point of p
i=1 Î»i fi is a global
minimum point.

136
5
Constrained Optimization Problems with Inequality Constraints
Proof We ï¬rst recall a theorem of the alternative due to Gale (Gale [30]; see also
Chap. 2, p. 43): For a given matrix A of order (m, n) and a given vector b âˆˆRm,
either the system
Ax â‰¦b
has a solution x âˆˆRn, or the system
AâŠ¤Î» = 0, bâŠ¤Î» = âˆ’1
has a solution Î» â‰§0, but never both. In other words, if a system of the type Ax â‰¦b
has no solution x âˆˆRn, then there exists Î» âˆˆRm
+ such that
m

i=1
Î»i Ai = 0 and
m

i=1
Î»ibi = âˆ’1,
where Ai is the ith row of A.
Now we prove the theorem. Implications (i) â‡’(ii) â‡’(iii) â‡’(iv) are obvious,
so we have to prove only the implication (iv) â‡’(i). Assume, by contradiction, that
there is no vector-valued function Î· : X Ã— X â†’Rn such that
fi(y) â‰§fi(x) + Î·(x, y)âŠ¤âˆ‡fi(x), x, y âˆˆX, i = 1, . . . , p.
In other words, there exist x, y âˆˆX such that the system
Î·(x, y)âŠ¤âˆ‡fi(x) â‰¦fi(y) âˆ’fi(x), i = 1, . . . , p,
in the unknown vector Î·(x, y) has no solution. Hence, by the theorem of the alter-
native of Gale above recalled, there is Î» âˆˆRp
+ such that p
i=1 Î»iâˆ‡fi(x) = 0 and
p
i=1 Î»i( fi(y) âˆ’fi(x)) = âˆ’1.Therefore,p
i=1 Î»i fi(x)hasastationarypointwhich
is not a global minimum, since
p

i=1
Î»i fi(y) =
p

i=1
Î»i fi(x) âˆ’1 <
p

i=1
Î»i fi(x).
This contradicts (iv).
â–¡
Therefore, not always invex functions are a useful tool in obtaining sufï¬cient
optimality conditions for (P4), as f and each gi can be individually invex, but only
with respect to different Î·. Ben-Israel and Mond [15] consider the following example.
Example 5.15 Consider the problem

min 1
2(x âˆ’1)2, x âˆˆR,
subject to: x3 + x â‰¦0.

5.2 Constraint Qualiï¬cations
137
If we take x = 0, u1 = 0, the Karush-Kuhn-Tucker conditions are satisï¬ed. Here
f is convex (and therefore invex) and g is pseudoconvex (and therefore invex), but
for u1 = 1 the Lagrangian function L = f + u1g = x3 + 1
2 x2 + 1
2 is not invex, i.e.
f and g are invex with respect to different Î·, so the sufï¬ciency result of Theorem
5.13 is not applicable, although, of course, x = 0 is a global minimum point, by
Theorem 5.10.
5.2
Constraint Qualiï¬cations
In the previous section, we obtained the Karush-Kuhn-Tucker conditions under the
constraint qualiï¬cation (5.1). In other words, this condition assures that in Theorem
5.5 of Fritz John it holds u0 = 1. We wish to stress that the question of constraint
qualiï¬cations (for (P4) or for the more general problem (P5) or also for other more
general mathematical programming problems) is not always related to the geometric
structureofthefeasiblesetaroundtheoptimalpoint x0,suchasthepresenceofacusp,
as suggested, e.g. by Mangasarian [12]. Constraint qualiï¬cations are indeed related
to the functional form of the constraints. If we reconsider the problem of Example
5.6, we see that the feasible set present a cusp at the optimal point x0 = (0, 0)âŠ¤.
We have seen that the Fritz John conditions for the said problem are veriï¬ed at x0
only by u0 = 0. As a matter of fact, at x0 = (0, 0)âŠ¤no constraint qualiï¬cation is
satisï¬ed by the constraints of the problem. However, the presence of a cusp is neither
necessary nor sufï¬cient to cause the Karush-Kuhn-Tucker conditions to fail at an
optimal solution. Let us add to the problem of Example 5.6 a new constraint:
x2 âˆ’x1 â‰¦0.
Clearly, the feasible set remains the same (the new constraint is therefore redun-
dant), but now the problem is qualiï¬ed, i.e. the Fritz John conditions are satisï¬ed at
x0 = (0, 0)âŠ¤with u0 > 0; hence the Karush-Kuhn-Tucker conditions hold at x0.
We now give an overview of the main (but not all!) constraint qualiï¬cations
proposed in the literature, with reference to (P4). Let x0 âˆˆK4.
1. Guignard-Gould-Tolle constraint qualiï¬cation. It is just condition (5.1):
(L(x0))âˆ—= (T (K4, x0))âˆ—,
which can be equivalently expressed as
L(x0) = P(K4, x0) â‰¡cl(conv(T (K4, x0))),
or also as
L(x0) = (T (K4, x0))âˆ—âˆ—.

138
5
Constrained Optimization Problems with Inequality Constraints
See Guignard [9], Gould and Tolle [10, 11]. Gould and Tolle [10] proved that
this condition is necessary and sufï¬cient for the Karush-Kuhn-Tucker conditions to
be veriï¬ed by any (differentiable) objective function of which x0 is a local optimal
solution on K4. In this sense the Guignard-Gould-Tolle constraint qualiï¬cation is the
weakest possible among constraint qualiï¬cations. See also the next chapter.
2. Abadie constraint qualiï¬cation. It is expressed as
L(x0) = T (K4, x0).
Therefore, the Abadie constraint qualiï¬cation requires that T (K4, x0) be a convex
cone. Obviously, the Abadie constraint qualiï¬cation implies the Guignard-Gould-
Tolle constraint qualiï¬cation. A point x0 âˆˆK4 satisfying the Abadie constraint qual-
iï¬cation is called by Hestenes [16] a â€œregular pointâ€, whereas x0 âˆˆK4 satisfying
the Guignard-Gould-Tolle constraint qualiï¬cation is called, by the same author, a
â€œquasiregular pointâ€.
3. Kuhn-Tucker constraint qualiï¬cation or, better, Karush-Kuhn-Tucker constraint
qualiï¬cation. It is expressed as
L(x0) = A(K4, x0).
Obviously, from the deï¬nitions of the related cones, the Karush-Kuhn-Tucker con-
straint qualiï¬cation implies the Abadie constraint qualiï¬cation.
4. Zangwill constraint qualiï¬cation (see Zangwill [17]). It is expressed as
L(x0) = cl(F(K4, x0)).
For what previously seen, we have that the Zangwill constraint qualiï¬cation
implies the Karush-Kuhn-Tucker constraint qualiï¬cation.
We note that all the above implications are strict.
5. Cottle constraint qualiï¬cation or Arrow-Hurwicz-Uzawa constraint qualiï¬ca-
tion. It is expressed as
Lo(x0) Ì¸= âˆ…
or, equivalently, as
L(x0) = cl(Lo(x0)).
This qualiï¬cation is considered, as a particular case of a more general constraint
qualiï¬cation, by Arrow et al. [1], who are, therefore, the ï¬rst authors to have intro-
duced this constraint qualiï¬cation. In its original form the Cottle constraint qualiï¬-
cation requires that the system

iâˆˆI (x0)
uiâˆ‡gi(x0) = 0, ui â‰§0, i âˆˆI (x0),

5.2 Constraint Qualiï¬cations
139
has the zero sulution only, i.e. the vectors âˆ‡gi(x0), i âˆˆI (x0), have to be positively
linearly independent. Indeed, by applying Gordanâ€™s theorem of the alternative (see
p. 44), we see that the two formulations are equivalent.
We have seen, in Theorem 5.3 and in Corollary 5.4, that the Cottle constraint
qualiï¬cation implies the Zangwill constraint qualiï¬cation.
The Cottle constraint qualiï¬cation has been â€œreï¬nedâ€ by Abadie [7] and by Arrow
etal.[1].Inordertodescribetheseconstraintqualiï¬cations,weintroducetwovariants
of the linearized cone L(x0), considered, respectively by Abadie and by Arrow,
Hurwicz and Uzawa.
L1(x0) =
 y âˆˆRn : âˆ‡gi(x0)âŠ¤y < 0, if gi is not linear, i âˆˆI (x0);
âˆ‡gi(x0)âŠ¤y â‰¦0, if gi is linear, i âˆˆI (x0)

.
L2(x0) =
 y âˆˆRn : âˆ‡gi(x0)âŠ¤y < 0, if gi is not pseudoconcave, i âˆˆI (x0);
âˆ‡gi(x0)âŠ¤y â‰¦0, if gi is pseudoconcave, i âˆˆI (x0)

.
6. Abadie constraint qualiï¬cation II. It is expressed as
L1(x0) Ì¸= âˆ…
or, equivalently, as
L(x0) = cl(L1(x0)).
7. Arrow-Hurwicz-Uzawa constraint qualiï¬cation II. It is expressed as
L2(x0) Ì¸= âˆ…
or, equivalently, as
L(x0) = cl(L2(x0)).
We have to note at once that if all functions gi, i âˆˆI (x0), are pseuconcave or even
concave, then the Arrow-Hurwicz-Uzawa constraint qualiï¬cation II is automatically
satisï¬ed.Arrowetal.[1]callthiscaseReverseconstraintqualiï¬cation.Ifallfunctions
gi, i âˆˆI (x0), are linear (or even linear afï¬ne), the Abadie constraint qualiï¬cation II
and the Arrow-Hurwicz-Uzawa constraint qualiï¬cation II are automatically satisï¬ed.
Hence, for a Linear Programming Problem (see Chap. 9) no constraint qualiï¬cation
is required.
Theorem 5.16 Let be x0 âˆˆK4. Then
Lo(x0) âŠ‚L1(x0) âŠ‚L2(x0) âŠ‚F(K4, x0) âŠ‚A(K4, x0) âŠ‚T (K4, x0) âŠ‚L(x0).
Proof We prove only the inclusions not previously already proved. It is easy to
see that Lo(x0) âŠ‚L1(x0) âŠ‚L2(x0). We now prove that L2(x0) âŠ‚F(K4, x0). Let
y âˆˆL2(x0); we claim that gi(x0 + Î´y) â‰¦0 with Î´ > 0 being sufï¬ciently small for

140
5
Constrained Optimization Problems with Inequality Constraints
all i âˆˆI (x0) such that gi is pseudoconcave. Otherwise gi(x0 + Î´y) > 0 = gi(x0)
and then Î´âˆ‡gi(x0)âŠ¤y > 0 by the pseudoconcavity, which is a contradiction. For
i âˆˆI (x0), gi is not pseudoconcave, the considerations are similar. In any case y âˆˆ
F(K4, x0) and hence L2(x0) âŠ‚F(K4, x0).
â–¡
Hence, we have the following implications:
Cottle c. q. â‡’Abadie c. q. II â‡’Arrow-Hurwicz-Uzawa c. q. II
â‡’Zangwill c. q. â‡’Karush-Kuhn-Tucker c. q. â‡’Abadie c. q.
â‡’Guignard-Gould-Tolle c. q.
8. Slater constraint qualiï¬cation. It is expressed as: every constraint gi, i âˆˆI (x0),
is pseudoconvex and there exists Â¯x âˆˆK4 such that gi(Â¯x) < 0, âˆ€i âˆˆI (x0).
Theorem 5.17 TheSlaterconstraintqualiï¬cationimpliestheCottleconstraintqual-
iï¬cation.
Proof Suppose that the Slater constraint qualiï¬cation is satisï¬ed. For i âˆˆI (x0), we
have gi(Â¯x) < gi(x0) = 0. Therefore, âˆ‡gi(x0)âŠ¤(Â¯x âˆ’x0) < 0 because gi is pseudo-
convex. Let be y = Â¯x âˆ’x0, then y âˆˆLo(x0). This means Lo(x0) Ì¸= âˆ…and hence the
Cottle constraint qualiï¬cation holds.
â–¡
TheoriginalSlaterconstraintqualiï¬cationwasgivenunderconvexityassumptions
ontheconstraints gi,i âˆˆI (x0).Notethat,underthisassumption,theSlaterconstraint
qualiï¬cation and the Cottle constraint qualiï¬cation are equivalent assertions. The
â€œrelaxedâ€ Slater constraint qualiï¬cation here presented, is due to Mangasarian [12].
9. Linear independence constraint qualiï¬cation. It is expressed as: the gradients
âˆ‡gi(x0), i âˆˆI (x0),
are linearly independent.
It is immediate to see that
Linear independence c. q. â‡’Cottle c. q.
Indeed, if the gradients of the active constraints at x0 are linearly independent,
they are also positively linearly independent, i.e. the Cottle constraint qualiï¬cation
holds. Note, moreover, that the Linear independence constraint qualiï¬cation assures
the uniqueness of the Karush-Kuhn-Tucker multipliers ui, i = 1, . . . , m, in relations
(5.2)â€“(5.3)â€“(5.4) of Theorem 5.8. We shall show in the next chapter, with reference to
problem (P5), a necessary and sufï¬cient condition for the uniqueness of the Karush-
Kuhn-Tucker multipliers.
Here, we have considered constraint qualiï¬cations for differentiable functions,
some of these qualiï¬cations have been extended for directionally differentiable func-
tions in Giorgi et al. [18].

5.3 Second-Order Conditions
141
5.3
Second-Order Conditions
We have already considered both second-order necessary and second-order sufï¬cient
optimality conditions in unconstrained optimization problems and in â€œclassicalâ€ con-
strained optimization problems. In absence of convexity or some kind of generalized
convexity of the functions involved in an optimization problem, the second-order
sufï¬cient conditions are an important tool to determinate whether a â€œcandidateâ€ to
be a (local) optimal point is indeed a local solution of the problem. In this section we
give the basic second-order necessary optimality conditions and the basic second-
order sufï¬cient optimality conditions for (P4). We shall reconsider these questions,
with further insights, in the next chapter, with reference to problem (P5).
Wemaketheassumptionsthatallfunctionsinvolvedin(P4)aretwice-continuously
differentiable on the open set X âŠ‚Rn.
Let be x0 âˆˆK4 and let the pair (x0, u) verify the Karush-Kuhn-Tucker conditions
âˆ‡f (x0) +
m

i=1
uiâˆ‡gi(x0) = 0,
uigi(x0) = 0, i = 1, . . . , m,
ui â‰§0, i = 1, . . . , m.
We deï¬ne the set of strictly active constraints at x0 âˆˆK4 :
I +(x0, u) =

i âˆˆI (x0) : ui > 0 in the KKT conditions

âŠ‚I (x0).
We introduce the set
G =

x âˆˆK4 : gi(x) = 0, âˆ€i âˆˆI +(x0, u)

.
Now we introduce two â€œregularity conditionsâ€ :
(R1) : The Bouligand tangent cone T (G, x0) is equal to the following â€œmodiï¬edâ€
linearizing cone or critical cone or cone of critical directions
Z(x0) =
 y âˆˆRn : âˆ‡gi(x0)âŠ¤y â‰¦0, âˆ€i âˆˆI (x0) \ I +(x0, u);
âˆ‡gi(x0)âŠ¤y = 0, âˆ€i âˆˆI +(x0, u)

i.e.
T (G, x0) = Z(x0).
(R2) : The vectors âˆ‡gi(x0), i âˆˆI +(x0, u), are linearly independent and there
exists y âˆˆRn such that

142
5
Constrained Optimization Problems with Inequality Constraints
âˆ‡gi(x0)âŠ¤y < 0, âˆ€i âˆˆI (x0) \ I +(x0, u);
âˆ‡gi(x0)âŠ¤y = 0, âˆ€i âˆˆI +(x0, u).
Note that this last condition is a restricted version of the Cottle constraint qualiï¬-
cation. With reference to (P5), this condition has been introduced by Kyparisis [19].
It is not difï¬cult to prove that x0 âˆˆK4 satisï¬es (R2) if and only if the system

iâˆˆI (x0)
uiâˆ‡gi(x0) = 0, ui â‰§0, âˆ€i âˆˆI (x0) \ I +(x0, u)
admits the zero solution only. In other words, the vectors âˆ‡gi(x0), i âˆˆI (x0) \
I +(x0, u), are positively linearly independent. We shall give the proof in the next
chapter, for problem (P5).
We can easily prove the following result on necessary second-order optimality
conditions for (P4).
Theorem 5.18 Let x0 âˆˆK4 be a local solution of problem (P4) and let the pair
(x0, u) verify the Karush-Kuhn-Tucker conditions. Then it holds
yâŠ¤âˆ‡2
xL (x0, u)y â‰§0, âˆ€y âˆˆT (G, x0).
If, moreover, condition (R1) holds, then we have
yâŠ¤âˆ‡2
xL (x0, u)y â‰§0, âˆ€y âˆˆZ(x0).
(5.9)
Proof Given the Lagrangian function L (x, u) = f (x) + uâŠ¤g(x), we have obvi-
ously, thanks to the complementary slackness conditions,
L (x, u) = f (x), âˆ€x âˆˆG.
As x0 âˆˆK4 is a local solution of (P4), this point is also a local solution of
min f (x) = L (x, u), x âˆˆG.
But the conditions of Karush-Kuhn-Tucker at x0 give âˆ‡xL (x0, u) = 0. Applying
Theorem 4.26, we have
yâŠ¤âˆ‡2
xL (x0, u)y â‰§0, âˆ€y âˆˆT (G, x0).
If T (G, x0) = Z(x0), i.e. (R1) holds, then obviously, we have relation (5.9).
â–¡
Now we prove that (R2) is sufï¬cient for the validity of (R1). We follow closely
Elster and others [20].

5.3 Second-Order Conditions
143
Theorem 5.19 Let be x0 âˆˆK4. Then
(R2) â‡’(R1).
Proof Let be I +(x0, u) Ì¸= âˆ…. Being the vectors âˆ‡gi(x0), i âˆˆI +(x0, u), linearly
independent, there exists a matrix A, of order (n, card(I +)), such that
det(âˆ‡gI +(x0)âŠ¤A) Ì¸= 0.
(5.10)
(For brevity we denote I +(x0, u) by I +).
Now let us consider a vector y âˆˆRn, y Ì¸= 0, which veriï¬es (R2), as well as the
system, in zI + and t :
gi(x0 + AzI + + ty) = 0, i âˆˆI +.
(5.11)
The system (5.11) admits the solution (zI +, t0)âŠ¤= (0, . . . , 0, 0)âŠ¤. By (5.10), there
exist, owing to the Implicit Function Theorem, in a neighborhood U0 of t0 = 0, the
functions zi(t), i âˆˆI +, with
zi(0) = 0, i âˆˆI +
gi(x0 + AzI +(t) + ty) = 0, i âˆˆI +, t âˆˆU0.
(5.12)
By differentiating (5.12) with respect to t at t = 0, we get
âˆ‡gi(x0)âŠ¤(AË™zI +(0) + y) = 0, i âˆˆI +.
From âˆ‡gi(x0)âŠ¤y = 0, âˆ€i âˆˆI +, it follows
âˆ‡gi(x0)âŠ¤AË™zI +(0) = 0, i âˆˆI +.
By (5.10) we obtain Ë™zI +(0) = 0 and therefore
lim
tâ†’0
zI +(t)
t
= 0.
(5.13)
Now we prove that there exists t1 such that t1 > 0, so that the curve
x(t) = x0 + AzI +(t) + ty, t âˆˆ[0, t1]
lies entirely in G. To this purpose, let us develop the functions gi, i âˆˆI (x0) \ I +, at
x0, with respect to AzI +(t) + ty, keeping in mind that gi(x0) = 0. It follows
gi(x0 + AzI +(t) + ty) = âˆ‡gi(x0)âŠ¤(AzI +(t) + ty) + o(âˆ¥AzI +(t) + tyâˆ¥)
= tâˆ‡gi(x0)âŠ¤y + o(âˆ¥AzI +(t) + tyâˆ¥) + âˆ‡gi(x0)âŠ¤AzI +(t).

144
5
Constrained Optimization Problems with Inequality Constraints
From (5.13) we obtain
âˆ‡gi(x0)âŠ¤AzI +(t) = o(t)
and
gi(x0 + AzI +(t) + ty) = tâˆ‡gi(x0)âŠ¤y + o(t).
As y satisï¬es condition (R2), we have âˆ‡gi(x0)âŠ¤y < 0, âˆ€i âˆˆI (x0) \ I +. There
exists therefore t0 > 0 such that, for t âˆˆ(0, t0), we have
gi(x0 + AzI +(t) + ty) < 0, âˆ€i âˆˆI (x0) \ I +.
Taking into account also relation (5.12), it follows the existence of t1 > 0 such that
the curve x(t), t âˆˆ[0, t1] , lies entirely in G. It is then possible to build a sequence

xk
, xk âˆˆG, with xk = x0 + AzI +  1
k

+ 1
k y, with the property xk yâˆ¥yâˆ¥âˆ’1
â†’
x0. We
have xk âˆˆG and for k > 1
t1 , taking relation (5.13) into account,
lim
kâ†’âˆ
xk âˆ’x0
		xk âˆ’x0		 = lim
kâ†’âˆ
AzI +( 1
k ) + 1
k y
		AzI +( 1
k ) + 1
k y
		 = lim
kâ†’âˆ
AzI +( 1
k )k + y
		AzI +( 1
k )k + y
		 =
y
âˆ¥yâˆ¥,
i.e. for I + Ì¸= âˆ…, we have the conclusion of the theorem. For I + = âˆ…, condition (R2)
is the Cottle constraint qualiï¬cation, and also in this case, the theorem holds.
â–¡
We point out that if the gradients âˆ‡gi(x0), i âˆˆI (x0), are linearly independent,
thensurely(R2)issatisï¬ed.Weobtaintherefore,asacorollary,thefollowingclassical
result on second-order necessary optimality conditions for (P4).
Corollary 5.20 Let x0 âˆˆK4 be a local solution of (P4) and let the gradients
âˆ‡gi(x0), i âˆˆI (x0), be linearly independent. Then, there exists a unique vector of
Karush-Kuhn-Tucker multipliers (u1, . . . , um) such that the Karush-Kuhn-Tucker
conditions are veriï¬ed at x0. Moreover, it holds
yâŠ¤âˆ‡2
xL (x0, u)y â‰§0, âˆ€y âˆˆZ(x0).
We note that, in absence of constraints, i.e. with reference to unconstrained opti-
mization problems, we have then the following classical result: if x0 is a local mini-
mum point, then âˆ‡2 f (x0) is positive semideï¬nite.
Theorem 5.18 and Corollary 5.20 do not give a sufï¬cient optimality condition.
Example 5.21 Consider the problem

min((x1)3 + x2)
subject to: âˆ’x2 â‰¦0,
(x1, x2) âˆˆR2. The point x0 = (0, 0)âŠ¤is the unique solution of the Karush-Kuhn-
Tucker conditions, with multiplier u = 1. The linear constraint is active at x0 and

5.3 Second-Order Conditions
145
âˆ‡g(x0) = (0, âˆ’1)âŠ¤. The Hessian matrix of the Lagrangian function at x0 is the zero
matrix, but x0 is not a local optimum because f (t, 0) < f (0, 0) for all t < 0.
Theorem 5.22 Let x0 âˆˆK4 and let the Karush-Kuhn-Tucker conditions be satisï¬ed
by the pair (x0, u). If
yâŠ¤âˆ‡2
xL (x0, u)y > 0,
âˆ€y Ì¸= 0,
(5.14)
y âˆˆT (K4, x0) âˆ©

y : âˆ‡gi(x0)âŠ¤y = 0, âˆ€y âˆˆI +(x0, u)

,
then x0 is a strict local minimum point for (P4).
Proof We perform the proof in an indirect way. We suppose that f has no strict local
minimizer at x0 âˆˆK4. Then, there exists a sequence

xk
âŠ‚K4, with xk
yâ†’x0 and
f (xk) âˆ’f (x0) â‰¦0, with k âˆˆN. It follows
lim
kâ†’âˆ
f (xk) âˆ’f (x0)
		xk âˆ’x0		
= âˆ‡f (x0)âŠ¤y â‰¦0
and, being gi(xk) â‰¦0, gi(x0) = 0, âˆ€i âˆˆI (x0) :
lim
kâ†’âˆ
gi(xk) âˆ’gi(x0)
		xk âˆ’x0		
= âˆ‡gi(x0)âŠ¤y â‰¦0, âˆ€i âˆˆI (x0).
Therefore, we obtain
L (xk, u) âˆ’L (x0, u) = f (xk) âˆ’f (x0) +

iâˆˆI (x0)
ui

gi(xk) âˆ’gi(x0)

â‰¦0.
From âˆ‡xL (x0, u) = 0, it follows
lim
kâ†’âˆ
L (xk, u) âˆ’L (x0, u)
		xk âˆ’x0		2
= 1
2 yâˆ‡2
xL (x0, u)y â‰¦0.
By assumption y âˆˆT (K4, x0). For I +(x0, u) = âˆ…, we have therefore a contradiction
with relation (5.14). If I +(x0, u) Ì¸= âˆ…, let us suppose that for an index iâˆ—âˆˆI +(x0, u)
it holds âˆ‡giâˆ—(x0)âŠ¤y < 0. Multiplying âˆ‡xL (x0, u) by y and taking into account that
âˆ‡f (x0)âŠ¤y â‰¦0 and ui > 0, âˆ€i âˆˆI +(x0, u), we have
0 = âˆ‡xL (x0, u)âŠ¤y = âˆ‡f (x0)âŠ¤y +

iâˆˆI +(x0,u)
uiâˆ‡gi(x0)âŠ¤y < 0,
and hence a contradiction. Therefore, we have âˆ‡gi(x0)âŠ¤y = 0, âˆ€i âˆˆI +(x0, u), and
we get the thesis of the Theorem.
â–¡

146
5
Constrained Optimization Problems with Inequality Constraints
As it holds always T (K4, x0) âŠ‚L(x0), we can write the thesis of the previous
theorem in a stronger form, which is the usual form of the second-order optimality
conditions for (P4) :
yâŠ¤âˆ‡2
xL (x0, u)y > 0, âˆ€y Ì¸= 0, y âˆˆZ(x0),
where Z(x0) is the critical cone previously introduced
Z(x0) =
 y âˆˆRn : âˆ‡gi(x0)âŠ¤y â‰¦0, âˆ€i âˆˆI (x0) \ I +(x0, u),
âˆ‡gi(x0)y = 0, âˆ€i âˆˆI +(x0, u)

.
This last formulation is essentially due to McCormick [21]. We may remark that
if I (x0) = I +(x0, u), i.e. the strict complementary slackness conditions hold at x0,
we have
yâŠ¤âˆ‡2
xL (x0, u)y > 0, âˆ€y Ì¸= 0, y âˆˆZ1(x0),
with
Z1(x0) =

y âˆˆRn : âˆ‡gi(x0)âŠ¤y = 0, âˆ€i âˆˆI (x0)

.
It is therefore possible to use, in this case, the criteria which assure that the
quadratic form
yâŠ¤âˆ‡2
xL (x0, u)y
is positive deï¬nite on the set of nonzero solutions of the system described by Z1(x0).
See Chap. 1 and see, e.g. Chabrillac and Crouzeix [2] and Debreu [22].
Example 5.23 Consider the problem
â§
âªâªâ¨
âªâªâ©
min

k(x1)2 âˆ’x2

subject to: âˆ’(x1)2 âˆ’(x2 âˆ’1)2 + 1 â‰¦0,
(x1 + 1)2 + (x2)2 âˆ’1 â‰¦0,
âˆ’x1 âˆ’1 â‰¦0,
where k âˆˆR is a parameter.
The point x0 = (0, 0)âŠ¤satisï¬es the Karush-Kuhn-Tucker conditions, with mul-
tipliers ( 1
2, 0, 0). Indeed, at this point the problem is qualiï¬ed (why?). But only for
k > 1
2 and y1 > 0 the sufï¬cient optimality conditions of Theorem 5.22 are satisï¬ed.
Then, for k > 1
2 the objective function has at (0, 0)âŠ¤a strict local minimum over the
feasible set. For k = 1
2 it holds yâŠ¤âˆ‡2
xL (x0, u)y = 0 and therefore, on the grounds
of Theorem 5.22, we cannot draw any conclusion.

5.4 Other Formulations of the Problem. Some Examples
147
5.4
Other Formulations of the Problem. Some Examples
On the grounds of what previously said, it is not difï¬cult to obtain the Karush-Kuhn-
Tucker conditions (or the Fritz John conditions) for other formulations of (P4). Let
us consider, for example, the following problem:
â§
â¨
â©
min f (x)
subject to: gi(x) â‰¦0, i = 1, . . . , m,
x â‰§0,
in which there are, besides the functional constraints, non-negativity constraints on
the variables, i.e. x1 â‰§0, . . . , xn â‰§0, that is, in vector notation, x â‰§0. This formu-
lation appears in all mathematical programming problems arising from economic
and ï¬nancial environments. Let us rewrite the above problem in the form

min f (x)
subject to: r(x) â‰¦0,
where
r(x) =
 g(x)
âˆ’x
!
, r : Rn â†’Rm+n.
Let us suppose that the functional constraints gi, i = 1, . . . , m, are qualiï¬ed at
the solution point of the problem. The constraints âˆ’xi, i = 1, . . . , m, are surely
qualiï¬ed, since they are linear functions. On the other hand, the Jacobian matrix of
âˆ’x is âˆ’I, a nonsingular matrix. The Karush-Kuhn-Tucker conditions at the solution
point x0 for the last problem are therefore
(i) âˆ‡f (x0) +
m+n

i=1
uiâˆ‡ri(x0) = 0;
(ii) uiri(x0) = 0, i = 1, . . . , m + n;
(iii) ui â‰§0, i = 1, . . . , m + n.
These conditions may be rewritten in the form
âˆ‡f (x0) +
m

i=1
ui,1 âˆ‡gi(x0) +
n

i=1
ui,2(âˆ’ei) = 0;
uiri(x0) = 0, i = 1, . . . , m + n â‡”{ui,1gi(x0) = 0, i = 1, . . . , m;
ui,2(âˆ’x0
i ) = 0, i = 1, . . . , n};

148
5
Constrained Optimization Problems with Inequality Constraints
ui,1 â‰§0, i = 1, . . . , m; ui,2 â‰§0, i = 1, . . . , n.
In other words, we have
âˆ‡f (x0) +
m

i=1
ui,1âˆ‡gi(x0) =
n

i=1
ui,2ei â‰§0;

âˆ‡f (x0) +
m

i=1
ui,1âˆ‡gi(x0)
âŠ¤
x0 = 0;
ui,1gi(x0) = 0, i = 1, . . . , m;
ui,1 â‰§0, i = 1, . . . , m.
We rewrite these last relations in a more usual way:
âˆ‡f (x0) +
m

i=1
uiâˆ‡gi(x0) â‰§0;

âˆ‡f (x0) +
m

i=1
uiâˆ‡gi(x0)
âŠ¤
x0 = 0;
uigi(x0) = 0, i = 1, . . . , m;
ui â‰§0, i = 1, . . . , m.
These are the Karush-Kuhn-Tucker conditions for the problem considered.
For example, if we consider the problem

min f (x)
subject to: x â‰§0,
and x0 â‰§0 is a local solution of this problem, the related Karush-Kuhn-Tucker
conditions are
âˆ‡f (x0) â‰§0; âˆ‡f (x0)âŠ¤x0 = 0.
We have seen in Chap. 4 that if f is differentiable and x0 âˆˆS is a local minimum
point of f over the closed convex set S âŠ‚Rn, then
âˆ‡f (x0)âŠ¤(x âˆ’x0) â‰§0, âˆ€x âˆˆS.

5.4 Other Formulations of the Problem. Some Examples
149
Being the nonnegative orthant of Rn, Rn
+, surely a closed convex set, the previous
relation becomes
âˆ‡f (x0)âŠ¤(x âˆ’x0) â‰§0, âˆ€x â‰§0,
i.e.
(âˆ‡f (x0)âŠ¤x âˆ’âˆ‡f (x0)âŠ¤x0) â‰§0, âˆ€x â‰§0.
(5.15)
We will now use the following technical result:
aâŠ¤x + b â‰§0 for all x â‰§0 if and only if a â‰§0 and b â‰§0 (a, b âˆˆRn).
Using this simple result it follows that (5.15) holds if and only if
âˆ‡f (x0) â‰§0 and âˆ‡f (x0)âŠ¤x0 â‰¦0.
(5.16)
Since âˆ‡f (x0) â‰§0 and x0 â‰§0, we can conclude that (5.16) holds if and only if
âˆ‡f (x0) â‰§0; âˆ‡f (x0)âŠ¤x0 = 0,
i.e. if and only if the Karush-Kuhn-Tucker conditions hold for the above problem.
Now we consider a maximization problem of the type
â§
â¨
â©
max f (x)
gi(x) â‰¦0, i = 1, . . . , m,
x â‰§0.
We recall that max f (x) â‡”min {âˆ’f (x)} . If x0 is a local solution of the said
maximization problem and the constraints gi, i = 1, . . . , m, are qualiï¬ed, we have
therefore that the following Karush-Kuhn-Tucker conditions hold:
âˆ’âˆ‡f (x0) +
m

i=1
uiâˆ‡gi(x0) â‰§0;

âˆ’âˆ‡f (x0) +
m

i=1
uiâˆ‡gi(x0)
âŠ¤
x0 = 0;
uigi(x0) = 0, i = 1, . . . , m;
ui â‰§0, i = 1, . . . , m,
i.e.
âˆ‡f (x0) âˆ’
m

i=1
uiâˆ‡gi(x0) â‰¦0;

150
5
Constrained Optimization Problems with Inequality Constraints

âˆ‡f (x0) âˆ’
m

i=1
uiâˆ‡gi(x0)
âŠ¤
x0 = 0;
uigi(x0) = 0, i = 1, . . . , m;
ui â‰§0, i = 1, . . . , m.
For example, the problem
max f (x)
x â‰§0,
presents at the local optimal solution x0, the following Karush-Kuhn-Tucker condi-
tions:
âˆ‡f (x0) â‰¦0; âˆ‡f (x0)âŠ¤x0 = 0.
For the readerâ€™s convenience we write in Table 5.1 the Karush-Kuhn-Tucker con-
ditions related to various reformulations of problem (P4).
If we have a Linear Programming Problem (see Chap. 9) of the type
â§
â¨
â©
min câŠ¤x
Ax â‰§b
x â‰§0,
where c âˆˆRn, c Ì¸= 0, b âˆˆRm, and A is a matrix of order (m, n), then x0 âˆˆRn is a
solution of the problem if and only if there exists a multipliers vector u âˆˆRm such
that
(Ax0 âˆ’b)âŠ¤u = 0;
Ax0 â‰§b;
u â‰§0;
x0 â‰§0; AâŠ¤u â‰¦c; (AâŠ¤u âˆ’c)âŠ¤x0 = 0.
We now consider some â€œlinearization propertiesâ€ related to a nonlinear program-
ming problem of the type (P4). We continue to assume that the functions involved
in (P4) are differentiable on the open set X âŠ‚Rn.
Theorem 5.24 (a) Let x0 âˆˆK4 be a solution of (P4) and let the constraints of (P4)
be qualiï¬ed at x0. Then x0 is also a solution of the linearized problem
(P4)L :

min

xâŠ¤âˆ‡f (x0)

subject to: (x âˆ’x0)âŠ¤âˆ‡gi(x0) â‰¦0, i âˆˆI (x0).
(b) Let f be pseudoconvex on the open convex set X âŠ‚Rn and let every gi,
i âˆˆI (x0), be quasiconvex on X. If x0 is a solution of (P4)L, then x0 is also solution
of (P4).

5.4 Other Formulations of the Problem. Some Examples
151
Table 5.1 Karush-Kuhn-Tucker conditions for several reformulations of problem (P4)
Problem
K.K.T. conditions
(a)
"
min f (x)
gi(x) â‰¦0, i = 1, . . . , m.
âˆ‡f (x0) + m
i=1 uiâˆ‡gi(x0) = 0,
ui gi(x0) = 0, i = 1, . . . , m,
ui â‰§0, i = 1, . . . , m.
(b)
"
min f (x)
gi(x) â‰§0, i = 1, . . . , m.
âˆ‡f (x0) âˆ’m
i=1 uiâˆ‡gi(x0) = 0,
ui gi(x0) = 0, i = 1, . . . , m,
ui â‰§0, i = 1, . . . , m.
(c)
"
max f (x)
gi(x) â‰¦0, i = 1, . . . , m.
âˆ‡f (x0) âˆ’m
i=1 uiâˆ‡gi(x0) = 0,
ui gi(x0) = 0, i = 1, . . . , m,
ui â‰§0, i = 1, . . . , m.
(d)
"
max f (x)
gi(x) â‰§0, i = 1, . . . , m.
âˆ‡f (x0) + m
i=1 uiâˆ‡gi(x0) = 0,
ui gi(x0) = 0, i = 1, . . . , m,
ui â‰§0, i = 1, . . . , m.
(a1)
â§
âªâ¨
âªâ©
min f (x)
gi(x) â‰¦0, i = 1, . . . , m,
x â‰§0.
âˆ‡f (x0) + m
i=1 uiâˆ‡gi(x0) â‰§0;

âˆ‡f (x0) + m
i=1 uiâˆ‡gi(x0)
âŠ¤x0 = 0;
ui gi(x0) = 0, i = 1, . . . , m;
ui â‰§0, i = 1, . . . , m.
(b1)
â§
âªâ¨
âªâ©
min f (x)
gi(x) â‰§0, i = 1, . . . , m,
x â‰§0.
âˆ‡f (x0) âˆ’m
i=1 uiâˆ‡gi(x0) â‰§0;

âˆ‡f (x0) âˆ’m
i=1 uiâˆ‡gi(x0)
âŠ¤x0 = 0;
ui gi(x0) = 0, i = 1, . . . , m;
ui â‰§0, i = 1, . . . , m.
(c1)
â§
âªâ¨
âªâ©
max f (x)
gi(x) â‰¦0, i = 1, . . . , m,
x â‰§0.
âˆ‡f (x0) âˆ’m
i=1 uiâˆ‡gi(x0) â‰§0;

âˆ‡f (x0) âˆ’m
i=1 uiâˆ‡gi(x0)
âŠ¤x0 = 0;
ui gi(x0) = 0, i = 1, . . . , m;
ui â‰§0, i = 1, . . . , m.
(d1)
â§
âªâ¨
âªâ©
max f (x)
gi(x) â‰§0, i = 1, . . . , m,
x â‰§0.
âˆ‡f (x0) + m
i=1 uiâˆ‡gi(x0) â‰§0;

âˆ‡f (x0) + m
i=1 uiâˆ‡gi(x0)
âŠ¤x0 = 0;
ui gi(x0) = 0, i = 1, . . . , m;
ui â‰§0, i = 1, . . . , m.
Proof (a) Let be
K â€²
4 =

x âˆˆX : (x âˆ’x0)âŠ¤âˆ‡gi(x0) â‰¦0, i âˆˆI (x0)

,
i.e. K â€²
4 is the feasible set for (P4)L.
Obviously, if x0 âˆˆK4, then x0 âˆˆK â€²
4. If x0 âˆˆK4 is a solution of (P4) and some
constraint qualiï¬cation holds at x0, the usual Karush-Kuhn-Tucker conditions will
be satisï¬ed:
âˆ‡f (x0) +
m

i=1
uiâˆ‡gi(x0) = 0,

152
5
Constrained Optimization Problems with Inequality Constraints
uigi(x0) = 0, i = 1, . . . , m,
ui â‰§0, i = 1, . . . , m.
We have therefore âˆ‡f (x0) = âˆ’m
i=1 uiâˆ‡gi(x0) and, from the complementary
slackness conditions, we have gi(x0) < 0, ui = 0, âˆ€i /âˆˆI (x0).
Therefore,
m

i=1
uigi(x0) =

iâˆˆI (x0)
uigi(x0) = 0
and
m

i=1
uiâˆ‡gi(x0) =

iâˆˆI (x0)
uiâˆ‡gi(x0).
We have therefore that for every x âˆˆK â€²
4:
(x0)âŠ¤âˆ‡f (x0) = âˆ’(x0)âŠ¤
m

i=1
uiâˆ‡gi(x0) = âˆ’(x0)âŠ¤
iâˆˆI (x0)
uiâˆ‡gi(x0)
= âˆ’

iâˆˆI (x0)
ui(x0)âŠ¤âˆ‡gi(x0) â‰¦âˆ’

iâˆˆI (x0)
uixâŠ¤âˆ‡gi(x0)
= xâŠ¤âˆ‡f (x0) âˆ’xâŠ¤#
âˆ‡f (x0) +

iâˆˆI (x0)
uiâˆ‡gi(x0)
$
= xâŠ¤âˆ‡f (x0),
which shows that x0 âˆˆK â€²
4 is solution of (P4)L.
(b) We remark that K4 âŠ‚K â€²
4, as if x âˆˆK4, we have, for every i âˆˆI (x0) :
gi(x) â‰¦gi(x0) = 0 â‡’(x âˆ’x0)âŠ¤âˆ‡gi(x0) â‰¦0,
being the functions gi, i âˆˆI (x0), quasiconvex on the open convex set X âŠ‚Rn. If
x0 is a solution of (P4)L, we have
(x âˆ’x0)âŠ¤âˆ‡f (x0) â‰§0, âˆ€x âˆˆK â€²
4.
But, being f pseudoconvex on X and being K4 âŠ‚K â€²
4, we have
f (x0) â‰¦f (x), âˆ€x âˆˆK4.
â–¡
We note that (P4)L is a linear programming problem and therefore, if the assump-
tions of Theorem 5.24 are veriï¬ed, the same theorem may be a â€œsolution testâ€ for
(P4).
Some authors have observed that (P4) is equivalent to the following problem

5.4 Other Formulations of the Problem. Some Examples
153
â§
âªâªâªâªâ¨
âªâªâªâªâ©
min f (x)
g1(x) + (z1)2 = 0,
Â· Â· Â·
gm(x) + (zm)2 = 0,
x âˆˆX âŠ‚Rn
where z âˆˆRm is a vector of â€œauxiliary variablesâ€ or â€œslack variablesâ€. This device
is also known as the â€œsquared slack variables techniqueâ€ for nonlinear programming
problems. See, e.g. the paper of Taylor [23]. We do not treat this question, but simply
remark that it is true that the above transformation reduces a nonlinear programming
problem with inequality constraints into a problem with only equality constraints
(â€œclassical constrained optimization problemâ€), but it is also true that the number of
variables increases considerably. Moreover, the transformed problem may lose some
important properties of the original problem, such as the linearity of the constraints,
etc. This transformation, even if it is useful for some cases and considerations, does
not get rid of treating in a speciï¬c way the case of inequality constraints. See also
Bertsekas [5] for more formal considerations.
Finally, we make some considerations for the case when, in (P4), besides the
functional constraints gi(x) â‰¦0, i = 1, . . . , m, there is also an abstract constraint
or set constraint, given by a closed set C âŠ‚X âŠ‚Rn. In other words, we have a
problem of the type (we continue to assume differentiability of the functions involved
in the problem)
(P4)â€² :

min f (x)
subject to: x âˆˆC âˆ©K4.
In this case the usual Fritz John conditions of Theorem 5.5 are no longer valid
and also several constraint qualiï¬cations have to be suitably modiï¬ed, in order to
obtain the Karush-Kuhn-Tucker conditions. The following result is proved by Barbu
and Precupanu [24], Giorgi and Guerraggio [25], Nagahisa and Sakawa [26].
Theorem 5.25 Let x0 be a local solution of (P4)â€². Then, there exist multipliers
u0 â‰§0, u1 â‰§0, . . . , um â‰§0, not all zero, such that
âˆ’

u0âˆ‡f (x0) +
m

i=1
uiâˆ‡gi(x0)

âˆˆ(T1(C, x0))âˆ—,
(5.17)
uigi(x0) = 0, i = 1, . . . , m,
where T1(C, x0) is any convex subcone of T (C, x0), with vertex at 0 âˆˆT1(C, x0).
The case T1(C, x0) = T (C, x0) is not excluded.
We remark that if it is possible to choose the largest convex subcone T1(C, x0)
of T (C, x0), in case T (C, x0) is not a convex cone, Theorem 5.25 will be sharper.
Treiman [27] has shown that there are inï¬nite convex subcones of the Bouligand
tangent cone. In Nonsmooth Analysis one of the most used of these convex subcones

154
5
Constrained Optimization Problems with Inequality Constraints
is the Clarke tangent cone. See Clarke [28]. Given S âŠ‚Rn and x0 âˆˆS, the cone
TC(S, x0) =
 y âˆˆRn : âˆ€N(y), âˆƒN(x0), âˆƒÎ» > 0, âˆ€t âˆˆ(0, Î»),
âˆ€Â¯x âˆˆN(x0) âˆ©S, âˆƒÂ¯y âˆˆN(y) : Â¯x + t Â¯y âˆˆS

,
is called Clarke tangent cone to S at x0. See also Chap. 10. This cone is closed and
convex and it holds
TC(S, x0) âŠ‚T (S, x0).
However, in some (perhaps pathological) cases, TC(S, x0) is a too small approxi-
mating cone of S at x0. The polar cone of TC(S, x0) is called Clarke normal cone to
S at x0 and denoted by NC(S, x0). With this choice, relation (5.17) can be therefore
written as
âˆ’

u0âˆ‡f (x0) +
m

i=1
uiâˆ‡gi(x0)

âˆˆNC(C, x0).
When S is a convex set, then NC(S, x0) coincides with the usual normal cone
of Convex Analysis.
It follows also that if C is a closed convex set, then (5.17) becomes
âˆ’

u0âˆ‡f (x0) +
m

i=1
uiâˆ‡gi(x0)

âˆˆN(C, x0),
where N(C, x0) is the normal cone to C at x0 (see Deï¬nition 2.42). The same relation
can be rewritten in the form
0 âˆˆu0âˆ‡f (x0) +
m

i=1
uiâˆ‡gi(x0) + N(C, x0)
or also in the form

u0âˆ‡f (x0) +
m

i=1
uiâˆ‡gi(x0)
âŠ¤
(x âˆ’x0) â‰§0, âˆ€x âˆˆC.
(5.18)
Remark 5.26 In order to get u0 > 0 (i.e. u0 = 1) in Theorem 5.25, we have to
impose some constraint qualiï¬cation.
If T1(C, x0) is convex and for some Ë†x âˆˆT1(C, x0) it holds
g(x0) + âˆ‡g(x0)âŠ¤Ë†x < 0,
then relation (5.17) holds with u0 = 1.
If C âŠ‚X âŠ‚Rn is (closed) and convex and there exists Ë†x âˆˆC such that

5.4 Other Formulations of the Problem. Some Examples
155
g(x0) + âˆ‡g(x0)âŠ¤(Ë†x âˆ’x0) < 0
(generalization of the Cottle constraint qualiï¬cation), then relation (5.18) holds with
u0 = 1.
For what concerns sufï¬cient optimality conditions for problem (P4)â€², we can
prove the following result.
Theorem 5.27 Let in (P4)â€² the functions f : Rn â†’R and each gi : Rn â†’R, i =
1, . . . , m, be differentiable convex functions on the open convex set X âŠ‚Rn and let
C âŠ‚X be a closed convex set. Let x0 be feasible for (P4)â€² and assume that there
exist multipliers ui â‰§0, i = 1, . . . , m, such that
(i) 0 âˆˆâˆ‡f (x0) + m
i=1 uiâˆ‡gi(x0) + N(C, x0);
(ii) uigi(x0) = 0, i = 1, . . . , m.
Then x0 is a solution of (P4)â€².
Proof From the condition (i) it is clear that there exists Î¾ âˆˆN(C, x0) such that
0 = âˆ‡f (x0) +
m

i=1
uiâˆ‡gi(x0) + Î¾.
(5.19)
Using the fact that f and each gi are convex (see Theorem 2.6(d)) and also using the
complementary slackness conditions (ii) and relation (5.19), along with the deï¬nition
of normal cone to a convex set, we have
f (x) +
m

i=1
uigi(x) âˆ’f (x0) â‰§âˆ’Î¾ âŠ¤(x âˆ’x0) â‰§0
for all x feasible in (P4)â€².
Now for any feasible x, we have m
i=1 uigi(x) â‰¦0, since ui â‰§0, i = 1, . . . , m.
This clearly shows that f (x) â‰§f (x0) for all feasible points x.
â–¡
Following Gould and Tolle [11], it is possible to obtain for (P4)â€² a sort of â€œmod-
iï¬ed Karush-Kuhn-Tucker conditionsâ€, in absence of assumptions about constraint
qualiï¬cations.
Let us deï¬ne the set S4 = C âˆ©K4.
The set
L(x0) =

y âˆˆRn : âˆ‡gi(x0)âŠ¤y â‰¦0, i âˆˆI (x0)

continues to denote the linearizing cone at x0 âˆˆS4.
We recall that it holds T (S4, x0) âŠ‚L(x0), i.e. (L(x0))âˆ—âŠ‚(T (S4, x0))âˆ—. As
(T (S4, x0))âˆ—is a convex cone, from
(T (S4, x0))âˆ—= (L(x0))âˆ—âˆª(T (S4, x0))âˆ—\ ((L(x0))âˆ—âˆª{0})

156
5
Constrained Optimization Problems with Inequality Constraints
we obtain
(T (S4, x0))âˆ—= (L(x0))âˆ—+ (T (S4, x0))âˆ—\ ((L(x0))âˆ—âˆª{0}),
i.e.
(T (S4, x0))âˆ—= B(x0) + (T (S4, x0))âˆ—\ ((L(x0))âˆ—âˆª{0}),
where B(x0) is the cone of gradients (previously already deï¬ned):
B(x0) =
â§
â¨
â©y âˆˆRn : y =

iâˆˆI (x0)
uiâˆ‡gi(x0), ui â‰§0, i âˆˆI (x0)
â«
â¬
â­.
We have therefore the following result.
Theorem 5.28 If x0 is a local solution of (P4)â€², then there exist multipliers ui â‰§0,
i = 1, . . . , m, such that
âˆ’

âˆ‡f (x0) +
m

i=1
uiâˆ‡gi(x0)

âˆˆT (S4, x0))âˆ—\ ((L(x0))âˆ—âˆª{0}
(5.20)
uigi(x0) = 0, i = 1, . . . , m.
On the previous theorem the following remarks can be useful. If it holds
(L(x0))âˆ—= (T (S4, x0))âˆ—
(5.21)
obviously relation (5.20) becomes
âˆ‡f (x0) +
m

i=1
uiâˆ‡gi(x0) = 0,
i.e. we obtain one of the classical Karush-Kuhn-Tucker conditions. The reader will
have noted that (5.21) is the Guignard-Gould-Tolle constraint qualiï¬cation referred
to (P4)â€². From a â€œpracticalâ€ point of view it is rather unlikely that this constraint
qualiï¬cation is satisï¬ed in most cases (see also Bazaraa and Shetty [29]). A more
convenient constraint qualiï¬cation involving the Bouligand tangent cones is con-
tained in the following result, due to Gould and Tolle [11] and Guignard [9].
Theorem 5.29 Let x0 be a local solution of (P4)â€² and let the following condition
(T (S4, x0))âˆ—= (L(x0))âˆ—+ (T (C, x0))âˆ—
be veriï¬ed. Then, there exist multipliers ui â‰§0, i = 1, . . . , m, such that

5.4 Other Formulations of the Problem. Some Examples
157
âˆ’

âˆ‡f (x0) +
m

i=1
uiâˆ‡gi(x0)

âˆˆ(T (C, x0))âˆ—;
uigi(x0) = 0, i = 1, . . . , m.
The Karush-Kuhn-Tucker conditions are basic tools in the construction of many
numerical algorithms for the determination of the solution or the approximate solu-
tion of a nonlinear programming problem. However, the direct application, with only
â€œpaper and penâ€, of these conditions may result rather complicate, even for simple
problems. We present few examples, just for giving an idea of what previously
expounded.
Example 5.30 Consider the problem
â§
â¨
â©
min f (x1, x2) = (x1 âˆ’2)2 + (x2 âˆ’3)2
subject to: x1 + x2 âˆ’2 â‰¦0,
(x1)2 âˆ’4 â‰¦0.
The problem is qualiï¬ed, as the constraints are convex functions and the point
(0, 0)âŠ¤âˆˆK4 satisï¬es the Slater constraint qualiï¬cation. The Karush-Kuhn-Tucker
conditions (Theorem 5.8) are
2(x1 âˆ’2) + u1 + 2u2x1 = 0,
2(x2 âˆ’3) + u1 = 0,
u1(x1 + x2 âˆ’2) = 0,
u2((x1)2 âˆ’4) = 0,
u1 â‰§0, u2 â‰§0.
(1)
First case: u1 = u2 = 0.
We have (ï¬rst equation): 2(x1 âˆ’2) = 0; (second equation): 2(x2 âˆ’3) = 0.
Hence, we get x1 = 2, x2 = 3. However (2, 3)âŠ¤/âˆˆK4.
(2) Second case: u1 = 0, u2 > 0.
We have (x1)2 âˆ’4 = 0, i.e. x1 = Â±2. From the second equation it results x2 = 3.
We have two points: (2, 3)âŠ¤/âˆˆK4 and (âˆ’2, 3)âŠ¤âˆˆK4.
However, from the ï¬rst equation, we have
2(âˆ’4) + 2u2(âˆ’2) = 0,
i.e. u2 = âˆ’2, not acceptable.
(3) Third case: u1 > 0, u2 = 0.
We have from the third condition (complementary slackness condition): x1 +
x2 âˆ’2 = 0, i.e. x2 = 2 âˆ’x1.
From the ï¬rst equation we get

158
5
Constrained Optimization Problems with Inequality Constraints
2(x1 âˆ’2) + u1 = 0.
From the second equation, we have
2(x2 âˆ’3) + u1 = 0,
i.e.
u1 = âˆ’2(x2 âˆ’3) = âˆ’2(2 âˆ’x1 âˆ’3) = âˆ’2(âˆ’x1 âˆ’1).
We substitute this value in the ï¬rst equation:
2(x1 âˆ’2) âˆ’2(âˆ’x1 âˆ’1) = 0,
i.e. 4x1 âˆ’2 = 0, from which x1 = 1
2.
Therefore, from x2 = 2 âˆ’x1, we get x2 = 3
2. We have ( 1
2, 3
2)âŠ¤âˆˆK4, with u1 =
âˆ’2(âˆ’1
2 âˆ’1) = 3 and u2 = 0.
(4)
Fourth case: u1 > 0, u2 > 0.
From the complementary slackness conditions, we have
x1 + x2 âˆ’2 = 0;
(x1)2 âˆ’4 = 0,
from which x1 = Â±2. If x1 = 2, we have x2 = 0 and, from the ï¬rst equation,
we have u1 + 4u2 = 0, not acceptable. If x1 = âˆ’2, we have x2 = 4 and, from
the second equation, we have 2 + u1 = 0, not acceptable.
So, the unique acceptable point is x0 = ( 1
2, 3
2)âŠ¤(see Fig. 5.2). Since the objective
function and the constraints are convex, by Theorem 5.10, we have that x0 is a
solution of the problem. Moreover, as the objective function is a strictly convex
function, from Theorem 3.37(b) it follows that x0 is the unique (strict) solution
of the problem.
Example 5.31 Consider the problem
â§
â¨
â©
max f (x1, x2) = x1 + log(x2 + 1)
subject to: x1 + x2 âˆ’1 â‰¦0,
x1 â‰§0, x2 â‰§0.
The constraints are linear and hence the problem is qualiï¬ed. The Karush-Kuhn-
Tucker conditions at the feasible point x0 are (see (c1) in Table 5.1, p. 151):
âˆ‡f (x0) âˆ’
m

i=1
uiâˆ‡gi(x0) â‰¦0;

âˆ‡f (x0) âˆ’
m

i=1
uiâˆ‡gi(x0)
âŠ¤
x0 = 0;

5.4 Other Formulations of the Problem. Some Examples
159
Fig. 5.2 Example 5.30. Feasible set and level curve for f
ui â‰§0, âˆ€i = 1, . . . , m; uigi(x0) = 0, âˆ€i = 1, . . . , m.
Therefore, we have
1 âˆ’u1 â‰¦0;
1
x2 + 1 âˆ’u1 â‰¦0;
(1 âˆ’u1)x1 = 0;

1
x2 + 1 âˆ’u1

x2 = 0;
u1 â‰§0, u1(x1 + x2 âˆ’1) = 0.
From 1 âˆ’u1 â‰¦0, we have u1 â‰§1.
Then, from (1 âˆ’u1)x1 = 0, we have either x1 = 0 or u1 = 1.
(1) If x1 = 0, then, from u1(x2 âˆ’1) = 0, we have x2 = 1 since u1 â‰§1. Hence,
from the condition
#
1
x2+1 âˆ’u1
$
x2 = 0, we have ( 1
2 âˆ’u1) = 0, i.e. u1 = 1
2, not
acceptable, as u1 â‰§1.
(2) If u1 = 1, from
#
1
x2+1 âˆ’u1
$
x2 = 0 it follows that
1
x2+1 âˆ’1 = 0 or x2 = 0.
Both equations have the solution x2 = 0, and hence from u1(x1 + x2 âˆ’1) = 0,
we have x1 âˆ’1 = 0, i.e. x1 = 1.
Hence, we have only a feasible point (1, 0)âŠ¤that satisï¬es the Karush-Kuhn-
Tucker conditions with u1 = 1.

160
5
Constrained Optimization Problems with Inequality Constraints
Fig. 5.3 Example 5.32.
Feasible set
As the feasible set S is compact and f is continuous on S, by the Weierstrass The-
orem, the maximum is attained. Then the Karush-Kuhn-Tucker conditions are
satisï¬ed at this maximum, and as x0 is the only point satisfying these conditions,
we derive that x0 solves the problem.
Example 5.32 Consider the problem
â§
âªâªâ¨
âªâªâ©
max(x1x2 âˆ’x1 âˆ’x2 + 2)
subject to: x1x2 â‰¦6;
x1 + x2 â‰¦5;
x1 â‰§0, x2 â‰§0.
We remark that the feasible set (see Fig. 5.3) is closed and bounded (and so it is
compact) and that the objective function is continuous.
The Karush-Kuhn-Tucker conditions, including the feasibility conditions, are (see
(c1) in Table 5.1, p. 151):
x2 âˆ’1 âˆ’u1x2 âˆ’u2 â‰¦0;
x1 âˆ’1 âˆ’u1x1 âˆ’u2 â‰¦0;
(x2 âˆ’1 âˆ’u1x2 âˆ’u2)x1 = 0;
(x1 âˆ’1 âˆ’u1x1 âˆ’u2)x2 = 0;
u1(6 âˆ’x1x2) = 0;
u2(5 âˆ’x1 âˆ’x2) = 0;
5 âˆ’x1 âˆ’x2 â‰§0;
6 âˆ’x1x2 â‰§0;
x1 â‰§0, x2 â‰§0.
(1) Case u1 = u2 = 0. The above conditions become

5.4 Other Formulations of the Problem. Some Examples
161
x2 âˆ’1 â‰¦0;
x1 âˆ’1 â‰¦0;
(x2 âˆ’1)x1 = 0;
(x1 âˆ’1)x2 = 0;
6 âˆ’x1x2 â‰§0;
5 âˆ’x1 âˆ’x2 â‰§0;
x1 â‰§0, x2 â‰§0.
From these conditions we obtain the points
x1 =
 0
0
!
;
x2 =
 1
1
!
.
It holds f (x1) = 2; f (x2) = 1.
We exclude however the point x2, which is interior to the feasible set, but where
âˆ‡2 f (x2) is indeï¬nite.
(2) Case u1 > 0, u2 = 0. We have the system
x2 âˆ’1 âˆ’u1x2 â‰¦0;
x1 âˆ’1 âˆ’u1x1 â‰¦0;
(x2 âˆ’1 âˆ’u1x2)x1 = 0;
(x1 âˆ’1 âˆ’u1x1)x2 = 0;
6 âˆ’x1x2 = 0;
5 âˆ’x1 âˆ’x2 â‰§0;
x1 â‰§0, x2 â‰§0.
From the third condition, we have
x2 =
1
1 âˆ’u1
âˆ¨x1 = 0.
From the fourth condition, we have
x1 =
1
1 âˆ’u1
âˆ¨x2 = 0.
The condition 6 âˆ’x1x2 = 0 eliminates the zero solutions. Moreover, we have
x1 = x2 and from 6 âˆ’x1x2 = 0 we get x1 = x2 =
âˆš
6, from which we have
âˆš
6 =
1
1 âˆ’u1
,

162
5
Constrained Optimization Problems with Inequality Constraints
i.e.
u1 = 6 âˆ’
âˆš
6
6
.
The reader can verify that these values satisfy the remaining relations of the
system. We have therefore the point
x3 =
 âˆš
6
âˆš
6
!
and it holds f (x3) = 8 âˆ’2
âˆš
6 â‰ƒ3, 1.
(3) Case u2 > 0, u1 = 0. We have the system
x2 âˆ’1 âˆ’u2 â‰¦0;
x1 âˆ’1 âˆ’u2 â‰¦0;
(x2 âˆ’1 âˆ’u2)x1 = 0;
(x1 âˆ’1 âˆ’u2)x2 = 0;
6 âˆ’x1x2 â‰§0;
5 âˆ’x1 âˆ’x2 = 0;
x1 â‰§0, x2 â‰§0.
From the third and fourth conditions we get
x1 = x2 = 1 + u2 âˆ¨x1 = x2 = 0.
Thezerosolutionsarenotacceptable.Wehaveu2 = 3
2,fromwhich x1 = x2 = 5
2.
Also this solution is not acceptable, as it is not feasible:
6 âˆ’5
2 Â· 5
2 = 6 âˆ’25
4 = âˆ’1
4 < 0.
Therefore, the case under examination does not produce new candidates.
(4) Case u1 > 0, u2 > 0. We have the system
x2 âˆ’1 âˆ’u1x2 âˆ’u2 â‰¦0;
x1 âˆ’1 âˆ’u1x1 âˆ’u2 â‰¦0;
(x2 âˆ’1 âˆ’u1x2 âˆ’u2)x1 = 0;
(x1 âˆ’1 âˆ’u1x1 âˆ’u2)x2 = 0;
6 âˆ’x1x2 = 0;
5 âˆ’x1 âˆ’x2 = 0;
x1 â‰§0, x2 â‰§0.

5.4 Other Formulations of the Problem. Some Examples
163
Fig. 5.4 Example 5.33.
Feasible set
From the ï¬fth and sixth conditions, we have
x4 =
 3
2
!
;
x5 =
 2
3
!
.
By substituting x4 in the third and fourth condition we ï¬nd u1 = 1, u2 = âˆ’1.
Therefore, x4 is not acceptable. By substituting the point x5 we ï¬nd again u1 = 1,
u2 = âˆ’1. Also x5 is not acceptable.
By comparison of the values assumed by f on the feasible points we have found,
x1 and x3, we can conclude that the solution of the problem is
x3 =
 âˆš
6
âˆš
6
!
,
with associated multipliers u1 = 1 âˆ’
âˆš
6
6 , u2 = 0.
Example 5.33 Consider the problem
â§
â¨
â©
min

2(x1)2 âˆ’x2

subject to: (x1)2 + (x2 âˆ’1)2 â‰§1
(x1)2 + (x2)2 â‰¦2.
The feasible set of this problem is drawn in Fig. 5.4.
We consider the Lagrangian function
L (x, u) = 2(x1)2 âˆ’x2 + u1(1 âˆ’(x1)2 âˆ’(x2 âˆ’1)2) + u2((x1)2 + (x2)2 âˆ’2).
We have
âˆ‡xL (x, u) =
4x1
âˆ’1

âˆ’2u1

x1
x2 âˆ’1

+ 2u2
 x1
x2

=
 0
0

.

164
5
Constrained Optimization Problems with Inequality Constraints
For I (x0) = âˆ…, we have u1 = u2 = 0 and therefore we have no solution of the
above relations.
The case I (x0) = {1} gives, with u2 = 0, (x1)2 + (x2 âˆ’1)2 = 1 and we have the
solutions
x1 =
0
0

with u1 =
 1
2
0

,
x2,3 =
Â± 1
4
âˆš
15
3
4

, with u2,3 =
 2
0

.
Also the case I (x0) = {2} gives, with u1 = 0, (x1)2 + (x2)2 = 2 and we have no
solution of the Kuhn-Tucker conditions.
Finally, for I (x0) = {1, 2} , from the nonlinear equations (x1)2 + (x2 âˆ’1)2 = 1,
(x1)2 + (x2)2 = 2 we get the solutions
x4,5 =
Â±1
1

, with u4,5 =

5
2
1
2

.
Now, let us consider the Hessian matrix
âˆ‡2
xL (x, u) =
 4 âˆ’2u1 + 2u2
0
0
âˆ’2u1 + 2u2

.
For
x1 =
0
0

with u1 =
 1
2
0

,
we have
âˆ‡2
xL (x1, u1) =
 3
0
0 âˆ’1

which is positive deï¬nite on the cone

y âˆˆR2 : y2 = 0

.
Therefore, by Theorem 5.22, this point is a strict local minimum point of the
problem.
The points
x2,3 =
Â± 1
4
âˆš
15
3
4

, with u2,3 =
2
0

both give the matrix
âˆ‡2
xL (x2,3, u2,3) =
0
0
0 âˆ’4

.

5.4 Other Formulations of the Problem. Some Examples
165
This matrix is not positive semideï¬nite on the cone

y âˆˆR2 : âˆ“1
4
âˆš
15y1 + 1
2 y2 = 0

and hence, by Theorem 5.18, these points are not local minimizers of the problem
proposed.
Finally, we consider the points
x4,5 =
Â±1
1

, with u4,5 =

5
2
1
2

.
As in this case, the critical cone is y âˆˆR2, y = 0, These points are trivially local
minimum points for the problem proposed.
By computing the values of the objective function and making the comparisons,
we have that x1 =
 0
0

is the global minimum point for the problem considered.
We propose the following problems. The reader is invited to use, when possible,
the Karush-Kuhn-Tucker conditions.
Problem 5.34
â§
â¨
â©
max(x âˆ’3)2 + y2
subject to: x + (y âˆ’1)3 â‰¦0,
x, y â‰§0, y â‰¦1.
(The point (0, 1) is the solution, which can be found by a geometric method. At
this point the Karush-Kuhn-Tucker conditions are satisï¬ed, with multipliers u1 =
u3 = 0, u2 = 6, u4 = 2).
Problem 5.35
â§
âªâªâ¨
âªâªâ©
min (x âˆ’9
4)2 + (y âˆ’2)2
subject to: y âˆ’x2 â‰§0;
x + y â‰¦6;
x, y â‰§0.
(Verify that the point ( 3
2, 9
4) satisï¬es the Karush-Kuhn-Tucker conditions, with
multipliers u2 = u3 = u4 = 0. Being the objective function convex, the above point
is a global solution of the problem).
Problem 5.36 Consider the problem
â§
âªâªâªâªâ¨
âªâªâªâªâ©
max y2 + zâˆ’5
subject to: x2 + (y âˆ’1)2 + z2 â‰¦1;
(x âˆ’y)2 â‰¦1;
2y + z â‰¦3;
z â‰§0

166
5
Constrained Optimization Problems with Inequality Constraints
and check whether the Karush-Kuhn-Tucker conditions are veriï¬ed at the point (0,
1, 1).
(The above point does not verify the Karush-Kuhn-Tucker conditions and hence
it cannot be a solution of the problem).
Problem 5.37 Consider the problem
â§
âªâªâ¨
âªâªâ©
min(x âˆ’3)2 + (y âˆ’2)2
subject to: x2 + y2 â‰¦5;
x + 2y â‰¦4;
x, y â‰§0.
Solve the problem by means of the Karush-Kuhn-Tucker conditions.
(The point (2, 1) is the solution of the problem).
Problem 5.38 Solve the problem
â§
âªâªâ¨
âªâªâ©
min x+3y+3
2x+y+6
subject to: 2x + y â‰¦12;
2y âˆ’x â‰¦4;
x, y â‰§0.
(The inï¬nite points of the segment of end points (0, 0) and (6, 0) are solutions of
the problem).
Problem 5.39 Use the ï¬rst- and second-order conditions to solve the problem
min

2x2 + y2
, subject to: y âˆ’x2 + 4 â‰¦0.
(The points (âˆ’
âˆš
3, âˆ’1) and (
âˆš
3, âˆ’1) are the two solutions).
Problem 5.40 Use the ï¬rst- and second-order conditions to solve the problem
â§
âªâªâ¨
âªâªâ©
max(x + y)
subject to: y âˆ’x2 + 1 â‰§0
x âˆ’y2 + 1 â‰§0
x, y â‰§0.
(The point ( 1
2(1 +
âˆš
5), 1
2(1 +
âˆš
5)) is the unique global solution).
Problem 5.41 Use the ï¬rst- and second-order conditions to solve the problem
â§
â¨
â©
max(xy)
subject to: (x âˆ’1)2 + y2 â‰¦1
x2 + (y âˆ’1)2 â‰¦1.
(The point (1, 1) is the unique solution).

References
167
References
1. K.J. Arrow, L. Hurwicz, H. Uzawa, Constraint qualiï¬cations in maximization problems. Naval
Res. Logist. 8, 175â€“191 (1961). Reprinted in Giorgi and Kjeldsen (2014)
2. Y. Chabrillac, J.-P. Crouzeix, Deï¬niteness and semi-deï¬niteness of quadratic forms revisited.
Linear Algebra Appl. 63, 283â€“292 (1984)
3. F. John, Extremum problems with inequalities as subsidiary conditions, in Studies and Essays:
Courant Anniversary Volume, eds. by K.O. Friedrichs, O.E. Neugebauer, J.J. Stoker (Inter-
science Publishers, New York), pp. 187â€“204. Reprinted in Giorgi and Kjeldsen (2014)
4. G. Giorgi, T.H. Kjeldsen, Traces and Emergence of Nonlinear Programming (BirkhÃ¤user, Basel
and New York, 2014)
5. D.P. Bertsekas, Nonlinear Programming, 2nd edn. (Athena Scientiï¬c, Belmont, Mass, 1999)
6. D.P. Bertsekas, A.E. Ozdaglar, Pseudonormality and Lagrange multiplier theory for constrained
optimization. J. Optim. Theory Appl. 114, 287â€“343 (2002)
7. J.M. Abadie, On the Kuhn-Tucker theorem, in Nonlinear Programming. ed. by J.M. Abadie
(North Holland, Amsterdam, 1967), pp. 21â€“36
8. H.W. Kuhn, A.W. Tucker, Nonlinear programming, in Proceedings of the Second Berkeley
Symposium on Mathematical Statistics and Probability, ed. by J. Neyman (Univ. of California
Press, Berkeley, 1951), pp. 481â€“492. Reprinted in Giorgi and Kjeldsen (2014)
9. M. Guignard, Generalized Kuhn-Tucker conditions for mathematical programming problems
in a Banach space. SIAM J. Control 7, 232â€“241 (1969)
10. F.J. Gould, J.W. Tolle, A necessary and sufï¬cient qualiï¬cation for constrained optimization.
SIAM J. Appl. Math. 20, 164â€“172 (1971)
11. F.J. Gould, J.W. Tolle, Geometry of optimality conditions and constraint qualiï¬cations. Math.
Program. 2, 1â€“18 (1972)
12. O.L. Mangasarian, Nonlinear Programming (McGraw-Hill Book Company, New York, 1969)
13. J. Stoer, C. Witzgall, Convexity and Optimization in Finite Dimensions, I (Springer, New York,
1971)
14. J.E. Martinez-Legaz, What is invexity with respect to the same Î·. Taiwanese J. Math. 13,
753â€“755 (2009)
15. A. Ben-Israel, B. Mond, What is invexity? J. Austral. Math. Soc. Ser. B 28, 1â€“9 (1986)
16. M.R. Hestenes, Optimization Theory. The Finite Dimensional Case (Wiley, New York, 1975)
17. W.I. Zangwill, Nonlinear Programming: A Uniï¬ed Approach (Prentice-Hall, Englewood Cliffs,
N.J., 1969)
18. G. Giorgi, B. JimÃ©nez, V. Novo, On constraint qualiï¬cations in directionally differentiable
multiobjective optimization problems. RAIRO Oper. Res. 38(3), 255â€“274 (2004)
19. J. Kyparisis, On uniqueness of Kuhn-Tucker multipliers in nonlinear programming. Math.
Program. 32, 242â€“246 (1985)
20. K.-H.Elster,R.Reinhardt,M.SchÃ¤uble,G.Donath,EinfÃ¼hrungindienichtlineareOptimierung
(Teubner Verlagsgesellschaft, Leipzig, BSB B. G, 1977)
21. G.P. Mccormick, Second order conditions for constrained minima. SIAM J. Appl. Math. 15,
641â€“652 (1967). Reprinted in Giorgi and Kjeldsen (2014)
22. G. Debreu, Deï¬nite and semideï¬nite quadratic forms. Econometrica 20, 285â€“300 (1952)
23. J.G. Taylor, A squared-variable transformation approach to nonlinear programming. Naval Res.
Logist. Quart. 20, 25â€“39 (1973)
24. V. Barbu, T. Precupanu, Convexity and Optimization in Banach Spaces, 4th edn. (Springer,
Berlin, 2012)
25. G. Giorgi, A. Guerraggio, First order generalized optimality conditions for programming prob-
lems with a set constraint, in Generalized Convexity. Proceedings of the IV International Work-
shop on Generalized Convexity, eds. by S. Komlosi, T. Rapcsak, S. Schaible (Pecs, Hungary,
Springer, Berlin, 1992), pp. 171â€“185
26. Y. Nagahisa, Y. Sakawa, Nonlinear programming in Banach spaces. J. Optim. Theory Appl. 4,
182â€“190 (1969)

168
5
Constrained Optimization Problems with Inequality Constraints
27. J.S. Treiman, An inï¬nite class of convex tangent cones. J. Optim. Theory Appl. 68, 563â€“581
(1991)
28. F.H. Clarke, Optimization and Nonsmooth Analysis (Wiley, New York, 1983)
29. M.S. Bazaraa, C.M. Shetty, Foundations of Optimization, Lecture Notes in Economics and
Mathematics Systems, vol. 122. (Springer, Berlin, 1976)
30. D. Gale, The Theory of Linear Economic Models (McGraw-Hill Book Company, New York,
1960)

Chapter 6
Constrained Optimization Problems
with Mixed Constraints
6.1
First-Order Conditions
In this chapter, we shall be concerned with problem (P5), i.e. with a constrained
minimization problem with mixed constraints, i.e. with both inequality and equality
constraints.
(P5) :
â§
âªâªâ¨
âªâªâ©
min f (x)
subject to: gi(x) â‰¦0, i = 1, . . . , m,
h j(x) = 0, j = 1, . . . , p < n,
x âˆˆX âŠ‚Rn,
where X âŠ‚Rn is an open set contained in the domains of the functions involved in
(P5), f, gi, i âˆˆM = {1, . . . , m} and h j, j âˆˆP = {1, . . . , p < n} , are real-valued
functions deï¬ned on Rn.
We make the assumptions that f and every gi, i = 1, . . . , m, are (at least) differ-
entiableon X andthat every h j, j = 1, . . . , p,is (at least) continuouslydifferentiable
on X (weaker differentiability assumptions are possible).
It is quite evident that (P5) subsumes the properties of (P3) and (P4), however,
it deserves a speciï¬c treatment. For example, if we rewrite the equalities h j(x) = 0,
j = 1, . . . , p, appearing in (P5), as h j(x) â‰¦0 and âˆ’h j(x) â‰¦0, the ï¬rst relation of
the Fritz John conditions for this equivalent problem (see Theorem 5.5) becomes
u0âˆ‡f (x0) +
m

i=1
uiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0) âˆ’
p

j=1
w jâˆ‡h j(x0) = 0,
with multipliers not all zero and nonnegative. Unfortunately, this condition is satisï¬ed
by any feasible point of (P5) by u0 = ui = 0, i = 1, . . . , m, and by v j = w j, j =
1, . . . , p, nonnegative and not all zero. The above reduction of (P5) to the form of
Â© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al., Basic Mathematical Programming Theory, International Series
in Operations Research & Management Science 344,
https://doi.org/10.1007/978-3-031-30324-1_6
169

170
6
Constrained Optimization Problems with Mixed Constraints
(P4) is in this case of no utility, being the necessary Fritz John conditions always
veriï¬ed by any feasible point, and therefore meaningless.
The feasible set or set of feasible points of (P5) is given by
K5 =

x âˆˆX : gi(x) â‰¦0, âˆ€i âˆˆM; h j(x) = 0, âˆ€j âˆˆP

and f is the objective function of (P5).
The set of active constraints or effective constraints or binding constraints at
x0 âˆˆK5 is
I (x0) =

i âˆˆM : gi(x0) = 0

.
If x0 âˆˆK5, the linearizing cone of K5 at x0 (or cone of locally constrained direc-
tions of K5 at x0) is given by
L(x0) =
	 y âˆˆRn : âˆ‡gi(x0)âŠ¤y â‰¦0, âˆ€i âˆˆI (x0);
âˆ‡h j(x0)âŠ¤y = 0, âˆ€j âˆˆP

.
Obviously, this cone is a convex polyhedral cone and hence it is closed and convex.
The cone
Lo(x0) =
	 y âˆˆRn : âˆ‡gi(x0)âŠ¤y < 0, âˆ€i âˆˆI (x0);
âˆ‡h j(x0)âŠ¤y = 0, âˆ€j âˆˆP

is called cone of relative interior locally constrained directions of K5 at x0 (or also
strictly inward cone or cone of descent directions of K5 at x0).
We note that Lo(x0) is a relatively open convex cone, with respect to the sub-
space

y âˆˆRn : âˆ‡h j(x0)âŠ¤y = 0, âˆ€j âˆˆP

. Obviously, if I (x0) = âˆ…, both L(x0)
and Lo(x0) coincide with the said subspace. We note also that the forms of T (K5, x0),
A(K5, x0) and F(K5, x0) remain quite similar to the ones deï¬ned for problem (P4),
howeve,r the cone of feasible directions F(K5, x0) is very likely given by the sin-
gleton {0} , unless the constraints h j(x), âˆ€j âˆˆP, are linear afï¬ne. So, in the present
chapter, we will not take F(K5, x0) into consideration.
Theorem 6.1 Let x0 âˆˆK5. It holds
T (K5, x0) âŠ‚L(x0).
If the Jacobian matrix âˆ‡h(x0) has full rank (i.e. the gradients âˆ‡h j(x0), j =
1, . . . , p, are linearly independent), then it holds
Lo(x0) âŠ‚T (K5, x0).
If, moreover, Lo(x0) Ì¸= âˆ…, then
cl(Lo(x0)) = T (K5, x0) = L(x0).

6.1 First-Order Conditions
171
Proof The ï¬rst inclusion is proved in a similar way of what proved in Theorem 4.38
and in Theorem 5.3. We repeat the proof. Let be given y âˆˆT (K5, x0), with âˆ¥yâˆ¥= 1.
Therefore, there exist a feasible sequence

xk
âŠ‚K5, with xk
yâ†’x0. Hence, for all
i âˆˆI (x0), the quotients
gi(xk) âˆ’gi(x0)
xk âˆ’x0
= âˆ‡gi(x0)âŠ¤(xk âˆ’x0) + o(
xk âˆ’x0)
xk âˆ’x0
converge to âˆ‡gi(x0)âŠ¤y â‰¦0.
For all j âˆˆP, the quotients
h j(xk) âˆ’h j(x0)
xk âˆ’x0
= âˆ‡h j(x0)âŠ¤(xk âˆ’x0) + o(
xk âˆ’x0)
xk âˆ’x0
converge to âˆ‡h j(x0)âŠ¤y = 0.
It follows that y âˆˆL(x0).
For the second inclusion let us assume I (x0) Ì¸= âˆ…, otherwise it would be Lo(x0) =
L(x0) and the thesis is immediate from Theorem 4.38. Then we have y âˆˆLo(x0),
with âˆ¥yâˆ¥= 1, so this vector belongs (on the grounds of the assumptions), thanks to
Theorem 4.38, to the Bouligand tangent cone to the set

x âˆˆRn : h j(x) = 0, âˆ€j âˆˆP

,
with only equality constraints, i.e. there exists a sequence

xk
belonging to this set
which converges tangentially to x0 in the direction y.
As, for each active constraint, the quotients
gi(xk) âˆ’gi(x0)
xk âˆ’x0
= âˆ‡gi(x0)âŠ¤(xk âˆ’x0) + o(
xk âˆ’x0)
xk âˆ’x0
converge to âˆ‡gi(x0)âŠ¤y < 0, we have that gi(xk) < 0 for k âˆˆN sufï¬ciently large.
For non-active constraints at x0, the said inequality holds, thanks to continuity. The
sequence

xk
is therefore a feasible sequence. Hence, y âˆˆT (K5, x0).
The proof of the third statement of the theorem is performed in a similar way of
the proof of Corollary 5.4.
â–¡
Remark 6.2 It is possible to prove a more complete version of Theorem 6.1, i.e.
with x0 âˆˆK5, it holds:
(a) A(K5, x0) âŠ‚T (K5, x0) âŠ‚L(x0).
(This is obvious, as we have always A(Â·, Â·) âŠ‚T (Â·, Â·)).
(b) If âˆ‡h j(x0), j = 1, . . . , p, are linearly independent, then it holds
Lo(x0) âŠ‚A(K5, x0) âŠ‚T (K5, x0) âŠ‚L(x0).
and if Lo(x0) Ì¸= âˆ…, then
cl(Lo(x0)) = A(K5, x0) = T (K5, x0) = L(x0).

172
6
Constrained Optimization Problems with Mixed Constraints
This is useful in order to compare (see the next section) the Kuhn-Tucker con-
straint qualiï¬cation and the Abadie constraint qualiï¬cation for (P5).
We are now ready to prove the Fritz John necessary optimality conditions for
problem (P5).
Theorem 6.3 (Fritz John Theorem) Let x0 âˆˆK5 be a local minimum point for (P5).
Then there exist multipliers (â€œFritz John multipliersâ€) u0, u1, . . . , um, v1, . . . , vp,
not all zero, such that
(i) u0âˆ‡f (x0) + m
i=1 uiâˆ‡gi(x0) + p
j=1 v jâˆ‡h j(x0) = 0;
(ii) uigi(x0) = 0, i = 1, . . . , m;
(iii) u0 â‰§0, u1 â‰§0, . . . , um â‰§0.
Proof If the vectors

âˆ‡h1(x0), . . . , âˆ‡h p(x0)

are linearly dependent, the thesis of
the theorem is trivial. Assume therefore that these vectors are linearly independent,
i.e. the Jacobian matrix âˆ‡h(x0) is of full rank.
As x0 âˆˆK5 is a local minimum point for (P5), it follows from Theorem 4.24 and
taking into account the second result of the previous theorem,
âˆ‡f (x0)âŠ¤y â‰§0, âˆ€y âˆˆT (K5, x0) âŠƒLo(x0).
It holds also âˆ‡f (x0)âŠ¤y â‰§0 for all those y such that âˆ‡gi(x0)âŠ¤y < 0, i âˆˆI (x0),
and such that âˆ‡h j(x0)âŠ¤y = 0, j âˆˆP. In other words, the inequality system
â§
â¨
â©
âˆ‡f (x0)âŠ¤y < 0,
âˆ‡gi(x0)âŠ¤y < 0, i âˆˆI (x0),
âˆ‡h j(x0)âŠ¤y = 0, j = 1, . . . , p,
(6.1)
admits no solution y âˆˆRn. By Motzkinâ€™s theorem of the alternative (Chap. 2),
there exist therefore numbers ui â‰§0, i âˆˆ{0} âˆªI (x0), not all zero, and v j âˆˆR,
j = 1, . . . , p, such that
u0âˆ‡f (x0) +

iâˆˆI (x0)
uiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0) = 0.
In any case, by choosing ui = 0 for all indices i /âˆˆI (x0), we obtain the thesis. â–¡
Conditions (i), (ii) and (iii) in Theorem 6.3 are called Fritz John conditions.
It appears from the proof of the previous theorem that if the gradients âˆ‡h j(x0),
j = 1, . . . , p, are linearly independent, then we can obtain that the multipliers u0 â‰§
0, u1 â‰§0, . . . , um â‰§0, are not all zero. If x0 âˆˆK5 is a local solution of (P5) and
the gradients âˆ‡h j(x0), j = 1, . . . , p, are linearly independent, from the proof of the
previous theorem it appears that the system (6.1) admits no solution y âˆˆRn. This is
the Abadie linearization lemma for (P5). It may be considered a (ï¬rst-order) â€œprimal

6.1 First-Order Conditions
173
necessary optimality conditionâ€ for (P5), whereas the Fritz John theorem may be
considered a â€œdual necessary optimality conditionâ€ for (P5).
We give now another type of proof of the Fritz John necessary conditions for (P5),
i.e. a proof based on a â€œpenalization techniqueâ€ on the original problem. This type of
proof is originally due to Mc Shane [1] and subsequently has been reconsidered and
ameliorated by Bertsekas [2] and Bertsekas and Ozdaglar [3], who obtained what
they call â€œenhanced Fritz John optimality conditionsâ€ (see Sect. 6.4).
We make the assumption that all functions involved in (P5) are continuously
differentiable on the open set X âŠ‚Rn.
Proof of Theorem 6.3 by a penalization technique For every k âˆˆN, k â‰§1, we
deï¬ne the function
Fk : X â†’R, Fk(x) = f (x) + k
m

i=1

g+
i (x)
2 + k
p

j=1

h j(x)
2 +
x âˆ’x02 ,
where g+
i (x) = max {gi(x), 0} .
Let us consider a closed neighborhood (a closed ball) Â¯B(x0,r) centered at x0 and
of radius r > 0 such that Â¯B(x0,r) âŠ‚X and
f (x) â‰§f (x0), âˆ€x âˆˆK5 âˆ©Â¯B(x0,r).
The function Fk is continuous on X and Â¯B(x0,r) is a compact set contained in
X. Therefore, there exists a point Â¯xk âˆˆÂ¯B(x0,r) which minimizes Fk over Â¯B(x0,r).
It holds in particular
Fk(Â¯xk) â‰¦Fk(x0) = f (x0),
i.e.
m

i=1

g+
i (Â¯xk)
2 +
p

j=1

h j(Â¯xk)
2 â‰¦1
k

f (x0) âˆ’f (Â¯xk) âˆ’
Â¯xk âˆ’x02
.
(6.2)
The expression between parentheses on the right-hand side of (6.2) is bounded
(with respect to k) and hence, taking the limit for k â†’âˆ, we get
lim
kâ†’âˆg+
i (Â¯xk) = 0, for i = 1, . . . , m;
lim
kâ†’âˆh j(Â¯xk) = 0, for j = 1, . . . , p.
The sequence

Â¯xk
is in the compact set Â¯B(x0,r), hence we can consider a
subsequence

Â¯xkâ„“
â„“converging to Ëœx. We have that Ëœx âˆˆÂ¯B(x0,r) and, by the continuity
of the functions g+
i
and h j, we get g+
i (Ëœx) = 0, âˆ€i = 1, . . . , m, and h j(Ëœx) = 0,
âˆ€j = 1, . . . , p. Therefore, Ëœx âˆˆK5 âˆ©Â¯B(x0,r).

174
6
Constrained Optimization Problems with Mixed Constraints
But, being f (Â¯xkâ„“) +
Â¯xkâ„“âˆ’x02 â‰¦f (x0) for every index â„“(this comes from
relation (6.2) since the left hand side of (6.2) is â‰§0), taking the limit we have
f (Ëœx) +
Ëœx âˆ’x02 â‰¦f (x0).
It holds f (x0) â‰¦f (Ëœx), as x0 is a minimizer of f over K5 âˆ©Â¯B(x0,r), hence
Ëœx âˆ’x02 = 0 and so Ëœx = x0.
Thisreasoningholdsforeveryconvergentsubsequenceof

Â¯xk
:hence,wededuce
that the sequence

Â¯xk
converges to x0 when k â†’âˆ.
By starting from a certain value of k, we have that Â¯xk lies in the interior of Â¯B(x0,r)
and therefore, by the stationary condition,
0 = âˆ‡Fk(Â¯xk)
= âˆ‡f (Â¯xk) + 2k
m

i=1
g+
i (Â¯xk)âˆ‡gi(Â¯xk) + 2k
p

j=1
h j(Â¯xk)âˆ‡h j(Â¯xk) + 2(Â¯xk âˆ’x0).
Let us denote
k =
â›
â1 + 4k2
m

i=1

g+
i (Â¯xk)
2 + 4k2
p

j=1

h j(Â¯xk)
2
â
â 
1
2
,
u0,k = 1
k
,
ui,k = 2kg+
i (Â¯xk)
k
,
v j,k = 2kh j(Â¯xk)
k
.
The vector (u0,k, u1,k, . . . , um,k, v1,k, . . . , vp,k) âˆˆR Ã— Rm Ã— Rp
and is of
Euclidean norm equal to 1 (by construction!). Moreover,
0 = u0,kâˆ‡f (Â¯xk) +
m

i=1
ui,kâˆ‡gi(Â¯xk) +
p

j=1
v j,kâˆ‡h j(Â¯xk) + 2(Â¯xk âˆ’x0)
k
.
By considering a subsequence, we take the limit of the above expression:
(u0,k, u1,k, . . . , um,k, v1,k, . . . , vp,k) â†’
kâ†’âˆ(u0, u1, . . . , um, v1, . . . , vp) Ì¸= 0;
0 = u0âˆ‡f (x0) +
m

i=1
uiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0)
as k â‰§1, Â¯xk â†’x0 and the applications âˆ‡f, âˆ‡gi and âˆ‡h j are continuous.
It is clear that u0, u1, . . . , um, being the limits of nonnegative quantities are non-
negative. Finally, if i /âˆˆI (x0), i. e. gi(x0) < 0, we have ui,k = 0, starting from a

6.1 First-Order Conditions
175
certain index k, and hence ui = 0, for i /âˆˆI (x0), from which the complementary
slackness conditions.
â–¡
As previously remarked for problem (P4), in order to avoid that in the Fritz John
conditions it holds u0 = 0, we have to impose some constraint qualiï¬cation. We
introduce for (P5) the Guignard-Gould-Tolle constraint qualiï¬cation.
Let x0 âˆˆK5. We say that the Guignard-Gould-Tolle constraint qualiï¬cation
holds if
(L(x0))âˆ—= (T (K5, x0))âˆ—,
(6.3)
equality equivalent to the expression given by Guignard [4]:
L(x0) = cl(conv(T (K5, x0))).
We introduce also the cone of gradients for (P5):
B(x0) =
â§
â¨
â©y âˆˆRn : y =

iâˆˆI (x0)
uiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0), ui â‰§0, âˆ€i âˆˆI (x0)
â«
â¬
â­.
Obviously, B(x0) is a ï¬nite cone, i.e. a convex polyhedral cone; hence it is a
closed convex set and with the same proof of Lemma 4.1, we see that
B(x0) = (L(x0))âˆ—
and
L(x0) = (B(x0))âˆ—.
We are now ready to obtain for (P5) the Karush-Kuhn-Tucker optimality
conditions.
Theorem 6.4 (Karush-Kuhn-Tucker) Let x0 âˆˆK5 be a local solution of (P5) and
let the Guignard-Gould-Tolle constraint qualiï¬cation (6.3) be satisï¬ed. Then there
exist multipliers (â€œKarush-Kuhn-Tucker multipliersâ€ ) u1, . . . , um and v1, . . . , vp
such that
(i) âˆ‡f (x0) + m
i=1 uiâˆ‡gi(x0) + p
j=1 v jâˆ‡h j(x0) = 0;
(ii) uigi(x0) = 0, i = 1, . . . , m;
(iii) ui â‰§0, i = 1, . . . , m.
Proof The proof is the same of the one for (P4). From Theorem 4.24, we know that
âˆ‡f (x0)âŠ¤y â‰§0 for every y âˆˆT (K5, x0), whence âˆ’âˆ‡f (x0) âˆˆ(T (K5, x0))âˆ—. We use
now the constraint qualiï¬cation (6.3), i. e. the relation (T (K5, x0))âˆ—= (L(x0))âˆ—, to
deduce that âˆ’âˆ‡f (x0) âˆˆ(L(x0))âˆ—.

176
6
Constrained Optimization Problems with Mixed Constraints
But, being (L(x0))âˆ—= B(x0), we get âˆ’âˆ‡f (x0) âˆˆB(x0). Consequently, there
exist ui â‰§0, i âˆˆI (x0), v j âˆˆR, v j = 1, . . . , p, such that
âˆ’âˆ‡f (x0) =

iâˆˆI (x0)
uiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0).
If we choose ui = 0 for all i /âˆˆI (x0), the thesis follows.
â–¡
Gould and Tolle [5] showed that (6.3) is not only a sufï¬cient condition for the
existence of Karush-Kuhn-Tucker multipliers for (P5) but also necessary, in a certain
sense. More precisely, the pair (g, h) is said to be Lagrange regular at x0 âˆˆK5 if for
every differentiable objective function f that has a local constrained minimum at x0,
there exist vectors u âˆˆRm and v âˆˆRp such that (i), (ii), and (iii) of Theorem 6.3
hold. It is shown by Gould and Tolle [5] that (g, h) is Lagrange regular at x0 âˆˆK5 if
and only if condition (6.3) holds. See the next section. It must be observed that this
question has been previously treated, for a problem of the type (P4), but assuming
that the feasible set K4 is a convex set, by Arrow et al. [6].
Some authors (e.g. Avriel [7] and Forst and Hoffmann [8]) follow a slightly
different approach in obtaining Theorem 6.4 by assuming the Guignard-Gould-Tolle
constraint qualiï¬cation. We report their â€œstepsâ€ for the readerâ€™s convenience.
â€¢ Let x0 âˆˆK5; the cone
D<( f, x0) =

y âˆˆRn : âˆ‡f (x0)âŠ¤y < 0

is called the cone of descent directions of f at x0.
â€¢ For x0 âˆˆK5, it holds L(x0) âˆ©D<( f, x0) = âˆ…if and only if (i), (ii), and (iii) of
Theorem 6.4 hold.
Indeed, by deï¬nition of L(x0) and D<( f, x0), it holds that
y âˆˆL(x0) âˆ©D<( f, x0) â‡”
â§
â¨
â©
âˆ‡f (x0)âŠ¤y < 0,
âˆ‡gi(x0)âŠ¤y â‰¦0, âˆ€i âˆˆI (x0),
âˆ‡h j(x0)âŠ¤y = 0, âˆ€j = 1, . . . , p.
â‡”
â§
âªâªâ¨
âªâªâ©
âˆ‡f (x0)âŠ¤y < 0,
âˆ’âˆ‡gi(x0)âŠ¤y â‰§0, âˆ€i âˆˆI (x0),
âˆ’âˆ‡h j(x0)âŠ¤y â‰§0, âˆ€j = 1, . . . , p,
âˆ‡h j(x0)âŠ¤y â‰§0, âˆ€j = 1, . . . , p.
By Farkasâ€™s Theorem of the Alternative (Chap. 2), we have the following equiva-
lence:
L(x0) âˆ©D<( f, x0) = âˆ…if and only if there exist ui â‰§0, i âˆˆI (x0) and Î¼ j â‰§0,
w j â‰§0, j = 1, . . . , p, such that

6.1 First-Order Conditions
177
âˆ‡f (x0) =

iâˆˆI (x0)
ui(âˆ’âˆ‡gi(x0)) +
p

j=1
Î¼ j(âˆ’âˆ‡h j(x0)) +
p

j=1
w jâˆ‡h j(x0).
If we set ui = 0 for i /âˆˆI (x0) and v j = Î¼ j âˆ’w j, for j = 1, . . . , p, we obtain
that L(x0) âˆ©D<( f, x0) = âˆ…if and only if there exist ui â‰§0, i = 1, . . . , m, and
v j âˆˆR, j = 1, . . . , p, such that (i), (ii) and (iii) of Theorem 6.4 hold.
â€¢ We recall Theorem 4.24: if x0 âˆˆK5 is a local minimizer for (P5), then
âˆ’âˆ‡f (x0) âˆˆ(T (K5, x0))âˆ—.
â€¢ Assume the Guignard-Gould-Tolle constraint qualiï¬cation (6.3). Then, if x0 âˆˆK5
is a local minimizer for (P5), then the thesis of Theorem 6.4 holds. Indeed, from
âˆ’âˆ‡f (x0) âˆˆ(T (K5, x0))âˆ—, we have, by (6.3), âˆ’âˆ‡f (x0) âˆˆ(L(x0))âˆ—. Now
âˆ’âˆ‡f (x0) âˆˆ(L(x0))âˆ—â‡”L(x0) âˆ©D<( f, x0) = âˆ….
Indeed:
L(x0) âˆ©D<( f, x0) = âˆ…â‡”âˆ€y âˆˆL(x0) : âˆ‡f (x0)âŠ¤y â‰§0 â‡”âˆ’âˆ‡f (x0) âˆˆ(L(x0))âˆ—.
But L(x0) âˆ©D<( f, x0) = âˆ…is just equivalent to the thesis of Theorem 6.4.
â–¡
By introducing for (P5), the related Lagrangian function
L (x, u, v) = f (x) + uâŠ¤g(x) + vâŠ¤h(x),
we can rewrite the Karush-Kuhn-Tucker conditions of Theorem 6.4 in the following
form, which takes into account also the feasibility of the point x0:
âˆ‡xL (x0, u, v) = 0,
âˆ‡uL (x0, u, v) â‰¦0,
âˆ‡vL (x0, u, v) = 0,
u â‰§0, uâŠ¤âˆ‡uL (x0, u, v) = 0.
Remark 6.5 (a) Let us consider the following generalization of problem (P5) when
some of the variables are nonnegative:
â§
âªâªâ¨
âªâªâ©
min f (x, y)
subject to: gi(x, y) â‰¦0, i = 1, . . . , m,
h j(x, y) = 0, j = 1, . . . , p,
y â‰§0,

178
6
Constrained Optimization Problems with Mixed Constraints
where f, gi, i = 1, . . . , m, h j, j = 1, . . . , p, are real-valued functions deï¬ned on
the open set X âŠ‚Rn1 Ã— Rn2, f and every gi are differentiable on X and every h j is
continuously differentiable on X.
Let (x0, y0) be a local minimum point for the said problem and let some constraint
qualiï¬cation be veriï¬ed at (x0, y0). Then there exist multipliers u âˆˆRm and v âˆˆRp,
such that, with
L (x, y, u, v) = f (x, y) + uâŠ¤g(x, y) + vâŠ¤h(x, y),
we have
âˆ‡xL (x0, y0, u, v) = 0;
âˆ‡yL (x0, y0, u, v) â‰§0;
(y0)âŠ¤âˆ‡yL (x0, y0, u, v) = 0;
u â‰§0, uâŠ¤âˆ‡uL (x0, y0, u, v) = 0.
(b) Consider now a minimization problem
min f (x)
with linear afï¬ne constraints of the type
â§
âªâªâ¨
âªâªâ©
A11x1 + A12x2 + A13x3 â‰§b1;
A21x1 + A22x2 + A23x3 = b2;
A31x1 + A32x2 + A33x3 â‰¦b3,
x1 â‰§0, x2 âˆˆRn2, x3 â‰¦0.
with x j âˆˆRn j, bi âˆˆRmi and Ai j matrix of order (mi, n j), i, j = 1, 2, 3. Let
f (x1, x2, x3) be differentiable on an open set X âŠ‚Rn1+n2+n3 and let x0 = (x1, x2,
x3)âŠ¤be a constrained local minimum point for the above problem (as we shall see
in the next section, the constraint qualiï¬cations are automatically veriï¬ed in the case
of linear afï¬ne constraints). Then there exist multipliers ui âˆˆRmi, i = 1, 2, 3, such
that
x1 â‰§0, âˆ‡x1 f (x0) âˆ’(AâŠ¤
11u1 + AâŠ¤
21u2 + AâŠ¤
21u3) â‰§0;
âˆ‡x2 f (x0) âˆ’(AâŠ¤
12u1 + AâŠ¤
22u2 + AâŠ¤
32u3) = 0;
x3 â‰¦0, âˆ‡x3 f (x0) âˆ’(AâŠ¤
13u1 + AâŠ¤
23u2 + AâŠ¤
33u3) â‰¦0;
u1 â‰§0, (u1)âŠ¤(A11x1 + A12x2 + A13x3 âˆ’b1) = 0;
u3 â‰¦0, (u3)âŠ¤(A31x1 + A32x2 + A33x3 âˆ’b3) = 0.

6.1 First-Order Conditions
179
The classical (ï¬rst-order) sufï¬cient conditions for global optimality for problem
(P5) are due to Mangasarian [9].
Theorem 6.6 Let x0 âˆˆK5 be a point such that, for u âˆˆRm and v âˆˆRp, it holds
âˆ‡f (x0) +
m

i=1
uiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0) = 0,
uigi(x0) = 0, i = 1, . . . , m,
ui â‰§0, i = 1, . . . , m.
In other words, x0, u and v satisfy the Karush-Kuhn-Tucker conditions of Theorem
6.4. Let f be pseudoconvex on the open convex set X âŠ‚Rn, let every gi, i âˆˆI (x0), be
quasiconvex on X and let every h j, j = 1, . . . , p, be quasiconvex and quasiconcave
on X. Then x0 is a solution of (P5).
Proof It is the same proof as the one given in Theorem 5.10, by observing that
the equality constraints h j(x) = 0, j = 1, . . . , p, can be written as h j(x) â‰¦0 and
âˆ’h j(x) â‰¦0, j = 1, . . . , p, and that the negative of a quasiconvex function is a
quasiconcave function (and vice-versa).
â–¡
Remark 6.7 (a) In particular, if x0 âˆˆK5, u and v satisfy the Karush-Kuhn-Tucker
conditions in Theorem 6.4, f and every gi, i âˆˆI (x0) are convex on X and every h j,
j = 1, . . . , p is linear afï¬ne, then x0 is a solution of (P5). Indeed, by Theorem 3.26(i)
one has that f is pseudoconvex and by Theorem 3.26(i)â€“(ii), each gi, i âˆˆI (x0), is
quasiconvex.
(b) Instead of the ï¬rst relation of the Karush-Kuhn-Tucker conditions, in the
previous theorem, we can impose the more general condition (â€œmimimum principle-
type conditionâ€):
(x âˆ’x0)âŠ¤âˆ‡xL (x0, u, v) â‰§0, âˆ€x âˆˆK5.
(c) One of the ï¬rst works concerning functions that are both quasiconvex and
quasiconcave (it is used also the term â€œquasilinearâ€) is the pioneering paper of Arrow
et al. [6]. These authors prove the following characterization of quasilinear functions.
Let f : X âŠ‚Rn â†’R be deï¬ned on the convex set X. Its level set
lev=Î± f = {x : f (x) = Î±}
is called maximal (resp. minimal) level set if it is the set on which f (x) attains
its maximum (resp. its minimum). A set S âŠ‚Rn will be said to be bounded by
two noncrossing hyperplanes in X if there exist linear functions L1(x), L2(x), not
identically constant in X such that
S =

x âˆˆX : L1(x) â‰§0, L2(x) â‰¦0


180
6
Constrained Optimization Problems with Mixed Constraints
and
L1(x) < 0, L2(x) > 0, for no x âˆˆX.
Then f is both quasiconvex and quasiconcave (i.e. quasilinear) on the convex
set X if and only if every level set is not minimal nor maximal is bounded by two
noncrossing hyperplanes in X. See also Martos [10].
Obviously, if every h j, j = 1, . . . , p, is linear afï¬ne the assumptions of Theorem
6.6 are veriï¬ed. It can be proved that if f : X âŠ‚Rn â†’R is differentiable on the
open convex set X, then f is quasilinear on X if and only if
x, y âˆˆX, f (x) = f (y) â‡’(y âˆ’x)âŠ¤âˆ‡f (x) = 0.
Every monotone function f : R â†’R is quasilinear.
If we make use, in Theorem 6.6, of â€œmodiï¬edâ€ Karush-Kuhn-Tucker conditions,
for what regards the multipliers v j, j = 1, . . . , p, we can relax the quasilinearity
assumption on equality constraints h j, j = 1, . . . , p. The proof of the following
result is obvious.
Theorem 6.8 Let x0 âˆˆK5 be a point such that there exist multipliers u âˆˆRm and
v âˆˆRp such that
(i) âˆ‡f (x0) + m
i=1 uiâˆ‡gi(x0) + p
j=1 v jâˆ‡h j(x0) = 0;
(ii) uigi(x0) = 0, i = 1, . . . , m;
(iii) ui â‰§0, i = 1, . . . , m; v j â‰§0, j = 1, . . . , p.
Suppose that f is pseudoconvex on the open convex set X âŠ‚Rn and that every
gi, i âˆˆI (x0), and every h j, j = 1, . . . , p, is quasiconvex on X. Then x0 is a
solution of (P5).
If, in Theorem 6.6, we suppose that the constraint h j with a positive multiplier
v j is quasiconvex and the constraint hk with a negative multiplier vk is quasiconcave
(the constraint hs with a zero multiplier obviously can be any), again we obtain that
x0 âˆˆK5 solves (P5) if the Karush-Kuhn-Tucker conditions hold at x0.
It is also possible to obtain ï¬rst-order global sufï¬cient optimality conditions for
(P5) by means of Fritz John conditions (instead of Karush-Kuhn-Tucker conditions).
We need the following deï¬nition.
Deï¬nition 6.9 The function f : X âŠ‚Rn â†’R deï¬ned on the open convex set X is
said to be strictly pseudoconvex on X if, for every x, y âˆˆX with x Ì¸= y:
(y âˆ’x)âŠ¤âˆ‡f (x) â‰§0 â‡’f (y) âˆ’f (x) > 0
i.e.
f (y) âˆ’f (x) â‰¦0 â‡’(y âˆ’x)âŠ¤âˆ‡f (x) < 0.

6.1 First-Order Conditions
181
This class of generalized convex functions does not contain the class of differen-
tiable convex functions, but does contain the class of (differentiable) strictly convex
functions. Obviously, the class of strictly pseudoconvex functions is contained in the
class of pseudoconvex functions.
Theorem 6.10 Let in (P5) the objective function f be pseudoconvex on the open
convex set X âŠ‚Rn; let every gi, i âˆˆI (x0), and every h j, j = 1, . . . , p, be strictly
pseudoconvex on X; let x0 âˆˆK5 satisfy the following modiï¬ed Fritz John conditions:
(a) u0âˆ‡f (x0) + m
i=1 uiâˆ‡gi(x0) + p
j=1 v jâˆ‡h j(x0) = 0;
(b) uigi(x0) = 0, i = 1, . . . , m;
(c) (u0, u, v) â‰§0, (u0, u, v) Ì¸= 0.
Then x0 solves (P5).
Proof Owing to the complementary slackness conditions, relation (a) of the theorem
can be rewritten as
u0âˆ‡f (x0) +

iâˆˆI (x0)
uiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0) = 0.
Applying Gordanâ€™s theorem of the alternative (Chap. 2, p. 44) we have that there
does not exist any z âˆˆRn such that
â§
â¨
â©
zâŠ¤âˆ‡f (x0) < 0,
zâŠ¤âˆ‡gi(x0) < 0, i âˆˆI (x0),
zâŠ¤âˆ‡h j(x0) < 0, j = 1, . . . , p.
(6.4)
Therefore, the system
â§
â¨
â©
f (x) âˆ’f (x0) < 0,
gi(x) âˆ’gi(x0) â‰¦0, i âˆˆI (x0),
h j(x) âˆ’h j(x0) = 0, j = 1, . . . , p,
(6.5)
has no solution x âˆˆX. Indeed, if there did exist a solution Â¯x âˆˆX (Â¯x Ì¸= x0) then,
thanks to the assumptions,
f (Â¯x) âˆ’f (x0) < 0 â‡’(Â¯x âˆ’x0)âŠ¤âˆ‡f (x0) < 0
(by pseudoconvexity of f );
gi(Â¯x) âˆ’gi(x0) â‰¦0 â‡’(Â¯x âˆ’x0)âŠ¤âˆ‡gi(x0) < 0, âˆ€i âˆˆI (x0),
h j(Â¯x) âˆ’h j(x0) = 0 â‡’(Â¯x âˆ’x0)âŠ¤âˆ‡h j(x0) < 0, j = 1, . . . , p,
(by strict pseudoconvexity of g and h).

182
6
Constrained Optimization Problems with Mixed Constraints
But this violates (6.4), which has no solution z = Â¯x âˆ’x0. Recalling that gi(x0) =
0, i âˆˆI (x0), we have from (6.5) that
â§
âªâªâ¨
âªâªâ©
f (x) âˆ’f (x0) < 0,
gi(x) â‰¦0, i âˆˆI (x0),
gi(x) â‰¦0, i /âˆˆI (x0),
h j(x) = 0, j = 1, . . . , p
has no solution x âˆˆX. Hence, x0 is an optimal solution of problem (P5), being
x0 âˆˆK5.
â–¡
Remark 6.11 It is worthwhile to make the following considerations. Let be given
the problems
(P1) â‰¡(P5) : min f (x), subject to g(x) â‰¦0, h(x) = 0;
(P2) : min f (x), subject to g(x) â‰¦0, h(x) â‰¦0;
(P3) â‰¡(P4) : min f (x), subject to g(x) â‰¦0.
Let Si be the feasible set of (Pi), i = 1, 2, 3. Let Ci(x0) be a sufï¬cient condition
for x0 âˆˆSi to be a solution of (Pi), i = 1, 2, 3. Clearly
S1 âŠ‚S2 âŠ‚S3.
(6.6)
Then it follows trivially from (6.6) that
Ci(x0) and h(x0) = 0, i = 2, 3,
(6.7)
is a sufï¬cient condition for x0 to be an optimal solution of (P1). If Ci(x0) in (6.7) is
well known, then the sufï¬cient condition (6.7) requires no further investigation and
proof.
We give now a local ï¬rst-order sufï¬cient optimality condition, due to Fritz John,
for (P5), which works in absence of generalized convexity assumptions and also
for the â€œdegenerate caseâ€ of u0 = 0 (see the similar conditions for (P4) in Theorem
5.12).
Theorem 6.12 Let x0 âˆˆK5 be a point satisfying the Fritz John conditions:
u0âˆ‡f (x0) +
m

i=1
uiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0) = 0;
uigi(x0) = 0, i = 1, . . . , m;

6.1 First-Order Conditions
183
(u0, u1, . . . , um) â‰§0, v1, . . . , vp âˆˆR;
u0, u1, . . . , um, v1, . . . , vp, not all zero.
If the vectors
u0âˆ‡f (x0),

uiâˆ‡gi(x0)

iâˆˆI (x0) ,

âˆ‡h j(x0)
p
j=1
span Rn, i.e. the matrix formed by the above vectors has rank n, then x0 is a local
minimizer of (P5).
Proof Suppose that x0 is not a local minimizer of (P5). Then, there exists a feasible
sequence of points xk â†’x0 satisfying f (xk) < f (x0). Writing xk = x0 + tk yk,
with tk > 0,
yk = 1, we have
0 > f (x0 + tk yk) âˆ’f (x0) = tkâˆ‡f (x0)âŠ¤yk + o(tk),
0 â‰§gi(x0 + tk yk) = tkâˆ‡gi(x0)âŠ¤yk + o(tk), i âˆˆI (x0),
0 = h j(x0 + tk yk) = tkâˆ‡h j(x0)âŠ¤yk + o(tk), j = 1, . . . , p.
Since
yk = 1, we can assume, by taking a subsequence if necessary, that yk â†’
y, âˆ¥yâˆ¥= 1. Dividing both sides of all equalities and inequalities above by tk and
letting tk â†’0 gives âˆ‡f (x0)âŠ¤y â‰¦0, âˆ‡gi(x0)âŠ¤y â‰¦0, i âˆˆI (x0), and âˆ‡h j(x0)âŠ¤y =
0, j = 1, . . . , p.
Since
u0âˆ‡f (x0)âŠ¤y +

iâˆˆI (x0)
uiâˆ‡gi(x0)âŠ¤y +
p

j=1
v jâˆ‡h j(x0)âŠ¤y = 0
we have
u0âˆ‡f (x0)âŠ¤y = 0;
uiâˆ‡gi(x0)âŠ¤y = 0, i âˆˆI (x0);
âˆ‡h j(x0)âŠ¤y = 0, j = 1, . . . , p.
By virtue of our assumption on the gradient vectors, the vector y is orthogonal to
every vector in Rn. This implies y = 0, contradicting âˆ¥yâˆ¥= 1.
â–¡
Another ï¬rst-order sufï¬cient condition for the local optimality of x0 âˆˆK5 is given
in the following â€œprimalâ€ condition given by Still and Streng [11].
Theorem 6.13 Let x0 âˆˆK5 and suppose that there is no nonzero solution y âˆˆRn
to the system

184
6
Constrained Optimization Problems with Mixed Constraints
â§
â¨
â©
âˆ‡f (x0)âŠ¤y â‰¦0,
âˆ‡gi(x0)âŠ¤y â‰¦0, i âˆˆI (x0),
âˆ‡h j(x0)âŠ¤y = 0, j = 1, . . . , p,
then x0 is a strict local minimizer of order one for problem (P5), i.e. there exist N(x0)
and a number m > 0 such that
f (x) â‰§f (x0) + m
x âˆ’x0 , âˆ€x âˆˆK5 âˆ©N(x0).
A ï¬rst-order sufï¬cient condition for local optimality of x0 âˆˆK5, in terms of
â€œdualâ€ conditions is given by Hestenes [12], Theorem 7.2. See also Giorgi, JimÃ©nez
and Novo [13].
Theorem 6.14 Let x0 âˆˆK5 and suppose that x0 satisï¬es the Karush-Kuhn-Tucker
conditions of Theorem 6.4. Suppose further that there is no vector y Ì¸= 0, y âˆˆL(x0)
such that âˆ‡f (x0)âŠ¤y = 0. Then x0 is a strict local minimizer of order one for problem
(P5).
Proof We have previously proved that the inequality
âˆ‡f (x0)âŠ¤y â‰§0
holds for every y âˆˆL(x0) if and only if x0 satisï¬es the Karush-Kuhn-Tucker condi-
tions (it is a direct consequence of Farkasâ€™ theorem). In virtue of this assertion, our
hypotheses imply
âˆ‡f (x0)âŠ¤y > 0
for every y Ì¸= 0, y âˆˆL(x0). But being T (K5, x0) âŠ‚L(x0), we have therefore
âˆ‡f (x0)âŠ¤y > 0, âˆ€y Ì¸= 0, y âˆˆT (K5, x0).
By Theorem 4.25, this states that x0 is a strict local minimizer for (P5); more
exactly (Hestenes [12]), x0 is a strict local minimizer of order one for (P5).
â–¡
6.2
Constraint Qualiï¬cations
In this section, we review the most used constraint qualiï¬cations for problem (P5).
The Guignard-Gould-Tolle c. q., the Abadie c. q. and the Kuhn-Tucker c. q. seen in
the previous chapter are simply generalized to problem (P5). Let x0 âˆˆK5.
(1) Guignard-Gould-Tolle constraint qualiï¬cation. It is expressed as
(L(x0))âˆ—= (T (K5, x0))âˆ—
or, equivalently,

6.2 Constraint Qualiï¬cations
185
L(x0) = cl(conv(T (K5, x0))).
(2) Abadie constraint qualiï¬cation. It is expressed as
L(x0) = T (K5, x0).
We shall see in the present section that the Guignard-Gould-Tolle c. q. is, in a
certain sense, the weakest constraint qualiï¬cation for (P5). The following example
shows that the Guignard-Gould-Tolle c. q. may be strictly weaker than the Abadie
c. q.
Example 6.15 Consider the problem
â§
â¨
â©
min

(x1)2 + (x2)2
subject to: x1x2 = 0,
x1 â‰§0, x2 â‰§0.
The global minimizer is x0 = (0, 0)âŠ¤.
T (K5, x0) =

y âˆˆR2 : y1 â‰§0, y2 â‰§0, y1y2 = 0

âŠ‚L(x0) =

y âˆˆR2 : y1 â‰§0, y2 â‰§0

.
Hence, the Abadie c. q. is violated at x0. On the other hand, we have
(T (K5, x0))âˆ—=

y âˆˆR2 : y1 â‰¦0, y2 â‰¦0

= (L(x0))âˆ—
and hence the Guignard-Gould-Tolle c. q. is satisï¬ed at x0. Note, however, that the
Abadie c. q. (and hence the Guignard-Gould-Tolle c. q.) is satisï¬ed at any other
feasible point of the problem.
(3) Kuhn-Tucker constraint qualiï¬cation or Karush-Kuhn-Tucker constraint qual-
iï¬cation. It is expressed as
L(x0) = A(K5, x0).
For what said about the cones A(Â·, Â·) and T (Â·, Â·), we have obviously
Kuhn-Tucker c.q. â‡’Abadie c. q. â‡’Guignard-Gould-Tolle c. q.
(4) Mangasarian-Fromovitz constraint qualiï¬cation (MF c. q.). It is expressed as:
(i) The gradients âˆ‡h j(x0), j = 1, . . . , p, are linearly independent.
(ii) It holds Lo(x0) Ì¸= âˆ…, i.e. the system
	âˆ‡gi(x0)âŠ¤y < 0, i âˆˆI (x0),
âˆ‡h j(x0)âŠ¤y = 0, j = 1, . . . , p,
has a solution y âˆˆRn.

186
6
Constrained Optimization Problems with Mixed Constraints
This constraint qualiï¬cation can be also expressed in the following equivalent
form: The gradients âˆ‡h j(x0), j = 1, . . . , p, are linearly independent and L(x0) =
cl(Lo(x0)).
The Mangasarian-Fromovitz c. q. has also a â€œdualâ€ representation, given in the
following result.
Theorem 6.16 Let x0 âˆˆK5; then the Mangasarian-Fromovitz constraint qualiï¬ca-
tion is equivalent to the positive linear independence of the vectors

âˆ‡gi(x0), i âˆˆI (x0); âˆ‡h j(x0), j = 1, . . . , p

.
That is, the only solution of the linear system

iâˆˆI (x0)
uiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0) = 0, ui â‰§0, âˆ€i âˆˆI (x0),
is the zero vector.
Proof Let us suppose that the Mangasarian-Fromovitz c. q. is satisï¬ed. If the system
of Theorem 6.16 admits a solution with ui > 0 for some i âˆˆI (x0), by using the
theorem of the alternative of Motzkin (Theorem 2.31) we obtain at once a contra-
diction with the Mangasarian-Fromovitz c. q. Let us suppose that the linear system
in question admits a solution with ui = 0, for all i âˆˆI (x0), but v j Ì¸= 0 for some
j = 1, . . . , p. In this case, the gradients âˆ‡h j(x0), j = 1, . . . , p, are linearly depen-
dent, and again we obtain a contradiction with the Mangasarian-Fromovitz c. q.
Vice versa, let us suppose that the linear system of the theorem admits only the
zero solution. In particular, the system has no solution ui > 0 for some i âˆˆI (x0).
Again by using the theorem of Motzkin, we obtain that there exists y âˆˆRn that
satisï¬es the Mangasarian-Fromovitz c. q. Indeed, the vectors

âˆ‡h j(x0), j = 1, . . . , p

are linearly independent, as, if not, there would exist some v j Ì¸= 0 such that 0 =
p
j=1 v jâˆ‡h j(x0), against the assumption that the linear system of the theorem has
the zero solution only (by choosing ui = 0, âˆ€i âˆˆI (x0)).
â–¡
The Mangasarian-Fromovitz c. q. is also called No Nonzero Abnormal Multiplier
Constraint Qualiï¬cation or also Basic Constraint Qualiï¬cation. Note that in absence
of equality constraints, the Mangasarian-Fromovitz c. q. is equivalent to the Cottle
c. q. or Arrow-Hurwicz-Uzawa c. q., seen for (P4). The Mangasarian-Fromovitz
constraint qualiï¬cation is a stable constraint qualiï¬cation, in the following sense. If
this qualiï¬cation holds at x0 âˆˆK5, then there exists a neighborhood U(x0) such that
the same constraint qualiï¬cation holds at each x âˆˆU(x0) âˆ©K5.

6.2 Constraint Qualiï¬cations
187
We shall see in the sequel another important property of the Mangasarian-
Fromovitz c. q. For what previously said in Theorem 6.1 and in Remark 6.2, we
have the following implications:
Mangasarian-Fromovitz c.q. â‡’Kuhn-Tucker c. q.
â‡’Abadie c. q. â‡’Guignard-Gould-Tolle c.q.
For a more detailed proof of the above implications, the reader can see the paper
of Still and Streng [11].
Similarly to what done in Chap. 5 for problem (P4), we can relax the Mangasarian-
Fromovitz c. q. by introducing the second Abadie c. q. and the second Arrow-
Hurwicz-Uzawa c. q.
(5) Abadie constraint qualiï¬cation II. It is expressed as: the vectors âˆ‡h j(x0),
j = 1, . . . , p, are linearly independent and Lo
1(x0) Ì¸= âˆ…, where
Lo
1(x0) =
â§
â¨
â©
y âˆˆRn : âˆ‡gi(x0)âŠ¤y < 0, i âˆˆI (x0), gi is nonlinear;
âˆ‡gi(x0)âŠ¤y â‰¦0, i âˆˆI (x0), gi is linear afï¬ne;
âˆ‡h j(x0)âŠ¤y = 0, j = 1, . . . , p.
â«
â¬
â­.
(6)Arrow-Hurwicz-Uzawaconstraintqualiï¬cationII(AHUc.q.II).Itisexpressed
as: the vectors âˆ‡h j(x0), j = 1, . . . , p, are linearly independent and Lo
2(x0) Ì¸= âˆ…,
where, with X âŠ‚Rn open convex set,
Lo
2(x0) =
â§
â¨
â©
y âˆˆRn : âˆ‡gi(x0)âŠ¤y < 0, i âˆˆI (x0), gi is non-pseudoconcave on X;
âˆ‡gi(x0)âŠ¤y â‰¦0, i âˆˆI (x0), gi is pseudoconcave on X;
âˆ‡h j(x0)âŠ¤y = 0, j = 1, . . . , p.
â«
â¬
â­.
Obviously, if all functions gi, i âˆˆI (x0), are linear (afï¬ne), and the gradients
âˆ‡h j(x0), j = 1, . . . , p, are linearly independent, then the Abadie constraint quali-
ï¬cation II holds automatically and if all functions gi, i âˆˆI (x0), are pseudoconcave
and the gradients âˆ‡h j(x0), j = 1, . . . , p, are linearly independent, then the Arrow-
Hurwicz-Uzawa constraint qualiï¬cation II holds automatically.
We have the following implications.
MF c. q. â‡’Abadie c. q. II â‡’AHU c. q. II â‡’Kuhn-Tucker c. q.
(7) Slater constraint qualiï¬cation.
In its extended form it is expressed as: every gi, i âˆˆI (x0), is pseudoconvex
and every h j, j = 1, . . . , p, is quasilinear (i.e. quasiconvex and quasiconcave) on
the open convex set X âŠ‚Rn, the gradients âˆ‡h j(x0), j = 1, . . . , p, are linearly
independent and there exists Â¯x âˆˆK5 such that gi(Â¯x) < 0, i âˆˆI (x0), and h j(Â¯x) = 0,
j = 1, . . . , p.

188
6
Constrained Optimization Problems with Mixed Constraints
Theorem 6.17 The Slater c. q. implies the Mangasarian-Fromovitz c. q.
Proof Let y = Â¯x âˆ’x0. We only need to prove that it holds âˆ‡h j(x0)âŠ¤y = 0 for all
j = 1, . . . , p. For each h j(x) and all Î» âˆˆ[0, 1] , we have
h j(Î»Â¯x + (1 âˆ’Î»)x0) â‰¦max

h j(x0), h j(Â¯x)

= 0,
because h j(x) is quasiconvex. Note that h j(x) is also quasiconcave, hence
h j(Î»Â¯x + (1 âˆ’Î»)x0) â‰§min

h j(x0), h j(Â¯x)

= 0.
Consequently, h j(Î»Â¯x + (1 âˆ’Î»)x0) = 0. By the Taylorâ€™s expansion of h j(Î»Â¯x + (1 âˆ’
Î»)x0) at x0, we have
Î»âˆ‡h j(x0)âŠ¤y + o(Î») âˆ¥yâˆ¥= 0,
as Î» â†’0. Similarly to the proof of Theorem 5.17, we can prove that âˆ‡gi(x0)âŠ¤y < 0,
âˆ€i âˆˆI (x0). Therefore, y âˆˆLo(x0) and so Lo(x0) Ì¸= âˆ…. The Mangasarian-Fromovitz
c. q. is therefore satisï¬ed.
â–¡
Note that if in (P5) the constraints h j(x), j = 1, . . . , p, are linear afï¬ne, with
the gradients âˆ‡h1(x0), . . . , âˆ‡h p(x0) linearly dependent, we can always choose a
linearly independent subset of this set, say âˆ‡h1(x0), . . . , âˆ‡hk(x0), such that
span

âˆ‡h1(x0), . . . , âˆ‡hk(x0)

= span

âˆ‡h1(x0), . . . , âˆ‡h p(x0)

.
Moreover, keeping only the constraints h1, . . . , hk in the formulation of (P5),
does not change its feasible set. Thatâ€™s why some authors (e.g. Bazaraa and Shetty
[14]) formulate the extended Slater c. q. for (P5), by assuming that the functions h j,
j = 1, . . . , p, are linear afï¬ne, without mentioning the linear independence of their
gradients. Therefore, we can assert that if in (P5) all functions gi, i âˆˆI (x0), and
all functions h j, j = 1, . . . , p, are linear afï¬ne, the problem is automatically qual-
iï¬ed. Again, for a Linear Programming Problem, with both inequality and equality
constraints, no constraint qualiï¬cation is needed.
(8) Linear Independence constraint qualiï¬cation (LI c. q.). It is expressed as: the
gradients

âˆ‡gi(x0), i âˆˆI (x0); âˆ‡h j(x0), j = 1, . . . , p

are linearly independent.
Owing to the â€œdualâ€ characterization of the Mangasarian-Fromovitz c. q. (Theo-
rem 6.16), we have the following implication:
LI c. q. â‡’MF c. q. .
(9) Constant Rank constraint qualiï¬cation (CR c.q.). It was introduced by Janin
[15] and is expressed as follows: there exists a neighborhood N(x0) of x0 âˆˆK5

6.2 Constraint Qualiï¬cations
189
such that for every pair of subsets I1(x0) âŠ‚I (x0) and J1 âŠ‚{1, . . . , p} , the set of
gradients

âˆ‡gi(x), i âˆˆI1(x0); âˆ‡h j(x), j âˆˆJ1

has the same rank for all x âˆˆN(x0) âˆ©K5.
It appears that the rank in question depends on the choice of I1(x0) and J1 but
not on the point x âˆˆN(x0) âˆ©K5. Clearly, the Linear Independence c. q. implies the
Constant Rank c. q. Linearity of all constraints of (P5) also implies the Constant Rank
c. q. The constant Rank c. q. is indeed a constraint qualiï¬cation: Janin [15] proved
that this constraint qualiï¬cation implies the Abadie c. q. However, the Constant Rank
c. q. is neither weaker nor stronger than the Mangasarian-Fromovitz c. q.
Note also that, unlike the Mangasarian-Fromovitz c. q., if the Constant Rank c. q.
holds at x0 âˆˆK5, it will continue to hold if any of the equality constraints h j(x) = 0
were to be replaced by the two inequalities h j(x) â‰¦0 and âˆ’h j(x) â‰¦0.
(10) Constant Positive Linear Dependence constraint qualiï¬cation (CPLD c. q.).
It was introduced by Qi and Wei [16] and is expressed as follows: there exists a
neighborhood N(x0) of x0 âˆˆK5 such that whenever for some index set I1(x0) âŠ‚
I (x0) and J1 âŠ‚{1, . . . , p} , the system

iâˆˆI1(x0)
uiâˆ‡gi(x0) +

jâˆˆJ1
v jâˆ‡h j(x0) = 0, ui â‰§0, âˆ€i âˆˆI1(x0),
has a nonzero solution, the set

âˆ‡gi(x), i âˆˆI1(x0)

âˆª

âˆ‡h j(x), j âˆˆJ1

is linearly dependent for all x âˆˆN(x0).
Comparing the dual form (Theorem 6.16) of the Mangasarian-Fromovitz c. q.
with the above constraint qualiï¬cation, it is immediate that
MF c. q. â‡’CPLD c. q. .
It can be proved that the Constant Positive Linear Dependence c. q. is indeed a
constraint qualiï¬cation, as it implies the Abadie c. q. (Andreani et al. [17]). It can be
also proved that CPLD c. q. is weaker than the Constant Rank c. q. Hence,
LI c. q. â‡’CR c. q. â‡’CPLD c. q. â‡’Abadie c. q.
and
LI c. q. â‡’MF c. q. â‡’CPLD c. q. â‡’Abadie c. q. .
The Mangasarian-Fromovitz constraint qualiï¬cation is a necessary and sufï¬cient
conditioninorderthatthesetofKarush-Kuhn-Tuckermultipliersfor(P5)at x0 âˆˆK5,
is a closed and bounded set. This result is due to Gauvin [18]. Let us denote by M(x0)

190
6
Constrained Optimization Problems with Mixed Constraints
the set of Karush-Kuhn-Tucker multipliers for (P5):
M(x0) =
	
(u, v) âˆˆRm Ã— Rp : âˆ‡xL (x0, u, v) = 0;
uigi(x0) = 0, i = 1, . . . , m; ui â‰§0, i = 1, . . . , m

.
We have the following result.
Theorem 6.18 Let x0 âˆˆK5 and let M(x0) Ì¸= âˆ…. Then M(x0) is closed and bounded
(more precisely: a compact convex polyhedron, i.e. a polytope) if and only if the
Mangasarian-Fromovitz c. q. holds at x0.
Proof Let us ï¬rst suppose that the Mangasarian-Fromovitz c. q. is satisï¬ed at x0.
As the set of multipliers is a polyhedron, it is closed and convex. It remains to prove
that M(x0) is bounded. Let us suppose absurdly that M(x0) is not bounded, i.e.
there exists a sequence

(uk, vk)

âŠ‚R|I (x0|
+
Ã— Rp such that
(uk, vk)

â†’âˆfor
k â†’âˆ, and that for every k
âˆ’âˆ‡f (x0) =

iâˆˆI (x0)
uk
i âˆ‡gi(x0) +
p

j=1
vk
jâˆ‡h j(x0).
By choosing, if necessary, a subsequence, we can assume that
(uk, vk)
(uk, vk)
 â†’(u, v) âˆˆ

R|I (x0|
+
Ã— Rp
\ {0} .
If we divide both members of the last equality by
(uk, vk)
 and take the limit
for k â†’âˆ, we get
0 =

iâˆˆI (x0)
uiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0).
But this relation contradicts the dual characterization of the Mangasarian-
Fromovitz constraint qualiï¬cation (Theorem 6.16).
Now, suppose that M(x0) is bounded. If the Mangasarian-Fromovitz c. q. is not
satisï¬ed, thanks to Theorem 6.16, there will exist a nonzero vector (u, v) âˆˆM(x0),
(u, v) âˆˆR|I (x0|
+
Ã— Rp, such that

iâˆˆI (x0)
uiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0) = 0.
Let (Ë†u, Ë†v) âˆˆM(x0). In particular, it will hold

6.2 Constraint Qualiï¬cations
191
âˆ’âˆ‡f (x0) =

iâˆˆI (x0)
Ë†uiâˆ‡gi(x0) +
p

j=1
Ë†v jâˆ‡h j(x0).
For every Î± âˆˆR+, we have Ë†u + Î±u â‰§0 and
âˆ’âˆ‡f (x0) =

iâˆˆI (x0)
(Ë†ui + Î±ui)âˆ‡gi(x0) +
p

j=1
(Ë†v j + Î±v j)âˆ‡h j(x0).
In other words, the multipliers vector (Ë†u + Î±u, Ë†v + Î±v) is a Karush-Kuhn-Tucker
multipliers vector. Being (u, v) Ì¸= 0, if we choose Î± > 0 and arbitrarily large, we
get that M(x0) is not bounded, in contradiction with our assumption.
â–¡
Another question related to a â€œmodiï¬edâ€ Mangasarian-Fromovitz c. q. is the
uniqueness of Karush-Kuhn-Tucker multipliers for an optimal solution x0 âˆˆK5. In
other words: when M(x0) is a singleton? The question has been solved by Kyparisis
[19] who introduced what he calls the Strict Mangasarian-Fromovitz c. q.
The Strict Mangasarian-Fromovitz constraint qualiï¬cation (Strict MF c. q.) holds
at x0 âˆˆK5 if, denoting by I +(x0, u) the set of strictly active inequality constraints
at x0, i.e.
I +(x0, u) =

i : i âˆˆI (x0) and ui > 0 for (u, v) âˆˆM(x0)

,
it holds:
(i) The gradients
âˆ‡gi(x0), i âˆˆI +(x0, u); âˆ‡h j(x0), j = 1, . . . , p,
are linearly independent.
(ii) The system
âˆ‡gi(x0)âŠ¤y < 0, i âˆˆI (x0) \ I +(x0, u);
âˆ‡gi(x0)âŠ¤y = 0, i âˆˆI +(x0, u);
âˆ‡h j(x0)âŠ¤y = 0, j = 1, . . . , p,
has a solution y âˆˆRn.
Obviously, we have
Linear Independence c. q. â‡’Strict MF c. q. â‡’MF c q. .
We note however that the Strict Mangasarian-Fromovitz c. q. is not properly a
constraint qualiï¬cation, as it involves the sign of the multipliers in its deï¬nition.
Usually, these multipliers depend also on the objective function and not only on the

192
6
Constrained Optimization Problems with Mixed Constraints
constraints. Perhaps a better name would be â€œStrict Mangasarian-Fromovitz regular-
ity conditionâ€.
Similarly to what holds for the Mangasarian-Fromovitz c. q., we have the follow-
ing â€œdualâ€ characterization of the Strict Mangasarian-Fromovitz c. q. For brevity, in
the summation symbols, we denote I +(x0, u) by I + and I (x0) \ I +(x0, u) by I 0.
Theorem 6.19 The Strict Mangasarian-Fromovitz c. q. holds at x0 âˆˆK5 if and only
if there exist no vector (s, t, v) Ì¸= 0, s = {si} , i âˆˆI 0, s â‰§0, such that

iâˆˆI 0
siâˆ‡gi(x0) +

iâˆˆI +
tiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0) = 0.
(6.8)
Proof We rewrite as follows the Strict Mangasarian-Fromovitz c. q.:
(a) The gradients
âˆ‡gi(x0), i âˆˆI +(x0, u); âˆ‡h j(x0), j = 1, . . . , p
are linearly independent.
(b) (By Motzkinâ€™s theorem) there is no vector (s, t, v), s â‰§0, s Ì¸= 0, such that

iâˆˆI 0
siâˆ‡gi(x0) +

iâˆˆI +
tiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0) = 0.
We now show the equivalence between (6.8) and (a) and (b). Assume absurdly that
there exists a multipliers vector (s, t, v) Ì¸= 0, with s â‰§0, such that (6.8) holds. We
have two cases:
(i) s Ì¸= 0; but this is in contradiction with (b).
(ii) s = 0; then it holds (t, v) Ì¸= 0, but this is in contradiction with (a).
Conversely, let us absurdly suppose that
âˆ‡gi(x0), i âˆˆI +(x0, u); âˆ‡h j(x0), j = 1, . . . , p
are linearly dependent, i.e. there exist multipliers vectors (t, v) Ì¸= 0 such that

iâˆˆI +
tiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0) = 0.
If we set s = 0, then there exists (s, t, v) Ì¸= 0 such that

iâˆˆI 0
siâˆ‡gi(x0) +

iâˆˆI +
tiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0) = 0.

6.2 Constraint Qualiï¬cations
193
But this contradicts the assumptions on relation (6.8).
â–¡
Theorem 6.20 The set M(x0) of Karush-Kuhn-Tucker multipliers associated to the
optimal point x0 âˆˆK5 is a singleton if and only if the Strict Mangasarian-Fromovitz
c. q. is satisï¬ed at x0.
Proof Let us suppose that the Strict Mangasarian-Fromovitz c. q. is satisï¬ed. Let
(Â¯u, Â¯v) âˆˆM(x0) be a pair of Karush-Kuhn-Tucker multipliers vectors, and let, as
usual,
I +(x0, Â¯u) =

i âˆˆI (x0) : Â¯ui > 0

;
I 0 = I (x0) \ I +(x0, Â¯u).
If there exists another pair (Ë†u, Ë†v) âˆˆM(x0), with (Ë†u, Ë†v) Ì¸= (Â¯u, Â¯v), then

iâˆˆI (x0)
(Ë†ui âˆ’Â¯ui)âˆ‡gi(x0) +
p

j=1
(Ë†v j âˆ’Â¯v j)âˆ‡h j(x0) = 0,
with (Ë†ui âˆ’Â¯ui; Ë†v j âˆ’Â¯v j) Ì¸= 0 and Ë†ui âˆ’Â¯ui = Ë†ui â‰§0 for i âˆˆI 0. But this contradicts
the validity of the Strict Mangasarian-Fromovitz c. q., on the grounds of Theorem
6.19.
Conversely, if (Â¯u, Â¯v) is the unique pair in M(x0), it is easy to verify that there
does not exist a nonzero solution of relation (6.8), which is equivalent to say that the
Strict Mangasarian-Fromovitz c. q. is satisï¬ed.
â–¡
Another question related to the set M(x0) of Karush-Kuhn-Tucker multipliers is
the following one: obviously M(x0) depends a priori on the point x0 âˆˆK5. When
M(x0) is independent of the choice of x0? If (P5) is a convex problem, in the sense
speciï¬ed by the next deï¬nition, then the set M(x0) does not depend on the minimum
point x0.
Deï¬nition 6.21 Problem (P5) is a convex problem if f : X â†’R and every gi :
X â†’R, i = 1, . . . , m, are convex functions on the open convex set X âŠ‚Rn and
every h j : Rn â†’R, j = 1, . . . , p, is a linear afï¬ne function.
Theorem 6.22 Let (P5) be a convex problem. The set M(x0) is the same for all
minimum points of f on K5.
Proof Clearly K5 is a convex set. Let x1, x2 âˆˆK5 be two minimum points of f on K5
and let M(x1) and M(x2) be the two related sets of Karush-Kuhn-Tucker multipliers.
Let us verify that M(x1) = M(x2). According to the fact that these points are global
minimum points ( f is convex) one has f (x1) = f (x2). Let (u, v) âˆˆM(x1). Then
âˆ‡f (x1) +
m

i=1
uiâˆ‡gi(x1) +
p

j=1
v jâˆ‡h j(x1) = 0,

194
6
Constrained Optimization Problems with Mixed Constraints
with ui â‰§0, uigi(x1) = 0, for every i = 1, . . . , m. The convex Lagrangian function
L (Â·, u, v) is minimized at x1 on X, therefore L (x2, u, v) â‰§L (x1, u, v), which
implies
f (x2) +
m

i=1
uigi(x2) â‰§f (x1) = f (x2).
Taking into account the signs of the multipliers ui and of gi(x2), we have that
uigi(x2) = 0 for every i = 1, . . . , m. From
L (x2, u, v) = f (x2) = f (x1) = L (x1, u, v)
we get that x2 is a minimum point for the convex function L (Â·, u, v) on X. Hence,
âˆ‡f (x2) +
m

i=1
uiâˆ‡gi(x2) +
p

j=1
v jâˆ‡h j(x2) = 0.
We have that (u, v) âˆˆM(x2). The inclusion M(x1) âŠ‚M(x2) is therefore proved.
The converse inclusion follows by exchanging x1 and x2 in the above proof.
â–¡
We have previously asserted that if the Guignard-Gould-Tolle constraint qualiï¬-
cation holds, i.e.
(T (K5, x0))âˆ—= (L(x0))âˆ—
(6.9)
then, any differentiable objective function f having a local minimum over K5 at x0
satisï¬es the Karush-Kuhn-Tucker conditions at x0:
âˆ‡f (x0) +

iâˆˆI (x0)
uiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0) = 0, ui â‰§0, âˆ€i âˆˆI (x0).
(6.10)
We have also, more than one time, asserted that (6.9) is, in a certain sense, the
weakest constraint qualiï¬cation that guarantees that the above Karush-Kuhn-Tucker
conditions will hold at a minimizer x0. In order to be more precise, we introduce the
following deï¬nition, due to Gould and Tolle [5], but anticipated for problem (P4) by
Arrow et al. [6].
Deï¬nition 6.23 The pair (g, h) of problem (P5) is said to be Lagrange regular
at x0 âˆˆK5 if and only if for every objective function f, with a constrained local
minimum at x0, the Karush-Kuhn-Tucker conditions hold at x0.
Gould and Tolle [5] show that the pair (g, h) is Lagrange regular at x0 âˆˆK5 if
and only if the Guignard-Gould. Tolle c. q. (6.9) holds. In other words, for any given
objective function f (x) with a local minimum over K5 at x0, if the Karush-Kuhn-
Tucker conditions (6.10) hold, we can claim that (6.9) holds.

6.2 Constraint Qualiï¬cations
195
Theorem 6.24 Let x0 âˆˆK5. Then the constraint qualiï¬cation (T (K5, x0))âˆ—=
(L(x0))âˆ—is equivalent to the fact that the pair (g, h) is Lagrange regular at x0.
Proof To prove the above theorem we only need to show that (T (K5, x0))âˆ—âŠ‚
(L(x0))âˆ—, since the converse inclusion is always true. We will show that for each
y âˆˆ(T (K5, x0))âˆ—there corresponds an objective function f which is differentiable
at x0 and has a local minimum over K5 at x0 with the property that y = âˆ’âˆ‡f (x0).
But from the Karush-Kuhn-Tucker conditions we have
âˆ’âˆ‡f (x0) =

iâˆˆI (x0)
uiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0),
where ui â‰§0, âˆ€i âˆˆI (x0). Hence, y âˆˆ(L(x0))âˆ—.
We follow closely the proof of Haeser and Ramos [20] who amend some minor
inaccuracies of the original proof of Gould and Tolle. Another proof is given by
Bazaraa and Shetty [14].
Then, let y Ì¸= 0, y âˆˆ(T (K5, x0))âˆ—. The Lagrange regularity assumption implies
y âˆˆ(L(x0))âˆ—. Let us deï¬ne Ck, k â‰§1, a cone of nonzero directions which form
with y an angle between 0 and Ï€
2 âˆ’
Ï€
k+3. Then, for every k â‰§1 there exists Ë†Îµk > 0,
such that K5 âˆ©N(x0, Ë†Îµk) âŠ‚Rn \ Ck. Indeed, if there would exist k such that xâ„“âˆˆ
Ck âˆ©K5, xâ„“â†’x0, then
yâŠ¤xâ„“
xâ„“ â‰§âˆ¥yâˆ¥cos
Ï€
2 âˆ’
Ï€
k + 3

> 0.
Taking the limit in â„“for a subsequence, we would have yâŠ¤d > 0, with d âˆˆ
T (K5, x0), which contradicts the fact that y âˆˆ(T (K5, x0))âˆ—.
Let us deï¬ne Îµ1 = min(Ë†Îµ1, 1) and Îµk = min(Ë†Îµk, Îµkâˆ’1
2 ), k > 1. Let us assume, with-
out loss of generality, that x0 = 0 and y = (0, . . . , 0, 1)âŠ¤; moreover, let us deï¬ne
P : Rnâˆ’1 â†’R in a subspace orthogonal to y, in the following way:
P(z) =
â§
âªâªâ¨
âªâªâ©
0,
if z = 0,
tan
 Ï€
3

,
if âˆ¥zâˆ¥â‰§Îµ2,
tan

Ï€
k+2

Îµk+1 +
tan

Ï€
k+1

Îµkâˆ’tan

Ï€
k+2

Îµk+1
Îµkâˆ’Îµk+1
Â· (âˆ¥zâˆ¥âˆ’Îµk+1), if Îµk+1 â‰¦âˆ¥zâˆ¥â‰¦Îµk.
We remark that P is piecewise linear and continuous. Moreover, for Îµk+1 â‰¦âˆ¥zâˆ¥â‰¦
Îµk, we have
tan

Ï€
k + 2

âˆ¥zâˆ¥â‰¦P(z) â‰¦tan

Ï€
k + 1

âˆ¥zâˆ¥.
This fact is a geometric property of afï¬ne and increasing functions which have
a negative value at the origin. It shows that P is differentiable at the origin, with
âˆ‡P(0) = 0. Let now be f : Rn â†’R deï¬ned by f (d) = P(z) âˆ’yâŠ¤d, where d =
(z, w) âˆˆRnâˆ’1 Ã— R and let us prove that f has a local minimum over K5 at x0 = 0.

196
6
Constrained Optimization Problems with Mixed Constraints
Letbed = (z, w) Ì¸= (0, 0) âˆˆRnâˆ’1 Ã— R,withd âˆˆK5 âˆ©N(0, Îµ3).As y = (0, . . . ,
0, 1)âŠ¤and P(0) = 0, it is sufï¬cient to show that w < P(z). If z = 0, in case w > 0
we would have that d is a positive multiple of y âˆˆ(T (K5, x0))âˆ—, which contradicts
the fact that d âˆˆK5. Hence, w < 0 = P(z). being z Ì¸= 0 there exists k â‰§2 such
that Îµk+1 â‰¦âˆ¥zâˆ¥â‰¦Îµk. Therefore, P(z) â‰¦âˆ¥zâˆ¥tan
 Ï€
k+2

. Note that d /âˆˆCr is equiv-
alent to say that w < tan
 Ï€
r+3
 âˆ¥zâˆ¥. Being d âˆˆK5 âˆ©N(0, Îµ3) âŠ‚Rn \ C3, we have
w < tan
 Ï€
3+3
 âˆ¥zâˆ¥< âˆ¥zâˆ¥. Assuming w > 0, as in the opposite case the result is
trivially veriï¬ed, we have
âˆ¥dâˆ¥=

âˆ¥zâˆ¥2 + |w|2 <
âˆš
2 âˆ¥zâˆ¥< 2Îµk â‰¦Îµkâˆ’1.
Hence, d âˆˆK5 âˆ©N(0, Îµkâˆ’1) âŠ‚Rn \ Ckâˆ’1. Being d Ì¸= Ckâˆ’1, we have w < tan

Ï€
kâˆ’1+3
 âˆ¥zâˆ¥. It follows that w < P(z). Being f (0) = 0 and f (d) > 0 for d Ì¸=
0 âˆˆK5 sufï¬ciently small, it follows from the assumptions that x0 = 0 satisï¬es the
Karush-Kuhn-Tucker conditions, i.e. y = âˆ’âˆ‡f (0) âˆˆ(L(x0))âˆ—.
â–¡
We wish to stress that the Lagrange regularity of (g, h) of problem (P5) is intended
with regard to all differentiable objective functions having at x0 âˆˆK5 a local mini-
mum point. It is therefore possible to ï¬nd examples where the Guignard-Gould-Tolle
constraint qualiï¬cation does not hold, yet the Karush-Kuhn-Tucker conditions hold
at an optimal point x0 of f over K5.
Example 6.25 Let us consider the problem
	
min x2
subject to: (x1)2 âˆ’x2 â‰¦0; x2 â‰¦0.
The point x0 = (0, 0) is a global minimum point of f over the feasible set, the
Guignard-Gould-Tolle c. q. is not satisï¬ed at x0, but at x0 the Karush-Kuhn-Tucker
conditions hold.
Following Forst and Hoffmann [8], further insights on the Karush-Kuhn-Tucker
conditions and on the Guignard-Gould-Tolle c. q. can be obtained by â€œlinearizingâ€
problem (P5). Let us consider the following linearized version of (P5).
(P5)L :
â§
â¨
â©
min f (x0) + âˆ‡f (x0)âŠ¤(x âˆ’x0)
subject to: gi(x0) + âˆ‡gi(x0)âŠ¤(x âˆ’x0) â‰¦0, i = 1, . . . , m,
h j(x0) + âˆ‡h j(x0)âŠ¤(x âˆ’x0) = 0, j = 1, . . . , p.
The feasible set of (P5)L will be denoted by (K5)L. If a local minimizer x0 of
(P5) also solves (P5)L, then the Karush-Kuhn-Tucker conditions for (P5)L are met
and hence also for (P5) since the gradients that occur are the same in both problems.
The following example, due to Forst and Hoffmann, shows that the converse of the
above assertion is not true.

6.2 Constraint Qualiï¬cations
197
Example 6.26 Let us consider the problem, with x = (x1, x2) âˆˆR2:
â§
â¨
â©
min x1
subject to: âˆ’(x1)3 + x2 â‰¦0,
âˆ’x2 â‰¦0.
It is seen that x0 = (0, 0)âŠ¤yields the global minimum for the problem. The related
linearized problem is
â§
â¨
â©
min x1
subject to: x2 â‰¦0,
âˆ’x2 â‰¦0,
with feasible set KL =

x âˆˆR2 : x2 = 0

. The linearized objective function x1 is
not even bounded from below on KL.
We can rewrite problem (P5)L by removing the value f (x0) and by using only
the set of the active inequalities at x0, i.e.
(P5(I (x0))L :
â§
â¨
â©
min âˆ‡f (x0)âŠ¤(x âˆ’x0)
subject to: âˆ‡gi(x0)âŠ¤(x âˆ’x0) â‰¦0, i âˆˆI (x0),
âˆ‡h j(x0)âŠ¤(x âˆ’x0) = 0, j = 1, . . . , p,
being of course h j(x0) = 0, j = 1, . . . , p.
Lemma 6.27 Let x0 âˆˆK5; then x0 is a solution of (P5)L if and only if x0 is a solution
of (P5(I (x0))L.
Proof Let us denote by (K5(I (x0)))L the feasible set of (P5(I (x0))L. If x0 is a
solution of (P5(I (x0))L, then âˆ‡f (x0)âŠ¤(x âˆ’x0) â‰§0 holds for x âˆˆ(K5(I (x0)))L.
Since x0 âˆˆ(K5)L âŠ‚(K5(I (x0)))L, x0 is also a solution of (P5)L.
If conversely x0 is a minimizer of (P5)L, then f (x0) + âˆ‡f (x0)âŠ¤(x âˆ’x0) â‰§
f (x0), hence âˆ‡f (x0)âŠ¤(x âˆ’x0) â‰§0 holds for x âˆˆ(K5)L. Let x âˆˆ(K5(I (x0)))L;
we consider the vector
u(t) = x0 + t(x âˆ’x0)
with t > 0. It holds that
âˆ‡h j(x0)âŠ¤(u(t) âˆ’x0) = tâˆ‡h j(x0)âŠ¤(x âˆ’x0) = 0, j = 1, . . . , p,
and for i âˆˆI (x0),
âˆ‡gi(x0)âŠ¤(u(t) âˆ’x0) = tâˆ‡gi(x0)âŠ¤(x âˆ’x0) â‰¦0.
For i /âˆˆI (x0) we have gi(x0) < 0 and thus for t sufï¬ciently small
gi(x0) + âˆ‡gi(x0)âŠ¤(u(t) âˆ’x0) = gi(x0) + tâˆ‡gi(x0)âŠ¤(x âˆ’x0) < 0.

198
6
Constrained Optimization Problems with Mixed Constraints
Hence, for such t the vector u(t) is in (K5)L, consequently
f (x0) + âˆ‡f (x0)âŠ¤(u(t) âˆ’x0) â‰§f (x0)
and thus
tâˆ‡f (x0)âŠ¤(x âˆ’x0) = âˆ‡f (x0)âŠ¤(u(t) âˆ’x0) â‰§0,
hence âˆ‡f (x0)âŠ¤(x âˆ’x0) â‰§0. Since we have chosen x âˆˆ(K5(I (x0)))L arbitrary, x0
yields a solution to (P5(I (x0))L.
â–¡
With the transformation d = x âˆ’x0 we obtain the following formulation of prob-
lem (P5(I (x0))L:
(P5(d))L :
â§
â¨
â©
min âˆ‡f (x0)âŠ¤d
subject to: âˆ‡gi(x0)âŠ¤d â‰¦0, i âˆˆI (x0),
âˆ‡h j(x0)âŠ¤d = 0, j = 1, . . . , p.
Lemma 6.28 Let x0 âˆˆK5; then x0 is a solution of (P5)L if and only if 0 âˆˆRn is a
solution of (P5(d))L.
Proof Obviously, on the grounds of Lemma 6.27.
â–¡
We remark that the feasible set of (P5(d))L is the linearizing cone L(x0) of (P5)
at x0 âˆˆK5.
The following proposition clariï¬es the role of the various linearized problems
with respect to the Karush-Kuhn-Tucker conditions for (P5). Let x0 âˆˆK5; we recall
that the cone
D<( f, x0) =

d âˆˆRn : âˆ‡f (x0)âŠ¤d < 0

is the cone of descent directions of f at x0, already considered in the present section
when we discussed how to obtain the Karush-Kuhn-Tucker conditions from the
Guignard-Gould-Tolle constraint qualiï¬cation.
Theorem 6.29 Let x0 âˆˆK5; then the following assertions are equivalent:
(a) x0 is a solution of (P5)L.
(b) x0 is a solution of (P5(I (x0)))L.
(c) 0 âˆˆRn is a solution of (P5(d))L.
(d) âˆ’âˆ‡f (x0) âˆˆ(L(x0))âˆ—.
(e) L(x0) âˆ©D<( f, x0) = âˆ….
(f) The Karush-Kuhn-Tucker conditions hold at x0.
The equivalence of the previous assertions has already been proved in the present
section.
We recall once more that if x0 âˆˆK5 is a local solution of (P5), then
âˆ’âˆ‡f (x0) âˆˆ(T (K5, x0))âˆ—,

6.2 Constraint Qualiï¬cations
199
being, moreover, T (K5, x0) âŠ‚L(x0), i.e. (L(x0))âˆ—âŠ‚(T (K5, x0))âˆ—. Therefore, if it
holds
(L(x0))âˆ—= (T (K5, x0))âˆ—,
i.e. the Guignard-Gould-Tolle c. q. holds at x0, then the Karush-Kuhn-Tucker con-
ditions hold at x0 (points (d) and (f ) of the previous theorem).
We conclude this section with a couple of examples.
Example 6.30 Consider the problem
min
	1
2((x1)2 + (x2)2)

subject to: (x1 âˆ’1)2 + (x2)2 âˆ’1
4 â‰¦0;
x1 + x2 âˆ’1 = 0.
The feasible set is given by the segment with end points A and B, with respective
coordinates

1 âˆ’
1
2
âˆš
2
,
1
2
âˆš
2

;

1 +
1
2
âˆš
2
, âˆ’1
2
âˆš
2

.
It is seen that, in all interior points of the said segment, only the equality constraint
is active and it holds âˆ‡h(x) = [1, 1]âŠ¤. At the end points of the segment, A and B,
both constraints are active and the independence constraint qualiï¬cation is satisï¬ed.
We have
L (x1, x2, u1, v1) = 1
2((x1)2 + (x2)2) + u1

(x1 âˆ’1)2 + (x2)2 âˆ’1
4

+ v1(x1 + x2 âˆ’1).
The Karush-Kuhn-Tucker conditions are
x1 âˆ’2u1(x1 âˆ’1) + v1 = 0;
x2 + 2u1x2 + v1 = 0;
u1

(x1 âˆ’1)2 + (x2)2 âˆ’1
4

= 0;
u1 â‰§0,
and the feasibility conditions are
x1 + x2 âˆ’1 = 0;
(x1 âˆ’1)2 + (x2)2 âˆ’1
4 â‰¦0.

200
6
Constrained Optimization Problems with Mixed Constraints
The case u1 = 0 is excluded, as it leads to the relation x1 = x2 = 1
2, which contra-
dicts the inequality constraint. Let therefore be u1 > 0. We obtain the two solutions
x1 = 1 âˆ“
1
2
âˆš
2
,
x2 = 1 Â±
1
2
âˆš
2
,
with multipliers
u1 = âˆ’1 Â±
âˆš
2
2
,
v1 = 1
2.
The multiplier âˆ’1âˆ’
âˆš
2
2
is negative and therefore must be rejected. Therefore, we
have the solutions
x1 = 1 âˆ’
1
2
âˆš
2
;
x2 = 1 +
1
2
âˆš
2
which give the unique constrained global minimum point, whose existence is assured
by the Weierstrass theorem (the objective function is continuous and the feasible set
is compact). Obviously, in this case, the use of the Karush-Kuhn-Tucker conditions
could be avoided.
Example 6.31 Consider the problem
â§
â¨
â©
min x1
subject to: (x1 âˆ’4)2 + (x2)2 âˆ’16 â‰¦0,
(x1 âˆ’3)2 + (x2 âˆ’2)2 âˆ’13 = 0.
It is quite easy to check that the feasible set is closed and bounded and that the
constraints are qualiï¬ed. The Karush-Kuhn-Tucker conditions are
1 + 2u1(x1 âˆ’4) + 2v1(x1 âˆ’3) = 0,
2u1x2 + 2v1(x2 âˆ’2) = 0,
u1((x1 âˆ’4)2 + (x2)2 âˆ’16) = 0,
u1 â‰§0
and the feasibility conditions are
(x1 âˆ’3)2 + (x2 âˆ’2)2 âˆ’13 = 0,
(x1 âˆ’4)2 + (x2)2 âˆ’16 â‰¦0.
We obtain that the point x0 = (0, 0)âŠ¤, with multipliers u1 = 1
8, v1 = 0, is the
global minimizer of the problem; the point Â¯x = ( 32
5 , 16
5 ) = (6.4, 3.2), with multipli-
ers u1 =
3
40, v1 = âˆ’1
5, is a constrained local minimizer.

6.3 Second-Order Conditions
201
6.3
Second-Order Conditions
We give in this section second-order necessary and second-order sufï¬cient optimality
conditions for problem (P5), i.e. for the problem of the form
(P5) :
â§
âªâªâ¨
âªâªâ©
min f (x)
subject to: gi(x) â‰¦0, i = 1, . . . , m,
h j(x) = 0, j = 1, . . . , p < n,
x âˆˆX âŠ‚Rn,
where X is an open set and the functions involved in (P5) are twice-continuously
differentiable on X.
First, we introduce three polyhedral cones, related to second-order optimality
conditions for (P5). We recall the following index sets previously deï¬ned:
I (x0) =

i : gi(x0) = 0

;
I +(x0, u) =

i : i âˆˆI (x0), ui > 0 in the KKT conditions

;
I o(x0, u) =

i : i âˆˆI (x0), ui = 0 in the KKT conditions

=

i : i âˆˆI (x0) \ I +(x0, u)

.
We deï¬ne, with x0 âˆˆK5,
Z(x0) =
â§
â¨
â©
y âˆˆRn : âˆ‡gi(x0)âŠ¤y = 0, i âˆˆI +(x0, u);
âˆ‡gi(x0)âŠ¤y â‰¦0, i âˆˆI o(x0, u);
âˆ‡h j(x0)âŠ¤y = 0, j = 1, . . . , p
â«
â¬
â­,
Z1(x0) =
	 y âˆˆRn : âˆ‡gi(x0)âŠ¤y = 0, i âˆˆI (x0);
âˆ‡h j(x0)âŠ¤y = 0, j = 1, . . . , p

,
Z2(x0) =
	 y âˆˆRn : âˆ‡gi(x0)âŠ¤y = 0, i âˆˆI +(x0, u);
âˆ‡h j(x0)âŠ¤y = 0, j = 1, . . . , p

.
Being I +(x0, u) âŠ‚I (x0), we have
Z1(x0) âŠ‚Z(x0) âŠ‚Z2(x0).
If the Strict Complementary Slackness Conditions hold at x0, i.e. in the Karush-
Kuhn-Tucker conditions ui > 0, âˆ€i âˆˆI (x0), then obviously

202
6
Constrained Optimization Problems with Mixed Constraints
Z1(x0) = Z(x0) = Z2(x0).
The cone Z(x0) is often called critical cone or cone of critical directions at
x0 âˆˆK5.
In the literature another description of the cone Z(x0) often appears; it is the cone
(again called â€œcritical coneâ€):
C(x0) =
	 y âˆˆRn : âˆ‡f (x0)âŠ¤y = 0; âˆ‡gi(x0)âŠ¤y â‰¦0, i âˆˆI (x0);
âˆ‡h j(x0)âŠ¤y = 0, j = 1, . . . , p

.
Indeed, it can be proved that, under the validity of the Karush-Kuhn-Tucker con-
ditions at x0 âˆˆK5, the two cones C(x0) and Z(x0) coincide.
Theorem 6.32 Let x0 âˆˆK5 verify the Karush-Kuhn-Tucker conditions. Then
C(x0) = Z(x0).
Proof We ï¬rst show that C(x0) âŠ‚Z(x0). Let y âˆˆC(x0); clearly, we only need to
show that, for i âˆˆI +(x0, u), we have âˆ‡gi(x0)âŠ¤y = 0. By the Karush-Kuhn-Tucker
conditions, we have that
âˆ‡f (x0)âŠ¤y +

iâˆˆI (x0)
uiâˆ‡gi(x0)âŠ¤y +
p

j=1
v jâˆ‡h j(x0)âŠ¤y = 0.
Because âˆ‡h j(x0)âŠ¤y = 0, j = 1, . . . , p, and ui = 0 for i âˆˆI (x0) \ I +(x0, u),
we have
âˆ‡f (x0)âŠ¤y +

iâˆˆI +(x0,u)
uiâˆ‡gi(x0)âŠ¤y = 0.
Because âˆ‡f (x0)âŠ¤y = 0, and every ui > 0 for all i âˆˆI +(x0, u), we have
âˆ‡gi(x0)âŠ¤y = 0, âˆ€i âˆˆI +(x0, u).
Now we prove that Z(x0) âŠ‚C(x0). Let y be any point in Z(x0). It sufï¬ces to
show that âˆ‡f (x0)âŠ¤y = 0. As before, we have
âˆ‡f (x0)âŠ¤y +

iâˆˆI (x0)
uiâˆ‡gi(x0)âŠ¤y +
p

j=1
v jâˆ‡h j(x0)âŠ¤y = 0.
Clearly, âˆ‡f (x0)âŠ¤y = 0, because all other terms are zero.
â–¡
Another critical cone is introduced in the analysis of second-order optimality
conditions and usually when second-order necessary conditions of the Fritz John-
type are considered. It is the cone deï¬ned as follows (x0 âˆˆK5):

6.3 Second-Order Conditions
203
C1(x0) =
	 y âˆˆRn : âˆ‡f (x0)âŠ¤y â‰¦0; âˆ‡gi(x0)âŠ¤y â‰¦0, i âˆˆI (x0);
âˆ‡h j(x0)âŠ¤y = 0, j = 1, . . . , p.

.
(6.11)
Obviously, C(x0) âŠ‚C1(x0). We may call C1(x0) the extended critical cone at
x0 âˆˆK5. We point out the following result.
Theorem 6.33 Let x0 âˆˆK5 be a local minimum point for (P5). Then the Fritz John
conditions are satisï¬ed at x0 with u0 > 0 if and only if C(x0) = C1(x0).
Proof If C(x0) Ì¸= C1(x0), there will exist y âˆˆRn such that
â§
â¨
â©
âˆ‡f (x0)âŠ¤y < 0,
âˆ‡gi(x0)âŠ¤y â‰¦0, i âˆˆI (x0),
âˆ‡h j(x0)âŠ¤y = 0, j = 1, . . . , p.
(6.12)
We write the ï¬rst basic Fritz John relation:
u0âˆ‡f (x0) +

iâˆˆI (x0)
uiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0) = 0.
Multiplying this relation by y, we have that u0 = 0. On the other hand, if C(x0) =
C1(x0) we conclude that system (6.12) has no solution y âˆˆRn. From Farkasâ€™ theorem
(Theorem 2.28), we deduce the existence of multipliers ui â‰§0, i âˆˆI (x0), v j âˆˆR,
j = 1, . . . , p, such that
âˆ‡f (x0) +

iâˆˆI (x0)
uiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0) = 0.
â–¡
We recall that if x0 âˆˆK5 is a local solution of (P5) and a constraint qualiï¬-
cation is satisï¬ed, then there exist multipliers ui â‰§0, i = 1, . . . , m, and v j âˆˆR,
j = 1, . . . , p, with uigi(x0) = 0, i = 1, . . . , m, such that
âˆ‡f (x0) +
m

i=1
uiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0) = 0.
We recall again the deï¬nition of the index set I +(x0, u) âŠ‚I (x0):
I +(x0, u) =

i : i âˆˆI (x0), ui > 0 in the KKT conditions

.
Let us introduce the set
Q =

x âˆˆK5 : gi(x) = 0, âˆ€i âˆˆI +(x0, u)

.

204
6
Constrained Optimization Problems with Mixed Constraints
If we consider the usual Lagrangian function for (P5)
L (x, u, v) = f (x) + uâŠ¤g(x) + vâŠ¤h(x),
we have, due to the complementary slackness conditions,
L (x, u, v) = f (x), âˆ€x âˆˆQ.
As x0 âˆˆK5 is a local solution of (P5), this point is also a local solution of the
problem
min L (x, u, v) = f (x), x âˆˆQ.
But, thanks to the Karush-Kuhn-Tucker conditions, we have âˆ‡xL (x0, u, v) = 0
and therefore Theorem 4.26 applies. We obtain the following second-order necessary
optimality conditions for (P5).
Theorem 6.34 Let x0 âˆˆK5 be a local minimum point of (P5) and let some con-
straint qualiï¬cation be veriï¬ed; then there exists a triplet (x0, u, v) which satisï¬es
the Karush-Kuhn-Tucker conditions and moreover we have
yâŠ¤âˆ‡2
xL (x0, u, v)y â‰§0, âˆ€y âˆˆT (Q, x0).
(6.13)
Now, if the Abadie constraint qualiï¬cation, referred to the set Q, holds, i.e. if
T (Q, x0) = Z(x0)
(6.14)
(note that Z(x0) is the linearizing cone of Q at x0), then obviously (6.13) can be
written as
yâŠ¤âˆ‡2
xL (x0, u, v)y â‰§0, âˆ€y âˆˆZ(x0),
(6.15)
which is one of the classical second-order necessary optimality conditions for (P5).
When is equality (6.14) satisï¬ed? The following result gives sufï¬cient conditions
for the validity of (6.14).
Theorem 6.35 If at x0 âˆˆK5 the Linear Independence constraint qualiï¬cation is
satisï¬ed or even the more general Strict Mangasarian-Fromovitz constraint qualiï¬-
cation is satisï¬ed (and hence M(x0) is a singleton), then (6.14) holds and therefore
(6.13) can be substituted by (6.15).
The proof follows, mutatis mutandis, from the proof of Theorem 5.19 and will
not be repeated here.
Note that the Linear Independence c. q. and the Strict Mangasarian-Fromovitz c.
q. are not only ï¬rst-order constraint qualiï¬cations, but also second-order constraint
qualiï¬cations which permit to obtain relation (6.15). This is not the case, as we shall
see next, for the Mangasarian-Fromovitz constraint qualiï¬cation.
Being Z1(x0) âŠ‚Z(x0), obviously a second-order necessary optimality condition
weaker than (6.15) is

6.3 Second-Order Conditions
205
yâŠ¤âˆ‡2
xL (x0, u, v)y â‰§0, âˆ€y âˆˆZ1(x0).
This condition appears in the paper of McCormick [21] and in Fiacco and
McCormick [22]. It has the advantage to be tested by means of the results on the
sign of a quadratic form constrained by a linear homogeneous equations system (see
Chap. 1, Chabrillac and Crouzeix [23], Debreu [24]).
A second-order constraint qualiï¬cation for (P5) is considered in the pioneering
paper of McCormick [21] and also in McCormick [25, 26].
â€¢ McCormick Second-Order Constraint Qualiï¬cation.
This constraint qualiï¬cation holds at x0 âˆˆK5 if for all y âˆˆZ(x0), y is the tangent
of a twice differentiable arc Î±(Î¸), where for some Î¸1 > 0:
gi [Î±(Î¸)] = 0, for Î¸ âˆˆ[0, Î¸1] , âˆ€i âˆˆI +(x0, u);
gi [Î±(Î¸)] â‰¦0, for Î¸ âˆˆ[0, Î¸1] , âˆ€i âˆˆI (x0) \ I +(x0, u);
h j [Î±(Î¸)] = 0, for Î¸ âˆˆ[0, Î¸1] , âˆ€j = 1, . . . , p
and Î±(0) = x0, Î±â€²(0) = y.
McCormick proves that if a ï¬rst-order constraint qualiï¬cation and the above
second-order constraint qualiï¬cation hold at the local optimal point x0 âˆˆK5, then,
besides the Karush-Kuhn-Tucker conditions, also condition (6.15) holds.
McCormick shows, by numerical examples, that his second-order c. q. does
not assure the validity of the Karush-Kuhn-Tucker conditions, i.e. the McCormick
second-order c. q. is not a ï¬rst-order c. q. On the other hand, the Linear Independence
c. q. and the Strict Mangasarian-Fromovitz c. q. assure the validity of the McCormick
second-order c. q., but this is not the case, for example, of the Mangasarian-Fromovitz
c. q. or of the Kuhn-Tucker c. q. (for this last case McCormick [21] gives a numerical
example).
Fiacco and McCormick in an unpublished paper of 1968 (A. V. Fiacco and
G. P. McCormick, Asymptotic conditions for constrained minimization, RAC-TP-
340, 1968, Research Analysis Corporation, McLean, Virginia) and subsequently
McCormick [26] give for (P5) also a second-order necessary optimality conditions
of the Fritz John-type.
Theorem 6.36 Let x0 âˆˆK5 be a local minimum point of (P5). Then, at x0, besides
the (ï¬rst-order) Fritz John conditions with multipliers u0, u, v, it will hold the fol-
lowing second-order necessary conditions:
yâŠ¤âˆ‡2
xL1(x0, u0, u, v)y â‰§0, âˆ€y âˆˆT (Q, x0),
(6.16)
where L1(x, u0, u, v) = u0 f (x) + uâŠ¤g(x) + vâŠ¤h(x).
Proof Itisenoughtoprove (6.16)for y âˆˆT (Q, x0)withâˆ¥yâˆ¥= 1.Thenthereexistsa
sequence {zk} âŠ‚Q such that zk
yâ†’x0 (see Deï¬nition 2.34), i.e. lim
kâ†’+âˆ
zkâˆ’x0
âˆ¥zkâˆ’x0âˆ¥= y.

206
6
Constrained Optimization Problems with Mixed Constraints
Observe that gi(x0) < 0 for all i /âˆˆI (x0). Then, for k sufï¬ciently large we have
g(zk) < 0. Hence, for k sufï¬ciently large zk is feasible for (P5). For k sufï¬ciently
large
f (zk) âˆ’f (x0) â‰§0.
Therefore,
(zk âˆ’x0)âŠ¤âˆ‡f (x0) + 1
2(zk âˆ’x0)âŠ¤âˆ‡2 f (x0)(zk âˆ’x0) + o(
zk âˆ’x02) â‰§0.
(6.17)
Note that, for every i âˆˆI +(x0, u), we have gi(zk) = 0. Therefore, for each i âˆˆ
I +(x0, u), we have
(zk âˆ’x0)âŠ¤âˆ‡gi(x0) + 1
2(zk âˆ’x0)âŠ¤âˆ‡2gi(x0)(zk âˆ’x0) + o(
zk âˆ’x02) = 0.
(6.18)
Again we have h j(zk) âˆ’h j(x0) = 0 for all j = 1, . . . , p. Therefore, for all j,
one has
(zk âˆ’x0)âŠ¤âˆ‡h j(x0) + 1
2(zk âˆ’x0)âŠ¤âˆ‡2h j(x0)(zk âˆ’x0) + o(
zk âˆ’x02) = 0.
(6.19)
Using (6.17), (6.18), (6.19) and the Fritz John conditions, one can easily establish
that
1
2(zk âˆ’x0)âˆ‡2
xL1(x0, u0, u, v)(zk âˆ’x0) + o(
zk âˆ’x02) â‰§0.
(6.20)
Dividing the expression (6.20) throughout by
zk âˆ’x02 and proceeding to the
limit as k â†’âˆ, we have, since ui = 0 for all i âˆˆI (x0) \ I +(x0, u),
yâŠ¤âˆ‡2
xL1(x0, u0, u, v)y â‰§0, âˆ€y âˆˆT (Q, x0),
i.e. the thesis of the theorem.
â–¡
Obviously, if T (Q, x0) = Z(x0), we can express (6.16) with reference to the
critical cone Z(x0). It is not difï¬cult to prove that if the Second-Order McCormick
c. q. holds at x0, then T (Q, x0) = Z(x0) in relation (6.16). See McCormick [26].
It is also possible to obtain second-order necessary optimality conditions of the
Fritz John-type which make reference to the extended critical cone C1(x0). How-
ever, in this case, the Fritz John multipliers which appear in L1(x0, u0, u, v) are
not necessarily ï¬xed. The following result (Theorem 6.39) is due to Ben-Tal [27],
previously we need a lemma and we do a comment.
Lemma 6.37 Let x0 âˆˆS2 and y âˆˆL(x0). Suppose that the gradients âˆ‡h j(x0), j =
1, . . . , p, are linearly independent. Then if z âˆˆRn satisï¬es

6.3 Second-Order Conditions
207
	âˆ‡gi(x0)âŠ¤z + yâŠ¤âˆ‡2gi(x0)y < 0,
âˆ€i âˆˆI (x0, y),
âˆ‡h j(x0)âŠ¤z + yâŠ¤âˆ‡2h j(x0)y = 0,
âˆ€j = 1, . . . , p,
(6.21)
where I (x0, y) = {i âˆˆI (x0) : âˆ‡gi(x0)âŠ¤y = 0}, then there exist a positive number
Î´ and a curve Î³ âˆˆC1[0, Î´] such that
Î³ (t) âˆˆK5 for all t âˆˆ[0, Î´], Î³ (0) = x0, Î³ â€²(0) = y, Î³ â€²â€²(0) = z.
(6.22)
Its proof, which is based on the inverse function theorem, can be seen in Still and
Streng [11], Lemma 2.1.
Remark 6.38 If the gradients âˆ‡h j(x0), j = 1, . . . , p, are linearly independent and
condition (6.21) holds for some z âˆˆRn, it is said that the second-order Mangasarian-
Fromovitz c. q. is satisï¬ed at (x0, y). This condition is implied by the (ï¬rst-order)
Mangasarian-Fromovitz c. q. Indeed, as âˆ‡h j(x0), j = 1, . . . , p, are linearly inde-
pendent, for a given y âˆˆL(x0), there exists d âˆˆRn such that
âˆ‡h j(x0)âŠ¤d + yâŠ¤âˆ‡2h j(x0)y = 0,
j = 1, . . . , p.
Then, for a vector z satisfying the ï¬rst-order Mangasarian-Fromovitz c. q., i.e.
âˆ‡gi(x0)âŠ¤z < 0, i âˆˆI (x0) and âˆ‡h j(x0)âŠ¤z = 0, j = 1, . . . , p, putting zt = d + tz,
we ï¬nd that
	âˆ‡gi(x0)âŠ¤zt + yâŠ¤âˆ‡2gi(x0)y < 0,
âˆ€i âˆˆI (x0, y),
âˆ‡h j(x0)âŠ¤zt + yâŠ¤âˆ‡2h j(x0)y = 0,
âˆ€j = 1, . . . , p,
for t > 0 large enough, i.e. zt is a vector satisfying (6.21).
Theorem 6.39 Let x0 âˆˆK5 be a local minimizer for problem (P5). Then, for any
y âˆˆC1(x0) (see (6.11)), there are multipliers (u0, u, v) not all zero, (u0, u) â‰§0, such
that the Fritz John conditions (see Theorem 6.3) are satisï¬ed at x0 and, moreover,
yâŠ¤âˆ‡2
xL1(x0, u0, u, v)y â‰§0.
(6.23)
The reader is invited to remark the structure of the previous theorem and its
different form with respect to the previous ones. An example of an optimization
problem where, at a minimizer x0, different multipliers are really necessary to get
(6.23), can be found in Ben-Tal [27], Example 2.1. The proofs of Theorem 6.39 given
by Ben-Tal [27] and by Still and Streng [11] are based on several lemmas. We follow
the soundproof of Bonnans and Shapiro [28].
Proof of Theorem 6.39 (Bonnans and Shapiro) Let y âˆˆC1(x0). If the gradients
âˆ‡h j(x0), j = 1, . . . , p, are linearly dependent, then there exists Ï„ Ì¸= 0 such that
p
j=1 Ï„ jâˆ‡h j(x0) = 0. Hence, (u0, u, v) = (0, 0, Ï„) or (u0, u, v) = (0, 0, âˆ’Ï„) are
Fritz John multipliers which satisfy the (ï¬rst-order) Fritz John conditions. If (6.23)
is satisï¬ed with (0, 0, Ï„), there is nothing else to prove. Otherwise, since (0, 0, âˆ’Ï„)
is another Fritz John multipliers vector, and

208
6
Constrained Optimization Problems with Mixed Constraints
yâŠ¤âˆ‡2
xL1(x0, 0, 0, âˆ’Ï„)y = âˆ’yâŠ¤âˆ‡2
xL1(x0, 0, 0, Ï„)y,
we have that (6.23) is satisï¬ed by (0, 0, âˆ’Ï„). Therefore, for any y âˆˆC1(x0), we can
choose one of the two possibilities, so that (6.23) is satisï¬ed.
We now assume that the gradients âˆ‡h j(x0), j = 1, . . . , p, are linearly inde-
pendent. Consider the following linear programming problem in the variables
(Î±, z) âˆˆR Ã— Rn:
â§
âªâªâ¨
âªâªâ©
min Î±
subject to: âˆ‡f (x0)âŠ¤z + yâŠ¤âˆ‡2 f (x0)y â‰¦Î±,
âˆ‡gi(x0)âŠ¤z + yâŠ¤âˆ‡2gi(x0)y â‰¦Î±, i âˆˆI (x0, y),
âˆ‡h j(x0)âŠ¤z + yâŠ¤âˆ‡2h j(x0)y = 0, j = 1, . . . , p,
(6.24)
where I (x0, y) = {i âˆˆI (x0) : âˆ‡gi(x0)âŠ¤y = 0}. The optimal value of this problem
is nonnegative. Indeed, otherwise, there exists z which satisï¬es
â§
â¨
â©
âˆ‡f (x0)âŠ¤z + yâŠ¤âˆ‡2 f (x0)y < 0,
âˆ‡gi(x0)âŠ¤z + yâŠ¤âˆ‡2gi(x0)y < 0, i âˆˆI (x0, y),
âˆ‡h j(x0)âŠ¤z + yâŠ¤âˆ‡2h j(x0)y = 0, j = 1, . . . , p.
(6.25)
By Lemma 6.37, there exists a path Î³ : [0, Î´] â†’Rn satisfying conditions (6.22).
Then, by a second-order Taylor expansion, we have for t > 0 small enough that
f (Î³ (t)) = f (x0) + tâˆ‡f (x0)âŠ¤y + 1
2t2 
âˆ‡f (x0)âŠ¤z + yâŠ¤âˆ‡2 f (x0)y

+ o(t2) < f (x0)
due to the ï¬rst condition in (6.24) and the fact that y âˆˆD<( f, x0). Therefore, for
t > 0 small enough, Î³ (t) âˆˆK5 is feasible and f (Î³ (t)) < f (x0), which contradicts
the local minimality of x0. This proves that (6.24) has a nonnegative optimal value.
Since âˆ‡h j(x0), j = 1, . . . , p, are linearly independent, the equality constraints
of (6.24) have a feasible solution because rk âˆ‡h(x0) = p and so âˆ‡h(x0)(Rn) =
Rp, and thus there exists z âˆˆRn such that âˆ‡h j(x0)âŠ¤z + yâŠ¤âˆ‡2h j(x0)y = 0 for all
j = 1, . . . , p, and hence, since Î± can be made arbitrarily large, problem (6.24) is
consistent. Therefore, (6.24) has a ï¬nite nonnegative optimal value. Since (6.24) is
a linear programming problem, it follows, by the Strong Duality Theorem of Linear
Programming (see Remark 9.19), that its dual, in the variables u0, u, v, with ui = 0
for i /âˆˆI (x0, y), has the same optimal value. The dual of (6.24) is
max yâŠ¤
â›
âu0âˆ‡2 f (x0) +

iâˆˆI (x0,y)
uiâˆ‡2gi(x0) +
p

j=1
v jâˆ‡2h j(x0)
â
â y
subject to:

6.3 Second-Order Conditions
209
u0âˆ‡f (x0) +

iâˆˆI (x0,y)
uiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0) = 0,
u0 +

iâˆˆI (x0,y)
ui +
p

j=1
v j = 1,
u0 â‰§0, ui â‰§0, i âˆˆI (x0, y).
Since an optimal solution of this dual problem is a Fritz John multipliers vector
associated to x0, by choosing ui = 0 for i /âˆˆI (x0, y), we get the thesis.
â–¡
The drawback of the previous theorem is that it may be u0 = 0. The Mangasarian-
Fromovitz c. q., if veriï¬ed, assures that this case cannot occur. However, even under
the validity of the Mangasarian-Fromovitz c. q., we are not able to obtain the second-
order necessary conditions with ï¬xed multipliers.
Theorem 6.40 Let x0 âˆˆK5 be a local optimal solution of problem (P5) and let x0
verify the Mangasarian-Fromovitz c. q.; then, for every y âˆˆC(x0) = Z(x0), there
exist Karush-Kuhn-Tucker multipliers vectors (u, v), u âˆˆRm
+, v âˆˆRp, uigi(x0) =
0, i = 1, . . . , m, such that the Karush-Kuhn-Tucker conditions are satisï¬ed at x0
and, moreover,
yâŠ¤âˆ‡2
xL (x0, u, v)y â‰§0.
Proof It is sufï¬cient to take into account that C(x0) âŠ‚C1(x0), to apply the previous
theorem and to remark that the Mangasarian-Fromovitz c. q. assures u0 > 0, and
hence u0 = 1, in the Fritz John conditions.
â–¡
A counterexample showing that the Mangasarian-Fromovitz c. q. is not able to
assure the usual second-order necessary optimality conditions for (P5) has been
constructed by Arutyunov [29] and subsequently another counterexample was found
by Anitescu [30]. Being M(x0) a convex and compact set (see Theorem 6.18), under
the validity of the Mangasarian-Fromovitz c. q., it is then possible to write the thesis
of Theorem 6.40 in the form
max
(u,v)âˆˆM(x0)yâŠ¤âˆ‡2
xL (x0, u, v)y â‰§0, âˆ€y âˆˆC(x0).
We may call â€œusualâ€ second-order necessary conditions the second-order con-
ditions with ï¬xed multipliers and â€œweakâ€ second-order necessary conditions the
second-order conditions with non-ï¬xed multipliers. The denominations are not stan-
dard!
It must be observed that if the Strict Mangasarian-Fromovitz c. q. holds at x0,
then M(x0) is a singleton and therefore the weak second-order necessary conditions
of Theorem 6.40 become the usual second-order necessary conditions previously

210
6
Constrained Optimization Problems with Mixed Constraints
described in Theorem 6.35. This conï¬rms once more that the Strict Mangasarian-
Fromovitz c. q. is not only a ï¬rst-order constraint qualiï¬cation, but also a second-
order constraint qualiï¬cation.
Besides the Linear Independence c. q. and the Strict Mangasarian-Fromovitz c. q.,
other ï¬rst-order constraint qualiï¬cations have been recognized to assure the validity
of the â€œusualâ€ second-order necessary conditions (i.e. with ï¬xed multipliers) for (P5).
Andreani, EchagÃ¼e and Schuverdt [31] have proved that under the Constant Rank
Constraint Qualiï¬cation, the following condition is valid (x0 local solution of (P5)):
âˆ€(u, v) âˆˆM(x0) : yâŠ¤âˆ‡2
xL (x0, u, v)y â‰§0, âˆ€y âˆˆC(x0).
Also, the following result has been established by Andreani, EchagÃ¼e and Schu-
verdt [31]. We ï¬rst introduce the notion of Weak Constant Rank Condition:
â€¢ Let x0 âˆˆK5, then the weak constant rank condition holds if there is a neighborhood
U(x0) such that the set

âˆ‡gi(x), i âˆˆI (x0)

âˆª

âˆ‡h j(x), j = 1, . . . , p

has the same rank for all x âˆˆU(x0) âˆ©K5.
Theorem 6.41 If x0 âˆˆK5 is a local minimizer for (P5) satisfying the Karush-Kuhn-
Tucker conditions (i.e. M(x0) Ì¸= âˆ…) and the weak constant rank condition holds,
then
âˆ€(u, v) âˆˆM(x0) : yâŠ¤âˆ‡2
xL (x0, u, v)y â‰§0, âˆ€y âˆˆZ1(x0).
(6.26)
Therefore, any constraint qualiï¬cation that ensures M(x0) Ì¸= âˆ…, in combination
with the weak constant rank condition, guarantees that (6.26) holds at a local mini-
mizer x0 for (P5).
Remark 6.42 It is convenient to remark that the following conjectures are false.
Conjecture 1. If x0 âˆˆK5 is a local minimizer of problem (P5), then the Hessian
matrix âˆ‡2 f (x0) is positive semideï¬nite.
Example.
min âˆ’(x1 + 1)2 âˆ’(x2)2
subject to: (x1)2 + (x2)2 â‰¦1.
The optimal point is x0 = (1, 0)âŠ¤, but âˆ‡2 f (x0) is not positive semideï¬nite.
Conjecture 2. If x0 âˆˆK5 is a local minimizer of problem (P5), then the Hessian
matrix of the Lagrangian function âˆ‡2
xL (x0, u, v) is positive semideï¬nite.
Example.
â§
â¨
â©
min âˆ’(x1)2 + (x2)2
subject to: x1 â‰¦1;
âˆ’x1 â‰¦0.

6.3 Second-Order Conditions
211
The optimal point is x0 = (1, 0)âŠ¤, but âˆ‡2
xL (x0, u) is not positive semideï¬-
nite. Note that any feasible direction y satisfying yâŠ¤âˆ‡2
xL (x0, u)y < 0 also satisï¬es
yâŠ¤âˆ‡g1(x0) < 0.
Now we turn to second-order sufï¬cient optimality conditions for (P5). Taking into
considerationTheorem 5.22wehavethefollowingsecond-order sufï¬cient conditions
for (P5).
Theorem 6.43 Let x0 âˆˆK5 and let the Karush-Kuhn-Tucker conditions be satisï¬ed
by the triplet (x0, u, v). If
yâŠ¤âˆ‡2
xL (x0, u, v)y > 0, âˆ€y Ì¸= 0,
y âˆˆT (K5, x0) âˆ©

y : âˆ‡gi(x0)âŠ¤y = 0, âˆ€i âˆˆI +(x0, u)

,
then x0 is a strict local minimum point for (P5).
As T (K5, x0) âŠ‚L(x0) it is possible to rewrite the previous conclusion in the
more usual form
yâŠ¤âˆ‡2
xL (x0, u, v)y > 0, âˆ€y Ì¸= 0, y âˆˆZ(x0).
For the readerâ€™s convenience, we give a direct proof of this last result.
Theorem 6.44 Let x0 âˆˆK5 and let the Karush-Kuhn-Tucker conditions be satisï¬ed
by the triplet (x0, u, v). If
yâŠ¤âˆ‡2
xL (x0, u, v)y > 0, âˆ€y Ì¸= 0, y âˆˆZ(x0),
(6.27)
then x0 is a strict local solution of (P5).
Proof The proof is indirect; let us assume that x0 is not a strict local minimum point
for (P5). Then there will exist a tangentially convergent sequence

xk
âŠ‚K5, xk Ì¸=
x0, with xk
yâ†’x0 and f (xk) â‰¦f (x0) for all k âˆˆN. Hence, y âˆˆT (K5, x0) \ {0} and
the quotients
f (xk) âˆ’f (x0)
xk âˆ’x0
= âˆ‡f (x0)âŠ¤(xk âˆ’x0) + o(
xk âˆ’x0)
xk âˆ’x0
,
gi(xk) âˆ’gi(x0)
xk âˆ’x0
= âˆ‡gi(x0)âŠ¤(xk âˆ’x0) + o(
xk âˆ’x0)
xk âˆ’x0
,
h j(xk) âˆ’h j(x0)
xk âˆ’x0
= âˆ‡h j(x0)âŠ¤(xk âˆ’x0) + o(
xk âˆ’x0)
xk âˆ’x0
,

212
6
Constrained Optimization Problems with Mixed Constraints
where i âˆˆI (x0) and j = 1, . . . , p, converge to, respectively, âˆ‡f (x0)âŠ¤y â‰¦0, âˆ‡
gi(x0)âŠ¤y â‰¦0 and âˆ‡h j(x0)âŠ¤y = 0.
By the Karush-Kuhn-Tucker conditions (ui â‰§0 for all i = 1, . . . , m), we have
âˆ‡f (x0)âŠ¤y +
m

i=1
uiâˆ‡gi(x0)âŠ¤y +
p

j=1
v jâˆ‡h j(x0)âŠ¤y = 0
and each summation term is equal to zero. Then we have
âˆ‡gi(x0)âŠ¤y = 0, âˆ€i âˆˆI +(x0, u).
Hence, y âˆˆZ(x0) \ {0} . By considering
L (xk, u, v) âˆ’L (x0, u, v) = f (xk) âˆ’f (x0)+
+
m

i=1
ui(gi(xk) âˆ’gi(x0)) +
p

j=1
v j(h j(xk) âˆ’h j(x0)) â‰¦0,
with âˆ‡xL (x0, u, v) = 0, the quotients
L (xk, u, v) âˆ’L (x0, u, v)
xk âˆ’x02
=
1
2(xk âˆ’x0)âŠ¤âˆ‡2x L (x0, u, v)(xk âˆ’x0) + o(
xk âˆ’x0
2
)
xk âˆ’x02
converge to 1
2 yâŠ¤âˆ‡2
xL (x0, u, v)y â‰¦0, in contradiction with the hypothesis.
â–¡
Following Hestenes [12] it is possible to reformulate the thesis of Theorem 6.44
in the following way:
â€¢ If (6.27) holds, together with the Karush-Kuhn-Tucker conditions, then the
feasible point x0 is a strict local minimizer of order two for (P5), i.e. there is a
constant m > 0 and a neighborhood U(x0) such that
f (x) â‰§f (x0) + m
x âˆ’x02 , âˆ€x âˆˆK5 âˆ©U(x0).
We recall the deï¬nition of the linear subspace Z2(x0):
Z2(x0) =

y âˆˆRn : âˆ‡gi(x0)âŠ¤y = 0, i âˆˆI +(x0, u); âˆ‡h j(x0)âŠ¤y = 0, j = 1, . . . , p
 
.
Being Z(x0) âŠ‚Z2(x0), then we can replace in Theorem 6.44 relation (6.27) with
the stronger condition
yâŠ¤âˆ‡2
xL (x0, u, v)y > 0, âˆ€y Ì¸= 0, y âˆˆZ2(x0).
(6.28)

6.3 Second-Order Conditions
213
Indeed,thislastconditionisknownasthestrongsecond-ordersufï¬cientoptimality
condition for (P5). See Robinson [32]. Note that when strict complementarity holds,
the strong second-order sufï¬cient condition and the usual second-order sufï¬cient
condition of Theorem 6.44 are equivalent. The advantage of (6.28) is that it permits
the use of the results of testing the sign of a quadratic form subject to a system of
homogeneous linear equations (see Chabrillac and Crouzeix [23], Debreu [24] and
Chap. 1). McCormick [26] remarks that (6.28) can be expressed also in the following
way. Let V be the matrix whose columns are a base of the linear space Z2(x0). Then
(6.28) holds if and only if
V âŠ¤âˆ‡2
xL (x0, u, v)V
is a positive deï¬nite matrix. See also Kelly and Kupferschmid [33].
We have to note that, contrary to what asserted in Fiacco and McCormick [22]
and in McCormick [26], the conditions given in Theorem 6.44 do not assure that x0
is an isolated (i.e. locally unique) solution of problem (P5). Robinson [34] provides
the following counterexample in R. See also Fiacco [35].
Example 6.45 Consider the problem
min f (x) = 1
2 x2, x âˆˆR,
subject to: h(x) = x6 sin
 1
x

= 0, h(0) = 0.
One can easily verify that the assumptions of Theorem 6.44 are veriï¬ed at x0 = 0.
However, every point in the set

(nÏ€)âˆ’1, n = Â±1, Â±2, . . .

is an isolated feasible point and therefore also a local minimum. However, x0 = 0 is
not an isolated local minimum for the problem considered.
Conditions sufï¬cient for x0 âˆˆK5 to be an isolated local minimum for (P5) are
obtained by Robinson [34] by strengthening the assumptions of Theorem 6.44 in two
ways.
Theorem 6.46 (Robinson) Suppose that the Karush-Kuhn-Tucker conditions hold at
x0 âˆˆK5 for (P5) with some multipliers u and v and that the Mangasarian-Fromovitz
constraint qualiï¬cation holds at x0. Moreover, assume that the following General
Second-Order Sufï¬cient Conditions hold at x0:
â€¢ The Second-Order Sufï¬cient Conditions of Theorem 6.44 hold at x0, with (u, v)
for every (u, v) âˆˆM(x0).
Then x0 is an isolated local minimum point for (P5), i.e. there exists a neighborhood
N(x0) of x0 such that x0 is the unique local minimum point for (P5) in N(x0).

214
6
Constrained Optimization Problems with Mixed Constraints
Note that if the Linear Independence c. q. or the more general Strict Mangasarian-
Fromovitz c. q. is substituted for the Mangasarian-Fromovitz c. q. in Theorem 6.46,
then the General Second-Order Sufï¬cient Conditions of Theorem 6.46 coincide with
the usual Second-Order Sufï¬cient Conditions of Theorem 6.44, since M(x0) is then
a singleton. Thus, under the Linear Independence c. q. or the Strict Mangasarian-
Fromovitz c. q., Theorem 6.44 assures that x0 is an isolated local minimum point of
(P5).
Example 6.47 Consider the problem
min f (x) = âˆ’(x1)2 âˆ’(x2)2, x âˆˆR2,
subject to:
â§
â¨
â©
âˆ’x1 â‰¦0,
âˆ’x2 â‰¦0,
x1 + x2 â‰¦2.
There are four Karush-Kuhn-Tucker points: x1 = [2, 0]âŠ¤, x2 = [0, 2]âŠ¤, x3 =
[1, 1]âŠ¤and x4 = [0, 0]âŠ¤. The second-order sufï¬cient conditions show that x1 and
x2 are strict local minimizers. The second-order necessary conditions show that x3
and x4 are not local minimizers.
We have also second-order sufï¬cient optimality conditions of the Fritz John-type
(and also for the case of non-ï¬xed multipliers; see Ben-Tal [27], Bonnans and Shapiro
[28], Still and Streng [11]. In this case, the extended cone of critical directions C1(x0)
is used). The following result is given in the book of McCormick [26].
Theorem 6.48 Let x0 âˆˆK5 and suppose that x0 satisï¬es the Fritz John conditions
for (P5), with a Lagrangian function
L1(x, u0, u, v) = u0 f (x) + uâŠ¤g(x) + vâŠ¤h(x).
If
yâŠ¤âˆ‡2
xL1(x0, u0, u, v)y > 0, âˆ€y Ì¸= 0, y âˆˆZ(x0),
then x0 is a strict local minimizer for (P5); more precisely, x0 is a strict local
minimizer of order two.
For what concerns second-order sufï¬cient optimality conditions for (P5) with
non-ï¬xed multipliers, we have the following results.
â€¢ If x0 âˆˆK5 and for each y âˆˆC1(x0) \ {0} there exists (u0, u, v) which together
with x0, satisfy the Fritz John conditions for (P5) and moreover
yâŠ¤âˆ‡2
xL1(x0, u0, u, v)y > 0,
then x0 is a strict local minimizer of (P5) of order two.

6.4 Problems with a Set Constraint. Asymptotic Optimality Conditions
215
â€¢ If x0 âˆˆK5, the set M(x0) of Karush-Kuhn-Tucker multipliers is nonempty and
for each y âˆˆC(x0) \ {0} there exists (u, v) âˆˆM(x0) such that
yâŠ¤âˆ‡2
xL (x0, u, v)y > 0,
then x0 is a strict local minimizer of (P5) of order two. These conditions can be
also written in the equivalent form
sup
(u,v)âˆˆM(x0)
yâŠ¤âˆ‡2
xL (x0, u, v)y > 0, âˆ€y âˆˆC(x0) \ {0} ,
where the above supremum can be +âˆ. If the Mangasarian-Fromovitz c. q. holds
at x0 (and hence M(x0) is compact), â€œsupâ€ can be substituted by â€œmaxâ€.
Finally, we report an interesting result of Ward [36], in which it is shown that the
StrictMangasarian-Fromovitzc.q.â€œclosesthegapâ€betweenthe(usual)second-order
necessary optimality conditions and the (usual) second-order sufï¬cient optimality
conditions.
Theorem 6.49 Let x0 âˆˆK5 and suppose that the Strict Mangasarian-Fromovitz
c. q. is satisï¬ed at x0 with multipliers (u, v) such that âˆ‡xL (x0, u, v) = 0, with
uigi(x0) = 0, ui â‰§0, i = 1, . . . , m. Then x0 is a strict local minimizer of order two
for (P5) if and only if
yâŠ¤âˆ‡2
xL (x0, u, v)y > 0, âˆ€y Ì¸= 0, y âˆˆZ(x0) = C(x0).
6.4
Problems with a Set Constraint. Asymptotic Optimality
Conditions
When in problem (P5) besides the functional constraints it appears also a set con-
straint or abstract constraint, represented by a closed set C âŠ‚X âŠ‚Rn, the usual
necessary Fritz John conditions, described in Theorem 6.3, and several constraint
qualiï¬cations seen for (P5) are no longer valid. Consider the following example.
Example 6.50
min {âˆ’(x + y)} , (x, y) âˆˆR2,
subject to:
	
h(x, y) = (x âˆ’1)2 + y2 âˆ’1 = 0,
(x, y) âˆˆC =

(x, y) : |x| + |y| â‰¦1

.
The point (x0, y0) = (1 âˆ’
âˆš
2/2;
âˆš
2/2) is a solution of the problem, but there is
no vector (u0, v1)âŠ¤Ì¸= (0, 0)âŠ¤such that
u0âˆ‡f (x0, y0) + v1âˆ‡h(x0, y0) = (0, 0)âŠ¤.

216
6
Constrained Optimization Problems with Mixed Constraints
We deï¬ne a new problem, (P6), which contains also a set constraint C âŠ‚X âŠ‚Rn:
(P6) :
â§
âªâªâ¨
âªâªâ©
min f (x)
subject to: gi(x) â‰¦0, i = 1, . . . , m;
h j(x) = 0, j = 1, . . . , p < n;
x âˆˆC âŠ‚X âŠ‚Rn,
where C is a closed set and the functions involved in (P6) satisfy the same assump-
tions made for (P5). The feasible set of (P6) is denoted by K6.
One of the ï¬rst papers which provides a general analysis of problem (P6) is the
one of Bazaraa and Goode [37]. These authors use the cone of interior directions to
a set S âŠ‚Rn at x0 âˆˆS:
I (S, x0) =
	 y âˆˆRn : âˆƒU(y), âˆƒÎ´0 > 0 such that v âˆˆU(y), Î´ âˆˆ(0, Î´0)
imply x0 + Î´v âˆˆS

.
It appears that I (S, x0) is an open cone and that I (S, x0) âŠ‚A(S, x0) âŠ‚T (S, x0).
Moreover, if x0 âˆˆint(S), then I (S, x0) = Rn and if S âŠ‚Rn is a convex set, with
int(S) Ì¸= âˆ…, then
cl(I (S, x0)) = cl(cone(S âˆ’x0)) = A(S, x0) = T (S, x0).
The main result of Bazaraa and Goode [37] is the following one.
Theorem 6.51 Suppose that x0 âˆˆK6 is a local solution of (P6) and suppose that
I (C, x0) is a convex cone. Then, there exist multipliers (u0, u, v), not all zero, such
that
(i) âˆ’

u0âˆ‡f (x0) + m
i=1 uiâˆ‡gi(x0) + p
j=1 v jâˆ‡h j(x0)

âˆˆ(I (C, x0))âˆ—;
(ii) uigi(x0) = 0, i = 1, . . . , m;
(iii) u0 â‰§0, ui â‰§0, i = 1, . . . , m, v j âˆˆR, j = 1, . . . , p.
Bazaraa and Shetty [14] give an example where it is shown that it is not possible
to replace in (i) of Theorem 6.51 the cone I (C, x0) with the larger cone T (C, x0),
in order to obtain a sharper necessary optimality condition.
The above result has been slightly improved by Giorgi and Guerraggio [38] who
use an open cone larger than I (C, x0), i.e. the cone of quasi-interior directions to C
at x0:
Q(C, x0) =
	 y âˆˆRn : âˆƒU(y), such that âˆ€Î´0 > 0 âˆƒÎ´ âˆˆ(0, Î´0), âˆ€v âˆˆU(y)
we have x0 + Î´v âˆˆS

.
We note that when C is convex, with int(C) Ì¸= âˆ…, relation (i) of Theorem 6.51
can be reformulated as

6.4 Problems with a Set Constraint. Asymptotic Optimality Conditions
217
âˆ’
â¡
â£u0âˆ‡f (x0) +
m

i=1
uiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0)
â¤
â¦âˆˆN(C, x0),
(6.29)
where N(C, x0) is the normal cone to C at x0.
Giorgi, JimÃ©nez and Novo [39] have observed that (6.29) is valid even if no
assumption on the convex set C is made (besides convexity). Also the approach of
Gould and Tolle [40], previously reported for (P4) in Chap. 5, Theorem 6.29, can be
immediately ï¬tted to (P6). We continue to denote by L(x0) the linearizing cone for
(P6) at x0 âˆˆK6. We have the following result.
Theorem 6.52 Let x0 âˆˆK6 be a local solution of (P6). Then there exist multipliers
(u, v), u â‰§0, such that
âˆ’
â¡
â£âˆ‡f (x0) +
m

i=1
uiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0)
â¤
â¦âˆˆ(T (K6, x0)âˆ—\ (L(x0))âˆ—âˆª{0} .
More recently, a fruitful approach to get necessary optimality conditions for (P6)
has been presented by Bertsekas [2] and Bertsekas and Ozdaglar [3]. These two last
authors consider, for a closed set C âŠ‚Rn and a point x0 âˆˆC, the Mordukhovich
normal cone (see. e.g. Aubin and Frankowska [41], Rockafellar and Wets [42],
Borwein and Lewis [43]; for the case of C âŠ‚Rn closed, the deï¬nitions of these
authors coincide with the following deï¬nition):
NM(C, x0) =
	 y âˆˆRn : âˆƒ

xk
âŠ‚C, âˆƒ

yk
, xk â†’x0,
yk â†’y : yk âˆˆ(T (C, xk))âˆ—, âˆ€k âˆˆN

.
Equivalently, the graph of NM(C, Â·), viewed as a point-to-set mapping, {(x, y) :
y âˆˆNM(C, x)} is the closure of the graph of (T (C, Â·))âˆ—. In general we have
(T (C, x0))âˆ—âŠ‚NM(C, x0) for every x0 âˆˆC.
The Mordukhovich normal cone is closed, however it may not be equal to
(T (C, x0))âˆ—, and in fact it may not even be a convex set. In the case where
(T (C, x0))âˆ—= NM(C, x0)
we say that C is regular at x0. Two important properties of the regularity are:
(i) If C is convex, then it is regular at each x âˆˆC.
(ii) If C is regular at some x âˆˆC, then T (C, x) is convex.
The Mordukhovich normal cone is also called the limiting or basic normal cone (to
C at x0). In this context the polar of the Bouligand tangent cone is called the FrÃ©chet

218
6
Constrained Optimization Problems with Mixed Constraints
normal cone or also the regular normal cone (to C at x0) and denoted by NF(C, x0).
It can be shown that
NF(C, x0) â‰¡(T (C, x0))âˆ—=
%
v âˆˆRn : lim sup
xâ†’x0,xâˆˆC
vâŠ¤(x âˆ’x0)
x âˆ’x0 â‰¦0
&
.
We have seen that, in general, it is not possible to obtain necessary Fritz John-type
necessary conditions for (P6) by using the polar of the Bouligand tangent cone (i.e.
the FrÃ©chet normal cone). It is however possible to use the Mordukhovich normal
cone.
We now assume that all functions involved in (P6) are continuously differentiable
on the open set X âŠ‚Rn. One of the basic results of Bertsekas and Ozdaglar [3] is
the following one. For further considerations, see also Ozdaglar and Bertsekas [44].
Theorem 6.53 Let x0 âˆˆK6 be a local solution of (P6). Then, there exist scalars u0,
u1, . . . , um and v1, . . . , vp, satisfying the following conditions:
(i) âˆ’

u0âˆ‡f (x0) + m
i=1 uiâˆ‡gi(x0) + p
j=1 v jâˆ‡h j(x0)

âˆˆNM(C, x0);
(ii) ui â‰§0, for alli = 0, 1, . . . , m;
(iii) u0, u1, . . . , um, v1, . . . , vp, are not all equal to zero;
(iv) If the index set I âˆªJ, where I = {i Ì¸= 0 : ui > 0} and J =

j : v j Ì¸= 0

, is
nonempty, there exists a sequence

xk
âŠ‚C that converges to x0 and is such
that, for all k,
f (xk) < f (x0), v jh j(xk) > 0, âˆ€j âˆˆJ, uigi(xk) > 0, âˆ€i âˆˆI,
''h j(xk)
'' = o(w(xk)), âˆ€j /âˆˆJ,
g+
i (xk) = o(w(xk)), âˆ€i /âˆˆI,
where
w(x) = min
	
min
jâˆˆJ
''h j(x)
'' , min
iâˆˆI gi(x)

,
g+
i (x) = max {0, gi(x)} .
Note that if C is regular at x0, i.e. NM(C, x0) = (T (C, x0))âˆ—, condition (i) of
Theorem 6.53 becomes
âˆ’
â¡
â£u0âˆ‡f (x0) +
m

i=1
uiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0)
â¤
â¦âˆˆ(T (C, x0))âˆ—
or, equivalently,

6.4 Problems with a Set Constraint. Asymptotic Optimality Conditions
219
â¡
â£u0âˆ‡f (x0) +
m

i=1
uiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0)
â¤
â¦
âŠ¤
y â‰§0, âˆ€y âˆˆT (C, x0)
and if C is convex (and hence regular at each its point), the previous relation becomes
â¡
â£u0âˆ‡f (x0) +
m

i=1
uiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0)
â¤
â¦
âŠ¤
(x âˆ’x0) â‰§0, âˆ€x âˆˆC.
It must be noted that conditions (iv) are stronger than the usual complementary
slackness conditions, i.e. they imply these last ones. If ui > 0, then according to con-
dition (iv), the corresponding i-th inequality constraint must be violated arbitrarily
close to x0, implying that gi(x0) = 0. Bertsekas and Ozdaglar [3] call conditions
(iv) complementary violation conditions, as these further conditions state that the
constraints for which the multipliers are zero are also violated but their â€œdegree of
violationâ€ is arbitrarily small. Moreover, the value of the objective function at such
nearby points is also strictly less than f (x0). This fact has important consequences
for the use of numerical methods, such as â€œpenalty techniquesâ€. See also Bector et
al. [45] who reformulate Theorem 6.53 in a nonsmooth setting.
For what concerns conditions which assure that in Theorem 6.53 it holds u0 > 0,
i.e. u0 = 1, one of them is the following one (see, e.g. Ruszczynsky [46]:
â€¢ C is a closed convex set and there exists a point Ë†x âˆˆint(C) such that, with x0 âˆˆK6,
âˆ‡gi(x0)âŠ¤(Ë†x âˆ’x0) < 0, âˆ€i âˆˆI (x0),
âˆ‡h j(x0)âŠ¤(Ë†x âˆ’x0) = 0, âˆ€j = 1, . . . , p,
and the gradients âˆ‡h j(x0), j = 1, . . . , p, are linearly independent.
Another one is a generalization of the Slater constraint qualiï¬cation:
â€¢ C is a closed convex set, the functions gi, i = 1, . . . , m, are convex on C, the
functions h j, j = 1, . . . , p, are linear afï¬ne, and there exists a feasible point Ë†x
such that Ë†x âˆˆint(C) and gi(Ë†x) < 0, i = 1, . . . , m.
We conclude the present section with some considerations on asymptotic optimality
conditionsfor(P5). The characterization of a local solution of a constrained opti-
mization problem has traditionally be given, as in the present section and in the
previous sections, in terms of the functions involved in the problem, put together to
form an associated Lagrangian function, whose gradient is evaluated at the solution
point for a corresponding set of ï¬nite multipliers (Lagrange multipliers, Fritz John
multipliers, Karush-Kuhn-Tucker multipliers). Besides this classical approach, other
treatments of constrained optimality conditions give a characterization of optimality
in terms of appropriate sequences of points and multipliers. In this case, we can
speak of â€œasymptotic optimality conditionsâ€ or â€œapproximate optimality conditionsâ€
or also â€œsequential optimality conditionsâ€. There are some quite recent papers on

220
6
Constrained Optimization Problems with Mixed Constraints
this second approach in studying optimality conditions for a problem of the type of
(P5). We quote only Andreani, MartÃ­nez and Svaiter [47] and Haeser and Schuverdt
[48]. We have to say that, prior to these contributions, the question was considered
in an unpublished paper of Fiacco and McCormick, already quoted in the previous
section (A. V. Fiacco and G. P. McCormick, Asymptotic conditions for constrained
Minimization, RAC-PTP-340, Research Analysis Corporation, McLean, Virginia).
We give a short account of the asymptotic optimality conditions for (P5) given by
Haeser and Schuverdt [48]. Following these authors, we assume that all functions
involved in (P5) are continuously differentiable on the open set X âŠ‚Rn.
Deï¬nition 6.54 We say that the Asymptotic or Approximate Karush-Kuhn-Tucker
Condition (AKKT) is satisï¬ed at x0 âˆˆK5 if, and only if, there exist sequences

xk
âŠ‚
Rn,

uk
âŠ‚Rm
+ and

vk
âŠ‚Rp, such that xk â†’x0,
âˆ‡f (xk) +
m

i=1
uk
i âˆ‡gi(xk) +
p

j=1
vk
jâˆ‡h j(xk) â†’0
(6.30)
and
for i = 1, . . . , m :

gi(x0) < 0 â‡’uk
i = 0 for sufï¬ciently large k

.
(6.31)
It must be noted that (AKKT) implies the usual Karush-Kuhn-Tucker conditions
for (P5) under the Constant Positive Linear Dependence c. q. (CPLD) (see Sect. 6.2,
p. 189):
â€¢ (CPLD) holds at x0 âˆˆK5 if there exists a neighborhood N(x0) of x0 such that for
I âŠ‚I (x0) and J âŠ‚{1, . . . , p} , whenever the gradients

âˆ‡gi(x0), i âˆˆI; âˆ‡h j(x0), j âˆˆJ

are positive-linearly dependent, then

âˆ‡gi(x), i âˆˆI; âˆ‡h j(x), j âˆˆJ

are linearly
dependent for every x âˆˆN(x0).
(CPLD) is a constraint qualiï¬cation weaker than the Mangasarian-Fromovitz c. q.;
moreover, (CPLD) is also implied by the Constant Rank Constraint Qualiï¬cation
at x0 âˆˆK5.
Note, moreover, that if x0 âˆˆK5 is a local minimum point for (P5) and any con-
straint qualiï¬cation holds at x0, then (AKKT) holds at x0 for constant sequences
xk = x0, uk = u, vk = v, being u âˆˆRm
+ and v âˆˆRp.
Haeser and Schuverdt [48] prove the following basic result, which is a special
case of a more general result of Andreani et al. [49].
Theorem 6.55 If x0 âˆˆK5 is a local minimum point for (P5), then x0 satisï¬es the
(AKKT) conditions (6.30)â€“(6.31).
The same authors prove that a stronger version of the (AKKT) conditions is
sufï¬cient for optimality in the case (P5) is a convex problem.

6.4 Problems with a Set Constraint. Asymptotic Optimality Conditions
221
Deï¬nition 6.56 A point x0 âˆˆK5 satisï¬es the strong (AKKT) condition (SAKKT) if
there exist sequences

xk
âŠ‚Rn,

uk
âŠ‚Rm
+ and

vk
âŠ‚Rp such that (6.30) holds
and
gi(xk) < 0 â‡’uk
i = 0.
We note that every local minimizer of (P5) satisï¬es also (SAKKT).
Theorem 6.57 Let in (P5) f and every gi, i = 1, . . . , m, be convex functions on the
open convex set X âŠ‚Rn and let every h j, j = 1, . . . , p, be linear afï¬ne. If x0 âˆˆK5
satisï¬es (SAKKT) and if the sequences

xk
,

vk
are such that vk
jh j(xk) â‰§0 for
every j = 1, . . . , p, and every k âˆˆN, then x0 is a solution of (P5).
Remark
In this chapter and in the previous ones, we have used local â€œï¬rst-orderâ€ cone approx-
imations in obtaining ï¬rst-order and second-order optimality conditions. However,
it is possible to use (local) second-order tangent sets and (local) second-order tan-
gent cones in order to obtain more accurate second-order optimality conditions. The
literature on these questions is by now rather abundant; we quote only the works
of Bonnans, Cominetti, and Shapiro [50], Bonnans and Shapiro [28], Cambini et
al. [51], Cominetti [52], Giorgi et al. [53], Hachimi and Aghezzaf [54], JimÃ©nez
and Novo [55, 56], Haeser and Ramos [57], Penot [58], Ruszczynski [46]. In the
said works, there are obviously many bibliographical references useful to deepen the
questions. Here, we give only few hints.
â€¢ The set
T 2(S, x0, v) =
	 z âˆˆRn : âˆƒzk â†’z, âˆƒtk â†’0+, with
x0 + tkv + 1
2t2
k zk âˆˆS, âˆ€k âˆˆN

is called second-order tangent set to S âŠ‚Rn at x0 âˆˆcl(S) and v âˆˆRn.
â€¢ The cone
T â€²â€²(S, x0, v) =
	 z âˆˆRn : âˆƒ(tk,rk) â†’(0+, 0+), âˆƒzk â†’z, such that
(tk/rk) â†’0 and x0 + tkv + 1
2tkrkzk âˆˆS, âˆ€k âˆˆN

is called asymptotic second-order tangent cone to S âŠ‚Rn at x0 âˆˆcl(S) and
v âˆˆRn.
It must be observed that T 2(S, x0, v) and T â€²â€²(S, x0, v) are closed sets and that
T â€²â€²(S, x0, v) is indeed a cone. Furthermore, if v /âˆˆT (S, x0), then T 2(S, x0, v) =
T â€²â€²(S, x0, v) = âˆ…; we have also T 2(S, x0, 0) = T â€²â€²(S, x0, 0) = T (S, x0). In gen-
eral, the second-order tangent set T 2(S, x0, v) is not a cone and it may not be con-
vex even for a convex set S âŠ‚Rn. However, if S âŠ‚Rn is convex and v âˆˆT (S, x0),
then
T â€²â€²(S, x0, v) = cl

cone

cone(S âˆ’x0) âˆ’v


222
6
Constrained Optimization Problems with Mixed Constraints
and
T 2(S, x0, v) âŠ‚T â€²â€²(S, x0, v).
See JimÃ©nez and Novo [56].
By means of T 2(S, x0, v) and T â€²â€²(S, x0, v) it is possible to obtain second-order
optimality conditions for scalar and for vector optimization problems. For exam-
ple, we have the following results (see, e.g. JimÃ©nez and Novo [56], Penot [58],
Ruszczynski [46]).
â€¢ Consider problem (P2), i.e.
min f (x), x âˆˆS âŠ‚Rn,
with f : Rn â†’R twice-continuously differentiable. Assume that x0 âˆˆS is a local
optimal solution of (P2). Then, for every v âˆˆT (S, x0) such that âˆ‡f (x0)âŠ¤v = 0,
we have the following optimality conditions:
(a) âˆ‡f (x0)âŠ¤z + vâŠ¤âˆ‡2 f (x0)v â‰§0, âˆ€z âˆˆT 2(S, x0, v).
(b) âˆ‡f (x0)âŠ¤z â‰§0, âˆ€z âˆˆT â€²â€²(S, x0, v).
â€¢ Let f : Rn â†’R be twice-continuously differentiable, let x0 âˆˆS. If for every v âˆˆ
T (S, x0) \ {0} such that âˆ‡f (x0)âŠ¤v = 0, one of the following conditions holds:
(a) âˆ‡f (x0)âŠ¤z + vâŠ¤âˆ‡2 f (x0)v > 0, âˆ€z âˆˆT 2(S, x0, v) âˆ©vâŠ¥.
(b) âˆ‡f (x0)âŠ¤z > 0, âˆ€z âˆˆT â€²â€²(S, x0, v) âˆ©vâŠ¥,
where vâŠ¥denotes the orthogonal subspace to v, then x0 is a strict local minimum
point for (P2); more precisely, it is a strict local minimum point of order 2 (see
JimÃ©nez and Novo [56]).
References
1. E.J. McShane, The Lagrange multiplier rule. Am. Math. Mon. 80, 922â€“925 (1973)
2. D.P. Bertsekas, Nonlinear Programming, 2nd edn. (Athena Scientiï¬c, Belmont, Mass, 1999)
3. D.P. Bertsekas, A.E. Ozdaglar, Pseudonormality and Lagrange multiplier theory for constrained
optimization. J. Optim. Theory Appl. 114, 287â€“343 (2002)
4. M. Guignard, Generalized Kuhn-Tucker conditions for mathematical programming problems
in a Banach space. SIAM J. Control 7, 232â€“241 (1969)
5. F.J. Gould, J.W. Tolle, A necessary and sufï¬cient qualiï¬cation for constrained optimization.
SIAM J. Appl. Math. 20, 164â€“172 (1971)
6. K.J. Arrow, L. Hurwicz, H. Uzawa, Constraint qualiï¬cations in maximization problems. Naval
Res. Logist. 8, 175â€“191 (1961). Reprinted in Giorgi and Kjeldsen (2014)
7. M. Avriel, Nonlinear Programming. Analysis and Methods (Prentice-Hall, Englewood Cliffs,
N.J., 1976)
8. W. Forst, D. Hoffmann, Optimization. Theory and Practice (Springer, New York, 2010)
9. O.L. Mangasarian, Nonlinear Programming (McGraw-Hill Book Company, New York, 1969)
10. B. Martos, Nonlinear Programming. Theory and Methods (North Holland, Amsterdam, 1975)

References
223
11. G. Still, M. Streng, Optimality conditions in smooth nonlinear programming. J. Optim. Theory
Appl. 90, 483â€“515 (1996)
12. M.R. Hestenes, Optimization Theory. The Finite Dimensional Case (Wiley, New York, 1975)
13. G. Giorgi, B. JimÃ©nez, V. Novo, A note on ï¬rst-order conditions for Pareto problems. Numer.
Funct. Anal. Optim. 29, 1108â€“1113 (2008)
14. M.S. Bazaraa, C.M. Shetty, Foundations of Optimization, Lecture Notes in Economic and
Mathematics Systems, vol. 122 (Springer, Berlin, 1976)
15. R. Janin, Directional derivative of the marginal function in nonlinear programming. Sensitivity,
stability and parametric analysis. Math. Program. Study 21, 110â€“126 (A.V. Fiacco Ed.) (1984)
16. L. Qi, Z. Wei, On the constant positive linear dependence condition and its application to SQP
methods. SIAM J. Optim. 10, 963â€“981 (2000)
17. R. Andreani, J.M. Martinez, M.L. Schuverdt, On the relation between constant positive linear
dependence condition and quasinormality constraint qualiï¬cations. J. Optim. Theory Appl.
125, 473â€“483 (2005)
18. J. Gauvin, A necessary and sufï¬cient regularity condition to have bounded multipliers in
nonconvex programming. Math. Program. 12, 136â€“138 (1977)
19. J. Kyparisis, On uniqueness of Kuhn-Tucker multipliers in nonlinear programming. Math.
Program. 32, 242â€“246 (1985)
20. G. Haeser, A. Ramos, CondiÃ§Ãµes de Otimalidade e Algoritmos em OptimizaÃ§Ã£o nÃ£o Linear
(Sociedade Brasileira de Matematica Aplicada e Computational, SÃ£o Carlos, Brasil (available
on the web, 2016)
21. G.P. Mccormick, Second order conditions for constrained minima. SIAM J. Appl. Math. 15,
641â€“652 (1967). Reprinted in Giorgi and Kjeldsen (2014)
22. A.V. Fiacco, G.P. Mccormick, Nonlinear Programming: Sequential Unconstrained Minimiza-
tion Techniques (Wiley, New York, 1968)
23. Y. Chabrillac, J.-P. Crouzeix, Deï¬niteness and semi-deï¬niteness of quadratic forms revisited.
Linear Algebra Appl. 63, 283â€“292 (1984)
24. G. Debreu, Deï¬nite and semideï¬nite quadratic forms. Econometrica 20, 285â€“300 (1952)
25. G.P. McCormick, Optimality criteria in nonlinear programming, in Nonlinear Programming,
eds. by R.W. Cottle, C.E. Lemke. SIAM-AMS Proceedings, vol. IX (American Mathematical
Society, Providence, RI, 1976), pp. 27â€“38
26. G.P. McCormick, Nonlinear Programming. Theory, Algoritms and Applications (Wiley, New
York, 1983)
27. A. Ben-Tal, Second-order and related extremality conditions in nonlinear programming. J.
Optim. Theory Appl. 31, 143â€“165 (1980)
28. J.F. Bonnans, A. Shapiro, Perturbation Analysis of Optimization Problems (Springer, New
York, 2000)
29. A.V. Arutyunov, Perturbations of extremum problems with constraints and necessary optimality
conditions. J. Sov. Math. 54, 1342â€“1400 (1991)
30. M. Anitescu, Degenerate nonlinear programming with a quadratic growth condition. SIAM J.
Optim. 10, 1116â€“1135 (2000)
31. R. Andreani, L.E. EchagÃ¼e, ML. Schuverdt, Constant-rank condition and second-order con-
straint qualiï¬cation. J. Optim. Theory Appl. 146, 255â€“266 (2010)
32. S.M. Robinson, Strongly regular generalized equations. Math. Oper. Res. 5, 43â€“62 (1980)
33. T.K. Kelly, M. Kupferschmid, Numerical veriï¬cation of second-order sufï¬ciency conditions
for nonlinear programming, SIAM Rev. 40, 310â€“314 (1998)
34. S.M. Robinson, Generalized equations and their solutions, Part II: Applications to nonlinear
programming. Math. Program. Study 19, 200â€“221 (1982)
35. A.V. Fiacco, Introduction to Sensitivity and Stability Analysis in Nonlinear Programming (Aca-
demic, New York, 1983)
36. D.E. Ward, Characterizations of strict local minima and necessary conditions for weak sharp
minima. J. Optim. Theory Appl. 80, 551â€“571 (1994)
37. M.S. Bazaraa, J.J. Goode, Necessary optimality criteria in mathematical programming in the
presence of differentiability. J. Math. Anal. Appl. 40, 609â€“621 (1972)

224
6
Constrained Optimization Problems with Mixed Constraints
38. G. Giorgi, A. Guerraggio, First order generalized optimality conditions for programming prob-
lems with a set constraint, in Generalized Convexity. Proceedings of the IV International Work-
shop on Generalized Convexity, eds. by S. Komlosi, T. Rapcsak, S. Schaible (P Ã©cs, Hungary,
Springer, Berlin, 1994), pp. 171â€“185
39. G. Giorgi, B. JimÃ©nez, V. Novo, Minimum principle-type optimality conditions for Pareto
problems. Int. J. Pure Appl. Math. 10, 51â€“68 (2004)
40. F.J. Gould, J.W. Tolle, Geometry of optimality conditions and constraint qualiï¬cations. Math.
Program. 2, 1â€“18 (1972)
41. J.P. Aubin, H. Frankowska, Set-Valued Analysis (BirkhÃ¤user, Boston, 1990)
42. R.T. Rockafellar, R.J.-B. Wets, Variational Analysis (Springer, Berlin, 2009)
43. J.M. Borwein, A.S. Lewis, Convex Analysis and Nonlinear Optimization (Springer, New York,
2000)
44. A.E. Ozdaglar, D.P. Bertsekas, The relation between pseudonormality and quasiregularity in
constrained optimization. Optim. Methods Soft. 19, 493â€“506 (2004)
45. C.R. Bector, S. Chandra, J. Dutta, Principles of Optimization Theory (Alpha Science Interna-
tional Ltd., Harrow, U. K., 2005)
46. A. Ruszczynski, Nonlinear Optimization (Princeton University Press, Princeton, 2006)
47. R. Andreani, J.M. Martinez, B.F. Svaiter, A new sequential optimality condition for constrained
optimization and algorithmic consequences. SIAM J. Optim., 20, 3533â€“3554 (2010)
48. G. Haeser, M.L. Schuverdt, On approximate KKT condition and its extension to continuous
variational inequalities. J. Optim. Theory Appl. 149, 528â€“539 (2011)
49. R. Andreani, G. Haeser, J.M. Martinez, On sequential optimality conditions for smooth con-
strained optimization. Optimization 60, 627â€“641 (2011)
50. J.F. Bonnans, R. Cominetti, A. Shapiro, Second-order optimality conditions based on parabolic
second-order tangent sets. SIAM J. Optim. 9, 466â€“492 (1999)
51. A. Cambini, L. Martein, M. Vlach, Second-order tangent sets and optimality conditions. Math.
Japonica 49, 451â€“461 (1999)
52. R. Cominetti, Metric regularity, tangent sets and second-order optimality conditions. Appl.
Math. Optim. 21, 265â€“287 (1990)
53. G. Giorgi, B. JimÃ©nez, V. Novo, An overview of second order tangent sets and their application
to vector optimization. Bol. Soc. Esp. Mat. Apl. 52, 73â€“96 (2010)
54. M. Hachimi, B. Aghezzaf, New results on second-order optimality conditions in vector opti-
mization problems. J. Optim. Theory Appl. 135, 117â€“133 (2007)
55. B. JimÃ©nez, V. Novo, Second order necessary conditions in set constrained differentiable vector
optimization. Math. Meth. Oper. Res. 58, 299â€“317 (2003)
56. B. JimÃ©nez, V. Novo, Optimality conditions in differentiable vector optimization via second-
order tangent sets. Appl. Math. Optim. 49, 124â€“144 (2004)
57. G. Haeser, A. Ramos, New constraint qualiï¬cations with second-order properties in nonlinear
optimization. J. Optim. Theory Appl. 184, 494â€“506 (2020)
58. J.-P. Penot, Second order conditions for optimization problems with constraints. SIAM J.
Control Optim. 37, 303â€“318 (1998)

Chapter 7
Sensitivity Analysis
7.1
General Results
An important area of applications of optimality conditions is concerned with ques-
tions arising from sensitivity analysis of nonlinear programming problems. In many
applications, the objective function f, as well as the constraints gi, i = 1, . . . , m,
and h j, j = 1, . . . , p, may depend also on certain number of parameters. For some
of these applications the optimal solution xâˆ—of the unperturbed problem (i.e. with
ï¬xed values of the parameters) may be of less interest than its sensitivity with respect
to changes in the parameters. In other words, one may ask: how does the solution of
the problem change as a function of the changes in the values of the parameters?
In mathematical programming the term â€œsensitivity analysisâ€ is usually referred
to all those investigations concerned in what happens to a solution of a mathematical
programming problem, containing a certain number of parameters, when there are
changes in the problem data. If we start from the usual formulation of (P5), i. e.
(P5) :
â§
â¨
â©
min f (x)
subject to: gi(x) â‰¦0, i = 1, . . . , m,
h j(x) = 0, j = 1, . . . , p < n,
with f, gi, i = 1, . . . , m; h j, j = 1, . . . , p, real-valued functions deï¬ned on an
open set X âŠ‚Rn, the parametric version of (P5) is the following problem, where
we explicitly introduce a vector Îµ âˆˆRk, that represents the parameters subject to
modiï¬cations:
(P5(Îµ)) :
â§
âªâªâ¨
âªâªâ©
min f (x, Îµ)
subject to: gi(x, Îµ) â‰¦0, i = 1, . . . , m,
h j(x, Îµ) = 0, j = 1, . . . , p < n,
x âˆˆX âŠ‚Rn, Îµ âˆˆRk.
Â© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al., Basic Mathematical Programming Theory, International Series
in Operations Research & Management Science 344,
https://doi.org/10.1007/978-3-031-30324-1_7
225

226
7
Sensitivity Analysis
When Îµ = Îµâˆ—is ï¬xed, the parametric problem (P5(Îµâˆ—)) becomes a standard non-
linear programming problem, only formally different from (P5).
We are interested in the analysis of the solutions x(Îµ) of (P5(Îµ)), in the analysis
of the optimal value function (called also the marginal function or the perturbation
function) f âˆ—(Îµ) = f [x(Îµ), Îµ] and in other questions on (P5(Îµ)).
We follow mainly the classical approach of [1] and his collaborators. For other
morerecentandmoresophisticatedapproachestosensitivityanalysisinoptimization,
one can consult the book of [3].
Throughoutthepresentchapterwemaketheassumptionthatallfunctionsinvolved
in (P5(Îµ)) are twice jointly continuously differentiable with respect to (x, Îµ) over
X Ã— Rk. It will be clear when this assumption is not necessary.
In the present chapter we adopt the conventions and notations of [1]:
â€¢ The vectors of Rn are again considered column vectors, but the gradient of a
function f : Rn â†’R is considered a row vector of Rn. Consequently the Jacobian
matrix âˆ‡f (x) of a function f : Rn â†’R is a (m, n) order matrix whose rows are
the gradients of the components of f.
â€¢ âˆ‡Îµx(Îµ) is an (n, k) matrix:
âˆ‡Îµx(Îµ) =
â¡
â¢â£
âˆ‡Îµx1(Îµ)
...
âˆ‡Îµxn(Îµ)
â¤
â¥â¦.
â€¢ âˆ‡Îµy(Îµ) is an (n + m + p, k) matrix representing the Jacobian of the Karush-Kuhn-
Tucker triplet (x(Îµ), u(Îµ), v(Îµ)) taken with respect to the parameter vector:
âˆ‡Îµy(Îµ) =
â¡
â£
âˆ‡Îµx(Îµ)
âˆ‡Îµu(Îµ)
âˆ‡Îµv(Îµ)
â¤
â¦.
â€¢ âˆ‡2
xL (x, u, v, Îµ) is the Hessian matrix of order n, of the Lagrangian function
L (x, u, v, Îµ), with respect to x.
â€¢ âˆ‡2
Îµ f âˆ—(Îµ) is the Hessian matrix, of order k, of f âˆ—(x, Îµ), with respect to Îµ.
â€¢ M(Îµ) is the Jacobian matrix of order (n + m + p) of the Karush-Kuhn-Tucker
conditions, with respect to (x, u, v).
â€¢ N(Îµ) is the Jacobian matrix of order (k, n + m + p) of the Karush-Kuhn-Tucker
conditions, with respect to Îµ.
â€¢ âˆ‡2
ÎµxL (x, u, v, Îµ) is the matrix of order (n, k) given by
â¡
â¢â£
âˆ‡Îµ(âˆ‚L /âˆ‚x1)
...
âˆ‡Îµ(âˆ‚L /âˆ‚xn)
â¤
â¥â¦.

7.1 General Results
227
â€¢ âˆ‡2
xÎµL (x, u, v, Îµ) is the matrix of order (k, n), whose (i, j) element is given by
(âˆ‚2L (x, u, v, Îµ)/âˆ‚x jâˆ‚Îµi), for i = 1, . . . , k and j = 1, . . . , n. Hence âˆ‡2
ÎµxL =
(âˆ‡2
xÎµL )âŠ¤.
First, we spend some words for the unconstrained case. Let us consider an uncon-
strained parametric problem of the type
(P1(Îµ)) :
min f (x, Îµ),
with x âˆˆX âŠ‚Rn, X open set, Îµ âˆˆRk, f twice jointly continuously differentiable
with respect to (x, Îµ) on X Ã— Rk. We have the following basic results. Let Îµ = Îµâˆ—a
ï¬xed vector and let xâˆ—âˆˆX.
Theorem 7.1 If âˆ‡x f (xâˆ—, Îµâˆ—) = 0 and âˆ‡2
x f (xâˆ—, Îµâˆ—) is positive deï¬nite (Second-
Order Sufï¬cient Optimality Conditions), then xâˆ—is a strict and locally isolated
minimizer of f (x, Îµâˆ—).
This last one is a well-known result (see Theorems 4.10 and 6.46) and the related
sensitivity results follow without additional assumptions.
Theorem 7.2 Assume that the Second-Order Sufï¬cient Optimality Conditions
(SOSOC) of Theorem 7.1 hold at (xâˆ—, Îµâˆ—). Then, for Îµ near Îµâˆ—there exists a
unique once continuously differentiable vector function x(Îµ) such that x(Îµâˆ—) = xâˆ—
and the (SOSOC) continue to hold at (x(Îµ), Îµ) and hence x(Îµ) is a locally unique
(i.e. isolated) local minimizer of f (x, Îµ). Furthermore, the optimal value function
f âˆ—(Îµ) = f [x(Îµ), Îµ] is twice continuously differentiable.
The previous result which follows directly from the classical implicit function
theorem, guarantees that the assumptions made at (xâˆ—, Îµâˆ—) will persist near (xâˆ—, Îµâˆ—)
at [x(Îµ), Îµ] , hence also the conclusions. It is possible, without any new assumptions
respect to the ones made in the previous theorem, to obtain sensitivity formulas for
the optimal value function.
Theorem 7.3 Assuming as in Theorem 7.1 and with x(Îµ) as in Theorem 7.2, it hold
the following relations at [x(Îµ), Îµ] near (xâˆ—, Îµâˆ—) :
(i) From the chain rule for differentiation we have
âˆ‡Îµ f âˆ—(Îµ) = d
dÎµ f [x(Îµ), Îµ]
= âˆ‡x f (x, Îµ)âˆ‡Îµx(Îµ) + âˆ‡Îµ f (x, Îµ) = âˆ‡Îµ f (x, Îµ)
x=x(Îµ)
since âˆ‡x f [x(Îµ), Îµ] = 0, where F(y)
y=z means to evaluate F at y = z. With
this understanding, we get
âˆ‡Îµ f âˆ—(Îµ) = âˆ‡Îµ f [x(Îµ), Îµ] .
(7.1)

228
7
Sensitivity Analysis
(ii) Differentiating this last result again by Îµ, we ï¬nd that
âˆ‡2
Îµ f âˆ—(Îµ) = âˆ‡2
xÎµ f (x, Îµ)âˆ‡Îµx(Îµ) + âˆ‡2
Îµ f (x, Îµ)
x=x(Îµ) .
The result in (7.1) is called in Economic Analysis â€œenvelope theoremâ€ (similarly
for a constrained optimization problem) and has some interesting applications in
utility theory, production theory, etc. See, e.g., [2, 4â€“7]. The term â€œenvelope theoremâ€
derives from the fact (see, e.g. [8], p. 342) that, given a one-dimensional parametrized
family of curves, fÎ± : [0, 1] â†’R, where Î± runs over some interval, a curve h :
[0, 1] â†’R is the envelope of the family if each point on the curve h is tangent to one
of the curves fÎ± and each curve fÎ± is tangent to h. That is, for each Î±, there is some
t and also for each t, there is some Î±, satisfying fÎ±(t) = h(t) and f â€²
Î±(t) = hâ€²(t).
We may state informally the envelope theorem by saying that under appropriate
conditions the graph of the optimal value function is the envelope of the family of
graphs of f (x, Îµ).
We now consider the parametric problem (P5(Îµ)) and we give for this problem
some basic sensitivity results, taken from the book of [1]. The reader must be aware
that there are many other results concerning sensitivity and stability for mathematical
programming problems (see, besides [1, 9]) and the more advanced book of [3]).
Especially for Linear Programming Problems, where sensitivity and stability analysis
is often referred to as postoptimal analysis, there is a huge literature, concerning also
algorithmic questions.
We denote by K5(Îµ) the feasible set of (P5(Îµ)) and we assume that the functions
deï¬ning (P5(Îµ)) are twice jointly continuously differentiable in (x, Îµ).
For the readerâ€™s convenience we recall the two basic second-order optimality
conditions for the non-parametric problem (P5), previously given in Chap. 6, i.e.
the second-order necessary optimality conditions and the second-order sufï¬cient
optimality conditions that will be used in the present section.
Theorem 7.4 (Second-ordernecessaryoptimalityconditions)Supposethat xâˆ—âˆˆK5
is a local minimum point of (P5(0)), i.e. of (P5), and that the Linear Independence
Constraint Qualiï¬cation holds at xâˆ—, i.e. the gradients

âˆ‡xgi(xâˆ—), i âˆˆI (xâˆ—); âˆ‡xh j(xâˆ—), j = 1, . . . , p

,
are linearly independent. Then the Karush-Kuhn-Tucker conditions hold at xâˆ—with
associated unique Karush-Kuhn-Tucker multipliers u and v, and the additional
(usual) second-order necessary conditions hold at xâˆ—, with multipliers (u, v) :
zâŠ¤âˆ‡2
xL (xâˆ—, u, v)z â‰§0, âˆ€z âˆˆZ(xâˆ—),
where Z(xâˆ—) is the critical cone (see also page 201) given by

7.1 General Results
229
Z(xâˆ—) =
â§
â¨
â©
z âˆˆRn : âˆ‡xgi(xâˆ—)z â‰¦0, âˆ€i âˆˆI (xâˆ—) \ I +(xâˆ—, u),
âˆ‡xgi(xâˆ—)z = 0, âˆ€i âˆˆI +(xâˆ—, u),
âˆ‡xh j(xâˆ—)z = 0, âˆ€j = 1, . . . , p
â«
â¬
â­.
We recall that I +(xâˆ—, u) denotes the set of strictly active constraints at xâˆ—, i.e.
I +(xâˆ—, u) =

i âˆˆI (xâˆ—) : ui > 0 in the (KKT) conditions

.
By strengthening the previous conditions one obtains the following standard
second-order sufï¬cient conditions for local strict optimality of xâˆ—âˆˆK5.
Theorem 7.5 (Second-order sufï¬cient optimality conditions). Suppose that the
Karush-Kuhn-Tucker conditions hold at xâˆ—âˆˆK5 with associated multipliers u and
v, and that the following second-order sufï¬cient conditions hold at xâˆ—:
zâŠ¤âˆ‡2
xL (xâˆ—, u.v)z > 0, âˆ€z Ì¸= 0, z âˆˆZ(xâˆ—).
Then xâˆ—is a strict local minimum point of (P5).
The following result was originally proved for a speciï¬c class of parametric non-
linear programming problems in [10] and subsequently, with reference to (P5(Îµ)),
in [1, 11].
Theorem 7.6 Suppose that:
(i) The functions involved in (P5(Îµ)) are jointly twice continuously differentiable
on X Ã— Rk.
(ii) The second-order sufï¬cient conditions of Theorem 7.5 for (P5(0)) hold at the
feasible point xâˆ—with associated Karush-Kuhn-Tucker multipliers u and v.
(iii) The gradients âˆ‡gi(xâˆ—, 0), i âˆˆI (xâˆ—), and âˆ‡h j(xâˆ—, 0), all j, are linearly inde-
pendent (i.e. the Linear Independence c. q. holds at xâˆ—for (P5(0)).
(iv) ui > 0 when i âˆˆI (xâˆ—), i.e. strict complementary slackness holds.
Then:
(a) xâˆ—is a local isolated minimum point of problem (P5(0)) and the associated
Karush-Kuhn-Tucker multipliers u and v are unique.
(b) For Îµ in a neighborhood of 0, there exists a unique, once continuously dif-
ferentiable vector function y(Îµ) = [x(Îµ), u(Îµ), v(Îµ)]âŠ¤satisfying the second-
order sufï¬cient conditions for a local minimum of problem (P5(Îµ)) such that
y(0) = (xâˆ—, u, v)âŠ¤= yâˆ—, and hence x(Îµ) is a locally unique local minimizer of
problem (P5(Îµ)), with associated unique Karush-Kuhn-Tucker multipliers u(Îµ)
and v(Îµ).
(c) For Îµ near 0, the set of active inequalities is unchanged, strict complementary
slackness holds, and the active constraint gradients are linearly independent at
x(Îµ).

230
7
Sensitivity Analysis
Proof (Fiacco) Part (a) follows if (b) is true. It is stated separately because it is of
intrinsic interest. That xâˆ—is a strict local minimum point of (P5(0)) follows from
assumption (ii), which also implies âˆ‡L (xâˆ—, u, v, 0) = 0. The uniqueness of u and
v follows from this and assumption (ii).
The proof of (b) follows from a straightforward application of the Implicit Func-
tion Theorem to the ï¬rst-order necessary optimality conditions of (P5(Îµ)), as follows.
Assumption (ii) implies the satisfaction of the Karush-Kuhn-Tucker conditions
â§
â¨
â©
âˆ‡L (x, u, v, Îµ) = 0,
uigi(x, Îµ) = 0, i = 1, . . . , m,
h j(x, Îµ) = 0, j = 1, . . . , p
(7.2)
at (x, u, v, Îµ) = (xâˆ—, u, v, 0). Assumption (i) implies that the system of equations
(7.2) is once continuously differentiable in all the arguments; so, in particular, the
Jacobian matrix of (7.2) with respect to (x, u, v) is well deï¬ned. It follows that
assumptions (ii), (iii) and (iv) imply the existence of the inverse of this matrix at
(xâˆ—, u, v, 0) (see [12] and the next Theorem 7.7). The assumptions of the Implicit
FunctionTheoremwithrespecttotheEq.(7.2)andtheparticularsolution(xâˆ—, u, v, 0)
are satisï¬ed and we can conclude that in a neighborhood of (xâˆ—, u, v), for Îµ in a
neighborhood of 0, there exists a unique once continuously differentiable function
[x(Îµ), u(Îµ), v(Îµ)] satisfying (7.2) with [x(0), u(0), v(0)] = (xâˆ—, u, v). The satisfac-
tion of (7.2) means that for Îµ near 0, x(Îµ) is a ï¬rst-order Karush-Kuhn-Tucker point
of problem (P5(Îµ)), with associated Karush-Kuhn-Tucker multipliers u(Îµ) and v(Îµ).
To prove (c), we ï¬rst note that the active constraint set at x(0) remains the
same for Îµ near 0. This is seen immediately for the equalities h j(x(Îµ), Îµ) = 0,
since x(Îµ) satisï¬es (7.2) near Îµ = 0. For the inequalities, we have from (7.2) that
ui(Îµ)gi(x(Îµ), Îµ) = 0, i = 1, . . . , m, near Îµ = 0. If gi(x(0), 0) = 0 for some i, then
ui(0) > 0 (by strict complementary slackness), hence ui(Îµ) > 0 near Îµ = 0 by con-
tinuity of u(Îµ) and we conclude that gi(x(Îµ), Îµ) = 0. If gi(x(0), 0) < 0 for some i,
then gi(x(Îµ), Îµ) < 0 near Îµ = 0 by continuity. Therefore, deï¬ning,
B(Îµ) = {i : gi(x(Îµ), Îµ) = 0}
we have concluded that B(Îµ) = B(0) for Îµ near 0. The argument also shows that
strict complementary slackness is preserved for Îµ near 0, proving the ï¬rst part of (c).
We now show that the second-order sufï¬cient optimality conditions hold at
[x(Îµ), u(Îµ), v(Îµ)] for any Îµ near 0. We must show that there exists Î´ > 0 such
that for any Îµ such that âˆ¥Îµâˆ¥< Î´, it follows z(Îµ)âŠ¤âˆ‡2L [x(Îµ), u(Îµ), v(Îµ)] z(Îµ) >
0 for any vector z(Îµ) Ì¸= 0 such that âˆ‡gi [x(Îµ), Îµ] z(Îµ) = 0 for all i âˆˆB(0) and
âˆ‡h j [x(Îµ), Îµ] z(Îµ) = 0 for all j. This may be proved as follows. Suppose the
assumption is false. Then there must exist Îµk > 0 and zk Ì¸= 0 such that Îµk â†’
0, âˆ‡gi [x(Îµk), Îµk] zk = 0 for all i âˆˆB(0), âˆ‡h j [x(Îµk), Îµk] zk = 0 for all j and
(zk)âŠ¤âˆ‡2L [x(Îµk), u(Îµk), v(Îµk), Îµk] zk â‰¦0 for k = 1, 2, . . .
Without loss of generality, assume
zk = 1 for all k. Select a convergent sub-
sequence of

zk
, relabel the subsequence

zk
for convenience and call the limit

7.1 General Results
231
Â¯z. Taking limits as k â†’+âˆand recalling assumption (i) yields the conclusion
that Â¯zâŠ¤âˆ‡2L [xâˆ—, u, v, 0] Â¯z â‰¦0 for some Â¯z such that âˆ¥Â¯zâˆ¥= 1, âˆ‡gi(xâˆ—, 0)Â¯z = 0 for
all i âˆˆB(0) and âˆ‡h j(xâˆ—, 0)Â¯z = 0 for all j. But this is a contradiction of assump-
tion (ii) and the proof of the assertion is complete. Since it was established that
[x(Îµ), u(Îµ), v(Îµ)] uniquely solves (7.2) for Îµ near 0, it follows that x(Îµ) is a locally
unique local minimizer of (P5(Îµ)) with associated unique Karush-Kuhn-Tucker mul-
tipliers u(Îµ) and v(Îµ), completing the proof of part (b).
The preservation of strict complementary slackness was proved above. The preser-
vation of the linear independence of the (say) r + p active constraint gradients at
x(Îµ) for Îµ near 0 follows directly from the fact that an (r + p) by (r + p) Jacobian
of the system of equations deï¬ned by the constraints that are active at x(0) must be
nonsingular, along with the assumed continuity of the ï¬rst derivatives. The proof is
complete.
â–¡
References [1, 11] also show that the parameter derivatives of
y(Îµ) â‰¡[x(Ïµ), u(Îµ), v(Îµ)]âŠ¤
can be calculated: indeed (7.2) is identically satisï¬ed by this function for Îµ near 0
(under the assumptions of Theorem 7.6) and can be differentiated with respect to
Îµ to yield explicit expression for the ï¬rst partial derivatives of the vector function
y(Îµ). Since the assumptions of Theorem 7.6 imply that the Jacobian matrix of (7.2),
M(Îµ), with respect to (x, u, v), is nonsingular, one obtains
M(Îµ)âˆ‡Îµy(Îµ) + N(Îµ) = 0
from which
âˆ‡Îµy(Îµ) = âˆ’[M(Îµ)]âˆ’1 N(Îµ),
(7.3)
where
M(Îµ) =
â¡
â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â£
âˆ‡2L
âˆ‡gâŠ¤
1 Â· Â· Â· âˆ‡gâŠ¤
m âˆ‡hâŠ¤
1 Â· Â· Â· âˆ‡hâŠ¤
p
u1âˆ‡g1
g1
Â· Â· Â·
0
0
Â· Â· Â·
0
...
...
...
...
...
...
...
umâˆ‡gm
0
Â· Â· Â· gm
0
Â· Â· Â·
0
âˆ‡h1
0
Â· Â· Â·
0
0
Â· Â· Â·
0
...
...
Â· Â· Â·
...
...
...
...
âˆ‡h p
0
Â· Â· Â·
0
0
Â· Â· Â·
0
â¤
â¥â¥â¥â¥â¥â¥â¥â¥â¥â¥â¦
and
N(Îµ) =

âˆ‡2
ÎµxL âŠ¤, u1âˆ‡ÎµgâŠ¤
1 , . . . , umâˆ‡ÎµgâŠ¤
m, âˆ‡ÎµhâŠ¤
1 , . . . , âˆ‡ÎµhâŠ¤
p
âŠ¤.
Thus (7.3) provides a formula for the parameter derivatives of all components of
(x(Îµ), u(Îµ), v(Îµ)) for Îµ near 0. It also follows that âˆ‡Îµy(Îµ) is continuous near 0, so
âˆ‡Îµy(Îµ) â†’âˆ‡Îµy(0) as Îµ â†’0.

232
7
Sensitivity Analysis
The previous theorem and its consequences obviously are valid, mutatis mutandis,
if instead of the unperturbed problem (P5(0)) we consider the unperturbed problem
(P5(Îµâˆ—)) with a ï¬xed Îµâˆ—.
The next theorem, due to [12], shows that the conditions imposed in Theorem 7.6
are also essentially necessary (under appropriate regularity assumptions) for the
invertibility of the Jacobian matrix M(Îµâˆ—).
Theorem 7.7 (i) Suppose that xâˆ—âˆˆK5(Îµ) satisï¬es the second-order necessary opti-
mality conditions of Theorem 7.4 for a local minimum point of (P5(Îµâˆ—)), with associ-
ated Karush-Kuhn-Tucker multipliers (u, v), and suppose that M(Îµâˆ—) has an inverse.
Then, the second-order sufï¬cient optimality conditions of Theorem 7.5 hold, the strict
complementary slackness conditions hold and the linear independence condition
holds.
(ii) If the second-order sufï¬cient optimality conditions of Theorem 7.5 hold for
(P5(Îµâˆ—)), with associated Karush-Kuhn-Tucker multipliers (u, v), the strict comple-
mentary slackness conditions hold and the linear independence condition holds, then
M(Îµâˆ—) has an inverse.
We can also calculate parameter derivatives of ï¬rst- and second-order of the
local optimal value f âˆ—(Îµ) = f (x(Îµ), Îµ) of (P5(Îµ)), again by repeated use of the
chain rule. Always under the assumptions of Theorem 7.6 (KKT) conditions for
xâˆ—âˆˆK5(Îµ), Second-Order Sufï¬cient Optimality Conditions, Strict Complementary
Slackness and Linear Independence), then in a neighborhood of Îµ = Îµâˆ—, the optimal
valuefunction f âˆ—(Îµ) â‰¡f [x(Îµ), Îµ]istwicecontinuouslydifferentiable.Theâ€œoptimal
value Lagrangianâ€ is deï¬ned as
L âˆ—(Îµ) = L [x(Îµ), u(Îµ), v(Îµ), Îµ] .
We have the following results (for the proof see [1]):
(a) In a neighborhood of Îµ = 0 it holds
f âˆ—(Îµ) = L âˆ—(Îµ) = L [x(Îµ), u(Îµ), v(Îµ), Îµ] ;
(b) Since âˆ‡Îµ f âˆ—(Îµ) = âˆ‡yL âˆ‡Îµy + âˆ‡ÎµL and since it can be shown that âˆ‡yL âˆ‡Îµy =
0, it follows that
âˆ‡Îµ f âˆ—(Îµ) = âˆ‡ÎµL (x, u, v, Îµ)
(x(Îµ),u(Îµ),v(Îµ),Îµ)
= âˆ‡Îµ f +
m

i=1
ui(Îµ)âˆ‡Îµgi +
p

j=1
v j(Îµ)âˆ‡Îµh j
= âˆ‡Îµ f + u(Îµ)âŠ¤âˆ‡Îµg + v(Îµ)âŠ¤âˆ‡Îµh,
where, as usual, the vertical bar denotes evaluation at the speciï¬ed point.

7.1 General Results
233
(c)
âˆ‡2
Îµ f âˆ—(Îµ) = d
dÎµ

âˆ‡ÎµL [x(Îµ), u(Îµ), v(Îµ), Îµ]âŠ¤
= âˆ‡2
ÎµxL (x, u, v, Îµ)âŠ¤âˆ‡Îµx(Îµ) + âˆ‡Îµg(x, Îµ)âŠ¤Â· âˆ‡Îµu(Îµ)
+âˆ‡Îµh(x, Îµ)âŠ¤âˆ‡Îµv(Îµ) + âˆ‡2
Îµ L (x, u, v, Îµ)

(x(Îµ),u(Îµ),v(Îµ),Îµ) .
We give now some insights on the convexity and other properties of the optimal
value function of (P5(Îµ)), deï¬ned as
f âˆ—(Îµ) =

inf
xâˆˆK5(Îµ) f (x, Îµ) if K5(Îµ) Ì¸= âˆ…,
+âˆ
if K5(Îµ) = âˆ….
For further developments see [1, 13, 14].
If in problem (P5(Îµ)) the objective function f and every gi, i = 1, . . . , m, are
convex in x and every h j, j = 1, . . . , p, is linear afï¬ne, for any Îµ âˆˆT âŠ‚Rk, the
problem (P5(Îµ)) is said to be convex in x. If these function properties hold jointly in
(x, Îµ) and T is a convex set, then (P5(Îµ)) is said to be jointly convex.
For simplicity, for the present considerations, continuous differentiability and
continuity are assumed. The solution set S(Îµ) of (P5(Îµ)) is deï¬ned as
S(Îµ) =

x is a local solution: f (x, Îµ) = f âˆ—(Îµ)

.
We recall (see, e.g., [15]) that if F is a point-to-set mapping of E âŠ‚Rk into Rp,
then it is said that F is uniformly compact near Â¯Îµ âˆˆE if there exists a neighborhood
N(Â¯Îµ) of Â¯Îµ such that the closure of the set âˆªÎµâˆˆN(Â¯Îµ)F(Îµ) is compact.
If problem (P5(Îµ)) is convex, then any local solution is global and the solution set
is convex; moreover, if the (KKT) conditions hold at the feasible point Â¯x, then Â¯x is a
global solution. We say that the Generalized Slater Constraint Qualiï¬cation, denoted
by (GS(Îµ)), holds for the convex problem (P5(Îµ)) if there exists a feasible point Â¯x
suchthat gi(Â¯x, Îµ) < 0 foralli andsuchthatthegradientsâˆ‡xh1(Â¯x, Îµ), . . . , âˆ‡xh p(Â¯x, Îµ)
are linearly independent. For (P5(Îµ)) convex, the (MFCQ) and (GS) are equivalent
conditions.
Thefollowingpropositionscanbeproved(seethereferencestoFiaccoandKypari-
sis quoted above).
Proposition 7.8 For the once differentiable problem (P5(Îµ)) with nonempty uni-
formly compact feasible set K5(Îµ), for Îµ near Îµâˆ—, the optimal value function f âˆ—is
continuous at Îµâˆ—if the (MFCQ) holds for some x âˆˆS(Îµâˆ—).
Proposition 7.9 The optimal value function f âˆ—is convex on T if (P5(Îµ)) is jointly
convex in (x, Îµ) as deï¬ned. Assuming solution attainment, this further implies that
f âˆ—is continuous and directionally differentiable in the interior of T.
We recall that the directional derivative of f âˆ—at Îµâˆ—in the direction z âˆˆRk is

234
7
Sensitivity Analysis
Df âˆ—(Îµâˆ—, z) = lim
Î±â†’0+
f âˆ—(Îµâˆ—+ Î±z) âˆ’f âˆ—(Îµâˆ—)
Î±
.
Proposition 7.10 If K5(Îµ) does not vary with Îµ and f is concave in Îµ and T is
convex, then f âˆ—is concave on T. Again, assuming the solution is attained, this
means that f âˆ—is continuous and directionally differentiable in the interior of T.
Proposition 7.11 Suppose K5(Îµ) is nonempty and compact and that it does not
change with Îµ, and assume f and âˆ‡Îµ f are continuous in (x, Îµ). Then, at any Îµ âˆˆT,
it follows that S(Îµ) Ì¸= âˆ…and compact and the directional derivative Df âˆ—(Îµâˆ—, z) exists
for any direction z and is given by
Df âˆ—(Îµâˆ—, z) = min
xâˆˆS(Îµ) âˆ‡Îµ f (x, Îµ)z.
Proposition 7.12 Assume that the problem (P5(Îµ)) is convex in x for each Îµ âˆˆT
and the problem functions are once continuously differentiable in (x, Îµ). Then, if
Îµâˆ—âˆˆint(T ) and the set of points (x, u, v, Îµâˆ—) satisfying (KKT) is nonempty and
bounded, then in a neighborhood N(Îµâˆ—) of Îµâˆ—, it holds S(Îµ) Ì¸= âˆ…, and S(Îµ) is convex
for each Îµ âˆˆN(Îµâˆ—) and S(Îµ) is uniformly compact in N(Îµâˆ—). Furthermore, f âˆ—is
continuous and directionally differentiable in N(Îµâˆ—) in any direction z and
Df âˆ—(Îµâˆ—, z) = min
xâˆˆS(Îµ)
max
(u,v)âˆˆM(x,Îµ)âˆ‡ÎµL (x, u, v, Îµ)z,
where M(x, Îµ) is the set of multipliers (u, v) that satisfy the (KKT) conditions.
As previously remarked, if (P5(Îµ)) is convex, the assumption (GS) is equivalent
to (MFCQ), or to assuming that M(x, Îµ) Ì¸= âˆ…and closed and bounded at a global
solution. Dispensing with convexity, but assuming that the gradients âˆ‡gi(x, Îµ), i
such that gi(x, Îµ) = 0, and âˆ‡h j(x, Îµ), j = 1, . . . , p, are linearly independent at
every x âˆˆS(Îµ), we have that Df âˆ—(Îµâˆ—, z) exists for each z âˆˆRk and
Df âˆ—(Îµâˆ—, z) = min
xâˆˆS(Îµ)âˆ‡ÎµL (x, u(x, Îµ), v(x, Îµ), Îµ)z
where {u(x, Îµ), v(x, Îµ)} is the unique optimal Karush-Kuhn-Tucker multipliers vec-
tor associated with x âˆˆS(Îµ).
References [16, 17] extend the results of Theorem 7.6 by relaxing the Strict
Complementary Slackness Conditions and strengthening the standard second-order
sufï¬cient optimality conditions of Theorem 7.5.
Theorem 7.13 SupposethattheKarush-Kuhn.Tuckerconditionsholdat xâˆ—âˆˆK5(Îµâˆ—)
with some multipliers vectors u and v, that the following additional Strong Second-
Order Sufï¬cient Conditions hold at xâˆ—for (P5(Îµâˆ—)), i.e.
zâŠ¤âˆ‡2
xL (xâˆ—, u, v, Îµâˆ—)z > 0
for all z Ì¸= 0 such that

7.1 General Results
235
âˆ‡xgi(xâˆ—, Îµâˆ—)z = 0, âˆ€i âˆˆI +(xâˆ—, u),
âˆ‡xh j(xâˆ—, Îµâˆ—)z = 0, âˆ€j = 1, . . . , p,
and that the Linear Independence Constraint Qualiï¬cation holds at xâˆ—.
Then:
(a) xâˆ—is an isolated local minimum point of (P5(Îµâˆ—)) and the associated Karush-
Kuhn-Tucker multipliers vectors u and v are unique.
(b) For Îµ in a neighborhood of Îµâˆ—there exists a unique continuous vector function
y(Îµ) = [x(Îµ), u(Îµ), v(Îµ)]âŠ¤satisfying the Karush-Kuhn-Tucker conditions and
the Strong Second-Order Sufï¬cient Conditions for a local minimum of (P5(Îµ))
such that y(Îµâˆ—) = (xâˆ—, u, v)âŠ¤and, hence, x(Îµ) is a locally unique local minimum
point of (P5(Îµ)) with associated unique Karush-Kuhn-Tucker multipliers vectors
u(Îµ) and v(Îµ).
(c) The Linear Independence Constraint Qualiï¬cation holds at x(Îµ) for Îµ near Îµâˆ—.
(d) There exist t > 0 and d > 0 such that for all Îµ with âˆ¥Îµ âˆ’Îµâˆ—âˆ¥< d, it follows that
y(Îµ) âˆ’y(Îµâˆ—)
 â‰¦t
Îµ âˆ’Îµâˆ— .
Note that the differentiability of x(Îµ), u(Îµ) and v(Îµ) is no longer assured by
the above theorem, however [16] proves that these functions admit at Îµâˆ—one-sided
directional derivatives. For what concerns the optimal value function f âˆ—(Îµ), under
the assumptions of Theorem 7.13 it is possible to obtain the following results [1, 16].
Theorem 7.14 If the assumptions of Theorem 7.13 are satisï¬ed at xâˆ—âˆˆK5(Îµâˆ—),
then for Îµ near Îµâˆ—, the local optimal value function f âˆ—(Îµ) is once continuously
differentiable and
(a)
f âˆ—(Îµ) = L [x(Îµ), u(Îµ), v(Îµ)],
(b) âˆ‡Îµ f âˆ—(Îµ) = âˆ‡ÎµL (x, u, v, Îµ)
(x(Îµ),u(Îµ),v(Îµ),Îµ) .
It is also possible to get some interesting sensitivity results for (P5(Îµ)) by substitut-
ing the Linear Independence Constraint Qualiï¬cation with the weaker Mangasarian-
Fromovitz Constraint Qualiï¬cation, but strengthening further the Strong Second-
Order Sufï¬cient Conditions for (local) strict optimality. This has been done in [18].
Theorem 7.15 (Kojima) Suppose that the Karush-Kuhn-Tucker conditions hold at
xâˆ—âˆˆK5(Îµâˆ—), with some multipliers vectors u and v. Suppose that the following Gen-
eral Strong Second-Order Sufï¬cient Conditions (GSSOSC) hold at xâˆ—for (P5(Îµâˆ—)).
â€¢ GSSOSC: the Strong Second-Order Sufï¬cient Conditions hold at xâˆ—for (P5(Îµâˆ—))
with multipliers (u, v) for every (u, v) âˆˆM(xâˆ—, Îµ), being
M(xâˆ—, Îµâˆ—) =
â§
â¨
â©
(u, v) âˆˆRm Ã— Rp : âˆ‡xL (xâˆ—, u, v, Îµâˆ—) = 0,
uigi(xâˆ—, uâˆ—) = 0, i = 1, . . . , m,
ui â‰§0, i = 1, . . . , m
â«
â¬
â­.

236
7
Sensitivity Analysis
Suppose further that the Mangasarian-Fromovitz constraint qualiï¬cation holds at
xâˆ—for (P5(Îµâˆ—)).
Then:
(a) xâˆ—is an isolated local minimum point of (P5(Îµâˆ—)) and the set M(xâˆ—, Îµâˆ—) is
compact and convex.
(b) There are neighborhoods N(xâˆ—) of xâˆ—and N(Îµâˆ—) of Îµâˆ—such that for Îµ in
N(Îµâˆ—) there exists a unique continuous vector function x(Îµ) in N(xâˆ—) satisfying
the Karush-Kuhn-Tucker conditions for some [u(Îµ), v(Îµ)] âˆˆM(x(Îµ), Îµ) and the
General Strong Second-Order Sufï¬cient Conditions such that x(Îµâˆ—) = xâˆ—, and,
hence, x(Îµ) is the locally unique local minimum point of (P5(Îµ)) in N(xâˆ—).
(c) The Mangasarian-Fromovitz constraint qualiï¬cation holds at x(Îµ) for Îµ in
N(Îµâˆ—).
7.2
Sensitivity Results for Right-Hand Side Perturbations
In the present section we give some insights on sensitivity analysis for nonlinear
programming problems subject to right-hand side perturbations, i. e. on problems of
the type
R(Îµ) :
â§
âªâªâ¨
âªâªâ©
min f (x)
subject to: g(x) â‰¦Îµ1,
h(x) = Îµ2,
x âˆˆX,
with X âŠ‚Rn open set, f : X â†’R, g : X â†’Rm and h : X â†’Rp. Obviously Îµ1 âˆˆ
Rm, Îµ2 âˆˆRp and Îµ = (Îµ1, Îµ2) âˆˆRk, with k = m + p. We continue to assume that
the functions of R(Îµ) are twice-continuously differentiable on the open set X âŠ‚Rn.
It is quite obvious that the general results for (P5(Îµ)) of the previous section can be
specialized and adapted to problem R(Îµ), but, curiously, also the vice-versa holds, in
the sense that any problem of the form (P5(Îµ)) may be reformulated as an equivalent
right-hand side parametric problem. It is sufï¬cient to redeï¬ne Îµ in (P5(Îµ)) to be a
variable and to introduce a new parameter Î± such that Îµ = Î±. This results in the
problem
P(Î±) :
â§
âªâªâ¨
âªâªâ©
min f (x, Îµ)
subject to: g(x, Îµ) â‰¦0,
h(x, Îµ) = 0,
Îµ = Î±,
which is clearly equivalent to (P5(Îµ)) and of the form of R(Îµ). See [1, 19].
Since the formulation of R(Îµ) is often considered in several applications (above
all economic applications), we restate the specialized results of sensitivity analysis
for R(Îµ).

7.2 Sensitivity Results for Right-Hand Side Perturbations
237
Theorem 7.16 If
(i) The functions deï¬ning R(Îµ) are twice-continuously differentiable (in x) on the
open set X âŠ‚Rn.
(ii) The second-order sufï¬cient optimality conditions for a strict local minimum
hold at the feasible point xâˆ—of R(0), with associated Karush-Kuhn-Tucker
multipliers u and v.
(iii) The gradients âˆ‡xgi(xâˆ—), i âˆˆI (xâˆ—), and âˆ‡xh j(xâˆ—), j = 1, . . . , p, are linearly
independent.
(iv) The Strict Complementary Slackness Conditions hold: ui > 0 when i âˆˆI (xâˆ—).
Then:
(a) xâˆ—is a local isolated minimizing point of R(0) and the associated Karush-Kuhn-
Tucker multipliers vectors u and v are unique.
(b) For Îµ in a neighborhood of 0, there exists a unique once-continuously dif-
ferentiable vector function y(Îµ) = [x(Îµ), u(Îµ), v(Îµ)]âŠ¤satisfying the second-
order suffcient conditions for a strict local minimum of problem R(Îµ) such that
y(0) = [xâˆ—, u, v]âŠ¤and hence, x(Îµ) is a locally unique minimum point of R(Îµ)
with associated Karush-Kuhn-Tucker multipliers u(Îµ) and v(Îµ).
(c) For Îµ in a neighborhood of 0 we have
f âˆ—(Îµ) = L âˆ—(Îµ),
where
L (x, u, v, Îµ) = f (x) +
m

i=1
ui(gi(x) âˆ’Îµi) +
p

j=1
v j(h j(x) âˆ’Îµ j+m).
(d) Strict complementary slackness conditions and linear independence of the active
constraint gradients hold at x(Îµ) for Îµ near 0.
(e) For Îµ in a neighborhood of 0, the gradient of the optimal value function is
âˆ‡Îµ f âˆ—(Îµ) = âˆ’
 u(Îµ)
v(Îµ)
âŠ¤
.
(f) For Îµ in a neighborhood of 0, the Hessian matrix of the optimal value function
is
âˆ‡2
Îµ f âˆ—(Îµ) = âˆ’
 âˆ‡Îµu(Îµ)
âˆ‡Îµv(Îµ)

.
The above results are easily obtained from the previous general results on (P5(Îµ))
by letting f (x, Îµ) = f (x), gi(x, Îµ) = gi(x) âˆ’Îµi, i = 1, . . . , m, and h j(x, Îµ) =
h j(x) âˆ’Îµ j+m, j = 1, . . . , p.
For the readerâ€™s convenience we give an autonomous proof of a reduced version
of the above theorem, i.e. we consider a parametric programming problem with

238
7
Sensitivity Analysis
right-hand side parameters and with only equality constraints, i.e. of the type (P3).
Therefore we consider the following problem
(P3(c)) :
â§
â¨
â©
min f (x)
subject to: h j(x) = c j, j = 1, . . . , p < n,
x âˆˆX âŠ‚Rn
and let f : X â†’R and every h j : X â†’R, j = 1, . . . , p, be twice-continuously
differentiable on the open set X âŠ‚Rn. For problem (P3(0)) we write the Lagrangian
function in the form
L (x, v) = f (x) + vâŠ¤h(x).
K3(c) is the feasible set of (P3(c)) and the optimal value function of (P3(c)) is
denoted, as before, by f âˆ—(c) â‰¡f [x(c)] . The autonomous proof for the sensitivity
resultsconcerningtheproblem(R(Îµ))canbeperformed,mutatismutandis,following
the steps of the proof given below for the parametric problem (P3(c)).
Theorem 7.17 Suppose that for c = 0 there is a local solution x0 of (P3(0)) and
that the gradients âˆ‡h1(x0), . . . , âˆ‡h p(x0) are linearly independent. Suppose that the
associated Lagrange multiplier vector v (unique) satisï¬es the Lagrangian conditions
âˆ‡xL (x0, v) = 0
and the second-order sufï¬cient conditions for strict optimality
zâŠ¤âˆ‡2
xL (x0, v)z > 0,
for all z Ì¸= 0 such that âˆ‡h(x0)z = 0.
Then, there exists a neighborhood N(0) of 0 âˆˆRp and a function x(c) continu-
ously differentiable on N(0), such that x(0) = x0 and, for very c âˆˆN(0), x(c) is a
strict local minimizer of f on K3(c). Furthermore,
âˆ‡c f âˆ—(c) = âˆ‡c [ f (x(c))] |c=0 = âˆ’vâŠ¤.
Proof Consider the system of equations
âˆ‡f (x) + vâŠ¤âˆ‡h(x) = 0
(7.4)
h(x) = c.
(7.5)
By the assumptions, there is a solution (x0, v) to this system when c = 0. The Jaco-
bian matrix of the system at this solution is
M =
âˆ‡2
xL (x0, v) âˆ‡h(x0)âŠ¤
âˆ‡h(x0)
0

.

7.2 Sensitivity Results for Right-Hand Side Perturbations
239
Because by assumption x0 is a regular point and âˆ‡2
xL (x0, v) is positive deï¬nite
on the linear subspace âˆ‡h(x0)z = 0, an immediate consequence of a criterion on
positive deï¬niteness of quadratic forms on the nonzero solutions of an homogeneous
linear system, is that M is nonsingular (see Chap. 1 and [20]). Otherwise, directly:
indeed, the unique solution d âˆˆRn Ã— Rp of Md = 0 is d = 0 and hence M is non-
singular. To prove this, let us consider (d1, d2) âˆˆRn Ã— Rp and decompose Md = 0
into
âˆ‡2
xL (x0, v)d1 + âˆ‡h(x0)âŠ¤d2 = 0
âˆ‡h(x0)d1 = 0.
It results
(d1)âŠ¤âˆ‡2
xL (x0, v)d1 + (d1)âŠ¤âˆ‡h(x0)âŠ¤d2 = 0
(d1)âŠ¤âˆ‡2
xL (x0, v)d1 + (d2)âŠ¤âˆ‡h(x0)d1 = 0,
whence
(d1)âŠ¤âˆ‡2
xL (x0, v)d1 = 0 and âˆ‡h(x0)d1 = 0.
(7.6)
But the only possibility for d1 to verify (7.6), owing to the second-order sufï¬cient
optimality conditions for x0, is d1 = 0. Hence âˆ‡h(x0)âŠ¤d2 = 0, but being âˆ‡h(x0)âŠ¤
of full rank, it holds also d2 = 0.
Being M nonsingular, it is possible to apply the Implicit Function Theorem: for
all c in some open neighborhood N(0), there exist x(c) and v(c) such that x(0) = x0,
v(0) = v, the functions x(Â·) and v(Â·) are continuously differentiable, and
âˆ‡f (x(c)) + v(c)âŠ¤âˆ‡h(x(c)) = 0,
h(x(c)) = c.
For c sufï¬ciently close to 0 the vectors x(c) and v(c) satisfy the second-order
sufï¬cient optimality conditions for the problem in question, since they satisfy them
by assunption for c = 0. This is straightforward to verify by using the continuity
assumptions: if it were not true, there would exist a sequence

ck
with ck â†’0 and
a sequence

zk
, with
zk = 1 and âˆ‡h(x(ck))zk = 0 for all k, such that
(zk)âŠ¤âˆ‡2
xL (x(ck), v(ck))zk â‰¦0, âˆ€k.
By taking the limit along a convergent subsequence of

zk
, we would obtain a
contradiction with the second-order sufï¬cient conditions at (x0, v). Hence, x(c) is a
strict local minimizer for problem (P(c)), with associated Lagrange multiplier v(c).
Finally, being x(c) continuously differentiable, also the composite function
f [x(c)] is continuously differentiable. By the chain rule we have

240
7
Sensitivity Analysis
âˆ‡c f (x(c)) |c=0 = âˆ‡x f (x0)âˆ‡cx(0)
and
âˆ‡ch(x(c)) |c=0 = âˆ‡xh(x0)âˆ‡cx(0).
In view of (7.5) the second of these relations is equal to the identity matrix I of
order p, while this, in view of (7.4), implies that the ï¬rst relation can be written as
âˆ‡c f (x(c)) |c=0 = âˆ’vâŠ¤.
âˆ‡c f (x(c)) |c=0 = âˆ’vâŠ¤.
â–¡
Thus, the rate of change of f âˆ—(c) with respect to changes in the constraint values
is captured entirely by the optimal Lagrange multipliers. In economic applications
these multipliers are referred to as shadow prices (i.e. imputed prices) of resource
levels. See, e. g., [6, 7, 21].
Remark 7.18 Let us consider again problem R(Îµ) :
R(Îµ) :
â§
âªâªâ¨
âªâªâ©
min f (x)
subject to: g(x) â‰¦Îµ1,
h(x) = Îµ2,
x âˆˆX,
with X âŠ‚Rn open set, f : X â†’R, g : X â†’Rm and h : X â†’Rp. We make the
assumption that R(Îµ) is a convex problem, i.e. that f and every gi, i = 1, . . . , m,
are convex on the open convex set X and that every h j, j = 1, . . . , p < n, is linear
afï¬ne. We make also the assumption that f and every gi is differentiable on X
(obviously every h j is differentiable on Rn). Without having recourse to second-
order optimality conditions, it is possible, under the said assumptions, to obtain
interesting results for R(Îµ). See, e.g., [13, 22].
Let us denote by f âˆ—(Îµ1, Îµ2) the optimal value function of R(Îµ).
Theorem 7.19 Let R(Îµ) be a convex problem; then:
(i) The function f âˆ—(Îµ1, Îµ2) is convex.
(ii) If Îµ1, Â¯Îµ1 are such that Îµ1
i â‰¦Â¯Îµ1
i , âˆ€i = 1, . . . , m, then f âˆ—(Ïµ1, Îµ2) â‰§f âˆ—(Â¯Îµ1, Îµ2).
Proof (i) Let be
K(Îµ1, Îµ2) =

x âˆˆX : g(x) â‰¦Îµ1, h(x) = Îµ2
.

7.2 Sensitivity Results for Right-Hand Side Perturbations
241
One can easily check that for Î» âˆˆ[0, 1] we have the inclusion
Î»K(Îµ1, Îµ2) + (1 âˆ’Î»)K(Â¯Îµ1, Â¯Îµ2) âŠ‚K(Îµ1(Î»), Îµ2(Î»))
where Îµ1(Î») = Î»Îµ1 + (1 âˆ’Î»)Â¯Îµ1 and Îµ2(Î») = Î»Îµ2 + (1 âˆ’Î»)Â¯Îµ2. Consequently, if x âˆˆ
K(Îµ1, Îµ2), Â¯x âˆˆK(Â¯Îµ1, Â¯Îµ2), Î» âˆˆ[0, 1] , then
f âˆ—(Îµ1(Î»), Îµ2(Î»)) â‰¦f (Î»x + (1 âˆ’Î»)Â¯x) â‰¦Î»f (x) + (1 âˆ’Î») f (Â¯x).
Hence
f âˆ—(Îµ1(Î»), Îµ2(Î»)) â‰¦Î»f âˆ—(Îµ1, Îµ2) + (1 âˆ’Î») f âˆ—(Â¯Îµ1, Â¯Îµ2).
(ii) Since K(Îµ1, Îµ2) âŠ‚K(Â¯Îµ1, Îµ2) Îµ1
i â‰¦Â¯Îµ1
i , i = 1, . . . , m, one has
f âˆ—(Îµ1, Îµ2) =
inf
xâˆˆK(Îµ1,Îµ2) f (x) â‰§
inf
xâˆˆK(Â¯Îµ1,Îµ2) f (x) = f âˆ—(Â¯Îµ1, Îµ2).
â–¡
Now we suppose that for the convex problem R(Îµ) the Slater constraint qualiï¬-
cation is satisï¬ed at Îµ = (0, 0) and that R(0, 0) admits a solution. With x0 âˆˆK(0, 0)
the Slater constraint qualiï¬cation for our problem can be expressed as:
â€¢ The vectors âˆ‡h j(x0) are linearly independent, j = 1, . . . , p;
There exists Â¯x âˆˆK(0, 0) such that gi(Â¯x) < 0, âˆ€i = 1, . . . , m, and h j(Â¯x) = 0,
âˆ€j = 1, . . . , p.
We recall that under this constraint qualiï¬cation the set M(x0) of the Karush-Kuhn-
Tucker multipliers of R(0, 0) is a convex and compact set (nonempty). Under the
said assumptions, it is not possible to obtain the differentiability of the optimal value
function f âˆ—(Îµ1, Îµ2), however it is possible to obtain its directional differentiability.
Theorem 7.20 Let in R(Îµ) the above conditions be fulï¬lled and let x0 be a solu-
tion of R(0, 0) with multipliers u, v. Then the directional derivative Df âˆ—(0, y) =
Dy f âˆ—(0, 0) of the optimal value function at (0, 0) in the direction y = (y1, y2) âˆˆ
Rm Ã— Rp exists and it holds
Dy f âˆ—(0) =
max
(u,v)âˆˆM(x0)

(âˆ’uâŠ¤y1) + (âˆ’vâŠ¤y2)

.
We have to note that in the case M(x0) is a singleton, then f âˆ—(Îµ1, Îµ2) is differen-
tiable at (0, 0) and we get the usual formula
âˆ‡Îµ f âˆ—(0) = âˆ’
 u
v
âŠ¤
.

242
7
Sensitivity Analysis
References
1. A.V. Fiacco, Introduction to Sensitivity and Stability Analysis in Nonlinear Programming (Aca-
demic, New York, 1983)
2. S.N. Afriat, Theory of maxima and the method of Lagrange. SIAM J. Appl. Math. 20, 43â€“357
(1971)
3. J.F. Bonnans, A. Shapiro, Perturbation Analysis of Optimization Problems (Springer, New
York, 2000)
4. B. Beavis, I. Dobbs, Optimization and Stability Theory for Economic Analysis (Cambridge
University Press, Cambrdidge, U.K., 1990)
5. E. Silberberg, W. Suen, The Structure of Economics: A Mathematical Analysis, 3rd edn.
(McGraw-Hill Publishing Company, New York, 2001)
6. A. Takayama, Sensitivity Analysis in Economic Theory (1977)
7. A. Takayama, Mathematical Economics, 2nd edn. (Cambridge University Press, Cambridge,
1985)
8. T.M. Apostol, Calculus, 2nd edn. (Blaisdell, Waltham, Mass, 1967)
9. B. Bank, J. Guddat, D. Klatte, B. Kummer, K. Tammer, Non-Linear Parametric Optimization
(BirkhÃ¤user, Basel, 1983)
10. A.V. Fiacco, G.P. Mccormick, Nonlinear Programming: Sequential Unconstrained Minimiza-
tion Techniques (Wiley, New York, 1968)
11. A.V. Fiacco, Sensitivity analysis for nonlinear programming using penalty methods. Math.
Program. 10, 287â€“311 (1976)
12. G.P. McCormick, Optimality criteria, in nonlinear Programming, in Nonlinear Programming,
eds. by R.W. Cottle, C.E. Lemke, S.I.A.M.-A.M.S. Proceedings, vol. IX (American Mathe-
matical Society, Providence, RI, 1976), pp. 27â€“38
13. A.V. Fiacco, J. Kyparisis, Convexity and concavity properties of the optimal value function in
parametric programming. J. Optim. Theory Appl. 48, 95â€“126 (1986)
14. J. Kyparisis, A.V. Fiacco, Generalized convexity and concavity of the optimal value function
in nonlinear programming. Math. Program. 39, 285â€“304 (1987)
15. J. Gauvin, A necessary and sufï¬cient regularity condition to have bounded multipliers in
nonconvex programming Math. Program. 12, 136â€“138 (1977)
16. K. Jittorntrum, Solution point differentiability without strict complementarity in nonlinear
programming. Math. Program. Study 21, 127â€“138. (A. V. Fiacco Ed.) (1984)
17. S.M. Robinson, Strongly regular generalized equations. Math. Oper. Res. 5, 43â€“62 (1980)
18. M. Kojima, Strongly stable stationary solutions in nonlinear programs, in Analysis and Com-
putation of Fixed Points, ed. by S.M. Robinson (Academic, New York, 1980), pp. 93â€“138
19. R.T. Rockafellar, Lagrange multipliers and subderivatives of the optimal value functions in
nonlinear programming. Math. Program. Study 17, 28â€“66 (1982)
20. G. Debreu, Deï¬nite and semideï¬nite quadratic forms. Econometrica 20, 285â€“300 (1952)
21. J. Gauvin, Shadow prices in nonconvex mathematical programming. Math. Program. 19, 300â€“
312 (1980)
22. W. Hogan, Directional derivatives of extremal-value functions with applications to the com-
pletely convex case. Oper. Res. 21, 188â€“209 (1973)

Chapter 8
Convex Optimization: Saddle Points
Characterization and Introduction to
Duality
8.1
Convex Optimization: Saddle Points Characterization
In the last 50 years or more, the words â€œnonsmooth optimizationâ€ generally refer
to nonlinear programming problems (or also to problems of calculus of variations
or optimal control) where the functions involved are not differentiable (in the sense
of FrÃ© chet), but satisfy weaker assumptions concerning various kinds of limits in
various kinds of differential quotients, in order to obtain generalized gradients or
generalized directional derivatives.
Some insights on these approaches to nonsmooth optimization problems will be
presented in Chap. 10. But, from a historic point of view, the ï¬rst approach used to
treat a nonlinear convex programming problem, in the absence of differentiability
assumptions on the functions involved in the problem, was the saddle points char-
acterization of the Lagrangian function associated with the problem. This classical
approach, which has some importance also with reference to dual problems and min-
imax theory (see the next section of the present chapter) will be summarized in what
follows.
For simplicity, let us consider a nonlinear programming problem with only
inequality constraints, i.e. a problem of the type (P4).
(P4) :
â§
â¨
â©
min f (x)
subject to: gi(x) â‰¦0, i = 1, . . . , m,
x âˆˆX âŠ‚Rn,
where X âŠ‚Rn is a nonempty set, f : X â†’R and every gi : X â†’R, i = 1, . . . , m.
Note that we do not assume (at least for the moment) any differentiability prop-
erty on the functions involved in (P4). With regard to (P4), we introduce the usual
Lagrangian function
Â© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al., Basic Mathematical Programming Theory, International Series
in Operations Research & Management Science 344,
https://doi.org/10.1007/978-3-031-30324-1_8
243

244
8
Convex Optimization: Saddle Points Characterization and Introduction to Duality
L (x, u) = f (x) +
m

i=1
uigi(x), x âˆˆX, ui â‰§0, i = 1, . . . , m,
or, in vector notation
L (x, u) = f (x) + uâŠ¤g(x), x âˆˆX, u â‰§0.
Deï¬nition 8.1 A pair (x0, u0) âˆˆX Ã— Rm
+ is called a Lagrangian saddle point or
simply a saddle point for (P4) if
L (x0, u) â‰¦L (x0, u0) â‰¦L (x, u0), âˆ€x âˆˆX, âˆ€u â‰§0.
(8.1)
Intuitively, in R3, this could produce a picture like a horse saddle; however, there
is a common misconception that a saddle point always looks similar to a saddle (in
R3). See [1].
Clearly, a saddle point may never exist and even if it exists, it is not necessarily
unique.
Remark 8.2 Deï¬nition 8.1 makes reference to (P4), i.e. to a minimization problem.
If we consider a maximization problem of the type
â§
â¨
â©
max f (x)
subject to: gi(x) â‰§0, i = 1, . . . , m,
x âˆˆX âŠ‚Rn,
the saddle point characterization for this problem is
L (x, u0) â‰¦L (x0, u0) â‰¦L (x0, u), âˆ€x âˆˆX, âˆ€u â‰§0,
(8.2)
where
L (x, u) = f (x) âˆ’uâŠ¤g(x), x âˆˆX, u â‰§0.
Some authors (really few) call (8.1) â€œnegative saddle point conditionâ€ and (8.2)
â€œpositive saddle point conditionâ€. We shall always make reference to minimization
problems.
Now we give a characterization of saddle points for the Lagrangian function of
problem (P4).
Theorem 8.3 Thepair(x0, u0), x0 âˆˆX,u0 â‰§0,isasaddlepointfortheLagrangian
function of problem (P4) if and only if the following conditions hold:
(i) gi(x0) â‰¦0, i = 1, . . . , m;
(ii) u0
i gi(x0) = 0, i = 1, . . . , m;
(iii)
f (x0) â‰¦f (x) + m
i=1 u0
i gi(x), âˆ€x âˆˆX.
Proof Let us suppose that (x0, u0) is a saddle point for the Lagrangian function
L (x, u) = f (x) + uâŠ¤g(x). By Deï¬nition 8.1 we have

8.1 Convex Optimization: Saddle Points Characterization
245
f (x0) +
m

i=1
uigi(x0) â‰¦f (x0) +
m

i=1
u0
i gi(x0) â‰¦f (x) +
m

i=1
u0
i gi(x), (8.3)
âˆ€x âˆˆX, âˆ€u â‰§0.
We rewrite the ï¬rst inequality:
f (x0) +
m

i=1
u0
i gi(x0) â‰§f (x0) +
m

i=1
uigi(x0), âˆ€u â‰§0.
(8.4)
Clearly, this implies that we must have gi(x0) â‰¦0, i = 1, . . . , m, or else (8.4)
can be violated by making a component of u sufï¬ciently large. Hence, (i) is proved.
Now, taking u = 0 in (8.4) we obtain m
i=1 u0
i gi(x0) â‰§0, but being gi(x0) â‰¦0, i =
1, . . . , m, and u0
i â‰§0, we have m
i=1 u0
i gi(x0) â‰¦0 and hence m
i=1 u0
i gi(x0) = 0.
Hence, (ii) is proved.
From (ii) and from (8.3) we have (iii). Conversely, suppose that we are given
(x0, u0), with x0 âˆˆX and u0 â‰§0 such that (i), (ii) and (iii) of the theorem hold.
Then L (x0, u0) â‰¦L (x, u0), âˆ€x âˆˆX, by properties (ii) and (iii). Furthermore,
L (x0, u0) = f (x0) +
m

i=1
u0
i gi(x0) = f (x0) â‰§f (x0) +
m

i=1
uigi(x0), âˆ€u â‰§0,
since (property (i)) gi(x0) â‰¦0, i = 1, . . . , m. Hence, (x0, u0) is a saddle point for
L (x, u).
â–¡
The next result, which is a quite immediate corollary of the previous theorem,
puts into relationship the existence of a saddle point for L (x, u) and the existence
of optimal solutions of (P4).
Theorem 8.4 If the pair (x0, u0), x0 âˆˆX, u0 â‰§0, is a saddle point for L (x, u) =
f (x) + uâŠ¤g(x), x âˆˆX, u â‰§0, then:
(a) x0 is a global solution of (P4).
(b) The complementary slackness conditions hold:
m

i=1
u0
i gi(x0) = 0, i.e. u0
i gi(x0) = 0, i = 1, . . . , m.
Proof Relation (b) has been already proved in Theorem 8.3. From the same theo-
rem we have that x0 is feasible for (P4) : gi(x0) â‰¦0, i = 1, . . . , m. From (iii) of
Theorem 8.3 we have
f (x0) â‰¦f (x) +
m

i=1
u0
i gi(x), âˆ€x âˆˆX.

246
8
Convex Optimization: Saddle Points Characterization and Introduction to Duality
For all feasible points x for (P4), it will hold m
i=1 uigi(x) â‰¦0 and hence, for all
feasible points x for (P4), we have f (x0) â‰¦f (x).
â–¡
We remark that the previous result (quite strong) yields a sufï¬cient condition for
a point x0 to be a global solution for (P4), with no differentiability assumptions,
nor convexity (or generalized convexity) assumptions on the functions involved in
(P4). The condition expressed by Theorem 8.4 is only sufï¬cient. The next example
exhibits a minimization problem having a global optimal solution, but no saddle
point for the Lagrangian function.
Example 8.5 Consider the problem
â§
â¨
â©
min(âˆ’x1)
subject to: (x1)2 âˆ’x2 â‰¦0,
x2 â‰¦0,
with (x1, x2) âˆˆR2. This problem has a unique global minimizer at x0 = (0, 0)âŠ¤. This
point is the only feasible solution (0 â‰§x2 â‰§(x1)2 â‰§0). The associated Lagrangian
function is
L (x1, x2, u1, u2) = âˆ’x1 + u1((x1)2 âˆ’x2) + u2x2.
Note that L (x0, u) = 0 for all u. If the Lagrangian function has a saddle point
(x0, u0), we would have
0 â‰¦âˆ’x1 + u0
1((x1)2 âˆ’x2) + u0
2x2 = L (x, u0), âˆ€x.
Let x2 = 0. If x1 is positive and sufï¬ciently small, we get L (x, u0) < 0, whereas
for (x0, u0) to be a saddle point, we must have 0 = L (x0, u0) â‰¦L (x, u0) < 0,
which is a contradiction.
To obtain necessary optimality conditions for (P4) in terms of a saddle point
characterization, we normally need to make some sort of regularity and convexity
assumption on the functions involved in (P4). Therefore, we consider a convex pro-
gramming problem, i.e. in (P4) the nonempty set X âŠ‚Rn is a convex set and the
functions f and every gi, i = 1, . . . , m, are convex on X.
We recall, from the previous chapters, mostly Chap. 3, the main properties of a
convex programming problem:
(1) The set of feasible solutions is convex.
(2) A local minimum point is a global minimum point.
(3) If the functions involved in the problem are differentiable, then a solution of the
Karush-Kuhn-Tucker conditions is a solution of the problem.
(4) A satisfactory duality theory can be established. See the next section.
(5) If the objective function is strictly convex, the minimum point (if there exists) is
unique (and hence strict).

8.1 Convex Optimization: Saddle Points Characterization
247
Some of these properties are still valid if the objective function and the constraints
are convenient generalized convex functions (see Chap. 3).
The following result is essentially due to [2] and in part to [3].
Theorem 8.6 (Kuhn-Tucker-Uzawa) Consider the convex problem (P4) and let x0
be a (global) minimum point for (P4). Then, there exist m + 1 multipliers Â¯u0 â‰§0,
Â¯u1 â‰§0, . . . , Â¯um â‰§0, not all zero, such that
Â¯u0 f (x) +
m

i=1
Â¯uigi(x) â‰§Â¯u0 f (x0), âˆ€x âˆˆX.
(8.5)
Furthermore, we get the complementary slackness conditions, i. e. Â¯uigi(x0) = 0,
i = 1, . . . , m.
Proof Being x0 a global minimum point for (P4), the system
â§
âªâªâªâ¨
âªâªâªâ©
f (x) âˆ’f (x0) < 0
g1(x) â‰¦0
...
gm(x) â‰¦0
has no solution x âˆˆX. Hence, a fortiori, the system
â§
âªâªâªâ¨
âªâªâªâ©
f (x) âˆ’f (x0) < 0
g1(x) < 0
...
gm(x) < 0
has no solution x âˆˆX. Being f and every gi, i = 1, . . . , m, convex on the convex
set X âŠ‚Rn, the function Ï• : Rn â†’Rm+1 given by
Ï•(x) =
 f (x) âˆ’f (x0)
g(x)
	
is convex on X and by the Theorem of Fan-Glicksberg-Hoffman (Theorem 3.45),
there exist (m + 1) nonnegative multipliers, not all zero, Â¯u0, Â¯u1, . . . , Â¯um, such that
Â¯u0( f (x) âˆ’f (x0)) +
m

i=1
Â¯uigi(x) â‰§0, âˆ€x âˆˆX.
Thus, relation (8.5) holds. Being Â¯ui â‰§0, i = 1, . . . , m, and gi(x0) â‰¦0,
i = 1, . . . , m, we have m
i=1 Â¯uigi(x0) â‰¦0. But if we substitute x0 into relation (8.5)
we obtain m
i=1 Â¯uigi(x0) â‰§0. Hence, we have m
i=1 Â¯uigi(x0) = 0, or equivalently,
Â¯uigi(x0) = 0, i = 1, . . . , m.
â–¡

248
8
Convex Optimization: Saddle Points Characterization and Introduction to Duality
We note that in Theorem 8.6 it may occur Â¯u0 = 0 (as in the Theorem of Fritz John
for the differentiable case). It is therefore essential to impose some conditions, i.e.
some constraint qualiï¬cation, which ensures that in relation (8.5) it holds Â¯u0 > 0, i.e.
without loss of generality, Â¯u0 = 1. We take into consideration the following constraint
qualiï¬cations, which require no differentiability assumptions. We recall that X âŠ‚Rn
is a convex set, and that f : X â†’R and every gi : X â†’R, i = 1, . . . , m, are convex
functions.
(a) Slater constraint qualiï¬cation: There exists Â¯x âˆˆX such that g(Â¯x) < 0.
(b) Karlin constraint qualiï¬cation (see [4]): There exists no u âˆˆRm
+ \ {0} such that
uâŠ¤g(x) â‰§0, âˆ€x âˆˆX.
(c) Strict constraint qualiï¬cation: There exist x1, x2 âˆˆK4, with x1 Ì¸= x2, such that
g is strictly convex at x1, with respect to x2, i. e. for all Î» âˆˆ(0, 1) it holds
g(Î»x1 + (1 âˆ’Î»)x2) < Î»g(x1) + (1 âˆ’Î»)g(x2).
Theorem 8.7 It holds: (c) â‡’(a) â‡”(b) .
Proof The equivalence (a) â‡”(b) is an immediate consequence of the theorem of
Fan-Glicksberg-Hoffman (Theorem 3.45). From the fact that g is strictly convex at
x1 (with respect to x2), it results, with Î» âˆˆ(0, 1), as x1, x2 âˆˆK4,
g(Î»x1 + (1 âˆ’Î»)x2) < Î»g(x1) + (1 âˆ’Î»)g(x2) â‰¦0
and this shows that the point (Î»x1 + (1 âˆ’Î»)x2) veriï¬es the Slater c. q.
â–¡
Theorem 8.8 Let x0 be a (global) solution of the convex problem (P4) and let the
Slater constraint qualiï¬cation be satisï¬ed. Then in (8.5) it holds Â¯u0 = 1 and the
pair (x0, Â¯u) is a saddle point for the Lagrangian function L (x, u). Furthermore,
Â¯uigi(x0) = 0, i = 1, . . . , m.
Proof If, absurdly, it would result Â¯u0 = 0, relation (8.5) then becomes
m

i=1
Â¯uigi(Â¯x) â‰§0,
which is absurd, as Â¯ui â‰§0, i = 1, . . . , m, not all equal to zero, and g(Â¯x) < 0. Then
we have the relations
L (x, Â¯u) = f (x) + Â¯uâŠ¤g(x);
L (x0, Â¯u) = f (x0) + Â¯ug(x0) = f (x0), by the complementary slackness condi-
tions;
L (x0, u) = f (x0) + uâŠ¤g(x0).
By relation (8.5), being u0 = 1, we have
L (x0, Â¯u) â‰¦L (x, Â¯u), âˆ€x âˆˆX.

8.1 Convex Optimization: Saddle Points Characterization
249
Moreover, it holds, being g(x0) â‰¦0,
L (x0, u) â‰¦L (x0, Â¯u), âˆ€u â‰§0.
Therefore, (x0, Â¯u) is a saddle point for the Lagrangian function and the comple-
mentary slackness conditions hold (from Theorem 8.7 and from the characterization
of saddle points).
â–¡
The following example shows that the Slater constraint qualiï¬cation (or another
suitable constraint qualiï¬cation) cannot be skipped in the above theorem.
Example 8.9 Consider the problem

min(âˆ’x), x âˆˆR
subject to:
x2 â‰¦0.
The only feasible point is x0 = 0, with value f (0) = 0. So, x0 = 0 is the unique
global solution of our problem. The Lagrangian function is
L (x, u) = âˆ’x + ux2, u â‰§0, x âˆˆR.
There is no u0 â‰§0 such that (x0, u0) is a saddle point of L .
We can therefore formulate the following scheme.
(x0, u0) saddle point for L (x, u) â‡’x0 (global) solution of (P4)
x0 global sol. of the convex problem (P4)
+c.q.
â‡’(x0, u0) saddle p. for L (x, u)
The above notions have been generalized towards various directions. We wish to
mention some results due to [5] who take into consideration the class of pre-invex
functions (see Chap. 3). Again let us consider problem (P4) :
â§
â¨
â©
min f (x)
subject to: g(x) â‰¦0,
x âˆˆX âŠ‚Rn,
where f : X â†’R and g : X â†’Rm.
Theorem 8.10 Let X âŠ‚Rn be a nonempty set and let f : X â†’Rm be a pre-invex
function on X, with respect to Î· : Rn Ã— Rn â†’Rm (i.e. each of its component is
pre-invex on X with respect to the same Î·). Then, either
f (x) < 0
has a solution x âˆˆX, or

250
8
Convex Optimization: Saddle Points Characterization and Introduction to Duality
pâŠ¤f (x) â‰§0, âˆ€x âˆˆX, for some p â‰§0, p Ì¸= 0.
Proof See [5].
â–¡
The problem (P4) will be said to satisfy the generalized Slater constraint qualiï¬-
cation if g is pre-invex (with respect to Î· ) and there exists Â¯x âˆˆX such that g(Â¯x) < 0.
The following result can be proved in the same manner as in the case of convex
functions.
Theorem 8.11 Assume that in (P4) the objective function f is pre-invex on X, with
respect to the vector function Î· and that the vector-valued function g is pre-invex on
X, with respect to the same function Î·. Assume that the generalized Slater constraint
qualiï¬cation holds. If x0 is a solution of (P4), then there exists u0 âˆˆRm
+ such that
(x0, u0) is a saddle point of the Lagrangian function of (P4) :
L (x0, u) â‰¦L (x0, u0) â‰¦L (x, u0), âˆ€x âˆˆX, âˆ€u âˆˆRm
+.
(8.6)
Conversely, if (8.6) is satisï¬ed for some (x0, u0), then x0 is a solution for (P4).
We now assume that in (P4) the functions f and every gi, i = 1, . . . , m, are differ-
entiable on the open set X âŠ‚Rn and will put into evidence the relationships between
saddle point conditions for (P4) and Karush-Kuhn-Tucker conditions for (P4), these
last ones called by [6], â€œquasi-saddle point conditionsâ€. These relationships are in
fact the central topic of the pioneering paper of [3].
Theorem 8.12 Let in (P4) the functions f and every gi, i = 1, . . . , m, be differen-
tiable on the open set X âŠ‚Rn. If the Lagrangian function of (P4) has a saddle point
(x0, u0), then the following Karush-Kuhn-Tucker conditions hold:
(i) âˆ‡xL (x0, u0) = 0;
(ii) u0 â‰§0, (u0)âŠ¤g(x0) = 0;
(iii) g(x0) â‰¦0.
Proof The points (ii) and (iii) are parts of the characterization of a saddle point
(x0, u0) : see Theorem 8.3. We recall the deï¬nition of saddle point for (P4) :
L (x0, u) â‰¦L (x0, u0) â‰¦L (x, u0), âˆ€x âˆˆX, âˆ€u â‰§0.
From the second inequality it results that x0 is a minimum point for L (x, u0)
over X. By Fermatâ€™s theorem we have (X is open):
âˆ‡xL (x0, u0) = âˆ‡f (x0) +
m

i=1
u0
i âˆ‡gi(x0) = 0.
Therefore, also (i) is proved.
â–¡
Now, let us consider the convex problem (P4), under differentiability assumptions.
We obtain the following converse result of the previous theorem.

8.1 Convex Optimization: Saddle Points Characterization
251
Theorem 8.13 Let in (P4) the functions f and every gi, i = 1, . . . , m, be differen-
tiable and convex on the open convex set X âŠ‚Rn. Let x0 âˆˆK4 verify the Karush-
Kuhn-Tucker conditions, with a multipliers vector u0 â‰§0. Then the pair (x0, u0) is
a saddle point of the Lagrangian function L (x, u).
Proof Being f and every gi, i = 1, . . . , m, convex functions, the Lagrangian func-
tionL (x, u) = f (x) + uâŠ¤g(x),u â‰§0,isaconvexfunction.Theï¬rstKarush-Kuhn-
Tucker condition is
âˆ‡xL (x0, u0) = âˆ‡f (x0) +
m

i=1
u0
i âˆ‡gi(x0) = 0.
Being L (x, u) convex, âˆ€u â‰§0, the previous stationary condition means that
L (x, u0) has a global minimum at x0 over X, hence
L (x0, u0) â‰¦L (x, u0), âˆ€x âˆˆX.
From the complementary slackness conditions and from the fact that x0 âˆˆK4,
we have
f (x0) +
m

i=1
uigi(x0) â‰¦f (x0) +
m

i=1
u0
i gi(x0), âˆ€u â‰§0,
and hence
L (x0, u) â‰¦L (x0, u0), âˆ€u â‰§0.
This inequality, together with the previous one, gives the thesis.
â–¡
We present a scheme which summarizes the main results previously obtained.
The reference problem is (P4), i.e.
(P4) :
â§
â¨
â©
min f (x)
subject to: gi(x) â‰¦0, i = 1, . . . , m,
x âˆˆX âŠ‚Rn.
(x0, u0) saddle point for L (x, u)
differentiability
â‡’
(x0, u0) satisï¬es (KKT).
(x0, u0) satisï¬es (KKT)
convexity
â‡’
(x0, u0) saddle point for L (x, u).
(x0, u0) saddle point for L (x, u)
always
â‡’
x0 solution of (P4).

252
8
Convex Optimization: Saddle Points Characterization and Introduction to Duality
x0 solution of (P4)
convexity + Slater c.q.
â‡’
(x0, u0) saddle point for L (x, u).
Remark 8.14 From the previous scheme it appears that if (P4) is a linear program-
ming problem (see Chap. 9), i.e. the functions involved in the said problem are all
linear (afï¬ne), i.e. differentiable and both convex and concave, the constraints are
automatically qualiï¬ed, and therefore the Karush-Kuhn-Tucker conditions hold at
the optimal point x0. From this fact it follows that also the saddle point conditions
are veriï¬ed, without any constraint qualiï¬cation. That is, for a linear programming
problem (L. P.) the necessary conditions, expressed by the saddle point characteri-
zation, need no constraint qualiï¬cation. This result is originally due to Goldman and
Tucker (see [7]), with a nontrivial proof. This shows that sometimes, the progress of
the mathematical machinery can drastically simplify the proofs of previous results.
We take again into consideration the convex problem (P4) in order to make two
further observations. First we show that the solutions of a convex problem (of the
type (P4)) do not change if we take into considerations only the active constraints,
referred to that solution x0.
Theorem 8.15 Let x0 âˆˆK4 be a solution of the convex problem (P4). Then x0 is
also an optimal solution of the â€œreducedâ€ problem
(P4(I (x0)) :
â§
â¨
â©
min f (x)
subject to: gi(x) â‰¦0, i âˆˆI (x0),
x âˆˆX âŠ‚Rn
where X âŠ‚Rn is a nonempty convex set.
Proof Let us suppose tnat x0 is not an optimal solution of (P4(I (x0)). It follows that
there exists Â¯x âˆˆX such that gi(Â¯x) â‰¦0, i âˆˆI (x0), and
f (Â¯x) < f (x0).
(8.7)
Since X is aconvexset, wehavethat xÎ» â‰¡Î»Â¯x + (1 âˆ’Î»)x0 âˆˆX for anyÎ» âˆˆ(0, 1).
Since all gi are convex functions, it results that
gi(xÎ») â‰¦Î»gi(Â¯x) + (1 âˆ’Î»)gi(x0)
(8.8)
for Î» âˆˆ(0, 1).
From (8.8) it follows that gi(xÎ») â‰¦0 for all i âˆˆI (x0). Since gi(x0) < 0 for
all i /âˆˆI (x0), from (8.8) we have that gi(xÎ») â‰¦0 for every i /âˆˆI (x0) and for Î»
sufï¬ciently small. Thus, xÎ» âˆˆK4 for a small Î». From (8.7) it follows that
f (xÎ») â‰¦Î»f (Â¯x) + (1 âˆ’Î») f (x0) < f (x0)
(8.9)
for all Î» âˆˆ(0, 1). Since xÎ» âˆˆK4, relation (8.9) contradicts the optimality of x0 âˆˆK4
for (P4).
â–¡

8.1 Convex Optimization: Saddle Points Characterization
253
Now we consider again the convex problem (P4) and add the differentiability
assumption: all functions involved in (P4) are differentiable on an open set containing
the convex set X âŠ‚Rn. Then, if we know a solution x0 of this problem, it is possible
to characterize the solution set of the same problem, i.e. the set
S â‰¡arg min
xâˆˆK4
f (x).
The following result has been obtained by [8], with the unnecessary assumption
that the functions involved in the problem are C 2.
Theorem 8.16 Let us consider the problem
(P4) :
â§
â¨
â©
min f (x)
subject to: gi(x) â‰¦0, i = 1, . . . , m,
x âˆˆX âŠ‚Rn,
where f and every gi, i = 1, . . . , m, are convex on the convex set X âŠ‚Rn and f
and every gi are continuously differentiable on some open set containing X. If x0 is
a solution of (P4), then a necessary and sufï¬cient condition such that x âˆˆK4 is a
solution of the same problem, is that:
âˆ‡f (x) = âˆ‡f (x0)
(8.10)
(x âˆ’x0)âŠ¤âˆ‡f (x0) = 0.
(8.11)
Proof In other words, the theorem asserts that if x0 âˆˆS, then
S = K4 âˆ©

x âˆˆRn : âˆ‡f (x) = âˆ‡f (x0); (x âˆ’x0)âŠ¤âˆ‡f (x0) = 0

.
We have to prove that, under the assumption that x0 âˆˆK4 is a solution of (P4),
then conditions (8.10)â€“(8.11) are equivalent to f (x) = f (x0). The sufï¬ciency is
immediate. From convexity of f , we get
(x âˆ’x0)âŠ¤âˆ‡f (x0) â‰¦f (x) âˆ’f (x0) â‰¦(x âˆ’x0)âŠ¤âˆ‡f (x)
and, by (8.10)â€“(8.11) it holds f (x) = f (x0) and hence x âˆˆK4 is a solution.
Conversely, let us suppose that f (x) = f (x0), with x âˆˆK4. From convexity of
S, we have
xÎ» â‰¡Î»x + (1 âˆ’Î»)x0 âˆˆS, âˆ€Î» âˆˆ(0, 1),
i.e.
f (xÎ») = f (x0) = f (x).
From this relation and from convexity of f (Theorem 3.7), we have

254
8
Convex Optimization: Saddle Points Characterization and Introduction to Duality
Î»(x âˆ’x0)âŠ¤âˆ‡f (x0) â‰¦f (xÎ») âˆ’f (x0) â‰¦Î»(x âˆ’x0)âŠ¤âˆ‡f (xÎ»),
(8.12)
i.e.
relation (8.11) holds. Indeed, we have (x âˆ’x0)âŠ¤âˆ‡f (x0) â‰¦0 and if (x âˆ’
x0)âŠ¤âˆ‡f (x0) < 0, then for Î» sufï¬ciently small we have
(x âˆ’x0)âŠ¤âˆ‡f (x0 + Î»(x âˆ’x0)) < 0,
against relation (8.12).
It remains to prove relation (8.10). Let us consider the convex function
Ï•(y) = f (y) âˆ’(y âˆ’x0)âŠ¤âˆ‡f (x0).
Obviously, Ï•(x) = Ï•(x0) = f (x0), by relation (8.11), previously proved. More-
over, âˆ‡Ï•(y) = âˆ‡f (y) âˆ’âˆ‡f (x0) and âˆ‡Ï•(x0) = 0, i.e. x0 is an unconstrained global
minimum point of the convex function Ï•. From Ï•(x) = Ï•(x0), it results therefore
that x is an unconstrained global minimum point of Ï•, i.e. âˆ‡Ï•(x) = 0, i.e. relation
(8.10) holds.
â–¡
8.2
Introduction to Duality
Duality plays a fundamental role in theory and methods of Linear Programming (see
Chap. 9), where this topic was born and where the pioneering results go back to the
classical minimax theorem of von Neumann for Games Theory (see [9]). Duality
theory for linear programming problems essentially consists in the possibility, given
a linear programming problem said â€œprimal problemâ€, to formulate an associated
linear programming problem, said â€œdual problemâ€ , with the basic property that if
one of the two problems admits solution, then also the other problem admits solution
and the two optimal values are equal (see Chap. 9).
Extensions of duality theory to the nonlinear case started immediately afterwards
the basic paper of Kuhn and Tucker [3] and the said extensions remain one of the
most investigated areas of mathematical programming, with great importance not
only from a theoretical point of view but also (similarly to what happened for linear
programming problems) for algorithmic developments.
The literature on duality theory in nonlinear programming is therefore abundant,
just as the literature on duality of linear programming problems. We shall give only
some basic results which are simple to prove and which open the path for the duality
results of Linear Programming presented in the next chapter.
There are various approaches to duality for nonlinear programming problems,
among which the Lagrangian approach, based on the Lagrangian function, and the
conjugate functions approach, based on conjugate functions, introduced by Fenchel
and subsequently studied in a great detail by Moreau and Rockfellar (see [10, 11]).
As [12] has shown that both approaches are equivalent, we shall not consider the
conjugate duality theory.

8.2 Introduction to Duality
255
Let now consider X âŠ‚Rn and Y âŠ‚Rm and let be given f : X â†’R and g : Y â†’
R. We can consider the following pair of mathematical programming problems: a
â€œprimalâ€ problem (P), of the type
(P) :
min
xâˆˆX f (x),
and a â€œdualâ€ problem (D), of the type
(D) :
max
yâˆˆY g(y).
We say that between (P) and (D) there are duality relations, or that (P) and
(D) is a pair of dual problems, when at least the ï¬rst of the following properties is
satisï¬ed.
(I) f (x) â‰§g(y), âˆ€x âˆˆX, âˆ€y âˆˆY.
We accept the convention that inf f (x) = +âˆ, if X = âˆ…and that sup g(y) = âˆ’âˆ,
if Y = âˆ…. Furthermore, the two objective functions of (P) and (D) may not reach the
respective optimal values, therefore (I) may be rewritten in the more general form
inf
xâˆˆX f (x) â‰§sup
yâˆˆY
g(y).
This property is usually called â€œweak dualityâ€ .
A more satisfactory duality theory holds between (P) and (D) if also the following
property is satisï¬ed.
(II) If one of the two problems (P) or (D) admits solution, then also the other
problem admits solution and it holds
min
xâˆˆX f (x) = max
yâˆˆY g(y).
This property is usually called â€œstrong dualityâ€ .
From (I), we get also the following other duality properties:
(III) If xâˆ—âˆˆX and yâˆ—âˆˆY, then the equality f (xâˆ—) = g(yâˆ—) assures that xâˆ—and
yâˆ—are solutions, respectively, of (P) and (D).
(IV) If one of the two problems (P) or (D) admits unbounded extremum, i.e.
inf
xâˆˆX f (x) = âˆ’âˆor sup
yâˆˆY
g(y) = +âˆ,
then the other problem does not admit a ï¬nite solution.
In the literature we ï¬nd also the following terminology, with reference to the
connections between a primal and a dual problem.
â€¢ Direct dual existence theorem: if the primal problem has an optimal solution, then
also the dual problem has an optimal solution.
â€¢ Converse dual existence theorem: if the dual problem has an optimal solution, then
also the primal problem has an optimal solution.

256
8
Convex Optimization: Saddle Points Characterization and Introduction to Duality
â€¢ Strict direct duality theorem: if xâˆ—solves the primal problem (P), then some yâˆ—
solves the dual and f (x) = g(yâˆ—).
â€¢ Strict converse duality theorem: if yâˆ—solves the dual problem, then some xâˆ—solves
the primal problem and g(yâˆ—) = f (xâˆ—).
Moreover, if for a dual problem (D), it happens that its dual is the primal problem
(P), we say that (P) and (D) is a pair of â€œsymmetricâ€ dual problems or that for (P)
and (D) the â€œinvolution propertyâ€ holds.
WegivenowsomebasicnotionsonLagrangianduality.Forsimplicityweconsider
a constrained minimization problem with only inequality constraints, i.e. of the type
(P4), that in the present context we call the primal problem (P).
(P):
â§
â¨
â©
min f (x)
subject to: gi(x) â‰¦0, i = 1, . . . , m,
x âˆˆX âŠ‚Rn,
where f : X â†’R and gi : X â†’R , i = 1, . . . , m, X nonempty subset of Rn.
Given (P), the corresponding Lagrangian function is deï¬ned in the usual way:
L (x, u) = f (x) + uâŠ¤g(x), u â‰§0.
We remark that problem (P) can be equivalently reformulated as
min
xâˆˆX sup
uâ‰§0
L (x, u),
being
sup
uâ‰§0
L (x, u) =

 f (x), if g(x) â‰¦0,
+âˆ, otherwise.
In this context, the multipliers ui â‰§0, i = 1, . . . , m, are also called â€œdual vari-
ablesâ€ .
The Lagrangian dual problem (D) is the following one.
(D) :

max Î¸(u)
subject to: u â‰§0,
where
Î¸(u) = inf {L (x, u), x âˆˆX}
is called the Lagrangian dual function.
Note that the Lagrangian dual function Î¸ may assume the value âˆ’âˆfor some
vector u. Moreover, the objective function of the dual may not reach the respective
optimal value, so it is more convenient to substitute inf f (x), instead of min f (x),
in the primal problem, and sup Î¸(u), instead of max Î¸(u), in the dual problem.

8.2 Introduction to Duality
257
We now give a fundamental example which shows that the Lagrangian dual, as
deï¬ned above, is equivalent to the dual problem for Linear Programming, in the form
this last one is usually formulated.
Example 8.17 Consider a linear programming problem of the form
(P) :
â§
â¨
â©
min câŠ¤x
subject to: b âˆ’Ax â‰¦0,
x â‰§0,
where c, x âˆˆRn, c Ì¸= 0, A is a matrix of order (m, n) and b âˆˆRm. Choosing X =
Rn
+, the Lagrangian dual problem is
(D) :

max Î¸(u)
subject to: u â‰§0,
where
Î¸(u) = inf
xâ‰§0câŠ¤x + uâŠ¤(b âˆ’Ax).
This reduces to
Î¸(u) = bâŠ¤u +

0,
if (c âˆ’AâŠ¤u) â‰§0
âˆ’âˆ, otherwise.
Assuming there are nonnegative values of u such that c â‰§AâŠ¤u, these would be
the only feasible choices for the maximization of Î¸(u) and therefore (D) takes the
familiar form of the dual problem for the linear programming (P) :
(D) :
â§
â¨
â©
max bâŠ¤u
subject to: AâŠ¤u â‰¦c,
u â‰§0.
See Chap. 9.
Example 8.18 (Differentiable convex programming problem) Let us consider the
problem
(P) :
â§
â¨
â©
min f (x)
subject to: gi(x) â‰¦0, i = 1, . . . , m.
x âˆˆX âŠ‚Rn,
where X âŠ‚Rn is an open convex set, f and every gi, i = 1, . . . , m, are differentiable
convex functions on X. The Lagrangian function is L (x, u) = f (x) + uâŠ¤g(x), u â‰§
0,andit is further assumedthatÎ¸(u) Ì¸= âˆ’âˆfor allu â‰§0.Withtheseassumptions the
Lagrangian function is convex in x and has a minimum where its gradient is zero. That
is, the requirement Î¸(u) = minxâˆˆX L (x, u) is the same as requiring âˆ‡xL (x, u) = 0.
Thus, the dual problem may be written as

258
8
Convex Optimization: Saddle Points Characterization and Introduction to Duality
(D) :
â§
â¨
â©
max L (x, u)
subject to: âˆ‡xL (x, u) = 0,
u â‰§0.
This is the Wolfe dual problem for (P), one of the ï¬rst nonlinear duals, proposed
in [13]. See further, in the present section.
In the general case, the dual problem may not have a solution, even if the primal
problem has a solution. Conversely, the primal problem may not have a solution,
even if the dual problem has a solution. With reference to the Lagrangian duality, we
have the following ï¬rst basic result.
Theorem 8.19 (Weak duality theorem) Let x be feasible for problem (P), that is
x âˆˆX, g(x) â‰¦0; let u be feasible for problem (D), that is u â‰§0. Then it holds
f (x) â‰§Î¸(u).
Proof By deï¬nition of Î¸, and since x âˆˆX, we have
Î¸(u) = inf

f (y) + uâŠ¤g(y), y âˆˆX

â‰¦f (x) + uâŠ¤g(x) â‰¦f (x),
since u â‰§0, g(x) â‰¦0. This completes the proof.
â–¡
Corollary 8.20 It holds
inf

f (x) : x âˆˆX, g(x) â‰¦0

â‰§sup

Î¸(u), u â‰§0

.
Corollary 8.21 If f (x0) = Î¸(u0), where u0 â‰§0 and x0 âˆˆ

x âˆˆX, g(x) â‰¦0

,
then x0 and u0 solve the primal and dual problems, respectively.
Corollary 8.22 If
inf

f (x) : x âˆˆX, g(x) â‰¦0

= âˆ’âˆ,
then Î¸(u) = âˆ’âˆ, for every u â‰§0.
Corollary 8.23 If
sup

Î¸(u) : u â‰§0

= +âˆ,
then the primal problem has no feasible solution.
If we set
Â¯p = inf

f (x), x âˆˆX, g(x) â‰¦0

and
Â¯d = sup

Î¸(u), u â‰§0

,
from Corollary 8.20 it appears that

8.2 Introduction to Duality
259
Â¯p âˆ’Â¯d â‰§0.
If in the above relation strict inequality holds true, then a duality gap is said to
exist. Contrary to Linear Programming Problems, for the nonlinear case, without
further assumptions on the functions involved in (P) and (D), there may exist a
duality gap. Consider, e.g. the following example.
Example 8.24 Let be f (x) = âˆ’x2, X = [0, 1] , g(x) = 2x âˆ’1. Then Â¯p = min(P)
= f
 1
2

= âˆ’1
4. L (x, u) = âˆ’x2 + u(2x âˆ’1), x âˆˆ[0, 1] , u â‰§0. We get
Î¸(u) = min{L (0, u), L (1, u)} = min{âˆ’u, u âˆ’1} =

âˆ’u,
if u â‰§1
2,
u âˆ’1, if u < 1
2
and hence Â¯d = max(D) = Î¸
 1
2

= âˆ’1
2.
The next theorem shows that under suitable convexity assumption and under a
constraint qualiï¬cation, we have no duality gap.
Theorem 8.25 (Strong duality theorem) Let us consider the primal problem (P),
where X âŠ‚Rn is a nonempty convex set, f : X â†’R and every gi : X â†’R, i =
1, . . . , m,areconvexon X.Supposethat theSlater constraint qualiï¬cationis veriï¬ed,
i.e. there exists Â¯x âˆˆX such that g(Â¯x) < 0. Then
inf

f (x) : x âˆˆX, g(x) â‰¦0

= sup

Î¸(u) : u â‰§0

.
(8.13)
Furthermore, if the inf is ï¬nite, then sup

Î¸(u) : u â‰§0

is achieved at some u0,
with u0 â‰§0. If the inf is achieved at x0, then (u0)âŠ¤g(x0) = 0.
Proof Let Â¯p = inf

f (x) : x âˆˆX, g(x) â‰¦0

. By assumption Â¯p < âˆ. If Â¯p = âˆ’âˆ
then, by Corollary 8.22, sup

Î¸(u), u â‰§0

= âˆ’âˆand therefore relation (8.13)
holds true. Hence, suppose that Â¯p is ï¬nite, and consider the following system
f (x) âˆ’Â¯p < 0,
g(x) â‰¦0,
x âˆˆX.
By deï¬nition of Â¯p, this system has no solution and a fortiori the following system
has no solution.
f (x) âˆ’Â¯p < 0,
g(x) < 0,
x âˆˆX.
By the Theorem of Fan-Glicksberg-Hoffman (Theorem 3.45), there exists a
nonzero vector (u0, u), with (u0, u) â‰§0, such that

260
8
Convex Optimization: Saddle Points Characterization and Introduction to Duality
u0( f (x) âˆ’Â¯p) + uâŠ¤g(x) â‰§0, âˆ€x âˆˆX.
(8.14)
We ï¬rst show that u0 > 0. By contradiction, suppose that u0 = 0. By assumption,
thereexists Â¯x âˆˆX suchthat g(Â¯x) < 0.Substitutingin (8.14),itfollowsthatuâŠ¤g(Â¯x) â‰§
0. Since g(Â¯x) < 0 and u â‰§0, the inequality uâŠ¤g(Â¯x) â‰§0 is possible only if u = 0.
But this is excluded from the Theorem of Fan-Glicksberg-Hoffman. Hence, u0 > 0.
Dividing (8.14) by u0 and denoting ( 1
u0 )u by u0, we get
f (x) + (u0)âŠ¤g(x) â‰§Â¯p, âˆ€x âˆˆX.
(8.15)
This shows that Î¸(u0) = inf

f (x) + (u0)âŠ¤g(x) : x âˆˆX

â‰§Â¯p. In view of The-
orem 8.19, it is clear that Î¸(u0) = Â¯p and that u0 solves the dual problem.
To complete the proof, suppose that x0 is an optimal solution of the primal prob-
lem, that is x0 âˆˆX, g(x0) â‰¦0 and f (x0) = Â¯p. From (8.15), letting x = x0, we get
(u0)âŠ¤g(x0) â‰§0. Since u0 â‰§0 and g(x0) â‰¦0, we get (u0)âŠ¤g(x0) = 0, and the proof
is complete.
â–¡
The Lagrangian dual function Î¸(u) is a is always a concave function on its domain,
as, for ï¬xed x, L (x, u) is linear in u and thus Î¸(u) is the inï¬mum of a (possibly
inï¬nite) collection of functions linear in u. It follows that Î¸(u) admits a directional
derivative at every point of its domain. However, the Lagrangian dual function Î¸(u)
may be not differentiable. Furthermore, we have to note that Theorem 8.25 provides
only sufï¬cient conditions for the existence of strong duality: strong duality can hold
also for nonconvex problems. Consider, e.g. the following example.
Example 8.26 Consider the problem
(P) :

min

âˆ’(x1)2 âˆ’(x2)2
subject to: (x1)2 + (x2)2 âˆ’1 â‰¦0.
We have Â¯p = min(P) = âˆ’1. The Lagrangian function is L (x, u) = âˆ’(x1)2 âˆ’
(x2)2 + u((x1)2 + (x2)2 âˆ’1) = (u âˆ’1)(x1)2 + (u âˆ’1)(x2)2 âˆ’u.
Î¸(u) =

âˆ’âˆ, if u < 1
âˆ’u,
if u â‰§1.
Hence, u0 = 1 is the dual optimum and Î¸(u0) = âˆ’1.
We consider again a primal problem of the type (P4), but now we add a differen-
tiability assumption on the functions involved in the said problem, in order to treat
the Wolfe dual, already introduced in Example 8.18. Let us therefore consider the
following primal problem (P), i.e.
(P) :
â§
â¨
â©
min f (x)
subject to: gi(x) â‰¦0, i = 1, . . . , m,
x âˆˆX âŠ‚Rn,

8.2 Introduction to Duality
261
where the functions f : X â†’R and every gi : X â†’R, i = 1, . . . , m, are differ-
entiable on the open set X âŠ‚Rn. The Wolfe dual (see [13]) is deï¬ned as follows
(L (x, u) is the usual Lagrangian function of (P) : L (x, u) = f (x) + uâŠ¤g(x),
u â‰§0).
(WD) :

max L (x, u)
subject to: (x, u) âˆˆK(WD) =

x âˆˆX : u â‰§0, âˆ‡xL (x, u) = 0

.
Note that the constraints of (WD) are part of the Karush-Kuhn-Tucker conditions
for the primal problem (P).
Theorem 8.27 (Weak duality theorem) Let X âŠ‚Rn be an open convex set and let
the functions f : X â†’R and every gi : X â†’R be differentiable convex functions
on X. If x is feasible for (P) and (xâ€², u) is feasible for (WD), we have
f (x) â‰§L (xâ€², u).
Proof As f is differentiable and convex on X, it holds
f (x) âˆ’f (xâ€²) â‰§(x âˆ’xâ€²)âŠ¤âˆ‡f (xâ€²).
As (xâ€², u) is feasible for (WD), it holds
âˆ‡f (xâ€²) +
m

i=1
(âˆ‡gi(xâ€²))âŠ¤ui = 0.
Being the functions gi, i = 1, . . . , m, differentiable and convex on X, it results
gi(x) âˆ’gi(xâ€²) â‰§(x âˆ’xâ€²)âŠ¤âˆ‡gi(xâ€²), i = 1, . . . , m.
From the last three relations, we get immediately
f (x) â‰§f (xâ€²) + uâŠ¤(g(xâ€²) âˆ’g(x)).
Finally, as x is feasible for (P), it results g(x) â‰¦0 and hence uâŠ¤g(x) â‰¦0. From
the last inequality proved above, we get therefore
f (x) â‰§f (xâ€²) + uâŠ¤g(xâ€²).
â–¡
Theorem 8.28 (Strict direct duality theorem) Let X âŠ‚Rn be an open convex set
and let the functions f : X â†’R and every gi : X â†’R be differentiable and convex
on X. If x0 is a solution of (P) and if the constraints of (P) verify a constraint
qualiï¬cation (i. e. (P) is â€œqualiï¬edâ€ ), then there exists some u0 âˆˆRm
+ such that the
pair (x0, u0) is a solution of (WD). Moreover, it holds

262
8
Convex Optimization: Saddle Points Characterization and Introduction to Duality
f (x0) = L (x0, u0).
Proof Being the primal problem (P) qualiï¬ed, the optimal point x0 veriï¬es the
Karush-Kuhn-Tucker conditions with a multipliers vector u0 âˆˆRm
+ :
âˆ‡xL (x0, u0) = 0
and
(u0)âŠ¤g(x0) = 0.
Therefore, the pair (x0, u0) is feasible for (WD). Now
L (x0, u0) = f (x0) + (u0)âŠ¤g(x0) = f (x0).
(8.16)
But, being f and g convex on X, by Theorem 8.27 we have
f (x0) â‰§L (x, u), âˆ€(x, u) âˆˆK(WD).
Hence, (x0, u0) solves (WD) and relation (8.16) puts into evidence that the optimal
values of the two problems are equal.
â–¡
Theorem 8.29 (Strict converse duality theorem) Assume that X âŠ‚Rn is an open
set and that f : X â†’R and gi : X â†’R, i = 1, . . . , m, are given. Let (x0, u0) be
a solution of (WD), and let f and every gi, i = 1, . . . , m, be twice-continuously
differentiable on X. If:
(a) L (Â·, u0) is pseudoconvex on X, with respect to x, and
(b) the Hessian matrix âˆ‡2
xL (x0, u0) is nonsingular,
then x0 is a solution of the primal problem (P) and, moreover,
f (x0) = L (x0, u0).
Proof Being (x0, u0) a solution of (WD), it results that the system
âˆ‡xL (x, u) = 0
admits a solution. The assumptions of the theorem permit the application of the
Implicit Function Theorem: there exists an open neighborhood U(u0) of u0 and a
function x : U(u0) â†’X such that x(u0) = x0 and
âˆ‡xL (x, u)
(x(u),u) = 0, âˆ€u âˆˆU(u0).
Now we observe that, as (x0, u0) is a solution of the dual problem (WD), it results
that u0 is a solution of the following nonlinear programming problem
max

L (x(u), u) : u âˆˆU(u0), u â‰§0

.

8.2 Introduction to Duality
263
It results that the following conditions are satisï¬ed:
u0 â‰§0, âˆ‡uL (x(u0), u0) â‰¦0, (u0)âŠ¤âˆ‡uL (x(u0), u0) = 0.
Now, being
âˆ‡uL (x(u), u) = (âˆ‡xL (x, u))âŠ¤âˆ‡ux(u) + âˆ‡uL (x, u),
it results
âˆ‡uL (x(u0), u0) = âˆ‡uL (x0, u0).
The conditions written above become
u0 â‰§0, âˆ‡uL (x0, u0) â‰¦0, (u0)âŠ¤âˆ‡uL (x0, u0) = 0,
i.e.
u0 â‰§0, g(x0) â‰¦0, (u0)âŠ¤g(x0) = 0.
(8.17)
As x0 âˆˆX, from (8.17) it results that x0 is also feasible for (P). As (x0, u0) âˆˆ
K(WD), it results
âˆ‡xL (x0, u0) = 0.
Being L (Â·, u0) pseudoconvex on X, with respect to X, it results that x0 is a
global minimum point of L (Â·, u0) on the feasible set of (P). In other words, for
every feasible x for (P), we have
L (x, u0) â‰§L (x0, u0),
i.e.
f (x) + (u0)âŠ¤g(x) â‰§f (x0).
Finally, as (u0)âŠ¤g(x) â‰¦0, for each feasible x (for (P)), it results, for all feasible
x
f (x) â‰§f (x0).
The fact that the optimal values of the two problems coincide, is an immediate
consequence of the complementary slackness conditions established in (8.17).
â–¡
Remark 8.30 In Theorem 8.29, instead of assuming that the Lagrangian function
L (Â·, u0) is pseudoconvex on X, with respect to x, it is possible to assume that f is
pseudoconvex and that every gi, i = 1, . . . , m, is quasiconvex on the open convex
set X âŠ‚Rn. The proof is quite similar. The theorem still holds if (x0, u0) is not a
global, but only a local maximum point of L (x, u) on K(WD).
As we have just asserted, Theorem 8.29 holds with suitable generalized convexity
assumptions on the functions f and every gi, i = 1, . . . , m, involved in (P) and

264
8
Convex Optimization: Saddle Points Characterization and Introduction to Duality
(WD), whereas Theorems 8.27 and 8.28 require convexity assumptions. Indeed, for
theselasttwotheorems,ageneralizedconvexityassumptiononthefunctionsinvolved
in (P) and (WD) does not assure their validity, not even for linear constraints. The
following example is due to Mangasarian [14].
Example 8.31 Consider the following primal problem
(P) :

min(âˆ’eâˆ’x2), x âˆˆR,
subject to: 1 âˆ’x â‰¦0.
Its Wolfe dual is
(WD) :

 max(âˆ’eâˆ’x2 âˆ’ux + u), x, u âˆˆR,
subject to: 2xeâˆ’x2 âˆ’u = 0, u â‰§0,
which can also be written in the equivalent form
max
xâ‰§0

âˆ’

2x2 âˆ’2x + 1

eâˆ’x2
.
The solution of the primal problem is obviously Â¯x = 1, the objective function
of (P) is pseudoconvex and all other assumptions of Theorem 8.29 are veriï¬ed.
Nevertheless, the problem (WD) has no optimal solution, as the equation 2x2 âˆ’
2x + 1 = 0 has no real root. It has a greatest upper value at 0, which is not attained,
and even the weak duality theorem is not satisï¬ed.
A more simple counterexample is the following one.
Example 8.32 Consider the primal problem
(P) :

min(x3 + x)
subject to: âˆ’x â‰¦âˆ’1.
The optimal point is at x0 = 1, whereas the value of the Wolfe dual
(WD) :

max(x3 + x + u(âˆ’x + 1), x, u âˆˆR,
subject to: 3x2 + 1 âˆ’u = 0, u â‰§0
is unbounded.
We have to note that if we impose (as in Theorem 8.29) pseudoconvexity on the
Lagrangian function, the weak and strong Wolfe duality do hold. We give the simple
proof for weak duality:
(x âˆ’xâ€²)âŠ¤
âˆ‡f (xâ€²) + uâŠ¤âˆ‡g(xâ€²)

= 0 â‡’f (x) + uâŠ¤g(x) âˆ’f (xâ€²) âˆ’uâŠ¤g(xâ€²) â‰§0.
Therefore,

8.2 Introduction to Duality
265
f (x) â‰§f (xâ€²) + uâŠ¤g(xâ€²).
Now we give some other properties on the Wolfe dual problem. For convenience
we denote by K(P) the feasible set of the primal problem and by K(WD) the feasible
set of the Wolfe dual problem.
Theorem 8.33 Let X âŠ‚Rn be an open set and let in (P) the objective function
f : X â†’R and the constraints gi : X â†’R, i = 1, . . . , m, be differentiable on X.
(a) If there exists a pair (x0, u0) âˆˆK(WD) such that the linear system
âˆ‡g(x0)âŠ¤z â‰¦âˆ’g(x0)
(8.18)
has no solution z âˆˆRn, then the Wolfe dual problem has an unbounded objective
function on K(WD), i.e. sup(x,u)âˆˆK(WD) L (x, u) = +âˆ.
(b) If, furthermore, g is convex on the open convex set X âŠ‚Rn, then K(P) = âˆ….
Proof By Farkasâ€™ theorem of the alternative, if system (8.18) admits no solution
z âˆˆRn, then there exists Â¯u âˆˆRm such that
Â¯u â‰§0, âˆ‡g(x0)Â¯u = 0, (Â¯u)âŠ¤g(x0) > 0.
(8.19)
Let us put u(Î») = u0 + Î»Â¯u, Î» âˆˆR+; it is clear that u(Î») â‰§0 and
âˆ‡xL (x0, u(Î»)) = 0
for every Î» âˆˆR+. In other words, (x0, u(Î»)) âˆˆK(WD) for every Î» âˆˆR+. Moreover,
as
L (x0, u(Î»)) = f (x0) + (u0)âŠ¤g(x0) + Î»(Â¯u)âŠ¤g(x0),
it results
lim
Î»â†’+âˆL (x0, u(Î»)) = +âˆ,
by the last inequality of (8.19). From the last written relation, we get
sup
(x,u)âˆˆK(WD)
L (x, u) = +âˆ,
i.e. the thesis of part (a).
(b) Let us suppose K(P) Ì¸= âˆ…and let be x1 âˆˆK(P). As g is convex on the open
convex set X âŠ‚Rn, it results
g(x1) âˆ’g(x0) â‰§(x1 âˆ’x0)âŠ¤âˆ‡g(x0) = âˆ‡g(x0)âŠ¤(x1 âˆ’x0).
As g(x1) â‰¦0, from the last relation we have that system (8.18) has a solution
z = x1 âˆ’x0, which is in contradiction with the assumptions.
â–¡

266
8
Convex Optimization: Saddle Points Characterization and Introduction to Duality
Theorem 8.34 If X = Rn, g is linear (afï¬ne), K(P) = âˆ…and K(WD) Ì¸= âˆ…, then
the Wolfe dual problem has an unbounded objective function on K(WD), i.e.
sup
(x,u)âˆˆK(WD)
L (x, u) = +âˆ.
Proof Let be g(x) = b âˆ’AâŠ¤x, with b âˆˆRm and A matrix of order (n, m). It is
sufï¬cient to prove that the linear system (8.18) has no solution z âˆˆRn. Indeed, if
this system has a solution z0 âˆˆRn, it results
âˆ’AâŠ¤z0 â‰¦AâŠ¤x0 âˆ’b,
i.e.
g(x0 + z0) = b âˆ’AâŠ¤(x0 + z0) â‰¦0.
In other words, x0 + z0 âˆˆK(P), which contradicts the assumption that K(P) =
âˆ….
â–¡
Theorem 8.35 Let X âŠ‚Rn be an open convex set and let f : X â†’R and every
gi : X â†’R, i = 1, . . . , m, be differentiable on X. If K(P) Ì¸= âˆ…and K(WD) = âˆ…,
and the functions f and every gi, i = 1, . . . , m, are concave on X, then f admits
no local minimizer on K(P).
Proof Let x0 âˆˆK(P); as x0 âˆˆX and K(WD) = âˆ…, it results that the linear system

âˆ‡f (x0) + âˆ‡g(x0)u = 0
u â‰§0
admits no solution u âˆˆRm. By Farkasâ€™ theorem of the alternative, it results that there
exists z0 âˆˆRn such that

 âˆ‡g(x0)âŠ¤z0 â‰¦0
âˆ‡f (x0)âŠ¤z0 < 0.
On the grounds of the previous relations, from the concavity assumptions on f
and g on X, for every Î» > 0, we obtain
f (x0 + Î»z0) â‰¦f (x0) + Î»(z0)âŠ¤âˆ‡f (x0) < f (x0)
and
gi(x0 + Î»z0) â‰¦gi(x0) + Î»(z0)âŠ¤âˆ‡gi(x0) â‰¦gi(x0), i = 1, . . . , m.
Moreover, by choosing Î» > 0 small enough, we have x0 + Î»z0 âˆˆX. From what
proved above, it results that for Î» > 0 small enough we have x0 + Î»z0 âˆˆK(P) and
f (x0 + Î»z0) < f (x0), which shows that x0 cannot be a local solution of the primal
problem (P).
â–¡

8.2 Introduction to Duality
267
As previously pointed out in Remark 8.30, when dealing with the Wolfe dual
(DW), weak and strong duality require convexity requirements on the objective
and constraint functions, whereas the converse duality theorem can be stated under
generalized convexity assumptions. In order to lessen the convexity requirements on
the weak and strong duality results (under differentiability assumptions), in [15] it
is proposed the following dual of (P).
(MWD) :
â§
â¨
â©
max f (y)
subject to: âˆ‡f (y) + m
i=1 uiâˆ‡gi(y) = 0,
uâŠ¤g(y) â‰§0, u â‰§0.
The advantage of (MWD) over (WD) is that the objective function of the dual is
the same as that of the primal, and, more importantly, the convexity requirements for
weak and strong duality relations can be furthermore relaxed.
Theorem 8.36 (Weak duality) If for all feasible vectors x of (P) and all feasible vec-
tors (y, u) of (MWD), the objective function f (x) is pseudoconvex and the function
uâŠ¤g(x) is quasiconvex, then
f (x) â‰§f (y).
Proof Let x be feasible for (P) and (y, u) be feasible for (MWD). Since uâŠ¤g(x) â‰¦0
and uâŠ¤g(y) â‰§0, by using Theorem 3.20 since uâŠ¤g(x) is quasiconvex, we have
m

i=1
uigi(x) âˆ’
m

i=1
uigi(y) â‰¦0 â‡’(x âˆ’y)âŠ¤
 m

i=1
uiâˆ‡gi(y)

â‰¦0, i = 1, . . . , m.
Therefore, by the constraints of (MWD), one has
(x âˆ’y)âŠ¤âˆ‡f (y) = âˆ’
m

i=1
ui(x âˆ’y)âŠ¤âˆ‡gi(y) â‰§0,
and using the pseudoconvexity of f , we derive that f (x) â‰§f (y).
â–¡
Theorem 8.37 (Strong duality) If x0 is a local or a global optimum point of (P)
at which a constraint qualiï¬cation is satisï¬ed, then there exists u âˆˆRm such that
(x0, u) is feasible for (MWD) and the corresponding values of (P) and (MWD) are
equal. If, also, for all feasible (x, y, u), f is pseudoconvex and uâŠ¤g is quasiconvex,
then x0 and (x0, u) are global optima for (P) and (MWD), respectively.
Proof Assuming that a constraint qualiï¬cation is satisï¬ed at x0, then by the Karush-
Kuhn-Tucker conditions, there exists u â‰§0 such that
âˆ‡f (x0) +
m

i=1
uiâˆ‡gi(x0) = 0,
uâŠ¤g(x0) = 0.

268
8
Convex Optimization: Saddle Points Characterization and Introduction to Duality
Thus, (x0, u) is feasible for (MWD). Equality follows, given the pseudoconvexity
of f and the quasiconvexity of uâŠ¤g, from weak duality.
â–¡
Example 8.38 We consider again the primal problem of Example 8.32:
(P) :

min(x3 + x)
subject to: âˆ’x â‰¦âˆ’1.
The Mond-Weir dual is now
(MWD) :
â§
âªâªâ¨
âªâªâ©
max(y3 + y)
subject to: 3y2 + 1 âˆ’u = 0,
u(âˆ’y + 1) â‰§0,
u â‰§0.
The optimum is attained at y = 1, u = 4.
Now we wish to give a generalization of the Lagrangian saddle point
(Deï¬nition 8.1) and to give further insights on the properties of saddle points, as
these properties will allow to point out the relationships between saddle point theory,
min-max theory and duality theory.
In general, saddle points are closely related to the Theory of Games, in which two
players with conï¬‚icting interests oppose each other. For a given â€œpay offâ€ function
Ï•(x, y), one player is minimizing Ï• with respect to x, while the other player is
maximizing Ï• with respect to y. This is called a min-max of Ï•. The mathematical
foundations of the theory of games and its applications to economics were laid down
by J. von Neumann in the twenties of the last century and subsequently described in
the classical work of [9].
Deï¬nition 8.39 Let Ï• be a real function of two real vectors x âˆˆX âŠ‚Rn and y âˆˆ
Y âŠ‚Rm. Thus, the domain of Ï• is X Ã— Y. A point (xâˆ—, yâˆ—), with xâˆ—âˆˆX and yâˆ—âˆˆY,
is said to be a saddle point of Ï• if
Ï•(xâˆ—, y) â‰¦Ï•(xâˆ—, yâˆ—) â‰¦Ï•(x, yâˆ—), âˆ€x âˆˆX, âˆ€y âˆˆY.
(8.20)
The value Ï•(xâˆ—, yâˆ—) is called the value of the saddle point. It is clear that (8.20)
is equivalent to
max
yâˆˆY Ï•(xâˆ—, y) = Ï•(xâˆ—, yâˆ—) = min
xâˆˆX Ï•(x, yâˆ—).
We have the following general property.
Theorem 8.40 For all saddle points (xâˆ—, yâˆ—), the value Ï•(xâˆ—, yâˆ—) is constant. If
(x1, y1) and (x2, y2) are saddle points, then (x1, y2) and (x2, y1) are saddle points
as well.
Proof The following relations hold:

8.2 Introduction to Duality
269
Ï•(x1, y) â‰¦Ï•(x1, y1) â‰¦Ï•(x, y1), âˆ€(x, y) âˆˆX Ã— Y;
Ï•(x2, y) â‰¦Ï•(x2, y2) â‰¦Ï•(x, y2), âˆ€(x, y) âˆˆX Ã— Y.
If, in the ï¬rst one, we take x = x2 and y = y2, and in the second one we put
x = x1 and y = y1, we get
Ï•(x1, y1) = Ï•(x2, y2) = Ï•(x2, y1) = Ï•(x1, y2).
Moreover, we can write for every (x, y) âˆˆX Ã— Y,
Ï•(x1, y) â‰¦Ï•(x1, y2) â‰¦Ï•(x, y2),
whence (x1, y2) is a saddle point. For (x2, y1) the proof is similar.
â–¡
Now, let be X âŠ‚Rn, Y âŠ‚Rm, Ï• : X Ã— Y â†’R and let us consider the following
two â€œmin-maxâ€ problems, i.e. the â€œprimalâ€ problem (P)
(P) :
min
xâˆˆX f (x);
and the â€œdualâ€ problem (D)
(D) :
max
yâˆˆY g(y),
where
f (x) = sup
yâˆˆY
Ï•(x, y)
and
g(y) = inf
xâˆˆX Ï•(x, y).
We note that it always holds (â€œweak duality theoremâ€ ):
max
yâˆˆY inf
xâˆˆX Ï•(x, y) â‰¦min
xâˆˆX sup
yâˆˆY
Ï•(x, y).
(8.21)
The following fundamental theorem gives a characterization of saddle points in
terms of a min-max property and therefore it establishes links between saddle points
characterizations, min-max properties and duality properties for (P) and (D). In a
certain sense, it may be regarded as a strong duality result without no convexity and
no regularity assumptions on the functions involved.
Theorem 8.41 Let be Ï• : X Ã— Y â†’R, with X âŠ‚Rn and Y âŠ‚Rm and let be
(xâˆ—, yâˆ—) âˆˆX Ã— Y. The following conditions are equivalent:
(a) The pair (xâˆ—, yâˆ—) is a saddle point of Ï• on X Ã— Y.

270
8
Convex Optimization: Saddle Points Characterization and Introduction to Duality
(b) xâˆ—is a solution of (P), yâˆ—is a solution of (D), and the two optimal values
are equal, i.e.
min
xâˆˆX sup
yâˆˆY
Ï•(xâˆ—, y) = max
yâˆˆY inf
xâˆˆX Ï•(x, yâˆ—)
(8.22)
Furthermore, if either (a) or (b) is satisï¬ed, the common optimal value of (P)
and (D) must be Ï•(xâˆ—, yâˆ—).
Proof Suppose that (a) holds. We have
sup
yâˆˆY
Ï•(xâˆ—, y) = max
yâˆˆY Ï•(xâˆ—, y) = Ï•(xâˆ—, yâˆ—) = min
xâˆˆX Ï•(x, yâˆ—) = inf
xâˆˆX Ï•(x, yâˆ—),
where the middle equalities follow directly from the deï¬nition of saddle point, and
the ï¬rst and last equalities are trivial. Then,
min
xâˆˆX sup
yâˆˆY
Ï•(x, y) â‰¦sup
yâˆˆY
Ï•(xâˆ—, y) = Ï•(xâˆ—, yâˆ—) = inf
xâˆˆXÏ•(x, yâˆ—) â‰¦
â‰¦max
yâˆˆY inf
xâˆˆXÏ•(x, y) â‰¦min
xâˆˆX sup
yâˆˆY
Ï•(x, y),
where the last inequality follows from the weak duality theorem (see (8.21)).
Since the ï¬rst and the last terms of the above inequalities are the same, we must
have equalities throughout. This proves (b), and the fact that the common optimal
value of (P) and (D) equals Ï•(xâˆ—, yâˆ—).
Conversely, suppose that (b) holds. Then (8.22) gives
inf
xâˆˆX Ï•(x, yâˆ—) = sup
yâˆˆY
Ï•(xâˆ—, y),
which in turn implies
Ï•(xâˆ—, y) â‰¦Ï•(xâˆ—, yâˆ—) â‰¦Ï•(x, yâˆ—), âˆ€x âˆˆX, âˆ€y âˆˆY,
that is proposition (a).
â–¡
From the previous result, it appears that an existence theorem on saddle points
for Ï• can be considered an existence theorem on duality between (P) and (D) and
vice-versa. Note that, since now, we have not imposed on X and Y any particular
structure, nor we have required some particular property on the function Ï•. Now we
recall the main results available in the literature, on the existence of a saddle point
for Ï• : X Ã— Y â†’R.
(i) (von Neumann). Let be
X =

x âˆˆRn
+ :
n

i=1
xi = 1

, Y =
â§
â¨
â©y âˆˆRm
+ :
m

j=1
y j = 1
â«
â¬
â­,

8.2 Introduction to Duality
271
Ï•(x, y) = yâŠ¤Ax, with A matrix of order (m, n). Then Ï• admits a saddle point
(xâˆ—, yâˆ—) on X Ã— Y.
(ii) (Kakutani). Let X and Y be convex and compact sets in Rn and Rm, respec-
tively. Let Ï• be continuous on X Ã— Y, convex with respect to x on X (âˆ€y âˆˆY) and
concave with respect to y on Y (âˆ€x âˆˆX). Then Ï• : X Ã— Y â†’R admits a saddle a
saddle point (xâˆ—, yâˆ—) on X Ã— Y.
(iii) (Sion). Let X and Y be convex and compact sets in Rn and Rm, respectively.
Let Ï• be lower semi-continuous and quasiconvex with respect to x on X and upper
semi-continuous with respect to y on Y. Then Ï• : X Ã— Y â†’R admits a saddle point
(xâˆ—, yâˆ—) on X Ã— Y.
See [16, 17].
We quote also a result, due to [18], which relates min-max theorems to duality
theorems. For other results of this type, the reader is referred to [19â€“22].
Theorem 8.42 Let X and Y be convex and closed sets in Rn and Rm, respectively;
let Ï• : X Ã— Y â†’R be continuous on X Ã— Y, convex with respect to x on X and
concave with respect to y on Y. For the programs
(P) :
min
xâˆˆX max
yâˆˆY Ï•(x, y);
(D) :
max
yâˆˆY min
xâˆˆX Ï•(x, y),
we have the following duality properties.
(i) If (D) admits a solution (xâˆ—, yâˆ—), i.e.
max
yâˆˆY min
xâˆˆX Ï•(x, y) = min
xâˆˆX Ï•(x, yâˆ—) = Ï•(xâˆ—, yâˆ—),
and if the set

x âˆˆX : Ï•(x, yâˆ—) = Ï•(xâˆ—, yâˆ—)

is bounded, then there exists x0 âˆˆX such that (x0, yâˆ—) is a solution of both (P) and
(D) and Ï•(xâˆ—, yâˆ—) = Ï•(x0, yâˆ—).
(ii) If (P) admits a solution (xâˆ—, yâˆ—), i.e.
min
xâˆˆX max
yâˆˆY Ï•(x, y) = max
yâˆˆY Ï•(xâˆ—, y) = Ï•(xâˆ—, yâˆ—),
and if the set

y âˆˆY : Ï•(xâˆ—, y) = Ï•(xâˆ—, yâˆ—)

is bounded, then there exists y0 âˆˆY such that (xâˆ—, y0) is a solution of both (P) and
(D) and Ï•(xâˆ—, yâˆ—) = Ï•(xâˆ—, y0).
Now let us reconsider the primal and dual problems (P) and (D) described at the
beginning of the present section.

272
8
Convex Optimization: Saddle Points Characterization and Introduction to Duality
(P) :
â§
â¨
â©
min f (x)
subject to: gi(x) â‰¦0, i = 1, . . . , m,
x âˆˆX âŠ‚Rn,
i.e.
(P) :
min
xâˆˆX sup L (x, u),
being L (x, u) = f (x) + uâŠ¤g(x), u â‰§0, and
sup
uâ‰§0
L (x, u) =

 f (x), if g(x) â‰¦0,
+âˆ, otherwise,
and
(D) :

max Î¸(u)
subject to: u â‰§0,
where
Î¸(u) = inf
xâˆˆXL (x, u).
On the grounds of what was previously asserted, we have the following result.
Theorem 8.43 The following statements are equivalent:
(i) The Lagrangian function L (x, u) admits a saddle point at (xâˆ—, uâˆ—) âˆˆX Ã— Rm
+.
(ii) xâˆ—is a solution of (P), uâˆ—is a solution of (D) and the optimal values of (P)
and (D) are equal:
f (xâˆ—) = Î¸(uâˆ—).
For the readerâ€™s convenience, we give an â€œautonomous proofâ€ of this theorem.
Proof (i) Suppose that (xâˆ—, uâˆ—) is a saddle point of the Lagrangian function; it will be
g(xâˆ—) â‰¦0 (Theorem 8.3), hence xâˆ—is feasible for (P). Since uâˆ—â‰§0, we have also
that (xâˆ—, uâˆ—) is feasible for (D). Moreover, (Theorem 8.3), Î¸(uâˆ—) = L (xâˆ—, uâˆ—) =
f (xâˆ—) + (uâˆ—)âŠ¤g(xâˆ—) = f (xâˆ—). By Corollary 8.21, xâˆ—and uâˆ—solve (P) and (D),
respectively, with no duality gap.
(ii) Suppose that xâˆ—and uâˆ—are optimal solutions to problem (P) and (D), respec-
tively, with f (xâˆ—) = Î¸(uâˆ—). Hence, we have xâˆ—âˆˆX, g(xâˆ—) â‰¦0 and uâˆ—â‰§0. More-
over, we have by primal-dual feasibility that
Î¸(uâˆ—) = min
xâˆˆX

f (x) + (uâˆ—)âŠ¤g(x)

â‰¦f (xâˆ—) + (uâˆ—)âŠ¤g(xâˆ—) â‰¦f (xâˆ—).
But Î¸(uâˆ—) = f (xâˆ—) by hypothesis. Hence, equality holds throughout above. In
particular, (uâˆ—)âŠ¤g(xâˆ—) = 0 and so,
L (xâˆ—, uâˆ—) = f (xâˆ—) = Î¸(uâˆ—) = min
xâˆˆX

L (x, uâˆ—)

.

References
273
Hence, all properties of Theorem 8.3 hold, in addition to xâˆ—âˆˆX and uâˆ—â‰§0, and
so the pair (xâˆ—, uâˆ—) is a saddle point of the Lagrangian function.
â–¡
References
1. A. Takayama, Mathematical Economics, 2nd edn. (Cambridge University Press, Cambridge,
1985)
2. H. Uzawa, The Kuhn-Tucker theorem in concave programming, in eds. by K.J. Arrow, L.
Hurwicz, H. Uzawa, pp. 32â€“37 (1958). Reprinted in Giorgi and Kjeldsen (2014)
3. H.W. Kuhn, A.W. Tucker, Nonlinear programming, in Proceedings of the Second Berkeley Sym-
posium on Mathematical Statistics and Probability, ed. by J. Neyman (University of California
Press, Berkeley, 1951), pp. 481â€“492. Reprinted in Giorgi and Kjeldsen (2014)
4. S. Karlin, Mathematical Methods and Theory in Games, Programming and Economics, vol. I,
II (Addison-Wesley, Reading, Mass, 1959)
5. T. Weir, B. Mond, Pre-invex functions in multiple objective optimization. J. Math. Anal. Appl.
136, 29â€“38 (1988)
6. K.J. Arrow, L. Hurwicz, H. Uzawa, Constraint qualiï¬cations in maximization problems. Naval
Res. Logist. 8, 175â€“191 (1961). Reprinted in Giorgi and Kjeldsen (2014)
7. H.W. Kuhn, A.W. Tucker (Eds.), Linear Inequalities and Related Systems, Annals of Mathe-
matics Studies N. 38 (Princeton University Press, Princeton, N.J., 1956)
8. O.L. Mangasarian, A simple characterization of solution sets of convex programming. Oper.
Res. Lett. 7, 21â€“26 (1988)
9. J. Von Neumann, O. Morgenstern, Theory of Games and Economic Behavior, 2nd edn. (Prince-
ton University Press, Princeton, 1947)
10. R.T. Rockafellar, Convex Analysis (Princeton University Press, Princeton, 1970)
11. R.T. Rockafellar, Conjugate Duality and Optimization. (Society for Industrial and Applied
Mathematics, Philadelphia, 1974)
12. T.L. Magnanti, Fenchel and Lagrange duality are equivalent. Math. Program. 7, 253â€“258 (1974)
13. P. Wolfe, A duality theorem for non-linear programming. Quart. Appl. Math. 19, 239â€“244
(1961)
14. O.L. Mangasarian, Nonlinear Programming (McGraw-Hill Book Company, New York, 1969)
15. B. Mond, T. Weir, Generalized concavity and duality, in Generalized Concavity in Optimization
and Economics, eds. by S. Schaible, W.T. Ziemba (Academic, New York, 1981), pp.263â€“280
16. M. Sion, On general minimax theorems. Pac. J. Math. 8, 171â€“176 (1958)
17. C. Berge, A. Ghouila-Houri, Programming, Games and Transportation Networks (Wiley, New
York, 1965)
18. J. Stoer, Duality in nonlinear programming and the minimax theorem. Numer. Math. 5, 371â€“379
(1963)
19. S. Karamardian, Strictly quasi-convex (concave) functions and duality in mathematical pro-
gramming. J. Math. Anal. Appl. 20, 344â€“358 (1967)
20. O.L. Mangasarian, J. Ponstein, Minmax and duality in nonlinear programming. J. Math. Anal.
Appl. 11, 504â€“518 (1965)
21. J. Stoer, C. Witzgall, Convexity and Optimization in Finite Dimensions, I (Springer, New York,
1971)
22. W. Vogel, Duale optimierungsaufgaben und sattelpunktsÃ¤. Unternehmensforschung 13, 1â€“28
(1969)

Chapter 9
Linear Programming and Quadratic
Programming
9.1
Linear Programming
As said in the previous pages, a Linear Programming problem (L. P. for friends)
is characterized by a linear (or a linear afï¬ne) objective function and by linear (or
linear afï¬ne) constraints. Usually, the variables are also required to be nonnegative.
As L. P. is a particular case of nonlinear programming (the involved functions are
both convex and concave and differentiable on Rn), all theorems seen for the general
case of nonlinear programming hold also for L. P. and almost always in a simpliï¬ed
form.
The subject of L. P. was considered before the Second World War. The French
mathematician Joseph Fourier (1768â€“1830) was one of the ï¬rst researchers to inves-
tigate this subject and to point out its importance for mechanics and probability
theory. In a certain sense, he may be considered a precursor of the modern theory
on theorems of the alternative for linear systems and for the celebrated â€œsimplex
algorithmâ€ for L. P., devised by the American mathematician Dantzig (1947). In
the Soviet Union, the mathematician L. V. Kantorovich, in 1939, had already pro-
posed an algorithm to solve a special linear programming problem arising from a
transportation problem of products from various industries dislocated in different
territorial points. Subsequently, it appeared that the two algorithms (of Dantzing and
Kantorovich) are in fact equivalent (see, e.g. [1]).
Kantorovich (but not Dantzig) was awarded in 1975 (together with T. C. Koop-
mans) the Nobel Prize in Economic Sciences for the development of L. P.. For some
other historical notions the reader may see the book edited by Giorgi and Kjeldsen
[2]. For a description of various mathematical techniques to deal with a linear pro-
gramming problem, it is useful to the paper of [3] and the works on L. P. quoted in
the References. See also, for example: [4â€“19].
In the present book we shall not be concerned with the algorithms proposed to
solve a linear programming problem, but only with the basic facts on optimality and
duality theory. In L. P. the objective function f is usually expressed in the form
Â© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al., Basic Mathematical Programming Theory, International Series
in Operations Research & Management Science 344,
https://doi.org/10.1007/978-3-031-30324-1_9
275

276
9
Linear Programming and Quadratic Programming
f (x) =
n

i=1
cixi = câŠ¤x,
c, x âˆˆRn, c Ì¸= 0, and the constraints as inequalities of the type
n

j=1
ai jx j â‰¦bi, i = 1, . . . , m,
or, in a matrix form
Ax â‰¦b,
where A is a (real) matrix of order (m, n) and b âˆˆRm. Furthermore, almost always
there is also a â€œsign restrictionâ€ on the variables, in the sense that they are required
to be nonnegative:
xi â‰§0, i = 1, . . . , n; i.e. x â‰§0, x âˆˆRn.
Usually, in case of a maximization problem, a linear programming problem is
written in the form, said â€œcanonical formâ€,
â§
â¨
â©
max câŠ¤x
Ax â‰¦b
x â‰§0.
In case of a minimization problem, usually we have the form (again called â€œcanon-
ical formâ€)
â§
â¨
â©
min câŠ¤x
Ax â‰§b
x â‰§0.
We remark once more that linear programming problems are differentiable opti-
mization problems, both convex and concave. These problems can be represented as
problems with functional constraints expressed by only equalities (this is possible
also for nonlinear programming problems, but in the case of L. P. the procedure is
more important, mostly for algorithmic considerations), by means of the introduc-
tion of nonnegative auxiliary variables, said â€œslack variablesâ€. More precisely, if the
functional constraints are of the type
Ax â‰¦b,
they are transformed into the equivalent equality system
Ax + s = b, s â‰§0,

9.1 Linear Programming
277
with s âˆˆRm.
If the functional constraints are expressed as
Ax â‰§b,
they are transformed into the equivalent equality system
Ax âˆ’s = b, s â‰§0,
with s âˆˆRm.
A linear programming problem in the form
â§
â¨
â©
max(min)câŠ¤x
Ax = b
x â‰§0,
is said to be in â€œstandard formâ€. Some classical books on L. P. adopt an opposite
denomination: they call a â€œcanonical formâ€ what we have called a â€œstandard formâ€
and vice-versa.
The applications of L. P. are numberless, in the most varied sectors; we limit
ourselves to give only some typical examples, arising from management and ï¬nancial
models (one of the ï¬rst books on economic applications of L. P. is the one of [11]).
(a) Diet Problem. A diet problem (in the sense of linear programming) is one of
ï¬nding the least expensive way to meet a given set of daily untrivial goals using
a particular set of foods.
(b) Activity Analysis Problem. We have to use a given set of activities (production
processes) and a given set of resources in order to maximize proï¬t associated
with the production processes subject to limitations on the resources. When the
objective and constraints are expressed by linear (afï¬ne) functions we have a L.
P. problem. The classical book on these questions (containing also the original
paper of G. B. Dantzig on the â€œsimplex algorithmâ€) is the one edited by [20].
(c) Transportation and Assignment Problems. The ï¬rst analysis of these types of
problems is usually attributed to L. V. Kantorovich in 1939 and to F. L. Hitchcock
in 1941: a single commodity is to be â€œshippedâ€ from m sources to n destinations.
At each source i there is a known supply ai > 0 of the commodity. At each
destination j there is a known demand b j > 0 for the commodity. To ship a
single unit of the commodity form source i to destination j costs ci j, the known
unit shipping cost. In such a problem we let the variable xi j denote the amount
of the commodity shipped from i to j. The objective is to minimize the total
shipping cost, taking into account the constraints:

278
9
Linear Programming and Quadratic Programming
â§
âªâªâ¨
âªâªâ©
min m
i=1
n
j=1 ci jxi j
subject to : n
j=1 xi j = ai, i = 1, . . . , m,
m
i=1 xi j = b j, j = 1, . . . , n,
xi j â‰§0, âˆ€i, âˆ€j.
The set K = {x âˆˆRn : Ax â‰¦b, x â‰§0} or K =

x âˆˆRn : Ax â‰§b, x â‰§0
	
or
K =

x âˆˆRn : Ax = b, x â‰§0
	
is the feasible set for a canonical or standard L. P.
problem. In the literature on L. P. the set K is also called â€œset of feasible solutionsâ€,
whereas the optimal point x0 is also called â€œoptimal feasible solutionâ€ (sic!).
Now, let S âŠ‚Rn be a convex set. A point x âˆˆS is called an extreme point of S if
there do not exist points x1 and x2 (x1 Ì¸= x2) in S such that
x = Î»x1 + (1 âˆ’Î»)x2, for 0 < Î» < 1.
Note that strict inequalities are imposed on Î». The deï¬nition stipulates that an
extreme point cannot be â€œbetweenâ€ any other two points of the set. Clearly, an
extreme point is a boundary point of the set, but the vice-versa is not obviously true.
If a convex set contains only a single point, this point will be considered an extreme
point. There exist also convex sets without extreme points: for example in R2 the
open set given by all interior points of a circle.
We have the following basic result on extreme points for convex sets. See, e.g.
[21, 22]. We ï¬rst need the following deï¬nition.
Deï¬nition 9.1 Theset S âŠ‚Rn isboundedfrombelow ifthereexistsavector xâˆ—âˆˆRn
such that
xâˆ—â‰¦x, âˆ€x âˆˆS.
The set S âŠ‚Rn is bounded from above ,if there exists a vector xâˆ—âˆ—âˆˆRn such that
xâˆ—âˆ—â‰§x, âˆ€x âˆˆS.
Obviously, a bounded set S âŠ‚Rn, is both bounded from below and bounded
from above. We recall again the concept of supporting hyperplane for a convex set
S âŠ‚Rn (see also Theorem 2.19): given a boundary point x0 âˆˆS, then câŠ¤x = Î±,
c Ì¸= 0, Î± âˆˆR, is called a supporting hyperplane at x0 if câŠ¤x0 = Î± and if all other
points of S lie in one of the closed half-spaces produced by the hyperplane, that is
câŠ¤x â‰§Î± for all x âˆˆS or câŠ¤x â‰¦Î±, for all x âˆˆS. (If x0 is a boundary point of a
closed convex set, there is at least one supporting hyperplane at x0).
Theorem 9.2 Let S âŠ‚Rn be a closed convex set, bounded from below (or bounded
from above). Then every supporting hyperplane for S contains at least an extreme
point of S.
Deï¬nition 9.3 A set in Rn which can be expressed as the intersection of a ï¬nite
number of closed half-spaces is called a polyhedral set or a polyhedron. A bounded
polyhedron is also called a polytope.

9.1 Linear Programming
279
We have to point out that in the literature there is not uniformity on the above
deï¬nitions. Several authors call â€œpolytopeâ€ what we have called â€œpolyhedronâ€ and
vice-versa. It can be shown that a polytope is given by the convex hull of a ï¬nite
number of points (see Theorem 9.4 below).
The intersection of a ï¬nite number of polyhedra is a polyhedron and if there is a
polytope among them, then the intersection is a polytope. A closed half-space is a
polyhedron; a hyperplane is a polyhedron; the empty set is considered a polytope;
the whole Rn is a polyhedron. It turns out that a polyhedron is a closed convex set.
A polyhedral set can be represented by

x âˆˆRn : Ax â‰¦b
	
or

x âˆˆRn : Ax â‰§b
	
,
where A is a matrix of order (m, n), x âˆˆRn and b âˆˆRm. If b = 0 âˆˆRm, we have
the representation of (convex) polyhedral cones (see Chap. 2).
Any nonempty (unbounded) polyhedron X âŠ‚Rn can be expressed as the sum
of a polytope and a polyhedral cone (Representation Theorem for polyhedra). This
means that for every x âˆˆX, there exist points p âˆˆP, where P âŠ‚Rn is a polytope,
and q âˆˆC, where C âŠ‚Rn is a polyedral cone, such that x = p + q. Accordingly,
we write
X = P + C.
An extreme point of a polyhedron is called also a vertex of the polyhedron. A
polyhedron that has at least a vertex is also called a pointed polyhedron.
Theorem 9.4 A nonempty polytope is given by the convex hull of its vertices.
(This theorem is a particular case of a more general theorem, known as Theorem of
Krein-Milman).
Let x1 and x2 be distinct extreme points of the convex set S âŠ‚Rn. The line
segment joining them is called an edge of the convex set if it is the intersection of S
with a supporting hyperplane. If x1 is an extreme point of S, and if there exists another
point Â¯x âˆˆS such that x = x1 + Î»(Â¯x âˆ’x1) âˆˆS, âˆ€Î» â‰§0, and if, in addition the set
L =

x : x = x1 + Î»(Â¯x âˆ’x1), âˆ€Î» â‰§0
	
is the intersection of S with a supporting
hyperplane, then the set L is said to be an edge of S which extends to inï¬nity.
Two distinct extreme points x1, x2 of the convex set S âŠ‚Rn are called adjacent
if the line segment joining them is an edge of the convex set. These concepts are
particularly useful when S is a convex polyhedron: the extreme points x1 and x2 of
the polyhedron K are adjacent if every point on the line segment joining x1 and x2
cannot be expressed as a convex combination of any pair of points in the convex
polyhedron that are not on this line segment. The line segment joining a pair of
adjacent extreme points of a convex polyhdron is an edge of the convex polyhedron.
From what previously said, we deduce that the feasible set of a linear programming
problem, if non-empty, of the type Ax â‰¦b, x â‰§0, or Ax â‰§b, x â‰§0, or Ax = b,

280
9
Linear Programming and Quadratic Programming
x â‰§0, is a convex polyhedron (hence a closed and convex set). This polyhedron is,
therefore, generated by the hyperplanes of equations
A1x = b1, A2x = b2, . . . , Amx = bm,
where Ai denotes the i-th row of A, i = 1, . . . , m; and by the hyperplanes x1 = 0,
x2 = 0, . . . , xn = 0.
If we denote by K the feasible set of an L. P. problem, then K can be:
(i) Empty, as the constraints are inconsistent.
(ii) Unbounded, i.e. some variables can assume arbitrary large values.
(iii) Bounded (and nonempty), i.e. a polytope. This is surely the most interesting
case, at least for practical problems.
We can now state the ï¬rst fundamental result on L. P.
Theorem 9.5 (First fundamental theorem on L. P.) A linear programming problem
which admits a solution, admits a global solution; furthermore, the optimal points
are not interior points of the feasible set. The optimal point, if unique, is at a vertex
of the feasible set; if the optimal point is not unique, there are inï¬nite optimal points
corresponding to two or more vertices of the feasible set and to all points of the edge
which contains these vertices.
Proof We ï¬rst remark that if the feasible set K is not bounded, the related P. L.
problem may have no solution (we are not saying that the problem has no solution!).
If K is bounded (i.e. it is a polytope), being also closed (and convex) and being
the objective function a continuous function, the theorem of Weierstrass assures the
existence of a solution. Being the objective function a linear (afï¬ne) function, it is
both convex and concave and hence the optimal points, if any, are global optimal
points. In any case, the optimal points cannot be interior to K: indeed, in this case
we would have (Fermatâ€™s theorem) âˆ‡f (x0) = 0, i.e. c = 0 âˆˆRn, which is excluded
by the assumption c Ì¸= 0. Therefore, the optimal points, if any, are on the boundary
of K. Let us consider, for example, the maximum point x0, i.e. we have
câŠ¤x â‰¦câŠ¤x0, âˆ€x âˆˆK.
Clearly, the relation câŠ¤x â‰¦câŠ¤x0 characterizes one of the two half-spaces asso-
ciated to the hyperplane câŠ¤x = câŠ¤x0; this half-space contains the whole K and the
associated hyperplane contains also the point x0 âˆˆK. The said hyperplane is, there-
fore, a supporting hyperplane for K, which is a closed and convex set. But K, in our
assumptions, is also (at least) a lower bounded set (i.e. bounded from below), being
x â‰§0, âˆ€x âˆˆK. Therefore, Theorem 9.2 assures that every supporting hyperplane
for K (and hence also the hyperplane câŠ¤x = câŠ¤x0) contains at least an extreme point
of K. This fact allows to say that at least an extreme point (or vertex) of K is a max-
imum point. Let us prove that if the objective function attains its maximum value
at more than one vertex, then it attains the same value at every point of the convex

9.1 Linear Programming
281
combination of the said maximum points. For example, let us assume that f has a
maximum value at the vertices x1, x2, . . . , xq, i.e.
f (x1) = f (x2) = Â· Â· Â· = f (xq) = M.
If Â¯x is any convex combination of the said vertices, i.e. if
Â¯x = Î»1x1 + Î»2x2 + Â· Â· Â· + Î»qxq,
being Î»i â‰§0, i = 1, . . . , q, q
i=1 Î»i = 1, by the linearity of f we have
f (Â¯x) = f (Î»1x1 + Î»2x2 + Â· Â· Â· + Î»qxq)
= Î»1 f (x1) + Î»2 f (x2) + Â· Â· Â· + Î»q f (xq) = M
q

i=1
Î»i = M,
so, Â¯x represents a (global) maximum point for the objective function. We can, there-
fore, conclude that if the optimal point is not unique and, say, x1 and x2 are two adja-
cent vertices which generate the solution of the problem, also all the inï¬nite points
(which form an edge) of the segment joining x1 and x2 are solutions, Obviously, for
the case of minimum points the reasoning is similar and similar considerations hold
for the case of problems expressed in standard form.
â–¡
Remark 9.6 Obviously, there are L. P. problems which admit no solution, for exam-
ple, because the constraints are inconsistent (i.e. K = âˆ…) or because, with K Ì¸= âˆ…,
the feasible set is not bounded (from below or from above or both) and also the
related objective function is not bounded over K. For example, consider the simple
problem
â§
â¨
â©
max(x1 + x2)
x1 âˆ’x2 â‰¦âˆ’10
x1 â‰§0, x2 â‰§0.
Remark 9.7 Theorem 9.5 may generate the idea that an L. P. problem is, after all,
a trivial problem: it is sufï¬cient to compute the objective function on all vertices of
K and then to draw the related conclusions. Unfortunately, in almost all practical
problems, the number of vertices of a convex polyhedron, generated, e.g. by
Ax â‰¦b, x â‰§0,
with A matrix of order (m, n), x âˆˆRn, b âˆˆRm, is a prohibitive number, also for a
powerful computer. Indeed, this number is less or equal than

m + n
n

.

282
9
Linear Programming and Quadratic Programming
If, for example, m = 50 and n = 100, the said number is about equal to 1040. The
â€œefï¬ciencyâ€ of the â€œsimplex methodâ€ essentially consists of a drastic reduction of
the number of vertices to inspect, in order to arrive to the solution (if there exists!)
through a tractable number of iterations. Sometimes the â€œrunâ€ is not so rosy, however
the algorithm is able to point out the obstacles that may exist. The reader is referred
to the works quoted in the References.
The reader is invited to develop, by using geometric considerations (i. e. the level
lines) the following simple problems in R2, in order to grasp the meaning of the main
propositions of Theorem 9.5.
Example 9.8 Consider the following L. P. problem
â§
âªâªâ¨
âªâªâ©
max z = 5x1 + 3x2
3x1 + 5x2 â‰¦15
5x1 + 2x2 â‰¦10
x1 â‰§0, x2 â‰§0.
The feasible set K is a bounded polyhedron (in R2 perhaps it is better to say
â€œpolygonâ€), whose vertices are (0, 0), (2, 0), (0, 3), ( 20
19, 45
19) (see Fig. 9.1).
The solution is the point x0 = ( 20
19, 45
19), with f (x0) = 235
19
Example 9.9 Consider the following L. P. problem
â§
âªâªâªâªâ¨
âªâªâªâªâ©
max(2x1 + x2)
2x1 âˆ’x2 â‰§0
x1 âˆ’x2 â‰§âˆ’1
x1 âˆ’5x2 â‰§âˆ’20
x1 â‰§0, x2 â‰§0.
The feasible set K is not bounded from above (see Fig. 9.2) and sup
xâˆˆK
f (x) = +âˆ.
Fig. 9.1 Example 9.8.
Feasible set and maximum

9.1 Linear Programming
283
Fig. 9.2 Example 9.9. Feasible set
If, instead of a maximization problem we consider a minimization problem (over
the same feasible set), the solution is x0 = (0, 0).
Example 9.10 Consider the following L. P. problem
â§
âªâªâªâªâ¨
âªâªâªâªâ©
max(âˆ’x1 + x2)
2x1 âˆ’x2 â‰§0
x1 âˆ’x2 + 1 â‰§0
x1 âˆ’5x2 + 20 â‰§0
x1 â‰§0, x2 â‰§0.
Note that the feasible set K is the same as Example 9.9. However, with this
objective function we have that the two adjacent vertices of K:
A = (1, 2); B =

15
4 , 19
4

are solutions of the problem, with f (A) = f (B) = 1. Hence, all points of the seg-
ment (edge) joining A and B are also solutions. Indeed, consider the (inï¬nite) points
x(Î») = Î»
 1
2

+ (1 âˆ’Î»)

15
4
19
4

, Î» âˆˆ[0, 1] .
Let us compute câŠ¤x(Î») :
[âˆ’1, 1]

Î» + (1 âˆ’Î») 15
4
2Î» + (1 âˆ’Î») 19
4

= âˆ’Î» âˆ’15
4 + Î»15
4 + 2Î» + 19
4 âˆ’Î»19
4 = 1.

284
9
Linear Programming and Quadratic Programming
We repeat that in the present book, we will not treat the computational questions
related to the â€œsimplex algorithmâ€, however, we present some â€œalgebraicâ€ results
that, in a sense, are basic for the theoretical foundations of the said algorithm and
that allow us to obtain the second fundamental theorem for L. P.
Let us consider a linear programming problem in its standard form:
â§
â¨
â©
min(max) câŠ¤x
Ax = b
x â‰§0,
(9.1)
where A is a matrix of order (m, n), x, c âˆˆRn, c Ì¸= 0, and b âˆˆRm. Without loss of
generality, let us assume that:
m < n and A has full rank, i.e. rk(A) = m.
This condition is not restrictive: indeed, if m = n (and rk(A) = m), the system admits
a unique solution x0, and this solution is feasible if x0 â‰§0. If m > n, and if the
system Ax = b admits solutions, then (m âˆ’n) constraints are linear combinations
of the remaining constraints. Therefore, these (m âˆ’n) constraints can be eliminated.
As rk(A) = m, it is always possible to choose m linearly independent columns of
A. Without loss of generality we assume that the ï¬rst m columns of A are linearly
independent (permute the columns, if necessary). We obtain the partitioned matrix
A = [B; N] ,
where B is square, non-singular, of order m and N is of order (m, n âˆ’m).
The matrix B is called a â€œbasis matrixâ€ of A, as its lines are a basis for Rm. In
correspondence, the vector x âˆˆRn is decomposed as follows
x =
 xB
xN

,
with xB âˆˆRm and xN âˆˆRnâˆ’m. The variables of xB are said â€œbasic variablesâ€ and
the variables of xN are said â€œnon-basic variablesâ€. We have
Ax = [B; N]
 xB
xN

= BxB + NxN = b,
from which, being B non-singular,
xB = Bâˆ’1b âˆ’Bâˆ’1NxN
and hence
x =
 Bâˆ’1b
0

+
âˆ’Bâˆ’1N
I

xN
(9.2)

9.1 Linear Programming
285
is a solution of Ax = b for all xN âˆˆRnâˆ’m.
Deï¬nition 9.11 The solution obtained by (9.2) putting in it xN = 0, i.e.
x =
 Bâˆ’1b
0

is said a basic solution. If, moreover, it holds x â‰§0, this solution is said a feasible
basic solution.
Deï¬nition 9.12 A basic solution with more than (n âˆ’m) zero components is said
a degenerate basic solution. If, moreover, this solution is nonnegative, we speak
of a feasible degenerate basic solution. The matrix B is also called, in this case,
degenerate basis matrix.
Example 9.13 Let us suppose that the system Ax = b is the following one:
â¡
â£
âˆ’2 0 0 1 0
0
1 0 0 2
0
0 1 3 2
â¤
â¦x =
â¡
â£
4
12
18
â¤
â¦.
The ï¬rst three columns of A are linearly independent, hence
xB =
â¡
â£
âˆ’2 0 0
0
1 0
0
0 1
â¤
â¦
âˆ’1 â¡
â£
4
12
18
â¤
â¦=
â¡
â£
âˆ’2
12
18
â¤
â¦.
The solution is x = [âˆ’2, 12, 18, 0, 0]âŠ¤which is a basic solution, but not feasible,
as x1 < 0.
Note that also the sub-matrix is formed by the fourth, second, and third column:
â¡
â£
1 0 0
0 1 0
3 0 1
â¤
â¦
is non-singular; hence, another basic solution is given by
xB =
â¡
â£
1 0 0
0 1 0
3 0 1
â¤
â¦
âˆ’1 â¡
â£
4
12
18
â¤
â¦=
â¡
â£
4
12
6
â¤
â¦.
Hence the solution x = [0, 12, 6, 4, 0]âŠ¤is a basic solution and a feasible basic
solution.
The notion of a basic solution is important as the search for optimal solutions (of
an L. P. problem) is performed among the basic solutions.

286
9
Linear Programming and Quadratic Programming
Theorem 9.14 (Second fundamental theorem on L. P.) Let be given a linear pro-
gramming problem in the standard form (9.1), with m < n and rk(A) = m. If this
problem admits a nonempty feasible set, then there exists a feasible basic solution.
If there exists a solution to the problem, then there exists an optimal basic (feasible)
solution.
Proof Let us suppose that x âˆˆK Ì¸= âˆ…, i.e.
Ax = b, x â‰§0,
i.e. with Ai denoting the i-th column of A,
n

i=1
xi Ai = b.
Let us suppose that x has p non-zero components (0 â‰¦p â‰¦n) and, without loss
of generality, let us suppose that these components are the ï¬rst p components. The
last relation becomes then
p

i=1
xi Ai = b.
(9.3)
We can have two cases:
(1) The columns A1, . . . , Ap are linearly independent, hence p â‰¦m. If p = m, we
have a basic solution, if p < m we have a degenerate basic solution and it is
possible to choose m âˆ’p columns among Ap+1, . . . , An, which, together with
the ï¬rst p columns form a basis.
(2) The columns A1, . . . , Ap are linearly dependent, i.e. there exist multipliers
y1, . . . , yp, not all zero, such that
p

i=1
yi Ai = 0.
(9.4)
From (9.3) and (9.4), by subtracting and multiplying (9.4) by a generic scalar Î±,
we obtain
p

i=1
(xi âˆ’Î±yi)Ai = b, âˆ€Î± âˆˆR.
We now deï¬ne y =

y1, . . . , yp, 0, . . . , 0
âŠ¤and so we obtain A(x âˆ’Î±y) = b, hence
x âˆ’Î±y satisï¬es the system, but it may be not feasible, i.e. not nonnegative. It is,
however, possible to choose Î± in such a way that at least one component of x âˆ’Î±y
is equal to zero (i.e. that component is feasible).
Now, let us consider every component of x âˆ’Î±y, with Î± âˆˆR:

9.1 Linear Programming
287
xi âˆ’Î±yi
â§
âªâ¨
âªâ©
= xi > 0, âˆ€Î±, if yi = 0
â‰§0, âˆ€Î± â‰§xi
yi , if yi < 0
â‰§0, âˆ€Î± â‰¦xi
yi , if yi > 0.
If we choose Â¯Î± = xiâˆ—
yiâˆ—Ì¸= 0, where iâˆ—is the index such that

xiâˆ—
yiâˆ—
 = min

xi
yi
 : yi Ì¸= 0, i = 1, . . . , p

,
then x âˆ’Î±y is a solution with at most p âˆ’1 non zero components, being equal to
zero the component corresponding to iâˆ—.
By iterating this process, it is possible to get a solution corresponding to linearly
independent columns. In order to prove that if there exists a feasible optimal solution,
then there exists also a feasible basic optimal solution, we can follow the same lines
of the previous proof. Again we consider two cases.
(i) The columns A1, . . . , Ap are linearly independent. In this case, the solution
considered, obtained by adding the zero components, is a basic solution.
(ii) The columns A1, . . . , Ap are linearly dependent. By modifying the vector x as
in the ï¬rst part of the present proof, we remark that câŠ¤x becomes câŠ¤x âˆ’Î±câŠ¤y.
We know that x âˆ’Î±y is feasible for every Î± âˆˆ[âˆ’|Â¯Î±| , |Â¯Î±|] . If câŠ¤y > 0 we
would have câŠ¤x âˆ’|Â¯Î±| câŠ¤y < câŠ¤x, against the assumption that x is optimal. If
câŠ¤y < 0 we would have câŠ¤x + |Â¯Î±| câŠ¤y < câŠ¤x, against the assumption that x is
optimal. Hence câŠ¤y = 0 and the optimality of the solution is kept, by passing
from x to x âˆ’Â¯Î±y, a solution with at most p âˆ’1 non zero components.
â–¡
The previous theorem is important, as it allows to reduce the computations of the
objective function over the set of the basic feasible solutions, whose number is less
or equal than

 n
m

=
n!
m!(n âˆ’m)!.
Moreover,itisalsopossibletoputintorelationtheverticesofaconvexpolyhedron,
generated by a linear programming problem in its standard form, and the basic
feasible solutions of the same problem.
Theorem 9.15 Let us consider a linear programming problem in its standard form
(9.1), with A of full rank and let P be the convex polyhedron generated by the
constraints of the said problem. Then the following statements are equivalent.
(a) x is a vertex of P.
(b) x is a basic feasible solution of the feasible set K.
Proof Let x be a basic feasible solution of a linear programming problem in its
standard form; we have, therefore,

288
9
Linear Programming and Quadratic Programming
x =
 xB
0

, xB âˆˆRm,
(9.5)
with det(B) Ì¸= 0 and xB = Bâˆ’1b. In order to prove that x is a vertex of P we have
to show that there do not exist two vectors x1, x2 âˆˆK, x1 Ì¸= x2 such that
x = Î»x1 + (1 âˆ’Î»)x2, 0 < Î» < 1.
(9.6)
Absurdly let us suppose that there exist two vectors x1 and x2 which verify (9.6)
and given by
x1 =
u1
v1

, x2 =
u2
v2

,
(9.7)
with u1, u2 âˆˆRm and v1, v2 âˆˆRnâˆ’m. By substituting relation (9.5) into relations
(9.6) and (9.7) and making equal the last (n âˆ’m) components, we obtain
0 = Î»v1 + (1 âˆ’Î»)v2
(9.8)
with Î» > 0, 1 âˆ’Î» > 0, v1 â‰§0, v2 â‰§0. Therefore, (9.8) holds only for v1 = v2 = 0.
Remembering that x1 and x2 are feasible, we have
Ax1 = Bu1 = b,
Ax2 = Bu2 = b.
From Bu1 = Bu2, being B non-singular, it follows u1 = u2 and hence x1 = x2,
against the assumptions, so x is a vertex of P.
Vice-versa,letussupposethat x isavertexof P andthat x hasitsï¬rstk components
different from zero. It will hold
x1A1 + x2 A2 + Â· Â· Â· + xk Ak = b
with xi > 0, i = 1, . . . , k. In order to show that x is a basic feasible solution, we have
to prove that A1, A2, . . . , Ak are linearly independent. If, absurdly, these vectors are
linearly dependent, there would exist a linear combination
y1A1 + y2 A2 + Â· Â· Â· + yk Ak = 0,
with yi not all zero. Then, putting yâŠ¤= (y1, y2, . . . , yk, 0, . . . , 0) âˆˆRn one has
x + Î±y âˆˆP forallÎ± âˆˆR.Rememberingthat xi > 0,i = 1, . . . , k,itwillbepossible
to choose Îµ > 0 such that
xi + Îµyi > 0; xi âˆ’Îµyi > 0 âˆ€i = 1, 2, . . . , k.

9.2 Duality for Linear Programming
289
Putting x = 1
2(x + Îµy) + 1
2(x âˆ’Îµy), this vector is given by the convex combi-
nation of two distinct vectors of P, which is absurd, as x is a vertex of P. Hence
A1, A2, . . . , Ak are linearly independent and x is a basic feasible solution.
â–¡
We conclude the present section by remarking that the solution of a linear pro-
gramming problem, in its standard form, is unique if xB > 0 (then B is unique), i.e.
for a non-degenerate basic solution; B can be non unique if some component of xB
is equal to zero, i.e. for a degenerate basic solution.
9.2
Duality for Linear Programming
DualitytheorywasbornwithinlinearmodelsandmostlywithinL.P.models.Wehave
already given in the previous chapter an example of dual problem for a â€œprimalâ€ L.
P. problem. It seems that it was the father of G. B. Dantzig, Tobias Dantzing, himself
a mathematician, who suggested the name of â€œprimal problemâ€, in contraposition
to â€œdual problemâ€. Duality theory for L. P. problems is important, not only from a
theoretical point of view, but also from a computational point of view: there exists also
a â€œdual simplex algorithmâ€, which can be used, together with the simplex algorithm,
to ameliorate the procedure of determining the solution of an L. P. problem.
â€¢ If we consider a primal linear programming problem in its canonical form, of the
type
(P) :
â§
â¨
â©
max câŠ¤x
Ax â‰¦b
x â‰§0,
its dual is the problem
(D) :
â§
â¨
â©
min yâŠ¤b (or bâŠ¤y)
yâŠ¤A â‰§câŠ¤(or AâŠ¤y â‰§c)
y â‰§0.
â€¢ If we consider a primal linear programming problem in its canonical form, of the
type
(P) :
â§
â¨
â©
min câŠ¤x
Ax â‰§b
x â‰§0,
its dual is the problem
(D) :
â§
â¨
â©
max yâŠ¤b (or bâŠ¤y)
yâŠ¤A â‰¦câŠ¤(or AâŠ¤y â‰¦c)
y â‰§0.

290
9
Linear Programming and Quadratic Programming
â€¢ If we consider a primal linear programming problem in its standard form, of the
type
(P) :
â§
â¨
â©
max câŠ¤x
Ax = b
x â‰§0,
its dual is the problem
(D) :
â§
â¨
â©
min yâŠ¤b (or bâŠ¤y)
yâŠ¤A â‰§câŠ¤(or AâŠ¤y â‰§c)
(y unrestricted).
â€¢ If we consider a primal linear programming problem in its standard form, of the
type
(P) :
â§
â¨
â©
min câŠ¤x
Ax = b
x â‰§0,
its dual is the problem
(D) :
â§
â¨
â©
max yâŠ¤b (or bâŠ¤y)
yâŠ¤A â‰¦câŠ¤(or AâŠ¤y â‰¦c)
(y unrestricted).
On the grounds of what previously asserted, it is worth remarking what follows.
(a) The dual (D) of the primal problem (P) is unique and is itself a linear program-
ming problem.
(b) The dual of the dual is the primal problem (â€œinvolution propertyâ€). We speak
also of a â€œpairâ€ of primal-dual problems.
(c) If (P) is a maximization problem, (D) is a minimization problem (and vice-
versa). If (P) is a minimization problem, (D) is a maximization problem (and
vice-versa).
(d) The coefï¬cients of the objective function of (D) are the right-hand side coefï¬-
cients of the functional constraints of (P) and the right-hand side coefï¬cients of
the functional constraints of (D) are the coefï¬cients of the objective function of
(P).
(e) If (P) is in its canonical form, also (D) is in a canonical form, but with the
constraints â€œreversedâ€, with respect to the constraints of the primal problem.
(f) If (P) is in its standard form, (D) is in a canonical form, but without sign
restrictions on the variables.
(g) If (P) is in a canonical form, but without sign restrictions on the variables, then
(D) is in a standard form.
For cases (f) and (g) we speak also of â€œasymmetricâ€ primal and dual problems. We
can resume the above correspondences between primal and dual in the following

9.2 Duality for Linear Programming
291
scheme, where I, J, M and N are sets of indices.
PRIMAL
DUAL
min câŠ¤x

max câŠ¤x

max yâŠ¤b

min yâŠ¤b

Constraints : = bi, i âˆˆI;
Variables : yi, i âˆˆI, unrestricted;
â‰§bi, i âˆˆJ;
yi â‰§0, i âˆˆJ;
Variables : x j â‰§0, j âˆˆM;
Constraints : â‰¦c j, j âˆˆM;
x j, j âˆˆN, unrestricted;
= c j, j âˆˆN.
Let us verify property (b). We consider the primal problem in the form
(P) :
â§
â¨
â©
max câŠ¤x
Ax â‰¦b
x â‰§0.
Its dual
(D) :
â§
â¨
â©
min yâŠ¤b
yâŠ¤A â‰§câŠ¤
y â‰§0
can be rewritten in the form
â§
â¨
â©
max(âˆ’yâŠ¤b)
âˆ’yâŠ¤A â‰¦âˆ’câŠ¤
y â‰§0,
i.e.
â§
â¨
â©
max yâŠ¤(âˆ’b)
yâŠ¤(âˆ’A) â‰¦âˆ’câŠ¤
y â‰§0.
If we dualize the last formulation we obtain
â§
â¨
â©
min(âˆ’c)âŠ¤x
(âˆ’A)x â‰§âˆ’b
x â‰§0,
i.e.
â§
â¨
â©
max câŠ¤x
Ax â‰¦b
x â‰§0,
which is just the primal problem we have considered at the beginning.
Let us verify property (f). We consider the following primal problem in its standard
form:

292
9
Linear Programming and Quadratic Programming
â§
â¨
â©
max câŠ¤x
Ax = b
x â‰§0,
which we rewrite in the form
â§
âªâªâ¨
âªâªâ©
max câŠ¤x
Ax â‰¦b
Ax â‰§b
x â‰§0,
i.e.
â§
âªâªâ¨
âªâªâ©
max câŠ¤x
Ax â‰¦b
âˆ’Ax â‰¦âˆ’b
x â‰§0,
,
i.e.
â§
âªâªâ¨
âªâªâ©
max câŠ¤x
 A
âˆ’A

x â‰¦
 b
âˆ’b

x â‰§0.
Now we dualize the last formulation:
â§
â¨
â©
min((y1)âŠ¤b âˆ’(y2)âŠ¤b)
((y1)âŠ¤A âˆ’(y2)âŠ¤A) â‰§câŠ¤
y1 â‰§0, y2 â‰§0.
If we put y = y1 âˆ’y2, we obtain
 min yâŠ¤b
yâŠ¤A â‰§câŠ¤,
with y unrestricted in sign, as y = y1 âˆ’y2, with y1 â‰§0 and y2 â‰§0 (obviously the
difference may be a vector with components unrestricted in sign).
Example 9.16 By using the dualizing rules of a maximization problem in its canon-
ical form, deduce the dual of
(P) :
â§
â¨
â©
min câŠ¤x
Ax â‰§b
x â‰§0.
We transform the primal problem into a maximization problem:
â§
â¨
â©
max(âˆ’câŠ¤x)
(âˆ’A)x â‰¦âˆ’b
x â‰§0.
Then we have:
(D) :
â§
â¨
â©
min yâŠ¤(âˆ’b)
yâŠ¤(âˆ’A) â‰§âˆ’câŠ¤
y â‰§0,

9.2 Duality for Linear Programming
293
i.e.
â§
â¨
â©
max yâŠ¤b
yâŠ¤A â‰¦câŠ¤
y â‰§0.
If we have the following general L. P. primal problem
(P) :
â§
âªâªâªâªâ¨
âªâªâªâªâ©
max [min] (c1)âŠ¤x1 + (c2)âŠ¤x2 + (c3)âŠ¤x3
A11x1 + A12x2 + A13x3 â‰§b1
A21x1 + A22x2 + A23x3 = b2
A31x1 + A32x2 + A33x3 â‰¦b3
x1 â‰§0, x2 unrestricted, x3 â‰¦0,
its dual is
(D) :
â§
âªâªâ¨
âªâªâ©
min [max] (b1)âŠ¤y1 + (b2)âŠ¤y2 + (b3)âŠ¤y3
AâŠ¤
11y1 + AâŠ¤
21y2 + AâŠ¤
31y3 â‰§c1 
â‰¦c1
AâŠ¤
12y1 + AâŠ¤
22y2 + AâŠ¤
32y3 = c2
AâŠ¤
13y1 + AâŠ¤
23y2 + AâŠ¤
33y3 â‰¦c3 
â‰§c3
.
The relations between the two problems, primal and dual, are strict and interesting,
not only from a formal point of view, and give rise to several results, useful also for
computational and interpretative aspects. First of all we make some considerations
on the Lagrangian functions of the primal and dual problems. We consider, e.g. the
primal problem
(P) :
â§
â¨
â©
max câŠ¤x
Ax â‰¦b
x â‰§0
and its dual
(D) :
â§
â¨
â©
min yâŠ¤b
yâŠ¤A â‰§câŠ¤
y â‰§0.
We write the respective Lagrangian functions, denoted, respectively, by L and
M :
L (x, Î») = câŠ¤x âˆ’Î»âŠ¤(Ax âˆ’b) = câŠ¤x + Î»âŠ¤(b âˆ’Ax) = câŠ¤x + Î»âŠ¤b âˆ’Î»âŠ¤Ax;
M (y, Î¼) = yâŠ¤b + (câŠ¤âˆ’yâŠ¤A)Î¼ = yâŠ¤b + câŠ¤Î¼ âˆ’yâŠ¤AÎ¼.
Putting in L , Î» = y and putting in M , Î¼ = x, the two Lagrangian functions
become equal:
L (x, y) = câŠ¤x + yâŠ¤b âˆ’yâŠ¤Ax = M (y, x) = yâŠ¤b + câŠ¤x âˆ’yâŠ¤Ax.

294
9
Linear Programming and Quadratic Programming
This shows that the vector of the variables of a problem is the vector of the
multipliers of the other problem. We now write the Karush-Kuhn-Tucker conditions
for the two said problems. We recall that being the constraints linear afï¬ne, the
problems are qualiï¬ed. Moreover, being also the objective functions linear functions
(i.e. both convex and concave), the Karush-Kuhn-Tucker conditions are necessary
and sufï¬cient for the optimality of a feasible point that veriï¬es the said conditions.
Hence, Ë†x is a solution of (P) if and only if there exists a vector Ë†y such that
âˆ‡xL (Â·, Ë†y) = câŠ¤âˆ’Ë†yâŠ¤A â‰¦0;
(câŠ¤âˆ’Ë†yâŠ¤A)Ë†x = 0;
b âˆ’A Ë†x â‰§0;
Ë†yâŠ¤(b âˆ’A Ë†x) = 0;
Ë†x â‰§0,
Ë†y â‰§0.
Similarly, Ë†y is a solution of (D) if and only if there exists a vector Ë†x such that
âˆ‡yM (Ë†x, Â·) = b âˆ’A Ë†x â‰§0;
Ë†yâŠ¤(b âˆ’A Ë†x) = 0;
câŠ¤âˆ’Ë†yâŠ¤A â‰¦0;
(câŠ¤âˆ’Ë†yâŠ¤A)Ë†x = 0;
Ë†y â‰§0,
Ë†x â‰§0.
The Karush-Kuhn-Tucker conditions are, therefore, the same for the two prob-
lems: if Ë†x is a solution of (P), then there exists Ë†y which satisï¬es the KKT conditions.
Vice-versa, if Ë†y is a solution of (D), then there exists Ë†x which satisï¬es the same con-
ditions.
Other relations between the primal problem (P) and its dual problem (D) are
put forward by various theorems and properties. We begin with two fundamental
â€œexistence theoremsâ€ on the primal and dual. We follow [23]. We continue to consider
(P) as a maximization problem in its canonical form and (D) as its dual problem.
We denote by K the feasible set of (P), i.e.
K =

x âˆˆRn : Ax â‰¦b, x â‰§0
	
and by Y the feasible set of (D), i.e.
Y =

y âˆˆRm : yâŠ¤A â‰§câŠ¤, y â‰§0
	
.
Theorem 9.17 (First fundamental existence theorem) Assume that K Ì¸= âˆ…and Y Ì¸=
âˆ…. Then:
(i) yâŠ¤b â‰§câŠ¤x, for any x âˆˆK, for any y âˆˆY.
(ii) Ë†yâŠ¤b = câŠ¤Ë†x for some Ë†x âˆˆK, Ë†y âˆˆY.

9.2 Duality for Linear Programming
295
Proof (i) Since y â‰§0 for y âˆˆY, pre-multiplying Ax â‰¦b (being x âˆˆK) by yâŠ¤âˆˆY,
yields yâŠ¤Ax â‰¦yâŠ¤b. Similarly, as x â‰§0 for x âˆˆK, we have yâŠ¤Ax â‰§câŠ¤x for all
y âˆˆY. Whence
yâŠ¤b â‰§yâŠ¤Ax â‰§câŠ¤x, âˆ€x âˆˆK, âˆ€y âˆˆY.
(ii) A method to prove (ii) is to use Farkasâ€™ theorem of the alternative (see
Theorem 2.28). In view of (i), it sufï¬ces to see that Ë†yâŠ¤b â‰¦câŠ¤Ë†x for some Ë†x âˆˆK
and Ë†y âˆˆY. Thus we have only to show the existence of a solution, consisting of an
m-dimensional vector y and an n-dimensional vector x, of the system
â›
â
0
A
âˆ’AâŠ¤
0
bâŠ¤
âˆ’câŠ¤
â
â 

 y
x

â‰¦
â›
â
b
âˆ’câŠ¤
0
â
â 
(9.9)
y â‰§0, x â‰§0.
(9.10)
This system can be converted, by introducing an (m + n + 1)-dimensional slack
vector w, to the system of equations
â›
â
0
A
âˆ’AâŠ¤
0
I
bâŠ¤
âˆ’câŠ¤
â
â 
â›
â
y
x
w
â
â =
â›
â
b
âˆ’c
0
â
â ,
(9.11)
y â‰§0, x â‰§0, w â‰§0,
(9.12)
where I is the identity matrix of order (m + n + 1).
Then, in the light of Farkasâ€™ theorem, the system of equations (9.11)â€“(9.12) has
a solution if
(pâŠ¤, qâŠ¤, Î¸)
â›
â
b
âˆ’c
0
â
â â‰§0
(9.13)
for any solution (pâŠ¤, qâŠ¤, Î¸) of
(pâŠ¤, qâŠ¤, Î¸)
â›
â
0
A
âˆ’AâŠ¤
0
I
bâŠ¤
âˆ’câŠ¤
â
â â‰§0,
(9.14)
where the dimension of the vectors pâŠ¤, qâŠ¤, Î¸ are m, n, 1, respectively.
Let us see that this sufï¬cient condition is fulï¬lled in effect whenever K Ì¸= âˆ…,
Y Ì¸= âˆ…. To this end, it is convenient to decompose (9.14) into the equivalent relations
pâŠ¤A â‰§Î¸câŠ¤; Aq â‰¦Î¸b
(9.15)
p â‰§0, q â‰§0, Î¸ â‰§0.
(9.16)

296
9
Linear Programming and Quadratic Programming
We divide the subsequent discussion into cases (a) and (b), depending on the
positivity of Î¸.
(a) Case Î¸ > 0. Dividing (9.15), (9.16) by Î¸ > 0, we obtain (pâŠ¤/Î¸)A â‰§câŠ¤,
(p/Î¸) â‰§0, A(q/Î¸) â‰¦b, (q/Î¸) â‰§0, so that p/Î¸ âˆˆY, (q/Î¸) âˆˆK. Whence by
part (i), bâŠ¤(p/Î¸) â‰§câŠ¤(q/Î¸), which, multiplied by Î¸ > 0, implies (9.13).
(b) Case Î¸ = 0. Equations (9.15) and (9.16) become pâŠ¤A â‰§0, p â‰§0, Aq â‰¦0,
q â‰§0. Choose some arbitrary x from K and y from Y. Then pâŠ¤b â‰§pâŠ¤(Ax) =
(pâŠ¤A)x â‰§0, câŠ¤q â‰¦(yâŠ¤A)q = yâŠ¤(Aq) â‰¦0. Hence bâŠ¤p âˆ’câŠ¤q + 0 Â· Î¸ â‰§0,
which implies (9.13).
Therefore, (9.14) implies (9.13) in both cases (a) and (b), so that the system of
equations (9.11)â€“(9.12) has a solution, or equivalently, the system of inequalities
(9.9)â€“(9.10) has a solution. This completes the proof.
â–¡
The duality situation established above can be expressed in a slightly different
way in the following second fundamental â€œexistence theoremâ€. We continue to make
reference to the maximization problem (P) in its canonical form and to its related
dual problem (D), with K and Y feasible sets of, respectively, (P) and (D).
Theorem 9.18 (Second fundamental existence theorem)
(i) If K Ì¸= âˆ…, then (P) admits a solution if and only if Y Ì¸= âˆ….
(ii) If Y Ì¸= âˆ…, then (D) admits a solution if and only if K Ì¸= âˆ….
Proof If Y Ì¸= âˆ…, then the assumptions of Theorem 6 are met, so that the common
value of Ë†yâŠ¤b and câŠ¤Ë†x in Theorem 9.17(ii) is a ï¬nite maximum (i.e. a solution) of
(P), as well as a ï¬nite minimum (i.e. a solution) of (D).
Conversely, let us prove that if Y = âˆ…, the function câŠ¤x is unbounded from above
on the set K, or, more symbolically, supxâˆˆK câŠ¤x = +âˆ. If we use a slack vector u
of dimension n, we ï¬nd that the emptiness of Y is equivalent to the non-existence of
a nonnegative solution (uâŠ¤, vâŠ¤) of
(uâŠ¤, vâŠ¤)

 âˆ’I
A

= câŠ¤,
where I is the identity matrix of order n. By FarkasÃ¢Åâ„¢theorem (see Theorem 2.28)
there is some n-dimensional vector Ë†q such that

âˆ’I
A

Ë†q â‰§0, câŠ¤Ë†q < 0.
If the substitution Ë†y = âˆ’Ë†q is done, these results become A Ë†y â‰¦0, câŠ¤Ë†y > 0, Ë†y â‰§0.
Choose now an arbitrary x from K; then x(Ï) = x + Ï Ë†y âˆˆK for all Ï > 0 and
câŠ¤x(Ï) = câŠ¤x + ÏcâŠ¤Ë†y â†’+âˆ, as Ï â†’+âˆ, as was to be shown. The proof of
(ii) is exactly similar.
â–¡

9.2 Duality for Linear Programming
297
Remark 9.19 The result (i) of Theorem 9.17 is also known as the weak duality
theorem for L. P., whereas the result (ii) of Theorem 9.17, together with Theorem
9.18, i.e. if Ë†x is feasible for (P) and Ë†y is feasible for (D), then the equality câŠ¤Ë†x = Ë†yâŠ¤b
is a necessary and sufï¬cient condition for Ë†x to be a solution of (P) and Ë†y to be a
solution of (D), is also known as the strong duality theorem for L. P.
We can summarize what previously said as follows (K and Y are, as usual, the
feasible sets of, respectively, the primal problem (P) and its associated dual (D)).
1. {K Ì¸= âˆ…, Y Ì¸= âˆ…} â‡”There exists a solution of (P) and (D).
2. K = âˆ…â‡’It holds Y = âˆ…or it holds Y Ì¸= âˆ…, but in this case the objective function
of (D) is unbounded over Y.
3. Y = âˆ…â‡’It holds K = âˆ…or it holds K Ì¸= âˆ…, but in this case the objective function
of (P) is unbounded over K.
Example 9.20 Consider the problem
â§
âªâªâ¨
âªâªâ©
max(4x1 + x2)
x1 âˆ’3x2 â‰¦30
âˆ’x1 + x2 â‰¦10
x1 â‰§0, x2 â‰§0.
It is seen without difï¬culty that the objective function is unbounded on the feasible
set K. Hence the problem admits no solution. Its dual is
â§
âªâªâ¨
âªâªâ©
min(30y1 + 10y2)
y1 âˆ’y2 â‰§4
âˆ’3y1 + y2 â‰§1
y1 â‰§0, y2 â‰§0.
Its feasible set, by Theorem 9.18(i), is empty: Y = âˆ….
We have other theorems which relate the primal problem (P) to its dual problem
(D). Again we assume that (P) is of the form
(P) :
â§
â¨
â©
max câŠ¤x
Ax â‰¦b
x â‰§0,
with dual
(D) :
â§
â¨
â©
min yâŠ¤b
yâŠ¤A â‰§câŠ¤
y â‰§0.
Theorem 9.21 (Equilibrium theorem or complementary slackness theorem) Let Ë†x âˆˆ
K and Ë†y âˆˆY. Then, Ë†x and Ë†y are solutions, respectively, of (P) and (D) if and only
if the following complementary slackness conditions hold:

298
9
Linear Programming and Quadratic Programming
(câŠ¤âˆ’Ë†yâŠ¤A)Ë†x = 0;
Ë†yâŠ¤(b âˆ’A Ë†x) = 0.
Proof The two above conditions are necessary, as they are part of the Karush-Kuhn-
Tucker conditions for (P) and (D). As for what concerns the sufï¬ciency, we note
that if Ë†x and Ë†y satisfy the said slackness complementary conditions, we have
câŠ¤Ë†x âˆ’Ë†yâŠ¤A Ë†x = 0 = Ë†yâŠ¤b âˆ’Ë†yâŠ¤A Ë†x.
Therefore, we have câŠ¤Ë†x = Ë†yâŠ¤b and so it holds (strong duality) that Ë†x solves (P)
and Ë†y solves (D).
â–¡
Remark 9.22 The complementary slackness conditions of Theorem 9.21 can be
rewritten in the form (Ai is the i-th row of A, whereas A j is the j-th column of A):
(a)
Ë†yi > 0 â‡’Ai Ë†x = bi;
(b)
Ai Ë†x < bi â‡’Ë†yi = 0;
(c)
Ë†x j > 0 â‡’Ë†yâŠ¤A j = c j;
(d)
Ë†yâŠ¤A j > c j â‡’x j = 0.
It is possible to give economic interpretations of these implications; see, e.g. [23].
The following result, due originally to Goldman and Tucker (see [24]), puts into
relation the primal and dual problems with the saddle point of the related Lagrangian
function.Fortheusualmaximizationproblem(P),theLagrangianfunctionisdeï¬ned
as
L (x, y) = câŠ¤x + yâŠ¤(b âˆ’Ax) = yâŠ¤b + (câŠ¤âˆ’yâŠ¤A)x,
x â‰§0, y â‰§0.
For the said maximization problem (P) a pair (Ë†x, Ë†y) âˆˆRn
+ Ã— Rm
+ is a saddle point
of L (x, y) if
L (x, Ë†y) â‰¦L (Ë†x, Ë†y) â‰¦L (Ë†x, y), âˆ€x âˆˆRn
+, âˆ€y âˆˆRm
+.
(9.17)
We recall that no constraint qualiï¬cation is needed (for the necessary conditions),
as the constraints are linear afï¬ne functions.
Theorem 9.23 (Saddle point and duality) The primal problem (P) admits a solution
Ë†x and the dual problem (D) admits a solution Ë†y if and only if the pair (Ë†x, Ë†y) is a saddle
point for the Lagrangian function L (x, y), i.e. if and only if (9.17) is satisï¬ed.
Proof (i) Necessity. If (Ë†x, Ë†y) is a pair of optimal solutions of, respectively, (P) and
(D), we have
câŠ¤Ë†x = Ë†yâŠ¤b,
Ë†x â‰§0,
Ë†y â‰§0,
b âˆ’A Ë†x â‰§0, câŠ¤âˆ’Ë†yâŠ¤A â‰¦0,

9.2 Duality for Linear Programming
299
Ë†yâŠ¤(b âˆ’A Ë†x) = (câŠ¤âˆ’Ë†yâŠ¤A)Ë†x = 0.
Whence
L (Ë†x, Ë†y) = Ë†yâŠ¤b + (câŠ¤âˆ’Ë†yâŠ¤A)Ë†x â‰§Ë†yâŠ¤b + (câŠ¤âˆ’Ë†yâŠ¤A)x = L (x, Ë†y), âˆ€x âˆˆRn
+;
L (Ë†x, Ë†y) = câŠ¤Ë†x + Ë†yâŠ¤(b âˆ’A Ë†x) â‰¦câŠ¤Ë†x + yâŠ¤(b âˆ’A Ë†x) = L (Ë†x, y), âˆ€y âˆˆRm
+,
proving the necessity.
(ii) Sufï¬ciency. If (Ë†x, Ë†y) is a saddle point of the Lagrangian function, (9.17)
entails
yâŠ¤(b âˆ’A Ë†x) â‰§0, âˆ€y âˆˆRm
+,
(câŠ¤âˆ’Ë†yâŠ¤A)x â‰¦0, âˆ€x âˆˆRn
+,
giving rise to
A Ë†x â‰¦b, Ë†x â‰§0, Ë†yâŠ¤A â‰§câŠ¤,
Ë†y â‰§0.
Hence Ë†x âˆˆK, Ë†y âˆˆY. On the other hand, (9.17) for x = 0, y = 0 implies
Ë†yâŠ¤b = L (0, Ë†y) â‰¦L (Ë†x, Ë†y) â‰¦L (Ë†x, 0) = câŠ¤Ë†x,
which proves the optimality of Ë†x, Ë†y. Therefore, Ë†x solves (P) and Ë†y solves (D).
â–¡
On the grounds of what previously expounded we can assert that the following
propositions are equivalent:
1. The Lagrangian function L (x, y) = câŠ¤x + yâŠ¤(b âˆ’Ax) has a saddle point
(Ë†x, Ë†y) over Rn
+ Ã— Rm
+.
2. The primal problem has an optimal solution Ë†x.
3. The dual problem has an optimal solution Ë†y.
4. Both the primal and the dual have a nonempty feasible set.
5. Ë†x is feasible for the primal and Ë†y is feasible for the dual and câŠ¤Ë†x = bâŠ¤Ë†y.
Finally, we give some insights on sensitivity for L. P. problems. The literature on
sensitivity, stability and in general postoptimal analysis for L. P. problems is quite
abundant (see, e.g. [25â€“27] and the works on L. P. quoted in the References of the
present book). We remark once more that the vector of the solutions of the dual
problem Ë†y, is nothing but the vector of the multipliers of the Lagrangian function
L (Â·, Â·). Let us consider, as before, the primal problem
(P) :
â§
â¨
â©
max câŠ¤x
Ax â‰¦b
x â‰§0,
and its dual problem

300
9
Linear Programming and Quadratic Programming
(D) :
â§
â¨
â©
min yâŠ¤b
yâŠ¤A â‰§câŠ¤
y â‰§0.
Let us consider the optimal value function v(b) of the primal problem, as a function
of the right-hand side vector b (while A is kept constant).
We write K(b) to put into evidence the dependence of the feasible set of (P) from
b. Let us denote
B =

b âˆˆRm : K(b) Ì¸= âˆ…
	
.
Theorem 9.24 The optimal value function v(b) is concave on B.
Proof Let Ë†x1 and Ë†x2 be two solutions of (P) corresponding, respectively, to b1, b2 âˆˆ
B, with c ï¬xed. Then it can be easily veriï¬ed that Î»1 Ë†x1 + Î»2 Ë†x2 âˆˆK(Î»1b1 + Î»2b2)
for any Î»1 â‰§0, Î»2 â‰§0, Î»1 + Î»2 = 1. Hence
v(Î»1b1 + Î»2b2) â‰§Î»1câŠ¤Ë†x1 + Î»2câŠ¤Ë†x2 = Î»1v(b1) + Î»2v(b2),
proving the desired concavity.
â–¡
Corrolary 9.25 The optimal value function v(b) is continuous on int(B). It is pos-
sible to prove that v(b) is continuous on B.
Corrolary 9.26 The optimal value function v(b) has right-hand side and left-hand
side partial derivatives on int(B).
Theorem 9.27 If Ë†yi, i = 1, . . . , m, is the i-th component of any optimal solution Ë†y
of (D), then we have, with b âˆˆint(B),
âˆ‚v
âˆ‚bâˆ’
i
â‰§Ë†yi â‰§âˆ‚v
âˆ‚b+
i
, i = 1, . . . , m.
Furthermore, if the dual problem (D) has a unique solution Ë†y, then the optimal
value function v(b) is differentiable at the corresponding point b and it holds
âˆ‡v(b) = Ë†y.
The economic interpretation of the last result is the same as the one given in Chap.
7: in economic analysis the dual solutions Ë†yi are called â€œshadow pricesâ€ or â€œmarginal
costsâ€ relative to the resource bi.
If (D) does not admit a unique solution, things are more complicate. However,
it is possible to prove that if the set of dual solutions is compact, then the left-hand
sided and the right-hand sided partial derivatives of the optimal value function v(b)
are computable in the way expressed by the following result.
Theorem 9.28 Let the set U(b) of the optimal solutions of the dual problem (D) be
nonempty and compact. Then it holds

9.3 Quadratic Programming
301
âˆ‚v
âˆ‚b+
i
= min
Ë†yâˆˆU(b) Ë†yi;
âˆ‚v
âˆ‚bâˆ’
i
= max
Ë†yâˆˆU(b) Ë†yi,
where Ë†yi denotes the i-th component of Ë†y.
For a discussion on uniqueness of the solutions in an L. P. problem see, e.g. [28].
9.3
Quadratic Programming
In the present section we give some insights on an important type of nonlinear
programming problems: the quadratic programming problems. All such problems
have a quadratic objective function and linear afï¬ne constraints. A quadratic function
is one of the form
Ï•(x) = 1
2 xâŠ¤Cx + câŠ¤x + Î±
(the presence of the factor 1
2 is useful when the gradient and Hessian of Ï•(x) are
computed), where usually C is a symmetric matrix of order n, and x, c âˆˆRn, Î± âˆˆR.
Usually the scalar Î± is omitted, as it does not affect the location of an optimal solution.
Therefore, in the sequel we shall consider a quadratic function in the form
Ï•(x) = 1
2 xâŠ¤Cx + câŠ¤x.
(9.18)
The subject of Quadratic Programming has been considered in several books and
papers, e.g. [29â€“34]. Quadratic programming has, similarly to L. P., many applica-
tions; one of the most important applications is the so-called â€œPortfolio Selection
Problemâ€, introduced by [35, 36]. Markowitz was, for the said contribution, one
of the recipients of the 1990 Nobel Prize in Economic Science. Another possible
application of quadratic optimization is the following one: consider the problem of
approximately solving an over-determined linear system Ax = b, where A has more
rows than columns. We might want to solve the problem
min
xâˆˆRn âˆ¥Ax âˆ’bâˆ¥.
Now note that âˆ¥Ax âˆ’bâˆ¥2 = xâŠ¤AâŠ¤Ax âˆ’2bâŠ¤Ax + bâŠ¤b, and so this problem is
equivalent to
min
xâˆˆRn

xâŠ¤AâŠ¤Ax âˆ’2bâŠ¤Ax + bâŠ¤b
	
which is in the format of a quadratic programming problem.
The assumption that C is symmetric is not restrictive, as it holds.

302
9
Linear Programming and Quadratic Programming
xâŠ¤Cx = 1
2 xâŠ¤(C + CâŠ¤)x
for any x âˆˆRn and so we can replace the non-symmetric matrix C by the symmetric
matrix Â¯C = 1
2(C + CâŠ¤). The matrix (C + CâŠ¤) is called the â€œsymmetric partâ€ of C;
therefore, in this section we assume, without loss of generality that in (9.18) C is
symmetric. Note that
âˆ‡Ï•(x) = Cx + c
and
âˆ‡2Ï•(x) = C.
Note that if in (9.18) we have c = 0 âˆˆRn, then Ï•(x) becomes a quadratic form:
Ï•(x) â‰¡Q(x) = xâŠ¤Cx.
(9.19)
We recall (see also Chap. 1) that a quadratic form (9.19) and its associated sym-
metric matrix C are positive semideï¬nite if
xâŠ¤Cx â‰§0, âˆ€x âˆˆRn.
If, in addition,
xâŠ¤Cx > 0, âˆ€x âˆˆRn, x Ì¸= 0,
then the quadratic form (9.19) and the matrix C are positive deï¬nite.
In [37] it is proved the following result.
Theorem 9.29 The symmetric matrix C of order n is positive semideï¬nite if and
only if
v âˆˆRn, vâŠ¤Cv â‰¦0 â‡’Cv = 0.
Proof (a) We have
vâŠ¤Cv â‰¦0 â‡’vâŠ¤Cv = 0,
so that vâŠ¤Cv < 0 cannot occur, and, therefore, vâŠ¤Cv â‰§0, âˆ€v âˆˆRn.
(b) Assuming vâŠ¤Cv â‰§0 to hold for all v âˆˆRn, we have to prove that Â¯vâŠ¤C Â¯v = 0
implies C Â¯v = 0. For every w âˆˆRn, Î³ âˆˆR, we have
0 â‰¦(w + Î³ Â¯v)âŠ¤C(w + Î³ Â¯v) = wâŠ¤Cw + 2Î³ wâŠ¤C Â¯v + Î³ 2Â¯vâŠ¤C Â¯v =
= wâŠ¤Cw + 2Î³ wâŠ¤C Â¯v.
The relation 0 â‰¦wâŠ¤Cw + 2Î³ wâŠ¤C Â¯v cannot hold for all Î³ âˆˆR but if wâŠ¤C Â¯v = 0,
and this holds for all w âˆˆRn only if C Â¯v = 0.
â–¡

9.3 Quadratic Programming
303
We remark furthermore that:
â€¢ The positive semideï¬nite matrix C is positive deï¬nite if and only if it is non-
singular. In this case the inverse Câˆ’1 is symmetric and is also positive deï¬nite.
â€¢ We have proved, in Chap. 3, that the quadratic form (9.19) is a convex (resp. a
strictly convex) function if and only if C is positive semideï¬nite (resp. positive
deï¬nite). These properties hold also for a quadratic function (9.18), as convexity
(resp. strict convexity) of Ï•(x) depends only from matrix C, being the addendum
câŠ¤x linear.
â€¢ The last result (last lines of the previous point) has been reï¬ned by [37] who proved
that the quadratic function
Ï•(x)=1
2 xâŠ¤Cx + câŠ¤x
is convex in any convex set X âŠ‚Rn, with a nonempty interior (e.g. Rn
+) if and
only if C is positive semideï¬nite.
The following results are immediate.
Theorem 9.30 Suppose that C is a positive semideï¬nite matrix; then the quadratic
function Ï•(x) = 1
2 xâŠ¤Cx + câŠ¤x attains its (global) minimum at xâˆ—if and only if xâˆ—
solves the system
âˆ‡Ï•(x) = Cx + c = 0.
If C is positive deï¬nite, then the unique global minimum of Ï•(x) is given by
xâˆ—= âˆ’Câˆ’1c.
Another, less trivial, result on the existence of optimal points for quadratic func-
tions, is given in the following theorem.
Theorem 9.31 If a quadratic function (9.18) is bounded from below (from above)
on a nonempty polyhedron, it assumes its minimum (maximum) there.
A full proof of the previous result is given, e.g. in [38].
We can describe various types of quadratic programming problems, e.g. the
following ones.
(QP1) :
min
1
2 xâŠ¤Cx + câŠ¤x : Ax â‰§b, x â‰§0

.
(QP2) :
min
1
2 xâŠ¤Cx + câŠ¤x : Ax = b, x â‰§0

.
(QP3) :
min
1
2 xâŠ¤Cx + câŠ¤x : Ax â‰§b

.

304
9
Linear Programming and Quadratic Programming
(QP4) :
min
1
2 xâŠ¤Cx + câŠ¤x : Ax = b

.
We note that the Lagrangian function for the above problems is
L (x, u) = 1
2 xâŠ¤Cx + câŠ¤x + uâŠ¤(b âˆ’Ax),
i.e.
L (x, u) = 1
2 xâŠ¤Cx + câŠ¤x âˆ’uâŠ¤(Ax âˆ’b).
It is easy, on the grounds of what expounded in the previous chapters, to write the
Karush-Kuhn-Tucker conditions for the various quadratic programming problems
described above (we recall that, being the constraints linear afï¬ne, the problems are
automatically qualiï¬ed).
â€¢ We begin with (QP1). The related Karush-Kuhn-Tucker and feasibility conditions
are (see (b1) in Table 5.1, p. 151):
x â‰§0; c + Cx âˆ’AâŠ¤u â‰§0;
xâŠ¤(c + Cx âˆ’AâŠ¤u) = 0;
u â‰§0;
âˆ’b + Ax â‰§0; uâŠ¤(âˆ’b + Ax) = 0.
Putting v â‰¡c + Cx âˆ’AâŠ¤u and y â‰¡Ax âˆ’b, we obtain
â§
â¨
â©
Ax âˆ’y = b
Cx âˆ’AâŠ¤u âˆ’v = âˆ’c
x â‰§0, u â‰§0, y â‰§0, v â‰§0
(9.20)
xâŠ¤v = 0; uâŠ¤y = 0.
(9.21)
The conditions (9.20) form a system of (m + n) equations with 2m + 2n unknowns.
The vector y has the meaning of some slack vector in the initial problem while v
may be interpreted as a slack vector in a dual problem. Conditions (9.21), that may
be rewritten as
x jv j = 0, 1 â‰¦j â‰¦n;
ui yi = 0, 1 â‰¦i â‰¦m,
show that we are interested only in those solutions of the system (9.20) which have
no more than (m + n) nonzero components.
Let us consider again the Eqs. (9.20) and (9.21)

9.3 Quadratic Programming
305
Ax âˆ’y = b
âˆ’Cx + AâŠ¤u + v = c
xâŠ¤v = 0; uâŠ¤y = 0
x â‰§0, u â‰§0, y â‰§0, v â‰§0.
Now letting
M =

0
A
âˆ’AâŠ¤C

; q =
 âˆ’b
c

; w =
 y
v

; z =
 u
x

,
we can rewrite the Karush-Kuhn-Tucker conditions above as a linear complemen-
tarity problem
w âˆ’Mz = q; wâŠ¤z = 0; (w, z) â‰§0.
Linear complementarity problems are an important subject within mathematical
programming (and also with reference to other types of problems), with both theoretic
and algorithmic consequences. See, e.g. [39, 40]).
We write the Karush-Kuhn-Tucker and the feasibility conditions for the other
types of quadratic programming problems previously considered.
â€¢ For (QP2) we have
Ax = b
Cx âˆ’v + AâŠ¤u = âˆ’c
x â‰§0, v â‰§0
xâŠ¤v = 0.
â€¢ For (QP3) we have
Ax + y = b
Cx âˆ’AâŠ¤u = âˆ’c
y â‰§0, u â‰§0
uâŠ¤y = 0.
â€¢ For (QP4) we have
Cx + AâŠ¤u = âˆ’c
Ax = b.

306
9
Linear Programming and Quadratic Programming
For what concerns the sufï¬cient optimality conditions, we can assert that if xâˆ—
satisï¬es the feasibility conditions, the Karush-Kuhn-Tucker conditions for (QPi),
i = 1, 2, 3, 4, and the matrix C is positive semideï¬nite, i.e. Ï•(x) is a convex function,
then xâˆ—is a solution of problem (QPi), i = 1, 2, 3, 4, by Remark 6.7(a). Obviously,
we could require that C is positive semideï¬nite only on the corresponding feasi-
ble set, but in this case the problem becomes more complicate. If we require, in
(QP1) and (QP2), that C is positive semideï¬nite on Rn
+, we gain nothing: recall that
a quadratic function Ï•(x) = 1
2 xâŠ¤Cx + câŠ¤x is convex on any convex set X âŠ‚Rn,
with a nonempty interior, if and only if C is positive semideï¬nite. Let us suppose
that in (QP2) the matrix A, of order (m, n), has full rank: rk(A) = m. In [41] it is
remarked that if Ï•(x) is convex on the feasible set S =

x âˆˆRn : Ax = b, x â‰§0
	
,
then it is convex on the larger set {x : Ax = b} and the same author shows that this
is so if and only if the quadratic form Q(x) = xâŠ¤Cx is positive semideï¬nite when
constrained by the homogeneous linear system Ax = 0. So, we have to solve the
problem
Ax = 0 â‡’xâŠ¤Cx â‰§0,
for which the criteria on constrained quadratic forms are applicable. See Chap. 1,
[30, 31].
Again: if in (QP4) the matrix A is of rank m and the matrix C is positive deï¬nite,
i.e. Ï•(x) = 1
2 xâŠ¤Cx + câŠ¤x is a strictly convex function and hence the feasible point
xâˆ—which veriï¬es the Karush-Kuhn-Tucker conditions, is the unique solution of the
problem, we can obtain an explicit formula for the solution and for the multipliers
vector. We rewrite for (QP4) the feasibility conditions and the Karush-Kuhn-Tucker
conditions:
Axâˆ—= b
Cxâˆ—+ c + AâŠ¤u = 0
Being C non-singular, we can write these conditions as follows
Axâˆ—= b; xâˆ—+ Câˆ’1c + Câˆ’1 AâŠ¤u = 0
(9.22)
or also, multiplying by A, as
Axâˆ—= b; ACâˆ’1 AâŠ¤u + ACâˆ’1c + b = 0.
(9.23)
The matrix ACâˆ’1 AâŠ¤, of order m, is symmetric and positive deï¬nite; indeed
yâŠ¤ACâˆ’1 AâŠ¤y = (AâŠ¤y)âŠ¤Câˆ’1 AâŠ¤y â‰§0, âˆ€y âˆˆRm.
We have
yâŠ¤ACâˆ’1AâŠ¤y = (AâŠ¤y)âŠ¤Câˆ’1 AâŠ¤y = 0

9.3 Quadratic Programming
307
if and only if AâŠ¤y = 0, i.e. if and only if y = 0 (AâŠ¤is injective, being of rank m;
Câˆ’1 is symmetric and positive deï¬nite). Therefore, from (9.23) and (9.22) we obtain
u = âˆ’B(ACâˆ’1c + b);
xâˆ—= Câˆ’1AâŠ¤B(ACâˆ’1c + b) âˆ’Câˆ’1c;
where we have put B â‰¡(ACâˆ’1 AâŠ¤)âˆ’1.
Instead of convexity of Ï•(x), i.e. of the quadratic form Q(x), we can assume
pseudoconvexity of Ï•(x), in order to obtain that the feasible point xâˆ—satisfying the
Karush-Kuhn-Tucker conditions for the various quadratic programming problems is
a (global) solution of the related problem by Theorem 6.6. We shall give, at the end
of the present section, some insights on the generalized convexity of quadratic forms
and quadratic functions. Finally, we remark that those quadratic forms Q(x) = xâŠ¤Cx
which are positive semideï¬nite on Rn
+, are called copositive (the same name is used
for the symmetric matrix C). Checking copositivity is, however, not a trivial task
(see, e. g., [39]).
We now consider the Wolfe dual problem of a quadratic programming problem.
Duality for quadratic programming problems was ï¬rst studied in [42]. For simplicity
we develop our analysis for the primal problem (QP3):
(QP3) :
min
x
1
2 xâŠ¤Cx + câŠ¤x : Ax â‰§b

,
where c âˆˆRn, b âˆˆRm, C is a symmetric matrix of order m and A is a matrix of
order (m, n), m â‰¦n.
The Wolfe dual of (QP3) can be written in the form
(DQP3) :
max
(x,u)

g(x, u) â‰¡bâŠ¤u âˆ’1
2 xâŠ¤Cx : AâŠ¤u âˆ’Cx = c, u â‰§0

.
Indeed, the Lagrangian function of (QP3) is
L (x, u) = câŠ¤x + 1
2 xâŠ¤Cx + uâŠ¤(b âˆ’Ax)
= bâŠ¤u âˆ’1
2 xâŠ¤Cx + xâŠ¤(c + Cx âˆ’AâŠ¤u).
Hence
âˆ‡xL (x, u) = câŠ¤+ 1
2Cx + 1
2 xâŠ¤C âˆ’uâŠ¤A = c + Cx âˆ’AâŠ¤u = 0.
Substituting this constraint in the objective function of the dual problem we obtain
the familiar form of (DQP3) given in [42]:

308
9
Linear Programming and Quadratic Programming
max
(x,u)

câŠ¤x + 1
2 xâŠ¤Cx + uâŠ¤(b âˆ’Ax) : c + Cx âˆ’AâŠ¤u = 0, u â‰§0

= max
(x,u)

câŠ¤x + 1
2 xâŠ¤Cx + bâŠ¤u âˆ’uâŠ¤Ax : c = AâŠ¤u âˆ’Cx, u â‰§0

= max
(x,u)

uâŠ¤Ax âˆ’xâŠ¤Cx + 1
2 xâŠ¤Cx + bâŠ¤u âˆ’uâŠ¤Ax : AâŠ¤u âˆ’Cx = c, u â‰§0

= max
(x,u)

(bâŠ¤u âˆ’1
2 xâŠ¤Cx) â‰¡g(x, u) : AâŠ¤u âˆ’Cx = c, u â‰§0

(in the second equality we have substituted câŠ¤by uâŠ¤A âˆ’xâŠ¤C).
If C is non-singular, (DQP3) reduces to
(DQP3) :
max
u

dâŠ¤u âˆ’1
2uâŠ¤Du : u â‰§0

,
with D â‰¡ACâˆ’1AâŠ¤; d â‰¡b + ACâˆ’1c â‰¡b âˆ’A Ëœx, with Ëœx = âˆ’Câˆ’1c.
Indeed, in this case the unique solution of
c + Cx âˆ’AâŠ¤u = 0
is given by
x = Câˆ’1 
AâŠ¤u âˆ’c

.
Substituting in the dual problem this last relation, we have the above given for-
mulation.
Let us denote by K and by Y the feasible sets of, respectively, (QP3) and (DQP3).
We have the following basic duality results for (QP3).
Theorem 9.32 Assume that C is positive semideï¬nite (i.e. the quadratic function
Ï•(x) = 1
2 xâŠ¤Cx + câŠ¤x is a convex function on Rn). Then:
(i) (Weak duality theorem):
âˆ€x1 âˆˆK, âˆ€(x2, u2) âˆˆY : Ï•(x1) â‰§g(x2, u2).
(ii) (Dornâ€™s duality theorem). If (QP3) has a solution xâˆ—, then there exists some
uâˆ—âˆˆRm
+ such that (xâˆ—, uâˆ—) solves (DQP3) and the two extrema are equal.
(iii) (Dornâ€™s converse duality theorem). If (DQP3) admits a solution (xâˆ—, uâˆ—), then
there exists some x0 (not necessarily equal to xâˆ—), satisfying Cx0 = Cxâˆ—, that
solves (QP3) and the two extrema are equal. If C is positive deï¬nite, then xâˆ—
is the unique solution of (QP3).
(iv) If both problems (QP3) and (DQP3) have a nonempty feasible set, then both
problems admit a solution.

9.3 Quadratic Programming
309
(v) If one of the two problems, (QP3) or (DQP3), has a nonempty feasible set, but
the other one has an empty feasible set, then the ï¬rst problem has an inï¬nite
extremal value.
Proof Properties (i) and (ii) are direct consequences of the results of Wolfe for
duality in differentiable nonlinear programming problems (see Theorems 8.27 and
8.28). Now we prove (iii). Being (xâˆ—, uâˆ—) solution of (DQP3), there exists (see
Remark 6.5(a)) vâˆ—âˆˆRn such that, with
L (u, x, v) â‰¡âˆ’bâŠ¤u + 1
2 xâŠ¤Cx + vâŠ¤(AâŠ¤u âˆ’Cx âˆ’c),
it holds
âˆ‡xL (uâˆ—, xâˆ—, vâˆ—) = Cxâˆ—âˆ’Cvâˆ—= 0;
(9.24)
âˆ‡uL (uâˆ—, xâˆ—, vâˆ—) = Avâˆ—âˆ’b â‰§0;
(9.25)
(uâˆ—)âŠ¤(Avâˆ—âˆ’b) = 0.
(9.26)
By (9.25), it follows that vâˆ—is feasible for (QP3). As (xâˆ—, uâˆ—) is feasible for
(DQP3), we have AâŠ¤uâˆ—âˆ’Cxâˆ—= c, hence câŠ¤= (uâˆ—)âŠ¤A âˆ’(xâˆ—)âŠ¤C. Substituting
in Ï•, it results Ï•(vâˆ—) = 1
2(vâˆ—)âŠ¤Cvâˆ—+ câŠ¤vâˆ—= 1
2(vâˆ—)âŠ¤Cvâˆ—+ (uâˆ—)âŠ¤Avâˆ—âˆ’(xâˆ—)âŠ¤Cvâˆ—.
From (9.26), (uâˆ—)âŠ¤Avâˆ—= (uâˆ—)âŠ¤b, and from (9.24), (xâˆ—)âŠ¤c = (vâˆ—)âŠ¤C, in conse-
quence
Ï•(vâˆ—) = 1
2(vâˆ—)âŠ¤Cvâˆ—+ (uâˆ—)âŠ¤Cvâˆ—= bâŠ¤uâˆ—âˆ’1
2(vâˆ—)âŠ¤Cvâˆ—= g(vâˆ—, uâˆ—).
Therefore, by (i) we have that vâˆ—is a solution of (QP3) and satisï¬es relation (9.24).
Now we prove (iv). This property results from (i) and from the fact that a quadratic
function, bounded from below (resp., from above) on a nonempty convex polyhedron,
reaches in the said polyhedron its minimum (resp., maximum) value (Theorem 9.31).
Now we prove (v). We have (Theorem 8.34) that if K = âˆ…, Y Ì¸= âˆ…, then
sup
(x,u)âˆˆY
g(x, u) = +âˆ. Conversely, let K Ì¸= âˆ…, Y = âˆ…. Being Y = âˆ…, by a theorem
of the alternative for linear systems and precisely the statements (see Sect. 2.2, point
6)
S â‰¡(Ax + By = b, x â‰§0);
Sâˆ—â‰¡(AâŠ¤u â‰§0, BâŠ¤u = 0, bâŠ¤u < 0),
there exists v âˆˆRn such that
Av â‰§0, Cv = 0, câŠ¤v < 0.
(9.27)

310
9
Linear Programming and Quadratic Programming
If x0 âˆˆK, then Ax0 â‰§b and so, âˆ€Î» â‰§0 it holds A(x0 + Î»v) â‰§b, i.e. âˆ€Î» â‰§0
we have x0 + Î»v âˆˆK and using (9.27), Ï•(x0 + Î»v) = Ï•(x0) + Î»câŠ¤v â†’âˆ’âˆfor
Î» â†’+âˆ.
â–¡
Remark 9.33 The dual pairs of quadratic programming problems considered above
possess a nice feature not shared by the Wolfe pairs of primal and dual problems: if
C is positive semideï¬nite, then the objective function of the primal is convex on Rn
and the objective function of the dual is concave on Rn Ã— Rm.
For the readerâ€™s convenience, we write the Dornâ€™s duality formulation also for the
other quadratic programming problems considered in the present section.
(QP1) :
min
x
1
2 xâŠ¤Cx + câŠ¤x : Ax â‰§b, x â‰§0

,
(DQP1) :
max
(x,u)

bâŠ¤u âˆ’1
2 xâŠ¤Cx : AâŠ¤u âˆ’Cx â‰¦c, u â‰§0

.
(QP2) :
min
x
1
2 xâŠ¤Cx + câŠ¤x : Ax = b, x â‰§0

,
(DQP2) :
max
(x,u)

bâŠ¤u âˆ’1
2 xâŠ¤Cx : AâŠ¤u âˆ’Cx â‰¦c

.
(QP4) :
min
x
1
2 xâŠ¤Cx + câŠ¤x : Ax = b

,
(DQP4) :
max
(x,u)

bâŠ¤u âˆ’1
2 xâŠ¤Cx : AâŠ¤u âˆ’Cx = c

.
We point out that Cottle [43] has proposed the following pair of primal and dual
quadratic programming problems, which result to be symmetric, i.e. for this pair it
holds the involution property.
(Cottle P) :
min
(x,y)

câŠ¤x + 1
2 xâŠ¤Cx + 1
2 yâŠ¤By : Ax + By â‰§b, x â‰§0, y â‰§0

â‰¡
min
(x,y)âˆˆZ1 f (x, y);
(Cottle DP) : max
(y,x)

bâŠ¤y âˆ’1
2 yâŠ¤By âˆ’1
2 xâŠ¤Cx : AâŠ¤y âˆ’Cx â‰¦c, y â‰§0, x â‰§0

â‰¡max
(x,y)âˆˆZ2g(x, y),

9.3 Quadratic Programming
311
with c âˆˆRn, b âˆˆRm, A of order (m, n), B a symmetric matrix of order n.
If we write (Cottle DP) in the form
âˆ’min
(y,x)

âˆ’bâŠ¤y + 1
2 yâŠ¤By + 1
2 xâŠ¤Cx : âˆ’AâŠ¤y + Cx â‰§âˆ’c, y â‰§0, x â‰§0

,
we note that the dual of (Cottle DP) is just (Cottle P) and hence the involution
property holds.
Theorem 9.34 (Cottle) Let the matrices C and B be positive semideï¬nite. Then the
following properties hold:
(i)
f (x1, y1) â‰§g(x2, y2), âˆ€(x1, y1) âˆˆZ1, âˆ€(x2, y2) âˆˆZ2.
(ii) If one of the two problems (Cottle P) or (Cottle DP) has a solution, then there
exists a common solution for (Cottle P) and (Cottle DP) such that the two
optimal values are equal. More precisely:
(a) If (Cottle P) admits a solution (xâˆ—, yâˆ—), then there exists y0 âˆˆRm
+, with
By0 = Byâˆ—, such that (xâˆ—, y0) is a solution of both (Cottle P) and (Cottle
DP).
(b) If (Cottle DP) admits a solution (xâˆ—, yâˆ—), then there exists x0 âˆˆRn
+, with
Cx0 = Cxâˆ—, such that (x0, yâˆ—) is a solution of both (Cottle DP) and (Cottle
P).
(iii) If both problems have a nonempty feasible set, then both problems admit a
solution.
(iv) If one of the two problems has a nonempty feasible set, but the other one has
an empty feasible set, then the ï¬rst of the two problems has an unbounded
objective function.
Finally, we give some insights on generalized convexity of quadratic forms and
quadratic functions. These topics have been extensively studied by various authors:
see, e.g. [32â€“34, 37, 44â€“46].
We have seen that a quadratic form
Q(x) = xâŠ¤Cx,
with C symmetric matrix of order n, is convex on Rn (resp. strictly convex) if and
only if C is positive semideï¬nite (resp. positive deï¬nite) and that a quadratic function
Ï•(x) = 1
2 xâŠ¤Cx + câŠ¤x
is convex on any convex set X âŠ‚Rn, with a nonempty interior, if and only if C is
positive semideï¬nite [37]. Since the sum of quasiconvex functions is not necessarily
quasiconvex, the quasiconvexity of the quadratic function Ï•(x) does not follow from
the quasiconvexity of the quadratic form xâŠ¤Cx, as it is the case for convexity.

312
9
Linear Programming and Quadratic Programming
We recall that a quadratic function Ï•(x) = 1
2 xâŠ¤Cx + câŠ¤x (where C is a real
symmetric matrix, of order n, and c âˆˆRn) is quasiconvex on the open convex set
X âŠ‚Rn (see Theorem 3.20(b)) if and only if, for all x, y âˆˆX:
1
2 yâŠ¤Cy + câŠ¤y â‰¦1
2 xâŠ¤Cx + câŠ¤x â‡’(c + Cx)âŠ¤(y âˆ’x) â‰¦0.
The quadratic function Ï•(x) is pseudoconvex on the open convex set X âŠ‚Rn (see
Deï¬nition 3.21) if and only if, for all x, y âˆˆX :
(c + Cx)âŠ¤(y âˆ’x) â‰§0 â‡’1
2 yâŠ¤Cy + câŠ¤y â‰§1
2 xâŠ¤Cx + câŠ¤x.
It is obvious that the convexity of a quadratic function depends only, as said before,
on the matrix C, while the pseudoconvexity and quasiconvexity may depend also on
the coefï¬cient vector c of the linear part. However, with reference to the whole space
Rn, we have the following basic result on the quasiconvexity of quadratic functions,
given in [37].
Theorem 9.35 The quadratic function Ï•(x) is quasiconvex on Rn if and only if it is
convex on Rn.
Proof Let v be any point of Rn and Î± > 0 a number such that
Ï•(Î±v) â‰¦Ï•(âˆ’Î±v).
(9.28)
(Change the sign of v, not of Î±, if necessary).
Then
1
2Î±2vâŠ¤Cv + Î±câŠ¤v â‰¦1
2Î±2vâŠ¤Cv âˆ’Î±câŠ¤v,
i.e. Î± > 0, this also (9.28) holds for any Î± > 0. If now Ï•(x) is quasiconvex on Rn,
then (9.28) implies that for all Î± > 0
[Î±v âˆ’(âˆ’Î±v)]âŠ¤[C(âˆ’Î±v) + c] = âˆ’2Î±2vâŠ¤Cv + 2Î±câŠ¤v â‰¦0,
or equivalently
Î±vâŠ¤Cv â‰§câŠ¤v.
The last inequality holds for all Î± > 0 only if vâŠ¤Cv â‰§0 (or (âˆ’v)âŠ¤C(âˆ’v) â‰§0,
if the sign of v has been changed); as v has been chosen arbitrarily, one has that C
is positive semideï¬nite and thus Ï•(x) is convex on Rn. The converse statement is
obvious: if Ï•(x) is convex, it is also quasiconvex by Theorem 3.25.
â–¡
On the grounds of the previous results we have, therefore, the following equiva-
lences (see also Theorem 3.26):

9.3 Quadratic Programming
313
Ï• convex on Rn â‡”Ï• pseudoconvex on Rn â‡”Ï• quasiconvex on Rn
â‡”xâŠ¤Cx convex on Rn â‡”C positive semideï¬nite.
Moreover, the previous results show also that there is no reason to study quadratic
functions that are quasiconvex on Rn, neither those that are convex on Rn
+ (recall
that a quadratic function Ï•(x) is convex on any convex set X âŠ‚Rn, with a nonempty
interior, if and only if C is positive semideï¬nite). However, there are quadratic
functions that are quasiconvex on Rn
+, without being convex on the same set. Take,
e.g. the function Ï•(x1, x2) = âˆ’x1x2.
Different is the case of the generalized convexity of quadratic forms and quadratic
functions, referred to proper subsets of Rn, for example the nonnegative orthant Rn
+.
Motivated by the statement of Theorem 9.29, [32, 37, 46] introduces the following
deï¬nitions.
Deï¬nition 9.36 The real symmetric matrix C of order n is positive subdeï¬nite if for
all x âˆˆRn :
xâŠ¤Cx < 0 â‡’Cx Ì¸= 0 and Cx â‰§0 or Cx â‰¦0.
The matrix C is strictly positive subdeï¬nite if for all x âˆˆRn :
xâŠ¤Cx < 0 â‡’Cx > 0 or Cx < 0.
(The corresponding notions of negative subdeï¬niteness can be obtained by sub-
stituting (âˆ’C) for C).
It is evident that positive semideï¬nite matrices are strictly positive subdeï¬nite,
and strictly positive subdeï¬nite matrices are positive subdeï¬nite. The same terminol-
ogy applies to the related quadratic forms. In order to distinguish positive subdeï¬nite
matrices which are not positive semideï¬nite, from positive semideï¬nite ones, Mar-
tos inserts the word â€œmerelyâ€ before â€œpositive subdeï¬niteâ€. The following results
summarize the principal theorems of Martos regarding these subjects. We omit the
proofs.
Theorem 9.37 ([46, 47]) The quadratic form Q(x) = xâŠ¤Cx is merely positive sub-
deï¬nite if and only if
(i) C â‰¦0, C Ì¸= 0;
(ii) The spectrum of C contains exactly one negative element, i.e. C has nonpositive
principal minors.
The merely positive subdeï¬nite quadratic form Q(x) = xâŠ¤Cx is strictly merely pos-
itive subdeï¬nite if and only if C does not contain a row (or column) of zeros.
The quasiconvexity and pseudoconvexity of quadratic forms on Rn
+ are charac-
terized by [32, 37, 46] in terms of positive subdeï¬niteness of the matrices associated
to the said quadratic form.

314
9
Linear Programming and Quadratic Programming
Theorem 9.38 (Martos) The quadratic form Q(x) = xâŠ¤Cx is quasiconvex on the
nonnegative orthant Rn
+ if and only if it is positive subdeï¬nite. The quadratic form
Q(x) = xâŠ¤Cx is pseudoconvex on the semipositive orthant Rn
+ \ {0} if and only if
it is strictly positive subdeï¬nite.
The following result, due to Martos, characterizes the quasiconvexity of quadratic
functions on Rn
+.
Theorem 9.39 (Martos). The quadratic function Ï•(x) = 1
2 xâŠ¤Cx + câŠ¤x is quasi-
convex on Rn
+ if and only if, for all x âˆˆRn :
xâŠ¤Cx < 0 â‡’
 câŠ¤x
Cx

â‰§0, but Ì¸= 0 or
 câŠ¤x
Cx

â‰¦0, but Ì¸= 0.
The following result, given in [32], characterizes the matrix C and the vector c of
the previous theorem.
Theorem 9.40 (Martos) The nonconvex quadratic function Ï•(x) = 1
2 xâŠ¤Cx + câŠ¤x
is quasiconvex on Rn
+ if and only if the following four conditions hold:
(i) C has exactly one (simple) negative eigenvalue;
(ii) C â‰¦0, C Ì¸= 0;
(iii) c â‰¦0;
(iv) There is a vector q âˆˆRn such that Cq = c and câŠ¤q â‰¦0.
We note that if C is non-singular, then (iv) of the previous theorem reduces to:
(iv)â€² : câŠ¤Câˆ’1c â‰¦0. Moreover, putting c = 0 in Theorem 9.39, we can see that if
Ï•(x) = 1
2 xâŠ¤Cx + câŠ¤x is quasiconvex on Rn
+, then so is the quadratic form Q(x) =
xâŠ¤Cx. Furthermore, we know that if Ï•(x) fails to be convex, then so does Q(x).
As for what concerns pseudoconvexity of quadratic functions Ï•(x), we report the
following result of [48].
Theorem 9.41 If the nonconvex quadratic function Ï•(x) = 1
2 xâŠ¤Cx + câŠ¤x is qua-
siconvex on Rn
+, then it is pseudoconvex on Rn
+ provided c Ì¸= 0 (i.e. if Ï•(x) is a
â€œproper quadratic functionâ€).
It turns out that for â€œmerelyâ€ quasiconvex quadratic functions, quasiconvexity
and pseudoconvexity on Rn
+ (but also on any open convex set of Rn) are equivalent
properties. Another signiï¬cant result ([32, 47]) is the following one.
Theorem 9.42 (a) The nonconvex quadratic function Ï•(x) = 1
2 xâŠ¤Cx + câŠ¤x is qua-
siconvex on Rn
+ if and only if the matrix
M =
 0 câŠ¤
c C

is merely positive subdeï¬nite.
(b) If the matrix M of point (a) has no row of zeros and Ï•(x) = 1
2 xâŠ¤Cx + câŠ¤x is
quasiconvex, but not convex, on the nonnegative orthant Rn
+, then Ï•(x) is pseudo-
convex on the semipositive orthant Rn
+ \ {0} .

References
315
Thus for a quadratic programming problem of the type (QP1) or (QP2), with
Ï•(x) satisfying condition (b) of the previous theorem, a nonzero feasible Karush-
Kuhn-Tucker stationary point xâˆ—must be a global solution to the related problem.
References
1. C. Van de Panne, F. Rahnama, The ï¬rst algorithm for linear programming: an analysis of
Kantorovichâ€™s method. Econ. Plan. 19, 76â€“91 (1985)
2. G. Giorgi, T.H. Kjeldsen, Traces and Emergence of Nonlinear Programming (BirkhÃ¤user, Basel
and New York, 2014)
3. M.J. Todd, The many facets of linear programming. Math. Program. Series B 91, 417â€“436
(2002)
4. S. Achmanov, Programmation LinÃ©aire (Editions MIR, Moscou, 1984)
5. C. Berge, Topological Spaces. Including a Treatment of Multi-valued Functions, Vector Spaces
and Convexity (Dover Publications, Mineola, N.Y., 1997)
6. V. Chvatal, Linear Programming (W.H., Freeman, New York, 1983)
7. R.W. Cottle, M.N. Thapa, Linear and Nonlinear Programming (Springer, New York, 2017)
8. G.B. Dantzig, Linear Programming and Extensions (Fourth Printing), (Princeton Univ. Press,
Princeton, 1968)
9. G.B. Dantzig, M.N. Thapa, Linear Programming 1: Introduction (Springer, New York, 1997)
10. G.B. Dantzig, M.N. Thapa, Linear Programming 2: Theory and Extensions (Springer, New
York, 2003)
11. R. Dorfman, P.A. Samuelson, R.M. Solow, Linear Programming and Economic Analysis
(McGraw-Hill, New York, 1958)
12. D. Gale, The Theory of Linear Economic Models (McGraw-Hill Book Company, New York,
1960)
13. D. Luenberger, Y. Ye, Linear and Nonlinear Programming, 3rd edn. (Springer, New York,
2008)
14. K.G. Murty, Linear Programming (Wiley, New York, 1983)
15. E.D. Nering, A.W. Tucker, Linear Programs and Related Problems (Academic, Boston, 1993)
16. J. Nocedal, S.J. Wright, Numerical Optimization, 2nd edn. (Springer, New York, 2006)
17. A. Schrijver, Theory of Linear and Integer Programs (Wiley, Chichester, 1986)
18. M. Simmonard, Linear Programming (Prentice-Hall, Englewood Cliffs, N.J., 1969)
19. R.J.Vanderbei,LinearProgramming:FoundationsandExtensions (Publishers,Boston,Kluwer
Acad, 1996)
20. T.C. Koopmans, Activity Analysis of Production and Allocation (Yale University Press, New
Haven, 1951)
21. G. Hadley, Nonlinear and Dynamic Programming (Addison-Wesley, Reading, Mass, 1964)
22. G. Hadley, Linear Programming (Addison-Wesley, Reading, Mass, 1975)
23. H. Nikaido, Convex Structures and Economic Theory (Academic, New York, 1968)
24. H.W. Kuhn, A.W. Tucker (Eds.), Linear Inequalities and Related Systems, Annals of Mathe-
matics Studies N. 38 (Princeton University Press, Princeton, N.J., 1956)
25. T. Gal, Postoptimal Analysis, Parametric Programming and Related Topics (McGraw-Hill,
New York, 1979)
26. T. Gal, Linear parametric programmingâ€”a brief survey. Math. Program. Study 21, 43â€“68
(1984)
27. J.E. Ward, R.E. Wendell, Approaches to sensitivity analysis in linear programming. Ann. Oper.
Res. 27, 3â€“38 (1990)
28. O.L. Mangasarian, Uniqueness of solution in linear programming. Linear Algebra Appl. 25,
151â€“162 (1979)

316
9
Linear Programming and Quadratic Programming
29. J.C. Boot, Quadratic Programming (North Holland, Amsterdam, 1964)
30. Y. Chabrillac, J.-P. Crouzeix, Deï¬niteness and semi-deï¬niteness of quadratic forms revisited.
Linear Algebra Appl. 63, 283â€“292 (1984)
31. G. Debreu, Deï¬nite and semideï¬nite quadratic forms. Econometrica 20, 285â€“300 (1952)
32. B. Martos, Quadratic programming with a quasiconvex objective function. Oper. Res. 19, 87â€“97
(1971)
33. S. Schaible, Second-order characterizations of pseudoconvex quadratic functions. J. Optim.
Theory Appl. 21, 15â€“26 (1977)
34. S. Schaible, Quasiconvex, pseudoconvex, and strictly pseudoconvex quadratic functions. J.
Optim. Theory Appl. 35, 303â€“338 (1981)
35. H.M. Markowitz, Portfolio selection. J. Financ. 7, 77â€“91 (1952)
36. H.M. Markowitz, Portfolio Selection (Yale University Press, New Haven, 1959)
37. B. Martos, Nonlinear Programming. Theory and Methods (North Holland, Amsterdam, 1975)
38. E. Blum, W. Oettli, Direct proof of the existence theorem for quadratic programming. Oper.
Res. 20, 165â€“167 (1972)
39. R.W. Cottle, J.S. Pang, R.E. Stone, The Linear Complementarity Problem, 2nd edn. (Society
for Industrial and Applied Mathematics, Philadelphia, 2009)
40. F. Facchinei, J.-S. Pang, Finite-Dimensional Variational Inequalities and Complementarity
Problems (Springer, New York, 2003)
41. R.W. Cottle, On the convexity of quadratic forms over convex sets. Oper. Res. 15, 170â€“172
(1967)
42. W.S. Dorn, Duality in quadratic programming. Quart. Appl. Math. 18, 155â€“162 (1960)
43. R.W. Cottle, Symmetric dual quadratic programs. Quart. Appl. Math. 21, 237â€“243 (1963)
44. M. Avriel, W.E. Diewert, S. Schaible, I. Zang, Generalized Concavity (Plenum Press, New
York, 1988)
45. A. Cambini, L. Martein, Generalized Convexity and Optimization. Theory and Applications
(Springer, Berlin, 2009)
46. B. Martos, Subdeï¬nite matrices and quadratic forms. SIAM J. Appl. Math. 17, 1215â€“1223
(1969)
47. R.W. Cottle, J.A. Ferland, Matrix-theoretic criteria for the quasi-convexity and pseudo-
convexity of quadratic functions. Linear Algebra Appl. 5, 123â€“136 (1972)
48. R.W. Cottle, J.A. Ferland, On pseudo-convex functions of non-negative variables. Math. Pro-
gram. 1, 95â€“101 (1971)

Chapter 10
Introduction to Nonsmooth Optimization
Problems
In treating the various optimization problems described in the previous chapters,
we have almost always supposed (with the exception of the characterization of sad-
dle points of the Lagrangian function, in Chap. 8) that the functions involved in the
said problems are differentiable or continuously differentiable or twice-continuously
differentiable. Starting from the 70s of the last century, the necessity of studying non-
smooth (i.e. nondifferentiable) functions and hence nonsmooth optimization prob-
lems, gave rise to a new mathematical theory, called Nonsmooth Analysis (this term
was introduced by the Canadian mathematician F. H. Clarke).
The most important â€œsupplierâ€ and â€œconsumerâ€ of nonsmooth problems is perhaps
optimization theory. The ï¬rst well-studied classes of nonsmooth functions have been
those of convex functions and max-type functions. In the 60s and 70s of the past
century, modern Convex Analysis and modern Minimax Theory were created; see
[1â€“6].
One of (if not the most) important concepts of Classical Calculus is the concept of
derivative (gradient in the multidimensional case). In Convex Analysis and Minimax
Theory, this role is played by directional derivatives and by subdifferentials. The
concept of subdifferential allows to study convex nonsmooth problems, as in a similar
way the smooth problems are studied with the help of gradients. What developed
for convex functions has been subsequently adapted to locally Lipschitz functions
by the basic results of the Canadian mathematician F. H. Clarke. We shall give some
insights into this approach in the next section (Sect. 10.2) of the present chapter.
By now, Nonsmooth Analysis is an autonomous branch of Mathematics and has
received important applications also outside optimization theory. We shall give some
insights into the axiomatic approach of Elster and Thierfelder [7â€“10] in deï¬ning
generalized directional derivatives and generalized subdifferentials in the third and
last section of the present chapter.
Â© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al., Basic Mathematical Programming Theory, International Series
in Operations Research & Management Science 344,
https://doi.org/10.1007/978-3-031-30324-1_10
317

318
10
Introduction to Nonsmooth Optimization Problems
10.1
The Convex Case
We have seen in Chap. 3 that if f : X â†’R is differentiable on the open convex set
X âŠ‚Rn, then f is convex on X if and only if, for every x, x0 âˆˆX
f (x) âˆ’f (x0) â‰§âˆ‡f (x0)âŠ¤(x âˆ’x0),
and we have seen (Theorem 3.6) that if f is not necessarily differentiable on the
open convex set X âŠ‚Rn, then f is convex on X if and only if for every x0 âˆˆX there
exists u0 âˆˆRn such that for every x âˆˆX
f (x) âˆ’f (x0) â‰§(u0)âŠ¤(x âˆ’x0).
(10.1)
For example, the function f (x) =
x âˆ’x0 , x, x0 âˆˆR, does not admit deriva-
tive at x = x0. However, there are inï¬nite straight lines passing through the point
(x0, f (x0)), lines of equation y = f (x0) + m(x âˆ’x0), that lie (except for the point
(x0, f (x0)) below the graph of f. In other words, there exist inï¬nite values of m âˆˆR
such that, for every x, the inequality
f (x) â‰§f (x0) + m(x âˆ’x0)
is satisï¬ed. In general, this suggests that, at least for convex functions, it is possible
to replace the gradient of f, when f is not differentiable, with a vector u0 âˆˆRn satis-
fying relation (10.1). These considerations allow us to give the following deï¬nition.
Deï¬nition 10.1 Let X âŠ‚Rn be a convex set and f : X â†’R a convex function on
X. A vector s âˆˆRn is called a subgradient of f at x0 âˆˆX if for every x âˆˆX it holds
f (x) âˆ’f (x0) â‰§sâŠ¤(x âˆ’x0).
(10.2)
The set of all subgradients of f at x0 âˆˆX is called the subdifferential of f at x0
and denoted by âˆ‚f (x0).
Example 10.2 From the previous deï¬nition, it follows at once that, for f (x) = |x| ,
x âˆˆR, âˆ‚f (0) = [âˆ’1, 1] .
Example 10.3 We recall what already remarked in Chap. 3: non-subdifferentiability
can however occur on the boundary of the domain of f ; this justiï¬es the assumption
on the openness of X in relation (10.1). Consider f : [0, 1] â†’R, with f (x) = âˆ’âˆšx.
Then f is clearly convex, but âˆ‚f (0) = âˆ….
If the set âˆ‚f (x0) is nonempty, we say that f is subdifferentiable at x0. The notion
of subgradient has a useful geometrical interpretation, already previously sketched.
Suppose s âˆˆâˆ‚f (x0); inequality (10.2) means that the epigraph of f is located on or
above the graph of the afï¬ne function l(x) = f (x0) + sâŠ¤(x âˆ’x0). For every point
(x, Î±) âˆˆepi( f ), we have

10.1 The Convex Case
319
Î± â‰§f (x) â‰§f (x0) + sâŠ¤(x âˆ’x0),
which can be rewritten as
sâŠ¤(x âˆ’x0) + (âˆ’1)(Î± âˆ’f (x0)) â‰¦0.
Consequently, (s, âˆ’1) is an element of the normal cone N(epi( f ), (x0, f (x0))):
âˆ‚f (x0) =

s âˆˆRn : (s, âˆ’1) âˆˆN(epi( f ), (x0, f (x0)))

.
We have seen in Theorem 3.17 that convex functions are directionally differen-
tiable at every point of their (open) convex domain. Before stating the basic results
on subgradients and subdifferentials of convex functions (and before giving the proof
of this last statement), we wish to recall some deï¬nitions and concepts on directional
derivatives, already given, but here we make also some further considerations.
Several modern treatments of convex functions consider extended real-valued
functions, i.e. functions deï¬ned on the whole space Rn and assuming also inï¬nite
values. Indeed, consider a convex function deï¬ned on a proper subset X of Rn.
Let be
f1(x) =
 f (x), if x âˆˆX,
+âˆ, if x /âˆˆX.
The epigraph of the function f deï¬ned on X is identical to epi( f1), deï¬ned
on the whole space Rn. In this way, we can always construct convex functions
deï¬ned throughout Rn. However, allowing convex functions to take on inï¬nite values,
requires some caution in arithmetic operations, such as the â€œindeterminate formsâ€
(+âˆâˆ’âˆ), (0 Â· âˆ), (âˆ/âˆ). Those convex functions that nowhere have the value
âˆ’âˆand are not identically equal to +âˆare usually called proper convex functions.
However, in the present book that presents the basic mathematical tools of opti-
mization theory in Rn, we shall be concerned only with the usual real-valued convex
functions, not necessarily deï¬ned on the whole space Rn. Now we recall the basic
notionsandpropertiesconcerningdirectionaldifferentiability,alreadypartiallyantic-
ipated in Chap. 3. Let us deï¬ne a direction as a vector v âˆˆRn, v Ì¸= 0. Given a real-
valued function f deï¬ned on a subset S of Rn, a point x0 âˆˆS and v âˆˆF(S, x0),
the right-sided derivative of f at x0 in the direction v or the right-sided directional
derivative of f at x0 in the direction v is deï¬ned as
D+ f (x0; v) = lim
tâ†’0+
f (x0 + tv) âˆ’f (x0)
t
,
if the limit exists (ï¬nite or not). Similarly, the left-sided directional derivative of f
at x0 in the direction v is deï¬ned as
Dâˆ’f (x0; v) = lim
tâ†’0âˆ’
f (x0 + tv) âˆ’f (x0)
t
,

320
10
Introduction to Nonsmooth Optimization Problems
if the limit exists (ï¬nite or not). For v = 0, both D+ f (x0; v) and Dâˆ’f (x0; v) are
deï¬ned to be zero.
The reader can easily verify that the left-sided directional derivative at x0 in the
direction v exists if and only if the right-sided directional derivative at x0 in the
direction (âˆ’v) exists and that it holds
Dâˆ’f (x0; v) = âˆ’D+ f (x0; âˆ’v),
so in the applications only D+ f (x0; v) is usually considered. If it holds
D+ f (x0; v) = Dâˆ’f (x0; v),
then we have the (bilateral) directional derivative in the classical sense: Df (x0; v).
We say also that f is directionally differentiable at x0, in the classical sense. In this
case, we have therefore
âˆ’D+ f (x0; âˆ’v) = D+ f (x0; v),
i.e.
D+ f (x0, v) + D+ f (x0; âˆ’v) = 0.
Example 10.4 Let us consider a ï¬xed point x2 âˆˆRn and the convex function f :
Rn â†’R deï¬ned by f (x) =
x âˆ’x2 . This function admits a right-sided directional
derivative at every point x0 âˆˆRn, in the direction v and we have
D+ f (x0; v) =

âˆ¥vâˆ¥,
if x0 = x2,
vâŠ¤(x0âˆ’x2)
âˆ¥x0âˆ’x2âˆ¥, if x0 Ì¸= x2.
A well-known result is: if a function f : Rn â†’R is differentiable at a point x0,
then the directional derivative (in the classical sense) of f at x0 in all directions v
exist ï¬nite and is given by
Df (x0; v) = vâŠ¤âˆ‡f (x0).
Other important results on directional derivatives are contained in the following
theorem.
Theorem 10.5 If
f : X âŠ‚Rn â†’R
admits
a
ï¬nite
directional
derivative
D+ f (x0; v) at x0 âˆˆint(X), this derivative is positively homogeneous of the ï¬rst
degree with respect to the direction v. The same is true for Dâˆ’f (x0; v).
Proof The assertion is quite immediate to get. We have, for each h > 0,

10.1 The Convex Case
321
D+ f (x0; hv) = lim
tâ†’0+
f (x0 + thv) âˆ’f (x0)
t
= h lim
tâ†’0+
f (x0 + thv) âˆ’f (x0)
th
= hD+ f (x0; v).
â–¡
In the sequel, we shall use the notation f â€²(x0; v) to denote the right-sided direc-
tional derivative of f at x0.
If f â€²(x0; v) exists for all v âˆˆRn and is linear in v, then f is said to be GÃ¢teaux
differentiable at x0. In this case, we have
f (x0 + tv) = f (x0) + tvâŠ¤âˆ‡f (x0) + o(t), as t â†’0+.
We come back to convex functions. We have seen in Example 10.4 that the con-
vex function f (x) =
x âˆ’x2 admits a right-sided directional derivative at every
point and for every direction v. Indeed, this property is typical of convex functions.
More precisely, we have the following result, already anticipated (without proof) in
Theorem 3.17.
Theorem 10.6 Let X be a nonempty open convex set in Rn and f : X â†’R a convex
function on X. Let x0 âˆˆX and v âˆˆRn. Then:
(a) The â€œdifference quotientâ€
q(t) = f (x0 + tv) âˆ’f (x0)
t
is a monotonically increasing function of t > 0, i.e. q(t1) â‰¦q(t2) for all 0 <
t1 < t2, with x0 + t2v âˆˆX.
(b) The directional derivative f â€²(x0; v) exists ï¬nite and we have
f â€²(x0; v) = inf
t>0
f (x0 + tv) âˆ’f (x0)
t
.
(c) For every x0 âˆˆX the function f â€²(x0; Â·) is sublinear, i.e. positively homogeneous
and subadditive. Hence, f â€²(x0; v) is a convex function of v and it holds
âˆ’f â€²(x0; âˆ’v) â‰¦f â€²(x0; v).
Proof (a) Let be 0 < t1 < t2, with x0 + t2v âˆˆX (and hence also x0 + t1v âˆˆX).
Being f convex, we have
f (x0 + t1v) = f
t1
t2
(x0 + t2v) + (1 âˆ’t1
t2
)x0
	
â‰¦t1
t2
f (x0 + t2v) +

1 âˆ’t1
t2
	
f (x0).

322
10
Introduction to Nonsmooth Optimization Problems
This inequality implies
q(t1) = f (x0 + t1v) âˆ’f (x0)
t1
â‰¦f (x0 + t2v) âˆ’f (x0)
t2
= q(t2).
(b) Let be given t, Ï„ > 0, with x0 âˆ’Ï„v âˆˆX and x0 + tv âˆˆX. The convexity of f
implies
f (x0) = f

t
t + Ï„ (x0 âˆ’Ï„v) +
Ï„
t + Ï„ (x0 + tv)
	
â‰¦
t
t + Ï„ f (x0 âˆ’Ï„v) +
Ï„
t + Ï„ f (x0 + tv).
From here, it follows that
q(t) = f (x0 + tv) âˆ’f (x0)
t
â‰§f (x0) âˆ’f (x0 âˆ’Ï„v)
Ï„
.
Hence, the difference quotient q(t), for t â†’0+ is bounded from below; on the
other hand, q(t) is a monotonically increasing function of t > 0 and hence the exis-
tence of a ï¬nite directional derivative f â€²(x0; v) holds true, with the property
f â€²(x0; v) = lim
tâ†’0+
f (x0 + tv) âˆ’f (x0)
t
= inf
t>0
f (x0 + tv) âˆ’f (x0)
t
.
(c) f â€²(x0; v) is a sublinear function of the direction v, i.e.
f â€²(x0; Î±v) = Î±f â€²(x0; v), âˆ€v âˆˆRn, âˆ€Î± > 0
and
f â€²(x0; v1 + v2) â‰¦f â€²(x0; v1) + f â€²(x0; v2), âˆ€v1, v2 âˆˆRn.
The homogeneity of the directional derivative with respect to the direction has
already been proved. Let us prove the subadditivity: if v1, v2 âˆˆRn, then for any t > 0
sufï¬ciently small the inequality
f (x0 + t(v1 + v2)) â‰¦1
2 f (x0 + 2tv1) + 1
2 f (x0 + 2tv2)
implies the relation
1
t

f (x0 + t(v1 + v2)) âˆ’f (x0)

â‰¦1
2t

f (x0 + 2tv1) âˆ’f (x0)

+ 1
2t

f (x0 + 2tv2) âˆ’f (x0)


10.1 The Convex Case
323
from which, taking the limit for t â†’0+,
f â€²(x0; v1 + v2) â‰¦f â€²(x0; v1) + f â€²(x0; v2).
We recall that linear homogeneity plus subadditivity produces convexity, since
f (Î»x + (1 âˆ’Î»)y) â‰¦f (Î»x) + f ((1 âˆ’Î»)y) = Î»f (x) + (1 âˆ’Î») f (y), Î» âˆˆ[0, 1] .
(also the vice versa holds true: linear homogeneity and convexity imply
subadditivity).
Finally, as f â€²(x0; 0) = 0, one has
0 = f â€² 
x0; 0

= f â€² 
x0; v + (âˆ’v)

â‰¦f â€² 
x0; v

+ f â€² 
x0; âˆ’v

by subadditivity. Therefore,
âˆ’f â€²(x0; âˆ’v) â‰¦f â€²(x0; v), âˆ€v âˆˆRn.
â–¡
We note that the above theorem holds also if x0 âˆˆint(X), where X âŠ‚Rn is a (not
necessarily open) nonempty convex set. The same is true also for the next results.
The following statement is a consequence of the previous theorem.
Theorem 10.7 Let X âŠ‚Rn be an open convex set and let f : X â†’R be convex.
Then it holds
f â€²(x0; x âˆ’x0) â‰¦f (x) âˆ’f (x0), âˆ€x, x0 âˆˆX.
Proof Let x0, x be any two points of X. Being f convex on X, we have
f (x0 + t(x âˆ’x0)) â‰¦(1 âˆ’t) f (x0) + t f (x),
for all t âˆˆ[0, 1] . From this relation, we obtain, for all t âˆˆ(0, 1] :
1
t

f (x0 + t(x âˆ’x0)) âˆ’f (x0)

â‰¦f (x) âˆ’f (x0).
Taking Theorem 10.6 into account, we obtain, for t â†’0+, the thesis.
â–¡
In particular, when f is differentiable we have the relation
(x âˆ’x0)âŠ¤âˆ‡f (x0) â‰¦f (x) âˆ’f (x0)
as seen in Theorem 3.7(d). Another consequence of the above results is the inequality
f â€²(x; x âˆ’x0) â‰§f â€²(x0; x âˆ’x0).

324
10
Introduction to Nonsmooth Optimization Problems
Indeed, by Theorems 10.7 and 10.6(a), we have
f (x0) âˆ’f (x) â‰§f â€²(x; x0 âˆ’x) â‰§âˆ’f â€²(x; x âˆ’x0),
and so
f â€²(x; x âˆ’x0) â‰§f (x) âˆ’f (x0) â‰§f â€²(x0, x âˆ’x0)
by Theorem 10.7.
In particular, when f is differentiable, we have the relation
(x âˆ’x0)âŠ¤
âˆ‡f (x) âˆ’âˆ‡f (x0)

â‰§0,
as seen in Theorem 3.7( f ).
As for what concerns differentiability of convex functions, we have the following
result, which is a particular case of a more general result, due to Rademacher; see,
e.g. [11].
If f : X âŠ‚Rn â†’R is convex on the open convex set X, it is differentiable with
continuous partial derivatives everywhere on X, except for a set of measure zero (in
the Lebesgue sense).
Summing up (see also [2, 11, 12]): Let f : X âŠ‚Rn â†’R be convex on the open
convex set X, let x0 âˆˆX (or, more generally, let f be convex on the convex set X
and let x0 âˆˆint(X)). Then the following properties are equivalent:
(i) The function f is differentiable at x0.
(ii) The function f is directionally differentiable at x0 in the classical sense, for
any direction v âˆˆRn.
(iii) The function f admits at x0 the n partial derivatives, with respect to its n
variables.
(iv) The function f is continuously differentiable at x0.
Nowweconsidersubgradientsofconvexfunctionsandtheirrelationswithdirectional
derivatives.
Theorem 10.8 Let X âŠ‚Rn be a nonempty open convex set and f : X â†’R a con-
vex function on X. Then the subdifferential âˆ‚f (x0), x0 âˆˆX, is a nonempty convex
compact set.
Proof We ï¬rst prove the nonemptiness of âˆ‚f (x0). We recall that, due to the convexity
of f, the set epi( f ) is a convex set (see Theorem 3.6). Noting that (x0, f (x0))
belongs to the boundary of epi( f ), and recalling the supporting hyperplane theorem
(Theorem 2.19), we have
zâŠ¤(x âˆ’x0) + Î¼(y âˆ’f (x0)) â‰¦0, âˆ€(x, y) âˆˆepi( f )
(10.3)
for some nonzero vector (zâŠ¤, Î¼) âˆˆRn+1. It follows that Î¼ â‰¦0 (otherwise, a contra-
diction will occur in (10.3) for a large y). If we suppose Î¼ = 0, then we have z Ì¸= 0

10.1 The Convex Case
325
and zâŠ¤(x âˆ’x0) â‰¦0, âˆ€x âˆˆX. Since X is an open set, we can choose a positive num-
ber Î» and a point x âˆˆX such that x âˆ’x0 = Î»z. Consequently, we have Î»zâŠ¤z â‰¦0,
which contradicts z Ì¸= 0. Hence, Î¼ < 0. Letting s = zâŠ¤/ |Î¼| and dividing (10.3) by
|Î¼| , we have
sâŠ¤(x âˆ’x0) âˆ’y + f (x0) â‰¦0, âˆ€(x, y) âˆˆepi( f ).
Since (x, f (x)) âˆˆepi( f ), âˆ€x âˆˆX, we obtain
sâŠ¤(x âˆ’x0) + f (x0) â‰¦f (x), âˆ€x âˆˆX.
This implies s âˆˆâˆ‚f (x0). Hence, âˆ‚f (x0) Ì¸= âˆ…. The convexity of âˆ‚f (x0) is obvious.
Now we prove the compactness of âˆ‚f (x0). From the deï¬nition of âˆ‚f (x0), it appears
that âˆ‚f (x0) is a closed set (it is given by the intersection of linear weak inequalities);
it remains to prove that it is also a bounded set. Since X is an open set, we choose a
positive number Îµ satisfying cl(N(x0, Îµ)) =

x âˆˆRn :
x âˆ’x0 â‰¦Îµ

âŠ‚X. If we
suppose that âˆ‚f (x0) is not bounded, then there exists a sequence

sk
âŠ‚âˆ‚f (x0)
such that
sk â†’+âˆ. It is clear that there exists a subsequence, that we denote
again by

sk
, and an index j âˆˆ{1, . . . , n} such that |sk
j | â†’+âˆas k â†’+âˆ.
Deï¬ne a sequence

xk
by xk
i = x0
i , i Ì¸= j, xk
j = x0
j + Îµsk
j /|sk
j |. Then it follows that
xk âˆˆcl(N(x0, Îµ)). Since a convex function is continuous on an open convex set (see
Theorem 3.13), it follows that the sequence

f (xk)

is bounded. Thus, the inequality
f (xk) â‰§f (x0) + (sk)âŠ¤(xk âˆ’x0) = f (x0) + Îµ|sk
j |
does not hold for a large k. But this contradicts the fact that sk âˆˆâˆ‚f (x0). We can
therefore conclude that âˆ‚f (x0) is bounded since xk âˆˆcl(N(x0, Îµ)) and cl(N(x0, Îµ))
is a compact set. Hence, âˆ‚f (x0) is a convex compact set.
â–¡
We recall here the following characterization of convex functions on an open
convex set X âŠ‚Rn, already given in Chap. 3 (see Theorem 3.6(e)): Let X âŠ‚Rn be
an open convex set and let f : X â†’R. Then f is convex on X if and only if, for
every x0 âˆˆX, there exists s0 âˆˆRn such that
(s0)âŠ¤(x âˆ’x0) â‰¦f (x) âˆ’f (x0), âˆ€x âˆˆX,
i.e. if and only if f is subdifferentiable at every point x0 âˆˆX.
Theorem 10.9 Let X be a nonempty open convex set in Rn, x0 âˆˆX and let f : X â†’
R be a convex function on X. Then
âˆ‚f (x0) =

s âˆˆRn : f â€²(x0; v) â‰§sâŠ¤v, âˆ€v âˆˆRn
.
In other words: if X is open (or, more generally, if x0 âˆˆint(X)), and f is convex
on X, then s âˆˆâˆ‚f (x0) if and only if

326
10
Introduction to Nonsmooth Optimization Problems
f â€²(x0; v) â‰§sâŠ¤v, âˆ€v âˆˆRn.
Proof Since by Theorem 10.6(b), f â€²(x0; v) is given by
inf
t>0
f (x0 + tv) âˆ’f (x0)
t
,
it holds that for arbitrarily ï¬xed s0 âˆˆâˆ‚f (x0),
f â€²(x0; v) = inf
t>0
f (x0 + tv) âˆ’f (x0)
t
â‰§(s0)âŠ¤v, âˆ€v âˆˆRn.
Hence, âˆ‚f (x0) âŠ‚

s âˆˆRn : f â€²(x0; v) â‰§sâŠ¤v, âˆ€v âˆˆRn
. We next show the
inverse inclusion. For arbitrarily ï¬xed s0 âˆˆRn satisfying
f â€²(x0; v) â‰§(s0)âŠ¤v, âˆ€v âˆˆRn,
we have
(s0)âŠ¤v â‰¦f â€²(x0; v) = inf
t>0
f (x0 + tv) âˆ’f (x0)
t
â‰¦f (x0 + tv) âˆ’f (x0)
t
,
âˆ€t âˆˆ(0, +âˆ),âˆ€v âˆˆRn.Since X isaconvexset,everyvector x âˆˆX canbeexpressed
by x = x0 + tv for some v âˆˆRn and t > 0. Thus, the above inequalities imply s0 âˆˆ
âˆ‚f (x0). Hence,

s âˆˆRn : f â€²(x0; v) â‰§(s0)âŠ¤v, âˆ€v âˆˆRn
âŠ‚âˆ‚f (x0).
â–¡
Theorem 10.10 Let X âŠ‚Rn be a nonempty open convex set, x0 âˆˆX and let f :
X â†’R be a convex function on X. Then
f â€²(x0; v) = max
sâˆˆâˆ‚f (x0)

sâŠ¤v

, âˆ€v âˆˆRn.
(It is also said that f â€²(x0; Â·) is the support function of âˆ‚f (x0)).
Proof Let v0 âˆˆRn be arbitrarily ï¬xed. The compactness of âˆ‚f (x0) (Theorem 10.8)
and Theorem 10.9 imply
f â€²(x0; v0) â‰§max
sâˆˆâˆ‚f (x0)sâŠ¤v0.
Then we have only to show that there exists a vector s0 âˆˆâˆ‚f (x0) such that
f â€²(x0; v0) = (s0)âŠ¤v0. From Theorem 10.6, we get that f â€²(x0; Â·) is a convex func-
tion on Rn, and from Theorem 10.8, we have that the subdifferential of f â€²(x0; v) at
v = v0 is not empty. Hence, we can choose a vector s0 âˆˆRn satisfying

10.1 The Convex Case
327
f â€²(x0; v) â‰§f â€²(x0; v0) + (s0)âŠ¤(v âˆ’v0), âˆ€v âˆˆRn.
(10.4)
Taking v = 0, we derive that f â€²(x0; v0) â‰¦(s0)âŠ¤v0, while v = Â¯tv0 (Â¯t > 1) yields
f â€²(x0; v0) â‰§(s0)âŠ¤v0. Therefore, we have
f â€²(x0; v0) = (s0)âŠ¤v0.
(10.5)
From (10.4) and (10.5), it follows that
f â€²(x0; v) â‰§(s0)âŠ¤v, âˆ€v âˆˆRn
and hence
inf
t>0
f (x0 + tv) âˆ’f (x0)
t
â‰§(s0)âŠ¤v, âˆ€v âˆˆRn.
We thus have
f (x0 + tv) â‰§f (x0) + t(s0)âŠ¤v, âˆ€t > 0, âˆ€v âˆˆRn,
with x0 + tv âˆˆX, which implies s0 âˆˆâˆ‚f (x0). This, together with (10.5), completes
the proof.
â–¡
The following result establishes a relation between gradient and subgradient of a
convex function on an open convex set X âŠ‚Rn.
Theorem 10.11 Let X âŠ‚Rn be a nonempty open convex set and f : X â†’R a
convex function on X. If f is differentiable at x0 âˆˆX, then âˆ‚f (x0) =

âˆ‡f (x0)

.
Conversely, if f has a unique subgradient at x0, then f is differentiable at x0.
Proof Since f is differentiable at x0, we have f â€²(x0; v) = (âˆ‡f (x0))âŠ¤v, for any
v âˆˆRn. Hence, from Theorem 10.9, we have that for s âˆˆâˆ‚f (x0) it holds
(âˆ‡f (x0))âŠ¤v â‰§sâŠ¤v, âˆ€v âˆˆRn.
This shows that
(âˆ‡f (x0) âˆ’s)âŠ¤v â‰§0, âˆ€v âˆˆRn.
Replacing v with âˆ’v, we see that the opposite inequality also holds and thus we
conclude that
(âˆ‡f (x0) âˆ’s)âŠ¤v = 0, âˆ€v âˆˆRn.
Hence, this shows that s = âˆ‡f (x0).
Conversely, let us assume that f has a unique subgradient s âˆˆRn at x0. By
Theorem 10.10, we have

328
10
Introduction to Nonsmooth Optimization Problems
f â€²(x0; v) = sâŠ¤v, âˆ€v âˆˆRn.
But it results
âˆ’f â€²(x0; âˆ’v) â‰¡âˆ’D+ f (x0; âˆ’v) = Dâˆ’f (x0; v), âˆ€v âˆˆRn.
Hence, D+ f (x0; v) = Dâˆ’f (x0; v), âˆ€v âˆˆRn. In other words, f is directionally
differentiable in the classic al sense at x0 for every direction v âˆˆRn. Being f convex,
this assures that f is differentiable at x0.
â–¡
From what said above, it is once more clear that the subgradient inequality for
convex differentiable functions satisï¬es the relation
f (y) âˆ’f (x) â‰§[âˆ‡f (x)]âŠ¤(y âˆ’x)
(10.6)
for every x, y âˆˆX (X âŠ‚Rn open convex set). But, for what said in Chap. 3 (see
Theorem 3.7(d)), also the converse is true: if a differentiable function on the open
convex set X âŠ‚Rn satisï¬es relation (10.6) for every x, y âˆˆX, then f is convex
on X.
Example 10.12 The Euclidean norm f (x) = âˆ¥xâˆ¥is differentiable at every point
x âˆˆRn, x Ì¸= 0, and hence in these points âˆ‚f (x) = {âˆ‡f (x)} . At x = 0, f is not
differentiable, it is subdifferentiable and âˆ‚f (0) =

s âˆˆRn : âˆ¥zâˆ¥â‰§sâŠ¤z, âˆ€z âˆˆRn
.
In other words, âˆ‚f (0) is given by the unit closed ball in Rn.
Example 10.13 The convex function
f (x) = âˆ’xÎ±, x âˆˆR, x â‰§0, 0 < Î± < 1,
is differentiable at any point x > 0 (and hence also subdifferentiable). At x = 0, this
function is neither differentiable nor subdifferentiable.
Example 10.14 If S âŠ‚Rn is a nonempty convex set, then indicator function of the
set S is deï¬ned as
Î´(x; S) =
 0,
if x âˆˆS,
+âˆ, if x /âˆˆS.
We have that âˆ‚Î´(x; S) is given by the normal cone of S at x (empty if x /âˆˆS).
Indeed, by deï¬nition, we have that s âˆˆâˆ‚Î´(x; S) if and only if
Î´(z; S) â‰§Î´(x; S) + sâŠ¤(z âˆ’x), âˆ€z âˆˆS.
This condition implies that x âˆˆS and
0 â‰§sâŠ¤(z âˆ’x), âˆ€z âˆˆS,
that is, s is normal to S at x :

10.1 The Convex Case
329
âˆ‚Î´(x; S) = N(S, x).
From the deï¬nition of subgradients and subdifferentials, it is immediate that
âˆ‚(Î»f )(x) = Î»âˆ‚f (x), âˆ€x, âˆ€Î» > 0.
The following theorem, due to J.-J. Moreau and R. T. Rockafellar (in a more
general version) gives an important calculus rule for subdifferentials of convex func-
tions.
Theorem 10.15 (Moreau-Rockafellar) Let X âŠ‚Rn be an open convex set and let
Î±, Î² â‰§0. If f : X â†’R and g : X â†’R are convex functions on X, then the function
F = Î±f + Î²g is convex on X and it holds
âˆ‚F(x0) = Î±âˆ‚f (x0) + Î²âˆ‚g(x0), âˆ€x0 âˆˆX.
Proof The ï¬rst part of the thesis has already been proved in Theorem 3.34. Let
now be x0 âˆˆX; the inclusion Î±âˆ‚f (x0) + Î²âˆ‚g(x0) âŠ‚âˆ‚F(x0) is evident. Suppose
that there exists z âˆˆâˆ‚F(x0) such that z /âˆˆÎ±âˆ‚f (x0) + Î²âˆ‚g(x0). By Theorem 10.8,
this last set is nonempty, convex, and compact. By the strong separation theorem
(Theorem 2.17), there exists h âˆˆRn such that
max

hâŠ¤y : y âˆˆÎ±âˆ‚f (x0) + Î²âˆ‚g(x0)

< hâŠ¤z.
Therefore, it is veriï¬ed the inequality
Î± max

hâŠ¤y : y âˆˆÎ±âˆ‚f (x0)

+ Î² max

hâŠ¤y : y âˆˆÎ²âˆ‚g(x0
< hâŠ¤z,
inequality which can be rewritten by Theorem 10.10 in the form
Î±f â€²(x0; h) + Î²gâ€²(x0; h) < hâŠ¤z.
Taking into account that
Î±f â€²(x0; h) + Î²gâ€²(x0; h) = Fâ€²(x0; h),
we get the inequality
Fâ€²(x0; h) < hâŠ¤z,
which, by Theorem 10.9, cannot hold. Hence, we have the thesis of the theorem. â–¡
Remark 10.16 We have to note that also Theorem 10.15 holds under the weaker
assumption that X âŠ‚Rn is a nonempty convex set, x0 âˆˆint(X), f : X â†’R and
g : X â†’R âˆª{+âˆ} are convex functions on X, âˆ‚f (x0) is compact, g(x0) ï¬nite and
âˆ‚g(x0) is closed.

330
10
Introduction to Nonsmooth Optimization Problems
Now we report some optimality conditions for various optimization problems,
where the functions involved are convex. We begin with an unconstrained optimiza-
tion problem, of the type (P1). We recall ï¬rst the basic optimality conditions for
(P1), in absence of convexity assumptions, and expressed in terms of directional
derivatives.
Theorem 10.17 Let be X âŠ‚Rn, and x0 âˆˆint(X); let f : X â†’R admit a (ï¬nite)
directional derivative f â€²(x0; v) for all v âˆˆRn. For the point x0 to be a local minimizer
of f over X, it is necessary that
f â€²(x0; v) â‰§0, âˆ€v âˆˆRn.
(10.7)
If f is locally Lipschitz in a neighborhood of x0 (see further, Deï¬nition 10.27),
and if
f â€²(x0; v) > 0, âˆ€v âˆˆRn, v Ì¸= 0,
(10.8)
then x0 is a strict local minimum point of f over X (i.e. condition (10.8) is a sufï¬cient
condition for a strict local minimum of f ).
Proof The necessity part is immediate. Since f is directionally differentiable at x0,
we have
f (x0 + tv) = f (x0) + t f â€²(x0; v) + o(t), âˆ€t â‰§0, âˆ€v âˆˆRn.
This implies (10.7).
For the sufï¬ciency part, see, e.g. [13, 14], or [15].
â–¡
A point x0 âˆˆint(X) satisfying (10.7) is called by some authors an inf-stationary
point of f.
We now revert to convex optimization, which may be considered a â€œï¬rst pathâ€ to
enter into the more complex and recent results on nonsmooth optimization. The fol-
lowing proposition generalizes to the nonsmooth convex case a well-known property
of differentiable convex functions.
Theorem 10.18 Let X âŠ‚Rn be an open convex set and f : X â†’R a convex func-
tion; let x0 âˆˆX. Then the following conditions are equivalent:
(a)
f admits at x0 a global minimum point, i.e. f (x0) â‰¦f (x), âˆ€x âˆˆX.
(b) 0 âˆˆâˆ‚f (x0).
(c)
f â€²(x0; v) â‰§0, âˆ€v âˆˆRn.
Proof The implication (a)â‡’(c) is evident and, as previously remarked in Theorem
10.17, holds also in absence of convexity assumptions on f . The implication (c)â‡’(b)
follows from Theorem 10.9. The implication (b)â‡’(a) follows at once from the
deï¬nition of subdifferential of f at x0 : the inequality f (x) âˆ’f (x0) â‰§sâŠ¤(x âˆ’x0),
âˆ€x âˆˆX, when s = 0 gives relation (a).
â–¡

10.1 The Convex Case
331
We now consider a convex programming problem of the type (P2), i. e. with a
(convex) set constraint.
Theorem 10.19 Let f : X â†’R be convex on the open convex set X âŠ‚Rn and let
C be an arbitrary convex subset of X. A point x0 âˆˆC is a solution of the problem
min
xâˆˆC f (x)
if and only if
0 âˆˆâˆ‚f (x0) + N(C, x0),
(10.9)
where N(C, x0) is the normal cone to C at x0.
Proof Let us ï¬rst assume that x0 is a solution of the above minimization problem.
Then it is clear that x0 is also a solution of the following unconstrained problem:
min h(x) â‰¡f (x) + Î´(x; C) =
 f (x), if x âˆˆC,
+âˆ, if x /âˆˆC,
where Î´(x; C) is the indicator function, previously introduced. By Theorem 10.18,
since x0 is a (global) minimum point of h(x), we have
0 âˆˆâˆ‚( f + Î´(Â·; C))(x0),
and by the sum rule for subdifferentials (Theorem 10.15 and Remark 10.16), we have
0 âˆˆâˆ‚f (x0) + âˆ‚Î´(x0; C).
But, being âˆ‚Î´(x0; C) = N(C, x0), we get relation (10.9). For the converse case,
observe that the condition 0 âˆˆâˆ‚f (x0) + N(C, x0) means that there exists s âˆˆâˆ‚f (x0)
such that âˆ’s âˆˆN(C, x0). This shows that from the deï¬nition of N(C, x0), it holds
sâŠ¤(x âˆ’x0) â‰§0, âˆ€x âˆˆC. Since s âˆˆâˆ‚f (x0), we see that
f (x) âˆ’f (x0) â‰§sâŠ¤(x âˆ’x0), âˆ€x âˆˆX.
This shows that for all x âˆˆC we have f (x) âˆ’f (x0) â‰§0, i.e. x0 is a global
minimum point of f over C.
â–¡
In terms of directional derivatives, under the same assumptions of Theorem 10.19,
relation (10.9) becomes
f â€²(x0; v) â‰§0, âˆ€v âˆˆT (C, x0),
where T (C, x0) is the Bouligand tangent cone to C at x0 (see Deï¬nition 2.35).
Indeed, from (10.9) there exists s âˆˆâˆ‚f (x0) such that âˆ’s âˆˆN(C, x0). By Theorem

332
10
Introduction to Nonsmooth Optimization Problems
10.9, one has f â€²(x0; v) â‰§sâŠ¤v for all v âˆˆRn. As âˆ’s âˆˆN(C, x0) = T (C; x0)âˆ—, we
have sâŠ¤v â‰§0 for all v âˆˆT (C, x0), and therefore, f â€²(x0; v) â‰§0 for all v âˆˆT (C, x0).
Moreover, as C convex, it holds T (C, x0) = cl(cone(C âˆ’x0)) by Theorem 2.41,
hence relation (10.9) becomes
f â€²(x0; x âˆ’x0) â‰§0, âˆ€x âˆˆC.
Let us now consider an open convex set X âŠ‚Rn; we study the case of a convex
optimization problem of the type (P5), but with no differentiability assumptions
on the functions involved in the problem. Instead of gradients, we make use of
subdifferentials.
(P5) :
â§
âªâªâ¨
âªâªâ©
min f (x)
subject to: gi(x) â‰¦0, i = 1, . . . , m,
h j(x) = 0, j = 1, . . . , p < n,
x âˆˆX âŠ‚Rn,
where f : X â†’R and every gi, i = 1, . . . , m, are convex functions on X and every
h j, j = 1, . . . , p, is a linear afï¬ne function on Rn. Note that under the said assump-
tions the feasible set
K5 =

x : x âˆˆX, g(x) â‰¦0, h(x) = 0

is a convex set.
We give ï¬rst a Fritz John-type result for (P5). We follow the approach of [16].
Theorem 10.20 Suppose that x0 âˆˆK5 is a solution of the convex problem (P5).
Then there exist multipliers u0, u1, . . . , um, v1, . . . , vp, not all zero, such that
0 âˆˆu0âˆ‚f (x0) +
m

i=1
uiâˆ‚gi(x0) +
p

j=1
v jâˆ‚h j(x0),
u0 â‰§0, u1 â‰§0, . . . , um â‰§0; uigi(x0) = 0, i = 1, . . . , m.
Proof Without loss of generality, we can suppose that all inequality constraints are
active at x0, i.e. I (x0) = {1, . . . , m} . Take
A =

( f (x) âˆ’f (x0) + t, g(x) + s, h(x)) : x âˆˆX, t âˆˆ[0, +âˆ) , s âˆˆRm
+

and
B = (âˆ’âˆ, 0) Ã— Rm
âˆ’Ã— {0}p .
It is easy to see that the properties of f, g and h ensure the convexity of A, while
the convexity of B is obvious. On the other hand, if a common element of A and B
exists, then there is also x âˆˆX with f (x) âˆ’f (x0) < 0, g(x) â‰¦0, h(x) = 0, which

10.1 The Convex Case
333
would contradict the (global) minimality of x0 for (P5). Hence, A âˆ©B = âˆ…; by the
separation theorem (Chap. 2), we can deduce the existence of elements u0 âˆˆR,
u1 âˆˆR,â€¦,um âˆˆR, v1 âˆˆR,â€¦,vp âˆˆR, not all zero, such that
u0a + ub â‰¦u0( f (x) âˆ’f (x0) + t) + uâŠ¤(g(x) + s) + vâŠ¤h(x),
for all x âˆˆX, t âˆˆ[0, +âˆ) , s âˆˆRm
+, a âˆˆ(âˆ’âˆ, 0), b âˆˆRm
âˆ’. It is not possible to have
u0 < 0. Indeed, if we suppose this case, letting a â†’âˆ’âˆ, we arrive to a contradic-
tion, since the right-hand side is ï¬xed, while the left-hand side goes to +âˆ. A similar
argument employed for si â†’âˆ(for all i = 1, . . . , m) allows us to conclude that
ui â‰§0 for all i = 1, . . . , m. Letting a â†’0, t â†’0, b â†’0 and s â†’0, we actually
get that
0 â‰¦u0( f (x) âˆ’f (x0)) + uâŠ¤g(x) + vâŠ¤h(x)
for all x âˆˆX. Since g(x0) = 0, we deduce that uigi(x0) = 0 for all i = 1, . . . , m.
Finally, we can write
0 â‰¦(u0 f (x) âˆ’u0 f (x0)) +
m

i=1
(uigi(x) âˆ’uigi(x0)) +
p

j=1
(v jh j(x) âˆ’v jh j(x0)),
for all x âˆˆX, which means that
0 âˆˆâˆ‚
â›
âu0 f +
m

i=1
uigi +
p

j=1
v jh j)(x0
â
â .
Theorem 10.15 allows us to write
0 âˆˆâˆ‚(u0 f )(x0) +
m

i=1
âˆ‚(uigi)(x0) +
p

j=1
âˆ‚(v jh j)(x0)(x0).
Since u0 â‰§0, one has âˆ‚(u0 f )(x0) = u0âˆ‚f (x0). The same argument is appli-
cable to the equality âˆ‚(uigi)(x0) = uiâˆ‚gi(x0) for all i = 1, . . . , m. The equality
âˆ‚(v jh j)(x0) = v jâˆ‚h j(x0), for all j = 1, . . . , p, is true by the fact that h is linear
afï¬ne.
â–¡
If in the previous result, we have u0 Ì¸= 0, i.e. u0 = 1, we obtain the related Karush-
Kuhn-Tucker conditions for (P5), expressed in terms of subdifferentials. Since prob-
lem (P5) is convex, we can use a Slater constraint qualiï¬cation:
â€¢ There exists Â¯x âˆˆX such that g(Â¯x) < 0, h(Â¯x) = 0 and the gradients âˆ‡h j(Â¯x), j =
1, . . . , p, are linearly independent.
(Note that the afï¬ne functions h j(x), j = 1, . . . , p, are differentiable everywhere
and that the gradients âˆ‡h j(x), j = 1, . . . , p, are the same for all x âˆˆX).

334
10
Introduction to Nonsmooth Optimization Problems
Theorem 10.21 Suppose that x0 is a solution of the convex problem (P5) and
that the above Slater constraint qualiï¬cation holds. Then, there exist real numbers
u1, . . . , um, v1, . . . , vp, such that
0 âˆˆâˆ‚f (x0) +
m

i=1
uiâˆ‚gi(x0) +
p

j=1
v jâˆ‚h j(x0),
ui â‰§0, i = 1, . . . , m; uigi(x0) = 0, i = 1, . . . , m.
Proof Itissufï¬cienttoshowthat,undertheassumptionsmadeinthepresenttheorem,
we cannot have u0 = 0 in the Fritz John conditions of Theorem 10.20. Suppose
absurdly that u0 = 0. Then
0 âˆˆ
m

i=1
uiâˆ‚gi(x0) +
p

j=1
v jâˆ‚h j(x0) = âˆ‚
â›
â
m

i=1
uigi +
p

j=1
v jh j
â
â (x0),
that is, for every x âˆˆX,
m

i=1
ui(gi(x) âˆ’gi(x0)) +
p

j=1
v j(h j(x) âˆ’h j(x0)) â‰§0,
i.e.
m

i=1
uigi(x) +
p

j=1
v jh j(x) â‰§0.
For x = Â¯x (the element of the Slater constraint qualiï¬cation), this becomes
m

i=1
uigi(Â¯x) â‰§0,
which is possible only if ui = 0 for all i = 1, . . . , m. So, in fact
p

j=1
v jh j(x) â‰§
p

j=1
v jh j(x0) = 0, âˆ€x âˆˆX.
This means that x0 is a minimum (unconstrained) for the function p
j=1 v jh j(x)
and, by Fermatâ€™s theorem, we get
p

j=1
v jâˆ‡h j(x0) = 0.

10.1 The Convex Case
335
But the linear independence of the gradients âˆ‡h j(x0), j = 1, . . . , p, says that the
above relation holds only if v j = 0, âˆ€j = 1, . . . , p. But then we have that u0 = 0,
u1 = Â· Â· Â· = um = 0, v1 = Â· Â· Â· = vp = 0, which is a contradiction to the thesis of
Theorem 10.20. The proof is complete.
â–¡
Remark 10.22 (a) The Karush-Kuhn-Tucker conditions of Theorem 10.21 are also
sufï¬cient for x0 âˆˆK5 to be a solution of (P5), being (P5) a convex problem.
(b) If in (P5) we have, besides the functional constraints, also a set constraint (or
abstract constraint), represented by C âŠ‚X, being C closed and convex, the related
necessary Karush-Kuhn-Tucker conditions must be suitably modiï¬ed. Call (P6) this
last problem. In this case, the point Â¯x which satisï¬es the Slater constraint qualiï¬cation
must be interior to C :
Â¯x âˆˆint(C), g(Â¯x) < 0, h(Â¯x) = 0, âˆ‡h j(Â¯x) j = 1, . . . , p, linearly independent.
The other requirements remain the same as the ones of Theorem 10.21. We have
the following result.
â€¢ Assume that x0 is a solution of the convex problem (P6) and that the above Slater
constraint qualiï¬cation is satisï¬ed. Then there exist u âˆˆRm
+ and v âˆˆRp such that
0 âˆˆâˆ‚f (x0) +
m

i=1
uiâˆ‚gi(x0) +
p

j=1
v jâˆ‚h j(x0) + N(C, x0);
(10.10)
uigi(x0) = 0, i = 1, . . . , m.
(10.11)
Conversely, if for some feasible point x0 for (P6), conditions (10.10) and (10.11)
are satisï¬ed, for some u âˆˆRm
+ and v âˆˆRp, then x0 is a solution of (P6).
(Here N(C, x0) is, as usual, the normal cone of the convex set C at x0).
Subgradients of convex functions can be used also to establish a duality result for
a nondifferentiable convex programming problem, on the lines of Wolfeâ€™s duality
theorems for the differentiable case (see Chap. 8).
We consider the â€œprimalâ€ problem
(P) :
â§
â¨
â©
min f (x)
subject to: gi(x) â‰¦0, i = 1, . . . , m,
x âˆˆX âŠ‚Rn,
where f and every gi, i = 1, . . . , m, are convex functions on the open convex set X.
We furthermore assume that the Slater constraint qualiï¬cation is satisï¬ed, i.e. there
exists a vector Â¯x âˆˆX such that gi(Â¯x) < 0, âˆ€i = 1, . . . , m. Based on the Karush-
Kuhn-Tucker conditions for (P), expressed in terms of subdifferentials, we relate
(P) to the following dual problem, of the Wolfe-type:

336
10
Introduction to Nonsmooth Optimization Problems
(WD) :
â§
â¨
â©
max

f (x) + yâŠ¤g(x)

subject to: 0 âˆˆâˆ‚f (x) + m
i=1 yiâˆ‚gi(x),
y â‰§0.
We recall the said Karush-Kuhn-Tucker conditions for (P) : if x0 is feasible for
(P) and the Slater constraint qualiï¬cation is satisï¬ed, then x0 is optimal for (P) if
and only if there exists y âˆˆRm such that y â‰§0, yâŠ¤g(x0) = 0 and
0 âˆˆâˆ‚f (x0) +
m

i=1
yiâˆ‚gi(x0).
Furthermore, if the functions gi, i = 1, . . . , m, are all linear afï¬ne, we get the
same conclusion without assuming the Slater constraint qualiï¬cation. Then we have
the following analogous result of Wolfeâ€™s duality theorem (see [17, 18]).
Theorem 10.23 If x0 is optimal for problem (P), then there exists y0 such that
(x0, y0) is optimal for problem (WD). Furthermore, the two problems have the same
extremal value. If the constraints gi, i = 1, . . . , m, are linear afï¬ne, this conclusion
holds without assuming the Slater constraint qualiï¬cation.
Proof Let (x, y) be feasible for problem (WD). Then y â‰§0 and furthermore, there
exist v âˆˆâˆ‚f (x) and vi âˆˆâˆ‚gi(x), i = 1, . . . , m, such that v + m
i=1 yivi = 0. Then
f (x0) âˆ’

f (x) + yâŠ¤g(x)

â‰§vâŠ¤(x0 âˆ’x) âˆ’yâŠ¤g(x) = âˆ’
m

i=1
yi(vi)âŠ¤(x0 âˆ’x) âˆ’yâŠ¤g(x)
â‰§
m

i=1
yi

gi(x) âˆ’gi(x0)

âˆ’yâŠ¤g(x) = âˆ’yâŠ¤gi(x0) â‰§0.
This shows that, for every (x, y) feasible for (WD), one has
f (x) + yâŠ¤g(x) â‰¦f (x0).
(10.12)
Furthermore, by the Karush-Kuhn-Tucker conditions, there exists a vector y0 âˆˆ
Rm such that (x0, y0) is feasible for (WD) and (y0)âŠ¤g(x0) = 0, so that
f (x0) = f (x0) + (y0)âŠ¤g(x0).
(10.13)
Comparing (10.12) and (10.13), we get the conclusions of the theorem.
â–¡

10.2 The Lipschitz Case
337
10.2
The Lipschitz Case
We have seen that a convex function f : X âŠ‚Rn â†’R possesses ï¬nite directional
derivatives at every interior point of the convex set X and that these directional
derivatives are convex for all directions v âˆˆRn. Being also homogeneous functions
of the ï¬rst degree, they are therefore sublinear functions of v âˆˆRn. The Canadian
mathematician F. H. Clarke presented [19â€“21] a generalized directional derivative
which, for locally Lipschitz functions, (non-necessarily convex) always exists ï¬nite
and is convex and homogeneous of the ï¬rst degree for all directions v âˆˆRn. This
generalized directional derivative, called Clarke directional derivative, and its asso-
ciated subdifferential, called Clarke subdifferential, provide useful tools in obtaining
optimality conditions for nonsmooth and non necessarily convex mathematical pro-
gramming problems.
Clarke theory has become an established theory. The literature on Clarke theory
and its applications to optimization (both scalar and vector), control theory, numerical
methods, etc., is very huge (mostly the papers, published on journals or on proceed-
ings of meetings). Here, for the readerâ€™s convenience, next, we give only some basic
references: [13, 21â€“36].
To go on, we need ï¬rst the deï¬nitions of Lipschitz functions and locally Lipschitz
functions.
Deï¬nition 10.24 Let X âŠ‚Rn be a nonempty set and f : X â†’R. The function f
is said to be Lipschitz over X (or Lipschitz continuous over X) if there exists a real
number k â‰§0 such that, for every x1, x2 âˆˆX, we have
 f (x1) âˆ’f (x2)
 â‰¦k
x1 âˆ’x2 .
(10.14)
The smallest constant k for which the previous relation holds is said â€œthe Lipschitz
constantâ€ or â€œthe Lipschitz rankâ€. Then f is said to be â€œLipschitz of constant kâ€.
If k = 1, then f is said to be non-expansive and if k < 1, then f is said to be a
contraction.
Note that if f is Lipschitz on X, then it is (uniformly) continuous on X, but
the converse is not true: take, e.g. the continuous function f (x) = x
1
3 , x âˆˆR; with
x2 = 0, we see that there is no constant k â‰§0 satisfying (10.14). To understand the
meaning of (10.14), rewrite it as follows:
 f (x1) âˆ’f (x2)

x1 âˆ’x2
â‰¦k, âˆ€x1 Ì¸= x2 âˆˆX.
Hence, a function is Lipschitz on the set X âŠ‚Rn if and only if all its difference
quotients are bounded.

338
10
Introduction to Nonsmooth Optimization Problems
Example 10.25 (a) The function f (x) = âˆ¥xâˆ¥, x âˆˆRn, is Lipschitz on Rn, with
k = 1.
(b) The function f (x) = âˆ¥xâˆ¥2 is not Lipschitz on the whole space Rn. Indeed, by
choosing x2 = 0, we have
x12 â‰¦k
x1
which holds only if
x1 â‰¦k.
A sufï¬cient condition for f to be Lipschitz on a set contained in its domain is given
by the following proposition, which is a consequence of the mean value theorem.
Theorem 10.26 Let be f : X âŠ‚Rn â†’R, with X open convex set. If f is differen-
tiable on X and if all its partial derivatives are bounded on X, then f is Lipschitz
on X. Moreover, for every M â‰§0 such that

âˆ‚f
âˆ‚xi
(x)
 â‰¦M, âˆ€x âˆˆX, âˆ€i = 1, . . . , n,
then relation (10.14) holds with k = âˆšnM.
Deï¬nition 10.27 Let X âŠ‚Rn be a nonempty open set and f : X â†’R. Given a
point x0 âˆˆX, if there exist a neighborhood N(x0) of x0 and a nonnegative number
k such that
 f (x1) âˆ’f (x2)
 â‰¦k
x1 âˆ’x2 , âˆ€x1, x2 âˆˆN(x0),
then f is said to be locally Lipschitz at x0 or Lipschitz near x0 or Lipschitz around
x0, with constant k.
We say that f is locally Lipschitz on X if f is locally Lipschitz at each x âˆˆX.
Thus, a function which is locally Lipschitz at a point means that the function satis-
ï¬es the Lipschitz condition in a neighborhood of that point. However, it is important
to note that the value of the Lipschitz constant k in general could change as we change
the point. Obviously, we have the implication
{ f Lipschitz on X âŠ‚R, X open} â‡’{ f locally Lipschitz at each point of X} ,
but the converse is in general not true. If, however, a locally Lipschitz function has a
uniform Lipschitz constant k at every point x0 âˆˆX, then f is Lipschitz on X in the
sense of Deï¬nition 10.24.
A sufï¬cient condition for f to be locally Lipschitz at a point x0 of its domain is
given by the following proposition.
Theorem 10.28 If a function f : X âŠ‚Rn â†’R is continuously differentiable (i.e.
of class C 1) in a neighborhood of x0 âˆˆint(X), then f is locally Lipschitz at x0.
Proof Continuous differentiability around x0 means that all n partial derivatives of
f are continuous on a neighborhood of x0. It follows that there exist constants Îµ > 0
and k â‰§0 such that

10.2 The Lipschitz Case
339
âˆ¥âˆ‡f (x)âˆ¥â‰¦k, for all x âˆˆN(x0, Îµ).
Suppose that x1, x2 âˆˆN(x0, Îµ). Then, by the classical mean value theorem, there
is z âˆˆ(x1, x2) âŠ‚N(x0, Îµ) such that
f (x1) âˆ’f (x2) = âˆ‡f (z)âŠ¤(x1 âˆ’x2).
We now have
 f (x1) âˆ’f (x2)
 â‰¦âˆ¥âˆ‡f (z)âˆ¥
x1 âˆ’x2 â‰¦k
x1 âˆ’x2 ,
i.e. f is Lipschitz continuous at x0.
â–¡
The following result gives an important property of convex functions for what
concerns Lipschitz continuity.
Theorem 10.29 Let f : X âŠ‚Rn â†’R be a convex function on the open convex set
X. Then f is locally Lipschitz on X.
Proof Consider any x0 âˆˆX. Since f : X â†’R is a convex function and X is open,
then f is continuous at x0. Hence, f is locally bounded, i.e. there exist Î´ > 0 and
k > 0 such that | f (x)| â‰¦k for all x âˆˆN2Î´(x0). Consider x and y to be two distinct
points in NÎ´(x0). Let be Î± = âˆ¥x âˆ’yâˆ¥and let be
z = y + Î´
Î± (y âˆ’x).
Thus, we have
z âˆ’x0 â‰¦
y âˆ’x0 + âˆ¥z âˆ’yâˆ¥=
y âˆ’x0 + Î´
Î± âˆ¥y âˆ’xâˆ¥â‰¦Î´ + Î´ = 2Î´.
This shows that z âˆˆN2Î´(x0). Note that y can be expressed as
y =
Î±
Î± + Î´ z +
Î´
Î± + Î´ x.
Using the convexity of f, we have
f (y) â‰¦
Î±
Î± + Î´ f (z) +
Î´
Î± + Î´ f (x).
Hence,
f (y) âˆ’f (x) â‰¦
Î±
Î± + Î´ ( f (z) âˆ’f (x)) â‰¦2k
Î´ Î± = 2k
Î´ âˆ¥x âˆ’yâˆ¥.
Interchanging the roles of x and y yields

340
10
Introduction to Nonsmooth Optimization Problems
| f (x) âˆ’f (y)| â‰¦2k
Î´ âˆ¥x âˆ’yâˆ¥,
thereby establishing the result.
â–¡
The deï¬nition of Lipschitz continuity of a function allows to give another use-
ful representation of the Bouligand tangent cone to a set S âŠ‚Rn at x0 âˆˆS (see
Deï¬nition 2.35) and it will be useful also to characterize the so-called Clarke tan-
gent cone to a set S âŠ‚Rn at x0 âˆˆS. See further and see, e.g. [37â€“40]. We ï¬rst need
the following deï¬nition.
Deï¬nition 10.30 Let S âŠ‚Rn be a given set and let x âˆˆRn. Then the distance of S
from x is given by the function
dS(x) = inf {âˆ¥x âˆ’sâˆ¥: s âˆˆS} .
If x âˆˆS, then it is clear that dS(x) = 0. The following result reveals a basic
property of the distance function.
Theorem 10.31 For a given set S âŠ‚Rn, the distance function dS(Â·) is a Lipschitz
function of rank 1 on Rn and if S is convex, then the distance function dS(Â·) is a
convex function on Rn.
Proof Let Îµ > 0 be an arbitrary scalar number. By deï¬nition, there exists a point
y âˆˆS such that, for some u âˆˆRn, one has dS(u) â‰§âˆ¥u âˆ’yâˆ¥âˆ’Îµ. Let x âˆˆRn.
Then dS(x) â‰¦âˆ¥x âˆ’yâˆ¥â‰¦âˆ¥x âˆ’uâˆ¥+ âˆ¥u âˆ’yâˆ¥. This shows that dS(x) â‰¦âˆ¥x âˆ’uâˆ¥+
dS(u) + Îµ. Hence, noting that Îµ > 0 is arbitrary, we deduce
dS(x) âˆ’dS(u) â‰¦âˆ¥x âˆ’uâˆ¥.
(10.15)
Now switching the roles of x and u in (10.15), we get that
|dS(x) âˆ’dS(u)| â‰¦âˆ¥x âˆ’uâˆ¥,
thus proving that dS(Â·) is a Lipschitz function on Rn of rank 1. For the proof that
dS(Â·) is a convex function on Rn if S is convex, see, e.g. [41].
â–¡
Theorem 10.32 Let be given S âŠ‚Rn and let be x0 âˆˆS. Then
T (S, x0) =

v âˆˆRn : lim inf
tâ†’0+
dS(x0 + tv)
t
= 0

.
We follow the proof of [37]. We ï¬rst need a preliminary result.
Lemma 10.33 Let f : X âŠ‚Rn â†’R be a locally Lipschitz function on the open set
X, x âˆˆX and v âˆˆRn. Then
lim inf
uâ†’v, tâ†’0+
f (x + tu) âˆ’f (x)
t
= lim inf
tâ†’0+
f (x + tv) âˆ’f (x)
t
.

10.2 The Lipschitz Case
341
Proof The left-hand side expression of the above equality can be written as
lim inf
uâ†’v, tâ†’0+
f (x + tu) âˆ’f (x)
t
=
= lim inf
uâ†’v, tâ†’0+
f (x + tu) âˆ’f (x + tv) + f (x + tv) âˆ’f (x)
t
.
Now the Lipschitzian property of f shows that
lim
uâ†’v, tâ†’0+
f (x + tu) âˆ’f (x + tv)
t
= 0.
(10.16)
Hence, this shows that
lim inf
uâ†’v, tâ†’0+
f (x + tu) âˆ’f (x)
t
=
=
lim
uâ†’v, tâ†’0+
f (x + tu) âˆ’f (x + tv)
t
+ lim inf
uâ†’v, tâ†’0+
f (x + tv) âˆ’f (x)
t
.
Using (10.16), we get
lim inf
uâ†’v, tâ†’0+
f (x + tu) âˆ’f (x)
t
= lim inf
uâ†’v, tâ†’0+
f (x + tv) âˆ’f (x)
t
.
(10.17)
Since in the right-hand side of (10.17) u plays no role, we conclude that
lim inf
uâ†’v, tâ†’0+
f (x + tu) âˆ’f (x)
t
= lim inf
tâ†’0+
f (x + tv) âˆ’f (x)
t
.
â–¡
Proof of Theorem 10.32. Consider v âˆˆT (S, x0). Then there exist sequences

vk
,
with vk â†’v and tk â†’0+ such that x0 + tkvk âˆˆS. We know that dS : Rn â†’R is
Lipschitz and that dS(x0) = 0. Then
lim inf
tâ†’0+
dS(x0 + tv)
t
= lim inf
tâ†’0+
dS(x0 + tv) âˆ’dS(x0)
t
exists and is ï¬nite. Now we have
lim inf
uâ†’v, tâ†’0+
dS(x0 + tu)
t
â‰¦lim inf
kâ†’+âˆ
dS(x0 + tkvk)
tk
.
(10.18)
As x0 + tkvk âˆˆS, it follows that

342
10
Introduction to Nonsmooth Optimization Problems
lim
kâ†’+âˆ
dS(x0 + tkvk)
tk
= 0.
Therefore, from (10.18), we have
lim inf
uâ†’v, tâ†’0+
dS(x0 + tu)
t
â‰¦0.
Since dS(Â·) is a Lipschitz function by Theorem 10.31, then, by using
Lemma 10.33, we have
lim inf
uâ†’v, tâ†’0+
dS(x0 + tu)
t
= lim inf
tâ†’0+
dS(x0 + tv)
t
.
This shows that
lim inf
tâ†’0+
dS(x0 + tv)
t
â‰¦0.
But, as dS(x0 + tv) â‰§0 and t > 0, we have
lim inf
tâ†’0+
dS(x0 + tv)
t
â‰§0,
and hence
lim inf
tâ†’0+
dS(x0 + tv)
t
= 0.
Now we prove the converse. Assume that v satisï¬es
lim inf
tâ†’0+
dS(x0 + tv)
t
= 0.
Hence, there exists tk â†’0+ such that
lim
tkâ†’0+
dS(x0 + tkv)
tk
= 0.
Now, by the deï¬nition of dS(Â·), for each k, we have sk âˆˆS such that
x0 + tkv âˆ’sk â‰¦dS(x0 + tkv) + tk
k .
Consider vk = (sk âˆ’x0)/tk. Then we have
vk âˆ’v
 =
x0 + tkv âˆ’sk
tk
â‰¦dS(x0 + tkv)
tk
+ 1
k .

10.2 The Lipschitz Case
343
This shows that vk â†’v as k â†’âˆ. Hence, vk â†’v and x0 + tkvk = sk âˆˆS.
Therefore, v âˆˆT (S, x0).
â–¡
Similarly, it can be proved that the cone of attainable directions A(S, x0) can be
characterized as follows:
A(S, x0) =

v âˆˆRn : lim
tâ†’0+
dS(x0 + tv)
t
= 0

,
from which it appears at once that A(S, x0) âŠ‚T (S, x0).
Itisworthnotingthatwhen S isconvex,dS : Rn â†’Risaconvexfunction(besides
a Lipschitz function), on the grounds of Theorem 10.31. Hence, in this case, we have
lim inf
tâ†’0+
dS(x0 + tv)
t
= lim inf
tâ†’0+
dS(x0 + tv) âˆ’dS(x0)
t
=
= lim
tâ†’0+
dS(x0 + tv) âˆ’dS(x0)
t
= dâ€²
S(x0; v),
being dâ€²
S(x0; v) the right-sided directional derivative of dS(Â·) at x0 in the direction v.
Hence, for a convex set S âŠ‚Rn and x0 âˆˆS, we have
T (S, x0) =

v âˆˆRn : dâ€²
S(x0, v) = 0

.
Clarke [19â€“21] generalized this last characterization, by deï¬ning a tangent cone
which is always closed and convex, also when S is not necessarily convex. See further.
We are now ready to give the basic deï¬nition of Clarke directional derivative or
generalized directional derivative of a function f : X â†’R, X âŠ‚Rn open set.
Deï¬nition 10.34 Let X âŠ‚Rn be a nonempty open set and f : X â†’R be a locally
Lipschitz function on X. The Clarke directional derivative, denoted f o(x0; v), of f
at x0 âˆˆX in the direction v âˆˆRn, is deï¬ned by
f o(x0; v) = lim sup
xâ†’x0,tâ†’0+
f (x + tv) âˆ’f (x)
t
.
(10.19)
Since f is locally Lipschitz, the difference quotient
f (x + tv) âˆ’f (x)
t
is bounded and the limit in (10.19) exists ï¬nite.
Other generalized directional derivatives have been introduced and used in opti-
mization theory, for example, the following ones:

344
10
Introduction to Nonsmooth Optimization Problems
fD(x0; v) = lim inf
tâ†’0+
f (x0 + tv) âˆ’f (x0)
t
,
called the lower Dini directional derivative (of f at x0 in the direction v âˆˆRn), and
f D(x0; v) = lim sup
tâ†’0+
f (x0 + tv) âˆ’f (x0)
t
,
called the upper Dini directional derivative (of f at x0 in the direction v âˆˆRn).
We note that fD(x0; v) and f D(x0; v) always exist, ï¬nite or not. From the deï¬-
nitions we have, for a locally Lipschitz function f,
fD(x0; v) â‰¦f D(x0; v) â‰¦f o(x0; v).
(10.20)
In order that the usual (right-sided) directional derivative f â€²(x0; v) exists ï¬nite,
we must have
âˆ’âˆ< fD(x0; v) = f D(x0; v) < +âˆ.
In this case, we have, if f o(x0; v) exists ï¬nite,
fD(x0; v) = f D(x0; v) = f â€²(x0; v) â‰¦f o(x0; v).
On the grounds of Theorem 10.32, it turns out that
T (S, x0) =

v âˆˆRn : (dS)D(x0; v) = 0

(10.21)
where (dS)D is the lower Dini directional derivative of dS.
For other notions and applications of Dini directional derivatives to optimization,
see, e.g. [42â€“45].
The Clarke directional derivative has several interesting properties, not possessed
in general by the Dini directional derivatives. We give below the main of the said
properties.
Theorem 10.35 Let f : X â†’R be locally Lipschitz with rank k at x0 âˆˆX, with X
open subset of Rn. Then:
(i) The Clarke directional derivative of f at x0 in any direction v âˆˆRn exists ï¬nite,
f o(x0; Â·) is a positively homogeneous and convex function on Rn with respect
to the direction v (i.e. it is a sublinear function), and it holds
 f o(x0; v)
 â‰¦k âˆ¥vâˆ¥, âˆ€v âˆˆRn.
(10.22)
(ii) It holds
f o(x0; âˆ’v) = (âˆ’f )o(x0; v), âˆ€v âˆˆRn,
(10.23)
(iii) The function v â†’f o(x0; v) is Lipschitz of rank k on Rn.

10.2 The Lipschitz Case
345
(iv) The function (x, v) â†’f o(x; v) is upper-semicontinuous at (x0, v).
Proof (i) Since f is locally Lipschitz near x0, it holds for any x + tv and x which
are sufï¬ciently close to x0,
| f (x + tv) âˆ’f (x)| â‰¦kt âˆ¥vâˆ¥.
Then it follows that f o(x0; v) exists ï¬nite and (10.22) holds. Now we prove the
positive homogeneity and convexity of f o(x0; Â·). It holds that for any v âˆˆRn and
Î» > 0
f o(x0; Î»v) = lim sup
xâ†’x0,tâ†’0+
f (x + Î»tv) âˆ’f (x)
t
= Î» lim sup
xâ†’x0,tâ†’0+
f (x + Î»tv) âˆ’f (x)
Î»t
= Î»f o(x0; v).
Hence, f o(x0; Â·) is a positively homogeneous function on Rn. Also, for any
v1, v2 âˆˆRn, we have
f o(x0; v1 + v2) = lim sup
xâ†’x0,tâ†’0+
f (x + tv1 + tv2) âˆ’f (x)
t
â‰¦lim sup
xâ†’x0,tâ†’0+
f (x + tv1 + tv2) âˆ’f (x + tv2)
t
+ lim sup
xâ†’x0,tâ†’0+
f (x + tv2) âˆ’f (x)
t
= f o(x0; v1) + f o(x0; v2).
Hence, from the positive homogeneity of f o(x0; v), we get that f o(x0; Â·) is a
convex function on Rn : indeed, homogeneity and subadditivity imply convexity.
See, e.g. [46].
(ii) For arbitrarily ï¬xed v âˆˆRn, we have
f o(x0; âˆ’v) = lim sup
xâ†’x0,tâ†’0+
f (x âˆ’tv) âˆ’f (x)
t
.
The transformation y = x âˆ’tv yields
f o(x0; âˆ’v) = lim sup
yâ†’x0,tâ†’0+
f (y) âˆ’f (y + tv)
t
= (âˆ’f o)(x0; v).
(iii) By the subadditivity and relations (10.22), (10.23), one gets that, with v and w
two vectors of Rn,
f o(x0; v) âˆ’f o(x0; w) â‰¦f o(xo, v âˆ’w) â‰¦k âˆ¥v âˆ’wâˆ¥, âˆ€v, w âˆˆRn.

346
10
Introduction to Nonsmooth Optimization Problems
Interchanging the roles of v and w establishes property (iii).
(iv) For the proof of this property, see, e.g. [21].
â–¡
We have to remark once more the following important property of f o(x0; Â·) :
even if f is a nonconvex function (but it is locally Lipschitz at x0), then f o(x0; Â·) is
guaranteed to be a positively homogeneous convex function on Rn.
Clarke introduced also the concept of â€œgeneralized subdifferentialâ€ for a locally
Lipschitz function, in the same spirit of the usual subdifferential in Convex Analysis.
Deï¬nition 10.36 Let f : X â†’R be locally Lipschitz at x0 âˆˆX, X open set of Rn.
Then the Clarke subdifferential of f at x0 or Clarke generalized gradient of f at x0,
denoted by âˆ‚o f (x0), is given by
âˆ‚o f (x0) =

Î¾ âˆˆRn : f o(x0; v) â‰§Î¾ âŠ¤v, âˆ€v âˆˆRn
.
The following basic properties of the Clarke subdifferential are due to [19â€“21].
Theorem 10.37 Let f : X â†’R be locally Lipschitz, with rank k, at x0 âˆˆX, X
open set of Rn. Then:
(i) âˆ‚o f (x0) is a nonempty compact convex set and we have
âˆ¥Î¾âˆ¥â‰¦k, âˆ€Î¾ âˆˆâˆ‚o f (x0).
(10.24)
(ii) It holds
f o(x0; v) =
max
Î¾âˆˆâˆ‚o f (x0)

Î¾ âŠ¤v

, âˆ€v âˆˆRn.
(10.25)
In other words, f o(x0; v) is the â€œsupport functionâ€ of the set âˆ‚o f (x0). See [21].
Proof (i) From Theorem 10.35, f o(x0; Â·) is a convex function. Thus, f o(x0; v) has
a nonempty subdifferential at v = 0 (in the Convex Analysis sense) and hence there
exists a vector Î¾ âˆˆRn such that
f o(x0; v) â‰§f o(x0; 0) + Î¾ âŠ¤v = Î¾ âŠ¤v, âˆ€v âˆˆRn.
This means that Î¾ âˆˆâˆ‚o f (x0) and hence âˆ‚o f (x0) is nonempty. If we next suppose
that
Â¯Î¾
 > k for some Â¯Î¾ âˆˆâˆ‚o f (x0), then from (10.22) of Theorem 10.35 we obtain
f o(x0; Â¯Î¾) â‰¦k
Â¯Î¾
 <
Â¯Î¾
2 = Â¯Î¾ âŠ¤Â¯Î¾
which contradicts Â¯Î¾ âˆˆâˆ‚o f (x0). Therefore, (10.24) holds and so âˆ‚o f (x0) is bounded.
The closedness and the convexity of âˆ‚o f (x0) follow immediately from the deï¬nition
of âˆ‚o f (x0) and the convexity of f o(x0; Â·).
(ii) From the deï¬nition and the compactness of âˆ‚o f (x0), it holds that for an arbi-
trarily ï¬xed vector Â¯v âˆˆRn

10.2 The Lipschitz Case
347
f o(x0; Â¯v) â‰§
max
Î¾âˆˆâˆ‚o f (x0)

Î¾ âŠ¤Â¯v

.
Thus, all we have to show is the existence of Â¯Î¾ âˆˆâˆ‚o f (x0) satisfying f o(x0; Â¯v) =
Â¯Î¾ âŠ¤Â¯v. Since f o(x0; Â·) is a convex function, we can choose an element, say Â¯Î¾, of its
subdifferential at Â¯v and it follows that
f o(x0; v) â‰§f o(x0; Â¯v) + Â¯Î¾ âŠ¤(v âˆ’Â¯v), âˆ€v âˆˆRn.
(10.26)
Letting v = 0, we have f o(x0; Â¯v) â‰¦Â¯Î¾ âŠ¤Â¯v. Meanwhile, (10.26) with v = t Â¯v, t > 1,
yields f o(x0; Â¯v) = Â¯Î¾ âŠ¤Â¯v. We thus have
f o(x0; Â¯v) = Â¯Î¾ âŠ¤Â¯v.
(10.27)
It follows from (10.26) and (10.27) that f o(x0; v) â‰§Â¯Î¾ âŠ¤v, âˆ€v âˆˆRn, showing
Â¯Î¾ âˆˆâˆ‚o f (x0). Thus, (10.25) follows from (10.27).
â–¡
We now give some basic information on the relationships between the Clarke sub-
differential and the usual gradient of a locally Lipschitz function. The ï¬rst question
to be pointed out is that even if f : Rn â†’R is locally Lipschitz and differentiable
at a given point x0 âˆˆdom( f ), the Clarke subdifferential may not be a singleton,
i.e. it need not coincide with the gradient of f at x0. However, if the function is
continuously differentiable around a point x0, then the Clarke subdifferential is a
singleton, given by the gradient of f at x0. More precisely, we have the following
result.
Theorem 10.38 (a) Let f : X â†’R be locally Lipschitz and differentiable at x0 âˆˆ
X, X open set of Rn; then
âˆ‡f (x0) âˆˆâˆ‚o f (x0).
(b) Let f : X â†’R be continuously differentiable around x0 âˆˆX, X open set of Rn;
then
âˆ‚o f (x0) =

âˆ‡f (x0)

.
The above theorem can be illustrated by the following example, given in [21].
Example 10.39 Let f : R â†’R be given by
f (x) =

x2 sin
 1
x

, if x Ì¸= 0,
0,
if x = 0.
This function is differentiable for all x âˆˆR and f â€²(0) = 0. Being f â€²(x) bounded
on each neighborhood U(0), then f is locally Lipschitz around x0 = 0 and we have
that âˆ‚o f (0) = [âˆ’1, 1] . The reader is invited to calculate âˆ‚o f (0).
The results of Theorem 10.38 can be ameliorated. Clarke [21] proved that the
Clarke subdifferential âˆ‚o f (x0) contains a unique element, âˆ‡f (x0), if and only if f

348
10
Introduction to Nonsmooth Optimization Problems
is strictly differentiable at x0. A function f : X âŠ‚Rn â†’R is strictly differentiable
at x0 âˆˆint(X) if
lim
(Â¯x, Â¯v, t)â†’(x0, v, 0+)
f (Â¯x + t Â¯v) âˆ’f (Â¯x)
t
= vâŠ¤z, âˆ€v âˆˆRn,
where z = âˆ‡f (x0). Let us observe that strict differentiability at x0 implies differ-
entiability at x0, but the converse does not hold. If f is C 1 at x0, then it is strictly
differentiable at x0 , but the converse does not hold. However, f : X âŠ‚Rn â†’R is
strictly differentiable on the open set X âŠ‚Rn if and only if f is C 1 on X. See [33].
The next theorem gives a useful result for calculating the Clarke subdifferential
of a locally Lipschitz function, as in general, it is not easy to get the expression of
the said subdifferential. For the proof of the theorem see [21].
Theorem 10.40 If a function f : X â†’R is locally Lipschitz at x0 âˆˆX, X open set
of Rn, then we have
âˆ‚o f (x0) = conv
Î¾ âˆˆRn : there exists

xk
âŠ‚X \ 
 f such that
xk â†’x0 and âˆ‡f (xk) â†’Î¾

,
where 
 f = {x âˆˆX : f is not differentiable at the pointx} .
In other words, as an important theorem of Rademacher says that a function which
is Lipschitz continuous on an open set U âŠ‚Rn is differentiable â€œalmost everywhereâ€
on U (i.e. except of sets of measure zero), the aspect of the Clarke subdifferential is
â€œindependentâ€ from sets of measure zero.
The following example which makes use of Theorem 10.40 is taken from [37].
Example 10.41 Consider f : R2 â†’R given by f (x, y) = |x| âˆ’|y| . This function
can be represented as
f (x, y) =
â§
âªâªâ¨
âªâªâ©
x âˆ’y,
if x â‰§0, y â‰§0
âˆ’x âˆ’y, if x â‰¦0, y â‰§0
x + y,
if x â‰§0, y â‰¦0
âˆ’x + y, if x â‰¦0, y â‰¦0.
Obviously, f (x, y) is not differentiable only at the points along the x-axis and
y-axis of the two-dimensional plane. We want to calculate âˆ‚o f (0, 0). At all other
points the gradient is given by
âˆ‡f (x, y) =
â§
âªâªâ¨
âªâªâ©
(1, âˆ’1)âŠ¤,
if x > 0, y > 0
(âˆ’1, âˆ’1)âŠ¤, if x < 0, y > 0
(1, 1)âŠ¤,
if x > 0, y < 0
(âˆ’1, 1)âŠ¤,
if x < 0, y < 0.
Using Theorem 10.40, we have

10.2 The Lipschitz Case
349
âˆ‚o f (0, 0) = conv {(1, âˆ’1), (âˆ’1, âˆ’1), (1, 1), (âˆ’1, 1)} ,
i.e. âˆ‚o f (0, 0) is a square in R2 with the above four points as its vertices.
We have seen that it holds
f â€²(x0; v) â‰¦f o(x0; v), âˆ€v âˆˆRn,
provided that these quantities exist. However, even in the Lipschitz case, the above
inequality may be strict: besides the case of Example 10.39, consider the following
case.
Example 10.42 Let be given the function f (x) = âˆ’|x| , x âˆˆR, and let be f1(x) =
|x| . It is easy to see that
f o
1 (0; v) = |v| .
Being f (x) = âˆ’f1(x), by Theorem 10.35(ii), we get f o(0; v) = |v| and being
f â€²(0; v) = âˆ’|v| , we deduce that f â€²(0; v) < f o(0; v), âˆ€v Ì¸= 0.
An important result states that for convex functions the one-sided directional
derivative f â€²(x0; v) and the Clarke directional derivative f o(x0; v) coincide. For the
proof of this property, see, e.g. [21].
Theorem 10.43 Let f : X âŠ‚Rn â†’R be convex on the open convex set X. Then
f â€²(x0; v) = f o(x0; v), âˆ€x0 âˆˆX, âˆ€v âˆˆRn.
Hence, âˆ‚f (x0) = âˆ‚0 f (x0), âˆ€x0 âˆˆX.
Following [21] we give the next deï¬nition.
Deï¬nition 10.44 Let f : X âŠ‚Rn â†’R be a locally Lipschitz function on the open
set X. The function f is called regular at x0 âˆˆX or Clarke regular at x0 âˆˆX if
(a)
f â€²(x0; v) exists (ï¬nite) for all v âˆˆRn.
(b) It holds
f â€²(x0; v) = f o(xo; v), âˆ€v âˆˆRn.
The function f is regular on X if it is regular at every x0 âˆˆX.
Therefore, any convex function on an open convex set X âŠ‚Rn is a Clarke regular
function on X. There are regular but non-convex functions and there are non-regular
functions. We give an example for the ï¬rst case. The second case can be illustrated
by Example 10.41.
Example 10.45 Consider the function f : R â†’R given by
f (x) =
0,
if x < 0
âˆ’x2, if x â‰§0.

350
10
Introduction to Nonsmooth Optimization Problems
It is easy to check that f â€²(0; v) = 0, âˆ€v. Now consider the function âˆ’f (x) :
âˆ’f (x) =
0,
if x < 0
x2, if x â‰§0.
It is clear that âˆ’f (x) is convex. We have f o(0; v) = (âˆ’f )o(0; âˆ’v). Hence,
f o(0; v) = 0 = f â€²(0; v). This shows that f is a regular function, even if it is not
convex.
Other sufï¬cient conditions for f to be regular at x0 are:
(1) f is continuously differentiable around x0;
(2) f = m
i=1 Î»i fi, where Î»i > 0, âˆ€i = 1, . . . , m, and every fi is regular at x0,
i = 1, . . . , m.
We note, moreover, that if f is differentiable and regular at x0, then
âˆ‚o f (x0) =

âˆ‡f (x0)

.
In other words, regularity guarantees that the gradient is the unique Clarke subdif-
ferential of a differentiable function.
We now give some calculus rules for the Clarke subdifferential, which are in a
certain sense, a generalization to the nonsmooth Lipschitz case of the calculus rules
of the classical (smooth) analysis. For the related proofs, see, e.g. [21].
Theorem 10.46 Let f : X âŠ‚Rn â†’R be locally Lipschitz on the open set X. Then,
for any scalar Î± âˆˆR and for any x0 âˆˆX, it holds
âˆ‚o(Î±f )(x0) = Î±âˆ‚o f (x0).
Theorem 10.47 Let f1, . . . , fm be locally Lipschitz on the open set X âŠ‚Rn. Then
it holds, for each x0 âˆˆX,
âˆ‚o
 m

i=1
fi(x0)

âŠ‚
m

i=1
âˆ‚o fi(x0).
More generally, with Î±1, . . . , Î±m âˆˆR,
âˆ‚o
 m

i=1
Î±i fi

(x0) âŠ‚
m

i=1
Î±iâˆ‚o fi(x0).
If every function f1, . . . , fm is Clarke regular, then, with Î±1 â‰§0, . . . , Î±m â‰§0,
âˆ‚o
 m

i=1
Î±i fi

(x0) =
m

i=1
Î±iâˆ‚o fi(x0), âˆ€x0 âˆˆX.

10.2 The Lipschitz Case
351
Theorem 10.48 If f : X â†’R and g : X â†’R are locally Lipschitz on the open set
X âŠ‚Rn, then f Â· g is locally Lipschitz on X and, for every x0 âˆˆX,
âˆ‚o( f Â· g)(x0) âŠ‚g(x0)âˆ‚o f (x0) + f (x0)âˆ‚og(x0).
If, in addition, f (x0) â‰§0, g(x0) â‰§0 and f and g are both Clarke regular, then
f Â· g is also Clarke regular and equality holds in the above inclusion.
Theorem 10.49 Let f : X â†’R and g : X â†’R be locally Lipschitz on the open
set X âŠ‚Rn; let be g(x) Ì¸= 0, x âˆˆX. Then the ratio f
g : X â†’R is locally Lipschitz
on X and, with x0 âˆˆX,
âˆ‚o
 f
g
	
(x0) âŠ‚g(x0)âˆ‚o f (x0) âˆ’f (x0)âˆ‚0g(x0)

g(x0)
2
.
If, in addition, f (x0) â‰§0, g(x0) > 0 and f and g are both Clarke regular, then
the equality holds in the above inclusion and f
g is also regular.
The next result is a chain rule for locally Lipschitz functions.
Theorem 10.50 Let f : Rn â†’R be such that f = g â—¦h, where h : Rn â†’Rm is
locally Lipschitz at x0 âˆˆRn (i.e. each of its components is locally Lipschitz at x0)
and g : Rm â†’R is locally Lipschitz at h(x0) âˆˆRm. Then f is locally Lipschitz at
x0 and
âˆ‚0 f (x0) âŠ‚conv
 m

i=1
yiÎ¾ i : Î¾ i âˆˆâˆ‚ohi(x0), (y1, . . . , ym)âŠ¤âˆˆâˆ‚og(h(x0))

.
Moreover, if g is Clarke regular at h(x0) and h is Clarke regular at x0 and for
any y âˆˆâˆ‚og(h(x0)) we have y â‰§0, then the above inclusion holds as equality. The
same is true if g is regular at h(x0) and h is continuously differentiable around x0.
We now discuss brieï¬‚y some geometric concepts associated to the Clarke direc-
tional derivative and to the Clarke subdifferential, i.e. we give some insights on the
notion of Clarke tangent cone and Clarke normal cone. We have seen that the Bouli-
gand tangent cone (or contingent cone) T (S, x0) to a set S âŠ‚Rn at x0 âˆˆS, is a
closed cone, with vertex at 0 âˆˆT (S, x0), but not necessarily convex. Clarke [19â€“21]
introduced a local cone approximation of a set S âŠ‚Rn at x0 âˆˆS, called Clarke tan-
gent cone, which is always closed and convex, even if in some particular cases it may
not be a â€œgoodâ€ local approximation of the set in question (i.e. it may be too small).
The Clarke tangent cone to a set S âŠ‚Rn at x0 âˆˆS, here denoted by T o(S, x0), can
be represented in several equivalent ways (see, e.g. [40, 42, 43]).

352
10
Introduction to Nonsmooth Optimization Problems
Deï¬nition 10.51 Let be given S âŠ‚Rn and x0 âˆˆS. The Clarke tangent cone to S at
x0 is given by
T o(S, x0) =
v âˆˆRn : âˆ€

xk
â†’x0, xk âˆˆS, âˆ€{tk} â†’0, tk > 0,
âˆƒ

vk
â†’v such that xk + tkvk âˆˆS

.
In terms of neighborhoods, we have
T o(S, x0) =
v âˆˆRn : âˆ€Îµ > 0, âˆƒÎ±, Î² > 0, âˆ€Â¯x âˆˆS âˆ©NÎ±(x0),
âˆ€t âˆˆ(0, Î²), âˆƒÂ¯y âˆˆNÎµ(v) such that Â¯x + t Â¯y âˆˆS

.
Another interesting description of the Clarke tangent cone is given in terms of the
Clarke generalized derivative of the distance function dS(x), which is a Lipschitz
function on Rn (Theorem 10.31).
Theorem 10.52 Let S âŠ‚Rn and let x0 âˆˆS; then it holds
T o(S, x0) =

v âˆˆRn : do
S(x0; v) = 0

.
(10.28)
Proof We use the deï¬nition of T o(S, x0) in terms of sequences. Let us denote by
T o
1 (S, x0) the second set of the equality in (10.28). Suppose ï¬rst that v âˆˆT o
1 (S, x0)
and that sequences xk â†’x0 with xk âˆˆS and tk â†’0+ are given. Then do
S(x0; v) = 0
and since xk âˆˆS, we have
0 â‰¦lim
kâ†’âˆ
dS(xk + tkv)
tk
= lim
kâ†’âˆ
dS(xk + tkv) âˆ’dS(xk)
tk
â‰¦
lim sup
yâ†’x0, tâ†’0+
dS(y + tv) âˆ’dS(y)
t
= do
S(x0; v) = 0.
It follows that the limit exists and is zero. Then, for all k âˆˆN, there exists zk âˆˆS
such that
xk + tkv âˆ’zk â‰¦dS(xk + tkv) + tk
k .
If we now deï¬ne
vk = zk âˆ’xk
tk
,
we have
v âˆ’vk =
v âˆ’zk âˆ’xk
tk
 =
xk + tk âˆ’zk
tk
â‰¦dS(xk + tkv)
tk
+ 1
k â†’0
as k â†’âˆand
xk + tkvk = xk + tk
zk âˆ’xk
tk
	
= zk âˆˆS.
Thus, v âˆˆT o(S, x0).

10.2 The Lipschitz Case
353
Now for the converse. Suppose that v âˆˆT o(S, x0) and choose sequences xk â†’x0
and tk â†’0+ such that
lim
kâ†’âˆ
dS(xk + tkv) âˆ’dS(xk)
tk
= do
S(x0; v).
(10.29)
In order to prove that do
S(x0; v) = 0, it sufï¬ces to show that the quantity in the
left side of (10.29) is nonpositive. Indeed, one has always do
S(x0; v) â‰§0, since dS(Â·)
attains a minimum at x0 (see further Theorem 10.56). Let {zk} âŠ‚S such that
âˆ¥zk âˆ’xkâˆ¥< dS(xk) + tk
k .
(10.30)
Then we have
x0 âˆ’zk â‰¦
x0 âˆ’xk +
xk âˆ’zk â‰¦
x0 âˆ’xk + dS(xk) + tk
k â†’0
as k â†’âˆ. Then by assumption, there exists a sequence {vk} converging to v such that
xk + tkvk âˆˆS. By Theorem 10.31, the distance function dS(Â·) is Lipschitz continuous
with Lipschitz constant k = 1 and, in view of (10.30), we get
dS(xk + tkv) â‰¦dS(zk + tkvk) +
xk âˆ’zk + tk
v âˆ’vk
â‰¦dS(xk) + tk
v âˆ’vk + 1
k
	
.
This implies that the quantity in (10.29) is nonpositive and hence we have
do
S(x0; v) = 0, i.e. v âˆˆT o
1 (S, x0).
â–¡
Theorem 10.53 For any set S âŠ‚Rn and any point x0 âˆˆS, the Clarke tangent cone
T o(S, x0) is a closed convex cone (with vertex at the origin). Moreover, T o(S, x0) âŠ‚
T (S, x0).
Proof From Theorem 10.35, we know that the Clarke directional derivative do
S(x0; Â·)
is a positively homogeneous convex function. This leads to the fact that T o(S, x0) is
a convex set by Theorem 10.52 since T o(S, x0) is the level set do
S(x0; v) â‰¦0. Con-
vexity of do
S(x0; Â·) also guarantees the continuity of do
S(x0; Â·) which in turn gives the
closedness of T o(S, x0). Consider now v âˆˆT o(S, x0); we have therefore (Theorem
10.52) do
S(x0; v) = 0.
By applying inequality (10.20) to the function dS(Â·), we obtain
(dS)D(x0; v) â‰¦do
S(x0; v) = 0,
and so (dS)D(x0; v) = 0 since always (dS)D(x0; v) â‰§0. Now, from (10.21), we
conclude that v âˆˆT (S, x0). Hence, T o(S, x0) âŠ‚T (S, x0).
â–¡

354
10
Introduction to Nonsmooth Optimization Problems
As already remarked, in some cases the Clarke tangent cone is however too
â€œsmallâ€ to be a good local approximation of S âŠ‚Rn at x0 âˆˆS. If S âŠ‚Rn is a set
such that at x0 âˆˆS we have T o(S, x0) = T (S, x0), we say that S is Clarke regular
at x0. It is now possible, utilizing polarity, to deï¬ne the Clarke normal cone.
Deï¬nition 10.54 Let S âŠ‚Rn and let x0 âˆˆS. Then the Clarke normal cone to S at
x0 is the cone
N o(S, x0) =

Î¾ âˆˆRn : Î¾ âŠ¤v â‰¦0, âˆ€v âˆˆT 0(S, x0)

= (T 0(S, x0))âˆ—.
The following theorem (for its proof, see, e.g. [21]) presents the main properties
of the Clarke normal cone.
Theorem 10.55 (i) Let S âŠ‚Rn and let x0 âˆˆS. Then the following properties hold.
(a) N o(S, x0) is a closed convex cone.
(b) N o(S, x0) = cl(cone(âˆ‚odS(x0))).
(c) T o(S, x0) =

v âˆˆRn : vâŠ¤Î¾ â‰¦0, âˆ€Î¾ âˆˆN o(S, x0)

= (N o(S, x0))âˆ—.
(ii) Suppose that S âŠ‚Rn is a nonempty convex set and that x0 âˆˆS. Then S is Clarke
regular at x0 and we have
T o(S, x0) = T (S, x0) = cl(cone(S âˆ’x0));
N o(S, x0) =

Î¾ âˆˆRn : Î¾ âŠ¤(y âˆ’x0) â‰¦0, âˆ€y âˆˆS

= N(S, x0).
Moreover, it can be shown that the Clarke normal cone is the closure of the convex
hull of the Mordukhovich normal cone (see [47], vol. 1, Sect. 6.4):
N o(S, x0) = cl(conv(NM(S, x0))).
As for the convex case, also the Clarke normal cone has an interesting geometric
interpretation. Indeed, it holds, if f : X âŠ‚Rn â†’R is locally Lipschitz at x0 âˆˆX,
epi( f o(x0; Â·)) = T o(epi( f ), (x0, f (x0))),
i.e. (v, Î±) âˆˆT o(epi( f ), (x0, f (x0))) if and only if Î± â‰§f o(x0; v). As a consequence
we have that if f : X âŠ‚Rn â†’R is locally Lipschitz at x0 âˆˆX, then similarly to the
convex case (previous Section), we have
âˆ‚o f (x0) =

Î¾ âˆˆRn : (Î¾, âˆ’1) âˆˆN o(epi( f ), (x0, f (x0)))

.
The above considerations have been used to ï¬t the Clarke nonsmooth calculus to a
class of functions larger than the class of locally Lipschitz functions, namely the class
of lower semicontinuous functions; see, e.g. [48]. The same considerations are also
a basic tool to introduce the axiomatic approach of K.-H. Elster and J. Thierfelder
to nonsmooth calculus. See the next Section.

10.2 The Lipschitz Case
355
We now establish necessary optimality conditions for an unconstrained optimiza-
tion problem involving a locally Lipschitz function.
Theorem 10.56 (Fermat rule for Lipschitz functions) Let be f : X âŠ‚Rn â†’R and
let x0 âˆˆint(X) be a local minimum point or a local maximum point for f over X.
Let f be locally Lipschitz at x0, then
0 âˆˆâˆ‚o f (x0),
(10.31)
or equivalently
f o(x0; v) â‰§0, âˆ€v âˆˆRn.
Proof One has, if x0 is a local minimum point, that
f o(x0; v) =
lim sup
xâ†’x0, tâ†’0+
f (x + tv) âˆ’f (x)
t
â‰§lim sup
tâ†’0+
f (x0 + tv) âˆ’f (x0)
t
â‰§0.
On the other hand, if x0 is a local maximum point,
f o(x0; v) =
lim sup
xâ†’x0, tâ†’0+
f (x + tv) âˆ’f (x)
t
â‰§lim sup
tâ†’0+
f (x0) âˆ’f (x0 âˆ’tv)
t
â‰§0.
Hence, in both cases,
f o(x0; v) â‰§0 for any v âˆˆRn, which proves the
conclusion.
â–¡
A point x0 satisfying relation (10.31) is also called a Clarke stationary point.
We now consider a minimization problem involving a Lipschitz objective function
and a set constraint, i.e. a problem of the type (P2).
(P2) :
min f (x), x âˆˆC âŠ‚X âŠ‚Rn,
where f : X â†’R is a locally Lipschitz function on the open set X and C is an
arbitrary subset of X. The following result is given in [48].
Theorem 10.57 Consider the above problem (P2). If x0 âˆˆC is a local minimum
point of f over C, then
f o(x0; v) â‰§0, âˆ€v âˆˆT (C, x0),
(10.32)
where T (C, x0) is the Bouligand tangent cone to C at x0.
Proof If v = 0, the result is trivially true. Let us now consider the case where v Ì¸= 0
and v âˆˆT (C, x0). By the deï¬nition of the Bouligand tangent cone, we can ï¬nd a
sequence {xn} in C and a sequence of scalars {tn} > 0, with xn â†’x0, tn â†’0, such
that vn = xnâˆ’x0
tn
â†’v, and so xn = x0 + tnvn.
Hence

356
10
Introduction to Nonsmooth Optimization Problems
f

x0 + tnv

âˆ’f (x0)
tn
= f

x0 + tnv

âˆ’f (xn)
tn
+ f (xn) âˆ’f (x0)
tn
,
(10.33)
Since f is locally Lipschitz, we have
| f

x0 + tnv

âˆ’f (xn)|
tn
â‰¦k
x0 + tnv âˆ’(x0 + tnvn)

tn
= k
vn âˆ’v
 â†’0,
where k is the Lipschitz constant. Hence,
f

x0 + tnv

âˆ’f (xn)
tn
â†’0.
Again we have f (xn) â‰§f (x0). Hence, from the equality (10.33), it follows that
lim sup
nâ†’âˆ
f

x0 + tnv

âˆ’f (x0)
tn
â‰§0.
From the deï¬nition of the Clarke directional derivative, we see that
f o(x0; v) â‰§lim sup
nâ†’âˆ
f

x0 + tnv

âˆ’f (x0)
tn
.
This shows that f o(x0; v) â‰§0. Since v âˆˆT (C, x0) is arbitrary, the result is
proved.
â–¡
Remark 10.58 In order to obtain the dual relation of (10.32) expressed by means of
the Clarke subdifferential, as shown by [48], we have to consider a convex subcone
of the Bouligand tangent cone T (C, x0). More precisely:
â€¢ Let x0 âˆˆC be a local minimum point for problem (P2) and let T1(C, x0) be a
nonempty closed convex subcone of T (C, x0). Then we have
0 âˆˆâˆ‚o f (x0) + (T1(C, x0))âˆ—,
where (T1(C, x0))âˆ—denotes, as usual, the polar cone of T1(C, x0).
If we choose T1(C, x0) = T o(C, x0), we obtain the necessary optimality condition
for (P2) given in [21] with a different proof, i.e.
0 âˆˆâˆ‚o f (x0) + N o(C, x0).
Under the same assumptions of Theorem 10.57 ( f locally Lipschitz on X), we
can obtain
f D(x0; v) â‰§0, âˆ€v âˆˆT (C, x0).

10.2 The Lipschitz Case
357
See [49]. Being f o(x0; Â·) â‰§f D(x0; Â·), we have that the above condition is sharper
than condition (10.28). Note that, contrary to what asserted in [49], it is not true the
following necessary optimality condition
fD(x0; v) â‰§0, âˆ€v âˆˆT (C, x0).
Indeed, consider the following counterexample: let C = {2âˆ’n : n = 1, 2, . . . } and
f : R â†’R deï¬ned by f (x) = âˆ’dC(x). One has that f is Lipschitz and x0 = 0 is a
minimum for f over C, however, fD(x0; v) = âˆ’1/3 < 0 for v = 1 âˆˆT (C, x0).
Now we wish to give Fritz John-type optimality conditions for a constrained
problem of the type (P4).
(P4) :
â§
â¨
â©
min f (x)
subject to: gi(x) â‰¦0, i = 1, . . . , m,
x âˆˆX âŠ‚Rn,
where the objective function f and the constraint functions gi, i = 1, . . . , m, are
supposed to be locally Lipschitz on the open set X. Let us denote by K4 the feasible
set of (P4). We follow the treatment of [23]. Without loss of generality, we can
scalarize the multiple constraints of (P4) by introducing the total constraint function
g : X â†’R deï¬ned by
g(x) = max {gi(x), i = 1, . . . , m} .
We need the following result.
Theorem 10.59 Let be f (x) = max { f1(x), . . . , fm(x)} , where each fi : X âŠ‚Rn
â†’R, i = 1, . . . , m, is locally Lipschitz on the open set X. Then f is locally Lipschitz
on X and
âˆ‚o f (x) âŠ‚conv

âˆ‚o fi(x), i âˆˆË†I(x)

, âˆ€x âˆˆX,
where Ë†I(x) = {i âˆˆ{1, . . . , m} : fi(x) = f (x)} .
Proof Deï¬ne g : Rm â†’R and h : X â†’Rm by
g(u) = max
i=1,...,m {ui} , u âˆˆRm,
h(x) = ( f1(x), . . . , fm(x)) .
Now we have f = g â—¦h. For all u, v âˆˆRm and Î» âˆˆ[0, 1] it holds
g(Î»u + (1 âˆ’Î»)v) =
max
i=1,...,m {Î»ui + (1 âˆ’Î»)vi}
â‰¦Î» max
i=1,...,m {ui} + (1 âˆ’Î») max
i=1,...,m {vi}
= Î»g(u) + (1 âˆ’Î»)g(v),

358
10
Introduction to Nonsmooth Optimization Problems
which means that g is convex on Rm and hence locally Lipschitz on Rm (Theorem
10.29). Therefore, f = g â—¦h is locally Lipschitz on X as can be easily checked. Let
be J(u) = {i âˆˆ{1, . . . , m} : ui = g(u)} . Then the directional derivative of g is
gâ€²(u; v) = lim
tâ†’0+
g(u + tv) âˆ’g(u)
t
= lim
tâ†’0+
max
i=1,...,m
{ui + tvi} âˆ’g(u)
t
= lim
tâ†’0+ max
iâˆˆJ(u)
{ui + tvi} âˆ’g(u)
t
= lim
tâ†’0+ max
iâˆˆJ(u)
{ui + tvi âˆ’ui}
t
.
Thus,
gâ€²(u; v) = max
iâˆˆJ(u)vi.
Being g convex, it is also Clarke regular (Theorem 10.43) and therefore we have
go = gâ€², which gives
âˆ‚og(u) =

Î± âˆˆRm : max
iâˆˆJ(u)vi â‰§Î±âŠ¤v, âˆ€v âˆˆRm

.
Now it is not hard to see that
Î± âˆˆâˆ‚og(u) â‡”
â§
â¨
â©
Î±i â‰§0, i = 1, . . . , m;
m
i=1 Î±i = 1;
Î±i = 0, when i /âˆˆJ(u),
and so we can calculate the Clarke subdifferential of g at h(x) âˆˆRm by
âˆ‚og(h(x)) =

Î± âˆˆRm : Î±i â‰§0,
m

i=1
Î±i = 1 and Î±i = 0 if i /âˆˆË†I(x)

.
By applying Theorem 10.50 to f , we get
âˆ‚o f (x) âŠ‚conv
 m

i=1
Î±iÎ¾ i : Î¾ i âˆˆâˆ‚ohi(x) and Î± âˆˆâˆ‚og(h(x))

= conv
â§
â¨
â©

iâˆˆË†I(x)
Î±iâˆ‚o fi(x) : Î±i â‰§0 and

iâˆˆË†I(x)
Î±i = 1
â«
â¬
â­
= conv

âˆ‚o fi(x) : i âˆˆË†I(x)

.
â–¡

10.2 The Lipschitz Case
359
Remark 10.60 In Theorem 10.59 if, in addition fi is Clarke regular at x for all
i = 1, . . . , m, then f is also Clarke regular at x and it can be proved that the inclusion
of the thesis of the same theorem holds as equality.
We are now ready to prove for (P4) a Fritz John-type necessary optimality con-
dition, expressed by means of Clarke subdifferentials.
Theorem 10.61 Let x0 be a local minimum point for (P4). Then, there exist multi-
pliers Î»i â‰§0, i = 0, 1, . . . , m, not all zero, such that
0 âˆˆÎ»0âˆ‚o f (x0) +
m

i=1
Î»iâˆ‚ogi(x0),
Î»igi(x0) = 0, i = 1, . . . , m.
Proof It is clear that the function h : X â†’R deï¬ned by
h(x) = max

f (x) âˆ’f (x0), g(x)

is locally Lipschitz on X by Theorem 10.59. Since x0 âˆˆK4 is a local minimizer for
(P4), there exists Î´ > 0 such that U(x0, Î´) âŠ‚X and
f (x0) â‰¦f (x), âˆ€x âˆˆK4 âˆ©U(x0, Î´),
Since x0 âˆˆK4, we have g(x0) â‰¦0, implying
h(x0) = max

f (x) âˆ’f (x0), g(x)

= 0.
Moreover,
h(x) = max

f (x) âˆ’f (x0), g(x)

â‰§h(x0) = 0, âˆ€x âˆˆX âˆ©U(x0, Î´).
because if x âˆˆK4, then g(x) â‰¦0 and f (x) âˆ’f (x0) â‰§0, and if x âˆˆU(x0, Î´) \ K4,
then g(x) > 0, and so h(x) > 0. In other words, h(x) attains a local minimum at
x0 âˆˆint X. Then, due to Theorem 10.56, we have
0 âˆˆâˆ‚oh(x0).
If g(x0) < 0, we have g(x0) < f (x0) âˆ’f (x0) and thus, due to Theorem 10.59,
we get
0 âˆˆâˆ‚oh(x0) âŠ‚âˆ‚o f (x0).
Then the assertion of the theorem is proved by choosing Î»0 = 1 and Î»i = 0 for
i = 1, . . . , m. On the other hand, if g(x0) = 0, we have g(x0) = f (x0) âˆ’f (x0) and
thus, again by Theorem 10.59, we get

360
10
Introduction to Nonsmooth Optimization Problems
0 âˆˆâˆ‚oh(x0) âŠ‚conv

âˆ‚0 f (x0) âˆªâˆ‚og(x0)

.
Furthermore, we have
âˆ‚og(x0) âŠ‚conv

âˆ‚ogi(x0), i âˆˆË†I(x0)

,
where Ë†I(x0) =

i âˆˆ{1, . . . , m} : gi(x0) = g(x0)

. Then, due to the deï¬nition of
convex hull, there exist Î»0 â‰§0 and Î»i â‰§0 for i âˆˆË†I(x0), Î»0 and Î»i not all zero, such
that Î»igi(x0) = 0 for i âˆˆË†I(x0) (since gi(x0) = 0) and
0 âˆˆÎ»0âˆ‚o f (x0) +

iâˆˆË†I(x0)
Î»iâˆ‚ogi(x0).
The assertion of the theorem is now proved by choosing Î»i = 0 for i /âˆˆË†I(x0). â–¡
We now prove for (P4) the Karush-Kuhn-Tucker-type necessary optimality con-
ditions. As usual, to avoid the case Î»0 = 0 in the Fritz John conditions, we need a
constraint qualiï¬cation. Let us consider problem (P4), under the same assumptions
as before.
Theorem 10.62 Let x0 âˆˆK4 be a local minimum point for (P4) and assume that
the following Arrow-Hurwicz-Uzawa constraint qualiï¬cation or Cottle constraint
qualiï¬cation is fulï¬lled:
â€¢ There exists v âˆˆRn such that go
i (x0; v) < 0, âˆ€i âˆˆI (x0) = {i : gi(x0) = 0}.
Then, there exist scalars Î»i â‰§0, i = 1, . . . , m, such that
(i) 0 âˆˆâˆ‚o f (x0) + m
i=1 Î»iâˆ‚ogi(x0);
(ii) Î»igi(x0) = 0, i = 1, . . . , m.
Proof It is sufï¬cient to show that under the above constraint qualiï¬cation, in the
Fritz John conditions of Theorem 10.61, it holds Î»0 Ì¸= 0 (and hence Î»0 = 1). Let us
assume on the contrary that Î»0 = 0. We have therefore
0 âˆˆ

iâˆˆI (x0)
Î»iâˆ‚ogi(x0).
Since Î»0 = 0 and the multipliers Î»i, i âˆˆI (x0), are not all equal to zero, there will
exist at least one i âˆˆI (x0) such that Î»i > 0. Also as 0 âˆˆ
iâˆˆI (x0) Î»iâˆ‚ogi(x0), we
see that there exists Î¾ i âˆˆâˆ‚ogi(x0), i âˆˆI (x0), such that 
iâˆˆI (x0) Î»iÎ¾ i = 0. Hence,
for any v âˆˆRn, we have (
iâˆˆI (x0) Î»iÎ¾ i)âŠ¤v = 0. By assumptions of the theorem,
there exists Â¯v âˆˆRn such that go
i (x0; Â¯v) < 0, i âˆˆI (x0). Hence, from the deï¬nition
of the Clarke subdifferential, we see that (Î¾ i)âŠ¤Â¯v < 0, i âˆˆI (x0). Again, as there
exists i âˆˆI (x0) such that Î»i > 0, we have (
iâˆˆI (x0) Î»iÎ¾ i)âŠ¤Â¯v < 0, which is clearly

10.2 The Lipschitz Case
361
a contradiction. Hence, we conclude that Î»0 Ì¸= 0 and without loss of generality we
can take Î»0 = 1. Putting Î»i = 0, âˆ€i /âˆˆI (x0), we get the thesis.
â–¡
Remark 10.63 Hiriart-Urruty [50] has obtained for (P4) â€œsharperâ€ Fritz John and
Karush-Kuhn-Tucker necessary optimality conditions, in the sense that this author
obtains the following necessary optimality conditions, expressed in terms of the
Clarke subdifferential of the Lagrangian function (recall Theorem 10.47):
0 âˆˆâˆ‚o

Î»0 f +
m

i=1
Î»igi

(x0);
0 âˆˆâˆ‚o

f +
m

i=1
Î»igi

(x0).
Clarke [20] has obtained a Fritz John-type necessary optimality theorem for a
problem of the type (P5), but with also a set constraint, i.e. for the problem
(P6) :
â§
âªâªâ¨
âªâªâ©
min f (x)
subject to: gi(x) â‰¦0, i = 1, . . . , m,
h j(x) = 0, j = 1, . . . , p < n,
x âˆˆC âŠ‚X âŠ‚Rn,
where C is an arbitrary subset of the open set X âŠ‚Rn and all functions are locally
Lipschitz at the local minimum point x0 of (P6). Clarke uses rather sophisticated
tools, such as the Ekeland variational principle (see [51, 52]). We report the result
of Clarke without proof.
Theorem 10.64 Let x0 be a local solution of (P6). Then there exist multipliers, not
all zero, u0, u1, . . . , um, v1, . . . , vp, such that
0 âˆˆu0âˆ‚o f (x0) +
m

i=1
uiâˆ‚ogi(x0) +
p

j=1
v jâˆ‚oh j(x0) + N o(C, x0);
uigi(x0) = 0, i = 1, . . . , m;
u0 â‰§0, ui â‰§0, i = 1, . . . , m.
Under appropriate constraint qualiï¬cations, it is possible to choose, in the above
Fritz John optimality conditions, u0 = 1. In other words, there exists then a set of
multipliers (u1, . . . , um, v1, . . . , vp) âˆˆRm+p such that the following Karush-Kuhn-
Tucker conditions hold for (P6) :
0 âˆˆâˆ‚o f (x0) +
m

i=1
uiâˆ‚ogi(x0) +
p

j=1
v jâˆ‚oh j(x0) + N o(C, x0);

362
10
Introduction to Nonsmooth Optimization Problems
uigi(x0) = 0, i = 1, . . . , m;
ui â‰§0, i = 1, . . . , m.
Nguyen et al. [53] consider problem (P6), but with the assumption that the functions
h j(x), j = 1, . . . , p, are continuously differentiable on X. These authors impose
the following constraint qualiï¬cation for (P6) at the optimal point x0.
â€¢ (C Q) : The gradients âˆ‡h j(x0), j = 1, . . . , p, are linearly independent and there
exists y0 âˆˆint(T o(C, x0)) such that go
i (x0; y0) < 0, âˆ€i âˆˆI (x0) and âˆ‡h j(x0)âŠ¤
y0 = 0, âˆ€j = 1, . . . , p.
Under the assumptions of Nguyen, Strodiot, and Mifï¬‚in, the Karush-Kuhn-Tucker
conditions for (P6) become
0 âˆˆâˆ‚o f (x0) +
m

i=1
uiâˆ‚ogi(x0) +
p

j=1
v jâˆ‡h j(x0) + N o(C, x0);
uigi(x0) = 0, i = 1, . . . , m;
ui â‰§0, i = 1, . . . , m
Let us denote by (x0) âˆˆRm+p the set of multipliers (ui, v j), i = 1, . . . , m;
j = 1, . . . , p, which satisfy the above Karush-Kuhn-Tucker-type optimality con-
ditions. The quoted authors prove that if int(T o(C, x0)) Ì¸= âˆ…, the condition (C Q),
besides assuring the satisfaction of the above necessary KKT conditions for local
optimality of the feasible point x0 in the problem considered, is both necessary and
sufï¬cient, for (x0) to be a nonempty closed, convex, and bounded set. Hence, the
above constraint qualiï¬cation can be viewed as a nonsmooth generalization of the
Mangasarian-Fromovitz constraint qualiï¬cation, given for the differentiable case. If
there are no equality constraints, then in (C Q) it is possible to replace int(T o(C, x0))
by T o(C, x0) and to delete the assumption that int(T o(C, x0)) Ì¸= âˆ…. Note that if C
is open or x0 âˆˆint(C), then T o(C, x0) = Rn and N 0(C, x0) = {0} .
We have mentioned in Chap. 6 the â€œenhanced Fritz John conditionsâ€ of [54] for
a continuously differentiable optimization problem with mixed constraints and a set
constraint. In [37] it has been obtained the enhanced Fritz John conditions for a
problem of the type (P6), with C an arbitrary convex subset of the open set X âŠ‚Rn.
We report their result, without proof.
Theorem 10.65 Let us consider problem (P6), where C is a convex subset of the
open set X âŠ‚Rn and where all functions are locally Lipschitz at x0, with x0 local
solution of the problem. Then, there exist scalars u0 â‰§0, u1 â‰§0, . . . , um â‰§0, v1 âˆˆ
R,. . . , vp âˆˆR, not all zero, such that
(i) 0 âˆˆu0âˆ‚o f (x0) + m
i=1 uiâˆ‚ogi(x0) + p
j=1 v jâˆ‚oh j(x0) + N(C, x0);

10.2 The Lipschitz Case
363
(ii) Consider the index sets I = {i : i Ì¸= 0, ui > 0} and J =

j : v j Ì¸= 0

. If I âˆª
J Ì¸= âˆ…, then there exists a sequence

xk
âŠ‚C such that xk â†’x0 and such that
for all k sufï¬ciently large we have f (xk) < f (x0), v jh j(xk) > 0 for all j âˆˆJ
and uigi(xk) > 0 for all i âˆˆI. We have also
h j(xk)
 = o(w(xk)), âˆ€j /âˆˆJ;
gi(xk)
 = o(w(xk)), âˆ€i /âˆˆI,
where
w(x) = min

min
iâˆˆI
g+
i (x)
 , min
jâˆˆJ
h j(x)


and g+
i (x) = max {gi(x), 0} .
We conclude the present section with some considerations on generalized convex
functions under a Lipschitz assumption. Pseudoconvex and quasiconvex functions
(see Chap. 3) have been extended by various authors to the Lipschitz case; see [23,
37, 55, 56]. See also the useful handbook [57], in particular the contributions of N.
Hadjisavvas and S. Komlosi.
We recall that a differentiable function f : X â†’R is pseudoconvex on the open
convex set X âŠ‚Rn if, with x, y âˆˆX, we have
(y âˆ’x)âŠ¤âˆ‡f (x) â‰§0 â‡’f (y) â‰§f (x).
The function f is quasiconvex on X if, with x, y âˆˆX, we have
f (y) â‰¦f (x) â‡’(y âˆ’x)âŠ¤âˆ‡f (x) â‰¦0.
If f is locally Lipschitz on the open convex set X âŠ‚Rn, but not necessarily
differentiable, the most natural generalizations of the previous traditional deï¬nitions
are given as follows.
Deï¬nition 10.66 Let f : X â†’R be a locally Lipschitz function on the open convex
set X âŠ‚Rn. Then f is said to be Clarke pseudoconvex on X if, with x, y âˆˆX, we
have
f o(x; y âˆ’x) â‰§0 â‡’f (y) â‰§f (x)
or, equivalently,
f (y) < f (x) â‡’f o(x; y âˆ’x) < 0.
Remark 10.67 The previous characterization can be given also in the form: with
x, y âˆˆX we have

Î¾ âŠ¤(y âˆ’x) â‰§0 for some Î¾ âˆˆâˆ‚o f (x)

â‡’f (y) â‰§f (x),

364
10
Introduction to Nonsmooth Optimization Problems
or
f (y) < f (x) â‡’

Î¾ âŠ¤(y âˆ’x) < 0, âˆ€Î¾ âˆˆâˆ‚o f (x)

.
Deï¬nition 10.68 Let f : X â†’R be a locally Lipschitz function on the open convex
set X âŠ‚Rn. Then f is said to be Clarke quasiconvex on X if, with x, y âˆˆX, we
have
f (y) â‰¦f (x) â‡’f o(x; y âˆ’x) â‰¦0
or, equivalently,
f o(x; y âˆ’x) > 0 â‡’f (y) > f (x).
Remark 10.69 The previous characterization can be given also in the form: with
x, y âˆˆX we have
f (y) â‰¦f (x) â‡’

Î¾ âŠ¤(y âˆ’x) â‰¦0, âˆ€Î¾ âˆˆâˆ‚o f (x)

,
or

Î¾ âŠ¤(y âˆ’x) > 0 for some Î¾ âˆˆâˆ‚o f (x)

â‡’f (y) > f (x).
Bector et al. [37] prove the following two results. We recall that the original deï¬nition
of a quasiconvex function does not require any differentiability assumption (see
Deï¬nition 3.18).
Theorem 10.70 Let f : X â†’R be locally Lipschitz on the open convex set X âŠ‚Rn.
Then f is quasiconvex on X if and only if, with x, y âˆˆX, we have
f (y) < f (x) â‡’

Î¾ âŠ¤(y âˆ’x) â‰¦0, âˆ€Î¾ âˆˆâˆ‚o f (x)

.
The immediate consequence of the above theorem is that both Clarke pseudo-
convex functions and Clarke quasiconvex functions are quasiconvex functions in the
usual sense.
Theorem 10.71 Let f : X â†’R be locally Lipschitz on the open convex set X âŠ‚Rn
and let f be regular (in the sense of Clarke) and quasiconvex on X. Then f is Clarke
quasiconvex on X.
The notion of Clarke pseudoconvexity allows to obtain sufï¬cient optimality con-
ditions for an unconstrained minimization problem involving a locally Lipschitz
function.
Theorem 10.72 If the function f : X â†’R is Clarke pseudoconvex on the open
convex set X âŠ‚Rn, then f attains its global minimum at x0 âˆˆX if and only if
0 âˆˆâˆ‚o f (x0).

10.2 The Lipschitz Case
365
Proof The necessity has already been proved (Theorem 10.56). On the other hand,
if 0 âˆˆâˆ‚o f (x0) and y âˆˆX, by deï¬nition of Clarke pseudoconvexity we have
f o(x0; y âˆ’x0) â‰§0âŠ¤(y âˆ’x0) = 0 â‡’f (y) â‰§f (x0).
â–¡
Example 10.73 ([23]) The function f : R â†’R deï¬ned by f (x) = min
|x| , x2
is
locally Lipschitz, but not convex nor pseudoconvex (it is not everywhere differen-
tiable). However, f is Clarke pseudoconvex and at its global minimum point x0 = 0,
we have âˆ‚o f (x0) = {0} .
It is also possible to give sufï¬cient optimality conditions for a problem of the type
(P2), i.e. with a set constraint, by means of Clarke generalized convex functions. It
is not difï¬cult to prove the following result.
Theorem 10.74 If f : X â†’R is Clarke pseudoconvex on the open convex set X âŠ‚
Rn, and C is an arbitrary convex subset of X, then x0 âˆˆC is a solution of the problem
min f (x) subject to x âˆˆC,
if and only if
0 âˆˆâˆ‚o f (x0) + N o(C, x).
We recall that, being C convex, we have N o(C, x) = N(C, x).
For sufï¬cient Karush-Kuhn-Tucker conditions in terms of Clarke generalized
derivatives or Clarke subdifferentials, see, e.g. [23, 58, 59].
Finally, we give some insight into the generalization to the Lipschitz case of
the notion of invex functions. We recall (see Deï¬nition 3.33) that invex functions
were introduced by [60] as a generalization of differentiable convex functions: let
X âŠ‚Rn be an open set and let f : X â†’R be differentiable on X; if there exists
a vector-valued function, called also â€œthe kernel functionâ€, Î·(x, y) : X Ã— X â†’Rn
such that
f (y) âˆ’f (x) â‰§Î·(x, y)âŠ¤âˆ‡f (x), âˆ€x, y âˆˆX,
then f is called invex.
The deï¬nition of invexity can be extended to a function f : X â†’R, X open
subset of Rn, f locally Lipschitz on X.
Deï¬nition 10.75 A locally Lipschitz function f : X â†’R is Clarke invex on the
open set X âŠ‚Rn if there exists a vector-valued function Î·(x, y) : X Ã— X â†’Rn
such that
f (y) âˆ’f (x) â‰§f o(x; Î·(x, y)), âˆ€x, y âˆˆX,
that is, equivalently if
f (y) âˆ’f (x) â‰§Î¾ âŠ¤Î·(x, y), âˆ€Î¾ âˆˆâˆ‚o f (x), âˆ€x, y âˆˆX.

366
10
Introduction to Nonsmooth Optimization Problems
We have seen that if f : X â†’R is a locally Lipschitz function on the open set
X âŠ‚Rn and x0 âˆˆX is a local minimum or also a local maximum point of f over
X, then x0 is a Clarke stationary point, i.e.
0 âˆˆâˆ‚o f (x0).
The following result gives a characterization of Clarke invex functions, similar to
the one given in Theorem 4.20 for differentiable functions.
Theorem 10.76 Let f : X â†’R be locally Lipschitz on the open set X âŠ‚Rn; then
f is Clarke invex on X if and only if every Clarke stationary point x0 âˆˆX is a global
minimum point of f over X.
Proof First, assume that every Clarke stationary point x0 âˆˆX is a global minimum
point of f over X. Let us consider the following two cases.
(1) If x1, x2 âˆˆX are points such that f (x2) â‰§f (x1), it is sufï¬cient to choose
Î·(x1, x2) = 0.
(2) If x1, x2 âˆˆX are points such that f (x2) < f (x1), then x1 cannot be a Clarke
stationary point and hence there exists a direction y(x1, x2) âˆˆRn such that
f o(x1; y(x1, x2)) < 0.
Deï¬ne the function
Î·(x1, x2) =
f (x2) âˆ’f (x1)
f o(x1; y(x1, x2)) y(x1, x2).
Then we have
f o(x1; Î·(x1, x2)) =
f (x2) âˆ’f (x1)
f o(x1; y(x1, x2)) f o(x1; y(x1, x2)) = f (x2) âˆ’f (x1).
Therefore, f is Clarke invex with respect to
Î·(x1, x2) =

0,
if f (x2) â‰§f (x1)
f (x2)âˆ’f (x1)
f o(x1;y(x1,x2)) y(x1, x2), if f (x2) < f (x1).
The vice versa is quite immediate: if f is invex, then 0 âˆˆâˆ‚o f (x0) implies f (x0) â‰¦
f (x), âˆ€x âˆˆX.
â–¡
Theabovetheoremhasbeenprovedby[58],however,underasuperï¬‚uousassump-
tion. See also the related papers of [61â€“65].
Clarke invex functions have been used also to obtain sufï¬cient Karush-Kuhn-
Tucker conditions for an optimization problem with inequality constraints. See, e.g.
[58, 59]. For this type of problems in [66] it has been obtained, by using a class

10.3 The Axiomatic Approach of K.-H. Elster and J. Thierfelder â€¦
367
of functions more general than Clarke invex functions, saddle points conditions and
also some duality results. Consider the problem
(P4) :
â§
â¨
â©
min f (x)
subject to: gi(x) â‰¦0, i = 1, . . . , m,
x âˆˆX âŠ‚Rn,
X open set, f : X â†’R and every gi : X â†’R,i = 1, . . . , m, locally Lipschitz on X.
Theorem 10.77 Let x0 be feasible for (P4). If the objective function f is Clarke
invex, with respect to a kernel function Î·(Â·, Â·), and every gi, i = 1, . . . , m, is Clarke
invex, with respect to the same function Î·(Â·, Â·), and the conditions
(a) 0 âˆˆâˆ‚o f (x0) + m
i=1 Î»0
i âˆ‚ogi(x0);
(b) Î»0
i gi(x0) = 0, i = 1, . . . , m;
(c) Î»0
i â‰§0, i = 1, . . . , m,
hold at x0, then x0 is a solution of (P4) and (x0, Î»0) is a saddle point of the
Lagrangian function L (x, Î») :
L (x0, Î») â‰¦L (x0, Î»0) â‰¦L (x, Î»0), âˆ€x âˆˆX, âˆ€Î» âˆˆRm
+.
Conversely,assumethat x0 isasolutionof(P4),that f andevery gi,i = 1, . . . , m,
are Clarke invex with respect to the same kernel function Î·(Â·, Â·), and that an appro-
priate constraint qualiï¬cation holds (e.g. the Cottle c. q. of Theorem 10.62). Then,
the Karush-Kuhn-Tucker conditions (a), (b), and (c) hold and the pair (x0, Î»0) is a
saddle point of the Lagrangian function L (x, Î»).
10.3
The Axiomatic Approach of K.-H. Elster and
J. Thierfelder to Nonsmooth Optimization
As we have previously mentioned, starting from the 60s and 70s of the last century,
several mathematicians have studied the possibility to generalize the classical con-
cepts of differentiability (GÃ¢teaux, FrÃ©chet, Hadamard, etc.) in order to treat problems
described by nonsmooth functions. Besides the approaches of Rockafellar to convex
functions and of Clarke to locally Lipschitz functions, it is worth mentioning the
approaches of [4, 13, 47, 67â€“70] that will not be treated in the present book.
The variety of the various approaches, proposed to study nonsmooth functions and
nonsmooth optimization problems, has led to deï¬ne axiomatic constructions which
include, as particular cases, several of the said above approaches. We brieï¬‚y examine
the axiomatic approach of [7â€“10], but we point out also the interesting approaches
of [71â€“73].
The approach of Elster and Thierfelder is based on an axiomatic deï¬nition of
local cone approximation of a set at a point. In some previous chapters and also in

368
10
Introduction to Nonsmooth Optimization Problems
the present chapter we have introduced and used various local cone approximations.
Elster and Thierfelder give the following general axiomatic deï¬nition (they consider
a locally convex Hausdorff space, but we continue to consider the Euclidean space
Rn). See also the papers of [40, 74â€“77].
Deï¬nition 10.78 A map K : 2Rn Ã— Rn â†’2Rn is a local cone approximation if for
each set S âŠ‚Rn and each point x0 âˆˆRn a cone K(S, x0) is associated such that the
following properties are fulï¬lled:
1. K(S, x0) = K(S âˆ’x0, 0);
2. K(S âˆ©N(x0, Îµ), x0) = K(S, x0), âˆ€Îµ > 0;
3. K(S, x0) = âˆ…, âˆ€x0 /âˆˆcl(S);
4. K(S, x0) = Rn, âˆ€x0 âˆˆint(S);
5. K(Ï•(S), Ï•(x0)) = Ï•(K(S, x0)), for any linear homeomorphism Ï• : Rn â†’Rn;
6. 0+S âŠ‚0+K(S, x0), âˆ€x0 âˆˆcl(S), where
0+S =

y âˆˆRn : a + ty âˆˆS, âˆ€t > 0, âˆ€a âˆˆS

is the recession cone of S (see [2]). Moreover, we set 0+âˆ…= Rn.
Theorem 10.79 The axioms 1â€“6 are independent, i.e. for each axiom there exists a
map K(Â·, Â·) which fails exactly the said axiom and satisï¬es the remaining axioms.
Almost all local cone approximations used in optimization theory verify the pre-
vious axioms. We give below a list of the most used local cone approximations which
are a particular case of the axiomatic deï¬nition described above (some of these cones
have already been presented and used in the previous chapters). We adopt the various
descriptions in terms of neighborhoods.
Deï¬nition 10.80 Let be S âŠ‚Rn and x0 âˆˆRn.
â€¢ The cone
F(S, x0) =

y âˆˆRn : âˆƒÎ´ > 0, âˆ€t âˆˆ(0, Î´) : x0 + ty âˆˆS

is called cone of feasible directions to S at x0.
â€¢ The cone
WF(S, x0) =

y âˆˆRn : âˆ€Î´ > 0, âˆƒt âˆˆ(0, Î´) : x0 + ty âˆˆS

is called cone of weakly feasible directions or radial tangent cone to S at x0.
â€¢ The cone
T (S, x0) =

y âˆˆRn : âˆ€Î´ > 0 âˆƒÂ¯y âˆˆN(y, Î´), âˆƒt âˆˆ(0, Î´) : x0 + t Â¯y âˆˆS

is called Bouligand tangent cone or contingent cone to S at x0.

10.3 The Axiomatic Approach of K.-H. Elster and J. Thierfelder â€¦
369
â€¢ The cone
I (S, x0) =

y âˆˆRn : âˆƒÎ´ > 0, âˆ€Â¯y âˆˆN(y, Î´), âˆ€t âˆˆ(0, Î´) : x0 + t Â¯y âˆˆS

is called cone of interior directions or cone of interior displacements to S at x0.
â€¢ The cone
A(S, x0) =

y âˆˆRn : âˆ€N(y) âˆƒÎ» > 0, âˆ€t âˆˆ(0, Î») âˆƒÂ¯y âˆˆN(y) : x0 + t Â¯y âˆˆS

is called cone of attainable directions or Kuhn-Tucker tangent cone or Ursescu
tangent cone [78] to S at x0.
â€¢ The cone
Q(S, x0) =

y âˆˆRn : âˆƒN(y), âˆ€Î» > 0, âˆƒt âˆˆ(0, Î»), âˆ€Â¯y âˆˆN(y) : x0 + t Â¯y âˆˆS

is called cone of quasi-interior directions to S at x0.
â€¢ The cone
T o(S, x0) =
 y âˆˆRn : âˆ€N(y), âˆƒN(x0), âˆƒÎ» > 0, âˆ€t âˆˆ(0, Î»),
âˆ€Â¯x âˆˆN(x0) âˆ©S âˆª

x0
, âˆƒÂ¯y âˆˆN(y) : Â¯x + t Â¯y âˆˆS

is called Clarke tangent cone to S at x0.
â€¢ The cone
H(S, x0) =
 y âˆˆRn : âˆƒN(x0), âˆƒÎ» > 0, âˆ€t âˆˆ(0, Î»),
âˆ€Â¯x âˆˆN(x0) âˆ©S âˆª

x0
: Â¯x + ty âˆˆS

is called Rockafellar hypertangent cone to S at x0.
â€¢ The cone
E(S, x0) =
 y âˆˆRn : âˆƒN(y), âˆƒN(x0), âˆƒÎ» > 0, âˆ€t âˆˆ(0, Î»),
âˆ€Â¯x âˆˆN(x0) âˆ©S âˆª

x0
, âˆ€Â¯y âˆˆN(y) : Â¯x + t Â¯y âˆˆS

is called cone of epi-Lipschitzian directions to S at x0
Remark 10.81 The descriptions of the cones T o(S, x0), H(S, x0) and E(S, x0)
are slightly different from the original deï¬nitions (see, e.g. [79]), where the point
Â¯x belongs to the set S âˆ©N(x0). The present description, taken from [7â€“9], allows
to verify the third axiom of Deï¬nition 10.78. However, the consideration of the set
S âˆ©N(x0) âˆª

x0
does not involve the original behavior of the map. More precisely,
in [38] it has been shown that if x0 âˆˆcl(S), the descriptions given in Deï¬nition 10.80
for T o(S, x0), H(S, x0) and E(S, x0) coincide with the original deï¬nitions.
For a quick overview of the main properties of the cones previously deï¬ned, it is
useful in the following scheme.

370
10
Introduction to Nonsmooth Optimization Problems
E(S, x0) âŠ‚I (S, x0) âŠ‚Q(S, x0)
âˆ©
âˆ©
âˆ©
H(S, x0) âŠ‚F(S, x0) âŠ‚WF(S, x0)
âˆ©
âˆ©
âˆ©
T o(S, x0) âŠ‚A(S, x0) âŠ‚T (S, x0)
With regard to this scheme, the following assertions hold true.
â€¢ The cones of the ï¬rst row are open and it holds
x0 âˆˆint(S) â‡”0 âˆˆK(S, x0).
The cones of the third row are closed and it holds
x0 âˆˆcl(S) â‡”0 âˆˆK(S, x0).
The cones of the second row verify the property
x0 âˆˆS â‡”0 âˆˆK(S, x0).
â€¢ The cones of the ï¬rst column are convex; the cones of the second and third column
are isotone, i.e.
S1 âŠ‚S2 =â‡’K(S1, x0) âŠ‚K(S2, x0), âˆ€x0 âˆˆRn.
By means of the axiomatic characterization of a local cone approximation, always
following [8, 9], but see also [75, 76], it is possible to give the following deï¬nition
of generalized directional derivative.
Deï¬nition 10.82 Let be f : Rn â†’[âˆ’âˆ, +âˆ], x0 âˆˆRn such that
 f (x0)
 < +âˆ
and K(Â·, Â·) a local cone approximation, according to Deï¬nition 10.78. Then the
function f K(x0; Â·) : Rn â†’[âˆ’âˆ, +âˆ] deï¬ned by
f K(x0; y) = inf

Î² âˆˆR : (y, Î²) âˆˆK(epi( f ), (x0, f (x0)))

, âˆ€y âˆˆRn,
is called the K-directional derivative of f at x0. It is assumed inf(âˆ…) = +âˆ.
It is worth noting that in [80] it was perhaps noticed by ï¬rst time the connection
between the Dini directional derivatives and an appropriate local cone approximation
of the epigraph of f at (x0, f (x0)). It is quite immediate to remark that f K(x0; Â·) is
positively homogeneous. Moreover, it can be proved that the topological properties
of the local cone approximation K(Â·, Â·) are reï¬‚ected on the K-directional derivatives,
as described in the following theorem, given in [9].

10.3 The Axiomatic Approach of K.-H. Elster and J. Thierfelder â€¦
371
Theorem 10.83 Let be f : Rn â†’R, x0 âˆˆRn and K(Â·, Â·) a local cone approxima-
tion. Then:
(i) If K(epi( f ), (x0, f (x0))) is convex, then f K(x0; Â·) is sublinear.
(ii) It holds
epi( f K (x0; Â·)) =

(y, Î²) âˆˆRn Ã— R : âˆ€Îµ > 0, (y, Î² + Îµ) âˆˆK(epi( f ), (x0, f (x0)))

.
In particular, if K(epi( f ), (x0, f (x0))) is closed, it holds
epi( f K(x0; Â·)) = K(epi( f ), (x0, f (x0)))
and f K(x0; Â·) is lower semicontinuous.
(iii) It holds
epio( f K (x0; Â·)) =

(y, Î²) âˆˆRn Ã— R : âˆ€Îµ > 0, (y, Î² âˆ’Îµ) âˆˆK(epi( f ), (x0, f (x0)))

,
where
epio( f K(x0; Â·)) =

(y, Î²) : f K(x0; y) < Î²

is the strict epigraph of the K-directional derivative.
In particular, if K(epi( f ), (x0, f (x0))) is open, it holds
epio( f K(x0; Â·)) = K(epi( f ), (x0, f (x0)))
and f K(x0; Â·) is upper semicontinuous.
BymeansofDeï¬nition10.82itispossibletogetafamilyofgeneralizeddirectional
derivatives. In particular, if we make use of the local cone approximations previously
recalled, we obtain the following results. We use the following notations, taken from
[69, 70]:
(Â¯x, Î±) â†“x0 â‡”(Â¯x, Î±) â†’(x0, f (x0)) and Î± â‰§f (Â¯x);
(Â¯x, Î±) â†‘x0 â‡”(Â¯x, Î±) â†’(x0, f (x0)) and Î± â‰¦f (Â¯x);
Â¯x â†’f x0 â‡”(Â¯x, f (Â¯x)) â†’(x0, f (x0)).
Also the deï¬nitions of â€œlim sup infâ€ and â€œlim inf supâ€ operations are taken from
[69, 70]. Let g : Rn â†’[âˆ’âˆ, +âˆ] and h : Rn Ã— Rm â†’[âˆ’âˆ, +âˆ] extended real-
valued functions. We have
lim inf
Â¯yâ†’y
g( Â¯y) = sup
U(y)
inf
Â¯yâˆˆU(y)g( Â¯y);
lim sup
Â¯yâ†’y
g( Â¯y) = inf
U(y)
sup
Â¯yâˆˆU(y)
g( Â¯y);

372
10
Introduction to Nonsmooth Optimization Problems
lim sup inf
Â¯zâ†’z, Â¯yâ†’y
h( Â¯y, Â¯z) = sup
U1(y)
inf
U2(z)
sup
Â¯zâˆˆU2(z)
inf
Â¯yâˆˆU1(y)h( Â¯y, Â¯z);
lim inf sup
Â¯zâ†’z, Â¯yâ†’y
h( Â¯y, Â¯z) = inf
U1(y) sup
U2(z)
inf
Â¯zâˆˆU2(z)
sup
Â¯yâˆˆU1(y)
h( Â¯y, Â¯z).
Let be f : Rn â†’[âˆ’âˆ, +âˆ] and x0 âˆˆRn. Then:
â€¢ The lower Dini-Hadamard directional derivative at x0 in the direction y âˆˆRn is
fH(x0; y) = f T (x0; y) =
lim inf
( Â¯y,t)â†’(y,0+)
f (x0 + t Â¯y) âˆ’f (x0)
t
.
â€¢ The upper Dini-Hadamard directional derivative at x0 in the direction y âˆˆRn is
f H(x0; y) = f I(x0; y) =
lim sup
( Â¯y,t)â†’(y,0+)
f (x0 + t Â¯y) âˆ’f (x0)
t
.
â€¢ The lower Dini directional derivative at x0 in the direction y âˆˆRn is
fD(x0; y) = f WF(x0; y) = lim inf
tâ†’0+
f (x0 + ty) âˆ’f (x0)
t
.
â€¢ The upper Dini directional derivative at x0 in the direction y âˆˆRn is
f D(x0; y) = f F(x0; y) = lim sup
tâ†’0+
f (x0 + ty) âˆ’f (x0)
t
.
â€¢ The lower Ursescu directional derivative at x0 in the direction y âˆˆRn is
f A(x0; y) = lim sup inf
tâ†’0+, Â¯yâ†’y
f (x0 + t Â¯y) âˆ’f (x0)
t
.
â€¢ The upper Ursescu directional derivative at x0 in the direction y âˆˆRn is
f Q(x0; y) = lim inf sup
tâ†’0+, Â¯yâ†’y
f (x0 + t Â¯y) âˆ’f (x0)
t
.
â€¢ The Clarke generalized directional derivative at x0 in the direction y âˆˆRn is
f o(x0; y) = f H(x0; y) =
lim sup
(Â¯x,Î±)â†“x0, tâ†’0+
f (Â¯x + ty) âˆ’Î±
t
.
Here H is the hypertangent cone (do not make confusion with the upper Dini-
Hadamard directional derivative!).

10.3 The Axiomatic Approach of K.-H. Elster and J. Thierfelder â€¦
373
â€¢ The Clarke-Rockafellar generalized directional derivative at x0 in the direction
y âˆˆRn is
f â†‘(x0; y) = f T o(x0; y) =
lim sup inf
(Â¯x, Î±) â†“x0, Â¯y â†’y
t â†’0+
f (Â¯x + t Â¯y) âˆ’Î±
y
.
â€¢ The epi-Lipschitzian directional derivative at x0 in the direction y âˆˆRn is
f E(x0; y) =
lim sup
(Â¯x, Î±) â†“x0, Â¯y â†’y
t â†’0+
f (Â¯x + t Â¯y) âˆ’Î±
y
.
Remark 10.84 When f is lower semicontinuous, the convergence (Â¯x, Î±) â†“x0
becomes simply Â¯x â†’f x0 and, moreover, if f is continuous, it becomes Â¯x â†’x0.
If f is locally Lipschitz, then:
(a)
f o(x0; y) = f â†‘(x0; y) =
lim sup
xâ†’x0, tâ†’0+
f (Â¯x + ty) âˆ’f (Â¯x)
t
,
i.e. we obtain the usual Deï¬nition 10.34 of the Clarke directional derivative.
(b)
f U(x0; Â·) = fD(x0; y) = fH(x0; y).
(c)
f Q(x0; y) = f D(x0; y) = f H(x0; y).
It follows that f is (right-sided) directionally differentiable at x0 in the direction
y âˆˆRn if and only if
f WF(x0; y) = f F(x0; y).
Moreover, f is GÃ¢teaux differentiable at x0 if and only if
f WF(x0; Â·) = f F(x0; Â·)
is linear.
Similar to the inclusion scheme concerning the various local cone approxima-
tions, we obtain the following scheme showing the relationships between the various
generalized directional derivatives previously considered.

374
10
Introduction to Nonsmooth Optimization Problems
f E(x0; Â·) â‰§f H(x0; Â·) â‰§f Q(x0; Â·)
âˆ¥âˆ¨
âˆ¥âˆ¨
âˆ¥âˆ¨
f o(x0; Â·) â‰§f D(x0; Â·) â‰§fD(x0; Â·)
âˆ¥âˆ¨
âˆ¥âˆ¨
âˆ¥âˆ¨
f â†‘(x0; Â·) â‰§f A(x0; Â·) â‰§fH(x0; Â·)
The following assertions hold true.
(1) The directional derivatives of the ï¬rst row of the scheme are upper semicontin-
uous and it holds
f K(x0; 0) â‰§0.
The directional derivatives of the third row of the scheme are lower semicontin-
uous and it holds
f K(x0; 0) â‰¦0.
For the directional derivatives of the second row of the scheme, it holds
f K(x0; 0) = 0.
(2) The directional derivatives of the ï¬rst column of the scheme are convex (more
precisely: sublinear). The directional derivatives of the second and third column
are isotone, in the sense that they verify the following property:
f1(Â·) â‰¦f2(Â·)
f1(x0) = f2(x0)

â‡’f K
1 (x0; Â·) â‰¦f K
2 (x0; Â·).
In a similar way with respect to the deï¬nition of K-directional derivative, it is possible
to introduce the concept of K-subdifferential.
Deï¬nition 10.85 Let be f : Rn â†’R, x0 âˆˆRn and K(x0, Â·) be a local cone approx-
imation. The set (possibly empty)
âˆ‚K f (x0) =

Î¾ âˆˆRn : f K(x0; y) â‰§Î¾ âŠ¤y, âˆ€y âˆˆRn
is said the K-subdifferential of f at x0 and the elements Î¾ âˆˆâˆ‚K f (x0) are said the
K-subgradients of f at x0.
Note that 0 âˆˆâˆ‚K f (x0) if and only if f K(x0; y) â‰§0, âˆ€y âˆˆRn. When âˆ‚K f (x0) Ì¸=
âˆ…, then âˆ‚K f (x0) is a closed and convex set. As the K-directional derivative of f is
directly related to the local cone approximation K(Â·, Â·) of its epigraph, something
similar holds true also for the K-subdifferential.
Theorem 10.86 Let be f : Rn â†’R, x0 âˆˆRn and K(x0, Â·) a local cone approxi-
mation. Then it holds
âˆ‚K f (x0) =

Î¾ âˆˆRn : (Î¾, âˆ’1) âˆˆK âˆ—(epi( f ), (x0, f (x0)))

,

10.3 The Axiomatic Approach of K.-H. Elster and J. Thierfelder â€¦
375
where K âˆ—is the polar cone of K.
Proof We have the following chain of equivalences:
Î¾ âˆˆâˆ‚K f (x0) â‡”inf

Î² âˆˆR : (y, Î²) âˆˆK(epi( f ), (x0, f (x0)))

â‰§Î¾ âŠ¤y, âˆ€y âˆˆRn
â‡”Î² â‰§Î¾ âŠ¤y, âˆ€(y, Î²) âˆˆK(epi( f ), (x0, f (x0)))
â‡”(Î¾, âˆ’1)âŠ¤(y, Î²) â‰¦0, âˆ€(y, Î²) âˆˆK(epi( f ), (x0, f (x0)))
â‡”(Î¾, âˆ’1) âˆˆK âˆ—(epi( f ), (x0, f (x0))).
â–¡
Now we consider brieï¬‚y some optimality conditions expressed in terms of K-
directional derivatives. We begin with an unconstrained minimization problem.
Theorem 10.87 Let be f : X âŠ‚Rn â†’R and let x0 âˆˆint(X) be a local minimum
point of f over X. If K(Â·, Â·) is any local cone approximation such that K(Â·, Â·) âŠ‚
T (Â·, Â·), then it holds
(i)
f K(x0; y) â‰§0, âˆ€y âˆˆRn;
(ii) 0 âˆˆâˆ‚K f (x0).
Proof (i) Let us assume f K(x0; y) < 0 for a vector y âˆˆRn. Then, because K(Â·, Â·) âŠ‚
T (Â·, Â·), we have
f T (x0; y) â‰¦f K(x0; y) < 0
and hence
lim inf
Â¯yâ†’y, tâ†’0+
f (x0 + t Â¯y) âˆ’f (x0)
t
< 0,
which means âˆ€N(y), âˆ€Î» > 0, âˆƒt âˆˆ(0, Î»), âˆƒÂ¯y âˆˆN(y) :
f (x0 + t Â¯y) âˆ’f (x0)
t
< 0,
which contradicts the assumption that x0 is an unconstrained local minimum point
of f.
(ii) The assertion follows from Deï¬nition 10.85.
â–¡
For example, we have, under the assumptions of Theorem 10.87,
f F(x0; y) = f D(x0; y) = lim sup
tâ†’0+
f (x0 + ty) âˆ’f (x0)
t
â‰§0, âˆ€y âˆˆRn,
or also the sharper condition

376
10
Introduction to Nonsmooth Optimization Problems
f WF(x0; y) = fD(x0; y) = lim inf
tâ†’0+
f (x0 + ty) âˆ’f (x0)
t
â‰§0, âˆ€y âˆˆRn,
or also, in terms of upper Hadamard directional derivatives,
f I(x0; y) = f H(x0; y) =
lim sup
( Â¯y,t)â†’(y,0+)
f (x0 + t Â¯y) âˆ’f (x0)
t
â‰§0, âˆ€y âˆˆRn,
or also the sharper condition
f T (x0; y) = fH(x0; y) =
lim inf
( Â¯y,t)â†’(y,0+)
f (x0 + t Â¯y) âˆ’f (x0)
t
â‰§0, âˆ€y âˆˆRn.
Now we consider a minimization problem of the type (P2), i.e. with a set con-
straint, and of type (P4), i.e. with inequality constraints. First, we introduce the
following sets.
â€¢ The cone of descent directions of f at x0 is:
DK
f (x0) =

y âˆˆRn : f K(x0; y) < 0

.
â€¢ The linearizing cone of f at x0 is:
C K
f (x0) =

y âˆˆRn : f K(x0; y) â‰¦0

.
â€¢ DK
M(x0) = âˆ©
iâˆˆMDK
gi (x0).
â€¢ C K
M(x0) = âˆ©
iâˆˆMC K
gi (x0).
Where M = {1, . . . , m}.
Obviously, these cones are convex, if K(x0; Â·) is convex.
In the following, we assume, when it is necessary, that the local cone approxima-
tion K(Â·, Â·) satisï¬es the following conditions.
(A1) K is convex and closed.
(A2) z âˆˆS â‡”0 âˆˆK(S, z).
(A3) K(Â·, Â·) âŠ‚T (Â·, Â·).
(A4) int(K(Â·, Â·)) âŠ‚I (Â·, Â·).
Let us consider problem (P2) :
min f (x), x âˆˆS âŠ‚Rn.
Theorem 10.88 If x0 âˆˆS is a local solution of (P2) and K(Â·, Â·) satisï¬es conditions
(A3) and (A4), then
(i) Dint(K)
f
(x0) âˆ©K(S, x0) = âˆ…;
(ii) DK
f (x0) âˆ©int(K(S, x0)) = âˆ….

10.3 The Axiomatic Approach of K.-H. Elster and J. Thierfelder â€¦
377
Theorem 10.89 If x0 âˆˆS is a local solution of (P2), if (A1), (A3) and (A4) are
veriï¬ed, and if one of the following conditions is veriï¬ed:
(B1) dom( f int(K)(x0; Â·)) âˆ©K(S, x0) = âˆ…;
(B2) dom( f K(x0; Â·)) âˆ©int(K(S, x0)) = âˆ…,
then it holds
0 âˆˆâˆ‚K f (x0) + K âˆ—(S, x0).
Now let us consider problem (P4), i.e.
(P4) :
â§
â¨
â©
min f (x)
subject to: gi(x) â‰¦0, i = 1, . . . , m,
x âˆˆX âŠ‚Rn,
with X open set of Rn. In order to avoid confusion with the cones K(Â·, Â·), we denote
by S4 the feasible set of (P4). [9] obtain for (P4) the following Karush-Kuhn-Tucker-
type necessary optimality conditions.
Theorem 10.90 Let x0 âˆˆS4 be a local solution of (P4) and let (A1), (A3), (A4),
either (B1) or (B2) be veriï¬ed. Moreover, the following constraint qualiï¬cation is
satisï¬ed:
(C Q)1 :
K âˆ—(S4, x0) âŠ‚B K
I (x0)(x0),
where
B K
I (x0)(x0) =
â§
â¨
â©Î¾ âˆˆRn : Î¾ =

iâˆˆI (x0)
Î»iÎ¾ i, Î»i â‰§0, Î¾ i âˆˆâˆ‚K gi(x0), i âˆˆI (x0)
â«
â¬
â­
is the convex cone generated by K-gradients of gi, i âˆˆI (x0), at x0.
Then, there exist multipliers Î»i â‰§0, i âˆˆI (x0), such that
(i) 0 âˆˆâˆ‚K f (x0) + 
iâˆˆI (x0) Î»iâˆ‚K gi(x0);
(ii)
f K(x0; y) + 
iâˆˆI (x0) Î»igK
i (x0; y) â‰§0, âˆ€y âˆˆRn.
Let us now consider the following further constraint qualiï¬cations (x0 âˆˆS4).
â€¢ (C Q)2. Generalized Guignard-Gould-Tolle constraint qualiï¬cation:
(K(S4, x0))âˆ—âŠ‚(C K
I (x0)(x0))âˆ—,
âˆ‚K gi(x0) Ì¸= âˆ…, âˆ€i âˆˆI (x0),
B K
I (x0)(x0) closed, either (B1) or (B2).
â€¢ (C Q)3. Generalized Abadie constraint qualiï¬cation:

378
10
Introduction to Nonsmooth Optimization Problems
C K
I (x0)(x0) âŠ‚K(S4, x0),
âˆ‚K gi(x0) Ì¸= âˆ…, âˆ€i âˆˆI (x0),
B K
I (x0)(x0) closed, either (B1) or (B2).
â€¢ (C Q)4. First generalized Slater constraint qualiï¬cation:
Dint(K)
I (x0) (x0) Ì¸= âˆ…, âˆ‚K gi(x0) Ì¸= âˆ…, âˆ€i âˆˆI (x0),
B K
I (x0)(x0) closed, either (B1) or (B2).
(C Q)5. Second generalized Slater constraint qualiï¬cation:
dom( f K(x0, Â·)) âˆ©Dint(K)
I (x0) (x0) Ì¸= âˆ…,
âˆ‚K gi(x0) Ì¸= âˆ…, âˆ€i âˆˆI (x0), B K
I (x0)(x0) closed.
We have the following result.
Theorem 10.91 ([9]) Let be x0 âˆˆS4 and let conditions (A1) âˆ’(A4) be veriï¬ed.
Moreover, let be veriï¬ed the condition
(A5) :
DK
I (x0)(x0) âŠ‚K(S4, x0).
Then we have the following implications:
(C Q)5 â‡’(C Q)4 â‡’(C Q)3 â‡’(C Q)2 â‡’(C Q)1.
The same authors obtain also Fritz John-type optimality conditions for (P4) in
terms of K-directional derivatives.
Theorem 10.92 Let x0 âˆˆS4 be a local solution of (P4) and let the conditions (A1) âˆ’
(A5) be veriï¬ed. Then:
(i) There exist multipliers Î»i â‰§0, i âˆˆ{0} âˆªI (x0), not all zero, such that
Î»0 f int(K)(x0; y) +

iâˆˆI (x0)
Î»igK
i (x0; y) â‰§0,
âˆ€y âˆˆdom( f int(K)(x0; Â·)) âˆ©
âˆ©
iâˆˆI (x0) dom(gK
i (x0; Â·)).
(ii) There exist multipliers Î»â€²
i â‰§0, i âˆˆ{0} âˆªI (x0), not all zero, such that
Î»â€²
0 f K(x0; y) +

iâˆˆI (x0)
Î»â€²
igint(K)
i
(x0; y) â‰§0,

References
379
âˆ€y âˆˆdom( f K(x0; Â·)) âˆ©
âˆ©
iâˆˆI (x0) dom(gint(K)
i
(x0; Â·)).
Under other appropriate conditions, the same authors obtain the following version
of the Fritz John necessary optimality conditions for (P4) :
â€¢ There exist multipliers u0 â‰§0, ui â‰§0, not all zero, such that
u0 f K(x0; y) +

iâˆˆI (x0)
uigK
i (x0; y) â‰§0, âˆ€y âˆˆRn;
0 âˆˆu0âˆ‚K f (x0) +

iâˆˆI (x0)
uiâˆ‚K gi(x0).
Under an appropriate constraint qualiï¬cation, it is possible to obtain u0 Ì¸= 0, i.e.
u0 = 1, in the above conditions.
References
1. J.-J. Moreau, Fonctionelles sous-diffÃ©rentiables, C. R. Acad. Sci. Paris. SÃ©r. A-B 257, 4117â€“
4119 (1963)
2. R.T. Rockafellar, Convex Analysis (Princeton University Press, Princeton, 1970)
3. A.D. Ioffe, V.M. Tichomirov, Theory of Extremal problems (North Holland, Amsterdam,
1979)
4. B.N. Pshenichnyi, Necessary Conditions for an Extremum (Marcel Dekker, New York, 1971)
5. J.M. Danskin, The Theory of Max-Min and Its Application to Weapons Allocation Problems
(Springer, New York, 1967)
6. V.F. Demyanov, V.N. Malozemov, Introduction to Minimax (Wiley, New York, 1974)
7. K.-H. Elster, J. Thierfelder, The general concept of cone approximations in nondifferen-
tiable optimization, in Nondifferentiable Optimization. ed. by V.F. Demyanov, D. Pallaschke
(Springer Verlag, Berlin, Motivations and Applications, 1985), pp.170â€“189
8. K.-H. Elster, J. Thierfelder, On cone approximations and generalized directional derivatives,
in Nonsmooth Optimization and Related Topics. ed. by V.F. Demyanov, F. Giannessi (Plenum
Press, New York, 1988), pp.133â€“154
9. K.-H. Elster, J. Thierfelder, Abstract cone approximations and generalized differentiability in
nonsmooth optimization. Optimization 19, 315â€“341 (1988)
10. K.-H. Elster, J. Thierfelder, Generalized notions of directional derivatives. Quaderni della
Sezione di Matematica Applicata, Gruppo di Ottimizzazione e Ricerca Operativa, UniversitÃ 
di Pisa, no. 155 (1989)
11. W. Fenchel, Convex Cones, Sets and Functions, Lecture Notes (Princeton University, 1953)
12. A.W. Roberts, D.E. Varberg, Convex Functions (Academic, New York, 1973)
13. V.F. Demyanov, A.M. Rubinov, Constructive Nonsmooth Analysis (Verlag Peter Lang, Frank-
furt a.M., 1995)
14. A. Ben-Tal, J. Zowe, Directional derivatives in nonsmooth optimization. J. Optim. Theory
Appl. 47, 483â€“490 (1985)
15. L. Qi, On an extended Lagrange claim. J. Optim. Theory Appl. 108, 685â€“688 (2001)
16. M. Durea, R. Strugariu, An Introduction to Nonlinear Optimization Theory (De Gruyter Open
Ltd., Warsaw/Berlin, 2014)

380
10
Introduction to Nonsmooth Optimization Problems
17. S. Schaible, Second-order characterizations of pseudoconvex quadratic functions. J. Optim.
Theory Appl. 21, 15â€“26 (1977)
18. M. Schechter, More on subgradient duality. J. Math. Anal. Appl. 71, 251â€“262 (1979)
19. F.H. Clarke, Generalized gradients and applications. Trans. Amer. Math. Soc. 205, 247â€“262
(1975)
20. F.H. Clarke, A new approach to Lagrange multipliers. Math. Oper. Res. 1, 165â€“174 (1976)
21. F.H. Clarke, Optimization and Nonsmooth Analysis (Wiley, New York, 1983)
22. Q.H. Ansari, C.S. Lalitha, M. Mehta, General Convexity, Nonsmooth Variational Inequalities
and Nonsmooth Optimization (CRC Press, Boca Raton, 2014)
23. A. Bagirov, N. Karmitsa, M.M. MÃ¤kelÃ¤, Introduction to Nonsmooth Optimization (Springer,
Heidelberg, 2014)
24. J.M. Borwein, A.S. Lewis, Convex Analysis and Nonlinear Optimization (Springer, New York,
2000)
25. F.H. Clarke, V.F. Demyanov, F. Giannessi, Nonsmooth Optimization and Related Topics
(Plenum Pub. Corp, New York, 1989)
26. F.H. Clarke, Y.S. Ledyaev, R.J. Stern, P.R. Wolenski, Nonsmooth Analysis and Control Theory
(Springer, New York, 1998)
27. V.F. Demyanov, P.M. Pardalos, M. Batsyn, Constructive Nonsmooth Analysis and Related
Topics (Springer, New York, 2014)
28. J. Ferrera, An Introduction to Nonsmooth Analysis (Academic, New York, 2014)
29. G. Giorgi, A. Guerraggio, J. Thierfelder, Mathematics of Optimization: Smooth and Nons-
mooth Case (Elsevier, Amsterdam, 2004)
30. J. Gwinner, Bibliography on non-differentiable optimization and nonsmooth analysis. J. Com-
put. Appl. Math. 7, 277â€“285 (1981)
31. J.-B. Hiriart-Urruty, Miscellanies on nonsmooth analysis and optimization, in Nondifferen-
tiable Optimization: Motivations and Applications. ed. by V.F. Demyanov, D. Pallaschke
(Springer, Berlin, 1985), pp.8â€“24
32. J.P. Penot, Calculus Without Derivatives (Springer, New York, 2013)
33. R.T. Rockafellar, R.J.-B. Wets, Variational Analysis (Springer, Berlin, 2009)
34. J. O. Royset, R. J.-B. Wets, An Optimization Primer (Springer, New York, 2022)
35. W. Schirotzek, Nonsmooth Analysis (Springer, Berlin, 2007)
36. K. Shimitzu, Y. Ishizuka, J.F. Bard, Nondifferentiable and Two-Level Math. Program (Kluwer
Academic Publishers, Boston, 1997)
37. C.R. Bector, S. Chandra, J. Dutta, Principles of Optimization Theory (Alpha Science Inter-
national Ltd., Harrow, U.K., 2005)
38. G. Giorgi, A. Guerraggio, On a characterization of Clarkeâ€™s tangent cone. J. Optim. Theory
Appl. 74, 369â€“372 (1992)
39. G. Giorgi, A. Guerraggio, On the notion of tangent cone in mathematical programming.
Optimization 25, 11â€“23 (1992)
40. G. Giorgi, A. Guerraggio, Characterizations, computations, algebraic and topological prop-
erties of tangent cones. J. Stat. Manag. Syst. 5, 275â€“294 (2002)
41. M.S. Bazaraa, C.M. Shetty, Foundations of Optimization, Lecture Notes in Economics and
Mathematical Systems, vol. 122, (Springer, Berlin, 1976)
42. G. Giorgi, S. Komlosi, Dini derivatives in optimizationâ€”Part I. Riv. Mat. Sci. Econom. Social.
15(1), 3â€“30 (1993)
43. G. Giorgi, S. Komlosi, Dini derivatives in optimizationâ€”Part II. Riv. Mat. Sci. Econom.
Social. 15(2), 3â€“24 (1993)
44. G. Giorgi, S. Komlosi, Dini derivatives in optimizationâ€”Part III. Riv. Mat. Sci. Econom.
Social. 18(1), 47â€“63 (1995)
45. B. JimÃ©nez, V. Novo, Alternative theorems and necessary optimality conditions for direction-
ally differentiable multiobjective programs. J. Convex Anal. 9(1), 97â€“116 (2002)
46. A. Cambini, L. Martein, Generalized Convexity and Optimization (Springer, Berlin, Theory
and Applications, 2009)

References
381
47. B.S. Mordukhovich, Variational Analysis and Generalized Differentiation, vol. 1, 2 (Springer,
Berlin, 2006)
48. J.-B. Hiriart-Urruty, On optimality conditions in nondifferentiable programming. Math. Pro-
gram. 14, 73â€“86 (1978)
49. M. Castellani, M. Pappalardo, First-order cone approximations and necessary optimality con-
ditions. Optimization 35, 113â€“126 (1995)
50. J.-B. Hiriart-Urruty, Reï¬nements of necessary optimality conditions in nondifferentiable pro-
gramming I. Appl. Math. Optim. 5, 63â€“82 (1979)
51. I. Ekeland, On the variational principle. J. Math. Anal. Appl. 47, 324â€“353 (1974)
52. J.-B. Hiriart-Urruty, A short proof of the variational principle for approximate solutions of a
minimization problem. Am. Math. Mon. 90, 206â€“207 (1983)
53. V.H. Nguyen, J.-J. Strodiot, R. Mifï¬‚in, On conditions to have bounded multipliers in locally
Lipschitz programming. Math. Program. 18, 100â€“106 (1980)
54. D.P. Bertsekas, A.E. Ozdaglar, Pseudonormality and Lagrange multiplier theory for con-
strained optimization. J. Optim. Theory Appl. 114, 287â€“343 (2002)
55. B.M. Glover, Generalized convexity in nondifferentiable programming. Bull. Austral. Math.
Soc. 30, 193â€“218 (1984)
56. M. Soleiman-Damaneh, Characterization of nonsmooth quasiconvex and pseudoconvex func-
tions. J. Math. Anal. Appl. 330, 1387â€“1392 (2007)
57. N. Hadjisavvas, S. Komlosi, S. Schaible (eds.), Handbook of Generalized Convexity and
Generalized Monotonicity (Springer, New York, 2005)
58. T.W. Reiland, Nonsmooth invexity. Bull. Austral. Math. Soc. 42, 437â€“446 (1990)
59. R.N. Kaul, S.K. Suneja, C.S. Lalitha, Generalized nonsmooth invexity. J. Inf. Optim. Sci. 15,
1â€“17 (1994)
60. M.A. Hanson, On sufï¬ciency of the Kuhn-Tucker conditions. J. Math. Anal. Appl. 80, 545â€“
550 (1981)
61. E. Caprari, Ï-invex functions and (F, Ï) -convex functions: properties and equivalences.
Optimization 52, 65â€“74 (2003)
62. G. Giorgi, A. Guerraggio, Various types of nonsmooth invex functions. J. Inf. Optim. Sci. 17,
137â€“150 (1996)
63. T.D. Phuong, P.H. Sach, N.D. Yen, Strict lower semicontinuity of the level sets and invexity
of a locally Lipschitz function. J. Optim. Theory Appl. 87, 579â€“594 (1995)
64. Y. Tanaka, M. Fukushima, T. Ibaraki, On generalized pseudoconvex functions. J. Math. Anal.
Appl. 144, 342â€“355 (1989)
65. Y. Tanaka, Note on generalized convex functions. J. Optim. Theory Appl. 66, 345â€“349 (1990)
66. V. Jeyakumar, Equivalence of saddle-points and optima, and duality for a class of non-smooth
non-convex problems. J. Math. Anal. Appl. 130, 334â€“343 (1988)
67. V.F. Demyanov, L.C.W. Dixon (eds.), Quasidifferential Calculus. Math. Program Study 29
(1986)
68. V.F. Demyanov, A.M. Rubinov (eds.), Quasidifferentiability and Related Topics. (Kluwer
Academic Publishers, Dordrecht/Boston/London, 2000)
69. R.T. Rockafellar, Generalized directional derivatives and subgradients of nonconvex func-
tions. Canad. J. Math. 32, 257â€“280 (1980)
70. R.T. Rockafellar, The Theory of Subgradients and Its Applications to Problems of Optimiza-
tion: Convex and Nonconvex Functions (Heldermann-Verlag, Berlin, 1981) (French version:
La ThÃ©orie des Sous-gradients et ses Applications Ã lâ€™Optimization, Les Presses de Lâ€™universitÃ©
de MontrÃ©al, MontrÃ©al)
71. F. Giannessi, Semidifferentiable functions and necessary optimality conditions. J. Optim.
Theory Appl. 60, 191â€“241 (1989)
72. F. Giannessi, Constrained Optimization and Image Space Analysis. Vol. 1: Separation of Sets
and Optimality Conditions (Springer, New York, 2005)
73. S. Komlosi, M. Pappalardo, A general scheme for ï¬rst order approximations in optimization.
Optim. Methods Softw. 3, 143â€“152 (1994)

382
10
Introduction to Nonsmooth Optimization Problems
74. A.D. Ioffe, On the theory of subdifferential, in Fermat-days 85: Mathematics for Optimization.
ed. by J.-B. Hiriart-Urruty (North Holland, Amsterdam, 1986), pp. 183â€“200
75. D.E. Ward, Isotone tangent cones and nonsmooth optimization. Optimization 18, 769â€“783
(1987)
76. D. Ward, The quantiï¬cational tangent cones. Canad. J. Math. 40, 666â€“694 (1988)
77. D.E. Ward, Directional derivative calculus and optimality conditions in nonsmooth mathe-
matical programming. J. Inf. Optim. Sci. 10, 81â€“96 (1989)
78. C. Ursescu, Tangent setâ€™s calculus and necessary conditions for extremality. SIAM J. Control
Optim. 20, 563â€“574 (1982)
79. J.P. Aubin, H. Frankowska, Set-Valued Analysis (BirkhÃ¤user, Boston, 1990)
80. M.S. Bazaraa, J.J. Goode, Extensions of optimality conditions via supporting functions. Math.
Program. 5, 267â€“285 (1973)

Chapter 11
Introduction to Multiobjective
Optimization
Frequently, optimization problems appear in any technique or scientiï¬c activity, and
the optimal decisions have traditionally attended to a unique criterion. However, in
areas such as Economics, Social Sciences, Engineering, or Industry it is usually nec-
essary to consider multiple objectives, confronted each other, that requires the use of
decision techniques based on a ï¬nite number of objectives or criteria (multiobjective
optimization or multicriteria decision), on a nonï¬nite number (vector optimization)
or even on the resolution of problems in which the aim is to optimize a set-valued
function. This fact has motivated the creation of mathematical theories, which are
currently in process of development. To expand knowledge of this area, the inter-
ested reader can consult the monographs by Ehrgott [1], Miettinen [2] and Sawaragi,
Nakayama and Tanino [3] in ï¬nite-dimensional spaces, and Jahn [4] and Luc [5] in
inï¬nite-dimensional spaces.
From the historical point of view, it seems that the ï¬rst to deal with multiobjective
problems were Francis Y. Edgeworth (1845â€“1926) and Vilfredo Pareto (1848â€“1923).
In 1881 at Kingâ€™s College (London) and later at Oxford, economics professor Edge-
worth was the ï¬rst to deï¬ne an optimum for multicriteria economic decision-making
[6], and he did so for a two-criteria problem. Pareto, graduated from the University
of Turin in 1870 with a degree in Civil Engineering, while working in Florence as a
civil engineer (1870-1893), was one of the ï¬rst to analyze economic problems with
mathematical tools. In 1893, he assumed the chair of Political Economy at the Uni-
versity of Lausanne, where he created one of his most famous theories, The Pareto
Optimum [7]: â€œThe optimal allocation of the resources of a society is not achieved
while it is possible to make at least one individual better in his own estimation while
maintaining others as well as beforeâ€.
The translation of Paretoâ€™s work into English, in 1971, prompted the development
of multiobjective methods in Applied Mathematics and Engineering. The growth of
this ï¬eld was particularly strong in the United States with pioneering contributions,
among others, by Stadler [8] and Steuer [9], and in the publication of two books
already focused on the theoretical aspects of multiobjective optimization, those by
Â© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al., Basic Mathematical Programming Theory, International Series
in Operations Research & Management Science 344,
https://doi.org/10.1007/978-3-031-30324-1_11
383

384
11
Introduction to Multiobjective Optimization
Sawaragi et al. [3] and Luc [5] in the vectorial case, without forgetting the famous
work by Kuhn and Tucker [10]. In the last decades, the applications of multiobjective
optimization have grown steadily in many areas.
Multiobjective optimization methods can be broken down into different cate-
gories, but as a ï¬rst approximation we can speak of two approaches, the scalarization
approach and the Pareto approach. In the ï¬rst group of methods, the multiobjective
problem is solved by translating it into a single objective problem, that is, a scalar
problem. Pareto methods keep the initial elements in their vector framework and
use some concept of dominance based on a preference relation to compare possible
solutions.
11.1
Optimality Notions
We are interested in the following multiobjective optimization problem
(M P1)
min [ f1(x), . . . , fq(x)]âŠ¤subject to x âˆˆS,
where fk : X âŠ‚Rn â†’R, k = 1, . . . , q, are the objective functions, X is an open
set, S âŠ‚X is an arbitrary nonempty subset, called the feasible set; Rn and Rq
are called decision space and objective space, respectively. We denote f (x) =
[ f1(x), . . . , fq(x)]âŠ¤which is called the objective function.
The ï¬rst thing we have to do is to say what means â€œminâ€ in (M P1). For this
purpose, we consider that in Rq the order is given componentwise. For x, y âˆˆRq we
write x â‰¦y if xk â‰¦yk, for k = 1, . . . , q, and x < y if xk < yk, for k = 1, . . . , q.
We denote Rq
+ = {y âˆˆRq : yk â‰§0, k = 1, . . . , q}, and Rq
++ = int(Rq
+) = {y âˆˆ
Rq : yk > 0, k = 1, . . . , q}.Letusobservethat x â‰¦y â‡”y âˆ’x âˆˆRq
+ and x < y â‡”
y âˆ’x âˆˆint(Rq
+).
Given x0, x1 âˆˆS, we say that x0 dominates (or is better than) x1 if f (x0) â‰¦f (x1).
Related to solutions of problem (M P1), the ideal would be to ï¬nd a point x0 âˆˆS
such that
f (x0) â‰¦f (x),
âˆ€x âˆˆS.
A point x0 âˆˆS satisfying this condition is called an ideal point for (M P1). This
point is the minimum of all the objectives fk, k = 1, . . . , q, over S. Such a point x0
usually does not exist, the common is that the objectives are in conï¬‚ict with each
other, in the following sense: to pass from x1 âˆˆS to x0 âˆˆS we can improve e.g. f1,
i.e. f1(x0) < f1(x1) but we worsen, e.g. f2, i.e. f2(x1) < f2(x0). When we ï¬nd a
point x0 âˆˆS such that we cannot improve it, we say that x0 is an efï¬cient solution
to problem (M P1). Next, we give the rigorous deï¬nition with the different notions
of optimality for (M P1).
Deï¬nition 11.1 Consider problem (M P1) and x0 âˆˆS.

11.1 Optimality Notions
385
(a) x0 is called efï¬cient or Pareto minimal if there exists no x âˆˆS such that f (x) â‰¦
f (x0) and fk(x0) < fk(x) for some k âˆˆ{1, . . . , q}, or equivalently, f (x) â‰¦
f (x0) and f (x) Ì¸= f (x0).
(b) x0 is called weak efï¬cient or weak Pareto minimal if there exists no x âˆˆS such
that f (x) < f (x0).
(c) x0 is called strict efï¬cient or strict Pareto minimal if f (x)  f (x0) for all x âˆˆS,
x Ì¸= x0.
We denote the set of all efï¬cient solutions of (M P1) and weak efï¬cient solutions
by E( f, S) and W( f, S), respectively, and they are called the efï¬cient set and the
weak efï¬cient set. The set of all strict efï¬cient solutions is denoted by sE( f, S).
Other equivalent notions of efï¬ciency are used in the literature, next we collect
some of them.
Remark 11.2 (i) The following statements are equivalent:
(a) x0 is efï¬cient.
(b) There is no x âˆˆS such that f (x) âˆ’f (x0) âˆˆâˆ’Rq
+ \ {0}.
(c)
f (x) âˆ’f (x0) âˆˆ(âˆ’Rq
+ \ {0})c for all x âˆˆS.
(d)
f (S) âˆ©( f (x0) âˆ’Rq
+) = { f (x0)}.
(e) ( f (S) âˆ’f (x0)) âˆ©âˆ’Rq
+ = {0}.
(f) The implication
x âˆˆS, f (x) â‰¦f (x0) â‡’f (x) = f (x0)
holds.
(ii) The following statements are equivalent:
(a) x0 is weak efï¬cient.
(b) There is no x âˆˆS such that f (x) âˆ’f (x0) âˆˆâˆ’int(Rq
+).
(c)
f (S) âˆ©( f (x0) âˆ’int(Rq
+)) = âˆ….
(d) ( f (S) âˆ’f (x0)) âˆ©âˆ’int(Rq
+) = âˆ….
(iii) The following statements are equivalent:
(a) x0 is strict efï¬cient.
(b) x0 is efï¬cient and f âˆ’1( f (x0)) âˆ©S = {x0}.
(c) x âˆˆS, f (x) â‰¦f (x0) â‡’x = x0.
The following inclusions are obvious:
sE( f, S) âŠ‚E( f, S) âŠ‚W( f, S).
We can also deï¬ne (weak) efï¬cient points for a set A âŠ‚Rq. If Id : Rq â†’Rq is the
identity map, i.e. Id(y) = y for all y âˆˆRq, then we say that a0 âˆˆA is an efï¬cient
point of A if a0 âˆˆE(Id, A), which means that (A âˆ’a0) âˆ©âˆ’Rq
+ = {0}. Similarly,
a0 âˆˆA is a weak efï¬cient point of A if a0 âˆˆW(Id, A), which means that (A âˆ’a0) âˆ©

386
11
Introduction to Multiobjective Optimization
Fig. 11.1 Illustration of efï¬ciency. x0 and x4 are efï¬cient, x2 is not efï¬ciency since is dominated
e.g. by x4, x1 is weak efï¬cient since f (S) âˆ©( f (x1) âˆ’int(Rq
+)) = âˆ…but it is not efï¬cient since
f (x4) âˆˆf (x1) âˆ’Rq
+ and f (x4) Ì¸= f (x1)
âˆ’int(Rq
+) = âˆ…. We denote by E(A) and W(A) the sets of efï¬cient and weak efï¬cient
points of A, respectively. It is obvious from the deï¬nition that E(A) = E(Id, A) and
W(A) = W(Id, A).
The following equivalences are also obvious:
x0 âˆˆE( f, S) â‡”f (x0) âˆˆE( f (S)),
and
x0 âˆˆW( f, S) â‡”f (x0) âˆˆW( f (S)).
(11.1)
For this reason, many times we prefer working in the objective space with the
image set f (S). Moreover, if y0 âˆˆE( f (S)) then f âˆ’1(y0) âˆ©S âŠ‚E( f, S), and if
y0 âˆˆW( f (S)) then f âˆ’1(y0) âˆ©S âŠ‚W( f, S).
Next, we give an example to illustrate the notions introduced (Fig. 11.1).
The ï¬rst questions we approach are the existence and the basic properties of the
efï¬ciency set. It is convenient to consider E(Y) as we have seen, with Y âŠ‚Rq. First
let us show through examples that the efï¬cient set can be empty or a singleton.
Example 11.3 (a) Let f : R â†’R2 deï¬ned by f (x) = [x2, x]âŠ¤and S = {x âˆˆR :
x â‰§2}. One has that f (S) = {(y1, y2) âˆˆR2 : y1 = y2
2, y2 â‰§2}. In consequence,
E( f (S)) = {(4, 2)} and E( f, S) = {2} are singleton.
(b) Let Y = {(y1, y2) âˆˆR2 : y2 = y2
1 + 1, y1 > 0}. One has E(Y) = W(Y) = âˆ….
We invite the reader to draw the sets f (S) in part (a) and Y in part (b).
Extension to an arbitrary convex cone
We can consider in Rq another relation âª¯instead of â‰¦. A binary relation âª¯over a
set A âŠ‚Rq comes deï¬ned by a set Râª¯âŠ‚A Ã— A so that y1 âª¯y2 â‡”(y1, y2) âˆˆRâª¯.

11.1 Optimality Notions
387
Deï¬nition 11.4 A relation âª¯deï¬ned on A is called
(a) reï¬‚exive if y âª¯y for all y âˆˆA,
(b) symmetric if y1 âª¯y2 â‡’y2 âª¯y1 for all y1, y2 âˆˆA,
(c) antisymmetric if y1 âª¯y2 and y2 âª¯y1 â‡’y1 = y2 for all y1, y2 âˆˆA,
(d) transitive if y1 âª¯y2 and y2 âª¯y3 â‡’y1 âª¯y3 for all y1, y2, y3 âˆˆA.
It is said that âª¯is a preorder if it is reï¬‚exive and transitive. A preorder is total
if, for all y1, y2 âˆˆA one has y1 âª¯y2 or y2 âª¯y1, it is called a partial preorder
otherwise.
Let us note that the usual order â‰¦on Rq is partial. It is important to note that in a
partial order, two arbitrary elements cannot be compared, in general.
Deï¬nition 11.5 A relation âª¯deï¬ned on Rq is said to be compatible with the linear
structure if
(a) y1 âª¯y2 â‡’Î±y1 âª¯Î±y2 for all y1, y2 âˆˆRq and Î± â‰§0, and
(b) y1 âª¯y2 and y3 âª¯y4 â‡’y1 + y3 âª¯y2 + y4 for all y1, y2, y3, y4 âˆˆRq.
A characterization of a partial preorder on Rq is given in the next result.
Theorem 11.6 (i) If âª¯is a partial preorder on Rq compatible with the linear struc-
ture, then the set
K = {y âˆˆRq : 0 âª¯y}
is a convex cone. If, in addition, âª¯is antisymmetric, then K is pointed (i.e. K âˆ©âˆ’K =
{0}).
(ii) Conversely, if K is a convex cone in Rq, then the relation deï¬ned by
y1, y2 âˆˆRq,
y1 â‰¦K y2 â‡”y2 âˆ’y1 âˆˆK
is a partial preorder compatible with the linear structure. If, in addition, K is pointed,
then â‰¦K is antisymmetric.
The proof is easy and it is left to the reader.
In vector optimization, it is common to consider that the order is given by a convex
cone. Note that the usual order â‰¦on Rq is given by the closed convex cone Rq
+.
We can extend the notions of efï¬ciency for an arbitrary preorder â‰¦K given by a
convex cone K âŠ‚Rq as follows.
Deï¬nition 11.7 Consider problem (M P1) and x0 âˆˆS.
(a) x0 is called efï¬cient if ( f (S) âˆ’f (x0)) âˆ©âˆ’K = {0}.
(b) x0 is called weak efï¬cient if ( f (S) âˆ’f (x0)) âˆ©âˆ’int(K) = âˆ…
(c) x0 is called strict efï¬cient if f (x) K f (x0) for all x âˆˆS, x Ì¸= x0.

388
11
Introduction to Multiobjective Optimization
Of course, we can also deï¬ne efï¬cient points for a set A âŠ‚Rq with respect to
a convex cone K similarly as we have done for Rq
+. In this introductory chapter to
multiobjective optimization we prefer to continue our study with the cone Rq
+. Most
of the properties studied here are also true for an arbitrarily pointed closed convex
cone with a nonempty interior. The interested reader can see Sawaragi et al. [3] or
Jahn [4].
We can deï¬ne Pareto maximal points as follows. a0 âˆˆA is a maximal point of
A if (A âˆ’a0) âˆ©K = {0}. Therefore, a Pareto maximal point with respect to K is a
Pareto minimal point with respect to âˆ’K. For this reason, in this chapter we only
deal with minimal Pareto points.
Next, we establish some basic properties. Let A âŠ‚Rq be a nonempty set.
Theorem 11.8 (i) E(A) = E(A + Rq
+).
(ii) W(A) âŠ‚W(A + Rq
+).
Proof (i) First, let a0 âˆˆE(A), then (A âˆ’a0) âˆ©âˆ’Rq
+ = {0}. This condition implies
that (A + Rq
+ âˆ’a0) âˆ©âˆ’Rq
+ = {0}, i.e. a0 âˆˆE(A + Rq
+). Indeed, assume by con-
tradiction that there exists d1, d2 âˆˆRq
+, d2 Ì¸= 0 such that âˆ’d2 âˆˆA + d1 âˆ’a0.
Hence âˆ’(d1 + d2) âˆˆA âˆ’a0, d = d1 + d2 âˆˆRq
+ since Rq
+ is a convex cone and
d = d1 + d2 Ì¸= 0. Otherwise, d2 = âˆ’d1 âˆˆRq
+ âˆ©Rq
+ = {0}, and it would be d2 = 0,
which is a contradiction. Therefore, âˆ’d âˆˆ(A âˆ’a0) âˆ©âˆ’Rq
+ with d Ì¸= 0, which con-
tradicts the hypothesis. Thus a0 âˆˆE(A + Rq
+).
Second,let y0 = a0 + d0 âˆˆE(A + Rq
+),witha0 âˆˆA andd0 âˆˆRq
+.Weafï¬rmthat
d0 = 0. Indeed, if we assume that d0 Ì¸= 0 then a0 â‰¦y0 (since y0 âˆ’a0 âˆˆRq
+) and
a0 Ì¸= y0, and as a0 âˆˆA + Rq
+ it follows that y0 is not an efï¬cient point of A + Rq
+,
which contradicts the hypothesis. Thus d0 = 0, and so a0 = y0 âˆˆE(A + Rq
+), and as
y0 âˆˆA âŠ‚A + Rq
+ it follows that y0 âˆˆE(A) because (A + Rq
+ âˆ’y0) âˆ©âˆ’Rq
+ = {0}
implies (A âˆ’y0) âˆ©âˆ’Rq
+ = {0}.
(ii) The proof of this fact is similar to that of the ï¬rst part of part (i), for this reason
we omit it.
â–¡
The inclusion W(A + Rq
+) âŠ‚W(A) is in general false. For example, in R2, if A =
{(0, 0)}, then W(A) = {(0, 0)} while W(A + R2
+) = {(x, y) âˆˆR2
+ : x = 0 or y =
0}.
Theorem 11.9 E(A) âŠ‚W(A) âŠ‚bd A.
In consequence, if A is open or A + Rq
+ is open, then W(A) = âˆ….
Proof We only have to prove W(A) âŠ‚bd A. Let a0 âˆˆW(A) and assume that a0 /âˆˆ
bd A. Then a0 âˆˆint(A), and so there exists a neighborhood U(a0) such that U(a0) âŠ‚
A. Pick up d âˆˆint(Rq
+). For a ï¬xed t > 0 small enough one has a1 = a0 âˆ’td âˆˆ
U(a0) and td âˆˆint(Rq
+). In consequence, a1 âˆ’a0 = âˆ’td âˆˆ(A âˆ’a0) âˆ©âˆ’int(Rq
+),
which contradicts the fact that a0 âˆˆW(A).
â–¡
Theorem 11.10 Let A, A1, A2 be nonempty subsets of Rq. We have
(i) E(A1 + A2) âŠ‚E(A1) + E(A2).

11.1 Optimality Notions
389
(ii) E(t A) = t E(A) for all t > 0.
The proof is easy and it is left to the reader.
We provide next, without proof, an existence result.
Theorem 11.11 (Borwein [11]) Let A be a nonempty subset of Rq and suppose that
there is some a âˆˆA such that the section
Aa = {y âˆˆA : y â‰¦a} = A âˆ©(a âˆ’Rq
+)
is compact (we say â€œA contains a compact sectionâ€). Then E(A) is nonempty.
Theorem 11.12 Consider problem (M P1) and suppose that S is compact and each
fk : X âŠ‚Rn â†’R, k = 1, . . . , q, is continuous. Then E( f, S) is nonempty.
Proof We know that f (S) is a compact set since f is continuous. Hence, for any
y âˆˆf (S) the section f (S) âˆ©(y âˆ’Rq
+) is compact, and by Theorem 11.11 it follows
that E( f (S)) Ì¸= âˆ…. In consequence, E( f, S) = f âˆ’1(E( f (S))) âˆ©S Ì¸= âˆ….
â–¡
The proof of Theorem 11.11 is based on Zornâ€™s Lemma. An easier proof can
be done to prove an existence result for weak efï¬cient points (see Theorem 2.25 in
Ehrgott [1]).
Theorem 11.13 If A âŠ‚Rq is compact, then W(A) Ì¸= âˆ….
In Deï¬nition 11.1 global efï¬ciency has been introduced. Another important con-
cept is local efï¬ciency.
Deï¬nition 11.14 Consider problem (M P1) and x0 âˆˆS.
(a) x0 is called local efï¬cient or local Pareto minimal if there exists a neighborhood
U(x0) of x0 such that x0 is efï¬cient in S âˆ©U(x0), i.e.
( f (S âˆ©U(x0)) âˆ’f (x0)) âˆ©âˆ’Rq
+ = {0}.
(11.2)
(b) x0 is called local weak efï¬cient or local weak Pareto minimal if there exists a
neighborhood U(x0) of x0 such that x0 is weak efï¬cient in S âˆ©U(x0), i.e.
( f (S âˆ©U(x0)) âˆ’f (x0)) âˆ©âˆ’int(Rq
+) = âˆ…,
(c) x0 is called local strict efï¬cient or local strict Pareto minimal if there exists
a neighborhood U(x0) of x0 such that x0 is strict efï¬cient in S âˆ©U(x0), i.e.
f (x)  f (x0) for all x âˆˆS âˆ©U(x0), x Ì¸= x0.
Naturally, any global (weak) efï¬cient point is local (weak) efï¬cient. The converse
is valid for convex problems.
Theorem 11.15 Assume that S is a convex set and each component fk : X â†’R,
k = 1, . . . , q is convex on S. If x0 âˆˆS is local efï¬cient, then it is global efï¬cient.

390
11
Introduction to Multiobjective Optimization
Proof By hypothesis, condition (11.2) is satisï¬ed for some neighborhood U(x0) of
x0. By contradiction, let us assume that x0 is not global efï¬cient. Then there exists
x1 âˆˆS such that
f (x1) âˆ’f (x0) âˆˆâˆ’Rq
+ \ {0}.
(11.3)
Deï¬ne xt = x0 + t(x1 âˆ’x0) = tx1 + (1 âˆ’t)x0, we have xt âˆˆS for all t âˆˆ(0, 1)
due to the convexity of S. For t > 0 small enough, one has xt âˆˆU(x0). As each fk
is convex on S, we derive
fk(xt) â‰¦t fk(x1) + (1 âˆ’t) fk(x0) = fk(x0) + t( fk(x1) âˆ’fk(x0)),
k = 1, . . . , q.
Hence,
f (xt) â‰¦f (x0) + t( f (x1) âˆ’f (x0)) = f (x0) + d,
where
d = t( f (x1)
âˆ’f (x0)) âˆˆâˆ’Rq
+ \ {0} by (11.3). Therefore, f (xt) âˆ’f (x0) âˆ’d âˆˆâˆ’Rq
+, and con-
sequently f (xt) âˆ’f (x0) âˆˆd âˆ’Rq
+ âŠ‚âˆ’Rq
+ \ {0} since d âˆˆâˆ’Rq
+ \ {0}. This is a
contradiction to (11.2). Thus, x0 âˆˆE( f, S).
â–¡
We can improve this result with some weaker assumptions. Recall that quasicon-
vex functions were introduced in Deï¬nition 3.18, p. 65.
Theorem 11.16 (Ruiz-Canales and Ruï¬Ã¡n-Lizana [12]) Assume that S is a convex
set and each component fk : X â†’R, k = 1, . . . , q, is quasiconvex on S and at least
one is strictly quasiconvex on S. Then every local efï¬cient solution is a global efï¬cient
solution.
Proof Recall that g : S â†’R is quasiconvex on S if for all x1, x2 âˆˆS, and all t âˆˆ
(0, 1) one has g(tx1 + (1 âˆ’t)x2 â‰¦max{g(x1), g(x2)}, with strict inequality if g is
strictly quasiconvex and x1 Ì¸= x2.
By assumption there exists a neighborhood U(x0) of x0 such that x0 âˆˆE( f, S âˆ©
U(x0)).
As above, by contradiction, let us assume that x0 is not global efï¬cient. Then there
exists x1 âˆˆS such that
fk(x1) â‰¦fk(x0) âˆ€k = 1, . . . , q and fi(x1) < fi(x0) for some i âˆˆ{1, . . . , q}.
(11.4)
Deï¬ne xt = x0 + t(x1 âˆ’x0) = tx1 + (1 âˆ’t)x0, we have xt âˆˆS for all t âˆˆ(0, 1)
due to the convexity of S. For t > 0 small enough, one has xt âˆˆU(x0). As fk is qua-
siconvex on S, from (11.4) it follows fk(xt) â‰¦fk(x0), for k = 1, . . . , q. Moreover,
as f j is strictly quasiconvex on S for some j âˆˆ{1, . . . , q} one has f j(xt) < f j(x0).
We have obtained a contradiction to the fact that x0 âˆˆE( f, S âˆ©U(x0)) since
xt âˆˆS âˆ©U(x0) and f (xt) âˆ’f (x0) âˆˆâˆ’Rq
+ \ {0}.
Let us observe that the second condition in (11.4) has only been used to assure
that x1 Ì¸= x0.
â–¡
Next we are going to give a geometrical characterization for the sets E( f, S),
W( f, S) and sE( f, S). To this aim, recall and introduce the level sets of a func-
tion g : S â†’R. Given x0 âˆˆS, the sets levâ‰¦(g, g(x0)) = {x âˆˆS : g(x) â‰¦g(x0)},

11.1 Optimality Notions
391
lev=(g, g(x0)) = {x âˆˆS : g(x) = g(x0)}
and
lev<(g, g(x0)) = {x âˆˆS : g(x)
< g(x0)} are called level set, level curve and strict level set of g at x0. Obviously,
lev<(g, g(x0)) âŠ‚levâ‰¦(g, g(x0)) and x0 âˆˆlev=(g, g(x0)) âŠ‚levâ‰¦(g, g(x0)).
Theorem 11.17 (Ehrgott [1], Theorem 2.20) Let f : S âŠ‚Rn â†’Rq, x0 âˆˆS and
deï¬ne y0
k = fk(x0), k = 1, . . . , q. Then
(i) x0 is efï¬cient â‡”q
k=1 levâ‰¦( fk, y0
k ) = q
k=1 lev=( fk, y0
k ).
(ii) x0 is weak efï¬cient â‡”q
k=1 lev<( fk, y0
k ) = âˆ….
(iii) x0 is strictly efï¬cient â‡”q
k=1 levâ‰¦( fk, y0
k ) = {x0}.
The proof is easy and it is left to the reader. This theorem is useful when the
level sets are geometrically known when n â‰¦3. We illustrate this theorem with two
examples.
Example 11.18 Consider the unconstrained biobjective Pareto problem:
(M P1)
min f (x) = [x2 + 2x, x2 âˆ’6x + 5]âŠ¤subject to x âˆˆR.
In this example, it is easy to obtain all the efï¬cient points by applying the method
of level sets. If we select a point a in the feasible set R, the set of feasible points that
improve it with respect to f1 are those that verify f1(x) â‰¦f1(a), that is the interval
[b, a] (see Fig. 11.2). Similarly, the set of those points that improve it with respect
to f2 is given by the interval [a, c], so âˆ©2
k=1 levâ‰¦( fk, fk(a)) = [b, a] âˆ©[a, c] = {a},
and by using part (iii) in Theorem 11.17 a is strictly efï¬cient. Therefore, it is clear
that if the point a is between the abscissas of the vertices of the two parabolas, the
above condition is veriï¬ed and consequently all points in [âˆ’1, 3] are strict efï¬cient.
If a is outside the previous interval, the intersection no longer reduces to the point
a, and, therefore, it is not efï¬cient (not even weak). In conclusion, the set of strict
efï¬cient points is [âˆ’1, 3]. Moreover, W( f, R) = E( f, R) = [âˆ’1, 3].
Example 11.19 Consider now the constrained biobjective Pareto problem:
(M P1)
min f (x, y) =

x, y2
2x
âŠ¤
subject to
â§
â¨
â©
âˆ’x âˆ’y + 8 â‰¦0
x + 2y âˆ’13 â‰¦0
âˆ’y âˆ’3 â‰¦0.
Determine if the points (9, âˆ’1)âŠ¤and (6, 2)âŠ¤are efï¬cient, weakly efï¬cient, or strictly
efï¬cient, by the method of level sets.
The feasible set S is the triangle with vertices A(3, 5), B(11, âˆ’3) and C(19, âˆ’3),
whose sides are AB : y = âˆ’x + 8, AC : x + 2y = 13 and BC : y = âˆ’3 (see
Fig. 11.3).
The strict level sets associated to the point (9, âˆ’1)âŠ¤are given by x < 9, y2
2x <
1
18.
The second one is the parabolic region 9y2 < x (we can assume that x > 0, because
the feasible set is contained in this half-plane). Since they cut into the interior of the

392
11
Introduction to Multiobjective Optimization
Fig. 11.2 Example 11.18. Method of level sets
Fig. 11.3 Example 11.19. Feasible set
feasible set S, from part (ii) of Theorem 11.17, it follows that (9, âˆ’1)âŠ¤is not weakly
efï¬cient (and, therefore, neither efï¬cient nor strict efï¬cient) (see Fig. 11.4).
The level sets associated to the point (6, 2)âŠ¤are given by x â‰¦6, y2
2x â‰¦
4
12. The
second one is the parabolic region 3
2 y2 â‰¦x. They only intersect with S in (6, 2)âŠ¤,
so taking into account part (iii) of Theorem 11.17 we conclude that the point (6, 2)âŠ¤
is strict efï¬cient (see Fig. 11.5).
Proper efï¬ciency
Proper efï¬cient points are efï¬cient points that satisfy a suitable property. There
are two important reasons to introduce proper efï¬cient points. First, some authors
observed that some efï¬cient points had undesirable properties. Second, mathematical
methods usually allow to obtain a subset of the efï¬cient set.

11.1 Optimality Notions
393
Fig. 11.4 Level sets for (9, âˆ’1)âŠ¤
Fig. 11.5 Level sets for (6, 2)âŠ¤
One of the ideas of proper efï¬ciency (particularly from Geoffrionâ€™s deï¬nition) is
that unbounded trade-offs between objectives are not allowed.
Until now there are many types of concepts of proper minimality. The notion
of proper Pareto minimality (or proper efï¬ciency) was ï¬rst introduced by Kuhn and
Tucker [10]. Then some further concepts of proper efï¬ciency were given by Geoffrion
[13], Borwein [14], Benson [15], Henig [16], etc.; see also Guerraggio et al. [17]
where the relationships between several notions are studied.
Deï¬nition 11.20 (Geoffrion [13]) A point x0 âˆˆS is said to be proper efï¬cient in
the sense of Geoffrion if it is efï¬cient and if there is a real number L > 0 such
that for all i and x âˆˆS satisfying fi(x) < fi(x0) there exists an index j such that
f j(x0) < f j(x) and
fi(x0) âˆ’fi(x)
f j(x) âˆ’f j(x0) â‰¦L.

394
11
Introduction to Multiobjective Optimization
According this deï¬nition, proper efï¬cient solutions are those efï¬cient solutions
that have bounded trade-offs between the objectives.
Deï¬nition 11.21 A point x0 âˆˆS is called proper efï¬cient
(a) in the sense of Borwein if
T

f (S) + Rq
+, f (x0)
	
âˆ©(âˆ’Rq
+) = {0}.
(b) in the sense of Benson if
cl

ray

f (S) + Rq
+ âˆ’f (x0)
		
âˆ©(âˆ’Rq
+) = {0}.
Recall that T (A, y0) denotes the Bouligand tangent cone (Deï¬nition 2.35, p. 47).
In this deï¬nition we can work with a set Y âŠ‚Rq and a point y0 âˆˆY because f
plays no role. In consequence, we say that y0 âˆˆY is a proper efï¬cient point of Y
(a) in the sense of Borwein if T (Y + Rq
+, y0) âˆ©(âˆ’Rq
+) = {0}.
(b) in the sense of Benson if cl

ray

Y + Rq
+ âˆ’y0		
âˆ©(âˆ’Rq
+) = {0}.
Remark 11.22 (a) Note that x0 âˆˆS is proper efï¬cient in the sense of Borwein (resp.,
Benson) if and only if f (x0) is a proper efï¬cient point of f (S) in the sense of Borwein
(resp., Benson).
(b) If y0 âˆˆY is proper efï¬cient of Y in the sense of Borwein, then it is also
efï¬cient.
Indeed, by contradiction assume that y0 is not an efï¬cient point of Y. Then there
exists y1 âˆˆY such that d = y1 âˆ’y0 âˆˆâˆ’Rq
+ \ {0}. Let us check that d is a feasible
direction to Y + Rq
+ at y0, i.e. d âˆˆF(Y + Rq
+, y0). Let t â‰§0, then
y0 + td = y0 + t(y1 âˆ’y0) = y1 + (1 âˆ’t)(y0 âˆ’y1) âˆˆY + Rq
+
âˆ€t âˆˆ[0, 1],
since y0 âˆ’y1 âˆˆRq
+ and 1 âˆ’t â‰§0. Therefore, by the deï¬nition d âˆˆF(Y + Rq
+, y0),
and by Remark 2.45, it follows that d âˆˆT (Y + Rq
+, y0). As d âˆˆâˆ’Rq
+ \ {0} we have
a contradiction with the fact that y0 is proper efï¬cient of Y in the sense of Borwein.
Next, we are going to introduce the notion of proper efï¬ciency in the sense of
Kuhn-Tucker. This notion is only deï¬ned when the feasible set is given by functional
constraints. These kinds of problems are very important in applications and we will
deal with them later. So we are going to study a multiobjective optimization problem
with inequality constraints and equality constraints as in Chap. 6, but there it was
with only one objective.
We consider the following multiobjective optimization problem:
(M P2)
â§
âªâªâ¨
âªâªâ©
min[ f1(x), . . . , fq(x)]âŠ¤
subject to: gi(x) â‰¦0, i = 1, . . . , m,
h j(x) = 0, j = 1, . . . , p < n,
x âˆˆX âŠ‚Rn,

11.1 Optimality Notions
395
where X âŠ‚Rn is an open set contained in the domains of the functions involved in
(M P2), fk, k âˆˆQ = {1, . . . , q}, gi, i âˆˆM = {1, . . . , m} and h j, j âˆˆP = {1, . . . ,
p < n}, are real-valued functions deï¬ned on Rn.
We make the assumptions that every fk, k âˆˆQ, every gi, i = 1, . . . , m, are (at
least) differentiable on X and that every h j, j = 1, . . . , p, is (at least) contin-
uously differentiable on X. We also denote f (x) = [ f1(x), . . . , fq(x)]âŠ¤, g(x) =
[g1(x), . . . , gm(x)]âŠ¤and h(x) = [h1(x), . . . , h p(x)]âŠ¤.
We denote by S2 the set of all feasible points of this problem, i.e.
S2 = {x âˆˆX : gi(x) â‰¦0, âˆ€i âˆˆM, h j(x) = 0, âˆ€j âˆˆP}.
Let us observe that this set was denoted by K5 in Chap. 6. Given x0 âˆˆS2, we denote by
I (x0) the set of indices of active constraints at x0, i.e. I (x0) = {i âˆˆM : gi(x0) = 0}.
Deï¬nition 11.23 Consider problem (M P2). A point x0 âˆˆS2 is said to be proper
efï¬cient in the sense of Kuhn-Tucker if it is efï¬cient and if there is no d âˆˆRn
satisfying
âˆ‡fk(x0)âŠ¤d â‰¦0, âˆ€k âˆˆ{1, . . . , q},
âˆ‡fk(x0)âŠ¤d < 0, for some k âˆˆ{1, . . . , q},
âˆ‡gi(x0)âŠ¤d â‰¦0, âˆ€i âˆˆI (x0),
âˆ‡h j(x0)âŠ¤d = 0, âˆ€j = 1, . . . , p.
â«
âªâªâ¬
âªâªâ­
(11.5)
Next we study the relations between these notions. See also Ehrgott [1], Sawaragi
et al. [3] and Guerraggio et al. [17].
We say that a set A âŠ‚Rq is Rq
+-convex if A + Rq
+ is a convex set. Clearly, if A
is convex, then A is Rq
+-convex.
Lemma 11.24 Consider problem (M P1). If S is convex and each fk, k = 1, . . . , q,
is convex on S, then f (S) is Rq
+-convex.
Proof Let x1, x2 âˆˆS, d1, d2 âˆˆRq
+ and t âˆˆ[0, 1]. We have to prove that
yt = t( f (x1) + d1) + (1 âˆ’t)( f (x2) + d2)
= t f (x1) + (1 âˆ’t) f (x2) + td1 + (1 âˆ’t)d2 âˆˆf (S) + Rq
+.
(11.6)
Each fk is convex on S, and so fk(xt) â‰¦t fk(x1) + (1 âˆ’t) fk(x2), for k =
1, . . . , q where xt = tx1 + (1 âˆ’t)x2 âˆˆS due to the convexity of S. Hence, f (xt) â‰¦
t f (x1) + (1 âˆ’t) f (x2), that is t f (x1) + (1 âˆ’t) f (x2) âˆˆf (xt) + Rq
+. Therefore, in
view of (11.6)
yt âˆˆf (xt) + Rq
+ + td1 + (1 âˆ’t)d2 âŠ‚f (S) + Rq
+
because Rq
+ + td1 + (1 âˆ’t)d2 âŠ‚Rq
+ + Rq
+ = Rq
+ since Rq
+ is a convex cone.
â–¡
A function f : S âŠ‚Rn â†’Rq such that f (S) + Rq
+ is a convex set is called
convex-like on S.

396
11
Introduction to Multiobjective Optimization
Theorem 11.25 Let Y âŠ‚Rq, y0 âˆˆY.
(i) If y0 is proper efï¬cient of Y in the sense of Benson, then it is also proper efï¬cient
in the sense of Borwein.
(ii) If Y is Rq
+-convex, then both deï¬nitions coincide.
(iii) Consider problem (M P1) and x0 âˆˆS. If S is convex and each fk, k = 1, . . . , q,
is convex on S, then x0 is proper efï¬cient in the sense of Benson if and only it is
proper efï¬cient in the sense of Borwein.
Proof (i) It is a direct consequence of the inclusion T (A, y0) âŠ‚cl ray(A âˆ’y0) (see
the proof of Theorem 2.41) with A = Y + Rq
+.
(ii) Since Y + Rq
+ is convex by assumption, it follows from Theorem 2.41 that
T (Y + Rq
+, y0) = cl cone

Y + Rq
+ âˆ’y0	
, and so the statement is obvious.
(iii) It follows from part (ii) in view of Lemma 11.24 and Remark 11.22(a) choos-
ing Y = f (S) and y0 = f (x0).
â–¡
Theorem 11.26 (Benson [15]) Consider problem (M P1). A feasible point x0 âˆˆS is
proper efï¬cient in the sense of Benson if and only if it is proper efï¬cient in the sense
of Geoffrion.
Proof Geoffrion â‡’Benson. Suppose x0 is efï¬cient, but not properly efï¬cient in
Bensonâ€™s sense. Then, we know that a nonzero d âˆˆcl(ray( f (S) + Rq
+ âˆ’f (x0))) âˆ©
(âˆ’Rq
+) exists. Without loss of generality we may assume that d1 < âˆ’1, dk â‰¦0,
k = 2, . . . , q (otherwise we can reorder the components of f and rescale d). Conse-
quently, there are sequences {tn} âŠ‚R, tn > 0, for each n, {xn} âŠ‚S, {rn} âŠ‚Rq
+ such
that tn( f (xn) + rn âˆ’f (x0)) â†’d.
Choosing a subsequence if necessary, we can assume that ËœQ = {k âˆˆ{1, . . . , q} :
fk(xn) > fk(x0)} is the same for all n and nonempty since x0 is efï¬cient. Moreover,
1 /âˆˆËœQ because tn( f1(xn) + rn
1 âˆ’f1(x0)) â†’d1 < âˆ’1 and so f1(xn) âˆ’f1(x0) <
âˆ’1/tn for all n large enough since rn
1 â‰§0. Let L > 0. From convergence we get
existence of n0 such that for all n â‰§n0
f1(xn) âˆ’f1(x0) < âˆ’1
tn
(11.7)
and
fk(xn) âˆ’fk(x0) â‰¦
1
Ltn
, k = 2, . . . , q.
(11.8)
In particular, for k âˆˆËœQ , we have
0 < fk(xn) âˆ’fk(x0) â‰¦
1
Ltn
, âˆ€n â‰§n0
(11.9)
and, therefore, from (11.7) and (11.9)

11.1 Optimality Notions
397
f1(x0) âˆ’f1(xn)
fk(xn) âˆ’fk(x0) >
1
tn
1
Ltn
= L.
(11.10)
Because L was arbitrarily chosen, x0 is not properly efï¬cient in Geoffrionâ€™s sense.
Benson â‡’Geoffrion. Suppose now that x0 is efï¬cient, but not properly efï¬cient
in Geoffrionâ€™s sense. Let Ln > 0 be an unbounded sequence of positive real numbers.
Without loss of generality we assume that for each n there is an xn âˆˆS such that
f1(xn) < f1(x0) and
f1(x0) âˆ’f1(xn)
fk(xn) âˆ’fk(x0) > Ln, âˆ€k âˆˆ{2, . . . , q} with fk(xn) > fk(x0).
(11.11)
Choosing a subsequence if necessary, we can assume
ËœQ = {k âˆˆ{2, . . . , q} : fk(xn) > fk(x0)}
is constant for all n and nonempty since x0 is efï¬cient. We are going to construct
appropriate sequences {tn} and {rn} such that the sequence tn( f (xn) + rn âˆ’f (x0))
converges to some d âˆˆcl(ray( f (S) + Rq
+ âˆ’f (x0))) âˆ©(âˆ’Rq
+) with d Ì¸= 0.
Deï¬ne tn = ( f1(x0) âˆ’f1(xn))âˆ’1 > 0 for all n. Deï¬ne now rn âˆˆRq
+ through
rn
k :=

0,
if k = 1 or k âˆˆËœQ,
fk(x0) âˆ’fk(xn), otherwise.
(11.12)
With these sequences we have
tn( fk(xn) + rn
k âˆ’fk(x0))
â§
â¨
â©
= âˆ’1,
if k = 1,
= 0,
if k Ì¸= 1, k /âˆˆËœQ,
âˆˆ(0, Lâˆ’1
n ), if k âˆˆËœQ.
(11.13)
This sequence converges due to the choice of Ln â†’âˆto some d âˆˆRq, where dk =
limnâ†’âˆtn( fk(xn) + rn
k âˆ’fk(x0))
for
k = 1, . . . , q.
Thus,
from
(11.13)
d1 = âˆ’1, dk = 0, k Ì¸= 1, k /âˆˆËœQ, dk = 0, k âˆˆËœQ. So d = (âˆ’1, 0, . . . , 0) âˆˆcl(ray
( f (S) + Rq
+ âˆ’f (x0)) âˆ©(âˆ’Rq
+), and so x0 is not properly efï¬cient in Bensonâ€™s
sense.
â–¡
Lemma 11.27 Assume that f : X âŠ‚Rn â†’Rq is differentiable and X is an open
set. Let y âˆˆRn, {x j} âŠ‚Rn be a sequence converging to x0 âˆˆX and t j > 0 with
t j â†’0. If lim jâ†’âˆx jâˆ’x0
t j
= y, then
lim
jâ†’âˆ
f (x j) âˆ’f (x0)
t j
= âˆ‡f (x0)y.
Proof Let y j = x jâˆ’x0
t j
â†’y and so x j = x0 + t j y j.

398
11
Introduction to Multiobjective Optimization
If there are inï¬nite j âˆˆN such that x j = x0, then clearly y j = 0 for inï¬nite j and
so y j â†’0 = y. And also lim jâ†’âˆ
f (x j)âˆ’f (x0)
t j
= 0 = âˆ‡f (x0)y.
Therefore, we can assume that x j Ì¸= x0 for all j and so y j Ì¸= 0 for all j. As
f is differentiable at x0, one has by deï¬nition limxâ†’x0 f (x)âˆ’f (x0)âˆ’âˆ‡f (x0)(xâˆ’x0)
âˆ¥xâˆ’x0âˆ¥
= 0.
Replacing x by x j = x0 + t j y j, it follows that lim jâ†’âˆ
f (x j)âˆ’f (x0)âˆ’t jâˆ‡f (x0)y j
t jâˆ¥y jâˆ¥
= 0.
As âˆ¥y jâˆ¥â†’âˆ¥yâˆ¥, one has that the sequence {y j} is bounded, and we derive that
lim jâ†’âˆ
f (x j)âˆ’f (x0)âˆ’t jâˆ‡f (x0)y j
t j
= 0. From here, the thesis follows.
â–¡
Theorem 11.28 (Geoffrion [13]) Consider problem (M P2) and x0 âˆˆS2. Assume
that the involved functions are differentiable at x0 and x0 satisï¬es the Abadie con-
straint qualiï¬cation (see p. 185). If x0 is proper efï¬cient in the sense of Geoffrion,
then x0 is proper efï¬cient in the sense of Kuhn-Tucker.
Proof Suppose x0 is efï¬cient, but not properly efï¬cient in the sense of Kuhn-Tucker.
Then there is some d âˆˆRn such that (without loss of generality, after renumbering
the objectives)
âˆ‡fk(x0)âŠ¤d â‰¦0, âˆ€k âˆˆ{2, . . . , q},
âˆ‡f1(x0)âŠ¤d < 0,
âˆ‡gi(x0)âŠ¤d â‰¦0, âˆ€i âˆˆI (x0),
âˆ‡h j(x0)âŠ¤d = 0, âˆ€j = 1, . . . , p.
â«
âªâªâ¬
âªâªâ­
(11.14)
By the Abadie constraint qualiï¬cation one has L(x0) = T (S2, x0), and as d âˆˆL(x0)
by (11.14), we have d âˆˆT (S2, x0). This means that there exist sequences xn â†’x0
and tn â†’0+ such that xn âˆˆS for all n and xnâˆ’x0
tn
â†’d.
By Lemma 11.27, one has limnâ†’âˆ
f1(xn)âˆ’f1(x0)
tn
= âˆ‡f1(x0)âŠ¤d < 0, and so f1(xn)
âˆ’f1(x0) < 0 for all n large enough. Taking a subsequence if necessary we can
assume that the set
ËœQ = {k âˆˆ{2, . . . , q} : fk(xn) > fk(x0)}
is the same for all n and nonempty since x0 is efï¬cient.
By Lemma 11.27, we have limnâ†’âˆ
fk(xn)âˆ’fk(x0)
tn
= âˆ‡fk(x0)âŠ¤d â‰§0 for all k âˆˆËœQ.
In view of (11.14) one has âˆ‡fk(x0)âŠ¤d â‰¦0, and therefore,
âˆ‡fk(x0)âŠ¤d = 0, âˆ€k âˆˆËœQ.
But since âˆ‡f1(x0)âŠ¤d < 0, the latter imply that for k âˆˆËœQ one has
lim
nâ†’âˆ
f1(x0) âˆ’f1(xn)
fk(xn) âˆ’fk(x0) = lim
nâ†’âˆ
f1(xn)âˆ’f1(x0)
tn
fk(xn)âˆ’fk(x0)
tn
= +âˆ
because limnâ†’âˆ
fi(xn)âˆ’fi(x0)
tn
= âˆ‡fi(x0)âŠ¤d for all i by Lemma 11.27. Hence x0 is
not properly efï¬cient in Geoffrionâ€™s sense.
â–¡

11.2 The Weighted Sum Method and Relations with Proper Efï¬ciency
399
The original proof given by Geoffrion uses the Kuhn-Tucker constraint qualiï¬-
cation, but we know that this constraint qualiï¬cation implies the Abadie constraint
qualiï¬cation (see p. 185).
The converse implication of Theorem 11.28 is true under convexity. It is not
necessarily a constraint qualiï¬cation because really convexity is yet a constraint
qualiï¬cation (see the Slater constraint qualiï¬cation at p. 187). The following theorem
is a consequence of some results in the next Sect. 11.3, but we present it here for
completeness.
Theorem 11.29 (Geoffrion[13])Assumethat fk,k = 1, . . . , q and gi,i = 1, . . . , m,
are convex and h j, j = 1, . . . , p are linear afï¬ne. If x0 âˆˆS2 is proper efï¬cient in the
sense of Kuhn-Tucker, then x0 is proper efï¬cient in the sense of Geoffrion.
Proof By Theorem 11.48(i), conditions (a), (b), (c) in that theorem are satisï¬ed,
and by Corollary 11.49 we conclude that x0 is proper efï¬cient in the sense of
Geoffrion.
â–¡
We sketch the relationships obtained in the following scheme.
Borwein
(1)
â‡”
Benson â‡”Geoffrion
(1) (2)
â‡”
Kuhn-Tucker
(1) convexity, (2) Abadie c. q.
11.2
The Weighted Sum Method and Relations with Proper
Efï¬ciency
Most used method to solve a multiobjective optimization problem (in short, MOP) is
scalarization. Scalarization means that the problem is transformed into a scalar or a
family of scalar optimization problems, so we can use all powerful tools and methods
developed for scalar optimization problems. The solutions to the scalar problem are
some kind of solution to the MOP. In this introductory chapter, we will only deal
with linear scalarization, or in other words, the Weighted Sum Method.
Theideaofthismethodistoassociateaweightcoefï¬cientwk â‰§0 toeachobjective
fk and minimize the weighted sum of the objectives. To be more precise, consider
the following scalar optimization problem:
(Pw)
min wâŠ¤f (x) =
q

k=1
wk fk(x) subject to x âˆˆS,
where f = ( f1, . . . , fq)âŠ¤: X âŠ‚Rn â†’Rq, X is an open set, w = (w1, . . . , wq)âŠ¤âˆˆ
Rq
+ and S âŠ‚X.

400
11
Introduction to Multiobjective Optimization
The set of solutions of (Pw) is denoted by argmin(wâŠ¤f, S).
Let Y be a nonempty subset of Rq. We denote
argmin(wâŠ¤, Y) = {y0 âˆˆY : wâŠ¤y0 â‰¦wâŠ¤y, âˆ€y âˆˆY},
Pos(Y) = âˆªwâˆˆRq
+\{0} argmin(wâŠ¤, Y) and
Pos>(Y) = âˆªwâˆˆint Rq
+ argmin(wâŠ¤, Y).
It is clear that Pos>(Y) âŠ‚Pos(Y).
In this section, we study the relationships between the solutions of the scalar
problem minyâˆˆY wâŠ¤y with w â‰§0, w Ì¸= 0 or w > 0 and the efï¬cient or weak efï¬cient
points of Y, and between solutions of (Pw) and solutions of (M P1).
Theorem 11.30 (i) Pos(Y) âŠ‚W(Y).
(ii) If Y is Rq
+-convex, then Pos(Y) = W(Y).
Proof (i) Let w âˆˆRq
+ \ {0} and y0 âˆˆPos(Y). Then wâŠ¤y0 â‰¦wâŠ¤y for all y âˆˆY.
Suppose that y0 /âˆˆW(Y). Then there is some yâ€² âˆˆY with yâ€²
k < yk for k =
1, . . . , q. Thus, wâŠ¤yâ€² < wâŠ¤y because at least one of the weights wk must be positive.
This is a contradiction and the result follows.
(ii) Taking into account part (i), we only have to prove that W(Y) âŠ‚Pos(Y).
Let y0 âˆˆW(Y). By Theorem 11.8(ii) we have that W(Y) âŠ‚W(Y + Rq
+) and so
y0 âˆˆW(Y + Rq
+). Then
(Y + Rq
+ âˆ’y0) âˆ©(âˆ’int(Rq
+)) = âˆ….
By hypothesis, the set Y + Rq
+ is convex and so Y + Rq
+ âˆ’y0 is also a convex set.
By a separation theorem (see Theorem 2.20), there exist w âˆˆRq \ {0} and Î± âˆˆR
such that
wâŠ¤(y + d âˆ’y0) â‰§Î± â‰§wâŠ¤(âˆ’dâ€²),
âˆ€y âˆˆY, d âˆˆRq
+, dâ€² âˆˆint(Rq
+).
(11.15)
On the one hand, choosing y = y0 and d = 0 we derive that 0 â‰§Î±. On the other
hand, choosing dâ€² = td0 with d0 âˆˆint(Rq
+) and t > 0, it follows that Î± â‰§wâŠ¤(âˆ’td0)
for all t > 0. Taking the limit as t â†’0+ we deduce that Î± â‰§0 and so Î± = 0. Thus in
view of (11.15), we have wâŠ¤dâ€² â‰§0 for all dâ€² âˆˆint(Rq
+). As the function y â†’wâŠ¤y
is continuous it follows that wâŠ¤dâ€² â‰§0 for all dâ€² âˆˆcl(int(Rq
+)) = Rq
+. In particular,
if we choose dâ€² = ek, where ek is the k-th unit vector, we obtain wk = wâŠ¤ek â‰§0, for
k = 1, . . . , q. Thus w âˆˆRq
+ \ {0}.
Finally, using (11.15) with d = 0 we get wâŠ¤(y âˆ’y0) â‰§0 for all y âˆˆY, or
equivalently, wâŠ¤y â‰§wâŠ¤y0 for all y âˆˆY, and, therefore, y0 âˆˆargmin(wâŠ¤, Y) âŠ‚
Pos(Y).
â–¡

11.2 The Weighted Sum Method and Relations with Proper Efï¬ciency
401
Theorem 11.31 Pos>(Y) âŠ‚E(Y).
Proof Let y0 âˆˆPos>(Y). Then there is some w âˆˆint Rq
+ satisfying wâŠ¤y0 â‰¦wâŠ¤y for
all y âˆˆY. Suppose y0 /âˆˆE(Y). Hence there exists yâ€² âˆˆY with yâ€² â‰¦y and yâ€² Ì¸= y, and
multiplying componentwise by the weights gives wk yâ€²
k â‰¦wk y0
k for all k = 1, . . . , q
and strict inequality for at least one k. This strict inequality together with the fact
that all wk are positive implies that wâŠ¤yâ€² < wâŠ¤y0, contradicting the fact that y0 âˆˆ
Pos>(Y).
â–¡
Corollary 11.32 If Y is Rq
+-convex, then E(Y) âŠ‚Pos(Y).
It follows from Theorem 11.30(ii) and the fact that E(Y) âŠ‚W(Y).
Theorem 11.33 If y0 is the unique element of argmin(wâŠ¤, Y) for some w âˆˆRq
+ \
{0}, then y0 âˆˆE(Y).
As usual, the proof is â€œby contradictionâ€ and is left to the reader because it does
not have difï¬culty.
Next, we obtain the corresponding results for problem (M P1) from the above
results.
Theorem 11.34 Consider problem (M P1). Suppose that x0 âˆˆS is a solution of
problem (Pw) for some w âˆˆRq
+ \ {0}. Then the following statements hold:
(i) If w âˆˆRq
+ \ {0}, then x0 âˆˆW( f, S).
(ii) If w âˆˆint Rq
+, then x0 âˆˆE( f, S).
(iii) If w âˆˆRq
+ \ {0} and x0 is the unique solution of (Pw), then x0 âˆˆsE( f, S).
Proof The assertions are immediate consequences of Theorems 11.30(i), 11.31 and
11.33 taking into account relation (11.1).
â–¡
Now we will state the relationships between proper efï¬cient points and solutions
of the problem minyâˆˆY wâŠ¤y.
We denote by Be(Y) the set of all proper efï¬cient points of Y in the sense of
Benson.
Lemma 11.35 Let C âŠ‚Rq be a closed cone. If there exists w âˆˆint Rq
+ such that
wâŠ¤y â‰§0 for all y âˆˆC, then C âˆ©âˆ’Rq
+ = {0}.
The converse statement is true if, in addition, C is convex.
Proof Assume by contradiction that there exists y âˆˆC âˆ©âˆ’Rq
+, with y Ì¸= 0. Then,
on the one hand, as y âˆˆâˆ’Rq
+, y Ì¸= 0 and w âˆˆint(Rq
+) we have wâŠ¤y < 0. On the
other hand, as y âˆˆC, by assumption it follows wâŠ¤y â‰§0, which is a contradiction.
Now assume that C âˆ©âˆ’Rq
+ = {0}. Let q =

y âˆˆRq
+ : q
k=1 yk = 1

. Clearly
q is a compact convex set contained in Rq
+ \ {0}, and from the assumption, we
derive that C âˆ©âˆ’q = âˆ…. By the strong separation theorem (Theorem 2.17), there
exist w âˆˆRq \ {0} and Î± âˆˆR such that
wâŠ¤c > Î± > âˆ’wâŠ¤y
âˆ€c âˆˆC, âˆ€y âˆˆq.
(11.16)

402
11
Introduction to Multiobjective Optimization
Choosing c = 0 âˆˆC, we obtain 0 > Î±, and in consequence
wâŠ¤y > 0 âˆ€y âˆˆq.
This condition implies that w > 0. Indeed, if we choose the point y = ek âˆˆq,
where ek is the kth unit vector, we have wk = wâŠ¤ek > 0 for all k âˆˆ{1, . . . , q}. Thus
w > 0.
Now, by contradiction, assume that wâŠ¤c0 < 0 for some c0 âˆˆC. Then tc0 âˆˆC
for all t > 0, and limtâ†’+âˆwâŠ¤(tc0) = âˆ’âˆ, which contradicts (11.16). Therefore,
wâŠ¤c â‰§0 for all c âˆˆC, and the proof is ï¬nished.
â–¡
Theorem 11.36 Pos(Y) âŠ‚Be(Y).
Proof Let y0 âˆˆPos>(Y). Then y0 âˆˆargmin(wâŠ¤, Y) for some w âˆˆint Rq
+, so wâŠ¤y0
â‰¦wâŠ¤y â‰¦wâŠ¤(y + d) for all y âˆˆY, d âˆˆRq
+. Therefore, wâŠ¤(y + d âˆ’y0) â‰§0, and
consequently, wâŠ¤z â‰§0 for all z âˆˆC = cl(ray(Y + Rq
+ âˆ’y0)). By using Lemma
11.35, we conclude that cl(ray(Y + Rq
+ âˆ’y0)) âˆ©âˆ’Rq
+ = {0}, that is,
y0 âˆˆ
Be(Y).
â–¡
Theorem 11.37 If Y is Rq
+-convex, then Pos>(Y) = Be(Y).
Proof We only have to prove Be(Y) âŠ‚Pos>(Y). Let y0 âˆˆBe(Y), then cl(ray(Y +
Rq
+ âˆ’y0)) âˆ©âˆ’Rq
+ = {0}. By hypothesis, Y + Rq
+ is a convex set, and so Y + Rq
+ âˆ’
y0 is also convex. By Theorem 2.6, ray(Y + Rq
+ âˆ’y0) = cone(Y + Rq
+ âˆ’y0) is a
convex cone. Hence C = cl(cone(Y + Rq
+ âˆ’y0)) is a closed convex cone and C âˆ©
âˆ’Rq
+ = {0}. By using Lemma 11.35, we conclude that there exists w âˆˆint(Rq
+) such
that wâŠ¤z â‰§0 for all z âˆˆcl(cone(Y + Rq
+ âˆ’y0)). From here, wâŠ¤(y + d âˆ’y0) â‰§0
for all y âˆˆY, d âˆˆRq
+. Choosing d = 0, it results that wâŠ¤y â‰§wâŠ¤y0 for all y âˆˆY,
which means that y0 âˆˆargmin(wâŠ¤, Y) âŠ‚Pos>(Y).
â–¡
Theorem 11.38 Assume S is convex and each fk, k = 1, . . . , q, is convex. Then
x0 âˆˆS is efï¬cient in the sense of Geoffrion if and only if x0 is a solution of the
problem (Pw) for some w âˆˆint(Rq
+).
Proof (â‡’) By Theorem 11.26, x0 is efï¬cient in the sense of Geoffrion if and only x0
is efï¬cient in the sense of Benson. In view of Remark 11.22(a), this statement is equiv-
alent to f (x0) âˆˆBe( f (S)). By Lemma 11.24, f (S) is Rq
+-convex, and using The-
orem 11.37 we derive Pos>( f (S)) = Be( f (S)). Therefore, f (x0) âˆˆPos>( f (S)),
which means that x0 is a solution of the problem (Pw) for some w âˆˆint(Rq
+).
(â‡) It is enough to revert the above reasoning.
â–¡
Theorem 11.39 IfY isRq
+-closedandRq
+-convex,thenBe(Y) âŠ‚E(Y) âŠ‚cl(Be(Y)).
We omit the proof because is very technical, it can be seen in Ehrgott [1], Theorem
3.17, or in Sawaragi et al. [3], Theorem 3.4.6 and Corollary 3.2.2.
The inclusion cl(Be(Y)) âŠ‚E(Y) is not always satisï¬ed, see Example 3.19 in
Ehrgott [1] or Example 3.4.2 in Sawaragi et al. [3], both examples are the same.

11.3 Optimality Conditions
403
The reader interested in delving into these topics is directed to Ehrgott [1] and
Sawaragi et al. [3].
We summarize the results obtained:
(i) If Y âŠ‚Rq then Pos>(Y) âŠ‚Be(Y) âŠ‚E(Y) and Pos(Y) âŠ‚W(Y).
(ii) If Y is Rq
+-convex then Pos(Y) = Be(Y) âŠ‚E(Y) âŠ‚cl(Pos>(Y)) = cl(Be(Y)).
11.3
Optimality Conditions
In this section, we study ï¬rst and second-order necessary and sufï¬cient optimal-
ity conditions for the general problem (M P1) and also for the problem deï¬ned by
inequality constraints and equality constraints (M P2).
We start providing optimality conditions for problem (M P1). We assume that
f : X âŠ‚Rn â†’Rq is differentiable and X is an open set.
Theorem 11.40 (General necessary condition) If x0 âˆˆS is a local weak efï¬cient
solution for (M P1), then the system
âˆ‡f (x0)y < 0
y âˆˆT (S, x0)
is incompatible in y âˆˆRn, i.e. âˆ‡f (x0)y /âˆˆâˆ’int Rq
+ for all y âˆˆT (S, x0).
Proof By contradiction, assume that âˆ‡f (x0)y âˆˆâˆ’int Rq
+ for some y âˆˆT (S, x0).
Then there exist sequences xk â†’x0 and tk â†’0+ such that xk âˆˆS and xkâˆ’x0
tk
â†’y.
By applying Lemma 11.27, we derive
f (xk)âˆ’f (x0)
tk
â†’âˆ‡f (x0)y âˆˆâˆ’int Rq
+. So, for
all k large enough one has f (xk)âˆ’f (x0)
tk
âˆˆâˆ’int Rq
+, and, therefore, f (xk) âˆ’f (x0) âˆˆ
âˆ’int Rq
+ for all k large enough, which contradicts the local weak efï¬ciency of x0
since xk â†’x0 and xk âˆˆS.
â–¡
Recall that the cones of linearized directions and strict linearized direction for
problem (M P2) are deï¬ned by
L(x0) = {y âˆˆRn : âˆ‡gi(x0)âŠ¤y â‰¦0, âˆ€i âˆˆI (x0); âˆ‡h j(x0)âŠ¤y = 0, âˆ€j âˆˆP},
Lo(x0) = {y âˆˆRn : âˆ‡gi(x0)âŠ¤y < 0, âˆ€i âˆˆI (x0); âˆ‡h j(x0)âŠ¤y = 0, âˆ€j âˆˆP}.
Of course, we can consider the constraint qualiï¬cations deï¬ned in Sect. 6.2
because only the constraints are involved, and not the objectives.
Next we establish the Fritz John necessary optimality conditions for problem
(M P2). Its proof follows the line of the proof of Theorem 6.3. We assume that the
involved functions are continuously differentiable on X.

404
11
Introduction to Multiobjective Optimization
Theorem 11.41 (Fritz John necessary conditions) Let x0 âˆˆS2 be a local weak efï¬-
cient solution for (M P2). Then there exist multipliers (â€œFritz John multipliersâ€)
(w, u, v) âˆˆRq Ã— Rm Ã— Rp such that
(i) q
k=1 wkâˆ‡fk(x0) + m
i=1 uiâˆ‡gi(x0) + p
j=1 v jâˆ‡h j(x0) = 0;
(ii) uigi(x0) = 0, i = 1, . . . , m;
(iii) w â‰§0, u â‰§0, and (w, u, v) Ì¸= 0.
Proof If the vectors

âˆ‡h1(x0), . . . , âˆ‡h p(x0)

are linearly dependent, the thesis of
the theorem is trivial. Assume, therefore, that these vectors are linearly independent.
From Theorem 6.1 it follows Lo(x0) âŠ‚T (S2, x0), and in view of Theorem 11.40 we
have that the system
âˆ‡f (x0)y < 0
y âˆˆL0(x0)
is incompatible in y âˆˆRn. Taking into account the deï¬nition of Lo(x0), the previous
statement is equivalent to say that the system
â§
â¨
â©
âˆ‡fk(x0)âŠ¤y < 0, k = 1, . . . , q,
âˆ‡gi(x0)âŠ¤y < 0, i âˆˆI (x0),
âˆ‡h j(x0)âŠ¤y = 0, j = 1, . . . , p
admits no solution y âˆˆRn. By Motzkinâ€™s theorem of the alternative (Theorem 2.31),
there exist vectors (w, u, v) âˆˆRq Ã— RI (x0) Ã— Rp such that (w, u) Ì¸= 0, w â‰§0, u â‰§0
and
q

k=1
wkâˆ‡fk(x0) +

iâˆˆI (x0)
uiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0) = 0.
By choosing ui = 0 for all indices i âˆˆ{1, . . . , m} \ I (x0), we obtain the
thesis.
â–¡
Conditions (i), (ii) and (iii) in Theorem 11.41, by analogy to Theorem 6.3, are
called Fritz John conditions.
Now, we state for (M P2) the Karush-Kuhn-Tucker optimality conditions.
Theorem 11.42 (Karush-Kuhn-Tucker) Let x0 âˆˆS2 be a local weak efï¬cient solu-
tion for (M P2) and let the Abadie constraint qualiï¬cation be satisï¬ed (page
185). Then there exist multipliers (â€œKarush-Kuhn-Tucker multipliersâ€) (w, u, v) âˆˆ
Rq Ã— Rm Ã— Rp such that
q

k=1
wkâˆ‡fk(x0) +
m

i=1
uiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0) = 0;
(11.17)
uigi(x0) = 0, i = 1, . . . , m;
(11.18)
w â‰§0, w Ì¸= 0, u â‰§0.
(11.19)

11.3 Optimality Conditions
405
Proof By the Abadie constraint qualiï¬cation we have T (S2, x0) = L(x0) and in
view of Theorem 11.40 we have that the system
âˆ‡f (x0)y < 0,
y âˆˆL(x0)
is incompatible in y âˆˆRn. Taking into account the deï¬nition of L(x0), the previous
statement is equivalent to say that the system
â§
â¨
â©
âˆ‡fk(x0)âŠ¤y < 0, k = 1, . . . , q,
âˆ‡gi(x0)âŠ¤y â‰¦0, i âˆˆI (x0),
âˆ‡h j(x0)âŠ¤y = 0, j = 1, . . . , p
admits no solution y âˆˆRn. By Motzkinâ€™s theorem of the alternative (Theorem 2.31),
there exist vectors (w, u, v) âˆˆRq Ã— RI (x0) Ã— Rp such that w â‰§0, w Ì¸= 0, u â‰§0 and
q

k=1
wkâˆ‡fk(x0) +

iâˆˆI (x0)
uiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0) = 0.
If we choose ui = 0 for all i âˆˆ{1, . . . , m} \ I (x0), the thesis follows.
â–¡
This theorem has been proved e.g. in Singh [18], Theorem 3.1, and in Lin [19],
Theorem 7.1, under the Kuhn-Tucker constraint qualiï¬cation.
In contrast to Theorem 6.4, where it is required the Guignard-Gould-Tolle con-
straint qualiï¬cation, in Theorem 11.42 we require the Abadie constraint qualiï¬cation.
This is a gap between multiobjective optimization and scalar optimization that has
been pointed out by several authors [20â€“22]. We can show it in the following example.
Example 11.43 Let us consider the next multiobjective optimization problem:
(M P2) min f (x, y) = (x, y)âŠ¤subject to (x, y) âˆˆS,
where the feasible set is S = {(x, y) âˆˆR2 : (2x + y)(x + 2y) â‰¦0}.
It is easy to check that the point x0 = (0, 0) is an efï¬cient solution using e.g.
Theorem 11.17, that T (S, x0) = S and that cl co T (S, x0) = L(x0) = R2, that is,
the Guignard-Gould-Tolle c. q. is satisï¬ed. On the other hand, the Karush-Kuhn-
Tucker conditions are not satisï¬ed, since the condition (11.17) is only satisï¬ed with
w = (0, 0) and any value of u1. Note that the Abadie c. q. is not satisï¬ed.
Next we provide (ï¬rst-order) sufï¬cient conditions for global weak efï¬ciency for
problem(M P2)undergeneralizedconvexityfollowingthesameideasasinTheorems
6.6, 6.8 and 6.10.
Theorem 11.44 Let x0 âˆˆS2 be a point such that (x0, w, u, v) satisfy the Karush-
Kuhn-Tucker conditions (11.17)â€“(11.19) for some (w, u, v) âˆˆRq Ã— Rm Ã— Rp. Let

406
11
Introduction to Multiobjective Optimization
wâŠ¤f be pseudoconvex on the open convex set X âŠ‚Rn, let every gi, i âˆˆI (x0), be
quasiconvex on X and let every h j, j = 1, . . . , p, be quasiconvex and quasiconcave
on X. Then x0 is a weak efï¬cient solution of (M P2).
Proof We are applying Theorem 6.6. Let us observe that the functions F = wâŠ¤f =
q
k=1 wk fk, gi, i âˆˆI (x0), h j, j = 1, . . . , p, satisfy the assumptions of Theorem 6.6
at the point x0 with the multipliers (u, v), and consequently, x0 is a (global) solution
of the problem minxâˆˆS2 wâŠ¤f (x). As w â‰§0, w Ì¸= 0, from Theorem 11.34(i) it follows
that x0 is a weak efï¬cient solution of problem (M P2).
â–¡
Corollary 11.45 Let x0 âˆˆS2 be a feasible point of (M P2) and assume that every
fk, k = 1, . . . , q, and every gi, i âˆˆI (x0), are convex on the open convex set X âŠ‚Rn
and every h j, j = 1, . . . , p, is linear afï¬ne. If (x0, w, u, v) satisfy the Karush-Kuhn-
Tucker conditions (11.17)â€“(11.19) for some (w, u, v) âˆˆRq Ã— Rm Ã— Rp, then x0 is a
weak efï¬cient solution of (M P2).
Proof The function wâŠ¤f = q
k=1 wk fk is convex since wk â‰§0. By Theorem 3.26(i)
one has that wâŠ¤f is pseudoconvex and by Theorem 3.26(i)â€“(ii), each gi, i âˆˆI (x0),
is quasiconvex. Now, the conclusion follows from Theorem 11.44.
â–¡
Similarly to Theorem 6.8 we can give a version for the multiobjective problem
(M P2). We omit the proof because it is easy.
Theorem 11.46 Let x0 âˆˆS2 be a point such that (x0, w, u, v) satisfy the Karush-
Kuhn-Tucker conditions (11.17)â€“(11.19) for some (w, u, v) âˆˆRq Ã— Rm Ã— Rp, and
in addition, v â‰§0. Suppose that wâŠ¤f is pseudoconvex on the open convex set X âŠ‚Rn
and every gi, i âˆˆI (x0), and every h j, j = 1, . . . , p, is quasiconvex on X. Then x0
is a weak efï¬cient solution of (M P2).
Similarly to Theorem 6.10 we can provide a sufï¬cient condition of weak efï¬ciency
for problem (M P2) with strict pseudoconvexity, in this case based on the Fritz John
conditions.
Theorem 11.47 Let x0 âˆˆS2 be a point such that (x0, w, u, v) satisfy the Fritz John
conditions (i), (ii) and (iii) in Theorem 11.41 for some (w, u, v) âˆˆRq Ã— Rm Ã— Rp,
and in addition, v â‰§0. Suppose that every fk, k = 1, . . . , q, is pseudoconvex on the
open convex set X âŠ‚Rn and every gi, i âˆˆI (x0), and every h j, j = 1, . . . , p, is
strictly pseudoconvex on X. Then x0 is a weak efï¬cient solution of (M P2).
The proof is very similar to the proof of Theorem 6.10 changing f by fk, k =
1, . . . , q and so we omit it. Other sufï¬cient conditions using different convexities
of the involved functions are given in Singh [18], Lee [23], Aghezzaf and Hachimi
[20], Cambini and Martein [24] and Giorgi et al. [25].
Next we establish optimality conditions of proper efï¬ciency in the sense of Kuhn-
Tucker.

11.3 Optimality Conditions
407
Theorem 11.48 Consider a differentiable problem (M P2) and x0 âˆˆS2.
(i) If x0 is proper efï¬cient in the sense of Kuhn-Tucker, then there exist multipliers
(w, u, v) âˆˆRq Ã— Rm Ã— Rp such that
(a) q
k=1 wkâˆ‡fk(x0) + m
i=1 uiâˆ‡gi(x0) + p
j=1 v jâˆ‡h j(x0) = 0;
(b) uigi(x0) = 0, i = 1, . . . , m;
(c) w > 0, u â‰§0.
(ii) Conversely, assume that the previous conditions (a), (b) and (c) are satisï¬ed,
wâŠ¤f is pseudoconvex on the open convex set X âŠ‚Rn, every gi, i âˆˆI (x0), is
quasiconvex on X and every h j, j = 1, . . . , p, is quasiconvex and quasiconcave
on X. Then x0 is proper efï¬cient in the sense of Kuhn-Tucker.
Proof (i) By hypothesis there is no d âˆˆRn satisfying system (11.5). Deï¬ning the
matrices
B = (âˆ‡fk(x0))k=1,...,q, C = (âˆ‡gi(x0))iâˆˆI (x0), D = (âˆ‡h j(x0)) j=1,...,p,
the incompatibility of system (11.5) is equivalent to saying that the system
Bd â‰¦0, Bd Ì¸= 0, Cd â‰¦0, Dd = 0
has no solution d âˆˆRn. By applying the theorem of the alternative of Tucker (p. 45),
there exist vectors (w, u, v) âˆˆRq Ã— RI (x0) Ã— Rp such that w > 0, u â‰§0 and
q

k=1
wkâˆ‡fk(x0) +

iâˆˆI (x0)
uiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0) = 0.
If we choose ui = 0 for all i âˆˆ{1, . . . , m} \ I (x0), the thesis follows.
(ii) By the theorem of the alternative of Tucker, saying that conditions (a), (b)
and (c) are satisï¬ed is equivalent to saying that system (11.5) has no solution. So we
only have to prove that x0 is efï¬cient.
Proceeding as in the proof of Theorem 11.44, by applying Theorem 6.6 to
F = wâŠ¤f instead of f , we derive that x0 is a (global) solution of the problem
minxâˆˆS2 wâŠ¤f (x). As w > 0, from Theorem 11.34(ii) it follows that x0 is an efï¬cient
solution of problem (M P2).
â–¡
Corollary 11.49 Let x0 âˆˆS2 and assume that every fk, k = 1, . . . , q, and every gi,
i âˆˆI (x0), are convex on the open convex set X âŠ‚Rn and let every h j, j = 1, . . . , p,
is linear afï¬ne. If conditions (a), (b), and (c) in Theorem 11.48 are satisï¬ed for some
(w, u, v), then x0 is proper efï¬cient in the sense of Kuhn-Tucker. If, in addition, every
gi, i âˆˆM \ I (x0), is convex, then x0 is also proper efï¬cient in the sense of Geoffrion.
Proof The proof of the fact that x0 is proper efï¬cient in the sense of Kuhn-Tucker
is as in the one of Corollary 11.45, but now we apply Theorem 11.48(ii) instead of
Theorem 11.44.

408
11
Introduction to Multiobjective Optimization
To prove the second part let us note that wâŠ¤f is convex, and so it is pseudocon-
vex, and every gi, i âˆˆI (x0) is quasiconvex. We have seen in the proof of Theorem
11.48(ii) that x0 is a solution of problem (Pw) with w > 0. In view of Theorem 11.38,
we conclude that x0 is proper efï¬cient in the sense of Geoffrion. We have been able
to apply Theorem 11.38 because S is a convex set since gi, i = 1, . . . , m, are convex
and h j, j = 1, . . . , m, are linear afï¬ne.
â–¡
To illustrate the previous results, we provide some examples.
Example 11.50 Consider the biobjective Pareto program with constraints:
min
f (x, y) = (6 âˆ’y, x)âŠ¤
subject to
âˆ’x + 7y âˆ’25 â‰¦0
x2 + y2 âˆ’25 â‰¦0.
Taking into account that the Abadie c. q. is veriï¬ed at every feasible point because
all involved functions are convex,
(a) obtain the points that satisfy the necessary Karush-Kuhn-Tucker conditions to
be a weak efï¬cient point, and
(b) which ones satisfy the necessary conditions in Theorem 11.48(i) to be a proper
efï¬cient point in the sense of Kuhn-Tucker?
(c) We are going to apply Theorem 11.42, conditions (11.17)â€“(11.19). We have
q = 2, m = 2, f1(x, y) = 6 âˆ’y, f2(x, y) = x, g1(x, y) = âˆ’x + 7y âˆ’25 and
g2(x, y) = x2 + y2 âˆ’25, so
âˆ‡f1(x, y) = (0, âˆ’1)âŠ¤, âˆ‡f2(x, y) = (1, 0)âŠ¤, âˆ‡g1(x, y) = (âˆ’1, 7)âŠ¤,
âˆ‡g2(x, y = (2x, 2y)âŠ¤,
and the equation (11.17) becomes
w1(0, âˆ’1)âŠ¤+ w2(1, 0)âŠ¤+ u1(âˆ’1, 7)âŠ¤+ u2(2x, 2y)âŠ¤= (0, 0)âŠ¤.
(11.20)
The feasible set S2 is given in Fig. 11.6. We also highlight there the points
A = (3, 4), B = (âˆ’4, 3) and C(âˆ’5, 0).
No point x0 = (x, y)âŠ¤in the interior of S2 veriï¬es the K-K-T necessary condi-
tions because g1(x0) < 0 and g2(x0) < 0, and, therefore, u1 = 0 and u2 = 0, con-
sequently, equation (11.20) has no solution verifying (11.19).
Now suppose that x0 is a point on segment AB. If x0 is not a extreme point of AB,
then g2 is not active (g2(x0) < 0), then u2 = 0 (by the Eq. (11.18)), and we have the
solution u1 = 1, u2 = 0, w1 = 7, w2 = 1. Solution that is also valid for x0 = A and
for x0 = B (although for these points, g2(A) = g2(B) = 0 and other solutions can
be found with u2 > 0).
If x0 is a feasible point of the arc of the circumference B A different from the
extremes, then g1 is not active (g1(x0) < 0), and, therefore, u1 = 0. Equation (11.20)
becomes

11.3 Optimality Conditions
409
Fig. 11.6 Example 11.50. Feasible set and points that satisfy Karush-Kuhn-Tucker conditions
w1(0, âˆ’1)âŠ¤+ w2(1, 0)âŠ¤+ u2(2x, 2y)âŠ¤= (0, 0)âŠ¤,
(11.21)
that is
w1 = 2yu2
w2 = âˆ’2xu2.
If u2 = 0, then w1 = w2 = 0 and (11.19) is not veriï¬ed. We can, therefore, assume
that u2 > 0 (speciï¬cally, we chose u2 = 1 to simplify, it could also be solved for
an arbitrary value u2 > 0). Since w1, w2 must be positive (at most one of them can
be 0), it follows that y â‰§0, x â‰¦0. Therefore, the only points of the arc B A that
verify the necessary conditions are those in the arc BC. For all of them, x < 0, so
w2 = âˆ’2x, and y > 0, so w1 = 2y = 2
âˆš
25 âˆ’x2. The only point for which w1 = 0
is C, but since w2 > 0, satisï¬es the Kuhn-Tucker condition.
In short, the only feasible points that verify the K-T necessary conditions are
the points of the segment AB and those of the arc BC, with all the extreme points
included (set that we will call T ). See Fig. 11.6.
(b) As we have seen in part (a), between the points that verify the K-T necessary
conditions, the only one for which there is no solution with w > 0 is C = (âˆ’5, 0).
Remarks:
1. By Corollary 11.45, taking into account that all functions fk, gi are convex, and
there is a solution with w â‰§0, w Ì¸= 0, it follows that all points in T are weak
efï¬cient.
2. ByCorollary11.49,itfollowsthatthepointsintheset T \ {C}areproperefï¬cient
solutions in the Kuhn-Tucker sense and also in the Geoffrion sense.

410
11
Introduction to Multiobjective Optimization
Example 11.51 Consider Example 11.19 and determine all the points that verify the
Karush-Kuhn-Tucker necessary conditions. Which are proper efï¬cient? and weak
efï¬cient? We leave the development to the reader as an exercise and we provide only
the solution.
(a) There is a solution with w > 0 at the points (8 âˆ’y, y) with 0 < y â‰¦5.
(b) There is a solution with w â‰§0, w Ì¸= 0, at the points (x, 0) with 8 â‰¦x â‰¦13.
Since all the functions are convex, the points for which exists w > 0 are proper in the
sense of Kuhn-Tucker and in the sense of Geoffrion (Corollary 11.49). By Corollary
11.45, all the points of parts (a) and (b) are weak efï¬cient. Using Theorem 11.17 one
can check that the only efï¬cient point, apart from the points of part (a), is (8, 0).
Example 11.52 Consider the biobjective Pareto program with constraints:
min f (x, y) =

x2 + y2 âˆ’8y, 2x + 2y
	âŠ¤
subject to
x2
2 âˆ’y â‰¦0.
Find all feasible points that satisfy the Kuhn-Tucker necessary conditions of weak
efï¬cient point or proper efï¬cient point in the Karush-Kuhn-Tucker sense, and know-
ing that all the functions are convex, determine which points of the previous ones
are proper efï¬cient in the Kuhn-Tucker sense. We also leave the development to the
reader as an exercise and we provide only the solution
Let us note that all the feasible points satisfy the linear independence c. q., and so
they also satisfy the Abadie c. q., and we can apply the Karush-Kuhn-Tucker con-
ditions (11.17)â€“(11.19) in Theorem 11.42. In this case, conditions (11.17)â€“(11.19)
become
w1(2x, 2y âˆ’8)âŠ¤+ w2(2, 2)âŠ¤+ u(x, âˆ’1)âŠ¤= (0, 0)âŠ¤,
(11.22)
w â‰§0, w Ì¸= 0, u â‰§0, ug(x, y) = 0.
We have that:
(a) There is a solution with w1 > 0 and w2 > 0 if âˆ’2 â‰¦x < âˆ’1, y = x2/2 or if
âˆ’2 < x < 0, y = x + 4. Since the program is convex, by Corollary 11.49, they
are Geoffrion proper efï¬cient points, and using the same Corollary 11.49), they
are also Kuhn-Tucker proper efï¬cient.
(b) There is a solution with w1 = 0 and w2 > 0, if x = âˆ’1, y = 1/2 and there is a
solution with w1 > 0 and w2 = 0, if x = 0, y = 4. In both cases, we can only
ensure that they satisfy the weak efï¬cient point necessary conditions (Theorem
11.42)andsincetheydonotsatisfythenecessaryconditionsofTheorem11.48(i),
we can say that they are not proper efï¬cient points in the Kuhn-Tucker sense.
The obtained points have been represented in Fig. 11.7.

11.3 Optimality Conditions
411
Fig. 11.7 Example 11.52.
Points that verify the n.c. of
K-K-T proper efï¬ciency
(red) and weak efï¬ciency
(blue)
Fig. 11.8 Example 11.53.
Feasible set
Example 11.53 Consider the biobjective Pareto program with constraints:
min f (x, y) =

x2 + y2, âˆ’x
	âŠ¤
subject to
4 âˆ’2y âˆ’x2 â‰¦0
y + x2 âˆ’10 â‰¦0.
Knowing that all feasible points satisfy the Abadie constraint qualiï¬cation (because
the linear independence c. q. is fulï¬lled), obtain all feasible points that verify the
Karush-Kuhn-Tucker necessary conditions of weak efï¬cient point or proper efï¬cient
point in the Kuhn-Tucker sense. Can we apply Corollary 11.49 to see if these points
are proper efï¬cient?
The feasible set for this program is given in Fig. 11.8.
We have f1 = x2 + y2, f2 = âˆ’x, g1 = 4 âˆ’2y âˆ’x2 y g2 = y + x2 âˆ’10, and so
Eq. (11.17) becomes
w1(2x, 2y)âŠ¤+ w2(âˆ’1, 0)âŠ¤+ u1(âˆ’2x, âˆ’2)âŠ¤+ u2(2x, 1)âŠ¤= (0, 0)âŠ¤,

412
11
Introduction to Multiobjective Optimization
that is
 2xw1 âˆ’w2 = 2xu1 âˆ’2xu2
2yw1
= 2u1 âˆ’u2
(11.23)
We study several cases depending on the feasible point is an interior or boundary
point in the feasible set.
(1) (x, y) is an interior point. Then u1 = 0, u2 = 0, and system (11.23) becomes
2xw1 âˆ’w2 = 0
2yw1
= 0,
(11.24)
which has a non-trivial solution (w Ì¸= 0), if and only if

2x âˆ’1
2y 0
 = 0, that is, if
and only if y = 0. From (11.24) we have that w2 = 2xw1. Therefore, there is a
solution w â‰§(0, 0), w Ì¸= (0, 0) if y = 0 and
â€¢ x > 0, any w1 > 0 and w2 = 2xw1 > 0;
â€¢ x = 0, any w1 > 0 and w2 = 0, which gives us the point (0, 0), but this point
is not feasible.
Since y = 0, points (x, 0) with 2 â‰¦x â‰¦
âˆš
10 and w > (0, 0) are feasible.
Although for x = 2 and x =
âˆš
10, the points (2, 0) and
âˆš
10, 0

are not interior
points, they satisfy the necessary conditions of K-K-T, and so in what follows
we can assume that y Ì¸= 0.
The solution of system (11.23) can be obtained, for example, by Cramerâ€™s rule
(we assume y Ì¸= 0), and is given by
â§
âªâ¨
âªâ©
w1 = 1
2y (2u1 âˆ’u2)
w2 = 2x Â· 1
2y (2u1 âˆ’u2) âˆ’2xu1 + 2xu2 = 2x(1 âˆ’y)
y
u1 + x(2y âˆ’1)
y
u2.
(11.25)
(2) If g2 is not active (u2 = 0) and g1 is active (y = 4âˆ’x2
2 ). The system (11.25) is
â§
âªâ¨
âªâ©
w1 =
2
4 âˆ’x2 u1
w2 = 2x(x2 âˆ’2)
4 âˆ’x2
u1.
This system has a solution with w1 â‰§0 and w2 â‰§0 if the following system is
fulï¬lled:
4 âˆ’x2 > 0
x(x2 âˆ’2) â‰§0.
â‡’
âˆ’2 < x < 2
âˆ’
âˆš
2 â‰¦x â‰¦0 or x â‰§
âˆš
2,

11.3 Optimality Conditions
413
whose solution (to obtain feasible points) is x âˆˆ

âˆ’
âˆš
2, 0

âˆª
âˆš
2, 2
	
, y =
4âˆ’x2
2 .
(3) If g1 is not active (u1 = 0) and g2 is active (y = 10 âˆ’x2). The solution of system
(11.25) now is
â§
âªâªâ¨
âªâªâ©
w1 =
âˆ’1
2(10 âˆ’x2)u2
w2 = x(2y âˆ’1)
y
u2 = x(19 âˆ’2x2)
10 âˆ’x2
u2.
There is a solution with w1 â‰§0 and w2 â‰§0 if the following system is fulï¬lled:
 10 âˆ’x2 < 0
x(19 âˆ’2x2) â‰¦0
â‡’

x < âˆ’
âˆš
10 or x >
âˆš
10
âˆ’âˆš19/2 â‰¦x â‰¦0 or x â‰§âˆš19/2,
whose solution is x âˆˆ
âˆš
10, 4

, y = 10 âˆ’x2, resulting w > 0 for these values.
(4) If g1 and g2 are active (then y = 4âˆ’x2
2
and y = 10 âˆ’x2), we obtain the points
(âˆ’4, âˆ’6) and (4, âˆ’6). We already know, from part 3), that for (4, âˆ’6) there
is a solution. Letâ€™s see what happens with the point (âˆ’4, âˆ’6). From (11.25) it
results:
 w1 =
1
12(u2 âˆ’2u1)
w2 = 2
3(14u1 âˆ’13u2).
There is a solution with w1 â‰§0 and w2 â‰§0 if the following system is fulï¬lled:
u2 âˆ’2u1 â‰§0, 14u1 âˆ’13u2 â‰§0.
But this system with u1 â‰§0, u2 â‰§0 only has the solution u1 = 0, u2 = 0 which
does not give a valid solution since it would be w = (0, 0).
In short: (a) There is a solution with w > 0 at the following points:
(a1) (x, 0) with 2 â‰¦x â‰¦
âˆš
10,
(a2) (x, y) with x âˆˆ

âˆ’
âˆš
2, 0
	
âˆª
âˆš
2, 2
	
, y = 4âˆ’x2
2 ,
(a3) (x, y) with x âˆˆ
âˆš
10, 4

, y = 10 âˆ’x2.
(b) There is a solution with w â‰§0, w Ì¸= 0, at the previous points, and also at the
points (x, y) with x âˆˆ

âˆ’
âˆš
2, 0,
âˆš
2

, y = 4âˆ’x2
2 , that is the points

âˆ’
âˆš
2, 1
	
,
(0, 2) and
âˆš
2, 1
	
(see Fig. 11.9).
Corollary 11.49 can be applied to the points in parts (a1) and (a3), except to the
point x0 = (2, 0) and x1 = (4, âˆ’6), and so they are proper efï¬cient in the sense
of Kuhn-Tucker. For the points x0, x1 and for the points in parts (a2) and (b),
Corollary 11.49 cannot be applied because the function g1(x, y) = 4 âˆ’2y âˆ’x2,
which is active, is not convex (note also that the feasible set is not convex).
Other procedures would have to be used to decide if the points that satisfy the
necessary conditions of K-K-T of Theorem 11.48(i) are proper efï¬cient points.
For example, in this case, if we consider the same biobjective Pareto problem

414
11
Introduction to Multiobjective Optimization
Fig. 11.9 Example 11.53.
Points that satisfy the K-K-T
necessary conditions
but now we replace the constraint 4 âˆ’2y âˆ’x2 â‰¦0 by âˆ’y âˆ’6 â‰¦0, it results
a convex problem whose feasible set contains the feasible set of the original
problem. Now, all the points in parts (a1) and (a3) satisfy Corollary 11.49 with
the same values of w, u and so they are proper efï¬cient in the senses of Kuhn-
Tucker, Geoffrion, and Benson, and the same happens for the original problem.
For other considerations, see also Exercise 11.79.
Next, we deï¬ne the notion of strict local efï¬cient point of order m for the general
problem (M P1). This notion was introduced by JimÃ©nez [26] generalizing the notion
given for a scalar function (Deï¬nition 1.11).
Deï¬nition 11.54 (JimÃ©nez[26])Letm â‰§1beanintegernumber.Wesaythat x0 âˆˆS
is a strict local efï¬cient (or Pareto minimal) point of order m for (M P1) if there are
a neighborhood U(x0) and a constant Î± > 0 such that
( f (x) + Rq
+) âˆ©U( f (x0), Î±âˆ¥x âˆ’x0âˆ¥m) = âˆ…,
âˆ€x âˆˆS âˆ©U(x0) \ {x0},
(11.26)
or equivalently
f (x) /âˆˆf (x0) + U(0, Î±âˆ¥x âˆ’x0âˆ¥m) âˆ’Rq
+,
âˆ€x âˆˆS âˆ©U(x0) \ {x0}.
(11.27)
This notion extends to multiobjective optimization the usual notion of a strict local
minimizer of order m (see Deï¬nition 1.11) for a scalar function. Indeed, if q = 1
then (11.27) becomes f (x) /âˆˆf (x0) + (âˆ’Î±âˆ¥x âˆ’x0âˆ¥m, Î±âˆ¥x âˆ’x0âˆ¥m) âˆ’R+, for all
x âˆˆS âˆ©U(x0) \ {x0}, which is equivalent to
f (x) â‰§f (x0) + Î±âˆ¥x âˆ’x0âˆ¥m,
âˆ€x âˆˆS âˆ©U(x0),
which is just the deï¬nition of a strict local minimizer of order m.

11.3 Optimality Conditions
415
Remark 11.55 Some basic properties are the following:
(i) Every strict local efï¬cient point of order m is also a strict local efï¬cient point of
order s for all s â‰§m.
(ii) Every strict local efï¬cient point of order m is also a strict local efï¬cient point.
The behavior under a linear application is stated in the next result.
Theorem 11.56 (JimÃ©nez and Novo [27], Proposition 2.7) Let A : Rq â†’Rs be a
linear application such that A(Rq
+) âŠ‚Rs
+. If x0 is a strict local efï¬cient point of
order m for Af on S (with respect to Rs
+), then x0 is a strict local efï¬cient point of
order m for f on S (with respect to Rq
+).
(Here, Af is the function (Af )(x) = A( f (x))).
Proof By assumption, there exist a neighborhood U of x0 and Î± > 0 such that
(Af (x) + Rs
+) âˆ©U(Af (x0), Î±âˆ¥x âˆ’x0âˆ¥m) = âˆ…âˆ€x âˆˆS âˆ©U \ {x0}.
(11.28)
As A is linear, it is also continuous. Hence there exists Î´ > 0 such that A(U(0, Î´)) âŠ‚
U(0, 1), and, therefore, A(U(0, 1)) âŠ‚U(0, Î²), where Î² = 1/Î´. In consequence, by
linearity
A(U(0, Ï)) âŠ‚U(0, ÏÎ²) âˆ€Ï > 0.
(11.29)
Let us prove that
( f (x) + Rq
+) âˆ©U( f (x0), Î±
Î² âˆ¥x âˆ’x0âˆ¥m) = âˆ…âˆ€x âˆˆS âˆ©U \ {x0}.
By contradiction, suppose that there exist Ë†x âˆˆS âˆ©U \ {x0} and d âˆˆRq
+ such that
f (Ë†x) + d âˆ’f (x0) âˆˆU(0, Î±
Î² âˆ¥Ë†x âˆ’x0âˆ¥m).
Then, from (11.29) we deduce that Af (Ë†x) + Ad âˆ’Af (x0) âˆˆU(0, Î±âˆ¥Ë†x âˆ’x0âˆ¥m)
with Ad âˆˆRs
+, contradicting (11.28).
â–¡
As a simple application we give an example.
Example 11.57 If x0 is a strict local minimizer of order m for fk on S for some
k âˆˆ{1, . . . , q}, then x0 is a strict local efï¬cient point of order m for f on S.
Indeed, we deï¬ne A : Rq â†’R by Ay = yk (the projection on the kth component).
Clearly, Af = fk and A(Rq
+) âŠ‚R+. Now the result follows from Theorem 11.56.
Next, in Theorem 11.59 we state a characterization for strict local efï¬cient points
of order 1 under differentiability. Previously we need a lemma.
Lemma 11.58 (JimÃ©nez [26], Proposition 3.4) Let x0 âˆˆS. Then x0 is not a strict
local efï¬cient point of order m for (M P1) if and only if there exist sequences {xn} âŠ‚
S \ {x0} and {dn} âŠ‚Rq
+, such that xn â†’x0 and

416
11
Introduction to Multiobjective Optimization
lim
nâ†’âˆ
f (xn) âˆ’f (x0) + dn
âˆ¥xn âˆ’x0âˆ¥m
= 0.
(11.30)
Proof â€œIfâ€ part. Since {xn} converges to x0 and (11.30) holds, for all Îµ > 0 there
exists n0 = n0(Îµ) such that for every n â‰§n0 we have xn âˆˆS, âˆ¥xn âˆ’x0âˆ¥< Îµ and
âˆ¥f (xn) âˆ’f (x0) + dnâˆ¥< Îµâˆ¥xn âˆ’x0âˆ¥m, that is,
f (xn) + dn âˆˆU( f (x0), Îµâˆ¥xn âˆ’
x0âˆ¥m).
Reasoning â€œad absurdumâ€, suppose x0 is a strict local efï¬cient point of order m
for (M P1). Then there exists a n.b.h. U(x0) = U(x0, Î´) and Î± > 0 such that (11.26)
holds. Now, for Îµ = min{Î´, Î±}, there exists n0 = n0(Îµ) such that for each n â‰§n0 we
have xn âˆˆS âˆ©U(x0, Î´) and
f (xn) + dn âˆˆU( f (x0), Îµâˆ¥xn âˆ’x0âˆ¥m) âŠ‚U( f (x0), Î±âˆ¥xn âˆ’x0âˆ¥m),
contradicting (11.26).
â€œOnly ifâ€ part. By assumption, for all Î´ > 0 and for all Î± > 0 there exists x âˆˆ
S âˆ©U(x0, Î´) \ {x0} such that
( f (x) + Rq
+) âˆ©U( f (x0), Î±âˆ¥x âˆ’x0âˆ¥m) Ì¸= âˆ….
In particular, for Î´ = 1/n and Î± = 1/n, there exist xn âˆˆS âˆ©U(x0, 1/n) \ {x0} and
dn âˆˆRq
+ such that
f (xn) + dn âˆˆU( f (x0), 1
n âˆ¥xn âˆ’x0âˆ¥m),
that is,
âˆ¥f (xn) + dn âˆ’f (x0)âˆ¥
âˆ¥xn âˆ’x0âˆ¥m
< 1
n ,
and the claim follows.
â–¡
Theorem 11.59 Assume that f is differentiable at x0 âˆˆS. Then x0 is a strict local
efï¬cient point of order 1 if and only if
âˆ€y âˆˆT (S, x0) \ {0} âˆƒk âˆˆ{1, . . . , q} such that âˆ‡fk(x0)âŠ¤y > 0,
or equivalently, T (S, x0) âˆ©D( f, x0) = {0}, where
D( f, x0) = {y âˆˆRn : âˆ‡fk(x0)âŠ¤y â‰¦0, k = 1, . . . , q}
is the cone of descent directions of f at x0.
Proof (â‡’) Let y âˆˆT (S, x0) âˆ©D( f, x0) and by contradiction assume that y Ì¸= 0.
Without lost of generality we can suppose that âˆ¥yâˆ¥= 1. As y âˆˆT (S, x0), there exists
a sequence xn â†’x0 with {xn} âŠ‚S \ {x0} and such that
xnâˆ’x0
âˆ¥xnâˆ’x0âˆ¥â†’y. By Lemma
11.27, we have

11.3 Optimality Conditions
417
lim
nâ†’âˆ
f (xn) âˆ’f (x0)
âˆ¥xn âˆ’x0âˆ¥
= âˆ‡f (x0)y.
(11.31)
On the other hand, as x0 is a strict local efï¬cient point of order 1, there exist a
neighborhood U(x0) and Î± > 0 such that f (x) /âˆˆf (x0) + U(0, Î±âˆ¥x âˆ’x0âˆ¥) âˆ’Rq
+,
for all x âˆˆS âˆ©U(x0) \ {x0}, or equivalently
f (x) âˆ’f (x0)
âˆ¥x âˆ’x0âˆ¥
âˆˆ[U(0, Î±) âˆ’Rq
+]c,
âˆ€x âˆˆS âˆ©U(x0) \ {x0}.
As xn â†’x0, there exists n0 such that xn âˆˆS âˆ©U(x0) \ {x0} for all n â‰§n0, and,
therefore,
f (xn)âˆ’f (x0)
âˆ¥xnâˆ’x0âˆ¥
âˆˆ[U(0, Î±) âˆ’Rq
+]c for all n â‰§n0. Since [U(0, Î±) âˆ’Rq
+]c is
a closed set, in view of (11.31) it follows that âˆ‡f (x0)y âˆˆ[U(0, Î±) âˆ’Rq
+]c. As
âˆ’Rq
+ âŠ‚U(0, Î±) âˆ’Rq
+, we conclude that âˆ‡f (x0)y /âˆˆâˆ’Rq
+, which contradicts the
assumption y âˆˆD( f, x0).
(â‡) By contradiction, assume that x0 is not a strict local efï¬cient point of order 1.
Then by Lemma 11.58 there exist sequences {xn} âŠ‚S \ {x0} and {dn} âŠ‚Rq
+, such
that xn â†’x0 and
lim
nâ†’âˆ
f (xn) âˆ’f (x0) + dn
âˆ¥xn âˆ’x0âˆ¥
= 0.
(11.32)
Without lost of generality we can suppose that
xnâˆ’x0
âˆ¥xnâˆ’x0âˆ¥â†’y âˆˆT (S, x0) with y Ì¸= 0,
and applying Lemma 11.27, we have limnâ†’âˆ
f (xn)âˆ’f (x0)
âˆ¥xnâˆ’x0âˆ¥
= âˆ‡f (x0)y. From (11.32)
it follows that limnâ†’âˆ
dn
âˆ¥xnâˆ’x0âˆ¥= âˆ’âˆ‡f (x0)y. From here and since
dn
âˆ¥xnâˆ’x0âˆ¥âˆˆRq
+ and
Rq
+ is closed, wederivethat âˆ‡f (x0)y âˆˆâˆ’Rq
+. Therefore, y âˆˆT (S, x0) âˆ©D( f, x0) \
{0}, which contradicts the hypothesis.
â–¡
Theorem 11.59 is contained in Theorem 4.8 in JimÃ©nez [26], but the proof here
is different.
Corollary 11.60 Consider problem (M P2) and x0 âˆˆS2. If L(x0) âˆ©D( f, x0) = {0},
then x0 is a strict local efï¬cient point of order 1 for (M P2).
It is a straightforward consequence of Theorem 11.59 since T (S2, x0) âŠ‚L(x0)
by Theorem 6.1.
Next we give an equivalent condition to the hypothesis of the previous corollary
in a more operative way.
Theorem 11.61 (Giorgi et al. [28], Theorem 3.4) Consider problem (M P2) and
x0 âˆˆS2 and assume that among the vectors

âˆ‡fk(x0)

k=1,...,q ,

âˆ‡gi(x0)

iâˆˆI (x0) ,

âˆ‡h j(x0)

j=1,...,p
there are n linearly independent. Then L(x0) âˆ©D( f, x0) = {0} if and only if there
exist Karush-Kuhn-Tucker multipliers wk > 0, k = 1, . . . , q, ui > 0, i âˆˆI (x0), v j âˆˆ

418
11
Introduction to Multiobjective Optimization
R, j = 1, . . . , p, such that
q

k=1
wkâˆ‡fk(x0) +

iâˆˆI (x0)
uiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0) = 0.
We omit the proof, which can be seen in the aforementioned reference.
Next, we provide a sufï¬cient condition for efï¬ciency of order 1 based on the Fritz
John conditions.
Theorem 11.62 Let x0 âˆˆS2 be a point satisfying the Fritz John conditions (i), (ii),
and (iii) in Theorem 11.41 for some (w, u, v) âˆˆRq Ã— Rm Ã— Rp. If the vectors

wkâˆ‡fk(x0)

k=1,...,q ,

uiâˆ‡gi(x0)

iâˆˆI (x0) ,

âˆ‡h j(x0)

j=1,...,p
span Rn, then x0 is a strict local efï¬cient solution of order 1 for (M P2).
Proof Suppose that x0 is not a strict local efï¬cient solution of order 1 for (M P2).
Then, by Theorem 11.59 there exists a vector y âˆˆT (S2, x0), y Ì¸= 0, such that
âˆ‡fk(x0)âŠ¤y â‰¦0, k = 1, . . . , q. By Theorem 6.1, we have T (S2, x0) âŠ‚L(x0), and
so y âˆˆL(x0), which means that âˆ‡gi(x0)âŠ¤y â‰¦0, i âˆˆI (x0) and âˆ‡h j(x0)âŠ¤y = 0,
j = 1, . . . , p. Then, multiplying condition (i) in Theorem 11.41 by yâŠ¤and using
condition (ii), we obtain
q

k=1
wkâˆ‡fk(x0)âŠ¤y +

iâˆˆI (x0)
uiâˆ‡gi(x0)âŠ¤y +
p

j=1
v jâˆ‡h j(x0)âŠ¤y = 0.
Taking into account that âˆ‡h j(x0)âŠ¤y = 0, j = 1, . . . , p, it results
q

k=1
wkâˆ‡fk(x0)âŠ¤y +

iâˆˆI (x0)
uiâˆ‡gi(x0)âŠ¤y = 0.
In view of the facts that âˆ‡fk(x0)âŠ¤y â‰¦0, k = 1, . . . , q, âˆ‡gi(x0)âŠ¤y â‰¦0, i âˆˆI (x0)
and (w, u) â‰§0 we derive that wkâˆ‡fk(x0)âŠ¤y = 0, k = 1, . . . , q, and uiâˆ‡gi(x0)âŠ¤y =
0, i âˆˆI (x0). By virtue of our assumption on the gradient vectors, the vector y is
orthogonal to every vector in Rn. This implies y = 0, which is a contradiction.
â–¡
Second-order Conditions
We provide in this part second-order necessary and second-order sufï¬cient optimality
conditions for problem (M P2). We assume that the involved functions in (M P2) are
twice-continuously differentiable.
Assume that x0 âˆˆS2 is a point satisfying the Fritz John conditions (i), (ii) and
(iii) in Theorem 11.41 or the Karush-Kuhn-Tucker conditions for some (w, u, v) âˆˆ
Rq Ã— Rm Ã— Rp. The Lagrangian function is deï¬ned by

11.3 Optimality Conditions
419
L (x, w, u, v) = wâŠ¤f (x) + uâŠ¤g(x) + vâŠ¤h(x)
=
q

k=1
wk fk(x) +
m

i=1
uigi(x) +
p

j=1
v jh j(x).
(11.33)
We deï¬ne the cone of strict descent directions of f at x0 by
D<( f, x0) = {y âˆˆRn : âˆ‡fk(x0)âŠ¤y < 0, k = 1, . . . , q}.
Lemma 11.63 L(x0) âˆ©D<( f, x0) = âˆ…if and only if the Karush-Kuhn-Tucker con-
ditions hold at x0.
Proof This
result
follows
from
Motzkinâ€™s
theorem
of
the
alternative
(Theorem 2.31).
â–¡
The cone C(x0) = L(x0) âˆ©D( f, x0) is called the critical cone. Next we establish
second-order necessary optimality conditions of the Fritz John-type.
Theorem 11.64 Let x0 âˆˆS2 be a local weak efï¬cient solution for problem (M P2).
Then for any y âˆˆL(x0) âˆ©D( f, x0) there are multipliers (w, u, v) âˆˆRq Ã— Rm Ã— Rp
such that the Fritz John conditions (i), (ii) and (iii) in Theorem 11.41 are satisï¬ed at
x0 and, moreover,
yâŠ¤âˆ‡2
xL (x0, w, u, v)y â‰§0.
Proof We follow the same lines as in the proof of Theorem 6.39. Let y âˆˆL(x0) âˆ©
D( f, x0). If the gradients âˆ‡h j(x0), j = 1, . . . , p, are linearly dependent, then
there exists Ï„ = (Ï„1, . . . , Ï„p) Ì¸= 0 such that p
j=1 Ï„ jâˆ‡h j(x0) = 0. Hence (w, u, v) =
(0, 0, Ï„) and (w, u, v) = (0, 0, âˆ’Ï„) are Fritz John multipliers that satisfy the (ï¬rst-
order) Fritz John conditions. Moreover, condition (11.36) is satisï¬ed either by
(0, 0, Ï„) or by (0, 0, âˆ’Ï„) since
yâŠ¤âˆ‡2
xL (x0, 0, 0, âˆ’Ï„)y = âˆ’yâŠ¤âˆ‡2
xL (x0, 0, 0, Ï„)y.
Therefore, for any y âˆˆL(x0) âˆ©D( f, x0) we can choose one of the two possibilities,
so that (11.36) is satisï¬ed.
We now assume that the gradients âˆ‡h j(x0), j = 1, . . . , p, are linearly inde-
pendent. Consider the following linear programming problem in the variables
(Î±, z) âˆˆR Ã— Rn:
â§
âªâªâ¨
âªâªâ©
min Î±
subject to: âˆ‡fk(x0)âŠ¤z + yâŠ¤âˆ‡2 fk(x0)y â‰¦Î±, k = 1, . . . , q,
âˆ‡gi(x0)âŠ¤z + yâŠ¤âˆ‡2gi(x0)y â‰¦Î±, i âˆˆI (x0, y),
âˆ‡h j(x0)âŠ¤z + yâŠ¤âˆ‡2h j(x0)y = 0, j = 1, . . . , p,
(11.34)
where I (x0, y) = {i âˆˆI (x0) : âˆ‡gi(x0)âŠ¤y = 0}. The optimal value of this problem
is nonnegative. Indeed, otherwise there exists z which satisï¬es

420
11
Introduction to Multiobjective Optimization
â§
â¨
â©
âˆ‡fk(x0)âŠ¤z + yâŠ¤âˆ‡2 fk(x0)y < 0, k = 1, . . . , q,
âˆ‡gi(x0)âŠ¤z + yâŠ¤âˆ‡2gi(x0)y < 0, i âˆˆI (x0, y),
âˆ‡h j(x0)âŠ¤z + yâŠ¤âˆ‡2h j(x0)y = 0, j = 1, . . . , p.
(11.35)
By Lemma 6.37, there exists a path Î³ : [0, Î´] â†’Rn satisfying conditions (6.22).
Then, by a second-order Taylor expansion, we have for t > 0 small enough and for
all k = 1, . . . , k that
fk(Î³ (t)) = fk(x0) + tâˆ‡fk(x0)âŠ¤y + 1
2t2 
âˆ‡fk(x0)âŠ¤z + yâŠ¤âˆ‡2 fk(x0)y

+ o(t2) < fk(x0)
due to the ï¬rst condition in (11.35) and the fact that y âˆˆD( f, x0). Therefore, for t >
0 small enough, Î³ (t) âˆˆS2 is feasible and fk(Î³ (t)) < fk(x0), k = 1, . . . , q, which
contradicts the local weak efï¬ciency of x0. This proves that (11.34) has a nonnegative
optimal value.
Since âˆ‡h j(x0), j = 1, . . . , p, are linearly independent, the equality constraints
of (11.34) have a feasible solution because rk âˆ‡h(x0) = p and so âˆ‡h(x0)(Rn) =
Rp, and thus there exists z âˆˆRn such that âˆ‡h j(x0)âŠ¤z + yâŠ¤âˆ‡2h j(x0)y = 0 for all
j = 1, . . . , p, and hence, since Î± can be made arbitrarily large, problem (11.34) is
consistent. Therefore, problem (11.34) has a ï¬nite nonnegative optimal value. Since
(11.34) is a linear programming problem, it follows, by the Strong Duality Theorem
of Linear Programming (see Remark 9.19), that its dual, in the variables w, u, v, with
ui = 0 for i /âˆˆI (x0, y), has the same optimal value. The dual of (11.34) is
max yâŠ¤
â›
â
q

k=1
wkâˆ‡2 fk(x0) +

iâˆˆI (x0,y)
uiâˆ‡2gi(x0) +
p

j=1
v jâˆ‡2h j(x0)
â
â y
subject to:
q

k=1
wkâˆ‡fk(x0) +

iâˆˆI (x0,y)
uiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0) = 0,
q

k=1
wk +

iâˆˆI (x0,y)
ui +
p

j=1
v j = 1,
wk â‰§0, k = 1, . . . , q; ui â‰§0, i âˆˆI (x0, y).
Since an optimal solution of this dual problem is a Fritz John multipliers vector
associated with x0, by choosing ui = 0 for i /âˆˆI (x0, y), we get the thesis.
â–¡
This theorem has been proved, with a different proof, in Bigi and Castellani [29].
The drawback of the previous theorem is that it may be w = 0. If the Mangasarian-
Fromovitz c. q. is satisï¬ed, this case cannot occur.

11.3 Optimality Conditions
421
Theorem 11.65 Let x0 âˆˆS2 be a local weak efï¬cient solution for problem (M P2)
and let x0 verify the Mangasarian-Fromovitz c. q. Then for any y âˆˆL(x0) âˆ©D( f, x0)
there are multipliers (w, u, v) âˆˆRq Ã— Rm Ã— Rp (that depend on y) such that the
Karush-Kuhn-Tucker conditions are satisï¬ed at x0 and, moreover,
yâŠ¤âˆ‡2
xL (x0, w, u, v)y â‰§0.
(11.36)
Proof The result follows as a consequence of Theorem 11.64 taking into account
that the Mangasarian-Fromovitz c. q. allows to assure that w Ì¸= 0.
â–¡
Some authors as Bigi and Castellani [30] have discussed the uniqueness of the
Karush-Kuhn-Tucker multipliers in multiobjective optimization. They state that,
ï¬xed w, there is uniqueness if and only if the strict Mangasarian-Fromovitz c.q.
(SMFCQ) holds. In order to obtain uniqueness without ï¬xing a unit vector w a pri-
ori, they introduce a new regularity condition, strengthening (SMFCQ) in such a way
that the objective functions fk are also involved, introducing a quite strong regularity
condition. We refer to the paper by these authors for more details.
The boundedness of the set of Karush-Kuhn-Tucker multipliers has been also
studied under a regularity condition involving the objective functions in Dutta and
Lalitha [31]. We refer to this paper to study this topic.
Let 
(x0) be the set of all the Karush-Kuhn-Tucker multipliers (w, u, v) at a
feasible point x0. Under the validity of the Mangasarian-Fromovitz c. q., it is then
possible to write the thesis of Theorem 11.65 in the form
sup
(w,u,v)âˆˆ
(x0)
yâŠ¤âˆ‡2
xL (x0, w, u, v)y â‰§0, âˆ€y âˆˆL(x0) âˆ©D( f, x0).
Now we turn to second-order sufï¬cient optimality conditions for (M P1) and
(M P2). We follow the approach of JimÃ©nez and Novo [32].
Deï¬nition 11.66 Consider problem (M P1), x0 âˆˆS and let F : Rn â†’R be differ-
entiable at x0 and w âˆˆRq, w â‰§0, w Ì¸= 0. We say that the pair (w, F) is a (lower)
support for f at x0 on S if the following three relations hold:
(i) F(x) â‰¦q
k=1 wk fk(x) for all x âˆˆS,
(ii) F(x0) = q
k=1 wk fk(x0),
(iii) âˆ‡F(x0) = 0.
We say that (w, F) is a weak support if the previous relations (i), (ii), and (iii)
hold and w â‰§0 (w = 0 is admitted).
The scalarization process contained in the previous deï¬nition is going to allow
us, on the one hand, to follow a parallel path to the scalar case and, on the other hand,
to apply the results from the scalar programming.
Remark 11.67 (a) Deï¬nition 11.66 is equivalent to say that F is a support (in the
Hestenes sense, see p. 102) for the scalar function wâŠ¤f = q
k=1 wk fk.

422
11
Introduction to Multiobjective Optimization
(b) Consider problem (M P2). If the Karush-Kuhn-Tucker conditions (11.17)â€“
(11.19) are satisï¬ed for some (w, u, v) âˆˆRq Ã— Rm Ã— Rp, then, calling F to the
Lagrangian function
F(x) = L (x, w, u, v),
we have that (w, F) is a support for f at x0 on S2 and the proof is immediate.
(c) If the Fritz John conditions (i), (ii) and (iii) in Theorem 11.41 are satisï¬ed at
x0, then (w, L (Â·, w, u, v)) is a weak support for f at x0 on S2.
(d) If in Deï¬nition 11.66, condition (i) holds on a relative neighborhood of x0,
S âˆ©U(x0, Î´), instead of on all S, we will say that F is a local support. Although the
theory below developed is valid for this type of support because the notions that are
used are local, we have employed (global) supports for simplicity reasons.
The following theorem provides some basic properties satisï¬ed if a support exists.
Note that the ï¬rst property coincides with the ï¬rst order necessary optimality condi-
tion (Theorem 11.40).
Theorem 11.68 (i) If (w, F) is a support for f at x0 on S and f is differentiable at
x0, then T (S, x0) âˆ©D<( f, x0) = âˆ….
(ii) If (w, F) is a weak support for f at x0 on S, F is twice differentiable at x0 and
there exists y âˆˆT (S, x0) such that yâŠ¤âˆ‡2F(x0)y > 0, then w Ì¸= 0, that is, (w, F) is
a support.
Proof (i) Let G(x) = q
k=1 wk fk(x) âˆ’F(x). Conditions (i), (ii) and (iii) in Deï¬ni-
tion 11.66 are equivalent to the following: (1) G(x) â‰§0 âˆ€x âˆˆS, 2) G(x0) = 0 and 3)
âˆ‡G(x0) = q
k=1 wkâˆ‡fk(x0). Conditions (1) and (2) imply that x0 is a minimum of
G on S. Using Theorem 4.24, it follows that âˆ‡G(x0)âŠ¤y â‰§0 âˆ€y âˆˆT (S, x0), which,
taking into account condition (3), is equivalent to
q

k=1
wkâˆ‡fk(x0)âŠ¤y â‰§0,
âˆ€y âˆˆT (S, x0).
(11.37)
Reasoning â€œad absurdumâ€, assume that there exists y âˆˆT (S, x0) âˆ©D<( f, x0). Then,
âˆ€k = 1, . . . , q, âˆ‡fk(x0)âŠ¤y < 0. As w â‰§0 and w Ì¸= 0, one has q
k=1 wkâˆ‡fk(x0)âŠ¤
y < 0, contradicting (11.37).
(ii) We have that y = lim
nâ†’âˆ
xn âˆ’x0
tn
for some sequences {xn} âŠ‚S, {tn} â†’0+. Let
us assume w = 0. With the notation of the previous part, now G(x) = âˆ’F(x) â‰§0
âˆ€x âˆˆS, G(x0) = 0, x0 is a minimum of G on S, âˆ‡G(x0) = 0 and yâŠ¤âˆ‡2G(x0)y < 0.
But, by using a second-order Taylor expansion, one has
1
2 yâŠ¤âˆ‡2G(x0)y = lim
nâ†’âˆ
G(xn) âˆ’G(x0)
t2n
â‰§0,
which is a contradiction.
â–¡

11.3 Optimality Conditions
423
Based on the notion of support function, we give some ï¬rst-order sufï¬cient opti-
mality conditions.
Theorem 11.69 If (a) (w, F) is a support for f at x0 on S and (b) T (S, x0) âˆ©
[D( f, x0) \ D<( f, x0)] = {0}, then x0 is a strict local efï¬cient point of order 1 for
(M P1).
Proof Condition (b) is equivalent to
T (S, x0) âˆ©D( f, x0) âˆ©D<( f, x0)c = {0}.
(11.38)
From Theorem 11.68(i), T (S, x0) âˆ©D<( f, x0) = âˆ…, hence, T (S, x0) âˆ©D<( f, x0)c
= T (S, x0). Therefore, taking into account (11.38), it follows that T (S, x0) âˆ©
D( f, x0) = {0}. By Theorem 11.59, x0 is a strict local efï¬cient point of order 1
for (M P1).
â–¡
Theorem 11.70 Consider problem (M P2). If the Karush-Kuhn-Tucker conditions
(11.17)â€“(11.19) are satisï¬ed at x0 and T (S2, x0) âˆ©[D( f, x0) \ D<( f, x0)] = {0},
then x0 is a strict local efï¬cient point of order 1 for (M P2).
Proof From Remark 11.67(b), (w, L (Â·, w, u, v)) is a support for f at x0 on S2, and
then it sufï¬ces to apply Theorem 11.69.
â–¡
Next, several second-order sufï¬cient optimality conditions are provided.
Theorem 11.71 Let S âŠ‚Rn, x0 âˆˆS, f : Rn â†’Rq differentiable at x0. If for every
y âˆˆT (S, x0) âˆ©D( f, x0) \ {0} there is a weak support (w, F) for f at x0 on S, which
is twice differentiable at x0 and such that yâŠ¤âˆ‡2F(x0)y > 0, then x0 is a strict local
efï¬cient point of order 2 for (M P1).
Proof By contradiction, assume that x0 is not a strict local efï¬cient point of order 2,
then, by Lemma 11.58, there exist sequences {xn} âŠ‚S \ {x0} and {dn} âŠ‚Rq
+, such
that xn â†’x0 and
lim
nâ†’âˆ
f (xn) âˆ’f (x0) + dn
âˆ¥xn âˆ’x0âˆ¥2
= 0.
(11.39)
Without lost of generality, we can suppose that
lim
nâ†’âˆ
xn âˆ’x0
âˆ¥xn âˆ’x0âˆ¥= y âˆˆT (S, x0)
with âˆ¥yâˆ¥= 1. If for some k âˆˆ{1, . . . , q}, âˆ‡fk(x0)âŠ¤y > 0, then by Lemma 11.27 one
has lim
nâ†’âˆ
fk(xn) âˆ’fk(x0)
âˆ¥xn âˆ’x0âˆ¥
= âˆ‡fk(x0)âŠ¤y,andconsequently lim
nâ†’âˆ
fk(xn) âˆ’fk(x0)
âˆ¥xn âˆ’x0âˆ¥2
=
+âˆ. From (11.39), we have
lim
nâ†’âˆ
 fk(xn) âˆ’fk(x0)
âˆ¥xn âˆ’x0âˆ¥2
+
dn
k
âˆ¥xn âˆ’x0âˆ¥2

= 0,

424
11
Introduction to Multiobjective Optimization
and so limnâ†’âˆ
dn
k
âˆ¥xnâˆ’x0âˆ¥2 = âˆ’âˆ, which is impossible because dn
k â‰§0. Therefore, for
all k âˆˆ{1, . . . , q}, âˆ‡fk(x0)âŠ¤y â‰¦0, that is, y âˆˆD( f, x0). Hence, y âˆˆT (S, x0) âˆ©
D( f, x0) and y Ì¸= 0, and by assumption, there is a weak support (w, F) such that
yâŠ¤âˆ‡2F(x0)y > 0.
Now, applying to (11.39) the continuous linear function from Rq to R given by
z â†’wâŠ¤z, it results
lim
nâ†’âˆ
wâŠ¤f (xn) âˆ’wâŠ¤f (x0) + wâŠ¤dn
âˆ¥xn âˆ’x0âˆ¥2
= 0.
(11.40)
Let G be the function deï¬ned in the proof of Theorem 11.68, i.e. G(x) =
wâŠ¤f (x) âˆ’F(x) â‰§0, hence wâŠ¤f (x) = F(x) + G(x) for x âˆˆS, and replacing in
(11.40) we obtain
lim
nâ†’âˆ
 F(xn) âˆ’F(x0)
âˆ¥xn âˆ’x0âˆ¥2
+ G(xn) + wâŠ¤dn
âˆ¥xn âˆ’x0âˆ¥2

= 0,
(11.41)
As âˆ‡F(x0) = 0, it follows limnâ†’âˆ
F(xn)âˆ’F(x0)
âˆ¥xnâˆ’x0âˆ¥2
= 1
2 yâŠ¤âˆ‡2F(x0)y > 0, and in con-
sequence limnâ†’âˆ
G(xn)+wâŠ¤dn
âˆ¥xnâˆ’x0âˆ¥2
< 0, but this is a contradiction because G(xn) â‰§0 and
wâŠ¤dn â‰§0 for all n.
â–¡
Corollary 11.72 Let f : Rn â†’Rq be twice differentiable at x0 âˆˆS âŠ‚Rn. If there
exists w âˆˆRq, w â‰§0, w Ì¸= 0 such that
(a)
q
k=1 wkâˆ‡fk(x0) = 0,
(b)
the quadratic form q(v) = q
k=1 wk yâŠ¤âˆ‡2 fk(x0)y is positive deï¬nite on the
cone T (S, x0) âˆ©{y âˆˆRn : wkâˆ‡fk(x0)âŠ¤y = 0 âˆ€k = 1, . . . , q},
then x0 is a strict local efï¬cient point of order 2 for f on S.
Proof Firstly, let us suppose w > 0. Let y âˆˆD( f, x0), this means that âˆ‡fk(x0)âŠ¤y â‰¦
0 for all k = 1, . . . , q. If for some k, âˆ‡fk(x0)âŠ¤y < 0, then q
k=1 wkâˆ‡fk(x0)âŠ¤y < 0
which contradicts (a). Hence, for all k = 1, . . . , q, âˆ‡fk(x0)âŠ¤y = 0. Consequently,
D( f, x0) = ker âˆ‡f (x0) = {y âˆˆRn : wkâˆ‡fk(x0)âŠ¤y = 0 âˆ€k = 1, . . . , q} and
T (S, x0) âˆ©D( f, x0) = T (S, x0) âˆ©{y âˆˆRn : wkâˆ‡fk(x0)âŠ¤y = 0 âˆ€k = 1, . . . , q}.
(11.42)
If T (S, x0) âˆ©D( f, x0) = {0}, by Theorem 11.59, x0 is a strict local efï¬cient point
of order 1 and, therefore, x0 is a strict local efï¬cient point of order 2 by Remark
11.55(i).
If T (S, x0) âˆ©D( f, x0) Ì¸= {0}, then we consider F = q
k=1 wk fk. One has, obvi-
ously, that (w, F) is a support for f .
By assumption (b), taking into account (11.42), âˆ€y âˆˆT (S, x0) âˆ©D( f, x0) \ {0}
we have that yâŠ¤âˆ‡2F(x0)y > 0, since âˆ‡2F(x0) = q
k=1 wkâˆ‡2 fk(x0). Therefore, by
Theorem 11.71, x0 is a strict local efï¬cient point of order 2.

11.3 Optimality Conditions
425
Let now w â‰§0. Rearranging, we can suppose that w = (w1, . . . , ws, ws+1, . . . ,
wq) with w1 > 0, â€¦, ws > 0, ws+1 = 0, â€¦, wq = 0 and s â‰§1. Consider the linear
map A : Rq â†’Rs given by A(z1, . . . , zq) = (z1, . . . , zs), i.e. the projection from Rq
to Rs on the s ï¬rst components, and let g = (g1, . . . , gs) = Af . Clearly, gk = fk for
k = 1, . . . , s. Moreover, condition (a) and (b) of the hypothesis become:
(aâ€²) s
i=1 wiâˆ‡gi(x0) = 0 and
(bâ€²) the quadratic form q0(y) = s
i=1 wi yâŠ¤âˆ‡2gi(x0)y is positive deï¬nite on the
cone T (S, x0) âˆ©{y âˆˆRn : âˆ‡gi(x0)âŠ¤y = 0 âˆ€i = 1, . . . , s}.
Using the ï¬rst part, we derive that x0 is a strict local efï¬cient point of order 2 for
g on S. Finally, as A(Rq
+) = Rs
+, by Theorem 11.56 we conclude that x0 is a strict
local efï¬cient point of order 2 for f on S.
â–¡
Example 11.73 Let f : R3 â†’R3 given by
f (x1, x2, x3) = (x1 + (x2)2 âˆ’(x3)3, âˆ’x1 + (x3)2 + (x2)3, x2x3)âŠ¤,
S = {(x1, x2, x3) âˆˆR3 : x2 â‰§0} and x0 = (0, 0, 0)âŠ¤. The assumptions of Corol-
lary 11.72 are satisï¬ed with w = (1, 1, 0)âŠ¤. Note that 3
k=1 wk yâŠ¤âˆ‡2 fk(x0)y =
2(y2)2 + 2(y3)2, which is positive deï¬nite on T (S, x0) âˆ©{y âˆˆR3 : âˆ‡fk(x0)âŠ¤y =
0, k = 1, 2} = {(y1, y2, y3) : y2 â‰§0, y1 = 0}. Thus, we derive that x0 is a strict
local efï¬cient point of order 2 for f .
Next, the general result (Theorem 11.71) is applied to problem (M P2). The fol-
lowing theorem is an immediate consequence of the aforesaid theorem taking into
account Remark 11.67(b).
Theorem 11.74 Considerproblem(M P2)andlet x0 âˆˆS2.Ifforevery y âˆˆT (S2, x0)
âˆ©D( f, x0) \ {0} there exist multipliers (w, u, v) satisfying the Karush-Kuhn-Tucker
conditions (11.17)â€“(11.19) and such that yâŠ¤âˆ‡2
xL (x0, w, u, v)y > 0, then x0 is a
strict local efï¬cient point of order 2 for (M P2).
Corollary 11.75 Consider problem (M P2) and let x0 âˆˆS2. If for every y âˆˆL(x0) âˆ©
D( f, x0) \ {0} there exist multipliers (w, u, v) satisfying the Karush-Kuhn-Tucker
conditions (11.17)â€“(11.19) and such that yâŠ¤âˆ‡2
xL (x0, w, u, v)y > 0, then x0 is a
strict local efï¬cient point of order 2 for (M P2).
This corollary is a straightforward consequence of the previous theorem since
T (S2, x0) âŠ‚L(x0).
The following example shows that the Lagrangian function varies on the vector.
The functions have already been considered by Ben-Tal [33] in Examples 2.1 and 4.1.
Example 11.76 Consider f : R3 â†’R3 deï¬ned by
f (x, y, z) = ( 1
2 x2 + 2yz,
1
2 y2 + 2xz,
1
2z2 + 2xy)âŠ¤,

426
11
Introduction to Multiobjective Optimization
S = R3 and x0 = (0, 0, 0)âŠ¤. We have that L(x0) âˆ©D( f, x0) = R3. The accom-
plished calculations by Ben-Tal prove that several Lagrangian functions (until six)
are needed to get
R3 \ {0} âŠ‚{y âˆˆR3 : âˆƒL (x0, w, u, v) | yâŠ¤âˆ‡2
xL (x0, w, u, v)y > 0},
and that just with only one it is impossible to obtain it. Therefore, x0 is a strict local
efï¬cient point of order 2.
In Corollary 11.75 the Lagrangian function L can vary on the vector y âˆˆL(x0) âˆ©
D( f, x0) \ {0}. If the same Lagrangian function L is valid for all the vectors y we
obtain the next result.
Corollary 11.77 Consider problem (M P2) and let x0 âˆˆS2. Suppose that there exist
multipliers (w, u, v) satisfying the Karush-Kuhn-Tucker conditions (11.17)â€“(11.19)
and such that
yâŠ¤âˆ‡2
xL (x0, w, u, v)y > 0 âˆ€y âˆˆL(x0) âˆ©D( f, x0) \ {0}.
Then x0 is a strict local efï¬cient point of order 2 for (M P2).
Next, we are going to state in Theorem 11.78 another second-order sufï¬cient
condition with ï¬xed multipliers. Previously, some of the notation.
Assume that x0 âˆˆS2 is a point satisfying the Fritz John conditions (i), (ii) and
(iii) in Theorem 11.41 or the Karush-Kuhn-Tucker conditions (11.17)â€“(11.19) for
some (w, u, v) âˆˆRq Ã— Rm Ã— Rp. Consider the Lagrangian function L deï¬ned by
Eq. (11.33). It is clear that âˆ‡xL (x0, w, u, v) = 0.
We deï¬ne the following sets:
Q+(w) = {k âˆˆQ : wk > 0};
I +(x0, u) =

i âˆˆI (x0) : ui > 0

;
I o(x0, u) =

i âˆˆI (x0) : ui = 0

= I (x0) \ I +(x0, u);
S2(u) = {x âˆˆS2 : gi(x) = 0, i âˆˆI +(x0, u)};
L(x0, u) =
 y âˆˆRn : âˆ‡gi(x0)âŠ¤y â‰¦0, i âˆˆI o(x0, u); âˆ‡gi(x0)âŠ¤y = 0, i âˆˆI +(x0, u);
âˆ‡h j(x0)âŠ¤y = 0, j âˆˆP

= L(x0) âˆ©ker âˆ‡gI +(x0),
(11.43)
where gI + is the function of components (gi)iâˆˆI +,
D( f, x0, w) = {y âˆˆRn : âˆ‡fk(x0)âŠ¤y â‰¦0, k âˆˆQ \ Q+; âˆ‡fk(x0)âŠ¤y = 0, k âˆˆQ+}
= D( f, x0) âˆ©ker âˆ‡fQ+(x0)

11.3 Optimality Conditions
427
where fQ+ is the function of components ( fk)kâˆˆQ+. For brevity, we have written I +
and Q+ instead of I +(x0, u) and Q+(w), respectively.
Let us observe that L(x0, u) is the linearized cone associated with the set S2(u).
Theorem 11.78 Consider problem (M P2) and let x0 âˆˆS2. Suppose that there exist
multipliers (w, u, v) satisfying the Karush-Kuhn-Tucker conditions or the Fritz John
conditions and such that
yâŠ¤âˆ‡2
xL (x0, w, u, v)y > 0,
âˆ€y âˆˆL(x0, u) âˆ©D( f, x0, w) \ {0}.
Then x0 is a strict local efï¬cient point of order 2 for (M P2).
Proof Let us check that
L(x0) âˆ©D( f, x0) = L(x0, u) âˆ©D( f, x0, w).
(11.44)
The inclusion â€œâŠƒâ€ is obvious. Let y âˆˆL(x0) âˆ©D( f, x0). Taking into account the
Karush-Kuhn-Tucker conditions or the Fritz John conditions and the deï¬nition of
the sets I +(x0, u) and Q+(w), the Lagrangian function (11.33) can be written
L (x, w, u, v) =

kâˆˆQ+
wk fk(x) +

iâˆˆI +
uigi(x) +
p

j=1
v jh j(x).
As âˆ‡xL (x0, w, u, v) = 0, it results

kâˆˆQ+
wkâˆ‡fk(x0) +

iâˆˆI +
uiâˆ‡gi(x0) +
p

j=1
v jâˆ‡h j(x0) = 0.
Multiplying by yâŠ¤, and using that âˆ‡h j(x0)âŠ¤y = 0, j = 1, . . . , p, we obtain

kâˆˆQ+
wkâˆ‡fk(x0)âŠ¤y +

iâˆˆI +
uiâˆ‡gi(x0)âŠ¤y = 0.
(11.45)
As y âˆˆD( f, x0) one has âˆ‡fk(x0)âŠ¤y â‰¦0, k âˆˆQ+, and as y âˆˆL(x0) one has
âˆ‡gi(x0)âŠ¤y â‰¦0, i âˆˆI +. Hence, wkâˆ‡fk(x0)âŠ¤y â‰¦0, k âˆˆQ+ and uiâˆ‡gi(x0)âŠ¤y â‰¦
0, i âˆˆI +, and taking into account (11.45), we deduce that wkâˆ‡fk(x0)âŠ¤y = 0,
k âˆˆQ+ and uiâˆ‡gi(x0)âŠ¤y = 0, i âˆˆI +. From here, âˆ‡fk(x0)âŠ¤y = 0, k âˆˆQ+ and
âˆ‡gi(x0)âŠ¤y = 0,i âˆˆI +,whichallowsustoconcludethat y âˆˆL(x0, u) âˆ©D( f, x0, w)
in view of (11.43).
Now, the thesis follows from (11.44) and Corollary 11.77.
â–¡
This theorem is a slight modiï¬cation of Theorem 5.4 in JimÃ©nez and Novo [32].
For other results on second-order sufï¬cient optimality conditions in multiobjective
optimization, see Wang [34] and Aghezzaf and Hachimi [35].
We illustrate the previous results with an example.

428
11
Introduction to Multiobjective Optimization
Example 11.79 Consider Example 11.53. Let us recall that the points of the form
x(t) =

t, 4âˆ’t2
2
	âŠ¤with t âˆˆA =

âˆ’
âˆš
2, 0

âˆª
âˆš
2, 2
	
satisfy the Karush-Kuhn-
Tucker conditions with w = w(t) =
2u1
4âˆ’t2

1, t(t2 âˆ’2)
	
, arbitrary u1 > 0 and u2 = 0.
Thus,
w1(t)âˆ‡f1(x(t)) + w2(t)âˆ‡f2(x(t)) + u1âˆ‡g1(x(t)) = 0
We want to study if these points satisfy some sufï¬cient optimality conditions. Let us
observe that the unique active constraint is g1 for all t âˆˆA, i.e. I (x(t)) = {1}.
As 4 âˆ’t2 > 0 on A, one has w(t) > 0 â‡”t(t2 âˆ’2) > 0 â‡”t âˆˆ

âˆ’
âˆš
2, 0
	
âˆª
âˆš
2, 2
	
= int A. Moreover, the set of vectors
âˆ‡f1(x(t)) = (2t, 4 âˆ’t2)âŠ¤, âˆ‡f2(x(t)) = (âˆ’1, 0)âŠ¤, âˆ‡g1(x(t)) = (âˆ’2t, âˆ’2)âŠ¤
has rank 2 for all t âˆˆA. By Theorem 11.61 we derive that L(x(t)) âˆ©D( f, x(t)) =
{0}, and from Corollary 11.60 we conclude that x(t) is a strict local efï¬cient point
of order 1 for all t âˆˆint A.
Ift âˆˆ

âˆ’
âˆš
2, 0,
âˆš
2

= A \ int A,wehave T (S2, x(t)) = L(x(t)) = {(y1, y2) âˆˆ
R2 : âˆ’2ty1 âˆ’2y2 â‰¦0}, and
CT (x(t)) = T (S2, x(t)) âˆ©D( f, x(t))
=

(y1, y2) âˆˆR2 : âˆ’2ty1 âˆ’2y2 â‰¦0, 2ty1 + (4 âˆ’t2)y2 â‰¦0, âˆ’y1 â‰¦0

=

(y1, y2) âˆˆR2 : y2 â‰§âˆ’ty1, y2 â‰¦âˆ’2t
4âˆ’t2 y1, y1 â‰§0

.
(a1) If t = 0, then CT (x(0)) =

(y1, y2) âˆˆR2 : y2 = 0, y1 â‰§0

. In view of The-
orem 11.59, x(0) = (0, 2)âŠ¤is not a strict local efï¬cient point of order 1.
(a2) If t = âˆ’
âˆš
2, then CT

x

âˆ’
âˆš
2
		
=

(y1, y2) âˆˆR2 : y2 =
âˆš
2y1, y1 â‰§0

.
In view of Theorem 11.59, x

âˆ’
âˆš
2
	
=

âˆ’
âˆš
2, 1
	âŠ¤is not a strict local efï¬cient
point of order 1.
(a3) If t =
âˆš
2, then CT

x
âˆš
2
		
=

(y1, y2) âˆˆR2 : y2 = âˆ’
âˆš
2y1, y1 â‰§0

. In
view of Theorem 11.59, x
âˆš
2
	
=
âˆš
2, 1
	âŠ¤is not a strict local efï¬cient point of
order 1.
Now, for these three points, we study the second-order conditions. The Hessian
of the Lagrangian function at x(t) is given by
âˆ‡2L (x(t)) =
2u1
4âˆ’t2
t2 âˆ’2 0
0
2

,
and we have to study the sign of the quadratic form
qt(y) = yâŠ¤âˆ‡2L (x(t))y =
2u1
4âˆ’t2 [(t2 âˆ’2)y2
1 + 2y2
2]
with y = (y1, y2)âŠ¤. Let us note that C(x(t)) = L(x(t)) âˆ©D( f, x(t)) = CT (x(t)).

References
429
(b1)Ift = 0,thenq0(y) = 1
2u1(âˆ’2y2
1 + 2y2
2) = âˆ’u1y2
1 < 0 forall y âˆˆC(x(0)) \
{0}, so by applying Theorem 11.64, x0 = (0, 2)âŠ¤is not a local weak efï¬cient solution.
(b2) If t âˆˆ{âˆ’
âˆš
2,
âˆš
2}, then qt(y) = u1(2y2
2) > 0 for all y âˆˆC(x(t)) \ {0}, so
by applying Corollary 11.77, x(t) is a strict local efï¬cient point of order 2.
The previous results are of local type (the points are locally efï¬cient except the
point (0, 2)), and they do not allow to assure if the studied points are globally efï¬cient.
To establish global efï¬ciency, Theorem 11.44 cannot be applied because the function
g1 isnotquasiconvex,butonecanbeappliedTheorem11.17resultinginthefollowing
(as the reader can check):
â€¢ for t = âˆ’
âˆš
2, x

âˆ’
âˆš
2
	
is weak efï¬cient;
â€¢ for t âˆˆ

âˆ’
âˆš
2, 0

, x(t) is not weak efï¬cient;
â€¢ for t âˆˆ
âˆš
2, 2
	
, x(t) is strictly efï¬cient.
References
1. M. Ehrgott, Multicriteria Optimization, 2nd edn. (Springer, Berlin, 2005)
2. K.M.Miettinen,NonlinearMultiobjectiveOptimization(KluwerAcademicPublishers,Boston,
1999)
3. Y. Sawaragi, H. Nakayama, T. Tanino, Theory of Multiobjective Optimization (Academic,
Orlando, 1985)
4. J. Jahn, Vector Optimization. Theory, Applications, and Extensions, 2nd edn. (Springer, Berlin,
2011)
5. D.T. Luc, Theory of Vector Optimization. Lecture Notes in Economic and Mathematics Systems,
vol. 319 (Springer, Berlin, 1989)
6. F.Y. Edgeworth, Mathematical Psychics (P. Keagan, London, 1881)
7. V. Pareto, Manuale di Economia Politica (Societa Editrice Libraria, Milano, 1906) Translated
into English by A.S, Schwier as Manual of Political Economy (Macmillan, New York, 1971)
8. W. Stadler, A survey of multicriteria optimization, or the vector maximum problem. J. Optim.
Theory Appl. 29, 1â€“52 (1979)
9. R.E. Steuer, Multiple Criteria Optimization. Theory, Computation and Application, Wiley
Series in Probability and Statistics (Wiley, New Jersey, 1986)
10. H.W. Kuhn, A.W. Tucker, Nonlinear programming, in Proceedings of the Second Berkeley Sym-
posium on Mathematical Statistics and Probability, ed. by J. Neyman (University of California
Press, Berkeley, 1951), pp. 481â€“492. Reprinted in Giorgi and Kjeldsen (2014)
11. J.M. Borwein, On the existence of Pareto efï¬cient points. Math. Oper. Res. 8, 64â€“73 (1983)
12. P. Ruiz-Canales, A. Ruï¬Ã¡n-Lizana, A characterization of weakly efï¬cient points. Math. Pro-
gram. 68, Ser. A, 205â€“212 (1995)
13. A.M. Geoffrion, Proper efï¬ciency and the theory of vector maximization. J. Math. Anal. Appl.
22, 618â€“630 (1968)
14. J.M. Borwein, Proper efï¬cient points for maximization with respect to cones. SIAM J. Control
Optim. 15, 57â€“63 (1977)
15. H.P. Benson, An improved deï¬nition of proper efï¬ciency for vector minimization with respect
to cones. J. Math. Anal. Appl. 71, 232â€“241 (1979)
16. M.I. Henig, Proper efï¬ciency with respect to cones. J. Optim. Theory Appl. 36, 387â€“407 (1982)
17. A. Guerraggio, E. Molho, A. Zaffaroni, On the notion of proper efï¬ciency in vector optimiza-
tion. J. Optim. Theory Appl. 82, 1â€“21 (1994)

430
11
Introduction to Multiobjective Optimization
18. C.Singh,Optimalityconditionsinmultiobjectivedifferentiableprogramming.J.Optim.Theory
Appl. 53, 115â€“123 (1987)
19. J.G. Lin, Maximal vectors and multiobjective optimization. J. Optim. Theory Appl. 18, 41â€“64
(1976)
20. B. Aghezzaf, M. Hachami, On a gap between multiobjective optimization and scalar. J. Optim.
Theory Appl. 109, 431â€“435 (2001)
21. M. Castellani, M. Papalardo, About a gap between multiobjective optimization and scalar
optimization. J. Optim. Theory Appl. 109, 437â€“439 (2001)
22. S.Y. Wang, F.M. Yang, A gap between multiobjective optimization and scalar optimization. J.
Optim. Theory Appl. 68, 389â€“391 (1991)
23. G.M. Lee, Optimality conditions in multiobjective optimization problems. J. Inf. Optim. Sci.
13, 107â€“111 (1992)
24. A. Cambini, L. Martein, Generalized convexity and optimality conditions in scalar and vector
optimization, in Handbook of Generalized Convexity and Generalized Monotonicity. ed. by N.
Hadjisavvas, S. Komlosi, S. Schaible (Springer, New York, 2005), pp. 151â€“193
25. G. Giorgi, B. JimÃ©nez, V. Novo, Sufï¬cient optimality conditions and duality in nonsmooth
optimization problems under generalized convexity, in Generalized Convexity and Related
Topics. ed. by I.V. Konnov, D.T. Luc, A.M. Rubinov (Springer, New York, 2007), pp. 265â€“278
26. B. JimÃ©nez, Strict efï¬ciency in vector optimization. J. Math. Anal. Appl. 265, 264â€“284 (2002)
27. B. JimÃ©nez, V. Novo, First and second order sufï¬cient conditions for strict minimality in
nonsmooth vector optimization. J. Math. Anal. Appl. 284, 496â€“510 (2003)
28. G. Giorgi, B. JimÃ©nez, V. Novo, A note on ï¬rst-order conditions for Pareto problems. Numer.
Funct. Anal. Optim. 29, 1108â€“1113 (2008)
29. G. Bigi, M. Castellani, Second order optimality conditions for differentiable multiobjective
problems. RAIRO Oper. Res. 34, 411â€“426 (2000)
30. G. Bigi, M. Castellani, Uniqueness of KKT multipliers in multiobjective optimization. Appl.
Math. Lett. 17, 1285â€“1290 (2004)
31. J. Dutta, C.S. Lalitha, Bounded sets of KKT multipliers in vector optimization. J. Global Optim.
36, 425â€“437 (2006)
32. B. JimÃ©nez, V. Novo, First and second order sufï¬cient conditions for strict minimality in
multiobjective programming. Numer. Funct. Anal. Optim. 23, 303â€“322 (2002)
33. A. Ben-Tal, Second-order and related extremality conditions in nonlinear programming. J.
Optim. Theory Appl. 31, 143â€“165 (1980)
34. S.Y. Wang, Second-order necessary and sufï¬cient conditions in multiobjective programming.
Numer. Funct. Anal. Optim. 12, 237â€“252 (1991)
35. B. Aghezzaf, M. Hachami, Second order optimality conditions in multiobjective optimization
problems. J. Optim. Theory Appl. 102, 37â€“50 (1999)

Index
A
Active constraints, 124, 170
C
Combination
afï¬ne, 24
convex, 24
convex conic, 24
linear, 24
Complementary slackness conditions, 128
Cone, 24
bipolar, 36
Bouligand tangent, 47
Clarke normal, 354
Clarke tangent, 154
contingent, 47
convex, 24
critical, 202, 419
extended critical, 203
ï¬nite, 27
ï¬nitely generated, 27, 38
isotone, 370
linearizing, 112, 125, 170
normal, 50
of attainable directions, 51
of critical directions, 202
of descent directions, 176
of epi-Lipschitzian directions, 369
of feasible directions, 51
of interior directions, 216
of quasi-interior directions, 216
of strict descent directions, 419
pointed, 22
polar, 36
polyhedral, 28
positive polar, 36
radial, 51
recession, 368
Rockafellar hypertangent, 369
Constraint qualiï¬cation, 128
Abadie, 138, 185
Abadie II, 187
Arrow-Hurwicz-Uzawa, 138
Arrow-Hurwicz-Uzawa II, 187
constant positive linear dependence, 189
Constant Rank, 188
Cottle, 138
Guignard-Gould-Tolle, 129, 137, 175,
184
Karlin, 248
Kuhn-Tucker, 138, 185
linear independence, 140, 188
Mangasarian-Fromovitz, 185
Slater, 140, 187
strict, 248
strict Mangasarian-Fromovitz, 191
Zangwill, 138
D
Directional derivative, 63
Clarke, 343
Clarke-Rockafellar, 373
epi-Lipschitzian, 373
left-sided, 319
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2023
G. Giorgi et al., Basic Mathematical Programming Theory, International Series
in Operations Research & Management Science 344,
https://doi.org/10.1007/978-3-031-30324-1
431

432
Index
lower Dini, 344
lower Dini-Hadamard, 372
lower Ursescu, 372
right-sided, 319
upper Dini, 344
upper Dini-Hadamard, 372
upper Ursescu, 372
Dual problem
Lagrangian, 256
Mond Weir, 267
Wolfe, 260
E
Efï¬cient point, 385
local, 389
local strict, 389
local weak, 389
strict, 385
strils local of order m, 414
weak, 385
Efï¬cient solution, 21
weak, 21
F
Feasible set, 10
Function
Clarke invex, 365
Clarke pseudoconvex, 363
Clarke quasiconvex, 364
Clarke regular, 349
coercive, 17
concave, 53
continuously differentiable, 4
contraction, 337
convex, 53
differentiable, 3
directionally differentiable, 320
GÃ¢teaux differentiable, 64
indicator, 331
invex, 72
Lagrangian, 107, 177, 418
Lagrangian dual, 256
Lipschitz continuous, 337
locally Lipschitz, 338
lower semi-continuous, 14
marginal, 226
optimal value, 226
perturbation, 226
preinvex, 71
proper convex, 319
pseudoconvex, 67
quasiconvex, 65
semistrictly quasiconvex, 68
strictly concave, 53
strictly convex, 53
strictly differentiable, 348
sublinear, 54
twice differentiable, 3
upper semi-continuous, 14
G
Geometrical method, 104
H
Half-spaces, 31
Hull
afï¬ne, 25
convex conic, 25
linear, 25
Hyperplane, 5
separating, 32
K
K-subdifferential, 374
K-subgradient, 374
L
Lagrange multipliers rule, 113
Lagrange regular, 194
Least-squares method, 94
Linear programming problem
basic solution, 285
degenerate basic solution, 285
dual, 290
feasible basic solution, 285
primal in canonical form, 289
primal in standard form, 290
Local cone approximation, 368
M
Matrix
Hessian, 4
Jacobian, 4
Minimizer
global, 10
isolated local, 12
local, 11
strict global, 12
strict local, 12

Index
433
N
Nonsmooth analysis, 317
O
Objective function, 10
P
Point
Clarke stationary, 355
critical, 84
Lagrangian saddle, 244
saddle, 85
stationary, 84
Polytope, 30
Problem
activity analysis, 277
assignment, 277
diet, 277
linear programming, 275
quadratic programming, 301
transportation, 277
Proper efï¬ciency, 392
Benson, 394
Borwein, 394
Geoffrion, 393
Kuhn-Tucker, 395
Q
Quadratic form, 7
deï¬nite, 7
indeï¬nite, 7
semideï¬nite, 7
S
Sensitivity analysis, 225
Set
convex, 23
convex hull, 25
lower level, 15
of the active constraints, 124
properly separable, 32
regular, 217
separable, 32
strictly convex, 23
strongly separable, 32
upper level, 61
Shadow prices, 240
Subdifferential, 318
Clarke, 346
Subgradient, 318
T
Taylorâ€™s formula, 4
Theorem
Caratheodory, 27
Cottle, 311
Elster and Thierfelder, 378
equilibrium, 297
Fermat, 84
Fermat rule for Lipschitz functions, 355
ï¬rst fundamental on L.P., 280
Fritz John, 127, 172, 404
generalized Weierstrass, 16
implicit function, 6
Karush-Kuhn-Tucker, 130, 175, 404
Kojima, 235
Kuhn-Tucker-Uzawa, 247
Minkowski-Weyl, 40
Moreau-Rockafellar, 329
saddle point and duality, 298
second fundamental on L.P., 286
strict converse duality, 262
strict direct duality, 261
strong duality, 259
Sylvester criterion, 8
weak duality, 258
Weierstrass, 16
Theorem of the alternative, 41
Farkas, 42
Fredholm, 43
Gale, 43
Gordan, 44
Ky Fan, 43
Motzkin, 43
Slater, 45
Tucker, 45
W
Weighted sum method, 399

