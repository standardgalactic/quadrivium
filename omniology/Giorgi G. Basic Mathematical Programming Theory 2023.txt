International Series in
Operations Research & Management Science
Giorgio Giorgi
Bienvenido Jiménez
Vicente Novo
Basic 
Mathematical 
Programming 
Theory

International Series in Operations Research &
Management Science
Founding Editor
Frederick S. Hillier
Volume 344
Series Editor
Camille C. Price, Department of Computer Science, Stephen F. Austin State
University, Nacogdoches, TX, USA
Associate Editor
Joe Zhu, Foisie Business School, Worcester Polytechnic Institute, Worcester, MA,
USA
Editorial Board
Emanuele Borgonovo, Department of Decision Sciences, Bocconi University,
Milan, Italy
Barry L. Nelson, Department of Industrial Engineering & Management Sciences,
Northwestern University, Evanston, IL, USA
Bruce W. Patty, Veritec Solutions, Mill Valley, CA, USA
Michael Pinedo, Stern School of Business, New York University, New York, NY,
USA
Robert J. Vanderbei, Princeton University, Princeton, NJ, USA

Giorgio Giorgi · Bienvenido Jiménez ·
Vicente Novo
Basic Mathematical
Programming Theory

Giorgio Giorgi
Department of Economics and Management
University of Pavia
Pavia, Italy
Vicente Novo
Department of Applied Mathematics
National University of Distance Education
Madrid, Spain
Bienvenido Jiménez
Department of Applied Mathematics
National University of Distance Education
Madrid, Spain
ISSN 0884-8289
ISSN 2214-7934 (electronic)
International Series in Operations Research & Management Science
ISBN 978-3-031-30323-4
ISBN 978-3-031-30324-1 (eBook)
https://doi.org/10.1007/978-3-031-30324-1
© The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature
Switzerland AG 2023
This work is subject to copyright. All rights are solely and exclusively licensed by the Publisher, whether
the whole or part of the material is concerned, speciﬁcally the rights of translation, reprinting, reuse
of illustrations, recitation, broadcasting, reproduction on microﬁlms or in any other physical way, and
transmission or information storage and retrieval, electronic adaptation, computer software, or by similar
or dissimilar methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication
does not imply, even in the absence of a speciﬁc statement, that such names are exempt from the relevant
protective laws and regulations and therefore free for general use.
The publisher, the authors, and the editors are safe to assume that the advice and information in this book
are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or
the editors give a warranty, expressed or implied, with respect to the material contained herein or for any
errors or omissions that may have been made. The publisher remains neutral with regard to jurisdictional
claims in published maps and institutional afﬁliations.
This Springer imprint is published by the registered company Springer Nature Switzerland AG
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland

For Elena, Elisa, Marcello and Lucia
Giorgio Giorgi
For my wife Elena and my children Roberto,
Cristina and Elena
Bienvenido Jiménez
For my grandchildren Leo, Vega, Eva and
Sara
Vicente Novo

Preface
It is quite superﬂuous to stress that mathematical optimization is a corner-
stone of not only several scientiﬁc subjects, such as Economic Analysis, Opera-
tions Research, Management Sciences, Engineering, Chemistry, Physics, Statistics,
Computer Science, but also Biology and other Social Sciences. The subject of (static)
optimization, called also mathematical programming, is, besides its various appli-
cations, one of the most important and wide branches of modern mathematics, with
deep and beautiful theoretical results. The present book is concerned with the main
theoretical questions on optimality and duality theory of mathematical programming
problems in the Euclidean space Rn. Also in order of limiting the dimension of the
book, we have decided to devote our efforts only to expose the basic mathematical
tools and results concerning the most treated mathematical programming problems
formulated in a ﬁnite-dimensional setting. We wish to make clear that it would
be desirable that the student or the researcher interested in these questions would
complete his knowledge by learning also the basic questions on the various algo-
rithmic methods and on the most important particular applications of mathematical
programming problems.
It is however our opinion that the student or researcher interested in learning
the fundamental facts of mathematical programming, before being acquainted with
the various algorithms and numerical questions, must possess the basic mathemat-
ical notions and the basic theoretical background used in analyzing optimization
problems.
As it happens for any book, also the present one reﬂects the tastes of its authors. We
have been compelled to make choices, as some subjects of Mathematical Program-
ming have grown at an exponential rate (e.g., Linear Programming) and it would
be impossible to cover in a single volume every aspect of mathematical program-
ming theory. Consequently, we have left out certain important subjects, such as,
for example, Complementarity Theory, Discrete Optimization, Stochastic Program-
ming, Semi-inﬁnite Programming, Bilevel Programming, and Fractional Program-
ming. Also, set-valued optimization problems are not treated in the present book.
vii

viii
Preface
However, the last chapter is concerned with an introduction to vector optimization
problems, but only in ﬁnite dimensions (as done for the scalar case), that is the
multiobjective case.
The text assumes no previous experience in optimization theory and the treatment
of the various topics is largely self-contained. The prerequisites are the basic tools of
differential calculus for functions of several variables, the basic notions of topology
in Rn and of Linear Algebra. Some of these concepts are recalled in Chap. 1. We
do not claim any originality on the structure of this book; however, we hope that the
gradual and self-contained treatment of the subjects will reveal to be a “friendly”
approach to the non-experienced reader. We have accompanied several theoretical
results with examples and we have often made reference to papers and books, in
order to give further information to the curious and willing reader. The list of works
in the bibliographical references is quite long.
The book addresses not only to both undergraduate and postgraduate students
interested in mathematical programming problems but also to those professionals
who use in their jobs optimization methods and wish to learn more theoretical aspects
of these questions. We hope that it can be useful in courses of optimization, operations
research, economic analysis, and in other courses where optimization theory and
methods are investigated. The book is organized into 11 chapters.
Chapter 1 includes background material on classical analysis and linear algebra,
together with some basic deﬁnitions and properties concerning optimization prob-
lems. We present also the main types of optimization problems that will be studied
in the next chapters.
Chapter 2 is concerned with the fundamental facts of convex analysis, a subject
which is at the heart of optimization theory. We give particular attention to the
theorems of the alternative for linear systems. One of the most used and known results
of this type, from which all other theorems of the alternative for linear systems can be
obtained, is the famous Theorem (or Lemma) of Farkas (or of Farkas-Minkowski).
However, some excellent books on optimization theory present an unsatisfactory
proof of this theorem, as it is given for granted that a polyhedral cone is a closed set.
But this is, in a certain sense, just equivalent to the statement of Farkas’ theorem.
In the same chapter, we give also the main deﬁnitions and properties of some local
cone approximations used in optimization theory.
Chapter 3 provides an overview of convex functions and generalized convex
functions, with emphasis on their most important properties regarding optimality
conditions. Generalized convexity and generalized monotonicity of functions have
attracted several researchers, both in mathematics and in other professional disci-
plines: the Working Group of Generalized Convexity (WGGC) is a section of the
Mathematical Programming Society (since 2010 named Mathematical Optimization
Society). The chapter concludes with some theorems of the alternative for nonlinear
systems.
Chapter 4 treats optimality conditions for an unconstrained optimization problem,
denoted by (P1) for a constrained optimization problem with a set constraint (or
abstract constraint), denoted by (P2), and for a “classical” constrained optimization
problem, denoted by (P3); in other words, (P3) is an optimization problem with

Preface
ix
only equality constraints. These problems have been called “classical” constrained
optimization problems, as they were studied for the ﬁrst time by J. L. Lagrange in
the second half of the 18th century.
Chapter 5 treats a “modern” constrained optimization problem, i.e., a constrained
minimization problem with inequality constraints, problem denoted by (P4). The
basic necessary and sufﬁcient ﬁrst-order and second-order optimality conditions
are given (Fritz John conditions and Karush-Kuhn-Tucker conditions). A special
attention is devoted to the question of constraint qualiﬁcations: various constraint
qualiﬁcations are presented, together with their inclusion properties. Other formula-
tions of (P4) are taken into consideration and several simple numerical examples are
discussed.
Chapter 6 treats constrained optimization problems with mixed constraints, i.e.,
with both equality and inequality constraints, problems denoted by (P5). We have
preferred to treat separately these types of problems, as the related optimality condi-
tions have some particular features. Also for these problems, ﬁrst-order conditions
and second-order conditions are discussed with a certain wideness and the question of
constraint qualiﬁcations is extensively treated, with various constraint qualiﬁcations
proposed and analyzed. The chapter concludes with some insights on a constrained
optimization problem with both equality and inequality constraints and with a set
constraint, problem denoted by (P6), and on asymptotic optimality conditions for
(P5).
Chapter 7 is concerned with sensitivity analysis for problem (P5) a subject usually
not treated in textbooks on optimization theory, but important for its economic and
ﬁnancial applications and also for computational questions. We follow mainly the
classical approach of Fiacco (1983).
Chapter 8 is concerned with optimality conditions for a convex programming
problem of the type (P4) expressed in terms of saddle points conditions, and with
Lagrangian duality. From a historical point of view, optimality conditions via saddle
points are important, as one of the aims of the pioneering paper of Kuhn and Tucker
(1951) was to extend to the nonlinear (convex) case the duality and saddle points
results previously obtained for the linear case (Linear Programming). As for what
concerns duality theory, we have chosen to give some basic insights on the so-
called “Lagrangian duality”, because this approach is equivalent (at least for convex
programming) to Fenchel’s approach which uses conjugate functions. We brieﬂy
treat also the general approach to duality which makes reference to the “minimax
theory”.
Chapter 9 is concerned with Linear Programming and Quadratic Programming.
Linear programming problems are treated with reference to their fundamental formal
properties, therefore with no mention to the famous “simplex method” of G. B.
Dantzig, nor to other more modern algorithmic questions. For these last aspects, we
have given in the bibliographical references some suggestions. The same holds true
for quadratic programming problems, which are important for some applications
in Finance, Econometrics and Statistics. A special attention has been devoted to
duality theory, both for linear programming problems and for quadratic programming
problems.

x
Preface
Chapter 10 is an introduction to nonsmooth optimization. The term “nonsmooth
analysis” is due to the Canadian mathematician F. H. Clarke; the related theory begins
with the necessity to treat, within convex optimization problems, non-necessarily
differentiable functions. The basic contributions to this case are the works of Fenchel
(1953), Moreau (1963), and the celebrated book Convex Analysis by Rockafellar
(1970). Subsequently, Clarke (1983) extended the domain of nonsmooth analysis
from convex to locally Lipschitz functions. The ﬁrst and second sections of Chap. 10
are, respectively, concerned with nonsmooth convex optimization problems and
with nonsmooth locally Lipschitz optimization problems. The third and last section
is concerned with an axiomatic approach to nonsmooth analysis and nonsmooth
optimization, due to Elster and Thierfelder (1985, 1988a, b, 1989).
The ﬁnal Chap. 11 is an introduction to vector optimization problems, but only in
ﬁnite dimensions, that is the multiobjective case. Necessary and sufﬁcient optimality
conditions are given, together with the so-called “weighted sum method”.
Pavia, Italy
Madrid, Spain
December 2022
Giorgio Giorgi
Bienvenido Jiménez
Vicente Novo
Acknowledgements This work, for the second and third authors, was partially supported by Minis-
terio de Ciencia e Innovación and Agencia Estatal de Investigación (Spain) under the project with
reference PID2020-112491GB-I00/AEI/10.13039/501100011033.

Contents
1
Basic Notions and Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.2
Basic Notions of Analysis and Linear Algebra . . . . . . . . . . . . . . . .
2
1.3
Basic Deﬁnitions and Properties of Optimization Problems . . . . .
9
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
22
2
Elements of Convex Analysis. Linear Theorems
of the Alternative. Tangent Cones . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
23
2.1
Elements of Convex Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
23
2.2
Theorems of the Alternative for Linear Systems . . . . . . . . . . . . . .
41
2.3
Tangent Cones . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
47
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
52
3
Convex Functions and Generalized Convex Functions . . . . . . . . . . . .
53
3.1
Convex Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
53
3.2
Generalized Convex Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
64
3.3
Optimality Properties of Convex and Generalized Convex
Functions. Nonlinear Theorems of the Alternative . . . . . . . . . . . . .
74
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
81
4
Unconstrained Optimization Problems. Set-Constrained
Optimization Problems. Classical Constrained Optimization
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
83
4.1
Unconstrained Optimization Problems
. . . . . . . . . . . . . . . . . . . . . .
83
4.2
Set-Constrained Optimization Problems . . . . . . . . . . . . . . . . . . . . .
96
4.3
Optimization Problems with Equality Constraints
(“Classical Constrained Optimization Problems”) . . . . . . . . . . . . .
102
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
121
5
Constrained Optimization Problems with
Inequality Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
123
5.1
First-Order Conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
123
5.2
Constraint Qualiﬁcations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
137
xi

xii
Contents
5.3
Second-Order Conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
141
5.4
Other Formulations of the Problem. Some Examples . . . . . . . . . .
147
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
167
6
Constrained Optimization Problems with Mixed Constraints . . . . . .
169
6.1
First-Order Conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
169
6.2
Constraint Qualiﬁcations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
184
6.3
Second-Order Conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
201
6.4
Problems with a Set Constraint. Asymptotic Optimality
Conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
215
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
222
7
Sensitivity Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
225
7.1
General Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
225
7.2
Sensitivity Results for Right-Hand Side Perturbations . . . . . . . . .
236
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
242
8
Convex Optimization: Saddle Points Characterization
and Introduction to Duality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
243
8.1
Convex Optimization: Saddle Points Characterization . . . . . . . . .
243
8.2
Introduction to Duality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
254
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
273
9
Linear Programming and Quadratic Programming . . . . . . . . . . . . . .
275
9.1
Linear Programming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
275
9.2
Duality for Linear Programming . . . . . . . . . . . . . . . . . . . . . . . . . . . .
289
9.3
Quadratic Programming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
301
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
315
10
Introduction to Nonsmooth Optimization Problems . . . . . . . . . . . . . .
317
10.1
The Convex Case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
318
10.2
The Lipschitz Case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
337
10.3
The Axiomatic Approach of K.-H. Elster and J. Thierfelder
to Nonsmooth Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
367
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
379
11
Introduction to Multiobjective Optimization . . . . . . . . . . . . . . . . . . . . .
383
11.1
Optimality Notions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
384
11.2
The Weighted Sum Method and Relations with
Proper Efﬁciency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
399
11.3
Optimality Conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
403
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
429
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
431

Chapter 1
Basic Notions and Deﬁnitions
1.1
Introduction
It is well-known that the central problem of mathematical programming is that of
minimizing or maximizing a given numerical function of several variables, where the
variables are free to move over the whole domain of the function or (more usually)
are constrained by a system of constraints.
Mathematical programming, called also nonlinear programming, can be viewed
as that ﬁeld of optimization theory which treats static and ﬁnite-dimensional opti-
mization problems. It seems that the term “mathematical programming” was ﬁrst
introduced by the American economist Robert Dorfman in 1949, as a generaliza-
tion of the term “linear programming”, introduced by the American mathematician
George B. Dantzig a couple of years before. The term “nonlinear programming”
appears for the ﬁrst time in 1951 in the title of the famous pioneering paper of Kuhn
and Tucker [1]. Mathematical programming problems are at the heart of many theo-
retic and applied sciences: indeed, these problems occur in different contexts, such as
for example, economic analysis, operations research, management sciences, games
theory, statistics, physics, engineerings, etc. Mathematical programming problems
have attracted a wide interest also because of their applications in many practical
questions arising in industry, commerce, government and military questions.
In the present text-book we shall be concerned with the basic aspects of optimality
conditions and duality conditions related to a mathematical programming problem.
We have preferred to point out the basic ideas on the mathematical structure of
these problems, rather than on the various algorithmic techniques, available in many
excellent books treating numerical optimization.
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al., Basic Mathematical Programming Theory, International Series
in Operations Research & Management Science 344,
https://doi.org/10.1007/978-3-031-30324-1_1
1

2
1
Basic Notions and Deﬁnitions
1.2
Basic Notions of Analysis and Linear Algebra
In this section we recall some basic notions of Analysis and Linear Algebra, which
will be useful to understand several notions developed in the next chapters. In order
to deepen the concepts expounded here, the reader is referred to the texts quoted in
the Bibliographical References.
General concepts of basic topology on Rn
Given a vector (point) in Rn
x = [x1, x2, . . . , xn]⊤,
we denote by ∥x∥its Euclidean norm:
∥x∥=

(x1)2 + (x2)2 + · · · + (xn)n.
A neighborhood U(x0), or also N(x0), of x0 ∈Rn is given by an open ball of a
given radius ε > 0 :
U(x0) =

x ∈Rn :
x −x0 < ε

.
When it is useful to specify the radius ε, we shall write Uε(x0), Nε(x0), U(x0, ε),
N(x0, ε), etc.
In any case we have
U(x0) = x0 + U(0), with 0 ∈Rn.
A point x0 is an interior point of a set S ⊂Rn if x0 ∈S and there exists a neigh-
borhood U(x0) contained in S.
The set S ⊂Rn is open if all its points are interior points. The set S ⊂Rn is closed
if its complementary set is open (equivalently: if it contains all its boundary points
or if it contains all its accumulation points). The boundary of S, denoted by ∂S or
bd(S), is the set of points x for which Uε(x) contains a point in S and a point not in
S, for all ε > 0.
The interior of a set S ⊂Rn is given by all its interior points, i.e., if we denote
the interior of S by int(S),
int(S) = {x ∈S : ∃U(x) ⊂S} .
The closure of S, denoted by cl(S) or also by ¯S, is given by the intersection of
all closed sets which contain S. It holds
cl(S) = ∩
ε>0(S + Uε(0)).

1.2 Basic Notions of Analysis and Linear Algebra
3
In other words, cl(S) consists of S and all boundary points of S, i.e. cl(S) =
S ∪bd(S).
The algebraic sum of two sets S1, S2 of Rn is deﬁned as
S1 + S2 =

x1 + x2 : x1 ∈S1, x2 ∈S2

.
The multiplication of a set S ⊂Rn by a real number or real scalar α is deﬁned as
αS = {αx : x ∈S} .
We have the following calculus rules:
α(S1 + S2) = αS1 + αS2,
(α + β)S ⊂αS + βS.
Let be given a set S ⊂Rn and an element x ∈S; we shall write S + x, instead of
S + {x} . Moreover, we shall write S1 −S2 to denote the operation S1 + (−1)S2.
Differentiability
Letbegivenafunction f : X ⊂Rn →R.Then f issaidtobe(Fréchet)differentiable
at x0 ∈int(X), if there exists a vector ∇f (x0) ∈Rn such that
f (x) = f (x0) + ∇f (x0)⊤(x −x0) + o(
x −x0),
for all x ∈X.
The Landau symbol (“small o”) o(t) means that
lim
t→0
o(t)
t
= 0.
The vector ∇f (x0) is the gradient of f at x0; its elements are given by the n
partial derivatives of f, evaluated at x0 :
∂f
∂xi
(x0), i = 1, . . . , n.
We observe that if, in the above deﬁnition, x = x0 + λv, with ∥v∥= 1, then
o(
x −x0) = o(λ).
We accept the following deﬁnition of twice differentiability. A function f : X ⊂
Rn →R, differentiable at x0 ∈int(X), is said to be twice differentiable at x0 if
each component of ∇f : X →Rn is differentiable at x0. Then, there exists a square
matrix, denoted ∇2 f (x0) or also H f (x0), of order n, such that
f (x) = f (x0) + ∇f (x0)⊤(x −x0) + 1
2(x −x0)⊤∇2 f (x0)(x −x0) + o
 x −x0
2 
,

4
1
Basic Notions and Deﬁnitions
for all x ∈X.
The matrix ∇2 f (x0) is the Hessian matrix of f evaluated at x0; its elements are
given by the second-order partial derivatives of f, evaluated at x0 :
∂2 f
∂xi∂x j
(x0), i, j = 1, . . . , n.
The function f is differentiable on the open set X ⊂Rn, respectively, twice dif-
ferentiable on the open set X ⊂Rn, if it is differentiable, respectively, twice dif-
ferentiable, at every point x ∈X. If the ﬁrst-order partial derivatives of f are also
continuous, we say that f is continuously differentiable or also that f belongs to the
C 1-class and shall write f ∈C 1. If f ∈C 1, then f is differentiable (the vice-versa
does not hold).
If all second-order partial derivatives of f are also continuous, we say that f is
twice-continuously differentiable and shall write f ∈C 2. If f ∈C 2, then f is twice
differentiable (the vice-versa does not hold). Obviously, twice continuous differen-
tiability is more easy to check than twice differentiability, however several results on
optimization theory hold under the assumption of twice differentiability. If a function
f is twice differentiable (and, even more, if f is twice-continuously differentiable),
then its Hessian matrix ∇2 f (x) is symmetric (Schwarz theorem), i. e.
∂2 f
∂xi∂x j
(x) =
∂2 f
∂x j∂xi
(x),
for all i, j = 1, . . . , n, i ̸= j.
A vector function h =

h1, . . . , h p
	⊤: X ⊂Rn →Rp is differentiable at x0 ∈
int(X) if each component hi : X →R, i = 1, . . . , p, is differentiable at x0. In this
case we can build the matrix
Jh(x0) ≡∇h(x0) =

∇h1(x0), . . . , ∇h p(x0)
	
of order (n, p), called the Jacobian matrix of h at x0. We draw the reader’s attention
on the fact that many authors deﬁne the Jacobian matrix as a matrix whose rows are
the gradients of the functions hi(x), i = 1, . . . , p.
Now, let be given f : X ⊂Rn →Rm and g : Rm →Rp, both differentiable, and
consider the composite function h = g ◦f : X →Rp, deﬁned by means of the com-
position operation h(x) = g( f (x)). This function will be differentiable and it holds
(“chain rule”):
∇h(x0) = ∇f (x0)∇g( f (x0)).
We recall Taylor’s formula for twice-continuously differentiable functions.
(a) Let f : X →R be a C 2-function on the open set X ⊂Rn and let be U(x0) ⊂X.
Then, for any x ∈U(x0) we have

1.2 Basic Notions of Analysis and Linear Algebra
5
f (x) = f (x0) + ∇f (x0)⊤(x −x0) + 1
2(x −x0)⊤∇2 f (x0)(x −x0) + o
 x −x0
2 
,
for x →x0.
(Taylor’s formula with remainder in Peano’s form).
(b) Let f : X →R be a C 2-function on the open set X ⊂Rn and let be U(x0) ⊂X.
Then, for any x ∈U(x0) we have
f (x) = f (x0) + ∇f (x0)⊤(x −x0) + 1
2(x −x0)⊤∇2 f (¯x)(x −x0),
where ¯x = x0 + θ(x −x0), with θ ∈(0, 1).
(Taylor’s formula with remainder in Lagrange’s form).
Putting h = x −x0, Taylor’s formula with remainder in Peano’s form becomes
f (x0 + h) = f (x0) + ∇f (x0)⊤h + 1
2h⊤∇2 f (x0)h + o(∥h∥2)
and putting h = tv, with t ∈(−ε, ε) and v ∈Rn, ∥v∥= 1,
f (x0 + tv) = f (x0) + t∇f (x0)⊤v + t2
2 v⊤∇2 f (x0)v + o(t2).
Systems of linear equations
Let be given a vector a ∈Rn, a ̸= 0, and a scalar β ∈R. The set
H(a, β) =

x ∈Rn : a⊤x = β

is a hyperplane in Rn. The vector a is called the normal to the hyperplane H(a, β).
Note that a hyperplane is a level set of a non-identically zero linear function.
Let be given a (real) matrix A of order (m, n), with m ≦n non-zero row vectors,
and a vector b ∈Rm. The solutions of the linear system
Ax = b
are given by the intersection of m hyperplanes. If the set of solutions is not empty,
it will be a linear manifold (a linear subspace if b = 0 ∈Rm), with dimension n −
rk(A), where rk(A) denotes the rank of matrix A.
Let the row vectors of A be linearly independent, i.e. matrix A has full rank. It is
then possible (maybe by reordering the rows of A) to decompose A into the form
A = (AB, AN)
with AB square non-singular matrix of order m. Correspondingly, vector x ∈Rn will
be partitioned as

6
1
Basic Notions and Deﬁnitions
x =
 xB
xN

,
where xB is called vector of basic variables and xN is the vector of non-basic
variables.
Then, the original system Ax = b has now the form
ABxB + AN xN = b
from which
xB = (AB)−1(b −AN xN).
Systems of nonlinear equations and Implicit Function Theorem
In the general case, the vector equation h(x) = b is not formed by linear equations.
Nevertheless, if the Jacobian matrix of h has full rank at a point x0 which solves the
equation h(x0) = 0, it is possible to get some important solvability results. These
results are contained in the following classical version of the Implicit Function Theo-
rem. In essence, this theorem gives sufﬁcient conditions for the existence of a function
that locally expresses a set of basic variables in terms of non basic variables, i.e. a
nonlinear version of what previously seen for the linear case.
Implicit Function Theorem
Let h : X ⊂Rn →Rm (m < n) be C 1 on the open set X and let x0 ∈X be a solution
of h(x) = 0. Let ∇h(x0) be of full rank, i.e. rk(∇h(x0) = m, decomposed as (after
a possible reordering of the variables)
∇h(x0) =
 ∇Bh(x0)
∇Nh(x0)

,
where ∇Bh(x0) is a non-singular square matrix of order m. Then, there exists a
neighborhood U of x0
N ∈Rn−m where the system h(x) = 0 deﬁnes “implicitly” a
system of functions of the type xB = H(xN). More precisely:
(a) There exists a unique function H : Rn−m →Rm, deﬁned in a neighborhood U
of x0
N, of C 1 class in this neighborhood.
(b) It holds h(H(xN), xN) = 0, for all xN in the said neighborhood U.
(c) H(xN) = xB for all xN in the said neighborhood U.
(d) It holds
∇H(x0
N) = −(∇Nh(x0))(∇Bh(x0))−1.
There are also weaker versions of this theorem; in particular, it is possible to
consider differentiable functions, instead of C 1 functions. See, e.g., Halkin [2].

1.2 Basic Notions of Analysis and Linear Algebra
7
Quadratic forms
Let be given a (real) symmetric matrix A of order n. The related quadratic form
Q : Rn →R is deﬁned as
Q(x) = x⊤Ax, x ∈Rn.
The above quadratic form (and its related matrix A) is classiﬁed as follows.
(a) Q is positive (negative) deﬁnite if Q(x) > 0 (Q(x) < 0), for all x ∈Rn, x ̸= 0.
(b) Q is positive (negative) semideﬁnite if Q(x) ≧0 (Q(x) ≦0), for all x ∈Rn.
(c) Q is indeﬁnite if there exist two vectors x1, x2 ∈Rn such that Q(x1) > 0 and
Q(x2) < 0.
Obviously the quadratic form x⊤Ax (i.e. the symmetric matrix A which charac-
terized the said quadratic form) is positive (negative) deﬁnite (semideﬁnite) if and
only if −A is negative (positive) deﬁnite (semideﬁnite).
We have the following two criteria which establish the sign of a quadratic form.
Theorem 1.1 The quadratic form Q(x) = x⊤Ax (the real symmetric matrix A) is:
(a) Positive (negative) deﬁnite if and only if all eigenvalues of A (which are real,
being A symmetric) are positive (negative).
(b) Positive (negative) semideﬁnite if and only if all eigenvalues of A are nonnegative
(nonpositive) and at least one eigenvalue of A is zero.
(c) Indeﬁnite if and only if A has at least one positive eigenvalue and least one
negative eigenvalue.
In order to introduce the next criterion (“Sylvester criterion”), we recall that, given
a matrix A, of order (m, n), we have the following deﬁnitions.
Theminors of order k of A,1 ≦k ≦min(m, n),areall thosedeterminants formed
by k rows and k columns of A. It is shown that we have
 m
k
 n
k

minors of order k. We recall that
n
k

=
n!
k!(n −k)!.
Now, let A be a square matrix of order n.
The principal minors of A of order k, 1 ≦k ≦n, are all those determinants
formed by k rows of A and the corresponding k columns. It is shown that we have
n
k


8
1
Basic Notions and Deﬁnitions
principal minors of order k.
The leading principal minors or North-West principal minors of A of order k,
1 ≦k ≦n, are all those determinants formed by the ﬁrst k rows and the ﬁrst k
columns of A. Obviously, we have n leading principal minors:
|a11| = a11,




a11
a12
a21
a22




 ,






a11
a12
a13
a21
a22
a23
a31
a32
a33






, . . . , |A| .
Theorem 1.2 (Sylvester criterion for quadratic forms) Let be given the quadratic
form Q(x) = x⊤Ax. Then Q(x) (i.e. the symmetric matrix A) is:
(i) Positive deﬁnite if and only if all leading principal minors of A are positive.
(ii) Negative deﬁnite if and only if all leading principal minors of A alternate in
sign, beginning with a11 < 0.
(iii) Positive semideﬁnite if and only if all principal minors of A are nonnegative
and |A| = 0.
(iv) Negative semideﬁnite if and only if all principal minors of A of odd order are
nonpositive, of even order are nonnegative, and |A| = 0.
(v) Indeﬁnite on the residual cases.
Note that if a symmetric matrix A is positive (negative) semideﬁnite and |A| ̸=
0, then A is positive (negative) deﬁnite, since A cannot have in this case, a zero
eigenvalue.
In many applications of real quadratic forms we are interested in determining the
sign of a quadratic form Q(x) when x ∈Rn must belong to some subset of Rn. In
particular, an important case is when x must belong to the set of nonzero solutions
of a homogeneous linear system of the form
Bx = 0,
where B is a matrix of order (m, n), with m < n and rk(B) = m. Let us consider
the following “bordered matrix”, square of order m + n :
M =
 0
B
B⊤
A

.
Theorem 1.3 Let be rk(B) = m and, without loss of generality, suppose that the ﬁrst
m columns of B are linearly independent. Then Q(x) = x⊤Ax is positive deﬁnite
on the set of nonzero solutions of Bx = 0 if and only if the leading principal minors
of M, of order 2m + 1, . . . , m + n, have the sign of (−1)m:
(−1)mΔh > 0, ∀h = 2m + 1, . . . , m + n,
where Δh is the h-th leading principal minor of M.

1.3 Basic Deﬁnitions and Properties of Optimization Problems
9
Q(x) = x⊤Ax is negative deﬁnite on the same set if and only if the sign of Δh
alternate, for h = 2m + 1, . . . , m + n, beginning with the sign of (−1)m+1.
See, e.g., Debreu [3].
Corollary 1.4 If m = 1, i.e. we have one constraint of the type b⊤x = 0, with b1 ̸=
0, the previous conditions become:
(a) Q(x) is positive deﬁnite on the set of nonzero solutions of b⊤x = 0 if and only if
Δ3 =






0
b1
b2
b1 a11 a12
b2 a21 a22






< 0, . . . , |M| > 0.
(b) Q(x) is negative deﬁnite on the same set of (a) if and only if
Δ3 =






0
b1
b2
b1 a11 a12
b2 a21 a22






> 0, Δ4 =








0
b1
b2
b3
b1 a11 a12 a13
b2 a21 a22 a23
b3 a31 a32 a33








< 0, etc.
We point out that the assumption in Theorem 1.3 stating that the ﬁrst m columns
of B give the rank of B (if necessary, renumber the variables) is essential to obtain
necessary and sufﬁcient conditions for checking the sign of a constrained quadratic
form. In absence of the said assumption, we have only sufﬁcient conditions. Consider,
e.g., Q : R3 →R, x = (x1, x2, x3) ∈R3,
Q(x) = (x1)2 + (x2)2 −(x3)2,
which is positive deﬁnite on x3 = 0 (i.e. here b⊤= [0, 0, 1]). Yet we have
Δ3 =






0 0 0
0 1 0
0 0 1






= 0.
1.3
Basic Deﬁnitions and Properties of Optimization
Problems
Any non-empty set S of real numbers that is bounded above has a least upper bound
b∗, i.e. b∗is an upper bound for S and b∗≦b for every upper bound b of S; b∗
is called the supremum of S and we write b∗= sup(S). If b∗∈S, then b∗is the
maximum of S and we write b∗= M = max(S).
Any non-empty set S of real numbers that is bounded below has a greatest lower
bound a∗, i.e. a∗is a lower bound for S and a∗≧a for every lower bound a of S;

10
1
Basic Notions and Deﬁnitions
a∗is called the inﬁmum of S and we write a∗= inf(S). If a∗∈S, then a∗is the
minimum of S and we write a∗= m = min(S).
If S ⊂R is not bounded above, we write sup(S) = +∞and if S is not bounded
below, we write inf(S) = −∞. One usually deﬁnes sup(∅) = −∞and inf(∅) =
+∞.
Obviously, with S ⊂Rn and f : S →R, we have that the inﬁmum value of f is
a∗= inf
x∈S f (x) = inf { f (x) : x ∈S} ;
the minimum value of f is
m = min
x∈S f (x) = min { f (x) : x ∈S} ;
the supremum value of f is
b∗= sup
x∈S
f (x) = sup { f (x) : x ∈S} ;
the maximum value of f is
M = max
x∈S f (x) = max { f (x) : x ∈S} .
In the following we will consider a minimization problem or a maximization
problem of the form
(P) :
min
x∈S f (x) or max
x∈S f (x),
where f : Rn →R is a real-valued function, called the objective function, and S ⊂
Rn is a subset of the domain of f, dom( f ). The case S = dom( f ) is not excluded.
The set S is called also the feasible set or feasible region or opportunity set. When S
is an open set (e.g. when S = Rn) or, more generally, when for the optimal point x0 it
holds x0 ∈int(S), we speak of unconstrained mathematical programming problem.
We suppose in any case that S ̸= ∅.
We recall some basic deﬁnitions.
Deﬁnition 1.5 A point x0 ∈S is called a global minimum point or global minimizer
for problem (P) or for the function f on S (respectively: a global maximum point
or global maximizer for problem (P) or for the function f on S) if
f (x0) ≦f (x), ∀x ∈S
(resp. f (x0) ≧f (x), ∀x ∈S).
We note the following facts.
• Global minimizers (global maximizers) need not exist, as one can see by consid-
ering the following examples.

1.3 Basic Deﬁnitions and Properties of Optimization Problems
11
(a) Minimize the function f (x) = 1/x2 over S = R \ {0} .
(b) Minimize the function f (x) = e−x2 over S = R.
(c) Minimize the function f (x) = x over S = {x ∈R : x > 0} .
• Global minimizers (global maximizers) need not be unique. One example is the
function f (x) = (x2 −1)2, with S = R, which has two global minimizers: x0 =
±1. A more extreme example is the function f (x) = k, k ∈R, for which every
point x ∈R is a global minimizer and a global maximizer.
The value m = y0 = f (x0), with x0 a global minimizer (the value M = y0 =
f (x0), with x0 a global maximizer) of f over S , is also said to be the global
minimum (resp. the global maximum) of f over S. The set of global minimizers
(global maximizers) is sometimes denoted by
arg min
x∈S
f (x)

arg max
x∈S
f (x)

.
It is easy but important to note that the minimizers of a function f on S coincide
with the maximizers of −f on S; we simply write
min
x∈S f (x) = max
x∈S −f (x),
whereas for the minimum value m = f (x0) and for the maximum value M =
−f (x0), we have the obvious relation
m = −M.
In order to avoid unnecessary and trivial repetitions, we shall be mainly concerned
in the sequel with minimization problems, being the results related to maximization
problems easily obtainable from the previous ones.
Deﬁnition 1.6 A point x0 ∈S is called a local minimizer or local minimum point
for problem (P) or for the function f on S if there exists a neighborhood N(x0) of
x0 such that x0 is a global minimizer of the problem
min
x∈S∩N(x0) f (x).
In other words, x0 ∈S is a local minimizer or a local minimum point for f on S,
if there exists ε > 0 such that
f (x0) ≦f (x),
for all x ∈S such that
x −x0 ≦ε.
Slightly strengthening the above deﬁnitions, we obtain the following ones.

12
1
Basic Notions and Deﬁnitions
Deﬁnition 1.7 A point x0 ∈S is called a strict local minimizer for problem (P) or
for the function f on S, if
f (x0) < f (x), ∀x ̸= x0, x ∈S ∩N(x0).
In other words, with respect to Deﬁnition 1.6, we replace the weak inequality ≦
by the strict inequality < (and in this case we consider x ̸= x0, x ∈S ∩N(x0)).
Deﬁnition 1.8 A point x0 ∈S is called a strict global minimizer for problem (P)
or for the function f on S, if
f (x0) < f (x), ∀x ̸= x0, x ∈S.
Remark 1.9 (a) If x0 is a global minimum point, then x0 is of course a local mini-
mum point. If x0 is a strict local (or also global) minimum point, then x0 is of course
also a local (or global) minimum point.
(b) The isolated points of S are both minimizers and maximizers, at least in the local
sense, of f : S →R.
(c) If there exists for (P) a strict global minimizer x0, then x0 is obviously the unique
strict global minimizer. However, note that it may exist inﬁnite global minimizers
(not in a strict sense!). For example, the function f (x) = sin x, x ∈R, presents
inﬁnite global minimizers at x0 = 3
2π ± 2kπ and inﬁnite global maximizers at x00 =
π
2 ± 2kπ. None of these points is, respectively, a strict global minimizer (a strict
global maximizer), as at all these points the value of the function is −1 (respectively:
1). On the other hand, everyone of the said points is, respectively, a strict local
minimizer (a strict local maximizer).
(d) It may also exist inﬁnite strict local minimizers (which however are not global
ones): for example, the function f (x) = x sin x,
x ∈R, has inﬁnite strict local
minimizers and inﬁnite strict local maximizers, which are not global ones.
Deﬁnition 1.10 A point x0 ∈S is called an isolated local minimizer for (P) if there
exists a neighborhood N(x0) of x0 such that x0 is the unique local minimizer for
f (x) in the said neighborhood N(x0) or in N(x0) ∩S.
Notethat everyisolatedlocal minimizer is astrict local minimizer, but theconverse
does not hold in general. As an example, consider the (rather pathological) function
f (x) =

2x2 + x2 sin
 1
x

if x ∈R, x ̸= 0,
0
if x = 0.
This function has a strict local minimizer at x0 = 0 (which is at the same time
the unique global minimizer of f ), but there exists a sequence of (isolated!) local
minimizers converging to zero. Thus the minimizer x0 = 0 is not isolated.
Deﬁnition 1.11 A point x0 ∈S is a strict local minimizer (or a minimum point) of
order p ∈N for (P), if there are a neighborhood N(x0) and a constant k > 0 such
that, it holds

1.3 Basic Deﬁnitions and Properties of Optimization Problems
13
f (x) ≧f (x0) + k
x −x0p , ∀x ∈S ∩N(x0).
If p = 1, the point x0 is more commonly called a strong local minimizer for (P)
or also a sharp local minimizer. If p = 2 some authors speak of “quadratic growth
condition”. We observe that if x0 is a strict local minimizer of order p, then it is also
a strict local minimizer of order r for all r > p. Moreover, it is clear that any strict
local minimizer of order p is a strict local minimizer. However, not every strict local
minimizer is a strict local minimizer of order p for some p.
For example, deﬁne f : [0, +∞) →R as follows
f (x) = x
1
x for x > 0,
f (0) = 0
and let S = [0, +∞) . Then x0 = 0 is a strict local minimizer that is not a strict local
minimizer of order p for any p ∈N.
Existence of Minimizers
First recall that the lower limit of a sequence of real numbers {zk} is deﬁned as
lim inf
k→∞zk = lim
k→∞inf
ℓ≧k zℓ.
This is equivalent to deﬁning lim inf
k→∞zk as the smallest possible limit of convergent
subsequences of {zk}. Note that, in contrast to the usual notion of limit of a sequence,
every sequence has a lower limit (the sequence (infℓ≧k zℓ)k∈N is increasing, and
therefore its limit exists).
Similarly for the deﬁnition of the upper limit of a sequence of real numbers {zk} :
lim sup
k→∞
zk = lim
k→∞sup
ℓ≧k
zℓ.
It can be proved that
lim sup
k→∞
zk ≧lim inf
k→∞zk
and that a sequence {zk} in R converges to a limit ¯z ∈R if and only if
lim sup
k→∞
zk = lim inf
k→∞zk = ¯z.
The above notions can be given directly with reference to a real-valued function
f : X ⊂Rn →R. If x0 ∈X, x0 is an accumulation point for X, we have
lim inf
x→x0
f (x) =
sup
U(x0)
inf
x∈U(x0)\{x0}
f (x)
lim sup
x→x0
f (x) =
inf
U(x0)
sup
x∈U(x0)\{x0}
f (x).

14
1
Basic Notions and Deﬁnitions
Deﬁnition 1.12 A function f : X ⊂Rn →R is said to be lower semi-continuous
on X if for every x ∈X and every sequence {xk} ⊂X converging to x we have
f (x) ≦lim inf
k→∞
f (xk).
A function f : X ⊂Rn →R is said to be upper semi-continuous on X if (and
only if) −f is lower semi-continuous on X, i.e. for every x ∈X and every sequence
{xk} ⊂X converging to x we have
lim sup
k→∞
f (xk) ≦f (x).
Thus, for a lower semi-continuous function, whenever we have a sequence {xk}
converging to x, the sequence of values { f (xk)} cannot have a limit smaller than
f (x). Similarly for an upper semi-continuos function.
Deﬁnition 1.12 can be restated in the following terms: f : X ⊂Rn →R is lower
semi-continuous on X if for every x0 ∈X (x0 accumulation point for X)
f (x0) ≦lim inf
x→x0
f (x).
(Similarly for upper semi-continuous functions).
We point out that several authors do not take into consideration, in the above
relation, a deleted neighborhood U(x0) \

x0
, but simply a neighborhood U(x0).
Under this assumption, f : X ⊂Rn →R is lower semi-continuous on X if for every
x0 ∈X
f (x0) = lim inf
x→x0
f (x).
A lower semi-continuous function (an upper semi-continuous function) need not
be a continuous function; indeed, it holds the vice-versa, as stated by the following
basic result.
Theorem 1.13 A function f : X ⊂Rn →R is continuous on X if and only if it is
both lower semi-continuous and upper semi-continuous on X.
Example 1.14 (a) The function f : R →R deﬁned by
f (x) =
 x2
if x > 0,
x2 −1 if x < 0
is lower semi-continuous, but not continuous.
(b) The function f : R →R deﬁned by
f (x) =
sin(1/x) if x ̸= 0,
−1
if x = 0

1.3 Basic Deﬁnitions and Properties of Optimization Problems
15
is lower semi-continuous, but not continuous.
(c) The function f : R →R deﬁned by
f (x) =
⎧
⎨
⎩
1
if x > 0,
0
if x = 0,
−1 if x < 0
is not lower semicontinuous (nor continuous).
(d) If fi : Rn→R, i ∈I, is any family of continuous functions, then the function
f (x) = sup
i∈I
fi(x)
is lower semi-continuous (note that it is not required that the family is ﬁnite!).
Remark 1.15 An alternative equivalent deﬁnition of lower semi-continuity is the
following one.
(a) A function f : X ⊂Rn→R is lower semi-continuous on X if (and only if) its
lower level set
lev≦α f =

x ∈X : f (x) ≦α

is relatively closed in X for every α ∈R. In other words: whenever α ∈R and
xk ∈lev≦α f is a sequence that converges to some x ∈X, we have that x ∈
lev≦α f. Because this characterization does not rely directly on sequences but
rather on the notion of closedness, it can, in some situations, be less cumbersome
to handle.
Other equivalent characterizations of lower semi-continuity of f : X ⊂Rn→R
are:
(b) The set
lev>α f = {x ∈X : f (x) > α}
is relatively open in X for every α ∈R.
(c) The epigraph of f :
epi( f ) =

(x, ζ) : x ∈X, ζ ∈R, f (x) ≦ζ

is relatively closed in X × R.
The importance of semi-continuous functions lies in a generalization of the well-
known Weierstrass Theorem.
Deﬁnition 1.16 Assume that the set S ⊂Rn of problem (P) is nonempty and let
f ∗= inf
x∈S f (x) ( f ∗may be −∞).
A minimizing sequence for (P), i.e. for the problem

16
1
Basic Notions and Deﬁnitions
min
x∈S f (x),
is a sequence {xk} ⊂S satisfying
lim
k→∞f (xk) = f ∗.
That is, a minimizing sequence is a sequence such that the function values of
which converge to the minimal (inﬁmal) value of f. A minimizing sequence always
exists. Note that this does not say anything about the convergence of the sequence

xk
itself. For example, the sequence
xk = (2k + 1)π + 1/k
is a minimizing sequence for the function f (x) = cos x.
Theorem 1.17 (Generalized Weierstrass Theorem) Assume that
S ⊂Rn
is
nonempty, closed and bounded (i.e. compact) and let be f : S →R.
(a) If f is lower semi-continuous on S, it admits at least one global minimizer
x∗∈S.
(b) If f is upper semi-continuous on S, it admits at least one global maximizer
x∗∗∈S.
Proof We prove only part (a). Since f is upper semi-continuous if and only if −f is
lower semi-continuous. Let {xk} ⊂S be a minimizing sequence for the optimization
problem (P). Because S is closed and bounded, it follows that the sequence {xk}
admits a sub-sequence, say {¯xk} ⊂S, converging to some point x∗∈S (Heine-Borel
Theorem). Thus the deﬁnitions of xk, ¯xk, and x∗, and the lower semi-continuity of
f imply that
inf
x∈S f (x) = f ∗= lim
k→∞f (xk) = lim
k→∞f (¯xk) = lim inf
k→∞
f (¯xk) ≧f (x∗),
which shows that f (x∗) ≦f (x) for every x ∈S. In other words, x∗is a global
minimizer of f on S.
□
Corollary 1.18 (Weierstrass Theorem) Assume that S ⊂Rn is closed and bounded
and that f : S →R is continuous on S. Then, there exists x∗∈S such that f (x∗) ≦
f (x), ∀x ∈S, and there exists x∗∗∈S such that f (x∗∗) ≧f (x), ∀x ∈S.
In order to obtain an existence result that is also applicable to an optimization
problem where the feasible set S ⊂Rn is not bounded, we have to introduce another
deﬁnition.

1.3 Basic Deﬁnitions and Properties of Optimization Problems
17
Deﬁnition 1.19 A function f : X ⊂Rn →R is called coercive, if every sequence
{xk} ⊂X, with
xk →∞, satisﬁes f (xk) →∞.
Theorem 1.20 Assume that in problem (P) the feasible set S ⊂Rn is nonempty and
closed, and that f : S →R is lower semi-continuous and coercive. Then problem
(P) admits at least one global minimizer x∗.
Proof Let {xk} ⊂S be a minimizing sequence of the optimization problem. Then the
sequence{ f (xk)}doesnotdivergeto∞,andthereforethecoercivityof f impliesthat
the sequence {xk} is bounded. Thus it admits a sub-sequence {¯xk} ⊂S converging
to some point x∗∈Rn. Because S is closed, it follows that, actually x∗∈S. Thus
we have (as above) that
inf
x∈S f (x) = f ∗= lim
k→∞f (xk) = lim
k→∞f (¯xk) = lim inf
k→∞
f (¯xk) ≧f (x∗),
which shows that x∗is a global minimizer of f on S.
□
In the sequel we shall be mainly concerned with the following mathematical
programming problems (or optimization problems): (P1), (P2), (P3), (P4) and (P5).
(1) Unconstrained minimization problems
(P1) :
min f (x), subject to x ∈S ⊂Rn,
where f : Rn →R and S is an open set or, more generally, where for the optimal
point x0 it holds x0 ∈int(S). In other words, we are looking for those optimal
points x0 of f (x) which are interior to S. We note that in this case the deﬁnition
of local minimizer for (P1) can be rewritten in the form
f (x0) ≦f (x), ∀x ∈U(x0),
being obviously always possible to choose U(x0) such that U(x0) ⊂S.
(2) Constrained minimization problems with a set constraint (or abstract
constraint)
(P2) :
min f (x), subject to x ∈S ⊂Rn,
where f : Rn →R and S is not necessarily open or not necessarily the optimal
point x0 is interior to S. We recall that the function f is called the objective
function and the set S ⊂Rn is called the feasible set or constraint set. We shall
assume S ̸= ∅; however, many authors adopt the convention that if S = ∅, then
minx∈S f (x) = infx∈S f (x) = +∞.

18
1
Basic Notions and Deﬁnitions
(3) “Classical” constrained minimization problems, i.e. minimization problems
with only equality constraints
(P3) :
⎧
⎨
⎩
min f (x)
subject to: h j(x) = 0, j = 1, . . . , p,
x ∈X ⊂Rn,
where X ⊂Rn is an open set contained in the domains of the functions involved
in (P3), f and each h j, j = 1, . . . , p < n, are real-valued function deﬁned on
Rn. The set
K3 =

x ∈X : h j(x) = 0, j = 1, . . . , p < n

is the feasible set for (P3) and f is the objective function. The restriction p < n
is made in order to avoid that the feasible set shrinks to only isolated points or
to the empty set.
This type of constrained minimization problem is called “classical”, as its anal-
ysis and related solution go back to the work of J. L. Lagrange (1736–1813). For
some related historical questions see, e.g., the book of Giorgi and Kjeldsen [4].
(4) Constrained minimization problems with only inequality constraints
(P4) :
⎧
⎨
⎩
min f (x)
subject to: gi(x) ≦0, i = 1, . . . , m,
x ∈X ⊂Rn,
where X ⊂Rn is an open set contained in the domains of the functions involved
in (P4), f and each gi, i = 1, . . . , m, are real-valued function deﬁned on Rn.
The set
K4 =

x ∈X : gi(x) ≦0, i = 1, . . . , m

is the feasible set for (P4) and f is the objective function. In contraposition
with (P3), (P4) is a type of “modern” constrained minimization problem or
nonlinear programming problem, as these problems have been systematically
analyzed starting from the second half of the 20th century.
We note that our formulation is sufﬁciently general for our purposes: for exam-
ple, a maximization problem can be transformed (as already remarked) into a
minimization problem:
max f (x) = min(−f (x)).
If we have a constraint of the type gi(x) ≧0, we can equivalently write
−gi(x) ≦0, and if we have a constraint of the type φi(x) ≦bi, we can equiva-
lently write gi(x) ≦0, where gi(x) ≡φi(x) −bi. Also the nonnegativity con-
straint on vector x could be transformed into: −x1 ≦0, . . . , −xn ≦0, even if
this procedure is not too useful.

1.3 Basic Deﬁnitions and Properties of Optimization Problems
19
(5) Constrained minimization problems with mixed constraints or general non-
linear programming problems
(P5) :
⎧
⎪⎪⎨
⎪⎪⎩
min f (x)
subject to: gi(x) ≦0, i = 1, . . . , m,
h j(x) = 0, j = 1, . . . , p < n,
x ∈X ⊂Rn,
where X ⊂Rn is an open set contained in the domains of the functions involved
in (P5), f , gi, i ∈M = {1, . . . , m} and h j, j ∈P = {1, . . . , p < n} are real-
valued functions deﬁned on Rn. In this case the feasible set is given by
K5 =

x ∈X : gi(x) ≦0, ∀i ∈M; h j(x) = 0, ∀j ∈P

,
and f is the objective function for (P5).
If in the above problems the objective function and the constraints are at least dif-
ferentiable, we speak of differentiable or smooth mathematical programming prob-
lems, otherwise of nonsmooth mathematical programming problems. If the objective
function and the inequality constraints are convex functions, the equality constraints
are afﬁne functions and X ⊂Rn is a convex set, then we speak of convex program-
ming problems (see Chap. 8). We shall be concerned also with some important
particular cases of the above problems:
(A) The Linear Programming Problem, usually written, for a minimization problem,
in the form
⎧
⎨
⎩
min c⊤x
Ax ≧b
x ≧0,
where c, x ∈Rn, A is a (real) matrix of order (m, n) and b ∈Rm. Here the
inequality signs are meant to denote componenwise inequality. The constraint
x ≧0 is usually called “nonnegativity constraint”. If the problem is a maximiza-
tion one, it is usually written as
⎧
⎨
⎩
max c⊤x
Ax ≦b
x ≧0.
(B) The Quadratic Programming Problem, under linear constraints, usually written,
for a minimization problem, in the form

min 1
2 x⊤Qx + p⊤x
subject to: Ax ≧b, x ≧0,

20
1
Basic Notions and Deﬁnitions
where Q is a symmetric matrix of order n, p ∈Rn, x ∈Rn, A is a (real) matrix
of order (m, n) and b ∈Rm.
Problems (A) and (B) are quite important, above all for economic applications.
There are also other special and important types of mathematical programming
problems we however shall not treat in the present book, e.g.:
• The fractional programming problem, usually written, for a minimization problem,
in the form

min a(x)
b(x)
subject to : gi(x) ≦0, i = 1, . . . , m,
where a(x), b(x) and every gi(x) are real-valued functions on Rn and b(x) > 0,
∀x ∈dom(b).
Also this type of mathematical programming problem has several interesting appli-
cations.
• The semi-inﬁnite programming problem, usually written, for a minimization prob-
lem, in the form

min f (x)
subject to : gα(x) ≦0, α ∈I,
where f (x) and gα(x) are real-valued functions deﬁned on Rn and I is an arbitrary
index set. Also this type of mathematical programming problems has received a
growing attention owing to its interesting applications.
Finally, we give here some hints on vector optimization problems, in ﬁnite dimen-
sions, called also multiobjective optimization problems. For example
(V min) :

V min f (x) =

f1(x), f2(x), . . . , fq(x)
	⊤
subject to: x ∈S ⊂Rn.
In multiobjective optimization problems the objectives often conﬂict with each
other and consequently the concepts of optimality seen for the scalar case are not
directly suitable for the vector case, even if there are techniques of scalarization,
in order to transform a vector problem into a scalar problem. These techniques,
however, work under suitable assumptions.
Of course, if there exists a feasible point x0 ∈S which minimizes all the com-
ponents of the vector objective function simultaneously, it provides a solution to the
problem. Such a point is usually called an utopia solution or utopia point, but this kind
of solution seldom exists and we are obliged to introduce other solution concepts.
These new concepts of optimality for the vector case were introduced, within Eco-
nomic Analysis, by the English economist Francis Ysidro Edgeworth (1845–1926)
in 1881 and by the Italian economist and sociologist Vilfredo Pareto (1848–1923) in
1896.

1.3 Basic Deﬁnitions and Properties of Optimization Problems
21
First, we remark that if we have a scalar function f : Rn →R, the deﬁnition of
(global) minimum point x0 for f over S ⊂Rn is, as previously seen,
f (x0) ≦f (x), ∀x ∈S.
This is equivalent to require that there exists no x ∈S such that
f (x0) > f (x).
If we wish to extend the concept of optimal point to problem (V min), the said
equivalence is no longer valid, but this second way is the right way to introduce the
concepts of optimal points for the vector case. More precisely, we have the following
formal deﬁnitions.
Deﬁnition 1.21 A feasible point x0 ∈S is said to be an efﬁcient solution (or Pareto
optimal solution) for (V min) if there exists no x ∈S such that
fi(x) ≦fi(x0), i = 1, . . . , q,
with at least one strict inequality.
If we denote by Rq
+ the nonnegative orthant of Rq, i.e. all vectors of Rq with
nonnegative elements, and by Rq
−the nonpositive orthant of Rq, i.e. all vectors of
Rq with nonpositive elements, the previous deﬁnition can be rewritten as
f (x) −f (x0) /∈Rq
−\ {0} .
Deﬁnition 1.22 A feasible point x0 ∈S is said to be a weak efﬁcient solution (or a
weakly efﬁcient solution) for (V min) if there exists no x ∈S such that
fi(x) < fi(x0), i = 1, . . . , q,
i. e., with S f =

x ∈Rn : fi(x) < fi(x0), i = 1, . . . , q

,
S f ∩S = ∅,
i. e.
f (x) −f (x0) /∈int(Rq
−), ∀x ∈S.
If the previous deﬁnitions are veriﬁed in N(x0) ∩S, where N(x0) is a suitable
neighbourhood of x0, then x0 is said, respectively, a local efﬁcient solution and a local
weak efﬁcient solution. Note that in the scalar case (q = 1), the above deﬁnitions
collapse to the ordinary deﬁnitions of a global (or local) minimum point. Note,
moreover, that (local) efﬁciency implies (local) weak efﬁciency.
Of course other ordering cones, not necessarily coincident with Rq
−or Rq
+, can
be considered. For example, if K is a convex cone in Rq, containing the origin and

22
1
Basic Notions and Deﬁnitions
pointed (i.e. (x ∈K, x ̸= 0) ⇒−x /∈K), then x0 ∈S is said to be a K-efﬁcient
point or K-minimal point for f : S ⊂Rn →Rq if there exists no x ∈S such that
f (x0) ∈f (x) + K \ {0} ,
a weak K-minimal point, if there exists no x ∈S such that
f (x0) ∈f (x) + int(K).
It can be proved that the order relation “induced” by the cone K veriﬁes the
reﬂexive, antisymmetric and transitive properties. For the deﬁnition of cone and
convex cone, see Chap. 2. These subjects will be developed in Chap. 11.
We point out that in the present book we do not intend to discuss the important
subjects concerning the various algorithms or numerical methods available to solve
or to get an approximate solution of the various mathematical programming problems
described above. We intend to express the basic optimality conditions referred to the
said problems, conditions which are, beyond their intrinsic interest, a fundamental
tool for developing the related numerical algorithms.
References
1. H.W. Kuhn, A.W. Tucker, Nonlinear programming, in Proceedings of the Second Berkeley Sym-
posium on Mathematical Statistics and Probability, ed. by J. Neyman (University of California
Press, Berkeley, 1951), pp. 481–492. Reprinted in Giorgi and Kjeldsen (2014)
2. H. Halkin, Implicit functions and optimization without continuous differentiability. SIAM J.
Control Optim. 12, 229–236 (1974)
3. G. Debreu, Deﬁnite and semideﬁnite quadratic forms. Econometrica 20, 285–300 (1952)
4. G. Giorgi, T.H. Kjeldsen, Traces and Emergence of Nonlinear Programming (Birkhäuser, Basel
and New York, 2014)

Chapter 2
Elements of Convex Analysis. Linear
Theorems of the Alternative. Tangent
Cones
2.1
Elements of Convex Analysis
Mathematical programming theory is strictly connected with Convex Analysis. We
giveinthepresentsectionthemainconceptsanddeﬁnitionsregardingconvexsetsand
convex cones. Convex functions and generalized convex functions will be discussed
in the next chapter.
Geometrically, a set S ⊂Rn is convex if the line segment joining any two points
in the set lies entirely in the set. We recall that the (closed) line segment joining the
points x1 and x2 of S, denoted as

x1, x2
, is given by

x1, x2
=

λx1 + (1 −λ)x2 : 0 ≦λ ≦1

=

x1 + λ(x2 −x1) : 0 ≦λ ≦1

.
The open line segment is denoted as (x1, x2) and is given by
(x1, x2) =

λx1 + (1 −λ)x2 : 0 < λ < 1

.
We have the following basic deﬁnitions.
Deﬁnition 2.1 A nonempty set S ⊂Rn is convex if for any two points x1, x2 ∈S,
we have

x1, x2
⊂S. A set S ⊂Rn is strictly convex if
λx1 + (1 −λ)x2 ∈int(S), for all x1, x2 ∈S, x1 ̸= x2, for all λ ∈(0, 1).
Note that, unlike a convex set, the boundary of a strictly convex set cannot contain
any segment. The empty set ∅is considered to be convex; any singleton (i.e. a set
containing just one single point) is convex.
We recall now some basic deﬁnitions concerning various types of combinations
of vectors of Rn.
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al., Basic Mathematical Programming Theory, International Series
in Operations Research & Management Science 344,
https://doi.org/10.1007/978-3-031-30324-1_2
23

24
2
Elements of Convex Analysis. Linear Theorems of the Alternative. Tangent Cones
Let x1, x2, . . . , xk be vectors of Rn. A linear combination of the vectors x1,
x2, . . . , xk is any expression of the form
k

i=1
αixi
(2.1)
where each αi ∈R.
When k
i=1 αi = 1, the linear combination (2.1) is called afﬁne combination of
the vectors x1, x2, . . . , xk.
When it holds that each αi ≧0, the linear combination (2.1) is called convex conic
combination or nonnegative combination of the vectors x1, x2, . . . , xk.
When in (2.1) it holds that each αi ≧0 and k
i=1 αi = 1, the expression (2.1) is
called a convex combination of the vectors x1, x2, . . . , xk.
Deﬁnition 2.2 A set K ⊂Rn is a cone with vertex at the origin if
x ∈K ⇒λx ∈K, ∀λ > 0.
Many authors, however, do include the vertex in the cone by letting λ ≧0 in the
above deﬁnition. It may be useful to accept both deﬁnitions, in order to have more
ﬂexibility in the various cases and problems encountered in treating this topic. A
cone K ⊂Rn which is also convex is called…a convex cone! It is easy to prove that
a cone K ⊂Rn is convex if and only if
x, y ∈K ⇒x + y ∈K.
Indeed, if K is convex, we have x + y = 2
 1
2 x + 1
2 y
	
where 1
2 x + 1
2 y ∈K, being
K convex and 2
 1
2 x + 1
2 y
	
∈K, being K a cone. Conversely, if x, y ∈K, then we
haveλx, (1 −λ)y ∈K,∀λ ∈[0, 1]since K isacone,andthereforeλx + (1 −λ)y ∈
K, i.e. K is a convex set.
Note that the deﬁnition of cone in Rn is an abstract and multi-dimensional gen-
eralization of the well-known ice-cream cone. A cone K ⊂Rn may be open, closed
or neither open nor closed. Examples of cones are:
K1 =

(x, y) ∈R2 : x ≧0, y ≧0

;
K2 =

(x, y) ∈R2 : 0 ≦y < x

;
K3 =

(x, y) ∈R2 : x ≧0, y = x

;
K4 =

(x, y) ∈R2 : x = 0

∪

(x, y) ∈R2 : y = 0

;
K5 =

x ∈Rn : Ax = 0

, with A matrix of order (m, n).
Note that K1, K2, K3 and K5 are convex cones.
If K1 and K2 are convex cones, also K1 ∩K2 and K1 + K2 are convex cones.
Every linear subspace of Rn is a closed convex cone.

2.1 Elements of Convex Analysis
25
Now, let S be a nonempty subset of Rn.
• The collection of all linear combinations of vectors of S is said to be the linear
space generated by S or linear span of S or also linear hull of S and denoted by
lin(S) or span(S);
lin(S) =

 k

i=1
αixi : each xi ∈S, each αi ∈R, k ∈N

.
It can be proved that lin(S) is the smallest linear space of Rn containing S.
• The collection of all afﬁne combinations of vectors of S is called afﬁne hull of S
and denoted by aff(S):
aff(S) =

 k

i=1
αixi : each xi ∈S, each αi ∈R,
k

i=1
αi = 1, k ∈N

.
It can be proved that aff(S) is the smallest afﬁne subspace of Rn containing S. If
aff(S) = α + L, where L is a linear subspace of Rn, then the dimension of the
afﬁne hull of S is given by the dimension of L. The dimension of S is given by
the dimension of its afﬁne hull.
• The collection of all convex conic combinations of vectors of S is called the convex
conic hull of S or convex cone generated by S or convex cone spanned by S and
denoted by cone(S):
cone(S) =

 k

i=1
αixi : each xi ∈S, each αi ≧0, k ∈N

.
Some authors (e.g. Bazaraa and Shetty [1]) require that the coefﬁcients αi, i =
1, . . . , k, are not all zero, i.e. k
i=1 αi > 0. It can be proved that cone(S) is the
smallest convex cone of Rn containing S (equivalently: it is the intersection of all
convex cones in Rn containing S).
• The collection of all convex combinations of vectors of S is called the convex hull
of S and denoted by conv(S) or co(S):
conv(S) =

 k

i=1
αixi : each xi ∈S, each αi ≧0,
k

i=1
αi = 1, k ∈N

.
It can be proved that conv(S) is the smallest convex set of Rn containing S;
equivalently: conv(S) is the intersection of all convex sets in Rn containing S (see
the next Theorem 2.4).
We note that if S is a nonempty subset of Rn, we have

26
2
Elements of Convex Analysis. Linear Theorems of the Alternative. Tangent Cones
S ⊂conv(S) ⊂aff(S) ⊂lin(S);
S ⊂conv(S) ⊂cone(S) ⊂lin(S).
Moreover:
(a) S ⊂Rn is a linear subspace of Rn if and only if S = lin(S).
(b) S ⊂Rn is an afﬁne set of Rn if and only if S = aff(S).
(c) S ⊂Rn is a convex set of Rn if and only if S = conv(S).
(d) S ⊂Rn is a convex cone with vertex at 0 ∈S if and only if S = cone(S).
Let us prove (c). The proofs of the other properties are similar and left to the
reader.
Theorem 2.3 A nonempty set S ⊂Rn is convex if and only if every convex combi-
nation of elements of S lies in S.
Proof The sufﬁciency of the condition is obvious from the deﬁnition. We prove
the necessity by induction on the number of elements of S occurring in the convex
combination. When k = 2, the condition follows from the deﬁnition. Assuming that
every convex combination of k or fewer points of S yields a point of S, we consider
a combination of k + 1 points. Let x = k+1
i=1 λixi, where λi ≧0 and k+1
i=1 λi = 1,
and xi ∈S for all i. If λk+1 = 1, then x = xk+1, which belongs to S and there is
nothing further to prove. Suppose that λk+1 < 1. In this case k
i=1 λi = 1 −λk+1 >
0 and we have
x =
 k

i=1
λi
  k

i=1
λixi/
k

i=1
λi

+ λk+1xk+1.
By the induction hypothesis, the point
y =
 k

i=1
λixi/
k

i=1
λi

belongs to S. Thus, x = (1 −λk+1)y + λk+1xk+1 is a convex combination of two
points in S and so x ∈S.
□
It is important to note that the intersection of any collection of convex sets is a
convex set, while the union of two (or more) convex sets is not convex in general.
The complement of a convex set need not be convex, For any two convex sets X and
Y of Rn, their sum X + Y is convex.
For any α ∈R and a convex set S ⊂Rn, the set αS is convex.
Now we prove that conv(S) is given by the intersection of all convex sets which
contain S.

2.1 Elements of Convex Analysis
27
Theorem 2.4 For any set S ⊂Rn we have that
conv(S) =
⎧
⎨
⎩x ∈Rn : x =
m

i=1
λi xi, each xi ∈S, each λi ≧0,
m

i=1
λi = 1, m ∈N
⎫
⎬
⎭
is equal to the set T ⊂Rn given by the intersection of all convex sets wich
contain S.
Proof Let x = m
i=1 λixi, with

x1, . . . , xm
⊂S, {λ1, . . . , λm} ⊂R+ and m
i=1
λi = 1. By Theorem 2.3 the point x obviously belongs to any convex set containing
S and therefore also the set T, i.e. conv(S) ⊂T. Conversely let x = r
i=1 αixi
and y = s
i=1 βi yi, where αi ≧0, r
i=1 αi = 1, and βi ≧0, s
i=1 βi = 1 be two
elements of conv(S). Then, for any λ, 0 ≦λ ≦1,
z ≡λx + (1 −λ)y = λ
r

i=1
αixi + (1 −λ)
s

i=1
βi yi
is an element of conv(S), since each coefﬁcient belongs to the interval [0, 1] and
λ
r

i=1
αi + (1 −λ)
s

i=1
βi = λ + 1 −λ = 1.
Then conv(S) is a convex set containing S and so T ⊂conv(S). Therefore
conv(S) = T .
□
A sharper result in Rn is the following Theorem of Carathedory:
Theorem 2.5 (Caratheodory) The convex hull of S ⊂Rn is precisely the set of all
convex combinations of at most (n + 1) elements of S.
The notation “cone(S)” is widely used, however some authors use other notations:
for example Jeter [2] uses the notation coni(S), whereas Dhara and Dutta [3]) use
the notation cone(co(S)) to denote the convex cone generated by S. We remark that
cone(S) need not be a closed set, even if S ⊂Rn is compact. However, it can be
proved that cone(S) is closed in special cases, such as when S is ﬁnite. We speak
in this case of ﬁnite cone or ﬁnitely generated cone, i.e. the closed convex cone
generated by a ﬁnite set C =

a1, a2, . . . , am
of vectors of Rn :
cone(C) =

x ∈Rn : x =
m

i=1
αiai, αi ≧0, i = 1, . . . , m

.
The vectors a1, a2, . . . , am of Rn are said to be the generators of cone(C). The
proof that a ﬁnitely generated cone is closed is basic in proving the well-known
Farkas Theorem (or Farkas Lemma); see the next section of the present chapter.

28
2
Elements of Convex Analysis. Linear Theorems of the Alternative. Tangent Cones
Another important convex cone is the following one:
K =

x ∈Rn : Bx ≦0

,
where B is a matrix of order (m, n). This cone is called a polyhedral (convex) cone.
The Minkowski-Weyl Theorem states that a cone is polyhedral if and only if it is
ﬁnitely generated. See, e.g., Bertsekas [4], Bertsekas et al. [5], Florenzano and Le
Van [6], Hiriart-Urruty and Lemaréchal [7], Rockafellar [8]).
In the literature it is often introduced the conic hull of S ⊂Rn or radial hull of
S, as the smallest cone (not necessarily convex!) which contains S. Unfortunately
this cone is almost always denote by cone(S), which can generate some confusions
and misunderstandings. As this cone is given by the union of all rays starting form
the origin and passing through the elements x ∈S, we propose the notation ray(S) :
ray(S) =

y : y = λx, x ∈S, λ ≧0

.
Some authors require λ > 0 and some authors use the notation R+(S). The basic
relation between cone(S) and ray(S) is given by the following result.
Theorem 2.6 If S ⊂Rn is a nonempty convex set, then
cone(S) = ray(S).
Proof As ray(S) is a cone, it is sufﬁcient to show that ray(S) is convex; then the
result is at hand by the deﬁnitions of ray(S) and cone(S). Let x1, x2 ∈ray(S); then
there exist two points y1, y2 ∈S and numbers λ1, λ2 ∈R+ such that
x1 = λ1y1, x2 = λ2y2.
For any μ1, μ2 ≧0, μ1 + μ2 = 1, we put
x = μ1x1 + μ2x2 = μ1λ1y1 + μ2λ2y2
(2.2)
and consider two cases.
(1) μ1λ1 + μ2λ2 > 0.
We put
ξ1 =
μ1λ1
μ1λ1 + μ2λ2
; ξ2 = 1 −
μ1λ1
μ1λ1 + μ2λ2
and note that ξ1 ≧0, ξ2 ≧0, ξ1 + ξ2 = 1. It follows from (2.2) and convexity
of S :
x = (μ1λ1 + μ2λ2) (ξ1y1 + ξ2y2) ∈ray(S).
(2) μ1λ1 + μ2λ2 = 0.
It follows μ1λ1 = μ2λ2 = 0 and hence x = 0 ∈ray(S).
□

2.1 Elements of Convex Analysis
29
Moreover, it holds, with S ⊂Rn : cone(S) = ray(conv(S)) = conv(ray(S)).
It is sometimes also useful to consider cones and convex cones generated by a set
S ⊂Rn, with reference to a point x0 ∈S. Let x0 ∈S, with S a nonempty subset of
Rn. Then ray(S, x0) is the smallest cone which contains S −x0 and cone(S, x0) is
the smallest convex cone which contains S −x0, i.e., with x0 ∈S,
ray(S, x0) = ray(S −x0) =

y : y = λ(x −x0), x ∈S, λ ≧0

;
cone(S, x0) = cone(S −x0).
These cones are also called, respectively, the cone generated by S at x0 (or from
x0) and the convex cone generated by S at x0 (or from x0). The cone ray(S, x0) is
called by Palata [9] the projection cone of S at x0. This cone may be viewed as a
(very) rough approximation of the set S in a neighborhood of x0 ∈S. In the next
section we shall consider other more “reﬁned” local cone approximations of the set
S at x0 ∈S.
We now recall some topological properties related to convex sets.
Theorem 2.7 (i) If S ⊂Rn is a convex set, then int(S) is convex.
(ii) If S ⊂Rn is a convex set, then cl(S) is convex.
Proof (i) For two points x1, x2 ∈int(S), consider two neighborhoods Uε1(x1) and
Uε2(x2) that belong entirely to S. Let λ ∈[0, 1] ; being S convex we have
λUε1(x1) + (1 −λ)Uε2(x2) ⊂S.
Obviously the relation appearing in the left-hand side of the last relation can be
rewritten in the form
λ

x1 + Uε1(0)
	
+ (1 −λ)(x2 + Uε2(0)) =
= (λx1 + (1 −λ)x2) + (λUε1(0) + (1 −λ)Uε2(0)).
So, we have found a neighborhood of λx1 + (1 −λ)x2 which lies in S, i.e. this
point belongs to the interior of S. The set int(S) is therefore convex.
(ii) The convexity of the closure of S follows at once from its deﬁnition:
cl(S) = ∩
ε>0(S + Uε(0)),
being the neighborhood Uε(0) a convex set.
□
Theorem 2.8 If S ⊂Rn is an open set, then conv(S) is open.
Proof Since S is open, S ∩∂(conv(S)) = ∅. But S ⊂conv(S), so we must have
S ⊂int(conv(S)). Furthermore, the previous theorem implies that int(conv(S)) is

30
2
Elements of Convex Analysis. Linear Theorems of the Alternative. Tangent Cones
convex, so conv(S) ⊂int(conv(S)). On the other hand, int(conv(S)) ⊂conv(S), so
conv(S) = int(conv(S)) and hence conv(S) is open.
□
Note that the convex hull of a closed set need not be closed. However, contrary
to what happens for cone(S), we have the following result.
Theorem 2.9 If S ⊂Rn is a compact set, then conv(S) is compact.
Deﬁnition 2.10 The dimension of a convex set S ⊂Rn, denoted dim(S), is the
dimension of the afﬁne hull of S.
Deﬁnition 2.11 The convex hull of a ﬁnite set of points is called a polytope; if
S =

x1, . . . , xk+1
and dim(S) = k, then conv(S) is called k-dimensional simplex
and the points x1, . . . , xk+1 are called vertices of the simplex.
From Theorem 2.9 we have that a polytope is closed, bounded and convex. A
zero-dimensional simplex is a point, a one-dimensional simplex is a line segment
and a two-dimensional simplex is a triangle.
We point out that we can have convex sets in Rn with empty interior (we recall
that the empty set ∅is convex by deﬁnition). For example, consider a line segment
in R2 or a circular disk in R3. It is therefore useful to introduce the notion of relative
interior of a convex set.
Deﬁnition 2.12 Let be given a set S ⊂Rn. The set
relint(S) = {x ∈S : ∃U(x) such that U(x) ∩aff(S) ⊂S}
is the relative interior of S. A point x0 ∈relint(S) is called a relative interior point
of S.
A set S ⊂Rn is said to be relatively open if relint(S) = S. We note that if S ⊂Rn
has maximal dimension, i.e. if aff(S) = Rn, then the sets int(S) and relint(S) coin-
cide. If S is a singleton, then relint(S) = S. The notion of relative interior is partic-
ularly important when referred to convex sets. Furthermore, we have the following
result.
Theorem 2.13 Let S ⊂Rn be a nonempty convex set; then relint(S) ̸= ∅.
Proof Consider a nonempty convex set S ⊂Rn. Without loss of generality assume
that 0 ∈S. Then aff(S) is a subspace containing S. Let us assume that aff(S) is a
subspace of dimension m. If m = 0, then S and aff(S) contain only one point and the
result holds. Hence we now consider m > 0. We can always ﬁnd linearly independent
vectors a1, . . . , am in S such that aff(S) = span{a1, . . . , am}. Indeed, if this would
not be possible, then one would always be able to ﬁnd linearly independent vectors
b1, . . . , br, r < m, such that S ⊂span{b1, . . . , br}. This however contradicts the
fact that aff(S) has dimension m. Now observe that the set conv{0, a1, . . . , am} ⊂S
has a nonempty interior relative to aff(S). Thus we have that relint(S) ̸= ∅.
□

2.1 Elements of Convex Analysis
31
The following result is known as line segment principle and gives further infor-
mation on the closure and relative interior of a convex set.
Theorem 2.14 Let S ⊂Rn be a nonempty convex set. Consider x ∈relint(S) and
y ∈cl(S). Then any point of the form λy + (1 −λ)x ∈relint(S) for 0 ≦λ < 1.
Proof For simplicity let us consider S to be a full dimensional set, i.e. aff(S) = Rn.
Hence relint(S) = int(S); we have to show that for any given λ ∈[0, 1) there exists
ε > 0 such that
λy + (1 −λ)x + εU(0) ⊂S.
Since y ∈cl(S), it is easy to see that for any ε > 0 there exists x ∈S such that
y ∈x + U(0). Thus y ∈S + εU(0) for any ε > 0. Therefore we have
(1 −λ)x + λy + εU(0) ⊂(1 −λ)x + λ(S + εU(0)) + εU(0).
This can be re-arranged to show that
(1 −λ)x + λy + εU(0) ⊂(1 −λ)

x + ε(1 + λ)
(1 −λ) U(0)

+ λS.
Since x ∈int(S), we have for sufﬁciently small ε > 0,

x + ε(1 + λ)
(1 −λ) U(0)

⊂S.
Thus we have
(1 −λ)x + λy + εU(0) ⊂(1 −λ)S + λS ⊂S.
This proves the result.
□
Moreover, we have that, if S ⊂Rn is a nonempty convex set, it holds:
(a) cl(relint(S)) = cl(S);
(b) relint(cl(S)) = relint(S).
We will now discuss separation theorems between convex sets, which play a
central role in mathematical programming. We recall that a hyperplane in Rn is a set
of the form
H =

x ∈Rn : a⊤x = α

,
where a ∈Rn is a nonzero vector and α ∈R. The vector a is called the normal to
the hyperplane. The related (closed) half-spaces determined by the hyperplane H
are given by
H −=

x ∈Rn : a⊤x ≦α

;

32
2
Elements of Convex Analysis. Linear Theorems of the Alternative. Tangent Cones
H + =

x ∈Rn : a⊤x ≧α

.
We accept the following deﬁnitions.
Deﬁnition 2.15 Two nonempty sets S1 and S2 of Rn are said to be:
(a) Separable or weakly separable, if there exists a hyperplane H = {x ∈Rn :
a⊤x = α}, a ̸= 0, α ∈R, such that
sup
x∈S1

a⊤x

≦α ≦inf
x∈S2

a⊤x

.
In other words, it must exist a hyperplane H, such that
S1 ⊂H −, S2 ⊂H +,
i.e. S1 is contained in one of the closed half-spaces determined by H and S2
lies in the opposite closed half-space. The hyperplane H is called separating
hyperplane (between S1 and S2).
(b) Properly separable, if they are separable and there exists at least a point z ∈
S1 ∪S2, such that
a⊤z ̸= α.
In other words, S1 and S2 are properly separable if they are separable and it holds
inf
x∈S1

a⊤x

< sup
x∈S2

a⊤x

.
(c) Strongly separable, if there exists a vector a ̸= 0, and a real scalar α such that
sup
x∈S1

a⊤x

< α < inf
x∈S2

a⊤x

.
It appears that strong separations implies proper separation and proper separation
implies (weak) separation. We point out that there are in the literature other kinds of
separationandalsoother denominations (for example, strongseparationis sometimes
called stable separation or also perfect separation).
The following result will be useful to prove the basic separations theorems we
will consider. We leave its proof to the reader.
Lemma 2.16 The two nonempty sets S1, S2 ⊂Rn are separable, respectively, prop-
erlyseparable,stronglyseparableifandonlyifthesets{0}and S1 −S2 areseparable,
respectively, properly separable, strongly separable.
First we formulate a result concerning strong separability.

2.1 Elements of Convex Analysis
33
Theorem 2.17 Let S1 and S2 be nonempty convex sets in Rn with S1 ∩S2 = ∅. If S1
is compact (i.e. closed and bounded) and S2 is closed, then there exists a hyperplane
that strongly separates S1 and S2.
Proof On the grounds of the assumptions, the set S1 −S2 is closed and convex and
it holds 0 /∈S1 −S2. We have to prove that {0} and S1 −S2 are strongly separable.
Hence, we look for a point a ∈S1 −S2 such that
∥a∥≦∥x∥, ∀x ∈S1 −S2.
This point exists (and it is uniquely determined). Moreover, we have a ̸= 0. Since
for a given point x ∈S1 −S2 and for a given number λ, with 0 < λ < 1, we have
λx + (1 −λ)a = a + λ(x −a) ∈S1 −S2,
it follows
∥a∥2 ∥a + λ(x −a)∥2 ≦∥a∥2 + 2λa⊤(x −a) + λ2 ∥x −a∥2
and hence
2a⊤(x −a) + λ ∥x −a∥2 ≧0.
As this inequality holds for all λ ∈(0, 1), we get
a⊤(x −a) ≧0,
i.e.
a⊤x ≧∥a∥2 .
In addition, we put α = 1
2 ∥a∥2 , so we have
a⊤0 = 0 < α ∥a∥2 ≦a⊤x
for all x ∈S1 −S2, i.e. the sets {0} and S1 −S2 are strongly separable and therefore
also S1 and S2 are strongly separable.
□
As an immediate corollary we have the following result.
Corollary 2.18 Let S be a closed convex set in Rn and let y ∈Rn be any point
outside of S, i.e. y /∈S. Then there exists a hyperplane H =

x : a⊤x = α

which
separates S and {y} strongly:
a⊤x < α < a⊤y, ∀x ∈S.
If S ⊂Rn is any nonempty convex set (not necessarily closed) and if y ∈Rn is
a boundary point of S, it is natural to conjecture that y can be (weakly) separated

34
2
Elements of Convex Analysis. Linear Theorems of the Alternative. Tangent Cones
from S by a hyperplane passing through y. This conjecture is correct and the related
hyperplane is called a supporting hyperplane to S at y. Indeed, we have the following
result (“supporting hyperplane theorem”).
Theorem 2.19 Let S be any nonempty convex set in Rn and let y ∈Rn be a boundary
point of S. Then, there exists at least one supporting hyperplane to S at y, i.e. there
exists a ∈Rn, a ̸= 0, such that
a⊤x ≦a⊤y, ∀x ∈S.
Proof Let ¯S be the closure of S. Then ¯S is convex by Theorem 2.7. Since y is a
boundary point for S and S is convex, y is also a boundary point for ¯S. Take any
sequence

yk
, k = 1, 2, . . . , lying outside ¯S and converging to y as k →+∞.
Since yk /∈¯S and ¯S is closed and convex, by Theorem 2.17 (more precisely by its
corollary), there is a vector ak such that (ak)⊤x < (ak)⊤yk, for all x ∈¯S. Without
loss of generality we might assume that
ak = 1 for each k, so that

ak
is a
sequence moving in the unit sphere of Rn. Since a unit sphere is compact,

ak
has
a convergent subsequence, we denote again by

ak
, such that
(ak)⊤x < (ak)⊤yk, ∀x ∈¯S.
(2.3)
If we let the limit of ak, as k →+∞, be the vector a, we get, taking the
limit in (2.3),
a⊤x ≦a⊤y, ∀x ∈S.
□
We are now ready to prove the (weak) separation theorem, essentially due to H.
Minkowski.
Theorem 2.20 Let S1 and S2 be two nonempty convex sets in Rn. If S1 and S2 are
disjoint, then there exists a hyperplane that separates them, that is, there exist a
vector a ∈Rn, a ̸= 0, and a real scalar α such that
a⊤x ≦α ≦a⊤y, ∀x ∈S1, ∀y ∈S2.
Proof Let X = S1 −S2. Then X is convex and 0 /∈X. The set cl(X) is also convex
by Theorem 2.7. If 0 /∈cl(X), then {0} and cl(X) can be strongly separated according
to Theorem 2.17 (Corollary 2.18). If 0 is a boundary point for X, then {0} and cl(X)
can be separated by Theorem 2.19 (“supporting hyperplane theorem”). In any case,
there exists a vector a ∈Rn, a ̸= 0, such that a⊤x ≦a⊤0 = 0, ∀x ∈X. Therefore
we can assert that there exists α ∈R such that
a⊤x ≦α ≦a⊤y, ∀x ∈S1, ∀y ∈S2.
□
More generally, the result of Theorem 2.20 holds under the assumption 0 /∈
int(S1 −S2).
Now we are able to formulate a theorem on proper separation.

2.1 Elements of Convex Analysis
35
Theorem 2.21 (Proper separation theorem) Two nonempty convex sets S1 and S2 in
Rn can be properly separated if and only if relint(S1) ∩relint(S2) = ∅.
Proof Deﬁne the convex set X = S1 −S2. It follows that relint(X) = relint(S1 −
S2) = relint(S1) −relint(S2). Thus relint(S1) −relint(S2) = ∅and 0 /∈relint(X)
are equivalent statements. Consequently, we have to prove that the sets {0} and
X are properly separable if and only if 0 /∈relint(X).
Suppose that the origin and X are properly separated by a hyperplane H such that
0 ∈H −and X ⊂H +. We claim that 0 /∈relint(X). If 0 ∈H, then relint(X) ⊂H +,
so that 0 /∈relint(X). Otherwise, 0 ∈H and there exists a point x ∈X \ H. If we
had 0 ∈relint(X), there would exist a point y ∈X such that 0 ∈(x, y), giving the
contradiction y ∈S1 ∩H −−= ∅, where
H −−=

x ∈Rn : a⊤x < α

.
This proves the claim.
Conversely, suppose that 0 /∈relint(X). Write
L ≡aff(X) = u0 + span

u1, . . . , uk
where

ui
, i = 1, . . . , k, are linearly independent vectors. If 0 /∈L, then

ui
,
i = 0, . . . , k are linearly independent and we can extend it to a basis

ui
, i =
0, . . . , n −1, of Rn. Then the hyperplane H ≡u0 + span

u1, . . . , un−1
does not
containtheorigin,soitproperlyseparates{0}and X.If0 ∈L,weapplyTheorem2.20
within the vector space L to the sets {0} and relint(X), and obtain a hyperplane P in
L separating {0} and X such that relint(X) ⊂P+. We may assume that 0 ∈P; other-
wise the translation of P so that it passes through the origin also satisﬁes the same sep-
aration properties. Extending P to the hyperplane H = span

P, uk+1, . . . , un−1
,
it is evident that H properly separates {0} and X.
□
As a consequence of the theorem on strong separability we have an interesting
characterization of closed convex sets of Rn.
Theorem 2.22 A closed convex set S ⊂Rn is given by the intersection of all closed
half-spaces that contain S.
Proof The intersection D of all closed half-spaces that contain S is obviously a
closed convex set and it holds S ⊂D. We now prove the opposite inclusion D ⊂S
by an indirect proof. Let be given a point x0 ∈D with x0 /∈S, so the sets S and

x0
are strongly separable, i.e. there exist a vector a ̸= 0 and a number α such that
a⊤x < α < a⊤x0, ∀x ∈S.
Therefore, it will exist a closed half-space

x ∈Rn : a⊤x ≦α


36
2
Elements of Convex Analysis. Linear Theorems of the Alternative. Tangent Cones
which surely contains the set S, but not the point x0, i.e. x0 /∈D, in contradiction
with the assumptions.
□
In order to get other applications of the separation theorems, we now present the
notion of polar cone of a set S ⊂Rn, of bipolar cone, and point out their main
properties.
Deﬁnition 2.23 Let S ⊂Rn be any set; then the (negative) polar cone of S is given
by
S∗=

y ∈Rn : y⊤x ≦0, ∀x ∈S

.
The bipolar cone of S is deﬁned by
S∗∗= (S∗)∗=

x ∈Rn : x⊤y ≦0, ∀y ∈S∗
.
Some authors call dual cone of S the positive polar cone:
S+ =

y ∈Rn : y⊤x ≧0, ∀x ∈S

.
However, there is not uniformity of deﬁnitions in the literature.
We accept the deﬁnition ∅∗= Rn. Obviously, any polar cone (and hence any
bipolar cone), being given by
S∗= ∩
x∈S

y ∈Rn : y⊤x ≦0

,
is the intersection of closed half-spaces and therefore it is a closed and convex cone,
with 0 ∈S∗.
From the deﬁnition it follows at once that
S∗= (cl(S))∗= (conv(S))∗= (cone(S))∗.
If L ⊂Rn is a linear subspace, the polar cone of L is given by the orthogonal
complement of L, i.e.
L⊥=

y ∈Rn : y⊤x = 0, ∀x ∈L

.
The following theorem gathers the main properties of polar cones.
Theorem 2.24 For any sets S ⊂Rn, S1, S2 ⊂Rn, the following properties hold.
(a) S1 ⊂S2 ⇒(S2)∗⊂(S1)∗.
(b) (S1 ∪S2)∗= (S1)∗∩(S2)∗.
(c) (S1)∗∪(S2)∗⊂(S1 ∩S2)∗.
(d) S ⊂S∗∗.
(e) S = S∗∗if S is a nonempty closed convex cone. Therefore if L is a linear subspace
of Rn, we have L = (L⊥)⊥= L⊥⊥.

2.1 Elements of Convex Analysis
37
(f) S∗= (cl(cone(S)))∗(if S ̸= ∅) and therefore S∗∗= cl(cone(S)).
(g) S∗= S∗∗∗.
(h) (S1 ∩S2)∗= cl(cone((S1)∗∪(S2)∗)) = cl((S1)∗+ (S2)∗), if S1 and S2 are
closed convex cones.
Proof The ﬁrst four properties are quite immediate consequences of the deﬁnitions
of polar and bipolar cones. We prove property (e), called also “bipolar theorem”: if
S ⊂Rn is a closed convex cone, then S = S∗∗. From the deﬁnition of S∗we see that
if x ∈S, then x⊤y ≦0 for all y ∈S∗; this proves that S ⊂S∗∗. Suppose that the
reverse inclusion S∗∗⊂S is not true, and pick a point x ∈S∗∗\ S. It follows from the
strong separation theorem (Theorem 2.17) that there exists a nonzero vector a ∈Rn
such that
a⊤x > a⊤z, ∀z ∈S.
(2.4)
Ontheonehand,setting z = 0 in (2.4)givesa⊤x > 0;ontheotherhand,if z ∈S is
a ﬁxed point, then tz ∈S for all t > 0 and (2.4) gives a⊤x > a⊤tz or a⊤z < (a⊤x)/t.
Letting t →+∞, we obtain
a⊤z ≦0, ∀z ∈S,
which implies that a ∈S∗. However, since x ∈S∗∗, we must have a⊤x ≦0, which
contradicts the fact a⊤x > 0 proved above.
Property (f ) follows from (e), being S∗∗= cl(cone(S))∗∗= cl(cone(S)).
As S∗is a non-empty closed convex cone, we have from property (e), also S∗∗∗=
(S∗)∗∗= S∗, i.e. property (g).
Property (h) is obtained from properties (b), (e) and (f ), being
(S1 ∩S2)∗= ((S1)∗∗∩(S2)∗∗)∗= ((S1)∗∪(S2)∗)∗∗= cl(cone((S1)∗∪(S2)∗)).
The proof of the proposition
cone((S1)∗∪(S2)∗) = (S1)∗+ (S2)∗
is left to the reader.
□
We remark that it could be proved that property (e) of Theorem 2.24 holds if and
only if S is a closed convex cone. Moreover, the same property can be given in the
following weaker form (called sometimes “polar cone theorem”): for any nonempty
cone S ⊂Rn, we have
S∗∗= cl(conv(S)).
Therefore
(S∗)∗∗= (cl(conv(S)))∗,
and hence

38
2
Elements of Convex Analysis. Linear Theorems of the Alternative. Tangent Cones
S∗= (cl(conv(S)))∗.
If 0 ∈S1 ∩S2, it holds
(S1 + S2)∗= S∗
1 ∩S∗
2.
We now brieﬂy recall again a special class of convex cones, called polyhedral
cones. First we introduce the notion of polyhedral sets. Polyhedral sets of Rn are
formed by the intersection of a ﬁnite number of closed half-spaces. Thus a typical
polyhedral set P can be represented as follows.
P =

x ∈Rn : (ai)⊤x −bi ≦0, i = 1, . . . , m

,
where ai ∈Rn and bi ∈R. It turns out that polyhedral sets are closed convex sets
and that alternatively they can be written in the form
P =

x ∈Rn : Ax ≦b

,
where A is a matrix of order (m, n) and b ∈Rm.
A polyhedral cone C ⊂Rn is represented as
C =

x ∈Rn : Ax ≦0

,
i.e. C is a polyhedral set where b = 0 ∈Rm. Obviously, polyhedral cones are closed
convex cones. For this type of cones the following properties hold.
If C, C1, C2 ⊂Rn are polyhedral cones, then:
(a) C = C∗∗.
(b) C∗is a polyhedral cone.
(c) C1 + C2 and C1 ∩C2 are polyhedral cones.
(d) (C1 + C2)∗= C∗
1 ∩C∗
2.
(e) (C1 ∩C2)∗= C∗
1 + C∗
2.
Properties (d) and (e) are also called “modularity theorem”.
In addition, we recall again the notion of ﬁnitely generated cone or ﬁnite cone.
Deﬁnition 2.25 A convex cone C ⊂Rn is said to be ﬁnitely generated if it is gen-
erated by a ﬁnite set of vectors of Rn, i.e. if it has the form
C =

x ∈Rn : x =
m

i=1
μiai, μi ≧0, i = 1, . . . , m

.
The vectors a1, . . . , am of Rn are said to be the generators of the cone C. We
point out that if a1, . . . , am ∈Rn are the columns of a matrix A, of order (n, m) and
μ = (μ1, . . . , μm)⊤, a ﬁnitely generated cone can be written as

2.1 Elements of Convex Analysis
39
C =

x ∈Rn : x = Aμ, μ ∈Rm, μ ≧0

.
(2.5)
We have two important results related to ﬁnitely generated cones, results previ-
ously mentioned.
Theorem 2.26 Let C ⊂Rn be a ﬁnitely generated cone given by
C =

z ∈Rn : z =
m

i=1
μiai, μi ≧0, i = 1, . . . , m

with A matrix of order (n, m). Then C is a closed convex cone.
Proof The facts that C is a cone with vertex at the origin 0 ∈C and that it is convex
are obvious. Let us rewrite C as a nonnegative linear combination of the columns A j
of A :
C =
⎧
⎨
⎩z ∈Rn : z =
m

j=1
μ j A j, μ j ≧0, j = 1, . . . , m
⎫
⎬
⎭.
We will show that the cone C is closed by an induction argument based on the
number of the columns A j, j = 1, . . . , k. When k = 1, C is either the origin 0 ∈Rn
or a half-line and is therefore closed. Now suppose that for k > 1 the cone generated
by the vectors A1, . . . , Ak−1 is closed:
Ck−1 =
⎧
⎨
⎩z : z =
k−1

j=1
μ j A j, μ j ≧0
⎫
⎬
⎭
is closed. We have to show that the cone
Ck =
⎧
⎨
⎩z : z =
k

j=1
μ j A j, μ j ≧0
⎫
⎬
⎭
is closed too. There are two cases.
(1) First, suppose that Ck contains the vectors −A1, −A2, . . . , −Ak. Then Ck is a
linear subspace of dimension not exceeding k, so it is closed.
(2) Assume that at least one of the vectors −A1, −A2, . . . , −Ak does not belong
to Ck, say −Ak /∈Ck (renumber if necessary). Then, every y ∈Ck can be rep-
resented as y = ¯y + αAk, α ≧0, where ¯y ∈Ck−1. To show that Ck is closed,
suppose that ¯z is a limit point. Then, there exists a sequence {zn} ⊂Ck such that
zn →¯z as n →∞, where zn has the form
zn = ¯yn + αn Ak, αn ≧0, with ¯yn ∈Ck−1.

40
2
Elements of Convex Analysis. Linear Theorems of the Alternative. Tangent Cones
If the sequence {αn} is bounded, we can assume, without loss of generality, that
the sequence converges to a limit α, and consequently ¯z −αAk ∈Ck−1, where
this last set is closed. Indeed,
¯z −αAk = lim
n→∞(zn −αn Ak) = lim
n→∞¯yn ≡¯y ∈Ck−1,
since Ck−1 is closed. We conclude that
¯z = ¯y + αAk ∈Ck.
Thus, if the sequence {αn} is bounded, then the set Ck is closed.
We now assume that αn →∞for n →∞. Then, since {zn} converges, it is a
bounded sequence. Hence (αn)−1zn →0 as n →∞. It follows that (αn)−1 ¯yn +
Ak →0 as n →∞. Therefore limn→∞(αn)−1 ¯yn = −Ak. But since Ck−1 is
closed, this means that −Ak ∈Ck−1, which is a contradiction.
□
Theorem 2.27 (Minkowski-Weyl Theorem). A cone C ⊂Rn is polyhedral if and
only if it is a ﬁnitely generated cone.
Note that from the Minkowski-Weyl theorem we obtain at once that a ﬁnitely
generated cone is closed. However, also the said theorem has not a trivial proof.
We now compute the polar of the ﬁnitely generated cone C ⊂Rn given by (2.5):
C∗=

y ∈Rn : y⊤x ≦0, ∀x ∈C

=

y ∈Rn : y⊤Aμ ≦0, ∀μ ≧0

=

y ∈Rn : A⊤y ≦0

,
i.e. the polar of a ﬁnitely generated cone is a polyhedral cone. Moreover, we can
assert that the angles between the vectors y ∈C∗and the column vectors of A are
not smaller than 90◦. For what concerns the bipolar cone of C we have
C∗∗=

x ∈Rn : x⊤y ≦0, ∀y ∈C∗
=

x ∈Rn : x⊤y ≦0, ∀y such that A⊤y ≦0

=

x ∈Rn : A⊤y ≦0 ⇒x⊤y ≦0

.
The equality between the cones C and C∗∗(according to Theorem 2.24(e) since
C is a closed convex cone), together with what obtained above, mean that, given a
matrix A and a vector b, the condition
A⊤y ≦0 ⇒b⊤y ≦0
is equivalent to
∃μ ≧0 : Aμ = b.

2.2 Theorems of the Alternative for Linear Systems
41
This is the statement of the well-known Farkas’ theorem or Farkas’ lemma. This
theorem is one of the most quoted and used theorem of the alternative for linear
systems. The next section is concerned with several theorems of the alternative for
linear systems.
2.2
Theorems of the Alternative for Linear Systems
The general structure of a theorem of the alternative is the following one. A theorem
of the alternative is a result concerning the following proposition: between two given
systems of linear (or also nonlinear) relatione, say a “primal” system S and a “dual”
system S∗, one and only one of them admits solutions. In other words: S admits
solutions if and only if S∗does not admit solutions (equivalently: S∗admits solutions
if and only if S does not admit solutions).
The theorem of the alternative of Farkas can therefore be expressed in the follow-
ing form, which puts into evidence the “alternative” between two linear systems.
Theorem 2.28 Let be given a matrix A of order (m, n) and a vector b ∈Rm. Then
the system
S1 ≡

Ax = b; x ≧0

admits solutions x ∈Rn if and only if the system
S∗
1 ≡

y⊤A ≧0; y⊤b < 0

does not admit solutions y ∈Rm.
Remark 2.29 Obviously system S∗
1 in Theorem 2.28 can be equivalently written in
the form
S∗
1 ≡

y⊤A ≦0; y⊤b > 0

.
Moreover, S1 and S∗
1 of Theorem 2.28 can be equivalently written as
S1 ≡

x⊤A⊤= b⊤; x ≧0

;
S∗
1 ≡

A⊤y ≧0; b⊤y < 0

.
Another equivalent formulation of Farkas’ theorem (not in an “alternative form”)
is the following one, previously given at the end of the last section:
A necessary and sufﬁcient condition for S1 to have solutions x ∈Rn is the validity
of the implication
y⊤A ≧0 ⇒y⊤b ≧0
or, equivalently,

42
2
Elements of Convex Analysis. Linear Theorems of the Alternative. Tangent Cones
y⊤A ≦0 ⇒y⊤b ≦0.
Finally, note that for b = 0 Farkas’ theorem becomes trivial.
The following result is a simple formal variant of Farkas’ theorem and generated
a ﬁrst list of theorems of the alternative for linear systems.
Theorem 2.30 Let be given the positive integers m1, m2, m3, n1, n2; the matrices
Ai j of order (mi, n j), i = 1, 2, 3; j = 1, 2; the vectors bi ∈Rmi, i = 1, 2, 3. The
system
⎧
⎪⎪⎨
⎪⎪⎩
A11x1 + A12x2 ≦b1
A21x1 + A22x2 = b2
A31x1 + A32x2 ≧b3
x1 ∈Rn1, x2 ∈Rn2, x1 ≧0,
(2.6)
admits solutions x1, x2 if and only if the system
⎧
⎪⎪⎨
⎪⎪⎩
(y1)⊤A11 + (y2)⊤A21 + (y3)⊤A31 ≧0
(y1)⊤A12 + (y2)⊤A22 + (y3)⊤A32 = 0
(y1)⊤b1 + (y2)⊤b2 + (y3)⊤b3 < 0
y1 ∈Rm1, y2 ∈Rm2, y3 ∈Rm3, y1 ≧0, y3 ≦0,
does not admit solutions y1, y2, y3.
Proof The above result comes out at once from Farkas’ theorem: we put x2 = v1 −
v2, with v1 ≧0, v2 ≧0 and then we transform inequalities into equalities by means
of the “slack vectors” s1 ≧0, s2 ≧0. System (2.6) can be therefore rewritten in the
form
⎡
⎣
A11
A12
−A12
I
0
A21
A22
−A22
0
0
A31
A32
−A32
0 −I
⎤
⎦
⎡
⎢⎢⎢⎢⎣
x1
v1
v2
s1
s2
⎤
⎥⎥⎥⎥⎦
=
⎡
⎣
b1
b2
b3
⎤
⎦
(2.7)
with x1 ≧0, v1 ≧0, v2 ≧0, s1 ≧0, s2 ≧0. Applying to (2.7) Farkas’ theorem we
obtain the thesis.
□
From Theorem 2.30 it is possible to obtain easily a ﬁrst list of theorems of the
alternative. In the following list we use the short convention
Sk ≡{. . . };
S∗
k ≡{. . . },
in order to specify that the “primal” system Sk admits solutions if and only if the
“dual” system S∗
k does not admit solutions.
(1) S2 ≡{Ax = b}; S∗
2 ≡

y⊤A = 0; y⊤b ̸= 0

.

2.2 Theorems of the Alternative for Linear Systems
43
Notethatthisresultgivesnecessaryandsufﬁcientconditionsfortheexistenceof
solutions of a non-homogeneous system of linear equations: system S2 admits
solutions if and only if it holds y⊤b = 0 for any vector y such that y⊤A = 0.
This result is sometimes called the Fredholm theorem of the alternative.
(2) (Theorem of the alternative of Gale [10]).
S3 ≡

Ax ≦b

; S∗
3 ≡

y⊤A = 0; y ≧0; y⊤b < 0

.
(3) S4 ≡

Ax ≦b; x ≧0

; S∗
4 ≡

y⊤A ≧0; y ≧0; y⊤b < 0

.
(4) (Theorem of the alternative of Ky Fan).
S5 ≡

Ax ≦b1; Bx = b2
;
S∗
5 ≡

(y1)⊤A + (y2)⊤B = 0; y1 ≧0; (y1)⊤b1 + (y2)⊤b2 < 0

.
(5) S6 ≡

Ax ≦b1; Bx = b2; x ≧0

;
S∗
6 ≡

(y1)⊤A + (y2)⊤B ≧0, y1 ≧0, (y1)⊤b1 + (y2)⊤b2 < 0

.
(6) S7 ≡

Ax + Bz = b; x ≧0

; S∗
7 ≡

y⊤A ≧0; y⊤B = 0; y⊤b < 0

.
(7) S8 ≡

Ax + Bz ≦b; x ≧0

; S∗
8 ≡

y⊤A ≧0; y⊤B = 0; y⊤b < 0; y ≧0

.
(8) S9 ≡

Cx ≧c

; S∗
9 ≡

y⊤C = 0; y ≧0; y⊤c > 0

.
(9) S10 ≡

Cx ≧c; x ≧0

; S∗
10 ≡

y⊤C ≦0; y ≧0; y⊤c > 0

.
(10) S11 ≡

Cx ≧c; Bx = b; x ≧0

;
S∗
11 ≡

(y1)⊤C + (y2)⊤B ≦0; y1 ≧0; (y1)⊤c + (y2)⊤b > 0

.
(11) S12 ≡

Cx + Dz ≧c; x ≧0

; S∗
12 ≡

y⊤C ≦0; y⊤D = 0; y ≧0; y⊤c > 0

.
(12) S13 ≡

Ax ≧0; b⊤x < 0

; S∗
13 ≡

y⊤A = b; y ≧0

.
(This result is nothing but Farkas’ theorem, where the “primal” and the “dual”
problems have been interchanged).
(13) S14 ≡

Ax ≧0; x ≧0; b⊤x < 0

; S∗
14 ≡

y⊤A ≦b; y ≧0

.
(14) S15 ≡

Cx ≦0; Dx = 0; c⊤x < 0

; S∗
15 ≡

y⊤C + v⊤D + c⊤= 0; y ≧0

.
(15) S16 ≡

Cx + Dz = 0; a⊤x + b⊤z > 0; z ≧0

;
S∗
16 ≡

y⊤C + a⊤= 0; y⊤D + b⊤≦0

.
Another important theorem of the alternative for linear systems (important for
its applications in obtaining optimality conditions for mathematical programming
problems) is Motzkin’s theorem of the alternative.
Theorem 2.31 (Motzkin) Let be given (real) matrices A, B and H of appropriate
dimensions. Then, exactly one of the following systems has a solution:
(i) Ax < 0; Bx ≦0; Hx = 0;
(ii) u⊤A + v⊤B + w⊤H = 0; u ≧0, u ̸= 0; v ≧0.
Proof It is easy to show that both (i) and (ii) cannot have a solution. Suppose
u⊤A + v⊤B + w⊤H = 0 for some u ≧0, u ̸= 0, v ≧0, w unrestricted in sign.
Then, for every vector x we have u⊤Ax + v⊤Bx + w⊤Hx = 0. If Bx ≦0, then
v⊤Bx ≦0 and if Hx = 0, then w⊤Hx = 0. Thus u⊤Ax ≧0. Since u ≧0, u ̸= 0,
Ax < 0 cannot hold.

44
2
Elements of Convex Analysis. Linear Theorems of the Alternative. Tangent Cones
Suppose now that (i) has no solution. Then the system
⎧
⎪⎪⎨
⎪⎪⎩
Ax + eθ ≦0, θ > 0
Bx ≦0
Hx ≦0
−Hx ≦0
has no solution (the vector e is the summation vector, i.e. e = [1, 1, . . . , 1]⊤). This
last system can be written in the form
⎡
⎢⎢⎣
A
e
B
0
H
0
−H
0
⎤
⎥⎥⎦
 x
θ
!
≦0, (0, . . . , 0, 1)
" x
θ
#
> 0.
From Farkas’ theorem, there exists a vector (u, v, w1, w2)⊤≧0 such that
⎡
⎢⎢⎣
A
e
B
0
H
0
−H
0
⎤
⎥⎥⎦
⊤⎛
⎜⎜⎝
u
v
w1
w2
⎞
⎟⎟⎠=
⎛
⎜⎜⎜⎝
0
...
0
1
⎞
⎟⎟⎟⎠.
This can be rewritten as
u⊤A + v⊤B + (w1 −w2)H = 0, u⊤e = 1.
Letting w⊤= (w1 −w2)⊤, we have completed the proof of (ii).
□
We remark that in Theorem 2.31 matrices B and H may be missing. If H in
Theorem 2.31 is missing, we have the two “alternative systems”:
(1)
Ax < 0; Bx ≦0;
(2)
u⊤A + v⊤B = 0; u ≧0, u ̸= 0; v ≧0.
Antosiewicz [11] proves that the previous statement is equivalent to the following
one: either
(a) Ax ≦0, Ax ̸= 0; Bx ≦0 has a solution, or
(b) u⊤A + v⊤B = 0; u > 0; v ≧0 has a solution, but never both.
If in (1) and (2) B is missing, we obtain the theorem of the alternative of Gordan:
• either Ax < 0 has a solution, or
• u⊤A = 0, u ≧0, u ̸= 0 has a solution, but never both.

2.2 Theorems of the Alternative for Linear Systems
45
If in (a) and (b) B is missing, we obtain the theorem of the alternative of Stiemke:
either Ax ≦0, Ax ̸= 0 has a solution, or
u⊤A = 0, u > 0 has a solution, but never both.
Therefore, Gordan’s theorem and Stiemke’s theorem are equivalent statements.
Obviously the ﬁrst statement of Gordan’s theorem can be equivalently restated as
Ax > 0.
ThisleadstothefollowinggeometricversionofGordan’stheorem:let S beasubspace
of Rn. Then one and only one of the following assertions is true:
I. S contains a positive vector.
II. S⊥contains a nonnegative nonzero vector (S⊥is the orthogonal complement
of S).
From Stiemke’s theorem, Nikaido [12] obtains the following result, due to A. W.
Tucker, and called also “key theorem”.
Theorem 2.32 For any given matrix A of order (m, n) the systems
Ax ≧0 and A⊤y = 0, y ≧0
possess solutions x and y such that
Ax + y > 0.
From this result, as shown by Mangasarian [13], it is possible to obtain several
theorems of the alternative, among which the theorems of Gordan, Stiemke, Farkas,
Motzkin and other ones, such as, for example the following ones.
• The theorem of the alternative of Slater: let A, B, C and D be given matrices (C
and D may be missing). Then either
Ax < 0; Bx ≦0, Bx ̸= 0; Cx ≦0; Dx = 0
has a solution x or
u⊤A + v⊤B + w⊤C + z⊤D = 0,
u ≧0, u ̸= 0; v ≧0; w ≧0 or u ≧0; v > 0; w ≧0
has a solution u, v, w, z, but never both.
• The theorem of the alternative of Tucker: let B, C and D be given matrices (C and
D may be missing). Then either
Bx ≦0, Bx ̸= 0; Cx ≦0; Dx = 0
has a solution x, or

46
2
Elements of Convex Analysis. Linear Theorems of the Alternative. Tangent Cones
v⊤B + w⊤C + z⊤D = 0, v > 0, w ≧0
has a solution v, w, z, but never both.
• The theorem of the alternative of Ville: either the system
S ≡

Ax < 0, x ≧0

has a solution x, or the system
S∗≡

y⊤A ≧0, y ≧0, y ̸= 0

has a solution y, but never both.
Note that system S can be equivalently written as
S ≡

Ax < 0, x ≧0, x ̸= 0

or also as
S ≡{Ax < 0, x > 0} .
It turns out that all the theorems of the alternative described in the present section
(and many other ones) are in fact equivalent statements.
In addition, we point out another result, due to A. W. Tucker, which is useful in
obtaining duality theorems for linear programming problems.
Theorem 2.33 Let be given a square skew-symmetric matrix L (i. e. L⊤= −L).
Then the system
Lw ≧0, w ≧0
admits a solution w such that
Lw + w > 0.
Proof By Tucker’s key theorem (Theorem 2.32), applied to matrix (L⊤, I), where
I has the same order of L, there are solutions x and y of
" L
I
#
x ≧0, (L⊤, I)y = 0, y ≧0,
" L
I
#
x + y > 0.
If we let u = (y1, . . . , yn)⊤, v = (yn+1, . . . , y2n)⊤, y = (y1, . . . , y2n)⊤, the
above relations become
Lx ≧0, x ≧0, L⊤u + v = 0, u ≧0, v ≧0,

2.3 Tangent Cones
47
Lx + u > 0, x + v > 0.
In view of L⊤= −L, the third relation entails Lu = v. Therefore, by letting
w = x + u, we have
Lw = Lx + Lu = Lx + v ≧0,
Lw + w = (Lx + v) + (x + u) = (Lx + u) + (x + v) > 0.
This completes the proof.
□
2.3
Tangent Cones
In mathematics the approximation of sets by means of other sets with a simpler
structure plays an important role, especially in optimization theory. In connection
with the development of Convex Analysis the interest focused on the approximation
of a given set S ⊂Rn around a given point x0 ∈S (or also x0 ∈cl(S)) with cones
or with convex cones. Since the vertex of the various approximating cones K(S, x0)
is usually at the origin of Rn, more precisely the approximating cone of a set S at
x0 ∈S is given by the translation K(S, x0) + x0.
There are various notions of local approximating cone; here we shall mention only
the following ones. We begin with a cone introduced by the French mathematician
Bouligand at the beginning of the 30’ies of the XX century, cone usually called
contingent cone or Bouligand tangent cone. For surveys of the various approximating
cones introduced in the literature, see, e.g., Aubin and Frankowska [14], Bazaraa and
Shetty [1], Giorgi et al. [15].
Deﬁnition 2.34 A sequence

xk
⊂Rn \

x0
with xk →x0, is called tangentially
convergent in the direction y ∈Rn to the point x0 if
lim
k→+∞
xk −x0
xk −x0 = y
and we write xk
y→x0.
Obviously any convergent sequence xk →x0 (with xk ̸= x0 for all k) contains
at least a tangentially convergent subsequence. The set of all directions y for which
there exists a feasible sequence

xk
⊂S, with S ⊂Rn, tangentially convergent to
x0 ∈S, form a cone which is a local cone approximation at x0 of the set S.
Deﬁnition 2.35 Let S ⊂Rn and x0 ∈S; the cone
T (S, x0) =

λy ∈Rn : ∃{xk} ⊂S, xk
y→x0, λ ≧0


48
2
Elements of Convex Analysis. Linear Theorems of the Alternative. Tangent Cones
is called Bouligand tangent cone or contingent cone to the set S at the point x0. If
x0 is an isolated point of S, we put T (S, x0) = {0}.
Other equivalent characterizations of T (S, x0) are the following ones:
T (S, x0) =

 y ∈Rn : ∃{xk} ⊂S, lim
k→+∞xk = x0, ∃{λk} ⊂R+,
such that y = lim
k→+∞λk(xk −x0)

;
T (S, x0) =

y ∈Rn : ∃yk →y, ∃tk →0+ such that x0 + tk yk ∈S

;
T (S, x0) =

y ∈Rn : ∃{xk} ⊂S, xk →x0, ∃tk →0+ such that xk−x0
tk
→y

;
T (S, x0) =

y ∈Rn : ∀N(y), ∀λ > 0, ∃t ∈(0, λ), ∃¯y ∈N(y) such that x0 + t ¯y ∈S

.
The notation tk →0+ means that tk →0 and tk > 0 for all k.
Note that T (S, x0) is indeed a cone, closed but not necessarily convex, with
0 ∈T (S, x0). We note also that:
(i) T (S, x0) depends only on the structure of S in a neighborhood of x0, that is
T (S, x0) = T (S ∩U(x0), x0),
where U(x0) is any neighborhood of x0 (the notion of “Bouligand tangent cone”
is therefore an “inﬁnitesimal notion”; this holds true also for the other approxi-
mating cones).
(ii) If x0 ∈int(S), then T (S, x0) = Rn.
(iii) T (S, x0) = T ( ¯S, x0), where ¯S = cl(S).
(iv) T (S1, x0) ⊂T (S2, x0), if S1 ⊂S2.
The fact that T (S, x0) is not necessarily convex appears, e.g., from the following
example.
Example 2.36 Consider the set
S =

(x1, x2) ∈R2 : x1x2 = 0, x1 ≧0, x2 ≧0

.
Take x0 = 0 ∈S. Then T (S, x0) = S, which is not a convex set.
Example 2.37 As T (S, x0) = Rn if x0 ∈int(S), we see that the deﬁnition of
Bouligand tangent cone is indeed meaningful when x0 is a point of the boundary of
S. Also in this evenience, it may be that T (S, x0) does not contain the set S. For
example, if x0 = (0, 0)⊤,
S1 =

(x1, x2) ∈R2 : x2 ≧(x1)2
and S2 =

(x1, x2) ∈R2 : x2 =
*
|x1|

,

2.3 Tangent Cones
49
then T (S1, x0) = {(x1, x2) ∈R2 : x2 ≧0} and T (S2, x0) = {(x1, x2) ∈R2 : x1 =
0, x2 ≧0}.
Example 2.38 If we have m < n functions h1, . . . , hm, continuously differentiable
on Rn, let us consider the set
S =

x ∈Rn : h j(x) = 0, j = 1, . . . , m

.
Let x0 ∈S be such that the gradients ∇h1(x0), . . . , ∇hm(x0), are linearly inde-
pendent; then T (S, x0) is the subspace

y ∈Rn : ∇h j(x0)⊤y = 0, j = 1, . . . , m

.
This can be proved with the help of the Implicit Function Theorem (see
Theorem 4.38).
Theorem 2.39 Let S be a nonempty set in Rn and let x0 ∈S. Then
T (S, x0) = ∩
ε>0 cl

λ(x −x0) : x ∈S ∩Uε(x0), λ > 0

.
Proof Note that the set y = λ(x −x0), λ > 0, x ∈S, is what we have called “cone
generated by S −x0”: ray(S, x0). Let us suppose that the point x0 is not an isolated
point, otherwise the property would be trivial. For a given number ε > 0 and a given
convergent sequence

xk
⊂S \

x0
, with xk →x0, it holds obviously the relation
xk −x0
xk −x0 ∈

λ(x −x0) : x ∈S ∩Uε(x0), λ > 0

for sufﬁciently large k ∈N. Let this sequence be in particular sequentially conver-
gent, with xk
y→x0, so vector y belongs (together with the related contingent cone
T (S, x0)) to the closure of all these cones and hence also to their intersection.
Conversely, let y ̸= 0 (we can choose y such that ∥y∥= 1), with y belonging to
the said intersection, so this vector belongs also to the closure of every single cone.
For every ε = 1/k, with k ∈N sufﬁciently large, there exists therefore a vector yk =
λk(xk −x0), with λk > 0, xk ∈S ∩U1/k(x0) and xk ̸= x0, such that
yk −y
 <
1/k. The expression
xk −x0
xk −x0 =
yk
yk
converges therefore to y, i.e. xk
y→x0, and hence vector y belongs to T (S, x0). □

50
2
Elements of Convex Analysis. Linear Theorems of the Alternative. Tangent Cones
Corollary 2.40 T (S, x0) is a closed cone.
Theorem 2.41 Let S ⊂Rn be a convex set and let x0 ∈S; then
T (S, x0) = cl

cone(S −x0)
	
= cl

ray(S −x0)
	
.
Under the said assumption T (S, x0) is therefore a closed convex cone.
Proof First we shall show that T (S, x0) ⊂cl(ray(S −x0)). For this, let us consider
v ∈T (S, x0). Then, there exists a sequence {xn} ⊂S, xn →x0, and λn > 0 such
that
v = lim
n→∞λn(xn −x0).
Again observe that λn(xn −x0) ⊂ray(S −x0). This shows that T (S, x0) ⊂
cl(ray(S −x0)) = cl(cone(S −x0), being S a convex set. In order to prove the
desired result we now need to prove the opposite inclusion. In this part of the proof
the assumption of the convexity of S will play its role. Let us consider a sequence of
the following form
xn = x0 + 1
n (x −x0),
when x ∈S. It is easy to see that xn can also be represented as
xn = 1
n x + (1 −1
n )x0.
Since S is a convex set, we see that xn ∈S. So we have
xn −x0 = 1
n
x −x0 →0,
as n →∞. This shows that xn →x0. Also, from the expression of xn, we can
show that n(xn −x0) = x −x0. Taking the limit as n →∞, we see that x −x0 ∈
T (S, x0). Since T (S, x0) is a cone and ray(S −x0) is the smallest cone containing
S −x0,wehavethatray(S −x0) ⊂T (S, x0).Sinceweknowthat T (S, x0)isclosed,
we conclude that cl

ray(S −x0)
	
⊂T (S, x0). Being S convex, it holds ray(S −
x0) = cone(S −x0) and we deduce that T (S, x0) is a closed and convex cone.
□
Note that the inclusion T (S, x0) ⊂cl

ray(S −x0)

holds without the assumption
that S is a convex set.
Deﬁnition 2.42 The normal cone N(S, x0) to a convex set S ⊂Rn at x0 ∈S is
deﬁned as
N(S, x0) =

v ∈Rn : v⊤(x −x0) ≦0, ∀x ∈S

.
In other words N(S, x0) is the polar cone of the convex set (S −x0), x0 ∈S.

2.3 Tangent Cones
51
It turns out that the Bouligand tangent cone and the normal cone at x0 ∈S of the
convex set S ⊂Rn are polar cones of each other, i.e.
T (S, x0) = (N(S, x0))∗=

w ∈Rn : w⊤v ≦0, ∀v ∈N(S, x0)

;
N(S, x0) = (T (S, x0))∗=

v ∈Rn : v⊤w ≦0, ∀w ∈T (S, x0)

.
Other local cone approximations of a set S ⊂Rn at x0 ∈S are the following ones.
Deﬁnition 2.43 Let S ⊂Rn and x0 ∈S; the cone
A(S, x0) =

y ∈Rn : ∃δ > 0, ∃a path α : [0, δ) →Rn such that
α(t) ∈S ∀t ∈(0, δ), α(0) = x0, and lim
t→0+
α(t)−α(0)
t
= y

is called cone of attainable directions to S at x0 or Kuhn-Tucker tangent cone to S
at x0.
ThisconewasusedbyKuhnandTucker[16]intheirpioneeringpaperonnonlinear
programming. It can be proved that A(S, x0) is a closed cone (see, e.g., Peterson [17])
and that
A(S, x0) ⊂T (S, x0).
Other equivalent expressions of A(S, x0) are, for example, the following ones.
A(S, x0) =

y ∈Rn : ∀N(y), ∃λ > 0, ∀t ∈(0, λ), ∃¯y ∈N(y), such that x0 + t ¯y ∈S

;
A(S, x0) =

y ∈Rn : ∀{tk} ⊂R+, tk →0+, ∃yk →y, such that x0 + tk yk ∈S

.
Deﬁnition 2.44 Let S ⊂Rn and x0 ∈S; the cone
F(S, x0) =

y ∈Rn : ∃¯λ > 0 such that x0 + ty ∈S, ∀t ∈

0, ¯λ

is called cone of feasible directions to S at x0 or also radial cone to S at x0.
Remark 2.45 Note that F(S, x0) is a cone containing the origin but it is neither
open nor closed. It need not be convex and it holds
F(S, x0) ⊂A(S, x0) ⊂T (S, x0).
If S ⊂Rn is a convex set, then F(S, x0), A(S, x0) and T (S, x0) are all convex
cones and it holds
cl(F(S, x0)) = A(S, x0) = T (S, x0) = cl

cone(S −x0)
	
= cl

ray(S −x0)
	
.

52
2
Elements of Convex Analysis. Linear Theorems of the Alternative. Tangent Cones
Therefore note that if S is convex, F(S, x0) consists of the vectors y = α(x −x0),
with α > 0 and x ∈S.
If S is a convex polyhedron, then
T (S, x0) = cone(S −x0) = ray(S −x0).
From a geometric point of view, we can say that if y ∈Rn is a feasible direction
at x0 with respect to S ⊂Rn, then we can move starting from x0 along a straight
line by a certain range of step to x0 + ty ∈S. The geometric meanings of attainable
and tangent directions are that, besides a straight line, x0 can be approached by a
continuous path and a sequence of points belonging to S, respectively.
References
1. M.S. Bazaraa, C.M. Shetty, Foundations of Optimization, Lecture Notes in Economic and
Mathematics Systems, vol. 122 (Springer, Berlin, 1976)
2. M. Jeter, Mathematical Programming. An Introduction to Optimization (Marcel Dekker, New
York, 1986)
3. A. Dhara, J. Dutta, Optimality Conditions in Convex Optimization. A Finite-Dimensional View
(CRC Press, Boca Raton, London, New York, 2012)
4. D.P. Bertsekas, Nonlinear Programming, 2nd edn. (Athena Scientiﬁc, Belmont, Mass, 1999)
5. D.P. Bertsekas, A. Nedic, A.E. Ozdaglar, Convex Analysis and Optimization (Athena Scien-
tiﬁc, Belmont, Mass, 2003)
6. M. Florenzano, C. Le Van, Finite Dimensional Convexity and Optimization (Springer, Berlin,
2001)
7. J.-B. Hiriart-Urruty, C. Lemarechal, Convex Analysis and Minimization Algorithms, vol. I, II
(Springer-Verlag, Berlin and New York, 1993)
8. R.T. Rockafellar, Convex Analysis (Princeton University Press, Princeton, 1970)
9. J. Palata, A survey of conical approximations used in optimization. Optimization 20, 147–161
(1989)
10. D. Gale, The Theory of Linear Economic Models (McGraw-Hill Book Company, New York,
1960)
11. H.A. Antosiewicz, A theorem of the alternative for pair of matrices. Pac. J. Math. 5, 641–642
(1955)
12. H. Nikaido, Convex Structures and Economic Theory (Academic, New York, 1968)
13. O.L. Mangasarian, Nonlinear Programming (McGraw-Hill Book Company, New York, 1969)
14. J.P. Aubin, H. Frankowska, Set-Valued Analysis (Birkhäuser, Boston, 1990)
15. G. Giorgi, A. Guerraggio, J. Thierfelder, Mathematics of Optimization: Smooth and Nons-
mooth Case (Elsevier, Amsterdam, 2004)
16. H.W. Kuhn, A.W. Tucker, Nonlinear programming, in Proceedings of the Second Berkeley
Symposium on Mathematical Statistics and Probability, ed. by J. Neyman (University of
California Press, Berkeley, 1951), pp. 481–492. Reprinted in Giorgi and Kjeldsen (2014)
17. D.W. Peterson, A review of constraint qualiﬁcations in ﬁnite-dimensional spaces. SIAM Rev.
15, 639–654 (1973)

Chapter 3
Convex Functions and Generalized
Convex Functions
3.1
Convex Functions
Similarly to convex sets, convex and concave functions play a central role in mathe-
matical programming theory. Geometrically, a real-valued function deﬁned on a con-
vex set X ⊂Rn is convex (concave) if the line segment connecting any two points on
the surface generated by the function nowhere lies below (above) the surface itself.
More formally, we have the following basic deﬁnition.
Deﬁnition 3.1 The function f : X ⊂Rn →R, X nonempty convex set, is said to
be convex on X if, for any two points x1, x2 ∈X, it holds
f (λ1x1 + λ2x2) ≦λ1 f (x1) + λ2 f (x2),
for all scalars λ1 ≧0, λ2 ≧0, with λ1 + λ2 = 1, i.e. for all x1, x2 ∈X it holds
f (λx1 + (1 −λ)x2) ≦λf (x1) + (1 −λ) f (x2), ∀λ ∈[0, 1] .
(3.1)
Obviously it is equivalent to require that the inequality in (3.1) holds for all
λ ∈(0, 1). The function f is called strictly convex on X when, for any two points
x1, x2 ∈X, x1 ̸= x2, it holds
f (λx1 + (1 −λ)x2) < λf (x1) + (1 −λ) f (x2), ∀λ ∈(0, 1).
(3.2)
A function f : X →R (X ⊂Rn nonempty convex set) is said to be concave
(resp. strictly concave) on X if and only if −f is convex (resp. strictly convex) on
X. In other words, the above inequalities (3.1) and (3.2) are reversed.
In what follows, in order to avoid useless repetitions, we shall refer in general only
to convex functions. The reader will remark that the set X ⊂Rn must be convex, in
order that the left-hand side of (3.1) and (3.2) makes sense. Note that a real-valued
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al., Basic Mathematical Programming Theory, International Series
in Operations Research & Management Science 344,
https://doi.org/10.1007/978-3-031-30324-1_3
53

54
3
Convex Functions and Generalized Convex Functions
function may be simultaneously convex and concave (e.g. any function of the type
f (x) = ax, a ∈Rn, a ̸= 0; see further), but a function cannot be simultaneously
strictly convex and strictly concave. Examples of strictly convex functions on R are
f (x) = x2 and f (x) = ex; the function f (x) = log x is a typical strictly concave
function on int(R+). The function f (x) = x3 is neither convex nor concave. The
function f (x) = sin x is alternatively convex and concave and, therefore, it is neither
convex nor concave on R. A more elaborated example of convex functions in Rn is
one of the following examples.
Example 3.2 The quadratic function
ϕ(x) = x⊤Bx + p⊤x
where B is a symmetric matrix of order n and p, x ∈Rn (p ̸= 0), is convex on Rn
if and only if the matrix B is positive semideﬁnite. Indeed, we have
ϕ(λx + (1 −λ)y) = λ2x⊤Bx + 2λ(1 −λ)x⊤By + (1 −λ)2y⊤By + λp⊤x + (1 −λ)p⊤y
= λϕ(x) + (1 −λ)ϕ(y) −λ(1 −λ)(x −y)⊤B(x −y)
and for all λ ∈[0, 1] we have
λ(1 −λ)(x −y)⊤B(x −y) ≧0
if and only if B is positive semideﬁnite. This and the deﬁnition of convex functions
imply the assertion of the example.
It is obvious that for a quadratic function ϕ to be strictly convex on Rn it is
necessary and sufﬁcient that the matrix B be positive deﬁnite.
Similarly to what was said for convex sets, we have the following result.
Theorem 3.3 A function f : X ⊂Rn →R (X nonempty convex set) is convex on
X if and only if, with x1, . . . , xk any collection of elements of X, it holds
f (λ1x1 + · · · + λkxk) ≦λ1 f (x1) + · · · + λk f (xk),
for all λ1, . . . , λk ≧0, with λ1 + · · · + λk = 1.
The above inequality is known as Jensen inequality for convex functions. Obvi-
ously, similar inequalities hold for strictly convex functions, for concave functions,
and for strictly concave functions.
A class of convex functions that plays an important role in optimization is given
by those functions called sublinear functions.
Deﬁnition 3.4 A function f : Rn →R is called a sublinear function if, for all
x, y ∈Rn,

3.1 Convex Functions
55
(i)
f (x + y) ≦f (x) + f (y) (subadditive property);
(ii)
f (λx) = λf (x), ∀λ > 0 (positive homogeneity property).
Note that for x = 0 we have f (0) = 0. It is possible to prove the following result.
Theorem 3.5 Let f : Rn →R be a convex function that is positively homogeneous.
Then f is a sublinear function.
Weﬁrst recall thebasicproperties of convexandconcavefunctions of onevariable,
properties useful also for characterizing convex and concave functions of several
variables. We have the following propositions.
Let ϕ : I ⊂R →R be a function deﬁned on an open interval I.
(1) Let ϕ be differentiable on I; then ϕ is convex (concave) on I if and only if ϕ′(x)
is increasing (decreasing) on I.
(2) Let ϕ be twice-differentiable on I; then ϕ is convex (concave) on I if and only
if ϕ′′(x) ≧0 (ϕ′′(x) ≦0) for all x ∈I.
(3) If ϕ is differentiable on I, then ϕ is strictly convex (strictly concave) on I if and
only if ϕ′(x) is strictly increasing (strictly decreasing) on I.
(4) If ϕ is twice-differentiable on I, then ϕ is strictly convex (strictly concave) on I
if ϕ′′(x) > 0 (ϕ′′(x) < 0) for all x ∈I. Note that here we have only a sufﬁcient
condition.
Now we describe several equivalent characterizations of convex functions of sev-
eral variables.
Theorem 3.6 Let X ⊂Rn be a nonempty convex set and let f : X →R. The follo-
wing properties are equivalent:
(a) The function f is convex on X.
(b) For every x ∈X and every y ∈Rn, the function gx,y(t) ≡f (x + ty) is convex
on the set T (x, y) = {t : t ∈R, x + ty ∈X} .
(c) For every x1, x2 ∈X, the function hx1,x2(λ) ≡f (λx1 + (1 −λ)x2) is convex on
the interval [0, 1] .
(d) The set (“epigraph of f ”)
epi( f ) =

(x, α) : (x, α) ∈X × R, f (x) ≦α

is convex.
(e) Let X ⊂Rn be convex and open. For every x0 ∈X there exists u0 ∈Rn such
that
f (x) −f (x0) ≧(u0)⊤(x −x0), ∀x ∈X.
Proof (a) ⇒(b). It is easy to see that the set T (x, y) is convex (it is an interval!).
Let t1, t2 ∈T (x, y) and λ ∈(0, 1). Being f convex, it holds
gx,y(tλ) = f (x + tλy) = f (λ(x + t1y) + (1 −λ)(x + t2y)
≦λf (x + t1y) + (1 −λ) f (x + t2y) = λgx,y(t1) + (1 −λ)gx,y(t2),

56
3
Convex Functions and Generalized Convex Functions
with tλ = λt1 + (1 −λ)t2.
(b) ⇒(c). For every x1, x2 ∈X and λ ∈(0, 1) it holds
hx1,x2(λ) = f (λx1 + (1 −λ)x2) = f (x2 + λ(x1 −x2)) = gx2,x1−x2(λ).
From the convexity of gx2,x1−x2(λ), it results at once the convexity of hx1,x2.
(c) ⇒(d). Let (x1, z1), (x2, z2) ∈epi( f ) and λ ∈(0, 1). From the convexity of
hx1,x2 it holds
hx1,x2(λ) ≦λhx1,x2(1) + (1 −λ)hx1,x2(0) = λf (x1) + (1 −λ) f (x2) ≦λz1 + (1 −λ)z2,
i.e.
f (λx1 + (1 −λ)x2) ≦λz1 + (1 −λ)z2,
which proves that
λ(x1, z1) + (1 −λ)(x2, z2) ∈epi( f ).
(d) ⇒(a). Let be x1, x2 ∈X and λ ∈(0, 1). As (x1, f (x1)) and (x2, f (x2)) are
elements of epi( f ) and this set is convex, it results that
λ(x1, f (x1)) + (1 −λ)(x2, f (x2))
is an element of epi( f ). Therefore,
f (λx1 + (1 −λ)x2) ≦λf (x1) + (1 −λ) f (x2).
(d) ⇒(e). Let be x0 ∈X. It results that (x0, f (x0)) belongs to the boundary of
the convex set epi( f ). From the supporting hyperplane theorem (see Theorem 2.19),
it results that there exists (v, v0) ̸= 0 such that
v⊤x + v0z ≧v⊤x0 + v0 f (x0)
(3.3)
for every (x, z) ∈epi( f ).
We can see that v0 > 0 : if it would be v0 = 0, it would result v⊤(x −x0) = 0,
which implies v = 0 and hence (v, v0) = 0, absurd. If v0 < 0, then by choosing z
sufﬁciently large, we could obtain
v⊤x + v0z < v⊤x0 + v0 f (x0),
in contradiction with inequality (3.3), previously proved. Now, from inequality (3.3),
with v0 > 0, by choosing z = f (x) and with u0 = 1
v0 v, we obtain
f (x) −f (x0) ≧(u0)⊤(x −x0).

3.1 Convex Functions
57
(e) ⇒(a). Let be x1, x2 ∈X and λ ∈(0, 1). By multiplying the inequality
f (x1) −f (x0) ≧(u0)⊤(x1 −x0)
and the inequality
f (x2) −f (x0) ≧(u0)⊤(x2 −x0)
respectively, by λ and (1 −λ), we obtain
λf (x1) + (1 −λ) f (x2) −f (x0) ≧(u0)⊤(λx1 + (1 −λ)x2 −x0).
By choosing x0 = λx1 + (1 −λ)x2, from the previous inequality it results that
f is convex.
□
It is useful to remark that vector u0 of characterization (e) is called a subgradient
of f (x) at x0 ∈X (see, e.g. Rockafellar [1] and see Sect. 10.1). The set of all
subgradients of f (x) at x0 ∈X is called the subdifferential of f (x) at x0 and denoted
by ∂f (x0).
To motivate the geometric interpretation of these concepts we consider the convex
function f (x) = |x| , x ∈R. Note that at the origin (point of non-differentiability)
we may draw an inﬁnite number of non-vertical tangent lines which are in fact non-
vertical supporting hyperplanes to the epigraph of f (x). The slope of each of these
lines is in fact a subgradient of f (x) at x0 = 0. Non-subdifferentiability can however
occur on the boundary of the domain of a convex function, where a vertical supporting
hyperplane to its epigraph may exist. Consider, e.g. the function f : [0, 1] →[0, 1]
deﬁned by f (x) = −√x. This function is clearly convex, however ∂f (0) = ∅. We
may, therefore, restate characterization (e) of Theorem 3.6 as:
• Let f be a real-valued function on an open convex set X ⊂Rn. Then f is convex
on X if and only if it has a subgradient at each point x0 ∈X.
From the above characterization, we get that a real-valued convex function on an
open convex subset X of Rn is subdifferentiable on X. See also Bazaraa and Shetty
[2], p. 92 or Bazaraa, Sherali, and Shetty [3]. We shall revert on these questions in
Chap. 10.
Theorem 3.7 (Equivalent characterizations of differentiable convex functions) Let
X ⊂Rn be an open convex set and f : X →R differentiable on X. The following
statements are equivalent:
(a)
f is convex on X.
(b) For every x ∈X and y ∈Rn the derivative g′
x,y(t) = y⊤∇f (x + ty) is increas-
ing on T (x, y).
(c) For
every
x1, x2 ∈X
the
derivative
h′
x1,x2(λ) = (x1 −x2)⊤∇f (λx1 +
(1 −λ)x2) is increasing on [0, 1] .

58
3
Convex Functions and Generalized Convex Functions
(d) For all x1, x2 ∈X it holds
f (x1) −f (x2) ≧(x1 −x2)⊤∇f (x2).
(e) For all x1, x2 ∈X it holds
f (x1) −f (x2) ≦(x1 −x2)⊤∇f (x1).
(f) For all x1, x2 ∈X it holds
(x1 −x2)⊤(∇f (x1) −∇f (x2)) ≧0.
Proof (a) ⇔(b). From the previous theorem it results that f is convex on X if and
only if gx,y is convex on T (x, y), which is equivalent to the fact that the derivative
g′
x,y(t) = y⊤∇f (x + ty) is increasing on T (x, y).
(a) ⇔(c). Again from the previous theorem, it results that f is convex on X if
and only if hx1,x2 is convex on [0, 1] , which is equivalent to the fact that the derivative
h′
x1,x2(λ) = (x1 −x2)⊤∇f (λx1 + (1 −λ)x2) of hx1,x2 is increasing on [0, 1] .
(c) ⇒(d). As h′
x1,x2(λ) is increasing on [0, 1] , it results for every λ ∈[0, 1] ,
h′
x1,x2(0) ≦h′
x1,x2(λ)
and, therefore,
(x1 −x2)⊤∇f (x2) ≦(x1 −x2)⊤∇f (λx1 + (1 −λ)x2).
From Taylor’s formula (ﬁrst-order expansion) we get
f (x1) −f (x2) = (x1 −x2)⊤∇f (θx1 + (1 −θ)x2),
0 ≦θ ≦1.
The result follows from the last two inequalities, with λ = θ.
(d) ⇒(e). For every x1, x2 ∈X we can write
f (x1) −f (x2) = −( f (x2) −f (x1)) ≦−(x2 −x1)⊤∇f (x1),
i.e.
f (x1) −f (x2) ≦(x1 −x2)∇f (x1).
(e) ⇒( f ). By summing the following two inequalities
f (x1) −f (x2) ≦(x1 −x2)∇f (x1);
f (x2) −f (x1) ≦−(x1 −x2)∇f (x2),

3.1 Convex Functions
59
we have the desired result.
( f ) ⇒(c). For any x1, x2 ∈X and any λ1, λ2 ∈[0, 1] , with λ1 < λ2, we can
write
h′
x1,x2(λ2) −h′
x1,x2(λ1) = (x1 −x2)⊤∇f (λ2x1 + (1 −λ2)x2)
−(x1 −x2)⊤∇f (λ1x1 + (1 −λ1)x2).
Let us denote y1 = λ1x1 + (1 −λ1)x2 and y2 = λ2x1 + (1 −λ2)x2. It results
that y1, y2 ∈X and that
y1 −y2 = (λ1 −λ2)(x1 −x2).
Therefore,
h′
x1,x2(λ2) −h′
x1,x2(λ1) =
1
λ1 −λ2
(y1 −y2)⊤(∇f (y2) −∇f (y1))
=
1
λ2 −λ1
(y2 −y1)⊤(∇f (y2) −∇f (y1)) ≧0,
and hence h′
x1,x2(λ) is increasing on [0, 1].
□
We are now concerned with the characterization of twice-continuously differen-
tiable convex functions, i.e. functions belonging to the C 2 class.
Theorem 3.8 Let f be C 2 on the open convex set X ⊂Rn. Then f is convex on X
if and only if its Hessian matrix ∇2 f (x) is positive semideﬁnite for every x ∈X.
Proof (1) Let ∇2 f (x) be positive semideﬁnite for all x ∈X. By Taylor’s formula
(second-order expansion) we can write
f (x1) −f (x2) = (x1 −x2)⊤∇f (x2) + 1
2(x1 −x2)⊤∇2 f (xθ)(x1 −x2),
with xθ = θx1 + (1 −θ)x2, θ ∈(0, 1).
Being ∇2 f (x) positive semideﬁnite for all x ∈X, we have
f (x1) −f (x2) ≧(x1 −x2)⊤∇f (x2), ∀x1, x2 ∈X.
(2) Let f be convex on X. We have (Theorem 3.7) that g′
x,y(t) = y⊤∇f (x + ty) is
increasing on T (x, y) = {t : t ∈R, x + ty ∈X} . Being f ∈C 2(X), also gx,y
is twice differentiable on T (x, y). It holds, therefore, that g′′
x,y(t) ≧0 for all
t ∈T (x, y), i.e.
y⊤∇2 f (x + ty)y ≧0
for all t ∈T (x, y). In particular, for t = 0 ∈T (x, y), we get

60
3
Convex Functions and Generalized Convex Functions
y⊤∇2 f (x)y ≧0
for all y ∈Rn and for all x∈X, i.e. ∇2 f (x) is positive semideﬁnite for all x ∈X.
□
The previous results can be easily transferred to the case of concave functions (of
several variables).
For what concerns strictly convex functions we have the following results.
Theorem 3.9 Let be f : X ⊂Rn →R, with X nonempty convex set. The following
statements are equivalent:
(a)
f is strictly convex on X, i.e.
f (λx1 + (1 −λ)x2) < λf (x1) + (1 −λ) f (x2), ∀x1, x2 ∈X, x1 ̸= x2, ∀λ ∈(0, 1).
(b) For any x ∈X and y ∈Rn, y ̸= 0, the function gx,y(t) = f (x + ty) is strictly
convex on the interval T (x, y) = {t ∈R : x + ty ∈X} .
(c) The function hx1,x2(λ) = f (λx1 + (1 −λ)x2) is strictly convex on the interval
[0, 1] .
Theorem 3.10 Let f : X ⊂Rn →R be differentiable on the open convex set X.
The following statements are equivalent:
(a)
f is strictly convex on X.
(b)
f (x1) −f (x2) > (x1 −x2)⊤∇f (x2), ∀x1, x2 ∈X, x1 ̸= x2.
(c)
f (x1) −f (x2) < (x1 −x2)⊤∇f (x1), ∀x1, x2 ∈X, x1 ̸= x2.
(d) (x1 −x2)⊤
∇f (x1) −∇f (x2)

> 0, ∀x1, x2 ∈X, x1 ̸= x2.
Theorem 3.11 Let f : X ⊂Rn →R be C 2 on the open convex set X. Then f is
strictly convex on X if ∇2 f (x) is positive deﬁnite for all x ∈X.
We note that Theorem 3.11 gives only sufﬁcient conditions for f ∈C 2 to be
strictly convex. Indeed, if we consider, for example, the function f (x) = x4, x ∈R,
or also f (x) = (x1)4 + (x2)4, x ∈R2, we can see that these functions are strictly
convex on R (on R2) but the second-order derivative evaluated at x = 0 (the Hessian
matrix evaluated at 0 ∈R2) is zero (is the zero matrix). A weaker sufﬁcient condition
for the strict convexity of C 2-functions is (see, e.g. Fenchel [4]).
TheHessianmatrix∇2 f (x)ispositivesemideﬁniteforall x ∈X anddet(∇2 f (x))
̸= 0 on all segments contained in X.
However, note that for quadratic functions
ϕ(x) = x⊤Bx + p⊤x
the positive deﬁniteness of the matrix B is necessary and sufﬁcient for ϕ to be strictly
convex (see the last lines of Example 3.2).
We give now a necessary condition for the convexity of a function deﬁned on a
nonempty convex set X ⊂Rn. This condition will be useful in characterizing a class
of generalized convex functions: the class of quasiconvex functions.

3.1 Convex Functions
61
Theorem 3.12 Let X ⊂Rn be a nonempty convex set and f : X ⊂Rn →R be
convex on X. Then the lower level set
lev≦α f =

x ∈X : f (x) ≦α

is convex for all α ∈R.
Proof Let x1, x2 ∈X and λ ∈[0, 1] . As X is a convex set, it results xλ ≡λx1 +
(1 −λ)x2 ∈X. From the convexity of f we obtain
f (xλ) ≦λf (x1) + (1 −λ) f (x2) ≦λα + (1 −λ)α = α.
Being α ∈lev≦α f, this shows the convexity of lev≦α f, for every α ∈R (we
recall that the empty set ∅is convex by deﬁnition).
□
As we have remarked, the proposition of Theorem 3.12 is only a necessary condi-
tion for the convexity of f : X →R (X ⊂Rn convex set). Consider, for example, the
function f (x) = log x, x ∈R, x > 0, which is not convex (it is strictly concave!),
but which satisﬁes the condition of Theorem 3.12. It is the same for f (x) = x3,
x ∈R, for f (x) = min(x, 2x), x ∈R, etc.
A similar result holds obviously for concave functions: the upper level set
lev≧α f =

x ∈X : f (x) ≧α

is convex for all α ∈R.
Theorem 3.13 Let X ⊂Rn be an open convex set. If f : X →R is convex on X,
then f is continuous on X.
Proof We prove the theorem in three steps.
Step1.If f isconvexon X and x1, . . . , xk ∈X andλ1, . . . , λk ≧0andk
j=1 λ j =
1, then (Jensen inequality)
f
⎛
⎝
k
	
j=1
λ jx j
⎞
⎠≦
k
	
j=1
λ j f (x j).
Step 2. For each x ∈X, there exists a β > 0 such that x ± βei ∈X, for i =
1, . . . , n, where ei is the unit vector. Call these vectors z1, . . . , z2n. Let be Mx =
max

f (z1), . . . , f (z2n)

.Since x liesintheinterioroftheconvexhullof z1, . . . , z2n,
there exists tx > 0 such that U(x, tx) =

y : ∥y −x∥≦tx

also lies in the con-
vex hull of z1, . . . , z2n. Then, for any y satisfying ∥y −x∥≦tx it holds that
y = 2n
j=1 λ jz j for some appropriate λ1, . . . , λ2n ≧0 and 2n
j=1 λ j = 1 and so
f (y) = f
⎛
⎝
2n
	
j=1
λ jz j
⎞
⎠≦
2n
	
j=1
λ j f (z j) ≦Mx.

62
3
Convex Functions and Generalized Convex Functions
Step 3. Without loss of generality, we assume that f (0) = 0 and we want to prove
that f (x) is continuous at x = 0. For any ε > 0, we must exhibit a δ > 0 such that if
∥y∥< δ then −ε ≦f (y) ≦ε. Let t > 0 and M be chosen so that ∥y∥≦t implies
f (y) ≦M (from Step 2). Now let be δ = tε/M. Let y satisfy ∥y∥< δ. Also, we
can assume that M > ε and write
y =

1 −ε
M

0 +
 ε
M
  M
ε y

.
Since
± M
ε y
 = M
ε ∥y∥< t, it follows that f

± M
ε y

≦M. Therefore,
f (y) ≦

1 −ε
M

f (0) +
 ε
M

f
 M
ε y

≦0 + ε
M M = ε.
We also have
0 =
ε
M
1 + ε
M

−M
ε y

+
1
1 + ε
M
y,
and so
0 = f (0) ≦
ε
M
1 + ε
M
f

−M
ε y

+
1
1 + ε
M
f (y) ≦
ε
M
1 + ε
M
M +
f (y)
1 + ε
M
.
Therefore, f (y) ≧−ε and so −ε ≦f (y) ≦ε.
□
From the previous theorem, it appears that if f is convex on X ⊂Rn, X convex
but not necessarily open, and if f has discontinuity points, these points are on the
boundary of X. Consider the following example:
X =

x ∈R, x ≧0

,
f : X →R deﬁned as
f (x) =
 x2, for x > 0,
1,
for x = 0.
It results that f is convex on X, with a discontinuity point at x = 0.
For what concerns the differentiability of convex functions, we report the follo-
wing results (see, e.g. Fenchel [4]).
Theorem 3.14 If f : X ⊂Rn →R is convex on the open convex set X, then f is
differentiable with continuous partial derivatives (i.e. f ∈C 1) everywhere on X,
except for a set of measure zero (in Lebesgue’s sense).
Hence a convex function f : X ⊂Rn →R, X open convex set, may be non-
differentiable at some points x ∈X. Consider, e.g. the convex function f (x) = |x| ,
x ∈R, obviously non-differentiable at x = 0.

3.1 Convex Functions
63
Theorem 3.15 Let X ⊂Rn be a convex set and f : X →R be convex on X. Then
(a)
f is bounded on every compact subset Y ⊂int(X).
(b)
f is bounded from below on every bounded subset Y ⊂int(X).
An afﬁne function is obviously both convex and concave (but not in the strict
sense!) on a convex set X ⊂Rn. Also the vice-versa holds, as shown by the following
(a bit less trivial) result.
Theorem 3.16 Let X ⊂Rn be a convex set and let be f : X →R. If f is both
convex and concave on X, then f is linear afﬁne on X, i.e.
f (μx1 + (1 −μ)x2) = μf (x1) + (1 −μ) f (x2),
for any x1, x2 ∈X and any μ ∈R such that μx1 + (1 −μ)x2 ∈X.
Proof Being f both convex and concave on X, it results, for any x1, x2 ∈X and for
all λ ∈[0, 1] ,
f (λx1 + (1 −λ)x2) = λf (x1) + (1 −λ) f (x2).
Let now μ ∈R such that x = μx1 + (1 −μ)x2 ∈X and let be x0 = 1
2(x1 + x2).
If we choose λ sufﬁciently small such that the inequality λ |2μ −1| < 1 is veriﬁed,
it results that 0 < λμ + (1 −λ)/2 < 1 and hence
λ(μf (x1) + (1 −μ) f (x2)) + (1 −λ) f (x0)
=

λμ + 1 −λ
2

f (x1) +

λ(1 −μ) + 1 −λ
2

f (x2)
= f

λμ + 1 −λ
2

x1 +

λ(1 −μ) + 1 −λ
2

x2

= λf (x) + (1 −λ) f (x0).
From here, we derive the desired property f (x) = μf (x1) + (1 −μ) f (x2).
□
We have seen that if f : X ⊂Rn →R is convex on the convex set X, then f
is continuous on int(X). We remark again that f may be non-differentiable on
int(X), however, convex functions possess some nice properties concerning direc-
tional derivatives.
Let f be a real-valued function deﬁned on an open set X ⊂Rn. The (one-sided)
directional derivative of f at x0 ∈X in the direction of y ∈Rn, denoted Df (x0, y)
or also Dy f (x0), or f ′(x0, y), etc., is given by
Df (x0, y) = lim
λ→0+
f (x0 + λy) −f (x0)
λ
,
if the limit exists (+∞and −∞being allowed as limits).

64
3
Convex Functions and Generalized Convex Functions
Note that
−Df (x0, −y) = lim
λ→0−
f (x0 + λy) −f (x0)
λ
.
If Df (x0, y) = −Df (x0, −y), then f is said to be a two-sided directional deriva-
tive at x0 in the direction of y, i.e. the limit
lim
λ→0
f (x0 + λy) −f (x0)
λ
exists (ﬁnite or not).
If f has a two-sided directional derivative in all directions at x0, then f is said
to be Gâteaux differentiable at x0. We recall that if f : Rn →R is differentiable
at x0, then f is Gâteaux differentiable at x0, with ﬁnite derivative, for all y ∈Rn.
Moreover,
Df (x0, y) = ∇f (x0)⊤y.
We have the following basic results (see, e.g. Delfour [5], Rockafellar [1], Roberts
and Varberg [6], Ruszczynski [7]).
Theorem 3.17 Let f : X ⊂Rn →R be a convex function on the convex set X.
Then, for every x ∈X and every y ∈Rn, the directional derivative Df (x, y) exists
(ﬁnite or inﬁnite). If x ∈int(X), then Df (x, y) is ﬁnite for all y ∈Rn. Moreover,
Df (x, y) is a positively homogeneous convex function of y, with
−Df (x, −y) ≦Df (x, y).
We can summarize in the following proposition what was previously asserted.
• Let f : X ⊂Rn →R be a convex function on the open convex set X; then:
(a) f admits ﬁnite one-sided directional derivatives for all directions y ∈Rn at any
point x ∈X. Therefore, f admits left- and right-sided partial derivatives at any
point x ∈X.
(b) At all points x ∈X, where there exists the gradient ∇f (x), then f is continu-
ously differentiable.
We shall revert on these questions in Chap. 10.
3.2
Generalized Convex Functions
Several generalizations of the classical concept of a convex function have been intro-
duced in the literature; under the name of “generalized convex functions” we mean
functions that are not convex but that retains some of the nice properties and char-
acteristics of convex functions. For good accounts of generalized convex functions

3.2 Generalized Convex Functions
65
one may consult the books quoted in the References, e.g. Bertsekas [8], Cambini and
Martein [9], Hadjisavvas et al. [10].
We have seen in Theorem 3.12 that a necessary (but not sufﬁcient) conditions for
f : X ⊂Rn →R to be convex on the convex set X ⊂Rn, is:
• The lower level set
lev≦α f =

x ∈X : f (x) ≦α

is convex for all α ∈R.
This property becomes one of the characterizations of the class of quasiconvex
functions.
Deﬁnition 3.18 Let be given f : X ⊂Rn →R and deﬁned on the convex set X.
Then f is said to be quasiconvex on X if
f (λx1 + (1 −λ)x2) ≦max

f (x1), f (x2)

, for all x1, x2 ∈X, for all λ ∈[0, 1] .
Obviously, the above relation is equivalent to:
f (x2) ≦f (x1) ⇒f (λx1 + (1 −λ)x2) ≦f (x1), ∀x1, x2 ∈X, ∀λ ∈[0, 1] .
The function f : X ⊂Rn →R is quasiconcave on the convex set X if and only
if −f is quasiconvex on X.
Theorem 3.19 Let X ⊂Rn be a nonempty convex set and let f : X →R. The follo-
wing statements are equivalent:
(a)
f is quasiconvex on X.
(b) For any x ∈X and any y ∈Rn the function gx,y(t) = f (x + ty) is quasiconvex
on the interval
T (x, y) = {t : t ∈R, x + ty ∈X} .
(c) For any x1, x2 ∈X the function hx1,x2(λ) = f (λx1 + (1 −λ)x2) is quasiconvex
on [0, 1] .
(d) For any α ∈R the lower level set
lev≦α f =

x ∈X : f (x) ≦α

is convex.
Proof (a) ⇒(b) ⇒(c). The proof is similar to the one for the corresponding impli-
cations in Theorem 3.6.
(c) ⇒(d). Let x1, x2 ∈lev≦α f and λ ∈[0, 1] . From the quasiconvexity of
hx1,x2(λ) it results
hx1,x2(λ) ≦max

hx1,x2(1), hx1,x2(0)

,

66
3
Convex Functions and Generalized Convex Functions
i.e.
f (λx1 + (1 −λ)x2) ≦max

f (x1), f (x2)

≦α
and, therefore, λx1 + (1 −λ)x2 ∈lev≦α f, i. e. lev≦α f is a convex set. Recall that
∅is convex by deﬁnition.
(d) ⇒(a). Let x1, x2 ∈X and λ ∈[0, 1] and let α = max

f (x1), f (x2)

. As
x1, x2 ∈lev≦α f , and lev≦α f is a convex set, it results that (λx1 + (1 −λ)x2) ∈
lev≦α f, that is
f (λx1 + (1 −λ)x2) ≦α,
i.e. f is quasiconvex on X.
□
Now we characterize the class of differentiable quasiconvex functions.
Theorem 3.20 Let f : X ⊂Rn →R be differentiable on the open convex set X.
Then the following statements are equivalent:
(a)
f is quasiconvex on X.
(b) x1, x2 ∈X, f (x1) ≦f (x2) ⇒(x1 −x2)⊤∇f (x2) ≦0.
(c) x1, x2 ∈X, (x1 −x2)⊤∇f (x2) > 0 ⇒f (x1) > f (x2).
(d) x1, x2 ∈X, f (x1) < f (x2) ⇒(x1 −x2)⊤∇f (x2) ≦0.
Proof (a) ⇒(b). Let f be quasiconvex on X, i.e. for any x1, x2 ∈X, the function
hx1,x2(λ) = f (λx1 + (1 −λ)x2), λ ∈[0, 1] ,
is quasiconvex on [0, 1] . Let be f (x1) ≦f (x2). It results
hx1,x2(λ) ≦max

hx1,x2(1), hx1,x2(0)

= hx1,x2(0),
which shows that hx1,x2 has at λ = 0 a global maximum point on [0, 1] . Being f
differentiable on the open and convex set X, it results that hx1,x2 is differentiable on
[0, 1] and, therefore, it must be
h′
x1,x2(0) ≦0
i.e.
(x1 −x2)⊤∇f (x2) ≦0.
(b) ⇒(a). Let x1, x2 ∈X with f (x1) ≦f (x2). It is sufﬁcient to prove that hx1,x2
has at λ = 0 a global maximum point on [0, 1] . Let us absurdly suppose that this
property does not hold; it results then that the set
A =

λ : λ ∈(0, 1), hx1,x2(λ) > hx1,x2(0)

is nonempty. Moreover, as hx1,x2 is differentiable, it results that it is continuous and
that A is open. It follows that λ0 = sup(A) /∈A and hence hx1,x2(λ0) ≦hx1,x2(0).

3.2 Generalized Convex Functions
67
Now we show that hx1,x2 is constant on A. As λ ∈A, it results hx1,x2(λ) > hx1,x2(0)
and, therefore, f (x2) < f (xλ), with xλ = λx1 + (1 −λ)x2. From the assumption
we obtain
(x2 −xλ)⊤∇f (xλ) ≦0.
Similarly, as f (x1) ≦f (x2) < f (xλ), we get
(x1 −xλ)⊤∇f (xλ) ≦0.
The last two inequalities can be written in the form
(1 −λ)(x1 −x2)⊤∇f (xλ) ≦0
and
−λ(x1 −x2)⊤∇f (xλ) ≦0,
from which we get
h′
x1,x2(λ) = (x1 −x2)⊤∇f (xλ) = 0,
which shows that hx1,x2 is constant on A. Therefore, it results
lim
λ→λ0, λ∈A hx1,x2(λ) > hx1,x2(0) ≧hx1,x2(λ0),
which is absurd, being hx1,x2 continuous at λ0.
(b) ⇔(c). Trivial.
(b) ⇔(d). Property (d) follows immediately from (b). For the converse, see [11].
□
Another useful class of generalized convex functions, originally introduced by O.
L. Mangasarian for differentiable functions, is the class of pseudoconvex functions.
Deﬁnition 3.21 Let X ⊂Rn be an open set and let f : X →R be differentiable on
X. Then f is pseudoconvex on X if
x1, x2 ∈X, (x1 −x2)⊤∇f (x2) ≧0 ⇒f (x1) ≧f (x2),
or equivalently,
x1, x2 ∈X,
f (x1) < f (x2) ⇒(x1 −x2)⊤∇f (x2) < 0.
The function f : X →R is pseudoconcave on X if and only if −f is pseudoconvex
on X.
In order to compare pseudoconvex functions with other classes of generalized
convex functions, it is convenient to assume that X ⊂Rn is open and convex.

68
3
Convex Functions and Generalized Convex Functions
Deﬁnition 3.22 Let be f : X ⊂Rn →R, with X nonempty convex set. Then f is
said to be semistrictly quasiconvex on X if
f (λx1 + (1 −λ)x2) < max

f (x1), f (x2)

for every x1 ̸= x2 ∈X, with f (x1) ̸= f (x2) and for every λ ∈(0, 1).
It can be proved that Deﬁnition 3.22 is equivalent to: for every x1, x2 ∈X, one
has
f (x1) < f (x2) ⇒f (λx1 + (1 −λ)x2) < f (x2), ∀λ ∈(0, 1).
We have to point out that in the literature semistrictly quasiconvex functions are
also called strictly quasiconvex functions and that also other denominations have
been used.
Theorem 3.23 Let X ⊂Rn beanonemptyconvexsetand f : X →Rbesemistrictly
quasiconvex on X and lower semi-continuous on X. Then f is quasiconvex on X.
Proof Let x1, x2 ∈X and let us suppose that it holds f (x1) ≦f (x2). If f (x1) <
f (x2), the thesis is immediate. If f (x1) = f (x2), we have to prove that
f (x) ≦max

f (x1), f (x2)

= f (x1) = f (x2),
for every x of the segment (x1, x2) =

x : x = λx1 + (1 −λ)x2, λ ∈(0, 1)

. Let
us absurdly suppose the opposite case. It results that the set
A =

x ∈

x1, x2
: f (x) > f (x1)

is nonempty. From the semistrict quasiconvexity of f, it results, therefore, that for
every x of the segment

x1, x2
=

x : x = λx1 + (1 −λ)x2, λ ∈[0, 1]

and for
every y ∈A \ {x} , we have f (x) < f (y). On the other hand, from the lower semi-
continuity of f, it results that A is open relatively to the segment (x1, x2) and,
therefore, there exist y1, y2 ∈A, with y1 ̸= y2. Hence it results f (y1) < f (y2) and
f (y1) > f (y2), which is absurd.
□
Remark 3.24 We note that in Theorem 3.23 if the assumption on lower semi-
continuity is missing, the implication does not hold. For instance, the function
f (x) =
1
if x = 0,
0
if x ̸= 0,
is semistrictly quasiconvex, but not quasiconvex. Obviously, there are functions
which are quasiconvex, but not semistrictly quasiconvex (for example a monotone
function on R, which is constant on some open interval).
We now point out the relationships among the classes of convex and generalized
convex functions previously introduced.

3.2 Generalized Convex Functions
69
Theorem 3.25 Let X ⊂Rn be a nonempty convex set and let be f : X →R.
(i) If f is strictly convex on X, then f is convex on X.
(ii) If f is convex on X, then f is semistrictly quasiconvex on X; if f is semistrictly
quasiconvex on X and it is also lower semi-continuous on X, then f is quasi-
convex on X.
Proof Implication (i) and the ﬁrst implication of (ii) follow directly from the deﬁ-
nitions. The second implication of (ii) is the thesis of Theorem 3.23.
□
Theorem 3.26 Let X ⊂Rn be an open convex set and let f : X →R be differen-
tiable on X.
(i) If f is convex on X, then f is pseudoconvex on X.
(ii) If f is pseudoconvex on X, then f is semistrictly quasiconvex on X and hence
also quasiconvex on X.
Proof (i) Let x1, x2 ∈X, with f (x1) < f (x2). Being f convex (and differentiable)
on X, by Theorem 3.7 we have
f (x1) −f (x2) ≧(x1 −x2)⊤∇f (x2)
and hence
(x1 −x2)⊤∇f (x2) < 0,
which proves that f is pseudoconvex.
(ii) Let us prove ﬁrst that if f is pseudoconvex on X, then f is semistrictly
quasiconvex on X. Assume, on the contrary that f is not semistrictly quasiconvex.
Then, there exist x1, x2 ∈X, x1 ̸= x2, and ¯z ∈(x1, x2) such that
f (¯z) ≧f (x2) > f (x1).
(3.4)
By pseudoconvexity of f we have
(x1 −¯z)⊤∇f (¯z) < 0.
(3.5)
As ¯z ∈(x1, x2) one has ¯z = λx1 + (1 −λ)x2 for some λ ∈(0, 1), and so
x1 −¯z = x1 −λx1 −(1 −λ)x2 = (1 −λ)(x1 −x2).
Also, ¯z = x2 + λ(x1 −x2), i.e. x2 −¯z = −λ(x1 −x2). Therefore,
x1 −¯z = −(1 −λ)(x2 −¯z)/λ.
From here, using (3.5), we obtain
(x2 −¯z)⊤∇f (¯z) > 0.

70
3
Convex Functions and Generalized Convex Functions
As limt→0+ 
f

¯z + t(x2 −¯z)

−f (¯z)

/t = (x2 −¯z)⊤∇f (¯z) > 0, there exists
μ ∈(0, 1) such that ˆz = μ¯z + (1 −μ)x2 ∈(¯z, x2) and f (ˆz) > f (¯z), and so f (ˆz) >
f (¯z) ≧f (x2) by (3.4). Again by pseudoconvexity of f applied to the pairs (ˆz, x2)
and (ˆz, ¯z), we have
(x2 −ˆz)⊤∇f (ˆz) < 0 and (¯z −ˆz)⊤∇f (ˆz) < 0.
(3.6)
From ˆz = μ¯z + (1 −μ)x2, reasoning as above, we get ¯z −ˆz = −(1 −μ)(x2 −
ˆz)/μ, but this equality is incompatible with (3.6). Thus f is semistrictly quasi-
convex. Since a differentiable function is continuous, it follows, from Theorem 3.23,
that f is also a quasiconvex function.
□
The next result is due mainly to Crouzeix and Ferland [12].
Theorem 3.27 Let X ⊂Rn be an open convex set and let f : X →R be differentia-
bleandquasiconvexon X.Then f is pseudoconvexon X if andonlyif everystationary
point x0 of f, i.e. any point x0 ∈X with ∇f (x0) = 0, is a global minimum point of
f over X.
Corollary 3.28 Let X ⊂Rn be an open convex set and let f : X →R be differen-
tiable on X, with ∇f (x) ̸= 0, ∀x ∈X. Then f is pseudoconvex on X if and only if
f is quasiconvex on X.
The above inclusion relationships are all strict. For example,
• f (x) = |x| , x ∈R, is convex, but not strictly convex.
• f (x) =
x2
1+x2 , x ∈R, is pseudoconvex, but not convex. A more important exam-
ple of a pseudoconcave function which is not concave is the probability density
function of a standardized random variable with a normal (Gaussian) distribution:
f (x) =
1
√
2π
e−x2
2 .
• f (x) = x3, x ∈R, is semistrictly quasiconvex (and also quasiconvex), but not
pseudoconvex.
•
f (x) =
 0
if 0 ≦x ≦1
−(x −1)2 if 1 ≦x ≦2,
is quasiconvex, but not semistrictly quasiconvex.
There are also conditions (necessary or sufﬁcient, or both) for quasiconvexity and
pseudoconvexity of C 2-functions. We report only the following ones.
Theorem 3.29 The following equivalent conditions are necessary for the C 2-
function f : X ⊂Rn →R to be quasiconvex on the open convex set X.

3.2 Generalized Convex Functions
71
(a) x ∈X, y⊤∇f (x) = 0 ⇒y⊤∇2 f (x)y ≧0.
(b) x ∈X and the equation

∇2 f (x) −λI
∇f (x)
∇f (x)⊤
0
 = 0,
of degree (n −1) in λ, has nonnegative roots.
Theorem 3.30 ThefollowingequivalentconditionsaresufﬁcientfortheC 2-function
f : X ⊂Rn →R to be pseudoconvex on the open convex set X.
(i) x ∈X, y ̸= 0, y⊤∇f (x) = 0 ⇒y⊤∇2 f (x)y > 0.
(ii) The matrix

∇2 f (x) + λ∇f (x)∇f (x)⊤
is positive deﬁnite for λ sufﬁciently large, for all x ∈X.
The following results give the necessary and sufﬁcient conditions for the quasi-
convexity and pseudoconvexity of a C 2-function on the open convex set X ⊂Rn.
Theorem 3.31 Assume that f : X ⊂Rn →R is a C 2-function on the open convex
set X. Then:
(i)
f is pseudoconvex on X if and only if:
(a) x ∈X, y⊤∇f (x) = 0 ⇒y⊤∇2 f (x)y ≧0, and
(b) x ∈X, ∇f (x) = 0 ⇒f achieves its minimum at x.
(ii)
f is quasiconvex on X if and only if:
(a′) The previous condition (a) holds, and
(b′) x ∈X, ∇f (x) = 0 ⇒∀h ∈Rn the function ϕ(t) = f (x + th) is quasicon-
vex.
There are many other deﬁnitions of generalized convex functions, more or less
useful and meaningful. We mention only the preinvex functions and the invex func-
tions.
Deﬁnition 3.32 A function f : X ⊂Rn →R, X nonempty convex set, is said to
be preinvex on X, when there exists a vector-valued function η : X × X →X, such
that
f (x2 + λη(x1, x2)) ≦λf (x1) + (1 −λ) f (x2), ∀x1, x2 ∈X, ∀λ ∈[0, 1] .
It is immediate to note that convex functions are a particular case of preinvex
functions, when we make the substitution η(x1, x2) = x1 −x2. There are functions
that are preinvex, but not convex. For example, consider the function f : R →R
deﬁned by f (x) = −|x| . Then f is not convex, but is preinvex, with η given by
η(x, y) =
⎧
⎨
⎩
x −y if x ≦0, y ≦0,
x −y if x ≧0, y ≧0,
y −x otherwise.

72
3
Convex Functions and Generalized Convex Functions
Preinvex functions keep some interesting properties of convex functions: for
example, every local minimum point of a preinvex function is a global minimum
point and nonnegative linear combinations of preinvex functions are preinvex (for
this last property, referred to convex functions, see the next Theorem 3.34).
Deﬁnition 3.33 A function f : X ⊂Rn →R differentiable on the open convex set
X is said to be invex on X, if there exists a vector-valued function η : Rn × Rn →Rn
such that
f (x1) −f (x2) ≧(η(x1, x2))⊤∇f (x2), ∀x1, x2 ∈X.
Also here it is evident that differentiable convex functions are a particular case
of invex functions. These functions have been introduced by Hanson [13] and called
“invex” by Craven [14]. This term is a contraction of the terms “invariant” and
“convex”. Indeed, if we operate a certain transformation on a convex function, this
transformation will destroy convexity, but the “transformed” function will be surely
invex.
In the next chapter we shall see a nice characterization of the class of invex
functions. It is easy to prove that if a differentiable function is preinvex on the open
convex set X ⊂Rn, then it is invex on X. Indeed, if f : X →R is differentiable on
X and x1, x2 ∈X, from the deﬁnition of preinvex functions it follows
f (x2 + λη(x1, x2)) −f (x2)
λ
≦f (x1) −f (x2), ∀λ ∈(0, 1] .
Taking the limit for λ →0+ we obtain
f (x1) −f (x2) ≧(η(x1, x2))⊤∇f (x2).
It will appear in the next chapter that pseudoconvex functions are invex, but there
exist invex functions that are not pseudoconvex. Moreover, there exist invex functions
that are not quasiconvex and there exist quasiconvex functions that are not invex. See,
e.g. Mishra and Giorgi [15].
The criteria of positive deﬁniteness and positive semideﬁniteness of the Hessian
matrix are “operative” criteria for establishing strict convexity and convexity of a
function f : Rn →R of class C 2. These criteria, however, sometimes may be noisy
to apply. For example, the function
f (x, y, z) = ex2+y2+z2 + (x + y + 1) + 3z2
is convex on R3, by a simple application of the next theorem, but its Hessian is a
mess. Fortunately, there are other ways than the use of the Hessian matrix to show
that a function is convex. The following theorem shows that convex functions can
be combinated in a variety of ways to produce other convex functions.

3.2 Generalized Convex Functions
73
Theorem 3.34 (a) If f1, f2, . . . , fk are convex functions on a convex set S ⊂Rn,
then
f (x) = f1(x) + f2(x) + · · · + fk(x)
is convex on S. Moreover, if at least one fi is strictly convex on S, then the sum
f is strictly convex.
(b) If f is convex (resp. strictly convex) on a convex set S ⊂Rn, and α ∈R is a
positive scalar, then αf is convex (resp. strictly convex) on S. Therefore, the
linear combination, with positive coefﬁcients, of convex functions is a convex
function.
(c) If f is a convex function (resp. a strictly convex function) deﬁned on the convex
set S ⊂Rn, and if g is an increasing (resp. a strictly increasing) convex function
deﬁned on the range of f , then the composite function g ◦f is convex (resp.
strictly convex) on S.
Proof (a) To show that any ﬁnite sum of convex functions on S is convex on S, it
sufﬁces to show that the sum f1 + f2 of two convex functions on S is again convex
on S. If y, z ∈S and λ ∈[0, 1] , then
f1(λy + (1 −λ)z) + f2(λy + (1 −λ)z)
≦λf1(y) + (1 −λ) f1(z) + λf2(y) + (1 −λ) f2(z)
= λ( f1(y) + f2(y)) + (1 −λ)( f1(z) + f2(z)).
Hence, f1 + f2 is convex on S. Moreover, it is clear from this computation that if
either f1 or f2 is strictly convex, then f1 + f2 is strictly convex.
(b) This result follows by an argument similar to the one used in (a).
(c) If y, z ∈S and λ ∈[0, 1] , then
f (λy + (1 −λ)z) ≦λf (y) + (1 −λ) f (z),
since f is convex on S. Consequently, since g is an increasing, convex function on
the range of f (x), it follows that
g( f (λy + (1 −λ)z)) ≦g(λf (y) + (1 −λ) f (z)) ≦λg( f (y)) + (1 −λ)g( f (z)).
Thus, the composite function g ◦f is convex on S. If f is strictly convex and
g is strictly increasing, the ﬁrst inequality in the preceding computation is strict for
y ̸= z and λ ∈(0, 1), so g ◦f is strictly convex on S.
□
Example 3.35 The function
f (x1, x2, x3) = e(x1)2+(x2)2+(x3)2
is strictly convex on R3 (it follows from Theorem 3.34(c)).
The function

74
3
Convex Functions and Generalized Convex Functions
f (x) =
k
	
i=1
cie(ai)⊤x,
with a1, . . . , ak vectors of Rn and c1 > 0, . . . , ck > 0, is convex on Rn (it follows
from Theorem 3.34(b)).
It must be noted that, contrary to convex functions, the sum of quasiconvex func-
tions is not in general a quasiconvex function. For example, let be
f (x) = x3;
g(x) = −x, x ∈R,
which are both quasiconvex (and quasiconcave) functions, but their sum f (x) +
g(x) = x3 −x is not quasiconvex (nor quasiconcave). The same holds true for the
sum of pseudoconvex functions.
Therearealsoresultsconcerningthecompositionofgeneralizedconvexfunctions.
We quote only the following one.
Theorem 3.36 Let f be a quasiconvex (resp. a semistrictly quasiconvex) function on
the convex set S ⊂Rn and let g be an increasing (resp. strictly increasing) function
deﬁned on the range of f . Then the composite function g ◦f is quasiconvex (resp.
semistrictly quasiconvex) on S.
3.3
Optimality Properties of Convex and Generalized
Convex Functions. Nonlinear Theorems of the
Alternative
We postpone to the next chapter the optimality properties of convex and generalized
convex functions in the differentiable case. Here we give some general optimality
properties that hold also without differentiability assumptions. We denote by
X∗
f ≡arg min
x∈X
f (x)
the set of optimal (global) solutions of the problem min f (x), x ∈X ⊂Rn,
f : X →R.
Theorem 3.37 (a) Let f : X ⊂Rn →R be convex on the convex set X. Then, if
x0 ∈X is a local minimizer of f, then x0 is a global minimizer of f.
(b) If f : X ⊂Rn →R is strictly convex on the convex set X and if x0 ∈X is a
local minimizer of f, then x0 is the unique (strict) global minimizer of f.
Proof (a) Let y be any point of X. Consider ¯λ > 0 and sufﬁciently close to 1. Then
we have that (x0 is the local minimizer in question)

3.3 Optimality Properties of Convex and Generalized Convex …
75
¯λx0 + (1 −¯λ)y ∈X,
since X convex. Moreover, ¯λx0 + (1 −¯λ)y ∈U(x0), and being x0 a local minimizer
and using the convexity of f , we have
f (x0) ≦f (¯λx0 + (1 −¯λ)y) ≦¯λ f (x0) + (1 −¯λ) f (y).
From here,
(1 −¯λ) f (x0) ≦(1 −¯λ) f (y),
and as (1 −¯λ) > 0, we derive that
f (x0) ≦f (y).
But y is any point of X :, therefore, x0 is a global minimizer for f on X.
(b) Absurdly, let us suppose that there exist two distinct (global) minimizers x∗
and x∗∗. Being f strictly convex, we would have
f
 1
2 x∗+ 1
2 x∗∗
< 1
2 f (x∗) + 1
2 f (x∗∗) = f (x∗).
which is absurd, because ( 1
2 x∗+ 1
2 x∗∗) ∈X and by assumption x∗is a global mini-
mizer for f on X.
□
Theorem 3.38 If f : X ⊂Rn →R is convex on the convex set X, then the set
X∗
f ≡arg minx∈X f (x) is a convex set. If f is strictly convex on X, then X∗
f contains
at most one point.
Proof If X∗
f = ∅, then X∗
f is convex by deﬁnition. Let be X∗
f ̸= ∅and let be x1, x2 ∈
X two global minimizers for f on X :
f (x1) ≦f (x), ∀x ∈X;
f (x2) ≦f (x), ∀x ∈X.
We have to show that it holds
f (λx1 + (1 −λ)x2) ≦f (x), ∀x ∈X, ∀λ ∈[0, 1] .
Indeed, we have, for any x ∈X and for any λ ∈[0, 1] :
f (λx1 + (1 −λ)x2) ≦λf (x1) + (1 −λ) f (x2) ≦λf (x) + (1 −λ) f (x) = f (x).
The second assertion of the theorem is an assertion (b) of Theorem 3.37.
□
Under suitable assumptions, the previous results hold also for some generalized
convex functions.

76
3
Convex Functions and Generalized Convex Functions
Theorem 3.39 Let X ⊂Rn be a convex set, let f : X →R and let x0 ∈X be a
local minimum point of f on X. If f is semistrictly quasiconvex on X, then x0 is a
global minimum point of f on X.
Proof As x0 ∈X is a local minimum point of f (x), there exists ε > 0 such that
f (x0) ≦f (x), ∀x ∈X ∩Uε(x0). Let us suppose that there exists ¯x ∈X such that
f (¯x) < f (x0). From the semistrict quasiconvexity of f it follows
f (λ¯x + (1 −λ)x0) < f (x0)
for all λ ∈(0, 1) for which λ¯x + (1 −λ)x0 ∈X ∩Uε(x0). Now, if we choose λ ∈
(0, 1) smaller than ε/
¯x −x0 , it results easily that λ¯x + (1 −λ)x0 ∈X ∩Uε(x0),
which contradicts the assumption that x0 is a local minimum point of f on X.
Therefore, it results that f (x) ≧f (x0), ∀x ∈X, i.e. x0 is a global minimum point
of f on X.
□
Obviously, the thesis of the above theorem holds also under the assumption that
f is pseudoconvex on X. The thesis is no longer true under the assumption of
quasiconvexity of f. For example, the function f : R →R deﬁned by
f (x) =
⎧
⎨
⎩
x + 1 if x ≦−1,
0
if −1 < x < 1,
x −1 if x ≧1,
is quasiconvex and has at x0 = 0 a local minimum point which is not global.
However, if a quasiconvex function f : X ⊂Rn →R, X convex set, has a strict
local minimum point at x0, then the following result holds.
Theorem 3.40 Let f : X ⊂Rn →R be quasiconvex on the convex set X. If x0 ∈X
is a strict local minimum point of f on X, then x0 is also a strict global minimum
point of f on X.
Proof Suppose that x0 ∈X is a strict local minimum point of f on X, i.e. there
exists N(x0) such that
f (x0) < f (x), ∀x ∈N(x0) ∩X, x ̸= x0.
(3.7)
If x0 is not a strict global minimum point of f, then there exists ¯x ∈X, ¯x ̸= x0,
such that
f (¯x) ≦f (x0).
By the quasiconvexity of f, we have
f (λ¯x + (1 −λ)x0) ≦f (x0), ∀λ ∈[0, 1] .
But for sufﬁciently small λ it follows that x = λ¯x + (1 −λ)x0 ∈N(x0) ∩X,
contradicting (3.7).
□

3.3 Optimality Properties of Convex and Generalized Convex …
77
We may mention here that if a local minimum point x0 of a quasiconvex function
f is not a global minimum point, then f is constant on the intersection of some
neighborhood N(x0) and the line segment between x0 and any global minimum
point. See Ponstein [11].
Theorem 3.41 Let X ⊂Rn be a nonempty convex set and let f : X →R be quasi-
convex on X. The set X∗
f = arg min
x∈X
f (x) is a convex set.
Proof As we can write, with x0 any point of X∗
f ,
arg min
x∈X
f (x) =

x : x ∈X ⊂Rn, f(x) ≦f (x0)

the result is evident from one of the characterizations of quasiconvex functions (see
Theorem 3.19(d)).
□
It is known that a necessary and sufﬁcient condition for x0 to be a global minimum
point of a function f : Rn →R over a set S ⊂Rn, is that x0 is a global ray minimum
point of f over S. That is, for every vector y ∈Rn, x0 is a global minimum point on

x ∈Rn : x + λy, λ ≧0

∩S.
Similarly, a necessary condition that x0 be a local minimum point of f over S is
that x0 be a local ray minimum pointoverS, i.e. for every vector y ∈Rn there exists
λ0(y) such that
f (x0 + λy) ≧f (x0),
whenever 0 < λ < λ0(y) and x0 + λy ∈S.
We may say that a local minimum point over S is a local ray minimum point over
S. But a local ray minimum point need not be a local minimum point, as the following
example, due to G. Peano, shows. Consider the function f : R2 →R deﬁned by
f (x1, x2) = (x1 −(x2)2)(x1 −2(x2)2).
The point x0 = (0, 0) is a local ray minimum over the plane, but not a local
minimum point for f. However, for quasiconvex functions on the convex set S ⊂Rn,
the necessary conditions become sufﬁcient.
Theorem 3.42 If f : S ⊂Rn →R is quasiconvex on the convex set S, then any
local ray minimum point of f over S is a local minimum point of f over S.
See Thompson and Parke [16].
Nonlinear Theorems of the Alternative
Many theorems of the alternative for nonlinear systems are available in the mathema-
tical literature. These theorems usually hold under various convexity or generalized
convexity assumptions on the functions involved and some of them are formulated in
an inﬁnite-dimensional topological setting. We mention only the following theorems.

78
3
Convex Functions and Generalized Convex Functions
Theorem 3.43 Let X ⊂Rn be a nonempty convex set, f : X →Rm a vector-valued
convex function (i. e. each component fi, i = 1, . . . , m, is a convex function on X)
and g : X →Rk a linear afﬁne vector-valued function. If the system
x ∈X,
f (x) < 0, g(x) = 0
has no solution, then there exist vectors u ∈Rm
+ and v ∈Rk, with (u, v) ̸= 0, such
that
u⊤f (x) + v⊤g(x) ≧0, ∀x ∈X.
Proof The set of Rm+k
Y =

x∈X

(y, z) : y ∈Rm, z ∈Rk, y > f (x), z = g(x)

is a convex set and 0 /∈Y, as it is easy to verify. From the separation theorem it results
that there exist u ∈Rm and v ∈Rk, with (u, v) ̸= 0, such that
u⊤y + v⊤z ≧0, ∀(y, z) ∈Y.
Moreover, it must be u ≧0; indeed, if ui < 0 for some index i, then, by choosing
yi sufﬁciently large, we should contradict the above inequality. Therefore, for any
ε > 0 and any x ∈X, we have ( f (x) + εe, g(x)) ∈Y, where e = [1, 1, . . . , 1]⊤,
and hence
u⊤f (x) + v⊤g(x) + εu⊤e ≧0
or
u⊤f (x) + v⊤g(x) ≧−εu⊤e, ∀x ∈X.
It results
δ = inf
x∈X(u⊤f (x) + v⊤g(x)) ≧0.
Indeed, if inf
x∈X(u⊤f (x) + v⊤g(x)) = −δ < 0, we get, by picking ε such that
εu⊤e < δ, thet
inf
x∈X(u⊤f (x) + v⊤g(x)) = −δ < −εu⊤e,
which is a contradiction to the fact that u⊤f (x) + v⊤g(x) ≧−εu⊤e, ∀x ∈X. Hence
inf
x∈X(u⊤f (x) + v⊤g(x)) ≧0.
□
If we observe that for an m-dimensional vector function f, deﬁned on  ⊂Rn,
we have

3.3 Optimality Properties of Convex and Generalized Convex …
79
{ f (x) < 0 has a solution x ∈} ⇒

f (x) ≦0, f (x) ̸= 0, has a solution x ∈

⇒

f (x) ≦0 has a solution x ∈

and

f (x) ≦0 has no solution x ∈

⇒

f (x) ≦0, f (x) ̸= 0, has no solution x ∈

⇒{ f (x) < 0 has no solution x ∈}
then, the following corollary is a direct consequence of Theorem 3.43.
Corollary 3.44 Let X ⊂Rn be a nonempty convex set, let f1 : X →Rm1, f2 : X →
Rm2, f3 : X →Rm3, be vector-valued convex functions on X and g : X →Rk a
linear afﬁne vector-valued function. If the system
x ∈X, f1(x) < 0, f2(x) ≦0, f2(x) ̸= 0, f3(x) ≦0, g(x) = 0
has no solution, then there exist u1 ∈Rm1, u2 ∈Rm2, u3 ∈Rm3 and v ∈Rk such that
u1, u2, u3 ≧0, (u1, u2, u3, v) ̸= 0,
(u1)⊤f1(x) + (u2)⊤f2(x) + (u3)⊤f3(x) + v⊤g(x) ≧0, ∀x ∈X.
From the previous theorem, it is possible to obtain a generalization to the nonlinear
case of Gordan’s theorem of the alternative. The following result is due to Fan et al.
[17].
Theorem 3.45 Let X ⊂Rn be a nonempty convex set and let f : X →Rm be a
vector-valued convex function. Then, either
(a)
f (x) < 0 has a solution x ∈X,
or
(b) u⊤f (x) ≧0, ∀x ∈X, for some u ∈Rm
+, u ̸= 0,
but never both.
Proof If the system described sub (a) has a solution, obviously (b) cannot hold. If
(a) has no solution, then by Theorem 3.43 we have at once that (b) has a solution. □
Another useful theorem of the alternative for nonlinear systems is presented by
Berge and Ghouila-Houri [18]. See also Stoer and Witzgall [19].
Theorem 3.46 Let be given the convex functions f0(x), f1(x), . . . , f p(x) deﬁned
on Rn and the linear afﬁne functions h1(x), h2(x), . . . , hm(x), also deﬁned on Rn.
If the system
⎧
⎨
⎩
f0(x) < 0,
fk(x) ≦0, k = 1, . . . , p,
h j(x) ≦0,
j = 1, . . . , m,

80
3
Convex Functions and Generalized Convex Functions
admits no solution, but there exists x0 ∈Rn such that it holds (“Slater constraint
qualiﬁcation”)
 fk(x0) < 0, k = 1, . . . , p,
h j(x0) ≦0,
j = 1, . . . , m,
then there exist multipliers y1 ≧0, . . . , yp ≧0, u1 ≧0, . . . , um ≧0, such that
f0(x) +
p
	
k=1
yk fk(x) +
m
	
j=1
u jh j(x) ≧0, ∀x ∈Rn.
The theorem of Farkas is easily obtained from Theorem 3.46. It is immediate to
see that the following systems
(S1) :
Ax = b, x ≧0
and
(S2) :
A⊤u ≧0, b⊤u < 0
cannot admit both solutions. It remains to prove that if (S2) does not admit solu-
tion, then (S1) admits solution. Let us rewrite (S2) by putting f0(u) ≡b⊤u < 0 and
−A⊤u ≦0. From Theorem 3.46 there exists x ∈Rn
+ such that b⊤u −x⊤A⊤u =
u⊤(b −Ax) ≧0, for every u ∈Rm, and, therefore, we have b −Ax = 0, i.e. (S1)
admits solution.
Another general approach to nonlinear theorems of the alternative is due to Gian-
nessi [20]. The following result is a particular case of a more general theorem, proved
by the said author.
Theorem 3.47 Let be ϕ : Rn →R and g : Rn →Rm.
(i) Assume that ϕ and g be linear afﬁne. Then the following system
(S3) :
ϕ(x) > 0
g(x) ≧0
is impossible if and only if there exist θ ∈R and λ ∈Rm such that
(S∗
3) :
θϕ(x) + λ⊤g(x) ≦0, ∀x ∈Rn
θ ≧0, λ ≧0, (θ, λ) ̸= 0,
where the ﬁrst inequality of (S∗
3) must be veriﬁed in a strict sense if θ = 0.
(ii) Assume that ϕ and g are concave, and that there exists ˆx ∈R such that g(ˆx) > 0.
Then (S3) is impossible if there exists λ ∈Rm
+, such that
ϕ(x) + λ⊤g(x) ≦0, ∀x ∈Rn.

References
81
(iii) Assume that ϕ and g are concave. (S3) is impossible if and only if there exist
θ ∈R and λ ∈Rm such that
θϕ(x) + λ⊤g(x) ≦0, ∀x ∈Rn,
with θ ≧0, λ ≧0, (θ, λ) ̸= 0, and

x ∈Rn : ϕ(x) > 0, g(x) ≧0, λ⊤g(x) = 0

= ∅,
when θ = 0.
Also from Theorem 3.47 it is possible to get easily Farkas’ theorem. Let us rewrite
Farkas’ theorem in the form
(S1) ≡

Ax ≧0, a⊤x < 0

and
(S∗
1) ≡

z⊤A = a, z ≧0

.
Set ϕ(x) = −a⊤x and g(x) = Ax. Theorem 3.47 (point (i)) can be applied. At
θ = 0, (S∗
3) becomes λ ≧0, λ⊤Ax < 0, ∀x ∈Rn, which is obviously impossible.
At θ = 1, (S∗
3) becomes λ ≧0, −a⊤x + λ⊤Ax ≦0, ∀x ∈Rn, which holds if and
only if λ ≧0, −a⊤x + λ⊤Ax = 0, which is equivalent to (S∗
1).
References
1. R.T. Rockafellar, Convex Analysis (Princeton University Press, Princeton, 1970)
2. M.S. Bazaraa, C.M. Shetty, Foundations of Optimization, Lecture Notes in Economic and
Mathematics Systems, vol. 122 (Springer, Berlin, 1976)
3. M.S. Bazaraa, H.D. Sherali, C.M. Shetty, Nonlinear Programming. Theory and Algorithms,
3rd edn. (Wiley Interscience, New York, 2006)
4. W. Fenchel, Convex Cones, Sets and Functions, Lecture Notes (Princeton University, Princeton,
1953)
5. M. Delfour, Introduction to Optimization and Hadamard Semidifferential Calculus, 2nd edn.
(SIAM, Philadelphia, 2020)
6. A.W. Roberts, D.E. Varberg, Convex Functions (Academic, New York, 1973)
7. A. Ruszczynski, Nonlinear Optimization (Princeton University Press, Princeton, 2006)
8. D.P. Bertsekas, Convex Optimization Theory (Athena Scientiﬁc, Belmont, Mass, 2009)
9. A. Cambini, L. Martein, Generalized Convexity and Optimization. Theory and Applications
(Springer, Berlin, 2009)
10. N. Hadjisavvas, S. Komlosi, S. Schaible (eds.), Handbook of Generalized Convexity and Gene-
ralized Monotonicity (Springer, New York, 2005)
11. J. Ponstein, Seven kinds of convexity. SIAM Rev. 9, 115–119 (1967)
12. J.P. Crouzeix, J.A. Ferland, Criteria for quasi-convexity and pseudo-convexity: Relationships
and comparisons. Math. Program. 23, 193–205 (1982)
13. M.A. Hanson, On sufﬁciency of the Kuhn-Tucker conditions. J. Math. Anal. Appl. 80, 545–550
(1981)

82
3
Convex Functions and Generalized Convex Functions
14. B.D. Craven, Duality for generalized convex fractional programs, in Generalized Concavity in
Optimization and Economics, eds. by S. Schaible, W.T. Ziemba (Academic, New York, 1981),
pp. 473–489
15. S.K. Mishra, G. Giorgi, Invexity and Optimization (Springer, Berlin, 2008)
16. W.A. Thompson, D.W. Parke, Some properties of generalized concave functions. Oper. Res.
21, 305–313 (1973)
17. K. Fan, I. Glicksberg, A.J. Hoffman, Systems of inequalities involving convex functions. Proc.
Amer. Math. Soc. 8, 617–622 (1957)
18. C. Berge, A. Ghouila-Houri, Programming, Games and Transportation Networks (Wiley, New
York, 1965)
19. J. Stoer, C. Witzgall, Convexity and Optimization in Finite Dimensions, I (Springer, New York,
1971)
20. F. Giannessi, Constrained Optimization and Image Space Analysis. Vol. 1: Separation of Sets
and Optimality Conditions (Springer, New York, 2005)

Chapter 4
Unconstrained Optimization Problems.
Set-Constrained Optimization Problems.
Classical Constrained Optimization
Problems
4.1
Unconstrained Optimization Problems
In this section we shall treat problem (P1), i.e.
(P1) :
min f (x),
subject to x ∈S ⊂Rn,
where f : Rn →R and S is an open set (for example, S = Rn) or, more generally,
where for the optimal point x0 it holds x0 ∈int(S). In other words, we assume that the
optimal points of (P1) are interior to S. A ﬁrst basic result is given by the following
necessary optimality conditions.
Lemma 4.1 Let x0 ∈int(S) be a local minimizer for (P1) and let f admit its ith
partial derivative evaluated at x0; then it holds
∂f
∂xi
(x0) = 0.
Proof Being x0 a local minimizer for (P1), it holds f (x0) ≦f (x), ∀x ∈U(x0).
Obviously, this inequality holds, a fortiori, with respect to the ith component of x0:
f (x0 + tei) ≧f (x0),
for each t ∈N(0), where N(0) is a (uni-dimensional) neighborhood of t = 0 and ei
is the ith elementary vector of Rn, i.e. ei = [0, 0, . . . , 1, . . . , 0]⊤, with 1 as its ith
element. It follows that
f (x0 + tei) −f (x0)
t
≧0, for t > 0,
≦0, for t < 0.
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al., Basic Mathematical Programming Theory, International Series
in Operations Research & Management Science 344,
https://doi.org/10.1007/978-3-031-30324-1_4
83

84
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems …
By letting t →0, the ﬁrst member becomes ∂f
∂xi (x0), which exists by assumption,
and, therefore, ∂f
∂xi (x0) = 0.
□
As an immediate consequence, we have the following celebrated result, due to P.
Fermat.
Theorem 4.2 (Fermat Theorem) If x0 ∈int(S) is a local solution for problem (P1)
and if f admits the gradient ∇f (x0), then it holds
∇f (x0) = 0.
Remark 4.3 The points x0 ∈int(S) such that ∇f (x0) = 0 are usually called sta-
tionary points or critical points. Obviously, Theorem 4.2 holds also if x0 ∈int(S)
is a local maximizer for the objective function f. Therefore, all those points, which
are unconstrained local minimum points or maximum points, are stationary points
(if all partial derivatives exist at these points).
This condition is only a necessary condition; consider, e.g. the function f (x) =
x3, x ∈R. It results f ′(0) = 0, but the point x0 = 0 is not a minimizer, nor a maxi-
mizer for f ; as it is well-known, x0 is an inﬂection point.
We have, therefore, no information on the “nature” of stationary points; we have
an information on all points which are not stationary, i.e. such that ∇f (x0) ̸= 0: they
cannot be (local) unconstrained minimum nor maximum points for (P1).
The previous remark demands the introduction of further assumptions in order to
get some information on the nature of stationary points. We begin by introducing the
following second-order necessary optimality conditions for (P1).
Theorem 4.4 Let x0 ∈int(S) be a local minimum point for (P1) and let f : Rn →R
be twice-continuously differentiable on N(x0) ⊂S. Then, x0 is a stationary point
for f and moreover, ∇2 f (x0) is positive semideﬁnite.
Proof Being x0 a stationary point, we have for all vectors y ∈Rn and for all scalars
t > 0, sufﬁciently small,
0 ≦f (x0 + ty) −f (x0) = ∇f (x0)⊤(ty) + 1
2(ty)⊤∇2 f (x0)(ty) + o(∥ty∥2)
= 1
2t2y⊤∇2 f (x0)y + o(∥ty∥2).
Because this last expression cannot be negative, it follows that the Hessian matrix
∇2 f (x0) is positive semideﬁnite.
□
Obviously, if x0 ∈int(S) is an unconstrained local maximum point for (P1), it
will hold that ∇2 f (x0) is negative semideﬁnite.
Again, if we consider the function f (x) = x3, x ∈R, we see that f ′(0) = 0 and
f ′′(0) = 0, which conﬁrms that the conditions of Theorem 4.4 are only necessary
optimality conditions. We give now sufﬁcient second-order optimality conditions for
(P1).

4.1 Unconstrained Optimization Problems
85
Theorem 4.5 Let x0 ∈int(S)beastationarypointfor f ,let f betwice-continuously
differentiable on N(x0) ⊂S, and let ∇2 f (x0) be positive deﬁnite. Then x0 is a strict
local minimum point of f for (P1).
Proof As in the proof of the previous theorem, we start from the relation
f (x0 + ty) −f (x0) = ∇f (x0)⊤(ty) + 1
2(ty)⊤∇2 f (x0)(ty) + o(∥ty∥2) =
= 1
2t2y⊤∇2 f (x0)y + o(∥ty∥2).
For all y ∈Rn \ {0} and for all t > 0 sufﬁciently small, the ﬁrst addendum of the
last expression is positive. It follows that also f (x0 + ty) −f (x0) > 0 and hence
x0 is a strict local minimum point of f over S.
□
Obviously, if ∇f (x0) = 0 and ∇2 f (x0) is negative deﬁnite, x0 ∈int(S) is a strict
local maximum point of f over S. Note, moreover, that the conditions of Theorem 4.5
are only sufﬁcient optimality conditions; indeed, consider, e.g. the function f (x) =
x4, x ∈R. Here x0 = 0 is a minimum point of f (it is the unique strict minimum
point), but f ′′(x0) = 0. The same is true for the function, deﬁned on R2, f (x, y) =
x4 + y4, with respect to the point x0 = (0, 0)⊤.
Deﬁnition 4.6 Let x0 ∈int(S) and let be ∇f (x0) = 0. If, for every neighborhood
N(x0) of x0 there exist points x ∈S such that f (x) > f (x0) and points x ∈S such
that f (x) < f (x0), then x0 is called a saddle point of f on S. More generally, a
stationary point x0 ∈int(S) is a saddle point if it is neither a local minimum point
for f on S, nor a local maximum point.
On the grounds of what previously expounded, we have the following result.
Theorem 4.7 Let f be twice-continuously differentiable on U(x0) ⊂S and let be
∇f (x0) = 0. If ∇2 f (x0) is indeﬁnite, then x0 is a saddle point for f on S.
The origin of the name “saddle point” stems from the fact that in some cases the
form of the surface generated (in R3) by a function f : R2 →R in a neighborhood
of a saddle point, looks like a saddle for horses. It is the case, for example, of the
function
f (x, y) = x2 −y2.
Its unique stationary point is the origin of R2. Moreover,
∇2 f (x, y) =
 2
0
0 −2

.
If we consider the restriction y = 0 then f (x, 0) = x2 and we see that the origin of
R2 is a minimizer for this last function; if we consider the restriction x = 0, then

86
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems …
f (0, y) = −y2 and now we see that the origin of R2 is a maximizer for this function.
Therefore,
f (0, 0) = min
x∈R f (x, 0) = max
y∈R f (0, y).
Hence, (0, 0) is a saddle point for f.
However, Deﬁnition 4.6 contains also other cases for the occurrence of a saddle
point. We may have a saddle point also if at a stationary point of x0 ∈int(S) the
Hessian matrix ∇2 f (x0) is positive semideﬁnite (or negative semideﬁnite). Consider,
e.g. the function f : R2 →R deﬁned as
f (x, y) = x2 −y4.
The origin of R2 is a stationary point for f and we have
∇2 f (0, 0) =
 2 0
0 0

,
which is positive semideﬁnite.
However, f (x, 0) = x2 has at x0 = 0 a minimum point, whereas f (0, y) = −y4
has at y0 = 0 a maximum point. Hence (0, 0) is a saddle point for f.
Let us consider the function f : R2 →R given by
f (x, y) = x2 −y3.
The origin of R2 is a stationary point for f and we have
∇2 f (0, 0) =
 2 0
0 0

.
For every scalar m ∈R, the function f (x, mx) = x2 −m3x3 has at x0 = 0 a
minimum point, whereas the function f (0, y) = −y3 has at y0 = 0 an inﬂection
point. Hence, (0, 0) is not a minimum point nor a maximum point: it is a saddle
point.
Finally, we remark that this concept of saddle point must not be confused with
the concept of saddle point of the Lagrangian Function that will be introduced in
Chap. 8.
Remark 4.8 We have previously remarked, in Chap. 3, that if x0 ∈int(S) is a sta-
tionary point for f and is a local ray minimum point with respect to any direction
starting from x0, then x0 need not be a local minimum point for f. The following
example, due to G. Peano, conﬁrms the said assertion. The function
f (x, y) = (y −x2)(y −2x2)

4.1 Unconstrained Optimization Problems
87
has a stationary point at (0, 0), with f (0, 0) = 0. The origin is a local ray minimum
point over the plane, but not a local minimum point, as on every neighborhood of
(0, 0) there are points where f is positive and points where f is negative. Hence
(0, 0) is a saddle point.
Summing up:
Let x0 ∈int(S) be a stationary point for (P1) and let f be twice-continuously
differentiable on a neighborhood N(x0).
• If ∇2 f (x0) is positive (resp. negative) semideﬁnite, we cannot exclude that x0
is a local minimum point for (P1) (resp. a local maximum for a maximization
problem). The “semideﬁnite” case is, in a sense, an “indeterminate case” and
further investigations are needed to try to specify the “nature” of the stationary
point.
• If ∇2 f (x0) is positive deﬁnite (resp. negative deﬁnite) we can conclude that x0 is
a local strict minimizer for (P1) (resp. a local strict maximizer for a maximization
problem).
• If ∇2 f (x0) is indeﬁnite, we can exclude that x0 is a local minimizer or a local
maximizer for f. In this case x0 is a saddle point.
Remark 4.9 Under the assumption of Theorem 4.5, it is possible to obtain a more
precise and sharper result. See, e.g. Hestenes [1, 2]. Indeed, if at a point x0 ∈int(S),
we have
∇f (x0) = 0, h⊤∇2 f (x0)h > 0, ∀h ∈Rn, h ̸= 0,
then there exists a neighborhood N(x0) of x0 and a positive number m such that
f (x) ≧f (x0) + m
x −x02 , ∀x ∈N(x0).
In other words, x0 is a strict local minimizer of order 2 for (P1). See Sect. 1.3.
Furthermore, always under the assumptions of Theorem 4.5, it is possible to assert
that x0 is an isolated strict local minimizer for (P1) :
Theorem 4.10 Let f be a C 2-function and let x0 ∈int(S) satisfy the relation
∇f (x0) = 0; moreover, let ∇2 f (x0) be positive deﬁnite. Then x0 is a locally unique
critical point and thus an isolated strict local minimizer for (P1).
Proof Assume to the contrary that there is a sequence xk →x0, xk ̸= x0, of critical
points xk, i.e. ∇f (xk) = 0. Then by the Taylor expansion formula, we have
0 = ∇f (xk) −∇f (x0) = ∇2 f (x0)(xk −x0) + o(
xk −x0).
Dividing by
xk −x0 yields
0 = ∇2 f (x0) xk −x0
xk −x0 + o(1).

88
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems …
The bounded sequence
xk−x0
∥xk−x0∥has a convergent subsequence, we continue to
denote by the same notation, such that
xk −x0
xk −x0 →¯y, with ∥¯y∥= 1.
Taking the limit for k →∞in the above equality, we have
0 = ∇2 f (x0) ¯y
and thus
¯y⊤∇2 f (x0) ¯y = 0,
contradicting the positive deﬁniteness of ∇2 f (x0).
□
The function, already considered in Chap. 1,
f (x) =

2x2 + x2 sin 1
x if x ∈R, x ̸= 0,
0
if x = 0
has a strict (global) minimizer at x0 = 0, which, however, is not isolated. Indeed,
this function is not C 2 at x0 = 0 and Theorem 4.5 is, therefore, not applied.
We anticipate that the usual second-order sufﬁcient conditions for constrained
problems do not guarantee in general that the optimal point is isolated. See Example
6.45 and Theorem 6.46.
Example 4.11 Specify the type to which belong the stationary points of the function
f (x1, x2) = 3(x1)3 −x1 + (x2)3 −3(x2)2 −1.
We have
∂f
∂x1
= 9(x1)2 −1;
∂f
∂x2
= 3(x2)2 −6x2.
So, we have the system

(x1)2 = 1
9
3x2(x2 −2) = 0
which generates four stationary points:
A

−1
3, 0

; B
 1
3, 0

; C

−1
3, 2

; D
 1
3, 2

.
Then we have
∂2 f
∂x2
1
= 18x1;
∂2 f
∂x1∂x2
=
∂2 f
∂x2∂x1
= 0;
∂2 f
∂x2
2
= 6x2 −6,

4.1 Unconstrained Optimization Problems
89
∇2 f (x) =
 18x1
0
0
6x2 −6

.
(1)
∇2 f (−1
3, 0) =
−6
0
0
−6

.
This matrix is negative deﬁnite, hence, the point A is an unconstrained strict
local maximizer for f.
(2)
∇2 f ( 1
3, 0) =
 6
0
0 −6

.
This matrix is indeﬁnite; therefore, the point B is a saddle point for f.
(3)
∇2 f (−1
3, 2) =
−6 0
0
6

.
We have the same conclusions of the previous point 2): C is a saddle point
for f.
(4)
∇2 f ( 1
3, 2) =
 6 0
0 6

.
This matrix is positive deﬁnite; the point D is, therefore, an unconstrained strict
local minimizer for f.
Example 4.12 Let be
f (x, y) = x2 −αxy + y2, α ∈R.
The system ∇f (x, y) = 0 is given by

∂f
∂x = 2x −αy = 0
∂f
∂y = −αx + 2y = 0.
For α ̸= ±2 the unique solution is the origin of R2, which is, therefore, the unique
stationary point. Then we have
∇2 f (x, y) =
 2
−α
−α
2

= ∇2 f (0, 0).
This matrix is positive deﬁnite if 4 −α2 > 0, i.e. if |α| < 2; positive semideﬁnite
if α = ±2; indeﬁnite if |α| > 2.
If α = 2, the function becomes

90
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems …
f (x, y) = x2 −2xy + y2 = (x −y)2
which obviously has inﬁnite (global) minimizers on the straight line y = x.
If α = −2, the function becomes
f (x, y) = x2 + 2xy + y2 = (x + y)2
which obviously has inﬁnite (global) minimizers on the straight line y = −x.
Moreover:
If −2 < α < 2, the function has a strict minimizer at (0, 0). In fact, this point is
the unique global minimizer, as in this case the function is strictly convex.
If |α| > 2, the point (0, 0) is a saddle point.
Example 4.13 Let us consider the function f : R2 →R deﬁned by
f (x, y) = log(2x −y) + xy.
We note that the domain of f is an open subset of R2: dom( f ) = {(x, y) ∈R2 :
y < 2x}. Then we have
∂f
∂x =
2
2x −y + y; ∂f
∂y = −
1
2x −y + x.
Hence
∂f
∂y = 0 ⇒x =
1
2x −y .
By substituting this relation into ∂f
∂x we get
∂f
∂x = 2x + y
and, therefore, ∂f
∂x = 0 for y = −2x.
Then, for x =
1
2x−y we have
1
4x = x and so ∂f
∂x = 0 for 1 −4x2 = 0, i.e. for
x = ± 1
2. Therefore, ∂f
∂y = 0 for y = ∓1.
We have only one stationary point A( 1
2, −1), as B(−1
2, 1) does not belong to
dom( f ).
Then we have
∂2 f
∂x2 = −
4
(2x −y)2 ;
∂2 f
∂y2 = −
1
(2x −y)2 ;
∂2 f
∂x∂y = ∂2 f
∂y∂x =
2
(2x −y)2 + 1.
∇2 f (A) =
−1
3
2
3
2
−1
4

.

4.1 Unconstrained Optimization Problems
91
Being
		∇2 f (A)
		 = −2 < 0, we conclude that A( 1
2, −1) is a saddle point for f.
Example 4.14 (a) Find the unconstrained minimizers, maximizers, and saddle
point (if any) of
f (x, y) = x(y −x)2.
We have
∂f
∂x = (y −x)2 −2x(y −x) = (y −x)(y −3x);
∂f
∂y = 2x(y −x).
Hence all stationary points are all those points on the straight line y = x.
∂2 f
∂x2 = 6x −4y; ∂2 f
∂y2 = 2x;
∂2 f
∂x∂y = ∂2 f
∂y∂x = 2y −4x.
∇2 f (x, y) =
 6x −4y 2y −4x
2y −4x
2x

.
∇2 f (x, x) =
 2x −2x
−2x 2x

.
The Hessian matrix ∇2 f (x, x) is, therefore, positive semideﬁnite for x > 0, neg-
ative semideﬁnite for x < 0 and both positive and negative semideﬁnite for x = 0
(in this last case ∇2 f (x, x) = the zero matrix).
We compute the difference between the values of the function and the values of
the function on its stationary points:
f = f (x, y) −f (x, x) = f (x, y) = x(y −x)2.
Therefore,
(1) For x > 0 all stationary points are local minimizers.
(2) For x < 0 all stationary points are local maximizers.
(3) At x = (0, 0) there is a saddle point.
(b) Find the unconstrained minimizers, maximizers, and saddle point (if any) of
f (x, y) = y2(y2 + x2 −2x).
We have
∂f
∂x = 2y2(x −1); ∂f
∂y = 2y(2y2 + x2 −2x).
In consequence, the following are stationary points:
A(1,

1/2); B(1, −

1/2); C(k, 0), k ∈R.

92
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems …
The Hessian matrix is
∇2 f (x, y) =

2y2
4y(x −1)
4y(x −1)
12y2 + 2x2 −4x

.
Hence
∇2 f (A) = ∇2 f (B) =
 1 0
0 4

.
Therefore, A and B are local minimum points. For the point C we have
∇2 f (C) =
0
0
0
2k2 −4k

.
This matrix is semideﬁnite. We have
f = y2(y2 + x2 −2x) −f (C) = f (x, y).
The sign of this difference depends, therefore, from the sign of g(x, y) = y2 +
x2 −2x. As g(x, y) = 0 represents a circumference centered at P(1, 0) and with
radius r = 1, we conclude:
C(k, 0), for k < 0 are all minimum points;
C(k, 0), for 0 < k < 2 are all maximum points;
C(k, 0), for k > 2 are all minimum points;
C(0, 0) is a saddle point;
C(2, 0) is a saddle point.
The results of Theorem 4.5 give sufﬁcient conditions for (unconstrained) local
optimality related to problem (P1). If we wish to obtain global solutions for (P1) we
have to make reference to some convexity (or generalized convexity) assumptions on
f. If f : Rn →R is convex on the convex set S ⊂Rn, we have seen in the previous
chapter that:
• Every local minimizer of f (if existing) is also a global minimizer (Theorem 3.37).
• The set of all minimizers of f (necessarily global minimizers) form a convex set
(Theorem 3.38).
We now add a differentiability assumption on f. The following result is an immediate
consequence of deﬁnitions and properties seen in the previous chapter.
Theorem 4.15 Let f in (P1) be differentiable on the open convex set S ⊂Rn.
(i) Let f be convex on S; then the point x0 ∈S is a global minimum point for (P1)
if and only if ∇f (x0) = 0.
(ii) Let f bestrictlyconvexon S;thepoint x0 ∈S is theuniquestrict global minimum
point for (P1) if and only if ∇f (x0) = 0.
(iii) Let f be pseudoconvex on S; the point x0 ∈S is a global minimum point for
(P1) if and only if ∇f (x0) = 0.

4.1 Unconstrained Optimization Problems
93
Example 4.16 Let us consider the function
f (x, y) = (x −y)2 + 3(x −y).
We have
∂f
∂x = 2(x −y) + 3; ∂f
∂y = −2(x −y) −3.
The stationary points of f are all points that belong to the straight line y = x + 3
2.
Then we have
∂2 f
∂x2 = 2; ∂2 f
∂y2 = 2;
∂2 f
∂x∂y = ∂2 f
∂y∂x = −2.
∇2 f (x, y) =
 2
−2
−2
2

,
The elements of the Hessian matrix are constant quantities, hence ∇2 f (x, y) is
positive semideﬁnite on the whole R2. This means that f is a convex function on
R2: all its stationary points y = x + 3
2 are global minimizers for f .
Let us observe that f = g ◦ℓ, where ℓ(x, y) = x −y is linear and g(x) = x2 +
3x has a global minimizer at x0 = −3
2 .
Example 4.17 Let us consider the function
f (x1, x2, x3) = −(x1)2 −2(x2)2 −3(x3)2 + 1
2 x1x2 −1
2 x2x3.
It results that the unique stationary point is the zero vector x∗= [0, 0, 0]⊤. The
Hessian matrix is
∇2 f (x) =
⎡
⎣
−2
1
2
0
1
2
−4
−1
2
0
−1
2
−6
⎤
⎦.
Also here ∇2 f (x) is made of numbers, i.e. of constant quantities. Its leading
principal minors are
1 = −2;
2 = 31
4 ; 3 = det(∇2 f (x)) = −46.
Therefore, ∇2 f (x) is negative deﬁnite on R3. This means that f is a strictly
concave function. Therefore, x∗= [0, 0, 0]⊤is the unique strict global maximizer
for f.
Example 4.18 Let us consider the quadratic function
F(x) = x⊤Ax + 2a⊤x + α

94
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems …
with A square symmetric matrix of order n. We have that stationary points are given
by the solutions (if they exist) of the linear system
∇F(x) = 2Ax + 2a = 0.
(1) If A is non-singular, there is a unique stationary point given by x0 = −A−1a.
Being ∇2F(x) = 2A, we conclude that:
• If A is positive deﬁnite, then x0 is the unique strict global minimizer for F.
• If A is negative deﬁnite, then x0 is the unique strict global maximizer for F.
• If A is indeﬁnite, then x0 is a saddle point for F.
(2) If A is singular, then F admits stationarypoints if andonlyif rk(A) = rk(A; −a).
Let us suppose that this condition is veriﬁed. Then, we can conclude that:
• If A is indeﬁnite, all stationary points are saddle points.
• If A is positive semideﬁnite, then F is a convex function and hence all its
stationary points are global minimizers.
• If A is negative semideﬁnite, then F is a concave function and hence all its
stationary points are global maximizers.
Example 4.19 (The least-squares method) Let be given n pairs of data (xi, yi),
i = 1, . . . , n, where xi and yi are mutually interconnected (for example, xi is the
price of the ith good and yi is the related demand, in a competitive market). The
problem is to ﬁnd a curve (“curve ﬁtting problem”), for example a straight line
of equation y = ax + b, which ﬁts “at best” the distribution of the points (xi, yi),
i = 1, . . . , n, in the plane. When a straight line is chosen, we speak of “linear least-
squares problem” ; this problem is a widely used statistical tool: the method is used
to ﬁt data to a function that is linear in the model parameters to be estimated.
In our problem we have to ﬁnd the coefﬁcients a and b of the equation y = ax + b,
in such a way that the corresponding line is “as much as possible close” to the given
n pairs. In the least-squares method it is chosen as a measure of the said distance the
smallest possible sum of squares of deviations of the observed data yi from the value
y of the said equation, in correspondence with xi:
n

i=1
[(axi + b) −yi]2 .
Inother words, wearelookingfor thosevalues ofa, b whichminimizethefunction
F(a, b) =
n

i=1
[(axi + b) −yi]2 .
We have

4.1 Unconstrained Optimization Problems
95
∂F
∂a = 2
n

i=1
(axi + b −yi)xi; ∂F
∂b = 2
n

i=1
(axi + b −yi).
We have that ∇a,bF(a, b) = 0 when it holds
a n
i=1(xi)2 + b n
i=1 xi = n
i=1 xi yi
a n
i=1 xi + bn = n
i=1 yi.
The determinant of the coefﬁcient matrix of the last system is
 = n
n

i=1
(xi)2 −
 n

i=1
xi
2
,
i.e.
 = n2
n
i=1(xi)2
n
−
n
i=1 xi
n
2
,
i.e.
 = n2 
M(X2) −[M(X)]2
= n2σ 2(X),
where M(X) is the mean value of the random variable X, which assumes the distinct
values x1, . . . , xn, all with the same probability 1
n , X2 is the square of the said random
variable and σ 2(X) is the variance of X.
If the values x1, . . . , xn are not all the same, it will be  > 0. Then, the above
system admits one solution:
a∗=
n
i=1 xi yi −(n
i=1 yi)M(X)
nσ 2(X)
;
b∗= (n
i=1 yi)M(X2) −(n
i=1 xi yi)M(X)
nσ 2(X)
.
Being
∇2F(a, b) = 2
⎡
⎢⎢⎣
n
i=1
(xi)2
n
i=1
xi
n
i=1
xi
n
⎤
⎥⎥⎦,
it results that ∇2F(a, b) is everywhere positive deﬁnite, hence (a∗, b∗) is the global
strict minimizer of F(a, b).
We have introduced in Chap. 3 the notion of invex functions (see Deﬁnition
3.33). A differentiable function f : Rn →R is invex if there exists a vector function
η(x, y) ∈Rn such that

96
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems …
f (y) −f (x) ≧η(x, y)⊤∇f (x), for all x, y ∈Rn.
(4.1)
Clearly, differentiable convex functions satisfy (4.1), with η(x, y) = y −x. It
may exist more than one η which satisﬁes (4.1) for a given function f. The class of
invex functions has a nice characterization, given in the following result (see, e.g.
Ben-Israel and Mond [3], and Craven and Glover [4]).
Theorem 4.20 The differentiable function f : Rn →R is invex if and only if every
stationary point is a global minimum point.
Proof Clearly, if f is invex, then ∇f (x) = 0 implies f (y) ≧f (x), ∀y.
Assume now that
∇f (x) = 0 ⇒[ f (y) ≧f (x), ∀y ∈Rn].
If ∇f (x) = 0, take η(x, y) = 0. If ∇f (x) ̸= 0, take
η(x, y) = [ f (y) −f (x)]
∇f (x)⊤∇f (x)∇f (x).
□
As a consequence, if f has no stationary points, then f is invex. Although pseudo-
convex functions are invex, this is not the case for quasiconvex functions. The class
of invex functions and the class of (differentiable) quasiconvex functions have only
a partial overlapping. For example, f (x) = x3, x ∈R, is quasiconvex but not invex,
since its stationary point x = 0 is not a global minimum point for f. The function
f (x1, x2) = (x1)3 + x1 −10(x2)3 −x2, (x1, x2) ∈R2,
is invex, since it has no stationary points, but it is not quasiconvex. Take x = (0, 0),
y1 = 2, y2 = 1. we have f (y) −f (x) < 0 but (y −x)⊤∇f (x) > 0, so f is not
quasiconvex.
4.2
Set-Constrained Optimization Problems
In this section we take into consideration problem (P2), i.e.
(P2) :
min f (x), x ∈S ⊂Rn,
where f : Rn →R and S is not necessarily open (for example, S is a closed set) or,
more generally, the optimal point x0 ∈S is not necessarily interior to S. The set S is
also called a set constraint for (P2) or an abstract constraint. The function f is the
objective function of (P2). This problem may, therefore, be considered a ﬁrst type of

4.2 Set-Constrained Optimization Problems
97
constrained optimization problem and hence the optimality results of the previous
section are no longer valid for the present case. A ﬁrst easy necessary optimality
condition for (P2) is given in the following result.
Theorem 4.21 Let f : Rn →R be differentiable on an open set A ⊂Rn containing
the set S and let x0 ∈S be a local minimum point of f on S (i.e. for problem (P2)).
Then
∇f (x0)⊤y ≧0, ∀y ∈F(S, x0),
(4.2)
where F(S, x0) is the cone of feasible directions of S at x0 (see Deﬁnition 2.44). If
x0 is a local maximum point of f over S, then
∇f (x0)⊤y ≦0, ∀y ∈F(S, x0).
Proof Being y a feasible direction, there will exist ¯α > 0 such that x0 + αy ∈S,
∀α ∈[0, ¯α] . Since f is differentiable on A, it will hold
f (x0 + αy) −f (x0) = α∇f (x0)⊤y + o(∥αy∥).
If, absurdly, we have ∇f (x0)⊤y < 0, for α > 0 and sufﬁciently small, it would
hold
α∇f (x0)⊤y + o(∥αy∥) < 0.
and hence f (x0 + αy) < f (x0), contrary to the assumptions.
□
Relation (4.2) can be rewritten in the form
−∇f (x0) ∈(F(S, x0))∗.
Moreover, note that if x0 ∈int(S), Theorem 4.21 recovers the Fermat theorem
(Theorem 4.2), since in this case any direction y ∈Rn is feasible (i.e. F(S, x0) = Rn)
and hence, for all y ∈Rn, we have
∇f (x0)⊤y ≧0 and ∇f (x0)⊤(−y) ≧0,
which implies that ∇f (x0) = 0.
Example 4.22 Let us consider the function f : R2 →R given by
f (x) = (x1)2 −x1 + x2 + x1x2
and let be S = R2
+, i.e. S =

(x1, x2) ∈R2 : x1 ≧0, x2 ≧0

.
The minimum point of f on S is x0 =
 1
2, 0
⊤. Hence x0 /∈int(S). Let us note
that
∂f
∂x1
= 2x1 −1 + x2;
∂f
∂x2
= 1 + x1.

98
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems …
Therefore, ∇f (x0)⊤=

0, 3
2

̸= 0, which shows that the Fermat rule is not valid
in the present case. The cone of feasible directions of S at x0 is given by the vector
[y1, y2]⊤, y1 ∈R, y2 ≧0. We have

0, 3
2
  y1
y2

= 3
2 y2 ≧0, ∀y2 ≧0.
There exist also second-order necessary optimality conditions related to
Theorem 4.21.
Theorem 4.23 Let f : Rn →R be C 2 on the open set A ⊂Rn containing the set
S and let x0 ∈S be a local minimum point for (P2). Then, for all y ∈F(S, x0) it
holds:
(i) ∇f (x0)⊤y ≧0;
(ii) If ∇f (x0)⊤y = 0, then y⊤∇2 f (x0)y ≧0.
Proof Relation (i) is nothing but Theorem 4.21. Being f a C 2-function, we have
f (x0 + αy) = f (x0) + α∇f (x0)⊤y + 1
2α2y⊤∇2 f (x0)y + o(∥αy∥2).
If ∇f (x0)⊤y = 0, it will hold
f (x0 + αy) −f (x0) = 1
2α2y⊤∇2 f (x0)y + o(∥αy∥2).
If y⊤∇2 f (x0)y < 0, for α sufﬁciently small it will hold
α2y⊤∇2 f (x0)y + o(∥αy∥2) < 0
and hence also f (x0 + αy) < f (x0), contrary to the assumptions.
The last part of the theorem is obvious.
□
If we consider again Example 4.22, we see that
∇f (x0)⊤y = 3
2 y2 = 0 for y2 = 0,
and
∇2 f (x0) =
 2 1
1 0

.
Therefore,
y⊤∇2 f (x0)y = [y1, 0]
2 1
1 0
  y1
0

= 2(y1)2 ≧0.

4.2 Set-Constrained Optimization Problems
99
The difﬁculty related to Theorem 4.21 is that its necessary condition may be
vacuous because there may be no feasible directions, other than zero, and hence
Theorem 4.21 has in this case no content. Consider, e.g. the set
S =

(x1, x2) ∈R2 : (x1)2 + (x2)2 −1 = 0

.
Then, the only feasible direction at any point of S is just the zero vector. Hence,
regardless of the objective function f and the point x0 ∈S, we have that (4.2) is
satisﬁed. It is, therefore, convenient to introduce a necessary optimality condition
for (P2) sharper than the one of Theorem 4.21.
Theorem 4.24 Let f : Rn →R be differentiable on the open set A ⊂Rn containing
the set S and let x0 ∈S be a local minimum point of f on S. Then it holds
∇f (x0)⊤y ≧0, ∀y ∈T (S, x0),
(4.3)
where T (S, x0) is the Bouligand tangent cone to S at x0 (see Deﬁnition 2.35).
Proof Let be y ̸= 0 any direction of T (S, x0) and without loss of generality, let us
suppose ∥y∥= 1. There will exist, therefore, a feasible sequence

xk
⊂S, with
xk
y→x0. As the quotients
f (xk) −f (x0)
xk −x0
= ∇f (x0)⊤(xk −x0) + o(
xk −x0)
xk −x0)

,
for k sufﬁciently large, are nonnegative, being x0 a local minimum point for (P2),
and converge to ∇f (x0)⊤y, the thesis is proved.
□
We note that (4.3) can be rewritten in the form
−∇f (x0) ∈(T (S, x0))∗.
Guignard [5] obtained the relation
−∇f (x0) ∈(P(S, x0))∗,
where P(S, x0) = cl(conv(T (S, x0))). However, this condition is equivalent to (4.3),
as, for any cone C ⊂Rn we have C∗= cl(conv(C))∗.
If S ⊂Rn in problem (P2) is a convex set, then it holds
(T (S, x0))∗= N(S, x0),
where N(S, x0) is the normal cone to S at x0 (see Deﬁnition 2.42) and hence we can
write
−∇f (x0) ∈N(S, x0),

100
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems …
relation that some authors write as
0 ∈∇f (x0) + N(S, x0)
or also as
∇f (x0)⊤(x −x0) ≧0, ∀x ∈S.
(4.4)
Now, if f is pseudoconvex on the convex set S (i.e. x, x0 ∈S, ∇f (x0)⊤(x −
x0) ⇒f (x) −f (x0) ≧0), then (4.4) is a necessary and sufﬁcient condition for
x0 ∈S to be a global minimum point for f on S.
We have also ﬁrst-order sufﬁcient local optimality conditions for (P2) :
Theorem 4.25 Let us consider a point x0 ∈S in problem (P2). If
∇f (x0)⊤y > 0, ∀y ∈T (S, x0) \ {0} ,
(4.5)
then x0 is a strict local minimum point for (P2).
Proof We suppose absurdly that x0 ∈S is not a strict local minimizer of f on S.
Then there exists for every index k ∈N a point xk ∈S ∩U 1
k (x0), with xk ̸= x0
and f (xk) ≦f (x0). The feasible sequence

xk
converges to x0 and contains a
tangentially convergent subsequence (see Deﬁnition 2.34). Without loss of generality
we can denote by

xk
this last subsequence for which we have xk
y→x0. We have,
therefore, y ∈T (S, x0) \ {0} , but the quotients
f (xk) −f (x0)
xk −x0
= ∇f (x0)⊤(xk −x0) + o(
xk −x0)
xk −x0)

converge to ∇f (x0)⊤y ≦0, contrary to the assumptions.
□
We note that for the validity of relation (4.5), the cone T (S, x0) must contain no
straight line, i.e. it must be a so-called “pointed cone”.
Moreover (see Hestenes [1, 2]), it can be proved that (4.5) gives a stronger result:
if (4.5) is satisﬁed, then there exist a neighborhood N(x0) and a positive number m
such that
f (x) ≧f (x0) + m
x −x0 , ∀x ∈S ∩N(x0).
In other words, x0 is a strong local minimizer or sharp local minimizer for (P2).
There are also second-order optimality conditions for (P2), related to Theorems
4.24 and 4.25.
Theorem 4.26 Let in (P2) the objective function f be twice-continuously differen-
tiable on an open set A ⊂Rn containing S and let x0 ∈S be a local minimum point
for f on S. If ∇f (x0) = 0, then
y⊤∇2 f (x0)y ≧0, ∀y ∈T (S, x0).

4.2 Set-Constrained Optimization Problems
101
Proof Let be y ̸= 0 any vector of T (S, x0). Without loss of generality we assume
∥y∥= 1. There will exist a feasible sequence

xk
⊂S with xk
y→x0. On the
grounds of the assumptions the quotients
f (xk) −f (x0)
xk −x02
=
1
2(xk −x0)⊤∇2 f (x0)(xk −x0) + o(
xk −x02)
xk −x0)
2
for sufﬁciently large k ∈N are nonnegative and converge to 1
2 y⊤∇2 f (x0)y.
□
Theorem 4.27 Let be given problem (P2), with f twice-continuously differentiable
on the open set A ⊂Rn containing S. If, for x0 ∈S it holds ∇f (x0) = 0 and
y⊤∇2 f (x0)y > 0, ∀y ∈T (S, x0) \ {0} ,
then x0 is a strict local minimum point for f on S.
Proof The proof is indirect; let us assume that x0 is not a strict local minimum for f
on S. Then there will exist for each index k ∈N a point xk ∈S ∩U 1
k (x0), with xk ̸=
x0 and f (xk) ≦f (x0). The feasible sequence

xk
converges to x0 and contains a
tangentially convergent subsequence, we shall denote again by

xk
: xk
y→x0. It
holds y ∈T (S, x0) \ {0} , but the quotients
f (xk) −f (x0)
xk −x02
=
1
2(xk −x0)⊤∇2 f (x0)(xk −x0) + o(
xk −x02)
xk −x0)
2
converge to 1
2 y⊤∇2 f (x0)y ≦0, contrary to the assumptions.
□
Remark 4.28 Following Hestenes [2], the thesis of Theorem 4.27 can be reformu-
lated in the following way: there exists a neighborhood N(x0) and a constant m > 0
such that
f (x) ≧f (x0) + m
x −x02 , ∀x ∈N(x0) ∩S.
Moreover, if the set S is a polyhedral convex set, then Theorems 4.26 and 4.27
can be reformulated in the following more general results:
(1) (Necessity). If x0 ∈S is a local minimum point for (P2), then ∇f (x0)⊤y ≧0
for all y ∈T (S, x0) and
y⊤∇2 f (x0)y ≧0
for all y ∈T (S, x0) such that ∇f (x0)⊤y = 0.
(2) (Sufﬁciency). If x0 ∈S is such that ∇f (x0)⊤y ≧0 for all y ∈T (S, x0) and
y⊤∇2 f (x0)y > 0

102
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems …
for all y ∈T (S, x0) \ {0} such that ∇f (x0)⊤y = 0, then there exist N(x0) and
m > 0 such that
f (x) ≧f (x0) + m
x −x02 , ∀x ∈N(x0) ∩S.
We point out ﬁnally that Hestenes [2] has further generalized Theorems 11 and
12 by means of the lower supporting functions for f at x0 ∈S as follows.
A function F : Rn →R having the same differentiability properties of f at x0
and satisfying the relations
F(x) ≦f (x) on S, F(x0) = f (x0), ∇F(x0) = 0
is called a lower support function for f at x0. Hestenes [2] proves the following
result.
• Let x0 ∈S and suppose that there exists y ∈T (S, x0), y ̸= 0, such that
∇f (x0)⊤y = 0.
(4.6)
Suppose further that for each vector y ̸= 0, y ∈T (S, x0) satisfying relation (4.6),
there is a lower support function F such that
y⊤∇2F(x0)y > 0.
Then there are a neighborhood N(x0) and a constant m > 0 such that
f (x) ≧f (x0) + m
x −x02 , ∀x ∈N(x0) ∩S.
Note that in the previous result it is not required that F to be the same for every
y ̸= 0, y ∈T (S, x0), satisfying relation (4.6).
4.3
Optimization Problems with Equality Constraints
(“Classical Constrained Optimization Problems”)
In the present section we shall treat the so-called “classical” constrained optimization
problems, i.e. optimization problems with only equality constraints. We consider,
therefore, problem (P3):
(P3) :
⎧
⎨
⎩
min f (x)
subject to: h j(x) = 0,
j = 1, . . . , p < n,
x ∈X ⊂Rn,

4.3 Optimization Problems with Equality Constraints …
103
where X ⊂Rn is an open set contained in the domains of the functions involved
in (P3), f : X →R is differentiable on X and every h j : X →R, j = 1, . . . , p, is
continuously differentiable on X. The feasible set of (P3) is denoted by
K3 =

x ∈X : h j(x) = 0,
j = 1, . . . , p < n

,
where h j, j = 1, . . . , p, are the constraints or constraint functions of the problem
( f is the objective function).
The restriction p < n is imposed in order to avoid that the feasible set shrinks
to only isolated points or to the empty set. We have called (P3) a “classical” con-
strained optimization problem, as it was treated by J. L. Lagrange since 1759 (J. L.
Lagrange: “Recherches sur la méthode de maximis et minimis”, Miscellanea Tau-
rinensia, 1759, t. 1, 18–32. Reprinted in Giorgi and Kjeldsen [6]). Subsequently
Lagrange reconsidered his method (within a more general class of problems, called
Calculus of Variations) in his famous book “Mécanique Analytique” (Paris, 1788.
Complete Edition, joining the notes of the 3rd Edition, revised, corrected, and anno-
tated by Joseph Bertrand, and those of the 4th Edition published under the direction of
Gaston Darboux, Albert Blanchard, Paris, 1965). This method, now called Lagrange
Multipliers Rule, is one of the main cornerstones of optimization theory and is the
basis of the modern developments of mathematical programming theory.
In rough words, the method of Lagrange converts the constrained problem (P3)
into an unconstrained one, by means of a suitable function, called “Lagrangian func-
tion” and then it uses the rules of unconstrained optimization problems to compute
the solutions of problem (P3). For some historical considerations see, e.g. Prekopa
[9], Bussotti [7], and Giorgi and Kjeldsen [6].
When in (P3) we have n = 2 and p = 1 (one constraint and two variables) it can be
sometimes useful the so-called “explicitation method”, i.e. to express one variable as
a function of the other one, in the constraint, and then to make the substitution into the
objective function. The problem becomes, therefore, an unconstrained optimization
problem. It must be paid attention to the fact that the domain of the new objective
function may change, owing to the “introduction” of the constraint functions. We
illustrate it with a couple of examples.
Example 4.29 Find the extremum values of
f (x1, x2) = x1x2
on the feasible set
K3 =

(x1, x2) ∈R2 : 2x1 + x2 −1 = 0

.
We have, from the constraint,
x2 = 1 −2x1.

104
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems …
Therefore, the objective function becomes
g(x1) ≡g(x) = x −2x2.
We have g′(x) = 1 −4x, from which we deduce that x0 = 1
4 is the global max-
imizer of g and hence, being x2 = 1 −2x, we have x2 = 1
2. Therefore, P( 1
4, 1
2) is
the global maximum point of f on K3.
Example 4.30 Find the extremum values of
f (x, y, z) = −x + x2 + y2 + y(z + x −1)
on the feasible set
K3 =

(x, y, z) ∈R3 : x2 + y2 = 1; x + y + z = 1

.
From the ﬁrst constraint we have y2 = 1 −x2, from which x ∈[−1, 1]. From the
second constraint we have z = 1 −x −y. Then f takes the form
g(x) = −x + x2 + 1 −x2 −1 + x2 = x2 −x,
with x ∈[−1, 1] ; g′(x) = 2x −1.
We have, therefore, four points to consider:
P1 = (−1, 0, 2); f (P1) = 2.
P2 =

1
2,
√
3
2 , 1−
√
3
2
 
; P3 =

1
2, −
√
3
2 , 1+
√
3
2
 
; f (P2) = f (P3) = −1
4.
P4 = (1, 0, 0); f (P4) = 0.
Hence P1 is the constrained global maximum point, P2 and P3 are the constrained
global minimum points and P4 is a local constrained maximum point.
Always for the case n = 2, p = 1, it may be useful also the geometrical method
which is based on the level sets or level lines of the objective function:
lev=α f =

(x, y) ∈R2 : f (x, y) = α

,
where α ∈R. Next we illustrate the method with an example.
Example 4.31 Find the extremum values of
f (x, y) = 3x + 4y
on the feasible set
S =

(x, y) ∈R2 : (x −5)2 + (y −3)2 ≦4

.

4.3 Optimization Problems with Equality Constraints …
105
Fig. 4.1 Example 4.31.
Feasible set, level lines,
minimum (a) and maximum
(b)
The feasible set is drawn in Fig. 4.1, it is a circle of radius 2 centered at (5, 3).
The level curves are of the form
3x + 4y = c,
c ∈R.
They are parallel lines to the line 3x + 4y = 0 and f increases in the direction (3, 4).
So the minimum is achieved at the point A and the maximum at the point B, where the
parallel lines are tangents to the circumference (x −5)2 + (y −3)2 = 4. At a point
of tangency, the tangent line is perpendicular to the radius at the point of contact.
So, if we consider the perpendicular line to 3x + 4y = 0 through the center of the
circumference, that is the line 4(x −5) −3(y −3) = 0, the points A and B are the
solutions of the system
 (x −5)2 + (y −3)2 = 4
4(x −5) −3(y −3) = 0.
Solving this system we obtain A =
 19
5 , 7
5

and B =
 31
5 , 23
5

.
A second possibility to obtain the points A and B is as follows:
A = (5, 3) −2
5(3, 4) and B = (5, 3) + 2
5(3, 4).
Let us observe that 1
5(3, 4) is a unit vector in the direction (3, 4) and 2 is the radius
of the circumference.
A third possibility to ﬁnd A and B is based on algebraic considerations. For each
c the line 3x + 4y = c from the family of level lines cuts the circumference at two
points, at only one (A or B) or at none. Therefore, the values of c to obtain A and B are
those for which the system
 (x −5)2 + (y −3)2 = 4
3x + 4y = c
has only one solution. Chang-
ing to the variables u = x −5, v = y −3, the system becomes
 u2 + v2 = 4
3u + 4v = α,

106
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems …
where α = c −27. From the second equation v = α−3u
4
, and substituting in the ﬁrst
equation, it results 25u2 −6αu + α2 −64 = 0. This equation in u has only one solu-
tion if its discriminant is zero, that is,  = b2 −4ac = 36α2 −100(α2 −64) = 0.
This gives α = ±10, and so c = 27 ± 10, u = 6α
50 = ± 6
5, v = ± 8
5, x = 5 ± 6
5 and
y = 3 ± 8
5, and with this values we obtain the same points A and B as above.
The reader is invited to solve the problem of Example 4.29 with the geometrical
method. We recall that the relation x1x2 = α, α ∈R, α ̸= 0, generates a family of
equilateral hyperbolas. Other examples where the geometrical method is useful are
Examples 4.35, 5.30, and 5.33 and the problems at the end of Chap. 5.
The above methods are in general no longer useful when (P3) has more than
two variables and more than one constraint. In the general case, it is the Lagrange
Multipliers Rule that must be adopted. For the reader’s convenience we begin to treat
problem (P3) again under the assumption of p = 1, n = 2. Subsequently we shall
treat the general case.
Theorem 4.32 Let be in problem (P3) n = 2 and p = 1, i.e. f : X ⊂R2 →R and
h : X ⊂R2 →R, with X open set of R2. Let f be differentiable on X and h be
continuously differentiable on X. Let (x0, y0) ∈K3 =

(x, y) ∈R2 : h(x, y) = 0

be a local minimum point of f on K3 and let be ∇h(x0, y0) ̸= 0. Then, there exists
a unique scalar λ ∈R, called “Lagrange multiplier”, such that
∇f (x0, y0) + λ∇h(x0, y0) = 0.
(4.7)
Proof Consider, without loss of generality, the case ∂h
∂y (x0, y0) ̸= 0. Owing to the
Implicit Function Theorem (Chap. 1, p. 6), there exists a neighborhood U(x0), where
h(x, y) deﬁnes implicitly a function y = ϕ(x) such that
y0 = ϕ(x0); ϕ′(x) = −∂h/∂x
∂h/∂y .
In this neighborhood we have also z = f (x, y) = f (x, ϕ(x)) = F(x).
It must hence hold
F′(x0) = f ′(x0, ϕ(x0)) = 0.
But, owing to the “chain rule” on differentiability of composite functions, we have
also
F′(x) = ∂f
∂x + ∂f
∂y ϕ′(x).
Hence
F′(x) = ∂f
∂x + ∂f
∂y

−∂h/∂x
∂h/∂y

.
Therefore, at the point (x0, y0) it will hold

4.3 Optimization Problems with Equality Constraints …
107
Fig. 4.2 Geometric
interpretation of Theorem
4.32. f decreases in the
direction −∇f (x0) and x0 is
a local minimum of f , one
has ∇f (x0) + λ∇h(x0) = 0
with λ ∈R (in this case
λ = −1
2)
∂f
∂x −
∂f
∂y /∂h
∂y
 ∂h
∂x = 0.
On the other hand we have the following obvious identity:
∂f
∂y −
∂f
∂y /∂h
∂y
 ∂h
∂y = 0.
If we put
−
∂f
∂y /∂h
∂y = λ

,
we have the ﬁnal result.
□
A geometric interpretation of this theorem is given in Fig. 4.2.
Remark 4.33 (i) Obviously it is equivalent to write the thesis of Theorem 4.32 in
the form
∇f (x0, y0) −λ∇h(x0, y0) = 0,
as no sign restriction is made on the multiplier λ.
(ii) The necessary optimality conditions of Theorem 4.32 are obviously the same
also for a constrained maximization problem
(P′
3) :
max
x∈K3 f (x).
In other words the necessary optimality conditions expressed by means of the
Lagrange Multipliers Rule makes no distinction between minimization problems
and maximization problems.
(iii) The function
L (x, y, λ) = f (x, y) + λh(x, y)
(or, equivalently, L (x, y, λ) = f (x, y) −λh(x, y)) is called Lagrangian function
or shortly, Lagrangian. We note that the thesis of Theorem 4.32 leads to ﬁnd the sta-
tionary points of the Lagrangian function. In this sense, the constrained optimization

108
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems …
problem in question is treated by means of an unconstrained one, where the function
involved is the Lagrangian function.
Under the assumptions of Theorem 4.32, if λ ̸= 0, the vectors ∇f (x0, y0) and
∇h(x0, y0) are, therefore, proportional. The thesis of Theorem 4.32 can be rewritten
as
∇xL (x0, y0, λ) = 0,
whereas the relation
∇λL (x0, y0, λ) = 0
is equivalent to the feasibility of the pair (x0, y0), i.e. h(x0, y0) = 0.
We wish to stress that Theorem 4.32 gives only necessary optimality condi-
tions and that the “nature” of the constrained optimal points is not conserved by
the Lagrangian function L ( · , λ). What can be said is that, if the assumptions of
Theorem 4.32 are satisﬁed and (¯x, ¯y) is a constrained optimal point for (P3), then
this point is a stationary point of the Lagrangian. For example, ¯x = 1 is the minimum
point of f (x) = x3 under the constraint h(x) = x + 1 = 0 (and also the maximum
point, as in this rather “pathological” case the feasible set intersects with the objec-
tive function at one point) with multiplier λ = −3, but ¯x is not a minimum point of
L (x, ¯λ) on R.
Always for the case n = 2 and p = 1 we now give the second-order sufﬁcient
optimality conditions. These conditions will be proved next, for the general case.
Theorem 4.34 Let f (x, y) and h(x, y) be twice-continuously differentiable on the
open set X ⊂R2. Let (x0, y0) ∈K3, with
K3 =

(x, y) ∈R2 : h(x, y) = 0

,
and let (x0, y0, λ) satisfy relation (4.7). If the quadratic form
z⊤∇2
x,yL (x0, y0, λ)z
is positive deﬁnite

resp. negative deﬁnite

for all z ∈R2, z ̸= 0, such that
∇h(x0, y0)⊤z = 0,
(4.8)
then (x0, y0) is a strict local minimum point of f on K3 [resp. a strict local maximum
point of f on K3].
We recall that on the grounds of Corollary 1.4, the above quadratic form is positive
deﬁnite

resp. negative deﬁnite

on the constraint (4.8) if, for the following bordered
matrix
 =

0
∇h(x0, y0)⊤
∇h(x0, y0)
∇2
x,yL (x0, y0, λ)


4.3 Optimization Problems with Equality Constraints …
109
it holds det() < 0

resp. det() > 0

.
Example 4.35 Find, by the method of Lagrange multipliers, the minimizers and/or
maximizers, if any, of the function
f (x, y) = x + y
on the feasible set K3 =

(x, y) ∈R2 : x2 + 2y2 −6 = 0

.
We write the Lagrangian function in the form
L (x, y, λ) = x + y −λ(x2 + 2y2 −6).
The conditions of Theorem 4.32 and the feasibility conditions are:
⎧
⎪⎨
⎪⎩
∂L
∂x = 1 −λ2x = 0
∂L
∂y = 1 −λ4y = 0
x2 + 2y2 −6 = 0.
From the ﬁrst two equations we have
λ = 1
2x = 1
4y ⇒x = 2y.
From the third equation we have
4y2 + 2y2 = 6 ⇒y2 = 1 ⇒y = ±1.
We have, therefore, the two triplets
A = (2, 1, 1
4); B = (−2, −1, −1
4).
Then we have
∇2
x,yL (x, y, λ) =
 −2λ
0
0
−4λ

.
Now we consider the bordered matrix
 =

0
∇h(x)⊤
∇h(x)
∇2
x,yL (x, y, λ)

,
i.e.
 =
⎡
⎣
0
2x
4y
2x
−2λ
0
4y
0
−4λ
⎤
⎦.
At A = (2, 1, 1
4) we have

110
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems …
Fig. 4.3 Example 4.35
 =
⎡
⎣
0
4
4
4 −1
2
0
4
0
−1
⎤
⎦.
As det() = 24 > 0, the point (2, 1) is a constrained strict local maximum point.
At B = (−2, −1, −1
4) we have
 =
⎡
⎣
0
−4 −4
−4
1
2
0
−4
0
1
⎤
⎦.
As det() = −24 < 0, the point (−2, −1) is a constrained strict local minimum
point.
Moreover, as the feasible set is closed and bounded and the objective function is
continuous on R2, really the points founded are constrained global extremum points.
This example is illustrated in Fig. 4.3.
Example 4.36 Find, by the method of Lagrange multipliers, the minimizers and/or
maximizers, if any, of
f (x, y) = x2 + y2
on the feasible set
K3 =

(x, y) ∈R2 : y2 −log(5 −x2) = 0

.
First of all, it must be x ∈(−
√
5,
√
5). We write the Lagrangian function in the
form
L (x, y, λ) = x2 + y2 + λy2 −λ log(5 −x2).
The conditions of Theorem 4.32 and the feasibility conditions are:

4.3 Optimization Problems with Equality Constraints …
111
⎧
⎪⎨
⎪⎩
∂L
∂x = 2x + λ 2x
5−x2 = 10x−2x3+2λx
5−x2
= 0
∂L
∂y = 2y + 2λy = 2y(1 + λ) = 0
∂L
∂λ = y2 −log(5 −x2) = 0.
From the second equation we have y = 0 or λ = −1.
(1) Let be λ = −1. From the ﬁrst equation we have
10x −2x3 −2x = 0 ⇒2x(4 −x2) = 0,
from which x = 0 or x = −2 or x = 2.
(a) x = 0 ⇒y2 = log 5 ⇒y = ±

log 5. We have, therefore, two “candidate
points”:
A = (0,

log 5 );
B = (0, −

log 5 ),
with λ = −1.
(b) x = 2 ⇒y2 = log 1 ⇒y = 0.
(c) x = −2 ⇒y = 0. We have two other “candidate points”:
C = (−2, 0); D = (2, 0),
with λ = −1.
(2) Let be y = 0 (and λ any). From the third equation we have log(5 −x2) = 0 ⇒
x = ±2. from the ﬁrst equation we ﬁnd again λ = −1 and, therefore, we ﬁnd
again the points C and D.
We note that also in the present example the feasible set is closed and bounded.
Therefore, we have no necessity to use the second-order sufﬁcient conditions. We
have
f (A) = log 5 ≃0.699; f (B) = log 5; f (C) = 4; f (D) = 4.
Therefore, we have that C and D are constrained global maximizers (not strict
global maximizers!) and A and B are constrained global minimizers.
We are now ready to state the results for a general problem (P3) :
(P3) :
⎧
⎨
⎩
min f (x)
subject to: h j(x) = 0, ∀j = 1, . . . , p < n,
x ∈X ⊂Rn,
where X ⊂Rn is an open set contained in the domains of the functions involved
in (P3), f : X →R is differentiable on X and every h j : X →R, j = 1, . . . , p, is
continuously differentiable on X. We recall that the set
K3 =

x ∈X : h j(x) = 0, j = 1, . . . , p

is the feasible set of (P3).

112
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems …
Deﬁnition 4.37 Let be x0 ∈K3; the cone
L(x0) =

y ∈Rn : ∇h j(x0)⊤y = 0, j = 1, . . . , p

is called the linearizing cone of K3 at x0.
Obviously, as L(x0) is the solution set of a homogeneous linear the system, is a
linear space, therefore, a closed and convex set.
Theorem 4.38 Let x0 ∈K3; it holds
T (K3, x0) ⊂L(x0).
If the Jacobian matrix ∇h(x0), of order (n, p), has full rank (i.e. rk(∇h(x0)) =
p), then
T (K3, x0) = L(x0).
Proof Let us consider a direction y ∈T (K3, x0), y ̸= 0, and without loss of gener-
ality let us suppose ∥y∥= 1. Then there exists a feasible sequence

xk
⊂K3, with
xk
y→x0. The quotients
h(xk) −h(x0)
xk −x0
= ∇h(x0)⊤(xk −x0) + o(
xk −x0)
xk −x0
then converge to ∇h(x0)⊤y = 0. Therefore, y ∈L(x0).
To prove the second part of the theorem, let us assume that the Jacobian matrix
∇h(x0) has full rank. From the Implicit Function Theorem (Chap. 1, p. 6), it is
possible to express the system h(x) = 0 in a neighborhood of the point x0, by means
of p basic variables, i.e. with the notation used in the said theorem, to write
xB = H(xN).
The derivatives at the point x0 of the vector-valued function H : Rn−p →Rp
have the following representation:
∇H(x0
N) = −(∇Nh(x0))(∇Bh(x0))−1.
For a given vector
y =
 yB
yN

∈L(x0),
the relation
∇h(x0)⊤y = ∇Bh(x0)⊤yB + ∇Nh(x0)⊤yN = 0
is, therefore, equivalent to

4.3 Optimization Problems with Equality Constraints …
113
yB = ∇H(x0
N)⊤yN.
Let us suppose yN ̸= 0 (otherwise we have also yB = 0 and the result would be
trivial). Without loss of generality, suppose ∥y∥= 1. Then, there exists a sequence

xk
N

of non-basic variables which converges tangentially in the direction yN to the
point x0
N. Therefore, also the corresponding sequence of basic variables

xk
B

, with
xk
B = H(xk
N) converges to x0
B = H(x0
N). The sequence

xk
=
 xk
B
xk
N
"
=
 H(xk
N)
xk
N
"
is, therefore, feasible and tangentially convergent in the direction
y
∥y∥to the point x0,
being
xk
N −x0
N
xk
N −x0
N
 →y
and
H(xk
N) −H(x0
N)
xk
N −x0
N

→∇H(x0
N)⊤yN = yB.
Therefore, it holds y ∈T (K3, x0).
□
The previous result is a modern version of a classical result: the Theorem of
Lyusternik (see, e.g. Ioffe and Tikhomirov [8]).
We are now in a position to prove the general version of Theorem 4.32, i. e. the
“Lagrange Multipliers Rule” for problem (P3).
Theorem 4.39 Let x0 ∈K3 be a local minimum point of (P3) and let the gradients
∇h1(x0), . . . , ∇h p(x0) be linearly independent. Then, there exists a unique vector
of multipliers v1, . . . , vp ∈R such that
∇f (x0) +
p

j=1
v j∇h j(x0) = 0.
(4.9)
Proof As the gradients ∇h j(x0), j = 1, . . . , p, are linearly independent, the Jaco-
bian matrix ∇h(x0) has full rank and hence, on the grounds of the previous theorem,
it holds T (K3, x0) = L(x0). From Theorem 4.24 we have, therefore,
∇f (x0)⊤y ≧0, ∀y ∈L(x0).
As L(x0) is a linear subspace of Rn, the previous relation holds as an equality,
i.e.
∇f (x0)⊤y = 0, ∀y ∈Rn such that ∇h(x0)⊤y = 0.

114
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems …
This means (recall also the theorem of the alternative of Motzkin, Theorem 2.31)
that the vector ∇f (x0) is given by the linear combination of the column vectors
∇h1(x0), . . . , ∇h p(x0) of the Jacobian matrix ∇h(x0). This is just the thesis of the
theorem.
□
As already said, the scalars v j ∈R, j = 1, . . . , p, are called “Lagrange multipli-
ers” and the function
L (x, v) = f (x) + v⊤h(x) or also L (x, v) = f (x) −v⊤h(x)
is called “Lagrangian function”. Obviously relation (4.9) holds also if x0 ∈K3 is a
local maximum point of (P3). The conditions
∇xL (x0, v) = 0; ∇vL (x0, v) = 0
are, therefore, ﬁrst-order necessary conditions for x0 to be a local minimizer (or local
maximizer) for (P3).
A point x0 ∈K3 for which ∇h(x0) has full rank is called a regular point for
(P3), which, in this case it is also called a “regular problem”. We point out that
when the constraints h j(x), j = 1, . . . , p, are all linear afﬁne, there is no need to
assume the linear independence of the gradients at x0. See the section on constraint
qualiﬁcations in Chap. 6.
If x0 ∈K3 is not a regular point, it is possible to obtain the following ﬁrst-order
necessary optimality conditions for (P3), conditions attributed to C. Caratheodory
(1935) and which anticipate, for classical constrained optimization problems, the
Fritz John Theorem for problems (P4) and (P5). See Chaps. 5 and 6.
Theorem 4.40 (Caratheodory) Let x0 ∈K3 be a local minimum point for (P3).
Then, there exist multipliers v0, v1, . . . , vp ∈R, not all zero, such that
v0∇f (x0) +
p

j=1
v j∇h j(x0) = 0.
Proof If ∇h(x0) has full rank, i.e. x0 is regular, i.e. rk(∇h(x0)) = p, then Theorem
4.39 applies with v0 = 1. If rk(∇h(x0)) < p, i.e. the vectors ∇h1(x0), . . . , ∇h p(x0)
are linearly dependent, there will exist multipliers, not all zero, v1, . . . , vp ∈R such
that
v1∇h1(x0) + · · · + vp∇h p(x0) = 0.
It is, therefore, sufﬁcient to choose v0 = 0.
□
Remark 4.41 In the above result the situation v0 = 0 points out the “non regularity”
of the problem, whereas a non zero multiplier v0 can be present in both regular
problems and non-regular problems. In other words, we have the implications

4.3 Optimization Problems with Equality Constraints …
115
(P3) regular problem ⇒v0 ̸= 0.
v0 = 0 ⇒(P3) non-regular problem.
Indeed, if we write the Lagrangian function at x0 ∈K3 in the form
L (x0, v) = f (x0) −v⊤h(x0),
we have that relation (4.9) is (∇h(x0) is the Jacobian matrix, of order (n, p)):
∇h(x0)v = ∇f (x0).
From a well-known theorem on systems of linear equations, this system has a
solution v ∈Rp if and only if (Theorem of Rouché-Capelli)
rk(∇h(x0)) = rk(∇h(x0); ∇f (x0)).
It is possible that the two ranks coincide even if rk(∇h(x0)) < p (for example, if
∇f (x0) = 0), and regardless of the fact that x0 is or not an optimal point for (P3)!.
Example 4.42 Consider the problem

min(x2 + y2)
subject to: (x −1)3 −y2 = 0.
By using, e.g. the level sets method, it is seen that the solution is at the point (1, 0).
This point is not regular, as ∇h(1, 0) = (0, 0)⊤. The Lagrange conditions (4.7) are
not veriﬁed at x0 = [1, 0]⊤. However, we have, with v0 = 0,
v0∇f (x0, y0) + v1∇h(x0, y0) = 0,
with v1 ∈R, v1 ̸= 0, relation which satisﬁes the thesis of Theorem 4.40.
We now give the second-order optimality conditions for optimization problems
with equality constraints.
Theorem 4.43 Let f : X →R and every h j : X →R, j = 1, . . . , p, be twice-
continuously differentiable on the open set X ⊂Rn.
(i) Let x0 ∈K3 be a local minimizer

resp. a local maximizer

of f on K3 and let
x0 be a regular point. Then, besides relation (4.9), it holds
y⊤∇2
xL (x0, v)y ≧0

resp. ≦0

for all y ∈Rn such that
y⊤∇h j(x0) = 0, j = 1, . . . , p.

116
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems …
(ii) Let x0 ∈K3. If relation (4.9) is satisﬁed by the pair (x0, v) and if
y⊤∇2
xL (x0, v)y > 0

resp. < 0

for all y ∈Rn, y ̸= 0, such that
y⊤∇h j(x0) = 0, j = 1, . . . , p,
(4.10)
then x0 is a strict local minimizer

resp. a strict local maximizer

for f on K3.
Proof (i) This result is a direct consequence of Theorem 4.26. Being x0 a regular
point it will hold
∇xL (x0, v) = 0.
Moreover, x0 is a local minimizer

resp. local maximizer

in K3 of L ( · , v).
Therefore, we have
y⊤∇2
xL (x0, v)y ≧0

resp. ≦0

for all y ∈T (K3, x0). But, thanks to Theorem 4.38, T (K3, x0) = L(x0) and the
thesis follows.
(ii) This result is a direct consequence of Theorem 4.27. Being (4.9) satisﬁed and
being, for all x ∈K3,
L (x, v) = f (x),
if
y⊤∇2
xL (x0, v)y > 0

resp. < 0

for all y ∈T (K3, x0) \ {0} , then L (x0, v) <

resp. >

L (x, v), ∀x ̸= x0, x ∈K3.
This is equivalent to state that x0 is a strict local minimum point (resp. local maxi-
mum point) of f on K3. Being T (K3, x0) ⊂L(x0), we can substitute in the above
inequality T (K3, x0) with L(x0). See also the end lines of Remark 4.44.
□
Remark 4.44 Following Hestenes [2], it is possible to assert that conditions (ii) of
the previous theorem guarantee that x0 is a strict local minimizer

resp. maximizer

of order 2 for (P3).
We recall (see Chap. 1) that in order to check the second-order sufﬁcient optimality
conditions (ii) of the previous theorem, we can consider the bordered matrix, of order
(p + n),
M(x0, v) =

0
∇h(x0)⊤
∇h(x0) ∇2
xL (x0, v)

.
If the leading principal minors of M(x0, v), of order 2p + 1, . . . , p + n, have
the sign of (−1)p, then the quadratic form y⊤∇2
xL (x0, v)y is positive deﬁnite on
the set (4.10). If the leading principal minors of M(x0, v), of order 2p + 1, . . . , p +
n, alternate in sign, beginning with the sign of (−1)p+1, then the quadratic form

4.3 Optimization Problems with Equality Constraints …
117
y⊤∇2
xL (x0, v)y isnegativedeﬁniteontheset (4.10).Notethatiftheaboveconditions
on M(x0, v) are satisﬁed, then the gradients ∇h1(x0), . . . , ∇h p(x0) are linearly
independent and hence T (K3, x0) = L(x0).
We have also sufﬁcient conditions for global optimality.
Theorem 4.45 Let x0 ∈K3 and let the pair (x0, v) satisfy relation (4.9). If L (x, v)
is pseudoconvex, with respect to x, on the open convex set X ⊂Rn, then x0 is a
global minimizer of f on K3. If L (x, v) is pseudoconcave in x, then x0 is a global
maximizer of f on K3.
Proof If L (x, v) is pseudoconvex, with respect to x, we have, for all x ∈X,
(x −x0)⊤∇L (x0, v) ≧0 ⇒L (x, v) ≧L (x0, v).
But being (4.9) satisﬁed, we have, ∀x ∈K3 :
(x −x0)⊤∇L (x0, v) = 0 ⇒f (x) + v⊤h(x) ≧f (x0) + v⊤h(x0),
i.e. , ∀x ∈K3 :
f (x) ≧f (x0).
□
We recall that if f is convex and the Lagrangian function is given in the form
L (x, v) = f (x) + p
j=1 v jh j(x), then L (x, v) is convex (with respect to x) if
every h j is a convex function and all multipliers are positive. If all constraints are
linear afﬁne (i.e. h j(x) = (a j)⊤x −b j, j = 1, . . . , p) and the objective function
is convex

resp. concave

, then the Lagrangian function is convex

resp. concave

regardless of the sign of the multipliers. We can, therefore, give the following result.
Theorem 4.46 Suppose f be convex

resp. concave

on the convex set X ⊂Rn and
suppose h1, . . . , h p be linear afﬁne. Then x0 ∈K3, such that the pair (x0, v) satisfy
relation (4.9), is a global minimizer

resp. a global maximizer

of f on K3.
Example 4.47 Find the minimizers and/or the maximizers, if any, of
f (x) = 5x1 + 2x2 −x3
on the feasible set
K3 =

(x1, x2, x3) ∈R3 : x1x2 = 3; x1x3 = 1

.
We write the Lagrangian function in the form
L (x, v) = 5x1 + 2x2 −x3 + v1(3 −x1x2) + v2(1 −x1x3).

118
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems …
The system ∇x,vL (x, v) = 0 is
⎧
⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩
5 −v1x2 −v2x3 = 0
2 −v1x1 = 0
−1 −v2x1 = 0
3 −x1x2 = 0
1 −x1x3 = 0.
We have: x2 = 3
x1 ; x3 = 1
x1 ; v1 = 2
x1 ; v2 = −1
x1 = −x3. The ﬁrst equation
becomes then
5 −2
x1
· 3
x1
+ 1
x1
· 1
x1
= 0,
i.e.
5 −
5
(x1)2 = 0.
We have, therefore,
x1 = ±1; x2 = ±3; x3 = ±1; v1 = ±2; v2 = ∓1.
Therefore, the two vectors
A = (1, 3, 1; 2, −1); B = (−1, −3, −1; −2, 1).
The bordered matrix M(x, v) is
M(x, v) =
⎡
⎢⎢⎢⎢⎣
0
0
−x2
−x1
0
0
0
−x3
0
−x1
−x2
−x3
0
−v1
−v2
−x1
0
−v1
0
0
0
−x1
−v2
0
0
⎤
⎥⎥⎥⎥⎦
.
Being n = 3 and p = 2, we have to compute only the leading principal minors
of M of order 2p + 1 = 5, i.e. det(M). For A we have det(M(x1, v1)) = 10 and
for B we have det(M(x2, v2)) = −10. As det(M(x1, v1)) has the sign of (−1)2,
it results that the constrained quadratic form is positive deﬁnite and hence x1 =
[1, 3, 1]⊤is a constrained strict local minimizer. As det(M(x2, v2)) has the sign of
(−1)3, it results that the constrained quadratic form is negative deﬁnite and hence
x2 = [−1, −3, −1]⊤is a constrained strict local maximizer.
Example 4.48 Factorize the integer number 8 into three positive (not necessarily
integer) factors, such that the sum of the inverses of the said factors is minimal.
In other words, we have the problem

4.3 Optimization Problems with Equality Constraints …
119
min
 1
x1
+ 1
x2
+ 1
x3
"
subject to: x1x2x3 = 8.
We use the Lagrangian multipliers method. The Lagrangian function is
L (x, v) = 1
x1
+ 1
x2
+ 1
x3
+ v(x1x2x3 −8)
and the related ﬁrst-order conditions are
∇xL (x, v) =
⎛
⎝
−(x1)−2
−(x2)−2
−(x3)−2
⎞
⎠+ v
⎛
⎝
x2x3
x3x1
x1x2
⎞
⎠=
⎛
⎝
0
0
0
⎞
⎠.
Obviously v ̸= 0; we obtain the equation
1
v = (x1)2x2x3 = x1(x2)2x3 = x1x2(x3)2.
We ﬁnd the solution x1 = x2 = x3 = 2, with the related multiplier v =
1
16. We
have
∇2
xL (x, v) =
⎛
⎝
2(x1)−3
vx3
vx2
vx3
2(x2)−3
vx1
vx2
vx1
2(x3)−3
⎞
⎠.
For x0 = [2, 2, 2]⊤and v =
1
16 we have
∇2
xL (x, v) = 1
8
⎛
⎝
2 1 1
1 2 1
1 1 2
⎞
⎠.
This matrix is positive deﬁnite everywhere (and not only on the set ∇h(x0)⊤y =
0). Therefore, the point x0 = [2, 2, 2]⊤is a constrained global minimum point, as f
is a strictly convex function on int(R3
+).
Example 4.49 Find the minimizers and/or maximizers, if any, of
f (x) = x2 + y2 + z2
subject to: x + 2y + z = 1; 2x −y −3z = 4.
We write the Lagrangian function in the form
L (x, v) = x2 + y2 + z2 −v1(x + 2y + z −1) −v2(2x −y −3z −4).
We write the system

120
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems …
⎧
⎪⎨
⎪⎩
∂L
∂x = 2x −v1 −2v2 = 0
∂L
∂y = 2y −2v1 + v2 = 0
∂L
∂z = 2z −v1 + 3v2 = 0.
We obtain from the ﬁrst two equations v1 = 2x
5 + 4y
5 ; v2 = 4x
5 −2y
5 . By insert-
ing these expressions in the third equation we get x −y + z = 0. This expression,
together with the two linear constraints, determines a linear system of three equations
in three unknowns. We obtain the (unique) solution
x = 16
15, y = 1
3, z = 11
15.
We observe that the objective function f (x) = x2 + y2 + z2 is a strictly con-
vex function (it is the sum of strictly convex functions). Since the constraints are
both linear afﬁne, the Lagrangian function is, therefore, (strictly) convex. Hence the
point
 16
15, 1
3, 11
15
⊤is the unique constrained strict global minimizer of the objective
function.
Example 4.50 (Variational characterization of the eigenvalues of a symmetric
matrix A of order n) Let us consider the Rayleigh quotient
R(x) = x⊤Ax
∥x∥2 ,
where x ∈Rn \ {0} and A is a symmetric matrix of order n. This function is homo-
geneous of zero degree: it holds, for t > 0, x ̸= 0,
R(tx) = (tx)⊤A(tx)/ ∥tx∥2 = t2x⊤Ax/t2 ∥x∥2 = R(x).
Therefore, in order to compute the minimum and the maximum of R(x) for
x ∈Rn \ {0} , if they exist, it is sufﬁcient to compute the minimum and the maximum
of R(x) on the unit sphere
U =

x ∈Rn : ∥x∥= 1

.
Note that we have a continuous function x⊤Ax on a compact set and, therefore,
the Weierstrass theorem applies. Let us denote
m = min {R(x) : x ∈U} ; M = max {R(x) : x ∈U} .
Let us order the eigenvalues of A (which are all real!) in the following way:
λ1 ≧λ2 ≧· · · ≧λn.
We want to prove the following proposition.

References
121
• If A is a symmetric matrix, of order n, with eigenvalues λ1 ≧λ2 ≧· · · ≧λn, then
max
x̸=0 R(x) = max
x∈U R(x) = λ1;
min
x̸=0 R(x) = min
x∈U R(x) = λn.
We use the Lagrangian multipliers theorem, where the objective function is
f (x) = x⊤Ax and x ∈U can be expressed as h(x) = x⊤x −1 = 0. We write
the Lagrangian function L (x, λ) in the form
L (x, λ) = f (x) −λh(x) = x⊤Ax −λ(x⊤x −1).
The gradient of L with respect to x is
∇xL (x, λ) = 2Ax −2λx.
Therefore, the condition ∇xL (x, λ) = 0 becomes
Ax = λx, x ∈U.
The maximum and minimum points of R(·) on U (points which surely exist) are to
be looked for among the n orthonormal eigenvectors v1, v2, . . . , vn of the matrix
A, eigenvectors corresponding to the eigenvalues λ1, λ2, . . . , λn. Let us compute
the value which R(·) assumes in correspondence of an eigenvector v j ∈U :
R(v j) = (v j)⊤Av j = (v j)⊤(λ jv j) = λ j(v j)⊤v j = λ j,
as (v j)⊤v j = 1. We conclude that R(·) reaches its maximum value for x = v1 and
its minimum value for x = vn. We ﬁnd, as a corollary, the well-known criterion
(see Chap. 1) for stating the sign of a (real) quadratic form Q(x) = x⊤Ax, where
the eigenvalues of A have been ordered in the following way: λ1 ≧λ2 ≧· · · ≧λn.
• Q(x) is positive deﬁnite if and only if λn > 0.
• Q(x) is positive semideﬁnite if and only if λn ≧0.
• Q(x) is negative deﬁnite if and only if λ1 < 0.
• Q(x) is negative semideﬁnite if and only if λ1 ≦0.
• Q(x) is indeﬁnite if and only if λn < 0 < λ1.
References
1. M.R. Hestenes, Calculus of Variations and Optimal Control Theory (Wiley, New York, 1966)
2. M.R. Hestenes, Optimization Theory. The Finite Dimensional Case (Wiley, New York, 1975)
3. A. Ben-Israel, B. Mond, What is invexity? J. Austral. Math. Soc. Ser. B 28, 1–9 (1986)

122
4
Unconstrained Optimization Problems. Set-Constrained Optimization Problems …
4. B.D. Craven, B.M. Glover, Invex functions and duality. J. Aust. Math. Soc. Ser. A 39, 1–20
(1985)
5. M. Guignard, Generalized Kuhn-Tucker conditions for mathematical programming problems
in a Banach space. SIAM J. Control 7, 232–241 (1969)
6. G. Giorgi, T.H. Kjeldsen, Traces and Emergence of Nonlinear Programming (Birkhäuser, Basel
and New York, 2014)
7. P. Bussotti, On the genesis of the Lagrange multipliers. J. Optim. Theory Appl. 117, 453–459
(2003)
8. A.D. Ioffe, V.M. Tichomirov, Theory of Extremal Problems (North Holland, Amsterdam, 1979)
9. A. Prekopa, On the development of optimization theory. Amer. Math. Mon. 87, 527–542 (1980)

Chapter 5
Constrained Optimization Problems
with Inequality Constraints
5.1
First-Order Conditions
In the present chapter, we are concerned with constrained optimization problems
with inequality constraints, i.e. with problem (P4).
(P4) :
⎧
⎨
⎩
min f (x)
subject to: gi(x) ≦0, i = 1, . . . , m,
x ∈X ⊂Rn,
where X is an open set contained in the domains of the functions involved in (P4),
f and each gi, i = 1, . . . , m, are real-valued functions deﬁned on Rn. The function
f is the objective function of (P4), gi, i = 1, . . . , m, are the constraints and the set
K4 =

x ∈X : gi(x) ≦0, i = 1, . . . , m

is the feasible set of (P4).
In the last century, just before the Second World War, it became apparent that there
are many optimization problems which involve constraints in the form of inequalities,
instead of in the form of equalities, or involve constraints in the form of both inequali-
ties and equalities. The transition from “classical” constrained optimization problems
to “modern” constrained optimization problems (i.e. with constraints expressed by
inequalities) requested almost 180 years! This, above all due to the fact that, whereas
the constrained classical optimization problems are substantially treated by means
of a standard result of Mathematical Analysis, i.e. the Implicit Function Theorem,
the modern constrained optimization problems require results from Convex Analysis
and Linear Algebra, topics developed mainly during the 20th century.
It was during the Second World War, in the USA, and a few years before its begin-
ning, in the Soviet Union, that a new chapter in the theory of constrained optimization
was developed: the Linear Programming theory by the American mathematician G.
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al., Basic Mathematical Programming Theory, International Series
in Operations Research & Management Science 344,
https://doi.org/10.1007/978-3-031-30324-1_5
123

124
5
Constrained Optimization Problems with Inequality Constraints
B. Dantzig and by the Russian mathematician L. V. Kantorovich (Nobel prize in
Economic Science in 1975, together with T. C. Koopmans). In 1951, in the USA,
mathematicians H. W. Kuhn and A. W. Tucker developed the Lagrange multipliers
rule with reference to convex and nonconvex (nonlinear) programming problems
with inequality constraints. Some years before [3], the mathematician Fritz John had
published a paper on the same subject (perhaps the ﬁrst published paper on these
problems), obtaining some weaker optimality conditions with respect to the ones of
Kuhn and Tucker. But, prior to F. John and Kuhn and Tucker, in 1939 W. Karush
in his Master’s Thesis at the University of Chicago, had obtained optimality condi-
tions for (P4), similar to the ones of Kuhn and Tucker. Thus, these conditions are
now known as Karush-Kuhn-Tucker conditions. The thesis of Karush was neglected
for several years and has been entirely published only in 2014. See Giorgi and
Kjeldsen [4].
For our purposes, the formulation of (P4) is sufﬁciently general. We recall that the
maximization problem max f (x), x ∈K4, is equivalent to min {−f (x)} , x ∈K4.
Obviously, it holds
f (x0) ≡max f (x) = −min {−f (x)} .
Moreover, if we have some inequalities of the type gk(x) ≧0, obviously, these
ones are equivalent to −gk(x) ≦0. If we have some constraints of the type gk(x) ≦
bk, it is possible to write them as ϕk(x) ≦0, with ϕk(x) = gk(x) −bk. Also the
constraints x1 ≧0, . . . , xn ≧0 (i.e. x ≧0, x ∈Rn) may be rewritten in the form
−x1 ≦0
−x2 ≦0
...
−xn ≦0,
even if this procedure is often not convenient.
Given x0 ∈K4, the constraints gi for which it holds gi(x0) = 0 are called active
constraints (or binding constraints or effective constraints) at x0. Those constraints
for which at x0 ∈K4, we have gi(x0) < 0, are called non-active constraints (or
non-binding constraints or non-effective constraints) at x0. For x0 ∈K4, the set
I (x0) =

i ∈{1, . . . , m} : gi(x0) = 0

is the set of indices of those constraints which are active at x0. It is also called set of
the active constraints at x0.
The active constraints have a special meaning: they restrict feasible corrections
around a feasible point. If a constraint gi is non-active at a feasible point x0 (i.e.
gi(x0) < 0) it is possible to move from x0 a bit in any direction without violating

5.1 First-Order Conditions
125
this constraint. So, in a sense, at least locally, non-active constraints are not important
with respect to optimality criteria for (P4).
Example 5.1 Let be, with x = (x1, x2) ∈R2,
g1(x) = x2 −(x1)2 ≦0;
g2(x) = x1 −1 ≦0;
g3(x) = −x1 ≦0;
g4(x) = −x2 ≦0.
At x0 = (0, 0)⊤, we have I (x0) = {1, 3, 4} ; at x0 = (1, 0)⊤, we have I (x0) =
{2, 4} ; at x0 =
 7
8, 1
2
⊤, we have I (x0) = ∅.
So, if I (x0) = ∅, problem (P4) becomes an unconstrained optimization problem
and this case is therefore not relevant to what treated in the present chapter.
Let us now make the assumption that all the functions involved in (P4) are (at
least) differentiable on the open set X ⊂Rn.
Deﬁnition 5.2 Let be x0 ∈K4; the set (polyhedral cone)
L(x0) =

y ∈Rn : ∇gi(x0)⊤y ≦0, ∀i ∈I (x0)

is called linearizing cone of K4 at x0 (or also cone of locally constrained directions
of K4 at x0).
The set
Lo(x0) =

y ∈Rn : ∇gi(x0)⊤y < 0, ∀i ∈I (x0)

is called cone of interior locally constrained directions of K4 at x0 or cone of descent
directions of K4 at x0.
Obviously, L(x0) ̸= ∅because 0 ∈L(x0). Actually, L(x0) is a polyhedral cone
and thus it is closed and convex. On the other hand, Lo(x0) is an open convex cone,
being Lo(x0) = int(L(x0)). Therefore, cl(Lo(x0)) = L(x0) if and only if Lo(x0) ̸=
∅. Geometrically, each vector y ∈Lo(x0) has a negative projection on the gradients
of active inequality constraints. This implies that moving from x0 along y within a
certain range of steps will not violate the constraint. Hence, y is a feasible direction,
i.e. y ∈F(K4, x0). L(x0) and Lo(x0) provide analytic representations of the local
approximation of K4 at x0.
Theorem 5.3 Let x0 ∈K4; then it holds
Lo(x0) ⊂F(K4, x0) ⊂A(K4, x0) ⊂T (K4, x0) ⊂L(x0),
where F(K4, x0), A(K4, x0), and T (K4, x0) are, respectively, the cone of feasible
directions to K4 at x0, the cone of attainable directions to K4 at x0, and the cone of
tangent directions or Bouligand tangent cone or contingent cone to K4 at x0.

126
5
Constrained Optimization Problems with Inequality Constraints
Proof If I (x0) = ∅, then x0 ∈int(K4) and it holds trivially Lo(x0) = F(K4, x0) =
A(K4, x0) = T (K4, x0) = L(x0) = Rn. Let us suppose therefore that I (x0) ̸= ∅.
Let be y ∈Lo(x0), and without loss of generality, let be ∥y∥= 1. First we prove that
Lo(x0) ⊂F(K4, x0). We need to show that there exists δ0 > 0 such that x0 + δy ∈
K4, ∀δ ∈[0, δ0] . When i /∈I (x0), we have, thanks to the continuity of gi,
gi(x0 + δy) < 0,
when δ is sufﬁciently small. When i ∈I (x0), for δ > 0 and sufﬁciently small, we
have
gi(x0 + δy) = gi(x0) + δ∇gi(x0)⊤y + o(t).
Consequently, gi(x0 + δy) < gi(x0) = 0, for δ > 0 sufﬁciently small. There-
fore, y ∈F(K4, x0) and Lo(x0) ⊂F(K4, x0). From the deﬁnitions of F(K4, x0),
A(K4, x0) and T (K4, x0) it is easy to check that F(K4, x0) ⊂A(K4, x0) ⊂T (K4,
x0) (see Remark 2.45). Finally, we prove that T (K4, x0) ⊂L(x0). Let be y ∈
T (K4, x0), with y ̸= 0 and, without loss of generality, with ∥y∥= 1. There will exist
therefore a feasible sequence

xk
⊂K4, with xk
y→x0. Then, for every i ∈I (x0),
the quotients
gi(xk) −gi(x0)
		xk −x0		
= ∇gi(x0)⊤(xk −x0) + o(
		xk −x0		)
		xk −x0		
converge to ∇gi(x0)⊤y ≦0. Then y ∈L(x0).
□
Theorem 5.3 shows that L(x0) can be slightly larger (if not equal to) F(K4, x0),
A(K4, x0) and T (K4, x0). We note, moreover, that it holds (see Theorem 2.24, prop-
erties of polar cones):
(L(x0))∗⊂(T (K4, x0))∗⊂(A(K4, x0))∗⊂(F(K4, x0))∗⊂(Lo(x0))∗.
Corollary 5.4 If Lo(x0) ̸= ∅, then it holds
cl(Lo(x0)) = T (K4, x0) = L(x0).
Proof Let be y ∈L(x0), i.e.
∇gi(x0)⊤y ≦0, ∀i ∈I (x0).
Now we choose a vector y0 ∈Lo(x0) ̸= ∅, i.e. a vector y0 such that
∇gi(x0)⊤y < 0, ∀i ∈I (x0).
For all λ > 0, we have therefore

5.1 First-Order Conditions
127
∇gi(x0)⊤(y + λy0) = ∇gi(x0)⊤y + λ∇gi(x0)y0 < 0, ∀i ∈I (x0).
Hence, y + λy0 ∈Lo(x0). Consequently, it holds y ∈cl(Lo(x0)) and therefore
we obtain the inclusion L(x0) ⊂cl(Lo(x0)), from which we obtain the thesis, on
the grounds of the previous theorem and taking into account the fact that both cones
T (K4, x0) and L(x0) are closed.
□
We shall see that the condition Lo(x0) ̸= ∅is known as “Cottle Constraint Qual-
iﬁcation”, a condition that really is due to Arrow, Hurwicz, and Uzawa [1].
We can now obtain the ﬁrst important result concerning necessary optimality con-
ditions for (P4), i.e. the Fritz John conditions. Perhaps this result is the ﬁrst published
theorem [3] regarding optimality conditions for a mathematical programming prob-
lem with inequality constraints. Though this result is usually treated without many
comments and with little emphasis in several books on optimization theory, recent
works by Bertsekas [5] and Bertsekas and Ozdaglar [6] bring a new light on the Fritz
John Theorem. These authors speak of “enhanced Fritz John conditions”, as their
conditions are useful also in view of theoretic and algorithmic developments. We
shall revert to the main results of Bertsekas and Ozdaglar in the next chapter. We
now give the classical version of the Fritz John theorem.
Theorem 5.5 (Fritz John Theorem) Let x0 ∈K4 be a local minimum point for (P4).
Then there exist multipliers u0 ≧0, u1 ≧0, . . . , um ≧0, not all zero, such that
u0∇f (x0) +
m

i=1
ui∇gi(x0) = 0,
uigi(x0) = 0,
∀i = 1, . . . , m.
Proof Let x0 ∈K4 be a local minimum point for (P4). Then we have (Theorem
4.24):
∇f (x0)⊤y ≧0, ∀y ∈T (K4, x0) ⊃Lo(x0).
We have also ∇f (x0)⊤y ≧0 for all vectors y such that ∇gi(x0)⊤y < 0, i ∈I (x0).
In other words, the system of linear inequalities
∇f (x0)⊤y < 0; ∇gi(x0)⊤y < 0, i ∈I (x0),
does not admit solutions y ∈Rn. Thanks to Gordan’s theorem of the alternative
(see Chap. 2, p. 44), it results that there exist multipliers ui ≧0, i ∈{0} ∪I (x0),
nonnegative and not all zero, such that
u0∇f (x0) +

i∈I (x0)
ui∇gi(x0) = 0.
By choosing ui = 0, ∀i /∈I (x0), we obtain the thesis.
□

128
5
Constrained Optimization Problems with Inequality Constraints
The conditions uigi(x0) = 0, i = 1, . . . , m, are called complementary slackness
conditions. Note that if I (x0) = ∅, we have the result ∇f (x0) = 0, i.e. x0 is a
stationary point for f . Note that only the multipliers u0, ui, i ∈I (x0), are required to
be not all zero. If u0 = 0, the necessary optimality conditions expressed by Theorem
5.5 become useless, as in this case, the role played by the objective function vanishes.
It is therefore important to have conditions which assure u0 ̸= 0, i.e. without loss of
generality, u0 = 1. The conditions which assure, in Theorem 5.5, u0 = 1, are called
“constraint qualiﬁcations” and have for (P4) the role that the “regularity conditions”
have for the “classical” constrained optimization problem (P3).
The result, contained in the proof of Theorem 5.5: Let x0 ∈K4 be a local minimum
point for (P4); then the system

∇f (x0)⊤y < 0
∇gi(x0)⊤y < 0, i ∈I (x0),
has no solution y ∈Rn, is also known as Abadie linearization lemma (Abadie [7]).
Its geometric meaning is clear: if x0 is a local solution of (P4), there does not exist
a direction y ∈Rn along which it is possible to remain in the feasible set and at the
same time to decrease the objective function.
The complementary slackness conditions emphasize that both ui and gi(x0) can-
not hold with a strict inequality at the same time. Hence,
gi(x0) < 0 ⇒ui = 0;
gi(x0) = 0 ⇒ui ≧0;
ui > 0 ⇒gi(x0) = 0.
If, for all i ∈I (x0), we have ui > 0, we say that the strict complementary slack-
ness conditions hold at x0, i.e.
gi(x0) = 0 ⇔ui > 0.
These conditions are important for some questions regarding second-order opti-
mality conditions and for some questions of sensitivity analysis (see Chap. 7).
Example 5.6 Let us consider the problem
⎧
⎨
⎩
min f (x1, x2) = x1 + x2
subject to: −(x1)3 + x2 ≦0,
−x2 ≦0.
It is easy to see (by geometric considerations) that the solution of the problem is the
point x0 = (0, 0)⊤. The Fritz John conditions for this problem are:
u0
1
1

+ u1
−3(x1)2
1

+ u2
 0
−1

=
0
0

;

5.1 First-Order Conditions
129
u1(−(x1)3 + x2) = 0;
u2(−x2) = 0;
u0 ≧0, u1 ≧0, u2 ≧0, not all zero.
At x0 = (0, 0)⊤, we have
u0
 1
1

+ u1
0
1

+ u2
 0
−1

=
0
0

,
i.e.
u0 + u1 · 0 + u2 · 0 = 0
u0 + u1 −u2 = 0,
from which it results that u0 = 0 (and u1 = u2 that can be chosen > 0).
In their pioneering paper of 1951 Kuhn and Tucker [8] introduced a condition,
called “constraint qualiﬁcation” (indeed, it was already introduced by Karush in 1939
in his Master Thesis) in order to avoid that, in the Fritz John conditions, we have (as
in Example 2) u0 = 0. There are many constraint qualiﬁcations, ranking from simple
ones, easy to check, to sophisticated ones, more general but less easy to check. A
problem (P4), where a constraint qualiﬁcation holds, is therefore called “qualiﬁed”.
Constraint qualiﬁcations usually are conditions regarding only the constraints and not
also the objective function. We consider for problem (P4) a very general constraint
qualiﬁcation, due to Guignard [9] and Gould and Tolle [10]. We shall see in the next
chapter that this constraint qualiﬁcation is, in a certain sense, the weakest among the
other constraint qualiﬁcations proposed for (P4) or for (P5).
Let x0 ∈K4. We say that the Guignard-Gould-Tolle constraint qualiﬁcation holds
if
(L(x0))∗= (T (K4, x0))∗,
(5.1)
which can be equivalently expressed as
L(x0) = (T (K4, x0))∗∗,
or also as
L(x0) = P(K4, x0) ≡cl(conv(T (K4, x0))).
In order to obtain the celebrated Kuhn-Tucker conditions or, better, Karush-Kuhn-
Tucker conditions, we need a simple previous result. Following Gould and Tolle [10,
11], we introduce for (P4) the cone of gradients:
B(x0) =
⎧
⎨
⎩y ∈Rn : y =

i∈I (x0)
ui∇gi(x0), ui ≧0, ∀i ∈I (x0)
⎫
⎬
⎭.

130
5
Constrained Optimization Problems with Inequality Constraints
Note that the cone of gradients is a ﬁnitely generated cone and hence it is closed
and convex (see Theorem 2.26). It is easy to show that B(x0) and L(x0) are polar
cones of each other.
Lemma 5.7 Let x0 ∈K4. Then it holds
B(x0) = (L(x0))∗
and
L(x0) = (B(x0))∗.
Proof Obviously, we prove only the ﬁrst equality. The inclusion B(x0) ⊂(L(x0))∗
is obvious: consider any y ∈L(x0) and thus y⊤∇gi(x0) ≦0, ∀i ∈I (x0). Thus, for
ui ≧0, i ∈I (x0), we have 
i∈I (x0) ui y⊤∇gi(x0) ≦0. This shows that B(x0) ⊂
(L(x0))∗. The opposite inclusion is a direct consequence of Farkas’ theorem (see
Theorem 2.28).
□
We are now able to prove, under assumption (5.1), the celebrated Karush-Kuhn-
Tucker conditions for (P4), perhaps the most important theorem for this kind of
mathematical programming problems.
Theorem 5.8 (Karush-Kuhn-Tucker) Let x0 ∈K4 be a local solution of (P4) and let
(5.1)beveriﬁed,i.e.letbeveriﬁedtheGuignard-Gould-Tolleconstraintqualiﬁcation.
Then, there exist multipliers (“Karush-Kuhn-Tucker multipliers”) u1, . . . , um, such
that
∇f (x0) +
m

i=1
ui∇gi(x0) = 0,
(5.2)
uigi(x0) = 0, i = 1, . . . , m,
(5.3)
ui ≧0, i = 1, . . . , m.
(5.4)
Proof We have proved in Theorem 4.24, that if x0 ∈K4 is a local solution of (P4),
then
−∇f (x0) ∈(T (K4, x0))∗.
But if (5.1) holds, then we can write the above relation as
−∇f (x0) ∈(L(x0))∗
and, on the grounds of Lemma 5.7,
−∇f (x0) ∈B(x0).
Consequently, there exist multipliers ui ≧0, i ∈I (x0), such that

5.1 First-Order Conditions
131
Fig.
5.1 Geometric
interpretation
of
the
Karush-Kuhn-Tucker
conditions:
−∇f (x0) =
u1∇g1(x0) + u2∇g2(x0) with u1, u2 ≧0, g3 is not active at x0. f decreases in the direction
−∇f (x0) and f attains a local minimum at x0
−∇f (x0) =

i∈I (x0)
ui∇gi(x0).
(5.5)
Now, taking ui = 0 for all i /∈I (x0), the thesis of the theorem is proved.
□
By using the Lagrangian function (here perhaps it is better to speak of Lagrange-
Kuhn-Tucker function)
L (x, u) = f (x) +
m

i=1
uigi(x),
the conditions (5.2)–(5.3)–(5.4) of Theorem 5.8 can be rewritten in the form
∇xL (x0, u) = 0;
uigi(x0) = 0, i = 1, . . . , m;
ui ≧0, i = 1, . . . , m.
Note that for I (x0) = ∅, the Karush-Kuhn-Tucker conditions collapse to the sta-
tionarity condition ∇f (x0) = 0. If I (x0) ̸= ∅, relation (5.5) says that the steepest
descent direction (i.e. negative gradient) of the objective function, −∇f (x0), is a
conic combination of the gradients of the active constraint functions (see Fig. 5.1).
This means that in general the active constraints could be violated if we move x0
along a descent direction of f at x0.
We insist on the fact that the Karush-Kuhn-Tucker theorem (and also the Fritz
John theorem) gives necessary optimality conditions, but not sufﬁcient ones.

132
5
Constrained Optimization Problems with Inequality Constraints
Example 5.9 Consider the problem

min(x1 + x2)
subject to: −(x1)2 −(x2)2 + 2 ≦0.
The point x0 = (1, 1)⊤veriﬁes the Karush-Kuhn-Tucker conditions with u1 = 1
2,
but x0 is not a local optimum for the problem.
We now give for (P4) some sufﬁcient ﬁrst-order optimality conditions, based on the
Karush-Kuhn-Tucker conditions.
Theorem 5.10 Let x0 ∈K4, let f be pseudoconvex on the open convex set X ⊂Rn,
and let every constraint gi, i ∈I (x0), be quasiconvex on X. Let x0 verify the Karush-
Kuhn-Tucker conditions (5.2)–(5.3)–(5.4). Then x0 is a solution of (P4).
Proof Being gi, i ∈I (x0), a quasiconvex function on X ⊂Rn, we have, for every
i ∈I (x0) and for every x ∈K4 :
gi(x) ≦gi(x0) = 0 ⇒(x −x0)⊤∇gi(x0) ≦0.
Being the multiplier ui ≧0, i ∈I (x0), it will hold, for every x ∈K4 :

i∈I (x0)
ui(x −x0)⊤∇gi(x0) ≦0.
As ui = 0, ∀i /∈I (x0), it holds
(x −x0)⊤∇gi(x0) ≦0.
m

i=1
ui(x −x0)⊤∇gi(x0) ≦0, ∀x ∈K4.
From relation (5.2) of the Karush-Kuhn-Tucker conditions, we obtain
(x −x0)⊤

∇f (x0) +
m

i=1
ui∇gi(x0)

= 0,
i.e.
(x −x0)⊤∇f (x0) +
m

i=1
(x −x0)⊤ui∇gi(x0) = 0.
Hence, it will hold, as m
i=1 ui(x −x0)⊤∇gi(x0) ≦0, ∀x ∈K4,
(x −x0)⊤∇f (x0) ≧0, ∀x ∈K4.

5.1 First-Order Conditions
133
But, being f pseudoconvex on X, we have
f (x) ≧f (x0), ∀x ∈K4.
□
We note that the quasiconvexity of the objective function f, together with the
quasiconvexity of every constraint gi, i ∈I (x0), does not imply that the Karush-
Kuhn-Tucker conditions are sufﬁcient for x0 to be a global minimum point for (P4).
Consider, e.g. the problem
⎧
⎨
⎩
min(1 −x)3, x ∈R
subject to: x −2 ≦0,
−x ≦0.
The objective function is quasiconvex (and quasiconcave), the point x0 = 1 satisﬁes
the Karush-Kuhn-tucker conditions with u1 = 0, u2 = 0, but the minimum occurs
at x = 2.
A more general sufﬁcient optimality condition for (P4), under the assumptions
on x0, the objective function f and every constraint gi, i ∈I (x0), contained in
Theorem 5.10, is:
(x −x0)⊤∇xL (x0, u) ≧0, ∀x ∈K4,
(5.6)
uigi(x0) = 0, i = 1, . . . , m.
Condition (5.6) is called by Mangasarian [12] “minimum principle” optimality
condition. The above assertion is quite obvious, on the grounds of the proof of
Theorem 5.10. The same is true if we assume, instead of the pseudoconvexity of
f and the quasiconvexity of gi, i ∈I (x0), that the Lagrangian function L (x, u) is
pseudoconvex, with respect to x, on the open convex set X ⊂Rn. This condition
is neither stronger nor weaker than the previous ones, as we recall that the sum
of pseudoconvex or quasiconvex functions is not necessarily a pseudoconvex nor a
quasiconvex function.
It is also possible to obtain sufﬁcient optimality conditions for (P4), starting from
the Fritz John conditions, but under rather strong assumptions.
Theorem 5.11 Let x0 ∈K4; let f be convex and every gi, i ∈I (x0), be strictly
convexontheopenconvexset X ⊂Rn.If(x0, u0, u)satisﬁestheFritzJohnconditions
of Theorem 5.5, then x0 is a solution of (P4).
Proof Since we have
u0∇f (x0) +

i∈I (x0)
ui∇gi(x0) = 0,
with u0 ≧0, ui ≧0, i ∈I (x0), not all zero, it follows from Gordan’s theorem of
the alternative that the system

134
5
Constrained Optimization Problems with Inequality Constraints

z⊤∇f (x0) < 0
z⊤∇gi(x0) < 0, i ∈I (x0),
(5.7)
has no solution z ∈Rn. Consequently, the system

f (x) −f (x0) < 0
gi(x) −gi(x0) ≦0, i ∈I (x0)
(5.8)
has no solution x ∈X, for it did have a solution ˆx ∈X, then ˆx ̸= x, and
0 > f (ˆx) −f (x0) ≧(ˆx −x0)⊤∇f (x0)
by convexity of f , and
0 ≧gi(ˆx) −gi(x0) > (ˆx −x0)⊤∇gi(x0), i ∈I (x0),
by strict convexity of every gi, i ∈I (x0). This contradicts (5.7) if we set z = ˆx −x0.
Recalling that gi(x0) = 0, i ∈I (x0), we have from (5.8) that
f (x0) > f (x)
gi(x) ≦0, i ∈I (x0)
gi(x) ≦0, i /∈I (x0)
has no solution x ∈X. Since g(x0) ≦0, x0 is in K4 and hence x0 solves (P4).
□
A similar result will be given for (P5) in the next chapter, but with weaker assump-
tions (see Theorem 6.10).
It is also possible to get ﬁrst-order sufﬁcient optimality conditions for (P4) in
absence of convexity or generalized convexity assumptions on the functions involved
in the problem. We obtain however only local optimality conditions and under rather
strong assumptions. The following result is due to John [3]; see Stoer and Witzgall
[13].
Theorem 5.12 Let x0 ∈K4 verify the Fritz John conditions of Theorem 5.5, with
multipliers u0, ui, i = 1, . . . , m. If
rk
⎡
⎢⎣
u0
∂f
∂x1 (x0) u1
∂g1
∂x1 (x0) · · · um
∂g1
∂x1 (x0)
...
...
...
...
u0
∂f
∂xn (x0) u1
∂gm
∂xn (x0) · · · um
∂gm
∂xn (x0)
⎤
⎥⎦= n,
then x0 is a local minimum point for (P4).
We shall give the proof of this result in the next chapter, with reference to
problem (P5).

5.1 First-Order Conditions
135
Another ﬁrst-order sufﬁcient optimality condition for (P4) is obtained by means
of invex functions (Deﬁnition 3.33).
Theorem 5.13 Let x0 ∈K4 and let the objective function f and the constraints
gi, i = 1, . . . , m, be invex functions, with respect to a same vector-valued function
η(x1, x2), on the open set X ⊂Rn. If x0 satisﬁes the Karush-Kuhn-Tucker conditions
(5.2)–(5.3)–(5.4) of Theorem 5.8, then x0 is a solution of (P4).
Proof For any x ∈K4, we have
f (x) −f (x0) ≧η(x, x0)⊤∇f (x0) = −η(x, x0)⊤
m

i=1
ui∇gi(x0),
by the Karush-Kuhn-Tucker conditions. Then we have
−η(x, x0)⊤
m

i=1
ui∇gi(x0) ≧−
 m

i=1
uigi(x) −
m

i=1
uigi(x0)

,
being ui ≧0, ∀i and being every gi invex with respect to a common function η.
The right-hand side of the last expression, thanks to the complementary slackness
conditions, is given by
−
m

i=1
uigi(x) ≧0,
being ui ≧0, ∀i and gi(x) ≦0, ∀x ∈K4. So, we have, for every x ∈K4,
f (x) ≧f (x0),
i.e. x0 is a solution of (P4).
□
It is interesting to know when a ﬁnite collection of functions is made of invex func-
tions, with respect to a common vector-valued function η. The answer is contained
in a result of Martínez-Legaz [14], we report for the reader’s convenience.
Theorem 5.14 Let f1, .., f p be differentiable functions deﬁned on an open subset
X of Rn. The following statements are equivalent:
(i) The functions f1, .., f p are invex with respect to the same η.
(ii) The functions p
i=1 λi fi, λ1 ≧0, . . . , λp ≧0, are invex with respect to the
same η.
(iii) The functions p
i=1 λi fi, λ1 ≧0, . . . , λp ≧0, are invex.
(iv) For every λ1 ≧0, . . . , λp ≧0, every stationary point of p
i=1 λi fi is a global
minimum point.

136
5
Constrained Optimization Problems with Inequality Constraints
Proof We ﬁrst recall a theorem of the alternative due to Gale (Gale [30]; see also
Chap. 2, p. 43): For a given matrix A of order (m, n) and a given vector b ∈Rm,
either the system
Ax ≦b
has a solution x ∈Rn, or the system
A⊤λ = 0, b⊤λ = −1
has a solution λ ≧0, but never both. In other words, if a system of the type Ax ≦b
has no solution x ∈Rn, then there exists λ ∈Rm
+ such that
m

i=1
λi Ai = 0 and
m

i=1
λibi = −1,
where Ai is the ith row of A.
Now we prove the theorem. Implications (i) ⇒(ii) ⇒(iii) ⇒(iv) are obvious,
so we have to prove only the implication (iv) ⇒(i). Assume, by contradiction, that
there is no vector-valued function η : X × X →Rn such that
fi(y) ≧fi(x) + η(x, y)⊤∇fi(x), x, y ∈X, i = 1, . . . , p.
In other words, there exist x, y ∈X such that the system
η(x, y)⊤∇fi(x) ≦fi(y) −fi(x), i = 1, . . . , p,
in the unknown vector η(x, y) has no solution. Hence, by the theorem of the alter-
native of Gale above recalled, there is λ ∈Rp
+ such that p
i=1 λi∇fi(x) = 0 and
p
i=1 λi( fi(y) −fi(x)) = −1.Therefore,p
i=1 λi fi(x)hasastationarypointwhich
is not a global minimum, since
p

i=1
λi fi(y) =
p

i=1
λi fi(x) −1 <
p

i=1
λi fi(x).
This contradicts (iv).
□
Therefore, not always invex functions are a useful tool in obtaining sufﬁcient
optimality conditions for (P4), as f and each gi can be individually invex, but only
with respect to different η. Ben-Israel and Mond [15] consider the following example.
Example 5.15 Consider the problem

min 1
2(x −1)2, x ∈R,
subject to: x3 + x ≦0.

5.2 Constraint Qualiﬁcations
137
If we take x = 0, u1 = 0, the Karush-Kuhn-Tucker conditions are satisﬁed. Here
f is convex (and therefore invex) and g is pseudoconvex (and therefore invex), but
for u1 = 1 the Lagrangian function L = f + u1g = x3 + 1
2 x2 + 1
2 is not invex, i.e.
f and g are invex with respect to different η, so the sufﬁciency result of Theorem
5.13 is not applicable, although, of course, x = 0 is a global minimum point, by
Theorem 5.10.
5.2
Constraint Qualiﬁcations
In the previous section, we obtained the Karush-Kuhn-Tucker conditions under the
constraint qualiﬁcation (5.1). In other words, this condition assures that in Theorem
5.5 of Fritz John it holds u0 = 1. We wish to stress that the question of constraint
qualiﬁcations (for (P4) or for the more general problem (P5) or also for other more
general mathematical programming problems) is not always related to the geometric
structureofthefeasiblesetaroundtheoptimalpoint x0,suchasthepresenceofacusp,
as suggested, e.g. by Mangasarian [12]. Constraint qualiﬁcations are indeed related
to the functional form of the constraints. If we reconsider the problem of Example
5.6, we see that the feasible set present a cusp at the optimal point x0 = (0, 0)⊤.
We have seen that the Fritz John conditions for the said problem are veriﬁed at x0
only by u0 = 0. As a matter of fact, at x0 = (0, 0)⊤no constraint qualiﬁcation is
satisﬁed by the constraints of the problem. However, the presence of a cusp is neither
necessary nor sufﬁcient to cause the Karush-Kuhn-Tucker conditions to fail at an
optimal solution. Let us add to the problem of Example 5.6 a new constraint:
x2 −x1 ≦0.
Clearly, the feasible set remains the same (the new constraint is therefore redun-
dant), but now the problem is qualiﬁed, i.e. the Fritz John conditions are satisﬁed at
x0 = (0, 0)⊤with u0 > 0; hence the Karush-Kuhn-Tucker conditions hold at x0.
We now give an overview of the main (but not all!) constraint qualiﬁcations
proposed in the literature, with reference to (P4). Let x0 ∈K4.
1. Guignard-Gould-Tolle constraint qualiﬁcation. It is just condition (5.1):
(L(x0))∗= (T (K4, x0))∗,
which can be equivalently expressed as
L(x0) = P(K4, x0) ≡cl(conv(T (K4, x0))),
or also as
L(x0) = (T (K4, x0))∗∗.

138
5
Constrained Optimization Problems with Inequality Constraints
See Guignard [9], Gould and Tolle [10, 11]. Gould and Tolle [10] proved that
this condition is necessary and sufﬁcient for the Karush-Kuhn-Tucker conditions to
be veriﬁed by any (differentiable) objective function of which x0 is a local optimal
solution on K4. In this sense the Guignard-Gould-Tolle constraint qualiﬁcation is the
weakest possible among constraint qualiﬁcations. See also the next chapter.
2. Abadie constraint qualiﬁcation. It is expressed as
L(x0) = T (K4, x0).
Therefore, the Abadie constraint qualiﬁcation requires that T (K4, x0) be a convex
cone. Obviously, the Abadie constraint qualiﬁcation implies the Guignard-Gould-
Tolle constraint qualiﬁcation. A point x0 ∈K4 satisfying the Abadie constraint qual-
iﬁcation is called by Hestenes [16] a “regular point”, whereas x0 ∈K4 satisfying
the Guignard-Gould-Tolle constraint qualiﬁcation is called, by the same author, a
“quasiregular point”.
3. Kuhn-Tucker constraint qualiﬁcation or, better, Karush-Kuhn-Tucker constraint
qualiﬁcation. It is expressed as
L(x0) = A(K4, x0).
Obviously, from the deﬁnitions of the related cones, the Karush-Kuhn-Tucker con-
straint qualiﬁcation implies the Abadie constraint qualiﬁcation.
4. Zangwill constraint qualiﬁcation (see Zangwill [17]). It is expressed as
L(x0) = cl(F(K4, x0)).
For what previously seen, we have that the Zangwill constraint qualiﬁcation
implies the Karush-Kuhn-Tucker constraint qualiﬁcation.
We note that all the above implications are strict.
5. Cottle constraint qualiﬁcation or Arrow-Hurwicz-Uzawa constraint qualiﬁca-
tion. It is expressed as
Lo(x0) ̸= ∅
or, equivalently, as
L(x0) = cl(Lo(x0)).
This qualiﬁcation is considered, as a particular case of a more general constraint
qualiﬁcation, by Arrow et al. [1], who are, therefore, the ﬁrst authors to have intro-
duced this constraint qualiﬁcation. In its original form the Cottle constraint qualiﬁ-
cation requires that the system

i∈I (x0)
ui∇gi(x0) = 0, ui ≧0, i ∈I (x0),

5.2 Constraint Qualiﬁcations
139
has the zero sulution only, i.e. the vectors ∇gi(x0), i ∈I (x0), have to be positively
linearly independent. Indeed, by applying Gordan’s theorem of the alternative (see
p. 44), we see that the two formulations are equivalent.
We have seen, in Theorem 5.3 and in Corollary 5.4, that the Cottle constraint
qualiﬁcation implies the Zangwill constraint qualiﬁcation.
The Cottle constraint qualiﬁcation has been “reﬁned” by Abadie [7] and by Arrow
etal.[1].Inordertodescribetheseconstraintqualiﬁcations,weintroducetwovariants
of the linearized cone L(x0), considered, respectively by Abadie and by Arrow,
Hurwicz and Uzawa.
L1(x0) =
 y ∈Rn : ∇gi(x0)⊤y < 0, if gi is not linear, i ∈I (x0);
∇gi(x0)⊤y ≦0, if gi is linear, i ∈I (x0)

.
L2(x0) =
 y ∈Rn : ∇gi(x0)⊤y < 0, if gi is not pseudoconcave, i ∈I (x0);
∇gi(x0)⊤y ≦0, if gi is pseudoconcave, i ∈I (x0)

.
6. Abadie constraint qualiﬁcation II. It is expressed as
L1(x0) ̸= ∅
or, equivalently, as
L(x0) = cl(L1(x0)).
7. Arrow-Hurwicz-Uzawa constraint qualiﬁcation II. It is expressed as
L2(x0) ̸= ∅
or, equivalently, as
L(x0) = cl(L2(x0)).
We have to note at once that if all functions gi, i ∈I (x0), are pseuconcave or even
concave, then the Arrow-Hurwicz-Uzawa constraint qualiﬁcation II is automatically
satisﬁed.Arrowetal.[1]callthiscaseReverseconstraintqualiﬁcation.Ifallfunctions
gi, i ∈I (x0), are linear (or even linear afﬁne), the Abadie constraint qualiﬁcation II
and the Arrow-Hurwicz-Uzawa constraint qualiﬁcation II are automatically satisﬁed.
Hence, for a Linear Programming Problem (see Chap. 9) no constraint qualiﬁcation
is required.
Theorem 5.16 Let be x0 ∈K4. Then
Lo(x0) ⊂L1(x0) ⊂L2(x0) ⊂F(K4, x0) ⊂A(K4, x0) ⊂T (K4, x0) ⊂L(x0).
Proof We prove only the inclusions not previously already proved. It is easy to
see that Lo(x0) ⊂L1(x0) ⊂L2(x0). We now prove that L2(x0) ⊂F(K4, x0). Let
y ∈L2(x0); we claim that gi(x0 + δy) ≦0 with δ > 0 being sufﬁciently small for

140
5
Constrained Optimization Problems with Inequality Constraints
all i ∈I (x0) such that gi is pseudoconcave. Otherwise gi(x0 + δy) > 0 = gi(x0)
and then δ∇gi(x0)⊤y > 0 by the pseudoconcavity, which is a contradiction. For
i ∈I (x0), gi is not pseudoconcave, the considerations are similar. In any case y ∈
F(K4, x0) and hence L2(x0) ⊂F(K4, x0).
□
Hence, we have the following implications:
Cottle c. q. ⇒Abadie c. q. II ⇒Arrow-Hurwicz-Uzawa c. q. II
⇒Zangwill c. q. ⇒Karush-Kuhn-Tucker c. q. ⇒Abadie c. q.
⇒Guignard-Gould-Tolle c. q.
8. Slater constraint qualiﬁcation. It is expressed as: every constraint gi, i ∈I (x0),
is pseudoconvex and there exists ¯x ∈K4 such that gi(¯x) < 0, ∀i ∈I (x0).
Theorem 5.17 TheSlaterconstraintqualiﬁcationimpliestheCottleconstraintqual-
iﬁcation.
Proof Suppose that the Slater constraint qualiﬁcation is satisﬁed. For i ∈I (x0), we
have gi(¯x) < gi(x0) = 0. Therefore, ∇gi(x0)⊤(¯x −x0) < 0 because gi is pseudo-
convex. Let be y = ¯x −x0, then y ∈Lo(x0). This means Lo(x0) ̸= ∅and hence the
Cottle constraint qualiﬁcation holds.
□
TheoriginalSlaterconstraintqualiﬁcationwasgivenunderconvexityassumptions
ontheconstraints gi,i ∈I (x0).Notethat,underthisassumption,theSlaterconstraint
qualiﬁcation and the Cottle constraint qualiﬁcation are equivalent assertions. The
“relaxed” Slater constraint qualiﬁcation here presented, is due to Mangasarian [12].
9. Linear independence constraint qualiﬁcation. It is expressed as: the gradients
∇gi(x0), i ∈I (x0),
are linearly independent.
It is immediate to see that
Linear independence c. q. ⇒Cottle c. q.
Indeed, if the gradients of the active constraints at x0 are linearly independent,
they are also positively linearly independent, i.e. the Cottle constraint qualiﬁcation
holds. Note, moreover, that the Linear independence constraint qualiﬁcation assures
the uniqueness of the Karush-Kuhn-Tucker multipliers ui, i = 1, . . . , m, in relations
(5.2)–(5.3)–(5.4) of Theorem 5.8. We shall show in the next chapter, with reference to
problem (P5), a necessary and sufﬁcient condition for the uniqueness of the Karush-
Kuhn-Tucker multipliers.
Here, we have considered constraint qualiﬁcations for differentiable functions,
some of these qualiﬁcations have been extended for directionally differentiable func-
tions in Giorgi et al. [18].

5.3 Second-Order Conditions
141
5.3
Second-Order Conditions
We have already considered both second-order necessary and second-order sufﬁcient
optimality conditions in unconstrained optimization problems and in “classical” con-
strained optimization problems. In absence of convexity or some kind of generalized
convexity of the functions involved in an optimization problem, the second-order
sufﬁcient conditions are an important tool to determinate whether a “candidate” to
be a (local) optimal point is indeed a local solution of the problem. In this section we
give the basic second-order necessary optimality conditions and the basic second-
order sufﬁcient optimality conditions for (P4). We shall reconsider these questions,
with further insights, in the next chapter, with reference to problem (P5).
Wemaketheassumptionsthatallfunctionsinvolvedin(P4)aretwice-continuously
differentiable on the open set X ⊂Rn.
Let be x0 ∈K4 and let the pair (x0, u) verify the Karush-Kuhn-Tucker conditions
∇f (x0) +
m

i=1
ui∇gi(x0) = 0,
uigi(x0) = 0, i = 1, . . . , m,
ui ≧0, i = 1, . . . , m.
We deﬁne the set of strictly active constraints at x0 ∈K4 :
I +(x0, u) =

i ∈I (x0) : ui > 0 in the KKT conditions

⊂I (x0).
We introduce the set
G =

x ∈K4 : gi(x) = 0, ∀i ∈I +(x0, u)

.
Now we introduce two “regularity conditions” :
(R1) : The Bouligand tangent cone T (G, x0) is equal to the following “modiﬁed”
linearizing cone or critical cone or cone of critical directions
Z(x0) =
 y ∈Rn : ∇gi(x0)⊤y ≦0, ∀i ∈I (x0) \ I +(x0, u);
∇gi(x0)⊤y = 0, ∀i ∈I +(x0, u)

i.e.
T (G, x0) = Z(x0).
(R2) : The vectors ∇gi(x0), i ∈I +(x0, u), are linearly independent and there
exists y ∈Rn such that

142
5
Constrained Optimization Problems with Inequality Constraints
∇gi(x0)⊤y < 0, ∀i ∈I (x0) \ I +(x0, u);
∇gi(x0)⊤y = 0, ∀i ∈I +(x0, u).
Note that this last condition is a restricted version of the Cottle constraint qualiﬁ-
cation. With reference to (P5), this condition has been introduced by Kyparisis [19].
It is not difﬁcult to prove that x0 ∈K4 satisﬁes (R2) if and only if the system

i∈I (x0)
ui∇gi(x0) = 0, ui ≧0, ∀i ∈I (x0) \ I +(x0, u)
admits the zero solution only. In other words, the vectors ∇gi(x0), i ∈I (x0) \
I +(x0, u), are positively linearly independent. We shall give the proof in the next
chapter, for problem (P5).
We can easily prove the following result on necessary second-order optimality
conditions for (P4).
Theorem 5.18 Let x0 ∈K4 be a local solution of problem (P4) and let the pair
(x0, u) verify the Karush-Kuhn-Tucker conditions. Then it holds
y⊤∇2
xL (x0, u)y ≧0, ∀y ∈T (G, x0).
If, moreover, condition (R1) holds, then we have
y⊤∇2
xL (x0, u)y ≧0, ∀y ∈Z(x0).
(5.9)
Proof Given the Lagrangian function L (x, u) = f (x) + u⊤g(x), we have obvi-
ously, thanks to the complementary slackness conditions,
L (x, u) = f (x), ∀x ∈G.
As x0 ∈K4 is a local solution of (P4), this point is also a local solution of
min f (x) = L (x, u), x ∈G.
But the conditions of Karush-Kuhn-Tucker at x0 give ∇xL (x0, u) = 0. Applying
Theorem 4.26, we have
y⊤∇2
xL (x0, u)y ≧0, ∀y ∈T (G, x0).
If T (G, x0) = Z(x0), i.e. (R1) holds, then obviously, we have relation (5.9).
□
Now we prove that (R2) is sufﬁcient for the validity of (R1). We follow closely
Elster and others [20].

5.3 Second-Order Conditions
143
Theorem 5.19 Let be x0 ∈K4. Then
(R2) ⇒(R1).
Proof Let be I +(x0, u) ̸= ∅. Being the vectors ∇gi(x0), i ∈I +(x0, u), linearly
independent, there exists a matrix A, of order (n, card(I +)), such that
det(∇gI +(x0)⊤A) ̸= 0.
(5.10)
(For brevity we denote I +(x0, u) by I +).
Now let us consider a vector y ∈Rn, y ̸= 0, which veriﬁes (R2), as well as the
system, in zI + and t :
gi(x0 + AzI + + ty) = 0, i ∈I +.
(5.11)
The system (5.11) admits the solution (zI +, t0)⊤= (0, . . . , 0, 0)⊤. By (5.10), there
exist, owing to the Implicit Function Theorem, in a neighborhood U0 of t0 = 0, the
functions zi(t), i ∈I +, with
zi(0) = 0, i ∈I +
gi(x0 + AzI +(t) + ty) = 0, i ∈I +, t ∈U0.
(5.12)
By differentiating (5.12) with respect to t at t = 0, we get
∇gi(x0)⊤(A˙zI +(0) + y) = 0, i ∈I +.
From ∇gi(x0)⊤y = 0, ∀i ∈I +, it follows
∇gi(x0)⊤A˙zI +(0) = 0, i ∈I +.
By (5.10) we obtain ˙zI +(0) = 0 and therefore
lim
t→0
zI +(t)
t
= 0.
(5.13)
Now we prove that there exists t1 such that t1 > 0, so that the curve
x(t) = x0 + AzI +(t) + ty, t ∈[0, t1]
lies entirely in G. To this purpose, let us develop the functions gi, i ∈I (x0) \ I +, at
x0, with respect to AzI +(t) + ty, keeping in mind that gi(x0) = 0. It follows
gi(x0 + AzI +(t) + ty) = ∇gi(x0)⊤(AzI +(t) + ty) + o(∥AzI +(t) + ty∥)
= t∇gi(x0)⊤y + o(∥AzI +(t) + ty∥) + ∇gi(x0)⊤AzI +(t).

144
5
Constrained Optimization Problems with Inequality Constraints
From (5.13) we obtain
∇gi(x0)⊤AzI +(t) = o(t)
and
gi(x0 + AzI +(t) + ty) = t∇gi(x0)⊤y + o(t).
As y satisﬁes condition (R2), we have ∇gi(x0)⊤y < 0, ∀i ∈I (x0) \ I +. There
exists therefore t0 > 0 such that, for t ∈(0, t0), we have
gi(x0 + AzI +(t) + ty) < 0, ∀i ∈I (x0) \ I +.
Taking into account also relation (5.12), it follows the existence of t1 > 0 such that
the curve x(t), t ∈[0, t1] , lies entirely in G. It is then possible to build a sequence

xk
, xk ∈G, with xk = x0 + AzI +  1
k

+ 1
k y, with the property xk y∥y∥−1
→
x0. We
have xk ∈G and for k > 1
t1 , taking relation (5.13) into account,
lim
k→∞
xk −x0
		xk −x0		 = lim
k→∞
AzI +( 1
k ) + 1
k y
		AzI +( 1
k ) + 1
k y
		 = lim
k→∞
AzI +( 1
k )k + y
		AzI +( 1
k )k + y
		 =
y
∥y∥,
i.e. for I + ̸= ∅, we have the conclusion of the theorem. For I + = ∅, condition (R2)
is the Cottle constraint qualiﬁcation, and also in this case, the theorem holds.
□
We point out that if the gradients ∇gi(x0), i ∈I (x0), are linearly independent,
thensurely(R2)issatisﬁed.Weobtaintherefore,asacorollary,thefollowingclassical
result on second-order necessary optimality conditions for (P4).
Corollary 5.20 Let x0 ∈K4 be a local solution of (P4) and let the gradients
∇gi(x0), i ∈I (x0), be linearly independent. Then, there exists a unique vector of
Karush-Kuhn-Tucker multipliers (u1, . . . , um) such that the Karush-Kuhn-Tucker
conditions are veriﬁed at x0. Moreover, it holds
y⊤∇2
xL (x0, u)y ≧0, ∀y ∈Z(x0).
We note that, in absence of constraints, i.e. with reference to unconstrained opti-
mization problems, we have then the following classical result: if x0 is a local mini-
mum point, then ∇2 f (x0) is positive semideﬁnite.
Theorem 5.18 and Corollary 5.20 do not give a sufﬁcient optimality condition.
Example 5.21 Consider the problem

min((x1)3 + x2)
subject to: −x2 ≦0,
(x1, x2) ∈R2. The point x0 = (0, 0)⊤is the unique solution of the Karush-Kuhn-
Tucker conditions, with multiplier u = 1. The linear constraint is active at x0 and

5.3 Second-Order Conditions
145
∇g(x0) = (0, −1)⊤. The Hessian matrix of the Lagrangian function at x0 is the zero
matrix, but x0 is not a local optimum because f (t, 0) < f (0, 0) for all t < 0.
Theorem 5.22 Let x0 ∈K4 and let the Karush-Kuhn-Tucker conditions be satisﬁed
by the pair (x0, u). If
y⊤∇2
xL (x0, u)y > 0,
∀y ̸= 0,
(5.14)
y ∈T (K4, x0) ∩

y : ∇gi(x0)⊤y = 0, ∀y ∈I +(x0, u)

,
then x0 is a strict local minimum point for (P4).
Proof We perform the proof in an indirect way. We suppose that f has no strict local
minimizer at x0 ∈K4. Then, there exists a sequence

xk
⊂K4, with xk
y→x0 and
f (xk) −f (x0) ≦0, with k ∈N. It follows
lim
k→∞
f (xk) −f (x0)
		xk −x0		
= ∇f (x0)⊤y ≦0
and, being gi(xk) ≦0, gi(x0) = 0, ∀i ∈I (x0) :
lim
k→∞
gi(xk) −gi(x0)
		xk −x0		
= ∇gi(x0)⊤y ≦0, ∀i ∈I (x0).
Therefore, we obtain
L (xk, u) −L (x0, u) = f (xk) −f (x0) +

i∈I (x0)
ui

gi(xk) −gi(x0)

≦0.
From ∇xL (x0, u) = 0, it follows
lim
k→∞
L (xk, u) −L (x0, u)
		xk −x0		2
= 1
2 y∇2
xL (x0, u)y ≦0.
By assumption y ∈T (K4, x0). For I +(x0, u) = ∅, we have therefore a contradiction
with relation (5.14). If I +(x0, u) ̸= ∅, let us suppose that for an index i∗∈I +(x0, u)
it holds ∇gi∗(x0)⊤y < 0. Multiplying ∇xL (x0, u) by y and taking into account that
∇f (x0)⊤y ≦0 and ui > 0, ∀i ∈I +(x0, u), we have
0 = ∇xL (x0, u)⊤y = ∇f (x0)⊤y +

i∈I +(x0,u)
ui∇gi(x0)⊤y < 0,
and hence a contradiction. Therefore, we have ∇gi(x0)⊤y = 0, ∀i ∈I +(x0, u), and
we get the thesis of the Theorem.
□

146
5
Constrained Optimization Problems with Inequality Constraints
As it holds always T (K4, x0) ⊂L(x0), we can write the thesis of the previous
theorem in a stronger form, which is the usual form of the second-order optimality
conditions for (P4) :
y⊤∇2
xL (x0, u)y > 0, ∀y ̸= 0, y ∈Z(x0),
where Z(x0) is the critical cone previously introduced
Z(x0) =
 y ∈Rn : ∇gi(x0)⊤y ≦0, ∀i ∈I (x0) \ I +(x0, u),
∇gi(x0)y = 0, ∀i ∈I +(x0, u)

.
This last formulation is essentially due to McCormick [21]. We may remark that
if I (x0) = I +(x0, u), i.e. the strict complementary slackness conditions hold at x0,
we have
y⊤∇2
xL (x0, u)y > 0, ∀y ̸= 0, y ∈Z1(x0),
with
Z1(x0) =

y ∈Rn : ∇gi(x0)⊤y = 0, ∀i ∈I (x0)

.
It is therefore possible to use, in this case, the criteria which assure that the
quadratic form
y⊤∇2
xL (x0, u)y
is positive deﬁnite on the set of nonzero solutions of the system described by Z1(x0).
See Chap. 1 and see, e.g. Chabrillac and Crouzeix [2] and Debreu [22].
Example 5.23 Consider the problem
⎧
⎪⎪⎨
⎪⎪⎩
min

k(x1)2 −x2

subject to: −(x1)2 −(x2 −1)2 + 1 ≦0,
(x1 + 1)2 + (x2)2 −1 ≦0,
−x1 −1 ≦0,
where k ∈R is a parameter.
The point x0 = (0, 0)⊤satisﬁes the Karush-Kuhn-Tucker conditions, with mul-
tipliers ( 1
2, 0, 0). Indeed, at this point the problem is qualiﬁed (why?). But only for
k > 1
2 and y1 > 0 the sufﬁcient optimality conditions of Theorem 5.22 are satisﬁed.
Then, for k > 1
2 the objective function has at (0, 0)⊤a strict local minimum over the
feasible set. For k = 1
2 it holds y⊤∇2
xL (x0, u)y = 0 and therefore, on the grounds
of Theorem 5.22, we cannot draw any conclusion.

5.4 Other Formulations of the Problem. Some Examples
147
5.4
Other Formulations of the Problem. Some Examples
On the grounds of what previously said, it is not difﬁcult to obtain the Karush-Kuhn-
Tucker conditions (or the Fritz John conditions) for other formulations of (P4). Let
us consider, for example, the following problem:
⎧
⎨
⎩
min f (x)
subject to: gi(x) ≦0, i = 1, . . . , m,
x ≧0,
in which there are, besides the functional constraints, non-negativity constraints on
the variables, i.e. x1 ≧0, . . . , xn ≧0, that is, in vector notation, x ≧0. This formu-
lation appears in all mathematical programming problems arising from economic
and ﬁnancial environments. Let us rewrite the above problem in the form

min f (x)
subject to: r(x) ≦0,
where
r(x) =
 g(x)
−x
!
, r : Rn →Rm+n.
Let us suppose that the functional constraints gi, i = 1, . . . , m, are qualiﬁed at
the solution point of the problem. The constraints −xi, i = 1, . . . , m, are surely
qualiﬁed, since they are linear functions. On the other hand, the Jacobian matrix of
−x is −I, a nonsingular matrix. The Karush-Kuhn-Tucker conditions at the solution
point x0 for the last problem are therefore
(i) ∇f (x0) +
m+n

i=1
ui∇ri(x0) = 0;
(ii) uiri(x0) = 0, i = 1, . . . , m + n;
(iii) ui ≧0, i = 1, . . . , m + n.
These conditions may be rewritten in the form
∇f (x0) +
m

i=1
ui,1 ∇gi(x0) +
n

i=1
ui,2(−ei) = 0;
uiri(x0) = 0, i = 1, . . . , m + n ⇔{ui,1gi(x0) = 0, i = 1, . . . , m;
ui,2(−x0
i ) = 0, i = 1, . . . , n};

148
5
Constrained Optimization Problems with Inequality Constraints
ui,1 ≧0, i = 1, . . . , m; ui,2 ≧0, i = 1, . . . , n.
In other words, we have
∇f (x0) +
m

i=1
ui,1∇gi(x0) =
n

i=1
ui,2ei ≧0;

∇f (x0) +
m

i=1
ui,1∇gi(x0)
⊤
x0 = 0;
ui,1gi(x0) = 0, i = 1, . . . , m;
ui,1 ≧0, i = 1, . . . , m.
We rewrite these last relations in a more usual way:
∇f (x0) +
m

i=1
ui∇gi(x0) ≧0;

∇f (x0) +
m

i=1
ui∇gi(x0)
⊤
x0 = 0;
uigi(x0) = 0, i = 1, . . . , m;
ui ≧0, i = 1, . . . , m.
These are the Karush-Kuhn-Tucker conditions for the problem considered.
For example, if we consider the problem

min f (x)
subject to: x ≧0,
and x0 ≧0 is a local solution of this problem, the related Karush-Kuhn-Tucker
conditions are
∇f (x0) ≧0; ∇f (x0)⊤x0 = 0.
We have seen in Chap. 4 that if f is differentiable and x0 ∈S is a local minimum
point of f over the closed convex set S ⊂Rn, then
∇f (x0)⊤(x −x0) ≧0, ∀x ∈S.

5.4 Other Formulations of the Problem. Some Examples
149
Being the nonnegative orthant of Rn, Rn
+, surely a closed convex set, the previous
relation becomes
∇f (x0)⊤(x −x0) ≧0, ∀x ≧0,
i.e.
(∇f (x0)⊤x −∇f (x0)⊤x0) ≧0, ∀x ≧0.
(5.15)
We will now use the following technical result:
a⊤x + b ≧0 for all x ≧0 if and only if a ≧0 and b ≧0 (a, b ∈Rn).
Using this simple result it follows that (5.15) holds if and only if
∇f (x0) ≧0 and ∇f (x0)⊤x0 ≦0.
(5.16)
Since ∇f (x0) ≧0 and x0 ≧0, we can conclude that (5.16) holds if and only if
∇f (x0) ≧0; ∇f (x0)⊤x0 = 0,
i.e. if and only if the Karush-Kuhn-Tucker conditions hold for the above problem.
Now we consider a maximization problem of the type
⎧
⎨
⎩
max f (x)
gi(x) ≦0, i = 1, . . . , m,
x ≧0.
We recall that max f (x) ⇔min {−f (x)} . If x0 is a local solution of the said
maximization problem and the constraints gi, i = 1, . . . , m, are qualiﬁed, we have
therefore that the following Karush-Kuhn-Tucker conditions hold:
−∇f (x0) +
m

i=1
ui∇gi(x0) ≧0;

−∇f (x0) +
m

i=1
ui∇gi(x0)
⊤
x0 = 0;
uigi(x0) = 0, i = 1, . . . , m;
ui ≧0, i = 1, . . . , m,
i.e.
∇f (x0) −
m

i=1
ui∇gi(x0) ≦0;

150
5
Constrained Optimization Problems with Inequality Constraints

∇f (x0) −
m

i=1
ui∇gi(x0)
⊤
x0 = 0;
uigi(x0) = 0, i = 1, . . . , m;
ui ≧0, i = 1, . . . , m.
For example, the problem
max f (x)
x ≧0,
presents at the local optimal solution x0, the following Karush-Kuhn-Tucker condi-
tions:
∇f (x0) ≦0; ∇f (x0)⊤x0 = 0.
For the reader’s convenience we write in Table 5.1 the Karush-Kuhn-Tucker con-
ditions related to various reformulations of problem (P4).
If we have a Linear Programming Problem (see Chap. 9) of the type
⎧
⎨
⎩
min c⊤x
Ax ≧b
x ≧0,
where c ∈Rn, c ̸= 0, b ∈Rm, and A is a matrix of order (m, n), then x0 ∈Rn is a
solution of the problem if and only if there exists a multipliers vector u ∈Rm such
that
(Ax0 −b)⊤u = 0;
Ax0 ≧b;
u ≧0;
x0 ≧0; A⊤u ≦c; (A⊤u −c)⊤x0 = 0.
We now consider some “linearization properties” related to a nonlinear program-
ming problem of the type (P4). We continue to assume that the functions involved
in (P4) are differentiable on the open set X ⊂Rn.
Theorem 5.24 (a) Let x0 ∈K4 be a solution of (P4) and let the constraints of (P4)
be qualiﬁed at x0. Then x0 is also a solution of the linearized problem
(P4)L :

min

x⊤∇f (x0)

subject to: (x −x0)⊤∇gi(x0) ≦0, i ∈I (x0).
(b) Let f be pseudoconvex on the open convex set X ⊂Rn and let every gi,
i ∈I (x0), be quasiconvex on X. If x0 is a solution of (P4)L, then x0 is also solution
of (P4).

5.4 Other Formulations of the Problem. Some Examples
151
Table 5.1 Karush-Kuhn-Tucker conditions for several reformulations of problem (P4)
Problem
K.K.T. conditions
(a)
"
min f (x)
gi(x) ≦0, i = 1, . . . , m.
∇f (x0) + m
i=1 ui∇gi(x0) = 0,
ui gi(x0) = 0, i = 1, . . . , m,
ui ≧0, i = 1, . . . , m.
(b)
"
min f (x)
gi(x) ≧0, i = 1, . . . , m.
∇f (x0) −m
i=1 ui∇gi(x0) = 0,
ui gi(x0) = 0, i = 1, . . . , m,
ui ≧0, i = 1, . . . , m.
(c)
"
max f (x)
gi(x) ≦0, i = 1, . . . , m.
∇f (x0) −m
i=1 ui∇gi(x0) = 0,
ui gi(x0) = 0, i = 1, . . . , m,
ui ≧0, i = 1, . . . , m.
(d)
"
max f (x)
gi(x) ≧0, i = 1, . . . , m.
∇f (x0) + m
i=1 ui∇gi(x0) = 0,
ui gi(x0) = 0, i = 1, . . . , m,
ui ≧0, i = 1, . . . , m.
(a1)
⎧
⎪⎨
⎪⎩
min f (x)
gi(x) ≦0, i = 1, . . . , m,
x ≧0.
∇f (x0) + m
i=1 ui∇gi(x0) ≧0;

∇f (x0) + m
i=1 ui∇gi(x0)
⊤x0 = 0;
ui gi(x0) = 0, i = 1, . . . , m;
ui ≧0, i = 1, . . . , m.
(b1)
⎧
⎪⎨
⎪⎩
min f (x)
gi(x) ≧0, i = 1, . . . , m,
x ≧0.
∇f (x0) −m
i=1 ui∇gi(x0) ≧0;

∇f (x0) −m
i=1 ui∇gi(x0)
⊤x0 = 0;
ui gi(x0) = 0, i = 1, . . . , m;
ui ≧0, i = 1, . . . , m.
(c1)
⎧
⎪⎨
⎪⎩
max f (x)
gi(x) ≦0, i = 1, . . . , m,
x ≧0.
∇f (x0) −m
i=1 ui∇gi(x0) ≧0;

∇f (x0) −m
i=1 ui∇gi(x0)
⊤x0 = 0;
ui gi(x0) = 0, i = 1, . . . , m;
ui ≧0, i = 1, . . . , m.
(d1)
⎧
⎪⎨
⎪⎩
max f (x)
gi(x) ≧0, i = 1, . . . , m,
x ≧0.
∇f (x0) + m
i=1 ui∇gi(x0) ≧0;

∇f (x0) + m
i=1 ui∇gi(x0)
⊤x0 = 0;
ui gi(x0) = 0, i = 1, . . . , m;
ui ≧0, i = 1, . . . , m.
Proof (a) Let be
K ′
4 =

x ∈X : (x −x0)⊤∇gi(x0) ≦0, i ∈I (x0)

,
i.e. K ′
4 is the feasible set for (P4)L.
Obviously, if x0 ∈K4, then x0 ∈K ′
4. If x0 ∈K4 is a solution of (P4) and some
constraint qualiﬁcation holds at x0, the usual Karush-Kuhn-Tucker conditions will
be satisﬁed:
∇f (x0) +
m

i=1
ui∇gi(x0) = 0,

152
5
Constrained Optimization Problems with Inequality Constraints
uigi(x0) = 0, i = 1, . . . , m,
ui ≧0, i = 1, . . . , m.
We have therefore ∇f (x0) = −m
i=1 ui∇gi(x0) and, from the complementary
slackness conditions, we have gi(x0) < 0, ui = 0, ∀i /∈I (x0).
Therefore,
m

i=1
uigi(x0) =

i∈I (x0)
uigi(x0) = 0
and
m

i=1
ui∇gi(x0) =

i∈I (x0)
ui∇gi(x0).
We have therefore that for every x ∈K ′
4:
(x0)⊤∇f (x0) = −(x0)⊤
m

i=1
ui∇gi(x0) = −(x0)⊤
i∈I (x0)
ui∇gi(x0)
= −

i∈I (x0)
ui(x0)⊤∇gi(x0) ≦−

i∈I (x0)
uix⊤∇gi(x0)
= x⊤∇f (x0) −x⊤#
∇f (x0) +

i∈I (x0)
ui∇gi(x0)
$
= x⊤∇f (x0),
which shows that x0 ∈K ′
4 is solution of (P4)L.
(b) We remark that K4 ⊂K ′
4, as if x ∈K4, we have, for every i ∈I (x0) :
gi(x) ≦gi(x0) = 0 ⇒(x −x0)⊤∇gi(x0) ≦0,
being the functions gi, i ∈I (x0), quasiconvex on the open convex set X ⊂Rn. If
x0 is a solution of (P4)L, we have
(x −x0)⊤∇f (x0) ≧0, ∀x ∈K ′
4.
But, being f pseudoconvex on X and being K4 ⊂K ′
4, we have
f (x0) ≦f (x), ∀x ∈K4.
□
We note that (P4)L is a linear programming problem and therefore, if the assump-
tions of Theorem 5.24 are veriﬁed, the same theorem may be a “solution test” for
(P4).
Some authors have observed that (P4) is equivalent to the following problem

5.4 Other Formulations of the Problem. Some Examples
153
⎧
⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩
min f (x)
g1(x) + (z1)2 = 0,
· · ·
gm(x) + (zm)2 = 0,
x ∈X ⊂Rn
where z ∈Rm is a vector of “auxiliary variables” or “slack variables”. This device
is also known as the “squared slack variables technique” for nonlinear programming
problems. See, e.g. the paper of Taylor [23]. We do not treat this question, but simply
remark that it is true that the above transformation reduces a nonlinear programming
problem with inequality constraints into a problem with only equality constraints
(“classical constrained optimization problem”), but it is also true that the number of
variables increases considerably. Moreover, the transformed problem may lose some
important properties of the original problem, such as the linearity of the constraints,
etc. This transformation, even if it is useful for some cases and considerations, does
not get rid of treating in a speciﬁc way the case of inequality constraints. See also
Bertsekas [5] for more formal considerations.
Finally, we make some considerations for the case when, in (P4), besides the
functional constraints gi(x) ≦0, i = 1, . . . , m, there is also an abstract constraint
or set constraint, given by a closed set C ⊂X ⊂Rn. In other words, we have a
problem of the type (we continue to assume differentiability of the functions involved
in the problem)
(P4)′ :

min f (x)
subject to: x ∈C ∩K4.
In this case the usual Fritz John conditions of Theorem 5.5 are no longer valid
and also several constraint qualiﬁcations have to be suitably modiﬁed, in order to
obtain the Karush-Kuhn-Tucker conditions. The following result is proved by Barbu
and Precupanu [24], Giorgi and Guerraggio [25], Nagahisa and Sakawa [26].
Theorem 5.25 Let x0 be a local solution of (P4)′. Then, there exist multipliers
u0 ≧0, u1 ≧0, . . . , um ≧0, not all zero, such that
−

u0∇f (x0) +
m

i=1
ui∇gi(x0)

∈(T1(C, x0))∗,
(5.17)
uigi(x0) = 0, i = 1, . . . , m,
where T1(C, x0) is any convex subcone of T (C, x0), with vertex at 0 ∈T1(C, x0).
The case T1(C, x0) = T (C, x0) is not excluded.
We remark that if it is possible to choose the largest convex subcone T1(C, x0)
of T (C, x0), in case T (C, x0) is not a convex cone, Theorem 5.25 will be sharper.
Treiman [27] has shown that there are inﬁnite convex subcones of the Bouligand
tangent cone. In Nonsmooth Analysis one of the most used of these convex subcones

154
5
Constrained Optimization Problems with Inequality Constraints
is the Clarke tangent cone. See Clarke [28]. Given S ⊂Rn and x0 ∈S, the cone
TC(S, x0) =
 y ∈Rn : ∀N(y), ∃N(x0), ∃λ > 0, ∀t ∈(0, λ),
∀¯x ∈N(x0) ∩S, ∃¯y ∈N(y) : ¯x + t ¯y ∈S

,
is called Clarke tangent cone to S at x0. See also Chap. 10. This cone is closed and
convex and it holds
TC(S, x0) ⊂T (S, x0).
However, in some (perhaps pathological) cases, TC(S, x0) is a too small approxi-
mating cone of S at x0. The polar cone of TC(S, x0) is called Clarke normal cone to
S at x0 and denoted by NC(S, x0). With this choice, relation (5.17) can be therefore
written as
−

u0∇f (x0) +
m

i=1
ui∇gi(x0)

∈NC(C, x0).
When S is a convex set, then NC(S, x0) coincides with the usual normal cone
of Convex Analysis.
It follows also that if C is a closed convex set, then (5.17) becomes
−

u0∇f (x0) +
m

i=1
ui∇gi(x0)

∈N(C, x0),
where N(C, x0) is the normal cone to C at x0 (see Deﬁnition 2.42). The same relation
can be rewritten in the form
0 ∈u0∇f (x0) +
m

i=1
ui∇gi(x0) + N(C, x0)
or also in the form

u0∇f (x0) +
m

i=1
ui∇gi(x0)
⊤
(x −x0) ≧0, ∀x ∈C.
(5.18)
Remark 5.26 In order to get u0 > 0 (i.e. u0 = 1) in Theorem 5.25, we have to
impose some constraint qualiﬁcation.
If T1(C, x0) is convex and for some ˆx ∈T1(C, x0) it holds
g(x0) + ∇g(x0)⊤ˆx < 0,
then relation (5.17) holds with u0 = 1.
If C ⊂X ⊂Rn is (closed) and convex and there exists ˆx ∈C such that

5.4 Other Formulations of the Problem. Some Examples
155
g(x0) + ∇g(x0)⊤(ˆx −x0) < 0
(generalization of the Cottle constraint qualiﬁcation), then relation (5.18) holds with
u0 = 1.
For what concerns sufﬁcient optimality conditions for problem (P4)′, we can
prove the following result.
Theorem 5.27 Let in (P4)′ the functions f : Rn →R and each gi : Rn →R, i =
1, . . . , m, be differentiable convex functions on the open convex set X ⊂Rn and let
C ⊂X be a closed convex set. Let x0 be feasible for (P4)′ and assume that there
exist multipliers ui ≧0, i = 1, . . . , m, such that
(i) 0 ∈∇f (x0) + m
i=1 ui∇gi(x0) + N(C, x0);
(ii) uigi(x0) = 0, i = 1, . . . , m.
Then x0 is a solution of (P4)′.
Proof From the condition (i) it is clear that there exists ξ ∈N(C, x0) such that
0 = ∇f (x0) +
m

i=1
ui∇gi(x0) + ξ.
(5.19)
Using the fact that f and each gi are convex (see Theorem 2.6(d)) and also using the
complementary slackness conditions (ii) and relation (5.19), along with the deﬁnition
of normal cone to a convex set, we have
f (x) +
m

i=1
uigi(x) −f (x0) ≧−ξ ⊤(x −x0) ≧0
for all x feasible in (P4)′.
Now for any feasible x, we have m
i=1 uigi(x) ≦0, since ui ≧0, i = 1, . . . , m.
This clearly shows that f (x) ≧f (x0) for all feasible points x.
□
Following Gould and Tolle [11], it is possible to obtain for (P4)′ a sort of “mod-
iﬁed Karush-Kuhn-Tucker conditions”, in absence of assumptions about constraint
qualiﬁcations.
Let us deﬁne the set S4 = C ∩K4.
The set
L(x0) =

y ∈Rn : ∇gi(x0)⊤y ≦0, i ∈I (x0)

continues to denote the linearizing cone at x0 ∈S4.
We recall that it holds T (S4, x0) ⊂L(x0), i.e. (L(x0))∗⊂(T (S4, x0))∗. As
(T (S4, x0))∗is a convex cone, from
(T (S4, x0))∗= (L(x0))∗∪(T (S4, x0))∗\ ((L(x0))∗∪{0})

156
5
Constrained Optimization Problems with Inequality Constraints
we obtain
(T (S4, x0))∗= (L(x0))∗+ (T (S4, x0))∗\ ((L(x0))∗∪{0}),
i.e.
(T (S4, x0))∗= B(x0) + (T (S4, x0))∗\ ((L(x0))∗∪{0}),
where B(x0) is the cone of gradients (previously already deﬁned):
B(x0) =
⎧
⎨
⎩y ∈Rn : y =

i∈I (x0)
ui∇gi(x0), ui ≧0, i ∈I (x0)
⎫
⎬
⎭.
We have therefore the following result.
Theorem 5.28 If x0 is a local solution of (P4)′, then there exist multipliers ui ≧0,
i = 1, . . . , m, such that
−

∇f (x0) +
m

i=1
ui∇gi(x0)

∈T (S4, x0))∗\ ((L(x0))∗∪{0}
(5.20)
uigi(x0) = 0, i = 1, . . . , m.
On the previous theorem the following remarks can be useful. If it holds
(L(x0))∗= (T (S4, x0))∗
(5.21)
obviously relation (5.20) becomes
∇f (x0) +
m

i=1
ui∇gi(x0) = 0,
i.e. we obtain one of the classical Karush-Kuhn-Tucker conditions. The reader will
have noted that (5.21) is the Guignard-Gould-Tolle constraint qualiﬁcation referred
to (P4)′. From a “practical” point of view it is rather unlikely that this constraint
qualiﬁcation is satisﬁed in most cases (see also Bazaraa and Shetty [29]). A more
convenient constraint qualiﬁcation involving the Bouligand tangent cones is con-
tained in the following result, due to Gould and Tolle [11] and Guignard [9].
Theorem 5.29 Let x0 be a local solution of (P4)′ and let the following condition
(T (S4, x0))∗= (L(x0))∗+ (T (C, x0))∗
be veriﬁed. Then, there exist multipliers ui ≧0, i = 1, . . . , m, such that

5.4 Other Formulations of the Problem. Some Examples
157
−

∇f (x0) +
m

i=1
ui∇gi(x0)

∈(T (C, x0))∗;
uigi(x0) = 0, i = 1, . . . , m.
The Karush-Kuhn-Tucker conditions are basic tools in the construction of many
numerical algorithms for the determination of the solution or the approximate solu-
tion of a nonlinear programming problem. However, the direct application, with only
“paper and pen”, of these conditions may result rather complicate, even for simple
problems. We present few examples, just for giving an idea of what previously
expounded.
Example 5.30 Consider the problem
⎧
⎨
⎩
min f (x1, x2) = (x1 −2)2 + (x2 −3)2
subject to: x1 + x2 −2 ≦0,
(x1)2 −4 ≦0.
The problem is qualiﬁed, as the constraints are convex functions and the point
(0, 0)⊤∈K4 satisﬁes the Slater constraint qualiﬁcation. The Karush-Kuhn-Tucker
conditions (Theorem 5.8) are
2(x1 −2) + u1 + 2u2x1 = 0,
2(x2 −3) + u1 = 0,
u1(x1 + x2 −2) = 0,
u2((x1)2 −4) = 0,
u1 ≧0, u2 ≧0.
(1)
First case: u1 = u2 = 0.
We have (ﬁrst equation): 2(x1 −2) = 0; (second equation): 2(x2 −3) = 0.
Hence, we get x1 = 2, x2 = 3. However (2, 3)⊤/∈K4.
(2) Second case: u1 = 0, u2 > 0.
We have (x1)2 −4 = 0, i.e. x1 = ±2. From the second equation it results x2 = 3.
We have two points: (2, 3)⊤/∈K4 and (−2, 3)⊤∈K4.
However, from the ﬁrst equation, we have
2(−4) + 2u2(−2) = 0,
i.e. u2 = −2, not acceptable.
(3) Third case: u1 > 0, u2 = 0.
We have from the third condition (complementary slackness condition): x1 +
x2 −2 = 0, i.e. x2 = 2 −x1.
From the ﬁrst equation we get

158
5
Constrained Optimization Problems with Inequality Constraints
2(x1 −2) + u1 = 0.
From the second equation, we have
2(x2 −3) + u1 = 0,
i.e.
u1 = −2(x2 −3) = −2(2 −x1 −3) = −2(−x1 −1).
We substitute this value in the ﬁrst equation:
2(x1 −2) −2(−x1 −1) = 0,
i.e. 4x1 −2 = 0, from which x1 = 1
2.
Therefore, from x2 = 2 −x1, we get x2 = 3
2. We have ( 1
2, 3
2)⊤∈K4, with u1 =
−2(−1
2 −1) = 3 and u2 = 0.
(4)
Fourth case: u1 > 0, u2 > 0.
From the complementary slackness conditions, we have
x1 + x2 −2 = 0;
(x1)2 −4 = 0,
from which x1 = ±2. If x1 = 2, we have x2 = 0 and, from the ﬁrst equation,
we have u1 + 4u2 = 0, not acceptable. If x1 = −2, we have x2 = 4 and, from
the second equation, we have 2 + u1 = 0, not acceptable.
So, the unique acceptable point is x0 = ( 1
2, 3
2)⊤(see Fig. 5.2). Since the objective
function and the constraints are convex, by Theorem 5.10, we have that x0 is a
solution of the problem. Moreover, as the objective function is a strictly convex
function, from Theorem 3.37(b) it follows that x0 is the unique (strict) solution
of the problem.
Example 5.31 Consider the problem
⎧
⎨
⎩
max f (x1, x2) = x1 + log(x2 + 1)
subject to: x1 + x2 −1 ≦0,
x1 ≧0, x2 ≧0.
The constraints are linear and hence the problem is qualiﬁed. The Karush-Kuhn-
Tucker conditions at the feasible point x0 are (see (c1) in Table 5.1, p. 151):
∇f (x0) −
m

i=1
ui∇gi(x0) ≦0;

∇f (x0) −
m

i=1
ui∇gi(x0)
⊤
x0 = 0;

5.4 Other Formulations of the Problem. Some Examples
159
Fig. 5.2 Example 5.30. Feasible set and level curve for f
ui ≧0, ∀i = 1, . . . , m; uigi(x0) = 0, ∀i = 1, . . . , m.
Therefore, we have
1 −u1 ≦0;
1
x2 + 1 −u1 ≦0;
(1 −u1)x1 = 0;

1
x2 + 1 −u1

x2 = 0;
u1 ≧0, u1(x1 + x2 −1) = 0.
From 1 −u1 ≦0, we have u1 ≧1.
Then, from (1 −u1)x1 = 0, we have either x1 = 0 or u1 = 1.
(1) If x1 = 0, then, from u1(x2 −1) = 0, we have x2 = 1 since u1 ≧1. Hence,
from the condition
#
1
x2+1 −u1
$
x2 = 0, we have ( 1
2 −u1) = 0, i.e. u1 = 1
2, not
acceptable, as u1 ≧1.
(2) If u1 = 1, from
#
1
x2+1 −u1
$
x2 = 0 it follows that
1
x2+1 −1 = 0 or x2 = 0.
Both equations have the solution x2 = 0, and hence from u1(x1 + x2 −1) = 0,
we have x1 −1 = 0, i.e. x1 = 1.
Hence, we have only a feasible point (1, 0)⊤that satisﬁes the Karush-Kuhn-
Tucker conditions with u1 = 1.

160
5
Constrained Optimization Problems with Inequality Constraints
Fig. 5.3 Example 5.32.
Feasible set
As the feasible set S is compact and f is continuous on S, by the Weierstrass The-
orem, the maximum is attained. Then the Karush-Kuhn-Tucker conditions are
satisﬁed at this maximum, and as x0 is the only point satisfying these conditions,
we derive that x0 solves the problem.
Example 5.32 Consider the problem
⎧
⎪⎪⎨
⎪⎪⎩
max(x1x2 −x1 −x2 + 2)
subject to: x1x2 ≦6;
x1 + x2 ≦5;
x1 ≧0, x2 ≧0.
We remark that the feasible set (see Fig. 5.3) is closed and bounded (and so it is
compact) and that the objective function is continuous.
The Karush-Kuhn-Tucker conditions, including the feasibility conditions, are (see
(c1) in Table 5.1, p. 151):
x2 −1 −u1x2 −u2 ≦0;
x1 −1 −u1x1 −u2 ≦0;
(x2 −1 −u1x2 −u2)x1 = 0;
(x1 −1 −u1x1 −u2)x2 = 0;
u1(6 −x1x2) = 0;
u2(5 −x1 −x2) = 0;
5 −x1 −x2 ≧0;
6 −x1x2 ≧0;
x1 ≧0, x2 ≧0.
(1) Case u1 = u2 = 0. The above conditions become

5.4 Other Formulations of the Problem. Some Examples
161
x2 −1 ≦0;
x1 −1 ≦0;
(x2 −1)x1 = 0;
(x1 −1)x2 = 0;
6 −x1x2 ≧0;
5 −x1 −x2 ≧0;
x1 ≧0, x2 ≧0.
From these conditions we obtain the points
x1 =
 0
0
!
;
x2 =
 1
1
!
.
It holds f (x1) = 2; f (x2) = 1.
We exclude however the point x2, which is interior to the feasible set, but where
∇2 f (x2) is indeﬁnite.
(2) Case u1 > 0, u2 = 0. We have the system
x2 −1 −u1x2 ≦0;
x1 −1 −u1x1 ≦0;
(x2 −1 −u1x2)x1 = 0;
(x1 −1 −u1x1)x2 = 0;
6 −x1x2 = 0;
5 −x1 −x2 ≧0;
x1 ≧0, x2 ≧0.
From the third condition, we have
x2 =
1
1 −u1
∨x1 = 0.
From the fourth condition, we have
x1 =
1
1 −u1
∨x2 = 0.
The condition 6 −x1x2 = 0 eliminates the zero solutions. Moreover, we have
x1 = x2 and from 6 −x1x2 = 0 we get x1 = x2 =
√
6, from which we have
√
6 =
1
1 −u1
,

162
5
Constrained Optimization Problems with Inequality Constraints
i.e.
u1 = 6 −
√
6
6
.
The reader can verify that these values satisfy the remaining relations of the
system. We have therefore the point
x3 =
 √
6
√
6
!
and it holds f (x3) = 8 −2
√
6 ≃3, 1.
(3) Case u2 > 0, u1 = 0. We have the system
x2 −1 −u2 ≦0;
x1 −1 −u2 ≦0;
(x2 −1 −u2)x1 = 0;
(x1 −1 −u2)x2 = 0;
6 −x1x2 ≧0;
5 −x1 −x2 = 0;
x1 ≧0, x2 ≧0.
From the third and fourth conditions we get
x1 = x2 = 1 + u2 ∨x1 = x2 = 0.
Thezerosolutionsarenotacceptable.Wehaveu2 = 3
2,fromwhich x1 = x2 = 5
2.
Also this solution is not acceptable, as it is not feasible:
6 −5
2 · 5
2 = 6 −25
4 = −1
4 < 0.
Therefore, the case under examination does not produce new candidates.
(4) Case u1 > 0, u2 > 0. We have the system
x2 −1 −u1x2 −u2 ≦0;
x1 −1 −u1x1 −u2 ≦0;
(x2 −1 −u1x2 −u2)x1 = 0;
(x1 −1 −u1x1 −u2)x2 = 0;
6 −x1x2 = 0;
5 −x1 −x2 = 0;
x1 ≧0, x2 ≧0.

5.4 Other Formulations of the Problem. Some Examples
163
Fig. 5.4 Example 5.33.
Feasible set
From the ﬁfth and sixth conditions, we have
x4 =
 3
2
!
;
x5 =
 2
3
!
.
By substituting x4 in the third and fourth condition we ﬁnd u1 = 1, u2 = −1.
Therefore, x4 is not acceptable. By substituting the point x5 we ﬁnd again u1 = 1,
u2 = −1. Also x5 is not acceptable.
By comparison of the values assumed by f on the feasible points we have found,
x1 and x3, we can conclude that the solution of the problem is
x3 =
 √
6
√
6
!
,
with associated multipliers u1 = 1 −
√
6
6 , u2 = 0.
Example 5.33 Consider the problem
⎧
⎨
⎩
min

2(x1)2 −x2

subject to: (x1)2 + (x2 −1)2 ≧1
(x1)2 + (x2)2 ≦2.
The feasible set of this problem is drawn in Fig. 5.4.
We consider the Lagrangian function
L (x, u) = 2(x1)2 −x2 + u1(1 −(x1)2 −(x2 −1)2) + u2((x1)2 + (x2)2 −2).
We have
∇xL (x, u) =
4x1
−1

−2u1

x1
x2 −1

+ 2u2
 x1
x2

=
 0
0

.

164
5
Constrained Optimization Problems with Inequality Constraints
For I (x0) = ∅, we have u1 = u2 = 0 and therefore we have no solution of the
above relations.
The case I (x0) = {1} gives, with u2 = 0, (x1)2 + (x2 −1)2 = 1 and we have the
solutions
x1 =
0
0

with u1 =
 1
2
0

,
x2,3 =
± 1
4
√
15
3
4

, with u2,3 =
 2
0

.
Also the case I (x0) = {2} gives, with u1 = 0, (x1)2 + (x2)2 = 2 and we have no
solution of the Kuhn-Tucker conditions.
Finally, for I (x0) = {1, 2} , from the nonlinear equations (x1)2 + (x2 −1)2 = 1,
(x1)2 + (x2)2 = 2 we get the solutions
x4,5 =
±1
1

, with u4,5 =

5
2
1
2

.
Now, let us consider the Hessian matrix
∇2
xL (x, u) =
 4 −2u1 + 2u2
0
0
−2u1 + 2u2

.
For
x1 =
0
0

with u1 =
 1
2
0

,
we have
∇2
xL (x1, u1) =
 3
0
0 −1

which is positive deﬁnite on the cone

y ∈R2 : y2 = 0

.
Therefore, by Theorem 5.22, this point is a strict local minimum point of the
problem.
The points
x2,3 =
± 1
4
√
15
3
4

, with u2,3 =
2
0

both give the matrix
∇2
xL (x2,3, u2,3) =
0
0
0 −4

.

5.4 Other Formulations of the Problem. Some Examples
165
This matrix is not positive semideﬁnite on the cone

y ∈R2 : ∓1
4
√
15y1 + 1
2 y2 = 0

and hence, by Theorem 5.18, these points are not local minimizers of the problem
proposed.
Finally, we consider the points
x4,5 =
±1
1

, with u4,5 =

5
2
1
2

.
As in this case, the critical cone is y ∈R2, y = 0, These points are trivially local
minimum points for the problem proposed.
By computing the values of the objective function and making the comparisons,
we have that x1 =
 0
0

is the global minimum point for the problem considered.
We propose the following problems. The reader is invited to use, when possible,
the Karush-Kuhn-Tucker conditions.
Problem 5.34
⎧
⎨
⎩
max(x −3)2 + y2
subject to: x + (y −1)3 ≦0,
x, y ≧0, y ≦1.
(The point (0, 1) is the solution, which can be found by a geometric method. At
this point the Karush-Kuhn-Tucker conditions are satisﬁed, with multipliers u1 =
u3 = 0, u2 = 6, u4 = 2).
Problem 5.35
⎧
⎪⎪⎨
⎪⎪⎩
min (x −9
4)2 + (y −2)2
subject to: y −x2 ≧0;
x + y ≦6;
x, y ≧0.
(Verify that the point ( 3
2, 9
4) satisﬁes the Karush-Kuhn-Tucker conditions, with
multipliers u2 = u3 = u4 = 0. Being the objective function convex, the above point
is a global solution of the problem).
Problem 5.36 Consider the problem
⎧
⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩
max y2 + z−5
subject to: x2 + (y −1)2 + z2 ≦1;
(x −y)2 ≦1;
2y + z ≦3;
z ≧0

166
5
Constrained Optimization Problems with Inequality Constraints
and check whether the Karush-Kuhn-Tucker conditions are veriﬁed at the point (0,
1, 1).
(The above point does not verify the Karush-Kuhn-Tucker conditions and hence
it cannot be a solution of the problem).
Problem 5.37 Consider the problem
⎧
⎪⎪⎨
⎪⎪⎩
min(x −3)2 + (y −2)2
subject to: x2 + y2 ≦5;
x + 2y ≦4;
x, y ≧0.
Solve the problem by means of the Karush-Kuhn-Tucker conditions.
(The point (2, 1) is the solution of the problem).
Problem 5.38 Solve the problem
⎧
⎪⎪⎨
⎪⎪⎩
min x+3y+3
2x+y+6
subject to: 2x + y ≦12;
2y −x ≦4;
x, y ≧0.
(The inﬁnite points of the segment of end points (0, 0) and (6, 0) are solutions of
the problem).
Problem 5.39 Use the ﬁrst- and second-order conditions to solve the problem
min

2x2 + y2
, subject to: y −x2 + 4 ≦0.
(The points (−
√
3, −1) and (
√
3, −1) are the two solutions).
Problem 5.40 Use the ﬁrst- and second-order conditions to solve the problem
⎧
⎪⎪⎨
⎪⎪⎩
max(x + y)
subject to: y −x2 + 1 ≧0
x −y2 + 1 ≧0
x, y ≧0.
(The point ( 1
2(1 +
√
5), 1
2(1 +
√
5)) is the unique global solution).
Problem 5.41 Use the ﬁrst- and second-order conditions to solve the problem
⎧
⎨
⎩
max(xy)
subject to: (x −1)2 + y2 ≦1
x2 + (y −1)2 ≦1.
(The point (1, 1) is the unique solution).

References
167
References
1. K.J. Arrow, L. Hurwicz, H. Uzawa, Constraint qualiﬁcations in maximization problems. Naval
Res. Logist. 8, 175–191 (1961). Reprinted in Giorgi and Kjeldsen (2014)
2. Y. Chabrillac, J.-P. Crouzeix, Deﬁniteness and semi-deﬁniteness of quadratic forms revisited.
Linear Algebra Appl. 63, 283–292 (1984)
3. F. John, Extremum problems with inequalities as subsidiary conditions, in Studies and Essays:
Courant Anniversary Volume, eds. by K.O. Friedrichs, O.E. Neugebauer, J.J. Stoker (Inter-
science Publishers, New York), pp. 187–204. Reprinted in Giorgi and Kjeldsen (2014)
4. G. Giorgi, T.H. Kjeldsen, Traces and Emergence of Nonlinear Programming (Birkhäuser, Basel
and New York, 2014)
5. D.P. Bertsekas, Nonlinear Programming, 2nd edn. (Athena Scientiﬁc, Belmont, Mass, 1999)
6. D.P. Bertsekas, A.E. Ozdaglar, Pseudonormality and Lagrange multiplier theory for constrained
optimization. J. Optim. Theory Appl. 114, 287–343 (2002)
7. J.M. Abadie, On the Kuhn-Tucker theorem, in Nonlinear Programming. ed. by J.M. Abadie
(North Holland, Amsterdam, 1967), pp. 21–36
8. H.W. Kuhn, A.W. Tucker, Nonlinear programming, in Proceedings of the Second Berkeley
Symposium on Mathematical Statistics and Probability, ed. by J. Neyman (Univ. of California
Press, Berkeley, 1951), pp. 481–492. Reprinted in Giorgi and Kjeldsen (2014)
9. M. Guignard, Generalized Kuhn-Tucker conditions for mathematical programming problems
in a Banach space. SIAM J. Control 7, 232–241 (1969)
10. F.J. Gould, J.W. Tolle, A necessary and sufﬁcient qualiﬁcation for constrained optimization.
SIAM J. Appl. Math. 20, 164–172 (1971)
11. F.J. Gould, J.W. Tolle, Geometry of optimality conditions and constraint qualiﬁcations. Math.
Program. 2, 1–18 (1972)
12. O.L. Mangasarian, Nonlinear Programming (McGraw-Hill Book Company, New York, 1969)
13. J. Stoer, C. Witzgall, Convexity and Optimization in Finite Dimensions, I (Springer, New York,
1971)
14. J.E. Martinez-Legaz, What is invexity with respect to the same η. Taiwanese J. Math. 13,
753–755 (2009)
15. A. Ben-Israel, B. Mond, What is invexity? J. Austral. Math. Soc. Ser. B 28, 1–9 (1986)
16. M.R. Hestenes, Optimization Theory. The Finite Dimensional Case (Wiley, New York, 1975)
17. W.I. Zangwill, Nonlinear Programming: A Uniﬁed Approach (Prentice-Hall, Englewood Cliffs,
N.J., 1969)
18. G. Giorgi, B. Jiménez, V. Novo, On constraint qualiﬁcations in directionally differentiable
multiobjective optimization problems. RAIRO Oper. Res. 38(3), 255–274 (2004)
19. J. Kyparisis, On uniqueness of Kuhn-Tucker multipliers in nonlinear programming. Math.
Program. 32, 242–246 (1985)
20. K.-H.Elster,R.Reinhardt,M.Schäuble,G.Donath,EinführungindienichtlineareOptimierung
(Teubner Verlagsgesellschaft, Leipzig, BSB B. G, 1977)
21. G.P. Mccormick, Second order conditions for constrained minima. SIAM J. Appl. Math. 15,
641–652 (1967). Reprinted in Giorgi and Kjeldsen (2014)
22. G. Debreu, Deﬁnite and semideﬁnite quadratic forms. Econometrica 20, 285–300 (1952)
23. J.G. Taylor, A squared-variable transformation approach to nonlinear programming. Naval Res.
Logist. Quart. 20, 25–39 (1973)
24. V. Barbu, T. Precupanu, Convexity and Optimization in Banach Spaces, 4th edn. (Springer,
Berlin, 2012)
25. G. Giorgi, A. Guerraggio, First order generalized optimality conditions for programming prob-
lems with a set constraint, in Generalized Convexity. Proceedings of the IV International Work-
shop on Generalized Convexity, eds. by S. Komlosi, T. Rapcsak, S. Schaible (Pecs, Hungary,
Springer, Berlin, 1992), pp. 171–185
26. Y. Nagahisa, Y. Sakawa, Nonlinear programming in Banach spaces. J. Optim. Theory Appl. 4,
182–190 (1969)

168
5
Constrained Optimization Problems with Inequality Constraints
27. J.S. Treiman, An inﬁnite class of convex tangent cones. J. Optim. Theory Appl. 68, 563–581
(1991)
28. F.H. Clarke, Optimization and Nonsmooth Analysis (Wiley, New York, 1983)
29. M.S. Bazaraa, C.M. Shetty, Foundations of Optimization, Lecture Notes in Economics and
Mathematics Systems, vol. 122. (Springer, Berlin, 1976)
30. D. Gale, The Theory of Linear Economic Models (McGraw-Hill Book Company, New York,
1960)

Chapter 6
Constrained Optimization Problems
with Mixed Constraints
6.1
First-Order Conditions
In this chapter, we shall be concerned with problem (P5), i.e. with a constrained
minimization problem with mixed constraints, i.e. with both inequality and equality
constraints.
(P5) :
⎧
⎪⎪⎨
⎪⎪⎩
min f (x)
subject to: gi(x) ≦0, i = 1, . . . , m,
h j(x) = 0, j = 1, . . . , p < n,
x ∈X ⊂Rn,
where X ⊂Rn is an open set contained in the domains of the functions involved in
(P5), f, gi, i ∈M = {1, . . . , m} and h j, j ∈P = {1, . . . , p < n} , are real-valued
functions deﬁned on Rn.
We make the assumptions that f and every gi, i = 1, . . . , m, are (at least) differ-
entiableon X andthat every h j, j = 1, . . . , p,is (at least) continuouslydifferentiable
on X (weaker differentiability assumptions are possible).
It is quite evident that (P5) subsumes the properties of (P3) and (P4), however,
it deserves a speciﬁc treatment. For example, if we rewrite the equalities h j(x) = 0,
j = 1, . . . , p, appearing in (P5), as h j(x) ≦0 and −h j(x) ≦0, the ﬁrst relation of
the Fritz John conditions for this equivalent problem (see Theorem 5.5) becomes
u0∇f (x0) +
m

i=1
ui∇gi(x0) +
p

j=1
v j∇h j(x0) −
p

j=1
w j∇h j(x0) = 0,
with multipliers not all zero and nonnegative. Unfortunately, this condition is satisﬁed
by any feasible point of (P5) by u0 = ui = 0, i = 1, . . . , m, and by v j = w j, j =
1, . . . , p, nonnegative and not all zero. The above reduction of (P5) to the form of
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al., Basic Mathematical Programming Theory, International Series
in Operations Research & Management Science 344,
https://doi.org/10.1007/978-3-031-30324-1_6
169

170
6
Constrained Optimization Problems with Mixed Constraints
(P4) is in this case of no utility, being the necessary Fritz John conditions always
veriﬁed by any feasible point, and therefore meaningless.
The feasible set or set of feasible points of (P5) is given by
K5 =

x ∈X : gi(x) ≦0, ∀i ∈M; h j(x) = 0, ∀j ∈P

and f is the objective function of (P5).
The set of active constraints or effective constraints or binding constraints at
x0 ∈K5 is
I (x0) =

i ∈M : gi(x0) = 0

.
If x0 ∈K5, the linearizing cone of K5 at x0 (or cone of locally constrained direc-
tions of K5 at x0) is given by
L(x0) =
	 y ∈Rn : ∇gi(x0)⊤y ≦0, ∀i ∈I (x0);
∇h j(x0)⊤y = 0, ∀j ∈P

.
Obviously, this cone is a convex polyhedral cone and hence it is closed and convex.
The cone
Lo(x0) =
	 y ∈Rn : ∇gi(x0)⊤y < 0, ∀i ∈I (x0);
∇h j(x0)⊤y = 0, ∀j ∈P

is called cone of relative interior locally constrained directions of K5 at x0 (or also
strictly inward cone or cone of descent directions of K5 at x0).
We note that Lo(x0) is a relatively open convex cone, with respect to the sub-
space

y ∈Rn : ∇h j(x0)⊤y = 0, ∀j ∈P

. Obviously, if I (x0) = ∅, both L(x0)
and Lo(x0) coincide with the said subspace. We note also that the forms of T (K5, x0),
A(K5, x0) and F(K5, x0) remain quite similar to the ones deﬁned for problem (P4),
howeve,r the cone of feasible directions F(K5, x0) is very likely given by the sin-
gleton {0} , unless the constraints h j(x), ∀j ∈P, are linear afﬁne. So, in the present
chapter, we will not take F(K5, x0) into consideration.
Theorem 6.1 Let x0 ∈K5. It holds
T (K5, x0) ⊂L(x0).
If the Jacobian matrix ∇h(x0) has full rank (i.e. the gradients ∇h j(x0), j =
1, . . . , p, are linearly independent), then it holds
Lo(x0) ⊂T (K5, x0).
If, moreover, Lo(x0) ̸= ∅, then
cl(Lo(x0)) = T (K5, x0) = L(x0).

6.1 First-Order Conditions
171
Proof The ﬁrst inclusion is proved in a similar way of what proved in Theorem 4.38
and in Theorem 5.3. We repeat the proof. Let be given y ∈T (K5, x0), with ∥y∥= 1.
Therefore, there exist a feasible sequence

xk
⊂K5, with xk
y→x0. Hence, for all
i ∈I (x0), the quotients
gi(xk) −gi(x0)
xk −x0
= ∇gi(x0)⊤(xk −x0) + o(
xk −x0)
xk −x0
converge to ∇gi(x0)⊤y ≦0.
For all j ∈P, the quotients
h j(xk) −h j(x0)
xk −x0
= ∇h j(x0)⊤(xk −x0) + o(
xk −x0)
xk −x0
converge to ∇h j(x0)⊤y = 0.
It follows that y ∈L(x0).
For the second inclusion let us assume I (x0) ̸= ∅, otherwise it would be Lo(x0) =
L(x0) and the thesis is immediate from Theorem 4.38. Then we have y ∈Lo(x0),
with ∥y∥= 1, so this vector belongs (on the grounds of the assumptions), thanks to
Theorem 4.38, to the Bouligand tangent cone to the set

x ∈Rn : h j(x) = 0, ∀j ∈P

,
with only equality constraints, i.e. there exists a sequence

xk
belonging to this set
which converges tangentially to x0 in the direction y.
As, for each active constraint, the quotients
gi(xk) −gi(x0)
xk −x0
= ∇gi(x0)⊤(xk −x0) + o(
xk −x0)
xk −x0
converge to ∇gi(x0)⊤y < 0, we have that gi(xk) < 0 for k ∈N sufﬁciently large.
For non-active constraints at x0, the said inequality holds, thanks to continuity. The
sequence

xk
is therefore a feasible sequence. Hence, y ∈T (K5, x0).
The proof of the third statement of the theorem is performed in a similar way of
the proof of Corollary 5.4.
□
Remark 6.2 It is possible to prove a more complete version of Theorem 6.1, i.e.
with x0 ∈K5, it holds:
(a) A(K5, x0) ⊂T (K5, x0) ⊂L(x0).
(This is obvious, as we have always A(·, ·) ⊂T (·, ·)).
(b) If ∇h j(x0), j = 1, . . . , p, are linearly independent, then it holds
Lo(x0) ⊂A(K5, x0) ⊂T (K5, x0) ⊂L(x0).
and if Lo(x0) ̸= ∅, then
cl(Lo(x0)) = A(K5, x0) = T (K5, x0) = L(x0).

172
6
Constrained Optimization Problems with Mixed Constraints
This is useful in order to compare (see the next section) the Kuhn-Tucker con-
straint qualiﬁcation and the Abadie constraint qualiﬁcation for (P5).
We are now ready to prove the Fritz John necessary optimality conditions for
problem (P5).
Theorem 6.3 (Fritz John Theorem) Let x0 ∈K5 be a local minimum point for (P5).
Then there exist multipliers (“Fritz John multipliers”) u0, u1, . . . , um, v1, . . . , vp,
not all zero, such that
(i) u0∇f (x0) + m
i=1 ui∇gi(x0) + p
j=1 v j∇h j(x0) = 0;
(ii) uigi(x0) = 0, i = 1, . . . , m;
(iii) u0 ≧0, u1 ≧0, . . . , um ≧0.
Proof If the vectors

∇h1(x0), . . . , ∇h p(x0)

are linearly dependent, the thesis of
the theorem is trivial. Assume therefore that these vectors are linearly independent,
i.e. the Jacobian matrix ∇h(x0) is of full rank.
As x0 ∈K5 is a local minimum point for (P5), it follows from Theorem 4.24 and
taking into account the second result of the previous theorem,
∇f (x0)⊤y ≧0, ∀y ∈T (K5, x0) ⊃Lo(x0).
It holds also ∇f (x0)⊤y ≧0 for all those y such that ∇gi(x0)⊤y < 0, i ∈I (x0),
and such that ∇h j(x0)⊤y = 0, j ∈P. In other words, the inequality system
⎧
⎨
⎩
∇f (x0)⊤y < 0,
∇gi(x0)⊤y < 0, i ∈I (x0),
∇h j(x0)⊤y = 0, j = 1, . . . , p,
(6.1)
admits no solution y ∈Rn. By Motzkin’s theorem of the alternative (Chap. 2),
there exist therefore numbers ui ≧0, i ∈{0} ∪I (x0), not all zero, and v j ∈R,
j = 1, . . . , p, such that
u0∇f (x0) +

i∈I (x0)
ui∇gi(x0) +
p

j=1
v j∇h j(x0) = 0.
In any case, by choosing ui = 0 for all indices i /∈I (x0), we obtain the thesis. □
Conditions (i), (ii) and (iii) in Theorem 6.3 are called Fritz John conditions.
It appears from the proof of the previous theorem that if the gradients ∇h j(x0),
j = 1, . . . , p, are linearly independent, then we can obtain that the multipliers u0 ≧
0, u1 ≧0, . . . , um ≧0, are not all zero. If x0 ∈K5 is a local solution of (P5) and
the gradients ∇h j(x0), j = 1, . . . , p, are linearly independent, from the proof of the
previous theorem it appears that the system (6.1) admits no solution y ∈Rn. This is
the Abadie linearization lemma for (P5). It may be considered a (ﬁrst-order) “primal

6.1 First-Order Conditions
173
necessary optimality condition” for (P5), whereas the Fritz John theorem may be
considered a “dual necessary optimality condition” for (P5).
We give now another type of proof of the Fritz John necessary conditions for (P5),
i.e. a proof based on a “penalization technique” on the original problem. This type of
proof is originally due to Mc Shane [1] and subsequently has been reconsidered and
ameliorated by Bertsekas [2] and Bertsekas and Ozdaglar [3], who obtained what
they call “enhanced Fritz John optimality conditions” (see Sect. 6.4).
We make the assumption that all functions involved in (P5) are continuously
differentiable on the open set X ⊂Rn.
Proof of Theorem 6.3 by a penalization technique For every k ∈N, k ≧1, we
deﬁne the function
Fk : X →R, Fk(x) = f (x) + k
m

i=1

g+
i (x)
2 + k
p

j=1

h j(x)
2 +
x −x02 ,
where g+
i (x) = max {gi(x), 0} .
Let us consider a closed neighborhood (a closed ball) ¯B(x0,r) centered at x0 and
of radius r > 0 such that ¯B(x0,r) ⊂X and
f (x) ≧f (x0), ∀x ∈K5 ∩¯B(x0,r).
The function Fk is continuous on X and ¯B(x0,r) is a compact set contained in
X. Therefore, there exists a point ¯xk ∈¯B(x0,r) which minimizes Fk over ¯B(x0,r).
It holds in particular
Fk(¯xk) ≦Fk(x0) = f (x0),
i.e.
m

i=1

g+
i (¯xk)
2 +
p

j=1

h j(¯xk)
2 ≦1
k

f (x0) −f (¯xk) −
¯xk −x02
.
(6.2)
The expression between parentheses on the right-hand side of (6.2) is bounded
(with respect to k) and hence, taking the limit for k →∞, we get
lim
k→∞g+
i (¯xk) = 0, for i = 1, . . . , m;
lim
k→∞h j(¯xk) = 0, for j = 1, . . . , p.
The sequence

¯xk
is in the compact set ¯B(x0,r), hence we can consider a
subsequence

¯xkℓ
ℓconverging to ˜x. We have that ˜x ∈¯B(x0,r) and, by the continuity
of the functions g+
i
and h j, we get g+
i (˜x) = 0, ∀i = 1, . . . , m, and h j(˜x) = 0,
∀j = 1, . . . , p. Therefore, ˜x ∈K5 ∩¯B(x0,r).

174
6
Constrained Optimization Problems with Mixed Constraints
But, being f (¯xkℓ) +
¯xkℓ−x02 ≦f (x0) for every index ℓ(this comes from
relation (6.2) since the left hand side of (6.2) is ≧0), taking the limit we have
f (˜x) +
˜x −x02 ≦f (x0).
It holds f (x0) ≦f (˜x), as x0 is a minimizer of f over K5 ∩¯B(x0,r), hence
˜x −x02 = 0 and so ˜x = x0.
Thisreasoningholdsforeveryconvergentsubsequenceof

¯xk
:hence,wededuce
that the sequence

¯xk
converges to x0 when k →∞.
By starting from a certain value of k, we have that ¯xk lies in the interior of ¯B(x0,r)
and therefore, by the stationary condition,
0 = ∇Fk(¯xk)
= ∇f (¯xk) + 2k
m

i=1
g+
i (¯xk)∇gi(¯xk) + 2k
p

j=1
h j(¯xk)∇h j(¯xk) + 2(¯xk −x0).
Let us denote
k =
⎛
⎝1 + 4k2
m

i=1

g+
i (¯xk)
2 + 4k2
p

j=1

h j(¯xk)
2
⎞
⎠
1
2
,
u0,k = 1
k
,
ui,k = 2kg+
i (¯xk)
k
,
v j,k = 2kh j(¯xk)
k
.
The vector (u0,k, u1,k, . . . , um,k, v1,k, . . . , vp,k) ∈R × Rm × Rp
and is of
Euclidean norm equal to 1 (by construction!). Moreover,
0 = u0,k∇f (¯xk) +
m

i=1
ui,k∇gi(¯xk) +
p

j=1
v j,k∇h j(¯xk) + 2(¯xk −x0)
k
.
By considering a subsequence, we take the limit of the above expression:
(u0,k, u1,k, . . . , um,k, v1,k, . . . , vp,k) →
k→∞(u0, u1, . . . , um, v1, . . . , vp) ̸= 0;
0 = u0∇f (x0) +
m

i=1
ui∇gi(x0) +
p

j=1
v j∇h j(x0)
as k ≧1, ¯xk →x0 and the applications ∇f, ∇gi and ∇h j are continuous.
It is clear that u0, u1, . . . , um, being the limits of nonnegative quantities are non-
negative. Finally, if i /∈I (x0), i. e. gi(x0) < 0, we have ui,k = 0, starting from a

6.1 First-Order Conditions
175
certain index k, and hence ui = 0, for i /∈I (x0), from which the complementary
slackness conditions.
□
As previously remarked for problem (P4), in order to avoid that in the Fritz John
conditions it holds u0 = 0, we have to impose some constraint qualiﬁcation. We
introduce for (P5) the Guignard-Gould-Tolle constraint qualiﬁcation.
Let x0 ∈K5. We say that the Guignard-Gould-Tolle constraint qualiﬁcation
holds if
(L(x0))∗= (T (K5, x0))∗,
(6.3)
equality equivalent to the expression given by Guignard [4]:
L(x0) = cl(conv(T (K5, x0))).
We introduce also the cone of gradients for (P5):
B(x0) =
⎧
⎨
⎩y ∈Rn : y =

i∈I (x0)
ui∇gi(x0) +
p

j=1
v j∇h j(x0), ui ≧0, ∀i ∈I (x0)
⎫
⎬
⎭.
Obviously, B(x0) is a ﬁnite cone, i.e. a convex polyhedral cone; hence it is a
closed convex set and with the same proof of Lemma 4.1, we see that
B(x0) = (L(x0))∗
and
L(x0) = (B(x0))∗.
We are now ready to obtain for (P5) the Karush-Kuhn-Tucker optimality
conditions.
Theorem 6.4 (Karush-Kuhn-Tucker) Let x0 ∈K5 be a local solution of (P5) and
let the Guignard-Gould-Tolle constraint qualiﬁcation (6.3) be satisﬁed. Then there
exist multipliers (“Karush-Kuhn-Tucker multipliers” ) u1, . . . , um and v1, . . . , vp
such that
(i) ∇f (x0) + m
i=1 ui∇gi(x0) + p
j=1 v j∇h j(x0) = 0;
(ii) uigi(x0) = 0, i = 1, . . . , m;
(iii) ui ≧0, i = 1, . . . , m.
Proof The proof is the same of the one for (P4). From Theorem 4.24, we know that
∇f (x0)⊤y ≧0 for every y ∈T (K5, x0), whence −∇f (x0) ∈(T (K5, x0))∗. We use
now the constraint qualiﬁcation (6.3), i. e. the relation (T (K5, x0))∗= (L(x0))∗, to
deduce that −∇f (x0) ∈(L(x0))∗.

176
6
Constrained Optimization Problems with Mixed Constraints
But, being (L(x0))∗= B(x0), we get −∇f (x0) ∈B(x0). Consequently, there
exist ui ≧0, i ∈I (x0), v j ∈R, v j = 1, . . . , p, such that
−∇f (x0) =

i∈I (x0)
ui∇gi(x0) +
p

j=1
v j∇h j(x0).
If we choose ui = 0 for all i /∈I (x0), the thesis follows.
□
Gould and Tolle [5] showed that (6.3) is not only a sufﬁcient condition for the
existence of Karush-Kuhn-Tucker multipliers for (P5) but also necessary, in a certain
sense. More precisely, the pair (g, h) is said to be Lagrange regular at x0 ∈K5 if for
every differentiable objective function f that has a local constrained minimum at x0,
there exist vectors u ∈Rm and v ∈Rp such that (i), (ii), and (iii) of Theorem 6.3
hold. It is shown by Gould and Tolle [5] that (g, h) is Lagrange regular at x0 ∈K5 if
and only if condition (6.3) holds. See the next section. It must be observed that this
question has been previously treated, for a problem of the type (P4), but assuming
that the feasible set K4 is a convex set, by Arrow et al. [6].
Some authors (e.g. Avriel [7] and Forst and Hoffmann [8]) follow a slightly
different approach in obtaining Theorem 6.4 by assuming the Guignard-Gould-Tolle
constraint qualiﬁcation. We report their “steps” for the reader’s convenience.
• Let x0 ∈K5; the cone
D<( f, x0) =

y ∈Rn : ∇f (x0)⊤y < 0

is called the cone of descent directions of f at x0.
• For x0 ∈K5, it holds L(x0) ∩D<( f, x0) = ∅if and only if (i), (ii), and (iii) of
Theorem 6.4 hold.
Indeed, by deﬁnition of L(x0) and D<( f, x0), it holds that
y ∈L(x0) ∩D<( f, x0) ⇔
⎧
⎨
⎩
∇f (x0)⊤y < 0,
∇gi(x0)⊤y ≦0, ∀i ∈I (x0),
∇h j(x0)⊤y = 0, ∀j = 1, . . . , p.
⇔
⎧
⎪⎪⎨
⎪⎪⎩
∇f (x0)⊤y < 0,
−∇gi(x0)⊤y ≧0, ∀i ∈I (x0),
−∇h j(x0)⊤y ≧0, ∀j = 1, . . . , p,
∇h j(x0)⊤y ≧0, ∀j = 1, . . . , p.
By Farkas’s Theorem of the Alternative (Chap. 2), we have the following equiva-
lence:
L(x0) ∩D<( f, x0) = ∅if and only if there exist ui ≧0, i ∈I (x0) and μ j ≧0,
w j ≧0, j = 1, . . . , p, such that

6.1 First-Order Conditions
177
∇f (x0) =

i∈I (x0)
ui(−∇gi(x0)) +
p

j=1
μ j(−∇h j(x0)) +
p

j=1
w j∇h j(x0).
If we set ui = 0 for i /∈I (x0) and v j = μ j −w j, for j = 1, . . . , p, we obtain
that L(x0) ∩D<( f, x0) = ∅if and only if there exist ui ≧0, i = 1, . . . , m, and
v j ∈R, j = 1, . . . , p, such that (i), (ii) and (iii) of Theorem 6.4 hold.
• We recall Theorem 4.24: if x0 ∈K5 is a local minimizer for (P5), then
−∇f (x0) ∈(T (K5, x0))∗.
• Assume the Guignard-Gould-Tolle constraint qualiﬁcation (6.3). Then, if x0 ∈K5
is a local minimizer for (P5), then the thesis of Theorem 6.4 holds. Indeed, from
−∇f (x0) ∈(T (K5, x0))∗, we have, by (6.3), −∇f (x0) ∈(L(x0))∗. Now
−∇f (x0) ∈(L(x0))∗⇔L(x0) ∩D<( f, x0) = ∅.
Indeed:
L(x0) ∩D<( f, x0) = ∅⇔∀y ∈L(x0) : ∇f (x0)⊤y ≧0 ⇔−∇f (x0) ∈(L(x0))∗.
But L(x0) ∩D<( f, x0) = ∅is just equivalent to the thesis of Theorem 6.4.
□
By introducing for (P5), the related Lagrangian function
L (x, u, v) = f (x) + u⊤g(x) + v⊤h(x),
we can rewrite the Karush-Kuhn-Tucker conditions of Theorem 6.4 in the following
form, which takes into account also the feasibility of the point x0:
∇xL (x0, u, v) = 0,
∇uL (x0, u, v) ≦0,
∇vL (x0, u, v) = 0,
u ≧0, u⊤∇uL (x0, u, v) = 0.
Remark 6.5 (a) Let us consider the following generalization of problem (P5) when
some of the variables are nonnegative:
⎧
⎪⎪⎨
⎪⎪⎩
min f (x, y)
subject to: gi(x, y) ≦0, i = 1, . . . , m,
h j(x, y) = 0, j = 1, . . . , p,
y ≧0,

178
6
Constrained Optimization Problems with Mixed Constraints
where f, gi, i = 1, . . . , m, h j, j = 1, . . . , p, are real-valued functions deﬁned on
the open set X ⊂Rn1 × Rn2, f and every gi are differentiable on X and every h j is
continuously differentiable on X.
Let (x0, y0) be a local minimum point for the said problem and let some constraint
qualiﬁcation be veriﬁed at (x0, y0). Then there exist multipliers u ∈Rm and v ∈Rp,
such that, with
L (x, y, u, v) = f (x, y) + u⊤g(x, y) + v⊤h(x, y),
we have
∇xL (x0, y0, u, v) = 0;
∇yL (x0, y0, u, v) ≧0;
(y0)⊤∇yL (x0, y0, u, v) = 0;
u ≧0, u⊤∇uL (x0, y0, u, v) = 0.
(b) Consider now a minimization problem
min f (x)
with linear afﬁne constraints of the type
⎧
⎪⎪⎨
⎪⎪⎩
A11x1 + A12x2 + A13x3 ≧b1;
A21x1 + A22x2 + A23x3 = b2;
A31x1 + A32x2 + A33x3 ≦b3,
x1 ≧0, x2 ∈Rn2, x3 ≦0.
with x j ∈Rn j, bi ∈Rmi and Ai j matrix of order (mi, n j), i, j = 1, 2, 3. Let
f (x1, x2, x3) be differentiable on an open set X ⊂Rn1+n2+n3 and let x0 = (x1, x2,
x3)⊤be a constrained local minimum point for the above problem (as we shall see
in the next section, the constraint qualiﬁcations are automatically veriﬁed in the case
of linear afﬁne constraints). Then there exist multipliers ui ∈Rmi, i = 1, 2, 3, such
that
x1 ≧0, ∇x1 f (x0) −(A⊤
11u1 + A⊤
21u2 + A⊤
21u3) ≧0;
∇x2 f (x0) −(A⊤
12u1 + A⊤
22u2 + A⊤
32u3) = 0;
x3 ≦0, ∇x3 f (x0) −(A⊤
13u1 + A⊤
23u2 + A⊤
33u3) ≦0;
u1 ≧0, (u1)⊤(A11x1 + A12x2 + A13x3 −b1) = 0;
u3 ≦0, (u3)⊤(A31x1 + A32x2 + A33x3 −b3) = 0.

6.1 First-Order Conditions
179
The classical (ﬁrst-order) sufﬁcient conditions for global optimality for problem
(P5) are due to Mangasarian [9].
Theorem 6.6 Let x0 ∈K5 be a point such that, for u ∈Rm and v ∈Rp, it holds
∇f (x0) +
m

i=1
ui∇gi(x0) +
p

j=1
v j∇h j(x0) = 0,
uigi(x0) = 0, i = 1, . . . , m,
ui ≧0, i = 1, . . . , m.
In other words, x0, u and v satisfy the Karush-Kuhn-Tucker conditions of Theorem
6.4. Let f be pseudoconvex on the open convex set X ⊂Rn, let every gi, i ∈I (x0), be
quasiconvex on X and let every h j, j = 1, . . . , p, be quasiconvex and quasiconcave
on X. Then x0 is a solution of (P5).
Proof It is the same proof as the one given in Theorem 5.10, by observing that
the equality constraints h j(x) = 0, j = 1, . . . , p, can be written as h j(x) ≦0 and
−h j(x) ≦0, j = 1, . . . , p, and that the negative of a quasiconvex function is a
quasiconcave function (and vice-versa).
□
Remark 6.7 (a) In particular, if x0 ∈K5, u and v satisfy the Karush-Kuhn-Tucker
conditions in Theorem 6.4, f and every gi, i ∈I (x0) are convex on X and every h j,
j = 1, . . . , p is linear afﬁne, then x0 is a solution of (P5). Indeed, by Theorem 3.26(i)
one has that f is pseudoconvex and by Theorem 3.26(i)–(ii), each gi, i ∈I (x0), is
quasiconvex.
(b) Instead of the ﬁrst relation of the Karush-Kuhn-Tucker conditions, in the
previous theorem, we can impose the more general condition (“mimimum principle-
type condition”):
(x −x0)⊤∇xL (x0, u, v) ≧0, ∀x ∈K5.
(c) One of the ﬁrst works concerning functions that are both quasiconvex and
quasiconcave (it is used also the term “quasilinear”) is the pioneering paper of Arrow
et al. [6]. These authors prove the following characterization of quasilinear functions.
Let f : X ⊂Rn →R be deﬁned on the convex set X. Its level set
lev=α f = {x : f (x) = α}
is called maximal (resp. minimal) level set if it is the set on which f (x) attains
its maximum (resp. its minimum). A set S ⊂Rn will be said to be bounded by
two noncrossing hyperplanes in X if there exist linear functions L1(x), L2(x), not
identically constant in X such that
S =

x ∈X : L1(x) ≧0, L2(x) ≦0


180
6
Constrained Optimization Problems with Mixed Constraints
and
L1(x) < 0, L2(x) > 0, for no x ∈X.
Then f is both quasiconvex and quasiconcave (i.e. quasilinear) on the convex
set X if and only if every level set is not minimal nor maximal is bounded by two
noncrossing hyperplanes in X. See also Martos [10].
Obviously, if every h j, j = 1, . . . , p, is linear afﬁne the assumptions of Theorem
6.6 are veriﬁed. It can be proved that if f : X ⊂Rn →R is differentiable on the
open convex set X, then f is quasilinear on X if and only if
x, y ∈X, f (x) = f (y) ⇒(y −x)⊤∇f (x) = 0.
Every monotone function f : R →R is quasilinear.
If we make use, in Theorem 6.6, of “modiﬁed” Karush-Kuhn-Tucker conditions,
for what regards the multipliers v j, j = 1, . . . , p, we can relax the quasilinearity
assumption on equality constraints h j, j = 1, . . . , p. The proof of the following
result is obvious.
Theorem 6.8 Let x0 ∈K5 be a point such that there exist multipliers u ∈Rm and
v ∈Rp such that
(i) ∇f (x0) + m
i=1 ui∇gi(x0) + p
j=1 v j∇h j(x0) = 0;
(ii) uigi(x0) = 0, i = 1, . . . , m;
(iii) ui ≧0, i = 1, . . . , m; v j ≧0, j = 1, . . . , p.
Suppose that f is pseudoconvex on the open convex set X ⊂Rn and that every
gi, i ∈I (x0), and every h j, j = 1, . . . , p, is quasiconvex on X. Then x0 is a
solution of (P5).
If, in Theorem 6.6, we suppose that the constraint h j with a positive multiplier
v j is quasiconvex and the constraint hk with a negative multiplier vk is quasiconcave
(the constraint hs with a zero multiplier obviously can be any), again we obtain that
x0 ∈K5 solves (P5) if the Karush-Kuhn-Tucker conditions hold at x0.
It is also possible to obtain ﬁrst-order global sufﬁcient optimality conditions for
(P5) by means of Fritz John conditions (instead of Karush-Kuhn-Tucker conditions).
We need the following deﬁnition.
Deﬁnition 6.9 The function f : X ⊂Rn →R deﬁned on the open convex set X is
said to be strictly pseudoconvex on X if, for every x, y ∈X with x ̸= y:
(y −x)⊤∇f (x) ≧0 ⇒f (y) −f (x) > 0
i.e.
f (y) −f (x) ≦0 ⇒(y −x)⊤∇f (x) < 0.

6.1 First-Order Conditions
181
This class of generalized convex functions does not contain the class of differen-
tiable convex functions, but does contain the class of (differentiable) strictly convex
functions. Obviously, the class of strictly pseudoconvex functions is contained in the
class of pseudoconvex functions.
Theorem 6.10 Let in (P5) the objective function f be pseudoconvex on the open
convex set X ⊂Rn; let every gi, i ∈I (x0), and every h j, j = 1, . . . , p, be strictly
pseudoconvex on X; let x0 ∈K5 satisfy the following modiﬁed Fritz John conditions:
(a) u0∇f (x0) + m
i=1 ui∇gi(x0) + p
j=1 v j∇h j(x0) = 0;
(b) uigi(x0) = 0, i = 1, . . . , m;
(c) (u0, u, v) ≧0, (u0, u, v) ̸= 0.
Then x0 solves (P5).
Proof Owing to the complementary slackness conditions, relation (a) of the theorem
can be rewritten as
u0∇f (x0) +

i∈I (x0)
ui∇gi(x0) +
p

j=1
v j∇h j(x0) = 0.
Applying Gordan’s theorem of the alternative (Chap. 2, p. 44) we have that there
does not exist any z ∈Rn such that
⎧
⎨
⎩
z⊤∇f (x0) < 0,
z⊤∇gi(x0) < 0, i ∈I (x0),
z⊤∇h j(x0) < 0, j = 1, . . . , p.
(6.4)
Therefore, the system
⎧
⎨
⎩
f (x) −f (x0) < 0,
gi(x) −gi(x0) ≦0, i ∈I (x0),
h j(x) −h j(x0) = 0, j = 1, . . . , p,
(6.5)
has no solution x ∈X. Indeed, if there did exist a solution ¯x ∈X (¯x ̸= x0) then,
thanks to the assumptions,
f (¯x) −f (x0) < 0 ⇒(¯x −x0)⊤∇f (x0) < 0
(by pseudoconvexity of f );
gi(¯x) −gi(x0) ≦0 ⇒(¯x −x0)⊤∇gi(x0) < 0, ∀i ∈I (x0),
h j(¯x) −h j(x0) = 0 ⇒(¯x −x0)⊤∇h j(x0) < 0, j = 1, . . . , p,
(by strict pseudoconvexity of g and h).

182
6
Constrained Optimization Problems with Mixed Constraints
But this violates (6.4), which has no solution z = ¯x −x0. Recalling that gi(x0) =
0, i ∈I (x0), we have from (6.5) that
⎧
⎪⎪⎨
⎪⎪⎩
f (x) −f (x0) < 0,
gi(x) ≦0, i ∈I (x0),
gi(x) ≦0, i /∈I (x0),
h j(x) = 0, j = 1, . . . , p
has no solution x ∈X. Hence, x0 is an optimal solution of problem (P5), being
x0 ∈K5.
□
Remark 6.11 It is worthwhile to make the following considerations. Let be given
the problems
(P1) ≡(P5) : min f (x), subject to g(x) ≦0, h(x) = 0;
(P2) : min f (x), subject to g(x) ≦0, h(x) ≦0;
(P3) ≡(P4) : min f (x), subject to g(x) ≦0.
Let Si be the feasible set of (Pi), i = 1, 2, 3. Let Ci(x0) be a sufﬁcient condition
for x0 ∈Si to be a solution of (Pi), i = 1, 2, 3. Clearly
S1 ⊂S2 ⊂S3.
(6.6)
Then it follows trivially from (6.6) that
Ci(x0) and h(x0) = 0, i = 2, 3,
(6.7)
is a sufﬁcient condition for x0 to be an optimal solution of (P1). If Ci(x0) in (6.7) is
well known, then the sufﬁcient condition (6.7) requires no further investigation and
proof.
We give now a local ﬁrst-order sufﬁcient optimality condition, due to Fritz John,
for (P5), which works in absence of generalized convexity assumptions and also
for the “degenerate case” of u0 = 0 (see the similar conditions for (P4) in Theorem
5.12).
Theorem 6.12 Let x0 ∈K5 be a point satisfying the Fritz John conditions:
u0∇f (x0) +
m

i=1
ui∇gi(x0) +
p

j=1
v j∇h j(x0) = 0;
uigi(x0) = 0, i = 1, . . . , m;

6.1 First-Order Conditions
183
(u0, u1, . . . , um) ≧0, v1, . . . , vp ∈R;
u0, u1, . . . , um, v1, . . . , vp, not all zero.
If the vectors
u0∇f (x0),

ui∇gi(x0)

i∈I (x0) ,

∇h j(x0)
p
j=1
span Rn, i.e. the matrix formed by the above vectors has rank n, then x0 is a local
minimizer of (P5).
Proof Suppose that x0 is not a local minimizer of (P5). Then, there exists a feasible
sequence of points xk →x0 satisfying f (xk) < f (x0). Writing xk = x0 + tk yk,
with tk > 0,
yk = 1, we have
0 > f (x0 + tk yk) −f (x0) = tk∇f (x0)⊤yk + o(tk),
0 ≧gi(x0 + tk yk) = tk∇gi(x0)⊤yk + o(tk), i ∈I (x0),
0 = h j(x0 + tk yk) = tk∇h j(x0)⊤yk + o(tk), j = 1, . . . , p.
Since
yk = 1, we can assume, by taking a subsequence if necessary, that yk →
y, ∥y∥= 1. Dividing both sides of all equalities and inequalities above by tk and
letting tk →0 gives ∇f (x0)⊤y ≦0, ∇gi(x0)⊤y ≦0, i ∈I (x0), and ∇h j(x0)⊤y =
0, j = 1, . . . , p.
Since
u0∇f (x0)⊤y +

i∈I (x0)
ui∇gi(x0)⊤y +
p

j=1
v j∇h j(x0)⊤y = 0
we have
u0∇f (x0)⊤y = 0;
ui∇gi(x0)⊤y = 0, i ∈I (x0);
∇h j(x0)⊤y = 0, j = 1, . . . , p.
By virtue of our assumption on the gradient vectors, the vector y is orthogonal to
every vector in Rn. This implies y = 0, contradicting ∥y∥= 1.
□
Another ﬁrst-order sufﬁcient condition for the local optimality of x0 ∈K5 is given
in the following “primal” condition given by Still and Streng [11].
Theorem 6.13 Let x0 ∈K5 and suppose that there is no nonzero solution y ∈Rn
to the system

184
6
Constrained Optimization Problems with Mixed Constraints
⎧
⎨
⎩
∇f (x0)⊤y ≦0,
∇gi(x0)⊤y ≦0, i ∈I (x0),
∇h j(x0)⊤y = 0, j = 1, . . . , p,
then x0 is a strict local minimizer of order one for problem (P5), i.e. there exist N(x0)
and a number m > 0 such that
f (x) ≧f (x0) + m
x −x0 , ∀x ∈K5 ∩N(x0).
A ﬁrst-order sufﬁcient condition for local optimality of x0 ∈K5, in terms of
“dual” conditions is given by Hestenes [12], Theorem 7.2. See also Giorgi, Jiménez
and Novo [13].
Theorem 6.14 Let x0 ∈K5 and suppose that x0 satisﬁes the Karush-Kuhn-Tucker
conditions of Theorem 6.4. Suppose further that there is no vector y ̸= 0, y ∈L(x0)
such that ∇f (x0)⊤y = 0. Then x0 is a strict local minimizer of order one for problem
(P5).
Proof We have previously proved that the inequality
∇f (x0)⊤y ≧0
holds for every y ∈L(x0) if and only if x0 satisﬁes the Karush-Kuhn-Tucker condi-
tions (it is a direct consequence of Farkas’ theorem). In virtue of this assertion, our
hypotheses imply
∇f (x0)⊤y > 0
for every y ̸= 0, y ∈L(x0). But being T (K5, x0) ⊂L(x0), we have therefore
∇f (x0)⊤y > 0, ∀y ̸= 0, y ∈T (K5, x0).
By Theorem 4.25, this states that x0 is a strict local minimizer for (P5); more
exactly (Hestenes [12]), x0 is a strict local minimizer of order one for (P5).
□
6.2
Constraint Qualiﬁcations
In this section, we review the most used constraint qualiﬁcations for problem (P5).
The Guignard-Gould-Tolle c. q., the Abadie c. q. and the Kuhn-Tucker c. q. seen in
the previous chapter are simply generalized to problem (P5). Let x0 ∈K5.
(1) Guignard-Gould-Tolle constraint qualiﬁcation. It is expressed as
(L(x0))∗= (T (K5, x0))∗
or, equivalently,

6.2 Constraint Qualiﬁcations
185
L(x0) = cl(conv(T (K5, x0))).
(2) Abadie constraint qualiﬁcation. It is expressed as
L(x0) = T (K5, x0).
We shall see in the present section that the Guignard-Gould-Tolle c. q. is, in a
certain sense, the weakest constraint qualiﬁcation for (P5). The following example
shows that the Guignard-Gould-Tolle c. q. may be strictly weaker than the Abadie
c. q.
Example 6.15 Consider the problem
⎧
⎨
⎩
min

(x1)2 + (x2)2
subject to: x1x2 = 0,
x1 ≧0, x2 ≧0.
The global minimizer is x0 = (0, 0)⊤.
T (K5, x0) =

y ∈R2 : y1 ≧0, y2 ≧0, y1y2 = 0

⊂L(x0) =

y ∈R2 : y1 ≧0, y2 ≧0

.
Hence, the Abadie c. q. is violated at x0. On the other hand, we have
(T (K5, x0))∗=

y ∈R2 : y1 ≦0, y2 ≦0

= (L(x0))∗
and hence the Guignard-Gould-Tolle c. q. is satisﬁed at x0. Note, however, that the
Abadie c. q. (and hence the Guignard-Gould-Tolle c. q.) is satisﬁed at any other
feasible point of the problem.
(3) Kuhn-Tucker constraint qualiﬁcation or Karush-Kuhn-Tucker constraint qual-
iﬁcation. It is expressed as
L(x0) = A(K5, x0).
For what said about the cones A(·, ·) and T (·, ·), we have obviously
Kuhn-Tucker c.q. ⇒Abadie c. q. ⇒Guignard-Gould-Tolle c. q.
(4) Mangasarian-Fromovitz constraint qualiﬁcation (MF c. q.). It is expressed as:
(i) The gradients ∇h j(x0), j = 1, . . . , p, are linearly independent.
(ii) It holds Lo(x0) ̸= ∅, i.e. the system
	∇gi(x0)⊤y < 0, i ∈I (x0),
∇h j(x0)⊤y = 0, j = 1, . . . , p,
has a solution y ∈Rn.

186
6
Constrained Optimization Problems with Mixed Constraints
This constraint qualiﬁcation can be also expressed in the following equivalent
form: The gradients ∇h j(x0), j = 1, . . . , p, are linearly independent and L(x0) =
cl(Lo(x0)).
The Mangasarian-Fromovitz c. q. has also a “dual” representation, given in the
following result.
Theorem 6.16 Let x0 ∈K5; then the Mangasarian-Fromovitz constraint qualiﬁca-
tion is equivalent to the positive linear independence of the vectors

∇gi(x0), i ∈I (x0); ∇h j(x0), j = 1, . . . , p

.
That is, the only solution of the linear system

i∈I (x0)
ui∇gi(x0) +
p

j=1
v j∇h j(x0) = 0, ui ≧0, ∀i ∈I (x0),
is the zero vector.
Proof Let us suppose that the Mangasarian-Fromovitz c. q. is satisﬁed. If the system
of Theorem 6.16 admits a solution with ui > 0 for some i ∈I (x0), by using the
theorem of the alternative of Motzkin (Theorem 2.31) we obtain at once a contra-
diction with the Mangasarian-Fromovitz c. q. Let us suppose that the linear system
in question admits a solution with ui = 0, for all i ∈I (x0), but v j ̸= 0 for some
j = 1, . . . , p. In this case, the gradients ∇h j(x0), j = 1, . . . , p, are linearly depen-
dent, and again we obtain a contradiction with the Mangasarian-Fromovitz c. q.
Vice versa, let us suppose that the linear system of the theorem admits only the
zero solution. In particular, the system has no solution ui > 0 for some i ∈I (x0).
Again by using the theorem of Motzkin, we obtain that there exists y ∈Rn that
satisﬁes the Mangasarian-Fromovitz c. q. Indeed, the vectors

∇h j(x0), j = 1, . . . , p

are linearly independent, as, if not, there would exist some v j ̸= 0 such that 0 =
p
j=1 v j∇h j(x0), against the assumption that the linear system of the theorem has
the zero solution only (by choosing ui = 0, ∀i ∈I (x0)).
□
The Mangasarian-Fromovitz c. q. is also called No Nonzero Abnormal Multiplier
Constraint Qualiﬁcation or also Basic Constraint Qualiﬁcation. Note that in absence
of equality constraints, the Mangasarian-Fromovitz c. q. is equivalent to the Cottle
c. q. or Arrow-Hurwicz-Uzawa c. q., seen for (P4). The Mangasarian-Fromovitz
constraint qualiﬁcation is a stable constraint qualiﬁcation, in the following sense. If
this qualiﬁcation holds at x0 ∈K5, then there exists a neighborhood U(x0) such that
the same constraint qualiﬁcation holds at each x ∈U(x0) ∩K5.

6.2 Constraint Qualiﬁcations
187
We shall see in the sequel another important property of the Mangasarian-
Fromovitz c. q. For what previously said in Theorem 6.1 and in Remark 6.2, we
have the following implications:
Mangasarian-Fromovitz c.q. ⇒Kuhn-Tucker c. q.
⇒Abadie c. q. ⇒Guignard-Gould-Tolle c.q.
For a more detailed proof of the above implications, the reader can see the paper
of Still and Streng [11].
Similarly to what done in Chap. 5 for problem (P4), we can relax the Mangasarian-
Fromovitz c. q. by introducing the second Abadie c. q. and the second Arrow-
Hurwicz-Uzawa c. q.
(5) Abadie constraint qualiﬁcation II. It is expressed as: the vectors ∇h j(x0),
j = 1, . . . , p, are linearly independent and Lo
1(x0) ̸= ∅, where
Lo
1(x0) =
⎧
⎨
⎩
y ∈Rn : ∇gi(x0)⊤y < 0, i ∈I (x0), gi is nonlinear;
∇gi(x0)⊤y ≦0, i ∈I (x0), gi is linear afﬁne;
∇h j(x0)⊤y = 0, j = 1, . . . , p.
⎫
⎬
⎭.
(6)Arrow-Hurwicz-UzawaconstraintqualiﬁcationII(AHUc.q.II).Itisexpressed
as: the vectors ∇h j(x0), j = 1, . . . , p, are linearly independent and Lo
2(x0) ̸= ∅,
where, with X ⊂Rn open convex set,
Lo
2(x0) =
⎧
⎨
⎩
y ∈Rn : ∇gi(x0)⊤y < 0, i ∈I (x0), gi is non-pseudoconcave on X;
∇gi(x0)⊤y ≦0, i ∈I (x0), gi is pseudoconcave on X;
∇h j(x0)⊤y = 0, j = 1, . . . , p.
⎫
⎬
⎭.
Obviously, if all functions gi, i ∈I (x0), are linear (afﬁne), and the gradients
∇h j(x0), j = 1, . . . , p, are linearly independent, then the Abadie constraint quali-
ﬁcation II holds automatically and if all functions gi, i ∈I (x0), are pseudoconcave
and the gradients ∇h j(x0), j = 1, . . . , p, are linearly independent, then the Arrow-
Hurwicz-Uzawa constraint qualiﬁcation II holds automatically.
We have the following implications.
MF c. q. ⇒Abadie c. q. II ⇒AHU c. q. II ⇒Kuhn-Tucker c. q.
(7) Slater constraint qualiﬁcation.
In its extended form it is expressed as: every gi, i ∈I (x0), is pseudoconvex
and every h j, j = 1, . . . , p, is quasilinear (i.e. quasiconvex and quasiconcave) on
the open convex set X ⊂Rn, the gradients ∇h j(x0), j = 1, . . . , p, are linearly
independent and there exists ¯x ∈K5 such that gi(¯x) < 0, i ∈I (x0), and h j(¯x) = 0,
j = 1, . . . , p.

188
6
Constrained Optimization Problems with Mixed Constraints
Theorem 6.17 The Slater c. q. implies the Mangasarian-Fromovitz c. q.
Proof Let y = ¯x −x0. We only need to prove that it holds ∇h j(x0)⊤y = 0 for all
j = 1, . . . , p. For each h j(x) and all λ ∈[0, 1] , we have
h j(λ¯x + (1 −λ)x0) ≦max

h j(x0), h j(¯x)

= 0,
because h j(x) is quasiconvex. Note that h j(x) is also quasiconcave, hence
h j(λ¯x + (1 −λ)x0) ≧min

h j(x0), h j(¯x)

= 0.
Consequently, h j(λ¯x + (1 −λ)x0) = 0. By the Taylor’s expansion of h j(λ¯x + (1 −
λ)x0) at x0, we have
λ∇h j(x0)⊤y + o(λ) ∥y∥= 0,
as λ →0. Similarly to the proof of Theorem 5.17, we can prove that ∇gi(x0)⊤y < 0,
∀i ∈I (x0). Therefore, y ∈Lo(x0) and so Lo(x0) ̸= ∅. The Mangasarian-Fromovitz
c. q. is therefore satisﬁed.
□
Note that if in (P5) the constraints h j(x), j = 1, . . . , p, are linear afﬁne, with
the gradients ∇h1(x0), . . . , ∇h p(x0) linearly dependent, we can always choose a
linearly independent subset of this set, say ∇h1(x0), . . . , ∇hk(x0), such that
span

∇h1(x0), . . . , ∇hk(x0)

= span

∇h1(x0), . . . , ∇h p(x0)

.
Moreover, keeping only the constraints h1, . . . , hk in the formulation of (P5),
does not change its feasible set. That’s why some authors (e.g. Bazaraa and Shetty
[14]) formulate the extended Slater c. q. for (P5), by assuming that the functions h j,
j = 1, . . . , p, are linear afﬁne, without mentioning the linear independence of their
gradients. Therefore, we can assert that if in (P5) all functions gi, i ∈I (x0), and
all functions h j, j = 1, . . . , p, are linear afﬁne, the problem is automatically qual-
iﬁed. Again, for a Linear Programming Problem, with both inequality and equality
constraints, no constraint qualiﬁcation is needed.
(8) Linear Independence constraint qualiﬁcation (LI c. q.). It is expressed as: the
gradients

∇gi(x0), i ∈I (x0); ∇h j(x0), j = 1, . . . , p

are linearly independent.
Owing to the “dual” characterization of the Mangasarian-Fromovitz c. q. (Theo-
rem 6.16), we have the following implication:
LI c. q. ⇒MF c. q. .
(9) Constant Rank constraint qualiﬁcation (CR c.q.). It was introduced by Janin
[15] and is expressed as follows: there exists a neighborhood N(x0) of x0 ∈K5

6.2 Constraint Qualiﬁcations
189
such that for every pair of subsets I1(x0) ⊂I (x0) and J1 ⊂{1, . . . , p} , the set of
gradients

∇gi(x), i ∈I1(x0); ∇h j(x), j ∈J1

has the same rank for all x ∈N(x0) ∩K5.
It appears that the rank in question depends on the choice of I1(x0) and J1 but
not on the point x ∈N(x0) ∩K5. Clearly, the Linear Independence c. q. implies the
Constant Rank c. q. Linearity of all constraints of (P5) also implies the Constant Rank
c. q. The constant Rank c. q. is indeed a constraint qualiﬁcation: Janin [15] proved
that this constraint qualiﬁcation implies the Abadie c. q. However, the Constant Rank
c. q. is neither weaker nor stronger than the Mangasarian-Fromovitz c. q.
Note also that, unlike the Mangasarian-Fromovitz c. q., if the Constant Rank c. q.
holds at x0 ∈K5, it will continue to hold if any of the equality constraints h j(x) = 0
were to be replaced by the two inequalities h j(x) ≦0 and −h j(x) ≦0.
(10) Constant Positive Linear Dependence constraint qualiﬁcation (CPLD c. q.).
It was introduced by Qi and Wei [16] and is expressed as follows: there exists a
neighborhood N(x0) of x0 ∈K5 such that whenever for some index set I1(x0) ⊂
I (x0) and J1 ⊂{1, . . . , p} , the system

i∈I1(x0)
ui∇gi(x0) +

j∈J1
v j∇h j(x0) = 0, ui ≧0, ∀i ∈I1(x0),
has a nonzero solution, the set

∇gi(x), i ∈I1(x0)

∪

∇h j(x), j ∈J1

is linearly dependent for all x ∈N(x0).
Comparing the dual form (Theorem 6.16) of the Mangasarian-Fromovitz c. q.
with the above constraint qualiﬁcation, it is immediate that
MF c. q. ⇒CPLD c. q. .
It can be proved that the Constant Positive Linear Dependence c. q. is indeed a
constraint qualiﬁcation, as it implies the Abadie c. q. (Andreani et al. [17]). It can be
also proved that CPLD c. q. is weaker than the Constant Rank c. q. Hence,
LI c. q. ⇒CR c. q. ⇒CPLD c. q. ⇒Abadie c. q.
and
LI c. q. ⇒MF c. q. ⇒CPLD c. q. ⇒Abadie c. q. .
The Mangasarian-Fromovitz constraint qualiﬁcation is a necessary and sufﬁcient
conditioninorderthatthesetofKarush-Kuhn-Tuckermultipliersfor(P5)at x0 ∈K5,
is a closed and bounded set. This result is due to Gauvin [18]. Let us denote by M(x0)

190
6
Constrained Optimization Problems with Mixed Constraints
the set of Karush-Kuhn-Tucker multipliers for (P5):
M(x0) =
	
(u, v) ∈Rm × Rp : ∇xL (x0, u, v) = 0;
uigi(x0) = 0, i = 1, . . . , m; ui ≧0, i = 1, . . . , m

.
We have the following result.
Theorem 6.18 Let x0 ∈K5 and let M(x0) ̸= ∅. Then M(x0) is closed and bounded
(more precisely: a compact convex polyhedron, i.e. a polytope) if and only if the
Mangasarian-Fromovitz c. q. holds at x0.
Proof Let us ﬁrst suppose that the Mangasarian-Fromovitz c. q. is satisﬁed at x0.
As the set of multipliers is a polyhedron, it is closed and convex. It remains to prove
that M(x0) is bounded. Let us suppose absurdly that M(x0) is not bounded, i.e.
there exists a sequence

(uk, vk)

⊂R|I (x0|
+
× Rp such that
(uk, vk)

→∞for
k →∞, and that for every k
−∇f (x0) =

i∈I (x0)
uk
i ∇gi(x0) +
p

j=1
vk
j∇h j(x0).
By choosing, if necessary, a subsequence, we can assume that
(uk, vk)
(uk, vk)
 →(u, v) ∈

R|I (x0|
+
× Rp
\ {0} .
If we divide both members of the last equality by
(uk, vk)
 and take the limit
for k →∞, we get
0 =

i∈I (x0)
ui∇gi(x0) +
p

j=1
v j∇h j(x0).
But this relation contradicts the dual characterization of the Mangasarian-
Fromovitz constraint qualiﬁcation (Theorem 6.16).
Now, suppose that M(x0) is bounded. If the Mangasarian-Fromovitz c. q. is not
satisﬁed, thanks to Theorem 6.16, there will exist a nonzero vector (u, v) ∈M(x0),
(u, v) ∈R|I (x0|
+
× Rp, such that

i∈I (x0)
ui∇gi(x0) +
p

j=1
v j∇h j(x0) = 0.
Let (ˆu, ˆv) ∈M(x0). In particular, it will hold

6.2 Constraint Qualiﬁcations
191
−∇f (x0) =

i∈I (x0)
ˆui∇gi(x0) +
p

j=1
ˆv j∇h j(x0).
For every α ∈R+, we have ˆu + αu ≧0 and
−∇f (x0) =

i∈I (x0)
(ˆui + αui)∇gi(x0) +
p

j=1
(ˆv j + αv j)∇h j(x0).
In other words, the multipliers vector (ˆu + αu, ˆv + αv) is a Karush-Kuhn-Tucker
multipliers vector. Being (u, v) ̸= 0, if we choose α > 0 and arbitrarily large, we
get that M(x0) is not bounded, in contradiction with our assumption.
□
Another question related to a “modiﬁed” Mangasarian-Fromovitz c. q. is the
uniqueness of Karush-Kuhn-Tucker multipliers for an optimal solution x0 ∈K5. In
other words: when M(x0) is a singleton? The question has been solved by Kyparisis
[19] who introduced what he calls the Strict Mangasarian-Fromovitz c. q.
The Strict Mangasarian-Fromovitz constraint qualiﬁcation (Strict MF c. q.) holds
at x0 ∈K5 if, denoting by I +(x0, u) the set of strictly active inequality constraints
at x0, i.e.
I +(x0, u) =

i : i ∈I (x0) and ui > 0 for (u, v) ∈M(x0)

,
it holds:
(i) The gradients
∇gi(x0), i ∈I +(x0, u); ∇h j(x0), j = 1, . . . , p,
are linearly independent.
(ii) The system
∇gi(x0)⊤y < 0, i ∈I (x0) \ I +(x0, u);
∇gi(x0)⊤y = 0, i ∈I +(x0, u);
∇h j(x0)⊤y = 0, j = 1, . . . , p,
has a solution y ∈Rn.
Obviously, we have
Linear Independence c. q. ⇒Strict MF c. q. ⇒MF c q. .
We note however that the Strict Mangasarian-Fromovitz c. q. is not properly a
constraint qualiﬁcation, as it involves the sign of the multipliers in its deﬁnition.
Usually, these multipliers depend also on the objective function and not only on the

192
6
Constrained Optimization Problems with Mixed Constraints
constraints. Perhaps a better name would be “Strict Mangasarian-Fromovitz regular-
ity condition”.
Similarly to what holds for the Mangasarian-Fromovitz c. q., we have the follow-
ing “dual” characterization of the Strict Mangasarian-Fromovitz c. q. For brevity, in
the summation symbols, we denote I +(x0, u) by I + and I (x0) \ I +(x0, u) by I 0.
Theorem 6.19 The Strict Mangasarian-Fromovitz c. q. holds at x0 ∈K5 if and only
if there exist no vector (s, t, v) ̸= 0, s = {si} , i ∈I 0, s ≧0, such that

i∈I 0
si∇gi(x0) +

i∈I +
ti∇gi(x0) +
p

j=1
v j∇h j(x0) = 0.
(6.8)
Proof We rewrite as follows the Strict Mangasarian-Fromovitz c. q.:
(a) The gradients
∇gi(x0), i ∈I +(x0, u); ∇h j(x0), j = 1, . . . , p
are linearly independent.
(b) (By Motzkin’s theorem) there is no vector (s, t, v), s ≧0, s ̸= 0, such that

i∈I 0
si∇gi(x0) +

i∈I +
ti∇gi(x0) +
p

j=1
v j∇h j(x0) = 0.
We now show the equivalence between (6.8) and (a) and (b). Assume absurdly that
there exists a multipliers vector (s, t, v) ̸= 0, with s ≧0, such that (6.8) holds. We
have two cases:
(i) s ̸= 0; but this is in contradiction with (b).
(ii) s = 0; then it holds (t, v) ̸= 0, but this is in contradiction with (a).
Conversely, let us absurdly suppose that
∇gi(x0), i ∈I +(x0, u); ∇h j(x0), j = 1, . . . , p
are linearly dependent, i.e. there exist multipliers vectors (t, v) ̸= 0 such that

i∈I +
ti∇gi(x0) +
p

j=1
v j∇h j(x0) = 0.
If we set s = 0, then there exists (s, t, v) ̸= 0 such that

i∈I 0
si∇gi(x0) +

i∈I +
ti∇gi(x0) +
p

j=1
v j∇h j(x0) = 0.

6.2 Constraint Qualiﬁcations
193
But this contradicts the assumptions on relation (6.8).
□
Theorem 6.20 The set M(x0) of Karush-Kuhn-Tucker multipliers associated to the
optimal point x0 ∈K5 is a singleton if and only if the Strict Mangasarian-Fromovitz
c. q. is satisﬁed at x0.
Proof Let us suppose that the Strict Mangasarian-Fromovitz c. q. is satisﬁed. Let
(¯u, ¯v) ∈M(x0) be a pair of Karush-Kuhn-Tucker multipliers vectors, and let, as
usual,
I +(x0, ¯u) =

i ∈I (x0) : ¯ui > 0

;
I 0 = I (x0) \ I +(x0, ¯u).
If there exists another pair (ˆu, ˆv) ∈M(x0), with (ˆu, ˆv) ̸= (¯u, ¯v), then

i∈I (x0)
(ˆui −¯ui)∇gi(x0) +
p

j=1
(ˆv j −¯v j)∇h j(x0) = 0,
with (ˆui −¯ui; ˆv j −¯v j) ̸= 0 and ˆui −¯ui = ˆui ≧0 for i ∈I 0. But this contradicts
the validity of the Strict Mangasarian-Fromovitz c. q., on the grounds of Theorem
6.19.
Conversely, if (¯u, ¯v) is the unique pair in M(x0), it is easy to verify that there
does not exist a nonzero solution of relation (6.8), which is equivalent to say that the
Strict Mangasarian-Fromovitz c. q. is satisﬁed.
□
Another question related to the set M(x0) of Karush-Kuhn-Tucker multipliers is
the following one: obviously M(x0) depends a priori on the point x0 ∈K5. When
M(x0) is independent of the choice of x0? If (P5) is a convex problem, in the sense
speciﬁed by the next deﬁnition, then the set M(x0) does not depend on the minimum
point x0.
Deﬁnition 6.21 Problem (P5) is a convex problem if f : X →R and every gi :
X →R, i = 1, . . . , m, are convex functions on the open convex set X ⊂Rn and
every h j : Rn →R, j = 1, . . . , p, is a linear afﬁne function.
Theorem 6.22 Let (P5) be a convex problem. The set M(x0) is the same for all
minimum points of f on K5.
Proof Clearly K5 is a convex set. Let x1, x2 ∈K5 be two minimum points of f on K5
and let M(x1) and M(x2) be the two related sets of Karush-Kuhn-Tucker multipliers.
Let us verify that M(x1) = M(x2). According to the fact that these points are global
minimum points ( f is convex) one has f (x1) = f (x2). Let (u, v) ∈M(x1). Then
∇f (x1) +
m

i=1
ui∇gi(x1) +
p

j=1
v j∇h j(x1) = 0,

194
6
Constrained Optimization Problems with Mixed Constraints
with ui ≧0, uigi(x1) = 0, for every i = 1, . . . , m. The convex Lagrangian function
L (·, u, v) is minimized at x1 on X, therefore L (x2, u, v) ≧L (x1, u, v), which
implies
f (x2) +
m

i=1
uigi(x2) ≧f (x1) = f (x2).
Taking into account the signs of the multipliers ui and of gi(x2), we have that
uigi(x2) = 0 for every i = 1, . . . , m. From
L (x2, u, v) = f (x2) = f (x1) = L (x1, u, v)
we get that x2 is a minimum point for the convex function L (·, u, v) on X. Hence,
∇f (x2) +
m

i=1
ui∇gi(x2) +
p

j=1
v j∇h j(x2) = 0.
We have that (u, v) ∈M(x2). The inclusion M(x1) ⊂M(x2) is therefore proved.
The converse inclusion follows by exchanging x1 and x2 in the above proof.
□
We have previously asserted that if the Guignard-Gould-Tolle constraint qualiﬁ-
cation holds, i.e.
(T (K5, x0))∗= (L(x0))∗
(6.9)
then, any differentiable objective function f having a local minimum over K5 at x0
satisﬁes the Karush-Kuhn-Tucker conditions at x0:
∇f (x0) +

i∈I (x0)
ui∇gi(x0) +
p

j=1
v j∇h j(x0) = 0, ui ≧0, ∀i ∈I (x0).
(6.10)
We have also, more than one time, asserted that (6.9) is, in a certain sense, the
weakest constraint qualiﬁcation that guarantees that the above Karush-Kuhn-Tucker
conditions will hold at a minimizer x0. In order to be more precise, we introduce the
following deﬁnition, due to Gould and Tolle [5], but anticipated for problem (P4) by
Arrow et al. [6].
Deﬁnition 6.23 The pair (g, h) of problem (P5) is said to be Lagrange regular
at x0 ∈K5 if and only if for every objective function f, with a constrained local
minimum at x0, the Karush-Kuhn-Tucker conditions hold at x0.
Gould and Tolle [5] show that the pair (g, h) is Lagrange regular at x0 ∈K5 if
and only if the Guignard-Gould. Tolle c. q. (6.9) holds. In other words, for any given
objective function f (x) with a local minimum over K5 at x0, if the Karush-Kuhn-
Tucker conditions (6.10) hold, we can claim that (6.9) holds.

6.2 Constraint Qualiﬁcations
195
Theorem 6.24 Let x0 ∈K5. Then the constraint qualiﬁcation (T (K5, x0))∗=
(L(x0))∗is equivalent to the fact that the pair (g, h) is Lagrange regular at x0.
Proof To prove the above theorem we only need to show that (T (K5, x0))∗⊂
(L(x0))∗, since the converse inclusion is always true. We will show that for each
y ∈(T (K5, x0))∗there corresponds an objective function f which is differentiable
at x0 and has a local minimum over K5 at x0 with the property that y = −∇f (x0).
But from the Karush-Kuhn-Tucker conditions we have
−∇f (x0) =

i∈I (x0)
ui∇gi(x0) +
p

j=1
v j∇h j(x0),
where ui ≧0, ∀i ∈I (x0). Hence, y ∈(L(x0))∗.
We follow closely the proof of Haeser and Ramos [20] who amend some minor
inaccuracies of the original proof of Gould and Tolle. Another proof is given by
Bazaraa and Shetty [14].
Then, let y ̸= 0, y ∈(T (K5, x0))∗. The Lagrange regularity assumption implies
y ∈(L(x0))∗. Let us deﬁne Ck, k ≧1, a cone of nonzero directions which form
with y an angle between 0 and π
2 −
π
k+3. Then, for every k ≧1 there exists ˆεk > 0,
such that K5 ∩N(x0, ˆεk) ⊂Rn \ Ck. Indeed, if there would exist k such that xℓ∈
Ck ∩K5, xℓ→x0, then
y⊤xℓ
xℓ ≧∥y∥cos
π
2 −
π
k + 3

> 0.
Taking the limit in ℓfor a subsequence, we would have y⊤d > 0, with d ∈
T (K5, x0), which contradicts the fact that y ∈(T (K5, x0))∗.
Let us deﬁne ε1 = min(ˆε1, 1) and εk = min(ˆεk, εk−1
2 ), k > 1. Let us assume, with-
out loss of generality, that x0 = 0 and y = (0, . . . , 0, 1)⊤; moreover, let us deﬁne
P : Rn−1 →R in a subspace orthogonal to y, in the following way:
P(z) =
⎧
⎪⎪⎨
⎪⎪⎩
0,
if z = 0,
tan
 π
3

,
if ∥z∥≧ε2,
tan

π
k+2

εk+1 +
tan

π
k+1

εk−tan

π
k+2

εk+1
εk−εk+1
· (∥z∥−εk+1), if εk+1 ≦∥z∥≦εk.
We remark that P is piecewise linear and continuous. Moreover, for εk+1 ≦∥z∥≦
εk, we have
tan

π
k + 2

∥z∥≦P(z) ≦tan

π
k + 1

∥z∥.
This fact is a geometric property of afﬁne and increasing functions which have
a negative value at the origin. It shows that P is differentiable at the origin, with
∇P(0) = 0. Let now be f : Rn →R deﬁned by f (d) = P(z) −y⊤d, where d =
(z, w) ∈Rn−1 × R and let us prove that f has a local minimum over K5 at x0 = 0.

196
6
Constrained Optimization Problems with Mixed Constraints
Letbed = (z, w) ̸= (0, 0) ∈Rn−1 × R,withd ∈K5 ∩N(0, ε3).As y = (0, . . . ,
0, 1)⊤and P(0) = 0, it is sufﬁcient to show that w < P(z). If z = 0, in case w > 0
we would have that d is a positive multiple of y ∈(T (K5, x0))∗, which contradicts
the fact that d ∈K5. Hence, w < 0 = P(z). being z ̸= 0 there exists k ≧2 such
that εk+1 ≦∥z∥≦εk. Therefore, P(z) ≦∥z∥tan
 π
k+2

. Note that d /∈Cr is equiv-
alent to say that w < tan
 π
r+3
 ∥z∥. Being d ∈K5 ∩N(0, ε3) ⊂Rn \ C3, we have
w < tan
 π
3+3
 ∥z∥< ∥z∥. Assuming w > 0, as in the opposite case the result is
trivially veriﬁed, we have
∥d∥=

∥z∥2 + |w|2 <
√
2 ∥z∥< 2εk ≦εk−1.
Hence, d ∈K5 ∩N(0, εk−1) ⊂Rn \ Ck−1. Being d ̸= Ck−1, we have w < tan

π
k−1+3
 ∥z∥. It follows that w < P(z). Being f (0) = 0 and f (d) > 0 for d ̸=
0 ∈K5 sufﬁciently small, it follows from the assumptions that x0 = 0 satisﬁes the
Karush-Kuhn-Tucker conditions, i.e. y = −∇f (0) ∈(L(x0))∗.
□
We wish to stress that the Lagrange regularity of (g, h) of problem (P5) is intended
with regard to all differentiable objective functions having at x0 ∈K5 a local mini-
mum point. It is therefore possible to ﬁnd examples where the Guignard-Gould-Tolle
constraint qualiﬁcation does not hold, yet the Karush-Kuhn-Tucker conditions hold
at an optimal point x0 of f over K5.
Example 6.25 Let us consider the problem
	
min x2
subject to: (x1)2 −x2 ≦0; x2 ≦0.
The point x0 = (0, 0) is a global minimum point of f over the feasible set, the
Guignard-Gould-Tolle c. q. is not satisﬁed at x0, but at x0 the Karush-Kuhn-Tucker
conditions hold.
Following Forst and Hoffmann [8], further insights on the Karush-Kuhn-Tucker
conditions and on the Guignard-Gould-Tolle c. q. can be obtained by “linearizing”
problem (P5). Let us consider the following linearized version of (P5).
(P5)L :
⎧
⎨
⎩
min f (x0) + ∇f (x0)⊤(x −x0)
subject to: gi(x0) + ∇gi(x0)⊤(x −x0) ≦0, i = 1, . . . , m,
h j(x0) + ∇h j(x0)⊤(x −x0) = 0, j = 1, . . . , p.
The feasible set of (P5)L will be denoted by (K5)L. If a local minimizer x0 of
(P5) also solves (P5)L, then the Karush-Kuhn-Tucker conditions for (P5)L are met
and hence also for (P5) since the gradients that occur are the same in both problems.
The following example, due to Forst and Hoffmann, shows that the converse of the
above assertion is not true.

6.2 Constraint Qualiﬁcations
197
Example 6.26 Let us consider the problem, with x = (x1, x2) ∈R2:
⎧
⎨
⎩
min x1
subject to: −(x1)3 + x2 ≦0,
−x2 ≦0.
It is seen that x0 = (0, 0)⊤yields the global minimum for the problem. The related
linearized problem is
⎧
⎨
⎩
min x1
subject to: x2 ≦0,
−x2 ≦0,
with feasible set KL =

x ∈R2 : x2 = 0

. The linearized objective function x1 is
not even bounded from below on KL.
We can rewrite problem (P5)L by removing the value f (x0) and by using only
the set of the active inequalities at x0, i.e.
(P5(I (x0))L :
⎧
⎨
⎩
min ∇f (x0)⊤(x −x0)
subject to: ∇gi(x0)⊤(x −x0) ≦0, i ∈I (x0),
∇h j(x0)⊤(x −x0) = 0, j = 1, . . . , p,
being of course h j(x0) = 0, j = 1, . . . , p.
Lemma 6.27 Let x0 ∈K5; then x0 is a solution of (P5)L if and only if x0 is a solution
of (P5(I (x0))L.
Proof Let us denote by (K5(I (x0)))L the feasible set of (P5(I (x0))L. If x0 is a
solution of (P5(I (x0))L, then ∇f (x0)⊤(x −x0) ≧0 holds for x ∈(K5(I (x0)))L.
Since x0 ∈(K5)L ⊂(K5(I (x0)))L, x0 is also a solution of (P5)L.
If conversely x0 is a minimizer of (P5)L, then f (x0) + ∇f (x0)⊤(x −x0) ≧
f (x0), hence ∇f (x0)⊤(x −x0) ≧0 holds for x ∈(K5)L. Let x ∈(K5(I (x0)))L;
we consider the vector
u(t) = x0 + t(x −x0)
with t > 0. It holds that
∇h j(x0)⊤(u(t) −x0) = t∇h j(x0)⊤(x −x0) = 0, j = 1, . . . , p,
and for i ∈I (x0),
∇gi(x0)⊤(u(t) −x0) = t∇gi(x0)⊤(x −x0) ≦0.
For i /∈I (x0) we have gi(x0) < 0 and thus for t sufﬁciently small
gi(x0) + ∇gi(x0)⊤(u(t) −x0) = gi(x0) + t∇gi(x0)⊤(x −x0) < 0.

198
6
Constrained Optimization Problems with Mixed Constraints
Hence, for such t the vector u(t) is in (K5)L, consequently
f (x0) + ∇f (x0)⊤(u(t) −x0) ≧f (x0)
and thus
t∇f (x0)⊤(x −x0) = ∇f (x0)⊤(u(t) −x0) ≧0,
hence ∇f (x0)⊤(x −x0) ≧0. Since we have chosen x ∈(K5(I (x0)))L arbitrary, x0
yields a solution to (P5(I (x0))L.
□
With the transformation d = x −x0 we obtain the following formulation of prob-
lem (P5(I (x0))L:
(P5(d))L :
⎧
⎨
⎩
min ∇f (x0)⊤d
subject to: ∇gi(x0)⊤d ≦0, i ∈I (x0),
∇h j(x0)⊤d = 0, j = 1, . . . , p.
Lemma 6.28 Let x0 ∈K5; then x0 is a solution of (P5)L if and only if 0 ∈Rn is a
solution of (P5(d))L.
Proof Obviously, on the grounds of Lemma 6.27.
□
We remark that the feasible set of (P5(d))L is the linearizing cone L(x0) of (P5)
at x0 ∈K5.
The following proposition clariﬁes the role of the various linearized problems
with respect to the Karush-Kuhn-Tucker conditions for (P5). Let x0 ∈K5; we recall
that the cone
D<( f, x0) =

d ∈Rn : ∇f (x0)⊤d < 0

is the cone of descent directions of f at x0, already considered in the present section
when we discussed how to obtain the Karush-Kuhn-Tucker conditions from the
Guignard-Gould-Tolle constraint qualiﬁcation.
Theorem 6.29 Let x0 ∈K5; then the following assertions are equivalent:
(a) x0 is a solution of (P5)L.
(b) x0 is a solution of (P5(I (x0)))L.
(c) 0 ∈Rn is a solution of (P5(d))L.
(d) −∇f (x0) ∈(L(x0))∗.
(e) L(x0) ∩D<( f, x0) = ∅.
(f) The Karush-Kuhn-Tucker conditions hold at x0.
The equivalence of the previous assertions has already been proved in the present
section.
We recall once more that if x0 ∈K5 is a local solution of (P5), then
−∇f (x0) ∈(T (K5, x0))∗,

6.2 Constraint Qualiﬁcations
199
being, moreover, T (K5, x0) ⊂L(x0), i.e. (L(x0))∗⊂(T (K5, x0))∗. Therefore, if it
holds
(L(x0))∗= (T (K5, x0))∗,
i.e. the Guignard-Gould-Tolle c. q. holds at x0, then the Karush-Kuhn-Tucker con-
ditions hold at x0 (points (d) and (f ) of the previous theorem).
We conclude this section with a couple of examples.
Example 6.30 Consider the problem
min
	1
2((x1)2 + (x2)2)

subject to: (x1 −1)2 + (x2)2 −1
4 ≦0;
x1 + x2 −1 = 0.
The feasible set is given by the segment with end points A and B, with respective
coordinates

1 −
1
2
√
2
,
1
2
√
2

;

1 +
1
2
√
2
, −1
2
√
2

.
It is seen that, in all interior points of the said segment, only the equality constraint
is active and it holds ∇h(x) = [1, 1]⊤. At the end points of the segment, A and B,
both constraints are active and the independence constraint qualiﬁcation is satisﬁed.
We have
L (x1, x2, u1, v1) = 1
2((x1)2 + (x2)2) + u1

(x1 −1)2 + (x2)2 −1
4

+ v1(x1 + x2 −1).
The Karush-Kuhn-Tucker conditions are
x1 −2u1(x1 −1) + v1 = 0;
x2 + 2u1x2 + v1 = 0;
u1

(x1 −1)2 + (x2)2 −1
4

= 0;
u1 ≧0,
and the feasibility conditions are
x1 + x2 −1 = 0;
(x1 −1)2 + (x2)2 −1
4 ≦0.

200
6
Constrained Optimization Problems with Mixed Constraints
The case u1 = 0 is excluded, as it leads to the relation x1 = x2 = 1
2, which contra-
dicts the inequality constraint. Let therefore be u1 > 0. We obtain the two solutions
x1 = 1 ∓
1
2
√
2
,
x2 = 1 ±
1
2
√
2
,
with multipliers
u1 = −1 ±
√
2
2
,
v1 = 1
2.
The multiplier −1−
√
2
2
is negative and therefore must be rejected. Therefore, we
have the solutions
x1 = 1 −
1
2
√
2
;
x2 = 1 +
1
2
√
2
which give the unique constrained global minimum point, whose existence is assured
by the Weierstrass theorem (the objective function is continuous and the feasible set
is compact). Obviously, in this case, the use of the Karush-Kuhn-Tucker conditions
could be avoided.
Example 6.31 Consider the problem
⎧
⎨
⎩
min x1
subject to: (x1 −4)2 + (x2)2 −16 ≦0,
(x1 −3)2 + (x2 −2)2 −13 = 0.
It is quite easy to check that the feasible set is closed and bounded and that the
constraints are qualiﬁed. The Karush-Kuhn-Tucker conditions are
1 + 2u1(x1 −4) + 2v1(x1 −3) = 0,
2u1x2 + 2v1(x2 −2) = 0,
u1((x1 −4)2 + (x2)2 −16) = 0,
u1 ≧0
and the feasibility conditions are
(x1 −3)2 + (x2 −2)2 −13 = 0,
(x1 −4)2 + (x2)2 −16 ≦0.
We obtain that the point x0 = (0, 0)⊤, with multipliers u1 = 1
8, v1 = 0, is the
global minimizer of the problem; the point ¯x = ( 32
5 , 16
5 ) = (6.4, 3.2), with multipli-
ers u1 =
3
40, v1 = −1
5, is a constrained local minimizer.

6.3 Second-Order Conditions
201
6.3
Second-Order Conditions
We give in this section second-order necessary and second-order sufﬁcient optimality
conditions for problem (P5), i.e. for the problem of the form
(P5) :
⎧
⎪⎪⎨
⎪⎪⎩
min f (x)
subject to: gi(x) ≦0, i = 1, . . . , m,
h j(x) = 0, j = 1, . . . , p < n,
x ∈X ⊂Rn,
where X is an open set and the functions involved in (P5) are twice-continuously
differentiable on X.
First, we introduce three polyhedral cones, related to second-order optimality
conditions for (P5). We recall the following index sets previously deﬁned:
I (x0) =

i : gi(x0) = 0

;
I +(x0, u) =

i : i ∈I (x0), ui > 0 in the KKT conditions

;
I o(x0, u) =

i : i ∈I (x0), ui = 0 in the KKT conditions

=

i : i ∈I (x0) \ I +(x0, u)

.
We deﬁne, with x0 ∈K5,
Z(x0) =
⎧
⎨
⎩
y ∈Rn : ∇gi(x0)⊤y = 0, i ∈I +(x0, u);
∇gi(x0)⊤y ≦0, i ∈I o(x0, u);
∇h j(x0)⊤y = 0, j = 1, . . . , p
⎫
⎬
⎭,
Z1(x0) =
	 y ∈Rn : ∇gi(x0)⊤y = 0, i ∈I (x0);
∇h j(x0)⊤y = 0, j = 1, . . . , p

,
Z2(x0) =
	 y ∈Rn : ∇gi(x0)⊤y = 0, i ∈I +(x0, u);
∇h j(x0)⊤y = 0, j = 1, . . . , p

.
Being I +(x0, u) ⊂I (x0), we have
Z1(x0) ⊂Z(x0) ⊂Z2(x0).
If the Strict Complementary Slackness Conditions hold at x0, i.e. in the Karush-
Kuhn-Tucker conditions ui > 0, ∀i ∈I (x0), then obviously

202
6
Constrained Optimization Problems with Mixed Constraints
Z1(x0) = Z(x0) = Z2(x0).
The cone Z(x0) is often called critical cone or cone of critical directions at
x0 ∈K5.
In the literature another description of the cone Z(x0) often appears; it is the cone
(again called “critical cone”):
C(x0) =
	 y ∈Rn : ∇f (x0)⊤y = 0; ∇gi(x0)⊤y ≦0, i ∈I (x0);
∇h j(x0)⊤y = 0, j = 1, . . . , p

.
Indeed, it can be proved that, under the validity of the Karush-Kuhn-Tucker con-
ditions at x0 ∈K5, the two cones C(x0) and Z(x0) coincide.
Theorem 6.32 Let x0 ∈K5 verify the Karush-Kuhn-Tucker conditions. Then
C(x0) = Z(x0).
Proof We ﬁrst show that C(x0) ⊂Z(x0). Let y ∈C(x0); clearly, we only need to
show that, for i ∈I +(x0, u), we have ∇gi(x0)⊤y = 0. By the Karush-Kuhn-Tucker
conditions, we have that
∇f (x0)⊤y +

i∈I (x0)
ui∇gi(x0)⊤y +
p

j=1
v j∇h j(x0)⊤y = 0.
Because ∇h j(x0)⊤y = 0, j = 1, . . . , p, and ui = 0 for i ∈I (x0) \ I +(x0, u),
we have
∇f (x0)⊤y +

i∈I +(x0,u)
ui∇gi(x0)⊤y = 0.
Because ∇f (x0)⊤y = 0, and every ui > 0 for all i ∈I +(x0, u), we have
∇gi(x0)⊤y = 0, ∀i ∈I +(x0, u).
Now we prove that Z(x0) ⊂C(x0). Let y be any point in Z(x0). It sufﬁces to
show that ∇f (x0)⊤y = 0. As before, we have
∇f (x0)⊤y +

i∈I (x0)
ui∇gi(x0)⊤y +
p

j=1
v j∇h j(x0)⊤y = 0.
Clearly, ∇f (x0)⊤y = 0, because all other terms are zero.
□
Another critical cone is introduced in the analysis of second-order optimality
conditions and usually when second-order necessary conditions of the Fritz John-
type are considered. It is the cone deﬁned as follows (x0 ∈K5):

6.3 Second-Order Conditions
203
C1(x0) =
	 y ∈Rn : ∇f (x0)⊤y ≦0; ∇gi(x0)⊤y ≦0, i ∈I (x0);
∇h j(x0)⊤y = 0, j = 1, . . . , p.

.
(6.11)
Obviously, C(x0) ⊂C1(x0). We may call C1(x0) the extended critical cone at
x0 ∈K5. We point out the following result.
Theorem 6.33 Let x0 ∈K5 be a local minimum point for (P5). Then the Fritz John
conditions are satisﬁed at x0 with u0 > 0 if and only if C(x0) = C1(x0).
Proof If C(x0) ̸= C1(x0), there will exist y ∈Rn such that
⎧
⎨
⎩
∇f (x0)⊤y < 0,
∇gi(x0)⊤y ≦0, i ∈I (x0),
∇h j(x0)⊤y = 0, j = 1, . . . , p.
(6.12)
We write the ﬁrst basic Fritz John relation:
u0∇f (x0) +

i∈I (x0)
ui∇gi(x0) +
p

j=1
v j∇h j(x0) = 0.
Multiplying this relation by y, we have that u0 = 0. On the other hand, if C(x0) =
C1(x0) we conclude that system (6.12) has no solution y ∈Rn. From Farkas’ theorem
(Theorem 2.28), we deduce the existence of multipliers ui ≧0, i ∈I (x0), v j ∈R,
j = 1, . . . , p, such that
∇f (x0) +

i∈I (x0)
ui∇gi(x0) +
p

j=1
v j∇h j(x0) = 0.
□
We recall that if x0 ∈K5 is a local solution of (P5) and a constraint qualiﬁ-
cation is satisﬁed, then there exist multipliers ui ≧0, i = 1, . . . , m, and v j ∈R,
j = 1, . . . , p, with uigi(x0) = 0, i = 1, . . . , m, such that
∇f (x0) +
m

i=1
ui∇gi(x0) +
p

j=1
v j∇h j(x0) = 0.
We recall again the deﬁnition of the index set I +(x0, u) ⊂I (x0):
I +(x0, u) =

i : i ∈I (x0), ui > 0 in the KKT conditions

.
Let us introduce the set
Q =

x ∈K5 : gi(x) = 0, ∀i ∈I +(x0, u)

.

204
6
Constrained Optimization Problems with Mixed Constraints
If we consider the usual Lagrangian function for (P5)
L (x, u, v) = f (x) + u⊤g(x) + v⊤h(x),
we have, due to the complementary slackness conditions,
L (x, u, v) = f (x), ∀x ∈Q.
As x0 ∈K5 is a local solution of (P5), this point is also a local solution of the
problem
min L (x, u, v) = f (x), x ∈Q.
But, thanks to the Karush-Kuhn-Tucker conditions, we have ∇xL (x0, u, v) = 0
and therefore Theorem 4.26 applies. We obtain the following second-order necessary
optimality conditions for (P5).
Theorem 6.34 Let x0 ∈K5 be a local minimum point of (P5) and let some con-
straint qualiﬁcation be veriﬁed; then there exists a triplet (x0, u, v) which satisﬁes
the Karush-Kuhn-Tucker conditions and moreover we have
y⊤∇2
xL (x0, u, v)y ≧0, ∀y ∈T (Q, x0).
(6.13)
Now, if the Abadie constraint qualiﬁcation, referred to the set Q, holds, i.e. if
T (Q, x0) = Z(x0)
(6.14)
(note that Z(x0) is the linearizing cone of Q at x0), then obviously (6.13) can be
written as
y⊤∇2
xL (x0, u, v)y ≧0, ∀y ∈Z(x0),
(6.15)
which is one of the classical second-order necessary optimality conditions for (P5).
When is equality (6.14) satisﬁed? The following result gives sufﬁcient conditions
for the validity of (6.14).
Theorem 6.35 If at x0 ∈K5 the Linear Independence constraint qualiﬁcation is
satisﬁed or even the more general Strict Mangasarian-Fromovitz constraint qualiﬁ-
cation is satisﬁed (and hence M(x0) is a singleton), then (6.14) holds and therefore
(6.13) can be substituted by (6.15).
The proof follows, mutatis mutandis, from the proof of Theorem 5.19 and will
not be repeated here.
Note that the Linear Independence c. q. and the Strict Mangasarian-Fromovitz c.
q. are not only ﬁrst-order constraint qualiﬁcations, but also second-order constraint
qualiﬁcations which permit to obtain relation (6.15). This is not the case, as we shall
see next, for the Mangasarian-Fromovitz constraint qualiﬁcation.
Being Z1(x0) ⊂Z(x0), obviously a second-order necessary optimality condition
weaker than (6.15) is

6.3 Second-Order Conditions
205
y⊤∇2
xL (x0, u, v)y ≧0, ∀y ∈Z1(x0).
This condition appears in the paper of McCormick [21] and in Fiacco and
McCormick [22]. It has the advantage to be tested by means of the results on the
sign of a quadratic form constrained by a linear homogeneous equations system (see
Chap. 1, Chabrillac and Crouzeix [23], Debreu [24]).
A second-order constraint qualiﬁcation for (P5) is considered in the pioneering
paper of McCormick [21] and also in McCormick [25, 26].
• McCormick Second-Order Constraint Qualiﬁcation.
This constraint qualiﬁcation holds at x0 ∈K5 if for all y ∈Z(x0), y is the tangent
of a twice differentiable arc α(θ), where for some θ1 > 0:
gi [α(θ)] = 0, for θ ∈[0, θ1] , ∀i ∈I +(x0, u);
gi [α(θ)] ≦0, for θ ∈[0, θ1] , ∀i ∈I (x0) \ I +(x0, u);
h j [α(θ)] = 0, for θ ∈[0, θ1] , ∀j = 1, . . . , p
and α(0) = x0, α′(0) = y.
McCormick proves that if a ﬁrst-order constraint qualiﬁcation and the above
second-order constraint qualiﬁcation hold at the local optimal point x0 ∈K5, then,
besides the Karush-Kuhn-Tucker conditions, also condition (6.15) holds.
McCormick shows, by numerical examples, that his second-order c. q. does
not assure the validity of the Karush-Kuhn-Tucker conditions, i.e. the McCormick
second-order c. q. is not a ﬁrst-order c. q. On the other hand, the Linear Independence
c. q. and the Strict Mangasarian-Fromovitz c. q. assure the validity of the McCormick
second-order c. q., but this is not the case, for example, of the Mangasarian-Fromovitz
c. q. or of the Kuhn-Tucker c. q. (for this last case McCormick [21] gives a numerical
example).
Fiacco and McCormick in an unpublished paper of 1968 (A. V. Fiacco and
G. P. McCormick, Asymptotic conditions for constrained minimization, RAC-TP-
340, 1968, Research Analysis Corporation, McLean, Virginia) and subsequently
McCormick [26] give for (P5) also a second-order necessary optimality conditions
of the Fritz John-type.
Theorem 6.36 Let x0 ∈K5 be a local minimum point of (P5). Then, at x0, besides
the (ﬁrst-order) Fritz John conditions with multipliers u0, u, v, it will hold the fol-
lowing second-order necessary conditions:
y⊤∇2
xL1(x0, u0, u, v)y ≧0, ∀y ∈T (Q, x0),
(6.16)
where L1(x, u0, u, v) = u0 f (x) + u⊤g(x) + v⊤h(x).
Proof Itisenoughtoprove (6.16)for y ∈T (Q, x0)with∥y∥= 1.Thenthereexistsa
sequence {zk} ⊂Q such that zk
y→x0 (see Deﬁnition 2.34), i.e. lim
k→+∞
zk−x0
∥zk−x0∥= y.

206
6
Constrained Optimization Problems with Mixed Constraints
Observe that gi(x0) < 0 for all i /∈I (x0). Then, for k sufﬁciently large we have
g(zk) < 0. Hence, for k sufﬁciently large zk is feasible for (P5). For k sufﬁciently
large
f (zk) −f (x0) ≧0.
Therefore,
(zk −x0)⊤∇f (x0) + 1
2(zk −x0)⊤∇2 f (x0)(zk −x0) + o(
zk −x02) ≧0.
(6.17)
Note that, for every i ∈I +(x0, u), we have gi(zk) = 0. Therefore, for each i ∈
I +(x0, u), we have
(zk −x0)⊤∇gi(x0) + 1
2(zk −x0)⊤∇2gi(x0)(zk −x0) + o(
zk −x02) = 0.
(6.18)
Again we have h j(zk) −h j(x0) = 0 for all j = 1, . . . , p. Therefore, for all j,
one has
(zk −x0)⊤∇h j(x0) + 1
2(zk −x0)⊤∇2h j(x0)(zk −x0) + o(
zk −x02) = 0.
(6.19)
Using (6.17), (6.18), (6.19) and the Fritz John conditions, one can easily establish
that
1
2(zk −x0)∇2
xL1(x0, u0, u, v)(zk −x0) + o(
zk −x02) ≧0.
(6.20)
Dividing the expression (6.20) throughout by
zk −x02 and proceeding to the
limit as k →∞, we have, since ui = 0 for all i ∈I (x0) \ I +(x0, u),
y⊤∇2
xL1(x0, u0, u, v)y ≧0, ∀y ∈T (Q, x0),
i.e. the thesis of the theorem.
□
Obviously, if T (Q, x0) = Z(x0), we can express (6.16) with reference to the
critical cone Z(x0). It is not difﬁcult to prove that if the Second-Order McCormick
c. q. holds at x0, then T (Q, x0) = Z(x0) in relation (6.16). See McCormick [26].
It is also possible to obtain second-order necessary optimality conditions of the
Fritz John-type which make reference to the extended critical cone C1(x0). How-
ever, in this case, the Fritz John multipliers which appear in L1(x0, u0, u, v) are
not necessarily ﬁxed. The following result (Theorem 6.39) is due to Ben-Tal [27],
previously we need a lemma and we do a comment.
Lemma 6.37 Let x0 ∈S2 and y ∈L(x0). Suppose that the gradients ∇h j(x0), j =
1, . . . , p, are linearly independent. Then if z ∈Rn satisﬁes

6.3 Second-Order Conditions
207
	∇gi(x0)⊤z + y⊤∇2gi(x0)y < 0,
∀i ∈I (x0, y),
∇h j(x0)⊤z + y⊤∇2h j(x0)y = 0,
∀j = 1, . . . , p,
(6.21)
where I (x0, y) = {i ∈I (x0) : ∇gi(x0)⊤y = 0}, then there exist a positive number
δ and a curve γ ∈C1[0, δ] such that
γ (t) ∈K5 for all t ∈[0, δ], γ (0) = x0, γ ′(0) = y, γ ′′(0) = z.
(6.22)
Its proof, which is based on the inverse function theorem, can be seen in Still and
Streng [11], Lemma 2.1.
Remark 6.38 If the gradients ∇h j(x0), j = 1, . . . , p, are linearly independent and
condition (6.21) holds for some z ∈Rn, it is said that the second-order Mangasarian-
Fromovitz c. q. is satisﬁed at (x0, y). This condition is implied by the (ﬁrst-order)
Mangasarian-Fromovitz c. q. Indeed, as ∇h j(x0), j = 1, . . . , p, are linearly inde-
pendent, for a given y ∈L(x0), there exists d ∈Rn such that
∇h j(x0)⊤d + y⊤∇2h j(x0)y = 0,
j = 1, . . . , p.
Then, for a vector z satisfying the ﬁrst-order Mangasarian-Fromovitz c. q., i.e.
∇gi(x0)⊤z < 0, i ∈I (x0) and ∇h j(x0)⊤z = 0, j = 1, . . . , p, putting zt = d + tz,
we ﬁnd that
	∇gi(x0)⊤zt + y⊤∇2gi(x0)y < 0,
∀i ∈I (x0, y),
∇h j(x0)⊤zt + y⊤∇2h j(x0)y = 0,
∀j = 1, . . . , p,
for t > 0 large enough, i.e. zt is a vector satisfying (6.21).
Theorem 6.39 Let x0 ∈K5 be a local minimizer for problem (P5). Then, for any
y ∈C1(x0) (see (6.11)), there are multipliers (u0, u, v) not all zero, (u0, u) ≧0, such
that the Fritz John conditions (see Theorem 6.3) are satisﬁed at x0 and, moreover,
y⊤∇2
xL1(x0, u0, u, v)y ≧0.
(6.23)
The reader is invited to remark the structure of the previous theorem and its
different form with respect to the previous ones. An example of an optimization
problem where, at a minimizer x0, different multipliers are really necessary to get
(6.23), can be found in Ben-Tal [27], Example 2.1. The proofs of Theorem 6.39 given
by Ben-Tal [27] and by Still and Streng [11] are based on several lemmas. We follow
the soundproof of Bonnans and Shapiro [28].
Proof of Theorem 6.39 (Bonnans and Shapiro) Let y ∈C1(x0). If the gradients
∇h j(x0), j = 1, . . . , p, are linearly dependent, then there exists τ ̸= 0 such that
p
j=1 τ j∇h j(x0) = 0. Hence, (u0, u, v) = (0, 0, τ) or (u0, u, v) = (0, 0, −τ) are
Fritz John multipliers which satisfy the (ﬁrst-order) Fritz John conditions. If (6.23)
is satisﬁed with (0, 0, τ), there is nothing else to prove. Otherwise, since (0, 0, −τ)
is another Fritz John multipliers vector, and

208
6
Constrained Optimization Problems with Mixed Constraints
y⊤∇2
xL1(x0, 0, 0, −τ)y = −y⊤∇2
xL1(x0, 0, 0, τ)y,
we have that (6.23) is satisﬁed by (0, 0, −τ). Therefore, for any y ∈C1(x0), we can
choose one of the two possibilities, so that (6.23) is satisﬁed.
We now assume that the gradients ∇h j(x0), j = 1, . . . , p, are linearly inde-
pendent. Consider the following linear programming problem in the variables
(α, z) ∈R × Rn:
⎧
⎪⎪⎨
⎪⎪⎩
min α
subject to: ∇f (x0)⊤z + y⊤∇2 f (x0)y ≦α,
∇gi(x0)⊤z + y⊤∇2gi(x0)y ≦α, i ∈I (x0, y),
∇h j(x0)⊤z + y⊤∇2h j(x0)y = 0, j = 1, . . . , p,
(6.24)
where I (x0, y) = {i ∈I (x0) : ∇gi(x0)⊤y = 0}. The optimal value of this problem
is nonnegative. Indeed, otherwise, there exists z which satisﬁes
⎧
⎨
⎩
∇f (x0)⊤z + y⊤∇2 f (x0)y < 0,
∇gi(x0)⊤z + y⊤∇2gi(x0)y < 0, i ∈I (x0, y),
∇h j(x0)⊤z + y⊤∇2h j(x0)y = 0, j = 1, . . . , p.
(6.25)
By Lemma 6.37, there exists a path γ : [0, δ] →Rn satisfying conditions (6.22).
Then, by a second-order Taylor expansion, we have for t > 0 small enough that
f (γ (t)) = f (x0) + t∇f (x0)⊤y + 1
2t2 
∇f (x0)⊤z + y⊤∇2 f (x0)y

+ o(t2) < f (x0)
due to the ﬁrst condition in (6.24) and the fact that y ∈D<( f, x0). Therefore, for
t > 0 small enough, γ (t) ∈K5 is feasible and f (γ (t)) < f (x0), which contradicts
the local minimality of x0. This proves that (6.24) has a nonnegative optimal value.
Since ∇h j(x0), j = 1, . . . , p, are linearly independent, the equality constraints
of (6.24) have a feasible solution because rk ∇h(x0) = p and so ∇h(x0)(Rn) =
Rp, and thus there exists z ∈Rn such that ∇h j(x0)⊤z + y⊤∇2h j(x0)y = 0 for all
j = 1, . . . , p, and hence, since α can be made arbitrarily large, problem (6.24) is
consistent. Therefore, (6.24) has a ﬁnite nonnegative optimal value. Since (6.24) is
a linear programming problem, it follows, by the Strong Duality Theorem of Linear
Programming (see Remark 9.19), that its dual, in the variables u0, u, v, with ui = 0
for i /∈I (x0, y), has the same optimal value. The dual of (6.24) is
max y⊤
⎛
⎝u0∇2 f (x0) +

i∈I (x0,y)
ui∇2gi(x0) +
p

j=1
v j∇2h j(x0)
⎞
⎠y
subject to:

6.3 Second-Order Conditions
209
u0∇f (x0) +

i∈I (x0,y)
ui∇gi(x0) +
p

j=1
v j∇h j(x0) = 0,
u0 +

i∈I (x0,y)
ui +
p

j=1
v j = 1,
u0 ≧0, ui ≧0, i ∈I (x0, y).
Since an optimal solution of this dual problem is a Fritz John multipliers vector
associated to x0, by choosing ui = 0 for i /∈I (x0, y), we get the thesis.
□
The drawback of the previous theorem is that it may be u0 = 0. The Mangasarian-
Fromovitz c. q., if veriﬁed, assures that this case cannot occur. However, even under
the validity of the Mangasarian-Fromovitz c. q., we are not able to obtain the second-
order necessary conditions with ﬁxed multipliers.
Theorem 6.40 Let x0 ∈K5 be a local optimal solution of problem (P5) and let x0
verify the Mangasarian-Fromovitz c. q.; then, for every y ∈C(x0) = Z(x0), there
exist Karush-Kuhn-Tucker multipliers vectors (u, v), u ∈Rm
+, v ∈Rp, uigi(x0) =
0, i = 1, . . . , m, such that the Karush-Kuhn-Tucker conditions are satisﬁed at x0
and, moreover,
y⊤∇2
xL (x0, u, v)y ≧0.
Proof It is sufﬁcient to take into account that C(x0) ⊂C1(x0), to apply the previous
theorem and to remark that the Mangasarian-Fromovitz c. q. assures u0 > 0, and
hence u0 = 1, in the Fritz John conditions.
□
A counterexample showing that the Mangasarian-Fromovitz c. q. is not able to
assure the usual second-order necessary optimality conditions for (P5) has been
constructed by Arutyunov [29] and subsequently another counterexample was found
by Anitescu [30]. Being M(x0) a convex and compact set (see Theorem 6.18), under
the validity of the Mangasarian-Fromovitz c. q., it is then possible to write the thesis
of Theorem 6.40 in the form
max
(u,v)∈M(x0)y⊤∇2
xL (x0, u, v)y ≧0, ∀y ∈C(x0).
We may call “usual” second-order necessary conditions the second-order con-
ditions with ﬁxed multipliers and “weak” second-order necessary conditions the
second-order conditions with non-ﬁxed multipliers. The denominations are not stan-
dard!
It must be observed that if the Strict Mangasarian-Fromovitz c. q. holds at x0,
then M(x0) is a singleton and therefore the weak second-order necessary conditions
of Theorem 6.40 become the usual second-order necessary conditions previously

210
6
Constrained Optimization Problems with Mixed Constraints
described in Theorem 6.35. This conﬁrms once more that the Strict Mangasarian-
Fromovitz c. q. is not only a ﬁrst-order constraint qualiﬁcation, but also a second-
order constraint qualiﬁcation.
Besides the Linear Independence c. q. and the Strict Mangasarian-Fromovitz c. q.,
other ﬁrst-order constraint qualiﬁcations have been recognized to assure the validity
of the “usual” second-order necessary conditions (i.e. with ﬁxed multipliers) for (P5).
Andreani, Echagüe and Schuverdt [31] have proved that under the Constant Rank
Constraint Qualiﬁcation, the following condition is valid (x0 local solution of (P5)):
∀(u, v) ∈M(x0) : y⊤∇2
xL (x0, u, v)y ≧0, ∀y ∈C(x0).
Also, the following result has been established by Andreani, Echagüe and Schu-
verdt [31]. We ﬁrst introduce the notion of Weak Constant Rank Condition:
• Let x0 ∈K5, then the weak constant rank condition holds if there is a neighborhood
U(x0) such that the set

∇gi(x), i ∈I (x0)

∪

∇h j(x), j = 1, . . . , p

has the same rank for all x ∈U(x0) ∩K5.
Theorem 6.41 If x0 ∈K5 is a local minimizer for (P5) satisfying the Karush-Kuhn-
Tucker conditions (i.e. M(x0) ̸= ∅) and the weak constant rank condition holds,
then
∀(u, v) ∈M(x0) : y⊤∇2
xL (x0, u, v)y ≧0, ∀y ∈Z1(x0).
(6.26)
Therefore, any constraint qualiﬁcation that ensures M(x0) ̸= ∅, in combination
with the weak constant rank condition, guarantees that (6.26) holds at a local mini-
mizer x0 for (P5).
Remark 6.42 It is convenient to remark that the following conjectures are false.
Conjecture 1. If x0 ∈K5 is a local minimizer of problem (P5), then the Hessian
matrix ∇2 f (x0) is positive semideﬁnite.
Example.
min −(x1 + 1)2 −(x2)2
subject to: (x1)2 + (x2)2 ≦1.
The optimal point is x0 = (1, 0)⊤, but ∇2 f (x0) is not positive semideﬁnite.
Conjecture 2. If x0 ∈K5 is a local minimizer of problem (P5), then the Hessian
matrix of the Lagrangian function ∇2
xL (x0, u, v) is positive semideﬁnite.
Example.
⎧
⎨
⎩
min −(x1)2 + (x2)2
subject to: x1 ≦1;
−x1 ≦0.

6.3 Second-Order Conditions
211
The optimal point is x0 = (1, 0)⊤, but ∇2
xL (x0, u) is not positive semideﬁ-
nite. Note that any feasible direction y satisfying y⊤∇2
xL (x0, u)y < 0 also satisﬁes
y⊤∇g1(x0) < 0.
Now we turn to second-order sufﬁcient optimality conditions for (P5). Taking into
considerationTheorem 5.22wehavethefollowingsecond-order sufﬁcient conditions
for (P5).
Theorem 6.43 Let x0 ∈K5 and let the Karush-Kuhn-Tucker conditions be satisﬁed
by the triplet (x0, u, v). If
y⊤∇2
xL (x0, u, v)y > 0, ∀y ̸= 0,
y ∈T (K5, x0) ∩

y : ∇gi(x0)⊤y = 0, ∀i ∈I +(x0, u)

,
then x0 is a strict local minimum point for (P5).
As T (K5, x0) ⊂L(x0) it is possible to rewrite the previous conclusion in the
more usual form
y⊤∇2
xL (x0, u, v)y > 0, ∀y ̸= 0, y ∈Z(x0).
For the reader’s convenience, we give a direct proof of this last result.
Theorem 6.44 Let x0 ∈K5 and let the Karush-Kuhn-Tucker conditions be satisﬁed
by the triplet (x0, u, v). If
y⊤∇2
xL (x0, u, v)y > 0, ∀y ̸= 0, y ∈Z(x0),
(6.27)
then x0 is a strict local solution of (P5).
Proof The proof is indirect; let us assume that x0 is not a strict local minimum point
for (P5). Then there will exist a tangentially convergent sequence

xk
⊂K5, xk ̸=
x0, with xk
y→x0 and f (xk) ≦f (x0) for all k ∈N. Hence, y ∈T (K5, x0) \ {0} and
the quotients
f (xk) −f (x0)
xk −x0
= ∇f (x0)⊤(xk −x0) + o(
xk −x0)
xk −x0
,
gi(xk) −gi(x0)
xk −x0
= ∇gi(x0)⊤(xk −x0) + o(
xk −x0)
xk −x0
,
h j(xk) −h j(x0)
xk −x0
= ∇h j(x0)⊤(xk −x0) + o(
xk −x0)
xk −x0
,

212
6
Constrained Optimization Problems with Mixed Constraints
where i ∈I (x0) and j = 1, . . . , p, converge to, respectively, ∇f (x0)⊤y ≦0, ∇
gi(x0)⊤y ≦0 and ∇h j(x0)⊤y = 0.
By the Karush-Kuhn-Tucker conditions (ui ≧0 for all i = 1, . . . , m), we have
∇f (x0)⊤y +
m

i=1
ui∇gi(x0)⊤y +
p

j=1
v j∇h j(x0)⊤y = 0
and each summation term is equal to zero. Then we have
∇gi(x0)⊤y = 0, ∀i ∈I +(x0, u).
Hence, y ∈Z(x0) \ {0} . By considering
L (xk, u, v) −L (x0, u, v) = f (xk) −f (x0)+
+
m

i=1
ui(gi(xk) −gi(x0)) +
p

j=1
v j(h j(xk) −h j(x0)) ≦0,
with ∇xL (x0, u, v) = 0, the quotients
L (xk, u, v) −L (x0, u, v)
xk −x02
=
1
2(xk −x0)⊤∇2x L (x0, u, v)(xk −x0) + o(
xk −x0
2
)
xk −x02
converge to 1
2 y⊤∇2
xL (x0, u, v)y ≦0, in contradiction with the hypothesis.
□
Following Hestenes [12] it is possible to reformulate the thesis of Theorem 6.44
in the following way:
• If (6.27) holds, together with the Karush-Kuhn-Tucker conditions, then the
feasible point x0 is a strict local minimizer of order two for (P5), i.e. there is a
constant m > 0 and a neighborhood U(x0) such that
f (x) ≧f (x0) + m
x −x02 , ∀x ∈K5 ∩U(x0).
We recall the deﬁnition of the linear subspace Z2(x0):
Z2(x0) =

y ∈Rn : ∇gi(x0)⊤y = 0, i ∈I +(x0, u); ∇h j(x0)⊤y = 0, j = 1, . . . , p
 
.
Being Z(x0) ⊂Z2(x0), then we can replace in Theorem 6.44 relation (6.27) with
the stronger condition
y⊤∇2
xL (x0, u, v)y > 0, ∀y ̸= 0, y ∈Z2(x0).
(6.28)

6.3 Second-Order Conditions
213
Indeed,thislastconditionisknownasthestrongsecond-ordersufﬁcientoptimality
condition for (P5). See Robinson [32]. Note that when strict complementarity holds,
the strong second-order sufﬁcient condition and the usual second-order sufﬁcient
condition of Theorem 6.44 are equivalent. The advantage of (6.28) is that it permits
the use of the results of testing the sign of a quadratic form subject to a system of
homogeneous linear equations (see Chabrillac and Crouzeix [23], Debreu [24] and
Chap. 1). McCormick [26] remarks that (6.28) can be expressed also in the following
way. Let V be the matrix whose columns are a base of the linear space Z2(x0). Then
(6.28) holds if and only if
V ⊤∇2
xL (x0, u, v)V
is a positive deﬁnite matrix. See also Kelly and Kupferschmid [33].
We have to note that, contrary to what asserted in Fiacco and McCormick [22]
and in McCormick [26], the conditions given in Theorem 6.44 do not assure that x0
is an isolated (i.e. locally unique) solution of problem (P5). Robinson [34] provides
the following counterexample in R. See also Fiacco [35].
Example 6.45 Consider the problem
min f (x) = 1
2 x2, x ∈R,
subject to: h(x) = x6 sin
 1
x

= 0, h(0) = 0.
One can easily verify that the assumptions of Theorem 6.44 are veriﬁed at x0 = 0.
However, every point in the set

(nπ)−1, n = ±1, ±2, . . .

is an isolated feasible point and therefore also a local minimum. However, x0 = 0 is
not an isolated local minimum for the problem considered.
Conditions sufﬁcient for x0 ∈K5 to be an isolated local minimum for (P5) are
obtained by Robinson [34] by strengthening the assumptions of Theorem 6.44 in two
ways.
Theorem 6.46 (Robinson) Suppose that the Karush-Kuhn-Tucker conditions hold at
x0 ∈K5 for (P5) with some multipliers u and v and that the Mangasarian-Fromovitz
constraint qualiﬁcation holds at x0. Moreover, assume that the following General
Second-Order Sufﬁcient Conditions hold at x0:
• The Second-Order Sufﬁcient Conditions of Theorem 6.44 hold at x0, with (u, v)
for every (u, v) ∈M(x0).
Then x0 is an isolated local minimum point for (P5), i.e. there exists a neighborhood
N(x0) of x0 such that x0 is the unique local minimum point for (P5) in N(x0).

214
6
Constrained Optimization Problems with Mixed Constraints
Note that if the Linear Independence c. q. or the more general Strict Mangasarian-
Fromovitz c. q. is substituted for the Mangasarian-Fromovitz c. q. in Theorem 6.46,
then the General Second-Order Sufﬁcient Conditions of Theorem 6.46 coincide with
the usual Second-Order Sufﬁcient Conditions of Theorem 6.44, since M(x0) is then
a singleton. Thus, under the Linear Independence c. q. or the Strict Mangasarian-
Fromovitz c. q., Theorem 6.44 assures that x0 is an isolated local minimum point of
(P5).
Example 6.47 Consider the problem
min f (x) = −(x1)2 −(x2)2, x ∈R2,
subject to:
⎧
⎨
⎩
−x1 ≦0,
−x2 ≦0,
x1 + x2 ≦2.
There are four Karush-Kuhn-Tucker points: x1 = [2, 0]⊤, x2 = [0, 2]⊤, x3 =
[1, 1]⊤and x4 = [0, 0]⊤. The second-order sufﬁcient conditions show that x1 and
x2 are strict local minimizers. The second-order necessary conditions show that x3
and x4 are not local minimizers.
We have also second-order sufﬁcient optimality conditions of the Fritz John-type
(and also for the case of non-ﬁxed multipliers; see Ben-Tal [27], Bonnans and Shapiro
[28], Still and Streng [11]. In this case, the extended cone of critical directions C1(x0)
is used). The following result is given in the book of McCormick [26].
Theorem 6.48 Let x0 ∈K5 and suppose that x0 satisﬁes the Fritz John conditions
for (P5), with a Lagrangian function
L1(x, u0, u, v) = u0 f (x) + u⊤g(x) + v⊤h(x).
If
y⊤∇2
xL1(x0, u0, u, v)y > 0, ∀y ̸= 0, y ∈Z(x0),
then x0 is a strict local minimizer for (P5); more precisely, x0 is a strict local
minimizer of order two.
For what concerns second-order sufﬁcient optimality conditions for (P5) with
non-ﬁxed multipliers, we have the following results.
• If x0 ∈K5 and for each y ∈C1(x0) \ {0} there exists (u0, u, v) which together
with x0, satisfy the Fritz John conditions for (P5) and moreover
y⊤∇2
xL1(x0, u0, u, v)y > 0,
then x0 is a strict local minimizer of (P5) of order two.

6.4 Problems with a Set Constraint. Asymptotic Optimality Conditions
215
• If x0 ∈K5, the set M(x0) of Karush-Kuhn-Tucker multipliers is nonempty and
for each y ∈C(x0) \ {0} there exists (u, v) ∈M(x0) such that
y⊤∇2
xL (x0, u, v)y > 0,
then x0 is a strict local minimizer of (P5) of order two. These conditions can be
also written in the equivalent form
sup
(u,v)∈M(x0)
y⊤∇2
xL (x0, u, v)y > 0, ∀y ∈C(x0) \ {0} ,
where the above supremum can be +∞. If the Mangasarian-Fromovitz c. q. holds
at x0 (and hence M(x0) is compact), “sup” can be substituted by “max”.
Finally, we report an interesting result of Ward [36], in which it is shown that the
StrictMangasarian-Fromovitzc.q.“closesthegap”betweenthe(usual)second-order
necessary optimality conditions and the (usual) second-order sufﬁcient optimality
conditions.
Theorem 6.49 Let x0 ∈K5 and suppose that the Strict Mangasarian-Fromovitz
c. q. is satisﬁed at x0 with multipliers (u, v) such that ∇xL (x0, u, v) = 0, with
uigi(x0) = 0, ui ≧0, i = 1, . . . , m. Then x0 is a strict local minimizer of order two
for (P5) if and only if
y⊤∇2
xL (x0, u, v)y > 0, ∀y ̸= 0, y ∈Z(x0) = C(x0).
6.4
Problems with a Set Constraint. Asymptotic Optimality
Conditions
When in problem (P5) besides the functional constraints it appears also a set con-
straint or abstract constraint, represented by a closed set C ⊂X ⊂Rn, the usual
necessary Fritz John conditions, described in Theorem 6.3, and several constraint
qualiﬁcations seen for (P5) are no longer valid. Consider the following example.
Example 6.50
min {−(x + y)} , (x, y) ∈R2,
subject to:
	
h(x, y) = (x −1)2 + y2 −1 = 0,
(x, y) ∈C =

(x, y) : |x| + |y| ≦1

.
The point (x0, y0) = (1 −
√
2/2;
√
2/2) is a solution of the problem, but there is
no vector (u0, v1)⊤̸= (0, 0)⊤such that
u0∇f (x0, y0) + v1∇h(x0, y0) = (0, 0)⊤.

216
6
Constrained Optimization Problems with Mixed Constraints
We deﬁne a new problem, (P6), which contains also a set constraint C ⊂X ⊂Rn:
(P6) :
⎧
⎪⎪⎨
⎪⎪⎩
min f (x)
subject to: gi(x) ≦0, i = 1, . . . , m;
h j(x) = 0, j = 1, . . . , p < n;
x ∈C ⊂X ⊂Rn,
where C is a closed set and the functions involved in (P6) satisfy the same assump-
tions made for (P5). The feasible set of (P6) is denoted by K6.
One of the ﬁrst papers which provides a general analysis of problem (P6) is the
one of Bazaraa and Goode [37]. These authors use the cone of interior directions to
a set S ⊂Rn at x0 ∈S:
I (S, x0) =
	 y ∈Rn : ∃U(y), ∃δ0 > 0 such that v ∈U(y), δ ∈(0, δ0)
imply x0 + δv ∈S

.
It appears that I (S, x0) is an open cone and that I (S, x0) ⊂A(S, x0) ⊂T (S, x0).
Moreover, if x0 ∈int(S), then I (S, x0) = Rn and if S ⊂Rn is a convex set, with
int(S) ̸= ∅, then
cl(I (S, x0)) = cl(cone(S −x0)) = A(S, x0) = T (S, x0).
The main result of Bazaraa and Goode [37] is the following one.
Theorem 6.51 Suppose that x0 ∈K6 is a local solution of (P6) and suppose that
I (C, x0) is a convex cone. Then, there exist multipliers (u0, u, v), not all zero, such
that
(i) −

u0∇f (x0) + m
i=1 ui∇gi(x0) + p
j=1 v j∇h j(x0)

∈(I (C, x0))∗;
(ii) uigi(x0) = 0, i = 1, . . . , m;
(iii) u0 ≧0, ui ≧0, i = 1, . . . , m, v j ∈R, j = 1, . . . , p.
Bazaraa and Shetty [14] give an example where it is shown that it is not possible
to replace in (i) of Theorem 6.51 the cone I (C, x0) with the larger cone T (C, x0),
in order to obtain a sharper necessary optimality condition.
The above result has been slightly improved by Giorgi and Guerraggio [38] who
use an open cone larger than I (C, x0), i.e. the cone of quasi-interior directions to C
at x0:
Q(C, x0) =
	 y ∈Rn : ∃U(y), such that ∀δ0 > 0 ∃δ ∈(0, δ0), ∀v ∈U(y)
we have x0 + δv ∈S

.
We note that when C is convex, with int(C) ̸= ∅, relation (i) of Theorem 6.51
can be reformulated as

6.4 Problems with a Set Constraint. Asymptotic Optimality Conditions
217
−
⎡
⎣u0∇f (x0) +
m

i=1
ui∇gi(x0) +
p

j=1
v j∇h j(x0)
⎤
⎦∈N(C, x0),
(6.29)
where N(C, x0) is the normal cone to C at x0.
Giorgi, Jiménez and Novo [39] have observed that (6.29) is valid even if no
assumption on the convex set C is made (besides convexity). Also the approach of
Gould and Tolle [40], previously reported for (P4) in Chap. 5, Theorem 6.29, can be
immediately ﬁtted to (P6). We continue to denote by L(x0) the linearizing cone for
(P6) at x0 ∈K6. We have the following result.
Theorem 6.52 Let x0 ∈K6 be a local solution of (P6). Then there exist multipliers
(u, v), u ≧0, such that
−
⎡
⎣∇f (x0) +
m

i=1
ui∇gi(x0) +
p

j=1
v j∇h j(x0)
⎤
⎦∈(T (K6, x0)∗\ (L(x0))∗∪{0} .
More recently, a fruitful approach to get necessary optimality conditions for (P6)
has been presented by Bertsekas [2] and Bertsekas and Ozdaglar [3]. These two last
authors consider, for a closed set C ⊂Rn and a point x0 ∈C, the Mordukhovich
normal cone (see. e.g. Aubin and Frankowska [41], Rockafellar and Wets [42],
Borwein and Lewis [43]; for the case of C ⊂Rn closed, the deﬁnitions of these
authors coincide with the following deﬁnition):
NM(C, x0) =
	 y ∈Rn : ∃

xk
⊂C, ∃

yk
, xk →x0,
yk →y : yk ∈(T (C, xk))∗, ∀k ∈N

.
Equivalently, the graph of NM(C, ·), viewed as a point-to-set mapping, {(x, y) :
y ∈NM(C, x)} is the closure of the graph of (T (C, ·))∗. In general we have
(T (C, x0))∗⊂NM(C, x0) for every x0 ∈C.
The Mordukhovich normal cone is closed, however it may not be equal to
(T (C, x0))∗, and in fact it may not even be a convex set. In the case where
(T (C, x0))∗= NM(C, x0)
we say that C is regular at x0. Two important properties of the regularity are:
(i) If C is convex, then it is regular at each x ∈C.
(ii) If C is regular at some x ∈C, then T (C, x) is convex.
The Mordukhovich normal cone is also called the limiting or basic normal cone (to
C at x0). In this context the polar of the Bouligand tangent cone is called the Fréchet

218
6
Constrained Optimization Problems with Mixed Constraints
normal cone or also the regular normal cone (to C at x0) and denoted by NF(C, x0).
It can be shown that
NF(C, x0) ≡(T (C, x0))∗=
%
v ∈Rn : lim sup
x→x0,x∈C
v⊤(x −x0)
x −x0 ≦0
&
.
We have seen that, in general, it is not possible to obtain necessary Fritz John-type
necessary conditions for (P6) by using the polar of the Bouligand tangent cone (i.e.
the Fréchet normal cone). It is however possible to use the Mordukhovich normal
cone.
We now assume that all functions involved in (P6) are continuously differentiable
on the open set X ⊂Rn. One of the basic results of Bertsekas and Ozdaglar [3] is
the following one. For further considerations, see also Ozdaglar and Bertsekas [44].
Theorem 6.53 Let x0 ∈K6 be a local solution of (P6). Then, there exist scalars u0,
u1, . . . , um and v1, . . . , vp, satisfying the following conditions:
(i) −

u0∇f (x0) + m
i=1 ui∇gi(x0) + p
j=1 v j∇h j(x0)

∈NM(C, x0);
(ii) ui ≧0, for alli = 0, 1, . . . , m;
(iii) u0, u1, . . . , um, v1, . . . , vp, are not all equal to zero;
(iv) If the index set I ∪J, where I = {i ̸= 0 : ui > 0} and J =

j : v j ̸= 0

, is
nonempty, there exists a sequence

xk
⊂C that converges to x0 and is such
that, for all k,
f (xk) < f (x0), v jh j(xk) > 0, ∀j ∈J, uigi(xk) > 0, ∀i ∈I,
''h j(xk)
'' = o(w(xk)), ∀j /∈J,
g+
i (xk) = o(w(xk)), ∀i /∈I,
where
w(x) = min
	
min
j∈J
''h j(x)
'' , min
i∈I gi(x)

,
g+
i (x) = max {0, gi(x)} .
Note that if C is regular at x0, i.e. NM(C, x0) = (T (C, x0))∗, condition (i) of
Theorem 6.53 becomes
−
⎡
⎣u0∇f (x0) +
m

i=1
ui∇gi(x0) +
p

j=1
v j∇h j(x0)
⎤
⎦∈(T (C, x0))∗
or, equivalently,

6.4 Problems with a Set Constraint. Asymptotic Optimality Conditions
219
⎡
⎣u0∇f (x0) +
m

i=1
ui∇gi(x0) +
p

j=1
v j∇h j(x0)
⎤
⎦
⊤
y ≧0, ∀y ∈T (C, x0)
and if C is convex (and hence regular at each its point), the previous relation becomes
⎡
⎣u0∇f (x0) +
m

i=1
ui∇gi(x0) +
p

j=1
v j∇h j(x0)
⎤
⎦
⊤
(x −x0) ≧0, ∀x ∈C.
It must be noted that conditions (iv) are stronger than the usual complementary
slackness conditions, i.e. they imply these last ones. If ui > 0, then according to con-
dition (iv), the corresponding i-th inequality constraint must be violated arbitrarily
close to x0, implying that gi(x0) = 0. Bertsekas and Ozdaglar [3] call conditions
(iv) complementary violation conditions, as these further conditions state that the
constraints for which the multipliers are zero are also violated but their “degree of
violation” is arbitrarily small. Moreover, the value of the objective function at such
nearby points is also strictly less than f (x0). This fact has important consequences
for the use of numerical methods, such as “penalty techniques”. See also Bector et
al. [45] who reformulate Theorem 6.53 in a nonsmooth setting.
For what concerns conditions which assure that in Theorem 6.53 it holds u0 > 0,
i.e. u0 = 1, one of them is the following one (see, e.g. Ruszczynsky [46]:
• C is a closed convex set and there exists a point ˆx ∈int(C) such that, with x0 ∈K6,
∇gi(x0)⊤(ˆx −x0) < 0, ∀i ∈I (x0),
∇h j(x0)⊤(ˆx −x0) = 0, ∀j = 1, . . . , p,
and the gradients ∇h j(x0), j = 1, . . . , p, are linearly independent.
Another one is a generalization of the Slater constraint qualiﬁcation:
• C is a closed convex set, the functions gi, i = 1, . . . , m, are convex on C, the
functions h j, j = 1, . . . , p, are linear afﬁne, and there exists a feasible point ˆx
such that ˆx ∈int(C) and gi(ˆx) < 0, i = 1, . . . , m.
We conclude the present section with some considerations on asymptotic optimality
conditionsfor(P5). The characterization of a local solution of a constrained opti-
mization problem has traditionally be given, as in the present section and in the
previous sections, in terms of the functions involved in the problem, put together to
form an associated Lagrangian function, whose gradient is evaluated at the solution
point for a corresponding set of ﬁnite multipliers (Lagrange multipliers, Fritz John
multipliers, Karush-Kuhn-Tucker multipliers). Besides this classical approach, other
treatments of constrained optimality conditions give a characterization of optimality
in terms of appropriate sequences of points and multipliers. In this case, we can
speak of “asymptotic optimality conditions” or “approximate optimality conditions”
or also “sequential optimality conditions”. There are some quite recent papers on

220
6
Constrained Optimization Problems with Mixed Constraints
this second approach in studying optimality conditions for a problem of the type of
(P5). We quote only Andreani, Martínez and Svaiter [47] and Haeser and Schuverdt
[48]. We have to say that, prior to these contributions, the question was considered
in an unpublished paper of Fiacco and McCormick, already quoted in the previous
section (A. V. Fiacco and G. P. McCormick, Asymptotic conditions for constrained
Minimization, RAC-PTP-340, Research Analysis Corporation, McLean, Virginia).
We give a short account of the asymptotic optimality conditions for (P5) given by
Haeser and Schuverdt [48]. Following these authors, we assume that all functions
involved in (P5) are continuously differentiable on the open set X ⊂Rn.
Deﬁnition 6.54 We say that the Asymptotic or Approximate Karush-Kuhn-Tucker
Condition (AKKT) is satisﬁed at x0 ∈K5 if, and only if, there exist sequences

xk
⊂
Rn,

uk
⊂Rm
+ and

vk
⊂Rp, such that xk →x0,
∇f (xk) +
m

i=1
uk
i ∇gi(xk) +
p

j=1
vk
j∇h j(xk) →0
(6.30)
and
for i = 1, . . . , m :

gi(x0) < 0 ⇒uk
i = 0 for sufﬁciently large k

.
(6.31)
It must be noted that (AKKT) implies the usual Karush-Kuhn-Tucker conditions
for (P5) under the Constant Positive Linear Dependence c. q. (CPLD) (see Sect. 6.2,
p. 189):
• (CPLD) holds at x0 ∈K5 if there exists a neighborhood N(x0) of x0 such that for
I ⊂I (x0) and J ⊂{1, . . . , p} , whenever the gradients

∇gi(x0), i ∈I; ∇h j(x0), j ∈J

are positive-linearly dependent, then

∇gi(x), i ∈I; ∇h j(x), j ∈J

are linearly
dependent for every x ∈N(x0).
(CPLD) is a constraint qualiﬁcation weaker than the Mangasarian-Fromovitz c. q.;
moreover, (CPLD) is also implied by the Constant Rank Constraint Qualiﬁcation
at x0 ∈K5.
Note, moreover, that if x0 ∈K5 is a local minimum point for (P5) and any con-
straint qualiﬁcation holds at x0, then (AKKT) holds at x0 for constant sequences
xk = x0, uk = u, vk = v, being u ∈Rm
+ and v ∈Rp.
Haeser and Schuverdt [48] prove the following basic result, which is a special
case of a more general result of Andreani et al. [49].
Theorem 6.55 If x0 ∈K5 is a local minimum point for (P5), then x0 satisﬁes the
(AKKT) conditions (6.30)–(6.31).
The same authors prove that a stronger version of the (AKKT) conditions is
sufﬁcient for optimality in the case (P5) is a convex problem.

6.4 Problems with a Set Constraint. Asymptotic Optimality Conditions
221
Deﬁnition 6.56 A point x0 ∈K5 satisﬁes the strong (AKKT) condition (SAKKT) if
there exist sequences

xk
⊂Rn,

uk
⊂Rm
+ and

vk
⊂Rp such that (6.30) holds
and
gi(xk) < 0 ⇒uk
i = 0.
We note that every local minimizer of (P5) satisﬁes also (SAKKT).
Theorem 6.57 Let in (P5) f and every gi, i = 1, . . . , m, be convex functions on the
open convex set X ⊂Rn and let every h j, j = 1, . . . , p, be linear afﬁne. If x0 ∈K5
satisﬁes (SAKKT) and if the sequences

xk
,

vk
are such that vk
jh j(xk) ≧0 for
every j = 1, . . . , p, and every k ∈N, then x0 is a solution of (P5).
Remark
In this chapter and in the previous ones, we have used local “ﬁrst-order” cone approx-
imations in obtaining ﬁrst-order and second-order optimality conditions. However,
it is possible to use (local) second-order tangent sets and (local) second-order tan-
gent cones in order to obtain more accurate second-order optimality conditions. The
literature on these questions is by now rather abundant; we quote only the works
of Bonnans, Cominetti, and Shapiro [50], Bonnans and Shapiro [28], Cambini et
al. [51], Cominetti [52], Giorgi et al. [53], Hachimi and Aghezzaf [54], Jiménez
and Novo [55, 56], Haeser and Ramos [57], Penot [58], Ruszczynski [46]. In the
said works, there are obviously many bibliographical references useful to deepen the
questions. Here, we give only few hints.
• The set
T 2(S, x0, v) =
	 z ∈Rn : ∃zk →z, ∃tk →0+, with
x0 + tkv + 1
2t2
k zk ∈S, ∀k ∈N

is called second-order tangent set to S ⊂Rn at x0 ∈cl(S) and v ∈Rn.
• The cone
T ′′(S, x0, v) =
	 z ∈Rn : ∃(tk,rk) →(0+, 0+), ∃zk →z, such that
(tk/rk) →0 and x0 + tkv + 1
2tkrkzk ∈S, ∀k ∈N

is called asymptotic second-order tangent cone to S ⊂Rn at x0 ∈cl(S) and
v ∈Rn.
It must be observed that T 2(S, x0, v) and T ′′(S, x0, v) are closed sets and that
T ′′(S, x0, v) is indeed a cone. Furthermore, if v /∈T (S, x0), then T 2(S, x0, v) =
T ′′(S, x0, v) = ∅; we have also T 2(S, x0, 0) = T ′′(S, x0, 0) = T (S, x0). In gen-
eral, the second-order tangent set T 2(S, x0, v) is not a cone and it may not be con-
vex even for a convex set S ⊂Rn. However, if S ⊂Rn is convex and v ∈T (S, x0),
then
T ′′(S, x0, v) = cl

cone

cone(S −x0) −v


222
6
Constrained Optimization Problems with Mixed Constraints
and
T 2(S, x0, v) ⊂T ′′(S, x0, v).
See Jiménez and Novo [56].
By means of T 2(S, x0, v) and T ′′(S, x0, v) it is possible to obtain second-order
optimality conditions for scalar and for vector optimization problems. For exam-
ple, we have the following results (see, e.g. Jiménez and Novo [56], Penot [58],
Ruszczynski [46]).
• Consider problem (P2), i.e.
min f (x), x ∈S ⊂Rn,
with f : Rn →R twice-continuously differentiable. Assume that x0 ∈S is a local
optimal solution of (P2). Then, for every v ∈T (S, x0) such that ∇f (x0)⊤v = 0,
we have the following optimality conditions:
(a) ∇f (x0)⊤z + v⊤∇2 f (x0)v ≧0, ∀z ∈T 2(S, x0, v).
(b) ∇f (x0)⊤z ≧0, ∀z ∈T ′′(S, x0, v).
• Let f : Rn →R be twice-continuously differentiable, let x0 ∈S. If for every v ∈
T (S, x0) \ {0} such that ∇f (x0)⊤v = 0, one of the following conditions holds:
(a) ∇f (x0)⊤z + v⊤∇2 f (x0)v > 0, ∀z ∈T 2(S, x0, v) ∩v⊥.
(b) ∇f (x0)⊤z > 0, ∀z ∈T ′′(S, x0, v) ∩v⊥,
where v⊥denotes the orthogonal subspace to v, then x0 is a strict local minimum
point for (P2); more precisely, it is a strict local minimum point of order 2 (see
Jiménez and Novo [56]).
References
1. E.J. McShane, The Lagrange multiplier rule. Am. Math. Mon. 80, 922–925 (1973)
2. D.P. Bertsekas, Nonlinear Programming, 2nd edn. (Athena Scientiﬁc, Belmont, Mass, 1999)
3. D.P. Bertsekas, A.E. Ozdaglar, Pseudonormality and Lagrange multiplier theory for constrained
optimization. J. Optim. Theory Appl. 114, 287–343 (2002)
4. M. Guignard, Generalized Kuhn-Tucker conditions for mathematical programming problems
in a Banach space. SIAM J. Control 7, 232–241 (1969)
5. F.J. Gould, J.W. Tolle, A necessary and sufﬁcient qualiﬁcation for constrained optimization.
SIAM J. Appl. Math. 20, 164–172 (1971)
6. K.J. Arrow, L. Hurwicz, H. Uzawa, Constraint qualiﬁcations in maximization problems. Naval
Res. Logist. 8, 175–191 (1961). Reprinted in Giorgi and Kjeldsen (2014)
7. M. Avriel, Nonlinear Programming. Analysis and Methods (Prentice-Hall, Englewood Cliffs,
N.J., 1976)
8. W. Forst, D. Hoffmann, Optimization. Theory and Practice (Springer, New York, 2010)
9. O.L. Mangasarian, Nonlinear Programming (McGraw-Hill Book Company, New York, 1969)
10. B. Martos, Nonlinear Programming. Theory and Methods (North Holland, Amsterdam, 1975)

References
223
11. G. Still, M. Streng, Optimality conditions in smooth nonlinear programming. J. Optim. Theory
Appl. 90, 483–515 (1996)
12. M.R. Hestenes, Optimization Theory. The Finite Dimensional Case (Wiley, New York, 1975)
13. G. Giorgi, B. Jiménez, V. Novo, A note on ﬁrst-order conditions for Pareto problems. Numer.
Funct. Anal. Optim. 29, 1108–1113 (2008)
14. M.S. Bazaraa, C.M. Shetty, Foundations of Optimization, Lecture Notes in Economic and
Mathematics Systems, vol. 122 (Springer, Berlin, 1976)
15. R. Janin, Directional derivative of the marginal function in nonlinear programming. Sensitivity,
stability and parametric analysis. Math. Program. Study 21, 110–126 (A.V. Fiacco Ed.) (1984)
16. L. Qi, Z. Wei, On the constant positive linear dependence condition and its application to SQP
methods. SIAM J. Optim. 10, 963–981 (2000)
17. R. Andreani, J.M. Martinez, M.L. Schuverdt, On the relation between constant positive linear
dependence condition and quasinormality constraint qualiﬁcations. J. Optim. Theory Appl.
125, 473–483 (2005)
18. J. Gauvin, A necessary and sufﬁcient regularity condition to have bounded multipliers in
nonconvex programming. Math. Program. 12, 136–138 (1977)
19. J. Kyparisis, On uniqueness of Kuhn-Tucker multipliers in nonlinear programming. Math.
Program. 32, 242–246 (1985)
20. G. Haeser, A. Ramos, Condições de Otimalidade e Algoritmos em Optimização não Linear
(Sociedade Brasileira de Matematica Aplicada e Computational, São Carlos, Brasil (available
on the web, 2016)
21. G.P. Mccormick, Second order conditions for constrained minima. SIAM J. Appl. Math. 15,
641–652 (1967). Reprinted in Giorgi and Kjeldsen (2014)
22. A.V. Fiacco, G.P. Mccormick, Nonlinear Programming: Sequential Unconstrained Minimiza-
tion Techniques (Wiley, New York, 1968)
23. Y. Chabrillac, J.-P. Crouzeix, Deﬁniteness and semi-deﬁniteness of quadratic forms revisited.
Linear Algebra Appl. 63, 283–292 (1984)
24. G. Debreu, Deﬁnite and semideﬁnite quadratic forms. Econometrica 20, 285–300 (1952)
25. G.P. McCormick, Optimality criteria in nonlinear programming, in Nonlinear Programming,
eds. by R.W. Cottle, C.E. Lemke. SIAM-AMS Proceedings, vol. IX (American Mathematical
Society, Providence, RI, 1976), pp. 27–38
26. G.P. McCormick, Nonlinear Programming. Theory, Algoritms and Applications (Wiley, New
York, 1983)
27. A. Ben-Tal, Second-order and related extremality conditions in nonlinear programming. J.
Optim. Theory Appl. 31, 143–165 (1980)
28. J.F. Bonnans, A. Shapiro, Perturbation Analysis of Optimization Problems (Springer, New
York, 2000)
29. A.V. Arutyunov, Perturbations of extremum problems with constraints and necessary optimality
conditions. J. Sov. Math. 54, 1342–1400 (1991)
30. M. Anitescu, Degenerate nonlinear programming with a quadratic growth condition. SIAM J.
Optim. 10, 1116–1135 (2000)
31. R. Andreani, L.E. Echagüe, ML. Schuverdt, Constant-rank condition and second-order con-
straint qualiﬁcation. J. Optim. Theory Appl. 146, 255–266 (2010)
32. S.M. Robinson, Strongly regular generalized equations. Math. Oper. Res. 5, 43–62 (1980)
33. T.K. Kelly, M. Kupferschmid, Numerical veriﬁcation of second-order sufﬁciency conditions
for nonlinear programming, SIAM Rev. 40, 310–314 (1998)
34. S.M. Robinson, Generalized equations and their solutions, Part II: Applications to nonlinear
programming. Math. Program. Study 19, 200–221 (1982)
35. A.V. Fiacco, Introduction to Sensitivity and Stability Analysis in Nonlinear Programming (Aca-
demic, New York, 1983)
36. D.E. Ward, Characterizations of strict local minima and necessary conditions for weak sharp
minima. J. Optim. Theory Appl. 80, 551–571 (1994)
37. M.S. Bazaraa, J.J. Goode, Necessary optimality criteria in mathematical programming in the
presence of differentiability. J. Math. Anal. Appl. 40, 609–621 (1972)

224
6
Constrained Optimization Problems with Mixed Constraints
38. G. Giorgi, A. Guerraggio, First order generalized optimality conditions for programming prob-
lems with a set constraint, in Generalized Convexity. Proceedings of the IV International Work-
shop on Generalized Convexity, eds. by S. Komlosi, T. Rapcsak, S. Schaible (P écs, Hungary,
Springer, Berlin, 1994), pp. 171–185
39. G. Giorgi, B. Jiménez, V. Novo, Minimum principle-type optimality conditions for Pareto
problems. Int. J. Pure Appl. Math. 10, 51–68 (2004)
40. F.J. Gould, J.W. Tolle, Geometry of optimality conditions and constraint qualiﬁcations. Math.
Program. 2, 1–18 (1972)
41. J.P. Aubin, H. Frankowska, Set-Valued Analysis (Birkhäuser, Boston, 1990)
42. R.T. Rockafellar, R.J.-B. Wets, Variational Analysis (Springer, Berlin, 2009)
43. J.M. Borwein, A.S. Lewis, Convex Analysis and Nonlinear Optimization (Springer, New York,
2000)
44. A.E. Ozdaglar, D.P. Bertsekas, The relation between pseudonormality and quasiregularity in
constrained optimization. Optim. Methods Soft. 19, 493–506 (2004)
45. C.R. Bector, S. Chandra, J. Dutta, Principles of Optimization Theory (Alpha Science Interna-
tional Ltd., Harrow, U. K., 2005)
46. A. Ruszczynski, Nonlinear Optimization (Princeton University Press, Princeton, 2006)
47. R. Andreani, J.M. Martinez, B.F. Svaiter, A new sequential optimality condition for constrained
optimization and algorithmic consequences. SIAM J. Optim., 20, 3533–3554 (2010)
48. G. Haeser, M.L. Schuverdt, On approximate KKT condition and its extension to continuous
variational inequalities. J. Optim. Theory Appl. 149, 528–539 (2011)
49. R. Andreani, G. Haeser, J.M. Martinez, On sequential optimality conditions for smooth con-
strained optimization. Optimization 60, 627–641 (2011)
50. J.F. Bonnans, R. Cominetti, A. Shapiro, Second-order optimality conditions based on parabolic
second-order tangent sets. SIAM J. Optim. 9, 466–492 (1999)
51. A. Cambini, L. Martein, M. Vlach, Second-order tangent sets and optimality conditions. Math.
Japonica 49, 451–461 (1999)
52. R. Cominetti, Metric regularity, tangent sets and second-order optimality conditions. Appl.
Math. Optim. 21, 265–287 (1990)
53. G. Giorgi, B. Jiménez, V. Novo, An overview of second order tangent sets and their application
to vector optimization. Bol. Soc. Esp. Mat. Apl. 52, 73–96 (2010)
54. M. Hachimi, B. Aghezzaf, New results on second-order optimality conditions in vector opti-
mization problems. J. Optim. Theory Appl. 135, 117–133 (2007)
55. B. Jiménez, V. Novo, Second order necessary conditions in set constrained differentiable vector
optimization. Math. Meth. Oper. Res. 58, 299–317 (2003)
56. B. Jiménez, V. Novo, Optimality conditions in differentiable vector optimization via second-
order tangent sets. Appl. Math. Optim. 49, 124–144 (2004)
57. G. Haeser, A. Ramos, New constraint qualiﬁcations with second-order properties in nonlinear
optimization. J. Optim. Theory Appl. 184, 494–506 (2020)
58. J.-P. Penot, Second order conditions for optimization problems with constraints. SIAM J.
Control Optim. 37, 303–318 (1998)

Chapter 7
Sensitivity Analysis
7.1
General Results
An important area of applications of optimality conditions is concerned with ques-
tions arising from sensitivity analysis of nonlinear programming problems. In many
applications, the objective function f, as well as the constraints gi, i = 1, . . . , m,
and h j, j = 1, . . . , p, may depend also on certain number of parameters. For some
of these applications the optimal solution x∗of the unperturbed problem (i.e. with
ﬁxed values of the parameters) may be of less interest than its sensitivity with respect
to changes in the parameters. In other words, one may ask: how does the solution of
the problem change as a function of the changes in the values of the parameters?
In mathematical programming the term “sensitivity analysis” is usually referred
to all those investigations concerned in what happens to a solution of a mathematical
programming problem, containing a certain number of parameters, when there are
changes in the problem data. If we start from the usual formulation of (P5), i. e.
(P5) :
⎧
⎨
⎩
min f (x)
subject to: gi(x) ≦0, i = 1, . . . , m,
h j(x) = 0, j = 1, . . . , p < n,
with f, gi, i = 1, . . . , m; h j, j = 1, . . . , p, real-valued functions deﬁned on an
open set X ⊂Rn, the parametric version of (P5) is the following problem, where
we explicitly introduce a vector ε ∈Rk, that represents the parameters subject to
modiﬁcations:
(P5(ε)) :
⎧
⎪⎪⎨
⎪⎪⎩
min f (x, ε)
subject to: gi(x, ε) ≦0, i = 1, . . . , m,
h j(x, ε) = 0, j = 1, . . . , p < n,
x ∈X ⊂Rn, ε ∈Rk.
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al., Basic Mathematical Programming Theory, International Series
in Operations Research & Management Science 344,
https://doi.org/10.1007/978-3-031-30324-1_7
225

226
7
Sensitivity Analysis
When ε = ε∗is ﬁxed, the parametric problem (P5(ε∗)) becomes a standard non-
linear programming problem, only formally different from (P5).
We are interested in the analysis of the solutions x(ε) of (P5(ε)), in the analysis
of the optimal value function (called also the marginal function or the perturbation
function) f ∗(ε) = f [x(ε), ε] and in other questions on (P5(ε)).
We follow mainly the classical approach of [1] and his collaborators. For other
morerecentandmoresophisticatedapproachestosensitivityanalysisinoptimization,
one can consult the book of [3].
Throughoutthepresentchapterwemaketheassumptionthatallfunctionsinvolved
in (P5(ε)) are twice jointly continuously differentiable with respect to (x, ε) over
X × Rk. It will be clear when this assumption is not necessary.
In the present chapter we adopt the conventions and notations of [1]:
• The vectors of Rn are again considered column vectors, but the gradient of a
function f : Rn →R is considered a row vector of Rn. Consequently the Jacobian
matrix ∇f (x) of a function f : Rn →R is a (m, n) order matrix whose rows are
the gradients of the components of f.
• ∇εx(ε) is an (n, k) matrix:
∇εx(ε) =
⎡
⎢⎣
∇εx1(ε)
...
∇εxn(ε)
⎤
⎥⎦.
• ∇εy(ε) is an (n + m + p, k) matrix representing the Jacobian of the Karush-Kuhn-
Tucker triplet (x(ε), u(ε), v(ε)) taken with respect to the parameter vector:
∇εy(ε) =
⎡
⎣
∇εx(ε)
∇εu(ε)
∇εv(ε)
⎤
⎦.
• ∇2
xL (x, u, v, ε) is the Hessian matrix of order n, of the Lagrangian function
L (x, u, v, ε), with respect to x.
• ∇2
ε f ∗(ε) is the Hessian matrix, of order k, of f ∗(x, ε), with respect to ε.
• M(ε) is the Jacobian matrix of order (n + m + p) of the Karush-Kuhn-Tucker
conditions, with respect to (x, u, v).
• N(ε) is the Jacobian matrix of order (k, n + m + p) of the Karush-Kuhn-Tucker
conditions, with respect to ε.
• ∇2
εxL (x, u, v, ε) is the matrix of order (n, k) given by
⎡
⎢⎣
∇ε(∂L /∂x1)
...
∇ε(∂L /∂xn)
⎤
⎥⎦.

7.1 General Results
227
• ∇2
xεL (x, u, v, ε) is the matrix of order (k, n), whose (i, j) element is given by
(∂2L (x, u, v, ε)/∂x j∂εi), for i = 1, . . . , k and j = 1, . . . , n. Hence ∇2
εxL =
(∇2
xεL )⊤.
First, we spend some words for the unconstrained case. Let us consider an uncon-
strained parametric problem of the type
(P1(ε)) :
min f (x, ε),
with x ∈X ⊂Rn, X open set, ε ∈Rk, f twice jointly continuously differentiable
with respect to (x, ε) on X × Rk. We have the following basic results. Let ε = ε∗a
ﬁxed vector and let x∗∈X.
Theorem 7.1 If ∇x f (x∗, ε∗) = 0 and ∇2
x f (x∗, ε∗) is positive deﬁnite (Second-
Order Sufﬁcient Optimality Conditions), then x∗is a strict and locally isolated
minimizer of f (x, ε∗).
This last one is a well-known result (see Theorems 4.10 and 6.46) and the related
sensitivity results follow without additional assumptions.
Theorem 7.2 Assume that the Second-Order Sufﬁcient Optimality Conditions
(SOSOC) of Theorem 7.1 hold at (x∗, ε∗). Then, for ε near ε∗there exists a
unique once continuously differentiable vector function x(ε) such that x(ε∗) = x∗
and the (SOSOC) continue to hold at (x(ε), ε) and hence x(ε) is a locally unique
(i.e. isolated) local minimizer of f (x, ε). Furthermore, the optimal value function
f ∗(ε) = f [x(ε), ε] is twice continuously differentiable.
The previous result which follows directly from the classical implicit function
theorem, guarantees that the assumptions made at (x∗, ε∗) will persist near (x∗, ε∗)
at [x(ε), ε] , hence also the conclusions. It is possible, without any new assumptions
respect to the ones made in the previous theorem, to obtain sensitivity formulas for
the optimal value function.
Theorem 7.3 Assuming as in Theorem 7.1 and with x(ε) as in Theorem 7.2, it hold
the following relations at [x(ε), ε] near (x∗, ε∗) :
(i) From the chain rule for differentiation we have
∇ε f ∗(ε) = d
dε f [x(ε), ε]
= ∇x f (x, ε)∇εx(ε) + ∇ε f (x, ε) = ∇ε f (x, ε)
x=x(ε)
since ∇x f [x(ε), ε] = 0, where F(y)
y=z means to evaluate F at y = z. With
this understanding, we get
∇ε f ∗(ε) = ∇ε f [x(ε), ε] .
(7.1)

228
7
Sensitivity Analysis
(ii) Differentiating this last result again by ε, we ﬁnd that
∇2
ε f ∗(ε) = ∇2
xε f (x, ε)∇εx(ε) + ∇2
ε f (x, ε)
x=x(ε) .
The result in (7.1) is called in Economic Analysis “envelope theorem” (similarly
for a constrained optimization problem) and has some interesting applications in
utility theory, production theory, etc. See, e.g., [2, 4–7]. The term “envelope theorem”
derives from the fact (see, e.g. [8], p. 342) that, given a one-dimensional parametrized
family of curves, fα : [0, 1] →R, where α runs over some interval, a curve h :
[0, 1] →R is the envelope of the family if each point on the curve h is tangent to one
of the curves fα and each curve fα is tangent to h. That is, for each α, there is some
t and also for each t, there is some α, satisfying fα(t) = h(t) and f ′
α(t) = h′(t).
We may state informally the envelope theorem by saying that under appropriate
conditions the graph of the optimal value function is the envelope of the family of
graphs of f (x, ε).
We now consider the parametric problem (P5(ε)) and we give for this problem
some basic sensitivity results, taken from the book of [1]. The reader must be aware
that there are many other results concerning sensitivity and stability for mathematical
programming problems (see, besides [1, 9]) and the more advanced book of [3]).
Especially for Linear Programming Problems, where sensitivity and stability analysis
is often referred to as postoptimal analysis, there is a huge literature, concerning also
algorithmic questions.
We denote by K5(ε) the feasible set of (P5(ε)) and we assume that the functions
deﬁning (P5(ε)) are twice jointly continuously differentiable in (x, ε).
For the reader’s convenience we recall the two basic second-order optimality
conditions for the non-parametric problem (P5), previously given in Chap. 6, i.e.
the second-order necessary optimality conditions and the second-order sufﬁcient
optimality conditions that will be used in the present section.
Theorem 7.4 (Second-ordernecessaryoptimalityconditions)Supposethat x∗∈K5
is a local minimum point of (P5(0)), i.e. of (P5), and that the Linear Independence
Constraint Qualiﬁcation holds at x∗, i.e. the gradients

∇xgi(x∗), i ∈I (x∗); ∇xh j(x∗), j = 1, . . . , p

,
are linearly independent. Then the Karush-Kuhn-Tucker conditions hold at x∗with
associated unique Karush-Kuhn-Tucker multipliers u and v, and the additional
(usual) second-order necessary conditions hold at x∗, with multipliers (u, v) :
z⊤∇2
xL (x∗, u, v)z ≧0, ∀z ∈Z(x∗),
where Z(x∗) is the critical cone (see also page 201) given by

7.1 General Results
229
Z(x∗) =
⎧
⎨
⎩
z ∈Rn : ∇xgi(x∗)z ≦0, ∀i ∈I (x∗) \ I +(x∗, u),
∇xgi(x∗)z = 0, ∀i ∈I +(x∗, u),
∇xh j(x∗)z = 0, ∀j = 1, . . . , p
⎫
⎬
⎭.
We recall that I +(x∗, u) denotes the set of strictly active constraints at x∗, i.e.
I +(x∗, u) =

i ∈I (x∗) : ui > 0 in the (KKT) conditions

.
By strengthening the previous conditions one obtains the following standard
second-order sufﬁcient conditions for local strict optimality of x∗∈K5.
Theorem 7.5 (Second-order sufﬁcient optimality conditions). Suppose that the
Karush-Kuhn-Tucker conditions hold at x∗∈K5 with associated multipliers u and
v, and that the following second-order sufﬁcient conditions hold at x∗:
z⊤∇2
xL (x∗, u.v)z > 0, ∀z ̸= 0, z ∈Z(x∗).
Then x∗is a strict local minimum point of (P5).
The following result was originally proved for a speciﬁc class of parametric non-
linear programming problems in [10] and subsequently, with reference to (P5(ε)),
in [1, 11].
Theorem 7.6 Suppose that:
(i) The functions involved in (P5(ε)) are jointly twice continuously differentiable
on X × Rk.
(ii) The second-order sufﬁcient conditions of Theorem 7.5 for (P5(0)) hold at the
feasible point x∗with associated Karush-Kuhn-Tucker multipliers u and v.
(iii) The gradients ∇gi(x∗, 0), i ∈I (x∗), and ∇h j(x∗, 0), all j, are linearly inde-
pendent (i.e. the Linear Independence c. q. holds at x∗for (P5(0)).
(iv) ui > 0 when i ∈I (x∗), i.e. strict complementary slackness holds.
Then:
(a) x∗is a local isolated minimum point of problem (P5(0)) and the associated
Karush-Kuhn-Tucker multipliers u and v are unique.
(b) For ε in a neighborhood of 0, there exists a unique, once continuously dif-
ferentiable vector function y(ε) = [x(ε), u(ε), v(ε)]⊤satisfying the second-
order sufﬁcient conditions for a local minimum of problem (P5(ε)) such that
y(0) = (x∗, u, v)⊤= y∗, and hence x(ε) is a locally unique local minimizer of
problem (P5(ε)), with associated unique Karush-Kuhn-Tucker multipliers u(ε)
and v(ε).
(c) For ε near 0, the set of active inequalities is unchanged, strict complementary
slackness holds, and the active constraint gradients are linearly independent at
x(ε).

230
7
Sensitivity Analysis
Proof (Fiacco) Part (a) follows if (b) is true. It is stated separately because it is of
intrinsic interest. That x∗is a strict local minimum point of (P5(0)) follows from
assumption (ii), which also implies ∇L (x∗, u, v, 0) = 0. The uniqueness of u and
v follows from this and assumption (ii).
The proof of (b) follows from a straightforward application of the Implicit Func-
tion Theorem to the ﬁrst-order necessary optimality conditions of (P5(ε)), as follows.
Assumption (ii) implies the satisfaction of the Karush-Kuhn-Tucker conditions
⎧
⎨
⎩
∇L (x, u, v, ε) = 0,
uigi(x, ε) = 0, i = 1, . . . , m,
h j(x, ε) = 0, j = 1, . . . , p
(7.2)
at (x, u, v, ε) = (x∗, u, v, 0). Assumption (i) implies that the system of equations
(7.2) is once continuously differentiable in all the arguments; so, in particular, the
Jacobian matrix of (7.2) with respect to (x, u, v) is well deﬁned. It follows that
assumptions (ii), (iii) and (iv) imply the existence of the inverse of this matrix at
(x∗, u, v, 0) (see [12] and the next Theorem 7.7). The assumptions of the Implicit
FunctionTheoremwithrespecttotheEq.(7.2)andtheparticularsolution(x∗, u, v, 0)
are satisﬁed and we can conclude that in a neighborhood of (x∗, u, v), for ε in a
neighborhood of 0, there exists a unique once continuously differentiable function
[x(ε), u(ε), v(ε)] satisfying (7.2) with [x(0), u(0), v(0)] = (x∗, u, v). The satisfac-
tion of (7.2) means that for ε near 0, x(ε) is a ﬁrst-order Karush-Kuhn-Tucker point
of problem (P5(ε)), with associated Karush-Kuhn-Tucker multipliers u(ε) and v(ε).
To prove (c), we ﬁrst note that the active constraint set at x(0) remains the
same for ε near 0. This is seen immediately for the equalities h j(x(ε), ε) = 0,
since x(ε) satisﬁes (7.2) near ε = 0. For the inequalities, we have from (7.2) that
ui(ε)gi(x(ε), ε) = 0, i = 1, . . . , m, near ε = 0. If gi(x(0), 0) = 0 for some i, then
ui(0) > 0 (by strict complementary slackness), hence ui(ε) > 0 near ε = 0 by con-
tinuity of u(ε) and we conclude that gi(x(ε), ε) = 0. If gi(x(0), 0) < 0 for some i,
then gi(x(ε), ε) < 0 near ε = 0 by continuity. Therefore, deﬁning,
B(ε) = {i : gi(x(ε), ε) = 0}
we have concluded that B(ε) = B(0) for ε near 0. The argument also shows that
strict complementary slackness is preserved for ε near 0, proving the ﬁrst part of (c).
We now show that the second-order sufﬁcient optimality conditions hold at
[x(ε), u(ε), v(ε)] for any ε near 0. We must show that there exists δ > 0 such
that for any ε such that ∥ε∥< δ, it follows z(ε)⊤∇2L [x(ε), u(ε), v(ε)] z(ε) >
0 for any vector z(ε) ̸= 0 such that ∇gi [x(ε), ε] z(ε) = 0 for all i ∈B(0) and
∇h j [x(ε), ε] z(ε) = 0 for all j. This may be proved as follows. Suppose the
assumption is false. Then there must exist εk > 0 and zk ̸= 0 such that εk →
0, ∇gi [x(εk), εk] zk = 0 for all i ∈B(0), ∇h j [x(εk), εk] zk = 0 for all j and
(zk)⊤∇2L [x(εk), u(εk), v(εk), εk] zk ≦0 for k = 1, 2, . . .
Without loss of generality, assume
zk = 1 for all k. Select a convergent sub-
sequence of

zk
, relabel the subsequence

zk
for convenience and call the limit

7.1 General Results
231
¯z. Taking limits as k →+∞and recalling assumption (i) yields the conclusion
that ¯z⊤∇2L [x∗, u, v, 0] ¯z ≦0 for some ¯z such that ∥¯z∥= 1, ∇gi(x∗, 0)¯z = 0 for
all i ∈B(0) and ∇h j(x∗, 0)¯z = 0 for all j. But this is a contradiction of assump-
tion (ii) and the proof of the assertion is complete. Since it was established that
[x(ε), u(ε), v(ε)] uniquely solves (7.2) for ε near 0, it follows that x(ε) is a locally
unique local minimizer of (P5(ε)) with associated unique Karush-Kuhn-Tucker mul-
tipliers u(ε) and v(ε), completing the proof of part (b).
The preservation of strict complementary slackness was proved above. The preser-
vation of the linear independence of the (say) r + p active constraint gradients at
x(ε) for ε near 0 follows directly from the fact that an (r + p) by (r + p) Jacobian
of the system of equations deﬁned by the constraints that are active at x(0) must be
nonsingular, along with the assumed continuity of the ﬁrst derivatives. The proof is
complete.
□
References [1, 11] also show that the parameter derivatives of
y(ε) ≡[x(ϵ), u(ε), v(ε)]⊤
can be calculated: indeed (7.2) is identically satisﬁed by this function for ε near 0
(under the assumptions of Theorem 7.6) and can be differentiated with respect to
ε to yield explicit expression for the ﬁrst partial derivatives of the vector function
y(ε). Since the assumptions of Theorem 7.6 imply that the Jacobian matrix of (7.2),
M(ε), with respect to (x, u, v), is nonsingular, one obtains
M(ε)∇εy(ε) + N(ε) = 0
from which
∇εy(ε) = −[M(ε)]−1 N(ε),
(7.3)
where
M(ε) =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
∇2L
∇g⊤
1 · · · ∇g⊤
m ∇h⊤
1 · · · ∇h⊤
p
u1∇g1
g1
· · ·
0
0
· · ·
0
...
...
...
...
...
...
...
um∇gm
0
· · · gm
0
· · ·
0
∇h1
0
· · ·
0
0
· · ·
0
...
...
· · ·
...
...
...
...
∇h p
0
· · ·
0
0
· · ·
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
and
N(ε) =

∇2
εxL ⊤, u1∇εg⊤
1 , . . . , um∇εg⊤
m, ∇εh⊤
1 , . . . , ∇εh⊤
p
⊤.
Thus (7.3) provides a formula for the parameter derivatives of all components of
(x(ε), u(ε), v(ε)) for ε near 0. It also follows that ∇εy(ε) is continuous near 0, so
∇εy(ε) →∇εy(0) as ε →0.

232
7
Sensitivity Analysis
The previous theorem and its consequences obviously are valid, mutatis mutandis,
if instead of the unperturbed problem (P5(0)) we consider the unperturbed problem
(P5(ε∗)) with a ﬁxed ε∗.
The next theorem, due to [12], shows that the conditions imposed in Theorem 7.6
are also essentially necessary (under appropriate regularity assumptions) for the
invertibility of the Jacobian matrix M(ε∗).
Theorem 7.7 (i) Suppose that x∗∈K5(ε) satisﬁes the second-order necessary opti-
mality conditions of Theorem 7.4 for a local minimum point of (P5(ε∗)), with associ-
ated Karush-Kuhn-Tucker multipliers (u, v), and suppose that M(ε∗) has an inverse.
Then, the second-order sufﬁcient optimality conditions of Theorem 7.5 hold, the strict
complementary slackness conditions hold and the linear independence condition
holds.
(ii) If the second-order sufﬁcient optimality conditions of Theorem 7.5 hold for
(P5(ε∗)), with associated Karush-Kuhn-Tucker multipliers (u, v), the strict comple-
mentary slackness conditions hold and the linear independence condition holds, then
M(ε∗) has an inverse.
We can also calculate parameter derivatives of ﬁrst- and second-order of the
local optimal value f ∗(ε) = f (x(ε), ε) of (P5(ε)), again by repeated use of the
chain rule. Always under the assumptions of Theorem 7.6 (KKT) conditions for
x∗∈K5(ε), Second-Order Sufﬁcient Optimality Conditions, Strict Complementary
Slackness and Linear Independence), then in a neighborhood of ε = ε∗, the optimal
valuefunction f ∗(ε) ≡f [x(ε), ε]istwicecontinuouslydifferentiable.The“optimal
value Lagrangian” is deﬁned as
L ∗(ε) = L [x(ε), u(ε), v(ε), ε] .
We have the following results (for the proof see [1]):
(a) In a neighborhood of ε = 0 it holds
f ∗(ε) = L ∗(ε) = L [x(ε), u(ε), v(ε), ε] ;
(b) Since ∇ε f ∗(ε) = ∇yL ∇εy + ∇εL and since it can be shown that ∇yL ∇εy =
0, it follows that
∇ε f ∗(ε) = ∇εL (x, u, v, ε)
(x(ε),u(ε),v(ε),ε)
= ∇ε f +
m

i=1
ui(ε)∇εgi +
p

j=1
v j(ε)∇εh j
= ∇ε f + u(ε)⊤∇εg + v(ε)⊤∇εh,
where, as usual, the vertical bar denotes evaluation at the speciﬁed point.

7.1 General Results
233
(c)
∇2
ε f ∗(ε) = d
dε

∇εL [x(ε), u(ε), v(ε), ε]⊤
= ∇2
εxL (x, u, v, ε)⊤∇εx(ε) + ∇εg(x, ε)⊤· ∇εu(ε)
+∇εh(x, ε)⊤∇εv(ε) + ∇2
ε L (x, u, v, ε)

(x(ε),u(ε),v(ε),ε) .
We give now some insights on the convexity and other properties of the optimal
value function of (P5(ε)), deﬁned as
f ∗(ε) =

inf
x∈K5(ε) f (x, ε) if K5(ε) ̸= ∅,
+∞
if K5(ε) = ∅.
For further developments see [1, 13, 14].
If in problem (P5(ε)) the objective function f and every gi, i = 1, . . . , m, are
convex in x and every h j, j = 1, . . . , p, is linear afﬁne, for any ε ∈T ⊂Rk, the
problem (P5(ε)) is said to be convex in x. If these function properties hold jointly in
(x, ε) and T is a convex set, then (P5(ε)) is said to be jointly convex.
For simplicity, for the present considerations, continuous differentiability and
continuity are assumed. The solution set S(ε) of (P5(ε)) is deﬁned as
S(ε) =

x is a local solution: f (x, ε) = f ∗(ε)

.
We recall (see, e.g., [15]) that if F is a point-to-set mapping of E ⊂Rk into Rp,
then it is said that F is uniformly compact near ¯ε ∈E if there exists a neighborhood
N(¯ε) of ¯ε such that the closure of the set ∪ε∈N(¯ε)F(ε) is compact.
If problem (P5(ε)) is convex, then any local solution is global and the solution set
is convex; moreover, if the (KKT) conditions hold at the feasible point ¯x, then ¯x is a
global solution. We say that the Generalized Slater Constraint Qualiﬁcation, denoted
by (GS(ε)), holds for the convex problem (P5(ε)) if there exists a feasible point ¯x
suchthat gi(¯x, ε) < 0 foralli andsuchthatthegradients∇xh1(¯x, ε), . . . , ∇xh p(¯x, ε)
are linearly independent. For (P5(ε)) convex, the (MFCQ) and (GS) are equivalent
conditions.
Thefollowingpropositionscanbeproved(seethereferencestoFiaccoandKypari-
sis quoted above).
Proposition 7.8 For the once differentiable problem (P5(ε)) with nonempty uni-
formly compact feasible set K5(ε), for ε near ε∗, the optimal value function f ∗is
continuous at ε∗if the (MFCQ) holds for some x ∈S(ε∗).
Proposition 7.9 The optimal value function f ∗is convex on T if (P5(ε)) is jointly
convex in (x, ε) as deﬁned. Assuming solution attainment, this further implies that
f ∗is continuous and directionally differentiable in the interior of T.
We recall that the directional derivative of f ∗at ε∗in the direction z ∈Rk is

234
7
Sensitivity Analysis
Df ∗(ε∗, z) = lim
α→0+
f ∗(ε∗+ αz) −f ∗(ε∗)
α
.
Proposition 7.10 If K5(ε) does not vary with ε and f is concave in ε and T is
convex, then f ∗is concave on T. Again, assuming the solution is attained, this
means that f ∗is continuous and directionally differentiable in the interior of T.
Proposition 7.11 Suppose K5(ε) is nonempty and compact and that it does not
change with ε, and assume f and ∇ε f are continuous in (x, ε). Then, at any ε ∈T,
it follows that S(ε) ̸= ∅and compact and the directional derivative Df ∗(ε∗, z) exists
for any direction z and is given by
Df ∗(ε∗, z) = min
x∈S(ε) ∇ε f (x, ε)z.
Proposition 7.12 Assume that the problem (P5(ε)) is convex in x for each ε ∈T
and the problem functions are once continuously differentiable in (x, ε). Then, if
ε∗∈int(T ) and the set of points (x, u, v, ε∗) satisfying (KKT) is nonempty and
bounded, then in a neighborhood N(ε∗) of ε∗, it holds S(ε) ̸= ∅, and S(ε) is convex
for each ε ∈N(ε∗) and S(ε) is uniformly compact in N(ε∗). Furthermore, f ∗is
continuous and directionally differentiable in N(ε∗) in any direction z and
Df ∗(ε∗, z) = min
x∈S(ε)
max
(u,v)∈M(x,ε)∇εL (x, u, v, ε)z,
where M(x, ε) is the set of multipliers (u, v) that satisfy the (KKT) conditions.
As previously remarked, if (P5(ε)) is convex, the assumption (GS) is equivalent
to (MFCQ), or to assuming that M(x, ε) ̸= ∅and closed and bounded at a global
solution. Dispensing with convexity, but assuming that the gradients ∇gi(x, ε), i
such that gi(x, ε) = 0, and ∇h j(x, ε), j = 1, . . . , p, are linearly independent at
every x ∈S(ε), we have that Df ∗(ε∗, z) exists for each z ∈Rk and
Df ∗(ε∗, z) = min
x∈S(ε)∇εL (x, u(x, ε), v(x, ε), ε)z
where {u(x, ε), v(x, ε)} is the unique optimal Karush-Kuhn-Tucker multipliers vec-
tor associated with x ∈S(ε).
References [16, 17] extend the results of Theorem 7.6 by relaxing the Strict
Complementary Slackness Conditions and strengthening the standard second-order
sufﬁcient optimality conditions of Theorem 7.5.
Theorem 7.13 SupposethattheKarush-Kuhn.Tuckerconditionsholdat x∗∈K5(ε∗)
with some multipliers vectors u and v, that the following additional Strong Second-
Order Sufﬁcient Conditions hold at x∗for (P5(ε∗)), i.e.
z⊤∇2
xL (x∗, u, v, ε∗)z > 0
for all z ̸= 0 such that

7.1 General Results
235
∇xgi(x∗, ε∗)z = 0, ∀i ∈I +(x∗, u),
∇xh j(x∗, ε∗)z = 0, ∀j = 1, . . . , p,
and that the Linear Independence Constraint Qualiﬁcation holds at x∗.
Then:
(a) x∗is an isolated local minimum point of (P5(ε∗)) and the associated Karush-
Kuhn-Tucker multipliers vectors u and v are unique.
(b) For ε in a neighborhood of ε∗there exists a unique continuous vector function
y(ε) = [x(ε), u(ε), v(ε)]⊤satisfying the Karush-Kuhn-Tucker conditions and
the Strong Second-Order Sufﬁcient Conditions for a local minimum of (P5(ε))
such that y(ε∗) = (x∗, u, v)⊤and, hence, x(ε) is a locally unique local minimum
point of (P5(ε)) with associated unique Karush-Kuhn-Tucker multipliers vectors
u(ε) and v(ε).
(c) The Linear Independence Constraint Qualiﬁcation holds at x(ε) for ε near ε∗.
(d) There exist t > 0 and d > 0 such that for all ε with ∥ε −ε∗∥< d, it follows that
y(ε) −y(ε∗)
 ≦t
ε −ε∗ .
Note that the differentiability of x(ε), u(ε) and v(ε) is no longer assured by
the above theorem, however [16] proves that these functions admit at ε∗one-sided
directional derivatives. For what concerns the optimal value function f ∗(ε), under
the assumptions of Theorem 7.13 it is possible to obtain the following results [1, 16].
Theorem 7.14 If the assumptions of Theorem 7.13 are satisﬁed at x∗∈K5(ε∗),
then for ε near ε∗, the local optimal value function f ∗(ε) is once continuously
differentiable and
(a)
f ∗(ε) = L [x(ε), u(ε), v(ε)],
(b) ∇ε f ∗(ε) = ∇εL (x, u, v, ε)
(x(ε),u(ε),v(ε),ε) .
It is also possible to get some interesting sensitivity results for (P5(ε)) by substitut-
ing the Linear Independence Constraint Qualiﬁcation with the weaker Mangasarian-
Fromovitz Constraint Qualiﬁcation, but strengthening further the Strong Second-
Order Sufﬁcient Conditions for (local) strict optimality. This has been done in [18].
Theorem 7.15 (Kojima) Suppose that the Karush-Kuhn-Tucker conditions hold at
x∗∈K5(ε∗), with some multipliers vectors u and v. Suppose that the following Gen-
eral Strong Second-Order Sufﬁcient Conditions (GSSOSC) hold at x∗for (P5(ε∗)).
• GSSOSC: the Strong Second-Order Sufﬁcient Conditions hold at x∗for (P5(ε∗))
with multipliers (u, v) for every (u, v) ∈M(x∗, ε), being
M(x∗, ε∗) =
⎧
⎨
⎩
(u, v) ∈Rm × Rp : ∇xL (x∗, u, v, ε∗) = 0,
uigi(x∗, u∗) = 0, i = 1, . . . , m,
ui ≧0, i = 1, . . . , m
⎫
⎬
⎭.

236
7
Sensitivity Analysis
Suppose further that the Mangasarian-Fromovitz constraint qualiﬁcation holds at
x∗for (P5(ε∗)).
Then:
(a) x∗is an isolated local minimum point of (P5(ε∗)) and the set M(x∗, ε∗) is
compact and convex.
(b) There are neighborhoods N(x∗) of x∗and N(ε∗) of ε∗such that for ε in
N(ε∗) there exists a unique continuous vector function x(ε) in N(x∗) satisfying
the Karush-Kuhn-Tucker conditions for some [u(ε), v(ε)] ∈M(x(ε), ε) and the
General Strong Second-Order Sufﬁcient Conditions such that x(ε∗) = x∗, and,
hence, x(ε) is the locally unique local minimum point of (P5(ε)) in N(x∗).
(c) The Mangasarian-Fromovitz constraint qualiﬁcation holds at x(ε) for ε in
N(ε∗).
7.2
Sensitivity Results for Right-Hand Side Perturbations
In the present section we give some insights on sensitivity analysis for nonlinear
programming problems subject to right-hand side perturbations, i. e. on problems of
the type
R(ε) :
⎧
⎪⎪⎨
⎪⎪⎩
min f (x)
subject to: g(x) ≦ε1,
h(x) = ε2,
x ∈X,
with X ⊂Rn open set, f : X →R, g : X →Rm and h : X →Rp. Obviously ε1 ∈
Rm, ε2 ∈Rp and ε = (ε1, ε2) ∈Rk, with k = m + p. We continue to assume that
the functions of R(ε) are twice-continuously differentiable on the open set X ⊂Rn.
It is quite obvious that the general results for (P5(ε)) of the previous section can be
specialized and adapted to problem R(ε), but, curiously, also the vice-versa holds, in
the sense that any problem of the form (P5(ε)) may be reformulated as an equivalent
right-hand side parametric problem. It is sufﬁcient to redeﬁne ε in (P5(ε)) to be a
variable and to introduce a new parameter α such that ε = α. This results in the
problem
P(α) :
⎧
⎪⎪⎨
⎪⎪⎩
min f (x, ε)
subject to: g(x, ε) ≦0,
h(x, ε) = 0,
ε = α,
which is clearly equivalent to (P5(ε)) and of the form of R(ε). See [1, 19].
Since the formulation of R(ε) is often considered in several applications (above
all economic applications), we restate the specialized results of sensitivity analysis
for R(ε).

7.2 Sensitivity Results for Right-Hand Side Perturbations
237
Theorem 7.16 If
(i) The functions deﬁning R(ε) are twice-continuously differentiable (in x) on the
open set X ⊂Rn.
(ii) The second-order sufﬁcient optimality conditions for a strict local minimum
hold at the feasible point x∗of R(0), with associated Karush-Kuhn-Tucker
multipliers u and v.
(iii) The gradients ∇xgi(x∗), i ∈I (x∗), and ∇xh j(x∗), j = 1, . . . , p, are linearly
independent.
(iv) The Strict Complementary Slackness Conditions hold: ui > 0 when i ∈I (x∗).
Then:
(a) x∗is a local isolated minimizing point of R(0) and the associated Karush-Kuhn-
Tucker multipliers vectors u and v are unique.
(b) For ε in a neighborhood of 0, there exists a unique once-continuously dif-
ferentiable vector function y(ε) = [x(ε), u(ε), v(ε)]⊤satisfying the second-
order suffcient conditions for a strict local minimum of problem R(ε) such that
y(0) = [x∗, u, v]⊤and hence, x(ε) is a locally unique minimum point of R(ε)
with associated Karush-Kuhn-Tucker multipliers u(ε) and v(ε).
(c) For ε in a neighborhood of 0 we have
f ∗(ε) = L ∗(ε),
where
L (x, u, v, ε) = f (x) +
m

i=1
ui(gi(x) −εi) +
p

j=1
v j(h j(x) −ε j+m).
(d) Strict complementary slackness conditions and linear independence of the active
constraint gradients hold at x(ε) for ε near 0.
(e) For ε in a neighborhood of 0, the gradient of the optimal value function is
∇ε f ∗(ε) = −
 u(ε)
v(ε)
⊤
.
(f) For ε in a neighborhood of 0, the Hessian matrix of the optimal value function
is
∇2
ε f ∗(ε) = −
 ∇εu(ε)
∇εv(ε)

.
The above results are easily obtained from the previous general results on (P5(ε))
by letting f (x, ε) = f (x), gi(x, ε) = gi(x) −εi, i = 1, . . . , m, and h j(x, ε) =
h j(x) −ε j+m, j = 1, . . . , p.
For the reader’s convenience we give an autonomous proof of a reduced version
of the above theorem, i.e. we consider a parametric programming problem with

238
7
Sensitivity Analysis
right-hand side parameters and with only equality constraints, i.e. of the type (P3).
Therefore we consider the following problem
(P3(c)) :
⎧
⎨
⎩
min f (x)
subject to: h j(x) = c j, j = 1, . . . , p < n,
x ∈X ⊂Rn
and let f : X →R and every h j : X →R, j = 1, . . . , p, be twice-continuously
differentiable on the open set X ⊂Rn. For problem (P3(0)) we write the Lagrangian
function in the form
L (x, v) = f (x) + v⊤h(x).
K3(c) is the feasible set of (P3(c)) and the optimal value function of (P3(c)) is
denoted, as before, by f ∗(c) ≡f [x(c)] . The autonomous proof for the sensitivity
resultsconcerningtheproblem(R(ε))canbeperformed,mutatismutandis,following
the steps of the proof given below for the parametric problem (P3(c)).
Theorem 7.17 Suppose that for c = 0 there is a local solution x0 of (P3(0)) and
that the gradients ∇h1(x0), . . . , ∇h p(x0) are linearly independent. Suppose that the
associated Lagrange multiplier vector v (unique) satisﬁes the Lagrangian conditions
∇xL (x0, v) = 0
and the second-order sufﬁcient conditions for strict optimality
z⊤∇2
xL (x0, v)z > 0,
for all z ̸= 0 such that ∇h(x0)z = 0.
Then, there exists a neighborhood N(0) of 0 ∈Rp and a function x(c) continu-
ously differentiable on N(0), such that x(0) = x0 and, for very c ∈N(0), x(c) is a
strict local minimizer of f on K3(c). Furthermore,
∇c f ∗(c) = ∇c [ f (x(c))] |c=0 = −v⊤.
Proof Consider the system of equations
∇f (x) + v⊤∇h(x) = 0
(7.4)
h(x) = c.
(7.5)
By the assumptions, there is a solution (x0, v) to this system when c = 0. The Jaco-
bian matrix of the system at this solution is
M =
∇2
xL (x0, v) ∇h(x0)⊤
∇h(x0)
0

.

7.2 Sensitivity Results for Right-Hand Side Perturbations
239
Because by assumption x0 is a regular point and ∇2
xL (x0, v) is positive deﬁnite
on the linear subspace ∇h(x0)z = 0, an immediate consequence of a criterion on
positive deﬁniteness of quadratic forms on the nonzero solutions of an homogeneous
linear system, is that M is nonsingular (see Chap. 1 and [20]). Otherwise, directly:
indeed, the unique solution d ∈Rn × Rp of Md = 0 is d = 0 and hence M is non-
singular. To prove this, let us consider (d1, d2) ∈Rn × Rp and decompose Md = 0
into
∇2
xL (x0, v)d1 + ∇h(x0)⊤d2 = 0
∇h(x0)d1 = 0.
It results
(d1)⊤∇2
xL (x0, v)d1 + (d1)⊤∇h(x0)⊤d2 = 0
(d1)⊤∇2
xL (x0, v)d1 + (d2)⊤∇h(x0)d1 = 0,
whence
(d1)⊤∇2
xL (x0, v)d1 = 0 and ∇h(x0)d1 = 0.
(7.6)
But the only possibility for d1 to verify (7.6), owing to the second-order sufﬁcient
optimality conditions for x0, is d1 = 0. Hence ∇h(x0)⊤d2 = 0, but being ∇h(x0)⊤
of full rank, it holds also d2 = 0.
Being M nonsingular, it is possible to apply the Implicit Function Theorem: for
all c in some open neighborhood N(0), there exist x(c) and v(c) such that x(0) = x0,
v(0) = v, the functions x(·) and v(·) are continuously differentiable, and
∇f (x(c)) + v(c)⊤∇h(x(c)) = 0,
h(x(c)) = c.
For c sufﬁciently close to 0 the vectors x(c) and v(c) satisfy the second-order
sufﬁcient optimality conditions for the problem in question, since they satisfy them
by assunption for c = 0. This is straightforward to verify by using the continuity
assumptions: if it were not true, there would exist a sequence

ck
with ck →0 and
a sequence

zk
, with
zk = 1 and ∇h(x(ck))zk = 0 for all k, such that
(zk)⊤∇2
xL (x(ck), v(ck))zk ≦0, ∀k.
By taking the limit along a convergent subsequence of

zk
, we would obtain a
contradiction with the second-order sufﬁcient conditions at (x0, v). Hence, x(c) is a
strict local minimizer for problem (P(c)), with associated Lagrange multiplier v(c).
Finally, being x(c) continuously differentiable, also the composite function
f [x(c)] is continuously differentiable. By the chain rule we have

240
7
Sensitivity Analysis
∇c f (x(c)) |c=0 = ∇x f (x0)∇cx(0)
and
∇ch(x(c)) |c=0 = ∇xh(x0)∇cx(0).
In view of (7.5) the second of these relations is equal to the identity matrix I of
order p, while this, in view of (7.4), implies that the ﬁrst relation can be written as
∇c f (x(c)) |c=0 = −v⊤.
∇c f (x(c)) |c=0 = −v⊤.
□
Thus, the rate of change of f ∗(c) with respect to changes in the constraint values
is captured entirely by the optimal Lagrange multipliers. In economic applications
these multipliers are referred to as shadow prices (i.e. imputed prices) of resource
levels. See, e. g., [6, 7, 21].
Remark 7.18 Let us consider again problem R(ε) :
R(ε) :
⎧
⎪⎪⎨
⎪⎪⎩
min f (x)
subject to: g(x) ≦ε1,
h(x) = ε2,
x ∈X,
with X ⊂Rn open set, f : X →R, g : X →Rm and h : X →Rp. We make the
assumption that R(ε) is a convex problem, i.e. that f and every gi, i = 1, . . . , m,
are convex on the open convex set X and that every h j, j = 1, . . . , p < n, is linear
afﬁne. We make also the assumption that f and every gi is differentiable on X
(obviously every h j is differentiable on Rn). Without having recourse to second-
order optimality conditions, it is possible, under the said assumptions, to obtain
interesting results for R(ε). See, e.g., [13, 22].
Let us denote by f ∗(ε1, ε2) the optimal value function of R(ε).
Theorem 7.19 Let R(ε) be a convex problem; then:
(i) The function f ∗(ε1, ε2) is convex.
(ii) If ε1, ¯ε1 are such that ε1
i ≦¯ε1
i , ∀i = 1, . . . , m, then f ∗(ϵ1, ε2) ≧f ∗(¯ε1, ε2).
Proof (i) Let be
K(ε1, ε2) =

x ∈X : g(x) ≦ε1, h(x) = ε2
.

7.2 Sensitivity Results for Right-Hand Side Perturbations
241
One can easily check that for λ ∈[0, 1] we have the inclusion
λK(ε1, ε2) + (1 −λ)K(¯ε1, ¯ε2) ⊂K(ε1(λ), ε2(λ))
where ε1(λ) = λε1 + (1 −λ)¯ε1 and ε2(λ) = λε2 + (1 −λ)¯ε2. Consequently, if x ∈
K(ε1, ε2), ¯x ∈K(¯ε1, ¯ε2), λ ∈[0, 1] , then
f ∗(ε1(λ), ε2(λ)) ≦f (λx + (1 −λ)¯x) ≦λf (x) + (1 −λ) f (¯x).
Hence
f ∗(ε1(λ), ε2(λ)) ≦λf ∗(ε1, ε2) + (1 −λ) f ∗(¯ε1, ¯ε2).
(ii) Since K(ε1, ε2) ⊂K(¯ε1, ε2) ε1
i ≦¯ε1
i , i = 1, . . . , m, one has
f ∗(ε1, ε2) =
inf
x∈K(ε1,ε2) f (x) ≧
inf
x∈K(¯ε1,ε2) f (x) = f ∗(¯ε1, ε2).
□
Now we suppose that for the convex problem R(ε) the Slater constraint qualiﬁ-
cation is satisﬁed at ε = (0, 0) and that R(0, 0) admits a solution. With x0 ∈K(0, 0)
the Slater constraint qualiﬁcation for our problem can be expressed as:
• The vectors ∇h j(x0) are linearly independent, j = 1, . . . , p;
There exists ¯x ∈K(0, 0) such that gi(¯x) < 0, ∀i = 1, . . . , m, and h j(¯x) = 0,
∀j = 1, . . . , p.
We recall that under this constraint qualiﬁcation the set M(x0) of the Karush-Kuhn-
Tucker multipliers of R(0, 0) is a convex and compact set (nonempty). Under the
said assumptions, it is not possible to obtain the differentiability of the optimal value
function f ∗(ε1, ε2), however it is possible to obtain its directional differentiability.
Theorem 7.20 Let in R(ε) the above conditions be fulﬁlled and let x0 be a solu-
tion of R(0, 0) with multipliers u, v. Then the directional derivative Df ∗(0, y) =
Dy f ∗(0, 0) of the optimal value function at (0, 0) in the direction y = (y1, y2) ∈
Rm × Rp exists and it holds
Dy f ∗(0) =
max
(u,v)∈M(x0)

(−u⊤y1) + (−v⊤y2)

.
We have to note that in the case M(x0) is a singleton, then f ∗(ε1, ε2) is differen-
tiable at (0, 0) and we get the usual formula
∇ε f ∗(0) = −
 u
v
⊤
.

242
7
Sensitivity Analysis
References
1. A.V. Fiacco, Introduction to Sensitivity and Stability Analysis in Nonlinear Programming (Aca-
demic, New York, 1983)
2. S.N. Afriat, Theory of maxima and the method of Lagrange. SIAM J. Appl. Math. 20, 43–357
(1971)
3. J.F. Bonnans, A. Shapiro, Perturbation Analysis of Optimization Problems (Springer, New
York, 2000)
4. B. Beavis, I. Dobbs, Optimization and Stability Theory for Economic Analysis (Cambridge
University Press, Cambrdidge, U.K., 1990)
5. E. Silberberg, W. Suen, The Structure of Economics: A Mathematical Analysis, 3rd edn.
(McGraw-Hill Publishing Company, New York, 2001)
6. A. Takayama, Sensitivity Analysis in Economic Theory (1977)
7. A. Takayama, Mathematical Economics, 2nd edn. (Cambridge University Press, Cambridge,
1985)
8. T.M. Apostol, Calculus, 2nd edn. (Blaisdell, Waltham, Mass, 1967)
9. B. Bank, J. Guddat, D. Klatte, B. Kummer, K. Tammer, Non-Linear Parametric Optimization
(Birkhäuser, Basel, 1983)
10. A.V. Fiacco, G.P. Mccormick, Nonlinear Programming: Sequential Unconstrained Minimiza-
tion Techniques (Wiley, New York, 1968)
11. A.V. Fiacco, Sensitivity analysis for nonlinear programming using penalty methods. Math.
Program. 10, 287–311 (1976)
12. G.P. McCormick, Optimality criteria, in nonlinear Programming, in Nonlinear Programming,
eds. by R.W. Cottle, C.E. Lemke, S.I.A.M.-A.M.S. Proceedings, vol. IX (American Mathe-
matical Society, Providence, RI, 1976), pp. 27–38
13. A.V. Fiacco, J. Kyparisis, Convexity and concavity properties of the optimal value function in
parametric programming. J. Optim. Theory Appl. 48, 95–126 (1986)
14. J. Kyparisis, A.V. Fiacco, Generalized convexity and concavity of the optimal value function
in nonlinear programming. Math. Program. 39, 285–304 (1987)
15. J. Gauvin, A necessary and sufﬁcient regularity condition to have bounded multipliers in
nonconvex programming Math. Program. 12, 136–138 (1977)
16. K. Jittorntrum, Solution point differentiability without strict complementarity in nonlinear
programming. Math. Program. Study 21, 127–138. (A. V. Fiacco Ed.) (1984)
17. S.M. Robinson, Strongly regular generalized equations. Math. Oper. Res. 5, 43–62 (1980)
18. M. Kojima, Strongly stable stationary solutions in nonlinear programs, in Analysis and Com-
putation of Fixed Points, ed. by S.M. Robinson (Academic, New York, 1980), pp. 93–138
19. R.T. Rockafellar, Lagrange multipliers and subderivatives of the optimal value functions in
nonlinear programming. Math. Program. Study 17, 28–66 (1982)
20. G. Debreu, Deﬁnite and semideﬁnite quadratic forms. Econometrica 20, 285–300 (1952)
21. J. Gauvin, Shadow prices in nonconvex mathematical programming. Math. Program. 19, 300–
312 (1980)
22. W. Hogan, Directional derivatives of extremal-value functions with applications to the com-
pletely convex case. Oper. Res. 21, 188–209 (1973)

Chapter 8
Convex Optimization: Saddle Points
Characterization and Introduction to
Duality
8.1
Convex Optimization: Saddle Points Characterization
In the last 50 years or more, the words “nonsmooth optimization” generally refer
to nonlinear programming problems (or also to problems of calculus of variations
or optimal control) where the functions involved are not differentiable (in the sense
of Fré chet), but satisfy weaker assumptions concerning various kinds of limits in
various kinds of differential quotients, in order to obtain generalized gradients or
generalized directional derivatives.
Some insights on these approaches to nonsmooth optimization problems will be
presented in Chap. 10. But, from a historic point of view, the ﬁrst approach used to
treat a nonlinear convex programming problem, in the absence of differentiability
assumptions on the functions involved in the problem, was the saddle points char-
acterization of the Lagrangian function associated with the problem. This classical
approach, which has some importance also with reference to dual problems and min-
imax theory (see the next section of the present chapter) will be summarized in what
follows.
For simplicity, let us consider a nonlinear programming problem with only
inequality constraints, i.e. a problem of the type (P4).
(P4) :
⎧
⎨
⎩
min f (x)
subject to: gi(x) ≦0, i = 1, . . . , m,
x ∈X ⊂Rn,
where X ⊂Rn is a nonempty set, f : X →R and every gi : X →R, i = 1, . . . , m.
Note that we do not assume (at least for the moment) any differentiability prop-
erty on the functions involved in (P4). With regard to (P4), we introduce the usual
Lagrangian function
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al., Basic Mathematical Programming Theory, International Series
in Operations Research & Management Science 344,
https://doi.org/10.1007/978-3-031-30324-1_8
243

244
8
Convex Optimization: Saddle Points Characterization and Introduction to Duality
L (x, u) = f (x) +
m

i=1
uigi(x), x ∈X, ui ≧0, i = 1, . . . , m,
or, in vector notation
L (x, u) = f (x) + u⊤g(x), x ∈X, u ≧0.
Deﬁnition 8.1 A pair (x0, u0) ∈X × Rm
+ is called a Lagrangian saddle point or
simply a saddle point for (P4) if
L (x0, u) ≦L (x0, u0) ≦L (x, u0), ∀x ∈X, ∀u ≧0.
(8.1)
Intuitively, in R3, this could produce a picture like a horse saddle; however, there
is a common misconception that a saddle point always looks similar to a saddle (in
R3). See [1].
Clearly, a saddle point may never exist and even if it exists, it is not necessarily
unique.
Remark 8.2 Deﬁnition 8.1 makes reference to (P4), i.e. to a minimization problem.
If we consider a maximization problem of the type
⎧
⎨
⎩
max f (x)
subject to: gi(x) ≧0, i = 1, . . . , m,
x ∈X ⊂Rn,
the saddle point characterization for this problem is
L (x, u0) ≦L (x0, u0) ≦L (x0, u), ∀x ∈X, ∀u ≧0,
(8.2)
where
L (x, u) = f (x) −u⊤g(x), x ∈X, u ≧0.
Some authors (really few) call (8.1) “negative saddle point condition” and (8.2)
“positive saddle point condition”. We shall always make reference to minimization
problems.
Now we give a characterization of saddle points for the Lagrangian function of
problem (P4).
Theorem 8.3 Thepair(x0, u0), x0 ∈X,u0 ≧0,isasaddlepointfortheLagrangian
function of problem (P4) if and only if the following conditions hold:
(i) gi(x0) ≦0, i = 1, . . . , m;
(ii) u0
i gi(x0) = 0, i = 1, . . . , m;
(iii)
f (x0) ≦f (x) + m
i=1 u0
i gi(x), ∀x ∈X.
Proof Let us suppose that (x0, u0) is a saddle point for the Lagrangian function
L (x, u) = f (x) + u⊤g(x). By Deﬁnition 8.1 we have

8.1 Convex Optimization: Saddle Points Characterization
245
f (x0) +
m

i=1
uigi(x0) ≦f (x0) +
m

i=1
u0
i gi(x0) ≦f (x) +
m

i=1
u0
i gi(x), (8.3)
∀x ∈X, ∀u ≧0.
We rewrite the ﬁrst inequality:
f (x0) +
m

i=1
u0
i gi(x0) ≧f (x0) +
m

i=1
uigi(x0), ∀u ≧0.
(8.4)
Clearly, this implies that we must have gi(x0) ≦0, i = 1, . . . , m, or else (8.4)
can be violated by making a component of u sufﬁciently large. Hence, (i) is proved.
Now, taking u = 0 in (8.4) we obtain m
i=1 u0
i gi(x0) ≧0, but being gi(x0) ≦0, i =
1, . . . , m, and u0
i ≧0, we have m
i=1 u0
i gi(x0) ≦0 and hence m
i=1 u0
i gi(x0) = 0.
Hence, (ii) is proved.
From (ii) and from (8.3) we have (iii). Conversely, suppose that we are given
(x0, u0), with x0 ∈X and u0 ≧0 such that (i), (ii) and (iii) of the theorem hold.
Then L (x0, u0) ≦L (x, u0), ∀x ∈X, by properties (ii) and (iii). Furthermore,
L (x0, u0) = f (x0) +
m

i=1
u0
i gi(x0) = f (x0) ≧f (x0) +
m

i=1
uigi(x0), ∀u ≧0,
since (property (i)) gi(x0) ≦0, i = 1, . . . , m. Hence, (x0, u0) is a saddle point for
L (x, u).
□
The next result, which is a quite immediate corollary of the previous theorem,
puts into relationship the existence of a saddle point for L (x, u) and the existence
of optimal solutions of (P4).
Theorem 8.4 If the pair (x0, u0), x0 ∈X, u0 ≧0, is a saddle point for L (x, u) =
f (x) + u⊤g(x), x ∈X, u ≧0, then:
(a) x0 is a global solution of (P4).
(b) The complementary slackness conditions hold:
m

i=1
u0
i gi(x0) = 0, i.e. u0
i gi(x0) = 0, i = 1, . . . , m.
Proof Relation (b) has been already proved in Theorem 8.3. From the same theo-
rem we have that x0 is feasible for (P4) : gi(x0) ≦0, i = 1, . . . , m. From (iii) of
Theorem 8.3 we have
f (x0) ≦f (x) +
m

i=1
u0
i gi(x), ∀x ∈X.

246
8
Convex Optimization: Saddle Points Characterization and Introduction to Duality
For all feasible points x for (P4), it will hold m
i=1 uigi(x) ≦0 and hence, for all
feasible points x for (P4), we have f (x0) ≦f (x).
□
We remark that the previous result (quite strong) yields a sufﬁcient condition for
a point x0 to be a global solution for (P4), with no differentiability assumptions,
nor convexity (or generalized convexity) assumptions on the functions involved in
(P4). The condition expressed by Theorem 8.4 is only sufﬁcient. The next example
exhibits a minimization problem having a global optimal solution, but no saddle
point for the Lagrangian function.
Example 8.5 Consider the problem
⎧
⎨
⎩
min(−x1)
subject to: (x1)2 −x2 ≦0,
x2 ≦0,
with (x1, x2) ∈R2. This problem has a unique global minimizer at x0 = (0, 0)⊤. This
point is the only feasible solution (0 ≧x2 ≧(x1)2 ≧0). The associated Lagrangian
function is
L (x1, x2, u1, u2) = −x1 + u1((x1)2 −x2) + u2x2.
Note that L (x0, u) = 0 for all u. If the Lagrangian function has a saddle point
(x0, u0), we would have
0 ≦−x1 + u0
1((x1)2 −x2) + u0
2x2 = L (x, u0), ∀x.
Let x2 = 0. If x1 is positive and sufﬁciently small, we get L (x, u0) < 0, whereas
for (x0, u0) to be a saddle point, we must have 0 = L (x0, u0) ≦L (x, u0) < 0,
which is a contradiction.
To obtain necessary optimality conditions for (P4) in terms of a saddle point
characterization, we normally need to make some sort of regularity and convexity
assumption on the functions involved in (P4). Therefore, we consider a convex pro-
gramming problem, i.e. in (P4) the nonempty set X ⊂Rn is a convex set and the
functions f and every gi, i = 1, . . . , m, are convex on X.
We recall, from the previous chapters, mostly Chap. 3, the main properties of a
convex programming problem:
(1) The set of feasible solutions is convex.
(2) A local minimum point is a global minimum point.
(3) If the functions involved in the problem are differentiable, then a solution of the
Karush-Kuhn-Tucker conditions is a solution of the problem.
(4) A satisfactory duality theory can be established. See the next section.
(5) If the objective function is strictly convex, the minimum point (if there exists) is
unique (and hence strict).

8.1 Convex Optimization: Saddle Points Characterization
247
Some of these properties are still valid if the objective function and the constraints
are convenient generalized convex functions (see Chap. 3).
The following result is essentially due to [2] and in part to [3].
Theorem 8.6 (Kuhn-Tucker-Uzawa) Consider the convex problem (P4) and let x0
be a (global) minimum point for (P4). Then, there exist m + 1 multipliers ¯u0 ≧0,
¯u1 ≧0, . . . , ¯um ≧0, not all zero, such that
¯u0 f (x) +
m

i=1
¯uigi(x) ≧¯u0 f (x0), ∀x ∈X.
(8.5)
Furthermore, we get the complementary slackness conditions, i. e. ¯uigi(x0) = 0,
i = 1, . . . , m.
Proof Being x0 a global minimum point for (P4), the system
⎧
⎪⎪⎪⎨
⎪⎪⎪⎩
f (x) −f (x0) < 0
g1(x) ≦0
...
gm(x) ≦0
has no solution x ∈X. Hence, a fortiori, the system
⎧
⎪⎪⎪⎨
⎪⎪⎪⎩
f (x) −f (x0) < 0
g1(x) < 0
...
gm(x) < 0
has no solution x ∈X. Being f and every gi, i = 1, . . . , m, convex on the convex
set X ⊂Rn, the function ϕ : Rn →Rm+1 given by
ϕ(x) =
 f (x) −f (x0)
g(x)
	
is convex on X and by the Theorem of Fan-Glicksberg-Hoffman (Theorem 3.45),
there exist (m + 1) nonnegative multipliers, not all zero, ¯u0, ¯u1, . . . , ¯um, such that
¯u0( f (x) −f (x0)) +
m

i=1
¯uigi(x) ≧0, ∀x ∈X.
Thus, relation (8.5) holds. Being ¯ui ≧0, i = 1, . . . , m, and gi(x0) ≦0,
i = 1, . . . , m, we have m
i=1 ¯uigi(x0) ≦0. But if we substitute x0 into relation (8.5)
we obtain m
i=1 ¯uigi(x0) ≧0. Hence, we have m
i=1 ¯uigi(x0) = 0, or equivalently,
¯uigi(x0) = 0, i = 1, . . . , m.
□

248
8
Convex Optimization: Saddle Points Characterization and Introduction to Duality
We note that in Theorem 8.6 it may occur ¯u0 = 0 (as in the Theorem of Fritz John
for the differentiable case). It is therefore essential to impose some conditions, i.e.
some constraint qualiﬁcation, which ensures that in relation (8.5) it holds ¯u0 > 0, i.e.
without loss of generality, ¯u0 = 1. We take into consideration the following constraint
qualiﬁcations, which require no differentiability assumptions. We recall that X ⊂Rn
is a convex set, and that f : X →R and every gi : X →R, i = 1, . . . , m, are convex
functions.
(a) Slater constraint qualiﬁcation: There exists ¯x ∈X such that g(¯x) < 0.
(b) Karlin constraint qualiﬁcation (see [4]): There exists no u ∈Rm
+ \ {0} such that
u⊤g(x) ≧0, ∀x ∈X.
(c) Strict constraint qualiﬁcation: There exist x1, x2 ∈K4, with x1 ̸= x2, such that
g is strictly convex at x1, with respect to x2, i. e. for all λ ∈(0, 1) it holds
g(λx1 + (1 −λ)x2) < λg(x1) + (1 −λ)g(x2).
Theorem 8.7 It holds: (c) ⇒(a) ⇔(b) .
Proof The equivalence (a) ⇔(b) is an immediate consequence of the theorem of
Fan-Glicksberg-Hoffman (Theorem 3.45). From the fact that g is strictly convex at
x1 (with respect to x2), it results, with λ ∈(0, 1), as x1, x2 ∈K4,
g(λx1 + (1 −λ)x2) < λg(x1) + (1 −λ)g(x2) ≦0
and this shows that the point (λx1 + (1 −λ)x2) veriﬁes the Slater c. q.
□
Theorem 8.8 Let x0 be a (global) solution of the convex problem (P4) and let the
Slater constraint qualiﬁcation be satisﬁed. Then in (8.5) it holds ¯u0 = 1 and the
pair (x0, ¯u) is a saddle point for the Lagrangian function L (x, u). Furthermore,
¯uigi(x0) = 0, i = 1, . . . , m.
Proof If, absurdly, it would result ¯u0 = 0, relation (8.5) then becomes
m

i=1
¯uigi(¯x) ≧0,
which is absurd, as ¯ui ≧0, i = 1, . . . , m, not all equal to zero, and g(¯x) < 0. Then
we have the relations
L (x, ¯u) = f (x) + ¯u⊤g(x);
L (x0, ¯u) = f (x0) + ¯ug(x0) = f (x0), by the complementary slackness condi-
tions;
L (x0, u) = f (x0) + u⊤g(x0).
By relation (8.5), being u0 = 1, we have
L (x0, ¯u) ≦L (x, ¯u), ∀x ∈X.

8.1 Convex Optimization: Saddle Points Characterization
249
Moreover, it holds, being g(x0) ≦0,
L (x0, u) ≦L (x0, ¯u), ∀u ≧0.
Therefore, (x0, ¯u) is a saddle point for the Lagrangian function and the comple-
mentary slackness conditions hold (from Theorem 8.7 and from the characterization
of saddle points).
□
The following example shows that the Slater constraint qualiﬁcation (or another
suitable constraint qualiﬁcation) cannot be skipped in the above theorem.
Example 8.9 Consider the problem

min(−x), x ∈R
subject to:
x2 ≦0.
The only feasible point is x0 = 0, with value f (0) = 0. So, x0 = 0 is the unique
global solution of our problem. The Lagrangian function is
L (x, u) = −x + ux2, u ≧0, x ∈R.
There is no u0 ≧0 such that (x0, u0) is a saddle point of L .
We can therefore formulate the following scheme.
(x0, u0) saddle point for L (x, u) ⇒x0 (global) solution of (P4)
x0 global sol. of the convex problem (P4)
+c.q.
⇒(x0, u0) saddle p. for L (x, u)
The above notions have been generalized towards various directions. We wish to
mention some results due to [5] who take into consideration the class of pre-invex
functions (see Chap. 3). Again let us consider problem (P4) :
⎧
⎨
⎩
min f (x)
subject to: g(x) ≦0,
x ∈X ⊂Rn,
where f : X →R and g : X →Rm.
Theorem 8.10 Let X ⊂Rn be a nonempty set and let f : X →Rm be a pre-invex
function on X, with respect to η : Rn × Rn →Rm (i.e. each of its component is
pre-invex on X with respect to the same η). Then, either
f (x) < 0
has a solution x ∈X, or

250
8
Convex Optimization: Saddle Points Characterization and Introduction to Duality
p⊤f (x) ≧0, ∀x ∈X, for some p ≧0, p ̸= 0.
Proof See [5].
□
The problem (P4) will be said to satisfy the generalized Slater constraint qualiﬁ-
cation if g is pre-invex (with respect to η ) and there exists ¯x ∈X such that g(¯x) < 0.
The following result can be proved in the same manner as in the case of convex
functions.
Theorem 8.11 Assume that in (P4) the objective function f is pre-invex on X, with
respect to the vector function η and that the vector-valued function g is pre-invex on
X, with respect to the same function η. Assume that the generalized Slater constraint
qualiﬁcation holds. If x0 is a solution of (P4), then there exists u0 ∈Rm
+ such that
(x0, u0) is a saddle point of the Lagrangian function of (P4) :
L (x0, u) ≦L (x0, u0) ≦L (x, u0), ∀x ∈X, ∀u ∈Rm
+.
(8.6)
Conversely, if (8.6) is satisﬁed for some (x0, u0), then x0 is a solution for (P4).
We now assume that in (P4) the functions f and every gi, i = 1, . . . , m, are differ-
entiable on the open set X ⊂Rn and will put into evidence the relationships between
saddle point conditions for (P4) and Karush-Kuhn-Tucker conditions for (P4), these
last ones called by [6], “quasi-saddle point conditions”. These relationships are in
fact the central topic of the pioneering paper of [3].
Theorem 8.12 Let in (P4) the functions f and every gi, i = 1, . . . , m, be differen-
tiable on the open set X ⊂Rn. If the Lagrangian function of (P4) has a saddle point
(x0, u0), then the following Karush-Kuhn-Tucker conditions hold:
(i) ∇xL (x0, u0) = 0;
(ii) u0 ≧0, (u0)⊤g(x0) = 0;
(iii) g(x0) ≦0.
Proof The points (ii) and (iii) are parts of the characterization of a saddle point
(x0, u0) : see Theorem 8.3. We recall the deﬁnition of saddle point for (P4) :
L (x0, u) ≦L (x0, u0) ≦L (x, u0), ∀x ∈X, ∀u ≧0.
From the second inequality it results that x0 is a minimum point for L (x, u0)
over X. By Fermat’s theorem we have (X is open):
∇xL (x0, u0) = ∇f (x0) +
m

i=1
u0
i ∇gi(x0) = 0.
Therefore, also (i) is proved.
□
Now, let us consider the convex problem (P4), under differentiability assumptions.
We obtain the following converse result of the previous theorem.

8.1 Convex Optimization: Saddle Points Characterization
251
Theorem 8.13 Let in (P4) the functions f and every gi, i = 1, . . . , m, be differen-
tiable and convex on the open convex set X ⊂Rn. Let x0 ∈K4 verify the Karush-
Kuhn-Tucker conditions, with a multipliers vector u0 ≧0. Then the pair (x0, u0) is
a saddle point of the Lagrangian function L (x, u).
Proof Being f and every gi, i = 1, . . . , m, convex functions, the Lagrangian func-
tionL (x, u) = f (x) + u⊤g(x),u ≧0,isaconvexfunction.TheﬁrstKarush-Kuhn-
Tucker condition is
∇xL (x0, u0) = ∇f (x0) +
m

i=1
u0
i ∇gi(x0) = 0.
Being L (x, u) convex, ∀u ≧0, the previous stationary condition means that
L (x, u0) has a global minimum at x0 over X, hence
L (x0, u0) ≦L (x, u0), ∀x ∈X.
From the complementary slackness conditions and from the fact that x0 ∈K4,
we have
f (x0) +
m

i=1
uigi(x0) ≦f (x0) +
m

i=1
u0
i gi(x0), ∀u ≧0,
and hence
L (x0, u) ≦L (x0, u0), ∀u ≧0.
This inequality, together with the previous one, gives the thesis.
□
We present a scheme which summarizes the main results previously obtained.
The reference problem is (P4), i.e.
(P4) :
⎧
⎨
⎩
min f (x)
subject to: gi(x) ≦0, i = 1, . . . , m,
x ∈X ⊂Rn.
(x0, u0) saddle point for L (x, u)
differentiability
⇒
(x0, u0) satisﬁes (KKT).
(x0, u0) satisﬁes (KKT)
convexity
⇒
(x0, u0) saddle point for L (x, u).
(x0, u0) saddle point for L (x, u)
always
⇒
x0 solution of (P4).

252
8
Convex Optimization: Saddle Points Characterization and Introduction to Duality
x0 solution of (P4)
convexity + Slater c.q.
⇒
(x0, u0) saddle point for L (x, u).
Remark 8.14 From the previous scheme it appears that if (P4) is a linear program-
ming problem (see Chap. 9), i.e. the functions involved in the said problem are all
linear (afﬁne), i.e. differentiable and both convex and concave, the constraints are
automatically qualiﬁed, and therefore the Karush-Kuhn-Tucker conditions hold at
the optimal point x0. From this fact it follows that also the saddle point conditions
are veriﬁed, without any constraint qualiﬁcation. That is, for a linear programming
problem (L. P.) the necessary conditions, expressed by the saddle point characteri-
zation, need no constraint qualiﬁcation. This result is originally due to Goldman and
Tucker (see [7]), with a nontrivial proof. This shows that sometimes, the progress of
the mathematical machinery can drastically simplify the proofs of previous results.
We take again into consideration the convex problem (P4) in order to make two
further observations. First we show that the solutions of a convex problem (of the
type (P4)) do not change if we take into considerations only the active constraints,
referred to that solution x0.
Theorem 8.15 Let x0 ∈K4 be a solution of the convex problem (P4). Then x0 is
also an optimal solution of the “reduced” problem
(P4(I (x0)) :
⎧
⎨
⎩
min f (x)
subject to: gi(x) ≦0, i ∈I (x0),
x ∈X ⊂Rn
where X ⊂Rn is a nonempty convex set.
Proof Let us suppose tnat x0 is not an optimal solution of (P4(I (x0)). It follows that
there exists ¯x ∈X such that gi(¯x) ≦0, i ∈I (x0), and
f (¯x) < f (x0).
(8.7)
Since X is aconvexset, wehavethat xλ ≡λ¯x + (1 −λ)x0 ∈X for anyλ ∈(0, 1).
Since all gi are convex functions, it results that
gi(xλ) ≦λgi(¯x) + (1 −λ)gi(x0)
(8.8)
for λ ∈(0, 1).
From (8.8) it follows that gi(xλ) ≦0 for all i ∈I (x0). Since gi(x0) < 0 for
all i /∈I (x0), from (8.8) we have that gi(xλ) ≦0 for every i /∈I (x0) and for λ
sufﬁciently small. Thus, xλ ∈K4 for a small λ. From (8.7) it follows that
f (xλ) ≦λf (¯x) + (1 −λ) f (x0) < f (x0)
(8.9)
for all λ ∈(0, 1). Since xλ ∈K4, relation (8.9) contradicts the optimality of x0 ∈K4
for (P4).
□

8.1 Convex Optimization: Saddle Points Characterization
253
Now we consider again the convex problem (P4) and add the differentiability
assumption: all functions involved in (P4) are differentiable on an open set containing
the convex set X ⊂Rn. Then, if we know a solution x0 of this problem, it is possible
to characterize the solution set of the same problem, i.e. the set
S ≡arg min
x∈K4
f (x).
The following result has been obtained by [8], with the unnecessary assumption
that the functions involved in the problem are C 2.
Theorem 8.16 Let us consider the problem
(P4) :
⎧
⎨
⎩
min f (x)
subject to: gi(x) ≦0, i = 1, . . . , m,
x ∈X ⊂Rn,
where f and every gi, i = 1, . . . , m, are convex on the convex set X ⊂Rn and f
and every gi are continuously differentiable on some open set containing X. If x0 is
a solution of (P4), then a necessary and sufﬁcient condition such that x ∈K4 is a
solution of the same problem, is that:
∇f (x) = ∇f (x0)
(8.10)
(x −x0)⊤∇f (x0) = 0.
(8.11)
Proof In other words, the theorem asserts that if x0 ∈S, then
S = K4 ∩

x ∈Rn : ∇f (x) = ∇f (x0); (x −x0)⊤∇f (x0) = 0

.
We have to prove that, under the assumption that x0 ∈K4 is a solution of (P4),
then conditions (8.10)–(8.11) are equivalent to f (x) = f (x0). The sufﬁciency is
immediate. From convexity of f , we get
(x −x0)⊤∇f (x0) ≦f (x) −f (x0) ≦(x −x0)⊤∇f (x)
and, by (8.10)–(8.11) it holds f (x) = f (x0) and hence x ∈K4 is a solution.
Conversely, let us suppose that f (x) = f (x0), with x ∈K4. From convexity of
S, we have
xλ ≡λx + (1 −λ)x0 ∈S, ∀λ ∈(0, 1),
i.e.
f (xλ) = f (x0) = f (x).
From this relation and from convexity of f (Theorem 3.7), we have

254
8
Convex Optimization: Saddle Points Characterization and Introduction to Duality
λ(x −x0)⊤∇f (x0) ≦f (xλ) −f (x0) ≦λ(x −x0)⊤∇f (xλ),
(8.12)
i.e.
relation (8.11) holds. Indeed, we have (x −x0)⊤∇f (x0) ≦0 and if (x −
x0)⊤∇f (x0) < 0, then for λ sufﬁciently small we have
(x −x0)⊤∇f (x0 + λ(x −x0)) < 0,
against relation (8.12).
It remains to prove relation (8.10). Let us consider the convex function
ϕ(y) = f (y) −(y −x0)⊤∇f (x0).
Obviously, ϕ(x) = ϕ(x0) = f (x0), by relation (8.11), previously proved. More-
over, ∇ϕ(y) = ∇f (y) −∇f (x0) and ∇ϕ(x0) = 0, i.e. x0 is an unconstrained global
minimum point of the convex function ϕ. From ϕ(x) = ϕ(x0), it results therefore
that x is an unconstrained global minimum point of ϕ, i.e. ∇ϕ(x) = 0, i.e. relation
(8.10) holds.
□
8.2
Introduction to Duality
Duality plays a fundamental role in theory and methods of Linear Programming (see
Chap. 9), where this topic was born and where the pioneering results go back to the
classical minimax theorem of von Neumann for Games Theory (see [9]). Duality
theory for linear programming problems essentially consists in the possibility, given
a linear programming problem said “primal problem”, to formulate an associated
linear programming problem, said “dual problem” , with the basic property that if
one of the two problems admits solution, then also the other problem admits solution
and the two optimal values are equal (see Chap. 9).
Extensions of duality theory to the nonlinear case started immediately afterwards
the basic paper of Kuhn and Tucker [3] and the said extensions remain one of the
most investigated areas of mathematical programming, with great importance not
only from a theoretical point of view but also (similarly to what happened for linear
programming problems) for algorithmic developments.
The literature on duality theory in nonlinear programming is therefore abundant,
just as the literature on duality of linear programming problems. We shall give only
some basic results which are simple to prove and which open the path for the duality
results of Linear Programming presented in the next chapter.
There are various approaches to duality for nonlinear programming problems,
among which the Lagrangian approach, based on the Lagrangian function, and the
conjugate functions approach, based on conjugate functions, introduced by Fenchel
and subsequently studied in a great detail by Moreau and Rockfellar (see [10, 11]).
As [12] has shown that both approaches are equivalent, we shall not consider the
conjugate duality theory.

8.2 Introduction to Duality
255
Let now consider X ⊂Rn and Y ⊂Rm and let be given f : X →R and g : Y →
R. We can consider the following pair of mathematical programming problems: a
“primal” problem (P), of the type
(P) :
min
x∈X f (x),
and a “dual” problem (D), of the type
(D) :
max
y∈Y g(y).
We say that between (P) and (D) there are duality relations, or that (P) and
(D) is a pair of dual problems, when at least the ﬁrst of the following properties is
satisﬁed.
(I) f (x) ≧g(y), ∀x ∈X, ∀y ∈Y.
We accept the convention that inf f (x) = +∞, if X = ∅and that sup g(y) = −∞,
if Y = ∅. Furthermore, the two objective functions of (P) and (D) may not reach the
respective optimal values, therefore (I) may be rewritten in the more general form
inf
x∈X f (x) ≧sup
y∈Y
g(y).
This property is usually called “weak duality” .
A more satisfactory duality theory holds between (P) and (D) if also the following
property is satisﬁed.
(II) If one of the two problems (P) or (D) admits solution, then also the other
problem admits solution and it holds
min
x∈X f (x) = max
y∈Y g(y).
This property is usually called “strong duality” .
From (I), we get also the following other duality properties:
(III) If x∗∈X and y∗∈Y, then the equality f (x∗) = g(y∗) assures that x∗and
y∗are solutions, respectively, of (P) and (D).
(IV) If one of the two problems (P) or (D) admits unbounded extremum, i.e.
inf
x∈X f (x) = −∞or sup
y∈Y
g(y) = +∞,
then the other problem does not admit a ﬁnite solution.
In the literature we ﬁnd also the following terminology, with reference to the
connections between a primal and a dual problem.
• Direct dual existence theorem: if the primal problem has an optimal solution, then
also the dual problem has an optimal solution.
• Converse dual existence theorem: if the dual problem has an optimal solution, then
also the primal problem has an optimal solution.

256
8
Convex Optimization: Saddle Points Characterization and Introduction to Duality
• Strict direct duality theorem: if x∗solves the primal problem (P), then some y∗
solves the dual and f (x) = g(y∗).
• Strict converse duality theorem: if y∗solves the dual problem, then some x∗solves
the primal problem and g(y∗) = f (x∗).
Moreover, if for a dual problem (D), it happens that its dual is the primal problem
(P), we say that (P) and (D) is a pair of “symmetric” dual problems or that for (P)
and (D) the “involution property” holds.
WegivenowsomebasicnotionsonLagrangianduality.Forsimplicityweconsider
a constrained minimization problem with only inequality constraints, i.e. of the type
(P4), that in the present context we call the primal problem (P).
(P):
⎧
⎨
⎩
min f (x)
subject to: gi(x) ≦0, i = 1, . . . , m,
x ∈X ⊂Rn,
where f : X →R and gi : X →R , i = 1, . . . , m, X nonempty subset of Rn.
Given (P), the corresponding Lagrangian function is deﬁned in the usual way:
L (x, u) = f (x) + u⊤g(x), u ≧0.
We remark that problem (P) can be equivalently reformulated as
min
x∈X sup
u≧0
L (x, u),
being
sup
u≧0
L (x, u) =

 f (x), if g(x) ≦0,
+∞, otherwise.
In this context, the multipliers ui ≧0, i = 1, . . . , m, are also called “dual vari-
ables” .
The Lagrangian dual problem (D) is the following one.
(D) :

max θ(u)
subject to: u ≧0,
where
θ(u) = inf {L (x, u), x ∈X}
is called the Lagrangian dual function.
Note that the Lagrangian dual function θ may assume the value −∞for some
vector u. Moreover, the objective function of the dual may not reach the respective
optimal value, so it is more convenient to substitute inf f (x), instead of min f (x),
in the primal problem, and sup θ(u), instead of max θ(u), in the dual problem.

8.2 Introduction to Duality
257
We now give a fundamental example which shows that the Lagrangian dual, as
deﬁned above, is equivalent to the dual problem for Linear Programming, in the form
this last one is usually formulated.
Example 8.17 Consider a linear programming problem of the form
(P) :
⎧
⎨
⎩
min c⊤x
subject to: b −Ax ≦0,
x ≧0,
where c, x ∈Rn, c ̸= 0, A is a matrix of order (m, n) and b ∈Rm. Choosing X =
Rn
+, the Lagrangian dual problem is
(D) :

max θ(u)
subject to: u ≧0,
where
θ(u) = inf
x≧0c⊤x + u⊤(b −Ax).
This reduces to
θ(u) = b⊤u +

0,
if (c −A⊤u) ≧0
−∞, otherwise.
Assuming there are nonnegative values of u such that c ≧A⊤u, these would be
the only feasible choices for the maximization of θ(u) and therefore (D) takes the
familiar form of the dual problem for the linear programming (P) :
(D) :
⎧
⎨
⎩
max b⊤u
subject to: A⊤u ≦c,
u ≧0.
See Chap. 9.
Example 8.18 (Differentiable convex programming problem) Let us consider the
problem
(P) :
⎧
⎨
⎩
min f (x)
subject to: gi(x) ≦0, i = 1, . . . , m.
x ∈X ⊂Rn,
where X ⊂Rn is an open convex set, f and every gi, i = 1, . . . , m, are differentiable
convex functions on X. The Lagrangian function is L (x, u) = f (x) + u⊤g(x), u ≧
0,andit is further assumedthatθ(u) ̸= −∞for allu ≧0.Withtheseassumptions the
Lagrangian function is convex in x and has a minimum where its gradient is zero. That
is, the requirement θ(u) = minx∈X L (x, u) is the same as requiring ∇xL (x, u) = 0.
Thus, the dual problem may be written as

258
8
Convex Optimization: Saddle Points Characterization and Introduction to Duality
(D) :
⎧
⎨
⎩
max L (x, u)
subject to: ∇xL (x, u) = 0,
u ≧0.
This is the Wolfe dual problem for (P), one of the ﬁrst nonlinear duals, proposed
in [13]. See further, in the present section.
In the general case, the dual problem may not have a solution, even if the primal
problem has a solution. Conversely, the primal problem may not have a solution,
even if the dual problem has a solution. With reference to the Lagrangian duality, we
have the following ﬁrst basic result.
Theorem 8.19 (Weak duality theorem) Let x be feasible for problem (P), that is
x ∈X, g(x) ≦0; let u be feasible for problem (D), that is u ≧0. Then it holds
f (x) ≧θ(u).
Proof By deﬁnition of θ, and since x ∈X, we have
θ(u) = inf

f (y) + u⊤g(y), y ∈X

≦f (x) + u⊤g(x) ≦f (x),
since u ≧0, g(x) ≦0. This completes the proof.
□
Corollary 8.20 It holds
inf

f (x) : x ∈X, g(x) ≦0

≧sup

θ(u), u ≧0

.
Corollary 8.21 If f (x0) = θ(u0), where u0 ≧0 and x0 ∈

x ∈X, g(x) ≦0

,
then x0 and u0 solve the primal and dual problems, respectively.
Corollary 8.22 If
inf

f (x) : x ∈X, g(x) ≦0

= −∞,
then θ(u) = −∞, for every u ≧0.
Corollary 8.23 If
sup

θ(u) : u ≧0

= +∞,
then the primal problem has no feasible solution.
If we set
¯p = inf

f (x), x ∈X, g(x) ≦0

and
¯d = sup

θ(u), u ≧0

,
from Corollary 8.20 it appears that

8.2 Introduction to Duality
259
¯p −¯d ≧0.
If in the above relation strict inequality holds true, then a duality gap is said to
exist. Contrary to Linear Programming Problems, for the nonlinear case, without
further assumptions on the functions involved in (P) and (D), there may exist a
duality gap. Consider, e.g. the following example.
Example 8.24 Let be f (x) = −x2, X = [0, 1] , g(x) = 2x −1. Then ¯p = min(P)
= f
 1
2

= −1
4. L (x, u) = −x2 + u(2x −1), x ∈[0, 1] , u ≧0. We get
θ(u) = min{L (0, u), L (1, u)} = min{−u, u −1} =

−u,
if u ≧1
2,
u −1, if u < 1
2
and hence ¯d = max(D) = θ
 1
2

= −1
2.
The next theorem shows that under suitable convexity assumption and under a
constraint qualiﬁcation, we have no duality gap.
Theorem 8.25 (Strong duality theorem) Let us consider the primal problem (P),
where X ⊂Rn is a nonempty convex set, f : X →R and every gi : X →R, i =
1, . . . , m,areconvexon X.Supposethat theSlater constraint qualiﬁcationis veriﬁed,
i.e. there exists ¯x ∈X such that g(¯x) < 0. Then
inf

f (x) : x ∈X, g(x) ≦0

= sup

θ(u) : u ≧0

.
(8.13)
Furthermore, if the inf is ﬁnite, then sup

θ(u) : u ≧0

is achieved at some u0,
with u0 ≧0. If the inf is achieved at x0, then (u0)⊤g(x0) = 0.
Proof Let ¯p = inf

f (x) : x ∈X, g(x) ≦0

. By assumption ¯p < ∞. If ¯p = −∞
then, by Corollary 8.22, sup

θ(u), u ≧0

= −∞and therefore relation (8.13)
holds true. Hence, suppose that ¯p is ﬁnite, and consider the following system
f (x) −¯p < 0,
g(x) ≦0,
x ∈X.
By deﬁnition of ¯p, this system has no solution and a fortiori the following system
has no solution.
f (x) −¯p < 0,
g(x) < 0,
x ∈X.
By the Theorem of Fan-Glicksberg-Hoffman (Theorem 3.45), there exists a
nonzero vector (u0, u), with (u0, u) ≧0, such that

260
8
Convex Optimization: Saddle Points Characterization and Introduction to Duality
u0( f (x) −¯p) + u⊤g(x) ≧0, ∀x ∈X.
(8.14)
We ﬁrst show that u0 > 0. By contradiction, suppose that u0 = 0. By assumption,
thereexists ¯x ∈X suchthat g(¯x) < 0.Substitutingin (8.14),itfollowsthatu⊤g(¯x) ≧
0. Since g(¯x) < 0 and u ≧0, the inequality u⊤g(¯x) ≧0 is possible only if u = 0.
But this is excluded from the Theorem of Fan-Glicksberg-Hoffman. Hence, u0 > 0.
Dividing (8.14) by u0 and denoting ( 1
u0 )u by u0, we get
f (x) + (u0)⊤g(x) ≧¯p, ∀x ∈X.
(8.15)
This shows that θ(u0) = inf

f (x) + (u0)⊤g(x) : x ∈X

≧¯p. In view of The-
orem 8.19, it is clear that θ(u0) = ¯p and that u0 solves the dual problem.
To complete the proof, suppose that x0 is an optimal solution of the primal prob-
lem, that is x0 ∈X, g(x0) ≦0 and f (x0) = ¯p. From (8.15), letting x = x0, we get
(u0)⊤g(x0) ≧0. Since u0 ≧0 and g(x0) ≦0, we get (u0)⊤g(x0) = 0, and the proof
is complete.
□
The Lagrangian dual function θ(u) is a is always a concave function on its domain,
as, for ﬁxed x, L (x, u) is linear in u and thus θ(u) is the inﬁmum of a (possibly
inﬁnite) collection of functions linear in u. It follows that θ(u) admits a directional
derivative at every point of its domain. However, the Lagrangian dual function θ(u)
may be not differentiable. Furthermore, we have to note that Theorem 8.25 provides
only sufﬁcient conditions for the existence of strong duality: strong duality can hold
also for nonconvex problems. Consider, e.g. the following example.
Example 8.26 Consider the problem
(P) :

min

−(x1)2 −(x2)2
subject to: (x1)2 + (x2)2 −1 ≦0.
We have ¯p = min(P) = −1. The Lagrangian function is L (x, u) = −(x1)2 −
(x2)2 + u((x1)2 + (x2)2 −1) = (u −1)(x1)2 + (u −1)(x2)2 −u.
θ(u) =

−∞, if u < 1
−u,
if u ≧1.
Hence, u0 = 1 is the dual optimum and θ(u0) = −1.
We consider again a primal problem of the type (P4), but now we add a differen-
tiability assumption on the functions involved in the said problem, in order to treat
the Wolfe dual, already introduced in Example 8.18. Let us therefore consider the
following primal problem (P), i.e.
(P) :
⎧
⎨
⎩
min f (x)
subject to: gi(x) ≦0, i = 1, . . . , m,
x ∈X ⊂Rn,

8.2 Introduction to Duality
261
where the functions f : X →R and every gi : X →R, i = 1, . . . , m, are differ-
entiable on the open set X ⊂Rn. The Wolfe dual (see [13]) is deﬁned as follows
(L (x, u) is the usual Lagrangian function of (P) : L (x, u) = f (x) + u⊤g(x),
u ≧0).
(WD) :

max L (x, u)
subject to: (x, u) ∈K(WD) =

x ∈X : u ≧0, ∇xL (x, u) = 0

.
Note that the constraints of (WD) are part of the Karush-Kuhn-Tucker conditions
for the primal problem (P).
Theorem 8.27 (Weak duality theorem) Let X ⊂Rn be an open convex set and let
the functions f : X →R and every gi : X →R be differentiable convex functions
on X. If x is feasible for (P) and (x′, u) is feasible for (WD), we have
f (x) ≧L (x′, u).
Proof As f is differentiable and convex on X, it holds
f (x) −f (x′) ≧(x −x′)⊤∇f (x′).
As (x′, u) is feasible for (WD), it holds
∇f (x′) +
m

i=1
(∇gi(x′))⊤ui = 0.
Being the functions gi, i = 1, . . . , m, differentiable and convex on X, it results
gi(x) −gi(x′) ≧(x −x′)⊤∇gi(x′), i = 1, . . . , m.
From the last three relations, we get immediately
f (x) ≧f (x′) + u⊤(g(x′) −g(x)).
Finally, as x is feasible for (P), it results g(x) ≦0 and hence u⊤g(x) ≦0. From
the last inequality proved above, we get therefore
f (x) ≧f (x′) + u⊤g(x′).
□
Theorem 8.28 (Strict direct duality theorem) Let X ⊂Rn be an open convex set
and let the functions f : X →R and every gi : X →R be differentiable and convex
on X. If x0 is a solution of (P) and if the constraints of (P) verify a constraint
qualiﬁcation (i. e. (P) is “qualiﬁed” ), then there exists some u0 ∈Rm
+ such that the
pair (x0, u0) is a solution of (WD). Moreover, it holds

262
8
Convex Optimization: Saddle Points Characterization and Introduction to Duality
f (x0) = L (x0, u0).
Proof Being the primal problem (P) qualiﬁed, the optimal point x0 veriﬁes the
Karush-Kuhn-Tucker conditions with a multipliers vector u0 ∈Rm
+ :
∇xL (x0, u0) = 0
and
(u0)⊤g(x0) = 0.
Therefore, the pair (x0, u0) is feasible for (WD). Now
L (x0, u0) = f (x0) + (u0)⊤g(x0) = f (x0).
(8.16)
But, being f and g convex on X, by Theorem 8.27 we have
f (x0) ≧L (x, u), ∀(x, u) ∈K(WD).
Hence, (x0, u0) solves (WD) and relation (8.16) puts into evidence that the optimal
values of the two problems are equal.
□
Theorem 8.29 (Strict converse duality theorem) Assume that X ⊂Rn is an open
set and that f : X →R and gi : X →R, i = 1, . . . , m, are given. Let (x0, u0) be
a solution of (WD), and let f and every gi, i = 1, . . . , m, be twice-continuously
differentiable on X. If:
(a) L (·, u0) is pseudoconvex on X, with respect to x, and
(b) the Hessian matrix ∇2
xL (x0, u0) is nonsingular,
then x0 is a solution of the primal problem (P) and, moreover,
f (x0) = L (x0, u0).
Proof Being (x0, u0) a solution of (WD), it results that the system
∇xL (x, u) = 0
admits a solution. The assumptions of the theorem permit the application of the
Implicit Function Theorem: there exists an open neighborhood U(u0) of u0 and a
function x : U(u0) →X such that x(u0) = x0 and
∇xL (x, u)
(x(u),u) = 0, ∀u ∈U(u0).
Now we observe that, as (x0, u0) is a solution of the dual problem (WD), it results
that u0 is a solution of the following nonlinear programming problem
max

L (x(u), u) : u ∈U(u0), u ≧0

.

8.2 Introduction to Duality
263
It results that the following conditions are satisﬁed:
u0 ≧0, ∇uL (x(u0), u0) ≦0, (u0)⊤∇uL (x(u0), u0) = 0.
Now, being
∇uL (x(u), u) = (∇xL (x, u))⊤∇ux(u) + ∇uL (x, u),
it results
∇uL (x(u0), u0) = ∇uL (x0, u0).
The conditions written above become
u0 ≧0, ∇uL (x0, u0) ≦0, (u0)⊤∇uL (x0, u0) = 0,
i.e.
u0 ≧0, g(x0) ≦0, (u0)⊤g(x0) = 0.
(8.17)
As x0 ∈X, from (8.17) it results that x0 is also feasible for (P). As (x0, u0) ∈
K(WD), it results
∇xL (x0, u0) = 0.
Being L (·, u0) pseudoconvex on X, with respect to X, it results that x0 is a
global minimum point of L (·, u0) on the feasible set of (P). In other words, for
every feasible x for (P), we have
L (x, u0) ≧L (x0, u0),
i.e.
f (x) + (u0)⊤g(x) ≧f (x0).
Finally, as (u0)⊤g(x) ≦0, for each feasible x (for (P)), it results, for all feasible
x
f (x) ≧f (x0).
The fact that the optimal values of the two problems coincide, is an immediate
consequence of the complementary slackness conditions established in (8.17).
□
Remark 8.30 In Theorem 8.29, instead of assuming that the Lagrangian function
L (·, u0) is pseudoconvex on X, with respect to x, it is possible to assume that f is
pseudoconvex and that every gi, i = 1, . . . , m, is quasiconvex on the open convex
set X ⊂Rn. The proof is quite similar. The theorem still holds if (x0, u0) is not a
global, but only a local maximum point of L (x, u) on K(WD).
As we have just asserted, Theorem 8.29 holds with suitable generalized convexity
assumptions on the functions f and every gi, i = 1, . . . , m, involved in (P) and

264
8
Convex Optimization: Saddle Points Characterization and Introduction to Duality
(WD), whereas Theorems 8.27 and 8.28 require convexity assumptions. Indeed, for
theselasttwotheorems,ageneralizedconvexityassumptiononthefunctionsinvolved
in (P) and (WD) does not assure their validity, not even for linear constraints. The
following example is due to Mangasarian [14].
Example 8.31 Consider the following primal problem
(P) :

min(−e−x2), x ∈R,
subject to: 1 −x ≦0.
Its Wolfe dual is
(WD) :

 max(−e−x2 −ux + u), x, u ∈R,
subject to: 2xe−x2 −u = 0, u ≧0,
which can also be written in the equivalent form
max
x≧0

−

2x2 −2x + 1

e−x2
.
The solution of the primal problem is obviously ¯x = 1, the objective function
of (P) is pseudoconvex and all other assumptions of Theorem 8.29 are veriﬁed.
Nevertheless, the problem (WD) has no optimal solution, as the equation 2x2 −
2x + 1 = 0 has no real root. It has a greatest upper value at 0, which is not attained,
and even the weak duality theorem is not satisﬁed.
A more simple counterexample is the following one.
Example 8.32 Consider the primal problem
(P) :

min(x3 + x)
subject to: −x ≦−1.
The optimal point is at x0 = 1, whereas the value of the Wolfe dual
(WD) :

max(x3 + x + u(−x + 1), x, u ∈R,
subject to: 3x2 + 1 −u = 0, u ≧0
is unbounded.
We have to note that if we impose (as in Theorem 8.29) pseudoconvexity on the
Lagrangian function, the weak and strong Wolfe duality do hold. We give the simple
proof for weak duality:
(x −x′)⊤
∇f (x′) + u⊤∇g(x′)

= 0 ⇒f (x) + u⊤g(x) −f (x′) −u⊤g(x′) ≧0.
Therefore,

8.2 Introduction to Duality
265
f (x) ≧f (x′) + u⊤g(x′).
Now we give some other properties on the Wolfe dual problem. For convenience
we denote by K(P) the feasible set of the primal problem and by K(WD) the feasible
set of the Wolfe dual problem.
Theorem 8.33 Let X ⊂Rn be an open set and let in (P) the objective function
f : X →R and the constraints gi : X →R, i = 1, . . . , m, be differentiable on X.
(a) If there exists a pair (x0, u0) ∈K(WD) such that the linear system
∇g(x0)⊤z ≦−g(x0)
(8.18)
has no solution z ∈Rn, then the Wolfe dual problem has an unbounded objective
function on K(WD), i.e. sup(x,u)∈K(WD) L (x, u) = +∞.
(b) If, furthermore, g is convex on the open convex set X ⊂Rn, then K(P) = ∅.
Proof By Farkas’ theorem of the alternative, if system (8.18) admits no solution
z ∈Rn, then there exists ¯u ∈Rm such that
¯u ≧0, ∇g(x0)¯u = 0, (¯u)⊤g(x0) > 0.
(8.19)
Let us put u(λ) = u0 + λ¯u, λ ∈R+; it is clear that u(λ) ≧0 and
∇xL (x0, u(λ)) = 0
for every λ ∈R+. In other words, (x0, u(λ)) ∈K(WD) for every λ ∈R+. Moreover,
as
L (x0, u(λ)) = f (x0) + (u0)⊤g(x0) + λ(¯u)⊤g(x0),
it results
lim
λ→+∞L (x0, u(λ)) = +∞,
by the last inequality of (8.19). From the last written relation, we get
sup
(x,u)∈K(WD)
L (x, u) = +∞,
i.e. the thesis of part (a).
(b) Let us suppose K(P) ̸= ∅and let be x1 ∈K(P). As g is convex on the open
convex set X ⊂Rn, it results
g(x1) −g(x0) ≧(x1 −x0)⊤∇g(x0) = ∇g(x0)⊤(x1 −x0).
As g(x1) ≦0, from the last relation we have that system (8.18) has a solution
z = x1 −x0, which is in contradiction with the assumptions.
□

266
8
Convex Optimization: Saddle Points Characterization and Introduction to Duality
Theorem 8.34 If X = Rn, g is linear (afﬁne), K(P) = ∅and K(WD) ̸= ∅, then
the Wolfe dual problem has an unbounded objective function on K(WD), i.e.
sup
(x,u)∈K(WD)
L (x, u) = +∞.
Proof Let be g(x) = b −A⊤x, with b ∈Rm and A matrix of order (n, m). It is
sufﬁcient to prove that the linear system (8.18) has no solution z ∈Rn. Indeed, if
this system has a solution z0 ∈Rn, it results
−A⊤z0 ≦A⊤x0 −b,
i.e.
g(x0 + z0) = b −A⊤(x0 + z0) ≦0.
In other words, x0 + z0 ∈K(P), which contradicts the assumption that K(P) =
∅.
□
Theorem 8.35 Let X ⊂Rn be an open convex set and let f : X →R and every
gi : X →R, i = 1, . . . , m, be differentiable on X. If K(P) ̸= ∅and K(WD) = ∅,
and the functions f and every gi, i = 1, . . . , m, are concave on X, then f admits
no local minimizer on K(P).
Proof Let x0 ∈K(P); as x0 ∈X and K(WD) = ∅, it results that the linear system

∇f (x0) + ∇g(x0)u = 0
u ≧0
admits no solution u ∈Rm. By Farkas’ theorem of the alternative, it results that there
exists z0 ∈Rn such that

 ∇g(x0)⊤z0 ≦0
∇f (x0)⊤z0 < 0.
On the grounds of the previous relations, from the concavity assumptions on f
and g on X, for every λ > 0, we obtain
f (x0 + λz0) ≦f (x0) + λ(z0)⊤∇f (x0) < f (x0)
and
gi(x0 + λz0) ≦gi(x0) + λ(z0)⊤∇gi(x0) ≦gi(x0), i = 1, . . . , m.
Moreover, by choosing λ > 0 small enough, we have x0 + λz0 ∈X. From what
proved above, it results that for λ > 0 small enough we have x0 + λz0 ∈K(P) and
f (x0 + λz0) < f (x0), which shows that x0 cannot be a local solution of the primal
problem (P).
□

8.2 Introduction to Duality
267
As previously pointed out in Remark 8.30, when dealing with the Wolfe dual
(DW), weak and strong duality require convexity requirements on the objective
and constraint functions, whereas the converse duality theorem can be stated under
generalized convexity assumptions. In order to lessen the convexity requirements on
the weak and strong duality results (under differentiability assumptions), in [15] it
is proposed the following dual of (P).
(MWD) :
⎧
⎨
⎩
max f (y)
subject to: ∇f (y) + m
i=1 ui∇gi(y) = 0,
u⊤g(y) ≧0, u ≧0.
The advantage of (MWD) over (WD) is that the objective function of the dual is
the same as that of the primal, and, more importantly, the convexity requirements for
weak and strong duality relations can be furthermore relaxed.
Theorem 8.36 (Weak duality) If for all feasible vectors x of (P) and all feasible vec-
tors (y, u) of (MWD), the objective function f (x) is pseudoconvex and the function
u⊤g(x) is quasiconvex, then
f (x) ≧f (y).
Proof Let x be feasible for (P) and (y, u) be feasible for (MWD). Since u⊤g(x) ≦0
and u⊤g(y) ≧0, by using Theorem 3.20 since u⊤g(x) is quasiconvex, we have
m

i=1
uigi(x) −
m

i=1
uigi(y) ≦0 ⇒(x −y)⊤
 m

i=1
ui∇gi(y)

≦0, i = 1, . . . , m.
Therefore, by the constraints of (MWD), one has
(x −y)⊤∇f (y) = −
m

i=1
ui(x −y)⊤∇gi(y) ≧0,
and using the pseudoconvexity of f , we derive that f (x) ≧f (y).
□
Theorem 8.37 (Strong duality) If x0 is a local or a global optimum point of (P)
at which a constraint qualiﬁcation is satisﬁed, then there exists u ∈Rm such that
(x0, u) is feasible for (MWD) and the corresponding values of (P) and (MWD) are
equal. If, also, for all feasible (x, y, u), f is pseudoconvex and u⊤g is quasiconvex,
then x0 and (x0, u) are global optima for (P) and (MWD), respectively.
Proof Assuming that a constraint qualiﬁcation is satisﬁed at x0, then by the Karush-
Kuhn-Tucker conditions, there exists u ≧0 such that
∇f (x0) +
m

i=1
ui∇gi(x0) = 0,
u⊤g(x0) = 0.

268
8
Convex Optimization: Saddle Points Characterization and Introduction to Duality
Thus, (x0, u) is feasible for (MWD). Equality follows, given the pseudoconvexity
of f and the quasiconvexity of u⊤g, from weak duality.
□
Example 8.38 We consider again the primal problem of Example 8.32:
(P) :

min(x3 + x)
subject to: −x ≦−1.
The Mond-Weir dual is now
(MWD) :
⎧
⎪⎪⎨
⎪⎪⎩
max(y3 + y)
subject to: 3y2 + 1 −u = 0,
u(−y + 1) ≧0,
u ≧0.
The optimum is attained at y = 1, u = 4.
Now we wish to give a generalization of the Lagrangian saddle point
(Deﬁnition 8.1) and to give further insights on the properties of saddle points, as
these properties will allow to point out the relationships between saddle point theory,
min-max theory and duality theory.
In general, saddle points are closely related to the Theory of Games, in which two
players with conﬂicting interests oppose each other. For a given “pay off” function
ϕ(x, y), one player is minimizing ϕ with respect to x, while the other player is
maximizing ϕ with respect to y. This is called a min-max of ϕ. The mathematical
foundations of the theory of games and its applications to economics were laid down
by J. von Neumann in the twenties of the last century and subsequently described in
the classical work of [9].
Deﬁnition 8.39 Let ϕ be a real function of two real vectors x ∈X ⊂Rn and y ∈
Y ⊂Rm. Thus, the domain of ϕ is X × Y. A point (x∗, y∗), with x∗∈X and y∗∈Y,
is said to be a saddle point of ϕ if
ϕ(x∗, y) ≦ϕ(x∗, y∗) ≦ϕ(x, y∗), ∀x ∈X, ∀y ∈Y.
(8.20)
The value ϕ(x∗, y∗) is called the value of the saddle point. It is clear that (8.20)
is equivalent to
max
y∈Y ϕ(x∗, y) = ϕ(x∗, y∗) = min
x∈X ϕ(x, y∗).
We have the following general property.
Theorem 8.40 For all saddle points (x∗, y∗), the value ϕ(x∗, y∗) is constant. If
(x1, y1) and (x2, y2) are saddle points, then (x1, y2) and (x2, y1) are saddle points
as well.
Proof The following relations hold:

8.2 Introduction to Duality
269
ϕ(x1, y) ≦ϕ(x1, y1) ≦ϕ(x, y1), ∀(x, y) ∈X × Y;
ϕ(x2, y) ≦ϕ(x2, y2) ≦ϕ(x, y2), ∀(x, y) ∈X × Y.
If, in the ﬁrst one, we take x = x2 and y = y2, and in the second one we put
x = x1 and y = y1, we get
ϕ(x1, y1) = ϕ(x2, y2) = ϕ(x2, y1) = ϕ(x1, y2).
Moreover, we can write for every (x, y) ∈X × Y,
ϕ(x1, y) ≦ϕ(x1, y2) ≦ϕ(x, y2),
whence (x1, y2) is a saddle point. For (x2, y1) the proof is similar.
□
Now, let be X ⊂Rn, Y ⊂Rm, ϕ : X × Y →R and let us consider the following
two “min-max” problems, i.e. the “primal” problem (P)
(P) :
min
x∈X f (x);
and the “dual” problem (D)
(D) :
max
y∈Y g(y),
where
f (x) = sup
y∈Y
ϕ(x, y)
and
g(y) = inf
x∈X ϕ(x, y).
We note that it always holds (“weak duality theorem” ):
max
y∈Y inf
x∈X ϕ(x, y) ≦min
x∈X sup
y∈Y
ϕ(x, y).
(8.21)
The following fundamental theorem gives a characterization of saddle points in
terms of a min-max property and therefore it establishes links between saddle points
characterizations, min-max properties and duality properties for (P) and (D). In a
certain sense, it may be regarded as a strong duality result without no convexity and
no regularity assumptions on the functions involved.
Theorem 8.41 Let be ϕ : X × Y →R, with X ⊂Rn and Y ⊂Rm and let be
(x∗, y∗) ∈X × Y. The following conditions are equivalent:
(a) The pair (x∗, y∗) is a saddle point of ϕ on X × Y.

270
8
Convex Optimization: Saddle Points Characterization and Introduction to Duality
(b) x∗is a solution of (P), y∗is a solution of (D), and the two optimal values
are equal, i.e.
min
x∈X sup
y∈Y
ϕ(x∗, y) = max
y∈Y inf
x∈X ϕ(x, y∗)
(8.22)
Furthermore, if either (a) or (b) is satisﬁed, the common optimal value of (P)
and (D) must be ϕ(x∗, y∗).
Proof Suppose that (a) holds. We have
sup
y∈Y
ϕ(x∗, y) = max
y∈Y ϕ(x∗, y) = ϕ(x∗, y∗) = min
x∈X ϕ(x, y∗) = inf
x∈X ϕ(x, y∗),
where the middle equalities follow directly from the deﬁnition of saddle point, and
the ﬁrst and last equalities are trivial. Then,
min
x∈X sup
y∈Y
ϕ(x, y) ≦sup
y∈Y
ϕ(x∗, y) = ϕ(x∗, y∗) = inf
x∈Xϕ(x, y∗) ≦
≦max
y∈Y inf
x∈Xϕ(x, y) ≦min
x∈X sup
y∈Y
ϕ(x, y),
where the last inequality follows from the weak duality theorem (see (8.21)).
Since the ﬁrst and the last terms of the above inequalities are the same, we must
have equalities throughout. This proves (b), and the fact that the common optimal
value of (P) and (D) equals ϕ(x∗, y∗).
Conversely, suppose that (b) holds. Then (8.22) gives
inf
x∈X ϕ(x, y∗) = sup
y∈Y
ϕ(x∗, y),
which in turn implies
ϕ(x∗, y) ≦ϕ(x∗, y∗) ≦ϕ(x, y∗), ∀x ∈X, ∀y ∈Y,
that is proposition (a).
□
From the previous result, it appears that an existence theorem on saddle points
for ϕ can be considered an existence theorem on duality between (P) and (D) and
vice-versa. Note that, since now, we have not imposed on X and Y any particular
structure, nor we have required some particular property on the function ϕ. Now we
recall the main results available in the literature, on the existence of a saddle point
for ϕ : X × Y →R.
(i) (von Neumann). Let be
X =

x ∈Rn
+ :
n

i=1
xi = 1

, Y =
⎧
⎨
⎩y ∈Rm
+ :
m

j=1
y j = 1
⎫
⎬
⎭,

8.2 Introduction to Duality
271
ϕ(x, y) = y⊤Ax, with A matrix of order (m, n). Then ϕ admits a saddle point
(x∗, y∗) on X × Y.
(ii) (Kakutani). Let X and Y be convex and compact sets in Rn and Rm, respec-
tively. Let ϕ be continuous on X × Y, convex with respect to x on X (∀y ∈Y) and
concave with respect to y on Y (∀x ∈X). Then ϕ : X × Y →R admits a saddle a
saddle point (x∗, y∗) on X × Y.
(iii) (Sion). Let X and Y be convex and compact sets in Rn and Rm, respectively.
Let ϕ be lower semi-continuous and quasiconvex with respect to x on X and upper
semi-continuous with respect to y on Y. Then ϕ : X × Y →R admits a saddle point
(x∗, y∗) on X × Y.
See [16, 17].
We quote also a result, due to [18], which relates min-max theorems to duality
theorems. For other results of this type, the reader is referred to [19–22].
Theorem 8.42 Let X and Y be convex and closed sets in Rn and Rm, respectively;
let ϕ : X × Y →R be continuous on X × Y, convex with respect to x on X and
concave with respect to y on Y. For the programs
(P) :
min
x∈X max
y∈Y ϕ(x, y);
(D) :
max
y∈Y min
x∈X ϕ(x, y),
we have the following duality properties.
(i) If (D) admits a solution (x∗, y∗), i.e.
max
y∈Y min
x∈X ϕ(x, y) = min
x∈X ϕ(x, y∗) = ϕ(x∗, y∗),
and if the set

x ∈X : ϕ(x, y∗) = ϕ(x∗, y∗)

is bounded, then there exists x0 ∈X such that (x0, y∗) is a solution of both (P) and
(D) and ϕ(x∗, y∗) = ϕ(x0, y∗).
(ii) If (P) admits a solution (x∗, y∗), i.e.
min
x∈X max
y∈Y ϕ(x, y) = max
y∈Y ϕ(x∗, y) = ϕ(x∗, y∗),
and if the set

y ∈Y : ϕ(x∗, y) = ϕ(x∗, y∗)

is bounded, then there exists y0 ∈Y such that (x∗, y0) is a solution of both (P) and
(D) and ϕ(x∗, y∗) = ϕ(x∗, y0).
Now let us reconsider the primal and dual problems (P) and (D) described at the
beginning of the present section.

272
8
Convex Optimization: Saddle Points Characterization and Introduction to Duality
(P) :
⎧
⎨
⎩
min f (x)
subject to: gi(x) ≦0, i = 1, . . . , m,
x ∈X ⊂Rn,
i.e.
(P) :
min
x∈X sup L (x, u),
being L (x, u) = f (x) + u⊤g(x), u ≧0, and
sup
u≧0
L (x, u) =

 f (x), if g(x) ≦0,
+∞, otherwise,
and
(D) :

max θ(u)
subject to: u ≧0,
where
θ(u) = inf
x∈XL (x, u).
On the grounds of what was previously asserted, we have the following result.
Theorem 8.43 The following statements are equivalent:
(i) The Lagrangian function L (x, u) admits a saddle point at (x∗, u∗) ∈X × Rm
+.
(ii) x∗is a solution of (P), u∗is a solution of (D) and the optimal values of (P)
and (D) are equal:
f (x∗) = θ(u∗).
For the reader’s convenience, we give an “autonomous proof” of this theorem.
Proof (i) Suppose that (x∗, u∗) is a saddle point of the Lagrangian function; it will be
g(x∗) ≦0 (Theorem 8.3), hence x∗is feasible for (P). Since u∗≧0, we have also
that (x∗, u∗) is feasible for (D). Moreover, (Theorem 8.3), θ(u∗) = L (x∗, u∗) =
f (x∗) + (u∗)⊤g(x∗) = f (x∗). By Corollary 8.21, x∗and u∗solve (P) and (D),
respectively, with no duality gap.
(ii) Suppose that x∗and u∗are optimal solutions to problem (P) and (D), respec-
tively, with f (x∗) = θ(u∗). Hence, we have x∗∈X, g(x∗) ≦0 and u∗≧0. More-
over, we have by primal-dual feasibility that
θ(u∗) = min
x∈X

f (x) + (u∗)⊤g(x)

≦f (x∗) + (u∗)⊤g(x∗) ≦f (x∗).
But θ(u∗) = f (x∗) by hypothesis. Hence, equality holds throughout above. In
particular, (u∗)⊤g(x∗) = 0 and so,
L (x∗, u∗) = f (x∗) = θ(u∗) = min
x∈X

L (x, u∗)

.

References
273
Hence, all properties of Theorem 8.3 hold, in addition to x∗∈X and u∗≧0, and
so the pair (x∗, u∗) is a saddle point of the Lagrangian function.
□
References
1. A. Takayama, Mathematical Economics, 2nd edn. (Cambridge University Press, Cambridge,
1985)
2. H. Uzawa, The Kuhn-Tucker theorem in concave programming, in eds. by K.J. Arrow, L.
Hurwicz, H. Uzawa, pp. 32–37 (1958). Reprinted in Giorgi and Kjeldsen (2014)
3. H.W. Kuhn, A.W. Tucker, Nonlinear programming, in Proceedings of the Second Berkeley Sym-
posium on Mathematical Statistics and Probability, ed. by J. Neyman (University of California
Press, Berkeley, 1951), pp. 481–492. Reprinted in Giorgi and Kjeldsen (2014)
4. S. Karlin, Mathematical Methods and Theory in Games, Programming and Economics, vol. I,
II (Addison-Wesley, Reading, Mass, 1959)
5. T. Weir, B. Mond, Pre-invex functions in multiple objective optimization. J. Math. Anal. Appl.
136, 29–38 (1988)
6. K.J. Arrow, L. Hurwicz, H. Uzawa, Constraint qualiﬁcations in maximization problems. Naval
Res. Logist. 8, 175–191 (1961). Reprinted in Giorgi and Kjeldsen (2014)
7. H.W. Kuhn, A.W. Tucker (Eds.), Linear Inequalities and Related Systems, Annals of Mathe-
matics Studies N. 38 (Princeton University Press, Princeton, N.J., 1956)
8. O.L. Mangasarian, A simple characterization of solution sets of convex programming. Oper.
Res. Lett. 7, 21–26 (1988)
9. J. Von Neumann, O. Morgenstern, Theory of Games and Economic Behavior, 2nd edn. (Prince-
ton University Press, Princeton, 1947)
10. R.T. Rockafellar, Convex Analysis (Princeton University Press, Princeton, 1970)
11. R.T. Rockafellar, Conjugate Duality and Optimization. (Society for Industrial and Applied
Mathematics, Philadelphia, 1974)
12. T.L. Magnanti, Fenchel and Lagrange duality are equivalent. Math. Program. 7, 253–258 (1974)
13. P. Wolfe, A duality theorem for non-linear programming. Quart. Appl. Math. 19, 239–244
(1961)
14. O.L. Mangasarian, Nonlinear Programming (McGraw-Hill Book Company, New York, 1969)
15. B. Mond, T. Weir, Generalized concavity and duality, in Generalized Concavity in Optimization
and Economics, eds. by S. Schaible, W.T. Ziemba (Academic, New York, 1981), pp.263–280
16. M. Sion, On general minimax theorems. Pac. J. Math. 8, 171–176 (1958)
17. C. Berge, A. Ghouila-Houri, Programming, Games and Transportation Networks (Wiley, New
York, 1965)
18. J. Stoer, Duality in nonlinear programming and the minimax theorem. Numer. Math. 5, 371–379
(1963)
19. S. Karamardian, Strictly quasi-convex (concave) functions and duality in mathematical pro-
gramming. J. Math. Anal. Appl. 20, 344–358 (1967)
20. O.L. Mangasarian, J. Ponstein, Minmax and duality in nonlinear programming. J. Math. Anal.
Appl. 11, 504–518 (1965)
21. J. Stoer, C. Witzgall, Convexity and Optimization in Finite Dimensions, I (Springer, New York,
1971)
22. W. Vogel, Duale optimierungsaufgaben und sattelpunktsä. Unternehmensforschung 13, 1–28
(1969)

Chapter 9
Linear Programming and Quadratic
Programming
9.1
Linear Programming
As said in the previous pages, a Linear Programming problem (L. P. for friends)
is characterized by a linear (or a linear afﬁne) objective function and by linear (or
linear afﬁne) constraints. Usually, the variables are also required to be nonnegative.
As L. P. is a particular case of nonlinear programming (the involved functions are
both convex and concave and differentiable on Rn), all theorems seen for the general
case of nonlinear programming hold also for L. P. and almost always in a simpliﬁed
form.
The subject of L. P. was considered before the Second World War. The French
mathematician Joseph Fourier (1768–1830) was one of the ﬁrst researchers to inves-
tigate this subject and to point out its importance for mechanics and probability
theory. In a certain sense, he may be considered a precursor of the modern theory
on theorems of the alternative for linear systems and for the celebrated “simplex
algorithm” for L. P., devised by the American mathematician Dantzig (1947). In
the Soviet Union, the mathematician L. V. Kantorovich, in 1939, had already pro-
posed an algorithm to solve a special linear programming problem arising from a
transportation problem of products from various industries dislocated in different
territorial points. Subsequently, it appeared that the two algorithms (of Dantzing and
Kantorovich) are in fact equivalent (see, e.g. [1]).
Kantorovich (but not Dantzig) was awarded in 1975 (together with T. C. Koop-
mans) the Nobel Prize in Economic Sciences for the development of L. P.. For some
other historical notions the reader may see the book edited by Giorgi and Kjeldsen
[2]. For a description of various mathematical techniques to deal with a linear pro-
gramming problem, it is useful to the paper of [3] and the works on L. P. quoted in
the References. See also, for example: [4–19].
In the present book we shall not be concerned with the algorithms proposed to
solve a linear programming problem, but only with the basic facts on optimality and
duality theory. In L. P. the objective function f is usually expressed in the form
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al., Basic Mathematical Programming Theory, International Series
in Operations Research & Management Science 344,
https://doi.org/10.1007/978-3-031-30324-1_9
275

276
9
Linear Programming and Quadratic Programming
f (x) =
n

i=1
cixi = c⊤x,
c, x ∈Rn, c ̸= 0, and the constraints as inequalities of the type
n

j=1
ai jx j ≦bi, i = 1, . . . , m,
or, in a matrix form
Ax ≦b,
where A is a (real) matrix of order (m, n) and b ∈Rm. Furthermore, almost always
there is also a “sign restriction” on the variables, in the sense that they are required
to be nonnegative:
xi ≧0, i = 1, . . . , n; i.e. x ≧0, x ∈Rn.
Usually, in case of a maximization problem, a linear programming problem is
written in the form, said “canonical form”,
⎧
⎨
⎩
max c⊤x
Ax ≦b
x ≧0.
In case of a minimization problem, usually we have the form (again called “canon-
ical form”)
⎧
⎨
⎩
min c⊤x
Ax ≧b
x ≧0.
We remark once more that linear programming problems are differentiable opti-
mization problems, both convex and concave. These problems can be represented as
problems with functional constraints expressed by only equalities (this is possible
also for nonlinear programming problems, but in the case of L. P. the procedure is
more important, mostly for algorithmic considerations), by means of the introduc-
tion of nonnegative auxiliary variables, said “slack variables”. More precisely, if the
functional constraints are of the type
Ax ≦b,
they are transformed into the equivalent equality system
Ax + s = b, s ≧0,

9.1 Linear Programming
277
with s ∈Rm.
If the functional constraints are expressed as
Ax ≧b,
they are transformed into the equivalent equality system
Ax −s = b, s ≧0,
with s ∈Rm.
A linear programming problem in the form
⎧
⎨
⎩
max(min)c⊤x
Ax = b
x ≧0,
is said to be in “standard form”. Some classical books on L. P. adopt an opposite
denomination: they call a “canonical form” what we have called a “standard form”
and vice-versa.
The applications of L. P. are numberless, in the most varied sectors; we limit
ourselves to give only some typical examples, arising from management and ﬁnancial
models (one of the ﬁrst books on economic applications of L. P. is the one of [11]).
(a) Diet Problem. A diet problem (in the sense of linear programming) is one of
ﬁnding the least expensive way to meet a given set of daily untrivial goals using
a particular set of foods.
(b) Activity Analysis Problem. We have to use a given set of activities (production
processes) and a given set of resources in order to maximize proﬁt associated
with the production processes subject to limitations on the resources. When the
objective and constraints are expressed by linear (afﬁne) functions we have a L.
P. problem. The classical book on these questions (containing also the original
paper of G. B. Dantzig on the “simplex algorithm”) is the one edited by [20].
(c) Transportation and Assignment Problems. The ﬁrst analysis of these types of
problems is usually attributed to L. V. Kantorovich in 1939 and to F. L. Hitchcock
in 1941: a single commodity is to be “shipped” from m sources to n destinations.
At each source i there is a known supply ai > 0 of the commodity. At each
destination j there is a known demand b j > 0 for the commodity. To ship a
single unit of the commodity form source i to destination j costs ci j, the known
unit shipping cost. In such a problem we let the variable xi j denote the amount
of the commodity shipped from i to j. The objective is to minimize the total
shipping cost, taking into account the constraints:

278
9
Linear Programming and Quadratic Programming
⎧
⎪⎪⎨
⎪⎪⎩
min m
i=1
n
j=1 ci jxi j
subject to : n
j=1 xi j = ai, i = 1, . . . , m,
m
i=1 xi j = b j, j = 1, . . . , n,
xi j ≧0, ∀i, ∀j.
The set K = {x ∈Rn : Ax ≦b, x ≧0} or K =

x ∈Rn : Ax ≧b, x ≧0
	
or
K =

x ∈Rn : Ax = b, x ≧0
	
is the feasible set for a canonical or standard L. P.
problem. In the literature on L. P. the set K is also called “set of feasible solutions”,
whereas the optimal point x0 is also called “optimal feasible solution” (sic!).
Now, let S ⊂Rn be a convex set. A point x ∈S is called an extreme point of S if
there do not exist points x1 and x2 (x1 ̸= x2) in S such that
x = λx1 + (1 −λ)x2, for 0 < λ < 1.
Note that strict inequalities are imposed on λ. The deﬁnition stipulates that an
extreme point cannot be “between” any other two points of the set. Clearly, an
extreme point is a boundary point of the set, but the vice-versa is not obviously true.
If a convex set contains only a single point, this point will be considered an extreme
point. There exist also convex sets without extreme points: for example in R2 the
open set given by all interior points of a circle.
We have the following basic result on extreme points for convex sets. See, e.g.
[21, 22]. We ﬁrst need the following deﬁnition.
Deﬁnition 9.1 Theset S ⊂Rn isboundedfrombelow ifthereexistsavector x∗∈Rn
such that
x∗≦x, ∀x ∈S.
The set S ⊂Rn is bounded from above ,if there exists a vector x∗∗∈Rn such that
x∗∗≧x, ∀x ∈S.
Obviously, a bounded set S ⊂Rn, is both bounded from below and bounded
from above. We recall again the concept of supporting hyperplane for a convex set
S ⊂Rn (see also Theorem 2.19): given a boundary point x0 ∈S, then c⊤x = α,
c ̸= 0, α ∈R, is called a supporting hyperplane at x0 if c⊤x0 = α and if all other
points of S lie in one of the closed half-spaces produced by the hyperplane, that is
c⊤x ≧α for all x ∈S or c⊤x ≦α, for all x ∈S. (If x0 is a boundary point of a
closed convex set, there is at least one supporting hyperplane at x0).
Theorem 9.2 Let S ⊂Rn be a closed convex set, bounded from below (or bounded
from above). Then every supporting hyperplane for S contains at least an extreme
point of S.
Deﬁnition 9.3 A set in Rn which can be expressed as the intersection of a ﬁnite
number of closed half-spaces is called a polyhedral set or a polyhedron. A bounded
polyhedron is also called a polytope.

9.1 Linear Programming
279
We have to point out that in the literature there is not uniformity on the above
deﬁnitions. Several authors call “polytope” what we have called “polyhedron” and
vice-versa. It can be shown that a polytope is given by the convex hull of a ﬁnite
number of points (see Theorem 9.4 below).
The intersection of a ﬁnite number of polyhedra is a polyhedron and if there is a
polytope among them, then the intersection is a polytope. A closed half-space is a
polyhedron; a hyperplane is a polyhedron; the empty set is considered a polytope;
the whole Rn is a polyhedron. It turns out that a polyhedron is a closed convex set.
A polyhedral set can be represented by

x ∈Rn : Ax ≦b
	
or

x ∈Rn : Ax ≧b
	
,
where A is a matrix of order (m, n), x ∈Rn and b ∈Rm. If b = 0 ∈Rm, we have
the representation of (convex) polyhedral cones (see Chap. 2).
Any nonempty (unbounded) polyhedron X ⊂Rn can be expressed as the sum
of a polytope and a polyhedral cone (Representation Theorem for polyhedra). This
means that for every x ∈X, there exist points p ∈P, where P ⊂Rn is a polytope,
and q ∈C, where C ⊂Rn is a polyedral cone, such that x = p + q. Accordingly,
we write
X = P + C.
An extreme point of a polyhedron is called also a vertex of the polyhedron. A
polyhedron that has at least a vertex is also called a pointed polyhedron.
Theorem 9.4 A nonempty polytope is given by the convex hull of its vertices.
(This theorem is a particular case of a more general theorem, known as Theorem of
Krein-Milman).
Let x1 and x2 be distinct extreme points of the convex set S ⊂Rn. The line
segment joining them is called an edge of the convex set if it is the intersection of S
with a supporting hyperplane. If x1 is an extreme point of S, and if there exists another
point ¯x ∈S such that x = x1 + λ(¯x −x1) ∈S, ∀λ ≧0, and if, in addition the set
L =

x : x = x1 + λ(¯x −x1), ∀λ ≧0
	
is the intersection of S with a supporting
hyperplane, then the set L is said to be an edge of S which extends to inﬁnity.
Two distinct extreme points x1, x2 of the convex set S ⊂Rn are called adjacent
if the line segment joining them is an edge of the convex set. These concepts are
particularly useful when S is a convex polyhedron: the extreme points x1 and x2 of
the polyhedron K are adjacent if every point on the line segment joining x1 and x2
cannot be expressed as a convex combination of any pair of points in the convex
polyhedron that are not on this line segment. The line segment joining a pair of
adjacent extreme points of a convex polyhdron is an edge of the convex polyhedron.
From what previously said, we deduce that the feasible set of a linear programming
problem, if non-empty, of the type Ax ≦b, x ≧0, or Ax ≧b, x ≧0, or Ax = b,

280
9
Linear Programming and Quadratic Programming
x ≧0, is a convex polyhedron (hence a closed and convex set). This polyhedron is,
therefore, generated by the hyperplanes of equations
A1x = b1, A2x = b2, . . . , Amx = bm,
where Ai denotes the i-th row of A, i = 1, . . . , m; and by the hyperplanes x1 = 0,
x2 = 0, . . . , xn = 0.
If we denote by K the feasible set of an L. P. problem, then K can be:
(i) Empty, as the constraints are inconsistent.
(ii) Unbounded, i.e. some variables can assume arbitrary large values.
(iii) Bounded (and nonempty), i.e. a polytope. This is surely the most interesting
case, at least for practical problems.
We can now state the ﬁrst fundamental result on L. P.
Theorem 9.5 (First fundamental theorem on L. P.) A linear programming problem
which admits a solution, admits a global solution; furthermore, the optimal points
are not interior points of the feasible set. The optimal point, if unique, is at a vertex
of the feasible set; if the optimal point is not unique, there are inﬁnite optimal points
corresponding to two or more vertices of the feasible set and to all points of the edge
which contains these vertices.
Proof We ﬁrst remark that if the feasible set K is not bounded, the related P. L.
problem may have no solution (we are not saying that the problem has no solution!).
If K is bounded (i.e. it is a polytope), being also closed (and convex) and being
the objective function a continuous function, the theorem of Weierstrass assures the
existence of a solution. Being the objective function a linear (afﬁne) function, it is
both convex and concave and hence the optimal points, if any, are global optimal
points. In any case, the optimal points cannot be interior to K: indeed, in this case
we would have (Fermat’s theorem) ∇f (x0) = 0, i.e. c = 0 ∈Rn, which is excluded
by the assumption c ̸= 0. Therefore, the optimal points, if any, are on the boundary
of K. Let us consider, for example, the maximum point x0, i.e. we have
c⊤x ≦c⊤x0, ∀x ∈K.
Clearly, the relation c⊤x ≦c⊤x0 characterizes one of the two half-spaces asso-
ciated to the hyperplane c⊤x = c⊤x0; this half-space contains the whole K and the
associated hyperplane contains also the point x0 ∈K. The said hyperplane is, there-
fore, a supporting hyperplane for K, which is a closed and convex set. But K, in our
assumptions, is also (at least) a lower bounded set (i.e. bounded from below), being
x ≧0, ∀x ∈K. Therefore, Theorem 9.2 assures that every supporting hyperplane
for K (and hence also the hyperplane c⊤x = c⊤x0) contains at least an extreme point
of K. This fact allows to say that at least an extreme point (or vertex) of K is a max-
imum point. Let us prove that if the objective function attains its maximum value
at more than one vertex, then it attains the same value at every point of the convex

9.1 Linear Programming
281
combination of the said maximum points. For example, let us assume that f has a
maximum value at the vertices x1, x2, . . . , xq, i.e.
f (x1) = f (x2) = · · · = f (xq) = M.
If ¯x is any convex combination of the said vertices, i.e. if
¯x = λ1x1 + λ2x2 + · · · + λqxq,
being λi ≧0, i = 1, . . . , q, q
i=1 λi = 1, by the linearity of f we have
f (¯x) = f (λ1x1 + λ2x2 + · · · + λqxq)
= λ1 f (x1) + λ2 f (x2) + · · · + λq f (xq) = M
q

i=1
λi = M,
so, ¯x represents a (global) maximum point for the objective function. We can, there-
fore, conclude that if the optimal point is not unique and, say, x1 and x2 are two adja-
cent vertices which generate the solution of the problem, also all the inﬁnite points
(which form an edge) of the segment joining x1 and x2 are solutions, Obviously, for
the case of minimum points the reasoning is similar and similar considerations hold
for the case of problems expressed in standard form.
□
Remark 9.6 Obviously, there are L. P. problems which admit no solution, for exam-
ple, because the constraints are inconsistent (i.e. K = ∅) or because, with K ̸= ∅,
the feasible set is not bounded (from below or from above or both) and also the
related objective function is not bounded over K. For example, consider the simple
problem
⎧
⎨
⎩
max(x1 + x2)
x1 −x2 ≦−10
x1 ≧0, x2 ≧0.
Remark 9.7 Theorem 9.5 may generate the idea that an L. P. problem is, after all,
a trivial problem: it is sufﬁcient to compute the objective function on all vertices of
K and then to draw the related conclusions. Unfortunately, in almost all practical
problems, the number of vertices of a convex polyhedron, generated, e.g. by
Ax ≦b, x ≧0,
with A matrix of order (m, n), x ∈Rn, b ∈Rm, is a prohibitive number, also for a
powerful computer. Indeed, this number is less or equal than

m + n
n

.

282
9
Linear Programming and Quadratic Programming
If, for example, m = 50 and n = 100, the said number is about equal to 1040. The
“efﬁciency” of the “simplex method” essentially consists of a drastic reduction of
the number of vertices to inspect, in order to arrive to the solution (if there exists!)
through a tractable number of iterations. Sometimes the “run” is not so rosy, however
the algorithm is able to point out the obstacles that may exist. The reader is referred
to the works quoted in the References.
The reader is invited to develop, by using geometric considerations (i. e. the level
lines) the following simple problems in R2, in order to grasp the meaning of the main
propositions of Theorem 9.5.
Example 9.8 Consider the following L. P. problem
⎧
⎪⎪⎨
⎪⎪⎩
max z = 5x1 + 3x2
3x1 + 5x2 ≦15
5x1 + 2x2 ≦10
x1 ≧0, x2 ≧0.
The feasible set K is a bounded polyhedron (in R2 perhaps it is better to say
“polygon”), whose vertices are (0, 0), (2, 0), (0, 3), ( 20
19, 45
19) (see Fig. 9.1).
The solution is the point x0 = ( 20
19, 45
19), with f (x0) = 235
19
Example 9.9 Consider the following L. P. problem
⎧
⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩
max(2x1 + x2)
2x1 −x2 ≧0
x1 −x2 ≧−1
x1 −5x2 ≧−20
x1 ≧0, x2 ≧0.
The feasible set K is not bounded from above (see Fig. 9.2) and sup
x∈K
f (x) = +∞.
Fig. 9.1 Example 9.8.
Feasible set and maximum

9.1 Linear Programming
283
Fig. 9.2 Example 9.9. Feasible set
If, instead of a maximization problem we consider a minimization problem (over
the same feasible set), the solution is x0 = (0, 0).
Example 9.10 Consider the following L. P. problem
⎧
⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩
max(−x1 + x2)
2x1 −x2 ≧0
x1 −x2 + 1 ≧0
x1 −5x2 + 20 ≧0
x1 ≧0, x2 ≧0.
Note that the feasible set K is the same as Example 9.9. However, with this
objective function we have that the two adjacent vertices of K:
A = (1, 2); B =

15
4 , 19
4

are solutions of the problem, with f (A) = f (B) = 1. Hence, all points of the seg-
ment (edge) joining A and B are also solutions. Indeed, consider the (inﬁnite) points
x(λ) = λ
 1
2

+ (1 −λ)

15
4
19
4

, λ ∈[0, 1] .
Let us compute c⊤x(λ) :
[−1, 1]

λ + (1 −λ) 15
4
2λ + (1 −λ) 19
4

= −λ −15
4 + λ15
4 + 2λ + 19
4 −λ19
4 = 1.

284
9
Linear Programming and Quadratic Programming
We repeat that in the present book, we will not treat the computational questions
related to the “simplex algorithm”, however, we present some “algebraic” results
that, in a sense, are basic for the theoretical foundations of the said algorithm and
that allow us to obtain the second fundamental theorem for L. P.
Let us consider a linear programming problem in its standard form:
⎧
⎨
⎩
min(max) c⊤x
Ax = b
x ≧0,
(9.1)
where A is a matrix of order (m, n), x, c ∈Rn, c ̸= 0, and b ∈Rm. Without loss of
generality, let us assume that:
m < n and A has full rank, i.e. rk(A) = m.
This condition is not restrictive: indeed, if m = n (and rk(A) = m), the system admits
a unique solution x0, and this solution is feasible if x0 ≧0. If m > n, and if the
system Ax = b admits solutions, then (m −n) constraints are linear combinations
of the remaining constraints. Therefore, these (m −n) constraints can be eliminated.
As rk(A) = m, it is always possible to choose m linearly independent columns of
A. Without loss of generality we assume that the ﬁrst m columns of A are linearly
independent (permute the columns, if necessary). We obtain the partitioned matrix
A = [B; N] ,
where B is square, non-singular, of order m and N is of order (m, n −m).
The matrix B is called a “basis matrix” of A, as its lines are a basis for Rm. In
correspondence, the vector x ∈Rn is decomposed as follows
x =
 xB
xN

,
with xB ∈Rm and xN ∈Rn−m. The variables of xB are said “basic variables” and
the variables of xN are said “non-basic variables”. We have
Ax = [B; N]
 xB
xN

= BxB + NxN = b,
from which, being B non-singular,
xB = B−1b −B−1NxN
and hence
x =
 B−1b
0

+
−B−1N
I

xN
(9.2)

9.1 Linear Programming
285
is a solution of Ax = b for all xN ∈Rn−m.
Deﬁnition 9.11 The solution obtained by (9.2) putting in it xN = 0, i.e.
x =
 B−1b
0

is said a basic solution. If, moreover, it holds x ≧0, this solution is said a feasible
basic solution.
Deﬁnition 9.12 A basic solution with more than (n −m) zero components is said
a degenerate basic solution. If, moreover, this solution is nonnegative, we speak
of a feasible degenerate basic solution. The matrix B is also called, in this case,
degenerate basis matrix.
Example 9.13 Let us suppose that the system Ax = b is the following one:
⎡
⎣
−2 0 0 1 0
0
1 0 0 2
0
0 1 3 2
⎤
⎦x =
⎡
⎣
4
12
18
⎤
⎦.
The ﬁrst three columns of A are linearly independent, hence
xB =
⎡
⎣
−2 0 0
0
1 0
0
0 1
⎤
⎦
−1 ⎡
⎣
4
12
18
⎤
⎦=
⎡
⎣
−2
12
18
⎤
⎦.
The solution is x = [−2, 12, 18, 0, 0]⊤which is a basic solution, but not feasible,
as x1 < 0.
Note that also the sub-matrix is formed by the fourth, second, and third column:
⎡
⎣
1 0 0
0 1 0
3 0 1
⎤
⎦
is non-singular; hence, another basic solution is given by
xB =
⎡
⎣
1 0 0
0 1 0
3 0 1
⎤
⎦
−1 ⎡
⎣
4
12
18
⎤
⎦=
⎡
⎣
4
12
6
⎤
⎦.
Hence the solution x = [0, 12, 6, 4, 0]⊤is a basic solution and a feasible basic
solution.
The notion of a basic solution is important as the search for optimal solutions (of
an L. P. problem) is performed among the basic solutions.

286
9
Linear Programming and Quadratic Programming
Theorem 9.14 (Second fundamental theorem on L. P.) Let be given a linear pro-
gramming problem in the standard form (9.1), with m < n and rk(A) = m. If this
problem admits a nonempty feasible set, then there exists a feasible basic solution.
If there exists a solution to the problem, then there exists an optimal basic (feasible)
solution.
Proof Let us suppose that x ∈K ̸= ∅, i.e.
Ax = b, x ≧0,
i.e. with Ai denoting the i-th column of A,
n

i=1
xi Ai = b.
Let us suppose that x has p non-zero components (0 ≦p ≦n) and, without loss
of generality, let us suppose that these components are the ﬁrst p components. The
last relation becomes then
p

i=1
xi Ai = b.
(9.3)
We can have two cases:
(1) The columns A1, . . . , Ap are linearly independent, hence p ≦m. If p = m, we
have a basic solution, if p < m we have a degenerate basic solution and it is
possible to choose m −p columns among Ap+1, . . . , An, which, together with
the ﬁrst p columns form a basis.
(2) The columns A1, . . . , Ap are linearly dependent, i.e. there exist multipliers
y1, . . . , yp, not all zero, such that
p

i=1
yi Ai = 0.
(9.4)
From (9.3) and (9.4), by subtracting and multiplying (9.4) by a generic scalar α,
we obtain
p

i=1
(xi −αyi)Ai = b, ∀α ∈R.
We now deﬁne y =

y1, . . . , yp, 0, . . . , 0
⊤and so we obtain A(x −αy) = b, hence
x −αy satisﬁes the system, but it may be not feasible, i.e. not nonnegative. It is,
however, possible to choose α in such a way that at least one component of x −αy
is equal to zero (i.e. that component is feasible).
Now, let us consider every component of x −αy, with α ∈R:

9.1 Linear Programming
287
xi −αyi
⎧
⎪⎨
⎪⎩
= xi > 0, ∀α, if yi = 0
≧0, ∀α ≧xi
yi , if yi < 0
≧0, ∀α ≦xi
yi , if yi > 0.
If we choose ¯α = xi∗
yi∗̸= 0, where i∗is the index such that

xi∗
yi∗
 = min

xi
yi
 : yi ̸= 0, i = 1, . . . , p

,
then x −αy is a solution with at most p −1 non zero components, being equal to
zero the component corresponding to i∗.
By iterating this process, it is possible to get a solution corresponding to linearly
independent columns. In order to prove that if there exists a feasible optimal solution,
then there exists also a feasible basic optimal solution, we can follow the same lines
of the previous proof. Again we consider two cases.
(i) The columns A1, . . . , Ap are linearly independent. In this case, the solution
considered, obtained by adding the zero components, is a basic solution.
(ii) The columns A1, . . . , Ap are linearly dependent. By modifying the vector x as
in the ﬁrst part of the present proof, we remark that c⊤x becomes c⊤x −αc⊤y.
We know that x −αy is feasible for every α ∈[−|¯α| , |¯α|] . If c⊤y > 0 we
would have c⊤x −|¯α| c⊤y < c⊤x, against the assumption that x is optimal. If
c⊤y < 0 we would have c⊤x + |¯α| c⊤y < c⊤x, against the assumption that x is
optimal. Hence c⊤y = 0 and the optimality of the solution is kept, by passing
from x to x −¯αy, a solution with at most p −1 non zero components.
□
The previous theorem is important, as it allows to reduce the computations of the
objective function over the set of the basic feasible solutions, whose number is less
or equal than

 n
m

=
n!
m!(n −m)!.
Moreover,itisalsopossibletoputintorelationtheverticesofaconvexpolyhedron,
generated by a linear programming problem in its standard form, and the basic
feasible solutions of the same problem.
Theorem 9.15 Let us consider a linear programming problem in its standard form
(9.1), with A of full rank and let P be the convex polyhedron generated by the
constraints of the said problem. Then the following statements are equivalent.
(a) x is a vertex of P.
(b) x is a basic feasible solution of the feasible set K.
Proof Let x be a basic feasible solution of a linear programming problem in its
standard form; we have, therefore,

288
9
Linear Programming and Quadratic Programming
x =
 xB
0

, xB ∈Rm,
(9.5)
with det(B) ̸= 0 and xB = B−1b. In order to prove that x is a vertex of P we have
to show that there do not exist two vectors x1, x2 ∈K, x1 ̸= x2 such that
x = λx1 + (1 −λ)x2, 0 < λ < 1.
(9.6)
Absurdly let us suppose that there exist two vectors x1 and x2 which verify (9.6)
and given by
x1 =
u1
v1

, x2 =
u2
v2

,
(9.7)
with u1, u2 ∈Rm and v1, v2 ∈Rn−m. By substituting relation (9.5) into relations
(9.6) and (9.7) and making equal the last (n −m) components, we obtain
0 = λv1 + (1 −λ)v2
(9.8)
with λ > 0, 1 −λ > 0, v1 ≧0, v2 ≧0. Therefore, (9.8) holds only for v1 = v2 = 0.
Remembering that x1 and x2 are feasible, we have
Ax1 = Bu1 = b,
Ax2 = Bu2 = b.
From Bu1 = Bu2, being B non-singular, it follows u1 = u2 and hence x1 = x2,
against the assumptions, so x is a vertex of P.
Vice-versa,letussupposethat x isavertexof P andthat x hasitsﬁrstk components
different from zero. It will hold
x1A1 + x2 A2 + · · · + xk Ak = b
with xi > 0, i = 1, . . . , k. In order to show that x is a basic feasible solution, we have
to prove that A1, A2, . . . , Ak are linearly independent. If, absurdly, these vectors are
linearly dependent, there would exist a linear combination
y1A1 + y2 A2 + · · · + yk Ak = 0,
with yi not all zero. Then, putting y⊤= (y1, y2, . . . , yk, 0, . . . , 0) ∈Rn one has
x + αy ∈P forallα ∈R.Rememberingthat xi > 0,i = 1, . . . , k,itwillbepossible
to choose ε > 0 such that
xi + εyi > 0; xi −εyi > 0 ∀i = 1, 2, . . . , k.

9.2 Duality for Linear Programming
289
Putting x = 1
2(x + εy) + 1
2(x −εy), this vector is given by the convex combi-
nation of two distinct vectors of P, which is absurd, as x is a vertex of P. Hence
A1, A2, . . . , Ak are linearly independent and x is a basic feasible solution.
□
We conclude the present section by remarking that the solution of a linear pro-
gramming problem, in its standard form, is unique if xB > 0 (then B is unique), i.e.
for a non-degenerate basic solution; B can be non unique if some component of xB
is equal to zero, i.e. for a degenerate basic solution.
9.2
Duality for Linear Programming
DualitytheorywasbornwithinlinearmodelsandmostlywithinL.P.models.Wehave
already given in the previous chapter an example of dual problem for a “primal” L.
P. problem. It seems that it was the father of G. B. Dantzig, Tobias Dantzing, himself
a mathematician, who suggested the name of “primal problem”, in contraposition
to “dual problem”. Duality theory for L. P. problems is important, not only from a
theoretical point of view, but also from a computational point of view: there exists also
a “dual simplex algorithm”, which can be used, together with the simplex algorithm,
to ameliorate the procedure of determining the solution of an L. P. problem.
• If we consider a primal linear programming problem in its canonical form, of the
type
(P) :
⎧
⎨
⎩
max c⊤x
Ax ≦b
x ≧0,
its dual is the problem
(D) :
⎧
⎨
⎩
min y⊤b (or b⊤y)
y⊤A ≧c⊤(or A⊤y ≧c)
y ≧0.
• If we consider a primal linear programming problem in its canonical form, of the
type
(P) :
⎧
⎨
⎩
min c⊤x
Ax ≧b
x ≧0,
its dual is the problem
(D) :
⎧
⎨
⎩
max y⊤b (or b⊤y)
y⊤A ≦c⊤(or A⊤y ≦c)
y ≧0.

290
9
Linear Programming and Quadratic Programming
• If we consider a primal linear programming problem in its standard form, of the
type
(P) :
⎧
⎨
⎩
max c⊤x
Ax = b
x ≧0,
its dual is the problem
(D) :
⎧
⎨
⎩
min y⊤b (or b⊤y)
y⊤A ≧c⊤(or A⊤y ≧c)
(y unrestricted).
• If we consider a primal linear programming problem in its standard form, of the
type
(P) :
⎧
⎨
⎩
min c⊤x
Ax = b
x ≧0,
its dual is the problem
(D) :
⎧
⎨
⎩
max y⊤b (or b⊤y)
y⊤A ≦c⊤(or A⊤y ≦c)
(y unrestricted).
On the grounds of what previously asserted, it is worth remarking what follows.
(a) The dual (D) of the primal problem (P) is unique and is itself a linear program-
ming problem.
(b) The dual of the dual is the primal problem (“involution property”). We speak
also of a “pair” of primal-dual problems.
(c) If (P) is a maximization problem, (D) is a minimization problem (and vice-
versa). If (P) is a minimization problem, (D) is a maximization problem (and
vice-versa).
(d) The coefﬁcients of the objective function of (D) are the right-hand side coefﬁ-
cients of the functional constraints of (P) and the right-hand side coefﬁcients of
the functional constraints of (D) are the coefﬁcients of the objective function of
(P).
(e) If (P) is in its canonical form, also (D) is in a canonical form, but with the
constraints “reversed”, with respect to the constraints of the primal problem.
(f) If (P) is in its standard form, (D) is in a canonical form, but without sign
restrictions on the variables.
(g) If (P) is in a canonical form, but without sign restrictions on the variables, then
(D) is in a standard form.
For cases (f) and (g) we speak also of “asymmetric” primal and dual problems. We
can resume the above correspondences between primal and dual in the following

9.2 Duality for Linear Programming
291
scheme, where I, J, M and N are sets of indices.
PRIMAL
DUAL
min c⊤x

max c⊤x

max y⊤b

min y⊤b

Constraints : = bi, i ∈I;
Variables : yi, i ∈I, unrestricted;
≧bi, i ∈J;
yi ≧0, i ∈J;
Variables : x j ≧0, j ∈M;
Constraints : ≦c j, j ∈M;
x j, j ∈N, unrestricted;
= c j, j ∈N.
Let us verify property (b). We consider the primal problem in the form
(P) :
⎧
⎨
⎩
max c⊤x
Ax ≦b
x ≧0.
Its dual
(D) :
⎧
⎨
⎩
min y⊤b
y⊤A ≧c⊤
y ≧0
can be rewritten in the form
⎧
⎨
⎩
max(−y⊤b)
−y⊤A ≦−c⊤
y ≧0,
i.e.
⎧
⎨
⎩
max y⊤(−b)
y⊤(−A) ≦−c⊤
y ≧0.
If we dualize the last formulation we obtain
⎧
⎨
⎩
min(−c)⊤x
(−A)x ≧−b
x ≧0,
i.e.
⎧
⎨
⎩
max c⊤x
Ax ≦b
x ≧0,
which is just the primal problem we have considered at the beginning.
Let us verify property (f). We consider the following primal problem in its standard
form:

292
9
Linear Programming and Quadratic Programming
⎧
⎨
⎩
max c⊤x
Ax = b
x ≧0,
which we rewrite in the form
⎧
⎪⎪⎨
⎪⎪⎩
max c⊤x
Ax ≦b
Ax ≧b
x ≧0,
i.e.
⎧
⎪⎪⎨
⎪⎪⎩
max c⊤x
Ax ≦b
−Ax ≦−b
x ≧0,
,
i.e.
⎧
⎪⎪⎨
⎪⎪⎩
max c⊤x
 A
−A

x ≦
 b
−b

x ≧0.
Now we dualize the last formulation:
⎧
⎨
⎩
min((y1)⊤b −(y2)⊤b)
((y1)⊤A −(y2)⊤A) ≧c⊤
y1 ≧0, y2 ≧0.
If we put y = y1 −y2, we obtain
 min y⊤b
y⊤A ≧c⊤,
with y unrestricted in sign, as y = y1 −y2, with y1 ≧0 and y2 ≧0 (obviously the
difference may be a vector with components unrestricted in sign).
Example 9.16 By using the dualizing rules of a maximization problem in its canon-
ical form, deduce the dual of
(P) :
⎧
⎨
⎩
min c⊤x
Ax ≧b
x ≧0.
We transform the primal problem into a maximization problem:
⎧
⎨
⎩
max(−c⊤x)
(−A)x ≦−b
x ≧0.
Then we have:
(D) :
⎧
⎨
⎩
min y⊤(−b)
y⊤(−A) ≧−c⊤
y ≧0,

9.2 Duality for Linear Programming
293
i.e.
⎧
⎨
⎩
max y⊤b
y⊤A ≦c⊤
y ≧0.
If we have the following general L. P. primal problem
(P) :
⎧
⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩
max [min] (c1)⊤x1 + (c2)⊤x2 + (c3)⊤x3
A11x1 + A12x2 + A13x3 ≧b1
A21x1 + A22x2 + A23x3 = b2
A31x1 + A32x2 + A33x3 ≦b3
x1 ≧0, x2 unrestricted, x3 ≦0,
its dual is
(D) :
⎧
⎪⎪⎨
⎪⎪⎩
min [max] (b1)⊤y1 + (b2)⊤y2 + (b3)⊤y3
A⊤
11y1 + A⊤
21y2 + A⊤
31y3 ≧c1 
≦c1
A⊤
12y1 + A⊤
22y2 + A⊤
32y3 = c2
A⊤
13y1 + A⊤
23y2 + A⊤
33y3 ≦c3 
≧c3
.
The relations between the two problems, primal and dual, are strict and interesting,
not only from a formal point of view, and give rise to several results, useful also for
computational and interpretative aspects. First of all we make some considerations
on the Lagrangian functions of the primal and dual problems. We consider, e.g. the
primal problem
(P) :
⎧
⎨
⎩
max c⊤x
Ax ≦b
x ≧0
and its dual
(D) :
⎧
⎨
⎩
min y⊤b
y⊤A ≧c⊤
y ≧0.
We write the respective Lagrangian functions, denoted, respectively, by L and
M :
L (x, λ) = c⊤x −λ⊤(Ax −b) = c⊤x + λ⊤(b −Ax) = c⊤x + λ⊤b −λ⊤Ax;
M (y, μ) = y⊤b + (c⊤−y⊤A)μ = y⊤b + c⊤μ −y⊤Aμ.
Putting in L , λ = y and putting in M , μ = x, the two Lagrangian functions
become equal:
L (x, y) = c⊤x + y⊤b −y⊤Ax = M (y, x) = y⊤b + c⊤x −y⊤Ax.

294
9
Linear Programming and Quadratic Programming
This shows that the vector of the variables of a problem is the vector of the
multipliers of the other problem. We now write the Karush-Kuhn-Tucker conditions
for the two said problems. We recall that being the constraints linear afﬁne, the
problems are qualiﬁed. Moreover, being also the objective functions linear functions
(i.e. both convex and concave), the Karush-Kuhn-Tucker conditions are necessary
and sufﬁcient for the optimality of a feasible point that veriﬁes the said conditions.
Hence, ˆx is a solution of (P) if and only if there exists a vector ˆy such that
∇xL (·, ˆy) = c⊤−ˆy⊤A ≦0;
(c⊤−ˆy⊤A)ˆx = 0;
b −A ˆx ≧0;
ˆy⊤(b −A ˆx) = 0;
ˆx ≧0,
ˆy ≧0.
Similarly, ˆy is a solution of (D) if and only if there exists a vector ˆx such that
∇yM (ˆx, ·) = b −A ˆx ≧0;
ˆy⊤(b −A ˆx) = 0;
c⊤−ˆy⊤A ≦0;
(c⊤−ˆy⊤A)ˆx = 0;
ˆy ≧0,
ˆx ≧0.
The Karush-Kuhn-Tucker conditions are, therefore, the same for the two prob-
lems: if ˆx is a solution of (P), then there exists ˆy which satisﬁes the KKT conditions.
Vice-versa, if ˆy is a solution of (D), then there exists ˆx which satisﬁes the same con-
ditions.
Other relations between the primal problem (P) and its dual problem (D) are
put forward by various theorems and properties. We begin with two fundamental
“existence theorems” on the primal and dual. We follow [23]. We continue to consider
(P) as a maximization problem in its canonical form and (D) as its dual problem.
We denote by K the feasible set of (P), i.e.
K =

x ∈Rn : Ax ≦b, x ≧0
	
and by Y the feasible set of (D), i.e.
Y =

y ∈Rm : y⊤A ≧c⊤, y ≧0
	
.
Theorem 9.17 (First fundamental existence theorem) Assume that K ̸= ∅and Y ̸=
∅. Then:
(i) y⊤b ≧c⊤x, for any x ∈K, for any y ∈Y.
(ii) ˆy⊤b = c⊤ˆx for some ˆx ∈K, ˆy ∈Y.

9.2 Duality for Linear Programming
295
Proof (i) Since y ≧0 for y ∈Y, pre-multiplying Ax ≦b (being x ∈K) by y⊤∈Y,
yields y⊤Ax ≦y⊤b. Similarly, as x ≧0 for x ∈K, we have y⊤Ax ≧c⊤x for all
y ∈Y. Whence
y⊤b ≧y⊤Ax ≧c⊤x, ∀x ∈K, ∀y ∈Y.
(ii) A method to prove (ii) is to use Farkas’ theorem of the alternative (see
Theorem 2.28). In view of (i), it sufﬁces to see that ˆy⊤b ≦c⊤ˆx for some ˆx ∈K
and ˆy ∈Y. Thus we have only to show the existence of a solution, consisting of an
m-dimensional vector y and an n-dimensional vector x, of the system
⎛
⎝
0
A
−A⊤
0
b⊤
−c⊤
⎞
⎠

 y
x

≦
⎛
⎝
b
−c⊤
0
⎞
⎠
(9.9)
y ≧0, x ≧0.
(9.10)
This system can be converted, by introducing an (m + n + 1)-dimensional slack
vector w, to the system of equations
⎛
⎝
0
A
−A⊤
0
I
b⊤
−c⊤
⎞
⎠
⎛
⎝
y
x
w
⎞
⎠=
⎛
⎝
b
−c
0
⎞
⎠,
(9.11)
y ≧0, x ≧0, w ≧0,
(9.12)
where I is the identity matrix of order (m + n + 1).
Then, in the light of Farkas’ theorem, the system of equations (9.11)–(9.12) has
a solution if
(p⊤, q⊤, θ)
⎛
⎝
b
−c
0
⎞
⎠≧0
(9.13)
for any solution (p⊤, q⊤, θ) of
(p⊤, q⊤, θ)
⎛
⎝
0
A
−A⊤
0
I
b⊤
−c⊤
⎞
⎠≧0,
(9.14)
where the dimension of the vectors p⊤, q⊤, θ are m, n, 1, respectively.
Let us see that this sufﬁcient condition is fulﬁlled in effect whenever K ̸= ∅,
Y ̸= ∅. To this end, it is convenient to decompose (9.14) into the equivalent relations
p⊤A ≧θc⊤; Aq ≦θb
(9.15)
p ≧0, q ≧0, θ ≧0.
(9.16)

296
9
Linear Programming and Quadratic Programming
We divide the subsequent discussion into cases (a) and (b), depending on the
positivity of θ.
(a) Case θ > 0. Dividing (9.15), (9.16) by θ > 0, we obtain (p⊤/θ)A ≧c⊤,
(p/θ) ≧0, A(q/θ) ≦b, (q/θ) ≧0, so that p/θ ∈Y, (q/θ) ∈K. Whence by
part (i), b⊤(p/θ) ≧c⊤(q/θ), which, multiplied by θ > 0, implies (9.13).
(b) Case θ = 0. Equations (9.15) and (9.16) become p⊤A ≧0, p ≧0, Aq ≦0,
q ≧0. Choose some arbitrary x from K and y from Y. Then p⊤b ≧p⊤(Ax) =
(p⊤A)x ≧0, c⊤q ≦(y⊤A)q = y⊤(Aq) ≦0. Hence b⊤p −c⊤q + 0 · θ ≧0,
which implies (9.13).
Therefore, (9.14) implies (9.13) in both cases (a) and (b), so that the system of
equations (9.11)–(9.12) has a solution, or equivalently, the system of inequalities
(9.9)–(9.10) has a solution. This completes the proof.
□
The duality situation established above can be expressed in a slightly different
way in the following second fundamental “existence theorem”. We continue to make
reference to the maximization problem (P) in its canonical form and to its related
dual problem (D), with K and Y feasible sets of, respectively, (P) and (D).
Theorem 9.18 (Second fundamental existence theorem)
(i) If K ̸= ∅, then (P) admits a solution if and only if Y ̸= ∅.
(ii) If Y ̸= ∅, then (D) admits a solution if and only if K ̸= ∅.
Proof If Y ̸= ∅, then the assumptions of Theorem 6 are met, so that the common
value of ˆy⊤b and c⊤ˆx in Theorem 9.17(ii) is a ﬁnite maximum (i.e. a solution) of
(P), as well as a ﬁnite minimum (i.e. a solution) of (D).
Conversely, let us prove that if Y = ∅, the function c⊤x is unbounded from above
on the set K, or, more symbolically, supx∈K c⊤x = +∞. If we use a slack vector u
of dimension n, we ﬁnd that the emptiness of Y is equivalent to the non-existence of
a nonnegative solution (u⊤, v⊤) of
(u⊤, v⊤)

 −I
A

= c⊤,
where I is the identity matrix of order n. By FarkasâŁ™theorem (see Theorem 2.28)
there is some n-dimensional vector ˆq such that

−I
A

ˆq ≧0, c⊤ˆq < 0.
If the substitution ˆy = −ˆq is done, these results become A ˆy ≦0, c⊤ˆy > 0, ˆy ≧0.
Choose now an arbitrary x from K; then x(ρ) = x + ρ ˆy ∈K for all ρ > 0 and
c⊤x(ρ) = c⊤x + ρc⊤ˆy →+∞, as ρ →+∞, as was to be shown. The proof of
(ii) is exactly similar.
□

9.2 Duality for Linear Programming
297
Remark 9.19 The result (i) of Theorem 9.17 is also known as the weak duality
theorem for L. P., whereas the result (ii) of Theorem 9.17, together with Theorem
9.18, i.e. if ˆx is feasible for (P) and ˆy is feasible for (D), then the equality c⊤ˆx = ˆy⊤b
is a necessary and sufﬁcient condition for ˆx to be a solution of (P) and ˆy to be a
solution of (D), is also known as the strong duality theorem for L. P.
We can summarize what previously said as follows (K and Y are, as usual, the
feasible sets of, respectively, the primal problem (P) and its associated dual (D)).
1. {K ̸= ∅, Y ̸= ∅} ⇔There exists a solution of (P) and (D).
2. K = ∅⇒It holds Y = ∅or it holds Y ̸= ∅, but in this case the objective function
of (D) is unbounded over Y.
3. Y = ∅⇒It holds K = ∅or it holds K ̸= ∅, but in this case the objective function
of (P) is unbounded over K.
Example 9.20 Consider the problem
⎧
⎪⎪⎨
⎪⎪⎩
max(4x1 + x2)
x1 −3x2 ≦30
−x1 + x2 ≦10
x1 ≧0, x2 ≧0.
It is seen without difﬁculty that the objective function is unbounded on the feasible
set K. Hence the problem admits no solution. Its dual is
⎧
⎪⎪⎨
⎪⎪⎩
min(30y1 + 10y2)
y1 −y2 ≧4
−3y1 + y2 ≧1
y1 ≧0, y2 ≧0.
Its feasible set, by Theorem 9.18(i), is empty: Y = ∅.
We have other theorems which relate the primal problem (P) to its dual problem
(D). Again we assume that (P) is of the form
(P) :
⎧
⎨
⎩
max c⊤x
Ax ≦b
x ≧0,
with dual
(D) :
⎧
⎨
⎩
min y⊤b
y⊤A ≧c⊤
y ≧0.
Theorem 9.21 (Equilibrium theorem or complementary slackness theorem) Let ˆx ∈
K and ˆy ∈Y. Then, ˆx and ˆy are solutions, respectively, of (P) and (D) if and only
if the following complementary slackness conditions hold:

298
9
Linear Programming and Quadratic Programming
(c⊤−ˆy⊤A)ˆx = 0;
ˆy⊤(b −A ˆx) = 0.
Proof The two above conditions are necessary, as they are part of the Karush-Kuhn-
Tucker conditions for (P) and (D). As for what concerns the sufﬁciency, we note
that if ˆx and ˆy satisfy the said slackness complementary conditions, we have
c⊤ˆx −ˆy⊤A ˆx = 0 = ˆy⊤b −ˆy⊤A ˆx.
Therefore, we have c⊤ˆx = ˆy⊤b and so it holds (strong duality) that ˆx solves (P)
and ˆy solves (D).
□
Remark 9.22 The complementary slackness conditions of Theorem 9.21 can be
rewritten in the form (Ai is the i-th row of A, whereas A j is the j-th column of A):
(a)
ˆyi > 0 ⇒Ai ˆx = bi;
(b)
Ai ˆx < bi ⇒ˆyi = 0;
(c)
ˆx j > 0 ⇒ˆy⊤A j = c j;
(d)
ˆy⊤A j > c j ⇒x j = 0.
It is possible to give economic interpretations of these implications; see, e.g. [23].
The following result, due originally to Goldman and Tucker (see [24]), puts into
relation the primal and dual problems with the saddle point of the related Lagrangian
function.Fortheusualmaximizationproblem(P),theLagrangianfunctionisdeﬁned
as
L (x, y) = c⊤x + y⊤(b −Ax) = y⊤b + (c⊤−y⊤A)x,
x ≧0, y ≧0.
For the said maximization problem (P) a pair (ˆx, ˆy) ∈Rn
+ × Rm
+ is a saddle point
of L (x, y) if
L (x, ˆy) ≦L (ˆx, ˆy) ≦L (ˆx, y), ∀x ∈Rn
+, ∀y ∈Rm
+.
(9.17)
We recall that no constraint qualiﬁcation is needed (for the necessary conditions),
as the constraints are linear afﬁne functions.
Theorem 9.23 (Saddle point and duality) The primal problem (P) admits a solution
ˆx and the dual problem (D) admits a solution ˆy if and only if the pair (ˆx, ˆy) is a saddle
point for the Lagrangian function L (x, y), i.e. if and only if (9.17) is satisﬁed.
Proof (i) Necessity. If (ˆx, ˆy) is a pair of optimal solutions of, respectively, (P) and
(D), we have
c⊤ˆx = ˆy⊤b,
ˆx ≧0,
ˆy ≧0,
b −A ˆx ≧0, c⊤−ˆy⊤A ≦0,

9.2 Duality for Linear Programming
299
ˆy⊤(b −A ˆx) = (c⊤−ˆy⊤A)ˆx = 0.
Whence
L (ˆx, ˆy) = ˆy⊤b + (c⊤−ˆy⊤A)ˆx ≧ˆy⊤b + (c⊤−ˆy⊤A)x = L (x, ˆy), ∀x ∈Rn
+;
L (ˆx, ˆy) = c⊤ˆx + ˆy⊤(b −A ˆx) ≦c⊤ˆx + y⊤(b −A ˆx) = L (ˆx, y), ∀y ∈Rm
+,
proving the necessity.
(ii) Sufﬁciency. If (ˆx, ˆy) is a saddle point of the Lagrangian function, (9.17)
entails
y⊤(b −A ˆx) ≧0, ∀y ∈Rm
+,
(c⊤−ˆy⊤A)x ≦0, ∀x ∈Rn
+,
giving rise to
A ˆx ≦b, ˆx ≧0, ˆy⊤A ≧c⊤,
ˆy ≧0.
Hence ˆx ∈K, ˆy ∈Y. On the other hand, (9.17) for x = 0, y = 0 implies
ˆy⊤b = L (0, ˆy) ≦L (ˆx, ˆy) ≦L (ˆx, 0) = c⊤ˆx,
which proves the optimality of ˆx, ˆy. Therefore, ˆx solves (P) and ˆy solves (D).
□
On the grounds of what previously expounded we can assert that the following
propositions are equivalent:
1. The Lagrangian function L (x, y) = c⊤x + y⊤(b −Ax) has a saddle point
(ˆx, ˆy) over Rn
+ × Rm
+.
2. The primal problem has an optimal solution ˆx.
3. The dual problem has an optimal solution ˆy.
4. Both the primal and the dual have a nonempty feasible set.
5. ˆx is feasible for the primal and ˆy is feasible for the dual and c⊤ˆx = b⊤ˆy.
Finally, we give some insights on sensitivity for L. P. problems. The literature on
sensitivity, stability and in general postoptimal analysis for L. P. problems is quite
abundant (see, e.g. [25–27] and the works on L. P. quoted in the References of the
present book). We remark once more that the vector of the solutions of the dual
problem ˆy, is nothing but the vector of the multipliers of the Lagrangian function
L (·, ·). Let us consider, as before, the primal problem
(P) :
⎧
⎨
⎩
max c⊤x
Ax ≦b
x ≧0,
and its dual problem

300
9
Linear Programming and Quadratic Programming
(D) :
⎧
⎨
⎩
min y⊤b
y⊤A ≧c⊤
y ≧0.
Let us consider the optimal value function v(b) of the primal problem, as a function
of the right-hand side vector b (while A is kept constant).
We write K(b) to put into evidence the dependence of the feasible set of (P) from
b. Let us denote
B =

b ∈Rm : K(b) ̸= ∅
	
.
Theorem 9.24 The optimal value function v(b) is concave on B.
Proof Let ˆx1 and ˆx2 be two solutions of (P) corresponding, respectively, to b1, b2 ∈
B, with c ﬁxed. Then it can be easily veriﬁed that λ1 ˆx1 + λ2 ˆx2 ∈K(λ1b1 + λ2b2)
for any λ1 ≧0, λ2 ≧0, λ1 + λ2 = 1. Hence
v(λ1b1 + λ2b2) ≧λ1c⊤ˆx1 + λ2c⊤ˆx2 = λ1v(b1) + λ2v(b2),
proving the desired concavity.
□
Corrolary 9.25 The optimal value function v(b) is continuous on int(B). It is pos-
sible to prove that v(b) is continuous on B.
Corrolary 9.26 The optimal value function v(b) has right-hand side and left-hand
side partial derivatives on int(B).
Theorem 9.27 If ˆyi, i = 1, . . . , m, is the i-th component of any optimal solution ˆy
of (D), then we have, with b ∈int(B),
∂v
∂b−
i
≧ˆyi ≧∂v
∂b+
i
, i = 1, . . . , m.
Furthermore, if the dual problem (D) has a unique solution ˆy, then the optimal
value function v(b) is differentiable at the corresponding point b and it holds
∇v(b) = ˆy.
The economic interpretation of the last result is the same as the one given in Chap.
7: in economic analysis the dual solutions ˆyi are called “shadow prices” or “marginal
costs” relative to the resource bi.
If (D) does not admit a unique solution, things are more complicate. However,
it is possible to prove that if the set of dual solutions is compact, then the left-hand
sided and the right-hand sided partial derivatives of the optimal value function v(b)
are computable in the way expressed by the following result.
Theorem 9.28 Let the set U(b) of the optimal solutions of the dual problem (D) be
nonempty and compact. Then it holds

9.3 Quadratic Programming
301
∂v
∂b+
i
= min
ˆy∈U(b) ˆyi;
∂v
∂b−
i
= max
ˆy∈U(b) ˆyi,
where ˆyi denotes the i-th component of ˆy.
For a discussion on uniqueness of the solutions in an L. P. problem see, e.g. [28].
9.3
Quadratic Programming
In the present section we give some insights on an important type of nonlinear
programming problems: the quadratic programming problems. All such problems
have a quadratic objective function and linear afﬁne constraints. A quadratic function
is one of the form
ϕ(x) = 1
2 x⊤Cx + c⊤x + α
(the presence of the factor 1
2 is useful when the gradient and Hessian of ϕ(x) are
computed), where usually C is a symmetric matrix of order n, and x, c ∈Rn, α ∈R.
Usually the scalar α is omitted, as it does not affect the location of an optimal solution.
Therefore, in the sequel we shall consider a quadratic function in the form
ϕ(x) = 1
2 x⊤Cx + c⊤x.
(9.18)
The subject of Quadratic Programming has been considered in several books and
papers, e.g. [29–34]. Quadratic programming has, similarly to L. P., many applica-
tions; one of the most important applications is the so-called “Portfolio Selection
Problem”, introduced by [35, 36]. Markowitz was, for the said contribution, one
of the recipients of the 1990 Nobel Prize in Economic Science. Another possible
application of quadratic optimization is the following one: consider the problem of
approximately solving an over-determined linear system Ax = b, where A has more
rows than columns. We might want to solve the problem
min
x∈Rn ∥Ax −b∥.
Now note that ∥Ax −b∥2 = x⊤A⊤Ax −2b⊤Ax + b⊤b, and so this problem is
equivalent to
min
x∈Rn

x⊤A⊤Ax −2b⊤Ax + b⊤b
	
which is in the format of a quadratic programming problem.
The assumption that C is symmetric is not restrictive, as it holds.

302
9
Linear Programming and Quadratic Programming
x⊤Cx = 1
2 x⊤(C + C⊤)x
for any x ∈Rn and so we can replace the non-symmetric matrix C by the symmetric
matrix ¯C = 1
2(C + C⊤). The matrix (C + C⊤) is called the “symmetric part” of C;
therefore, in this section we assume, without loss of generality that in (9.18) C is
symmetric. Note that
∇ϕ(x) = Cx + c
and
∇2ϕ(x) = C.
Note that if in (9.18) we have c = 0 ∈Rn, then ϕ(x) becomes a quadratic form:
ϕ(x) ≡Q(x) = x⊤Cx.
(9.19)
We recall (see also Chap. 1) that a quadratic form (9.19) and its associated sym-
metric matrix C are positive semideﬁnite if
x⊤Cx ≧0, ∀x ∈Rn.
If, in addition,
x⊤Cx > 0, ∀x ∈Rn, x ̸= 0,
then the quadratic form (9.19) and the matrix C are positive deﬁnite.
In [37] it is proved the following result.
Theorem 9.29 The symmetric matrix C of order n is positive semideﬁnite if and
only if
v ∈Rn, v⊤Cv ≦0 ⇒Cv = 0.
Proof (a) We have
v⊤Cv ≦0 ⇒v⊤Cv = 0,
so that v⊤Cv < 0 cannot occur, and, therefore, v⊤Cv ≧0, ∀v ∈Rn.
(b) Assuming v⊤Cv ≧0 to hold for all v ∈Rn, we have to prove that ¯v⊤C ¯v = 0
implies C ¯v = 0. For every w ∈Rn, γ ∈R, we have
0 ≦(w + γ ¯v)⊤C(w + γ ¯v) = w⊤Cw + 2γ w⊤C ¯v + γ 2¯v⊤C ¯v =
= w⊤Cw + 2γ w⊤C ¯v.
The relation 0 ≦w⊤Cw + 2γ w⊤C ¯v cannot hold for all γ ∈R but if w⊤C ¯v = 0,
and this holds for all w ∈Rn only if C ¯v = 0.
□

9.3 Quadratic Programming
303
We remark furthermore that:
• The positive semideﬁnite matrix C is positive deﬁnite if and only if it is non-
singular. In this case the inverse C−1 is symmetric and is also positive deﬁnite.
• We have proved, in Chap. 3, that the quadratic form (9.19) is a convex (resp. a
strictly convex) function if and only if C is positive semideﬁnite (resp. positive
deﬁnite). These properties hold also for a quadratic function (9.18), as convexity
(resp. strict convexity) of ϕ(x) depends only from matrix C, being the addendum
c⊤x linear.
• The last result (last lines of the previous point) has been reﬁned by [37] who proved
that the quadratic function
ϕ(x)=1
2 x⊤Cx + c⊤x
is convex in any convex set X ⊂Rn, with a nonempty interior (e.g. Rn
+) if and
only if C is positive semideﬁnite.
The following results are immediate.
Theorem 9.30 Suppose that C is a positive semideﬁnite matrix; then the quadratic
function ϕ(x) = 1
2 x⊤Cx + c⊤x attains its (global) minimum at x∗if and only if x∗
solves the system
∇ϕ(x) = Cx + c = 0.
If C is positive deﬁnite, then the unique global minimum of ϕ(x) is given by
x∗= −C−1c.
Another, less trivial, result on the existence of optimal points for quadratic func-
tions, is given in the following theorem.
Theorem 9.31 If a quadratic function (9.18) is bounded from below (from above)
on a nonempty polyhedron, it assumes its minimum (maximum) there.
A full proof of the previous result is given, e.g. in [38].
We can describe various types of quadratic programming problems, e.g. the
following ones.
(QP1) :
min
1
2 x⊤Cx + c⊤x : Ax ≧b, x ≧0

.
(QP2) :
min
1
2 x⊤Cx + c⊤x : Ax = b, x ≧0

.
(QP3) :
min
1
2 x⊤Cx + c⊤x : Ax ≧b

.

304
9
Linear Programming and Quadratic Programming
(QP4) :
min
1
2 x⊤Cx + c⊤x : Ax = b

.
We note that the Lagrangian function for the above problems is
L (x, u) = 1
2 x⊤Cx + c⊤x + u⊤(b −Ax),
i.e.
L (x, u) = 1
2 x⊤Cx + c⊤x −u⊤(Ax −b).
It is easy, on the grounds of what expounded in the previous chapters, to write the
Karush-Kuhn-Tucker conditions for the various quadratic programming problems
described above (we recall that, being the constraints linear afﬁne, the problems are
automatically qualiﬁed).
• We begin with (QP1). The related Karush-Kuhn-Tucker and feasibility conditions
are (see (b1) in Table 5.1, p. 151):
x ≧0; c + Cx −A⊤u ≧0;
x⊤(c + Cx −A⊤u) = 0;
u ≧0;
−b + Ax ≧0; u⊤(−b + Ax) = 0.
Putting v ≡c + Cx −A⊤u and y ≡Ax −b, we obtain
⎧
⎨
⎩
Ax −y = b
Cx −A⊤u −v = −c
x ≧0, u ≧0, y ≧0, v ≧0
(9.20)
x⊤v = 0; u⊤y = 0.
(9.21)
The conditions (9.20) form a system of (m + n) equations with 2m + 2n unknowns.
The vector y has the meaning of some slack vector in the initial problem while v
may be interpreted as a slack vector in a dual problem. Conditions (9.21), that may
be rewritten as
x jv j = 0, 1 ≦j ≦n;
ui yi = 0, 1 ≦i ≦m,
show that we are interested only in those solutions of the system (9.20) which have
no more than (m + n) nonzero components.
Let us consider again the Eqs. (9.20) and (9.21)

9.3 Quadratic Programming
305
Ax −y = b
−Cx + A⊤u + v = c
x⊤v = 0; u⊤y = 0
x ≧0, u ≧0, y ≧0, v ≧0.
Now letting
M =

0
A
−A⊤C

; q =
 −b
c

; w =
 y
v

; z =
 u
x

,
we can rewrite the Karush-Kuhn-Tucker conditions above as a linear complemen-
tarity problem
w −Mz = q; w⊤z = 0; (w, z) ≧0.
Linear complementarity problems are an important subject within mathematical
programming (and also with reference to other types of problems), with both theoretic
and algorithmic consequences. See, e.g. [39, 40]).
We write the Karush-Kuhn-Tucker and the feasibility conditions for the other
types of quadratic programming problems previously considered.
• For (QP2) we have
Ax = b
Cx −v + A⊤u = −c
x ≧0, v ≧0
x⊤v = 0.
• For (QP3) we have
Ax + y = b
Cx −A⊤u = −c
y ≧0, u ≧0
u⊤y = 0.
• For (QP4) we have
Cx + A⊤u = −c
Ax = b.

306
9
Linear Programming and Quadratic Programming
For what concerns the sufﬁcient optimality conditions, we can assert that if x∗
satisﬁes the feasibility conditions, the Karush-Kuhn-Tucker conditions for (QPi),
i = 1, 2, 3, 4, and the matrix C is positive semideﬁnite, i.e. ϕ(x) is a convex function,
then x∗is a solution of problem (QPi), i = 1, 2, 3, 4, by Remark 6.7(a). Obviously,
we could require that C is positive semideﬁnite only on the corresponding feasi-
ble set, but in this case the problem becomes more complicate. If we require, in
(QP1) and (QP2), that C is positive semideﬁnite on Rn
+, we gain nothing: recall that
a quadratic function ϕ(x) = 1
2 x⊤Cx + c⊤x is convex on any convex set X ⊂Rn,
with a nonempty interior, if and only if C is positive semideﬁnite. Let us suppose
that in (QP2) the matrix A, of order (m, n), has full rank: rk(A) = m. In [41] it is
remarked that if ϕ(x) is convex on the feasible set S =

x ∈Rn : Ax = b, x ≧0
	
,
then it is convex on the larger set {x : Ax = b} and the same author shows that this
is so if and only if the quadratic form Q(x) = x⊤Cx is positive semideﬁnite when
constrained by the homogeneous linear system Ax = 0. So, we have to solve the
problem
Ax = 0 ⇒x⊤Cx ≧0,
for which the criteria on constrained quadratic forms are applicable. See Chap. 1,
[30, 31].
Again: if in (QP4) the matrix A is of rank m and the matrix C is positive deﬁnite,
i.e. ϕ(x) = 1
2 x⊤Cx + c⊤x is a strictly convex function and hence the feasible point
x∗which veriﬁes the Karush-Kuhn-Tucker conditions, is the unique solution of the
problem, we can obtain an explicit formula for the solution and for the multipliers
vector. We rewrite for (QP4) the feasibility conditions and the Karush-Kuhn-Tucker
conditions:
Ax∗= b
Cx∗+ c + A⊤u = 0
Being C non-singular, we can write these conditions as follows
Ax∗= b; x∗+ C−1c + C−1 A⊤u = 0
(9.22)
or also, multiplying by A, as
Ax∗= b; AC−1 A⊤u + AC−1c + b = 0.
(9.23)
The matrix AC−1 A⊤, of order m, is symmetric and positive deﬁnite; indeed
y⊤AC−1 A⊤y = (A⊤y)⊤C−1 A⊤y ≧0, ∀y ∈Rm.
We have
y⊤AC−1A⊤y = (A⊤y)⊤C−1 A⊤y = 0

9.3 Quadratic Programming
307
if and only if A⊤y = 0, i.e. if and only if y = 0 (A⊤is injective, being of rank m;
C−1 is symmetric and positive deﬁnite). Therefore, from (9.23) and (9.22) we obtain
u = −B(AC−1c + b);
x∗= C−1A⊤B(AC−1c + b) −C−1c;
where we have put B ≡(AC−1 A⊤)−1.
Instead of convexity of ϕ(x), i.e. of the quadratic form Q(x), we can assume
pseudoconvexity of ϕ(x), in order to obtain that the feasible point x∗satisfying the
Karush-Kuhn-Tucker conditions for the various quadratic programming problems is
a (global) solution of the related problem by Theorem 6.6. We shall give, at the end
of the present section, some insights on the generalized convexity of quadratic forms
and quadratic functions. Finally, we remark that those quadratic forms Q(x) = x⊤Cx
which are positive semideﬁnite on Rn
+, are called copositive (the same name is used
for the symmetric matrix C). Checking copositivity is, however, not a trivial task
(see, e. g., [39]).
We now consider the Wolfe dual problem of a quadratic programming problem.
Duality for quadratic programming problems was ﬁrst studied in [42]. For simplicity
we develop our analysis for the primal problem (QP3):
(QP3) :
min
x
1
2 x⊤Cx + c⊤x : Ax ≧b

,
where c ∈Rn, b ∈Rm, C is a symmetric matrix of order m and A is a matrix of
order (m, n), m ≦n.
The Wolfe dual of (QP3) can be written in the form
(DQP3) :
max
(x,u)

g(x, u) ≡b⊤u −1
2 x⊤Cx : A⊤u −Cx = c, u ≧0

.
Indeed, the Lagrangian function of (QP3) is
L (x, u) = c⊤x + 1
2 x⊤Cx + u⊤(b −Ax)
= b⊤u −1
2 x⊤Cx + x⊤(c + Cx −A⊤u).
Hence
∇xL (x, u) = c⊤+ 1
2Cx + 1
2 x⊤C −u⊤A = c + Cx −A⊤u = 0.
Substituting this constraint in the objective function of the dual problem we obtain
the familiar form of (DQP3) given in [42]:

308
9
Linear Programming and Quadratic Programming
max
(x,u)

c⊤x + 1
2 x⊤Cx + u⊤(b −Ax) : c + Cx −A⊤u = 0, u ≧0

= max
(x,u)

c⊤x + 1
2 x⊤Cx + b⊤u −u⊤Ax : c = A⊤u −Cx, u ≧0

= max
(x,u)

u⊤Ax −x⊤Cx + 1
2 x⊤Cx + b⊤u −u⊤Ax : A⊤u −Cx = c, u ≧0

= max
(x,u)

(b⊤u −1
2 x⊤Cx) ≡g(x, u) : A⊤u −Cx = c, u ≧0

(in the second equality we have substituted c⊤by u⊤A −x⊤C).
If C is non-singular, (DQP3) reduces to
(DQP3) :
max
u

d⊤u −1
2u⊤Du : u ≧0

,
with D ≡AC−1A⊤; d ≡b + AC−1c ≡b −A ˜x, with ˜x = −C−1c.
Indeed, in this case the unique solution of
c + Cx −A⊤u = 0
is given by
x = C−1 
A⊤u −c

.
Substituting in the dual problem this last relation, we have the above given for-
mulation.
Let us denote by K and by Y the feasible sets of, respectively, (QP3) and (DQP3).
We have the following basic duality results for (QP3).
Theorem 9.32 Assume that C is positive semideﬁnite (i.e. the quadratic function
ϕ(x) = 1
2 x⊤Cx + c⊤x is a convex function on Rn). Then:
(i) (Weak duality theorem):
∀x1 ∈K, ∀(x2, u2) ∈Y : ϕ(x1) ≧g(x2, u2).
(ii) (Dorn’s duality theorem). If (QP3) has a solution x∗, then there exists some
u∗∈Rm
+ such that (x∗, u∗) solves (DQP3) and the two extrema are equal.
(iii) (Dorn’s converse duality theorem). If (DQP3) admits a solution (x∗, u∗), then
there exists some x0 (not necessarily equal to x∗), satisfying Cx0 = Cx∗, that
solves (QP3) and the two extrema are equal. If C is positive deﬁnite, then x∗
is the unique solution of (QP3).
(iv) If both problems (QP3) and (DQP3) have a nonempty feasible set, then both
problems admit a solution.

9.3 Quadratic Programming
309
(v) If one of the two problems, (QP3) or (DQP3), has a nonempty feasible set, but
the other one has an empty feasible set, then the ﬁrst problem has an inﬁnite
extremal value.
Proof Properties (i) and (ii) are direct consequences of the results of Wolfe for
duality in differentiable nonlinear programming problems (see Theorems 8.27 and
8.28). Now we prove (iii). Being (x∗, u∗) solution of (DQP3), there exists (see
Remark 6.5(a)) v∗∈Rn such that, with
L (u, x, v) ≡−b⊤u + 1
2 x⊤Cx + v⊤(A⊤u −Cx −c),
it holds
∇xL (u∗, x∗, v∗) = Cx∗−Cv∗= 0;
(9.24)
∇uL (u∗, x∗, v∗) = Av∗−b ≧0;
(9.25)
(u∗)⊤(Av∗−b) = 0.
(9.26)
By (9.25), it follows that v∗is feasible for (QP3). As (x∗, u∗) is feasible for
(DQP3), we have A⊤u∗−Cx∗= c, hence c⊤= (u∗)⊤A −(x∗)⊤C. Substituting
in ϕ, it results ϕ(v∗) = 1
2(v∗)⊤Cv∗+ c⊤v∗= 1
2(v∗)⊤Cv∗+ (u∗)⊤Av∗−(x∗)⊤Cv∗.
From (9.26), (u∗)⊤Av∗= (u∗)⊤b, and from (9.24), (x∗)⊤c = (v∗)⊤C, in conse-
quence
ϕ(v∗) = 1
2(v∗)⊤Cv∗+ (u∗)⊤Cv∗= b⊤u∗−1
2(v∗)⊤Cv∗= g(v∗, u∗).
Therefore, by (i) we have that v∗is a solution of (QP3) and satisﬁes relation (9.24).
Now we prove (iv). This property results from (i) and from the fact that a quadratic
function, bounded from below (resp., from above) on a nonempty convex polyhedron,
reaches in the said polyhedron its minimum (resp., maximum) value (Theorem 9.31).
Now we prove (v). We have (Theorem 8.34) that if K = ∅, Y ̸= ∅, then
sup
(x,u)∈Y
g(x, u) = +∞. Conversely, let K ̸= ∅, Y = ∅. Being Y = ∅, by a theorem
of the alternative for linear systems and precisely the statements (see Sect. 2.2, point
6)
S ≡(Ax + By = b, x ≧0);
S∗≡(A⊤u ≧0, B⊤u = 0, b⊤u < 0),
there exists v ∈Rn such that
Av ≧0, Cv = 0, c⊤v < 0.
(9.27)

310
9
Linear Programming and Quadratic Programming
If x0 ∈K, then Ax0 ≧b and so, ∀λ ≧0 it holds A(x0 + λv) ≧b, i.e. ∀λ ≧0
we have x0 + λv ∈K and using (9.27), ϕ(x0 + λv) = ϕ(x0) + λc⊤v →−∞for
λ →+∞.
□
Remark 9.33 The dual pairs of quadratic programming problems considered above
possess a nice feature not shared by the Wolfe pairs of primal and dual problems: if
C is positive semideﬁnite, then the objective function of the primal is convex on Rn
and the objective function of the dual is concave on Rn × Rm.
For the reader’s convenience, we write the Dorn’s duality formulation also for the
other quadratic programming problems considered in the present section.
(QP1) :
min
x
1
2 x⊤Cx + c⊤x : Ax ≧b, x ≧0

,
(DQP1) :
max
(x,u)

b⊤u −1
2 x⊤Cx : A⊤u −Cx ≦c, u ≧0

.
(QP2) :
min
x
1
2 x⊤Cx + c⊤x : Ax = b, x ≧0

,
(DQP2) :
max
(x,u)

b⊤u −1
2 x⊤Cx : A⊤u −Cx ≦c

.
(QP4) :
min
x
1
2 x⊤Cx + c⊤x : Ax = b

,
(DQP4) :
max
(x,u)

b⊤u −1
2 x⊤Cx : A⊤u −Cx = c

.
We point out that Cottle [43] has proposed the following pair of primal and dual
quadratic programming problems, which result to be symmetric, i.e. for this pair it
holds the involution property.
(Cottle P) :
min
(x,y)

c⊤x + 1
2 x⊤Cx + 1
2 y⊤By : Ax + By ≧b, x ≧0, y ≧0

≡
min
(x,y)∈Z1 f (x, y);
(Cottle DP) : max
(y,x)

b⊤y −1
2 y⊤By −1
2 x⊤Cx : A⊤y −Cx ≦c, y ≧0, x ≧0

≡max
(x,y)∈Z2g(x, y),

9.3 Quadratic Programming
311
with c ∈Rn, b ∈Rm, A of order (m, n), B a symmetric matrix of order n.
If we write (Cottle DP) in the form
−min
(y,x)

−b⊤y + 1
2 y⊤By + 1
2 x⊤Cx : −A⊤y + Cx ≧−c, y ≧0, x ≧0

,
we note that the dual of (Cottle DP) is just (Cottle P) and hence the involution
property holds.
Theorem 9.34 (Cottle) Let the matrices C and B be positive semideﬁnite. Then the
following properties hold:
(i)
f (x1, y1) ≧g(x2, y2), ∀(x1, y1) ∈Z1, ∀(x2, y2) ∈Z2.
(ii) If one of the two problems (Cottle P) or (Cottle DP) has a solution, then there
exists a common solution for (Cottle P) and (Cottle DP) such that the two
optimal values are equal. More precisely:
(a) If (Cottle P) admits a solution (x∗, y∗), then there exists y0 ∈Rm
+, with
By0 = By∗, such that (x∗, y0) is a solution of both (Cottle P) and (Cottle
DP).
(b) If (Cottle DP) admits a solution (x∗, y∗), then there exists x0 ∈Rn
+, with
Cx0 = Cx∗, such that (x0, y∗) is a solution of both (Cottle DP) and (Cottle
P).
(iii) If both problems have a nonempty feasible set, then both problems admit a
solution.
(iv) If one of the two problems has a nonempty feasible set, but the other one has
an empty feasible set, then the ﬁrst of the two problems has an unbounded
objective function.
Finally, we give some insights on generalized convexity of quadratic forms and
quadratic functions. These topics have been extensively studied by various authors:
see, e.g. [32–34, 37, 44–46].
We have seen that a quadratic form
Q(x) = x⊤Cx,
with C symmetric matrix of order n, is convex on Rn (resp. strictly convex) if and
only if C is positive semideﬁnite (resp. positive deﬁnite) and that a quadratic function
ϕ(x) = 1
2 x⊤Cx + c⊤x
is convex on any convex set X ⊂Rn, with a nonempty interior, if and only if C is
positive semideﬁnite [37]. Since the sum of quasiconvex functions is not necessarily
quasiconvex, the quasiconvexity of the quadratic function ϕ(x) does not follow from
the quasiconvexity of the quadratic form x⊤Cx, as it is the case for convexity.

312
9
Linear Programming and Quadratic Programming
We recall that a quadratic function ϕ(x) = 1
2 x⊤Cx + c⊤x (where C is a real
symmetric matrix, of order n, and c ∈Rn) is quasiconvex on the open convex set
X ⊂Rn (see Theorem 3.20(b)) if and only if, for all x, y ∈X:
1
2 y⊤Cy + c⊤y ≦1
2 x⊤Cx + c⊤x ⇒(c + Cx)⊤(y −x) ≦0.
The quadratic function ϕ(x) is pseudoconvex on the open convex set X ⊂Rn (see
Deﬁnition 3.21) if and only if, for all x, y ∈X :
(c + Cx)⊤(y −x) ≧0 ⇒1
2 y⊤Cy + c⊤y ≧1
2 x⊤Cx + c⊤x.
It is obvious that the convexity of a quadratic function depends only, as said before,
on the matrix C, while the pseudoconvexity and quasiconvexity may depend also on
the coefﬁcient vector c of the linear part. However, with reference to the whole space
Rn, we have the following basic result on the quasiconvexity of quadratic functions,
given in [37].
Theorem 9.35 The quadratic function ϕ(x) is quasiconvex on Rn if and only if it is
convex on Rn.
Proof Let v be any point of Rn and α > 0 a number such that
ϕ(αv) ≦ϕ(−αv).
(9.28)
(Change the sign of v, not of α, if necessary).
Then
1
2α2v⊤Cv + αc⊤v ≦1
2α2v⊤Cv −αc⊤v,
i.e. α > 0, this also (9.28) holds for any α > 0. If now ϕ(x) is quasiconvex on Rn,
then (9.28) implies that for all α > 0
[αv −(−αv)]⊤[C(−αv) + c] = −2α2v⊤Cv + 2αc⊤v ≦0,
or equivalently
αv⊤Cv ≧c⊤v.
The last inequality holds for all α > 0 only if v⊤Cv ≧0 (or (−v)⊤C(−v) ≧0,
if the sign of v has been changed); as v has been chosen arbitrarily, one has that C
is positive semideﬁnite and thus ϕ(x) is convex on Rn. The converse statement is
obvious: if ϕ(x) is convex, it is also quasiconvex by Theorem 3.25.
□
On the grounds of the previous results we have, therefore, the following equiva-
lences (see also Theorem 3.26):

9.3 Quadratic Programming
313
ϕ convex on Rn ⇔ϕ pseudoconvex on Rn ⇔ϕ quasiconvex on Rn
⇔x⊤Cx convex on Rn ⇔C positive semideﬁnite.
Moreover, the previous results show also that there is no reason to study quadratic
functions that are quasiconvex on Rn, neither those that are convex on Rn
+ (recall
that a quadratic function ϕ(x) is convex on any convex set X ⊂Rn, with a nonempty
interior, if and only if C is positive semideﬁnite). However, there are quadratic
functions that are quasiconvex on Rn
+, without being convex on the same set. Take,
e.g. the function ϕ(x1, x2) = −x1x2.
Different is the case of the generalized convexity of quadratic forms and quadratic
functions, referred to proper subsets of Rn, for example the nonnegative orthant Rn
+.
Motivated by the statement of Theorem 9.29, [32, 37, 46] introduces the following
deﬁnitions.
Deﬁnition 9.36 The real symmetric matrix C of order n is positive subdeﬁnite if for
all x ∈Rn :
x⊤Cx < 0 ⇒Cx ̸= 0 and Cx ≧0 or Cx ≦0.
The matrix C is strictly positive subdeﬁnite if for all x ∈Rn :
x⊤Cx < 0 ⇒Cx > 0 or Cx < 0.
(The corresponding notions of negative subdeﬁniteness can be obtained by sub-
stituting (−C) for C).
It is evident that positive semideﬁnite matrices are strictly positive subdeﬁnite,
and strictly positive subdeﬁnite matrices are positive subdeﬁnite. The same terminol-
ogy applies to the related quadratic forms. In order to distinguish positive subdeﬁnite
matrices which are not positive semideﬁnite, from positive semideﬁnite ones, Mar-
tos inserts the word “merely” before “positive subdeﬁnite”. The following results
summarize the principal theorems of Martos regarding these subjects. We omit the
proofs.
Theorem 9.37 ([46, 47]) The quadratic form Q(x) = x⊤Cx is merely positive sub-
deﬁnite if and only if
(i) C ≦0, C ̸= 0;
(ii) The spectrum of C contains exactly one negative element, i.e. C has nonpositive
principal minors.
The merely positive subdeﬁnite quadratic form Q(x) = x⊤Cx is strictly merely pos-
itive subdeﬁnite if and only if C does not contain a row (or column) of zeros.
The quasiconvexity and pseudoconvexity of quadratic forms on Rn
+ are charac-
terized by [32, 37, 46] in terms of positive subdeﬁniteness of the matrices associated
to the said quadratic form.

314
9
Linear Programming and Quadratic Programming
Theorem 9.38 (Martos) The quadratic form Q(x) = x⊤Cx is quasiconvex on the
nonnegative orthant Rn
+ if and only if it is positive subdeﬁnite. The quadratic form
Q(x) = x⊤Cx is pseudoconvex on the semipositive orthant Rn
+ \ {0} if and only if
it is strictly positive subdeﬁnite.
The following result, due to Martos, characterizes the quasiconvexity of quadratic
functions on Rn
+.
Theorem 9.39 (Martos). The quadratic function ϕ(x) = 1
2 x⊤Cx + c⊤x is quasi-
convex on Rn
+ if and only if, for all x ∈Rn :
x⊤Cx < 0 ⇒
 c⊤x
Cx

≧0, but ̸= 0 or
 c⊤x
Cx

≦0, but ̸= 0.
The following result, given in [32], characterizes the matrix C and the vector c of
the previous theorem.
Theorem 9.40 (Martos) The nonconvex quadratic function ϕ(x) = 1
2 x⊤Cx + c⊤x
is quasiconvex on Rn
+ if and only if the following four conditions hold:
(i) C has exactly one (simple) negative eigenvalue;
(ii) C ≦0, C ̸= 0;
(iii) c ≦0;
(iv) There is a vector q ∈Rn such that Cq = c and c⊤q ≦0.
We note that if C is non-singular, then (iv) of the previous theorem reduces to:
(iv)′ : c⊤C−1c ≦0. Moreover, putting c = 0 in Theorem 9.39, we can see that if
ϕ(x) = 1
2 x⊤Cx + c⊤x is quasiconvex on Rn
+, then so is the quadratic form Q(x) =
x⊤Cx. Furthermore, we know that if ϕ(x) fails to be convex, then so does Q(x).
As for what concerns pseudoconvexity of quadratic functions ϕ(x), we report the
following result of [48].
Theorem 9.41 If the nonconvex quadratic function ϕ(x) = 1
2 x⊤Cx + c⊤x is qua-
siconvex on Rn
+, then it is pseudoconvex on Rn
+ provided c ̸= 0 (i.e. if ϕ(x) is a
“proper quadratic function”).
It turns out that for “merely” quasiconvex quadratic functions, quasiconvexity
and pseudoconvexity on Rn
+ (but also on any open convex set of Rn) are equivalent
properties. Another signiﬁcant result ([32, 47]) is the following one.
Theorem 9.42 (a) The nonconvex quadratic function ϕ(x) = 1
2 x⊤Cx + c⊤x is qua-
siconvex on Rn
+ if and only if the matrix
M =
 0 c⊤
c C

is merely positive subdeﬁnite.
(b) If the matrix M of point (a) has no row of zeros and ϕ(x) = 1
2 x⊤Cx + c⊤x is
quasiconvex, but not convex, on the nonnegative orthant Rn
+, then ϕ(x) is pseudo-
convex on the semipositive orthant Rn
+ \ {0} .

References
315
Thus for a quadratic programming problem of the type (QP1) or (QP2), with
ϕ(x) satisfying condition (b) of the previous theorem, a nonzero feasible Karush-
Kuhn-Tucker stationary point x∗must be a global solution to the related problem.
References
1. C. Van de Panne, F. Rahnama, The ﬁrst algorithm for linear programming: an analysis of
Kantorovich’s method. Econ. Plan. 19, 76–91 (1985)
2. G. Giorgi, T.H. Kjeldsen, Traces and Emergence of Nonlinear Programming (Birkhäuser, Basel
and New York, 2014)
3. M.J. Todd, The many facets of linear programming. Math. Program. Series B 91, 417–436
(2002)
4. S. Achmanov, Programmation Linéaire (Editions MIR, Moscou, 1984)
5. C. Berge, Topological Spaces. Including a Treatment of Multi-valued Functions, Vector Spaces
and Convexity (Dover Publications, Mineola, N.Y., 1997)
6. V. Chvatal, Linear Programming (W.H., Freeman, New York, 1983)
7. R.W. Cottle, M.N. Thapa, Linear and Nonlinear Programming (Springer, New York, 2017)
8. G.B. Dantzig, Linear Programming and Extensions (Fourth Printing), (Princeton Univ. Press,
Princeton, 1968)
9. G.B. Dantzig, M.N. Thapa, Linear Programming 1: Introduction (Springer, New York, 1997)
10. G.B. Dantzig, M.N. Thapa, Linear Programming 2: Theory and Extensions (Springer, New
York, 2003)
11. R. Dorfman, P.A. Samuelson, R.M. Solow, Linear Programming and Economic Analysis
(McGraw-Hill, New York, 1958)
12. D. Gale, The Theory of Linear Economic Models (McGraw-Hill Book Company, New York,
1960)
13. D. Luenberger, Y. Ye, Linear and Nonlinear Programming, 3rd edn. (Springer, New York,
2008)
14. K.G. Murty, Linear Programming (Wiley, New York, 1983)
15. E.D. Nering, A.W. Tucker, Linear Programs and Related Problems (Academic, Boston, 1993)
16. J. Nocedal, S.J. Wright, Numerical Optimization, 2nd edn. (Springer, New York, 2006)
17. A. Schrijver, Theory of Linear and Integer Programs (Wiley, Chichester, 1986)
18. M. Simmonard, Linear Programming (Prentice-Hall, Englewood Cliffs, N.J., 1969)
19. R.J.Vanderbei,LinearProgramming:FoundationsandExtensions (Publishers,Boston,Kluwer
Acad, 1996)
20. T.C. Koopmans, Activity Analysis of Production and Allocation (Yale University Press, New
Haven, 1951)
21. G. Hadley, Nonlinear and Dynamic Programming (Addison-Wesley, Reading, Mass, 1964)
22. G. Hadley, Linear Programming (Addison-Wesley, Reading, Mass, 1975)
23. H. Nikaido, Convex Structures and Economic Theory (Academic, New York, 1968)
24. H.W. Kuhn, A.W. Tucker (Eds.), Linear Inequalities and Related Systems, Annals of Mathe-
matics Studies N. 38 (Princeton University Press, Princeton, N.J., 1956)
25. T. Gal, Postoptimal Analysis, Parametric Programming and Related Topics (McGraw-Hill,
New York, 1979)
26. T. Gal, Linear parametric programming—a brief survey. Math. Program. Study 21, 43–68
(1984)
27. J.E. Ward, R.E. Wendell, Approaches to sensitivity analysis in linear programming. Ann. Oper.
Res. 27, 3–38 (1990)
28. O.L. Mangasarian, Uniqueness of solution in linear programming. Linear Algebra Appl. 25,
151–162 (1979)

316
9
Linear Programming and Quadratic Programming
29. J.C. Boot, Quadratic Programming (North Holland, Amsterdam, 1964)
30. Y. Chabrillac, J.-P. Crouzeix, Deﬁniteness and semi-deﬁniteness of quadratic forms revisited.
Linear Algebra Appl. 63, 283–292 (1984)
31. G. Debreu, Deﬁnite and semideﬁnite quadratic forms. Econometrica 20, 285–300 (1952)
32. B. Martos, Quadratic programming with a quasiconvex objective function. Oper. Res. 19, 87–97
(1971)
33. S. Schaible, Second-order characterizations of pseudoconvex quadratic functions. J. Optim.
Theory Appl. 21, 15–26 (1977)
34. S. Schaible, Quasiconvex, pseudoconvex, and strictly pseudoconvex quadratic functions. J.
Optim. Theory Appl. 35, 303–338 (1981)
35. H.M. Markowitz, Portfolio selection. J. Financ. 7, 77–91 (1952)
36. H.M. Markowitz, Portfolio Selection (Yale University Press, New Haven, 1959)
37. B. Martos, Nonlinear Programming. Theory and Methods (North Holland, Amsterdam, 1975)
38. E. Blum, W. Oettli, Direct proof of the existence theorem for quadratic programming. Oper.
Res. 20, 165–167 (1972)
39. R.W. Cottle, J.S. Pang, R.E. Stone, The Linear Complementarity Problem, 2nd edn. (Society
for Industrial and Applied Mathematics, Philadelphia, 2009)
40. F. Facchinei, J.-S. Pang, Finite-Dimensional Variational Inequalities and Complementarity
Problems (Springer, New York, 2003)
41. R.W. Cottle, On the convexity of quadratic forms over convex sets. Oper. Res. 15, 170–172
(1967)
42. W.S. Dorn, Duality in quadratic programming. Quart. Appl. Math. 18, 155–162 (1960)
43. R.W. Cottle, Symmetric dual quadratic programs. Quart. Appl. Math. 21, 237–243 (1963)
44. M. Avriel, W.E. Diewert, S. Schaible, I. Zang, Generalized Concavity (Plenum Press, New
York, 1988)
45. A. Cambini, L. Martein, Generalized Convexity and Optimization. Theory and Applications
(Springer, Berlin, 2009)
46. B. Martos, Subdeﬁnite matrices and quadratic forms. SIAM J. Appl. Math. 17, 1215–1223
(1969)
47. R.W. Cottle, J.A. Ferland, Matrix-theoretic criteria for the quasi-convexity and pseudo-
convexity of quadratic functions. Linear Algebra Appl. 5, 123–136 (1972)
48. R.W. Cottle, J.A. Ferland, On pseudo-convex functions of non-negative variables. Math. Pro-
gram. 1, 95–101 (1971)

Chapter 10
Introduction to Nonsmooth Optimization
Problems
In treating the various optimization problems described in the previous chapters,
we have almost always supposed (with the exception of the characterization of sad-
dle points of the Lagrangian function, in Chap. 8) that the functions involved in the
said problems are differentiable or continuously differentiable or twice-continuously
differentiable. Starting from the 70s of the last century, the necessity of studying non-
smooth (i.e. nondifferentiable) functions and hence nonsmooth optimization prob-
lems, gave rise to a new mathematical theory, called Nonsmooth Analysis (this term
was introduced by the Canadian mathematician F. H. Clarke).
The most important “supplier” and “consumer” of nonsmooth problems is perhaps
optimization theory. The ﬁrst well-studied classes of nonsmooth functions have been
those of convex functions and max-type functions. In the 60s and 70s of the past
century, modern Convex Analysis and modern Minimax Theory were created; see
[1–6].
One of (if not the most) important concepts of Classical Calculus is the concept of
derivative (gradient in the multidimensional case). In Convex Analysis and Minimax
Theory, this role is played by directional derivatives and by subdifferentials. The
concept of subdifferential allows to study convex nonsmooth problems, as in a similar
way the smooth problems are studied with the help of gradients. What developed
for convex functions has been subsequently adapted to locally Lipschitz functions
by the basic results of the Canadian mathematician F. H. Clarke. We shall give some
insights into this approach in the next section (Sect. 10.2) of the present chapter.
By now, Nonsmooth Analysis is an autonomous branch of Mathematics and has
received important applications also outside optimization theory. We shall give some
insights into the axiomatic approach of Elster and Thierfelder [7–10] in deﬁning
generalized directional derivatives and generalized subdifferentials in the third and
last section of the present chapter.
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al., Basic Mathematical Programming Theory, International Series
in Operations Research & Management Science 344,
https://doi.org/10.1007/978-3-031-30324-1_10
317

318
10
Introduction to Nonsmooth Optimization Problems
10.1
The Convex Case
We have seen in Chap. 3 that if f : X →R is differentiable on the open convex set
X ⊂Rn, then f is convex on X if and only if, for every x, x0 ∈X
f (x) −f (x0) ≧∇f (x0)⊤(x −x0),
and we have seen (Theorem 3.6) that if f is not necessarily differentiable on the
open convex set X ⊂Rn, then f is convex on X if and only if for every x0 ∈X there
exists u0 ∈Rn such that for every x ∈X
f (x) −f (x0) ≧(u0)⊤(x −x0).
(10.1)
For example, the function f (x) =
x −x0 , x, x0 ∈R, does not admit deriva-
tive at x = x0. However, there are inﬁnite straight lines passing through the point
(x0, f (x0)), lines of equation y = f (x0) + m(x −x0), that lie (except for the point
(x0, f (x0)) below the graph of f. In other words, there exist inﬁnite values of m ∈R
such that, for every x, the inequality
f (x) ≧f (x0) + m(x −x0)
is satisﬁed. In general, this suggests that, at least for convex functions, it is possible
to replace the gradient of f, when f is not differentiable, with a vector u0 ∈Rn satis-
fying relation (10.1). These considerations allow us to give the following deﬁnition.
Deﬁnition 10.1 Let X ⊂Rn be a convex set and f : X →R a convex function on
X. A vector s ∈Rn is called a subgradient of f at x0 ∈X if for every x ∈X it holds
f (x) −f (x0) ≧s⊤(x −x0).
(10.2)
The set of all subgradients of f at x0 ∈X is called the subdifferential of f at x0
and denoted by ∂f (x0).
Example 10.2 From the previous deﬁnition, it follows at once that, for f (x) = |x| ,
x ∈R, ∂f (0) = [−1, 1] .
Example 10.3 We recall what already remarked in Chap. 3: non-subdifferentiability
can however occur on the boundary of the domain of f ; this justiﬁes the assumption
on the openness of X in relation (10.1). Consider f : [0, 1] →R, with f (x) = −√x.
Then f is clearly convex, but ∂f (0) = ∅.
If the set ∂f (x0) is nonempty, we say that f is subdifferentiable at x0. The notion
of subgradient has a useful geometrical interpretation, already previously sketched.
Suppose s ∈∂f (x0); inequality (10.2) means that the epigraph of f is located on or
above the graph of the afﬁne function l(x) = f (x0) + s⊤(x −x0). For every point
(x, α) ∈epi( f ), we have

10.1 The Convex Case
319
α ≧f (x) ≧f (x0) + s⊤(x −x0),
which can be rewritten as
s⊤(x −x0) + (−1)(α −f (x0)) ≦0.
Consequently, (s, −1) is an element of the normal cone N(epi( f ), (x0, f (x0))):
∂f (x0) =

s ∈Rn : (s, −1) ∈N(epi( f ), (x0, f (x0)))

.
We have seen in Theorem 3.17 that convex functions are directionally differen-
tiable at every point of their (open) convex domain. Before stating the basic results
on subgradients and subdifferentials of convex functions (and before giving the proof
of this last statement), we wish to recall some deﬁnitions and concepts on directional
derivatives, already given, but here we make also some further considerations.
Several modern treatments of convex functions consider extended real-valued
functions, i.e. functions deﬁned on the whole space Rn and assuming also inﬁnite
values. Indeed, consider a convex function deﬁned on a proper subset X of Rn.
Let be
f1(x) =
 f (x), if x ∈X,
+∞, if x /∈X.
The epigraph of the function f deﬁned on X is identical to epi( f1), deﬁned
on the whole space Rn. In this way, we can always construct convex functions
deﬁned throughout Rn. However, allowing convex functions to take on inﬁnite values,
requires some caution in arithmetic operations, such as the “indeterminate forms”
(+∞−∞), (0 · ∞), (∞/∞). Those convex functions that nowhere have the value
−∞and are not identically equal to +∞are usually called proper convex functions.
However, in the present book that presents the basic mathematical tools of opti-
mization theory in Rn, we shall be concerned only with the usual real-valued convex
functions, not necessarily deﬁned on the whole space Rn. Now we recall the basic
notionsandpropertiesconcerningdirectionaldifferentiability,alreadypartiallyantic-
ipated in Chap. 3. Let us deﬁne a direction as a vector v ∈Rn, v ̸= 0. Given a real-
valued function f deﬁned on a subset S of Rn, a point x0 ∈S and v ∈F(S, x0),
the right-sided derivative of f at x0 in the direction v or the right-sided directional
derivative of f at x0 in the direction v is deﬁned as
D+ f (x0; v) = lim
t→0+
f (x0 + tv) −f (x0)
t
,
if the limit exists (ﬁnite or not). Similarly, the left-sided directional derivative of f
at x0 in the direction v is deﬁned as
D−f (x0; v) = lim
t→0−
f (x0 + tv) −f (x0)
t
,

320
10
Introduction to Nonsmooth Optimization Problems
if the limit exists (ﬁnite or not). For v = 0, both D+ f (x0; v) and D−f (x0; v) are
deﬁned to be zero.
The reader can easily verify that the left-sided directional derivative at x0 in the
direction v exists if and only if the right-sided directional derivative at x0 in the
direction (−v) exists and that it holds
D−f (x0; v) = −D+ f (x0; −v),
so in the applications only D+ f (x0; v) is usually considered. If it holds
D+ f (x0; v) = D−f (x0; v),
then we have the (bilateral) directional derivative in the classical sense: Df (x0; v).
We say also that f is directionally differentiable at x0, in the classical sense. In this
case, we have therefore
−D+ f (x0; −v) = D+ f (x0; v),
i.e.
D+ f (x0, v) + D+ f (x0; −v) = 0.
Example 10.4 Let us consider a ﬁxed point x2 ∈Rn and the convex function f :
Rn →R deﬁned by f (x) =
x −x2 . This function admits a right-sided directional
derivative at every point x0 ∈Rn, in the direction v and we have
D+ f (x0; v) =

∥v∥,
if x0 = x2,
v⊤(x0−x2)
∥x0−x2∥, if x0 ̸= x2.
A well-known result is: if a function f : Rn →R is differentiable at a point x0,
then the directional derivative (in the classical sense) of f at x0 in all directions v
exist ﬁnite and is given by
Df (x0; v) = v⊤∇f (x0).
Other important results on directional derivatives are contained in the following
theorem.
Theorem 10.5 If
f : X ⊂Rn →R
admits
a
ﬁnite
directional
derivative
D+ f (x0; v) at x0 ∈int(X), this derivative is positively homogeneous of the ﬁrst
degree with respect to the direction v. The same is true for D−f (x0; v).
Proof The assertion is quite immediate to get. We have, for each h > 0,

10.1 The Convex Case
321
D+ f (x0; hv) = lim
t→0+
f (x0 + thv) −f (x0)
t
= h lim
t→0+
f (x0 + thv) −f (x0)
th
= hD+ f (x0; v).
□
In the sequel, we shall use the notation f ′(x0; v) to denote the right-sided direc-
tional derivative of f at x0.
If f ′(x0; v) exists for all v ∈Rn and is linear in v, then f is said to be Gâteaux
differentiable at x0. In this case, we have
f (x0 + tv) = f (x0) + tv⊤∇f (x0) + o(t), as t →0+.
We come back to convex functions. We have seen in Example 10.4 that the con-
vex function f (x) =
x −x2 admits a right-sided directional derivative at every
point and for every direction v. Indeed, this property is typical of convex functions.
More precisely, we have the following result, already anticipated (without proof) in
Theorem 3.17.
Theorem 10.6 Let X be a nonempty open convex set in Rn and f : X →R a convex
function on X. Let x0 ∈X and v ∈Rn. Then:
(a) The “difference quotient”
q(t) = f (x0 + tv) −f (x0)
t
is a monotonically increasing function of t > 0, i.e. q(t1) ≦q(t2) for all 0 <
t1 < t2, with x0 + t2v ∈X.
(b) The directional derivative f ′(x0; v) exists ﬁnite and we have
f ′(x0; v) = inf
t>0
f (x0 + tv) −f (x0)
t
.
(c) For every x0 ∈X the function f ′(x0; ·) is sublinear, i.e. positively homogeneous
and subadditive. Hence, f ′(x0; v) is a convex function of v and it holds
−f ′(x0; −v) ≦f ′(x0; v).
Proof (a) Let be 0 < t1 < t2, with x0 + t2v ∈X (and hence also x0 + t1v ∈X).
Being f convex, we have
f (x0 + t1v) = f
t1
t2
(x0 + t2v) + (1 −t1
t2
)x0
	
≦t1
t2
f (x0 + t2v) +

1 −t1
t2
	
f (x0).

322
10
Introduction to Nonsmooth Optimization Problems
This inequality implies
q(t1) = f (x0 + t1v) −f (x0)
t1
≦f (x0 + t2v) −f (x0)
t2
= q(t2).
(b) Let be given t, τ > 0, with x0 −τv ∈X and x0 + tv ∈X. The convexity of f
implies
f (x0) = f

t
t + τ (x0 −τv) +
τ
t + τ (x0 + tv)
	
≦
t
t + τ f (x0 −τv) +
τ
t + τ f (x0 + tv).
From here, it follows that
q(t) = f (x0 + tv) −f (x0)
t
≧f (x0) −f (x0 −τv)
τ
.
Hence, the difference quotient q(t), for t →0+ is bounded from below; on the
other hand, q(t) is a monotonically increasing function of t > 0 and hence the exis-
tence of a ﬁnite directional derivative f ′(x0; v) holds true, with the property
f ′(x0; v) = lim
t→0+
f (x0 + tv) −f (x0)
t
= inf
t>0
f (x0 + tv) −f (x0)
t
.
(c) f ′(x0; v) is a sublinear function of the direction v, i.e.
f ′(x0; αv) = αf ′(x0; v), ∀v ∈Rn, ∀α > 0
and
f ′(x0; v1 + v2) ≦f ′(x0; v1) + f ′(x0; v2), ∀v1, v2 ∈Rn.
The homogeneity of the directional derivative with respect to the direction has
already been proved. Let us prove the subadditivity: if v1, v2 ∈Rn, then for any t > 0
sufﬁciently small the inequality
f (x0 + t(v1 + v2)) ≦1
2 f (x0 + 2tv1) + 1
2 f (x0 + 2tv2)
implies the relation
1
t

f (x0 + t(v1 + v2)) −f (x0)

≦1
2t

f (x0 + 2tv1) −f (x0)

+ 1
2t

f (x0 + 2tv2) −f (x0)


10.1 The Convex Case
323
from which, taking the limit for t →0+,
f ′(x0; v1 + v2) ≦f ′(x0; v1) + f ′(x0; v2).
We recall that linear homogeneity plus subadditivity produces convexity, since
f (λx + (1 −λ)y) ≦f (λx) + f ((1 −λ)y) = λf (x) + (1 −λ) f (y), λ ∈[0, 1] .
(also the vice versa holds true: linear homogeneity and convexity imply
subadditivity).
Finally, as f ′(x0; 0) = 0, one has
0 = f ′ 
x0; 0

= f ′ 
x0; v + (−v)

≦f ′ 
x0; v

+ f ′ 
x0; −v

by subadditivity. Therefore,
−f ′(x0; −v) ≦f ′(x0; v), ∀v ∈Rn.
□
We note that the above theorem holds also if x0 ∈int(X), where X ⊂Rn is a (not
necessarily open) nonempty convex set. The same is true also for the next results.
The following statement is a consequence of the previous theorem.
Theorem 10.7 Let X ⊂Rn be an open convex set and let f : X →R be convex.
Then it holds
f ′(x0; x −x0) ≦f (x) −f (x0), ∀x, x0 ∈X.
Proof Let x0, x be any two points of X. Being f convex on X, we have
f (x0 + t(x −x0)) ≦(1 −t) f (x0) + t f (x),
for all t ∈[0, 1] . From this relation, we obtain, for all t ∈(0, 1] :
1
t

f (x0 + t(x −x0)) −f (x0)

≦f (x) −f (x0).
Taking Theorem 10.6 into account, we obtain, for t →0+, the thesis.
□
In particular, when f is differentiable we have the relation
(x −x0)⊤∇f (x0) ≦f (x) −f (x0)
as seen in Theorem 3.7(d). Another consequence of the above results is the inequality
f ′(x; x −x0) ≧f ′(x0; x −x0).

324
10
Introduction to Nonsmooth Optimization Problems
Indeed, by Theorems 10.7 and 10.6(a), we have
f (x0) −f (x) ≧f ′(x; x0 −x) ≧−f ′(x; x −x0),
and so
f ′(x; x −x0) ≧f (x) −f (x0) ≧f ′(x0, x −x0)
by Theorem 10.7.
In particular, when f is differentiable, we have the relation
(x −x0)⊤
∇f (x) −∇f (x0)

≧0,
as seen in Theorem 3.7( f ).
As for what concerns differentiability of convex functions, we have the following
result, which is a particular case of a more general result, due to Rademacher; see,
e.g. [11].
If f : X ⊂Rn →R is convex on the open convex set X, it is differentiable with
continuous partial derivatives everywhere on X, except for a set of measure zero (in
the Lebesgue sense).
Summing up (see also [2, 11, 12]): Let f : X ⊂Rn →R be convex on the open
convex set X, let x0 ∈X (or, more generally, let f be convex on the convex set X
and let x0 ∈int(X)). Then the following properties are equivalent:
(i) The function f is differentiable at x0.
(ii) The function f is directionally differentiable at x0 in the classical sense, for
any direction v ∈Rn.
(iii) The function f admits at x0 the n partial derivatives, with respect to its n
variables.
(iv) The function f is continuously differentiable at x0.
Nowweconsidersubgradientsofconvexfunctionsandtheirrelationswithdirectional
derivatives.
Theorem 10.8 Let X ⊂Rn be a nonempty open convex set and f : X →R a con-
vex function on X. Then the subdifferential ∂f (x0), x0 ∈X, is a nonempty convex
compact set.
Proof We ﬁrst prove the nonemptiness of ∂f (x0). We recall that, due to the convexity
of f, the set epi( f ) is a convex set (see Theorem 3.6). Noting that (x0, f (x0))
belongs to the boundary of epi( f ), and recalling the supporting hyperplane theorem
(Theorem 2.19), we have
z⊤(x −x0) + μ(y −f (x0)) ≦0, ∀(x, y) ∈epi( f )
(10.3)
for some nonzero vector (z⊤, μ) ∈Rn+1. It follows that μ ≦0 (otherwise, a contra-
diction will occur in (10.3) for a large y). If we suppose μ = 0, then we have z ̸= 0

10.1 The Convex Case
325
and z⊤(x −x0) ≦0, ∀x ∈X. Since X is an open set, we can choose a positive num-
ber λ and a point x ∈X such that x −x0 = λz. Consequently, we have λz⊤z ≦0,
which contradicts z ̸= 0. Hence, μ < 0. Letting s = z⊤/ |μ| and dividing (10.3) by
|μ| , we have
s⊤(x −x0) −y + f (x0) ≦0, ∀(x, y) ∈epi( f ).
Since (x, f (x)) ∈epi( f ), ∀x ∈X, we obtain
s⊤(x −x0) + f (x0) ≦f (x), ∀x ∈X.
This implies s ∈∂f (x0). Hence, ∂f (x0) ̸= ∅. The convexity of ∂f (x0) is obvious.
Now we prove the compactness of ∂f (x0). From the deﬁnition of ∂f (x0), it appears
that ∂f (x0) is a closed set (it is given by the intersection of linear weak inequalities);
it remains to prove that it is also a bounded set. Since X is an open set, we choose a
positive number ε satisfying cl(N(x0, ε)) =

x ∈Rn :
x −x0 ≦ε

⊂X. If we
suppose that ∂f (x0) is not bounded, then there exists a sequence

sk
⊂∂f (x0)
such that
sk →+∞. It is clear that there exists a subsequence, that we denote
again by

sk
, and an index j ∈{1, . . . , n} such that |sk
j | →+∞as k →+∞.
Deﬁne a sequence

xk
by xk
i = x0
i , i ̸= j, xk
j = x0
j + εsk
j /|sk
j |. Then it follows that
xk ∈cl(N(x0, ε)). Since a convex function is continuous on an open convex set (see
Theorem 3.13), it follows that the sequence

f (xk)

is bounded. Thus, the inequality
f (xk) ≧f (x0) + (sk)⊤(xk −x0) = f (x0) + ε|sk
j |
does not hold for a large k. But this contradicts the fact that sk ∈∂f (x0). We can
therefore conclude that ∂f (x0) is bounded since xk ∈cl(N(x0, ε)) and cl(N(x0, ε))
is a compact set. Hence, ∂f (x0) is a convex compact set.
□
We recall here the following characterization of convex functions on an open
convex set X ⊂Rn, already given in Chap. 3 (see Theorem 3.6(e)): Let X ⊂Rn be
an open convex set and let f : X →R. Then f is convex on X if and only if, for
every x0 ∈X, there exists s0 ∈Rn such that
(s0)⊤(x −x0) ≦f (x) −f (x0), ∀x ∈X,
i.e. if and only if f is subdifferentiable at every point x0 ∈X.
Theorem 10.9 Let X be a nonempty open convex set in Rn, x0 ∈X and let f : X →
R be a convex function on X. Then
∂f (x0) =

s ∈Rn : f ′(x0; v) ≧s⊤v, ∀v ∈Rn
.
In other words: if X is open (or, more generally, if x0 ∈int(X)), and f is convex
on X, then s ∈∂f (x0) if and only if

326
10
Introduction to Nonsmooth Optimization Problems
f ′(x0; v) ≧s⊤v, ∀v ∈Rn.
Proof Since by Theorem 10.6(b), f ′(x0; v) is given by
inf
t>0
f (x0 + tv) −f (x0)
t
,
it holds that for arbitrarily ﬁxed s0 ∈∂f (x0),
f ′(x0; v) = inf
t>0
f (x0 + tv) −f (x0)
t
≧(s0)⊤v, ∀v ∈Rn.
Hence, ∂f (x0) ⊂

s ∈Rn : f ′(x0; v) ≧s⊤v, ∀v ∈Rn
. We next show the
inverse inclusion. For arbitrarily ﬁxed s0 ∈Rn satisfying
f ′(x0; v) ≧(s0)⊤v, ∀v ∈Rn,
we have
(s0)⊤v ≦f ′(x0; v) = inf
t>0
f (x0 + tv) −f (x0)
t
≦f (x0 + tv) −f (x0)
t
,
∀t ∈(0, +∞),∀v ∈Rn.Since X isaconvexset,everyvector x ∈X canbeexpressed
by x = x0 + tv for some v ∈Rn and t > 0. Thus, the above inequalities imply s0 ∈
∂f (x0). Hence,

s ∈Rn : f ′(x0; v) ≧(s0)⊤v, ∀v ∈Rn
⊂∂f (x0).
□
Theorem 10.10 Let X ⊂Rn be a nonempty open convex set, x0 ∈X and let f :
X →R be a convex function on X. Then
f ′(x0; v) = max
s∈∂f (x0)

s⊤v

, ∀v ∈Rn.
(It is also said that f ′(x0; ·) is the support function of ∂f (x0)).
Proof Let v0 ∈Rn be arbitrarily ﬁxed. The compactness of ∂f (x0) (Theorem 10.8)
and Theorem 10.9 imply
f ′(x0; v0) ≧max
s∈∂f (x0)s⊤v0.
Then we have only to show that there exists a vector s0 ∈∂f (x0) such that
f ′(x0; v0) = (s0)⊤v0. From Theorem 10.6, we get that f ′(x0; ·) is a convex func-
tion on Rn, and from Theorem 10.8, we have that the subdifferential of f ′(x0; v) at
v = v0 is not empty. Hence, we can choose a vector s0 ∈Rn satisfying

10.1 The Convex Case
327
f ′(x0; v) ≧f ′(x0; v0) + (s0)⊤(v −v0), ∀v ∈Rn.
(10.4)
Taking v = 0, we derive that f ′(x0; v0) ≦(s0)⊤v0, while v = ¯tv0 (¯t > 1) yields
f ′(x0; v0) ≧(s0)⊤v0. Therefore, we have
f ′(x0; v0) = (s0)⊤v0.
(10.5)
From (10.4) and (10.5), it follows that
f ′(x0; v) ≧(s0)⊤v, ∀v ∈Rn
and hence
inf
t>0
f (x0 + tv) −f (x0)
t
≧(s0)⊤v, ∀v ∈Rn.
We thus have
f (x0 + tv) ≧f (x0) + t(s0)⊤v, ∀t > 0, ∀v ∈Rn,
with x0 + tv ∈X, which implies s0 ∈∂f (x0). This, together with (10.5), completes
the proof.
□
The following result establishes a relation between gradient and subgradient of a
convex function on an open convex set X ⊂Rn.
Theorem 10.11 Let X ⊂Rn be a nonempty open convex set and f : X →R a
convex function on X. If f is differentiable at x0 ∈X, then ∂f (x0) =

∇f (x0)

.
Conversely, if f has a unique subgradient at x0, then f is differentiable at x0.
Proof Since f is differentiable at x0, we have f ′(x0; v) = (∇f (x0))⊤v, for any
v ∈Rn. Hence, from Theorem 10.9, we have that for s ∈∂f (x0) it holds
(∇f (x0))⊤v ≧s⊤v, ∀v ∈Rn.
This shows that
(∇f (x0) −s)⊤v ≧0, ∀v ∈Rn.
Replacing v with −v, we see that the opposite inequality also holds and thus we
conclude that
(∇f (x0) −s)⊤v = 0, ∀v ∈Rn.
Hence, this shows that s = ∇f (x0).
Conversely, let us assume that f has a unique subgradient s ∈Rn at x0. By
Theorem 10.10, we have

328
10
Introduction to Nonsmooth Optimization Problems
f ′(x0; v) = s⊤v, ∀v ∈Rn.
But it results
−f ′(x0; −v) ≡−D+ f (x0; −v) = D−f (x0; v), ∀v ∈Rn.
Hence, D+ f (x0; v) = D−f (x0; v), ∀v ∈Rn. In other words, f is directionally
differentiable in the classic al sense at x0 for every direction v ∈Rn. Being f convex,
this assures that f is differentiable at x0.
□
From what said above, it is once more clear that the subgradient inequality for
convex differentiable functions satisﬁes the relation
f (y) −f (x) ≧[∇f (x)]⊤(y −x)
(10.6)
for every x, y ∈X (X ⊂Rn open convex set). But, for what said in Chap. 3 (see
Theorem 3.7(d)), also the converse is true: if a differentiable function on the open
convex set X ⊂Rn satisﬁes relation (10.6) for every x, y ∈X, then f is convex
on X.
Example 10.12 The Euclidean norm f (x) = ∥x∥is differentiable at every point
x ∈Rn, x ̸= 0, and hence in these points ∂f (x) = {∇f (x)} . At x = 0, f is not
differentiable, it is subdifferentiable and ∂f (0) =

s ∈Rn : ∥z∥≧s⊤z, ∀z ∈Rn
.
In other words, ∂f (0) is given by the unit closed ball in Rn.
Example 10.13 The convex function
f (x) = −xα, x ∈R, x ≧0, 0 < α < 1,
is differentiable at any point x > 0 (and hence also subdifferentiable). At x = 0, this
function is neither differentiable nor subdifferentiable.
Example 10.14 If S ⊂Rn is a nonempty convex set, then indicator function of the
set S is deﬁned as
δ(x; S) =
 0,
if x ∈S,
+∞, if x /∈S.
We have that ∂δ(x; S) is given by the normal cone of S at x (empty if x /∈S).
Indeed, by deﬁnition, we have that s ∈∂δ(x; S) if and only if
δ(z; S) ≧δ(x; S) + s⊤(z −x), ∀z ∈S.
This condition implies that x ∈S and
0 ≧s⊤(z −x), ∀z ∈S,
that is, s is normal to S at x :

10.1 The Convex Case
329
∂δ(x; S) = N(S, x).
From the deﬁnition of subgradients and subdifferentials, it is immediate that
∂(λf )(x) = λ∂f (x), ∀x, ∀λ > 0.
The following theorem, due to J.-J. Moreau and R. T. Rockafellar (in a more
general version) gives an important calculus rule for subdifferentials of convex func-
tions.
Theorem 10.15 (Moreau-Rockafellar) Let X ⊂Rn be an open convex set and let
α, β ≧0. If f : X →R and g : X →R are convex functions on X, then the function
F = αf + βg is convex on X and it holds
∂F(x0) = α∂f (x0) + β∂g(x0), ∀x0 ∈X.
Proof The ﬁrst part of the thesis has already been proved in Theorem 3.34. Let
now be x0 ∈X; the inclusion α∂f (x0) + β∂g(x0) ⊂∂F(x0) is evident. Suppose
that there exists z ∈∂F(x0) such that z /∈α∂f (x0) + β∂g(x0). By Theorem 10.8,
this last set is nonempty, convex, and compact. By the strong separation theorem
(Theorem 2.17), there exists h ∈Rn such that
max

h⊤y : y ∈α∂f (x0) + β∂g(x0)

< h⊤z.
Therefore, it is veriﬁed the inequality
α max

h⊤y : y ∈α∂f (x0)

+ β max

h⊤y : y ∈β∂g(x0
< h⊤z,
inequality which can be rewritten by Theorem 10.10 in the form
αf ′(x0; h) + βg′(x0; h) < h⊤z.
Taking into account that
αf ′(x0; h) + βg′(x0; h) = F′(x0; h),
we get the inequality
F′(x0; h) < h⊤z,
which, by Theorem 10.9, cannot hold. Hence, we have the thesis of the theorem. □
Remark 10.16 We have to note that also Theorem 10.15 holds under the weaker
assumption that X ⊂Rn is a nonempty convex set, x0 ∈int(X), f : X →R and
g : X →R ∪{+∞} are convex functions on X, ∂f (x0) is compact, g(x0) ﬁnite and
∂g(x0) is closed.

330
10
Introduction to Nonsmooth Optimization Problems
Now we report some optimality conditions for various optimization problems,
where the functions involved are convex. We begin with an unconstrained optimiza-
tion problem, of the type (P1). We recall ﬁrst the basic optimality conditions for
(P1), in absence of convexity assumptions, and expressed in terms of directional
derivatives.
Theorem 10.17 Let be X ⊂Rn, and x0 ∈int(X); let f : X →R admit a (ﬁnite)
directional derivative f ′(x0; v) for all v ∈Rn. For the point x0 to be a local minimizer
of f over X, it is necessary that
f ′(x0; v) ≧0, ∀v ∈Rn.
(10.7)
If f is locally Lipschitz in a neighborhood of x0 (see further, Deﬁnition 10.27),
and if
f ′(x0; v) > 0, ∀v ∈Rn, v ̸= 0,
(10.8)
then x0 is a strict local minimum point of f over X (i.e. condition (10.8) is a sufﬁcient
condition for a strict local minimum of f ).
Proof The necessity part is immediate. Since f is directionally differentiable at x0,
we have
f (x0 + tv) = f (x0) + t f ′(x0; v) + o(t), ∀t ≧0, ∀v ∈Rn.
This implies (10.7).
For the sufﬁciency part, see, e.g. [13, 14], or [15].
□
A point x0 ∈int(X) satisfying (10.7) is called by some authors an inf-stationary
point of f.
We now revert to convex optimization, which may be considered a “ﬁrst path” to
enter into the more complex and recent results on nonsmooth optimization. The fol-
lowing proposition generalizes to the nonsmooth convex case a well-known property
of differentiable convex functions.
Theorem 10.18 Let X ⊂Rn be an open convex set and f : X →R a convex func-
tion; let x0 ∈X. Then the following conditions are equivalent:
(a)
f admits at x0 a global minimum point, i.e. f (x0) ≦f (x), ∀x ∈X.
(b) 0 ∈∂f (x0).
(c)
f ′(x0; v) ≧0, ∀v ∈Rn.
Proof The implication (a)⇒(c) is evident and, as previously remarked in Theorem
10.17, holds also in absence of convexity assumptions on f . The implication (c)⇒(b)
follows from Theorem 10.9. The implication (b)⇒(a) follows at once from the
deﬁnition of subdifferential of f at x0 : the inequality f (x) −f (x0) ≧s⊤(x −x0),
∀x ∈X, when s = 0 gives relation (a).
□

10.1 The Convex Case
331
We now consider a convex programming problem of the type (P2), i. e. with a
(convex) set constraint.
Theorem 10.19 Let f : X →R be convex on the open convex set X ⊂Rn and let
C be an arbitrary convex subset of X. A point x0 ∈C is a solution of the problem
min
x∈C f (x)
if and only if
0 ∈∂f (x0) + N(C, x0),
(10.9)
where N(C, x0) is the normal cone to C at x0.
Proof Let us ﬁrst assume that x0 is a solution of the above minimization problem.
Then it is clear that x0 is also a solution of the following unconstrained problem:
min h(x) ≡f (x) + δ(x; C) =
 f (x), if x ∈C,
+∞, if x /∈C,
where δ(x; C) is the indicator function, previously introduced. By Theorem 10.18,
since x0 is a (global) minimum point of h(x), we have
0 ∈∂( f + δ(·; C))(x0),
and by the sum rule for subdifferentials (Theorem 10.15 and Remark 10.16), we have
0 ∈∂f (x0) + ∂δ(x0; C).
But, being ∂δ(x0; C) = N(C, x0), we get relation (10.9). For the converse case,
observe that the condition 0 ∈∂f (x0) + N(C, x0) means that there exists s ∈∂f (x0)
such that −s ∈N(C, x0). This shows that from the deﬁnition of N(C, x0), it holds
s⊤(x −x0) ≧0, ∀x ∈C. Since s ∈∂f (x0), we see that
f (x) −f (x0) ≧s⊤(x −x0), ∀x ∈X.
This shows that for all x ∈C we have f (x) −f (x0) ≧0, i.e. x0 is a global
minimum point of f over C.
□
In terms of directional derivatives, under the same assumptions of Theorem 10.19,
relation (10.9) becomes
f ′(x0; v) ≧0, ∀v ∈T (C, x0),
where T (C, x0) is the Bouligand tangent cone to C at x0 (see Deﬁnition 2.35).
Indeed, from (10.9) there exists s ∈∂f (x0) such that −s ∈N(C, x0). By Theorem

332
10
Introduction to Nonsmooth Optimization Problems
10.9, one has f ′(x0; v) ≧s⊤v for all v ∈Rn. As −s ∈N(C, x0) = T (C; x0)∗, we
have s⊤v ≧0 for all v ∈T (C, x0), and therefore, f ′(x0; v) ≧0 for all v ∈T (C, x0).
Moreover, as C convex, it holds T (C, x0) = cl(cone(C −x0)) by Theorem 2.41,
hence relation (10.9) becomes
f ′(x0; x −x0) ≧0, ∀x ∈C.
Let us now consider an open convex set X ⊂Rn; we study the case of a convex
optimization problem of the type (P5), but with no differentiability assumptions
on the functions involved in the problem. Instead of gradients, we make use of
subdifferentials.
(P5) :
⎧
⎪⎪⎨
⎪⎪⎩
min f (x)
subject to: gi(x) ≦0, i = 1, . . . , m,
h j(x) = 0, j = 1, . . . , p < n,
x ∈X ⊂Rn,
where f : X →R and every gi, i = 1, . . . , m, are convex functions on X and every
h j, j = 1, . . . , p, is a linear afﬁne function on Rn. Note that under the said assump-
tions the feasible set
K5 =

x : x ∈X, g(x) ≦0, h(x) = 0

is a convex set.
We give ﬁrst a Fritz John-type result for (P5). We follow the approach of [16].
Theorem 10.20 Suppose that x0 ∈K5 is a solution of the convex problem (P5).
Then there exist multipliers u0, u1, . . . , um, v1, . . . , vp, not all zero, such that
0 ∈u0∂f (x0) +
m

i=1
ui∂gi(x0) +
p

j=1
v j∂h j(x0),
u0 ≧0, u1 ≧0, . . . , um ≧0; uigi(x0) = 0, i = 1, . . . , m.
Proof Without loss of generality, we can suppose that all inequality constraints are
active at x0, i.e. I (x0) = {1, . . . , m} . Take
A =

( f (x) −f (x0) + t, g(x) + s, h(x)) : x ∈X, t ∈[0, +∞) , s ∈Rm
+

and
B = (−∞, 0) × Rm
−× {0}p .
It is easy to see that the properties of f, g and h ensure the convexity of A, while
the convexity of B is obvious. On the other hand, if a common element of A and B
exists, then there is also x ∈X with f (x) −f (x0) < 0, g(x) ≦0, h(x) = 0, which

10.1 The Convex Case
333
would contradict the (global) minimality of x0 for (P5). Hence, A ∩B = ∅; by the
separation theorem (Chap. 2), we can deduce the existence of elements u0 ∈R,
u1 ∈R,…,um ∈R, v1 ∈R,…,vp ∈R, not all zero, such that
u0a + ub ≦u0( f (x) −f (x0) + t) + u⊤(g(x) + s) + v⊤h(x),
for all x ∈X, t ∈[0, +∞) , s ∈Rm
+, a ∈(−∞, 0), b ∈Rm
−. It is not possible to have
u0 < 0. Indeed, if we suppose this case, letting a →−∞, we arrive to a contradic-
tion, since the right-hand side is ﬁxed, while the left-hand side goes to +∞. A similar
argument employed for si →∞(for all i = 1, . . . , m) allows us to conclude that
ui ≧0 for all i = 1, . . . , m. Letting a →0, t →0, b →0 and s →0, we actually
get that
0 ≦u0( f (x) −f (x0)) + u⊤g(x) + v⊤h(x)
for all x ∈X. Since g(x0) = 0, we deduce that uigi(x0) = 0 for all i = 1, . . . , m.
Finally, we can write
0 ≦(u0 f (x) −u0 f (x0)) +
m

i=1
(uigi(x) −uigi(x0)) +
p

j=1
(v jh j(x) −v jh j(x0)),
for all x ∈X, which means that
0 ∈∂
⎛
⎝u0 f +
m

i=1
uigi +
p

j=1
v jh j)(x0
⎞
⎠.
Theorem 10.15 allows us to write
0 ∈∂(u0 f )(x0) +
m

i=1
∂(uigi)(x0) +
p

j=1
∂(v jh j)(x0)(x0).
Since u0 ≧0, one has ∂(u0 f )(x0) = u0∂f (x0). The same argument is appli-
cable to the equality ∂(uigi)(x0) = ui∂gi(x0) for all i = 1, . . . , m. The equality
∂(v jh j)(x0) = v j∂h j(x0), for all j = 1, . . . , p, is true by the fact that h is linear
afﬁne.
□
If in the previous result, we have u0 ̸= 0, i.e. u0 = 1, we obtain the related Karush-
Kuhn-Tucker conditions for (P5), expressed in terms of subdifferentials. Since prob-
lem (P5) is convex, we can use a Slater constraint qualiﬁcation:
• There exists ¯x ∈X such that g(¯x) < 0, h(¯x) = 0 and the gradients ∇h j(¯x), j =
1, . . . , p, are linearly independent.
(Note that the afﬁne functions h j(x), j = 1, . . . , p, are differentiable everywhere
and that the gradients ∇h j(x), j = 1, . . . , p, are the same for all x ∈X).

334
10
Introduction to Nonsmooth Optimization Problems
Theorem 10.21 Suppose that x0 is a solution of the convex problem (P5) and
that the above Slater constraint qualiﬁcation holds. Then, there exist real numbers
u1, . . . , um, v1, . . . , vp, such that
0 ∈∂f (x0) +
m

i=1
ui∂gi(x0) +
p

j=1
v j∂h j(x0),
ui ≧0, i = 1, . . . , m; uigi(x0) = 0, i = 1, . . . , m.
Proof Itissufﬁcienttoshowthat,undertheassumptionsmadeinthepresenttheorem,
we cannot have u0 = 0 in the Fritz John conditions of Theorem 10.20. Suppose
absurdly that u0 = 0. Then
0 ∈
m

i=1
ui∂gi(x0) +
p

j=1
v j∂h j(x0) = ∂
⎛
⎝
m

i=1
uigi +
p

j=1
v jh j
⎞
⎠(x0),
that is, for every x ∈X,
m

i=1
ui(gi(x) −gi(x0)) +
p

j=1
v j(h j(x) −h j(x0)) ≧0,
i.e.
m

i=1
uigi(x) +
p

j=1
v jh j(x) ≧0.
For x = ¯x (the element of the Slater constraint qualiﬁcation), this becomes
m

i=1
uigi(¯x) ≧0,
which is possible only if ui = 0 for all i = 1, . . . , m. So, in fact
p

j=1
v jh j(x) ≧
p

j=1
v jh j(x0) = 0, ∀x ∈X.
This means that x0 is a minimum (unconstrained) for the function p
j=1 v jh j(x)
and, by Fermat’s theorem, we get
p

j=1
v j∇h j(x0) = 0.

10.1 The Convex Case
335
But the linear independence of the gradients ∇h j(x0), j = 1, . . . , p, says that the
above relation holds only if v j = 0, ∀j = 1, . . . , p. But then we have that u0 = 0,
u1 = · · · = um = 0, v1 = · · · = vp = 0, which is a contradiction to the thesis of
Theorem 10.20. The proof is complete.
□
Remark 10.22 (a) The Karush-Kuhn-Tucker conditions of Theorem 10.21 are also
sufﬁcient for x0 ∈K5 to be a solution of (P5), being (P5) a convex problem.
(b) If in (P5) we have, besides the functional constraints, also a set constraint (or
abstract constraint), represented by C ⊂X, being C closed and convex, the related
necessary Karush-Kuhn-Tucker conditions must be suitably modiﬁed. Call (P6) this
last problem. In this case, the point ¯x which satisﬁes the Slater constraint qualiﬁcation
must be interior to C :
¯x ∈int(C), g(¯x) < 0, h(¯x) = 0, ∇h j(¯x) j = 1, . . . , p, linearly independent.
The other requirements remain the same as the ones of Theorem 10.21. We have
the following result.
• Assume that x0 is a solution of the convex problem (P6) and that the above Slater
constraint qualiﬁcation is satisﬁed. Then there exist u ∈Rm
+ and v ∈Rp such that
0 ∈∂f (x0) +
m

i=1
ui∂gi(x0) +
p

j=1
v j∂h j(x0) + N(C, x0);
(10.10)
uigi(x0) = 0, i = 1, . . . , m.
(10.11)
Conversely, if for some feasible point x0 for (P6), conditions (10.10) and (10.11)
are satisﬁed, for some u ∈Rm
+ and v ∈Rp, then x0 is a solution of (P6).
(Here N(C, x0) is, as usual, the normal cone of the convex set C at x0).
Subgradients of convex functions can be used also to establish a duality result for
a nondifferentiable convex programming problem, on the lines of Wolfe’s duality
theorems for the differentiable case (see Chap. 8).
We consider the “primal” problem
(P) :
⎧
⎨
⎩
min f (x)
subject to: gi(x) ≦0, i = 1, . . . , m,
x ∈X ⊂Rn,
where f and every gi, i = 1, . . . , m, are convex functions on the open convex set X.
We furthermore assume that the Slater constraint qualiﬁcation is satisﬁed, i.e. there
exists a vector ¯x ∈X such that gi(¯x) < 0, ∀i = 1, . . . , m. Based on the Karush-
Kuhn-Tucker conditions for (P), expressed in terms of subdifferentials, we relate
(P) to the following dual problem, of the Wolfe-type:

336
10
Introduction to Nonsmooth Optimization Problems
(WD) :
⎧
⎨
⎩
max

f (x) + y⊤g(x)

subject to: 0 ∈∂f (x) + m
i=1 yi∂gi(x),
y ≧0.
We recall the said Karush-Kuhn-Tucker conditions for (P) : if x0 is feasible for
(P) and the Slater constraint qualiﬁcation is satisﬁed, then x0 is optimal for (P) if
and only if there exists y ∈Rm such that y ≧0, y⊤g(x0) = 0 and
0 ∈∂f (x0) +
m

i=1
yi∂gi(x0).
Furthermore, if the functions gi, i = 1, . . . , m, are all linear afﬁne, we get the
same conclusion without assuming the Slater constraint qualiﬁcation. Then we have
the following analogous result of Wolfe’s duality theorem (see [17, 18]).
Theorem 10.23 If x0 is optimal for problem (P), then there exists y0 such that
(x0, y0) is optimal for problem (WD). Furthermore, the two problems have the same
extremal value. If the constraints gi, i = 1, . . . , m, are linear afﬁne, this conclusion
holds without assuming the Slater constraint qualiﬁcation.
Proof Let (x, y) be feasible for problem (WD). Then y ≧0 and furthermore, there
exist v ∈∂f (x) and vi ∈∂gi(x), i = 1, . . . , m, such that v + m
i=1 yivi = 0. Then
f (x0) −

f (x) + y⊤g(x)

≧v⊤(x0 −x) −y⊤g(x) = −
m

i=1
yi(vi)⊤(x0 −x) −y⊤g(x)
≧
m

i=1
yi

gi(x) −gi(x0)

−y⊤g(x) = −y⊤gi(x0) ≧0.
This shows that, for every (x, y) feasible for (WD), one has
f (x) + y⊤g(x) ≦f (x0).
(10.12)
Furthermore, by the Karush-Kuhn-Tucker conditions, there exists a vector y0 ∈
Rm such that (x0, y0) is feasible for (WD) and (y0)⊤g(x0) = 0, so that
f (x0) = f (x0) + (y0)⊤g(x0).
(10.13)
Comparing (10.12) and (10.13), we get the conclusions of the theorem.
□

10.2 The Lipschitz Case
337
10.2
The Lipschitz Case
We have seen that a convex function f : X ⊂Rn →R possesses ﬁnite directional
derivatives at every interior point of the convex set X and that these directional
derivatives are convex for all directions v ∈Rn. Being also homogeneous functions
of the ﬁrst degree, they are therefore sublinear functions of v ∈Rn. The Canadian
mathematician F. H. Clarke presented [19–21] a generalized directional derivative
which, for locally Lipschitz functions, (non-necessarily convex) always exists ﬁnite
and is convex and homogeneous of the ﬁrst degree for all directions v ∈Rn. This
generalized directional derivative, called Clarke directional derivative, and its asso-
ciated subdifferential, called Clarke subdifferential, provide useful tools in obtaining
optimality conditions for nonsmooth and non necessarily convex mathematical pro-
gramming problems.
Clarke theory has become an established theory. The literature on Clarke theory
and its applications to optimization (both scalar and vector), control theory, numerical
methods, etc., is very huge (mostly the papers, published on journals or on proceed-
ings of meetings). Here, for the reader’s convenience, next, we give only some basic
references: [13, 21–36].
To go on, we need ﬁrst the deﬁnitions of Lipschitz functions and locally Lipschitz
functions.
Deﬁnition 10.24 Let X ⊂Rn be a nonempty set and f : X →R. The function f
is said to be Lipschitz over X (or Lipschitz continuous over X) if there exists a real
number k ≧0 such that, for every x1, x2 ∈X, we have
 f (x1) −f (x2)
 ≦k
x1 −x2 .
(10.14)
The smallest constant k for which the previous relation holds is said “the Lipschitz
constant” or “the Lipschitz rank”. Then f is said to be “Lipschitz of constant k”.
If k = 1, then f is said to be non-expansive and if k < 1, then f is said to be a
contraction.
Note that if f is Lipschitz on X, then it is (uniformly) continuous on X, but
the converse is not true: take, e.g. the continuous function f (x) = x
1
3 , x ∈R; with
x2 = 0, we see that there is no constant k ≧0 satisfying (10.14). To understand the
meaning of (10.14), rewrite it as follows:
 f (x1) −f (x2)

x1 −x2
≦k, ∀x1 ̸= x2 ∈X.
Hence, a function is Lipschitz on the set X ⊂Rn if and only if all its difference
quotients are bounded.

338
10
Introduction to Nonsmooth Optimization Problems
Example 10.25 (a) The function f (x) = ∥x∥, x ∈Rn, is Lipschitz on Rn, with
k = 1.
(b) The function f (x) = ∥x∥2 is not Lipschitz on the whole space Rn. Indeed, by
choosing x2 = 0, we have
x12 ≦k
x1
which holds only if
x1 ≦k.
A sufﬁcient condition for f to be Lipschitz on a set contained in its domain is given
by the following proposition, which is a consequence of the mean value theorem.
Theorem 10.26 Let be f : X ⊂Rn →R, with X open convex set. If f is differen-
tiable on X and if all its partial derivatives are bounded on X, then f is Lipschitz
on X. Moreover, for every M ≧0 such that

∂f
∂xi
(x)
 ≦M, ∀x ∈X, ∀i = 1, . . . , n,
then relation (10.14) holds with k = √nM.
Deﬁnition 10.27 Let X ⊂Rn be a nonempty open set and f : X →R. Given a
point x0 ∈X, if there exist a neighborhood N(x0) of x0 and a nonnegative number
k such that
 f (x1) −f (x2)
 ≦k
x1 −x2 , ∀x1, x2 ∈N(x0),
then f is said to be locally Lipschitz at x0 or Lipschitz near x0 or Lipschitz around
x0, with constant k.
We say that f is locally Lipschitz on X if f is locally Lipschitz at each x ∈X.
Thus, a function which is locally Lipschitz at a point means that the function satis-
ﬁes the Lipschitz condition in a neighborhood of that point. However, it is important
to note that the value of the Lipschitz constant k in general could change as we change
the point. Obviously, we have the implication
{ f Lipschitz on X ⊂R, X open} ⇒{ f locally Lipschitz at each point of X} ,
but the converse is in general not true. If, however, a locally Lipschitz function has a
uniform Lipschitz constant k at every point x0 ∈X, then f is Lipschitz on X in the
sense of Deﬁnition 10.24.
A sufﬁcient condition for f to be locally Lipschitz at a point x0 of its domain is
given by the following proposition.
Theorem 10.28 If a function f : X ⊂Rn →R is continuously differentiable (i.e.
of class C 1) in a neighborhood of x0 ∈int(X), then f is locally Lipschitz at x0.
Proof Continuous differentiability around x0 means that all n partial derivatives of
f are continuous on a neighborhood of x0. It follows that there exist constants ε > 0
and k ≧0 such that

10.2 The Lipschitz Case
339
∥∇f (x)∥≦k, for all x ∈N(x0, ε).
Suppose that x1, x2 ∈N(x0, ε). Then, by the classical mean value theorem, there
is z ∈(x1, x2) ⊂N(x0, ε) such that
f (x1) −f (x2) = ∇f (z)⊤(x1 −x2).
We now have
 f (x1) −f (x2)
 ≦∥∇f (z)∥
x1 −x2 ≦k
x1 −x2 ,
i.e. f is Lipschitz continuous at x0.
□
The following result gives an important property of convex functions for what
concerns Lipschitz continuity.
Theorem 10.29 Let f : X ⊂Rn →R be a convex function on the open convex set
X. Then f is locally Lipschitz on X.
Proof Consider any x0 ∈X. Since f : X →R is a convex function and X is open,
then f is continuous at x0. Hence, f is locally bounded, i.e. there exist δ > 0 and
k > 0 such that | f (x)| ≦k for all x ∈N2δ(x0). Consider x and y to be two distinct
points in Nδ(x0). Let be α = ∥x −y∥and let be
z = y + δ
α (y −x).
Thus, we have
z −x0 ≦
y −x0 + ∥z −y∥=
y −x0 + δ
α ∥y −x∥≦δ + δ = 2δ.
This shows that z ∈N2δ(x0). Note that y can be expressed as
y =
α
α + δ z +
δ
α + δ x.
Using the convexity of f, we have
f (y) ≦
α
α + δ f (z) +
δ
α + δ f (x).
Hence,
f (y) −f (x) ≦
α
α + δ ( f (z) −f (x)) ≦2k
δ α = 2k
δ ∥x −y∥.
Interchanging the roles of x and y yields

340
10
Introduction to Nonsmooth Optimization Problems
| f (x) −f (y)| ≦2k
δ ∥x −y∥,
thereby establishing the result.
□
The deﬁnition of Lipschitz continuity of a function allows to give another use-
ful representation of the Bouligand tangent cone to a set S ⊂Rn at x0 ∈S (see
Deﬁnition 2.35) and it will be useful also to characterize the so-called Clarke tan-
gent cone to a set S ⊂Rn at x0 ∈S. See further and see, e.g. [37–40]. We ﬁrst need
the following deﬁnition.
Deﬁnition 10.30 Let S ⊂Rn be a given set and let x ∈Rn. Then the distance of S
from x is given by the function
dS(x) = inf {∥x −s∥: s ∈S} .
If x ∈S, then it is clear that dS(x) = 0. The following result reveals a basic
property of the distance function.
Theorem 10.31 For a given set S ⊂Rn, the distance function dS(·) is a Lipschitz
function of rank 1 on Rn and if S is convex, then the distance function dS(·) is a
convex function on Rn.
Proof Let ε > 0 be an arbitrary scalar number. By deﬁnition, there exists a point
y ∈S such that, for some u ∈Rn, one has dS(u) ≧∥u −y∥−ε. Let x ∈Rn.
Then dS(x) ≦∥x −y∥≦∥x −u∥+ ∥u −y∥. This shows that dS(x) ≦∥x −u∥+
dS(u) + ε. Hence, noting that ε > 0 is arbitrary, we deduce
dS(x) −dS(u) ≦∥x −u∥.
(10.15)
Now switching the roles of x and u in (10.15), we get that
|dS(x) −dS(u)| ≦∥x −u∥,
thus proving that dS(·) is a Lipschitz function on Rn of rank 1. For the proof that
dS(·) is a convex function on Rn if S is convex, see, e.g. [41].
□
Theorem 10.32 Let be given S ⊂Rn and let be x0 ∈S. Then
T (S, x0) =

v ∈Rn : lim inf
t→0+
dS(x0 + tv)
t
= 0

.
We follow the proof of [37]. We ﬁrst need a preliminary result.
Lemma 10.33 Let f : X ⊂Rn →R be a locally Lipschitz function on the open set
X, x ∈X and v ∈Rn. Then
lim inf
u→v, t→0+
f (x + tu) −f (x)
t
= lim inf
t→0+
f (x + tv) −f (x)
t
.

10.2 The Lipschitz Case
341
Proof The left-hand side expression of the above equality can be written as
lim inf
u→v, t→0+
f (x + tu) −f (x)
t
=
= lim inf
u→v, t→0+
f (x + tu) −f (x + tv) + f (x + tv) −f (x)
t
.
Now the Lipschitzian property of f shows that
lim
u→v, t→0+
f (x + tu) −f (x + tv)
t
= 0.
(10.16)
Hence, this shows that
lim inf
u→v, t→0+
f (x + tu) −f (x)
t
=
=
lim
u→v, t→0+
f (x + tu) −f (x + tv)
t
+ lim inf
u→v, t→0+
f (x + tv) −f (x)
t
.
Using (10.16), we get
lim inf
u→v, t→0+
f (x + tu) −f (x)
t
= lim inf
u→v, t→0+
f (x + tv) −f (x)
t
.
(10.17)
Since in the right-hand side of (10.17) u plays no role, we conclude that
lim inf
u→v, t→0+
f (x + tu) −f (x)
t
= lim inf
t→0+
f (x + tv) −f (x)
t
.
□
Proof of Theorem 10.32. Consider v ∈T (S, x0). Then there exist sequences

vk
,
with vk →v and tk →0+ such that x0 + tkvk ∈S. We know that dS : Rn →R is
Lipschitz and that dS(x0) = 0. Then
lim inf
t→0+
dS(x0 + tv)
t
= lim inf
t→0+
dS(x0 + tv) −dS(x0)
t
exists and is ﬁnite. Now we have
lim inf
u→v, t→0+
dS(x0 + tu)
t
≦lim inf
k→+∞
dS(x0 + tkvk)
tk
.
(10.18)
As x0 + tkvk ∈S, it follows that

342
10
Introduction to Nonsmooth Optimization Problems
lim
k→+∞
dS(x0 + tkvk)
tk
= 0.
Therefore, from (10.18), we have
lim inf
u→v, t→0+
dS(x0 + tu)
t
≦0.
Since dS(·) is a Lipschitz function by Theorem 10.31, then, by using
Lemma 10.33, we have
lim inf
u→v, t→0+
dS(x0 + tu)
t
= lim inf
t→0+
dS(x0 + tv)
t
.
This shows that
lim inf
t→0+
dS(x0 + tv)
t
≦0.
But, as dS(x0 + tv) ≧0 and t > 0, we have
lim inf
t→0+
dS(x0 + tv)
t
≧0,
and hence
lim inf
t→0+
dS(x0 + tv)
t
= 0.
Now we prove the converse. Assume that v satisﬁes
lim inf
t→0+
dS(x0 + tv)
t
= 0.
Hence, there exists tk →0+ such that
lim
tk→0+
dS(x0 + tkv)
tk
= 0.
Now, by the deﬁnition of dS(·), for each k, we have sk ∈S such that
x0 + tkv −sk ≦dS(x0 + tkv) + tk
k .
Consider vk = (sk −x0)/tk. Then we have
vk −v
 =
x0 + tkv −sk
tk
≦dS(x0 + tkv)
tk
+ 1
k .

10.2 The Lipschitz Case
343
This shows that vk →v as k →∞. Hence, vk →v and x0 + tkvk = sk ∈S.
Therefore, v ∈T (S, x0).
□
Similarly, it can be proved that the cone of attainable directions A(S, x0) can be
characterized as follows:
A(S, x0) =

v ∈Rn : lim
t→0+
dS(x0 + tv)
t
= 0

,
from which it appears at once that A(S, x0) ⊂T (S, x0).
Itisworthnotingthatwhen S isconvex,dS : Rn →Risaconvexfunction(besides
a Lipschitz function), on the grounds of Theorem 10.31. Hence, in this case, we have
lim inf
t→0+
dS(x0 + tv)
t
= lim inf
t→0+
dS(x0 + tv) −dS(x0)
t
=
= lim
t→0+
dS(x0 + tv) −dS(x0)
t
= d′
S(x0; v),
being d′
S(x0; v) the right-sided directional derivative of dS(·) at x0 in the direction v.
Hence, for a convex set S ⊂Rn and x0 ∈S, we have
T (S, x0) =

v ∈Rn : d′
S(x0, v) = 0

.
Clarke [19–21] generalized this last characterization, by deﬁning a tangent cone
which is always closed and convex, also when S is not necessarily convex. See further.
We are now ready to give the basic deﬁnition of Clarke directional derivative or
generalized directional derivative of a function f : X →R, X ⊂Rn open set.
Deﬁnition 10.34 Let X ⊂Rn be a nonempty open set and f : X →R be a locally
Lipschitz function on X. The Clarke directional derivative, denoted f o(x0; v), of f
at x0 ∈X in the direction v ∈Rn, is deﬁned by
f o(x0; v) = lim sup
x→x0,t→0+
f (x + tv) −f (x)
t
.
(10.19)
Since f is locally Lipschitz, the difference quotient
f (x + tv) −f (x)
t
is bounded and the limit in (10.19) exists ﬁnite.
Other generalized directional derivatives have been introduced and used in opti-
mization theory, for example, the following ones:

344
10
Introduction to Nonsmooth Optimization Problems
fD(x0; v) = lim inf
t→0+
f (x0 + tv) −f (x0)
t
,
called the lower Dini directional derivative (of f at x0 in the direction v ∈Rn), and
f D(x0; v) = lim sup
t→0+
f (x0 + tv) −f (x0)
t
,
called the upper Dini directional derivative (of f at x0 in the direction v ∈Rn).
We note that fD(x0; v) and f D(x0; v) always exist, ﬁnite or not. From the deﬁ-
nitions we have, for a locally Lipschitz function f,
fD(x0; v) ≦f D(x0; v) ≦f o(x0; v).
(10.20)
In order that the usual (right-sided) directional derivative f ′(x0; v) exists ﬁnite,
we must have
−∞< fD(x0; v) = f D(x0; v) < +∞.
In this case, we have, if f o(x0; v) exists ﬁnite,
fD(x0; v) = f D(x0; v) = f ′(x0; v) ≦f o(x0; v).
On the grounds of Theorem 10.32, it turns out that
T (S, x0) =

v ∈Rn : (dS)D(x0; v) = 0

(10.21)
where (dS)D is the lower Dini directional derivative of dS.
For other notions and applications of Dini directional derivatives to optimization,
see, e.g. [42–45].
The Clarke directional derivative has several interesting properties, not possessed
in general by the Dini directional derivatives. We give below the main of the said
properties.
Theorem 10.35 Let f : X →R be locally Lipschitz with rank k at x0 ∈X, with X
open subset of Rn. Then:
(i) The Clarke directional derivative of f at x0 in any direction v ∈Rn exists ﬁnite,
f o(x0; ·) is a positively homogeneous and convex function on Rn with respect
to the direction v (i.e. it is a sublinear function), and it holds
 f o(x0; v)
 ≦k ∥v∥, ∀v ∈Rn.
(10.22)
(ii) It holds
f o(x0; −v) = (−f )o(x0; v), ∀v ∈Rn,
(10.23)
(iii) The function v →f o(x0; v) is Lipschitz of rank k on Rn.

10.2 The Lipschitz Case
345
(iv) The function (x, v) →f o(x; v) is upper-semicontinuous at (x0, v).
Proof (i) Since f is locally Lipschitz near x0, it holds for any x + tv and x which
are sufﬁciently close to x0,
| f (x + tv) −f (x)| ≦kt ∥v∥.
Then it follows that f o(x0; v) exists ﬁnite and (10.22) holds. Now we prove the
positive homogeneity and convexity of f o(x0; ·). It holds that for any v ∈Rn and
λ > 0
f o(x0; λv) = lim sup
x→x0,t→0+
f (x + λtv) −f (x)
t
= λ lim sup
x→x0,t→0+
f (x + λtv) −f (x)
λt
= λf o(x0; v).
Hence, f o(x0; ·) is a positively homogeneous function on Rn. Also, for any
v1, v2 ∈Rn, we have
f o(x0; v1 + v2) = lim sup
x→x0,t→0+
f (x + tv1 + tv2) −f (x)
t
≦lim sup
x→x0,t→0+
f (x + tv1 + tv2) −f (x + tv2)
t
+ lim sup
x→x0,t→0+
f (x + tv2) −f (x)
t
= f o(x0; v1) + f o(x0; v2).
Hence, from the positive homogeneity of f o(x0; v), we get that f o(x0; ·) is a
convex function on Rn : indeed, homogeneity and subadditivity imply convexity.
See, e.g. [46].
(ii) For arbitrarily ﬁxed v ∈Rn, we have
f o(x0; −v) = lim sup
x→x0,t→0+
f (x −tv) −f (x)
t
.
The transformation y = x −tv yields
f o(x0; −v) = lim sup
y→x0,t→0+
f (y) −f (y + tv)
t
= (−f o)(x0; v).
(iii) By the subadditivity and relations (10.22), (10.23), one gets that, with v and w
two vectors of Rn,
f o(x0; v) −f o(x0; w) ≦f o(xo, v −w) ≦k ∥v −w∥, ∀v, w ∈Rn.

346
10
Introduction to Nonsmooth Optimization Problems
Interchanging the roles of v and w establishes property (iii).
(iv) For the proof of this property, see, e.g. [21].
□
We have to remark once more the following important property of f o(x0; ·) :
even if f is a nonconvex function (but it is locally Lipschitz at x0), then f o(x0; ·) is
guaranteed to be a positively homogeneous convex function on Rn.
Clarke introduced also the concept of “generalized subdifferential” for a locally
Lipschitz function, in the same spirit of the usual subdifferential in Convex Analysis.
Deﬁnition 10.36 Let f : X →R be locally Lipschitz at x0 ∈X, X open set of Rn.
Then the Clarke subdifferential of f at x0 or Clarke generalized gradient of f at x0,
denoted by ∂o f (x0), is given by
∂o f (x0) =

ξ ∈Rn : f o(x0; v) ≧ξ ⊤v, ∀v ∈Rn
.
The following basic properties of the Clarke subdifferential are due to [19–21].
Theorem 10.37 Let f : X →R be locally Lipschitz, with rank k, at x0 ∈X, X
open set of Rn. Then:
(i) ∂o f (x0) is a nonempty compact convex set and we have
∥ξ∥≦k, ∀ξ ∈∂o f (x0).
(10.24)
(ii) It holds
f o(x0; v) =
max
ξ∈∂o f (x0)

ξ ⊤v

, ∀v ∈Rn.
(10.25)
In other words, f o(x0; v) is the “support function” of the set ∂o f (x0). See [21].
Proof (i) From Theorem 10.35, f o(x0; ·) is a convex function. Thus, f o(x0; v) has
a nonempty subdifferential at v = 0 (in the Convex Analysis sense) and hence there
exists a vector ξ ∈Rn such that
f o(x0; v) ≧f o(x0; 0) + ξ ⊤v = ξ ⊤v, ∀v ∈Rn.
This means that ξ ∈∂o f (x0) and hence ∂o f (x0) is nonempty. If we next suppose
that
¯ξ
 > k for some ¯ξ ∈∂o f (x0), then from (10.22) of Theorem 10.35 we obtain
f o(x0; ¯ξ) ≦k
¯ξ
 <
¯ξ
2 = ¯ξ ⊤¯ξ
which contradicts ¯ξ ∈∂o f (x0). Therefore, (10.24) holds and so ∂o f (x0) is bounded.
The closedness and the convexity of ∂o f (x0) follow immediately from the deﬁnition
of ∂o f (x0) and the convexity of f o(x0; ·).
(ii) From the deﬁnition and the compactness of ∂o f (x0), it holds that for an arbi-
trarily ﬁxed vector ¯v ∈Rn

10.2 The Lipschitz Case
347
f o(x0; ¯v) ≧
max
ξ∈∂o f (x0)

ξ ⊤¯v

.
Thus, all we have to show is the existence of ¯ξ ∈∂o f (x0) satisfying f o(x0; ¯v) =
¯ξ ⊤¯v. Since f o(x0; ·) is a convex function, we can choose an element, say ¯ξ, of its
subdifferential at ¯v and it follows that
f o(x0; v) ≧f o(x0; ¯v) + ¯ξ ⊤(v −¯v), ∀v ∈Rn.
(10.26)
Letting v = 0, we have f o(x0; ¯v) ≦¯ξ ⊤¯v. Meanwhile, (10.26) with v = t ¯v, t > 1,
yields f o(x0; ¯v) = ¯ξ ⊤¯v. We thus have
f o(x0; ¯v) = ¯ξ ⊤¯v.
(10.27)
It follows from (10.26) and (10.27) that f o(x0; v) ≧¯ξ ⊤v, ∀v ∈Rn, showing
¯ξ ∈∂o f (x0). Thus, (10.25) follows from (10.27).
□
We now give some basic information on the relationships between the Clarke sub-
differential and the usual gradient of a locally Lipschitz function. The ﬁrst question
to be pointed out is that even if f : Rn →R is locally Lipschitz and differentiable
at a given point x0 ∈dom( f ), the Clarke subdifferential may not be a singleton,
i.e. it need not coincide with the gradient of f at x0. However, if the function is
continuously differentiable around a point x0, then the Clarke subdifferential is a
singleton, given by the gradient of f at x0. More precisely, we have the following
result.
Theorem 10.38 (a) Let f : X →R be locally Lipschitz and differentiable at x0 ∈
X, X open set of Rn; then
∇f (x0) ∈∂o f (x0).
(b) Let f : X →R be continuously differentiable around x0 ∈X, X open set of Rn;
then
∂o f (x0) =

∇f (x0)

.
The above theorem can be illustrated by the following example, given in [21].
Example 10.39 Let f : R →R be given by
f (x) =

x2 sin
 1
x

, if x ̸= 0,
0,
if x = 0.
This function is differentiable for all x ∈R and f ′(0) = 0. Being f ′(x) bounded
on each neighborhood U(0), then f is locally Lipschitz around x0 = 0 and we have
that ∂o f (0) = [−1, 1] . The reader is invited to calculate ∂o f (0).
The results of Theorem 10.38 can be ameliorated. Clarke [21] proved that the
Clarke subdifferential ∂o f (x0) contains a unique element, ∇f (x0), if and only if f

348
10
Introduction to Nonsmooth Optimization Problems
is strictly differentiable at x0. A function f : X ⊂Rn →R is strictly differentiable
at x0 ∈int(X) if
lim
(¯x, ¯v, t)→(x0, v, 0+)
f (¯x + t ¯v) −f (¯x)
t
= v⊤z, ∀v ∈Rn,
where z = ∇f (x0). Let us observe that strict differentiability at x0 implies differ-
entiability at x0, but the converse does not hold. If f is C 1 at x0, then it is strictly
differentiable at x0 , but the converse does not hold. However, f : X ⊂Rn →R is
strictly differentiable on the open set X ⊂Rn if and only if f is C 1 on X. See [33].
The next theorem gives a useful result for calculating the Clarke subdifferential
of a locally Lipschitz function, as in general, it is not easy to get the expression of
the said subdifferential. For the proof of the theorem see [21].
Theorem 10.40 If a function f : X →R is locally Lipschitz at x0 ∈X, X open set
of Rn, then we have
∂o f (x0) = conv
ξ ∈Rn : there exists

xk
⊂X \ 
 f such that
xk →x0 and ∇f (xk) →ξ

,
where 
 f = {x ∈X : f is not differentiable at the pointx} .
In other words, as an important theorem of Rademacher says that a function which
is Lipschitz continuous on an open set U ⊂Rn is differentiable “almost everywhere”
on U (i.e. except of sets of measure zero), the aspect of the Clarke subdifferential is
“independent” from sets of measure zero.
The following example which makes use of Theorem 10.40 is taken from [37].
Example 10.41 Consider f : R2 →R given by f (x, y) = |x| −|y| . This function
can be represented as
f (x, y) =
⎧
⎪⎪⎨
⎪⎪⎩
x −y,
if x ≧0, y ≧0
−x −y, if x ≦0, y ≧0
x + y,
if x ≧0, y ≦0
−x + y, if x ≦0, y ≦0.
Obviously, f (x, y) is not differentiable only at the points along the x-axis and
y-axis of the two-dimensional plane. We want to calculate ∂o f (0, 0). At all other
points the gradient is given by
∇f (x, y) =
⎧
⎪⎪⎨
⎪⎪⎩
(1, −1)⊤,
if x > 0, y > 0
(−1, −1)⊤, if x < 0, y > 0
(1, 1)⊤,
if x > 0, y < 0
(−1, 1)⊤,
if x < 0, y < 0.
Using Theorem 10.40, we have

10.2 The Lipschitz Case
349
∂o f (0, 0) = conv {(1, −1), (−1, −1), (1, 1), (−1, 1)} ,
i.e. ∂o f (0, 0) is a square in R2 with the above four points as its vertices.
We have seen that it holds
f ′(x0; v) ≦f o(x0; v), ∀v ∈Rn,
provided that these quantities exist. However, even in the Lipschitz case, the above
inequality may be strict: besides the case of Example 10.39, consider the following
case.
Example 10.42 Let be given the function f (x) = −|x| , x ∈R, and let be f1(x) =
|x| . It is easy to see that
f o
1 (0; v) = |v| .
Being f (x) = −f1(x), by Theorem 10.35(ii), we get f o(0; v) = |v| and being
f ′(0; v) = −|v| , we deduce that f ′(0; v) < f o(0; v), ∀v ̸= 0.
An important result states that for convex functions the one-sided directional
derivative f ′(x0; v) and the Clarke directional derivative f o(x0; v) coincide. For the
proof of this property, see, e.g. [21].
Theorem 10.43 Let f : X ⊂Rn →R be convex on the open convex set X. Then
f ′(x0; v) = f o(x0; v), ∀x0 ∈X, ∀v ∈Rn.
Hence, ∂f (x0) = ∂0 f (x0), ∀x0 ∈X.
Following [21] we give the next deﬁnition.
Deﬁnition 10.44 Let f : X ⊂Rn →R be a locally Lipschitz function on the open
set X. The function f is called regular at x0 ∈X or Clarke regular at x0 ∈X if
(a)
f ′(x0; v) exists (ﬁnite) for all v ∈Rn.
(b) It holds
f ′(x0; v) = f o(xo; v), ∀v ∈Rn.
The function f is regular on X if it is regular at every x0 ∈X.
Therefore, any convex function on an open convex set X ⊂Rn is a Clarke regular
function on X. There are regular but non-convex functions and there are non-regular
functions. We give an example for the ﬁrst case. The second case can be illustrated
by Example 10.41.
Example 10.45 Consider the function f : R →R given by
f (x) =
0,
if x < 0
−x2, if x ≧0.

350
10
Introduction to Nonsmooth Optimization Problems
It is easy to check that f ′(0; v) = 0, ∀v. Now consider the function −f (x) :
−f (x) =
0,
if x < 0
x2, if x ≧0.
It is clear that −f (x) is convex. We have f o(0; v) = (−f )o(0; −v). Hence,
f o(0; v) = 0 = f ′(0; v). This shows that f is a regular function, even if it is not
convex.
Other sufﬁcient conditions for f to be regular at x0 are:
(1) f is continuously differentiable around x0;
(2) f = m
i=1 λi fi, where λi > 0, ∀i = 1, . . . , m, and every fi is regular at x0,
i = 1, . . . , m.
We note, moreover, that if f is differentiable and regular at x0, then
∂o f (x0) =

∇f (x0)

.
In other words, regularity guarantees that the gradient is the unique Clarke subdif-
ferential of a differentiable function.
We now give some calculus rules for the Clarke subdifferential, which are in a
certain sense, a generalization to the nonsmooth Lipschitz case of the calculus rules
of the classical (smooth) analysis. For the related proofs, see, e.g. [21].
Theorem 10.46 Let f : X ⊂Rn →R be locally Lipschitz on the open set X. Then,
for any scalar α ∈R and for any x0 ∈X, it holds
∂o(αf )(x0) = α∂o f (x0).
Theorem 10.47 Let f1, . . . , fm be locally Lipschitz on the open set X ⊂Rn. Then
it holds, for each x0 ∈X,
∂o
 m

i=1
fi(x0)

⊂
m

i=1
∂o fi(x0).
More generally, with α1, . . . , αm ∈R,
∂o
 m

i=1
αi fi

(x0) ⊂
m

i=1
αi∂o fi(x0).
If every function f1, . . . , fm is Clarke regular, then, with α1 ≧0, . . . , αm ≧0,
∂o
 m

i=1
αi fi

(x0) =
m

i=1
αi∂o fi(x0), ∀x0 ∈X.

10.2 The Lipschitz Case
351
Theorem 10.48 If f : X →R and g : X →R are locally Lipschitz on the open set
X ⊂Rn, then f · g is locally Lipschitz on X and, for every x0 ∈X,
∂o( f · g)(x0) ⊂g(x0)∂o f (x0) + f (x0)∂og(x0).
If, in addition, f (x0) ≧0, g(x0) ≧0 and f and g are both Clarke regular, then
f · g is also Clarke regular and equality holds in the above inclusion.
Theorem 10.49 Let f : X →R and g : X →R be locally Lipschitz on the open
set X ⊂Rn; let be g(x) ̸= 0, x ∈X. Then the ratio f
g : X →R is locally Lipschitz
on X and, with x0 ∈X,
∂o
 f
g
	
(x0) ⊂g(x0)∂o f (x0) −f (x0)∂0g(x0)

g(x0)
2
.
If, in addition, f (x0) ≧0, g(x0) > 0 and f and g are both Clarke regular, then
the equality holds in the above inclusion and f
g is also regular.
The next result is a chain rule for locally Lipschitz functions.
Theorem 10.50 Let f : Rn →R be such that f = g ◦h, where h : Rn →Rm is
locally Lipschitz at x0 ∈Rn (i.e. each of its components is locally Lipschitz at x0)
and g : Rm →R is locally Lipschitz at h(x0) ∈Rm. Then f is locally Lipschitz at
x0 and
∂0 f (x0) ⊂conv
 m

i=1
yiξ i : ξ i ∈∂ohi(x0), (y1, . . . , ym)⊤∈∂og(h(x0))

.
Moreover, if g is Clarke regular at h(x0) and h is Clarke regular at x0 and for
any y ∈∂og(h(x0)) we have y ≧0, then the above inclusion holds as equality. The
same is true if g is regular at h(x0) and h is continuously differentiable around x0.
We now discuss brieﬂy some geometric concepts associated to the Clarke direc-
tional derivative and to the Clarke subdifferential, i.e. we give some insights on the
notion of Clarke tangent cone and Clarke normal cone. We have seen that the Bouli-
gand tangent cone (or contingent cone) T (S, x0) to a set S ⊂Rn at x0 ∈S, is a
closed cone, with vertex at 0 ∈T (S, x0), but not necessarily convex. Clarke [19–21]
introduced a local cone approximation of a set S ⊂Rn at x0 ∈S, called Clarke tan-
gent cone, which is always closed and convex, even if in some particular cases it may
not be a “good” local approximation of the set in question (i.e. it may be too small).
The Clarke tangent cone to a set S ⊂Rn at x0 ∈S, here denoted by T o(S, x0), can
be represented in several equivalent ways (see, e.g. [40, 42, 43]).

352
10
Introduction to Nonsmooth Optimization Problems
Deﬁnition 10.51 Let be given S ⊂Rn and x0 ∈S. The Clarke tangent cone to S at
x0 is given by
T o(S, x0) =
v ∈Rn : ∀

xk
→x0, xk ∈S, ∀{tk} →0, tk > 0,
∃

vk
→v such that xk + tkvk ∈S

.
In terms of neighborhoods, we have
T o(S, x0) =
v ∈Rn : ∀ε > 0, ∃α, β > 0, ∀¯x ∈S ∩Nα(x0),
∀t ∈(0, β), ∃¯y ∈Nε(v) such that ¯x + t ¯y ∈S

.
Another interesting description of the Clarke tangent cone is given in terms of the
Clarke generalized derivative of the distance function dS(x), which is a Lipschitz
function on Rn (Theorem 10.31).
Theorem 10.52 Let S ⊂Rn and let x0 ∈S; then it holds
T o(S, x0) =

v ∈Rn : do
S(x0; v) = 0

.
(10.28)
Proof We use the deﬁnition of T o(S, x0) in terms of sequences. Let us denote by
T o
1 (S, x0) the second set of the equality in (10.28). Suppose ﬁrst that v ∈T o
1 (S, x0)
and that sequences xk →x0 with xk ∈S and tk →0+ are given. Then do
S(x0; v) = 0
and since xk ∈S, we have
0 ≦lim
k→∞
dS(xk + tkv)
tk
= lim
k→∞
dS(xk + tkv) −dS(xk)
tk
≦
lim sup
y→x0, t→0+
dS(y + tv) −dS(y)
t
= do
S(x0; v) = 0.
It follows that the limit exists and is zero. Then, for all k ∈N, there exists zk ∈S
such that
xk + tkv −zk ≦dS(xk + tkv) + tk
k .
If we now deﬁne
vk = zk −xk
tk
,
we have
v −vk =
v −zk −xk
tk
 =
xk + tk −zk
tk
≦dS(xk + tkv)
tk
+ 1
k →0
as k →∞and
xk + tkvk = xk + tk
zk −xk
tk
	
= zk ∈S.
Thus, v ∈T o(S, x0).

10.2 The Lipschitz Case
353
Now for the converse. Suppose that v ∈T o(S, x0) and choose sequences xk →x0
and tk →0+ such that
lim
k→∞
dS(xk + tkv) −dS(xk)
tk
= do
S(x0; v).
(10.29)
In order to prove that do
S(x0; v) = 0, it sufﬁces to show that the quantity in the
left side of (10.29) is nonpositive. Indeed, one has always do
S(x0; v) ≧0, since dS(·)
attains a minimum at x0 (see further Theorem 10.56). Let {zk} ⊂S such that
∥zk −xk∥< dS(xk) + tk
k .
(10.30)
Then we have
x0 −zk ≦
x0 −xk +
xk −zk ≦
x0 −xk + dS(xk) + tk
k →0
as k →∞. Then by assumption, there exists a sequence {vk} converging to v such that
xk + tkvk ∈S. By Theorem 10.31, the distance function dS(·) is Lipschitz continuous
with Lipschitz constant k = 1 and, in view of (10.30), we get
dS(xk + tkv) ≦dS(zk + tkvk) +
xk −zk + tk
v −vk
≦dS(xk) + tk
v −vk + 1
k
	
.
This implies that the quantity in (10.29) is nonpositive and hence we have
do
S(x0; v) = 0, i.e. v ∈T o
1 (S, x0).
□
Theorem 10.53 For any set S ⊂Rn and any point x0 ∈S, the Clarke tangent cone
T o(S, x0) is a closed convex cone (with vertex at the origin). Moreover, T o(S, x0) ⊂
T (S, x0).
Proof From Theorem 10.35, we know that the Clarke directional derivative do
S(x0; ·)
is a positively homogeneous convex function. This leads to the fact that T o(S, x0) is
a convex set by Theorem 10.52 since T o(S, x0) is the level set do
S(x0; v) ≦0. Con-
vexity of do
S(x0; ·) also guarantees the continuity of do
S(x0; ·) which in turn gives the
closedness of T o(S, x0). Consider now v ∈T o(S, x0); we have therefore (Theorem
10.52) do
S(x0; v) = 0.
By applying inequality (10.20) to the function dS(·), we obtain
(dS)D(x0; v) ≦do
S(x0; v) = 0,
and so (dS)D(x0; v) = 0 since always (dS)D(x0; v) ≧0. Now, from (10.21), we
conclude that v ∈T (S, x0). Hence, T o(S, x0) ⊂T (S, x0).
□

354
10
Introduction to Nonsmooth Optimization Problems
As already remarked, in some cases the Clarke tangent cone is however too
“small” to be a good local approximation of S ⊂Rn at x0 ∈S. If S ⊂Rn is a set
such that at x0 ∈S we have T o(S, x0) = T (S, x0), we say that S is Clarke regular
at x0. It is now possible, utilizing polarity, to deﬁne the Clarke normal cone.
Deﬁnition 10.54 Let S ⊂Rn and let x0 ∈S. Then the Clarke normal cone to S at
x0 is the cone
N o(S, x0) =

ξ ∈Rn : ξ ⊤v ≦0, ∀v ∈T 0(S, x0)

= (T 0(S, x0))∗.
The following theorem (for its proof, see, e.g. [21]) presents the main properties
of the Clarke normal cone.
Theorem 10.55 (i) Let S ⊂Rn and let x0 ∈S. Then the following properties hold.
(a) N o(S, x0) is a closed convex cone.
(b) N o(S, x0) = cl(cone(∂odS(x0))).
(c) T o(S, x0) =

v ∈Rn : v⊤ξ ≦0, ∀ξ ∈N o(S, x0)

= (N o(S, x0))∗.
(ii) Suppose that S ⊂Rn is a nonempty convex set and that x0 ∈S. Then S is Clarke
regular at x0 and we have
T o(S, x0) = T (S, x0) = cl(cone(S −x0));
N o(S, x0) =

ξ ∈Rn : ξ ⊤(y −x0) ≦0, ∀y ∈S

= N(S, x0).
Moreover, it can be shown that the Clarke normal cone is the closure of the convex
hull of the Mordukhovich normal cone (see [47], vol. 1, Sect. 6.4):
N o(S, x0) = cl(conv(NM(S, x0))).
As for the convex case, also the Clarke normal cone has an interesting geometric
interpretation. Indeed, it holds, if f : X ⊂Rn →R is locally Lipschitz at x0 ∈X,
epi( f o(x0; ·)) = T o(epi( f ), (x0, f (x0))),
i.e. (v, α) ∈T o(epi( f ), (x0, f (x0))) if and only if α ≧f o(x0; v). As a consequence
we have that if f : X ⊂Rn →R is locally Lipschitz at x0 ∈X, then similarly to the
convex case (previous Section), we have
∂o f (x0) =

ξ ∈Rn : (ξ, −1) ∈N o(epi( f ), (x0, f (x0)))

.
The above considerations have been used to ﬁt the Clarke nonsmooth calculus to a
class of functions larger than the class of locally Lipschitz functions, namely the class
of lower semicontinuous functions; see, e.g. [48]. The same considerations are also
a basic tool to introduce the axiomatic approach of K.-H. Elster and J. Thierfelder
to nonsmooth calculus. See the next Section.

10.2 The Lipschitz Case
355
We now establish necessary optimality conditions for an unconstrained optimiza-
tion problem involving a locally Lipschitz function.
Theorem 10.56 (Fermat rule for Lipschitz functions) Let be f : X ⊂Rn →R and
let x0 ∈int(X) be a local minimum point or a local maximum point for f over X.
Let f be locally Lipschitz at x0, then
0 ∈∂o f (x0),
(10.31)
or equivalently
f o(x0; v) ≧0, ∀v ∈Rn.
Proof One has, if x0 is a local minimum point, that
f o(x0; v) =
lim sup
x→x0, t→0+
f (x + tv) −f (x)
t
≧lim sup
t→0+
f (x0 + tv) −f (x0)
t
≧0.
On the other hand, if x0 is a local maximum point,
f o(x0; v) =
lim sup
x→x0, t→0+
f (x + tv) −f (x)
t
≧lim sup
t→0+
f (x0) −f (x0 −tv)
t
≧0.
Hence, in both cases,
f o(x0; v) ≧0 for any v ∈Rn, which proves the
conclusion.
□
A point x0 satisfying relation (10.31) is also called a Clarke stationary point.
We now consider a minimization problem involving a Lipschitz objective function
and a set constraint, i.e. a problem of the type (P2).
(P2) :
min f (x), x ∈C ⊂X ⊂Rn,
where f : X →R is a locally Lipschitz function on the open set X and C is an
arbitrary subset of X. The following result is given in [48].
Theorem 10.57 Consider the above problem (P2). If x0 ∈C is a local minimum
point of f over C, then
f o(x0; v) ≧0, ∀v ∈T (C, x0),
(10.32)
where T (C, x0) is the Bouligand tangent cone to C at x0.
Proof If v = 0, the result is trivially true. Let us now consider the case where v ̸= 0
and v ∈T (C, x0). By the deﬁnition of the Bouligand tangent cone, we can ﬁnd a
sequence {xn} in C and a sequence of scalars {tn} > 0, with xn →x0, tn →0, such
that vn = xn−x0
tn
→v, and so xn = x0 + tnvn.
Hence

356
10
Introduction to Nonsmooth Optimization Problems
f

x0 + tnv

−f (x0)
tn
= f

x0 + tnv

−f (xn)
tn
+ f (xn) −f (x0)
tn
,
(10.33)
Since f is locally Lipschitz, we have
| f

x0 + tnv

−f (xn)|
tn
≦k
x0 + tnv −(x0 + tnvn)

tn
= k
vn −v
 →0,
where k is the Lipschitz constant. Hence,
f

x0 + tnv

−f (xn)
tn
→0.
Again we have f (xn) ≧f (x0). Hence, from the equality (10.33), it follows that
lim sup
n→∞
f

x0 + tnv

−f (x0)
tn
≧0.
From the deﬁnition of the Clarke directional derivative, we see that
f o(x0; v) ≧lim sup
n→∞
f

x0 + tnv

−f (x0)
tn
.
This shows that f o(x0; v) ≧0. Since v ∈T (C, x0) is arbitrary, the result is
proved.
□
Remark 10.58 In order to obtain the dual relation of (10.32) expressed by means of
the Clarke subdifferential, as shown by [48], we have to consider a convex subcone
of the Bouligand tangent cone T (C, x0). More precisely:
• Let x0 ∈C be a local minimum point for problem (P2) and let T1(C, x0) be a
nonempty closed convex subcone of T (C, x0). Then we have
0 ∈∂o f (x0) + (T1(C, x0))∗,
where (T1(C, x0))∗denotes, as usual, the polar cone of T1(C, x0).
If we choose T1(C, x0) = T o(C, x0), we obtain the necessary optimality condition
for (P2) given in [21] with a different proof, i.e.
0 ∈∂o f (x0) + N o(C, x0).
Under the same assumptions of Theorem 10.57 ( f locally Lipschitz on X), we
can obtain
f D(x0; v) ≧0, ∀v ∈T (C, x0).

10.2 The Lipschitz Case
357
See [49]. Being f o(x0; ·) ≧f D(x0; ·), we have that the above condition is sharper
than condition (10.28). Note that, contrary to what asserted in [49], it is not true the
following necessary optimality condition
fD(x0; v) ≧0, ∀v ∈T (C, x0).
Indeed, consider the following counterexample: let C = {2−n : n = 1, 2, . . . } and
f : R →R deﬁned by f (x) = −dC(x). One has that f is Lipschitz and x0 = 0 is a
minimum for f over C, however, fD(x0; v) = −1/3 < 0 for v = 1 ∈T (C, x0).
Now we wish to give Fritz John-type optimality conditions for a constrained
problem of the type (P4).
(P4) :
⎧
⎨
⎩
min f (x)
subject to: gi(x) ≦0, i = 1, . . . , m,
x ∈X ⊂Rn,
where the objective function f and the constraint functions gi, i = 1, . . . , m, are
supposed to be locally Lipschitz on the open set X. Let us denote by K4 the feasible
set of (P4). We follow the treatment of [23]. Without loss of generality, we can
scalarize the multiple constraints of (P4) by introducing the total constraint function
g : X →R deﬁned by
g(x) = max {gi(x), i = 1, . . . , m} .
We need the following result.
Theorem 10.59 Let be f (x) = max { f1(x), . . . , fm(x)} , where each fi : X ⊂Rn
→R, i = 1, . . . , m, is locally Lipschitz on the open set X. Then f is locally Lipschitz
on X and
∂o f (x) ⊂conv

∂o fi(x), i ∈ˆI(x)

, ∀x ∈X,
where ˆI(x) = {i ∈{1, . . . , m} : fi(x) = f (x)} .
Proof Deﬁne g : Rm →R and h : X →Rm by
g(u) = max
i=1,...,m {ui} , u ∈Rm,
h(x) = ( f1(x), . . . , fm(x)) .
Now we have f = g ◦h. For all u, v ∈Rm and λ ∈[0, 1] it holds
g(λu + (1 −λ)v) =
max
i=1,...,m {λui + (1 −λ)vi}
≦λ max
i=1,...,m {ui} + (1 −λ) max
i=1,...,m {vi}
= λg(u) + (1 −λ)g(v),

358
10
Introduction to Nonsmooth Optimization Problems
which means that g is convex on Rm and hence locally Lipschitz on Rm (Theorem
10.29). Therefore, f = g ◦h is locally Lipschitz on X as can be easily checked. Let
be J(u) = {i ∈{1, . . . , m} : ui = g(u)} . Then the directional derivative of g is
g′(u; v) = lim
t→0+
g(u + tv) −g(u)
t
= lim
t→0+
max
i=1,...,m
{ui + tvi} −g(u)
t
= lim
t→0+ max
i∈J(u)
{ui + tvi} −g(u)
t
= lim
t→0+ max
i∈J(u)
{ui + tvi −ui}
t
.
Thus,
g′(u; v) = max
i∈J(u)vi.
Being g convex, it is also Clarke regular (Theorem 10.43) and therefore we have
go = g′, which gives
∂og(u) =

α ∈Rm : max
i∈J(u)vi ≧α⊤v, ∀v ∈Rm

.
Now it is not hard to see that
α ∈∂og(u) ⇔
⎧
⎨
⎩
αi ≧0, i = 1, . . . , m;
m
i=1 αi = 1;
αi = 0, when i /∈J(u),
and so we can calculate the Clarke subdifferential of g at h(x) ∈Rm by
∂og(h(x)) =

α ∈Rm : αi ≧0,
m

i=1
αi = 1 and αi = 0 if i /∈ˆI(x)

.
By applying Theorem 10.50 to f , we get
∂o f (x) ⊂conv
 m

i=1
αiξ i : ξ i ∈∂ohi(x) and α ∈∂og(h(x))

= conv
⎧
⎨
⎩

i∈ˆI(x)
αi∂o fi(x) : αi ≧0 and

i∈ˆI(x)
αi = 1
⎫
⎬
⎭
= conv

∂o fi(x) : i ∈ˆI(x)

.
□

10.2 The Lipschitz Case
359
Remark 10.60 In Theorem 10.59 if, in addition fi is Clarke regular at x for all
i = 1, . . . , m, then f is also Clarke regular at x and it can be proved that the inclusion
of the thesis of the same theorem holds as equality.
We are now ready to prove for (P4) a Fritz John-type necessary optimality con-
dition, expressed by means of Clarke subdifferentials.
Theorem 10.61 Let x0 be a local minimum point for (P4). Then, there exist multi-
pliers λi ≧0, i = 0, 1, . . . , m, not all zero, such that
0 ∈λ0∂o f (x0) +
m

i=1
λi∂ogi(x0),
λigi(x0) = 0, i = 1, . . . , m.
Proof It is clear that the function h : X →R deﬁned by
h(x) = max

f (x) −f (x0), g(x)

is locally Lipschitz on X by Theorem 10.59. Since x0 ∈K4 is a local minimizer for
(P4), there exists δ > 0 such that U(x0, δ) ⊂X and
f (x0) ≦f (x), ∀x ∈K4 ∩U(x0, δ),
Since x0 ∈K4, we have g(x0) ≦0, implying
h(x0) = max

f (x) −f (x0), g(x)

= 0.
Moreover,
h(x) = max

f (x) −f (x0), g(x)

≧h(x0) = 0, ∀x ∈X ∩U(x0, δ).
because if x ∈K4, then g(x) ≦0 and f (x) −f (x0) ≧0, and if x ∈U(x0, δ) \ K4,
then g(x) > 0, and so h(x) > 0. In other words, h(x) attains a local minimum at
x0 ∈int X. Then, due to Theorem 10.56, we have
0 ∈∂oh(x0).
If g(x0) < 0, we have g(x0) < f (x0) −f (x0) and thus, due to Theorem 10.59,
we get
0 ∈∂oh(x0) ⊂∂o f (x0).
Then the assertion of the theorem is proved by choosing λ0 = 1 and λi = 0 for
i = 1, . . . , m. On the other hand, if g(x0) = 0, we have g(x0) = f (x0) −f (x0) and
thus, again by Theorem 10.59, we get

360
10
Introduction to Nonsmooth Optimization Problems
0 ∈∂oh(x0) ⊂conv

∂0 f (x0) ∪∂og(x0)

.
Furthermore, we have
∂og(x0) ⊂conv

∂ogi(x0), i ∈ˆI(x0)

,
where ˆI(x0) =

i ∈{1, . . . , m} : gi(x0) = g(x0)

. Then, due to the deﬁnition of
convex hull, there exist λ0 ≧0 and λi ≧0 for i ∈ˆI(x0), λ0 and λi not all zero, such
that λigi(x0) = 0 for i ∈ˆI(x0) (since gi(x0) = 0) and
0 ∈λ0∂o f (x0) +

i∈ˆI(x0)
λi∂ogi(x0).
The assertion of the theorem is now proved by choosing λi = 0 for i /∈ˆI(x0). □
We now prove for (P4) the Karush-Kuhn-Tucker-type necessary optimality con-
ditions. As usual, to avoid the case λ0 = 0 in the Fritz John conditions, we need a
constraint qualiﬁcation. Let us consider problem (P4), under the same assumptions
as before.
Theorem 10.62 Let x0 ∈K4 be a local minimum point for (P4) and assume that
the following Arrow-Hurwicz-Uzawa constraint qualiﬁcation or Cottle constraint
qualiﬁcation is fulﬁlled:
• There exists v ∈Rn such that go
i (x0; v) < 0, ∀i ∈I (x0) = {i : gi(x0) = 0}.
Then, there exist scalars λi ≧0, i = 1, . . . , m, such that
(i) 0 ∈∂o f (x0) + m
i=1 λi∂ogi(x0);
(ii) λigi(x0) = 0, i = 1, . . . , m.
Proof It is sufﬁcient to show that under the above constraint qualiﬁcation, in the
Fritz John conditions of Theorem 10.61, it holds λ0 ̸= 0 (and hence λ0 = 1). Let us
assume on the contrary that λ0 = 0. We have therefore
0 ∈

i∈I (x0)
λi∂ogi(x0).
Since λ0 = 0 and the multipliers λi, i ∈I (x0), are not all equal to zero, there will
exist at least one i ∈I (x0) such that λi > 0. Also as 0 ∈
i∈I (x0) λi∂ogi(x0), we
see that there exists ξ i ∈∂ogi(x0), i ∈I (x0), such that 
i∈I (x0) λiξ i = 0. Hence,
for any v ∈Rn, we have (
i∈I (x0) λiξ i)⊤v = 0. By assumptions of the theorem,
there exists ¯v ∈Rn such that go
i (x0; ¯v) < 0, i ∈I (x0). Hence, from the deﬁnition
of the Clarke subdifferential, we see that (ξ i)⊤¯v < 0, i ∈I (x0). Again, as there
exists i ∈I (x0) such that λi > 0, we have (
i∈I (x0) λiξ i)⊤¯v < 0, which is clearly

10.2 The Lipschitz Case
361
a contradiction. Hence, we conclude that λ0 ̸= 0 and without loss of generality we
can take λ0 = 1. Putting λi = 0, ∀i /∈I (x0), we get the thesis.
□
Remark 10.63 Hiriart-Urruty [50] has obtained for (P4) “sharper” Fritz John and
Karush-Kuhn-Tucker necessary optimality conditions, in the sense that this author
obtains the following necessary optimality conditions, expressed in terms of the
Clarke subdifferential of the Lagrangian function (recall Theorem 10.47):
0 ∈∂o

λ0 f +
m

i=1
λigi

(x0);
0 ∈∂o

f +
m

i=1
λigi

(x0).
Clarke [20] has obtained a Fritz John-type necessary optimality theorem for a
problem of the type (P5), but with also a set constraint, i.e. for the problem
(P6) :
⎧
⎪⎪⎨
⎪⎪⎩
min f (x)
subject to: gi(x) ≦0, i = 1, . . . , m,
h j(x) = 0, j = 1, . . . , p < n,
x ∈C ⊂X ⊂Rn,
where C is an arbitrary subset of the open set X ⊂Rn and all functions are locally
Lipschitz at the local minimum point x0 of (P6). Clarke uses rather sophisticated
tools, such as the Ekeland variational principle (see [51, 52]). We report the result
of Clarke without proof.
Theorem 10.64 Let x0 be a local solution of (P6). Then there exist multipliers, not
all zero, u0, u1, . . . , um, v1, . . . , vp, such that
0 ∈u0∂o f (x0) +
m

i=1
ui∂ogi(x0) +
p

j=1
v j∂oh j(x0) + N o(C, x0);
uigi(x0) = 0, i = 1, . . . , m;
u0 ≧0, ui ≧0, i = 1, . . . , m.
Under appropriate constraint qualiﬁcations, it is possible to choose, in the above
Fritz John optimality conditions, u0 = 1. In other words, there exists then a set of
multipliers (u1, . . . , um, v1, . . . , vp) ∈Rm+p such that the following Karush-Kuhn-
Tucker conditions hold for (P6) :
0 ∈∂o f (x0) +
m

i=1
ui∂ogi(x0) +
p

j=1
v j∂oh j(x0) + N o(C, x0);

362
10
Introduction to Nonsmooth Optimization Problems
uigi(x0) = 0, i = 1, . . . , m;
ui ≧0, i = 1, . . . , m.
Nguyen et al. [53] consider problem (P6), but with the assumption that the functions
h j(x), j = 1, . . . , p, are continuously differentiable on X. These authors impose
the following constraint qualiﬁcation for (P6) at the optimal point x0.
• (C Q) : The gradients ∇h j(x0), j = 1, . . . , p, are linearly independent and there
exists y0 ∈int(T o(C, x0)) such that go
i (x0; y0) < 0, ∀i ∈I (x0) and ∇h j(x0)⊤
y0 = 0, ∀j = 1, . . . , p.
Under the assumptions of Nguyen, Strodiot, and Mifﬂin, the Karush-Kuhn-Tucker
conditions for (P6) become
0 ∈∂o f (x0) +
m

i=1
ui∂ogi(x0) +
p

j=1
v j∇h j(x0) + N o(C, x0);
uigi(x0) = 0, i = 1, . . . , m;
ui ≧0, i = 1, . . . , m
Let us denote by (x0) ∈Rm+p the set of multipliers (ui, v j), i = 1, . . . , m;
j = 1, . . . , p, which satisfy the above Karush-Kuhn-Tucker-type optimality con-
ditions. The quoted authors prove that if int(T o(C, x0)) ̸= ∅, the condition (C Q),
besides assuring the satisfaction of the above necessary KKT conditions for local
optimality of the feasible point x0 in the problem considered, is both necessary and
sufﬁcient, for (x0) to be a nonempty closed, convex, and bounded set. Hence, the
above constraint qualiﬁcation can be viewed as a nonsmooth generalization of the
Mangasarian-Fromovitz constraint qualiﬁcation, given for the differentiable case. If
there are no equality constraints, then in (C Q) it is possible to replace int(T o(C, x0))
by T o(C, x0) and to delete the assumption that int(T o(C, x0)) ̸= ∅. Note that if C
is open or x0 ∈int(C), then T o(C, x0) = Rn and N 0(C, x0) = {0} .
We have mentioned in Chap. 6 the “enhanced Fritz John conditions” of [54] for
a continuously differentiable optimization problem with mixed constraints and a set
constraint. In [37] it has been obtained the enhanced Fritz John conditions for a
problem of the type (P6), with C an arbitrary convex subset of the open set X ⊂Rn.
We report their result, without proof.
Theorem 10.65 Let us consider problem (P6), where C is a convex subset of the
open set X ⊂Rn and where all functions are locally Lipschitz at x0, with x0 local
solution of the problem. Then, there exist scalars u0 ≧0, u1 ≧0, . . . , um ≧0, v1 ∈
R,. . . , vp ∈R, not all zero, such that
(i) 0 ∈u0∂o f (x0) + m
i=1 ui∂ogi(x0) + p
j=1 v j∂oh j(x0) + N(C, x0);

10.2 The Lipschitz Case
363
(ii) Consider the index sets I = {i : i ̸= 0, ui > 0} and J =

j : v j ̸= 0

. If I ∪
J ̸= ∅, then there exists a sequence

xk
⊂C such that xk →x0 and such that
for all k sufﬁciently large we have f (xk) < f (x0), v jh j(xk) > 0 for all j ∈J
and uigi(xk) > 0 for all i ∈I. We have also
h j(xk)
 = o(w(xk)), ∀j /∈J;
gi(xk)
 = o(w(xk)), ∀i /∈I,
where
w(x) = min

min
i∈I
g+
i (x)
 , min
j∈J
h j(x)


and g+
i (x) = max {gi(x), 0} .
We conclude the present section with some considerations on generalized convex
functions under a Lipschitz assumption. Pseudoconvex and quasiconvex functions
(see Chap. 3) have been extended by various authors to the Lipschitz case; see [23,
37, 55, 56]. See also the useful handbook [57], in particular the contributions of N.
Hadjisavvas and S. Komlosi.
We recall that a differentiable function f : X →R is pseudoconvex on the open
convex set X ⊂Rn if, with x, y ∈X, we have
(y −x)⊤∇f (x) ≧0 ⇒f (y) ≧f (x).
The function f is quasiconvex on X if, with x, y ∈X, we have
f (y) ≦f (x) ⇒(y −x)⊤∇f (x) ≦0.
If f is locally Lipschitz on the open convex set X ⊂Rn, but not necessarily
differentiable, the most natural generalizations of the previous traditional deﬁnitions
are given as follows.
Deﬁnition 10.66 Let f : X →R be a locally Lipschitz function on the open convex
set X ⊂Rn. Then f is said to be Clarke pseudoconvex on X if, with x, y ∈X, we
have
f o(x; y −x) ≧0 ⇒f (y) ≧f (x)
or, equivalently,
f (y) < f (x) ⇒f o(x; y −x) < 0.
Remark 10.67 The previous characterization can be given also in the form: with
x, y ∈X we have

ξ ⊤(y −x) ≧0 for some ξ ∈∂o f (x)

⇒f (y) ≧f (x),

364
10
Introduction to Nonsmooth Optimization Problems
or
f (y) < f (x) ⇒

ξ ⊤(y −x) < 0, ∀ξ ∈∂o f (x)

.
Deﬁnition 10.68 Let f : X →R be a locally Lipschitz function on the open convex
set X ⊂Rn. Then f is said to be Clarke quasiconvex on X if, with x, y ∈X, we
have
f (y) ≦f (x) ⇒f o(x; y −x) ≦0
or, equivalently,
f o(x; y −x) > 0 ⇒f (y) > f (x).
Remark 10.69 The previous characterization can be given also in the form: with
x, y ∈X we have
f (y) ≦f (x) ⇒

ξ ⊤(y −x) ≦0, ∀ξ ∈∂o f (x)

,
or

ξ ⊤(y −x) > 0 for some ξ ∈∂o f (x)

⇒f (y) > f (x).
Bector et al. [37] prove the following two results. We recall that the original deﬁnition
of a quasiconvex function does not require any differentiability assumption (see
Deﬁnition 3.18).
Theorem 10.70 Let f : X →R be locally Lipschitz on the open convex set X ⊂Rn.
Then f is quasiconvex on X if and only if, with x, y ∈X, we have
f (y) < f (x) ⇒

ξ ⊤(y −x) ≦0, ∀ξ ∈∂o f (x)

.
The immediate consequence of the above theorem is that both Clarke pseudo-
convex functions and Clarke quasiconvex functions are quasiconvex functions in the
usual sense.
Theorem 10.71 Let f : X →R be locally Lipschitz on the open convex set X ⊂Rn
and let f be regular (in the sense of Clarke) and quasiconvex on X. Then f is Clarke
quasiconvex on X.
The notion of Clarke pseudoconvexity allows to obtain sufﬁcient optimality con-
ditions for an unconstrained minimization problem involving a locally Lipschitz
function.
Theorem 10.72 If the function f : X →R is Clarke pseudoconvex on the open
convex set X ⊂Rn, then f attains its global minimum at x0 ∈X if and only if
0 ∈∂o f (x0).

10.2 The Lipschitz Case
365
Proof The necessity has already been proved (Theorem 10.56). On the other hand,
if 0 ∈∂o f (x0) and y ∈X, by deﬁnition of Clarke pseudoconvexity we have
f o(x0; y −x0) ≧0⊤(y −x0) = 0 ⇒f (y) ≧f (x0).
□
Example 10.73 ([23]) The function f : R →R deﬁned by f (x) = min
|x| , x2
is
locally Lipschitz, but not convex nor pseudoconvex (it is not everywhere differen-
tiable). However, f is Clarke pseudoconvex and at its global minimum point x0 = 0,
we have ∂o f (x0) = {0} .
It is also possible to give sufﬁcient optimality conditions for a problem of the type
(P2), i.e. with a set constraint, by means of Clarke generalized convex functions. It
is not difﬁcult to prove the following result.
Theorem 10.74 If f : X →R is Clarke pseudoconvex on the open convex set X ⊂
Rn, and C is an arbitrary convex subset of X, then x0 ∈C is a solution of the problem
min f (x) subject to x ∈C,
if and only if
0 ∈∂o f (x0) + N o(C, x).
We recall that, being C convex, we have N o(C, x) = N(C, x).
For sufﬁcient Karush-Kuhn-Tucker conditions in terms of Clarke generalized
derivatives or Clarke subdifferentials, see, e.g. [23, 58, 59].
Finally, we give some insight into the generalization to the Lipschitz case of
the notion of invex functions. We recall (see Deﬁnition 3.33) that invex functions
were introduced by [60] as a generalization of differentiable convex functions: let
X ⊂Rn be an open set and let f : X →R be differentiable on X; if there exists
a vector-valued function, called also “the kernel function”, η(x, y) : X × X →Rn
such that
f (y) −f (x) ≧η(x, y)⊤∇f (x), ∀x, y ∈X,
then f is called invex.
The deﬁnition of invexity can be extended to a function f : X →R, X open
subset of Rn, f locally Lipschitz on X.
Deﬁnition 10.75 A locally Lipschitz function f : X →R is Clarke invex on the
open set X ⊂Rn if there exists a vector-valued function η(x, y) : X × X →Rn
such that
f (y) −f (x) ≧f o(x; η(x, y)), ∀x, y ∈X,
that is, equivalently if
f (y) −f (x) ≧ξ ⊤η(x, y), ∀ξ ∈∂o f (x), ∀x, y ∈X.

366
10
Introduction to Nonsmooth Optimization Problems
We have seen that if f : X →R is a locally Lipschitz function on the open set
X ⊂Rn and x0 ∈X is a local minimum or also a local maximum point of f over
X, then x0 is a Clarke stationary point, i.e.
0 ∈∂o f (x0).
The following result gives a characterization of Clarke invex functions, similar to
the one given in Theorem 4.20 for differentiable functions.
Theorem 10.76 Let f : X →R be locally Lipschitz on the open set X ⊂Rn; then
f is Clarke invex on X if and only if every Clarke stationary point x0 ∈X is a global
minimum point of f over X.
Proof First, assume that every Clarke stationary point x0 ∈X is a global minimum
point of f over X. Let us consider the following two cases.
(1) If x1, x2 ∈X are points such that f (x2) ≧f (x1), it is sufﬁcient to choose
η(x1, x2) = 0.
(2) If x1, x2 ∈X are points such that f (x2) < f (x1), then x1 cannot be a Clarke
stationary point and hence there exists a direction y(x1, x2) ∈Rn such that
f o(x1; y(x1, x2)) < 0.
Deﬁne the function
η(x1, x2) =
f (x2) −f (x1)
f o(x1; y(x1, x2)) y(x1, x2).
Then we have
f o(x1; η(x1, x2)) =
f (x2) −f (x1)
f o(x1; y(x1, x2)) f o(x1; y(x1, x2)) = f (x2) −f (x1).
Therefore, f is Clarke invex with respect to
η(x1, x2) =

0,
if f (x2) ≧f (x1)
f (x2)−f (x1)
f o(x1;y(x1,x2)) y(x1, x2), if f (x2) < f (x1).
The vice versa is quite immediate: if f is invex, then 0 ∈∂o f (x0) implies f (x0) ≦
f (x), ∀x ∈X.
□
Theabovetheoremhasbeenprovedby[58],however,underasuperﬂuousassump-
tion. See also the related papers of [61–65].
Clarke invex functions have been used also to obtain sufﬁcient Karush-Kuhn-
Tucker conditions for an optimization problem with inequality constraints. See, e.g.
[58, 59]. For this type of problems in [66] it has been obtained, by using a class

10.3 The Axiomatic Approach of K.-H. Elster and J. Thierfelder …
367
of functions more general than Clarke invex functions, saddle points conditions and
also some duality results. Consider the problem
(P4) :
⎧
⎨
⎩
min f (x)
subject to: gi(x) ≦0, i = 1, . . . , m,
x ∈X ⊂Rn,
X open set, f : X →R and every gi : X →R,i = 1, . . . , m, locally Lipschitz on X.
Theorem 10.77 Let x0 be feasible for (P4). If the objective function f is Clarke
invex, with respect to a kernel function η(·, ·), and every gi, i = 1, . . . , m, is Clarke
invex, with respect to the same function η(·, ·), and the conditions
(a) 0 ∈∂o f (x0) + m
i=1 λ0
i ∂ogi(x0);
(b) λ0
i gi(x0) = 0, i = 1, . . . , m;
(c) λ0
i ≧0, i = 1, . . . , m,
hold at x0, then x0 is a solution of (P4) and (x0, λ0) is a saddle point of the
Lagrangian function L (x, λ) :
L (x0, λ) ≦L (x0, λ0) ≦L (x, λ0), ∀x ∈X, ∀λ ∈Rm
+.
Conversely,assumethat x0 isasolutionof(P4),that f andevery gi,i = 1, . . . , m,
are Clarke invex with respect to the same kernel function η(·, ·), and that an appro-
priate constraint qualiﬁcation holds (e.g. the Cottle c. q. of Theorem 10.62). Then,
the Karush-Kuhn-Tucker conditions (a), (b), and (c) hold and the pair (x0, λ0) is a
saddle point of the Lagrangian function L (x, λ).
10.3
The Axiomatic Approach of K.-H. Elster and
J. Thierfelder to Nonsmooth Optimization
As we have previously mentioned, starting from the 60s and 70s of the last century,
several mathematicians have studied the possibility to generalize the classical con-
cepts of differentiability (Gâteaux, Fréchet, Hadamard, etc.) in order to treat problems
described by nonsmooth functions. Besides the approaches of Rockafellar to convex
functions and of Clarke to locally Lipschitz functions, it is worth mentioning the
approaches of [4, 13, 47, 67–70] that will not be treated in the present book.
The variety of the various approaches, proposed to study nonsmooth functions and
nonsmooth optimization problems, has led to deﬁne axiomatic constructions which
include, as particular cases, several of the said above approaches. We brieﬂy examine
the axiomatic approach of [7–10], but we point out also the interesting approaches
of [71–73].
The approach of Elster and Thierfelder is based on an axiomatic deﬁnition of
local cone approximation of a set at a point. In some previous chapters and also in

368
10
Introduction to Nonsmooth Optimization Problems
the present chapter we have introduced and used various local cone approximations.
Elster and Thierfelder give the following general axiomatic deﬁnition (they consider
a locally convex Hausdorff space, but we continue to consider the Euclidean space
Rn). See also the papers of [40, 74–77].
Deﬁnition 10.78 A map K : 2Rn × Rn →2Rn is a local cone approximation if for
each set S ⊂Rn and each point x0 ∈Rn a cone K(S, x0) is associated such that the
following properties are fulﬁlled:
1. K(S, x0) = K(S −x0, 0);
2. K(S ∩N(x0, ε), x0) = K(S, x0), ∀ε > 0;
3. K(S, x0) = ∅, ∀x0 /∈cl(S);
4. K(S, x0) = Rn, ∀x0 ∈int(S);
5. K(ϕ(S), ϕ(x0)) = ϕ(K(S, x0)), for any linear homeomorphism ϕ : Rn →Rn;
6. 0+S ⊂0+K(S, x0), ∀x0 ∈cl(S), where
0+S =

y ∈Rn : a + ty ∈S, ∀t > 0, ∀a ∈S

is the recession cone of S (see [2]). Moreover, we set 0+∅= Rn.
Theorem 10.79 The axioms 1–6 are independent, i.e. for each axiom there exists a
map K(·, ·) which fails exactly the said axiom and satisﬁes the remaining axioms.
Almost all local cone approximations used in optimization theory verify the pre-
vious axioms. We give below a list of the most used local cone approximations which
are a particular case of the axiomatic deﬁnition described above (some of these cones
have already been presented and used in the previous chapters). We adopt the various
descriptions in terms of neighborhoods.
Deﬁnition 10.80 Let be S ⊂Rn and x0 ∈Rn.
• The cone
F(S, x0) =

y ∈Rn : ∃δ > 0, ∀t ∈(0, δ) : x0 + ty ∈S

is called cone of feasible directions to S at x0.
• The cone
WF(S, x0) =

y ∈Rn : ∀δ > 0, ∃t ∈(0, δ) : x0 + ty ∈S

is called cone of weakly feasible directions or radial tangent cone to S at x0.
• The cone
T (S, x0) =

y ∈Rn : ∀δ > 0 ∃¯y ∈N(y, δ), ∃t ∈(0, δ) : x0 + t ¯y ∈S

is called Bouligand tangent cone or contingent cone to S at x0.

10.3 The Axiomatic Approach of K.-H. Elster and J. Thierfelder …
369
• The cone
I (S, x0) =

y ∈Rn : ∃δ > 0, ∀¯y ∈N(y, δ), ∀t ∈(0, δ) : x0 + t ¯y ∈S

is called cone of interior directions or cone of interior displacements to S at x0.
• The cone
A(S, x0) =

y ∈Rn : ∀N(y) ∃λ > 0, ∀t ∈(0, λ) ∃¯y ∈N(y) : x0 + t ¯y ∈S

is called cone of attainable directions or Kuhn-Tucker tangent cone or Ursescu
tangent cone [78] to S at x0.
• The cone
Q(S, x0) =

y ∈Rn : ∃N(y), ∀λ > 0, ∃t ∈(0, λ), ∀¯y ∈N(y) : x0 + t ¯y ∈S

is called cone of quasi-interior directions to S at x0.
• The cone
T o(S, x0) =
 y ∈Rn : ∀N(y), ∃N(x0), ∃λ > 0, ∀t ∈(0, λ),
∀¯x ∈N(x0) ∩S ∪

x0
, ∃¯y ∈N(y) : ¯x + t ¯y ∈S

is called Clarke tangent cone to S at x0.
• The cone
H(S, x0) =
 y ∈Rn : ∃N(x0), ∃λ > 0, ∀t ∈(0, λ),
∀¯x ∈N(x0) ∩S ∪

x0
: ¯x + ty ∈S

is called Rockafellar hypertangent cone to S at x0.
• The cone
E(S, x0) =
 y ∈Rn : ∃N(y), ∃N(x0), ∃λ > 0, ∀t ∈(0, λ),
∀¯x ∈N(x0) ∩S ∪

x0
, ∀¯y ∈N(y) : ¯x + t ¯y ∈S

is called cone of epi-Lipschitzian directions to S at x0
Remark 10.81 The descriptions of the cones T o(S, x0), H(S, x0) and E(S, x0)
are slightly different from the original deﬁnitions (see, e.g. [79]), where the point
¯x belongs to the set S ∩N(x0). The present description, taken from [7–9], allows
to verify the third axiom of Deﬁnition 10.78. However, the consideration of the set
S ∩N(x0) ∪

x0
does not involve the original behavior of the map. More precisely,
in [38] it has been shown that if x0 ∈cl(S), the descriptions given in Deﬁnition 10.80
for T o(S, x0), H(S, x0) and E(S, x0) coincide with the original deﬁnitions.
For a quick overview of the main properties of the cones previously deﬁned, it is
useful in the following scheme.

370
10
Introduction to Nonsmooth Optimization Problems
E(S, x0) ⊂I (S, x0) ⊂Q(S, x0)
∩
∩
∩
H(S, x0) ⊂F(S, x0) ⊂WF(S, x0)
∩
∩
∩
T o(S, x0) ⊂A(S, x0) ⊂T (S, x0)
With regard to this scheme, the following assertions hold true.
• The cones of the ﬁrst row are open and it holds
x0 ∈int(S) ⇔0 ∈K(S, x0).
The cones of the third row are closed and it holds
x0 ∈cl(S) ⇔0 ∈K(S, x0).
The cones of the second row verify the property
x0 ∈S ⇔0 ∈K(S, x0).
• The cones of the ﬁrst column are convex; the cones of the second and third column
are isotone, i.e.
S1 ⊂S2 =⇒K(S1, x0) ⊂K(S2, x0), ∀x0 ∈Rn.
By means of the axiomatic characterization of a local cone approximation, always
following [8, 9], but see also [75, 76], it is possible to give the following deﬁnition
of generalized directional derivative.
Deﬁnition 10.82 Let be f : Rn →[−∞, +∞], x0 ∈Rn such that
 f (x0)
 < +∞
and K(·, ·) a local cone approximation, according to Deﬁnition 10.78. Then the
function f K(x0; ·) : Rn →[−∞, +∞] deﬁned by
f K(x0; y) = inf

β ∈R : (y, β) ∈K(epi( f ), (x0, f (x0)))

, ∀y ∈Rn,
is called the K-directional derivative of f at x0. It is assumed inf(∅) = +∞.
It is worth noting that in [80] it was perhaps noticed by ﬁrst time the connection
between the Dini directional derivatives and an appropriate local cone approximation
of the epigraph of f at (x0, f (x0)). It is quite immediate to remark that f K(x0; ·) is
positively homogeneous. Moreover, it can be proved that the topological properties
of the local cone approximation K(·, ·) are reﬂected on the K-directional derivatives,
as described in the following theorem, given in [9].

10.3 The Axiomatic Approach of K.-H. Elster and J. Thierfelder …
371
Theorem 10.83 Let be f : Rn →R, x0 ∈Rn and K(·, ·) a local cone approxima-
tion. Then:
(i) If K(epi( f ), (x0, f (x0))) is convex, then f K(x0; ·) is sublinear.
(ii) It holds
epi( f K (x0; ·)) =

(y, β) ∈Rn × R : ∀ε > 0, (y, β + ε) ∈K(epi( f ), (x0, f (x0)))

.
In particular, if K(epi( f ), (x0, f (x0))) is closed, it holds
epi( f K(x0; ·)) = K(epi( f ), (x0, f (x0)))
and f K(x0; ·) is lower semicontinuous.
(iii) It holds
epio( f K (x0; ·)) =

(y, β) ∈Rn × R : ∀ε > 0, (y, β −ε) ∈K(epi( f ), (x0, f (x0)))

,
where
epio( f K(x0; ·)) =

(y, β) : f K(x0; y) < β

is the strict epigraph of the K-directional derivative.
In particular, if K(epi( f ), (x0, f (x0))) is open, it holds
epio( f K(x0; ·)) = K(epi( f ), (x0, f (x0)))
and f K(x0; ·) is upper semicontinuous.
BymeansofDeﬁnition10.82itispossibletogetafamilyofgeneralizeddirectional
derivatives. In particular, if we make use of the local cone approximations previously
recalled, we obtain the following results. We use the following notations, taken from
[69, 70]:
(¯x, α) ↓x0 ⇔(¯x, α) →(x0, f (x0)) and α ≧f (¯x);
(¯x, α) ↑x0 ⇔(¯x, α) →(x0, f (x0)) and α ≦f (¯x);
¯x →f x0 ⇔(¯x, f (¯x)) →(x0, f (x0)).
Also the deﬁnitions of “lim sup inf” and “lim inf sup” operations are taken from
[69, 70]. Let g : Rn →[−∞, +∞] and h : Rn × Rm →[−∞, +∞] extended real-
valued functions. We have
lim inf
¯y→y
g( ¯y) = sup
U(y)
inf
¯y∈U(y)g( ¯y);
lim sup
¯y→y
g( ¯y) = inf
U(y)
sup
¯y∈U(y)
g( ¯y);

372
10
Introduction to Nonsmooth Optimization Problems
lim sup inf
¯z→z, ¯y→y
h( ¯y, ¯z) = sup
U1(y)
inf
U2(z)
sup
¯z∈U2(z)
inf
¯y∈U1(y)h( ¯y, ¯z);
lim inf sup
¯z→z, ¯y→y
h( ¯y, ¯z) = inf
U1(y) sup
U2(z)
inf
¯z∈U2(z)
sup
¯y∈U1(y)
h( ¯y, ¯z).
Let be f : Rn →[−∞, +∞] and x0 ∈Rn. Then:
• The lower Dini-Hadamard directional derivative at x0 in the direction y ∈Rn is
fH(x0; y) = f T (x0; y) =
lim inf
( ¯y,t)→(y,0+)
f (x0 + t ¯y) −f (x0)
t
.
• The upper Dini-Hadamard directional derivative at x0 in the direction y ∈Rn is
f H(x0; y) = f I(x0; y) =
lim sup
( ¯y,t)→(y,0+)
f (x0 + t ¯y) −f (x0)
t
.
• The lower Dini directional derivative at x0 in the direction y ∈Rn is
fD(x0; y) = f WF(x0; y) = lim inf
t→0+
f (x0 + ty) −f (x0)
t
.
• The upper Dini directional derivative at x0 in the direction y ∈Rn is
f D(x0; y) = f F(x0; y) = lim sup
t→0+
f (x0 + ty) −f (x0)
t
.
• The lower Ursescu directional derivative at x0 in the direction y ∈Rn is
f A(x0; y) = lim sup inf
t→0+, ¯y→y
f (x0 + t ¯y) −f (x0)
t
.
• The upper Ursescu directional derivative at x0 in the direction y ∈Rn is
f Q(x0; y) = lim inf sup
t→0+, ¯y→y
f (x0 + t ¯y) −f (x0)
t
.
• The Clarke generalized directional derivative at x0 in the direction y ∈Rn is
f o(x0; y) = f H(x0; y) =
lim sup
(¯x,α)↓x0, t→0+
f (¯x + ty) −α
t
.
Here H is the hypertangent cone (do not make confusion with the upper Dini-
Hadamard directional derivative!).

10.3 The Axiomatic Approach of K.-H. Elster and J. Thierfelder …
373
• The Clarke-Rockafellar generalized directional derivative at x0 in the direction
y ∈Rn is
f ↑(x0; y) = f T o(x0; y) =
lim sup inf
(¯x, α) ↓x0, ¯y →y
t →0+
f (¯x + t ¯y) −α
y
.
• The epi-Lipschitzian directional derivative at x0 in the direction y ∈Rn is
f E(x0; y) =
lim sup
(¯x, α) ↓x0, ¯y →y
t →0+
f (¯x + t ¯y) −α
y
.
Remark 10.84 When f is lower semicontinuous, the convergence (¯x, α) ↓x0
becomes simply ¯x →f x0 and, moreover, if f is continuous, it becomes ¯x →x0.
If f is locally Lipschitz, then:
(a)
f o(x0; y) = f ↑(x0; y) =
lim sup
x→x0, t→0+
f (¯x + ty) −f (¯x)
t
,
i.e. we obtain the usual Deﬁnition 10.34 of the Clarke directional derivative.
(b)
f U(x0; ·) = fD(x0; y) = fH(x0; y).
(c)
f Q(x0; y) = f D(x0; y) = f H(x0; y).
It follows that f is (right-sided) directionally differentiable at x0 in the direction
y ∈Rn if and only if
f WF(x0; y) = f F(x0; y).
Moreover, f is Gâteaux differentiable at x0 if and only if
f WF(x0; ·) = f F(x0; ·)
is linear.
Similar to the inclusion scheme concerning the various local cone approxima-
tions, we obtain the following scheme showing the relationships between the various
generalized directional derivatives previously considered.

374
10
Introduction to Nonsmooth Optimization Problems
f E(x0; ·) ≧f H(x0; ·) ≧f Q(x0; ·)
∥∨
∥∨
∥∨
f o(x0; ·) ≧f D(x0; ·) ≧fD(x0; ·)
∥∨
∥∨
∥∨
f ↑(x0; ·) ≧f A(x0; ·) ≧fH(x0; ·)
The following assertions hold true.
(1) The directional derivatives of the ﬁrst row of the scheme are upper semicontin-
uous and it holds
f K(x0; 0) ≧0.
The directional derivatives of the third row of the scheme are lower semicontin-
uous and it holds
f K(x0; 0) ≦0.
For the directional derivatives of the second row of the scheme, it holds
f K(x0; 0) = 0.
(2) The directional derivatives of the ﬁrst column of the scheme are convex (more
precisely: sublinear). The directional derivatives of the second and third column
are isotone, in the sense that they verify the following property:
f1(·) ≦f2(·)
f1(x0) = f2(x0)

⇒f K
1 (x0; ·) ≦f K
2 (x0; ·).
In a similar way with respect to the deﬁnition of K-directional derivative, it is possible
to introduce the concept of K-subdifferential.
Deﬁnition 10.85 Let be f : Rn →R, x0 ∈Rn and K(x0, ·) be a local cone approx-
imation. The set (possibly empty)
∂K f (x0) =

ξ ∈Rn : f K(x0; y) ≧ξ ⊤y, ∀y ∈Rn
is said the K-subdifferential of f at x0 and the elements ξ ∈∂K f (x0) are said the
K-subgradients of f at x0.
Note that 0 ∈∂K f (x0) if and only if f K(x0; y) ≧0, ∀y ∈Rn. When ∂K f (x0) ̸=
∅, then ∂K f (x0) is a closed and convex set. As the K-directional derivative of f is
directly related to the local cone approximation K(·, ·) of its epigraph, something
similar holds true also for the K-subdifferential.
Theorem 10.86 Let be f : Rn →R, x0 ∈Rn and K(x0, ·) a local cone approxi-
mation. Then it holds
∂K f (x0) =

ξ ∈Rn : (ξ, −1) ∈K ∗(epi( f ), (x0, f (x0)))

,

10.3 The Axiomatic Approach of K.-H. Elster and J. Thierfelder …
375
where K ∗is the polar cone of K.
Proof We have the following chain of equivalences:
ξ ∈∂K f (x0) ⇔inf

β ∈R : (y, β) ∈K(epi( f ), (x0, f (x0)))

≧ξ ⊤y, ∀y ∈Rn
⇔β ≧ξ ⊤y, ∀(y, β) ∈K(epi( f ), (x0, f (x0)))
⇔(ξ, −1)⊤(y, β) ≦0, ∀(y, β) ∈K(epi( f ), (x0, f (x0)))
⇔(ξ, −1) ∈K ∗(epi( f ), (x0, f (x0))).
□
Now we consider brieﬂy some optimality conditions expressed in terms of K-
directional derivatives. We begin with an unconstrained minimization problem.
Theorem 10.87 Let be f : X ⊂Rn →R and let x0 ∈int(X) be a local minimum
point of f over X. If K(·, ·) is any local cone approximation such that K(·, ·) ⊂
T (·, ·), then it holds
(i)
f K(x0; y) ≧0, ∀y ∈Rn;
(ii) 0 ∈∂K f (x0).
Proof (i) Let us assume f K(x0; y) < 0 for a vector y ∈Rn. Then, because K(·, ·) ⊂
T (·, ·), we have
f T (x0; y) ≦f K(x0; y) < 0
and hence
lim inf
¯y→y, t→0+
f (x0 + t ¯y) −f (x0)
t
< 0,
which means ∀N(y), ∀λ > 0, ∃t ∈(0, λ), ∃¯y ∈N(y) :
f (x0 + t ¯y) −f (x0)
t
< 0,
which contradicts the assumption that x0 is an unconstrained local minimum point
of f.
(ii) The assertion follows from Deﬁnition 10.85.
□
For example, we have, under the assumptions of Theorem 10.87,
f F(x0; y) = f D(x0; y) = lim sup
t→0+
f (x0 + ty) −f (x0)
t
≧0, ∀y ∈Rn,
or also the sharper condition

376
10
Introduction to Nonsmooth Optimization Problems
f WF(x0; y) = fD(x0; y) = lim inf
t→0+
f (x0 + ty) −f (x0)
t
≧0, ∀y ∈Rn,
or also, in terms of upper Hadamard directional derivatives,
f I(x0; y) = f H(x0; y) =
lim sup
( ¯y,t)→(y,0+)
f (x0 + t ¯y) −f (x0)
t
≧0, ∀y ∈Rn,
or also the sharper condition
f T (x0; y) = fH(x0; y) =
lim inf
( ¯y,t)→(y,0+)
f (x0 + t ¯y) −f (x0)
t
≧0, ∀y ∈Rn.
Now we consider a minimization problem of the type (P2), i.e. with a set con-
straint, and of type (P4), i.e. with inequality constraints. First, we introduce the
following sets.
• The cone of descent directions of f at x0 is:
DK
f (x0) =

y ∈Rn : f K(x0; y) < 0

.
• The linearizing cone of f at x0 is:
C K
f (x0) =

y ∈Rn : f K(x0; y) ≦0

.
• DK
M(x0) = ∩
i∈MDK
gi (x0).
• C K
M(x0) = ∩
i∈MC K
gi (x0).
Where M = {1, . . . , m}.
Obviously, these cones are convex, if K(x0; ·) is convex.
In the following, we assume, when it is necessary, that the local cone approxima-
tion K(·, ·) satisﬁes the following conditions.
(A1) K is convex and closed.
(A2) z ∈S ⇔0 ∈K(S, z).
(A3) K(·, ·) ⊂T (·, ·).
(A4) int(K(·, ·)) ⊂I (·, ·).
Let us consider problem (P2) :
min f (x), x ∈S ⊂Rn.
Theorem 10.88 If x0 ∈S is a local solution of (P2) and K(·, ·) satisﬁes conditions
(A3) and (A4), then
(i) Dint(K)
f
(x0) ∩K(S, x0) = ∅;
(ii) DK
f (x0) ∩int(K(S, x0)) = ∅.

10.3 The Axiomatic Approach of K.-H. Elster and J. Thierfelder …
377
Theorem 10.89 If x0 ∈S is a local solution of (P2), if (A1), (A3) and (A4) are
veriﬁed, and if one of the following conditions is veriﬁed:
(B1) dom( f int(K)(x0; ·)) ∩K(S, x0) = ∅;
(B2) dom( f K(x0; ·)) ∩int(K(S, x0)) = ∅,
then it holds
0 ∈∂K f (x0) + K ∗(S, x0).
Now let us consider problem (P4), i.e.
(P4) :
⎧
⎨
⎩
min f (x)
subject to: gi(x) ≦0, i = 1, . . . , m,
x ∈X ⊂Rn,
with X open set of Rn. In order to avoid confusion with the cones K(·, ·), we denote
by S4 the feasible set of (P4). [9] obtain for (P4) the following Karush-Kuhn-Tucker-
type necessary optimality conditions.
Theorem 10.90 Let x0 ∈S4 be a local solution of (P4) and let (A1), (A3), (A4),
either (B1) or (B2) be veriﬁed. Moreover, the following constraint qualiﬁcation is
satisﬁed:
(C Q)1 :
K ∗(S4, x0) ⊂B K
I (x0)(x0),
where
B K
I (x0)(x0) =
⎧
⎨
⎩ξ ∈Rn : ξ =

i∈I (x0)
λiξ i, λi ≧0, ξ i ∈∂K gi(x0), i ∈I (x0)
⎫
⎬
⎭
is the convex cone generated by K-gradients of gi, i ∈I (x0), at x0.
Then, there exist multipliers λi ≧0, i ∈I (x0), such that
(i) 0 ∈∂K f (x0) + 
i∈I (x0) λi∂K gi(x0);
(ii)
f K(x0; y) + 
i∈I (x0) λigK
i (x0; y) ≧0, ∀y ∈Rn.
Let us now consider the following further constraint qualiﬁcations (x0 ∈S4).
• (C Q)2. Generalized Guignard-Gould-Tolle constraint qualiﬁcation:
(K(S4, x0))∗⊂(C K
I (x0)(x0))∗,
∂K gi(x0) ̸= ∅, ∀i ∈I (x0),
B K
I (x0)(x0) closed, either (B1) or (B2).
• (C Q)3. Generalized Abadie constraint qualiﬁcation:

378
10
Introduction to Nonsmooth Optimization Problems
C K
I (x0)(x0) ⊂K(S4, x0),
∂K gi(x0) ̸= ∅, ∀i ∈I (x0),
B K
I (x0)(x0) closed, either (B1) or (B2).
• (C Q)4. First generalized Slater constraint qualiﬁcation:
Dint(K)
I (x0) (x0) ̸= ∅, ∂K gi(x0) ̸= ∅, ∀i ∈I (x0),
B K
I (x0)(x0) closed, either (B1) or (B2).
(C Q)5. Second generalized Slater constraint qualiﬁcation:
dom( f K(x0, ·)) ∩Dint(K)
I (x0) (x0) ̸= ∅,
∂K gi(x0) ̸= ∅, ∀i ∈I (x0), B K
I (x0)(x0) closed.
We have the following result.
Theorem 10.91 ([9]) Let be x0 ∈S4 and let conditions (A1) −(A4) be veriﬁed.
Moreover, let be veriﬁed the condition
(A5) :
DK
I (x0)(x0) ⊂K(S4, x0).
Then we have the following implications:
(C Q)5 ⇒(C Q)4 ⇒(C Q)3 ⇒(C Q)2 ⇒(C Q)1.
The same authors obtain also Fritz John-type optimality conditions for (P4) in
terms of K-directional derivatives.
Theorem 10.92 Let x0 ∈S4 be a local solution of (P4) and let the conditions (A1) −
(A5) be veriﬁed. Then:
(i) There exist multipliers λi ≧0, i ∈{0} ∪I (x0), not all zero, such that
λ0 f int(K)(x0; y) +

i∈I (x0)
λigK
i (x0; y) ≧0,
∀y ∈dom( f int(K)(x0; ·)) ∩
∩
i∈I (x0) dom(gK
i (x0; ·)).
(ii) There exist multipliers λ′
i ≧0, i ∈{0} ∪I (x0), not all zero, such that
λ′
0 f K(x0; y) +

i∈I (x0)
λ′
igint(K)
i
(x0; y) ≧0,

References
379
∀y ∈dom( f K(x0; ·)) ∩
∩
i∈I (x0) dom(gint(K)
i
(x0; ·)).
Under other appropriate conditions, the same authors obtain the following version
of the Fritz John necessary optimality conditions for (P4) :
• There exist multipliers u0 ≧0, ui ≧0, not all zero, such that
u0 f K(x0; y) +

i∈I (x0)
uigK
i (x0; y) ≧0, ∀y ∈Rn;
0 ∈u0∂K f (x0) +

i∈I (x0)
ui∂K gi(x0).
Under an appropriate constraint qualiﬁcation, it is possible to obtain u0 ̸= 0, i.e.
u0 = 1, in the above conditions.
References
1. J.-J. Moreau, Fonctionelles sous-différentiables, C. R. Acad. Sci. Paris. Sér. A-B 257, 4117–
4119 (1963)
2. R.T. Rockafellar, Convex Analysis (Princeton University Press, Princeton, 1970)
3. A.D. Ioffe, V.M. Tichomirov, Theory of Extremal problems (North Holland, Amsterdam,
1979)
4. B.N. Pshenichnyi, Necessary Conditions for an Extremum (Marcel Dekker, New York, 1971)
5. J.M. Danskin, The Theory of Max-Min and Its Application to Weapons Allocation Problems
(Springer, New York, 1967)
6. V.F. Demyanov, V.N. Malozemov, Introduction to Minimax (Wiley, New York, 1974)
7. K.-H. Elster, J. Thierfelder, The general concept of cone approximations in nondifferen-
tiable optimization, in Nondifferentiable Optimization. ed. by V.F. Demyanov, D. Pallaschke
(Springer Verlag, Berlin, Motivations and Applications, 1985), pp.170–189
8. K.-H. Elster, J. Thierfelder, On cone approximations and generalized directional derivatives,
in Nonsmooth Optimization and Related Topics. ed. by V.F. Demyanov, F. Giannessi (Plenum
Press, New York, 1988), pp.133–154
9. K.-H. Elster, J. Thierfelder, Abstract cone approximations and generalized differentiability in
nonsmooth optimization. Optimization 19, 315–341 (1988)
10. K.-H. Elster, J. Thierfelder, Generalized notions of directional derivatives. Quaderni della
Sezione di Matematica Applicata, Gruppo di Ottimizzazione e Ricerca Operativa, Università
di Pisa, no. 155 (1989)
11. W. Fenchel, Convex Cones, Sets and Functions, Lecture Notes (Princeton University, 1953)
12. A.W. Roberts, D.E. Varberg, Convex Functions (Academic, New York, 1973)
13. V.F. Demyanov, A.M. Rubinov, Constructive Nonsmooth Analysis (Verlag Peter Lang, Frank-
furt a.M., 1995)
14. A. Ben-Tal, J. Zowe, Directional derivatives in nonsmooth optimization. J. Optim. Theory
Appl. 47, 483–490 (1985)
15. L. Qi, On an extended Lagrange claim. J. Optim. Theory Appl. 108, 685–688 (2001)
16. M. Durea, R. Strugariu, An Introduction to Nonlinear Optimization Theory (De Gruyter Open
Ltd., Warsaw/Berlin, 2014)

380
10
Introduction to Nonsmooth Optimization Problems
17. S. Schaible, Second-order characterizations of pseudoconvex quadratic functions. J. Optim.
Theory Appl. 21, 15–26 (1977)
18. M. Schechter, More on subgradient duality. J. Math. Anal. Appl. 71, 251–262 (1979)
19. F.H. Clarke, Generalized gradients and applications. Trans. Amer. Math. Soc. 205, 247–262
(1975)
20. F.H. Clarke, A new approach to Lagrange multipliers. Math. Oper. Res. 1, 165–174 (1976)
21. F.H. Clarke, Optimization and Nonsmooth Analysis (Wiley, New York, 1983)
22. Q.H. Ansari, C.S. Lalitha, M. Mehta, General Convexity, Nonsmooth Variational Inequalities
and Nonsmooth Optimization (CRC Press, Boca Raton, 2014)
23. A. Bagirov, N. Karmitsa, M.M. Mäkelä, Introduction to Nonsmooth Optimization (Springer,
Heidelberg, 2014)
24. J.M. Borwein, A.S. Lewis, Convex Analysis and Nonlinear Optimization (Springer, New York,
2000)
25. F.H. Clarke, V.F. Demyanov, F. Giannessi, Nonsmooth Optimization and Related Topics
(Plenum Pub. Corp, New York, 1989)
26. F.H. Clarke, Y.S. Ledyaev, R.J. Stern, P.R. Wolenski, Nonsmooth Analysis and Control Theory
(Springer, New York, 1998)
27. V.F. Demyanov, P.M. Pardalos, M. Batsyn, Constructive Nonsmooth Analysis and Related
Topics (Springer, New York, 2014)
28. J. Ferrera, An Introduction to Nonsmooth Analysis (Academic, New York, 2014)
29. G. Giorgi, A. Guerraggio, J. Thierfelder, Mathematics of Optimization: Smooth and Nons-
mooth Case (Elsevier, Amsterdam, 2004)
30. J. Gwinner, Bibliography on non-differentiable optimization and nonsmooth analysis. J. Com-
put. Appl. Math. 7, 277–285 (1981)
31. J.-B. Hiriart-Urruty, Miscellanies on nonsmooth analysis and optimization, in Nondifferen-
tiable Optimization: Motivations and Applications. ed. by V.F. Demyanov, D. Pallaschke
(Springer, Berlin, 1985), pp.8–24
32. J.P. Penot, Calculus Without Derivatives (Springer, New York, 2013)
33. R.T. Rockafellar, R.J.-B. Wets, Variational Analysis (Springer, Berlin, 2009)
34. J. O. Royset, R. J.-B. Wets, An Optimization Primer (Springer, New York, 2022)
35. W. Schirotzek, Nonsmooth Analysis (Springer, Berlin, 2007)
36. K. Shimitzu, Y. Ishizuka, J.F. Bard, Nondifferentiable and Two-Level Math. Program (Kluwer
Academic Publishers, Boston, 1997)
37. C.R. Bector, S. Chandra, J. Dutta, Principles of Optimization Theory (Alpha Science Inter-
national Ltd., Harrow, U.K., 2005)
38. G. Giorgi, A. Guerraggio, On a characterization of Clarke’s tangent cone. J. Optim. Theory
Appl. 74, 369–372 (1992)
39. G. Giorgi, A. Guerraggio, On the notion of tangent cone in mathematical programming.
Optimization 25, 11–23 (1992)
40. G. Giorgi, A. Guerraggio, Characterizations, computations, algebraic and topological prop-
erties of tangent cones. J. Stat. Manag. Syst. 5, 275–294 (2002)
41. M.S. Bazaraa, C.M. Shetty, Foundations of Optimization, Lecture Notes in Economics and
Mathematical Systems, vol. 122, (Springer, Berlin, 1976)
42. G. Giorgi, S. Komlosi, Dini derivatives in optimization—Part I. Riv. Mat. Sci. Econom. Social.
15(1), 3–30 (1993)
43. G. Giorgi, S. Komlosi, Dini derivatives in optimization—Part II. Riv. Mat. Sci. Econom.
Social. 15(2), 3–24 (1993)
44. G. Giorgi, S. Komlosi, Dini derivatives in optimization—Part III. Riv. Mat. Sci. Econom.
Social. 18(1), 47–63 (1995)
45. B. Jiménez, V. Novo, Alternative theorems and necessary optimality conditions for direction-
ally differentiable multiobjective programs. J. Convex Anal. 9(1), 97–116 (2002)
46. A. Cambini, L. Martein, Generalized Convexity and Optimization (Springer, Berlin, Theory
and Applications, 2009)

References
381
47. B.S. Mordukhovich, Variational Analysis and Generalized Differentiation, vol. 1, 2 (Springer,
Berlin, 2006)
48. J.-B. Hiriart-Urruty, On optimality conditions in nondifferentiable programming. Math. Pro-
gram. 14, 73–86 (1978)
49. M. Castellani, M. Pappalardo, First-order cone approximations and necessary optimality con-
ditions. Optimization 35, 113–126 (1995)
50. J.-B. Hiriart-Urruty, Reﬁnements of necessary optimality conditions in nondifferentiable pro-
gramming I. Appl. Math. Optim. 5, 63–82 (1979)
51. I. Ekeland, On the variational principle. J. Math. Anal. Appl. 47, 324–353 (1974)
52. J.-B. Hiriart-Urruty, A short proof of the variational principle for approximate solutions of a
minimization problem. Am. Math. Mon. 90, 206–207 (1983)
53. V.H. Nguyen, J.-J. Strodiot, R. Mifﬂin, On conditions to have bounded multipliers in locally
Lipschitz programming. Math. Program. 18, 100–106 (1980)
54. D.P. Bertsekas, A.E. Ozdaglar, Pseudonormality and Lagrange multiplier theory for con-
strained optimization. J. Optim. Theory Appl. 114, 287–343 (2002)
55. B.M. Glover, Generalized convexity in nondifferentiable programming. Bull. Austral. Math.
Soc. 30, 193–218 (1984)
56. M. Soleiman-Damaneh, Characterization of nonsmooth quasiconvex and pseudoconvex func-
tions. J. Math. Anal. Appl. 330, 1387–1392 (2007)
57. N. Hadjisavvas, S. Komlosi, S. Schaible (eds.), Handbook of Generalized Convexity and
Generalized Monotonicity (Springer, New York, 2005)
58. T.W. Reiland, Nonsmooth invexity. Bull. Austral. Math. Soc. 42, 437–446 (1990)
59. R.N. Kaul, S.K. Suneja, C.S. Lalitha, Generalized nonsmooth invexity. J. Inf. Optim. Sci. 15,
1–17 (1994)
60. M.A. Hanson, On sufﬁciency of the Kuhn-Tucker conditions. J. Math. Anal. Appl. 80, 545–
550 (1981)
61. E. Caprari, ρ-invex functions and (F, ρ) -convex functions: properties and equivalences.
Optimization 52, 65–74 (2003)
62. G. Giorgi, A. Guerraggio, Various types of nonsmooth invex functions. J. Inf. Optim. Sci. 17,
137–150 (1996)
63. T.D. Phuong, P.H. Sach, N.D. Yen, Strict lower semicontinuity of the level sets and invexity
of a locally Lipschitz function. J. Optim. Theory Appl. 87, 579–594 (1995)
64. Y. Tanaka, M. Fukushima, T. Ibaraki, On generalized pseudoconvex functions. J. Math. Anal.
Appl. 144, 342–355 (1989)
65. Y. Tanaka, Note on generalized convex functions. J. Optim. Theory Appl. 66, 345–349 (1990)
66. V. Jeyakumar, Equivalence of saddle-points and optima, and duality for a class of non-smooth
non-convex problems. J. Math. Anal. Appl. 130, 334–343 (1988)
67. V.F. Demyanov, L.C.W. Dixon (eds.), Quasidifferential Calculus. Math. Program Study 29
(1986)
68. V.F. Demyanov, A.M. Rubinov (eds.), Quasidifferentiability and Related Topics. (Kluwer
Academic Publishers, Dordrecht/Boston/London, 2000)
69. R.T. Rockafellar, Generalized directional derivatives and subgradients of nonconvex func-
tions. Canad. J. Math. 32, 257–280 (1980)
70. R.T. Rockafellar, The Theory of Subgradients and Its Applications to Problems of Optimiza-
tion: Convex and Nonconvex Functions (Heldermann-Verlag, Berlin, 1981) (French version:
La Théorie des Sous-gradients et ses Applications àl’Optimization, Les Presses de L’université
de Montréal, Montréal)
71. F. Giannessi, Semidifferentiable functions and necessary optimality conditions. J. Optim.
Theory Appl. 60, 191–241 (1989)
72. F. Giannessi, Constrained Optimization and Image Space Analysis. Vol. 1: Separation of Sets
and Optimality Conditions (Springer, New York, 2005)
73. S. Komlosi, M. Pappalardo, A general scheme for ﬁrst order approximations in optimization.
Optim. Methods Softw. 3, 143–152 (1994)

382
10
Introduction to Nonsmooth Optimization Problems
74. A.D. Ioffe, On the theory of subdifferential, in Fermat-days 85: Mathematics for Optimization.
ed. by J.-B. Hiriart-Urruty (North Holland, Amsterdam, 1986), pp. 183–200
75. D.E. Ward, Isotone tangent cones and nonsmooth optimization. Optimization 18, 769–783
(1987)
76. D. Ward, The quantiﬁcational tangent cones. Canad. J. Math. 40, 666–694 (1988)
77. D.E. Ward, Directional derivative calculus and optimality conditions in nonsmooth mathe-
matical programming. J. Inf. Optim. Sci. 10, 81–96 (1989)
78. C. Ursescu, Tangent set’s calculus and necessary conditions for extremality. SIAM J. Control
Optim. 20, 563–574 (1982)
79. J.P. Aubin, H. Frankowska, Set-Valued Analysis (Birkhäuser, Boston, 1990)
80. M.S. Bazaraa, J.J. Goode, Extensions of optimality conditions via supporting functions. Math.
Program. 5, 267–285 (1973)

Chapter 11
Introduction to Multiobjective
Optimization
Frequently, optimization problems appear in any technique or scientiﬁc activity, and
the optimal decisions have traditionally attended to a unique criterion. However, in
areas such as Economics, Social Sciences, Engineering, or Industry it is usually nec-
essary to consider multiple objectives, confronted each other, that requires the use of
decision techniques based on a ﬁnite number of objectives or criteria (multiobjective
optimization or multicriteria decision), on a nonﬁnite number (vector optimization)
or even on the resolution of problems in which the aim is to optimize a set-valued
function. This fact has motivated the creation of mathematical theories, which are
currently in process of development. To expand knowledge of this area, the inter-
ested reader can consult the monographs by Ehrgott [1], Miettinen [2] and Sawaragi,
Nakayama and Tanino [3] in ﬁnite-dimensional spaces, and Jahn [4] and Luc [5] in
inﬁnite-dimensional spaces.
From the historical point of view, it seems that the ﬁrst to deal with multiobjective
problems were Francis Y. Edgeworth (1845–1926) and Vilfredo Pareto (1848–1923).
In 1881 at King’s College (London) and later at Oxford, economics professor Edge-
worth was the ﬁrst to deﬁne an optimum for multicriteria economic decision-making
[6], and he did so for a two-criteria problem. Pareto, graduated from the University
of Turin in 1870 with a degree in Civil Engineering, while working in Florence as a
civil engineer (1870-1893), was one of the ﬁrst to analyze economic problems with
mathematical tools. In 1893, he assumed the chair of Political Economy at the Uni-
versity of Lausanne, where he created one of his most famous theories, The Pareto
Optimum [7]: “The optimal allocation of the resources of a society is not achieved
while it is possible to make at least one individual better in his own estimation while
maintaining others as well as before”.
The translation of Pareto’s work into English, in 1971, prompted the development
of multiobjective methods in Applied Mathematics and Engineering. The growth of
this ﬁeld was particularly strong in the United States with pioneering contributions,
among others, by Stadler [8] and Steuer [9], and in the publication of two books
already focused on the theoretical aspects of multiobjective optimization, those by
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2023
G. Giorgi et al., Basic Mathematical Programming Theory, International Series
in Operations Research & Management Science 344,
https://doi.org/10.1007/978-3-031-30324-1_11
383

384
11
Introduction to Multiobjective Optimization
Sawaragi et al. [3] and Luc [5] in the vectorial case, without forgetting the famous
work by Kuhn and Tucker [10]. In the last decades, the applications of multiobjective
optimization have grown steadily in many areas.
Multiobjective optimization methods can be broken down into different cate-
gories, but as a ﬁrst approximation we can speak of two approaches, the scalarization
approach and the Pareto approach. In the ﬁrst group of methods, the multiobjective
problem is solved by translating it into a single objective problem, that is, a scalar
problem. Pareto methods keep the initial elements in their vector framework and
use some concept of dominance based on a preference relation to compare possible
solutions.
11.1
Optimality Notions
We are interested in the following multiobjective optimization problem
(M P1)
min [ f1(x), . . . , fq(x)]⊤subject to x ∈S,
where fk : X ⊂Rn →R, k = 1, . . . , q, are the objective functions, X is an open
set, S ⊂X is an arbitrary nonempty subset, called the feasible set; Rn and Rq
are called decision space and objective space, respectively. We denote f (x) =
[ f1(x), . . . , fq(x)]⊤which is called the objective function.
The ﬁrst thing we have to do is to say what means “min” in (M P1). For this
purpose, we consider that in Rq the order is given componentwise. For x, y ∈Rq we
write x ≦y if xk ≦yk, for k = 1, . . . , q, and x < y if xk < yk, for k = 1, . . . , q.
We denote Rq
+ = {y ∈Rq : yk ≧0, k = 1, . . . , q}, and Rq
++ = int(Rq
+) = {y ∈
Rq : yk > 0, k = 1, . . . , q}.Letusobservethat x ≦y ⇔y −x ∈Rq
+ and x < y ⇔
y −x ∈int(Rq
+).
Given x0, x1 ∈S, we say that x0 dominates (or is better than) x1 if f (x0) ≦f (x1).
Related to solutions of problem (M P1), the ideal would be to ﬁnd a point x0 ∈S
such that
f (x0) ≦f (x),
∀x ∈S.
A point x0 ∈S satisfying this condition is called an ideal point for (M P1). This
point is the minimum of all the objectives fk, k = 1, . . . , q, over S. Such a point x0
usually does not exist, the common is that the objectives are in conﬂict with each
other, in the following sense: to pass from x1 ∈S to x0 ∈S we can improve e.g. f1,
i.e. f1(x0) < f1(x1) but we worsen, e.g. f2, i.e. f2(x1) < f2(x0). When we ﬁnd a
point x0 ∈S such that we cannot improve it, we say that x0 is an efﬁcient solution
to problem (M P1). Next, we give the rigorous deﬁnition with the different notions
of optimality for (M P1).
Deﬁnition 11.1 Consider problem (M P1) and x0 ∈S.

11.1 Optimality Notions
385
(a) x0 is called efﬁcient or Pareto minimal if there exists no x ∈S such that f (x) ≦
f (x0) and fk(x0) < fk(x) for some k ∈{1, . . . , q}, or equivalently, f (x) ≦
f (x0) and f (x) ̸= f (x0).
(b) x0 is called weak efﬁcient or weak Pareto minimal if there exists no x ∈S such
that f (x) < f (x0).
(c) x0 is called strict efﬁcient or strict Pareto minimal if f (x)  f (x0) for all x ∈S,
x ̸= x0.
We denote the set of all efﬁcient solutions of (M P1) and weak efﬁcient solutions
by E( f, S) and W( f, S), respectively, and they are called the efﬁcient set and the
weak efﬁcient set. The set of all strict efﬁcient solutions is denoted by sE( f, S).
Other equivalent notions of efﬁciency are used in the literature, next we collect
some of them.
Remark 11.2 (i) The following statements are equivalent:
(a) x0 is efﬁcient.
(b) There is no x ∈S such that f (x) −f (x0) ∈−Rq
+ \ {0}.
(c)
f (x) −f (x0) ∈(−Rq
+ \ {0})c for all x ∈S.
(d)
f (S) ∩( f (x0) −Rq
+) = { f (x0)}.
(e) ( f (S) −f (x0)) ∩−Rq
+ = {0}.
(f) The implication
x ∈S, f (x) ≦f (x0) ⇒f (x) = f (x0)
holds.
(ii) The following statements are equivalent:
(a) x0 is weak efﬁcient.
(b) There is no x ∈S such that f (x) −f (x0) ∈−int(Rq
+).
(c)
f (S) ∩( f (x0) −int(Rq
+)) = ∅.
(d) ( f (S) −f (x0)) ∩−int(Rq
+) = ∅.
(iii) The following statements are equivalent:
(a) x0 is strict efﬁcient.
(b) x0 is efﬁcient and f −1( f (x0)) ∩S = {x0}.
(c) x ∈S, f (x) ≦f (x0) ⇒x = x0.
The following inclusions are obvious:
sE( f, S) ⊂E( f, S) ⊂W( f, S).
We can also deﬁne (weak) efﬁcient points for a set A ⊂Rq. If Id : Rq →Rq is the
identity map, i.e. Id(y) = y for all y ∈Rq, then we say that a0 ∈A is an efﬁcient
point of A if a0 ∈E(Id, A), which means that (A −a0) ∩−Rq
+ = {0}. Similarly,
a0 ∈A is a weak efﬁcient point of A if a0 ∈W(Id, A), which means that (A −a0) ∩

386
11
Introduction to Multiobjective Optimization
Fig. 11.1 Illustration of efﬁciency. x0 and x4 are efﬁcient, x2 is not efﬁciency since is dominated
e.g. by x4, x1 is weak efﬁcient since f (S) ∩( f (x1) −int(Rq
+)) = ∅but it is not efﬁcient since
f (x4) ∈f (x1) −Rq
+ and f (x4) ̸= f (x1)
−int(Rq
+) = ∅. We denote by E(A) and W(A) the sets of efﬁcient and weak efﬁcient
points of A, respectively. It is obvious from the deﬁnition that E(A) = E(Id, A) and
W(A) = W(Id, A).
The following equivalences are also obvious:
x0 ∈E( f, S) ⇔f (x0) ∈E( f (S)),
and
x0 ∈W( f, S) ⇔f (x0) ∈W( f (S)).
(11.1)
For this reason, many times we prefer working in the objective space with the
image set f (S). Moreover, if y0 ∈E( f (S)) then f −1(y0) ∩S ⊂E( f, S), and if
y0 ∈W( f (S)) then f −1(y0) ∩S ⊂W( f, S).
Next, we give an example to illustrate the notions introduced (Fig. 11.1).
The ﬁrst questions we approach are the existence and the basic properties of the
efﬁciency set. It is convenient to consider E(Y) as we have seen, with Y ⊂Rq. First
let us show through examples that the efﬁcient set can be empty or a singleton.
Example 11.3 (a) Let f : R →R2 deﬁned by f (x) = [x2, x]⊤and S = {x ∈R :
x ≧2}. One has that f (S) = {(y1, y2) ∈R2 : y1 = y2
2, y2 ≧2}. In consequence,
E( f (S)) = {(4, 2)} and E( f, S) = {2} are singleton.
(b) Let Y = {(y1, y2) ∈R2 : y2 = y2
1 + 1, y1 > 0}. One has E(Y) = W(Y) = ∅.
We invite the reader to draw the sets f (S) in part (a) and Y in part (b).
Extension to an arbitrary convex cone
We can consider in Rq another relation ⪯instead of ≦. A binary relation ⪯over a
set A ⊂Rq comes deﬁned by a set R⪯⊂A × A so that y1 ⪯y2 ⇔(y1, y2) ∈R⪯.

11.1 Optimality Notions
387
Deﬁnition 11.4 A relation ⪯deﬁned on A is called
(a) reﬂexive if y ⪯y for all y ∈A,
(b) symmetric if y1 ⪯y2 ⇒y2 ⪯y1 for all y1, y2 ∈A,
(c) antisymmetric if y1 ⪯y2 and y2 ⪯y1 ⇒y1 = y2 for all y1, y2 ∈A,
(d) transitive if y1 ⪯y2 and y2 ⪯y3 ⇒y1 ⪯y3 for all y1, y2, y3 ∈A.
It is said that ⪯is a preorder if it is reﬂexive and transitive. A preorder is total
if, for all y1, y2 ∈A one has y1 ⪯y2 or y2 ⪯y1, it is called a partial preorder
otherwise.
Let us note that the usual order ≦on Rq is partial. It is important to note that in a
partial order, two arbitrary elements cannot be compared, in general.
Deﬁnition 11.5 A relation ⪯deﬁned on Rq is said to be compatible with the linear
structure if
(a) y1 ⪯y2 ⇒αy1 ⪯αy2 for all y1, y2 ∈Rq and α ≧0, and
(b) y1 ⪯y2 and y3 ⪯y4 ⇒y1 + y3 ⪯y2 + y4 for all y1, y2, y3, y4 ∈Rq.
A characterization of a partial preorder on Rq is given in the next result.
Theorem 11.6 (i) If ⪯is a partial preorder on Rq compatible with the linear struc-
ture, then the set
K = {y ∈Rq : 0 ⪯y}
is a convex cone. If, in addition, ⪯is antisymmetric, then K is pointed (i.e. K ∩−K =
{0}).
(ii) Conversely, if K is a convex cone in Rq, then the relation deﬁned by
y1, y2 ∈Rq,
y1 ≦K y2 ⇔y2 −y1 ∈K
is a partial preorder compatible with the linear structure. If, in addition, K is pointed,
then ≦K is antisymmetric.
The proof is easy and it is left to the reader.
In vector optimization, it is common to consider that the order is given by a convex
cone. Note that the usual order ≦on Rq is given by the closed convex cone Rq
+.
We can extend the notions of efﬁciency for an arbitrary preorder ≦K given by a
convex cone K ⊂Rq as follows.
Deﬁnition 11.7 Consider problem (M P1) and x0 ∈S.
(a) x0 is called efﬁcient if ( f (S) −f (x0)) ∩−K = {0}.
(b) x0 is called weak efﬁcient if ( f (S) −f (x0)) ∩−int(K) = ∅
(c) x0 is called strict efﬁcient if f (x) K f (x0) for all x ∈S, x ̸= x0.

388
11
Introduction to Multiobjective Optimization
Of course, we can also deﬁne efﬁcient points for a set A ⊂Rq with respect to
a convex cone K similarly as we have done for Rq
+. In this introductory chapter to
multiobjective optimization we prefer to continue our study with the cone Rq
+. Most
of the properties studied here are also true for an arbitrarily pointed closed convex
cone with a nonempty interior. The interested reader can see Sawaragi et al. [3] or
Jahn [4].
We can deﬁne Pareto maximal points as follows. a0 ∈A is a maximal point of
A if (A −a0) ∩K = {0}. Therefore, a Pareto maximal point with respect to K is a
Pareto minimal point with respect to −K. For this reason, in this chapter we only
deal with minimal Pareto points.
Next, we establish some basic properties. Let A ⊂Rq be a nonempty set.
Theorem 11.8 (i) E(A) = E(A + Rq
+).
(ii) W(A) ⊂W(A + Rq
+).
Proof (i) First, let a0 ∈E(A), then (A −a0) ∩−Rq
+ = {0}. This condition implies
that (A + Rq
+ −a0) ∩−Rq
+ = {0}, i.e. a0 ∈E(A + Rq
+). Indeed, assume by con-
tradiction that there exists d1, d2 ∈Rq
+, d2 ̸= 0 such that −d2 ∈A + d1 −a0.
Hence −(d1 + d2) ∈A −a0, d = d1 + d2 ∈Rq
+ since Rq
+ is a convex cone and
d = d1 + d2 ̸= 0. Otherwise, d2 = −d1 ∈Rq
+ ∩Rq
+ = {0}, and it would be d2 = 0,
which is a contradiction. Therefore, −d ∈(A −a0) ∩−Rq
+ with d ̸= 0, which con-
tradicts the hypothesis. Thus a0 ∈E(A + Rq
+).
Second,let y0 = a0 + d0 ∈E(A + Rq
+),witha0 ∈A andd0 ∈Rq
+.Weafﬁrmthat
d0 = 0. Indeed, if we assume that d0 ̸= 0 then a0 ≦y0 (since y0 −a0 ∈Rq
+) and
a0 ̸= y0, and as a0 ∈A + Rq
+ it follows that y0 is not an efﬁcient point of A + Rq
+,
which contradicts the hypothesis. Thus d0 = 0, and so a0 = y0 ∈E(A + Rq
+), and as
y0 ∈A ⊂A + Rq
+ it follows that y0 ∈E(A) because (A + Rq
+ −y0) ∩−Rq
+ = {0}
implies (A −y0) ∩−Rq
+ = {0}.
(ii) The proof of this fact is similar to that of the ﬁrst part of part (i), for this reason
we omit it.
□
The inclusion W(A + Rq
+) ⊂W(A) is in general false. For example, in R2, if A =
{(0, 0)}, then W(A) = {(0, 0)} while W(A + R2
+) = {(x, y) ∈R2
+ : x = 0 or y =
0}.
Theorem 11.9 E(A) ⊂W(A) ⊂bd A.
In consequence, if A is open or A + Rq
+ is open, then W(A) = ∅.
Proof We only have to prove W(A) ⊂bd A. Let a0 ∈W(A) and assume that a0 /∈
bd A. Then a0 ∈int(A), and so there exists a neighborhood U(a0) such that U(a0) ⊂
A. Pick up d ∈int(Rq
+). For a ﬁxed t > 0 small enough one has a1 = a0 −td ∈
U(a0) and td ∈int(Rq
+). In consequence, a1 −a0 = −td ∈(A −a0) ∩−int(Rq
+),
which contradicts the fact that a0 ∈W(A).
□
Theorem 11.10 Let A, A1, A2 be nonempty subsets of Rq. We have
(i) E(A1 + A2) ⊂E(A1) + E(A2).

11.1 Optimality Notions
389
(ii) E(t A) = t E(A) for all t > 0.
The proof is easy and it is left to the reader.
We provide next, without proof, an existence result.
Theorem 11.11 (Borwein [11]) Let A be a nonempty subset of Rq and suppose that
there is some a ∈A such that the section
Aa = {y ∈A : y ≦a} = A ∩(a −Rq
+)
is compact (we say “A contains a compact section”). Then E(A) is nonempty.
Theorem 11.12 Consider problem (M P1) and suppose that S is compact and each
fk : X ⊂Rn →R, k = 1, . . . , q, is continuous. Then E( f, S) is nonempty.
Proof We know that f (S) is a compact set since f is continuous. Hence, for any
y ∈f (S) the section f (S) ∩(y −Rq
+) is compact, and by Theorem 11.11 it follows
that E( f (S)) ̸= ∅. In consequence, E( f, S) = f −1(E( f (S))) ∩S ̸= ∅.
□
The proof of Theorem 11.11 is based on Zorn’s Lemma. An easier proof can
be done to prove an existence result for weak efﬁcient points (see Theorem 2.25 in
Ehrgott [1]).
Theorem 11.13 If A ⊂Rq is compact, then W(A) ̸= ∅.
In Deﬁnition 11.1 global efﬁciency has been introduced. Another important con-
cept is local efﬁciency.
Deﬁnition 11.14 Consider problem (M P1) and x0 ∈S.
(a) x0 is called local efﬁcient or local Pareto minimal if there exists a neighborhood
U(x0) of x0 such that x0 is efﬁcient in S ∩U(x0), i.e.
( f (S ∩U(x0)) −f (x0)) ∩−Rq
+ = {0}.
(11.2)
(b) x0 is called local weak efﬁcient or local weak Pareto minimal if there exists a
neighborhood U(x0) of x0 such that x0 is weak efﬁcient in S ∩U(x0), i.e.
( f (S ∩U(x0)) −f (x0)) ∩−int(Rq
+) = ∅,
(c) x0 is called local strict efﬁcient or local strict Pareto minimal if there exists
a neighborhood U(x0) of x0 such that x0 is strict efﬁcient in S ∩U(x0), i.e.
f (x)  f (x0) for all x ∈S ∩U(x0), x ̸= x0.
Naturally, any global (weak) efﬁcient point is local (weak) efﬁcient. The converse
is valid for convex problems.
Theorem 11.15 Assume that S is a convex set and each component fk : X →R,
k = 1, . . . , q is convex on S. If x0 ∈S is local efﬁcient, then it is global efﬁcient.

390
11
Introduction to Multiobjective Optimization
Proof By hypothesis, condition (11.2) is satisﬁed for some neighborhood U(x0) of
x0. By contradiction, let us assume that x0 is not global efﬁcient. Then there exists
x1 ∈S such that
f (x1) −f (x0) ∈−Rq
+ \ {0}.
(11.3)
Deﬁne xt = x0 + t(x1 −x0) = tx1 + (1 −t)x0, we have xt ∈S for all t ∈(0, 1)
due to the convexity of S. For t > 0 small enough, one has xt ∈U(x0). As each fk
is convex on S, we derive
fk(xt) ≦t fk(x1) + (1 −t) fk(x0) = fk(x0) + t( fk(x1) −fk(x0)),
k = 1, . . . , q.
Hence,
f (xt) ≦f (x0) + t( f (x1) −f (x0)) = f (x0) + d,
where
d = t( f (x1)
−f (x0)) ∈−Rq
+ \ {0} by (11.3). Therefore, f (xt) −f (x0) −d ∈−Rq
+, and con-
sequently f (xt) −f (x0) ∈d −Rq
+ ⊂−Rq
+ \ {0} since d ∈−Rq
+ \ {0}. This is a
contradiction to (11.2). Thus, x0 ∈E( f, S).
□
We can improve this result with some weaker assumptions. Recall that quasicon-
vex functions were introduced in Deﬁnition 3.18, p. 65.
Theorem 11.16 (Ruiz-Canales and Ruﬁán-Lizana [12]) Assume that S is a convex
set and each component fk : X →R, k = 1, . . . , q, is quasiconvex on S and at least
one is strictly quasiconvex on S. Then every local efﬁcient solution is a global efﬁcient
solution.
Proof Recall that g : S →R is quasiconvex on S if for all x1, x2 ∈S, and all t ∈
(0, 1) one has g(tx1 + (1 −t)x2 ≦max{g(x1), g(x2)}, with strict inequality if g is
strictly quasiconvex and x1 ̸= x2.
By assumption there exists a neighborhood U(x0) of x0 such that x0 ∈E( f, S ∩
U(x0)).
As above, by contradiction, let us assume that x0 is not global efﬁcient. Then there
exists x1 ∈S such that
fk(x1) ≦fk(x0) ∀k = 1, . . . , q and fi(x1) < fi(x0) for some i ∈{1, . . . , q}.
(11.4)
Deﬁne xt = x0 + t(x1 −x0) = tx1 + (1 −t)x0, we have xt ∈S for all t ∈(0, 1)
due to the convexity of S. For t > 0 small enough, one has xt ∈U(x0). As fk is qua-
siconvex on S, from (11.4) it follows fk(xt) ≦fk(x0), for k = 1, . . . , q. Moreover,
as f j is strictly quasiconvex on S for some j ∈{1, . . . , q} one has f j(xt) < f j(x0).
We have obtained a contradiction to the fact that x0 ∈E( f, S ∩U(x0)) since
xt ∈S ∩U(x0) and f (xt) −f (x0) ∈−Rq
+ \ {0}.
Let us observe that the second condition in (11.4) has only been used to assure
that x1 ̸= x0.
□
Next we are going to give a geometrical characterization for the sets E( f, S),
W( f, S) and sE( f, S). To this aim, recall and introduce the level sets of a func-
tion g : S →R. Given x0 ∈S, the sets lev≦(g, g(x0)) = {x ∈S : g(x) ≦g(x0)},

11.1 Optimality Notions
391
lev=(g, g(x0)) = {x ∈S : g(x) = g(x0)}
and
lev<(g, g(x0)) = {x ∈S : g(x)
< g(x0)} are called level set, level curve and strict level set of g at x0. Obviously,
lev<(g, g(x0)) ⊂lev≦(g, g(x0)) and x0 ∈lev=(g, g(x0)) ⊂lev≦(g, g(x0)).
Theorem 11.17 (Ehrgott [1], Theorem 2.20) Let f : S ⊂Rn →Rq, x0 ∈S and
deﬁne y0
k = fk(x0), k = 1, . . . , q. Then
(i) x0 is efﬁcient ⇔q
k=1 lev≦( fk, y0
k ) = q
k=1 lev=( fk, y0
k ).
(ii) x0 is weak efﬁcient ⇔q
k=1 lev<( fk, y0
k ) = ∅.
(iii) x0 is strictly efﬁcient ⇔q
k=1 lev≦( fk, y0
k ) = {x0}.
The proof is easy and it is left to the reader. This theorem is useful when the
level sets are geometrically known when n ≦3. We illustrate this theorem with two
examples.
Example 11.18 Consider the unconstrained biobjective Pareto problem:
(M P1)
min f (x) = [x2 + 2x, x2 −6x + 5]⊤subject to x ∈R.
In this example, it is easy to obtain all the efﬁcient points by applying the method
of level sets. If we select a point a in the feasible set R, the set of feasible points that
improve it with respect to f1 are those that verify f1(x) ≦f1(a), that is the interval
[b, a] (see Fig. 11.2). Similarly, the set of those points that improve it with respect
to f2 is given by the interval [a, c], so ∩2
k=1 lev≦( fk, fk(a)) = [b, a] ∩[a, c] = {a},
and by using part (iii) in Theorem 11.17 a is strictly efﬁcient. Therefore, it is clear
that if the point a is between the abscissas of the vertices of the two parabolas, the
above condition is veriﬁed and consequently all points in [−1, 3] are strict efﬁcient.
If a is outside the previous interval, the intersection no longer reduces to the point
a, and, therefore, it is not efﬁcient (not even weak). In conclusion, the set of strict
efﬁcient points is [−1, 3]. Moreover, W( f, R) = E( f, R) = [−1, 3].
Example 11.19 Consider now the constrained biobjective Pareto problem:
(M P1)
min f (x, y) =

x, y2
2x
⊤
subject to
⎧
⎨
⎩
−x −y + 8 ≦0
x + 2y −13 ≦0
−y −3 ≦0.
Determine if the points (9, −1)⊤and (6, 2)⊤are efﬁcient, weakly efﬁcient, or strictly
efﬁcient, by the method of level sets.
The feasible set S is the triangle with vertices A(3, 5), B(11, −3) and C(19, −3),
whose sides are AB : y = −x + 8, AC : x + 2y = 13 and BC : y = −3 (see
Fig. 11.3).
The strict level sets associated to the point (9, −1)⊤are given by x < 9, y2
2x <
1
18.
The second one is the parabolic region 9y2 < x (we can assume that x > 0, because
the feasible set is contained in this half-plane). Since they cut into the interior of the

392
11
Introduction to Multiobjective Optimization
Fig. 11.2 Example 11.18. Method of level sets
Fig. 11.3 Example 11.19. Feasible set
feasible set S, from part (ii) of Theorem 11.17, it follows that (9, −1)⊤is not weakly
efﬁcient (and, therefore, neither efﬁcient nor strict efﬁcient) (see Fig. 11.4).
The level sets associated to the point (6, 2)⊤are given by x ≦6, y2
2x ≦
4
12. The
second one is the parabolic region 3
2 y2 ≦x. They only intersect with S in (6, 2)⊤,
so taking into account part (iii) of Theorem 11.17 we conclude that the point (6, 2)⊤
is strict efﬁcient (see Fig. 11.5).
Proper efﬁciency
Proper efﬁcient points are efﬁcient points that satisfy a suitable property. There
are two important reasons to introduce proper efﬁcient points. First, some authors
observed that some efﬁcient points had undesirable properties. Second, mathematical
methods usually allow to obtain a subset of the efﬁcient set.

11.1 Optimality Notions
393
Fig. 11.4 Level sets for (9, −1)⊤
Fig. 11.5 Level sets for (6, 2)⊤
One of the ideas of proper efﬁciency (particularly from Geoffrion’s deﬁnition) is
that unbounded trade-offs between objectives are not allowed.
Until now there are many types of concepts of proper minimality. The notion
of proper Pareto minimality (or proper efﬁciency) was ﬁrst introduced by Kuhn and
Tucker [10]. Then some further concepts of proper efﬁciency were given by Geoffrion
[13], Borwein [14], Benson [15], Henig [16], etc.; see also Guerraggio et al. [17]
where the relationships between several notions are studied.
Deﬁnition 11.20 (Geoffrion [13]) A point x0 ∈S is said to be proper efﬁcient in
the sense of Geoffrion if it is efﬁcient and if there is a real number L > 0 such
that for all i and x ∈S satisfying fi(x) < fi(x0) there exists an index j such that
f j(x0) < f j(x) and
fi(x0) −fi(x)
f j(x) −f j(x0) ≦L.

394
11
Introduction to Multiobjective Optimization
According this deﬁnition, proper efﬁcient solutions are those efﬁcient solutions
that have bounded trade-offs between the objectives.
Deﬁnition 11.21 A point x0 ∈S is called proper efﬁcient
(a) in the sense of Borwein if
T

f (S) + Rq
+, f (x0)
	
∩(−Rq
+) = {0}.
(b) in the sense of Benson if
cl

ray

f (S) + Rq
+ −f (x0)
		
∩(−Rq
+) = {0}.
Recall that T (A, y0) denotes the Bouligand tangent cone (Deﬁnition 2.35, p. 47).
In this deﬁnition we can work with a set Y ⊂Rq and a point y0 ∈Y because f
plays no role. In consequence, we say that y0 ∈Y is a proper efﬁcient point of Y
(a) in the sense of Borwein if T (Y + Rq
+, y0) ∩(−Rq
+) = {0}.
(b) in the sense of Benson if cl

ray

Y + Rq
+ −y0		
∩(−Rq
+) = {0}.
Remark 11.22 (a) Note that x0 ∈S is proper efﬁcient in the sense of Borwein (resp.,
Benson) if and only if f (x0) is a proper efﬁcient point of f (S) in the sense of Borwein
(resp., Benson).
(b) If y0 ∈Y is proper efﬁcient of Y in the sense of Borwein, then it is also
efﬁcient.
Indeed, by contradiction assume that y0 is not an efﬁcient point of Y. Then there
exists y1 ∈Y such that d = y1 −y0 ∈−Rq
+ \ {0}. Let us check that d is a feasible
direction to Y + Rq
+ at y0, i.e. d ∈F(Y + Rq
+, y0). Let t ≧0, then
y0 + td = y0 + t(y1 −y0) = y1 + (1 −t)(y0 −y1) ∈Y + Rq
+
∀t ∈[0, 1],
since y0 −y1 ∈Rq
+ and 1 −t ≧0. Therefore, by the deﬁnition d ∈F(Y + Rq
+, y0),
and by Remark 2.45, it follows that d ∈T (Y + Rq
+, y0). As d ∈−Rq
+ \ {0} we have
a contradiction with the fact that y0 is proper efﬁcient of Y in the sense of Borwein.
Next, we are going to introduce the notion of proper efﬁciency in the sense of
Kuhn-Tucker. This notion is only deﬁned when the feasible set is given by functional
constraints. These kinds of problems are very important in applications and we will
deal with them later. So we are going to study a multiobjective optimization problem
with inequality constraints and equality constraints as in Chap. 6, but there it was
with only one objective.
We consider the following multiobjective optimization problem:
(M P2)
⎧
⎪⎪⎨
⎪⎪⎩
min[ f1(x), . . . , fq(x)]⊤
subject to: gi(x) ≦0, i = 1, . . . , m,
h j(x) = 0, j = 1, . . . , p < n,
x ∈X ⊂Rn,

11.1 Optimality Notions
395
where X ⊂Rn is an open set contained in the domains of the functions involved in
(M P2), fk, k ∈Q = {1, . . . , q}, gi, i ∈M = {1, . . . , m} and h j, j ∈P = {1, . . . ,
p < n}, are real-valued functions deﬁned on Rn.
We make the assumptions that every fk, k ∈Q, every gi, i = 1, . . . , m, are (at
least) differentiable on X and that every h j, j = 1, . . . , p, is (at least) contin-
uously differentiable on X. We also denote f (x) = [ f1(x), . . . , fq(x)]⊤, g(x) =
[g1(x), . . . , gm(x)]⊤and h(x) = [h1(x), . . . , h p(x)]⊤.
We denote by S2 the set of all feasible points of this problem, i.e.
S2 = {x ∈X : gi(x) ≦0, ∀i ∈M, h j(x) = 0, ∀j ∈P}.
Let us observe that this set was denoted by K5 in Chap. 6. Given x0 ∈S2, we denote by
I (x0) the set of indices of active constraints at x0, i.e. I (x0) = {i ∈M : gi(x0) = 0}.
Deﬁnition 11.23 Consider problem (M P2). A point x0 ∈S2 is said to be proper
efﬁcient in the sense of Kuhn-Tucker if it is efﬁcient and if there is no d ∈Rn
satisfying
∇fk(x0)⊤d ≦0, ∀k ∈{1, . . . , q},
∇fk(x0)⊤d < 0, for some k ∈{1, . . . , q},
∇gi(x0)⊤d ≦0, ∀i ∈I (x0),
∇h j(x0)⊤d = 0, ∀j = 1, . . . , p.
⎫
⎪⎪⎬
⎪⎪⎭
(11.5)
Next we study the relations between these notions. See also Ehrgott [1], Sawaragi
et al. [3] and Guerraggio et al. [17].
We say that a set A ⊂Rq is Rq
+-convex if A + Rq
+ is a convex set. Clearly, if A
is convex, then A is Rq
+-convex.
Lemma 11.24 Consider problem (M P1). If S is convex and each fk, k = 1, . . . , q,
is convex on S, then f (S) is Rq
+-convex.
Proof Let x1, x2 ∈S, d1, d2 ∈Rq
+ and t ∈[0, 1]. We have to prove that
yt = t( f (x1) + d1) + (1 −t)( f (x2) + d2)
= t f (x1) + (1 −t) f (x2) + td1 + (1 −t)d2 ∈f (S) + Rq
+.
(11.6)
Each fk is convex on S, and so fk(xt) ≦t fk(x1) + (1 −t) fk(x2), for k =
1, . . . , q where xt = tx1 + (1 −t)x2 ∈S due to the convexity of S. Hence, f (xt) ≦
t f (x1) + (1 −t) f (x2), that is t f (x1) + (1 −t) f (x2) ∈f (xt) + Rq
+. Therefore, in
view of (11.6)
yt ∈f (xt) + Rq
+ + td1 + (1 −t)d2 ⊂f (S) + Rq
+
because Rq
+ + td1 + (1 −t)d2 ⊂Rq
+ + Rq
+ = Rq
+ since Rq
+ is a convex cone.
□
A function f : S ⊂Rn →Rq such that f (S) + Rq
+ is a convex set is called
convex-like on S.

396
11
Introduction to Multiobjective Optimization
Theorem 11.25 Let Y ⊂Rq, y0 ∈Y.
(i) If y0 is proper efﬁcient of Y in the sense of Benson, then it is also proper efﬁcient
in the sense of Borwein.
(ii) If Y is Rq
+-convex, then both deﬁnitions coincide.
(iii) Consider problem (M P1) and x0 ∈S. If S is convex and each fk, k = 1, . . . , q,
is convex on S, then x0 is proper efﬁcient in the sense of Benson if and only it is
proper efﬁcient in the sense of Borwein.
Proof (i) It is a direct consequence of the inclusion T (A, y0) ⊂cl ray(A −y0) (see
the proof of Theorem 2.41) with A = Y + Rq
+.
(ii) Since Y + Rq
+ is convex by assumption, it follows from Theorem 2.41 that
T (Y + Rq
+, y0) = cl cone

Y + Rq
+ −y0	
, and so the statement is obvious.
(iii) It follows from part (ii) in view of Lemma 11.24 and Remark 11.22(a) choos-
ing Y = f (S) and y0 = f (x0).
□
Theorem 11.26 (Benson [15]) Consider problem (M P1). A feasible point x0 ∈S is
proper efﬁcient in the sense of Benson if and only if it is proper efﬁcient in the sense
of Geoffrion.
Proof Geoffrion ⇒Benson. Suppose x0 is efﬁcient, but not properly efﬁcient in
Benson’s sense. Then, we know that a nonzero d ∈cl(ray( f (S) + Rq
+ −f (x0))) ∩
(−Rq
+) exists. Without loss of generality we may assume that d1 < −1, dk ≦0,
k = 2, . . . , q (otherwise we can reorder the components of f and rescale d). Conse-
quently, there are sequences {tn} ⊂R, tn > 0, for each n, {xn} ⊂S, {rn} ⊂Rq
+ such
that tn( f (xn) + rn −f (x0)) →d.
Choosing a subsequence if necessary, we can assume that ˜Q = {k ∈{1, . . . , q} :
fk(xn) > fk(x0)} is the same for all n and nonempty since x0 is efﬁcient. Moreover,
1 /∈˜Q because tn( f1(xn) + rn
1 −f1(x0)) →d1 < −1 and so f1(xn) −f1(x0) <
−1/tn for all n large enough since rn
1 ≧0. Let L > 0. From convergence we get
existence of n0 such that for all n ≧n0
f1(xn) −f1(x0) < −1
tn
(11.7)
and
fk(xn) −fk(x0) ≦
1
Ltn
, k = 2, . . . , q.
(11.8)
In particular, for k ∈˜Q , we have
0 < fk(xn) −fk(x0) ≦
1
Ltn
, ∀n ≧n0
(11.9)
and, therefore, from (11.7) and (11.9)

11.1 Optimality Notions
397
f1(x0) −f1(xn)
fk(xn) −fk(x0) >
1
tn
1
Ltn
= L.
(11.10)
Because L was arbitrarily chosen, x0 is not properly efﬁcient in Geoffrion’s sense.
Benson ⇒Geoffrion. Suppose now that x0 is efﬁcient, but not properly efﬁcient
in Geoffrion’s sense. Let Ln > 0 be an unbounded sequence of positive real numbers.
Without loss of generality we assume that for each n there is an xn ∈S such that
f1(xn) < f1(x0) and
f1(x0) −f1(xn)
fk(xn) −fk(x0) > Ln, ∀k ∈{2, . . . , q} with fk(xn) > fk(x0).
(11.11)
Choosing a subsequence if necessary, we can assume
˜Q = {k ∈{2, . . . , q} : fk(xn) > fk(x0)}
is constant for all n and nonempty since x0 is efﬁcient. We are going to construct
appropriate sequences {tn} and {rn} such that the sequence tn( f (xn) + rn −f (x0))
converges to some d ∈cl(ray( f (S) + Rq
+ −f (x0))) ∩(−Rq
+) with d ̸= 0.
Deﬁne tn = ( f1(x0) −f1(xn))−1 > 0 for all n. Deﬁne now rn ∈Rq
+ through
rn
k :=

0,
if k = 1 or k ∈˜Q,
fk(x0) −fk(xn), otherwise.
(11.12)
With these sequences we have
tn( fk(xn) + rn
k −fk(x0))
⎧
⎨
⎩
= −1,
if k = 1,
= 0,
if k ̸= 1, k /∈˜Q,
∈(0, L−1
n ), if k ∈˜Q.
(11.13)
This sequence converges due to the choice of Ln →∞to some d ∈Rq, where dk =
limn→∞tn( fk(xn) + rn
k −fk(x0))
for
k = 1, . . . , q.
Thus,
from
(11.13)
d1 = −1, dk = 0, k ̸= 1, k /∈˜Q, dk = 0, k ∈˜Q. So d = (−1, 0, . . . , 0) ∈cl(ray
( f (S) + Rq
+ −f (x0)) ∩(−Rq
+), and so x0 is not properly efﬁcient in Benson’s
sense.
□
Lemma 11.27 Assume that f : X ⊂Rn →Rq is differentiable and X is an open
set. Let y ∈Rn, {x j} ⊂Rn be a sequence converging to x0 ∈X and t j > 0 with
t j →0. If lim j→∞x j−x0
t j
= y, then
lim
j→∞
f (x j) −f (x0)
t j
= ∇f (x0)y.
Proof Let y j = x j−x0
t j
→y and so x j = x0 + t j y j.

398
11
Introduction to Multiobjective Optimization
If there are inﬁnite j ∈N such that x j = x0, then clearly y j = 0 for inﬁnite j and
so y j →0 = y. And also lim j→∞
f (x j)−f (x0)
t j
= 0 = ∇f (x0)y.
Therefore, we can assume that x j ̸= x0 for all j and so y j ̸= 0 for all j. As
f is differentiable at x0, one has by deﬁnition limx→x0 f (x)−f (x0)−∇f (x0)(x−x0)
∥x−x0∥
= 0.
Replacing x by x j = x0 + t j y j, it follows that lim j→∞
f (x j)−f (x0)−t j∇f (x0)y j
t j∥y j∥
= 0.
As ∥y j∥→∥y∥, one has that the sequence {y j} is bounded, and we derive that
lim j→∞
f (x j)−f (x0)−t j∇f (x0)y j
t j
= 0. From here, the thesis follows.
□
Theorem 11.28 (Geoffrion [13]) Consider problem (M P2) and x0 ∈S2. Assume
that the involved functions are differentiable at x0 and x0 satisﬁes the Abadie con-
straint qualiﬁcation (see p. 185). If x0 is proper efﬁcient in the sense of Geoffrion,
then x0 is proper efﬁcient in the sense of Kuhn-Tucker.
Proof Suppose x0 is efﬁcient, but not properly efﬁcient in the sense of Kuhn-Tucker.
Then there is some d ∈Rn such that (without loss of generality, after renumbering
the objectives)
∇fk(x0)⊤d ≦0, ∀k ∈{2, . . . , q},
∇f1(x0)⊤d < 0,
∇gi(x0)⊤d ≦0, ∀i ∈I (x0),
∇h j(x0)⊤d = 0, ∀j = 1, . . . , p.
⎫
⎪⎪⎬
⎪⎪⎭
(11.14)
By the Abadie constraint qualiﬁcation one has L(x0) = T (S2, x0), and as d ∈L(x0)
by (11.14), we have d ∈T (S2, x0). This means that there exist sequences xn →x0
and tn →0+ such that xn ∈S for all n and xn−x0
tn
→d.
By Lemma 11.27, one has limn→∞
f1(xn)−f1(x0)
tn
= ∇f1(x0)⊤d < 0, and so f1(xn)
−f1(x0) < 0 for all n large enough. Taking a subsequence if necessary we can
assume that the set
˜Q = {k ∈{2, . . . , q} : fk(xn) > fk(x0)}
is the same for all n and nonempty since x0 is efﬁcient.
By Lemma 11.27, we have limn→∞
fk(xn)−fk(x0)
tn
= ∇fk(x0)⊤d ≧0 for all k ∈˜Q.
In view of (11.14) one has ∇fk(x0)⊤d ≦0, and therefore,
∇fk(x0)⊤d = 0, ∀k ∈˜Q.
But since ∇f1(x0)⊤d < 0, the latter imply that for k ∈˜Q one has
lim
n→∞
f1(x0) −f1(xn)
fk(xn) −fk(x0) = lim
n→∞
f1(xn)−f1(x0)
tn
fk(xn)−fk(x0)
tn
= +∞
because limn→∞
fi(xn)−fi(x0)
tn
= ∇fi(x0)⊤d for all i by Lemma 11.27. Hence x0 is
not properly efﬁcient in Geoffrion’s sense.
□

11.2 The Weighted Sum Method and Relations with Proper Efﬁciency
399
The original proof given by Geoffrion uses the Kuhn-Tucker constraint qualiﬁ-
cation, but we know that this constraint qualiﬁcation implies the Abadie constraint
qualiﬁcation (see p. 185).
The converse implication of Theorem 11.28 is true under convexity. It is not
necessarily a constraint qualiﬁcation because really convexity is yet a constraint
qualiﬁcation (see the Slater constraint qualiﬁcation at p. 187). The following theorem
is a consequence of some results in the next Sect. 11.3, but we present it here for
completeness.
Theorem 11.29 (Geoffrion[13])Assumethat fk,k = 1, . . . , q and gi,i = 1, . . . , m,
are convex and h j, j = 1, . . . , p are linear afﬁne. If x0 ∈S2 is proper efﬁcient in the
sense of Kuhn-Tucker, then x0 is proper efﬁcient in the sense of Geoffrion.
Proof By Theorem 11.48(i), conditions (a), (b), (c) in that theorem are satisﬁed,
and by Corollary 11.49 we conclude that x0 is proper efﬁcient in the sense of
Geoffrion.
□
We sketch the relationships obtained in the following scheme.
Borwein
(1)
⇔
Benson ⇔Geoffrion
(1) (2)
⇔
Kuhn-Tucker
(1) convexity, (2) Abadie c. q.
11.2
The Weighted Sum Method and Relations with Proper
Efﬁciency
Most used method to solve a multiobjective optimization problem (in short, MOP) is
scalarization. Scalarization means that the problem is transformed into a scalar or a
family of scalar optimization problems, so we can use all powerful tools and methods
developed for scalar optimization problems. The solutions to the scalar problem are
some kind of solution to the MOP. In this introductory chapter, we will only deal
with linear scalarization, or in other words, the Weighted Sum Method.
Theideaofthismethodistoassociateaweightcoefﬁcientwk ≧0 toeachobjective
fk and minimize the weighted sum of the objectives. To be more precise, consider
the following scalar optimization problem:
(Pw)
min w⊤f (x) =
q

k=1
wk fk(x) subject to x ∈S,
where f = ( f1, . . . , fq)⊤: X ⊂Rn →Rq, X is an open set, w = (w1, . . . , wq)⊤∈
Rq
+ and S ⊂X.

400
11
Introduction to Multiobjective Optimization
The set of solutions of (Pw) is denoted by argmin(w⊤f, S).
Let Y be a nonempty subset of Rq. We denote
argmin(w⊤, Y) = {y0 ∈Y : w⊤y0 ≦w⊤y, ∀y ∈Y},
Pos(Y) = ∪w∈Rq
+\{0} argmin(w⊤, Y) and
Pos>(Y) = ∪w∈int Rq
+ argmin(w⊤, Y).
It is clear that Pos>(Y) ⊂Pos(Y).
In this section, we study the relationships between the solutions of the scalar
problem miny∈Y w⊤y with w ≧0, w ̸= 0 or w > 0 and the efﬁcient or weak efﬁcient
points of Y, and between solutions of (Pw) and solutions of (M P1).
Theorem 11.30 (i) Pos(Y) ⊂W(Y).
(ii) If Y is Rq
+-convex, then Pos(Y) = W(Y).
Proof (i) Let w ∈Rq
+ \ {0} and y0 ∈Pos(Y). Then w⊤y0 ≦w⊤y for all y ∈Y.
Suppose that y0 /∈W(Y). Then there is some y′ ∈Y with y′
k < yk for k =
1, . . . , q. Thus, w⊤y′ < w⊤y because at least one of the weights wk must be positive.
This is a contradiction and the result follows.
(ii) Taking into account part (i), we only have to prove that W(Y) ⊂Pos(Y).
Let y0 ∈W(Y). By Theorem 11.8(ii) we have that W(Y) ⊂W(Y + Rq
+) and so
y0 ∈W(Y + Rq
+). Then
(Y + Rq
+ −y0) ∩(−int(Rq
+)) = ∅.
By hypothesis, the set Y + Rq
+ is convex and so Y + Rq
+ −y0 is also a convex set.
By a separation theorem (see Theorem 2.20), there exist w ∈Rq \ {0} and α ∈R
such that
w⊤(y + d −y0) ≧α ≧w⊤(−d′),
∀y ∈Y, d ∈Rq
+, d′ ∈int(Rq
+).
(11.15)
On the one hand, choosing y = y0 and d = 0 we derive that 0 ≧α. On the other
hand, choosing d′ = td0 with d0 ∈int(Rq
+) and t > 0, it follows that α ≧w⊤(−td0)
for all t > 0. Taking the limit as t →0+ we deduce that α ≧0 and so α = 0. Thus in
view of (11.15), we have w⊤d′ ≧0 for all d′ ∈int(Rq
+). As the function y →w⊤y
is continuous it follows that w⊤d′ ≧0 for all d′ ∈cl(int(Rq
+)) = Rq
+. In particular,
if we choose d′ = ek, where ek is the k-th unit vector, we obtain wk = w⊤ek ≧0, for
k = 1, . . . , q. Thus w ∈Rq
+ \ {0}.
Finally, using (11.15) with d = 0 we get w⊤(y −y0) ≧0 for all y ∈Y, or
equivalently, w⊤y ≧w⊤y0 for all y ∈Y, and, therefore, y0 ∈argmin(w⊤, Y) ⊂
Pos(Y).
□

11.2 The Weighted Sum Method and Relations with Proper Efﬁciency
401
Theorem 11.31 Pos>(Y) ⊂E(Y).
Proof Let y0 ∈Pos>(Y). Then there is some w ∈int Rq
+ satisfying w⊤y0 ≦w⊤y for
all y ∈Y. Suppose y0 /∈E(Y). Hence there exists y′ ∈Y with y′ ≦y and y′ ̸= y, and
multiplying componentwise by the weights gives wk y′
k ≦wk y0
k for all k = 1, . . . , q
and strict inequality for at least one k. This strict inequality together with the fact
that all wk are positive implies that w⊤y′ < w⊤y0, contradicting the fact that y0 ∈
Pos>(Y).
□
Corollary 11.32 If Y is Rq
+-convex, then E(Y) ⊂Pos(Y).
It follows from Theorem 11.30(ii) and the fact that E(Y) ⊂W(Y).
Theorem 11.33 If y0 is the unique element of argmin(w⊤, Y) for some w ∈Rq
+ \
{0}, then y0 ∈E(Y).
As usual, the proof is “by contradiction” and is left to the reader because it does
not have difﬁculty.
Next, we obtain the corresponding results for problem (M P1) from the above
results.
Theorem 11.34 Consider problem (M P1). Suppose that x0 ∈S is a solution of
problem (Pw) for some w ∈Rq
+ \ {0}. Then the following statements hold:
(i) If w ∈Rq
+ \ {0}, then x0 ∈W( f, S).
(ii) If w ∈int Rq
+, then x0 ∈E( f, S).
(iii) If w ∈Rq
+ \ {0} and x0 is the unique solution of (Pw), then x0 ∈sE( f, S).
Proof The assertions are immediate consequences of Theorems 11.30(i), 11.31 and
11.33 taking into account relation (11.1).
□
Now we will state the relationships between proper efﬁcient points and solutions
of the problem miny∈Y w⊤y.
We denote by Be(Y) the set of all proper efﬁcient points of Y in the sense of
Benson.
Lemma 11.35 Let C ⊂Rq be a closed cone. If there exists w ∈int Rq
+ such that
w⊤y ≧0 for all y ∈C, then C ∩−Rq
+ = {0}.
The converse statement is true if, in addition, C is convex.
Proof Assume by contradiction that there exists y ∈C ∩−Rq
+, with y ̸= 0. Then,
on the one hand, as y ∈−Rq
+, y ̸= 0 and w ∈int(Rq
+) we have w⊤y < 0. On the
other hand, as y ∈C, by assumption it follows w⊤y ≧0, which is a contradiction.
Now assume that C ∩−Rq
+ = {0}. Let q =

y ∈Rq
+ : q
k=1 yk = 1

. Clearly
q is a compact convex set contained in Rq
+ \ {0}, and from the assumption, we
derive that C ∩−q = ∅. By the strong separation theorem (Theorem 2.17), there
exist w ∈Rq \ {0} and α ∈R such that
w⊤c > α > −w⊤y
∀c ∈C, ∀y ∈q.
(11.16)

402
11
Introduction to Multiobjective Optimization
Choosing c = 0 ∈C, we obtain 0 > α, and in consequence
w⊤y > 0 ∀y ∈q.
This condition implies that w > 0. Indeed, if we choose the point y = ek ∈q,
where ek is the kth unit vector, we have wk = w⊤ek > 0 for all k ∈{1, . . . , q}. Thus
w > 0.
Now, by contradiction, assume that w⊤c0 < 0 for some c0 ∈C. Then tc0 ∈C
for all t > 0, and limt→+∞w⊤(tc0) = −∞, which contradicts (11.16). Therefore,
w⊤c ≧0 for all c ∈C, and the proof is ﬁnished.
□
Theorem 11.36 Pos(Y) ⊂Be(Y).
Proof Let y0 ∈Pos>(Y). Then y0 ∈argmin(w⊤, Y) for some w ∈int Rq
+, so w⊤y0
≦w⊤y ≦w⊤(y + d) for all y ∈Y, d ∈Rq
+. Therefore, w⊤(y + d −y0) ≧0, and
consequently, w⊤z ≧0 for all z ∈C = cl(ray(Y + Rq
+ −y0)). By using Lemma
11.35, we conclude that cl(ray(Y + Rq
+ −y0)) ∩−Rq
+ = {0}, that is,
y0 ∈
Be(Y).
□
Theorem 11.37 If Y is Rq
+-convex, then Pos>(Y) = Be(Y).
Proof We only have to prove Be(Y) ⊂Pos>(Y). Let y0 ∈Be(Y), then cl(ray(Y +
Rq
+ −y0)) ∩−Rq
+ = {0}. By hypothesis, Y + Rq
+ is a convex set, and so Y + Rq
+ −
y0 is also convex. By Theorem 2.6, ray(Y + Rq
+ −y0) = cone(Y + Rq
+ −y0) is a
convex cone. Hence C = cl(cone(Y + Rq
+ −y0)) is a closed convex cone and C ∩
−Rq
+ = {0}. By using Lemma 11.35, we conclude that there exists w ∈int(Rq
+) such
that w⊤z ≧0 for all z ∈cl(cone(Y + Rq
+ −y0)). From here, w⊤(y + d −y0) ≧0
for all y ∈Y, d ∈Rq
+. Choosing d = 0, it results that w⊤y ≧w⊤y0 for all y ∈Y,
which means that y0 ∈argmin(w⊤, Y) ⊂Pos>(Y).
□
Theorem 11.38 Assume S is convex and each fk, k = 1, . . . , q, is convex. Then
x0 ∈S is efﬁcient in the sense of Geoffrion if and only if x0 is a solution of the
problem (Pw) for some w ∈int(Rq
+).
Proof (⇒) By Theorem 11.26, x0 is efﬁcient in the sense of Geoffrion if and only x0
is efﬁcient in the sense of Benson. In view of Remark 11.22(a), this statement is equiv-
alent to f (x0) ∈Be( f (S)). By Lemma 11.24, f (S) is Rq
+-convex, and using The-
orem 11.37 we derive Pos>( f (S)) = Be( f (S)). Therefore, f (x0) ∈Pos>( f (S)),
which means that x0 is a solution of the problem (Pw) for some w ∈int(Rq
+).
(⇐) It is enough to revert the above reasoning.
□
Theorem 11.39 IfY isRq
+-closedandRq
+-convex,thenBe(Y) ⊂E(Y) ⊂cl(Be(Y)).
We omit the proof because is very technical, it can be seen in Ehrgott [1], Theorem
3.17, or in Sawaragi et al. [3], Theorem 3.4.6 and Corollary 3.2.2.
The inclusion cl(Be(Y)) ⊂E(Y) is not always satisﬁed, see Example 3.19 in
Ehrgott [1] or Example 3.4.2 in Sawaragi et al. [3], both examples are the same.

11.3 Optimality Conditions
403
The reader interested in delving into these topics is directed to Ehrgott [1] and
Sawaragi et al. [3].
We summarize the results obtained:
(i) If Y ⊂Rq then Pos>(Y) ⊂Be(Y) ⊂E(Y) and Pos(Y) ⊂W(Y).
(ii) If Y is Rq
+-convex then Pos(Y) = Be(Y) ⊂E(Y) ⊂cl(Pos>(Y)) = cl(Be(Y)).
11.3
Optimality Conditions
In this section, we study ﬁrst and second-order necessary and sufﬁcient optimal-
ity conditions for the general problem (M P1) and also for the problem deﬁned by
inequality constraints and equality constraints (M P2).
We start providing optimality conditions for problem (M P1). We assume that
f : X ⊂Rn →Rq is differentiable and X is an open set.
Theorem 11.40 (General necessary condition) If x0 ∈S is a local weak efﬁcient
solution for (M P1), then the system
∇f (x0)y < 0
y ∈T (S, x0)
is incompatible in y ∈Rn, i.e. ∇f (x0)y /∈−int Rq
+ for all y ∈T (S, x0).
Proof By contradiction, assume that ∇f (x0)y ∈−int Rq
+ for some y ∈T (S, x0).
Then there exist sequences xk →x0 and tk →0+ such that xk ∈S and xk−x0
tk
→y.
By applying Lemma 11.27, we derive
f (xk)−f (x0)
tk
→∇f (x0)y ∈−int Rq
+. So, for
all k large enough one has f (xk)−f (x0)
tk
∈−int Rq
+, and, therefore, f (xk) −f (x0) ∈
−int Rq
+ for all k large enough, which contradicts the local weak efﬁciency of x0
since xk →x0 and xk ∈S.
□
Recall that the cones of linearized directions and strict linearized direction for
problem (M P2) are deﬁned by
L(x0) = {y ∈Rn : ∇gi(x0)⊤y ≦0, ∀i ∈I (x0); ∇h j(x0)⊤y = 0, ∀j ∈P},
Lo(x0) = {y ∈Rn : ∇gi(x0)⊤y < 0, ∀i ∈I (x0); ∇h j(x0)⊤y = 0, ∀j ∈P}.
Of course, we can consider the constraint qualiﬁcations deﬁned in Sect. 6.2
because only the constraints are involved, and not the objectives.
Next we establish the Fritz John necessary optimality conditions for problem
(M P2). Its proof follows the line of the proof of Theorem 6.3. We assume that the
involved functions are continuously differentiable on X.

404
11
Introduction to Multiobjective Optimization
Theorem 11.41 (Fritz John necessary conditions) Let x0 ∈S2 be a local weak efﬁ-
cient solution for (M P2). Then there exist multipliers (“Fritz John multipliers”)
(w, u, v) ∈Rq × Rm × Rp such that
(i) q
k=1 wk∇fk(x0) + m
i=1 ui∇gi(x0) + p
j=1 v j∇h j(x0) = 0;
(ii) uigi(x0) = 0, i = 1, . . . , m;
(iii) w ≧0, u ≧0, and (w, u, v) ̸= 0.
Proof If the vectors

∇h1(x0), . . . , ∇h p(x0)

are linearly dependent, the thesis of
the theorem is trivial. Assume, therefore, that these vectors are linearly independent.
From Theorem 6.1 it follows Lo(x0) ⊂T (S2, x0), and in view of Theorem 11.40 we
have that the system
∇f (x0)y < 0
y ∈L0(x0)
is incompatible in y ∈Rn. Taking into account the deﬁnition of Lo(x0), the previous
statement is equivalent to say that the system
⎧
⎨
⎩
∇fk(x0)⊤y < 0, k = 1, . . . , q,
∇gi(x0)⊤y < 0, i ∈I (x0),
∇h j(x0)⊤y = 0, j = 1, . . . , p
admits no solution y ∈Rn. By Motzkin’s theorem of the alternative (Theorem 2.31),
there exist vectors (w, u, v) ∈Rq × RI (x0) × Rp such that (w, u) ̸= 0, w ≧0, u ≧0
and
q

k=1
wk∇fk(x0) +

i∈I (x0)
ui∇gi(x0) +
p

j=1
v j∇h j(x0) = 0.
By choosing ui = 0 for all indices i ∈{1, . . . , m} \ I (x0), we obtain the
thesis.
□
Conditions (i), (ii) and (iii) in Theorem 11.41, by analogy to Theorem 6.3, are
called Fritz John conditions.
Now, we state for (M P2) the Karush-Kuhn-Tucker optimality conditions.
Theorem 11.42 (Karush-Kuhn-Tucker) Let x0 ∈S2 be a local weak efﬁcient solu-
tion for (M P2) and let the Abadie constraint qualiﬁcation be satisﬁed (page
185). Then there exist multipliers (“Karush-Kuhn-Tucker multipliers”) (w, u, v) ∈
Rq × Rm × Rp such that
q

k=1
wk∇fk(x0) +
m

i=1
ui∇gi(x0) +
p

j=1
v j∇h j(x0) = 0;
(11.17)
uigi(x0) = 0, i = 1, . . . , m;
(11.18)
w ≧0, w ̸= 0, u ≧0.
(11.19)

11.3 Optimality Conditions
405
Proof By the Abadie constraint qualiﬁcation we have T (S2, x0) = L(x0) and in
view of Theorem 11.40 we have that the system
∇f (x0)y < 0,
y ∈L(x0)
is incompatible in y ∈Rn. Taking into account the deﬁnition of L(x0), the previous
statement is equivalent to say that the system
⎧
⎨
⎩
∇fk(x0)⊤y < 0, k = 1, . . . , q,
∇gi(x0)⊤y ≦0, i ∈I (x0),
∇h j(x0)⊤y = 0, j = 1, . . . , p
admits no solution y ∈Rn. By Motzkin’s theorem of the alternative (Theorem 2.31),
there exist vectors (w, u, v) ∈Rq × RI (x0) × Rp such that w ≧0, w ̸= 0, u ≧0 and
q

k=1
wk∇fk(x0) +

i∈I (x0)
ui∇gi(x0) +
p

j=1
v j∇h j(x0) = 0.
If we choose ui = 0 for all i ∈{1, . . . , m} \ I (x0), the thesis follows.
□
This theorem has been proved e.g. in Singh [18], Theorem 3.1, and in Lin [19],
Theorem 7.1, under the Kuhn-Tucker constraint qualiﬁcation.
In contrast to Theorem 6.4, where it is required the Guignard-Gould-Tolle con-
straint qualiﬁcation, in Theorem 11.42 we require the Abadie constraint qualiﬁcation.
This is a gap between multiobjective optimization and scalar optimization that has
been pointed out by several authors [20–22]. We can show it in the following example.
Example 11.43 Let us consider the next multiobjective optimization problem:
(M P2) min f (x, y) = (x, y)⊤subject to (x, y) ∈S,
where the feasible set is S = {(x, y) ∈R2 : (2x + y)(x + 2y) ≦0}.
It is easy to check that the point x0 = (0, 0) is an efﬁcient solution using e.g.
Theorem 11.17, that T (S, x0) = S and that cl co T (S, x0) = L(x0) = R2, that is,
the Guignard-Gould-Tolle c. q. is satisﬁed. On the other hand, the Karush-Kuhn-
Tucker conditions are not satisﬁed, since the condition (11.17) is only satisﬁed with
w = (0, 0) and any value of u1. Note that the Abadie c. q. is not satisﬁed.
Next we provide (ﬁrst-order) sufﬁcient conditions for global weak efﬁciency for
problem(M P2)undergeneralizedconvexityfollowingthesameideasasinTheorems
6.6, 6.8 and 6.10.
Theorem 11.44 Let x0 ∈S2 be a point such that (x0, w, u, v) satisfy the Karush-
Kuhn-Tucker conditions (11.17)–(11.19) for some (w, u, v) ∈Rq × Rm × Rp. Let

406
11
Introduction to Multiobjective Optimization
w⊤f be pseudoconvex on the open convex set X ⊂Rn, let every gi, i ∈I (x0), be
quasiconvex on X and let every h j, j = 1, . . . , p, be quasiconvex and quasiconcave
on X. Then x0 is a weak efﬁcient solution of (M P2).
Proof We are applying Theorem 6.6. Let us observe that the functions F = w⊤f =
q
k=1 wk fk, gi, i ∈I (x0), h j, j = 1, . . . , p, satisfy the assumptions of Theorem 6.6
at the point x0 with the multipliers (u, v), and consequently, x0 is a (global) solution
of the problem minx∈S2 w⊤f (x). As w ≧0, w ̸= 0, from Theorem 11.34(i) it follows
that x0 is a weak efﬁcient solution of problem (M P2).
□
Corollary 11.45 Let x0 ∈S2 be a feasible point of (M P2) and assume that every
fk, k = 1, . . . , q, and every gi, i ∈I (x0), are convex on the open convex set X ⊂Rn
and every h j, j = 1, . . . , p, is linear afﬁne. If (x0, w, u, v) satisfy the Karush-Kuhn-
Tucker conditions (11.17)–(11.19) for some (w, u, v) ∈Rq × Rm × Rp, then x0 is a
weak efﬁcient solution of (M P2).
Proof The function w⊤f = q
k=1 wk fk is convex since wk ≧0. By Theorem 3.26(i)
one has that w⊤f is pseudoconvex and by Theorem 3.26(i)–(ii), each gi, i ∈I (x0),
is quasiconvex. Now, the conclusion follows from Theorem 11.44.
□
Similarly to Theorem 6.8 we can give a version for the multiobjective problem
(M P2). We omit the proof because it is easy.
Theorem 11.46 Let x0 ∈S2 be a point such that (x0, w, u, v) satisfy the Karush-
Kuhn-Tucker conditions (11.17)–(11.19) for some (w, u, v) ∈Rq × Rm × Rp, and
in addition, v ≧0. Suppose that w⊤f is pseudoconvex on the open convex set X ⊂Rn
and every gi, i ∈I (x0), and every h j, j = 1, . . . , p, is quasiconvex on X. Then x0
is a weak efﬁcient solution of (M P2).
Similarly to Theorem 6.10 we can provide a sufﬁcient condition of weak efﬁciency
for problem (M P2) with strict pseudoconvexity, in this case based on the Fritz John
conditions.
Theorem 11.47 Let x0 ∈S2 be a point such that (x0, w, u, v) satisfy the Fritz John
conditions (i), (ii) and (iii) in Theorem 11.41 for some (w, u, v) ∈Rq × Rm × Rp,
and in addition, v ≧0. Suppose that every fk, k = 1, . . . , q, is pseudoconvex on the
open convex set X ⊂Rn and every gi, i ∈I (x0), and every h j, j = 1, . . . , p, is
strictly pseudoconvex on X. Then x0 is a weak efﬁcient solution of (M P2).
The proof is very similar to the proof of Theorem 6.10 changing f by fk, k =
1, . . . , q and so we omit it. Other sufﬁcient conditions using different convexities
of the involved functions are given in Singh [18], Lee [23], Aghezzaf and Hachimi
[20], Cambini and Martein [24] and Giorgi et al. [25].
Next we establish optimality conditions of proper efﬁciency in the sense of Kuhn-
Tucker.

11.3 Optimality Conditions
407
Theorem 11.48 Consider a differentiable problem (M P2) and x0 ∈S2.
(i) If x0 is proper efﬁcient in the sense of Kuhn-Tucker, then there exist multipliers
(w, u, v) ∈Rq × Rm × Rp such that
(a) q
k=1 wk∇fk(x0) + m
i=1 ui∇gi(x0) + p
j=1 v j∇h j(x0) = 0;
(b) uigi(x0) = 0, i = 1, . . . , m;
(c) w > 0, u ≧0.
(ii) Conversely, assume that the previous conditions (a), (b) and (c) are satisﬁed,
w⊤f is pseudoconvex on the open convex set X ⊂Rn, every gi, i ∈I (x0), is
quasiconvex on X and every h j, j = 1, . . . , p, is quasiconvex and quasiconcave
on X. Then x0 is proper efﬁcient in the sense of Kuhn-Tucker.
Proof (i) By hypothesis there is no d ∈Rn satisfying system (11.5). Deﬁning the
matrices
B = (∇fk(x0))k=1,...,q, C = (∇gi(x0))i∈I (x0), D = (∇h j(x0)) j=1,...,p,
the incompatibility of system (11.5) is equivalent to saying that the system
Bd ≦0, Bd ̸= 0, Cd ≦0, Dd = 0
has no solution d ∈Rn. By applying the theorem of the alternative of Tucker (p. 45),
there exist vectors (w, u, v) ∈Rq × RI (x0) × Rp such that w > 0, u ≧0 and
q

k=1
wk∇fk(x0) +

i∈I (x0)
ui∇gi(x0) +
p

j=1
v j∇h j(x0) = 0.
If we choose ui = 0 for all i ∈{1, . . . , m} \ I (x0), the thesis follows.
(ii) By the theorem of the alternative of Tucker, saying that conditions (a), (b)
and (c) are satisﬁed is equivalent to saying that system (11.5) has no solution. So we
only have to prove that x0 is efﬁcient.
Proceeding as in the proof of Theorem 11.44, by applying Theorem 6.6 to
F = w⊤f instead of f , we derive that x0 is a (global) solution of the problem
minx∈S2 w⊤f (x). As w > 0, from Theorem 11.34(ii) it follows that x0 is an efﬁcient
solution of problem (M P2).
□
Corollary 11.49 Let x0 ∈S2 and assume that every fk, k = 1, . . . , q, and every gi,
i ∈I (x0), are convex on the open convex set X ⊂Rn and let every h j, j = 1, . . . , p,
is linear afﬁne. If conditions (a), (b), and (c) in Theorem 11.48 are satisﬁed for some
(w, u, v), then x0 is proper efﬁcient in the sense of Kuhn-Tucker. If, in addition, every
gi, i ∈M \ I (x0), is convex, then x0 is also proper efﬁcient in the sense of Geoffrion.
Proof The proof of the fact that x0 is proper efﬁcient in the sense of Kuhn-Tucker
is as in the one of Corollary 11.45, but now we apply Theorem 11.48(ii) instead of
Theorem 11.44.

408
11
Introduction to Multiobjective Optimization
To prove the second part let us note that w⊤f is convex, and so it is pseudocon-
vex, and every gi, i ∈I (x0) is quasiconvex. We have seen in the proof of Theorem
11.48(ii) that x0 is a solution of problem (Pw) with w > 0. In view of Theorem 11.38,
we conclude that x0 is proper efﬁcient in the sense of Geoffrion. We have been able
to apply Theorem 11.38 because S is a convex set since gi, i = 1, . . . , m, are convex
and h j, j = 1, . . . , m, are linear afﬁne.
□
To illustrate the previous results, we provide some examples.
Example 11.50 Consider the biobjective Pareto program with constraints:
min
f (x, y) = (6 −y, x)⊤
subject to
−x + 7y −25 ≦0
x2 + y2 −25 ≦0.
Taking into account that the Abadie c. q. is veriﬁed at every feasible point because
all involved functions are convex,
(a) obtain the points that satisfy the necessary Karush-Kuhn-Tucker conditions to
be a weak efﬁcient point, and
(b) which ones satisfy the necessary conditions in Theorem 11.48(i) to be a proper
efﬁcient point in the sense of Kuhn-Tucker?
(c) We are going to apply Theorem 11.42, conditions (11.17)–(11.19). We have
q = 2, m = 2, f1(x, y) = 6 −y, f2(x, y) = x, g1(x, y) = −x + 7y −25 and
g2(x, y) = x2 + y2 −25, so
∇f1(x, y) = (0, −1)⊤, ∇f2(x, y) = (1, 0)⊤, ∇g1(x, y) = (−1, 7)⊤,
∇g2(x, y = (2x, 2y)⊤,
and the equation (11.17) becomes
w1(0, −1)⊤+ w2(1, 0)⊤+ u1(−1, 7)⊤+ u2(2x, 2y)⊤= (0, 0)⊤.
(11.20)
The feasible set S2 is given in Fig. 11.6. We also highlight there the points
A = (3, 4), B = (−4, 3) and C(−5, 0).
No point x0 = (x, y)⊤in the interior of S2 veriﬁes the K-K-T necessary condi-
tions because g1(x0) < 0 and g2(x0) < 0, and, therefore, u1 = 0 and u2 = 0, con-
sequently, equation (11.20) has no solution verifying (11.19).
Now suppose that x0 is a point on segment AB. If x0 is not a extreme point of AB,
then g2 is not active (g2(x0) < 0), then u2 = 0 (by the Eq. (11.18)), and we have the
solution u1 = 1, u2 = 0, w1 = 7, w2 = 1. Solution that is also valid for x0 = A and
for x0 = B (although for these points, g2(A) = g2(B) = 0 and other solutions can
be found with u2 > 0).
If x0 is a feasible point of the arc of the circumference B A different from the
extremes, then g1 is not active (g1(x0) < 0), and, therefore, u1 = 0. Equation (11.20)
becomes

11.3 Optimality Conditions
409
Fig. 11.6 Example 11.50. Feasible set and points that satisfy Karush-Kuhn-Tucker conditions
w1(0, −1)⊤+ w2(1, 0)⊤+ u2(2x, 2y)⊤= (0, 0)⊤,
(11.21)
that is
w1 = 2yu2
w2 = −2xu2.
If u2 = 0, then w1 = w2 = 0 and (11.19) is not veriﬁed. We can, therefore, assume
that u2 > 0 (speciﬁcally, we chose u2 = 1 to simplify, it could also be solved for
an arbitrary value u2 > 0). Since w1, w2 must be positive (at most one of them can
be 0), it follows that y ≧0, x ≦0. Therefore, the only points of the arc B A that
verify the necessary conditions are those in the arc BC. For all of them, x < 0, so
w2 = −2x, and y > 0, so w1 = 2y = 2
√
25 −x2. The only point for which w1 = 0
is C, but since w2 > 0, satisﬁes the Kuhn-Tucker condition.
In short, the only feasible points that verify the K-T necessary conditions are
the points of the segment AB and those of the arc BC, with all the extreme points
included (set that we will call T ). See Fig. 11.6.
(b) As we have seen in part (a), between the points that verify the K-T necessary
conditions, the only one for which there is no solution with w > 0 is C = (−5, 0).
Remarks:
1. By Corollary 11.45, taking into account that all functions fk, gi are convex, and
there is a solution with w ≧0, w ̸= 0, it follows that all points in T are weak
efﬁcient.
2. ByCorollary11.49,itfollowsthatthepointsintheset T \ {C}areproperefﬁcient
solutions in the Kuhn-Tucker sense and also in the Geoffrion sense.

410
11
Introduction to Multiobjective Optimization
Example 11.51 Consider Example 11.19 and determine all the points that verify the
Karush-Kuhn-Tucker necessary conditions. Which are proper efﬁcient? and weak
efﬁcient? We leave the development to the reader as an exercise and we provide only
the solution.
(a) There is a solution with w > 0 at the points (8 −y, y) with 0 < y ≦5.
(b) There is a solution with w ≧0, w ̸= 0, at the points (x, 0) with 8 ≦x ≦13.
Since all the functions are convex, the points for which exists w > 0 are proper in the
sense of Kuhn-Tucker and in the sense of Geoffrion (Corollary 11.49). By Corollary
11.45, all the points of parts (a) and (b) are weak efﬁcient. Using Theorem 11.17 one
can check that the only efﬁcient point, apart from the points of part (a), is (8, 0).
Example 11.52 Consider the biobjective Pareto program with constraints:
min f (x, y) =

x2 + y2 −8y, 2x + 2y
	⊤
subject to
x2
2 −y ≦0.
Find all feasible points that satisfy the Kuhn-Tucker necessary conditions of weak
efﬁcient point or proper efﬁcient point in the Karush-Kuhn-Tucker sense, and know-
ing that all the functions are convex, determine which points of the previous ones
are proper efﬁcient in the Kuhn-Tucker sense. We also leave the development to the
reader as an exercise and we provide only the solution
Let us note that all the feasible points satisfy the linear independence c. q., and so
they also satisfy the Abadie c. q., and we can apply the Karush-Kuhn-Tucker con-
ditions (11.17)–(11.19) in Theorem 11.42. In this case, conditions (11.17)–(11.19)
become
w1(2x, 2y −8)⊤+ w2(2, 2)⊤+ u(x, −1)⊤= (0, 0)⊤,
(11.22)
w ≧0, w ̸= 0, u ≧0, ug(x, y) = 0.
We have that:
(a) There is a solution with w1 > 0 and w2 > 0 if −2 ≦x < −1, y = x2/2 or if
−2 < x < 0, y = x + 4. Since the program is convex, by Corollary 11.49, they
are Geoffrion proper efﬁcient points, and using the same Corollary 11.49), they
are also Kuhn-Tucker proper efﬁcient.
(b) There is a solution with w1 = 0 and w2 > 0, if x = −1, y = 1/2 and there is a
solution with w1 > 0 and w2 = 0, if x = 0, y = 4. In both cases, we can only
ensure that they satisfy the weak efﬁcient point necessary conditions (Theorem
11.42)andsincetheydonotsatisfythenecessaryconditionsofTheorem11.48(i),
we can say that they are not proper efﬁcient points in the Kuhn-Tucker sense.
The obtained points have been represented in Fig. 11.7.

11.3 Optimality Conditions
411
Fig. 11.7 Example 11.52.
Points that verify the n.c. of
K-K-T proper efﬁciency
(red) and weak efﬁciency
(blue)
Fig. 11.8 Example 11.53.
Feasible set
Example 11.53 Consider the biobjective Pareto program with constraints:
min f (x, y) =

x2 + y2, −x
	⊤
subject to
4 −2y −x2 ≦0
y + x2 −10 ≦0.
Knowing that all feasible points satisfy the Abadie constraint qualiﬁcation (because
the linear independence c. q. is fulﬁlled), obtain all feasible points that verify the
Karush-Kuhn-Tucker necessary conditions of weak efﬁcient point or proper efﬁcient
point in the Kuhn-Tucker sense. Can we apply Corollary 11.49 to see if these points
are proper efﬁcient?
The feasible set for this program is given in Fig. 11.8.
We have f1 = x2 + y2, f2 = −x, g1 = 4 −2y −x2 y g2 = y + x2 −10, and so
Eq. (11.17) becomes
w1(2x, 2y)⊤+ w2(−1, 0)⊤+ u1(−2x, −2)⊤+ u2(2x, 1)⊤= (0, 0)⊤,

412
11
Introduction to Multiobjective Optimization
that is
 2xw1 −w2 = 2xu1 −2xu2
2yw1
= 2u1 −u2
(11.23)
We study several cases depending on the feasible point is an interior or boundary
point in the feasible set.
(1) (x, y) is an interior point. Then u1 = 0, u2 = 0, and system (11.23) becomes
2xw1 −w2 = 0
2yw1
= 0,
(11.24)
which has a non-trivial solution (w ̸= 0), if and only if

2x −1
2y 0
 = 0, that is, if
and only if y = 0. From (11.24) we have that w2 = 2xw1. Therefore, there is a
solution w ≧(0, 0), w ̸= (0, 0) if y = 0 and
• x > 0, any w1 > 0 and w2 = 2xw1 > 0;
• x = 0, any w1 > 0 and w2 = 0, which gives us the point (0, 0), but this point
is not feasible.
Since y = 0, points (x, 0) with 2 ≦x ≦
√
10 and w > (0, 0) are feasible.
Although for x = 2 and x =
√
10, the points (2, 0) and
√
10, 0

are not interior
points, they satisfy the necessary conditions of K-K-T, and so in what follows
we can assume that y ̸= 0.
The solution of system (11.23) can be obtained, for example, by Cramer’s rule
(we assume y ̸= 0), and is given by
⎧
⎪⎨
⎪⎩
w1 = 1
2y (2u1 −u2)
w2 = 2x · 1
2y (2u1 −u2) −2xu1 + 2xu2 = 2x(1 −y)
y
u1 + x(2y −1)
y
u2.
(11.25)
(2) If g2 is not active (u2 = 0) and g1 is active (y = 4−x2
2 ). The system (11.25) is
⎧
⎪⎨
⎪⎩
w1 =
2
4 −x2 u1
w2 = 2x(x2 −2)
4 −x2
u1.
This system has a solution with w1 ≧0 and w2 ≧0 if the following system is
fulﬁlled:
4 −x2 > 0
x(x2 −2) ≧0.
⇒
−2 < x < 2
−
√
2 ≦x ≦0 or x ≧
√
2,

11.3 Optimality Conditions
413
whose solution (to obtain feasible points) is x ∈

−
√
2, 0

∪
√
2, 2
	
, y =
4−x2
2 .
(3) If g1 is not active (u1 = 0) and g2 is active (y = 10 −x2). The solution of system
(11.25) now is
⎧
⎪⎪⎨
⎪⎪⎩
w1 =
−1
2(10 −x2)u2
w2 = x(2y −1)
y
u2 = x(19 −2x2)
10 −x2
u2.
There is a solution with w1 ≧0 and w2 ≧0 if the following system is fulﬁlled:
 10 −x2 < 0
x(19 −2x2) ≦0
⇒

x < −
√
10 or x >
√
10
−√19/2 ≦x ≦0 or x ≧√19/2,
whose solution is x ∈
√
10, 4

, y = 10 −x2, resulting w > 0 for these values.
(4) If g1 and g2 are active (then y = 4−x2
2
and y = 10 −x2), we obtain the points
(−4, −6) and (4, −6). We already know, from part 3), that for (4, −6) there
is a solution. Let’s see what happens with the point (−4, −6). From (11.25) it
results:
 w1 =
1
12(u2 −2u1)
w2 = 2
3(14u1 −13u2).
There is a solution with w1 ≧0 and w2 ≧0 if the following system is fulﬁlled:
u2 −2u1 ≧0, 14u1 −13u2 ≧0.
But this system with u1 ≧0, u2 ≧0 only has the solution u1 = 0, u2 = 0 which
does not give a valid solution since it would be w = (0, 0).
In short: (a) There is a solution with w > 0 at the following points:
(a1) (x, 0) with 2 ≦x ≦
√
10,
(a2) (x, y) with x ∈

−
√
2, 0
	
∪
√
2, 2
	
, y = 4−x2
2 ,
(a3) (x, y) with x ∈
√
10, 4

, y = 10 −x2.
(b) There is a solution with w ≧0, w ̸= 0, at the previous points, and also at the
points (x, y) with x ∈

−
√
2, 0,
√
2

, y = 4−x2
2 , that is the points

−
√
2, 1
	
,
(0, 2) and
√
2, 1
	
(see Fig. 11.9).
Corollary 11.49 can be applied to the points in parts (a1) and (a3), except to the
point x0 = (2, 0) and x1 = (4, −6), and so they are proper efﬁcient in the sense
of Kuhn-Tucker. For the points x0, x1 and for the points in parts (a2) and (b),
Corollary 11.49 cannot be applied because the function g1(x, y) = 4 −2y −x2,
which is active, is not convex (note also that the feasible set is not convex).
Other procedures would have to be used to decide if the points that satisfy the
necessary conditions of K-K-T of Theorem 11.48(i) are proper efﬁcient points.
For example, in this case, if we consider the same biobjective Pareto problem

414
11
Introduction to Multiobjective Optimization
Fig. 11.9 Example 11.53.
Points that satisfy the K-K-T
necessary conditions
but now we replace the constraint 4 −2y −x2 ≦0 by −y −6 ≦0, it results
a convex problem whose feasible set contains the feasible set of the original
problem. Now, all the points in parts (a1) and (a3) satisfy Corollary 11.49 with
the same values of w, u and so they are proper efﬁcient in the senses of Kuhn-
Tucker, Geoffrion, and Benson, and the same happens for the original problem.
For other considerations, see also Exercise 11.79.
Next, we deﬁne the notion of strict local efﬁcient point of order m for the general
problem (M P1). This notion was introduced by Jiménez [26] generalizing the notion
given for a scalar function (Deﬁnition 1.11).
Deﬁnition 11.54 (Jiménez[26])Letm ≧1beanintegernumber.Wesaythat x0 ∈S
is a strict local efﬁcient (or Pareto minimal) point of order m for (M P1) if there are
a neighborhood U(x0) and a constant α > 0 such that
( f (x) + Rq
+) ∩U( f (x0), α∥x −x0∥m) = ∅,
∀x ∈S ∩U(x0) \ {x0},
(11.26)
or equivalently
f (x) /∈f (x0) + U(0, α∥x −x0∥m) −Rq
+,
∀x ∈S ∩U(x0) \ {x0}.
(11.27)
This notion extends to multiobjective optimization the usual notion of a strict local
minimizer of order m (see Deﬁnition 1.11) for a scalar function. Indeed, if q = 1
then (11.27) becomes f (x) /∈f (x0) + (−α∥x −x0∥m, α∥x −x0∥m) −R+, for all
x ∈S ∩U(x0) \ {x0}, which is equivalent to
f (x) ≧f (x0) + α∥x −x0∥m,
∀x ∈S ∩U(x0),
which is just the deﬁnition of a strict local minimizer of order m.

11.3 Optimality Conditions
415
Remark 11.55 Some basic properties are the following:
(i) Every strict local efﬁcient point of order m is also a strict local efﬁcient point of
order s for all s ≧m.
(ii) Every strict local efﬁcient point of order m is also a strict local efﬁcient point.
The behavior under a linear application is stated in the next result.
Theorem 11.56 (Jiménez and Novo [27], Proposition 2.7) Let A : Rq →Rs be a
linear application such that A(Rq
+) ⊂Rs
+. If x0 is a strict local efﬁcient point of
order m for Af on S (with respect to Rs
+), then x0 is a strict local efﬁcient point of
order m for f on S (with respect to Rq
+).
(Here, Af is the function (Af )(x) = A( f (x))).
Proof By assumption, there exist a neighborhood U of x0 and α > 0 such that
(Af (x) + Rs
+) ∩U(Af (x0), α∥x −x0∥m) = ∅∀x ∈S ∩U \ {x0}.
(11.28)
As A is linear, it is also continuous. Hence there exists δ > 0 such that A(U(0, δ)) ⊂
U(0, 1), and, therefore, A(U(0, 1)) ⊂U(0, β), where β = 1/δ. In consequence, by
linearity
A(U(0, ρ)) ⊂U(0, ρβ) ∀ρ > 0.
(11.29)
Let us prove that
( f (x) + Rq
+) ∩U( f (x0), α
β ∥x −x0∥m) = ∅∀x ∈S ∩U \ {x0}.
By contradiction, suppose that there exist ˆx ∈S ∩U \ {x0} and d ∈Rq
+ such that
f (ˆx) + d −f (x0) ∈U(0, α
β ∥ˆx −x0∥m).
Then, from (11.29) we deduce that Af (ˆx) + Ad −Af (x0) ∈U(0, α∥ˆx −x0∥m)
with Ad ∈Rs
+, contradicting (11.28).
□
As a simple application we give an example.
Example 11.57 If x0 is a strict local minimizer of order m for fk on S for some
k ∈{1, . . . , q}, then x0 is a strict local efﬁcient point of order m for f on S.
Indeed, we deﬁne A : Rq →R by Ay = yk (the projection on the kth component).
Clearly, Af = fk and A(Rq
+) ⊂R+. Now the result follows from Theorem 11.56.
Next, in Theorem 11.59 we state a characterization for strict local efﬁcient points
of order 1 under differentiability. Previously we need a lemma.
Lemma 11.58 (Jiménez [26], Proposition 3.4) Let x0 ∈S. Then x0 is not a strict
local efﬁcient point of order m for (M P1) if and only if there exist sequences {xn} ⊂
S \ {x0} and {dn} ⊂Rq
+, such that xn →x0 and

416
11
Introduction to Multiobjective Optimization
lim
n→∞
f (xn) −f (x0) + dn
∥xn −x0∥m
= 0.
(11.30)
Proof “If” part. Since {xn} converges to x0 and (11.30) holds, for all ε > 0 there
exists n0 = n0(ε) such that for every n ≧n0 we have xn ∈S, ∥xn −x0∥< ε and
∥f (xn) −f (x0) + dn∥< ε∥xn −x0∥m, that is,
f (xn) + dn ∈U( f (x0), ε∥xn −
x0∥m).
Reasoning “ad absurdum”, suppose x0 is a strict local efﬁcient point of order m
for (M P1). Then there exists a n.b.h. U(x0) = U(x0, δ) and α > 0 such that (11.26)
holds. Now, for ε = min{δ, α}, there exists n0 = n0(ε) such that for each n ≧n0 we
have xn ∈S ∩U(x0, δ) and
f (xn) + dn ∈U( f (x0), ε∥xn −x0∥m) ⊂U( f (x0), α∥xn −x0∥m),
contradicting (11.26).
“Only if” part. By assumption, for all δ > 0 and for all α > 0 there exists x ∈
S ∩U(x0, δ) \ {x0} such that
( f (x) + Rq
+) ∩U( f (x0), α∥x −x0∥m) ̸= ∅.
In particular, for δ = 1/n and α = 1/n, there exist xn ∈S ∩U(x0, 1/n) \ {x0} and
dn ∈Rq
+ such that
f (xn) + dn ∈U( f (x0), 1
n ∥xn −x0∥m),
that is,
∥f (xn) + dn −f (x0)∥
∥xn −x0∥m
< 1
n ,
and the claim follows.
□
Theorem 11.59 Assume that f is differentiable at x0 ∈S. Then x0 is a strict local
efﬁcient point of order 1 if and only if
∀y ∈T (S, x0) \ {0} ∃k ∈{1, . . . , q} such that ∇fk(x0)⊤y > 0,
or equivalently, T (S, x0) ∩D( f, x0) = {0}, where
D( f, x0) = {y ∈Rn : ∇fk(x0)⊤y ≦0, k = 1, . . . , q}
is the cone of descent directions of f at x0.
Proof (⇒) Let y ∈T (S, x0) ∩D( f, x0) and by contradiction assume that y ̸= 0.
Without lost of generality we can suppose that ∥y∥= 1. As y ∈T (S, x0), there exists
a sequence xn →x0 with {xn} ⊂S \ {x0} and such that
xn−x0
∥xn−x0∥→y. By Lemma
11.27, we have

11.3 Optimality Conditions
417
lim
n→∞
f (xn) −f (x0)
∥xn −x0∥
= ∇f (x0)y.
(11.31)
On the other hand, as x0 is a strict local efﬁcient point of order 1, there exist a
neighborhood U(x0) and α > 0 such that f (x) /∈f (x0) + U(0, α∥x −x0∥) −Rq
+,
for all x ∈S ∩U(x0) \ {x0}, or equivalently
f (x) −f (x0)
∥x −x0∥
∈[U(0, α) −Rq
+]c,
∀x ∈S ∩U(x0) \ {x0}.
As xn →x0, there exists n0 such that xn ∈S ∩U(x0) \ {x0} for all n ≧n0, and,
therefore,
f (xn)−f (x0)
∥xn−x0∥
∈[U(0, α) −Rq
+]c for all n ≧n0. Since [U(0, α) −Rq
+]c is
a closed set, in view of (11.31) it follows that ∇f (x0)y ∈[U(0, α) −Rq
+]c. As
−Rq
+ ⊂U(0, α) −Rq
+, we conclude that ∇f (x0)y /∈−Rq
+, which contradicts the
assumption y ∈D( f, x0).
(⇐) By contradiction, assume that x0 is not a strict local efﬁcient point of order 1.
Then by Lemma 11.58 there exist sequences {xn} ⊂S \ {x0} and {dn} ⊂Rq
+, such
that xn →x0 and
lim
n→∞
f (xn) −f (x0) + dn
∥xn −x0∥
= 0.
(11.32)
Without lost of generality we can suppose that
xn−x0
∥xn−x0∥→y ∈T (S, x0) with y ̸= 0,
and applying Lemma 11.27, we have limn→∞
f (xn)−f (x0)
∥xn−x0∥
= ∇f (x0)y. From (11.32)
it follows that limn→∞
dn
∥xn−x0∥= −∇f (x0)y. From here and since
dn
∥xn−x0∥∈Rq
+ and
Rq
+ is closed, wederivethat ∇f (x0)y ∈−Rq
+. Therefore, y ∈T (S, x0) ∩D( f, x0) \
{0}, which contradicts the hypothesis.
□
Theorem 11.59 is contained in Theorem 4.8 in Jiménez [26], but the proof here
is different.
Corollary 11.60 Consider problem (M P2) and x0 ∈S2. If L(x0) ∩D( f, x0) = {0},
then x0 is a strict local efﬁcient point of order 1 for (M P2).
It is a straightforward consequence of Theorem 11.59 since T (S2, x0) ⊂L(x0)
by Theorem 6.1.
Next we give an equivalent condition to the hypothesis of the previous corollary
in a more operative way.
Theorem 11.61 (Giorgi et al. [28], Theorem 3.4) Consider problem (M P2) and
x0 ∈S2 and assume that among the vectors

∇fk(x0)

k=1,...,q ,

∇gi(x0)

i∈I (x0) ,

∇h j(x0)

j=1,...,p
there are n linearly independent. Then L(x0) ∩D( f, x0) = {0} if and only if there
exist Karush-Kuhn-Tucker multipliers wk > 0, k = 1, . . . , q, ui > 0, i ∈I (x0), v j ∈

418
11
Introduction to Multiobjective Optimization
R, j = 1, . . . , p, such that
q

k=1
wk∇fk(x0) +

i∈I (x0)
ui∇gi(x0) +
p

j=1
v j∇h j(x0) = 0.
We omit the proof, which can be seen in the aforementioned reference.
Next, we provide a sufﬁcient condition for efﬁciency of order 1 based on the Fritz
John conditions.
Theorem 11.62 Let x0 ∈S2 be a point satisfying the Fritz John conditions (i), (ii),
and (iii) in Theorem 11.41 for some (w, u, v) ∈Rq × Rm × Rp. If the vectors

wk∇fk(x0)

k=1,...,q ,

ui∇gi(x0)

i∈I (x0) ,

∇h j(x0)

j=1,...,p
span Rn, then x0 is a strict local efﬁcient solution of order 1 for (M P2).
Proof Suppose that x0 is not a strict local efﬁcient solution of order 1 for (M P2).
Then, by Theorem 11.59 there exists a vector y ∈T (S2, x0), y ̸= 0, such that
∇fk(x0)⊤y ≦0, k = 1, . . . , q. By Theorem 6.1, we have T (S2, x0) ⊂L(x0), and
so y ∈L(x0), which means that ∇gi(x0)⊤y ≦0, i ∈I (x0) and ∇h j(x0)⊤y = 0,
j = 1, . . . , p. Then, multiplying condition (i) in Theorem 11.41 by y⊤and using
condition (ii), we obtain
q

k=1
wk∇fk(x0)⊤y +

i∈I (x0)
ui∇gi(x0)⊤y +
p

j=1
v j∇h j(x0)⊤y = 0.
Taking into account that ∇h j(x0)⊤y = 0, j = 1, . . . , p, it results
q

k=1
wk∇fk(x0)⊤y +

i∈I (x0)
ui∇gi(x0)⊤y = 0.
In view of the facts that ∇fk(x0)⊤y ≦0, k = 1, . . . , q, ∇gi(x0)⊤y ≦0, i ∈I (x0)
and (w, u) ≧0 we derive that wk∇fk(x0)⊤y = 0, k = 1, . . . , q, and ui∇gi(x0)⊤y =
0, i ∈I (x0). By virtue of our assumption on the gradient vectors, the vector y is
orthogonal to every vector in Rn. This implies y = 0, which is a contradiction.
□
Second-order Conditions
We provide in this part second-order necessary and second-order sufﬁcient optimality
conditions for problem (M P2). We assume that the involved functions in (M P2) are
twice-continuously differentiable.
Assume that x0 ∈S2 is a point satisfying the Fritz John conditions (i), (ii) and
(iii) in Theorem 11.41 or the Karush-Kuhn-Tucker conditions for some (w, u, v) ∈
Rq × Rm × Rp. The Lagrangian function is deﬁned by

11.3 Optimality Conditions
419
L (x, w, u, v) = w⊤f (x) + u⊤g(x) + v⊤h(x)
=
q

k=1
wk fk(x) +
m

i=1
uigi(x) +
p

j=1
v jh j(x).
(11.33)
We deﬁne the cone of strict descent directions of f at x0 by
D<( f, x0) = {y ∈Rn : ∇fk(x0)⊤y < 0, k = 1, . . . , q}.
Lemma 11.63 L(x0) ∩D<( f, x0) = ∅if and only if the Karush-Kuhn-Tucker con-
ditions hold at x0.
Proof This
result
follows
from
Motzkin’s
theorem
of
the
alternative
(Theorem 2.31).
□
The cone C(x0) = L(x0) ∩D( f, x0) is called the critical cone. Next we establish
second-order necessary optimality conditions of the Fritz John-type.
Theorem 11.64 Let x0 ∈S2 be a local weak efﬁcient solution for problem (M P2).
Then for any y ∈L(x0) ∩D( f, x0) there are multipliers (w, u, v) ∈Rq × Rm × Rp
such that the Fritz John conditions (i), (ii) and (iii) in Theorem 11.41 are satisﬁed at
x0 and, moreover,
y⊤∇2
xL (x0, w, u, v)y ≧0.
Proof We follow the same lines as in the proof of Theorem 6.39. Let y ∈L(x0) ∩
D( f, x0). If the gradients ∇h j(x0), j = 1, . . . , p, are linearly dependent, then
there exists τ = (τ1, . . . , τp) ̸= 0 such that p
j=1 τ j∇h j(x0) = 0. Hence (w, u, v) =
(0, 0, τ) and (w, u, v) = (0, 0, −τ) are Fritz John multipliers that satisfy the (ﬁrst-
order) Fritz John conditions. Moreover, condition (11.36) is satisﬁed either by
(0, 0, τ) or by (0, 0, −τ) since
y⊤∇2
xL (x0, 0, 0, −τ)y = −y⊤∇2
xL (x0, 0, 0, τ)y.
Therefore, for any y ∈L(x0) ∩D( f, x0) we can choose one of the two possibilities,
so that (11.36) is satisﬁed.
We now assume that the gradients ∇h j(x0), j = 1, . . . , p, are linearly inde-
pendent. Consider the following linear programming problem in the variables
(α, z) ∈R × Rn:
⎧
⎪⎪⎨
⎪⎪⎩
min α
subject to: ∇fk(x0)⊤z + y⊤∇2 fk(x0)y ≦α, k = 1, . . . , q,
∇gi(x0)⊤z + y⊤∇2gi(x0)y ≦α, i ∈I (x0, y),
∇h j(x0)⊤z + y⊤∇2h j(x0)y = 0, j = 1, . . . , p,
(11.34)
where I (x0, y) = {i ∈I (x0) : ∇gi(x0)⊤y = 0}. The optimal value of this problem
is nonnegative. Indeed, otherwise there exists z which satisﬁes

420
11
Introduction to Multiobjective Optimization
⎧
⎨
⎩
∇fk(x0)⊤z + y⊤∇2 fk(x0)y < 0, k = 1, . . . , q,
∇gi(x0)⊤z + y⊤∇2gi(x0)y < 0, i ∈I (x0, y),
∇h j(x0)⊤z + y⊤∇2h j(x0)y = 0, j = 1, . . . , p.
(11.35)
By Lemma 6.37, there exists a path γ : [0, δ] →Rn satisfying conditions (6.22).
Then, by a second-order Taylor expansion, we have for t > 0 small enough and for
all k = 1, . . . , k that
fk(γ (t)) = fk(x0) + t∇fk(x0)⊤y + 1
2t2 
∇fk(x0)⊤z + y⊤∇2 fk(x0)y

+ o(t2) < fk(x0)
due to the ﬁrst condition in (11.35) and the fact that y ∈D( f, x0). Therefore, for t >
0 small enough, γ (t) ∈S2 is feasible and fk(γ (t)) < fk(x0), k = 1, . . . , q, which
contradicts the local weak efﬁciency of x0. This proves that (11.34) has a nonnegative
optimal value.
Since ∇h j(x0), j = 1, . . . , p, are linearly independent, the equality constraints
of (11.34) have a feasible solution because rk ∇h(x0) = p and so ∇h(x0)(Rn) =
Rp, and thus there exists z ∈Rn such that ∇h j(x0)⊤z + y⊤∇2h j(x0)y = 0 for all
j = 1, . . . , p, and hence, since α can be made arbitrarily large, problem (11.34) is
consistent. Therefore, problem (11.34) has a ﬁnite nonnegative optimal value. Since
(11.34) is a linear programming problem, it follows, by the Strong Duality Theorem
of Linear Programming (see Remark 9.19), that its dual, in the variables w, u, v, with
ui = 0 for i /∈I (x0, y), has the same optimal value. The dual of (11.34) is
max y⊤
⎛
⎝
q

k=1
wk∇2 fk(x0) +

i∈I (x0,y)
ui∇2gi(x0) +
p

j=1
v j∇2h j(x0)
⎞
⎠y
subject to:
q

k=1
wk∇fk(x0) +

i∈I (x0,y)
ui∇gi(x0) +
p

j=1
v j∇h j(x0) = 0,
q

k=1
wk +

i∈I (x0,y)
ui +
p

j=1
v j = 1,
wk ≧0, k = 1, . . . , q; ui ≧0, i ∈I (x0, y).
Since an optimal solution of this dual problem is a Fritz John multipliers vector
associated with x0, by choosing ui = 0 for i /∈I (x0, y), we get the thesis.
□
This theorem has been proved, with a different proof, in Bigi and Castellani [29].
The drawback of the previous theorem is that it may be w = 0. If the Mangasarian-
Fromovitz c. q. is satisﬁed, this case cannot occur.

11.3 Optimality Conditions
421
Theorem 11.65 Let x0 ∈S2 be a local weak efﬁcient solution for problem (M P2)
and let x0 verify the Mangasarian-Fromovitz c. q. Then for any y ∈L(x0) ∩D( f, x0)
there are multipliers (w, u, v) ∈Rq × Rm × Rp (that depend on y) such that the
Karush-Kuhn-Tucker conditions are satisﬁed at x0 and, moreover,
y⊤∇2
xL (x0, w, u, v)y ≧0.
(11.36)
Proof The result follows as a consequence of Theorem 11.64 taking into account
that the Mangasarian-Fromovitz c. q. allows to assure that w ̸= 0.
□
Some authors as Bigi and Castellani [30] have discussed the uniqueness of the
Karush-Kuhn-Tucker multipliers in multiobjective optimization. They state that,
ﬁxed w, there is uniqueness if and only if the strict Mangasarian-Fromovitz c.q.
(SMFCQ) holds. In order to obtain uniqueness without ﬁxing a unit vector w a pri-
ori, they introduce a new regularity condition, strengthening (SMFCQ) in such a way
that the objective functions fk are also involved, introducing a quite strong regularity
condition. We refer to the paper by these authors for more details.
The boundedness of the set of Karush-Kuhn-Tucker multipliers has been also
studied under a regularity condition involving the objective functions in Dutta and
Lalitha [31]. We refer to this paper to study this topic.
Let 
(x0) be the set of all the Karush-Kuhn-Tucker multipliers (w, u, v) at a
feasible point x0. Under the validity of the Mangasarian-Fromovitz c. q., it is then
possible to write the thesis of Theorem 11.65 in the form
sup
(w,u,v)∈
(x0)
y⊤∇2
xL (x0, w, u, v)y ≧0, ∀y ∈L(x0) ∩D( f, x0).
Now we turn to second-order sufﬁcient optimality conditions for (M P1) and
(M P2). We follow the approach of Jiménez and Novo [32].
Deﬁnition 11.66 Consider problem (M P1), x0 ∈S and let F : Rn →R be differ-
entiable at x0 and w ∈Rq, w ≧0, w ̸= 0. We say that the pair (w, F) is a (lower)
support for f at x0 on S if the following three relations hold:
(i) F(x) ≦q
k=1 wk fk(x) for all x ∈S,
(ii) F(x0) = q
k=1 wk fk(x0),
(iii) ∇F(x0) = 0.
We say that (w, F) is a weak support if the previous relations (i), (ii), and (iii)
hold and w ≧0 (w = 0 is admitted).
The scalarization process contained in the previous deﬁnition is going to allow
us, on the one hand, to follow a parallel path to the scalar case and, on the other hand,
to apply the results from the scalar programming.
Remark 11.67 (a) Deﬁnition 11.66 is equivalent to say that F is a support (in the
Hestenes sense, see p. 102) for the scalar function w⊤f = q
k=1 wk fk.

422
11
Introduction to Multiobjective Optimization
(b) Consider problem (M P2). If the Karush-Kuhn-Tucker conditions (11.17)–
(11.19) are satisﬁed for some (w, u, v) ∈Rq × Rm × Rp, then, calling F to the
Lagrangian function
F(x) = L (x, w, u, v),
we have that (w, F) is a support for f at x0 on S2 and the proof is immediate.
(c) If the Fritz John conditions (i), (ii) and (iii) in Theorem 11.41 are satisﬁed at
x0, then (w, L (·, w, u, v)) is a weak support for f at x0 on S2.
(d) If in Deﬁnition 11.66, condition (i) holds on a relative neighborhood of x0,
S ∩U(x0, δ), instead of on all S, we will say that F is a local support. Although the
theory below developed is valid for this type of support because the notions that are
used are local, we have employed (global) supports for simplicity reasons.
The following theorem provides some basic properties satisﬁed if a support exists.
Note that the ﬁrst property coincides with the ﬁrst order necessary optimality condi-
tion (Theorem 11.40).
Theorem 11.68 (i) If (w, F) is a support for f at x0 on S and f is differentiable at
x0, then T (S, x0) ∩D<( f, x0) = ∅.
(ii) If (w, F) is a weak support for f at x0 on S, F is twice differentiable at x0 and
there exists y ∈T (S, x0) such that y⊤∇2F(x0)y > 0, then w ̸= 0, that is, (w, F) is
a support.
Proof (i) Let G(x) = q
k=1 wk fk(x) −F(x). Conditions (i), (ii) and (iii) in Deﬁni-
tion 11.66 are equivalent to the following: (1) G(x) ≧0 ∀x ∈S, 2) G(x0) = 0 and 3)
∇G(x0) = q
k=1 wk∇fk(x0). Conditions (1) and (2) imply that x0 is a minimum of
G on S. Using Theorem 4.24, it follows that ∇G(x0)⊤y ≧0 ∀y ∈T (S, x0), which,
taking into account condition (3), is equivalent to
q

k=1
wk∇fk(x0)⊤y ≧0,
∀y ∈T (S, x0).
(11.37)
Reasoning “ad absurdum”, assume that there exists y ∈T (S, x0) ∩D<( f, x0). Then,
∀k = 1, . . . , q, ∇fk(x0)⊤y < 0. As w ≧0 and w ̸= 0, one has q
k=1 wk∇fk(x0)⊤
y < 0, contradicting (11.37).
(ii) We have that y = lim
n→∞
xn −x0
tn
for some sequences {xn} ⊂S, {tn} →0+. Let
us assume w = 0. With the notation of the previous part, now G(x) = −F(x) ≧0
∀x ∈S, G(x0) = 0, x0 is a minimum of G on S, ∇G(x0) = 0 and y⊤∇2G(x0)y < 0.
But, by using a second-order Taylor expansion, one has
1
2 y⊤∇2G(x0)y = lim
n→∞
G(xn) −G(x0)
t2n
≧0,
which is a contradiction.
□

11.3 Optimality Conditions
423
Based on the notion of support function, we give some ﬁrst-order sufﬁcient opti-
mality conditions.
Theorem 11.69 If (a) (w, F) is a support for f at x0 on S and (b) T (S, x0) ∩
[D( f, x0) \ D<( f, x0)] = {0}, then x0 is a strict local efﬁcient point of order 1 for
(M P1).
Proof Condition (b) is equivalent to
T (S, x0) ∩D( f, x0) ∩D<( f, x0)c = {0}.
(11.38)
From Theorem 11.68(i), T (S, x0) ∩D<( f, x0) = ∅, hence, T (S, x0) ∩D<( f, x0)c
= T (S, x0). Therefore, taking into account (11.38), it follows that T (S, x0) ∩
D( f, x0) = {0}. By Theorem 11.59, x0 is a strict local efﬁcient point of order 1
for (M P1).
□
Theorem 11.70 Consider problem (M P2). If the Karush-Kuhn-Tucker conditions
(11.17)–(11.19) are satisﬁed at x0 and T (S2, x0) ∩[D( f, x0) \ D<( f, x0)] = {0},
then x0 is a strict local efﬁcient point of order 1 for (M P2).
Proof From Remark 11.67(b), (w, L (·, w, u, v)) is a support for f at x0 on S2, and
then it sufﬁces to apply Theorem 11.69.
□
Next, several second-order sufﬁcient optimality conditions are provided.
Theorem 11.71 Let S ⊂Rn, x0 ∈S, f : Rn →Rq differentiable at x0. If for every
y ∈T (S, x0) ∩D( f, x0) \ {0} there is a weak support (w, F) for f at x0 on S, which
is twice differentiable at x0 and such that y⊤∇2F(x0)y > 0, then x0 is a strict local
efﬁcient point of order 2 for (M P1).
Proof By contradiction, assume that x0 is not a strict local efﬁcient point of order 2,
then, by Lemma 11.58, there exist sequences {xn} ⊂S \ {x0} and {dn} ⊂Rq
+, such
that xn →x0 and
lim
n→∞
f (xn) −f (x0) + dn
∥xn −x0∥2
= 0.
(11.39)
Without lost of generality, we can suppose that
lim
n→∞
xn −x0
∥xn −x0∥= y ∈T (S, x0)
with ∥y∥= 1. If for some k ∈{1, . . . , q}, ∇fk(x0)⊤y > 0, then by Lemma 11.27 one
has lim
n→∞
fk(xn) −fk(x0)
∥xn −x0∥
= ∇fk(x0)⊤y,andconsequently lim
n→∞
fk(xn) −fk(x0)
∥xn −x0∥2
=
+∞. From (11.39), we have
lim
n→∞
 fk(xn) −fk(x0)
∥xn −x0∥2
+
dn
k
∥xn −x0∥2

= 0,

424
11
Introduction to Multiobjective Optimization
and so limn→∞
dn
k
∥xn−x0∥2 = −∞, which is impossible because dn
k ≧0. Therefore, for
all k ∈{1, . . . , q}, ∇fk(x0)⊤y ≦0, that is, y ∈D( f, x0). Hence, y ∈T (S, x0) ∩
D( f, x0) and y ̸= 0, and by assumption, there is a weak support (w, F) such that
y⊤∇2F(x0)y > 0.
Now, applying to (11.39) the continuous linear function from Rq to R given by
z →w⊤z, it results
lim
n→∞
w⊤f (xn) −w⊤f (x0) + w⊤dn
∥xn −x0∥2
= 0.
(11.40)
Let G be the function deﬁned in the proof of Theorem 11.68, i.e. G(x) =
w⊤f (x) −F(x) ≧0, hence w⊤f (x) = F(x) + G(x) for x ∈S, and replacing in
(11.40) we obtain
lim
n→∞
 F(xn) −F(x0)
∥xn −x0∥2
+ G(xn) + w⊤dn
∥xn −x0∥2

= 0,
(11.41)
As ∇F(x0) = 0, it follows limn→∞
F(xn)−F(x0)
∥xn−x0∥2
= 1
2 y⊤∇2F(x0)y > 0, and in con-
sequence limn→∞
G(xn)+w⊤dn
∥xn−x0∥2
< 0, but this is a contradiction because G(xn) ≧0 and
w⊤dn ≧0 for all n.
□
Corollary 11.72 Let f : Rn →Rq be twice differentiable at x0 ∈S ⊂Rn. If there
exists w ∈Rq, w ≧0, w ̸= 0 such that
(a)
q
k=1 wk∇fk(x0) = 0,
(b)
the quadratic form q(v) = q
k=1 wk y⊤∇2 fk(x0)y is positive deﬁnite on the
cone T (S, x0) ∩{y ∈Rn : wk∇fk(x0)⊤y = 0 ∀k = 1, . . . , q},
then x0 is a strict local efﬁcient point of order 2 for f on S.
Proof Firstly, let us suppose w > 0. Let y ∈D( f, x0), this means that ∇fk(x0)⊤y ≦
0 for all k = 1, . . . , q. If for some k, ∇fk(x0)⊤y < 0, then q
k=1 wk∇fk(x0)⊤y < 0
which contradicts (a). Hence, for all k = 1, . . . , q, ∇fk(x0)⊤y = 0. Consequently,
D( f, x0) = ker ∇f (x0) = {y ∈Rn : wk∇fk(x0)⊤y = 0 ∀k = 1, . . . , q} and
T (S, x0) ∩D( f, x0) = T (S, x0) ∩{y ∈Rn : wk∇fk(x0)⊤y = 0 ∀k = 1, . . . , q}.
(11.42)
If T (S, x0) ∩D( f, x0) = {0}, by Theorem 11.59, x0 is a strict local efﬁcient point
of order 1 and, therefore, x0 is a strict local efﬁcient point of order 2 by Remark
11.55(i).
If T (S, x0) ∩D( f, x0) ̸= {0}, then we consider F = q
k=1 wk fk. One has, obvi-
ously, that (w, F) is a support for f .
By assumption (b), taking into account (11.42), ∀y ∈T (S, x0) ∩D( f, x0) \ {0}
we have that y⊤∇2F(x0)y > 0, since ∇2F(x0) = q
k=1 wk∇2 fk(x0). Therefore, by
Theorem 11.71, x0 is a strict local efﬁcient point of order 2.

11.3 Optimality Conditions
425
Let now w ≧0. Rearranging, we can suppose that w = (w1, . . . , ws, ws+1, . . . ,
wq) with w1 > 0, …, ws > 0, ws+1 = 0, …, wq = 0 and s ≧1. Consider the linear
map A : Rq →Rs given by A(z1, . . . , zq) = (z1, . . . , zs), i.e. the projection from Rq
to Rs on the s ﬁrst components, and let g = (g1, . . . , gs) = Af . Clearly, gk = fk for
k = 1, . . . , s. Moreover, condition (a) and (b) of the hypothesis become:
(a′) s
i=1 wi∇gi(x0) = 0 and
(b′) the quadratic form q0(y) = s
i=1 wi y⊤∇2gi(x0)y is positive deﬁnite on the
cone T (S, x0) ∩{y ∈Rn : ∇gi(x0)⊤y = 0 ∀i = 1, . . . , s}.
Using the ﬁrst part, we derive that x0 is a strict local efﬁcient point of order 2 for
g on S. Finally, as A(Rq
+) = Rs
+, by Theorem 11.56 we conclude that x0 is a strict
local efﬁcient point of order 2 for f on S.
□
Example 11.73 Let f : R3 →R3 given by
f (x1, x2, x3) = (x1 + (x2)2 −(x3)3, −x1 + (x3)2 + (x2)3, x2x3)⊤,
S = {(x1, x2, x3) ∈R3 : x2 ≧0} and x0 = (0, 0, 0)⊤. The assumptions of Corol-
lary 11.72 are satisﬁed with w = (1, 1, 0)⊤. Note that 3
k=1 wk y⊤∇2 fk(x0)y =
2(y2)2 + 2(y3)2, which is positive deﬁnite on T (S, x0) ∩{y ∈R3 : ∇fk(x0)⊤y =
0, k = 1, 2} = {(y1, y2, y3) : y2 ≧0, y1 = 0}. Thus, we derive that x0 is a strict
local efﬁcient point of order 2 for f .
Next, the general result (Theorem 11.71) is applied to problem (M P2). The fol-
lowing theorem is an immediate consequence of the aforesaid theorem taking into
account Remark 11.67(b).
Theorem 11.74 Considerproblem(M P2)andlet x0 ∈S2.Ifforevery y ∈T (S2, x0)
∩D( f, x0) \ {0} there exist multipliers (w, u, v) satisfying the Karush-Kuhn-Tucker
conditions (11.17)–(11.19) and such that y⊤∇2
xL (x0, w, u, v)y > 0, then x0 is a
strict local efﬁcient point of order 2 for (M P2).
Corollary 11.75 Consider problem (M P2) and let x0 ∈S2. If for every y ∈L(x0) ∩
D( f, x0) \ {0} there exist multipliers (w, u, v) satisfying the Karush-Kuhn-Tucker
conditions (11.17)–(11.19) and such that y⊤∇2
xL (x0, w, u, v)y > 0, then x0 is a
strict local efﬁcient point of order 2 for (M P2).
This corollary is a straightforward consequence of the previous theorem since
T (S2, x0) ⊂L(x0).
The following example shows that the Lagrangian function varies on the vector.
The functions have already been considered by Ben-Tal [33] in Examples 2.1 and 4.1.
Example 11.76 Consider f : R3 →R3 deﬁned by
f (x, y, z) = ( 1
2 x2 + 2yz,
1
2 y2 + 2xz,
1
2z2 + 2xy)⊤,

426
11
Introduction to Multiobjective Optimization
S = R3 and x0 = (0, 0, 0)⊤. We have that L(x0) ∩D( f, x0) = R3. The accom-
plished calculations by Ben-Tal prove that several Lagrangian functions (until six)
are needed to get
R3 \ {0} ⊂{y ∈R3 : ∃L (x0, w, u, v) | y⊤∇2
xL (x0, w, u, v)y > 0},
and that just with only one it is impossible to obtain it. Therefore, x0 is a strict local
efﬁcient point of order 2.
In Corollary 11.75 the Lagrangian function L can vary on the vector y ∈L(x0) ∩
D( f, x0) \ {0}. If the same Lagrangian function L is valid for all the vectors y we
obtain the next result.
Corollary 11.77 Consider problem (M P2) and let x0 ∈S2. Suppose that there exist
multipliers (w, u, v) satisfying the Karush-Kuhn-Tucker conditions (11.17)–(11.19)
and such that
y⊤∇2
xL (x0, w, u, v)y > 0 ∀y ∈L(x0) ∩D( f, x0) \ {0}.
Then x0 is a strict local efﬁcient point of order 2 for (M P2).
Next, we are going to state in Theorem 11.78 another second-order sufﬁcient
condition with ﬁxed multipliers. Previously, some of the notation.
Assume that x0 ∈S2 is a point satisfying the Fritz John conditions (i), (ii) and
(iii) in Theorem 11.41 or the Karush-Kuhn-Tucker conditions (11.17)–(11.19) for
some (w, u, v) ∈Rq × Rm × Rp. Consider the Lagrangian function L deﬁned by
Eq. (11.33). It is clear that ∇xL (x0, w, u, v) = 0.
We deﬁne the following sets:
Q+(w) = {k ∈Q : wk > 0};
I +(x0, u) =

i ∈I (x0) : ui > 0

;
I o(x0, u) =

i ∈I (x0) : ui = 0

= I (x0) \ I +(x0, u);
S2(u) = {x ∈S2 : gi(x) = 0, i ∈I +(x0, u)};
L(x0, u) =
 y ∈Rn : ∇gi(x0)⊤y ≦0, i ∈I o(x0, u); ∇gi(x0)⊤y = 0, i ∈I +(x0, u);
∇h j(x0)⊤y = 0, j ∈P

= L(x0) ∩ker ∇gI +(x0),
(11.43)
where gI + is the function of components (gi)i∈I +,
D( f, x0, w) = {y ∈Rn : ∇fk(x0)⊤y ≦0, k ∈Q \ Q+; ∇fk(x0)⊤y = 0, k ∈Q+}
= D( f, x0) ∩ker ∇fQ+(x0)

11.3 Optimality Conditions
427
where fQ+ is the function of components ( fk)k∈Q+. For brevity, we have written I +
and Q+ instead of I +(x0, u) and Q+(w), respectively.
Let us observe that L(x0, u) is the linearized cone associated with the set S2(u).
Theorem 11.78 Consider problem (M P2) and let x0 ∈S2. Suppose that there exist
multipliers (w, u, v) satisfying the Karush-Kuhn-Tucker conditions or the Fritz John
conditions and such that
y⊤∇2
xL (x0, w, u, v)y > 0,
∀y ∈L(x0, u) ∩D( f, x0, w) \ {0}.
Then x0 is a strict local efﬁcient point of order 2 for (M P2).
Proof Let us check that
L(x0) ∩D( f, x0) = L(x0, u) ∩D( f, x0, w).
(11.44)
The inclusion “⊃” is obvious. Let y ∈L(x0) ∩D( f, x0). Taking into account the
Karush-Kuhn-Tucker conditions or the Fritz John conditions and the deﬁnition of
the sets I +(x0, u) and Q+(w), the Lagrangian function (11.33) can be written
L (x, w, u, v) =

k∈Q+
wk fk(x) +

i∈I +
uigi(x) +
p

j=1
v jh j(x).
As ∇xL (x0, w, u, v) = 0, it results

k∈Q+
wk∇fk(x0) +

i∈I +
ui∇gi(x0) +
p

j=1
v j∇h j(x0) = 0.
Multiplying by y⊤, and using that ∇h j(x0)⊤y = 0, j = 1, . . . , p, we obtain

k∈Q+
wk∇fk(x0)⊤y +

i∈I +
ui∇gi(x0)⊤y = 0.
(11.45)
As y ∈D( f, x0) one has ∇fk(x0)⊤y ≦0, k ∈Q+, and as y ∈L(x0) one has
∇gi(x0)⊤y ≦0, i ∈I +. Hence, wk∇fk(x0)⊤y ≦0, k ∈Q+ and ui∇gi(x0)⊤y ≦
0, i ∈I +, and taking into account (11.45), we deduce that wk∇fk(x0)⊤y = 0,
k ∈Q+ and ui∇gi(x0)⊤y = 0, i ∈I +. From here, ∇fk(x0)⊤y = 0, k ∈Q+ and
∇gi(x0)⊤y = 0,i ∈I +,whichallowsustoconcludethat y ∈L(x0, u) ∩D( f, x0, w)
in view of (11.43).
Now, the thesis follows from (11.44) and Corollary 11.77.
□
This theorem is a slight modiﬁcation of Theorem 5.4 in Jiménez and Novo [32].
For other results on second-order sufﬁcient optimality conditions in multiobjective
optimization, see Wang [34] and Aghezzaf and Hachimi [35].
We illustrate the previous results with an example.

428
11
Introduction to Multiobjective Optimization
Example 11.79 Consider Example 11.53. Let us recall that the points of the form
x(t) =

t, 4−t2
2
	⊤with t ∈A =

−
√
2, 0

∪
√
2, 2
	
satisfy the Karush-Kuhn-
Tucker conditions with w = w(t) =
2u1
4−t2

1, t(t2 −2)
	
, arbitrary u1 > 0 and u2 = 0.
Thus,
w1(t)∇f1(x(t)) + w2(t)∇f2(x(t)) + u1∇g1(x(t)) = 0
We want to study if these points satisfy some sufﬁcient optimality conditions. Let us
observe that the unique active constraint is g1 for all t ∈A, i.e. I (x(t)) = {1}.
As 4 −t2 > 0 on A, one has w(t) > 0 ⇔t(t2 −2) > 0 ⇔t ∈

−
√
2, 0
	
∪
√
2, 2
	
= int A. Moreover, the set of vectors
∇f1(x(t)) = (2t, 4 −t2)⊤, ∇f2(x(t)) = (−1, 0)⊤, ∇g1(x(t)) = (−2t, −2)⊤
has rank 2 for all t ∈A. By Theorem 11.61 we derive that L(x(t)) ∩D( f, x(t)) =
{0}, and from Corollary 11.60 we conclude that x(t) is a strict local efﬁcient point
of order 1 for all t ∈int A.
Ift ∈

−
√
2, 0,
√
2

= A \ int A,wehave T (S2, x(t)) = L(x(t)) = {(y1, y2) ∈
R2 : −2ty1 −2y2 ≦0}, and
CT (x(t)) = T (S2, x(t)) ∩D( f, x(t))
=

(y1, y2) ∈R2 : −2ty1 −2y2 ≦0, 2ty1 + (4 −t2)y2 ≦0, −y1 ≦0

=

(y1, y2) ∈R2 : y2 ≧−ty1, y2 ≦−2t
4−t2 y1, y1 ≧0

.
(a1) If t = 0, then CT (x(0)) =

(y1, y2) ∈R2 : y2 = 0, y1 ≧0

. In view of The-
orem 11.59, x(0) = (0, 2)⊤is not a strict local efﬁcient point of order 1.
(a2) If t = −
√
2, then CT

x

−
√
2
		
=

(y1, y2) ∈R2 : y2 =
√
2y1, y1 ≧0

.
In view of Theorem 11.59, x

−
√
2
	
=

−
√
2, 1
	⊤is not a strict local efﬁcient
point of order 1.
(a3) If t =
√
2, then CT

x
√
2
		
=

(y1, y2) ∈R2 : y2 = −
√
2y1, y1 ≧0

. In
view of Theorem 11.59, x
√
2
	
=
√
2, 1
	⊤is not a strict local efﬁcient point of
order 1.
Now, for these three points, we study the second-order conditions. The Hessian
of the Lagrangian function at x(t) is given by
∇2L (x(t)) =
2u1
4−t2
t2 −2 0
0
2

,
and we have to study the sign of the quadratic form
qt(y) = y⊤∇2L (x(t))y =
2u1
4−t2 [(t2 −2)y2
1 + 2y2
2]
with y = (y1, y2)⊤. Let us note that C(x(t)) = L(x(t)) ∩D( f, x(t)) = CT (x(t)).

References
429
(b1)Ift = 0,thenq0(y) = 1
2u1(−2y2
1 + 2y2
2) = −u1y2
1 < 0 forall y ∈C(x(0)) \
{0}, so by applying Theorem 11.64, x0 = (0, 2)⊤is not a local weak efﬁcient solution.
(b2) If t ∈{−
√
2,
√
2}, then qt(y) = u1(2y2
2) > 0 for all y ∈C(x(t)) \ {0}, so
by applying Corollary 11.77, x(t) is a strict local efﬁcient point of order 2.
The previous results are of local type (the points are locally efﬁcient except the
point (0, 2)), and they do not allow to assure if the studied points are globally efﬁcient.
To establish global efﬁciency, Theorem 11.44 cannot be applied because the function
g1 isnotquasiconvex,butonecanbeappliedTheorem11.17resultinginthefollowing
(as the reader can check):
• for t = −
√
2, x

−
√
2
	
is weak efﬁcient;
• for t ∈

−
√
2, 0

, x(t) is not weak efﬁcient;
• for t ∈
√
2, 2
	
, x(t) is strictly efﬁcient.
References
1. M. Ehrgott, Multicriteria Optimization, 2nd edn. (Springer, Berlin, 2005)
2. K.M.Miettinen,NonlinearMultiobjectiveOptimization(KluwerAcademicPublishers,Boston,
1999)
3. Y. Sawaragi, H. Nakayama, T. Tanino, Theory of Multiobjective Optimization (Academic,
Orlando, 1985)
4. J. Jahn, Vector Optimization. Theory, Applications, and Extensions, 2nd edn. (Springer, Berlin,
2011)
5. D.T. Luc, Theory of Vector Optimization. Lecture Notes in Economic and Mathematics Systems,
vol. 319 (Springer, Berlin, 1989)
6. F.Y. Edgeworth, Mathematical Psychics (P. Keagan, London, 1881)
7. V. Pareto, Manuale di Economia Politica (Societa Editrice Libraria, Milano, 1906) Translated
into English by A.S, Schwier as Manual of Political Economy (Macmillan, New York, 1971)
8. W. Stadler, A survey of multicriteria optimization, or the vector maximum problem. J. Optim.
Theory Appl. 29, 1–52 (1979)
9. R.E. Steuer, Multiple Criteria Optimization. Theory, Computation and Application, Wiley
Series in Probability and Statistics (Wiley, New Jersey, 1986)
10. H.W. Kuhn, A.W. Tucker, Nonlinear programming, in Proceedings of the Second Berkeley Sym-
posium on Mathematical Statistics and Probability, ed. by J. Neyman (University of California
Press, Berkeley, 1951), pp. 481–492. Reprinted in Giorgi and Kjeldsen (2014)
11. J.M. Borwein, On the existence of Pareto efﬁcient points. Math. Oper. Res. 8, 64–73 (1983)
12. P. Ruiz-Canales, A. Ruﬁán-Lizana, A characterization of weakly efﬁcient points. Math. Pro-
gram. 68, Ser. A, 205–212 (1995)
13. A.M. Geoffrion, Proper efﬁciency and the theory of vector maximization. J. Math. Anal. Appl.
22, 618–630 (1968)
14. J.M. Borwein, Proper efﬁcient points for maximization with respect to cones. SIAM J. Control
Optim. 15, 57–63 (1977)
15. H.P. Benson, An improved deﬁnition of proper efﬁciency for vector minimization with respect
to cones. J. Math. Anal. Appl. 71, 232–241 (1979)
16. M.I. Henig, Proper efﬁciency with respect to cones. J. Optim. Theory Appl. 36, 387–407 (1982)
17. A. Guerraggio, E. Molho, A. Zaffaroni, On the notion of proper efﬁciency in vector optimiza-
tion. J. Optim. Theory Appl. 82, 1–21 (1994)

430
11
Introduction to Multiobjective Optimization
18. C.Singh,Optimalityconditionsinmultiobjectivedifferentiableprogramming.J.Optim.Theory
Appl. 53, 115–123 (1987)
19. J.G. Lin, Maximal vectors and multiobjective optimization. J. Optim. Theory Appl. 18, 41–64
(1976)
20. B. Aghezzaf, M. Hachami, On a gap between multiobjective optimization and scalar. J. Optim.
Theory Appl. 109, 431–435 (2001)
21. M. Castellani, M. Papalardo, About a gap between multiobjective optimization and scalar
optimization. J. Optim. Theory Appl. 109, 437–439 (2001)
22. S.Y. Wang, F.M. Yang, A gap between multiobjective optimization and scalar optimization. J.
Optim. Theory Appl. 68, 389–391 (1991)
23. G.M. Lee, Optimality conditions in multiobjective optimization problems. J. Inf. Optim. Sci.
13, 107–111 (1992)
24. A. Cambini, L. Martein, Generalized convexity and optimality conditions in scalar and vector
optimization, in Handbook of Generalized Convexity and Generalized Monotonicity. ed. by N.
Hadjisavvas, S. Komlosi, S. Schaible (Springer, New York, 2005), pp. 151–193
25. G. Giorgi, B. Jiménez, V. Novo, Sufﬁcient optimality conditions and duality in nonsmooth
optimization problems under generalized convexity, in Generalized Convexity and Related
Topics. ed. by I.V. Konnov, D.T. Luc, A.M. Rubinov (Springer, New York, 2007), pp. 265–278
26. B. Jiménez, Strict efﬁciency in vector optimization. J. Math. Anal. Appl. 265, 264–284 (2002)
27. B. Jiménez, V. Novo, First and second order sufﬁcient conditions for strict minimality in
nonsmooth vector optimization. J. Math. Anal. Appl. 284, 496–510 (2003)
28. G. Giorgi, B. Jiménez, V. Novo, A note on ﬁrst-order conditions for Pareto problems. Numer.
Funct. Anal. Optim. 29, 1108–1113 (2008)
29. G. Bigi, M. Castellani, Second order optimality conditions for differentiable multiobjective
problems. RAIRO Oper. Res. 34, 411–426 (2000)
30. G. Bigi, M. Castellani, Uniqueness of KKT multipliers in multiobjective optimization. Appl.
Math. Lett. 17, 1285–1290 (2004)
31. J. Dutta, C.S. Lalitha, Bounded sets of KKT multipliers in vector optimization. J. Global Optim.
36, 425–437 (2006)
32. B. Jiménez, V. Novo, First and second order sufﬁcient conditions for strict minimality in
multiobjective programming. Numer. Funct. Anal. Optim. 23, 303–322 (2002)
33. A. Ben-Tal, Second-order and related extremality conditions in nonlinear programming. J.
Optim. Theory Appl. 31, 143–165 (1980)
34. S.Y. Wang, Second-order necessary and sufﬁcient conditions in multiobjective programming.
Numer. Funct. Anal. Optim. 12, 237–252 (1991)
35. B. Aghezzaf, M. Hachami, Second order optimality conditions in multiobjective optimization
problems. J. Optim. Theory Appl. 102, 37–50 (1999)

Index
A
Active constraints, 124, 170
C
Combination
afﬁne, 24
convex, 24
convex conic, 24
linear, 24
Complementary slackness conditions, 128
Cone, 24
bipolar, 36
Bouligand tangent, 47
Clarke normal, 354
Clarke tangent, 154
contingent, 47
convex, 24
critical, 202, 419
extended critical, 203
ﬁnite, 27
ﬁnitely generated, 27, 38
isotone, 370
linearizing, 112, 125, 170
normal, 50
of attainable directions, 51
of critical directions, 202
of descent directions, 176
of epi-Lipschitzian directions, 369
of feasible directions, 51
of interior directions, 216
of quasi-interior directions, 216
of strict descent directions, 419
pointed, 22
polar, 36
polyhedral, 28
positive polar, 36
radial, 51
recession, 368
Rockafellar hypertangent, 369
Constraint qualiﬁcation, 128
Abadie, 138, 185
Abadie II, 187
Arrow-Hurwicz-Uzawa, 138
Arrow-Hurwicz-Uzawa II, 187
constant positive linear dependence, 189
Constant Rank, 188
Cottle, 138
Guignard-Gould-Tolle, 129, 137, 175,
184
Karlin, 248
Kuhn-Tucker, 138, 185
linear independence, 140, 188
Mangasarian-Fromovitz, 185
Slater, 140, 187
strict, 248
strict Mangasarian-Fromovitz, 191
Zangwill, 138
D
Directional derivative, 63
Clarke, 343
Clarke-Rockafellar, 373
epi-Lipschitzian, 373
left-sided, 319
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2023
G. Giorgi et al., Basic Mathematical Programming Theory, International Series
in Operations Research & Management Science 344,
https://doi.org/10.1007/978-3-031-30324-1
431

432
Index
lower Dini, 344
lower Dini-Hadamard, 372
lower Ursescu, 372
right-sided, 319
upper Dini, 344
upper Dini-Hadamard, 372
upper Ursescu, 372
Dual problem
Lagrangian, 256
Mond Weir, 267
Wolfe, 260
E
Efﬁcient point, 385
local, 389
local strict, 389
local weak, 389
strict, 385
strils local of order m, 414
weak, 385
Efﬁcient solution, 21
weak, 21
F
Feasible set, 10
Function
Clarke invex, 365
Clarke pseudoconvex, 363
Clarke quasiconvex, 364
Clarke regular, 349
coercive, 17
concave, 53
continuously differentiable, 4
contraction, 337
convex, 53
differentiable, 3
directionally differentiable, 320
Gâteaux differentiable, 64
indicator, 331
invex, 72
Lagrangian, 107, 177, 418
Lagrangian dual, 256
Lipschitz continuous, 337
locally Lipschitz, 338
lower semi-continuous, 14
marginal, 226
optimal value, 226
perturbation, 226
preinvex, 71
proper convex, 319
pseudoconvex, 67
quasiconvex, 65
semistrictly quasiconvex, 68
strictly concave, 53
strictly convex, 53
strictly differentiable, 348
sublinear, 54
twice differentiable, 3
upper semi-continuous, 14
G
Geometrical method, 104
H
Half-spaces, 31
Hull
afﬁne, 25
convex conic, 25
linear, 25
Hyperplane, 5
separating, 32
K
K-subdifferential, 374
K-subgradient, 374
L
Lagrange multipliers rule, 113
Lagrange regular, 194
Least-squares method, 94
Linear programming problem
basic solution, 285
degenerate basic solution, 285
dual, 290
feasible basic solution, 285
primal in canonical form, 289
primal in standard form, 290
Local cone approximation, 368
M
Matrix
Hessian, 4
Jacobian, 4
Minimizer
global, 10
isolated local, 12
local, 11
strict global, 12
strict local, 12

Index
433
N
Nonsmooth analysis, 317
O
Objective function, 10
P
Point
Clarke stationary, 355
critical, 84
Lagrangian saddle, 244
saddle, 85
stationary, 84
Polytope, 30
Problem
activity analysis, 277
assignment, 277
diet, 277
linear programming, 275
quadratic programming, 301
transportation, 277
Proper efﬁciency, 392
Benson, 394
Borwein, 394
Geoffrion, 393
Kuhn-Tucker, 395
Q
Quadratic form, 7
deﬁnite, 7
indeﬁnite, 7
semideﬁnite, 7
S
Sensitivity analysis, 225
Set
convex, 23
convex hull, 25
lower level, 15
of the active constraints, 124
properly separable, 32
regular, 217
separable, 32
strictly convex, 23
strongly separable, 32
upper level, 61
Shadow prices, 240
Subdifferential, 318
Clarke, 346
Subgradient, 318
T
Taylor’s formula, 4
Theorem
Caratheodory, 27
Cottle, 311
Elster and Thierfelder, 378
equilibrium, 297
Fermat, 84
Fermat rule for Lipschitz functions, 355
ﬁrst fundamental on L.P., 280
Fritz John, 127, 172, 404
generalized Weierstrass, 16
implicit function, 6
Karush-Kuhn-Tucker, 130, 175, 404
Kojima, 235
Kuhn-Tucker-Uzawa, 247
Minkowski-Weyl, 40
Moreau-Rockafellar, 329
saddle point and duality, 298
second fundamental on L.P., 286
strict converse duality, 262
strict direct duality, 261
strong duality, 259
Sylvester criterion, 8
weak duality, 258
Weierstrass, 16
Theorem of the alternative, 41
Farkas, 42
Fredholm, 43
Gale, 43
Gordan, 44
Ky Fan, 43
Motzkin, 43
Slater, 45
Tucker, 45
W
Weighted sum method, 399

