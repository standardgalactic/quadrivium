 
From Logic to Logic Programming 

Foundations of Computing 
Michael Garey and Albert Meyer, editors 
Complexity Issues in VLSI: Optimal Layouts for the Shuffie-Exchange Graph and Other 
Networks, Frank Thomson Leighton, 1983 
Equational Logic as a Programming Language, Michael J. O'Donnell, 1985 
General Theory of Deductive Systems and Its Applications, S. Yu Maslov, 1987 
Resource Allocation Problems: Algorithmic Approaches, Toshihide Ibaraki and Naoki 
Katoh, 1988 
Algebraic Theory of Processes, Matthew Hennessy, 1988 
PX: A Computational Logic, Susumu Hayashi and Hiroshi Nakano, 1989 
The Stable Marriage Problem: Structure and Algorithms, Dan Gusfield and Robert Irv­
ing, 1989 
Realistic Compiler Generation, Peter Lee, 1989 
Single-Layer Wire Routing and Compaction, F. Miller Maley, 1990 
Basic Category Theory for Computer Scientists, Benjamin C. Pierce, 1991 
Categories, Types, and Structures: An Introduction to Category Theory for the Working 
Computer Scientist, Andrea Asperti and Giuseppe Longo, 1991 
Semantics of Programming Languages: 
Structures and Techniques, Carl A. Gunter, 
1992 
The Formal Semantics of Programming Languages: An Introduction, Glynn Winskel, 
1993 
Hilbert's Tenth Problem, Yuri V. Matiyasevich, 1993 
Exploring Interior-Point Linear Programming: 
Algorithms and Software, Ami Arbel, 
1993 
Theoretical Aspects of Object-Oriented Programming: Types, Semantics, and Language 
Design, edited by Carl A. Gunter and John C. Mitchell, 1993 
From Logic to Logic Programming, Kees Doets, 1994 

From Logic to Logic Programming 
Kees Doets 
The MIT Press 
Cambridge, Massachusetts 
London, England 

© 1994 Massachusett.s Institute of Technology 
All rights reserved. No part of this book may be reproduced in any form by any electronic or 
mechanical means (including photocopying, recording, or information storage and retrieval) without 
permission in writing from the publisher. 
This book was set in Computer Modern by the author and was printed and bound in the United States 
of America. 
Library of Congress Cataloging-in-Publication Data 
Doets, Kees. 
From logic to logic programming / Kees Doets. 
p. 
cm. - (Foundations of computing) 
Includes bibliographical references and index. 
ISBN 0-262-04142-1 
1. Logic programming. 
I. Title. 
II. Series. 
QA 76.63.064 
1994 
005.1-dc20 
93-6196 
CIP 

Contents 
Series Foreword 
ix 
Preface 
xi 
1 
Preliminaries 
1 
1.1 
Mathematical Induction 
1 
1.2 
Trees 
3 
1.3 
Multisets 
5 
1.4 
Ordinals and Cardinals 
9 
1.5 
Notes 
11 
2 
Propositional Logic 
13 
2.1 
Syntax 
13 
2.2 
Semantics 
15 
2.3 
Conjunctive Normal Form 
17 
2.4 
Resolution 
20 
2.5 
Notes 
27 
3 
First-order Logic 
29 
3.1 
Introduction 
29 
3.2 
Syntax 
29 
3.3 
Semantics 
31 
3.4 
Quantifier-free Sentences 
36 
3.5 
Universal Sentences 
41 
3.6 
Prenex and Skolem Forms 
46 
3.6.1 Prenex Form 
49 
3.6.2 Skolem Form 
49 
3.6.3 Compactness 
52 
3.7 
Resolution: The Unrestricted Version 
54 
3.8 
Unification 
57 
3.9 
Resolution 
65 
3.10 Notes 
68 

vi 
Contents 
4 
Program-definability 
71 
4.1 
Programs 
71 
4.2 
The Least Herbrand Model 
73 
4.3 
Fixed Points 
76 
4.4 
Hierarchies 
80 
4.5 
Definability 
85 
4.6 
Representing Domains as Herbrand Universes 
87 
4.6.1 Natural Numbers 
87 
4.6.2 Binary Notation 
88 
4.6.3 Lists 
90 
4.7 
Notes 
91 
5 
Linear Resolution 
93 
5.1 
Preliminaries 
93 
5.2 
Unrestricted Linear Resolution 
95 
5.3 
Ground Completeness 
99 
5.4 
Linear Resolution 
102 
5.4.1 Motivation 
102 
5.4.2 Resolvents 
102 
5.4.3 Derivations 
107 
5.5 
SLD-Resolution 
114 
5.6 
Notes 
119 
6 
Infinite Derivations 
121 
6.1 
Negative Information 
121 
6.2 
Non-standard Algebras 
122 
6.3 
Resolution over Non-standard Algebras 
126 
6.4 
Realization Trees 
130 
6.5 
The Interplay of SLD-trees and Realization Trees 
134 
6.6 
Notes 
139 

Contents 
vii 
7 
Computability 
141 
7.1 
Preliminaries 
141 
7.2 
Computability of Recursive Functions 
148 
7.3 
Complexity of Tp! 
155 
7.3.1 Analytical Hierarchy 
155 
7.3.2 Kleene Normal Form 
158 
7.3.3 Well-founded Part 
160 
7.3.4 Co-defining m-Relations 
162 
7.4 
Notes 
163 
8 
Negation 
165 
8.1 
Introduction 
165 
8.2 
Negation Implemented: SLDNF 
167 
8.3 
3-Valued Models 
174 
8.4 
3-Valued Consequence Operator 
176 
8.5 
Soundness 
178 
8.6 
Saturation 
180 
8.7 
Completeness for SLDNF 
185 
8.7.1 Modes 
185 
8.7.2 Completeness 
190 
8.8 
Notes 
195 
Bibliography 
197 
Rules and Programs 
201 
Notation 
203 
Index 
207 

Series Foreword 
Theoretical computer science has now undergone several decades of development. The 
"classical" topics of automata theory, formal languages , and computational complexity 
have become firmly established , and their importance to other theoretical work and to 
practice is widely recognized. Stimulated by technological advances, theoreticians have 
been rapidly expanding the areas under study, and the time delay between theoreti­
cal progress and its practical impact has been decreasing dramatically. Much publicity 
has been given recently to breakthroughs in cryptography and linear programming, and 
steady progress is being made on programming language semantics, computational ge­
ometry, and efficient data structures . 
Newer , more speculative, areas of study include 
relational databases , VLSI theory, and parallel and distributed computation. As this list 
of topics continues expanding, it is becoming more and more difficult to stay abreast 
of the progress that is being made and increasingly important that the most significant 
work be distilled and communicated in a manner that will facilitate further research and 
application of this work. By publishing comprehensive books and specialized monographs 
on the theoretical aspects of computer science, the series on Foundations of Computing 
provides a forum in which important research topics can be presented in their entirety 
and placed in perspective for researchers, students, and practitioners alike. 
Michael R. Garey 
Albert R. Meyer 

Preface 
Resolution is a single-rule refutability technique for logical formulas that, at least in 
principle, is suitable for use on the computer. 
This book discusses resolution in the 
versions for three logical formalisms: propositional logic, first-order logic, and the so­
called Horn-fragment of first-order logic, in the context of which it is called (definite) 
logic programming. Resolution in propositional logic forms the basis for the first-order 
version. 
Though the version for the Horn-fragment appears to be just a special case 
of the one for full first-order logic, it nevertheless is the most important of the three 
since it can be given a computational component also. As a recent logic programming 
symposium announcement puts it, initial interest in logic programming derived from the 
discoveries that a simple fragment of logic, Horn clauses, could be given a computational 
interpretation and that a programming language, Prolog, could be designed from that 
simple fragment. 
In fact, since resolution forms the main logical ingredient of Prolog, 
logic programming can be looked at as providing a theoretical basis for this programming 
language. 
Chapter 1 of this book contains preliminaries on mathematical induction, trees, mul­
tisets and ordinals. Propositional resolution - also called the cut rule, which permits 
one to derive 6. V r from 6. V A and r V -.A - is dealt with in Chapter 2, which also 
contains all necessary preliminary details on propositional calculus. Chapter 3 is about 
general first-order logic. After a speedy, but essentially complete, introduction to the 
syntax and semantics of this formalism, resolution is defined as that particular case of 
unrestricted resolution producing most general resolvents, unrestricted resolution being 
the extension of the propositional resolution rule that allows preliminary instantiation of 
the premisses. This approach yields completeness rather smoothly. Chapter 4 introduces 
(positive) programs, their least Herbrand models, and program-definability. Chapter 5 
follows an approach to logic programming similar to the one of Chapter 3: resolution 
again is defined as that particular case of unrestricted resolution that, in a precise sense, 
produces most general results. Compared with the traditional, ad-hoc way of defining re­
solvents, the slightly more abstract approach advocated here has several advantages. For 
instance, invariance with respect to renamings is immediate. Our approach also makes 
evident that maximal generality of derivations (resolution iterated) has two sources: the 
particular way in which resolvents are defined, and the non-confusion of variables. This 
clarifies an important issue on which the existing literature (with a multitude of compet­
ing approaches on "standardization-apart") does not seem to have a clear-cut answer. 
The resulting form of the Lifting Theorem generalizes known results. Chapter 6 gener­
alizes resolution over the Herbrand algebra to resolution over non-standard algebras and 
contains general information on infinite derivations. Chapter 7 contains a crash course 

xii 
Preface 
on recursive function theory, shows that all recursive functions are program-computable, 
and ends with a self-contained presentation of results of Blair and Kunen, showing that 
greatest fixed points may be very complex. Finally, Chapter 8 contains what is probably 
the first completely adequate description of the notion of SLDNF -tree, discusses Fitting's 
3-valued interpretation, and presents Stark's completeness theorem. 
A reader with some logical background who is primarily interested in logic program­
ming can skip Chapters 2 and 3 (with the exception of the discussion of unification in 
Section 3.8). The core of logic programming theory is in Chapters 4 and 5. 
Except for 
minor things (e.g., Chapter 8 uses the material on lifting ground steps from Chapter 6), 
Chapters 6, 7 and 8 can be read independently from one another. 
The material of this book lends itself easily to exercises with algorithmic solutions. 
Though we certainly do not want to underestimate the value of exercises of this type (to 
carry out at least some of them will be necessary to get a feeling of what is going on), it 
is not the purpose of this book to teach people to behave like computers. Thus, if readers 
wish to find conjunctive, prenex, clausal , and Skolem forms, unify sequences of terms and 
refute formulas or compute functions using (SLD) (SLDNF) resolution, they can easily 
think of the necessary exercises themselves, or find them in one of the references listed 
at the end . 
With [Apt 90] as a starting point, the actual writing of this book began in the summer 
of 1991 as a joint enterprise of Krzysztof Apt and myself, beginning with Krzysztof 
teaching me the basics of Unix, Emacs and UTEX. One year later, I more or less finished 
my part of the undertaking, leaving to my co-author matters dealing with applications 
and Prolog, mainly centering around termination and occur check. Due to circumstances 
partly unforeseen, Krzysztof unfortunately had to leave the project , and I decided to 
publish the material in its present form. However, the contents still bear the marks of 
our (quite fruitful) cooperation, and the debts lowe to my former co-author cannot be 
overestimated. In particular, the definition of SLDNF tree in Chapter 8 is a result of 
joint efforts. 
Finally, many thanks are due to my colleague Maarten de Rijke for his patience and 
ingenuity in solving a number of problems relating to the incorporation of sty files sup­
plied by the publisher, and to the people of MIT Press, in particular to Beth LaFortune 
Gies and Bob Prior, for a fine cooperation. 

From Logic to Logic Programming 

 
1 Preliminaries 
The notations from set theory and logic that we use are standard. Explanations can be 
found at the beginning of the list of notations at the end of this book. 
1.1 
Mathematical Induction 
The set {O, 1,2, .
.
.
 } of natural numbers 0, 1, 2, .
.
.
 is designated by IN. Note that 0 is 
considered to be a natural number (the first one). 
Principle 1.1 (Induction) If E is a property of natural numbers such that 
(i) E(O) - i.e., E holds of 0 - and 
(ii) for every natural number n: if E(n), then E(n + 1) 
then E holds of every natural number. 
• 
Though this principle sounds pretty much obvious, it is nevertheless the main tool for 
proving universal statements of the form V'n E IN: E(n). A proof by induction of such a 
statement thus consists of proving two things: 
(i) E(O). 
This is called the basis of the induction. 
(ii) V'nEIN [E(n) ::} E(n + 1)]. 
This is called the induction step. 
To carry out the induction step, you clearly must assume that an unspecified natural 
number n satisfies E - this assumption is called the induction hypothesis - and you 
have to show, presumably making use of this assumption, that n + 1 satisfies E, as well. 
The nice thing about a proof with induction is that the induction hypothesis comes free. 
For a first example of a proof by induction, see Theorem 1.2. 
Induction sometimes is formulated and used with sets of numbers instead of properties: 
If X is a set of natural numbers such that 
(i) 0 E X, and 
(ii) for all nEIN, if n E X, then n + 1 E X; 
then X = IN. 
This form is equivalent with the previous one, as with any property E of natural numbers 
is associated the set X := {n E IN I E(n)} of numbers satisfying E, and, conversely, a 
subset X C IN of IN determines the property E( n) ::: n E X of being an element of X. 1 
A variant of induction is the following principle of strong induction. Again, we give 
the version with properties. 
1 We use := and := for: is by definition equal to, resp.: is by definition equivalent with. 

2 
Chapter 1 
Theorem 1.2 (Strong Induction) If E is a property of natural numbers such that 
"In [("1m < n : E(m)) => E(n)], 
then every natural number satisfies E. 
Note that, for n 
= 0, the condition "1m < n : E(m) is trivially satisfied (there are no 
natural numbers < 0), and therefore the implication ("1m < 0 : E(m)) => E(O) amounts 
to E(O). This explains the "disappearance" of the basis of the induction compared with 
1.1. 
Strong induction is called strong because the induction hypothesis that the induction 
step is allowed to use here is stronger than the one of 1.1: in order to show that E( n) , 
you may suppose that for all m < n ,  E(m) instead of only for m = n - 1. Nevertheless, 
strong induction is provable from simple induction, via a trick. 
Proof. Define a second property E' by 
E'(n) := "1m < n :  E(m). 
The hypothesis of the theorem exactly says that E' (n) => E( n). Therefore, to prove the 
conclusion of the theorem, it suffices to show that 
VnElN E'(n). 
This we do, using ordinary induction "with respect to n". 
Basis. 
That E'(O) holds is evident, as 0 is the least natural number; and so the statement 
"1m < 0 E(m) holds vacuously. 
Induction step. 
Induction hypothesis: Assume that E'(n), where n is an arbitrary number. 
We have to show that E'(n + 1) holds. This amounts to: \1m < n + 1 : E(m). Now 
since we have the equivalence m < n + 1 ¢:} m < n V m = n, this again amounts to: 
["1m < n : E(m)]/\. E(n). However, the first conjunct simply coincides with the induction 
hypothesis, and it implies the second conjunct by assumption. 
• 
In the future, numbers usually occur in a concealed way only. For instance, we shall 
often deal with formal expressions. Expressions are finite sequences of symbols; hence, 
their length is a natural number. It follows that statements of the form 'for every expres­
sion A, we have that ... A . .. ' are open to proof by induction with respect to the length 
of the expressions involved. Still other forms of induction shall be dealt with when the 
need arises. 

Preliminaries 
3 
Exercises 
1.1 (Least number principle) Prove that every non-empty set of natural numbers has 
a least element. Thus, descending infinite sequences no > nl > n2 > .. , of natural 
numbers do not exist. 
Hint. Assume that 0 #- Xc IN, Apply strong induction to the property E(n) := n E 
IN-X. 
1.2 Show: if the property E of natural numbers and p E IN are such that (i) E(p); (ii) 
'inElN [E(n) Ǐ E(n + 1)], then 'in Z pEen). 
1.3 Assume that E(O), E(l) and E(n) => E(n + 2). Show that 'in E IN E(n). 
1.4 Assume that the function f : IN-lN is such that 'in E IN (f(n + 1) ::; f(n». 1. 
Show that for some m E IN: 
f(m + 1) 
= f(m). 2. Show that for some m E IN: 
\In f(m + n) = f(m), 
1.5 Assume that f : IN-lN is such that \In, mE IN (n < m => fen) < f(m». Show: 
'in ElN (n :5 fen»Ó. 
1.2 
Trees 
The remaining sections of this chapter may be omitted until needed. 
They discuss 
trees and Konig's Lemma (the present section), multisets, multiset ordering and well­
foundedness (Section 1.3) and ordinals (Section 1.4). 
Let X and Y be sets, The set of all ordered pairs (x, y) with x E X and y E Y is 
denoted by X x Y. For X = Y, X2 := X x X, A (binary) relation on a set X is a 
mapping R that assigns to every pair of elements (x, y) E X2 a statement xRy that is 
either true or false. For instance, the familiar ordering < of the set of natural numbers 
IN assigns to the ordered pair (2,5) the true statement that 3 < 5, whereas it assigns to 
(3,3) the false one that 3 < 3. The standard set-theoretic viewpoint identifies a relation 
R on X with the subset {(x,y) I xRy} of X2 of pairs (x,y) for which xRy is true, and 
this is what we usually shall do. Thus, < is identified with the set {(n, m) I n < m}, 
which contains (2,5) but does not contain (3,3). 
In this chapter, all relations are binary. However, the notion of n-ary relation (n E IN, 
n #- 2), which occurs from Chapter 3 onwards, is obtained entirely similarly, this time 
assigning statements to n-tuples from xn of elements from the relevant domain X. An 
1-ary relation also is called unary, A unary relation is identified with the set of things 
satisfying it. 
Definition 1.3 A directed graph is a structure (T, R) where T is a non-empty set and 
R is a binary relation on T. Let (T, R) he a directed graph, A (backward R-) path from 

4 
Chapter 1 
8 E T to t E T is a finite sequence 80 = s, . .. ,Sn = t ( n ?: 1) such that for all i < n, 
SHIRsi. 
A structure T = (T, R, u) , where (T, R) is a directed graph and u E T, is a tree if for all 
sET there is a unique path from u to s. 
The elements of T are called the nodes of T, and u is the root of 7. The pairs (s, t) E R 
are called edges of T. 
If sRt, then s is called a child of t and t the parent of s. A childless node is a leaf If 
there is a path from t to s, then s is a descendant of t. 
T is finitely branching if every node has at most finitely many children. 
The notion of path is extended to infinite sequences as follows. An infinite sequence 
to, h, t2,'" will be called a path if every finite initial sequence to, ... , tn is a path in the 
aforementioned sense. A branch through T is a maximal path; that is, a path that starts 
from the root and either ends in a leaf or is infinite. 
I 
Note our convention that paths and branches run backwards in the relation R: our trees 
"grow against" the direction given by R. 
If we picture a tree with its relation R directed downwards, it looks more or less like 
a tree found in nature, growing upward from the root towards its leaves (if any). This is 
the picture of the proof trees in Chapters 2 and 3. 
However, the resolution trees occurring from Chapter 5 onwards usually will be pictured 
growing downward. 
Remark 1.4 
(i) If T = (T, R, u) is a tree, then from the unicity condition in the definition it follows 
that R has no loops. That is, there is no path from a node to that same node. In 
practice, however, we frequently employ trees that do appear to have loops. To get 
a tree properly satisfying the defining condition, we may imagine that one node 

Preliminaries 
5 
has several different occurrences in the tree. For instance, the one-element "tree" 
( {U}, {( u, U)}, u) must be thought of as infinite, its root u having infinitely many 
occurrences forming an infinite branch uo, Ul! U2,' ... 
(ii) Note that a tree T is completely described by specifying 
• its root, 
• for every node, what its children are. 
I 
The following is the one simple but useful result on finitely branching trees. 
Lemma 1.5 (Konig) Every infinite, finitely branching tree has an infinite branch. 
Proof. Let T = (T, R, u) be an infinite, finitely branching tree. We use the pigeon-hole 
principle: if an infinite set is partitioned in finitely many pieces, then (since a finite union 
of finite sets must be finite) at least one of the pieces must be infinite. 
Construct the required branch Uo = U, Ul, U2, •
.
.
 through T such that for every i, Ui 
has infinitely many descendants. 
To begin with, Uo 
= U has infinitely many descendants, since T is infinite. Suppose 
the path Uo = U, ... , Un is found such that Un has infinitely many descendants. Every 
descendant of Un either is a child of Un or a descendant of one of the finitely many 
children of Un. By the pigeon-hole principle, Un has a child Un+! with infinitely many 
descendants. This completes the construction of our branch. 
• 
1.3 
Multisets 
In (the presentation of) a set, order and multiplicity do not count. In a multiset, order 
still does not count, but multiplicity does. To motivate the formal definition, consider 
the case of the characteristic function of a subset A C X of a given set X. This is the 
function XA : X --+{O, I} defined by 
{I ifxEA 
XA(X) = 
0 
if x ¢ A. 
Note that A can be recovered from its characteristic function, since we have that A = 
{xEX I XA(X) = I}. Now, a characteristic function is just a special type of multiset. 
Definition 1.6 Let X be a set. A multiset over X is a function f : X -IN. 
The elements of D(j) := {xEX I f(x) =I- O} are called elements of f. 
For x E D(j), the number f(x) is called the multiplicity of x in f. 
f is called finite if D(j) is finite. In that case, If I := EXED(f) f(x) is called the number 
of elements of f· 
• 

6 
Chapter 1 
Notation 1.7 If f is a finite multiset over X, D(f) = {Xl, .
. . ,xn}, and e: {I, .
.
.
 , Ifl}-+ 
D(f) is such that, for 1 ::; i ::; n, {j E Dom(e) I e(j) = xd has exactly f(Xi) elements, 
then f may be written as {{ e(1), .
.
.
 , e( I fl)}}· 
In this notation, when e(j) = Xi, e(j) is called an occurrence of Xi. 
I 
Example. If D(f) = {O, 1, 2}, f(O) = 2, f(l) = 1 and f(2) = 3, then If I = 6 and f can 
be written as, e.g., {{O, 0,1,2,2, 2}}, {{2, 0,1,0,2, 2}} and {{I, 2, 0, 2, 0, 2}}. This notation 
of multisets allows for the use of the set-theoretic operations of union, intersection and 
subtraction. E.g., {{3, 3, 4, 4, 7, 9}} = ({{3, 7, 7, 9}} 
- {{7}}) U {{3, 4, 4}}. 
I 
A relation R on X is transitive if for all X, y, z E X, if both xRy and yRz, then xRz. 
For instance, the ordering < on IN is transitive. 
The following lemma says that every relation - conceived of as a set of pairs - is 
contained in a transitive one, and among those, there is a least one. 
Lemma 1.8 Let R be a binary relation on the set X. There is a least transitive relation 
S on X such that ReS. 
Proof. Define S by: xSy iff there is a backward R-path from y to x. 
I 
Definition 1.9 The least transitive relation containing R is called the transitive closure 
of R; we denote it by Rtr. 
I 
Examples. If R is the successor relation on IN defined by: nRm :::= n + 1 = m, then 
Rtr is the familiar ordering < of IN. If R is the child-parent relation in some tree , then 
Rtr is the descendant relation. If R is the relation of parenthood between humans, then 
Rtr is the one of ancestorship. 
I 
The next definition introduces the multiset ordering . 
A (partial) ordering of X is a relation < on X that is irrefiexive (for no X EX, X < x) 
and transitive . For instance, since trees do not have loops, the descendant relation on a 
tree is a partial ordering . 
A partial ordering < of X is linear if for every two different x, y E X either X < yor 
y < x. For instance, the ordering < of lN is linear , but the descendant relation of a tree 
usually is not. 
To avoid unnecessary abstractness, the reader may as well digest what follows with 
X = IN and < the usual ordering of IN in mind . 
Definition 1.10 Let < be a partial ordering of the set X. The multiset ordering over 
(X, <) is the transitive closure of the relation of immediate precedence on the collection 
of finite multisets over X, where 9 immediately precedes f iff for some x E D(f), we have 
(i) g(x) = f(x) - 1, (ii) '<:/y < x[g(y) ƴ f(y)] and (iii) '<:/y Ȝ x[g(y) = f(y)]. 
I 

Preliminaries 
7 
Thus, 9 precedes f if it can be obtained from f by replacing one occurrence of an element 
x of f by some occurrences of elements y < x. 
Example. For X = IN, we have 
{{3, 3, 4, 4,7, 9}} immediately precedes {{3, 7, 7, 9}}, 
since {{3, 3, 4, 4, 7, 9}} = ({{3, 7, 7, 9}} - {{7}})U{{3, 4, 4}}: to obtain {{3, 3, 4, 4, 7, 9}} from 
{{3, 7, 7, 9}}, one (occurrence of the) element 7 of {{3, 7, 7, 9}} is replaced by the finite 
multiset {{3, 4, 4}} of elements all smaller than 7. 
I 
Definition 1.11 A binary relation on a set is well-founded if it has no infinite path. 
A well-founded linear ordering is called a well-ordering. 
I 
Along a well-founded relation there may be arbitrarily long infinite increasing sequences 
(see Section 1.4), but every decreasing sequence must come to a stop at some minimal 
element after finitely many steps. 
All finite linear orderings and (IN, <) are well-orderings (Exercise 1.1). (IN, » is a 
linear ordering that is not a well-ordering. 
Note that a tree is well-founded iff it has no infinite branch. So, Konig's Lemma may 
be stated as follows: every well-founded, finitely branching tree is finite. 
The purpose of the rest of this section is to show that (Theorem 1.13) the multiset 
ordering over a well-founded partial ordering is well-founded. 
Lemma 1.12 The transitive closure of a well-founded relation is well-founded. 
Proof. See Exercise 1.9. 
• 
Theorem 1.13 The multiset ordering over a well-founded ordering is well-founded. 
Proof. By Lemma 1.12, it suffices to show that the immediate precedence relation, whose 
transitive closure is the multiset ordering, is well-founded. We argue by contradiction. 
Assume that fo, !I, 12, .
.
.
 is an infinite sequence of multi sets over the well-founded partial 
ordering (X, <) such that for all i: fi+l immediately precedes J.. For each i then, fi+l 
is obtained from Ii by replacing one occurrence of some x E D(h) by occurrences of 
elements y < x. Let us denote the occurrence of x that has been replaced in h by Xi. 
Let T be the tree of these occurrences Xi, where we stipulate that Xj is a child of Xi iff 
Xj is one of the occurrences replacing Xi to obtain fi+l from J. Thus, if Xj is a child 
of Xi, then j ț i + 1. In general, j -:f:. i + 1, since Xj might get replaced at a much later 
stage of the sequence. (The "roots" of T are the occurrences of elements of fo eventually 
replaced, so T really might be a finite union of trees. This defect can be remedied by 
adding one new root, joining these trees.) 

8 
Chapter 1 
Note that, since we only consider finite multisets, T is a finitely branching tree. By 
Konig's Lemma 1.5, T must have an infinite branch. However, the occurrences along 
such a branch are descending in the well-founded ordering <, a contradiction. 
I 
A nice feature of Theorem 1.13 is that it can be iterated. For instance, the multiset 
ordering of the multiset ordering of (IN, <) again is well-founded, etc. 
We close with a couple of characterizations of the notion of well-foundedness of which 
1 . l4(iii) is the most elegant (compare Theorem 1.2). In (ii), y E Y is -<-minimal if for 
no x E Y, x -< y. 
Lemma 1.14 Let -< be a relation on T. The following conditions are equivalent: 
(i) -< is well-founded on T, 
(ii) every non-empty set YeT has a -<-minimal element, 
(iii) (strong) -<-induction holds: 
if Xc T is such that VtET [Vs -< t(s E X) => t E XI, then X = T, 
Proof. See Exercise 1.8. 
Exercises 
1.6 Complete the proof of Lemma 1.8. 
1. 7 Let R be a relation on the set X. 
I 
Show: for all x, Z EX, xRtrz {:} xRz V 3y(xRtry 1\ yRz). Show: if R is well-founded, 
then there is exactly one relation S satisfying the condition xSz {:} xRz V 3y(xSy 1\ yRz) . 
1.8 Prove Lemma 1.14. 
1.9 Prove Lemma 1.12. 
Hint. Use the form of Lemma 1.14(iii) and copy the proof of Theorem 1.2 using Exercise 
1.7; or, simpler, but less elegantly, just use the definition of well-foundedness. 
1.10 In Smullyan's Ball Game, you, the only player of the game, are given a box with 
(finitely many) balls, each of them carrying a natural number. A move in the game 
consists in replacing one ball (the choice is free) with as many balls as you wish (but 
no more than finitely many), each carrying a number less than the number of the one it 
replaces. Show that, no matter how you choose your moves, you'll end up with an empty 
box eventually. (Alas! your last move probably will be to remove a ball carrying the 
number zero ... ) 
1.11 Generalize Smullyan 's Ball Game (and the accompanying theorem), replacing the 
balls by boxes containing finitely many boxes, containing finitely many boxes, ... con­
taining numbered balls. 

Preliminaries 
9 
1.12 Suppose that < is a linear ordering of the set X such that both < and its converse 
> are well-orderings. Show that X is finite. 
Hint. Assume that < is a well-ordering of the infinite set X. Construct an infinite 
increasing sequence Xo < Xl < X2 < ... by repeatedly using Lemma 1.14(ii). 
1.4 
Ordinals and Cardinals 
Ordinals are used here and there in Chapters 4, 7 and 8 (to index fixed point hierarchies) 
and in 6 (to measure heights of well-founded trees). These objects arise as a generalization 
of the notion of natural numbers as follows. Natural numbers have a cardinal, as well as 
an ordinal, character. In their cardinal guise, they are used to measure the number of 
elements of finite sets. For instance, the set of planets of the solar system has cardinal 
number 9. Ordinally, natural numbers are used to pinpoint positions in finite linear 
orderings: Earth is the 3rd planet of the solar system. Ordinally also, they measure 
lengths of finite linear orderings: Pluto is the 9th and last ofthe row of planets. However, 
cardinal and ordinal aspects of natural numbers collapse to the same thing since the final 
outcome of the counting process of a finite set is independent of the way of counting. 
Putting this more abstractly: 
Proposition 1.15 All linear orderings of the same finite set are isomorphic. 
Proof. Induction with respect to the number of elements of the set. 
I 
By the way: 
Definition 1.16 An isomorphism between the relational systems (linear orderings, well­
orderings, trees, . . . ) (X, R) and (Y, S) is a bijection h : X -+Y such that for all a, bE X: 
xRy ¢:> h(a)Sh(b). 
(X, R) and (Y, S) are isomorphic in case there exists an isomorphism between them. 
• 
Proposition 1.15 does not hold any longer if the restriction to finite sets is removed, 
even when restricted to linear orderings that are well-orderings. For instance, consider 
IN. The familiar ordering < of IN orders the naturals according to the following listing: 
0,1,2,3, ... Exchanging 2 and 5 results in the following list: 0,1,5,3,4,2, 6,7, .. . Here, 
the corresponding well-ordering still is isomorphic with (IN, <). A non-isomorphic one is 
obtained by removing 0 as the first element and adding it as the last one: 1,2,3, ... , o. 
This procedure can be iterated, producing infinitely many non-isomorphic well-orderings 
of IN. Still another one is obtained by putting the odd numbers after the even ones: 
0,2,4, ... ,1,3,5, ... etc. 
Natural numbers simultaneously serve as cardinal numbers of finite sets and as order 
types of finite linear (well-) orderings. Order types are thought of as associated to (linear) 
orderings in such a way that orderings are isomorphic iff they obtain the same type. Now: 

10 
Chapter 1 
Definition 1.17 An ordinal is the order type of a well-ordered set. 
(Notations for) the first few ordinals are: 
0, 1, 2, ... (the natural numbers are also used as the order types of finite orderings) 
w (the order type of (IN, <)) 
w + 1, w + 2, . .
. , w + w = w . 2, 
w· 2 + 1, w· 2 + 2, .
. . ,w . 3, ... , w . 4, ... 
w . w = w2, w2 + 1, ... , w2 + w, ... , w2 + w . 2, 
.
. . , w3, .
•
. 
wW, •
•
•
 , ww+w3·5+w+ 1, .. . 
w'" 
W 
, . .
.
 
• 
It will be more or less clear what the notations of addition, multiplication and exponen­
tiation here stand for. w + 1 is the ordinal of the ordering of natural numbers according 
to the listing 1,2,3, .
.
.
 , 0; w + 2 is the ordinal of 2,3,4, .
.
.
 ,0, 1 and w· 2 is the ordinal 
of 0, 2, 4, . . . , 1, 3,5, ... . 
From the way in which the ordinals are generated it is seen that they are well-ordered 
themselves. However, there is no ordinal corresponding to this well-ordering since the 
ordinals do not form a set. (This is the way set theory escapes the Burali-Forti paradox.) 
The ordinals displayed in the previous list are all countable, that is, they are types of 
well-orderings of (subsets of) IN. (In fact, they are types of recursive well-orderings, cf. 
Chapter 7.) Set theory also provides for uncountable ordinals, but we will not encounter 
these. 
Definition 1.18 Let -< be a well-ordering of the set X. The height ht(x) of an element 
x E X is the order type of {y E X I y -< x}. The height ht(X) of (X, -<) is the order 
type of (X, -<). 
If R is only well-founded on X, for instance, (X, R, u) might be a well-founded tree, 
height is defined by recursion along R by ht(x) = sup{ht(y) + 1 I yRx}. (If A is a set 
of ordinals, then supA is the least ordinal that is 2: all ordinals in A.) Height of (X, R) 
itself then is defined by ht(X) := sup{ht(x) + 1 I x E X}. 
I 
2 
o 
tree of height 3 

Preliminaries 
11 
Note that the height of a tree is measured from the leaves down to the root. In a tree, 
leaves have height O. So if a tree consists of a root only, this root obtains height 0, and 
the tree itself has height 1. 
For basic facts on cardinals (which we shall seldom use), see any introduction in set 
theory. A set is countable if it can be rendered as {ai liE IN}. That is, it is either finite 
or of the same power as IN. 
Exercises 
1.13 Describe a well-ordering of IN in type w . w. 
A concrete well-ordering of type WW is much harder to come by, but see Exercise 1.16. 
1.14 Suppose that < is a relation on X, that -< is a well-founded relation on Y and 
that h : X--.Y is such that for all a,b E X: a < b =? h(a) -< h(b). Show that < is 
well-founded. 
1.15 Let T be a well-founded tree. Show: if T is finitely branching, then it has finite 
height. 
* 1.16 2 With a multiset f over (IN, <), associate the ordinal <p(f) := wnl 
. f(nd + . .
. + 
wnk . f(nk), where nl, .
.
.
 , nk are the elements of D(f) in decreasing order. 
Now, use 
Exercise 1.14 to give an alternative proof of Theorem 1.13 for the case of multisets over 
(IN, <). (It follows that the multiset ordering over (IN, <) has order type wW.) 
1.5 
Notes 
Theorem 1.13 is from [Dershowitz/Manna 79]. 
Exercise 1.10 is from [Smullyan 79]. 
2 A * indicates that an exercise may be difficult or needs material not treated in this book. 

 
2 Propositional Logic 
Propositional logic is that part of logic which deals with the connectives -', A, V, ---4 
and _ . The first few sections of this chapter consist of a speedy introduction to syntax, 
semantics and conjunctive normal forms. Though our treatment here is quite complete, 
previous contact with the material can be an advantage. In Section 2.4 the treatment is 
more elaborate. 
In this chapter and the next one, satisfiability of formulas is the central issue. Reso­
lution is a combinatorial, proof-theoretic approach to establishing (un)satisfiability that 
does not involve truth tables. Formulas are introduced in the next section; the satisfia­
bility notion is in Definition 2.5. The method of resolution is dealt with in Section 2.4 
of this chapter. 
2.1 
Syntax 
The language of propositional logic consists of the following symbols. 
(i) infinitely many variables or proposition letters, 
(ii) the connectives: negation -', conjunction A, disjunction V, implication -, equiv­
alence -, 
(iii) parentheses. 
We can now form finite sequences of these symbols. Our interest concerns a special 
type of sequence, the formulas of propositional logiC: 
Definition 2.1 The collection of formulas is the smallest one satisfying: 
(i) all variables (sequences of length 1) are formulas, 
(ii) if the sequences !P and 't/J are formulas, then so are 
• the negation of !P, -'!p, 
• the implication of I{J and 't/J, (!p-'t/J) and 
• the equivalence of!p and 't/J, (!p+-+'t/J), 
(iii) if !Po, ... ,!Pn-l are formulas, then so are 
• the conjunction of !Po, ... ,!Pn-l, (!po A ... A I{Jn-d and 
• the disjunction of !Po, ... ,!Pn-I. (!po V .,. V!Pn-l). 
I 
For instance, the sequence «A 1\ B)-C) (where A, Band C are variables) is a formula: 
A B and C are formulas (by 2.1(i» , hence, (A A B) is one (by 2. 1(iii», therefore, 
«A A B)-C) is a formula (2.1(ii». 

14 
Chapter 2 
For the conjunction of a sequence of formulas I{)o, •
.
•
 ,I{)n-l we also use the notation 
Ai<n I{)i· If <P is the set of formulas {I{)i I i < n}, this conjunction can also be denoted 
simply by A <P. Similarly, disjunctions can be written as Vi<n I{)i or V <P. 
The formulas you encounter when constructing a formula using the instructions of 
the definition are its subformulas. Thus, the subformulas of «A 1\ B) ..... C) are A, B, C, 
(A 1\ B) and the formula «A 1\ B) ..... C) itself. 
Putting this differently: 
Definition 2.2 A subformula of a formula I{) is an uninterrupted subsequence of I{) that 
itself is a formula. 
I 
Though (A-+C) is a subsequence of «A 1\ B)-+C) that is a formula, it is not an unin­
terrupted one and so it is not a subformula. The same goes for (B--C) and « B)-+C). 
The sequence B)-+C is an uninterrupted subsequence, but it is not a formula (for in­
stance, cf. Exercise 2.1). 
Formulas (1{)o 1\ . .. 1\ I{)n-d and (1{)0 V ... V I{)n-r) are called conjunctions resp. dis-
junctions and I{)o, .. . ,I{)n-l are called their conjuncts resp. disjuncts. 
In most presentations of the subject, 1\ and V are binary connectives. That is: 2.1(jii) 
usually is restricted to the case where n = 2, so that every conjunction has two conjuncts, 
and every disjunction has two disjuncts. Our choice to have 1\ and V of indefinite arity 
is dictated by the desire to have a simpler presentation of resolution later on. 
Part (iii) of Definition 2.1 even has two "degenerate" cases. First, we allow that n = 1 
and have formally indistinguishable conjunctions and disjunctions (I{) oflength 1, which, 
except for the outer parentheses, are indistinguishable from their sole conjunct/disjunct 
I{) itself. We even admit n 
= O. In that case, we do distinguish and let the empty 
conjunction be denoted by T (verum) and the empty disjunction by 1- (falsum). 
On not writing parentheses. If confusion is unlikely, we may drop parentheses in 
our notation of formulas. We shall always leave out outermost parentheses. (And so 
the distinction between a formula I{) and the length-1 conjunction and disjunction (I{) 
vanishes completely.) Also, we shall assume that 1\ and V bind stronger than -+ and 
..... Thus, e.g., with A 1\ B-+C we mean the formula «A 1\ B)-+C). 
I 
Since formulas, considered as sequences of symbols, have finite length, it is possible 
to use induction with respect to length when proving universal statements about them. 
Somewhat more elegant is the use of strong induction on the number of (occurrences of) 
connectives. Formula induction is a slight variant of this, and parallels the formulation 
of Definition 2.1. Formally, it makes precise the requirement in Definition 2.1 that the 
class of formulas is the smallest one satisfying the closure principles stated. 
Lemma 2.3 (Formula Induction) Suppose that E is a property of formulas such that 

Propositional Logic 
(i) every variable satisfies E, 
(ii) if cP and 1/J satisfy E, then so do -'CP, (cp ..... 1/J) and (cp .... 1/J), 
(iii) if CPo, ... ,CPn-l satisfy E, then so do (CPo 1\ ... 1\ CPn-l) and (CPo V ... V 'Pn-d. 
Then every formula has E. 
Exercises 
By way of example: 
2.1 Show that every formula has an even number of parentheses. 
Hint. Formula induction. 
15 
• 
2.2 A construction tree for cP is a finite tree of formulas, with root 'P. 
Its leaves are 
propositional variables, and for every node 1/J, 
• if 1/J = ...,ɲ, then ɳ is the only child of 1/J, 
• if 1/J = (1/Jl ..... 1/J2) or 1/J = (1/Jl .... 1/J2) , then the children of 1/J are exactly 1/Jl and 1/J2, 
• if 1/J = /\ if> or 1/J = V if>, then the children of 1/J are exactly the elements of if>. 
Show that every formula has a (unique) construction tree. 
Note that the subformulas of 'P are precisely the formulas in the construction tree for 'P. 
2.2 
Semantics 
Intuitively, the formulas of propositional logic stand for statements. Statements can be 
either true or false. The symbols t and f stand for the truth values TRUE resp. FALSE. 
(Instead of these letters, the numbers 1 and 0 are also in use.) 
Every connective has a truth table that explains how the truth value of a compound 
formula using it is calculated from the truth values of its components. Hence, the truth 
table in a sense represents the meaning of the connective. Here follow the truth tables: 
cP 
1/J 
-''P 
cPl\1/J 
'Pv'ljJ 
cp ..... 1/J 
cp .... 1/J 
t 
t 
f 
t 
t 
t 
t 
t 
f 
f 
t 
f 
f 
f 
t 
t 
f 
t 
t 
f 
f 
f 
f 
f 
t 
t 
For conjunctions and disjunctions of arbitrarily many formulas, we stipUlate that 
'Po 1\ ... 1\ CPn-l obtains t iff every CPi (i < n) has value t, and 'Po V . .. V CPn-l ob­
tains t iff at least one CPi (i < n) has value t. It follows that the empty conjunction T 
has the value t, since trivially, all its conjuncts have this value. (Also trivially true, but 

16 
Chapter 2 
irrelevant, is that all conjuncts of T have value f.) Similarly, 1. has the value f since 
there is no disjunct in 1. that has value t. By this stipulation, the length-l conjunction 
and disjunction (<p) obviously have the same value as <p, and so there is not much harm 
in confusing them. 
Associating a truth value with a formula starts with associating truth values to its 
variables : 
Definition 2.4 A truth assignment is a function mapping variables to truth values. 
• 
If I is a truth assignment for the variables in the formula <P, then we can calculate 
the truth value of rp under I using the truth tables. For instance, if the I assigns t to 
the variables A and Band f to C, then, following truth tables, A 1\ B obtains t and 
A 1\ B--'>C obtains f. A more elaborate example is in the proof of Lemma 2.7. 
Definition 2.5 We say that I satisfies rp, notation: IP'P, if 'P obtains the truth value 
t under I' 
A formula is satisfiable if it is satisfied by some truth assignment for its variables. 
• 
The symbol P occurs in a couple of different contexts, which should not be confused. 
Definition 2.6 
(i) I satisfies the set r of formulas, notation: ,pf, if it satisfies every formula in f; 
(ii) rp is logically valid, notation: P'P, if <P is satisfied by every assignment; 
(iii) rp is a logical consequence of, or follows logically from the set of formulas f, notation: 
rp'P, if every assignment satisfying f satisfies 'P, as well; 
(iv) rp and 'l/J are called equivalent, notation: <P rv 'l/J, if they are satisfied by the same 
assignments. 
• 
For instance, T, ..,1. and A --'> A are logically valid, ,A follows logically from { ,( B --'> A) }, 
and A--'>.., B and B--'>,A are equivalent. 
The next section uses the equivalences of the following lemma. 
Lemma 2.7 
(i) '-''P rv <Pi (<p--,>'l/J) rv ('<p V 'l/J); (<p+-+'l/J) rv (,<p V 'l/J) 1\ ('P V ,'l/J), 
(ii) -.( <PI 1\ ... 1\ <Pk) rv '<PI V ... V '<Pk; 
-.( 'PI V ... V <Pk) rv '<PI 1\ . . . 1\ -''Pk (DeMorgan laws), 
(iii) <PI 1\ (<P2 1\ ... 1\ <Pk) rv rpi 1\ . . . 1\ <Pk; rpi V (<P2 V ... V <Pk) ""' <PI V '" 
V <pk, 
(iv) <P V ('l/JI 1\ ... 1\ 'l/Jk) rv (<p V 'l/Jd 1\ ... 1\ (<p V 'l/Jk); 
<P 1\ ('l/JI V ... V 'l/Jk) '" ('P 1\ 'l/Jr) V ... V (<p 1\ -rPk) (left distributive laws). 

Propositional Logic 
17 
Proof. See Exercise 2.5. To give just one example, here follows the calculation for the 
first DeMorgan law for the case k = 2. Note that the presence of k variables needs 
the checking of 2k possible distributions of truth values among these variables. In the 
following table, each row calculates the values of ""(<PI 1\ <P2) and '<PI V -'<P2 for one of 
the four possible distributions of truth values over the constituents <Pl and <P2 indicated 
on the left. 
<PI 
<P2 
.., 
(<Pl 
1\ 
<P2) 
.., 
<PI 
V 
-, 
<P2 
t 
t 
f 
t 
t 
t 
f 
t 
f 
f 
t 
t 
f 
t 
t 
f 
f 
f 
t 
t 
t 
f 
f 
t 
t 
f 
f 
t 
t 
f 
t 
f 
t 
f 
f 
t 
f 
f 
f 
t 
f 
t 
t 
f 
In this table, the intermediate results of the calculations corresponding to subformulas 
are written beneath the main connective of the subformula. We see that both formulas 
obtain the same value under every possible distribution of truth values. 
• 
Exercises 
2.3 Show that <P '" 1/J iff f=(<p+-+1/J). 
The next exercise shows (un)satisfiability and validity to be closely related. 
2.4 Show that <P is unsatisfiable iff f=-,<p. 
2.5 Prove Lemma 2.7. 
2.3 
Conjunctive Normal Form 
The propositional variant of resolution handles only formulas of a special type, the so­
called conjunctive normal forms. The Conjunctive Normal Form Theorem 2.9 states that 
every formula has an equivalent of that type, and the proof of this result shows how to 
find such an equivalent. Therefore, it is this theorem that makes resolution adequate to 
deal with all propositional formulas. 
Definition 2.8 Variables and negations of variables are called (positive resp. negative) 
literals. 
A formula is called a conjunctive normal form (c.n.f.) if it is a conjunction of disjunctions 
of literals. 
• 
Thus, the "general form" of a c.n.f. looks as follows: 
(L! V . . , V LVJ 1\ . . . 1\ (Ll' V . .. V LW,J 

18 
Chapter 2 
where each L is a literal. This c.nJ. has m conjuncts; its i-th conjunct (1 ::; i ::; m) is 
the disjunction of the ni literals L1, . .. , L; . 
There is a dual notion of disjunctive normal form: these are disjunctions of conjunc­
tions of literals. They are of no importance for the theory of resolution. 
Example. If A and B are variables, then A (a length-l conjunction of one length-l 
disjunction), -,A, ...,A V B (a length-l conjunction of one length-2 disjunction), ....,A /\ B 
(a length-2 conjunction of two length-l disjunctions) and (-,A V B) /\ (-,A V ..,B) are 
examples of conjunctive normal forms. 
A V (....,A /\ B) is not a conjunctive normal form (but it is a disjunctive normal form). • 
Theorem 2.9 (Conjunctive Normal Form) Every formula has an equivalent in con­
junctive normal form. 
Proof. The desired conjunctive normal form is produced in a number of steps, using the 
equivalences of Lemma 2.7. 
(i) Elimination of unwanted connectives. 
Replace subformulas <p-+'¢ and <P-'¢ by their equivalents: 
""'<p V '¢ resp. ( ... <p V '¢) /\ (<p V ..,'¢). 
(ii) Pushing negation signs inside. 
Replace subformulas ""'(<PI/\ ... /\ <Pk) and ""'(<PI V 
'
"
 
V <Pk) by their equivalents 
""'<PI V ... V ""<Pk resp, ""'<PI 1\ ... /\ ""'<Pl<:, erasing double negations whenever en-
countered; Le., replacing subformulas """"'<P by <po 
(iii) Erasing parentheses in conjunctions and disjunctions. 
(iv) Applying distribution. 
Replace subformulas <P V ('¢I /\ ... /\ '¢k) and (,¢l /\ ... /\ '¢k) V <P by their equiva­
lents: (<p V '¢l) 1\ ... /\ (<p V '¢k) resp. ('¢I V <p) 1\ ... /\ ('¢k V <p), 
Eventually, the required conjunctive normal form will show up. 
Example. -,(A /\ (B /\ C-+D» is transformed successively in 
(step 1) ..,(A 1\ (...,(B /\ C) V D», 
(step 2) ..,A V ...,( ..,(B /\ C) V D), 
(2 again) ...,A V (...,..,(B /\ C) /\ ..,D), 
(2 once more) ,A V «B /\ C) /\ ....,D), 
(step 3) ..,A V (B /\ C /\ ..,D), 
(step 4) (-,A V B) 1\ (...,A V C) /\ (...,A V ..,D), 
• 
• 

Propositional Logic 
19 
Exercises 
2.6 In the proof of Theorem 2.9, implicit use is made of the fact that replacement, in 
a formula, of a subformula by an equivalent will result in an equivalent of that formula. 
Prove this. 
Solution: Formula induction. 
(a) The subformula of ({J to be replaced is ({J itself. In this case, the result is evident. 
(b) The subformula to be replaced is a proper one. For instance, ({J is a conjunction 
'l/J 1\ X, and the replacement concerns a subformula of 'l/J. Induction hypothesis: the result 
holds for 'l/J. Therefore, the result 'l/J' of the replacement of the subformula in 'l/J is an 
equivalent of'l/J. It is now easy to check that ({J is equivalent with 'l/J' 1\ X. (Every formula 
('l/J .... 'l/J')--.( 'l/J 1\ X .... 'l/J' 1\ X) is logically valid.) 
The cases where ({J is a disjunction or a negation are similar. 
* 2.7 The last line in the proof of Theorem 2.9 requires an argument. Show that the 
process of repeatedly applying steps 1-4 (i) terminates, and (ii) produces, in fact, a 
formula in conjunctive normal form. 
2.8 Prove that every formula has an equivalent in disjunctive normal form (d.n.f.). 
Hint. Here are three different methods to produce a d.n.f. 
1. Parallel the proof of Theorem 2.9. 
2. ({J has -'-'({J as an equivalent. Form a c.n.f.-equivalent of -'({J and push the remaining 
negation symbol inside. 
3. Construct the truth table of ({J. A d.nJ. for ({J can now be read off immediately. (To 
every row that has t in the final column corresponds a disjunct; if t (resp., f) occurs in 
the row under the variable A, then A (resp., -.A) is a conjunct of this disjunct.) 
2.9 Assume that -', 1\ and V are the only connectives in the formula ({J. 
({Jd is the 
formula obtained from ({J by exchanging 1\ and V . Show: ({J is logically valid iff -'({Jd is 
logically valid. 
2.10 A, B, C, D and E are variables. Give equivalents in conjunctive normal form for 
(i) (A 1\ B) .... (C V D), 
(ii) « (-.A V B) 1\ -,C) V D) 1\ -,E. 
2.11 Give d.n.f. 's for 
(i) (-.A V B) 1\ (C V -.D), 
(ii) -.«A V B)--'C). 
It is in the nature of our subject that we shall discuss algorithmic decidability now 
and then. For an intuitive definition of this concept and related ones, see Definition 7.1 
in Chapter 7. 

20 
Chapter 2 
2.12 Produce a simple (in fact, trivial) decision method for satisfiability for formulas in 
disjunctive normal form. 
2.13 Show that the following procedure outputs, for a given propositional formula 'P, a 
c.n.f. 1/J (in general, not an equivalent of 'P) that is satisfiable iff 'P is satisfiable. 
Enumerate all subformulas 'Po, .. ·, 'Pm = 'P of 'P. Fix a sequence of variables Po,··· ,Pm 
corresponding to these formulas. 1/J is the conjunction of Pm (which corresponds to 'P) 
and formulas in the variables Po, ... ,Pm obtained as follows. For all i ˮ m such that 'Pi 
is not a variable: if 'Pi is -''Pj, then a c.n.f. of Piʓ-'Pj is one of the conjuncts of 1/J; if 'Pi 
is 'Pr-+'Pk, then a c.n.f. of Pi̫(Pr-+Pk) is one of them, etc. 
2.4 
Resolution 
Resolution for propositional logic is a method with which one can test conjunctive normal 
forms for (un)satisfiability. To obtain a somewhat simplified exposition, it is useful to 
present the conjunctive normal form to be tested in its so-called clausal fonn. 
Definition 2.10 A clause is a finite set of literals. 
A clausal fonn is a set of clauses. 
The clausal fonn of the c.nJ. 
(Li V ... V L.) 1\ ... 1\ (L'{' V .
.
.
 V Lm) 
is the set of clauses {{ Lt , ... , L̪l }, .
.
.
 , {Lf, ... , L m } }. 
I 
Two (syntactically) different conjunctive normal forms can have the same clausal 
form. For instance, (A V A) 1\ (A V B) and (A) 1\ (B V A) both have the clausal form 
HA}, {A, Bn: since {A, A} = {A} and {A, B} = {B, A}, we have that HA, A}, {A, Bn 
= HA}, {A, Bn = HA}, {B, A}}. 
Lemma 2.11 If two conjunctive nonnal fonns have the same clausal fonn, then they 
are logically equivalent. 
Proof. See Exercise 2.14. 
• 
Logically interpreted, a clause stands for the disjunction of its elements. Thus: if 'Y is 
a truth assignment for the variables in the clause C, then "y satisfies C iff 'Y satisfies at 
least one literal in C. 
Again, there are two degenerate cases. The singleton clause {L} stands for the "dis­
junction" (L). The empty clause stands for the empty disjunction 1-; as a clause, it has 
its own notation: 
Notation 2.12 The notation for the empty clause is D. 
• 

Propositional Logic 
21 
Next comes the simple definition of propositional resolution. 
Definition 2.13 Assume that C and V are clauses and A a variable such that A E C 
and -,A ED. The clause (C - {A} ) u (V - { -,A}) is called a (propositional) resolvent of 
C and D with respect to A. 
• 
Thus I clauses C and V have a resolvent in case a variable A exists such that A E C 
and -,A E D (or conversely). The resolvent with respect to this variable is obtained by 
removing A resp. -,A from C resp. V and joining their remains. 
For instance, {A, -,B I C} and {-,A, B I C} have the resolvents { -,B 
I B I C} (with respect 
to A) and {A,-,A, C} (with respect to B). They do not have a resolvent with respect to 
C. 
Definition 2.14 (Propositional) resolution is forming (propositional) resolvents repeat­
edly. 
More precisely: a propositional derivation of a clause E from a set E of clauses is a finite 
tree T such that 
(i) E is the root of T, 
(ii) every leaf of T belongs to E, 
(iii) every non-leaf V of T has children Vi and Va of which it is a propositional resol-
vent. (It is allowed that Vi = Va, but see Exercise 2.18.) 
The number of non-leaf nodes of a derivation is its number of steps. 
The notation: E I-p E is used when E is so derivable from E. 
A propositional derivation of 0 from E is called a refutation of E. E is refutable if it has 
a refutation. 
I 
For instance: here is a two-step refutation of the set {{ -,A}, {A, B}, {-,B}}: 
{--,A} 
{A,B} 
/ 
{B} 
o 
The next two results establish that every derivable clause follows logically from the set 
from which it is derived. 
Lemma 2.15 If E is a resolvent of C and V, then {C, V} FE. 

22 
Chapter 2 
Proof. We have to show that every truth assignment "Y for the variables involved that 
satisfies both C and D also satisfies E. Assume that E = (C - {A}) U (D - {...,A}) and 
"YF{C,D}. 
(i) "Y ȅ A. Since we have "YFC, "Y must satisfy some literal in C - {A}. However, this 
literal also occurs in E, and so we have that "YFE. 
(ii) "YFA. Thus, "Y ,F-,A. Since we have "YI=D, "Y must satisfy some literal in D - {-,A} 
which also is in E: again we have that "YFE. 
• 
The next result expresses that the derivability notion is sound with respect to the one 
involving truth tables: every derived clause follows logically. 
Corollary 2.16 (Soundness) If E I-p C, then EI=C. 
Proof. Let T be a derivation of C from E. We apply strong induction with respect to 
the number of steps of the derivation and use Lemma 2.15. If T has no steps, then its 
only element is C, C E E, and the result is immediate. Otherwise, C is a resolvent of its 
children clauses C1 and C2 in T. The subderivations of T that derive C1 and C2 from 
E have at least one step less than T. By induction hypothesis, EI=Ci (i = 1, 2). Since 
by Lemma 2.15, {C},C2}I=C, it follows that EI=C. 
• 
By definition, EI=D means: every assignment that satisfies E, satisfies D. However, 
D is unsatisfiable. Thus, EI=D is just another way of expressing that E is unsatisfiable. 
Therefore, the following is just a special case of the Soundness Corollary 2.16: 
Corollary 2.17 If E t-p D, then E is unsatisfiable. 
I 
The next converse expresses that refutability is complete with respect to the truth 
table notion of unsatisfiability : resolution is capable of establishing refutability of any 
unsatisfiable clause set. 
Theorem 2.18 (Completeness) If E is unsatisfiable, then E r-p D. 
For the proof of Theorem 2.18 we need a combinatorial result: Lemma 2.21, and a few 
notions. 
Definition 2.19 Suppose that P is a collection of sets. A set J is called 
(i) meet of P if VC E P : J n C '# 0, that is: .T intersects every set in P, 
(ii) minimal meet of P if J is a meet of P but it has no proper subset that still is a 
meet of P 
• 
If P is a collection of non-empty sets, then a meet of P always exists ; e.g., the union 
UP of all sets in P will be an obvious example of such a meet. However, to find minimal 
meets can be more difficult, and sometimes they simply do not exist. 
Examples. 

Propositional Logic 
23 
(i) Every element of P := {{I, 2}, {2, 3}, {I, 3}} is a minimal meet of P. 
(ii) Define Cn := in, n + 1, n + 2, ... }. The collection {Cn I n E IN} has no minimal 
mecl. 
• 
Lemma 2.20 Assume that J is a meet of P. The following conditions are equivalent: 
(i) 1 is a minimal meet of P; 
(ii) 'iaEJ3CEP: lnC={a}. 
Proof. (ii) =} (i) If a E 1, then 1 - {a} is not a meet: by (ii), take C E P such that 
J n C = {a}. J - {a} does not intersect C. 
(i) =} (ii) If (ii) does not hold, then a E J exists such that for every C in P: if a E J n C, 
then 1 n C has yet another element -1= a. Thus, the proper subset 1 - {a} of .J also is a 
meet of P. 
• 
Lemma 2.21 Every collection of finite, non-empty sets has a minimal meet. 
Proof. Suppose that P is a collection of finite, non-empty sets. To simplify the argument, 
we assume that an enumeration xo, Xl, X2, ... of all elements occurring in the sets of P 
can be given. (That is, we assume that UP is countable. This condition will be satisfied 
in every situation where we apply the lemma.) Put 1o := {Xo, Xl, X2," .}. Note that 10 
is a meet of P Define the sequence 11,12, h,··· as follows. If Jo - {xo} is a meet as 
well, put Jl := 10 - {xo}. If not, put 11 := 10. In other words: throw away Xo if its 
dismissal does not result in a set that no longer is a meet of P
his defined similarly: 
this is h - {xd in case this set still is a meet of P; and otherwise we put h := 11, etc. 
All sets ln produced are meets for P We now let 1 be the set of objects x that are 
members of every ln, that is: .J consists of the objects not thrown away. 
Since every A E P is finite, we cannot have thrown away all of its elements: if Xk is the 
element with the largest index in A, then lk+l would have no element in A; and hence 
it would not be a meet of P, contrary to construction. Therefore, J is a meet of P But 
now, J also is a minimal meet: if Xk E J could be left out, then we would have thrown 
it away when forming Jk+l' 
• 
Proof of the Completeness Theorem 2.18. 
Assume that 0 is not derivable from the set of clauses˭. 
The following argument 
produces a truth assignment that satisfies every clause in it. 
Let A be the set of all clauses derivable fromȄ. Let P consist of the clauses in A 
the literals of which are all positive, i.e., variables. Note that P is a collection of finite, 
non-empty sets (as, by assumption, 0 is not an element of A). Apply Lemma 2.21: let 
1 be a minimal meet for P Identify 1 with the truth assignment that assigns t to every 
variable in J and f to every other variable. Then, since 1 is a meet of P, we have that 

24 
Chapter 2 
JI=P. 
Claim. JI=a. 
Hence, since E Ca: JI=E. 
Proof of claim. Pick C E ˬ. We prove that JI=C using induction with respect to the 
number of negative literals in C. 
Basis. If this number is 0, then we have C E P, and hence JI=C, as noted previously. 
Induction step. Choose a negative literal ..,A in C. If A r/. J, then JI=C. So, assume 
that A E J. By Lemma 2.20, D E P exists such that J n D = {A}. Note that 
(C - { ..,A} ) u (D - {A}) is a resolvent of C and D - and hence, an element of ˫ - that 
has one negative literal less than C. By induction hypothesis, this resolvent is satisfied 
by J. Therefore, J satisfies at least one of the constituents C - {..,A} and D - {A} of 
the resolvent. However, it does not satisfy the second one by choice of D. Therefore, 
JI=C - {..,A}. A fortiori, JI=C. 
• 
Exercises 
2.14 Prove Lemma 2.11. What about its converse? 
2.15 Bring first in conjunctive normal form (if necessary) and rewrite in clausal form 
(A, B, C are variables): 
(i) ..,A, 
(ii) A /\ ..,B, 
(iii) ..,A V B, 
(iv) ..,(..,A /\ B /\ ..,C), 
(v) (-.A /\ ..,B /\ C) V (A /\ ..,B /\ ..,C), 
(vi) Aś(..,B /\ C). 
2.16 Form all possible resolvents of the following pairs of clauses: 
(i) {A,B}; {..,A,..,B} (cf. Exercise 2.21), 
(ii) {..,A, ..,B, ..,C} ; {-.B, C}, 
(iii) {A, ..,A} ; {A, ..,A} (cf. Exercise 2.18). 
2.17 Produce all possible resolvents of two clauses in the following sets: 
(i) {{..,A,..,B}, {-.A,B}, {A}}, 
(ii) {{A,B,C},{..,B,..,C},{..,A,..,C}}, 
(iii) {{""A,""B},{B,C},{-.C,A}}, 
(iv) {{..,A} , {A,B, ..,C}, {C, ..,An . 
2.18 Show: if E is a resolvent of C and D, and C = D, then E = C = D. 
2.19 Show: if E is a resolvent of C and {A, ..,A}, then E = C. 

Propositional Logic 
25 
2.20 Show: 
(i) <p E E :::} E I-p <Pi 
(ii) if E I-p <P and V1/J E E (IT I-p 1/J), then IT I-p <po 
2.21 Is 0 resolvent of {A, B} and {,A, ,B}? 
Hint. Find out whether {{A, B}, {,A, ,B}} is satisfiable. 
2.22 Show that every collection with a finite meet has a minimal meet. 
2.23 Prove that every finite collection of non-empty sets has a minimal meet. 
2.24 
(i) What is the minimal meet for the collection P := {{n,n + 1} I n E IN} 
produced by the proof of Lemma 2.21? 
(ii) Give the first 14 elements of the minimal meet for {{ n, 2n} I n E IN}, produced by 
this proof. 
(iii) Idem, for {{n, n + 1, ... , 2n} In E IN}, but now only the first 6 elements. 
If a finite set 8 of clauses is unsatisfiable, this can be demonstrated by deriving 0 from 
8 using resolution. However, what if 8 happens to be satisfiable? The following exercise 
shows that, if 8 is finite, then the set of all clauses derivable from 8 is finite as well; and 
hence a systematic search eventually shows 0 to be underivable. Thus, resolution can be 
used also to ascertain satisfiability of finite sets of clauses. This contrasts strongly with 
the case of resolution in first-order logic, dealt with in the next chapter. 
2.25 Let V be a set of n propositional variables. 
(i) There are 2n literals using variables from V. How many clauses are there? 
(ii) Give an upper bound on the number of derivations of height k in which the clauses 
use only variables from V. 
(iii) Let 8 be a set of clauses using the variables from V. nm(8) is the set of clauses 
derivable from 8 by a derivation of height ˪ m. Show that for some m, nm (8) 
contains every clause that is derivable from 8. 
(iv) Describe a decision method (cf. Definition 7.1) for satisfiability of finite sets of 
clauses based on resolution. 
2.26 A, Band C are propositional variables. Is 0 derivable from the following sets of 
clauses? If so, give a derivation. If not, give an argument showing that such a derivation 
does not exist. 
(i) {{A, B}, {B, C}, {A, C}, {,A, ,B}, {,B, ,C}, {,A, ,C}}, 
(ii) {{A, B}, {B, C}, {,A, ,B}, {,B, ,C}, {,A, -.e}}. 
2.21 Use conjunctive normal forms and resolution to show that the following formulas 
are unsatisfiable. 

26 
(i) (A ..... (B@C)) 1\ (A ..... B) 1\ (A-,C), 
(ii) ....,((A->B)->....,B)---,B), 
Chapter 2 
(iii) «A 1\ B) V (A 1\ C) V (B 1\ C» 1\ «-,A 1\ -,B) V (..,A 1\ ..,C) V (-,B 1\ ...,C». 
2.28 Give a simple example showing that the implication EFC ʐ E f-p C can be false 
when C f:. D. 
2.29 Let X be a set and P := {{a, b} I a, b E X 1\ a f:. b}. Show: if X has at least 2 
elements (i.e., if P f:. 0), then: Y is a minimal meet for P iff, for some a E X, we have 
Y=X-{a}. 
2.30 Assume that q, is a collection of non-empty pairwise disjoint sets, and P := {{a, b} I 
3X E q, (a, b E X)}. Let Y be a minimal meet for P Show: if X E q" then X - Y contains 
exactly one element. 
2.31 A c IN is co-finite iflN -A is finite. Show that a collection U c IN exists, containing 
all co-finite sets and such that 1. AE U 1\ A c B c IN [ BE U; 2. A, BE U ʑ A nBEU; 
3. A c IN ʒ (A E U {:} IN - A ¢ U). (A collection with these properties is called an 
ultrafilter over IN.) 
Hint. Apply Lemma 2.21 to the collection {K C P(lN) I K is finite and UK is co-finite}. 
2.32 Give a different proof of the Completeness Theorem 2.18, along the following lines. 
Assume that 0 is not derivable from the set of clauses E. Again, let .60 be the set of 
all clauses derivable from clauses in E using resolution. 
Thus, 0 ¢ D.. The aim is 
to construct a satisfying assignment "I for D.. Fix an enumeration Po, Pl, P2, ... of all 
propositional variables. For C E D., let i(C) be the largest index of a variable occurring 
in C (n.b.: C f:. 01). Recursively define the value "I(Pj) by the following stipulation: 
"I(Pj) := t, unless there exists DE.6o, such that i(D) = j, which is not satisfied by this 
choice of "I(Pj); in which case we of course put "I(Pj) := f. Show that C E D. [ "IFC, 
using strong induction with respect to i(C). 
Hint. Assume that C E D. and "I ?f: C. Let j := i(C). Show: 1. "I(Pj) = f; 2. ""'Pj ¢ C, 
Pj E C; 3. Modify "I to "I' by changing the value in Pj to t. Then DE D. exists such 
that i(D) = j and "I' ?f: D; 4. Pj ¢ D, -'Pj ED; 5. B:= (C - {Pj}) U (D - {"'Pj}) is a 
resolvent of C and D in D.; 6. i(B) < j; 7. "IFB; 8. "I ?f: (C - {Pj}); 9. "I ̩ (D - {"'Pj}); 
10. "I ?f: B. 
The following is a fundamental result of propositional logic. 
Theorem 2.22 (Compactness of Propositional Logic) If every finite subset of an 
infinite set E of formulas is satisfiable, then E is satisfiable as well. 
* 2.33 Prove Theorem 2.22. 
Hint. A refutation can only involve finitely many clauses. 

PropOSitional Logic 
27 
* 2.34 Complete the following sketch of a proof of Konig's Lemma 1.5, using the Com­
pactness Theorem. 
Let T = (T, R, u) be an infinite, finite branching tree. Choose a propositional variable 
At for every element t E T. E is the set of all formulas of one of the following forms: 
(i) At--+-,As, if At is not a descendant of As and As is not a descendant of At; 
(ii) Atl V ... V At .. , if every branch passes through one of Atl, . . . ,Atm; 
(iii) -,At, whenever t is a leaf of T. 
Show that every finite subset of E is satisfiable. 
Now, assume that "YI=E. Show that {tET I "Y(At) = t} is a branch through T. 
(A slightly simpler proof is possible ifT has no leaves. We can take care of this, restricting 
the argument to the subtree of nodes which have infinitely many descendants.) 
* 2.35 Prove the general case of Lemma 2.21, without the countability assumption. 
Hint. Use a well-ordering of UP, or apply Zorn's Lemma. 
2.5 
Notes 
The satisfiability problem for propositional formulas is one of the prominent examples 
of NP-completeness. If you have solved Exercise 2.12 correctly, it is obvious that the 
satisfiability problem for d.n.f. 's is much simpler than the problem for general formulas. 
It follows that (if P#NP) it cannot be that simple to produce disjunctive normal forms. 
This is quite remarkable in view of Exercise 2.13. 
The proof of the Completeness Theorem 2.18 given here, via Lemma 2.21, is from 
[Bezem 90], which also contains a number of variations and refinements. 
Exercise 2.30 (which positively -and unexpectedly- answers the problem whether 
Lemma 2.21 is an equivalent of the Axiom of Choice) is due to Hurkens; see the note 
[Bezem/Hurkens 92J. 
Exercise 2.31 shows Lemma 2.21 to be closely related to the boolean prime ideal 
theorem. 
The Compactness Theorem 2.22 expresses that the space of truth assignments is com-
pact in the product topology corresponding to the discrete space {t, fl. Note that it does 
not refer to resolution, though the proof suggested in Exercise 2.33 uses this concept. 

 
3 First-order Logic 
3.1 
Introduction 
The contents of the previous chapter can be described as follows. Resolution in propo­
sitional logic is a decision method for satisfiability of conjunctive normal forms (more 
precisely, of clausal forms). Thanks to the Conjunctive Normal Form Theorem 2.9, res­
olution can be used also to test an arbitrary formula for unsatisfiability: the only extra 
thing needed is to put it in conjunctive normal form first. 
The purpose of this chapter is to extend the resolution technique to first-order logic 
where, next to the connectives, we also have the quantifiers V and 3. We shall see that 
the first-order variant of resolution is a decision method for unsatisfiability of universal 
sentences with a matrix in conjunctive normal form (see the following details). However, 
here the method produces a result that is weaker than the one for propositional logic: in 
case the initial sentence is unsatisfiable the method will yield a proof witnessing this fact, 
but it cannot always witness satisfiability. This is called positive decidability of first-order 
unsatisfiability (Definition 7.1). The Theorem of Church (Theorem 7.19) explains that 
this shortcoming is unavoidable. 
Not every first-order sentence has a universal equivalent. However, for every sentence 
a universal sentence (its Skolem Form) can be produced that is satisfiable iff the original 
one is, and this, of course, suffices. This reduction to universal form is described in 
Section 3.6, which may be skipped by readers primarily interested in resolution. 
The basics of first-order logic are explained in Sections 3.2 and 3.3 (some previous 
contact with this material is an advantage); subsequently we establish positive decidabil­
ity of first-order unsatisfiability in Sections 3.4-3.6. Finally, resolution is dealt with in 
Sections 3.7-3.9. 
3.2 
Syntax 
In propositional logic, there are three categories of symbols: variables, connectives and 
parentheses. In first-order logic (more precisely, in a first-order logical language), there 
are seven. 
(i) infinitely many (individual) variables, 
(ii) symbols for the logical operations; next to the connectives -', 1\ , V ,  -, +-+ we now 
also have the universal quantifier V and the existential quantifier 3, 
(iii) symbols indicating grouping: parentheses, and now also the comma, 

30 
(iv) much later, the identity symbol 7 will be used, 
(v) relation symbols, 
(vi) function symbols, 
(vii) constant symbols, or (individual) constants. 
Chapter 3 
Categories (i)-(iv) are fixed for every first-order language; but categories (v)-{vii), 
the so-called non-logical symbols, may vary. A (first-order) language is determined by 
the choice of (v)-(vii); therefore, a language will be identified with its set of non-logical 
symbols. 
We always suppose that categories (i)-(vii) are pairwise disjoint and that 
to every relation and function symbol a positive natural number (its arity has been 
associated. 
In the following passages, some such language is always thought to be fixed. 
In propositional logic, there is only one type of expression of any importance: the 
formula. Here, there are two : terms (which are intended to be descriptions of objects) 
and formulas (intended to describe statements) . The definitions of these classes take the 
same form as that of the formulas in propositional logic. 
Definition 3.1 Terms: 
(i) all variables and constant symbols, 
(ii) all sequences f(tl ,
"
"
 tn) in which f is an n-ary function symbol and tl,"" tn are 
terms (formed previously). 
• 
Thus, if f and s are (2- resp. l-ary) function symbols, c is a constant symbol and y is 
a variable, then f(s(y), f(s(c), y)) is a term. 
Recall the principle of formula induction corresponding to the notion of propositional 
formula; similarly, there is a principle of term induction corresponding to the present 
notion of term: 
Lemma 3.2 (Term Induction) Suppose that E is a property of terms such that 
(i) every variable and constant symbol satisfies E, and 
(ii) if t 1, .
.
.
 , tn satisfy E and f is an n-ary function symbol, then f (t 1> •
•
•
 , tn) satisfies 
E. 
Then every term satisfies E. 
• 
Definition 3.3 Var(t) denotes the set of all variables occurring in the term t. 
A variable-free term (Le., a term t for which Var(t) = 0) is called ground. 
• 
Definition 3.4 Formulas: 
(i) all sequences r(t!, .
.
.
 , tn) in which r is an n-ary relation symbol and tl, .
.
.
 , tn are 
terms: the atomic formulas or atoms, 

First-order Logic 
31 
(ii) sequences 8  t (8 and t terms) - at least, when  is present: the identities, 
(iii) combinations -'<p, (<Po 1\ 
.
.
•
 1\ <Pn-d , (<po V . . . V <Pn-l), (<p-+'I/J), (<p+-+'I/J) , Vx<p and 
3x<p in which <p, <Po, .. . ,<Pn-l> 'I/J are formulas and x is a variable. 
• 
For the principle of formula induction corresponding to the present notion of formula, 
cf. Exercise 3.l. 
Definition 3.5 The quantifier combinations Vx and 3x that begin the quantifications 
Vx<p resp., 3x<p have <P as their scope. 
Quantifiers Vx, 3x bind every occurrence of x in their scope - at least, if such an 
occurrence is not already in a smaller scope of such a quantifier occurring inside the 
scope of the first one. 
Occurrences of variables that are not bound are called free. 
A sentence is a formula without free variables. 
V ar( <p) denotes the set of variables that have a free (!) occurrence in the formula <po 
An expression without variables or quantifiers is called ground. 
• 
Thus, only the first occurrence of x in (r(x)-+3xq(x, y» is free in this formula. Adding 
one universal quantifier Vx, Vx(r(x}-+3xq(x, y» has no free occurrences of x. The quan­
tifier Vx only binds the occurrence of x in r(x)j it does not bind the one in the q-atom 
(bound already by 3x). 
On not writing parentheses, continued. We go on using the conventions on not 
writing parentheses from the previous chapter and add a couple of new ones. 
In terms, we often omit parentheses around arguments of a unary function symbol: 'fffe' 
stands for the term f (f (f ( e ))) . 
Also, we sometimes omit parentheses around arguments of relation symbols and the 
comma between them. Thus: 'rxy' stands for the atom r(x, y). 
• 
Exercise 
3.1 Formulate a principle of formula induction parallelling Definition 3.4. 
3.3 
Semantics 
Formulas in propositional logic are interpreted using truth assignments. In first-order 
logic, the appropriate concept is that of a model. 
Definition 3.6 Suppose that the language C = 'R. U :F U C consists of relation symbols 
from the set 'R., function symbols from:F and constant symbols from C. Then an C-model 
is a complex 
A = (A, .. . ,r, . . . ,f,· .. ,c, ... )I'ER,fE1'".ca: 

32 
Chapter 3 
in which A is a non-empty set, the universe of A, and A has 
(i) an n-ary relation r C An over A corresponding to each n-ary relation symbol r E R, 
(ii) an n-ary function f : An-+A for each n-ary function symbol f E F, 
(iii) an element (constant) c E A for each constant symbol c E C. 
• 
For instance, if C consists of a (binary) function symbol f, a (binary) relation symbol 
r and a constant symbol c, then (IN, +, <,0) is an example of an C-model. 
The object (1 is called the interpretation or the meaning of the non-logical symbol 
u in the model A. Usually, we assume that r shall be the interpretation of r, f the 
interpretation of f, etc . Usually also, we assume that A is the universe of the model A, 
B the one of the model B, etc. 
In the context of a model A, terms are intended to stand for (descriptions of) certain 
elements of A, and formulas are meant to stand for certain statements about A, at least, 
as long as no (free) variables are around. If they are around, we first have to specify 
which elements of the universe they stand for. There are two standard solutions for this 
predicament, which are essentially equivalent. 
The first solution consists in the use of assignments, mappings from variables to el­
ements of the universe (cf. Definition 3.10), to keep track of which variables stand for 
which elements. The second solution expands the language with constant symbols for 
all elements of the universe and (temporarily) replaces variables by these constants. The 
second solution sounds more complicated but leads to a slightly simpler notation, and so 
we opt for this one. 
Definition 3.7 Let A be a model for a language C. 
The A-language CA is obtained from C by the addition of all elements of A as new 
constant symbols. The model A is adjusted to this expanded language by the stipulation 
that every new "constant symbol" a E A shall have itself as interpretation. 
A-terms, A-formulas and A-sentences are terms, formulas and sentences in the expanded 
language CA. 
• 
Remarks. In forming CA we usually do not care whether an element a E A already 
is interpretation of an C-constant symbol or not; we add it as a new constant symbol 
anyway. 
If the readers do not like terms and formulas (usually thought of as sequences of concrete 
symbols) containing elements of some abstract universe A that need not be symbols at 
all, let them add a constant symbol a for every element a E A with the stipulation that 
it shall be interpreted as a. 
I 
The next definition of the notion of value follows the way in which terms are built. 
In it, we suppress the mentioning of the underlying language; from now on, some such 
language C is thought to be fixed as a parameter throughout the discussion. 

First-order Logic 
33 
Definition 3.8 If A is a model and t a ground A-term, the following rules determine 
an element tA of A: the value of t in A. 
(i) If t = c is a constant symbol of the original language, the value tA = c is given by 
the model A. 
(ii) If t = a E A is a new constant symbol, then tA = a, in agreement with Definition 
3.7. 
(iii) Finally, if t = f(tb ... ,tn) is a complex term formed by the n-ary function symbol 
f and the ground A-terms tb ... ,tn (where the values t; are thought of as deter­
mined already), then tA = f(tf'-, ... ,t9) (f being the interpretation of f given by 
A). 
• 
As a particular case, by leaving out part (ii), Definition 3.8 determines the values of 
ground terms of the original language, before the addition of elements of A as constant 
symbols has taken place. 
By the way, this definition only serves theoretical purposes, and the rules given are 
used in proofs for general results only. In concrete (simple) cases it will always be pretty 
clear what the value of a certain ground term will be. Much the same goes for the next, 
even more cumbersome, definition: the truth definition for A-sentences, which similarly 
follows the corresponding generating process. 
Definition 3.9 If A is a model and cp is an A-sentence, truth of cp in A is denoted by: 
Apcp . This relation is determined by the following rules, which distinguish the form of 
cp: 
Apr(tb .
. . ,tn) 
Aps  t  
Ap 'cp 
Ap(cpo 1\ 
.
.
.
 1\ CPn-d 
Ap3xcp 
Ap'v'xcp 
r(t:, ... ,t9) (r the A-interpretation of r) 
sA = tA 
A )=cp 
for all i < n, APCPi (and Similarly for V 
,-+ , and t-+) 
for some a E A, Apcp{x/a} 
for every a E A, Apcp{x/a}. 
Here, the A-sentence cp{x/a} is obtained from the A-formula cp by replacing every free 
occurrence of the variable x by the new constant symbol a E A. 
I 
Again, Definition 3.9 determines, as a particular case, the notion of truth-in-a-model 
for sentences of the old language. But this time, we cannot simply drop some equivalences 
in order to obtain this particular case. For instance, truth-in-A of an C-sentence 'v'xcp is 
defined in terms of truth-in-A of all CA-sentences cp{x/a} (a E A). 
Note that the equivalences pertaining to the connectives precisely say that p respects 
the truth tables for.." 
1\, V ,  .... 

34 
Chapter 3 
The next definition introduces A-assignments, which map variables to elements in A 
and can be used to transform formulas into LA-sentences. 
Definition 3.10 
(i) An A-assignment for a term t resp. a formula <p is a function a from variables to 
elements of A, such that Var(t) c Dom(a), resp. Var(<p) C Dom(a). 
(ii) If a is an A-assignment and t is a term, then ta is the A-term obtained from t by 
replacing every variable in Dom(a) n Var(t) by its a-image. 
(iii) If a is an A-assignment and <p is a formula, then the A-formula cpa is obtained 
from <p by replacing every free occurrence of a variable in Dom(a) n Var(<p) by its 
a-image. 
I 
Thus, if a(x) = a and a(y) = b, a, b E A, then (r(x)-+3xq(x, y»a is the A-sentence 
r(a)-+3xq(x, b). In this context, the following notations (expanding the one used in 
Definition 3.9) sometimes are useful. 
Notation 3.11 If x is a variable and a E A, then x/a denotes the ordered pair (x,a). 
Thus, in agreement with the set-theoretic concept of a function as set of pairs, if Xl, ... ,xn 
are different variables and aI, ... , an E A, then {xl/ aI, ... , Xn / an} is the A-assignment 
a with Dom(a)={xl,'" ,xn} such that, for 1 ::; i::; n: a(xi) = ai. 
If Var(t) 
= {Xl,"" Xn}, then t can be written as t = t(Xl, ... ,Xn) and t(al, ... ,an) 
then is used to denote t{XI/al,'" ,xn/an}. Similarly, if Var(cp) = {Xl,'" ,xn}, then <p 
can be written as <P(XI,' . . ,xn) and <p(al' ... ,an) is short for <p{xl/al, ... , xn/an}. 
I 
Satisfiability of L-formulas can now be defined via truth-in-A of LA-sentences. 
Definition 3.12 The A-assignment a for the (A-) formula cp satisfies cp in the model A 
if Ap<pa. 
A formula is satisfiable if it is satisfied in some model by some assignment. 
I 
In particular, a sentence is satisfiable if it is true in some model. (A sentence has 
no free variables to assign values to.) The purpose of much of this chapter consists in 
explaining a version of resolution adequate with respect to this notion of satisfiability. 
Other uses of p (similar to the situation in propositional logic and not to be confused 
with each other) are given next. 
Definition 3.13 Let <p be a formula, r a set of formulas, and A a model. 
(i) cp is valid or true in A, or A is a model of cp, notation: Ap<p, if it is satisfied by 
every A-assignment in A, 
(ii) A is a model of r, notation: Apr, if it is a model of every formula in r, 
(iii) p<p, <p is (logically) valid, if <p is valid in every model, 

First-order Logic 
35 
(iv) rprp, rp is a logical consequence of or follows logically from r, if rp is valid in every 
model of r, 
(v) rp '" 'I/J, rp is (logically) equivalent with 'I/J, if p( rp+-+'I/J). 
• 
The following lemma collects some examples of logical validities and equivalences in­
volving quantifiers. 
Lemma 3.14 If rp, 'I/J and rpi (i < n) are formulas, then: 
(i) VxVyrp '" VyVxcp ,. 3x3yrp rv 3y3xrp, 
(ii) 1=(3xVycp-Vy3xcp) (but Vy3xcp--+3xVycp is not valid), 
(iii) -Nxrp rv 3x-,rp ,. -,3xcp rv Vx-,cp, 
(iv) if x is not free in rp, then Vxrp rv 3xrp rv 'P, 
(v) Vx(rpo 1\ ... 1\ rpn-l) rv ("Ix CPo 1\ ... 1\ VXrpn-t) ,. 
3x(cpo V 
.
.
•
 V CPn-I} rv (3xrpo V ... V 3xrpn- t), 
(vi) p(Vx(cp-'l/J)-(Vxrp-Nx'l/J)j ,. p(Vx(rp-'l/J)-(3xrp-3x'l/J)j, 
(vii) l=(Vx(rp+-+'l/J)-(Vxrp+-+Vx'l/J)j ,. P(Vx(rp+-+'I/J)-(3xrp+-+3x'I/J)j. 
Proof. See Exercise 3.2. 
Exercises 
• 
3.2 Give a proof of Lemma 3.14 based on Definition 3.9. (If you find this convenient, 
assume that cp, 'l/J and rpi are atomic.) 
3.3 Prove: if cp is a sentence and A a model, then we have: AI=...,cp iff A j;t: rp. 
Give a simple example of a formula for which this equivalence fails. 
3.4 (Compare Exercise 2.4.) Show: a formula is unsatisfiable iff its negation is logically 
valid. 
3.5 Determine which of the following sentences are logically valid and which are unsat­
isfiable. Note that a sentence may be either valid, unsatisfiable, or neither. 
(i) VxVy(px V qy) V 3x3y(...,px 1\ ...,qy), 
(ii) -,3x3ypxy V 3xpxx, 
(iii) 3x3ypxy V ...,3xpxx, 
(iv) VxVy(pxy V ...,pyx), 
(v) Vxpxx-3xVy(pxy-+pyx), 
(vi) Vxpxx-+Vy3x(pxy-+pyx), 
(vii) 3x Vy(pxy +-+ ...,pyy) (compare the Russell paradox), 
(viii) 3xVy(rxy +-+ -,3z(ryz 1\ rzy» (cf. Example 3.40). 
For the case of partial orderings, the notion of isomorphism was introduced by Defini­
tion 1.16. Here follows the notion for models generally. 

36 
Chapter 3 
Definition 3.15 A bijection h : A-B is an isomorphism between the .c-models A and 
B if 
(i) for every .c-relation symbol rand al, ... , an E A: 
rA(al, ... ,an) ¢::> rB(h(al), ... ,h(an» 
(rA and rB the interpretations of r in A resp. B), 
(ii) for every .c-function symbol f and al,· .. , an E A: 
h(fA(al, ... , an)) = fB(h(ad,.··, h(an)) 
(fA and fB the interpretations of f in A resp. B), 
(iii) for every .c-constant symbol c: h( cA) = cB 
(cA and cB the interpretations of c in A resp. B). 
Models A and B are isomorphic, notation: A ˨ B, if there is an isomomorphism between 
iliѹ. 
I 
The following exercise shows that isomorphic models are first-order indistinguishable. 
3.6 Suppose that h is an isomorphism between A and B. Show that for every term 
t 
= t(Xb . . . ,Xn), for every formula r.p = r.p(Xb ... ,Xn) , all al, ... ,an E A and every 
sentence 'I/J: 
(i) h(tA[al, ... , an]) = tB[h(ad,···, h(an)], 
(ii) AI=r.p[al, ... , an] ¢:> BI=r.p[h(al)' ... ' h(an)], 
(iii) AI='I/J ¢:> BF'I/J. 
Hint. For (i), use term induction, for (ii) formula induction. (iii) is a special case of (ii). 
3.4 
Quantifier-free Sentences 
As usual, let a language .c, that is, a collection of non-logical symbols, be fixed. Recall 
(Definitions 3.3 and 3.5) that a ground term has no variables and a ground sentence has 
neither variables nor quantifiers. We can view first-order logic as an applied propositional 
logic by letting the ground atoms of .c play the role of propositional variables. In order 
that at least some ground atom is present, we have to make the assumption that £, 
contains at least one relation symbol and at least one constant symbol. 
Now, under the identification: 
propositional variables = ground atoms 
the propositional formulas clearly coincide with the ground sentences. 
From this point of view, every ground sentence can be interpreted in two ways: 
(i) as a sentence in first-order logic, in a model, 
(ii) as a formula in propositional logic, using a truth assignment for its ground atoms. 

First-order Logic 
37 
Lemma 3.16 makes evident that the diff'erence between these two interpretations is 
negligable. The proof of this lemma is not difficult, though it may be surprising when 
seen for the first time. It introduces the notion of a Herbrand model. This is a (simple) 
type of model that will be quite prominent in what follows, and therefore the proof 
deserves thorough attention. 
Lemma 3.16 Let C be a language containing at least one constant symbol. Assume that 
E is a set of ground sentences. The following are equivalent. 
(i) E is satisfiable in the'sense of first-order logic (i.e., by a model), 
(ii) E is satisfiable in the sense of propositional logic (i, e., by a truth assignment). 
Proof. (i}=>(ii) Assume that A is a model in which all sentences of E are valid. Define the 
truth assignment 'Y on ground atoms I{) by: 'Y(I{)} = tiff' Al=cp. Using formula induction 
(Exercise 3.1), we show that for every ground sentence cp: 'Yl=cp ¢:} Al=cp. 
O. cp is a ground atom. Then the conditions 'Yl=cp and 'Y(cp) = t are synonymous, and the 
equivalence holds by definition of 'Y. 
1. 'P is -'1/1. Then by induction hypothesis we have that 'Y1=1/1 ¢:} AI=1/1. But then: 
'YI='P 
iff: 'Y 1= -,1/1 (since 'P = -,1jJ) 
iff': 'Y Ѯ 1/1 (by truth tables) 
iff': A ˖ 1/1 (by induction hypothesis) 
iff': AI=-,1/1 (by Definition 3.9) 
iff': AI='P (again since 'P = -.1jJ). 
2. 'P is ('Po II . . . II 'Pk-t)· Then by induction hypothesis the equivalence holds for all 'Pi 
and the result again follows by truth tables and Definition 3.9. 
3. Other connectives: similarly. 
(ii}=?(i) Now assume that we have a truth assignment 'Y for ground atoms satisfying 
all sentences in E. We produce a model A as follows. The universe A of A consists 
of all ground terms. Note that A =/:. 0, since the language contains constant symbols 
by assumption, and constant symbols are examples of ground terms. We next define 
interpretations a for the non-logical symbols (T occurring in the sentences in E. For 
constant and function symbols, we use the canonical interpretation, explained now under 
1 and 2. 
1. CONSTANT SYMBOLS 
For a constant symbol c we put c := Cj the interpretation of c is the symbol C itself. 
2. FUNCTION SYMBOLS 
For an n-ary function symbol f we define the n-ary function f over A by f(tl,"" tn) := 
f(tb' .. ,tn)' 

38 
Chapter 3 
Note. At the left-hand side of this defining equation, the function f is applied to the 
arguments tl,' .. ,tn from A; at the right-hand side of the equation the ground term 
f(tl,"" tn) is formed out of the function symbol f and these terms. 
We still have to give interpretations for the relation symbols involved. However, we 
already can calculate the values of ground terms in our model. The following lemma says 
that the answer is rather simple: the value of a ground term is the term itself. 
Lemma 3.17 For ground terms t we have: tA = t. 
Proof. Term induction 3.2. 
t is a constant symbol c. But then cA = c by definition. 
t = f(tl,"" tn), where f is a n-ary function symbol and tl,"" tn are ground terms. By 
induction hypothesis, for 1 ::; i ::; n we have: tt-
= ti. But then 
tA 
= (f(tl, . . . , tn))A = f( tf'-, ... , t8) by Definition 3.8 
= f(tl,"" tn) by induction hypothesis 
= f(tl"'" tn) = t by definition of the function f. 
I 
Definition 3.18 The Herbrand universe (relative to a given language) is the set of all 
ground terms. Notation : HU. 
A Herbrand model is a model that has HU as its universe, whereas the interpretation of 
constant and function symbols is canonical. (But the interpretation of relation symbols 
can be just anything.) 
I 
So apparently we are involved in the construction of a Herbrand model, since A = HU. 
We complete the definition of A by giving interpretations for the relation symbols. This 
is the place where we use the truth assignment ,. 
3. RELATION SYMBOLS 
If r is an n-ary relation symbol, then its interpretation, the n-ary relation r, is defined 
by: 
In other words, we let r( t I, ... , tn) be true just in case, assigns t to the atom r (tl , ... , tn). 
The definition of the model A is complete. 
In order that Ai='E, it again suffices to establish the following equivalence for all ground 
formulas I{J: 
Ai=1{J ¢:? ,i=I{J, 
since ,i='E by hypothesis. Again, this is done using formula induction. 

First-order Logic 
For atoms r(tll ... ,tn) this is seen as follows: 
Al=r(tl. .. . , tn) 
˧ 
r(tf"-, .. . ,t<) 
 r(t}, ... ,tn) 
˦ 
,(r(tl, ... , tn)) = t 
 
,I=r(tl, ... , tn) 
by Definition 3.9 
by Lemma 3.17 
by definition of r 
synonymous with the previous. 
The induction steps for the connectives are trivial as before. 
This finally ends the proof of Lemma 3.16. 
39 
• 
Example. E 
= {r(c) /\ (r(d)->r(c))} is satisfied by the truth assignment that maps 
r(c) to t and red) to f. The corresponding Herbrand model has universe {c,d}, and the 
interpretation of the unary relation symbol r is the set r = {c}. 
• 
We close this section with some elaborations on the notion of a Herbrand model. 
Definition 3.19 A language is algebraic if it does not contain relation symbols. 
A model for an algebraic language is called an algebra. 
The algebraic part of a language is its subset of function and constant symbols. 
The Herbrand algebra H A (relative to the language given) is the part common to all 
Herbrand models: it is the model for the algebraic part of the language whose universe 
is HU and that only interprets the function and constant symbols of the language in the 
canonical way previously explained. 
I 
If the language does not contain function symbols, then the Herbrand universe HU 
coincides with the set of constant symbols. In the simplest non-trivial case, HU is 
generated from just one individual constant, say 0, by means of just one unary function 
symbol, say s. 
Notation 3.20 In this situation, we identify the ground term 
s( .. . s(o) ... ) 
----
n 
that has n occurrences of s with the number n E IN. By this identification, HU = IN. 
Thus, the constant symbol a is interpreted as the number 0, and s is interpreted as 
the successor function S, which sends a number n E lN to its immediate successor 
Sen) := n + 1. 
I 
Though Herbrand models are quite special, it is in the nature of our subject that we 
shall be dealing with them most of the time, and only now and then with more general 
types of models. There are two ways in which Herbrand models deviate from arbitrary 
ones. Consider the 0, s-case. Here, every Herbrand model is infinite, since it has IN' as 

40 
Chapter 3 
its universe. However, an arbitrary model for this language may very well be finite. For 
instance, consider the algebra M od(3) over the set {O, 1, 2}, interpreting 0 again as 0, 
but interpreting s by the function s defined by s(O) = 1, s(l) = 2, and s(2) = O. So, one 
difference between a Herbrand model and an arbitrary one is that, in Herbrand models, 
different ground terms are always evaluated differently. 
There are also models for this language that extend the Herbrand interpretation. For 
instance, the algebra IN + M od(3), with universe IN U {O', 1', 2'}, the constant 0 still 
interpreted as the number 0, whereas s is interpreted as successor on IN and acts on 
{O', 1', 2'} as it does on M od(3). Another possibility is the set'lL. of all integers, 0 still 
interpreted as 0 and s as successor. Still another one is the algebra with universe the 
set TM of all terms (variables allowed), which interprets function and constant symbols 
canonically. And of course, there are endless variations and combinations. Thus, a second 
difference between a Herbrand model and an arbitrary one is that its universe exactly 
consists of the (interpretations of) ground terms. 
Remark 3.21 A more abstract but essentially equivalent notion of a Herbrand model 
A is obtained by requiring that the term-evaluation mapping t Ĭ tA from HU to A is 
a bijection: injective (different ground terms evaluated differently) and surjective (every 
element value of a ground term). 
• 
Obviously, we can add another one to the equivalents of Lemma 3.16: 
Lemma 3.22 Assume that E is a set of ground sentences. The following are equivalent: 
(i) E has a model, 
(ii) E has a Herbrand model, 
(iii) E is satisfiable in the sense of propositional logic. 
Proof. The implication (i) ˥ (iii) is given by Lemma 3.16, and (iii) ˤ (ii) was in fact 
established by the proof of that lemma. That (ii) ˣ (i) is evident. 
• 
Exercises 
3.7 The Herbrand algebra for {o, s} satisfies the following free equality axioms: 
(i) sx:::: sy-x ::::: y 
(ii) o':j; sx 
(iii) x ':j; sx, x ':j; ssx, x ':j; sssx, ... 
(iv) x:::: 0 V 3y(x ::::: sy). 
Check which of these axioms are true in the algebras previously described (M od(3) , 
IN + M od(3), the integers'lL., the algebra IN + 'lL. (see Example 6.4) consisting of IN plus 
a disjoint copy of the integers, the canonical algebra based on the set of all terms T M). 
Produce an algebra in which (ii) and (iii) hold but (i) and (iv) don't. 

First-order Logic 
3.8 Let t,p be a ground sentence. Show that the following are equivalent. 
(i) t,p is logically valid in the sense of first-order logic, 
(ii) t,p is true in every Herbrand model, 
(iii) t,p is logically valid in the sense of propositional logic. 
Hint. Use Exercise 3.4. 
41 
3.9 Note that, under the identification: propositional variables = atomic formulas, the 
propositional formulas coincide with the quantifier-free formulas. Now, assume that İ is 
a set of quantifier-free formulas (free variables are allowed). Show that the following are 
equivalent: 1.  is satisfiable in the sense of first-order logic (Le., for some model A and 
some A-assignment Q, we have A F t,pQ for all t,p E ̰); 2. M is satisfiable in the sense of 
propositional logic (Le., by a truth assignment for atomic formulas). 
Hint. Modify the proof of Lemma 3.16. For 2 => 1, consider the canonical algebra over 
the set of all terms TM and let a be the identity assignment. 
3.5 
Universal Sentences 
The result of the previous section can be pushed a little further. For this, we must 
know something about substitutions and their effect on values of terms and satisfaction 
of formulas first. Compare Definition 3.10 and Notation 3.11: a substitution in fact is 
an assignment into the set of all terms. 
Definition 3.23 A substitution is a function () from all variables to terms, such that its 
domain Dam«(}) := {x I x ¥- (}(x)} is finite. 
In the context of substitutions, it is common to use a postfix-notation: x(} := (}{x). 
If x is a variable and t a term, then x/t (a binding of x) denotes the ordered pair 
(x, t). Thus, {xdtl, . . . ,xn/tn}, where Xl, ... ,Xn are pairwise different variables, is the 
substitution that has {Xl!'" ,Xn} (more precisely: {Xi I Xi ¥- til) as its domain and, for 
1 \ i \ n, assigns the term ti to the variable Xi· 
If t is a term and 0 is a substitution, then to (the O-instance of t) is the term obtained 
from t by replacing every occurrence of a variable x E Var(t) by its {I-image xO. And if 
t,p is a formula, then the formula t,pO (the (I-instance of t,p) is obtained from t,p by replacing 
every free occurrence of a variable x E Var(t,p) by its (}-image. 
o is called ground for the expression E if xB is ground for every x E Var (E). () is ground 
if xO is a ground term for every x E Dam(O). 
I 
For the moment, this definition suffices. Later on, in Section 3.8, more will come. 
Notation. Compare Notation 3.11. If E = E(Xl, ... ,xn) is a term or a formula and 
0 = {xI/h, ... ,Xn/tn}, then we write E(tl,"" tn) as short for EO. 
I 

42 
Chapter 3 
We need some technical (though rather evident) results about the relationship between 
the interpretation of an expression and its instances. 
Lemma 3.24 Assume that B is a ground substitution, that A is a model and a is the 
A-assignment defined on Dom(O) by: a(x) = (xB)A. Then 
(i) if 0 is ground for the term t, then: (tB)A = (ta)A
, 
(ii) if B is ground for the quantifier-free formula 'P, then: Ap'PO <=> Ap'Pa. 
To appreciate this lemma, note the difference between to and 'PO on the one hand, and ta 
and 'Pa on the other: e.g., to can be very complicated compared to t, since application of 0 
may substitute complicated terms for variables in t; however, ta has the "same degree" of 
complexity as t since now only (new) constant symbols are being substituted. Of course, 
since a(x) = (xO)A, the constant substituted by a for x has the same value as the term 
substituted by B, and this intuitively explains why the lemma is true. The calculations of 
the values of to and ta, according to the rules of Definition 3.8, parallel each other until 
terms xB resp. xa are reached, which have the same value anyway. Something similar 
can be said about ascertaining truth of 'PO and 'Pa in A using the rules of Definition 3.9. 
Proof. (i) Induction on t. 
1. t is the variable x. Then (xO)A = a(xl = (xa)A. 
2. t is the constant symbol c. Then (cO) 
= cA = (ca)A. 
3. t = f(tl"" ,tn)' By inductive hypothesis, for 1 ::; i ::; n we have (tl(})A = (tla)A. 
Now: (to)A = (f(tlB, . . .  , tnB))A 
= f((tlB)A, ... , (tnB)A) = f «ha)A, ... ,(tna)A) 
= f(tlo!, ... , tna)A = (f(tl"'" tn)a)A= (ta)A. 
(ii) Induction on 'P. For 'P an atom r(tl' ... ,tn) we have, using (i): 
Apr(h, .. . ,tn)B 
{:} 
Apr(tlB, ... , tnO) 
{:} 
r((hO)A, ... , (tnB)A) 
{:} 
r((ha)A, ... , (tnO!)A) 
{:} 
Apr(tla, ... ,tna) 
{:} 
Apr(tb .. . , tn)a. 
The induction steps corresponding to the connectives are all straightforward. 
I 
Remark. Assume that the model A considered in Lemma 3.24(ii) is Herbrand. By 
Lemma 3.17 we then have, for x E Dom(B) , O!(x) = (xO)A = xB = B(x); i.e.: a = B. 
The equality (to)A = (to!)A and the equivalence Ap'PB {:} Ap'Pa apparently reduce to 
trivialities. However, as just remarked, the terms and formulas here must be conceived 

First-order Logic 
43 
of differently. That, in a Herbrand model, one simple constant symbol a(x) can actually 
be a composite must be considered a coincidence connected with the particular way in 
which the notion of Herbrand model is defined. The confusion would disappear when 
using Herbrand models as suggested by Remark 3.21. 
• 
The following definition introduces the objects of interest of this section. 
Definition 3.25 If <p is a formula with Var(<p) 
= {Xl,." ,Xn}, then V<p denotes the 
(universal) closure VXI ... Vxncp of cp and 3cp the existential closure ::IXl ... 3xncp, V here 
being short for the sequence VXI ... VXn and 3 as short for 3Xl .. ·3xn. 
A sentence VXl'" Vxncp (resp., 3Xl'" 3xncp) is called universal (resp. existential) if cp is 
quantifier-free. In that case, VXI ... VXn (resp. 3Xl .. ·3xn) is called the prefix and cp the 
matrix of Vcp (3cp). 
• 
Remark 3.26 A universal sentence will often be confused with its matrix. The justifi­
cation for this is that they both have the same models. For, the universal closure Vcp is 
true in a model A iff (by Definition 3.9) for all A-assignments a for cp we have Al=cpa 
iff (by Definition 3.13(i)) cp is true in A. 
• 
Part (i) of the next result forms the logical explanation of arguments like: if everyone 
is mortal, then so is Socrates. As to part (ii), witnessing Socrates die, we are entitled to 
the conclusion that someone is mortal. 
Corollary 3.27 Suppose that cp is a quantifier-free formula and 0 a substitution that is 
ground for cp. Then 
(i) Vcpl=cpO, 
(ii) cp01=3<p. 
Proof. (i) Suppose that AI=Vcp. That is, by Remark 3.26: for every A-assignment a 
for cp we have Al=cpa. In particular, this must be true for the assignment a defined by 
a(x) := (xO)A. Apply Lemma 3.24. (ii) Similarly. 
• 
In a later section, we shall need to generalize these results slightly. 
Definition 3.28 If cp is a quantifier-free formula, then both ground(cp) and ground(Vcp) 
denote the set of all ground instances of cp (all sentences of the form cpO). (ground(<p) 
also is called the Skolem expansion of cp.) 
If P is a set of quantifier-free formulas and/or universal sentences, then ground(P) 
denotes the union of all sets ground(<p) for cp E P. 
• 
The following is a satisfiability criterion for sets of universal sentences. 
Theorem 3.29 (Herbrand) Suppose that P is a set of universal sentences. The fol­
lowing are equivalent. 

44 
(i) P has a model, 
(ii) P has a Herbrand model, 
(iii) ground(P) is satisfiable. 
Chapter 3 
Note. By Lemma 3.16 or Lemma 3.22, it makes no difference whether we interpret 
satisfiability in (iii) either in propositional or in first-order logic. 
Proof. ( ii) => (i). This is evident. 
(i) => (iii). By Corollary 3.27, every sentence in ground( P) follows logically from P. That 
is, every model of P is a model of ground(P) as well. 
(iii) => (ii). Assume that ground(P) is satisfiable. By Lemma 3.22, there exists a Her­
brand model A for ground(P). 
Claim: A also is a model for P! 
This is an immediate consequence of the fact that, in a Herbrand model, every element 
is the value of a ground term ( by Lemma 3.17, an element t E HU is the value of t itself) 
and half of the following Lemma 3.30. 
• 
Lemma 3.30 Suppose that A is a model with the property that 
every element a E A is the value of a ground term: A = {tA I t E HU}. 
If'P is a quantifier-free formula, then A!=V'P iff A is a model of ground('P). 
Proof. Corollary 3.27 is responsible for the trivial half. Now, assume that A!= ground(cp), 
where Var('P) = {Xl,' .. ,xn}. By Remark 3.26, we have to show that A!='PO: for an 
arbitrary A-assignment 0: = {XI/al,'" xn/an} for 'P. For 1 ѯ i Ѱ n, choose a ground 
term ti such that tft- = ai. Let () be the substitution () = {xI/tl,'" xn/tn}. () is ground 
for 'P. By hypothesis, A!='P8. By Lemma 3.24, A!='PO:. 
• 
Example. Consider the universal sentence Vx[r(so) 1\ (r(x)-r(ssx»J. 
The elements 
o = 0, 1 = so, 2 = 880, 3 
= S8S0, . . . form the universe IN of the Herbrand model. 
Taking the set r := {1, 3, 5, ... } as interpretation of the relation symbol r over this 
universe, the result is a Herband model for it. Another one is obtained by letting r be 
IN+. Try to find two more Herbrand models for this sentence. 
• 
Example. Suppose that c is a constant symbol and r a 1-ary relation symbol. Every 
Herbrand model for this language has but one element: c. A model of the ( satisfiable) 
sentence r(c) 1\ 3x-.r(x) must have at least two elements; and so there is no Herbrand 
model for this sentence (suited to its own language). This sentence is not universal. 
Thus, it is not true that every satisfiable sentence has a Herbrand model corresponding 
to its own language. 
• 

First-order Logic 
45 
By the Conjunctive Normal Form Theorem 2.9 (which of course holds in the extended 
context of first-order logic for quantifier-free formulas) ,  we always can transform the 
matrix cp of a universal sentence into conjunctive normal form. Satisfiability of ground( cp) 
(and hence, by Theorem 3.29, of Vcp) can then be tested using the concept of resolution 
from the previous chapter. Letting ground atoms take over the role of propositional 
variables, we consider clauses made up of ground atoms and their negations and try to 
derive the empty clause D .  
Example 3.31 Look at the following universal sentence. r is a binary relation symbol, 
c is a constant symbol and f is a 1-ary function symbol. 
VyVw [( -,r( c, y) V -,r(y, w) V -,r( w.y)) 1\ (r( c, y) V r(y, fy)) 1\ (r( e, y) V r(fy, y))]. 
Using the ground substitution {y / e, w / c} the first conjunct of the matrix produces the 
clause {-,r( c, c)} (the three disjuncts all produce the same instance), the second conjunct 
is responsible for {r(c, e), r(e, fc))}, and the third one makes {r(c, c), r(fc, e)}. 
The first two have a resolvent {r( e, fe)}, the first and third produce {r(fe, c)}. 
Next we use the ground substitution {y/fc, w/c}; under it, the first conjunct produces 
the clause {-,r(c, fe), -,r(fc, c)} (first and third disjunct producing the same instance). 
Together with the clauses derived previously, we reach the empty clause 0 in two more 
propositional resolution steps. 
• 
Discussion. 
Suppose that a matrix (a quantifier-free formula) cp in conjunctive normal form is given. 
If ground( cp) is not satisfiable, then 0 can be derived using propositional resolution 
from the set of clauses that are, in fact, nothing else but conjuncts of sentences in 
ground( cp). Such a refutation consists of finitely many clauses, and so it can use only 
finitely many clauses corresponding to conjuncts of sentences in ground(cp). These finitely 
many clauses, in turn, can have used only finitely many ground terms as replacements 
of occurring variables. 
In Example 3.31, we used only two ground terms in the derivation of 0 :  c en fc. 
If the matrix cp has no function symbols, then constant symbols are the only ground 
terms, and of these, only finitely many can occur in the matrix. Then ground( cp) is 
finite; the number of clauses that resolution is able to produce is finite too. In such a 
case, resolution is a test for satisfiability as well; just produce all resolvents possible, there 
is an end to this (and it is clear when that stage has beel!- reached) . If 0 is one of the 
clauses produced, then the original sentence is unsatisfiable, and if not, it is satisfiable. 
The situation is completely similar to the one of propositional resolution, cf. Exercise 
2.25. 

46 
Chapter 3 
However, if the matrix contains but one function symbol, then infinitely many ground 
terms are generated , infinitely many ground substitutions are possible, and a problem 
arises: which do you need to derive O? 
In case the original universal sentence happens to be unsatisfiable, and the search has 
been systematic, not skipping any ground substitution, then 0 has to be derived at some 
time or other. But in the case of a satisfiable sentence, the search will go on for ever. 
You may try more and more complex ground substitutions without 0 ever being derived. 
Still worse , you may not even notice that your search is in vain. 
So, resolution here usually only produces half of what we would like: it will always 
signalize unsatisfiability, but often, satisfiability is not signalized. This is called positive 
decidability of unsatisfiability of universal formulas. According to the Theorem of Church 
7.19 (and the existence of Skolem transforms, Theorem 3.34), this cannot be remedied. 
Nevertheless, in a sense there is an answer to the problem of which instances are needed 
to derive O .  This is given by the notion of resolution for first-order logic, dealt with in 
the last section of this chapter. 
Exercises 
3. 10 The universal sentence 
V'x[r(c) 1\ -,r(fc) 1\ r(fffc) 1\ (r(x) V ..,r(fffx)) 1\ (--,r(x) V r(ffx))] 
is unsatisfiable. Give a set of ground clauses, instances of conjuncts of the matrix, from 
which 0 may be derived. 
* 3.1 1  Let cp be a quantifier-free formula. Show that the following are equivalent . 
(i) p3cp, 
(ii) there are finitely many substitutions 00, . . .  , Ok-l ground for cp such that 
pcpBo V ' "  V cpOk-l. 
Give an example which shows that in (ii) we can not always have k = 1. 
Hint. Use Theorem 3.29 and the Compactness Theorem 2.22 of propositional logic. 
3.6 
Prenex and Skolem Forms 
The previous section established positive decidability of unsatisfiability for universal sen­
tences with matrix in conjunctive normal form. This section discusses two transfor­
mations with which this result extends to arbitrary first-order sentences. The reader 
primarily interested in resolution can skip to Section 3.7. 

First-order Logic 
47 
Definition 3.32 A formula is called prenex if it has the form 
where tp is quantifier-free, Xl ,  . . . , Xn are pairwise different variables, and for 1 $ i $ n ,  
either Qi = V or Qi = 3. 
QIXI . . .  Qnxn is called the prefix of the formula and tp is called its matrix. 
• 
Compare Definition 3.25; note that a universal sentence is a prenex sentence, the prefix 
of which consists of universal quantifiers only. 
Theorem 3.33 (Prenex Normal Form) Every formula has a logical equivalent in 
prenex form with the same free variables. 
Theorem 3.34 (Skolem Form) To every prenex sentence there exists a universal sen­
tence (in general containing new constant and function symbols) that is satisfiable iff the 
original one is. 
The universal sentence of the last theorem is called the Skolem form or transform of 
the prenex sentence. 
The constructions of prenex and Skolem forms are effective processes (see the proofs 
of Theorems 3.33 and 3.34 in subsections 3.6. 1 resp. 3.6.2). 
Corollary 3 . 35 Logical validity and unsatisfiability in first-order logic are positively de­
cidable. 
Proof. Note that a sentence is logically valid iff its negation is unsatisfiable; so if we 
can positively decide on unsatisfiability, then so can we on logical validity. To decide 
whether a sentence tp is unsatisfiable, produce an equivalent prenex form and a subse­
quential Skolem form V,¢, where '¢ is in conjunctive normal form. By Theorem 3.29, tp is 
unsatisfiable iff ground( '¢) is. To test whether ground( '¢) is unsatisfiable, systematically 
generate its elements one by one (using more and more complex ground terms) and start 
producing propositional resolvents .  If indeed ground( '¢) is unsatisfiable, 0 will turn up 
eventually. 
• 
The proofs of Theorems 3.33 and 3.34 need a strengthened form of Lemma 3.24 and 
a nasty notion. Since intuitively the construction of prenex and Skolem forms is quite 
straightforward, readers troubled by the next few technical results should skip proofs 
here. 
Definition 3.36 
(i) The term t is substitutable for the variable x in the formula tp if tp does not contain 
a free occurrence of x in the scope (Definition 3.5) of a quantifier binding a variable 
from Var(t). 

48 
Chapter 3 
(ii) The substitution B is called admissible for cp if for every variable x E V are cp): xB 
is substitutable for x in cp. 
• 
Thus, t is not substitutable for x in cp if, applying the substitution {xjt} to cp, some 
variable in t becomes bound in the resulting expression. 
Clearly, ground terms are always substitutable and ground substitutions are always ad­
missible; for a quantifier-free formula, every term is substitutable and every substitution 
is admissible. 
Example. 
The variable y is not substitutable for x in 3yr(x, y). 
'v'x3yr(x, y)-(3yr(x, y»{xjy}, that is: 'v'x3yr(x, y)-3yr(y, y), is not logically valid Oust 
consider the model (IN, <)). 
• 
Thus it is not always the case (contrary to what might be expected on the basis of 
Corollary 3.27) that truth of 'v'xcp implies truth of cp{xjt}. For this, t needs to be substi­
tutable for x in cp. This illustrates necessity of the admissibility condition in Corollary 
3.38(i). 
The next lemma extends Lemma 3.24(i) in allowing B to be non-ground for t and it 
extends 3.24(ii) in allowing 8 to be non-ground for cp and cp to contain quantifiers. 
Lemma 3.37 Suppose that A is a model, B a substitution and (3 an A-assignment. Let 
the A-assignment a be defined by a(x) = (xB{3)A . Then 
(i) if t is a term, then (ta)A = (tB{3)A; 
(ii) if <p is a formula and B is admissible for <p, then: Af=<pa iff AFCPB{3. 
Proof. (i) This only slightly extends the proof of the corresponding part of Lemma 3.24 
and is left to the reader. 
(ii) Induction with respect to <p. Basis and induction steps for the connectives are 
straightforward. Here follows the induction step for the 'v'-case. We may as well as­
sume that Dom(B) C Dom(a) = Var(<p) - {x} and x E Var(<p) . Then: 
Af=('v'xcp)a 
iff for all a E A : AF<p(a U {x/a}) (by Definition 3.9) 
iff for all a E A: AF<PB({3 U {x/a}) (by inductive hypothesis for <p, applied 
to a U {x/a} and {3 U {x j a}, since B a fortiori is admissible for cp and does not affect x) 
iff AF ('v'x ( <pB»{3 (by Definition 3.9) 
iff Af=('v'x<p)B{3 (since x ѭ Dom(O» . 
• 
Corollary 3.38 If B is admissible for the formula <P, then 
(i) 'v'<pp<pB, 
(ii) <pBp3<p. 
Proof. As Corollary 3.27, but this time using Lemma 3.37. 
• 

First-order Logic 
49 
3.6.1 
Prenex Form 
Here follows the proof of the Prenex Form Theorem 3.33. 
Suppose that 'P is a formula for which we want to construct a prenex equivalent. We 
may as well suppose that .." 
1\ and V are the only connectives occurring in 'P. We now 
use the following equivalences (read from left to rightj the first two are given by Lemma 
3.14) to "pull quantifiers out" of a negation, a conjunction or a disjunction: 
(i) ..,Vx'I/J I'V 3x-,'I/J, 
(ii) -,3x'I/J I'V VX-'t/J, 
(iii) (Vx'I/J 1\ X) I'V Vy('I/J{x/y} 1\ X), 
(iv) (3x'I/J 1\ X) I'V 3y('I/J{x/y} 1\ X), 
(v) (Vx'I/J V X) I'V Vy('I/J{x/y} V X), 
(vi) (3x'I/J V X) I'V 3y('I/J{x/y} V X)j 
and similarly if the quantifier to be pulled does not occur in the first con- or disjunct. 
For the variable y we have the choice between x (but only in case x does not occur free 
in X) and some arbitrary variable not occurring in 'I/J or X. The fact that the formulas 
displayed are equivalences indeed needs Corollary 3.38. The reason to change the bound 
variable x to y if it is free in X is clearj otherwise, the quantifier, after pulling it out, 
suddenly would bind the occurrences of x in X and equivalence would be lost. 
Note that we have to apply these equivalences inside a given formula. This needs the 
result from the following exercise. 
• 
Exercise 
3.12 Show: replacement, in a formula, of a subformula by an equivalent, results in an 
equivalent of the original formula. 
3.6.2 
Skolem Form 
Here follows the proof of the Skolem Form Theorem 3.34. 
Suppose that VXl .. . Vxn3y'P is a prenex sentence. By Definition 3.32, no two different 
occurrences of quantifiers in the prefix bind the same variable. Note that 'P is allowed 
here to contain quantifiers as well. We have exhibited the prefix "Ix! . . .  VXn3y only up to 
and including the first existential quantifier. However, possible quantifiers in 'P will not 
bind Xl, . . . , Xn (or y). Since 'P does not contain quantifiers binding X l , . . .  , Xn, Y cannot 
occur free in 'P in the scope of such a quantifier. 
Now assume that f is an n-ary function symbol not occurring in 'P. If n = 0, i.e., if no 
universal quantifiers precede the first existential one, this means that f is a constant sym-

50 
Chapter 3 
bol instead of a function symbol. It follows that the term f(x} , . . .  , xn) is substitutable 
for y in cp; hence, the substitution {y/f(X l , ' "  , Xn)} is admissible for cpo 
In the context of the following lemma, f is referred to as a Skolem function symbol. 
Lemma 3.39 '"fix} . . .  'Vxn3ycp is satisfiable iff '"fix} . . .  '"fIxncp{y/f(Xl ,  . . .  , xn)} is satisfi­
able. 
Proof. For ease of notation, suppose that n = 1; Le., we are dealing with the sentence 
'"fIx3ycp(x, y). 
<= By Corollary 3.38, we have cp{y/f(x)} p3ycp. That is, every model of 'Vxcp{y/f(x)} 
is a model of 'Vx3ycp as well. 
=? Assume that A is a model appropriate to the language of cp in which '"fIx3ycp(x, y) 
is true. That is, to every a E A there exists b E  A such that Apcp(a, b). Let f(a) be 
one of those b's. Then f : A-.A and for all a E A we have Apcp(a, f(a» . Adjust 
A to the language expanded with f by taking f as interpretation of this symbol. Let 
A' be the model so obtained. By Lemma 3.37 we have for all a: A'pcp(a, f(a» , i.e., 
A'p'"flxcp(x, f(x» . 
I 
By repeated application of Lemma 3.39, all existential quantifiers from the prefix of 
our prenex sentence are eliminated in favor of new function symbols. Eventually, the 
required Skolem form appears. 
I 
On strategy. In the construction of the prenex form we often have a choice as to 
which quantifier is pulled out first. It is profitable to follow a strategy by which Skolem 
function symbols will get the least number of arguments, since this may simplify the 
ensuing resolution process. This usually will mean pulling out existential quantifiers 
first. 
Example 3.40 Consider the sentence 
3x'Vy Irxyo-dz(ryz 1\ rzy)J. 
(3.6.1) 
This sentence is unsatisfiable. Assume that (A, R) is a model for it. Then an element 
a E A exists such that 
'"fIy E A  [Rayp-dz E A(Ryz 1\ Rzy)]. 
(3.6.2) 
In particular, for y := a, 
Raa/...,3z E A(Raz 1\ Rza). 
(3.6.3) 
Evidently we also have 
Raa-.3z E A(Raz 1\ Rza) 
(take z : =  a). 

First-order Logic 
51 
As a consequence, Raa cannot hold. Therefore, by (3.6.3), we have 3z E A(Raz A Rza). 
For instance, assume that b E A is such that Rab A Roo. From (3.6.2) it now follows, 
taking y := b, that 
Rab<-+--,3z E A(Rbz A Rzb). 
But of course we also have, by choice of b, that 
Rab-+3z E A(Rbz A Rzb) 
(take z := a). Therefore we have -.Rab, a contradiction. 
In order to establish unsatisfiability using propositional resolution, we first produce a 
prenex equivalent for (3.6.1). Eliminate <-+ :  
3xVy [[--.rxy V --.3z(ryz A rzy») A [rxy V 3z(ryz A rzy)]]. 
Pulling the second z-quantifier out in two steps, we obtain 
3xVy3z [[--.rxy V --.3z(ryz A rzy)] A [rxy V (ryz A rzy)]] . 
Pulling out the other z-quantifier one step, we obtain first 
3xVy3z [[--,rxy V Vz--.(ryz A rzy)J A [rxy V (ryz A rzy)lI . 
But now we have to change z to some new variable w before we can move it over the free 
z in the right conjunct; the required prenex form finally is (after applying DeMorgan in 
left conjunct and distribution in the right one) 
3xVy3zVw [(-,rxy V -.ryw V -.rwy) A (rxy V ryz) A (rxy V rzy)]. 
The Skolem transformation (Lemma 3.39) introduces a constant symbol c (for the first 
existential quantifier 3x) and a 1-ary function symbol f (for the second one 3z), and we 
obtain finally 
VyVw [(-.r(c, y) V -.r(y, w) V -.r(w, y» A (r(c, y) V r(y, fey»Å) A (r(c, y) V r(f{y), y» J. 
This is the universal sentence of Example 3.31. 
Exercises 
3.13 Construct prenex and Skolem forms for the following sentences: 
(i) 3x(Vy3zp(x, y, z) A 3z'Vy-.p(x, y, z» ,  
(ii) Vx(3yq(x, y) V Vy3zr(x, y, z» ,  
• 

52 
Chapter 3 
(iii) Vx(-,3xp(x, y)-3xq(x, x». 
3.14 Produce Skolem forms for the following sentences and unsatisfiable finite subsets 
of Herbrand expansions: 
(i) 3xVyr(x, y) 1\ Vy3x-,r(y, x), 
(ii) ..,(Vxpx V 3y-,qy) 1\ (Vzpz V 3w-,qw). 
3 . 1 5  Show, via Skolem form and propositional resolution, unsatisfiability of the following 
sentences: 
(i) 3xVy(r(x, y).-.-,r(y, y», 
(ii) 3xVy[r(x, y).-.-,3z3u(r(y, z) 1\ r(z, u) 1\ r(u, y» ]. 
3.16 'P, 'r/J and X are three different quantifier-free formulas such that V ar( 'P):: V ar( 'r/J)= 
{x, y} and Var(x) :: {u, v} Consider the sentence 3 x.., (3y'P V  Vy'r/J) v Vu3vX· 
(i) In how many ways can you pull out quantifiers to obtain a prenex normal form for 
this sentence? 
(ii) Which of these forms would be your choice if you had to produce a Skolem form 
next, in order to apply resolution? 
(iii) Describe the Skolem form of the prenex form of your choice. 
3 .17 Prove that the relation of logical consequence: 'P\='r/J (where 'P and 1/J are first-order 
sentences) is positively decidable. 
3.6.3 
Compactness 
The following result is the Compactness Theorem of first-order logic. Compare Theorem 
2.22. 
Theorem 3.41 (Compactness) If every finite subset of an infinite set of first-order 
sentences is satisfiable, then so is the set itself 
Proof. Exercise 3.18. 
• 
The following model-theoretic material is used only in Chapters 6 and 8 but, since it 
rests on the Compactness Theorem, is best put here. It will not be needed until much 
later and can safely be skipped until then. 
Definition 3.42 Suppose that the models A and B have the same language L. 
A is a submodel of B, and B an extension of A, notation: A c B, if A c B, and: 
(i) if r is an n-ary relation or function symbol, then the interpretation rA of r in A is 
the restriction to A of the interpretation rB of r in B, that is, rA coincides with 
rB on An , 
(ii) if c is a constant symbol, then its interpretations in A and B are the same. 

First-order Logic 
53 
A is an elementary submodel of B and B an elementary extension of A, notation: A -< B, 
if 
(i) A c B, and 
(ii) A-assignments satisfy the same formulas in A as in B; equivalently, A and B satisfy 
the same A-sentences. 
• 
For instance, (IN, <) c (71, <), but (IN, <) 1< (71, <), since 0 has a predecessor in 7l 
but not in IN. Natural examples of elementary submodels are harder to come by, though 
it is the content of Lemma 3.43 that they exist in abundance. However, without proof 
we mention the facts that the algebra IN + 7l (cf. Exercise 3.7) elementarily extends the 
Herbrand algebra IN corresponding to the language {o, s}, and the ordering of the reals 
elementarily extends the ordering of the rationals. 
The Compactness Theorem is responsible for the fact that elementary extensions 
abound. 
Lemma 3.43 Every infinite model has a proper elementary extension. 
Proof. Suppose that A is an infinite model. Let E be the set of all A-sentences true in 
A. Add one new constant symbol c to the language and consider the set r := E U {...,c  
a I a E A}. Every finite subset of r is satisfiable (use A with a suitable interpretation 
of c). By compactness, r has a model that we may take to be an elementary extension 
of A. The sentences ...,c  a take care that the interpretation of c is different from each 
a E A and so the extension is proper. 
• 
Exercises 
3. 18 Prove Theorem 3.41. 
Hint. Use Skolem forms; note that a derivation of 0 from ground instances of conjuncts 
can use only finitely many of such ground instances. 
The following is the Downward Lowenheim-Skolem Theorem for countable sets of sen­
tences. 
Theorem 3.44 (Lowenheim-Skolem) Every countable satisfiable set of sentences has 
a countable model. 
3. 19 Prove Theorem 3.44. 
Hint. Use the solution to Exercise 3.18. 
3.20 Show: if A c B, then A and B satisfy the same quantifier-free A-sentences. 
Hint. Induction on the sentence involved . 
3.21 Let A be a model and suppose that If> = (<pi l i E IN) is an infinite sequence of 
formulas <pi with only x free. Suppose that for every N E IN: AI=3x l\i<N <pi. Show: 
some elementary extension B of A has an element b such that for all i E IN: BI=<pi{xjb}. 

54 
Chapter 3 
3.22 Assume that the models Ai form a chain: Ao C Al C A2 C . . . . Show that there 
is a unique model A such that A = Un An and such that for all n: An C A. 
Show: if, in fact, the models form an elementary chain: Ao -< Al -< A2 -< "
', then 
(Elementary Chain Lemma) for all n: An -< A. 
Hint. For the second part: induction on sentences, keeping n variable. Part of the 
argument is the following. Suppose that Ap3xcp, 3xcp an An-sentence. Say, Al=cp{x/a}, 
a E A. Now A = Ui A;; for instance, a E Am, where we may assume that n < m. Then 
Amp3xcp, and hence An l=3xcp, as, by assumption, An -< Am . 
3.7 
Resolution: The Unrestricted Version 
The basic idea of "resolution in first-order logic is that propositional resolution steps (in­
volving clauses corresponding to ground instances of conjuncts of the matrix of a Skolem 
transform) that are "similar" can be done all at the same time, before the instantiating 
process has taken place, thus saving steps. More importantly, the method solves the 
problem of which ground instances are needed to derive D .  
We begin with unrestricted resolution, of which the proper resolution notion is just a 
special case. 
Since we are in first-order logic, atoms - variables allowed now! - again take over the 
role of propositional variables. Thus, a literal (d. Definition 2.8) is an atom (a positive 
literal) or the negation of an atom (a negative literal) . A clause is a finite set of literals 
(d. Definition 2.10) .  Since clauses originate from conjuncts of a universal Skolem form, 
variables should be thought of as quantified universally; that is, a clause C represents 
the universal closure V V C of the disjunction V C of the elements of C. 
In the rest of this chapter, the notation Co. is used for the set of a-instances of literals 
in C: Co. : =  {La I L E C}. 
Recall that (Definition 2. 13) in the propositional case, the clause (C - {A} )U(D-{ -,A}) 
is a resolvent of C and D when A E C and -,A E D. In the present context, in which 
propositional variables are identified with ground atoms (see Section 3.4), we must require 
C and D to be ground here. Compare Example 3.31 and the discussion given there. From 
now on we drop this requirement, and allow variables in clauses when forming resolvents. 
When applied to clauses containing variables, a transition of the type described is still 
referred to as a propositional resolution step. The derivability relation it defines is written, 
as before, as f-p• 
We now relax this notion of resolution by admitting preliminary instantiations. 
Definition 3.45 An unrestricted resolvent of two clauses is a propositional resolvent of 
instances of those clauses. 
• 

First-order Logic 
55 
To explain this definition in somewhat more detail: suppose that P, C, N ' and D are 
clauses such that P n C = N n D = 0 and a and f3 are substitutions. Then Ca U D(3 
is an unrestricted resolvent of the clauses P u C  and N U D in case an atom A exists 
such that Pa = {A} and Nf3 = {.A} (or vice versa). In this situation, we will say that 
Ca U Df3 is an unrestricted resolvent of the clauses P u C  and N U D with respect to the 
subclauses P and N. 
P u c  
N u D  
l 
{A} U Ca 
{.A} U Df3 
 /  
Ca U D(3 
instantiation 
prop. resolution 
The clauses P and/or N may have been singletons (one-element sets) already, but this 
is not required by the definition. However, a and f3 must collapse P resp. N to singletons 
Pa and N f3 of opposite literals. (In the next section we shall say that a and f3 unify P 
resp. N.) 
Example. Let C = {-.r(x, fy), s(x, fz)} and D = {r(z, fz) , r(fy, u)}. Then application 
of a := {x/fy, y/fy, z/y} transforms C into {.r(fy, ffy), s(fy, fy)}; application of (3 := 
{z/fy, u/ffy} transforms D into the singleton {r(fy, ffy)}. A propositional resolvent of 
the instances Ca and Df3 is {s(fy, fy)}, which thus is an unrestricted resolvent of C and 
D with respect to the sub clauses {-.r(x, fy)} and D itself. 
I 
Compare Definition 2. 14 with the following one. 
Definition 3.46 Unrestricted resolution is forming unrestricted resolvents repeatedly. 
More precisely: an unrestricted derivation of a clause E from a set r: of clauses is a finite 
tree T such that 
(i) E is the root of T, 
(ii) every leaf of T belongs to :2:, 
(iii) every non-leaf D of T has children Dl and D2 of which it is an unrestricted resol­
vent. (Again, it is allowed that Dl = D2, see Exercise 3.25.) 

56 
Chapter 3 
The number of non-leaf nodes of a derivation is its number of steps. 
The notation : ˢ I-u E is used when there exists an unrestricted derivation of E from ̰. 
An unrestricted derivation of 0 from ̰ is called an unrestricted refutation of İ. E is 
unrestrictedly refutable if it has an unrestricted refutation. 
• 
Example. To see that unrestricted resolution can economize on steps compared with 
propositional resolution, consider the following clauses {r(c)} ,  {r(fc)}, {...,r(x), s(x)}, 
{...,s(x), q(x)}, and {-,q(c), -,q(fc), -,r(c)}. 
Using the instances {-'r(c), s(c)}, {-'r(fc), s(fc)} of the third clause and {-,s(c), q(c)}, 
{-,s(fc), q(fc)} of the fourth, we successively derive {s(c)}, {s(fc)}, {q(c)} , {q(fc)}, 
{-,q(fc), -,r(c)}, {-'r(c) }, 0 in 7 steps using proposional resolution. 
Applying unrestricted resolution to the original clauses, we derive {.r(x), q(x)}, {q( c)} ,  
{q(fc)}, {-,q(fc), -'r(c)}, {-'r(c)}, 0 in 6 steps. 
The gain is not impressive, but the principle is clear. 
• 
We recall a couple of notions from Definition 3. 13, but now in the context of clauses 
and clausal forms. 
Definition 3 .47 
(i) A is a model of the clause C, notation: AFC, if AF'v' V  C; that is, every A­
assignment satisfies at least one literal of C, 
(ii) A is a model of a set of clauses if it is a model of every clause in the set, 
(iii) the clause C follows logically from the set of clauses B, notation: BFC, if every 
model of B is a model of C, as well. 
• 
Lemma 3.48 If E is an unrestricted resolvent of C and D, then {C, D} F E. 
Proof. Immediate from the corresponding fact for propositional resolution (Lemma 2.15) 
and Corollary 3.27. 
• 
The following soundness result asserts that, from a set of clauses, we can only derive 
logical consequences. 
Corollary 3.49 (Soundness) If E I-u E, then œFE. 
Proof. See Exercise 3.23. 
Corollary 3.50 If n is unrestrictedly refutable, then n is unsatisfiable. 
Proof. Immediate from 3.49, since 0 is not satisfiable. 
• 
• 
The following result is not of much interest in itself. However, by "lifting" (to be 
explained later) it produces the completeness result we're aiming for (Theorem 3.80 of 
Section 3.9). 

First-order Logic 
57 
Theorem 3.51 (Unrestricted Completeness) Every unsatisfiable set of clauses is 
unrestrictedly refutable. 
Proof. If E is unsatisfiable, then, by Theorem 3.29, so is groundCE). Hence by com­
pleteness of propositional resolution (which applies here, by Lemma 3.22), Theorem 2. 18, 
ground(E) f-p O. 
Let T be a derivation of 0 from ground(E) using propositional resolution. In T, every 
leaf is ground instance of a clause from E. Replace every leaf by the clause from E from 
which it is an instance. The resulting tree clearly is an unrestricted derivation of 0 from 
E. 
I 
Exercises 
3.23 Prove Corollary 3.49. 
Hint. Strong induction with respect to the height of the derivation given. The induction 
step uses Lemma 3.48. Compare the proof of Corollary 2. 16. 
3.24 Note that Theorem 3.51 claims the implication: EFC ::} E f-u C, only for C = o. 
Show (by giving a simple example) that this may be false for C i:- D. (Compare Exercise 
2.28.) 
3.25 In propositional resolution, it is not useful to form a resolvent of identical clauses. 
(Cf. Exercise 2.18.) Discuss this case here. 
Hint. Consider {,rx, rf x}. 
3.26 Derive 0 ,  using unrestricted resolution from, or give a Herbrand model for the 
following: 
(i) {{rex, y) ,  r(y, x)}, {,r(x, fX)}}, 
(ii) {{rex, y), r(y, z)} ,  {-,r(x, fx)}}, 
(iii) {{ -,px, pffx}, {-,qx, qffx}, {px, qx}, {,px, ,qx}}. 
3.27 Assume that E f- p  D and that a is a substitution. Show that for some E C Da we 
have that {Ca I C E  E} I-p E. 
(The example E := {{r(a), r(b), r(x)}, {-,r(a), r(c)}}, D := {r(b), r(x), r(c)} and a := 
{x/a} shows we cannot require E = Da.) 
3.8 
Unification 
Before going on to the proper notion of resolution, we need to discuss the syntactical 
notion of unification. 
Recall (Definition 3.23) that a substitution is a function 0 mapping the variables to 
terms such that Dom(O) = {xix i:- xO} is finite (xO denotes the value of 0 at the variable 
x) . The notation {xI/xIO, . . .  , Xn/xnO} for f) is used in case Dom(f) 
= {Xl , " "  Xn}. 

58 
Chapter 3 
For a quantifier-free expression E, the expression EO is obtained from E replacing 
every variable by its B-image. Thus: 
Lemma 3.52 x E Var(EO) iff for some y E Var(E), we have that x E Var(yO) .  
• 
Definition 3. 53 By £ we denote the identity substitution (which has an empty domain) . 
If V is a set of variables, then 0IV : =  {x/O I x E V n Dom(O)} is the restriction of B to 
V .  
• 
Definition 3.54 If () and >' are substitutions, then the substitution 0)", the composition 
of 0 and >., is defined by: x(O>') = (xO)..\. 
• 
In this defining equation for 0..\, the right-hand side denotes the expression obtained from 
the term xO by replacing variables by their "\-image. 
Note that composition does not commute. E.g., {x/y}{y/z} == {x/z, y/z}, whereas 
{y/z}{x/y} = {x/y, y/z}. 
Lemma 3 . 5 5  If t is a term and 0, ..\ are substitutions, then (to)>' = t(O..\) . 
Proof. Induction with respect to t. 
For t a constant symbol: (to)>' = t = t(O..\). 
For t a variable, this is immediate from Definition 3.54. 
Finally, assume t = f(Sl, " " Sn), and (induction hypothesis) (slO)..\ = Sl (O..\), . . .  , (snO)..\ 
= sn(O..\). Then: (to)..\ = (f(Sl, " " sn)O)..\ = f(slO, . . .  , snO)..\ = f« slO»", . . . , (snO)..\) 
== f(Sl (O..\), . . .  , sn(O..\» 
== f(Sl , " " sn)(O..\) == t(O>'). 
• 
Remark. Substitutions 0 and (3 are considered to be equal iff Dom(o) == Dom«(3) and 
for every x E Dom(o): xo = x(3; equivalently, if they are equal as functions in the usual 
set-theoretic sense, that is, for every variable x: xo == x(3. 
• 
Lemma 3.56 If 0, ..\ and a are substitutions, then (0).)17 == 0(>.17) . 
Proof. x[(O..\) aJ == [x(O..\»)a == [(xO» .. )a = (xO) (..\a) = x[O(>.a)J. (The third equality uses 
3.55.) 
• 
As a consequence of this lemma, we can save on parentheses, indiscriminately writing 
(0..\)17 == 0(..\17) = 0"\17. 
Definition 3.57 0 is called a renaming for the term or atom E if 0 is injective on 
Var(E) and maps variables to variables. In that case, Eo is called a variant of E. 
• 
Example. f(x, gy) is a variant of fey, gx), but not of f(x, gx) . 
• 
The following lemma says that the relation variant of is symmetric: 
Lemma 3.58 If 0 is a renaming for E, then there exists a renaming (3 for Eo such that 
Eo(3 = E. 
• 

First-order Logic 
59 
Lemma 3.59 If Eo:(3 = E, then 0: is a renaming for E. 
Proof. Assume that Eo:(3 = E. If x E Var(E) and xo: is no variable, then xo:(3 can 
be no variable either. And if x, y E Var(E) are different but xo: = yo:, then we have 
u = v w x. 
• 
Lemma 3.60 For terms or atoms A and B, the following are equivalent: 
(i) A and B are instances of each other, 
(ii) A and B are variants of each other. 
Proof. (ii) => (i) This is clear. 
(i) => (ii) Assume B = AO, A = B)". Then A = B)" = AO)". Now, use Lemma 3.59. 
• 
Next, we introduce a crucial, at first sight perhaps obvious, but tricky notion. (See 
Exercise 3.28.) 
Definition 3.6 1 The substitution 0 is more general than the substitution ). if, for some 
a, we have that ). = Oa. 
I 
The notion of unification applies equally to expressions (terms or atoms), sequences of 
expressions and sets of expressions. 
Definition 3.62 The substitution 0 unifies or is a unifier of 
(i) the expressions A and B if AO = BO, 
(ii) the sequences of expressions (AI , . . .  , An) and (BI , . . .  , Bn) if, for 1 :::; i :::; n ,  0 
unifies Ai and Bi· 
(iii) the set of expressions K if KO := {LO I L E K} hð exactly one element. 
A unifier 0 for certain expressions (resp. sequences of expressions or a set of expressions) 
is called most general, or a most general unifier (mgu for short) if it is more general than 
every other unifier of these expressions (resp. ,  sequences or set) in the sense of Definition 
3.61. 
• 
Unification of sets of atoms is the relevant notion for resolution in first-order logic, 
but it can be defined (see Lemma 3.66) via the one for sequences of terms, which is dealt 
with now. Usually (in particular in the later chapters on logic programming), we need to 
unify atoms only. Note that atoms involving different relation symbols do not unify, and 
r(sl " ' "  sn )  and r(tl , " " tn) unify just in case the sequences of terms (Sl , . . . , sn) and 
(tl , ' "  , tn) do. Thus, atom unification is reduced to unification of sequences of terms as 
well. 
Theorem 3.63 (Unification) There is an algorithm that, when applied to a pair of 
sequences of terms, produces an mgu for those sequences in case a unifier exists, and 
ends with failure otherwise. 
In particular, if a unifier exists, then an mgu exists as well. 

60 
Chapter 3 
Proof. Suppose that we are given a pair of sequences of terms (Sl, . . .  , sn ) and (tl , . ' "  tn ) .  
As a first step, this pair is transformed into the set { S l   tb . . .  , S n   tn }  of identities 
(the use of the identity symbol '' here is only a suggestive notational convenience) .  In 
connection with such sets, we employ the following: 
Terminology. 
• Q unifies the set {Sl  tl , . . .  , Sn  tn } ,  of course, if it unifies the related sequences 
(Sl "
" , Sn) and (t l ,  . .  · , tn ) ,  
• sets of identities are called equivalent if they have the same unifiers, 
• a set {VI  UI , . . .  , Vm :::: um }  is called solved, in case 
(i) the Vi are pairwise different variables 
(ii) no Vi occurs in a term Uj (1 Ѹ i,j g m) . 
By (i) , a solved set V : =  {VI 
:::: Ul , . . .  , Vm :::: Urn } determines a substitution () 
. ­
{vI /UI , ' "  , vm/um} . 
Condition (ii) makes () unify V: Vi(} = Ui = Ui(}' 
Finally, note that () even is a mgu of V: if A is a substitution such that, for 1 g i g m, 
Vi A = UiA, then ViA = Ui A = Vi(}A, and of course, XA = X(}A for variables different from 
the Vi; hence: A = (}A. 
Claim: 
the Unification Algorithm described next either transforms a set of identities into a solved 
equivalent, or it terminates with failure if unification is impossible. 
The Unification Algorithm. 
Repeat the following procedure. Choose an identity from your set that allows one of the 
following 6 actions (if such a choice is impossible, the algorthm terminates). The action 
depends on the form of the identity. 
1. f(S I "
' "  sn ) :::: f(tl "
' "  tn) : 
replace this by the identities Sl :::: tl , . . .  , Sn :::: tn . 
(If f is a constant symbol, f :::: f is erased.) 
2. f(S l , , , , , Sn) :::: g(tl ,  . . .  , tm ) (f f g): 
terminate with failure. 
(f and/or g can be constant symbols here) 
3. x :::: x (x a variable) :  
erase the identity. 

First-order Logic 
4. t  x (t not a variable): 
replace the identity by x  t. 
5. x  t (t different from x, x occurring in t): 
terminate with failure. 
61 
6. x  t (t different from x, x does not occur in t and x occurs in at least one of the 
other identities): 
maintain this identity and apply the substitution {x/t} to the others. 
Proof of Claim: 
(i) Every action 1, 3, 4, 6 transforms a set into an equivalent one. For 1, 3 and 4 this is 
clear. 
For 6: note first that if xO = to, then 0 = {x/t}O. 
Now suppose that one action 6 transforms V : =  {x  t}UW into V' := {x  t}UW {x/t}. 
Then: 
o unifies V 
iff: xO = to and 0 unifies W 
iff: xO = to and {x/t}O unifies W (as xO = to implies that 0 = {x/t}O) 
iff: xO = to and 0 unifies W { x / t } 
iff: 0 unifies V'. 
(ii) The algorithm terminates. Otherwise, it produces an infinite sequence of sets. 
Then in particular, the algorithm does not terminate with failure, and situations de­
scribed under 2 and 5 of the algorithm never occur. 
For a given variable x, item 6 can be used only once (it eliminates x from every other 
identity, and 1, 4 and 6 cannot re-introduce x again). Thus, 6 is only applied finitely 
many times and, from a certain stage onwards, will not be applied any more. 
Finally, 1 and 4 decrease the number of function symbols on the left of  . Thus the num­
ber of their applications must be finite, as well. Hence, from a certain stage onwards, 
only action 3 is used, an impossibility. 
(iii) A successful termination clearly can happen only at a solved set. 
(iv) Since the algorithmic actions respect equivalence , a solved set that is the outcome 
of a successful termination has the same unifiers as the initial set; in particular, it has 
the same mgu's. Therefore, the mgu associated with the solved set also is an mgu of the 
initial one. 
(v) Termination with failure clearly happens only at a set for which a unifier does not 
exist; and then the initial set has no unifier either. 
• 
Mgu's obtained by the algorithm satisfy some additional properties. 

62 
Chapter 3 
Definition 3.64 An mgu B for (Sl, " " sn) and (tl , " " tn) is idempotent if BB = (), it is 
relevant if every variable in its domain occurs in some of the terms Si or ti (1 ::; i ::; n) 
and, for x E Dom(B) , every variable in x(} also occurs in some of these terms . 
I 
Lemma 3.65 Mgu 's obtained by the unification algorithm are both idempotent and rel­
evant. 
Proof. Idempotent : since mgu's are constructed from solved sets of identities (cf. condi­
tion (ii) of solved and Exercise 3.37) . Relevant: the algorithm clearly does not introduce 
new variables (also, d. Exercise 3.38). 
I 
Unification of sets of atoms can be reduced to unifying two sequences of terms by the 
following recipe. 
Lemma 3.66 A substitution unifies the set of atoms {r(tL .
. . , t;'), .
.
.
 , r(ti, .
. . , tK)} 
(k Ѷ 2) just in case it unifies the sequences (tl , . .
. , t;', .
.
.
 , t7-l, 
.
.
.
 , tD- l )  and (ti, .
.
.
 , t;" 
. . .  , tN , . . .  , t6) .  
I 
We end this section with an axiomatic characterisation of the notion of equivalence 
between sets of equalities, which is not needed for the rest of this chapter. 
For 0: a substitution, let Eo. := {x 7 xo: I x E Dom(o:)} be the associated set of 
identities. 
Lemma 3.67 Suppose that 0: and (j are substitutions. Then the following are equivalent: 
(i) (j unifies Eo. , 
(ii) (j = O:(j. 
Moreover, if 0: is idempotent, these conditions amount to 
(iii) for some , (j = 0:Ѭ . 
Proof. The equivalence of (i) and (ii) follows by inspection. That (ii) implies (iii) is 
trivial. Finally, if (j = o:ı and 0: is idempotent, then (j = o:Q = o:o: = O:(j. 
I 
The following definition introduces Clark's Equality Theory CET. It is closely related 
to the unification algorithm, as the following results will show. 
Definition 3.68 The formulas of the following three types are called the Free Equality 
Axioms; they determine Clark 's Equality Theory, for short : CET. 
(i) f(Xl ,  
.
.
.
 , xn)  f(Yl , .
.
.
 , Yn) --+ (Xl  Yl 1\ .
.
. 1\ Xn  Yn), 
(ii) f(xl , .
.
.
 , Xn)  g(Yl, .
.
.
 , Ym) (f, g different), 
(iii) x ѷ t (if the variable X is a proper subterm of t). 
I 

First-order Logic 
63 
Here, we conceive of individual constants as O-argument function symbols; therefore, (ii) 
includes formulas like c ¢ g(Yl ' . . .  , Ym) and c ¢ d (c and d different constant symbols). 
(iii) is usually called the occur check axiom. 
Its name will become clear after we've 
established the connection between CET and unification. 
For the case of one constant symbol and one unary function symbol, these axioms 
were spelled out previously in Exercise 3.7. One model of CET is the Herbrand algebra 
H A of closed terms (Definition 3.19); another is the canonical algebra T M of all terms. 
Note that a substitution is nothing but an assignment into this model, and a substitution 
unifies two terms s and t iff it satisfies the identity s Ľ t in T M. 
Lemma 3 .69 Suppose that the algebra I satisfies CET and that E is a set of identities 
satisfied by the I -assignment a. Then E has an (idempotent) mgu a such that a 
= aa. 
Proof. Feed E to the unification algorithm. By induction it is verified that, for every set 
F of identities the algorithm produces, we have that IpFa. In particular, the algorithm 
cannot terminate with failure, and we have IpElka, where a is the (idempotent) mgu 
eventually produced by the algorithm. Thus (compare Lemma 3.67), a = aa. 
• 
Lemma 3.70 Suppose that E is a (finite) set of identities and s and t are terms. The 
following are equivalent: 
(i) CETp /\ E-+s  t, 
(ii) s and t are unified by every unifier of E, 
(iii) s and t are unified by every mgu of E. 
Proof. 
(i) => (ii). Suppose that a unifies E, i.e., that a satisfies E in TM. By (i) , a satisfies 
s = t in TM, i.e.: it unifies s and t. 
(ii) => (iii). Trivial. 
(iii) => (i). Suppose that IpCET, and a satisfies E in I. By Lemma 3.69, there exists 
an (idempotent) mgu a of E such that (J = aa. By (iii) , sa = tao But then, s Ľ t 
trivially is satisfied by (J in I. 
• 
Recall that sets of equations E and F are called equivalent if they have the same 
unifiers. Given a set of equations, every operation from the unification algorithm (items 
1 ,  3, 4 and 6) produces an equivalent one. The following corollary enables us to more 
easily establish equivalences of sets of identities. 
Corollary 3.71 For sets of identities E and F, the following are equivalent: 
(i) CETp(/\ E- /\ F), 
(ii) E and F are equivalent, 
(iii) E and F have the same mgu 's. 
• 

64 
Exercises 
3.28 Is {x/y} more general than {x/c}? 
Hint. Compute {x/y}{y/c}. 
3.29 Prove Lemma 3.55 for the case that t is an arbitrary expression. 
3.30 Apply the unification algorithm to the following sets: 
(i) {p(x, y), p(y, fz)} (i.e., try to unify the sequences (x, y) and (y, fz)) , 
(li) {p(c, y, fy), p(z, z, u)}, 
(iii) {p(x, gx) , p(y, y)}, 
(iv) {p(x, gx, y), p(z, u, gu)}, 
(v) {p(gx, y), p(y, y), p(u, fw)} (use the recipe from Lemma 3.66), 
(vi) {p(x, fy, z), p(gw, u, gw), p(v, v, gw)}. 
Chapter 3 
3.31 You may have derived 0 in Exercise 3.26(i) in two steps. Can it be done in one? 
Definition 3.72 An expression C is a common instance (c.i.) of A and B if for some 
substitutions a and /3, C = Aa = B(3. It is a most general common instance (m.g.c.i.) 
if it is a c.i. of which every other c.i. is an instance. 
• 
3.32 Suppose that the expressions A and B have a c.i. Aa = B(3. Show that they have 
an m.g.c.i. as well. (A proof can be extracted from the next section.) 
Is there always an m.g.c.i. C such that Var(C) C Var(A) U Var(B)? 
Hint. Consider A = f(f(x, y), z) and B = f(x, fey, z) . 
3.33 The solution of Exercise 3.32 transforms the mgu-producing unification algorithm 
into one that produces m.g.c.i.'s. Show how to transform any m.g.c.i.-producing algo­
rithm into one that produces mgu's. 
Hint. Instead of unifying s and t, find an m.g.c.i. of f(x, x) and f(s, t). 
3.34 Let a be an idempotent mgu of the set of identities E. Show: 
(i) Eo: "" E, 
(ii) E U F 
"" E U Fa. 
3.35 Suppose that E and F are sets of equations, and a and /3 are substitutions such 
that a is an mgu of E and /3 is an mgu of Fa. Show that a(3 is an mgu of E U F. 
3.36 Suppose that Var(a) n Dom(fJ) = 0. Show that a/3 = a U  (3. 
3.37 Show: e is idempotent (Le., ee = e) iff Dom(e) n Ran(e) = 0. 
* 3.38 Show: every idempotent is relevant. (This sounds remarkable; relevance refers 
to the expressions to be unified, while idem potency does not. But note for instance that 
{x/u, y/v} is a - both idempotent and relevant - mgu of f(x, y) and feu, v) but not of 
g(x) and g(u): {x/u} is a unifier and there is no a such that {x/u} = {x/u, y/v}a.) 

First-order Logic 
65 
3.9 
Resolution 
If we seek to establish unsatisfiability of a (finite) set of clauses involving variables using 
propositional resolution, and at least one function symbol is present, then the problem 
arises which ground instances of the clauses should be tried. And if we use unrestricted 
resolution, there is the problem of which substitutions to apply to clauses. Resolution 
completely eliminates this problem (at least, up to renaming: Corollary 3.75). 
Definition 3.73 An element in a set K of expressions is called most general if it has 
every element of K as an instance. 
• 
By Lemma 3.60, most general elements (if they exist) are unique, up to renaming. 
Definition 3.74 A clause is a resolvent of clauses C and D with respect to the sub clauses 
P C C and N e D, if it is most general in the class of all unrestricted resolvents of C 
and D with respect to P and N. 
• 
Corollary 3.75 Up to renaming, a resolvent of clauses with respect to given subclauses 
is unique. 
• 
Example. Suppose that C is {r(x}, q(x, yH and D is {.r(sx}, q(x, y)}. An unrestricted 
resolvent of these clauses (w.r.t. {r(x)} and {.r(sx)}) is {q(sx, y), q(x, y)} (take the 
{x/sx}-instance of C); however, this is not a resolvent. An example of a resolvent is 
{q(sx, y), q(x, z)} (take the {x/sx}-instance of C and the {y/z}-instance of D). 
• 
The main fact on resolution is contained in the following lemma. 
Lemma 3.76 If two clauses have an unrestricted resolvent with respect to certain sub­
clauses, then they also have a resolvent with respect to these subclauses . 
P u K  
I 
I 
j 
Pa U Ka 
• N U M 
 
K{) U Mf,() 
.N{3 U M{3 
 Ka U M{3 

66 
Chapter 3 
Proof. We need Theorem 3.63 on most general unification. Assume that C = P U K, 
D = -,N U M (N a set of atoms; ..,N : =  {-,A I A E N}), that Po: = N{3 is a singleton 
and K 0: U M (3 is the unrestricted resolvent of C and D with respect to P and -,N. 
First, separate variables. That is, choose a renaming Q for D such that C and DѮ have 
no variables in common. 
Claim: P U NQ is unifiable. 
Proof: Choose a substitution that undoes the effect ि has on D, i.e., such that DѮ6 = 
D; cf. Lemma 3.58. Now, let 'Y := o:lVar(C) U (6{3)lVar(DR). (Note that Var(C) n 
Var(DQ) = 0 by choice of 0 We have P'Y = Po: = N{3 = N!,6{3 = NQ'Y is a singleton, 
i.e, 'Y unifies P U NQ. 
By Theorem 3.63, P U Nı has an mgu B. Since PO = NQO is a singleton, KB U MQB 
also is an unrestricted resolvent of C and D with respect to P and -,N. 
Claim: in fact, this is a resolvent of C and D. 
For instance (comparing with the unrestricted resolvent K o:U M {3}, since B most generally 
unifies P an Nी, there exists some a such that Oa = 'Y; hence, (KO U MѫO)a = K'Y U 
M!,'Y = Ko: U M{3. 
Obviously, the same argument works for every other unrestricted resolvent with respect 
to P and -,N. 
• 
Recipe. The previous proof contains the following recipe for finding a resolvent (if there 
is one) of two clauses P U K and -,N U M with respect to the subclauses P and -,N. First, 
apply a renaming !, to one of the clauses - say, -,N U M - such that the transformed 
clause (-,N U M)!, has no variables in common with the other one, P U K. Next, find 
an mgu B for P U Nt, (for this, you can use the unification algorithm). The resolvent is 
(K U MQ}O. 
• 
Definition 3.77 Define the derivability relation r- like r-u (see Definition 3.46), but this 
time using resolvents instead of unrestricted resolvents. 
A refutation is a derivation of D .  
• 
Of course, we have the following Soundness Theorem. 
Theorem 3.78 (Soundness) If Ѵ r- E, then I=E. 
Proof. Immediate from Theorem 3.49, since ѵ r- E implies ѳ r-u E. 
• 
The main property of resolution is given by the following Lifting Theorem, which 
simply iterates Lemma 3.76. 
Theorem 3. 79 (Lifting) If 1: r-u C I then C is an instance of a clause D such that 
n r- D. 

First-order Logic 
67 
Proof. Strong induction on the height of the unrestricted derivation, using the basic 
existence result, Lemma 3.76. 
Assume that T is an unrestricted derivation of C from E. We show that C is an instance 
of a clause that has a derivation T' from E. 
(i) T has height l. 
Take 7' = 7 and D = C. 
(ii) C is an unrestricted resolvent of its children C1 and C2 in T. 
The subtrees of 7 that derive C1 and C2 have heights less than T. By induction hy­
pothesis, there exist clauses Dl and D2 that are derivable from E and of which C1 and 
C2 are instances. Obviously, C is an unrestricted resolvent of Dl and D2 . By 3.76, Dl 
and D2 have a resolvent D that is derivable from E. By maximality of resolvents, C is 
an instance of D. 
• 
The following theorem expresses refutational completeness of the resolution method. 
Theorem 3.80 (Completeness) If E is an unsatisfiable set of clauses, then E is re­
futable: E I- o .  
Proof. Suppose that E is unsatisfiable. Then by Theorem 3.51: E I-u O .  By the Lifting 
Theorem 3.79, 0 is instance of a clause D such that E I- D. However, 0 can be an 
instance of 0 only, hence D = 0 ,  and the result follows. 
• 
Corollary 3.81 E is an unsatisfiable set of clauses iff E I- o .  
Proof. Immediate from Theorems 3.80 and 3.78. 
Discussion. 
• 
Suppose that Vcp is an unsatisfiable universal sentence with matrix cp in conjunctive 
normal form. Let S be the finite set of clauses corresponding to the conjuncts from cpo 
By Theorem 3.80, S I- O .  The virtues of resolution (compared with resolution applied 
to ground clauses) are that its derivations may be shorter and that it solves the problem 
of which elements of the possibly infinite set ground(S) are actually needed to derive 
O. Resolution finds these elements (and the ground terms involved) automatically. In 
the case that the finite S is unsatisfiable, we can find a derivation of 0 in the following 
mechanical way (compare Exercise 2.25): 
Define 'R.(T) : =  T U {C I C is resolvent of two clauses in T} . Note that, if T is finite, 
then so is 'R.(T) . Construct 1(.°(8), 1(.1 (S), 1(.2 (S), . . .  by: 1(.°(S) = 8, and 1(.n+l(8} ::; 
'R.('R.n(s» . These sets are all finite, can be constructed effectively, and for some n we 
must get 0 E 'R.n(S), obtaining our derivation. 
However, contrasting to the case for propositional logic, the process may not stabilize, 
the sets 'R.n (s) may grow indefinitely, and we cannot tell beforehand how large an n 

68 
Chapter 3 
we must look for. Accordingly, the method gives positive decidability of unsatisfiability 
only, in agreement with Church's Theorem 7. 19. 
Example. 'R°(S) 
= S = {{-,r(x), r(fx)}}. 'R1 (S) = S U {{-,r(x), r(ffx)}}, 'R2(S) = 
'R1 (S) U {{-,r{x), r(fffx)}}, etc. In this particular example, of course, we immediately 
see that 0 is never encountered. But there are more complicated cases. 
• 
Exercises 
3.39 Determine whether 0 is derivable from the following sets of clauses. If so, give a 
derivation. If not, why? 
(i) {{r(x, x)}, {-.r(x, fx)}, {r(x, fx), -,r(fx, y)} ,  {r(x, y), -,r(x, z), -,r(y, z)}}, 
(iD {{r(x, x)}, {-,r(x, fx)}, {r(x, fx), -.r(fx, y)}, {-,r(x, y), rex, z), r(y, z)}}. 
3 .40 Show: E is a resolvent of C U {A} and D U {-,B} with respect to {A} and {-,B} iff 
for some substitutions a and f3: Dom(a) C Var(C, A), Dom(f3) C Var(D, B), Aa = Bf3 
is a most general common instance of A and B, E = Ca u Df3, and aI [Var(C) - Var(A)] 
and f3\[Var(D) - Var(B)] injectively map variables to variables such that {xa I x E 
Var(C) - Var(A)} and {xf3 1  x E Var(D) - Var(B)} are disjoint. 
3.10 
Notes 
The material in Subsection 3.6.3 on elementary extensions and chains forms the first few 
steps into first-order model theory. The "bible" for this subject is [Chang/Keisler 90]. A 
more recent reference is [Hodges 93]. 
Our Definition 3.23 of substitution has several alternatives in the literature. Also, 
there are many different notations for substitution. In the literature, one may also 
encounter the notations it/x}, [x/t] and [t/x] for the substitution we have denoted 
by {x/t}, and both prefix (aE) and postfix notation (Ea) are employed. The postfix 
notation we are using is slightly unfortunate (after all, a substitution is a function, and 
function application generally is denoted by prefixing), but quite common in the logic 
programming literature. 
Corollary 3.35 also is a consequence of the Completeness Theorem of Godel (1930). 
The methods used in the proof of Godel's Incompleteness Theorem (1931) are essential for 
proving Church's Theorem 7.19, which says that Corollary 3.35 cannot be strengthened 
to decidability of first-order validity and unsatisfiability. 
Exercise 3.27 is due to Daniel Mey. 
The term unrestricted resolution is unfortunate since it seems to refer to a special type 
of resolution, whereas, on the contrary, resolution is a special type of the unrestricted 

First-order Logic 
69 
version. However, in the context of linear resolution (Chapter 5) the term is generally 
accepted. 
Theorem 3.63 is from [Robinson 65]. Since unification is the main computational 
component of resolution, it is desirable to have a fast unification algorithm. The one 
described by Robinson is not fast (it uses exponential time). Fast algorithms are due 
to [Martelli/Montanari 82] and [Paterson-Wegman 78] . 
The unification algorithm as 
presented here is due, at least in principle, to Herbrand (cf. [Herbrand 30], p. 124 in the 
French volume, p. 148 in the translated one) but was first explicitly described and proved 
adequate in [Martelli/Montanari 82] . The condition, in the last part of the algorithm 
(selected identity x  t), that the variable x should not occur in the term t, is called 
the occur check condition. Remarkably, even though unification can be accomplished in 
linear time, this check usually is omitted in Prolog implementations for efficiency reasons. 
The effect of this omission has been studied, among others, by [Apt/Pellegrini 92]. The 
surprising outcome is that this usually does not lead to mistakes (although it affects 
soundness in principle). The problem whether the algorithm can lead to failure due to 
occur check for a given set of identities was recently shown to be NP-complete by van 
Emde Boas and Welling. For much more on unification, cf. [Lassez/Maher/Marriott 88]. 
Clark's equality axioms are from [Clark 78J. 
The traditional definition of resolution is rather ad-hoc. Here, the lifting property is 
used as the defining one. As a result, the proof of completeness becomes quite straight­
forward. 

 4 Program-definability 
4.1 
Programs 
The previous chapter introduced Herbrand models for universal sentences. The present 
one is devoted to Herbrand models for universal sentences of a special type: rules, and 
(finite) sets of those: programs. 
Before describing and motivating the contents of this chapter, these notions are defined 
and some examples are given. 
Definition 4.1 A rule is a disjunction of literals containing exactly one positive literal 
called the head of the rule. The rest - the negative part - is called the body of the 
rule. 
• 
A rule with head A and negative literals ..,BI, ... , ..,Bm will be written thus: 
A-BI,···, Bm· 
In first-order notation, this would be the implication (or its universal closure, cf. Remark 
3.26) 
BI/\ . . .  /\ Bm-A; 
thus, ' .... ' is just a reversed implication symbol, and the commas stand for conjunctions. 
If C is the sequence C = (B1, . . .  , Bm), then the rule displayed can be written as 
A-C. 
A rule is allowed to have an empty body. It then has the form 
A- .  
The first-order notation of this is the atom A itself. Rules with empty body often are 
called facts or unit clauses. 
Definition 4.2 A program is a finite set of rules. 
• 
Example 4.3 The following two rules make up the program SUM (sum is a 3-ary 
relation symbol) : 
sum(x, 0, x) +-
sum(x, sy, sz) - sum(x, y, z). 
Recall Definition 3.19 and the conventions of Notation 3.20 about representing IN (with 
zero and successor function) as a Herbrand algebra generated from one constant symbol 
o (for zero) and one unary function symbol s (for successor) . 
Consider the Herbrand model over HU = IN with the relation sum:= {(n,m,n+m) I 
n, m E IN}. This is a model of SUM. For, in the context of this model, the first rule 
expresses that n + 0 
= n for every number n E IN; the second one expresses that if 

72 
Chapter 4 
n + m = k, then n + Sm = Ski i.e., that n + Sm = S(n + m). 
(Note that the two equations n + 0 = nand n + Sm = S(n + m) enable us to evaluate 
every sum of natural numbers using the notation with 0 and S. E.g., 1 + 2 = SO + SSO = 
S(SO + SO) = SS(SO + 0) = SSSO = 3.) 
I 
Example 4.4 The following four rules involve a binary function symbol that is written 
as [ .1 . J and two relation symbols last and reverse (modifying slightly Exercise 4.59): 
last([xl[YlzJJ, [xly], z)  
last([zluJ, [zlv], y) 1 last(u, v, y) 
reverse([xIY]' [ylx)) 1 
reverse(u, [ylw)) Ł last(u, v, y), reverse(v, w). 
Let HU be generated from 0, s and [ . I . J. A finite sequence (tl, ... , tn) from HU of 
length n ? 2 is identified with the ground term [tll[t2I!t31··· tn]]]. A Herbrand model in 
which these rules are true is obtained by interpreting last as the relation that holds of 
s, t = (t1,"" tn) and u iff s = (tl"'" tn, u) and reverse as the relation that holds of s 
and t iff they are the reverse of each other. 
• 
The examples given explain programs by providing a meaning for them, in the form 
of a (Herbrand) model. This is a so-called declarative interpretation of programs. It 
is the subject of the present chapter to describe a special type of Herbrand model for 
programs. However, programs also have a computational, or procedural, content. Again, 
look at the previous examples. The second sum-rule may be interpreted as: in order 
to add m + 1 to n, first add m, and next take the successor of the result. The second 
reverse-rule may be interpreted as: to reverse a sequence u, split it up into last element 
y and its remains w; now obtain v by reversing wand putting Y in front of the result. 
This clearly provides an algorithmic approach to reversing sequences. 
Remarkably, it has turned out that even complicated algorithmic processes can be 
described by the simple type of first-order sentences that rules represent. This discovery 
is the main raison d'etre for Prolog. 
The procedural interpretation of programs by means of linear resolution and its relation 
to the declarative aspect is the subject of Chapter 5. For positive programs, as introduced 
here, the theory is quite unproblematic and well-established. Problems come up as soon 
as we admit negations, which is the subject of Chapter 8, with a mild introduction in 
Chapter 6. 
The hurried reader can switch to linear resolution in Chapter 5 before finishing the 
present one. A first place from where such a switch can sensibly be made is after Corollary 
4.8; a much better one is after Theorem 4.26. Section 4.6 serves as a source of examples 
that will be used in later chapters as well. 

Program-definability 
4.2 
The Least Herbrand Model 
73 
By Theorem 3.29, a satisfiable set of universal sentences always has a Herbrand model. 
Since rules represent universal sentences of a special type (once again recall Remark 
3.26; we confuse here a rule with the universal closure of the implication it represents), 
it turns out that programs have Herbrand models with a special character. This section 
looks further into the matter. However, before doing so, it is convenient to introduce a 
somewhat different way of viewing Herbrand models, namely as subsets of the Herbrand 
base. 
Definition 4.5 The Herbrand base, with respect to a given language, is the set of all 
ground atoms. The notation for the Herbrand base is H B. 
• 
Let M be a Herbrand model. M can be recovered from the subset X := {A E H B I 
MFA} of HE of ground atoms true in M. For, if r is any n-ary relation symbol, then 
its interpretation in Mover HU must be the relation r given by 
r(tl, ... , tn) {:} r(tl,.··, tn) E X. 
Proof: By Lemma 3.17, tt"l = ti (1 :5 i :5 n) j thus: 
r(tb . . " tn) 
<=> 
r(t, . . . , t) 
{:} 
MFr(tl,'" ,tn) 
<=> 
r(tl, . . . ,tn) E X 
(by Definition 3.9 of F) 
(by definition of X). 
Consequently, a Herbrand model henceforth will be identified with the associated set of 
ground atoms true in it. Conceived of this way, Herbrand models are subsets of H B. 
The identification is succinctly put in the form of a lemma. 
Lemma 4.6 If A E H Band M is a Herbrand model, then the following are equivalent: 
(i) MFA, 
(ii) A E M. 
• 
As subsets of the Herbrand base, Herbrand models are partially ordered by set in­
clusion. Programs have the remarkable property that they have least Herbrand models. 
Obviously, every logical consequence A E H B of a program must belong to this least 
model. And it is precisely these atoms that form the least Herbrand model of the pro-
gram. 
Definition 4.7 Let P be a program. Mp:= {A E HB I PpA}. 
• 

74 
Chapter 4 
Recall that (Definition 3.28) for P a set of universal sentences and/or quantifier-free 
formulas, ground(P) is the set of ground instances of the sentences or formulas in P 
By Lemma 3.30, for such a set P and a Herbrand model M, that Mf=P amounts to 
Mf=ground(P}. 
The next theorem states that, indeed, (i) Mp is a (Herbrand) model of P, and (ii) it 
is the least Herbrand model of P-
Theorem 4.8 
(i) Mpf=P, 
(ii) if Me H B is such that Mf=P, then Mp C M. 
Proof. (ii) Trivial: if Mf=P and A E Mp, then Pf=A and hence Mf=A. 
(i) By Lemma 3.30, it suffices to establish that Mpf=ground(P). Thus, consider a ground 
instance of a P-rule A-Bo, ... , Bn-I such that Mpf=Bj (i < n) . That is, Pf=Bi (i < n) . 
Note that by Corollary 3.27, Pf=(Bo 1\ ... 1\ Bn-I-A). Therefore, Pf=A; i.e.: Mpf=A. 
• 
We finish this subsection by presenting a characterization of Mp in terms of implication 
trees that will be useful later on. 
Definition 4.9 An implication tree for an atom B with respect to a program P is a 
finite tree T of atoms with root B such that for all A E T, there is an instance A-C of 
a P-rule such that the children of A in T are exactly the atoms from C. 
An implication tree is ground if all its nodes are. 
• 
An implication tree for A can be looked at as an extremely simple type of proof of A: 
see the following lemma; also, see Exercise 6.4. 
Lemma 4.10 For a program P and a ground atom A the following are equivalent: 
(i) A E Mp, 
(ii) there is a ground implication tree for A. 
Proof. (ii) =:::> (i) Strong induction with respect to the height of the implication tree T 
for A. Thus, suppose that A <-C is ground instance of a P-rule and the children of A in 
T are the atoms of C. Then every atom of C has a ground implication tree that can be 
found as a subtree of T. The heights of these subtrees are less than the one of T. By 
induction hypothesis, the atoms of C are (true) in Mp. It follows that A E Mp. 
(i) =:::> (ii) Let M be the Herbrand model consisting of those A E H B that have a ground 
implication tree. It suffices to show that M is a model of P since then, by Theorem 
4.8(ii), Mp eM, and the implication follows. By Lemma 3.30, for Mf=P it suffices to 
show that Mf=ground(P). Thus, let A-C be a ground instance of a P-rule such that 
Mf= !\ C. By definition of M, every atom of C has a ground implication tree. Then, 
however, a ground implication tree for A can be formed from those trees, adding A as a 
new root. 
• 

Program-definability 
75 
Exercises 
4.1 Show: the empty Herbrand model 0 C H B is a model of the program P iff every 
rule in P has a non-empty body, that is, P does not contain a fact. 
Show: the largest Herbrand model H B is a model of every program . 
4.2 Show that if X and Yare Herbrand models of the program P, then so is X n Y. 
What about X U Y? Give a proof that it is, or a simple counter-example showing that 
it need not be one. 
4.3 Give a Herbrand model for the program SUM (cf. Example 4.3) that is different 
from both HB and {sum(n,m, n+m) I n,m E IN}. 
4.4 Let C be a finite set of atomic formulas (variables allowed). Show: P 1= :J A C iff 
Mp 1= :JAC. 
4.5 c = {o, s, N}. P consists of the following two rules. 
N(o)<­
N(sx)<-N(x). 
The universal sentence VxN(x) is true in Mp (why?). Show: it does not logically follow 
from P. 
(For an even simpler example, put C = {o, N} and P = {N (0) <-}.) 
4.6 Let P be a program and A and B ground atoms. Show: if P 1= A V B, then P 1= A 
or P 1= B. Give an example of a set P of universal sentences for which this implication 
fails. 
4.7 Let P be a program and A C a conjunction of atoms. Show: if P 1= 3 A C, then 
some ground instance of A C logically follows from P. Give an example of a set P of 
universal sentences for which this fails. 
The following (trivial) remark can often be fruitfully applied whenever we have a 
concrete Herbrand model M e  H B for which we want to verify that M = Mp. It says 
that we only have to prove two things: (i) that M is a model of P, and (ii) that every 
atom in M follows logically from P-
Remark 4.11 Let P be a program, H B the corresponding Herbrand base and M C H B. 
(i) if M is a model of P (i.e.: MI=P), then Mp eM; 
(ii) if every atom in M follows logically from P (i.e.: PI=M), then M e  Mp. 
I 
In concrete cases, (i) usually follows by mere inspection, but (ii) may require an induction. 
4.8 Prove Remark 4.11. Which of the implications can be strengthened to an equiva­
lence? Which one cannot? Why? Give an argument or a counter-example. 

76 
4.9 P consists of the following two rules: 
reo, y)+-
r(sx, sy )+-r(x, y). 
Identify M p. 
Chapter 4 
Hint. Try {r(n,m)ln::; m}. Use Remark 4.11. To prove that n::; m => PFr(n,m), 
induct with respect to n. 
4.10 Again, suppose that HU = IN. 
Construct a simple program that has M := 
{r(n, m) In > m} as its least Herbrand model. Give a proof of this using Remark 
4.11. 
4.3 
Fixed Points 
This section puts the simple results of the previous section in the general perspective of 
inductive definability, using consequence operators. 
In the following definition, as in the sequel, we employ the following shorthand. If C 
is a sequence from H B and X c H B a Herbrand model, then by C c X we mean that 
every atom occurring in C belongs to X; equivalently, that /\ C is true in X. 
The powerset 'P(K) := {X I Xc K} is the collection of all subsets of the class K. 
Thus, the powerset 'P(H B) is the collection of all Herbrand models. 
Definition 4.12 Let P be a program. The immediate consequence operator of P is the 
function Tp : 'P(H B)-+'P(H B), which maps Herbrand models to Herbrand models and 
is defined by Tp(X):= {AEHB I for some C C X: (A+-C) E ground(P)}. 
• 
Example 4.13 Consider the program EVEN, made up of the following rules. 
even(o) +-
even( ssx) +- even( x) . 
Note that MEVEN = {even(2n) In E IN}. Let T = TEVEN be the associated immediate 
consequence operator. We have: 
T(0) = {even(o)}, 
T(T(0» = {even(o) , even(sso)} , etc.; 
T(HB) = T(0) u {even(n) I n u 2}, 
T(T(HB» = T(T(0» u {even(n) I n u 4}, etc. 
Now, consider the program SUM of Example 4.3. Let T = TSUM be its immediate 
consequence operator. We have: 
T(0) = {sum(n,O,n) In E IN}, 
T(T(0» = {sum(n, m, n + m) 1m::; 1/\ n E IN}, 
T(T(T(0») = {sum(n, m, n + m) 1m::; 2/\ n E IN}. etc.; 
T(HB) = T(0) u {sum(n,m,p) I n,m,p E IN,m,p - I}, 

Program-definability 
77 
T(T(H B» = T(T(0» U U{sum(n, m,p) In, m,p E IN, m,p ɜ 2} , etc. 
I 
For the following couple of definitions, the reader may think of the set U as the 
Herbrand base and the function T as an immediate consequence operator over it, but 
this is not necessary. 
The primary interest concerns inductive pre-fixed points. 
Since co-inductive post­
fixed points may appear somewhat mysterious and are not needed for much that is 
in this chapter and the next one, the reader may skip material referring to them and 
concentrate on parts (i), (ii) and (iv) of the following. 
Definition 4.14 Let T: P(U)-P(U) be an operator mapping subsets of U to subsets 
of U. A set Xc U is called 
(i) pre-fixed point of T, or T-closed, if T(X) eX, 
(ii) fixed point of T if T(X) = X, 
(iii) post-fixed point of T, or T-supported, if Xc T(X), 
(iv) T -inductive if it is included in every pre-fixed point of T, 
(v) T -co-inductive if it contains every post-fixed point of T. 
• 
Remark. The terminology of T-inductivity is justified as follows. Let U := IN and 
T(X) := {O} U {n + 1 In E X}. IN is the only pre-fixed point of T, and it is T-inductive 
as well. Now X is a pre-fixed point of Tiff 0 E X 1\ 'In E X(n + 1 E X). Thus, inductivity 
of IN here coincides with Principle 1.1 of mathematical induction. 
• 
Example 4.15 U = IN, T(X) := {O} U {n + 21 n E X}. This operator is closely related 
to the immediate consequence operator TEV EN of the program EVEN in Example 4.13.1. 
For Xc HB, put X' := {n 1 even(n) E X}. Then (TEVEN(X»' = T(X'). 
(i) Pre-fixed points: {2n 1 n E IN} and all sets of the form {2n 1 n E IN} U {2n + 1 1 
n - m}. In particular (m = 0) IN is a pre-fixed point. 
(ii) The only fixed point is {2n In E IN}. 
(iii) Post-fixed points: IN, and all sets {2n 1 n Z m}. 
I 
Our interest in pre-fixed points is explained by the following lemma. 
Lemma 4.16 Let P be a program. For a Herbrand model M, the following conditions 
are equivalent: 
(i) M is a pre-fixed point ofTp, 
(ii) M F= P. 

78 
Chapter 4 
Proof. (i)::>(ii): Assume that (i) holds. Instead of MI=P, we show that Ml=ground(P), 
using Lemma 3.30. Thus, suppose that (A+-C) E ground(P). If C c M, then A E 
Tp(M); therefore, by (i), A E M; and hence A+-C is true in M. 
(ii)::>(i): Conversely, assume that M satisfies P. Let A be an atom in Tp(M). Then 
for some ground instance A+-C of a rule in P, we have C C M. Then by (ii) A E M, 
proving (i). 
• 
Example 4.17 From the facts given by Example 4.15 it follows that , one excepted, the 
Herbrand models of EVEN from Example 4.13 are of the form {even(2n) I n E IN} U 
{even(2n+l) I n - m}. The exception is the least Herbrand model {even(2n) I n E IN} . 
• 
That programs have least Herbrand models can also be seen as a consequence of their 
operators being monotone . 
Definition 4.18 T: P(U) --t P(U) is monotone if for all X, Y c U: if Xc Y, then 
T(X) C T(Y). 
• 
Lemma 4.19 Immediate consequence operators are monotone. 
• 
Lemma 4.20 An operator has at most one inductive pre-fixed point and one co-inductive 
post-fixed point. The inductive pre-fixed point and the co-inductive post-fixed point of a 
monotone operator are fixed points. 
Proof. Suppose that X and Y both are inductive pre-fixed points. Since X is a pre-fixed 
point and Y is inductive, we have that Y C X. By symmetry, X C Y. The argument for 
co-inductive post-fixed points is similar. Now suppose that X is an inductive pre-fixed 
point of T. That is, T(X) eX. By monotonicity, T(T(X» c T(X). Thus , T(X) is a 
pre-fixed point. By inductivity of X, X c  T(X). Therefore, X is a fixed point. 
• 
The lemma shows that inductive pre-fixed points are the same as inductive fixed points; 
similarly, co-inductive post-fixed points and co-inductive fixed points are the same. Since 
the inductive fixed point (if it exists) is contained in every (pre-) fixed point, it also is 
the least fixed point. Similarly, the co-inductive fixed point is the greatest one. 
The following, completely general, result shows that these objects indeed exist (but of 
course, they may coincide). 
Theorem 4.21 (on Fixed Points) Every monotone operator has an inductive and a 
co-inductive fixed point. 
Proof. Suppose that T: P(U) --t P(U) is monotone. For the inductive fixed point, 
let K := {X cUI T(X) c X} be the collection of all pre-fixed points of T and let 

Program-definability 
79 
M := n K = nXEK X be their intersection. Note that, since U E K, we have K =I- 0; 
therefore, M is well-defined. 
We show that M is a pre-fixed point of T. 
Let X be an arbitrary pre-fixed point. 
Then Me X. 
Hence, by monotonicity, 
T(M} c T(X}; therefore, since T(X) C X, we have T(M) C X. Thus, T(M) is included 
in every pre-fixed point. Therefore, T(M} is included in the intersection M of all pre­
fixed points; that is, M is a pre-fixed point itself. 
From the definition of M, inductivity is immediate. 
For co-inductive fixed points, see Exercise 4.11. 
I 
So, the existence of least Herbrand models once again follows from Lemma 4.19 and 
Theorem 4.21. 
By the way, note that every program trivially has a greatest Herbrand model as well 
(not to be confused with the co-inductive fixed point of its operator), the Herbrand base 
H B itself (Exercise 4.1). 
Notation 4.22 The least fixed point of a monotone operator T : P(U) 
-+ P(U) is 
denoted by Ti; the greatest one by T 1. 
Thus for the immediate consequence operator of P, T = T p, we have that M p = T pi .• 
Readers who have never encountered least fixed points and who find the various def­
initions of Mp rather too abstract may feel uneasy. They may be somewhat comforted 
by Theorem 4.26. 
Remark. Examples of least fixed points occurring before are the sets of formulas and 
terms in propositional and first-order logic. Here, U is the set of all finite sequences of 
symbols. Try to identify the monotone operators involved. For yet another example, see 
Exercise 4.15. In Chapter 8, two more examples of inductively defined sets occur. See 
Definitions 8.12 and 8.47. The formulation there is quite close to the ones for formulas 
and terms. 
• 
Exercises 
4.11 Complete the proof of Theorem 4.21 for co-inductive fixed points. 
Hint. The co-inductive fixed point is the union of all post-fixed points. 
* 4.12 If S is a set of pairwise disjoint trees and u is not a node of a tree in S, then 
T = {u} + L S is the tree the nodes of which are u and those of the trees of S, with 
root u, such that the children of u are the roots of the trees in S and the children of a 
node in a tree T E S are the same as the children of this node in T. 
Let T be the class of all trees. Define r: PT)-+P(T) by r(X) := {{u} + LSI SeX 
is a set of pairwise disjoint trees and u is not in a tree of S}. 

80 
Chapter 4 
Show: the elements of Ii are exactly the well-founded trees . 
4.4 
Hierarchies 
Immediate consequence operators enjoy the property of being finitary, which is respon­
sible for the fact that their least fixed points can be finitely approximated . 
Definition 4.23 An operator T : P(U)--+P(U) is called finitary if, for all Xc U and 
A E U such that A E T(X), there exists a finite Y C X for which A E T(Y). 
• 
Lemma 4.24 Immediate consequence operators are finitary. 
Proof. Bodies of rules consist of finitely many atoms only. 
• 
Finite approximation of the least fixed point is established by the upward fixed point 
hierarchy. 
Definition 4.25 Let T : P(U) --+ P(U) be a monotone operator. The (finite) stages of 
the upward hierarchy of T are the sets Tin (n E :IN) recursively defined by 
TiO 
= 0, 
Tl(n+ 1) 
= 
T(Tjn). 
Finally, Tiw := UnEIN Tin. 
I 
The next result says that the upward fixed point hierarchy corresponding to a monotone 
operator consists of an increasing sequence of sets inside the least fixed point; moreover, 
the least fixed point actually is given by the union of the hierarchy. 
Theorem 4.26 Let T : P(U) --+ P(U) be monotone. Then: 
(i) for all nEIN: Tin C Tj(n + 1), 
(ii) for all nEIN: Tin C Ti, 
(iii) Tiw c Tl, 
(iv) ifT is finitary, then Tj = Tiw. 
Proof. (i) Induction with respect to n. 
Basis. Trivially, TiO = 0 c Ti 1. 
Induction step. 
If Tin C Ti (n + 1) (induction hypothesis) , then, by monotonicity, 
Tj(n + 1) = T(Tin) C T(Tj(n + 1» 
= Tj(n + 2). 
(ii) Again, induction with respect to n. 
Basis. TiO = 0 c Ti. 
Induction step. If Tin C T i (induction hypothesis), then, by monotonicity and the fact 
that Ti is a fixed point of T, we have Ti (n + 1) = T(Tin) C T(Tj) = Tj. 

Program-definability 
81 
(iii) This is immediate from (ii). 
(iv) By (iii), it suffices to show that Tj c Tjw. By inductivity, Tj C Tjw follows 
from the inclusion T(Tjw) C Tjw. For this, we use that T is finitary. Assume that 
A E T(TTw). Then we have A E T(Y) for some finite subset Y of Tjw. 
Since 
T T w = Un T Tn, every B E Y  is element of some T j n. Let m be the maximum of these 
finitely many n. By part (i), Y c Tim. Hence, by monotonicity, A E T(Y) C T(TTm) = 
TT(m + 1) C TTw. 
• 
Exercises 
4.13 Let P be the program of Exercise 4.9. Compute Tp j 0, Tp T 1 and Tp T 2. Describe 
T p T n generally. 
4.14 Show: A E Tp Tn iff A has a ground implication tree with respect to P of height 
Z n. 
4.15 Let R be a binary relation on X. Define r : P(X2) __ .P(X2) by: r(S) := R U 
((x,z) I 3y«x,y) E S l\yRz)}. Show that Rtr, the transitive closure of R (Definition 
1.9), is the least fixed point of r. 
Give a monotone operator different from r that also has Rtr as its least fixed point. 
Hint. See the proof of Lemma 1.8 and Exercise 1.7. Note that r is finitary. 
Thanks to immediate consequence operators being finitary, their least fixed points are 
reached at (or before) stage w of the upward fixed point hierarchy. The next exercise 
describes the situation for arbitrary, not necessarily finitary, monotone operators. 
* 4.16 Let T : P(U) - P(U} be a monotone operator that is not necessarily finitary. 
The complete upward hierarchy of T consists of the increasing series of sets T j a (a an 
ordinal) extending the ones of Definition 4.25 and recursively defined by 
T iO 
0, 
TT(a + 1) 
= 
T(TTa), 
Tj-y 
= U TT7 b a limit). 
{<-y 
Show that, for some ordinal a (of cardinality ɛ P(U» we have that T i = Ti a. (The 
least such ordinal is called the closure ordinal of the upward hierarchy.) 
Hint. Let a be the first ordinal for which T i a = T T (a + 1). 
4.17 (Compare Exercise 4.14.) Let T : P(U)-P(U) be monotone. Show: a E TT a iff 
there is a tree of height Z a with root a such that for every node b, if X is the set of 
children of b, then bE T(X). 

82 
Chapter 4 
The next definition of the downward hierarchy describes the situation for greatest fixed 
points, which are in some sense dual to least fixed points. (See Exercise 4.24.) 
Definition 4.27 Let T : P(U) -+ P(U) be a monotone operator. The stages of the 
downward hiemrchy of T are the sets T 10' C U (0' an ordinal), recursively defined by 
T10 
= 
U 
TlCO'+l) 
= 
T(T!O') 
Th 
= 
nT!{ 
e<'Y 
where "y is an arbitrary limit. 
• 
The difference between upward and downward hierarchy is that the latter starts from U 
instead of 0 and uses intersections at limits. 
* 4.18 Let T: P(U) -+ P(U) be a monotone operator. Show that, for some ordinal 0' 
of cardinality ɚ P(U), we have that T 1 = T 1 0'. (The least such ordinal is called the 
closure ordinal of the downward hierarchy.) 
Hint. Compare Exercise 4.16 or deduce the result from 4.16 and Exercise 4.24. 
4.19 Identify Tp! for the program P of Exercise 4.9. 
4.20 HU = IN. P has the following two rules: 
r(sx) +-r(x) 
q(o) +-r(x) . 
Determine Tp 1w, T l(w + 1) and Tp 1. 
Exercise 4.20 illustrates that the closure ordinal of the downward hierarchy of a conse­
quence operator can be> w, contrasting with the fact that the upward hierarchy always 
closes at or before w. 
4.21 Construct, for as many ordinals as you can, programs that downward close at that 
ordinal. (Details are given by Chapter 7, Section 7.3.) 
The following exercise presents a useful sufficient condition for a consequence operator 
to have exactly one fixed point. 
4.22 Let P be a program. Define the relation -< on the Herbrand base H B of ground 
atoms by: B -< A iff for some rule A+- L in ground(P), B occurs in L. Show: if -< is 
well-founded (Definition 1.11), then Tp has exactly one fixed point. (Of course, there 
still may be lots of pre-fixed points.) 
Hint. It suffices to verify the implication A E Tp 1 =} A E Tp i· For this, use -<-induction 
with respect to A (that is: Lemma 1 .14(iii». 

Program-definability 
83 
4.23 Apply the criterion of Exercise 4.22 to the programs of Exercises 4.20 and 4.9. 
4.24 (The dual of a monotone operator) Let T : P(U) -+ P(U) be monotone. Define 
Td : P(U) -+ P(U) by Td(X) := U - T(U - X). Show: 
(i) Td is monotone, 
(ii) for all ordinals a, we have Tdja = U - T 1a and Td 1a = U - Tta, 
(iii) Td(X) = X iff T{U - X) = U - X, 
(iv) Tdt = U - T 1; Td 1 = U - Ti, 
(v) Tdd = T. 
Give an example of a finitary operator with a non-finitary dual. 
4.25 Let P be a program. We always have 0 C Mp = Tp i c Tp 1 c Tp 1w c H B. Give 
four simple examples of programs, showing that the combinations 
1. 0 i= Tp i = Tp! = Tp!w i= HB, 
2. 0 i= Tpi = Tp! i= Tp!w oF HB, 
3. 0 oF Tpi:j: Tp! = Tp!w:j: HB and 
4. 0:j: Tp i :j: Tp! :j: Tp !w :j: H B 
are all possible. 
4.26 Let T : P(U)-+P(U) be a monotone operator over U and suppose that Z c U. 
Show that T has a least pre-fixed point containing Z. 
Hint. Consider the least fixed point of the operation T' defined by: T'(X):= ZUT(X). 
Notation. The least pre-fixed point of T containing Z is denoted by Tt (Z). 
• 
4.27 Let Tl, T2 : P(U)-+P(U) be monotone operators over U. Define the monotone 
operator T : P{U)-+P(U) by: T(X) := Tl(X) U T2(X). Is it true that 1j = T1iU T2i? 
Give a proof or a counter-example. 
What if we change U to n? 
4.28 Let T : P(U)-+P(U) be a monotone operator over U. Let T+ be defined by: 
T+(X):= X U T(X). Show that T+ i= Tt· 
4.29 Let T : P(U)-+P(U) be a finitary monotone operator over U and Z C U. Define 
the sets Tin(Z) by recursion as follows. 
TiO(Z) = Z; 
Ti (n + l)(Z) = T+(Tin(Z» ( = 1jn(Z) U T(1jn(Z». 
Show that Ti (Z) = Un Ttn(Z). 
Programs often are constructed in stages. The following lemma presents an alternative 
description for the least Herbrand model of such a program. 

84 
Chapter 4 
Lemma 4.28 (Modularity Lemma) Suppose that £1 and £2 are languages such that 
£1 C £2; H Bl is the Herbrand base of £1. Let Pi be a program in £i (i = 1,2) such that: 
no relation symbol in the head of a P2-rule occurs in a PI-rule. 
Let P := H U P2 and let T, Tl and T2 be the operators of, resp., P, PI and P2. Then 
(i) TIT = Ti n HB1; 
(ii) HBI nT2i(X) = HBI nx; 
(iii) TT = T2i(T1i). 
The third equation states that T i may be obtained by first generating TIT, and subse­
quently generating the least fixed point of T2 containing TIl 
* 4.30 Prove Lemma 4.28. 
The next exercise describes a stability property of programs with respect to the un­
derlying language. 
4.31 Let P be a program in the language £1. Suppose that £1 c £2. 
HUi is the 
Herbrand universe relative to £i (i = 1,2), HBi the Herbrand base. Let Mi be the least 
Herbrand model P generates over H Bi (i = 1,2). Show that M2 n H Bl = MI. 
What about the equality M2 = Ml? 
What is the situation for greatest fixed point models? 
The following exercise describes a type of inductive definability that will be used in 
Chapter 8. But in fact, least Herbrand models of programs already furnish examples, 
see Exercise 4.33. 
* 4.32 (Simultaneous inductive definitions.) Assume that T, S : peA) x P(A)-.P(A) are 
monotone; that is, if Xl C X2 and Y1 C Y2, then T(X1, Y1) C T(X2, Y2) (and similarly 
for S). Show: there are I, J c A such that 
(i) T(l, J) c ; S(I, J) C J (closure), 
(ii) if T(X, Y) c X and SeX, Y) c Y, then I C X and J C Y (induction). 
4.33 Suppose that P is a program. Let R = Rl U R2 be a partition of the set R of 
relation symbols of the language of P 
Define T(X) := {A E Tp(X) I A carries a relation 
symbol from R1} and SeX) := {A E Tp(X) I A carries a relation symbol from R2}. 
Let I and J be the sets the existence of which is claimed by Exercise 4.32. Show that 
Mp = lUJ. 

Program-definability 
4.5 
Definability 
The next definition describes the objects defined by a program. 
Definition 4.29 Let P be a program. 
85 
(i) P defines the n-ary relation r C Hun over HU in the n-ary relation symbol r if 
for all tb'" ,tn E HU: 
r(tl, .. · , tn) {=:} PUr(tl"'" tn). 
(ii) P defines the n-ary (partial) function I : Hun-.HU over HU in the (n + l)-ary 
relation symbol f if for all s, tb' .. , tn E HU: 
I(tl, ... , tn) = S {=:} PVf(tl."" tn, s); 
that is, if P defines the graph {(tl, ... ,tn,s) I l(tl, ... ,tn) = s} of I in f in the 
sense of (i). 
• 
Of course, by Definition 4.7, the right-hand side of the equivalence in 4.29(i) can be 
replaced by: r(tl, . .. , tn) E Mp. Thus, program-definability is closely related to least 
Herbrand models. P defines r in r exactly in case r is the interpretation of r in the least 
Herbrand model Mp of P 
The same goes for the function case. 
In Chapter 7 (Theorem 7.17), we shall establish that a relation (resp., function) over 
HU is program-definable in the sense defined iff it is positively decidable (resp., cal­
culable). It follows that the results in Exercises 4.35 and 4.36 (closure of the class of 
program-definable relations under unions, intersections and existential quantifications) 
cannot be extended by closure under complementation and universal quantification. 
Exercises 
4.34 Let P be a program that defines the relation R in the binary relation symbol r. 
Extend P to p+ by the following four rules involving p and q: 
p(x, y) +-r(x, y) 
p(x, z) +-p(x, y), p(y, z) 
q(x, y) +-r(x, y} 
q(x, z) +-q(x, y), r(y, z) . 
Show that P+ defines the transitive closure Rtr both in p and q. Is the interpretation of 
q transitive in every Herbrand model of P+? 
4.35 (Unions and intersections of program-definable relations are program-definable.) 
Suppose that PI and P2 are two programs that do not have any relation symbol in 
common. Assume that Pi defines the set Ai C HU in the unary relation symbol D:i 
( i  = 1,2). 

86 
Chapter 4 
(i) Extend H U P2 to a program that defines Al U A2 (in some relation symbol). 
(ii) Extend H U P2 to a program that defines Al n A2· 
4.36 (Existential quantification of a program-definable relation is program-definable.) 
Assume that P defines the relation r c HU2 in the binary relation symbol r. Define 
s c HU by: set) ::: 3u E HU ret, u). Construct a program (an extension of P with one 
rule) that defines s in some unary relation symbol s. 
The problem of which program-definable relations have a program-definable comple­
ment will be answered in Chapter 7. The next exercise shows that the equality relation, 
which is defined in eq by the rule eq(x, x) +-, is one of them. 
* 4.37 (Also, see Exercise 4.52.) Recall Clark's equality axioms CET (Definition 3.68) 
relative to an algebraic language: 
(i) f(XI ,"
" xn) R: f(YI,"" Yn) -+ (Xl R: Yl 1\ ... 1\ Xn R: Yn), 
(ii) f(Xl, . . .  ,Xn) ¢ g(Yl.··· ,Ym) (f, g different), 
(iii) x ¢ t (the variable x a proper subterm of t). 
The axioms of the first two types can be transformed into the following rules involving 
the binary relation symbol noteq: 
(i) noteq(f(xl"'" xn), f(Yl, . . .  , Yn)) +-noteq(xi, Yi) 
(1 ::; i ::; n) 
(ii) noteq(f(x}, ... , xn}, g(Yl, ... , Ym)) +-
(f, g different). 
Show: these rules define the inequality relation on HU in noteq. Thus, the least Her­
brand model of these rules satisfies the CET axioms of the third type. 
Hint. To see that noteq(s, t) follows logically from these rules whenever s, t E HU 
are different, first apply induction with respect to s (keeping t variable), next, apply 
induction again, but now with respect to t. 
* 4.38 Suppose that the k-place relation symbol r occurs in a program p. Show that, 
for every n, the k-ary relation on HU defined by: r( tl, .. . , tk) E Tp i n, is first-order 
definable on the Herbrand algebra H A. That is, show that for every n, 
a first-order 
formula ¢˒ with free variables Xl, . . .  , Xk may be constructed (involving identity, constant 
and function symbols, but of course no relation symbol) such that for all tl,"" tk E HU: 
H A F ¢i!{xl/tl,"" Xk/tk} <=> r(tb"., tk) E Tp i n. 
N.B.: Usually, the condition r(tl' ... , tk) E Tp i will not be first-order definable. For 
instance, a simple example of this phenomenon is the program of Exercise 4.10, which 
defines the ordering < of IN in terms of 0 and S. No first-order formula can accomplish 
this. 
Same question for the finite stages in the downward hierarchy of Tp• 

Program-definability 
4.6 
Representing Domains as Herbrand Universes 
87 
When we seek to define a relation by means of a program, we need to represent the 
domain of the relation as a suitable Herbrand universe. Usually, several representations 
will be possible; the choice will be dictated by circumstances. 
Contrasting with the case of "ordinary" logical settings, logic programming has an 
asymmetry in the roles of constant and function symbols on the one hand, and relation 
symbols on the other. Here, constant and function symbols generate the Herbrand uni­
verse (simulating a domain we're interested in), over which our programs define relations 
relevant for this domain. 
In the following, we present a couple of representations of domains-as-Herbrand uni­
verses that are often encountered: the domain of natural numbers, domains of expressions 
over a finite alphabet (of course, the natural numbers form the special case where the 
alphabet consists of one symbol only) and domains with lists. 
Finally, these representations are the source of an almost endless series of exercises. 
The readers may digest as many of these as they find suitable. (Some of the programs can 
be experimented with on the computer, using Prolog; to do this, we need the material 
in the next chapter.) 
4.6.1 
Natural Numbers 
Time and again, we have used the fact that we can consider the set of natural numbers 
1N as a Herbrand universe, generated by means of one individual constant 0 (for the 
natural number 0) and one unary function symbol s (for the successor-operation S). See 
Notation 3.20. Chapter 7 on computability deals extensively with this representation. 
Some of the following programs have been used already for illustration. 
Exercises 
4.39 P consists of the rules 
N(o)-
N(sx)-N(x). 
Determine, for each n, Tp T n. Determine Mp = Tp T. Same questions for Tp!. 
4.40 P consists of 
r(0,2) +-
r(sx, sy) - r(x, Y) 
r(x, ssy) - r(x, y). 
Determine Mp. Note that the interpretation of r in Mp is transitive. Find Herbrand 
models for P in which the interpretation of r is not transitive. 

88 
Chapter 4 
4.41 Consider the program SUM of Example 4.3. Is it true that Mp = Tp lw? 
4.42 Construct a program that defines the function max (max(n, m) is the maximum 
of nand m) in some symbol. 
4.43 Consider the following program. 
p{x,o,x)+-
p(x, sy, z) +- p(sx, y, z) 
q(x, y, 0 ,  y) +-
q(x, y, sz, w) +-p(x, y, u), q(x, u, z , w) 
rex, y, z) +- q(x, 0, y, z). 
What does it define in resp. p, q and r? 
4.6.2 
Binary Notation 
To the language considered in the previous subsection we add one unary function symbol, 
but we change the notation. The individual constant is now denoted by A, the two unary 
function symbols by So and S I . A ground term here can be thought of as representing a 
finite sequence of zeros and ones, A representing the empty sequence, and, e.g., sososlsoA 
representing the sequence 0010. We use the notations Ot := so(t) and It := SI(t) for an 
arbitrary term t. 
Exercises 
4.44 For t E BU, the ground term tl is recursively defined by the following equations: 
Al = SIA, (slt)l = sl(tl) and (sot)l = so(tl). 
I.e., t1 is obtained from t by the 
replacement of A by 1. (Note that tl is defined only for t ground.) Consider the following 
program: 
aPI(A, 1) +-
apl(lx,ly) +- aPI(x,y) 
apl(Ox,Oy) +- aPl(x,y). 
Give a detailed proof that this program defines the relation {(t, tl) I t E BU} in the 
relation symbol aPI ˑ 
4.45 Extend the program of the previous exercise with three rules involving a relation 
symbol apo defining the relation of appending 0 at the end of a sequence. For S E BU, 
s denotes the reverse version of Sj e.g., for S = 10111, S = 11101. Add the following 
rules involving the relation symbol rev. 
rev(A,A) +-
rev(lx, z) +- rev(x, y), apiCy, z) 
rev(Ox, z) +- rev(x, y), apo(y, z). 

Program-definability 
89 
Show that the resulting program (which has nine rules) defines the relation {(s, t) I t = s} 
on HU in the relation symbol rev. 
4.46 Consider the following program: 
r(A, x, x) +-
r(Ox, y, z) +- r(x, Oy, z) 
r(lx, y, z) +- rex, ly, z) 
q(x, z) +- rex, A, z) . 
What does this program define? 
4.47 Construct a program defining the set of palindromes in some unary relation symbol. 
(A palindrome is a sequence s for which s = s.) 
4.48 Find out what the following program defines. 
rCA, x, x) +-
r(Ox, y, Oz) +- rex, y, z) 
r(Ix, y, lz) +- rex, y, z). 
n 
,..-. 
4.49 Give a program that defines the set {I . . . 1 I n :2: OJ. 
4.50 Every ground term that does not begin with 0 and is different from A can be 
conceived of as denoting a natural number written in binary notation. For the following, 
it is slightly easier (though not essential) to work with binary notations written from 
right to left. Produce a program defining the relation {(s, t) I s E HU does not contain 
So and t is the number of occurrences of SI in s in binary notation} in a binary relation 
symbol bin. 
(i) Try to find a solution of your own. Don't make it too complicated; you're supposed 
to prove that it works! 
(ii) Here is a program that accomplishes this. It involves an extra relation symbol q. 
q(x , x, A) +-
q(x, y, Ii) +- q(x, lly, i) 
bin(x, OJ) +- q(x, A, i), bin(i, j) 
bin(x, Ij) +- q(x, 1, i), bin(i, j) 
bin(l, l) +-
bin(A, O) +- .  
Prove that this program accomplishes what it is supposed to. 
Hint. First, show that q(n, m, p) E Mp iff n - m = 2p. 
4.51 Again considering ground terms as binary notations for natural numbers, show 
that relations as smaller than and addition (conceived of as a ternary relation) can be 
defined by suitable programs. 

90 
Chapter 4 
4.52 Construct a program that defines the relation EQ := {(s, t) E HU2 I s = t} in a 
relation symbol eq. Construct a program that defines the relation NOTEQ := {(S, t) E 
HU2 I s  f. t} in a relation symbol noteq. (See Exercise 4.37.) 
4.6.3 
Lists 
Fix a constant symbol [ ]. Suppose that a binary function symbol [ . 1 . )  is present. Denote 
the set of finite sequences (tl , " " tn) of elements of HU by HU<w. Using [ ) and [ · 1 · ], 
we can construct an injection i : HU<w -+ HU using a recursion with respect to the 
length of the sequence involved: 
(i) i maps the empty sequence to [ ]; 
(ii) i(t, tl, . . . , tn) = [tli(tl " ' "  tn)] . 
Thus, i(tb . . .  , tn) = [td[t21 · . . 1 [tn I [ JJ . . .  J]). 
Usually, i(tl , . . . , tn) is denoted by [h , . . .  , tn]. We often shall confuse sequences of terms 
(usually called lists) with their i-image. 
Exercises 
4.53 Define the set of sequences of natural numbers. 
Solution: 
r([ )) +-
r([xly)) +- N(x), r(y). 
(N defining lN, using the rules of Exercise 4.39.) 
4. 54 [tl , " " tn, S l , "
" sm! is called the concatenation of [tl, " " tn! and [Sl , . . .  , sm). 
The concatenation of the lists a and (3 is denoted by aǤ (3. Construct a program defining 
concatenation as a 3-ary relation (Conc(a, (3, "'() := "'( = a[(3) in a 3-ary relation symbol 
append. 
4.55 B is the smallest set C H U  such that 
(i) 0, 1 E B, and 
(ii) every (finite) list of elements of B is again in B. 
(E.g., [ ], [0), [1, [ JJ are all in B.) Construct a program defining B as a unary relation. 
(N.B.: You cannot translate (ii) into one rule since lengths of lists vary. Next to the 
B-defining relation symbol, you'll need another one!) 
4.56 Construct a program defining the length of a list, that is, the function defined On 
lists that, when applied to a list, produces its length. 
4.57 Construct a program defining the function that produces the least element of a list 
of natural numbers. 

Program-definabili ty 
4.58 Find out what the following rules define. 
member(x, [xlv]) -
member(x, [Ylv]) +- member(x, v). 
4.59 Same question for the following rules: 
last{[zl , [ I, z) +-
last([zluj, [zlx), y) +-- last( u, x, y) 
reverse([ ] ,  [ ]) -
reverse(u, [Ylzj) - last(u, x, y), reverse(x, z}. 
91 
4.60 The sorted version of a list of numbers has the same elements as this list, but 
sorted in increasing order. Construct a program defining the binary relation sort (in a 
binary relation symbol qs), where sort(s, t) iff s is a list of numbers and t is its sorted 
version. 
Solution. The so-called quicksort-program consists of the following rules: 
qs«( J ,  [ J) 4-
qs(x, y, z) +- f(x, y, Yb Y2), qS(Yl ,  Zl), qS(Y2' Z2) ,  append(zl ' [XIZ2J , z) 
f(x, [ ) , [ I, [ ]) +-
f(x, [Ylzl, [yIYlj, Y2) - X > Y, f{x, Z, Yl , Y2) 
rex, [Ylz) , Yl , [yIY2]) +-x .$ Y, f(x, Z ,  Yl , Y2) 
plus the rules of the append-program asked for by Exercise 4.54. 
Determine the relation defined in f. 
4.7 
Notes 
The notion of implication tree, Definition 4.9, is from [Stark 891, in which Lemma 4.10 
is implicit. 
The notions of immediate consequence operator, least Herbrand model and their ele­
mentary properties are due to (van Emden/Kowalski 76] . 
Yet another interesting domain over which to define relations by means of programs is 
that of finite trees (of, say, numbers, suitably represented). 

 5 Linear Resolution 
5.1 
Preliminaries 
This chapter is devoted to the special case of first-order resolution where one of the two 
clauses to be resolved (the goal clause) consists of negative literals only, and the other one 
is a rule. Then, since the positive literal of the rule must be active in the resolution step, 
this results in a new goal clause of negative literals, preparing for a new step involving 
some rule. 
\1 
\1 
\/ 
Thus, a derivation here contains a unique sequence of goal clauses. This accounts for the 
linear character of this version of resolution. 
In Chapters 2 and 3, clauses are defined as sets of literals. From now on, a clause will 
be a disjunction of literals and we shall not use the set representation of disjunctions any 
longer. 
Suppose that K is a clause consisting of positive literals AI, ... , Ak and negative literals 
..,BI, ... , ..,Bm. Separating the positive from the negative literals, K is usually written 
as 
When k = 1, this is a rule. 
Definition 5.1 A goal is a clause with an empty positive part. 
• 

94 
Chapter 5 
A goal that is the disjunction of the negative literals ,B1, ... , ,Bm can thus be written 
as: 
Logically, this represents the universal closure '</( ,B1 V' .. V ,Bm) of the goal. Of course, 
other logical equivalents of this are '</,(B1 /\ .. . /\ Bm) and ->3(B1 /\ . . . /\ Bm). 
If C is the sequence (B1, . .. , Bm), the goal -B1, ... , Bm is also denoted by -C. A 
particular case is the empty goal/disjunction 1-, which we keep referring to by D. 
Definition 5.2 A Horn sentence is a universally quantified disjunction of literals of 
which at most one is positive. 
I 
Thus, goals and rules are Horn. 
Rules are often called definite clauses (this notion of definiteness will be expanded 
in Chapter 8). Ultimately, we come to explain the notion of SLD resolution, which 
stands for Selection rule driven Linear resolution for Definite clauses. We have already 
indicated why this new version of resolution will have a linear character; and it is clear 
now what the 'D' stands for. The notion of a selection rule will be explained much later; 
see Definition 5.42. 
Suppose that P is a program and -C is a goal, where C = (B 1, . .. , Bm). As in the 
first-order case, linear resolution attempts to establish unsatisfiability of P u { -C} by 
refuting - C on the basis of P, that is, by deriving the goal 0 from P and -C. 
Since the method is sound, deriving 0 implies that 0 logically follows from P together 
with -C, and hence (since 0 is the unsatisfiable clause par excellence) that -C cannot 
be satisfied in a model of P. As -C represents '</( -,B1 V . . . V ,Bm), this amounts 
to saying that the negation ,'</(,B1 V ... V ,Bm), equivalently, that 3(B1 /\ ..
. /\ Bm) 
logically follows from the rules of P Therefore, the procedure can be conceived as a 
method for proving statements of the form Pp3(B1 /\ ... /\ Bm). 
Thinking of linear resolution as a method to establish unsatisfiability of a goal -C 
relative to some program P is more tiresome than thinking of it as trying to ascertain 
that Pp3 A C. Therefore, in what follows, we prefer to use queries instead of goals: 
Definition 5.3 A query is a finite sequence of atoms. The notation 0 is also used to 
denote the empty query. 
I 
In view of the aforementioned remarks , logically speaking, a query should be thought 
of as the conjunction of its elements. 
Linear resolution now can be conceived as a (backward) search method for proofs of 
3 /\ C from a program P, where C is a query. Such a search succeeds if the empty query 
o has been derived, which, in this conception, should now be thought of as an empty 
conjunction, hence as T instead of as 1-. 

Linear Resolution 
95 
At this point, the reader of Chapter 3 might ask (since linear resolution is just a special 
case of resolution in first-order logic): what more can be said here? The answer is that, 
by its linear character, this version of resolution, next to being a refutation method, is 
able to compute as well. To give a glance ahead: a proof that Pr=3/\ C using linear 
resolution will actually produce values for the variables in C witnessing this fact. That 
is, the linear resolution proof will produce a substition 0 for which P r= /\ CO. We shall 
see that 0 can be looked at as the result of a computation process carried out by the 
linear resolution machinery. 
5.2 
Unrestricted Linear Resolution 
It is time to get down to business. The proper notion of linear resolution will be in­
troduced in Section 5.4. First, we define a more general version: unrestricted linear 
resolution. This notion is not of much importance; however, it has two special cases that 
are. The situation is similar to the one encountered in Chapter 3 (though a little more 
complex). Firstly, linear resolution is the special case of unrestricted linear resolution 
producing "maximal generality". Secondly, the opposite case regarding generality is that 
of ground linear resolution. Again, similar to the situation in Chapter 3, it is the first 
one we're really interested in. However, what this version actually establishes is seen 
by "lifting" the ground version, which is more closely related to the (Herbrand) models 
involved. Finally, the unrestricted notion offers the opportunity for the uninitiated to 
become familiar with linear resolution in a step-by-step fashion. 
In the sequel, we use juxtaposition to denote concatenation of sequences. E.g., if 
K = (AI."" An) and M = (Bl, . .. , Bm) are (possibly empty) queries and A is an 
atom, then K, M or (K, M) denotes the query (Al, .
.
• , An, Bl, ... , Bm) and K, A or 
(K, A) denotes (Al' . .. ,An' A), etc. 
Definition 5.4 An unrestricted resolvent of the query C = (K, A, L) with respect to the 
atom A and the rule R is a pair (a, D) such that 
• a is a substitution such that Dom(a) c Var(C), 
• D = (Ka,M, La), where Aa-M is an instance of R. 
In this context, A is called the selected atom and a the specialization. 
Q 
Instead of (a, D) we shall usually write 3u D. 
The notation C ʖu D (A, R) expresses that ʕu D is an unrestricted resolvent of 
Q 
Q 
C with respect to the atom A and the rule R; by C ʍu D we mean that ---+u D 
is an unrestricted resolvent with respect to some atom of C and some rule that, in the 
case that some program is given, is understood to belong to that program. 

96 
Chapter 5 
'" 
A co nfigu ra tio n C --+u D will be referred to as an unrestricted transition or resolution 
step. 
'" 
Finally, D is called an unrestricted resolvent of C in case some --->u Dis. 
• 
'" 
Thus: if C = (K, A, L) --->u D (A, R), then D is obtained from the query C by two 
successive transformations: 
(i) instantiating C using a, which yields Ca = (K a, Aa, La), and 
(ii) replacing Aa by M, o bta ining D = Ca{Aa/M} = (Ka,M,La)l 
whe re Aa <- IvI i s some instance of R. 
The re stri ctio n on the domain of a avoids c onsid erat io n of irrelevant variables and the 
'" 
reference to a in the unrestricted resolvent --->u D allows us to retrie ve a. 
While Aa<-M is an instance of R, it does not need to be Ra. In fact, in general 
this instance of R will be obtained by applying to R a different substitution (3. Then 
Aa = B{3, where B is the head of R. If Rand C do not have common variables, the 
domains o f a and f3 may be assumed disjoint. Then a U f3 is well-defined, and we get 
A{cx u(3) = B(a U (3), a being part of the unifica tion aU f3 of A and B. 
A query may contain several occ urrence s of th e same atom. To have a completely 
unambiguous notation, we therefore should mention no t the atom with respect to which 
the resolution ste p is carried out, but its selected occurrence. 
Note that forming an unrestricted resolvent is in fact almost the same as for the case 
of first-order logic; the only difference being that resolvents are always formed here with 
respect to singleton (one-element) sub clauses. For the rule, this is no restriction, since 
exactly one literal in it is positive, but for the query, it is. 
Example 5.5 
(i) Consider the program SUM from Example 4.3. 
{y/Sy} 
We have that sum(x, y, sz) -----+u sum(x, y, z), using the second rule. 
{xjSz,y/O} 
Also, we have sum(x, y, sz) 
-----+u 
0, using t he first rule. 
{xft} 
(ii) For any terms sand t, the construc t --->u q(s) is an unrestricted resolvent of r(x) 
with respect to the atom r(x) and the rule r(x) <-q(y). 
• 
a 
Definition 5.6 Suppose that C --'u D. The implica tio n D -- Ca is ca lle d the resul-
tant associated with this transition. In case D is empty, we identify the resultant with 
Ca. 
I 
lE{A/C} denotes the expression obtained from E replacing the sub-expression A by C. 

Linear Resolution 
97 
Remark 5.7 From now on, sequences C of atoms often will be identified with the con­
junction A C of their elements. So, for instance, a resultant D-Ca is to be identified 
with A D-A CO'. and a statement that, e.g., PFC is to be interpreted as PFA C. 
• 
Logically speaking, the resultant of a transition is what is being established by the 
transition. 
Lemma 5.8 If Q is the resultant associated with an unrestricted resolution step produced 
by means of the rule R, then R F Q. 
o 
Proof. Suppose that K, A, L -u K a, M, La (A, R). The resultant associated with 
this step is the implication K a, M, La-+K a, Aa , La, which logically follows from the 
instance M-Aa of R, and of course, that RF(M-+Aa) is a consequence of Corollary 
3.38(i). 
• 
Unrestricted derivations are defined as sequences of successive unrestricted resolution 
transitions. 
Definition 5.9 
(i) A (finite or infinite) sequence 
01 
0'+1 
Co -u C1"
,Ci -u CHI'" 
is called an unrestricted derivation relative to a program P if, for all (relevant) i, 
0,+1 
--+u Ci+l is an unrestricted resolvent of Ci with respect to some atom of Ci and 
some rule of P. 
If the derivation is finite and ends with Cn, it is called a derivation of Cn from Co. 
(ii) The resultant of the finite unrestricted derivation 
is the implication 
res(r) := Cn - COal' .
.
 an· 
In case Cn is empty we identify the resultant with COal" . an· 
I 
Thus, forming an unrestricted resolvent is making an unrestricted derivation of length 
1. Note that the resultants of an unrestricted resolvent (Definition 5.6) and the corre­
sponding I-step unrestricted derivation (Definition 5.9{ii» coincide. 
Compare this definition of (unrestricted) derivation with that for the case of first-order 
resolution, Definition 3.46. Here, we do not include the rules (for a given context, they 
constitute a fixed program), but we do include the specializations used on the queries 
(which, back in Chapter 3, we did not). 
The specializations involved in a finite derivation make up its resultant, about which 
we have the following lemma, generalizing Lemma 5.8 to derivations of length> 1. 

98 
Chapter 5 
Lemma 5.10 If r is a finite unrestricted derivation relative to the program P, then 
P 1= res(r). 
Proof. Induction on the length n of r. 
Basis n = 1. This is Lemma 5.8. 
Induction step. Suppose that 
01 
On+l 
Co -U··· -u Cn+1 
is an unrestricted derivation from the program P. 
By Lemma 5.8 we have that PI={Cn+1--+Cnan+d. By induction hypothesis applied 
01 
On 
to the derivation Co -u ' "  -u Cn, we have that PI=(Cn--+COal'" an) . Thus, 
by Corollary 3.38{i), PI=(Cn--+COal " ·an)an+1; that is, PI=(Cnan+1--+COal" ·an+d· 
Combining these, we obtain PI={Cn+1--+COal'" an+ 1), as desired. 
• 
Recall (Definition 3.53) that for a substitution a and a set of variables V, the restriction 
alV of a to V is the substitution {x/xa I x E V n Dom(a)}. 
Definition 5.11 A finite unrestricted derivation 
a1 
On 
r: Co -u . . .  --+u Cn 
is called successful or simply an unrestricted success (for Co), if Cn = O. 
In that case (Cn 
= 0), the restriction a := (al" ·an)lVar(Co) of the composition 
al ... an of the successive specializations to the variables of the initial query Co is called 
an (unrestrictedly) computed answer substitution (c.a.s.) for Co. 
• 
Note that an unrestricted computed answer substitution need not be ground; see the 
next example. 
Example 5.12 Consider the program SUM from Example 4.3. The following is a suc­
cessful derivation (we use the convention of Notation 3.20): 
sum(x,3,y) 
{y/Sy} 
--+u sum{x, 2, y) 
{y/Sy} 
-u sum(x, 1, y) 
{y/Sy} 
--+u sum{x,O,y) 
{y/x} 
--+u O. 
Its resultant is sum{x, 3, sssx) and its computed answer substitution is {y/sssx}. 
• 
Definition 5.13 A substitution a is called a correct answer for the query C with respect 
to the program P if P 1= Ca. 
I 

Linear Resolution 
99 
Computed answer substitutions are obtained by means of unrestricted resolution and 
correct answer substitutions are obtained by referring to the logical content of the pro­
gram. They are related to each other by the following Soundness Theorem. 
Theorem 5.14 (Soundness of Unrestricted Resolution) The computed answer 
substitution of a successful unrestricted derivation is correct. 
Proof. This is the special case of Lemma 5.10 where r is a success. 
• 
Conversely, every correct answer also is unrestrictedly computed; see Exercises 5.3 and 
5.21. 
Exercises 
5.1 Consider the program SUM of Example 4.3. 
(i) Show that the substitution {x/l,y/2} is a computed answer substitution for 
sum(x, y, 3). 
(ii) Extend the program SUM to MULT by adding the rules 
mult(x, 0, 0) -
mult(x, sy, z) - mult(x, y, z'), sum(z', x, z) . 
What is the least Herbrand model of MULT? 
(iii) Find a c.a.s. for mUlt(3, 2, z). 
(iv) If nand m are natural numbers, then an unrestricted success for mult(n, m, z) (z 
a variable) exists using this program. What is its length? What is its c.a.s.? 
(v) Same question when the last rule of the program is changed to 
mult(x,sy,z) - mult(x,y,z'),sum(x,z',z). 
5.2 Assume that P defines the (unary) function f : HU--+HU in the (binary) rela­
tion symbol f, cr. Definition 4.29. Let y be a variable. Show: for all s E HU: every 
unrestricted success for f(s, y) has the computed answer substitution {YI f(s)}. 
5.3 
Ground Completeness 
In the procedural interpretation of a program, we conceive of its rules as a series of 
computing instructions. On the other hand, a declarative interpretation of the program 
refers to its logical content. The Soundness Theorem 5.14 provides one half of the match 
between the procedural interpretation given by unrestricted resolution and the declarative 
interpretation of programs. Completeness theorems provide the (more difficult) other 
half. This section proves ground completeness, a result that can be compared to the 
propositional Completeness Theorem 2.18 of Chapter 2. However, the proof here is 
rather different from its propositional companion. A parallel with the situation in the 

100 
Chapter 5 
chapters on propositional and first-order logic is that ground completeness, as treated 
here, will allow us to establish stronger completeness results in later sections via a lifting 
procedure similar to the one from Chapter 3. 
Definition 5.15 An unrestricted derivation is called a ground derivation iff all its queries 
ʓʔ. 
. 
Of course, the specializations of a ground derivation all equal f, the identity substitution. 
, 
f 
Therefore, the resultant of a ground derivation Co --tu ... ---+u Cn is Cn -+Co; and 
when this is a success (Cn = 0), the resultant is Co. 
The following ground completeness result states that ground queries logically following 
from the program start a successful ground derivation. 
The proof transforms a set 
of ground implication trees (see Definition 4.9) for the atoms of the query, which are 
obtained from Lemma 4.10, into the required derivation. 
Theorem 5.16 (Ground Completeness) Let P be a program. If C is a ground query 
such that PFC, then there is a successful ground derivation for C with respect to P 
Proof. Suppose that C = (AI, ... , Am) is ground. Since PFC, by Lemma 4.10, there 
is a is a ground implication tree 'Ti, for Ai (i = 1, ... ,m). Let n be the total number of 
nodes in the trees 1i, ... , Tm. 
€ 
€ 
Claim. For every k ̏ n, there exist a ground derivation Co 
= C ---+u . . . ---+u Ck 
and a set of ground implication trees for the atoms of Ck such that the total number of 
nodes in these trees is n - k. 
Note that the theorem is just the special case of the claim where k = n. The claim itself is 
proved using induction on k. For k = 0, the claim holds by definition of n. Now suppose 
• 
f 
that we have constructed Co = C ---+u .
•
.
 ---+u Ck and a set of ground implication 
trees for the atoms of Ck such that the total number of nodes in these trees is n - k. 
Choose any atom A from Ck. Replace A in Ck by its children in the implication tree for 
A to obtain G\'+1' To obtain a new set of implication trees, replace the implication tree 
for A in the old one by its subtrees, the roots of which are the children of A. (So th e one 
node A vanishes.) 
• 
Eventually, we shall establish a completeness result for linear resolution by lifting 
the Ground Completeness Theorem once we have proved the lifting property for linear 
resolution. 
Corollary 5.17 Let P be a program and C a ground query. The following are equivalent: 
(i) P F C, 
(ii) C c Mp, 
(iii) there is a successful ground derivation for C relative to P, 

Linear Resolution 
101 
(iv) there is an unrestricted successful derivation for C with respect to P. 
Proof. By Definition 4.7, (i) ¢:} (ii). By the 
Ground Complet eness 
Theorem 5.16, 
(i) => (iii). As to (iii) => (iv), obviously, every success ful grouud derivation also is 
an unrestricted successful derivation. Fin ally, that (iv) => (i) is due to the Soundness 
Theore m 5.14. 
• 
Exercises 
5.3 Prove the 
follow ing partial converse of Theorem 5.14: every gro und correct answer 
substitution is an unrestricted computed answer substitution. 
5.4 Prove , or give a counter-example to, the following statement: every ground deriva­
tion relative to P for a query C s uch that C c Mp is finit e. 
Definition 5.18 The rank rk(A) of a ground atom A E Mp (rel ative to P) is the least 
n for which A E Tp In. 
For a ground query D = (Al,'" ,Ak) of atoms A}, . .. , Ak E Mp, the multiset rk(D) 
associated with it is defined by rk(D) := Hrk(Ad, . .. , rk(Ak)}}; it is called t he rank of 
the query. 
• 
Together with Theorem 1.13, the following exercise can be used to produce another 
proof of Theorem 5.16. However, the proof given is much more explicit about the resulting 
derivation. 
5.5 Assum e that C c Mp. Show: C has a ground unres tricted resolvent D such t hat 
rk(D} immediately precedes rk(C) in the multiset ord ering. 
5.6 The following is a sketch for a proof of Theorem 5.16, which rese m bles the on e from 
Chapter 2 more, but here is much less informative. 
Assume that no ground derivation using the P-rules and starting with the ground query 
C ends with D. The fo llow ing argument shows ground{P) U {-,C} to be propositionally 
satisfiable. 
Let E be the set of all queries D that end some P-ground derivat ion s tartin g from C. We 
conceive of E as a collection of finite, non-empty sets. By Le mma 2.21, E has a minimal 
meet S. We identify S with the truth assignment that assigns a ground atom t iff it is 
not in S. 
Claim. S sat is fies P U { -,C}. 
Proof. Assume that A E S n C. Then St=-,A, and a fortiori St=-,C. Next, suppose that 
(A+-Bl, ... , Bn) E ground(P) is not satisfied by S. Then A E S, but B1, •
.
•
 , En f/. S. 
S ince S is a minimal meet for E, by Lemma 2.20, DEE exists such that D n S = {A}. 
Then D{A/(B1, •
•
.
 , Bn)} is a ground unrestricted res olvent of D, hence, belongs to E, 
but does not contain an atom in S, contrary to the choice of S. 

5.4 
Linear Resolution 
5.4.1 
Motivation 
First, we explain what is being gained by the notion of linear resolution compared to the 
unrestricted version treated before. Suppose that a program P and a query C are given. 
There are three or four things by which an unrestricted resolvent of C relative to P is 
determined. 
(i) The atom selected from C, 
(ii) the rule of P involved in the unrestricted resolution step, 
(iii) finally, the specialization for the variables in C and the instance of the rule which 
together produce the unrestricted resolvent. 
It follows that if we intend to implement the refutation procedure, then we have to supply 
strategies that produce these selections. 
It can be shown that the selection of the atom in (i) is not critical (that is, if our interest 
only concerns successes). We do not stop to prove this for unrestricted resolution (but 
see the proof of Theorem 5.16), since eventually proofs will be given for linear resolution; 
see Corollary 5.48 and Theorem 5.49. 
The choice of the rule in (ii) is critical for unrestricted resolution and will remain 
critical for linear resolution also. 
What we shall see is that linear resolution completely eliminates the problem in (iii) of 
choosing specialization and rule-instance. The situation is similar to the one encountered 
for first-order resolution in Chapter 3. The solution adopted here also aims at maximal 
generality. However, a resolvent here consists not only of a query, but of a specialization 
as well; and so the situation is more complex. The solution consists in making resultants 
maximal. 
5.4.2 
Resolvents 
Recall that an expression is most general in the class K iff (Definition 3.73) every ex­
pression in K is an instance of it. 
Definition 5.19 A resolvent of a query (with respect to some atom and rule) is an 
unrestricted resolvent (with respect to these same things) whose associated resultant is 
most general. 
a 
The notation - D (now dropping the subscript 'u' from the arrow) is used for resol-
̎. 
. 
Other notations similar to the ones used in the unrestricted context will be used. 

Linear Resolution 
103 
The definition states that ʒ D is a resolvent of the query C with respect to the 
atom A and the rule R if it is an unrestricted resolvent with the additional property that, 
01' 
for every unrestricted resolvent -- D' of C (again, with respect to A and R), there 
exists a substitution r such that (D-Co)r = D'-Co'; that is: 
• Cor;::; Co', 
• Dr = D'. 
The following diagram depicts the situation. 
C 
D 
D' 
We shall often employ diagrams to illustrate situations like this one. In such a diagram, 
vertically downward pointing arrows indicate instantiations, and the other arrows stand 
for (possibly unrestricted) resolution steps. 
The condition Cor = Co' expresses commutativity of the diagram of substitutions on 
variables from C. 
Example 5.20 
(i) Reconsider Example 5.5 and the program SUM of Example 4.3. We noticed there 
that 
{y/Sy} 
sum(x, y, sz) -u sum(x, y, z), 
using the second rule. In fact, it is seen that 
{y/Sy} 
sum{x, y, sz) --- sum{x, y, z). 
{x/Sz,y/O} 
Similarly, we have that sum (x, y, sz) 
---+ 
0, using the first rule. 
(ii) Of course, ʑ q(y) is a resolvent of r(x) with respect to the rule r(x) +- q(y). (Its 
resultant is q(y)-+r(x).) 
ʐ q(x) is an unrestricted resolvent of r(x) (use the rule-instance r(x)+-q(x)), but it 

104 
Chapter 5 
is not a resolvent. (Its resultant is q(x)--;r(x).) However, the query q(x) is a resolvent; 
just use the specialization {x/y} instead. The resulta nt obtained: q(x)--;r(y), is a variant 
of q(y)--;r(x). 
I 
The following lemma conditionally ensures existence of resolvents. 
Lemma 5.21 (Resolvent Existence) If a query has an unrestricted resolvent with re­
spect to an atom and a rule, then it also has a resolvent with respect to these. 
Proof. The proof is analogous to the case for first-order resolution, handled in Lemma 
3.76, and proceeds via separation of varia bles and most gener al unification, as follows. 
Suppose tha t the following presents the details of an unrestricted resolution step 
0< 
C ---tu D' (A, R): 
C = (K,A,L) 
R = (B;-M), An = B/3, specialization n, 
D' = (Kn,M/3,Ln). 
We may assume that Dom(j3) C Var(R). 
Note that, if rules Rand R' are va riants of each other, they have the same instances; 
o 
0 
and hence we have C ---tu D (A, R) iff C ---tu D (A, R'). In particular, we have 
o 
0 
C ---t D (A, R) iff C ---t D (A, R'). It follows that we may assume tha t R and C 
have no variables in common (otherwise, change to a variant of R). Under this condition , 
, := n U /3 is well-defined, and unifies A and B, since A, = An = B/3 = B,. 
Let 0 be an mgu of A a nd B. We claim that the followin g unrestric ted resolution 
transition
: 
C = (K,A,L) 
specialization OW are C) 
D = (K,M,L)O 
is, in fact, a resolution step. 
To see this, let r be such that Or = ,. Then, e.g., the resultant associated with the 
former unrestricted resolvent: K n, M /3, Ln--;(K, A, L )n, is the r-instance of the resultant 
associated with the la tter one: (K,M,L)e--;(K,A,L)O. 
I 
The previous proof shows that we ha ve the following recipe for obtaining resolvents. 
Corollary 5.22 (on Resolvents) If the query C has a resolvent with respect to A and 
R = (B <- M), then a particular one can be obtained by 
(i) applying a renaming e to R, separating its variables from C; and 

Linear Resolution 
(ii) constructing an mgu () for A and B€. 
6IVar(C) 
Then 
- C(){A()jM€()} is a resolvent. 
105 
I 
Lemma 5.23 (Invariance for Renaming) If C ʏ D (A, R) and € is a renaming 
("'̌)lVar(C) 
for the associated resultant, then C 
-
D€ (A, R). 
("'̍)lVar(C) 
Proof. That C 
-1.1 
D€ (A, R) follows by inspection. That this is, in fact, a 
resolution step is clear also, since its resultant is a variant of the resultant of the resolution 
step given. 
I 
Lemma 5.24 Suppose that R is a rule, C and D queries, A an atom of C and a, {3 
ʋ 
(C1ʌ)lVar(C) 
substitutions. If Ca -1.1 D (Aa, R), then C 
-1.1 
D (A, R). 
The situation is depicted by the following diagram. 
C 
D 
Proof. By a simple inspection of the definition. 
I 
The Resolvent Existence Lemma 5.21 and Lemma 5.24 are now combined into the fol­
lowing. 
ʊ 
Lemma 5.25 (One Step Lifting) Assume that Cf7 -1.1 D (Aa, R). 
'" 
(i) There exist a substitution a and a query D+ such that C -- D+ (A, R), 
'" 
. 
(ii) for every a and D+ such that C ----+ D+ (A, R), there exists a substitution r for 
which 
(a) (f7{3)tvar(C) = (ar)lVar(C) ("commutation"), 
(b) D+r = D ("instantiation"). 

106 
Chapter 5 
o 
D+ 
0(1 
D 
{3 
(O'{3)lVar(C) 
Proof. Suppose that 0(1 --->u D (A(1, R). By Lemma 5.24, 0 
--->u 
D (A, R). 
See the diagram. Applying the Existence Lemma 5.21, part (i) follows; and part (ii) now 
is an immediate consequence of Definition 5.1 9. 
• 
The One Step Lifting Lemma states that (i) every unrestricted resolution step from 
0(1 can be "lifted" to a similar resolution step from 0; and (ii) every such lift is related 
to the unrestricted step by a substitution 1'. The main purpose of the next subsection 
will be to generalize the One Step Lifting Lemma to the case of derivations (defined in 
the proper way). 
Exercises 
{y/fy} 
{y/x} 
5.1 Show that p(x),q(y) --->u p(x),r(z) and p(x),q(y) ---->u p(x),r(z) are unre-
stricted resolution steps with respect to the atom q(y) and the rule q(Y)f-r(z) that are 
not resolution steps. 
e 
Hint. Show they don't lift the transition p(x), q(y) --->u p(x), r(z) (which, in fact, is 
a resolution step) in the sense of the One Step Lifting Lemma. (Compare Exercise 5.10.) 
5.8 Look through the unrestricted derivations you have produced up till now, and check 
which of the steps were, in fact, resolution steps. 
Thanks to the use of the variables-separating renaming, the recipe described by the 
Resolvent Corollary 5.22 often introduces more variables than are necessary. Of course, 
we can always rename variables back to reduce their number, if only we take care that 
the two resultants are variants of each other. 
5.9 Show that the following problems are decidable. 
(i) Whether a given unrestricted resolvent is, in fact, a resolvent. 

Linear Resolution 
(ii) Whether a given resolvent introduces a minimal number of new variables. 
(iii) Whether a given resolvent uses a minimal specialization. 
107 
5.10 (Compare Exercise 3.40.) 
Assume that C ʎu D (A, R) is an unrestricted 
resolution step, that R = (B +- M) and that /3 is the unique substitution such that 
Dom(/3) c Var(R), Aa = B/3, and D = Ca{Aa/M/3}. 
Show: this is a resolution step iff the following conditions are met: 
(i) Aa is a most general common instance of A and B, 
(ii) aI[Var(C) - Var(A)] and /31[Var(R) - Var(B)] injectively map variables to vari­
ables, 
(iii) the sets of variables Var(Aa), {xa I x E Var(C) - Var(A)} and {x/3 I x E 
Var(R) - Var(B)} are pairwise disjoint. 
5.11 Explain the reason for putting a restriction in the specialization in the claim of 
Lemma 5.24. 
Is it true that Dom(O') C Var(C) and Dom(/3) C Var(CO') imply Dom(O'/3) C Var(C)? 
f 
€ 
5.12 Suppose that C -u D (A, R). Show that for some D, C ---> D (A, R). 
5.4.3 
Derivations 
A derivation is simply defined as a sequence of resolution steps - except for one nasty 
detaiL To explain this, we introduce a notion and present a couple of examples. 
a 
Definition 5.26 A transition C -u D releases the variable x if x E Var(Ca) -
Var(D). 
A variable is released by an unrestricted derivation if it is released by one of the steps of 
the unrestricted derivation. 
• 
For instance, consider the program SUM of Example 4.3. The resolution step 
{x/Sz,y/o} 
sum(x,y,sz) 
-
0 
(using the first rule sum( x, 0, x)+-) releases the variable z. 
Example 5.27 
(i) Given the rules rex) +- p(y) and p(y) +- q(x), the following is an unrestricted 
derivation every step of which is a resolution step: 
f 
f 
rex) - p(y) - q(x). 
Its resultant is q(x) -+ rex). However, by just changing the first specialization € to {x/z} 
or using the rule-instance p(y) +- q(z), we can obtain strictly more general resultants, 

108 
Chapter 5 
namely (the variants) q(x)-->r(z) resp. q(z)-->r(x). The reason for not obtaining maximal 
generality here is re-introduction of the variable x (released at the first step) in the last 
query of the unrestricted derivation. 
(ii) Given the rules r(x,y)+-p(y) and p(y)+-, the following sequence is an unrestricted 
successful derivation using resolvents: 
f 
{y/x} 
rex, y) --+ p(y) --+ D. 
Its resultant is rex, x). A more general resultant can be obtained by changing the second 
specialization to E or the first one to {x I z }. 
Here, the re-introduction of x (released at the first step) by the second specialization 
is the culprit. 
• 
Note that in both examples non-maximality of the resultant of a two-step unrestricted 
derivation is due to the re-introduction of a variable released at the first step in the 
resultant of the second step. It turns out that this is the only cause that can endanger 
maximal generality of resultants. Therefore, we have the following definition. 
Definition 5.28 An unrestricted derivation is called a derivation if it consists of reso­
lution steps and satisfies the following condition: 
[ t ] no variable released at some step occurs in the resultant associated with a later 
one. 
• 
In other words, a derivation is an unrestricted derivation made up of resalvents in which 
a variable, once released, is never re-introduced, either in a query or by a specialization. 
The seemingly ad-hoc condition [ t J can be motivated further, both from a syntactic 
and from a semantic viewpoint. Syntactically, it is clear that re-introduction of a variable 
released at the first step will account for a resultant not being most general. Semantically, 
re-introduction of a released variable allows for further instantiation at later steps; if the 
derivation culminates in a success, this is not what is intended. Of course, it remains to 
be seen that [ t J not only is a necessary condition, but also a condition sufficient for our 
aims. 
Note that, in the step-by-step construction of a derivation, it is never a problem to 
satisfy [ t ]. 
Lemma 5.29 Suppose that ̋ is a derivation with last query C. If C has a resolvent 
with respect to an atom and a rule, then there also is a resolvent ʍ D with respect to 
these things with the additional property that appending it at the end of ̊ again results 
in a derivation. 

Linear Resolution 
109 
Proof. Use a variant of the rule that neither contains a variable from Var(C) nor one 
that has been released previously. Let a be the restriction to V ar( C) of a relevant mgu 
(d. Lemma 3.65) of the atom selected and the head of this variant. Apply the Resolvent 
Corollary 5.22. 
• 
For some examples of how to regain [ t 1, see Example 5.27. 
Definition 5.30 An unrestricted success that is a derivation is a success. 
• 
From now on, it is understood (unless the contrary is indicated) that computed answer 
substitutions always are obtained by derivations (and not by unrestricted ones). 
Theorem 5.31 (Soundness of Resolution) Every computed answer substitution is 
correct. 
Proof. This is a special case of Theorem 5.14. 
• 
Example 5.32 Here is a successful derivation based on the program of Exercise 4.59. 
Each step resolves the left-most atom of the query at hand. 
reverse([xl' X2], z) 
{z/(ylz]} 
---+ last([xl' X2], x, y), reverse(x, z) 
{x/(xllx]} 
---+ 
last ([X2], x, y), reverse( [xl lx] , z) 
{xiI ],Y/X2} 
---+ 
reverse([xl] , z) 
{z/[ylz]} 
---+ last([XI], x, y), reverse(x, z) 
{xII J,y/x,} 
----+ 
reverse( [ 1, z) 
{z/[ ]} 
----+ D. 
This derivation releases X2 at its third step and Xl at its fifth. Its c.a.s. is {Z/[X2,Xtl}, 
which is in agreement with Theorem 5.31 and the result of Exercise 4.59. 
• 
The following technicality is needed later on. 
01 
Qn 
,;" 
Lemma 5.33 If r: Co --'-'u . . .  --'--'u Cn 
.., an unrestricted derivation and X E 
V ar( COal· .
.
 an) - Var( Cn), then x is released by r. 
Proof. Induction with respect to n. 
Basis. For n = 1, this holds by definition. 
Induction step. 
Assume the result for unrestricted derivations of length n. 
Suppose 
that r : Co ʋu . .
. ʌu Cn+l now is an unrestricted derivation of length n + 1 and 
x E Var(Coal ... an+d - Var(Cn+l). By Lemma 3.52, y E Var(Coal ... an) exists such 
that x E Var(yan+l). 

110 
Chapter 5 
(a) y ¢ Var(Cn}. By induction hypothesis, y is released at one of the first n steps of r. 
Also, since Dom(an+l) C Var(Cn), we have yan+l = Y and hence, x = y. Thus, x is 
released by r. 
(b) y E Var(Cn). Thus, x E Var(Cnan+d. So, x E Var(Cnan+d - Var(Cn+1), i.e.: x 
is released at the last step of r. 
I 
It is the lifting property of derivations which shows that our derivation concept is the 
right one, in the sense that it produces most general resultants. To explain what this is 
about, we introduce a notion of similarity for queries and unrestricted derivations. 
Definition 5.34 Queries (AIt ... , An) and (BIt . . . , Bn) of the same length n are called 
similar if, for 1 :-:; i :-:; n, the atoms Ai and Bi carry the same relation symbol. 
• 
Suppose that C and D are similar in this sense. Form unrestricted resolvents of C 
resp. D by selecting atoms Ai resp. Bi in the same i-th position and applying the same 
rule. Then obviously, these unrestricted resolvents will be similar again. Thus, similarity 
of queries is propagated through unrestricted derivations as long as we keep selecting 
atoms in the same position and applying the same rule at corresponding stages of the 
two derivations. 
Definition 5.35 
(i) Unrestricted derivations r and A are similar if they start from similar queries, 
have the same length and, at corresponding places, apply the same rule to selected 
(occurrences of) atoms in the same position. 
(ii) The derivation A is a lift of the unrestricted derivation r if A is similar to r and 
the initial query of r is an instance of the initial query of A. 
I 
The following key-result shows that (i) lifts always exist and (ii) lifts are related to 
the unrestricted derivation they lift by means of a sequence of substitutions satisfying 
instantiation and commutation properties; compare the One Step Lifting Lemma 5.25. 
The following piece of notation is used. 
01 
02 
Notation 5.36 If r : Co -u C1 --+u C2• •• is a (possibly, unrestricted) derivation 
Qi+l 
Q " 
and i < j, then r i,j denotes the subderivation Ci -u ... -':"'u Cj which derives Cj 
from Ci, and ai,j (i < j) stands for the composition (aH l· · ·aj) of the specializations 
of ri,j. 
I 
Theorem 5.37 (Lifting) Suppose that Do = Co(1, where Dom«(1} C Var(Co). 
(i) Every (finite or infinite) unrestricted derivation starting from Do has a lift starting 
from Co. 
(ii) If A: Co  .. . lifts the unrestricted derivation r: Do ʊu···, then there 
exists a sequence u: (10, (11, (12, . . . of substitutions such that, for i < j: 

Linear Resolution 
(a) 0'0 = 0', 
(b) Dj = CjO'j ("instantiation"), 
(c) (O'iQi,j)IVar(Cd = (,6i,jO'i)\Var(Ci) ("commutation"), 
(d) res(ri,j) = res(6.i,j)O'j. 
The following diagram illustrates part (ii)(b,c) of the theorem. 
A: 
(7: 
r: 
Proof. 
,61 
Co 
I 
u=¢ 
Do 
Oil 
,6n+l 
Dn Q_n_+_l 
__ 
• 
Dn+1 
(i) Repeatedly, apply the One Step Lifting Lemma 5.25 and Lemma 5.29. 
111 
0<1 
Let r : Do --+u · · · be the given unrestricted derivation from Do. By 5.25(i), we can 
0<1 
/31 
lift the first step Do --+u Dl of r to a resolution step Co ---+ Cl. By 5.25(ii), there 
exists a substitution r1 such that Dl = C1 rl. 
0<2 
Therefore, again by 5.25(i), we can lift the second step Dl --+u D2 of r to a resolution 
(12 
step C1 --+ C2• By 5.29, we can satisfy [ t J for the resulting two-step derivation. By 
5.25(ii), r2 exists such that D2 = C2r2. 
Obviously, this construction can be repeated until we have lifted all of r, obtaining the 
required lift. 
(ii) First note that (d) is nothing but (b) and (c) put together. We show how to obtain 
the sequence (7. 
Suppose that 0'0, ... ,un have been found, satisfying conditions (a-d) for i < j :5 n. 
Since 6. is made up of resolvents, by Lemma 5 .25(ii) we obtain a substitution r such that 
both Dn+l = Cn+1r and (O'nll:n+1)\Var(Cn) = (,6n+lr)\Var(Cn). 
Since A satisfies [ t J, no variable released somewhere along 6.o,n is in V are Cn.Bn+1, Cn+!). 
This is exactly what is needed to be able to extend r to a substitution un+! by defining 
if x E Yare Cn,6n+l' Cn+1), 
if x has been released along 6.o,n. 
It now follows that, for m < n, Cmll:m,n+!Un+! 
= Cmum,6m,n+l. Note first that (1) if 
x E Var(Cn), then X,6n+1Un+! = x,6n+1r = XUnQn+l; (2) if x has been released along 

112 
Chapter 5 
Ao,n , then x!3n+l 
= x, hence again : X!3n+lan+1 
= xan+1 = XlTnan+l · Now assume 
that y E Var(Cm) and y!3m,n = t. Since by Lemma 5.33 any variable in t either occurs 
in Cn or is released along Ao,n, we have: y!3m,n+l an+l = t!3n+lan+1 = tanan+l = 
• 
Corollary 5.38 If P successfully unrestrictedly resolves Ca in n steps via the specializa­
tions al l . . .  , anI then P successfully resolves C in n steps via specializations !31 , · . .  , !3n 
such that for some T :  Caa l · · ·  an 
= C!3l · · ·  !3nT. 
Proof. B y  Theorem 5.37, a suitable lift o f  the unrestricted derivation o f  Ca will do. 
Note that a lift of a success is a success again, since 0 can be only an instance of D. 
• 
The following completeness result is weak in two respects: it is about ground instances 
of queries only, and it does not take into account selection rules. A completeness result 
that remedies both defects is in the next section. 
Corollary 5.39 (Weak Completeness) lf G-'Y is ground and PI=C,)" then a computed 
answer substitution () exists for C such that C,), is an instance of C(). 
Proof. By the Ground Completeness Theorem 5.16, P has a successful unrestricted 
derivation for C')'. Apply Corollary 5.38. 
• 
Exercises 
5.13 Show: a resolution step can release variables only if it is performed by means of a 
rule B <- M  for which Var(B) - Var(M) i 0. 
5.14 The following is a succesful unrestricted derivation based on the program of Exer­
cise 4.59. 
reverse([u, u) , [u, ul) 
€ 
---+u last([u, ul . [u) , u) , reverse( [uJ , [ul) 
€ 
---+u last([u], [ I, u), reverse([ul , [ul) 
€ 
---+u reverse([ul , [ul) 
• 
---+u last([u] , [ j ,  u), reverse{! ], [ ]) 
€ 
--->u reverse([ ) ,  I ]) 
• 
-----> u D .  
Check that the derivation of Example 5.32 lifts this unrestricted derivation. 
Construct the sequence of substitutions aO = {xl/u, X2/U, z/[u, uj } ,  . . .  , a6 that relates 
the two derivations in the sense of the Lifting Theorem 5.37 part (ii) . Note that, though 
the empty query 0 ends both derivations, a6 i E. Thus, the instantiation property does 
not suffice to construct the sequence. 

Linear Resolution 
1 13 
fJ 
5.15 Show: if C -- D (A, R), a, a and r are substitutions such that Caa= Cf3r 
and Dam(a) c Var(CO'), then Co' ʉu Dr (Aa, R) . (Hence, the first step lifts the 
second one . )  
E 
In particular, Cf3r -->u Dr (Af3r, R) . 
Show by means of a simple example that these transitions are not necessarily resolution 
steps. 
5.16 (Compare Lemma 5.29.) Suppose that Do is a derivation with last query C, and 
E 
that C has an unrestricted resolvent -->u D with respect to an atom and a rule. Show: 
f 
C also has a resolvent --> D with respect to these things with the additional property 
that appending it at the end of Do again results in a derivation. 
5 . 1 1  Assume that the query C has an unrestricted success (relative to some program) 
with computed answer substitution e. Show: e has a successful derivation with computed 
answer substitution E. 
5.18 Show that the converse of Lemma 5.33 is false, even if we require r to be a deriva­
tion. 
0 1  
an 
Show: Co --> .
.
.
 --> Cn releases x iff for some i < n :  
x E Var(Ciai+l ' "  an) -
Var(Cn). 
5.19 Give an example of an infinite derivation that does not lift a ground derivation. 
(Chapter 6 contains information about derivations like these.) 
5.20 Show: every finite derivation lifts a ground derivation. 
Hint. Use Exercise 5.15, or cf. Lemma 6. 1 1 .  
5.21 Compare Exercise 5.3. Prove the full converse of Theorem 5.14: every correct 
answer for a query (with respect to some program) is the computed answer substitution 
of an unrestricted derivation for that query (with respect to that program) . 
Show - by means of a simple example - that the adjective unrestricted cannot be 
dropped here. 
Definition 5.40 Let some program be fixed. Suppose that C and D are queries and a 
'" 
is a substitution. By the notation C --+-+ D we mean that Dom(a) C Var(C) and for 
0' 1  
an 
some derivation Co = C --> . . .  --> Cn = D (n 2: 1) using rules of the program, we 
have a = (al ' "  an) !Var(C). 
I 
Q 
fJ 
Lemma 5.41 If C --+-+ D, D --+-+ E and Var(Ca) n Var(Df3) C Var(D), then 
(afJ)/Var(C) 
C 
-->-> 
E. 
5.22 Prove Lemma 5.4 1 .  

114 
Chapter 5 
5.23 (Cf. also Chapter 8, Definition 8. 12.) Fix some program P. Let R be the smallest 
relation between queries and substitutions such that 
(i) ORE, 
(ii) if DR{3, C ʈ D (using some rule of P) and Var(Ca) n Var(D{3) C Var(D), 
then CR( a,8) IV ar (C). 
Show: CRa iff a is c.a.s. of some successful P-derivation starting from C. 
5.24 (Cf. also Chapter 8, Definition 8.47.) Fix some program P. Let YeS be the least 
set of queries such that 
(Yl) 0 E YeS, 
• 
(Y2) if C ---+ D (using some P-rule) and D E YeS, then C E YeS. 
Show: 
(i) if CO' E YeS, then there is a computed answer substitution 0 for C such that CO' 
is an instance of CO, 
(ii) if 0 is a computed answer substitution for C, then C() E YeS. 
5.5 
SLD·Resolution 
At the beginning of the previous section, it was noted that an unrestricted resolvent is 
determined by three choices: (i) selection of an atom from the query, (ii) choice of an 
(applicable) rule, (iii) determination of specialization and rule instance. Only the last 
problem in this list is eliminated by the concept of resolution. 
One of the topics of the present section is to eliminate - in some sense - the first 
one. Also, the completeness result of Corollary 5.39 is generalized. 
Intuitively, a selection rule is a function that handles choice (i) in the construction of 
a derivation. In order to obtain a simpler formulation of the next definition, we consider 
a query as a derivation of length O. 
Definition 5.42 A selection rule is a function defined on finite (possibly, unrestricted) 
derivations that do not end with the empty query. When applied to such a derivation, 
it outputs (an occurrence of) one of the atoms of the last query. 
• 
Note that a selection rule is not at all required to pick atoms that unify with the head 
of some (variant of a) program rule. Even if there are such atoms in the query under 
consideration, it may select one to which no rule is applicable (and so the derivation 
comes to an unsuccessful end). 
SLD-resolution, in full: Selection-rule driven Linear Resolution for Definite clauses, is 
constructing derivations where the atoms are selected by means of some selection rule. 

Linear Resolution 
115 
A very simple example of a selection rule is to always pick the leftmost atom in a query. 
This is the leftmost rule; it is the selection rule Prolog uses. This rule does not take 
into account the "history" of the query in which it selects-the derivation by which it 
has been obtained. The selection rule that alternates between left- and rightmost atom 
selection is a simple example of a rule that is not completely history-independent. 
Here are two simple properties a selection rule may possess. 
Definition 5.43 A selection rule is lifting invariant if, whenever applied to a derivation 
r and its lift A, it always selects atoms in the same position. 
A selection rule is fair if, for every infinite derivation produced by it, every atom occurring 
in a query of the derivation is eventually selected. 
• 
In other words, if the infinite derivation r is produced by a fair rule, has specializations 
th , 02, 03, •
•
.
 , and if an atom A occurs in the i-th query of r, then either the rule 
immediately selects A in this query, or for some (first) j > i, it selects the descendant 
AOi,i of A in the j-th query of r. 
Note that the leftmost rule is lifting invariant. However, it is not fair. For instance, 
let the program P consist of the one rule p +- p. Then the query (p, q), with the leftmost 
rule, starts an infinite derivation in which the atom q is never selected. 
Derivations from a fixed query, conceived of as sequences of successive resolvents, can 
be organized into trees. If we consider only derivations produced using a fixed selection 
rule, then we obtain an SLD-tree. 
Let us call a rule applicable to the atom A if its head and A have a common instance. 
Definition 5.44 Let P be a program, C a query and p a selection rule. A p-SLD-tree 
for C with respect to P is a tree T with root C in which all other nodes are of the form 
Q 
- D, and such that 
a 
• for every such node, the unique path r 
= C -- . . . -- D through T is a 
derivation, and 
Q 
• for every such node D and path r = C --+ . . .  -- D, if D :f=. 0 and p(f) = 
a 
A E D, then for every rule R E P  applicable to A, the node --+ D has exactly 
one child ...!.- E in T for which D ...!.- E (A, R). 
Of course, this stipulation is also required of the root C, that is, if C i= 0 and 
p( C) = A E C, then for every rule R E P  applicable to A, the root C has exactly 
one child  E in T for which C  E (A, R). 
Finally, an empty node is a leaf of T. 
• 
The actual construction of SLD-trees presupposes some way of picking, for each appli­
cable rule, exactly one resolvent among infinitely many variants. 

116 
Chapter 5 
81 
Let T be the SLD-tree determined by P, Co and p, and suppose that r := Co ʇ . . .  
 Cn is a path through T, where Cn -:f. D. Let A : =  per) be the p-selected atom 
8 
of Cn. Then the node Cn (actually, the node ̉ Cn) has as many children in T as 
there are A-applicable rules in P- Since there are only finitely many rules in a program, 
it follows that SLD-trees are finitely branching. 
Three things may happen in climbing an SLD-tree. 
(i) The climb follows a successful derivation, after finitely many steps ending at a 
success leaf D. A tree containing a success is called successful, otherwise it fails. 
(ii) After finitely many steps the climb ends at a leaf different from 0 (the selection 
rule selects an atom here for which no applicable rule exists in the program). Such 
a leaf is called a failure. 
(iii) The climb goes on forever, along an infinite branch. This can happen if the tree is 
not well-founded. 
Example 5.45 Consider the following three rules: 
path (x, z) +- arc(x, y),path(y, z) 
path(x, x) +-
arc(d, c) +-. 
The SLD-tree for the query path(x, c) generated using the leftmost selection rule is finite. 
It has three leaves: two successes and one failure; there are no infinite branches. The 
rightmost selection rule (which always picks the rightmost atom in a query) generates 
an infinite, non well-founded SLD-tree for the same query. 
• 
Here follows a completeness result incorporating the selection rule independence phe­
nomenon. 
Theorem 5.46 (Completeness) Let P be a program, C a query and u a substitution 
ground for C such that PI=Cu. Then every SLD-tree for C contains a success with a 
computed answer substitution f) such that Cu is an instance of Cf). 
Proof. We mix the proof of the Ground Completeness Theorem 5.16 with a lifting 
construction. 
Assume that PpCu, where Cu is ground. By Lemma 4.10, every atom in Cu has a 
ground implication tree. Let n be the total number of nodes in these trees. We show that 
01 
Ok 
for k ::; n, a p-derivation rO,k : Co = C ----0 •
•
•
 ----0 Ck, a ground substitution uk and 
a set of ground implication trees for the atoms in CkUk exist such that Cu = C(h . . .  f)kuk 
and the total number of nodes in these trees is n - k. 
The required result follows by putting k = n. 

Linear Resolution 
117 
For k = 0, these conditions are satisfied by hypothesis. As an induction hypothesis, 
assume they are satisfied for the derivation fO,k and a set of ground implication trees 
for the atoms in CkO'k, where k < n. Suppose that A E Ck is the atom selected by 
p. Let AO'k <- E be the ground instance of the rule R of P such that the children of A 
in the implication tree for A are precisely the elements of E. Now, CkO'k -u D = 
8k+l 
CkO'k {AO'k / E} is a ground resolution step. Lift this to a step Ck -- Ck+l ,  not re-
introducing variables from fO,k , and suppose that T is such that Ck+l T = D and CkO'k = 
Ck Ok+ 1 T. 
Extend T to O'k+l as required, putting XO'k+l 
= XO'k for variables x released 
along fO,k. (Compare the proof of Theorem 5.37.) The set of ground implication trees 
for the atoms in D is obtained from the set for the atoms of CkO'k replacing the tree for 
AO'k by its subtrees for the children of AO'k . 
• 
The following result strengthens Theorem 5.46 by admitting 0' to be non-ground. 
Corollary 5.47 (Strong Completeness) Let , be a substitution such that PFC" 
Then every SLD-tree for C contains a success with a computed answer substitution f} 
such that C, is an instance of Cf}. 
Proof. The trick is to consider the variables of C, as new constant symbols. Let T be 
an SLD-tree for C. Let 0' be a substitution mapping V ar( C,) 1-1 onto a set of new 
constant symbols. Since PFC" we have that P F C,O', as well. 
Note that the addition of the new constant symbols to the language does not stop T 
from being an SLD-tree for C. 
By the Completeness Theorem 5.46, T contains a success A with a computed answer 
substitution f} such that C,O' is an instance of C(). Clearly then, since CO does not 
contain any of the new constant symbols, C, also is an instance of Cf}. 
• 
Note that this theorem eliminates the problem of selecting atoms - at least if it is a 
success we're after. 
For a nice alternative to the proof of Corollary 5.47, see Exercises 6.4 and 6.5. 
Corollary 5.48 (Irrelevance of Selection Rule) If a query has a sUCcess using some 
selection rule, then it has a success using any selection rule. 
• 
A stronger, more informative version of this result can be obtained by switching steps 
in a derivation. This shows that the use of a different selection rule cannot result in a 
computed answer substitution that is more general, nor in a success that is shorter. 
Theorem 5.49 (Strong Independence of Selection Rule) Let p be a selection rule 
and C a query. For every success for C there exists a p-success for C of the same length 
and with the same computed answer substitution. 

118 
Chapter 5 
Proof. Since we are only interested in p as far as derivations from C are concerned, we 
may as well assume that p is lifting-invariant. 
Let A be a success for C with c.a.s. 6. Then A lifts an unrestricted success r for C6 
that has all its specializations equal to f. 
Construct a p-unrestricted success E of C6 stepwise by moving steps from r to the front, 
if this is required in order to satisfy p. Note that this is possible, since every p-selected 
atom - or a descendant - must be selected somewhere along r as r is a success. All 
specializations remain unchanged equal to f; we need modify only in queries. 
Lift E to a p-success E+ for C. Let u be the c.a.s. of E+ .  By the Lifting Theorem, Cu 
is more general than Co. 
Of course, E+ can be projected-switched-and-lifted again, using the same procedure. 
I.e.: project E+ to an unrestricted similar success for Cu with all specializations = f, 
subsequently, modify this to an unrestricted success similar to A with all specializations 
= f. 
By the Lifting Theorem, Cu is an instance of C6. Therefore, Co and Cu are variants of 
each other. 
By invariance for renamings, there is a p-success for C with the same c. a.s. 6, as well. I 
Exercises 
5.25 Check the details of Example 5.45. Note that the rightmost tree also contains two 
successes, corresponding to the two of the leftmost tree. This illustrates the phenomenon 
of irrelevance of the selection rule. 
5.26 Assume that the query C has an SLD-tree relative to the program P (and some 
selection rule) that does not contain a success. Let C' be an instance of C. Show that 
C' has such a tree as well (possibly using a different selection rule). Describe it. 
5.27 Let p be an arbitrary selection rule and C a query. Show, using Corollary 5.47 
alone: for every successful derivation of C with computed answer substitution "( there 
exists a successful p-derivation of C with computed answer substitution () such that C,,( 
is an instance of CO. 
0'1 
0:2 
5.28 Suppose that a given two-step derivation Co --+ C1 --+ C2 first applies the rule 
R and next the rule Q .  
{31 
fh 
Show that a two-step derivation Co --+ Dl --+ C2 exists that first performs Q and 
then R, such that CofJdh = COCklCk2. 
5.29 Prove: if "( is a correct answer substitution for C with respect t o  the program P 
and T is an SLD-tree for C,,(, then T contains a success of which the computed answer 
substitution is a renaming for C"(. 

Linear Resolution 
119 
Instead of computing, logic programming can also be used to find solutions to a problem 
in a large search space. The following two exercises illustrate this possibility. See Exercise 
5.32 for a general observation concerning programs accomplishing such searches. 
* 5.30 Construct a program and a query with the following property. The leftmost SLD­
tree for the query is finite, and the computed answer substitutions along its successes 
coincide with all solutions to the game of Solitaire (coded appropriately). 
* 5.31 Construct a program that "finds" (in the sense of Exercise 5.30) all sequences of 
length 27 in which each of the numbers 1 ,  . . .  ,9 occurs exactly three times, and which have 
the property that, between two successive occurrences of a number n, there are exactly n 
occurrences of other numbers (n = 1, . . .  , 9). (There are six pairwise-symmetric solutions; 
one of them is [7, 5, 3, 8, 6, 9, 3, 5, 7, 4, 3, 6, 8, 5, 4, 9, 7, 2, 6, 4, 2, 8, 1, 2, 1, 9, 1].) 
Solution. Consider the rules: 
find(x) +-
twentyseven(x ), 
sublist([I, X u ,  1 ,  X 12 , 1], x), 
sublist([2, X2 1 , X22 , 2, X23 , X24 , 2], x), 
sublist([3, X31 .  X32 , X33 , 3, X34 , X35 ,  X36 ,  3], x), 
sublist([9, X9 l , X92 ,  . . .  , Xgg , 9, XlOO, .
•
.
 , X108 , 9], x) 
twentyseven([xl, . . .  , X27]) +-
sublist(x, y) +- append(u, x, v) , append(v, w, y) 
plus rules for append. Note that the declarative interpretation of these rules leaps into 
the eye: they straightforwardly formulate, in logical terms, the conditions a solution must 
satisfy. 
5.32 Assume that HU is infinite. Suppose that the query C has only finitely many cor­
rect answer substitutions (w.r.t. some program). Show: its correct answer substitutions 
and its computed answer substitutions coincide. 
5.6 
Notes 
One of the oldest references in the subject is [Kowalski 74J. At about the same time, 
Colmerauer was developing Prolog. 
In the literature and in Prolog, the inverted implication symbol also is written as : -. 
For the name Horn, see: A .  Horn, On sentences true of direct unions of algebras, J. 
Symbolic Logic 16 (1951) pp 1-14. 
The unrestricted version of resolution occurs in [Lloyd 87] . 

120 
Chapter 5 
The way to define resolvents in Definition 5.19 is similar to the one used in Chapter 
3, and different from the traditional, ad-hoc set-up that defines resolvents using the 
explicit recipe of Corollary 5.22. Similarly, the notion of derivation, Definition 5.28, is 
different from the traditional one, which avoids confusion of previously released variables 
with new ones using so-called standardization-apart conditions, of which there are many 
competing ones occurring in the literature. About a quarter of a century ago, Curry 's 
Principle ( "every paper dealing with substitutions contains at least one mistake" ) still 
held. This logical tradition seems to have been taken over by workers in the field of logic 
programming for some time (be it that the type of mistake has changed). We hope the 
present chapter contributes to putting an end to this remarkable phenomenon. 
'" 
The arrow notation as in C ---> D does not correspond properly to the direction 
in which the rules point (it is the resultant DtCa that logically follows from the rule 
employed for this step); however, it does correspond both with the direction in which a 
derivation is constructed and with the commutation property of diagrams. 
Shepherdson's notion of resultant (Definitions 5.6 and 5.9) is in [LloydjShepherdson 91] . 
Much of the material from this chapter is taken from [Doets b] (that paper uses a more 
abstract notion of derivation, proved to be equivalent with the simpler one used here), 
which also discusses the precise relationship with the traditional approach. 
Example 5.45 is from [Apt 90] . 
Theorem 5.49 appears to be new. 
The note [SHirk 89J contains a short and beautiful proof of Corollary 5.47 (indicated 
in Exercises 6.4 and 6.5) of which the proof for Theorem 5.46 is a special case. The proof 
of Theorem 5.16 is implicit in [SHirk 89]. 
The observation contained in Exercise 5.32 is due to Apt. 

 
6 Infinite Derivations 
6.1 
Negative Information 
Linear resolution only deduces positive information from programs. What it proves 
are statements of the form 3/\ C, where C is a sequence of atoms. In many practical 
situations, however, it makes perfectly good sense to deduce negative information as well. 
E.g., from the fact that the time table does not list a train leaving at 12.08, I should 
be able to rightly and correctly make the inference that no train will leave at that time. 
Thus arises the need to construct inference systems that make up for this deficiency. Now 
for every program P and every ground atom A, PU{A} is satisfiable (the Herbrand base 
HB is a Herbrand model for it); and so we never have that P 1= ..,A. Therefore, if such an 
inference system permits the derivation of..,A from P, it necessarily is unsound. Secondly, 
the train example shows that whatever our approach to this problem, an inference system 
that is able to deduce negative facts probably will be non-monotone. The edition of the 
time table in Our possession may have been incomplete and its latest revision may show 
us that a train does leave at 12.08 after all. Thus, although ..,A "follows" from P, ..,A 
need no longer be corroborated by an updating pI :J P of P that, in fact, possibly might 
entail that A. 
Now, let us have a look at some possible ways of drawing negative conclusions from 
programs. Naively, at least three possible answers come to mind. 
Recall, that Mp = Tp i c Tp 1 c Tp lw. Let A be a ground atom. 
(i) If we consider the least Herbrand model Mp of P to be its "real" meaning, then 
one can consider ..,A to be inferred in case A rt. M p. 
This rule is known as the Closed World Assumption. 
(ii) Somewhat less liberal, one can consider ..,A to be inferred in case A rt. Tp 1. 
This is called Herbrand's rule. 
(iii) Even less liberal, one may consider ..,A inferred in case A rt. Tp lw. 
This is known as negation as (finite) failure; this terminology will be explained 
shortly. 
Of these three, the Closed World Assumption may well be the most sensible one. 
Note that, for ground atoms A, A rt. Mp amounts to P ï A; hence, the Closed World 
Assumption considers a ground atom to be false just in case it does not follow from P 
However, computationally, it often is not a feasible rule, even in the widest possible sense 
of this term. Chapter 7 shows that Mp is positively decidable but possibly not decidable. 

122 
Chapter 6 
Therefore, its complement H B - Mp may not be positively decidable; and it follows that 
no effective deduction method exists that will allow us to conclude that A ¢ Mp in all 
cases where this is true. 
Herbrand's rule is even more problematic in this respect: Chapter 7 shows that Tp! 
can be even more complex. 
From the Completeness Theorem 5.46 we know that, for a program P and a ground 
atom A, A ¢ Mp iff A has an unsuccessful SLD-tree. 
The reason this condition may not be positively decidable is that an SLD-tree can 
be infinite; hence, generating it, we can never be sure that it will indeed turn out to 
eventually fail. 
It is clear that one possible (but rather ad-hoc) way to restore positive decidability 
consists in requiring A not to have an arbitrary failing SLD-tree, but a finite failing tree. 
For, since we can systematically search through all finite SLD-trees, this obviously is a 
positively decidable condition. 
One of the results in this chapter is the equivalence of this condition with that of 
negation as failure. Another equivalent uses the notion of completion of a program, cf. 
Definition 6.19. It has been argued that the "real" meaning of a program is given by its 
completion. And it turns out that A E H B - Tp ! w iff ..,A follows from the completion 
of P, cf. Corollary 6.20. 
Other upcoming results are related to the question of when these ways of inferring 
negative information are different and when not; that is, under what conditions the sets 
Mp = Tp 1, Tp ! and Tp! w differ and under which circumstances they coincide. 
For a discussion of negative information in the proper context of general queries and 
programs (which fully allow negations) , see Chapter 8. 
6.2 
Non-standard Algebras 
Given a non-empty set of constant and function symbols, the standard Herbrand algebra 
H A (Definition 3.19) consists of the ground terms constructed using these symbols, 
together with the canonical interpretation for them. We are going to consider seriously 
other algebras as well. 
Note that H A satisfies the set CET of free equality axioms 
introduced by Definition 3.68, which are repeated here. 
(i) f(XI,"" xn) = f(Yl,' .. ,Yn) -+ (Xl = Yl 1\ ... 1\ Xn = Yn), 
(ii) f(XI,"" xn) 1= g(Ylt ... ,Ym) (f, g different), 
(iii) x 1= t (for X a proper subterm of t). 

Infinite Derivations 
123 
Axioms of type (iii) are called occur check axioms. To see these axioms spelled out for 
the simplest non-trivial language {o, s}, see Exercise 3.7(i)-(iii) . An application of the 
first two axioms (a program defining non-equality on HU) is contained in Exercise 4.37. 
The theory of SLD-resolution from Chapter 5 is based on the Herbrand algebra H A. As 
we shall see, the theory CET derives its importance from the fact that we can generalize 
SLD-resolution, replacing H A by just any model of CET. I.e.: the free equality axioms 
exactly express the properties of H A that make SLD-resolution possible. 
Recall the notion of an algebra from Definition 3.19 and the discussion following it. 
Definition 6.1 A CET-algebra is an algebra that satisfies CET. 
• 
Of course, the primary example of a CET-algebra is the standard Herbrand algebra 
H A. See the following examples. 
Next to the CET -axioms, H A satisfies yet another 
sentence, the Domain Closure Axiom DCA (as in the CET-axioms, we conceive of a 
constant symbol as a O-argument function symbol) : 
"Ix V{3YI'" 3Yn[x = r(Yb ... , Yn)J I f an arbitrary function symbol } 
that says every element is the value of a function. 
From now on, let a CET-algebra J be fixed. 
Lemma 6.2 The function t ,... tJ, mapping a ground term t E BU to its value tJ in J, 
is injective. 
Proof. By induction on t, we verify the following 
Claim. If t E BU, then "Is E HU[tJ = sJ => t = sJ. 
For t a constant symbol, this immediately follows from the second CET -axiom. Next, 
suppose that t = f(tl, ... , tn). Assume that tJ 
= sJ. Again by the second axiom, s 
cannot be a constant symbol. Suppose that s = g(Sl, .. . ,8m) . Now by the second axiom 
f = g and n = m; hence, by the first axiom, tf = sf, . .. , t;' = s"fn. 
Therefore, by 
induction hypothesis, tl 
= 8b"
" tn = Sm. (The argument does not involve the occur 
check axiom.) 
• 
It follows that (up to isomorphism) J extends HAj Le., HA is a submodel (Definition 
3.42) of J. 
Compare Remark 3.21. Without loss of generality, we can thus make the 
following simplifying assumption comfortably. 
Assumption. Every CET-algebra extends H A. 
CET-algebras properly extending HA are called non-standard. There are two ways of 
non-standard ness, which may coexist. The simpler one looks as follows. 
Definition 6.3 Let V be any set of variables. HU(V) is the set of all terms t with 
Var(t) C V. Just as is the case with HU, HU(V) can be turned into an algebra HA(V) 
(in fact, a GET-algebra) by interpreting constants and function symbols canonically. • 

124 
Chapter 6 
Note that H A(0) 
= H A. If V is the set of all variables, then H A(V) = T M, the 
algebra of all terms. If V 'I- 0, then H A(V) does not satisfy the domain-closure axiom 
DCA. 
The more complicated form of non-standardness is the presence of elements with an 
infinite parsing tree. The simplest example of this is the following. 
Example 6.4 The language consists of one individual constant: 0, and one function 
symbol that is unary: s. That is, HU = IN. We now describe the non-standard CET­
algebra IN + 7J, relative to this language. The universe of this algebra is the union of the 
set of natural numbers and a copy { ... , -1', 0', 1',2', ... } of the set of integers 7J, disjoint 
from IN. 
0 is interpreted as the natural number O. s is interpreted as the ordinary 
successor operation S on the natural numbers, as well as on the copy of the integers. 
Now every element of the 7l-copy of IN + 7l has an infinite parsing tree. For instance, 
0' = S( -I') = SS( -2') = SSS( -3') = .... 
• 
If t is a term and t7 is an assignment of elements of J to the variables in t, then we 
have the notation (tt7)J for the value of the J-term tt7 in J, see Definitions 3.1O(ii) and 
3.8. In the sequel we drop the superscript J and use the notation tt7 for (tt7)J if J is clear 
from the context. Of course, by Definition 3.1O(ii), the notation tt7 previously stood for 
the J-term obtained from t by replacing its variables by their t7-image. Thus from now 
on, to avoid possible confusion, (complex) J-terms can not be discussed any longer. 
The notation tt7, with t7 now a substitution, is subsumed by the one in which t7 is an 
assignment; letting J := T M be the algebra of all terms, the two notions collapse into 
one. 
By our basic assumption, HU c J. Extend the language of J by adding every element 
of .J - HU as a new constant symbol. 
Definition 6.5 
(i) An atom r(al, ... , an) with al,"
" an E J is called J-ground. Variable-free expres­
sions which contain only terms from J are called J -ground as well. 
(ii) Let A := r(tb . . . , tn) be an atomic formula. A J-instance of the atom A is a 
J-ground instance AO' = r(tIO', .. . , tn(7) of A where t7 is a J-assignment for the 
variables in A. 
(iii) If <p is a quantifier-free formula and t7 a J-assignment for its variables, then <pO' is ob­
tained from <p by replacing every atomic subformula A by AO'. If C = (AI, .. . , Ak) 
is a query, then CO' = (AI 0', •
•
•
 , AkO')' 
(iv) The Herbrand base over .J (relative to a set of relation symbols), notation: H BJ, 
is the set of all J-ground atoms. 
• 
Note that H BJ extends the ordinary Herbrand base H B. 

Infinite Derivations 
125 
Definition 6.6 Let J be an algebra the (algebraic) language of which is L. Suppose 
that L' ::> L is obtained by adding a finite number of relation symbols to L. The L' -model 
M is a model over J if it has the same universe and interprets symbols from L in the 
same way. 
• 
Thus, a model over J simply is obtained by adding to J some relations over its universe. 
Adding structure to a model without changing its universe or previously existing structure 
is called expanding it; the new model obtained is an expansion of the old one, while the 
old one is a reduct of its expansion. 
Recall that a model over H A - a Herbrand model - is identified with the set of 
atomic sentences in H B true in it. Similarly, a model over the CET-algebra J can be 
identified with the set of J-ground atoms from H BJ true in it. 
We can now generalize the definition of the immediate consequence operator relative 
to a program to this extended context. 
Definition 6.7 Let P be a program. Tt is the operator mapping subsets of H BJ to 
subsets of H BJ that is defined by: 
• Tt(X) := {AEHBJI for some C c X, A+-C is J-instance of a P-rule}. 
• 
Note that Tt still is a finitary (Definition 4.23), monotone operator. Therefore (cf. 
Chapter 4), it has a least fixed point Tt i and a greatest fixed point Tt L which both 
are models of P; there are upward and downward hierarchies with their stages Tt r ƒ and 
Tt ! ƒ of which these are the limits, and the upward hierarchy stabilizes after w steps: 
Tti=Ttiw. 
Exercises 
A function h : I--+J from the algebra I into the algebra J is a homomorphism if 
(i) h(cI) = cJ for every constant symbol c (c1 and cJ the interpretations of c in J 
resp. J) 
(ii) h(fI (aI, ... , an)) = e (h(al)'" . , h(an))) for every function symbol f and elements 
al,"" an E I (f1 and e interpreting f in I resp. J). 
6.1 Show: 
(i) IN + 71, is a CET-algebra, 
(ii) IN + 'lL is a model of DCA, 
(iii) every CET-algebra for the language {o,s} can be homomorphic ally mapped into 
IN + 'lL. 

126 
Chapter 6 
6.2 Consider the algebra J 
= IN + 'l. Let P consist of the two rules N(o) <- and 
N(sx} +- N(x). Determine Tt T and Tt t· 
Add the rule q(o) +- N(x). Determine the resulting fixed points and their approxima­
tions. 
Determine least and greatest fixed points for some other programs relevant to this alge­
bra. 
6.3 Again, consider the case of one individual constant and one unary function symbol. 
Show that there are only count ably many non-isomorphic CET -algebras corresponding 
to this language. 
What about the case that has one constant and two unary function symbols? And what 
if there is a binary function symbol? 
Exercise 4.5 contains the simplest of examples, showing that a (necessarily non-ground) 
atom true in M p does not need to follow from P - The following exercise shows that 
extending the Herbrand universe may remedy this defect. A ground version of (part of) 
it occurs in Exercise 4.10. 
6.4 Let V be the set of all variables and put J := H A(V) (Definition 6.3). Show that for 
every program P and atom A (which may contain variables) the following are equivalent: 
(i) PpA, 
(ii) Tt TpA, 
(iii) A has an implication tree (see Definition 4.9). 
Hint. Warning for the different roles variables play in this context. 
The next exercise (together with the previous one) provides an alternative proof for 
Corollary 5.47. 
6.5 Suppose 1i is an implication tree for AiO" (i = 1, .
.
. , m), where C = (AI, .
.
.
 , Am) 
is a query (CO" is allowed to contain variables). Let n be the total number of nodes 
in T1, .
. . , T m' Let p be any selection rule. Show that a successful p-derivation for C 
exists of length n, which has a computed answer substitution 0 such that for some 7, 
CO" = C07. 
Hint. Show by induction on k S; n that a derivation Co 
= C } .
.
. | Ck, a 
substitution O"k and implication trees for the atoms in CkO"k exist such that the total 
number of nodes in these trees is n - k and CO" = COl' .. Okak. 
6.3 
Resolution over Non-standard Algebras 
Let a program P and a CET-algebra .J be fixed. We are going to relativize the notions 
of resolvent and derivation to J. Next, we shall consider the lifting of such derivations. 

Infinite Derivations 
127 
Definition 6.8 
(i) The J-ground query D is called a J -ground resolvent of the J-ground query C with 
respect to the atom A of C and the rule R, if for some M, A+-M is a J-ground 
instance of R, and D = C {AIM} is obtained from C replacing A by M. 
(ii) A J -ground derivation with respect to the program P is a sequence of successive 
J-ground resolvents with respect to the rules of P. 
• 
We employ the, by now familiar, arrow notation for J-ground resolvents and derivations. 
If from the context it is clear that by C ɝu D a J-ground unrestricted resolution step 
is meant, we omit E and the subscript 'u' and just write C --+ D. 
The J-assignment u is said to unify the expressions (terms or atoms) sand t over 
J if su = tu. Note that unification tout court is nothing but unification over the term 
algebra TM. 
Recall Lemma 3.69, according to which every two terms that unify over some CET­
algebra J unify (over TM). (In fact, if u : Var(s, t) --. J unifies the terms s and t, then 
an idempotent mgu () of sand t exists such that u = (}u on Var(s, t).) This observation 
allows us to extend the resolution-machinery, that is, ordinary resolution ("over T M" ), 
to resolution over an arbitrary CET-algebra. As a result of this, J-ground resolution 
steps can be lifted. 
Lemma 6.9 (One Step Ground Lifting) Suppose that Cu is a J-ground instance of 
the query C. Let D be a J -ground resolvent of Cu with respect to the atom Au and the 
rule R. Then: 
9 
(i) C has a resolvent --+ D+ with respect to A and R,' and 
9 
(ii) for every resolvent --+ D+ of C with respect to A and R there is a J -assignment 
T for which 
(a) u = (}T on variables from Var(C) (commutation), 
(b) D = D+ T (instantiation). 
Proof. (i) Suppose that C = (A, K); R = B +-M and Au = Bu', u' is a J-assignment 
for the variables in R. Let e be a renaming for B such that Var(A) n Var(Be) = 0. 
Let 0 undo this, Le., let Beo = B. Now, Au = Bu' = Beou', and it follows that A and 
Be unify over J by the assignment 'Y for which 'YjVar(A) = oIVar(A) and 'YjVar(Be} = 
(ou')jVar(Be). By Lemma 3.69, A and Be unify (over TM). For the rest of the proof, 
see the proof of Lemma 5.21. 
9' 
(ii) The proof of (i) produces a resolvent --+ D' of C and a J-assignment T' such that 
u = (}'T' on Var(C) and D = D'T'. However, the two resultants D'--.C(}' and D+--.C(} 

128 
Chapter 6 
are variants of each other; in particular , a exists such that (D+ -COla = D'-CO'. Now, 
define r := ar' 
I 
There are two ways of looking at lifting J-ground derivations: one syntactical and one 
more model-theoretic. It is useful to have them both. The model-theoretic approach 
uses the notion of realization. 
0'1 
Q2 
Definition 6.10 Suppose that x : Co --+ C1 --+ C2··• is a derivation. Recall No-
tation 5.36 according to which ai,j 
= ai+l ... aj (i < j). The sequence of J-assignments 
u: aO, aI, a2, •
•
•
 (of the same length as x) realizes x in J if for all relevant i < j we 
have that ailVar(Ci) = (ai,jaj)lVar(Ci). 
I 
Thus, realization of ˇ by u just means that a suitable commutation property is satisfied. 
Example. 
Language: {o,s,r} . 
Consider the rule r(sx) ;.-r(x) . If u: aO, aI, (72, ... 
{x/Sx} 
{x/Sx} 
realizes the infinite derivation rex) --+ r(x) --+ r(x) ··· in J, then we must have 
(7°(x) = 8a1 (x) = 88a2(x) = .. , = 888 ... in J (8 = sJ) ; in particular, J must (up to 
isomorphism) contain IN + 7l. 
I 
Note that the notion of lift makes sense for J-ground derivations. The following the­
orem collects all we need about lifting such derivations and realizability. In particular, 
parts (ii) and (iii) show the close relationship between J-realizability and lifting a J­
ground derivation. 
Lemma 6.11 (Lifting Ground Derivations) 
(i) Let a be a J-assignment for the variables of the query; C. Every; (finite or infinite) 
J-ground derivation starting from Ca has a lift starting from C. 
81 
(ii) If the derivation x : Co --+ C1 ... lifts the J -ground derivation r: Do = 
Coa --+ Dl--+ D2 . ", then a sequence u: aO = a, (71, a2, . .. of J -ground 
substitutions exists such that 
• 
u realizes ˆ in J (commutation) 
• for all (relevant) i: Di = Cia; (instantiation). 
(iii) If the sequence of J -assignments u: aO, aI, a2, .
.
•
 realizes the derivation x : 
Ih 
° 
1 
Co --+ C1···, then xu; Coa --+ CIa --+ C2a2 ... is a J -ground deriva-
tion of which x is a lift. 
(iv) Every; finite derivation lifts a HU -ground derivation. 
(v) Every infinite derivation is realized in some CET-algebra. 

Infinite Derivations 
129 
Proof. (iii). By inspection. 
(i}/(ii). These are the J-modifications of the Lifting Theorem. Compare the one-step 
case Lemma 6.9. 
81 
On 
(iv). Let A: Co ---. ... ---. Cn be a finite derivation. Choose an arbitrary substitu-
tion an ground for all variables in V ar( Cn) and all variables released somewhere along 
A. Define, for j < n, the substitution aj by aj := (}j,na". Clearly then, for i < j < n: 
ai = (}i,nan = (}i,j(}j,nan 
= (}i,jaj. I.e., the sequence aD, ... ,an realizes A in HU. The 
ground derivation lifted is Coao --+ . .. ---> Cnan. 
01 
(v). 
Let A: 
Co --+ C1··· be an infinite derivation. 
Assume that Var(Co) = 
{Xl, ... ,Xk}. 
Choose new constant symbols Cl, . . .  ,Ck. For every n E lN, we can 
construct a sentence !.pn (involving the new constant symbols but no relation sym­
bol) that is true in the expansion (J, al, ... , ak) of an algebra J (ai interpreting Ci 
for i = 1, ... k) iff the initial Ao,n of A is realized in J by a sequence of assignments 
starting with {xI/al, ... , Xk/ak}. By (iv), for every n there is an expansion of HU sat­
isfying (!.pl! ... , !.pn-l and) !.pn. By the Compactness Theorem 3.41, we can satisfy all of 
{ !.pI , !.p2, !.p3, •
.
•
 } in a model of the CET -axioms. 
• 
There is an algebraic construction (a direct limit of algebras HA(Vi) induced by the 
specializations of the given derivation) for an algebra I satisfying Lemma 6.11(v), avoid­
ing first-order compactness. See Exercise 6.6. 
Exercise 
6.6 Let A: Co { C1··• be an infinite derivation. 
Make disjunct copies TERMi of the sets TERM(Vi) (i E lN, TERM(Vi) 
= {t I 
Var(t) c Vi}, Vi being the set of variables occurring up to the i-th stage of the derivation) 
by defining TERMi := ((t,i) It E TERM(Vi)}. Tm is the union of all those copies. 
Define the relation f'V on Tm by 
(t, i) f'V (s,j) := 3k 2: i, j : t(}i,k = S(}j,k. 
Check that this is an equivalence. Tm/ f'V is the quotient of Tm modulo f'V consisting of 
all equivalence classes l(t,i)I:= {(s,j) I (s,j) f'V (t, i)} . 
Tm/ f'V is turned into an algebra J by defining interpretations for constant and function 
symbols as follows: 
• cJ := l(c,O)I, 
• fJ (I(tt, idl, ... , I(tn, in)!) := l(f(tl(}i1,k.···, tn(}in,k}, k)l, 
where k := max{i1,···, in}. 
(i) Show that this definition does not depend on the representatives chosen. 

130 
(ii) Show that e (I(tl, i)I,·.·, l(tn, i)l) = I(f(tl,"" tn), i)l· 
(iii) Show that J is a CET-algebra. 
(iv) Define (1i : Vi ... J by: (1i(X) := l(x,i)l· 
(a) Show that for every term t E TERM(Vi): tui = j(t, i)l. 
Hint. Induction with respect to t. 
(b) Show that the sequence (10, (11
, (12, .
.
•
 realizes  in J. 
6.4 
Realization Trees 
Chapter 6 
Let a program P be fixed. Suppose that T is the SLD-tree of all P-derivations from a 
query C relative to some selection rule. Let (1 be a J-assignment for the variables of C. 
Definition 6.12 GRD(T, J, (1), the realization tree over J relative to T and (1, is the 
tree the paths through which are all sequences u: (10 
= (1, (11, q2, .
•
•
 of J-assignments 
starting with (1 and realizing a derivation from To 
• 
Note that, by Lemma 6.1l(ii!iii), we can define GRD(T, J, (1) equivalently as the tree 
of J-ground derivations r : Cu -- ... that possess a lift in T. In the sequel, we shall 
take the viewpoint that is best suited for the situation at hand. 
If T is infinite, then, by Konig's lemma, it must have a branch. Nevertheless, J need 
not realize any of the branches through T, and hence, GRD(T, J,(1) need not have 
branches; i.e.: GRD(T, J, (1) may very well be well·founded. 
The theorems following give a complete picture of the situation. Let us give an example 
first. 
Example. HU = IN. P has two rules: r(sx) +- r(x) and q(o) +- r(x). The initial query 
is q(o). There is no selection·rule problem for this situation: T has one branch 
E 
{x/sx} 
{x/sx} 
q(o) -- r(x)-- r(x)--. r(x) -+ . . .  
(i) GRD(T, IN, e) has branches of every finite length, corresponding to the ground re­
solvents r(O), r(l), r(2), . . . of q(O). E.g., q(O) -- r(l)-- r(O) is the IN·ground 
derivation of length 2. However, there is no infinite branch; the realization tree is well· 
founded. 
(ii) On the other hand, GRD(T, IN + ɜ,E) does have infinite branches as well; just lift 
the infinite IN + 7l-ground derivation 
q(O) ---. r(O')--+ r(-l')- r(-2') ... 

Infinite Derivations 
131 
Therefore, it is non-well-founded. 
• 
The following is a symmetric form of soundness and completeness for this extended 
context. 
Theorem 6.13 (Success) 
Let T be an SLD-tree for the query Go and let a : V are Go) -t J be an assignment. The 
following are equivalent: 
(i) GoO" C Tt 1 ; 
(ii) GRD(T, J,a) contains a J-ground success. 
Proof. For the implication (i) => (ii), see Exercise 6.5. 
I 
The height of a well-founded tree is measured by an ordinal; see Definition 1.18. To 
have infinite height means to be either well-founded of height ˅ w or to be non-well­
founded. 
A (finite or infinite) derivation A : Go z G1 y G2 --+ 
.
. . is fair if, for every 
i and every atom A occurring in Gi, there exists j 7 i such that AOi+l '" OJ is the 
selected atom of Gj• Thus, every success is fair, but a finite failing derivation isn't. A 
selection rule is fair (Definition 5.43) if every infinite derivation produced by it is fair. 
An SLD-tree is fair if it is produced using a fair selection rule. 
The following theorems constitute symmetric results on failing queries. 
Theorem 6.14 (Finite Failure) 
Let T be an SLD-tree for the query Go and a: Var(Go) -t J. 
(i) Suppose that Goa rt Tt 1· If Goa C Tt lw, then GRD{T, J, a) has infinite height . 
(ii) Suppose that T is fair. Then, conversely: 
if GRD(T, J,O") has infinite height, then Goa C Tt lw. 
Theorem 6.15 (Infinite Failure) 
Let T be an SLD-tree for the query Go and a: Var{Go) -t J. 
(i) Suppose that Goa rt Tt 1· If Goa C Tt L then GRD(T, J, a) is not well-founded. 
(ii) Suppose that T is fair. Then, conversely: 
if GRD(T, J, a) is not well-founded, then Goa C Tt 1· 
The proofs of these results are similar. However, we begin with the last one since it is 
slightly easier. 
Proof of 6.15. 
(i) Assume that Do .- Goa C Tt 1. We have to produce an infinite branch through 
GRD(T,a). 

132 
Chapter 6 
We employ the definition of GRD(T, l, a) in terms of l-ground-derivations. Simulta­
neously, produce an infinite derivation 
through T and a l-ground derivation 
r: Do ɛD1 ---+D2 -t . . .  
of which D. is a lift, such that, for all i, we have Di C Tt 1 and Di ct. Tt i· 
To start with, we have Do = Coa C Tt 1 and Do ct. Tt i by hypothesis. 
91 
9, 
Suppose now that rO,i : Do -- . . .  -t Di and its lift D.O,i : Co -> . .. -- Ci 
have been constructed up to and including stage i such that Di C Tt 1 and Di ct. Tt i· 
Note that Ci cannot be empty, otherwise, Di would be empty as well and we would 
have that Di C Tt i· 
T selects an atom in Ci. Let A be the atom of Di corresponding to it. Since A E 
Di C Tt 1 = Tt(Tt 1), Di has a l-ground resolvent DHI with respect to A such that 
Di+1 C Tt 1. And if A-L is the rule-instance employed and A fj. Tt 1, then L rt. Tt j. 
So, Di+l rt. Tt i· By Lemma 6.9, this l-ground resolution transition can be lifted to a 
8i+1 
resolvent ---+ CHI of Ci in T. 
(ii) Now we employ the definition of the realization tree in terms of realizing sequences. 
Suppose that 
81 
82 
83 
D. : Co ---+C1 ---+C2 --+ . . .  
is an infinite derivation through T, realized in 1 by the sequence u: aO 
= a, a1, a2, .... 
Define the model X over 1 by: X := {AaiiA E Ci}. It suffices to prove the 
Claim. Xc Tt(X). 
For then, since Tt 1 is the greatest post-fixed point, we have that Xc Tt 1, and the 
required result follows. 
To prove the claim, suppose that Aai E X, i.e., A E Ci. We have to show that 
Aai E Tt(X). Since T is fair, at some stage Cj ( j ˄ i) the descendant of A at that 
stage, which is ABi,j, must be selected. Then for some instance B - K of a P-rule, 
ABi,j+1 = ABi,jBj+l = Band K is part of CHI. By definition of X we have KaHl eX. 
Therefore, BaHl E Tt(X). However, Aai = ABi,H1aHl = BaHl 
I 
Proof of Theorem 6.14. 
(i) Assume that not Coa C Tt i and Do := Coa C Tt lw. Fix a natural number n. We 
show that GRD(T, J, a) has a path of length at least n. 

Infinite Derivations 
133 
Simultaneously, produce a derivation 
through 7 and a J-ground derivation r : Do þ ... ÿ Dn of which 6. is a lift such 
that for all j S n, the condition 
[j ): 
is satisfied. 
By assumption, Do = Goa c Tp!w c Tp! n; which means that we do satisfy the initial 
requirement [ ° ). 
Suppose that 6. and r have been constructed up to and including stage i < n, satisfying 
[j J for every j S i. If Gi is empty, then Di is empty as well and we have a J-ground 
refutation of - Goa. That would entail Goa c Tfo i, contrary to hypothesis. Therefore, 
Gi is non-empty. 7 selects some atom in Gi. Let A be the atom in Di that corresponds 
to it. Since by [ i J we have A E Di C Tfo! (n - i) and n - i > 0, Di has a J-ground 
resolvent DHl with respect to A such that Di+1 C Tfo! ( n -i-I). By Lemma 6.9, Gi 
has a resolvent v Gi+1 in 7 lifting this J-ground step, as required. 
(ii) Let 7' be the subtree of 7 consisting of all derivations 6. that possess a realization 
in GRD(7, J, a). By assumption, 7' has infinite height. Since 7' is finitely splitting, by 
Ih 
Konig's lemma it must have an infinite branch 6.: Go Ā G1 .... 
Fix n. We show that Goa C Tfo ! n. 
By fairness, choose indices mo 
= ° < m1 < . . . < mn (in that order) such that (a 
descendant of) every atom in Gm; has been selected in 6. before stage mi+1 (i < n) . 
Choose u: aO = a, ... ,am" realizing 81, ... ,8m". 
Claim. If is nand j S mi, then Gjaj C Tfo! (n -i). 
Induction with respect to n - i. 
For n - i = 0, this is trivial. 
For the induction step, assume that j S mi and A E Gj• We have to show that 
Aaj E Tfo! (n - i). By fairness, assume that A8j,k is selected in Gk. By construction, 
k < mi+1' There is an instance AOj,k+1 -L of a rule such that L is part of Gk+1. Since 
k+ 1 S mi+1, we can apply the inductive hypothesis, obtaining LO'k+l C Tfo! (n -i-I). 
But then, AO'j = A8j,k+1O'k+1 E Tfo! (n - i). 
• 
Exercises 
6.7 Let .J be a CET -algebra. A model M C H BJ over .J is called good if for every query 
G the following holds: if GO' c M for some J-assignment 0', then for some substitution 
o we have GO C M. Prove the following. 

134 
(i) If M is good, then Tu (M) is good. 
(ii) If M is good, then H B n TX(M) = Tp(H B n M). 
(iii) For all n, TX r n and TX L n are good. 
(iv) For all n, HBnTX Tn = TpTn and HB nTX Ln = TpLn. 
(v) HB nTXTw = Tptw and HB n TY Lw = TpLw. 
Chapter 6 
Hint. Here is a proof for part (i). Assume that the model M over the algebra ./ is 
good, and that for C = (Ao, ... ,Ak-d and u: Var(C) -+ J we have CucTt{M). 
By extending u, we may assume that, for i < k, Bi ý Li is a rule of the underlying 
program P such that AiU = Biu and Liu C M. By Lemma 3.69, for some substitution 
() we have, for i < k, Ai() = Bi() and u = ()u on all variables under consideration. Hence, 
Li()u = Liu c M. Since M is good, a ground substitution 'Y exists such that, for i < k, 
we have that Li()'Y c M. Therefore, Ai()'Y = Bi()'Y E Tt(M). 
* 6.8 Assume that P is a program and A E H B - Tp !. 
Relate the height of the 
realization tree corresponding to a (fair) SLD-tree for the query A to the least ordinal Q 
for which A ¢ Tp L Q. 
6.5 
The Interplay of SLD-trees and Realization Trees 
As in the previous section, we fix a program P and a CET-algebra J. 
The following is a compactness phenomenon for the present context. 
Lemma 6.16 (Adding a Branch) Let T be an SLD-tree for the query Co and suppose 
that u: Var(Co) -+ J. If GRD(T, J, u) has infinite height, then for some GET-algebra 
I:J J, GRD(T, I, u) is not well-founded. 
Proof. Assume that GRD(T, J, u) has infinite height. Argue as in the proof of The­
orem 6.14. Let T' be the subtree of T consisting of all derivations x that possess a 
realization in J starting with u. By assumption, T' has infinite height. Since it is 
81 
finitely splitting, it has an infinite branch : Co -- C1 • " . By definition of T', every 
initial sequence ()l, ... , ()n of the sequence of specializations of x is realized in J by a 
sequence of assignments starting with u. By the Compactness Theorem 3.41, the infinite 
sequence (}1, ()2,()3, ... is realized in some elementary extension I of J (Definition 3.42) 
by a sequence starting with u. But then, GRD(T, I, u) is not well-founded. 
• 
Corollary 6.17 (Pushing Up a Goal) Let C be a query and u a J -assignment for its 
variables. If Cu C TZ ! w then, for some GET-algebra I :J J, Cu c Tt !. 
Proof. Assume that Cu C Tf, !w. If Gu c Tt T, then we may take I = J. Therefore, 
assume that Cu ct Tf, T. Let T be a fair SLD-tree for C. By the Finite Failure Theorem 

Infinite Derivations 
135 
6.14(i), GRD(T, J,u) has infinite height. By Lemma 6.16, for some I :J J, GRD(T,I,a) 
is not well-founded. By the Infinite Failure Theorem 6.15(ii}, Ca C TG 1. 
• 
For Xc H BJ a model over J, X F P amounts to X being a pre-fixed point of Tf,. 
(This is the J-relativized version of Lemma 4.16.) Similarly, we can characterize post­
fixed points and fixed points using suitable sets of first-order sentences obtained from 
P. 
Lemma 6.18 There is a first-order sentence IFF(P} (not depending on J) such that, 
for X C HBJ: X F IFF(P) iJJTf,(X) = X. 
Proof. A first-order sentence IFF(P} satisfying the equivalence from the lemma may 
be explicitly constructed by the procedure from Definition 6.19. 
• 
The following definition introduces the completion of a program. 
Definition 6.19 IF(P) is the set of sentences obtained from the program P by the 
following procedure consisting of steps 1-5. 
First, fix a sequence of new variables 
Xl>X2,XS,·· . 
Step 1: Remove terms from rule heads. 
Replace every rule r{tl, ... tn} +-Bl>' .. ,Bm by r{xl, ... , Xn)+-Xl 
;:; tll\ ... 1\ Xn ;:; 
tn 1\ Bl 1\ 
•
.
.
 1\ Bm. 
Step 2: Introduce existential quantifiers. 
Transform each formula r(xl,'" ,xn)+-F obtained in the previous step into 
where YI, .. " Yk are all variables of Var{F) - {Xl>'" ,xn}. 
Step 3: Group formulas with the same head. 
If r{x)+-Fli ... ir(x)+-FI are all formulas obtained with r in their head, replace them 
by r(x)-Fl V ... V Fl· 
The formula FI V ... V FI is called the defining formula for r. 
Step 4: Handle "undefined" relation symbols. 
For every n-ary relation symbol r that does not occur in a rule head, add the formula 
r{x)-l.. (Indeed, this is the special case of 3 where 1 
= OJ of course, .i here is the 
defining formula for r.) 
Step 5: Introduce universal quantifiers. 
Replace each formula obtained by its universal closure. 
Replacing the left-pointed arrows by right-pointing implication-signs everywhere in 
IF(P), we obtain the set ONLY - IF{P). 
Next, replacing them by equivalences, we obtain the set IF F{P). 

136 
Chapter 6 
Finally, the completion comp(P) of P is the set of first-order sentences consisting of 
(i) the sentences of IFF(P) and (ii) all free equality axioms of CET. 
I 
Note that IF(P) and P are logically equivalent sets, since transformations 1-5 preserve 
logical equivalence. 
The completion of a program will play an important role in Chapter 8. It could well 
be that, for "sensible" programs P, comp(P) is what we have in mind when writing 
down the rules of P. Therefore, it is not unreasonable to use comp(P) instead of P when 
formulating soundness and completeness results. 
Note that, by Lemma 6.18, a model M satisfies comp(P) iff for some CET-algebra J, 
M is a model over J that is a fixed point of Tf,. 
Corollary 6.20 Let P be a progmm and C a query. The following are equivalent. 
(i) There is a finite failing SLD-tree for C, 
(ii) every fair SLD-tree for C fails finitely, 
(iii) for every CET-algebm I: Tx H=--,3/\ C, 
(iv) comP(P)F--,3/\ C. 
Furthermore, these conditions imply 
(v) Tp!WF--,3/\C; 
and in the case that Cis HU-ground, (v) implies the other conditions. 
The rule r(sx) +-r(x) and the query r(x) illustrate that we can have Tp !WF--,3/\ C 
without there being a finite failing SLD-tree for r(x). 
Proof. 
(ii)=>(i) Trivial. 
(i)=>(iii) Let T be a finite failing tree for C. 
Suppose that I and u are such that 
Cu c Tx!. By the Success Theorem, Ca r:t Tx i. By the Infinite Failure Theorem part 
1, GRD(T,I,a) is not well-founded. But then T cannot be finite. 
(iii)=>(ii) Suppose that T is a fair tree for C. If T contains a success with computed 
answer 0, then every HU-ground instance of CO is satisfied in Tp i c Tp L contradicting 
(iii). If T is infinite, it has an infinite branch by Konig's Lemma. By Lemma 6.11(v), 
this branch is realized in some algebra I. Since T is fair, by the Infinite Failure Theorem 
part 2, Cu C Tt L where a is the first assignment of the realization, again contradicting 
(iii). 
(iii)=>(iv) Every model M of comp(P) over some algebra I must be included in Tx!. 
(iv)=>(iii) This is immediate. 
Corollary 6.17 shows (iii) to imply (v). 
Finally, we show that (v) implies (ii) when C is ground. 
Let T be a fair SLD-tree for the ground query C that is not finitely failing. Distinguish 

Infinite Derivations 
137 
two cases. (a) T contains a success. Then C c Tp 1 c Tp 1w. (b) T contains an infinite 
derivation. 
By Lemma 6. 1 1(iv), GRD(T, HU, f) has infinite height. 
(f is the empty 
assignment.) By the Finite Failure Theorem we have, once more, C c Tp 1w. 
• 
Remark. In Corollary 6.20, the implication (i) =} (iv)-if C has a finitely failing tree, 
then comp(P)I=..,3/\ C- is known as Soundness of Negation as Failure (also, see Exer­
cise 6.17); its converse is known as Completeness of Negation as Failure. This terminology 
refers to the viewpoint that a better declarative interpretation of programs is obtained 
by referring to the completion of a program and not to the program itself. In particular, 
negative queries often logically follow from completions, whereas they never follow from 
programs. However, see Exercise 6.10. The proper context for these notions is Chapter 
8. There, the soundness-half will be generalized in Corollary 8.29. 
• 
Lemma 6.21 If J C I, then Tt 1 c T  1· 
Proof. It suffices to show that Tt! C T!(Tt 1), since T" 1 is the largest post-fixed point 
of the operator T . Now if X c HBJ, then obviously Tt(X) C Tq(X). Hence in partic­
ular Tt 1 = Tt(Tt 1) c T!(Tt 1)· 
• 
A more direct proof of the following theorem is given in Chapter 8 by Theorem 8.36. 
Theorem 6.22 For every GET-algebra J there exists a GET-algebra [ ::J J such that 
for every program P: Tr 1 = T! 1 w. 
Proof. Construct a countable sequence of CET-algebras Jo 
= J C J1 C J2 C ... such 
that for all programs P, atoms A, and 0': Var(A) --+ In, we have: if for some I::J In we 
have AO' E T!lw, then AO' E T£n+l 1· 
In constructed, In+l is taken to be the union of a sequence of algebras of length Pnl 
produced by Lemma 6.16. By Lemma 6.21, once an instance AO' has been maneuvered 
into a greatest fixed point, it remains there upon extending the algebra any further. 
Now, just let I be the union of the In· 
To see that T~ 1w C Tw 1, assume that AO' E T& 1w. For some n, we have 0' : Var(A)--+Jn. 
By construction, AO' E T£n+l 1. Therefore, AO' E Ts 1· 
• 
Exercises 
6.9 Let P be a program and C a clause. Show: if comp(P) 1= 3/\ C, then P 1= 3/\ C. 
Also, show: if comp(P) 1= 'V /\ C, then P 1= 'V /\ C. 
6.10 Consider the following rules. 
p(o) +-
p(x) +- p(ssx). 

138 
Chapter 6 
Characterize the fixed points of the consequence operator associated with this program. 
Construct the completion of it. Show that neither p(80) nor -,p(80) logically follows 
from the completion. 
6.11 Motivated by the previous exercise, let us call comp(P) weakly complete if for every 
ground atom A, either comp(P)pA or comp(p)p-,A. 
Show: if Tp i = Tp !w, then comp(P) is weakly complete. 
Prove, or give a counter-example to the implication: if Tp i = Tp1, then comp(P) is 
weakly complete. 
6.12 HU = IN. P consists of the following rules. 
r(o, 880) <-
r(8x, sy) <- r(x , y) 
r(x, 8SY) <- r(x, y). 
(i) Construct comp(P). 
(ii) Show that comp(P) p -,r(s80, 8S80) . 
(iii) The interpretation r of r in the model Mp is transitive. Show that the sentence 
VxVyVz[r(x, y) 1\ r(y, z) -- r(x, z)J that expresses transitivity does not logically 
follow from comp(P). (Cf. Exercise 4.40.) 
Definition 6.23 Let .J be a CET-algebra for a language containing 0, 8 and [ . I . J. 
Suppose that 1 : IN--HU (e.g., 1 might be a number theoretic function). The element 
a E J represents f if for some (by the CET-axioms, unique) sequence ao = a, a I , a2 , ' "  E 
J we have, for all i: ai = [1(i)lai+d. 
I 
If a represents 1, then, in some sense, we thus have: a = [1(0) , 1(1), 1(2), . .
. J .  
6.13 Show that every number theoretic function is represented in some CET-algebra in 
the sense of Definition 6.23. 
6. 14 Assume that the program P defines the function 1 : IN--HU in the 2-ary relation 
symbol f. Show that P can be extended to a program (using a new unary relation 
symbol q) that, confronted with the query q(z), produces an infinite derivation 6. with 
the property that, for every algebra J and every sequence of assignments aO, •
•
•
 realizing 
the specializations of 6. in J, zaG represents 1 in J. 
Hint. Consider the rules 
r(x, [Ylz]) <-f(x, y), r(8x, z) 
q(z) <-r(o, z). 
6. 15 Concoct a notion of representation for number theoretic functions using only the 
constant A and the two succesSOr functions So and 81 . Modify the previous exercises for 
this setting. 

Infinite Derivations 
139 
6.16 Let J := IN + 'l. Show: for every program P, we have that Tt ! = Tt t w. 
6.17 Give a direct, simple proof that comp(P)F-,3 /\ C for every query C with a finitely 
failing tree. 
Hint. Use induction with respect to the height of a finitely failing tree. (This proof does 
not use at all the fact that the derivations of the tree satisfy [ t J.) 
6.6 
Notes 
The closed world assumption was introduced by [Reiter 78) . In [Clark 78J it is argued 
that it is comp( P) , not the program P itself, that provides the real meaning of P and 
that, for " sensible" programs P, comp(P) is what we have in mind when writing down 
the rules of P. If "sensible" here means that Tp T = Tp L i.e.: Tp has exactly one fixed 
point, this sounds reasonable. But if Tp has several fixed points, then comp(P) (which 
"axiomatizes" fixed points by Lemma 6.18) cannot fix the meaning of P In particular, 
comp(P) does not axiomatize Mp-truth. If we want to axiomatize the notion of least 
Herbrand model, there are rather obvious induction schemas to be added to comp(P). 
The material from this chapter is mainly from [Doets b] . 
Exercises 6.4 and 6.5, which together constitute a proof of strong SLD-completeness, 
are from [Stark 89]. 
Exercise 6.7 is from [Apt 90J. 
Theorem 6.22 is due to [Blair/Brown 90}, and so are the represent ability notion from 
Definition 6.23 and the result of Exercise 6.14. 

 
7 Computability 
7.1 
Preliminaries 
In this chapter it is shown, among other things, how to compute an arbitrary recursive 
function by means of a logic program. 
As a corollary, recursive complexity of least 
Herbrand models for logic programs is identified. Contrasting to this, it is shown that 
greatest fixed points Tp 1 can be very complex. 
For the basics of recursion theory, the reader is referred to the literature. The funda­
mental notions run as follows. In standard recursion theory, the basic domain of objects 
is IN, but we take a more general stand. In the following, D is any domain of concrete 
objects. Usually, D = HU. with D ::= IN as special case. Sometimes, D::= H B. 
In this chapter, it is always assumed that the language £ is finite and that there is a 
function symbol present. 
Definition 7.1 
(i) An n-ary relation R C Dn is decidable if there is a decision method for membership 
in R that, when applied to an arbitrary n-tuple s from Dn, after a finite number 
of steps terminates with output 'yes' if R(S) is true, and with 'no' if R(S) is false. 
(ii) An n-ary relation R C Dn is positively decidable if there is a decision method for 
membership in R that, when applied to an n-tuple s from Dn, after a finite number 
of steps terminates with output 'yes' iff R(S) is true. (It mayor may not terminate 
and output 'no' when R(S) is false, but of course it will not output 'yes' in that 
case.) 
(iii) An n-ary function F : Dom(F) ... D such that Dom(F) C Dn is called calculable 
or computable if there is an algorithm ʊuch that for every sequence s E Dn 
(a) the algorithm terminates on input s iff s E Dom(F); 
(b) if s E Dom{F) then, on input S, the algorithm outputs the value F{S). 
• 
We sometimes also admit relations and functions of mixed types and extend the defi­
nitions to these contexts. E.g., we might have that R C IN x HU, F : IN ... HU. etc. 
It trivially follows from the definitions that every decidable relation is positively de­
cidable. 
As we shall see (cf. Exercise 7.8), partiality is an essential ingredient of the theory of 
calculability. Therefore, the notation F : Dn -+ D henceforth allows for the possibility 
that Dom(F) '" Dn In the case that Dom(F) = Dn, we shall leave no doubt about this 
circumstance and call F total. 

142 
Chapter 7 
By the assumption that at least one function symbol is present, there is a representation 
of IN in HU. For, let c be an individual constant and f a function symbol. Then the 
equations 
rep(O) 
= 
c 
rep(n + 1) 
f(rep(n), . . . , rep(n)) 
recursively define an injective map rep: IN -- HU representing IN. In the following, IN 
may refer to the set of natural numbers, or to a Herbrand universe generated from one 
constant and one unary function symbol, or to a representation of the natural numbers 
of the type indicated in any Herbrand universe. 
An important coding ingredient is given by the following lemma. 
Lemma 7.2 There exists a computable bijection j : lN2 -- IN with computable left- and 
right-inverses j1 and h, i.e., such that for all p E IN we have j(j1 (p), i2(p)) = p. 
Proof. Let p E IN, p =I O. There are p pairs (n, m) E lN2 such that n + m = p - 1. It 
follows that the number of pairs (n, m) such that n+m ::; p-1 is 1+2+· '+p = =p(p+1). 
Define the linear ordering -< on lN2 by 
(n',m') -< (n,m):= n' +m' < n+m, or: tn' +m' 
= n + m 1\ m' < m]. 
Then (n, m) has = (n + m) (m + m + 1) + m predecessors in this ordering. Therefore, the 
map j defined by j(n, m) := *(n + m)(n + m + 1) + m is a bijection as desired . It is left 
to the reader to check that j1 and i2 are computable. 
• 
Next, the computable pairing can be used to computably enumerate the domains we're 
interested in. 
Lemma 7.3 There are computable bijections gnr : HU -- IN and gnr' : H B -- IN with 
computable inverses tm and at. 
. 
Proof. N.B.: 'gnr' stands for 'G6del number'. G6del (in his proof of the incompleteness 
theorems) was one of the first to employ an enumeration of syntactic objects. 
We consider one example only. Cf. also Exercise 7.4. Let HU be generated by the 
constants 0, A, the unary function symbol s and the binary one [ . I .]. 
We let gnr(o) = 0 and gnr(A) 
= 1. From the remaining numbers> 1, we reserve 
the even ones as values of terms s(t) E HU, the odd ones we reserve as values of terms 
[sit] E HU. 
It is now clear that the following equations recurSively establish the desired bijection: 
(i) gnr(o) = 0, gnr(A) = 1 
(ii) gnr(s(t)) = 2gnr(t) + 2 

Computability 
143 
(iii) gnr(lslt]) = 2j(gnr(s),gnr(t)) + 3. 
Since j has computable inverses, it is easy to see that the inverse of gnr is computable 
asˎ 
I 
Recall the notion of the graph of a (partial) function (which is the relational represen­
tation of the function) from Definition 4.29. 
Here is a simple relationship between calculability and positive decidability. 
Lemma 7.4 The k-ary partial function F : Dk --+ D is calculable iff its graph is posi­
tively decidable. 
Proof. Assume that D = HU. 
Only if: assume that F is calculable. To positively decide the relation F(B) = t, first 
calculate the value of F(B). If the calculation terminates, it produces the value F(B). 
Now, compare this value with t. 
If: assume that F has a graph that is positively decidable by means of a method M. 
Given a sequence of arguments s, let M work for some time on the problem of whether 
F(B) = tm(O). If it terminates with yes, we know that F(B) = tm(O). If not, give it 
some time to figure out whether F(B) = tm(!). If it terminates with yes this time, 
we know that F(B) = tm(!). If not, we give it some more time to figure out whether 
F(B) = tm(O), and, if need be, whether F(B) = tm(!) or maybe F(B) = tm(2). If a 
positive decision is not reached yet, give it yet more time for working on the questions of 
whether F(B) = tm(O), F(B) = tm(l), F(B) = tm(2) or F(B) = tm(3). If we go on this 
way (letting M work longer and longer on more and more possible answers), eventually 
the function value (if there is one) must turn up. 
I 
The following theorem establishes positive decidability of two subsets of the Herbrand 
base related to a program: its least Herbrand model and its finite failure set. 
Theorem 7.5 For every program P, Mp and H B - Tp!w are positively decidable. 
Proof. A decision method ascertaining positive decidability of Mp is (ground) resolution. 
That H B - T p ! w is positively decidable follows immediately from the characterization 
of finite failure, cf., e.g., Corollary 6.20 of Chapter 6. 
• 
Recall the notions of program definability for relations and functions, Definition 4.29. 
As an easy consequence of the previous result, we have the following lemma. 
Lemma 7.6 
(i) Every program definable relation is positively decidable. 
(ii) Every program definable function is calculable. 

144 
Chapter 7 
Proof. See Exercise 7.5. 
• 
The next section is devoted to proofs of converses of this lemma. 
Lemma 7.7 A relation R c Dn is decidable iff both R and its complement Dn - R ar£! 
positively decidable. 
Proof. If: combine the two decision methods into one. 
Definition 7.8 The program P is called determinate if Mp = Tplw. 
Corollary 7.9 If P is determinate, then Mp and Tp lw are decidable. 
Proof. Immediate from Lemma 7.7 and Theorem 7.5. 
The following presents some standard characterizations of positive decidability. 
Lemma 7.10 For R C HU (resp., R C H B), the following are equivalent: 
(i) R is positively decidable (as a unary relation), 
(ii) R is the domain of a calculable function, 
I 
I 
I 
(iii) either R = 0 or R is the range of a calculable function F for which Dom(F) = IN, 
(iv) for some decidable relation S C IN x HU (resp. S C IN x H B) we have the equiva-
lence s E R ɴ :3n : Sen, s). 
Proof. Assume that R c HU. 
(i)=>(ii). Let t E HU be arbitrary. A function satisfying (ii) is {(s, t)jR(s)}. 
(ii)=>(i). Assume that R = Dom(F) for some calculable function F. To decide whether 
R(s), calculate F(s). Now, R(s) holds iff a function value is found. 
(i)=>(iii). Suppose that R is a non-empty set with a positive decision method M. Fix 
an arbitrary t such that R(t). The required function F is defined by 
F(n) 
= { tm(j2(n») Kf M ascertains R(tm(i2(n») within jl(n) steps 
t 
If not. 
(iii)=>(i). Suppose that F enumerates R. In order to positively decide R(s) for a given 
s, just start generating F(O), F(l), F(2), ... . Clearly, R(s) holds iff s turns up in this 
sequence. 
(iii)=>(iv). Let R = Ran(F), Dom(F) = IN. Note that IN, and hence the graph of F. is 
decidable. We have that s E R ¢:? :3n[n E Dom(F) 1\ F(n) = s], and the right-hand side 
of this equivalence has the required form. 
(iv)=>(ii). Assume the equivalence s E R ¢:? :3nS(n, s). Just define the required function 
F by letting F(s) be the least number n such that Sen, s) . 
Obvious modifications prove this lemma for R C H B. 
I 
The following simple existence result is one of the cornerstones of the theory. 

Computability 
145 
Theorem 7.11 (Turing) There exists a relation that is positively decidable but not de­
cidable. 
Proof. Note that there is a problem here of a methodological nature. Experience shows 
that we can always recognize a decision method as such. We have just seen some instances 
of this phenomenon. However, in order to be able to give a precise proof that for a 
certain set no decision method exists, we need a precise definition of decision method. 
'lUring was the first to provide such a (well-motivated) definition (in terms of his 'lUring 
machines) and prove the present theorem. The following sketch makes clear what the 
basic ingredients for such a definition should be. 
We may assume that a decision method can be described in a formal way. In fact, we 
shall assume that one Herbrand universe HU exists such that every method is described 
by a term in HU. By effectively enumerating all possible descriptions, this is seen to be 
true in fact for HU = IN, although a little more structure can make life more pleasant. 
Consider the following binary relation R (the halting problem) on HU. 
R(p, e) : ::: the method described by p (if any) terminates on the input e. 
Note that this relation is in fact positively decidable: given p and e, just put the method 
described by p at work on the input e and see what happens. 
We proceed to show that R cannot be decidable. We argue by contradiction. Suppose 
that R is decidable. Consider its modification U defined by 
U(p, e) : ::: the method described by p (if any) terminates on the input e with 
output yes. 
Clearly, if R is decidable, then so is U. Also, if S is any positively decidable unary relation, 
then for some description s of a decision method for S, we have Ve[S(e) <=> U(s, e)]. (A 
relation U with this property is called universal for the class of unary positively decidable 
relations.) Now, since we have argued that U is decidable, ..,U(e, e) is decidable as well. 
Therefore, we can choose u such that Ve[--,U(e,e) <=> U(u,e)]. Then, in particular for 
e := u, we obtain ..,U(u, u) <=> U(u, u), a contradiction. 
I 
The notions of (positive) decidability and calculability as introduced here have an 
intuitive content. However, for HU = IN, there exist mathematically precise definitions 
of recursive and recursively enumerable for relations R C INn and of (partially) recursive 
for functions F : INn - IN. There is overwhelming evidence for the following 
Extended Church's Thesis. 
(i) A relation R C INn is decidable iff it is recursive, 
(ii) a relation R C INn is positively decidable iff it is recursively enumerable, 
(iii) a number theoretic (partial) function is calculable iff it is (partially) recursive. 
• 

146 
Chapter 7 
(The usual formulation of Church's thesis consists of part (iii) only.) 
There are many equivalent definitions of recursive (using machines and formal systems 
of several kinds). In the next section, such a definition is obtained in the context of the 
logic programming paradigm. The following definition is the direct number theoretic one. 
In it we use the A-notation for functions, which works as follows. IfT(X) (x = (Xl, . . .  , Xn) 
a sequence of n variables) is an expression every instance T(S) of which denotes an object, 
then the expression Ax.T(i) denotes the n-ary function that sends a sequence s to the 
object" denoted by T(S). Example: P.xy.x2 +y)(2, 3) = 7, since AXy.X2 +y is the function 
that sends a pair of numbers X, y to x2 + y. 
Finally, let T(n) be a statement involving a natural number n that may be either true 
or false or have no definite truth value at all. Then /l-m .T(m) (the least number satisfying 
T) denotes the number m such that (i) for all m' < m, T(m') is false, and (ii) T(m) 
holds. There may be no such numbers, in which case the expression has no denotation 
at all. 
Definition 7.12 A number theoretic (partial) function F is partially recursive if it has 
a recursive definition, that is, a finite list Fo, . . .  , Fq = F such that for every k ::; q one 
of the following six possibilities obtains: 
Rl. Fk = An.n + 1 
(the successor function), 
R2. Fk = AnI' .. nl.nj, where 1 ::; j ::; I 
(the j-th projection function of I variables), 
R3. Fk = An.O 
(the constant = 0 function), 
R4. for some j,l1, . . .  ,jp < k: 
Fk = AnI' .. n/.Fj(Fj1 (nI,' . .  ,nl), ... ,Fjp (nl,' . . ,nl» 
(the composition of Fj, Fh, ... , Fjp), 
R5. For some j, i < k, Fk is the unique function satisfying 
(a) Fk(nl,"" nl, 0) = Fj(nl, ... , n,) 
(b) Fk(nl,'" ,nl,p + 1) = Fi(nl,"" nl,p, Fk(nl, ... ,nl,p» 
(primitive recursion), 
R6. For some j < k, Fk = Ani'" n/./l-m[Fj(nl, ... , nl, m) = OJ 
(minimalization) . 
• 
If part (6) of the definition is left out, the class of so-called primitive recursive functions 
is obtained. These are all total functions. But note that the minimalization (6) is 

Computability 
147 
responsible for the fact that a lot of recursive functions are partial, i.e., have a domain 
that is properly included in some lNn. 
To obtain the class of total recursive functions, i.e., partially recursive functions defined 
on all tuples from IN, the definition should be augmented with the existence condition 
in part (6) that for all nl,"" nl E IN an m exists such that Fj(nl,"" nl, m) = O. 
Once we have the notion of recursive for functions, definitions for the other notions 
are motivated by Lemma 7.10 and Lemma 7.7. 
Definition 7.13 
(i) R C lNk is recursively enumerable if it is the domain of a partial recursive function. 
(ii) R C lNk is recursive if both R and its complement lNk - R are recursively enumer-
able. 
• 
In the sequel, we feel free to use the Extended Church's Thesis whenever needed. 
For instance, there are results parallel to those for (positively) decidable relations and 
calculable functions, obtained by exchanging these notions by recursively enumerable 
resp. recursive. 
Exercises 
7.1 Let IN be a representation of the natural numbers in some Herbrand universe HU 
of the type indicated. Show that IN is decidable by describing a decision method for it. 
7.2 Give a (simple) program defining the relation {(n,m,p)U(n,m) = p} on IN, where 
j is defined in the proof of Lemma 7.2. 
Hint. Consider the following rules. 
j(o, 0, 0) +-
j(x, sy, sz) +- j(sx, y, z) 
j(sy,o,sz) +-j(o,y,z). 
7.3 Produce programs defining the functions gnr and tm from the proof of Lemma 7.3. 
7.4 Suppose that HU is generated by constants a, b, c, a unary function symbol f, a 
binary one g and a ternary h. Establish a bijection between HU and IN. 
Hint. The map (n, m,p) I-> j(j(n, m),p) is a bijection: lN3 .... IN. Assign numbers 0,1,2 
to resp. a, b, c; assign numbers 3n+3 to f-terms, numbers 3n+4 to g-terms and numbers 
3n + 5 to h-terms. 
7.5 Prove Lemma 7.6. 
Hint. Use Theorems 7.5 and Lemma 7.4. 
7.6 Let P be a program. Show: Mp is decidable iff every relation defined by P is 
decidable. 

148 
Chapter 7 
7.7 Let F be calculable. Show: if Dom(F) is decidable, then the graph of F is decidable. 
Show that the converse of this is false. 
Hint. Try F(n) = m := the method described by jl(n) terminates on input hen) in 
exactly m steps. 
7.8 Show that a calculable partial function F : HU -+ HU exists that cannot be ex­
tended to a calculable function G such that Dom(G) = HU. 
Hint. Use Turing's theorem. 
7.9 Show that addition, multiplication and exponentiation are (primitive) recursive. 
7.10 Show: R c 1N is recursive iff it has a characteristic function that is recursive. 
7.2 
Computability of Recursive Functions 
In this section it is shown that recursive functions can be computed by logic programs. 
By Definition 4.7, it is seen that the first and second parts of the following definition 
are equivalent with the corresponding parts of Definition 4.29. 
Definition 7.14 Let P be a program. 
(i) P defines the relation R c Hun in the n-ary relation symbol r if 
(ii) P defines the partial n-ary function F : HUn -+ HU in the (n + 1}-ary relation 
symbol f if it defines the graph of F in f. 
(iii) P computes the partial n-ary function F : Hun -+ HU in the (n + 1)-ary re­
lation symbol f if, for all ground terms tl, ... ,tn and all terms s (possibly con­
taining variables), {y/ s} is a computed answer substitution for f(tl' .. ' ,tn, y) iff 
F(tl,"" tn) = S. 
• 
Lemma 7.15 P defines the function F in f iff it computes F in f. 
Proof. See Exercise 7.11. 
I 
Theorem 7.16 Every partially recursive function is computable over HU = 1N by some 
logic program. 
Proof. Let Fo, ... , Fq = F be a recursive definition for F in the sense of Definition 7.12. 
We construct a program for every function Fk (k $ q) in the definition, as follows. The 
construction distinguishes cases RI-6 from Definition 7.12. 
Rl. Fk = An.n + 1. 

Computability 
This function is computed in f k by the single rule 
R2. We have 1 :5 j :5 I and Fk = AnI,"', nl.nj' 
This function is computed in f k by the rule 
R3. Fk = An.O. 
This function is computed in f k by the rule 
R4. j, j1,' ,. ,jp < k, and Fk = AnI,"', nl.Fj(Fil (n!, ... , nl), . . . , Fjp(n1,"" nl)). 
149 
By induction hypothesis, assume that we have programs (which we may assume to be 
without common relation symbols) computing Fj and Fj1, ... , Fjp in the symbols fj and 
f h ' ... , f jp' Add the following rule to the rules of these programs: 
The resulting program computes Fk in fk• 
R5. Suppose that j, i < k, and Fk (which for simplicity we take to have 2 arguments) 
satisfies 
(a) Fk(n,O) = Fj(n) 
(b) Fk(n,p + 1) = Fi(n,p, Fk(n,p». 
To the rules that compute Fj and Fi in fj resp. fi (without common relation symbols), 
add the following two: 
1. A(x,o,z) +- h(x,z) 
2. fk(X, sy, z) +- !k(X, y, Zl), hex, y, z', z). 
This computes Fk in fk· 
R6. Finally, suppose that F = H, j < k, G = Fj and F = An.}.Lm[G(n, m) = 0] (for 
simplicity assuming that G has two arguments) . 
Suppose we have rules computing G in g. Define the relation H by: 
Adding the two rules 
1. h(x,o) +-
H(n, m) := 'rim' < m[G(n, m') =1= OJ. 

150 
2. h(x,sy) +- g(x,y,sz),h(x,y) 
produces a program that defines H in h. 
Now, add one more rule 
f(x, y) +- g(x, y, 0), hex, y). 
This computes F in f. 
Chapter 7 
I 
The following theorem shows that the present theory of programs forms an adequate 
approach to computability theory. 
Theorem 7.17 
(i) R C HUk is positively decidable iff R is program definable. 
(ii) F : HUk -t HU is calculable iff F is program definable. 
Proof. (ii) Let F : HU -t HU be calculable. By Church's Thesis, the number theoretic 
function F' defined by: F'(n) := gnr(F(tm(n))), is recursive. Construct a program that 
computes F'. Note that F(s) 
= tm(F'(gnr(s))). (tmF'gnr = tm gnrFtm gnr = F.) 
Construct rules computing tm and gnr (Exercise 7.3). Since F is the composition of tm, 
F' and gnr, it is program computable as well. Conversely, every program computable 
function is calculable (modulo Lemma 7.15), which is the content of Lemma 7.6(ii). 
(i) Let R C HU be positively decidable. Say, R = Dom(F), with F calculable. Let P 
compute F in the symbol f. Adding the rule rex) +- f(x,y) produces a program defining 
R in r. Conversely, every program definable relation is positively decidable, which is the 
content of Lemma 7.6(i). 
• 
Theorem 7.18 There exists a program P such that Mp is undecidable. 
Proof. Let P define an undecidable relation. 
• 
The following is the basic undecidability result in first-order logic. It is straightfor­
wardly derivable from what we have so far. 
Theorem 7.19 (Church) There is no decision method for logical validity and unsatis­
fiability in first-order logic . 
Proof. By Theorem 7.18, let P be a program such that Mp is undecidable. For a ground 
atom A, we have: p(P-tA) iff PpA iff A E Mp. Hence, logical validity of sentences 
P-tA is undecidable. 
• 
The rules R6 that compute a minimalization are not very satisfactory. Though it is 
true that if jLm[G(n, m) = OJ exists and has value p, then the rules produce a success 
for fen, y) with a computed answer substitution {yip}, the actual finding of this success 

Computability 
151 
seems to require knowledge of the value p of JLm[G(n, m) = OJ. Indeed, using the second 
h-rule over and over again will result in an infinite derivation; and we can only avoid this 
by starting to resolve the g-atoms at exactly the right time, determined by this value. 
Example: assume that 2 = JLm[G(O, m) = OJ. We get the following derivation starting 
with the initial query £(0, y): 
£ 
f(o, y) --+ g(o, y, 0) , h(o, y) 
{ll/sy} 
--+ g(o,sy,o),g(o,y,sz),h(o,y) 
{y/Sy} 
--+ g(o, ssy, 0), g(o, sy,sz), g(o, y, sz'), h(o, y). 
At exactly this spot, we use our knowledge that 2 = JLm[G(O, m) = 0], which implies that 
the {y/o}-instance of the last query can be successfully resolved; and hence, by lifting, 
that the query itself can be successfully resolved. 
Trying to resolve the g-atoms before or after this stage will fail. And finally, there does 
not seem to be a good way to find a success for the query other than the one obtained 
by lifting a success for the proper instance. 
Because of this, the following alternative R6' to the rules R6 is offered. To motivate 
this alternative, consider the relation ZERO, defined as follows. 
ZERO(n, i,j) := Vj' < j[G(n, i + j') =F OJ/\ G(n, i + j) = o. 
The following rules are valid for this relation: 
R6'. 
1. zero(x,y,o) +- g(x,y,o) 
2. zero(x, y, sz) +- g(x, y, su), zero(x, sy, z) 
3. f(x, z) +- zero(x, 0, z). 
Claim: these rules (together with appropriate ones for g) define ZERO in zero and F 
in f. 
Again consider the example where 2 = JLm[G(O, m) = OJ. We now get the following 
derivation: 
f(o,z) ѯ zero(o,o,z) 
Now, two zero-rules are applicable, producing the resolvents: 
{z/O} 
•
.
 
a. -- g(o,o,o), which falls eventually; 
b. J g(o, 0, su), zero(o, 1, z), which, since the g-atom here eventually succeeds, 
resolves to zero(o, 1, z). 
Again, there are two resolvents: 
{z/O} 
a. the failing -- g(o, 1,0), and 

152 
Chapter 7 
{z/Sz} 
b. 
ş g(o, 1, su), zero(o, 2, z), which, after resolving the g-atom, reduces to 
zero(o, 2, z). 
The first resolvent of the following two 
{z/o} 
a. Š g{o,2,o) now succeeds, producing the c.a.s. {z/2}. 
{z/sz} 
b. The other one --+ g(o, 2, su), zero(o, 3, z) must fail because of the presence of 
the g-atom. 
The upshot of this example is that the implementation R6' of the IL-operator almost 
automatically generates the desired success. A precise formulation of this is the content 
of the following theorem. 
Theorem 7.20 Suppose that F is a k-ary total recursive function and P is a program 
computing F in f constructed using Rl-5 and Rf/. For every (nl,' .. ,nk) the SLD­
tree for f( n}, .. . , nk, y) constructed using the leftmost selection rule is finite, has exactly 
one successful leaf, and the computed answer substitution corresponding to this leaf is 
{y/ F{nl"'" nk)} ' 
Proof. The theorem is an immediate consequence of the observation that for every 
(k + l)-ary relation symbol r and every nl,"
" nk E IN and term t, the leftmost SLD­
tree for r( nl, ... , nk, t) is finite, has at most one success, and, if present, this derivation 
has a computed answer substitution B such that tB E IN. 
• 
Lemma 7.21 Let P be a program. If there exists a selection rule such that every SLD­
tree for a ground atomic goal produced by it is finite, then P is determinate. 
Proof. Immediate from the finite failure-characterization, Corollary 6.20.(i) => (v), from 
Chapter 6. 
I 
Example. The converse of this fails badly. E.g., let P consist of the rules r(x) _ r(x) 
and r(x) -. Then Tpt = Tpl 
= Tplw = HB, but no selection rule can prevent the 
f 
• 
infinite derivation r(c) --+ r(c)--+ r(c) ·· . 
I 
Corollary 7.22 Every total recursive function can be computed by a determinate pro­
gram. 
Proof. Programs constructed by means of Rl-5 and R6' for total recursive functions are 
determinate. If the leftmost selection rule produces an infinite derivation starting from 
a ground atom r(n, m), this can be lifted to an infinite derivation from r(n, y). Apply 
Theorem 7.20 and Lemma 7.21. 
• 

Computability 
153 
Exercises 
7.11 Give a detailed proof for Lemma 7.15. 
7.12 Verify the necessary details of the proof of Theorem 7.16. 
Definition 7.23 A program P is called weakly recurrent with respect to the "level func­
tion" I : H B -+ IN if for every ground instance A <-C of a rule of P such that A ¢ Tp l, 
there exists aBE C with l(B) < l(A) such that B ¢ Tp r. 
• 
7.13 Show that every program constructed by means of Rl-5 is weakly recurrent with 
respect to some function l. Extend this result to programs constructed using Rl-5 and 
R6'. 
7.14 Show that a program is determinate iff it is weakly recurrent with respect to some 
function. 
Hint. Only if: use the downward hierarchy to construct the required function l. If: show 
that a fair SLD-tree for a ground atom A ¢ Mp must be finite. Use Corollary 6.20. 
Definition 7.24 
(i) A program P is called recurrent with respect to the function l : H B -+ IN if for 
every ground instance A<-C of a rule of P and for all B E C we have l(B) < l(A). 
(ii) An atom A is bounded with respect to l : H B -+ IN if {l(A') I A' a ground instance 
of A} has a maximum. This maximum is denoted by l(A). 
(iii) A query C is bounded if all its elements are. When C = (Al, ... , Ak) is bounded, 
then l(C) is the multiset of numbers {{l(Ad,.··, l(Ak)}}' 
• 
7.15 Show that every recurrent program is weakly recurrent. 
Are the programs constructed using Rl-5, R6' recurrent? 
7.16 Let P be recurrent with respect to 1. Show that if D is a resolvent of a bounded 
query C, then (i) D is bounded, and (ii) I(D) < I(C) in the multiset ordering over IN. 
C> 
Hint. 
Assume that C - D. (i) Let Dr be a ground instance of D. Let C' be 
E 
Car if this is ground, or a ground instance of Car otherwise. Then C' -u Dr and 
I(Dr) < [(C') :; [(C). (ii) Let Dr be a ground instance of D such that I(Dr) = [(D). If 
C' is as before, then l(D) = l(Dr) < [(C') :; I(C). 
Note that, by Exercise 7.16 and Theorem 1.13, no derivation starting from a bounded 
goal can be infinite. 
Definition 7.25 A program is terminating if it cannot produce infinite derivations for 
ground atomic queries (under any selection rule) . 
• 

154 
Chapter 7 
7.17 Show: a program is terminating iff it is recurrent with respect to some function 
l:HB-+lN. 
Hint. For the only-if-part: define l : H B -+ lN by putting leA) equal to the maximum 
length a derivation from A can have. 
Use Konig's lemma to see that this maximum 
always exists. 
7.18 Reconsider previously given programs and determine whether they are recurrent, 
resp. weakly recurrent. 
7.19 Consider the quicksort program of Exercise 4.60. Show that it does not produce 
infinite derivations starting with a query qs([tt, .
.
.
 , tn], t) where tl, ... , tn and tare 
arbitrary terms, and using the leftmost selection rule. 
7.20 Exercise 4.22 offers a condition on programs P that suffices for Tp to have exactly 
one fixed point: the relation -<, defined by 
B -< A iff B occurs in the body of a ground instance of a P-rule of which A 
is the head 
should be well-founded. What do you need to know about -< in order that P is determi­
nate? 
By Theorem 7.5, H B - Tp ÷w is positively decidable. The following exercise shows 
that Tp lw can be undecidable. 
7.21 For the following, assume that HU = IN. 
(i) The program Pl involves the binary r. Choose a new binary relation symbol q. P2 
is formed by adding the rule 
q(x, y) f- rex, y), q(x, sy). 
Tl and T2 are the operators of Pl resp. P2. Show that the following are equivalent: 
(a) q(n,o) E Tdw, 
(b) \1m: q(n, m) E T21w, 
(c) '<1m: r(n,m) E Tdw. 
(ii) Assume that Pl is determinate and defines the complement -.R of the relation R 
in r. Form P3 by adding to P2 the rule 
p(x) f- q(x,o). 
Let T3 be the operator of P3. Show that 
pen) E T3 øw <=> ,3m: R(n, m). 
(iii) Show: for every recursively enumerable relation S there exists a program P using 
a relation symbol p such that Sen) <=> pen) rt Tp!w. 
(iv) Show that Tp!w can be undecidable . 

Computability 
155 
7.22 Reconsider the implementation of primitive recursion, R5. 
Assume that F 
IN2-+IN is recursively defined from the functions G and H by the equations 
F(n, 0) = G(n) 
F(n,m+ 1) = H(n,m,F(n,m)). 
Assume that the program P computes G and H in the symbols g resp h. Extend P by 
the following rules. 
f(x, y, z) -g(x, v), up(x, y, 0, v, z) 
up(x, y, u, v, z) - h(x, u, v, w), up(x, y, su, w, z) 
up(x, y, y, z, z) -. 
Show that this computes F in f. What exactly is defined by up? What is the advantage 
of this implementation over the one given before? (Note that the computational or 
procedural content of these rules is much clearer than their logical or declarative content.) 
7.23 Compare the previous exercise. We can save one argument-place from up. Con­
sider the following rules. 
f(x, y, z) -g(x, v), down(x,y, v, z) 
down(x, su, v, z) f- h(x, u, v, w) , down(x, u, w, z) 
down(x, 0, z, z) -. 
Answer the same questions with respect to these rules. 
7.3 
Complexity of Tp! 
7.3.1 
Analytical Hierarchy 
The classes of recursive and recursively enumerable relations form the lowest levels of 
the infinite arithmetical hierarchy of number theoretic relations. The other levels of this 
hierarchy are defined as follows. 
Let K be a class of number theoretic relations. Then E(K) is the class of relations R 
that can be written as an existential quantification of some S E K: 
EѮ ̅s the class of recursiveHy enumerable sets and relations. The arithmetical hierarchy 
nOYl proceeds from this, by 
(i) IIÅ := {-,RjR E Er} 
(ii) EI+l := E(II&) 
(iii) A' := E& n AÅ. 

156 
Chapter 7 
A relation is arithmetical iff it belongs to some level (EF, nF) of the arithmetical hier­
archy. By Lemma 7.7, LlD is the class of recursive relations and sets. By Theorem 7.11, 
E? - n? is non-empty since it contains the halting problem. In fact, there is a Hiemrchy 
Theorem stating that nE - EG and EG - nѭ are non-empty for all n. 
Obviously, we can generalize these notions to refer to sets and relations over an arbi­
trary Herbrand universe or Herbrand base using our computable enumerations of these 
classes. We use the same notations for the hierarchies so generalized. 
Next we introduce relation arguments in program definable relations, as follows. 
Definition 7.26 
(i) Let R C HUk be an arbitrary relation. Let P be a program and r a k-ary relation 
symbol not occurring in the head of a rule of P. P(R) is the program consisting 
of (1) all rules of P and (2) all rules r(tl,' . . ,tk) <- such that R(tl, ... ,tk) holds 
(tll ... ,tk E HU). 
(ii) Extend the class E? by allowing relations of relations as follows. 
Rel(HU, k) 
is the class of all k-ary relations on HU. A relation Q c Rel(HU, k) x Hum 
is in E? if for some program P involving an m-ary relation symbol q, we have 
Q(R, tl,"" tm) {=} q(tl,"" tm) E Tp(R) t. 
• 
The previous definitions may be generalized, allowing for a finite sequence of relations 
instead of just one; we can extend all classes EG, nG and LlG admitting relations as 
arguments; and, finally, we can generalize these notions to relations on H B as well. 
Note that a program P(R) - if R is infinite - has infinitely many rules. We deviate 
here thus expressly from our convention, that programs shall be finite. Nevertheless, 
consequence operators remain monotone and fixed points exist and can be finitely ap­
proximated. 
Also, note that the relation Q of part (ii) of the definition is monotone in its relation 
argument. 
Lemma 7.27 IfQ E E?, R c R' and Q(R, tl,"" tm) holds, then Q(R', tI, . .. , tm) holds 
as well. 
• 
Admitting relation arguments in relations, we can now quantify with respect to rela­
tions and obtain a more extensive classification: 
Definition 7.28 
(i) Q c HU is in nt if, for some arithmetical S, we have that Q(t) {::::> 'VR: S(R, t). 
(ii) Et is the class of complements of relations in m. 
(iii) .t.Ä = m n EÄ is the class of so-called hypemrithmetical relations. 
• 

Computability 
157 
The previous definition gives the lowest levels of the Analytical Hierarchy, the building 
of which parallels the arithmetical hierarchy, but now uses quantification over relations 
instead of numbers. Of course, these classes also contain relations of more than one 
argument, and arguments may be relations themselves; but we have no need for these 
generalizations. 
A simple example of a hyper arithmetical set that is not arithmetical is the set of sen­
tences true in the standard model of arithmetic. It is hyperarithmetical basically because 
the recursion equations E for satisfaction in this model are arithmetical conditions with 
exactly one solution: the satisfaction relation relative to this model. Therefore, the truth 
set T for this model can be defined both by!p E T <=} 3S[E(S) I\!p E Sj, making it Et, 
and by !p E T ¢:::} 'v'S[E(S) => !p E S1, making it TIt. Finally, T is not arithmetical by 
Tarski's theorem on undefinability of truth, see Exercise 7.25. 
The a priori complexity of greatest fixed points is El: 
Theorem 7.29 For every logic program P: Tp1 E E}. 
Proof. We have: A E Tp 1 iff A E X for some X c H B such that X c  Tp(X); the 
condition X C Tp(X) is arithmetical (in fact, it is m). 
• 
As a consequence of this, greatest fixed points define relations that are EI. 
Corollary 7.30 If P is a logic program involving the k-ary relation symbol r, then the 
relation R C HUk defined by R(tb ... , tk) <=> r(tI.' .. ,tk) E Tp 1 is in Ei· 
• 
The purpose of this section is to prove the following converse. In view of the coming 
definition, we formulate it in the dual form: 
Theorem 7.31 If R C HUk is in ITt, then for some program P involving a k-ary relation 
symbol r, we have R(tl. . . . , tk) <=> r{tl,"" tk) ¢ Tp 1· 
Definition 7.32 P co-defines the relation R in the symbol r if 
R(tb ... , tk) ¢:::} r(tl"'" tk) ¢ Tp 1· 
I 
Thus, Theorem 7.31 states that every TIt-relation can be co-defined. To prove it, we 
employ Kleene's Normal Form Theorem for il-relations, which is the subject of the next 
section. 
Exercises 
Identify IN with the ("standard") model of arithmetic that has universe IN and the struc­
ture of which comprises addition, multiplication, and whatever is convenient (ordering, 
constants 0,1,2, ... ) . 

158 
Chapter 7 
7.24 Show that a number theoretic relation R is arithmetical iff it is definable on lNj that 
is, for some formula 1/1 in the arithmetical language, we have the equivalence R( nl, . . .  , nk) 
iff lNl=1/1[nt , . . .  , nk) ' 
7.25 ( Tarski 's theorem.) Let gnr be a computable function injectively mapping formulas 
from the arithmetical language to integers. Show that the set T RU E := {gnr( <p) \ <p an 
L-sentence true in IN} is not arithmetical. 
Hint. Otherwise, the relation {(n, gnr(1/1» 1 1/1  a formula satisfied by n in IN} would 
be definable on IN by some formula TJ = TJ(x, y). Thus, for all n and 1/1, IN 1=1/1 In] iff 
INI=TJ[n, gnr(1/1)]. Apply this to 1/1 set to -'TJ{x, x) and n := gnr(-'TJ(x, x» .  
7.26 Show that every arithmetical relation is in At. 
7.3.2 
Kleene Normal Form 
To make life a little easier, we will always assume the presence of a binary function symbol 
in the language under consideration, and so have lists in HU. In agreement with what is 
usual, the relations we quantify over will be functions defined on all of IN always. This 
does not change the concepts previously introduced: every total function a : IN -+ HU 
can be considered to code the k-ary relation {(tt , . . .  , tk}la{nr([tl , . . .  , tkJ)) = [ ]}j hence, 
every definition involving quantification over relations can be turned into one involving 
quantification over (unary, total) functions. 
In the sequel HUIN is the set of all total functions a :  IN -+ HU and HU<w is the set 
of all finite functions Q such that for some p E IN, we have Q : {iii < p} -+ HU. When 
Q :  {iii < p} -+ HU, we shall identify Q with the finite sequence (Q(O), . . . , Q(p - 1» of 
length p. 
For p E IN and a : IN -+ HU, (f(p) denotes the function defined on {iii < p} by 
(f(P){i) : =  a{i). In other words, (f(p) is al{i\i < p}, the finite approximation of a on 
{iii < pl· 
The following lemma states that EY involving relation-arguments can b e  reduced to 
EY without such arguments. 
Lemma 7.33 For every EY-relation Q C HUIN X HU there exists a decidable relation 
R c HU x HU such that Q(a, t) ¢:} 3p R«(f(p), t). 
Proof. By Definition 7.26(ii) of EY, there exists a program P involving a relation symbol 
q, such that Q(a, t) holds iff the program Pea) (Definition 7.26(i» successfully resolves 
the query q{t). In some computable way, injectively assign numbers to finite derivations. 
Now, note that, since a success can only use finitely many rules: P(a} successfully resolves 
q(t) iff for some p, we have: P«(f(P» has a success for q(t) that has a number < p. The 
relation S C HU<w x HU defined by 

Computability 
R{a, t) := pea) has a success for q(t) with a number < the length of a 
is the required decidable relation. 
Next, we blow this up to deal with m. 
159 
• 
Lemma 7.34 For every m -relation Q c HU there exists a decidable relation R such 
that Q(t) # '10' E HUIN 3p E IN R(O'(p), t) . 
Proof. By a Skolemization-procedure, eliminate all universal quantifiers over terms in 
the prefix of the nt-definition of Q in favor of universal quantifiers over functions. E.g., 
replace 3s'Vt S(s, t) by: 'V7'3s 8(s, 7'{nr(s»). If it is not clear that these expressions are 
equivalent, replace them by their negations and note that 'Vs3t ,S(s, t) is equivalent to: 
37''Vs ,S(s, r(nr(s))). 
Next, contract similar quantifiers. E.g., replace 3s3tS(s, t) by 3pS(tm(jl (p» , tm(h(n»; 
and replace 30'37' Sea, 7') by 3v S(>.n.v{2n), >.n.v(2n + 1». 
Eventually, find that Q can be defined by one universal function quantification applied 
to a (by Church's Thesis) Eù-relation. Now, apply the previous lemma. 
• 
A prefix tree is a tree T the nodes of which are finite sequences with the empty sequence 
as root, where 0' = (al, " " an) is by definition a child of {J = (bb " " bm) if n = m + 1 
and for i = 1 ,  . . .  , m, ai = bi; that is, 0' extends (J by one element. In order that such a 
set T satisfies the defining condition of trees, it is necessary that any sequence extended 
by an element of T is in T too. 
Assume that Q C HU is a nC relation. By the previous lemma, it can be rendered 
thus: 
Q(t) ¢::} 'V0'3p R(O'(p), t) 
with a decidable R, ultimately obtained by the proof of Lemma 7.33, and hence monotone 
in its relation argument (Lemma 7.27). Define the relation -< on finite sequences by 
a -< {J := (J = aIDom({J), i.e.: 0' extends {J. Note that, by monotonicity, 
0' -< (J f\ R({J, t) => R(a, t). 
Define 'It : =  {al,R(a, tn. Then by contraposition 
a -< {J f\ a E 'It => {J E 'It .  
Hence, 'It is a prefix tree for every t E HU. 
The following is the required normal form result. 
Theorem 7.35 (Kleene) For every m -relation Q c HU there exists a decidable rela­
tion R C HU<w x HU such that 

160 
(i) Tt := {aj.R(a, tn is a prefix tree for every t E HU, 
(ii) Q(t) holds iff Tt is well-founded. 
Proof. Let R be given by the previous discussion. Then (i) is clear. 
Chapter 7 
(ii) =? 
If -< is not well-founded on Tt, choose aD T a l  T a2  
.
.
.
 through Tt· Let 
(1 := Un an' Then Vp.R(Cf(p) ,  t), hence -,Q(t) .  
(ii) ¢= .  If ...,Q(t) , then for some (1 we have Vp-'R(a(p), t ) .  Then 0'(0)  0'(1)  0'(2) ɳ 
'
"
 
constitutes an infinite branch through Tt ,  and so Tt is not well-founded. 
I 
7. 3.3 
Well-founded Part 
Next, the normal form result 7.35 is transformed into one involving inductive definability, 
so as to connect it with (complements of) greatest fixed points. 
Let -< be a binary relation on a set T. 
V e T  is a (-<-)initial of T iff Va E V "113 -< a [13 E V]. 
Definition 1.36 W f(T, -<), the well-founded part of T (relative to -<), is the union of 
all initials of T on which -< is well-founded. 
I 
Lemma 7.37 W f(T, -<) is the largest well-founded initial of T. 
Proof. Immediate from Exercise 7.27. 
I 
Lemma 1.38 Define the monotone operator q, : p(n -+ p(n by q,(X) : =  {a E T j 
"113 -< a[f3 E Xl}. Then q, i= Wf(T, -<). 
Proof. Exercise 7.28. 
I 
Recall the notion of co-definability from Definition 7.32. The connection with well­
founded parts and co-definability is made in the next result. 
Theorem 7.39 Assume that T c HU and -< c HU2 . Suppose that the program P co­
defines T and the complement of -< in the symbols nt and pr, respectively. Then addition 
of the following two rules 
(i) wf(a) Ş pr(f3, a), wf(f3) 
(ii) wf(a) ŝ nt(a) 
produces a program Q that co-defines W f(T, -<) in wf . 
Proof. Let T and S be the immediate consequence operators associated with P resp. 
Q. Defining q,(X) : == {a E T I 'Vf3 -< a (13 E Xj), by 7.38 we have that W f(T, -<) == q, r. 
Therefore, we have to establish the equivalence 
a E q, i¢=? wf(a) fj. S 1 ·  

Computability 
161 
=} Put r 
:= {a I wf{a) (j. 8 n. We show that II> i c r. We have the following 
equivalences. 
a E r  
Z wf(a) (j. 8 ! 
Z -,3,8 [pr(,8, a) , wf(,8) E 8 !J 1\ nt{a) (j. 8 !  
(by the wf-rules, since 8 ! is a fixed point) 
ɲ -,3,8 (pr(,8, a) E T ! I\wf(f3) E 8 !] I\  nt(a) \t T !  
(on the P-language, Q and P behave similarly) 
ɱ -,3,8 [f3 -< a 1\ wf(f3) E 8 !J 1\ a E T 
(by assumption on P) 
ɰ '1f3 -< a [wf(f3) (j. 8 !] I\  a E T 
(by logic) 
Z a E 1I>(r) 
(by definition of II> and r) . 
So, r is a fixed point of 11> ,  and it follows that II> i C r. 
{:= This part uses ordinals and the downward fixed point hierarchy. It clearly suffices 
to show that, for every ordinal a, we have 
wf(a) \t 8! ѱ * a E 11> 1 .  
This is accomplished by induction with respect to Æ. The cases ʉ = 0 and Æ a limit are 
unproblematic. For the successor-step, note the following equivalences and implications. 
wf(a) \t 8 ! (c + 1) 
S wf(a) \t 8(8 ! b) 
(by definition of the fixed point hierarchy) 
ɮ -.3,8 [pr(,8, a), wf(f3) E 8 ! ѫJ 1\ nt(a) \t 8 ! Ѱ  
(by the wf-rules) 
ɯ -,3f3 (pr(f3, a) E T ! Ѩ 1\ wf{,8) E 8 !  aJ 1\ nt(a) \t T ! a 
(since pr and nt belong to the P-language) 
S '1,8 [pr(f3, a) E T!Ѭ * wf(f3) \t 8 ! bJ 1\ nt(a) \t T ! a 
(by logic) 
=} V,8 [f3 -< a * wf(f3) \t 8 l aJ 1\ a E T 
(we have ,8 -< a {:} pr(,8, a) E T !=> pr(,8, a) E T ! Ѫj 
and nt(a) \t T ! a => nt(a) \t T !{:} a E T) 
=} '1f3 [,8 -< a => ,8  E II> iJ 1\ a E T 
(by inductive hypothesis on 0 
{=;> a E 11>( <I> 1) = <I> i 
(by definition of <I> ) . 
I 

162 
Chapter 7 
Exercises 
7.27 Show: a union of well-founded initials of T is well-founded. Give a simple example 
showing that a union of well-founded subsets of 7 need not be well-founded. 
7.28 Prove Lemma 7.38. 
7.29 With reference to Lemma 7.38, show that the closure ordinal of K (the least ɻ such 
that cI> i  { = cI> l ({ + 1» is equal to the height of W f(7, -<). 
7.3.4 
Co-defining TIt-Relations 
Theorem 7.40 Suppose that A c HU and P are such that 
(i) t E A  iff -< is well-founded on 'It := {a: I R(a:, tn, 
(ii) P co-defines R and the complement of -< in nr resp. pr, 
(iii) P co-defines the complement of R in r. 
Then addition of the following rules 
(i) wf(a:, t) +- pr(tJ, a:), wf(tJ, t) 
(ii) wf(a:, t) +- nr(a:, t) 
(iii) a(t) +- r(a:, t), wf(a:, t) 
produces a program Q that co-defines A in a .  
Proof. For every t, define t : P('It) -t P('It) by Kt(X) := {a: E 'It I 'V{3 -< a: [{3 E Xl}. 
Then Kt j= Wf(1;, -<). Therefore, 1; is well-founded iff 1; c Ãt j. It follows that 
t E A  <=> 1; c cI>t j. By Theorem 7.39 (adding the parameter t), the wf-rules co-define 
the relation a: E cI>t T in w f. 
Let U be the operator associated with Q. We have the following equivalences: 
a(t) It U 1 
<=> -,3a: [r(a:, t), wf(a:, t) E U 1J 
(by the third rule, since U 1 is a fixed point) 
<=> Va: [r(a:, t) E U 1=> wf(a:, t) It U 1J 
(by logic) 
<=> Va: [R(a:, t) => a: E Ãt iJ 
(since Q co-defines a: E t j in wf) 
<=> 7; c ѩt i 
(by definition of T) 
<=> t E A  
(as was indicated at the beginning of the proof). 
Corollary 7.41 Every il-relation is co-defined by some program. 
• 

Computability 
163 
Proof. By Corollary 7.22, decidable relations can be defined by determinate programs. 
Therefore, decidable relations are co-definable. Now use the Kleene normal form and the 
previous theorem. 
• 
An ordinal is recursive if it is the height of a well-founded decidable prefix tree (7, -<). 
Exercise 
7.30 Show: every recursive ordinal is the height of a downward fixed point hierarchy. 
Hint. Use Exercise 7.29. 
The least non-recursive ordinal is denoted by wfK (Church-Kleene-wd. This is a 
countable ordinal since there are only countably many recursive ordinals. It is known 
that the height of the downward fixed point hierarchy of a program P is a recursive 
ordinal iff Tp 1 is hyperarithmetical. Since there are non-hyperarithmetical IIѧ-sets, it 
follows that some downward fixed point hierarchies have height equal to wf K. 
7.4 
Notes 
A beautiful recent reference on recursion theory is [Odifreddi 89). 
The notion of determinateness, Corollary 7.22 and the result from Exercise 7.21 are 
from [Blair 82) . 
The proof of 7.22 given, involving the R6'-implementation of the /1,­
operator , is from [Doets a) . 
The notions of (weak) recurrency and boundedness and the related exercises are from 
[Bezem 93] ' which also contains the strengthening of Corollary 7.22 that total recursive 
functions can be computed by recurrent programs. For work that extends Bezem's to 
termination of Prolog programs, the reader is referred to [Apt/Pedreschi 91] , which also 
contains an elaborated solution for Exercise 7. 19. 
Corollary 7.41 and Exercise 7.30 are from [Blair 82); another reference for the first 
result is [Kunen 87) . The details of the proof given here are taken from [Doets 92). 

 
8 Negation 
8.1 
Introduction 
According to a well-known slogan, Algorithm equals Logic plus Control. The ideal of 
logic programming is to write programs directly in logic so as to have a clear-cut declar­
ative interpretation, immediately available to the practical programmer , and to leave the 
control to the implementation of the interpreter. This ideal is satisfactorily realized for 
the case of positive programs and queries dealt with in Chapter 5. The way in which logic 
programming makes use of negation destroys this simple picture. This chapter discusses 
only one of the many approaches to the semantics of negation in logic programming. 
Unfortunately, this is a semantics that departs from the classical, 2-valued one. Conse­
quently, it can be doubted whether it is of much use to the practical programmer. And 
even then, it is far from adequate in a lot of cases. However, the recent result covered in 
Section 8.7 indicates that maybe things might not be as bad as they look. 
We start with some motivating remarks. Recall the introductory discussion in Section 
6.1. The set-up of logic programming with positive programs and queries from Chapter 
5 is rather weak in some respects . In particular, there are cases where one would like to 
be able to infer negative information from a program. There are two a priori solutions to 
overcome this deficiency. The first solution is to use all of first-order logic. This still has 
the clear-cut declarative interpretation given by the Tarski-semantics from Chapter 3. 
Unfortunately, first-order theorem-proving procedures (such as the notion of resolution 
as treated in that chapter) are not very well-behaved and "combinatorial explosions" 
are common. At the other end of the scale of possibilities is using positive programs in 
combination with queries in which negative literals are allowed. Chapter 6 contains an 
overview of some of the semantical issues raised in that context. If one is not prepared to 
add some essential derivation rule next to the one of resolution, then a somewhat naive 
but practical way to treat negative literals is to use negation as (finite) failure. This is 
what happens in Prolog, and what this chapter is about. 
The allowance of negative literals in queries calls for a redefinition of this notion. 
Definition 8.1 A (general) query is a finite sequence of literals. 
• 
From the procedural standpoint, the following generalization now seems only a minor 
one, since resolving a general query using a general rule will produce a general query 
again. 
Definition 8.2 A (general) rule is an expression A-M, where A is an atom (the head) 
and M is a (general) query (the body); a (general) program is a finite set of such rules .• 

166 
Chapter 8 
Conceived of as a clause, that is, a disjunction of literals, a general rule is thus a clause 
with one designated positive literal, its head. Extending the terminology from Chapter 
5, we go on calling such rules definite. Programs and queries in the old sense from now 
on will be called positive. Note that a clause with more than one positive literal can be 
written as a rule in more than one way; we shall consider these as different rules. 
It seems now rather straightforward to extend linear resolution to the new context 
with general queries and positive rules, to resolve positive literals using resolution, and 
to handle the negative ones using negation as finite failure. This is the "procedural" side 
of the coin. However, it is sensible to ask what is being established exactly by following 
this recipe; that is, what about the "declarative" aspects of negation as finite failure? 
It turns out that this question has no straightforward answer. Compare the situation 
for SLD discussed in Chapter 5. For positive programs P and queries C, if 0: is a 
computed answer substitution for C, then (soundness) PI=Co:, equivalently: Co: C Mp. 
However, negative literals never follow from a program (the largest Herbrand model H B 
always is a model), and a general program does not need to have a least Herbrand model. 
To see exactly what can be generalized, assume that P is a general program. With it, 
we still can associate the immediate consequence operator Tp over the space of Herbrand 
models, defined by T p (X) := {A E H B I for Some C eX, A..-C is ground instance of a 
P-rule}. We still have that the Herbrand models of P coincide with the pre-fixed points 
of Tp. However, existence of a least pre-fixed point needs monotonicity of the operator, 
and operators corresponding to general programs usually will not be monotone. 
Examples. Consider the program consisting of the rule A..-,A. Now, 0 c {A}. How­
ever, if T is the operator of the program, then T(0) = {A} rt. 0 = T( {A}). T has no 
fixed point; the completion of the program has no model. (It does have a least Herbrand 
model though.) 
Another example: consider the program consisting of the rule A..- ,B. There are two 
minimal Herbrand models, {A} and {B}, but there is no least one. 
• 
A more promising idea is the one from Chapter 6, to use comp(P) as the "meaning" of 
P (comp(P) still defined by the procedure from Definition 6.19), and try to establish that 
if 0: is a computed answer substitution for C, then comp(P)I=Co:. This soundness result 
indeed will hold (Corollary 8.29) . However, there is a more faithful, 3-valued, semantics 
for general logic programs, which preserves the least fixed point-idea as well. 
The rest of this chapter is planned as follows. Section 8.2 defines SLDNF-resolution, 
which extends SLD-resolution by implementing the negation of finite failure rule. Section 
8.3 explains the 3-valued semantics for general programs and queries (and, indeed, for 
all of first-order logic); Section 8.4 discusses the consequence operator and its fixed point 

Negation 
167 
hierarchy in the 3-valued setting. Soundness of SLDNF-resolution with respect to this 
semantics is proved in Section 8.5; this result extends the soundness of negation-as-failure 
theorem (in Corollary 6.20 and Exercise 6.17). Finally, Section 8.6 contains technical 
material preparing for Section 8.7, which contains what is probably the strongest known 
completeness result on SLDNF. 
8.2 
Negation Implemented: SLDNF 
We start with four preliminary definitions, introducing a number of auxiliary notions 
and simultaneously expanding a couple of old ones to the present context. 
Definition 8.3 
Q 
(i) The query C resolves to D via a with respect to E, or: ---+ D is a resolvent of C 
Q 
with respect to E, notation: C --+ D (E), if 
Q 
either: E = (A, R), and C --+ D (A, R) in the sense of Definition 5.19 (the 
presence of negative literals here is no obstacle), 
or: E is (an occurrence of) a negative literal in C, a = 10, and D = C - {E} is 
obtained from C by removing E. 
Q 
(ii) As before (Definition 5.26), the transition C --+ D (E) releases the variables 
from Var(Ca) - Var(D). 
I 
0'1 
On 
Qn.+l 
Definition 8.4 A (finite or infinite) sequence Co --+ .
.
.
 --+Cn --+ .
. . of resolu-
tion steps in the previous sense is a pseudo-derivation if condition [ t J of Definition 5.28 
is obeyed, that is, no variable released at some step occurs in the resultant of a later one. 
I 
Intuitively, an SLDNF-derivation is a pseudo-derivation in which the deletion of nega­
tive literals -.A (8.3(i)) is justified by means of a subsidiary (finitely failed SLDNF-) tree 
for A. Success or failure of a tree derives from markers on its leaves, as follows. 
Definition 8.5 A tree is called 
• successful if it has a leaf marked as success, 
• finitely failed if it is finite and all its leaves are marked as failed. 
In the sequel we consider systems of trees, which are naturally called forests. 
Definition 8.6 A forest is a system T = (T, T, subs) where 
• T is a set of trees, 
• T is an element of T called the main tree, 
I 
• subs is a function that, to some nodes of trees in T, assigns a ("subsidiary") tree 
from T. 

168 
Chapter 8 
Viewing subs as contributing a special type of edge, a path in T is a (finite or infinite) 
sequence of nodes Co, . . .  ,Ci, .. . such that for all i, Gi+l either is a child of Gi in some 
tree in T or it is the root of the tree subs(Gi). 
I 
Thus a forest is a special directed graph with two types of edges: the "usual" ones 
stemming from the tree structures, and the ones connecting a node with the root of a 
subsidiary tree. We shall consider only forests that are outgrowths of their main tree, 
and the directed graph of which is a tree as well. 
After these preliminaries, we now come to the main definition. An SLDNF-tree is a 
special type of forest built as a limit of certain finite forests: pre-SLDNF-trees. 
Definition 8.7 A pre-SLDNF-tree (relative to some program) is a forest, the nodes of 
Or 
which are (possibly marked) queries (or pairs ---+ D) of (possibly marked) literals. 
For queries, there are markers failed and success; for literals, the marker selected. The 
function subs assigns to nodes containing a selected negative literal -,A a tree in T with 
root A. The class of pre-SLDNF-trees is defined inductively: 
• For every query C, the forest consisting of the main tree with the single node G is 
an ( initia0 pre-SLDNF -tree, 
• If T is a pre-SLDNF-tree, then any extension of T is a pre-SLDNF-tree. 
Here, an extension of a pre-SLDNF-tree T is obtained by (simultaneously) performing 
the following actions for every non-empty query C that is an unmarked leaf in some tree 
TET 
First, if no literal in G is marked yet as selected, then mark one as selected. Let L be the 
(now or at some earlier stage) selected literal of C. 
• L is positive. 
- No rule of the program is applicable to L. 
Then C is marked as failed. 
- Otherwise. 
Then for every rule R of the program which is applicable to L, choose one 
a 
resolvent -----; D of C with respect to Land R and add this resolvent as 
child of C in T. These resolvents are to be chosen in such a way that branches 
through T remain pseudo-derivations. (This is possible by a straightforward 
extension of Lemma 5.29.) 
• L = -,A is negative. 
- subs( C) is undefined. 
Then a new tree T' with the single node A is added to T and subs( C) is set 
to T'. 

Negation 
169 
- subs( C) is defined and successful, and the successive specializations towards 
at least one success of subs(C) compose to a substitution D: such that AD: is a 
variant of A. 
Then C is marked as Jailed. 
- subs( C) is defined and finitely failed. 
f 
Then the resolvent --> (C - {L}) of C is added as the only child of C in T. 
Additionally, all empty queries are marked as success. 
• 
Note that if no tree in T has unmarked leaves, then trivially T is an extension of itself, 
and the extension process becomes stationary. 
One detail in the previous definition may be puzzling: the condition, in the case of 
a negative literal L = ...,A being selected in C, that C is marked failed when subs(C) 
contributes a computed answer substitution D: such that AD: is a variant of A. Without 
the latter condition, the resolution notion becomes unsound in the sense that negations of 
finitely failing queries no longer follow from the completion of the program. Remarkably, 
most implementations of Prolog use the unsound version! 
Example. Consider the rule p(a)+- and the query ...,p(x). The subsidiary tree for 
p(x) succeeds with computed answer substitution {x/a}. If we would not mind p(a) not 
being a variant of p(x), then we consequently should consider ...,p(x) as failing. However, 
...,...,p(x) does not follow logically from the completion of this rule. (Consider the model 
over {a, b} in which p is interpreted as {a}.) 
• 
Examples such as these can also be avoided by requiring that negative literals may be 
selected only if they are ground. This restriction is usually taken to be part of the defini­
tion of SLDNF, and what we are defining via Definition 8.7 is called SLDNFE (SLDNF 
extended). However, it may happen that, somewhere in the resolution process, a query 
arises containing only negative literals that are non-ground. This is called floundering. 
One problem with floundering is that the question whether it will occur for a given initial 
query is (in general) undecidable. The condition of allowedness on programs and queries 
(Definition 8.46) is a severe one, avoiding floundering. 
Since every pre-SLDNF-tree is a tree with two types of edges between possibly marked 
nodes, the concepts of inclusion between such trees and of limit of a growing sequence 
of such trees have a clear meaning. 
Definition S.S 
• An SLDNF-tree for C is the limit of a sequence To,·.·, Ti, ... such that To is the 
initial pre-SLDNF-tree, the main tree of which consists of C only, and for all i, 
Ti+l is an extension of Ti· 

170 
Chapter 8 
• A (pre-)SLDNF-tree is called successful (resp. finitely failed) if its main tree is 
successful (resp. finitely failed) . 
• An SLDNF-tree is called finite if it has no infinite path. 
• 
Finally, we define the concept of SLDNF -derivation. 
Definition 8.9 A {pre-} SLDNF-derivation for C is a pseudo-derivation through the 
main tree of a (pre-) SLDNF -tree T for C together with the set of all trees in T whose 
roots are path-connected with the nodes of this pseudo-derivation. 
An SLDNF-derivation is called finite if all paths through it are finite. 
• 
It is clear now how to define the notion of a computed answer substitution. 
Definition 8.10 Consider a pseudo-derivation through the main tree of a (pre-) SLDNF­
tree for C that ends with the empty query. Let 01, ... ,an be the consecutive special­
izations along this pseudo-derivation. Then (01'" an)IC is called a computed answer 
substitution (c.a.s.) of C. 
I 
Examples. We illustrate the definitions by depicting some SLDNF-trees. In them, 
horizontal arrows are used for the edges contributed by subs. 
(i) P = {A+-A}. The only SLDNF-tree for -,A has then the following form. 
-,A ---+-
A 
1 
A 
1 
(ii) P = {A+--,A}. There is only one SLDNF-tree for A: 
A 
1 
-,A -
A 
1 
-,A_ 

Negation 
171 
(iii) According to our definition, the construction of a subsidiary tree can go on forever 
even if the information about its "status" has already been passed to the main tree. The 
following general program illustrates this point. 
P = {A--.B, B-, B- B}. The only SLDNF-tree for A looks as follows: 
A 
1 
..,B -- B 
fail 
/ 
o 
success 
success 
Here the subsidiary tree with the root B grows forever. However, once an extension of 
this subsidiary tree becomes successful, then in the next extension the node ..,B of the 
main tree is marked as failed. Consequently, the SLDNF-tree for A is finitely failed even 
though it is not finite. 
• 
Pre-SLDNF-trees may keep growing forever. However, when the resulting SLDNF-tree 
is successful or finitely failed, this fact becomes apparent after a finite number of steps. 
More precisely, we have the following result. 
Theorem 8.11 
(i) Every pre-SLDNF-tree is finite. 
(ii) Every SLDNF-tree is the limit of a unique sequence of pre-SLDNF-trees. 
(iii) If the SLDNF-tree T is the limit of the sequence To, ... , 1i, ... , then: 
(a) T is successful and yields T as c.a.s. iff some 1i is successful and yields T as 
c.a.s., 
(b) T is finitely failed iff some 1i is finitely failed. 
Proof. 
{i} Obvious. 
(ii) The only way in which two extensions of the same pre-SLDNF tree can become 
different is by the selection of different literals in a non-empty node. But this selection 
is prescribed by the SLDNF-tree that is the limit of the pre-SLDNF trees. 
(iii) (=}) A pseudo-derivation of the main ҟree of T ending in 0, resp. a finitely failed 
main tree of T, consists of finitely many, possibly marked, nodes. Each of these nodes 

172 
Chapter 8 
(markings included) belongs to some T; and the T; with the largest i is the desired pre­
SLDNF-tree. 
( <= ) Each T; is contained (markings included) in T 
• 
Part (iii) of this theorem allows us to apply induction on the height of a successful resp. 
finitely failed pre-SLDNF-tree witnessing success resp. finite failure of a given SLDNF­
tree. 
In our definition of an SLDNF-tree, the selection rule is "incorporated" into the COn­
struction of an extension through the selection of literals in the last generated nodes. 
Clearly, this selection process can be separated from the construction of an extension. 
Let us drop the selection of literals in the last generated nodes from the definition of 
the pre-SLDNF tree. Thus, a selection rule is a function defined on pre-SLDNF-trees 
selecting a literal in every non-empty, non-marked leaf. In this set-up an SLDNF-tree 
is obtained by alternating the process of applying the selection rule with the process of 
extending the pre-SLDNF-tree. 
There is a remarkably simple, direct way to inductively define the notions of success and 
finite failure. See the following definition. For the general principle behind a simultaneous 
inductive definition of this type, see Exercise 4.32. 
Definition 8.12 Let P be a general program. The set F = F p of queries and the set 
R = Rp of pairs (C,u) - C a query and a a substitution for which Dom(u) C Var(C) 
- are defined by a simultaneous inductive definition as the least sets satisfying the 
following closure principles. 
0) DR€, 
a 
R+) if C ---; D (A, R), R E P, DRu, and Var(Ca) n Var(Du) C Var(D), then 
CR(aa)IC, 
R-) if A is an atom in F and (C,C')Ra, then (C,-.A,C')Ra, 
F +) if A E C and for every REP that is applicable to A there exist a and D E F such 
a 
that C ---; D (A, R), then C E F, 
F-) if A is an atom and Aa is a variant of A such that ARa, then (C, -.A, C') E F . • 
The intention here is of course that R is the set of pairs (C, a) such that a is a c.a.s. 
for C and F is the set of queries C that have a finitely failed SLDNF -tree. Note that 
only 0) and R+) already define the corresponding notions relative to SLD. 
Lemma 8.13 IIC E F and C CD, then D E F. 
Proof. See Exercise 8.2. 
• 

Negation 
173 
Theorem 8.14 If C is a query, then 
• CRr iff r is a c.a.s. for C, 
• C E F iff C has a finitely failed SLDNF-tree. 
Proof. See Exercise 8.3. 
• 
Exercises 
8.1 Extend Lemma 5.41 to the present context; that is, show: if C Ҝ D (A, R) and 
u is a c. a.s. for D such that Var(Ca)n Var(Du) C Var(C), then (au)jVar(C) is a c.a.s. 
for C. 
8.2 Prove Lemma 8.13. 
Hint. Straightforward induction using only clauses F+) and F-) of Definition 8.12. 
8.3 Prove Theorem 8.14. 
8.4 Show: if C E F, then Cu E F. 
The following exercise illustrates a use of negation that most elegantly forces termina­
tion in a situation that does not directly seems to call for negative information. 
8.5 Let R be a finite set of rules of the form r(s, t) Ǔ with sand t being ground. R 
defines the finite relation r := {(s, t) I r(s, t) ǔ E R} on HU. To R, add the following 
rules. 
q(x, y) <-r(x, y), 
q(x, z) .... r(x, y), q(y, z) . 
According to Exercise 4.34, these rules define the transitive closure r
tT of r in q (cf. 
Definition 1.9). 
Assuming that r contains a loop, give an example of an infinite derivation using these 
rules and the leftmost selection rule. 
Computation of rtT avoiding infinite search can be done by the following trick. Define 
the ternary relation S by 
S(s, t, l) ::=: there is a sequence So = S, ... ,sn+l 
= t such that for 0 Ē i Ē n, r(si' Si+l), 
and l is a finite sequence of elements of HU not containing an element of Sl,' .. , Sn· 
That is, there exists an r-path connecting s with t avoiding the elements of the list l. In 
particular then, S(s, t, [ ]) iff rtT(s, t}. 
Check that S(s, u, I) holds iff: r( s, u) , or for some t outside l: r(s, t) and S(t, u, [till). 
This motivates the following rules defining S (for the last two rules, see Exercise 4.58): 
s(x, z, v} ?r(x, z) 
s(x, z, v) @r(x, y), -,member(y, v), s(y, z, [ylv]) 
member(x, [xlv]) ? 

174 
Chapter 8 
member(x, [Ylv]) ;.-member(x, v). 
Show that these rules do in fact define S and that, moreover, no query sex, y, [Zl,"" zn]) 
starts an infinite derivation using the leftmost rule. 
8.6 Discuss the workings of the program EVEN2, made up of the following rules. 
even(o);.-
even(sx);.- ... even(x) . 
8.3 
3-Valued Models 
In the introduction to this chapter, we hinted at the problem of giving a satisfying 
semantics corresponding to the notion of SLDNF-resolution. The least Herbrand model­
approach does not work in the context with negation. Consideration of 3-valued logic 
arises as follows. When given a query, the SLDNF -interpreter (on the basis of a given 
program) may return a computed answer substitution, it may halt with the answer NO, 
or it may return no answer at all, going on forever. The third truth value u for undefined 
allows for this third possibility. We shall see that this simple device is able to provide a 
rather natural semantics for SLDNF resolution. 
Definition 8.15 Let J be an algebra. 
A 3-valued model over J is a function M : 
HBJ--+{t, f, u}, mapping each J-ground atom to one of the three truth values t, f and 
u. 
I 
An ordinary 2-valued model will be considered as a 3-valued model that never assumes 
the value u. 
The notion of 3-valued truth for sentences is defined using truth tables. These can be 
explained (not very accurately) as follows: the truth value of a complex expression is t 
(resp., f) if, replacing the values u of atomic sub expressions by either t or f arbitrarily, 
always yields the classical truth value t (resp., f) for the complex expression. Here is the 
formal definition that, in fact, doesn't mention u at all. 
Definition 8.16 Let M be a 3-valued model over the algebra J. We extend M to a 
function that maps J-sentences to truth values by the following "3-valued truth defini­
tion" . 
( .., ) M( ... cp) = tiff M(cp) = f 
M( ... cp) = f iff M(cp) = t, 
(A) M(A <1» 
= t iff for all cp E <1>, M(cp) = t 
M(A <1» 
= f iff for some cp E <1>, M(cp) = f, 
(V) M(V <1» 
= t iff for some cp E <1>, M(cp) = t 
M(V <1» 
= f iff for all cp E <1>, M(cp) = f, 

Negation 
( V) M(Vxcp) = t iff for all a E J, M(cp{x/a}) = t 
M(Vxcp) = f iff for some a E J, M(cp{x/a}) = f, 
(3) M(3xcp) = t iff for some a E J, M(cp{x/a}) = t 
M(3xcp) = f iff for all a E J, M(cp{x/a}) = f. 
175 
We shall not need -. We do need +-+ (but only to form completions of programs) and 
define 2-valued-style 
( +-+ ) M(cp+-+"p) = t iff M( cp) = M(t/!) 
M(cp+-+t/!) = f iff M( cp) =F M(t/!). 
• 
Thus, an equivalence never obtains the value u. 
For convenience, the propositional truth tables are summarized in the following table, 
which only contains the binary 1\ and V: 
cp 
"p 
-'Cp 
cpl\t/! 
cpVt/! 
cp+-+"p 
t 
t 
f 
t 
t 
t 
t 
f 
f 
t 
f 
t 
u 
u 
t 
f 
f 
t 
t 
f 
t 
f 
f 
f 
f 
f 
t 
f 
u 
f 
u 
f 
u 
t 
u 
u 
t 
f 
u 
f 
f 
u 
f 
u 
u 
u 
u 
t 
Definition 8.17 For v E {t, f, u}, we say that cp is v in M in case M(cp) = v. For 
v = t, we also use the shorthand MF3CP and say that M is a 3-valued model of cpo 
By EF3CP we understand that cp is t in every 3-valued model of (all sentences in) E. 
• 
Note that Definition 8.16 extends the clauses of the 2-valued case. Therefore, the 
following lemma holds. 
Lemma 8.18 
(i) If M is a 2-valued model and cp a sentence, then MF3CP iff MFCP; 
(ii) if EF3CP, then EFCP· 
• 
The following definition introduces a partial ordering Ú between 3-valued models over 
the same algebra. M Ú N means that N is obtained from M by changing some undefined 
values to either true or false. 
Definition 8.19 For 3-valued models M, N over an algebra J, define M Ú N := for all 
J-ground atoms A, if M(A) =F u, then N( A) = M(A). 
• 

176 
Chapter 8 
Earlier, we identified the 2-valued models over J with their set of true J-ground atoms 
in H BJ. We now can identify a 3-valued model Mover J with the pair (TM, FM) of 
disjunct sets TM := {AEHBJ I M( A) = t} and FM:= {AEHBJ I M(A) = fl· Then 
we have that M ::; N iff both TM C TN and FM C FN' 
The intuition behind the 3-valued semantics is brought out by the following lemma. 
Lemma 8.20 If M and N are 3-valued models over the algebra J such that M ::; Nand 
cp is a J -sentence (not containing +-+) that is t in M, then cp is also t in N. 
Proof. See Exercise 8.9. 
• 
Exercises 
8.7 Produce a 3-valued truth table for -t such that (cp-t'IjJ )+-+(-,cp V 'IjJ) is a 3-valued 
tautology. 
Produce a 3-valued truth table for -t such that (cp-t'IjJ) 1\ ('IjJ-tcp) has the same truth 
table as cp+-+'IjJ. 
8.8 Show that 3-valued logic has no logical truths; that is, there are no sentences cp (not 
containing +-+) such that F3CP. 
Hint. Consider a model that has all its relations identical u. 
8.9 Prove Lemma 8.20. 
Hint. Induction with respect to cpo Simultaneously, show that if a sentence is f in M, 
then it is f in N. 
8.4 
3-Valued Consequence Operator 
The following definition generalizes the notion of immediate consequence operator to the 
3-valued context. 
Definition 8.21 Let J be an algebra and P a program. The 3-valued consequence 
operator T3û associated with P maps 3-valued models over J to 3-valued models over 
J, and is defined as follows. If M is a 3-valued model over J and A E H BJ, then 
(i) T3(M)(A) = t iff for some J-ground instance A+-C of a P-rule, M(C) = t, 
(ii) T3ü(M)(A) = f iff for all J-ground instances A+-C of P-rules, M(C) = f 
(as usual identifying a sequence C with the conjunction of its elements). 
We use the shorthand T3p for T3}tu. 
• 
Note that, by this definition, no A E H BJ can receive both values t and f in T33( M). 
So, T3ý(M) is a well-defined 3-valued model over J whenever M is one. 

Negation 
177 
The following lemma says that the completion of a program still characterizes fixed 
points. (Compare Lemma 6.18.) It is this characterization that dictates the 2-valued 
truth table for equivalence. 
Lemma 8.22 Let M be a 3-valued model over the algebra J. Then MF3comp(P) iff 
T3Ż(M) = M. 
Proof. Note that we have given +-+ the classical, 2-valued semantics. 
The 3-valued consequence operator is monotone, but now in the sense of ::;: 
Lemma 8.23 IfM::; N, then T3*(M) ::; T3+(N) . 
Proof. See Exercise 8.10. 
• 
• 
The ordering of 3-valued models provides a natural notion of limit of an increasing 
sequence of models. If (M I e  < 1') is a ::;-increasing sequence of 3-valued models over 
J {i.e., if e < {j < l' implies Mҝ ::; M,,), then Lim΢<')"MΟ is the 3-valued model over 
J that assigns a J-ground atom the value t (resp. , f) iff for some e < " MҞ(A) 
= t 
(resp., f). Conceiving of models as pairs of sets, we clearly have that LimΠ<')"MΡ 
= 
(UҚ<')" TMǒ ' UE<,)" FM) 
Now we can define the simultaneous analogue of both upward and downward fixed­
point hierarchy for this setting. 
Definition 8.24 Let J be an algebra and P a general program. For every ordinal e, 
T3ŻTe is the 3-valued model over J recursively defined by 
(i) T3żjO is identically = ll, 
(ii) T31(ҙ + 1) = T3(T3Me), 
(iii) T33li = LimE<')"T3żTe for limits ,. 
We abbreviate: T3pIa := T3)tula. 
• 
By Lemma 8.23, the hierarchy of T3ΞTe increases in the sense of ::; , and hence it must 
become stationary at some closure ordinal. (Compare Exercise 4.16.) 
Definition 8.25 T3M = T341"', where", is the closure ordinal of the T35-hierarchy, 
that is, the least ordinal such that T3M('" + 1) = T3M",· 
Abbreviating again, T3FT:= T3)tuf. 
• 
Thus: 
Theorem 8.26 The completion of a program has a least 3-valued model over any algebra. 
• 

178 
Chapter 8 
, Example. Once more, let P consist of the one rule A--,A. Note that T3pj = T3p1O. 
Note also that this is a Ú-maximal 3-valued model of comp(P). Therefore, the truth 
value u is unavoidable in this case, and comp(P) does not have any 2-valued model at 
all. 
• 
The following lemma shows that the present hierarchy neatly subsumes both the up­
ward and the (complements of the) downward hierarchy in the context of positive pro­
grams. 
Lemma 8.27 If P is positive, then for J -ground atoms A E H BJ : 
(i) T3*+(A) = t iff A E Tt,, 
(ii) T3*-(A) = f iff A rf. Tt.· 
Proof. See Exercise 8.11. 
• 
Conceiving of models as pairs of sets, note that Lemma 8.27 can be succinctly stated as: 
T3/0 = (Tt,HBJ - T). 
By this lemma and the results of Chapter 7 (see Exercise 7.30), it follows that 3-valued 
hierarchies may close arbitrarily high up to the least non-recursive ordinal wfK. 
Exercises 
8.10 Prove Lemma 8.23. 
8.11 Prove Lemma 8.27. 
8.12 Show: if P consists of n rules that are ground, then T3pj= T3pj(n + 1). 
8.5 
Soundness 
Completions of programs plus 3-valued semantics offer a sound interpretation of what is 
going on. 
Theorem 8.28 (Soundness) Let P be a program and C a query. 
(i) If a is a computed answer substitution for C, then comp(P)P3'<i A Ca, 
(ii) if C has a finitely failed SLDNF-tree, then comp(P)P3-a A C. 
Proof. Simultaneous induction on the height of a pre-SLDNF-tree witnessing success or 
failure. Thus, assume that T is a pre-SLDNF-tree for C with a main tree T that either 
is successful or finitely failed. We distinguish a number of cases. 
1. The height of T is 1. Then C = D. SO, a = f, and comp(P)F3Df is trivial. 
Thus, suppose that the height of T is > 1. Then C -1= D. 

Negation 
2. Suppose that T selects a positive literal A in C. 
(i) T has a success leaf D. 
oc 
179 
Suppose that - D is the child of C towards this success. By induction hypoth-
esis (applied to the subtree with root D), comP(P)Fa'v' A D{3, where {3 is the com­
position of the remaining substitutions towards the success. We need to show that 
comp(P)Fa'v' A Co.{3. Assume that MFacomp(P) and let r be an M-assignment. Then 
£ 
Co:{3r -.. D{3r is an M-ground resolution step. By assumption, MFa A D{3r. Thus, 
MFa A Co:{3r. 
(ii) T is finitely failed. 
By induction hypothesis (applied to the subtrees the roots of which are the children 
oc 
of C), for every child - D of C in T, we have that comp(P) Fa..,3 A D. We need 
to show that comp(P)Fa...,3AC. Fix MFaComp(P) and let r be an M-assignment; we 
have to verify that M(A Cr) = f. Now if M(A Cr) I- f, then in particular M(Ar) I- f. 
Since MFacomp(P) , some M-ground resolvent of Ar is not f in M. Use this to form an 
£ 
oc 
M-ground resolution step Cr -.. E with E not f in M. Lift this to a step C - D 
in T. Then D has the non-f instance E, contradicting comp(P)Fa..,3AD. 
3. T selects a negative literal ..,A in C. 
Note that, since T is either successful or finitely failed, C cannot be an unmarked leaf 
of T, and so subs(C) necessarily is successful (yielding a c.a.s. 0. for A such that A and 
Ao. are variants) or finitely failed. 
(i) subs ( C) is finitely failed. 
E 
Then --+ (C - {..,A}) is the child of C in T. Now if T is finitely failed, then by induc-
tion hypothesis comp( P) Fa..,3 A (C - { ...,A}) and a fortiori we have comp( P) Fa..,3 A C as 
well. Thus, suppose that T has a success. By induction hypothesis, comp(P)Fa'v' A(C ­
{...,A} ) 0:, where 0. is the computed answer substitution corresponding to this success. 
Since subs(C) is finitely failed, again by induction hypothesis comP(P)F3...,3A, and 
therefore we have comP(P)F3..,3Ao. as well. It follows that comp(P)F3'v' A co:. 
(ii) subs(C) yields a computed answer substitution 0: for A such that A and Ao. are 
variants. 
By induction hypothesis, comP(P)F3'v'Ao:; hence, comp(P)Fa'v'A holds as well. A 
fortiori, comP(P)F3..,3 A C. 
• 
Note that if, in case 3(ii) of the proof, we did not possess the information that Ao. and 
A were variants, then we could have only concluded that comP(P)F3..,3 A Co. but not 
that comP(P)F3..,3 A c. 
Part (ii) of the following corollary generalizes the soundness of negation as failure result 
from Chapter 6. 

180 
Corollary 8.29 (2-Valued Soundness) 
(i) If a is a computed answer substitution for C, then comp(P)p'v' A Ca, 
(ii) if C has a finitely failed SLDNF-tree, then comp(P)p-,3 A C. 
Proof. Immediate from Theorem 8.28 and Lemma 8.18. 
8.6 
Saturation 
Chapter 8 
• 
This section contains model theoretic preliminaries needed for the next section. The 
reader primarily interested in the completeness result may well take Corollary 8.37 for 
granted and skip to the next section. 
Definition 8.30 Let q, = (cpi liE IN) be a sequence of formulas cpi in finitely many free 
variables Xl, ... Xk, YI, ... ,Ym and let 1 be a (ordinary, 2-valued) model. 
1 is called q,-saturated if for all assignments T 
: {Yl,'" ,Ym}--.J, either some 0' 2 T 
exists such that for all i, 1pcpiO' -j that is, {cpiT liE 1N} is satisfiable in 1 -, or there 
exists N E 1N such that for no 0' 2 T, 1p Ai<N cpiO' -j that is, {cpiT I i < N} is not 
satisfiable in J. 
J is saturated if it is q,-saturated for every sequence q,. J is recursively saturated if it is 
$-saturated for every computable sequence q,. 
• 
For the notion of computable sequence of formulas (and hence, of recursive saturation) 
to make sense, we require that the underlying language C is effectively enumerated as 
C = {O'i liE 1N}. Moreover, the number of arguments of a relation or function symbol 
should be computable from its index in the enumeration. 
Remark 8.31 Note that in the context of Definition 8.30, J is ѭ-saturated iff the fol­
lowing implication holds for all T : {Yll' .. ,Ym}-->J (where 'ljJi replaces -,cpi): 
if "10' ;2 T 3i Jp'ljJiO', then for some N E 1N: "10' ;2 T 3i < N Jp'ljJiO'. 
.Ҙ 
Recall the notion of elementary extension from Definition 3.42. 
Lemma 8.32 
(i) Every model has a saturated elementary extension, 
(ii) every countable model has a countable recursively saturated elementary extension. 
Proof. (i) Here is a sketch. Let .J be a model. 
Using first-order compactness (more precisely, Exercise 3.21), construct an elementary 
chain 
10 = J -< J1 -< J2 -< ... 
of models such that for every n, q, = (vi liE IN) a sequence in free variables Xl, .
•
.
 ,Xk, Yl. 
... , Ym and all T : {Yl.·.·, Ym}->Jn: 

Negation 
either {,iT liE N} is satisfiable in In+l, 
or there exists an N E N such that {'PiT I i < N} is not satisfiable in In. 
The required model is the union of the In (see Exercise 3.22). 
181 
(ii) Essentially the same construction is used. 
Since there are only countably many 
computable sequences, it is possible to keep all Ji countable. 
• 
The presence of the variables Yl, ... , Yrn in the formulas of the sequences cP (cf. Defini­
tion 8.30) is responsible for the fact that the previous proofs require the construction of a 
limit structure. In their absence, the required model is produced by just one application 
of compactness. This special case in fact suffices for the application to completeness in 
the next section. 
Lemma 8.33 Let P be a program. For every formula 'P, i E N and v E {t, f, u} there 
exists a first-order formula rpi.V (computable in i) in the algebraic language with the same 
free variables as rp such that for every algebra J and every u : V ar( cp )-+J, we have that: 
Jl=rpi,V u iff (T3Mi)(rpu) = v. 
Proof. (Compare Exercise 4.38.) 
Let L be the language of P- Let r be some n-ary relation symbol of L. We indicate 
how to construct the required formulas r(xl, ... , Xn)i,t and r(xl, . . . , Xn)i.f Once this 
is done, the rest is rather easy. For cpi.V, where rp is non-atomic and v = t or v = f, we 
follow the calculations given by the 3-valued truth definition (keeping i fixed). And of 
course for 'Pi,u we can take ..,rpi,t 1\ ..,rpi.f. 
For i = 0, put r(xI, ... , Xn)i,t = r(xI, .. . , Xn)i,f := .L 
The following move may be helpful in constructing the remaining formulas (i > 0). 
For every relation symbol q of L, add a new relation symbol rv q. This extends L to L Ѭ. 
Let T3Ma be the 3-valued L-model which is the a-th stage of the 3-valued hierarchy 
over J generated by P- We transform T3Ma into a 2-valued L9-model T2Ta over J, 
by taking {(al, .
.
.
•
 ak) E Jk I q(al. ... , ak) is t in T3Ma} as the interpretation of q E L 
and {( aI, ... , ak) E Jk I q( al, ... , ak) is f in T3Ma} as the interpretation of '" q E L ́ . 
(Of course any 3-valued model can be so transformed.) Thus, 
T2,Tal=q(al"
" ,ak) ¢:} T3-TaI=3q(al"" ,ak), 
T2f,Tal= "' q(a } , ... ,ak) ¢:} T3*TaI=3..,q(al, ... ,ak). 
Let 6 be any L-formula (not containing ..... ) in which negation symbols occur in front 
of atoms only.  is the L 9 -formula obtained from 6 by replacing every negated atom 
""q(t}, ... , tk) by the L9-atom "'q(tl,"" tk)' By induction on 8, it follows that 
T2Tal=(al'"'' an) <=> T3.iaI=38(al'''. ,an), 

182 
Chapter 8 
In particular, we can apply this transformation to the the defining formula 0 for r (see 
Definition 6.19). Thus, 6, does not contain any negation and its quantifiers are all 
existential. 6,d is obtained from the negation ..,6, by (i) moving the negation symbol 
inward and (ii) replacing negations -.q(tt . . . .  , tk) and .... "-'q(t l , . . . , tk) by ""q(h, . . .  , tk) 
resp. q(tl , . . .  , tk)' Note that in 6,d, negations occur only in front of identities and 
quantifiers are all universal. We now have that 
The point of these transformations is contained in the following claim. 
Claim. For all J, al , "
" 
an E J and a, 
(i) T2j(a + 1)l=r(at . . . . , an) iff T2jal=6,(al" " ,an), 
(ii) T2j(a + 1)1= ""r(a!, . . . , an) iff T2jaF6,d(al ' " ' '  an). 
These equivalences form an explicit description as to how the hierarchy of models T3ja 
(T2ja) is recursively defined. Restricting them to finite a ,  they can be used to pro­
duce the desired formulas. For instance, r(xl , . . .  , Xn)l,t is obtained from 6" replac­
ing all atoms q(tl, ' ' ' '  tk) and "" q(tl , . . .  , tk) by .1 (since both q(yt. . . . , Yk)O,t and 
q(Ylr . . .  , Yk)o,f are defined to be .i). Similarly, r(xl , . . .  , xn)l,f is obtained from 6,d 
by carrying out the same replacements. Next, r(xI , . . .  , Xn}2,t is obtained from 6" re­
placing all atoms q(tl! " "  tk) and "" q(tl r . . .  , tk) by the formulas q(tl ' . . .  , tk)l,t resp. 
q(tl, . . . , tk)l.f. Similarly, r(xI , . . .  , Xn)2,f is obtained from 6,d by the same replacements, 
etc. See Exercise 8.14. 
I 
Corollary 8.34 Suppose that J elementarily extends H A. Then for every sentence r.p 
and n E IN, T3pjnl==3r.p iff T3jnI=3r.p. 
Proof. Using the formulas of Lemma 8.33, T3pjnl=3r.p iff H AFr.pn,t iff JI=r.pn,t iff 
T3jnI=3r.p· 
I 
The following continuity property is crucial. 
Lemma 8.35 If the GET-algebra J is recursively saturated then, for every J -sentence 
r.p (not containing +-+): if r.p is t (resp., f) in T3jw, then for some n E IN, r.p is t (resp., 
f) in T3Mn. 
Proof. (That J satisfies the CET axioms has no role in the proof.) Induction with 
respect to r.p. For atomic r.p, this is trivial. The following case is the one that needs 
recursive saturation of J. Assume that Yx1/; is t in T3jw. Thus, 
for all a E J, 1/;{x/a} is t in T3jw. 
By induction hypothesis, 

Negation 
for all a E J there exists i E IN such that 1jI{ x/a} is t in T3'ii. 
By saturation (Lemma 8.33, Remark 8.31), n E IN exists such that 
for all a E J there exists i < n such that 1jI{x/a} is t in T3Mi. 
But then Vx1jl is t in T3ein. 
183 
I 
The closure ordinal of a 3-valued hierarchy can be anything ::; wfK. The following 
result says that any 3-valued hierarchy over a recursively saturated algebra will close at 
or before w. Together with Lemma 8.32, this produces another proof for Theorem 6.22. 
Theorem 8.36 If the GET-algebra .J is recursively saturated, then for every program 
P: T3'l = T3Mw. 
Proof. Assume the hypothesis. Let A = r(al, . . . , an) be an arbitrary J-ground atom. 
We have to show that if A is t (f) in T3fl(w + 1), then A is t (resp., f) already in T3Mw. 
This is an almost immediate result of Lemma 8.35 and the explanations given in the 
proof of Lemma 8.33. 
For instance (letting L'l. be the formula obtained from the defining formula 8 for r in the 
way described there), r(al , . . .  , an) is t in T3M(w + 1) iff r(al , . . . , an) is true in the two­
valued companyon model T2fj(w + 1), iff L'l.(al, . . . , an) is true in T2elw, iff 8(al, ' . .  , an) 
is true in T3elw. By Lemma 8.35, this implies 3-valued truth of 8(al , "
" an) in some 
T3(in. But then, L'l.(ab . . . , an) is true in T2Mn, r(al , . . .  , an) is true in T2M(n + 1), 
and hence in T3M(n + 1) and in T3glw. 
Similarly, r(ab " " an) is f in T3hl(w + 1) iff ,,-,r(al ! " " an) is true in T2gl(w + 1), iff 
L'l.d(al , " " an) is true in T2g-p.;, iff -,8(al , " " an) is true in T3Mw. By Lemma 8.35, this 
implies that .. 8(al , " "  an) is t in some T3Mn, whence L'l.d(al . ' ' ' '  an) is true in T2fln, 
so ,,-, r(al. . ' "  an) is true in T2el(n + 1), and hence r(al , . . .  , an) is false in T3M(n + 1) 
  n. 
I 
By Lemma 8.27(ii), the following result for ground atoms A can be seen to generalize 
the implication comp(P)I= .. A :::;. A fj. Tp t w  (related to completeness of negation as finite 
failure) for P positive and A a ground atom (cf. Corollary 6.20). In it we may in fact 
replace the Herbrand algebra H A by an arbitrary CET -algebra. It is this result that is 
instrumental in the completeness proof of the next section. For the converse implication, 
see Example 8.38. 
Corollary 8.37 Let <p be any sentence (not containing +-+). If comp(P) 1=3<P, then for 
some n, T3ptnI=3<P' 
Proof. Assume that comp(P)1=3<P' By Lemma 8.32, choose an elementary extension J 
of H A that is recursively saturated. Since (by Theorem 8.36 and Lemma 8.22) T3glw is 

184 
Chapter 8 
a 3-valued model of comp(P), i.p is t in T3*lw. By Lemma 8.35, i.p is t in some T3Mn. 
Now, use Corollary 8.34. 
• 
Example 8.38 Here is a counter-example to the implication T3plni=3 'P => comp(P)i=3'P· 
P consists of the following rules. 
q(a) .-
r .- .q(x) . 
In the following table we calculate the truth values produced by the 3-valued hierarchy 
over the universe HU = {a}, indicating the level at which an atom becomes t or f. 
level 
t 
f 
1 
q(a) 
2 
r 
Therefore, T3p12 i=3-,r. 
However, over the algebra J := {a, b}, we have the following calculation: 
level 
t 
f 
1 
q(a) 
q(b) 
2 
r 
Therefore, comp(P) қ3 ·r. 
I 
The lesson this example teaches is that, in the context with negation, what is true may 
change upon adding elements to the underlying algebra without changing the program. 
With a Herbrand universe that is sufficiently large, there is no such dependency, and the 
converse of Corollary 8.37 holds. See Exercise 8.16. 
Exercises 
8. 13 Show: every finite model is saturated. 
8.14 Complete the proof of Lemma 8.33. 
8. 15 Complete the remaining details of the proof of Lemma 8.35. 
8. 16 Fact: if the algebraic language is infinite, then every CET-algebra elementarily 
extends HA. 
Assume the algebraic language is infinite. Show that the converse of Corollary 8.37 holds. 
Hint. If M is a 3-valued model of comp(P) over the algebra J, then T3M ::; M. 
8.17 Show that the algebra IN + 7l (see Example 6.4) is not recursively saturated. Show 
that there is exactly one countable recursively saturated CET-algebra for the language 
{o, s}. Describe it. (See Exercise 6.16.) 

Negation 
185 
8.7 
Completeness for SLDNF 
Until very recently, theorists failed to obtain completeness results of much importance. 
An abundance of examples provided evidence for the belief that such completeness results 
would remain an illusion. On the other hand, practice indicated that, for reasonable 
programs, SLDNF would accomplish what was intended, whereas the counter-examples 
often did not seem to be related to real life. And so the question arose: exactly what 
makes a program reasonable? The completeness result that is the topic of this section 
suggests that this is to be found in the well-moding of programs. At the same time, the 
proof itself uses very little of the information provided by having this property. 
8.7.1 
Modes 
The notion of a mode arises from the following considerations. Consider a general rule 
A+- Ao, · · · , Am-I .  .., Bo, · · · ,  .., Bn-l · 
In a practical context, the use of a rule like this (according to leftmost selection) causes 
a "data flow" . An instance of A is resolved using this rule, containing some input values. 
Next, when a corresponding instance of Ao with these values is resolved, certain output 
values are computed, serving as input values for a subsequential resolution of an instance 
of AI, etc. Finally, (instances of) Bo, . . .  , Bn-l are tested. If they finitely fail, the output 
finally produced by Am-l is assigned to some output variables of A by way of computed 
answer substitution. 
This dynamic way of looking at rules can be made explicit by a mode specification 
for relation symbols. Each of the n argument places of an n-ary relation symbol can be 
assigned one of three modes: in (for input), out (for output) and neutral. 
Definition 8.39 
(i) A mode specification for an n-ary relation symbol is an n-tuple of elements from 
the set {in, out, neutral}. 
(ii) If a = (al , . . .  , an) is a mode specification for the n-ary symbol r and tl , . . . , tn 
are terms, then in(r(h , . . .  , tn), a) := U"'i=in Var(ti). 
Similarly, out(r(tl '  . . .  , tn), a) := U",.=out Var(ti). 
(iii) A n  input/output specification i s  a function S assigning t o  every relation symbol r 
a set S+(r) C {in, out, neutral}n of positive mode specifications for r (n the arity 
of r) and a set S- (r) C {in, neutral}n of negative mode specifications for r. 
• 
The idea is that positive calls of r will be made according to some of its positive mode 
specifications, whereas a negative mode specification is used when r is called in a negated 

186 
Chapter 8 
position. Negative mode specifications do not use the mode out, reflecting the idea that 
negative literals do not contribute to the computation of output. It is allowed that, in a 
mode specification S, one or both sets S+ (r), S- (r) are empty. 
The fact that an input/output specification can assign more than one mode specifica­
tion to a single symbol reflects the different ways in which the symbol may be used by 
the program. For instance, the rules for append (Exercise 4.54) may be used to concate­
nate lists according to the mode specification (in, in, out), but it may be used also to 
decompose a list (according to (out , out , in» .  
The following definitions are meant to capture the intuitive picture previously sketched. 
In it we use the notations S+ (A) and S- (A) for S+ (r) resp. S- (r) whenever A 
r(tl , . . .  , tn) is an r-atom. 
For the rest of this section, let some input/output specification S be fixed. 
Definition 8.40 A general rule A +- K is S-correct if 
(Rl) for all Q E S+(A), the body K can be permuted to a sequence Ao, . . .  , Am-l > ..,Bo, 
. . .  , -.Bn- 1 such that for some Qi E S+ (Ai) (i < m): 
(a) if k < m, then in(Ak '  Qk) C inCA, Q) U Ui<k out(Ai, Qi), 
(b) out(A, a) C inCA, Q) U U<m out(Ai, Qi), 
(c) if j < n, then S- (Bj )  =I- 0, and VadBj) C inCA, Q) U Ui<m out(A, Qi), 
(R2) for all Q E S- (A) : 
(a) for all positive literals Ai E K, there exists Qi E S- (Ai) such that 
in(Ai, Qi) C inCA, Q) , and 
(b) for all negative literals -.Bj E K, there exists (3j E S+ (Bj )  such that 
in(Bj ,  (3j ) C in(A, Q) . 
A program is S-correct if all its rules are. 
Lemma 8.41 An instance of an S-correct rule is S-correct. 
Proof. Exercise 8.20. 
I 
• 
Definition 8.42 A query is S-correct if it can be permuted to a sequence Ao, . . .  , Am-I , 
..,Bo, . . .  , .Bn-1 such that for some Qi E S+ (Ai) (i < m): 
(Ql) if k < m, then in(Ak, Qk) C Ui<k out(Ai, Qi), 
(Q2) if j < n, then S- (Bj) =I- 0 and Var(Bj) C Ui<m out(Ai ' Qi). 
I 
Definition 8.43 A query is S-closed if for every positive literal A in it, there is an 
Q E S- (A) such that inCA, Q) = 0 and for every negative literal ..,B in it, there is a 
(3 E S+ (B) for which in(B, {3) = 0. 
• 

Negation 
187 
For some examples, see Exercises 8.22, 8.23 and 8.30. 
Very few consequences of correctness are needed in the forthcoming completeness proof. 
The following lemma isolates the Stark conditions actually used. 
For the rest of this section fix a program P that is correct with respect to the in­
put/output specification S. 
Definition 8.44 C+ = ct is the set of S-correct queries; C- = Cs is the set of S-closed 
queries. 
• 
Lemma 8.45 (Stark conditions) 
(AJ) if C E C+, then Cu E C+, 
(A2) if C E C+ and C җu D (using a P-rule), then D E C+, 
(A3) ij (-.Al! " " ..,Ak) E C+, then, for 1 :5  i :5  k, Ai is ground and Ai E C- , 
(Bl) if C E C- , then Cu E C- , 
( 
(B2) if C E C- and C -u D (using a P-rule), then D E C- , 
(B3) if -,A E C E C-, then A E C+ . 
Proof. For (A3), see 8.42(Q2). For (B2), use Lemma 8.41. For (B3), see Exercise 8.19. 
See Exercise 8.21. 
• 
Note that (A1/2) imply that an unrestricted resolvent of a query in C+ is in C+; 
similarly, (Bl/2) imply that an unrestricted resolvent of a query in C- is in C- .  
Note that the Completeness Theorem 8.52 holds with respect to any two classes C+ and 
C- satisfying the Stark conditions (AI-B3). Except for (A3), these are closure principles 
that can easily be satisfied. It is (A3) which makes this more problematic. Well-moding 
provides a practical way to obtain non-trivial classes satisfying (AI-B3). See Exercise 
8.26 for another way to realize the Stark conditions. 
Exercises 
8.18 Show: a fact A - is S-correct iff for all a E S+(A), out(A, a) C in(A, a). 
8.19 Show: a query is S-closed iff for everyone of its negative literals -'A, the query A 
is S-correct. 
8.20 Prove Lemma 8.41. 
8.21 Complete the proof of Lemma 8.45. 
8.22 Consider the input/output specification S that assigns one positive resp. negative 
mode specification (neutral, . . .  , neutral) to every relation symbol. Show: every pos­
itive program is S-correctj a general query is S-correct iff all its negative literals are 
ground and every query is S-closed. 

188 
Chapter 8 
8.23 Verify that the s-program of Exercise 8.5 is correct with respect to the following 
mode specification S. 
S+(s) = {(out, out, in)}, 
S- (s) = {(neutral, neutral, neutral)}, 
S+ (member) = {(neutral, neutral), (out, in)}, 
S- (member) = {(neutral, neutral)}. 
Check that every query s(x, y, [ ]) is correct. 
8.24 Add the usual rules for member to the following rules, involving binary relation 
symbols ct., C ,  and = ,  that determine whether two lists contain the same elements. 
ct. (y, z) +- member(x, y), ,member(x, z) , 
C (y, z) +- , ct. (y, z) , 
= (y, z) ;- C (y, z), c (z, y). 
Find a mode specification with respect to which this program and ground queries = ( 8 ,  t) 
are correct. 
8.25 Partially order the input/output specifications for a set R of relation symbols by 
Sl ::; S2 := for all r E R, St(r) c St(r) and Sl(r) C S; (r) . Show: if a program is 
S-correct for some S, then there is a greatest S for which it is correct. 
Hint. If P is Si-correct (i = 1, 2), then P is (Sl U S2)-correct. (Sl U S2 defined by 
(Sl U S2)+I-(r) = Stl-(r) U Stl-(r).) 
8.26 Assume that V+ and V- are classes of queries satisfying the following conditions. 
a 
(i) If C E V+ (resp. C E V-) and C -- D (A, R), where R is a P-rule, then 
D E  V+ (resp. D E  V- ), 
(ii) if (,AI , . . .  "
Ak) E V+ , then, for 1 ::; i ::; k, Ai is ground and Ai E V- , 
(iii) if ,A E C E V- , then A E V+ . 
Show that the classes C+ := {CO' l C E V+ } and C-
: =  {CO' l C E V- } satisfy (AI-B3). 
The following notion of allowed ness was concocted to avoid floundering. 
Definition 8.46 A general rule is allowed if every variable that occurs in it has an 
occurrence in a positive literal in the body of the rule. A general program is allowed if 
all its rules are. 
A general query is allowed if every variable that occurs in it has an occurrence in a 
positive literal of the query. 
I 
Allowedness is a severe restriction on programs. E.g. , every allowed fact is ground. This 
excludes many useful rules. For instance the following one, defining equality over HU, 
is not allowed: 
eq(x, x) ;-. 
The first addition-defining rule is not allowed: 

Negation 
sum(x, 0, x) +-. 
The usual rules defining membership in a list (Exercise 4.58) are not allowed: 
member(x, [xlz]) +-
member(x, [YlzJ) +- member(x, z). 
189 
8.27 Suppose that C and R are allowed and that C Җ D(A, R}. Show that D is 
allowed. 
Hint. An instance of an allowed query (resp. rule) is allowed. 
It follows that floundering cannot occur when dealing with allowed queries and programs. 
8.28 Show that every computed answer substitution for an allowed query relative to an 
allowed program is ground. 
Solution. The following proof uses an amusing trick. Suppose that .>. is the computed 
answer substitution of the successful SLDNF -tree T for the allowed query C relative to an 
allowed program. Let L be a negative literal such that Var(L} = Var(C). (E.g. , L might 
be of the form -,r(x l , ' "  , xn) or -,r(f(xl .
.
.
.
•
 xn» .) Modify T by replacing its initial 
query C by (C, L) and making the obvious change in derived queries, adding instances 
of L. The resulting SLDNF -tree then will have a leaf L'>'. Since (C, L) is allowed. it 
follows (mainly by Exercise 8.27) that L'>' is allowed also. Therefore. L'>' cannot contain 
a variable. Therefore • .>. is ground. 
8.29 Suppose that P and C are allowed. Show that, for every n. there are only finitely 
many rJ' : Var(C)-HU such that T3pTnP3Ca. 
Solution. Induction with respect to n .  Fix an allowed query C. The case Var(C) = 0 
is triviaL Choose x E Var(C}. We have to show that the set {xa I a : Var(C)-HU 
and T3pTn!=3Ca} is finite. Assume that a : Var(C)-HU and T3pinp3Ca. Since C 
is allowed, x occurs in a positive literal A E C. Take any ground instance Aa +- D  of a 
P-rule such that T3pT(n - 1)p3D. 
E 
a 
Lift the ground resolution step Aa ---+u D to a resolution step A ---> E. There exists 
7r such that Dom(7r) C Var(Aa, E}. D = E7r and Aa = Aa7r; in particular, xa = XQ7r . 
Since P is allowed. Var(Aa) C Var(E}. Thus, Dom(7r) C Var(E). Since D 
= E7r is 
ground, 7r : Var(E)-HU. 
Now T3pT(n - l) P3E7r. By Exercise 8.27, E is allowed. By induction hypothesis. there 
are only finitely many 7r : Var(E)-HU such that T3pT(n - 1)P3E7r. Since A (up to 
variants) has only finitely many resolvents, this proves the claim: xa = xa7r; and there 
are but finitely many a and 7r available. 
8.30 Consider the input/output specification S that to every relation symbol assigns one 
positive mode specification of the form a+ = (out •
.
.
.
 , out) and one negative mode speci­
fication of the form a-
= (neutral, . . .  , neutral). Thus for every atom A, inCA, a+) = 0 

190 
Chapter 8 
and out(A, a+) = Var(A) .  Show that rules and queries are S-correct iff they are allowed 
and that every query is S-closed. 
8.7.2 
Completeness 
The following auxiliary definition introduces two sets of queries YES = YES p and NO = 
NOp (depending on the program P) that are closely related to the sets of provable and 
finitely failed ones. See Exercise 4.32 for the general principle on which definitions of 
this type are based. 
Definition 8.47 The sets of queries YES and NO are inductively defined as the least 
ones satisfying the following closure principles. 
(YI) 0 E YES, 
f 
(Y2) if C --+,. D (using some P-rule) and D E  YES, then C E YES, 
(Y3) if AI , , , "  Ak E NO, then (--.Al > " "  --.Ak) E YES, 
(NI) if A E C and, for all R E P  that are applicable to A and for all a and D: 
'" 
if C --+,. D (A, R), then D E NO; 
then C E NO, 
(N2) if A E YES is an atom, then (C, --.A, C') E NO. 
The following is a straightforward consequence of this definition. 
Lemma 8.48 
(i) If C E YES, then C(1 E YES, 
(ii) if C E NO, then C(1 E NO, 
• 
Proof. (i) and (ii) are proved simultaneously, by induction, following the clauses of 
Definition 8.47. 
(i) 
(YI). C = o. 
Then C(1 = 0 E YES, by (YI). 
(Y2). C ҕ,. D E YES. 
f 
Then Ca --+,. Da. By induction hypothesis for (i), D(1 E YES. By (Y2), C(1 E YES. 
(Y3) . C = (-,AI ,  . . .  , -,Ak) ,  AI , "
" Ak E NO. 
By induction hypothesis for (ii), Ala, . . .  , Ak(1 E NO. By (Y3) ,  C(1 E YES. 
(ii) 
(Nl). A E C, and if R E P  and C Ҕ,. D (A, R), then D E NO. 
Assume that R E P  and Ca ғ,. E (A(1, R). Lift this to C  D (A, R) . For some 
r, Dr = E. By hypothesis, D E  NO. By induction hypothesis for (ii), E = Dr E NO. 

Negation 
Therefore, it follows by (Nl) that Ca E NO. 
(N2). C = (C', ..,A, C"), A E YES. 
191 
By induction hypothesis for (i), Aa E YES. Therefore by (N2), Ca = (C'a, ...,Aa, C"a) E 
NO. 
• 
The following lemma shows YES and NO to be closely related to the sets of (SLDNF) 
provable and finitely failed queries; also, see Exercise 8.33. 
Note that the version of SLDNF employed here is the one that (a) let ..,A succeed if A 
is ground and finitely failed (this is according to the usual formulation of SLDNF); (b) 
let .,A fail if A succeeds with a computed answer substitution that is a renaming for it 
(this is from what is called SLDNFE). 
Lemma 8.49 
(i) If C E C+ and Ca E YES, then there exists a computed answer substitution (J for 
C such that Ca is an instance of C(J, 
(ii) if C E C- and C E NO, then C has a finitely failed SLDNF-tree. 
Proof. Induction via Definition 8.47. 
(i) 
(Yl). Ca = D .  Then a = t:. Take (J = f .  
E 
Q 
(Y2). C(1 --+u D E YES. By lifting, assume that C --+ E. For some T, Ca = COlT 
and Er = D. By (Al/2), E E C+. By induction hypothesis for E and r, for some >. 
A 
we have that E --+-+ 0 and Er is an instance of E>'. We may assume this success is 
such that (Var(CQ) - Var(E» n Var(E>.) = 0. Then, however, (J := (Q>')IVar(C) is a 
computed answer substitution for C and Ca is an instance of CQ>' = C(J. 
(Y3). Suppose that C = (..,Al , . .
. , ..,Ak) E C+ ,  Ai(1 E NO (i = 1, . . .  , k). By (A3), 
every Ai is ground and in C-. In particular, Aia = Ai. By induction hypothesis for (ii), 
8:=. 
every Ai has a finitely failed SLDNF-tree. Thus, we have that C --+-+ 0 in k steps, 
using these trees. 
(ii) 
Q 
(Nl). A E C E C- and for every R E P  applicable to A and all Q: if C --+u D (A, 
a 
R), then D E NO. By induction hypothesis for (ii), if C --+ D (A, R), then (since by 
(B1/2), D E C-) D has a finitely failed SLDNF-tree. But then C has such a tree as well. 
(N2) . C = (C', ..,A, C"), A E YES. By (B3), A E C+. By induction hypothesis for (i), 
A has a computed answer substitution B such that A = At: is an instance of AB. Thus, 
B is a renaming for A. So, C has a finitely failed SLDNF-tree. 
• 
Before coming to the main lemma, we have to dispose of a technicality. 

192 
Chapter 8 
Lemma 8.50 Suppose that C E C+ and 0 = {Xl /CI , " " xm/cm } is a substitution where 
CI , . . .  , Cm are pairwise different constant symbols not occurring in P or C. If CO E yes, 
then C E yeS. 
Proof. Induction via the definition of YES (keeping 0 variable). (That (Nl/2) do not 
enter the argument is due to (A3).) 
(Yl). CO = O .  Then C = 0 E YES by (Yl). 
£ 
(Y2). CO --+ u D E YES. 
If D does not contain any of the variables Xl , . . .  , Xm, obtain D' from D by changing 
the c; back to the Xi. Then D == D'O, C --=-'u D'. By (A2), D' E C+ . By induction 
hypothesis, D' E YES. Thus, C E yes by (Y2). 
If D does contain some of the Xi, then we argue as follows. Choose variables Yl , . . . , Ym 
not in C or D. Put 0' : =  {YI/Cl , . . .  , Ym/Cm}. There is a variant C' of C and a query 
D' such that CO = C'O' and D == D'O' (To obtain C' from C, replace the Xi by the Yi; 
to obtain D' from D, replace the Ci by the Yi.) Now, C' --=-. .. D'. By (AI) ,  c' E C+ .  
By (A2) , D' E C + .  Since D'O' 
= D E yeS, by induction hypothesis for D '  and ()', 
D' E yes. By (Y2), c' E yes. Therefore, by Lemma 8.48(i), C E yeS. 
(Y3) . C = (.AI ,  . . . , .Ak), where .AlO, . . . , .Ak(} E NO. By (A3) , C is ground. Thus, 
.Ai(} = ..,Ai E NO and, by (Y3), C E yes. 
I 
Next comes the main lemma. It employs the following notions of rank with respect to 
the 3-valued hierarchy. (Compare Definition 5. 18.) 
Suppose that C = (Ll , . . . , Lk) is a query and T) 
= {{nl , ' "  , nd} a multiset. T) is a 
positive rank of C if C is ground and for all i, i = 1 ,  . . .  , k, Li is t in T3plni . T) is a 
negative rank of C if for every assignment (j of its variables in HU, some Li(j is f in 
T3pjni. 
If a ground query has a positive rank, then it also has a (in the multiset ordering) least 
one, which we might call the positive rank of the query. However, a least negative rank 
need not exist. 
Lemma 8.5 1  Assume that the language has infinitely many constant symbols. Let C = 
(L1 , . . .  , Lk) be a query and T) = {{nl , '  . . , nk}} a multiset. 
(i) If C E C+ and T) is a positive rank of C, then C E YES, 
(ii) if C E C- and T) is a negative rank of C, then C E NO. 
Proof. We prove (i) and (ii) simultaneously, using multiset induction with respect to T); 
that is, Theorem 1 .13. The proof splits into cases I-IV. Cases I and IV together make 
up part (i) of the lemma; cases II and III make up part (ii). 
Case I. C E C+ is ground, T) is a positive rank of C, and at least one literal Li is 
positive, Li = A. 

Negation 
193 
Since A is t in T3ptni, we have that ni > 0, T3ptni = T3p(T3pt(ni - 1» and so there 
E 
is a ground unrestricted resolution step of the form C -u D (A, R), where R is a 
P-rule. Let R have m body literals. Obtain rl' from TJ, replacing ni by m occurrences of 
ni - 1 .  Then r!, precedes TJ in the multiset ordering and r/ is a positive rank for D. By 
(A1/2) , D E  C+ .  By induction hypothesis for (i), D E  yes. By (Y2), C E yeS. 
Case II. C E C- , ", is a negative rank of C, and for some i (1 :$ i :$ k), Li is positive, 
Li = A, and ni > o. 
Q 
Let R be any P-rule applicable to A and suppose that C -u D (A, R) . Obtain the 
multiset ",' from "" replacing ni by as many occurrences of ni - 1 as R has body literals. 
Then TJ' precedes TJ in the multiset ordering. 
Claim. r/ is a negative rank for D. 
Assuming the claim, since by (B1/2) we have that D E C - ,  it follows by induction 
hypothesis that D E NO. Since this holds for every P-rule applicable to A, by (N1) we 
have that C E NO. 
Proof of Claim. 
Let r be ground for D. We must find a literal in Dr f in T3ptn 
where n is the element of ",' corresponding to this literal. Extend ar to a substitution 
Q 
f 
0' ground for C. Then C -u D lifts the ground resolution step CO' -u Dr. Since 
", = {{ nl, . . .  , nk H is a negative rank for C, there exists j (1 :$ j :$ k) such that the j-th 
literal of CO' is f in T3ptnj . 
(a) j =f. i .  Then this literal occurs in Dr as well, and nj is the corresponding element of 
",' . 
(b) j = i. Then this literal, AO', has been replaced by instances of body literals of R 
in Dr, and, since AO' is f in T3ptni = T3p(T3pt(ni - 1 » , at least one of them is f in 
T3pT(ni - 1 ) ,  and ni - 1 is the corresponding element of r/ . 
Case III. C E C- , ", is a negative rank of C, and for all i (1 :$ i :$ k), if Li is positive, 
then ni = o. 
Suppose that Var( C) = {Xl , . . .  , xm}· Choose distinct constant symbols Cl , . . .  , Cm that 
do not occur in P or C. Put () := {xI/Cl , . · · ,  xm/cm}. Since () is ground for C, for some 
i (1 :$ i :$ k), Li() is f in T3ptni. But then ni > 0 and so Li must be negative, Li = ..,A. 
Thus, A() is t in T3pjni. By (B3), since -.A E C E C- , we have that A E C+ .  By (AI), 
A() E C+ 
Now if -.A is not the only literal of C (that is, if k > 1), then the positive rank {{niH 
for A8 precedes ", in the multiset ordering. By induction hypothesis for (i) , A() E yeS. 
But also, if C = -.A (that is, k = 1 and {{ ni H = TJ), then by the argument of Case I, it 
still follows that A() E yes. So we have that A() E yes anyway. 

194 
Chapter 8 
Then by Lemma 8.50, A E YeS. Finally, by (N2) (whatever k), C E NO. 
Case IV. C E C+ is ground, 1/ is a positive rank of C, and all literals Li are negative, 
Li = ...,Ai ·  
By (A3), Ai E C - (i = 1 ,  . . .  , k). 
Now if C has more than one literal (that is, if k > 1), then the negative rank {{ni}} 
for Ai (i = 1 ,  . . .  , k) precedes 1/ in the multiset ordering. By induction hypothesis for 
(ii), A E NO (i = 1, . . . , k). Therefore, by (Y3), C E YeS. 
But also, if C = -.AI consists of one literal only (k = 1), then by the argument of Case 
II it still follows that Al E NO. And again by (Y3), C E YeS. 
• 
Combining these results with Corollary 8.37, the following completeness result now is 
easy. 
Theorem 8.52 (Completeness) 
(i) Suppose that C E C+ . If comp(P)Pa'V A C(J, then C has a computed answer sub­
stitution 0 such that C(J is an instance of CO. 
(ii) Suppose that C E C- . If comp(P)P3..,3 A C, then there is a finitely failed SLDNF-
tree for C. 
Proof. If necessary, extend the language with infinitely many new constant symbols. 
Then P remains S-correct. This move extends the classes C+ and C-. We prove the 
theorem with respect to these extended classes. 
(i). Assume that C E C+ and comp(P)p3'V A C(J. Let Var(Cu) = {Xb . . .  , Xm}. 
Choose constant symbols Cl , . . .  , em  outside C and P. Put 0 := {xI/cl, . . . .  Xm/em}. 
Then comp(P)p3 A C(JO. By Corollary 8.37, n exists such that A C(JO is t in T3pln. 
Thus, 1J := {{n, . .
. , n}} is a positive rank of CuO. By (AI), C(J and C(JO are in C+ . By 
Lemma 8.51, C(JI) E YeS. By Lemma 8.50, C(J E YeS. Now the claim follows from 
Lemma 8.49(i). 
(ii). Suppose that C E C- and comp(P) P3-.3 A C. By Corollary 8.37, n exists such 
that ..,3 A C is t in T3pln. Thus, 1J := {{ n, . . .  , n}} is a negative rank for C. By Lemma 
8.51, C E NO. The claim follows from Lemma 8.49(ii). 
• 
Exercises 
8.31 Show: 
(i) every permutation of a query in YeS (resp. NO) is in YES (resp. NO), 
(ii) (C, D) is i n  YeS iff both C and D are in YeS. 
8.32 Show: if A E No and C E YeS, then (-.A, C) E YeS. 
Hint. Induction with respect to the hypothesis that C E YeS. 

Negation 
8.33 Show: 
(i) if () is a computed answer substitution for C, then C() E YeS, 
(ii) if C has a finitely failed SLDNF-tree, then C E NO. 
Hint. Use Exercise 8.32. 
8.8 
Notes 
195 
The slogan "Algorithm=Logic+Control" is from [Kowalski 79). For the semantical issues 
raised by negation as finite failure, see [Kunen 91) , [Shepherdson) and [Apt/Bol 93}. The 
problem that any semantics that is adequate with respect to negation as finite failure 
necessarily must be rather involved, entails what [Kunen 91] calls the Ph.D. effect, which 
means a Ph.D. in logic is needed to understand it. With deplorable consequences for the 
poor programmer at work. But note that [Kunen 89] shows that 3- and 2-valued semantics 
coincide for programs that are strict. 
Negation as (finite) failure was suggested in [Clark 78). At first glance, it appears that 
a formal definition of the resulting derivability notion will not present any difficulties. 
However, this impression seems to be mistaken. (The definitions in both editions of 
[Lloyd 87) do not always yield what is expected.} What is presented in Section 8.2 
constitutes the proposal from [Apt/Doets]. The term forest was suggested by Roland 
Bol. 
Undecidability of the problem whether floundering will occur is shown in [Apt 90]. 
For a proof of Theorem 8. 14 (Exercise 8.3) in a somewhat different context, see 
[Apt/Doets). 
The material from Exercise 8.5 is elaborated upon in [Apt/Pedreschi 91]. 
The idea to use a 3-valued semantics with respect to SLDNF is from [Fitting 85], 
following the example of [Kripke 75]. The 3-valued truth tables are due to Kleene. 
Exercise 8.12 occurs in [Kunen 87J as Lemma 6.l. 
The almost purely model theoretic material of Section 8.6 replaces the exotic limit of 
3-valued ultrapowers of the models T3pjn from [Kunen 87] by recursive saturation. For 
more on this notion, see [Chang/Keisler 90J section 2.4. Lemma 8.32 occurs there as 
Corollary 2.4.2. Or see [Hodges 93] . 
The final results of Section 8.6 can be generalized - with the same proofs - to the 
more general context where J is an arbitrary model (in the sense of first-order logic, that 
is, with relations) and where the bodies of the rules of P may refer to the relations of 
J. In particular, they can be generalized to the context of constraint logic programming. 
Theorem 8.36 is a special case of the general phenomenon that first-order definable 
monotone operators over a recursively saturated model have their hierarchy close at w .  
For consequence operators, the proof of this fact happens to be particularly simple. 

196 
Chapter 8 
Lemma 8.35 is from [Kunen 87], but transposed to the context of recursive saturation. 
Section 8.7 is entirely based on [Stark 93], which dramatically strengthens [Kunen 89] . 
Using proof-theoretic methods, completeness results stronger than Kunen's were already 
obtained in [Stark 9 1 J .  The Ph.D. effect is felt here. 
Except for the use of three­
valuedness, the present completeness result appears to close the gap between theory 
and practice quite satisfactorily; in any case, it connects a positive solution to the com­
pleteness problem of the theory with the way in which programs are used in practice. 
Also, the solution given does not depend on the terminating behavior of programs. Of 
course, to actually find the SLDNF proofs the existence of which is claimed, a breadth­
first search is needed. For SLDNF, there is no selection rule independence result. As 
a first approximation, it is worthwhile to delay selection of negative literals as far as 
possible until they have become ground. Also, the completeness result still is a far cry 
from what would be needed for Prolog, with its meta-level facilities. 
For work pursuing that of [Stark 93], see [Stark 93a]. 
The amusing solution to Exercise 8.28 is Apt 's; the result is in [Lloyd/Topor 86] . 
Exercise 8.29 is from [Kunen 89] . 
The proof of Lemma 8.51 goes back to an induction in [Kunen 89]. Exercise 8.30 shows 
Kunen's result, which is about allowed programs and queries, to be subsumed by Stark's. 
Stark gives credit to Buchholz for the use of YES and NO. His notion of SLDNF is that 
of Definition 8.12, which is from [Kunen 89] . Since completeness only is about success 
and finite failure, this simple "bottom-up" inductive definition forms an elegant way to 
avoid conSidering SLDNF-trees and SLDNF-derivations altogether. Though Definition 
8.12 suffices when dealing with completeness of SLDNF-resolution, it cannot be used to 
reason about properties that inherently refer to SLDNF-trees, such as termination. Note 
that [Kunen 89J and [Stark 93] do not put the restriction Var(Ca) n Var(DC7) C Var(D) 
in R+), thereby allowing answers that are not maximally general. 
On the topic of termination, largely left untouched here, the reader should consult 
[Apt/Pedreschi 91J. 
To get better 2-valued semantics, theorists have concentrated on special programs, 
e.g., (locally) stratified ones, and programs permitting natural, e.g., stable, well-founded 
models. This line of research has not been considered here. 

 
Bibliography 
(Apt 90] 
[Apt/Bezem 91] 
[Apt/Bol 93] 
[Apt/Doets] 
[Apt/Pedreschi 91] 
[Apt/Pellegrini 92] 
[Barwise 75] 
[Bezem 90) 
[Bezem 93] 
[Bezem/Hurkens 92] 
[Blair 82] 
[Blair/Brown 90] 
[Chang/Keisler 90] 
[Church 36] 
[Clark 78] 
[Davis/Putnam 60] 
[Dershowitz/Manna 79J 
[Doets 92] 
[Doets aJ 
[Doets bl 
[Fitting 85J 
KR. Apt: Logic programming. In: Handbook of Theoretical Computer 
Science. (J. van Leeuwen, ed.) Elsevier 1990, pp 493-574. 
KR. Apt and M.A. Bezem: Acyclic programs. New Genemtion Com­
puting 29 (1991) pp 335-363. 
KR. Apt and R. Bol: Logic programming and negation. Manuscipt 
1993. Submitted for publication. 
KR. Apt and K Doets: A new definition of SLDNF. J. Logic Pro­
gmmming, forthcoming. 
K.R. Apt and D. Pedreschi: Proving termination of general Prolog 
programs. In Proceedings of the International Conference on Theo­
retical Aspects of Computer Software (T. Ito and A. Meyer, editors), 
Lecture Notes in Computer Science 526, pp 265-289, Springer, Berlin 
1991. 
KR. Apt and A. Pellegrini: On occur-check free Prolog programs. 
Report CS-R9238, CWI Amsterdam 1992. Also ACM Toplas, forth­
coming. 
J. Barwise: Admissible sets and structures. Springer, Berlin etc. 1975. 
M.A. Bezem: Completeness of resolution revisited. Th. Computer Sci­
ence 74 (1990) pp 227-237. 
M.A. Bezem: Strong termination of logic programs. J. Logic Progmm­
ming 15 (1993) pp 79-97. 
M.A. Bezem and A.J.C. Hurkens: Yet another equivalent of the Axiom 
of Choice. Problem lO245 , Am. Math. Monthly 99 (1992) P 675. 
H. A. Blair: The recursion-theoretic complexity of predicate logic as a 
programming language. Information and Control 54 (1982) pp 25-47. 
H.A. Blair and A.L. Brown: Definite clause programs are canonical 
over a suitable domain. Annals of Mathematics and Artificial Intelli­
gence 1 (1990) pp 1-19. 
C.C. Chang and H.J. Keisler: Model theory, Amsterdam 1990. 
A. Church: A note on the Entscheidingsproblem. J. Symbolic Logic 1 
(1936) pp 40-41 and 101-102. Reprinted in The Undecidable, M. Davis 
editor, pp 110-115, Raven Press 1965. 
KL. Clark: Negation as failure. In: Logic and Data Bases, (H. Gal­
laire and J. Minker, eds.) Plenum, New York 1978, pp 293-322. 
M. Davis, H. Putnam: A computing procedure for quantification the­
ory. J. ACM 7 (1960) pp 201-215. 
N. Dershowitz and Z. Manna: Proving termination with multiset or­
derings. Comm. ACM 22 (l979) pp 465-476. 
K Doets: A slight strengthening of a theorem of Blair and Kunen. 
Th. Computer Science 97 (1992) pp 175-181. 
K Doets: 
Left termination turned into termination. Th. Computer 
Science, forthcoming. 
K. Doets: Levationis laus. Logic and Computation, forthcoming. 
M. Fitting: A Kripke-Kleene semantics for logic programs. J. Logic 
Progmmming 2 (1985) pp 295-312. 

198 
[Herbrand 30] 
(Hodges 93] 
(Kowalski 74] 
(Kowalski 79J 
[Kripke 75J 
[Kunen 87J 
[Kunen 89J 
[Kunen 91) 
[Lassez/Maher /Marriott 88] 
(Lloyd 87] 
(Lloyd/Shepherdson 91J 
[Lloyd/Topor 86J 
(Martelli/Montanari 82] 
(Odifreddi 89J 
[Paterson-Wegman 78J 
[Reiter 78] 
[Robinson 65) 
[Shepherdson] 
[Smullyan 79) 
Bibliography 
J. Herbrand: 
Recherches sur la theorie de la demonstration, The­
sis, Paris 1930. In: Bcrits logiques de Jacques Herbrand, Paris PUF 
1968. English translation Investigations in Proof Theory in: Jacques 
Herbrand, Logical Writings, W. Goldfarb editor, Harvard University 
Press 1971. 
W. Hodges: Model theory, Cambridge University Press 1993. (VoI.42, 
Encycl. of Math. and its Applications.) 
R.A. Kowalski: Predicate logic as a programming language. Proceed­
ings IFIP'74 North-Holland 1974, pp 569-574. 
R.A. Kowalski: Algorithm=logic+control. Comm. ACM 22 (1979) pp 
424-435. 
S. Kripke: Outline of a theory of truth. J. Philosophy 72 (1975) pp 
69{)-715. 
K. Kunen: Negation in logic programming. J. Logic Programming 4 
(1987) pp 289-308. 
K. Kunen: Signed data dependencies in logic programs. J. Logic Pro­
gramming 7 (1989) pp 231-245. 
K. Kunen: Declarative semantics of logic programming. Bulletin of 
the European Ass. for Theoretical Computer Science 44 (1991) pp 
147-167. 
J.L. Lassez, M.J. Maher and K .  Marriott: 
Unification revisited. 
In: 
Foundations oJ- Deductive Databases and Logic Programming 
(J. Minker ed.) Morgan Kaufmann, Los Altos 1988. 
J.W. Lloyd: Foundations of Logic Programming. 2nd, extended edi­
tion, Springer 1987. 
J.W. Lloyd, J.C. Shepherdson: Partial evaluation in logic program­
ming. J.Logic Programming 11 (1991), pp 217-242. 
J.W. Lloyd and R. Topor: A basis for deductive databases II. J. Logic 
programming 3 (1986) pp 55-67. 
A. Martelli and U. Montanari: 
An efficient unification algorithm. 
ACM 1Tans. on Programming Languages and Systems 4 (1982) pp 
258-282. 
P. Odifreddi: Classical recursion theory. Studies in logic and the foun­
dations of mathematics Vol. 125, North-Holland, Amsterdam 1989. 
M.S. Paterson and M.N. Wegman: 
Linear unification: J. Comput. 
Systems Sci. 16 (1978) pp 158-167. 
R. Reiter: On closed world data bases. In: Logic and Databases, (eds. 
Gallaire and Minker), Plenum 1978, pp 55-76. 
J.A. Robinson: A machine-oriented logic based on the resolution prin­
ciple. J. ACM 12 (1965) pp 23-41. 
J. Shepherdson: 
Negation as failure, completion and stratification. 
Draft; to appear in Handbook of logic in artificial intelligence and 
logic programming Vol. IV, Chapter 4.5. 
R. M. Smullyan: 
Trees and ball games. Annals of the New York 
Academy of Sciences 321 (1979) pp 86-90. 

Bibliography 
[Stark 89) 
[Stark 91) 
[Stark 93) 
[Stark 93a) 
(Sterling/Shapiro 86) 
(van Emden/Kowalski 76) 
199 
RF. Stark: A direct proof for the completeness of SLD-resolution. In: 
E. Borger, H. Kleine Buning, M.M. Richter (Eds.): CSL '89. Springer 
Lecture Notes in Computer Science 440, Springer-Verlag 1990, pp 
382-·383. 
R F. Stark: A complete axiomatization of the three-valued completion 
of logic programs. J.Logic and Computation 1 (1991) pp 811-834. 
RF. Stark: 
Input/output dependencies of normal logic programs. 
Report 93:6, Universitat Munchen, Centrum fur Informations- und 
Sprachverarbeitung. J. Logic and Computation, forthcoming. 
RF. Stark: From logic programs to inductive definitions. Manuscript, 
submitted to Logic Colloquium '93. 
L. Sterling and E. Sha.piro: The Art of Pmlog. MIT Press 1986. 
M.H. van Emden and RA. Kowalski: The semantics of predicate logic 
as a programming langua.ge. J. ACM 23 (1976) pp 733-742. 

 
Rules and Programs 
$,76 
EVEN,76 
eq, 86 
noteq,86 
lN, 87 
SUM, MULT, 88, 96 
binary notation, 89 
append,90 
list length, 90 
member, 91 
reverse, 91 
quicksort, 91 
Solitaire, 119 
wonderful sequences, 119 
infinite computations, 138 
pairing, 147 
recursive functions , 148 
zero, 151 
computing over Tpjw, 154 
primitive recursion using up, 155 
primitive recursion using down, 155 
co-computing well-founded parts, 160 
co-computing IIf relations, 162 
transitive closure , 173 
EVEN2,174 
List inclusion, 188 

 
Notation 
:=, definitionally equivalent with, 1 
:=, definition ally equal to, 1 
sets: 
a E A, a element of A 
{a, b, c, . . . }, set of a, b, c, ... 
{a E A I E(a)}, set of a E A satisfying E 
n, n, U, U, intersection, union 
-, difference 
A c B, A (not necessarily proper) subset of B 
P(K), powerset of K, 76 
0,1,2, . . . , natural numbers 
lN, set of natural numbers, 1 
7l, set of integers, 40 
{{al,"" an}}, multiset of al, ... , an, 6 
W, first infinite ordinal, 10 
supA, supremum of set of ordinals A, 10 
relations: 
( a, b), (al,' .. , an), ordered pair, n-tuple 
A x B, (Cartesian) product 
A2, An, sets of pairs, n-tuples from A 
aRb, a R-related to b 
Rtr, transitive closure of R, 6 
functions: 
f : A--+B, f function from A to B, 3 
f : a 1-+ b, f(a) = b, f sends a to b 
Dam(J), domain of f 
logic, informally used: 
=>, ¢:}, if· . ·then, iff (if and only if) 
/\, V, -', and, or, not 
'1:/, 3, for all, there exists 
formal logic: 
-', /\, /\, v, V, --+, t-+, connectives, 13 

204 
T, J.., empty conjunction/disjunction, 14 
V, 3, quantifiers, 29 
other: 
ht(x), height, 10 
t, f, (classic) truth values , 15 
'Ypcp, propositional satisfaction , 16 
'Ypr, pcp, rpcp, 16, 34 
cp '" '1/;, logical equivalence, 16, 35 
0, empty clause/query, 20, 45, 94 
E I-p E, propositional derivability, 21, 54 
N, equality symbol, 30 
Var{t), Var(cp) , (free) variables, 30, 31 
CA, A-language, 32 
tA, value of t in A, 33 
Apcp, first-order satisfiability, 33, 34 
ta, cpa, 34 
{XI/al"" ,xn/an} , assignment, 34 
A ® B, isomorphic ,  36 
HU, Herbrand universe, 38 
H A, Herbrand algebra, 39 
TM, set/algebra of all terms, 40, 124 
Dom(O), domain of 0, 41 
EO, O-instance of E, 41 
{XI/tl,' . .  , xn/tn} , substitution, 41 
'Icp, 3cp, closures of cp, 43 
ground(cp), ground instances of cp, 43 
A c B, A -< B, (elementary) submodel, 52, 53 
E I-u E, unrestricted first-order derivability, 56 
E, identity substitution, 58 
OjV, V-restriction of 0, 58 
0>', composition, 58 
Eon set of identities associated with a, 62 
E I- D, first-order derivability, 66 
A¯C, rule, 71 
HB, Herbrand base, 73 
Mp, least Herbrand model, 73 
Notation 

Notation 
Tp, immediate consequence operator, 76 
T i, T L least- and greatest fixed point, 79 
T i Ct, Ct-th stage upward hierarchy, 80 
T! Ct, Ct-th stage downward hierarchy, 82 
Td, dual of T, 83 
Tj(Z), T+, 83 
+- C, goal, 94 
C< 
C -----+u D, unrestricted resolution step, 95 
E{A/C}, replacing A by C in E, 96 
res(r), resultant of r, 97 
rk(A), rk(D), ranks of atom, query, 101 
C< 
C -----+ D, resolution step 102 
[ t ], released variables condition, 108 
C< 
C --+-> D, derivation, 113 
C E F, CRCt, inductively defined SLD(NF), 114, 172 
HU(V), extended Herbrand universe, 123 
H A(V), extended Herbrand algebra, 123 
1N + 7l, 124 
HBJ, J-Herbrand base, 124 
Tt, J-operator, 125 
GRD(T, J, cr), realization tree 130 
comp(P) , completion of P, 136 
Ax.T(x), A-notation, 146 
pm.T(m), minimality-operator, 146 
rr, 2:, , arithmetical hierarchy, 155 
m, 2:L kL analytical hierarchy, 156 
a(p), p-approximation of cr, 158 
Wf(T, -<), well-founded part, 160 
wfK, Church-Kleene WI, 163 
u, truth value undefined, 174 
MP3ip, 3-valued satisfaction, 175 
M S N, 3-valued models ordering, 175 
T3p, T3R, 3-valued operators, 176 
T3~ , stage 3-valued hierarchy, 177 
in, out, neutral, modes, 185 
C+, C-, correct/closed queries, 187 
YES, NO, 190 
205 

 
Index 
A 
algebra, 39 
CET, 123 
Herbrand, 39 
non-standard, 123 
arithmetical, 156, 158 
assignment 
truth, 16 
variable, 34 
atom, 30 
J-ground, 124 
bounded, 153 
ground 
rank of, 101 
occurrence, 96 
selected, 95, 102 
axiom 
domain closure, 123 
free equality, 40, 62, 122 
occur check, 123 
B 
branch,4 
c 
c.a.s., computed answer substitution, 98, 
170 
calculable, 141 
CET, 62,122 
algebra, 123 
chain, 54 
elementary, 54 
lemma, 54 
characteristic function, 5 
child, 4 
Church 
theorem, 29, 46, 68, 150 
thesis, 145 
clausal form, 20 
clause 
definite, 94 
empty, 20 
first-order, 54 
propositional, 20 
unit, 71 
closed, 77 
closed world assumption, 121 
closure 
existential, 43 
transitive, 6, 173 
universal, 43 
co-define, 157 
compactness 
first-order, 52 
propositional, 26 
completeness 
first-order, 67 
ground linear, 100 
negation as failure, 137 
propositional, 22 
SLD,116 
strong, 117 
SLDNF,194 
unrestricted first-order, 57 
weak linear, 112 
completion, 135 
computable, 141 
concatenation, 90 
conjunct, 14 
conjunction, 13, 14 
length-D, length-I, 14 

208 
conjunctive normal form, 17 
theorem, 18 
connective, 13, 29 
constant, 32 
countable, 11 
D 
DCA, 123 
decidable, 141 
positively, 141 
definable 
first-order, 86 
define, 85 
De Morgan law, 16 
derivation 
J-ground, 127 
first-order, 66 
first-order unrestricted, 55 
ground, 100 
linear, 108 
lift of, 110 
unrestricted, 97 
propositional, 21 
pseudo-, 167 
realization, 128 
similar, 11 a 
SLDNF,170 
finite, 170 
step, 21, 56 
successful, 98, 109 
descendant, 4 
disjunct, 14 
disjunction, 13, 14 
length-a, length-I, 14 
disjunctive normal form, 18 
distribution law, 16 
E 
edge, 4 
equivalence, 13 
equivalent, 
first-order, 35 
propositionally, 16 
expression 
most general, 65 
extension, 52 
elementary, 53 
F 
fact, 71 
false, 15 
falsum, 14 
finite failure 
negation as, 121 
rule, 121 
theorem, 131 
fixed point, 77 
greatest, 125 
inductive, co-inductive, 77 
least, 125 
least, greatest, 78 
pre-, post, 77 
pre-, post-, 77 
theorem, 78 
floundering, 169, 189 
follow logically 
first-order, 35 
propositionally, 16 
forest , 167 
main tree, 167 
path, 168 
formula 
Index 

Index 
A-,32 
atomic, 30 
defining, 135 
first-order, 30 
ground, 31 
prenex, 47 
propositional, 13 
G 
goal, 93 
empty-,94 
Codel number, 142 
graph 
directed, 3 
of function, 85 
ground, 31 
J-,124 
H 
halting problem, 145 
Herbrand 
J-base, 124 
algebra, 39, 122 
base, 73 
model, 38, 39, 73 
rule, 121 
theorem, 43 
universe, 38 
hierarchy 
3-valued, 177 
analytical, 157 
arithmetical, 155 
downward, 82, 125, 178 
stage, 82 
upward, 80, 81, 125, 178 
stage, 80, 81 
Horn, 119 
hyperarithmetical, 156 
I 
identity, 31 
implication, 13 
induction, 1, 77 
basis, 1 
fixed point-, 77 
formula-, 14, 31 
hypothesis, 1 
proof by, 1 
step, 1 
strong-, 2 
term-,30 
inductive, 77 
co-,77 
instance, 41 
J,124 
common, 64 
most general, 64 
interpretation 
declarative, 166 
209 
declarative, procedural, 72, 165, 166 
isomorphism, 9, 36 
K 
Kleene's theorem, 159 
Konig's lemma, 5, 133, 136, 154 
L 
lambda notation, 146 
language 

210 
A-, 32 
algebraic, 39 
algebraic part of, 39 
first-order, 30 
propositional, 13 
leaf, 4 
lift, 110 
lifting 
ground derivations, 128 
one step, 105 
one step ground-, 127 
theorem 
first-order resolution, 66 
linear resolution, 110 
list, 90 
length, 90 
literal 
first-order, 54 
negative, 17, 165 
positive, 17 
propositional, 17 
selected, 168 
logical consequence 
first-order, 35 
propositional, 16 
loop, 4 
M 
marker, 167, 168 
meet, 22 
minimal,22 
mgu,59 
idempotent, 62, 63, 64 
relevant, 62, 64 
minimal,8 
minimalization, 146 
mode, 185 
specification, 185 
model, 31 
(elementary) sub-, 52 
3-valued, 174 
expansion, 125 
extension, 52 
elementary, 53 
Herbrand, 38 
least, 73 
over J, 125 
reduct, 125 
saturated, 180 
recursively, 180 
universe of, 32 
model of, 34 
multiset, 5, 6 
N 
negation, 13 
as (finite) failure, 121, 166 
node, 4 
o 
operator 
dual, 83 
finitary, 80 
immediate consequence, 76, 125 
3-valued, 176 
monotone, 78 
order type, 9 
ordering, 6 
ordinal, 10 
closure, 81, 177 
recursive, 163 
Index 

Index 
p 
parent, 4 
parentheses, 13, 14, 31 
path, 3, 168 
Ph.D. effect, 195 
powerset, 76 
prenex form, 47 
primitive recursion, 146 
principle 
Curry's, 120 
induction, 1 
least number, 3 
pigeon-hole, 5 
program, 71 
allowed, 169, 188 
co-definable, 157 
completion, 135, 166, 177 
computable, 148 
correct, 186 
declarative interpretation, 72, 99 
definable, 85, 148 
definite, 166 
determinate, 144 
general, 165 
positive, 166 
procedural interpretation, 72, 99 
recurrent, 153 
weakly, 153 
terminating, 153 
Prolog, 69, 72, 87, 115, 119, 163, 165, 
169, 196 
proposition letter, 13 
Q 
quantifier 
existential, 29 
scope, 31 
universal, 29 
query, 94 
(positive) rank, 101, 192 
allowed, 188 
bounded, 153 
closed, 186 
correct, 186 
empty, 94 
failed, 168 
general, 165 
negative rank, 192 
positive, 166 
similar, 110 
success, 168 
R 
rank 
of atom, 101 
of query, 101, 192 
realization, 128 
recursive, 145, 147 
definition, 146 
partially, 145, 146 
total, 147 
recursively enumerable, 145, 147 
refutation 
first-order, 66 
unrestricted, 56 
propositional, 21 
relation, 3 
binary, n-ary, 3 
inequality, 86 
irreflexive, 6 
transitive, 6 
211 

212 
unary, 3 
renaming, 58 
resolution 
first-order, 66 
unrestricted, 55 
linear, 93 
propositional, 21, 54 
SLD,114 
SLDNF,169 
SLDNFE,169 
resolvent 
J-ground, 127 
first-order, 65 
unrestricted, 54 
linear, 102 
unrestricted, 95 
propositional, 21 
SLDNF, 167 
resultant, 96, 97 
root, 4 
rule, 71 
s 
allowed, 188 
applicable, 115 
body, 71 
correct, 186 
definite, 94, 166 
general, 165 
head, 71 
positive, 166 
selection, 114 
satisfaction 
first-order, 34 
propositional, 16 
satisfiable 
first-order, 34 
propositionally, 16, 25 
saturated, 180 
recursively, 180 
selection rule, 114, 172 
fair , 115, 131 
irrelevance of, 117 
strong, 117 
leftmost, 115 
lifting invariant, 115 
sentence, 31 
A-,32 
existential, 43 
Horn, 94 
universal, 43 
matrix, 43 
prefix, 43 
Skolem 
expansion , 43 
form , 47 
theorem, 47 
SLD, 114 
SLDNF, 169 
SLDNFE,169 
soundness 
3-valued, 178 
first-order, 66 
unrestricted, 56 
linear, 109 
unrestricted, 99 
negation as failure, 137 
propositional, 22 
SLDNF, 180 
specialization, 95 
specification 
input/output, 185 
mode, 185 
Stark conditions, 187 
Index 

Index 
standardizing-apart, 120 
subformula, 14 
submodel, 52 
substitution, 41, 57 
admissible, 48 
answer 
computed, 98, 170 
correct, 98 
composition, 58 
domain, 41 
ground, 41 
identity, 58 
more general, 59 
success, 98, 109 
supported, 77 
symbol,30 
interpretation of, 32 
canonical, 37 
meaning of, 32 
Skolem function, 50 
T 
Tarski's theorem, 157, 158 
term, 30 
A-,32 
ground, 30 
substitutable, 47 
value of, 33 
termination, 173 
tree, 4 
branch,4 
description of, 5 
edge, 4 
finitely branching, 4 
finitely failed, 167 
forest, 167 
height, 10 
implication, 74, 126 
leaf, 4 
main, 167 
node, 4 
occurrence, 5 
path,3 
pre-SLDNF, 168 
extension of, 168 
initial, 168 
prefix, 159 
realization, 130 
well-founded, 131 
root, 4 
SLD, 115 
failing, 1 16 
fair, 131 
successful, 116 
SLDNF, 169 
finite, 170 
finitely failed, 170 
successful, 170 
subsidiary, 167 
successful, 167 
well-founded, 7, 131 
true, 15 
first-order, 34 
truth 
3-valued, 174 
assignment, 16 
definition, 33 
table, 15 
value, 15, 174 
Turing'S theorem, 145 
213 

214 
u 
unification, 59, 127 
algorithm, 60 
theorem, 59 
unifier, 59 
idempotent, 62 
most general (mgu), 59 
relevant, 62 
v 
valid 
first-order, 34, 47 
logically, 34 
propositionally, 16 
variable 
bound occurrence, 31 
free occurrence, 31 
individual, 29 
propositional, 13 
release of, 107, 167 
variant, 58 
verum, 14 
w 
well-founded, 7, 8, 154, 160 
part, 160 
well-ordering, 7 
Index 

