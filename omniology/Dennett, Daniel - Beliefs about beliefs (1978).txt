THE BEHAVIORAL AND BRAIN SCIENCES (1978), 49 555-629
Printed in the United States of America
consciousness
In nonhuman species:
Open Peer Commentary
and Authors' Responses
Commentaries submitted by the qualified professional readership of this journal will be
considered for publication in a later issue as Continuing Commentary on these articles.
Note: Commentary reference lists omit works already cited in target article (as indicated
by op. cit.).
Commentary by Donald R. Griffin
The Rockefeller University, New York, N. Y. 10021
Experimental cognitive ethology. Why stop with apes [P&WJ? The experiments
described in P&W's paper provide an excellent example of experimental cognitive
ethology. Most are still under way or planned for the future, so that it is not yet
possible to evaluate what they may tell us. The preliminary results sound
promising, and we will await with considerable interest the subsequent more
complete report. Meanwhile P&W have set all ethologists an excellent example by
trying an approach which, if successful, will be very informative indeed. There is
no reason why comparable experiments should not be attempted with animals
other than Great Apes. Obviously the experimental details will need appropriate
modification, but the basic possibility deserves serious exploration. Unsuccessful
and usually unpublished attempts to elicit significant responses to motion pictures
have discouraged this approach, and it may well be that only a few of the most
gifted species will prove amenable to it. But significant results have been obtained
by Jenssen (1970 op. cit. G) with Anolis iizards and by Amlaner and Stout (1978)
with gulls. Only further efforts will disclose whether a wider variety of social
animals can be induced to respond to experimental simulations of various kinds
in a sufficiently normal fashion to permit experimenters to establish significant
two-way communication. The potential significance of the results that might be
achieved is difficult to overestimate, and the tentative conclusions discussed by
P&W give us a taste of what may lie ahead.
The final remarks concerning primitive and natural inferences and "intelligent"
positivism should stimulate all interested behavioral scientists to consider carefully
whether preconceptions or biases affect their interpretations of animal behavior.
To the extent that inferring mental states in other living organisms is primitive and
natural, the possibility arises that such states are widespread among social
animals. Even though the content of the inferences may be simple and crude, their
presence would be a significant attribute of animals. It is correspondingly
important for ethologists to ascertain whether or not such inferences about the
intentions of other organisms are present in various species, and if so, under what
conditions. If this prospect appears fanciful, unrealistic, or too difficult to warrant
serious consideration, I suggest that we ask ourselves how realistic P&W's
experiments would have seemed had anyone suggested them ten or fifteen years
ago.
Parsimonious intentionality [SR&B]. The ability of Austin and Sherman to
communicate about tools needed to acquire particular foods provides important
new evidence that chimpanzees can communicate intentionally with at least
rudimentary understanding of what they are doing. There will doubtless be some,
like Sebeok (1977), who continue to suspect that unrecognized cues, unintention-
ally provided by the experimenters, may be responsible for what looks so much
like intentional communication. But the complexity that would have to be postu-
lated in such a "Clever Hans" explanation makes the assumption of intentionality
seem parsimonious. The ability of Austin and Sherman to interchange roles is also
important; it is reminiscent of the spontaneous interchange of transmitting and
receiving roles observed by Lindauer (1971 op. cit. G) in honeybees dancing
about the location of cavities. As other commentators will doubtless discuss in
detail, all the accomplishments of Washoe and her several successors can be
interpreted in behavioristic terms as complex examples of discriminative learning.
But since human intellectual activities and linguistic communication can also be
viewed in a similar light, such interpretations are not particularly helpful in trying to
decide whether or not apes are sometimes aware of the results their signalling is
likely to produce.
Much will depend on the extent to which apes that have been trained to employ
symbolic communication may later use it spontaneously to accomplish objectives
not built into the experimental situation by the investigators. It is too early to
expect ideally controlled and completely documented examples of spontaneous
symbolic communication, because the acquisition of such communicative abilities
is a necessary first step before they can be used in a spontaneous and creative
fashion. Spontaneous behavior is by its very nature difficult to organize into a
controlled experiment. If it has been anticipated by the experimenters and
arrangements made for suitable controls, these arrangements themselves may
encourage the occurrence of what looks like spontaneity. It may be necessary to
wait and see whether apes surprise us by unanticipated uses of symbolic
communication for their own purposes.
The leading groups of experimenters training apes to use symbolic communi-
cation share a general faith in the significance of the endeavor, but they are often
critical of each other's specific experimental procedures. If one accepts the
sharpest of these mutual criticisms, it is tempting to dismiss all of the results as
inconclusive. But this type of experiment is so new, so challenging, and so
exhaustingly difficult, that despite serious problems remaining to be resolved, the
accomplishments of both apes and experimenters suffice to demonstrate much
more versatile and enterprising thinking on the part of nonhuman animals than
most scientists were prepared to recognize as little as ten years ago. It is difficult
to escape the conclusion that these animals must have specific intentions, definite
awareness, and at least rudimentary understanding of the relationships about
which they manage to communicate.
REFERENCES
Amlaner, C. J., Jr., and Stout, J. F. Aggressive communication by Larus glau-
cescens: Part VI. Interactions of territory residence with a remotely con-
trolled, locomotory model. Behaviour 66:223-251, 1978.
Sebeok, T. A. Zoosemiotic components of human communication. In T. A. Se-
beok, ed., How animals communicate. Bloomington, Ind. Indiana Univ.
Press, 1977.
Commentary by E. Sue Sawage-Ftumbaugh, Dyane i .
Rymfoaugh, and Sally Boysen
Yerkes Regional Primate Center, Emory University, Atlanta, Georgia 303227Depart-
ment of Psychology, Georgia State University, Atlanta, Ga. 30303 and Yerkes
Regional Primate Center, Emory University, Atlanta, Ga. 30322
Sarah's problems of comprehension. We concur with G's suggestion that
comparative psychologists should investigate the experiential similarities between
human and nonhuman brain function. The study by P&W is obviously an attempt
to answer this type of challenge. Does it succeed? Do the techniques put forth by
P&W demonstrate that the chimpanzee Sarah "recognized the videotape as
representing a problem, understood the actor's purpose, and chose alternatives
compatible with that purpose?"
Â© 1978 Cambridge University Press
0140-525X/78/CCNSOPCR$08.00/0
555

Commentary /Cognition and consciousness in nonhuman species
P&W reach these conclusions on the basis of one animal's selection of static
photographs; her selection of photographs is presumed to be statistically
independent from trial to trial, although materials do not vary across trials on a
given problem. No evidence, other than anecdote, is presented to indicate that
Sarah (1) saw the videotaped scenarios as problems-to-be-solved; (2) perceived
her choice as representing a solution to the portrayed problem; (3) understood
either the elements of the problems or the nature of the solutions; or (4) if faced
with the problem herself, could solve it. Such factors should not be presumed to
be the inherent bases for Sarah's choices of photographs until it is clear that
Sarah understood what she was choosing and why. While such binary choice
tasks are of value if used appropriately, they become meaningless when the
number of cognitive processes to be inferred becomes so large as to permit
essentially a demonstration of anything, provided that the researcher frames his
questions in a sequentially embedded fashion.
P&W's failure to demonstrate that Sarah indeed perceived the taped segments
as problems allows for the real possibility that the dynamics of the scenarios were
beyond Sarah's comprehension and that her photograph choices were based on
strategies simpler than those imputed by the authors. If the scenarios were not
perceived as problems by Sarah, then her choices obviously could not have been
solutions. That she would pick the "correct" photograph - a static, single-frame
sample of a "solution" - should not be construed, without corroborating
evidence, to mean that Sarah saw a logical relationship between the photograph
and an implied course of action which, if carried out, would solve the actor's
problem.
For it to be reasoned that the scenarios were, in fact, problems in Sarah's
perception, it should have been demonstrated at some point that the individual
elements of the problem were meaningful to Sarah and that she understood their
videotaped representation. The fact that she chose a photograph of a burning
wick in response to a photograph of a furnace does not necessarily mean that
she understood that furnaces must be lighted if one is to be warm. Perhaps it
simply implies that Sarah knows that wicks "go with" furnaces and that keys and
faucets do not.
If Sarah did not perceive the video scenes as representations of problems,
then the question arises as to how she might have selected the alternatives as
she did. It seems reasonable to conclude, given the variety of previous training
paradigms Sarah has received, that she could have used relatively simple
associationistic and match-to-sample strategies, none of which would require an
understanding of either the problems portrayed in the videotape or that her
choices represent solutions. For instance, it is clear from the video stills and
photographs presented by P&W that problems 1 and 2 of the banana attainment
series could readily have been solved by a straightforward match-to-sample of
the photograph to the scene held on the monitor on the basis of physical similarity
of the images themselves. Problems 3 and 4 present a more difficult match-
to-sample choice; however, Sarah performed at chance on these. We suggest,
based on numerous cognitive tests of chimpanzees (Rumbaugh 1970 op. cit.
SR&B, 1971), that Sarah would use the simplest strategy available to her, and in
the case of the food attainment problem, the simplest strategy was a physical
match.
The next four problems (nos. 5-8) were object-choice tasks in which Sarah
was to pick a photograph of an object that could be used to solve the actor's
problem. That physical matching was precluded in this particular set of problems
does not mean that Sarah did not use a physical match-to-sample strategy in the
first set of problems as argued by P&W.
Sarah could have solved the second group of problems (problems 5-8) by
past observational experience. It is important to note that Sarah had previous
experience with this type of associative match-to-sample problem ("causality"
problems, in Premack, op. cit. G 1976). It is more parsimonious to conclude that
in the present study Sarah chose the key because she associated keys with
locks, the faucet because she associated the hose with the faucet, and so forth,
than to infer, as P&W do, that Sarah understood that a member of another
species faced a problem, that she comprehended the nature of the problem, and
that she intentionally chose a picture which represented the solution to be
enacted by another individual.
We made a specific test of this possibility with our chimpanzees, Austin and
Sherman, by presenting to them twenty-eight items with which they were familiar
and having them select which one of two additional objects was to be paired with
each sample item. The presented pairs were, in some cases, similar to those
used by P&W (e.g., lock and key - see Table 1) and in other cases quite
different. Five of the pairs represented items with which Sherman and Austin had
worked in keyboard-related tasks and twenty-three pairs represented items with
Table 1. (Savage-Rumbaugh et al.) Single-trial data on unrewarded,
spontaneous associative match-to-sample task
Sample items
Choice items3
foot
automatic food dispenser
vaseline jar
slide tray
wastebasket
padlock
scrub brush
thermos with hole in top
pounding toy
bolt
head
can (used to hold washers)
string (usually used with sponge)
telephone body
pencil
hammer
utensil rack (S)b
bottle
dipping platform (usually used with
stick)
hasp
magnet (S, A)
hose
paper towels (A)
hotplate (A)
can
shoe (S)
food bin
shoe vs. key
dispenser tray vs. hose nozzle
thermometer vs. lock
slides vs. scrub-brush handle
plastic liner vs. hammer
key vs. scoop
scrub-brush handle vs. phone body
drinking-straw vs. paper
mallet vs. dispenser tray
wrench vs. shoelace
hat vs. stick
washers vs. dowel (for juicer)
sponge vs. nail
receiver vs. bottle top
paper vs. thermometer
nail vs. slide
serving spoon vs. hat
bottle top vs. wrench
stick vs. straw
padlock vs. towel rack
metal vs. shoe
spray nozzle vs. washers
towel rack vs. mallet
pan vs. plastic liner
can opener vs. sponge
shoelace vs. telephone receiver
food-scoop vs. can opener
aCorrect item, left. Right-left positions of the items when presented to the
subjects were randomized.
bS and /or A indicates incorrect response by Sherman and/or Austin.
which they were familiar, but with which they had experienced no previous
training. Incorrect alternatives were randomly paired and right-left positioned with
correct alternatives; all testing was given in a blind situation. One experimenter sat
outside the room with the sample object and another experimenter, who did not
know the sample on any trial, sat inside the room with the alternatives. The
chimpanzee observed the sample, went into the room, selected an alternative,
and carried it out of the room to the first experimenter. The chimpanzees received
social praise for all their choices; food reward was unnecessary. The pairs of
items and the alternatives were presented once to each subject and are listed in
Table 1. Sherman and Austin were both correct on 25 of 28 trials (p < .0001,
binomial test), though their errors were not identical. Clearly, Sherman and Austin
were able to make these selections easily even though the experimenter did not
present any formal problem to be solved - simply an object. Their choices were
based on associations between items.
On the basis of these tests we believe that P&W's conclusion that Sarah's
choices were solutions to the actor's videotaped problems is untenable.
The fact that in the third experiment Sarah was able to choose the key, wick,
and so forth, which was the "best" in the sense that it was intact, should not be
taken to imply that Sarah understood that only intact objects could aid the actor in
the solution of his problem. The photographs that required Sarah to choose
among these objects were presented to her after she had already performed the
associative object match. At this point, all that was necessary was for her to
recognize and choose once again the previously rewarded photograph, as
opposed to the new photographs placed beside them. Such recognition
responses have been shown to be well within the capability of monkeys
(Overman, MS submitted to Science, 1978), and one would presume that this
would be an even easier task for a chimpanzee.
In the final set of problems described by P&W, Sarah is described as having
chosen one set of alternatives for one actor and a different set for another actor,
whom she reportedly disliked. The photographs and video scenes for the "good"
actor were those which Sarah had seen before; it is not surprising then that for
him she chose the same photographs as she had initially. Why did she choose the
wrong alternatives for the "bad" actor? P&W do not present to the reader either
the static video scenes or the still photograph solutions involving this actor. Thus,
it is difficult to ascertain exactly what Sarah saw and exactly what she chose. In
556
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4

Commentary /Cognition and consciousness in nonhuman species
any case, for the bad-actor video segment, the good and bad alternatives were
all new to Sarah, and thus she would not be able to choose alternatives that had
been previously correct. Therefore, if she did not understand the problem, one
would expect more variability in her performance, selecting in some instances
good alternatives and in others bad. This is exactly what Sarah did.
In addition to the methodological problems described above, P&W's statistical
case in very weak. Test-wise chimpanzees such as Sarah can easily learn a
series of two-choice problems on the basis of correctness on the first trial and
consequently be right on all subsequent trials. Therefore, in paired-choice tasks
such as those used by P&W it is only the first trial performance on each problem
that reflects the animal's comprehensional capacity. Sarah was given only twelve
trials (four in the banana-attainment series, four in the object-choice, and four in
the good-bad actor series) in which the correct choices presented to her on a
given trial were composed of items not used on previous trials. Although Sarah
was correct on three of the four first-trial choices on the first set of problems of
the banana-attainment series and all four of the first-trial choices on the second
set of problems (nos. 5-8), neither of these results can be statistically significant
at the p < .05 level. (The probability of being correct on four choices in a row by
chance is (1/2)4 or 1/16, a p of only .0625.) As these two sets of four choices
are from qualitatively different problems, pooling them together to obtain p <. .05
is questionable. Even if the pooling were a valid procedure, it should be pointed
out that the significance hinges on the correctness of a single choice of a single
animal on a single trial, for although seven out of eight is significant, six out of
eight falls well short of significance at the p < .05 level. P&W do not report
Sarah's performance on the first four trails of the bad-actor series.
In conclusion, we feel that P&W's paper does not succeed in answering
questions such as those posed by G. Though P&W attempt to offer a new set of
techniques for the study of the ape's knowledge about problem-solving, close
analysis reveals that theirs is simply a modified version of the traditional
match-to-sample paradigm, with rich interpretations replacing important controls.
Explicit efforts will have to be made to take into account criticisms of the kind
made in this commentary if the study of animal thinking is to be resurrected from
the disrepute in which it has been for so long.
ACKNOWLEDGMENT
Research for this commentary was supported by grants NICHD-06016 and
RR-00165, NIH.
REFERENCES
Premack, D., and Woodruff, G. Chimpanzee problem-solving: A test for com-
prehension. Science 202 (4367): 532-535, 1978.
Rumbaugh, D. M. Chimpanzee intelligence. In Bourne, G. (ed), The chim-
panzee, vol. 4., pp. 19-45. Basel: Karger, 1971.
by Benjamin B. Beck
Chicago Zoological Park, Brookfield, III. 60513; and Department of Anthropology,
The University of Chicago, Chicago, III. 60637
Talkers and doers. Humphrey (1977 op. cit. G) and Mason (1976 op. cit. G)
were among the reviewers of Griffin's 1976 monograph (op. cit. G, SR&B) who
noted that his advocacy of nonhuman awareness was neither a new position nor
a revival of a dormant one. Early work in the field to nonhuman cognition ran
headlong into the positivism of behaviorism and the materialism of neurobiology.
The collision produced "talkers" and "doers." Talkers derided both the reduc-
tionism of the neurobiologists and the biological agnosticism of the behaviorists.
However, their most eloquent pleas failed to slow either, and thankfully so, for
both neurobiology and behaviorism have provided major contributions to our
knowledge of the animal mind.
The doers on the other hand, while few, worked steadily. Their research was
neither neurobiological nor behaviorist, but it was sound empirical research
indeed. They preached a bit, but always after supplying data on animal cognition.
A list of doers would surely include Kohler, Yerkes, Kluver, and Menzel.
To be sure, we still do not know much about awareness, mental experiences,
mental images, predictions, or intentions in nonhuman animals, but this is not
surprising, since we really don't know much about such phenomena in humans.
However, we have discovered a great deal about how different animals acquire,
store, and act upon information they encounter in their physical and social
environment. I regard the admittedly modest contributions of the doers to be far
more constructive than continued attempts, doubtlessly fruitless, to convert
neurobiologists, behaviorists, and classical ethologists into cognitive ethologists.
The SR&B and P&W papers are in the best doer tradition. SR&B provide the
first demonstrated instance of symbolically mediated cooperation in nonhumans,
and show that such behavior is more than the mere sum of languagelike
communication and cooperation. Indeed, the various stages of symbol acquisition
and cooperative deployment of those symbols illuminate the essence of such
behavior. I am excited to learn that apes will learn the symbols for objects that
have functional value more rapidly than those for objects with no utility. SR&B's
flagging of the importance of receptive capacity in nonhuman symbolic communi-
cation is timely.
P&W provide evidence that a chimpanzee can impute purpose to humans, but I
do not follow the logic of the purported demonstration of the ape's also imputing
knowledge to the actors. Replication to increase sample sizes would be welcome
but, as the authors note, different tapes and photographs would be required.
Sarah's remarkable capacity for vicarious mischief (toward Bill) has implications
for the nature of chimpanzee sociality. SR&B note that their subjects sometimes
cooperated spontaneously; will they also learn selfishly to deceive?
The SR&B and P&W papers are remarkable in that they both provide ingenious
and innovative probes into the animal mind, and they do so with impeccable
empirical technique. They exemplify the type of research that will constitute
cognitive ethology as a science as contrasted with cognitive ethology as an
assertion.
P&W seem at times to equate "a theory of mind" with the ability to predict the
behavior of others. I am confident that they recognize that a theory of mind is not
a logical requisite for predictive ability. P&W also allude to what I think is an
important point and one that I have made previously (Beck, 1975): there is no
need to assume that the most pedestrian association learning is devoid of mental
experience. I daily avoid burning my hand, and I do so unconsciously. However,
when I choose to contemplate the relationship between my cooking fire, my flesh,
and pain, I can do so with rich imagery. Cognitive automation may be an
adaptation to the conservation of an organism's consciousness for use on
relationships that it does not yet comprehend.
I was a bit concerned by P&W's emphases on the "power and complexity of
the primate mind" as opposed to that of "lesser species." Chimpomorphism will
retard cognitive ethology. We should not conclude that symbolically mediated
cooperation and theories of mind are confined to laboratory-housed chimpan-
zees. Field literature suggests that many wild anthropoids as well as social
carnivores employ such cognitive operations under natural conditions. I have
provided data that indicate that even herring gulls are cognitively active (Beck,
1976). If the evolutionary continuum of cognition proves to be so extended,
Griffin's reminder of the implications for our care of laboratory animals must be
amplified: "cropping" an elephant is distasteful but cropping a thinking elephant
is, to me, unthinkable.
REFERENCES
Beck, B. Primate tool behavior. In Tuttle, R. H. (ed.), Primate socio-ecology
and psychology, pp. 413-447. The Hague: Mouton, 1975.
Predatory shell dropping by herring gulls. Paper presented at the annual
meeting of the Animal Behavior Society, Boulder, Colo., June 1976.
by Jonathan Bennett
Department of Philosophy, University of British Columbia, Vancouver, B.C., Canada
V6T1W5
Some remarks about concepts. "Communication" and "symbolism" [SR&B].
Savage-Rumbaugh et al. show that chimpanzees can interact, in intentional ways,
using symbols. It is good to get away from interactions between chimpanzees and
humans. The mere fact that one participant is human generates a bottomless
reservoir of possible contributions to the chimpanzee's performance; these are all
filtered out when the chimpanzees are induced to interact with one another.
It's also valuable that the chimpanzees faced problems which, though they
were set up by humans, owed none of their essential features to that fact. All the
problems had the form "How can it be opened?" rather than "What does E want
me to do?" In moving from essentially contrived problems to possibly natural
ones, SR&B have escaped from speculations about the chimpanzee's beliefs
about the trainer's desires (see my comments below on P&W); and that filters out
a further possible source of perturbation.
SR&B are to be congratulated on this elegant experiment. Unfortunately, their
interpretation of it is flawed by their uncritical use of certain concepts. Their work
breaks new ground, they say, because it "has demonstrated that two chimpan-
zees have been able to comprehend the symbolic and communicative function of
the symbols they use." But if they have a definite sense for the word "communi-
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4
557

Commentary/Cognition and consciousness in nonhuman species
cative," it is one which makes that claim obviously false; and I cannot find any one
sense that they are giving to the term "symbolic."
SR&B use "communication" to mean something distinct from - perhaps
narrower than? - problem-solving, and this generates for them a criticism of
Premack: "Does Sarah give evidence of comprehending that she is communicat-
ing with her teachers, or that they are communicating with her, as opposed to
simply solving a set of problems?" One would like to know what distinction SR&B
have in mind here. This matters, not just for their importance-claim, but also for
the following reason.
The performances of SR&B's subjects are analogous to injunctions - requests,
commands, pleas, etc. - which aim to elicit behaviour from the other party,
contrast injunctions with statements, which aim to produce belief (or awareness,
or realization, or knowledge) in the other party. Now, what is wrong with saying
that an animal which purposively does anything is thereby requesting or
commanding the universe to produce the desired result? If there were nothing
wrong with that, then all purposive behaviour would be the uttering of injunctions,
and all practical problem-solving would be "communication." There does exist a
stopgap answer to this, namely, that we always restrict "communicate" to cases
where both parties to the transaction are sentient. That is surely right. But why do
we want this restriction? If it is not a mere aesthetic preference, a superficial
linguistic nuance, then there must be some underlying rationale for it, some further
strand in the concept of communication which will lie idle unless the communica-
tors are both sentient. What can this further strand be? One possible answer is
this: "Unless both parties to the transaction are sentient, the communicator can't
produce a belief in the other; and the latter is involved in all communication." That
is not the only nonarbitrary way of stopping the notion of communication from
flattening out so that it covers all purposive behaviour; but it is one plausible way,
and I think it is the one SR&B would choose. They repeatedly appear to assume
that communication essentially involves transfer of information, this being under-
stood as production of belief or awareness or the like. This implies that the basic
purpose of an injunction such as "Hand me the stick" is - in SR&B's phrase -
"the transfer of information regarding the necessary tool"; that is, the command
is really the statement, "I want you to hand me the stick."
I like that account of injunction, and the account of communication in general
which goes with it. I think that in most human communication the speaker does
intend to produce in the hearer a belief-change which may, but need not, be
intended to have some specific further behavioural upshot. That's over-simplified
(see Bennett, 1976, Â§41), but it will do for now. Simplified as it is, it carries an
impressive conceptual load: X intends to make Y believe that X wants such-
and-such. And on any viable account of intention, that involves: X believes that X
can make Y believe that X wants such-and-such. SR&B write as though they were
content with this. They find it "difficult to understand how Sarah could come to
realize that the plastic chips could be used to communicate desires," and they
apparently think that their chimpanzees did come to "realize" such things. On the
most modest construal of this that I can devise, it involves a belief about a belief
about a desire. See also their pregnant remark: "The initiator expected the
recipient to understand why he was gesturing."
Although this is the concept of communication which SR&B manifestly employ,
they couldn't be content with it if they saw what it involved. For they would see
that their experimental work goes no way towards showing that chimpanzees can
"communicate" - let alone believe or comprehend that they are "communicat-
ing" - in this strong sense.
It's puzzling that one should have to say these things. SR&B themselves write:
"The question of whether signing chimpanzees . . . comprehend the nature,
function, and symbolic power of the symbols they use becomes a question of
awareness and intentionality"; and evidently they see this as a problem area
which is "now being reopened." I can't understand how, if they realize that, they
can have permitted themselves to use the concepts of awareness and intention in
such an innocently uncritical manner, both in evaluating their own work and in
criticizing that of others.
Now let us turn to "symbolic." SR&B do not offer to explain this, and it isn't
self-explanatory. Sometimes they apparently use it simply to mean "noniconic";
but then what does "iconic" mean? I would explain it in terms of natural
associations between features, in contrast to those that are institutional, artificial,
stipulated, and so forth; but then one could hardly credit chimpanzees with
making a distinction between icon and symbol - with "understanding that they
could make symbolic requests to one another" or "comprehending the symbolic
nature of the materials they are using" - at least not on any evidence presented
in this paper. It looks as though SR&B would tie "icon" to the notion of something
that resembles what it stands for, and that generates a feeble sense of "symbol"
in which the chimpanzee probably can distinguish icons from symbols, that is,
similar pairs of items from dissimilar pairs.
But neither of those senses of "symbol" makes any sense of SR&B's crucial
use of the term in their importance-claim: their chimpanzees, they say, compre-
hend the symbolic function of the symbols they are using; and elsewhere items
are said to have symbolic power. These phrases are not explained at all, and
couldn't be explained by reading "symbolic" as "noniconic" on any sane
account of what "iconic" means.
An item's symbolic function (or power) might be its use (or capacity to be used)
to symbolize or stand for something else; but SR&B surely do not think that their
results show their chimpanzees to have a grasp of the relation of standing-for.
The chimpanzees do, it is true, know that certain symbols are associated with
other things, but other chimpanzees have been shown to know that much. They
know further that these associations can be exploited for practical purposes; but
there's nothing new about that either.
The best guess I can make is that in the phrases "symbolic power" and
"symbolic function," the word "symbolic" is being given the same meaning as
"communicative." SR&B do sometimes write as though they took those two
terms to be equivalent. Thus they write: "It is impossible to tell whether the
chimparizee is simply imitating or echoing ... the action or object, or whether the
animal is indeed attempting to relay a symbolic message." Here something which
is both symbolic and communicative is contrasted with something which is neither,
and there is no attempt to sort out the ingredients of the mix; so the suggestion is
that "(non)symbolic" and "(non)communicative" must stand or fall together. The
same thing is firmly implied when SR&B allude to "the symbolic and communica-
tive function" - not functions - "of the symbols they use."
Of course I do not accuse SR&B of not knowing that the terms "symbolic" and
"communicative," far from being equivalent, are perfectly independent of one
another: I'm sure that they do know. But I think that they have slipped into a way of
writing and thinking which belies this knowledge. If I am right, then what seems to
be a double importance-claim is really the single claim that their chimpanzees
knew that their behaviour was communicative. If I am wrong, and SR&B's
"symbolic function" and kindred phrases mean something other than "communi-
cative function," I am at a loss to know what that meaning can be.
Beliefs about beliefs [P&WJ. If one wants to apply to chimpanzees a concept of
communication as rich as SR&B's, one must first ask what evidence there is that
chimpanzees can have beliefs about beliefs about anything (let alone beliefs
about beliefs about desires). It is good news that P&W are investigating this
question in a properly isolated way, getting belief-about-belief out of the under-
growth and into the open where it can be looked at squarely. Their work -
achieved and projected - is so interesting and potentially important that I would
do anything to be allowed to help it along. I here offer what I can: three criticisms,
a comment, and a suggestion.
First, a small point which illustrates a large one. The "empathy" interpretation
of the first experiment is said to "assume that the animal imputes a purpose to the
human actor [but] does not grant the animal any inferences about [the human's]
knowledge." That is wrong, I submit: Sarah's behaviour isn't relevant to what she
thinks the human wants or intends unless she thinks that he thinks (perceives,
cognizes) his situation to be thus and thus.
The large point is that when one is attributing mental states on the evidence of
behaviour, cognition and motivation must go hand in hand. An animal's actions
show what it thinks only on certain assumptions about what it wants, and they
show what it wants only on assumptions about what it thinks. This goes for our
attributions to the chimpanzee, and for hers to the human: if she is perfectly
agnostic about the human's cognition, how could she have any thought about
how his purposes would lead him to behave, or about what purposes his
behaviour would manifest? If she can have neither, then she can have no thought
about his purposes.
So I dissent from P&W's conjecture that "inferences about motivation will
precede those about knowledge." If the inferences are to be based upon
behaviour, it is impossible for there to be this separation (see Bennett, 1976,
Â§15). This is worth stressing, if it is true, as a warning against devising
experiments where one of the two factors is attended to while the other hovers in
the background, unrecognized and thus uncontrolled.
Secondly, some of the experiments are, as P&W recognize, disturbed by the
question, What is Sarah up to? Presumably she wants to succeed in her assigned
task, but that is an empty conjecture unless we know what she thinks the
assigned task is. Although P&W are properly cautious about this, the situation
may be worse than they recognize. If all goes according to plan, Sarah thinks, in
the first experiments, that she is to predict what the human actor will do, in the
558
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4

Commentary /Cognition and consciousness in nonhuman species
next lot she thinks she is to express what she prefers, and in the "embedded
videotape" experiments she thinks that she is to predict and that he is to express
what he prefers. I'm not optimistic.
Might it not be better to escape from experiments whose interpretation
depends on what the animal thinks its assigned task to be? My objection is not
that that concerns what she believes the trainer wants, and thus concerns her
pschological theory; for we can surely construe "what she thinks the assigned
task is" so that it doesn't automatically credit her with any psychological theory.
The objection is just that this feature introduces a not easily remedied uncertainty
about how the results - whatever they are - should be interpreted.
Thirdly, although P&W's current experiments on the attitudes of chimpanzees
to liars and fools have the merit of not involving the concept of an assigned task,
they do strike me - as clearly they strike P&W also - as being highly tenuous for
other reasons. I hope that more work will be done on the rockbottom matter of
belief about belief before much more effort is expended on these more complex
and recherche matters - in which I include the distinction between knowing and
guessing. I don't deny that these matters are amenable to experimental investiga-
tion; but I suggest that they are better left aside until the groundwork has been
more completely done.
Fourthly, as P&W imply in their closing remark, the price of avoiding mentalistic
concepts is an increase in the complexity of the conceptual structures needed to
handle the materials; and that is what justifies using mentalistic concepts. Now,
suppose we know that in the first experiments Sarah was predicting how the
human actor would behave, and let us ask: Why shouldn't she have reached this
prediction by purely behavioural computations, without going through interme-
diate stages concerning his states of mind? P&W answer this, it seems, by saying
that if her route to the prediction wasn't mentalistic, it must be describable in
"associationist" terms, and they object to this for reasons that I am not sure I
understand. Perhaps what they are saying comes down to what I contend to be
the best answer (if it is true), namely: For Sarah to get from data to prediction by a
route which didn't attribute beliefs to the human actor she would need an
extremely complex inference, whereas she could get there without undue
complexity if along the way she had hypotheses about the human's mental states.
That claim about relative complexity is needed to justify crediting Sarah with
beliefs about beliefs and not mere beliefs about behaviour.
Finally, whether the relative-complexity claim can truthfully be made in connec-
tion with those first experiments of P&W's is not clear to me, because I don't
know enough about what Sarah's premises were. Exact information about an
animal's data would be easier to get if the experiment had to do, not with "Does
she think that he knows that heaters have to be plugged in?" but rather with
"Does she think that he knows that this heater is not plugged in?" That is, there
would be better grounds for a belief-about-belief interpretation if the focus were
on her beliefs about what the human believes about this particular situation. For
then one could vary the evidence she had about his knowledge of individual
features of the situation - features which were relevant to whether or how the
problem could be solved. Let her see that the key is turned while he is not looking;
or that the box is sneaked away after being hidden from him by a screen; and so
on. This could provide strong evidence for beliefs-about-beliefs, by showing that
the chimpanzee must be making inferences which are dauntingly complex when
stated in purely behavioural terms but relatively simple when stated in terms of
mentalistic concepts.
How is she to manifest these predictive beliefs about the other party's
behaviour? I suggest the following. Let A be the agent about whose beliefs we
hope the subject chimpanzee will form beliefs. Give the chimpanzee abundant
evidence of A's sharing her value-system and being prepared to cooperate with
her towards common ends: this is to justify us in assuming that if she has any
psychological theory about A, its motivational part will credit A with roughly the
motivations that she herself has. Then construct coordination problems -
situations where the chimpanzee can see that what it is prudent for her to do
depends upon what A is in fact going to do (see Lewis, 1969, chap. 1). Her
predictions about A will then be manifested in behaviour which can be much more
confidently interpreted than could any amount of photograph-selection - namely,
in terms of her pursuit of her own natural down-to-earth goals. I don't mean that
interpretative problems may not still arise, but merely that they aren't likely to be
problems about what her motivations are, what she is "up to."
I cannot put experimental flesh on these bones; no doubt Herculean labours
are needed to turn such armchair proposals into a practicable programme. Still,
abstract proposals can have value, and I offer mine, hopefully, as pointing to a
possible kind of experiment which (1) keeps both belief about motivation and
belief about cognition clearly in view; (2) avoids the notion of "the assigned task";
(3) can be aimed at the most elemental kinds of belief about belief, leaving the
complex ones until later; and (4) makes it possible to know fairly exactly what the
animal's data are, and what her conclusion is, thus facilitating the comparison (in
respect of complexity) between the mentalistic and the nonmentalistic routes from
the one to the other.
The need for criteria [GJ. I share G's interest in developing a richly mentalistic
psychology and ethology; but his advocacy, persuasive as it is, would be stronger
still if he were more cautious in his deployment of mentalistic concepts. That
would involve two things.
1. More clarity and explicitness are needed regarding the criteria for applying
mentalistic concepts. G says a good deal about this in particular cases, for
example, in his good remarks about the possibility that honeybees might learn to
report on fibreglass; but his campaign needs a general statement as to what sorts
of behaviour support which mentalistic attributions. It would be controversial, and
would need defence; but the mere statement of it would give us a better idea of
what G wants us to accept.
That statement of criteria should govern the discussion. One feels the need of it
in, for instance, G's remarks about chimpanzee-communication experiments. He
seems to assume that some of those studies provide evidence of "communica-
tion of intentions" in some significant sense, unless all of them are vitiated by
"Clever Hans" errors. But there are hosts of ways in which those experiments
might, without being vitiated by cueing, have to be interpreted as something other
than communication of intentions.
The desired statement of behavioural criteria would direct more attention to the
internal geography of our system of mentalistic concepts. G tends to cut corners,
as in his handling of the case of the two planes, one guided by a kamikaze pilot
and the other by a heat-seeking device, where "communication . . . might well
convince us that a real, live, conscious pilot was flying one machine." So indeed it
might, but how and why? We are to be impressed by the pilot's responding
appropriately to our messages; and presumably the "simple dialogue" mustn't be
so stereotyped as to revive the suspicion that we are talking to a tape - for
example, it mustn't consist just in commands from us and "Yessirs" from the
pilot. So the dialogue is to provide evidence that we should get appropriate
replies to most things we might say; and the only thing capable of such a feat is a
human being - a mind-endowed, conscious, aware person. Now, I don't dispute
that a simple dialogue could convince me that the plane was piloted by a
conscious being. But two corners have been cut.
Firstly, the story is not essentially one about communication. It's true that we
are in doubt about the pilot until we discover that he can communicate with us; but
that is a large, cloudy truth which contains within it the leaner and more precise
truth that we are in doubt about the pilot until we discover that he can respond
appropriately to a large range of input. The input is provided by us, and could in
that sense be called "signalling," and thus "communication"; but that is a mere
accident of the example, and not part of what makes the dialogue evidence as to
the pilot's status.
Secondly, G's route from "The dialogue is succeeding" to "There is a
conscious being at the other end" is invalid, for a reason which has nothing to do
with whether "communication" is involved. The dialogue is evidence that the
plane's guide would respond appropriately to a vast number of distinct signals,
but that is not in itself evidence of consciousness. It points to consciousness only
with the help of the fact that in our region of space-time the only things which have
such a large store of responses are the higher animals, and they are all
conscious. What qualifies them as conscious, however, is not the size and
complexity of their stores so much as their flexibility, adaptability, educability. It is
true that in the animal kingdom complexity and flexibility tend to go together, with
humans having a uniquely high degree of each; and this is no mere coincidence.
Still, they are distinct properties of an organism, and they are not equally relevant
to consciousness or mentality. If there were a tremendously complex hard-wired
device which could handle the pilot's end of the "simple dialogue" but which was
perfectly ineducable, it would pass G's dialogue test yet wouldn't be conscious
[See Haugeland: "The Plausibility of Cognitivism" BBS 1(2) 1978]. I'm not saying
that G's test isn't good enough ("Maybe it's not a man answering us, but rather a
technologically innovative device . . ."); I'm saying that he doesn't make suffi-
ciently clear why it is good enough.
2. When the criteria are actually formulated, they should not be too generous,
that is, they should not make it too easy to establish that a given animal is
conscious. This is not because consciousness should not be spread too widely: I
hold no brief for the view that we must keep the other animals at a respectful
distance from ourselves. Rather, the reason is that the more lax the criteria for
something's being X are, the less content there is in the statement "This animal is
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4
559

Commentary/Cognition and consciousness in nonhuman species
X," and so the less interesting such statements are. Sometimes G tends to push
towards making such statements true at the price of making them uninteresting.
For example, in one place he asks plaintively "what else bees might be expected
to do that would provide stronger evidence of intention to communicate, given the
circumstances under which their behavior has been studied so far." This
mislocates the onus of proof. Until we have good evidence that honeybees intend
to communicate, we should not say or think they do; otherwise our uses of such
expressions as "intend to communicate" become empty and boring. (My own
guess is that the evidence will never be forthcoming; and I wish G hadn't permitted
himself the jibe "Is it because bees are small?," ignoring a reason which surely
deserves a respectful hearing - namely that the neural organization of bees may
be too simple to permit that adaptability and flexibility which many of us regard as
criterial for mentality. But that's by the way.)
G's remark about bees' intention to communicate, having served to illustrate
my main point about severity of criteria, also illustrates my general theme. See
what precedes it:
"Smith [says] that honeybee dances communicate information 'about
characteristics of the next flight the dancing communicator will make' rather than
about the location of something desirable. But the distinction between predicting
one's future behavior and expressing an intention is a rather subtle one that is
certainly difficult to analyze in another species. It is therefore appropriate to ask
what else bees might be expected to do that would provide stronger evidence of
intention to communicate. ..."
This contains two conflations. Firstly, it conflates (i) the difference between
flight-prediction and report-on-/bod with (ii) the difference between flight-
prediction and report-on-flight-intention. It will be hard to get any purchase on (i)
in the apian context, and G is right that (ii) is elusive in any context; but he writes
as though they were the same distinction, when in fact they are as different as
chalk from cheese. I can only suppose that this conflation results from a kind of
conceptual hurry that appears to be present throughout the article.
Another sign of hurry occurs in the next transition in the quoted passage.
There, G glides from "expressing an intention" to "intention to communicate," as
though he didn't distinguish "X communicates that it intends to fly" from "X
intends to communicate that it will fly." But these two are also quite different: the
question of what is communicated, for example, whether it is a message about
intentions, is independent of whether the communication is intentional.
Just because I find G's campaign so sympathetic, and so many of his details
interesting and persuasive, I would like to urge upon him the importance of
circumspection-of a patient, careful, continuous attention to conceptual founda-
tions.
REFERENCES
Bennett, J. Linguistic behaviour. Cambridge: Cambridge Univ. Press, 1976.
Lewis, D. Convention: A philosophical study. Cambridge, Mass.: Harvard
Univ. Press, 1969.
by irwin S= Bernstein
Yerkes Regional Primate Research Center, Emory University, Atlanta, Ga. 30322;
and Department of Psychology, University of Georgia, Athens, Ga. 30602
Awareness, intention, expectancy, and plausibility. Animal cognition [GJ. G
takes the position that behaviorists are unnecessarily impoverishing their scientific
world by refusing even to consider animal cognitive states. The arguments posed
and the counters to be expected will remind psychologists of the battles between
Gestalt psychologists arguing for insight versus trial-and-error-leaming theorists,
and the arguments concerning latent learning versus reinforcement theory.
Although we can all agree as to what response was performed by a subject,
accounting for why that particular response occurred at that particular time
requires some theoretical commitment. In one case, we examine the history of
reinforcement for the subject prior to the time that a response occurs. In the other
case, we assume that the present motivational state draws on past experience to
produce an expectancy of the outcomes of available alternative responses. In
actual practice the only difference in the two approaches is the inference of a
mental state in the second view.
Why does one chimpanzee making the "correct" choice in a discrimination
task quietly accept the carrot slice reward while a second, previously rewarded
with banana slices, rejects the reward and shows behavior often described as
temper tantrums or frustration? Can we ever reduce such a question to the realm
of scientific investigation?
Communication and intention [P&WJ. P&W answer with a resounding yes. In
considering the sequence of responses exchanged between individuals, one can
think that the behavior of the recipient is modified by the sender and that the new
behavior of the former recipient is now received by the original sender and
modifies its behavior in turn. In such a model, each new response is determined
by the previous one. If the original sender, on the other hand, modifies its signal in
such a way as to guide the receiver toward a particular form or behavior, or better
still toward a class of responses any of which will produce a particular outcome,
then the communication may be regarded as goal-directed.
The questions raised by P&W are even more sophisticated than the simple
case given above. They outline a series of studies, some completed, some yet to
be run, all of which may produce results which could reasonably be interpreted as
demonstrating that chimpanzee subjects are capable of identifying (correctly or
incorrectly) the motivational state of another. Much as we might respond very
differently to a blow received if we regarded it as deliberate, accidental, or playful,
the differential response of an animal to the same response in others, dependent
upon a greater context, suggests an awareness of motivation in the other, or a
"theory of mind."
Plausibility [SR&BJ, The difficulty in obtaining "proof" for either G or P&W is
exemplified by the contribution of SR&B. They begin by examining other studies of
linguistic ability in chimpanzees, recognize the criticisms of such studies, and
indicate what the appropriate controls should have been. They then present their
most recent studies to show that their new work does control for many of the
alternate explanations that have in the past been proffered by scientists who find
linguistic ability in nonhuman subjects antithetical to their view of the world. SR&B
suggest that subtle "Kluge Hans" phenomena, chance events, observer bias,
and complex chain conditioning, in some combination, can account for the
performances of Washoe, Sarah, and similar subjects. Proper controls and
systematic data collection plus refinements of experimental design can indeed
discount these alternative hypotheses for existing data relevant to language
acquisition in the chimpanzee.
One can, nevertheless, suggest a complex sequence of learned responses
involving matching and contingencies to account for the performances of Austin
and Sherman. In fact, the learning sequences described, the error scores, and the
dependency on particular interactants might make more plausible such an
extraordinarily complex learning chain. We would then shift our attention to the
remarkable instances of food sharing, cooperation, and possible imitation
learning involved in following the experimenter model.
Indeed, the search for controls will be endless. When one asks what variables
need to be controlled in designing an experiment, we usually assume a consen-
sus with regard to what alternative explanations are as plausible as our original
hypothesis in accounting for the anticipated results. The question of plausibility is,
however, a personal decision. Should I find it unacceptable that chimpanzees
should differ from humans only quantitatively, then I will insist either that there is
yet one more quality of language that chimpanzees have not been demonstrated
to be capable of, or that there is yet another explanation for your data, which you
may think so farfetched as to be absurd, but which I think more reasonable than
the absurd conclusion that an animal might achieve language.
Although the arguments go on, and are likely to continue for some time to
come, maybe it is time to forget the labeling and assess what we do know about
the cognitive life of animals, decide how we can meaningfully test our concepts of
cognition, and consider the significance of the data we already possess. Now,
suppose an individual did anticipate the behavior of another in terms of the
presumed intentions of that individual. . . . Where do we go from here?
by Tyler Burge*
Department of Philosophy, University of California, Los Angeles, Calif. 90024
Concept of mind in primates? The need for a psychological theory [P&W,
SR&BJ. The experiments involving communication with and among chimps have
provided an interesting alternative to child language learning as a means of
studying the developmental foundations of intentional concepts. It is too early to
tell how much may be gleaned from this area, partly because no clear limit on
what chimps can learn has yet been established, and partly because there is no
generally agreed upon theory about what they have learned. But the experiments
already performed promise a variety of interesting applications.
I am not inclined to rest much weight on the question of whether the chimps
really speak a language or really have a theory of mind, at least in our present
state of knowledge about them. There are as yet no agreed upon criteria or
Â°Received too late for a Response from P&W or SR&B. See Continuing
Commentary. [Ed.]
560
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4

Commentary/Cognition and consciousness in nonhuman species
pieces of evidence which justify applying these notions beyond the paradigmatic
cases of human language users. And there are striking differences between the
chimps and these paradigmatic cases, in addition to the tantalizing similarities.
The issue of whether the chimps employ language or intentional concepts
depends on whether our systems of description and explanation which attribute
these notions are optimal for theorizing about the chimps' capacities. And here
we run up against the fact that psychological theories have hardly gotten off the
ground. English-speaking psychology has just begun to emerge from decades of
behaviorist domination, which had the effect of stifling theory. In this situation it is
natural and perhaps fruitful to try out the conceptual apparatus of commonsense
psychology and commonsense linguistic interpretation. Whether systems of
descriptions and explanation more appropriate to nonhuman primates are in the
offing is, as far as I am concerned, a wide open question. There is some point,
however, in emphasizing differences between human language-use and what has
so far been shown about the capacities of the chimps, particularly since
researchers in the field tend to be more interested in the similarities.
Linguists have frequently pointed out that the "languages" that the chimps
have mastered are not generative. The animals give no evidence of the capacity
for producing an infinity of semantically distinct grammatical constructions. This
difference is related to another. Any given chimp has learned to use his symbols in
what may be easily described as a relatively small number of linguistic and
environmental contexts. It would be glib to dismiss this difference as a matter of
"degree" rather than "kind." For what is at issue is whether fundamentally
simpler explanatory systems than those ordinarily applied to humans will suffice to
explain the capacities of chimps. (One of the sources of the failure of behavioris-
tic schemes was the sheer complexity of human language use and cognitive
capacity.) Explanatory systems that use less than the full conceptual arsenal of
commonsense psychology and semantic description are certainly promising as
means of accounting for the chimp's capacities.
Savage-Rumbaugh et. al. 's experiment, to take a case in point, has the chimp
associate a given symbol for a tool with three contexts: matching symbol and tool
(given certain promptings), fetching a tool subsequent to "hearing" the symbol,
and expecting to get the tool subsequent to uttering the symbol. Even if these
contexts were increased five hundred-fold, the chimp's capacity would not begin
to approach that of Man. There is no finite listing of the possible linguistic and
environmental contexts in which human words may be employed. I have, of
course, described one of the three contexts mentalistically. And I am far from sure
that mentalistic attribution can be reasonably avoided. But the relatively narrow
capacities of chimps in their use of symbols, even granted various instances of
transfer, suggest that relatively simple explanatory systems deserve exploration. I
think we should be particularly cautious about applying the rich systems of
semantic notions that we ascribe to human language-users.
One aspect of this complexity of human linguistic skill bears emphasizing.
SR&B note at the outset of their paper the characteristic that allows language to
transmit "specific information in an abstract, context-free form." There is an
important sense in which none of the chimp's uses of symbols are context free.
All symbol uses in the experiments can be matched with perceptually relevant
contexts in the animal's present, recent past, or immediate future. All symbol uses
are close approximations to what Quine has called "occasion sentences" (Quine,
1960 op. cit. by Churchland & Churchland). Their truth conditions are relatively
easily inferred from the animal's perceptions in the context of the symbol's
utterance. Even such generalizations as have been taught to chimps in other
experiments are easily decomposable into finite conjunctions or disjunctions of
such occasion sentences. Schemes for explaining symbol use which avoid appeal
to irreducibly semantic notions are far more plausible as applied to uses of such
sentences than as applied to sentences without such immediate perceptual
relevance.
SR&B put the matter in the right light when they suggest caution about
comparing the chimp's symbol acquisition with that of a child and when they
emphasize the significance of role-reversal and cooperative communicative
behavior that their experiments have elicited. It is not so much the chimp's use of
symbols or his ability to learn the relevant tasks that is impressive. Ability to learn
the skills so far demonstrated should come as no great surprise in the light of
Kohler's early discoveries, and known cases of signalling in the wild. The skills
described so far are not very complex. In my view, the chief interest of the SR&B
experiments lies rather in their suggestions regarding the role of social coopera-
tion in the origins of language. Under what conditions do the chimps invent iconic
signs to replace the ones they have been taught? Under what conditions are they
led to invent signs for new objects or actions? What kinds of social goals
stimulate the relevant cooperation? What sorts of comparisons can be drawn
between the laboratory cases of cooperative behavior and known cases of social
sharing among chimps in the wild (for example, in occasional ventures into
meat-eating)? Can nonhuman primates not known to share food, such as
baboons, be induced to cooperate as the SR&B chimps have done? These
questions and a host of others invite exploration.
Premack and Woodruff's paper is inventive and stimulating, but, to my mind,
unconvincing. Part of the problem stems from my general skepticism, articulated
earlier, about the state of psychological theory. But I am also doubtful about
particular arguments in the paper. For the sake of discussion, I shall grant (what I
find plausible in any case) that in some sense, so far poorly delimited, chimps
have mental states. What I shall question is whether the experiments described
provide much reason to think that they have a theory, or even a concept, of
mental states. The basic tests (whether or not they involve physical inaccessibili-
ty) can apparently be explained without imputing such a theory to the chimp.
Assuming that Sarah understands the problem of the actor's getting the bananas
and the solution (say, knocking them down with a rod), she chooses the
photograph that represents what she would like to happen. Sarah's motivation for
wanting the problem solved may take any number of forms. She may like the
actor, or simply want such problems solved, other things being equal. In the case
of the actor she does not like, the experimental results can be explained in terms
of her understanding the actor's plight and wishing negative outcomes upon him.
Do these accounts of the matter entail attributing to Sarah a belief that the
actors have the mental state of wanting the bananas? I do not see that they do. It
is enough for her to recognize a problem for a person and want (or not want) it to
be solved on his behalf. Compare my seeing a beetle stymied by an obstacle in its
path. I need not attribute mental states to the beetle in order to understand its
problem, and want (or not want) it solved. Similarly, the chimp need not attribute
mental states, or even know what it is to have a mental state, in order to act as
she does in understanding the actor's problems. Perhaps Sarah does have to
have some sense (instinctive or learned) of what is good for, or bad for, a
person - what improves his well-being and what inhibits his normal activity. She
has to make intelligent inferences in these matters. But attributing these notions to
her does not entail attributing to her a theory of mind.
The embedded videotape is also unconvincing, for various reasons, of which I
will mention one. The experiments as decribed do not rule out the possibility that
Sarah is basing her choices purely on her attitude toward the participant. Perhaps
she simply chooses the photo that provides the solution. The information as to
whether the observer likes the participant might be interpreted by Sarah simply as
evidence as to whether she should like the participant. The role of the observer,
as intermediary between Sarah and participant, would be essentially vacuous.
Obviously, the experiment could be complicated to test this interpretation. (Sarah
could like the participant antecedently and be given evidence that the observer
does not like her and vice-versa.) But until the experiment is refined, it is doubtful
whether it shows anything that the unembedded experiments do not already
show.
The experimental tests for "lying" seem inconclusive in the same way that the
basic, unembedded tests do. The chimp may be seen as being angry toward the
selfish trainer because he frustrates her expectations. It is a simple matter for the
animal to determine which of several people, in a given context, is in a position to
give her the bait - or is likely to give it to her, relative to her past experience.
Lower animals commonly make such discriminations. These discriminations
together with frustrated expectations (and an aggressive rather than docile
temperament), appear sufficient to account for the difference between the way
she treats the guesser and the liar. Again, one can reasonably impute mental
states to the chimp without attributing a theory, or a set of concepts, about mental
states.
P&W's remarks at the end of their paper provide a vastly over-schematized
choice to someone (in particular, the chimp) trying to understand the actor's
activity. The alternative as posed is between a non-inferential viewpoint which
contents itself with disconnected descriptions of behavior, and a theory of mental
states. The former alternative would be unacceptable even to most of those who
have traditionally been counted behaviorists. Behaviorists rarely content them-
selves with disconnected descriptions of behavior. They have typically inferred
unobservable dispositions and have postulated simple theoretical (non-observ-
able) mechanisms (e.g. association) to explain the observable evidence. More-
over, there is a range of functional concepts that are neither behavioristic nor
mentalistic that may be invoked to account for certain sorts of activity of animals
or machines.
None of the foregoing is to suggest that we know a priori that chimps do not
have a theory of mind or a concept of the mental. But to be persuasive in claiming
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4
561

Commentary/Cognition and consciousness in nonhuman species
that they do, it is not sufficient to argue that they make relatively simple causal or
functional inferences about the behavior and capacities of human beings.
by Gordon 1 . Burghardt*
Department of Psychology, University of Tennessee, Knoxville, Tenn 37916
Closing the circle: The ethology of mind. I only seem able to deal with these
three papers in a historical context. I think that behind all the discussion of
experimental design, controls, heuristic value, linguistic clarity, operational defini-
tions, uncited papers, and philosophical implications that these papers will surely
provoke, there will be many strugglings like mine. If my comments seem off the
point, that is the point; for you, after all, are not me.
We have scotch'd the snake, notkill'dit. Prior to Darwin we could allow animals
their instincts and humans their minds. But Darwin argued that some of the animal
was still in the human, structurally and behaviorally, and that these were inherited
traits. And then he argued that some of what was thought most human was found
in the animal, meaning that precursors to almost every human mental and
emotional characteristic could be found in the nonhuman. This double-pronged
attack, finding the Animal in Man and Man in the Animal was most ingenious. But
the world wasn't quite ready for it. Scientists were still trying to come to grips with
physical evolution, and Darwin's necessary reliance on limited and questionable
evidence made going back to his work, when the air had cleared a few decades
later, too difficult.
An experimental attitude and laboratory approach was on the rise, marked by
figures such as Lloyd Morgan, Thorndike, Small, and soon Yerkes, Watson, and
Pavlov. Darwin's interest in the mental life of animals became transmuted into the
apparently more tractable problems of measuring intelligence in animals, itself
soon demoted to learning. The study of instinctive behavior waned and largely
disappeared. Those experimental psychologists who studied humans relied
almost solely on introspective reports or verbal reflections on affect, cognition, or
memory. Psychology to them was the study of consciousness and not behavior
(Angell, 1911). Just consider the situation prior to World War I: The natural
behavior of animals was being ignored, along with questions of genetically based
behavior and predispositions. The concept of instinct was being flagrantly
misused with people. Experimental human psychology was becoming increasingly
mired in apparently unsolvable and erudite controversies between functionalists
and structuralists. Workers with animals, however, were having great success in
training animals, developing powerful theoretical and empirical methods relying on
observable behavior and what we now call classical and instrumental condition-
ing. The colonels of the behaviorists' revolution, led by J.B. Watson, soon took
over, although it must be admitted that there were always some rebel guerillas
making quick forays from inaccessible cloud-covered mountains.
The first of the two main consequences of the behaviorist takeover was the
emphasis on overt behavior. They argued that a focus on "mind" and
"consciousness" was unproductive in the study not only of animals, but of
humans as well. Such things may or may not exist, but they obviously cannot be
studied. Thus scientific psychology lost its mind. Second, they argued that human
and animal evidence on instinct was minimal and its use as an explanatory
concept ludicrous. And had they not shown how important learning and the
environment were to animal behavior? Thus, both instinct and mind were removed
from human and animal alike, leaving a variety of mechanistic stimulus-response
processes to fill the slack. Obviously this situation could not last; what amazes me
is that it held on so long and so firmly. This perhaps indicates that there is much of
value in behaviorism, which should not be discarded.
But back to the two evils, instinct and mind, that the behaviorists thought they
had eliminated from scientific discourse. In reality they had only wounded the
snake and driven it deep into its den. And it was a two-headed snake they tried to
eliminate. (The left head being Instinct, the right head being Mind; thus, our lab's
two-headed black rat snake is named Im). Later most ethologists were willing to
grant the behaviorists their due in the emphasis on behavior; they only protested
their ignoring of evolution [see Eibl-Eibesfeldt: "Human Ethology" BBS 2 (1),
1979]. But I'm starting to believe that the behaviorists knew what they were doing
in tying the two together.
In any event, a reaction against the elimination of instinctive behavior from
animal psychology arose by the late 1930s, and today the existence of important
innate or genetic aspects of behavior is accepted in all nonhumans. Thus
instinctive behavior was put back in the animal. It was inevitable that humans
would soon be studied for similar phenomena and evidence, which did in fact
happen as ethologists (reviews in Burghardt, 1973; Eibl-Eibesfeldt, 1975) and
then sociobiologists (Wilson, 1975) applied their methods and concepts to
people. The innate is now back in the human.
And mind made a comeback too during the 1950s. People studying humans
were feeling overly restricted by behaviorism of whatever variety. New views of
language, cognition, and information processing were on the rise and behavior-
ism, weakened, could not hold off this front either. Thus by the mid-1960s mind
was back in the human. The only missing link now was putting mind back into the
animal. The Gestalt psychologists tried to do this in the twenties and thirties as did
Bierens de Haan, Buytendijk, Von Uexkull, and others, although they were
effectively silenced. But even at that time some honeybees in Austria were
dancing up a storm, and that brought new clouds for behaviorists and ethologists
alike. Von Frisch's work was widely known in America during the 1950s, but as
long as something as anomalous as a symbolic language was restricted to a lowly
invertebrate it could be repressed in a variety of ways.
But then came the gesturing, tool-making chimps and the language training by
Premack and Rumbaugh. Field-oriented primatologists began looking toward
sociology and anthropology for methods and concepts, and it became increas-
ingly difficult to ignore the subjective baggage that went along with them. For
instance, in discussing the role concept, an eminent and unrelentingly behavioris-
tic ethologist had to deal with the idea that "shared expectations" are involved in
the sociological use of the term.
"Does this imply that conscious awareness is a necessary part of the use of the
role concept? If so, one could argue that the term role cannot usefully be applied
to animals simply because the evidence we can obtain about their conscious
intentions is so much less secure than that available in the human case." (Hinde,
1974:387)
The fact that Hinde even had to raise the issue was astounding. And then Griffin's
book (1976 op. cit. SR&B) formally and seriously addressed the issue and
completed the circle. We are now in the second revolution that ethology seems to
be provoking, although many ethologists and animal psychologists are them-
selves unconvinced. Two-headed snakes are often referred to as monsters, but
can one head live alone?
Communication as a window [GJ. Now the above is public history, however
debatable and jaundiced by selectivity and judgment. Personally, I have always
delighted in the idea that animals have complex mental processes, though I have
found that it was circumspect both as student and teacher to be restrained in
advocating mentalistic terminology. Possibly the fact that my empathy extended
especially to snakes and lizards rather than apes had something to do with it. G's
account of the resistance to "awareness" as applied to bees extends the
apparent absurdity even further, and I am pleased that G did not retreat from
bees by pleading one of the myriad available excuses for concentrating on
primates or even just apes. Thus G does not subscribe to the gratuitous
assumption explicity held by P&W, who twice on the same page assert that
animals other than humans and chimps are "lesser species." And G addresses
the difficulties on the conceptual, methodological, and empirical level. He has, in
fact, performed an admirable service by updating his earlier reassessment of
cognitive processes in animals.
But it is also important to ask what is new and what is old about cognitive
ethology, as questions of animal mental life and consciousness were addressed
early in the post-Darwinian era. G is aware of this but chose to concentrate on the
current scene. Holmes (1911) stated the dilemma we are struggling with now
(p. 3):
"Concerning the conscious life of animals distinguished from the objective facts
of behavior - our knowledge rests upon an insecure foundation. We have no
means of cognizing directly the conscious states of any creature besides
ourselves and what we know of the psychology of our fellow human beings is
based upon what we find taking place in our own minds. We infer consciousness
in other beings because we are conscious ourselves, and we judge of the mental
states in the minds of others, such as joy, sorrow, anger, or fear, from certain
physiological manifestations which are like the accompanying manifestation of
these mental states in ourselves. With beings much like ourselves our inferences
may be fairly accurate. When thrown amid people of other nations or races our
judgments are most apt to be erroneous. And when we try to infer what goes on
in the mind of a cat or dog the difficulties are very greatly increased."
But however sensible in theory, the continuum position does not sit well with
most of us who favor a greater human-nonhuman split. Washbum (1908:3) nicely
made the next step: "To this fundamental difficulty of the dissimilarity between
animal minds and ours is added, of course, the obstacle that animals have no
language in which to describe their experience to us."
Thus as I have perused this early literature I have discovered that not only was
communication between animals largely ignored in discussion of mental abilities, it
was nonexistent as a separate topic of study. Symbolic language in animals was
562
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4

Commentary/Cognition and consciousness in nonhuman species
considered an impossibility, and what communication did exist, instinctive. Thus G
and others in the new cognitive ethology are really opening up something new in
using communication as the window in the wall that other methods could not
penetrate.
Washbum understood the procedural problems in the endeavor all three of the
present papers are attempting (1908:4):
"Knowledge regarding the animal mind, like knowledge of human minds other
than our own, must come by way of inference from behavior. Two fundamental
questions then confront the comparative psychologist. First, by what method
shall he find out how an animal behaves? Second, how shall he interpret the
conscious aspect of that behavior?"
Language among chimps [SR&B]. The efforts by SR&B to study communication
are truly seminal in terms of being ingenious, methodologically tight, and showing
strong results, although the amount of chimp-chimp versus chimp-computer
communication is somewhat unclear. The suggested link between language and
tool use is attractive, but given the lack both of a comprehensive survey of tool
use in the animal kingdom (now being rectified by Benjamin Beck) and of an
accepted characterization of nonhuman language, too much should not be made
of it at this stage. Although nonprimates are ignored by SR&B, the scholarship
evidenced in the paper is truly impressive and valuable, contrasting with the
following piece by P&W.
While the majority of SR&B is devoted to a report of their innovative
experiments, a goodly portion is a critique of earlier work, particularly the ASL
approach of the Gardners and the plastic-chip work with Sarah by Premack. Most
of the criticisms are convincing and useful to have together, but one wonders why
they did not allude to their own earlier Lana work. If it was exempt from the
criticisms leveled at the Washoe and Sarah projects, this should have been made
clear, as Lana is also part of the history of this area. And, if not, critical
assessment here would have been fair.
Do Premack and Woodruff have a theory ofmind[P&W]?'In contrast, the article
by P&W is frustrating: some good ideas and brilliant work obscured by rhetoric
and argument. The experiments as reported here and elsewhere are exciting, but
most of the present paper reads like a verbally shrouded grant proposal. Some
pilot data are alluded to, but lots of hypothetical to-be-done experiments are also
outlined, complete with exhaustive if-then discussion and interpretation. Plausible
argument and anecdote do not provide adequate control. For example, the TV
experiments need to be done without any actor.
There are other problems as well: Throughout the later sections it is often
unclear what has actually been done and what is proposed; the discussion of
results is vague, with data reported as consistent or invariable with no indication
of how many trials were run (2, 20, 200?). And why does a person a chimp does
not like have to be given a fictitious name whereas a more favored person can be
mentioned? There is too little awareness that many people have looked at these
issues: Only one reference before 1973, and this to Kohler. I would suggest
everyone read chapter 12 in Hobhouse (1901) on "the concept" and then reread
both SR&B and P&W.
And finally, it can be answered that P&W, but not the chimps, have a theory of
mind. Their preoccupation with proving it has led to experiments gauged to
support the "theory," although this inadequacy tends to be obscured by the
rhetoric in which the reports are embedded. The theory maybe of value; a clearer
presentation would have given the reader more understanding and faith.
The attempt and not the deed confounds us. But the question arises: How
effective and necessary is the new cognitive approach? Certainly both heads of
the snake were attacked by the early behaviorists with the fervor (and ignoring of
evidence) we see raised today in the more socially relevant areas of sex and race
differences. For to be on guard against misuse is one thing, to deny "mental"
processes in animals is another, and as G notes at the end of his paper, there are
indeed some moral and ethical issues raised by giving animals back their minds.
Should we do this if there is still disagreement on whether discussion in these
terms aids analysis (the initial behaviorist point)? Definitely.
In my classes in psychology and ethology I find it necessary to raise the issues
of teleology and anthropomorphism early. Somehow, in spite of the profound
moral, religious, and evolutionary issues raised, most students are willing to talk
about animal behavior in subjective and mentalistic terms and cannot see the
logical problems and the "as if" distinction. Why is this? Is it just a remnant of
childlike identification with cute animals with anthropomorphic features? Morgan
(1903:51) was of a different mind: "There can be no question that the interpreta-
tion of the actions of animals as the outcome of mental processes essentially
similar to those of man amply suffices for practical needs." In other words, "it
works." But just as all of us can get around in the world on a fairly primitive
understanding of physics, yet nonetheless take physics and mechanics in school
to prepare us for going beyond rough working hypotheses, so more rigorous
approaches are needed in psychological science too.
The fact that many competent scientists did not believe von Frisch's findings on
bees, not on methodological grounds but because of blinders, is unfortunate. But
we should be cautious in using such instances of earlier narrowness as grounds
for accepting empirical findings calling for a revival of specific mentalistic
concepts. Many human ethologists might see the irony of bringing cognitive
processes into the analysis of nonhuman behavior at the same time they are
trying to get the analysis of human behavior onto a more objective plane. SR&B
and P&W beautifully show the complex behavioral interaction and language
abilities of chimps, but SR&B discuss their results in largely behavioral (but not
old-line behavioristic) terms while P&W bring in mentalistic slush that undercuts
worthwhile data and ideas. And this is the danger. Even competent psychologists
can be seduced into fuzziness when the focus is removed from behavior.
Yet I think we need to work toward a cognitive ethology, which at this time I
would like to see characterized as an open-minded concern with the subtleties
and complexities of animal behavior. G is not giving us answers but raising
questions and emphasizing the need for rigorous experimentation and logical
thinking. SR&B and P&W are trying for answers, and perhaps at this time it is most
generous not to stifle diversity of approach. I do think that the phenomenological
approach as a way out of Cartesian thinking should be considered. Thines (1977)
has written a useful book that apparently hasn't yet elicited a reaction from
American students of animal cognition.
ACKNOWLEDGMENT
The comments of W. S. Verplanck on an early draft were most helpful.
REFERENCES
Angell, J. R. Psychology. Encyclopaedia Brittanica. 11th ed., 1911.
Burghardt, G. M. Instinct and innate behavior: toward an ethological psychol-
ogy. In: J. A. Nevin (ed.), The study of behavior Glenview, 111.: Scott,
Foresman, 1973.
Eibl-Eibesfeldt, I. Ethology, the biology of behavior. 2nd ed. New York: Holt,
Rinehart, and Winston, 1975.
Hinde, R. A. Biological bases of human social behaviour. New York: McGraw-
Hill, 1974.
Hobhouse, L. T. Mind in evolution. London: Macmillan, 1901.
Holmes, S. J. The evolution of animal intelligence. New York: Holt, 1911.
Morgan, C. L. An introduction to comparative psychology. 2nd ed., London:
Walter Scott, 1903.
Thines, G. Phenomenology and the science of behaviour. London: Allen
and Unwin, 1977.
Washburn, M. F. The animal mind. New York: Macmillan, 1908.
Wilson, E. O. Sociobiology: the new synthesis. Cambridge, Mass.: Harvard
University Press, 1975.
EDITORIAL NOTE
"Received too late for a Response from G, P&W, and SR&B. See Continuing
Commentary. [Ed.]
by Douglas K. Candland
Program in Animal Behavior, Bucknell University, Lewisburg, Pa. 17837
How the animals lost their minds. Since the invention of radical behaviorism
(and, later, logical positivism) wags have cried that we have a psychology that
lost its mind. Less tiresome critics have whispered that ethology never found its
brain. This issue of The Behavioral and Brain Sciences shows that the mind is
alive, healthy, and again the permissible object of fascination, by those who wish
to know what, if anything, animals think.
I wish to show that study of the animal mind, whether of awareness, conscious-
ness, probability learning, or whatever designation human beings may contrive,
was not sent packing by behaviorism; that the task of uncovering what animals
think depends upon the strategies of materialism, mysticism, and perhaps
phenomenology; that these strategies of studying animal thinking assume and
thereby discover different properties of the mind; that the study of language as a
representation of the mind is inappropriate; and that animal awareness,
consciousness, or cognition is most effectively seen as a sensory filter, rather
than as an independent entity.
Fundamentally, we can identify three theories of mind: materialism, which
defines mind in terms of the things that it can classify; mysticism (in the Greek,
and still best sense of the word), which defines awareness as comprehension
transcending but classifying things; and, possibly, the developments since Kant
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4
563

Commentary /Cognition and consciousness in nonhuman species
that have attempted to solve the lovers' quarrel between mysticism and material-
ism by attempting to describe consciousness itself. In this commentary, I draw no
important distinction between awareness and consciousness, as some do, only
because the proposed differences are unimportant to the question of whether
either can be described as characteristic of animal life. (But see Natsoulas, 1978,
on the kinds of consciousness.)
The radical behaviorism of the 1920s developed for many reasons, among
these being the fact that the study of psychology had begun to fail to make the
essential distinction between hypothetical constructs and intervening variables.
The mind, awareness, consciousness, and cognition have the properties of
hypothetical constructs, not intervening variables. The latter "abstract the empiri-
cal relationships," but hypothetical constructs "involve the supposition of entities
or processes not among the observed" (Tolman, 1932; amended by MacCor-
quodale and Meehl, 1948). Among the reasons for the denunciation by radical
behaviorism of nineteenth-century faculty psychology, a psychology that focused
on the presumed trinity of faculties of the mind (emotion, reason, and the will
[motivation)), was that students of the mind had begun to confuse mind as an
intervening variable with mind as an hypothetical construct. Mind, then, assumed
a reality separate from its logical properties and degrees of empirical verification.
Behaviorism stripped study of the mind from this methodological error but, by so
doing, made it unfashionable to ask questions regarding the mind, conscious-
ness, awareness, and like concepts.
Both G, and P&W argue for a revised code to govern the study of the animal
mind. G prefers to concentrate on the possibility of animal awareness by adopting
a reasoned materialistic view of the rules of scientific inquiry that provides
appropriate warnings - and they are needed - regarding the sensibleness of
considering animals as sensing and aware models.
I think it not true that behaviorism, or those who so describe their activities, has
routinely dismissed mentalism as G contends. Certainly the work of the gestalt
school (Kohler, 1927 op. cit. SREB), Tolman's still influential Purposive behavior in
animals and men (1932), Mowrer's analysis of learning and symbols in animals
(1960), Thorpe's analysis of purposive behavior in animals (1956, 1962), and
contemporary work on information processing and signal detection, have kept
sturdy the study of mental events. It was Tolman who first drew convincingly the
distinction between intervening variables and hypothetical constructs and who
clarified the distinction between learning and performance, a distinction that is of
relevance to the work of P&W and SR&B as well as to G's analysis of how one
studies awareness. Boden's excellent work on purposive explanations in psychol-
ogy clarifies Tolman's influences splendidly (Boden, 1972, pp. 80-98). Smith
(1971) is well aware of the mentalistic view of animal behavior in his helpful book
Purpose in animal behavior, especially pp. 27-33. However compelling G's
warnings may be, it would be unfortunate and (one must believe) contrary to his
wishes if the warnings prevent the development of a biology of the mind. One
cannot quarrel with the strict materialistic view presented by him, for the brief
history of attempts at mentalistic explanations provides clear warnings of the
dangers of straying thoughtlessly from the path so clearly plodded by those of the
"nothing but" materialistic persuasions. Still, occasionally excursions from the
true path are rewarding if hazardous, as P&W and SR&B demonstrate.
Apes and philosophers [P&W]. Reversing the occasional trend, P&W have
made philosophers out of monkeys - or apes, to be precise. Of greatest
importance for the rejuvenation of the study of mentalism in animals is their view
that an umweg is to explore the possibility that animals reason from the general
category to the particular event. This contradicts the unfortunate view that has
controlled study of animal life for many years, that animals build from experiences
of the particular. The evidence collected by P&W supports the view that the
chimpanzee mind contains something akin to Kantian categories of judgment. If
true, research focus shifts to uncovering the categories and how they are
modified by experience. I cannot imagine a potentially more fruitful approach for
the study of the mental states of animals, a view supported by the success of their
work.
It would appear that this approach is bound to set off rounds of studies,
creating the danger that in the hands and minds of the philosophically uninitiated
the distinction between hypothetical construct and intervening variable may, once
again, be confused. To my mind, the logical experimental steps must now make
use of the knowledge we have gained from the description of mind by Fechner
(1860) and Stevens (1957). Fechner's psychophysics, a system he predicted
could not be destroyed because there could be no agreement on how to do so,
represents the strict nineteenth-century materialistic view offered by G. Stevens,
by showing the plausibility of direct scaling of mental experiences, permits one to
uncover and scale mathematically the categories of the mind. The obvious
success of these techniques with human beings - coupled with P&W's tentative
but compelling success with chimpanzees - suggests how one may locate the
nature of the categories without succumbing to the intervening variable/hypo-
thetical construct confusion still so prevalent in theories of animal behavior.
Among the achievements of P&W's contribution is the reintroduction of the
faculty of motivation as a meaningful research subject with animals. In the
behavioristic rebellion against animal mentalism, motivation (and emotion) were
the constructs most damaged by neglect. It is not surprising that one of the
recognized and attractive contributions of modern phenomenology and the study
of consciousness (albeit in human beings) is the recognition of the investigability
of motivation (Moss and Keen, 1978). If chimpanzees can be "liars" or "fools,"
altruistic or spiteful, to human beings, depending upon categories and experi-
ences, we have begun to appreciate the logic of the animal mind and the
relationship between categories of the mind and experience. If it be true, as P&W
conclude, cheek filled with tongue, that "The ape could only be a mentalist... he
is not intelligent enough to be a behaviorist," may it also be conversely true that
the human behaviorist is not sufficiently intelligent to grasp the Critique of Pure
Reason?
Aping language [SR&B, GJ. The fundamental difference among these contribu-
tions lies not in how each values strict materialism, Kantian phenomena, or gestalt
mysticism, but in the importance and status given language. As SR&B state so
clearly in their introduction, a linguistic situation consists of the transfer of
information. The transfer may be verbal and acoustic, certainly, but it may also be
observed in bodily motion, facial expression, and behavior. G appears to
understand this fully, for his section "Testable hypotheses concerning cognitive
ethology" concentrates on examples that involve communication, symbolically,
posturally, or verbally. Presumably this section replies to the ideas, cited by him
just previously, of Ryle (1949 op. cit. G) whose work failed to perceive the
importance of the difference between learning and performance, much less the
broad meaning of language, and succeeded in providing an example of how and
why not to impose human categories on other species.
Both SR&B and P&W show no fright at introducing the concept of intentionality
into their explanations and designs. Intentionality, long a fortress of ethological
theory, can be conceived as a reasonable extension of motivation, and its return
along with emotion as an area of study is overdue and welcome, so long as the
concept's role as hypothetical construct is appreciated. SR&B's understanding of
symbolic representations leads them to procedures and interpretations that are
dramatic. Awareness (in G's word), cognition, or the mind is unlikely to be
singular. If awareness or mental state is not communicated, its selective value is
much restricted, and our observations tell us that animals do communicate mental
states to one another and, now it would seem, to us as well. May symbolic
representations be viewed with profit as a category of the mind - one, perhaps
called visual representation?
Language is a potential menace. All three of the papers under Commentary
agree on its importance; each differs somewhat concerning the view, stated or
tacit, as to what language is and how it is best investigated. I doubt that it is true
that language is the most important view of awareness or mental states, for
mystic, materialist, and phenomenologist alike can agree that language is but one
of many behavioral expressions that have little meaning to the investigator unless
the expression is communicated: that is, is understood and acted upon by
another being. So long as we conceive of language as something "given off" by
an animal, we shall attempt to read it as a lost language requiring a Rosetta stone
for interpretation. Language has meaning only insofar as it is reacted to: its
meaning lies in the behavior of the observer, not in the presumed motivations of
the giver. To lose sight of this distinction is to lose much that has been gained, as
shown in these papers, in our understanding of productive strategies of studying
the animal mind.
I propose that language, in the broad sense described, be treated as any other
hypothetical construct ought to be, as an entity "not observed." To write that it is
not observed is not to say that we have no observations of language: indeed, we
have too much of some and not enough of others. What has not been observed
systematically is the meaning of language as perceived by the recipient. Our
approach has been to compile a haphazard dictionary of what expressions,
postures, and the like "mean" to the giver. This dictionary is doomed, for it
assumes that the word units of language are graven. They are not: they are
alterable, evolving, and understandable only by observing the behavior of those
who read them.
P&W's and SR&B's research make it evident that they appreciate this
distinction, although I do not find them explicit about it. Those who follow to
expand and refine this research should understand the importance of the
564
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4

Commentary/Cognition and consciousness in nonhunian species
strategy, or animals will once again lose their minds. They, no doubt, will not find
its loss troublesome, but we human beings who want to peek into the animal mind
will lose a splendid opportunity. Be aware.
REFERENCES
Boden, M A. Purposive explanation in psychology. Cambridge, Mass.: Har-
vard Univ. Press, 1972.
Fechner, G. T. Elemente der psychophysik. Leipzig: Breitkopf and Hartel,
1860.
MacCorquodale, K., and Meehl, P. E. On a distinction between hypothetical
constructs and intervening variables. Psychological review, 55, 95-107,
1948.
Moss, D. McK., and Keen, J. E. The nature of consciousness: the phenomeno-
logical approach. Symposium paper presented at meeting of the American
Psychological Association, Toronto, 1978.
Mowrer, O. H. 1. Learning theory and behavior; 2. Learning theory and sym-
bolic processes. New York: Wiley, 1960.
Natsoulas, T. Consciousness. American Psychologist, 33, 906-914, 1978.
Smith, F. V. Purpose in animal behavior. London: Hutchinson, 1971.
Stevens, S. S. On the psychophysical law. Psychological Review, 64, 153-181,
1957.
Thorpe, W. H. Learning and instinct in animals. Cambridge, Mass.: Harvard
Univ. Press, 1956. Revised ed., 1962.
Tolman, E. C. Purposive behavior in animals and men. New York: Appleton-
Century-Crofts, 1932.
by Patricia Smith Chyrchlanci and Paul i . ChurchfaneS
Department of Philosophy, University of Manitoba, Winnipeg, Manitoba, Canada
R3T2N2
Internal states and cognitive theories. [G, P&W]. Mental States: Natural kinds
or functional kinds? [G] We are in clear accord with G on the cardinal insight of the
new wave, cognitivism: it is fruitful - nay, necessary - to postulate internal states
and processes in order to explain intelligent behavior in humans and other
animals [see Haugeland: "The Plausibility of Cognitivism" BBS 1(2) 1978]. But it
should be emphasized that the states and processes in question are best
conceived as functional in character. Unfortunately, G's laudable attempts to
seek a philosopher's perspective on the nature of minds and mental states did
not lead him to the strongest theory available, namely, functionalism (see, for
example, Putnam, 1967; Fodor, 1975; Dennett, 1978). The central tenet of
functionalism is that mental states are functional states; that is, they are the states
that they are in virtue of the interactive role they play in the larger information-
processing system. On the functionalist theory, mental states are not natural
kinds, nor is there a well-defined division between things that really do have
mental states and things that really do not. And as to determining how far down
the phylogenetic tree things really do have mental states, according to functional-
ism there is no fact of the matter. What is an empirical matter is what functional
organization chimpanzees do have, what functional organization rats have, and
what bees have. We can be tolerably sure in advance that the functional
organization of chimpanzees and bees will be substantially different, for the
nervous system of the chimpanzee is markedly different from that of the bee, and
the behavioural repertoire of the chimpanzee is much richer and more flexible
than that of the bee. And if we discover that chimpanzee behaviour can be
explained by a functional theory that postulates, among other things, beliefs and
desires, those states will be like our own to the degree that the chimpanzee's
internal functional organization is like our functional organization. That is, to the
extent that our functional organizations match up, so the functional role of our
"belief states" will match up, and to that extent the "belief states" in the
chimpanzee and the belief states in us are similar. Beyond this, there is little point
to pondering intrinsic similarities or a shared natural essence for mental states
generally, for if mental states are functional states, they have no intrinsic (i.e.,
non-functional) properties essentially, and the search for any such essence to
help us make transspecific identifications of mental activity is a false errand.
Dualism is the view that (a) mental states form a natural kind, and (b) this
natural kind is characteristic of a nonphysical dimension of reality. Most of us, G
included, have put (b) behind us. But (a) wants rejecting no less than (b). And
once (a) is behind us as well, it is plain that the only relevant cross-specific
similarities to be delineated are functional similarities.
Given that this is so, and turning to theories about the functional organization of
chimpanzees and bees, we must ask if it is really useful to include states like
beliefs and desires among the functional states we assign to them. Perhaps, so
long as we are aware that the states can only be analogues of our own - very
distant analogues in the case of bees, less distant in the case of chimpanzees. To
the degree that the analogy is remote, the ascription of beliefs and desires is
metaphorical, and in that case, it will surely be more promising to look for a quite
different sort of functional theory, leaving the belief-desire paradigm for, at most,
the higher animals. For this reason it is likely, in the case of very simple animals,
that neuroscience will be a faster route to such a theory than will orthodox
cognitive psychology. For as Pylyshyn's commentary illustrates, orthodox cogni-
tive psychology is still dominated by the belief-desire paradigm. Whether that
paradigm is appropriate for the higher animals is the question to which we now
turn.
Representational states: how should we conceive of them [P&W]? Let us
suppose, with P&W, that the chimpanzee does indeed have a theory that
postulates inner states in humans and other chimpanzees - inner states which, on
the chimpanzees' theory, are related to one another, to sensory circumstances,
and to behavior in ways that permit the systematic anticipation of behaviour in
others. This supposition is certainly appealing, for chimpanzees and other
animals can indeed anticipate the behaviour of other creatures to a degree that
seems explicable only on the assumption of their possessing something as rich
and powerful as a theory of the kind described. And for our part, we do not
hesitate to accept this much.
However, there are two cautions that must be entered here, for the proper
conclusion to draw is in fact crucially weaker than the one P&W defend. First, the
fact that the chimpanzee successfully anticipates what we would anticipate in a
given situation does not guarantee that the theory he uses to do this is the same
theory that we use. It implies only that his theory predicts more or less what ours
does in that situation. Beyond their behavioural consequences in prosaic
domains, their theory and ours might differ substantially. Even radically.
In illustration, consider an alien people (whose language remains untranslated)
who display an impressive ability to anticipate and control thermal phenomena.
Their capacity in this respect might be put down to their knowledge of the familiar
corpuscular/kinetic theory of heat. But it could also be accounted for by
supposing them to hold the very different caloric fluid theory of heat. Over a wide
range of cases, these two theories are empirically indistinguishable, and so will be
the behaviour of their respective adherents. In fact, there is a potential infinity of
theories of heat that share this feature, and the gross behaviour of the aliens will
be fairly well accounted for whichever such theory we assume them to hold [cf.
Pylyshyn: "Computational Models and Empirical Constraints" BBS 1(1) 1978].
Accordingly, the chimpanzee may indeed be a theorist, and a successful one,
but the evidence tendered by P&W does not show that what the chimpanzee
imputes consists of desires that P, beliefs that Q, and so forth. The chimpanzee's
theory of mind might be as different from ours as is the caloric from the kinetic
theory of heat.
We do not wish to insist from this, as perhaps Quine (1960) would, that the
chimpanzee's theory is ultimately inaccessible to us. But we do wish to caution
against reading our theory of mind into his outlook.
To caution thus is of course to remain faithful to the idea that the chimpanzee
must possess something as rich and powerful as a theory. And we agree that he
must. But here a second caution wants making. To assume that what the
chimpanzee possesses is actually and literally a theory, a set of beliefs in sundry
general and particular propositions, is to suppose that our common-sense theory
of mind is literally true of chimpanzees. And this is a supposition of which we
should be very chary, given the lesson learned in the preceding paragraph, for the
very modest success of our folk psychology - as applied to chimpanzees, and
even to ourselves - need not be due to its truth. Beyond question the chimpanzee
manipulates internal world representations of some highly sophisticated kind. But
for us to represent his representings on the overtly linguistic model that dominates
(almost constitutes) our own theory of mind is to be insupportably parochial
again. Recall that it is a framework feature of our folk theory of mind that the
principal mental states are always identified by reference to a sentence - John
believes, desires, fears, suspects, doubts, hopes, and so on - that P, we say,
(where some sentence substitutes for "P".) Granted, human language is so far
the only model for systematic world representation we possess; but that is a
defect in our intellectual situation that desperately needs remedy, arguable as it is
that the linguistic model is inadequate even to represent our own cognitive
activities. For extended discussions of the inadequacies of the linguistic para-
digm, see Churchland, P. S. (1978, 1979), and Churchland, P. M. (1979).
In sum, it seems clear that chimpanzees are "world representers" in some
sense, and also that they "represent" some things in the world as (other)
"representers." But it is far from clear that they believe that others have, for
example, beliefs, and it is probably self-stultifying for psychology to assume that
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4
565

Commentary /Cognition and consciousness in nonhuman species
they do. For what we need is a psychological theory that can explicate the vague
notion of a representational system in ways that go beyond the linguistic
paradigm which has so long imprisoned us.
REFERENCES
Churchland, P. S. Foclor on language learning. Synthese, 38: 148-59. 1978.
Language, thought, and information processing. Nous, 1979.
Churchland, Paul M. Scientific realism and the plasticity of mind. Cam-
bridge, 1979.
Dennett, D. C. Brainstorms: Philosophical essays on mind and psychology.
Montgomery, Vt: Bradford, 1978.
Fodor, J. The language of thought. New York: Thomas Crowell, 1975.
Putnam, H. The mental life of some machines. In Casteneda, H. (ed.), Inten-
tionality, mind, and perception. Detroit: Wayne State Univ. Press, 1967.
Quine, W. V. Word and object, chap. 2. Cambridge, Mass.: MIT Press, 1960.
by Lawrence H. Davis
Department of Philosophy, University of Missouri-St. Louis, St. Louis, Mo. 63121
Intentions, awareness, and awareness thereof. Intentions and awareness in
communicating [SR&BJ. According to SR&B, they have evidence that Sherman
and Austin not only communicate information (even DNA and bacteriophages do
that, as G points out), but also "comprehend the symbolic and communicative
function of the symbols they use." Comparable evidence for Washoe and Sarah
has, they believe, not been reported. But on their own account, such comprehen-
sion turns out to require beliefs about one another's beliefs and intentions (what
P&W call a "theory of mind"). And the evidence for this seems no better than
what might be assembled for Washoe or Sarah: "richly interpreted" anecdote or
things simply taken for granted ("E responded by demonstrating to Cr, with an
open-hand gesture, that he had no tools . . . after five or six trials the animals
seemed to begin to comprehend").
The alleged comprehension is a question, they say, "of awareness and
intentionality." But awareness of what? And precisely what intentions? SR&B
quote Mounin (1976 op. cit.) and Steklis and Hamad (1976 op. cit.) to the effect
that, among others, the following are requisite: (1) the "transmitter" of a
communication must be aware that his target is the "receiver"; (2) the receiver
must be aware of being the transmitter's target; and (3) the gestures or symbols
used must be "intended and relied upon to transmit information."
What do these mean, and why are they necessary? One plausible account runs
as follows. When Cr (requester chimp) presses wrench, he is trying to get Cp
(provider chimp) to bring the wrench. He believes that pressing wrench (and
getting Cp to notice) is a good means for achieving this. Why does he believe
this? Perhaps because, during those first five or six trials, each C realized that
when he was Cr, Cp would in fact bring the tool requested. But if this is the sum of
the matter - in particular, if Cr has no idea why Cp brings the tool requested - we
cannot say there is genuine communication (that is, communication with the
"comprehension" of which SR&B speak). Cr would merely be manipulating Cp as
he might manipulate an inanimate object; he would not be asking Cp to bring the
wrench. We must say that Cr does not regard Cp merely as a "black box," but as
a creature with intentions and beliefs. If so, we can say that Cr understands his
pressing the wrench as getting Cp to believe that he has reason to bring the
wrench, and so getting him to form the appropriate intention. If so, we can say he
is pressing the wrench intending thereby to transmit information to a specific
target (1 and 3 above). And this can plausibly be regarded as genuine
communication.
At the other end, Cp may view Cr's action as an attempt to tell him something -
to give him the information that he (Cp) has reason to bring the wrench - or
simply as an indication that he does have reason to bring the wrench. In the
former case we can say he is "aware of being Cr's target" (2 above). And only in
the former case can we say that he "comprehends the communicative function"
of Cr's action.
(Among philosophers, this general approach to communication has been
pioneered by Grice, 1957, 1969 op. cit. SR&B, and to my knowledge, most fully
and carefully developed by Bennett, 1976.)
Can we say that Cr imputes intentions and beliefs to Cp? SR&B say that after
the first few trials, Sherman and Austin had for the first time "reason to presume
that the other animal knew and used [intentionally?] such symbols" (my empha-
sis). But no particular evidence is given that either animal actually came to this
realization, rather than the simpler realization that each animal would in fact
behave in certain ways. (Cf. Mounin's suggestion, endorsed by SR&B, that
Sarah's "messages" might in fact be contentless, merely reflecting her belief that
if she makes such-and-such a response, she will be rewarded.)
Perhaps it is relevant that Sherman and Austin readily reversed roles. We can
imagine each thinking "when he presses wrench and I bring it, I do so because I
believe I will be rewarded; so when I press wrench and he brings it, he must do so
for the same reason." But this is plausible only if it is plausible to suppose that
each imputes intentions and beliefs to himself. In the next section, I will explore the
possibility that in one sense (though perhaps not the sense relevant here),
animals do not make such imputations.
But first, notice again that SR&B take for granted that Sherman and Austin
themselves do have intentions and beliefs, whether or not they impute them to
one another. Perhaps this is justifiable (since no single experiment could prove it,
anyway; see my last section, below.) But what follows if we take seriously their
descriptions - say, that of C as "gesturally and vocally soliciting aid if he could
not orient the tool properly"? If C has beliefs and intentions, and solicits aid by
means of gesture, he must believe that the gesture is likely to result in aid being
tendered him. And if it is really proper to describe C as "soliciting aid" rather than
merely doing something he has reason (what reason?) to believe will cause E to
help him, then again we must suppose that C imputes intentions and beliefs to the
target of his gesture. He has learned that E is generally benevolent, and will offer
aid if he (C) gives him (E) reason to believe he (C) needs it.
If SR&B are willing to stand by this description of C as "soliciting aid" (and
similar descriptions), then they must regard their whole experiment as showing
little beyond what they took for granted right from the start. And if they are not
willing, they ought explicitly to address the question of what in their experiment
shows that Sherman and Austin really had the intentions and awareness neces-
sary for genuine communication. Certainly not the mere fact that they employed
symbols rather than "iconic" gestures. For in those first trials, they might have
learned to rely on one another's behavior without having or making use of any
insight into why they could do so.
In any case, notice that all the intentionality and awareness requisite for
genuine communication could have been present in the case of gestural commu-
nication. The "issue of iconicity " seems to be relatively unimportant, contrary to
what SR&B say.
Awareness of intentions, awareness, etc. [P&W]. An organism has a theory of
mind if it imputes mental states to itself and others, say P&W, but virtually all the
experiments they describe at best yield evidence that their animal subjects impute
mental states to others.
It is worth taking seriously the possibility that there are organisms which impute
mental states to others but not to themselves. Perhaps Sarah's choice of
photograph really does reflect her belief that the actor wants to get the bananas
and believes (or would realize if he stopped struggling long enough to look around
his cage) that stepping on the box would be a good way to get them. (I have
misgivings, however. How did P&W manage to "ask the animal to indicate how
she thought the human actor would solve his problem," and how sure can they be
that she got the message? Cf. Mounin's criticism of other experiments with Sarah,
quoted by SR&B.) It remains possible that Sarah has no beliefs about - no
awareness of - her own wants and beliefs, or any other of her mental states.
If we grant that Sarah has beliefs and is capable of acting intentionally and
intending (for the distinction, see Davis (1979)), we would probably also have to
grant her beliefs about - awareness of - what she is doing and what she expects
to do. But present and future actions are not mental states, present or future. A
chimpanzee making a termite-probe might know that he was doing so, that he
was going to catch termites with it, and even that he was doing the former in order
to do the latter, without imputing any mental state to himself. G speculates that if
asked what he was doing, such a chimpanzee might answer "that he was
contemplating the capture or eating of termites." Now contemplating may be a
mental action rather than a mental state, but it is still entirely mental, and so we
would have to accept this answer as refuting the hypothesis that chimpanzees do
not impute mental states or actions to themselves. But of course no such answer
has yet been obtained, so we may continue exploring this hypothesis. (Nor would
it be easy to be sure we had gotten such an answer. How could we ascertain that
something the chimpanzee said had this meaning? Difficult, but perhaps not
impossible. See Bennett, 1976.)
P&W suppose that if Sarah could be taught to say whether she knew
something or was merely guessing, this would show that she did impute mental
states to herself. But strictly, they envisage her applying "know/guess" to her
actions. Conceivably she could come to discriminate actions based on her
relevant knowledge from actions performed despite the absence of relevant
566
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4

Commentary /Cognition and consciousness in nonhunian species
knowledge, while at the same time failing to have any belief about the presence or
absence of this relevant knowledge. (Parallel remarks apply to "truth/lie".)
Our understanding of mental states is essentially flavored by the fact that we
do impute them both to ourselves and to others - to others on the basis of
behavioral criteria, and to ourselves, in many cases, on the basis of no criteria
(Strawson, 1959; Shoemaker, 1963). If Sarah really imputes no mental states to
herself, then (a) those she has differ from ours, at least in not directly causing
awareness of (i.e., belief about) themselves, and (b) what it is that she imputes to
others would not quite consist of mental states as we understand them, but
merely of what P&W suggest: a system of inferred states useful in predicting the
behavior of other individuals. Perhaps we should say she imputes "psychologi-
cal" states rather than "mental" states, so that P&W's experiments would show
that Sarah has a psychological theory of the behavior of others, rather than a
theory of mind. And perhaps in the light of (a) we might say that Sarah herself
does not have "mental" states, but only "psychological" states. But it would be
dangerous to make much of this distinction without a good deal of supporting
argument. I am thinking in particular of possible claims that the distinction has
moral significance. Suppose for example that Sarah, when injured, is in a
"psychological" state that is just like our "mental" state of pain except that she
lacks "direct awareness" that she is in it. (She might have indirect awareness
based on her awareness of the injury and of her behavioral tendencies.) Could
this difference make a difference so far as the moral injunction to relieve pain is
concerned? (Cf. the last section of G, and Davis, 1974.)
Final Comments [GJ. G discusses the presence in nonhumans of what I would
call (i) beliefs and thinking, (ii) acting intentionally and intending, and (iii) direct
awareness of one's own mental states. Some points on which I would agree or
disagree may be gleaned from my comments on SR&B and P&W, especially as
regards communicative behavior, and my distinction between "mental" states
and "psychological" states. But several further points should be made.
1. "One necessary . . . condition for the occurrence of awareness and think-
ing is the presence in the brain of patterned images. . . . " G allows that these
images may be "coded in a variety of noniconic ways," but they still sound too
much like actual pictures in the head. Surely his point could better be made in
terms of concepts, or information and its storage, rather than in terms of images.
2. G often uses the phrase "conscious intent"; to me, the phrase suggests
"intention which the organism is aware of having," and so I want to stress again
that we might have plenty of evidence for animal intentions of various sorts but
much less evidence for supposing they are aware, directly or even indirectly, of
having them. In the same vein, G quotes himself on the presumed "adaptive
advantage" conferred by "awareness." This is plausible if it is specifically
awareness of - beliefs about - the organism's environment, its own bodily state,
what it is doing, what it will do, and so on. I am much less convinced of any such
adaptive advantage to awareness of its own "psychological" states (an aware-
ness which, if direct, would render them "mental" states), outside of a fairly
sophisticated linguistic community. But work by Gordon (1978, 1979) may be
relevant here.
3. Favorable results of G's proposed experiment to test whether honeybees
intend to communicate by means of their dances (hence "comprehend the
symbolic nature and communicative function" of the dances, as SR&B might put
it) might indeed support the claim that they do. But there is a major proviso.
Alternative interpretation of such results is possible, as we have already seen.
What inclines us to interpret specific chimpanzee behavior in terms of communi-
cative intentions is our general readiness to interpret and explain so much of
chimpanzee behavior in terms of beliefs and intentions. And this general
readiness stems from the fact that so much of this behavior fits the very natural
hypothesis that they have beliefs and intentions, and fits so well that this
hypothesis must be counted our "best (only?) explanation" of the behavior. (For
this reason, the wealth of anecdotal evidence disparaged by SR&B yet tacitly
relied on by them is actually of great and legitimate importance as background
support for their interpretation of the isolated behaviors on which their report
focuses.) G's envisioned experiment could never convince us if the waggle-
dances remained the only area of the honeybee's life for which explanation in
terms of beliefs and intentions seemed plausible. (For more on the kinds of
behavioral evidence needed to support claims about beliefs and intentions in
languageless creatures, see Bennett, 1976.)
4. I cannot understand the alleged significance of Gallup's experiment, cited
by G. If we are at all willing to impute beliefs to the chimpanzee, we must surely
allow him to believe that someone is stepping on his toe if, indeed, someone is
stepping on his toe. So he must have the concept of his toe, and a concept of
himself. (He does not respond by attacking someone stepping on another
chimpanzee's toe!) Perhaps this is what G is saying in pointing out the absurdity of
"awareness of everything but me." But then obviously chimpanzees have
self-awareness, and Gallup's experiment teaches us nothing except that chim-
panzees can acquire beliefs about themselves via mirrors as well as in other
ways. We already knew they could acquire them in other ways. An interesting kind
of self-awareness would be awareness of one's own mental states; but Gallup's
experiment is totally irrelevant to this.
ACKNOWLEDGMENT
I wish to thank John E. Parks-Clifford for helpful discussion of SR&B.
REFERENCES
Bennett, J. Linguistic behaviour. Cambridge: Cambridge Univ. Press, 1976.
Davis, L. H. Functional definitions and how it feels to be in pain. Paper read to
the Society for Philosophy and Psychology, Boston, October 1974.
Theory of Action. Englewood Cliffs, N.J.: Prentice-Hall, 1979.
Gordon, R. M. Hedonic motivation, rationality, and adaptation. Paper read to
the Society for Philosophy and Psychology, Medford, Mass., April 1978.
Pain and terminating reasons. In preparation, 1979.
Grice, H. P. Meaning. Philosophical Review, 66:377-88, 1957.
Shoemaker, S. Self-knowledge and self-identity. Ithaca: Cornell Univ. Press,
1963.
Strawson, P. F. Persons. In Strawson, P. F., Individuals, pp. 81-113. Garden
City, N.Y.: Anchor Books, 1963.
by Roger T. Dawis
Washington State University, Department of Psychology, Pullman, Wash. 99164
Animal cognition without human consciousness. The BBS issue on cognition
and consciousness in nonhuman species contains three distinct papers. SR&B
have combined the traditions of studying tool use, both from laboratory and field
observations, with what they have learned about communication and cooperation
in chimpanzees. The result consists of data and logical arguments supporting
"symbolically mediated exchange of goods and information in a nonhuman
species." P&W's paper describes the halfway point in their long-term program of
research on inferences about the chimpanzee's mind by human beings, and,
more interestingly, the reverse. A progress report like P&W's is intriguing not only
because it presents completed studies, but also because it suggests plans for
future research. Thus one excitedly awaits the papers in press and the next
installment. Since SR&B and P&W approach animal mental life empirically and
empirical-programatically, respectively, G's paper should have been a good
review of the literature on cognition in nonhumans, or at least a systematic sequel
to his 1976 book on animal awareness. He makes lengthy quotations from his
book, but presents little that is new. Ultimately, he attacks a straw man,
"behaviorism," and advocates what we need least, another neologism, "cogni-
tive ethology."
Although Premack & Woodruff reassure us that the ape "is not intelligent
enough to be a behaviorist", they (and, less so, SR&B) can be faulted for failing to
tie their exciting data and projections to what we already know about nonhuman
awareness. For example, P&W employ distinctly dressed actors to convey
purpose, knowledge, belief, doubt, liking, and so forth, in stopped film strips. In
this, they are similar to (perhaps even more sophisticated than) Hebb and
Thompson (1954), who had actors in distinctive suits and masks play the roles of
a bold or timid man. Chimpanzee subjects were quite able to make inferences
about the mental states of the masked actors, and the actors played their roles
sufficiently well to be able to interchange suits and receive corresponding
differential treatment by the apes. Another point of P&W's discussion involves
their developing concern with the primitiveness of perceived causality. One hopes
that they will take advantage of the fact that their animals are movie-trained so as
to employ cartoons embodying demonstrations which elicit perception of cause in
human beings (see Michotte, 1946). Shaping might be needed, but the demon-
stration would help P&W avoid a problem, which they recognized elsewhere, of
language-dependent mental perceptions.
Savage-Rumbaugh et al. make significant methodological advances in the
study of animal-animal communication problem solving, but they owe an historical
debt to earlier studies of observational learning in monkeys (e.g., Darby and
Riopelle, 1959). If one monkey can benefit from seeing another make an error, it
is entirely possible that the tools could be matched samples to their associated
functions for apes. One must remember that chimpanzees have the cognitive
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4
567

Commentary /Cognition and consciousness in nonhuman species
capacity to match across modality (Davenport and Rogers, 1970), so the match
from tool to function is a reasonable possibility. This does not detract from the
clever experiments of SR&B and of P&W, but I would have preferred more context
from the rich literature on animal cognition.
Griffin presents no new data and omits much of the progress in animal
cognition over the past twenty years. Also, he plays the intellectual game of
shooting down a theoretical position which is already dead and inventing an
imaginary field. This generalization obviously omits his own brilliant work on
navigation in birds and echo-location in bats, and his more complete earlier
attempt to raise the question of animal awareness (1976 op. at. G, SR&B).
Behaviorism was never as monolithic as G's straw man. It lacked adequate
technology, data, and theory to justify expending much time or effort in contem-
plating nonobservables when there were so many interesting things to observe,
measure, and control. However, as technology advanced and data were
collected, many theoretical structures associated with behaviorism had to be
discarded. This resulted in a neobehaviorism with many ideas concerning animal
cognition. Much of this work on animal cognition was done with the behavioristic
penchant for careful control and was even conducted in alley mazes (Gleitman
and Steinman, 1963) and Skinner boxes (Gleitman and Bemheim, 1963). Space
does not permit full development of this argument, but a few examples may
suffice to illustrate that comparative psychologists have been studying cognitive
problems during the past twenty years and are much more in need of a theoretical
structure than a fictional field such as cognitive ethology or sociobiology.
To illustrate that my own contention is not just an attack on another straw man,
the following are areas in which psychologists have recently studied cognitive
experiences by animals: (1) cross-modal transfer; (2) surgical and optical
sensory recombination; (3) several hundred papers on memory and its develop-
ment, including reinstatement, rehearsal, and the use of surprising cues; (4)
transposition; (5) conditional reaction problems; (6) perceptual constancies; and
(7) the perception of barriers and detours. Probably I should also have included
Harlow's (1949) formation of learning sets, which bridges the gap between
incremental learning and insight. This is a considerable commitment to a
comparative and evolutionary analysis of cognition. We need to organize animal
cognition into a coherent theoretical structure using the presently abundant data.
REFERENCES
Darby, C. L., and Riopelle, A. J. Observational learning in the rhesus monkey.
Journal of Comparative and Physiological Psychology, 52, 94-98, 1959.
Davenport, R. K., and Rogers, C. M. Intermodal equivalence of stimuli in apes.
Science, 168, 279-280, 1970.
Gleitman, H., and Bernheim, J. W. Retention of fixed-interval performance in
rats. Journal of Comparative and Physiological Psychology, 56, 839-841,
1963.
Gleitman, H., and Steinman, F. Retention of runway performance as a func-
tion of proactive interference. Journal of Comparative and Physiological
Psychology, 56, 834-838, 1963.
Harlow, H. F. The formation of learning sets. Psychological Review, 56, 51-
65, 1949.
Hebb, D. O., and Thompson, W. R. The social significance of animal studies.
In G. Lindzey, (ed.), Handbook of Social Psychology, vol. 2, Reading,
Mass., Addison-Wesley, 1954.
Michotte, A. La perception de la causalite. Louvain, Institut Superieur de Phi-
losophic, 1946.
by Marian Oawkins
Animal Behaviour Research Group, Department of Zoology, University of Oxford,
Oxford, England
The second time around. The behavioral sciences appear to be coming full
circle. There was a time, many years ago, before the dominance of behaviorism,
when questions about animal minds and emotions were considered to be quite
legitimate, and indeed they are still seen as such by people not schooled in the
behaviorist tradition. Then, in the early part of this century, the methodological
self-discipline of behaviorism took over, and most ethologists and psychologists
even up to the present day have fought shy of considering questions of
consciousness and mental awareness on the grounds that they are not accessi-
ble to scientific investigation and should be left severely alone. Now times are
again changing. Subjective phenomena are once more being seen as legitimate
areas for scientific study. But whereas this appears to be simply a reversion to an
earlier view, a counter-revolution to bring us back to a more enlightened time, it is
in reality far more than this. The second time around for scientific consideration of
subjective phenomena in animals is characterized by a rigor, a determination to
consider alternatives, and above all by attempts to make predictions and test
hypotheses, all of which was previously lacking.
Griffin sets the stage by arguing forcefully for a cognitive ethology and
attempting to meet head on some of the objections to it. For example, it is often
argued by skeptics that postulating subjective experiences in animals does not
lead to any specific predictions at all - it would not seem to make any difference
to an animal's behavior whether or not it was conscious. In other words, the
existence of subjective experiences is something for which there can be no
rigorous test. G answers this objection in two ways. Firstly, he argues that
open-minded agnosticism is more appropriate (and indeed more scientific) than
flat denial, and that while it is true that we have no rigorous proof of the existence
of subjective experiences in animals, neither are we able to claim rigorous proof in
many other areas of biology (as is the case with the far-reaching and productive
theories of sociobiology). G's second argument, which follows from this, is really
the more exciting one, namely, that it is possible to formulate testable hypotheses
about animal subjective awareness. The two papers on chimpanzees by P&W
and by SR&B, which accompany G's in this issue, illustrate this point.
Premack & Woodruff set out to investigate something that appears at first sight
to be quite out of bounds as far as respectable science is concerned, namely,
whether chimpanzees ascribe mental states to other animals, such as human
beings. The importance of this paper seems to lie not so much in whether it
actually shows that chimpanzees do have a concept of mind as in the method of
approach. There seem to be some objections to the evidence that is actually
presented, but in thinking about these objections, one is forced to the conclusion
that it would still be possible to devise an experiment which would be convincing.
This is a far cry from saying that the phenomenon is one which is in principle not
open to investigation at all.
In fairness to the authors I should be more specific. In the first experiment, the
matching between the actor's stance in the video sequence and his stance in the
"correct solution" photograph is acknowledged by the authors as being a
confounding factor and considerably weakens the conclusion. This result is so
crucial to the idea that the chimpanzees are really "assuming that the human
actor wants the banana," as opposed to just completing a sequence, that it is a
pity that it suffers from this objection. The later experiments with inanimate
objects which are said to rule out physical matching suffer from the fact that
although familiar sights cannot easily explain the results, the effects of familiar
sequences do not seem to have been ruled out as completely. In any case, it is
unfortunate to have to use a later experiment to justify the conclusions of an
earlier one without simultaneous controls. But, as I said before, this is not the
important point. The fact that controls could have been introduced and means
could have been devised of more completely eliminating simpler explanations
does not detract from the conceptual leap forward which the authors have taken
in daring to ask their questions.
Savage-Rumbaugh et al.'s very valid criticisms of earlier experiments on
chimpanzee communication (for example that there were often inadequate
controls for experimenter bias) actually reinforce the point that it is in principle
possible to devise rigorous experiments. Picking small holes in existing evidence
is in fact a means of developing new and more watertight experimental
paradigms, rather in the way that experiments on pigeon homing have been
improved by the realization that more controls have to be introduced than was at
first thought.
The second time around for the scientific assessment of animal consciousness
is, as illustrated by the three papers in this special issue, characterized by
adventurous questions and by the realization that it is possible to make
determined attempts to answer them. It is not a time when "anything goes" and
one interpretation is as good as any other. As G points out, the prospects for a
cognitive ethology are much better now than they were in the days of Darwin and
Romanes. At long last we can look forward to a real understanding of subjective
awareness in animals, one of the profoundest mysteries in the whole of biology on
this, the second time around.
by Daniel C. Dennett*
Department of Philosophy Tufts University, Medford, Mass. 02155
Beliefs about beliefs [P&W, SR&B]. Because of its intrinsic interest - indeed its
fascination - it is easy to lose track of the point of this kind of research. Getting a
chimpanzee to talk takes on the aspect of sending a man to the moon. Suppose
you succeeded. Then what? Presumably behaviorists would have to claim to be
unimpressed, as unimpressed as they are by the verbal abilities of - themselves,
for instance. So suppose we grant for the sake of a superannuated argument that
568
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4

Commentary/Cognition and consciousness in nonhuman species
in principle a suitably complex version of behaviorism can "handle" all ape
behavior (and all human behavior too). That version of behaviorism will of course
be scarcely distinguishable from mere mechanistic materialism - with micro-
events in the brain being viewed as responses, for instance - and there is scant
reason to oppose that creed, at least at this stage of our knowledge. The issue
that remains is, on a first pass, how fancy a cognitive structure is required in
practice to predict a chimpanzee's behavior. That is, granting that in practice it is
desirable to intentionalize our account of chimpanzees (by attributing beliefs and
desires, or belieflike states and desirelike states, Dennett, 1971, 1976), which
beliefs and desires will it be useful, predictive, illuminating to attribute? In the
present instance, will we find it valuable to attribute second-order beliefs and
desires - beliefs and desires about the beliefs and desires of others? If so, then
chimpanzees have a theory of mind in the requisite sense, for they use the
concepts of belief and desire (or concepts importantly analogous) in their own
action governance. If they turn out to have humanlike theories of mind, they will
have use of even higher-order intentional attributions; they perhaps believe
someone wants them to believe something, or want someone to believe they want
something, and so forth. But how can these suppositions be put to the test?
I think the issue is analogous to the current controversy about mental images.
What the growing literature on mental images shows is that whatever it is to which
we may in the end "reduce" mental-image talk, there can be no doubt that there
is a level of description of the phenomena at which imagistic characterizations are
perspicuous because they are richly predictive of a surprisingly wide variety of
behavioral effects. Talking of mental images may be a fagon de parler, but it is no
"mere" fagon de parler, because taking the talk (quite) literally keeps on leading
to confirmed predictions. This is undeniable even if it is also true that talking about
mental images is itself in dire need of explanation - and even of ultimate
elimination if one supposes that mental images cannot be taken dead literally as
3-D pictures in the brain.
What must be shown by Premack & Woodruff, analogously, is that imputing a
theory of mind to chimpanzees (whatever that comes to literally, in the end) is
richly predictive. As P&W note, any single test, however consonant its results with
the theory-of-mind hypothesis, can be given a deflationary redescription by
associationists et al. What one wants is a panoply of results elegantly predicted
by the theory-of-mind hypothesis and only predictable with the aid of ad hoc
provisions by its competitors. P&W do not yet have these results, as they grant,
but while the experiments they are now undertaking would favor their hypothesis if
the results were positive, they seem somehow slightly off target. P&W are
searching for evidence that chimpanzees have expectations of the behavior of
others that are better explained by supposing that they are (tantamount to)
predictions derived from the chimpanzee's beliefs about the beliefs and desires of
those others than from supposing that they are derived from either habits (of
thought) or beliefs about other features of the world (e.g., experienced regulari-
ties in the behavior of others). But the very training required to bring an animal into
P&W's test situations seems to provide the relevant experience for engendering
such alternate habits or beliefs. P&W are aware of this, and much of the
complexity of the tests they have designed is dictated by their desire to make this
alternative hypothesis less plausible. But in becoming so devious, the tests
seem - to me - to sacrifice the most interesting hypothesis: it would be much
more exciting to discover that chimpanzees normally have (naturally acquire in
their lives) a theory of mind than to discover that chimpanzees can have a theory
of mind dinned into them eventually. Bears can ride bicycles - a surprising fact of
elusive theoretical interest. But when one tries (as I have, now, for several days)
to dream up better experiments for P&W to run, one begins to appreciate that it is
very hard to think up direct, natural, plausible tests. Why should this be?
Very young children watching a Punch and Judy show squeal in anticipatory
delight as Punch prepares to throw the box over the cliff. Why? Because they
know Punch thinks Judy is still in the box. They know better; they saw Judy
escape while Punch's back was turned. We take the children's excitement as
overwhelmingly good evidence that they understand the situation - they under-
stand that Punch is acting on a mistaken belief (although they are not sophisti-
cated enough to put it that way). Would chimpanzees exhibit similar excitement if
presented with a similar bit of play acting (in a drama that spoke directly to their
"interests")? I do not know, and think it would be worth finding out, for if they
didn't react, the hypothesis that they impute beliefs and desires to others would
be dealt a severe blow, even if all the P&W tests turn out positively, just because it
can be made so obvious - obvious enough for four-year-old children - that
Punch believes (falsely) that Judy is in the box.
But suppose we are uncertain how to interpret the children's glee; how can we
go about strengthening the hypothesis that they believe Punch believes . . . ? We
can ask them questions, particularly "why questions," but others as well ("What
do you think Punch would have done if... ?"). But are there nonverbal tests we
can also employ? It is hard to think of any that would be decisive that wouldn't be
too difficult for the children. This is because of the complexity of the "thought
processes" one has to impute to any person or animal who acts on the basis of
such a prediction from a theory of mind. So far as I can see, the minimally
complex pattern has the following format:
1 C believes that E believes that p.
2 C believes that E desires that q.
3 C infers from his beliefs in (1) and (2) that E will therefore do x, and so,
anticipating E's doing x,
4 C does y because
5 C believes that if E does x, then unless C does y, C won't get something C
wants, or will get something C wants to avoid.
(This is the minimally complex pattern for doing something because you believe
someone believes . . . ; doing something in order to get someone to believe
something in order to get him to do something . . . has a different but equally
complex scenario.)
The ideal experiment to establish the use of such an explanatory format will
have the following features:
a. E's anticipated action x will be a (relatively) novel action, or at least an action
that (arguably) could not be anticipated by C under the circumstances simply by
virtue of being habitual for E or oft-repeated in just these circumstances. (An
elegant way of accomplishing this is to ensure that the belief attributed to E in (1)
is false (cf. Punch and Judy), for then E will be expected to act inappropriately to
the circumstances, and hence, in all likelihood, not the way E has typically acted in
the past.)
b. C's action y will also be an action as much as possible from C's natural
repertoire, rather than a highly trained artificial response, for again, arduous
training procedures almost inevitably provide grist for the associationist's mill
(Dennett, 1976).
c. The perceived (by C) dependence of y on x should also be natural and
obvious, so that C's belief in it (5) can be attributed to C on the basis of C's
straightforward observation of a relatively novel circumstance, rather than on the
basis of extensive training.
Trying to design experiments to meet these conditions soon reveals the
difficulty. Conditions (1-3) are relatively easy to meet - one would think. For
instance, suppose there is a key that E, the experimenter, uses to open the
banana locker. One day two boxes, one red and one green, are placed in the
scene, and C sees E put the key in the red box and leave the scene. Then C sees
Sneaky Pete come in and move the key to the green box. When E returns to feed
C, ex hypothesi C believes that E believes that the key is still in the red box, and
hence C expects E to go to the red box (since he believes that E wants to get the
key). But now, how can things be rigged so there is something C might see to do
that is appropriate to C's expectation (meeting conditions (4) and (5))? P&W's
solution at this step is to train C to perform a sort of proto-speech-act, a
prediction by choice of photograph, with the assumption that, for predictions,
truth is its own reward (thus satisfying C's desire in (5)). But this is gimmicky. One
would prefer to have C's action y interact more meaningfully with E's action x, but
reflection reveals that this is hard to set up without resorting to another sort of
gadgetry: artificial dependencies created between x-type actions and y-type
actions that C might be trained'to recognize.
The conclusion that seems borne in on one is that unless there is a great deal
of normal interaction - either competitive or cooperative - between C and E,
there is just no way for C to come to perceive his own actions as meshing with E's
in the tight way required at step (5). One can rig it up - e.g., C could be taught
that he will get a shock if E opens the red box unless C, anticipating this, moves to
a particular location - but this requires training that removes the desired novelty
listed in (a). This objection to gimmickry is not just aesthetic, of course; the more
artificial the test circumstances, the more restricted the range of predictions
available to the theory-of-mind hypothesis, and as noted at the outset, predictive
fecundity is of the essence in this investigation.
It appears that except in tricky environments that require extensive training to
produce familiarity, the only act-types that naturally meet the conditions are
communicative acts, such as C's warning E, or requesting something from E, or
asking E a question; and so the problem of the training factor now pertains to the
training up of communicative act-types. In this regard Savage-Rumbaugh et al. 's
format with Austin and Sherman looks much more straightforward and promising
if the communicative mode of interaction between Austin and Sherman can be
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4
569

Commentary /Cognition and consciousness in nonhuman species
extended to relatively novel situations without (much) additional training. But still
the conclusion that would follow success in such experiments would be at best
that chimpanzees can be put in complex artificial environments (artificial for
chimpanzees, not for people) in which they eventually develop a theory of mind. In
their natural environments there seems to be no clear need for them to develop a
theory of mind about each other, and hence no compelling reason to impute it to
them. But perhaps further ingenious experiments will find a way of meeting the
desiderata listed and make a believer out of me.
REFERENCES
Dennett, D., Intentional systems. Journal of Philosophy. 68:87-106. 1971.
Conditions of personhood. In: A. Rorty (ed.), The Identities of persons.
Berkeley: U. Cal. Press, 1976.
EDITORIALNOTE
"Received too late for a Response from P&W or SR&B. See Continuing
Commentary. [Ed.]
by William Orr Dingwall
Linguistics Program, University of Maryland, College Park, Md. 20742
Animals and the rest of us: Descartes versus Darwin. Topics as complex,
ill-defined, and open-ended as those to which this special issue of BBS is devoted
cannot possibly be resolved, if at all, within the compass of a few thousand
words. One can at best select those aspects of the problems that have personal
appeal, relying on differences of interest as well as opinion to provide the needed
breadth of coverage. Since Griffin, in his contribution and earlier book (1976 op.
cit. G, SR&B), elaborates the kinds of questions that are partially addressed by
the experiments in the other two contributions, it seems logical to begin with a
discussion of his views.
Are the meadows of cognitive ethology really greener [GJ? Since the views of
Darwin, a firm believer in continuity, are often cited as forming one of the major
pillars of modern ethology (cf. Eibl-Eibesfeldt, 1975; see also Eibl-Eibesfeldt:
"Human Ethology" BBS 2(1) 1979), it seems a bit odd that G feels the need to
sound a battle cry against Cartesian discontinuity - a doctrine that would appear
to have been laid to rest in an earlier age (at least as far as ethology is
concerned). Indeed, Darwin's brilliant defender, T. H. Huxley, discusses this issue
at length using arguments from neurological continuity very similar to G's to affirm
continuity of consciousness (1874). To imagine a genetic saltation suddenly
resulting in a phenomenon as complex as consciousness (or human communica-
tion for that matter) appeared as nonsensical to Huxley as it does to the British
philosopher, Mary Midgley, who, in a recent work, points out that it requires us to
assume "a quite advanced point in animal evolution when parents who were
merely unconscious objects suddenly had a child which was a fully conscious
subject (1978, p. 217)." Indeed, it appears that ethologists do not deny the
continuity of subjective states per se, only that one can say anything specific
about them (cf. Eibl-Eibesfeldt, 1975). Thus, continuity does not seem to be the
question; rather it is whether such vague terms as cognition and consciousness
can be defined with sufficient explicitness to allow for the formulation of testable
hypotheses.
What one will find, I believe, is that such terms do not designate entities that an
organism either possesses in their entirety or not at all, but rather a mosaic of
structures, skills, and knowledge that, like human communication, does not
develop in children as a whole, does not disappear in cases of pathology as a
whole, and undoubtedly did not evolve as a whole. But what is consciousness? Is
it to be contrasted with unconsciousness or subconsciousness? Is it the same as
thinking, self-awareness, ability to learn, volition, perception of relationships, a
private world of mind? Each of these definientia yields different results in terms of
the continuity question. If self-awareness is chosen as a distinguishing character-
istic, perhaps only hominoids can be said to be conscious; if learning is chosen,
then even one-celled organisms would appear to evince consciousness. It is not
clear to me that terms like cognition and consciousness even define a coherent
network of functions in the way I assume a term such as communicative behavior
does (cf. Dingwall, in press). To postulate a neurophysiological basis for
consciousness in terms of neuronal cell number and degree of connectivity as
Rose (1976) has recently done is not based on any firm neurobiological evidence
[see also Puccetti & Dykes: "Sensory Cortex and the Mind-Brain Problem" BBS
1(3) 1978] and implies a scala naturae of consciousness with the primates at its
apex, which is already known to be unsupported in the case of some indices of
learning (Hodos, 1970).
At this point, I'm inclined to agree with the position of ethologists such as
Eibl-Eibesfeldt concerning the vagueness of these terms. It is not the case, one
should hasten to point out, that ethologists have shied away altogether from
postulating theoretical constructs, often in terms of hypothetical neural structures
(e.g., motor coordination center, releasing mechanism, etc.); indeed, as Konishi
(1971) has pointed out, many of these constructs have been shown to have
neurophysiological bases. It is the program of research which involves careful
observation of behavior, (either in the field or in the laboratory), isolation of critical
aspects of this behavior which can be provided with plausible neurological
correlates, followed by neurophysiological testing for such correlates - it is in
such a program (which might be termed: neuroethology) that I would place my
hopes for progress, rather than in a cognitive ethology, which may well reveal
itself a chimera. Incidentally, the use of animal surrogates in the investigation of
communicative behavior, which, in my view, is likely to be one of the most
productive of G's proposals, is clearly compatible with the program outlined
above.
No end of wonders [P&W]. Premack & Woodruff, who show themselves to be
well aware of the need for careful definition of terms as well as for the careful
evaluation of alternative explanations of experimental results, have provided a
fascinating demonstration of how much remains to be learned about the mental
states of chimpanzees (as well as of other animals). It will be most interesting to
discover the level of performance of other populations mentioned (viz., normal
and retarded children) on these same tasks. They may well prove to be
significantly lower than those of such a sophisticated subject as Sarah.
Rather than raising quibbles concerning details of the experiments reported, it
seems to me more important to address a theoretical point brought up at the very
beginning of the paper. Since neither associationism nor rule systems of the type
proposed by linguists have provided a viable theory of language, on what basis, I
wonder, do P&W assume that these will prove adequate for a theory of something
as poorly defined as mind?
In the beginning was the word. [SR&BJ. If P&W's contribution shows us how
much remains to be learned about the chimpanzee's concept of problem, then
the contribution by SR&B shows us how much remains to be learned about this
great ape's communicative capacities. The sophisticated analysis of the role of
function in word-learning and of levels of wordness constitutes a major contribu-
tion of this paper and provides interesting parallels with similar research involving
children. As in P&W's experiments, it would be interesting to have direct evidence
of normal children's performance in the tasks involved. The keyboard-off control
condition provides an important supplement to the work of Menzel [q.v.] on the
efficacy of the chimp's "natural" communicative behavior in transmitting informa-
tion.
It is perhaps important to note at this point that the gap between what is known
of the great apes' communicative behavior in the wild (which is very little as yet)
and the languagelike capacities demonstrated in the laboratory is often cited as
evidence for the discontinuity view. This involves a misunderstanding of evolution-
ary theory, for it is not the minimal abilities of an animal that are important in the
struggle for existence but rather their behavioral potential for dealing with new or
unusual situations.
There are a number of minor yet important statements made in the course of
SR&B's contribution which may be misleading. Let me mention three. (1) It is an
error to suggest that Myers (1976 op.cit. SRB) or anyone else who has
investigated the neurological bases of nonhuman primate nonverbal {sic) commu-
nication has failed to notice that the limbs are under volitional control and differ
significantly in this regard from the substrates of such communicative behaviors
as vocalization and certain emotion-linked facial expressions. (2) The statement
that the elements that make up the lexigrams of Yerkish are analogous to
phonemes should not lead one to believe that such a level of analysis in the
processing of Yerkish has been empirically demonstrated in either humans or
chimps, which is, as far as I know, not the case. (3) Finally, the link between tool
use and the emergence of language is tenuous at best; the only evidence cited by
SR&B in support of this view, namely, the putative constraints on apes' manipula-
tion of objects, is considerably weakened by the recent demonstration that an
orangutan is quite capable of making and using flaked stone tools (Wright,
1978).
REFERENCES
Dingwall, W. O. The evolution of human communication systems. In Whitak-
er, H. and Whitaker H. A. (eds.), Studies in neurolinguistics, vol 4. New
York: Academic Press, in press.
Eibl-Eibesfeldt, I. Ethology. New York: Holt, Rinehart and Winston, 1975.
Hodos, W. Evolutionary interpretation of neural and behavioral studies of liv-
570
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4

Commentary/Cognition and consciousness in nonhuman species
ing vertebrates. In Schmitt, F. O. (ed.), The neurosciences, second study
program. New York: The Rockefeller University Press, 1970.
Huxley, T. H. On the hypothesis that animals are automata. Fortnightly Re-
view, xvi:555-580, 1874.
Konishi, M. Ethology and neurobiology. American Scientist, 59:56-63, 1971.
Midgley, M. Beast and man: The roots of human nature. Ithaca: Cornell
Univ. Press, 1978.
Rose, S. The conscious brain. New York: Vintage Books, 1976.
Wright, R. Imitative learning of a flaked stone technology - The case of an
orangutan. In Washburn, S. and McCown, E. (eds.), Human evolution.
Menlo Park: Benjamin/Cummings, 1978.
by B. A. Farrell*
Corpus Christi College, Oxford
Some considerations in the philosophy of mind. Why the language of P&W
distresses me. I have a mixed response to the paper of P&W. I am very interested
in, and admire, the experimental work that the authors report; but I am distressed
by the language they use to do so. Because I am a philosopher, it is proper that I
should concentrate on their language. But this will have the unfortunate general
effect of overemphasising my disapproval, and greatly underemphasising my
approval, of their paper.
According to P&W, to say that an individual has "a theory of mind" is to say
that "the individual imputes mental states to himself and to others"; and to do this
is (apparently) to have and to exercise "a system of inferences." But P&W
themselves do not have a theory of mind in this sense; for it is not the case that
P&W must logically impute a state of mind to themselves, or to others, in order for
them to claim to know that they can and do think, can and do feel pain, and so
forth, and to know the same of their wives and others. I only impute a state of
mind to Smith when, for example, I accuse him of being jealous of my success; I
only infer a state of mind in another, when I do some detective work and conclude
that Nixon really does intend to make a comeback. And I certainly do not
generally impute states of mind to myself. On the contrary, I just take it for
granted, or just presuppose, or assume (P&W's word), or something of this sort,
that I can think, feel pain, and so on, and that others can do the same.
Now, do P&W want to claim that the chimpanzee really does do some
detective work in their experiments and can, therefore, be said correctly to impute
mental states to himself and to the humans involved? Or do they think of the
chimpanzee, not as a private eye, but as just taking it for granted that the animal
itself, and the humans involved, have certain mental states in the circumstances
described? Presumably, the latter, since this is the more lowly achievement. I will
now rewrite P&W accordingly.
We are told that the animal solves certain problems by just assuming that the
human actor wants the banana and is struggling to reach it, and by then making
use of this assumption to solve the problem. This is a mysterious claim and, as it
stands, not particularly helpful.
a. To assert that "the animal assumes that. . . ," is to ascribe a propositional
achievement and attitude to it. For this ascription to be true, it must also be true
that the animal has the ability to exercise concepts, such as "want" and
"struggling to reach," and actually exercises these concepts in the relevant
experiments. What evidence is there that the animal has this ability and manifests
it here? It is not clear to me that P&W vouchsafe the evidence to justify us in
asserting that the chimpanzee has this propositional achievement to its credit.
b. 
P&W seem to be unconcerned about this problem, for they appear to
argue that this and similar claims must be correct, since they embody the only
satisfactory way of explaining the animal's achievements in the experiments.
Now, if this were true, it would be very puzzling indeed. For then we would all be
logically committed to maintain that the chimpanzee has acquired certain
concepts, and related rules for correct application, without (apparently) learning
to do so by the aid of any public means of expression. That is to say, the animal
has acquired its own, quite private nexus of concepts. This is all rather
mysterious. Indeed, there are well-known considerations, stemming from Wittgen-
stein, that go to show that this claim is incoherent when made about humans. It
would be very unfortunate if comparative psychologists found themselves driven
into incoherence about animals.
c. 
But is the P&W claim (that animals assume that. . . ) the only way of
explaining the experimentally discovered facts? This is not a question that I as an
outsider, am in a position to answer. But I should be happier if P&W were to pay
more attention to other possibilities. For example, perhaps the animal is built to
react in appropriate ways to the patterns of input coming from the purposive
behaviour of other organisms like itself; and perhaps it solved the experimenter's
problems redintegratively with the aid of some experimentally acquired and
internally produced mediating cues or aids. I suspect that it may be helpful to look
upon the comparable achievements of the small child in a similar way. Then in the
course of its next few years, the child comes to acquire the relevant nexus of
concepts, and other abilities, which are necessary preconditions for the formation
of propositional attitudes about his own purposive behaviour, and that of others.
The chimpanzee, on the other hand, may or may not be able to get as far as the
child in these respects. But until we obtain evidence that it can do so, we are not
justified in asserting simpliciter that the animal assumes that the human actor has
purposes, it has purposes, and the like.
I suspect that P&W have been misled by our everyday ways of talking. These
ways seem to have restricted their scientific imagination into supposing that, if we
cannot talk about Sarah as psychologists have done in the past (for example, in
terms of association), then we are compelled'to speak in the way we ordinarily do
for everyday purposes. This does not seem to be true; the disjunction is not
exhaustive. What I hope P&W will do is to press on with their empirical studies of
the abilities of animals and combine these with theoretical work, which will help to
describe and explain the structure and functioning of these abilities.
Why the language of G pains me. G produces a case for the prosecution of
research in a certain field of animal life and activity. This is a very interesting and,
no doubt, important field, and I wish him and his colleagues every success.
However, I am forced to confess that I do not think G has presented his case as
satisfactorily as it might be done. For he seems to have described the field in a
confusing way, and he could be accused of overvaluing the relevance of some of
the experimental work he uses to support his case.
He tells us that he is concerned with "the mental experiences" of animals. Do
they have any comparable to our own? But what is "a mental experience," in
contrast with "a nonmental experience," or "a bodily experience," or just "an
experience?" His use of the expression "a mental experience" seems to be
pleonastic. What he wants to explore, presumably, are "the experiences" of
animals. If an animal can be shown to be aware of something, to think, to intend,
and the like, then on each and every occasion when it does think (etc.), it can be
said to have an experience.
Very well. But what has to be done to show that an animal is, for example,
aware of x, or has an intention to do k? G does not tell us clearly, if at all, what the
criteria are that have to be satisfied before we would be justified in claiming that,
for example, "That animal intends to do k." Nor does G appear to offer us any
stipulative criteria. This is a pity. In his book (Griffin, 1976 op. cit. G) he says that
"an intention involves mental images of future events." But, alas, this answer just
will not do.
i. 
Smith may have some mental imagery connected with an intention. But this
does not entail that he has some particular item, or items, in his mind's eye, as he
would have if he were an eidetiker projecting some particular picture onto a
background. So what we are saying of Smith here is the usual very vague story
that we produce when we speak ordinarily about imagery.
ii. 
More serious, for an act of Smith's to be intentional, it is not necessary that
it should be preceded or accompanied by imagery. He can perform an act
intentionally as part of a habitual routine, with his mind on other things.
iii. 
Nor is it sufficient merely to have some "picture" in the mind's eye. If this
"picture" is to fuction for me as an image of, for example, Nelson's Column, I
must also know that it is Nelson's Column I am imagining. I must be able to use the
image to represent the Column, and so on. Consequently, to say that Smith or a
chimpanzee has an image of Nelson's Column, or of some future act, is to say
that Smith or the animal can achieve propositional functioning and therefore can
enter into a range of propositional attitudes in respect of the column or the act. I
think G should, and would, accept this consequence. But I am uncertain that he is
aware of all this.
Elsewhere in his article G has a different suggestion to offer. Insofar as human
thinking is "closely linked to language," and "insofar as animal communication
shares (the) basic properties of language, the employment of versatile communi-
cations systems by animals becomes evidence" that they can think, can form
intentions, and so on.
In my judgment, this is a much better suggestion to pursue. The power to use
language and to communicate is, in an important way, a matter of degree; and
this implies that the power of animals to think (etc.) is also a matter of degree.
This suggestion coheres with G's own emphasis on the continuity between men
and animals. Moreover, it also enables him to sidestep completely the confusion
generated by our ordinary concepts of consciousness, awareness, and so forth,
and it allows him to get on with his job as an ethologist. If it turns out that the
animal's communication can only be explained by postulating a power to
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4
571

Commentary /Cognition and consciousness in nonhuman species
conceptualize sufficient for the achievement of propositions and propositional
attitudes, we can then use its communicative behavior as evidence of the sort of
internal world the animal possesses.
However, I suspect that the skeptical psychologist will hesitate to agree that the
experimental work to which G refers does oblige us to postulate propositional
powers. Of course, if we are required to describe the animals in Gallup's
experiment as G does, viz. that "they recognized the mirror image as a
representation of their own bodies," then we do seem to be committed to
postulating that the animals have the connected conceptual and propositional
powers. But why are we required to use G's description? Why should we not say
instead, for example, that an animal has learned to react to the mirror input by
treating it as a set of cues for reacting to the corresponding part of its own body?
This description - or something much better and more sophisticated along these
lines - does not commit us to ascribe conceptual and propositional powers to the
animal. This story, or some better story of this type, does seem to deserve
discussion.
I think it is important that workers in this field not succumb to a zoophilism that
drives them to upgrade their subjects, and to groom these, in fantasy, for
presentation at their mother's tea party, lika a latter day Eliza Doolittle. It is also
important that they should not denigrate the skeptics with the pejorative use of
labels (e.g. "behaviorist"). All such propaganda is apt to be counterproductive,
especially in Great Britain. An ounce of good theoretical and experimental work is
worth a ton of polemic and propaganda.
Is there balm in SR&B? Yes. As an outsider I find myself commending the
critical and relatively detached tone of this paper, and its attempt to elucidate the
concept of symbolic communication (and related notions) - an attempt that
exhibits some of the complexities involved. Even though the particular experimen-
tal findings that are reported may not be very surprising, it is such findings, surely,
that help to shape the future of knowledge. Res ipsa loquitur.
ACKNOWLEDGMENT
I am grateful to Dr. R. Passingham for his comments, but it must not be
assumed that he agrees with anything I have said.
EDITORIAL NOTE
"Received too late for a Response from G or SR&B. See Continuing Commen-
tary.
by Howard Gardner
Project Zero, Harvard University, Cambridge, Mass. 02138; and Veterans Adminis-
tration Hospital, Boston, Mass. 02130
A social synthesis. Hegel would take satisfaction in the course of discussions
about the powers of animals. As against the vitalist thesis that the full spectrum of
mental capacities can be found in the lowliest vertebrate, and the humanist's
antithetical horror at the prospect of a conscious ape, the recent spate of studies
on animal communication has inspired a much more reasonable and informed
synthesis. Most authorities now concur that infrahuman primates are capable of
significant cognitive and communicative activities but that the exact line of
demarcation between animal and human powers remains to be drawn.
Griffin. The three statements presented in this symposium can be organized in
terms of increasingly strong (and controversial) claims. With reference to G's call
for open-mindedness, there is little basis for quarrel; my eyebrows were arched
only by his suggestion that bees may well intentionally interrogate one another.
Savage-Rumbaugh, Rumbaugh, and Boy sen. The study by SR&B seems a
convincing demonstration that chimpanzees can cooperate with one another in
the pursuit of desired ends and that the possession of a symbol system can aid
significantly in this process. The fact that the Rumbaugh group is so hard on its
rivals in the simian semantic sweepstakes tempts one to apply equally critical
calipers to the work reported here: but I am not certain that would be appropriate
in view of the conservative claims about its significance.
Premack and Woodruff. As always, P&W's work is ambitious, bold, somewhat
programmatic, and somewhat problematic. The cleverness of the studies devised
should not deter us from invoking Occam's razor in their interpretation. In this
spirit I must voice reservations about certain theoretical distinctions (for example,
appreciation of an organism's motives as against appreciation of that organism's
knowledge). And I must also cavil about some interpretations. The fact that
primates may select photographs appropriate to the solution of a problem, and
assign different photographs to different agents, seems interpretable along at
least half a dozen dimensions, some of which may prove difficult to disentangle
from one another. Nonetheless, P&W's demonstrations continue to provide
fascinating insights about the unsuspected capacities of Sarah and her circle as
well as the forbidding difficulties entailed in assessing any organism's intellectual
capacities.
A Stock-taking. This provocative set of studies encourages some stocktaking
concerning the enterprise of primate intellection. Efforts to demonstrate that
primates are linguistic in the same sense as humans seem less prevalent
nowadays: parallels to human syntactic and phonological capacities seem less
than striking, and so authorities are properly focusing on the cognitive and
pragmatic aspects of primate communication systems. It is instructive to note that
each of these papers highlights a dimension which has hitherto been minimized:
the social aspects of communication. In a manner reminiscent of the Chicago
school of social knowledge (Baldwin, Cooley, Mead), researchers are focusing
on the capacities of animals to understand and adopt the role of conspecifics as
a royal road toward an emergent awareness (or consciousness) of themselves,
their minds, their "societies." And, indeed, it is in beholding "symboling" primates
as they aid one another in gathering food, or indicating which of a set of options
would aid a fellow organism in distress, that I feel an interspecies tie with them.
(Conversely, it is because I cannot - for whatever reason - empathize with the
waggle dance, and because I do not find interesting syntactic parallels between
Lana's performance and those of young children, that I am inclined to minimize
cross-species analogies in these areas.)
Just where we ultimately draw the line between human and infrahuman
capacities will depend, it seems to me, on the ease with which, and the extent to
which, other animals acquire the kinds of cognitive, linguistic, and symbolic
behaviors which human beings universally acquire. In this regard, the problems
faced by G, P&W, and SR&B in assessing the progress of their charges is not
fundamentally different from those confronted by my colleagues and myself as we
trace the development of symbolic competences in children. We are inclined to
credit children with "genuine" symbolic competence, consciousness, intention,
and other human virtues, when we find them engaged in generative or inventive
behaviors (for instance, using a symbol system in a comprehensible yet nonimita-
tive manner); capable of utilizing a range of symbolic vehicles (language,
picturing, gesturing, numbers) to express or refer to a given entity; able to adopt a
playful or experimental (as opposed to a rigid "preprogrammed") approach with
materials; inclined to reflect upon their own activities (or those of others), using
symbolic vehicles to make "meta" comments. Conversely, to the extent that
behaviors (1) appear only when elicited by strong training models, (2) recur in
virtually identical form over many occasions, (3) display little experimental
playfulness, (4) exhibit restricted coupling to a single symbolic system, or (5) fail
ever to be used to refer in "meta" fashion to one's own activities, we are inclined
to minimize their significance.
No organism will ever reach a level of total consciousness, full awareness, or
constant intentionality - these are emergent capacities in terms of which it
becomes, at best, increasingly acceptable to describe organisms as the latter,
come to exhibit more and more of the kinds of behaviors alluded to above. My
reading of the literature of animal communication to this point suggests that it is
the much longer period of immaturity in man, coupled with the proclivity to express
and understand himself via a much greater range of symbolic vehicles, which
brings about the principal differences between human beings and other higher
primates.
by James L. Goyld
Department of Biology, Princeton University, Princeton, N.J. 08540
Behavioral programming in honeybees [GJ. The source of the knowledge
behind an animal's behavior has always been a question of great interest.
Spalding (1873), for example, marveled at the seemingly prescient behavior of a
female wasp who would work tirelessly to "gather food . . . she never tasted" to
feed "larvae she would never see." The insights of three pioneering ethologists,
however, have removed much of the superficial mystery surrounding behavior. In
the early part of the century, Karl von Frisch (1967 op. cit. G) discovered that
each animal lives in a rich, species-specific sensory world to which evolution may
have denied us admission. Hence, bees can navigate by means of patterns of
polarized, ultraviolet light in the sky to which we are doubly blind. The subsequent
discovery of species-specific sensory-information processing emphasizes the
problem with reading our own limitations into the behavior of other species.
Later, Lorenz and Tinbergen (1938) discovered that seemingly intelligent
behavior may often result from the mindless workings of a machine. The most
remarkable example for me is the egg-rolling response of ground-nesting birds.
572
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4

Commontary/Cognition and consciousness in nonhuman species
The animal spots the orphan egg and rolls it back into the nest. One possible
interpretation of the behavior is that the bird knows what it is about, but a little
discreet tampering with the situation reveals that this is not the case. For
example, the bird will retrieve anything even vaguely round, beer cans and
volleyballs for instance, but recognizes them as inappropriate once they are in the
nest and discards them. More striking still, the object may be removed once the
bird has begun the retrieval, and the now-imaginary egg will be gently rolled back
into the nest nevertheless. The bird is simply a well-programmed machine, wired
to recognize one or more simple but normally diagnostic cues for "eggness" and
to execute a complicated motor program in response.
A host of ethologists, beginning with Lorenz, Tinbergen, and von Frisch,
discovered that learning may be programmed to occur only with the appropriate
combination of context, time, and cues, and can be used to build hard-wired
motor programs. For example, many birds learn how to sing, but can learn to sing
only their own species' song (Marler, 1970). The bird recognizes its own song
and ignores those of other species on the basis of certain diagnostic cues. During
a critical period in the life of the bird, the song is memorized. Months later, males
begin to practice until they learn to manipulate their vocal muscles in a way that
will produce a good copy. This motor program becomes fixed, so that an adult
male may be deafened without affecting his song.
The lesson from these discoveries is that complex and seemingly inexplicable
behavior may be the consequence of an animal's use of unexpected sensory
windows, elegant programming, or "instinctive learning." Most of animal behavior
may be explained in this way. We reject these explanations of much of human
behavior, though, in favor of the elitist notion that our special niche in the world is
one in which things are consciously reasoned out with brute intelligence. G raises
the ever-intriguing possibility that this strategy may not be confined to our
species - that the creatures which throng the stage of life around us may not all
be simply the elegant, microcomputer-equipped robots of classical ethology, and
that somewhere inside their brains may be an abstracted self-image, and an
ability to know what they are doing.
By its very nature, the knowledge of what is going on in a mind is private. The
three lessons of ethology mentioned above caution us that mere complexity is not
itself a reliable clue. The novelty of G's approach is that is suggests two general
categories of tests for self-awareness. One sort looks at what animals do when
presented with problems which evolution could not have anticipated, so that any
intelligent output from the animals must represent its own analysis of the problem
rather than evolution's. The other method is to engage in a dialogue of sorts with
the species in question, and to look for telltale signs for a disembodied
consciousness on the part of the other party. The judgements in either case are
largely intuitive, but so they often are at the leading edge of science (Kuhn,
1962).
G concentrates on two groups of animals in his arguments: the higher primates,
and the honeybees, each the intellectual apex in their respective phyla. The
evidence he cites in the first case is already intuitively satisfying, but it is difficult to
imagine consciousness being even possible in bees. Nevertheless, in all fairness I
must admit that there are aspects of bee behavior which, in our present state of
knowledge, lend themselves to the consciousness hypothesis at least as well as
to the robot theory (reviewed in Gould, 1975, pp. 187-194). For example, during
training with respect to an artifical food source, there comes a point at which bees
begin to "catch on" that the experimenter is systematically moving the food
further and further away, and Frisch (1967 op. cit. G, p. 17) recalls instances in
which the trained foragers began to anticipate subsequent moves and to wait for
the feeder at the presumptive new location. It is not easy for me to imagine a
natural analogue of this situation for which evolution could conceivably have
programmed the bees.
Another example revolves around honeybees' hatred of alfalfa. These flowers
possess spring-loaded anthers which give honeybees a rough blow when
entered. Although bumble bees, who evolved to pollinate alfalfa, do not seem to
mind, honeybees, once so treated, avoid alfalfa religiously (Lovell, 1963). Placed
in the middle of a field of alfalfa, foraging bees will simply fly tremendous
distances to find alternate food sources. Modern agricultural practices and the
finite though surprisingly long flight range of honeybees, however, often bring the
bees to a grim choice between foraging alfalfa or starving.
In the face of certain starvation, honeybees are said finally to begin foraging
alfalfa, but they rapidly learn to avoid being clubbed. Some bees come to
recognize tripped from untripped flowers, and frequent only the former, while
others learn to chew a hole in the back of the flower and to rob untripped
blossoms without ever venturing inside (Reinhardt, 1952; Pankiw, 1967). What
has analyzed and solved this problem: evolution, or the bees themselves?
I find G's suggestions for language-related experiments too technically chal-
lenging to be practicable, but I have another experiment to propose. In his
charming book Rationality, Bennett (1964 op. cit. G) develops logical criteria for
real, self-conscious rationality. He uses bees as the counter example, though by
the time he wrote the book they had been found to do most of the things he says
they cannot (reviewed in Gould, 1975, pp. 187-194). His arguments lead him to
propose as the unique characteristic of rationality what he calls an "R-denial":
denying the truth of a statement because, logically, it cannot be true - that is, the
ability to recognize an abstract lie as a lie. Now bees do not normally lie - in view
of their close genetic relationship to one another and their common goal of
sustaining the hive and its queen, it would be maladaptive to do so. Under special
circumstances (Gould, 1976), however, foragers may be made unwittingly to lie
about the direction of a food source. Bees learn the topography around the hive
before beginning to forage. If a colony were placed next to a lake and forager
dances made to indicate a familiar food source out in the middle of it, would
experienced recruits be fooled into leaving the hive, or, having left, would they
search seriously in the lake? If they did, would a subsequent set of dances to
another food odor that was apparently still in the lake again elicit a machinelike
response? Since throughout evolution foragers have never lied, it seems unlikely
that the bee's on-board computer could have been programmed for this
eventuality.
My own combination of biases and intuition leads me to doubt that bees know
what they are doing. If the examples mentioned above can be taken at face value,
however, I must suppose that evolution is capable of such subtle feats of
intellectual engineering to deal with unpredictable situations that it is difficult or
impossible at present to distinguish the programming of a 1-mg bee brain from
some sort of insect free will. If this is the case, how, I wonder, can we talk so
confidently about any qualitatively different sources of human behavior?
REFERENCES
Gould, J. L. Thesis. New York: Rockefeller Univ., 1975.
Honey bee recruitment. Science 189:685-693, 1976.
Kuhn, T. S. The structure of scientific revolutions. Chicago: Univ. of Chicago
Press, 1962.
Lorenz, K. Z. and Tinbergen, N. Taxis and Instinkthandlung in der Eirollbe-
wegung der Graugans. Zeitschrift fur Tierpsychologie. 2:328-342, 1938.
Lovell, H. B. Sources of nectar and pollen. In Grout, R. A. (ed.) Hive and
honey bee, pp. 191-206. Hamilton, 111.: Dadant, 1963.
Marler, P. Song development in white-crowned sparrows. Journal of Compar-
ative and Physiological Psychology. 71:1-25, 1970.
Pankiw, P. Studies of honey bees on alfalfa flowers. Journal of Apicultural Re-
search. 6:105-112, 1967.
Reinhardt, J. F. Responses of honey bees to alfalfa flowers. American Natural-
ist. 86:257-275, 1952.
Spalding, D. A. Instinct. MacMillans Magazine. 27:282-293, 1873.
by Patricia M. Greenfield
Department of Psychology, University of California, Los Angeles, Calif. 90024
Developmental processes in the language learning of child and chimp
[SR&BJ. I shall be approaching this commentary primarily from the point of view of
a developmental psychologist, comparing the linguistically mediated tool use and
exchange by chimpanzees described by SR&B with comparable developments in
human children.
An interesting contrast with children is the apparently greater difficulty for
chimps of simply labeling an object in comparison with naming the same object
when it is needed as a tool. Indeed, my research has indicated that the linguistic
encoding of an instrument or tool is extremely rare in the one-word stage of
children, and its first appearance is months after the first appearance of a simple
label (Greenfield and Smith, 1976 op. cit. SR&B). Our study of the development of
linguistic functions in two children in the one-word stage also found that the
earliest labels precede the earliest instances of naming something in a request
context.
All of this would seem to indicate that the difficulty of the two sorts of semantic
function is reversed in children and chimps, with chimps (1) more easily learning
to use language to request than to name and (2) showing more interest in tools
than children do. The first contrast is the more interesting, for it suggests that a
primary difference between chimps and people is the chimps' difficulty with
symbolization per se - forming arbitrary relations between signifier and signified,
making one thing arbitrarily stand for another. For the chimps, there seems a
relatively long period in which they learn more easily when the word to be
acquired is embedded in or part of an action context. The behavior of the more
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4
573

Commentary/'Cognition and consciousness in nonhuman species
language-experienced Lana does indicate, however, that awareness of arbitrary
symbols eventually develops even in chimps, for Lana was immediately able to
transfer her tool words from the request to the labeling context without further
training.
As SR&B point out, the stage of action-embedding parallels our description of
the pure performative stage in child language. In pure performatives, sounds are
part of action contexts; sound pattern and referent are not clearly separable. The
arbitrary connection between sign and referent does not yet exist. The parallel
should not be stretched too far, however; the chimps' requests for tools involve
using a word to trigger an action of another person in a specific situation. The
chimp's early tool vocabulary is less tied to the animal's own action than the
child's pure performative (e.g., saying "bye-bye" while waving). The chimp's
vocabulary does appear, however, to be more tied than the child's to the total
context in which a new word is introduced. Children seem to have a greater
tendency to abstract a part of the context in which a word is introduced. They
then use this abstraction as the basis for further uses of that word, correct or
incorrect. But there may be an earlier stage in which human children do not
abstract either; Piaget (1951) describes the earliest word uses of his children as
totally tied to one particular context.
There are, however, a couple of other possible explanations for the chimps'
difficulty with labels. From the procedural information presented, it seems as
though the chimps had to produce labels in response to a question like "What's
this?" (or some other verbally presented request for a name). In the original
tool-request situation, in contrast, the chimps were to name the tool in response
to a nonverbal situation: seeing a hiding place baited with food. In our study, we
found that a child's spontaneous use of a given semantic function in one-word
form occurred first in response to a nonverbal context, only later in response to a
verbal one. For example, the children in our study could spontaneously label
entities before they could use the same words to answer the question "What's
this?" If this same progression exists in chimps, it could also explain why labels
were so difficult for them to learn under the conditions of this study.
Another possible explanation of the chimps' difficulty in learning object labels
lies in the role of extrinsic versus intrinsic reinforcement in language learning. In
the label-training procedure the chimp was asked to name an object and
rewarded with praise or food if correct - an extrinsic reinforcement condition. In
the tool-request situation, in contrast, the chimp was given the tool he had named
(even if it was the wrong tool for the situation); here, the consequences had an
intrinsic relation to the chimp's language behavior. In the naturally occurring
language acquisition process of children, extrinsic reinforcement seems to play
almost no role at all (e.g., Brown, 1973). At the same time, students of child
language have pointed to the potential importance of intrinsic feedback that gives
the child information about what he has been taken to mean (Ryan, 1974). This
type of intrinsic feedback is provided in the tool-requesting situation, where the
chimp is given a tool corresponding to the name he produces on the computer
keyboard. In the object-labeling situation, in contrast, he could be given food as a
reinforcer, no matter what object name was produced. If this extrinsic reinforce-
ment was interpreted by the chimp as intrinsic, the procedure could actually be
confusing. The chimp might conclude that the referent of blanket, one of the
labels in the study, was the food reinforcer. Finally, after-the-fact reinforcement
for correct symbol selection in the label-learning procedure seems to have
replaced an initial stage in which symbol and referent are systematically paired.
Such a stage existed in the tool-request procedures, but not in the object-labeling
one.
Each of these different explanations for the greater ease of learning and using
vocabulary in the tool-request procedure would have different implications for the
language acquisition process in chimps and its comparison with its human
analogue. But more information from the authors about the object learning
procedure is needed before it is possible to rule out any particular explanation.
A parallel between chimps and children appears in the concepts implicit in their
errors of word use during the acquisition of particular lexical items. Thus, SR&B
report a confusion between words denoting members of the tool category (e.g.,
between key and stick), but not between tool names and food names. This
pattern indicates the functional category "tool" as the basis for the lexical
confusion. Similarly, Braunwald (in press) reports examples where her own child
spontaneously extends tool names to other tools that fulfill a similar function (e.g.,
broo for broom is extended to refer also to dust mops). Function is certainly not
the only basis of children's lexical extensions and, in fact, it is often difficult to
separate function and form (as in the broom/dust mop examples). What is clear,
however, is that the surface behavior of child and chimp is not very different in
some cases of lexical extension.
Perhaps the most striking parallel between child and chimp is the necessity for
a prelinguistic sensorimotor understanding of various forms of action and
communication for the symbolic encoding of actions and desires to take place.
Evidence on this point continues to accumulate for children. For example, using
the child's response to offers in order to study the transition from sensorimotor to
linguistic communication, we found that offers (of an object or an activity) were
initially made by the mother on the sensorimotor level alone, then simultaneously
on both the linguistic and sensorimotor levels, and finally on the linguistic level
alone (Zukow, Reilly, and Greenfield, in press). Correlatively, at the early stages,
children would generally not respond to offers unless all the sensorimotor
elements were present (e.g., the mother says "Do you want a cookie?" while
holding out the cookie to the child). Response to a linguistic offer depended on
having the sensorimotor information simultaneously available. Recently Bruner
(personal communication) has found the same pattern of development from
sensorimotor to linguistic for the child's expression of requests to the mother. In
the interanimal communication experiment reported here, the animal differs from
the human child in not having prior experience in which a second chimp fulfills his
requests. Hence, it was necessary for the human experimenter to direct one
chimp's attention to the other chimp, in order to get the chimp to address his
request to another animal. Here the experimenter acted like the mothers in our
study, using attention-getting devices to transform initially unsuccessful communi-
cations into successful ones.
These parallels and divergences between the developmental processes of
child and chimp are important in establishing the full nature of linguistic communi-
cation and in identifying what is uniquely human therein. Knowledge of parallels is
also important in preventing premature conclusions about chimpanzee language-
learning limitations. When many of the chimp's limitations of today turn out to have
been analogous to early stages in the child's acquisition process, we should not
be surprised when tomorrow the chimp follows the child in taking the next step on
the road to mature linguistic communication.
REFERENCES
Braunwald, S. R. Context, word and meaning: Toward a communicational
analysis of lexical acquisition. In Lock, A. (ed.), Action, gesture and sym-
bol: The emergence of language. London: Academic Press, in press.
Brown, R. A first language: The early stages. Cambridge, Mass.: Harvard
Univ. Press, 1973.
Piaget, J. Play, dreams, and imitation in childhood. New York: Norton, 1951.
(Original French publication, 1945.)
Ryan, J. Early language development: Towards a communication analysis. In
Richards, P. M. (ed.), The integration of a child into a social world, pp.
185-214. London: Cambridge Univ. Press, 1974.
Zukow, P. G., Reilly, J., and Greenfield, P. M. Making the absent present: Fa-
cilitating the transition from sensorimotor to linguistic communication. In
Nelson, K. (ed.), Children's language, vol. 2. New York: Gardner Press, in
press.
by Harjoiie Grene
Department of Philosophy, University of California, Davis, Calif. 95616
Basic concepts for cognitive ethology. Ethology, as Griffin (1976 op. cit. G,
SR&B) has argued, was founded under the aegis of behaviorism. But behaviorism
was Cartesian dualism with its mental sector atrophied. Now that experimental
psychologists, as well as some philosophers, have undertaken investigations that
bypass the Cartesian dichotomy and analyze the cognitive powers of animals,
including ourselves, without that embarrassing impediment to understanding, the
need to articulate adequate concepts to guide such work brings the interests of
philosophers into convergence with those of experimentalists.
1. The conversations of Sherman and Austin [SR&B]. Work of the kind
reported by SR&B represents not only "a large step" for their experimental
animals, but for human theorists as well. Concepts like "intentionality," "proposi-
tionality" (from Steklis and Hamad, 1976 op. cit. SR&B, p. 451), "comprehen-
sion," and "symbolic representational capacity" should indeed become pivotal to
the study of cognition. The context in which they are used and the development of
experimental design under their guidance illustrate, for this commentator, the
fruitful interaction of theory and experiment that a fresh perspective in science
can encourage, and offer, at long last, support for the biologically biased
epistemologist in the study of animal cognitive behavior. For a philosophical
account of intentionality that parallels SR&B's usage, see, for example, F<6llesdal
(1969) and Searle (1979).
"Awareness" seems to me rather more difficult. Granted, one no longer wants
to deny awareness to other animals, any more than to human beings. Granted
574
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4

Commentary/Cognition and consciousness in nonhuman species
also, "awareness," being vaguer than "consciousness" or "subjectivity," smells
less than do the latter terms of the ghost of the ghost in the machine (Ryle, 1949
op. cit. G), and therefore also less of the ghost of the machine itself. The reasons
why it seems to me a questionable concept, at least in some contexts, will be
mentioned in my comments on G below. In connection with SR&B, I would only
add that their excellent survey of previous work confirms the hunch that both the
"objective" and "subjective" halves of the Cartesian duality have haunted
previous studies of apes' use of language. Signing could be studied "objectively"
and then there was something "subjective" left over that could only be hinted at.
To study "symbolic representational capacity" as distinct from signing, on the
other hand, is to move from the behavioral, not io the mental in some "privileged
access" sense, but to a complex context of the kind referred to by SR&B in their
conclusion (see Holloway, 1969 op. cit. SR&B). An attempt to show how human
intelligence is grounded in a complex network of animal competences was made
many years ago by Polanyi (1958). It may be that his long-neglected work will
prove to have some bearing on future research in animal and human cognition.
2. What Sarah knows [P&W]. Given the post-Cartesian position that I welcome
in respect to SR&B, I have obviously no overall comments on P&W. For the sake
of my commentary on G, I want chiefly to take both SR&B and P&W as examples
of work in cognitive ethology already in progress. Nevertheless, a few points,
chiefly terminological, may be worth making. First, although I know it is habitual
with linguists to use "theory" as liberally as P&W do, I cannot help finding this
usage strange. Not being a linguist, I don't "have" a theory of English. Being a
competent user of language is not being a theorist of language. Nor is
understanding "minding" identical with having a theory of mind. Although Sarah
may well be a genius among chimpanzees, she is no more a learning theorist than
I am. Or are what philosophers of science call theories in fact metatheories?
There is too much slippage of logical levels here for philosophical comfort.
The same sort of (admittedly purely terminological) uneasiness overcomes me
in the face of P&W's "three interpretations." "Physical matching," "association,"
"theory of mind," and "empathy" would count as three ( + ) methods by which
Sarah might be held to solve her problems. To "association/sm" would have to be
matched three other theories (or metatheories?) of animal problem-solving
embraced by psychologists.
One, more substantive, question: the bracketing of positivists with young
children as "parties that would hold a noninferential view" is both charming and
instructive. But does the analogy with causality really hold? Causality identified
with constant conjunction, whether or not it is narrowed to necessary and
sufficient conditions, seems to some thinkers an "unnatural" empiricist contri-
vance. I would like to ask developmental psychologists whether childish thinking
really is of the constant conjunction kind, and to suggest to P&W that even "filling
in all four cells in the contingency table" does not in itself produce a causal
explanation. (See Grene, 1974, pp. 1-12; Scheibe, 1970; Cartwright, MS.)
It is to be hoped that P&W will comment on SR&B's criticism of the experimen-
tal design of Premack (1976 op. cit. G).
3. Mental images, plans, and the life of the hive [G]. The difficulties I find in G's
presentation are twofold.
First, while both SR&B and P&W present work in progress in cognitive ethology
designed in the light of appropriate regulative concepts, G, like the earlier workers
discussed by SR&B, seems to consider the program for this discipline from a
perspective still haunted by Cartesian thought and the empiricist approach
descended from it. G is interested especially in "mental images," or "representa-
tions" in the sense of copies of external objects (as against Sarah's presumptive
"symbolic representational capacity"). These, he asserts, are "particularly
important components in mental experience." Space does not permit me here to
marshal evidence against this thesis; I can only assert, with respect, that as a
generalization it is patently false. Imaging is a relatively minor and uninteresting
aspect of mental life. In addition, G mentions "intentions," evidently in the sense
of plans. Maybe. That there is "purposive" behavior in other species no
reasonable person ought to deny. But the most promising novel subject matter for
cognitive ethology is intentionality as SR&B and P&W use the term, not intentions
in the sense of plans. Rather than taking refuge in "internal images" to escape
behaviorism (a still Cartesian device), it would be more fruitful, in my view, to rely
on concepts like those employed by SR&B and P&W (as well as by many
philosophers) and escape altogether the old alternative of outer-public-
nonmental and inner-private-mental. (Hence my uneasiness about SRB's use of
"awareness.") It is of course true, as G points out, that mind is not (yet) definable
as exactly as a chemical compound is. Nevertheless, there are approaches to the
study of mind, neither behavioristic nor subjectivistic, which can guide research in
this area â as, once more, SR&B and P&W demonstrate.
Such approaches, moreover, would support the notion of a causal relation
between the development of mind and the degree of organization of the nervous
system. This is where my second difficulty arises. For G both explicitly asserts
and, at least implicitly, denies this kind of relation. At least he seems to deny that
the difference in the brains of a primate and an insect makes any important
difference to their mental powers. Is it because bees are small, or such distant kin
to us, he asks, that we deny them "intentions"? Of course not; first and foremost,
it's because of the organization of the arthropod nervous system as compared
with that of primates. G himself has told us that it is "parsimonious to assume that
mental experiences are as similar from species to species as are the neuro-
physiological processes with which they are held to be identical." And as
different! Even if the firing of a single neuron is indistinguishable in bee and
chimpanzee and man, the organization of the nervous system is very different
indeed in the first case from the other two, and somewhat different in the second
and third.
In looking for formulations to take account of such differences, I had thought
that A.J.P. Kenny's definition of mind, quoted by G, was a good candidate
(Grene, 1976, 1978). It seemed to me a radically non-Cartesian statement that
applied to the kind of mental life apparently correlated with especially highly
organized nervous systems, with the full development of the organisms possess-
ing them dependent on the use of artifactual symbol systems of the kind most
strikingly characteristic of human natural languages. Clearly, however, I was
mistaken. That G can apply this definition so readily to apian communication must
rest, I admit, in part on the inadequacy of the definition itself. The "symbols" in the
case are not meant to be just signings (see SR&B) and the "activity" is to be
understood (a) in terms of competence, not performance, and (b) in intrinsic
relation to the achievement of the power of responsible choice. In trying to refine
Kenny's statement appropriately, it will be useful to consider such work as that
reported in SR&B and P&W. As SR&B suggest, it is probable that more can
usefully be said not only about the likenesses, but also about the differences
between symbol use in chimpanzees and children. In any event, it seems to me
essential for the careful development of a cognitive ethology in general that the
massive differences in neuroanatomy, proportion of learning to "wired-in"
behavior patterns, and so on, between primates and arthropods be kept in mind
(cf. table in Popper and Eccles, 1977 op. cit. G, p. 58). G's insistence on
overlooking such differences appears on the whole to weaken, rather than to
reinforce, the foundations for the comparative cognitive ethology he wishes to
support.
REFERENCES
Cartwright, N. Causal laws and effective strategies. Unpublished manuscript.
F^llesdal, D. Husserl's notion of noema. Journal of Philosophy 66:680-687,
1969.
Grene, M. The understanding of nature. Dordrecht: Reidel, 1974.
To have a mind 
Journal of Medicine and Philosophy 1:177-199, 1976.
Sociobiology and the human mind. In M. S. Gregory, A. Silvers & D. Sutch
(Eds.) Sociohiology and human nature. San Francisco: Jossey-Bass, 1978.
Polanyi, M. Personal knowledge. Chicago: Univ. of Chicago Press, 1958.
Scheibe, E. Ursache und Erklarung. In Kriiger, L. (ed.), Erkenntnisprobleme
der Naturwissenschaften. Cologne: Kiepenheuer and Witsch, 1970.
Searle, J. R. What is an intentional state? Mind, forthcoming, 1979.
by Colin P- Groves
Department of Prehistory and Anthropology, Australian National University, Canber-
ra, A.C.T. 2600, Australia
What does it mean to be conscious? The proof of the pudding [SR&B]. The
meaning of the symbol use experiments with apes has been endlessly discussed;
the experimenters themselves - the Gardners, the Rumbaughs, Premack,
Patterson - tend to regard the behavior as truly linguistic, while their detractors -
Bronowski and Bellugi, Sebeok {op. cit. by SR&B and G) - find fault in the
experiments themselves or in their interpretation. Sebeok even proposes that the
experimenters have fallen victim to the "Clever Hans" fallacy, an interpretation
which I have little hesitation in rejecting. More perceptive critics accept, by
implication if not quite openly, an evolutionary continuum from "not-language" to
"language," but erect barriers across the road at some point, on one side of
which is language and on the other side mere brute intellect; this type of response
is reminiscent of the misapplied ingenuity that went on in the 1960s to define
"man," when tool-use, tool-making, tools-to-make-tools, and so on fell in rapid
succession to the onslaughts of chimpanzees, yet the lesson still was not learnt
that where there is an evolutionary continuum any threshold or barrier set up is
bound to be artificial. Instead of trying to fix a gulf between "man" and "animal,"
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4
575

Commentary/Cognition and consciousness in nonhuman species
it is surely much more useful to ask just how much further along the track of
hominization a given ape would theoretically have to travel; or indeed, since living
apes are not merely proto-humans, what aspects of a chimpanzee's or a gorilla's
psychological capabilities are peculiar to that species and are not along the track
of hominization.
Nonetheless, some of the first experimenters, in their understandable enthu-
siasm, may well have overstated their case, and left howling gaps into which the
perspicacious human chauvinist can insert a crowbar (or, let us say, a monkey
wrench). It is to SR&B's credit that they review previous work and pick out some
of these gaps. From the standpoint of their own criticism, the experiment they
report comes through unscathed. I think it answers all potential criticisms: have
the chimpanzees internalized their symbol use system? Will they still use it when
no experimenter is present? Will they use it to each other?
The subplot of SR&B's experiment, which the authors do not stress but which is
surely almost as remarkable in its implications, is the food-sharing. The two
chimpanzees were not mates, nor were they brothers: no question of Inclusive
Fitness. They did not have anything tangible to gain from sharing the food: the
sorts of factors that seem to operate in the meat-sharing in the wild - such,
presumably, as dominance, hunting partnerships, oestrous females - are quite
inoperative in the laboratory. Though speculation about the relationships between
the two chimpanzees outside working hours would be possible, the most
parsimonious explanation is simply "Thanks for your help."
The biter bit[P&WJ. This paper is less satisfactory than SR&B's, because of its
incompleteness. SR&B describe in foolproof detail a single experimental series,
and follow it up with a satisfying theoretical discussion; P&W pass in review a
whole gamut of experiments, clearly the product of someone's fertile and
enterprising imagination - but in only one case is there anything that can be called
a result, and most of the experiments have not even been performed yet! It is
disappointing to read of experimental set-ups with most exciting potential, only to
read on and discover that it is all in the future.
The one experiment that has some claim to completeness, that of the
chimpanzee finding the solution to her handler's problem, is very cursorily
described. How, for example, did she understand what she was to do when the
film was stopped? The argument that she had a "theory of mind" seems a little
tenuous. Certainly simple association is not, on the description offered, altogether
excluded as an explanation; nor even, in this case, is "Clever Hans." I am bound
to say, though, that the disasters in which she placed the handler she dislikes add
a great deal to the conviction of the experiment, and do make the reader turn to a
"tit-for-tat" explanation. Revenge is sweet, after all: or are we anthropomorphis-
ing too much? And does a chmipanzee, despite many a theologian's categorical
assertion, know right from wrong?
Does the noosphere inevitably reflect [G]? I would like to make my feelings
quite clear: I think, with G, that self-awareness, or consciousness, is one of those
attributes which has up to now been far too glibly put down as a human
species-specific characteristic (see, for example, Teilhard de Chardin, 1959),
simply because it has not been sought in other species (also, of course, because
of that human chauvinism which has for so long been permitted to retard
interpretations of nonhuman psychology). On evolutionary grounds, I would
expect it to exist, in however rudimentary a form, in very many nonhuman species.
Yet I am not satisfied that G's article - or even his book The Question of Animal
Awareness (1976 op. cit. G, SR&B) - has really attacked the problem more than
superficially. The review of his book by Humphrey (1977 op. cit. G) is on target
here; and Humphrey also asks whether, and in what sense, it might matter
whether a given species is self-conscious or not: a point to which I will return
later.
The obvious question to ask, which G has hardly touched, is "What would
actually be evidence for awareness in animals?"; and this in turn demands that
we define awareness very closely - no easy task, for it is one of those concepts
that recedes as we examine it. If awareness means simply an image of self, an
ability to imagine one's self, then are not dogs self-aware in their dreams, as they
whine and bark and - if we are to follow the popular interpretation - chase
imaginary rabbits? Such an explanation springs to mind, but I would not accept
dreaming in dogs as evidence of awareness by any means. More acceptable are
the mirror-reaction experiments with apes, as discussed by Slobodkin (1977):
adjusting one's appearance in a mirror implies the existence of fantasies about
oneself, and indeed recognizing that a mirror image is oneself seems sufficient to
indicate awareness of one's own existence.
In a U.S. Primate Center, Dr. Peter Reynolds (personal communication)
observed a juvenile gorilla playing by itself, eyes tight shut, making a play-face.
This seems to me a very thought-provoking observation. To whom was the
play-face directed? To an imaginary playmate? To itself? Either way, a self-image
does seem to be a necessary part of the explanation. Another example might be
found in the nature of orangutan food-finding behaviour, which virtually requires
the ape to have a conscious mental map of its home range (Rijksen, 1978). I
suggest that experiments could be designed in which the solutions would depend
on the animal's capacity to imagine itself; I am not sure that even the SR&B and
P&W experiments fulfil this requirement.
The subject of self-awareness, of course, lends itself to loose thinking, and it is
hardly surprising that even the discoverer of echolocation in bats can lose his way
in the utter darkness surrounding the topic. Culture is an associated concept;
strikingly, the very first attempt to give a formal definition of culture in terms of the
behaviour it involves (rather than of the species it is supposed to characterize)
dates from June 1978! (McGrew & Tutin, 1978); and it would be simply too facile
to link the two by saying that culture depends on awareness, or indeed
vice-versa. It could be argued that innovation, the first step in cultural develop-
ment according to McGrew & Tutin, demands awareness, but I am sure that even
this step could be quite unconscious. One of the major adaptive functions of
culture, as Humphrey (1976) makes clear, is to extend the range of activities that
can be performed with least effort, either physical or mental.
It may be true, as G suggests, that it is the cavalier rejection of the possibility of
a self-awareness in nonhumans that has cleared the way for physical abuses of
them; yet remember that the very rationale for biomedical research is that
nonhumans do work in the same way as humans, that there is evolutionary
continuity. The nineteenth-century dog-vivisectors, even the unspeakable Claude
Bernard, were in complete agreement with today's primate "users" over this. I
think the explanation lies not in their rejection of the concept of awareness - is
pain any the more terrible if one knows that one is in pain? - but in making a
decision that they will not follow through the logical implications of their basic
premises. The point is, as Jeremy Bentham put it, "not, can they reason? nor, can
they talk? but, can they suffer?" That is a much simpler question to answer, and
(contra Griffin, if I understand him right) is the only question that can possibly be
relevant for a human being in deciding how to interact with members of other
species.
REFERENCES
Humphrey, N. K. The social function of intellect. In Bateson, P. and Hinde,
R. A. (eds.), Growing points in ethology. Cambridge: Cambridge Univ.
Pr. 1976.
McGrew, W. C, and Tutin, C. E. G. Evidence for a social custom in wild
chimpanzees? Man 13:234-251, 1978.
Rijksen, H. D. A field study on Sumatran Orang Utans. Wageningen: Veen-
man & Zonen, 1978
Slobodkin, L. B. Evolution is no help. World Archaeology 8:332-343, 1977.
Teilhard de Chardin, P. The phenomenon of man. New York: Harper-Row,
1959.
by Gilbert Harman
Department of Philosophy, Princeton University, Princeton, N.J. 08540
Studying the chimpanzee's theory of mind. Purpose and knowledge [P&W].
P&W say, "Not even the chimpanzee will fail tests that require him to impute
wants, purposes, or affective attitudes to another individual, but he may fail when
required to impute states of knowledge." This cannot be right. Purpose and
knowledge are interrelated concepts. A chimpanzee can have a conception of
desire or purpose or goal only if it also has a conception of knowledge or belief.
The concept of a desire or goal or purpose is the concept of an attitude toward
something that can lead a creature with that attitude to do what it knows or thinks
will promote the existence of that thing.
P&W say what they say because they take a chimpanzee to have a conception
of knowledge only if it distinguishes know from guess or realizes that adults have
more knowledge than children. But distinguishing knowing from not knowing
would be enough - for example, the chimpanzee does not expect a second
chimpanzee to approach some partially hidden bananas until the second chim-
panzee has caught sight of them.
Furthermore, a chimpanzee might distinguish know from guess or merely
believe without satisfying the strong condition P&W propose, namely that the
chimpanzee should be able to distinguish knowledge from correct guess or true
belief. I have had students at Princeton University who distinguish knowing from
merely believing but have trouble distinguishing knowledge from true belief or
correct guess. There is no reason to require more of a chimpanzee than of an
adult human being. Suppose that a subject chimpanzee sees a second chimpan-
zee watch a banana being placed into one of two opaque pots. The second
576
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4

Commentary/Cognition and consciousness in nonhuman species
chimpanzee is then distracted while the banana is removed from the first pot and
placed in the second. If the subject chimpanzee expects the second chimpanzee
to reach into the pot which originally contained the banana, that would seem to
show that it has a conception of mere belief.
Expectation and discrimination fP&WJ. Now it is important that, as P&W stress,
a chimpanzee's theory of mind, if any, will be manifested in its predictions or
expectations about others. Expectations or predictions are not just discrimina-
tions that the chimpanzee makes. A chimpanzee might discriminate between X's
being followed by Y and X's being followed by Z without expecting an actual X to
be followed by Y (or by Z). The fact that the chimpanzee makes certain
distinctions, no matter how complex, does not show that it has the relevant
expectations and so does not show that it has a theory of mind. P&W's
experiments using videotapes and photographs test a chimpanzee's ability to
make certain distinctions but do not clearly test what it expects to happen, so it is
not clear what such experiments can show about a chimpanzee's theory of mind.
A chimpanzee manifests its expectations by relying on them in its own
purposive behavior. It manifests its expectations about what another chimpanzee
will do if in obtaining its goals it relies on the other chimpanzee to do the thing in
question. The cooperative behavior described by SR&B may be a good example.
Manifesting or acquiring a theory of mind [SR&BJ? SR&B report that "Prior to
the training that promoted learning of tool function and cooperative sharing of the
obtained foods, mutual requests for aid were not observed between the ani-
mals. . . . Now they regularly employ prelinguistic gestures of this sort in their
interactions with one another." This should remind us that in asking "Does the
chimpanzee have a theory of mind?" we might mean either "Does the chimpan-
zee in nature have a theory of mind?" or "Can the chimpanzee acquire a theory
of mind, for example by learning cooperative sharing, and so forth?" We must
allow for the possibility that these questions receive different answers. Our
studying a chimpanzee's theory of mind might be what leads the chimpanzee to
develop such a theory.
by D. 0= Hebb
Department of Psychology, Dalhousie University, Halifax, Nova Scotia, Canada
B3H4J1
Behavioral evidence of thought and consciousness [Gj. There is no need of
dissent from G's conclusion that animals (or some animals) are conscious and
have representational processes and intentions; and there is a reasonable case
for the idea that apes may have a concept of self. The trouble with G's paper is
that it is an anachronism, at least as far as comparative psychology is concerned,
and I would be sorry to think that ethology was lagging so far behind. The
argument would not have been out of place in 1935 when the great continui-
ty/noncontinuity debate was getting under way, concerned with the question
whether cognitive processes must be postulated to account for the way in which
animals learn. But comparative psychology has moved on, with the noncontinuity
or cognitive position tacitly conceded following the important unifying paper of
Meehl and MacCorquodale (1951). It is true that some learning theorists (to whom
G refers, apparently, when he speaks of strict behaviorists) still prefer to avoid the
problems of imagery, intention, and insight, though they do not deny that such
things exist; but they are not at all representative of comparative psychology - or
indeed, of behaviorism generally. Lashley and Tolman both called themselves
behaviorists and were certainly strict enough in behavioristic method, but both
spent their careers in the attack on Watsonian and neoWatsonian ideas.
Familiarity with the development of that line of thought in comparative psychol-
ogy, besides showing that Watson need not be disproved all over again, would
have made it easier for G to find objective criteria of what used to be called
thinking but is now called cognition, and to show the objective, behavioral
meaning of terms like consciousness and mind without appealing to self-
awareness or having to resort to the commonsense definitions of a nontechnical
dictionary. Such an approach has been made elsewhere (Hebb, 1949, 1960,
1972; see also Puccetti & Dykes: "Sensory Cortex and the Mind-Brain Problem"
BBS 1(3) 1978). It depends on a distinction between cognitive behavior, thought-
controlled, and behavior controlled by conditioned as well as unconditioned
reflex, which is sense-dominated or environmentally programmed - a distinction
that would immediately prevent the error of regarding the communications of
honeybee and chimpanzee as similar, except in complexity. The ordinary commu-
nications of the untrained chimpanzee are cognitive and different in kind from the
reflexive "language of the bees."
To recognize that fact is not to abandon objectivity. Dichotomies are neces-
sary in biology. Evolution has produced qualitatively new physical structures,
different in kind from what preceded; in a comparable way, in the development of
the nervous system, qualitatively new kinds of behavior have emerged. These can
be thought of as produced by the attainment of critical mass (or a critical level of
complexity) in the nervous system. Cognitive behavior has been demonstrated in
mammals, even in the laboratory rat. There is little evidence of it elsewhere.
The objective approach to these questions might run as follows. Conscious-
ness is a state of reactivity to the environment that is characterized by the
presence of representational processes. That is, consciousness requires the
presence of thought. The essence of thought is the representational process,
image, or idea. The representational process is an activity of the brain that is
initially elicited by stimulation from some object or event, but can later occur in the
absence of that stimulation. In effect, it may be thought of as a perception excited
by an associative process instead of by the adequate stimulus. This conception
was made fully operational and objective by Hunter (1913, 1917), who showed
how to demonstrate the presence of representational activity in animals and
young children by means of the delayed response, without any appeal to verbal
report. He thus gave us the means of finding out which species are capable of
cognitive activity.
The perfect demonstration was made by Tinklepaugh (1928) in Tolman's
laboratory, using the delayed response with monkeys. The monkeys liked lettuce,
but liked banana better. When they saw lettuce put in the food cup, and after the
delay period found lettuce there, they took it and ate it. But when they saw
banana and then found lettuce (the experimenter having made an exchange
during the delay period), they disregarded this second-class reward and hunted in
and around the food cup for the missing banana - or had a temper tantrum
instead. Here the evidence for the existence of a memory image and expectancy
is unassailable. Together with Kohler's (1927 op. cit. SR&B) classical work with
the chimpanzee, it leaves no reason for debate in the question of thought and
consciousness in the primate; and the work with rats in Tolman's laboratory (e.g.,
Tolman, 1948) tells the same story, even at this lower evolutionary level.
Now the crucial point is that such evidence is almost totally restricted to
mammals. It seems likely that the larger-brained birds also have cognitive
capacities and that their nest-building or broken-wing behavior is more than a
compulsive situation-guided and controlled set of responses, but the necessary
experimental analysis has not been done. It seems clear, however, that there is
no basis at all for attributing representational processes to the insect, and hence
no basis for regarding the communication of ant or bee as the same in kind as the
intentional communication of the chimpanzee. Intention or purpose includes an
anticipatory idea of a future state of affairs that will result from the intentional act.
REFERENCES
Hebb, D. O. The organization of behavior. New York: Wiley, 1949.
The American Revolution. American Psychologist 15:735-745, 1960.
Textbook of psychology. 3rd ed. Philadelphia: Saunders, 1972.
Hunter, W. S. The delayed reaction in animals and children. Behavior Mono-
graphs 2, no. 6, 1913.
The delayed reaction in a child. Psychological Review 24:75-87, 1917.
Meehl, P. E., and MacCorquodale, K. Some methodological comments con-
cerning expectancy theory. Psychological Review 58:230-233, 1951.
Tinklepaugh, O. L. An experimental study of representative factors in mon-
keys. Journal of Comparative Psychology 8.197-236, 1928.
Tolman, E. C. Cognitive maps in animals and man. Psychological Review
55:189-208, 1948.
by John Heffner
Department of Psychology, Northwestern University, Evanston, III. 60201 (Corre-
spondence to: Lebanon Valley College, Annville, Pa. 17003)
Perception and animal consciousness: the philosophical context [G, P& WJ.
Unless our conclusions are to be constrained unnecessarily by method or
ideology, there is little reason to doubt that mental activity in humans forms a
continuous spectrum from sensory processes to high-level abstractions. Behav-
ioral and anatomical evidence make it quite reasonable to conclude that many
animal species experience roughly similar spectra, even though theirs probably
do not extend as far into the abstract part of the range as the human spectrum. In
treating this subject, ethologists are concerned primarily to ascertain and
compare the ranges of the various spectra, whereas philosophers are concerned
primarily to articulate criteria by which the ethological judgments can be made.
Both concerns overlap, but their different aims suggest caution in the use of
philosophical literature by ethologists and in the use of ethological studies by
philosophers.
Much twentieth-century Anglo-American analytic philosophy has been
constrained by method and ideology. It has been constrained methodologically by
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4
577

Commentary/Cognition and consciousness in nonhuman species
a rigid separation of data and theory, and, in its virtual exclusion of empirical
considerations, by conceptual and other a priori analytic techniques. Ideological-
ly, it has been constrained by its narrow interpretation of philosophy as a study of
the attribution of meaning to various linguistic forms. These constraints apply
equally, although in somewhat different ways, to both the positivistic (Shaffer,
1975 op. cit. G; Edwards and Pap, 1973 op. cit. G) and the ordinary-language
(Ryle, 1949 op. cit. G) branches of analytic philosophy. Philosophy has accord-
ingly tended to be unconcerned with specifically empirical questions, naive in its
use of empirical data, and historically myopic. Because its doctrines have usually
been molded by its constraints, its literature should be used cautiously. And
because it tends not to treat the problem of animal consciousness as an empirical
problem, its basic assumptions probably are not compatible at bottom with the
programs of P&W or G. What G refers to as a "customary" denial that animals
have experiences comparable to our own, therefore, should be read specifically
as being customary within the Anglo-American analytic approach to philosophy.
Some other approaches to philosophy make the same denial (e.g., Cartesianism)
and some do not (e.g., much of traditional empiricism, pragmatism, and some
forms of Platonism and Aristotelianism), but in each case the reasons for the
specific doctrines, which vary greatly among the various approaches, are
probably more important than the doctrines themselves.
G notes correctly that psychology, no less than philosophy, has been
constrained by method and ideology. Methodologically it has been constrained by
too great an emphasis on radical behaviorism, and ideologically it has been
constrained by its implicit naive materialism (Campbell, 1969). To view the
problem of animal consciousness as an empirical problem, broadly construed, is
to go far by way of eliminating both straw men and straw ghosts. To do so,
moreover, as indicated in G's quotation from Whiteley (1973 op. cit. G), is to
return to a more traditional philosophical perspective, in which the scientist and
the philosopher are considered to share certain general questions about nature.
This more traditional, more naturalistic perspective denies a radical distinction
between data and theory. It sees an understanding of data as leading to theory,
and it sees theory as a useful basis for the interpretation of data. Data and
theoretical concepts are thus considered to be related dialectically by mutual
criticism and support, so that neither assumes absolute epistemological prece-
dence over the other (James, 1904; Shimony, 1971; Campbell, 1974). Philosophi-
cal theories are thus considered to be continuous with scientific theories and also
to have empirical implications. This philosophical perspective, which is implicit in
G's program for cognitive ethology, is epistemologically unobjectionable,
provided only that recent Anglo-American analytic philosophy is not taken for
orthodoxy. When the problem of animal consciousness is viewed from this
broader perspective, it becomes a relatively uncontroversial problem which has
empirical implications. Both the philosopher and the ethologist can focus on the
interesting question, which is not whether animals have minds, but what specific
cognitive structures they may have.
Perception is a rich source of clues about these cognitive structures. Because
they affect phenomenal fields themselves, it is misleading to divide perception into
mental photographs plus interpretative inferences (Heffner, 1976). Spatial vision,
for example, is highly organized by memory, classification, and other cognitive
structures, which affect the visual field itself and not just the use which the
perceiver makes of visually received information. It is reasonably certain that the
spatial vision of many animal species closely resembles human spatial vision,
which argues strongly for a similarly close resemblance of the relevant cognitive
structures.
In their treatments of intentionality in animal cognition, both G and P&W touch a
matter of great philosophical interest. Intentionality is not limited to conscious
planning. In logic the term designates the definition of class membership by
characteristics rather than by enumeration, and in philosophy of mind, especially
in the phenomenological movement begun by Husserl (Spiegelberg, 1971), it
designates the cognitive processes by which experience is referred beyond its
own phenomenal content to external objects. By virtue of its organization, human
perception is intentional in both senses, even though it is not usually voluntary.
The extent to which animal perception is similarly intentional could provide clues
about the higher cognitive processes in animals. The further issue of intentionality
as volitional, of course, is also interesting in its own right. P&W's efforts to gauge
various modalities and epistemic states are particularly impressive in this regard.
They seem to circumvent some of the difficulties that arise when communication,
language, and speech are taken simplistically to be coextensive. Much linguisti-
cally oriented philosophy is not this simplistic, but it is important to supplement its
tendency to rely exclusively on verbal examples. The results obtained by P&W
seem to indicate that at least some primates besides humans have at least a
limited ability to make and use symbols. These results imply corresponding mental
activities, and accordingly they should interest philosophers as examples of
experimental data which have epistemological implications.
Impressive though P&W's results are, they finally suggest a philosophical
caveat. One ability that humans have undoubtedly to a far greater degree than
other species - if, indeed, other species have it at all - is the ability to think
meta-linguistically. To manipulate symbols, and even to invent them, is not
necessarily to comprehend their nature as symbols. Chimpanzees may learn to
communicate, but they probably will not become grammarians or logicians. To
have mental activity in various modes is not necessarily to recognize them as
such, just as many humans who have never studied logic can nevertheless think
logically. Chimpanzees may learn sophisticated ways of communicating and of
coping with the world, but they probably will not become ethologists or philoso-
phers. To say that chimpanzees attribute states of mind to other organisms is not
to say that they have even implicit theories of mind. "Theory" usually designates
a meta-language, and it really is too well embedded in the vocabulary of science
to receive an impromptu definition.
ACKNOWLEDGMENT
This work was supported in part by National Science Foundation Grant SPI
78-15654.
REFERENCES
Campbell, D. T. A phenomenology of the other one: Corrigible, hypothetical,
and critical. In Mischel, T. (ed.), Human action: Conceptual and empiri-
cal issues. New York: Academic Press, 1969.
Evolutionary epistemology. In Schilpp, P. A. (ed.), The Philosophy of Karl
Popper, LaSalle, 111: Open Court, 1974.
Heffner, J. Some epistemological aspects of recent work in visual perception.
In Suppe, F., and Asquith, P.D. (eds.), PSA 1976, vol. 1. East Lansing: Phi-
losophy of Science Association, 1976.
James, W. Does consciousness exist? Journal of Philosophy, Psychology, and
Scientific Method 1:477-91, 1904 (frequently reprinted).
Shimony, A. Perception from an evolutionary point of view. Journal of Philos-
ophy. 68:571-583, 1971.
Spiegelberg, H. The phenomenological movement. 2nd. ed. The Hague: Mar-
tinus Nijhoff, 1971.
by Julian Jaynes
Department of Psychology, Princeton University, Princeton, N.J. 08540
In a manner of speaking. If we compare the vocabulary between early and late
Greek texts over the first millennium B.C., or between early and late Hebrew texts
over the same period, a dramatic change is obvious. Early texts have no mental
words. The referents of words are concrete, indicant, objective, touchable,
watchable. But, in a few centuries only, the human lexicon is suddenly aglitter with
a network of new subjective words that to us are equivalent to mind, belief, know,
remember, imagine, aware, purpose, intention, and so forth. The referents of
such words are only observable, if at all so, by a new kind of mental process
currently called introspection, previously reflection, or simply and more fuzzily
thought. And the peculiar quality of these words, in contrast to cup, run, green,
river et al. is that they create their own referents on the basis of metaphor,
becoming those analog behaviors which we call consciousness.
This new way of talking about human happenings became its own theory of
human behavior. Previously, it might have been said that a man seeks shelter.
Now, a man seeks shelter because he wants shelter - a vacuous tautology which
says almost nothing, but whose function is perhaps to help us look "inside" the
man and pay attention to his consciousness rather than his motions. We like
dealing with the "insides" of others, their intentions, ideas, thoughts. It is safer. It
makes behavior more predictable. Most of our social interactions are now on this
level. In fact, talking about other's consciousnesses is itself an inherent feature of
consciousness. Even in this peer commentary journal, we are talking about ideas
which we locate in the heads of others and ourselves. Nothing of the sort could
have taken place 1000 B.C.
This mentalizing lexicon was so useful that it spread out to describe almost all
human action, even when not warranted. A person after consciousness devel-
oped may indeed want X or have an intention to Y or be aware of Z, but not all X's
and Y's and Z's are preceded by wants, intentions, or awarenesses. The
attribution of all our behavior to wants, purposes, intentions, and so forth,
became so habitual that it left us with the false conviction that consciousness
governs all and is responsible for everything from concepts to learning and
speaking.
578
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4

Commentary/Cognition and consciousness in nonhuman species
So excessive did this way of speaking about ourselves become that it spread
to all animate behavior, until during part of the first millennium A.D., animals could
be tried in court of law and proven guilty or innocent of willful misbehavior. And
then it engulfed even inanimate behavior. In the Renaissance, because magnets
had the ability to move and be moved, they were thought to have souls. Or even
rivers seeking valleys. And after Copernicus showed that the earth really moved,
no less an assembly than Campanella, Kepler, and - at one time - Newton
believed that the universe was what we would call "cognitive." Even today,
contemporary physicists such as John Wheeler and Eugene Wigner are making
the same confusion of metaphor and actuality, proclaiming that consciousness
has to be brought in as a force in the universe because of certain astonishing
findings of quantum mechanics.
This wisp of history is not beside the point here. It is meant to show that we
have inherited a group of mentalistic words that are as slippery as live fish and
just as difficult to hold still. Moreover, there seems to exist, from their first
significations to conscious processes, a hierarchy of levels of metaphoric
application as we descend from human adults to rivers or magnets. I think it is
obvious with this preamble that I am about to suggest that the three papers under
discussion are using these mental terms on a metaphoric level, not as they pertain
to actual human consciousness.
Let me immediately say, however, that my criticism is in a sense unfair, since
none of the writers stresses the word consciousness. I apologize, but only
halfheartedly. For I think the average reader will certainly assume that it is a
consciousness like his own that is being talked about with such cognate terms as
awareness, intentionality, or theory of mind.
Let me take just one part of Griffin's extremely interesting paper, his descrip-
tion of Gallup's experiment. That a mirror-educated chimpanzee immediately rubs
off a spot on his forehead when he sees it in a mirror is not, I suggest, "clear
evidence for self-awareness," at least in its usual sense. Self-awareness usually
means a consciousness of our own persona over time, a sense of who we are,
our hopes and fears, as we daydream about ourselves in relation to others. Our
conscious selves are not our bodies, although our bodies, particularly our faces,
are often emblems of ourselves. We do not see our conscious selves in mirrors.
Gallup's chimpanzee has learned a point-to-point relation between a mirror image
and his body, wonderful as that is. Rubbing a spot noticed in a mirror is not
essentially different from rubbing a spot noticed on his body without a mirror. The
animal is not shown to be imagining himself anywhere else, or thinking of his life
over time, or introspecting in any sense - all signs of consciousness.
As for mental representations or images, it depends what our precise referents
are. A dog seeking a particular stick thrown by his master into a high hayfield
certainly has a persisting brain-representation of the stick, a visual-olfactory-
tactile complex by which he will recognize the stick. But he does not introspect
upon this brain-representation as we do with our conscious images.
When two chimpanzees are communicating with each other, we have a vastly
more complicated situation than one chimpanzee communicating with a mirror.
The experiment by Savage-Rumbaugh et al. is methodologically elegant and
exciting in clearing out extraneous variables. The reader is almost impatient to
suggest further studies with the same paradigm. But I do not understand the
necessity of emphasizing such difficult terms as "intentionality" and "symbolic." I
am reminded here of Sir John Lubbock, who, in 1888, hearing of the methods
used in the training of the human handicapped, trained his dog to "read." The
dog would bring to him in appropriate situations any of several cards on which
were printed "food," "out," "bone," "tea," and do this in a way that simulated
human speech expressing human wishes. I would call this symbolic and intentional
behavior, but explainable on a far simpler level than consciousness.
Even more complicated is the relationship of a chimpanzee to a videotape of
actors in problematic situations. Premack's papers are always so articulate about
these issues as to leave one full of doubts about one's own ideas. As he well
knows, so much depends on definitions and the referents of the terms of those
definitions, and also on the connotations of the terms used. "Theory of mind"
certainly conjures up human intellectual processes. If the term simply means the
recognition of a particular mental state in another animal and by mental we do not
imply conscious, I do not disagree. But then we can apply such a phrase much
more widely: to a dog that cowers to his master's scolding tone or wags his tail to
praise; or to a four-year-old child who can choose appropriate gifts for a
two-year-old. Both dog and four-year-old are recognizing the mental states of
others, and I suggest that this is more automatic than introspective.
Although this is not explicit, all three papers seem to say that demonstrating
that animal behavior can be made to simulate aspects of human behavior,
simultaneously demonstrates a similarity to human conscious functioning. It is the
same argument used with that other method of simulation of cognitive processes,
computer intelligence [see Pylyshyn: "Computational Models and Empirical
Constraints" BBS 1(1) 1978]. But - to use a wildly dissimilar and probably
inaccurate example - because Mickey Mouse looks and behaves so humanly on
a screen does not mean that a celluloid film is conscious; it means Mickey is
made to look conscious.
In no way do I mean to diminish the very real breakthroughs of these ingenious
studies in what, with G, we could call "animal cognition." They point to a new era
in studying the primate mind. But we must not be misled by our labels into thinking
the results identical with that metacognition we call "introspective conscious-
ness" or what Alexander Bain long ago called "the awareness of awareness." It
would be interesting in this connection to do a reverse simulation, to run these
experiments with human subjects, particularly if they had been trained in giving
introspective reports by Kulpe back in Wurzburg.
by Alison Jolly
School of Biological Sciences, University of Sussex, Sussex, England.
The chimpanzees' tea-party. The editors of BBS go out of their way to ask
commentators to argue. It seem only fair, then, to begin by stating one's own
position. I take the naive view that animals are conscious, and that animals that
look and act like ourselves probably have awareness rather like our own. The
alternative, that consciousness is uniquely human, which has seemed plausible to
many followers of the Judeo-Christian tradition, strikes me as un-Darwinian,
unparsimonious, and (to quote G) conceited. Another alternative is that
consciousness does not exist because it is hard to define - or if it does, let us not
mention it. I can see no point in trying to converse with people who ignore
consciousness, though they may be suitable cases for therapy.
Which said, I respect the conclusions of all the authors, but feel they have
sometimes worked too hard to prove, if not the obvious, at least the likely. The
real excitement would be if we could worry less about whether an animal is
enough like ourselves to be called conscious, and ask instead how its mind differs
from ours in its own right, qualitatively or quantitatively. When will psychologists
outgrow the chimpanzees' tea-party?
Griffin attacks the central problem: how can we decide whether a creature is
aware of itself or of its intentions? How would we distinguish a guided missile
piloted by computer from one with a human kamikaze pilot, and how would we
apply the same criteria to a dancing bee?
There are at least three parts to the answer: criteria derived from an
organism's actions, those from its structure, and those from our own ethical
views.
In spite of G's analysis, I am not fully convinced that we can decide simply from
an organism's actions, even with the possibility of two-way communication. Even
if we leave aside the question of whether other humans are conscious, we could
now install a computer in the guided missile that did not just play patriotic songs,
but would answer back. Weizenbaum (1976) describes a sample of conversation
between a patient and a psychotherapeutic computer. The computer reflected
the patient's own statements and put them together as leading questions, in a
sympathetic baritone. Eventually the patient declared, "You remind me of my
father!" Of course, she may have been right and the machine's program may
indeed have resembled her father's, but it seems increasingly difficult to decide
that even a machine is not conscious. Any robot can be equipped with pain
circuits - feedback devices to help it preserve itself from noxious stimuli. If a
computer uses a thermostat to adjust the temperature of its room, it behaves
much like a thermoregulating animal, and if the temperature fluctuates out of
control so that it flashes a warning light, it is acting like a social animal that cries
for help. All we would need to simulate the apish emotions of its guardians would
be a tape-recording instead of the warning light - perhaps a series of tapes that
responded to rising temperature in ever more urgent tones, ending with a
scream.
This may seem to argue against the thesis that common sense is right in
guiding us to believe that other beings are conscious, for computers could now
trick common sense. We do not believe the computers because we know we
made them. The question of the origin and mechanics of the organism seems to
be crucial. If an unknown device, which was rational and socially responsive,
arrived from outer space, we should probably conclude that it was alive and
aware. When we ourselves succeed in synthesising a moving, respiring cell from
biochemical components, will we not admit it is alive? If we could make a
biochemical computer that conducted a two-way conversation, might we not call
it conscious?
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4
579

Commentary/Cognition and consciousness in nonhuman species
The fact that chimpanzees are constructed like ourselves, and that we share a
common origin, makes it highly probable that they also think in similar ways. The
presumption that chimps think more like us than bats do, and bats than do bees,
is plain zoology. I shall return to ape mentality in discussing the other two articles.
G, however, is more concerned with our approach to bats and to bees, where our
evolved repertoire of communication does not bridge the species gap.
Here it seems that we are on ground where we can only use the criteria that we
would for a totally strange machine. We can be tricked in the same ways. The
machine may keep silence or may not speak our language, or it may have a
complex responsiveness that we do not wish to call consciousness. Whether we
call such an alien mind conscious seems to me to reflect our value system, rather
than objective criteria. Perhaps only humans have foreknowledge of death, but
shall we deny that other creatures know the terror of death? Whether we call it
that depends, not so much on our logic, as on whether we think the feelings of a
computer, a bee, a bat, or a laboratory ape, actually matter.
We can be delighted that G has not only raised and analysed the subject of
animal awareness, but that he also links the logical, evolutionary, and ethical
criteria, whichever turn out to be most fundamental. His article, and book, should
inspire much more research that reflects his own respect for the capacities of
animals.
Savage-Rumbaugh, Rumbaugh, and Boysen show, to a new degree, the
interrelation of symbolization, tool use, and interanimal cooperation. They have
shown that their two young chimps understand the symbols they use, in the sense
that the symbols are both produced and received as utilitarian communication.
It is true that they have shown all this with rigor and sophistication. The
cleverness, however, is the experimenters' not the chimps'. Cooperative multi-
male hunting in the Gombe Stream, or the joint intimidation of Evered by the
brothers Figan and Faben, seem to me more sophisticated than the handling of
tools, even named tools, through a partition. The fundamental importance of
interanimal attention when learning language and role reversal is hardly new to
this experiment, but is common to theorists from De Laguna to Bruner, in practice
to human mothers, and, it must be admitted, to people who make pets of their
apes while teaching them language. The authors will not be pleased if I suggest
they have rigorously arrived where the Gardners started.
I hope that SR&B will now use the enormous potential of their system to build
their experiments into still different spheres. Apes that request tools are a model
of human interests. Is the emergence of "wordness" significantly more human
when a chimpanzee must discuss tools than if he must instruct another to turn
somersaults, drum on the walls, or distract an experimenter so that his accom-
plice can steal food? Until we compare words in different spheres we cannot
make too much of the relation between symbols and tool use. Might it be possible
to allow the computer-language chimpanzees still more productivity, to give us a
cross-check on the ASL chimps that would reveal and analyse what one ape
wants to say to another?
We are back to G's concern with the quality of minds that differ from our own.
At the circus we applaud with awe as the human acrobat brachiates above
ground. Then we chortle when bediapered chimps waddle in on their hind legs
and sit down to tea. Could the authors now devise an intellectual equivalent of
letting the chimpanzees loose on the trapeze?
Premack and Woodruff's experiments reach for the trapeze. As always, it is
possible to quibble - to think that the ape's view of differences in ability between
chimps and humans might be as interesting as the differences between children
and adults, or that the ape may make a very wide distinction between "pretend"
and "lie," for one is likely to be playful and one malevolent. On the whole, though,
both logic and experiments in this paper are fascinating.
Two comments on their concluding remarks. It does seem reasonable that
apes and young children will find it easier to solve problems about wanting than
knowing. The distinction between wanting and knowing, though, probably arises
through several stages in young children. Even adults may slide from one
interpretation to the other, as in whacking a tired child because it didn't know
enough to go to bed an hour ago, or as in "The car didn't want to start so I kicked
it."
P&W's overintelligent behaviorist who believes that consciousness is in princi-
ple beyond the reach of science is here dismissed to join the mystic who believes
that consciousness is in principle uniquely human, and so beyond the reach of
biological analysis. P&W put primates' theories of each other's minds firmly back
into evolutionary context. They open the door again to talking of human origins
not just in terms of our technological breakthrough in understanding tools, but in
terms of the evolution of our understanding of each other.
REFERENCE
Weizehbaum, Joseph. Computer Power and Human Reason. Freeman, San
Francisco, 1976.
by Michael Lewis
Institute for the Study of Exceptional Children, Educational Testing Service,
Princeton, N.J. 08540
Social knowledge and mental acts. Imagine that the positivist and radical
behaviorist movements did not exist and that events had to be interpreted in
terms of a different paradigm. My grandmother, for example, would have little
trouble explaining the following events: our kitten, earlier taught to retrieve a small
black ball, later spontaneously brings the ball to one member of the family; she
places it at their feet, and when it is picked up and thrown, runs after it and brings
it back. This game goes on for many trials before either the kitten or person tires
of it. My grandmother would explain the kitten's behavior by saying that "the
kitten wants to play." Whether or not the kitten had such a plan, or has a plan
before she sees the ball, it is clear that having obtained the ball (and possibly the
association from it) she does seek out someone to play with. In fact, everyone at
home accepts as correct that the kitten has intention and, as a result of this belief,
plays with her so as not to disappoint her. SR&B cite a similar incident, from the
Hayes and Hayes (1954 op. cit SR&B) reports, in this case referring to the
behavior of Vicki, a chimpanzee.
That such incidents, across a wide range of species, do occur, and that we
have failed to give them meaning - indeed, that we have assigned them meaning
devoid of mental action - speaks to our bias. The three accompanying target
articles seek in various ways to question the bias of radical behaviorism and
positivism - G by logical analysis, SR&B by demonstrating that chimpanzees are
capable of symbolically mediated exchanges of goods and information, and P&W
by demonstrating that chimpanzees are capable of role-taking, which is affected
by their knowledge of the situation and of another individual, in this case a human.
The exciting feature of all three papers is not only the attempt to refocus our
interest on the mental life of nonhuman (and by inference, human) animals, but at
the same time to suggest empirically compatible tests of mental operation and
action. In reading these papers, I am concerned by the relative lack of inclusion,
at least in two of them, of the work of scientists who, with other nonspeaking
organisms (human infants and young children), have likewise attempted to study
mental life. For me, there is a clear analogy between the problems of demonstrat-
ing intention, awareness, empathy, and so forth, in chimpanzees and in human
young. The analogy appears to rest on the same assumptions. First, and most
important, is the belief that infants and animals have little or no mental life, even if
mental life can be defined and demonstrated for adults of the species. It should
come as no surprise that intentions on the part of infants appear to many as
farfetched as intentions in animals. Thus, the problem explored within these three
papers is similar to the problems explored by Baldwin (1894), Piaget (1963),
Merleau-Ponty (1964), G. H. Mead (1934) and, most recently, by Lewis and
Brooks-Gunn (in press) [see also: Brainerd: "The Stage Question in Cognitive-
Developmental Theory" BBS 1(2) 1978]. There is a long history within the study of
developmental psychology which addresses these problems and because of this
they beg for a developmental consideration.
Indeed, my most serious concern with the SR&B and P&W papers (in fact, with
most studies of this sort) is that the authors tend to spend too little time on the
developmental aspects of their work. For this they cannot be faulted. Clearly, the
problem they pose is directed toward the behavior of an animal not in its infancy;
nevertheless, there is some similarity between the training procedures used to
shape the responses these investigators are interested in studying and the
developmental issues themselves, if only that development and learning may have
some processes in common, although over a different time span. If we share an
interest in intention, awareness, the use of self as in empathy (empathy being the
ability to put oneself in the place of the other), it becomes important to ask how
the complex set of behaviors we use to infer mental life comes about; that is, the
history of learning or the developmental course becomes critical to the very heart
of the argument.
One aspect of the development/learning of these abilities appears to be the
relationship of the chimpanzee to its social world. One is impressed that in both
papers the point is made of the existence of a special relationship between
caretaker and chimpanzee and how this relationship interacts with the phenom-
ena under study. This would not surprise those of us interested in the develop-
mental aspects of these abilities since, for example, Lewis and Brooks-Gunn (in
press), in their study on social cognition and the acquisition of self, place a
580
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4

Commentary/Cognition and consciousness in nonhuman species
special importance on the interaction of the infant with its social world and how
through that interaction the child acquires at the same time knowledge of itself
and another. That the acquisition of self, and thus agency, the prerequisites of
intention, (1) have a social interaction derivative, (2) are related to knowledge
through interaction, and (3) are not specifically shaped, plays an important role in
assigning them "mental" status. The social origin of the mental abilities discussed
by SR&B and P&W finds additional support within both papers. In particular, the
fact that for chimpanzees as for children, words and concepts are at first closely
and therefore concretely linked to function, suggests that early cognitions are
socially derived from the organism's adaptation to its environment. For both apes
and man, the most critical aspect of this environment is social; thus, we must
support Levi-Strauss's (1962) contention that symbolic behavior is a social
contract between conspecifics.
The social environment also acts on responses, once they are emitted, and
may thus contribute to the latter's meaning. It appears to be the case that
humans, at least, impute intentionality to the action of others, even to animals, in
varying degrees. The effect of such attributions on the quality and nature of
emitted acts is certainly unexplored but it is difficult to imagine that it should not
differentially affect the meaning of the action to the actor. As G. H. Mead (1934)
and Cooley (1912) have pointed out, we are what is, to some degree, determined
by how others think of and respond to us. That the caretakers attribute various
meanings to the chimpanzees' behavior should affect the nature of the interaction
as well as the meaning attributed to it by the chimpanzee. The acquisition of self
and intention may require that young organisms be treated as //they do possess
these attributes.
If we care to pay attention to social interactions as part of the process by which
mental life develops, two special issues are raised by these papers. The first has
to do with the nature or content of the symbol system being taught to these
animals. We may make the mistake (as Washoe herself is reported to have done
in thinking that chimpanzees were people) of assuming that since chimpanzees
have a "mental" life, the content of this life is or should be similar to our own. This
latter assumption may be unwarranted, since it is possible to believe that
chimpanzees can both think and think "chimpanzee thoughts." We assume, as
does a child's mother, that the content of thought should be the same; this is the
process of socialization by which they in fact become the same.
Might it not be better to teach chimpanzees to communicate about those things
that are more chimpanzee than human? Surely the behavior of free-roaming
chimpanzees is well enough known for us to select more species specific
problems. Although P&W suggest that chimpanzees are being used as actors in
the problem-solving scripts, why not adapt the context of the problems to them as
well? Likewise, SR&B might consider chimpanzee problems and exchange, rather
than human tool use. A confusion between "content" and "mental" needs
clarification. Are we being told that (1) chimpanzees are like humans, or (2)
chimpanzees have a "mental" life, or (3) "mental" life is a valid explanation for
some classes of events? While we have evidence that human infants have a self
concept or intention, we would not assume the content, and perhaps the process,
to be the same as that in adults (Lewis and Brooks-Gunn, in press).
A second question concerning the "mental" abilities in question constitutes a
metaproblem or an epistemological issue, namely, how the chimp knows what
you want, and what it is that he knows. In the chimpanzee's understanding of
cueing (SR&B) and his answering of questions (P&W), a prerequisite is the
preexistence of a social interaction, a sharing of symbols, and a shared meaning
system that has to be predicated on what the chimpanzee already knows about
you and what you want.
In both cases, it is the social interaction of the chimpanzee and his caretaker
that sets the stage and provides meaning for any subsequent mental act. We
would hold, therefore, that the origins and sustaining vehicles of "mental" acts
are social acts. Not until the prior social task is mastered can the child and
chimpanzee develop further, and abstract "mental" actions from social experi-
ence. In reading the accompanying target articles, one cannot fail to be
impressed with the attempt to provide a broader theoretical framework for the
explanation of complex events than that provided by radical behaviorism. As
others have pointed out, however, such cross-paradigmatic issues cannot be
solved by data (Reese and Overton, 1970). Instead, it is necessary to demon-
strate the heuristic value of alternate views. The utilization and integration of the
social origin of these actions seem to me to serve as some basis for an integrated
theory of the mind which connects mental acts with the organism's total
experience. As such, mental life constitutes only one aspect of the organism's
interaction with its environment.
REFERENCES
Baldwin, J. M. Handbook of psychology: Feeling and will. New York: Holt,
1894.
Cooley, C. H. Human nature and the social order. New York: Charles
Scribner & Sons, 1912.
Levi-Strauss, C. The savage mind. Chicago: Univ. of Chicago Press, 1962.
Lewis, M., and Brooks-Gunn, J. Social cognition and the acquisition of self.
New York: Plenum Press, in press.
Mead, G. H. Mind, self, and society: From the standpoint of a social hehav-
iorist. Chicago: Univ. of Chicago Press, 1934.
Merleau-Ponty, M. Primacy of perception. J. Eddie (ed.) and W. Cobb (trans.).
Evanston: Northwestern Univ. Press, 1964.
Piaget, J. The origins of intelligence in children. M. Cook (trans.) New York:
Norton, 1963.
Reese, H., and Overton, W. Models of development and theories of develop-
ment. In Goulet, L. R., and Bakes, P. B. (eds.), Life span 
developmental
psychology: Research and theory. New York: Academic Press, 1970.
by John Limber
Department of Psychology, University of New Hampshire, Durham, N.H. 03824
Good-bye behaviorism! An ancient psychologist returning from a sixty-year
sabbatical in Katmandu or thereabouts and reading this issue of The Behavioral
and Brain Sciences would experience an extraordinary sense of deja vu, taking
him back to his graduate school days. That was a time when everyone was
concerned with cognition and consciousness in nonhuman species - and not just
that of the recently discovered great apes. Romanes (1885), for example, had
already located the origins of consciousness somewhere between the Coelenter-
ata and Annelida. Others vigorously and seriously debated the implications of
demonstrations of learning in protozoa (e.g., Walkin, 1899) for theories of mind.
The question of language in nonhuman species, of course, had continually been
in the air from Descartes to Max Muller, and indeed for all we know our
apocryphal centenarian psychologist might well have fled to the East to avoid
speculation on the subject, rampant then as now:1
"A great deal has been published in both magazines and newspapers during the
past few years about the so-called "language" of animals, especially apes ... in
consequence there was given the widest publicity to an immense amount of the
veriest nonsense, from which the average person who depends entirely upon his
newspaper for his information is likely to have formed an entirely false
conception of this very interesting matter." (Gladden, 1914, p. 307.)
In any event I am certain our psychologist would be familiar with most of the
issues raised in this volume as well as impressed by the research discussed in the
three papers. He might be inclined, however, to wonder what all the fuss was
about; why devote a special issue to such mundane topics? We should then have
to tell him about behaviorism and how behaviorism tried convincing us, success-
fully in many cases, to forget about mental life, mind, and consciousness and to
concentrate on pure behavior. Pragmatically it advised its adherents to forget
about common sense and not to bother with anything done by nonbehaviorists.
We should also be pleased to point out that behaviorism had been on the decline
for several decades under pressures from such things as ethology, cognitive
psychology, Noam Chomsky, John Garcia, "autoshaping," and "constraints on
learning" - not to mention an occasional mutiny (Herrnstein, 1977). Indeed, the
present volume might well be said to commemorate the end of behaviorism [see
also Bindra: "How Adaptive Behavior is Produced" BBS 1(1) 1978; and Hauge-
land: The Plausibility of Cognitivism" BBS 1(2) 1978].
Other nonhuman minds [G]? The paper of G sharpens the thesis developed in
his book, The question of animal awareness (1976 op. cit.G, SR&B). On the one
hand he calls for an end to the "behavioristic Zeitgeist" that inhibited inquiry into
the mental life of organisms, and on the other he suggests that extension and
refinement of two-way communication between ethologists and the animals they
study offer the prospect of developing a truly experimental science of cognitive
ethology. I am in considerable agreement with G on both of these points. If
anything, I think he understates the case against behaviorism; I have in mind the
restrictive effects of removing hypothetical, causally effective constructs from the
tools of scientific analysis and the practical difficulties in ascertaining such things
as "behavioral repertoires," "effective reinforcers," or "histories of reinforce-
ment." Many psychologists simply do not see the point of giving up useful
explanatory concepts, however mentalistic, for the sake of prescriptive scientific
ideology. As P&W - certainly no strangers to behaviorism - remark in their paper,
how could they avoid mentalistic notions in their explanation of Sarah's behavior?
One thing I missed in G's paper is some recognition that behaviorism did not in
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4
581

Commentary /Cognition and consciousness in nonhuman species
fact completely snuff out all research into the mental life of animals. For example, I
see no mention of E. C. Tolman's (1932) purposive behaviorism, with its
suspiciously mentalistic notions of such things as cognitive map and hypotheses.
It is my impression that Tolman's work not only gave a certain intellectual
respectability to the rise of behaviorism but also today serves as an important link
between pre-behaviorist psychology, contemporary cognitive psychology, and
G's cognitive ethology. Elsewhere - since behaviorism was primarily an American
affliction - comparative psychologists and ethologists continued to seek empiri-
cal answers to the traditional questions about the minds of organisms (e.g., Katz,
1939). Contemporary Soviet studies on the orienting response also seem to be
directed at similar matters. It is just possible that G gives behaviorism more
discredit than it deserves.
The most important features of G's paper are his hortatory efforts to get
psychologists and ethologists to look at the behavior of animals with an open
mind and to stimulate research that might tap whatever mental life exists. In
addition to what G has to say on the importance of two-way communication
between experimenter and animal, it may be useful not to overlook a cognitive
interpretation (Tolman, 1932; Dulaney, 1968) of the traditional instrumental/oper-
ant conditioning paradigm as a communication paradigm. As Tolman pointed out
long ago, the reinforcer, for example, food pellet, has both affective and
informational elements to it that are typically confounded in the behaviorist
account.
Probably what excites G and others most about the recent developments with
Washoe, Sarah, and Lana is the possibility that much more sophisticated
quasilinguistic human animal communication is just around the comer. One might
imagine, although G was not so bold as to suggest it, that at some point we shall
have direct Cartesian evidence that certain animals have a mental life analogous
to ours. One might even fantasize that the structure of their quasi-language
should reflect the structure of their quasithoughts, much as it is sometimes
supposed that the structure of human thought is reflected in the structure of
human speech.
At the present time, however, there is very little reason to be overly concerned
about any of this. First of all, there are serious unanswered questions about the
accomplishments of Washoe et al. (See, for example, Sebeok, 1978, and SR&B,
this issue). Even if we accept at face value the glosses given to the symbol-using
apes by their interpreters, there seems to be a striking lack of cognitive or
intentional verbs such as want, think, or decide. This may be only a temporary
vocabulary gap; on the other hand, it may prove extremely important in the search
for nonhuman minds. For it is just these verbs and their sentential complements
(e.g., think that such and such) that are the foundations of the traditional linguistic
analysis of other minds (e.g., Margolis, 1978). Moreover, it is just these complex
constructions that inevitably mark the beginnings of syntactic speech in children
between two and three years (Limber, 1973).
I surely do not want to suggest on the basis of language alone that apes do not
want, decide, or think. For example, it is quite plausible that when Washoe signs
"Gimme banana" she actually wants a banana. At a pragmatic (but not syntactic
or semantic) level her signs may be functionally equivalent to the eighteen-
month-old child's "wa nana" or the three-year-old's "I want a banana." I do,
however, think these linguistic factors raise the possibility that apes may not have
conscious access to their mental life in the same way that children do. Similar
notions have been expressed quite independently of any specific linguistic
considerations. Katz (1939, p. 253) for example, says "Man not only has
consciousness, but he knows that he has it." While Washoe may truly want a
banana, she may not know it!
One should be careful about jumping to conclusions about the underlying basis
for any putative consciousness level differences among primates. While these
may exist independently of language as intrinsic cognitive differences, it may also
turn out that language itself is in some way causally implicated in these
differences. If this should be the case, training an ape in quasilinguistic skills may
do more than let us study its mind as G suggests; it may in a sense create that
mind.2
Do behaviorists have minds [P&WJ? I have maintained over the past few years
to my students that probably the most significant effect of the various efforts to
train quasilinguistic apes may be on the thinking of their behaviorist trainers. P&W
bear me out in an interesting paper that reports not only on an important research
program into the mind of Sarah but also provides an unusually reflective account
of how the authors, on pragmatic grounds, were driven to formulate a primate
cognitive psychology. The paper should be required reading for anyone inter-
ested in the traditional conflict between behaviorism and mentalism.
I have relatively little to say about the paper itself; the videotape paradigm
seems most promising and I can only agree with the authors' conclusions about
the incompleteness of behavioristic accounts of behavior. Nonbehaviorists long
ago recognized the difficulty of fully characterising even the simplest behavior
without some intrinsically mentalistic concepts like purpose, want, or attention.
P&W suggest that the ape is not intelligent enough to be a behaviorist; in a sense,
neither is Homo sapiens. Behavior even in the simplest situations is a function of
the organism's interpretation of stimulus conditions. Only with a model of the
organism's mind can we generate predictions of its behavior in novel situations.
Only through our theories of others can we overcome the egocentricism of
childhood and positivism.
I do have various doubts about the P&W program for examining "epistemic
states" in the chimpanzee but at this point in time it seems proper to praise
appropriate behavior rather than to criticize it. P&W, I suspect, will have their
hands full dealing with their colleagues and the ghost of Lloyd Morgan.
Some implications of symbol use by chimpanzees [SR&B]. The paper by SR&B
takes the trained apes and their acquired symbolic skills far beyond moot and
irrelevant debates about whether apes can learn language. As I have remarked
elsewhere, the promising aspect of this research - the effects of symbol availabil-
ity on animal behavior - have not yet been realized (Limber, 1977 op. cit. SR&B).
Now SR&B have reported what may be the first account of the utilization of
arbitrary symbol systems in animal behavior. They have demonstrated that
chimpanzees trained in a suitable symbol system can indeed use that system
cooperatively to achieve ends well beyond their means without it. I found the
SR&B paper thought-provoking and will try, with some difficulty, to limit myself to
brief comments on two interrelated issues: one concerns the functions of human
language, the other its origins.
SR&B, like most others who deal with animals and many who do not, take
communication to be the "true adaptive function" of language, "enabling man to
transmit specific information in abstract, context-free form." Now it would be
absurd to deny the importance of the communicative function of language; yet
there is another function traditionally ascribed to human language, typically by
logicians, philosophers, and cognitively oriented psychologists. This function
concerns mental representation and thought itself. Without going into details here,
I find it premature, to say the least, to suppose that the communicative
advantages far outweighed any representational advantages in the evolution of
human language. It seems, for example, that the representational capacity of
English far outstrips its use in everyday interpersonal communication (cf. Limber,
1976). What is exciting about the SR&B studies is that for the first time we can
begin to think about experimentally studying the effects of mental representations
themselves on animal behavior. How would variation in the symbol system affect
cooperation in the SR&B paradigm? SR&B's discussion of functional and
nonfunctional naming capacities in chimpanzees immediately suggests intriguing
experiments in the realm of "functional fixedness" (Duncker, 1945). Numerous
possibilities for investigating the recalcitrant problems of linguistic relativity and
determinism suggest themselves. Many of the classic paradigms of experimental
psychology, for example, the delayed reaction experiment, double alternation
problems, associative cue effects in problem solving, might be adapted to
examine the effects of arbitrary symbol systems on behavior.
To sum up this point, the mental representational capacity inherent in human
language seems at least as much of an adaptive advantage as does the
communicative advantage. The SR&B paradigm provides the potential for experi-
mental study of adaptive advantages that accrue to organisms having symbol
systems of varying complexity.
It is not impossible that a focus on the representational aspects of language will
also give us a chance to break into the notorious problems of language origin.
(Even formulating the issue adequately is difficult [cf. Kenny, 1973]: among the
traditional answers to this question at least Sussmilch's "divine origin" theory lays
the cards on the table!) There seem to be two fundamental obstacles to solving
the problem. One is to understand how the rule-governed, arbitrary symbol
system that is human language came to exist among a population with no
previous system; another is to enumerate whatever conditions - biological,
cognitive, social, environmental - support human language, yet might have
evolved in its absence. If, however, we reasonably suppose adaptive advantages
came to those organisms with increasingly complex intrapersonal representa-
tional systems, the fabled "private language" or "language of thought," then we
can postpone, for a while, a consideration of the really tough problem of the
extemalization of that system into the social phenomenon of language. On this
problem it may be that the SR&B and P&W papers supply some small pieces of
the puzzle. It appears that SR&B's chimpanzees, once given their symbol system,
had little difficulty using it; there seemed to be a preexisting emphatic relationship,
582
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4

Commentary /Cognition and consciousness in nonhuman species
initially developed between experimenter and animal, then readily generalized to
other chimps. This suggests exactly what P&W clearly demonstrate, namely that
chimpanzees have quite elaborate theories of others. Now the adaptive advan-
tages of such theories seem obvious; they enable an organism to understand the
behavior of others, more importantly they probably underlie the enormously
advantageous process of observational learning. Learning from another surely
requires an elaborate conception of another in relation to one's self. Observa-
tional learning, which perhaps evolved in connection with mechanisms of sociali-
zation (see also Beck, 1974 op. cit. SR&B), is important in connection with
language origins in that its processes of rule induction and rule following resemble
those processes required in the acquisition and use of language. In contrast to
natural laws causally governing behavior, rules can be violated, modified, and
become objects of awareness. For all I know, one of our clever ancestors, whose
population had independently acquired a certain representational capacity,
communication skills at an animal level, and empathic learning ability, just
invented language serendipitously and it then spread like wildfire. Naturally the
invention need not have been structurally like ours; considerable subsequent
cultural evolution may have taken place.
NOTES
I. We cannot be entirely certain of this; he might just as well have gone off to
investigate the language of the Yeti.
2.1 have hinted at some of these issues (1977 op. cit. SR&B) and discussed
them at greater length in my monograph in preparation on language among
primates. Everyone should also read Vygotsky (1962, chap. 4).
REFERENCES
Dulaney, D. E. Awareness, rules, and propositional control: Confrontation with
S-R behavior theory. In Dixon, T. R., and Horton, D. L. (eds.), Verbal be-
havior and general behavior theory. Englewood Cliffs, N.J.: Prentice-
Hall, 1968.
Duncker, K. On problem solving. Psychological Monographs 58, 5 (whole No.
270), 1945.
Gladden, G. A chimpanzee's vocabulary. The Outlook 106: 307-310, 1914.
Herrnstein, R. J. The evolution of behaviorism. American Psychologist, 32:
593-603, 1977.
Katz, D. Animals and men: Studies in comparative psychology. London:
Longmans, Green, 1939.
Limber, J. The genesis of complex sentences. In Moore, T. (ed.), Cognitive de-
velopment and the acquisition of language. New York: Academic Press,
1973.
Unravelling competence, performance, and pragmatics in the speech of
young children. Journal of Child Language 3: 309-318, 1976.
Kenny, A. J. P. The origin of language. In Kenny, A. J. P. et al, The develop-
ment of mind. Edinburgh: Edinburgh Univ. Press, 1973.
Margolis, J. Persons and minds: The prospects of nonreductive materialism.
Dordrecht: Reidel, 1978.
Romanes, G. J. Mental evolution in animals. London: Kegan Paul, Trench,
1885.
Sebeok, T. A. Looking for in the destination what should have been sought in
the source. In Horowitz, L., Orenstein, A., and Stern, R. (eds.), Language
and psychotherapy. New York: Haven, 1978.
Tolman, E. C. Purposive behavior in animals and men. New York: Appleton-
Century, 1932.
Vygotsky, L. S. Thought and language. Cambridge, Mass.: MIT Press, 1962.
Walkin, G. P. Psychical life in protozoa. American journal of Psychology 11:
160-180, 1899.
by Joan S. Lockard
Departments of Psychology & Neurological Surgery, School of Medicine, University
of Washington, Seattle, Wash. 98195
Speculations on the adaptive significance of cognition and consciousness
in nonhuman species. It would appear that the social and biological sciences,
and in particular psychology, are once again concerned with the mind/body
problem (e.g., Boring, 1957). The issues are not as philosophical as they were
near the turn of the century, but the questions being addressed are similar in
intent. As before, the most salient inquiry is whether humans are unique among
the numerous species of animals in possessing self-knowledge, in being aware of
their own existence and in using such detachment to some survival advantage.
Although the gist of the answer is less decidedly a no than it was some sixty years
ago, the discourse still has the flavor of human centricity more than of science.
Whatever the reasons - for example, more positive data, a concern for the
welfare of animals, or a need for people to feel a part of nature - nonhuman
animals (particularly the chimpanzee) are being championed as possessing
cognition (as well they might) and, with less certainty, as being part of a
continuum in this regard which culminates in Homo sapiens. As with any obvious
change in scientific dictum, there comes an overemphasis of the new position,
with straw arguments (or dated information) put forth so that they may be struck
down by the weight of "new evidence." For example, such a tactic was being
employed when G stated that "The standard response of a behaviorist is to insist
that only external contingencies of reinforcement are of any interest, at least to
him."
However, it is not so much what is being said in these exchanges that is
disturbing, as what has been omitted, both in the debates of earlier times (out of
possibly a lack of data) and in the more recent discussions for which there is no
ready excuse. No reference has been made as to the adaptive significance of
cognition and consciousness in nonhuman species. The focus has been either to
show that certain animals to have mental processes akin to man's (e.g., P&W) or
to use animals as models (e.g., SR&B) whereby some understanding of human
communicative mechanisms (essentially verbal language) may be derived. Little if
any effort has been directed toward seeking answers to questions as to why and
how natural selection may have operated to predispose certain species to
"think" and apparently not others, or as to what significance such capabilities
may have in the perpetuation of those animals. As in the quest for "general laws
of learning," the hunt has begun for "general laws of mental processes." While
motivation of this sort may be admirable and may, in time, even lead to a better
understanding of brain circuitry, the importance of biological evolution is once
again largely ignored.
What an animal is, or if it is capable of cognition and consciousness, is a
function of its ancestry and the ecological selective pressures of the past that
have shaped its genotype and influenced its phenotype. The behavior or
physiology of an animal is independent neither of its proximal experiences nor its
distant genetic history. In retrospect, therefore, it is not surprising that chimpan-
zees are unable to acquire most verbal symbols (Hayes and Hayes, 1954 op. cit.
SR&B), given their particular vocal anatomy, while ASL signing (Gardner and
Gardner, 1969 op. cit. SR&B) has met with somewhat greater success. Anthro-
poids such as chimpanzees have an evolved repertoire of gestures and grimaces
that could preadapt them to the learning and performance of other signals
involving similar musculature and memory storage. In the same view, while
SR&B's criticism of Premack's employment of plastic chips (as being in essence
artificial symbolic instruments) seems reasonable, SR&B's research results might
have had a less favorable outcome if the training tools utilized in the learned
symbolic associations had not been "extensions of the hands." There is a body
of literature from field studies indicating that foliage (sticks, leaves, grass) is used
by chimpanzees to obtain items (mainly food) out of reach or not accessible
directly (e.g., Goodall, 1972). While it is insightful of SR&B to have proposed (and
to have found) that experience with the objects to be symbolized is important for
the recall and consistently accurate deployment of the symbols, the field data had
already suggested such an outcome. For example, whereas the chimpanzee may
be genetically predisposed toward some tool use, the efficient stripping of a
blade of grass for termite "fishing" is gradually learned by the young chimp
through watching its mother or older siblings and imitating their behavior. In spite
of the thoroughness of SR&B, the essential biological point has still been
overlooked in their captive-animal research.
Perhaps one of the most succinct statements of the application of evolutionary
theory to laboratory research has been made by Mayr (1974). He addressed
what he called "opened" and "closed" genetic programs. He did not intend a
dichotomy per se but only a relative emphasis as to whether certain behaviors are
more or less genetically fixed. Notice that individual behavioral categories are at
issue and not the animal species as a whole (although there is obviously some
correlation between the two). He suggests that ecological selective pressures of
the past (including those from other species, or even conspecifics in the case of
social species) predetermine whether specific animals are likely to be highly
invariant in some of their behaviors, or if survival instead requires a more open
genetic program. For instance, the genetic strategy in song acquisition of
parasitic birds (e.g., coo-coos) is likely to be different from nonparasitic avian
species whose biological parents are those attending the brood. Further, in social
species in which individual recognition is important, an open genetic strategy such
as imprinting assures the bonding of offspring to their mothers and provides a
template for species recognition in mating, whereas a closed program already
genetically hard-wired might be more appropriate for nongregarious, solitary
animals (as in the case of species recognition displays in certain lizards). In other
words, in seeking a research direction to ascertain whether cognition and
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4
583

Commentary/Cognition and consciousness in nonhuman species
consciousness are attributes of some nonhuman species, the first question is
whether such open genetic programs would be biologically advantageous for
particular animals given their specific social organization and ecological niche.
Taking the position of Mayr, the rest of this commentary will be concerned
largely with speculations as to the adaptive significance of mental processes and
animal awareness, or lack thereof. For the purposes of this discussion, cognition
will be regarded as necessary but not sufficient for consciousness. Moreover, the
argument will not in the least be exhaustive in terms of those species which may
eventually be shown to be cognizant of either their surroundings or of themselves
as entities. These speculations will merely be a framework in which the study of
such processes is likely to be biologically reasonable and scientifically fruitful.
Also, in no way will it be suggested that the cognitive processes which nonhuman
animals might possess are similar to, or simply less complex than, human
"thinking." Each species is a biological unit, and whereas closely related species
may have homologous processes, such generality is not the intent of this
message - in fact, the opposite emphasis is desired. If a general principle is to be
gleaned from this thesis, it is that animal species are molded by ecological
determinants, and convergent behaviors may be frequent occurrences (e.g.,
Wilson, 1975).
The first of two hypotheses to be presented considers those social species in
which individual conspecific recognition is essential for survival and suggests that
in those animals which also have relatively altricial offspring, an extended infancy
period, male/male competition for limited resources (e.g., habitats or females),
and a gregarious social organization, cognitive processes are likely. In other
words, it is proposed that species which may be capable of cognition are those
that are long-living, ecological generalists (Wasser, 1978) and depend upon
conspecifics in rearing offspring, seeking out food resources, or predator
defense. Most social carnivores (e.g., felids and canids), some primates (e.g.,
langurs, baboons, and chimpanzees) and several marine mammals (e.g.,
porpoises and whales) meet many of the suggested criteria. These animals are
likely candidates for possessing cognitive processes, since it would be either
genetically difficult to have built in all of the ecological contingencies necessary
for their perpetuation, or it would be essentially impossible to predict genetically
the outcome of competition among individuals for positions of dominance within
each species.
The second hypothesis proposes that in those cognizing species where social
deceit (see, for example, Wallace, 1973; Dawkins, 1976) is adaptive (and is not
already manifested in the physical phenotype), the capacity for consciousness,
or, perhaps more importantly, its possible antithesis, subconsciousness, is
probable. If in deceiving conspecifics one is more successful (in terms of inclusive
fitness, see Hamilton, 1964) when self-deceived as to the actual motive for their
deception, possessing a subconscious would indeed be adaptive. However,
self-deception itself, without the intent to deceive conspecifics, may be an asset,
in terms of reproductive success of the unaware organism, particularly if cognition
were under a fairly strong selective pressure for some other function. For
example, since parents and full-sibling offspring have only one half of their genes
in common, if parent/offspring conflict (Trivers, 1974) were to become exces-
sive, parents self-deceived into continuing to provide care for offspring, no matter
what the conflicts, would reap statistically greater reproductive success (all else
equal) than parents not self-deceived [cf. Rajecki, Lamb & Obmascher: "Toward
a General Theory of Infantile Attachment" BBS 1(3) 1978]. Therefore, of those
animals possessing cognition, species likely to have consciousness as well would
be ones where the mating system was polygamous and the infancy period quite
extensive. In other words, animals that compete for mates, where the male and
female mating strategies are dissimilar and where the rearing of offspring may
often have to be borne by one parent either by default (the death of the other
parent) or by design (desertion by the other parent), are good candidates for
possessing consciousness, and, by inference, subconsciousness. Until more is
known of the intricacies in social organization of land mammals such as elephants
or marine mammals such as porpoises, it may well be that the greater apes (apart
from humans), and in particular the chimpanzee, may be the few extant species
which are likely to possess an awareness of themselves as physical beings, apart
from what they are feeling and doing at the moment.
In summary, a few specific comments are in order about each of the three
papers which stimulated the present discussion. The study by SR&B (and in light
of their succinct review of the status of the literature on symbolically mediated
behavior in chimpanzees) may well constitute, apart from descriptive field data,
"the first instance of symbolically mediated exchange of goods and information in
a nonhuman species." However, it is surprising that they may have expected their
subjects to perform better than they did with the keyboard turned off. Given that
these researchers demonstrated the importance of experience in symbolically
mediated behavior, the outcome of only some 10 percent correct with the
keyboard off should have been predicted by them. If their subjects were to be
given training in improvising, either by means of alternative symbolic media or
iconic gestures, these authors might well find that chimpanzees have the capacity
to learn to employ such detours and even make up some of their own.
The paper by P&W is an example itself in creative thinking. Without the
experience themselves in trying to outsmart the chimpanzee, the ingenuity in
research design shown in their article seems unlikely to have materialized. From
the point of view of an animal behaviorist, however, how much more esthetic it
would be if the test tapes involved conspecifics solving more "naturalistic"
problems for the chimpanzee than the everyday trivia and frustrations of humans.
If for no other reason than that it would appear to be less anthropomorphic,
symbolic mediation demonstrated between two or more chimpanzees, rather
than a chimpanzee's interpretation of staged human behavior via videotape, is
somehow more desirable.
As for the paper by G on the prospects for a cognitive ethology, the objective is
academically worthy, but the interpretation of the evidence he rules as supportive
is largely intuitive. For example, many ethologists would undoubtedly not concur
with his alternative explanation of the bee dance. Moreover, a lack of theoretical
parsimony seems to permeate many of his arguments. His personal philosophy
that "animal awareness, if it occurs, is also important for our definition and
understanding of the human condition" is not scientifically debatable. It is, though,
not the usual reason expounded by colleagues for studying animal behavior,
including cognition. In this regard, it may be that G is less self-deceived as to what
motivates behavioral scientists than they themselves are willing to admit, at least
in a public forum.
REFERENCES
Boring, E. History of experimental psychology. New York: Appleton-Century-
Crofts, 1957.
Dawkins, R. The selfish gene. New York: Oxford Univ. Press, 1976.
Goodall, J. van Lawick. A preliminary report on expressive movements and
communication in the Gombe Stream chimpanzees. In Dolhinow, P. (ed),
Primate patterns, pp. 25-84. New York: Holt, Rinehart and Winston,
1972.
Hamilton, W. D. The genetical evolution of social behaviour. Journal of Theo-
retical Biology 7:1-52, 1964.
Mayr, E. Behavior programs and evolutionary strategies. American Scientist
62(6):650-659, 1974.
Parent-offspring conflict. American Zoologist 14:249-264, 1974.
Wallace, B. Misinformation, fitness and selection. American Naturalist
107(953): 1-7, 1973.
Wasser, Samuel K. Optimal consorts: A function of complementarity and re-
latedness. Paper presented at the Annual Meeting of the Animal Behavior
Society, University of Washington, Seattle, June 1978.
Wilson, E. O. Sociohiology, the new synthesis. Cambridge, Mass.: Harvard
Univ. Press (Belknap Press), 1975.
byB. M. l
Department of Communication and Neuroscience, University of Keele, Staffs., ST5
5BG, England
Evaluation as an indicator of intention [G]. I agree with so much of G's
commonsensical analysis that I have only a little to add by way of qualification.
1. The case for "reopening these long neglected questions" seems to me
unanswerable. If the behavioristic Zeitgeist has in some quarters been allowed to
smother them as "unscientific," this only highlights the dangerous extent to which
the Church Scientific has (in these quarters) allowed itself to become priest-
ridden.
2. To characterise the approach sketched by G as "materialistic," however,
would I think be misleading. His main point seems to be that questions about
mental experience in animals can be scientifically pursued by methods which use
essentially mechanistic concepts. I agree (MacKay, 1965, 1972). But as the
literature of "Artificial Intelligence" bears witness, it is possible to take a
mechanistic approach to cognitive processes even at a "software" level, to
which the dogmas of metaphysical materialism are totally irrelevant; and I believe
that the adoption of such a methodology is no more incompatible with theistic
than with materialistic assumptions (MacKay, 1954, 1966, 1978).
3. This point is well illustrated in relation to what G claims that "thoroughgoing
materialists" believe or accept as a working hypothesis. A "thoroughgoing
theist" could be no less ready to assume that the events we call "mental
584
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4

Commentary /Cognition and consciousness in nonhuman species
experiences" have direct correlates in physical brain processes, and to look at a
mechanistic level for the difference between brain processes that are and are not
correlates of conscious experience. I would argue, however, that the appropriate
level at which to look for such differences is not that of brain physiology as such,
but rather that of the information-flow-structure sustained in and by the physiologi-
cal activity (McKay, 1966, 1978) [cf. Puccetti & Dykes: "Sensory Cortex and the
Mind-Brain Problem" BBS 1 (3) 1978].
This choice of starting level can crucially affect the kind of hypothesis that
suggests itself for scientific exploration. Those who start with the mass of
simultaneously ongoing physiological processes tend to speculate whether it
could be the anatomical location, or the chemical constituents, or perhaps the
pattern of firing, that offer certain material processes the privilege of "generating
mental experiences." Suppose, however, that we start at the level of our
conscious experience itself, and then ask what programmatic correlates we might
expect at the system-engineering level of our CNS. The whole enterprise is now a
different one, and moreover one to which the details of our conscious experience
can be expected to make scientifically useful contributions as we discover the
relevant information-engineering questions to ask of it.
To reuse a well-worn analogy (MacKay, 1965), I am suggesting that looking for
the physiological correlates of conscious experience is rather like looking for the
electronic correlates of some abstract mathematical property of an equation
being solved on a computer. To start at the level of the transistors would be
scientifically inept, not because in principle it could never succeed, but because
methodologically it would be a bad gamble. Only by starting at the mathematical
end, and exploring hypotheses as to the programming structure and the encoding
scheme, could we have a reasonable hope of finding what distinguishes the
requisite physical correlates from all the other physical activities in the mechanism
[cf. Haugeland: "The Plausibility of Cognitivism" BBS 1 (2) 1978].
4. I agree with G that we should try to design tests for mental experience in
lower animals by analogy with those found appropriate in our own case. Although
it would be nice to use the growing communicative repertoire of apes, however, I
do not see this as an essential experimental tool. I suggest that the key feature of
conscious mentality in ourselves is not communication, or activity in view of ends,
or even evaluation of situations, but rather evaluation of priorities, or if you like,
self-evaluation on the part of the evaluative system. This is what makes possible a
rational (as distinct from an irrational or an unconscious) change of our priorities.
Unless there were reason to hold a priori that this process has no analogue
within the information systems of subhuman species, it would seem unwarranted
to deny them some degree of mental experience. The hypothesis I would favour is
that what distinguishes the human brain is its capacity for forming and manipulat-
ing representations of representations. This does not exclude the possibility that
nonhuman animals might "know what they are doing," but does set presumptive
limits to the degree of insight they might have into what they are doing - the level
of abstraction at which they could think about themselves as agents and above all
as evaluators.
5. In these terms, the key test of "intention to communicate" would be a
variational one (MacKay, 1972): In what way, and to what extent, would the
sender's internal evaluative indices be disturbed by evidence that his signals were
not having the "intended" effect on the recipient? This again is essentially a
mechanistic criterion, which in due course might even hope to have a direct
physiological application.
REFERENCES
MacKay, D. M. On comparing the brain with machines. American Scientist
42:261-268, 1954.
A mind's eye view of the brain. In Wiener, N., and Schade, J. P. (eds.), Cy-
bernetics of the nervous system: Progress in brain research 17:321-332.
Amsterdam: Elsevier, 1965.
Cerebral organization and the conscious control of action. In Eccles, J. C.
(ed.), Brain and conscious experience, pp. 422-445. New York: Springer-
Verlag, 1966.
Formal analysis of communicative processes. In Hinde, R. A. (ed.), Non-ver-
bal communication, pp. 3-25. Cambridge: Cambridge Univ. Press, 1972.
Selves and brains. Neuroscience 3:599-606, 1978.
by Roger L. MeSlgren and Roger S- Foyts1
Department of Psychology, Institute for Primate Studies, University of Oklahoma,
Norman, Okla. 73019
Mentalism and methodology. A rigorous, behavioristic cognitive ethology [GJ?
G's article has many cogent arguments supporting the position that the influence
of behaviorism has led to a rather myopic view of behavior by limiting its
examination to those aspects that are not considered to be mentalistic. In our
opinion G is certainly correct in this position. Naive behaviorism has severely
limited the questions a behavioral scientists could examine with impunity. As a
result, many important and interesting behavioral characteristics of nonhuman
species have traditionally been ignored. G is careful to note that when studying
behaviors previously considered mentalistic one should be very careful to use
proper methodology and controls. In other words, although behaviorism has
inhibited scientific investigation in the past, it has at the same time developed a
rigorous methodology that is invaluable to worthwhile research. This methodology
should never be comprised, otherwise the research will have no more scientific
value than the anecdotal method as used by Romanes, which was the stimulus
against which behaviorism reacted.
Would you mind a theory fP&W)? P&W's article can be viewed as an attempt
to follow G's suggestions. It is a refreshing reminder of the early Kohler
experiments on the mentality of apes and it is certainly a welcome return to an
area of research that did not gain the acceptance or establish the scientific
traditions that other behavioral approaches did. P&W are certainly examining
interesting questions with regard to the chimpanzee mind. Unfortunately they
seem to have been carried away by the exciting and interesting prospect of
exploring heretofore taboo topics of theory of mind (e.g., intentionality and
empathy), while forgetting the cautions of G and the valuable legacy of behavio-
rism in terms of providing well-controlled experiments using proper methodology.
As a result, P&W's interpretation of the results of their experiment is questionable
because of certain methodological oversights.
For example, P&W presented Sarah with four different problems six times
each. In the first set of four problems Sarah missed one and got three correct.
The expected chance level of responding would be two correct and two
incorrect. P&W collapse across the six presentations, presumably assuming that
they were independent presentations, when in fact they were not. Only the first set
of four problems would be independent; after this Sarah is now informed and
could simply respond by choosing the same alternatives she chose on the first set
(which is exactly what she did on the second and third presentations). SR&B
indicate that Sarah could respond correctly after one presentation on ten
separate discrimination problems, supporting the contention that after the first
trial the choices are not independent. As a result, the probability value for Sarah's
performance is .25 rather than the rather impressive p < .001 as reported by
P&W.
Another problem is that P&W did not run the proper control conditions. Sarah
should have been pretested with the two-picture choice problem prior to testing
with the videotape. This would have established what pre-experiment bias these
pictures had for Sarah. For example, a picture of a key might have intrinsic value
for a caged chimpanzee. Had this been done, these choices could have then
been compared to choices Sarah made under testing conditions.
A final point concerns P&W's method of controlling for social cues. The
method was for the trainer to take a box holding the two pictures (counterbal-
anced for position) into Sarah's cage, set it down, and leave. Sarah then opened
the box and made her choice. P&W do not state who placed the two pictures in
the box prior to taking it into Sarah's cage; nor is this stated in P&W's Science
article (1978 op. cit.) where the experiment is also reported. If the trainer who
carried the box in was also the person who placed the pictures in the box or even
knew its contents, then this procedure would not qualify as a control for social
cueing. For example, it would be easy for such a person to cue Sarah
inadvertently as to which side of the box held the correct picture. Likewise, it
would not be difficult for Sarah to remember this until she opened the box.
It is unfortunate that these errors and ambiguities occurred in such a pioneering
experiment. It is likely that tough-minded behaviorists will view this as nothing
more than a continuation of the sloppy mentalistic experiments of the past, which
is a justified conclusion because an exciting research topic cannot replace sound
methodology.
Observations, anecdotes, and monologues with a computer [SR&B]. SR&B
present an interesting analysis of how the meaning of a word may be acquired by
a chimpanzee. The word "key" first represented food in an adjacent locked
room; then, with the introduction of a new food site, it was applied (incorrectly) to
this site, so that it was then relegated to applying only to the "food in the adjacent
locked room" situation. The chimp did not use the word for key when a locked
box was introduced, although he did use a key to try to open the box. After
learning that the word "key" could be used to obtain a key for unlocking the box,
the chimp successfully used the "key" word to represent a key in new test
situations. Lana, a much more experienced chimp, did not go through these
stages in learning what the word "key" meant, but was able to acquire
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4
585

Commentary/'Cognition and consciousness in nonhuman species
immediately the appropriate meaning of the tools, although no definitive reasons
for her ability are offered. Eventually, two chimps were able to learn the names of
six objects and to request them through a keyboard button press or to deliver
them to an experimenter when requested to do so.
Unfortunately, the main point of the SR&B report seems to be chimpanzee-
to-chimpanzee communication. The experiment fails to demonstrate any such
communication, except for one reported anecdotal episode. The experimental
procedure consists of having the chimpanzee request a tool from the other
chimpanzee, the requester then obtaining the food and sharing it with the
tool-provider. That a chimp would willingly share any amount of food with another
chimp is surprising in itself, although not germane to the question at hand. The
"control" to show that the two chimpanzees were actually communicating with
each other was to turn off the keyboard. This seems much like teaching a person
to drive a car and then removing the steering wheel. It tells us absolutely nothing
about chimp-to-chimp communication. To find out the degree to which the chimps
were interdependent on each other (as opposed to communicating with a
machine), what should have been done was to have an automatic dispenser send
the requested tool down a chute into the requester's grasp and to have the
computer programmed to request tools from one of the chimps so that if the
chimp put the appropriate tool through a hole in the wall, it would deliver some
food to the chimp a little later. Would the performance accuracy be affected in
any way? We doubt it. The communication between chimpanzees is limited to
monologues, with one chimpanzee requesting and the other complying. One
piece of evidence that the presence of another chimp is important (as opposed to
a computer or a tool delivery mechanism) is an anecdote:
". . . on one trial Sherman requested key erroneously when he needed a wrench.
He then watched carefully as Austin searched the tool kit. When Austin started to
pick up the key, Sherman looked over his shoulder toward the keyboard, and
when he noticed the word key, which he had left displayed on the projectors, he
rushed back to the keyboard, depressed wrench, and tapped the projectors to
draw Austin's attention to the new symbol he had just transmitted."
This richly-interpreted anecdote (italics added to emphasize the richness of the
interpretation) is the best evidence SR&B have to indicate that the chimps are
communicating with one another, as opposed to the computer. SR&B incorrectly
state that such anecdotes are the only data "suggesting that Washoe and other
signing apes are producing anything more than short-circuited iconic
sequences."
The vitriolic attack by SR&B on Project Washoe might seem puzzling to the
reader familiar with the published reports of the Gardners and Fouts, and seems
rather difficult to explain purely in terms of objective science. It is ironic that SR&B
present their most interesting result as an anecdote (see above). Apparently one
investigator's "observation" turns into an anecdote when seen through another's
eyes.
NOTE
1. Order of authorships was determined by the flip of a coin.
by E* W. Menzel, Jr= and Garcia K. Johnson
Department of Psychology, State University of New York at Stony Brook, Stony
Brook, N.Y. 11794
Should mentalistic concepts be defended or assumed? Although we consider
ourselves cognitivists of sorts, and although we would have been at least 75
percent favorable toward any one of the target articles taken separately, together
they had a cumulative effect which has left us uneasy and wondering what is in
store for animal psychology in the future. Indeed, the harder we have struggled
with the authors' treatment of awareness, intentionality, language, symbolism,
iconicity, self concept and animals' theories of mind, the more inclined we are to
concur with Popper: "One should never quarrel about words, and never get
involved in questions of terminology. One should always keep from discussing
concepts. What we are really interested in, our real problems, are factual
problems, problems of theories and their truth" (Popper, 1972, p. 310). Perhaps
the difficulty is that all-or-none questions such as "Do animals have awareness?"
or "language?" create qualitative if not artificial dichotomies of what are
psychological continuities, and run the risk of obscuring as much as they clarify.
Are mentalistic concepts useful? Until the advent of behaviorism and ethology it
was generally assumed that the study of behavior was of interest only insofar as it
could be shown to shed some light upon mind. Today the situation is to some
extent reversed. The prediction and control of behavior is one of our major goals
(for some it is the sole goal), and there is a tendency (illustrated in all three
articles) for people interested in the functioning of minds either to try to make their
questions sound as behavioristic as possible or to try to set them up in direct
opposition to behaviorism. Is it really necessary, however, to bow to or to flail at
this demon? Why not simply say that what constitutes a useful, interesting, or
fruitful question depends upon one's point of view? From our point of view,
mentalistic questions or concepts need no more defense than behavioristic
questions need defense for a behaviorist. As a matter of fact, even if it should
prove possible to predict and control 100 percent of the variance of behavior as a
nonmentalist defines it, this would not necessarily tell us anything we care to
know. Consider, for example, a man who is falling from a tower. Where is he
going? From the point of view of physics, a Newtonian account would be just as
accurate and complete for the man as for a stone (assuming, of course that the
man has no parachute); but it would say nothing about whether or not the man
was going to his death (a question that we would not even pose in the case of the
stone and that could not be answered by a Newtonian physics), let alone whether
he was aware of this fact but perceived it as going to meet his maker and to a
new life (questions that we would not ask about most animals or even about an
anesthetized human).
The most important function of theories in our present state of ethology and
psychology is not that they summarize knowledge already obtained but that they
serve a guiding function, affecting the sorts of new hypotheses we propose and
the sorts of new data we collect. In this respect cognitive approaches need no
defense - or at least, no more than any other approach.
Defining mentalistic concepts. The idea that it is possible to identify mind (or
awareness, or what have you) is not substantially different from a naturalist's
belief that it is possible to identify "life," a behaviorist's belief that it is possible to
identify "real behavior" as opposed to simple motion, or a linguist's belief that it is
possible to identify "language." None of these terms refer to physical objects as
such; they all refer to processes that we attribute to some objects or beings and
not to others. While G initially suggests that it does not seem necessary to be
overly concerned with formalistic definitions (and we agree), he then seems to
encourage this very formalism. Ostensive definitions probably work just as well,
but it is important to remember that at least two such definitions are possible and
each alone has serious limitations. On the one hand, following the logic of Turing
(1950) one can simply produce or point to one or more specimens (A) to which
most scientists would unquestionably attribute mind, intent, or what-have-you.
Other specimens (B) about which we are unsure are then assessed against this
norm. To the extent that one would find it difficult or impossible to discriminate
between the performances of competencies of B and A, we would accept the null
hypothesis of no difference and (by definition) attribute to B whatever specific
process in question we attributed to A. Today, of course, the accepted norm (A)
is a "normal adult human being" (some would even say a linguist), and B is
anything else, for example, a computer, a one-month-old child, a chimpanzee. As
we see it, all students of "chimpanzee language" operate on this Turing logic
(Menzel, 1978). The target articles by SR&B and by P&W are cases in point.
On the other hand, following the inverse of Turing's logic, we might produce or
point to a normative specimen (A) to whom we would definitely not attribute the
internal process in question. A stone or a gas molecule that is moving purely in
accordance with the known "laws" of physics, chemistry, or "chance" is a simple
case in point; a computer simulation is a more complicated case. The perform-
ances and competencies of an unknown specimen (B) may then be compared
against those of A, and if we cannot discriminate between them, we assert that
there is no basis for rejecting the null hypothesis of "no difference, therefore no
mind (etc.)." Williams (1966) says we know we are dealing with life when, in order
to achieve an adequate explanation of what we see, we are forced to invoke
principles above and beyond those of physics and chemistry, which apply to all
objects in general. To expand on this, we know that we are dealing with sentient
life when we must invoke still more specialized principles, above and beyond
those that apply to all objects in general, and to all living things in general,
including plants and . . . (here already the list grows problematical).
Quite obviously, whether we use the performances of adult humans or of rocks
as our definitional criteria for abstract concepts rests on conventions which are
apt to change from time to time and on which there is less than 100 percent
agreement at any one time. These conventions (including what performances on
the part of A and B are critical to an issue) are philosophical and sociological as
well as scientific. Which of these criteria is most fruitful may depend on the issue
being addressed; however, it is safe to say that keeping both in mind is apt to be
less limiting than concentrating on either one alone.
Can one animal take into account the behavioral and cognitive capacities of
another? It is hard for us to imagine how any animal could survive otherwise. We
therefore concur with P&W that this question should be answered in the
586
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4

Commentary /Cognition and consciousness in nonhuman species
affirmative. We have developed our own argument in some detail elsewhere
(Menzel and Johnson, 1976 op. cit. G). It should, however, be noted that even
nonmentalistic accounts of evolutionary epistemology would have no quarrel with
such a position. In the evolutionary sense, animals, and even plants, are problem
solvers. The conjectures and tentative solutions that they incorporate into their
anatomy and their behavior are (if one chooses to use such terminology)
biological analogues of theories, and vice versa (Campbell, 1974; Lorenz, 1977;
Popper, 1972). Just where one is justified in attributing to animals phenomenolog-
ical understanding of others, or theories of mind in the literal, anthropomorphic
sense, is an interesting and open question; and there are not many animal
researchers who have addressed themselves to this question as directly and
explicitly as have P&W. However, we would suggest that the important issue is not
whether animals have "theories of mind" but what these "theories" are, how they
came to be "formulated," and so on. We would emphasize that certain concepts,
seen in the overall context of the animal's natural behavior, including its economic
situation and biological and social history, do not seem so strange or mystical as
they might when proposed in the abstract.
As another example, take the question: Can animals withhold information or
lie? If by "withholding information" one means inhibiting one's response under
circumstances in which another animal might profit more than oneself from this
response (or in which one might stand to lose a good bit), then withholding of
information is common, if not ubiquitous (see Dawkins and Krebs, 1978). Why
else, for example, do many animals "freeze" at the first sign of a predator? Here,
as in many other "mentalistic" issues, the presumed special status of information
withholding - or prevarication, for that matter - tends to obscure the similarity
between this problem and the general one of assessing perceptual and concep-
tual categories and capacities of animals, or indeed of humans.
Is human language the archetypic communication event or the archetypic
cognitive event? All three of the target articles seem to imply that human language
is the archetypic communicative or cognitive phenomenon. In our opinion, such a
position generates a number of pseudo-questions that deflect research away
from more interesting and fundamental questions. One of these pseudo-issues is
"What is language?" Quite possibly because they are so concerned with this
issue, students of "chimpanzee language" (see also the symposium on this topic
in Harnad, Steklis and Lancaster, 1976 op. cit. G) seem to be the most severe
critics of each other's work. SR&B in particular seem to require far deeper
understanding on the part of other investigators' chimpanzees before they use
the terms "communication," "language," or "intent" than could easily be
demonstrated for most humans.
Adequately operationalized concepts are, of course, critical for studying
psychological processes. However, one can operationalize away the main point
of an idea. For example, SR&B emphasized the importance of finding context-free
demonstrations that the chimp has knowledge about arbitrary relationships
between signs and the things they stand for, which sounds to us like S-R
psychology revisited. They also seem to imply that reliance upon recall cues
make a performance less like language. This is part of the source of their criticism
of American Sign Language as a vehicle for studying language in the chimpan-
zee - the signs resemble the things they stand for (iconicity). It is as if they require
the animal to talk out of context and hopefully without reference to memory
before pronouncing the act "language." Suppose an Englishman visited France
and was able to communicate by constantly referring to an English-French
dictionary (or a vocabulary list). Or suppose our traveler has used some
mnemonics to learn words and could remember them only when external cues
reminded him of his mnemonics. We would probably say that the person was not
very facile, but not that he wasn't engaging in language. The issue of "iconicity" is
a particularly big Pandora's box because it assumes, with no evidence, that we
know the basis on which animals judge similarity (and how judgments of similarity
are made is probably a more fundamental question than whether a particular
communication meets a formalistic definition of language).
Part of the impetus to focus on language probably comes from the prevalent
view that linguistics has rescued people (and might similarly rescue animals) from
behaviorism. Thus there is a tendency to pit ideas like rules, which have figured
saliently in linguistics, against ideas like generalization, which have figured
saliently in associative and behavioristic theories. But these are not mutually
exclusive ideas. A number of people working within associative frameworks
would be quite comfortable with the notion that rules are applied to information
that builds up according to associative principles. With respect to P&W's
discussion, we would also suggest that the idea of rules is really no more specific
than the idea of generalization. Finally, recent work on natural categories (e.g.,
Rosch, 1975) highlights the fact that many of our concepts do not have a neat
rule structure. The idea, therefore, that understanding and communication are
governed by rules may not by itself take us much further than the idea that they
are governed by generalization from past experience.
In a similar spirit, the SR&B paper seems to imply that appropriate use of signs
or symbols is somehow not a good criterion for inferring what they call "semantic
comprehension." From a functionalist point of view, it is hard to imagine a better
criterion. However, it is generally true that the adoption of linguistic-style analyses
of meaning for psychological purposes has tended to lead toward an overly
"taxonomic" view of meaning. For example, suppose a man is shown an apricot,
some wheat, and an apple, and asked to choose the odd item. If he grew up on a
farm, he might say apple is odd because apricots and wheat both ripen in the
spring and apples in the fall. We wouldn't want to say he responded nonsemanti-
cally because he didn't respond according to conventional taxonomic categories
of fruits and grains. It would seem to be reasonable as a general approach to
simply assume that animals are responding "semantically," and then to try to find
out the basis of their responses. That is, how do they organize the world? An
argument can be made that all signs are symbolic (even the dinner bell) and the
interesting questions are: what do such signs signify to various individuals or
species? how did they come to signify what they do? what are the implications of
a given cognitive structure? and so forth.
Would any new ethical questions arise if animals could be shown to "have
language" or to be "aware?" We see no reason why ethical considerations
should wait upon, or be subordinated to, "openminded" scientific research that is
conducted in strict accordance with Lloyd Morgan's canon. Indeed, in our
treatment of animals as well as people we see every reason to adopt the
opposite of Morgan's canon: "Assume until proved otherwise that others are just
as intelligent, complicated, and so on, in their own way as you are in yours. And
be very skeptical of your own motives and intellect if you think you have proved
otherwise." As a matter of fact, even in some areas of scientific research this
constitutes the more appropriate "null hypothesis." The study of "animal
language," after the fashion of the target articles, may have, if anything, tended to
increase rather than decrease expectations of human chauvinism and presumed
"biological superiority," especially in the popular press, where it is more and
more often suggested that chimpanzees, gorillas, and perhaps dolphins may
deserve special consideration based on the outcome of research projects
demonstrating their similarity to humans. The poet Robert Frost, noticing the
apparent fear reactions of a paper mite, spared its life and wrote, "I have a mind
myself and recognize / Mind when I meet with it in any guise." While we would
question the usefulness of his statement if it were given as the principal
conclusion of a scientific paper, it does not seem inappropriate as a starting point
for ethics, or for a cognitively oriented ethology or animal psychology.
REFERENCES
Campbell, D. T. Evolutionary epistemology. In Schilpp, P. A. (eel.), The
philosophy of Karl Popper, pp. 413-463. LaSalle, 111.: Open Court Press,
1974.
Dawkins, R. and Krebs, J. R. Animal signals: Information or manipulation? In
press, 1978.
Lorenz, K. Z. Behind the mirror. London: Methuen, 1977.
Menzel, E. W. Implications of chimpanzee language-training experiments for
primate field research - and vice versa. In Chivers, D. J., and Herbert, J.
(eds.), Recent advances in primatology: 1. Behavior, pp. 883-896. Lon-
don: Academic Press, 1978.
Popper, K. R. Objective knowledge. Oxford Univ. Press, 1972.
Rosch, E. Cognitive representations of semantic categories, journal of Experi-
mental Psychology: General 104:192-233, 1975.
Turing, A. M. Can a machine think? Mind 59:433-458, 1950.
Williams, G. C. Adaptation and natural selection. Princeton: Princeton Univ.
Press, 1966.
by Jylius M. Morawcsik
Department of Philosophy, Stanford University, Stanford, Calif. 94305
Can the concept of cognition bear the weight psychologists place on it? [G,
P& WJ Today there is a lot of interest in experiments testing the so-called
cognitive skills of animals. These experiments typically involve planning, tool
using, complex expectations, and responses mediated by the use of what are
allegedly symbol systems. The interest, however, centers often not on the intrinsic
value of the work, but on its alleged connection with sweeping questions
concerning the uniqueness of the human species, ethical issues, and the
evolutionary hypothesis. The articles by P&W and G give us an opportunity to
place the work on animal cognition into proper perspective.
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4
587

Commentary/Cognition and consciousness in nonhuman species
P&W's results and "theories of mind." The experiments described in this paper
show that a chimpanzee can find solutions to someone else's problems, and she
can ascribe good or bad possible alternatives in a hypothetical case to an agent,
depending on whether she likes the agent or not. P&W interpret the data as
showing that the chimp ascribes mental states to herself and to others, and thus
has a "theory of mind."
The difficulties lie not in the experiments, but in the interpretations. There are
two distinct grounds for attributing mental states to ourselves. One of these is
experience and introspection. The other is that such attributions might help to
account for behaviour and capacity. P&W ignore this distinction, and concentrate
only on the latter ground. But it remains to be shown that imputing mental states
to others would be a "natural" way to account for behaviour even if we did not
have the direct experiential evidence in our own case. Thus, from the mere fact
that the chimp seems to attribute purpose to agents in certain situations we
cannot conclude that in the chimp's case, too, this involves the attribution of
mental states to others. P&W argue that behaviourism is an "unnatural" view for
humans, requiring considerable sophistication. But this does not show that
behaviouristic interpretations - especially of purpose - might not be more natural
to the chimpanzee. It depends on whether the chimp has the same direct
experiential base for concluding that it has mental states as we do; but that is
precisely the issue in question. Mere behavioural evidence will not settle the
matter.
A similar overinterpretation is to be found when P&W say that Sarah's choice
"may be intended as an answer to any of three questions: What would the human
actor do if in this situation? ..." The crucial issue is, however, not whether we
may interpret the response in this manner, but whether we must do so. A small
child can exhibit the skill of knowing how another child would solve a jigsaw puzzle
without necessarily having the capacity to process questions of the sort P&W
pose here.
I also have doubts about the attempted behavioural contrast that is supposed
to compare "guess" with "know," but lack of space prevents me from articulat-
ing the doubt. (Roughly, the point about whether someone knows or not is not
simply whether he has the required evidence available but whether he uses it; and
in P&W's proposed setting, nothing guarantees that.)
To sum up, my main question is why experiments that have obvious intrinsic
merit need to be tied to such nebulous notions as "theory of mind" and
"imputation of mental states."
Animal psychology and the "big questions" [GJ. The article by G answers the
question raised at the end of the previous section. For he claims that determining
the nature of animal thinking will have crucial bearing on the following issues: (a)
human uniqueness and our place in the universe; (b) whether general learning
principles apply across human and animal learning situations; and (c) ethical
issues concerning the treatment of animals. Furthermore, G sees as the critical
issue whether or not "the differences between men and animals in this respect
are qualitative and absolute. ..."
I find the notion of "qualitative and absolute" unclear. Suppose that we find that
in terms of formal complexity there is a striking difference between the grammars
of natural human languages and animal communication systems. Suppose,
furthermore, that in terms of logical complexity there is an equally striking
difference in semantic expressive power. Would such differences count as
"qualitative and absolute?" If not, why not? Why is it necessary to link the phrase
"qualitative and absolute" to such hazy and ill-defined questions as: "can
animals (or humans?) think?" or "can animals (or certain humans) use
language?"
There is another problem with G's methodological assumptions. He writes as if
the only choices were either behaviourism or the view that mental states are
known directly through introspection. There is a third alternative, however, and it
seems to me to be more plausible than either of the two that G considers.
According to this view, some of our key cognitive processes, such as calculation
or language processing, are not fully knowable directly, either via introspection or
via behavioural evidence. Hence we can study them best indirectly, by concen-
trating on the properties of the abstract objects that these processes can deal
with.
Returning to the "big questions," I find their link to work on animal thinking
doubtful. It is one thing to say that we are interested in what are, for humans,
species-invariant capacities, and another to lay such heavy stress on uniqueness.
Why is uniqueness so important? I shall not value human freedom and dignity less
if it turns out that we share of what we take to be unique features with dolphins,
chimps, or beavers. Furthermore, if the differences turn out to be on the order of
what I have sketched above, that will be quite sufficient to show that general
principles of learning do not carry across species. Finally, my care and concern
for animals in general, and endangered species in particular, or for matters of the
ethics of animal experimentation, would not diminish if we found what G regards
as "absolute and qualitative" differences. Philosophically, I would argue for a
general respect for life in all of its manifestations. The expression of this respect
will, obviously, depend on what we happen to know at any given time about
different types of living creatures.
Conclusions. Cognition is a many-splendoured thing. It includes a variety of
competences such as concept formation, reasoning, information processing,
symbolic representation, and so forth. These capacities are not only conceptually
distinct; it is an open question as to how tight the causal interrelations are. Today
there is a lot of talk of cognition, cognitive science, and the like [see Haugeland:
"The Plausibility of Cognitivism" BBS 1 (2) 1978]. If this means simply that the
capacities listed above will be subjected to interdisciplinary study, then it is all to
the good. But this must not mean that terms like "cognition," or "thinking" will be
key terms in scientific theories; these terms are neither sharp enough nor tied to
empirical evidence with sufficient clarity to bear that kind of a conceptual burden.
Work on animal psychology would probably benefit from being no longer tied to
the "big issues" that G lists. Physics benefited from being no longer considered
as having grave relevance to theological issues. Why should one not draw a
lesson from the history of neighbouring sciences?
Finally, even if my advice were to be heeded, work like that of P&W would still
be of interest to philosophers. For philosophers should ponder over the cases
that P&W describe, and ask: "if these are not cases that we would regard as
cases of thought or language processing, what is missing?" Thinking of this sort
might help us eventually to substitute a series of clearer and more sharply defined
notions in place of the current stock of concepts that haunt philosophy and animal
psychology alike.
by Adam Morton
Department of Philosophy, University of Ottawa, Ottawa, Canada K1N6N5
What to look for in comparing species. Suppose that some sign-using
chimpanzee of the twenty-first century, perhaps the result of special breeding and
evidently the result of a very special education, receives her Ph.D. in psychology
(comparative) with a thesis on twentieth-century speculation about the cognitive
capacities of her species. What will she make of papers such as those of SR&B,
P&W, and G? No doubt she will praise their intention; no doubt she will find them a
little patronising. But what will she think of the attempt that these papers make to
think through, in relation to the small amount of evidence we now possess, the
extension of some of our most impressive, and, as we once thought, characteris-
tic, qualities to other species?
Of course, to begin to tell the story this way is to beg the question. Our culture,
our science, and the skills that allow us to manage them may be so peculiar to us
that in order to have enough of them even to talk and interact socially in anything
like a human manner an organism would have to be human. Evidently, to answer
these questions we would have to understand basic essential facts about human
cognition, language, and sociality. All the grand old questions lie in waiting along
the way. It is tempting, then, to want to formulate clear definitions of those
attributes of people whose extension to other species is conceivable and then
with these definitions in mind to formulate a feasible research program towards
answering some of the basic questions. In this regard the conjunction of the
papers by SR&B, P&W, and G is extremely instructive, for G shows an acute form
of the temptation I just mentioned, and SR&B provides some interesting reasons
for resisting it, while P&W poses questions that might seem premature, were it not
for SR&B's evident need for someone to formulate them.
Grammar versus intentions {SR&BJ. Savage-Rumbaugh et al. are concerned
that the impressive data on vocabulary size and appropriateness of use of this
vocabulary, and the rather more ambiguous data on acquisition of syntax, found
in the chimpanzee work of Gardner and Gardner, Premack, and others, does not
show that chimpanzees are capable of assigning meaning to symbols in the way
that people do. The concern is that an animal's use of a sign in the presence of,
as a result of a desire for, or even because the animal is thinking of, an object or
situation, does not establish that the animal is using it with any communicative
intent. The animal may not intend that the signs be taken by an audience as
grounds for believing that the animal intends to refer to the object or situation in
question. (The exact formulation of this requirement is tricky; many variations on it
are due to the philosopher Paul Grice and his pupils.) SR&B have therefore
devised experiments in which the presence of such communicative intentions is
the best explanation of the chimpanzees' sign-using behavior.
Note in this connection that the necessity of an independent confirmation of
588
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4

Commentary/Cognition and consciousness in nonhuman species
such intentions is in part due to the uncertainty of conjectures about the syntactic
capacities of chimpanzees, for appropriate use of much of a language like English
requires that such intentions be present; they are not a further addition to using
the right sentence at the right time. For example, if one says "listen to me and try
to do exactly what I say" appropriately, then one is addressing an audience-
setting up a situation in which their response to what one says is what
matters - and presupposing that the audience is ascribing an intention to
communicate to one. But sentences like this are clearly far beyond the output of
any present sign-using animal, and therefore the experiments of SR&B, and also
P&W, are necessary.
If the possibility of an animal that can produce the output of a rich transforma-
tional grammar but not mean anything by what it produces is thus very unlikely
(and the sketchy argument in the last paragraph could at most show that an
animal is unlikely to produce and use appropriately a sufficiently rich output
without having semantical intentions), several consequences of the need for
separate verification of appropriate production and communicative intention
remain striking. The most important, I think, is the possibility that the various
syntactic, semantic, and social abilities that go into human use of language may
have no inherent unity. SR&B suggest that this may in fact be the case, by
showing that object-naming is considerably harder for their chimpanzees to learn
when the objects are presented just as perceivable objects than it is when objects
are presented as tools, as solutions to problems of manipulation. Certain
functions that objects may serve seem easier for these two chimpanzees to name
than the objects themselves. Is this part of a more general fact about chimpanzee
cognition? Does the communicative competence that these animals exhibit
depend on a connection with this particular range of tasks, manipulating objects
to achieve definite rewards? More work is needed to answer these questions. The
point that seems clearest is just how important and open a question is the one
concerning the connections among the ability to manipulate objects, the ability to
cooperate with others in manipulating objects, the ability to learn sign-object
correlations, and the ability to recognize the intentions of others to have one
cooperate with them. The openness of the question is obvious. Its importance
derives from the possibility that the relations among these skills may not be the
same in humans and in chimpanzees. If they are significantly different, then for all
the similarities there may be in what we can do, there may be no single thing
called "linguistic competence" that we share.
Does the human have a theory of mind [P&W]? To have a theory of mind is to
impute mental states to oneself and others, according to P&W. I imagine that I
qualify as having a theory of mind, according to this definition, but I am rather less
sure what this theory is. When I try to state it I only come up with trivialities. These
trivialities (and various profounder things the expression of which I usually botch)
may, for all I know, be tied together in a comprehensive implicit theory. I expect
they are, but it is possible also that all that social psychology will ever find in the
likes of me is a scattered bundle of inclinations to say that this person and that is
in this state or that. Given that this is probably false, and that different people with
different socializations have probably imposed different organizing schemes on
their inclinations to ascribe states of mind, we can ask what kind of processes
organize these ascriptions and how specific to our species they are. I take it that
this is the central problem of social psychology.
The experiments P&W describe provide what seems to me very strong
evidence that the chimpanzee they were working with had some relatively
complicated representations of the states of mind of particular humans. Their
sophisticated nature is significant, for to ascribe, say, an intention to get at some
bananas by means of a stick, is of an order of complication beyond, say,
ascribing rage, and it is precisely these more complicated ascriptions that are
needed for language use to be humanlike in the way SR&B stress. And
ascriptions of at least this complexity are required in order to have a representa-
tion of even the simplest form of social rule.
It is not as clear, though, what the form of the ascriptions or imputations is,
what the animal's relations to representations of states of mind are. Does Sarah
represent the actor as looking for the right key because of the latter's fear of the
approaching lion? Does she explain his behavior by reference to his state? If she
takes an experimeter to be a malicious liar, is she taking him just as a negative
force in her search for truth and reward, or is she representing him as acting as a
result of an intention to produce false beliefs in her? I find that my uncertainty
about what is supposed to be involved in the ascription of a state of mind to an
agent makes it hard for me to decide to what extent the alternative explanations
P&W suggest for the data presented in the earlier sections of the paper are real
alternatives; and I am also uncertain as to quite what is being conjectured in the
later sections with regard to Sarah's possible differentiation of guessing from
knowing or of fools from liars. One reason why my lack of understanding on this
point disturbs me is that the kinds of ascriptions that SR&B take to be essential to
full linguistic competence require more than a simple assignment of an intention to
a speaker, for in recognizing an intention to communicate one must take the
speaker to believe that the sentence he produces will cause the audience to
believe that he produced the sentence to make them agree to it. Here the use of
beliefs and intentions in an implicit pattern of psychological explanation, the sort
of pattern that holds together our scattered everyday ascriptions of states of
mind, is as essential as the complex content of the states ascribed.
Universal structures [G] Griffin's paper throws out possible explanations and
possible experiments right and left. I won't discuss most of them, since my
general sympathy should be clear. One very basic premise of his argument seems
to me misguided, though. It is the idea that we should take the human
commonsense categories of consciousness, language, and so on, and, after
elaborating them somewhat into definitions, try to discover to what extent they are
applicable to other species. These categories are elaborations by philosophers
of the human theory of mind that P&W are concerned with. This naive theory tells
us almost nothing about the underlying causes of consciousness or language,
and it is in comparing these underlying causes that we are likely to find surprising
resemblances and differences between species. Or, to put the point in the idiom
of recent philosophers of science, an investigation of the meaning that mental
concepts have in their present use is not going to tell one anything essential about
them. Rather, one should try to see what kinds of thing these concepts refer to.
And in this enterprise, which begins just with a description of the cases to which
the concept applies and then asks the factual question of what these cases have
in common, the essential nature of commonsense concepts is likely to be
revealed in their reduction to the scientific concepts that causally underly the
phenomena they explain.
What I would suggest then is that what psychology should do, and what SR&B
and P&W are actually beginning to do, is to see what similarities of behavior
between humans and animals can be discovered or induced, and then to
investigate the similarities and differences among the processes and skills that
underly similar behavioral capacities. When the facts are in, we shall no doubt
seem naive - and the chimpanzee reviewer of my first paragraph will no doubt
note this as a piece of typically human arrogance - in thinking that the ways we
think and speak and conceive of ourselves are the ways all thinking, speaking,
social creatures must.
by Donald A. Norman
Department of Psychology, and Program in Cognitive Science, Center for Human
Information Processing, University of California, San Diego, La Jolla, Calif. 92093
Stop already, my mind is made up [P&W]. P&W are forced into doing a large set
of experiments in order to prove what they must already know. How could they
not be right? I do not believe it possible for any intelligent organism (human or
nonhuman, animate or artificial) to learn complex tasks and problem-solving
activities without imparting cause, purpose, and intention to the participants in the
problem. But then, who am I to speak? I am a confirmed mentalist, so I am
fundamentally biased in favor of the position of P&W.
Why do P&W even bother? As they know only too well, a confirmed behaviorist
is confirmed. Nothing seems to change behaviorists' mental behaviors, and even
if they change their minds, by their own definition that is quite irrelevant. The true
behaviorist does not believe in the necessity of mind for anything, not even for
humans, not even for themselves. P&W do not have a chance.
Nonetheless, what P&W have done is important. I see emerging a comparative
theory of intelligence. Such comparative studies have long been talked about, but
all the existing studies in the literature are, to my prejudiced mind, unusually
uninformative. I simply do not know what to make of the comparative study of
animals solving various mazes. And the normal experimental tasks in the literature
are singularly uninteresting. P&W are developing techniques that might let us get
at a taxonomy of intelligent performance. I would love to see similar studies
performed on a range of animals, from the human (especially the human child),
through the gorilla, chimpanzee, and other primates, and then to the general
intelligent mammals.
Consider the dog. The household dog, jointly evolved with man for human
domestication, probably exhibits some subset of the characteristics talked about
by P&W. Now, the dogma about dogs would have them incapable of watching
television and getting much out of it. But this would not stop the clever
experimenter, for I think the type of experimental condition devised by P&W could
still be applied to dogs, with perhaps some clever variations on the method of
presentation. And from there we can go to other animals. We might finally get
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4
589

Commentary/Cognition and consciousness in nonhuman species
some experimental statement of the ranges of intellectual capacity in animals.
Today we simply do not have that. We know whether animals can solve various
mazes, we know when animals fail at double-alternation, or at various delayed
tasks. But these do not get at the fundamental basis of mind: the ability to have
different levels of consciousness and different levels of knowledge about the
world.
In doing their experiment, although P&W should act as competent experimental
psychologists, I urge them to abandon the attempt to convince the behaviorists.
The behaviorists cannot be convinced. Forget them. Any attempt to draw up a
series of experiments that logically can hold no other interpretation but that of
mentalism is doomed to failure. Worse, it is likely to distort the very experiments
themselves, forcing so many controls and so many contrived situations, that the
entire phenomenon may itself be destroyed. I am quite willing to agree with my
behaviorist colleagues that I cannot prove that my thought patterns mean
anything, or that my distinction between conscious and subconscious states can
really be demonstrated. I cannot prove this: I have tried and tried. I reside in a
department with simultaneously one of the best cognitive psychology groups in
the country and one of the best operant learning groups. The contrasting views
held by our two groups provide an interesting study in the sociology of science
and in the manner in which fundamental positions are formed and held. Please,
P&W, don't waste your time trying to convince those whose entire livelihood and
entire reputation resides in intelligent interpretation of data and of intelligent
discovery of possible artifacts so as to avoid having to become convinced.
I am a student of human intelligence and of artifical intelligence (the latter in part
deriving from the belief that I can understand intelligent behavior better if I can
learn how to create intelligent machines). In order to engage in dialogue, one finds
it absolutely essential to have a theory of the mind of other participants. Real
language simply does not describe all the thoughts and concepts one wishes to
communicate with another. Rather, we rely heavily upon the large, shared
knowledge base of the other communicant. It would be impossible to understand
stories if we could not impart intent, motive, and so forth. (Can a chimp
understand a story? I bet he can. Actually, the simple scenarios devised by P&W
are short stories.)
I have argued strongly that it is simply not possible to learn without some causal
inference. I believe that the basic law of learning is what can be called the Law of
Causal Effect: an organism will come to learn the relationship between its actions
and an outcome when it believes there to be an apparent causal relationship
between the action and the outcome. Many readers will recognize this as a
modified form of the standard "Law of Effect," one of the early axioms of
behavioral learning theory. The major change is the phrase "apparent causal
relation." By this, I mean that the organism must come to believe that what one
does produces some result. It does not matter at all whether this be true or not. It
helps if the action is located near in time or in space to the result, but it is certainly
not necessary. If I flip a light switch and a light across the room goes on, I can
learn this relationship. If I go to a friend's house for dinner tonight and tomorrow
feel sick, I impart the sickness to my friend's cooking, even though considerable
time and space have elapsed (and even though my sickness may have nothing
whatsoever to do with that food). Moreover, I believe that the very same need to
interpret people's and animal's actions in terms of their mental states is required
when we interpret the actions of the world. Thus, it is a general tendency across
all cultures to impart "mental states" to the action of the weather, or the gods, or
the general environmental happenings. As P&W point out, it matters not whether
the statement about mental activities is correct; what is of interest here is the
necessity for an intelligent creature to make such assessment.
I have argued these things elsewhere, better, and at greater length. Alas, the
arguments reside in an introductory textbook (Lindsay and Norman, 1977). Let
me close by commenting briefly upon why my best arguments and best analyses
of mental phenomena are put in introductory textbooks, and not in a literature
where my professional colleagues would normally read (and benefit from?) them.
It has to do with the same problem that P&W face in making their argument so
long and prolonged. I could not publish these ideas in the normal journals of my
discipline for two contradictory reasons. In the psychology literature, my
colleagues would claim that my statements are unproved, possibly unprovable.
My behavioristically trained friends would say, "but look, you have left out the
critical control condition. You have ignored the possible interpretation that. . . ."If
I try to publish these thoughts in journals of the discipline of cognitive science, the
paper would most likely be rejected as being so obvious as not to need saying.
You cannot prove the existence of mental events to the behaviorist, and you need
not prove it to the mentalist.
Thank you, P&W, for a fascinating set of experiments. Please go on to develop
an intelligent assessment of mental capacity. Please expand the range of animals
tested. At the very least, please include human children so that we can' make
some comparative assessment between the abilities of your research animals
and normal human children. But please, do not protest too much. The behav-
iorists are too intelligent to be convinced, so aim at a lower level: talk to us
mentalists.
REFERENCE
Lindsay, P. H., and Norman, D. A. Human information processing. 2nd ed.
New York: Academic Press. 1977.
by Karl H. Pribram
Department of Psychology, Stanford University, Stanford, Calif. 94305
Consciousness, classified and declassified. The three papers on cognition
and consciousness make somewhat different contributions. All are devoted, as
requested, to whether conscious cognitive processes are to be attributed to
animals. The most conservative statement is G's, the most radical is P&W's. G
urges that the behavioristic Zeitgeist which had inhibited inquiry into cognitive
processes in animals is past and that, "with appropriate caution," we might
"weigh the likelihood that animals sometimes know what they are doing." P&W
insist that it is obvious when one watches animals that they know what they are
doing - in fact, that it takes a very intelligent being to come up with a theory which
does away with "mind" as has been done in operationalism and the resulting
behavioristic approach to psychological problems. SR&B go further than G in
presenting incontrovertible data on the use of symbols by chimpanzees, but do
not go as far as P&W in drawing the conclusion that chimpanzees must therefore
have a "theory of mind" in mind when they use symbols.
These three contributions to this issue of The Behavioral and Brain Sciences
represent the first steps in a cognitive ethology, in comparative linguistics, and in
a science of animal mentality. First steps are always difficult, and it is easier to
fault them than to take them. The papers are based on a prodigious amount of
hard and worthwhile experimental work which, even without the carefully phrased
interpretations, would stand as major contributions. In the remainder of this
commentary I want therefore to add some data in the form of pertinent
reminiscences and provide some analysis of concepts not covered in the papers
which are, however, germane and even critical to the problem of whether it is
possible to construct a comparative cognitive psychology ("psyche" implying
consciousness), as contrasted with a science of comparative behavior.
In 1956 I was asked by Science magazine to write a lead article on my work. I
did so, and submitted a paper on "The Neurology of Thinking." The paper dealt
with experiments on monkeys with a variety of brain operations tested in a
multiple choice situation. The introduction pointed out that problem solving and
thinking were not synonymous, but that there was evidence in their prolonged
reaction time and the gestures (tentative reaches, stroking of the chin, and pulling
of an ear lobe) that our monkeys were thoughtfully approaching the more
complex portions of the problem.
The paper was promptly rejected, with only two comments: (1) the paper "did
not reflect the type of work being done in the field"; and (2) "it was generally held
that animals could not think, and that anthropomorphizing as exemplified by this
paper was dangerous and misleading." The paper was published in Behavioral
Science instead (Pribram, 1959), and also incorporated into an article in the
Handbook of Physiology (Pribram, 1960). Over a hundred additional cognitive
experiments on monkeys, using the multiple choice apparatus (which is very
similar to the graphics display used by the Rumbaughs), have been successfully
accomplished and published since (see, for example, Pribram, 1969 and 1975).
Shortly thereafter, Miller, Galanter, and I wrote Plans and the structure of
behavior (1960), in which we declared ourselves subjective behaviorists. The
book received damning reviews but seems to have been influential in allowing
cognition and consciousness to return to human psychology. Now, after two
decades, evidence is being presented that perhaps some animals do think, are
conscious, and may even go about their business of behaving with a mind of their
own! As the Brelands (1966) pointed out to Skinner many years ago, no one who
has ever trained animals can come to a different conclusion.
Were the behaviorists, then, completely wrong in what they attempted? I do not
believe so. Giving operational definitions to concepts is not a trivial pursuit. Nor is
the tackling of the complex psychological problems that they eschewed for their
590
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4

Commentary /Cognition and consciousness in nonhuman species
time. I believe that Griffin, the Rumbaughs, Premack, and Pribram have all
benefited from lessons taught by behaviorism, and have "kept the faith" in the
care with which they have defined the inferences which they draw from the
behavior of animals. When those inferences are drawn from animal behavior that
is identical (or at least very similar) to that from which mental phenomena are
inferred to take place in man, is it not reasonable to use the same concepts for
the inferences? There is a danger, of course. Mental terminology comes bag and
baggage with a host of connotations which may not be appropriate. These
connotations must be diligently carved away to leave only precise statements.
Physicists have accomplished this: Newton took such terms as force, field, and
energy from psychology and gave them precise physical meanings. No one today
faults nuclear scientists when they deliberately attribute flavors, colors, and charm
to quarks. There is humor, of course, but also a deeper reminder that, as noted
by Wigner (1969), modern physics deals with "relations among observations, not
observables." Quarks are inferences. So are the cognitions and conscious-
nesses of animals. Both physics and psychology go about their science in like
manner.
Just what do we mean when we imply that animals cognize and are conscious.
Has anyone ever objected to the statement that animals re-cognize an object,
person, or environment? Recognition is a cognitive process. Animals learn to
identify objects and patterns by discriminating between cues - the literature is full
of discrimination-learning experiments. Object identification is the test used in
clinical neurology to determine whether a patient is suffering from an agnosia.
Agnosias are disturbances of "gnosis," that is, cognition. Animals communicate,
and some, such as the apes, are adept at symbolic communication, as shown by
the Gardners, Rumbaughs and Premack. No one doubts these data, or their
importance. But are such communications linguistic?
What is at issue is whether the processes discerned in animals are different in
kind or only in degree from those of humans. If the processes are different in kind,
then terms such as "cognitive" and "linguistic" should be reserved for the human
case and not used to describe the results of animal observations and experi-
ments.
"Cognitive" and "linguistic" fare somewhat differently when the question is
asked in this manner. As noted, the operations that define cognitive processing in
animals are not readily distinguished from those that define them in humans. But
the root of the terms "language" and "linguistics" is "lingua," the tongue. Studies
of animal communication have thus far not demonstrated much similarity between
human and nonhuman speech. This is taking a purist position, but until everyone
agrees to use the term "linguistic" to refer to structured patterns of communica-
tion (or some similar definition) irrespective of modality, there is danger of being
misunderstood. When Washoe and the Gardners (1969 op. cit. SR&B) communi-
cate by gestural signs, is this language? When Bellugi-Klima (1972) and her deaf
and dumb children communicate by gestural signs, is that language? If American
Sign Language is a "language," is symbolic communication using a computer
programmed with Yerkish, a "linguistic" communication as claimed by the
Rumbaughs? There are no immediate answers to such questions because the
answers demand a consensus on an acceptable definition of language. But the
problem can be noted, and care can be taken when terms are used that are
undergoing a transition in usage - and the question can be raised as to whether
the meaning of the term "language" is in transition.
Mind is another construction that raises similar issues. Do apes have a "theory
of mind" ask P&W. Mind is derived from minding, attending, as Ryle noted in The
Concept of Mind (1949 op. cit. G). Is there any question regarding the fact that
animals attend selectively, focally, and even dividedly? Or that they mind their
owners? And if they mind, do they have "a mind"? As P&W have shown, their
behavior is uninterpretable if one does not infer that apes construct representa-
tions of their environment. Sokolov's (1963) experiments on dishabituations of
habituated orienting reactions, when used with animals as in our experiments
(see, for example, Pribram and McGuinness, 1975), demonstrate with physiologi-
cal indicators not only that such representations are formed, but that they reach
considerable complexity. Is minding - attention - then a function of such repre-
sentations? The orienting reaction is the simplest case of attending - so the
answer to that question is yes. What P&W must mean, therefore, is that
representations, since they determine minding, make up mind. What P&W say is
that we infer representations to guide behavior in humans when we see them
observing and attending. So P&W infer them to be present in animals. How can
anyone object to that?
But objections will be raised, no doubt, because "mind" connotes much more
than "minding." In fact, in other languages, such as German and French, a
comparable term does not exist. Mental is ordinarily translated into words that are
much closer in meaning to our "spiritual." Are P&W advocating "animal spirits"?
Of course not, but once again the warning should be raised, lest implicitly held
connotations destroy the force of the contribution.
Finally, what about consciousness? G addresses the problem of animal
awareness and intention. A layman reading either his book (1976 op. cit. G,
SR&B) or his paper in this issue of BBS might well react as did Granit in an earlier
commentary on another paper [Roland: "Sensory Feedback to the Cerebral
Cortex During Voluntary Movement in Man" BBS 1(1) 1978, p. 152] by wondering
why it is necessary to "break down open doors." Not only do animals mind, but of
course they are aware of their surroundings. We can quickly discern whether an
animal is conscious or unconscious, and, if conscious, what state of conscious-
ness he is in. Why could not the behaviorists let sleeping dogs lie? To deny their
sleep state was not their intention, but to deny dogs an intent to go to sleep was.
Intentional states were to be denied not only to animals but to humans as well.
Why?
As Skinner makes patently clear in Beyond freedom and dignity (1971),
intentional states imply an element of unpredictability. I would put it more
specifically: we infer intentional states when behavior becomes unpredictable
("the road to hell is paved. . . "). How can reliable inferences be reached from
unreliable data? Von Neuman (1956) wrote a paper on how reliable outputs could
be achieved by a machine composed of unreliable parts, and probability theorists
have constructed a whole statistical technology to deal with such inferences. Why
shouldn't animal psychologists use these tools in their conceptualizations as well
as in analysis of their data? Would not a Bayesian approach (see, for example,
Edwards, Lindman, and Savage, 1963) to inferring "intentions" be as respectable
a scientific endeavor as the probabilistic approach which spawned the currently
popular information processing?
G's argument, perhaps more than the others, loses force because of its failure
to make explicit the hidden connotations of the terms it advocates. Of course
animals are not ordinarily unconscious. No one would argue that point. But
whether they are intentional, self-conscious, and self-reflective remains open to
investigation (Pribram, 1976a).
The issue may seem trivial but it is not. Weiskrantz has recently reported on
patients who exhibit "blind-sight" (Weiskrantz et al, 1974). Despite repeatedly
avowing a loss of vision in the field contralateral to a surgical excision of the
occipital lobe, these patients are able to identify instrumentally the location and
shape of large objects placed within the "blind" portion of the field. H. M., Brenda
Milner's famous patient with a medial temporal lobe resection, has displayed a
complete "loss of memory" for over thirty years (Milner, 1970). Still, when tested
instrumentally by Sidman (Sidman, Stoddard, and Mohr, 1968) H. M. showed
complete retention of learned operant behavior. I have reported other incidents of
dissociation between verbal reports of introspection and observed behavior
(Pribram, 1965); and even in animals different behaviors will be displayed under
slightly different conditions. Thus, rats with lesions in the area of the ventromedial
nucleus of the hypothalamus will overeat when food is available ad libitum, but
when an inch-high barrier is placed between rat and food, these same animals will
starve [see also Toates: "Homeostasis and Drinking" BBS 2(1) 1979]. Originally,
the lesions were thought to impair "drive," a respectable but untenable behav-
ioristic concept. An inference that does fit the data is that the lesion impairs
"effort," defined in terms of work attempted and accomplished (Pribram, 1970).
Do rats make an effort? What is the difference between a memory only
instrumentally displayed and one accessible to awareness? I would like to know
and want to use animal models to find out. If animal awareness is ruled out by
behavioristic fiat, I may never gain the necessary control over variables so dear to
the behaviorist, and thus never have the opportunity to ask and answer the
question properly.
States of consciousness appear to delimit ranges of behavior in both man and
animal (Pribram, 1976b). The contents of consciousness are processed within
those limits. Experimental psychologists, including those working with animals,
have, since William James, dealt with this issue in terms of "span" - the temporal
and spatial span of attention, awareness, and short-term memory (e.g., digit
span). The processing per se has classically been the province of psychophysics
and perceptual psychology. As noted by G, these disciplines have now admitted
Images and Plans as explanatory concepts. Animals apparently perceive; to what
extent are their perceptions similar to those of humans? Both G and P&W
propose that the similarity is much greater than would be allowed by a strict
behaviorism. My view is that once the strictures are lifted and carefully made,
operationally valid inferences are admitted, the question becomes experimental
and subject to testing in the laboratory and clinic. It is this spirit of experimentation
which informs the three papers in this issue and makes them so valuable.
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4
591

Commentary /Cognition and consciousness in nonhunian species
REFERENCES
El-eland, K., and Breland, M. Animal behavior. New York: Macmillan, 1966.
Edwards, W., Lindman, H., and Savage, L. J. Bayesian statistical inferences for
psychological research. Psychological Review, 70:193-242, 1963.
Klima, E., and Bellugi, U. The signs of language in child and chimpanzee. In
Alloway, T., Kramer, L., and Ploner, P. (eds.), Communication and af-
fect: A comparative approach, pp. 67-96. New York: Academic Press,
1972.
Miller, G. A., Galanter, E. BL, and Pribram, K. H. Plans and the structure of
behavior. New York: Henry Holt, 1960.
Milner, B. Memory and the medial regions of the brain. In Pribram, K. H., and
Broadbent, D. (eds.) Biology of memory, pp. 29-50. New York: Academic
Press, 1970.
Pribram, K. H. On the neurology of thinking. Behavioral Science 4:265-284,
1959.
The intrinsic systems of the forebrain. In Field, J., Magoun, H. W., and Hall,
V. E. (eds.), Handbook of physiology: II. Neurophysiology, pp. 1323-
1344. Washington: American Physiological Society, 1960.
Proposal for a structural pragmatism: Some neuropsychological considera-
tions of problems in philosophy. In Wolman, B., and Nagle, E., (eds.),
Scientific psychology: Principles and approaches, pp. 426-459. New
York: Basic Books, 1965.
DADTA III: An on-line computerized system for the experimental analysis
of behavior. Perceptual and Motor Skills 29:599-608, 1969.
The biology of mind: Neurobehavioral foundations. In Gigen, R. A., (ed.),
Scientific psychology: Some perspectives, pp. 45-70. New York: Aca-
demic Press, 1970.
Psychosurgery. In Bradley,; P. B., (ed.), Methods in brain research, pp. 531-
544. New York: Wiley, 1975.
Problems concerning the structure of consciousness. In Globus, G., Maxwell,
G., and Savodnick, I. (eds), Consciousness and brain: A scientific and
philosophical inquiry, pp. 297-313. New York: Plenum Press, 1976a.
Self-consciousness and iritentionality: A model based on an experimental
analysis of the brain mechanisms involved in the Jamesian theory of moti-
vation and emotion. In Schwartz, G. E., and Shapiro, D. (eds.), Conscious-
ness and self-regulation, vol. 1. New York: Plenum Press, 1976b.
Pribram, K. H., and McGuinness, D. Arousal, activation and effort in the con-
trol of attention. Psychological Review 82(2): 116-149, 1975.
Sidman, M., Stoddard, L. T., and Mohr, J. P. Some additional quantitative ob-
servations of immediate memory in a patient with bilateral hippocampal
lesions. Neuropsychologia 6:245-254, 1968.
Skinner, B. F. Beyond freedom and dignity. New York: Knopf, 1971.
Sokolov, Y. N. Perception and the conditioned reflex. New York: Macmillan,
1963.
Von Neumann, J. Probabilistic logics and the synthesis of reliable organisms
from unreliable components. Automata Studies, pp. 43-98. Princeton:
Princeton Univ. Press, 1956.
Weiskrantz, L., Warrington, E. K., Sanders, M. D., and Marshall, J. Visual ca-
pacity in the hemianopic field following a restricted occipital ablation.
Brain 97(4):709-728, 1974.
Wigner, E. P. Epistemology of quantum mechanics: Its appraisals and de-
mands. In Grene, M. (ed.), The anatomy of knowledge. London: Rout-
ledge and Kegan Paul, 1969.
by Zenon W. Pylyshyn
Departments of Psychology and Computer Science, The University of Western
Ontario, London, Ontario, Canada N6A 5C2; Presently Visiting Fellow, Department
of Linguistics and Philosophy, MIT, Cambridge, Mass. 02139
When is attribution 
of beliefs justified? 
[P&W] The purpose of this commentary
is to offer a few remarks concerning the conditions under which it might be
legitimate to use certain mentalistic or cognitive terms like believe, want, think
that, intend, and so on, to describe an organism's behavior. Such language has
traditionally been frowned upon as unscientific, or at least as being eliminable in
favor of a naturalistic vocabulary. Even those who favor the use of cognitive terms
to characterize human thought processes may be reluctant to apply them to
nonhuman organisms. Morgan's canon urges that the attempt to formulate a
naturalistic account of animal behavior should not be abandoned in favor of the
easier road of anthropomorphism. While this is no doubt sound advice, one must
also guard against mere phylocentric chauvinism by attempting to be explicit
about when it might nontheless be legitimate to use such language. It seems clear
that not every case of apparently adaptive behavior, or behavior that could be
described teleologically, merits a cognitive explanation. A river flowing to the
ocean by a path of "least resistance" (i.e., minimum potential energy) is a case in
point, as are many examples of useful reflexive behavior in organisms. What we
need is a general characterization of the class of behaviors for which a cognitive
account is the appropriate form of explanation. Note, however, that we need not
require anything as strong as a set of necessary and sufficient conditions for the
use of cognitive terms. The lack of a precise and decisive criterion for when such
language is appropriate would be no reason to abandon it entirely. In many cases
such criteria are not even available for obvious distinctions (for instance, the fact
that we can't say exactly how many hairs it takes to qualify as a beard or a head
of hair does not prevent the notions of "beard" or "baldness" from being
legitimate).
For the purposes of this commentary I shall assume that the facts regarding
chimpanzee behavior are as P&W and others have reported them-i.e., that
there are no major methodological flaws in the experimental design or in the
reporting of the observations. If these reports are correct, I see nothing
problematic in accepting the cognitive explanation of chimpanzee behavior.
Although terms such as believe and want carry a certain mystique because of
their role in many traditional philosophical discussions of intentionality (say, in the
works of Brentano), their use in contemporary cognitive science is much more
straightforward. In this context they refer to certain formal properties of represen-
tations and an organism's (or a device's) relation to these representations. Thus,
they are used whenever the explanation of some behavior, under the description
which gives it maximal systematicity and coherence, requires that we posit
internal representational states of various types (e.g., belief-states, goal-states,
percept-states, and so on). It is the representation-governed nature of the
behavior that is at issue when we concern ourselves with the use of cognitive
terms. What I would argue is that representations need to be posited whenever
behavior can be shown to be significantly plastic and stimulus-independent (or at
least independent of the physically described stimulus situation).
First, however, one might note one or two reasons why hypothesizing such
states in humans is somewhat less problematic than in nonhuman organisms. In
humans, representational states can be created and altered very nearly at will,
and in many cases their consequences can be observed rather directly through
the use of language. Human behavior is extremely plastic because it can be
influenced to an unlimited degree (though not always in predictable ways) by
purely linguistic events. We are led to posit belief and goal representations in
order to account for the fact that the semantic content of an utterance can have
arbitrarily far-reaching effects on subsequent behavior.
The chimpanzee case also differs from the human one in that there is a deeply
entrenched need for us to describe our behavior in cognitive terms in order that it
make sense to us. In fact everyone, including the behaviorist, talks about human
behavior under a cognitive description. We simply cannot avoid speaking of
actions such as eating, going somewhere, or telling someone something, instead
of describing raw behaviors such as moving forks, legs, or lips. What makes a
particular piece of behavior "saying something," rather than making sounds by
moving one's lips, is that it is the former, the cognitive interpretation, which allows
us to account for certain systematic consequences of these acts [see Haugeland:
"The Plausibility of Cognitivism" BBS 1(2) 1978]. This, in turn, is because it is not
the behavioral movements per se, but rather the behavior under one or another
interpretation (as a meaningful act) that has explanatory force. We can't, for
example, say that the young woman blushed because of the way the boys moved
their lips and tensed their vocal chords, because it is presumably what they said
that explains her blushing. But as soon as we admit that it is not the physical
movements themselves but our interpretations of them that matter in explanations
of behavior, we are really placing the explanatory burden on the subject's
represention of these actions. We routinely speak of our reasons for doing things
in terms of beliefs and intentions, and expect our explanatory theories also to
appeal to such constructs, because we want the explanations to address our
actions under our intended interpretations of them.
While the linguistic route to such notions is not available in the case of
chimpanzees and other organisms (at least not in the creative sense of
language), other independent criteria are available. If it can be shown that the
chimpanzee's behavior is responsive to how he interprets (and thus how he
represents) a situation, then it would follow that the use of cognitive terms would
be appropriate. We would then, for instance, be justified in saying that the
chimpanzee's behavior was determined by what he thought or believed or took to
be the case. But what would count as a demonstration that an interpretation of a
situation rather than a causal consequence of the situation was the appropriate
characterization?
Here it seems to me that there are two primary criteria for what might be called
epistemic mediation between a stimulus event and subsequent behavior. These
are (a) the arbitrariness and (b) the informational plasticity of certain aspects of
the relation between the event and the ensuing behavior. A relation can be said to
592
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4

Commentary /Cognition and consciousness in nonhuman species
be arbitrary if under that particular description of the event and of the behavior the
relation does not instantiate a natural (nomological) law; there is, for example, no
natural law relating what someone says to you and what you will do - the latter
depends on what you know, believe, infer, want, and so on, and might have to
appeal to arbitrary rules and conventions. A relation can be said to be informa-
tionally plastic if it can be radically altered by information - that is, if it can be
systematically varied by a wide range of conditions which have nothing in
common other than that they allow the valid inference that, say, a certain state of
affairs holds (though this range of variation will not be as large in the case of
nonhuman organisms as in human, since the latter involves the unbounded
number of ways in which information can be linguistically imparted).
Now it seems to me that unless even the older reports of chimpanzee behavior
that have been circulating are all radically in error, the case for the arbitrariness of
the stimulus-response relation is already clear, since these reports have
suggested that what a chimpanzee will do when confronted with a situation (e.g.,
an out-of-reach banana) depends on how he interprets such things as sticks,
chairs, the trainer, and so forth. It is only by interpreting the trainer as a tall,
climbable object that the chimpanzee could solve the problem of obtaining the
bananas in the classical Kohler story. In fact, even the reported ability of the
chimpanzee to imitate humans can be taken as evidence for their representa-
tional ability. For if the set of behaviors produced in imitation is anything like the
set which a human would produce (as is implied by the anecdotes of chimpanzee
imitations), then what the chimpanzee is doing is not merely producing a
trajectory of movements which under some uniform similarity metric comes close
enough to being the one that is being imitated; rather, he is producing some
behavior that can be given the same interpretation as the original (e.g., "walking
across the room and opening the door").
Although I believe that such reported behaviors show that there is a sophisti-
cated representational component governing chimpanzee behavior, the case can
be made all the more impressive if we can demonstrate that the chimpanzee has
multiple access, and in particular a reflective access, to these representations so
that he can, as it were, "mention" as well as "use" them. This would argue that
the representational system is available for a variety of purposes apart from
directly determining the immediately relevant behavior, such as to represent
possible (contrary-to-fact) states of affairs, to compare a desired state of affairs
with one that obtains, and to infer certain representational states in others. The
last is perhaps the most interesting, for it means that the chimpanzee's behavior
is determined not only by the fact that he represents a situation in a certain way,
but also by his ability to represent the representing relation itself: he not only
represents the belief B but also the notion of "a belief that B." In the case of
humans, of course, this is evident from the existence of such constructions in the
language. The studies P&W report are an attempt to show that not only can the
chimpanzee be in the kind of relation to a representation that Russell called
"relations of propositional attitude" (e.g., believing that B, wanting it to be the
case that B, expecting that B, wondering whether it is the case that B, or even
considering what would happen if B were the case), but also that he can
represent these relations themselves - or specifically that he can represent that
other organisms are in these relations to their representations. In other words, the
studies argue that we must not only posit beliefs in order to account for certain of
the chimpanzee behaviors, but also beliefs about beliefs and intentions of others
(and, presumably, about the chimpanzee himself).
That this kind of meta-representational ability occurs in nonhuman species is
not as obvious as the existence of representations per se, though nothing
prohibits it in principle. The fact that chimpanzees do not possess a generative
expressive language predisposes us against assuming that they have such
meta-descriptive internal representational capacities. If, however, the kind of
evidence discussed by P&W can be sustained, the lack of expressive language in
the chimpanzee will clearly have to be explained in terms other than limitations
upon their conceptual apparatus. The P&W interpretation clearly points to the
chimpanzees' having an extremely rich internal representational system or
"mentalese" - certainly much richer in expressive power than any communicative
code they have ever been taught by human trainers. In particular, it suggests a
capacity for at least some limited recursive embedding of propositions, an
expressive power even beyond the reach of first-order logic. In fact, it might be
argued that this interpretation has even more radical consequences. There are
those who believe that the recursive meta-representational capacity is to be
identified with the notion of consciousness itself. Certainly, if concepts like lying
(or "deliberate") are among the kinds of relations between an organism and its
representation that can themselves be represented by the chimpanzee, one must
take seriously the idea of a chimpanzee as a moral agent.
That P&W's interpretation of their observations has such far-reaching conse-
quences does not in itself cause any difficulties for their view. Indeed, one of the
common results of taking one's findings and theoretical commitments seriously is
the discovery that they entail counterintuitive consequences. Far from being a
reductio ad absurdum, such consequences are the usual way in which radically
new ideas enter a scientific enterprise.
by Howard Bachlin
Department of Psychology, State University of New York, Stony Brook, N. Y. 11790
Who cares if the chimpanzee has a theory of mind? Griffin. The behavioristic
Zeitgeist as invoked by G is a scary Geist indeed. If this is the atmosphere in
which ethologists have been working for the past fifty years, then it is certainly
time to get rid of it. If, as G implies, the behavioristic Zeitgeist has caused
ethologists to identify mental experiences with neurophysiological processes, to
hold that man is discontinuous with other animals, to refuse to study complex
behavior, to reject verbal report as a scientific datum, and to study only behavior
which can be elicited by known stimuli, all psychologists will join their voices to G's
and plead that this ghost be exorcized. But it is important to realize that what G
calls the behavioristic Zeitgeist has nothing at all to do with behavioristic
psychology. I doubt whether even Watson held many of these views; Skinner
certainly holds none of them. The major problem with G's argument, however, is
not that it attacks a behaviorism which does not exist but that it proposes a
cognitive Zeitgeist that has about as little relation to current cognitive psychology
as the supposed behavioral Zeitgeist has to current behavioral psychology. The
view of S-R psychology attacked by G is actually closer to current cognitive
psychology than to current behavioral psychology. The most salient characteristic
of cognitive psychology today is its reliance upon models, mostly taken from the
operation of digital computers, of how information is processed in the nervous
system. A cognitive ethology that had any relation to cognitive psychology would
propose models for information processing in other organisms which differed,
perhaps, in certain elements from that of humans. For instance, humans and
chimpanzees might have similar or different input or output buffers or storage
systems or programming codes, etc. From a behavioral point of view a program
to uncover and compare such mechanisms in various organisms would be
unfruitful but it would at least be a reasonable cognitive ethology, in line with
cognitive psychology. What G proposes is a return to the anecodotal method of
Romanes. By virtue of clever behavior which, as Disney has shown, may be
adorably similar to that of humans, he proposes that we endow other animals with
honorific titles. One imagines a Wizard-of-Oz-like scene in which G, as the wizard,
awards to the chimpanzee or the bee a "Certificate of Consciousness" for having
demonstrated, in its behavior, awareness or knowledge or courage for that
matter.
This is a game that may be played at any level. With a little effort one can
imagine a cognitive physics. A gallon of water, for instance, is: (a) infinitely
complex; represents the environment (b) externally by taking the shape of its
container and (c) internally in the form of pressure and temperature gradients
which, in turn, affect the environment in terms of subtle alterations in magnetic,
electrical, or gravitational fields; communicates its intention (d) to boil by first
steaming and then exhibiting little bubbles, and (e) to freeze, by increasing in
density, and so on. It is true that a pail of water has its own language, which must
be interpreted by us, but so do the French and I've never heard of an attempt to
deny them consciousness for that reason. With two examples of infinite complex-
ity there is no justification for holding that one is more complex. In arguing that a
pail of water has degrees of complexity similar to that of humans, I am not
proposing panpsychism but just that consciousness be seen for what it is - an
honorific word for a particularly human complexity of behavior which, if it is to
have any meaning at all, must be spelled out more specifically than has heretofore
been done.
Referring to Lindauer's work with bees, G cites the finding that bee-W does not
usually imitate bee-N's (more vigorous) dance directly but first visits cavity-n, and
then dances as bee-N did. An obvious next step is to see whether there are any
conditions under which bee-W will imitate bee-N's dance without first visiting
cavity-n. This is the sort of question a good researcher of any persuasion might
ask. It does not require (as G asserts it does) first postulating that bee-W be
thinking, "Very good cavity up north at such and such a distance."
Words such as intention are not meaningless. To test whether a certain person
has an intention, however, we first have to define the word and then observe
whether a person's behavior (including verbal behavior) conforms to the defini-
tion. If it does there is no reason to attribute mystical qualities to the person. We
could decide in advance that words such as intention are useful to us only in
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4
593

Commentary/Cognition and consciousness in nonhuman species
social interactions with other humans and thus restrict the referents of such words
to human behavior. Or we could arbitrarily define the behavior to which we want to
apply the word and look at the behavior of other species for conformity to the
definition. We should then be prepared to find technical conformity among any
species or even among inanimate objects. Such conformity does not in itself imply
any special connection between humans and other exemplars of the behavior.
The conformity might prompt us to look for a common structure, a common
function served similarly by different structures, or a common reinforcement
history. But why should we postulate mental events in the object under study
before we begin the search?
Savage-Rumbaugh, Rumbaugh, and Boyson. The papers of SR&B and of P&W
both show that chimpanzees can exhibit behavior that looks remarkably similar to
human behavior. In both cases, however, the cards are stacked. There are at
least three sorts of environment in which to study the behavior of a nonhuman
species:
a. Natural or naturalistic environments;
b. Extremely simple environments;
c. Humanlike environments.
The advantage of natural environments is that, in its own biological niche, the
complexity and adaptiveness of the behavior of an organism is most likely to be
revealed. The advantage of extremely simple environments is that important
variables may be varied on one dimension at a time. The advantage of humanlike
environments is that in them the activities of animals are entertaining. But it is
dangerous to draw scientific conclusions on the basis of such behavior; the
always-present temptation to anthropomorphize is exaggerated when, for
instance, apes are using keys to unlock locks rather than using straws to hunt
insects as they would do in their natural environments, or pressing levers as they
might do in extremely simple environments. The use of the keys, money, and
wrenches in the experiments of SR&B seems designed more to impress the
reader than to study the behavior of the chimp.
The game being played by SR&B and P&W is exactly the one prescribed by G.
One player sets a criterion or a series of criteria drawn from human behavior and
the other tries to see if chimpanzees' behavior can be manipulated to conform to
the criteria. The more humanlike the atmosphere the better. Then the first player,
acting as devil's advocate, performs a behavioristic analysis of the second
player's experiment whereby the awareness or intention or other cognitive
attribute is shown to be only an "illusion." The cognitive attribute is then defined in
stricter terms and (forgetting the arbitrariness of the initial definition) the game
can begin again.
The nature of this enterprise is most clearly revealed in the discussion section
of SR&B's paper, where Project Washoe and Project Sarah are criticized for not
decisively testing the "symbolic capacity" of chimpanzees. But the present study
of SR&B can be criticized on the same grounds. SR&B will undoubtedly be taken
to task by psycholinguists for having abandoned linguistics experiments for
social-psychology experiments. The communication between the two chimpan-
zees in their experiments was of the simplest kind (one chimpanzee pushes a
single button which lights up the corresponding button of another chimpanzee).
This communication satisfies the quotation (indirectly from Bloomfield) at the
head of the article but many communication experiments of this kind have been
done with pigeons, rats, and other organisms supposedly deficient in linguistic
ability. Indeed, if one reads the quotation literally, it is satisfied by the communica-
tion between a piston of a car (A) which communicates with the piston linkage (B)
to do something impossible for the piston to do itself (splash oil from the oil pan)
which is adaptive with respect to A (in the sense that it lubricates the cylinder wall
and prolongs the piston's life). It is heartening to see that the nature of linguistic
ability is being defined by SR&B in this functional sense. But then why are they still
concerned that Project Washoe and Project Sarah did not reveal awareness and
intentionality in the chimpanzees? Bloomfield's "fundamental linguistics situation"
quoted at the head of the article (with which the experiments are wholly
consistent) says nothing about awareness, intentionality, or other cognitive
states. It defines linguistics wholly in behavioral terms as a certain sort of
interaction between two individuals - that is, as a social event.
And it is as social psychology that the experiments have their interest. I do not
know in which direction a cognitive psychologist would take future experiments in
this area. But what is unusual here is not the simple communication between the
two chimpanzees but the fact that they came to share the food. With pigeons, in
my own laboratory, I have not found sharing except when each pigeon could
punish the other for not sharing. Similarly, with humans, prisoner's-dilemma
games reveal that sharing only occurs under special circumstances. What caused
these chimpanzees to share their food? It seems unlikely (but certainly possible)
that chimpanzees occupy a particularly altruistic ecological niche between the
selfishly primitive pigeon and the selfishly sophisiticated human. More likely, there
was something about the training procedure that caused each chimpanzee to
give up some of its food. Perhaps this was the alternation of roles of the
chimpanzees or the presence of the experimenter. These variables could be
investigated without attributing to the chimpanzee any particular internal linguistic
events (such as: "If I no give him my food, he no give me his") as G might
demand. I am not saying that such internal linguistic events cannot occur. It might
even be possible to externalize them by means of Rumbaugh's graphic system. I
am saying that such a search would be less interesting and less fruitful than a
search among the environmental contingencies for what caused the chimpanzees
to share their food.
Premack and Woodruff. The experiments of P&W are more complicated on the
stimulus end (and less complicated on the social end) than those of SR&B. As the
latter can be thought of as social experiments, the former can be thought of as
perception experiments. Attributing a theory of mind to the chimpanzee tends to
obscure what is really interesting about these experiments. The procedure
consists of showing a chimpanzee a videotape and then a group of pictures and
asking it to choose one of the pictures. The tapes and pictures have been
selected by P&W so that a given picture either represents a solution to a problem
posed in the videotape or does not. The chimpanzee, usually on its first try,
chooses the picture representing the solution.
Now, as P&W say, it is clear that most adult humans would also solve the
problem. One might now ask, how do they solve it? I submit that a paper such as
P&W's with an adult human instead of a chimpanzee as subject would be rejected
for publication by any respectable psychology journal because it does not
seriously consider this question. It would not be sufficient (with adult human
subjects) to attribute the correct solution to the fact that subjects had a theory of
mind. One then wants to know how the theory of mind works, how the videotape
and respective pictures operate within the person's theory of mind, and why the
mind accepts one picture and rejects the other. With chimpanzee subjects, no
less than for human, such an analysis ought to be provided. It is not enough to
say, "You would do the same if you were a subject in this experiment." What is
needed to analyze this experiment is a sort of "grammar" for the videotapes in
relation to the pictures, and a training procedure with the grammar. Perhaps one
might start with "Gestalt laws" such as symmetry, closure, pragnantz, or common
fate (not, obviously, in terms of rudimentary physical properties but in terms of
structural and functional aspects of the situation. Even pigeons can quickly learn
to discriminate one person from another and, presumably, a shivering person
from a nonshivering one, and a locked-up person from a free person. The
interesting question here is what in Sarah's experience caused her to choose the
key when she saw the locked-up person, not what her mental state was at the
time she did it. The particular pictures used by P&W make such an analysis
difficult because it is not clear how they are related to the experimental and
nonexperimental history of the subject. The fact that P&W (and this commentator)
can think of no clear-cut analysis does not mean that the chimpanzees have a
theory of mind. If we cannot figure out how the chimpanzees do their tricks (in
terms of, say, a "grammar" for the videotapes and pictures), then we should
proclaim our ignorance rather than the chimpanzee's mental powers.
The experiments of SR&B and P&W are fascinating, instructive, and provoca-
tive. I am by no means arguing that they should not have been done. But
questions for now are: What do these experiments mean? and, What should we
do next? So long as we continue to test the hypothesis: "Chimpanzees are like
human beings" and then, having prearranged conditions to get an affirmative
answer, conclude: "Chimpanzees have this or that mental power," we will be
hindering ourselves in our attempt to discover what sort of creature the chimpan-
zee is.
by Aystin H. RIesen
Department of Psychology, University of California, Riverside, Calif. 92521
Responses versus cognitions. In the late 1940s Hebb (1949a, p. 192) identified
two "great discontinuities" in the theoretical structure of psychology. One had to
do with the micro-anatomy and physiology of learning and the other concerned
the "intuitive judgments" on which knowledge of social perceptions, cognitions,
and emotions were based. Social behavior and the study of social behavior were
so dependent on intuitions, he argued, that methods for quantification and
objectivity were a crying need of the time. Many psychologists were in the mood
for rejecting rather than facing the problems of research in these areas. The three
accompanying target articles to which this commentary addresses itself are
594
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4

Commentary/Cognition and consciousness in nonhuman species
happy reminders that progress has been made on the second theoretical front,
and we find assurance that the first discontinuity is also yielding to direct attack.
Hebb [q.v.] has himself been a most creative contributor toward the breaking
down of both discontinuities. The one at issue here has to do with the "private
experience" of not always so private emotions and cognitions. Hebb (1946)
made the study of inferred mental states in nonhuman species both respectable
and theoretically fruitful. He showed that observers could judge animal emotions
and individual differences in temperament with a high degree of reliability. These
studies helped to turn the tide toward acceptance of feelings, motives, and
cognitions as subject matter for students of animal behavior.
Premack & Woodruff's use of choice behavior with Sarah to answer objectively
new questions about thinking, purpose, and intentions, provides a tool for asking
what the animal infers about human intentions, and so forth. The method was
used in a different form by Robert Fantz (1958) with chimpanzee and human
infants as a means for asking questions without having to rely on language
behavior. The studies that P&W give us are breaking new ground, in the sense of
providing new evidence for expectation and for the ability of a chimpanzee to
impute purpose in another primate. They also illustrate once again the desirability
of having objective methods (such as Hebb was asking for) for validating human
judgments about mental states in animals. This is the answer to arguments
against studying consciousness that behaviorists were putting forth so strongly in
the days of Watson and Thorndike and Hull.
The newer studies of capacities for language behavior in chimpanzees and
gorillas add a further dimension to advance the study of mental states and
problem solving in animals that have succeeded far beyond expectations of even
a decade ago. When a gorilla or a chimp even tells a lie by ingenious use of sign
language, we are reminded that behavioral checks are necessary even in the use
of linguistic avenues to the investigation of what animals feel, know, and
"manipulate" in their heads.
We are sometimes asked whether it is natural for animals to use "typewriters"
or to "sign" for desired objects and actions. How would learning to do this help in
adjusting to their African environments? The question is irrelevant to the study of
animal capabilities, although it may be relevant to questions of ecology and
evolution. Even these reservations about relevance must be dropped when one
considers possible future developments. Changes that are going on now lead us
to doubt that future environments can be predicted. Students of animal behavior
know well that capabilities of animals and human beings are often beyond the
requirements of environments in which the lives of many organisms are now being
lived.
Griffin's paper extends the questions about mental activities and experiences
to nonprimate species. Is it indeed futile to ask whether birds experience colors in
their visual world? We obviously cannot know whether they experience them
exactly as we do. Since birds show preferences (in choice situations) and
execute action patterns when appropriate colors are part of certain visual
patterns, reasonable guesses are that they do experience colors in some fashion,
and furthermore, that certain emotional experiences go with the visual. To deny
some forms of conscious experience to dogs, cats, horses, birds, and so forth,
would gain nothing. The question at issue remains: do such experiences mediate
between environmental inputs and the behaviors that we see as being responsive
to the input?
When nervous systems differ greatly from those of higher primates we are
understandably reluctant to ascribe similarities of conscious processing. Further-
more, we see behavior in ourselves that is unaided or even hindered by
awareness. Simpler neural circuits suffice to mediate bodily orienting, postural
adjustments, and adaptations to metabolic requirements. But we are not yet
exactly clear on what the neural substrates of being conscious are. G is right
about our need to keep an open mind. Laymen, neurobiologists, and psycholo-
gists will not have open minds, however, if they see no alternative to ascribing
intention to every goal-directed behavior. Behaviorism taught an important lesson
that needs to be appreciated. The lesson of objective behavioral investigation is
not obvious to all, and for many research purposes it is the preferable approach.
For some, it is the only approach, and we can afford not only tolerance but strong
support for those who prefer to work without assuming consciousness as a
mediating process in behavior.
On the other side of the coin, the question of anticipatory mentation gives
behaviorists problems with which they have struggled. As G points out, the
training of language skills should give us important new information about this. Do
the great apes plan ahead? Spontaneous communication by chimpanzees (see
Menzel and Johnson, 1976 op. cit. G) indicates an affirmative answer. Savage-
Rumbaugh, Rumbaugh, and Boysen find strong support for such planning in the
interchimpanzee communications that involve requests for an appropriate tool.
How far can these requests be extended in time?
Hull (1952) developed his ingenious "anticipatory goal response" and "ante-
dating defense reaction" constructs to explain expectant behaviors in rats. To
others the same behaviors support the concept of "cognitive maps." Rats, dogs,
apes, humans are all endowed with cognitive maps or anticipatory goal
responses (each with both, in this commentator's opinion).
Is there any need for keeping anticipatory behavior in the motor (response)
portion of the nervous system? Hebb (1949b) persuaded many of us that central
circuitry was in the brain to keep cognitions and maps organized and ready to
function during periods when sensory inputs were absent or inappropriate.
Goal-directed use of such maps may reach its peak in human activities, but their
use by apes and other animals is different in degree, rather than kind. At some as
yet unknown stages between amoeba and humans, differences in kind will be
discovered.
REFERENCES
Fantz, R. L. Visual discrimination in a neonate chimpanzee. Perceptual and
Motor Skills 8:59-66, 1958.
Hebb, D. O. On the nature of fear. Psychological Review 53:88-106, 259-276,
1946.
Temperament in chimpanzees: I. Method of analysis. Journal of Compara-
tive and Physiological Psychology 42:192-206, 1949a.
The organization of behavior. New York: Wiley, 1949b.
Hull, C. A behavior system. New Haven: Yale Univ. Press, 1952.
by Harvey Saries
Department of Anthropology, University of Minnesota, Minneapolis, Minn. 55455
One new theme and . . . One supposes that G is being direct in claiming that the
"basic question at issue involves a comparison of... brain function" having to
do with possible "mental experiences" in various species. However, this claim is
complexly bound up with many "whethers" and "whats" of "mental experi-
ences." Each of these papers uses a different definition of "language," which
then serves as a foundation for its framework.
Griffin's paper takes what I find to be a reasoned and reasonable position: that
we must remain open and "agnostic" even to begin to discuss the questions at
issue. This paper is a shortened and interestingly elaborated version of his book
on animal awareness (Griffin, 1976 op cit. G, SR&B). In order to discover the very
nature of what we are discussing, we have to wonder a little about our
metaphysical commitments to particular views and questions about human and
animal nature. If, as he and the other authors seem to say, it is clearly true that
chimps et al. are much "smarter" than we would have supposed, why is it that we
have supposed as we have? It appears that our theories about language and
mind never really need much "evidence." The presentation of "evidence,"
instead of raising consciousness, tends instead to decline into arguments about
methods and unknowables.
Premack & Woodruff's essay uses the "creativity" argument to situate the
"problem" in tractable dimensions. "No theory of generalization will explain the
comprehension and production of structurally novel sentences," they claim. Many
readers will recognize this argument to be one that is often used to distinguish
humans from other species on qualitative grounds (Saries, 1977, Chaps. 1,4).
Once this move is made, most of us who have considered the problem think that
attempts at comparison are gratuitous: the essential uniqueness of humans is
already presumed. Only certain "boundary issues" are open to debate; probably
none, seriously. If the "creativity" argument indeed has these inbuilt presupposi-
tions, is it possible that the claim to be doing serious comparative work carries
other agendas?
In their abstract, P&W state: "An individual has a theory of mind if he imputes
mental states to himself and others." This sets up so many levels of puzzle that
one finds it difficult to sit still and think. Why a "theory of mind?" In what sense
does an individual "have" one? Is it possible not to "have" one? Why is this a
"theory?" Is it "because such states are not directly observable, and the system
can be used to make predictions about the behavior of others" (P&W, sentence
2)? While hardly anyone would disagree with the "predictions" clause, it does not
necessarily help the first. In fact, one wonders if there is a subject matter here at
all, if it is not "directly observable" in fact (or in principle?). Frankly, it seems to
me to set up the possibility, even the likelihood, that a "theory" is properly for
"nonobservables." Maybe it accounts for the recent increase in the perceived
lack of boundaries between behavioral science, parapsychology, and other forms
of mysticism.
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4
595

Commentary/Cognition and consciousness in nonhuman species
After the presuppositions about individuality and human nature and the claim
about what a theory is and is for, I am puzzled by the remainder of this essay. In
some senses, it is about "other minds" and toward some theory of discourse,
mutuality of understanding, and sociality. But the invocation of a chimp "theory of
history" to account for one experiment, the association of other species and
human "retarded" persons, and the concluding remarks about the very nature of
what is and is not "natural," suggest to me that much more is going on than is
actually expressed in this essay. What is it? What is it for? Is it behaviorism
redefined?
Savage-Rumbaugh, Rumbaugh & Boysen's essay seems to be much like
P&W's, even though it is severe in its criticism of Premack's work. It (also) invokes
a definition of "language" which confines and prescribes a qualitative sense of
human uniqueness: "the true adaptive function of language lies in the ability it
confers upon man to transmit specific information in an abstract, context-free
form."
How could we know what the "true" function of "language" is? To invoke the
term "adaptive" seems to "biologize" the definition, but what does it explain?
Doesn't this definition depend on a prior view of "language" which is approxi-
mately like "logic" - an "infinite" set of ideas or sentences?
Are humans capable of "context-free" exchanges? The idea of "abstract"
seems to derive from the human/animal debate itself, and is thus circular. This
sort of definition serves principally to claim that, in some aspects of our being, we
are extranatural; "language" is a cover term for features of our being which are
assumed to be unique.
The language argument is used to criticize chimp/human communication
studies, and to define intraspecies communication as the "proper" locus of
nonhuman communication studies. This seems more than reasonable, except
that it is then re-placed in the context of what "symbolic" communication is - as if
this is a clear discussion.
To say, for example, that a (laboratory) animal "cannot use symbols" seems
to prejudge; to claim that an animal "does not" might be reasonable. But to claim
understanding of what is "prelinguistic" and what is "symbolic" is merely to enter
the mind/body, human/animal controversies in the name of yet another meta-
phor. The fact that SR&B's methods seem very reasonable (even to me) should
not blind us to the fact that the issues are embedded in old dualisms. The authors
seem defensive, not critical, as they claim and ought to be.
The "state of the art," as represented in these three papers, sees a clash
between those who are involved in serious attempts to solve problems by the
usual experimental/empirical means, and those who have come to a new, also
serious, position which might be called "methodological agnosticism." (Penn,
personal communication). Although I too have come to G's position of having to
rethink what this area is all about, it is not difficult to appreciate the ordinary
attempts to solve interesting problems. Whereas in most areas of inquiry
philosophy follows periods of problem-posing and solution, G and some others
believe that there is already a great deal of intellectual baggage which embeds
the very ways in which we tend to ask questions.
Surely this is a fascinating debate, and one to which we must become
educated - not only in methods, but also in the history and sociology of these
ideas. Many of them are, of course, ancient, and have become the common
sense through which we judge their reasonableness.
REFERENCE
Sarles H. "After metaphysics: Toward a grammar of interaction and discourse.
Lisse: Peter de Ridder Press, 1977.
by C. Wade Savage
Minnesota Center for Philosophy of Science, University of Minnesota, Minneapolis,
Minn. 55455
Isn't the answer obvious? fP&WJ. Preliminary comment. P&W ask: Does the
chimpanzee ascribe purposes, knowledge, and other mental states to itself and
others? Their answer is affirmative, on the ground that only thus can we explain
how Sarah selects the correct solution to various problems encountered by
another (human) agent. The problems are presented to Sarah as sequences of
pictures of the agent confronting and attempting to solve the problem, and Sarah
is required to select, from among several alternatives, the picture that depicts a
correct solution.
At a first level, P&W consider the competing associationist and nonassocia-
tionist explanations of Sarah's ability. The associationist maintains that Sarah
selects moving the box and standing on it (as the solution to the problem of
reaching the suspended banana) by completing a behavioral sequence like those
previously performed or observed by her. (The elements of the behavioral
sequence become "associated" by repeated co-occurrence in a certain order.)
The nonassociationist argues that the above explanation fails where the correct
completion produces a behavior sequence unlike any experienced before, and
that Sarah is capable of such completions. For example, she selects a key as the
solution to the human's problem of getting out of a locked cage (and presumably
she has never herself been, nor seen anyone else, imprisoned in quite this way).
We must, the nonassociationist argues, posit rules in Sarah that generate the
sequence containing the key, in just the way that rules must be posited in children
to explain their generation of structurally novel sequences of linguistic behavior.
At a second level, P&W consider the "theory-of-mind" explanation of Sarah's
ability (a confusing label, since both the associationist and nonassociationist
views are theories of mind), but fail to consider its true competitor, the no-
theory-of-mind explanation. The theory-of-mind explanation is that Sarah selects
correct solutions by ascribing purposes and knowledge to the human agent and
choosing the behavior consistent with her ascription. For example, she ascribes
to the human an intention to get the banana and the knowledge that there is a box
nearby. The no-theory-of-mind explanation is that Sarah chooses the behavior
that would constitute a solution for her, given her purposes and knowledge, which
she ascribes neither to herself nor to the human. (I do not know where in this
classificatory scheme to locate the "empathy" explanation considered by the
authors.)
P&W fail to consider the no-theory-of-mind explanation because they erro-
neously assume that the associationist explanation is the competitor of the
theory-of-mind explanation. They thus run the two levels together, treating the
associationist and no-theory-of-mind explanations as equivalent, and the nonas-
sociationist and theory-of-mind explanations as equivalent. But these equiva-
lences do not obtain. The nonassociationist, who hypothesizes rules in Sarah that
generate her completion of allegedly novel behavior sequences, can consistently
maintain that Sarah does not ascribe purposes, knowledge, or any other mental
states to herself or to others. The associationist, who holds that Sarah completes
novel behavioral sequences by "generalizing" previously experienced
sequences, can consistently maintain that Sarah ascribes purposes and knowl-
edge to herself and to others. He must, of course, provide a suitable association-
istic analysis of these mental states; but having done so, he can consistently
maintain that Sarah ascribes these states to herself and others (though Sarah
does not understand the analysis).
Main comment. It seems obvious to me that chimpanzees, and many animals
less like humans than chimpanzees, ascribe purposes, knowledge, and feelings
to others, and sometimes to themselves, the cat believes that / intend to scold
her, for she knows that / believe that she intended to take the ham slice on the
counter, and that / want her not to take it. (The italicized expressions indicate the
cat's ascriptions of mental states: other-ascriptions, where the expression
contains " I " , self-ascriptions where it contains "she".) And that is why she
cringes as I enter the room. Most persons well acquainted with domesticated
animals will find such explanations of animal behavior entirely natural. Why, then,
do our authors find it necessary to deploy their considerable experimental
resources to prove what must seem obvious to them - that chimpanzees do
ascribe purposes, knowledge and other mental states to themselves and to other
animals?
The main reason, I think, is connected with the confusion of levels discussed
above. P&W assume that their result is incompatible with the (still powerful,
though declining) behaviorist-associationist theory of mind. I offer some remarks
on the possible sources of and errors in this assumption.
Behaviorist associationism defines purposes, knowledge, and other mental
states as (learned, adaptive) dispositions to emit (sequences of) behavior and
ideas. Behaviorism eliminates ideas from the definition - they, too, get defined as
dispositions to behave - and notes that, since purposes and knowledge thus
defined are theoretical entities (behaviors being the observables), they are no
more introspected by the animal who has them than by the animal who infers them
in others.
1. It may be supposed that behaviorist associationism denies the existence of
purposes and knowledge, in the ordinary sense, and thus implies that Sarah
cannot be ascribing these to anyone. Such an interpretation would be mistaken.
Contemporary physics is a theory that defines such ordinary terms as "sour" and
"yellow" in terms of pH level and light-wave frequency. It does not deny that
lemons are sour and yellow, or that humans and animals ascribe sourness and
yellowness to lemons. Similarly, behaviorist-associationism is a psychological
theory that defines such ordinary terms as "want" and "know" in terms of
dispositions to behave. It does not deny that animals want and know things, or
596
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4

Commentary/Cognition and consciousness in nonhunian species
that chimpanzees ascribe purposes and knowledge to themselves and to others.
Note that Sarah need not be a psychological theorist to ascribe mental states to
animals, any more than she need be a physicist to ascribe sourness to lemons.
Note also that if the behaviorist-associationist definitions implied that Sarah could
not ascribe purposes and knowledge to animals, they would also imply that
humans could not ascribe those states to animals.
2. It may be supposed that behaviorist associationism is a theory of the
subhuman animal mind, not of the human, and that it countenances the following
argument:
I, a human, know (directly) by introspection what purposes and knowledge are.
So I am able to infer (i.e., know indirectly) that some other animals have these
mental states. But Sarah, whose mind is described by the behaviorist-
associationist view, cannot introspect her own purposes and knowledge, if
indeed she has any at all. Hence, she does not know what these mental states
are, and cannot infer that other animals have them.
Now, behaviorist associationism is a general theory of mind, applying to the minds
of all animals, human as well as subhuman; and it does not countenance the
argument above. It does maintain that neither Sarah nor I introspect our purposes
and knowledge (these are unobservables). But neither Sarah nor I need know
mental states by introspection to ascribe them to others: we can know them by
inference, by constructing them from the behavior of others and (perhaps) our
own.
3. It may be supposed that subhuman animals are only capable of observa-
tion, not of inference - at least not of inferences to the existence of unobserv-
able, theoretical entities such as atoms and magnetic fields - and that subhuman
animals are therefore incapable of ascribing unobservable, theoretical states to
systems. This assumption, combined with the behaviorist-associationist view that
mental states are unobservable, theoretical states, leads to the conclusion that
Sarah cannot ascribe mental states to herself and to others. But the assumption
is false. Although Sarah may be incapable of ascribing a magnetic field to the
earth, she is obviously capable of ascribing purposes and knowledge to other
animals. Perhaps psychological theoretical states are easier to grasp than
physical theoretical states and entities. (I must confess that it is almost as easy to
argue that the assumption is true, and behaviorist associationism partly false. For
behaviorist associationism claims that the distinction between observable and
theoretical entities is sharp and useful, and that mental states are theoretical
entities; and both claims are controversial.)
It may be unfair to suspect P&W of harboring any of the assumptions discussed
above (especially the first two). It would certainly be unfair to suggest that they
have done nothing more than provide a question with an obvious answer.
For even if it is obvious that chimpanzees do ascribe purposes, knowledge,
and other mental states to themselves and to others, it is by no means obvious
how far this ability extends. Do chimpanzees ascribe lying, guessing (as opposed
to predicting), embedded intentions, and so forth to others? Here P&W provide us
with information and tentative answers which are genuine additions to the
common stock of knowledge.
by Glendon Schubert
Nederlands Instituut voor Voortgezet Wetenschappelijk Ondersoek op bet Gebied
van de Mens- en Maatschappijwetenschappen, Mayboomlaan 1, Wassenaar
2242PR, Holland; and University of Hawaii at Manoa, Honolulu, Hawaii 96822
Cooperation, cognition and communication. To a social scientist interested in
the biology of human behavior, it is astounding that primatologists formulate their
research inquiries in terms of such questions as whether "the chimpanzee's
concept and use of tool names [provides] insight into the factors that determine
and promote evolving, complex forms of word usage"- presumably among
chimpanzees (SR&B, emphasis added); or "whether or not the chimpanzee
imputes mental states to others," which evidently is deemed by its authors to be
an operationalization of their speculation "that the chimpanzee may have a
'theory of mind,' ... not markedly different from our own" (P&W). What is wrong
with both questions is that they appraise the relative excellence of nonhuman
cognitive abilities by measuring the extent to which these conform to those
characteristics of our own species - which impresses me as a very unbiological
approach. And that raises questions about what we should understand to be the
relevant theoretical significance of what these human experimenters, as well as
their chimpanzee subjects, are doing.
I shall undertake to comment upon each paper in turn, but before I do so, two
prefatory caveats are needed. Whatever may be true of chimpanzees, it certainly
is the case that humans can and do make many imputations in complete
innocence of any kind of cognitive theory, to say nothing of a theory of mind. On
the other hand, theory of the human mind has yet to achieve the degrees of
cohesion, integration, and consensus meet to its functioning as the criterion for
modeling the cognitive processes of other species, at least at the grandiose level
of "theory of mind" and "states of mind."
Training primates to cooperate [SR&B]. "Words" are elements of either human
speech or else human written language; and their postulation as a variable in
chimpanzee cognition is neither necessary nor sufficient, nor indeed even helpful,
to the elucidation of how two such animals were trained to cooperate in the
sharing of tools and food. The latter kinds of social behavior were surely critical in
the evolution of hominids and eventually the human species, but there is no
evidence that either tool or food sharing depended or depends upon the prior
acquisition of verbal language; on the contrary, language probably developed to
meet the social needs of bands of protohumans whose ancestors already had
been sharing tools and food for millions of years (Lancaster, 1975, p. 78; Pfeiffer,
1977, p.50). Moreover, both tool and food sharing sometimes occur within feral
bands of chimpanzees (Lancaster, 1975, p. 77; McGrew, 1977 op. cit. SR&B;
Wilson, 1975, pp. 128, 207; Pfeiffer, 1977, pp. 48-49), so the training here
enhances what are already evolved abilities (if not traits) of Pan Troglodytes.
SR&B state that Austin and Sherman "distinguished these words, as well as
additional tool words" (emphasis added); and I take exception to this kind of
linguistic anthropomorphizing, particularly in a paper that purports to discuss
cross-species language transfer. The paper is replete with statements that
exemplify my point, such as several in its conclusion: "the chimpanzee's
comprehension of single words" is discussed there, together with "word acquisi-
tion" by chimpanzees, and then the remark about "complex forms of word
usage" quoted in the opening sentence of my introduction. This kind of attribution
of "word" as a concept of chimpanzee cognition may not be characteristic of the
authors' own thinking but it certainly permeates their discussion here.1 Yet it is
abundantly clear from the data presented that what Austin and Sherman
responded to, and what they initiated their other nonverbal (including oral
nonspeech) communications with, were the lexigrams of the customized
computer terminal that was their constant robot companion. These lexigrams are
symbols, color-coded combinations of from one to four among nine design
elements, all linguistically arbitrary from the perspective of human language; but
they are not words in either English or any other natural language. As native
speakers of the English language, SR&B apparently found it easiest to transliter-
ate the lexigrams, which identify the keys that symbolize the computer language
that the keys activated, to the English in which it is most probable that they
thought about the behaviors with which the lexigrams had been associated by or
for them. The lexigrams were words to the humans who directed and participated
in the research, and who had a sophisticated understanding of the artificial
Yerkes language and the computer programming that some of them had spent
much time and effort to develop, as the medium through which chimpanzee-
human communication might better take place.2
But irrespective of whether chimpanzees have a "theory of mind," no evidence
is presented to suggest that chimpanzees have a theory of computer-minds.
Pushing a lexigram key, and monitoring one's own (or another's) performance by
observing a lighted display of the same lexigram, is a function qualitatively
indistinguishable from that of pigeons pecking or rats pressing levers to obtain
food (or surcease, or whatever). The observation and interpretation of more than
one lighted lexigram, in sequence and in context, certainly does have implications
of notable import for a theory of chimpanzee cognition; but the chimpanzee's role
in the interaction process neither requires nor entails understanding on its part
about how computers work. The Cs (chimpanzees) know lexigram symbols as
identification signs not atypical of the strange, mechanically human environment in
which they find and adapt themselves. It is not helpful, in discussing their behavior
in so doing, to attribute to them the cognitive concepts of natural language.
An explicit demonstration of the kind of unnecessary difficulties that the SR&B
perspective on words invites is found in their having attached, for their own
purposes (and conceivably, psychic benefits), the word "straw" to the piece of
plastic tubing that is photographed in their Figure 1. This word usage, I submit, is
not merely semantically incorrect; what is worse, it is patently an affectation. It is
semantically incorrect, because flexible plastic tubing is not referred to as
"straw," at least not by native speakers of the English language. It is true that a
tertiary meaning of "straw" is a hollow paper tube, used in drinking certain
beverages such as an ice cream soda; but the primary meaning is a single stalk
or stem, especially of certain pieces of grain. It is an affectation, because the
latent image implied by the use of the word, in the context of the research, is that
of a feral chimpanzee, indulging in the frequently reported tool-behavior of using a
plant stem, twig, or long stick, to dip for termites or ants. This is a natural tool-use
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4
597

Commentary /Cognition and consciousness in nonhuman species
by the animal (McGrew, 1977 op. cit. SR&B). So here we have an example of
what Kenneth Burke (1937) once called "secular prayer," as SR&B - whether
intentionally or not - cash in on the overtones of the word, at least for other
primatologists (although probably not for Austin or Sherman). Calling their plastic
tubing a straw permits SR&B to take a free ride in the minds of their human
readers, on the associated idea of how natural it is for the research animals to be
using the tubing. Of course, Austin and Sherman could not care less whether or
not SR&B call a spade a spade; they would have responded no differently if SR&B
had decided to call the tubing "snake" instead of "straw" - unless and until, of
course, both the analogy and the research were extended to include live
representatives of the order Ophidia. It would probably have been much simpler,
as well as more accurate, to have just called the plastic tubing "plastic tubing."
There is other evidence of a proclivity for hyperbole, as in SR&B's claim that if
Austin and Sherman "could comprehend the function and intentionality of their
communications and, through joint symbolic communication, share their access
to tools and the food obtained through tool use - then, by all definitions of human
culture, they would surely have taken a large step" (emphasis in original). This
claim of "all" definitions of human culture is both literally and figuratively a gross
exaggeration. Even a rudimentary acquaintance with cultural anthropology shows
that not only many, but indeed most, definitions of human culture demand more
than the sharing of tools and food through nonverbal communication - which is
what Austin and Sherman did, no matter what "words" were attached to
lexigrams by the experimenters. What cultural anthropologists typically mean by
culture is an elaborate complex of cognitive associations, together with both
linguistic and other symbolic representations thereof, built upon the use of natural
human language. A critical element in anthropological definitions of culture, which
is both conspicuously and oddly missing from the one proffered by SR&B, is
evidence of transferability from one generation to the next. It may be that Austin
and Sherman will succeed by some means of social communication in teaching
their progeny how to cooperate in the sharing of tools and food obtained through
their use. But they haven't done so yet, and the requirement that they succeed in
doing so is a minimal element in most definitions of human culture. We surely can
speak of the culture of preverbal hominids, or of other primates, or indeed of
other animals (iviainardi, 1979); but to identify with all definitions of culture the
exchange of tools and food through the use of nonverbal communication is
unacceptable to most anthropologists (Hall and Sharp, 1978; Weiss, 1973;
Chappie, 1970), to say nothing of other social scientists or humanists (who think
that they also know something about the meaning of culture).
A more serious problem concerns the administration of the major test. In part
the exciting questions raised are rhetorical: "could [Austin and Sherman] perceive
the necessity of requesting tools from one another?" This question is not
answered by the tasks in fact performed because the experimenters evidently
chose not to be daring enough. What would have happened if, after the animals
had been trained in the requisite skills and placed in the experimental situation,
one crucial variable had been omitted: the presence of the experimenter in the
baited room? The chimpanzees' performance would have been extraordinarily
more impressive if they themselves were able to figure out, interactively with the
computer and each other, how to solve their problem. Such a performance would
indeed have answered the question raised by the experimenters about the test
that they in fact administered; but then one more thing would have been essential.
It is remarked that before the test situation, Austin and Sherman "had never
observed one another use tools or employ tool symbols to request tools, and thus
had no reason to presume that the other animal knew and used such symbols or
would cooperate with requests for tools." No explanation for such a research
policy is given; one infers that an assumption was made that such foreknowledge
would "contaminate" the experiment, but it is by no means apparent why this
would have been so. All social skills are learned and shared through social
interaction by feral bands of chimpanzees; and it would be unnatural in the
extreme for one such animal to be able to use tools (or do anything else) without
some other animal in the band having observed his behavior. I think that a mistake
was made in the research design, at precisely this point. It would have been much
better to have gone the other way and socialized this pair of animals in their
reciprocal knowledge about skills in the requesting and use of tools in interaction
with the experimenters; and then to have set up the crucial experiment to
ascertain whether they could voluntarily transfer that knowledge and induce
equivalent interaction with each other. If that stage of the experiment failed, even
after a fair test with role reversals and an adequate number of trials, it would still
have been possible to undertake the explicitly directed training in cooperation that
in fact was done. Indeed, it is entirely possible that the principal accomplishment
of that training was to show the two chimpanzees each other's abilities to use
tools and to use the keyboard symbols to request them.
One's puzzlement that these animals were never given a chance to show what
they might do is enhanced by noting Menzel's remark "that there is already good
evidence that group-living chimpanzees are capable of communicating a good bit
of information to each other about the environment even without the benefit of
extensive human training" (1978, p. 891; 1973a op. cit. SR&B). The spontaneity
of such "cultural" innovations as sweet-potato washing and grain cleansing by
Macaca fuscata (Itani and Nishimura, 1973) is an example familiar to thousands
of undergraduates through courses in comparative psychology and introductory
ethology; and because Pan Troglodytes is considered to be more intelligent than
the macaques (Chevalier-Skolnikoff, 1977), grounds for the missing experiment in
serendipity surely were present in the professional literature of primatology (cf.
Menzel, 1972 op. cit. SR&B). However, as Menzel (1978, p. 890) has remarked,
"The problem of 'animal genius' has . . . received almost no scientific atten-
tion . . . [although] I have been repeatedly impressed ... by how often one can
find a single odd-ball monkey that does something quite out of the ordinary for
other members of [the same] population. . . . [But the] spread of a behaviour
requires good receivers as well as good senders, and for this reason the
group-as-a-whole went nowhere."
This leads us into a closely related point, not discussed by SR&B but manifest
in their data: the significance of individual differences in the intelligence (Gibson,
1977) of these juvenile research animals. SR&B do recognize that "Austin . . . did
attend to the tools closeiy from the beginning" and "Austin initially generalized
from food-naming skills more rapidly than Sherman" and "Austin attended closely
to E's statements and did well from the beginning of this task"; and Table 2
certainly supports these appraisals. But Austin is one year younger than Sherman;
and it is therefore unlikely that the difference in learning speed between them can
be explained on developmental grounds, or at least those of age. It is true that
other differentials in the training or experience of the two animals might be
sufficient to account for Austin's superiority (Chevalier-Skolnikoff, 1977); but no
hint of such information appears in this paper. On the evidence presented, Austin
is a more intelligent chimpanzee than Sherman; and if this is true, that finding
could have been - but apparently was not - used in the design of the "tool
transfer" tests, irrespective of whether these were to be used, as I have argued
they should have been, for an exploration of the ingenuity and intelligence of
these animals. Intelligence could have been a useful variable even if the Cs were
only going to be taught the standard operating procedure, for which purpose it
would seem reasonable to have anticipated a higher standard of performance
from Austin, both in speed and accuracy, than from Sherman.
SR&B claim that their tests are "blind"; but to what extent does this appear to
be true? Implicit in the role of the (unidentified) experimenters during various of the
tests are two problems. One concerns possible differences in the emotional
attachment of each of the two Cs, towards each of the Es. The other is a Clever
Hans problem, and involves the possible effects of unwitting nonverbal cues,
communicated differently but perhaps consistently by different E's. SR&B
acknowledge that "Changes in personnel inevitably resulted in performance
decrement at all stages of training"; and this implies not only that there was some
information loss (mostly, no doubt, nonverbal) when one E replaced another; it
implies also that different cues were communicated by different Es. P&W point out
in their paper that "Sarah's choice was affected by the actor's identity"; and their
paper reports details of the results of her fondness for her regular trainer and her
lesser affection for Keith's substitute. We are not informed about the dispositions
of either Austin or Sherman toward E^ and E2; nor do we know the identity of the
experimenters in the roles discussed in the reports of the tests. Randomizing the
assignment of E's, as well as reversing Cs, in the test roles during their repetition,
would at least have tended to control for whatever effect differential attachments
may have had. SR&B state that "Both animals did very well on these tasks (Table
3), thus demonstrating that their abilities were not dependent upon cues from E."
But aren't affective cues "cues"? Moreover, "In the naming task, E again stood
outside the room and held up a tool so that it was visible to C through a lexan wall,
although neither C nor E could see one another." But if C could see the tool well
enough to distinguish it, he could also see at least part of E's hand, and perhaps
part of his arm(s) too. How much more information does a chimpanzee need to
identify which human (among the small sample of available alternatives) he was
dealing with? There is also an entailed problem of equity in the invocation of
standards for appraising the reliability of these particular research results. For
reasons that are not divulged, each of the blind tests "was administered only
once." Of course, this magnified the opportunity for either of the two types of
598
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4

Commentary/Cognition and consciousness in nonhuman species
extraneous communication discussed above to have influenced the results; but
there is the additional consideration that the Gardners are criticized for their
acceptance of "a weaker criterion of initial acquisition . . . [with only] one correct
spontaneous usage per day," the apparent point being that little confidence
should be placed in data of such putatively low reliability. Evidently, what is sauce
for the goose is not sauce for the Gardners.
SR&B recognize that there is an obvious alternative explanation, and one that
ought to be preferred on philosophy-of-science and methodological grounds: that
Austin and Sherman cooperated as they had been trained to do, and after they
were trained to so behave, by the experimenters. Perhaps, say SR&B, Austin and
Sherman's "use of the keyboard merely reflected the continuance of behaviors
that they had been conditioned to emit by E"; but this straw man is immediately
knocked down, or so the authors presume, by the next sentence and those that
follow it. They remark that "Observations of trials on which Cs were in error
suggested that this was not the case" - but the adjective "anecdotal" is omitted
from the pride of place that it evidently deserves in the sentence quoted, because
all of the evidence presented is precisely that. If these authors are to discount the
research findings of other primatological linguists on the grounds that the
evidence supporting the latters' work is merely anecdotal, as they do in their
critiques of other projects, there seems no reason why we should accept a lesser
standard of proof for their own claims.
Do Premack and Woodruff have a theory of mind [P&W]? Theories of mind get
pretty esoteric even for human subjects; and they are more so in relation to a
species whose natural language is at the more difficult level (Menzel, 1978,
p. 891) of nonverbal communication. Having endeavored to employ a theory of
mind to study certain social behaviors of elite human political decision-makers
(Schubert, 1965, 1974), I am convinced that there must be a more parsimonious
way to tune in on the cognitive signification of a particular chimpanzee's
photographic preferences, without vaulting to the more transcendental levels of
cognitive theory.
There is at least a logical problem with the explication of the theory profferred
(P&W: "can be understood"), as a possible "explanation" of Sarah's photo
choices. The authors' preferred "theory of mind" is defined as Sarah's imputation
of "at least two states of mind to the human actor, namely, intention or purpose
on the one hand, and knowledge or belief on the other." Yet in the concluding
remarks, in the context of further speculations about the possible findings from as
yet unanalyzed data comparing chimpanzees with both normal and retarded
children, it is conceded that chimpanzees may well be /^capable of making
imputations about knowledge. On the basis of the data reported, therefore, it is
more parsimonious to reject these authors' "explanation" of Sarah's behavior, in
favor of the one more consistent with the authors' own supportable imputation
about chimpanzee minds: that Sarah was guided in her choices primarily by her
affective stance towards the human actors.
Alternatively, and these authors to the contrary notwithstanding, it remains
possible that Sarah's discriminations were based on what is described as the
simple matching of physical elements. It is conceded that one of her three correct
choices might be explained by physical matching (the more upright posture of the
actor); but it is argued that the same explanation cannot account for her other two
correct choices, because the actor's posture was not upright in them. Surely this
misses the point of what is implied by "the same explanation." Because P&W's
own discussion is anecdotal, it seems fair to point out that there are an infinite
number of other possible physical matches between the content of the photo-
graphs and the videotape, depending upon what is perceived to be relevant and
important; and it is Sarah's perceptions, not the authors', that count. But even if
no such unwitting cues were present (perceived by Sarah) in either of her other
two correct choices, her discrimination (which P&W call, her "comprehension of
problem solving") is down to two right and two wrong for this series, on P&W's
own concession; and success ratios that match chance are not impressive
evidence of comprehension. Nor does the remark, that "physical matching is
ruled out... even more [for other series to be reported] later," save this series. It
may well be that "chimpanzees . . . can solve problems with strategies more
sophisticated than simply matching physically identical or similar items"; it may
also well be that, not unlike humans, chimpanzees do things the simple, easy way
when they can. In any event, we ought to assume that if Sarah could have solved
these problems by physical matching she did so, leaving her keepers to worry
about the complexity of the primate mind.
The evolutionary continuity of communication fGJ. I associate myself whole-
heartedly with the general tenor of G's thesis. In particular, I agree with his
admonition that "Defining mental experiences as uniquely human discourages
inquiry into the possibility of their occurrence in other species"; and his sugges-
tion of the more useful hypothesis "that thinking and experiencing are related in
comparable ways to the functioning of central nervous systems in various
species." Such cross-species analyses of psychoneural relationships would, of
course, need to be done in the context of all that we know about the brain
systems as well as the behavior systems of each species concerned, pursuant to
Menzel's advice (1978, p. 892) that in "conducting a field study of communica-
tion" among chimpanzees, one should "start at the level of general cognitive,
societal, or even ecological considerations and then work backwards towards
the data that might be of more concern to" cognitive ethologists. Furthermore,
"communication is part of the general information-processing activities of an
organism . . . [and] beneath the 'deep structure' of human language and human
thought there are indeed 'deep-deep' structures that we share with other species,
and ... it is on these structures that our linguistic abilities are predicated"
(Menzel and Johnson, 1976 op. cit. G, p. 140).
The qualitative evolutionary continuity discussed by G refers to development
that is species-specific consequent to divergence, even for such closely related
species as humans and chimpanzees. To take as an example our own
experience, for which the evidence of dynamic change during the past ten million
years is more impressive than that for chimpanzees, we can distinguish among
three levels of communicative ability: nonverbal, verbal speech, and written
language. We can appraise these three modes of human communication in terms
of two dimensions: (1) recency of evolution; and (2) relative efficiency (and/or
use) as a carrier of affective, as distinguished from effective, messages. The
ordinality of these modes is indubitable, and even the interval estimates for the
first dimension are sufficiently disparate to preclude extended discussion for
present purposes. Nonverbal communication developed prior to verbal among
humans, and at least some aspects of it are very much older than the ten million
years to which our knowledge about some characteristics of protohominids can
arguably be stretched. Oral speech evolved much more recently, perhaps a
million to half a million years ago, and in phase with the doubling in size of the
brain. At least on our evolutionary time scale, written language is an exceptionally
recent acquisition and probably it is less than ten thousand years old; the earliest
known writing dates from 5500 B.C., but that threshhold may well be pushed back
by future discovery and research. Conversely, and although their number and
variety are diminishing rapidly, many bands of preliterate, human primitive
societies have been studied throughout the present century: all of these lacked
written language, but were articulate in both verbal speech and nonverbal
communication. Our interest in, and possible admiration for, the adaptive or
esthetic virtues of such other modes of animal communication as whale or bird
song, or bee dancing, cannot sway our appraisal that all of these - indeed, all
known modes of nonhuman communication - are nonverbal, at least in the sense
of written language. On the other hand, many mammalian oral communications,
and certainly those of many canids (Harrington and Mech, 1978) as well as
nonhuman primates, may very well exemplify some of the cross-species psycho-
neural relationships adumbrated by G. Certainly, we should anticipate at least as
broad a spectrum of such relationships for nonverbal human communications,
because of the potentially larger number of homologous species with which they
might be shared.
MacLean's model of the brain (1958; and cf. Lancaster, 1975, p. 62) implies
that affective messages must have been communicated for a very long time
before any animals had developed brains of sufficient complexity to receive or
transmit messages with effective content. Perhaps this is what P&W mean when
they say that "motivational states seem more primitive than cognitive ones" and
that "inferences about motivation will precede those about knowledge, both
across species and across developmental stages." Assuming that to be true, we
might hypothesize that the ratio of affective to effective message content will in
general be maximal for nonverbal human communication, and minimal for
messages in written language, with verbal speech in the middle;3 but that
components of both affective and effective content usually will be present in all
three modes for human communication. Certainly the hypothesis is not inconsis-
tent with such observations as that "The nonverbal communication of nonhuman
primates has traditionally been characterized as species-specific, emotionally-
based, and nonintentional" (SR&B); or that "there is little evidence that the ability
to devise non-verbal codes derives from the prior possession of verbal ones"
(Menzel, 1978, p. 890).
G certainly is correct that "ethology has made a contribution of fundamental
importance by discovering a rich variety of nonverbal communication in many
kinds of animals," and "many social animals communicate by systematic codes
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4
599

Commentary/Cognition and consciousness in nonheman species
which convey information and often lead to predictable changes in the behavior of
the animal receiving the message." We now have available more than a
generation's such work from the students of Tinbergen alone, as exemplified by
the sophisticated models of social communication constructed by the first of
these students, based upon a lifetime of field studies of herring gulls and related
species (Baerends, 1975, 1976a, 1976b); and also by the flourishing of studies of
human nonverbal communication (Hinde, 1972; Argyle, 1975; Key, 1979; Morris,
1977; von Cranach, in press). There is even a beginning of studies that undertake
to analyze all three modes of human communication simultaneously, as diverse
and interacting dimensions of the same social communications (Schubert, in
press).
To the extent that we can study the communicative abilities of chimpanzees
and other animals, with our own minds open to the possibility that in the process
of so doing we may learn as much about our own modes of communication as we
do about theirs, we can begin to explore the evolutionary continuity of mental
experience that is the subtitle of Griffin's book (1976 op. cit. G, SR&B) and that he
has postulated to be the proper task of cognitive ethology.
NOTES
1. The Rumbaughs are much more careful to distinguish between words and
lexigrams in their concluding chapter to the book that they edited (Savage-
Rumbaugh and Rumbaugh, 1977); so it may be that what we confront in the
present paper is a writing problem - but that makes it no less a problem. The
difference between Yerkish lexigrams and English words is explicitly discussed
on p. 96-97, and the design of lexigrams is explained in detail on p. 92-95, in
von Glasersfeld (1977).
2. All three of the authors, plus several other researchers involved in the
design or administration of the LANA project, spoke at a symposium on
"Language Formation Studies with Apes and Children," on September 7, 1978,
at the second annual meeting of the American Society of Primatologists
convening on the campus of Emory University. I was present and heard the
presentations.
3. The modal qualities of speech are illustrated by voice stress analysis (e.g.,
Wiegele, 1978), which provides information about emotional arousal that is
manifest in speech even though undetectable in written transcripts of the same
communications.
REFERENCES
Argyle, M. Bodily communication. London: Methuen, 1975.
Baerends, G. An evaluation of the conflict hypothesis as an explanatory princi-
ple for the evolution of displays. In Baerands, G., Beer, C, and Manning,
A. (eds.), Function and evolution in behaviour: Essays in honour of Pro-
fessor Niko Tinbergen. Oxford: Oxford Univ. Press, 1975.
On drive, conflict and instinct, and the functional organization of behavior.
In Corner, M. A., and Swaab, D. F. (eds.), Perspectives in brain research:
Progress in brain research, vol. 45. Amsterdam: Elsevier/North-Holland
Biomedical Press, 1976a.
The functional organization of behaviour. Animal Behaviour 24:726-738,
1976b.
Burke, K. Attitudes toward history, vol. 2. New York: New Republic Press,
1937.
Chappie, E. D. Culture and biological man: Explorations in behavioral an-
thropology. New York: Holt, Rinehart and Winston, 1970.
Chevalier-Skolnikoff, S. A Piagetian model for describing and comparing so-
cialization in monkey, ape, and human infants. In Chevalier-Skolnikoff,
S., and Poirier, F. E. (eds.), Primate bio-social development. New York:
Garland, 1977.
Gibson, K. Brain structure and intelligence in macaques and human infants
from a Piagetian perspective. In Chevalier-Skolnikoff, S., and Poirier,
F. E. (eds.), Primate bio-social development. New York: Garland, 1977.
Hall, R. L. and Sharp, H. S. (eds.) Wolf and man: Evolution in parallel. New
York: Academic Press, 1978.
Harrington, F. H., and Mech., L. D. Wolf vocalization. In Hall, R. L., and
Sharp, H. S. (eds.), Wolf and man: Evolution in parallel. New York: Aca-
demic Press, 1978.
Hinde, R. A. (ed.) Non-verbal communication. Cambridge: Cambridge Univ.
Press, 1972.
Itani, J., and Nishimura, A. The study of infra-human culture in Japan: A re-
view. In Menzel, E. W. (ed.), Precultural primate behavior. Basel
S. Karger, 1973.
Key, M. R. (ed.) The relationship of verbal and nonverbal communication.
The Hague: Mouton, 1979.
Lancaster, J. B. Primate behavior and the emergence of human culture. New
York: Holt, Rinehart and Winston, 1975.
MacLean, P. D. The limbic system with respect to self-preservation and pres-
ervation of the species. Journal of Nervous and Mental Disease 127(1):1-
11, 1958.
Mainardi, D. Tradition and the social transmission of behavior in animals. In
Barlow, G. W. , and Silverberg, J. (eds.), Sociobiology: Beyond na-
ture/nurture. A.A.A.S. Special Symposium 35. Boulder, Colo.:Westview
Press, 1979.
Menzel, E. W., Implications of chimpanzee language-training experiments for
primate field research - and vice versa. In Chivers, D. J. and Herbert, J.
(eds.), Recent advances in primatology. 1. Behaviour. London: Academic
Press, 1978.
Morris, D. Manwatching: A field guide to human behaviour. London: Jona-
than Cape, 1977.
Pfeiffer, J. E. The emergence of society. New York: McGraw-Hill, 1977.
Savage-Rumbaugh, E. S., and Rumbaugh, D. M. Communication, language,
and LANA: A perspective. In Rumbaugh, D. M. (ed.), Language learning
by a chimpanzee: The LANA project. New York: Academic Press, 1977.
Schubert, G. The judicial mind: The attitudes and ideologies of Supreme
Court Justices, 1946-1963. Evanston, III: Northwestern Univ. Press, 1965.
The judicial mind revisited. New York: Oxford Univ. Press, 1974.
Nonverbal communication as political behavior. In Key, M. R., and Preziosi,
D. (eds.), Nonverbal communication today: Current research, in press.
von Cranach, M., et al. (eds.) Human ethology: Claims and limits of a new
discipline. Cambridge: Cambridge Univ. Press, in press.
von Glasersfeld, E. Linguistic communication: theory and definition. In Rum-
baugh, D. M., (ed.), Language learning by a chimpanzee: The LANA
project. New York: Academic Press, 1977.
Weiss, G. A scientific concept of culture. American Anthropologist 75:1376-
1413 (esp. p. 1395), 1973.
Wiegele, T. C. Physiologically-based content analysis: An application in politi-
cal communication. In Ruben, B. D. (ed.), Communication yearbook 2.
New Brunswick, N.J.: Transaction Books. 1978.
Wilson, E. O. Sociobiology: The new synthesis. Cambridge, Mass.: Harvard
Univ. Press, 1975.
byj. 
P. Scott
Center for Research on Social Behavior, Bowling Green State University, Bowling
Green, Ohio 43403
Fantasy and communication. I am delighted to have the opportunity to comment
on this series of papers on the inner life of nonhuman species, but in doing so I
shall start from a somewhat different frame of reference. If any general conclu-
sions can be drawn from human subjective reports, it is that the inner world of
humans is only indirectly and remotely related to the real world around them. We
do react to the stimuli in the surrounding environment, but most of our time is
spent in fantasy, thinking about things that have been, might be, or never will be.
Most of us keep this process under control, but some do not, and fantasy has
consequently been associated principally with maladaptive behavior, and as such
has been much studied by psychiatrists and clinical psychologists. Because of its
association with madness, fantasy has connotations of uselessness. I suggest,
on the contrary, that this kind of activity is extraordinarily adaptive, enabling us to
solve problems more efficiently and directly than by trial and error, and to create
new, useful, and enjoyable objects and activities.
One of the side effects of the evolution of human language is that it makes it
possible for one person to share his fantasies with another, in stories, through the
written word, through television, through music, and other forms of artistic
expression. Obviously, living in someone else's fantasy world is highly rewarding
to most of us. Objectively considered, even this present exchange of scientific
communication is a method of sharing our various fantasy worlds.
What is the nature of fantasy? Subjectively reported, some of it is verbal. We
speak, listen, and even write in imagination. However, this is not all. A very
important part of human fantasy is visualization; we actually see things in
imagination. Similarly, we can create things and events through any sensory
modality: hearing, touch, smell, kinetic sensation, or any combination of these.
With this process we solve problems, we create new things, and we activate
ourselves, responding to much more than immediately concurrent stimuli. All this
is part of being an organism with the properties of a living system rather than a
mechanism.
These observations raise the problem of whether similar capacities are present
in other species than man. First, does any nonhuman species possess all the
capacities necessary for verbal language? The answer to this question is no;
there is no other talking animal, although the research with anthropoids reported
by SR&B shows that our close biological relatives have, at least in latent and
primitive form, capacities to manipulate symbols similar to those capacities that
may have preadapted our own species to evolve verbal language.
600
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4

Commentary/Cognition and consciousness in nonhuraan species
A second question is, Do other animals have nonverbal capacities to fantasize,
such as visualization? The answer is probably yes, from the evidence of the
complex problem-solving abilities that have been well demonstrated in a variety of
nonhuman research animals, including the primates investigated by P&W.
A third question is whether or not nonhumans can communicate their inner
fantasy world, either within species or across species. Could a chimpanzee, for
example, given sufficient training in manipulating symbols, communicate to a
human experimenter a "thought" independently of immediate stimulation from
external sources and internal needs? Finding the answer to this question is the
most difficult of all, as it must involve a great deal of indirect inference and
subjective judgment.
The three papers in this series comprise three quite different approaches to
this general problem of the inner world of nonhuman animals. That by SR&B is a
straightforward attempt to extend the capacities of symbolic transfer of informa-
tion in chimpanzees to a social situation involving two chimpanzees and includes
an excellent critical review of the field. Their demonstration of communication
between two trained chimpanzees brings up the question of whether this ability is
ever used by chimpanzees in natural situations. I am aware of no reports of
chimpanzees or gorillas sitting around and exchanging reciprocal series of
symbols, but this may have simply been overlooked.
The two papers by P&W and G are different in that they make frequent use of
the concepts of "mind" and "mental." Historically, these concepts are a part of
philosophical dualism, usually attributed to Descartes, but also part of our cultural
tendency to dichotomize and arrange phenomena into bipolar opposites. What-
ever the limitations of the behaviorists, they at least enabled us to escape from
this straitjacket. I can do no better than to repeat the remark of Robert M. Yerkes,
who once said, "I never saw a disembodied mind."
The paper by P&W comes the closest to dealing with the third problem listed
above, namely the transfer of the inner world of images, but it becomes confused
with the philosophical problem of what is consciousness [see also Puccetti &
Dykes: "Sensory Cortex and the Mind-Brain Problem" BBS 1(3) 1978]. To me,
consciousness presents no great conceptual difficulty - it simply means that one
is able to put something into words and so have a dual or multiple awareness of a
particular phenomenon. P&W directly approach this problem in nonhumans,
attributing human verbal concepts to animals that we know do not have words.
While it is not impossible that a chimpanzee could somehow have acquired such
concepts, the notion is inherently a dubious one. This does not exclude the
possibility that animals could be conscious in the sense of being able to separate
various nonverbal sorts of fantasy modalities.
G presents a stimulating call for ethologists to attack the problem of cognition
in nonhumans. There are two cases of communication that approach that of
humans - the dancing bees and the signing apes. Of the two, bee language is like
human language in that bees can convey information about a third object to
another bee, something which is yet to be demonstrated in field studies of
primates. G feels that this evidence justifies our looking for unknown inner
phenomena in the nonhumans, and I agree. But insofar as he has fallen into the
trap of mentalism, his plea is likely to be rejected. Whatever the inner life of other
animals, it is going to be different from that of man. Species do not evolve in
parallel but divergently.
As a minor point, G uses the word "institution" in a sense that departs from its
usual meaning with respect to humans. As used by sociologists, human institu-
tions such as religion, government, and so forth, are supra-organizations based
on verbal language and culture, and for which it would be impossible to find
analogues in nonhuman societies.
It is obvious that this field of inquiry lends itself to controversy. By its nature, it
rests on subjective inferences concerning human nature. If what I have said about
the creative nature of the human internal world is correct, it follows that subjective
inferences will vary from one individual to another. Finally, I am in favor of fantasy
(suitably controlled) in science. It has always been fascinating to speculate
concerning the inner world of other animals, and I hope these papers will start us
on the way to something more than speculation. And, whatever we find about the
nonhumans, this kind of research will lead us to know more about ourselves.
by Ewaiyn Fe Segal*
Department of Psychology, San Diego State University, San Diego, Cal. 92182
Does mind matter? The December 5, 1978 San Diego Union ran the following
episode of the comic strip "Tucker" by Joe Martin. Two men are seated facing
one another. One has an animal (probably a chimpanzee) on his lap. Behind the
man with the chimpanzee stands a third man, looking on. The following conversa-
tion occurs:
Man with chimpanzee: I've spent 10 years trying to prove that man could
communicate with the apes, only to find their level of intelligence so hopelessly
below humans that I must abandon research and seek new work.
Second seated man: Gee, that's too bad.
Chimpanzee: Grrbnit.
Onlooker: (looking at his watch) Almost 10:30.
How shall we interpret the onlooker's remark? Was he Natural Man,.under-
standing the chimpanzee's utterance where the foolish scientist (probably a
positivist behaviorist) had lost the natural ability to do so? Or was he engaging in
"rich interpretation" (Brown, 1973) of the chimpanzee's vocal noises, imputing to
the chimpanzee his own state of mind (perhaps it was time for his mid-morning
coffee break)?
But then, do we need to impute a state of mind to the onlooker? Harzem and
Miles (1978), in a recent discussion of philosophical issues in behaviorism, remind
us of Wittgenstein's "polar principle" - "Since concepts distinguish, they divide
material in at least a two-fold way. Thus if one characterizes something as being
'X" one is thereby excluding the thesis that it is 'not-X.' . . . The polar principle,
then, invites us to ask the question, 'As opposed to what?' "
What would it mean to say that the chimpanzee, or the human onlooker, does
not have a theory of mind? Theory of mind as opposed to what? What would it
mean to say that the chimpanzee, and the human onlooker, do not have minds at
all? Minds as opposed to what?
I am enormously impressed with the experiments that P&W and SR&B describe
in their papers. They have uncovered, or instilled (as the case may be),
remarkably complex behavior in their chimpanzees. The work that these investi-
gators have been doing over the past ten years has revealed an affinity between
ape and human that was hardly suspected earlier. But, as a thoroughly indoctri-
nated positivist behaviorist, what I do not understand is the necessity for ascribing
a mind, or a theory of mind, either to human or to chimpanzee. How would our
understanding of brain and behavioral processes be different if we did not do
so?
Reading G's paper, I think I glimpse the key to my puzzlement. G, and P&W,
appear to be using mind, awareness, theory of mind, mental states, and the like,
as causal terms. But surely mind, if it refers to anything, simply names the
complex functioning of an organism with a complex brain, so complex that subtle
relations among stimulus events in the environment are able to trigger corre-
spondingly complex (brain-mediated) behavior? I do not doubt that Sarah, viewing
the trainer's videotaped predicament, selects the photograph that depicts the
correct solution. I do not doubt that Austin and Sherman have learned the value of
sharing the loot that speaker-listener cooperation has enabled them to obtain.
The information-processing mechanisms of the chimpanzee brain must be on a
scale of complexity comparable to the human's. To express one's appreciation of
such behavior by awarding it the epithet of mind is at least excusable. What does
not seem to me excusable is the intimation that talk of mental states or
awareness explains the chimpanzee's or the human's information-processing
mechanisms, or how those mechanisms govern overt behavior. Contemporary
psychology appears to want to call back the ghost in the machine, as contempo-
rary society longs to call back God. I understand that a belief \n spirits of one or
another sort may affect both one's everyday behavior and one's scientific
behavior, but I cannot believe that spirits do. If they do, then what we need is a
theology of chimpanzee and human, with P&W and G showing us the way to
Revelation. For myself, I prefer to go on studying and cataloguing the functioning
of complicated organisms in interaction with their complicated environments, and
to admit that I haven't a clue how they do it. My faith is that the answer lies in the
brain, not the mind.
REFERENCES
Brown, R. A first language: the early stages. Cambridge, Mass.: Harvard Uni-
versity Press, 1973.
Harzem, P., and Miles, T. R. Conceptual issues in operant psychology. New
York: Wiley, 1978.
Martin, J. Tucker. San Diego Union, December 5, 1978.
EDITORIAL NOTE
"Received too late for a Response from G or SR&B. See Continuing Commen-
tary.
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4
601

Commentary/Cognition and consciousness in nonhuman species
by Aaron Sloman*
Cognitive Studies Programme, School of Social Sciences, University of Sussex,
Brighton BN1 9QN England
What about their internal languages? 1. Fun, but so what? All three papers
are, of course, fascinating sources of information about some of the things
chimpanzees and bees can do. It is comforting to have rigorous laboratory
observations to reinforce and augment what every dog-owner or circus-goer
knows about the rich mental life of other animals. No doubt anecdotal evidence
cannot be as important for the advance of science as papers that resound with
phrases such as "the altered performance was again accompanied by a
noticeable orientation of the attentional response" (SR&B). Behaviourists will
surely cower and tremble before P&W's ingenious use of the antibehaviourist
beliefs of apes! And, finally, we must welcome G's use of philosophy to push
away some behaviourist barriers to scientific insight, even if both mentalists and
behaviourists prove unable to provide theories with deep explanatory power.
Yet, despite their virtues, and the evident satisfaction with which these authors
put down their intellectual rivals, I find something sadly lacking: an awareness of
deep problems and a search for deep explanations. I'll try to enlarge on this.
2. Deep science and shallow science. Looking back over the history of
science we can distinguish three major types of advance:
1. the collection of facts expressible in previously available language,
2. the extension of our thinking powers by the creation of new concepts,
taxonomies, symbolisms and inference techniques, and
3. the construction of generative explanatory theories about underlying mech-
anisms, a task that has much in common with engineering design.
The collection of facts (including laws and generalisations) is intrinsically
interesting, and also important for the other two processes, since facts determine
what it is that our theories need to explain and help to show up inadequacies in
our descriptive and explanatory resources, and they may even be of great
practical value. But facts alone give us no new understanding, no new insight into
underlying mechanisms, no new ways of thinking about old phenomena.
Are the authors of these papers merely concerned to collect facts? Clearly not:
they are also deeply concerned to learn the extent of man's uniqueness in the
animal world, to refute behaviourism, and to replace anecdote with experimental
rigour. But what do they have to say to someone who doesn't care whether
humans are unique, who believes that behaviourism is either an irrefutible
collection of tautologies or a dead horse, and who is already deeply impressed by
the abilities of cats, dogs, chimps, and other animals, but who constantly
wonders: How do they do it?
This is the sort of question which is at the heart of all science (and philosophy),
namely: "How is this possible?" For example: How is it possible for a chimp to
interpret flat pictures as representing three-dimensional scenes involving agents
with purposes (P&W)? How is it possible for a chimp to learn to fish for juice with a
sponge on a string (SR&B)? How is it possible for a bee to find its way to a
specific location (G)? How is it possible for a chimp to pull a blanket with just the
right force to retrieve a ball? How is it possible for a chimp to learn that after being
shown a videotape she is to select a photograph from a box left by the
experimenter before he departs, then place the picture alongside the television
set, and finally ring a bell to recall the experimenter (P&W)? How can a chimp
realise that tapping another's hand is an adequate method of getting the latter to
relinquish the straw through which he is sucking juice (SR&B figure 6e)? How does
the other chimp know that this is the intention? How can they learn to push
buttons? How can they remember where to look for the effects? How can they
learn associations? How can they use them? How can they combine previously
learnt actions into larger wholes (SR&B)? How can they use so-called iconic
symbolism (SR&B)? How can they form beliefs? How can they react to unintended
cues from experimenters? How can they form beliefs about the intentions or
beliefs of others (all three papers)? How can they have likes or dislikes (P&W)?
Of course, all these, and myriad other questions suggested by the papers, may
be asked about human beings too! But when the authors begin to broach such
questions, for instance as G does at several points, they hardly seem able to go
beyond antibehaviourist incantations that reiterate what has always been obvious
to anyone with common sense: that animals have experiences, beliefs, hopes,
fears, doubts, surprises, intentions, plans, and so on. As if we already knew how
to explain these things, and the only problem was to collect more examples.
3. Am I being unfair? One cannot do everything, least of all in a short scientific
paper, even a speculative one, like G's. Surely a scientist is entitled to choose an
area of research and pursue it? Surely it is unreasonable for me to criticise these
authors for not pursuing the questions that interest me? Perhaps, but I suspect
that it is not merely a difference of interest that is at issue.
Although the questions I have formulated are still a long way from being
answered, one thing seems clear from the few serious attempts that have been
made to gain some insight into these matters: all the abilities in question seem to
depend on internal processes in which symbols of some kind are constructed,
stored and manipulated: they use inner languages.
For some first crude attempts at theorising about such internal processes see
Miller et al. (1960), and more recent work in artificial intelligence reported in
Sussman (1975), Winston (1975, 1977), Boden (1977), 
and Lindsay and
Norman (1972). What sorts of internal symbolisms are required? How are they
used? How are they acquired? Are very different kinds used for different
purposes? How are they stored? How did they evolve? These are all basically
unanswered questions. But if it is even remotely plausible that in order to perceive,
learn, find their way around some terrain, form and execute intentions, and so
forth, animals must make use of internal symbolisms, then surely one might
expect discussions of the ability of apes to use overt languages (sign language,
push-button language, gesture, or whatever) to be related to speculations about
their inner linguistic competence?
The essence of language is often thought to be its use in communication. What
I am saying is that there is a more fundamental class of uses - for storing
information and procedures, and for making inferences, forming plans, guiding
actions, and so forth. In every way this is more basic: it evolves earlier, it develops
earlier in individuals, and it is a prerequisite for the overt use of language for
communication.
This inner symbolic competence is clearly quite profound even in relatively
unintelligent animals, to judge from the enormous difficulties artificial intelligence
workers have experienced in their efforts to simulate apparently commonplace
abilities. (I am not talking about physiological processes. Studying the physiology
of a computer can tell you very little about the programs that run on it, since these
may be radically altered without physiological change.) Could it not be the case
that by theorising about such (mostly unconscious) inner symbol-manipulating
processes (going far beyond traditional mentalists in precision and detail), we
might be able to form a framework to guide research into the overt linguistic
abilities of apes, and possibly other creatures? And then we shall not be
dependent for our scientific motivation on a concern about the uniqueness of
human beings, or semantic quibbles about the essence of language! Unless work
on the behaviour of animals is placed in the context of attempts to theorise about
underlying mechanisms, it is little more than ethological rubber-necking (often
done very effectively in TV documentaries).
4. On experimenting in the dark. Insofar as claims are being made about
controlled experiments, we have a right to ask "How do the experiments work?"
A scientist should not be satisfied with an experiment using some complicated
piece of apparatus whose behaviour he could not explain. Yet all the experiments
described in these papers require the animals to deploy very complex cognitive
skills: perceptual skills, learning skills, problem-solving skills, memory skills.
Without the use of these skills, the animals would not be able to acquire or display
the other skills that are explicitly being studied, such as the ability to use symbols
in a cooperative situation, or the ability to think about somebody else's predica-
ment. Why are the researchers content to study the latter skills without any theory
of the mechanisms underlying the skills that are part of their experimental set-up?
Without such understanding, the observed behaviour is subject to radical
ambiguities of interpretation. How can we tell to what extent the experimentalists'
descriptions are naively anthropomorphic?
I suspect that many experimenters are as unaware of the need for explanations
of the kinds requested above as the child who feels no need for an explanation of
why unsupported apples move downwards. For instance SR&B assume that
"deferred imitation" might explain some of Washoe's behaviour, and P&W
suggest that "physical matching" might be an explanation of some of Sarah's
problem solving.
5. Conclusion. Of course I cannot now give explanations, and that is the main
reason why my criticism is so unfair. But I have a strong suspicion that in the long
run we shall all learn more if we spend a little less time collecting new curiosities
and a little more time pondering the deeper questions. The latter are harder and
don't generate publications so easily, but the questions are important and we
need more good young scientists trained to think about them. The best method I
know of is to explore attempts to design working systems that display the abilities
we are trying to understand. Later, when we have a better idea of what the
important theoretical problems are, we'll need to supplement this kind of research
with more empirical studies (cf. Pylyshyn 1978).
602
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4

Commentary/'Cognition and consciousness in nonhuman species
Finally, an ethical comment. The discoveries reported in the papers by SR&B
and P&W show that at least some apes have a profound potential which they
cannot realise without human intervention. (It is not clear how far the use of
computerised equipment is essential.) This is no different from the situation with
humans: without the benefit of an elaborate culture a human child will not develop
the ability to talk, to play or enjoy music, to solve mathematical problems, to
puzzle about the workings of the human mind. It is now widely accepted that
people have a right to the kind of education and social opportunities that will
enable them to realise their potential - not all their potential of course, for
instance not the potential to become vicious, which possibly lurks in all of us.
Whether they have the right or not, it is clear that for the vast majority of human
children the opportunities for development just are not available - and often the
right is not recognised. But insofar as they have the right, it would seem that
similar reasons exist for ascribing such a right to other animals. Where this
argument ends I cannot tell, but at least it should be borne in mind by all who are
interested in finding out just how much apes can be helped to become human.
REFERENCES
Boden, M. A. Purposive Explanation In Psychology. Cambridge, Mass.: Har-
vard University Press, 1972. Reprinted: Harvester Press, 1978.
Artificial intelligence and Natural Man. Hassocks: Harvester Press, 1977.
Lindsay, P. H. and D. A. Norman. Human Information Processing. Academic
Press, 1972 (and new edition 1977).
Miller, G. A., Eugene Galanter, and K. H. Pribram. Plans and the Structure of
Behaviour. New York: Holt, 1960.
Pylyshyn, Z. W. "Computational models and empirical constraints." In The
Behavioural and Brain Sciences 1, 93-127. 1978.
Sussman G. A Computer Model of Skill Acquisition. New York: American El-
sevier, 1975.
Winston, P. H. The Psychology of Computer Vision, New York: McGraw-Hill,
1975.
Artificial Intelligence. Addison Wesley, 1977.
EDITORIAL NOTE
"Received too late for Response from G, P&W, and SR&B. See Continuing
Commentary.
by Charles T. Snowdon and Alexandra Hodurt
Department of Psychology, University of Wisconsin, Madison, Wise. 53706
What's the matter with mind? The vehemence with which criticism has been
directed toward Griffin's proposal that animals have a mental life and experience
something akin to what we call "awareness" is simultaneously reasonable and
puzzling. Understandably, behaviorism evolved as a historical antidote to the
excesses of structuralist introspection in human psychology and to the excesses
in attribution of mental qualities such as "the appreciation of music" to birds, the
use of "tactics and strategems" to insects, and "heroism and patriotism" to dogs
(Lindsay, 1888) common in the last century. Given the behaviorists1 decision to
study laboratory rats and pigeons in a highly restricted laboratory environment,
evidence of behaviors that would allow one to intuit the existence of something
akin to mental states in animals would be rare indeed.
However, if one considers that the study of mental states has again become a
legitimate topic in psychology (masquerading as human information processing or
cognitive psychology) or if one observes animals other than laboratory rats in
natural environments or even in greatly enriched laboratory environments, it is
puzzling that G's arguments should have provoked so much controversy [see
Haugeland: "The Plausibility of Cognitivism" BBS 1(2) 1978).]
In a sense there is nothing really new about "cognitive ethology. Some mental
processes of animals have been extensively studied over the past three decades.
For example, psychophysical functions have been gathered in a large number of
species in several sensory modalities, and a psychophysical function is a
statement about the relationship between the physical world and the mental world
[see Wasserman & Kong: Absolute Timing of Mental Activities" BBS 2(1) 1979].
Short-term and long-term memory processes have been extensively studied in
animals using many of the same techniques used by cognitive psychologists to
elucidate the structure of the human mind (Medin, Roberts, and Davis, 1976 op.
cit. G). Even such mental states as "expectancies," "desires," and "intentions"
can be studied objectively in animals following paradigms devised by Irwin (1971).
The intellectual processing capacities of some animals have been shown to differ
only in degree from those of human beings by a large variety of studies ranging
from Kohler's to those of present-day chimpanzee researchers. Thus, there
should be no difficulty for even the behaviorist to accept that certain aspects of
the animal mind can be effectively studied.
What then is the problem? G is proposing that animals may experience
awareness of self and of others, that they have intentions, and that they may
experience emotions such as empathy, joy, or fear. There seems to be no a priori
reason for rejecting these attributes of mind for nonhuman animals, while
accepting the psychophysical and intellectual similarities of human and nonhuman
animals. Yet questions of awareness, emotion, intentions, or consciousness
seem to raise the behaviorist's hackles more than questions of perception,
learning skills, tool use, and so forth. Perhaps it is the behaviorist's traditional
subjects, white rats and pigeons, that impose blinders. After all, even if I accept
the rat's perceptual or operant behavior as a model of similar processes in human
beings, do I dare attribute consciousness, awareness, or empathy to a creature
like that!
However, even casual observation of animals in more natural environments
suggests, at least intuitively, some of the mental states that G argues exist in
animals. Consider the following anecdotes: (1) On warm days a cat is put outside
early in the morning. As the days become colder in the fall the cat disappears
from sight somewhere between 8:15 and 8:45 A.M. If anyone searches for her, it is
unlikely that she will be found in the same location on successive days. (2) An
infant pygmy marmoset has been pestering its adolescent sibling for several
minutes. The adolescent begins to move and emits calls that generally accom-
pany movement to a distant part of the home range. The infant follows. The
adolescent stops en route. The infant passes by and continues on to the other
location. The adolescent ceases calling and returns to its original location without
the infant. (3) Pygmy marmosets almost always give a call when approaching the
feeding tree. Other feeding animals move away. Occasionally the animal fails to
call and arrives at the tree unannounced. Invariably a brief fight ensues. (C.
Snowdon and A. Hodun, unpublished observations.)
One can argue that each of these anecdotes provides presumptive evidence
for qualities such as awareness of self, awareness of others, intentionality, and in
the second case even deception. Mere anecdotes, however, fail to prove the
existence of such mental states. In fact, claims of mental states for these animals
may be subject to the same mistakes Lindsay and others made in the last century.
Nevertheless, contrary to the argument of SR&B, anecdotal data and intuitions
should not be rejected out of hand. The overwhelming weight of many such
anecdotal observations has motivated the search for the existence of mental
states in nonhuman animals (and not just in chimpanzees and honey bees), and
subsequently, attempts to demonstrate formally that such states exist. (It is
interesting to note that no primatologist with whom we have discussed G's
proposals for animal awareness has objected to them. In fact the typical
response is "So what else is new?")
How does one formally demonstrate mental states in nonhuman animals? G
proposes that the chimpanzees who have learned an artificial communication
system are the best subjects for confirming such mental states. On the other
hand, the papers by Savage-Rumbaugh et at. and by P&W indicate that the
artificial communication systems taught their chimpanzees may not be that useful
for understanding the mind of the chimp. SR&B make much of the fact that chimps
can exchange information and material through a symbolic communication
system. Rather than illustrating notions of chimpanzee awareness, conscious-
ness, and so forth, the studies seem rather to indicate that chimpanzees can be
remarkably clever in obtaining food. In fact, obtaining food underlies all the
communication that goes on in the Yerkes laboratory. All the conversations
reported for Lana revolved around her obtaining food; otherwise she seemed
uninterested in conversing (Rumbaugh, 1976 op. cit. SR&B). Likewise, Sherman
and Austin only learn the names of objects that are useful for obtaining food.
Given this concreteness about using symbols only when they will serve to obtain
food, it is difficult to imagine a Yerkes chimp ever being able to learn the
lexigrams needed to tell us about mental states. It would be interesting to know
whether chimpanzees can acquire and use symbols that could express self-
awareness, empathy, prevarication, and the like, or whether being able to
communicate about mental states abstractly is one of the few points of unique-
ness remaining to human beings. However, a symbolic communication system
may not be necessary for the inference of mental states.
The most interesting point in the SR&B paper is the observation that the
animals share food with each other. Since there is little or no evidence that
chimpanzees ever share food in the wild, it is significant to find that the
chimpanzee who obtains the food shares it with the one who provides the tool for
obtaining the food. Unfortunately, no information is presented on the acquisition
of food-sharing behavior. Did food sharing occur on the first trials or did one
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4
603

Commentary/'Cognition and consciousness in nonhuman species
chimpanzee have to learn to share food with the other in order to have the other
continue to provide tools? If the chimpanzee knew on the first occasion that he
would have to share food with the tool provider to obtain continued cooperation,
then that would be evidence that the chimpanzee has a theory of mind. It would be
interesting to know whether tool exchange would still occur if food exchange were
prohibited. So long as each chimpanzee had equal opportunity as tool provider
and tool receiver, they would still receive equivalent amounts of food. However,
the animals would have to develop a strategy based on anticipating future food
availability and future dependence upon the other animal in order to be motivated
to provide immediate assistance to the other animal in obtaining food. Such
behavior would demonstrate a very sophisticated theory of mind. It is a pity that
SR&B have restricted so much of their presentation to a critique of "linguistic"
chimpanzees and a defense of their own methods. They have missed the fact that
the issue has moved beyond one of linguistic competence to the broader issue of
the structure of the chimpanzee mind.
Premack & Woodruff show that mental states in chimpanzees can be studied
effectively. Such studies do not require a symbolic communication system nor do
they require a dependence upon food reinforcement in order to demonstrate
mental states. The studies of P&W are much more like those one would perform
with human beings, and because a symbolic communication system is not
necessary, their methods can also be applied to the study of mind in other
species. On the basis of what P&W present, and on the gleanings from the SR&B
experiments, there is evidence not only that our intuitions about mental states
existing in nonhuman animals are likely to be accurate, but also that we can study
such states in a rigorous fashion without repeating the errors of Lindsay and his
followers.
REFERENCES
Irwin, F. W. International Behavior and Motivation: A Cognitive Theory.
Philadelphia: Lippincott, 1971.
Lindsay, W. L. Mind in the Lower Animals. New York: D. Appleton, 1888.
by Stephen PÂ» Stieh*
Department of Philosophy and Committee on the History and Philosophy of
Science, University of Maryland, College Park, Md, 20742
Cognition and content in nonhuman species. "What, if anything, do animals
think about?" This is the question with which Griffin begins his paper. The thesis
of my commentary is that G's question is badly cast, for it conflates a pair of
questions that are best kept apart. His question suggests that if animals think at
all, then they must think about something. And this, in turn, suggests that if we
cannot say what an animal thinks or believes, then it is inappropriate to say what
an animal thinks or believes, then it is inappropriate to say that the animal has
thoughts or beliefs at all. On my view, the cognitive ethologist would do well to
separate the question of whether animals think from the question of what they
think, and thus leave open the possibility that certain species of animals are
cognitive systems, though we cannot, in principle, say what it is they think. Put in
another way, what I am urging is that we distinguish the question of whether an
animal is a cognitive system [see Haugeland: "The Plausibility of Cognitivism"
BBS 1(2) 1978] from the question of whether its cognitive states have an
expressible content, and if so, what content they have. Let me elaborate on both
these questions.
1. Are animals cognitive systems?
Our everyday vocabulary about mental states and processes gains much of its
meaning from the role it plays in an informal and largely tacit theory, a folk
psychology, which we regularly invoke to explain our own behavior and that of our
fellows. Thus consider the following dialogue:
A: "Why did Nixon keep the Watergate tapes?"
B: "Because he believed that he could never be forced to surrender them, and
he wanted to use them to write his memoirs. If he had believed that he would be
ordered to turn them over, he surely would have burned them." Here a certain
action or bit of behavior (Nixon's keeping the tapes) is explained by citing a belief
(that he could never be forced to surrender them) and a want or desire (to use
them to write his memoirs). Also, a counterfactual prediction is offered: had he
had a different belief, he would have behaved differently.
The folk psychology of beliefs and desires has been the subject of consider-
able philosophical scrutiny (Dennett, 1969, 1978; Fodor, 1975; Goldman, 1970;
Harman, 1973; Lewis, 1974; Stich, 1978a, 1978b, 1979a). The theory postulates
two quite different types of psychological states, beliefs, and desires, with normal
subjects having large numbers of each. It also postulates several additional
mechanisms and systems which interact with a subject's store of beliefs and
desires. They include the following:
i. the perceptual system(s), which serve to monitor the external and internal
environment and to insert and delete beliefs from the belief store as the
perceptual input changes;
ii. the inference mechanism, which generates new beliefs from old;
iii. the "practical reasoning" mechanism, which generates new desires from
old desires in conjunction with beliefs (as when my desire to hear Solti conduct
and my belief that he will be conducting at the Kennedy Center next Saturday
generate the desire to go to the Kennedy Center next Saturday);
iv. the desire-interpreting mechanism(s), which convert certain desires (like
the desire to move my left leg forward) into appropriate bodily motions.
There is much more that might be said about the various components of our
folk-psychological theory. For the present, however, these brief remarks, along
with figure 1, will, I hope, suffice to indicate something of the gross architecture of
the theory.
Now I have claimed that folk psychology is the intuitive theory used by the
ordinary man when offering common-sense explanations of the behavior of his
fellows. But, of course, there is no guarantee that this folk theory is a true theory,
or even a first approximation to a true theory, of the explanation of behavior.
Indeed, it is just on this point that behaviorists and cognitivists divide. The
behaviorist urges that there is no need to postulate anything that much resembles
the elaborate and interacting systems of folk psychology, since behavior can be
explained by postulating much more modest mechanisms intervening between
stimulus and behavior. Cognitivists, by contrast, are inclined to take folk psychol-
ogy seriously, at least as a first approximation. Thus the cognitivists' models will
postulate beliefs (or memories or cognitive maps or schemata) and desires (or
plans or goal structures) along with perceptual and inferential mechanisms which
interact more or less along the lines sketched in figure 1. As I propose to use the
term cognitive system, the claim that a given subject is a cognitive system is
equivalent to the claim that a theory that accounts for the subject's behavior will
be cast along the lines of figure 1. A thoroughgoing behaviorist would claim that
neither animals nor people are cognitive systems. However, there is no a priori
reason to think that the same model is applicable to all species. So it would be
perfectly consistent to be a behaviorist about paramecia and a cognitivist about
chimpanzees. As G stresses, the behaviorist model is wildly implausible for
animals like chimpanzees. The complexity and sophistication of the behavior
recounted in the Savage-Rumbaugh etal. and Premack & Woodruff papers serve
to underscore the point. G is surely right that much of the allure of a thoroughgo-
ing behaviorism is rooted in the suspicion that the alternative is some form of
Cartesian dualism which postulates a ghostly extramaterial realm [see Puccetti &
Dykes: "Sensory Cortex and the Mind-Brain Problem" BBS 1(3) 1978]. But the
suspicion is quite unfounded. To say that an animal is a cognitive system, and
Perceptual
systems
Figure 1 (Stich). Cognition and content in nonhuman species.
604
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4

Commentary/Cognition and consciousness in. nonhuman species
thus that it has beliefs and desires, makes inferences, and so forth, is to say
simply that the mechanisms responsible for the animal's behavior are organized
(more or less) as indicated in figure 1. And this is a claim that might be true of a
system as unghostly as a computer-controlled robot.
Much of G's paper is a polemic against behaviorism and in favor of cognitivism.
In light of the lingering virulence of behaviorism in this area, the polemic is quite
appropriate. However, when the issue is cast as a debate between cognitivists
and behaviorists, it is easy to lose sight of a fundamentally important point.
Cognitivism and behaviorism are not the only two alternatives. It is perfectly
possible that the best models for the mechanisms underlying behavior in higher
animals will not at all resemble the layout of figure 1, but will nonetheless postulate
elaborate interacting mechanisms that are anathema to behaviorists. Should this
turn out to be the case, then we should, I think, conclude that animals (or people
for that matter) do not think, do not have beliefs, do not have desires, and so
forth. For terms like "think," "believe," and "desire," gain their meaning from the
role they play in folk psychology. If folk psychology is false, these terms will have
no proper application. An analogy may be helpful here. Terms like "witch" and
"cast a spell" gain their meaning from the role they play in a folk theory that we
long ago discarded as false, and so we believe that there are no witches and no
one can cast spells (cf. Rorty, 1965).
Before turning to the question of content, we should note that the various
components of a cognitive model are inextricably interrelated. We can, of course,
choose to study one or another component while attempting to hold the rest of
the system more or less constant. This is the strategy of those cognitive theorists
who focus on human memory, for example, or on human inference. However, it is
not a memory alone that results in a subject answering a question in a certain
way. Rather, it is a memory plus (at least) a number of additional beliefs about
what the experimeter wants, and a desire to report honestly what one remem-
bers. While it is a perfectly sensible, indeed inevitable, research strategy to study
one component of a cognitive model while keeping the rest constant, it is quite
another matter to suppose that one or another component might sensibly be said
to exist without the rest. It simply makes no sense to speak of a system that, for
example, has a full complement of desires, but has no beliefs, is incapable of
practical reasoning, and so on. For to be a desire just is to be a state that
interacts with the rest of the components of the cognitive model in the appropriate
way. Thus I suspect that it is incoherent to suggest, as P&W do, that on the
chimpanzee's theory of mind people and other chimpanzees might be thought of
as having motivational states but not belief states.
2. Do animal cognitive states have expressible content, and if so what content
do they have?
This second question presupposes an affirmative answer to the first, since if
the members of a given species are not cognitive systems at all, then they simply
do not have cognitive states such as beliefs, desires, and thoughts. But if we
grant that a model along the lines sketched in figure 1 is appropriate for a given
species, then we can go on to ask about the content of the animal's belief and
desire states. That is, we can attempt to characterize the animal's beliefs in the
way we typically characterize the beliefs of our fellow men and women. For
example, I might recount some of the beliefs of a human friend by saying: "She
believes that someone is frying bacon in the kitchen;" or: "She believes that Los
Angeles is east of Reno." Generally, when we attribute beliefs to a fellow human,
we do so by finding an appropriate sentence to replace "p" in: "S believes that
p." The sentence selected must express the content of the belief being attributed;
often it is the sentence the subject herself would use to express the belief.
Similarly, if P&W's chimpanzee Sarah is a cognitive system, then we might try to
specify the content of her beliefs by finding suitable sentences to replace "p" in
"Sarah believes that p."
However, as a number of philosophers have noted (Dennett, 1969); Davidson,
1975; Stich, 1979a, 1979b), the possibility of giving this sort of characterization of
a subject's beliefs presupposes that the subject's store of beliefs is appropriately
similar to our own. Analogously, in order to translate what a subject says into our
language requires that the subject's store of beliefs be appropriately similar to our
own (cf. Quine, 1960). To see the point vividly, imagine a human subject who is
suffering from degenerative senility. Gradually the subject's store of beliefs and
memories slips away. In one such case familiar to me, the subject, at an
advanced stage of the disease, would regularly respond to the request, "Tell me
what happened to McKinley," by saying, "McKinley was assassinated." However,
when the subject was asked questions about assassination it became clear that
she had quite forgotten what the word meant. For example, if asked whether
people are dead after being assassinated, she claimed she did not know. When
coming from this subject, the words "McKinley was assassinated" can no longer
be interpreted as meaning that McKinley was assassinated. Nor can the belief
state underlying the pronouncement be identified as the belief that McKinley was
assassinated. There are analogous, though less depressing, problems in inter-
preting the words and attributing content to the beliefs of small children.
Now it might be thought that these problems are in principle solvable, and that
with sufficient effort we could find a sentence that appropriately expressed the
content of the child's belief or the meaning of the senile patient's sentence. But
that, I would urge, is not the case. There simply is no sentence in English that can
be used to capture the content of the child's or the senile patient's belief (see
Stich, 1979b). However, the impossibility of finding a content sentence that does
justice to these beliefs does not mean we cannot talk about these beliefs. Still less
does it mean that the child and the senile patient have no beliefs, that they are not
cognitive systems. It means only that we cannot use expressions of the form "S
believes that p" in talking about these subjects' beliefs. The alternative is to
describe the beliefs as developmental psychologists and students of child
language do, by describing the sensory input that leads to their formation, the
sorts of inferences that are and are not drawn from them, how they interact with
motivational states, and so forth. My point, then, is that we can treat subjects as
cognitive systems and study their beliefs and inferences fruitfully, even though we
cannot express the content of those beliefs.
Finally, let me indicate how these observations are relevant to G's paper. G is
much concerned with how we are to interpret, translate, or decode the communi-
cative behavior of animals. If the view I have been urging is correct, then this talk
of interpreting communicative behavior is systematically ambiguous. On one
reading, an interpretation may be an account of the circumstances under which a
given bit of communicative behavior is produced, the effects it has on its
audience, and even, perhaps, the inferential relations among the beliefs and
desires that underlie the behavior. On the other reading, to give an interpretation
is to translate the communicative behavior into our language, to give some English
sentence whose content is the same. Now when the communicative behavior at
issue is the behavior of insects, the latter sort of interpretation is almost certainly
impossible. The cognitive differences between people and bees are much too
great for there to be any sentence of ours that captures the content of a bee's
beliefs or desires. But the fact that we cannot express the content of a bee's
beliefs loses much of its sting when we realize it does not mean that bees are not
cognitive systems.
REFERENCES
Davidson, D. Thought and Talk. In: Samuel Guttenplan (ed.), Mind And Lan-
guage. London: Oxford University Press, 1975.
Dennett D. C. Content and Consciousness. London: Routledge & Kegan Paul,
1969.
Brain Storms. Montgomery, Vt: Bradford Books, 1978.
Fodor, Jerry A. The Language of Thought. New York: Thomas Y. Crowell,
1975.
Goldman, A. I. A Theory of Human Action. Englewood Cliffs, N.J.: Prentice-
Hall, 1970.
Harman, G. Thought. Princeton, N.J.: Princeton University Press, 1973.
Lewis, David. Radical interpretation. Synthe'se, 23:331-44. 1974.
Quine, W. V. D. Word and Object. Cambridge, Mass.: MIT Press. 1960.
Rorty, R. Mind-body identity, privacy and categories. Review of Metaphysics,
20, 1. 1965.
Stich, S. P. Beliefs and subdoxastic states. Philosophy of Science, Dec. 1978.
1978a.
Autonomous psychology and the belief-desire thesis. The Monist, 61,4.
1978b.
Do animals have beliefs? To appear in the Australasian Journal of Philoso-
phy. 1979a.
On the attribution of content. To appear in A. Woodfield et al. (eds.) Papers
From the Bristol Workshop. 1979b.
EDITORIAL NOTE
"Received too late for a response from G, P&W or SR&B. See forthcoming
Continuing Commentary.
by Shimon UHman*
Artificial Intelligence Laboratory, Massachusetts Institute of Technology,
Cambridge, Mass., 02139
Mental representations and mental experiences [Gj. As a result of a funda-
mental distinction he fails to draw, valid arguments are mixed with invalid ones in
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4
605

Commentary/Cognition and consciousness in-nonhuman species
G's advocacy of "cognitive ethology." In a nutshell, the distinction is between
mental representation on the one hand and mental experiences on the other.
I shall use the term "mental," or "symbolic representation" as roughly
equivalent in meaning to G's "mental images of objects, events, or relationships."
A system can justifiably be said to have symbolic representations of a certain
domain if certain events within the system can be consistently interpreted as
having meanings in that domain (see Ullman, 1979). If, for example, certain
voltage patterns inside a computer can be consistently interpreted as having a
meaning in the domain of arithmetic, the computer can be said to employ a
symbolic representation of arithmetic entities. In the same sense, the brain might
be said to employ symbolic representations (which in this case are also called
"mental representations") of (for example) physical objects or events [see also:
Haugeland: "The Plausibility of Cognitivism" BBS 1(2) 1978].
Humans also have what G calls "mental experiences," "awareness," or
"conscious experience." Symbolic representations and mental experiences
should not be confounded. There is nothing in the former that necessarily entails
the latter. Computer systems provide one example of this distinction. They often
employ elaborate symbolic representations. They also have, to a limited extent,
visual and linguistic capabilities. These capacities do not imply, however, that they
enjoy any sort of mental experience.
Symbolic representations within a system are amenable, at least to some
degree, to empirical investigation. Chomsky's theory of syntax, for instance, aims
at revealing the mental representations of syntactic structures and the way these
structures are manipulated. Marr and Nishihara (1978) provide another example
of investigating mental representations, in this case visual recognition of three-
dimensional shapes.
Mental experiences, unlike symbolic representations, probably cannot, in
principle, be shown to exist (see also Sherrington, 1940; Schrodinger, 1958;
Penfield, 1975). In this I agree with Cambell and Blake (1977 op. cit, G) and with
Krebs (1977 op. cit., G) (G's Section 7). In refuting their position G confuses
mental representations with mental experiences. This same confusion is reflected
in claims such as: "Consciousness itself is a representational system" (John,
quoted in G's Section 2); "It seems possible ... to detect and examine any
mental experience or conscious intention that animals might have" (G's Section
2); or "The study of consciousness is a legitimate branch of natural science"
(Taylor, quoted in G's Section 5).
Embedded in this confusion are two fallacies frequently encountered in
discussions of conscious experience. The first is the fallacy of identifying
self-awareness with the representation of the self (see e.g., Dawkins, 1976).
Gallup's studies (G's Section 7) suggest that the chimpanzee has some sort of a
representation of its own body, and this is taken by G as an indication of
self-awareness. A similar view is reflected in John's definition of consciousness
as "information about the information in the system" (G's Section 2). There is
nothing mysterious or very special about representing in a system certain aspects
of the system itself. Computer programs have been written (e.g., MYCIN, a
program that analyzes bacterial infections) that can reason about their own
behavior. They possess "information about the information in the system" without
having self-awareness or mental experience of any kind.
The second fallacy is to equate the capacity for planning future activities with
conscious intentions. Again, if the ability "to form a plan, and make a decision -
to adopt a plan" (Longuet-Higgins, quoted in G's Section 2) were indeed a test for
conscious mind, computing machines should long have qualified as conscious
intentional beings.
Since he does not draw a distinction between symbolic representations and
mental experiences, G maintains that the exclusion of mental experiences from
the realm of empirical investigations amounts to behaviorism. This accusation is
not justified. In fact, mental experiences lie outside the realm of contemporary
cognitive psychology as well. The difference between the two approaches is that
the behaviorist denies the existence of symbolic representations, or at least the
usefulness of the concept, while in cognitive psychology mental representations
are of key importance.
G advocates the use of communication in investigating the mental experiences
and mental representations in animals. The point that the study of communication
in the animal kingdom might be of value is well taken. Less clear, however, is why
communication should have a special status. One of the arguments raised by G is
that communication provides a direct window to other minds: "It provides our best
evidence about the mental experiences of our fellow men." Communication, like
any other behavior, cannot provide direct evidence for mental experiences. Our
best evidence for mental experiences in other minds is perhaps an isomorphism
argument: If they are built the same way, they probably share similar properties. In
this limited sense, empirical studies may provide indirect and inconclusive
evidence for mental experience. Accordingly, the communicative act cannot in
itself provide a proof for the existence of mental experience. Computers can
communicate intelligently with one another and with humans without being
endowed with experiences similar to humans. An extra caution is required when
drawing conclusions on the basis of communicative behavior, since humans have
a compelling tendency to attribute to the communicating agent false humanlike
properties (see for example the reactions reported by Weizenbaum to his
simple-minded "conversing" program ELIZA, (Weizenbaum, 1976).
Communication is certainly central to the study of mental representations in
humans. What makes it particularly instrumental is the richness of information
conveyed through human language. G's hope that communication with animals
(especially outside the ape family) will be rich enough for them to report to us
directly "about mental experience, awareness, intentions, and the like" [Section 7]
seems somewhat optimistic at present.
In conclusion, the argument that studies of communicative behavior, along with
other studies, might be of help in exploring the symbolic representations
employed by certain animals seems plausible. I do not see, however, why they
should enjoy the special status G argues for, nor can I accept his claims regarding
their power in exploring mental experiences in the animal kingdom.
REFERENCES
Dawkins, R. The Selfish Gene. Oxford: Oxford University Press, 1976.
Marr, D., and Nishihara, K. Representation and recognition of the spatial orga-
nization of three-dimensional shapes. Proceedings of the Royal Society, B,
269-294.
Penfield, W. The Mystery of the Mind. Princeton: Princeton University Press,
1975.
Schrodinger, E. Mind and Matter. In: What is Life and Mind and Matter
(1967). Cambridge: Cambridge University Press, 1958.
Sherrington, C. Man on His Nature. Harmondsworth: Penguin Books, 1940.
Ullman, S. The Interpretation of Visual Motion. Cambridge, Mass.: M.I.T.
Press, 1979.
Weizenbaum, J. Computer Power and Human Reason. San Francisco: W. H.
Freeman, 1976.
EDITORIAL NOTE
"Received too late for a Response from G. See Continuing Commentary.
by Bernard WÂ©iner and Sysan Landes
Department of Psychology, University of California, Los Angeles, Calif. 90024/
University of California, Berkeley, Calif. 94720
A cognitive psychology for infrahumans. Since the turn of the century,
American psychology has been guided by Morgan's canon - "in no case is an
animal activity to be interpreted as an outcome of the exercise of a higher
psychical activity, if it can be fairly interpreted as an outcome of an exercise which
stands lower in the psychological scale" (Morgan, 1896). This canon came about
as a revolt against the typically unsubstantiated claims of members of the
anecdotal school of psychology, who gathered stories illustrating the supposed
amazing intellectual capacities in infrahumans. Hence, while this school of
psychologists contended that moths fly into fire because they are curious, the
newer psychologists, guided by the cautions of Morgan, countered that such
behavior was more probably due to a built-in, unlearned mechanism, akin to a
tropism.
The behaviorists coupled Morgan's Canon with Darwin's continuity postulate to
develop their unique approach to human behavior. They reasoned that if the
behavior of infrahumans can be explained with mechanistic principles, and if there
is an infrahuman-human continuity, then human behavior can also be explained
without appealing to higher-order processes. It thus came about that psychology
was said to have lost its mind!
But all of this is old history. Mechanism as the basic approach to the
understanding of human behavior has been laid to rest; in the last twenty-five
years we have witnessed the rebirth of cognitive psychology. But it is a cognitive
psychology different from that which was championed by the anecdotal school.
This cognitive psychology is influenced by information theory and computer
models and analogues; it is a cognitive psychology with the methodological
sophistication introduced by the behaviorists, wary of the errors of the early
introspectionists; it is a cognitive psychology that addresses the problems of
personality, motivation, and social psychology.
The papers in the present series are part of this larger cognitive movement. It
now seems, for example, that chimps have a theory of the mind and that
606
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4

Commentary /Cognition and consciousness in nonhuman species
behaviors of infrahumans are not only instigated by associations between sign
stimuli and releasers. The argument now is that if human behavior is guided by
higher-order processes, and if there is a human-infrahuman continuity, then the
behavior of infrahumans also is influenced by these mental processes. The circle
is thus completed. This is also a return to our common-sense and everyday
observations. But, as the authors in this issue so creatively show, it is the
experimental data that force us to take very seriously the cognitive explanations
and inferences.
The shifting methodology. The theoretical movement from mechanism back to
cognition has been accompanied by some methodological alterations. There is a
trend in both infrahuman and human research to study complex behavior in its
natural habitat, in field settings, where the experimenter does not intrude upon the
normal flow of events but rather observes, records, and then interprets. The
anthropological field research with infrahumans has broadened our appreciation
of the complexity of other species. These observations have called attention to
some of the limitations of, for example, making inferences from captive lower
animals or, for that matter, from human subjects in an experimental room. Thus,
the field research movement served as a precursor for the work of, for example,
P&W.
But, as P&W demonstrate, we also have to craft the environment so that
theories about the chimp's theories can be tested. For certain questions to be
answered, environments must often be created; this may be crucial in theoretical
advancements when the limits of the mind are under investigation. One might
guess that these limits are in great part determined by the boundaries of our
experimental sophistication. In sum, the field research and the current laboratory
methodology are now complementary (a point that we will come back to later in
this discussion).
Cognition, emotion, and motivation: New research directions. It has long been
recognized that the three aspects of psychology - cognition, emotion, and
motivation - are closely intertwined, so that these distinctions often are hard to
maintain. If it is now accepted that infrahumans engage in higher-order cognitive
behavior, then it follows that our conceptions of their emotional and motivational
lives must also change. For example, current research in the area of affect not
only examines the biologically-rooted emotions, but also cognitively mediated
feeling-states. Considering the chimp Sarah, for example, one might ask: If she
observes a good person doing a bad deed (or vice versa), will she exhibit
surprise? If she does something that her peers cannot do, will she be proud? If
she does not try to help a colleague in distress, is she capable of experiencing
guilt or shame? If she tries to help but fails, will she display or experience a
difference emotional reaction? These questions seem to be amenable to the
experimental magic of P&W. Descartes, caught within the mechanistic framework
for infrahumans, wrote that "animals eat without pleasure and cry without pain."
Let us broaden the research, away from cognitions per se and toward their
dynamic psychological implications and consequences.
A similar argument can be made about the study of motivation. For example, it
appears that Sarah may desire to maintain cognitive consistency or a balanced
cognitive state, with good things happening to good people and bad things to bad
people. This is in accord with the suggestion of Lawrence and Festinger (1962)
that infrahumans as well as humans experience adverse psychological reactions
when their cognitions are not in harmony. Do Sarah, and other members of her
species or additional species, exhibit a broad array of psychogenic motivations?
To date, the experimental studies of infrahuman motivation have been largely
confined to viscerogenic need states such as hunger and thirst, with an
occasional recognition that infrahumans are also curious and act to increase
stimulation. But do they attempt to do tasks well (need for achievement), to help
others (altruism), to maintain friendships (need for affiliation), to have an impact
upon others (need for power)? Some of our observations appear to implicate
these sources of motivation, but without evidence of the sort that P&W have been
able to provide regarding the mediating role of cognitions. Let us move in this
motivational direction to develop a more complete comparative psychology.
The evolution of cognition: The use of mental processes for a comparative
taxonomy. Darwin's theory of evolution through natural selection is the organizing
principle of biology. One of its principal postulates is that the process of evolution
is gradual and continuous; evolution does not consist of a series of sudden
changes or saltations. It was not, however, until the 1920s and the advent of
population genetics that the gradual origin of complex types and new species
became widely accepted. Genetics revealed how new species might emerge
through a process of gradual evolution.
Traditionally, comparative anatomy has been the discipline most concerned
with evolutionary arguments. However, the idea that sufficient morphological
evidence could tell us everything about the relations between species has proven
incorrect. The work reviewed and offered in this issue concerning the cognitive
capacities of infrahuman primates may provide another avenue to the evolution-
ary history of our order. These new clues could lead us to alter our prior ideas or,
conversely, to have even greater confidence in some conclusions already
reached. For example, the newer data on the cognitive capabilities of apes
reaffirm the conclusions from both comparative anatomy and primate field
studies. The field studies of the 1960s and 1970s have shown that African apes
have complex and highly personal social relationships enduring over lifetimes,
tool use, elaborate gestural communication, and even cooperative hunting. In a
sybiosis between field and laboratory work, SR&B have demonstrated the extent
of these capacities. The very fact that the ape does things in the laboratory that
are not observed or cannot be performed in the field may be a key to the
understanding of the evolution of the mind.
In sum, a cognitive ethology should provide further data about humans'
evolutionary relations to other animals. The imaginative experiments thus far
reported enhance Darwin's view of gradualism and continuity in evolution. The
research supports the thesis that humans share a common ancestry with modern
apes and that there probably was a long period during which selective pressures
shaped a basic adaptive complex before the pongid-hominid lines diverged.
Experiments with other taxa are needed to elaborate this point, but it seems clear
that human and ape have some broadly similar cognitive abilities not shared by
monkeys and other infrahumans.
REFERENCES
Lawreoce, D. H., & Festinger, L. Deterrents and reinforcement. Stanford,
Calif.: Stanford Univ. Press, 1962.
Morgan, C. L. An introduction of comparative psychology. London: Walter
Scott, 1896.
by Eran Zaidei*
Division of Biology, California Institute of Technology, Pasadena, Calif. 91125
Of apes and hemispheres. In his "Prospects for a Cognitive Ethology," D. R.
Griffin calls for a research program on nonhuman cognition that would center on
internal representation of self and world, on intentionality, and on awareness.
Language is a natural source of evidence for intentions and awareness, but can
one adduce nonlinguistic evidence for their existence? Can intentions occur in the
absence of language? This is the perennial question of the relation of language to
thought, and it is central to SR&B's and P&W's papers. SR&B's paper is really
about the cognitive basis of language acquisition in apes, whereas P&W's paper
is about nonlinguistic evidence in apes for cognitive structures that have simple
human linguistic labels, such as "know," "believe," "doubt," and "like." The
study of the relation of language to thought through cases of unusual dissociation
between linguistic and cognitive abilities is in the tradition of experimental
psychology. Apes and the human right hemisphere share the status of models of
cognition without a well-developed expressive language, and I will therefore
comment on the three papers from the perspective of my own work on language
and cognition in the surgically separated right hemisphere (RH) of split-brain
patients.
The lure of continuity [GJ. I read G's focus on intentionality and awareness in
nonhuman cognition as a welcome heuristic for exploring the possible conse-
quences of internal representation in animals rather than as a literal or dogmatic
insistence that, say, honeybees possess intentions and plans. This heuristic is
useful precisely to the extent that it leads to the formulation of behavioral tests for
the occurrence of internal representation of self, of other conspecifics, of the
world, and of intentionality. This can lead to interesting experiments and alterna-
tive interpretations of existing data. Implicit here is the assumption that the
cognitive behavior of nonhuman species is more complex than is commonly
believed.
What behavioral criteria could distinguish an intentional honeybee from an
automaton bee in the Lindauer report? Or a hard-wired instinct for self-
preservation from existential fear of death? Perhaps the best evidence would be
the animal communicating its spontaneous introspections, but that is precisely the
kind of data that is missing. Otherwise one posits intentions and awareness only
when it becomes unparsimonious to account for the range of observable
behaviors in terms of special-purpose mechanisms. Behavioral evidence for
intentions includes planning or internal representation of delayed future
outcomes, choice between similarly attractive alternatives, and an affective
posture of preference, hope, and belief in the feasibility of the outcome. It is a
main task of a cognitive ethology to articulate simple behavioral tests for planning,
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4
607

Commentary/Cognition and consciousness in nonhuman species
choice, and belief that rely on behaviors that are within the animal's cognitive
repertoire.
For example, it may be possible to test an ape's competence for planning (and
its sense of past) by having it reconstruct sequences of pictures so as to
represent a significant novel future (or past) event or by letting it show preference
for one sequence over others. To show belief one needs to show, among other
things, that the animal follows a previous expectation even when it is in conflict
with otherwise apparent fact. Awareness is perhaps best demonstrated by
recognition of self, and this can be easily tested if the animal can again recognize
pictorial representations of personally significant real events and a symbol of self.
This could, but need not, be a picture or mirror image of the animal and clearly
requires special training in the ape, though not in the human RH.
By now it should be clear that I do not subscribe to the position that mental
experiences can only be detected and analyzed through the use of language and
introspective reports. It is also misleading of G to argue that there is "no
qualitative dichotomy, but rather a quantitative difference in complexity of signals
and range of intentions that separate animal communication from human
language." Rather, range and complexity seem to me to be precisely what (so
far) make human language unique and what qualify a system of communication as
language. Consequently, G's call for a cognitive ethology can be strengthened
since it need not depend on the actual versatility of animal communication
systems. In other words, nonverbal tests of complex cognitions are possible. In
fact, any nonlinguistic procedure used to train and test the ability of the ape to
acquire symbols for "future" or "yesterday" could be used to assess directly the
acquisition of the underlying concept of time. It is this underlying cognitive
structure rather than its linguistic expression that is important here. I have used
such nonverbal paradigms to study RH mentation and found that its cognitive and
linguistic abilities develop and operate fairly independently of each other (Zaidel
1978b).
How would one develop a systematic program for designing experiments on
language and thought in a communicating species? There are at least two
classes of possible paradigms. The first may be described as "data or hypothe-
sis-generating experiments," such as observation of natural, spontaneous
behavior. This is G's approach to communication. Similarly, factor analysis of rich
data bases can generate hypotheses about patterns in the data. Here as
elsewhere the observer's interpretation is necessarily affected by his world view,
but he can nonetheless observe an infinity of potential patterns in the data.
Nonverbal projective (e.g. constructional) clinical tests are also designed to
generate hypotheses about the subject's personality structure, but none of the
ones available (such as the Luschner Colot Test, the Szondi Test, Make-
a-Picture-Story World Test) has adequate validity or reliability.
A second class of paradigms is the common "hypothesis-testing experi-
ments." One example of this is the forced choice, multiple choice, conceptual
matching--to-sample paradigm, or simply "the multiple choice paradigm." Here a
stimulus is presented or a problem is posed, and the subject has to solve it by
pointing to a picture that best corresponds to the answer. I have used this
paradigm extensively with the disconnected RH since no speech responses are
required. For similar reasons P & W 
use it now with Sarah. Of course,
hypotheses-testing paradigms no longer tap the animal's natural performance
repertoire and focus instead on limits of competence under specific training
conditions. Experimental psychology is especially guilty of incorrectly inferring the
structure of natural information processing from unnatural and contrived limit-
case experiments, and of treating rare skills, such as abstract mathematical
reasoning, and common abilities, such as language, as theoretically equivalent.
Do apes have language [SR&B]? In the absence of spontaneous linguistic
introspection in apes it may still be possible to teach chimps an artificial language
system which can be used subsequently to communicate about ape mentation.
This is what SR&B are trying to do. Although they claim to provide a methodologi-
cally conservative demonstration of linguistic communication between two
chimps, I think they have actually demonstrated some cognitive prerequisites for
symbol use in these nonhuman primates. SR&B's experimental paradigm seems
too narrow to qualify as linguistic communication. They have trained two chimps
to perform a complex sequence of acts in a specific context in order to obtain
food. There is no evidence of spontaneous extension of the social exchange to
novel cases. Even when the apes were trained to request and provide tools, the
dyadic exchange did not occur spontaneously, and communicative intent had to
be taught first in a precise context. Thus this example of alleged linguistic
communication fails the crucial tests of novelty and range of application. How
context-independent do we require linguistic communication to be? We want it
flexible enough to apply to a new partner without special training yet not so
nondiscriminating that it applies to an inanimate model or to a clearly uncoopera-
tive mate.
However, it is not important whether or not we call the social exchange
between Sherman and Austin linguistic, for SR&B's paper presents an important
account of the interplay between complex cognition and symbol use in chimps.
The exchange task is undeniably complex: It involves generalization, notably
about role reversal and the interchangeability of food type and location; it also
involves the manipulability of objects and other individuals; and it involves social
interaction mediated by linquistic symbols. The greatest insight comes from the
cognitive constraints on the acquisition of the task. These were already apparent
in the preliminary naming task, where in order to avoid confusion, no more than
three items could be used in any session. It was found that the apes could not
learn to name some objects, so tool requests had to be taught in the highly
specific functional context of obtaining particular foods from particular sites.
Similarly, tool naming was harder than tool requesting. It is clear that the chimp
acquires the symbol for a particular word in the context of a specific function
which it finds difficult to divorce from the word itself. Use of more than two
objects, changing the examplars, and intersession delay all caused performance
breakdown in the object-naming task. From these data it may follow that verbs
should be easier for the ape to acquire than proper and abstract nouns.
SR&B's data suggest that the cognitive bases for word meanings are very
different in the chimps and in the disconnected RHs. The RH lexicon is clearly
more abstract and context-independent. In fact, although the RH can often signal
the meaning of a verb by pointing to a picture describing the action, it may
nevertheless be unable to perform the same action. Thus tool use and the
imitation of action do not seem to form the basis of word acquisition in the RH.
Furthermore, SR&B cite cases of spontaneous iconic gesturing as an adjunct to
the abstract keyboard symbols. In contrast, even though it has access to some
writing and other meaning-carrying symbols, the RH rarely if ever initiates
expressive communication. The RH can manipulate linguistic symbols semanti-
cally (e.g., by matching printed synonyms or antonyms), but its linguistic compe-
tence is inherently receptive.
When language fails [P& WJ. In academic circles I have often encountered a
certain "mystique of reticence," whereby verbal reticence in social interaction is
interpreted as judiciousness, even profundity. Perhaps P&W were so lured by
Sarah's persistent reticence after some thirteen years of training in using an
artificial language, that they were moved to anthropomorphize her and even try to
show with nonverbal tests that she is a philospher (although philosphers never
seem guilty of reticence). Weary of waiting for Sarah to express her latent
philosophical concerns spontaneously, P&W undertook to elicit her cognitive and
philosophical competence by ingenious applications of the multiple-choice para-
digm.
The paradigm is of the hypothesis-testing variety, but it nevertheless allows
incredible freedom in the formulation of hypotheses. Most commonly the choices
are pictures, and the relation between them and the stimulus or problem can be
highly associative and thus arbitrarily abstract. The foils can be carefully selected
to constitute precisely the contrasts of direct interest and to allow for the analysis
of false positive errors. No speech or manual construction, only pointing or show
of preference, is necessary for a response, so the paradigm is ideal for testing
brain-damaged patients with cognitive deficit, children with congenital language
disability, and the disconnected RH. I have used this paradigm to obtain
comprehensive linguistic and cognitive profiles for the nondominant hemisphere,
including tests of phonology, syntax, semantics, memory, intelligence, and
personality (Zaidel 1978a, b).
However, the multiple-choice paradigm is not universally applicable to all
subjects. It has cognitive prerequisites which we cannot assume a priori to obtain
for nonhumans or RHs. Thus a subject has to share the problem context with the
test designer, and he has to be able to recognize two-dimensional pictures of
three-dimensional objects as well as the meaning of complex pictures. Both seem
to be the case for RH but the former not for naive apes. Similarly, the paradigm
depends on the subject's ability reliably to search, remember, and select from
alternatives. In the case of the RH this seems limited to choice sets with about four
to six items, but what about Sarah? A systematic use of multiple-choice pictures
calls for a metric of picture perception and of pictorial associations similar to that
available in verbal learning.
P&W describe two exciting variations of the multiple choice paradigm. Instead
of using still pictures or drawings they use dynamic video scenes; they also
incorporate a recursive condition into the procedure (pictures of subjects taking
the test) which makes it possible to evaluate second-order cognitions or
metacognitive relations. P&W's use of these techniques demonstrates that
608
THE BEHAVIORAL AND BRAIN SCIENCES (1978), 4

Response/Cognition and consciousness in nonhuman species
evidence about intentionality and awareness can be elicited without expressive
communication. Yet the paradigm lends itself to testing binary dichotomies (e.g.,
does Sarah regard an adult chimp as less likely to make errors than an adult
gorilla?) rather than affective gradients or degrees of cognitions. The latter would
require some pretraining, such as teaching symbols for comparative terms or
teaching rating responses on a generic intensity scale represented, say, by a
horizontal series of color chips arranged in order of increasing saturation.
It seems plausible to tap Sarah's sense of physical reality by asking her, as
P&W do, to identify the solution to the problem of a hose improperly attached to a
faucet. But in what sense (except association) could she realize that plugging in a
fan will make it work? Surely there are more direct ways of studying Sarah's sense
of causality and reality, such as by using pictorial multiple choices of Piagetian
tasks. P&W assert that they are not primarily interested in the animal's grasp of
physical relations, but rather in using that grasp to establish, say, that the
chimpanzee has an abstract concept of "problem." But the animal's conception
of physical reality and causality are probably central to its concepts of error,
ambiguity, and conflict which, in turn, are essential ingredients of "problem."
Sarah's ability to solve diverse problems tells us nothing about whether she has a
conceptual category "problem" in mind which she applies to all these problems.
Are P&W justified in attributing their own human interpretation to Sarah without
specifying behavioral criteria for acquiring the concept "problem?"
P&W may be attracted by philosophical questions and ingenious, logically
complex paradigms at the expense of simpler answers to more direct cognitive
questions. Consider the embedded video tape paradigm. It is clearly useful for
studying second-order cognitions such as opinions or feelings about opinions or
feelings, and especially for eliciting reactions to the whole experimental paradigm
itself (video of ape judge observing an actor). But is the embedded video tape
necessary for distinguishing a "smart" from a "stupid" observer? This could be
tested by making the observer O be the participant P rather than its judge. Surely
the question of whether Sarah thinks that O can solve a problem should be
answered before the question of whether she thinks that O would correctly judge
a video tape solution to the problem.
But these are minor gripes. P&W outline an exciting program for studying a
wide range of cognitive issues focusing, notably, on knowledge, belief, and
empathy. Empathy - using oneself as a partial model for another - is important
because it is a good example of an affective heuristic serving a cognitive function.
Empathy is the basis for shared context that makes it possible for Sarah to
recognize the meaning of the stimuli and problems. But empathy need not entail
complete identification with an actor or problem solver. Thus I can empathize with
Sarah without equating our respective cognitive abilities, or without even liking
her. In particular I can empathize with Sarah and have an opinion about the
limitations of her knowledge at the same time. I believe the whole distinction
between motivation and knowledge tends to be drawn too sharply in the sense
that, internally, inferences about knowledge in humans may usually incorporate
inferences about belief. In other words, we associate feelings with particular
cognitions in order to facilitate their processing and change.
Is the alleged cognitive and receptive linguistic superiority of the disconnected
human RH over the ape a consequence of the much richer cognitive experience
of the RH as part of normal development? We don't know much about the
learning process in the normal RH, but the disconnected RH seems uniquely
unresponsive to standard behavioral learning paradigms and to error correction
(Zaidel, 1978b). It is distinguished by what it has not learned, in spite of years of
potential experience (e.g., to speak). Indeed, Chomsky's anti-Skinnerian argu-
ment has emphasized the inadequacy of a learning theoretic account of language
acquisition and the need to postulate an innate biological capacity for language.
On the other hand, it is generally acknowledged that human competence for
language can only be realized after exposure to normal communication and social
interaction (cf. feral children). The question then becomes, what environment
would constitute a comparable natural catalyst for the upper limits of ape
language?
ACKNOWLEDGMENTS
Thanks to D. Zaidel and C. R. Hamilton for helpful comments.
Supported by NSF Grant BNS 78-2429.
REFERENCES
Zaidel, E. Lexical organization in the right hemisphere. In: P. A. Buser and A.
Rougeul-Buser (eds.), Cerebral Correlates of Conscious Experience. Pp.
177-97. Amsterdam: Elsevier, 1978a.
Concepts of cerebral dominance in the split brain. Ibid. Pp. 263-84. 1978b.
EDITORIAL NOTE
"Received too late for a response from G, P&W, or SR&B. See Continuing
Commentary.
Author's Response
by D. R. Griffin
Helpful "talk" on what to "do"
I welcome these thoughtful and significant contributions to the
development of cognitive ethology. I am so sympathetic to the
general ideas expressed by many commentators that it is pointless to
say so at great length; and I will leave to SR&B and P&W specific
questions about languagelike behavior learned by captive apes (see
also Ristan and Robbins, in press). To paraphrase Beck, the "talkers"
have lots of constructive and promising suggestions for future
"doers." These will help us to inquire whether particular kinds of
mental experiences are likely to be occuring in various animals and to
control our impulse to assert whatever we may believe about these
matters. As Karl Popper put it succinctly (Popper and Eccles, 1977),
"Let our theories fight it out... let our theories die in our stead."
One theme runs through several commentaries, especially those of
Beck, Caedlaed, R.T. Davis, Hebb, Limber, and RaeJhllns Compar-
ative psychologists have actually been studying the minds of animals
for several decades through experiments on discriminative learning,
problem solving, cross-modal transfer, perceptual constancies,
perception of barriers and detours, learning sets, and the like. Of
course, understanding these topics is directly relevant to a cognitive
ethology, and it is helpful to be assured that so many behavioral
scientists have really been studying animal thinking all along. But
only very rarely (for example, in Hulse et al., 1978) have recent
students of these kinds of problems attempted to relate their findings
to mental experiences of the animals concerned. Unwary students
and general readers can perhaps be forgiven for interpreting what
they hear and read to mean that all nonhuman animals are what
Malcolm (1973) called "thoughtless brutes." The recent revival of
interest in cognitive ethology will be a valuable development even if
it accomplishes no more than the general recognition that behavioral
scientists are indeed studying the minds of animals as well as their
behavior.
It is important to keep firmly in mind the distinction between
awareness and responsiveness. Granted that detecting awareness in
another species is difficult, let us tentatively assume some measure of
mental continuity and begin by considering the human case. Clearly
we can be aware of some stimulation or relationship without
responding to it in any detectable fashion. Conversely, we respond to
many kinds of stimulation without being aware that we are doing so
[cf. Roland: "Sensory Feedback to the Cerebal Cortex During Volun-
tary Movement in Man" BBS 1(1) 1978]. We are convinced that this
is true of other people primarily because they tell us about current or
past awareness of particular objects and events. Can we hope to
obtain comparable evidence about awareness in other species?
Behavior, no matter how complex and adaptive, can always be
interpreted without postulating awareness, but the plausibility of
such an interpretation varies enormously. What kinds of animal
behavior provide the strongest evidence of awareness? Appropriate
communicative behavior is clearly one of the strongest potential
sources of such evidence. This becomes most convincing when it
involves communication about internal representations rather than
about concurrent stimulation, not because awareness of ongoing
events is unimportant, but because communicative behavior, which
has the property of displacement, seems more likely to be accompa-
nied by awareness.
As empirical scientists we can all concur in Beck's preference for
"doers" over "talkers." He warns us against "chimpomorphism," or
THE BEHAVIORAL AND BRAIN SCIENCES (1978), <
609

