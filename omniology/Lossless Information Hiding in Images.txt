Lossless Information
Hiding in Images
Zhe-Ming Lu
Professor, School of Aeronautics and Astronautics
Zhejiang University
Hangzhou, P.R. China
Shi-Ze Guo
Professor, School of Computer Science
Beijing University of Posts and Communications
Beijing, China
AMSTERDAM • BOSTON • HEIDELBERG • LONDON
NEW YORK • OXFORD • PARIS • SAN DIEGO
SAN FRANCISCO • SINGAPORE • SYDNEY • TOKYO
Syngress is an imprint of Elsevier

Syngress is an imprint of Elsevier
50 Hampshire Street, 5th Floor, Cambridge, MA 02139, United States
Copyright © 2017 Zhejiang University Press Co., Ltd., published by Elsevier Inc.
All rights reserved.
No part of this publication may be reproduced or transmitted in any form or by any means,
electronic or mechanical, including photocopying, recording, or any information storage
and retrieval system, without permission in writing from the publisher. Details on how to
seek permission, further information about the Publisher’s permissions policies and our
arrangements with organizations such as the Copyright Clearance Center and the
Copyright Licensing Agency, can be found at our website: www.elsevier.com/permissions.
This book and the individual contributions contained in it are protected under copyright by
the Publisher (other than as may be noted herein).
Notices
Knowledge and best practice in this ﬁeld are constantly changing. As new research and
experience broaden our understanding, changes in research methods, professional
practices, or medical treatment may become necessary.
Practitioners and researchers must always rely on their own experience and knowledge in
evaluating and using any information, methods, compounds, or experiments described
herein. In using such information or methods they should be mindful of their own safety
and the safety of others, including parties for whom they have a professional responsibility.
To the fullest extent of the law, neither the Publisher nor the authors, contributors, or
editors, assume any liability for any injury and/or damage to persons or property as a
matter of products liability, negligence or otherwise, or from any use or operation of any
methods, products, instructions, or ideas contained in the material herein.
Library of Congress Cataloging-in-Publication Data
A catalog record for this book is available from the Library of Congress
British Library Cataloguing-in-Publication Data
A catalogue record for this book is available from the British Library
ISBN: 978-0-12-812006-4
For information on all Syngress publications
visit our website at https://www.elsevier.com/
Publisher: Todd Green
Acquisition Editor: Simon Tian
Editorial Project Manager: Naomi Robertson
Production Project Manager: Priya Kumaraguruparan
Cover Designer: Mark Rogers
Typeset by TNQ Books and Journals

Preface
The enormous popularity of the World Wide Web in the early 1990s demonstrated the
commercial potential of offering multimedia resources through digital networks.
Representation of media in digital format facilitates its access. Digital media
includes text, digital audio, images, video, and software. The recent growth of net-
worked multimedia systems has increased the need for the protection of digital
media. Since commercial interests seek to use the digital networks to offer digital
media for proﬁt, it is particularly important for the protection and enforcement of
intellectual property rights, and they have a strong interest in protecting their owner-
ship rights. On the other hand, the age of digital multimedia has brought many advan-
tages in the creation and distribution of information. Representation of media in
digital format enhances the accuracy, efﬁciency, and portability of existence of
data. The powerful multimedia manipulation software has made it possible to edit
and alter the media’s content seamlessly. Since the ease of copying and editing
decreases the credibility of multimedia, a secure authentication system is needed to
verify data integrity and trustworthiness. Furthermore, the rapid development of
the Internet requires conﬁdential information that needs to be protected from the un-
authorized users. Thus, the standard and concept of “what you see is what you get
(WYSIWYG),” which we encounter sometimes while printing images or other mate-
rials, is no longer precise and would not fool a steganographer as it does not always
hold true. Images can be more than what we see with our human visual system (HVS);
hence, they may convey more than merely 1000 words. For decades, people strove to
develop innovative methods for secret communication.
Under these circumstances, many approaches have been presented to protect the
digital media itself or utilize the digital media to protect other important informa-
tion. These approaches can be mainly classiﬁed into two categories, i.e., cryptog-
raphy and information hiding. In conventional cryptographic systems, the sender
generates a digital signature for an image in advance using a public key cryptog-
raphy system such as the RivesteShamireAdleman system. The sender then trans-
mits both the digital signature and the corresponding image to the receiver. Later, the
receiver can verify the integrity and authenticity of the received image by using the
corresponding digital signature. The cryptographic system permits only valid key-
holders access to encrypted data, but once such data is decrypted there is no way
to track its reproduction or retransmission. Information hiding, which is also known
as data hiding, is distinct from cryptography as it aims to make the embedded data
unrecoverable and inviolateable. Information hiding is a method of hiding secret
messages into a cover medium so that an unintended observer will not be aware
of the existence of the hidden messages.
Information hiding techniques can be classiﬁed into three techniques, i.e., steg-
anography, watermarking, and ﬁngerprinting. These techniques are quite difﬁcult to
tease apart especially for people coming from different disciplines. The term steg-
anography is retrieved from the Greek words stegos means cover and graﬁa meaning
xi

writing, deﬁning it as covered writing. The similarity between steganography and
cryptography is that both are used to conceal information. However, the difference
is that steganography does not reveal any suspicion about the hidden information to
the user. Therefore the attackers will not try to decrypt information. There are other
two techniques that seem to be same as steganography. They are watermarking and
ﬁngerprinting. Both these techniques sounds to be the same and provide the same
end goals, but both are very different in the way they work. Watermarking allows
a person to provide hidden copyright notices or other veriﬁcation licenses, whereas
ﬁngerprinting uses each copy of the content and makes it unique to the receiver.
Watermarking is usually a signature to identify the origin, and all the copies are
marked in the same way. However, in ﬁngerprinting different unique copies are
embedded for distinct copies. Digital watermarking has also been proposed as a
possible solution for data authentication and tamper detection. The invisible authen-
ticator, sensitive watermark is inserted using the visual redundancy of HVS and is
altered or destroyed when the host image is modiﬁed by various linear or nonlinear
transformations. The changes of authentication watermark can be used to determine
the modiﬁcation of the marked image, and even locate the tampered area. Because
the watermark is embedded in the content of image, it can exert its efﬁciency in the
whole lifecycle.
Today, there is a huge volume of literature on information hiding techniques.
However, most of the existing information hiding schemes distort the original image
irreversibly; then, the challenge becomes one of minimizing distortion relative to ca-
pacity. In several applications, such as medical or military imaging, any distortion is
intolerable. In such cases, lossless information hiding schemes are the only recourse.
To meet this need, the concept of distortion-free embedding has become a very
important issue, especially in sensitive images. Lossless information hiding, also
called reversible information hiding or reversible data hiding, allows a sender to
embed invisible information into an original image in a reversible manner. Then,
the receiver can extract the embedded data and restore the original image. Lossless
information hiding in images is gaining more attention in the past few years because
of its increasing applications in military communication, health care, and law
enforcement.
Lossless information hiding can be used in many applications. A possible appli-
cation is to use lossless reversible watermarking algorithms to achieve the lossless
watermark authentication, supporting completely accurate authentication for the
cover media, which is actually the original intention of reversible watermarking
schemes. In some applications, people are more concerned about the quality of
the cover media itself. In this type of application, the common requirements are
that the watermarking algorithm and the watermark embedding process do not intro-
duce permanent distortion to the cover media. A special class of application that we
are most likely to think of is the special accuracy requirement for special media, such
as medical images, military images, remote sensing images, legal evidence images,
secret documents, precious works of art, and science experimental images. For this
type of application, even 1-bit permanent loss in the original cover media is not
xii
Preface

allowed, so the data embedding algorithms must be reversible. Since reversible
watermark embedding algorithms can remove the embedding distortion completely,
they can be referred to as data embedding styles with 100% ﬁdelity. Another appli-
cation is to restore the image modiﬁcation operations. In some image processing ap-
plications, the process is completed by a few simple adjustments. If the image
processing operator worries about the fact that the users are not satisﬁed with the
image processing results, he can treat the parameters as a watermark and reversibly
embed it in the cover image and in the future restore the image to its original state or
its approximate state, thus you do not have to store a lot of original images.
Lossless information hiding algorithms for images can be classiﬁed into three
categories, i.e., the spatial domainebased, the transform domainebased, and the
compressed domainebased schemes. Transform domainebased lossless informa-
tion hiding methods can be classiﬁed into two categories, i.e., integer discrete cosine
transform (DCT)ebased schemes and integer discrete wavelet transform (DWT)e
based schemes. Here, the transform used in reversible information hiding should
be in the category of invertible mapping. Nowadays, since more and more images
are being stored in compressed formats such as JPEG and JPEG2000 or transmitted
based on vector quantization (VQ) and block truncation coding (BTC), more and
more efforts are being focused on developing the compressed domain information
hiding approaches. Here, we view the compressed image as the cover image, and
reversibility means that after extracting the secret data from the unattacked stego im-
age, we can recover the original compressed image losslessly.
In general, payload capacity, stego image quality, and complexity of the data
embedding algorithm are the three major criteria used to evaluate lossless informa-
tion hiding. Payload capacity means how much secret information can be embedded
in an image. The quality of a stego image is measured by the peak signal-to-signal
ratio (PSNR): a higher PSNR value can guarantee less distortion caused in the cover
image. Moreover, the complexity of the data embedding algorithm should be as sim-
ple as it is effective. In practice, high payload capacity and low distortion are con-
ﬂicting requirements: the larger the capacity created by a reversible embedding
technique, the higher is the distortion introduced by embedding.
Based on this background, this book is devoted to lossless information hiding
techniques for images. This book is suitable for researchers in the ﬁeld of informa-
tion hiding. Our aim is to recommend a relatively novel monograph to cover recent
progress of research hotspots in the area of lossless information hiding such that the
researchers can refer to this book to have a comprehensive understanding and carry
out in-depth research in their own directions. This book consists of six chapters.
Chapter 2 discusses the lossless information techniques in the spatial domain. In
this chapter, we ﬁrst overview the spatial domainebased lossless schemes. Then,
we discuss some typical spatial domain lossless information hiding methods.
Chapter 3 discusses transform domainebased lossless schemes. In this chapter,
we ﬁrst introduce some related concepts and requirements for lossless information
hiding in transform domains. Then we give a brief overview of transform domaine
based information hiding. Next we introduce two types of transform domainebased
Preface
xiii

lossless information hiding methods. Chapter 4 focuses on the VQ-based lossless in-
formation hiding schemes. We ﬁrst review the schemes related to VQ-based infor-
mation hiding. Then, we mainly focus on three kinds of VQ-based lossless
information hiding schemes. Chapter 5 discusses the topic of embedding data in
BTC-compressed images with lossless hiding techniques. First, we introduce the
block truncation coding technique. Then, we review the schemes related to BTC-
based information hiding. Then, we focus on two topics, i.e., lossless information
hiding schemes for BTC-compressed grayscale images and color images. Chapter
6 ﬁrst introduces JPEG and JPEG2000 compression techniques in brief, together
with the embedding challenges. Then, we introduce the lossless information hiding
schemes for JEPG- and JPEG2000-compressed images.
This book is a monograph in the area of information hiding. It focuses on one
branch of the ﬁeld of information hiding, i.e., lossless information hiding. Further-
more, it focuses on the most popular media, images. This book embodies the
following characteristics. (1) Novelty: This book introduce many state-of-the-art
lossless hiding schemes, most of that come from the authors’ publications in the
past 5 years. The content of this book covers the research hotspots and their recent
progress in the ﬁeld of lossless information hiding. After reading this book, readers
can immediately grasp the status, the typical algorithms, and the trend in the ﬁeld of
lossless information hiding. For example, in Chapter 6, reversible data hiding in
JPEG2000 images is a very new research branch. (2) All roundedness: In this
book, lossless information hiding schemes for images are classiﬁed into three cate-
gories, i.e., spatial domainebased, transform domainebased, and compressede
domain based schemes. Furthermore, the compressed domainebased methods are
classiﬁed into VQ-based, BTC-based, and JPEG/JPEG2000-based methods. Espe-
cially, the lossless information hiding in JPEG images is very useful since most of
the images are stored in the JPEG format. Therefore, the classiﬁcation of lossless
hiding schemes covers all kinds of methods. (3) Theoretical: This book embodies
many theories related to lossless information hiding, such as image compression,
integer transforms, multiresolution analysis, VQ, BTC, JPEG, and JPEG2000. For
example, in Chapter 3, several deﬁnitions related to invertible mappings and integer
DCT transforms are introduced in detail to understand the content of later chapters
easily. (4) Practical: It is suitable for all researchers, students, and teachers in the
ﬁelds of information security, image processing, information hiding, and communi-
cations. It can guide the engineers to design a suitable hiding scheme for their spe-
cial purpose, such as copyright protection, content authentication, and secret
communication in the ﬁelds of military, medicine, and law.
This book is completely written by Prof. Zhe-Ming Lu. The research fruits of this
book are based on the work accumulation of the author for over a decade, most of
which comes from the fruits of PhD and master students supervised by Prof. Lu.
For example, Dr. Zhen-Fei Zhao and Dr. Hao Luo carried out the research work
on reversible secret sharingebased lossless information hiding schemes supervised
by Prof. Lu. Dr. Bian Yang, who was a former masters and PhD student, cosuper-
vised by Prof. Lu, carried out the research work in Germany on lossless information
xiv
Preface

hiding schemes based on integer DCT/DWT transforms as the main part of his thesis
topic. Dr. Yu-Xin Su, who was a former masters student, supervised by Prof. Lu, car-
ried out the research work on lossless information hiding schemes for BTC-
compressed color images as part of his thesis topic. Mr. Xiang Li, who was a former
masters student, supervised by Prof. Lu, carried out the research work on lossless
information hiding in JPEG/JPEG2000-compressed images as part of his thesis
topic. We would like to show our great appreciation of the assistance from other
teachers and students at the Institute of Astronautics Electronics Engineering of
Zhejiang University. Part of research work in this book was supported by the
National Scientiﬁc Foundation of China under the grants 61171150 and 61003255
and the Zhejiang Provincial Natural Science Foundation of China under the grants
R1110006 and RLY14F020024. Owing to our limited knowledge, it is inevitable
that errors and defects will appear in this book, and we adjure readers to criticize.
Zhe-Ming Lu
Hangzhou, China
June 2016
Preface
xv

Introduction
1
1.1 BACKGROUND
1.1.1 DEFINITION OF IMAGES
1.1.1.1 Images
An image is a visual representation of something that depicts or records visual
perception. For example, a picture is similar in appearance to some subject, which
provides a depiction of a physical object or a person. Images may be captured by
either optical devices, such as cameras, mirrors, lenses, and telescopes, or natural
objects and phenomena, such as human eyes or water surfaces. For example, in a
ﬁlm camera works the lens focuses an image onto the ﬁlm surface. The color ﬁlm
has three layers of emulsion, each layer being sensitive to a different color, and
the (slide) ﬁlm records on each tiny spot of the ﬁlm to reproduce the same color
as the image projected onto it, the same as the lens saw. This is an analog image,
the same as our eyes can see, so we can hold the developed ﬁlm up and look at it.
Images may be two-dimensional, such as a photograph, or three-dimensional,
such as a statue or a hologram. An image in a broad sense also refers to any two-
dimensional ﬁgure such as a map, a graph, a pie chart, or an abstract painting. In
this sense, images can also be rendered manually, such as by drawing, painting, carv-
ing; can be rendered automatically by printing or computer graphics technology; or
can be developed by a combination of methods, especially in a pseudophotograph. In
photography, visual media, and the computer industries, the phrase “still image” re-
fers to a single static image that is distinguished from a kinetic or moving image
(often called video), which emphasizes that one is not talking about movies. The
phrase “still image” is often used in very precise or pedantic technical writing
such as an image compression standard.
In this book, we consider two-dimensional still images in a broad sense. Thus, an
analog image (physical image) I deﬁned in the “real world” is considered to be a
function of two real variables as follows:
I ¼ fIðx; yÞ˛½0; Bj0  x  X; 0  y  Yg
(1.1)
where I(x,y) is the amplitude (e.g., brightness or intensity) of the image at the real
coordinate position (x,y), B is the possible maximum amplitude, and X and Y deﬁne
the maximum coordinates. An image may be considered to contain subimages
CHAPTER
Lossless Information Hiding in Images. http://dx.doi.org/10.1016/B978-0-12-812006-4.00001-2
Copyright © 2017 Zhejiang University Press Co., Ltd., published by Elsevier Inc. All rights reserved.
1

sometimes referred to as regions. This concept reﬂects the fact that images
frequently contain collections of objects, each of which can be the basis for a region.
1.1.1.2 Digital Images
A digital image is the numeric representation of an analog image (physical image).
Any image from a scanner, from a digital camera, or in a computer is a digital image.
Depending on whether the image resolution is ﬁxed or not, it may be of vector or
raster type. Raster images are created through the process of scanning source
artwork or “painting” with a photo editing or paint program such as Corel Photo-
PAINT or Adobe PhotoShop. A raster image is a collection of dots called pixels.
Pixel is a computer word formed from PICture ELement, because a pixel is a tiny
colored square that is the smallest element of the digital image. Scanned images
and web images [Joint Photographic Experts Group (JPEG) and graphics inter-
change format (GIF) ﬁles] are the most common forms of raster images. Vector im-
ages are created through the process of drawing with vector illustration programs
such as CorelDRAW or Adobe Illustrator. The word “vector” is a synonym for
line. A vector image is a collection of connected lines and curves that produce ob-
jects. When creating a vector image in a vector illustration program, node or drawing
points are inserted and lines and curves connect the nodes together. Sometimes, both
raster and vector elements will be combined in one image, for example, in the case
of a billboard with text (vector) and photographs (raster). By itself, the term “digital
image” usually refers to raster images.
In this book, we mainly consider two-dimensional still raster images. Raster im-
ages can be created by a variety of input devices and techniques, such as digital cam-
eras, scanners, coordinate-measuring machines, seismographic proﬁling, and
airborne radar. A digital camera creates a digital picture with a charge-coupled de-
vice or complementary metal oxide semiconductor chip behind the lens. The lens
focuses the physical image onto the digital sensor, which is constructed with a
grid of many tiny light-sensitive cells, or sensors, arranged to divide the total picture
area into rows and columns composed of a huge number of very tiny subareas called
pixels, as shown in Fig. 1.1. Each sensor inspects and remembers the color of the tiny
area. A digital camera remembers the color by digitizing the analog color into three
digital values representing the color (i.e., three components, red, green, and blue,
FIGURE 1.1
Digitalization of the Physical Image by Pixels.
2
CHAPTER 1 Introduction

called RGB), or sometimes one digital value representing the brightness of the color.
Similarly, a scanner has a one-row array of similar cells, and a carriage motor moves
this row of sensors down the page, making columns in many rows to form the full
image grid. Both scanners and cameras generate images composed of pixels, and
a pixel contains the digital RGB color data or brightness of one tiny surface area.
This process is called digitization. Printers and video screens are digital devices
too, and their only purpose in life is to display pixels.
From these descriptions, we come to know that a digital image contains a ﬁxed
number of rows and columns of pixels. Pixels are the smallest individual element in
a digital image, holding quantized values that represent the brightness of a given co-
lor at any speciﬁc point. Typically, the pixels are stored in computer memory as a
raster image or raster map, a two-dimensional array of small integers. Thus, a digital
image I can be deﬁned as an array, or a matrix, of square pixels arranged in columns
and rows as follows:
I ¼ fIðm; nÞj0  m  M  1;
0  n  N  1g
(1.2)
where I(m,n) is the color data or brightness value of the pixel at the mth column and
nth row, and M and N deﬁne the width (number of columns) and height (number of
rows) of the digital image.
According to the range of I(m,n), we can classify digital images into binary im-
ages, grayscale images, and color images, and three examples are shown in Fig. 1.2.
In color images, each pixel’s color sample has three numerical RGB components to
represent the color of that tiny area, i.e., I(m,n) is denoted by (R, G, B) with R˛[0,
255], G˛[0, 255], and B˛[0, 255]. Typically, for each pixel, its three RGB compo-
nents are three 8-bit numbers. These 3 bytes (1 byte for each RGB) compose a 24-bit
color. Each byte can have 256 possible values, ranging from 0 to 255. In the RGB
system, we know red and green make yellow. Thus (255, 255, 0) means both red
and green are fully saturated (255 is as large as an 8-bit value can be), with no
FIGURE 1.2
The (a) Binary, (b) Grayscale, and (c) Color Images of Lena.
1.1 Background
3

blue (zero), resulting in the color yellow. However, three values like (250, 165, 0),
meaning (red ¼ 250, green ¼ 165, blue ¼ 0), can denote one orange pixel.
A grayscale image is what people normally call a black-and-white image, but the
name emphasizes that such an image will also include many shades of gray. In an 8-
bit grayscale image, each picture element has an assigned intensity that ranges from
0 to 255, i.e., I(m,n)˛[0, 255]. A gray has the property of having equal RGB values.
For example, black is an RGB value of (0, 0, 0) and white is (255, 255, 255), (220,
220, 220) is a light gray (near white), and (40, 40, 40) is a dark gray (near black).
Since gray has equal values in RGB, a grayscale image only uses 1 byte per pixel
instead of 3 bytes. The byte still holds values 0 to 255, to represent 256 shades of
gray. Fig. 1.3 shows an enlarged grayscale image with 100 pixels of different
grayscales.
A binary image is a digital image that has only two possible values for each pixel,
i.e., I(m,n)˛{0, 1}. Typically the two colors used for a binary image are black and
white, although any two colors can be used. Binary images are also called bilevel or
two level. This means that each pixel is stored as a single bit, i.e., 0 or 1. Binary im-
ages often arise in digital image processing as masks or as a result of certain oper-
ations such as segmentation, thresholding, and dithering. Some input/output devices,
such as laser printers, fax machines, and bilevel computer displays, can only handle
bilevel images. A binary image can be stored in memory as a bitmap, a packed array
of bits, i.e., every 8 bits is packed into 1 byte.
1.1.2 IMAGE PROCESSING AND IMAGE ANALYSIS
1.1.2.1 Image Processing in a Broad Sense
In a broad sense, image processing is any form of signal processing for which the
input is an image, such as a photograph or video frame; the output of image
FIGURE 1.3
An Example Grayscale Image With 100 pixels, Where Each Pixel Has a Value From
0 (Black) to 255 (White), and the Possible Range of the Pixel Values Depends on the Color
Depth of the Image, Here 8 bits ¼ 256 tones or Grayscales.
4
CHAPTER 1 Introduction

processing may be either an image or a set of characteristics or parameters related to
the image. Most image processing techniques involve treating the image as a two-
dimensional signal and applying standard signal processing techniques to it.
Image processing usually refers to digital image processing, but optical and
analog image processing also are possible. In electrical engineering and computer
science, analog image processing is any image processing task conducted on two-
dimensional analog signals by analog means as opposed to digital image processing.
Digital image processing is the use of computer algorithms to perform image pro-
cessing on digital images. As a subcategory or ﬁeld of digital signal processing, dig-
ital image processing has many advantages over analog image processing. It allows a
much wider range of algorithms to be applied to the input data and can avoid prob-
lems such as the buildup of noise and signal distortion during processing. Since im-
ages are deﬁned over two dimensions (perhaps more), digital image processing may
be modeled in the form of multidimensional systems.
In this book, we only discuss digital image processing. Digital image processing
refers to the processing of a 2D/3D image by a computer. Digital image processing
systems require that the images be available in the digitized form. For digitization,
the given analog image is sampled on a discrete grid and each sample or pixel is quan-
tized using a ﬁnite number of bits. The digitized image then can be processed by a
computer. Modern digital technology has made it possible to manipulate multidimen-
sional signals with systems that range from simple digital circuits to advanced parallel
computers. The goal of this manipulation can be divided into three categories: (1) im-
age processing in a narrow sense, where the input is an image and the output is also an
image; (2) image analysis, where the input is an image, whereas the outputs are some
measurements of the image; and (3) image understanding, where the input is an im-
age, whereas the outputs are some high-level descriptions of the image.
An image may be considered to contain subimages sometimes referred to as re-
gions of interest, or simply regions. This concept reﬂects the fact that images
frequently contain collections of objects each of which can be the basis for a region.
In a sophisticated image processing system, it should be possible to apply speciﬁc
image processing operations to selected regions. Thus one part of an image (region)
might be processed to suppress motion blur, whereas another part might be pro-
cessed to improve color rendition.
Two concepts closely related to image processing are computer graphics and com-
puter vision. In computer graphics, images are manually made from physical models
of objects, environments, and lighting, instead of being acquired (via imaging devices
such as cameras) from natural scenes, as in most animated movies. Computer vision,
on the other hand, is often considered high-level image processing out of which a ma-
chine/computer/software intends to decipher the physical contents of an image or a
sequence of images (e.g., videos or 3D full-body magnetic resonance scans).
In modern sciences and technologies, images also gain much broader scopes due
to the ever-growing importance of scientiﬁc visualization (of often large-scale com-
plex scientiﬁc/experimental data). Examples include microarray data in genetic
research, or real-time multiasset portfolio trading in ﬁnance.
1.1 Background
5

1.1.2.2 Image Processing in a Narrow Sense
In this section, we consider image processing in a narrow sense, that is, the study of
any algorithm that takes an image as input and returns an image as output. Before
processing an image, it is converted into a digital form. Digitization includes sam-
pling of an image and quantization of the sampled values. After converting the im-
age into bit information, the following processing steps are performed. Three main
traditional processing techniques are image enhancement, image restoration, and
image compression, which are brieﬂy described as follows.
1.1.2.2.1 Image Enhancement
The goal of image enhancement is to improve the usefulness of an image for a given
task such as providing a more subjectively pleasing image for human viewing. In im-
age enhancement, little or no attempt is made to estimate the actual image degrada-
tion process, and the techniques are often ad hoc. This process does not increase the
inherent information content in data. It is a subjective process. It includes gray level
and contrast manipulation, noise reduction, edge sharpening, ﬁltering, interpolation
and magniﬁcation, and pseudocoloring. Image enhancement techniques can be
divided into two categories: frequency domain methods and spatial domain methods.
The former process the image as a two-dimensional signal and enhance the image
based on its two-dimensional Fourier transform. The low-pass ﬁlterebased method
can remove noise from the image, whereas using high-pass ﬁltering, we can enhance
the edge, which is a kind of high-frequency signal, and make the blurred image clear.
Typical spatial domainebased algorithms are the local mean ﬁlteringebased
method and median ﬁltering (take intermediate pixel value of the local neighbor-
hood)ebased method, which can be used to remove or weaken the noise.
1.1.2.2.2 Image Restoration
Images are often degraded during the data acquisition process. The degradation may
involve motion blurring, information loss due to sampling, camera misfocus, quan-
tization effects, and various sources of noise. The purpose of image restoration is to
estimate the original image from the degraded data. It is concerned with ﬁltering the
observed image to minimize the effect of degradations. Effectiveness of image resto-
ration depends on the extent and accuracy of the knowledge of the degradation pro-
cess as well as on ﬁlter design. Image restoration is different from image
enhancement in that the latter is designed to emphasize features of the image that
make the image more pleasing to the observer, but not necessarily to produce real-
istic data from a scientiﬁc point of view. Image enhancement techniques use no a
priori model of the process that created the image.
1.1.2.2.3 Image Compression
The objective of image compression is to reduce irrelevance and redundancy of the
image data to be able to store or transmit data in an efﬁcient form. It is concerned
with minimizing the number of bits required to represent an image. Image compres-
sion may be lossy or lossless. Lossless compression is preferred for archival
6
CHAPTER 1 Introduction

purposes and often for medical imaging, technical drawings, clip art, or comics.
Lossy compression methods, especially when used at low bit rates, introduce
compression artifacts. Lossy methods are especially suitable for natural images
such as photographs in applications in which minor (sometimes imperceptible)
loss of ﬁdelity is acceptable to achieve a substantial reduction in bit rate. The lossy
compression that produces imperceptible differences may be called visually lossless.
We will provide an overview of image compression methods in Section 1.3.
Besides these three techniques, in fact, we can view the process of information
embedding in cover images as a special kind of digital image processing, since
both its input and output are digital images.
1.1.2.3 Image Analysis
Image analysis is the extraction of meaningful information from images, mainly
from digital images by means of digital image processing techniques. Image anal-
ysis tasks can be as simple as reading bar coded tags or as sophisticated as identi-
fying a person based on faces. There are many different techniques used in
automatically analyzing images. Each technique may be useful for a small range
of tasks; however, there are still no known methods of image analysis that are
generic enough for wide ranges of tasks, compared with the abilities of a human’s
image-analyzing capabilities. Examples of image analysis techniques in different
ﬁelds include: 2D and 3D object recognition, image segmentation, motion detection
(e.g., single particle tracking), video tracking, optical ﬂow, medical scan analysis,
3D pose estimation, automatic number plate recognition, and so on.
Digital image analysis is the process in which a computer or electrical device
automatically studies an image to obtain useful information from it. Note that the
device is often a computer, but it may also be an electrical circuit, a digital camera,
or a mobile phone. The applications of digital image analysis are continuously
expanding through all areas of science and industry, including medicine, such as
detecting cancer in an MRI scan; microscopy, such as counting the germs in a
swab; remote sensing, such as detecting intruders in a house and producing land
cover/land use maps; astronomy, such as calculating the size of a planet; materials
science, such as determining if a metal weld has cracks; machine vision, such as
automatically counting items in a factory conveyor belt; security, such as detecting
a person’s eye color or hair color; robotics, such as avoiding steering into an
obstacle; optical character recognition, such as detecting automatic license plate;
assay microplate reading, such as detecting where a chemical was manufactured;
and metallography, such as determining the mineral content of a rock sample.
Computers are indispensable for the analysis of large amounts of data, for tasks
that require complex computation, or for the extraction of quantitative information.
Computer image analysis largely involves the ﬁelds of computer or machine vision,
and medical imaging, and makes heavy use of pattern recognition, digital geometry,
and signal processing. It is the quantitative or qualitative characterization of 2D or
3D digital images. Two-dimensional images are usually analyzed in computer
vision, whereas 3D images in are analyzed in medical imaging. On the other
1.1 Background
7

hand, the human visual cortex is an excellent image analysis apparatus, especially
for extracting higher level information, and for many applicationsdincluding med-
icine, security, and remote sensingdhuman analysts still cannot be replaced by
computers. For this reason, many important image analysis tools such as edge detec-
tors and neural networks are inspired by human visual perception models.
In fact, we can view the process of information extracting from stego images as a
special kind of digital image analysis, since its input is an image and its output is the
secret information or the conclusion whether the stego image is authentic or water-
marked. Thus, the topic of information hiding in images is closely related to digital
image processing and analysis, and many traditional image processing and analysis
techniques can be used in information hiding.
1.1.3 NETWORK INFORMATION SECURITY
With the rapid development of computer technology, the information network has
become an important guarantee of social development. An information network in-
volves national governments, military, cultural, educational, and other ﬁelds, and the
information it transmits, stores, and processes is related to the government’s macro-
control policies, business and economic information, bank money transfer informa-
tion, important information in stocks and bonds, energy and resource data, and
research data. There is a lot of sensitive information, or even a state secret, so it
will inevitably attract the attack from a variety of people around the world (such
as information leakage, information theft, data tampering, data deletion, and
appending, computer viruses). Often, in crime using computers, it is difﬁcult to leave
evidences of a crime, which greatly stimulates the occurrence of high-tech computer
crime cases. The rapid increase in computer crimes causes computer systems of all
countries, especially network systems, to face a serious threat, and it has become one
of the serious social problems.
Network information security is an important issue related to national security
and sovereignty, social stability, and ethnic and cultural inheritance. It becomes
more and more important with the accelerated pace of global information. Network
information security is a comprehensive discipline involving computer science,
network technology, communication technology, cryptography, information security
technology, applied mathematics, number theory, information theory, and other dis-
ciplines. It mainly refers to the fact that the hardware, software, and data in the
network system are protected from destruction, alteration, and disclosure due to
accidental or malicious reasons; that the network system can run continuously
and reliably; and that the network service is not interrupted.
Network information security consists of four aspects, i.e., the security problems
in information communication, the security problems in storage, the audit of
network information content, and authentication. To maintain the security of data
transmission, it is necessary to apply data encryption and integrity identiﬁcation
techniques. To guarantee the security of information storage, it is necessary to guar-
antee database security and terminal security. Information content audit is to check
8
CHAPTER 1 Introduction

the content of the input and output information from networks, so as to prevent or
trace the possible whistle-blowing. User identiﬁcation is the process of verifying
the principal part in the network. Usually there are three kinds of methods to verify
the principal part identity. One is that only the secret known by the principal part is
available, e.g., passwords or keys. The second is that the objects carried by the prin-
cipal part are available, e.g., intelligent cards or token cards. The third is that only
the principal part’s unique characteristics or abilities are available, e.g., ﬁngerprints,
voices, or retina or signatures. The technical characteristics of the network informa-
tion security mainly embody the following aspects. (1) Integrity: It means the
network information cannot be altered without authority; it is against active attacks,
guaranteeing data consistence and preventing data from being modiﬁed and
destroyed by illegal users. (2) Conﬁdentiality: It is the characteristic that the network
information cannot be leaked to unauthorized users; it is against passive attacks so as
to guarantee that the secret information cannot be leaked to illegal users. (3) Avail-
ability: it is the characteristics that the network information can be visited and used
by legal users if needed. It is used to prevent information and resource usage by legal
users from being rejected irrationally. (4) Nonrepudiation: It means all participants
in the network cannot deny or disavow the completed operations and promises; the
sender cannot deny the already sent information, while the receiver also cannot deny
the already received information. (5) Controllability: It is the ability of controlling
the network information content and its prevalence, namely, it can monitor the
network information security.
The coming of the network information era also proposes a new challenge to
copyright protection. Copyright is also called author right. It is a general designation
(http://dict.iciba.com/be) called by a joint name/of spirit right based on a special pro-
duction and the economic right which completely dominates this production and its
interest. With the continuous enlargement of the network scope and the gradual
maturation of digitalization techniques, the quantity of various digitalized books,
magazines, pictures, photographs, music, songs, and video products has increased
rapidly. These digitalized products and services can be transmitted by the network
without the limitation of time and space, even without logistic transmission. After
the trade and payment completed, they can be efﬁciently and quickly provided for
clients by the network. On the other hand, the network openness and resource
sharing will cause the problem of how to validly protect the digitalized network
products’ copyright. There must be some efﬁcient techniques and approaches for
the prevention of digitalized products’ alteration, counterfeit, plagiarism and
embezzlement, etc.
Information security protection methods are also called security mechanisms. All
security mechanisms are designed for some types of security attack threats. They can
be used individually or in combination in different manners. The commonly used
network security mechanisms are as follows. (1) Information encryption and hiding
mechanism. Encryption makes an attacker unable to understand the message con-
tent, and thus the information is protected. On the contrary, hiding is to conceal
the useful information in other information, and thus the attacker cannot ﬁnd it. It
1.1 Background
9

not only realizes information secrecy but also protects the communication itself. So
far, information encryption is the most basic approach in information security pro-
tection, whereas information hiding is a new direction in information security areas.
It draws more and more attention in the applications of digitalized productions’
copyright protection. (2) Integrity protection. It is used for illegal alteration preven-
tion based on the cipher theory. Another purpose of integrity protection is to provide
nonrepudiation services. When information source’s integrity can be veriﬁed but
cannot be simulated, the information receiver can verify the information sender. Dig-
ital signatures can provide methods for us. (3) Authentication mechanism. The basic
mechanism of network security, namely, network instruments should authenticate
each other so as to guarantee the right operations and audit of a legal user. (4) Audit.
It is the foundation of preventing inner criminal offenses and taking evidence after
accidents. Through the records of some important events, errors can be localized and
reasons of successful attacks can be found when mistakes appear in the system or it
is attacked. Audit information should prevent illegal deletion and modiﬁcation. (5)
Power control and access control. It is the requisite security means of host computer
systems. Namely, the system endows suitable operation power to a certain user ac-
cording to the right authentication and thus makes him not exceed his authority.
Generally, this mechanism adopts the role management method, that is, aiming at
system requirements, to deﬁne various roles, e.g., manager, and accountant, and
then to endow them different executive powers. (6) Trafﬁc padding. It generates
spurious communications or data units to disguise the amount of real data units be-
ing sent. Typically, useless random data are sent out in vacancy and thus enhance the
difﬁculty to obtain information through the communication stream. Meanwhile, it
also enhances the difﬁculty to decipher the secret communications. The sent random
data should have good simulation performance and thus can mix the false with the
genuine. This book focuses on applying digital watermarking techniques to solve
the copyright protection and content authentication problems for images, involving
the ﬁrst three security mechanisms.
1.1.4 IMAGE PROTECTION AND IMAGE AUTHENTICATION
With the rapid development of digital image processing techniques and populariza-
tion of the Internet, digital images are being more and more widely used in a number
of applications from medical imaging and law enforcement to banking and daily
consumer use. They are much more convenient in editing, copying, storing, trans-
mitting, and utilizing. However, unfortunately, at the same time, digital images
are facing the problems of protection and authentication as follows.
1.1.4.1 Image Protection
Image protection mainly includes copyright protection, copy control, and source
tracing for digital images. Both companies and private individuals have access to net-
works with an ever-growing bandwidth and network infrastructure. Lack of sufﬁ-
ciently strong copyright protection and copy control is one of the hindrances for
10
CHAPTER 1 Introduction

increased use of the Internet for publishing images where protection of copyright is a
requirement and for distribution of images where copy control is a requirement. Source
tracing refers to tracing the source of the pirated image and telling us who the pirate is.
It is important that there be a level of control on what one of the parties is doing
with the image received or made available from the other. One example of this kind
of transaction is purchase of the image downloaded via the Internet in digital repre-
sentation and therefore easily manipulated and duplicated with computers or other
devices that can read, copy, and transform the received image unless there is
some mechanism that controls what the user can do with the image. Often there
will be an intellectual property right and a commercial issue connected to the image,
and the publisher and distributor therefore need to have inﬂuence and control over
what the buyer is doing with the delivered digital image.
Another important area is when the image is not delivered from one part to the
other but is published on the Internet available for anybody with access to the
Internet. Still there may be connected intellectual property rights to the published
image, so the publisher needs to be able to trace and prove that the pirate violates
the intellectual property rights and copyrights.
What does a potential publisher of images on the Internet or a potential distrib-
utor of images over the Internet have to assess before he can decide which tech-
niques, methods, and security products he should employ to ensure protection of
copyrights of published images and control over copying of distributed images?
There are mainly two approaches used to ensure security and control when distrib-
uting and publishing images where intellectual right protection and copy control are
major concerns: (1) use of information hiding for copyright protection of images
published on the Internet and (2) establishing digital right management systems
(DRMS) for copy control of distributed information.
In Section 1.4, we will give an overview of information hiding in images and
describe how different applications of information hiding can be used to protect in-
tellectual property rights when distributing and publishing images. For example, the
robust image watermarking technique can be used to embed copyright information
in the cover image; then if it is required we can extract the copyright information
from the watermarked image, or even the attacked version, to verify the ownership
of the image. Furthermore, description of systems that are used for distribution of
images when copy control is of critical importance are discussed. These systems
are often referred to as DRMS.
Besides copyright protection and copy control, information hiding can be also
applied to source tracing. A watermark can be embedded into a digital image at
each point of distribution. If a copy of the image is found later, then the watermark
may be retrieved from the copy and the source of the distribution is known. This
technique can be used to detect the source of illegally copied images or movies.
1.1.4.2 Image Authentication
With the development of network, multimedia information such as books, music,
images, and videos has been widespread because of its ease of access and of
1.1 Background
11

copying, which has greatly enriched people’s lives. However, digital images, in the
case of absence of protection, are vulnerable to be tampered or forged, thereby their
authenticity and integrity are damaged. When a digital image is used as an evidence,
its authenticity and integrity is particularly important. For example, in medicine, the
accuracy and integrity of the medical image is very important to diagnosis; in court,
the authenticity of provided photographs has an important effect on the nature of the
evidence. Therefore, there is an urgent need to develop a technique to protect the
authenticity and integrity of multimedia information, especially for images.
Image authentication is a technology emerging in the context of the aforemen-
tioned applications, which has been rapidly developed, and its purpose is to identify
and detect the authenticity and integrity of the image. Image authentication methods
currently implemented can be mainly divided into two categories:
The ﬁrst category is digital signatureebased image authentication schemes,
which simply add the signature information after the original image. The authenti-
cation is realized by recalculating the signature information in the input image and
comparing it with the original additional signature information to detect possible im-
age tampering. Although this kind of algorithm is simple in ideas and easy to be
implemented, its biggest drawback is that during veriﬁcation we require additional
signature information, and thus we cannot fulﬁll the blind authentication where we
cannot use any additional information.
The second category is digital watermarkingebased image authentication
schemes, which overcome the deﬁciencies of the signature-based schemes. The
authentication information hidden in the original image without the need for addi-
tional signature information is the main advantage of this type of approach. In
fact, the whole book mainly focuses on this type of image authentication algorithm.
Authentication watermarks can be generally divided into fragile watermarks and
semifragile watermarks. Utilizing the fragility of watermarks, the tampering opera-
tions on the watermarked image will also affect the embedded watermark, and there-
fore the extracted watermark can be used to determine if the image has been
tampered with or not. The fragile watermark is sensitive to all operations, that is,
any modiﬁcation operation on the watermarked image will change the extracted
watermark. As long as the detected watermark has subtle changes, it shows that
the original watermarked image has been altered. The semifragile watermark is
robust to some well-intentioned operations but fragile to other malicious operations.
The semifragile watermarkingebased authentication system can allow certain oper-
ations such as image compression and format conversion, but not other malicious
operations like pruning.
1.2 OVERVIEW OF INFORMATION HIDING
Digital equipment and computer technologies provide a great convenience for pro-
duction and access to multimedia information such as audio, images, video, anima-
tion, text, and 3D models. Meanwhile, with the growing popularity of the Internet,
12
CHAPTER 1 Introduction

multimedia information exchange has reached unprecedented breadth and depth.
People can now publish their works through the Internet, communicate important
information, or perform network trade. However, as a result, some very serious prob-
lems also emerge: it becomes easier to infringe the rights of digital works and violate
the privacy of people, it becomes more convenient to tamper and forge the digital
works, and the malicious attacks become more rampant. Therefore, the problem
of how to effectively protect intellectual properties and ensure network information
security has attracted people’s attention. In addition, modern warfare is a multidi-
mensional war where multiple arms perform cooperative combats; in a way it is a
kind of electronic warfare, information warfare, and network warfare and it has
been transformed from traditional electronic warfare into information confrontation.
Under these circumstances, an emerging interdisciplinary, information hiding, was
ofﬁcially born. Today, as a primary means of secret communication, intellectual
property protection, content authentication, and other areas, information hiding is
widely studied and applied.
To combat the crime of piracy and ensure network information security, on the
one hand, we need to strengthen the protection of intellectual property and network
information through legislation; on the other hand we must use advanced techniques
to ensure the implementation of the law. Although cryptography can be used to solve
some of these problems, there are three disadvantages. (1) It clearly tells the at-
tackers where the important information is, it is easy to cause the attacker’s curiosity
and attention, and the encrypted information may be cracked by attackers. (2) Once
the encrypted ﬁle is cracked, its content will be completely transparent. (3) In the
case that an attacker failed to decipher the information, he might destroy the infor-
mation, so that even a legitimate recipient cannot read the message content. In the
early 1990s, information hiding technology, with its unique advantages of solving
some deﬁciencies in cryptography, has begun to attract people’s attention, and
various applications of information hiding have attracted concern and attention
from different research groups. The ﬁrst International Symposium on Information
Hiding held in the United Kingdom in May 1996 make these independent research
groups come together to achieve consensus on some basic concepts and terminol-
ogies of information hiding. The main purpose of this section is to overview the in-
formation hiding technique, including basic concepts, models, research branches,
properties, and applications of information hiding, together with the classiﬁcation
of information hiding schemes.
1.2.1 BASIC CONCEPTS RELATED TO INFORMATION HIDING
Since the emergence of human culture, human beings have the idea of protecting the
information. The two words cryptography and steganography ofﬁcially appeared in
the mid-17th century, and both are derived from the Greek, where steganography
means “covered writing.” In fact, the concept of information hiding can be dated
back to ancient Greece times. Information hiding is also known as data hiding.
Broadly speaking, there are a variety of meanings for information hiding; the ﬁrst
1.2 Overview of Information Hiding
13

means the message is not visible, the second means the existence of information is
hidden, the third means the information recipient and sender are hidden, and the four
means the transmission channels are hidden. Information hiding is the process of
hiding the secret information in another open carrier so as to not draw the examiner’s
attention. Here, the carrier may be an image, a video sequence, an audio clip, a chan-
nel, or even a coding system or a cryptographic system. Thus, cryptography only
hides the content of information, whereas information hiding technology hides
not only the content of information but also the existence of information. In the
broad sense, information hiding technology includes steganography, digital water-
marking,
digital
ﬁngerprinting,
covert
channel,
subliminal
channel,
low-
probability intercept communication, and anonymous communication. From the
narrow point of view, information hiding is to hide a secret message in another pub-
lic information and then to pass secret information through transmitting public infor-
mation. Information hiding in the narrow sense usually refers to steganography and
digital watermarking (including digital ﬁngerprinting).
There are two reasons why information can be used to hide in the multimedia
data. (1) There is a big redundancy in multimedia information. From the perspective
of information theory, the coding efﬁciency of uncompressed multimedia informa-
tion is very low, so the process of embedding the secret information into the multi-
media information for conﬁdential transmission is feasible and will not affect the
transmission and use of multimedia information. (2) The human eye or ear itself
has a masking effect; for example, the resolution of the human eye has only a few
dozen gray levels, and human eyes are insensitive to the information near edges.
By utilizing these human features, we can very well hide the information to make
it unnoticed.
Typically, both hiding and encryption techniques should be based on keys to pro-
tect the information. However, information hiding is different from traditional cryp-
tography. Cryptography is to study how to encode the special secret information to
form a ciphertext that cannot be identiﬁed, whereas information hiding is to study
how to hide the secret information into other carriers and then pass the secret infor-
mation through transmitting these public carriers. For encryption-based communica-
tion, the possible monitors or illegal interceptors can intercept the ciphertexts and
decipher them, or destroy them before sending them, thus affecting the security of
conﬁdential information. However, for information hiding, it is difﬁcult for the
possible monitors or illegal interceptors to determine the existence of secret infor-
mation based on the public carriers, thus it is difﬁcult to intercept the conﬁdential
information, which can ensure the security of conﬁdential information. For
increasing the difﬁculty of deciphering, we can also combine cryptography and in-
formation hiding, that is, the information to be embedded is encrypted to be cipher-
texts and then the ciphertexts are hidden into the cover object. Thus, the traditional
cryptography-based information security and hiding-based information security are
not conﬂicting or competing but complementary.
Under the broad concept of information hiding, here are some terms given in the
ﬁrst International Conference on Information Hiding. The object to be secretly
14
CHAPTER 1 Introduction

hidden in other media is known as the embedded object, which is the secret informa-
tion (secret message) for a particular purpose. The carrier used to hide the embedded
object is called the cover object. It should be noted that, here, the object can refer to a
message, a text, an image, a video sequence, an audio clip, a cryptographic protocol,
or a coding system. The output of embedding an embedded object into a cover object
is called stego object, because it has no perceivable difference from the cover object.
The process of adding the embedded object to the cover object is called information
embedding, whereas the algorithm used in the embedding process is referred to as
embedding algorithm. The inverse process of information embedding, i.e., the pro-
cess of extracting the embedded object from the stego object, is called information
extracting. Similarly, the algorithm used in the extraction process is referred to as
extracting algorithm. The organization or individual who performs the embedding
process and the extraction process are referred to as the embeddor and extractor,
respectively.
In the information hiding system, people often need to use some additional secret
information to control the embedding and extraction processes that only its holder
can operate; we call the secret information stego key. The key used in the embedding
process is referred to as the embedding key, whereas in the extraction process the key
is called the extracting key. Usually the embedding key is the same as the extracting
key, and the corresponding information hiding technique is called symmetric infor-
mation hiding; if the keys are not the same, it is called asymmetric information
hiding.
Similar to cryptography, the research on information hiding can be divided into
steganography and stegoanalysis. The former focuses on how to add the embedded
object to the cover object. The latter focuses on how to break out from the stego ob-
ject the embedded information, or destroy the embedded information or prevent in-
formation detection through processing the stego object. Similarly, we can call the
person who researches or implements the hiding technology as a hider, whereas the
attacker or analyzer of the hiding system is called a stegoanalyst.
Note that in different branches of information hidden, the aforementioned terms
may correspond to different terminologies.
1.2.2 PROPERTIES AND REQUIREMENTS OF INFORMATION HIDING
Information hiding is different from traditional cryptography, since its purpose is not
to restrict normal access to the stego object, but rather to ensure that the secret in-
formation will not be violated and discovered. Therefore, the information hiding
technology must consider the threat caused by the normal operation of the informa-
tion, i.e., to make the embedded object (secret information) immune to normal data
manipulation techniques. The key of this immunity is to make the part where we
embed information not easy to be destroyed by normal data manipulations (such
as normal operations of signal conversion or data compression). According to
different purposes and technical requirements of information hiding, this technology
has the following characteristics or requirements:
1.2 Overview of Information Hiding
15

1. Transparency (imperceptibility)
The transparency property requires that, based on the characteristics of the hu-
man visual system or the human auditory system, through a series of hidden
processing, the stego object does not have obvious degradation phenomena
compared with the cover object, and the embedded object cannot be seen or
heard artiﬁcially. Of course, very few applications may need to use visible
watermarking technologies.
2. Robustness
Robustness refers to the ability of extracting the embedded object when the stego
object is subject to some signal processing operations. Here, signal processing
operations include the common information processing (such as data
compression, low-pass ﬁltering, image enhancement, subsampling, requanti-
zation, A/D and D/A conversion), geometric transformation and geometric
distortion (e.g., cropping, scaling, translation, and rotation), adding noise,
ﬁltering operations, printing, scanning, and multiple watermarking. After these
changes, robust information hiding algorithms should be able to extract the
embedded secret information from the stego object.
3. Security
Security refers to the ability of resisting malicious attacks, i.e., the stego object
should be able to withstand intentional attacks to a certain degree, while
ensuring that the embedded object is not destroyed. In addition, similar to
encryption, the information hiding technique requires that protecting the secret
information eventually relies on protecting keys. Thus, the basic requirements
of cryptography on keys is also applicable to the information hiding techniques,
that is, there must be a large enough key space. In designing an information
hiding system, key generation, distribution, and management must also be
synthetically considered.
4. Undetectability
Undetectability requires that the stego object and the cover object have consis-
tent characteristics, such as a consistent statistical noise distribution, so that the
analyst cannot determine whether the embedded object is hidden in the stego
object.
5. Self-recoverability
After certain operations or transformations, the stego object may be greatly
damaged. If we can recover the embedded object from only a fragment of the
stego object, and the recovery process does not require the cover object, then the
algorithm has high self-recoverability. Of course, not all applications require
self-recoverability.
6. Hiding capacity
The cover object should be able to hide as much information as possible. In fact,
if the stego object would not be subject to any disturbance, people could hide
more information in the cover object without being noticed. Of course, under
the condition of guaranteeing the transparency, the more information we hide,
the worse the robustness is.
16
CHAPTER 1 Introduction

In fact, the three most important factors of information hiding are transparency,
robustness, and hiding capacity; it is difﬁcult to simultaneously achieve them opti-
mally, and we must focus on different factors according to different scenarios. The
performance of the entire information hiding system is the result of balancing these
three major factors. For example, the research focus of steganography is to hide se-
cret information, thus transparency and hiding capacity must be guaranteed ﬁrst.
However, for digital watermarking technology, the main purpose is to protect the
cover object; we need to consider the robustness requirement against all possible
attacks.
1.2.3 INFORMATION HIDING MODELS
In the research course of information hiding techniques, different models have been
proposed to explain the information hiding. These models can be roughly divided
into the prisoner model, the general model, and the communication-based models.
Among them, the prisoner model is a classic model of information hiding, the gen-
eral model gives the algorithm ﬂow of embedding-based information hiding
schemes using the cover object, and communication-based models from the perspec-
tive of information theory study the model of information hiding and hiding capac-
ity. These models are brieﬂy introduced in the following sections.
1.2.3.1 Prisoner’s Model
The prisoner’s model is a classic model of information hiding as shown in Fig. 1.4.
The model is based on the prisoner’s problem proposed by Simmons in 1983. Alice
and Bob were arrested and detained in different cells. Now they want to plan to
escape; unfortunately, all communications between them should be carried out in
the surveillance of the warden Wendy. Wendy does not allow them to carry out
encryption-based communications, and if she notices any suspicious communica-
tions, she will put them both into single prisons and prohibit any individual informa-
tion exchange. Therefore, both sides must communicate in a secretive way, to avoid
Wendy’s suspicion. To this end, they have to create a subliminal channel. A practical
approach is to hide useful information in some seemingly ordinary information. In
this scenario, Alice and Bob, respectively, correspond to the embeddor and extractor
in the information hiding system, whereas the warden Wendy is the stegoanalyst,
i.e., attacker. The embeddor Alice uses an information hiding system to transmit
the secret information to the extractor such that the warden Wendy cannot ﬁnd
the embedded object in the stego object, because Wendy may modify the stego ob-
ject, and forward the modiﬁed stego object to Bob. Therefore, to let the secret infor-
mation still pass to Bob, the system should be robust to small modiﬁcations.
1.2.3.2 General Model
The prisoner’s model summarizes the main idea of most information hiding tech-
niques from the ancient times to nowadays, where the covert communication process
between Alice and Bob can be described using a more general model. The general
1.2 Overview of Information Hiding
17

model is used to describe the system structure of the embedding ﬂow of information
hiding. In fact, according to the terminology introduced in Section 1.2.1, we can get
a general model as shown in Fig. 1.5.
1.2.3.3 Communication-Based Models
In essence, information hiding is a kind of communication that passes secret mes-
sages between the embeddor and extractor. In the background of digital watermark-
ing technology, Cox proposed three communication-based models for information
hiding [1]. The difference between these three models lies in how the cover object
is introduced into the traditional communication model. In the ﬁrst basic model, as
shown in Figs. 1.6 and 1.7, the cover object is solely viewed as noise. In the second
model, the cover object is still regarded as a noise, but the noise as the side informa-
tion is input to the channel encoder. In the third model, the cover object is not
regarded as noise, but as the second information, and this information together
with the secret message is transmitted in a multiplexed form. These three commu-
nication models have the following obvious ﬂaws. (1) They do not take the features
of information hiding into account, namely, the information hiding system makes
Alice
Bob
Cover object
Embedded 
object 
Wendy
FIGURE 1.4
The Prisoner Model Proposed by Simmons.
Embedding process
Extracting process
Key generator
Embedded
object
Cover object
Stego object
Extracting 
key
Embedding 
key
Cover object
Embedded
object
Stegoanalyst
FIGURE 1.5
The General Model of Information Hiding Systems.
18
CHAPTER 1 Introduction

use of the human perceptual model to embed secret messages in the most inconspic-
uous places of the cover object, and at the same time, the cover object cannot be
completely viewed as noise. (2) The robustness is not considered, where robustness
means the ability of making the so-called secret message embedded with redun-
dancy, and resistant to signal processing, lossy compression, and geometric attacks.
1.2.4 RESEARCH BRANCHES OF INFORMATION HIDING
Information hiding is an emerging interdisciplinary, and it has broad application
prospects in the ﬁelds of computers, communications, cryptology, and so on. Infor-
mation hiding studies involve many ﬁelds including cryptography, image process-
ing, pattern recognition, mathematics, and computer science. According to
different purposes and different kinds of cover objects, information hiding can be
divided into many branches, as shown in Fig. 1.8. The following subsections brieﬂy
introduce several major branches of information hiding.
1.2.4.1 Steganography
The research work on information security includes not only the study of cryptog-
raphy but also the study of channel security, whose essence lies in hiding the exis-
tence of information. The application of information hiding in this area is an
important branch called steganography. The word “steganography” is derived
from the Greek word “ssεgayu,” which literally means “covert writing,” i.e., hiding
w
x
wa
Output 
message
Watermark 
decoder
Watermarking key
m
Watermark 
encoder
Input
message
Watermarking key Original carrier work
Watermark detector
Watermark embedder
K
m
w
x
n
Noise
x
Original carrier work
K
x
FIGURE 1.6
Nonblind Watermarking System Described by a Communication-Based Model.
x
wa
Output
message
Watermark 
decoder
Watermarking key
m
Watermark 
encoder
Input
message
Watermarking key Original carrier work
Watermark detector
Watermark embedder
K
m
w
x
n
Noise
K
x
FIGURE 1.7
Blind Watermarking System Described by a Communication-Based Model.
1.2 Overview of Information Hiding
19

secret messages in other messages. The main purpose of steganography is to hide
important information and transmit and store it unobtrusively. Therefore, in the steg-
anographic system, the embedded object is the secret message, which is the main
body to be protected, whereas the cover object may be any cover data that can be
used to achieve the purpose of concealment. Under normal circumstances, we
need to consider two factors, stego capacity and the imperceptibility of the steganog-
raphy results when selecting a cover object. Steganography can be broadly divided
into two types, one is to record the secret message to be transmitted and then send it
out through other media, namely, technical steganography; another is to hide the
behavior of recording itself, where the message consists of the language or language
forms used in covert writing, namely, linguistic steganography. For example, induc-
tion ink, diminished image, and spread spectrum communication technologies are
technical steganography, whereas linguistic steganography includes semagram,
open code, null cipher, and so on.
1.2.4.2 Copyright Marking
Adding an inconspicuous but distinguishable mark to the digital work is an effective
scheme of copyright protection, which is called copyright marking technique. The
mark can be a trademark, serial number, or a label preventing unauthorized users
to directly copy. According to the content and purpose of labeling, copyright
marking techniques can be divided into digital watermarking technology and digital
ﬁngerprinting technology. In the digital watermarking system, the digital watermark
Information Hiding
Covert 
Channel
Steganography
Anonymous 
Communication
Copyright 
Marking
Linguistic 
Steganography
Technical
 Steganography
Robust 
Copyright 
Marking
Fragile 
Watermarking
Fingerprinting
Robust
Watermarking
Imperceptible 
Watermarking
Visible 
Watermarking
Subliminal
Channel 
FIGURE 1.8
Main Research Branches of Information Hiding.
20
CHAPTER 1 Introduction

is used to represent the identity of the author. This information must be registered
and accredited by management agencies, and a number of digital works can be
embedded with the same watermark. On the contrary, in the digital ﬁngerprinting
system, digital ﬁngerprint is used to represent the identity of the purchaser; it is
required to embed different ﬁngerprints in the same work to distinguish different
buyers. Note that this book views copyright marking as digital watermarking in a
broad sense. In the digital watermarking and digital ﬁngerprint system, the analyst
is often called pirate and traitor, respectively.
1.2.4.3 Covert Channel
The so-called covert channel refers to a channel that allows information delivery in
the state of violation of safety rules, or allows interprocess communication in the
operating system in the state of violation of legitimate security policies. There are
two kinds of covert channels, i.e., covert storage channels and covert timing chan-
nels. Covert storage channel includes directly or indirectly writing a memory
address by one process, while reading by another process. In a covert timing chan-
nel, a process sends a message to another process by adjusting its usage of the system
resources (such as CPU time). This treatment also affects the observed actual
response time of the second process. The concepts in covert channels are similar
to many concepts in steganography, but in covert channel, the cover object is the
entire process of a system, rather than speciﬁc information media.
1.2.4.4 Subliminal Channel
In 1978, Simmons discovered the fatal ﬂaw existing in the supervision agreement of
the SALT II treaty signed between the Soviet Union and the United States, and thus
proposed the concept of subliminal channel. Subliminal channel refers to the overt
channel created in an implementation of covert communication. The subliminal
channel in cryptographic protocols refers to the mathematical structure that is adop-
ted to transmit secret messages in a variety of coding systems and cryptographic pro-
tocols. Some research work shows that a vast majority of digital signature schemes
contain subliminal communication channels, whose greatest feature is that the sub-
liminal message has no impact on the digital signature and veriﬁcation processes.
Even if the monitor knows what to look for, he cannot ﬁnd the usage of the channel
and get subliminal messages being sent, because the characteristics of subliminal
channels determine their security and conﬁdentiality, which are either unconditional
or computationally unbreakable.
1.2.4.5 Anonymous Communication
Anonymous communication is the process of looking for ways to hide the sender and
receiver of information, whose main techniques include anonymous retransmission
and network proxy technologies. This technique can be used in wired telephone net-
works and satellite telephone networks, and it applies not only to the military but
also for business and has been widely used in e-mail, Web browsing, and remote
registration. Web applications emphasize the anonymity of the recipient, and
1.2 Overview of Information Hiding
21

e-mail users are concerned about the anonymity of the sender. In addition, the
anonymous communication technology can also be used in electronic voting and
electronic cash scheme to ensure that the identity of the voter or purchase is not
leaked.
1.2.5 CLASSIFICATION OF INFORMATION HIDING TECHNOLOGIES
In addition to the classiﬁcation way of information hiding based on research
branches (or the object to be protected) in Section 1.2.4, information hiding tech-
niques can also be classiﬁed according to various other ways, such as the types of
cover objects, the symmetry of the keys, and the embedding domains. The following
subsections brieﬂy describe the various classiﬁcation schemes.
1.2.5.1 Classiﬁcation According to the Types of Cover Objects
According to different types of cover objects, information hiding techniques can be
divided into information hiding techniques for text, images, audio, video, 3D models
and animations, and so on. Information hiding techniques in text realize the informa-
tion embedding process by changing the text mode or some of the basic character-
istics of the text, which introduces some changes in the document, but the human
visual is insensitive to this change. Image-based information hiding techniques
view digital images as cover objects and embed the secret information in digital im-
ages based on a certain algorithm. Audio-based information hiding techniques
embed secret information in the cover audio imperceptibly to achieve copyright pro-
tection, covert communication, and other functions. In the information hiding sys-
tem for video, based on the visual characteristics of the human eyes’ limitations
on the resolution and sensitivity, the secret information is embedded in the percep-
tion redundant of the carrier signal.
1.2.5.2 Classiﬁcation According to the Symmetry of Keys
According to the keys used in the embedding and extraction processes, information
hiding techniques can be divided into keyless information hiding, symmetric infor-
mation hiding (private key information hiding), and asymmetric information hiding
(public key information hiding).
If an information hiding system does not require prearranged keys, we call it key-
less information hiding system. Mathematically, the information hiding process can
be described as a mapping Em: C  M / S, where C is the set of all possible cover
objects, M is the set of all possible secret messages, and S is the set of all stego ob-
jects. The information extraction process can also be viewed as a mapping Ex:
S / M, which extracts the conﬁdential information from the stego object.
To improve the security of keyless information hiding technology, the secret in-
formation can be encrypted before hiding, thus the information is protected by two
layers, one is based on cryptograph, and the other is based on information hiding, so
that it is more secure than single layerebased schemes. If the embedding and
extracting keys are the same, then the system is called symmetric information hiding
22
CHAPTER 1 Introduction

(private key information hiding), otherwise known as asymmetric information hid-
ing (public key information hiding).
1.2.5.3 Classiﬁcation According to the Embedding Domains
According to the embedded domains, information hiding methods can be divided
into the original domainebased, transform domainebased, and compressed
domainebased methods. Original domainebased methods refer to a class of infor-
mation hiding method that directly modiﬁes the original data of the cover object ac-
cording to certain rules, e.g., replacing the redundant portion of the cover object with
the secret information. Original domainebased schemes can be further divided into
spatial, temporal, and spatiotemporal domainebased schemes.
Transform domainebased information hiding algorithms ﬁrst perform a transfor-
mation, such as fast Fourier transform (FFT), discrete cosine transform (DCT), and
discrete wavelet transform (DWT), on the original cover signal to obtain the trans-
form coefﬁcients and then embed the secret information by modifying the transform
coefﬁcients. With the research progress of multimedia compression technologies,
many cover objects are usually stored in a compressed format, so the method of
embedding the secret information directly in the compressed domain has become
the focus of scholars’ attention. The compressed domainebased information hiding
technique combines the information hiding process and the compression process,
which can effectively prevent attacks that come from perceptual coding. For
example, during the JPEG image compression process, we can embed the secret in-
formation by modifying the transform coefﬁcients and the quantization factor, thus it
can be effectively robust to JPEG decompression and recompression attacks.
1.2.5.4 Classiﬁcation Based on Other Ways
In addition to above three ways of classiﬁcation, there are several other classiﬁcation
ways as follows.
According to the situation whether the original cover object is required
during the extraction of secret information, information hiding techniques can be
divided into nonblind hiding (private hiding) and blind hiding (public hiding)
schemes. If the original cover object is not required during the extraction of secret
information, it is a blind hiding scheme. On the contrary, if the original cover object
is required during the extraction of secret information, then it is a nonblind scheme.
Clearly, the use of original cover object can facilitate the detection and extraction of
the secret information. However, in the ﬁelds of data monitoring and tracking, we
cannot get the original cover object. So blind schemes are the focus of research
scholars.
According to the reversibility, information hiding techniques can be divided into
reversible and irreversible information hiding schemes. For reversible information
hiding schemes, if the stego object is not subject to modiﬁcations, we can not only
decode the secret information from the stego object but also recover the original cover
object. For irreversible information hiding schemes, we can only decode the secret in-
formation from the stego object, but cannot recover the original cover object.
1.2 Overview of Information Hiding
23

According to the robustness, information hiding techniques can be divided into
robust information hiding schemes, fragile information hiding schemes, and semi-
fragile information hiding schemes. For robust information hiding systems, under
the condition that the attacked stego object is visually similar to the cover object,
the secret information can be still extracted from the stego object that is attacked
by a variety of inadvertent and malicious attacks. For fragile information hiding sys-
tems, by contrast, under a variety of unintentional and malicious attacks, the hidden
secret information will be lost. For semifragile information hiding systems, they are
robust to certain attacks but fragile to other attacks.
1.2.6 APPLICATIONS OF INFORMATION HIDING TECHNIQUES
The application ﬁelds of information hiding techniques are very wide. There are
mainly the following nine categories: covert communication, broadcast monitoring,
owner identiﬁcation, ownership veriﬁcation, transaction tracking, content authenti-
cation, annotation, copy control, and device control. Each application is concretely
introduced in the following sections.
1.2.6.1 Covert Communication
In the modern society with network globalization and economic globalization, every
day a large amount of data are sent over the network, some of which involve the
important information related to political, military, commercial, ﬁnancial, and per-
sonal privacy. Once the information is illegally intercepted, it will lead to incalcu-
lable consequences. Since information hiding techniques have the role of keeping
the conﬁdentiality of information, they can protect the information. Covert commu-
nication is mainly used for secure communication of conﬁdential information; it pro-
tects the information that is embedded in the cover object, where usually we adopt
the multimedia information as the cover object. Due to the huge amount of multi-
media information online, the secret information is hard to be detected by an
eavesdropper.
1.2.6.2 Broadcast Monitoring
The advertiser hopes that his advertisements can be aired completely in the airtime
that is bought from the broadcaster, whereas the broadcaster hopes that he can obtain
advertisement dollars from the advertiser. To realize broadcast monitoring, we can
hire some people to directly survey and monitor the aired content. However, this
method costs a lot, and it is also easy to make mistakes. We can also use the dynamic
monitoring system to put recognition information outside the area of broadcast
signal, e.g., vertical blanking interval; however, there are some compatibility prob-
lems to be solved. The watermarking technique can encode recognition information,
and it is a good method to replace dynamic monitoring technique. It uses the char-
acteristic of embedding itself in content and requires no special fragments of the
broadcast signal. Thus it is completely compatible with the installed analog or digital
broadcast device.
24
CHAPTER 1 Introduction

1.2.6.3 Owner Identiﬁcation
There are some limitations in using the text copyright announcement for product
owner recognition. First, during the copying process, this announcement is very
easy to be removed, sometimes accidentally. For example, when a professor copies
several pages of a book, the copyright announcement in topic pages is probably
neglected to be copied. Another problem is that it may occupy some parts of the im-
age space, destroying the original image, and it is easy to be cropped. As watermark
is not only invisible but also cannot be separated from the watermarked product, it is
more beneﬁcial than text announcement in owner identiﬁcation. If the product user
has a watermark detector, he can recognize the watermarked product’s owner. Even
if the watermarked product is altered by the method that can remove the text copy-
right announcement, the watermark can still be detected.
1.2.6.4 Ownership Veriﬁcation
Besides identiﬁcation of the copyright owner, applying watermarking techniques for
copyright veriﬁcation is also a particular concern. Conventional text announcement
is extremely easy to be tampered with and counterfeited, and thus it cannot be used
to solve this problem. A solution for this problem is to construct a central informa-
tion database for digital product registration. However, people may not register their
products because of the high cost. To save the registration fee, people may use wa-
termarks to protect copyright. And to achieve a certain level of security, the granting
of detectors may need to be restricted. If the attacker has no detector, it is quite difﬁ-
cult to remove watermarks. However, even if the watermark cannot be removed, the
attacker also may use his own watermarking system. Thus people may feel there is
also attacker’s watermark in the same digital product. Therefore, it is not necessary
to directly verify the copyright with the embedded watermark. On the contrary, the
fact that an image is obtained from another image must be proved. This kind of sys-
tem can indirectly prove that this disputed image may be owned by the owner instead
of the attacker because the copyright owner has the original image. This veriﬁcation
manner is similar to the case that the copyright owner can take out the negative,
whereas the attacker can only counterfeit the negative of the disputed image. It is
impossible for the attacker to counterfeit the negative of the original image to
pass the examination.
1.2.6.5 Transaction Tracking
The watermark can be used to record one or several trades for a certain product copy.
For example, the watermark can record each receiver who has been legally sold and
distributed with a product copy. The product owner or producer can embed different
watermarks in different copies. If the product is misused (e.g., disclosed to the press
or illegally promulgated), the owner can ﬁnd the people who are responsible for it.
1.2.6.6 Content Authentication
Nowadays, it becomes much easier to tamper with digital products in an inconspic-
uous manner. Research on the message authentication problem is relatively mature
1.2 Overview of Information Hiding
25

in cryptography. Digital signature is the most popular encryption scheme. It is
essentially an encrypted message digest. If we compare the signature of a suspicious
message with the original signature and ﬁnd that they do not match, then we can
conclude that the message must have been changed. All these signatures are source
data and must be transmitted together with the product to be veriﬁed. Once the signa-
ture is lost, this product cannot be authenticated. It may be a good solution to embed
the signature in products with watermarking techniques. This kind of embedded
signature is called authentication mark. If a very small change can make the authen-
tication mark invalid, we call this kind of mark “fragile watermark.”
1.2.6.7 Annotation
Annotation refers to the additional data that are embedded in the digital works; such
information may be details about the work, notes, and so on. This hiding-based
annotation requires no additional bandwidth, and the annotation data are not easily
lost. This technique is often used in the maintenance of medical images; when the
patient’s medical staff ﬁnish shooting X-ray ﬁlms or photographic ﬁlms, we can
embed the patient’s name, doctor’s name, and medical history in the image data,
to avoid the case that we cannot ﬁnd the right medical records when the connection
between the patient and doctor is lost.
1.2.6.8 Copy Control
Most of the aforementioned watermarking techniques take effect only after the
illegal behavior has happened. For example, in the broadcast monitoring system,
only when the broadcaster does not broadcast the paid advertisement can we regard
the broadcaster dishonest, whereas in the transaction tracking system, only when the
opponent has distributed the illegal copy can we identify the opponent. It is obvious
that we had better design the system to prevent the behavior of illegal copying. In
copy control, people aim to prevent the protected content from being illegally
copied. The primary defense of illegal copying is encryption. After encrypting the
product with a special key, the product completely cannot be used by those without
this key. Then this key can be provided to legal users in a secure manner such that the
key is difﬁcult to be copied or redistributed. However, people usually hope that the
media data can be viewed, but cannot be copied by others. At this time, people can
embed watermarks in content and play it with the content. If each recording device is
installed with a watermark detector, the device can forbid copying when it detects
the watermark “copy forbidden.”
1.2.6.9 Device Control
In fact, copy control belongs to a larger application category called device control.
Device control means that the device can react when the watermark is detected. For
example, the “media bridge” system of Digimarc can embed watermark in printed
images such as magazines, advertisements, parcels, and bills. If this image is
captured by a digital camera again, the “media bridge” software and recognition
unit in the computer will open a link to related websites.
26
CHAPTER 1 Introduction

1.3 OVERVIEW OF IMAGE CODING AND COMPRESSION
TECHNIQUES
1.3.1 SOURCE CODING AND DATA COMPRESSION
In computer science and information theory, data compression or source coding is
the process of encoding information with fewer bits than an unencoded representa-
tion would use based on speciﬁc encoding schemes. As with any communication,
compressed data communication only works when both the sender and receiver of
the information understand the encoding scheme. Similarly, compressed data can
only be understood if the decoding method is known by the receiver. Compression
is useful because it helps reduce the consumption of expensive resources, such as the
hard disk space or the transmission bandwidth. On the downside, compressed data
must be decompressed to be used, and this extra processing may be detrimental to
some applications. The design of data compression schemes therefore involves
trade-offs among various factors, including the degree of compression, the amount
of distortion introduced, and the computational resources required.
Lossless compression algorithms usually exploit statistical redundancy in such a
way as to represent the sender’s data more concisely without error. Lossless
compression is possible because most real-world data possess statistical redundancy.
For example, in English text, the letter “e” is much more common than the letter “z,”
and the probability that the letter “q” will be followed by the letter “z” is very small.
Another kind of compression, called lossy data compression, is possible if some loss
of ﬁdelity is acceptable. Generally, a lossy data compression will be guided by
research on how people perceive the data in question. For example, the human
eye is more sensitive to subtle variations in luminance than it is to variations in color.
JPEG image compression works in part by “rounding off” some of this less-
important information. Lossy data compression provides a way to obtain the best ﬁ-
delity for a given amount of compression.
1.3.2 LOSSLESS IMAGE CODING TECHNIQUES
Image compression is the application of data compression on digital images. The
objective is to reduce redundancy of the image data to be able to store or transmit
data in an efﬁcient form. Image compression can be lossy or lossless. Lossless
compression is sometimes preferred for artiﬁcial images such as technical drawings,
icons, or comics. This is because lossy compression methods, especially when used
at low bit rates, introduce compression artifacts. Lossless compression methods may
also be preferred for high value content, such as medical imagery or image scans
made for archival purposes. Lossy methods are especially suitable for natural images
such as photographs in applications where minor loss of ﬁdelity is acceptable to
achieve a substantial reduction in bit rate. The lossy compression that produces
imperceptible differences can be called visually lossless. Typical methods for loss-
less image compression are as follows.
1.3 Overview of Image Coding and Compression Techniques
27

1.3.2.1 Run-Length Encoding
Run-length encoding (RLE) is used as a default method in PCX and as one of
possible method in BMP, TGA, and TIFF. RLE is a very simple form of data
compression in which runs of data are stored as a single data value and its count,
rather than as the original run. This is most useful for data that contain many
such runs, for example, relatively simple graphic images such as icons, line draw-
ings, and animations. It is not recommended for use with ﬁles that do not have
many runs as it could potentially double the ﬁle size.
1.3.2.2 Differential Pulse-Code Modulation and Predictive Coding
Differential pulse-code modulation (DPCM) was invented by C. Chapin Cutler at
Bell Labs in 1950, and his patent includes both methods. DPCM is a signal encoder
that uses the baseline of PCM but adds some functionality based on the prediction of
the samples of the signal. The input can be an analog signal or a digital signal. If the
input is a continuous-time analog signal, it needs to be sampled ﬁrst so that a
discrete-time signal is the input to the DPCM encoder. There are two options.
The ﬁrst one is to take the values of two consecutive samples; the difference between
the ﬁrst one and the next is calculated and the difference is further entropy coded.
The other one is, instead of taking a difference relative to a previous input sample,
the difference relative to the output of a local model of the decoder process is taken,
and in this option, the difference can be quantized, which allows a good way to
incorporate controlled loss in the encoding.
1.3.2.3 Entropy Encoding
In information theory, entropy encoding is a lossless data compression scheme that is
independent of the speciﬁc characteristics of the medium. One of the main types of
entropy coding creates and assigns a unique preﬁx code to each unique symbol that
occurs in the input. These entropy encoders then compress data by replacing each
ﬁxed-length input symbol by the corresponding variable-length preﬁx codeword.
The length of each codeword is approximately proportional to the negative logarithm
of the probability. Therefore, the most common symbols use the shortest codes. Ac-
cording to Shannon’s source coding theorem, the optimal code length for a symbol
is logbP, where b is the number of symbols used to make output codes and P is the
probability of the input symbol. Two most commonly used entropy encoding tech-
niques are Huffman coding and arithmetic coding. If the approximate entropy charac-
teristics of a data stream are known in advance, a simpler static code may be useful.
1.3.2.4 Adaptive Dictionary Algorithms
Adaptive dictionary algorithms are used in GIF and TIFF, and the typical one is the
LZW algorithm. It is a universal lossless data compression algorithm created by
Lempel, Ziv, and Welch. It was published by Welch in 1984 as an improved imple-
mentation of the LZ78 algorithm published by Lempel and Ziv in 1978. The algo-
rithm is designed to be fast to implement but is not usually optimal because it
performs only limited analysis of the data.
28
CHAPTER 1 Introduction

1.3.2.5 Deﬂation
Deﬂation is used in portable network graphics (PNG), MNG, and TIFF. It is a
lossless data compression algorithm that uses a combination of the LZ77 algorithm
and Huffman coding. It was originally deﬁned by Phil Katz for version 2 of his
PKZIP archiving tool, and was later speciﬁed in RFC 1951. Deﬂation is widely
thought to be free of any subsisting patents, and at a time before the patent on
LZW (which is used in the GIF ﬁle format) expired, this has led to its use in gzip
compressed ﬁles and PNG image ﬁles, in addition to the ZIP format for which
Katz originally designed it.
1.3.3 LOSSY IMAGE CODING TECHNIQUES
Typical methods for lossy image compression are as follows.
1.3.3.1 Color Space Reduction
The main idea of color space reduction is to reduce the color space to the most com-
mon colors in the image. The selected colors are speciﬁed in the color palette in the
header of the compressed image. Each pixel just references the index of a color in
the color palette. This method can be combined with dithering to avoid
posterization.
1.3.3.2 Chroma Subsampling
Chroma subsampling takes advantage of the fact that the eye perceives spatial
changes in brightness more sharply than those in color, by averaging or dropping
some of the chrominance information in the image. It is used in many video encod-
ing schemes, both analog and digital, and also in JPEG encoding. Because the hu-
man visual system is less sensitive to the position and motion of color than
luminance, bandwidth can be optimized by storing more luminance detail than color
detail. At normal viewing distances, there is no perceptible loss incurred by sam-
pling the color detail at a lower rate.
1.3.3.3 Transform Coding
Transform coding is the most commonly used method. Transform coding is a type of
data compression for “natural” data like audio signals or photographic images. The
transformation is typically lossy, resulting in a lower quality copy of the original
input. A Fourier-related transform such as DCT or the wavelet transform is applied,
followed by quantization and entropy coding. In transform coding, knowledge of the
application is used to choose information to be discarded, thereby lowering its band-
width. The remaining information can then be compressed via a variety of methods.
When the output is decoded, the result may not be identical to the original input,
but is expected to be close enough for the purpose of the application. The JPEG
format is an example of transform coding, one that examines small blocks of the
image and “averages out” the color using a DCT to form an image with far fewer
colors in total.
1.3 Overview of Image Coding and Compression Techniques
29

1.3.3.4 Fractal Compression
Fractal compression is a lossy image compression method using fractals to achieve
high compression ratios. The method is best suited for photographs of natural scenes
such as trees, mountains, ferns, and clouds. The fractal compression technique relies
on the fact that in certain images parts of the image resemble other parts of the same
image. Fractal algorithms convert these parts, or more precisely, geometric shapes
into mathematical data called “fractal codes,” which are used to re-create the
encoded image. Fractal compression differs from pixel-based compression schemes
such as JPEG, GIF, and MPEG since no pixels are saved. Once an image has been
converted into fractal code, its relationship to a speciﬁc resolution has been lost and
it becomes resolution independent. The image can be re-created to ﬁll any screen
size without the introduction of image artifacts or loss of sharpness that occurs in
pixel-based compression schemes. With fractal compression, encoding is extremely
computationally expensive because of the search used to ﬁnd the self-similarities.
However, decoding is quite fast. At common compression ratios, up to about 50:1, -
fractal compression provides similar results to DCT-based algorithms such as JPEG.
At high compression ratios, fractal compression may offer superior quality.
The following four subsections focus on two famous block-based lossy image
compression schemes and two famous image coding standards.
1.3.4 VECTOR QUANTIZATION
Vector quantization (VQ) is an attractive block-based encoding method for image
compression [2]. It can achieve a high compression ratio. In environments such as image
archival and one-to-many communications, the simplicity of the decoder makes VQ
very efﬁcient. In brief, VQ can be deﬁned as mapping from k-dimensional Euclidean
space Rk into a ﬁnite subset C ¼ {cij i ¼ 0, 1, ., M1}, which is generally called a
codebook, where ci is a codeword and M is the codebook size, as shown in Fig. 1.9.
VQ ﬁrst generates a representative codebook from a number of training vectors using,
for example, the well-known iterative clustering algorithm that is often referred to as the
generalized Lloyd algorithm. In VQ, as shown in Fig. 1.10, the image to be encoded is
ﬁrst decomposed into vectors and then sequentially encoded vector by vector. In the
encoding phase, each k-dimensional input vector x ¼ (x1, x2, ., xk) is compared
with the codewords in the codebook C ¼ {c0, c1, ., cM1} to ﬁnd the best matching
codeword ci ¼ (ci1, ci2, ., cik) satisfying the following condition:
dðx; ciÞ ¼
min
0jN1 dðx; cjÞ
(1.3)
That is, the distance between x and ci is the smallest, where d(x,cj) is the distor-
tion of representing the input vector x by the codeword cj, which is often measured
by the squared Euclidean distance, i.e.,
dðx; cjÞ ¼
X
k
l¼1
ðxl  cjlÞ2
(1.4)
30
CHAPTER 1 Introduction

And then the index i of the best matching codeword assigned to the input vector x
is transmitted over the channel to the decoder. The decoder has the same codebook
as the encoder. In the decoding phase, for each index i, the decoder merely performs
a simple table lookup operation to obtain ci and then uses ci to reconstruct the input
vector x. Compression is achieved by transmitting or storing the index of a codeword
rather than the codeword itself. The compression ratio is determined by the code-
book size and the dimension of the input vectors, and the overall distortion depends
on the codebook size and the selection of codewords.
1.3.5 BLOCK TRUNCATION CODING
Block truncation coding (BTC) [3] is a simple and efﬁcient lossy image compression
technique, which has the advantage of being easy to implement when compared with
other block-based compression techniques such as transform coding and VQ. Its
simplicity, performance, and channel error resisting capability make it attractive
in the real-time image transmission. Essentially, BTC is a 1-bit adaptive moment-
preserving quantizer that preserves certain statistical moments of small blocks of
the input image in the quantized output. The principle of the original BTC method
is to preserve the block mean and the block standard deviation (STD). Lema and
Mitchell present absolute moment BTC (AMBTC) [4] that preserves the higher
FIGURE 1.9
The Principle of VQ.
Source
Input
Vector
vector
Destination
Encoder
Nearest
Neighbor
Search
Index
Index
Generated by
LBG(GLA)
Codebook
Codebook
Decoder
Output
Channel
Algorithm [12]
Look up
Table
FIGURE 1.10
The Encoding and Decoding Processes of VQ.
1.3 Overview of Image Coding and Compression Techniques
31

and the lower means of a block. In the AMBTC method, the image is divided into
blocks of size m ¼ 4  4. The mean value x of the pixels in each block x is taken
as the one-bit quantizer threshold, i.e.,
x ¼ 1
m
X
m
i¼1
xi
(1.5)
The two output quantization level values are
xL ¼
1
m  q
X
xi<¼x
xi
(1.6)
xH ¼ 1
q
X
xi>x
xi
(1.7)
where xLand xH denote the lower and higher means, respectively and q stands for the
number of pixels whose values are larger than the mean value. Then the two-level
quantization is performed for the pixels in the block to form a bit plane so that “0”
is stored for the pixels with values not larger than the mean, and the rest of the pixels
are presented by “1.” The image is reconstructed at the decoding phase from the bit
plane by assigning the value xL to “0” and xH to “1.” Thus a compressed block appears
as a triple (xL, xH, B), where xL,xH, and B denote the lower mean, the higher mean, and
the bit plane, respectively. Fig. 1.11 shows an example of a compressed image block.
AMBTC is very fast, requires no extra memory, is easy to implement, and has
low computational demands. It preserves the quality of the reconstructed image
and retains the edges. However, in the AMBTC, the lower and higher means are
coded separately with 8 bits each, and the bit plane needs 16 bits, so the bit rate
of AMBTC is 8þ8þ16
16
¼ 2 bits/pixel.
1.3.6 JPEG
The JPEG standard is a collaboration among the International Telecommunication
Union (ITU), International Organization for Standardization (ISO), and International
Electrotechnical Commission (IEC). Its ofﬁcial names are “ISO/IEC 10918-1 Digital
compression and coding of continuous-tone still image,” and “ITU-T Recommenda-
tion T.81.” JPEG has the following modes of operations. (1) Lossless mode: The image
is encoded to guarantee exact recovery of every pixel of original image, even though
the compression ratio is lower than those of the lossy modes. (2) Sequential mode: It
compresses the image in a single left-to-right, top-to-bottom scan. (3) Progressive
mode: It compresses the image in multiple scans. When transmission time is long,
the image will display from indistinct to clear appearance. (4) Hierarchical mode:
The image is compressed at multiple resolutions so that the lower resolution of the
image can be accessed ﬁrst without decompressing the whole resolution of the image.
The last three DCT-based modes are lossy compressions because precision lim-
itation to compute DCT and the quantization process introduce distortion in the
32
CHAPTER 1 Introduction

reconstructed image. The lossless mode uses predictive method and does not have
quantization process. The hierarchical mode can use DCT-based coding or predic-
tive coding optionally. The most widely used mode in practice is called the baseline
JPEG system, which is based on sequential mode, DCT-based coding, and Huffman
coding for entropy encoding. Fig. 1.12 is the block diagram of baseline system.
The baseline encoding process can be brieﬂy described as follows:
Step 1: The representation of the colors in the image is converted from RGB to
YCbCr, consisting of one luma component (Y), representing brightness, and two
chroma components, (Cb and Cr), representing color. The advantage of con-
verting the image into luminance-chrominance color space is that the luminance
and chrominance components are very much decorrelated between each other.
This step is sometimes skipped. The transformation from RGB to YCbCr is
based on the following mathematical expression:
2
64
Y
Cb
Cr
3
75 ¼
2
64
0:299000
0:587000
0:114000
0:168736
0:331264
0:500002
0:500000
0:418688
0:081312
3
75
2
64
R
G
B
3
75 þ
2
64
0
128
128
3
75
(1.8)
9
2
2
2
3
9
11
3
3
4
14
11
12 15
12 15
Original
94
.7
=
x
Bit-plane
0
0
0
0
0
0
0
1
1
1
1
1
1
1
1
1
9
=
q
12
3
3
3
3
12
12
3
3
3
12
12
12 12
12 12
Reconstructed
3
=
Lx
12
=
H
x
FIGURE 1.11
AMBTC by the Triple (xL, xH, B).
Color 
components
(Y, Cb, or Cr)
8×8
FDCT
Quantizer
Quantization
Table
Zig-zag 
reordering
Difference
Encoding
Huffman
coding
Huffman
coding
JPEG
bit-stream
Huffman
Table
Huffman
Table
AC
DC
FIGURE 1.12
Baseline JPEG Encoder.
1.3 Overview of Image Coding and Compression Techniques
33

Step 2: The resolution of the chroma data is reduced, usually by a factor of 2 or 3.
This reﬂects the fact that the eye is less sensitive to ﬁne color details than to ﬁne
brightness details.
Step 3: The image is split into blocks of 8  8 pixels, and for each block, each of
the Y, CB, and CR data undergo DCT. A DCT is similar to a Fourier transform
in the sense that it produces a kind of spatial frequency spectrum. The forward
DCT block F(u,v) of the input block f(x,y) is deﬁned as
Fðu; vÞ ¼ 1
4 CðuÞCðvÞ
X
7
x¼0
X
7
y¼0
fðx; yÞcos
pð2x þ 1Þu
16

cos
pð2y þ 1Þv
16

for u ¼ 0; .; 7 and v ¼ 0; .; 7
where CðkÞ ¼
8
<
:
1

ﬃﬃﬃ
2
p
for k ¼ 0
1
otherwise
(1.9)
and the inverse DCT of F(u,v) is deﬁned as
fðx; yÞ ¼ 1
4
X
7
u¼0
X
7
v¼0
CðuÞCðvÞFðu; vÞcos
pð2x þ 1Þu
16

cos
pð2y þ 1Þv
16

for x ¼ 0; .; 7 and y ¼ 0; .; 7
(1.10)
Step 4: The amplitudes of the frequency components are quantized. Here, each
of the 64 DCT coefﬁcients are uniformly quantized. The 64 quantization
step-size parameters for uniform quantization of the 64 DCT coefﬁcients form
an 8  8 quantization matrix. The JPEG standard does not deﬁne any ﬁxed
quantization matrix. It is the prerogative of the user to select a quantization
matrix. Each element in the quantization matrix is an integer between 1 and 255.
Each DCT coefﬁcient F(u,v) is divided by the corresponding quantizer step-size
parameter Q(u,v) in the quantization matrix and rounded to the nearest
integer as
Fqðu; vÞ ¼ Round
Fðu; vÞ
Qðu; vÞ

(1.11)
Human vision is much more sensitive to small variations in color or brightness
over large areas than to the strength of high-frequency brightness variations.
Therefore, the magnitudes of the high-frequency components are stored with
lower accuracy than those of low-frequency components. The quality setting of
the encoder affects to what extent the resolution of each frequency component is
reduced. If an excessively low-quality setting is used, the high-frequency
components are discarded altogether.
Step 5: The resulting data for all 8  8 blocks are traversed zigzag, like in
Fig. 1.13 (the reason for this zigzag traversing is that we traverse the 8  8 DCT
34
CHAPTER 1 Introduction

coefﬁcients in the order of increasing the spatial frequencies) and further
compressed with a lossless algorithm, a variant of Huffman encoding.
The decoding process reverses these steps, except the quantization because it is
irreversible.
1.3.7 JPEG2000
JPEG 2000 is an image compression standard and coding system. It was created by
the Joint Photographic Experts Group committee in 2000 with the intention of super-
seding their original DCT-based JPEG standard created in 1992 with a newly
designed, wavelet-based method. The standardized ﬁlename extension is .jp2 for
ISO/IEC 15444-1econforming ﬁles and .jpx for the extended part-2 speciﬁcations,
published as ISO/IEC 15444-2. The aim of JPEG 2000 is not only improving
compression performance over JPEG but also adding or improving features such
as scalability and editability. The improvement of JPEG 2000 in compression per-
formance relative to the original JPEG standard is actually rather modest and should
not ordinarily be the primary consideration for evaluating the design. Very low and
very high compression rates are supported in JPEG 2000. The ability of the design to
handle a very large range of effective bit rates is one of the strengths of JPEG 2000,
e.g., to reduce the number of bits for a picture below a certain amount; the advisable
thing to do with the ﬁrst JPEG standard is to reduce the resolution of the input image
before encoding. This is unnecessary when using JPEG2000, because it already does
this automatically by its multiresolution decomposition structure. The following
subsections describe the algorithm of JPEG 2000.
1.3.7.1 Color Component Transformation
Similar to JPEG, initially the images have to be transformed from the RGB color
space to another color space, leading to three components that are handled sepa-
rately. For JPEG2000, there are two possible choices. (1) Irreversible color trans-
form uses the well-known YCbCr color space as given in JPEG. It is called
“irreversible” because it has to be implemented in ﬂoating or ﬁx-point and causes
round-off errors. (2) Reversible color transform (RCT) uses a modiﬁed YUV color
0
1
5
6
14
15
27
28
2
4
7
13
16
26
29
42
3
8
12
17
25
30
41
43
9
11
18
24
31
40
44
53
10
19
23
32
39
45
52
54
20
22
33
38
46
51
55
60
21
34
37
47
50
56
59
61
35
36
48
49
57
58
62
63
FIGURE 1.13
Zigzag Reordering Matrix.
1.3 Overview of Image Coding and Compression Techniques
35

space that does not introduce quantization errors, so it is fully reversible. Proper
implementation of the RCT requires that numbers are rounded by a special method
that cannot be expressed exactly in the matrix form. The transformation is:
Y ¼
R þ 2G þ B
4
	
; Cb ¼ B  G; Cr ¼ R  G
(1.12)
and
G ¼ Y 
Cb þ Cr
4
	
; R ¼ Cr þ G; B ¼ Cb þ G
(1.13)
The chrominance components can be, but do not necessarily have to be, down-
scaled in resolution; in fact, since the wavelet transform already separates images
into scales, downsampling is more effectively handled by dropping the ﬁnest
wavelet scale. This step is called multiple component transformation in the JPEG
2000 language since its usage is not restricted to the RGB color model.
1.3.7.2 Tiling
After color transformation, the image is split into the so-called tiles, rectangular re-
gions of the image that are transformed and encoded separately. Tiles can be any
size, and it is also possible to consider the whole image as one single tile. Once
the size is chosen, all the tiles will have the same size (except optionally those on
the right and bottom borders). Dividing the image into tiles is advantageous in
that the decoder will need less memory to decode the image and it can opt to decode
only selected tiles to achieve a partial decoding of the image. The disadvantage of
this approach is that the quality of the picture decreases due to a lower peak
signal-to-noise ratio (PSNR). Using many tiles can create a blocking effect similar
to the older JPEG standard.
1.3.7.3 Wavelet Transform
The tiles obtained are then wavelet transformed to an arbitrary depth, in contrast to
JPEG 1992, which uses an 8  8 block size DCT. JPEG 2000 uses two different
wavelet transforms. (1) Irreversible: the CDF 9/7 wavelet transform. It is said to
be “irreversible” because it introduces quantization noise that depends on the preci-
sion of the decoder. (2) Reversible: a rounded version of the biorthogonal CDF 5/3
wavelet transform. It uses only integer coefﬁcients, so the output does not require
rounding (quantization), and so it does not introduce any quantization noise. It is
used in lossless coding. The wavelet transforms are implemented by the lifting
scheme or by convolution.
1.3.7.4 Quantization
After wavelet transform, the coefﬁcients are scalar-quantized to reduce the number
of bits to represent them, at the expense of quality. The output is a set of integer
numbers that have to be encoded bit by bit. The parameter that can be changed to
set the ﬁnal quality is the quantization step: the greater the step, the greater is the
36
CHAPTER 1 Introduction

compression and the loss of quality. With a quantization step that equals 1, no quan-
tization is performed, which is used in lossless compression.
1.3.7.5 Coding
The result of the previous process is a collection of subbands that represent several
approximation scales. A subband is a set of coefﬁcientsdreal numbers that repre-
sent aspects of the image associated with a certain frequency range as well as a
spatial area of the image. The quantized subbands are split further into precincts,
rectangular regions in the wavelet domain. They are typically selected in a way
that the coefﬁcients within them across the subbands form approximately spatial
blocks in the image domain, although this is not a requirement. Precincts are split
further into code blocks. Code blocks are located in a single subband and have
equal sizesdexcept those located at the edges. The encoder has to encode the bits
of all quantized coefﬁcients of a code block, starting with the most signiﬁcant
bits and progressing to less signiﬁcant bits by a process called the Embedded
Block Coding with Optimal Truncation (EBCOT) scheme. In this encoding process,
each bit plane of the code block gets encoded in three so-called coding passes, ﬁrst
encoding bits (and signs) of insigniﬁcant coefﬁcients with signiﬁcant neighbors
(i.e., with 1 bit in higher bit planes), then reﬁnement bits of signiﬁcant coefﬁcients,
and ﬁnally coefﬁcients without signiﬁcant neighbors. The three passes are called sig-
niﬁcance propagation, magnitude reﬁnement, and Cleanup pass, respectively.
Clearly, in lossless mode all bit planes have to be encoded by the EBCOT, and no
bit planes can be dropped. The bits selected by these coding passes then get
encoded by a context-driven binary arithmetic coder, namely, the binary MQ coder.
The context of a coefﬁcient is formed by the state of its nine neighbors in the code
block.
The result is a bit-stream that is split into packets where a packet groups selected
passes of all code blocks from a precinct into one indivisible unit. Packets are the key
to quality scalability. Packets from all subbands are then collected in the so-called
layers. The way the packets are built up from the code-block coding passes, and
thus which packets a layer will contain, is not deﬁned by the JPEG 2000 standard,
but, in general, a codec will try to build layers in such a way that the image quality
will increase monotonically with each layer, and the image distortion will shrink
from layer to layer. Thus, layers deﬁne the progression by image quality within
the code stream. The problem is now to ﬁnd the optimal packet length for all
code blocks that minimizes the overall distortion in a way that the generated target
bit rate equals the demanded bit rate.
Although the standard does not deﬁne a procedure as to how to perform this form
of rate-distortion optimization, the general outline is given in one of its many appen-
dices: For each bit encoded by the EBCOT coder, the improvement in image quality,
deﬁned as the mean square error (MSE), gets measured; this can be implemented by
an easy table lookup algorithm. Furthermore, the length of the resulting code stream
gets measured. This forms for each code block a graph in the rate-distortion plane,
giving image quality over bit-stream length. The optimal selection for the truncation
1.3 Overview of Image Coding and Compression Techniques
37

points, and thus for the packet buildup points, is then given by deﬁning critical
slopes of these curves and picking all those coding passes whose curve in the
rate-distortion graph is steeper than the given critical slope. This method can be
seen as a special application of the method of Lagrange multiplier, which is used
for optimization problems under constraints. The Lagrange multiplier, typically
denoted by l, turns out to be the critical slope, the constraint is the demanded target
bit rate, and the value to optimize is the overall distortion.
Packets can be reordered almost arbitrarily in the JPEG 2000 bit-stream;
this gives the encoder as well as image servers a high degree of freedom.
Already encoded images can be sent over networks with arbitrary bit rates by
using a layer-progressive encoding order. On the other hand, color components
can be moved back in the bit-stream; lower resolutions (corresponding to low-
frequency subbands) could be sent ﬁrst for image previewing. Finally, spatial
browsing of large images is possible through appropriate tile and/or partition selec-
tion. All these operations do not require any reencoding but only byte-wise copy
operations.
1.4 OVERVIEW OF INFORMATION HIDING TECHNIQUES FOR
IMAGES
In this section, we provide an overview the information hiding techniques for im-
ages. That is, the cover object is a digital image, and after we embed the secret in-
formation into the cover image, we can get the stego image. According to different
purposes and applications, we can mainly classify information hiding techniques
into four categories, i.e., robust watermarking for copyright protection, fragile
watermarking for content authentication, ﬁngerprinting for transaction tracking,
and steganography for covert communication. For these four categories, we do
not care regarding the recoverability of the cover image after extracting the secret
information in the stego image. For some areas, it is required that the cover image
should be recovered after removing the secret information from the stego image,
thus we have a new category named lossless information hiding, and this category
is mainly used for content authentication for special images, such as military images,
law images, and medical images.
1.4.1 ROBUST IMAGE WATERMARKING
1.4.1.1 Background
Because of the fast and extensive growth of network technology, digital information
can be distributed with no quality loss, low cost, and nearly instantaneous delivery.
Protection of multimedia content has become an important issue because of the con-
sumers’ insufﬁcient cognizance of the ownership of intellectual property. Many
research groups around the world are working toward the highly ambitious techno-
logical goal of protecting the ownership of digital contents, which would
38
CHAPTER 1 Introduction

dramatically protect inventions represented in the digital form for being vulnerable
to illegal possession, duplication, and dissemination [5]. Digital watermarking [6] is
the process of embedding digital information called watermark into a multimedia
product, and then the embedded data can later be extracted or detected from the
watermarked product, for protecting digital content copyright and ensuring tamper
resistance, which is indiscernible and hard to remove by unauthorized persons.
Copyright protection appears to be one of the ﬁrst applications for which digital
watermarking was targeted. The metadata in this case contains information about
the copyright owner. It is imperceptibly embedded as a watermark in the cover
work to be protected. If users of digital content (music, images, and video) have
easy access to watermark detectors, they should be able to recognize and interpret
the embedded watermark and identify the copyright owner of the watermarked
content.
1.4.1.2 Deﬁnitions
Essentially, watermarking is deﬁned as the process of embedding the watermark
within the cover signal. A cover signal is a raw digital audio, image, or video signal
that will be used to contain a watermark. A watermark itself is loosely deﬁned as a
set of data, usually in binary form, that will be stored or transmitted through a cover
signal. The watermark may be as small as a single bit or as large as the number of
samples in the cover signal itself. It may be a copyright notice, a secret message, or
any other information. It is important to realize that a watermark is not transmitted in
addition to a digital signal, but rather as an integral part of the signal samples. The
value of watermarking comes from the fact that regular sideband data may be lost or
modiﬁed when the digital signal is converted between formats, but the samples of
the digital signal are (typically) unchanged [7]. Finally, a key may be necessary
to embed a watermark into a cover signal, and it may be needed to extract the water-
mark data afterward [6].
1.4.1.3 Image Watermarking System
Digital watermarking systems typically include two primary components: the
encoder and the decoder. To combine a watermark with a digital document, for
example, images, you need an image (CO), a watermark (W) that contains the water-
marking information, a security key (K), and an encoding algorithm (E) to create a
watermarked image (CW). The encoder takes the signature and the cover document
and generates the watermarked image, which is described as a function
CW ¼ EðCO; W; KÞ
(1.14)
In this case, secret or public keys and other parameters can be used to extend the
watermarking encoder. The watermark is considered to be robust if it is embedded in
such a way that the watermark can survive even if the watermarked data CW go
through severe distortions.
A watermark extractor or detector involves a two-step process. Watermark
retrieval is the ﬁrst step that applies some scrambling algorithms to extract a
1.4 Overview of Information Hiding Techniques for Images
39

sequence referred to as retrieved watermarks. Then, in the second step, the
embedded watermarks are detected and extracted from a suspected signal of contain-
ing watermarks. The second step normally requires the analysis and comparison of
the unreliable watermark with the original one, and the consequences could be
several kinds of conﬁdence assessment displaying the similarity between the
extracted watermark and the original one. The watermark detection procedure is
depicted as follows:
W0 ¼ DðCW; K; .Þ
(1.15)
where D(.) is the detection algorithm and C and W are the optional inputs for the
detection function. In this case, the decoder loads the watermarked, normal or cor-
rupted image CW and extracts the hidden signature W. Using nonblind and blind
watermarking techniques in Figs. 1.6 and 1.7, the decoder D loads an additional im-
age CO, which is often the original image, to extract the watermarking information
by correlation.
1.4.1.4 Characteristics
It is essential to deﬁne the criteria for evaluating a watermarking system. Generally,
there are ﬁve important issues that are usually considered in the most practical
application.
1. Imperceptibility
There are two main reasons why it is important to keep the imperceptibility of the
cover media after the encoding with watermark data. First, the presence or
absence of a watermark cannot be distinguished from the primary purpose of the
original media, if the watermarked media is so badly distorted that its value is
lost. In addition, suspicious perceptible artifacts may introduce a watermark,
perhaps its precise location being detected from the cover media. This infor-
mation may provide accesses for distorting, substituting, or removing the
watermark data maliciously.
2. Robustness
One of the most commonly measured properties is that watermark signals must
be reasonably resilient to various attacks and common signal processing op-
erations in digital watermarking systems. For the digital watermarking of im-
ages, the good watermarking method is likely to resist against noise addition;
ﬁltering processing; geometrical transformations such as scaling, translation,
and rotation; and also JPEG compression.
3. Capacity
Capacity is deﬁned using the largest quantity of information that inserted wa-
termarks are capable of hiding, and embedded watermarks can be extracted
credibly for the purposes of copyright safeguards. For images, the
capacity refers to the amount of embedded bits into pixels or patterns of the
images.
40
CHAPTER 1 Introduction

4. Security
All existing watermarking algorithms that are not secure cannot be used for
copyright protection. The watermarking algorithm is safe and robust, if the
attacker, using watermarking procedures and knowledge, does not know the key
used for watermarking digital content. In addition, the complexity of the
watermark process may be safety related. To improve the security of the al-
gorithm, it can enlarge the embedded space and increase the size of the keys
split into small pieces of cover image.
5. False-positive
There are two subtle distinctive ways to describe this probability. In the ﬁrst
explanation, the false-positive probability is the possibility that for a precondi-
tioned settled cover image and arbitrarily chosen watermarks, the detector will
state that a watermark exists in that image. In the second deﬁnition, the false-
positive possibility is that for randomly chosen images and a preconditioned
settled watermark, the detector will retrieve that watermark in an image.
Note that the conditions of imperceptibility, robustness, and capability are
conﬂicted and limited by each other. One may want to increase the watermarking
strength to increase the robustness, but this results in a more perceptible watermark.
On the other hand, under the condition of imperceptibility, a watermark would have
to be created with the maximum possible separation to avoid a situation where a
small corruption of the watermarked image would lead to erroneous watermark
detection. Similarly, one can increase the data payload by decreasing the number
of samples allocated to each hidden bit, but this is counterbalanced by a loss of
robustness. In other words, for any watermarking scheme, it is impossible to meet
these three requirements simultaneously. As a result, a good trade-off among these
requirements has to be achieved.
1.4.1.5 Overview of Techniques
Up to now, two traditionally used strategies, spatial domain [8] and transform
domain [9,10] techniques, have been developed for digital image watermarking.
The former category is designed to insert directly a watermark into the original im-
age by a factor, which would lead to fair-quality watermarked images. The latter
approach, for taking advantage of perceptual properties, is devised to embed a water-
mark into the frequency domain of the original images. These types of watermarking
schemes have good performances of robustness when compared with the most com-
mon signal processing manipulations such as JPEG compression, ﬁltering, and addi-
tion of noise [11]. Signal processing operators are applied to watermarked images
for removing the watermark or decreasing its energy so that the extracted watermark
is unrecognizable or insufﬁcient as the validate evidence. Unfortunately, the ineffec-
tiveness of existing traditional watermarking algorithms is described by the robust-
ness against unintentional or malicious geometric attacks [12]. Geometric attacks
induce synchronization errors between the original and the extracted watermark dur-
ing the detection process. In other words, the watermark still exists in the
1.4 Overview of Information Hiding Techniques for Images
41

watermarked image, but its positions have been changed. Therefore, although tradi-
tional watermarking systems require the creation of a framework of resilience to
geometrical modiﬁcations as well as creation and enforcement of synchronization
errors of watermarked data, correction of such frameworks is now possible. Besides
facilitating more efﬁcient copyrighted protection and robustness against desynchro-
nization, adaptation of geometrically invariant image features can potentially offer a
greater robust capacity to detect watermarks without synchronization errors, espe-
cially when applied to surviving local distortions such as random bending attacks.
Development of such a framework is an essential starting point for organizations
that wish to improve or replace currently existing watermarking algorithmebased
pixel frequency or other transform coefﬁcients for watermark embedding, and
develop a set of means to establish and maintain feature-based watermarking of geo-
metric distortion correction.
Watermarking algorithms robust to the geometrical distortions have been the
focus of research [13]. Several approaches to this problem include exhaustive
search, synchronization pattern/template, and invariant domain, and implicit syn-
chronization using image features are widely used. The exhaustive search tech-
nique [14] performs the process of watermark detection over a training sequence
containing each pilot geometrical inverse deformation. The watermark is recov-
ered by searching each hypothetical distortion parameter. The template-based
approach performs the watermark retrieval process by asserting the presence of
a watermark and estimating and compensating the severe geometric transformation
of the watermarked image for accomplishing resynchronization patterns [15].
Another solution consists in embedding the watermark in a geometrical invariant
subspace. In Ref. [16] using histogram speciﬁcation to hide a watermark invariant
to geometrical distortions is suggested. Feature-based synchronization watermark-
ing schemes follow the same basic process: detected feature points are localized at
the local maxima, whereas nonmaxima suppression eliminates pixels that are not
local maxima, and the ﬁnal set of features is determined by analysis of threshold.
Afterward, extracted feature points are applied to identify regions for watermark
insertion in the cover image. At the receiver side, the feature points are detectable
without synchronization error. The feature-based process can be invariant to local
geometrical deformations so that it is an encouraging approach to solve the robust-
ness against geometrical deformations in the watermarking scheme with blind
detection. Most of the proposed geometrical transform invariant algorithms are
actually only rotation-scaling-translation invariant. Also, the systematic analysis
of the watermarking algorithm performance under geometrical distortion has
begun to draw great attention. Most of these efforts conﬁne to theoretically
analyzing and quantifying the effect of the global afﬁne transform to the perfor-
mance of the watermarking algorithms. Local distortions are more and more
regarded as a necessary test scenario in benchmarking software. However, it is
difﬁcult to theoretically analyze its effect on watermark detection due to its
complexity.
42
CHAPTER 1 Introduction

1.4.2 FRAGILE IMAGE WATERMARKING
1.4.2.1 Background
Digital watermarking has been also proposed as a possible solution for data authen-
tication and tamper detection. The invisible authenticator, sensitive watermark,
is inserted using the visual redundancy of human visual system (HVS), and is altered
or destroyed when the cover image is modiﬁed by various linear or nonlinear trans-
formations. The changes of authentication watermark can be used to determine the
modiﬁcation of the marked image, even locate the tampered area. Because the water-
mark is embedded in the content of image, it can exert its efﬁciency in the whole
lifecycle.
1.4.2.2 Classiﬁcation
The authentication watermark can be classiﬁed into fragile watermark and semifrag-
ile watermark according to its fragility and sensitivity. The fragile watermark is very
sensitive and designed to detect every possible change in marked image; so it ﬁts to
verify the integrity of data and is viewed as an alternative veriﬁcation solution to a
standard digital signature scheme. However, in most multimedia applications, minor
data modiﬁcations are acceptable as long as the content is authentic, so the semifrag-
ile watermark is developed and widely used in content verifying. Semifragile water-
mark is robust for acceptable content-preserving manipulations (compression,
enhancement, etc.) whereas fragile watermark is robust for malicious distortions
such as feature adding or removal. Therefore it is suitable to verify the trustworthi-
ness of data.
1.4.2.3 Requirements
A watermarking-based authentication system can be considered as effective if it sat-
isﬁes the following requirements:
1. Invisibility: The embedded watermark is invisible. It is the basic requirement of
keeping the commercial quality of watermarked images. The watermarked
image must be perceptually identical to the original one under normal
observation.
2. Tampering detection: An authentication watermarking system should detect any
tampering in a watermarked image. This is the most fundamental property to
reliably test image’s authenticity.
3. Security: The embedded watermark cannot be forged or manipulated. In such
systems the marking key is private, the marking key should be difﬁcult to
deduce from the detection information, and the insertion of a mark by unau-
thorized parties should be difﬁcult.
4. Identiﬁcation of manipulated area: The authentication watermark should be
able to detect the location of altered areas and verify other areas as authentic.
The detector should also be able to estimate what kind of modiﬁcation had
occurred.
1.4 Overview of Information Hiding Techniques for Images
43

1.4.2.4 Watermarking-Based Authentication System
The process of digital watermarkingebased authentication is similar to any water-
marking system; it is composed of two parts: the embedding of authentication water-
mark and the extraction and veriﬁcation of authentication watermark.
1.4.2.4.1 Authentication Watermark Embedding
The general description of watermark embedding is:
c0 ¼ Eðc; a; w; KprÞ
(1.16)
where E(.) is the watermark embedding operator; c and c0 are image pixels or coef-
ﬁcients before and after watermark embedding; w is the embedded watermark sam-
ple, which is generated by the pseudorandom sequence generator or chaotic
sequence; and a is a tuning parameter determining the strength of the watermark
to ensure the invisibility. It can be a constant or a JND function proposed by HVS
[17]. Kpr is the private key that controls the generation of watermark sequence or
selects the location for embedding.
1.4.2.4.2 Authentication Watermark Extraction and Veriﬁcation
The general description of watermark extraction is:
w0 ¼ DðI1; KpuÞ
(1.17)
where D(.) is the watermark extraction operator, I1 is the questionable marked im-
age, and Kpu is the public key corresponding to Kpr [18]. If the Hamming distance
between the extracted and original watermarks is less than a predeﬁned threshold,
the modiﬁcation of marked image is acceptable and the image’s content is authentic,
or the marked image is unauthentic. The tampered area can be located by the differ-
ences between the extracted and original watermarks: the watermark differences of
the tampered image are most likely concentrated in a particular area, whereas the
differences caused by incidental manipulation such as compression are sparse and
widely spread over the entire image. So the tampered area can be determined.
1.4.2.5 Overview of Techniques
Many early authenticating watermarking systems embed the mark in the spatial
domain of an image. Some watermark schemes can easily detect random changes
to an image but fail to detect tampered area. An example is the fragile mark
embedded in the least signiﬁcant bit (LSB) plane of an image [19].
The later authentication watermark schemes are developed in transform do-
mains, such as DCT and wavelet domains. The properties of a transform can be
used to characterize how the image has been damaged, and the choice of watermark
embedding locations enables us to ﬂexibly adjust the sensitivity of the authentication
watermark. For example, if one is only interested in determining whether an image
has been tampered with, one could use a special type of signal that can be easily
destroyed by slight. modiﬁcations, e.g., an encrypted JPEG compressed image
ﬁle. On the other hand, if one is interested in determining which part of an image
44
CHAPTER 1 Introduction

has been altered, one should embed the watermark in each DCT block or wavelet
detail subband, to ﬁnd out which part has been modiﬁed. Some authentication water-
mark schemes are developed from the spread spectrum-based robust watermarking
algorithms [20,21]. The semifragile watermarks are attached on the middle-low
DCT coefﬁcients or the wavelet low-resolution detail subbands as additive white
Gaussian noise. At detector, the correlation value between the original watermark
sequence and the extracted watermark or marked image is used to determine the
authenticity of the test image. Because the inﬂuence on middle-low frequency coef-
ﬁcients of incidental manipulations such as compression is small, whereas that of
tampering is signiﬁcant, the algorithms can detect whether the images are tampered
or not, but cannot locate the tampered area.
Considering the authentication watermark is sensitive to noise, the quantization
technique is widely used in the authentication schemes. As a result, the effect of the
noise created by the cover image is concealed. Kundur [22,23] proposed a semifrag-
ile watermarking authentication scheme based on the wavelet transform. The image
is decomposed using the Haar wavelets. Both the embedding and extraction pro-
cesses of authentication watermark depend on the quantization process of secret
key selected wavelet transform coefﬁcients. The spatial frequency property of
wavelet transform helps to locate and characterize the tampered area. Yu et al.
[24] developed Kundur’s schemes, and modeled the probabilities of watermark er-
rors caused by malicious tampering and incidental distortion as Gaussian distribu-
tions with large and small variances, respectively, and computed the best number
of coefﬁcients needed to embed watermark at each scale such that the trade-off be-
tween robustness and fragility is optimized, so the scheme can detect maliciously
tampered areas while tolerating some incidental distortions.
1.4.3 IMAGE FINGERPRINTING
1.4.3.1 Background and Basic Concept
Basically, there are two concepts related to multimedia ﬁngerprinting. First, multi-
media ﬁngerprinting is referred to as robust hashing, where ﬁngerprints are percep-
tual features or short summaries of a multimedia object. This concept is an analogy
with cryptographic hash functions, which map arbitrary length data to a small and
ﬁxed number of bits. Second, multimedia ﬁngerprinting is regarded as the second
application of robust image watermarking technique. Here, a ﬁngerprint is a type
of watermark that identiﬁes the recipient of a digital object as well as its owner
(i.e., a “serial number” assigned by the vendor to a given purchaser). In this book,
we adopt the second concept. As in the applications of copyright protection, the
watermark for ﬁngerprinting is used to trace authorized users who violate the license
agreement and distribute the copyrighted material illegally. Thus, the information
embedded in the content is usually about the customer such as customer’s identiﬁ-
cation number. Additional data embedded by watermark in this application is used to
trace the originator or recipients of a particular copy of multimedia ﬁle. This is
intended to act as a deterrent to illegal redistribution by enabling the owner of the
1.4 Overview of Information Hiding Techniques for Images
45

data object to identify the original buyer of the redistributed copy. For example, wa-
termarks carrying different serial or ID numbers are embedded in different copies of
multimedia information before distributing them to a large number of recipients.
1.4.3.2 Differences Between Watermarking and Fingerprinting
Both watermarking and ﬁngerprinting are techniques of embedding hidden data in
the multimedia. In watermarking, the hidden data are called a watermark, and it
identiﬁes the owner of the multimedia. In ﬁngerprinting, the hidden data are called
a ﬁngerprint, and it identiﬁes the purchaser. Watermarking is a technique used to
retain the owner’s copyright, whereas ﬁngerprinting is used to trace the source of
illegal copies. Fingerprints must be embedded in the multimedia in an imperceptible
way. This can be done by embedding ﬁngerprints in the image’s pixels [25,26], in the
DCT domain [25,27e29] or in the wavelet transform domain [30]. An analysis of the
ﬁngerprint presenting in the illegal copy will allow to identify the pirate.
1.4.3.3 Requirements
The algorithms implemented in ﬁngerprinting applications need to be invisible and
must also be invulnerable to intentional attacks and signal processing modiﬁcations
such as lossy compression or ﬁltering. It should be assumed that pirates will perform
attacks intended to remove ﬁngerprints from their copies to distribute a pirate copy.
The greatest threat are organized groups of pirates. In these groups each pirate has
ﬁngerprinted copies, and they combine them to produce a pirated copy with a heavi-
ly damaged ﬁngerprint. Such attacks are called collusion attacks [31e34]. Finger-
printing should be resistant to the collusion attack, that is, it is impossible to
embed more than one ID number in the cover multimedia ﬁle; otherwise, a group
of users with the same image containing different ﬁngerprints would be able to
collude and validate the ﬁngerprint or create a copy without any ﬁngerprint.
Fingerprinting is an active tamper detection technique. In this case the authors of
the tampered copy (pirates) are trying to deny that they have distributed this copy. It
is known that the copy was tampered with, and the objective is to prove that the pi-
rates were in fact the originators of the tampered copy. A description of passive
tamper detection techniques can be found in [35]. In this case the authors of the
tampered copy are trying to make changes that look natural and/or want to claim
the copyrights. It is not known that the copy was tampered with, and the objective
is to verify the copy’s integrity and its authors’ copyrights. This is contrary to the
purpose of digital ﬁngerprinting, thus passive tamper detection techniques will not
be discussed in this chapter.
1.4.3.4 Overview of Techniques
There are many ﬁngerprinting methods in literatures, but to the best of our knowl-
edge, none of them are based on quaternion calculus. Therefore, this section focuses
on the most representative schemes. Fingerprinting methods can be divided into
three groups according to the place where the ﬁngerprints can be embedded.
46
CHAPTER 1 Introduction

Transmitter-side ﬁngerprinting: the ﬁngerprints are embedded on the transmitter
side, and then copies are sent to the users via unicast transmissions. The most impor-
tant method is Cox’s method [36], which inserts i.i.d. Gaussian sequences into the
perceptually most signiﬁcant components of the data. The watermark is robust
against signal processing and against the collusion of ﬁve pirates. The method based
on Cox’s formula is a watermarking scheme that is based on the extreme learning
machine [37], which reduces the time of watermark construction to milliseconds.
In-network ﬁngerprinting: the ﬁngerprints are embedded as the data travel
through the network. For example, in Ammar’s method [38] there are special devices
in the network that embed their own watermarks in the transmitted data. Therefore,
the user’s ﬁngerprint is a composition of embedded watermarks, and it depends on
the user’s location in the network.
Receiver-side ﬁngerprinting: each user has a unique decryption key that allows to
decrypt the data with some unique and imperceptible changes, i.e., ﬁngerprints. The
most important method is joint ﬁngerprinting and decryption [28], which encrypts
the low-frequency DCT coefﬁcients of the image by reversing their signs, and
each user’s key can decrypt only a portion of the coefﬁcients. Unfortunately, ﬁnger-
print embedding reduces image quality, and the method has very limited robustness
against collusion attacks. Another method is called Chameleon [39], which is a
stream cipher based on lookup tables. The decryption changes only the LSBs of
the image, so the ﬁngerprint does not reduce image quality. However, this method
can trace only up to four pirates in a collusion. The next example is the Fingercasting
scheme [40,41], which improves Chameleon by using a spread spectrum watermark-
ing scheme. The main drawback is the large size of the lookup table.
1.4.4 IMAGE STEGANOGRAPHY
1.4.4.1 Background and Basic Concept
Over the past two decades, the rapid development of the Internet requires conﬁden-
tial information that needs to be protected from unauthorized users. This is accom-
plished through data hiding. It is a method of hiding secret messages into a cover
medium so that an unintended observer will not be aware of the existence of the hid-
den messages. This is achieved by steganography. The term steganography is
retrieved from the Greek words “stegos” (means cover) and “graﬁa” (means
writing), deﬁning it as covered writing. Steganography is the science that involves
communicating secret data in an appropriate multimedia carrier, e.g., image, audio,
and video ﬁles. The similarity between steganography and cryptography is that both
are used to conceal information. However, the difference is that steganography does
not reveal any suspicion about the hidden information to the user. Therefore the at-
tackers will not try to decrypt information.
1.4.4.2 Image Steganography System
The graphical representation of a typical image steganography system is shown in
Fig. 1.14. Let C denote the cover carrier and C0 the stegoimage. Let K represent
1.4 Overview of Information Hiding Techniques for Images
47

an optional key (a seed used to encrypt the message or to generate a pseudorandom
noise, which can be set to{F} for simplicity) and let M be the message we want to
communicate. Em is an acronym for embedding and Ex for extraction. We can deﬁne
the processes of embedding and extraction as follows:
Em: C4K4M/C
(1.18)
ExðEmðc; k; mÞÞzm; for any c˛C; k˛K; m˛M
(1.19)
1.4.4.3 Overview of Techniques
This subsection attempts to give an overview of the most important steganographic
techniques in digital images. The most popular image formats on the Internet are
GIF, JPEG, and to a lesser extentdthe PNG. Most of the techniques developed
were set up to exploit the structures of these formats with some exceptions in the
literature that use the bitmap format (BMP) for its simple data structure. We can
classify the existing image steganography schemes into four categories, i.e., stega-
nography exploiting the image format, steganography in the image spatial domain,
steganography in the image frequency domain and adaptive steganography.
Steganography can be accomplished by simply appending the secret message in
the text ﬁle “Message.txt” into the JPEG image ﬁle “Cover.jpg” and produces the
stego image “Stego.jpg.” The message is packed and inserted after the EOF(End
of ﬁle) tag. When Stego.jpg is viewed using any photo editing application, anything
coming after the EOF tag will be ignored. However, when opened in Notepad, for
example, the message reveals itself after displaying some messy data. The
embedded message does not impair the image quality. Unfortunately, this simple
technique would not resist any kind of editing to the stego image nor any attacks
by steganalysis experts. Another naive implementation of steganography is to
append hidden data into the image’s extended ﬁle information, which is a standard
used by digital camera manufacturers to store information in the image ﬁle, which is
metadata information about the image and its source located at the header of the ﬁle.
This method is not a reliable one as it suffers from the same drawbacks as that of the
EOF method. Note that it is not always recommended to hide data directly without
encrypting as in this example.
FIGURE 1.14
The Graphical Representation of a Typical Image Steganography System.
48
CHAPTER 1 Introduction

In spatial domain methods, a steganographer modiﬁes the secret data and the
cover medium in the spatial domain, which involves encoding at the level of the
LSBs. Although this method is simpler, it has a larger impact compared to the other
three types of methods [42]. Potdar et al. [43] used a spatial domain technique in
producing a ﬁngerprinted secret sharing steganography for robustness against image
cropping attacks. Shirali-Shahreza and Shirali-Shahreza [44] exploited Arabic and
Persian alphabet punctuations to hide messages. Color paletteebased steganography
exploits the smooth ramp transition in colors as indicated in the color palette. Jung
and Yoo [45] downsampled an input image to half of its size, and then used a modi-
ﬁed interpolation method, termed the neighbor mean interpolation, to upsample the
result back to its original dimensions ready for embedding. Histogram-based data
hiding is another commonly used data hiding scheme, which is a lossless scheme
that will be discussed in Chapter 2 in detail.
The discovery of the LSB embedding mechanism is actually a big achievement.
Although it is perfect in not deceiving the HVS, its weak resistance to attacks left
researchers wondering where to apply it next until they successfully applied it within
the frequency domain. DCT is used extensively with video and image compression,
e.g., JPEG lossy compression. Most of the techniques use JPEG images as carriers to
embed their data. For example, Li and Wang [46] presented a steganographic
method that modiﬁes the QT and inserts the hidden bits in the middle frequency co-
efﬁcients. Some famous JPEG steganography schemes are JSteg, F5, and Outguess.
According to Raja et al.’s article [47], the FFT-based method introduces round-off
errors, thus it is not suitable for covert communication. However, Johnson and Jajo-
dia [48] thought differently and included it among the used transformations in steg-
anography, and McKeon [49] utilized the 2D discrete Fourier transform to generate
Fourier-based steganography in movies. As for steganography in the DWT, the
reader is directed to some examples in the literature. The DWT-based embedding
technique is still in its infancy. Abdelwahab and Hassan [50] proposed a data hiding
technique in the DWT domain. Both secret and cover images are decomposed using
DWT(ﬁrst level). Each of this is divided into disjoint 4  4 blocks. Blocks of the se-
cret image ﬁt into the cover blocks to determine the best match. Afterward, error
blocks are generated and embedded into coefﬁcients of the best matched blocks
in the HL subband of the cover image.
Adaptive steganography is a special case of the two former methods. It is
also known as “statistics-aware embedding” [51], “masking” [48], or “model-
based” [52]. This kind of method takes statistical global features of the image
before attempting to interact with its LSB/DCT coefﬁcients. The statistics will
dictate where to make the changes [53,54]. It is characterized by a random adaptive
selection of pixels depending on the cover image and the selection of pixels in
a block with large local STD. The latter is meant to avoid areas of uniform
color (smooth areas). This behavior makes adaptive steganography seek images
with existing or deliberately added noise and images that demonstrate color
complexity.
1.4 Overview of Information Hiding Techniques for Images
49

1.4.5 LOSSLESS INFORMATION HIDING IN IMAGES
1.4.5.1 Background and Basic Concepts
Through suitable watermarking techniques, protection of the data can be ensured
and one can know whether the received content has been tampered with or not.
However, watermarking can cause damage to the sensitive information present
in the cover work, and thus at the receiving end, the exact recovery of cover
works may not be possible. In some applications, even the slightest distortion
in the cover work is intolerable. For example, in the ﬁeld of medical imagery,
if a medical image is modiﬁed using conventional watermarking, the small
change may affect the interpretation signiﬁcantly and a physician may make a
wrong diagnosis. Similarly, in case of military application, changes due to
embedding of secret information can substantially alter the cover image and
therefore, the decision taken may cost considerably. Consequently, there is a
strong need to restore the cover work to its original form.
Lossless information hiding, also known as reversible information hiding or
reversible watermarking, mainly refers to the technique that has the following prop-
erty: after information embedding based on this technique, although it may damage
the visual quality of the cover image to some extent, if the watermarked image suf-
fers no change in the transmission process, then the legitimate users and authorities
can clear the distortion and restore the original image according to the embedded
information. That is to say, it allows full extraction of the embedded information
along with the complete restoration of the cover work. Reversible watermarking
can thus be considered as a special case of watermarking. Due to the unique nature
of this technique, reversible watermarking is gaining more attention in the past few
years because of its increasing applications in military communication, health care,
and law enforcement, that is, it can be applied to areas where there is a high require-
ment for the quality of the original image. For example, in the commercial area, it
can be applied to prevent the digital ticket from being tampered with; in the medical
area, it can be used to check if the digital medical images are modiﬁed during the
transmission; in the military area, it may be used to ensure the integrity of the ob-
tained digitized military satellite images; and in the court, it can be used to verify
the authenticity of the digital photographs that are used as evidences.
The principle of lossless information hiding is as follows: for the input digital
image signal I, we embed the information W into it by using some kind of nonde-
structive information embedding methods, obtaining another digital image signal
I0, and then, the signal I0 may be transmitted and communicated publicly. For the
authorized user, in the absence of the digital image signal I and the embedded infor-
mation W, from the obtained signal I0, we can obtain the embedded information W
through an appropriate extraction method and at the same time completely recover
the original digital image signal I. Fig. 1.15 shows the block diagram of a basic
reversible watermarking system.
In fact, there is no essential difference in principle between the lossless informa-
tion hiding and traditional information hiding techniques. However, for the lossless
50
CHAPTER 1 Introduction

information technique, because of the need to extract the embedded information and
then completely recover the original image without any loss, the requirements for
embedding information become more stringent:
1. We need to know the embedding order and embedding locations of the data.
2. We need to know each altered value of the original image data.
3. We need to avoid the embedded data information from exceeding the scope of
the original image data.
Referring to the general information hiding model, the lossless information hid-
ing model is given in Fig. 1.16, which includes:
1. The cover media: It is the carrier used to hide the secret information. Since this
book focuses on lossless information hiding methods described on digital
images, thus it is speciﬁcally referred to as the cover image in our book.
2. The secret information: It is one of the inputs for the embedding process, which is
referred to as the object to be embedded into the original cover media. It can be
called a watermark that is a sequence consisting of a number of randomly
generated “0”s and “1”s by, where each bit is called watermark bit.
3. The embedding process: Based on the key, this process hides the secret infor-
mation into the cover media through the lossless embedding model.
4. The stego media: It is the output of the embedding process embedded in the
output process, referring to the obtained media after embedding secret infor-
mation. For image media, we often call it the watermarked image.
5. The extraction process: Based on the key, this process extracts the hidden in-
formation from the stego media or possible attacked stego media and/or re-
covers the cover media. In this process, the required auxiliary information is
generally referred to as side information.
6. The recovered media: It is one of the outputs of the extraction process, i.e., the
recovered cover media after extracting the secret information from the stego
media. For images, it is speciﬁcally referred to as the recovered image.
FIGURE 1.15
Basic Reversible Image Watermarking Scheme.
1.4 Overview of Information Hiding Techniques for Images
51

7. The key: It is the additional secret information that may be required during the
information hiding process. In general, we can generate the key from the
important parameters or side information of the embedding process.
8. The covert attack: It is located in the transmission channel of stego media. Taking
into account the special nature of lossless information hiding, we only study the
effects of nonmalicious operations on the watermarked image, e.g., JPEG lossy
compression and additive Gaussian noises. However, in the lossless case, it is
assumed that there is no inﬂuence of covert attacks.
1.4.5.2 Classiﬁcations of Schemes
In past, reviews of different reversible watermarking techniques were carried out
[55e57]. Feng et al. [56] discussed key requirements of the watermark and classiﬁed
reversible watermarking schemes into three categories: data compression, difference
expansion (DE), and histogram shifting. A single reversible watermarking scheme is
discussed in each of these categories. Some major challenges faced by the re-
searchers in this ﬁeld are also outlined. Pan et al. [57] categorized various reversible
watermarking approaches into two classes, additive and substitution, based on the
embedding method. Comparison is carried out through empirical analysis of
selected reversible watermarking approaches on medical images. Caldelli et al.
[55] provided another review that classiﬁes reversible watermarking techniques on
the basis of watermarking properties, i.e., into robust, fragile, and semifragile. Cal-
delli et al. [55] also performed classiﬁcation according to the watermark embedding
domain, i.e., spatial or frequency domain. The aforementioned review articles were
quite valuable; however, they cover very limited area and discuss only few of the
works in the ﬁeld of reversible watermarking. The prospective reversible watermark-
ing approaches based on the concept of error expansion have been reported in large
numbers, and they mostly outperform other types of reversible watermarking ap-
proaches. Most of these new and efﬁcient prediction errorebased reversible water-
marking techniques are not covered by the aforementioned reviews. Additionally,
there has been a rapid increase in the applications of reversible watermarking
Secret 
Information
Key
Embedding 
Process
Key Generator
Key
Side 
Information
Recovered Media
Covert Attack
Stego Media
Stego Media
Extraction
Process
Secret 
Information
Receiver
Cover Media
Sender
FIGURE 1.16
The Lossless Information Hiding Model.
52
CHAPTER 1 Introduction

techniques. Consequently, a review of newly emerging reversible watermarking
techniques is highly desirable.
1.4.5.3 Overview of Techniques
One of the ﬁrst reversible watermarking method was introduced by Honsinger et al.
[58]. They utilized modulo addition 256 to achieve reversibility in their watermark-
ing technique. Macq [59] developed a reversible watermarking approach by modi-
fying the patchwork algorithm and using modulo addition 256. Although,
Honsinger et al. [58] and Macq [59] proposed reversible techniques, the impercept-
ibility of their approaches is not impressive. The watermarked images resulting from
Honsinger et al. [58] and Macq’s [59] techniques suffer from salt-and-pepper noises
because of the use of modulo addition 256. A reversible watermarking technique
without using modulo addition 256 was then introduced by Fridrich et al. [60]. Fri-
drich et al. [60] proposed the concept of compressing the LSB plane of cover image
to make space for the watermark to be embedded. However, the embedding capacity
of this approach was limited. To improve the embedding capacity and imperceptibil-
ity of the watermarked image, Fridrich et al. [61] then proposed another approach.
Evolution of reversible watermarking started around 2000, and it is now quite difﬁ-
cult to keep up with the development that is going on in this ﬁeld. Many reversible
watermarking algorithms have been developed in the 2000s. A number of new tech-
niques, extensions, or improved versions of the earlier techniques have been pro-
posed afterwards. The improvement is primarily based upon making a good
imperceptibility versus capacity trade-off. Zheng et al. reported a comprehensive
survey on robust image watermarking algorithms [62]. Guo [63] and Guo et al.
[64] reported reversible watermarking techniques for the halftone images. We
reviewed newly emerging reversible watermarking techniques and categorized
them into four groups, i.e., compression based, histogram modiﬁcation based, quan-
tization based, and expansion based.
To recover the original image, we need to store the information essential for re-
covery of the original image along with the watermark. Thus, in case of reversible
watermarking, additional data need to be embedded and consequently, we need
more space compared with conventional watermarking for data embedding. A sim-
ple approach may be compressing a part of cover image for embedding data.
Several reversible watermarking schemes are reported using this approach. In
2004, Yang et al. [65] proposed a high-capacity companding technique for image
watermarking in the DCT domain. Celik et al. [66] in 2005 proposed a well-
known compression-based approach. The intensity values of pixels in the cover im-
age are ﬁrst quantized by applying L-level scalar quantization. Then, the remainders
obtained are compressed using a context-based adaptive lossless image codec, and
watermark information is concatenated with it. Xuan et al. [67] developed a revers-
ible watermarking technique using companding function on integer wavelet coefﬁ-
cients. Arsalan et al. [68] utilized Xuan et al. [67] companding function in
combination with genetic algorithm to develop a high-capacity reversible water-
marking technique.
1.4 Overview of Information Hiding Techniques for Images
53

Many researchers have carried out research in the ﬁeld of histogram
modiﬁcationebased reversible watermarking. Initially, Vleeschouwer et al. [69] pre-
sented circular interpretationebased reversible watermarking. In 2006, Ni et al. [70]
developed a novel reversible watermarking approach based on image histogram
modiﬁcation. Before embedding, a pair of peak and zero points is selected from
the histogram of the cover image. Only pixels with values between peak and zero
points undergo modiﬁcation during the embedding process. To increase the embed-
ding capacity of histogram-based reversible watermarking techniques, different al-
gorithms
are
reported.
Lin
et
al.
[71]
presented
a
multilevel
reversible
watermarking approach that utilizes the histogram of difference image for data
embedding. In another work, Ni et al. [72] proposed an approach that does not suffer
from salt-and-pepper noise. Gao et al. [73] then highlighted the shortcomings of Ni
et al.’s approach [72] and improved it. Tsai et al. [74] proposed a subtly different
approach from Lin et al. [71]. The difference between a basic pixel and every other
pixel in the block is used rather than the difference of adjacent pixels. Kim et al. [75]
proposed a novel method that exploits the spatial correlation between subsampled
images. Kamran et al. [76] reported a novel approach that utilizes the concept of
downsampling for performance improvement.
Quantization-based watermarking techniques are, in general, robust. However,
the reversible quantizationebased watermarking approaches are mostly fragile in
nature. In 2007, Cheung et al. proposed a Sequential Quantization Strategy (SQS)
for data embedding [77]. SQS makes the modulation of a pixel value dependent
on the previous pixels. A reversible data embedding method is used with SQS to
make it more suitable for the authentication purposes. Saberian et al. [78] presented
a Weighted Quantization Method (WQM) approach, which can be applied in spatial
as well as transform domains. In contrast to other approaches, the distortion caused
by this scheme is not payload dependent. It is shown that WQM gives high embed-
ding capacity, when applied to Point-to-Point Graph transform. Lee et al. [79] pro-
posed a VQ-based reversible watermarking technique using histogram modiﬁcation
to achieve high embedding capacity. The conventional quantization index modula-
tion (QIM)ebased watermarking techniques are not reversible in general, because of
the irreversible distortions caused in the watermarked image due to the quantization
process. However, in 2011, Ko et al. [80] developed a nested QIM watermarking al-
gorithm for medical image watermarking systems, which ensures the recovery of the
cover image. Ko et al. [81] also presented a reversible watermarking technique for
biomedical image using QIM and fractional DCT. This technique outperforms the
nested QIM [80].
In 2003, Tian [82] presented a novel approach, named DE. It gave a new direc-
tion to the reversible watermarking methods. It achieves high embedding capacity
and low computational complexity compared with the preceding techniques. Several
improved DE-based watermarking schemes were then proposed over the time. There
are mainly three types of expansion-based reversible watermarking techniques:
contrast mappingebased reversible watermarking, correlation-based reversible
watermarking and interpolationebased reversible watermarking. Their typical
54
CHAPTER 1 Introduction

schemes are described as follows. In 2007, Coltuc et al. [83] presented their work on
contrast mappingebased reversible watermarking. In their technique, they per-
formed transformation of pair of pixels. The transformation is invertible for some
pair of pixels, even if the LSBs of transformed pairs are lost. In 2004, Thodi et al.
[84] proposed a new reversible watermarking scheme based on the correlation
among the neighboring pixels for grayscale images. This correlation is modeled us-
ing a predictor, which computes the current pixel intensity. Luo et al. [85] reported a
reversible watermarking method using interpolation technique. The watermark bits
are ﬁrst embedded in the nonsample pixels until no nonsample pixel is left. Then, the
rest of the watermark bits are inserted into the sample pixels, which are interpolated
using neighboring watermarked pixels.
In medical diagnostics, remote sensing and forensic evidence, and other sensitive
applications, as an effective means to protect the copyright of digital media, lossless
information hiding has received many researchers’ attention. However, conventional
lossless information hiding methods do not consider the covert attack on the stego
media during the transmission process, making it difﬁcult to meet the needs of prac-
tical applications. In other words, even if the stego media suffers very slight degra-
dation, the receiver cannot correctly extract the secret information. To solve this
problem, robust lossless information hiding has been put forward and has attracted
many researchers’ interests [86e89].
1.4.5.4 Performance Evaluation Criteria for Lossless Data
Hiding Schemes
For particular applications, the performance metrics for a lossless information
hiding scheme should reﬂect if it is really suitable for this particular application.
However, for algorithm research, the general performance of some algorithms is
still a topic of researchers’ concern, since the performance of the algorithm can
reﬂect its adaptation range and accuracy, and also the application potential of an
algorithm. For fragile reversible watermarking algorithms, the performance is
mainly reﬂected in the following aspects:
1. The ratio of data capacity to distortion
Similar to general nonreversible watermarking schemes, the watermark
embedding process will deﬁnitely cause a change in the carrier medium; we
call this difference between the stego media and the cover media as
distortion. We always hope that a watermark embedding algorithm can have
as much data capacity as possible under certain distortion. Reversible
watermarking algorithms also take this as an important performance
measure of the algorithm, i.e., the ratio of data capacity to distortion. Also,
because there is no robustness requirement for fragile reversible
watermarking schemes, the ratio of data capacity to distortion becomes the
main criterion to evaluate the performance of a reversible watermarking
scheme, and it has also become a focus of reversible watermarking algorithms.
1.4 Overview of Information Hiding Techniques for Images
55

Strictly speaking, the data capacity can be speciﬁc as the amount of watermark
data that can be completely extracted after they are embedded into a cover
media based on a certain reversible watermarking algorithm; we usually use the
embedded bits per sample to represent it. For images, it is just denoted as the
number of embedded bits per pixel (BPP). On the other hand, the distortion
calculation often adopts the Euclidean distanceebased MSE, or directly the
MSE-based PSNR. Let the size of the cover image be L1  L2; xij is the pixel
value at the position (i,j) (0  i  L11, 0  j  L21), wherein PSNR and
MSE are deﬁned as follows:
MSE ¼
PL11
i¼0
PL21
j¼0 ðxij  xwijÞ2
L1  L2
(1.20)
PSNR ¼ 10$Log10
L1  L1
MSE
(1.21)
In reversible watermarking, although the original cover media can be fully
restored, according to the general requirements for watermarking algorithm,
the bigger the PSNR and data capacity (Capacity) the better. In the
simulation for a reversible information hiding scheme, we often use the
PSNReBITRATE curve to represent the ratio of data capacity to distortion as
shown in Fig. 1.17.
2. Performance stability
Performance stability has two meanings: one refers to the performance stability
of reversible watermarking algorithms with regard to different statistical
properties of the image, whereas the other refers to the performance stability of
the reversible watermarking algorithm with regard to different ranges of in-
dicators. For a good algorithm, its performance should cover a wider range of
BPP on the PSNReBITRATE curve, and the change of PSNR values in this
range should be as smooth as possible.
3. Performance ﬁneness
Performance ﬁneness refers to the density of the sampling points that can be
achieved on the performance curve. In an algorithm whose performance curve is
actually connected or ﬁtted by a plurality of performance points, if the density
of performance points is high, then the ﬁneness is high. For users, the high
ﬁneness means the adjustability or controllability of the algorithm performance
is high.
4. Computational complexity
The complexity of an algorithm consists of two main aspects: one is the time
complexity of the algorithm, represented by the required time for reversible
watermark embedding and extraction/recovery processes; the other is the spatial
complexity of the algorithm, represented by the required extra space for
reversible watermark embedding and extraction processes. A good algorithm
56
CHAPTER 1 Introduction

should have low time complexity and less additional information utilized, that
too without taking up extra storage space.
5. The security of the algorithm
Algorithm security, on the one hand, refers to the fact that the watermark content
and the storage locations of the additional information are kept secret for the
reversible watermarking algorithm, which can be achieved by using encryption;
on the other hand, it refers to the fact that the watermarking algorithm itself is
imperceptible (undetectability), that is, the algorithm satisﬁes the requirements
of steganography.
1.5 APPLICATIONS OF LOSSLESS INFORMATION HIDING IN
IMAGES
Lossless information hiding in images is gaining more attention in the past few years
because of its increasing applications in military communication, health care, and
law enforcement. Following are some typical application ﬁelds.
1.5.1 LOSSLESS HIDING AUTHENTICATION
People can use lossless reversible watermarking algorithms to achieve the lossless
watermark authentication, supporting completely accurate authentication for the
cover media, which is actually the original intention of reversible watermarking
schemes. A more comprehensive and detailed discussion of this aspect can be found
in Fridrich’s article [60], and we will not repeat them here.
From the idea of the reversible watermarking schemes that embed signature in-
formation in cover media, we can know that reversible watermarking algorithms
should be able to be used to embe1d other information and fully realize exact
Data Capacity(BPP)
Better performance curve
Worse performance curve
PSNR(dB)
FIGURE 1.17
PSNReBPP Reversible Watermarking Performance Curve.
1.5 Applications of Lossless Information Hiding in Images
57

information authentication. For example, when we perform lossless watermarking
authentication on an original military map, in addition to the signature information
of the original image, we may also want to hide some other information in the cover
media, such as the generation time, the generation place, the generation manner, cre-
ator’s information, distributor’s information, the expected handling manner, the
dissemination manner, and the destruction manner. Another possible application
is to view the cover media as a covert communication channel; then you can write
secret messages in the cover media in a steganographic manner. In these cases, you
need to not only perform authentication on the cover media but also perform security
authentication of originality, authenticity, and integrity on these metadata or secret
messages. Sometimes, we even only need to perform authentication on metadata and
secret messages and adopt the cover media as covert communication tools. We call
this type of authentication that is mainly performed on the embedded information is
lossless hiding authentication.
For the applications that need to perform authentication both on the cover media
X and the embedded metadata W, we can use reversible watermarking algorithm to
embed W reversibly in and generate a signature S based on the resulting water-
marked cover media XW, and then adopt a reversible watermarking algorithm to
embed this signature S reversibly in the watermarked media XW, resulting in the ﬁnal
media XWS embedded with the signature S and metadata W. This authentication
scheme can be shown in Fig. 1.18. Obviously, the object that is generated with a
signature S is the media XW that has been already embedded with metadata, thus
we can simultaneously perform authentication on the cover media X and the
embedded metadata W. Thus, any change in the embedded result XW will cause
the inconformity between the recalculated signature from XW and the signature
extracted from XWS. In addition, since the algorithm that embeds W in X is a revers-
ible watermarking algorithm, X and W can be fully restored.
For the applications that only need to perform authentication on the embedded
secret message M, its authentication scheme is similar to the authentication scheme
mentioned earlier that is performed on both the cover media X and metadata W,
which can be shown in Fig. 1.19. Note that because we only need to perform authen-
tication on the secret message M, the method used to embed W in X does not need to
be reversible, but it is should be guaranteed that it can correctly extract the secret
message M in the absence of external attack or change. However, according to
different applications, we may require that the embedding method for W should
satisfy steganography requirements to some extent.
In the two applications shown in Figs. 1.18 and 1.19, since the authentication
methods performed on the media embedded with the secret message and the media
embedded with the metadata (XWand XM) are both based on reversible watermarking
algorithms, both them can be completely recovered. Such lossless hiding
authenticationebased applications extend the lossless watermark authenticatione
based applications to the authentication applications based on embedding any
data, which requires higher data capacity to meet different uses of data embedding
and authentication.
58
CHAPTER 1 Introduction

1.5.2 FIDELITY CONTROL FOR COVER MEDIA
In some applications, people are more concerned about the quality of the cover me-
dia itself. In this type of application, the common requirements are that the water-
marking algorithm and the watermark embedding process do not introduce
permanent distortion to the cover media. A special class of application that we
are most likely to think of is that there is a special accuracy requirement for special
media, such as medical images, military images, remote sensing images, legal evi-
dence images, secret documents, precious works of art, and science experimental
images. For this type of application, even only 1 bit permanent loss in the original
cover media is not allowed, so the data embedding algorithms must be reversible.
Since reversible watermark embedding algorithms can remove the embedding
distortion completely, they can referred to as the data embedding style with 100%
ﬁdelity.
In some other occasions, people are not demanding a 100% ﬁdelity for the cover
media; they just expect the media to possess more ﬁdelity to improve the perceptual
effect of the cover media. This gives us an inspiration: we can use the fact that water-
mark embedding will cause ﬁdelity reduction to achieve the grading control of the
Cover 
Media X
00101101011101
Reversible 
embedder Em
Signature 
computation
01001
0
1101
Signature S
Metadata W
010..
Media embedded 
with metadata XW
Reversible 
embedder Em
010..
Media embedded 
with metadata and 
signature XWS
FIGURE 1.18
Embedding of Lossless Hiding Authentication for Host Media and Metadata.
Cover Media X
@#$%&
Embedder E
Signature 
computation
01001
01101
Signature S
Secret Message M
#$%.
..
Media embedded 
with secret 
message XM
Reversible 
embedder Em
#$%.
.
Media embedded with 
secret message
and 
signature XMS
FIGURE 1.19
Embedding of Lossless Hiding Authentication for Secret Messages.
1.5 Applications of Lossless Information Hiding in Images
59

media ﬁdelity. However, because the ﬁdelity reduction caused by the watermark
cannot be restored, ﬁdelity control can only be performed in one way, that is, quality
degradation; if we utilize the reversibility of reversible watermarks, we can fulﬁll the
bidirectional control of the media ﬁdelity, i.e., embed more watermark bits to
decrease ﬁdelity, or remove part of the watermark to restore some of the media to
improve the visual quality of the media. One potential application is the pricing
model of television programs based on their grading visual effects, as shown in
Fig. 1.20: The TV station T sends the same reversibly watermarked TV program
P to all users Ui; here P suffers the most serious distortion with the worst visual ef-
fects due to reversible watermarking, but it can be watched by any TV user Ui
(i ¼ 1,2,3) (including the TV users who do not pay). At the same time, the user
U1 possesses a key K1 to purchase programs from the TV station; through the key
K1, part of the watermark can be removed from the TV program P, and thus the pro-
gram P is partially restored to obtain a program P1 with higher visual ﬁdelity. How-
ever, the user U2 may pay with a higher price, and thus more watermark is removed
through the key K2 to obtain a program P2 with much higher visual ﬁdelity, and the
user U3 does not purchase any key, so he can only watch the program P with the
lowest visual ﬁdelity. Obviously, compared with the traditional TV encryption tech-
nology, the reversible watermarking technique has the advantage of ﬁne-grading
control of media ﬁdelity, and we can freely set the minimum ﬁdelity effect, so
that free users can also enjoy the program in low visual quality, to attract the audi-
ence’s attention. However, the encrypted TV programs cannot be completely
watched by free users, which is an apt situation to cause loss of potential users.
As can be seen, the substance of the ﬁdelity control for the cover media is to use
the reversibility of the reversible watermarking technology to adjust the media ﬁdel-
ity in two opposite ways, to meet different application needs with different multi-
media perceptual quality.
1.5.3 STATUS RECOVERY FOR COVER MEDIA
The reversibility of reversible watermarking systems means the recoverability of the
signal status. In some applications, it is desirable to record the steps and parameters
of signal processing for signal recovery in case of need. Here, the signal recovery is
often not due to the accuracy requirements of the cover media, but due to the require-
ments of further processing of cover media, so such applications may be referred to
as status protection during signal processing.
The most common scenario is the occasion that requires performing multiple
watermark embedding operations on the same image; if the embedding method is
not reversible, then the accumulated distortion caused by embedding every time
may seriously affect the visual quality of the image. For example, during the artiﬁ-
cial image generation process, for most of the time, the image is in the state to be
modiﬁed and edited. In this case, it is clearly inappropriate if we embed nonrevers-
ible watermarks to protect these process data, because data embedding will bring
permanent distortion to the cover data, which will affect the accuracy of subsequent
60
CHAPTER 1 Introduction

editing on the image. Furthermore, with the increase in the amount of modiﬁcation
and storage times, the number of embedded watermarks also increases, thus the vi-
sual quality of the image is likely damaged due to the accumulated embedding
distortion. If we use reversible watermarking schemes to embed data, we can fully
restore the status after last editing; thus we can completely avoid the permanent
distortion during the embedding process, and we will also be able to avoid affecting
the visual quality of the image due to the follow-up processes.
The transfers and transactions of usage rights of digital media products can also
adopt the reversible watermarking scheme to restore the original state. For example,
a user Awants to transfer a copy of the CD to another user B, but because the content
data of CD has been embedded with the user’s identity, the corresponding access
permissions, and the copy control watermark, direct transfer of the CD from A to
B will be viewed as illegal by B’s playback device. To proceed with this legal trans-
action smoothly, the watermark embedding techniques used must be reversible, that
is, A allows a legitimate and authorized dealer to erase the identity information in
A’s CD according to A’s key, and then reset B’s key and embed the identity and li-
cense declarations of B in the CD according to B’s key, thus B will be able to legally
play this CD. As can be seen, in the case involving the changes of former informa-
tion embedded in the digital products, reversible watermarking techniques can be
conveniently used to achieve the recovery of the original state of the cover media,
and can then successfully update the key information and the watermark
information.
Another possible application of status recovery is to eliminate the traces of image
steganography. After performing data embedding using watermarks, some charac-
teristics introduced by watermarking will be left in different parts of the spatial or
Key K1 
Key K2 
P
P
P
Fidelity P1
Fidelity P2
Fidelity P
User U1 
User U2 
User U3 
TV station T
FIGURE 1.20
Visual Quality Scalable Reﬁnement of TV Program.
1.5 Applications of Lossless Information Hiding in Images
61

transformed image. After using watermarks, these features are often difﬁcult to be
removed, so that the image obtained after watermark extraction is difﬁcult to be
recovered to the “clean” state in which no watermark is embedded, thus the traces
of these watermarking processes can easily be detected by steganalysis. In some
cases, permanent retention of such traces will prejudice the security of the whole
watermarking system. The reversible watermarking scheme does not have this prob-
lem, since it requires complete recovery of the original state of the image, which
purges the traces of embedding data completely.
Another application is to restore the image modiﬁcation operations. In some im-
age processing applications, the process is completed by a few simple adjustments.
For example, for gray transform of the image (Log transform, gamma correction,
contrast stretching, etc.), histogram modiﬁcation (histogram equalization, histogram
speciﬁcation, brightness adjustment, etc.), and image enhancement, the goals can be
achieved by adjusting a few algorithm parameters. If the image processing operator
worries about that the users are not satisﬁed with the image processing results, he or
she can treat the parameters as a watermark and reversibly embed it in the cover im-
age, and in the future restore the image to its original state or its approximate state,
thus you do not have to store a lot of original images. If the change is not a simple
image processing operation but the local content of the image, then we can adopt a
reversible watermarking method to record the changes of such content, and thus we
are able to restore the original local content according to this information. This latter
application may be suitable for occasions requiring the original image content to be
conﬁdential but not to use encryption to attract other people’s attention, or the occa-
sion intending to use it as a tool for information deceiving. Here, the modiﬁed signal
is viewed as an intermediate signal, which can be used to restore the original state of
the signal as required at any time.
1.6 MAIN CONTENT OF THIS BOOK
This book focuses on lossless information hiding techniques for images, which are
classiﬁed into three categories, i.e., spatial domainebased schemes, transform
domainebased schemes, and compressed domainebased schemes. For compressed
domainebased schemes, we mainly focus on four compressed domains, i.e., VQ,
BTC, JPEG, and JPEG2000. Succedent chapters are organized as follows:
Chapter 2 discusses the lossless information techniques in the spatial domain. In
this chapter, we ﬁrst provide an overview the spatial domainebased lossless
schemes. Then, we discuss some typical spatial domain lossless information hiding
methods, including modulo additionebased schemes, DE-based schemes, histogram
modiﬁcationebased schemes, lossless compressionebased schemes, and reversible
secret sharingebased schemes.
Chapter 3 discusses transform domainebased lossless schemes. In this chapter,
we ﬁrst introduce some related concepts and requirements for lossless information
hiding in transform domains. Then we give a brief overview of transform domaine
62
CHAPTER 1 Introduction

based information hiding. Next we introduce two types of transform domainebased
lossless information hiding methods, i.e., integer DCTebased schemes and integer
DWTebased schemes.
Chapter 4 focuses on the VQ-based lossless information hiding schemes. We ﬁrst
review the schemes related to VQ-based information hiding. Then, we mainly focus
on three kinds of VQ-based lossless information hiding schemes, i.e., the modiﬁed
fast correlation VQebased scheme, side match VQebased schemes, and VQ index
codingebased schemes.
Chapter 5 discusses the topic of embedding data in BTC compressed images with
lossless hiding techniques. First, we introduce the BTC technique. Then, we review
the schemes related to BTC-based information hiding. Then, we focus on two topics,
i.e., lossless information hiding schemes for BTC compressed grayscale images and
for color images. With regard to the schemes in the ﬁrst topic, we classify them into
bitplane ﬂippingebased and mean codingebased schemes. With regard to the
schemes in the second topic, we ﬁrst introduce the problem of BTC compression
for color images and then introduce and discuss two algorithms proposed by us.
Chapter 6 ﬁrst introduces JPEG and JPEG2000 compression techniques in brief,
together with the embedding challenges. Then, we introduce the lossless informa-
tion hiding schemes for JEPG compressed images and JPEG2000 compressed im-
ages. For each kind of compressed image, we ﬁrst overview the existing schemes
and then introduce some typical schemes in detail.
REFERENCES
[1] I.J. Cox, Digital Watermarking and Steganography, Morgan Kaufmann, Burlington,
MA, USA, 2008.
[2] Y. Linde, A. Buzo, R.M. Gray, An algorithm for vector quantizer design, IEEE Trans-
actions on Communications 28 (1) (1980) 84e95.
[3] E.J. Delp, O.R. Mitchell, Image compression using block truncation coding, IEEE
Transactions on Communications 27 (9) (1979) 1335e1342.
[4] M.D. Lema, O.R. Mitchell, Absolute moment block truncation coding and its application
to color images, IEEE Transactions on Communications 32 (10) (1984) 1148e1157.
[5] H.Y. Liang, C.H. Cheng, C.Y. Yang, K.F. Zhang, A blind data hiding technique with er-
ror correction abilities and a high embedding payload, Journal of Applied Research and
Technology 11 (2013) 259e271.
[6] I.J. Cox, M.L. Miller, A review of watermarking and the importance of perceptual
modeling, in: Proc. SPIE Electronic Imaging ‘97, Storage and Retrieval for Image
and Video Databases, 3016, 1997.
[7] S. Vukmirovic, A. Erdeljan, L. Imre, D. Capko, Optimal workﬂow scheduling in critical
infrastructure systems with neural networks, Journal of Applied Research and Technol-
ogy 10 (2) (2012) 114e121.
[8] A. Takahashi, R. Nishimura, Y. Suzuki, Multiple watermarks for stereo audio signals
using phase-modulation techniques, IEEE Transactions on Signal Processing 53
(2005) 806e815.
References
63

[9] T.Y. Kim, H. Choi, K. Lee, T. Kim, An asymmetric watermarking system with many
embedding watermarks corresponding to one detection watermark, IEEE Signal Pro-
cessing Tellers 2 (2004) 375e377.
[10] C. Cruz-Ramos, R. Reyes-Reyes, M. Nakano-Miyatake, H. Pe´rez-Meana, A blind video
watermarking scheme robust to frame attacks combined with MPEG2 compression,
Journal of Applied Research and Technology 8 (3) (2010) 323e337.
[11] J. Prado-Molina, A. Peralta-Higuera, J.L. Palacio-Prieto, R. Sandoval, Airborne high-
resolution digital imaging system, Journal of Applied Research and Technology 4 (1)
(2010) 3e23.
[12] V. Licks, R. Jordan, Geometric attacks on image watermarking systems, IEEE Multi-
media Magazine 12 (3) (2005) 68e78.
[13] E. Elba¸sı, Robust MPEG watermarking in DWT four bands, Journal of Applied
Research and Technology 10 (2) (2012) 87e93.
[14] M. Kutter, F. Jordan, F. Bossen, Digital watermarking of color images using amplitude
modulation, Journal of Electronic Imaging 7 (2) (1998) 326e332.
[15] W. Lu, H.T. Lu, F.L. Chung, Feature based watermarking using watermark template
match, Applied Mathematics Computing 177 (1) (2006) 377e386.
[16] D. Coltuc, P. Bolon, Robust watermarking by histogram speciﬁcation, Proceedings of
IEEE International Conference on Image Processing 2 (1999) 236e239.
[17] J. Fridrich, M. Goljan, Images with self-correcting capabilities, in: Proceedings of IEEE
International Conference on Image Processing, Kobe, Japan, October 1999, pp.
792e796.
[18] P.W. Wong, A public key watermark for image veriﬁcation and authentication, Proceed-
ings of IEEE International Conference on Image Processing vol. I (1998) 455e459.
[19] R.B. Wolfgang, E.J. Delp, A watermark for digital images, Proceedings of IEEE Inter-
national Conference on Image Processing 3 (1996) 219e222.
[20] E.T. Lin, C.I. Podilchuk, E.J. Delp, Detection of image alterations using semi-fragile
watermarks, in: Proceedings of SPlE International Conference on Security and Water-
marking of Multimedia Contents 11, vol. 3971, January 23e28, 2000, San Jose, CA,
2000, pp. 152e163.
[21] L. Xie, G.R. Arce, A blind wavelet based digital signature for image authentication, in:
Proceedings of EUSIPCO-98-Signal Processing IX Theories and Applications, vol. I,
1998, pp. 21e24.
[22] D. Kundur, D. Hatzinakos, Towards a telltale watermarking technique for tamper-
prooﬁng, in: Proceedings of IEEE International Conference on Image Processing,
1998, pp. 409e413.
[23] D. Kundur, D. Hatzinakos, Digital watermarking for telltale tamper prooﬁng and
authentication, Proceedings of IEEE 87 (7) (1999) 1167e1180.
[24] G.J. Yu, C.S. Lu, H.Y. Mark Liao, J.P. Sheu, Mean quantization blind watermarking for
image authentication, in: Proceedings of IEEE International Conference on Image Pro-
cessing, Vancouver, Canada, vol. III, 2000, pp. 706e709.
[25] Y. Wang, A. Pearmain, Blind image data hiding based on self reference, Pattern Recog-
nition Letters 25 (15) (2004) 1681e1689.
[26] C.C. Chang, Y.S. Hu, T.C. Lu, A watermarking-based image ownership and tampering
authentication scheme, Pattern Recognition Letters 27 (5) (2006) 439e446.
[27] N. Ahmed, T. Natarajan, K.R. Rao, Discrete cosine transform, IEEE Transactions on
Computer 32 (1974) 90e93.
64
CHAPTER 1 Introduction

[28] D. Kundur, K. Karthik, Video ﬁngerprinting and encryption principles for digital rights
management, Proceedings of the IEEE 92 (6) (2004) 918e932.
[29] S. Suthaharan, S.W. Kim, H.K. Lee, S. Sathananthan, Perceptually tuned robust water-
marking scheme for digital images, Pattern Recognition Letters 21 (2) (2000) 145e149.
[30] S. Maity, M. Kundu, T. Das, Robust SS watermarking with improved capacity, Pattern
Recognition Letters 28 (3) (2007) 350e356.
[31] K.J.R. Liu, W. Trappe, Z.J. Wang, M. Wu, Collusion-resistant ﬁngerprinting for
multimedia, IEEE Signal Processing Magazine 21 (2004) 15e27.
[32] K.J.R. Liu, W. Trappe, Z.J. Wang, M. Wu, H. Zhao, Multimedia ﬁngerprinting forensics
for traitor tracing, in: EURASIP Book Series on Signal Processing and Communication,
vol. 4, Hindawi Publishing Corporation, 2005.
[33] K.J.R. Liu, Z.J. Wang, M. Wu, H. Zhao, Forensic analysis of nonlinear collusion attacks
for multimedia ﬁngerprinting, IEEE Transactions on Image Processing 14 (5) (2005)
646e661.
[34] S. He, M. Wu, Joint coding and embedding techniques for multimedia ﬁngerprinting,
IEEE Transactions on Information Forensics and Security 1 (2) (2006) 231e247.
[35] J. Goodwin, G. Chetty, Blind video tamper detection based on fusion of source features,
in: Proceedings of 2011 International Conference Digital Image Computing: Tech-
niques and Applications (DICTA), 2011, pp. 608e613.
[36] I.J. Cox, J. Kilian, F.T. Leighton, T.G. Shamoon, Secure spread spectrum watermarking
for multimedia, IEEE Transactions on Image Processing 6 (12) (1997) 1673e1687.
[37] A. Mishra, A. Goel, R. Singh, G. Chetty, L. Singh, A novel image watermarking scheme
using extreme learning machine, in: Proceedings of 2012 International Joint Conference
on Neural Networks (IJCNN), 2012, pp. 10e15.
[38] M. Ammar, P. Judge, WHIM: watermarking multicast video with a hierarchy of inter-
mediaries, in: Proceedings of 10th International Workshop on Network and Operating
Systems Support for Digital Audio and Video (NOSSDAV’00), Chapel Hill, USA,
2000, pp. pp.699e712.
[39] R. Anderson, C. Manifavas, Chameleon-a new kind of stream cipher, in: E. Biham
(Ed.), Lecture Notes in Computer Science, Fast Software Encryption, Springer-
Verlag, Heidelberg, Germany, 1997, pp. 107e113.
[40] A. Adelsbach, U. Huber, A.R. Sadeghi, Fingercasting-joint ﬁngerprinting and decryp-
tion of broadcast messages, in: Proceedings of 11th Australasian Conference Informa-
tion Security Privacy, vol. 4058, 2006, pp. 136e147.
[41] S. Katzenbeisser, B. Skoric, M. Celik, A.R. Sadeghi, Combining Tardos ﬁngerprinting
codes and ﬁngercasting information hiding, in: T. Furon, F. Cayre, et al. (Eds.), Lecture
Notes in Computer Science, vol. 4567, Springer, Berlin/Heidelber, Germany, 2007, pp.
294e310.
[42] P. Alvarez, Using extended ﬁle information (EXIF) ﬁle headers in digital evidence
analysis, International Journal of Digital Evidence, Economic Crime Institute (ECI) 2
(3) (2004) 1e5.
[43] V.M. Potdar, S. Han, E. Chang, Fingerprinted secret sharing steganography for robust-
ness against image cropping attacks, in: Proceedings of IEEE Third International Con-
ference on Industrial Informatics (INDIN), Perth, Australia, August 10e12, 2005, pp.
717e724.
[44] M.H. Shirali-Shahreza, M. Shirali-Shahreza, A new approach to Persian/Arabic text
steganography, in: Proceedings of Fifth IEEE/ACIS International Conference on
References
65

Computer and Information Science (ICIS-COMSAR 2006), July 10e12, 2006, pp.
310e315.
[45] K.H. Jung, K.Y. Yoo, Data hiding method using image interpolation, Computer Stan-
dards and Interfaces 31 (2) (2009) 465e470.
[46] X. Li, J. Wang, A steganographic method based upon JPEG and particle swarm optimi-
zation algorithm, Information Sciences 177 (15) (2007) 3099e3109.
[47] K.B. Raja, C.R. Chowdary, K.R. Venugopal, L.M. Patnaik, A secure image steganogra-
phy using LSB, DCT and compression techniques on raw images, in: Proceedings of
IEEE 3rd International Conference on Intelligent Sensing and Information Processing,
ICISIP’05, Bangalore, India, December 14e17, 2005, pp. 170e176.
[48] N.F. Johnson, S. Jajodia, Exploring steganography: seeing the unseen, IEEE Computer
31 (2) (1998) 26e34.
[49] R.T. McKeon, Strange Fourier steganography in movies, in: Proceedings of the IEEE
International Conference on Electro/Information Technology (EIT), May 17e20,
2007, pp. 178e182.
[50] A.A. Abdelwahab, L.A. Hassan, A discrete wavelet transform based technique for im-
age data hiding, in: Proceedings of 25th National Radio Science Conference, NRSC
2008, Egypt, March 18e20, 2008, pp. 1e9.
[51] N. Provos, P. Honeyman, Hide and seek: an introduction to steganography, IEEE Secu-
rity and Privacy 1 (3) (2003) 32e44.
[52] P. Sallee, Model-based steganography, in: Proceedings of the Second International
Workshop on Digital Watermarking, Seoul, Korea, October 20e22, 2003, Lecture
Notes in Computer Science, vol. 2939, 2003, pp. 254e260.
[53] M. Kharrazi, H.T. Sencar, N. Memon, Performance study of common image steganog-
raphy and steganalysis techniques, Journal of Electrical Imaging 15 (4) (2006) 1e16.
[54] R. Tzschoppe, R. Baum, J. Huber, A. Kaup, Steganographic system based on higher-
order statistics, in: Proceedings of SPIE, Security and Watermarking of Multimedia
Contents V. Santa Clara, California, USA vol. 5020, 2003, pp. 156e166.
[55] R. Caldelli, F. Filippini, R. Becarelli, Reversible watermarking techniques: an overview
and a classiﬁcation, EURASIP Journal of Information Security 2010 (2010) 1e19.
[56] J. Feng, I. Lin, C. Tsai, Y. Chu, Reversible watermarking: current status and key issues,
International Journal of Network Security 2 (3) (2006) 161e170.
[57] W. Pan, G. Coatrieux, J. Montagner, N. Cuppens, F. Cuppens, C. Roux, Comparison of
some reversible watermarking methods in application to medical images, in: Interna-
tional Conference of the IEEE Engineering in Medicine and Biology Society, Minneap-
olis, USA, 2009, pp. 2172e2175.
[58] C.W. Honsinger, P.W. Jones, M. Rabbani, J.C. Stoffel, Lossless recovery of an original
image containing embedded data, 2001. U.S. Patent No. 6,278,791.
[59] B. Macq, Lossless multiresolution transform for image authenticating watermarking, in:
Proc. EUSIPCO, 2000, pp. 533e536.
[60] J. Fridrich, M. Goljan, R. Du, Invertible authentication, in: Proceedings of the SPIE Se-
curity and Watermarking of Multimedia Content, San Jose, USA, 2001, pp. 197e208.
[61] J. Fridrich, M. Goljan, R. Du, Lossless data embedding-new paradigm in digital
watermarking, EURASIP Journal on Advances in Signal Processing 2 (2002) 185e196.
[62] D. Zheng, Y. Liu, J. Zhao, A. El Saddik, A survey of RST invariant image watermarking
algorithms, ACM Computing Surveys 39 (2) (2007). Article 5.
[63] J.M. Guo, Watermarking in dithered halftone images with embeddable cells selection
and inverse halftoning, Signal Processing 88 (6) (2008) 1496e1510.
66
CHAPTER 1 Introduction

[64] J.M. Guo, J.J. Tsai, Reversible data hiding in low complexity and high quality compres-
sion scheme, Digital Signal Processing 22 (5) (2012) 776e785.
[65] B. Yang, M. Schmucker, W. Funk, C. Busch, S. Sun, Integer DCT-based reversible
watermarking for images using companding technique, in: E.J. Delp III, P.W. Wong
(Eds.), Proceedings of the SPIE, Security, Steganography, and Watermarking of Multi-
media Contents VI, 2004, pp. 405e415.
[66] M.U. Celik, G. Sharma, A.M. Tekalp, E. Saber, Lossless generalized-LSB data
embedding, IEEE Transactions on Image Processing 14 (2) (2005) 253e266.
[67] G. Xuan, C. Yang, Y. Zhen, Y.Q. Shi, Z. Ni, Reversible data hiding using integer wavelet
transform and companding technique, in: Lecture Notes in Computer Science, Digital
Watermarking, vol. 3304, Springer, Berlin, Heidelberg, 2005, pp. 115e124.
[68] M. Arsalan, S.A. Malik, A. Khan, Intelligent reversible watermarking in integer wavelet
domain for medical images, Journal of System and Software 85 (4) (2012) 883e894.
[69] C. De Vleeschouwer, J.E. Delaigle, B. Macq, Circular interpretation of histogram for
reversible watermarking, in: IEEE Fourth Workshop on Multimedia Signal Processing,
2001, pp. 345e350.
[70] Z. Ni, Y. Shi, N. Ansari, W. Su, Reversible data hiding, IEEE Transactions on Circuits
System for Video Technology 16 (3) (2006) 354e362.
[71] C.C. Lin, W.-L. Tai, C.-C. Chang, Multilevel reversible data hiding based on histogram
modiﬁcation of difference images, Pattern Recognition 41 (12) (2008) 3582e3591.
[72] Z. Ni, Y.Q. Shi, N. Ansari, W. Su, Q. Sun, X. Lin, Robust lossless image data hiding
designed for semi-fragile image authentication, IEEE Transactions on Circuits System
18 (4) (2008) 497e509.
[73] X. Gao, L. An, X. Li, D. Tao, Reversibility improved lossless data hiding, Signal Pro-
cessing 89 (10) (2009) 2053e2065.
[74] P. Tsai, Y.-C. Hu, H.-L. Yeh, Reversible image hiding scheme using predictive coding
and histogram shifting, Signal Processing 89 (6) (2009) 1129e1143.
[75] K.-S. Kim, M.-J. Lee, H.-Y. Lee, H.-K. Lee, Reversible data hiding exploiting spatial
correlation between sub-sampled images, Pattern Recognition 42 (11) (2009)
3083e3096.
[76] Kamran, A. Khan, S.A. Malik, A high capacity reversible watermarking approach for
authenticating images: exploiting down-sampling, histogram processing, and block
selection, Information Sciences 256 (2014) 162e183.
[77] Y. Cheung, S. Member, H. Wu, S. Member, A sequential quantization strategy for data
embedding and integrity veriﬁcation, IEEE Transactions on Circuits Systems for Video
Technology 17 (8) (2007) 1007e1016.
[78] M.J. Saberian, M.A. Akhaee, F. Marvasti, An invertible quantization based watermark-
ing approach, in: IEEE International Conference on Acoustics, Speech and Signal Pro-
cessing, Las Vegas, USA, 2008, pp. 1677e1680.
[79] J. Lee, Y. Chiou, J. Guo, S. Member, Reversible data hiding based on histogram modi-
ﬁcation of SMVQ indices, IEEE Transactions on Information Forensics and Security 5
(4) (2010) 638e648.
[80] L.T. Ko, J.E. Chen, Y.S. Shieh, H.C. Hsin, T.Y. Sung, Nested quantization index mod-
ulation for reversible watermarking and its application to healthcare information man-
agement systems, Computational and Mathematical Methods 2012 (2012) 1e8.
[81] L.T. Ko, J.E. Chen, Y.S. Shieh, M. Scalia, T.Y. Sung, A novel fractional discrete cosine
transform based reversible watermarking for healthcare information management
systems, Mathematical Problems in Engineering 2012 (2012) 1e17.
References
67

[82] J. Tian, Reversible data embedding using a difference expansion, IEEE Transactions on
Circuits Systems 13 (8) (2003) 890e896.
[83] D. Coltuc, J. Chassery, Very fast watermarking by reversible contrast mapping, IEEE
Signal Processing Letters 14 (4) (2007) 255e258.
[84] D.M. Thodi, J.J. Rodriguez, Prediction-error based reversible watermarking, in: Inter-
national Conference on Image Processing, 2004, pp. 1549e1552.
[85] L. Luo, Z. Chen, M. Chen, X. Zeng, Z. Xiong, Reversible image watermarking using
interpolation technique, IEEE Transactions on Information Forensics and Security 5
(1) (2010) 187e193.
[86] C. De Vleeschouwer, J. Delaigle, B. Macq, Circular interpretation of bijective trans-
formmions in lossless watermarking for media asset management, IEEE Transactions
on Multimedia 5 (1) (2003) 97e105.
[87] Z. Ni, Y. Shi, N. Ansari, et al., Robust lossless image data hiding, in: Proceeding of
IEEE International Conference on Multimedia and Expo, 3, 2004, pp. 2199e2202.
[88] D. Zou, Y. Shi, Z. Ni, A semi-fragile lossless digital watermarking scheme based on
integer wavelet transform, in: Proceedings of IEEE 6th Workshop Multimedia Signal
Processing, 2004, pp. 195e198.
[89] D. Zou, Y. Shi, Z. Ni, et al., A semi-fragile lossless digital watermarking scheme based
on integer wavelet transform, IEEE Transcations on Circuits Systems for Video Tech-
nology 16 (10) (2006) 1294e1300.
68
CHAPTER 1 Introduction

Lossless Information
Hiding in Images on the
Spatial Domain
2
2.1 OVERVIEW OF SPATIAL DOMAINeBASED INFORMATION
HIDING
At present, the vast majority of reversible information hiding algorithms are focused
on the spatial domain, and most algorithms select an image as the carrier signal. Pixels
are chosen for the hidden information carrier mainly because the image pixel value is
an integer in a certain range without any error. Thus, the spatial domainebased algo-
rithms are relatively abundant and early developed. Currently, researchers have
devised a number of spatial domain lossless information hiding methods, which are
classiﬁed from different angles. Depending on the embedding model, these methods
can be divided into four categories, i.e., modulo additionebased, compression-based,
difference expansion (DE)ebased and histogram-based approaches.
In the early years, modulo additionebased methods were ﬁrst put forward, which
use modulo 256 operations to achieve lossless watermark embedding [1e4]. How-
ever, the modulo operation brings the pixel ﬂipping problem, which makes such
methods result in a watermarked image with salt-and-pepper noise.
Subsequently, Fridrich et al. [5,6] proposed a reversible authentication frame-
work, which embeds the watermark into the host image through compressing bit-
planes. When compressed bit-planes are too many, although the capacity has
increased, the visual quality of the watermarked image will drop dramatically. To
this end, Celik et al. [7,8] developed this idea, and proposed a method based on gener-
alized least signiﬁcant bit (G-LSB) plane compression, in pursuit of a better trade-off
between the capacity and the quality of the watermark image. Despite the fact that the
compression-based method overcomes the salt-and-pepper noise in the watermarked
image, its performance is still affected by the compression efﬁciency largely.
To this end, Tian and Tiara [9,10] proposed a method based on DE; it divides the
pixels of the host image into two types, i.e., expandable and nonexpandable pixels,
and uses the DE and least signiﬁcant bit (LSB) replacing manners for embedding. To
mark the type of the pixel pair, the location map after compression together with the
watermark is embedded into the host image, which reduces the net capacity to some
extent. Alattar et al. [11] used the pixel vector instead of the pixel pair to improve the
performance of Tian’s method. Kamstra et al. [12] used a low-pass image to predict
CHAPTER
Lossless Information Hiding in Images. http://dx.doi.org/10.1016/B978-0-12-812006-4.00002-4
Copyright © 2017 Zhejiang University Press Co., Ltd., published by Elsevier Inc. All rights reserved.
69

the expandable difference, which greatly reduced the space of the location map. Sub-
sequently, Kim et al. [13] further simpliﬁed the location map design and introduced a
new deﬁnition of expandability. Thodi and Rodriguez [14] improved the capacity of
Tian’s method by expanding the prediction error. But the compressibility of the loca-
tion map is still one of the factors that affect the performance of this method. There-
fore, Hu et al. [15] proposed a new idea to utilize the sparse location map to improve
the capacity. Wang et al. [16] applied the DE technique to content protection of two-
dimensional vector maps. Thereafter, still many researchers have proposed new
methods that are based on DE [17e21].
At the same time, the histogram-based methods were also proposed. Depending on
whether the transmission process considers the impact of covert attacks or not, such
methods can be divided into two types, i.e., fragile and robust methods. Ni et al. [22]
ﬁrst proposed the embedding model based on histogram shifting, whose core idea is to
ﬁnd a pair of peak and zero points in the histogram of the host image and to perform
watermark embedding by shifting the neighboring histogram column of the peak point
forward the zero histogram column. Because the peak point and the zero position in-
formation needs to be transmitted to the receiver to extract the watermark and recover
the host image, Hwang et al. [23] designed the location map and proposed a two-way
iterative embedding method. Then, Kuo et al. [24] further improved the location map.
Fallahpour [25] and Tai et al. [26], respectively, utilized the gradient adjustable pre-
diction error histogram and difference histogram to improve the performance.
Unlike the fragile methods that emphasize the capacity and visual quality of the
watermarked image, robust lossless information hiding approaches focus on the
robustness under the covert attack. De Vleeschouwer presented the ﬁrst robust loss-
less information hiding scheme [27,28], which ﬁrst divides the host image into
nonoverlapping blocks of the same size, randomly divides the pixels of each block
into two subregions of the same size, maps their histograms onto the circle, and
ﬁnally embeds the watermark by rotating the centroid vectors of the two regions. Ex-
periments show that the method is robust to JPEG compression, but due to the
modulo 256 addition operation, which is used to avoid overﬂow pixels, there are
a large number of salt-and-pepper noisy pixels in the watermarked image, greatly
reducing the visual quality of the watermarked image. To solve this problem, Ni
et al. [29e32] proposed an idea to embed information by modifying the statistical
features of the image with constraints according to the histogram distribution of
the host image. Although they overcome the salt-and-pepper noise and improve
the visual quality of the watermarked image, due to the use of the error correction
code, it faces the problems of low capacity, unreliable robustness, and so on.
Then, Zeng et al. [33] further enhanced the performance of the method in [29] by
introducing dual thresholds and a new embedding model.
So far, the research on lossless information hiding is still in full swing, and new
research results continue to emerge [34e36]. Nevertheless, the actual needs of the
application environment, improvement in the performance of lossless information
hiding methods, and enhancement of their applicability are still challenges that
the information hiding ﬁeld faces.
70
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

2.2 MODULO ADDITIONeBASED SCHEME
The modulo additionebased robust reversible watermarking algorithm ﬁrst ap-
peared in the patent of Eastman Kodak Company applied by Honsinger et al. [4];
then Fridrich et al. [6] extended this idea to the DCT transform domain. The modulo
addition idea can achieve reversibility, because the nonadaptive watermark signal
can be directly subtracted from the pixel value without any loss, as long as we
know the possible embedded watermark pattern and the pixel value overﬂow prob-
lem does not appear, and this modulo addition operation is completely reversible. In
Refs. [4,6], this modulo addition mode is used for embedding authentication infor-
mation into the carrier media. The watermark embedding and authentication process
can be shown in Fig. 2.1 as follows:
2.2.1 EMBEDDING PROCESS
The embedding process can be described as follows:
Step 1: Let X be the original image to be authenticated; compute its hash value
H(X).
Step 2: Select an addition nonadaptive robust watermarking technique, and
generate a watermark pattern W through a secret key K making the payload of W
be H(X), where the watermark pattern W is the function of the secret key K and
the payload H(X), i.e., W ¼ W(K, H(X)).
Step 3: Using the modulo addition operation 4, add the watermark pattern W to
X, generating the image to be generated, i.e., XW ¼ X 4aW, where a is the
embedding strength coefﬁcient.
2.2.2 AUTHENTICATION PROCESS
Step 1: Extract the watermark bit string H0(payload) from XW.
Step 2: Generate the watermark pattern W’ ¼ W(K, H0) through the secret key K
and the extracted bit string H’.
Step 3: Subtract W0 from XW, obtaining X’ ¼ XW  aW’.
Step 4: Compute the hash value H(X0), and compare it with the preextracted hash
value H’. If they coincide, the image is authentic, that is, X0 is the original image
without modiﬁcation. Otherwise, it is nonauthentic, i.e., the cover image is
subject to modiﬁcation.
2.2.3 EXPLANATION OF THE MODULO ADDITION OPERATION
In the aforementioned watermark embedding and authentication processes, the
modulo addition operation is deﬁned as follows:
i4k ¼ C P i=CR þ modði þ k; CÞ
(2.1)
2.2 Modulo AdditioneBased Scheme
71

where i and k are two integers involved in the addition modulo operation, P$R is the
rounding operation, C is the modulo, and mod(.,.) is the operation to get the
remainder. Through this modulo addition operation, if i þ k is just integer times
the modulo C, then mod(i þ k,C) ¼ 0, thus the absolute difference D between the
modulo addition result i4k ¼ C P i=CR and i þ k is just one modulo C, i.e.,
D ¼ ji þ k  CPi=CRj ¼ jCðPi=CR  1Þ  CPi=CRj ¼ C
(2.2)
For example, if C ¼ 16, assume that the dynamic range of i is [0,255] and k ¼ 1,
then we have the modulo addition result 0/1, 1/2, ., 15/0, 16/17, 17/18,
., 31/16, and so on. Obviously, the smaller the modulo C is, the less distortion
this operation introduces near the boundary (i.e., the case that i þ k is just integer
times C). However, on the other hand, the smaller the modulo C is, the more distorted
 Embedding of robust reversible watermarking
Authentication based on robust reversible watermarking
Hash Computation
Watermark Pattern Generation
Embed Strength Control
X
H(X)
Secret key K
W=W(K,H(X))
W
XW = X
W
Watermark 
Extraction
Watermark Pattern 
Generation
Embed Strength Control
Hash Computation
?=
XW
H
Secret key K
W =W(K,H )
W
X = XW 
W
H(X )
Y
N
Authentic
Non-Authentic
(a)
(b)
FIGURE 2.1
(a) Robust reversible watermark embedding process and (b) corresponding
authentication process.
72
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

pixels there are in the whole dynamic range (e.g., the dynamic range of an 8-bit gray-
scale image is [0,255]). For a given image, to reduce the distortion introduced by
the modulo addition operation, it is required to choose C according to concrete con-
ditions: if k is small and the number of pixels near the boundary (the pixel value near
0 or 255) is small, then we can use a big C, e.g., 256; otherwise, a small value of C
should be adopted to avoid severe visual distortion like the salt-and-pepper noise. In
addition, note that in the ﬁrst step of authentication, the method used in watermark
extraction is the correlation operation with the noise sequence, thus the robustness
of the watermark extraction operation can be guaranteed.
2.3 DIFFERENCE EXPANSIONeBASED SCHEMES
2.3.1 TIAN’S SCHEME
The DE technique for reversible data hiding was ﬁrst proposed by Tian and Tiara
[9,10]. It is a high-capacity approach based on expanding the pixel difference value
between neighboring pixels. His method allows one bit to be embedded in every pair
of pixels. Given a pair of 256-grayscale image pixel values (x, y), 0  x, y  255,
their integer average c and difference d are computed as
c ¼
x þ y
2

; d ¼ x  y
(2.3)
where PzR denotes the ﬂoor function that seeks the greatest integer less than or equal
to z. The inverse transform of Eq. (2.3) is
x ¼ c þ
d þ 1
2

; y ¼ c 
d
2

(2.4)
The reversible transforms denoted by Eqs. (2.3) and (2.4) are called the integer
Haar wavelet transform, or the S transform. Tian and Tiara [9,10] shifted d to the left
one unit and appended the watermarking bit b in LSB according to the following
rule:
d0 ¼ 2d þ b
(2.5)
This reversible data-embedding operation given in Eq. (2.5) is called DE. To pre-
vent overﬂow and underﬂow problems, that is, to restrict x and y in the range of
[0,255], d must satisfy the condition in Eq. (2.6). Here the inverse transform is
computed as
jdj  minð2$ð255  cÞ; 2c þ 1Þ
(2.6)
The authors classify difference values into four disjoint sets according to the
following deﬁnitions.
1. The ﬁrst set, EZ, contains all the expandable d ¼ 0 and the expandable d ¼ 1.
2. The second set, EN, contains all the expandable d ; EZ.
2.3 Difference ExpansioneBased Schemes
73

3. The third set, CN, contains all the changeable d, which are not in EZWEN.
4. The fourth set, NC, contains the rest of d, which are not able to be changed.
Deﬁnition 2.1: A difference value d is expandable under the integer average
value c if j2d þ bj  minð2$ð255  cÞ; 2c þ 1Þ for both b ¼ 0 and 1.
Deﬁnition 2.2: A difference value d is changeable under the integer average
value c if j2$Pd
2R þ bj  minð2$ð255  cÞ; 2c þ 1Þ for both b ¼ 0 and b ¼ 1.
From Deﬁnitions 2.1 and 2.2, it can be proved that:
1. A changeable difference value d remains changeable even after modifying its
LSB.
2. An expandable difference value d is changeable.
3. After DE, the expanded difference value d’ is changeable.
4. If d ¼ 0 or 1, the conditions for expandable and changeable are equivalent.
At the receiving end, to extract embedding data and restore the original image,
the expandable, changeable, and nonchangeable sets must be identiﬁed. Since an
expanded difference value via the DE d’ and a changeable difference value with
its modiﬁed LSB are both changeable after embedding, which is mentioned earlier.
All difference values in NC (not changeable) can be unambiguously identiﬁed dur-
ing extraction using the condition in Eq. (2.6). It is necessary to know which differ-
ence value has been selected for the DE. That is, some additional information (AI)
needs to be used to further identify all the expanded difference values via the DE
from all the changeable values. The authors create a binary location map, which con-
tains the location information of all selected expandable difference values, as an
overhead for later reconstruction of the original image.
To achieve the payload capacity limit, they select all expandable differences that
are in the range of [255, 255] for the DE, but the peak signal-to-noise ratio (PSNR)
value is generally very low and the visual quality degradation of the watermarked
image is almost perceptible. To build a balance between the PSNR value and
payload size, they present two selection methods to reduce the payload size, which
is less than the payload capacity limit, and consequently improve the PSNR value.
The ﬁrst method is described as follows.
They select d with small magnitudes for the DE. That is, they choose a threshold
value T, d˛[-T, T], and partition EN into EN1 and EN2. Using EN1 ¼ {d ˛ EN:
jdj  T}, EN2 ¼ {d ˛ EN: jdj > T}. For a payload whose size is equal to the payload
capacity limit EN1 ¼ EN, EN2 ¼ F. For a d in EZWEN1, a value of “1” is assigned
in the location map; for a value of d in EN2WCNWNC, a value of “0” is assigned.
Hence a value of “1” indicates the selected expandable difference values.
The embedding process is generalized as follows. After creating the location map,
it is compressed without loss using a JBIG2 compression or an arithmetic compression
coding to form a bitstream L. For every d in EN2WCN, LSB(d) is stored in a bitstream
C. The payload P, including an authentication hash of the original image (for
example, MD5) and the bitstreams L and C are concatenated to form the ﬁnal binary
bitstream B. They then embed B into LSBs of one bit left-shifted versions of
74
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

difference values in EZWEN1 and also into LSBs of difference values in EN2WCN.
In the embedding process, the difference values in NC is kept intact. The data embed-
ding by replacement is illustrated in Table 2.1. After all bits in B are embedded, they
then apply the inverse transform in Eq. (2.4) to obtain the embedded image.
In the DE method, data embedding and extraction rely on expendable and
changeable differences. The expandable differences provide space for data embed-
ding and the changeable differences are used to guarantee blind data extraction. All
difference values in the difference image are classiﬁed into three categories: expand-
able, changeable but nonexpandable, and nonchangeable. For a pure payload (the
secret bits to be hidden), a number of expandable differences should be selected
and their locations should be stored into a binary-type location map, which can be
losslessly compressed by run-length coding. All the LSBs of changeable but nonex-
pandable differences are recorded as an original bitstream. The compressed location
map, the original bitstream, and the pure payload are embedded into the difference
image together.
The secret data extraction process is simple. The LSBs of all changeable differ-
ences in the image compose a bitstream, from which we can extract the location map,
the original bitstream, and the pure payload. To restore the image, all previous
expandable differences divide by two integrally. The LSBs of all changeable but
not expandable differences are reset with the original bitstream. The extraction pro-
cess starts by calculating the average value c’ and the difference value d’ of pixel
pairs (x’, y’) by scanning the watermarked image in the same order used during
embedding. Referring to Table 2.1, they divide pixel pairs into two sets CH (change-
able) and NC (not changeable) using the condition given in Eq. (2.6). They extracts
all LSBs of d’ for each pair in CH to form a bitstream B, which is identical to that
formed during embedding. The extracted bitstream B is decompressed to restore the
location map by a JBIG2 decoder. Hence, all expanded pixel pairs after the DE in CH
are identiﬁed. By identifying an end of message symbol at its end for a JBIG2, the
bitstream C including the original LSBs of the changeable difference in EN2WCN
and the payload is retrieved. The original values of differences are restored as fol-
lows. For d’ in EZWEN1, they restore the original values of d’ as follows:
d ¼
d0
2

(2.7)
Table 2.1 Embedding on Difference Values
Category
Original Set
Original
Value
Location
Map Value
New Value
New Set
Changeable
EZ or EN1
D
1
2d þ b
CH
EN2 or CN
D
0
2$

d
2

þ b
Nonchangeable
NC
D
0
d
NC
2.3 Difference ExpansioneBased Schemes
75

For d’ in EN2WCN, they restore the original values of according to Eq. (2.8)
d ¼ 2 
d0
2

þ b1
b1˛C
(2.8)
Finally, they apply the inverse transform given in Eq. (2.4) to retrieve the original
image. They then compare the retrieved authentication hash with the hash function
of the restored image. If the two hash functions match exactly, the image content is
authentic and the restored image is exactly the same as the original image.
Tian implemented the DE method and tested it on various standard grayscale im-
ages. Tian also implemented the regular-singular (RS) lossless data-embedding
method in Ref. [37] and the lossless G-LSB data-embedding method in Ref. [7] to
compare the results among the three methods using 512  512, 8 bits per pixel
(bpp) grayscale Lena. From the comparison results described in Ref. [38], Tian
achieves the highest embedding capacity, while keeping the lowest distortion. Except
for images with many smooth regions, the payload capacity limit of the G-LSB
method does not exceed 1 bpp. The DE method could easily embed more than
1 bpp. The payload capacity limit of the RS method is lower than those of the G-
LSB and DE methods. By embedding a payload of the same bit length, the embedded
Lena image by the DE method is about 2e3 dB higher than those obtained by the G-
LSB and RS methods.
2.3.2 ALATTER’S SCHEME
Alatter [11] presented a high-capacity, data hiding algorithm. The proposed algorithm
is based on a generalized, reversible, integer transform (GRIT), which calculates the
average and pairwise differences between the elements of a vector extracted from the
pixels of the image. Several conditions are derived and used in selecting the appro-
priate difference values. Either the watermark bits are embedded into the LSBs of
selected differences or alternatively the LSBs are 1 bit left-shifted versions of selected
differences. Derived conditions can identify which difference is selected after embed-
ding to ensure that the new vector computed from the average and embedded differ-
ence has grayscale values. To ensure the reversibility, the locations of shifted
differences and the original LSBs must be embedded before embedding the payload.
The proposed algorithm can embed N1 bits in every vector with a size of N  1. The
proposed algorithm is based on a GRIT. We will now introduce the theorem for GRIT.
Theorem 2.1: For Du ¼ [a, d1, d2, ., dN1]T, if v ¼ PDuR, then u ¼

D1PvR

. v
and u form a GRIT pair, where D is an N  N full-rank matrix with an inverse D1,
u is an N  1 integer column vector, a is the weighted average value of the elements
of u, and d1, d2, ., dN1 are the independent pairwise differences between the ele-
ments of u. Here, Q:S and P:R, respectively, indicate round up or down to the nearest
integer.
The proof is given by Alatter [11]. Alatter generalized the algorithm based on
GRIT to vectors of length more than 3. Alatter uses an example in which N ¼ 4.
One possible value of D is given by
76
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

D ¼
2
6664
a0=c
a1=c
a2=c
a3=c
1
1
0
0
0
1
1
0
0
0
1
1
3
7775
(2.9)
where c ¼ a0 þ a1 þ a2 þ a3 and,
D ¼
2
6664
1
ðc  a0Þ=c
ða2 þ a3Þ=c
a3=c
1
a0=c
ða2 þ a3Þ=c
a3=c
1
a0=c
ða0 þ a1Þ=c
a3=c
1
a0=c
ða0 þ a1Þ=c
ðc  a3Þ=c
3
7775
(2.10)
Using this theorem, for the vector q ¼ (u0, u1, u2, u3), the appropriate GRIT may
be deﬁned as
8
>
>
>
>
>
>
>
>
<
>
>
>
>
>
>
>
>
:
v0 ¼
a0u0 þ a1u1 þ a2u2 þ a3u3
a0 þ a1 þ a2 þ a3

v1 ¼ u1  u0
v2 ¼ u2  u1
v3 ¼ u3  u2
(2.11)
8
>
>
>
>
>
>
>
>
<
>
>
>
>
>
>
>
>
:
u0 ¼ v0 
ða0 þ a1 þ a2Þv1 þ ða2 þ a3Þv2 þ a3v3
a0 þ a1 þ a2 þ a3

u1 ¼ v1 þ u0
u2 ¼ v2 þ u1
u3 ¼ v3 þ u2
(2.12)
To describe the reversible algorithm in detail and unambiguously, we choose
quads to introduce the embedding and detection processes. A quad is a 1  4 vector
formed from four pixel values chosen from four different locations each having
the same component according to a predetermined order. Each quad is assembled
from 2  2 adjacent pixel values in Alatter’s algorithm (Fig. 2.2). Each pixel
quad of the original image is classiﬁed into three groups according to the following
deﬁnitions.
1. The ﬁrst group, S1 contains all expandable quads having v1  T1, v2  T2, and
v3  T3. Here, T1, T2, and T3 are predeﬁned thresholds.
2. The second group, S2, contains all changeable pairs that are not in S1.
3. The third group, S3, contains the rest of the pairs, and these are not changeable.
Deﬁnition 2.3: The quad q ¼ (u0, u1, u2, u3) is said to be expandable if for all
values of b1, b2, and b3 ˛ {0, 1}.
2.3 Difference ExpansioneBased Schemes
77

0  v00 
ða0 þ a1 þ a2Þv01 þ ða2 þ a3Þv02 þ a3v03
a0 þ a1 þ a2 þ a3

 255
0  v01 þ u0  255
0  v02 þ u1  255
0  v03 þ u2  255
(2.13)
where
v01 ¼ 2v1 þ b1
v02 ¼ 2v2 þ b2
v03 ¼ 2v3 þ b3
(2.14)
Deﬁnition 2.4: The quad q ¼ (u0, u1, u2, u3) is said to be changeable if for all
values of b1, b2, and b3˛{0, 1}, v’1, v’2, and v’3 are given by Eq. (2.15) and satisfy
Eq. (2.13). Here
v01 ¼ 2 
jv1
2
k
þ b1; v02 ¼ 2 
jv2
2
k
þ b2; v03 ¼ 2 
jv3
2
k
þ b3
(2.15)
Each of v1, v2, and v3 in S1 was shifted left by 1 bit to form v’1, v’2, and v’3.
Watermark bits b1, b2, and b3 are, respectively, appended in the LSBs of v’1, v’2,
and v’3. The conditions in Eq. (2.13) ensure that the new quad is computed using
v’0, v’1, v’2, and v’3 according to the inverse transform with grayscale values in
[0, 255]. v1, v2, and v3 in S2 are the same as v’1, v’2, and v’3 with replaced LSBs
with watermark bits. A changeable quad after LSB has been modiﬁed is still change-
able. An expandable quad is also changeable.
The locations of all the quads in S1 are indicated by 1’s in a binary location map.
The JBIG algorithm is used to compress the map to produce the bitstream B1. The
LSBs of v1, v2, and v3 of all the quads in S2 are now extracted into a bitstream B2. The
payload P, including the authentication hash (MD5) of original image, bitstream B1
Quad q=(u0, u1, u2, u3)
h
w
Image
h
FIGURE 2.2
Quads in an image.
78
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

and B2, are concatenated to form B. Finally, the bitstream B is embedded into LSBs
of one-bit left-shifted versions of difference values in S1. For any quad in S2, a bit is
embedded in the difference by replacing the LSB.
Since the embedding process is completely reversible, the algorithm can be
applied to the image recursively to embed more data. However, the difference be-
tween the original image and the embedded image increases with every application
of the algorithm. Fig. 2.3 depicts four different structures that can be used to permute
a quad that is a 1  4 vector.
The retrieval process starts by identifying all the changeable quads in the
embedded image using the conditions in Eq. (2.14). The LSBs of the difference
values of all the changeable quads are collected to form a bitstream B. The JBIG al-
gorithm is then used to decompress bitstream B to retrieve the location map. By use
of the location map, all expandable quads are separated from the changeable quads.
The original image can be restored by dividing each difference in the expandable
quads by 2 and replacing the LSBs of each difference in the changeable quads
with the retrieved original bits. The retrieved authentication hash is compared
with the hash function of the restored image. If they match exactly, the image content
is authentic and the restored image will be exactly the same as the original image.
Alattertestedthe quad-basedalgorithm onseveraltestimages,i.e.,Fruits,Lena,and
Baboon. The experimental results indicate that the achievable embedding capacity de-
pends on the nature of the image. The algorithm performs much better with Fruits and
Lena than with Baboon. It performs slightly better with Fruits than with Lena. With
Fruits, the algorithm is able to embed 982 kB (3.74 bits/pixel) with an image quality
of 28.42 dB. It is also able to embed 296 kB (0.77 bits/pixel) with a high image quality
of 39.05 dB. With Baboon the algorithm is able to embed 808 kB (3.08 bits/pixel) at
20.18 dB and 130 kB (0.50 bits/pixel) at 32.62 dB. Alatter compared the performance
of the quad-based algorithm [39] with that of Tian’s method described in Ref. [38]
using grayscale Lena and Barbara images. The results indicate that the quad-based
algorithm outperforms Tian’s method at a PSNR value higher than 35 dB. Tian’s al-
gorithm marginally outperforms Alatter’s algorithm at lower values of PSNR.
u3
u1
u2
u0
u3=(u3, u0, u1, u2)
u1
u0
u2
u3
u1=(u1, u0, u2, u3)
u0
u1
u2
u3
u0=(u0, u1, u2, u3)
u2
u1
u0
u3
u2=(u2, u0, u1, u3)
(a)
(b)
(c)
(d)
FIGURE 2.3
Quads conﬁguration in an image.
2.3 Difference ExpansioneBased Schemes
79

2.4 HISTOGRAM MODIFICATIONeBASED SCHEMES
2.4.1 ORIGINAL HISTOGRAM SHIFTINGeBASED SCHEME
Ni et al. [22] proposed a novel reversible algorithm based on histogram shifting tech-
niques. The algorithm ﬁrst ﬁnds a zero point (no pixel) and a peak point (a maximum
number of pixels) of the image histogram. If zero point does not exist for some im-
age histogram, a minimum point with a minimum number of pixels is treated as a
zero point by memorizing the pixel grayscale value and the coordinates of those
pixels as overhead information. Ni et al. [22] shifted the peak point toward the
zero point by one unit and embedded the data in the peak and neighboring points.
Note that the original peak point after embedding disappears in the histogram.
Hence, to ensure the reversible restoration, the embedding algorithm needs to
memorize the zero and peak points as part of the overhead information. The algo-
rithm can embed a signiﬁcant amount of data (5 kbits to 80 kbits for a
512  512  8 grayscale image) while keeping a very high visual quality for all nat-
ural images. Speciﬁcally, the PSNR of the marked image versus the original image is
guaranteed to be higher than 48 dB.
Assume that x represents the pixel value and H(x) represents the occurrence fre-
quency of x. Find the maximum H(xHmax) and minimum H(xHmin). Shift all the bars
between xHmax and xHmin (xHmax and xHmin are not included) to xHmin, and the shift
distance is 1. Assume that xHmax < xHmin. The meaning of the shifting operation is
just adding 1 to all the pixels whose value xi is between xHmax and xHmin. After
the shifting operation, H(xHmaxþ1) ¼ 0. Traverse all the pixels in order. If
xi ¼ xHmax, check the secret to be embedded. If it is 0, do not change xi; otherwise,
add 1 to xi, and then search the next pixel whose value equals xHmax and embed the
next secret data. So we can know the hiding capacity of this scheme is H(xHmax).
During the extracting process, just check the pixel values in order. If xi ¼ xHmax,
then the hiding data is 0; otherwise, if xi ¼ xHmax þ 1, then the hiding data is 1. After
the extraction, all the pixel values can be recovered. If xHmax > xHmin, the shifting
operation means that 1 should be subtracted from all the pixels with values
xi ˛ðxHmax; xHminÞ. The mechanism of the histogram modiﬁcation algorithm is
shown in Fig. 2.4, where we take the case xHmax < xHmin as an example.
2.4.2 ADJACENT PIXEL DIFFERENCEeBASED SCHEME
Li et al. [40] proposed a reversible data hiding method named adjacent pixel differ-
ence (APD) based on the neighbor pixel differences modiﬁcation. In this method, an
inverse “S” order is adopted to scan the image pixels. As shown in Fig. 2.5, a 3  3
image block is used to illustrate this principle. The scan direction is marked as the
blue line, and the block can be rearranged into a pixel sequence as p1, p2, ., p9.
Suppose the host image I is an 8-bit gray level image sized as M  N. Then a
pixel sequence p1, p2, ., pM  N is obtained via the inverse “S” order scan. The dif-
ferences of adjacent pixels are computed as
80
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

di ¼

p1
i ¼ 1
pi1  pi
2  i  M  N
(2.16)
Considering the similarity of pixel values between pi1 and pi, a large quantity of
di (2  i  M  N) is equal or close to 0. The difference histogram is constructed
based on these M  N1 difference statistics. Suppose the histogram bins from
left to right are denoted by b(255), b(254), ., b(1), b(0), b(1), ., b(254),
and b(255). Fig. 2.6 shows the 512  512 Lena image’s difference histogram. Obvi-
ously most differences are concentrated around b(0). When the curve spreads
FIGURE 2.4
The histogram modiﬁcation algorithm for the case xHmax < xHmin.
FIGURE 2.5
Inverse “S” scan of a 3  3 image block.
2.4 Histogram ModiﬁcationeBased Schemes
81

away to both sides, it drops dramatically, and no differences fall into those bins far
from b(0).
Basically, APD selects one pair of bins b(p1) and b(z1) (suppose p1 < z1) where
b( p1) and b(z1) denote the peak and zero points, respectively. Then the bins between
[b( p1 þ 1), b(z11)] are shifted rightward one level. Thus b(p1 þ 1) are emptied for
data embedding. That is, if a secret bit “1” is embedded, the differences equaling p1
are added by 1. If “0” is embedded, they are not changed.
To enhance the capacity, APD can also select two pairs of peakezero points, e.g.
[b(p1), b(z1)] and [b(z2), b( p2)] (suppose p1 < z1 and z2 < p2). Then the bins between
[b( p1 þ 1), b(z11)] are shifted rightward one level, and those between [b(z2 þ 1),
b(p21)] are shifted leftward one level. Thus b( p1 þ 1) and b( p21) are emptied for
data embedding. The secret bits modulation is similar as that in one pair of peake
zero points embedding. Note the ranges of [b( p1), b(z1)] and [b(z2), b( p2)] must not
be overlapped.
2.4.3 MULTILEVEL HISTOGRAM MODIFICATIONeBASED SCHEME
The disadvantage of the APD method is that the provided capacity is not very high
due to only two pairs of peakezero points at most are employed for data hiding. This
limits its scope of application where a large quantity of data is to be embedded. In
fact, more pairs of peakezero points can be utilized. Motivated from this, we
designed a multilevel histogram modiﬁcation mechanism for large capacity data hid-
ing [41], which can be described in detail as follows.
FIGURE 2.6
The difference histogram of 512  512 Lena image.
82
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

2.4.3.1 Data Embedding
In our scheme, the inverse “S” order is adopted to scan the image pixels for differ-
ence generation. The secret data are binary sequences produced by a pseudo random
number generator. In the data-embedding stage, a multilevel histogram modiﬁcation
strategy is utilized. An integer parameter called embedding level EL (EL  0)
is involved to control the hiding capacity. A larger EL indicates that more secret
data can be embedded. As the embedding operations for EL > 0 are more
complicated than those of EL ¼ 0, we describe them for EL ¼ 0 and EL > 0
separately.
Step 1. Inverse “S” scan the image I into a pixel sequence p1, p2, ., pM  N.
Step 2. Compute the differences di (1  i  M  N) according to Eq. (2.16) and
construct a histogram based on di (2  i  M  N).
Step 3. Select an EL. If EL ¼ 0, execute Step 4. If EL > 0, go to Step 5.
Step 4. Data embedding for EL ¼ 0.
Step 4.1. Shift the right bins of b(0) rightward one level as:
d0i ¼
8
>
<
>
:
p1
if
i ¼ 1
di
if
di  0; 2  i  M  N
di þ 1
if
di > 0; 2  i  M  N
(2.17)
Step 4.2. Examine d’i ¼ 0 (2  i  M  N) one by one. Each difference
equaling 0 can be used to hide one secret bit. If the current processing secret
bit w ¼ 0, it is not changed. If w ¼ 1, it is added by 1. The operation is as:
d00i ¼
8
>
<
>
:
p1
if
i ¼ 1
d0i þ w
if
d0i ¼ 0; 2  i  M  N
d0i
if
d0is0; 2  i  M  N
(2.18)
The histogram modiﬁcation strategy for EL ¼ 0 is shown in Fig. 2.7aed where the
red and blue arrows indicate embedding “0” and “1,” respectively. After that, go to
Step 6.
Step 5. Data embedding for EL > 0.
Step 5.1. Shift the right bins of b(EL) rightward EL þ 1 levels, and shift the
left bins of b(EL) leftward EL levels as:
d0i ¼
8
>
>
>
<
>
>
>
:
p1
if
i ¼ 1
di
if
EL  di  EL; 2  i  M  N
di þ EL þ 1
if
di > EL; 2  i  M  N
di  EL
if
di < EL; 2  i  M  N
(2.19)
Step 5.2. Examine d’i ¼ 0 (2  i  M  N) in the range of [EL, EL] one by
one. The multilevel data-embedding strategy is described as follows.
2.4 Histogram ModiﬁcationeBased Schemes
83

Step 5.2.1. Embed the secret data as:
d00i ¼
8
>
>
>
<
>
>
>
:
p1
if
i ¼ 1
d0i
if
EL  d0i  EL; 2  i  M  N
2  EL þ w
if
d0i ¼ EL; 2  i  M  N
2  EL  w þ 1
if
d0i ¼ EL; 2  i  M  N
(2.20)
Step 5.2.2. EL is decreased by 1.
Step 5.2.3. If EL s 0, execute Steps 5.2.1 and 5.2.2 repeatedly. If EL ¼ 0,
execute Eq. (2.21) and then go to Step 6:
d00i ¼
8
>
<
>
:
p1
if
i ¼ 1
d0i þ w
if
d0i ¼ 0; 2  i  M  N
d0i
if
d0is0; 2  i  M  N
(2.21)
The histogram modiﬁcation strategy for EL ¼ 2 is shown in Fig. 2.8aeh, where the
red and blue arrows correspond to embedding “0” and “1,” respectively.
Step 6. Generate the marked pixels sequence p’ as:
p0
i ¼

p1
i ¼ 1
pi1  d00i
2  i  M  N
(2.22)
Step 7. Rearrange p’, and the marked image I0 is obtained.
–4
0
4
–4
0
4
–4
0
4
–4
0
4
(a)
(b)
(c)
(d)
FIGURE 2.7
Histogram modiﬁcation for EL ¼ 0.
84
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

2.4.3.2 Data Extraction and Image Recovery
The data extraction and image recovery is the inverse process of data embedding,
and the details are as follows.
Step 1. Inverse “S” scan the image I0 into a pixel sequence p’i (1  i  M  N).
Step 2. Receive the EL parameter from the encoder via a secure channel. If
EL ¼ 0, then execute Steps 3 and 4. If EL > 0, execute Steps 5 and 6.
(g)
(h)
(a)
(b)
(c)
(d)
(e)
(f)
–4
0
4
–4
0
4
–4
0
4
–4
0
4
–4
0
4
–4
0
4
–4
0
4
–4
0
4
FIGURE 2.8
Histogram modiﬁcation for EL ¼ 2.
2.4 Histogram ModiﬁcationeBased Schemes
85

Step 3. For EL ¼ 0, the host image pixels are recovered as:
pi ¼
8
>
<
>
:
p0
1
if
i ¼ 1
p0
i
if
pi1  p0
i  0; 2  i  M  N
p0
i þ 1
if
pi1  p0
i  1; 2  i  M  N
(2.23)
Step 4. For EL ¼ 0, the secret data is extracted as:
w ¼
 0
pi1  p0
i ¼ 0; 2  i  M  N
1
pi1  p0
i ¼ 1; 2  i  M  N
(2.24)
That is, if coming across pi1p’i ¼ 0 (2  i  M  N), a secret bit “0” is
extracted. If pi1p’i ¼ 1 (2  i  M  N), a “1” is extracted. Rearrange these
extracted bits, and the original secret sequence is obtained. After that, go to Step 7.
Step 5. For EL > 0, obtain the ﬁrst host pixel as p1 ¼ p’1. The marked differences
are computed as
d00i ¼

p0
1
i ¼ 1
pi1  p0
i
2  i  M  N
(2.25)
Then the original differences are obtained as
di ¼
8
>
>
>
<
>
>
>
:
d00i  EL  1
if
d00i > 2  EL þ 1; 2  i  M  N
d00i þ EL
if
d00i  2  EL; 2  i  M  N
r
if
d00i˛f2r; 2r þ 1g; r ¼ 0; 1; :::; EL; 2  i  M  N
r
if
d00i˛f 2r; 2r þ 1g; r ¼ 1; 2; :::; EL; 2  i  M  N
(2.26)
Next the host pixel sequence is recovered as
pi ¼

p0
1
i ¼ 1
p0
i1  di
2  i  M  N
(2.27)
Note Eqs. (2.23)e(2.25) are executed repeatedly, i.e., pi (2  i  M  N) is
recovered in advance, and then pi þ 1 is recovered with the aid of pi. In other
words, a sequential recovery strategy is utilized.
Step 6. For EL > 0, the secret data extraction is associated with EL þ 1 rounds.
First set the round index R ¼ 1.
Step 6.1. Extract the data as:
wR ¼
8
>
>
>
<
>
>
>
:
0
if
d00i ¼ 2  EL; 2  i  M  N
0
if
d00i ¼ 2  EL þ 1; 2  i  M  N
1
if
d00i ¼ 2  EL þ 1; 2  i  M  N
1
if
d00i ¼ 2  EL; 2  i  M  N
(2.28)
86
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

Step 6.2. EL is decreased by 1 and R is increased by 1.
Step 6.3. If EL s 0, execute Steps 6.1 and 6.2 repeatedly. If EL ¼ 0, execute
Eq. (2.29) as
wR ¼
 0
d00i ¼ 0; 2  i  M  N
1
d00i ¼ 1; 2  i  M  N
(2.29)
In Eq. (2.29), R is increased as EL þ 1.
Step 6.4. Rearrange and concatenate the extracted data wR (1  R  EL þ 1) as
w ¼ catðw1; w2; :::; wELþ1Þ
(2.30)
Hence, the hidden secret bits are obtained, and then go to Step 7.
Step 7. Rearrange the recovered sequence pi (1  i  M  N) into the host
image I.
2.4.3.3 Examples
Two examples for EL ¼ 0 and EL ¼ 2 are given to explain these principles with a
3  3 block investigated.
2.4.3.3.1 EL ¼ 0
1. Data embedding. The data-embedding principle for EL ¼ 0 is shown in Fig. 2.9.
First, the 3  3 block is inverse “S” scanned and the difference histogram is
constructed. Next, the histogram shifting is performed. Suppose the secret bits
are “10.” Thus the “1” can be hidden by changing the ﬁrst difference 0 to 1 and
the “0” is hidden by keeping the second difference 0 unchanged (marked as
red). In this way, each marked pixel can be produced by its left neighbor
55
55
2
3
3
2
2
3
0
1
1
0
0
–1
–1
–2
3
0
–1
–1
–2
2
0
–1
–1
–2
55
55
55
54
54
56
56
56
56
53
51
51
52
53
53
52
52
Pixel Scan
Difference
computation
Histogram
shifting
Embedding
“10”
Rearrange
54
53
55
55
53
53
54
56
56
54
52
52
51
51
53
54
56
56
53
52
FIGURE 2.9
Example of data embedding for EL ¼ 0.
2.4 Histogram ModiﬁcationeBased Schemes
87

subtracting the modiﬁed difference, as indicated by the blue arrows. Finally,
these marked pixels can be rearranged into the marked block.
2. Data extraction and image recovery. As shown Fig. 2.10, the marked block is
also inverse “S” scanned into a sequence ﬁrst. As the ﬁrst pixel is not changed
during embedding, we have p1 ¼ p’1 ¼ 55. Second, the difference
d’’2 ¼ p1  p’2 ¼ 3. Obviously, its counterpart d’2 ¼ 2. Thus the original pixel
associated with p’2 is p2 ¼ p1d’2 ¼ 53. Next, we obtain d’’3 ¼ p2p’3 ¼ 2, and
its counterpart d’3 ¼ 1. Then p3 ¼ p2d’3 ¼ 52. Repeat these operations for the
remaining marked pixels, and all the host pixels are recovered. In this example,
p1 is obtained ﬁrst, and then p2; p3, ., p9 are recovered consecutively. As
marked red in Fig. 2.10, 1 bit secret data “1” is extracted from p3p’4 ¼ 1, and a
“0” is extracted from p7p’8 ¼ 0.
2.4.3.3.2 EL ¼ 2
1. Data embedding. As shown in Fig. 2.11, EL is set as 2 to describe the data-
embedding operations for EL > 0. The inverse “S” scan and the difference
histogram construction are the same as those in EL ¼ 0. Next, the histogram is
shifted as follows: as EL ¼ 2, 3 is added to those differences that are larger than
2 (i.e., EL þ 1) and 2 is subtracted from those that are smaller than 2 (i.e., EL).
For example, d’2 ¼ d2þ3 ¼ 7, d’5 ¼ d5  2 ¼ 6.
Now the secret data can be embedded. Suppose the secret bits are “01101.” In the
ﬁrst round, only d’6 ¼ 2 and d’8 ¼ 2 are investigated for falling into [2, 2] (i.e.,
[EL, EL]). As “0” and “1”are embedded in d’6 and d’8, respectively, we obtain the
marked differences d’’6 ¼ 21 ¼ 3 and d’’8 ¼ 2 þ 3 ¼ 5. In the second round,
only d’7 ¼ 1 and d’9 ¼ 1 are investigated for falling into [1, 1] (i.e., [EL þ 1,
EL1]). As “1” and “0” are embedded in d’7 and d’9, respectively, we obtain
d’’7 ¼ 11 ¼ 2 and d’’9 ¼ 1 þ 1 ¼ 2. In the third round, only d’4 is investigated
Pixel Scan
Rearrange
54
54
53
53
54
53
53
52
52
52
51
51
51
51
52
52
52
56
56
56
56
55
55
55
53
53
54
54
56
56
53
53
54
56
56
55
55
3
2
2
1
0
2
1
–1
–1
–2
0
–1
–1
–2
0
3
Extracted bits: 1
0
FIGURE 2.10
Example of data extraction and image recovery for EL ¼ 0.
88
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

for equaling 0. As “1” is embedded in d’4, we obtain d’’4 ¼ 0 þ 1 ¼ 1. All the
marked differences are marked as red. Now each marked pixel can be produced
by its left neighbor host pixel subtracting the modiﬁed difference, as indicated
by the blue arrows. That is, as d’’ ¼ [80, 7, 6, 1,6,3,2, 5, 2] are produced,
the marked pixels are obtained as p01 ¼ p1; p02 ¼ p1  d002 ¼ 80  7 ¼ 73; p03 ¼
p2  d002 ¼ 76  6 ¼ 70; .; p09 ¼ p8  d009 ¼ 78  2 ¼ 76. At last, the marked
block is obtained by rearranging these marked pixels.
2. Data extraction and image recovery. The image pixel recovery for EL ¼ 2 is
shown in Fig. 2.12. The marked block is also inverse “S” scanned into a
sequence ﬁrst. Obviously, the ﬁrst pixel is not changed during embedding.
Second, the difference d’’2 ¼ p1p’2 ¼ 8073 ¼ 7. Its counterpart
d’2 ¼ 7(EL þ 1) ¼ 4. Thus the second host pixel is recovered as
p2 ¼ p1d’2 ¼ 76. Next, we obtain d’’3 ¼ p2  p’3 ¼ 6, and its counterpart
d’3 ¼ 3. Then p3 ¼ p2d’3 ¼ 73. Sequentially these operations are repeated for
the remaining marked pixels, and all the host pixels are recovered.
For EL ¼ 2, the secret data are extracted with three (i.e., EL þ 1) rounds. In the
ﬁrst round, EL is set as 2. As p5p’6 ¼ 2  EL þ1 ¼ 3, a secret bit “0” is
extracted from p5 and p’6. Besides, as p7p’8 ¼ 2  ELþ1 ¼ 5, a “1” is extracted
from p7 and p’8. These two secret bits w1 ¼ “ 01” ¼ are indicated as bold.
In the second round, EL is decreased by one and thus EL ¼ 1. As
p6p’7 ¼ 2  EL ¼ 2, a “1” is extracted from p6 and p’7. Besides, as
–3
80
80
80
80
80
80
80
7
6
1
–6
–3
–2
5
5
5
2
7
6
0
–6
7
6
0
–6
7
4
3
–4
6
0
0
–6
–3
–2
–2
–2
–1
–1
–1
2
2
2
80
73
70
72
79
80
81
75
76
80
80
79
75
76
72
81
73
70
Rearrange
Pixel Scan
76
76
73
73
73
73
77
78
77
77
79
78
77
80
80
79
1
1
1
Embedding
“1”
Embedding
“10”
Embedding
“01”
Histogram
shifting
Difference
computation
FIGURE 2.11
Example of data embedding for EL ¼ 2.
2.4 Histogram ModiﬁcationeBased Schemes
89

p8p’9 ¼ 2  EL ¼ 2, a “0” is extracted from p8 and p’9. The w2 ¼ “10” ¼ are indi-
cated as italic.
In the third round, EL is further decreased by 1 and thus EL ¼ 0. As p3p’4 ¼ 1,
a “1” is extracted from p3 and p’4. The w3 ¼ “1” ¼ is indicated as underlined.
The last step is to rearrange all the extracted bits as w ¼ cat(w1, w2, w3) ¼
“01101”. It is exactly the same as the original secret data.
2.4.3.4 Discussion
2.4.3.4.1 Capacity Estimation
The embedding capacity of our scheme is determined by two factors, the embedding
level and the peak points around b(0). If no overﬂow or underﬂow occurs, the capac-
ity Cap (bit) can be computed as
Cap ¼
8
>
<
>
:
bð0Þ
EL ¼ 0
X
EL
k¼EL
bðkÞ
EL > 0
(2.31)
2.4.3.4.2 Overﬂow and Underﬂow Prevention
Given a large EL, the operations of histogram bins empty and shifting may cause
overﬂow (i.e., p’ > 255) or underﬂow (i.e., p’ < 0). Actually, we can predict when
they appear. The overﬂow or underﬂow ﬁrst appears on the pixels with values
near 255 or 0. In particular, suppose pmax and pmin represent the maximum and
80
80
80
80
7
4
3
0
6
1
–6
–4
–2
–1
2
1
–3
–2
5
2
76
73
73
70
72
79
80
81
75
76
73
77
79
78
77
80
79
77
77
78
76
76
75
81
80
80
73
70
Pixel Scan
Rearrange
Rearranged extracted bits: 0 1 1 0 1
Extracted: 1
0
1
1
0
72
79
73
73
80
FIGURE 2.12
Example of data extraction and image recovery for EL ¼ 2.
90
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

minimum of the pixel values in I, respectively. In the worst case, the distortions on
pmax and pmin can be computed as
 p0
max ¼ pmax þ EL þ 1
p0
min ¼ pmin  EL
(2.32)
where p’max and p’min represent the marked pixels. When p’max  255 and p’min  0,
no overﬂow or underﬂow occurs, and consequently EL must be set as
EL  minð254  pmax; pminÞ
(2.33)
That is, EL should be no larger than the minimum of 254pmax and pmin. In other
words, if a host pixel has value belonging to [0, EL1], underﬂow may appear on it.
If belonging to [255EL, 255], overﬂow may appear.
In this work, the embedding level is tested as integers that are less than 10. This is
because with the EL increasing, the overﬂow and underﬂow problems becomes
increasingly prevalent. As a result, a lot of pixels with boundary values (i.e., near
255 or 0) in the cover image cannot be used for data embedding. Hence the capacity
will not be enhanced any longer. Moreover, the length of the compressed location
map is increased at the same time. As the compressed location map is also hiding
the cover image, the valid capacity for conﬁdential data hiding is also decreased.
Actually, EL selection depends on the cover image content. According to the exper-
imental results, EL can be set as an integer less than 10 on the average for providing
a maximum value of valid capacity. In our work, an M  N location map LM is used
for overﬂow and underﬂow prevention. Before data embedding, I is preprocessed. If
a pixel has value falling into [0, EL1] or [255EL, 255], it is excluded for data
embedding and a “1” is recorded in the LM, otherwise a “0” is recorded. After all
pixels are processed, a binary LM is generated. Obviously, a larger EL corresponds
to more “1”s and fewer “0”s in it. Next, the LM is losslessly compressed. In our case,
the arithmetic coding is used for its high efﬁciency. The compressed map LMc can be
also hidden in I. In particular, I is segmented into two parts, I1 and I2, for embedding
w and LMc, respectively. That is, some pixels in I2 are selected according to a secret
key, their LSB are replaced by LMc, and these LSB bits are hidden in I1 concatenated
with w. In decoder, the same key is used to retrieve the selected pixels’ LSB bits in I2
and thus LMc is reconstructed. After lossless decompression, LM is further obtained.
Then we can extract w and the original LSB bits of the selected pixels in I2. Finally,
the host image can be recovered by removing w from I1 and replacing LSB bits of the
selected pixels in I2 with the latter part of data extracted from I1.
2.4.3.5 Experimental Results and Comparison With Other Schemes
As shown in Fig. 2.13, six 512  512 gray level images are selected as test images.
Table 2.2 lists the capacity (bit) and PSNR (dB) values of the proposed scheme with
various ELs. From Table 2.2, we ﬁnd that a larger EL leads to a larger capacity. Even
for EL ¼ 9, the average PSNR is higher than 30 dB. As human eyes are not sensitive
to distortions when PSNR > 30 dB, the marked images’ visual qualities are
acceptable.
2.4 Histogram ModiﬁcationeBased Schemes
91

Our scheme is compared with two state-of-the-art methods proposed by Li et al.’s
method [40] and Kim et al.’s method [42]. The reason to compare with the method in
Ref. [40] is that both methods are based on inverse scan order. That is, the difference
histogram is exactly the same, whereas a multilevel histogram modiﬁcation strategy is
FIGURE 2.13
Test images, Lena, Barbara, Aerial, Goldhill, Airplane, Car (from left to right, from top to
bottom).
Table 2.2 Performance Comparison of Li et al.’s Method [40] and Our
Scheme
Method
Lena
Barbara
Aerial
Cap
PSNR
Cap
PSNR
Cap
PSNR
APD1
[40]
24,976
51.14
16,845
51.14
9247
51.13
APD2
[40]
48,383
48.55
33,113
48.41
18,110
48.28
Our
EL ¼ 0
24,976
51.14
16,845
51.14
9247
51.15
EL ¼ 1
71,727
44.84
49,062
44.61
27,183
44.40
EL ¼ 2
111,629
41.38
78,018
40.90
44,532
40.49
EL ¼ 3
143,182
39.20
102,547
38.49
60,684
37.87
EL ¼ 4
167,336
37.68
122,019
36.74
75,864
35.95
EL ¼ 5
185,073
36.56
137,108
35.38
90,160
34.45
EL ¼ 6
198,326
35.68
148,842
34.28
103,499
33.23
EL ¼ 7
208,079
34.97
157,873
33.34
115,700
32.21
EL ¼ 8
215,528
34.37
165,031
32.54
126,803
31.35
EL ¼ 9
221,413
33.85
170,783
31.82
137,316
30.60
92
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

used in our scheme. Hence the performance improvement achieved by this novel strat-
egy is validated in our work. In addition, the reason to compare with the method of
Ref. [42] is that both methods adopt similar multilevel histogram modiﬁcation strate-
gies. However, as our scheme is based on a pixelwise differential mechanism instead of
blockwise processing in Ref. [42], the capacity and the quality of marked images are
enhanced simultaneously as proved in the following experimental results. First, our
scheme is compared with Li et al.’s method [40] for both are based on APD histogram
modiﬁcation. In Ref. [40], only two cases, APD1 and APD2, are provided for data
embedding. Here APD1 and APD2 denote that one and two pairs of peakezero
points are used, respectively. The comparison results are also given in Table 2.2.
Our scheme can provide a higher capacity than Li et al.’s method with good marked
images quality.
Next, our scheme is compared with Kim et al.’s method [42]. Although both
are based on multilevel histogram modiﬁcation, the histogram construction mec-
hanisms are different. In general, the capacity of difference histogram modiﬁcation
is jointly affected by the total number of differences and their concentricity to b(0).
In Ref. [42], the differences are computed based on subimages’ correlation, and
hence the number of differences is determined by the number of subimages. For
example, if a 512  512 host image is subsampled into 16 equal-sized subimages,
there are 512  512  15/16 ¼ 245,760 differences produced. In contrast, there
are 512  5121 ¼ 262,143 differences produced in our scheme. The histogram
bins belonging to [b(30), b(30)] obtained by Ref. [42] and our scheme are shown
in Fig. 2.14. Obviously, more differences in our histograms are concentrated around
b(0). As a result, a larger capacity can be provided in our scheme than in Ref. [42].
Moreover, b(1) is emptied after embedding in Ref. [42] because the leftward shift
is one level farther than that in our scheme, and consequently the introduced distor-
tions are more serious.
The performance comparisons of our scheme (marked as blue) and Kim et al.’s
method (marked as red) are shown in Figs. 2.15e2.20. The horizontal axis denotes
that the EL set from 0 to 9. The vertical axes of capacity and PSNR are normalized as
[0, 1.0] bpp and [30,55] dB, respectively. In these experiments, the host images are
partitioned into 16 equal-sized subimages in Ref. [42]. All these results demonstrate
that not only the capacity but also the PSNR is improved. In other words, even
though more secret data are embedded in our scheme, the quality of marked images
is still better than the qualities of those in Ref. [42].
2.4.4 HYBRID PREDICTION AND INTERLEAVING HISTOGRAM
MODIFICATIONeBASED SCHEME
In the conventional histogram shiftingebased scheme [43], the histogram of the
cover image pixel values is constructed in advance. Then, one or several pairs of
peakezero points of the histogram are found and exploited to insert conﬁdential
data. However, as the height of peak points are image dependent, the capacity ob-
tained in this prototype is relatively low. Hereafter, efforts focus on how to construct
2.4 Histogram ModiﬁcationeBased Schemes
93

a histogram with higher peak points. One efﬁcient solution is based on prediction
[44]. In particular, the histogram is constructed based on the statistics of prediction
errors, and the histogram shifting is reduced to the task of modifying them. To
further enhance the capacity, a multilevel histogram mechanism is applied in
Ref. [42]. To overcome the disadvantages, we proposed a reversible data hiding
FIGURE 2.14
Histogram bins of [b(30), b(30)] obtained by Kim et al.’s scheme [42] (marked as red
Gray in print versions) and our scheme (blue Black in print versions) on Lena, Barbara,
Aerial, Goldhill, Airplane, and Car.
94
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

FIGURE 2.15
Comparison of Kim et al.’s scheme [42] and our scheme on Lena image.
FIGURE 2.16
Comparison of Kim et al.’s scheme [42] and our scheme on Barbara image.
FIGURE 2.17
Comparison of Kim et al.’s scheme [42] and our scheme on Aerial image.
2.4 Histogram ModiﬁcationeBased Schemes
95

FIGURE 2.18
Comparison of Kim et al.’s scheme [42] and our scheme on Goldhill image.
FIGURE 2.19
Comparison of Kim et al.’s scheme [42] and our scheme on Airplane image.
FIGURE 2.20
Comparison of Kim et al.’s scheme [42] and our scheme on Car image.
96
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

scheme based on the prediction in Ref. [45]. The cover image with the exception of a
seed pixel is partitioned into four segments. Then, a hybrid prediction strategy is
employed to predict the approximate values with different predictors. A histogram
is constructed based on the prediction errors, and an interleaving histogram modi-
ﬁcation mechanism is designed for data embedding. In this way, a good trade-off
can be achieved between a high capacity and an acceptable quality of marked
images.
In prediction-based reversible data hiding methods, the capacity jointly depends on
the number of errors and the concentricity of them around zero. Motivated by this, it is
necessary to reduce the number of seeds, and meanwhile, to yield errors equaling or
close to zero with a high frequency of occurrence. The prediction in our scheme is
triggered by a single seed pixel and then spreads all over the cover image.
As shown in Fig. 2.21 (left), the cover image I is partitioned into ﬁve disjoint seg-
ments (S, A, B, C, and D for short). The prediction of the current processing pixel p
can be explained with a 3  3 image block as shown in Fig. 2.21 (right), where p is
disposed in the center surrounded by eight neighbors n1, n2, ., n8. Some of these
neighbors are used for engendering the approximate value pc of p via various predic-
tors. Speciﬁcally, the pixels in A and B are predicted with one neighbor as
pc ¼
 n4
if
pc˛A
n2
if
pc˛B
(2.34)
The pixel in C is predicted by the median edge detection predictor [46] as
pc ¼
8
>
<
>
:
minðn2; n4Þ
if
n1  maxðn2; n4Þ
maxðn2; n4Þ
if
n1  minðn2; n4Þ
n2 þ n4  n1
otherwise
(2.35)
FIGURE 2.21
Five-segment partition of an image (left) and a 3  3 image block (right).
2.4 Histogram ModiﬁcationeBased Schemes
97

The pixel in D is predicted with four neighbors as
pc ¼ roundðð2n2 þ 2n4 þ n1 þ n3Þ=6Þ
(2.36)
where “round(•)” means rounding off its element to the nearest integer. Note the pre-
dicted value of ps is set as itself. In this way, as all pixels of I are predicted, a pre-
dicted image Ip can be obtained. The prediction error e is calculated as
e ¼ pc  p
(2.37)
2.4.4.1 Data Embedding
Given a cover image I and conﬁdential data W, the procedures are as follows.
Step 1. Partition I into S, A, B, C, and D, and generate a prediction error image.
Step 2. Construct a histogram according to these errors with the exception of the
left and topmost one. Suppose the histogram bins (corresponding heights) from
left to right are denoted as b255(h255), ., b0(h0), ., b255(h255). An integer
parameter termed embedding level (EL for short) is introduced that is estab-
lished depending on the size of conﬁdential data. Here, we initialize EL ¼ 1. Let
F denote the ﬂooring operation. Assume rem denotes the embedding round
index and rem ¼ F(EL/2).
Step 3. Compute the capacity Cap as
Cap ¼
8
>
>
>
>
>
<
>
>
>
>
>
:
P
FðEL=2Þ
k¼FðEL=2Þ
hk
if
ELmod 2 ¼ 1
X
FðEL=2Þ
k¼FððEL1Þ=2Þ
hk
if
ELmod 2 ¼ 0
(2.38)
Step 4. If Cap is larger than the size of W, then go to Step 5. Otherwise EL in-
crease by 1 and return to Step 3.
Step 5. Empty the associated histogram bins for data embedding. Now EL is
ﬁnally determined. If it is an odd, the error e is modiﬁed into e’ as
e0 ¼
8
>
<
>
:
e þ FðEL=2Þ
if
e > FðEL=2Þ
e  FððEL þ 1Þ=2Þ
if
e < FðEL=2Þ
e
otherwise
(2.39)
If EL is an even, e is modiﬁed as
e0 ¼
8
>
<
>
:
e þ FðEL=2Þ
if
e > FðEL=2Þ
e  FðEL=2Þ
if
e < FððEL  1Þ=2Þ
e
otherwise
(2.40)
Step 6. Shift peak point bins according to conﬁdential bits. The peak bins from
the center to both sides (i.e., b0, b1, b1, b2, b2, .) are interleaving tagged as
1, 2, ., EL. The bins with odd tags are shifted leftward, whereas those with
98
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

even tags are shifted rightward. The tagged bin that is farther away from b0
indicates higher shifting priority. For example, given EL ¼ 7, the shifting order
is b3/b3/b2/b2/b1/b1/b0. If EL > 1, several rounds are involved
in the embedding process. If EL is odd, go to Step 6.1; otherwise go to Step 6.2.
Step 6.1. For an odd EL, a special case of EL ¼ 1 must be considered. If
EL ¼ 1, only one round is required for data embedding and e’ is modiﬁed as
e00 ¼
 e0  w
if
e0 ¼ 0
e0
otherwise
(2.41)
where w denotes the current bit to be embedded. If EL > 1, modify e’ as
e00 ¼
8
>
<
>
:
e0 þ rem  1 þ w
if
e0 ¼ rem
e0  rem  w
if
e0 ¼ rem
e0
otherwise
(2.42)
Then rem is decreased by 1. If the updated rem > 0, execute Eq. (2.42) repeatedly. If
the updated rem ¼ 0, execute Eq. (2.41) and then go to Step 7.
Step 6.2. For an even EL, e’ is modiﬁed as
e00 ¼
8
>
<
>
:
e0 þ rem  1 þ w
if
e0 ¼ rem
e0  rem  w þ 1
if
e0 ¼ rem þ 1
e0
otherwise
(2.43)
Then rem is decreased by 1, and execute Eq. (2.43) repeatedly until rem ¼ 0. If the
updated rem ¼ 0, go to Step 7.
Step 7. Generate the marked pixel pw according to e’’ and pc as
pw ¼ pc  e00
(2.44)
Step 8. Repeat Steps 5e7 for all the cover pixels, and thus the marked image Iw is
obtained. So far the phase of data embedding is completed.
2.4.4.2 Data Extraction and Image Recovery
This phase is to remove the conﬁdential data from the marked images and re-
construct the cover image losslessly. As a whole, the segments A and B are ﬁrst
derived, and then C and D. This is because some pixels of C and D are recovered
with the aid of recovered pixels of A and B. Speciﬁcally, the pixels of A and B are
recovered one by one from left to right and from top to bottom, respectively. The
pixels of C and D are recovered with raster scan order. Suppose Iw obtained in
the decoder is intact. The details of image recovery and data extraction are described
as follows.
Step 1. Obtain the parameter EL from the encoder via a secure channel. Retrieve
the seed pixel ps and partition the rest of Iw into four segments A, B, C, and D.
2.4 Histogram ModiﬁcationeBased Schemes
99

Step 2. Recover the pixels of A one by one. If the current processing marked pixel
pw belongs to A, initialize the value of pc ¼ ps, then compute e’’ as
e00 ¼ pc  pw
(2.45)
If EL is odd, calculate the original error e as
e ¼
8
>
<
>
:
e00  FðEL=2Þ
if
e00 > EL  1
e00 þ FððEL þ 1Þ=2Þ
if
e00 < EL
Fððe00 þ 1Þ=2Þ
if
 EL  e00  EL  1
(2.46)
If EL is even, calculate e as
e ¼
8
>
<
>
:
e00  FðEL=2Þ
if
e00 > EL
e00 þ FðEL=2Þ
if
e00 < EL þ 1
Fððe00 þ 1Þ=2Þ
if
 EL þ 1  e00  EL
(2.47)
Then the recovered pixel p can be obtained as
p ¼ pc  e
(2.48)
After that, go to process the next marked pixel and repeat the previous steps for
all the marked pixels in this segment.
Step 3. Recover the pixels of B as those of A. The only difference is that
the prediction value of the current processing pixel is its upper neighbor
instead of the left one. Note that the recovery of A and B can be processed in
parallel.
Step 4. Recover the pixels of C and D. If the current processing pw belongs to C,
predict its approximate value pc according to Eq. (2.35). If it belongs to D,
obtain the prediction values pc by means of Eq. (2.36). Then compute e’’ with
Eq. (2.45). Next, reconstruct e according to Eq. (2.46) or Eq. (2.47). At last,
recover the original pixel with Eq. (2.48). All the pixels of C and D are
recovered one by one in a sequential order of raster scan.
Step 5. Recover the cover image I by recomposing S, A, B, C, and D.
Step 6. The conﬁdential data extraction is associated with e’’. A given EL may
correspond to several rounds of data extraction that is opposite to embedding.
Initialize the extraction round index rex ¼ 1 and a variable t ¼ EL. If EL is odd,
go to Step 6.1, otherwise go to Step 6.2.
Step 6.1 For an odd EL, if EL ¼ 1, one round data extraction is implemented
as
wrex ¼
 1
if
e00 ¼ 1
0
if
e00 ¼ 0
(2.49)
If EL > 1, the rex-th round data extraction is implemented as
100
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

wrex ¼
 1
if
e00˛ft  1; tg
0
if
e00˛ft  2; t þ 1g
(2.50)
Then, t is decreased by 2 and rex is increased by 1 at the same time. If t s 1, execute
Eq. (2.50) repeatedly. If t ¼ 1, execute Eq. (2.49).
Step 6.2 For an even EL, the rexth round data extraction is implemented as
wrex ¼
 1
if
e00 ¼ t
0
if
e00 ¼ t  1
(2.51)
Then, t is decreased by 2 and rex is increased by 1. If t s 0, execute Eq. (2.52).
wrex ¼
 1
if
e00˛ft; t  1g
0
if
e00˛ft  1; tg
(2.52)
Then, t is decreased by 2 and rex is increased by 1. If t s 0, execute Eq. (2.52)
repeatedly. If t ¼ 0, execute Eq. (2.49).
In short, no matter what the parity of a positive EL is, the variable t is changed from
an odd EL to 1 or an even EL to 0, in steps of two at a time. Therefore, the cor-
responding extraction round index rex is changed from 1 to F(EL/2) þ 1. Thus,
there are also totally F(EL/2) þ 1 rounds of extraction processing. That is, sym-
metry exists between data embedding and extraction.
Step 7. Rearrange and concatenate the extracted data as
W ¼ w1

w2

.

wFðEL=2Þþ1
(2.53)
2.4.4.3 Experimental Results and Comparisons
As shown in Fig. 2.13, a set of 512  512 gray level natural images is selected as test
images to evaluate the performance of our scheme. The conﬁdential data are binary
sequences produced by a pseudo random number generator. Our scheme is
compared with that in Ref. [42] as the results shown in Fig. 2.22. Given an
EL, not only the capacities but also the PSNR values of marked images in our
scheme are higher than those obtained by Ref. [42] with 4  4 block partition.
The improvement is led by more errors concentrated around zero and used for
data embedding.
Our scheme is also compared with those in Refs. [40,47] as the results shown in
Fig. 2.23. Obviously, our scheme’s capacityePSNR curves are superior to the coun-
terparts of the three predictors in Ref. [47]. Besides, the comparison with Ref. [48] is
shown in Table 2.3. On average, the capacity provided by Ref. [48] and our scheme
are 40,978 and 47,597 bits, respectively. Nevertheless, the corresponding PSNR
values are 48.51 and 48.55 dB, respectively. All the results of our scheme are ob-
tained with EL ¼ 2. Clearly both performance indicators are enhanced.
2.4 Histogram ModiﬁcationeBased Schemes
101

2.5 LOSSLESS COMPRESSIONeBASED SCHEMES
2.5.1 LOSSLESS BIT-PLANE COMPRESSION IN THE SPATIAL
DOMAIN
Fridrich’s group produced profound research on lossless data hiding techniques and
developed a number of algorithms. This group proposed two techniques in this area
[6]. The ﬁrst technique, based on robust spatial additive watermarks, utilizes the
modulo addition to embed the hash of the original image. The second technique
uses the JBIG Lossless Compression Scheme [49] for losslessly compressing the
FIGURE 2.22
Comparison of Ref. [42] and our scheme on Lena, Barbara, Aerial, Goldhill, Airplane, and
Truck (from left to right, from top to bottom).
102
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

bit-planes to make room for data embedding. To provide sufﬁcient room for data
embedding for the second technique, it is usual to compress the high level bit-
plane. This mostly leads to visual quality degradation. Since the method aims at
authentication, the amount of embedded data is limited.
FIGURE 2.23
Comparison of our scheme with Ref. [47] (the top two ﬁgures) and Ref. [40] (the bottom
two ﬁgures).
Table 2.3 Comparison of Ref. [48] and Our Scheme
Image
Hong et al.’s Scheme
Our Scheme (EL [ 2)
Capacity (bit)
PSNR (dB)
Capacity (bit)
PSNR (dB)
Lena
51,809
48.60
64,348
48.70
Barbara
38,184
48.48
44,356
48.51
Aerial
17,853
48.30
20,586
48.30
Goldhill
35,999
48.46
39,184
48.47
Airplane
65,319
48.73
79,866
48.85
Truck
36,701
48.46
37,243
48.45
Average
40,978
48.51
47,597
48.55
2.5 Lossless CompressioneBased Schemes
103

2.5.2 LOSSLESS RS-DATA EMBEDDING METHOD
Goljan et al. [37] presented the ﬁrst lossless marking technique suitable for data
embedding. They generated loss-free compressible bitstreams using the concepts
of invertible noise adding or ﬂipping. Special discrimination or prediction functions
were also used on small groups of pixels. The new approach is much more efﬁcient
when allowing for large payload with minimal or invertible distortion.
The details are as follows. The pixels in an image with size M  N are partitioned
into nonoverlapped n groups, each of which consist of adjacent pixels (x1, x2,., xn).
For instance, it could be a horizontal block having four consecutive pixels. A
discrimination function f is established that assigns a real number f (x1, x2,.,
xn) ˛ ℝto each pixel group G(x1, x2,., xn).
The authors use the discrimination function to capture the smoothness of the
groups. For example, the “variation” of the group of pixels (x1, x2,., xn) can be cho-
sen as the discrimination function f($):
fðx1; x2; .; xnÞ ¼
X
n1
i¼1
jxiþ1  xij
(2.54)
The purpose of the discrimination function is to capture the smoothness or “reg-
ularity” of the group of pixels G. An invertible operation F with the amplitude A can
be applied to the groups. It can map a gray level value to another gray level value. It
is reversible applying it to a gray level value twice produces the original gray level
value. That is, F has the property that F2 ¼ Identity or F(F(x)) ¼ x, for all x ˛P,
where P ¼ {0, 1,., 255}, for an 8-bit grayscale image. This invertible operation
is called ﬂipping F. The difference between the ﬂipped values and the original values
is A.
A suitably chosen discrimination function f($) and the ﬂipping operation F are
utilized to deﬁne three types of pixel groups: Regular R, Singular S, and Unusable U.
Regular groups: G ˛ R 5 f (F(G)) > f(G);
Singular groups: G ˛ S 5 f (F(G)) < f(G);
Unusable groups: G ˛ U 5 f (F(G)) ¼ f(G).
From the deﬁnitions of the R, S, and U groups, it is apparent that if G is regular,
F(G) is singular; if G is singular, F(G) is regular; and if G is unusable, F(G) is un-
usable. Thus, the R and S groups are ﬂipped into each other using the ﬂipping oper-
ation F. The unusable groups U do not change their status. In a symbolic form,
F(R) ¼ S, F(S) ¼ R, and F(U) ¼ U.
In the expression F(G), the ﬂipping function F may be applied to all or to
selected components of the vector G(x1, x2,., xn). The noisier the group of pixels
G(x1, x2,., xn) is, the larger the value of the discrimination function becomes.
The purpose of the ﬂipping F is to perturb the pixel values in an invertible way
by a small amount thus simulating the act of “Invertible Noise Adding.” In typical
pictures, adding small amount of noise, or ﬂipping by a small amount, will lead
to an increase in the discrimination function rather than to a decrease. Although
104
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

this bias may be small, it will enable us to embed a large amount of information in an
invertible manner.
As explained previously, F is a permutation that consists entirely of two cycles.
For example, the permutation FLSB is deﬁned as 0 4 1, 2 4 3,., 254 4 255 cor-
responds to ﬂipping or negating the LSB in each gray level. The permutation corre-
sponds to an invertible noise with an amplitude larger than 2. The amplitude A of the
ﬂipping permutation F is deﬁned as 0 4 2, 1 4 3, ., 253 4 255. The average
change under the application of F is:
A ¼ 1
jPj
X
x˛P
jx  FðxÞj
(2.55)
For FLSB the amplitude is 1. The other permutation from the previous paragraph
has A ¼ 2. Larger values of the amplitude A correspond to the action of adding more
noise after applying F.
The main idea for lossless embedding is that the image by groups can be scanned
according to a predeﬁned order and the status of the image can be losslessly com-
pressed. The bitstream of R and S groups or the RS vector with the U groups may
be skipped. This may be considered as the overhead needed to leave room for
data embedding. It is not necessary to include the U groups, because they do not
change in the process of message embedding and can be all unambiguously identi-
ﬁed and skipped during embedding and extraction. The higher a bias between the
number of R and S groups, the lower the capacity consumed by the overheads and
the higher the real capacity. By assigning a 1 to R and a 0 to S they embed one mes-
sage bit in each R or S group. If the message bit and the group type do not match, the
ﬂipping operation F is applied to the group to obtain a match. The data to be
embedded consist of the overhead and the watermark signal.
The extraction starts by partitioning the watermarked image into disjoint groups
using the same pattern as used in the embedding. They apply the ﬂipping operation F
and discrimination function f to all groups to identify the R, S, and U groups. They
then extract the bitstream from all R and S groups (R ¼ 1, S ¼ 0) by scanning the im-
age in the same order as embedding. The extracted bitstream is separated into the
message and the compressed RS vector C. The bitstream C is decompressed to reveal
the original status of all R and S groups. The image is then processed once more, and
the status of all groups is adjusted as necessary by ﬂipping the groups back to their
original state. Thus, an exact copy of the original image is obtained. The block di-
agram of the embedding and extracting procedure is given in Fig. 2.24.
Let NR, NS, and NU be, respectively, used to indicate the number of regular, sin-
gular, and unusable groups in the image. The sum of NR, NS, and NU is equal to MN/n
(the number of all groups). The raw information capacity for this data embedding
method is NR þ NS ¼ MN/n  NU bits. However, since the compressed bitstream
C consumes a large part of the available capacity, the real capacity Cap that can
be used for the message is given by
Cap ¼ NR þ NS  jCj
(2.56)
2.5 Lossless CompressioneBased Schemes
105

Embedding
 Extraction
Image
Extract
Groups
Compute
RS-vector
Compress
RS-vector
Flip
Groups
Optional Key Flipping Function
Message bits
Stego Image
Original
Image
Extract
Groups
Compute
RS-vector
Decompress
RS-vector
Unflip
Groups
Optional Key Flipping Function
Message bits
Stego Image
(a)
(b)
FIGURE 2.24
Diagram for the distortion-free data embedding and extraction algorithm.
where jCj is the length of the bitstream. A theoretical estimate or an upper bound
C’ap for the real capacity is
C0ap ¼ NR þ NS þ NR log

NR
NR þ NS
	
þ NS log

NS
NR þ NS
	
(2.57)
An ideal lossless context-free compression scheme (the entropy coder) would
compress the RS vector consisting of (NR þ NS) bits using NR log

NR
NRþNS
	

NS log

NS
NRþNS
	
bits.
This estimate for C’ap will be positive whenever there is a bias between the num-
ber of R and S groups, or when NR ¼ NS. This bias is inﬂuenced by the size and shape
of the group G, the discrimination function f, the amplitude of the invertible noisy
permutation F, and the content of the original image. The bias increases with the
group size and the amplitude of the permutation F. Smoother and less noisy images
lead to a larger bias than images that are highly textured or noisy.
In a practical application, for some natural images, by deﬁning a different
discrimination function f, choosing the group size, selecting the number of the pixels
that should be ﬂipped, or selecting embedding mask M ¼ [A1, A2, ., An], for
example, the embedding capacity can be further improved.
The method provides a high embedding capacity while introducing a very small
and invertible distortion. A number of experimental results show that the highest ca-
pacity was obtained for relatively small groups where n is approximately equal to 4.
2.5.3 LOSSLESS G-LSB DATA EMBEDDING METHOD
Celik et al. [7] presented a high-capacity, low-distortion reversible data hiding tech-
nique. A G-LSB modiﬁcation is proposed as the data embedding method. Lossless
106
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

recovery of the host signal is achieved by compressing the lowest levels instead of
the bit-planes of the signal. The levels chosen were those susceptible to embedding
distortion and transmitting the resulting compressed bitstream as part of the embed-
ding payload. The CALIC compression algorithm, which uses the unaltered portions
of the host signal as side information, improves the compression efﬁciency and, thus,
the data embedding capacity.
2.5.3.1 G-LSB Embedding
A generalization of LSB-embedded method, namely, G-LSB, is employed by Celik
et al. [7]. If the host signal is represented by a vector, G-LSB embedding and extrac-
tion can be represented as
sw ¼ QLðsÞ þ w
(2.58)
w ¼ sw  QLðswÞ
(2.59)
where sw represents the signal containing the embedded information and w repre-
sents the embedded payload vector of L-ary symbols. That is, wi ˛ {0, 1,.,
L1}, and
QLðxÞ ¼ L
jx
L
k
(2.60)
is an L-level scalar quantization function and P$R represents the operation of trunca-
tion to the integer part.
In the embedding procedure given in Eq. (2.58), for L-ary watermark symbols wi, it
is necessary for them to be converted into binary bitstream, and vice versa, in some
practical applications. The following binary to L-ary conversion algorithm can effec-
tively avoid out-of-range sample values produced by the embedding procedure. For
instance, in an 8 bpp representation where the range is [0, 255], if operating parameters
L ¼ 6, QL(s) ¼ 252, w ¼ 5 are used, the output sw ¼ 257 exceeds the range [0, 255].
The binary to L-ary conversion is presented as follows:
The binary input string h is interpreted as the binary representation of a number
H in the interval R ¼ [0, 1]. That is, H ¼ .h0h1h2. and H ˛ [0, 1]. The signal is
encoded using integer values between 0 and smax.
1. Given s and smax, determine QL(s) and N ¼ min(L, smax  QL(s)) the number of
possible levels.
2. Divide R into N equal subintervals, R0 to RN1.
3. Select the subinterval that satisﬁes H ˛ Rn.
4. The watermark symbol is w ¼ n.
5. Set R ¼ Rn and then go to Step 1, for the next sample.
The conversion process is illustrated in Fig. 2.25. This process involves the
following steps.
1. Given s and smax, determine QL(s) and N ¼ min(L, smax  QL(sw)) which is the
number of possible levels.
2.5 Lossless CompressioneBased Schemes
107

2. Divide R into N equal subintervals, R0 to RN1.
3. Set R ¼ Rw, where w ¼ sw  QL(sw) is the current watermark symbol.
4. If there are remaining symbols, go to Step 1. Find the shortest binary string
H ˛ R.
The classical LSB modiﬁcation, which embeds a binary symbol (bit) by over-
writing the LSB of a signal sample, is a special case. Here L ¼ 2. G-LSB embedding
enables the embedding of a noninteger number of bits in each signal sample. Thus, it
introduces new operating points along the rateedistortion or capacityedistortion
curve.
2.5.3.2 Lossless G-LSB Data Embedding and Extraction
Fig. 2.26 shows a block diagram of the proposed algorithm. In the embedding phase,
the host signal is quantized, and the residual is obtained as follows:
r ¼ s  QLðsÞ
(2.61)
Then they adopt the CALIC lossless image compression algorithm. This has the
quantized values as side information, to efﬁciently compress the quantization resid-
uals to create high capacity for the payload data. The compressed residual and the
payload data are concatenated and embedded into the host signal using the
G-LSB modiﬁcation method. The resulting bitstream is converted to L-ary symbols
as mentioned previously. This is then added to the quantized host to form the water-
marked signal sw in Eq. (2.58). Note that the compression block uses the rest of the
host signal, QL(s), as side information, to facilitate better compression and higher
capacity.
In the extraction phase, the watermarked signal sw is quantized and the water-
mark payload h, which is the compressed residual and the payload data, is extracted
H= .h0h1h2...
1
0
..........
H
H
N=3
w0=1
N=2
w1=0
N=3
w2=1
FIGURE 2.25
Binary to L-ary conversion using a variant of arithmetic encoding.
108
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

s
Quantize
Q(s)
+
-
+
Compress
r
h
Append&
Translate
+
sw
w
+
+
sw
Quantize
Q(sw)
+
-
+
Decompress
w
h
Translate 
&Partition
+
s
r
+
+
FIGURE 2.26
(Top) Embedding phase and (bottom) extraction phase of the proposed lossless data-
embedding algorithm.
in Eq. (2.61). The residual r is decompressed by QL(sw) ¼ s  QL(s) as side informa-
tion. The original host is reconstructed by replacing the lowest levels of the water-
marked signal by the residual as follows:
s ¼ QLðsÞ þ r ¼ QLðswÞ þ r
(2.62)
The lossless embedding capacity of the system is given by
CLossless ¼ CGLSB  Cresidual
(2.63)
where CLossless is the raw capacity of G-LSB embedding (CGLSB ¼ log2(L)) and
Cresidual is the capacity consumed by the compressed residual. To further improving
the lossless embedding capacity, Celik et al. adopt the CALIC lossless image
compression algorithm [49,50]. This uses the unaltered portions of the host signal,
QL(s) as side information, to efﬁciently compress the residual.
From what is reported in Ref. [7], Celik et al. applied several test images, F-16,
Mandrill, and Barbara, to the lossless G-LSB algorithm with its selective embedding
extension; Celik et al. compared the results with the RS embedding scheme [37].
The amplitude of the ﬂipping function varied from 1 to 6. The lossless G-LSB algo-
rithm at 100% embedding outperforms the RS embedding scheme from a capacity
distortion perspective at most points except for the lowest distortion points at A ¼ 1
and L ¼ 2. The reason is that RS embedding modiﬁes the pixels corresponding to the
R and S groups while skipping the U groups. By modifying the embedding extension
from 100% to 75%, the lossless G-LSB algorithm slightly surpasses RS embedding
at the lowest distortion points. From the aforementioned description, the LGLSB
(lossless G-LSB) algorithm can operate at a speciﬁed distortion value by ﬂexibly
modifying the embedding intensity, or an extension at a given level. The LGLSB
also has an advantage over the RS embedding scheme in embedding capacity for
a comparable distortion and computational complexity. The LGLSB algorithm
2.5 Lossless CompressioneBased Schemes
109

can achieve embedding capacities exceeding 1 bpp, whereas the embedding capac-
ity of RS was less than 1 bpp.
2.5.4 LOOK-UP TABLE-BASED SCHEME FOR ERROR DIFFUSED
HALFTONE IMAGES
To improve the hiding performance, we presented a hybrid-based method in
Ref. [51]. The original idea is motivated from the R-S algorithm developed in Fri-
drich et al. [6]. First, a look-up table (LUT) is constructed. It consists of pairs of
similar block patterns that are selected according to the statistics combining charac-
teristics of the human visual system (HVS). We use “0” and “1” to denote the states
of two group patterns of the LUT. Second, we search all blocks in the image: if one is
the same as some pattern in the LUT, record its state. Thus a state sequence can be
obtained. Third, this sequence is losslessly compressed and the saved space is ﬁlled
with the hidden data and some AI. Here the AI refers to extra data aroused by the
LUT embedding. Fourth, data is hidden by similar patterns toggling with reference
to the new sequence. The last step is to insert the LUT with a secret key, and mean-
while the watermarked halftone image is obtained. In the data extraction stage, the
LUT must be re-created ﬁrst and other procedures are just the inverse process of data
hiding. As a reversible technique, the original image can be perfectly recovered if
the watermarked version is intact. Furthermore, our approach is also easily extended
for halftone image authentication, e.g., hiding a hash sequence. The detailed proced-
ure can be described as follows.
2.5.4.1 Pattern Histogram
The original image is partitioned into a set of nonoverlapping 4  4 blocks. This step
aims to choose some appropriate blocks to embed data. Obviously a 4  4 block has
totally 216 different patterns. In most cases, a majority of patterns never appear or
appear only once in an image. We rearrange a 4  4 block into a binary sequence,
and transform it into a decimal integer. Therefore, each pattern is uniquely associ-
ated with an integer in the range of [0, 216  1], which we call a pattern index
(PI). Each PI is associated with a value named the number of appearance times
(NAT) of this pattern in the image. The NAT is counted for each PI, and thus the
pattern histogram (PH) can be constructed. Fig. 2.27 shows the PHs of six
512  512 halftone images with the x- and y-axes denoting the PI and the NAT,
respectively. It is obvious that a small portion of patterns appears many
times, whereas others appear rarely. This statistics feature can be employed to insert
data.
2.5.4.2 Human Visual System Characteristics
According to the study on the HVS [52], the spatial frequency sensitivity of human
eyes is usually estimated as a modulation transfer function. Speciﬁcally, the impulse
response to a printed image of 300 dpi at a viewing distance of 30 in. is virtually
110
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

FIGURE 2.27
Pattern histograms of Lena, Airplane, Baboon (top row, from left to right), Boat, Pepper, and Barbara (lower row, from left to right).
2.5 Lossless CompressioneBased Schemes
111

identical to that of a Gaussian ﬁlter with s ¼ 1.5 and s ¼ 0.0095. In our method, we
adopt the 5  5 visual response ﬁlter given in Ref. [53] as follows:
f ¼
1
11:566
2
6666664
0:1628
0:3215
0:4035
0:3215
0:1628
0:3215
0:6352
0:7970
0:6352
0:3215
0:4035
0:7970
1
0:7970
0:4035
0:3215
0:6352
0:7970
0:6352
0:3215
0:1628
0:3215
0:4035
0:3215
0:1628
3
7777775
(2.64)
2.5.4.3 Look-Up Table Construction
Based on the statistics of the PH and HVS characteristics, some patterns are chosen and
classiﬁed into two groups, H and L. Suppose H ¼ {h1, h2, .,hu} denotes the group
with the ﬁrst u biggest NATs, and ni denotes the NAT of pattern hi; obviously we have
nk  nl
(2.65)
where 1  k < l  u. The other group L ¼ {l1, l2,., lv} is composed of v patterns with
NAT ¼ 1. Similar pattern pairs {hi, h’i} (1  i  u) constitute the LUT, where h’i ˛ L
is the block similar to hi. Therefore LUT construction is reduced to the task of ﬁnding
h’i in L. In addition, we need to compute the size of the LUT in advance because the
hiding capacity is controlled by it. In this research, the size of the LUT is determined
by the number of similar pattern pairs I, and it can be transformed into a 32I-bits bi-
nary sequence because each pattern contains 4  4 pixels. Since the LUT is also
embedded into the original image, the valid capacity P for hidden data is
P ¼
 X
I
i¼1
ni
!
þ I  lSc  32I
(2.66)
where PI
i¼1 ni and I are the sums of NATs in the groups H and L, respectively. 32I is
the size of the AI aroused by the LUT embedding. lSc denotes the length of the com-
pressed state sequence S; the detailed description is given in the next section.
Suppose D is the length of the hidden data W, the ﬂow chart of the LUT construc-
tion is shown in Fig. 2.28 with steps as follows.
1. Initialize i ¼ 1, I ¼ 1, and construct the PH.
2. Find in L the similar pattern h’i for hi, and insert {hi, h’i} into the LUT. If P  D,
go to Step 4; otherwise, go to Step 3.
3. i ¼ i þ 1, I ¼ I þ 1, and go to Step 2.
4. The LUT is attained.
To ﬁnd h’i in Step 2, we convolute hi with f and also all patterns in L with f as
follows:
hfi ¼ hi  f
(2.67)
lfj ¼ lj  f
(2.68)
112
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

where j ¼ 1, 2,., v. Obviously the size of the convolution results hﬁand lfj is 8  8
(the 4  4 matrix convoluted with the 5  5 matrix). Next, the Euclidean distance dij
computed with Eq. (2.69) is used to measure the similarity between hﬁand lfj. The lfj
with the smallest dij from hﬁis recorded, and the associated pattern in L is selected as
the h’i.
dij ¼
X
8
u¼1
X
8
v¼1

hfiðu; vÞ  lfjðu; vÞ
2
(2.69)
An example LUT is shown in Fig. 2.29, which is constructed from the 512  512
halftone Lena image. Only the patterns h1  h10 (the top row) with the ﬁrst 10
biggest NATs and their similar patterns h’1  h’10 (the bottom row) are given.
2.5.4.4 Data Hiding
The block diagram of the data hiding process is shown in Fig. 2.30. We use “0” and
“1” to denote the states of hi and h’i. Once the LUT is created, the process of hiding
data is transformed into a simple operation of hi  h’i replacement, whose steps are
as follows:
1. Partition the original image into nonoverlapping 4  4 blocks.
2. Construct a LUT based on the PH.
3. Search all blocks in the original image. As long as we come across a pattern in
the LUT, we record its state based on the following rule: if it belongs to H, “0” is
recorded; otherwise if it belongs to L, then “1” is recorded. Thus the state
sequence S can be obtained. In fact, suppose lS denotes the length of S, we have
lS ¼
 X
I
i¼1
ni
!
þ I
(2.70)
FIGURE 2.28
Flow chart of the LUT construction.
2.5 Lossless CompressioneBased Schemes
113

4. Compress S into Sc based on certain lossless entropy coding method; in our case,
the arithmetic coding algorithm is used. Here the length of Sc is lSc.
5. Noting that the length of the saved space is lS  lSc,we ﬁll the space lS  lSc  32I
and the space 32I with the hidden data W and the AI, respectively, as shown in
Fig. 2.31. Thus we get a new state sequence S’ ¼ fs01; s02; .; s0lsg. Note that
the length of S0 is still equal to lS.
6. Modulate the states of patterns belonging to the LUT to be the states in S0 based
on the following rule: If s’k (1  k  ls) equals “0” and the current pattern cp is
exactly the same as h’i, then we replace h’i with hi; Else if s’k equals “1” and cp
is exactly the same as hi, then we replace hi with h’i. For the other two cases,
patterns are unchanged. These operations can be expressed as follows:
8
>
>
>
<
>
>
>
:
h0i)hi
if s0k ¼ 0; cp ¼ h0i
hi)hi
if s0k ¼ 0; cp ¼ hi
h0i)h0i
if s0k ¼ 1; cp ¼ h0i
hi)h0i
if s0k ¼ 1; cp ¼ hi
(2.71)
where ) means replacing the left pattern with the right one. Hence, data is hidden
through the aforementioned similar pair toggling operation.
2.5.4.5 Look-Up Table Embedding
Since different images have different LUTs, no universal table is suitable for all im-
ages. Besides, the LUT is also need to be protected. Therefore, the LUT is also
embedded in the image in this research, with the steps being as follows. It is rear-
ranged into a 32I bits binary sequence. A secret key K is used to generate 32I random
pixel locations to embed the LUT, noting that these pixels must not fall into the
FIGURE 2.29
An example of a look-up table obtained from the Lena image.
FIGURE 2.30
Block diagram of the data hiding process.
114
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

blocks in the LUT. We extract the selected pixel values into a 32I binary sequence
and embed it based on Eq. (2.71). Then we directly replace the selected pixels with
the LUT sequence.
This principle is illustrated in Fig. 2.32; the red blocks (Gray in print versions)
denote the patterns used to extract the state according to the LUT, whereas the
blue points (Black in print versions) denote the select pixels with K. These pixels
values are extracted as AI, and then the rearranged LUT (a binary sequence) is
inserted into these locations. For example, if the LUT shown in Fig. 2.32 is to be
inserted, we need to select 320 pixel positions (blue points) and replace their pixels
values using the rearranged LUT, and the original 320 pixels values are hidden by
watermark embedding (red blocks). More details of the LUT embedding method
can be seen in Ref. [54].
FIGURE 2.31
State sequence lossless compression and the saved space allocation.
FIGURE 2.32
Look-up table embedding.
2.5 Lossless CompressioneBased Schemes
115

2.5.4.6 Data Extraction
The block diagram of data extraction is shown in Fig. 2.33, with steps being as
follows.
1. The LUT reconstruction: we use the same key K to ﬁnd the 32I pixel locations
and arrange the pixel values into the LUT.
2. The state sequence S0 is extracted according to the LUT.
3. Lossless decompression: S0 can be divided into three parts: the compressed
version of S, the hidden data, and the pixel values selected by K. We use the
arithmetic decoding method to decode the ﬁrst part of S0 to get S. Then, the
hidden data is extracted from the middle lS  lSc  32I bits. The process is
illustrated in Fig. 2.34.
4. AI Recovery: We directly extract the last 32I bits of S0 to recover the pixel values
occupied by the LUT.
5. Similar pair toggling: Demodulate the states of patterns belonging to the LUT to be
the states in S based on the following rule: If Sk (1  k  ls) equals “0” and the cp
is exactly the same as h’i, then we replace h’i with hi; Else if Sk equals “1” and the
cp is exactly the same as hi, then we replace hi with h’i. For the other two cases,
block patterns are unchanged. These operations can be described as follows:
8
>
>
>
<
>
>
>
:
hi)h0i
if sk ¼ 0; cp ¼ h0i
hi)hi
if sk ¼ 0; cp ¼ hi
h0i)h0i
if sk ¼ 1; cp ¼ h0i
h0i)hi
if sk ¼ 1; cp ¼ hi
(2.72)
2.5.4.7 Experimental Results
Six 512  512 error-diffused halftone images, Lena, Baboon, Airplane, Boat, Pep-
per, and Barbara, are selected to test the performance of the proposed method, as
FIGURE 2.33
Block diagram of the data extraction process.
116
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

shown in Fig. 2.35. These halftones are obtained by performing FloydeSteinberg
error diffusion ﬁltering on the 8-bit gray level images. The capacities for different
images and different sizes of LUT are listed in Table 2.4.
In our experiments, a 1D binary sequence created by a pseudo random number
generator is chosen as the hidden data. Fig. 2.36a and b illustrate the original image
Lena and its watermarked version, whereas Fig. 2.36c shows the recovered one. To
FIGURE 2.34
State sequence lossless decompression for the hidden data extraction and the additional
information recovery.
FIGURE 2.35
Six test errorediffused images Lena, Airplane, Baboon (top row, from left to right), Boat,
Pepper, and Barbara (bottom row, from left to right).
2.5 Lossless CompressioneBased Schemes
117

evaluate the introduced distortion, we apply an effective quality metric proposed by
Valliappan et al. [55], i.e., weighted signal-to-noise ratio (WSNR). The linear distor-
tion is quantiﬁed in Ref. [55] by constructing a minimum mean squared error Weiner
ﬁlter; in this way the residual image is uncorrelated with the input image. The residual
image represents the nonlinear distortion plus additive independent noise. Valliappan
et al. [55] spectrally weight the residual by a contrast sensitivity function (CSF) to
quantify the effect of nonlinear distortion and noise on quality. A CSF is a linear
approximation of the HVS response to a sine wave of a single frequency, and a
low-pass CSF assumes that the human eyes do not focus on one point but freely moves
the around the image. Since the halftone image is attempted to preserve the useful
information of the gray level image, we compare the halftone or watermarked
image with the original gray level image. Similar to PSNR, a higher WSNR means
a higher quality. In our experiments, the WSNR between the gray level Lena and
the halftone Lena is 29.18 dB, whereas the WSNR between the gray level Lena and
the watermarked Lena is 28.59 dB. It can be seen that the introduced distortion of
the visual quality is slight. Since the WSNR between the gray level Lena and the
recovered Lena is 29.18 dB, the recovered version is exactly the same as the original
image.
Our method can also be used for halftone image authentication. For example, a
hash sequence of the original halftone image can be hidden in the halftone image.
We only need to compare the hash extracted from the watermarked image (Hash1)
with the hash sequence computed from the recovered image (Hash2). When these
two sequences are equal, we can conﬁrm that the watermarked image suffers no
alteration. Under no attacks, both of them are certainly equal to the original hash,
whereas if the watermarked image is an unauthorized changed, the two sequences
are different. The process is illustrated in Fig. 2.37.
Table 2.4 Capacity (Bits) With Different Images and Different Sizes
of LUT(I)
LUT
Lena
Airplane
Baboon
Boat
Pepper
Barbara
I ¼ 1
201
195
8
68
152
33
I ¼ 2
339
385
21
142
258
73
I ¼ 3
432
522
28
204
355
112
I ¼ 4
512
635
37
261
429
140
I ¼ 5
582
742
41
314
487
165
I ¼ 6
641
844
45
366
540
188
I ¼ 7
690
936
48
416
582
212
I ¼ 8
739
1025
51
464
620
228
I ¼ 9
788
1109
52
512
655
241
I ¼ 10
831
1191
54
553
685
254
LUT, look-up table.
118
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

2.6 REVERSIBLE SECRET SHARINGeBASED SCHEMES
Secret sharing plays an important role in data encryption. Shamir et al. [56] proposed
an (r, n)-threshold prototype based on Lagrange polynomial interpolation. In this
model, the secret data are encrypted into n shares. If r or more than r shares are
polled, the secret can be decrypted. Otherwise, if r  1 or fewer shares are collected,
no meaningful information can be revealed. Thien et al. [57] extended Shamir et al.’s
model into image secret sharing, i.e., hiding a secret image in a set of noiselike
shadow images. Visual cryptography [58] is another useful technique for image se-
cret sharing. It employs the properties of human visual system and thus maintains the
advantage that the secret content can be viewed via stacking a qualiﬁed set of
shadow images. This stack-to-see mechanism makes it useful in the applications
where no computer is available.
More recently, Lin et al. [59,60] proposed two reversible secret sharing schemes
based on Lagrange polynomial interpolation. Compared with the available irrevers-
ible schemes, Lin et al.’s schemes have two extra advantages. One is that the
shadows are meaningful instead of meaningless images. Consequently, much
FIGURE 2.36
Data hiding on the halftone Lena. (a) The original Lena, WSNR ¼ 29.18 dB, (b) the
watermarked Lena with 831 bits inserted, WSNR ¼ 28.58 dB, (c) the recovered Lena,
WSNR ¼ 29.18 dB. WSNR, weighted signal-to-noise ratio.
FIGURE 2.37
Application of our scheme in halftone image authentication.
2.6 Reversible Secret SharingeBased Schemes
119

attention of hacker’s for attacking is reduced. The other is the reversibility, which
means not only the secret image but also the cover image can be recovered accu-
rately. In contrast, the cover image cannot be accurately recovered any longer in irre-
versible secret sharing.
In this section, we introduces our two high-capacity data hiding schemes during
reversible secret sharing.
2.6.1 DATA HIDING IN REVERSIBLE SECRET SHARING
In this section, we introduce our high-capacity data hiding scheme during reversible
secret sharing proposed in Ref. [61]. In the encoder, a large quantity of conﬁdential
data is embedded and shared along with a secret image in a set of camouﬂage
shadows. In the decoder, the secret and cover images and the conﬁdential data
can be precisely recovered simultaneously. This scheme can be used for covert
communication, secret image annotation, authentication, etc. Additionally, it is theo-
retically secure due to the foundation of Lagrange polynomial interpolation.
2.6.1.1 Related Work
In Shamir’s model, a prime p is randomly selected and an r1 degree polynomial is
constructed as Eq. (2.73) to encrypt a secret integer se into n shares.
qðxÞ ¼

se þ a1$x þ ::: þ ar1$xr1
modp
(2.73)
where the coefﬁcients a1,., ar  1 are randomly chosen positive integers. Both se
and a1,., ar  1 belong to [0, p  1]. In this way n shares q(1), ., q(n) are
generated as
qð jÞ ¼

se þ j$a1 þ ::: þ jr1$ar1

modp
(2.74)
where j ¼ 1, 2, ., n. According to Lagrange interpolation, se can be recovered by
solving the equation set constructed by any r or more than r shares.
According to Eq. (2.74), it is easy to ﬁnd that the coefﬁcient ai is also calculated
along with se during decryption. Lin et al.’s method [59] employs all coefﬁcients of
the r  1 degree polynomial to carry two parts of information, one from the cover
image and the other from the secret image. In the encoding stage, the input consists
of a secret image S and a cover image C of the same size. The output is composed of
a set of shadow images C1,.,Cn.
2.6.1.2 Proposed Scheme
Our scheme aims to hide some extra conﬁdential data during secret image sharing
with the original advantages of Lin et al.’s method [59] well preserved. A straight-
forward method is to employ conventional irreversible data hiding techniques on the
secret image ﬁrst, and then share the watermarked secret image using Lin et al.’s
method. However, this idea has two shortcomings contradicting the purpose of
our method. One is that the limited capacity provided in the conventional data hiding
techniques for the visual quality of watermarked images must be carefully
120
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

considered. Moreover, the host image (i.e., secret image) cannot be recovered accu-
rately in those irreversible methods. Instead, the lossless data hiding is adequate.
As shown in Fig. 2.38, we design a novel high-capacity data hiding method in-
tegrated in reversible secret sharing. The key characteristics lie in a double module
structure and a lossless data hiding mechanism based on multilevel histogram shift-
ing. In Ref. [59], the same prime p is used for the module processing of S and C.
However, in our double module structure, a pair of integers {b, p} is adopted. In
particular, a prime p and another integer b (b < p) are introduced for C and S pro-
cessing, respectively. The encoding stage consists of secret image sharing and
data hiding, and the decoding stage includes secret image decryption and data
extraction.
2.6.1.2.1 Encoding Stage
In this stage, the input includes a cover image C, a secret image S, and a binary
sequence conﬁdential data W. Suppose both C and S are M  N gray level images
 
 
 
Cover image 
 
b-base sequence 
conversion 
Difference 
computation 
Histogram 
construction 
Histogram 
shifting 
Minority 
computation 
Lagrange polynomial construction 
Range 
adjustment 
 
Majority 
computation 
Camouflage image generation 
Camouflage images 
Confidential 
data 
Secret image 
Inverse S  
scan 
FIGURE 2.38
Block diagram of the proposed method.
2.6 Reversible Secret SharingeBased Schemes
121

and the {b, p} pair is predetermined. The output are n shadow images C1,.,Cn. The
encoding details are described as follows.
Step 1. Inverse “S” scan. Scan the pixels of S in the inverse “S” order [40] and a
pixel sequence s1, s2,., sMN is obtained.
Step 2. b-base sequence conversion. Translate each pixel si (1  i  M  N) into
a b-base sequence

si
1; si
2:::; si
v

b. Here v ¼ dlogb255e and b is a positive integer
smaller than p and not required to be a prime. In this way, there are totally v
sequences si
j (1  j  v) obtained with each containing M  N elements, i.e.,
sj ¼
n
s1
j ; s2
j ; ::::sMN
j
o
.
An example of a 3  3 block inverse “S” scan and b-base sequence conversion is
shown in Fig. 2.39, where the scan direction is indicated as the blue line (Black
in print versions) and b ¼ 7.
Step 3. Difference computation. Compute the difference between two adjacent
elements of sj as
di
j ¼ si1
j
 si
j
(2.75)
where 2  i  M  N. It is expectable that each element’s value in sj is usually
similar to its adjacent neighbors because of the similarity of adjacent pixels in S.
That is, a large number of differences are equal or close to 0.
Step 4. Histogram construction. Construct the difference histogram hj of sj ac-
cording to the M  N  1 differences d2
j ; d3
j ; :::; dMN
j
. Obviously, as si
j belongs
to [0, b  1], di
j belongs to [b þ 1, b  1]. Here, the histogram bins from left to
right are denoted by hj(b þ 1),., hj(1), hj(0), hj(1), ., hj(b  1).
Step 5. Histogram shifting. Compute the embedding level EL according to {b, p} as
EL ¼
p  b  1
2

(2.76)
 
pixel   value    b-base sequence 
s1     149   {  3,   0,   2  }7 
s2     152   {  3,   0,   5  }7 
s3     151   {  3,   0,   4  }7 
s4     157   {  3,   1,   3  }7 
s5     150   {  3,   0,   3  }7 
s6     147   {  3,   0,   0  }7 
s7     148   {  3,   0,   1  }7 
     
s9     156   {  3,   1,   2  }7 
s1={3,3,3,3,3,3,3,3,3};  s2={0,0,0,1,0,0,0,1,1};  s3={2,5,4,3,3,0,1,0,2} 
149 
147 
152 
150 
 
151 
157 
148 
154 
156 
FIGURE 2.39
Inverse “S” scan and b-base sequence conversion of a 3  3 image block.
122
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

A larger EL indicates that more secret data can be embedded. As the embedding
operations of EL > 0 are more complicated than those of EL ¼ 0, we describe
them separately. If EL ¼ 0, execute Step 5.1. If EL > 0, go to Step 5.2.
Step 5.1 Data embedding for EL ¼ 0.
Step 5.1.1 Shift the right bins of h(0) rightward by one level as
ed
i
j ¼
8
<
:
di
j þ 1
if
di
j > 0
di
j
if
di
j  0
(2.77)
Step 5.1.2. For the current processing conﬁdential bit w, perform the following
embedding operation as
eed
i
j ¼
8
<
:
ed
i
j þ w
if
ed
i
j ¼ 0
ed
i
j
if
ed
i
j s0
(2.78)
After that, go to Step 6.
Step 5.2. Data embedding for EL > 0.
Step 5.2.1. Shift the right bins of hj(EL) rightward by EL þ 1 levels, and shift the
left bins of hj(EL) leftward by EL levels as
ed
i
j ¼
8
>
>
>
<
>
>
>
:
di
j þ EL þ 1
if
di
j > EL
di
j
if
EL  di
j  EL
di
j  EL
if
di
j < EL
(2.79)
Step 5.2.2. Embed the conﬁdential data w as
eed
i
j ¼
8
>
>
>
>
<
>
>
>
>
:
ed
i
j
if
ed
i
j s  EL
2  EL þ w
if
ed
i
j ¼ EL
2  EL  w þ 1
if
ed
i
j ¼ EL
(2.80)
Then EL is decreased by 1. If EL s 0, execute Eqs. (2.79) and (2.80) repeatedly until
EL ¼ 0. If EL ¼ 0, execute Eq. (2.81) and then go to Step 6.
eed
i
j ¼
8
<
:
ed
i
j þ w
if
ed
i
j ¼ 0
ed
i
j
if
ed
i
j s0
(2.81)
Step 6. Generate the watermarked sequence es i
j as
2.6 Reversible Secret SharingeBased Schemes
123

es i
j ¼
8
<
:
si
j
if
i ¼ 1
si1
j
 eed
i
j
if
2  i  M  N
(2.82)
Step 7. Adjust the range according to
ees
i
j ¼ es i
j þ EL þ 1
(2.83)
Hence the conﬁdential data embedding is completed. The output ees
i
j can be used
for the following secret sharing operations.
Step 8. Compute the minority cmi of the current processing pixel c as
cmi ¼ cmodp
(2.84)
Step 9. Compute the majority cma according to c and cmi as
cma ¼ c  cmi
(2.85)
Step 10. Construct a v-degree polynomial F(x) according toees
i
1;ees
i
2; .ees
i
v and cmi as
FðxÞ ¼

ees
i
1 þees
i
2$x þ ::: þees
i
v$xv1 þ cmi$xv
	
modp
(2.86)
Step 11. Generate F(km) (m ¼ 1,., n) via each participant’s key km as
8
>
>
>
>
>
<
>
>
>
>
>
:
Fðk1Þ ¼

ees
i
1 þees
i
2$k1 þ ::: þees
i
v$kv1
1
þ cmi$kv
1
	
modp
Fðk2Þ ¼

ees
i
1 þees
i
2$k2 þ ::: þees
i
v$kv1
2
þ cmi$kv
2
	
modp
/
FðknÞ ¼

ees
i
1 þees
i
2$kn þ ::: þees
i
v$kv1
n
þ cmi$kv
n
	
modp
(2.87)
Step 12. Compute cm according to cma and F(km) as
cm ¼ cma þ FðkmÞ
(2.88)
where cm corresponds to the current pixel of the shadow image Cm.
Step 13. Repeat Steps 1e12 for all pixels of S and C. In this way, all the shadows
images C1,.,Cn are produced.
2.6.1.2.2 Decoding Stage
The input is composed of r or more than r shadow images. If more than r shadows
are obtained, we can choose any r different shadows randomly. Besides, suppose the
decoder obtains the {b, p} via a secure channel. The output consists of the secret im-
age, the cover image, and the conﬁdential data.
124
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

Step 1. Suppose C1; .; Cr denote r different shadow images. Obtain the current
processing pixels cl and compute F

kl

as
F

kl

¼ clmodp
(2.89)
where l ¼ 1, 2,.,r and p is the same prime used in the encoder.
Step 2. Construct an equation set as
8
>
>
>
>
>
<
>
>
>
>
>
:
F

k1

¼

ees
i
1 þees
i
2$k1 þ ::: þees
i
v $kv1
1
þ cmi$kv
1
	
modp
F

k2

¼

ees
i
1 þees
i
2$k2 þ ::: þees
i
v $kv1
2
þ cmi$kv
2
	
modp
/
F

kr

¼

ees
i
1 þees
i
2$kr þ ::: þees
i
v $kv1
n
þ cmi$kv
r
	
modp
(2.90)
Thus ees
i
1;ees
i
2; :::ees
i
v and cmi are obtained by solving this equation set.
Step 3. Compute cma according to c1 and F

k1

as
cma ¼ c1  F

k1

(2.91)
Step 4. Recover the cover pixel c according to cma and cmi as
c ¼ cma þ cmi
(2.92)
Repeat Steps 1e4 for all pixels of C1; .; Cr. In this way, the cover image C is
reconstructed accurately.
Step 5. Range readjustment. Compute the embedding level as EL ¼

pb1
2

and
obtain the es i
j as
es i
j ¼ ees
i
j  EL  1
(2.93)
Step 6. If EL ¼ 0, execute Steps 7 and 8. If EL > 0, execute Steps 9 and 10.
Step 7. For EL ¼ 0, si
j can be recovered as
si
j ¼
8
<
:
es i
j
if
si1
j
 es i
j  0
es i
j þ 1
if
si1
j
 es i
j  1
(2.94)
Step 8. For EL ¼ 0, the current conﬁdential data w is extracted as
w ¼
8
<
:
0
if
si1
j
 es i
j ¼ 0
1
if
si1
j
 es i
j ¼ 1
(2.95)
Rearrange all the extracted bits into the original conﬁdential sequence W. After
that, go to Step 11.
2.6 Reversible Secret SharingeBased Schemes
125

Step 9. For EL > 0, obtain s1
j ¼ es 1
j and compute eed
i
j as
eed
i
j ¼ si1
j
 es i
j
(2.96)
where 2  i  M  N. Then di
j is obtained as
di
j ¼
8
>
>
>
>
>
>
>
>
>
<
>
>
>
>
>
>
>
>
>
:
eed
i
j  EL  1
if
eed
i
j > 2  EL þ 1
eed
i
j þ EL
if
eed
i
j < 2  EL
r
if
eed
i
j ˛f2  r; 2  r þ 1g; r ¼ 0; 1; .; EL
r
if
eed
i
j ˛f  2  r; 2  r þ 1g; r ¼ 1; .; EL
(2.97)
Next, si
j is recovered as
si
j ¼ es i1
j
 di
j
(2.98)
Note Eqs. (2.96)e(2.98) are executed repeatedly, i.e., si
j is recovered in advance
and then siþ1
j
is recovered with the aid of si
j. That is, a sequential recovery
strategy is utilized.
Step 10. For EL > 0, the conﬁdential data extraction is associated with EL þ 1
rounds. First set the round index R ¼ 1.
Step 10.1. Retrieve the Rth round conﬁdential data wR as
wR ¼
8
>
<
>
:
0
if
eed
i
j ¼ 2  EL
or
eed
i
j ¼ 2  EL þ 1
1
if
eed
i
j ¼ 2  EL
or
eed
i
j ¼ 2  EL þ 1
(2.99)
Step 10.2. EL is decreased by 1 and R is increased by 1.
Step 10.3. If EL s 0, execute Steps 10.1 and 10.2 repeatedly until EL ¼ 0. If
EL ¼ 0, execute
wR ¼
8
>
<
>
:
0
if
eed
i
j ¼ 0
1
if
eed
i
j ¼ 1
(2.100)
Now R is increased as EL þ 1.
Step 10.4. Rearrange and concatenate the extracted data wR (R ¼ 1,
2,.,EL þ 1) as
W ¼ w1jjw2jj; .; jjwELþ1
(2.101)
where jj represents the concatenation operation. Hence, the hidden conﬁdential data
W is extracted, and then go to Step 11.
Step 11. The secret pixel si can be losslessly recovered according to
126
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

si ¼ bv1  si
1 þ bv2  si
2 þ ::: þ si
v
(2.102)
Step 12. Perform the inverse “S” scan on the si pixels to recover the secret
image S.
Hence all the operations in the decoder are completed.
2.6.1.2.3 Example
As shown in Fig. 2.40, an example with {b, p} ¼ {7, 13} and s3 ¼ {2, 5, 4, 3, 3, 0, 1,
0, 2} produced in Fig. 2.39 is investigated for data embedding. In this case, we can
obtain EL ¼ 2. Obviously, 6 bits conﬁdential data can be embedded in s3. Suppose
the conﬁdential sequence is “001101.” In all sequel operations, the ﬁrst element
of s3 is kept unchanged because the decoding operations are triggered by it. The
preparation procedure includes difference computation and histogram shifting. First,
a difference sequence {2,3,1,1,0,3,1,1,2} is obtained. The next step is the his-
togram shifting. As EL ¼ 2, the shifted results are {2, 5, 1, 1, 0, 6, 1, 1, 3}.
Then the embedding operations are executed with three rounds. In the ﬁrst round,
only the last shifted difference value 2 can be utilized for the ﬁrst secret bit “0”
embedding and it is modiﬁed as 3. In the second round, four shifted difference
value {1, 1, 1, 1} can be utilized for the subsequent secret bits “0110” embedding
and they are modiﬁed as {2, 3, 2, 2}. In the third round, only one shifted difference
value 0 can be utilized for the last secret bit “1” embedding and it is modiﬁed as 1. In
this way, the watermarked difference is obtained as {2, 5, 2, 3, 1, 6, 2, 2, 3} and
those modiﬁed differences are marked as orange (Gray in print versions) in
Fig. 2.39. Then, the watermarked sequence is deduced as {2, 7, 3, 1, 2, 3,
2, 1, 3} by subtracting the watermarked differences from the original values of
the left neighbor. This processing is indicated as the blue arrows. The last operation
is range adjustment. As EL ¼ 2, 3 is added to each element of {2, 7, 3, 1, 2, 3,
2, 1, 3} except the ﬁrst one (i.e., EL þ 1) and thus the ﬁnal watermarked sequence
is obtained as {2, 10, 6, 4, 5, 0, 5, 2, 6}.
The conﬁdential data extraction principle is shown in Fig. 2.41. Suppose the
decoder obtained the parameters {b, p} ¼ {7, 13} and the intact watermarked
sequence {2, 10, 6, 4, 5, 0, 5, 2, 6}. Hence EL ¼ 2 can be calculated. The ﬁrst oper-
ation is range readjustment by subtracting EL þ 1 from {2, 10, 6, 4, 5, 0, 5, 2, 6}
except the ﬁrst element and the intermediate result {2, 7, 3, 1, 2, 3, 2, 1, 3}.
Next, the s3 recovery is triggered by the ﬁrst element 2. That is, the watermarked
difference 5 is computed according to 2 and 7 and its corresponding shifted differ-
ence 3 is deduced. According to trigger element 2 and the shifted difference 3,
the original element of s3 is recovered as 5. Repeat this processing with a sequential
order, and s3 can be accurately recovered as {2, 5, 4, 3, 3, 0, 1, 0, 2}. The conﬁdential
data extraction is indicated as orange rectangles also with three rounds involved.
Each conﬁdential bit is retrieved by comparing the watermarked elements and their
corresponding recovered elements. In the ﬁrst round, only one secret bit “0” is
extracted from the last rectangle for the difference 2 is used in the ﬁrst round
2.6 Reversible Secret SharingeBased Schemes
127

data embedding. In the second round, four secret bits “0110” are extracted for the
associated differences are used in the second round data embedding. Likewise,
one secret bit “1” is extracted in the third round. After that, the original conﬁdential
sequence can be obtained by rearranging the extracted results of the three rounds
into “001101”. These operations prove that s3 along with the conﬁdential data can
be perfectly recovered at the same time. Consequently, the reversibility of secret
sharing is still preserved.
2.6.1.3 Experimental Results
As shown in Fig. 2.42, ten 512  512 gray level images are selected as test images to
evaluate the average performance of our scheme. The conﬁdential data W in the
following experiments are binary sequences produced by a pseudo random number
generator. The embedding capacity is jointly determined by the parameters {b, p}
and the secret image content. Tables 2.5e2.7 show the embedding capacities of
10 images with various {b, p}, where EL ¼ 0, EL ¼ 1, and EL ¼ 2, respectively.
In Table 2.5, the average capacities provided by s1, s2, and s3 are 239,309,
115,524, and 31,098 bits, respectively. In Table 2.6, they are 259,152, 171,483,
Embedding 
Embedding 
Embedding 
2
-5
2
3
0
6
-2
2
-3
Histogram 
shifting
Difference 
computation
2
5
4
3
3
0
1
0
2
2
-3
1
1
0
3
-1
1
-2
2
-5
1
1
0
6
-1
1
-2
2
-5
1
1
0
6
-1
1
-3
2
-5
2
3
1
6
-2
2
-3
2
7
3
1
2
-3
2
-1
3
2
1
6
4
5
0
5
2
6
Range 
adjustment
FIGURE 2.40
Example of data embedding for {b, p} ¼ {7, 13}.
128
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

and 106,376 bits, respectively. In Table 2.7, they are 261,940, 202,386, and
157,780 bits, respectively. Obviously, a larger difference of b and p (i.e., a larger
EL) leads to a higher capacity. Besides, as the similarity among these sequences
is s1 > s2 > s3, the capacity provided is also s1 > s2 > s3. The highest average capac-
ity of 2.37 bpp is achieved when {b, p} ¼ {7, 13}.
Fig. 2.43 shows the capacities with b ¼ 7, 8, 9, 10, 11, 12 and p ¼ 13. The
average highest capacity of 2.37 bpp is achieved when b ¼ 7, and the lowest capacity
of 1.50 bpp is achieved when b ¼ 12. In fact, the distortions on shadow images with
various b values are of the same level as long as the same p used. Therefore, it is
recommended to set b as 7 to provide the highest capacity.
2.6.2 JOINT SECRET SHARING AND DATA HIDING FOR
BLOCK TRUNCATION CODING-COMPRESSED IMAGES
In this subsection, we introduce our secure transmission system for block truncation
coding (BTC)-compressed images proposed in Ref. [62]. The application scenario
can be described as follows. Given a gray level or color image, we need to compress
and transmit it over two independent but not secure channels. Besides transmission
security, the following three factors must be considered in the system design. (1) The
reconstruction image quality should be preserved, i.e., nearly the same as that in
2
10
6
4
5
0
5
2
6
2
2
-5
2
3
1
6
-2
2
-3
2
7
3
1
2
-3
2
-1
3
-3
1
1
0
3
-1
1
-2
5
4
3
3
0
1
0
2
Extracted:                          
0
Extracted:       0    1  
1    0
Rearranged extracted bits: 0 0 1 1 0 1
FIGURE 2.41
Example of data extraction for {b, p} ¼ {7, 13}.
2.6 Reversible Secret SharingeBased Schemes
129

BTC compression. (2) There should be low-complexity encoding and decoding, thus
maintaining the real-time performance of BTC compression. (3) The shares should
have a small size. This is essential to save transmission time and channel resources.
In fact, in most available secret sharing methods, the sizes of shares are expanded
when compared with the original secret data.
In particular, these three advantages are achieved in the proposed system with
secret sharing and data hiding well synthesized. The compressed image can be
reconstructed as long as both shares are collected. Otherwise, no meaningful infor-
mation is decrypted. Besides, the encoding/decoding procedures are quite simple
and the reconstructed image quality is nearly the same as that in BTC compression.
Furthermore, each share is half the size of the compressed image, and thus no extra
burden is laid on transmission channels.
FIGURE 2.42
Test image Lena, Baboon, Barbara, Airplane, Boat, (top row, from left to right), Bridge,
Peppers, Aerial, Truck, and Texture (bottom row, from left to right).
Table 2.5 Capacities With {b, p} ¼ {11, 13}
Secret Image
s1 (Bit)
s2 (Bit)
s3 (Bit)
Total (Bit)
bpp
Lena
250,758
160,164
30,549
441,471
1.68
Baboon
224,799
71,855
24,055
320,709
1.22
Barbara
229,202
119,883
26,838
375,923
1.43
Airplane
253,331
176,023
44,350
473,704
1.81
Boat
246,792
121,672
25,654
394,118
1.50
Bridge
238,091
105,077
56,169
399,337
1.52
Peppers
252,299
142,461
24,842
419,602
1.60
Aerial
224,261
85,253
24,312
333,826
1.27
Truck
242,383
110,903
29,443
382,729
1.46
Texture
231,172
61,950
24,768
317,890
1.21
Average
239,309
115,524
31,098
385,931
1.47
130
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

2.6.2.1 Related Work
The standard BTC compression technique [63] is reviewed in the following discus-
sion. Suppose the original image I is a gray level image. In the encoding stage, I is
ﬁrst partitioned into a set of nonoverlapping k  k blocks, and the mean value pm of
each block is calculated as
pm ¼
1
k  k
X
k
x¼1
X
k
y¼1
pðx; yÞ
(2.103)
where p(x,y) denotes the pixel value in the position (x,y). Next, the block pixels are
thresholded as
Table 2.6 Capacities with {b, p} ¼ {7, 11}
Secret Image
s1 (Bit)
s2 (Bit)
s3 (Bit)
Total (Bit)
bpp
Lena
261,598
211,254
106,052
578,904
2.21
Baboon
256,372
130,972
102,160
489,504
1.87
Barbara
253,467
176,998
102,638
533,103
2.03
Airplane
260,766
219,298
123,758
603,822
2.30
Boat
259,433
178,078
103,649
541,160
2.06
Bridge
259,694
162,935
115,420
538,049
2.05
Peppers
261,048
203,496
101,874
566,418
2.16
Aerial
260,160
142,684
101,711
504,555
1.92
Truck
261,984
170,137
103,376
535,497
2.04
Texture
256,994
118,973
103,122
479,089
1.83
Average
259,152
171,483
106,376
537,010
2.05
Table 2.7 Capacities with {b, p} ¼ {7, 13}
Secret Image
s1 (Bit)
s2 (Bit)
s3 (Bit)
Total (Bit)
bpp
Lena
262,137
227,737
158,787
648,661
2.47
Baboon
261,998
176,420
155,346
593,764
2.27
Barbara
261,513
202,911
155,811
620,235
2.37
Airplane
261,783
231,767
170,742
664,292
2.53
Boat
261,711
205,501
157,230
624,442
2.38
Bridge
262,066
198,311
154,103
614,480
2.34
Peppers
261,936
224,300
155,516
641,752
2.45
Aerial
262,114
184,628
155,451
602,193
2.30
Truck
262,140
206,147
158,512
626,799
2.39
Texture
261,998
166,141
156,306
584,445
2.23
Average
261,940
202,386
157,780
622,106
2.37
2.6 Reversible Secret SharingeBased Schemes
131

bðx; yÞ ¼
 1
if pðx; yÞ > pm
0
otherwise
(2.104)
resulting in a binary bitmap M, where b(x,y) is the pixel value in the position (x,y) of
M. Third, two quantization levels ph and pl are computed for each block, i.e., the
mean values of those pixels with p(x,y) > pm and p(x,y)  pm, respectively. Thus,
each block is represented by a pair of integers ph, pl in the range of [0, 255] and a
k  k bitmap. The encoding procedure is completed, and the compressed content
is transmitted.
In the decoding stage, each block can be approximately recovered with ph, pl, and
M as
p0ðx; yÞ ¼
 ph
if bðx; yÞ ¼ 1
pl
otherwise
(2.105)
where p’(x,y) is the reconstructed pixel value in the position (x,y) of the current
decoded block. In this way, the decoded image can be reconstructed by collecting
all the reconstructed blocks. In our context, pm, ph, and pl are rounded to their nearest
integers.
2.6.2.2 Joint Data Encryption and Data Hiding Model
We start from presenting the joint data encryption and data hiding model. Suppose
the
secret
data
is
composed
of
two
binary
sequences
u ¼ (u1,u2,.uK)
and v ¼ (v1,v2,.vK-1). The main idea of our model is to encrypt u, and meanwhile,
Lena
Baboon
Barbara
Airplane
Boat
Bridge
Peppers
Aerial
Truck
Texture
8
7
1.2
1.4
1.6
1.8
Capacity (bpp)
Parameter b
2
2.2
2.4
2.6
9
10
11
12
FIGURE 2.43
Capacities with b ¼ 7, 8, 9, 10, 11, 12 and p ¼ 13.
132
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

v is also hidden in two shares m ¼ (m1,m2,.mK) and n ¼ (n1,n2,.nK). The encryp-
tion strategy of this model is shown in Fig. 2.44.
The encoding procedures are as follows.
Step 1. Encrypt u1 in m1 and n1. Randomly select a “1” or “0” and assign it to m1,
and then n1 is determined by m1 and u1 as
n1 ¼

m1
if u1 ¼ 1
1  m1
if u1 ¼ 0
(2.106)
Step 2. Hide v1 in n1 and m2. That is, m2 is determined by n1 and v1 as
m2 ¼

n1
if v1 ¼ 1
1  n1
if v1 ¼ 0
(2.107)
Step 3. Encrypt u2 in m2 and n2. That is, n2 is determined by m2 and u2 as
n2 ¼

m2
if u2 ¼ 1
1  m2
if u2 ¼ 0
(2.108)
Step 4. Repeat these operations until vj1 is hidden in nj1 and mj as indicated
with the dashed arrow, and uj is encrypted in mj and nj as indicated with the solid
arrow.
In this way, the sequence u is encrypted and v is hidden in two produced shares m
and n.
In decoding, the sequences u and v can be recovered as
ui ¼ 1  mi4ni
1  i  K
(2.109)
vi ¼ 1  miþ14ni
1  i  K  1
(2.110)
where 4 denotes the exclusive-OR operation.
uK
uK-1
vK-1
vK-2
v3
u3
v2
u2
v1
u1
m
m1
m2
m3
mK-1
mK
n
n1
n2
n3
nK-1
nK
FIGURE 2.44
Encryption strategy of the joint data encryption and data hiding model.
2.6 Reversible Secret SharingeBased Schemes
133

2.6.2.3 Joint Block Truncation Coding and Secret Sharing
In the joint BTC and secret sharing scheme, the standard BTC compression and the
joint data encryption and data hiding model are applied. In our case, the original im-
age is partitioned into 4  4 blocks.
In the encoding stage, operations are as follows.
Step 1. Perform the standard BTC encoding on the ﬁrst block, and its pm, ph, and
pl are obtained.
Step 2. Compute the difference d between pm and pl as
d ¼ pm  pl
(2.111)
Considering in natural images, pixel values change gradually in a 4  4 block;
the difference d is small for most natural image blocks as illustrated in Section
2.6.2.4. Therefore, it is reasonable to regard d as an integer that belongs to
[0, 127], otherwise we set d ¼ 127.
Step3. Translate pl and d into 8-bit and 7-bit binary sequences, respectively.
Concatenate them to form a 15-bit sequence denoted by v ¼ (v1, v2,., v15).
Besides, rearrange the bitmap M into a 16-bit binary sequence, represented with
u ¼ (u1, u2,., u16).
Step 4. Apply the encoding procedure [Eqs. (2.106)e(2.108)] of the joint data
encryption and data hiding model to the block. Thus u is encrypted, and at the
same time v is hidden in two produced shares m ¼ (m1, m2,., m16) and n ¼ (n1,
n2, ., n16).
Step 5. For the ﬁrst share, translate (m1, m2,., m8) and (m9, m10,., m16) into two
integers in the range of [0, 255], respectively. The similar operations are also
performed on n for the second share. In this way, the compressed information of
each block corresponds to two shares, each with two “pixels.”
Step 6. Repeat these operations for all the other blocks, and the share images S1
and S2 are obtained and transmitted independently.
The corresponding operations in the decoding stage are described as follows.
Step 1. Translate the received ﬁrst two pixels of S1 and S2 into two 16-bit binary
sequences.
Step 2. Apply the decoding procedure [Eqs. (2.109)e(2.110)] of the joint data
encryption and data hiding model to these two sequences. Thus pl, d, and the
associated bitmap M are recovered. Suppose the number of “0”s and “1”s in M
are nl and nh ¼ 16-nl, respectively.
Step 3. Compute pm according to pl and d as
pm ¼ pl þ d
(2.112)
Step 4. Compute ph according to pl and pm as
ph ¼ ð16pm  nlplÞ
nh
(2.113)
134
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

Step 5. Reconstruct the BTC-compressed block based on pl, pm, and M according
to Eq. (2.105).
Step 6. Repeat Steps 1e5 for all the other received shares’ pixels, and thus the
BTC-compressed image is reconstructed.
2.6.2.4 Experimental Results
The 512  512 gray level Lena image is selected as the test image, and the related
experimental results are shown in Fig. 2.45. Obviously, the two 128  256 share im-
ages produced in our scheme look like random noises, thus transmission security of
the compressed image can be guaranteed. Furthermore, the total amount of the trans-
mission content is the same as that in the standard BTC compression, i.e., the
compression ratio is kept as 4.
Many transmission scenarios, especially wireless transmissions, usually suffer
from some abrupt errors such as packet loss [4]. As our scheme is based on a block-
wise processing mechanism, these transmission errors of share images only corrupt
the associated decrypted blocks. In other words, errors are not diffused to other
reconstructed blocks, as illustrated in another experiment shown in Fig. 2.46.
Fig. 2.46a and b are the corrupted versions of Fig. 2.45c and d respectively. From
Fig. 2.46c, it is easy to ﬁnd that only the corresponding blocks are corrupted,
whereas others are still reconstructed correctly.
It is necessary to note that, compared with the reconstructed image based on the
standard BTC, there is a slight quality degradation of the reconstructed image with
the two intact shares. This is because the computed ph for image reconstruction in
our scheme is not exactly equal to that directly transmitted in the standard BTC.
FIGURE 2.45
Experimental results on the Lena image. (a) The original image, (b) the reconstructed
image by our scheme, (c) the share image S1, (d) the share image S2.
2.6 Reversible Secret SharingeBased Schemes
135

Namely, error is introduced in Eqs. (2.111)e(2.113) when a ﬂoating point number is
rounded to its nearest integer. A large quantity of experimental results show that this
image quality degradation is acceptable. For example, the PSNR of the recon-
structed Lena using the standard BTC is 34.00 dB, whereas 33.96 dB is obtained
in our scheme.
As mentioned in Section 2.6.2.3, d is set as 127 when it is larger than 127 such
that it can be translated into a 7-bit sequence. Thus truncation errors may be pro-
duced for the range of d [0, 255] theoretically. Fortunately, as high correlation exist
among pixels in natural image blocks, d is small in most cases. Ten 512  512 gray
level images (Lena, Baboon, Barbara, Bridge, Boat, F16, Peppers, Elaine, Aerial,
Truck) are selected to investigate the statistics of d values. Each image is partitioned
into 4  4 blocks, thus totally 163,840 blocks, i.e., 163,840 d values are obtained
and examined. The 256-bin histogram of d values is shown in Fig. 2.47. The bins
at the high end (bins from 150 to 255) are empty and hence only a part (150 of
256) of the histogram is shown. In this experiment, only 44 d values are larger
than 127. In addition, these large d values are in the range of [128, 150]. That is,
the percentage of the special case is merely about 0.027%, and thus the possible
errors are acceptable in practice.
In addition, there is another special case in our scheme, i.e., all the pixels in an
original image block are of the same value. Suppose this value is denoted by ps. In
this case, pm ¼ ps, pl ¼ ps, d ¼ 0, and all bits in the bitmap M are 0. Obviously, Eq.
(2.113) cannot be applied any longer for both its denominator and numerator equal
0. Thus we set ph ¼ ps, and keep all the other operations unchanged.
Actually, our scheme is also suitable for BTC-compressed color image transmis-
sion. Speciﬁcally, the original color image is decomposed into red, green, and blue
(a)
(b)
(c)
FIGURE 2.46
Experimental results on the received shares suffering transmission errors. (a) the
corrupted S1, (b) the corrupted S2, and (c) the reconstructed image.
136
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

channels, and each channel is encoded as a gray level image. Finally all encoded
channels are recomposed into color noiselike shares.
2.6.2.5 Discussions
Thien and Lin [57] develop a Lagrange interpolationebased (r, t) threshold scheme
for image secret sharing. An input image can be encrypted into t random noiselike
share images. If r or more than r shares are collected, the original image can be
reconstructed. Thien and Lin’s scheme is an alternative method to encrypt the
BTC-compressed image with r ¼ t ¼ 2. For example, a 512  512 input image
can be encrypted into two 128  256 shares. However, this is achieved by truncating
all compressed “pixel” values (e.g., 4 “pixels” translated from ph, pl, and M of a
block) from the range [0, 255] to [0, 250] before encryption. In other words, to
perfectly reconstruct the BTC-compressed image, the truncation errors must also
be encrypted additionally. Consequently, two produced shares are usually larger
than 128  256 pixels, resulting in more storage space and transmission time.
2.7 SUMMARY
This chapter discussed the reversible data hiding schemes in the spatial domain. We
ﬁrst provide an overview of the spatial domainebased schemes. Then we discussed
ﬁve types of spatial domain lossless information hiding methods, i.e., the modulo
additionebased
scheme,
DE-based
schemes,
histogram
modiﬁcationebased
00
50
100
150
0.5
1.5
2.5
x 104
2
1
FIGURE 2.47
Statistical histogram of d values.
2.7 Summary
137

schemes, lossless compressionebased schemes, and reversible secret sharingebased
schemes. With regard to DE-based schemes, we introduce two traditional DE-based
schemes, i.e., Tian’s scheme and Alatter’s scheme.
With regard to histogram modiﬁcationebased schemes, we ﬁrst introduce two
traditional schemes, i.e., Ni et al.’s original scheme and Li et al.’s APD method.
Then we introduce our reversible data hiding scheme based on multilevel histogram
modiﬁcation. On the one hand, a higher capacity is provided compared with one- or
two-level histogram modiﬁcationebased methods. On the other hands, as secret data
are embedded in differences of adjacent pixels values, the marked image quality is
improved compared with that in previous multilevel histogram modiﬁcationebased
work. Finally, we introduce another reversible data hiding scheme by means of
hybrid prediction and multilevel histogram shifting. As only one seed pixel involved,
our scheme yields more prediction errors concentrating at 0 compared with conven-
tional prediction-based methods. Moreover, more errors concentrated around
0 because the prediction precision is enhanced. Our method depends on only one
parameter, which can be adjusted to trade the marked image quality for capacity,
and vice versa. By experimental comparison with several previous methods, we
observe that the proposed method leads to a better performance in capacity and
marked image quality simultaneously.
With regard to lossless compressionebased schemes, we ﬁrst introduce two
traditional schemes, i.e., the lossless RS data-embedding and lossless G-LSB data
embedding methods. Then, we introduce our reversible data hiding method for error
diffused halftone images. In this method, the hidden data can be extracted with a se-
cret key and the original image is perfectly recovered. Experimental results show the
effectiveness of the method. Since the characteristics of the HVS are exploited,
lower degradation is introduced to the visual quality of the image. Our method in
this research only focuses on the gray level halftone images, and it is expected to
be extended to the color halftone images in the future.
With regard to reversible secret sharingebased schemes, we introduce two of our
methods. One is the high-capacity data hiding scheme integrated in reversible secret
sharing, where a double module mechanism and a multilevel histogram modiﬁcation
strategy are utilized. Both the secret and cover images can be recovered accurately.
In addition, a large quantity of conﬁdential data can be embedded in shadow images
during secret sharing and then perfectly retrieved during secret image decryption. As
the architecture of our scheme relies on Lagrange interpolation, the security is guar-
anteed. Experimental results show that the capacity can be achieved as about
2.37 bpp on natural images. Another scheme is a joint secret sharing and data hiding
system for BTC-compressed image secure transmission. The compressed content is
encrypted and hidden in two share images. Since each share image is half size of the
compressed content, the available channel resources are enough for share image
transmission. Not only the standard BTC compression properties such as low-
encoding/decoding complexity and acceptable reconstructed image quality are still
preserved but also transmission security is guaranteed because each block is encryp-
ted individually.
138
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

REFERENCES
[1] J. Barton, Method and Apparatus for Embedding Authentication Information Within
Digital Data, July 8, 1997. U. S. Patent 5646997.
[2] B. Macq, Lossless multiresolution transform for image authenticating watermarking,
The 10th European Signal Processing Conference (2000) 1973e1976.
[3] B. Macq, F. Dewey, Trusted headers for medical images, in: Proceedings of DFG VIII-
DII Watermarking Workshop, 1999.
[4] C. Honsinger, P. Jones, M. Rabbani, et al., Lossless Recovery of All Original Image
Containing Embedded Data, Auguest 21, 2001. U. S. Patent 6278791 BI.
[5] J. Fridrich, M. Goljan, R. Du, Lossless data embedding for all image formats, Proceed-
ings of SPIE 4675 (2002) 572e583.
[6] J. Fridrieh, M. Goljan, R. Du, Invertible authentication, Proceedings of SPIE 4314
(2001) 197e208.
[7] M. Celik, G. Sharma, A. Tekalp, et al., Reversible data hiding, Proceedings of Interna-
tional Conference on Image Processing 2 (2002) 157e160.
[8] M. Celik, G. Sharma, A. Tekalp, et al., Lossless generalized-LSB data embedding,
IEEE Transactions on Image Processing 14 (2) (2005) 253e266.
[9] J. Tian, Reversible watermarking using a difference expansion, Transactions on Circuits
and Systems for Video Technology 13 (8) (2003) 890e896.
[10] J. Tiara, High capacity reversible data embedding and content authentication, in: Pro-
ceedings of IEEE International Conference on Acoustics, Speech, and Signal Process-
ing 3, 2003, pp. 517e520.
[11] A. Alattar, Reversible watermark using the difference expansion of a generalized
integer transform, IEEE Transactions on Image Processing 13 (8) (2004) 1147e1156.
[12] L. Kamstra, H. Heijmans, Reversible data embedding into images using wavelet tech-
niques and sorting, IEEE Transactions on Image Processing 14 (12) (2005) 2082e2090.
[13] H. Kim, V. Sachnev, Y. Shi, et al., A novel difference expansion transform for reversible data
embedding, IEEE Transactions on Information Forensics and Security 3 (3) (2008) 456e465.
[14] D. Thodi, J. Rodriguez, Expansion embedding techniques for reversible watermarking,
IEEE Transactions on Image Processing 16 (3) (2007) 721e730.
[15] Y. Hu, H. Lee, J. Li, DE-based reversible data hiding with improved overﬂow location
map, IEEE Transactions on Circuits and Systems forVideo Technology 19 (2) (2009)
250e260.
[16] X. Wang, C. Shao, X. Xu, et al., Reversible data-hiding scheme for 2-D vector maps
based on difference expansion, IEEE Transactions on Information Forensics and Secu-
rity 2 (3) (2007) 311e320.
[17] Y. Hu, H. Lee, K. Chen, et al., Difference expaansion based reversible data hiding using
two embedding directions, IEEE Transactions onMultimedia 10 (8) (2008) 1500e1512.
[18] C. Lee, H. Wu, C. Tsai, et al., Adaptive lossless steganographic scheme with centralized
difference expansion, Pattern Recognition 41 (6) (2008) 2097e2106.
[19] D. Wu, G.Z. Wang, Lossless data hiding based on difference expansion and difference
shifting, Journal of Jilin University (Engineering and Technology Edition) 40 (4) (2010)
1071e1074.
[20] L. Jiang, X. Guo, H. Yang, et al., Threshold controlled scheme of difference expansion
techniques for reversible watermarking, Journal of Shanghai Jiaotong University
(Science) 15 (5) (2010) 541e548.
References
139

[21] F. Peng, Y. Lei, M. Long, et al., A reversible watermarking scheme for two-dimensional
CAD engineering graphics based on improved difference expansion, Computer-Aided
Design 43 (8) (2011) 1018e1024.
[22] Z. Ni, Y. Shi, N. Ansari, et al., Reversible data hiding, IEEE Transactions on Circuits
and Systems for Video Technology 6 (3) (2006) 354e362.
[23] J. Hwang, J. Kim, J. Choi, A reversible watermarking based on histogram shifting, in:
Proceeding of Digital Watermarking 4283, 2006, pp. 348e361. LNCS.
[24] W. Kuo, D. Jiang, Y. Huang, Reversible data hiding based on histogram, in: Proceeding
Advanced
Intelligent
Computing
Theories
and
Application
4682,
2007,
pp.
1152e1161. LNCS.
[25] M. Fallahpour, Reversible image data hiding based on gradient adjusted prediction,
IEICE Electronic Express 5 (20) (2008) 870e876.
[26] W. Tai, C. Yeh, C. Chang, Reversible data hiding based on histogram modiﬁcation of
pixel differences, IEEE Transactions on Circuits and systems for Video Technology
19 (6) (2009) 906e910.
[27] C. De Vleeschouwer, J. Delaigle, B. Macq, Circular interpretation of bijective transfor-
mations in lossless watermarking for media asset management, IEEE Tranctions on
Multimedia 5 (1) (2003) 97e105.
[28] C. De Vleeschouwer, J. Delaigle, B. Macq, Circular interpretation of histogram for
reversible watermarking, in: Proceedings of IEEE Workshop Multimedia Signal Pro-
cessing, 2001, pp. 345e350.
[29] Z. Ni, Y. Shi, N. Ansari, et al., Robust lossless image data hiding designed for semi-
fragile image authentication, IEEE Transactions on Circuits and systems for Video
Technology 18 (4) (2008) 497e509.
[30] Z. Ni, Y. Shi, N. Ansari, et al., Robust lossless image data hiding, in: Proceedings of
IEEE International Conference on Multimedia Expo, 3, 2004, pp. 2199e2202.
[31] D. Zou, Y. Shi, Z. Ni, A semi-fragile lossless digital watermarking scheme based on
integer wavelet transform, in: Proceedings of IEEE 6th Workshop Multimedia Signal
Processing, 2004, pp. 195e198.
[32] D. Zou, Y. Shi, Z. Ni, et al., A semi-fragile lossless digital watermarking scheme based
on integer wavelet transform, IEEE Transactions on Circuits and systems for Video
Technology 16 (10) (2006) 1294e1300.
[33] X. Zeng, L. Ping, X. Pan, A lossless robust data hiding scheme, Pattern Recognition 43
(4) (2010) 1656e1667.
[34] K. Hayat, W. Puech, G. Gesquiere, Scalable 3-D terrain visualization through reversible
JPEG2000-based blind data hiding, IEEE Transactions on Multimedia 10 (7) (2008)
1261e1276.
[35] C. Chang, D. Kieu, Y. Chou, Reversible information hiding for VQ indices based on
locally adaptive coding, Journal of Visual Communication and Image Representation
20 (1) (2009) 57e64.
[36] Y. Shi, Q. Xuan, Methods and Apparatus for Lossless Data Hiding, November 2, 2010.
U. S. Patent 7 826 638 B2.
[37] M. Goljan, J. Fridrich, R. Du, Distortion-free data embedding for images, in: The 4th
Information Hiding Workshop, vol. 2137, LNCS, Springer-Verlag, 2001, pp. 27e41.
[38] J. Tian, Reversible watermarking by difference expansion, Proceedings of Workshop on
Multimedia and Security (2002) 19e22.
140
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

[39] A.M. Alattar, Reversible watermark using difference expansion of quads, in: Proceed-
ings of IEEE International Conference on Acoustics, Speech, and Signal Processing,
vol. 3, 2004, pp. 377e380.
[40] Y.C. Li, C.M. Yeh, C.C. Chang, Data hiding based on the similarity between neigh-
boring pixels with reversibility, Digital Signal Processing 20 (4) (2009) 1116e1128.
[41] Z.F. Zhao, H. Luo, Z.M. Lu, J.S. Pan, Reversible data hiding based on multilevel his-
togram modiﬁcation and sequential recovery, AEUdInternational Journal of Elec-
tronics and Communications 65 (10) (2011) 814e826.
[42] K.S. Kim, M.J. Lee, H.Y. Lee, H.K. Lee, Reversible data hiding exploiting spatial cor-
relation between sub-sampled images, Pattern Recognition 42 (11) (2009) 3083e3096.
[43] D. Coltuc, P. Bolon, J.M. Chassery, Exact histogram speciﬁcation, IEEE Transactions
on Image Processing 15 (5) (2006) 1143e1152.
[44] H.C. Wu, H.C. Wang, C.S. Tsai, C.M. Wang, Reversible image steganographic scheme
via predictive coding, Displays 31 (1) (2010) 35e43.
[45] H. Luo, F.X. Yu, Z.L. Huang, H. Chen, Z.M. Lu, Reversible data hiding based on hybrid
prediction and interleaving histogram modiﬁcation with single seed pixel recovery,
Signal, Image and Video Processing 8 (1) (2014) 813e818.
[46] R.C. Gonzalez, R.E. Woods, Digital Image Processing, Second ed., Prentice Hall, Eng-
lewood Cliffs, 2002.
[47] H.W. Tseng, C.P. Hsieh, Prediction-based reversible data hiding, Information Sciences
179 (14) (2009) 2460e2469.
[48] W. Hong, T.S. Chen, C.W. Shiu, Reversible data hiding for high quality images using
modiﬁcation of prediction errors, Journal of Systems and Software 82 (11) (2009)
1833e1842.
[49] X. Wu, N. Memon, Context-based, adaptive, lossless image codec, IEEE Transactions
on Communication 45 (1997) 437e444.
[50] X. Wu, Lossless compression of continuous-tone images via context selection, quanti-
zation, and modeling, IEEE Transactions on Image Processing 6 (1997) 656e664.
[51] Z.F. Zhao, K.Y. Chau, Z.M. Lu, High capacity data hiding in reversible secret sharing,
International Journal of Innovative Computing, Information and Control 7 (11) (2011)
6411e6422.
[52] T.N. Pappas, D.L. Neuhoff, Least-squares model based halftoning, IEEE Transactions
on Image Processing 8 (8) (1999) 1102e1116.
[53] S.M. Cheung, Y.H. Chan, A technique for lossy compression of error-diffused halftones,
in: Proceedings Of International Conference on Multimedia & Expo, 2004, pp.
1083e1086.
[54] J.S. Pan, H. Luo, Z.M. Lu, A lossless watermarking scheme for halftone image
authentication, International Journal of Computer Science and Network Security 6
(2B) (2006) 147e151.
[55] M. Valliappan, B.L. Evans, D.A.D. Tompkins, F. Kossentini, Lossy compression of sto-
chastic halftones with JBIG2, in: Proceedings Of International Conference on Image
Processing, 1999, pp. 214e218.
[56] A. Shamir, How to share a secret, Communication of the ACM 22 (11) (1979) 612e613.
[57] C.C. Thien, J.C. Lin, Secret image sharing, Computers and Graphics 26 (5) (2002)
765e770.
[58] M. Naor, A. Shamir, Visual Cryptography. Advances in Cryptology: Eurocrypt’94,
Spring-Verlag, Berlin, 1995, pp. 1e12.
References
141

[59] P.Y. Lin, J.S. Lee, C.C. Chang, Distortion-free secret image sharing mechanism using
modulus operator, Pattern Recognition 42 (2009) 886e895.
[60] P.Y. Lin, C.S. Chan, Invertible secret image sharing with steganography, Pattern Recog-
nition Letters 31 (2010) 1887e1893.
[61] Z.F. Zhao, K.Y. Chau, Z.M. Lu, High capacity data hiding in reversible secret sharing,
International Journal of Innovative Computing, Information and Control 7 (11) (2011)
6411e6422.
[62] H. Luo, Z.F. Zhao, Z.M. Lu, Joint secret sharing and data hiding for block truncation
coding compressed image transmission, Information Technology Journal 10 (3)
(2011) 681e685.
[63] O.R. Mitchell, E.J. Delp, S.G. Carlton, Block truncation coding: a new approach to im-
age compression, in: Proceedings of the IEEE International Conference on Communi-
cations, 1978, 12B.1.1e12B.1.4.
142
CHAPTER 2 Lossless Information Hiding in Images on the Spatial Domain

Lossless Information
Hiding in Images on
Transform Domains
3
3.1 INTRODUCTION
3.1.1 INVERTIBLE MAPPING
Among all the methods suitable for reversible data hiding, transform domainebased
methods belong to a category, which are of great signiﬁcance to value expansione
based reversible watermarking algorithms. Note that during the reversible water-
marking process, all the operations should be reversible, including the transform
reversibility. The transform used in reversible information hiding should be in the
category of invertible mapping, thus we introduce related concepts of functions
and invertible mapping.
3.1.1.1 Functions
For a mapping f: X / Y, it is called a function if it satisﬁes the following two
conditions:
(1) Total: For any x ˛ X, there is at least one y ˛ Y, which makes xfy, that is, x and y
hold the relationship f.
(2) Many-to-One: If xfy and xfz, then y ¼ z. That is to say, multiple input values can
correspond to one output value, but one input value cannot correspond to
multiple output values. Note that, many-to-one also involves one-to-one.
For any mapping satisfying these two conditions, we can use a function y ¼ f(x)
to denote this mapping.
3.1.1.2 Injection, Surjection, and Bijection
Functions can be classiﬁed into three categories, i.e., injection, surjection, and
bijection.
(1) Injection, also called one-to-one mapping, maps different arguments x to
different images y.
(2) Surjection, also called onto, means for every image y, at least one argument x is
mapped on it.
(3) Bijection means for every image y, one and only one argument x is mapped on it.
We can prove that if the function f: X / Y is a bijection, then its inverse
CHAPTER
Lossless Information Hiding in Images. http://dx.doi.org/10.1016/B978-0-12-812006-4.00003-6
Copyright © 2017 Zhejiang University Press Co., Ltd., published by Elsevier Inc. All rights reserved.
143

mapping is a function from Y to X denoted as f 1 and the function f 1: Y / X
is also a bijection. Moreover, we also say f is invertible, that is, f is an invertible
mapping or invertible function.
Fig. 3.1 gives four combinations related to injection and surjection.
3.1.1.3 Left and Right Inverses
Assume f: X / Y and g: Y / X; if gf ¼ Ex, then g is a left inverse for f, and if
fg ¼ Ey, then g is the right inverse for f. Here, Ex means the identity function on
the set X, i.e., the function that leaves its argument unchanged. If we use mappings
to denote left and right inverses, for f: X / Y, we can prove the following
conclusions:
(1) f has a left inverse, if and only if f is injective.
(2) f has a right inverse, if and only if f is a surjective.
Obviously, in Fig. 3.1, (a) has both left and right inverses, (b) only has a left in-
verse but no right inverse, (c) only has a right inverse but no left inverse, and (d) has
neither left inverse nor right inverse.
In the design of reversible watermark embedding algorithms, the used transform
should be reversible, that is, it has both left and right inverses; in other words, it
should be bijective to meet the required reversibility.
(b)
(c)
(d)
Injection and non-surjection
Surjection and non-injection 
Injection and surjection (bijection)
Non-injection and non-surjection
x1
x2
x3
x4
y1
y2
y3
y4
x1
x2
x3
y1
y2
y3
y4
x1
x2
x
y1
y2
y3
y4
x1
x2
x3
x4
y1
y2
y3
(a)
FIGURE 3.1
The combinations of injection and surjection. (a) Injection and surjection (bijection),
(b) injection and nonsurjection, (c) surjection and noninjection, (d) noninjection and
nonsurjection.
144
CHAPTER 3 Lossless Information Hiding in Images on Transform Domains

3.1.2 REQUIREMENTS OF REVERSIBLE INFORMATION HIDING
TO INTEGER TRANSFORMS
The integer transform we refer to is a reversible transform whose input and output
are all integers and whose output is not scaled. This integer transform, in fact, is an
approximation of ﬂoat version of corresponding transform. Traditional orthogonal
transforms such as discrete cosine transform (DCT) and discrete wavelet transform
(DWT) should adopt ﬂoat versions to guarantee the orthogonality and linearity. But
for reversible watermarking systems, the inverse transform of ﬂoat version will have
rounding error. To guarantee the overall reversibility of the algorithm, we need to
impose some constraints on the embedding algorithm to avoid the expansion of
the rounding error introduced by quantizing the result of inverse transform into in-
tegers to guarantee the reversibility of integer transform. For example, the coefﬁ-
cient data C (ﬂoats) can be obtained by performing the ﬂoat DCT forward
transform on the image data X (integers):
C ¼ DCTðXÞ
(3.1)
If C is not further processed, it can be performed with the direct inverse trans-
form to obtain
X0 ¼ DCT1ðCÞ
(3.2)
As long as the ﬂoat precision of the computer or other digital signal processor is
sufﬁciently high, we can guarantee that the rounding result [X] (integers) of the in-
verse transform X0(ﬂoats) is equal to the original input image data X: [X0] ¼ X, where
[.] is the rounding operation to get the closest integer of a ﬂoat. However, if we
perform other operations on the coefﬁcient C before the inverse transform, for
example, the watermark embedding operation, which turns C into CW, then
we can get the inverse transform result XW:
XW ¼ DCT1ðCWÞ
(3.3)
After the rounding operation, we can obtain [XW], thus the error between XW and
[XW] may result in that the error between the forward DCT transform result CW 0
of [XW]:
CW0 ¼ DCTð½XWÞ
(3.4)
and CW exceeds 2 times of the general rounding error, that is, larger than 1. This will
result in the loss of embedded watermark data and the irreversibility of the whole
algorithm.
From this discussion, we can see that, unless we impose special requirements on
the embedding algorithm, traditional ﬂoat version transforms cannot guarantee the
overall reversibility of the reversible watermarking algorithms. Therefore, for the
occasions where we need transform domainebased algorithms, we consider using
3.1 Introduction
145

integer transforms to replace the ﬂoat versions of the corresponding transforms.
These integer transforms should have the following two properties:
(1) The input and output are both integers, that is, integer-to-integer.
(2) The transform is reversible, that is, it is bijective.
In the history, the deﬁnitions of integer transforms [1e12] are not so explicit.
Some refer to the transforms whose whole conversion process is based on integer
arithmetic without rounding error, but the results are often dyadic rational numbers
rather than integers in the true sense [1e4]; some refer to the transforms whose input
and output are integers, although the intermediate calculations may involve ﬂoating
points and rounding operations [10e12]. For the latter, there are two cases, one is
that the output is subject to scaling operations such as Algorithm B given in
Ref. [10], that is, each output is in fact an integer approximation of N times corre-
sponding ﬂoating-point real number; the other is that each output is an integer
approximation of corresponding ﬂoating-point real number without scaling such
as Algorithm A given in Ref. [10], which is the true sense of integer approximation
of corresponding ﬂoating-point conversion.
From the reversibility requirement of reversible watermarking algorithms, i.e., the
transform should have both a left and a right inverse, we can see that, among the afore-
mentioned various integer transforms, the integer transforms that are really suitable for
reversiblewatermarkingare onlythose integer-to-integer transforms whose outputisan
integer approximation of corresponding ﬂoating-point real number without scaling.
Note that for the integer transform whose conversion result is a dyadic rational number
[2e5], its output is not an integer in the true sense; there will be accumulated rounding
errors and irreversible problems mentioned earlier; However, for the integer transform
whose output is subject to scaling operations such as Algorithm B in Ref. [10], similar
to the situation given in Fig. 3.1b, there is no guarantee that it is right invertible, there-
fore, it cannot guarantee that the overall algorithm is reversible. In this chapter, the
integer DCT (IntDCT) we adopt is the 8  8 transform derived from Algorithm A
given in Ref. [10] (for the one-dimensional case), whereas the integer DWT we adopt
is the integer version of the famous Cohen-Daubechies-Feauveau (CDF) (2,2) wavelet
[13] obtained by using the lifting scheme in Ref. [14]. Both integer transforms satisfy
the reversibility requirement of reversible watermarking algorithms.
3.2 OVERVIEW OF TRANSFORM-BASED
INFORMATION HIDING
In general, transform-based information hiding algorithms are based on spectrum
spread. Among various information hiding algorithms, transform domainebased
algorithms are the most frequently used information-embedding algorithms.
Compared with the spatial domain, transform domain is more complex, but it is
robust, even if a lot of payload is embedded, the visual effect is still very good.
146
CHAPTER 3 Lossless Information Hiding in Images on Transform Domains

Now a widely accepted view is that secret information should be embedded in the
middle-frequency coefﬁcients of the transform domain of the host image. This is
because the high-frequency part has little effect on the quality of the original image,
whereas the low-frequency part can achieve good robustness (after JPEG compres-
sion, a large part of the high-frequency components may be quantized to 0), so the
middle-frequency part is a good compromise between visibility and robustness. Here
we only introduce several kinds of common discrete transform domainebased
algorithms.
3.2.1 DISCRETE COSINE TRANSFORMeBASED
INFORMATION HIDING
The DCT-based orthogonal transform method proposed by Ahmed et al. [15] is
considered to be the best transform domain method for images and speech. For
DCT, because the algorithm used in JPEG (image compression standard) is based
on two-dimensional 8  8 DCT blocks, it is more robust to compression and ﬁltering
operations. The following is the shortcoming of DCT: the main feature of DCT is
that after the conversion of an image from the spatial domain to the frequency
domain, the image has a good timeefrequency property, but this property is not
made full use of during the information-embedding process. Although the visual
quality of the image obtained is greatly improved, for the image without complex
texture, its embedding capacity is still high, however, when the texture is very com-
plex, due to the inability of the algorithm to recognize the texture complexity of the
image, there may be a small embedding capacity.
Koch was the ﬁrst to propose an effective watermarking scheme based on DCT
[16]. This scheme ﬁrst divided the image into 8  8 blocks for further calculation.
Then the scheme selected a pair of frequency coefﬁcients from the predetermined 12
pairs of middle-frequency DCT coefﬁcients to embed information.
The DCT-based algorithm proposed by Cox et al. is not based on blocking, but
performs DCT on the whole image and adopts the spectrum spreading information
hiding technique [17]. By modifying the ﬁrst N coefﬁcients that perceive most
strongly the human visual system (HVS), it achieves the information hiding purpose.
Unfortunately, because the embedding strength of the DCT coefﬁcients are different,
no further discussion was given in their scheme; however, the algorithm is robust to
various image-processing operations, which made a great contribution to improving
the robustness of information hiding algorithms.
Tao et al. proposed an adaptive information hiding scheme [18]. This scheme per-
formed data hiding on the alternating current (AC) DCT coefﬁcients. In this scheme,
the authors proposed a local classiﬁcationebased algorithm and adopted the masking
effects of HVS to determine the sensitivity to noise. Since this method requires the
original image during the watermark extraction, it is a nonblind watermarking scheme.
Compared with the traditional irreversible watermarking algorithms, there are
relatively fewer DCT domain reversible watermarking algorithms. Two typical algo-
rithms are Yang et al.’s IntDCT coefﬁcients based histogram modiﬁcation scheme
3.2 Overview of Transform-Based Information Hiding
147

[19] and the DCT quantized coefﬁcients based reversible watermarking algorithm
proposed by Chen and Kao [20].
3.2.2 DISCRETE FOURIER TRANSFORMeBASED
INFORMATION HIDING
Assume we use f(x1,x2) to denote an image of size N1  N2, where x1, x2 are all in-
tegers and 0  x1  N1, 0  x2  N2; then its two-dimensional discrete Fourier
transform is as follows:
Fðk1; k2Þ ¼
X
N11
n1¼0
X
N21
n2¼0
fðx1; x2Þe
2px1k1
N1 
2px2k2
N2
(3.5)
and the inverse discrete Fourier transform can be given as follows:
fðx1; x2Þ ¼
1
N1N2
X
N11
k1¼0
X
N21
k2¼0
Fðk1; k2Þe
2px1k1
N1 þ
2px2k2
N2
(3.6)
Here, f(x1,x2) and F(k1,k2) form a DFT pair. In general, the computational load to
perform DFT on a natural image is huge.
The basic properties of DFT are as follows:
(1) Translation
If an image is translated in the spatial domain, then its phase will also be
translated in the frequency domain, and we have:
Fðk1; k2Þ ¼ exp½  jðak1 þ bk2Þ4f ðx1 þ a; x2 þ bÞ
(3.7)
By using this property of DFT, the energy of an image concentrates on the low-
frequency region, after translation, since f(x1,x2) and F(k1,k2) are periodical
functions, the energy of the image will concentrate on the center of the image,
which facilitates various operations on the image in the frequency domain and
also accord with our visual perception.
(2) Scaling
The scaling effect in the frequency domain is just opposite to that in the spatial
domain, which can be described as follows:
1
r F
k1
r ; k2
r

4fðrx1; rx2Þ
(3.8)
(3) Rotation
If the image is rotated in the spatial domain by an angle q, then the corre-
sponding image in the frequency domain is also rotated by an angle q, which
can be described as follows:
Fðk1 cos q  k2 sin q; k1 sin q þ k2 cos qÞ4fðx1 cos q  x2 sin q; x1 sin q
þ x2 cos qÞ
(3.9)
148
CHAPTER 3 Lossless Information Hiding in Images on Transform Domains

Pereira et al. presented a watermarking scheme [21] based on the fast Fourier
transform domain [i.e., FFT, which is proposed to reduce the computational
complexity of DFT, by using the periodicity and symmetry of the complex exponen-
tial WN ¼ ej2p/N and using the butterﬂy structure to release the computational
burden of DFT, where the complexity is not higher than N1N2  log2(N1N2)]. The
watermark is composed of two parts, one is the template and the other is the spread
spectrum signal containing secret information and payload. The template does not
contain any information that can be used to detect the watermark information in
the DFT-transformed image. If there is a template in the image, then we calibrate
the image based on the embedded template, and then extract the watermark informa-
tion from the calibrated image. This scheme is robust to various image processing
operations such as rotation, scaling, and translation; however, the attackers can
attack the embedded template by exchanging their own information, which makes
the watermark security not easy to guarantee.
3.2.3 DISCRETE WAVELET TRANSFORMeBASED INFORMATION
HIDING
With the new JPEG compression standard determining to use the new technology
wavelet transform, even though it has not been widely used until now, if you want
that your own researched and developed information hiding algorithm has more vi-
tality, you must take into account the wavelet transform. The wavelet transform is
developed on the basis of Fourier, and compared with DFT or DCT, its ﬂexibility
in the nonstationary signal analysis is stronger, its ability to adapt to the visual char-
acteristics of human eyes is stronger, and it is therefore considered to be a fairly ac-
curate model of the HVS.
Wavelet transform provides a local analysis of time and space frequencies by
performing detailed multiresolution analysis on the signal with the scaling and trans-
lation operations, which can be focused on any details of the signal, so the wavelet
transform is also known as “mathematical microscope.”
The wavelet transform can divide the image into a low-resolution approximation
image LL and three low-frequency detail images, i.e., HL (horizontal), LH (verti-
cal), and HH (diagonal). After wavelet transform, the image is divided into multiple
scales. Fig. 3.2 shows a two-level DWT decomposition of the Lena image.
As can be seen from Fig. 3.2, once every wavelet transform is done, the low-
frequency part of it at the same level of resolution is decomposed, whereas the
high frequency part is retained, due to the fact that the low-frequency part concen-
trates most of the energy of the image, whereas the high-frequency part just records
some of the edge of the image information. Therefore, in practice, we generally
embed data in the high-frequency part, while preserving the low-frequency part of
the information as much as possible; otherwise it will affect the quality of the recon-
structed image.
3.2 Overview of Transform-Based Information Hiding
149

Corvi et al. proposed one of the ﬁrst schemes for information hiding in the
wavelet transform domain [22]. The scheme randomly generates a spread spectrum
sequence as secret information based on a key and then embeds the secret informa-
tion in the low-frequency part of the wavelet-transformed image. Since the data are
embedded in the low-frequency part, the quality of the reconstructed image is not
affected; however, this algorithm needs original carrier during the detection and
extraction of hidden information.
The watermarking scheme proposed by Kundur utilized the multiresolution
property of the wavelet-transformed image together with the human perceptual
system (HVS) model [23]. Unlike the scheme proposed by Corvi et al., it embeds
secret data in three high-frequency detail components at the same resolution. On
the other hand, the selection of secret data is also different from that of Corvi
et al.’s scheme; Kundur’s scheme uses a binary image as secret information. The
speciﬁc method is as follows: the host image and the watermark message are
both converted from the spatial domain into the wavelet domain, and the host im-
age is independently performed with wavelet transform x times, resulting in 3x
high-frequency components, whereas the watermark message is performed with
wavelet transform only once, resulting in three high-frequency components and
a low-frequency component. The selected rectangles from the detail components
of each layer of the host image are with the same size of the corresponding com-
ponents of the watermark message; ﬁnally each watermark information is hidden
in each rectangle based on the reversible integer wavelet transformebased infor-
mation hiding scheme. In addition, Xuan et al. [24] proposed an integer wavelete
based histogram gap method, by which the wavelet coefﬁcient histogram continues
to form a gap for embedding.
LH2
HL2
HL2
LL2
LH1
HL1
HH1
FIGURE 3.2
Two-level discrete wavelet transform decomposition of the Lena image.
150
CHAPTER 3 Lossless Information Hiding in Images on Transform Domains

3.3 INTEGER DISCRETE COSINE TRANSFORMeBASED
SCHEMES
3.3.1 INTEGER DISCRETE COSINE TRANSFORM
3.3.1.1 One-Dimensional Integer Discrete Cosine Transform
and Its Fast Algorithm
Let x(n) (n ¼ 0, 1, ., N1) be a real input sequence. We assume that N ¼ 2t, where
t > 0. The scaled DCT of x(n) is deﬁned as follows:
XðkÞ ¼
X
N1
n¼0
xðnÞcos pð2n þ 1Þk
2N
;
k ¼ 0; 1; .; N  1
(3.10)
Let CN be the transform matrix of the DCT, that is
CN ¼

cos pð2n þ 1Þk
2N

k;n¼0;1;.;N1
(3.11)
To derive the fast algorithm, we ﬁrst get a factorization of the transform matrix
based on the following lemma [5]:
Lemma 3.1: The transform matrix CN can be factored as
CN ¼ PN
"
IN=2
0
0
UN=2
#"
CN=2
0
0
CN=2
#"
IN=2
0
0
DN=2
#"
IN=2
bIN=2
IN=2
bIN=2
#
(3.12)
where IN/2 is the identity matrix of order N/2, bIN=2 is the matrix derived by reversing
the rows of IN/2, and DN/2 is a diagonal matrix deﬁned as follows:
DN=2 ¼ diag

2 cos p
2N; 2 cos 3p
2N; .; 2 cos ðN  1Þp
2N

(3.13)
UN=2 ¼
2
666666664
0:5
0
0
.
0
0
0:5
1
0
.
0
0
0:5
1
1
.
0
0
.
.
.
.
.
.
0:5
1
1
.
1
0
0:5
1
1
.
1
1
3
777777775
(3.14)
PN is a permutation matrix deﬁned as follows:
PN ¼
2
666666666664
1
0
.
0
0
0
.
0
0
0
.
0
1
0
.
0
0
1
.
0
0
0
.
0
0
0
.
0
0
1
.
0
.
.
.
.
.
.
.
.
0
0
.
1
0
0
.
0
0
0
.
0
0
0
.
1
3
777777777775
(3.15)
3.3 Integer Discrete Cosine TransformeBased Schemes
151

and CN/2 is the transform matrix of the scaled DCT with length N/2.
Float-point multiplications are needed for the algorithm when the matrix DN/2 is
multiplied by a vector. To avoid ﬂoat multiplications, we want to turn this matrix into
products of lifting matrices and then approximate the elements of the lifting matrices
by numbers with the form b/2l, where b and l are integers. To get an IntDCT, we can
turn the matrix into DN/2 ¼ EN/2FN/2, where
EN=2 ¼ diag

ﬃﬃﬃ
2
p
; 1; .; 1

(3.16)
FN=2 ¼ diag

ﬃﬃﬃ
2
p
cos p
2N; 2 cos 3p
2N; .; 2 cos ðN  1Þp
2N

(3.17)
Lemma 3.2: The determinant of the matrix FN/2 is 1, that is, det(FN/2) ¼ 1.
The matrix FN/2 can be factored into the product of lifting matrices as follows:
FN=2 ¼
( Y
N=41
k¼0
	
L2k;2kþ1ða2k  1ÞL2kþ1;2kð1Þ  L2k;2kþ1
 1
a2k
 1

L2kþ1;2kða2kÞ

)
$
( Y
N=41
k¼1
	
L2k1;2kða2k1  1ÞL2k;2k1ð1Þ  L2k1;2k

1
a2k1
 1

L2k;2k1ða2k1Þ

)
(3.18)
where Li, j(s) are lifting matrices with order N/2, which is deﬁned as follows:
Deﬁnition 3.1: A lifting matrix is a matrix whose diagonal elements are 1s, and
only one nondiagonal element is nonzero. If the order of a lifting matrix is N, we use
the notation Li, j(s) (i s j) to denote the lifting matrix whose only nonzero element
is at the ith row and the jth column (i, j ¼ 0, 1, ., N1) and whose nondiagonal
nonzero element is s.
In Eq. (3.18), ak is deﬁned as follows:
a0 ¼
ﬃﬃﬃ
2
p
cos p
2N; ak ¼ 2ak1 cos ð2k þ 1Þp
2N
k ¼ 1; 2; .; N=2  1
(3.19)
To avoid ﬂoat multiplications, we can approximate the nonzero element of the
lifting matrices by numbers that are of the form b/2l, where b and l are integers,
that is, we replace every nonzero element s by RB(s) deﬁned as follows:
Deﬁnition 3.2: The notation RB(s) is used to denote a number that is of the form
b/2l (dyadic rational number) and approximates to the real number s.
Furthermore, we replace aj and 1/aj in Eq. (3.18) by RB(aj) and RB(1/aj) and get
an approximating matrix for FN/2 as follows
FN=2 ¼
( Y
N=41
k¼0
	
L2k;2kþ1ðRBða2kÞ  1ÞL2kþ1;2kð1Þ  L2k;2kþ1

RB
 1
a2k

 1

L2kþ1;2kð RBða2kÞÞ

)
$
( Y
N=41
k¼1
	
L2k1;2kðRBða2k1Þ  1ÞL2k;2k1ð1Þ  L2k1;2k

RB

1
a2k1

 1

L2k;2k1ð RBða2k1ÞÞ

)
(3.20)
152
CHAPTER 3 Lossless Information Hiding in Images on Transform Domains

We also approximate the matrix EN/2 by
EN=2 ¼ diag

RB

ﬃﬃﬃ
2
p 
; 1; .; 1

(3.21)
Then, the correspondent approximating matrix for the transform matrix CN is
CN ¼ PN
"
IN=2
0
0
UN=2
#"
CN=2
0
0
CN=2
#"
IN=2
0
0
DN=2
#"
IN=2
bIN=2
IN=2
bIN=2
#
(3.22)
where
DN=2 ¼ EN=2FN=2
(3.23)
If the same method is used to factor the matrix CN=2 recursively until the order is
1, we get the complete factorization of CN. The matrix CN deﬁnes a new transform
that does not need ﬂoat multiplications. Finally, we call it an IntDCT.
Deﬁnition 3.3: Assume that N ¼ 2t. The transform matrix of an IntDCT CN is
deﬁned recursively by C1 ¼ f1g, and
C2j ¼ P2j
	 I2j1
0
0
U2j1

"
C2j1
0
0
C2j1
#	
I2j1
0
0
D2j1

"
I2j1
bI2j1
I2j1
bI2j1
#
(3.24)
The transform is not unique. Actually, any choice of function RB determines a
transform. Based on the deﬁnition, we get a fast algorithm for the IntDCTas follows.
Algorithm 3.1: Fast Algorithm for IntDCT:
Step 1: Compute
gðnÞ ¼ xðnÞ þ xðN  1  nÞ
hðnÞ ¼ xðnÞ  xðN  1  nÞ;
n ¼ 0; 1; .; N=2  1
(3.25)
Step 2: Compute bh ¼ EN=2FN=2h, where
h ¼ ðhð0Þ; hð1Þ; .; hðN=2  1ÞÞT
bh ¼

bhð0Þ; bhð1Þ; .; bhðN=2  1Þ
T
(3.26)
Step 3: Compute the IntDCTwith length N/2 for sequences g(n) and bhðnÞ, and let
the outputs be G(k) and H(k), respectively. Steps 1 and 2 can be used recursively
during the computation.
Step 4: Compute
Xð2kÞ ¼ GðkÞ;
k ¼ 0; 1; .; N=2  1
Xð1Þ ¼ Hð0Þ=2
Xð2k þ 1Þ ¼ HðkÞ  Xð2k  1Þ; k ¼ 1; 2; .; N=2  1
(3.27)
3.3 Integer Discrete Cosine TransformeBased Schemes
153

3.3.1.2 Two-Dimensional Integer Discrete Cosine Transform
and its Fast Algorithm
This section introduces the 2D-IntDCTs proposed in Ref. [5]. In general, a 2D trans-
form can be generated by simply using the tensor products of the corresponding 1D
transform, that is, we can process the 2D input array by implementing the 1D trans-
form along its rows and columns consecutively (also called the rowecolumn
method). This method gives a 2D transform that has a separable kernel. In this sec-
tion, we introduce a nonseparable 2D integer transform by combining the 1D integer
transform and the polynomial transform. The 2D transform proposed in Ref. [5]
needs far fewer numbers of operations than the rowecolumn 2D transform does.
Let x(n,m) (n ¼ 0, 1, ., N1; m ¼ 0, 1, ., M1) be the 2D input sequence. We
assume that M and N are powers of 2 and M  N. Therefore, we can write N ¼ 2t and
M ¼ 2JN, where t > 0 and J  0, respectively. If M < N, the deﬁnition can also be
used by simply interchanging N and M. The scaled 2D DCT is deﬁned as follows:
Xðk; lÞ ¼ P
N1
n¼0
P
M1
m¼0
xðn; mÞcos pð2n þ 1Þk
2N
cos pð2m þ 1Þl
2M
;
k ¼ 0; 1; .; N  1;
l ¼ 0; 1; :::; M  1
(3.28)
3.3.1.2.1 Two-Dimensional Integer Discrete Cosine Transform
Based on the 1D IntDCT and the polynomial transform, we have the following
integer 2D IntDCT [5].
Deﬁnition 3.4: The 2D-IntDCT of x(n,m) is X(k,l) (k ¼ 0, 1,.,N1; l ¼ 0,
1,.,M1), which can be computed in the following steps.
Step 1: Compute y( p,m) ¼ x(q( p,m),m), where q( p,m) is deﬁned as follows:
qð p; mÞ ¼
8
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
<
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
:
2f

p; m
2

m is even and f

p; m
2

< N
2
2N  1  2f

p; m
2

m is even and f

p; m
2

 N
2
2f

p; M  m þ 1
2

m is odd and f

p; M  m þ 1
2

< N
2
2N  1  2f

p; M  m þ 1
2

m is odd and f

p; M  m þ 1
2

 N
2
p ¼ 0; 1; .; N  1; m ¼ 0; 1; .; M  1
(3.29)
where f( p,m) ¼ ((4p þ 1)m þ p) mod N.
Step 2: Compute the 1D-IntDCT of each row of the array y(p,m), and let the
output array be V( p,l).
154
CHAPTER 3 Lossless Information Hiding in Images on Transform Domains

Step 3: Compute a polynomial transform
AkðzÞ h
X
N1
p¼0
VpðzÞbz pkmod

z2M þ 1

;
k ¼ 0; 1; .; N  1
(3.30)
where
VpðzÞ ¼ PM1
l¼0 Vðp; lÞzl  P2M1
l¼Mþ1 Vðp; 2M  lÞzl;
bzhz2Jþ2mod z2M þ 1,
and then we get
BkðzÞ h AkðzÞz2Jkmod

z2M þ 1

(3.31)
Step 4: Compute
XkðzÞ ¼
X
2M1
l¼0
Xðk; lÞzl h 1
2

BkðzÞ þ Bk

z1
mod

z2M þ 1

(3.32)
where only X(k,l) (k ¼ 0, 1, ., N1; l ¼ 0, 1, ., M1) is needed.
It can be proved that if the IntDCT in Step 2 is replaced by the ordinary DCT, the
2D-IntDCT deﬁned earlier is the scaled version of the ordinary 2D-DCT deﬁned in
Eq. (3.28). Therefore, the 2D-IntDCT can also be viewed as the integer approxima-
tion to the ﬂoat-point 2D-DCT. However, it is different from the rowecolumn 2D-
IntDCT.
3.3.1.2.2 Reconstruction Algorithm for 2D-Integer Discrete Cosine
Transform
The aforementioned 2D-IntDCT is invertible if the 1D-IntDCT used in Step 1 is
invertible. In addition, the inverting process can be described as follows.
Algorithm 3.2: Fast Algorithm for Inverse 2D-IntDCT:
Step 1: Generate the polynomials
XkðzÞ ¼
X
M1
l¼0
Xðk; lÞzl 
X
2M1
l¼Mþ1
Xðk; 2M  lÞzl, and compute
AkðzÞ h

XkðzÞ þ XNkðzÞzM
zk2Jmod

z2M þ 1

(3.33)
Step 2: Compute a polynomial transform
VpðzÞ h 1
N
X
N1
k¼0
AkðzÞbz pkmod

z2M þ 1

;
p ¼ 0; 1; .; N  1
(3.34)
where the coefﬁcient of Vp(z) is denoted by V( p,l).
Step 3: Compute the inverse 1-D IntDCT of each row of the array V( p,l), and let
the output array be y( p,m).
3.3 Integer Discrete Cosine TransformeBased Schemes
155

Step 4: Reorder the array y( p,m) to get x( p,m) ¼ y(r(n,m),m), where
rðn; mÞ ¼
8
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
<
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
:
g
n
2; m
2

m and n are even
g

N  n þ 1
2
; m
2

m is even and n is odd
g
n
2; M  m þ 1
2

n is even and m is odd
g

N  n þ 1
2
; M  m þ 1
2

m and n are odd
n ¼ 0; 1; .; N  1; m ¼ 0; 1; .; M  1
(3.35)
and the function g(n,m) ¼ ((4m þ 1)1(nm)) mod N.
3.3.1.3 Comparison of Discrete Cosine Transform and Integer Discrete
Cosine Transform
IntDCT has at least two advantages over DCT. First, IntDCT needs no ﬂoating-point
multiplications. The ﬂoating-point multiplications are replaced by lifting steps that
need only integer operations and shifting. This is very important for applications in
mobile devices since it is easier and cheaper (power saving) to realize integer oper-
ations than to implement ﬂoating-point multiplications. Second, if a sufﬁcient word
length is used to represent the intermediate data of IntDCT, the round-off error can
be eliminated completely. There is no information lost after the transform even if it is
computed in a ﬁxed-point computer. Therefore, it can be used for lossless compres-
sion. Furthermore, we can also approximate the lifting step as shown in Fig. 3.3 by
using a nonlinear transform, i.e., approximate a DCT by an invertible integer to
integer nonlinear transform as follows:
byðiÞ ¼ xðiÞ þ Psxð jÞR;
byðkÞ ¼ xðkÞ;
ksi
(3.36)
This transform is nonlinear! In addition, it maps integer into integer! The
nonlinear transform is invertible, and its inverse is as follows:
xðiÞ ¼ byðiÞ  Psbyð jÞR;
xðkÞ ¼ byðkÞ;
ksi
(3.37)
x(i)
y(i)
y(j)
x(j)
s
FIGURE 3.3
Flowchart of a lifting step.
156
CHAPTER 3 Lossless Information Hiding in Images on Transform Domains

Although DCT is also an invertible transform, the round-off error always exists
when we approximate the trigonometric functions. It is impossible to perfectly
construct the original data. Therefore, it cannot be used for lossless image compres-
sion. However, since IntDCT is a new transform, its performance, such as the decor-
relation property, remains to be questioned, and more experiments are needed to be
done. Generally speaking, the performance of IntDCT is related to the number of
bits used for the lifting multipliers. In the aforementioned algorithms, it is equivalent
to the accuracy of approximating (aj) or (1/aj) by RB(aj) or RB(1/aj). It is very difﬁ-
cult to give a theoretical analysis on the accuracy and performance. Fortunately,
experiments in Refs. [25] and [26] have shown that even with a very coarse approx-
imation, the performance of eight-point and 16-point IntDCT is still close to that
of DCT.
3.3.2 INTEGER DISCRETE COSINE TRANSFORMeBASED LOSSLESS
INFORMATION HIDING SCHEME USING COMPANDING
TECHNIQUE
As we know, natural images’ histogram is shaped differently. And bit-shifts on pixel
values will cause much noticeable distortion to images. These two facts make the
companding and bit-shift-based approach hard to be suitable for lossless information
hiding applications in images, although the capacity performance is quite a desirable
advantage of this reversible technique. Yang et al. proposed a 2-dimensional
IntDCTebased approach [27] to circumvent these problems and use the bit-shift
operation of companding technique successfully in reversible watermarking for im-
ages. In 2003, the authors from Philips Research proposed a reversible image water-
marking scheme [28], which also exhibits high capacity, but this scheme is not based
on bit-shift operations. In this section, we ﬁrst review some relevant knowledge on
the approach proposed in Ref. [29] and integer-to-integer DCT, then introduce Yang
et al.’s reversible image watermarking scheme [27], and ﬁnally introduce the simu-
lation results given in Ref. [27].
3.3.2.1 Related Knowledge
3.3.2.1.1 The Distribution of 8  8 Discrete Cosine Transform
Coefﬁcients
With regard to the distribution of 8  8 DCT transform coefﬁcients, Lam analyzed it
theoretically [30]; the distribution of 8  8 DCT coefﬁcients of most natural images
can be summarized as a generalized Gaussian distribution, and the higher the image
redundancy, the narrower the shape of the distribution (i.e., the larger the number of
coefﬁcients with small values is, the better role the bit-shift operation plays). We
divide the original gray-scale image of size M  N into 8  8 blocks (assuming
the total number of image blocks is S), and perform the 8  8 DCT transform
on each pixel block Bi (i ¼ 0, 1, ., S1) to obtain S coefﬁcient blocks Ci (i ¼ 0,
1, ., S1). Next, for all S coefﬁcient blocks Ci (i ¼ 0,1, ., S1), we
take all AC coefﬁcients ci(p,q) at position (p,q) to compose 63 AC coefﬁcient
3.3 Integer Discrete Cosine TransformeBased Schemes
157

sets Gj ( j ¼ 1, 2, ., 63), as shown in Fig. 3.4. Ref. [30] provided all typical
histogram distributions for the direct current (DC)-efﬁcient set and all AC coefﬁcient
groups Gj( j ¼ 1, 2, .,63) as shown in Fig. 3.5. As can be seen from Fig. 3.5, the
histogram of DCT coefﬁcient group Gj shows the trend of being gradually concen-
trated near the value 0 with the AC coefﬁcient tending to be of high frequency, which
gives us a revelation: if we perform the bit-shift operation on high-frequency DCT
coefﬁcients, we should be able to get the best watermarking performance in terms
of peak signal-to-noise ratio (PSNR)-bit-rate curve. However, note that owing to
the presence of rounding errors and accumulated errors during the calculation
process for ﬂoating-point DCT, it is difﬁcult to meet the reversibility requirements
for reversible watermarking algorithms; we can only consider the integer transforms
that meet the reversibility requirements (discussed in detail in Section 3.1.2).
The q-th column 
. . 
. 
S 
C0
C1
CS-1
c0 (p,q) 
c1 (p,q) 
cS-1 (p,q) 
The p-th row 
8×8 Coefficient Blocks  
Gj={gji,i=0,1,…,S-1}  
gji = ci (p,q), 
j=8×p+q(p=0,1,…,7; q=0,1,…,7), j>0.
FIGURE 3.4
8  8 Discrete cosine transform coefﬁcient grouping.
DC coefficient group 
AC coefficient groups 
FIGURE 3.5
8  8 Discrete cosine transform direct current (DC) and alternating current (AC)
coefﬁcient groups’ distribution shape.
158
CHAPTER 3 Lossless Information Hiding in Images on Transform Domains

3.3.2.1.2 Bit-Shift-Based Reversible Watermarking Technique
Assume there is a time discrete signal x of length N: x ˛ {0, 1, ., 2m1}N, where m
is the number of bits used to represent a sample. The bit-shift operation used in the
companding techniqueebased watermarking algorithm [29] can be brieﬂy described
as follows.
Note that if xmax is not larger than half the maximum possible value, i.e.,
xmax  2m11, it may be ampliﬁed by 2 (left shifted by 1 bit) without introducing
any overﬂow in the quantization:
y0 ¼ 2x
(3.38)
e.g., x ¼ 5(101B), y0 ¼ 10(1010B).
Obviously, the result contains only even-valued samples. So the least signiﬁcant
bit (LSB) of y0 is available for embedding a watermark and additional information.
This result can be generalized to the case of p bit-shift operations, which allows the
embedding of p bits in the LSB of a signal x:
y0 ¼ 2px
(3.39)
with
xmax  2mp1 and p ¼ 1; 2; .; m  1
(3.40)
Note that as long as Eq. (3.40) is satisﬁed, the embedded watermark and addi-
tional bits can be retrieved from the LSB of y0 and the original signal x can be
restored perfectly by one bit-shift operation to the right side.
In some cases, Eq. (3.40) is not satisﬁed, and an overﬂow can be prevented by
applying a companding function. In this book, a companding process includes the
bit-shift operation, a compression function C, and an expansion function E, and C
and E are related as follows:
EC x ¼ I xðI: identity functionÞ
(3.41)
In the digital case, the quantized version of C and E are CQ and EQ, where Q re-
ﬂects a quantization operation. It can be easily seen that, for some n, CQ may map
more than one input x[n] to the same output xQ[n] and EQ cannot reconstruct the
original signal, i.e.,:
xE½n ¼ ðEQCQxÞ½nsI x½n
(3.42)
Then the companding error can be deﬁned as
q½n ¼ x½n  ðEQCQxÞ½n ¼ x½n  xE½n
(3.43)
Note that this companding error will not be 0 whenever a non-one-to-one map-
ping occurs in CQ. To make the embedding process reversible, we must losslessly
compress q[n] as a part of the overhead bits embedded in the space saved from
the bit-shift operations. While extracting the embedded data and restoring the orig-
inal signal, the expansion function and inverse bit-shift operations are performed.
3.3 Integer Discrete Cosine TransformeBased Schemes
159

The embedding and extracting structures and further details about bit-shift and com-
panding process are presented in Ref. [29].
The reversible watermarking approach proposed in Ref. [29] shows high capac-
ity, which is close to 1 bit per sample for audio signals. However, due to the disad-
vantage of natural images’ histogram, this approach is obviously not suitable for
images. We give a watermarked example in Fig. 3.6 as a simulation result from
an original 512  512-sized 256 grayscale Lena image by using the companding
scheme directly in the spatial domain. We can see from Fig. 3.6b that although
the capacity reaches 262,144 (512  512) bits, the quality of the watermarked image
is completely unacceptable and the bit cost (1,027,315 bits) for the companding
error is even much more than the capacity! In our simulations, although companding
functions can be improved to gain a better result in some cases, the bits used to repre-
sent companding errors are hard to be less than the saved space.
3.3.2.1.3 Integer Discrete Cosine Transform and Left and Right
Invertible Mapping
The problem of histogram shape suggests our searching for a way to modify an im-
age’s original histogram to exhibit a “good” shape with as many samples as possible
around small values like Laplacian distribution shape. Of course this modiﬁcation
must be a reversible transformation if the reversibility is required. It is easily seen
that many integer-to-integer transforms satisfy this condition.
With regard to the energy-concentrating ability, we consider DCTs. Lam and
Goodman [30] analyzed the distribution of 2D 8  8 DCT coefﬁcients of 8  8 im-
age blocks and provide a theoretical explanation for the generalized Gaussian
FIGURE 3.6
Comparison between the watermarked Lena image and the original Lena. (a) Original 256
grayscale Lena (b) Watermarked Lena using the companding scheme directly in the
spatial domain: Peak signal-to-noise ratio ¼ 6.457 dB, capacity < 0.
160
CHAPTER 3 Lossless Information Hiding in Images on Transform Domains

distributiondthe distribution of the DCT coefﬁcients of most natural images. In
many cases, the shape of the generalized Gaussian distribution looks close to the
Laplacian distribution, which makes it possible to use the bit-shift scheme in the
transformed domain of integer-to-integer version of ﬂoat-point 2D DCT.
We perform 2D-IntDCT on each 8  8 block and bit-shifts on each coefﬁcient
group consisting of coefﬁcients from all coefﬁcient blocks corresponding to the
same position in an 8  8 array. For example, if we divide a 512  512 sized image
into 8  8 blocks Bij (i ¼ 0,1,.,4095; j ¼ 0,1,.,63), which corresponds to coefﬁ-
cient blocks Cij (i ¼ 0, 1, ., 4095; j ¼ 0, 1, ., 63), all the coefﬁcients collected
from the 4096 blocks in the same position j in each coefﬁcient block constitute a co-
efﬁcient group Gji ( j ¼ 0, 1, ., 63; i ¼ 0, 1, ., 4095) as shown in Fig. 3.4. The
histogram of each Gji exhibits a Laplacian-like shape, which can be explained in
Fig. 3.5 [30]. Then we can perform the bit-shift operations on all Gji to embed wa-
termarks and other overhead bits as described in Sections 3.3.2.2e3.3.2.5.
Note that the integer data type of outputs in the forward or inverse transform is
not sufﬁcient to ensure the reversibility of Yang et al.’s reversible watermarking
scheme [27]. Another important factor is that the chosen IntDCT must be both a
left-invertible and a right-invertible mapping. For example, when we perform the
forward 2D IntDCT on an original image block B, we can obtain the result C, and
when we perform the inverse transform on C, we can surely restore B. The process
from B to C and back to B can be called left-invertible property of this IntDCT, as in
Eq. (3.44), where Int.DCT and Int.1DCT represent forward 2D-IntDCT and its in-
verse operation.
 Int:DCTðBÞ ¼ C
Int:1DCTðCÞ ¼ B
(3.44)
Now suppose we modify C (corresponding to B in the spatial domain) to C0
(C0 s C) in the IntDCT domain; the reversibility requires that for any C0, the result
B0 by the inverse transform must not equal the original B. We call this process from
C0 to B0 (B0 s B) and back to C0 right-invertible property, as in Eq. (3.45).
(
Int:1 DCTðC0Þ ¼ B0
Int: DCTðB0Þ ¼ C0
(3.45)
Now if B ¼ B0 when C0 s C, Eqs. (3.44) and (3.45) cannot be satisﬁed at the
same time, so this IntDCT does not satisfy the reversibility required for Yang
et al.’s scheme. Note that in Refs. [3,4] IntDCTs represent those transforms close
to regular DCT but with integer operations and dyadic rationales as resulting coef-
ﬁcients. These IntDCTs can modify the output coefﬁcients to integers by value
scaling, but they are absolutely not right-invertible after the scaling operation. If
we modify one LSB bit of a coefﬁcient in C, it is hard to ensure that the resulting
B0 is different, at least 1 bit, from the original B. So we only consider those
integer-to-integer DCTs that are both left and right invertible. In Yang et al.’s
schemes, they derived a 2D-IntDCT from the 1D version proposed in Ref. [10]
3.3 Integer Discrete Cosine TransformeBased Schemes
161

(algorithm A in Ref. [10]) and utilized it to obtain coefﬁcient values for bit-shift op-
erations. This IntDCT is linearly constructed by a very simple lifting matrix and sat-
isﬁes the requirement of left and right invertible property on the whole integer ﬁeld.
Another problem we must consider is the pixel value over- and underﬂow caused
by the coefﬁcient modiﬁcation in the 2D-IntDCT domain. The errors between the
original pixels and those modiﬁed ones are difﬁcult to estimate due to nonlinearity
of IntDCTs. Yang et al. estimated the errors in an indirect way, as described in
Section 3.3.2.2.
3.3.2.2 Basic Embedding and Extracting Processes
A basic frame of Yang et al.’s scheme is presented in Fig. 3.7, based on the 2D-
IntDCT described in Section 3.3.2.1, where x is an original 8  8 image block;
xW is the watermarked version of x; c and cW are coefﬁcient blocks of the original
image block and the watermarked coefﬁcient block, respectively; and cBS is the co-
efﬁcient block with those selected AC coefﬁcients’ LSB saved by bit-shift opera-
tions. Key is a secret key to decide which coefﬁcients are to be modiﬁed in one
coefﬁcient block. The positions tagged with “” in Fig. 3.7, for example, represent
the coefﬁcients selected by Key in the coefﬁcient block. WM represents the water-
mark bits. Int.DCT represents 2D-IntDCT and Int.1DCT is the inverse transform.
x
Int. DCT
Int.-1 DCT
Int.-1 DCT
Int. DCT
c
Key
Coefficient selection 
& p-bit-shifts
Inverse p-bit-shifts
Original 8x8 
image block
Watermarked 
8 8 image 
block
xW
cW
Watermark embedding
Coefficient selection & 
Watermark extracting
Key
cBS
8 8 coefficient
block with 
bit-shifted 
coefficients
WM
8 8 coefficient 
block
8 8 watermarked 
coefficient block
FIGURE 3.7
Embedding and extracting process for one 8  8 image block (solid arrow, embedding;
dashed arrow, extracting).
162
CHAPTER 3 Lossless Information Hiding in Images on Transform Domains

3.3.2.3 Error Estimation to Prevent Overﬂow and Underﬂow
Note that not all 8  8 blocks in the original image are suitable for watermark
embedding due to possible overﬂow (e.g., >255 for 256 grayscale images) and
underﬂow (e.g., <0 for 256 grayscale images) problems. Speciﬁcally, overﬂows
and underﬂows can be caused by two reasons: the ﬁrst is the bit-shift operation
and the second is the embedding of watermark bits in the saved p LSBs.
Overﬂows and underﬂows caused by the ﬁrst reason can be determined correctly
simply by applying bit-shift operations over selected coefﬁcients, and it should be
sees if the resulting pixels after the inverse IntDCT will overﬂow or underﬂow or
not. If overﬂows or underﬂows occur, the original image block cannot be a candidate
for embedding and we can just leave it intact. Otherwise, we proceed to consider the
second reasondthe embedded watermark bits. Obviously, we cannot predict the
speciﬁc watermark bits to be embedded, so we must manage to ﬁnd out those block
proof against overﬂows and underﬂows under the condition whatever information is
embedded. Similar to the preprocessing method in Ref. [31], Yang et al. preset two
thresholds THl and THh (0  THl < THh  255) in image’s pixel scale range
[0.255]. Assume x is the original image block, then x0 is the restored version of x
by IntDCT with selected coefﬁcients bit-shifted but without any watermark or other
overhead bits embedded (i.e., all LSB of selected coefﬁcients equal 0). It is expected
that any x0 with all its 64 pixels’ values falling inside the scale range [THl,THh] can
be embedded with any watermark bits embedded in the LSB of selected coefﬁcients
without worrying about any overﬂows or underﬂows. To calculate the two thresholds
THl and THh, we must estimate the maximum pixel errors caused by the watermark
bits embedding in the saved LSB.
However, the IntDCT is not a linear transform and the error estimation based on
x0 is a complicated task. We can circumvent this problem with a ﬂoat-point DCT as a
bridge. The detailed scheme is shown in Fig. 3.8, where x is the original 8  8 image
block, c is the 2D-IntDCT coefﬁcient block of x; cBS is the coefﬁcient block after bit-
shift (with all LSB of selected coefﬁcients to be “0”), xBSF is the pixel block restored
from cBS by 2-dimensional ﬂoat-point DCT, w is watermark bits to be embedded in
LSB of cBS, cW is the coefﬁcient block with watermark bits embedded in the LSB
plane, xwF is the pixel block restored from cW by 2D ﬂoat-point DCT, and xwI is
the pixel block restored from cW by 2D-IntDCT. Int.DCT and Flt.DCT represent
FIGURE 3.8
Pixel value error estimation scheme.
3.3 Integer Discrete Cosine TransformeBased Schemes
163

2D-IntDCT and 2D ﬂoat-point DCT, respectively; Int.1DCT and Flt.1DCT are the
corresponding inverse transforms. The details of the error estimation scheme are as
follows.
Based on the errors in Ref. [10] between the ﬂoat-point DCT coefﬁcients and the
IntDCT coefﬁcients for the same integer input, we deduce the 8  8 error matrix
T(i, j) (i, j ¼ 0, 1, ., 7), in which each component tij > 0 represents the maximum
value error for the pixel in the corresponding position (i, j) in the 8  8 image block.
The error matrix T(i, j) is as follows:
Tði; jÞ ¼
2
66666666666664
17:9
16:7
17:1
22:4
17:3
22:8
16:1
15:3
16:3
15:2
15:5
20:3
15:7
20:7
14:6
13:8
16:6
15:5
15:9
20:8
16:1
21:2
14:9
14:2
18:3
17:2
17:5
22:4
17:7
22:7
16:6
15:9
17:7
16:5
16:9
22:2
17:1
22:6
15:8
15:1
18:4
17:3
17:7
22:5
17:9
22:9
16:7
16:0
16:3
15:1
15:5
20:4
15:7
20:8
14:5
13:8
15:7
14:7
15:0
20:0
15:2
20:2
14:0
13:3
3
77777777777775
(3.46)
For any ﬁxed xwI, we can obtain
jxwIði; jÞ  xwFði; jÞj < tij
(3.47)
where xwI(i, j) and xwF(i, j) are pixel values at position (i, j), 0  i  7, 0  j  7, in-
side xwI and xwF, respectively. In view of the linearity of the transforms cBS 4 xBSF
and cW 4 xwF, we have
xwFði; jÞ  xBSFði; jÞ <
X
7
m¼0
X
7
n¼0
fp

Flt:DCT1
1m;n

ði; jÞ

¼ tpij
(3.48)
xwFði; jÞ  xBSFði; jÞ <
X
7
m¼0
X
7
n¼0
fp

Flt:DCT1
1m;n

ði; jÞ

¼ tnij
(3.49)
where xBSF (i,j) is the pixel value at position, 0  i  7, 0  j  7, inside xBSF, and
1m,n is an 8  8 matrix with “1” values for those components whose positions (m,n)
(0  m  7, 0  n  7) correspond to the positions of all selected coefﬁcients in
cBS, and all the other components are set to be “0.” We deﬁne Flt.DCT1(a) as
the result matrix of inverse 2D ﬂoat-point DCT where a is an 8  8 matrix and
[Flt.DCT1(a)](i,j) is the component at position (i,j) inside the result matrix. fp
and fn are deﬁned as follows:
fpðxÞ ¼
 0
if x  0
x
if x > 0
(3.50)
fnðxÞ ¼
 0
if x  0
x
if x < 0
(3.51)
164
CHAPTER 3 Lossless Information Hiding in Images on Transform Domains

Suppose tpij and tnij (0  i  7, 0  j  7) are components at position (i,j) inside
the error matrices Tp(i,j) and Tn(i,j), then from Eqs. (3.48) to (3.51) we can see that
tpij and tnij represent a maximum positive limit and a maximum negative limit for
errors caused by the embedded watermark bits for the pixel at position (i,j), respec-
tively. According to Eqs. (3.47)e(3.49), if xwI is required not to be bigger than 255
or less than 0, the safe range of each pixel xBSF(i,j) (0  i  7, 0  j  7) can be
deﬁned by
tij  tnij  xBSFði; jÞ  255  tij  tpij
(3.52)
Thus we can set THl ¼ tijetnij and THh ¼ 255etijetpij. Note that in this indirect
estimation scheme, the two thresholds THl and THh are set on xBSF instead of x0.
For example when m þ n > 0 in Eqs. (3.48) and (3.49), i.e., the case that all AC
coefﬁcients modiﬁed, the corresponding error estimation matrices Tp(i,j) and Tn(i,j)
are calculated as follows:
Tpði; jÞ ¼
2
66666666666664
6:9
2:4
4:1
3:1
3:8
3:3
3:6
3:5
2:4
3:6
3:2
3:4
3:3
3:4
3:3
3:3
4:1
3:2
3:5
3:3
3:5
3:4
3:4
3:4
3:1
3:4
3:3
3:4
3:3
3:7
3:3
3:4
3:8
3:3
3:5
3:3
3:4
3:4
3:4
3:4
3:3
3:4
3:4
3:4
3:4
3:4
3:4
3:4
3:6
3:3
3:4
3:3
3:4
3:4
3:4
3:4
3:5
3:3
3:4
3:4
3:4
3:4
3:4
3:4
3
77777777777775
(3.53)
Tnði; jÞ ¼ ð1Þ$
2
66666666666664
0:0
4:4
2:7
3:8
3:1
3:5
3:3
3:4
4:4
3:2
3:7
3:4
3:6
3:5
3:6
3:5
2:7
3:7
3:3
3:5
3:4
3:5
3:4
3:5
3:8
3:4
3:6
3:5
3:5
3:5
3:5
3:5
3:1
3:6
3:4
3:5
3:4
3:5
3:5
3:5
3:5
3:5
3:5
3:5
3:5
3:5
3:5
3:5
3:3
3:6
3:4
3:5
3:5
3:5
3:5
3:5
3:4
3:5
3:5
3:5
3:5
3:5
3:5
3:5
3
77777777777775
(3.54)
It can be easily seen that the componentwise errors estimated by the above-
mentioned method are quite large. However, in practical experiments, the errors
are usually much smaller than these estimated values, depending on different orig-
inal images.
3.3.2.4 Twice-Try Structures for Block Discrimination
As mentioned earlier, for those blocks suitable for embedding, we can ﬁrst estimate
the pixel value errors and then set the two thresholds to ﬁnd them out. Once these
3.3 Integer Discrete Cosine TransformeBased Schemes
165

candidate blocks have been used for embedding, they may no longer be suitable for a
second embedding, and therefore cannot be differentiated from those originally inel-
igible blocks. This problem is unavoidable during the extracting process. Identifying
those blocks modiﬁed during the embedding process is the key to watermark extrac-
tion and image restoration.
One possible solution is to use overhead bits to record the blocks’ locations in the
original image. This strategy was also employed in Ref. [6] where a location map
acts as the indication of pixel pairs used for embedding. Similarly, we use overhead
bits to record the block location information. Another problem is where to embed
these overhead bits in view of the fact that the embedding positions for these over-
head bits should be able to be determined directly by the retrieval algorithm itself
without any additional overhead information to indicate. In other words, we must
embed the location information in those blocks with some features that are invariant
to embedding and can be recognized directly during extraction. Obviously, those
blocks, which are proof against overﬂows and underﬂows after twice embedding
process, should satisfy this condition because they can be easily located by a second
embedding test during extraction. Yang et al. call this block discrimination method
“twice-try.” Yang et al. utilized this method to retrieve those twice-embedding
permitted blocks and then identify the location information of other blocks used
for embedding (once-embedding permitted blocks).
For the second-embedding process, the error estimation for the last two LSB
planes can be calculated, and the safe range of each pixel xBSF(i,j) (0  i  7,
0  j  7) can be deﬁned as:
tij  t0
nij  xBSFði; jÞ  255  tij  t0
pij
(3.55)
and the two thresholds can be set to TH0
l ¼ tijt0
nij and TH0
h ¼ 255tijt0
pij. For
example, when m þ n > 0 in Eqs. (3.48) and (3.49), i.e., the case that all AC coef-
ﬁcients are modiﬁed, the corresponding error estimation matrices T0
pði; jÞ and
T0
nði; jÞ of t0
pij and t0
nij are calculated as follows:
T0
pði; jÞ ¼
2
66666666666664
20:6
7:2
12:4
9:3
11:3
10:0
10:8
10:4
7:2
10:9
9:5
10:3
9:8
10:1
9:9
10:0
12:4
9:5
10:6
9:9
10:4
10:1
10:2
10:2
9:3
10:3
9:9
10:2
10:0
10:1
10:0
10:1
11:3
9:8
10:4
10:0
10:2
10:1
10:2
10:1
10:0
10:1
10:1
10:1
10:1
10:1
10:1
10:1
10:8
9:9
10:2
10:0
10:2
10:1
10:1
10:1
10:4
10:0
10:2
10:1
10:1
10:1
10:1
10:1
3
77777777777775
(3.56)
166
CHAPTER 3 Lossless Information Hiding in Images on Transform Domains

T0
nði; jÞ ¼ ð1Þ$
2
66666666666664
0:0
13:3
8:2
11:3
9:2
10:6
9:8
10:2
13:3
9:7
11:1
10:3
10:8
10:4
10:7
10:6
8:2
11:1
10:0
10:6
10:2
10:5
10:3
10:4
11:3
10:3
10:6
10:4
10:6
10:5
10:5
10:5
9:2
10:8
10:2
10:6
10:3
10:5
10:4
10:4
10:6
10:4
10:5
10:5
10:5
10:5
10:5
10:5
9:8
10:7
10:3
10:5
10:4
10:5
10:4
10:4
10:2
10:6
10:4
10:5
10:4
10:5
10:4
10:5
3
77777777777775
(3.57)
Fig. 3.9 shows the twice-try-based block discrimination structure for the embed-
ding process, by which Yang et al. classiﬁed the input 8  8-sized image block x into
one of three classes [27]. In Fig. 3.9, Int.DCT and Flt.1DCT represent a 2D-IntDCT
Original image block
1 st error
estimation
2nd error
estimation
Int. DCT
1 bit-shift left
(3.52)
(3.55)
N
Y
N
Y
Classify x into
Class 1
Classify x into
Class 3
Classify x into
Class 2
satisfied?
1 bit-shift left
satisfied?
Flt.-1 DCT
Flt.-1 DCT
x
c
cBS
cBS
cBS’
xBSF
xBSF 
, 
FIGURE 3.9
Twice-try-based block discrimination structure for embedding process.
3.3 Integer Discrete Cosine TransformeBased Schemes
167

and an inverse 2D ﬂoat-point DCT, respectively. Note that Yang at al. utilized
the inverse ﬂoat-point DCT according to the error estimation method discussed in
Section 3.3.2.3. The deﬁnition of c, cBS, and xBSF are the same as in Fig. 3.8,
and c0
BS and x0
BSF are obtained directly from cBS according to Fig. 3.9. Yang et al.
utilized this twice-try structure to ﬁnd suitable blocks (Class 2 and Class 3) for
embedding [27].
Fig. 3.10 shows the twice-try-based block discrimination structure for the
extracting process, by which Yang et al. classiﬁed the input 8  8-sized water-
marked image block xwI (and its original version x) into one of three classes.
Note that during extraction, some xwBSF originating from Class 2 in the embedding
process may satisfy Eq. (3.52) because errors caused by actual watermark bits
embedded in xwI are usually much smaller than the absolute values of tij, tpij, and
tnij in Eq. (3.52), and this makes a portion of xwBSF originally in Class 2 now able
to satisfy Eq. (3.52). We deﬁne this portion of xwBSF (and their original version x)
as Class 200 and the remaining xwBSF [those still unable to satisfy Eq. (3.52)]
Watermarked image block
Int. DCT
1 bit-shift left
1 bit-shift right
Retrieve class 2&3,s
location from LSB of
 class 2&3,s
location 
cw
xwI
x
cwBS
cw
cw
cw
cw
cBS
xwBSF
Flt.-1 DCT
Int.-1DCT
(3.52)
satisfied?
N
Classify original
x into class 1 or
class 2,
Classify original x into 
class 2,, or class 3
Classify x into 
class 2,,
Twice-try structure
Fig.3.9
Classify x into 
class 3
Y
FIGURE 3.10
Twice-try-based block discrimination structure for extracting process.
168
CHAPTER 3 Lossless Information Hiding in Images on Transform Domains

(and their original version x) as Class 20. Obviously, Class 2 is the combination of
Class 20 and Class 200. Now that all xwI in Class 2 and Class 3 are 1-bit-shifted
and watermarked versions of x, we can ﬁrst restore xwI to x and then use the
twice-try structure in Fig. 3.9 to discriminate Class 200 from Class 3. We can retrieve
the location information bits from Class 3 and then discriminate Class 20 from Class
1, and ﬁnally we can retrieve all embedded bits from cw in Class 3 and Class 2 and
restore the original x perfectly.
Note that in Figs. 3.9 and 3.10, for convenience and simplicity, we suppose the
companding process includes only a bit-shift operation.
3.3.2.5 Improved Embedding and Extracting Processes
The embedding process of Yang et al.’s scheme is illustrated in Fig. 3.11, where x is
an original image block; Classes 1, 2, and 3 are the classiﬁcation result of x by the
twice-try structure mentioned in Section 3.3.2.4; w is the watermark bit vector
formed by the original N (N is the number of coefﬁcients selected in one 8  8
coefﬁcient block) binary watermark bits and other (64-N) “0” bits; l is the vector
consisting of location information overhead bits for those blocks to be embedded
with data (Classes 2&3) formed by N meaningful bits and other (64-N) “0” bits;
and cw and xwI are the watermarked coefﬁcient block and the image block, respec-
tively. Int.1DCT represents inverse 2D-IntDCT. Note that in this embedding pro-
cess, Yang et al. ﬁrst embedded all l bits in the LSB space saved by the bit-shift
operation over coefﬁcient blocks of Class 3, which will not cause any overﬂow
and underﬂow after twice embedding processes, and next Yang et al. embedded
real watermark bits w in the space saved from the remaining blocks in Class 3
and all blocks in Class 2 following all l bits. Yang et al. kept those x in Class 1 intact
during the whole embedding process because they will surely overﬂow or underﬂow
when tested with Eq. (3.52).
Int.-1DCT
xwI = x
cw = cBS + w
cw= cBS + l or
cw= cBS + w
xwI
xwI
Int.-1DCT
Twice-try block
discrimination
structure for
embedding
Class 1
Embedding watermark w in LSB of cBS
Keep x intact (embedding prohibited)
Embedding location overhead l & then
watermark w in LSB of cBS
Class 2
Class 3
x
FIGURE 3.11
Embedding process of Yang et al.’s scheme [27].
3.3 Integer Discrete Cosine TransformeBased Schemes
169

The extracting process of Yang et al.’s scheme is illustrated in Fig. 3.12, from
which we can see that it is virtually the inverse process of the embedding process
in Fig. 3.11. We can use the twice-try-based block discrimination structure in
Fig. 3.9 to retrieve data embedded in blocks of Classes 2 and 3 and then restore
all original image blocks. Note that deﬁnitions of w, l, xwI, c, and cw are the same
as in Figs. 3.10 and 3.11, and xR is restored version of the original image block x.
3.3.2.6 Simulation Results
Yang et al. tested the above-mentioned reversible watermarking scheme on four 256
grayscale images with size 512  512: Lena, Barbara, Baboon, and Goldhill as
shown in Fig. 3.13aed. In all simulations, they selected N coefﬁcients in one
8  8 coefﬁcient block and obtained watermarked images with different qualities
in terms of PSNR and different capacities (bits). The simulation results are presented
in Table 3.1, where the N coefﬁcients are selected in the order i þ j > M(M ¼ 12, 11,
Twice-try block
discrimination
structure for
extraction (Fig.5)
Class 1
Class 2
Extracting watermark bits w from LSB of cw
1 bitshift right
1 bitshift right
Extracting location overhead l & then
watermark w from LSB of cw
Class 3
xR = xwI
xwI
xR 
xR 
Keep xwI intact 
cw - w
cw - l or
cw - w
c
c
Int.-1DCT
Int.-1DCT
FIGURE 3.12
Extracting process of Yang et al.’s scheme [27].
FIGURE 3.13
Test images. (a) Lena, (b) Barbara, (c) Mandrill, and (d) Goldhill.
170
CHAPTER 3 Lossless Information Hiding in Images on Transform Domains

Table 3.1 Simulation Results of Yang et al.’s Scheme [27] for Four 512  512 Grayscale Images
N
3
6
15
36
49
58
63
Lena
PSNR (dB)
49.645
46.765
42.852
38.188
36.106
34.665
31.847
Capacity (bit)a
5192
14,432
41,834
103,616
138,053
156,158
150,758
Barbara
PSNR (dB)
49.419
45.979
39.136
33.046
31.917
30.669
30.098
Capacity (bit)a
8003
20,012
55,334
119,852
146,922
161,088
139,670
Mandrill
PSNR (dB)
41.306
37.661
33.178
30.284
30.102
30.100
30.063
Capacity (bit)a
7307
18,524
50,129
85,931
97,136
103,436
106,056
Goldhill
PSNR (dB)
48.523
45.438
41.196
35.336
32.495
30.302
28.158
Capacity (bit)a
7484
19,004
53,309
131,444
174,509
192,930
173,123
PSNR, peak signal-to-noise ratio.
a The capacity is the lower limit. Actual capacity should be about 2000e4000 more than the images in Table 3.1.
3.3 Integer Discrete Cosine TransformeBased Schemes
171

6, 4, 2, 0), 0  i  7, 0  j  7, and i, j are the row and column numbers, respec-
tively, in one coefﬁcient block c(i, j). Note that the capacity presented in this table
is the lower limit number in light of the fact:
Capa: ¼ Saved bits from bit  shift operation  location overhead
where the location overhead is calculated, for simplicity, as the maximum value
(4096 binary bits, 1 bit for one block indicating embedded or not) in the simulations
without any compression. The actual capacity is expected to be 2000e4000 more
than the images in Table 3.1 if location overhead is appropriately losslessly
compressed.
From Table 3.1 we can see that Yang et al.’s scheme shows advantage in capacity
while good quality of watermarked image is maintained. Note that for simplicity,
they omitted (1) the compressing process in companding (bit-shift operation
remained) and (2) the losslessly compressing process for location overhead. On
the other hand, IntDCT algorithms and overﬂow/underﬂow prevention method
may be improved in the future. Considering these facts, they believed their scheme
has potential in performance, which will be exploited in their future work.
3.3.3 HISTOGRAM SHIFT TECHNIQUE IN INTEGER DISCRETE COSINE
TRANSFORM DOMAIN
In this section, we introduce Yang et al.’s another reversible watermarking scheme
using histogram modiﬁcation in the 8  8 IntDCT domain [19]. This scheme
exploits the high-energy-concentrating property of IntDCT, allows ﬁne coefﬁcient
selection for watermarking, and thus, shows equivalent or higher performance and
wider quality (PSNR) ranges when compared with those in Refs. [31] and [32]. In
Section 3.3.3.1, we ﬁrst review the histogram modiﬁcation technique for reversible
watermarking. In Section 3.3.3.2, the histogram modiﬁcation technique is intro-
duced into the 8  8 IntDCT domain and Yang et al.’s scheme is introduced.
Some experimental results are presented in Section 3.3.3.3.
3.3.3.1 Histogram Modiﬁcation Technique for Lossless Information Hiding
The idea of histogram modiﬁcation proposed in Refs. [31] and [32] is to exploit the
redundancy of scale points in an image histogram. We illustrate this idea brieﬂy in
Fig. 3.14. After ﬁnding a peak point P and a zero point Z in the image’ s original
histogram, the scale values in the range [P, Z1] shift to the right side by 1 unit
to occupy the range [P þ 1, Z]. This shifting operation is equivalent to adding 1
unit to all pixels with scale values originally in the range [P, Z1]. Now we have
artiﬁcially created a zero point at the scale value P and the original peak point at
P has shifted to Pþ1. The watermark embedding process is performed by reassign-
ing the peak-point-pixels’ scale values to P or P þ 1. For example, in Fig. 3.14, there
are N peak-point-pixels at P þ 1 (originally at P). During the embedding process, we
embed “0” by keeping unaltered a pixel with scale value P þ 1, or embed “1” by
restoring it to P. Thus the embedding capacity in this example is N. In practical
172
CHAPTER 3 Lossless Information Hiding in Images on Transform Domains

applications, overhead information should be used to record the positions of the peak
point and the zero point. If there is no zero point in the histogram, the minimum
point (scale value with fewest pixels) can act as a zero point. In this case, more over-
head bits are needed to differentiate the modiﬁed pixels from those original ones in
the minimum point.
With the overhead bits to carry necessary information of the original histogram,
this histogram modiﬁcation technique is a reversible process. The reversible water-
marking scheme in Ref. [31] uses this technique in the histogram of a whole image,
so the performance depends on the peak point in the histogram. If the shape of the
histogram is ﬂat, the capacity will be limited. In addition, the distortion caused by
the histogram shifting operation depends not only on the peak point but also on
the zero or minimum point, or equivalently, on the size of the range [P, Z1].
The scheme in Ref. [32] decreases the size of the histogram by dividing the whole
image into small blocks and performs histogram modiﬁcation on each block, thus
reducing the distortion caused by histogram shifting operations. For each block,
the scheme in Ref. [32] needs 1e2 bits as an overhead to store information of the
original histogram, which makes the overhead reoccupy a large proportion of the to-
tal saved bits.
Note that the histogram modiﬁcation techniques in both Refs. [31] and [32] are
directly used in the spatial domain and the algorithms’ performance is determined by
the pixel distribution of the original image. Based on this fact, Yang et al. proposed
using histogram modiﬁcation in the IntDCT domain [19] in light of IntDCT’s energy
concentration property, and expected to heighten the amplitude of the peak point P
and thus increase the capacity.
3.3.3.2 Yang et al.’s Scheme
Similar to a ﬂoat-point DCT, an IntDCT has the energy concentration property,
which can be used to improve the capacity of histogram modiﬁcation scheme.
P P+
Z-1 Z
N
(a)
(b)
1unit shift
N2
N1
N
N = N1 + N2
P P+
Z-1 Z
FIGURE 3.14
The idea of histogram modiﬁcation technique. (a) Original histogram, and (b) modiﬁed
histogram after embedding watermark.
3.3 Integer Discrete Cosine TransformeBased Schemes
173

Unlike the ﬂoat-point DCT, the IntDCT is lossless and suitable for reversible water-
marking. Besides, we require the IntDCT to satisfy the fact that (1) both input and
output data are integers and (2) the transform is left-and-right invertible mapping.
According to the two requirements, Yang et al. derived an 8  8 IntDCT from the
1D version proposed in Ref. [10] (algorithm A in Ref. [10]). It is easy to prove
that this IntDCT satisﬁes the two requirements, and at the same time, possesses
high-energy-concentrating efﬁciency. We explain Yang et al.’s whole watermarking
process as follows.
The ﬁrst step of Yang et al.’s scheme [19] is to generate the coefﬁcient histograms
in the IntDCT domain to perform histogram modiﬁcation discussed in Section 3.3.3.1.
Assume x is a gray-scale image with size at least 8  8. They divided the original x
into M image blocks Bi (i ¼ 1, 2, ., M) with size 8  8, as shown in Fig. 3.15. Then
Yang et al. performed 8  8 IntDCT on all M image blocks to obtain M coefﬁcient
blocks Ci (i ¼ 1, 2, ., M) with size 8  8, as shown in Fig. 3.15. To obtain a histo-
gram for modiﬁcation, we pick the coefﬁcient in the position ( p,q) (1  p, q  58)
inside each coefﬁcient block Ci (i ¼ 1, 2, ., M), where p and q are the row index
and column index, respectively, in the 8  8 coefﬁcient block. Thus for any coefﬁ-
cient position ( p,q), totally M coefﬁcients ci( p,q) (i ¼ 1, 2, ., M) can be collected
to form a coefﬁcient group G( p,q). For each coefﬁcient group G( p,q), Yang et al.
embedded the watermark reversibly by histogram modiﬁcation in its histogram
H( p,q) (l  p, q  8), and there are totally 64 histograms formed by the 64 coefﬁcient
groups. Note that in the DCT domain, the AC coefﬁcient group G(p,q) (l  p, q  8,
and p þ q > 2) can be modeled with a general Gaussian distribution [11], with sam-
ples concentrated around “0,” which is especially suitable for histogram modiﬁcation.
Since Yang et al.’s derived 8  8 IntDCT [27] has high compatibility with the ﬂoat-
point DCT in the sense of energy concentration, they assumed its AC coefﬁcient
groups are also distributed close to the general Gaussian model. So they considered
only the AC coefﬁcient groups G( p,q) (0  p, q  8, p þ q > 2) and their histograms
for modiﬁcation. In concrete applications, they utilized a secret key Kc to select
N(N  63) coefﬁcient groups for watermarking.
..
.
M
B1
B2
BM
8 8 pixel blocks
..
.
M
C1
C2
CM
c1(p,q)
c2(p,q)
cM (p,q)
The q-th column
The p-th row
8 8 coefficient blocks
8 8 Int. DCT
FIGURE 3.15
Coefﬁcient grouping in 8  8 integer discrete cosine transform (DCT) domain.
174
CHAPTER 3 Lossless Information Hiding in Images on Transform Domains

After the generation of the N coefﬁcient groups and their histograms, Yang et al.
performed the histogram modiﬁcation scheme introduced in Section 3.3.3.1 on each
of the N histograms. The watermark embedding process shown in Fig. 3.16 is similar
to that in Fig. 3.14, except that the histogram is now calculated from the IntDCT co-
efﬁcients instead of the original pixel values. Therefore the peak point P’s amplitude
is supposed to account for a higher proportion among the total number M than in the
spatial domain (as in Fig. 3.14), whereas the size of range [P, Z1] is supposed to be
shorter than in the spatial domain for the same reason. It is expected that the trans-
form from the spatial domain to the IntDCT domain should improve the whole
algorithm’s capacity and image ﬁdelity. Note that for each histogram of the total
N coefﬁcient groups, we must record the positions of the original peak point P
and zero point Z as overhead information OHpz to provide the synchronization infor-
mation for watermark extraction. Where to store this overhead information later in
this section.
Since both the histogram modiﬁcation technique and the 8  8 IntDCT are
reversible processes, the watermark extraction is just a reversed process of the
embedding process. A problem we cannot neglect is the overﬂows (>255 for a
256 grayscale image) and underﬂows (<0) caused by histogram modiﬁcation in
the IntDCT domain. In the spatial domain, it is easy for us to predict the occurrence
of over- and underﬂows, i.e., to see if the histogram shifting operation and the water-
mark embedding process involve any pixels with boundary scale values such as “0”
and “255.” If yes, we exclude these pixels from the histogram shifting operation,
even with additional overhead bits to guarantee the reversibility of the whole algo-
rithm, so that over- and underﬂows will not occur. However, for the case in the
IntDCT domain, it is hard to know in advance which pixel will overﬂow or under-
ﬂow as a result of embedding before we carry out a real embedding process. It is
obvious that over- and underﬂows are related to two factors: the histogram shifting
range [P, Z1] and the speciﬁc watermark bits. The range [P, Zl] is determined by
L
0 P P
Z-1Z
1 unit shift
(a)
(b)
H( p,q) 
L2
L1
L
L = L1 + L2
0 P P
Z-1 Z
H
p, q) 
FIGURE 3.16
Histogram modiﬁcation in the 8  8 integer discrete cosine transform domain. (a) Original
histogram and (b) modiﬁed histogram after embedding watermark.
3.3 Integer Discrete Cosine TransformeBased Schemes
175

the original image itself and the pixel errors caused by the histogram shifting in
[P, Z1] can be directly calculated before we embed a real watermark, whereas
the pixel errors caused by different watermark bits are variant, which makes it
impossible to predict the errors. In this chapter, we estimate the errors caused by
the watermark embedding using the same strategy as in Yang et al.’s previous
work [27], which gave two maximum error estimation matrices to prevent over-
and underﬂows. With this error estimation strategy, we can decide which original
8  8 image blocks are suitable for the embedding process, and the other blocks
(possible to over- and underﬂow) must be kept unchanged during embedding and
extraction. Yang et al. recorded this block decision information as overhead informa-
tion, named as location overhead OHL.
During extraction, with OHL we can ﬁnd out those image blocks embedded with
watermark, and then with OHpz we can ﬁnd out the histogram shifting ranges on his-
tograms of all coefﬁcient groups G(p,q) and ﬁnally restore the original image suc-
cessfully. Now we consider where to store the overhead OHpz and OHL. In Yang
et al.’s previous work [27], they stored the overhead information in the twice-
embedding permitted blocks, which can be determined by a “twice-try” block
discrimination scheme. Despite its high efﬁciency, this block discrimination scheme
is complicated. Therefore, Yang et al. proposed a relatively simple scheme to store
the overhead information, as shown in Fig. 3.17, an example of a gray-scale image
with size 128  128. In this example, the original image can be divided into 16  16
blocks and we pick out some blocks O1, O2, ., OH as overhead blocks according to
a secret key Ko and then replace the LSBs of pixels in these blocks with the bits of
the overhead OHpz and OHL. The original LSBs are embedded with watermark bits
into the saved space from the histogram modiﬁcation technique. During extraction,
we can use Ko to ﬁnd out these blocks and extract the overhead information OHpz
and OHL. The total number of the overhead blocks H is decided by the length of
all overhead bits and embedded in the ﬁrst overhead block O1.
B1
B2
BK
Selected based 
on Key
FIGURE 3.17
Block selection example for storage of overhead information.
176
CHAPTER 3 Lossless Information Hiding in Images on Transform Domains

3.3.3.3 Experimental Results
Yang et al. tested their scheme using 5 grayscale images as shown in Fig. 3.18aee,
where Lena and Bridge are 256  256 in size, and Barbara, Airplane, and Baboon
are 512  512 in size. In all experiments, Yang et al. selected N coefﬁcients accord-
ing to the key Kc in an 8  8 coefﬁcient block and obtained watermarked images
with different PSNR values compared with the original image and different capac-
ities (bits). The results are presented in Table 3.2, where the N coefﬁcients are
selected in the order p þ q > A (A ¼ 15, 13, 11, 8, 6, 4 corresponding to N ¼ 1,
6, 15, 36, 49, 58, respectively), 1  p  8, 1  q  8, where N is the coefﬁcient
number selected for modiﬁcation and p, q are the row and column indices, respec-
tively, in an coefﬁcient block. The capacity is obtained by Capacity ¼ Saved
bitsOHpzOHL.
From Table 3.2 we can see Yang et al.’s scheme has relatively high capacity in the
high PSNR range. Compared with other reversible image watermarking schemes
[27,32,33], our scheme shows equivalent or higher performance, and particularly,
capability of ﬁne adjustment of the watermarked image’s quality (PSNR) by select-
ing different numbers of coefﬁcients. We notice that the experimental results, espe-
cially the capacities, are quite different for various tested images. This is related to
Yang et al.’s special over- and underﬂow prevention measure [27].
(a)
(b)
(c)
(d)
(e)
FIGURE 3.18
Images for test: (a) Lena, (b) Bridge, (e) Barbara, (d) Airplane, (e) Baboon.
3.3 Integer Discrete Cosine TransformeBased Schemes
177

Table 3.2 Experimental Results of the Proposed Scheme for Five Grayscale Images
Image
Size
N
1
6
15
36
49
58
Lena
256  256
PSNR (dB) Capacity (bits)
Bit rate (bpp)
*
52.11
48.78
46.19
45.36
44.98
750
573
2646
7230
9457
10,541
*
0.0087
0.0404
0.1103
0.1443
0.1608
Bridge
256  256
PSNR (dB) Capacity (bits)
Bit rate (bpp)
*
*
48.74
46.36
45.56
45.199
952
508
165
1456
2099
2415
*
*
0.0025
0.0222
0.032
0.0368
Barbara
512  512
PSNR (dB) Capacity (bits)
Bit rate (bpp)
59.428
51.84
48.49
45.83
44.95
44.50
1233
7265
17,708
39,103
49,489
54,494
0.0047
0.0277
0.0676
0.1492
0.1888
0.2079
Airplane
512  512
PSNR (dB) Capacity (bits)
Bit rate (bpp)
60.25
52.43
48.78
45.957
45.06
44.62
1529
9438
22,292
47,288
59,282
65,433
0.0058
0.036
0.085
0.1804
0.2261
0.2496
Baboon
512  512
PSNR (dB) Capacity (bits)
Bit rate (bpp)
*
51.39
48.27
45.76
44.99
44.60
256
2003
5706
12,650
15,867
17,395
*
0.0076
0.0218
0.0483
0.0605
0.0664
PSNR, peak signal-to-noise ratio.* Cases in which Yang et al.’s scheme is infeasible because the overhead is higher than the saved space.
178
CHAPTER 3 Lossless Information Hiding in Images on Transform Domains

Note that the results given in Table 3.2 are obtained by just 1-unit shifting oper-
ation on the histograms. In Yang et al.’s experiments, they also tested their scheme
by ﬁnding two highest peak points and shifting 2 units on each histogram, only to
ﬁnd that the capacity can be almost doubled and the PSNR can reach a lower end
around 40 dB, but the performance in terms of PSNR and capacity remained close
to the 1-unit shifting case.
3.3.4 LOSSLESS INFORMATION HIDING BY ADAPTIVE COEFFICIENT
MODIFICATION IN INTEGER DISCRETE COSINE TRANSFORM
DOMAIN
In Ref. [34], Yang et al. investigated several possible methods to improve the perfor-
mance of the bit-shifting operationebased reversible image watermarking algorithm
in the IntDCT domain. In view of the large distortion caused by the modiﬁcation of
high-amplitude coefﬁcients in the IntDCT domain, several coefﬁcient selection
methods were proposed to provide the coefﬁcient modiﬁcation process with some
adaptability to match the coefﬁcient amplitudes’ status of different 8  8 DCT co-
efﬁcient blocks. Yang et al.’s adaptive modiﬁcation methods include global
coefﬁcient-group distortion sorting (GCDS), zero-tree DCT prediction (ZTDCT),
and a low-frequency-based coefﬁcient prediction method for block classiﬁcation.
All these methods are supposed to optimize the bit-shifting-based coefﬁcient modi-
ﬁcation process so as to improve the watermarking performance in terms of capac-
ity/distortion ratio. They presented comparisons for these methods in aspects of
performance in terms of capacity/distortion ratio, performance stability, perfor-
mance scalability, algorithm complexity, and security. The following three subsec-
tions introduce Yang et al.’s three adaptive modiﬁcation methods.
3.3.4.1 Global Coefﬁcient-Group Distortion Sorting
The ﬁrst idea that Yang et al. presented for coefﬁcient adaptive modiﬁcation is very
simple: to collect all coefﬁcients in the correspondent position ( p,q) (0  p, q  7)
in all 8  8 coefﬁcient block cl(l ¼ 1, 2, ., M, M is the total number of all coefﬁ-
cient blocks) into a group ACk(k ¼ 8  p þ q and 1  k  63), calculate the bit-
shifting distortion Dk associated with each coefﬁcient group ACk, and then sort
the ACk in the ascending order of Dk(1  k  63) values to obtain AC0
k, and tag
the ﬁrst N coefﬁcient groups AC0
1 w AC0
N as candidates for modiﬁcation. An
example of coefﬁcient grouping and tagging process of GCDS is illustrated in
Fig. 3.19, in which N ¼ 6, that is, the six coefﬁcient groups with the minimum
six Dk are selected for bit-shifting, tagged by “.”
Considering that the general distortion measure PSNR is based on mean square
error calculation, and the distortion caused by coefﬁcient bit-shifting is directly related
to the coefﬁcients’ original amplitudes jACk(l)j (1  k  63, l ¼ 1, 2, ., M), we
realize Dk in the following form:
Dk ¼
X
M
l¼1
jACkðlÞj2
(3.58)
3.3 Integer Discrete Cosine TransformeBased Schemes
179

Once we obtain the sorted coefﬁcient groups AC0
k, we can tag the ﬁrst N coefﬁ-
cient groups AC0
1 w AC0
N by “1” and other groups by “0” in the 8  8 coefﬁcient
block pattern, therefore totally 63 bits are stored as overhead to convey the informa-
tion regarding which coefﬁcient groups should be for watermarking. In Yang et al.’s
experiments, they examined the coefﬁcient-group distortion sorting process over
two 512  512 grayscale imagesdLena and Mandrill, and the two block patterns
in Fig. 3.20 show the sorting results for the two images (the ﬁgures representing
the order of the coefﬁcient groups in the ascending order of Dk). Yang et al.’s exper-
iments demonstrate that the N coefﬁcient groups selected by the aforementioned
GCDS method are always lower or equal in bit-shifting distortion compared with
the scheme by the zigzag order used in their old scheme [27]. The associated
FIGURE 3.19
An example (N ¼ 6) of coefﬁcient grouping and sorting in global coefﬁcient-group
distortion sorting.
FIGURE 3.20
Coefﬁcient-group distortion sorting results for 512  512 grayscale images, Lena and
Mandrill. (a) 8  8 coefﬁcient group sorting for Lena, (b) 8  8 coefﬁcient group sorting
for Mandrill.
180
CHAPTER 3 Lossless Information Hiding in Images on Transform Domains

capacity/distortion rate also has noticeable gain over the old scheme, and the price
for this gain is lowdjust 63 bits, indicating which N coefﬁcient groups are suitable
for bit-shifting (by “1”) and others are not (by “0”). Detailed results and comparisons
are shown in Section 3.3.4.4.
3.3.4.2 Zero-Tree Discrete Cosine Transform Prediction
Similar to wavelet transform, the coefﬁcients of DCT can be also structured in the
form of a zero tree [35], considering the fact that the 8  8 DCT can be regarded
as a 64-subband decomposition, which labels the coefﬁcients’ indices in a way pre-
sented in Fig. 3.21. The parentechildren relationship in the tree structure is deﬁned
as follows:
The parent: i ¼ floorðk=4Þð1  k  63Þ
(3.59)
The children: j ¼ f4i; 4i þ 1; 4i þ 2; 4i þ 3g
(3.60)
In view of the correlation between the parent and children coefﬁcients, the zero-
tree embedded coding algorithm generally assumes that the signiﬁcance of the chil-
dren nodes can be predicted by their parent nodes. Intuitively, this assumption
should also work if it is taken as an adaptive selection method for the coefﬁcients
generated in the IntDCT domain. In Yang et al.’s ZTDCT method, they set a
threshold TH for all parent coefﬁcients (4  k  15) in the second layer in
Fig. 3.21, and the coefﬁcient selecting process can be formulated as
In the embedding process of Yang et al.’s reversible watermarking algorithm,
they perform the aforementioned procedure for every 8  8 coefﬁcient block of
the original image. Yang et al. expected some improvements in performance using
this tree structure for coefﬁcient prediction and modiﬁcation, but the experimental
results are rather disappointing (refer to Section 3.3.4.4), showing even lower efﬁ-
ciency than that of the zigzag orderebased selection method. This fact may be
FIGURE 3.21
Coefﬁcient labeling in the form of a tree structure.
3.3 Integer Discrete Cosine TransformeBased Schemes
181

explained by DCT’s high-energy-concentrating property, which has exploited the
pixel correlation to a very high degree. A possibility for improvement is to select
the coefﬁcients by the original zigzag order but among the adopted coefﬁcients
collected by earlier mentioned procedure.
3.3.4.3 Low-Frequency Coefﬁcients-Based Prediction (LFCP)
Both value expansionebased reversible watermarking algorithms and value
additionebased algorithms face a problem: how to discriminate the modiﬁed values
from the original ones if the two value sets have an overlap (actually in most cases
this overlap is inevitable). Overhead information is a solution [28] but usually costly
for the discrimination. The companding technique may also be a way [27] to achieve
better rate of watermarking capacity versus overhead. Voigt et al. [36] proposed an
AC coefﬁcient addition scheme to obtain a clear discrimination for the three cases:
exceptional, watermarked “1,” and watermarked “0.” The basic idea is to add an
offset to the coefﬁcients unsuitable for watermarking inside one 8-point data group.
Note that this value addition operation is only for discrimination between the water-
marked and the original case and has no watermark information involved in. This
idea shares some similarities with the histogram shifting schemes used in
Ref. [19] and the prediction-error expansionebased reversible watermarking algo-
rithm [37], and in the spread spectrumebased algorithm [38], the authors name
the result of this value addition operation as “pseudowatermark bit.”
A possible reversible watermarking scheme is to adopt the value addition scheme
similar to those in Refs. [37,38] over those IntDCT coefﬁcients unsuitable for water-
marking and perform bit-shifting over those coefﬁcients to be watermarked. Accord-
ingly, a threshold BSTH is preset to deﬁne which coefﬁcients are suitable ones and
which are not. Additionally, Yang et al. employed their algorithm [27] or the GCDS
proposed in Section 3.3.4.1 to deﬁne the N coefﬁcients to which the value addition
scheme is applied. Based on this idea, they proposed a reversible image watermark-
ing algorithm in the IntDCT domain, which can be simply viewed as a combination
of GCDS proposed in Section 3.3.4.1 and the value addition scheme with a threshold
BSTH. They named it as baseline algorithm (BA) for comparison with LFCP, which
is based on BA and improved by referencing the 5 low AC coefﬁcients’ status for
coefﬁcient block classiﬁcation. Details are presented as follows.
The adaptive block classiﬁcation scheme that Yang et al. proposed for LFCP is
based on an assumption: if the low-frequency coefﬁcients are universally small in
absolute value, in high probability the remaining coefﬁcients are also small in abso-
lute value. This assumption actually holds for most natural images. In Ref. [39], a
DCT block classiﬁcation scheme was proposed referencing low-frequency coefﬁ-
cients, but it was relatively complicated to use as many as 22 low-frequency coefﬁ-
cients for decision. Yang et al. proposed a simple but efﬁcient low-frequency
coefﬁcient block classiﬁcation scheme to predict the status of the remaining
182
CHAPTER 3 Lossless Information Hiding in Images on Transform Domains

coefﬁcients, which uses only 5 lowest frequency coefﬁcients shown in Fig. 3.22. The
scheme checks if the absolute value of the maximum (denoted as ACmax) of the 5
lowest AC coefﬁcients AC1, AC2, ., AC5 is larger than a preset threshold TH to
classify all blocks into two classes. The classiﬁcation rule and the detailed water-
marking embedding process are formulated as follows (ACbk represents the AC
coefﬁcient after bit-shifting and ACwk represents the AC coefﬁcient with the water-
mark bit embedded):
if |ACmax| ≤ TH
classified as “plane block”;
perform bit-shifting operation over all the other AC coefficients (AC6~
AC63): ACbk=ACk×2;
watermark embedding: ACwk= ACbk + w(“0” or “1”)
else
classified as “complicated block”;
perform BA (Baseline Algorithm, the combination of GCDS and the value 
addition scheme with threshold BSTH);
end
FIGURE 3.22
The 5 coefﬁcients selected for block classiﬁcation for LFCP.
3.3 Integer Discrete Cosine TransformeBased Schemes
183

The BA can be formulated as (AC0
ak represents the AC coefﬁcients after value
addition):
Step 0 (GCDS): obtain the sorted coefficient groups AC’k (1≤k≤63)(ref. to
Section 3.3.4.1);
Step 1: for an input coefficient number N, select AC’1~ AC’N;
Step 2 (Value addition scheme): for k=1:N
if |AC’k| ≤ BSTH
perform bit-shifting operation over AC’k: AC’bk=AC’k×2;
watermark embedding: AC’wk= AC’bk + w(“0” or “1”)
else
perform the value addition scheme over AC’k:
if AC’k > 0
AC’ak= AC’k +BSTH;
else
AC’ak= AC’k -BSTH;
end
end
end
Compared with the BA, the low frequency coefﬁcients based prediction (LFCP)
efﬁciently exploits the capacity potential of those “plane blocks,” and the experi-
mental results in Section 3.3.4.4 demonstrate this improvement in performance in
terms of capacity/distortion.
3.3.4.4 Experimental Results and Performance Analysis
Yang et al.’s experiments include tests on the ﬁve adaptive IntDCT coefﬁcient
modiﬁcationebased reversible image watermarking algorithms proposed in this sec-
tion: ZTDCT, GCDS, BA, LFCP1, and LFCP2 (different threshold settings for
LFCP1 and LFCP2); and other three reversible image watermarking algorithms pro-
posed in 2004: BS (Yang et al.’s old IntDCT-based bit-shifting algorithm) [27], the
integer waveletebased spread spectrum algorithm (SS) [38], and the prediction-
error expansion based algorithm (PEE) [37]. The images for the testing are the
256-grayscale 512  512-sized Lena and Mandrill. The 8  8 IntDCT we used in
all experiments is the same as in their old algorithm [27], which was proposed in
Ref. [10] (algorithm A).
Another key problem to all reversible watermarking algorithms is the over- and
underﬂows caused by the modiﬁcation of those pixels close to the grayscale bound-
aries (such as 0 and 255 for 256-grayscale images) in the watermarked image. Yang
et al. circumvented this problem in Ref. [27] by a pixel error estimation scheme to
predict if a block will generate an overﬂow or underﬂow after bit-shifting and water-
mark embedding, which gave a guaranteed pixel range deﬁned by two thresholds for
184
CHAPTER 3 Lossless Information Hiding in Images on Transform Domains

the embedding process of any speciﬁc form of the watermark bits. In Ref. [34],
instead, Yang et al. used an iteratively trying process to obtain the two thresholds,
which are obviously (1) not so secured as the two obtained from the error estimation
scheme in Ref. [27] and (2) depend on watermark bits, but permit more blocks to be
watermarked and therefore higher capacity.
Yang et al. employed the same overhead recording scheme in Ref. [34] as in
Ref. [19], in which the overhead bits can be stored in the LSB planes of some image
blocks preselected by a secret key and the original LSB bits can be embedded
together with watermark bits. Obviously, the selected blocks for storing the overhead
information should not be modiﬁed in the later watermark embedding process. Yang
et al. presented the experimental results and performance analysis in the following
aspects.
3.3.4.4.1 Watermarking Capacity Versus Distortion
For most reversible image watermarking applications, we are interested in an algo-
rithm’s performance in terms of the capacity it is able to achieve [usually represented
by bits-per-pixel (bpp)] and the distortion between the original image and its water-
marked version [usually reﬂected by the ﬁdelity index PSNR (dB)]. The experi-
mental results are exhibited in Fig. 3.23 (for Lena) and Fig. 3.24 (for Mandrill)
FIGURE 3.23
Capacity versus image quality comparison for the Lena image.
3.3 Integer Discrete Cosine TransformeBased Schemes
185

consisting of the curves of the eight algorithms: ZTDCT, BS, GCDS, BA
(BSTH ¼ 10), LFCP1 (TH ¼ 6, BSTH ¼ 10), LFCP2 (TH ¼ 20, BSTH ¼ 5), SS,
and PEE. The bit-rate (bpp) adjusting in Figs. 3.23 and 3.24 for ZTDCT is by setting
TH (Section 3.3.4.2) to different values: for BS, GCDS, BA, LFCP1, and LFCP2, by
setting the coefﬁcient number N ([27] or Sections 3.3.4.1 and 3.3.4.3); for SS, by
threshold A [38]; and for PEE, by threshold T [37]. For convenience of comparison,
for all algorithms, we only consider the one-time embedding case instead of multiple
embedding cases.
For convenience of comparison, the ﬁve algorithms (ZTDCT, GCDS, BA,
LFCP1, and LFCP2) proposed in this chapter are represented in Figs. 3.23 and
3.24 by bold curves and the other three algorithms (BS, SS, PEE), by thin curves.
As analyzed in Section 3.3.4.2, the ZTDCT-based algorithm is not as efﬁcient as
we imagined and always inferior to Yang et al.’s old algorithm BS proposed in
Ref. [27] in the whole bit-rate range, both for Lena and Mandrill. With a GCDS
method, the new bit-shifting-based algorithm (GCDS) is always superior to the
old algorithm BS [27] in the whole bit rate range with improvement of 0e0.8 dB
for Lena and 0e1.4 dB for Mandrill. The preponderance is most distinct in the mid-
dle bit rate range (0.25e0.8 bpp for Lena and 0.1e0.6 bpp). The reason is, in low bit
rate range, N (the number of coefﬁcients selected for bit-shifting) is small and the
FIGURE 3.24
Capacity versus image quality comparison for the Mandrill image.
186
CHAPTER 3 Lossless Information Hiding in Images on Transform Domains

coefﬁcients selected by the zigzag order in BS are almost the same as those selected
by GCDS, out of the highest frequency range, whereas in high bit-rate range, N is
close to 63 (the highest number that can be selected) and distortion sorting results
are also almost the same as the results by zig-zag ordering.
The BA for LFCP algorithms employs the value addition scheme (Section
3.3.4.3), which efﬁciently deduces the distortion caused by the high-amplitude (in
absolute value) coefﬁcients in the bit-shifting scheme. This can be veriﬁed by the
curve of BA in both Figs. 3.23 and 3.24, from which we can see that the preponder-
ance of BA over BS and GCDS is increasing with the improvement of capacity, due
to the fact that the higher is N, the more are low-frequency coefﬁcients are included
for value addition and bit-shifting, and thus the more distinct is the advantage of the
value addition scheme over bit-shifting for high-amplitude coefﬁcients. In Yang
et al.’s experiment, the threshold for the value addition scheme is set to BSTH ¼ 10.
Compared with BA, the low-frequency coefﬁcients prediction (LFCP)ebased al-
gorithms have an additional parameter TH to determine the statistical complexity
status of the current image block. This preexamination process exploits the capacity
potential, which is originally constrained by the coefﬁcient number N. The argument
is, in BS, GCDS, and BA, the same coefﬁcient number N is imposed on all image
blocks as the scope from which coefﬁcient can be selected for bit-shifting, regardless
of the statistical complexity of a speciﬁc image block. It is easily seen that for a
plane block, N could be larger than the usual case, and in LFCP algorithms, TH takes
this responsibility to determine if the current block is a plane block or not. If yes, N
shall be counted as 58 (all the remaining AC coefﬁcients except for the 5 lowest
ones, which are references for the decision). In Yang et al.’s experiments, TH ¼ 6
and BSTH ¼ 10 is set for LFCP1 and TH ¼ 20 and BSTH ¼ 5 is set to LFCP2.
From Figs. 3.23 and 3.24, we can see that LFCP-based algorithms exhibit prepon-
derance of 0e1.7 dB over BA, around 1.0e4.0 dB over BS and GCDS for Lena,
0e4.0 dB over BA, and around 1.3e7.0 dB over BS and GCDS for Mandrill. These
results demonstrate the effectiveness of the low-frequency coefﬁcients predictione
based block classiﬁcation scheme.
Compared with the spread spectrum based algorithm(SS) [38], for Lena, GCDS
has no preponderance till after 0.5 bpp; BA and LFCP1 and LFCP2 have no prepon-
derance till after 0.4 bpp. In the high-bit-rate range, GCDS, BA, and LFCP algo-
rithms exhibit preponderance around 0e9.0 dB, and this can be explained by the
fact that the IntDCTwe used has higher energy-concentrating efﬁciency in the whole
transformed domain than the integer wavelet CDF(2,2) used in SS. But the integer
wavelet CDF(2,2) exhibits better scalability of energy concentration. That is, low-
amplitude coefﬁcients in CDF(2,2) are more efﬁciently distributed in high-
frequency bands but globally less in amount than in the IntDCT used in Ref. [34].
For Mandrill, the case is similar, but the preponderance of BA and LFCP over SS
in the high-bit-rate range is higher than the case of Lena. We note that LFCP2
even exhibits a preponderance of around 0.8e2.3 dB over SS in the whole bit-rate
range that LFCP2 covers (0.08e0.35 bpp).
3.3 Integer Discrete Cosine TransformeBased Schemes
187

Compared with the PEE [37], only LFCP2 exhibits preponderance of around
0e0.4 dB in the bit-rate range 0.55e0.75 bpp for Lena. In all other cases, PEE ex-
hibits absolute advantage over other algorithms. For Mandrill, LFCP2 exhibits a pre-
ponderance of around 0.8e1.8 dB over PEE in the whole bit-rate range that LFCP2
covers (0.08e0.35 bpp); BA and LFCP1 exhibit a preponderance of around
0e1.6 dB over PEE in the bit-rate range > 0.35 bpp.
In general, the algorithms GDCS, BA, and LFCP demonstrate distinct improve-
ments in capacity/distortion performance compared with Yang et al.’s old algorithm
[27] in almost all bit-rate ranges and exhibit noticeable preponderance over SS and
PEE in high bit-rate ranges. This preponderance is especially distinct for the image
Mandrill.
3.3.4.4.2 Performance Stability
From Figs. 3.23 and 3.24, we note that all algorithms exhibit relatively similar per-
formance comparison results for the different images Lena and Mandrill, except that
SS bears different performance compared with BS and GCDS in the high bit-rate
ranges. LFCP2 is always the best in high-bit-rate ranges, and as a price the bit-
rate range it covers is much constrained. PEE comprehensively bears an excellent
performance in the whole bit-rate range, for both Lena and Mandrill. BS, GCDS,
and BA cover the most comprehensive bit-rate ranges and PSNR ranges, for both
Lena and Mandrill.
3.3.4.4.3 Performance Scalability
Algorithms based on N coefﬁcient selection in the IntDCT domain (BS, GCDS, BA,
LFCP) have better performance scalability than other algorithms in that the AC co-
efﬁcients of the IntDCT bear a natural ﬁne adjustability either by the zig-zag order or
the GCDS order. For LFCP algorithms, threshold TH and BSTH are adjustable to
achieve even higher performance than those exhibited in Figs. 3.23 and 3.24.
3.3.4.4.4 Algorithm Complexity
In terms of watermark embedding and extracting, the time complexity increases in
the
order
PEE < SS < BS < ZTDCT < GCDS < BA < LFCP.
Although
for
GCDS, BA, and LFCP algorithms, an extra storage of the distortion sorting results
is needed, this information can be embedded together with other overhead informa-
tion into the LSB planes of some preselected image blocks controlled by a secret
key, and we do not need additional memory.
3.3.4.4.5 Algorithm Security
As mentioned earlier, for GCDS, BA, and LFCP algorithms, Yang et al. employed
the same secret-key controlled overhead storing scheme as in Ref. [19]. The over-
head information can be securely embedded into some preselected blocks whose po-
sitions (deciding the synchronization information) are encrypted by the secret key
owned by authorized operators. In Yang et al.’s old algorithm BS, a twice-try scheme
was used and they even do not need the secret key to position the blocks with
188
CHAPTER 3 Lossless Information Hiding in Images on Transform Domains

overhead information embedded, but the security of the watermarking process is
compromised. This problem is also with SS and PEE, in which where and how to
securely embed such overhead bits has not been considered. Especially in PEE,
the overhead bits for indication of block classiﬁcation are closely embedded in
the next embeddable location (refer to Ref. [37]), which is easy to recognize by posi-
tioning those pixels close to the grayscale boundaries. Aside from the security for the
synchronization information, SS also has an artifact trace on the modiﬁed wavelet
coefﬁcients: there is no coefﬁcient with “0” value (refer to Ref. [38]). This affects
the undetectability of the watermarking process if we need to consider the steganog-
raphy aspect in some applications.
3.4 INTEGER WAVELET TRANSFORMeBASED SCHEMES
In this section, we turn to integer wavelet transformebased lossless information hid-
ing schemes, which adopt the so-called CDF(2,2) wavelet. Thus, we ﬁrst introduce
related concept of the CDF(2,2) wavelet.
The CDF(2,2) wavelet was proposed by Cohen, Daubechies, and Feauveau in
1992 [14]; it is a dual orthogonal (i.e., biorthogonal) (5,3) wavelet, whose low-
pass and high-pass ﬁlters are with lengths of 5 and 3, respectively, both presenting
symmetry. We can obtain an integer-to-integer bijective CDF(2,2) wavelet by lifting
the original CDF (2,2) wavelet based on a certain lifting scheme, and this type of
integer wavelet has been adopted in the JPEG2000 standard. Experiments have
shown that, compared with other integer wavelets, the integer CDF (2,2) wavelet
can get better performance in data capacity and distortion when it is used in revers-
ible watermarking.
Assume that xi(0  i  N) is a discrete integer signal sequence, then the forward
and inverse transforms of CDF(2,2) can be deﬁned as follows:
(1) Forward transform
Step 1: Grouping of the samples
si ) x2i
di ) x2iþ1
(3.61)
Step 2: Prediction
di ) di 
1
2 ðsi þ siþ1Þ þ 1
2

(3.62)
Step 3: Updating
si ) si þ
1
4 ðdi1 þ diÞ þ 1
2

(3.63)
3.4 Integer Wavelet TransformeBased Schemes
189

(2) Inverse transform
Step 1: Inverse updating
si ) si 
1
4 ðdi1 þ diÞ þ 1
2

(3.64)
Step 2: Inverse prediction
di ) di þ
1
2 ðsi þ siþ1Þ þ 1
2

(3.65)
Step 3: Sample recovery
x2i ) si
x2iþ1 ) di
(3.66)
These equations give the form of forward and inverse transforms only for one-
dimensional integer CDF (2,2). However, the integer CDF (2,2) wavelet is separable,
so we can easily obtain the 2D integer wavelet transform for natural images through
the transforms in horizontal and vertical directions.
3.4.1 VALUE EXPANSION TECHNIQUE IN THE INTEGER WAVELET
TRANSFORM DOMAIN
Conceptually, the integer Haar wavelet transform domain high-frequency coefﬁcient
expansion (i.e., the difference expansion) technique introduced in Section 2.3.1 of
Chapter 2 also belongs to the integer transform domain value expansion technology.
However, because the application of the difference expansion technique is conﬁned
in the pair of adjacent pixels, the effect is closer to the spatial domain prediction
decorrelation approach, therefore we classify it as the spatial domain value expan-
sion technology. This section describes Xuan et al.’s global integer wavelet trans-
form (DWT) domain value expansion technique [40].
Based on Yang et al.’s bit-shift idea in the IntDCT domain, Xuan et al. tried to
perform the companding and value expansion techniques on the integer CDF(2,2)
transform coefﬁcients, which are obtained from one-level integer CDF (2,2) wavelet
decomposition (resulting in three high-frequency LH, HL, HH coefﬁcients),
achieving relatively good performance [40]. Note that, in this algorithm, the key
problem to improving the performance is to design a suitable compression function.
Next, we ﬁrst introduce the compression function proposed by Xuan et al. Then, we
discuss the calculation of the compression and expansion error and introduce a
simpliﬁed method to record the error and give a more succinct form of the compres-
sion and expansion function.
190
CHAPTER 3 Lossless Information Hiding in Images on Transform Domains

3.4.1.1 The Compression Function Suitable for Value Expansion
To minimize the substantial distortion due to bit-shifting, Xuan et al. designed a
compression function C according to the compression and expansion principles,
and in this compression function, the amplitude distortion due to bit-shifting can
be controlled by a preset threshold T, to obtain better balance between data capacity
and distortion and improve the overall performance. The compression function C is
designed as follows:
CðxÞ ¼
8
>
<
>
:
x; jxj < T
signðxÞ$
jxj  T
2
þ T

;
jxj  T
(3.67)
wherein the sign(x) denotes the sign of x, and the compression function and the error
due to the compression and bit-shift operations are shown in Fig. 3.25. Fig. 3.25
shows that after the compression function C and the bit left shift operation (i.e.,
the amplitude is multiplied by 2) are performed on the original value x, the differ-
ence Dx is calculated as follows:
Dx ¼
 x;
jxj < T
T;
jxj  T
(3.68)
That is, no matter how much the amplitude of the original value x is, after the
compression process and the bit-shift operation, the absolute value of the magnitude
of the error is always limited within the range T. This process can signiﬁcantly
reduce the image distortion caused by the reversible watermark embedding process.
The digitized version CQ(x) of the compression function x is as follows:
CQðxÞ ¼
8
>
<
>
:
x;
jxj < T
signðxÞ$
jxj  T
2

þ T

;
jxj  T
(3.69)
C(x)=x
The compressing function curve C
The bit-shifting result ( 2) of 
compressing function curve C
x
( )
C x
T
T
3T
2T
4T
3T
x
FIGURE 3.25
Compression function C and coefﬁcient amplitude error analysis.
3.4 Integer Wavelet TransformeBased Schemes
191

where x is an integer. Because of the rounding operation after being divided by 2,
CQ(x) is unlikely to be a one-to-one mapping, which will inevitably bring the error
to the expansion function. How to effectively record the error is also the key to
improving the performance of the algorithm.
3.4.1.2 Recording of the Compression and Companding Error and
Simpliﬁcation of the Value Expansion
From Eq. (3.69), we can see that, if we keep the sign of x unchanged, jxj ¼ T þ 2k with
jxj ¼ T þ 2k þ 1, k ˛ N will be compressed into the same value sign(x)  (k þ T),
so that the end of the extension function EQ:
EQðxÞ ¼
 x;
jxjhT
signðxÞ$ð2x  TÞ;
jxj  T
(3.70)
Thus, we will be unable to recover the original amplitude from x ¼ sign(x)(k þ T),
and we can only restore this value into the amplitude with the form jxj ¼ T þ 2k
but cannot restore to jxj ¼ T þ 2k þ 1. That is, for all the original values with the
amplitude form jxj ¼ T þ 2k þ 1 value, after the compression and expansion, there
is an error:
q½n ¼ x½n  ðEQCQxÞ½n ¼
 ðT þ 2kÞ  ðT þ 2kÞ ¼ 0;
jxj ¼ T þ 2k
ðT þ 2k þ 1Þ  ðT þ 2kÞ ¼ 1;
jxj ¼ T þ 2k þ 1
(3.71)
Obviously, no matter what the value of T is, the number of high-frequency coef-
ﬁcients of the integer CDF(2,2) whose amplitude is not less than T is always equal to
the data capacity that these high-frequency coefﬁcients can provide (assume that
each coefﬁcient can only be left-shifted by 1 bit), and is also equal to the number
of resulting coefﬁcients after compression and expansion that are required to be
discriminated from their original magnitude. A relatively better method to record
the error that is used to discriminate between the compressed and expanded ampli-
tude and the original one is to use bits “0” and “1” to distinguish each coefﬁcient
error after compression and expansion, and this bit is stored in the vacated LSB after
compression and left shifting. We illustrate the process with the example shown in
Fig. 3.26, where jxj is the original magnitude, jCQ(x)j is the magnitude compressed
|x
|CQ(x
|2CQ(x
|2CQ(x
A
|:
1
2
3
4
5
6
7
8
9
10…
)|:
1
2
3
3
4
4
5
5
6
6 …
)|:
2
4
6
6
8
8
10
10
12
12…
)’|:
2
4
6
7
8
9
10
11
12
13…
:
0
1
0
1
0
1
0
1 …
|EQCQ(x)|:
1
2
3
3
5
5
7
7
9
9  …
FIGURE 3.26
An example for value companding functions.
192
CHAPTER 3 Lossless Information Hiding in Images on Transform Domains

by the compression function CQ, j2CQ(x)j is a 1-bit left-shifted magnitude, j2CQ(x)0j
is the magnitude that contains the information to distinguish the original amplitude,
A is the bit string for distinguishing the original amplitudes, jEQCQ(x)j is the
expanded magnitude by the expansion function, and T ¼ 3 is the threshold of the
companding and compressing functions adopted in this example.
From Fig. 3.26, we can see that the companding error jxjjEQCQ(x)j is even
directly equal to the information A that is used to distinguish the original amplitude.
The reason is that the error determined by Eqs. (3.69) and (3.70) is just the 0,1 inter-
leaved situation Eq. (3.71). In this example, we use “0” to indicate the compression
and expansion error 0, whereas “1” to represent the error 1, so the discrimination
information A can be directly used to represent the companding error. Of course,
you can change the way, saying that “0” indicates the companding error 1, and
“1” represents the companding error 0. However, the experiment has proved that
under this representation, the error between j2CQ(x)0j and the original amplitude
jxj becomes larger. The detailed analysis shows that, under the former representa-
tion, the error between j2CQ(x)0j and the original amplitude jxj is T when jxj  T
(see Fig. 3.26), whereas under the latter representation, the corresponding error is
T þ 1 or T1. Since the distortion is calculated by using the square of the magnitude
of the error, in the case that the distribution of adjacent original amplitudes is more
balanced, obviously the former method can get smaller overall distortion.
From the above-mentioned analysis, we also ﬁnd that if the ﬁrst representation
method is used, that is, the companding error 0 is denoted by “0”, whereas the error
1 is denoted by “1.”, we can always have the following relationship:
2CQðxÞ0 ¼
 2$jxj;
jxjhT
jxj þ T;
jxj  T
(3.72)
Thus, we can get a simpliﬁed form for value expansionebased watermark
embedding:
XW ¼
 2X þ W;
jXjhT
X þ signðXÞ$T;
jXj  T
(3.73)
It is easy to know that Eq. (3.73) is equivalent to Eq. (3.72) in terms of the magni-
tude distortion, and this value expansionebased watermark embedding method ap-
proximates Xuan et al.’s compressing and companding method in performance, but
the form is more concise with less amount of calculation; hereinafter, it is referred to
as the value expansion method within the threshold.
3.4.2 COEFFICIENTS’ MAGNITUDE PREDICTION TECHNIQUE IN
INTEGER WAVELET TRANSFORM DOMAIN
From the previous section, we can see that the coefﬁcient companding and compres-
sion method in the integer DWT domain should consider further the selection of
middle- and high-frequency coefﬁcients. Obviously, if we need to perform the value
3.4 Integer Wavelet TransformeBased Schemes
193

expansionebased watermark embedding on N coefﬁcients, the best way is to choose
the N coefﬁcients with the minimum absolute magnitude value, so as to make the
watermark embedding algorithm bring the minimum distortion to the image quality.
However, the problem is that once the N coefﬁcients with minimum absolute magni-
tude values are performed with the expansion and watermark embedding operations,
their resulting coefﬁcients may not be the N coefﬁcients with minimum absolute
magnitude values; then during the watermark extraction and image recovery phase,
we cannot recognize these N coefﬁcients, and thus the image watermark extraction
and recovery will be impossible.
According to the principle of selecting the coefﬁcients with magnitude absolute
values as small as possible, here we provide an adaptive selection scheme for integer
CDF (2,2) wavelet coefﬁcients, which can predict the magnitude distribution of co-
efﬁcient blocks or the positions of coefﬁcients with small magnitudes by making use
of the redundancy among the transform domain coefﬁcients or bands. In theory, if
the accuracy of this predictive method reaches 100%, then the correlation degree
among coefﬁcients must also reach 100%, which is not possible under the integer
transform, which is clearly contrary to the decorrelation features of the original
DWT. However, you can guess, the higher is the accuracy of this prediction, the
less is the distortion that the watermark embedding method introduces, and the al-
gorithm performance can be signiﬁcantly improved.
Here, we provide a simple integer CDF (2,2) wavelet domainebased amplitude
coefﬁcient prediction method. For the integer CDF (2,2) wavelet, more redundancy
exists between different frequency bands, and the corresponding coefﬁcient posi-
tions reﬂect the similarity of the pixel distribution in the spatial domain. We can
make use of the correlation between the high-frequency subbands HH2, LH2, and
HL2 in the second level and the high-frequency subbands HH1, LH1, and HL1 in
the ﬁrst level to construct a tree structure similar to a zero tree, as shown in
Fig. 3.27. Based on the M1 thresholds TH1, TH2, ., THM1, which are set accord-
ing to a certain parent node with the absolute magnitude value c0 among HH2, LH2,
LL2  
LH2
HH2
HL2
HL1
LH1
HH1
c0
c1c2
c3 c4
FIGURE 3.27
The spaceefrequency zero-tree structure.
194
CHAPTER 3 Lossless Information Hiding in Images on Transform Domains

and HL2 subbands, we can classify their corresponding four child nodes {c1,c2,c3,c4}
into a certain class among M classes. Obviously, these M classes of high-frequency
coefﬁcients are with different expectation values, which are suitable for different
watermarking algorithms to achieve improved performance.
3.4.3 COMPARISONS BETWEEN GENERALIZED LOSSLESS
COMPRESSIONeBASED AND VALUE EXPANSIONeBASED
SCHEMES
In this section, we compare the generalized lossless compressionebased generalized
LSB scheme [41], the integer DWT domain lossless bit-plane compressionebased
algorithm [31], the integer DWT domain coefﬁcient compression- and expansion-
based algorithm, and the integer DWT domain histogram shiftebased algorithm.
We will compare the performance of lossless compressionebased methods in the
spatial domain and in the integer DWT domain, as well as the performance of loss-
less compressionebased methods and value expansionebased methods.
3.4.3.1 Generalized Least Signiﬁcant Bit Lossless Compression Scheme
Celik et al. presented a kind of generalized LSB lossless compression (general
LSB
lossless
compression)ebased
reversible
watermarking
technology
in
Ref. [41]. Unlike the traditional bit-plane lossless compressionebased and value
expansionebased schemes, Celik et al.’s method utilizes an efﬁcient lossless
compression algorithm CALIC [42] to losslessly compress the quantized residual,
i.e., the lowest L amplitude levels (instead of the least n bit-planes), and embeds
the watermark data and the compressed bit-planes into the original L minimum
amplitude levels. In fact, the traditional LSB bit lossless compression method is
a special case of L ¼ 2. The performance and data capacity of this method are
better than the original bit-plane lossless compression algorithm, and in theory,
this method can embed log2L bit watermark data in each sample, representing
the
high
level
of
generalized
lossless
compressionebased
methods.
Therefore, we adopt it here as a reference for performance comparison, as shown
in Table 3.3.
3.4.3.2 Integer Discrete Wavelet Transform Domain Lossless Bit-Plane
Compression Scheme
Xuan et al.’s method perform the compression operation on the integer CDF(2,2)
high-frequency subband bit-planes [31], with the performance shown in Table 3.4.
3.4.3.3 Integer Discrete Wavelet Transform Domain Coefﬁcient
Companding and Compression Scheme
Xuan et al. presented a lossless information hiding scheme based on coefﬁcient com-
panding and compression in the integer CDF(2,2) domain in Ref. [40], but they did
3.4 Integer Wavelet TransformeBased Schemes
195

Table 3.3 Performance of Reversible Watermarking Based on General LSB Lossless Compression
Level L
2
3
4
5
6
8
10
12
14
16
Lena
PSNR (dB)
51.1
46.9
44.2
42.1
40.5
38.0
36.0
34.4
33.0
31.9
Bit-rate (bpp)
0.018
0.047
0.087
0.131
0.180
0.285
0.387
0.481
0.584
0.675
Baboon
PSNR (dB)
51.1
46.9
44.2
42.1
40.5
38.0
36.0
34.4
33.0
31.9
Bit-rate (bpp)
0.003
0.008
0.014
0.023
0.034
0.058
0.085
0.117
0.141
0.176
196
CHAPTER 3 Lossless Information Hiding in Images on Transform Domains

not provide the embedding scheme of the companding and compression errors.
Thus, in the simulation, we adopt the value expansion method within the threshold
as shown in Eq. (3.73), and the results are shown in Table 3.5, where T is the
threshold in Eq. (3.73).
3.4.3.4 Integer Discrete Wavelet Transform Domain Histogram Shift
Scheme
We can also perform the histogram shifting technique on the integer CDF(2,2) high-
frequency coefﬁcients to implement the lossless information hiding. In the simula-
tion, we adopt the ﬁrst N peak points with highest magnitude Pi(i ¼ 0, 1, ., N1)
for histogram shifting, and the results are shown in Table 3.6, where N denotes the
number of peaks.
Based on the results shown in Tables 3.3e3.6, we can give a comprehensive
curve (PSNR-bit-rate) to show the performance for four different methods as given
in Fig. 3.28 (Lena) and Fig. 3.29 (Baboon). In ﬁgures, GLSB denotes the generalized
LSB lossless compression, DWTLC is the integer CDF(2,2) wavelet domain lossless
bit-plane compression-based algorithm, DWTCP is the integer CDF(2,2) wavelet
domain coefﬁcient compression- and expansion-based algorithm, and DWTHS is
the integer CDF(2,2) wavelet domain histogram shiftebased algorithm.
From Figs. 3.28 and 3.29, we can obviously see that, the performance of
DWTCP and DWTHS is much better than that of GLSB and DWTLC. Under
the same data capacity, the improvement is nearly 5e8 dB (Lena) or 7e12 dB (Ba-
boon). The performance of DWTLC is very close to that of GLSB, which indicates
that, compared with the bit-planes in the spatial domain, the bit-planes in the
integer wavelet domain are with much more unbalance of the “0” and “1” data,
thus we can deeply compress them to embed more information without affecting
the image quality. Furthermore, we can note that the performance advantage is
much more obvious for the Baboon image, which indicates that the value expan-
sion technique and the histogram shifting technique are much more suitable for im-
ages with high details.
Table 3.4 Performance of Reversible Watermarking Based on Bit-Plane
Lossless Compression in the Discrete Wavelet Transform Domain
Lena
PSNR (dB)
41.0
39.0
38.0
35.6
34.1
Bit-Rate (bpp)
0.1
0.2
0.3
0.4
0.5
Baboon
PSNR (dB)
32.5
29.4
27.6
25.3
Bit-rate (bpp)
0.1
0.2
0.3
0.4
PSNR, peak signal-to-noise ratio.
3.4 Integer Wavelet TransformeBased Schemes
197

Table 3.5 Performance of the Method Given in Eq. (3.73) to Simulate the Companding-Based Reversible Watermarking in
the Integer Discrete Wavelet Transform Domain
T
1
2
3
4
5
6
7
8
9
10
Lena
PSNR (dB)
48.054
44.46
42.413
41.175
40.299
39.638
39.117
38.68
38.307
37.995
Bit-rate (bpp)
0.114
0.314
0.465
0.563
0.625
0.661
0.684
0.699
0.709
0.717
Baboon
PSNR (dB)
48.059
43.687
40.69
38.672
37.053
35.807
34.756
33.883
33.112
32.452
Bit-rate (bpp)
0.036
0.108
0.172
0.229
0.278
0.322
0.358
0.389
0.416
0.442
PSNR, peak signal-to-noise ratio.
198
CHAPTER 3 Lossless Information Hiding in Images on Transform Domains

Table 3.6 Performance of Histogram ShiftingeBased Reversible Watermarking in the Integer Discrete Wavelet Transform
Domain
N
1
2
3
4
5
6
7
8
9
10
Lena
PSNR (dB)
48.705
45.322
42.413
41.175
40.299
39.638
39.117
38.68
38.307
37.995
Bit-rate (bpp)
0.2
0.351
0.465
0.563
0.625
0.661
0.684
0.699
0.709
0.717
Baboon
PSNR (dB)
48.255
43.934
40.954
38.925
37.305
35.807
34.756
33.883
33.112
32.452
Bit-rate (bpp)
0.07
0.135
0.191
0.243
0.286
0.322
0.358
0.389
0.416
0.442
PSNR, peak signal-to-noise ratio.
3.4 Integer Wavelet TransformeBased Schemes
199

24
26
28
30
32
34
36
38
40
42
44
46
48
50
52
0
0.1
0.2
0.3
0.4
PSNR(dB)
bitrate(bpp)
Baboon
GLSB
DWTLC
DWTCP
DWTHS
FIGURE 3.29
Performance of general lossless compression and discrete wavelet transform coefﬁcient
expansionebased reversible watermarking algorithms: Baboon.
30
32
34
36
38
40
42
44
46
48
50
52
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
PSNR(dB)
bitrate(bpp)
Lena
GLSB
DWTLC
DWTCP
DWTHS
FIGURE 3.28
Performance of general lossless compression and discrete wavelet transform coefﬁcient
expansionebased reversible watermarking algorithms: Lena.
200
CHAPTER 3 Lossless Information Hiding in Images on Transform Domains

3.5 SUMMARY
This chapter has discussed transform domain lossless information hiding schemes,
including IntDCT-based schemes and integer DWT-based schemes. Before intro-
ducing then, we introduced some related concepts and requirements for lossless in-
formation hiding, and gave a brief overview of transform domainebased
information hiding.
With regard to IntDCT-based schemes, we have introduced three Yang et al.’s
schemes,
i.e.,
the
companding
techniqueebased
scheme,
the
histogram
modiﬁcationebased scheme, and the adaptive coefﬁcient modiﬁcationebased
scheme. The ﬁrst scheme takes advantage of the bit-shift operation in the compand-
ing process to achieve high watermarking capacity and good quality of watermarked
images. To solve the over- and underﬂow problems caused by the coefﬁcient modi-
ﬁcation, Yang et al. designed a twice-try-based block discrimination structure to ﬁnd
those twice-embedding permitted blocks to store overhead for block location
information that reﬂects all blocks’ over- and underﬂow situations. These twice-
embedding permitted blocks can be recognized during extraction without any
overhead for indication. The watermark bits can be reversibly embedded in the
remaining twice-embedding permitted blocks and all once-embedding permitted
blocks. In the second scheme, the histogram modiﬁcation techniqueebased scheme
is generalized into an 8  8 integer DCI’ domain successfully and achieves high
capacity and ﬁne quality adjustment capability in relatively high PNSR ranges
(about 40e60 dB) of the watermarked image. The experimental results demonstrate
this scheme’s competitive performance for general reversible image watermarking
applications. In the third scheme, Yang et al. investigated three IntDCT coefﬁcient
selection methods to adapt the coefﬁcient modiﬁcation process to the current block’s
coefﬁcients’ amplitude status, and thus improved the watermarking performance in
terms of the capacity/distortion rate. They integrated the GCDS technique, the value
addition scheme, and a low-frequency coefﬁcient-based block classiﬁcation method
and obtained satisfactory improvements in several performance aspects. Note that
some coefﬁcient adaptive modiﬁcation ideas, such as the coefﬁcient distortion sort-
ing and the low frequency coefﬁcient prediction, can be actually modiﬁed and
migrated to other integer transform domains such as integer wavelet transform
and achieve even greater improvements in some performance aspects.
With regard to integer DWT-based schemes, we introduce three schemes, i.e., the
value expansionebased scheme, the histogram shiftebased scheme, and the coefﬁ-
cient magnitude predictionebased scheme. The ﬁrst scheme was originally pro-
posed by Xuan et al. Based on Yang et al.’s bit-shift idea in the IntDCT domain,
Xuan et al. tried to perform the companding and value expansion techniques on
the integer CDF(2,2) transform coefﬁcients, which are obtained from one-level
integer CDF(2,2) wavelet decomposition (resulting in three high frequency LH,
HL, HH coefﬁcients), achieving relatively good performance. Note that, in this al-
gorithm, the key problem to improving the performance is to design a suitable
compression function. With regard to the second scheme, it is just a scheme to
3.5 Summary
201

perform the histogram shifting technique on the integer CDF(2,2) high-frequency
coefﬁcients to implement the lossless information hiding. All these schemes are
compared with the typical spatial domainebased schemes. With regard to the third
scheme, we provide an adaptive selection scheme for integer CDF(2,2) wavelet co-
efﬁcients, which can predict the magnitude distribution of coefﬁcient blocks or the
positions of coefﬁcients with small magnitudes by making use of the redundancy
among the transform domain coefﬁcients or bands redundancy. Finally, all the
afore-mentioned methods are simulated and compared.
REFERENCES
[1] K. Komatsu, K. Sezaki, Reversible discrete cosine transform, Proceedings of IEEE
ICASSP98 (1998) 1113e1772.
[2] W. Philips, Lossless DCT for combined lossy/lossless image coding, Proceedings of
IEEE International Conference on Image Processing 3 (1998) 871e875.
[3] T. Tran, The BinDCT: fast multiplierless approximation of the DCT, IEEE Signal Pro-
cessing Letters 7 (2000) 141e144.
[4] L. Cheng, H. Xu, Y. Luo, Integer discrete cosine transform and its fast algorithm, Elec-
tronics Letters 37 (2001) 64e65.
[5] Y. Zhang, L. Cheng, G. Bi, A.C. Kot, Integer DCTs and fast algorithms, IEEE Trans-
actions on Signal Processing 49 (2001) 2774e2782.
[6] M.D. Adams, Reversible Integer-to-integer Wavelet Transforms for Image Coding
(Ph.D. thesis), Department of Electrical and Computer Engineering, The University
of British Columbia, 2002.
[7] M.D. Adams, F. Kossentini, Reversible integer-to-integer wavelet transforms for image
compression: performance evaluation and analysis, IEEE Transactions on Image Pro-
cessing 9 (6) (2000) 1010e1024.
[8] A.R. Calderbank, I. Daubechies, W. Sweldens, B.L. Yeo, Wavelet transforms that maps
integers to integers, Applied and Computational Harmonic Analysis 5 (1998) 332e369.
[9] S. Dewitte, J. Cornelis, Lossless integer wavelet transform, IEEE Signal Processing Let-
ters 4 (6) (1997) 158e160.
[10] G. Plonka, M. Tasch, Invertible integer DCT algorithms, Applied and Computational
Harmonic Analysis 15 (2003) 70e88.
[11] G. Plonka, M. Tasche, Reversible Integer DCTAlgorithms, Preprint, Gerhard-Mercator-
University, Duisburg, 2002.
[12] G. Plonka, A Global Method for Invertible Integer DCT and Integer Wavelet Algo-
rithms, Preprint, Gerhard-Mercator-University, Duisburg, 2004.
[13] W. Sweldens, The lifting scheme: a custom-design construction of biorthogonal
wavelets, Applied and Computational Harmonic Analysis 3 (2) (1996) 186e200.
[14] A. Cohen, I. Daubechies, J.C. Feauveau, Biorthogonal bases of compactly supported
wavelets, Communications on Pure and Applied Mathematics 45 (1992) 485e560.
[15] N. Ahmed, T. Natarajan, K.R. Rao, Discrete cosine transform, IEEE Transactions on
Computers 32 (1974) 90e93.
[16] E. Koch, J. Zhao, Towards robust and hidden image copyright labeling, in: Proceedings
of the IEEE Workshop on Nonlinear and Marmaras, Greece, 1995, pp. 1e4.
202
CHAPTER 3 Lossless Information Hiding in Images on Transform Domains

[17] I.J. Cox, J. Kilian, F.T. Leighton, et al., Secure spread spectrum watermarking for
multimedia, IEEE Transactions on Image Processing 6 (12) (1997) 1673e1687.
[18] B. Tao, B. Dickinson, Adaptive watermarking in the DCT domain, in: Proceeding of the
1997 IEEE International Conference on Acoustics, Speech, and Signal Processing, 4
(4), 1997, pp. 2985e2988.
[19] B. Yang, M. Schmucker, X. Niu, C. Busch, S. Sun, Reversible image watermarking by
histogram modiﬁcation for integer DCT coefﬁcients, in: IEEE 6th Workshop on Multi-
media Signal Processing, September 29eOctober 1, 2004, 2004, pp. 143e146, http://
dx.doi.org/10.1109/MMSP. 2004.1436446.
[20] C.C. Chen, D.S. Kao, DCT-based reversible image watermarking approach, in: Third
International Conference on Intelligent Information Hiding and Multimedia Signal Pro-
cessing, November 26e28, 2007, Kaohsiung, 2007, pp. 489e492.
[21] S. Pereira, J.J.K. O’Ruanaidh, F. Deguillaume, et al., Template based recovery of
Fourier-based watermarks using log-polar and log-log maps, in: Proceedings of the
IEEE International Conference on Multimedia Computing and Systems. Florence, Italy,
1999, pp. 870e874.
[22] M. Corvi, G. Nicchiotti, Wavelet based image watermarking for Copyright Protection[C], in:
Scandinavian Conference on Image Analysis. Lappeenranta,Finland, 1997, pp. 157e163.
[23] D. Kundur, D. Hatzinakos, A robust digital image watermarking method using wavelet-
based fusion[C], in: Proceedings of the IEEE International Conference on Image Pro-
cessing, 1997, pp. 544e547.
[24] G. Xuan, Y. Shi, P. Chai, et al., Optimum histogram pair based image lossless data
embedding, in: Proceedings of Digital Watermarking, LNCS, 5041, 2008, pp. 264e278.
[25] Y.J. Chen, Integer discrete cosine transform (IntDCT), in: Presented at the Second In-
ternational Conference on Information Communications and Signal Processing,
Singapore, December 1999 (Invited paper).
[26] T.D. Tran. Fast multiplierless approximation of the DCT. (Online). Available: http://
thanglong.ece.jhu.edu/Tran/Pub/intDCT.ps.gz.
[27] B. Yang, M. Schmucker, W. Funk, C. Busch, S. Sun, Integer DCT-based reversible
watermarking for images using companding technique, in: Proc. SPIE, Security and
Watermarking of Multimedia Content, Electronic Imaging, San Jose, USA, January
2004, pp. 405e415.
[28] A. Leest, M. Veen, F. Bruekers, Reversible image watermarking, in: IEEE Proceedings
of ICIP’03, vol. 2, 2003, pp. 731e734.
[29] M. Veen, F. Bruekers, A. Leest, S. Cavin, High capacity reversible watermarking for
audio, in: Proceedings of the SPIE, vol. 5020, 2003, pp. 1e11.
[30] E. Lam, J. Goodman, A mathematical analysis of the DCT coefﬁcient distribution for
images, IEEE Transactions on Image Processing 9 (10) (2000) 1661e1666.
[31] G. Xuan, J. Zhu, J. Chen, Y. Shi, Z. Ni, W. Su, Distortionless data hiding based on
integer wavelet transform, IEE Electronics Letters 38 (25) (2002) 1646e1648.
[32] Z. Ni, Y.Q. Shi, N. Ansari, W. Suo, Reversible data hiding, in: IEEE Proceedings of/
SCAS’03, vo1.2, May 2003, pp. II$912eII-915.
[33] A. Leesl, M. Veen, E. Broekers, Reversible image watemarking, in: IEEE Proceedings
of ICIP’03, vol. 2, September 2003, pp. 731e734.
[34] B. Yang, M. Schmucker, X. Niu, C. Busch, S. Sun, Integer DCT based reversible image
watermarking by adaptive coefﬁcient modiﬁcation, in: SPIE-EI, Security and Water-
marking of Multimedia Content, Proc. of SPIE-IS&T Electronic Imaging, SPIE, vol.
5681, Electronic Imaging, San Jose, USA, January, 2005, pp. 218e229.
References
203

[35] Z. Xiong, O.G. Guleryuz, M.T. Orchard, A DCT-based embedded image coder, IEEE
Signal Processing Letters 3 (11) (1996) 289e290.
[36] M. Voigt, B. Yang, C. Busch, Reversible watermarking of 2D-vector data, in: Proceed-
ings of the 2004 ACM International Workshop on Multimedia and Security, Magde-
burg, Germany, 2004, pp. 160e165.
[37] M. Thodi, J.J. Rodrı´guez, Reversible watermarking by prediction-error expansion, in:
The 6th IEEE Southwest Symposium on Image Analysis and Interpretation, Lake
Tahoe, CA, USA, March 28e30, 2004, 2004, pp. 21e25.
[38] G. Xuan, C. Yang, Y. Zhen, Y. Shi, Z. Ni, Reversible data hiding based on wavelet
spread spectrum, in: IEEE Proceedings of Multimedia Signal Processing Workshop,
2004. Siena, Italy.
[39] J. Nam, K. Rao, Image coding using a classiﬁed DCT/VQ based on two-channel con-
jugate vector quantization, IEEE Transactions on Circuits and Systems for Video Tech-
nology 1 (4) (1991) 325e336.
[40] G. Xuan, C. Yang, Y. Zhen, Y. Shi, Z. Ni, Reversible Data Hiding Using Integer Wavelet
Transform and Companding Technique, IWDW, 2004.
[41] M.U. Celik, G. Sharma, A.M. Tekalp, E. Saber, Reversible data hiding, in: Proc. of In-
ternational Conference on Image Processing, vol. II, September 2002, pp. 157e160.
[42] X. Wu, Lossless compression of coutinuous-tone images via context selection, quanti-
zation and modelling, IEEE Transactions on Image Processing 6 (5) (May 1997)
656e664.
204
CHAPTER 3 Lossless Information Hiding in Images on Transform Domains

Lossless Information
Hiding in Vector
Quantization Compressed
Images
4
4.1 INTRODUCTION
4.1.1 BASIC FRAMEWORK OF LOSSLESS INFORMATION HIDING IN
THE COMPRESSED DOMAIN
When we view the lossless information hiding problem in the compressed domain, such
as vector quantization (VQ) [1] and block truncation coding (BTC) [2], the cover object
becomes the compressed version of the original imagedthe code stream. For the change
of information hiding from the pixel domain to the compressed domain the change of
some requirements is necessary and information hiding algorithms are desired, which
will be given afterward. Before that, we introduce a basic framework of lossy compres-
sion (encoding and decoding) and lossless information hiding [3] in the compressed
domain presented by Yang et al. in Fig. 4.1, where Io is supposed to be the original
image, E is a lossy encoder containing a quantizer, and C is the code stream, resulting
from E, as the exact cover object in the lossless information hiding model. D is a decoder
corresponding to E, and Em. and Ex. are the embeddor and extractor, respectively.
From Fig. 4.1, we can see that the mapping from Io to C is many-to-one because
of the quantization operation in E. Thus, if we directly reversibly embed information
in Io, some distortion may be caused to the information embedded in Io during the
extraction process, which destroys the reversibility of the algorithm used in the pixel
domain. So we change the cover object from Io to C, which is the actual existing
form of Io for storing and transmission.
4.1.2 REQUIREMENTS OF LOSSLESS INFORMATION HIDING IN THE
COMPRESSED DOMAIN
Now we prescribe some requirements in the deﬁnition of lossless information hiding
in the aforementioned framework [3].
1. Reversibility
The perfect restoration of C and w after extraction without attacks, that is,
C ¼ CR and w ¼ wr.
CHAPTER
Lossless Information Hiding in Images. http://dx.doi.org/10.1016/B978-0-12-812006-4.00004-8
Copyright © 2017 Zhejiang University Press Co., Ltd., published by Elsevier Inc. All rights reserved.
205

2. Dispensability
The information w embedded in the C should be dispensable in format from the
other part of C, which will guarantee the “invisibility” to the decoder. In other words,
the decoder should be able to read the code stream Cw as smoothly as its normal
version C without any “notice” that there is some information w embedded.
3. Fidelity
The embedding of w should not cause great perceptual distortion to the recon-
structed image Iw compared with its original version Io, which is decided by water-
mark’s original intention.
4. Size preservation of the original image
The size of the reconstructed images I and Iw should be equal in the pixel
domain. Note that this requirement is not necessary to the code stream as long as
the change in code stream’s size will not compromise the function of the decoder,
although in many cases it is also desired that the code stream’s size be preserved.
Aside from these requirements that are necessary for the general lossless infor-
mation hiding algorithms in the compressed domain, there are also some desired
properties of the algorithms from some practical views.
E
Encoder
Compressed 
stream C
D
Decoder
Original image
IO
Reconstructed 
image
I
E
Encoder
Compressed 
stream C 
Em.
Stego
compressed 
stream CW
Embedder
D
Decoder
IW
Image reconstructed
from CW
E
Encoder
Compressed 
stream CW
Ex.
Extractor
Restored 
compressed 
stream CR
Compressed
stream C
Em.
der
Ex.
tor
Reversible information hiding frame
wr
w
FIGURE 4.1
Framework of lossy compression and lossless information hiding in compressed domain.
206
CHAPTER 4 Lossless Information Hiding in Vector Quantization

1. Compatibility
The lossless information hiding algorithm should be as compatible with existing
lossy compression schemes as possible. No or least modiﬁcation of existing en-
coders and decoders is preferred considering the convenience of algorithm
implementation.
2. Size preservation of the code stream
This desired property has been explained in Requirement 4.
3. Clipping avoidance
Some modiﬁcation due to lossless information hiding algorithms will be sensi-
tive to pixel clipping (overﬂows and underﬂows), which will destroy the equality
of Cw and C0
w in images’ reconstruction, and accordingly, affect the inheritance of
the information w from Cw to C0
w. Although the information extracted from C0
w is
not a requirement for the general lossless information hiding scheme, in some cases,
users may appreciate this virtue.
4. Separation of the encoder and the embeddor
This property facilitates the individual processing of encoder and information
embeddor. From the previous discussion, we can see the difference between the
pixel-domain lossless information hiding and the one performed in the compressed
domain. In the VQ-compressed domain too, the requirements and desires apply in
most cases.
4.1.3 VECTOR QUANTIZATION
VQ [1] has become an attractive block-based encoding method for image compres-
sion. It can achieve a high compression ratio. In environments such as image archival
and one-to-many communications, the simplicity of the decoder makes VQ very
efﬁcient. In brief, VQ can be deﬁned as a mapping from k-dimensional Euclidean
space Rk into a ﬁnite subset C ¼ {ciji ¼ 0, 1, ., N  1} that is generally called a
codebook, where ci is a codeword and N is the codebook size, as shown in
Fig. 4.2. Before compression, VQ generates a representative codebook from a
training set consisting of a number of training vectors using, for example, the
well-known iterative clustering algorithm [1] that is often referred to as the gener-
alized Lloyd algorithm. In VQ, the image to be encoded is ﬁrst decomposed into
vectors and then sequentially encoded vector by vector. As shown in Fig. 4.3, in
the encoding stage, each k-dimensional input vector x ¼ (x1, x2, ., xk) is compared
with the codewords in the codebook C ¼ {c0, c1, ., cNL1} to ﬁnd the best matching
codeword ci ¼ (ci1, ci2, ., cik) satisfying the following condition:
dðx; ciÞ ¼
min
0jN1 dðx; cjÞ
(4.1)
4.1 Introduction
207

i.e., the distance between x and ci is the smallest, where d(x,cj) is the distortion of
representing the input vector x by the codeword cj, which is often measured by
the squared Euclidean distance, i.e.,
dðx; cjÞ ¼
X
k
l¼1
ðxl  cjlÞ2
(4.2)
Then the index i of the best matching codeword assigned to the input vector x is
transmitted over the channel to the decoder. The decoder has the same codebook as
the encoder. In the decoding phase, for each index i, the decoder merely performs a
simple table look-up operation to obtain ci and then uses ci to reconstruct the input
vector x. The compression ratio is determined by the codebook size and the dimen-
sion of the input vectors, and the overall distortion depends on the codebook size and
the selection of codewords.
4.2 OVERVIEW OF VECTOR QUANTIZATIONeBASED
INFORMATION HIDING
Since 2000, VQ has been successfully applied to digital image watermarking
[21e31]. Since 2005, because of the emergence of lossless information hiding,
FIGURE 4.2
The principle of vector quantization.
Source
Input
Index
Index
Output
vector
Destination
Generated by
LBG(GLA)
Algorithm
Encoder
Decoder
Codebook
Codebook
Look up
Table
Channel
Vector
Nearest
Neighbor
Search
FIGURE 4.3
The encoding and decoding processes of vector quantization.
208
CHAPTER 4 Lossless Information Hiding in Vector Quantization

several scholars have been dedicated to lossless information hiding in VQ-
compressed images. In the following two subsections, we overview typical methods
related to VQ-based watermarking and VQ-based lossless information hiding.
4.2.1 OVERVIEW OF VECTOR QUANTIZATIONeBASED IMAGE
WATERMARKING
Traditional digital watermarking schemes are mainly based on discrete cosine trans-
form (DCT) and discrete wavelet transform. In the past 15 years, many robust image
watermarking techniques based on VQ [21e31] have been presented. These algo-
rithms can be mainly classiﬁed into three categories: codebook partition based, in-
dex properties based, and multipurpose methods. Refs. [21e26] embed the
watermark information into the encoded indices under the constraint that the extra
distortion is less than a given threshold. Ref. [27] embeds the watermark bit in
the dimension information of the variable dimension reconstruction blocks of the
input image. Refs. [28,29] embed the watermark information by utilizing the prop-
erties, such as mean and variance, of neighboring indices. Refs. [30,31] present
multipurpose watermarking methods based on multistage VQ and DCT domain
VQ, respectively. For example, in Ref. [30], the robust watermark is embedded in
the ﬁrst stage by using the embedding method presented in Ref. [28], and the semi-
fragile watermark is embedded in the second stage by using index-constrained VQ.
In the following two subsections, we introduce the main idea of the algorithms in the
ﬁrst two categories.
4.2.1.1 Watermarking Algorithms Based on Codebook Partition
The main idea of this kind of VQ-based digital watermarking schemes [21e26] is to
carry secret copyright information by codeword indices. The aim of the codebook
partition is to classify the neighboring codewords into the same cluster. Given a
threshold D > 0, we denote by S ¼ {S1, S2, .,SM} a standard partition of the code-
book C ¼ {c0, c1, ., cNL1} for the threshold D, if S satisﬁes the following four
conditions:
1. S ¼ WM
i¼1 Si;
2. ci, j, 1  i, j  M, if i s j, then SiXSj ¼ F;
3. ci, 1  i  M, if cl˛Si and cj˛Si (0  l, j  N  1), then d(cl,cj)  D;
4. kSik ¼ 2nðiÞ, where kSik denotes the number of codewords in Si and n(i) is a
natural number.
Before the embedding process, the original image is ﬁrst divided into blocks. For
each block, the index of the best match codeword is found. The watermarked code-
word index is then obtained by modifying the original codeword index according to
the corresponding watermark bits. The modiﬁcation is under the constraint that the
modiﬁed index and the original one is in the same partition such that the introduced
extra distortion is less than the given distortion threshold. In the decoding phase, not
the original but the watermarked codeword is used to represent the input image
4.2 Overview of Vector QuantizationeBased Information Hiding
209

block. Therefore, the VQ-based digital image watermarking will introduce some ex-
tra distortion. Whether the original image is required or not during the watermark
extraction depends on the embedding method. In these algorithms, the codebook
is open for users but the partition is the secret key. Experimental results show that
these algorithms are robust to VQ compression with high-performance codebooks,
JPEG compression, and some spatial image processing operations. However, these
algorithms are fragile to rotation operations and VQ compression with low-
performance codebooks.
4.2.1.2 Watermarking Algorithms Based on Index Properties
To enhance the robustness to rotation operations and VQ compression operations,
some image watermarking algorithms [28,29] based on the properties of neighboring
indices have been proposed. In Ref. [28], the original watermark W with size
Aw  Bw is ﬁrst permuted by a predetermined key, key1, to generate the permuted
watermark WP for embedding. The original image X with size A  B is then divided
into vectors x(m,n) with size (A/Aw)  (B/Bw), where x(m,n) denotes the image block
at the position (m,n). After that, each vector x(m,n) ﬁnds its best codeword ci in the
codebook C and the index i is assigned to x(m,n); we can then obtain the indices ma-
trix Y with elements y(m,n), which can be represented by
Y ¼ VQðXÞ ¼
W
A
Aw  1
m¼0
W
B
Bw  1
n¼0 VQðxðm; nÞÞ ¼
W
A
Aw  1
m¼0
W
B
Bw  1
n¼0 yðm; nÞ
(4.3)
For natural images, the VQ indices among neighboring blocks tend to be very
similar, so we can make use of this property to generate the polarities P. After calcu-
lating the variances of y(m,n) and the indices of its surrounding blocks with
s2ðm; nÞ ¼
0
@1
9
X
mþ1
i¼m1
X
nþ1
j¼n1
y2ði; jÞ
1
A 
0
@1
9
X
mþ1
i¼m1
X
nþ1
j¼n1
yði; jÞ
1
A
2
(4.4)
We can obtain the polarities P as follows:
P ¼
W
A
Aw  1
m¼0
W
B
Bw  1
n¼0 pðm; nÞ
(4.5)
where
pðm; nÞ ¼
(
1
if s2ðm; nÞ  T
0
otherwise
(4.6)
For convenience, we set the threshold T to be half of the codebook size, N/2. We
are then able to generate the ﬁnal embedded watermark or the secret key, key2, with
the exclusive-or operation as follows:
key2 ¼ WP4P
(4.7)
210
CHAPTER 4 Lossless Information Hiding in Vector Quantization

After the inverse VQ operation, both the reconstructed image, X
0, and the secret
key, key2, work together to protect the ownership of the original image.
In the extraction process, we ﬁrst calculate the estimated polarities P0 from X0
and then obtain an estimate of the permuted watermark as follows:
W0
P ¼ key24P0
(4.8)
Finally, we can perform the inverse permutation operation with key1 to obtain the
extracted watermark W0.
To embed multiple watermarks, Ref. [29] also uses the mean of indices to
generate another polarities P1 for embedding. Experimental results show that these
algorithms are robust to many kinds of attacks, including JPEG, VQ, ﬁltering, blur-
ring, and rotation. However, these algorithms have the following two problems:
1. We can also extract the watermark from the original image that has no watermark
embedded in it at all.
2. The codebook should be used as a key, because if the user possesses the same
codebook, he can also embed his own watermark in the watermarked image
without any modiﬁcation.
In fact, unlike traditional watermarking methods, this kind of watermarking al-
gorithm does not modify the VQ-compressed cover work at all. The term “ﬁnger-
print” or “secure ﬁngerprint” may be more appropriate, and sometimes we can
call this kind of watermark “zero-watermark.”
4.2.2 OVERVIEW OF VECTOR QUANTIZATIONeBASED LOSSLESS
INFORMATION HIDING
As one of the most commonly studied image compression techniques, VQ has been
widely applied in information hiding techniques because of its simplicity and cost-
effective implementation. Promoted by the research works proposed by Chang et al.
[32], Lu et al. [10], and Chen and Huang [16], VQ has been widely applied to infor-
mation hiding. These schemes can be roughly classiﬁed into two categories: infor-
mation hiding during VQ encoding and information hiding during VQ index coding.
For the ﬁrst category, Yang et al. [3] proposed a lossless information hiding
scheme based on modiﬁed fast correlation VQ (MFCVQ). Since the embeddable lo-
cations are determined by a predeﬁned distance threshold, the hiding payload of the
MFCVQ method is unstable and low. To improve the hiding payload, Chang et al.
[4e7] proposed several information hiding algorithms based on side match VQ
(SMVQ). The SMVQ algorithm [18e20] can achieve a lower bit rate; however, it
brings relatively high computation cost.
In literatures, several lossless information hiding schemes based on VQ index
coding have been proposed. Chang et al. proposed a lossless information embedding
scheme [8] based on the VQ image compression technique, which emphasizes that
the original VQ-compressed codes can be recovered after data extraction. Chang
et al. [9] presented a lossless information hiding method based on the so-called joint
4.2 Overview of Vector QuantizationeBased Information Hiding
211

neighboring coding (JNC) technique. This method embeds secret data by using the
difference values between the current VQ-compressed index and left or upper neigh-
boring indices. In 2013, Chu et al. [12] proposed a lossless information hiding
scheme based on the difference coding technique, which achieves higher stego im-
age quality and higher payload. However, the secret data are exposed in the output
bitstream, and hence it is not safe enough. To enhance the security, Lu et al. [10] pro-
posed a lossless information hiding algorithm based on the VQ-index residual value
coding (VQIRVC). This algorithm can achieve higher peak signal-to-noise ratio
(PSNR) and higher payload than the algorithms proposed by Yang et al. [3] and
Chang et al. [6]. In 2009, a novel path optional lossless information hiding method
[11] has been proposed with improvements on payload, stego image quality, trans-
mission efﬁciency, and security. Lu et al. presented an improved JNC (IJNC) process
[13] for both lossless information hiding and lossless index compression. The JNC
process performs information hiding on each index outside the seed area, whereas
the IJNC process performs information hiding on each 2  2 index block without
any seed area. Wang et al. also proposed a novel lossless information hiding frame-
work [14] to hide secret data into a binary codestream of VQ indices invertibly, in
which matrix encoding is used to efﬁciently embed secret data, and error correction
coding is employed for lossless restoration of the marked codestream at the receiver
side. Zhao et al. [15] proposed a novel lossless information hiding scheme based on
two-stage VQ (TSVQ), where the framework consists of three phases, TSVQ code-
book generation, path selection and data embedding, and cover image reconstruction
and secret data extraction.
In the following sections, we will introduce the aforementioned schemes in
detail. We ﬁrst introduce the MFCVQ-based scheme, the ﬁrst VQ-based lossless in-
formation hiding algorithm. Then we introduce SMVQ-based schemes. Finally, we
introduce VQ-index codingebased schemes.
4.3 MODIFIED FAST CORRELATION VECTOR
QUANTIZATIONeBASED SCHEME
Image blocks encoded by VQ are usually in the form of indices, which represent
codewords’ positions in a codebook C. The VQ encoder E quantizes the input image
block x by selecting a best-matched code vector cb [cb ˛ C ¼ {c0, c1,., cN1},
where N is the size of the codebook C]. Here, the Euclidean distance given in Eq.
(4.2) is often employed as a metric for the best matching. It is obvious that this quan-
tization might cause some distortion to the watermark information embedded in the
pixel domain, if the embedding algorithms are sensitive to this operation, like most
value expansionebased lossless information hiding algorithms [34e38]. So a loss-
less watermarking algorithm that works in the VQ indices is desired to circumvent
the quantization operation. Many watermarking or information hiding algorithms
have been proposed based on the VQ technique, which use VQ as a watermark
embedding and extracting means based on the idea of quantization index modulation
212
CHAPTER 4 Lossless Information Hiding in Vector Quantization

(QIM) [33], which is a popular type of watermarking algorithm for VQ-compressed
images. However, many VQ-based watermarking algorithms [22,25] by QIM just
view VQ as a watermark embedding and extracting method for the original image.
In Section 4.3.1, we review basic VQ (BVQ)ebased watermarking algorithms from
the view of the reversibility of the VQ indices in the compressed domain. Consid-
ering that the reversibility is usually traded with the compression performance of
VQ, we ﬁrst introduce the original fast correlationebased VQ (FCVQ) in Section
4.3.2 and then introduce the lossless information hiding algorithm based on MFCVQ
in Section 4.3.3, where we give some simulation results and the advantages and dis-
advantages of the MFCVQ-based lossless information hiding algorithm.
4.3.1 LOSSLESS INFORMATION HIDING FOR BASIC VECTOR
QUANTIZATION
Now we construct a lossless information hiding algorithm for BVQ indices based on
the QIM idea [10], which has been implemented in [22,25] practically. Note the
object of VQ-based watermarking techniques in [22,25] is to embed watermark
information into the original image in the pixel domain. However, now for revers-
ibility, we only need to ﬁx the encoding results from one codebook as the original
code stream, and the others for information hiding, then the whole schemes in
[22,25] can be directly converted into lossless ones for indices. The whole scheme
is illustrated as in Fig. 4.4 with a simple example containing two codebooks C1 and
C2 with the same size N, where the indices encoded by C1 represent the original set
of indices (e.g., watermark bit “0”), and the indices encoded by C2 represent the
modiﬁed indices (e.g., watermark bit “1”). Note that all code vectors in C1 and C2
are grouped into pairs by two code vectors from C1 and C2, respectively, and each
pair represents the two closest (in the Euclidean distance) code vectors of all code
vectors out of C1 and C2. If we set the encoding results by C1 as the original indices,
we can then set C2 for index modulation for watermark embedding. Thus whichever
index we get, we can ﬁnd its “partner” in the pair and their pertaining codebooks that
modulate the watermark bit “0” and “1.” After retrieval of the watermark, the indices
can be perfectly restored to the original ones from C1.
This basic lossless information hiding algorithm uses two N-sized codebooks to
modulate the watermark bit “0” and “1,” which has the watermarking capacity as
Codebook C1
Codebook C2
w
0
1
ck1
ck2
ck1
FIGURE 4.4
Basic index modulation based lossless information hiding: code vector ck1 and ck2 are in
the same kth pair (0  k  N  1).
4.3 Modiﬁed Fast Correlation Vector QuantizationeBased Scheme
213

high as the amount of the indices. However, it is easily seen that this hiding algo-
rithm trades compression performance with the watermarking performance and its
bitrate nearly doubles at the similar encoding quality for the original VQ coding al-
gorithm if we consider the desired properties (1) and (2) given in Section 4.1.2.
4.3.2 FAST CORRELATION VECTOR QUANTIZATIONeBASED IMAGE
COMPRESSION
Since the MFCVQ is derived from the original FCVQ [17], we introduce FCVQ
before describing the lossless information hiding scheme based on MFCVQ.
The FCVQ predicts the current 4  4 pixel block x’s state with its neighboring
four encoded blocks ca, cb, cc, and cd, or the three encoded blocks ca, cb, and cc
for the last column of image blocks as shown in Fig. 4.5. An N-sized codebook C
is used for encoding and decoding. The detailed encoding and decoding processes
are described as follows with the example in Fig. 4.5a.
4.3.2.1 Encoding
Step 0: Encode the ﬁrst row and the ﬁrst column of original image blocks by full
search in the codebook C.
Step 1: Calculate the distances between ca, cb, cc, cd, and the current bock x,
respectively, as da ¼ kca  xk2
2, db ¼ kcb  xk2
2, dc ¼ kcc  xk2
2, and
dd ¼ kcd  xk2
2; ﬁnd the smallest distance dm ¼ min{da, db, dc, dd}.
Step 2: Compare dm with the preset distance threshold TH, if dm  TH, send a
ﬂag bit “0” to the code stream, and go to Step 3; otherwise, send a ﬂag bit “1” to
the code stream, and go to Step 5.
Step 3: Find the best-matched code vector cmb out of {ca, cb, cc, cd} as the
encoded code vectors of the current block x and send the 2 bits’ index of cmb
(indices of ca, cb, cc, and cd are 00, 01, 10, and 11 respectively) to the code
stream, and go to Step 5.
Step 4: Find the best-matched code vector cmb out of the whole codebook C as
the current block x’s encoded code vector and send its index in C to the code
stream, and go to Step 5.
Step 5: Go to the next image block to be encoded and perform Steps 1 to 5
iteratively and only stop after all image blocks are encoded.
cb
cb
ca
ca
cc
cc
cd
x
x
(a)
(b)
FIGURE 4.5
Correlation-based algorithms: (a) normal case of x’s state prediction by ca, cb, cc, and cd
and (b) last-column block case of x’s state prediction by ca, cb, and cc.
214
CHAPTER 4 Lossless Information Hiding in Vector Quantization

4.3.2.2 Decoding
The decoding process is actually the inverse of the embedding process since the ﬂag
bits can be explicitly used to guide the index selection.
4.3.3 MODIFIED FAST CORRELATION VECTOR QUANTIZATIONe
BASED LOSSLESS INFORMATION HIDING
Now we introduce MFCVQ, which satisﬁes both the desire of compression perfor-
mance and the reversibility requirement of the watermarking algorithm for the
indices. This MFCVQ is based on the aforementioned FCVQ [17] but modiﬁed in
its index selection method to satisfy the reversibility but still exhibits higher
compression ability than the ordinary VQ.
4.3.3.1 Encoding
Step 0: Encode the ﬁrst row and the ﬁrst column of original image blocks by full
search in the codebook C.
Step 1: Calculate the distances between ca, cb, cc, cd, and the current bock x,
respectively, as da ¼ kca  xk2
2, db ¼ kcb  xk2
2, dc ¼ kcc  xk2
2, and
dd ¼ kcd  xk2
2; ﬁnd the smallest distance dm ¼ min{da, db, dc, dd}.
Step 2: Compare dm with the preset distance threshold TH; if dm  TH (infor-
mation able to embed), send a ﬂag bit “0” to the code stream, and go to Steps 3
and 4; otherwise, send a ﬂag bit “1” to the code stream, and go to Step 5.
Step 3: Calculate the mean code vector cm ¼ 1/4*(ca þ cb þ cc þ cd).
Step 4: Find the best-matched (with the minimum Euclidean distance) code
vector cmb of cm out of {ca, cb, cc, cd} as the encoded code vectors of the current
block x, and send the 2 bits’ index of cmb (indices of ca, cb, cc, and cd are 00, 01,
10, and 11 respectively) to the code stream, and go to Step 6.
Step 5: Find the best-matched code vector cmb out of the whole codebook C as
the current block x’s encoded code vector, and send its index in C to the code
stream, and go to Step 6.
Step 6: Go to the next image block to be encoded and perform Steps 1 to 6
iteratively and only stop after all image blocks are encoded.
4.3.3.2 Decoding
The decoding process is actually the inverse of the embedding process since the ﬂag
bits can be explicitly used to guide the index selection.
Note in the modiﬁed FCVQ mentioned earlier, when there is high correlation
among adjacent blocks (in the case of dm  TH), we use the closest encoded code
vector cmb to encode the current block x directly, which is different from original
FCVQ’s ﬁnding the code vector cx with the minimum distance from the current
block x because cmb can be known to the decoder without any other knowledge about
the original x except the retrievable ﬂag bit in the code stream, and this provides the
reversibility if we deﬁne cmb as always the original indices.
4.3 Modiﬁed Fast Correlation Vector QuantizationeBased Scheme
215

Now we can go further to the lossless information hiding algorithm mentioned
earlier. The embedding and extracting processes are quite simple: we embed all
watermark bits by modulating the 2-bits indices in the high-correlation case to
cmb or to the best-matched cx out of {ca, cb, cc, cd} while encoding. Speciﬁcally,
for embedding, if the current watermark bit w ¼ 0, we keep the original selected
cmb unchanged; if w ¼ 1, we change cmb or to the best-matched 2-bits index cx.
Note that when the case cmb ¼ cx occurs, we choose the next best-matched code vec-
tor cx0 (scmb) to encode the current block x. For the decoder, ﬁrst, know if all water-
mark bits have been embedded in the high-correlation structured image code vectors
tagged with ﬂag bit “0”, and then check whether all the subsequent indices are cmb
or not; if yes, the embedded watermark bit is “0,” otherwise it is “1.” Then all the
embedded watermark bits can be retrieved without loss. To restore the original
indices, just change all non-cmb indices back to cmb, and then the original
MFCVQ-compressed indices can be perfectly restored. In addition, this lossless in-
formation hiding algorithm with MFCVQ satisﬁes the desired property (3) in
Section 4.1.2.
We test two images sized 512  512 with 256 grayscales: Lena and Boat
(Fig. 4.6), in the simulations, to compare the compression and the lossless informa-
tion hiding performances, including PSNR between the original image and the
reconstructed image without watermark embedded, PNSR between the original im-
age and the reconstructed image with watermark embedded, the compression
bitrates, encoding time of these two cases, and the watermarking capacity. Aside
from these aspects, we also compare several desired properties given in Section
4.1.2. The algorithm testing is based on the basic lossless watermarking algorithm
for VQ indices (BVQ) and the MFCVQ. Besides, the compression performance
of the ordinary VQ and FCVQ is also presented for reference.
FIGURE 4.6
Two test images without vector quantization compression.
216
CHAPTER 4 Lossless Information Hiding in Vector Quantization

The simulation results of VQ compression performance are presented in
Table 4.1, where N is the size of codebooks and TH is the distance threshold
for FCVQ and MFCVQ. All codebooks are trained from the two images them-
selves, and the same 512-sized codebook is used for FCVQ and MFCVQ. From
Table 4.1, although the compression performance of MFCVQ is lower than the
original FCVQ, which is attributed to the suboptimal code vector selection
method traded with hiding reversibility, it still shows preponderance over the
Table 4.1 Compression Performance of Different VQs
Algorithms
Parameter
Boat
Lena
VQ
N ¼ 128
PSNR (dB)
30.067
PSNR (dB)
31.426
Bit rate (bpp)
0.438
Bit rate (bpp)
0.438
Coding time (s)
1.9
Coding time (s)
1.9
N ¼ 256
PSNR (dB)
31.197
PSNR (dB)
32.506
Bit rate (bpp)
0.500
Bit rate (bpp)
0.500
Coding time (s)
3.7
Coding time (s)
3.8
N ¼ 512
PSNR (dB)
32.344
PSNR (dB)
33.664
Bit rate (bpp)
0.563
Bit rate (bpp)
0.563
Coding time (s)
7.5
Coding time (s)
7.7
FCVQ (N ¼ 512)
TH ¼ 160
PSNR (dB)
32.315
PSNR (dB)
33.632
Bit rate (bpp)
0.400
Bit rate (bpp)
0.409
Coding time (s)
1.6
Coding time (s)
1.7
TH ¼ 320
PSNR (dB)
32.214
PSNR (dB)
33.476
Bit rate (bpp)
0.370
Bit rate (bpp)
0.371
Coding time (s)
1.3
Coding time (s)
1.4
TH ¼ 640
PSNR (dB)
32.004
PSNR (dB)
33.117
Bit rate (bpp)
0.347
Bit rate (bpp)
0.335
Coding time (s)
1.1
Coding time (s)
1.1
MFCVQ
(N ¼ 512)
TH ¼ 320
PSNR (dB)
32.244
PSNR (dB)
33.572
Bit rate (bpp)
0.506
Bit rate (bpp)
0.543
Coding time (s)
2.2
Coding time (s)
2.4
TH ¼ 640
PSNR (dB)
31.981
PSNR (dB)
33.380
Bit rate (bpp)
0.457
Bit rate (bpp)
0.505
Coding time (s)
1.9
Coding time (s)
2.2
TH ¼ 2000
PSNR (dB)
31.009
PSNR (dB)
32.205
Bit rate (bpp)
0.408
Bit rate (bpp)
0.432
Coding time (s)
1.6
Coding time (s)
1.7
PSNR, peak signal-to-noise ratio; VQ, vector quantization.
4.3 Modiﬁed Fast Correlation Vector QuantizationeBased Scheme
217

ordinary VQ in almost every aspect. Another performance is the encoding and
decoding time, MFCVQ shows greater advantage in this aspect than the
ordinary VQ.
The lossless hiding performance is presented in Table 4.2, where the PSNR is
calculated between the original images and the reconstructed images by MFCVQ
with watermark embedded. Note that, MFCVQ selects the best-matched code vector
cmb as a modulation of the watermark “1” out of the neighboring encoded blocks,
which makes the PSNR (compared with the original images) even higher
(0.1e0.5 dB improved in the simulations) than the typical compressing case
(without watermark embedded). This may be a desired virtue for many applications.
Another advantage of MFCVQ is that the code stream obtained by MFCVQ can be
directly processed by the same decoder as the FCVQ, which is desired by compat-
ibility prescribed in Section 4.1.2.
However, the lossless watermarking algorithm with MFCVQ has two prob-
lems. The ﬁrst is related to the separation property in Section 4.1.2: the water-
marking embedding process is inseparable from the encoding process because
the best-matched code vector cmb can only be found with the knowledge of the cur-
rent pixel block x reachable while encoding. However, this deﬁciency can be
easily removed by replacing the cmb (that depends on x) with another neigh-
boring encoded code vector (independent from x) among ca, cb, cc, cd, e.g., the
next closest code vector, except cmb, compared with cm. The encoding quality
degradation by this replacement will not be high considering the fact the highest
distortion has been bounded by the threshold TH. The second problem is related to
the size preservation property: the compression bitrate change caused by the index
modulation, which usually changes the candidate scope for the next image block’s
encoding. Fortunately, this bit rate variance is quite mild, and in the simulations,
below 0.005 bpp.
Table 4.2 Lossless Information Hiding Performance With MFCVQ
Method
Parameter
Boat
Lena
Lossless information
hiding on MFCVQ’s
indices (N ¼ 512)
TH ¼ 320
PSNR (dB)
32.27
PSNR (dB)
33.59
Capacity (bits)
4570
Capacity (bits)
3075
TH ¼ 640
PSNR (dB)
32.13
PSNR (dB)
33.44
Capacity (bits)
6363
Capacity (bits)
4556
TH ¼ 2000
PSNR (dB)
31.53
PSNR (dB)
32.52
Capacity (bits)
8255
Capacity (bits)
7300
MFCVQ, modiﬁed fast correlation vector quantization; PSNR, peak-signal-to-noise ratio; VQ, vector
quantization.
218
CHAPTER 4 Lossless Information Hiding in Vector Quantization

4.4 SIDE MATCH VECTOR QUANTIZATIONeBASED SCHEMES
From Section 4.3, we can see that the hiding capacity of the MFCVQ method is
unstable and low. To improve the hiding capacity, Chang et al. proposed several in-
formation hiding algorithms [4e7] based on SMVQ. We ﬁrst introduce SMVQ in
Section 4.4.1, and then introduce Chang and Wu’s information hiding algorithm
[4] in Section 4.4.2, Chang and Lu’s lossless information hiding algorithm [5] in
Section 4.4.3, and Chang-Tai-Lin’s lossless information hiding scheme [6] in
Section 4.4.4.
4.4.1 SIDE MATCH VECTOR QUANTIZATION
VQ takes advantage of the high degree of correlation between individual pixels
within a block without considering the similarity between neighboring blocks. In
VQ, each block is coded independently and therefore tends to cause visible bound-
aries between blocks. The original SMVQ-based image coding scheme proposed by
Kim [18] is designed to enhance the visual quality of VQ by reducing these visible
boundaries. It employs the previous coded blocks, which are above and on the left-
hand side of the current block, to help predict the current block so that the visible
boundaries can be reduced. The SMVQ encoder ﬁrst uses the master codebook C
to encode the blocks in the ﬁrst column and the blocks in the ﬁrst row. Then all other
image blocks are encoded from left to right row by row using the correlation of
neighboring encoded blocks. Fig. 4.7 shows the SMVQ ﬂowchart. Let x denote
the current processing vector, and let u and l be the codewords of the upper and
left neighboring blocks (Fig. 4.8), respectively. The side match distortion of a code-
word c in C is deﬁned as
smdðcÞ ¼ vdðcÞ þ hdðcÞ
(4.9)
where the vertical and horizontal distortions of c are deﬁned as
vdðcÞ ¼
X
4
i¼1

uð4;iÞ  cð1;iÞ
2
(4.10)
and
hdðcÞ ¼
X
4
i¼1

lði;4Þ  cði;1Þ
2
(4.11)
where x(i,j) denotes the value of the jth pixel of the ith row in an image block x.
In SMVQ, a main codebook is required to encode the blocks in the ﬁrst row and
ﬁrst column, and a state codebook is required to encode the rest of the blocks. The
state codebook CS is a subset of the main codebook. SMVQ is based on the concept
that the pixels of the top row in the current block are correlated closely with those of
the bottom row in the upper block, and the pixels of the ﬁrst column in the current
block are correlated closely with those of the right column in the left block. The gray
4.4 Side Match Vector QuantizationeBased Schemes
219

areas in Fig. 4.8 represent the upper and left blocks. These gray regions are used to
choose codewords from the main codebook to create a state codebook.
The blocks in the ﬁrst row and ﬁrst column are encoded using VQ. During this
process, the main codebook is fully searched to ﬁnd the best representative code-
word to replace the original blocks. The blocks of the ﬁrst row and ﬁrst column
must be encoded accurately since these blocks are used to predict future blocks.
If an error occurs in this encoding step, it propagates throughout the entire image.
Encode the 1st row and
the 1st column using VQ
Use upper and left blocks
to predict the current block
Yes
More blocks ?
No
End
FIGURE 4.7
Flowchart of side match vector quantization (VQ).
u
l
x11
Current Block x
x12
x13
x14
x24
x34
x44
x23
x33
x43
x22
x32
x42
x21
x31
x41
l14
u41
u42
u43
u44
l24
l34
l44
FIGURE 4.8
Neighboring blocks of the current block in side match vector quantization.
220
CHAPTER 4 Lossless Information Hiding in Vector Quantization

In the state codebook generation procedure, the upper and left blocks previously
encoded are used to generate the state codebook for the current block. The state
codebook consists of Ns codewords, which are selected from the main codebook
having the least side match distortion when compared with the side areas. The cur-
rent block is encoded using VQ compression scheme with the state codebook of size
Ns. This process is repeated for each block of the original image until all the blocks
are encoded. This approach requires that only the codewords in the state codebook
be searched, rather than all codewords in the main codebook, and the size of the state
codebook is much smaller than that of the main codebook. Hence, the advantage of
SMVQ is its signiﬁcant saving in the number of bits required to encode blocks.
To decode a block, the previously encoded upper and left blocks are used to pre-
dict the state codebook with the least side match distortion for the current block. The
generated state codebook is then searched to ﬁnd the corresponding codeword to
approximate the current block. Thus, SMVQ saves signiﬁcant bits per pixel (bpp)
without a signiﬁcant reduction in the PSNR.
4.4.2 CHANG AND WU’S SCHEME
In 2005, Chang and Wu [4] proposed a steganographic scheme to hide secret data
using SMVQ and VQ. Note that it is not a lossless information hiding scheme; how-
ever, it is the ﬁrst information hiding algorithm using SMVQ, thus we brieﬂy intro-
duce it here. In their scheme, a random seed is generated and used to generate two
mapping tables, listSMVQ and listVQ, that contain half 0’s and half 1’s. The mapping
table listSMVQ is with the same size as the state codebook CS and the mapping table
listVQ is with the same sizes as the main codebook C. Thereafter, VQ is used to
encode the ﬁrst row and the ﬁrst column of the cover image. For the residual blocks,
the corresponding state codebooks are created using SMVQ. The codewords in each
state codebook are sorted in advance according to the similarity between the code-
words and the corresponding blocks.
Because each state codebook is sorted in advance, the codewords are checked
sequentially until the value in the mapping table that corresponds to the index value
of the checked codeword is the same as the secret bit. However, if the Euclidean dis-
tance between the checked codeword and the current block exceeds the given
threshold, VQ rather than SMVQ is used to hide secret data in the block.
The encoding steps using VQ are almost the same as the aforementioned steps.
Since the main codebook is sorted in advance, the codewords are checked sequen-
tially until the value in the mapping table for the index value of the checked code-
word is the same as the secret bit. However, once the Euclidean distance between the
checked codeword and the current block exceeds the given threshold, no secret is
hidden in this block.
Chang and Wu’s scheme does not achieve reversibility. To conquer this weak-
ness, Chang et al. proposed two lossless information hiding schemes for SMVQ-
based compressed images. We discuss them in Sections 4.4.3 and 4.4.4.
4.4 Side Match Vector QuantizationeBased Schemes
221

4.4.3 CHANG AND LU’S SCHEME
The diagram of Chang and Lu’s scheme [5] is shown in Fig. 4.9, consisting of two
phases: the embedding and the extraction phases. The embedding phase explains the
procedure of hiding secret data in the cover image to generate the stego indices,
whereas the extraction phase describes the procedure of extracting the hidden secret
data and recovering the decoded image from the stego indices. These two phases are
described in detail in the following sections.
4.4.3.1 The Embedding Phase
First, Chang and Lu’s scheme encrypts the plaintext, which a sender wants to send to
a receiver, by using a Data Encryption Standard (DES)-like method associated with
the private key to form the secrete data. Next, this scheme divides a cover image into
several nonoverlapping blocks. Let x ¼ {x1, x2, ., xk} be a block of size k, where
xi ˛ [0, 255] and 1  i  k. Let C ¼ {c0, c1, ., cN1} be the codebook that is gener-
ated by the Linde-Buzo-Gray (LBG) algorithm [1], and let the number of codewords
Residual
Block
State Codebook
Codebook
Seed
Block
b
Index
Cover Image
SC0
SC1
(a)
Index
Indicator = 1
Indicator = 0
Message type
State Codebook
Codebook
Recovered 
Image
SC0
SC1
(b)
FIGURE 4.9
The diagram of Chang and Lu’s scheme: (a) embedding phase and (b) extraction phase.
222
CHAPTER 4 Lossless Information Hiding in Vector Quantization

in the codebook be N. If the block is in the ﬁrst row or the ﬁrst column, which is
called seed block, then this scheme matches the closest codeword for the block
from the codebook. The measurement used to estimate the distance between the
block x and the closest codeword ci is
EDðx; ciÞ ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
X
k
p¼1
ðxp  cipÞ2
v
u
u
t
(4.12)
where cip is the pth component of ci and xp is the p-th component of x. The codeword
with the least ED value is the closest codeword of x.
If the block is not the seed block, then the closest codeword is predicated by us-
ing SMVQ, and hide one secret bit b on it. Let u ¼ {u1, u2, ., uk} be the block in the
upper of x, and l ¼ {l1, l2, ., lk} be the block in the left side of x. Chang and Lu’s
scheme uses the neighboring encoded pixels to predict the codeword of x. For
k ¼ 16, as shown in Fig. 4.8, u ¼ {u1, u2, ., u16} ¼ {u(1,1), u(1,2), ., u(4,4)}, l ¼
{l1, l2, ., l16} ¼ {l(1,1), l(1,2), ., l(4,4)}, then seven values x0
1
¼
(u13 þ l4)/2,
x0
2 ¼ u14, x0
3 ¼ u15, x0
4 ¼ u16, x0
5 ¼ l8, x0
9 ¼ l12, x0
13 ¼ l16 are used to ﬁnd the closest
codeword from the codebook. The measurement used to predict the closest code-
word is given as
SEDðx; ciÞ ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
X
k
p˛f1;2;3;4;5;9;13g

x0p  cip
2
v
u
u
t
(4.13)
Then, Chang and Lu’s scheme sorts the codewords according to the SED values
in the ascending order and selects the ﬁrst Ns codewords from the sorted codebook to
generate a state codebook Cs ¼ fsc0; sc1; .; scNs=21g, where sci is the ith coded-
word in Cs and the SED value of sci is smaller than that of sciþ1.
Chang and Lu’s scheme equally divides the state codebook into two parts
Cs0 ¼ fsc0; sc1; .; scNs=21g and Cs1 ¼ fscNs=2; scNsþ1; .; scNs1=2g. Each
part has its own message type, for example, the message type of Cs0 is 0 and that
of Cs1 is 1. Next, they use the original block x to map the nearest codeword scj
from Cs0. If the distance between scj and x is shorter than a predetermined threshold
T, then x can be used to hide the secret bit. If the hidden secret bit matches with the
message type of Cs0, then Chang and Lu’s scheme uses scj to represent x. Otherwise,
the codeword is used at the corresponding location of Cs1 to represent x.
In short, for the block x of size k ¼ 16 to hide the secret bit b, the embedding
process can be depicted as follows:
Step 1: Let x0
1 ¼ (u13 þ l4)/2, x0
2 ¼ u14, x0
3 ¼ u15, x0
4 ¼ u16, x0
5 ¼ l8, x0
9 ¼ l12,
x0
13 ¼ l16 be the neighboring pixels of x. Compute the distance between the
neighboring pixels and the corresponding pixels of each codeword by using Eq.
(4.13).
4.4 Side Match Vector QuantizationeBased Schemes
223

Step 2: Sort the codewords according to the distance value of each in the
ascending order. Select the ﬁrst Ns codewords to generate a state codebook
Cs ¼

sc0; sc1; .; scNs1

.
Step 3: Divide the state codebook into two parts Cs0 ¼ fsc0; sc1; .; scNs=21g
and Cs1 ¼ fscNs=2; scNsþ1; .; scNs1g, where each part has Ns/2 codewords,
and give each part a distinct message type.
Step 4: Generate a random bit by using a random-number generator, which is
only known by the sender and the receiver, and let it be the message type of Cs0.
The message type of Cs1 is the inverse value of the random bit.
Step 5: Find out the nearest codeword scj of x from Cs0 by using Eq. (4.12),
where scj is the jth codeword of the state codebook.
Step 6: If the distance between scj and x using Eq. (4.12) is shorter than the
threshold T, then hide b in the compressed code of x. If the message type of Cs0
is matched with b, then Chang and Lu’s scheme uses an indicator “1,” and the
index of scj in the binary format to represent the stego block of x. If not, then an
indicator “1” is used with the index of scjþNs=2 in the binary format to represent
the stego block of x.
Step 7: If the distance between scj and x using Eq. (4.12) is larger than the
threshold T, then x is coded by VQ and the indicator of x is “0.”
Now we give a concrete example to explain the hiding process. Assuming that we
have a gray-level image of size 12  8. First, the scheme divides the image into
3  2 blocks. The size of the block used in this example is 4  4. Next, for the
blocks in the ﬁrst row and the ﬁrst column, we ﬁnd out the closest codewords
from the codebook by using Eq. (4.12) and decode the blocks by using the closest
codewords. Fig. 4.10 shows the example image where the blocks in the ﬁrst row
the ﬁrst column have been decoded. Assume the threshold T ¼ 200.
The ﬁfth block is not the seed block. Thus, the scheme uses the neighboring
encoded
pixels
x0
1 ¼ (90 þ 72)/2 ¼ 81,
x0
2 ¼ u14 ¼ 15,
x0
3 ¼ u15 ¼ 53,
x0
4 ¼ u16 ¼ 34, x0
5 ¼ l8 ¼ 51 x0
9 ¼ l12 ¼ 91, x0
13 ¼ l16 ¼ 49 to predict the codeword
FIGURE 4.10
An example image of size 12  8.
224
CHAPTER 4 Lossless Information Hiding in Vector Quantization

and generate the state codebook using SMVQ. Let Ns here be 8. The state codebook
of the ﬁfth block is shown in Table 4.3. Then, the scheme matches the closest code-
word from codeword numbered 0 to the codeword numbered 3 in the state codebook
The distances between the ﬁfth block and sc0, sc1, sc2, and sc3 are 55.34, 125.29,
207.87, and 148.05, respectively. Hence, the nearest codeword of the ﬁfth block is
sc0 and the distance is 55.34. Let the ﬁrst random bit generated by random-
number generator be 1. That is to say, the message type of Cs0 ¼ {sc0, sc1, sc2,
sc3} is 1 and that of Cs1 ¼ {sc4, sc5, sc6, sc7} is 0. We assume that the hidden secret
bit is 1, which is the same as the message type of Cs0. Therefore, the compressed
code of the ﬁfth block is composed by an indicator “1” followed with “000,” which
is the index of sc0 in the binary format. Because the size of the state codebook is 8,
Ns ¼ 8, we use 3 bits to represent the index, since log2Ns ¼ log28 ¼ 3.
For the sixth block, the sorted state codebook is shown in Table 4.4. The dis-
tances between the sixth block and sc0, sc1, sc2, and sc3 are 200.3, 149.5, 182.2,
and 215.3, respectively, thus the nearest codeword is sc1. Let the second random
bit be 0 such that the message type of Cs0 is 0 and that of Cs1 is 1. We assume
that the hidden secret bit is 1, which is not the same as the message type of Cs0.
Table 4.3 The State Codebook of the Fifth Block in Fig. 4.10
Codeword No.
Codeword Value
SED
sc0
(81,6,43,28,60,86,66,19,27,88,57,40,19,18,10,6)
72.76
sc1
(78,42,14,63,54,66,54,39,27,54,68,98,40,70,28,4)
85.36
sc2
(9,62,69,21,29,4,11,68,68,24,80,74,79,79,49,56)
98.65
sc3
(99,78,28,14,77,58,24,60,29,87,24,77,35,73,38,48)
100.17
sc4
(56,20,61,72,6,33,77,51,22,33,5,91,83,1,99,49)
100.50
sc5
(54,88,49,26,17,2,5,19,16,51,52,50,90,15,53,34)
120.83
sc6
(11,63,91,90,4,50,23,62,58,53,34,85,53,59,94,12)
122.87
sc7
(2,88,0,69,52,19,25,79,88,96,73,35,37,61,73,6)
125.53
Table 4.4 The State Codebook of the Sixth Block in Fig. 4.10
Codeword No.
Codeword Value
SED
sc0
(9,62,69,21,29,4,11,68,68,24,80,74,79,79,49,56)
83.71
sc1
(11,63,91,90,4,50,23,62,58,53,34,85,53,59,94,12)
85.36
sc2
(54,88,49,26,17,2,5,19,16,51,52,50,90,15,53,34)
98.65
sc3
(81,6,43,28,60,86,66,19,27,88,57,40,19,18,10,6)
100.17
sc4
(56,20,61,72,6,33,77,51,22,33,5,91,83,1,99,49)
100.50
sc5
(78,42,14,63,54,66,54,39,27,54,68,98,40,70,28,4)
120.83
sc6
(2,88,0,69,52,19,25,79,88,96,73,35,37,61,73,6)
122.87
sc7
(99,78,28,14,77,58,24,60,29,87,24,77,35,73,38,48)
125.53
4.4 Side Match Vector QuantizationeBased Schemes
225

Thus, the compressed code of the sixth block contains an indicator “1” followed with
“101,”,
which
is
the
index
of
sc5
in
the
binary
format,
where
scjþNs=2 ¼ sc1þ8=2 ¼ sc5.
4.4.3.2 The Extraction Phase
In this subsection, we introduce Chang and Lu’s extraction process, which is used to
extract the hidden information and recover the original indices of VQ-compressed
image.
Step 1: If the indicator is “0,” then the block is encoded by the traditional VQ.
The following bitstream with length log2N is represented in decimal format to
form an index i. Then, Chang and Lu’s scheme uses the ith codeword ci of the
codebook to recover the block. After that, other blocks are continued to be
decoded.
Step 2: If the indicator is “1,” then the block is encoded by SMVQ, and the
following bitstream with length log2Ns is represented in decimal format to form
an index v.
Step 3: Use seven decoded pixels x0
1 ¼ ðu13 þ l4Þ=2, x0
2 ¼ u14, x0
3 ¼ u15,
x0
4 ¼ u16, x0
5 ¼ l8, x0
9 ¼ l12, x0
13 ¼ l16 to match the index of the block from
the codebook, where up is the pth recovered pixel in the upper block, and lp is
the pth recovered pixel in the left block.
Step 4: Measure the distances between the seventh decoded pixel and the cor-
responding pixel of each codeword in the codebook using Eq. (4.13), and sort
the codewords according to their distances in the ascending order.
Step 5: The ﬁrst Ns codewords are selected to generate a state codebook,
Cs ¼

sc0; sc1; .; scNs1

, and the state codebook is divided into two parts
Cs0 ¼ fsc0; sc1; .; scNs=21g and Cs1 ¼ fscNs=2; scNsþ1; .; scNs1g.
Step 6: Generate a random bit as the message type of Cs0 by using the random-
number generator.
Step 7: If v is smaller than Ns/2 and the random bit is 0, then the hidden bit in the
block is “0.” Recover the block using the vth codeword of Cs0.
Step 8: If v is smaller than Ns/2 and the random bit is 1, then the hidden bit in the
block is “1.” Recover the block using the vth codeword of Cs0.
Step 9: If v is greater than Ns/2 and the random bit is 0, then the hidden bit in the
block is “1.” Recover the block using the (v  Ns/2)th codeword of Cs1.
Step 10: If v is greater than Ns/2 and the random bit is 1, then the hidden bit in the
block is “0.” Recover the block using the (v  Ns/2)th codeword of Cs1.
Step 11: Continue to decode the other blocks.
4.4.3.3 Experimental Results
As shown in Fig. 4.11, 6 gray-level images of the same size 512  512, Airplane,
Baboon, Boat, Lena, Pepper, and Sailboat, were used as the host images to evaluate
the performance of Chang and Lu’s scheme. The sizes of the codebooks generated
226
CHAPTER 4 Lossless Information Hiding in Vector Quantization

by the LBG algorithm are 256, 512 and 1024. The system used the random function
to generate pseudo random numbers and a secret data.
The PSNR, the hiding capacity jHj, and bpp are used to measure the stego image
quality, the total number of the secret bits hidden in the stego image, and the
compression rate of the stego image, respectively. The image with smaller bpp
means that the compression performance of Chang and Lu’s scheme on the image
is higher. To determine the proper T for hiding information on the host image, Chang
and Lu tested the host images with different T’s. The experimental results are shown
in Figs. 4.12e4.14. Chang and Lu’s scheme with T ¼ 100 and Ns ¼ 16 obviously has
the best performance for Lena, where 14,703 bits are hidden with image quality of
24.05 dB and compression rate of 0.34 bpp. As to Baboon, Chang and Lu’s scheme
is able to hide 11,513 bits with image quality of 21.97 dB and compression rate of
0.39 bpp. The stego image after the extraction phase can obtain the original indices
to recover the image. The image quality of the recovered image is the same as that of
the image after SMVQ compression. For example, the PSNR of the stego Lena with
T ¼ 50 is 26.43 dB, and the PSNR of the recovered Lena is 30.99 dB, which is just
the same as that of Lena after SMVQ compression. The stego images of Lena and
Baboon are shown in Fig. 4.15a and c, and the recovered images of Lena and Baboon
are shown in Fig. 4.15b and d, respectively.
Next, Chang and Lu tested the host images with different Ns to measure the
proper size of the state codebook. The results are shown in Table 4.5. From the re-
sults obtained, Chang and Lu’s scheme with Ns ¼ 16 and T ¼ 100 apparently has the
FIGURE 4.11
Six test images.
4.4 Side Match Vector QuantizationeBased Schemes
227

best performance. For example, although the system will decrease the image quality
of Lena from 24.94 dB to 23.97 dB, jHj can be increased from 14,348 to 14,654 bits.
We can see that the hiding capacities of most images decrease when Ns increases
from 64 to 128. That is because of the derailment phenomenon. In the embedding
phase, if a secret bit b is not matched with the message type of the state codebook,
then Chang and Lu’s scheme encodes the block by using the index of the alternative
codeword scjþNs=2 instead of the index of the closest codeword scj. However, the dis-
tance between scjþNs=2 and the block x is larger than that between scj and the block x,
especially for a state codebook with greater value of Ns. In this case, if the scheme
Boats
20
22
24
PSNR (dB)
26
28
30
32
Baboon
Jet_(F16)
Image Name
Lena
Pepper
SailBoat
SMVQ T = 50
SMVQ T = 100
Chang&LuT = 100
Chang&Lu T = 80
Chang&LuT = 150
Chang&Lu T = 50
VQ
FIGURE 4.12
The image quality of Chang and Lu’s scheme for the six host images. PSNR, peak signal-
to-noise ratio; SMVQ, side match vector quantization; VQ, vector quantization.
0.50
Chang&LuT = 100
SMVQ T = 100
Chang&LuT = 80
SMVQ T = 50
VQ
Chang&LuT= 50
Chang&LuT= 150
0.45
0.40
0.35
0.30
Boats
Baboon
Jet_(F16)
Image Name
Compression rate (bpp)
Lena
Pepper
SailBoat
FIGURE 4.13
The compression rate of Chang and Lu’s scheme for the six host images.
228
CHAPTER 4 Lossless Information Hiding in Vector Quantization

0
2,000
4,000
6,000
8,000
10,000
12,000
14,000
16,000
Boats
Capacity (bits)
Baboon
Jet_(F16)
Image Name
Lena
Pepper
SailBoat
Chang&LuT = 100
Chang&LuT = 80
Chang&LuT = 150
Chang&LuT = 50
FIGURE 4.14
The hiding capacity of Chang and Lu’s scheme for the six host images.
(a)
(b)
(c)
(d)
FIGURE 4.15
The stego images and recovered images of Lena and Baboon: (a) stego image Lena,
(b) recovered image Lena, (c) stego image Baboon, and (d) recovered image Baboon.
4.4 Side Match Vector QuantizationeBased Schemes
229

continually uses the alternative codeword to predicate the closest codeword for the
following blocks, more and more distortion will be made. Some valuable blocks,
which originally can be used to hide a secret data, may become valueless. To avoid
this problem, Chang and Lu set Ns ¼ 16 in the following experiments.
The codebook size is an important factor that affects the efﬁciency and the effect
of a compression algorithm. The following experiment examines whether the code-
book size inﬂuences the performance of Chang and Lu’s scheme. Fig. 4.16 shows the
Table 4.5 The Performance of the Chang and Lu’s Scheme on Different
Images With Different Ns’s when T ¼ 100
File Name
Ns
PSNR
jHj
bpp
Baboon
8
22.25
10,846
0.31
16
21.92
11,500
0.34
32
21.42
12,112
0.38
64
20.43
12,580
0.42
128
18.81
12,936
0.46
Boats
8
23.84
13,642
0.25
16
23.17
14,075
0.29
32
21.69
14,143
0.35
64
20.10
14,272
0.40
128
17.75
14,149
0.45
F16
8
24.46
13,945
0.24
16
23.49
14,295
0.29
32
21.47
14,194
0.35
64
19.34
13,933
0.40
128
17.14
13,772
0.46
Lena
8
24.94
14,348
0.23
16
23.97
14,654
0.28
32
22.73
14,851
0.34
64
20.75
14,839
0.39
128
18.54
14,767
0.45
Pepper
8
24.34
14,116
0.24
16
23.51
14,485
0.29
32
21.91
14,626
0.34
64
20.07
14,599
0.40
128
17.88
14,533
0.45
Sailboat
8
23.40
13,503
0.25
16
22.68
13,984
0.30
32
21.38
14,191
0.35
64
19.67
14,159
0.40
128
17.48
14,039
0.46
PSNR, peak signal-to-noise ratio.
230
CHAPTER 4 Lossless Information Hiding in Vector Quantization

performance of Chang and Lu’s scheme with different N. A larger codebook can
obtain higher image quality. That is to say, N is a factor to judge the image quality,
but it is not a factor to inﬂuence the capacity.
The execution times of VQ, SMVQ, and Chang and Lu’s scheme are shown in
Table 4.6. Because Chang and Lu’s scheme is based on SMVQ, the execution
time of Chang and Lu’s scheme depends on the encoding and the extraction pro-
cesses of SMVQ. According to the experimental results shown in Table 4.6, the hid-
ing process of Chang and Lu’s scheme only increases a few of the encoding and
extraction times of SMVQ.
Now, we compare Chang and Lu’s scheme with Chang and Wu’s scheme. The
comparisons are shown in Table 4.7. The thresholds used in Chang and Wu’s scheme
are THSMVQ ¼ 30 and THVQ ¼ 50. For example, when T ¼ 30, the PSNR, hiding ca-
pacity, and compression rate of Chang and Lu’s scheme for Lena are 27.64 dB,
10,246 bits, and 0.41 bpp, respectively, and the PSNR of the recovered image of
Lena is 31.30 dB. On the contrary, those of Chang and Wu’s scheme are
256
512
1024
Baboon
PSNR (dB)
Boats
Jet_(F16)
Image Name
Lena
Pepper
SailBoat
20.00
21.00
22.00
23.00
24.00
25.00
26.00
FIGURE 4.16
The image quality of Chang and Lu’s scheme with different N’s. PSNR, peak signal-to-
noise ratio.
Table 4.6 The Execution Time Comparison Among VQ, Side Match VQ, and
Chang and Lu’s Scheme on Lena of Size 512  512 With Codebook Size
N ¼ 256, T ¼ 50 and Ns ¼ 16
Compare
Methods
VQ
SMVQ
Chang and Lu’s Scheme
Time (s)
12.391
14.281
14.578
PSNR (dB)
31.348
30.99
26.32
PSNR, peak signal-to-noise ratio; SMVQ, side match vector quantization; VQ, vector quantization.
4.4 Side Match Vector QuantizationeBased Schemes
231

29.25 dB, 13,487 bits, and 0.47 bpp, respectively. Although the PNSR of the stego
images using Chang and Lu’s scheme is lower than that of the stego images using
Chang and Wu’s schemes, Chang and Lu’s scheme can recover the stego image to
reconstruct the SMVQ-compressed image. Therefore, when given the same hiding
capacity, the PSNRs of the recovered images using Chang and Lu’s scheme are
higher than those of the stego images of Chang and Wu’s scheme. In addition, the
compression performance of Chang and Lu’s scheme is better than that of Chang
and Wu’s scheme. The comparison results demonstrate that Chang and Lu’s scheme
indeed outperforms Chang and Wu’s scheme.
From these data, we can see that Chang and Lu’s scheme is a lossless index-
domain information hiding scheme based on SMVQ for gray-level images. This
scheme not only conceals information on the indices of SMVQ-compressed image
with low image distortion but also recovers the original indices to reconstruct the
SMVQ-compressed image from the hidden indices without any loss. As proved
by the experiments, Chang and Lu’s scheme obviously outperforms Chang and
Wu’s scheme. In terms of security problem, the scheme sets the message type of
Cs0 by using a random-number generator in the embedding phase to ensure the se-
curity of the hidden secret data. Hence, illegal people cannot correctly extract the
secret data, except for those who know the random-number generator. In addition,
the secret data are encrypted by using a DES-like method. Only legal people who
own the private key have the ability to decrypt the original plaintext from the secret
data.
4.4.4 CHANGeTAIeLIN’S SCHEME
Both Chang and Wu’s scheme and Chang and Lu’s scheme require additional in-
formation to indicate that the current block is encoded using VQ or SMVQ, and
the additional indicators will yield a low compression rate. To conquer this weak-
ness, Chang et al. [6] proposed a lossless information hiding scheme (we call it
ChangeTaieLin’s scheme) for SMVQ-based compressed images that do not
Table 4.7 The Comparisons Between Chang and Wu’s and Chang and Lu’s
Scheme on Lena With N ¼ 256 and Ns ¼ 16
Method
Chang and Wu’s
Scheme
Chang and Lu’s Scheme
Threshold
THSMVQ [ 30 and
THVQ [ 50
T [ 30
T [ 50
T [ 80
T
[ 100
T
[ 150
PSNRstego
29.25
27.64
26.43
24.85
24.05
24.03
PSNRrecovered
e
31.30
30.99
30.15
29.46
27.92
jHj
13.487
10.246
12.404
14.075
14.703
14.657
bpp
0.47
0.41
0.37
0.35
0.34
0.34
PSNR, peak signal-to-noise ratio.
232
CHAPTER 4 Lossless Information Hiding in Vector Quantization

require the use of additional indicators. To ensure that the original compression
codes can be recovered directly during the extracting phase and stored for later
use, ChangeTaieLin’s scheme modiﬁed the codeword selection strategy of
SMVQ and developed an information hiding scheme with the property of revers-
ibility. To achieve this goal, ChangeTaieLin’s scheme was broken into three
phases: the preprocessing phase, the hiding phase, and the extracting and
reversing phase. These phases are described in greater detail in the following
subsections.
4.4.4.1 Preprocessing Phase
Secret data must be preprocessed for security reasons. Encrypting the hidden data
prevents them from being illegally accessed or unscrambled. Some existing encryp-
tion techniques, such as DES and RSA others can be used to encrypt hidden data.
Secret data also can be compressed in advance using lossless compression tech-
niques to reduce the amount of hidden data and increase the visual quality of
stego-image, and thus deceive potential grabbers.
After preprocessing in ChangeTaieLin’s scheme, the cover image is encoded
using SMVQ and the SMVQ-compressed image is created. The preprocessed secret
data are then hidden in the SMVQ-compressed image using ChangeTaieLin’s
scheme. The stego image is thus generated, ready for transmission to a receiver.
Receivers can extract the secret data from the stego image using Chang TaieLin’s
extracting and reversing scheme. In addition, receivers can restore the original
SMVQecompressed codes completely. The reconstructed SMVQ-compressed
codes can be stored directly to save storage space. The hiding, extracting, and
reversing phases are described in detail in the following subsections.
4.4.4.2 The Hiding Phase
Fig. 4.17 shows the ﬂowchart of ChangeTaieLin’s hiding procedure. To better
explain this phase, they deﬁned the symbols to be used in hiding phase as follows:
the main codebook C ¼ {c0, c1, ., cNL1}, the SMVQ-compressed cover image I,
the subindices D ¼ {d0, d1, ., dr}, and the secret data B ¼ {b0, b1, ., br}, where
bi ˛ {0, 1} and 0  i  r. The hiding phase consists of the following steps.
Step 1: The SMVQ-compressed cover image I is divided into nonoverlapping
blocks. Because the blocks in the ﬁrst row and ﬁrst column are encoded by VQ,
the secret data B are hidden in the residual blocks.
Step 2: For each residual block, the upper and left encoded blocks in I are used to
generate the state codebook Cs ¼

sc0; sc1; .; scNs1

, where sci is the ith
codeword and 0  i  Ns  1. The subindex di is used to ﬁnd the corresponding
codeword sca from the state codebook Cs.
Step 3: If the secret bit bi is equal to 0, then the codeword sca becomes the content
of the stego image.
Step 4: If the secret bit bi is equal to 1, then we search the codeword scb from the
state codebook Cs so that the codeword scb is the closest to the codeword sca.
4.4 Side Match Vector QuantizationeBased Schemes
233

The approximate codeword c* becomes the content of the stego image and is
deﬁned as
c ¼
2sca þ scb
3

(4.14)
where PvR stands for the operation of obtaining a different but closest vector with
integer components to v.
Step 5: Steps 2e4 are repeated until the whole stego image is generated.
In ChangeTaieLin’s lossless information hiding scheme, the modiﬁed SMVQ
compression codes are converted into a stego image. The stego image must be trans-
mitted without extra messages being required to achieve reversibility.
4.4.4.3 Extracting and Reversing Phases
Once the stego image is received, the receiver can extract the secret data without
having to refer to the original cover image. The steps for extracting and reversing
follow.
Step 1: The stego image is divided into nonoverlapping blocks. The ﬁrst row and
ﬁrst column blocks are encoded using VQ and the indexes are generated.
Step 2: For each residual block, the previously reconstructed upper and left
blocks are used to generate a state codebook Cs ¼

sc0; sc1; .scNs1

, where
scj is the jth codeword and 0  j  Ns  1. The codeword sca is selected from
FIGURE 4.17
Flowchart showing the steps in the hiding phase. SMVQ, side match vector quantization;
VQ, vector quantization.
234
CHAPTER 4 Lossless Information Hiding in Vector Quantization

the state codebook Cs such that the Euclidean distance between the current
block x and the codeword sca is the shortest.
Step 3: If the Euclidean distance ED(x,sca) is equal to 0, then the secret bit
bi ¼ 0. The index a of the codeword sca is output to restore the original state.
Step 4: If the Euclidean distance ED(x,sca) does not equal 0, then the secret bit
bi ¼ 1. The index a of the codeword sca is output to restore the original state.
Step 5: Steps 2e4 are repeated until all the secret data are extracted and all the
original indices are generated.
After all ﬁve steps in the extracting and reversing phases have been performed,
the secret data can be accurately extracted and the output indexes should equal the
original SMVQ-compressed codes. The reconstructed compressed codes can now be
stored directly to save storage space and can be reused repeatedly for a variety of
applications.
4.4.4.4 Experimental Results
In this subsection, we test the effectiveness and feasibility of ChangeTaieLin’s
scheme. The experiments use ﬁve 512  512 gray-level test images: Lena, F16,
Boat, Peppers, and Baboon. These standard gray-level images are compressed as
the cover images using SMVQ with a main codebook of 256 codewords and a state
codebook of 128 codewords. The secret data are a randomly generated bitstream.
The relative PSNRs for ChangeTaieLin’s SMVQ-compressed cover images
(without hidden data) are shown in Table 4.8.
Hiding the secret data in the compressed information certainly creates larger dis-
tortions in stego images. However, ChangeTaieLin’s lossless information hiding
scheme shows its ability to hide the secret data in a low bit rate (0.438 bpp) com-
pressed cover image that achieves a very high hiding capacity and keeps the
Table 4.8 PSNRs for SMVQ-Compressed Cover Image With/Without Hidden
Data
Images
Bit Rate 0.438 bpp
PSNR (dB)
Lena
With hidden data
30.7746
Without hidden data
31.0487
F16
With hidden data
29.9363
Without hidden data
30.2280
Boat
With hidden data
28.7849
Without hidden data
29.0712
Peppers
With hidden data
29.0675
Without hidden data
30.1798
Baboon
With hidden data
22.6614
Without hidden data
22.8004
PSNR, peak signal-to-noise ratio; SMVQ, side match vector quantization.
4.4 Side Match Vector QuantizationeBased Schemes
235

distortion low. Fig. 4.18 illustrates the hiding results using 16K bits of secret data. As
Fig. 4.18 shows, ChangeTaieLin’s scheme keeps the hiding distortion low and
achieves very high visual quality. Table 4.8 shows the PSNRs with and without hid-
den data at the same bit rate (0.438 bpp) for various images. This table also shows
that the average PSNR of the ﬁve stego images is about 29 dB. In the best case, the
PSNR is still 30.7746, which is close to that of the SMVQ-compressed cover images.
Table 4.9 gives additional hiding results for the Lena image at a range of sizes for
the main codebook and the state codebook. The average PSNR of Lena is
29.0686 dB, which is quite close to that of SMVQ-compressed Lena without the se-
cret data embedded but with the same compression rate and a main codebook of 512
codewords. All this shows that ChangeTaieLin’s scheme guarantees not only that
(a)
(b)
FIGURE 4.18
Compressed and stego Lena images. (a) Original compressed image (PSNR:
31.0487 dB). (b) Stego image (PSNR: 30.7746 dB). PSNR, peak signal-to-noise ratio.
Table 4.9 Hiding Results of Lena for Various Main Codebook Sizes and State
Codebook Sizes
State Codebook Size
Main Codebook Size
128
256
512
PSNR
bpp
PSNR
bpp
PSNR
bpp
16
26.37
0.252
26.54
0.253
25.73
0.254
32
27.92
0.314
28.42
0.315
27.81
0.316
64
28.67
0.375
29.85
0.377
29.52
0.377
128
30.77
0.438
31.06
0.439
256
31.21
0.501
PSNR, peak signal-to-noise ratio.
236
CHAPTER 4 Lossless Information Hiding in Vector Quantization

the receiver can accurately extract the hidden secret data but also that the SMVQ-
compressed codes can be recovered and reused after the secret data are extracted.
Table 4.10 compares ChangeTaieLin’s scheme and Chang and Wu’s scheme by
size of secret data, visual quality, and compression rate. In Chang and Wu’s scheme,
THSMVQ ¼ 30 and THVQ ¼ 50 and a state codebook of size 16 is used to maintain a
lower bit rate. The main codebook with a size of 256 is adopted in all schemes for
this comparison. As the table shows, ChangeTaieLin’s hiding capacity is larger and
the visual quality is still better than Chang and Wu’s scheme. In addition, Change
TaieLin’s scheme can preserve the high compression rate because additional indi-
cators are not needed. Thus, the compression rate of ChangeTai-Lin’s scheme is su-
perior to that of Chang and Wu’s scheme. Most important, ChangeTaieLin’s
scheme maintains the high hiding capacity and compression rate while achieving
reversibility. This superior performance enables the receiver to use the reconstructed
compression codes as cover media, hide secret data, and send back the SMVQ stego
image to make communication between parties more efﬁcient.
From this discussion, we can see that hiding data in SMVQ-compressed codes
originally caused a large distortion in stego images because SMVQ is a low-
bitrate compression scheme. To maintain the advantages of SMVQ and make sure
the original compression indexes can be successfully reconstructed after secret
data are extracted, ChangeTaieLin’s scheme hides the secret data in the com-
pressed cover image and achieves the property of reversibility. The procedures for
hiding and extracting and reversing are straightforward. Being lossless, the original
compressed codes can be completely reconstructed after hidden secret data extrac-
tion, and the original compressed codes can be stored directly and used repeatedly.
In addition, ChangeTaieLin’s scheme can simply hide or extract the secret data and
restore the SMVQ-compressed codes without complex computations. The hidden
secret data can also be extracted from the stego image without referencing the orig-
inal compressed cover image. In terms of secret data size, visual quality, and
compression rate, the performance of ChangeTaieLin’s scheme is superior to
that of Chang and Wu’s hiding scheme.
Table 4.10 Comparisons Between ChangeTaieLin’s Scheme and Chang
and Wu’s Scheme
Images
Chang and Wu’s Scheme
Chang-Tai-Lin’s Scheme
Payload
(bits)
PSNR
(dB)
Bit Rate
(bpp)
Payload
(bits)
PSNR
(dB)
Bit Rate
(bpp)
Lena
13,487
29.25
0.47
16,129
30.78
0.44
F16
13,914
29.15
0.45
16,129
29.94
0.44
Boat
13,246
28.12
0.46
16,129
28.79
0.44
Peppers
13,984
29.07
0.45
16,129
30.18
0.44
Baboon
8794
22.43
0.61
16,129
22.66
0.44
PSNR, peak signal-to-noise ratio.
4.4 Side Match Vector QuantizationeBased Schemes
237

However, the main drawback of SMVQ-based hiding methods is that the PSNR
value of the stego image is much less than that of the original VQ-compressed im-
age. Thus, improving the stego image quality while maintaining high hiding capac-
ity is the main goal of VQ-based lossless information hiding. Next, we introduce
VQ-index-codingebased schemes, which can achieve this goal.
4.5 VECTOR QUANTIZATIONeINDEX CODINGeBASED
SCHEMES
Achieving low image distortion (i.e., it reduces the suspicion of adversaries), high
data embedding capacity, reversibility, and efﬁciency are desired by most informa-
tion hiding system designers. Since no method is capable of achieving all these
goals, a class of information hiding schemes is needed to span the range of possible
applications. With the purpose of improving the visual quality of reconstructed im-
ages and achieving high embedding capacity and fast execution speed at the cost of a
little higher bit rate, Chang et al., Wang et al., and Lu et al. propose a kind of lossless
information embedding schemes for the steganographic application (i.e., secret
communications) by using index coding for VQ-compressed images. These methods
embed secrets into VQ-compressed indices by using the difference values between
the current index and left or upper neighboring indices. Next, we will introduce
seven typical index codingebased methods in detail.
4.5.1 JOINT NEIGHBORING CODINGeBASED SCHEME
JNC was ﬁrst proposed by Chang et al. [9]. In their article, as a lossless coding al-
gorithm, JNC is used to encode VQ indices and hide secret data during the encoding
process. Compared with the traditional method to transform each VQ index directly
into the binary format with the preset number of bits, JNC of the VQ index table efﬁ-
ciently takes advantage of the correlation between the adjacent indices. In the JNC
scheme, the VQ-compressed indices located in the ﬁrst row and the ﬁrst column of
the index table P (as shown in Fig. 4.19) are kept unchanged during the data
A
D
E
B
C
125
128
66
95
123
Encoder
The index table
The sorted codebook
FIGURE 4.19
The generation process of the index table.
238
CHAPTER 4 Lossless Information Hiding in Vector Quantization

embedding process. This means that there is no data embedding in this area (called
the seed area). Embedding the secret data into the index table P (i.e., into VQ
indices) is started from the VQ-compressed index located at the second row and
the second column of the index table P.
For the security purpose, the secret data B is encrypted before embedding by us-
ing a pseudo random number generator with a seed z, which is known by the sender
and the receiver only, to generate a bitstream U. Next, the new bitstream Z is created
by Z ¼ B4U, where 4 is the exclusive OR operator. Then, Z is embedded into the
index table P. The detailed embedding process of the JNC scheme can be repre-
sented as follows.
4.5.1.1 The Embedding Process
Given an A  B-sized cover image I and the N-sized codebook C containing N k-
dimensional codewords ci’s, where ci ¼ (ci1, ci2, ., cik) and i ¼ 0, 1, ., N  1.
First, compute the sum Si of each codeword ci in the codebook C by
Si ¼ ci1 þ ci2 þ . þ cik. Second, sort the codebook C according to Si in ascending
order: S0 < S1 < . < SN1. The purpose of sorting the codebook C in this way is to
make neighboring codewords ci’s in the sorted codebook C close to each other.
Consequently, the difference values d’s, where d means the distance between two
neighboring VQ-compressed indices, are very small. The set of VQ-compressed
indices is called the index table P as shown in Fig. 4.19. For k ¼ 4  4, the index
table P is (A/4)  (B/4)-sized matrix containing VQ-compressed indices pa,b, where
a ¼ 0, 1, ., (A/4)  1 and b ¼ 0, 1, ., (B/4)  1. The secret data are then
embedded by encoding the current VQ-compressed index. One secret bit is
embedded into the current VQ-compressed index at a time during the embedding
process. More speciﬁcally, encoding the current index pa,b is performed by encoding
the difference values d’s between the left neighboring index pa,b1 or the upper
neighboring index pa1,b and the index pa,b as shown in Fig. 4.20. The embedding
strategy is based on two embedding rules as follows.
Rule 1: If the secret bit is 1, then the difference value d between the left
neighboring index pa,b1 and the current VQ-compressed index pa,b is
computed by d ¼ pa,b1  pa,b.
Rule 2: If the secret bit is 0, then the difference value d between the upper
neighboring index pa1,b and the current VQ-compressed index pa,b is
computed by d ¼ pa1,b  pa,b.
The JNC technique is really affected by various amplitudes of the difference
values d’s. The amplitude variation of the difference values d’s depends on the image
content (i.e., smooth images or complex images). The various amplitudes of the dif-
ference values d’s are represented with various number of bits. The d’s absolute
value jdj ranges from 0 to N  1 (i.e. 0  jdj  N  1). Thus, the binary represen-
tation of d needs m bits, where 1  m  Ceil(log2N) and the notation Ceil(x) denotes
the ceiling function returning the smallest integer not less than x. The possible am-
plitudes of d are represented as 2m  1. The dynamic values of m used
4.5 Vector QuantizationeIndex CodingeBased Schemes
239

correspondingly to the dynamic values of d during the embedding process of the
JNC scheme are shown in Table 4.11. Note that d equals 0 is the typical case and
it is considered in detail in Case 3.
For the sake of convenience, the binary representation of d is denoted as
d(2) ¼ g0g1.gm1, where gj ˛ {0, 1} and 0  j  m  1. Two preﬁx bits 00, 01,
10, and 11 used for four different cases of the various amplitudes of d are represented
as follows. Note that, in Cases 1 and 2 (called normal cases), and Case 3(called zero
case), m bits are needed to represent d(2). So the (2 þ m)-bit code is concatenated
with the binary code stream for each case. For example, if 15 < jdj  31 then
5 bits (i.e., m ¼ 5) are needed to represent d(2) and the 7-bit code is concatenated
with the binary codestream.
Case 1: 0 < d  2m1. The current VQ-compressed index pa,b is encoded into
binary form as 11jd(2) or 01jd(2), where j denotes the concatenation operation, to
represent embedding the secret bit 1 or 0, respectively.
Case 2: (2m1)  d < 0. The current VQ-compressed index pa,b is encoded into
binary form as 10jd(2) or 00jd(2) to represent embedding the secret bit 1 or 0,
respectively.
Case 3: d ¼ 0. The current VQ-compressed index pa,b is encoded into binary
form as 11jd(2) or 01jd(2), where d(2) is represented with m digits “0,” to
represent embedding the secret bit 1 or 0, respectively.
Case 4: jdj > 2m  1. The current VQ-compressed index pa,b is encoded into
binary form as 10j00.0j (pa,b)(2), (m digits “0”), or 00j00.0j(pa,b)(2), (m digits
“0”), to represent embedding the secret bit 1 or 0, respectively, where (pa,b)(2) is
pa,b–1
···
···
···
pa–1,b
pa,b
FIGURE 4.20
Left and upper joint neighboring indices pa,b1 and pa1,b.
Table 4.11 m’s Dynamic Values Used Corresponding to the d’s Dynamic
Ranges
M
1
2
3
4
.
m
.
Ceil(log2N)
D
1
3
7
15
.
2m1
.
N1
240
CHAPTER 4 Lossless Information Hiding in Vector Quantization

the binary representation of pa,b, (pa,b)(2) ¼ g0g1.gCeil(log2N)1 (gj ˛ {0, 1},
0  j  Ceil(log2N)1). Note that, in this case, Ceil(log2N) bits are needed to
represent (pa,b)(2). So the (2 þ m þ Ceil(log2N))-bit code is concatenated with
the binary code stream. The embedding process of the JNC scheme is sum-
marized in Table 4.12.
4.5.1.2 The Extracting Process
When the data embedding process is done, the sender sends the binary code stream
to the receiver, the N-sized sorted codebook C, and the seed area to the receiver via a
secure channel. The extracting process used to extract the embedded secret data and
recover the original VQ-compressed indices is represented in the following
description.
Step 1: Read the next (2 þ m) bits into p from the binary code stream.
Step 2: Get the ﬁrst bit of p to be the secret bit.
Step 3: If the last m bits of p are 00.0, (m digits “0”), then
If the second bit of p is 1 (i.e. d = 0), then
If the secret bit is 1, then
The original VQ index is decoded by pa,b=pa,b-1. 
Otherwise
The original VQ index is decoded by pa,b=pa-1,b.
Otherwise, (i.e. |d| > 2m-1)
Read next Ceil(log2N) bits into q(2) from the binary code stream.
Convert q(2) into the decimal value q. 
The original VQ index is decoded by pa,b=q.
Otherwise, (i.e. -(2m-1) d<0 or 0<d 2m-1) 
Assign the last m bits of p to the difference value d(2).
Convert d(2) into the decimal difference value d. 
If the second bit of p is 0 (i.e. -(2m-1) d<0), then d=-d.
If the secret bit is 1, then
The original VQ index is decoded by pa,b= pa,b-1-d. 
Otherwise
The original VQ index is decoded by pa,b= pa-1,b-d. 
Table 4.12 Summary of the Embedding Process
Secret Bit
Case 1
Case 2
Case 3
Case 4
1
11jd(2)
10jd(2)
11j00.0
10j00.0j(pa,b)(2)
0
01jd(2)
00jd(2)
01j00.0
00j00.0j(pa,b)(2)
4.5 Vector QuantizationeIndex CodingeBased Schemes
241

Step 4: Repeat Steps 1e3 until all bits of the binary code stream are read.
The main drawback of JNC-based hiding method is that the bit rate of the stego
image is a bit larger than that of the original VQ-compressed image, which will be
tested in the following subsections.
4.5.2 VECTOR QUANTIZATIONeINDEX RESIDUAL VALUE
CODINGeBASED SCHEME
The main idea of the VQIRVC-based lossless information hiding scheme [10] is to
encode the cover image with an index table and then utilize the relationship between
the neighboring four indices of the current index and their mean values to hide the
secret bit; ﬁnally the index difference is encoded by the proper bitstream to reduce
the bit rate. This algorithm consists of three phases as follows.
4.5.2.1 The Preprocessing Phase
During the preprocessing phase, a sorted VQ codebook is generated to encode the
original cover image as follows:
Step 1: The original cover image is divided into nonoverlapping blocks of size
4  4.
Step 2: A codebook of size N is generated by the well-known LBG algorithm [1]
based on the training set consisting of all blocks of the cover image.
Step 3: For each codeword vector ci, add up the values of its components to
obtain its sum value Si ¼ ci1 þ ci2 þ . þ cik. Sort the codewords in the
codebook in the ascending order of their sum values.
Step 4: Encode each image block with the sorted codebook, obtaining the index
table of the cover image, as shown in Fig. 4.19.
Here, the purpose of using a sorted codebook is to make the VQ indices of adja-
cent blocks as close to each other as possible.
4.5.2.2 The Information Hiding Phase
The secret data are hidden based on the index table obtained in the preprocessing
phase. The indices of the ﬁrst row and the leftmost and rightmost columns of the in-
dex table are selected as the seed area and kept unchanged during the information
hiding process. This means that no data are hidden in these locations. The informa-
tion hiding process is performed from the second to the last row and from the second
to the second last column of the VQ index table. The hiding process consists of the
following steps. The form of the resulting codestreams is shown in Table 4.13, where
(**)1 and (**)2 denote two different 2-bit ﬂag numbers.
Step 1: For each index icur that is not in the seed area, mark its adjacent indices il,
ilu, iu, and iru with 2-bit ﬂag numbers “00,” “01,” “10,” and “11,” respectively, as
shown in Fig. 4.21. Then we calculate the approximate mean value of these
242
CHAPTER 4 Lossless Information Hiding in Vector Quantization

indices by im ¼ Floor((il þ ilu þ iu þ iru)/4), where Floor(a) denotes the largest
integer that is not greater than a.
Step 2: Compute the absolute value of the difference between each adjacent
index and the approximate mean calculated in Step 1, i.e., dl ¼ jil-imj, dlu ¼
jilu-imj, du ¼ jiu-imj, dru ¼ jiru-imj.
Step 3: Judge if the four difference values obtained in Step 2 are equal. If they are
identical, the current index is jumped over and the secret data are not embedded
into it, and then go to Step 8. Otherwise, if at least two of them are different,
secret data can be embedded into the current index, and then go to Step 4.
Step 4: Find the smallest value dmin ¼ min{dl, dlu, du, dru} and then ﬁnd a
different second smallest value dmin2 among {dl, dlu, du, dru} to ensure that dmin2
is not equal to dmin.
Step 5: Input 1 bit of secret data w. If w ¼ 1, go to Step 6. Otherwise, go to Step 7.
Step 6: Get the two ﬂag bits of the adjacent index imin that are closest to the
approximate mean im (their distance is dmin) and then append the two ﬂag bits to
the resulting code stream. Finally, the index residual value d ¼ icur  imin is
calculated, and then go to Step 9.
Step 7: Get the two ﬂag bits of the adjacent index imin2 that are second closest to
the approximate mean im (their distance is dmin2) and then append the two ﬂag
bits to the resulting code stream. Finally, the index residual value
d ¼ icur  imin2 is calculated, and then go to Step 9.
Table 4.13 The Final Codestreams for Different Cases
Secret Bit
Case 1
Case 2
Case 3
Case 4
1
(**)1j11j(d)2
(**)1j10j(d)2
(**)1j01jðdÞ0
2
(**)1j00jðdÞ0
2
0
(**)2j11j(d)2
(**)2j10j(d)2
(**)2j01jðdÞ0
2
(**)2j00jðdÞ0
2
FIGURE 4.21
The ﬂag numbers of the neighboring indices related to the current index.
4.5 Vector QuantizationeIndex CodingeBased Schemes
243

Step 8: Out of the four adjacent indices, ﬁnd the adjacent index iclo that is closest
to icur and send the corresponding two ﬂag bits to the output codestream. Finally,
the index residual value d ¼ icur  iclo is calculated.
Step 9: To decrease the bit rate of the output code stream, we choose a ﬁxed
appropriate integer s, which is unchanged for all the indices in the information
hiding phase and can be acquired through the experiments mentioned in Section
4.5.2.4, i.e., the number of bits required to represent the absolute value of each
residual value can be denoted in the binary form. For a codebook of size N, the
residual value d ranges from (Ni  1) to (N  1). Thus the integer s ranges
from 1 to Ceil(log2N), where Ceil(a) denotes the least integer not less than a.
Step 10: With the integer s determined in the previous step and the obtained
index residual value d, we can encode d according to one of the four following
different cases and concatenate the binary encoding result right after the two
ﬂag bits to form the ﬁnal resulting codestream.
Case 1: If 0  d  2s  1, the current index residual value d is encoded into
the binary form 11 j(d)2, where j denotes the concatenation operation.
Case 2: If (2s  1)  d < 0, the current index residual value d is encoded
into the binary form 10j(d)2.
Case 3: If jdj > 2s  1 and d > 0, the current index residual value d is encoded
into the binary form 01 j(d)02, where (d)02 ¼ g0g1.gCeil(log2N)  1,
gi ˛ {0, 1}, 0  i  Ceil(log2N)  1, and N is the size of the codebook.
Case 4: If jdj > 2s  1 and d < 0, the current index residual value d is
encoded into the binary form 00 j(d)0
Step 11: Repeat Steps 1e10 to encode the following index in the raster-scan
order until all the indices except for the indices in the seed area are encoded.
4.5.2.3 The Decoding and Extracting Phase
In the VQIRVC-based scheme, the decoder used to reconstruct the stego image is the
same as the one used to restore the original image and extract the secret data. The
detailed decoding and extracting process can be described as follows.
Step 1: Read the ﬁrst two ﬂag bits at the proper position from the code stream
(started from the second block in the second row of the stego image) to ﬁnd the
corresponding adjacent index iadj, and then compute the mean value im of the
four adjacent indices.
Step 2: Whether the four adjacent indices are with the same distance from im is
judged. If the result is true, then no secret data are embedded into the index. Go
to Step 5. Otherwise, go to Step 3.
Step 3: Find the index iclo closest to im among the four adjacent indices.
Step 4: If iadj ¼ iclo, then the hidden secret bit is “1.” Otherwise, the secret bit
is “0.”
Step 5: Read the next 2 bits. If they are “’11,” go on with reading the following s
bits and convert them into the decimal difference value d; then the original VQ
index is recovered as iadj þ d. If the 2 bits are “’10,” go on with the similar
244
CHAPTER 4 Lossless Information Hiding in Vector Quantization

operation and recover the original VQ index as iadj  d. If the 2 bits are “’01,”
continue to read the next Ceil(log2N) bits and change them into the decimal
form d’, and the original VQ index is recovered as iadj þ d’. If the 2 bits are
“’00,” perform the same operation to get d’ and restore the original VQ index as
iadj  d’.
Step 6: Repeat Steps 1 to 4 to extract other secret data from the next index in the
raster-scan order until all indices are processed.
Step 7: According to the restored VQ indices and the sorted codebook, we can
reconstruct the VQ-compressed original image. In this way, the whole lossless
process is realized.
4.5.2.4 Experimental Results
To evaluate the VQIRVC-based scheme, we use six test images, Lena, Peppers,
Mandrill, Boat, Goldhill, and Jet_F16, of the same size 512  512 with 256 gray-
scales, as shown in Fig. 4.22. The VQIRVC scheme, the MFCVQ-based scheme
[3], and the SMVQ-based scheme [6] are compared (i.e., ChangeTaieLin’s
scheme). Three aspects are assessed in the experiment to evaluate an information
hiding scheme, i.e., the capacity representing the maximum amount of information
that can be hidden, the PSNR representing the quality of the stego image, and the bit
rate representing the performance of the compression efﬁciency whose unit is bpp.
FIGURE 4.22
Six test images.
4.5 Vector QuantizationeIndex CodingeBased Schemes
245

To ensure that all the algorithms can be fairly compared, the sizes of codebooks
adopted in all algorithms are 512. The VQIRVC-based algorithm is performed with
the appropriate s values. The comparisons are shown in Table 4.14. From Table 4.14,
we can see that the PSNR in the VQIRVC-based scheme is much larger than that of
the other two methods, which indicates that the quality of the stego image is much
better. This is because in the VQIRVC-based scheme the secret data are hidden in the
ﬂag bits of the codestream rather than in the index residual values. In fact, the recon-
structed image itself does not contain any secret information, whereas its codestream
does. The information hiding capacity has evidently been increased in comparison
with the MFCVQ-based scheme. In the VQIRVC-based scheme, we can nearly
hide 1 bit secret data per index. Unlike the MFCVQ-based method, there is no
need to judge whether a location is ﬁt for information hiding. Compared with the
SMVQ-based scheme, the capacity of the VQIRVC-based scheme is a little lower
than that of the SMVQ-based method. However, the PSNRs of the stego images
in the VQIRVC-based algorithm are signiﬁcantly higher than those of the SMVQ-
based scheme. Obviously, the two parameters have a relationship of mutual restric-
tion. The more secret data are embedded in the cover image, the lower the PSNR of
the stego image obtained.
To take the two attributes into comprehensive consideration, 3000, 6000, 9000,
12,000 and the embedding capacity (i.e., the number of maximum bits that can be
embedded) are embedded in the test images to measure the PSNRs of the stego
images. Based on test images of Lena and Peppers, the comparison results in
Fig. 4.23 show that the performance curve of the VQIRVC-based scheme is greater
than that of the SMVQ-based method, which means when the number of embedded
bits is the same, the PSNRs of the VQIRVC-based method are much higher. There-
fore, these experiments demonstrate the superiority of the VQIRVC-based
Table 4.14 Comparisons of the VQIRVC-Based, MFCVQ-Based, and
SMVQ-Based Algorithms
Algorithm
Parameters
Lena
Peppers
Mandrill
Boat
Goldhill
Jet_F16
VQIRVC
(N ¼ 512)
VQ (dB)
31.216
30.561
23.887
30.038
31.230
31.608
PSNR (dB)
31.216
30.561
23.887
30.038
31.230
31.608
Capacity
15,319
15,590
15,829
15,537
15,395
14,631
Bit rate (bpp)
0.635
0.626
0.684
0.664
0.662
0.649
MFCVQ
(N ¼ 512,
TH ¼ 18)
PSNR (dB)
29.831
29.072
23.229
27.002
28.135
26.879
Capacity
7512
6995
969
7155
2317
8283
Bit rate (bpp)
0.424
0.438
0.599
0.431
0.566
0.406
SMVQ
(N ¼ 512,
Ns ¼ 128)
PSNR (dB)
28.192
28.747
21.542
26.681
27.322
28.032
Capacity
16,129
16,129
16,129
16,129
16,129
16,129
Bit rate (bpp)
0.44
0.44
0.44
0.44
0.44
0.44
MFCVQ, modiﬁed fast correlation vector quantization; PSNR, peak signal-to-noise ratio; SMVQ, side
match vector quantization; VQ, vector quantization; VQIRVC, vector quantizationeindex residual value
coding.
246
CHAPTER 4 Lossless Information Hiding in Vector Quantization

algorithm. As to the bit rate, it is a bit larger in the VQIRVC-based algorithm. This is
because we have introduced two ﬂag bits for each index. However, taking the three
attributes into comprehensive consideration, the VQIRVC-based scheme is a more
effective method for its high capacity, high PSNR, and an acceptable bit rate.
From this, we can see that the main advantages of the VQIRVC-based lossless
information hiding scheme are as follows. (1) This algorithm achieves higher
PSNR and higher information hiding capacity than the MFCVQ- and the SMVQ-
based schemes. (2) This scheme can be separated into the VQ encoding process
for generating the VQ index table and the information hiding process to embed
secret data into the codestream. Obviously, this algorithm realizes the desired
“separation of the encoder and the embedder” requirement stated in Section 4.1.2,
which facilitates the individual processing of the encoder and the watermark embed-
der and the controlling of the corresponding performance. (3) It is obvious that
whether the secret data are embedded or not, the composition of the output code-
stream is the same. The only difference lies in the ﬂag bits for each index. This char-
acteristic makes unauthorized users not perceive the existence of the secret data and
thus makes the VQIRVC-based scheme meet the requirement of “distinguishability”
described in Section 4.1.2, which is important for the application of information
hiding.
4.5.3 PATH OPTIONAL LOSSLESS INFORMATION HIDING SCHEME
In the applications of lossless information hiding techniques, the stego image qual-
ity, the embedding capacity, and the security level are the three main aspects to be
considered. To improve the performance of previous algorithms, Wang and Lu pro-
posed a novel path optional lossless information hiding scheme [11]. This method
encodes the VQ indices of the cover image into the binary codestream using the
0
28
28.5
29
PSNR
29.5
30
30.5
31
31.5
2000
4000
6000
8000 10000
capacity
Cover image:Lena
12000 14000 16000 18000
the VQIRVC-based scheme
the SMVQ-based scheme
0
28.5
29
PSNR
29.5
30
30.5
31
2000
4000
6000
8000 10000
capacity
Cover image:Peppers
12000 14000 16000 18000
the VQIRVC-based scheme
the SMVQ-based scheme
FIGURE 4.23
Comparisons of the capacity and peak signal-to-noise ratio (PSNR) of vector
quantizationeindex residual value coding (VQIRVC)ebased and side match vector
quantization (SMVQ)ebased schemes.
4.5 Vector QuantizationeIndex CodingeBased Schemes
247

JNC scheme and hides secret data in the resulting codestream during the encoding
process. Compared with previous information hiding schemes in the VQ domain,
this algorithm not only achieves higher stego image quality and higher embedding
capacity but also greatly improves the security level. This scheme can be divided
into three phases, i.e., the preprocessing phase, the information hiding phase, and
the decoding and extraction phase. The overall ﬂowchart of this scheme is shown
in Fig. 4.24.
4.5.3.1 The Preprocessing Phase
There are two main tasks during the preprocessing phase, i.e., index table generation
and M-sequence generation.
For the index table generation task, a sorted VQ codebook is generated, and then
the cover image is encoded to be an index table using the obtained codebook. This
task can be described in detail as follows:
Step 1: The cover image is divided into nonoverlapping blocks of size 4  4.
Step 2: The codebook is generated by the well-known LBG algorithm based on
the training set composed of all cover image blocks. And then according to Eq.
(2), the codewords are sorted in the ascending order of their sum values.
Step 3: The sorted codebook is utilized to encode each block, generating the VQ
index table, as described in Section 4.5.2.1.
For the second task, the M-sequence is generated according to the selected path
and an initial key. Wang and Lu’s scheme provides users with two optional paths.
When the amount of secret data is huge, Path 2 in Fig. 4.25b is suggested to reach
higher transmission efﬁciency. When the amount of secret data is not large, Path 1 in
Fig. 4.25a is proposed to reduce the length of the output codestream. This task is
performed by the M-sequence generator, where the length of the M-sequence is
determined according to the selected path in the following two cases:
Case 1: When Path 1 is selected, 2-bit secret data are hidden in each block on an
average, and the number of bits of the output M-sequence is twice as large as the
number of blocks in the cover image to ensure that almost each block can be
distributed with 2-bit data from the M-sequence.
Case 2: When Path 2 is selected, 3-bit secret data are hidden in each block on an
average, and then the number of bits of the output M-sequence is three times as
large as the number of blocks in the cover image to ensure that almost each
block can be distributed with 3-bit data from the M-sequence.
4.5.3.2 The Hiding Phase
During the information hiding phase, Wang and Lu employ two different implemen-
tation processes, i.e., Path 1ebased and Path 2ebased schemes corresponding to the
two different paths. When the amount of secret data is huge, Path 2ebased method is
suggested to almost embed 3-bit secret data in each block to achieve high embedding
capacity and transmission efﬁciency. When the purpose is to reduce the length of the
output codestream, Path 1ebased scheme is proposed to nearly embed 2 bits secret
data in each block. These two processes can be expressed in detail as follows.
248
CHAPTER 4 Lossless Information Hiding in Vector Quantization

4.5.3.2.1 Path 1eBased Scheme
Input: the VQ index table, secret data, the M-sequence (or initial key)
Output: the output JNC codestream
Step 1: Two parameters m and n are preset, which indicate the number of bits
required to represent each absolute residual value between the current index and
the selected adjacent index and the number of the adjacent indices to be
searched, respectively. The parameter m is a randomly selected integer value
between 1 and Ceil(log2N), where N is the codebook size, whereas the
parameter n is set to be 4.
Step 2: The indices in the ﬁrst row and the leftmost and rightmost columns of the
index table are selected as seed area, in which the indices are kept unchanged
during the information hiding process. It means that no data are hidden in these
Preprocessing phase
Data hiding phase
Output codestream
VQ index table
JNC decoding
Input the key
Does the input key
equal the initial key?
Yes
Extract the secret data
End
Decoding and extracting phase
110111001101...100
No
VQ index table
VQ
Cover image
Initial key
1234
M-sequence
0110100101101...110
110111001101...100
Secret data
Select paths
Path 1 based scheme
Path 2 based scheme
FIGURE 4.24
The overall ﬂow chart of Wang and Lu’s scheme [11].
4.5 Vector QuantizationeIndex CodingeBased Schemes
249

locations. The information hiding process is performed from the second to the
last row and from the second to the second last column of the VQ index table.
Step 3: For each current index Ia, mark its adjacent indices Ib, Ic, Id, and Ie with
corresponding 2-bit position ﬂags “00,” “01,” “10,” and “11,” respectively, as
shown in Fig. 4.25a.
Step 4: Read 2-bit binary data from the M-sequence as the ﬂag to indicate the
position of an initially selected adjacent index. For example, if the 2 bits binary
data read from the M-sequence are “10,” then the initially selected adjacent
index is Id, as shown in Fig. 4.25a.
Step 5: Read 2 bits secret data to be hidden, and then utilize them to indicate the
location shift between the initially selected adjacent index and the ﬁnally
selected adjacent index in the clockwise direction along Path 1, as shown in
Fig. 4.25a. Based on the shift information, we can easily locate the ﬁnally
selected adjacent index. Assume that d has been selected as an initial adjacent
index; then the ﬁnal adjacent index can be obtained according to the following
four cases:
Case 1: If the 2 bits secret data are “00,” then the location shift is 0, and thus
the ﬁnally selected adjacent index is Id.
Case 2: If the 2 bits secret data are “01,” then the location shift is 1, and thus
the ﬁnally selected adjacent index is Ie.
Case 3: If the secret data are “10,” then the ﬁnal selected adjacent index is Ib.
Case 4: If the secret data are “11,” then the ﬁnal selected adjacent index is Ic.
Step 6: Based on the ﬁnally selected adjacent index, we can perform the JNC-
encoding process to encode the current index Ia as follows:
d ¼ indexa  indexfinal
(4.15)
where d is the residual value and indexa and indexﬁnal are the current index and the
ﬁnally selected adjacent index, respectively.
Step 6.1: The position ﬂag of the ﬁnally selected adjacent index is appended
to the output codestream.
Id (10)
Ic (01)
Ia
Path 1
Path 2
Ib (00)
Ie (11)
Ih (110)
Ii (111)
Ig (101)
Ic (001)
Id (010)
Ie (011)
If (100)
Ib (000)
Ia
(a)
(b)
FIGURE 4.25
The ﬂag bits of adjacent indices and the two related paths, (a) n ¼ 4 and (b) n ¼ 8.
250
CHAPTER 4 Lossless Information Hiding in Vector Quantization

Step 6.2: According to the preset parameter n in Step 1, for the current index
Ia, a search set composed of four neighboring indices is determined.
Step 6.3: The residual value between the ﬁnally selected adjacent index and
the current index is calculated as follows:
Step 6.4: According to the preset parameter m, the decimal residual value d is
transformed into the binary form in one of four cases mentioned in
Table 4.15, and then the resulting binary form is appended to the output
codestream.
Step 7: Repeat Steps 3 to 6 for all the indices except the indices in the seed area.
Obviously, when the parameter m is set to be different values, the length of the
output codestream may be different. To decrease the length of the output code-
stream, we should test all possible m values and select the optimal case. In this chap-
ter, the parameter m is set to the integer value from 1 to Ceil(log2N) successively,
where N is the codebook size. The appropriate m value is selected by ﬁnding the
case in which the resulting length of the output codestream is minimal.
It is obvious that the form of the output codestream obtained through the Path
1ebased scheme for each index is similar to that obtained through the basic JNC
scheme as shown in Table 4.15, where (**/***) for the output codestream of the
Path 1ebased scheme represents the position ﬂag of the ﬁnally selected adjacent
index.
Let us give a concrete example as shown in Fig. 4.26. The indices in the gray
blocks are selected as the seed area, and thus no secret data are hidden there. Assume
that the codebook size N is 256, and the parameters m ¼ 2 and n ¼ 4. In Fig. 4.26,
the ﬁrst index to be encoded is “138.” The 2-bit “10” in the M-sequence indicates
that the initially selected adjacent index is “136,” and “00” in the secret data denotes
that the location shift is 0. So the ﬁnally selected adjacent index is still “136,” and the
residual value d ¼ 138  136 ¼ 2. According to the relationship between d and m,
we know that d can be denoted as (10)2 satisfying Case 1. Thus, the index “138” can
be ﬁnally encoded as “10jj11jj10.” Now, the following index to be encoded is “133.”
The 2-bit “11” in the M-sequence indicates that the initially selected adjacent index
is “129,” and then that based on “10” in the secret data, i.e., the location shift is 2, the
ﬁnally selected adjacent index is “136” and d ¼ 133  136 ¼ 3. Obviously,
because m and d satisfy the relationship (2m  1) ¼  3  d ¼ 3 < 0, we have
(d)¼(11)2 based on Case 2. Therefore, the index “133” is ﬁnally encoded as
“01jj10jj11.” Similarly, for the index “137,” the 2-bit “01” in the M-sequence
Table 4.15 Forms of the JNC Codestream for Each Index in Different Cases
Cases
Case 1:
0 £ d £ 2m L 1
Case 2:
L(2m L 1) £ d < 0
Case 3:
d > 2m L 1
Case 4:
d < L(2m L 1)
Forms
(**/***)2j11j(d)2
(**/***)2j10j(d)2
(**/***)2j01j ðdÞ0
2
(**/***)2j00jðdÞ0
2
JNC, joint neighboring coding.
4.5 Vector QuantizationeIndex CodingeBased Schemes
251

denotes that the initially selected adjacent index is “142” and the ﬁnal selected adja-
cent
index is “129”
based on “01” in
the secret
data; then we have
d ¼ 137  129 ¼ 8. Because m and d satisfy Case 3 and log2N ¼ 8, we have
d ¼ (00,001,000)2.
Finally,
the
index
“137”
can
be
encoded
as
“10jj01jj00001000.” For the following index “131,” based on the following 2-bits
data in the M-sequence and secret data, the initially and ﬁnally selected adjacent
indices are both 137. Thus we have d ¼ 131  137 ¼ 6 which can be denoted
as (d) ¼ (00000110)2 satisfying Case 4. Therefore, the encoded binary form for
the index “131” is “00jj00jj00000110.”. Obviously, the ﬁnal output codestream
for
the
index
sequence
“138
133
137
131”
is
“10jj11jj10
01jj10jj11
10jj01jj00001000 00jj00jj00000110”.
4.5.3.2.2 Path 2eBased Scheme
Input: the VQ index table, secret data, the M-sequence.
Output: the output JNC codestream
The implementation of the Path 2ebased scheme is similar to that of the Path
1ebased scheme, which can be described as follows:
Step 1: Two parameters m and n are preset. The parameter m is a randomly
selected integer value between 1 and Ceil(log2N), where N is the codebook size,
while the parameter n is set to be 8.
Step 2: The indices in the ﬁrst and second rows, the leftmost, the second leftmost,
and rightmost columns of the index table are selected as seed area. The infor-
mation hiding process is performed from the third to the last row and from the
third to the second last column of the VQ index table.
Step 3: For each current index Ia, mark its adjacent indices Ib, Ic, Id, Ie, If, Ig, Ih,
and Ii with three-bit position ﬂags “000,” “001,” “010” “011,” “100,” “101,”
“110,” and “111,” respectively, as shown in Fig. 4.25b.
Step 4: Read 3-bit binary data from the M-sequence as the ﬂag to indicate the
position of an initially selected adjacent index.
Step 5: Read 3-bit secret data to be hidden, and then utilize them to indicate the
location shift between the initially selected adjacent index and the ﬁnally
selected adjacent index in the clockwise direction along Path 2, as shown in
128
M-sequence
Seed area
Output code
stream
10 11 01 00 11 01 00 11...01 01
Secret data
00 10 01 00 01 01 01...10 01
132138133137131137
136142129137126
135137168119123
110
FIGURE 4.26
A concrete example for the Path 1ebased scheme.
252
CHAPTER 4 Lossless Information Hiding in Vector Quantization

Fig. 4.25b. Based on the shift information, we can easily locate the ﬁnally
selected adjacent index.
For example, if the 3-bit binary data read from M-sequence are “100,” the
initially selected adjacent index of Ia is If. Then, if the secret data are “000,” the
location shift is 0 and thus the ﬁnally selected adjacent index is If. If the secret
data are “010,” the ﬁnally selected adjacent index should be Ih. If the secret data
are “100,” the ﬁnally selected adjacent index is Ib.
Step 6: Based on the ﬁnally selected adjacent index, we can perform the JNC
encoding process to encode the current index Ia similar to the Path 1ebased
scheme.
Step 7: Repeat Steps 3e6 for all the indices except the indices in the seed area.
Similar to the Path 1ebased scheme, the appropriate m value should also be
selected by ﬁnding the case in which the resulting length of the output codestream
is minimal.
4.5.3.3 The Decoding and Extraction Phases
The codestream decoding and secret data extraction are two separate tasks. The
codestream decoding algorithm is open to all users to ensure that anyone who re-
ceives the codestream can reconstruct the VQ index table of the cover image. More-
over, the secret data extraction algorithm can also be publicized, since the security of
secret data only depends on the initial key.
4.5.3.3.1 The Codestream Decoding Process
The codestream decoding algorithm is the same as the JNC decoding process, which
can be described in detail as follows:
Input: the received codestream, the seed area, parameters m and n, the codebook
size N.
Output: the VQ index table.
Step 1: When Path 1 is selected, the ﬁrst 2-bit binary data are read from the
codestream as the position ﬂag to indicate the ﬁnally selected adjacent index
indexﬁnal for the current index. Similarly, if Path 2 is selected, the ﬁrst 3-bit
binary data are read to indicate indexﬁnal.
Step 2: The next 2-bit binary data are read from the codestream to denote the case
in which the residual value d is encoded into the binary form. Here, 2-bit binary
data “11,” “10,” “01,” and “00” indicate Cases 1, 2, 3, and 4, respectively, as
described in Table 4.15.
Step 3: The residual result d is calculated according to the following four cases:
Case 1: If the 2-bit data read in Step 2 are “11,” then Case 1 described in
Section 2.2 is satisﬁed. Therefore, the following m-bit binary data are read
and then transformed into the decimal value d.
Case 2: If the 2-bit data read in Step 2 are “10,” then Case 2 is indicated.
Therefore, the following m-bit binary data are read and then transformed
into the decimal value ed.
4.5 Vector QuantizationeIndex CodingeBased Schemes
253

Case 3: If the 2-bit data read in Step 2 are “01,” then Case 3 is indicated. The
following Ceil(log2N)-bit binary data are read and then transformed into the
decimal value d.
Case 4: If the 2-bit data read in Step 2 are “00,” then Case 4 is indicated. The
following Ceil(log2N)-bit binary data are read and then transformed into the
decimal value d.
Step 4: The original VQ index indexa is recovered according to Eq. (4.15).
Step 5: Repeat Steps 1e4 to recover all VQ indices.
4.5.3.3.2 The Secret Data Extracting Process
Input: the received codestream, the seed area, parameters m and n, the codebook
size N, the initial key.
Output: Secret data.
Step 1: According to the selected path, the corresponding M-sequence is
generated using the initial key. The detailed process can be referred to the
preprocessing phase.
Step 2: For each index, its ﬁnally selected adjacent index is recorded during the
codestream decoding process.
Step 3: When Path 1 is selected, the following 2-bit binary data from the M-
sequence are read to indicate the position of the initially selected adjacent index.
When Path 2 is selected, the following 3-bit binary data from the M-sequence
are read to indicate the position of the initially selected adjacent index.
Step 4: According to positions of the initially and ﬁnally selected adjacent
indices, the location shift in the anticlockwise direction along the path is
calculated and then transformed into the binary form as the output secret data
previously hidden in the current index.
Step 5: Repeat Steps 2e4 to extract other secret data until all the indices are
processed.
4.5.3.4 Experimental Results
To evaluate the performance of Wang and Lu’s scheme, we compared it with another
two algorithms. Six general test images, Lena, Peppers, Mandrill, Boat, Goldhill,
and Jet_F16, of size 512  512 with 256 grayscales, were adopted as shown in
Fig. 4.22. Five aspects of performance, i.e., the hiding capacity, the stego image
quality, the bit rate of the output codestream, the transmission efﬁciency, and the se-
curity are discussed. In the experiment, the parameter capacity denoting the number
of secret bits hidden in each test image with the same size is utilized to estimate the
hiding capacity. The PSNR is used to evaluate the image quality. The parameter
bit_rate deﬁned as follows is used to estimate the compression performance of
the output codestream.
bit rate ¼
L
P  Q
(4.16)
254
CHAPTER 4 Lossless Information Hiding in Vector Quantization

where L is the number of total bits in the output codestream and P  Q is the test
image size. The unit of the parameter bit_rate is bpp. Besides, the parameter e is
introduced to denote the transmission efﬁciency that represents the cost of band-
width for transmitting the same secret data. Namely, the parameter e denotes how
many bits of secret data can be carried when the output codestream of the same
length is transmitted. Therefore, the parameter e is deﬁned as:
e ¼
capacity
bit rate  P  Q
(4.17)
where P  Q is the size of test images. Obviously, when e is higher, the transmission
efﬁciency is also higher and the corresponding algorithm is more applicable.
To demonstrate the superiority of Wang and Lu’s algorithm, we compared it with
the MFCVQ-based algorithm proposed by Yang et al. [3] and the SMVQ-based al-
gorithm proposed by Chang et al. [6]. To ensure all of them can be fairly compared,
the codebook size for all the algorithms is ﬁxed to be 512. Wang and Lu’s algorithm
is performed with the appropriate m values. The comparisons are shown in
Table 4.16.
Based on Table 4.16, we can see that the PSNR values of Wang and Lu’s scheme
are much larger than those of the other two methods, which indicates that the method
can obtain stego images with much higher quality. This is because in this scheme a
lossless index coding method is adopted and the secret data are hidden in the posi-
tion ﬂags in the codestream. The reconstructed image based on the output code-
stream does not contain any secret information.
Table 4.16 also shows that, based on the same test image size, the method can
evidently increase the hiding capacity. In this scheme, we nearly hide 2-bits (or 3-
bits) secret data per index based on Path 1 (or Path 2), whereas the hiding capacity
of other two algorithms is not more than 1 bit per index on an average. And unlike
the MFCVQ-based method, there is no need to judge whether a location is ﬁt for in-
formation hiding or not in the scheme.
In terms of bit rate, it is somewhat larger in this algorithm. That is because the 2-
bit or 3-bit position ﬂag is introduced for each index. However, when taking the three
attributes (capacity, quality, and bit rate) into comprehensive consideration, Wang
and Lu’s scheme is more effective for its high capacity, high PSNR, and an accept-
able bit rate. According to the transmission efﬁciency e shown in Fig. 4.27, the effec-
tiveness of Wang and Lu’s method can be further proved. The results in Fig. 4.27
show that the method can hide many more bits of secret data than other two methods
if the length of the output codestream is the same. In addition, it is true that the trans-
mission efﬁciency of the Path 2ebased scheme is much higher than that of the Path
1ebased scheme in the same case.
Finally, the security issue is discussed. Compared with the MFCVQ-based algo-
rithm and the SMVQ-based algorithm, Wang and Lu’s scheme has improved the se-
curity level because of the following two main characteristics. One is that the JNC
encoding process and the secret information hiding algorithm can be publicized over
the Internet and the security of secret data only depends on the unique initial key that
4.5 Vector QuantizationeIndex CodingeBased Schemes
255

Table 4.16 Comparisons of Wang and Lu’s, MFCVQ-Based and SMVQ-Based
Schemes
Algorithm
Parameter
Lena
Peppers
Mandrill
Boat
Goldhill
Jet_F16
Wang and
Lu’s
(N ¼ 512, the
initial key:
3387)
m (Path 1)
5
5
6
5
5
5
VQ (dB)
31.216
30.561
23.887
30.038
31.231
31.608
Stego image
quality (dB)
31.216
30.561
23.887
30.038
31.231
31.608
Capacity
(Path 1)
32,004
32,004
32,004
32,004
32,004
32,004
Bit rate
(bpp, Path 1)
0.641
0.632
0.691
0.665
0.664
0.649
m (Path 2)
5
5
6
6
6
5
Capacity
(Path 2)
47,250
47,250
47,250
47,250
47,250
47,250
Bit rate
(bpp, Path 2)
0.706
0.701
0.751
0.732
0.731
0.722
MFCVQ-
based
(N ¼ 512,
TH ¼ 18)
Stego image
quality (dB)
29.831
29.072
23.300
27.002
28.135
26.879
Capacity
7512
6995
969
7155
2317
8283
Bit rate (bpp)
0.424
0.438
0.599
0.431
0.566
0.406
SMVQ-
based
(N ¼ 512,
Ns ¼ 128)
Stego image
quality (dB)
28.192
28.747
21.542
26.681
27.322
28.032
Capacity
16,129
16,129
16,129
16,129
16,129
16,129
Bit rate (bpp)
0.44
0.44
0.44
0.44
0.44
0.44
MFCVQ, modiﬁed fast correlation vector quantization; SMVQ, side match vector quantization; VQ,
vector quantization.
the efficiency(e) comparisons of three algorithms
0.25
0.2
0.15
0.1
0.05
0
lena
peppers
Mandrill
Boat
Goldhill
Jet_F16
the test images
efficiency
path1 based scheme
path2 based scheme
FCVQ-based algorithm
SMVQ-based algorithm
FIGURE 4.27
Transmission efﬁciency comparisons of Wand and Lu’s, modiﬁed fast correlation vector
quantizationebased and side match vector quantizationebased schemes.
256
CHAPTER 4 Lossless Information Hiding in Vector Quantization

is known to authorized users. The other is that the secret data extraction process and
the cover image recovering process are separated, as shown in Fig. 4.24. These fea-
tures enable all users (even malicious attackers) to reconstruct the cover image ac-
cording to the received codestream using the open JNC algorithm, while only
enabling the authorized users to extract secret data using the unique initial key
and the publicized data extraction algorithm. Wang and Lu’s algorithm enables all
users to deal with the output codestream without noticing the existence of the secret
data and thus improves the security, whereas the MFCVQ-based algorithm and the
SMVQ-based algorithm do not possess these two features. Obviously, the excellent
characteristics can be efﬁciently utilized in covert communication systems. To hide
secret data, a content-related cover image, which maybe represents the opposite
meaning, is used to transmit the secret data. As a result, when a certain segment
of data are intercepted by a malicious eavesdropper, based on the given decoder,
a cover image carrying the opposite information can be reconstructed to mislead
the malicious eavesdropper and consequently conceal the real content of secret data.
Experimental results demonstrate that Wang and Lu’s scheme achieves several
improvements: (1) to achieve a higher PSNR and a higher information hiding capac-
ity compared with the algorithms proposed by Yang et al. and Chang et al., respec-
tively; (2) to realize the desired separation of the secret data extraction process and
the cover image recovering process; and (3) to meet the desired requirement of al-
gorithm openness by adopting the JNC algorithm and the proposed secret informa-
tion hiding algorithm. In addition, it is important that a path optional scheme be
offered to users who can choose an appropriate path based on various actual
requirements.
4.5.4 DIFFERENCE CODINGeBASED SCHEME
The main shortcomings of SMVQ and MFCVQ-based schemes are low hiding ca-
pacity and low stego image quality. To partially solve these problems, Chu et al. pro-
poses a novel lossless information hiding scheme for VQ-compressed images by
performing a special difference coding operation on the VQ indices [12]. During
the hiding process, the difference between the current index and its neighboring
ones is computed and encoded based on four cases in view of the current watermark
bits to be embedded. In the decoding phase, not only the original watermark bits but
also the original indices can be losslessly recovered if the codestream of the stego
image is under no attacks. This scheme includes two opposite processes, i.e., hiding
and extracting processes, which can be described in detail as follows.
4.5.4.1 The Hiding Process
In this subsection, we provide Chu et al.’s hiding process. Based on a pretrained
codebook, we ﬁrst perform the VQ compression operation on the original image
blocks to generate the corresponding index table and then hide secret bits based
on the obtained index table. The VQ indices located in the ﬁrst row and the leftmost
and rightmost columns of the index table remain unchanged during the hiding
4.5 Vector QuantizationeIndex CodingeBased Schemes
257

process, i.e., no secret bits are hidden in these locations. This unchanged special area
is called the seed area. Chu et al.’s hiding process is started from the VQ index
located in the second row and the second column to the index located in the last
row and the second last column. Assuming that the input image is of size R  R
and the block size is 4  4, the detailed process can be illustrated as follows:
Step 1: Ofﬂine step. The mean value Vi ¼ (ci1 þ ci2 þ .þ cik)/k of each code-
word ci(i ¼ 0, 1, ., N  1) is computed and all the codewords in the codebook
are sorted in the ascending order of their mean values. The purpose of this
ofﬂine step is to make neighboring codewords in the sorted codebook C close to
each other. Therefore, the difference values between two neighboring VQ
indices are relatively small.
Step 2: VQ index table generation. The input original image is segmented into
nonoverlapping 4  4 blocks to form input vectors, and then each input vector is
encoded based on the sorted codebook C to obtain its corresponding index. Thus
a (R/4)  (R/4)-sized index table can be generated. Obviously, the index table is
an (R/4)  (R/4)-sized matrix with elements pi,j, where i ¼ 0, 1, ., (R/4)  1
and j ¼ 0,1, ., (R/4)  1.
Step 3: Index difference calculation. According to the secret bits, the residual
value of the current index is calculated based on the following rule. The secret
bits can be hidden into a new code stream by encoding the difference value
d between the current VQ index pi,j and an optional neighboring VQ index,
pi1,j1, pi1,j, pi,j1, or pi1,jþ1. During the hiding process, two secret bits are
hidden in the current VQ index pi,j at a time. If the two secret bits to be hidden
are “00,” d is deﬁned as the difference between the left neighboring index pi,j1
and the current index pi,j, i.e., d ¼ pi,j1  pi,j. If the 2 bits to be hidden are “01,”
d is deﬁned as the difference between the upper left index pi1,j1 and pi,j, i.e.,
d ¼ pi1,j1  pi,j. If the 2 bits to be hidden are “10,” d is deﬁned as the dif-
ference between the upper neighboring index pi1,j and pi,j, i.e., d ¼ pi1,j  pi,j.
Similarly, if the 2 bits to be hidden are “11,” d is deﬁned as d ¼ pi1,jþ1  pi,j.
Step 4: Difference coding. According to the distribution of difference values, an
appropriate integer m is chosen to record the number of bits required to
represent each difference value. Namely, the difference d can be denoted as the
binary form (d)2 ¼ a0a1.am1, where ai ˛ {0, 1}. Since Chu et al.’s hiding
process is affected by the amplitude range of the difference values, which de-
pends on the image content, various amplitudes should be represented with
various numbers of bits. Obviously, the amplitude of the absolute difference
value s from 0 to N  1, thus m ranges from 1 to Ceil(log2N), where Ceil(z) is a
function to get the smallest integer not less than z.
Step 5: Codestream generation. According to the obtained difference and the
chosen m, the hiding process is performed based on the following rule: if
0 < d < 2m  1, pi,j is encoded as 001jj(d)2, 011jj(d)2,101jj(d)2, or 111jj(d)2 to
represent hiding the secret bits 00,01,10, or 11, respectively, where jj denotes
the concatenation operation. If (2m  1) < d < 0, pi,j is encoded as 000jj(d)2,
258
CHAPTER 4 Lossless Information Hiding in Vector Quantization

010jj(d)2,100jj(d)2, or 110jj(d)2 to represent hiding the secret bits 00,01,10, or
11, respectively. If d ¼ 0, pi,j is encoded as 001jj(d)2, 011jj(d)2,101jj(d)2, or
111jj(d)2, where (d)2 equals m bits of “0” (000.0), to represent hiding the
secret bits 00,01,10, or 11, respectively. If jdj > 2m  1, pi,j is encoded as
000jj00.0jj(pi,j)2, 010jj00.0jj(pi,j)2, 100jj00.0jj(pi,j)2, or 110jj00.0jj(pi,j)2,
to represent hiding the secret bits 00,01,10, or 11, respectively, where
(pi,j)2 ¼ g0g1.glog2N1 (gi ˛ {0, 1}, 0  i  log2N  1), and there are m bits of
“0” in the middle part. Obviously, if the difference values satisfy the ﬁrst two
cases (called normal case) and the third case (called zero case), m bits are
required to represent (d)2. Thus (3 þ m) bits are required to form a new code-
stream for each case. If the difference values satisfy the last case (called special
case), Ceil(log2N) bits are required to represent (pi,j)2, thus
(3 þ m þ Ceil(log2N)) bits are concatenated to form a new codestream for this
case.
4.5.4.2 The Extracting Process
Chu et al.’s extracting process is just the opposite process of the hiding process, and
this process can recover the original VQ-compressed image. That is, Chu et al.’s
extracting process is a lossless process. Assume we have the stego VQ-
compressed image whose binary codestream is possibly hidden with secret bits,
and then we can extract the secret bits and recover the VQ index table by following
steps:
Step 1: (3 þ m) bits are read from the bitstream and stored into a register p.
Step 2: p’s ﬁrst 2 bits are directly extracted to be the two secret bits.
Step 3: If p’s last m bits are all 0 and p’s third bit is 1, then the following cases are
judged: If the secret bits are “00,” then the original VQ index is recovered as
pi,j ¼ pi,j1; else if the secret bits are “01,” then the original VQ index is
recovered as pi,j ¼ pi1,j1; if the secret bits are “10,” then the original VQ index
is recovered as pi,j ¼ pi1,j; else the original VQ index is recovered as
pi,j ¼ pi1,jþ1. Go to Step 6.
Step 4: If p’s last m bits are all 0 and p’s third bit is 0, then we read the next
	
logN
2

bits into a temporary register q2 from the code stream and convert q2 into
the decimal value q; then the recovered VQ index is computed by pi,j ¼ q. Go to
Step 6.
Step 5: If p’s last m bits are not all 0, then we compute the p’s last m bits as the
difference value d2 and convert d2 into the decimal value d. If p’s third bit is 0,
then we set d ¼ d. The following cases are judged: If the secret bits are “00,”
then the VQ index is recovered as pi,j ¼ pi,j1  d; else if the secret bits are
“01,” then pi,j ¼ pi1,j1d; if the secret bits are “10,” then pi,j ¼ pi1,jd; else
pi,j ¼ pi1,jþ1d. Go to Step 6.
Step 6: Repeat Steps e5 until all the codestream are read.
4.5 Vector QuantizationeIndex CodingeBased Schemes
259

4.5.4.3 Experimental Results
To evaluate performance of Chu et al.’s scheme, three 256 grayscale images (Lena,
Pepper, and Baboon) of size 512  512 are adopted as test images, and then Chu
et al.’s algorithm is compared with the MFCVQ-based algorithm proposed by
Yang et al. [3] and the SMVQ-based algorithm proposed by Chang et al. [6]. The
codebook C of size 512 is pregenerated before hiding. To measure the performance
of a lossless information hiding algorithm, we choose three parameters: payload ca-
pacity representing the maximal amount of information can be hidden, the PSNR
representing the quality of the image with hidden data, and the bit rate representing
the number of bits required to transmit during the lossless process in the experiment.
In Chu et al.’s algorithm, we should ﬁrst choose an appropriate integer m to make
the number of transmitted bits as less as possible. Namely, we should make the bit
rate as less as possible. The results are shown in Table 4.17 for the test image Lena.
From this table, we can see that we should select m ¼ 6 for the test image Lena.
To show the superiority of Chu et al.’s algorithm, we compare it with the
MFCVQ-based algorithm and the SMVQ-based algorithm. The results are shown
in Table 4.18. Obviously, Chu et al.’s algorithm uses the ordinary VQ and actually
hides the secret bits into a new codestream, and therefore the quality of the stego
image is better than that generated by the algorithms in Refs. [3,6]. From the perfor-
mance in hiding capacity, we can see that Chu et al.’s algorithm outperforms the
other two algorithms, which makes Chu et al.’s algorithm have more application
foreground. In view of the bit rate, Chu et al.’s algorithm is a little worse than other
algorithms; however if we take both the capacity and bit rate into account, the per-
formance of Chu et al.’s algorithm is much better.
From this, we can conclude that the lossless information hiding scheme based on
the difference coding of VQ indices has a higher greater role in the stego image’s
quality and hiding capacity, thus it will have a wider application area.
Table 4.17 The Performance of the Test Image Lena
m
2
3
4
5
6
7
8
9
bpp
0.744
0.740
0.703
0.670
0.654
0.654
0.666
0.727
Blocks
in
normal
case
1086
2949
5787
8526
10,767
12,511
13,928
13,928
Blocks
in zero
case
1948
1948
1948
1948
1948
1948
1948
1948
Blocks
in
special
case
12,842
10,979
8141
5402
3161
1417
0
0
260
CHAPTER 4 Lossless Information Hiding in Vector Quantization

4.5.5 IMPROVED JOINT NEIGHBORING CODINGeBASED SCHEME
From the previous sections, we can see that MFCVQ, SMVQ, and JNC-based infor-
mation hiding methods do not embed secret bits in the seed area. Furthermore, they
perform the information hiding process in embeddable blocks one by one. In order to
embed more secret bits, Lu et al.’ presented an IJNC scheme [13]. In this scheme, the
ﬁrst strategy is to cancel the seed area and make all blocks embeddable. To reduce
the coding bit rate, the second strategy is to perform the index coding process on
each 2  2 index block rather than one by one. The main idea of the IJNC scheme
is to ﬁrst vector-quantize the cover image, obtaining an index table, and then divide
the index table into nonoverlapping 2  2 index blocks. Finally, we encode the
indices in each 2  2 index block according to four input secret bits and the dynamic
range is evaluated by the difference between the maximal index value and the min-
imal index value in the index block. The IJNC algorithm consists of three stages, i.e.,
the VQ encoding stage, the information hiding and index coding stage, and the data
extraction and decoding stage, which can be illustrated as follows.
4.5.5.1 The Vector Quantization Encoding Stage
This stage is a preprocessing stage before information hiding and index coding. The
aim of this stage is to obtain the index table for later use. Given a P  Q-sized 256
grayscale host image I and the codebook C with N 16-dimensional codewords ci,
i ¼ 0, 1, ., 511 (here, we adopt k ¼ 4  4 and N ¼ 512), this stage can be
expressed as follows:
Step 1: For each codeword ci, compute its sum value by
si ¼ ci1 þ ci2 þ . þ ci16, i ¼ 0, 1, ., 511.
Step 2: Sort the codebook C according to si in the ascending order,
s0  s1 $$$ s511, obtaining the sorted codebook Cs.
Table 4.18 Comparison Results Among Chu et al.’s and Existing Algorithms
Algorithm
Parameter
Lena
Pepper
Baboo
Chu et al.’s scheme (m ¼ 6)
PSNR
31.2804
30.6384
23.8881
Capacity
31,752
31,752
31,752
Bit rate (bpp)
0.6535
0.6246
0.7392
SMVQ-based scheme (Ns ¼ 128)
PSNR
28.1923
28.7471
21.5422
Capacity
13,487
13,984
8794
Bit rate (bpp)
0.539
0.528
0.692
MFCVQ-based scheme (TH ¼ 18)
PSNR
29.8311
29.0723
23.2998
Capacity
7512
6995
969
Bit rate (bpp)
0.424
0.438
0.599
MFCVQ, modiﬁed fast correlation vector quantization; PSNR, peak signal-to noise ratio; SMVQ, side
match vector quantization.
4.5 Vector QuantizationeIndex CodingeBased Schemes
261

Step 3: The original cover image I is divided into nonoverlapping 4  4-sized
blocks bi,j, i ¼ 0, 1, ., P/4  1, j ¼ 0,1,.,Q/4  1.
Step 4: Encode each image block bi,j with the sorted codebook Cs, obtaining the
index of its best matched codeword, pi,j. All these indices compose the index
table P ¼ {pi,j ji ¼ 0,1,.,P/4  1; j ¼ 0,1,.,Q/4  1}.
4.5.5.2 The Information Hiding and Index Coding Stage
With the index table P in hand, now we can introduce IJNC-based lossless informa-
tion hiding and index coding algorithm. Before embedding, we perform the permu-
tation operation on the secret bit sequence to enhance the security. The IJNC
embedding method is performed not index by index but on each 2  2 index block
to make full use of the correlation between neighboring indices, and thus the encod-
ing bit rate can be reduced. Assume the index table P is segmented into nonoverlap-
ping 2  2 index blocks, qh,l, h ¼ 0,1,.,P/8  1; l ¼ 0,1,.,Q/8  1. Here,
qh,l ¼ {p2h,2l, p2h,2lþ1, p2hþ1,2l, p2hþ1,2lþ1}, and we adopt {“00,” “01,” “10,”
“11”} to denote their locations accordingly. For each 2  2 index block qh,l, assume
the corresponding four secret bits to be embedded are {w1, w2, w3, w4}; the informa-
tion hiding and index coding process can be illustrated in detail as follows.
Step 1: Find the maximal and minimal indices pmax and pmin in qh,l, and record
their location bits wmax ˛ {“00,” “01,” “10,” “11”} and wmin ˛ {“00,” “01,”
“10,” “11”}.
Step 2: Calculate the dynamic range r ¼ pmax  pmin. For N ¼ 512, based on the
dynamic range r, consider eight cases as shown in Table 4.19. Obviously, it
requires 3 bits to denote each case. Append these 3 bits (they are called range
bits wran in this chapter) to the codestream. (If N ¼ 256, we may consider four
cases, and thus each case requires 2 bits.)
Step 3: Viewing the ﬁrst two secret bits w1 and w2 as the location bits, ﬁnd the
reference index pref in qm,n (e.g., if the ﬁrst two secret bits are “01,” then
pref ¼ p2h,2lþ1). Append the two secret bits wref ¼ w1jjw2 (they are called
reference location bits) followed by the 9 bits (pref)2 (since the codebook size
N ¼ 512) to the codestream. Here, jj denotes the concatenation operation,
and ( )2 denotes the operation to get the binary description of a number.
Step 4: According to the third secret bit w3, select the comparison index pcom out
of {pmax, pmin}. If w3 ¼ 1, then set pcom ¼ pmax and wcom ¼ wmax; Otherwise, if
w3 ¼ 0, then set pcom ¼ pmin and wcom ¼ wmin. Here we should consider two
cases. In Case 1, the reference index and the comparison index are located at the
same position, i.e., pref ¼ pcom and wref ¼ wcom. Denote the remainder three
indices in qh,l as pA, pB, and pC (in the raster-scan order). In Case 2, the reference
index and the comparison index are located at different positions, i.e.,
wref s wcom. Except for pcom, deﬁne pA ¼ pref and denote the remainder two
indices in qh,l as pB and pC (in the raster-scan order). Append the third secret bit
w3 followed by the two comparison location bits wcom to the codestream.
262
CHAPTER 4 Lossless Information Hiding in Vector Quantization

Step 5: According to the secret bits w3 and w4, calculate the differences among
pcom, pA, pB, and pC. If w4 ¼ 0 and w3 ¼ 0, then dA ¼ pA  pcom,
dB ¼ pB  pcom, and dC ¼ pC  pcom. If w4 ¼ 0 and w3 ¼ 1, then
dA ¼ pcom  pA, dB ¼ pcom  pB, and dC ¼ pcom  pC. If w4 ¼ 1 and w3 ¼ 0,
then dA ¼ pcom  pA, dB ¼ pcom  pB, and dC ¼ pcom  pC. If w4 ¼ 1 and
w3 ¼ 1, then dA ¼ pA  pcom, dB ¼ pB  pcom, dC ¼ pC  pcom. We easily ﬁnd
that w4 can indicate the sign of the differences, i.e., if w4 ¼ 0, the sign is pos-
itive; otherwise, the sign is negative.
Step 6: According to the dynamic range r given in Table 4.19 look up the number
of bits (it is denoted by m) required to encode each difference. If w4 ¼ 0, 3m bits
are used to denote (dA)2, (dB)2, and (dC)2. Otherwise, if w4 ¼ 1, 3m bits are used
to denote (dA)2, (dB)2, and (dC)2. Append the fourth secret bit w4 followed
by the 3m bits of dA, dB, and dC to the codestream.
Perform Steps 1e6 for each 2  2 index block qh,l; we can hide 4 bits in each
index block and output a bit string of length 18 þ 3m, as given in Fig. 4.28. Here,
m is different from block to block. If most of the index blocks are with m < 6,
then the bit rate can be reduced compared to the original index table that requires
36 bits to denote four indices in each index block (N ¼ 512). An index coding
and information hiding example for a typical 2  2 index block is shown in
Fig. 4.29.
4.5.5.3 The Decoding and Extracting Stage
The IJNC-based information hiding scheme is lossless because we can recover the
original index table after data extraction, and thus the original VQ-compressed im-
age can be losslessly recovered. The input is the IJNC codestream, and the purpose is
to extract the secret bit sequence and recover the original VQ-compressed image.
Table 4.19 Eight Cases Considered for Coding the Index Differences
(N ¼ 512)
Case
Dynamic Range r
[ pmax L pmin
Range Bits
wran
m (Number of Bits
Required to Code Each
Difference)
Case 1
0  r < 2
“000”
1
Case 2
2  r < 4
“001”
2
Case 3
4  r < 8
“010”
3
Case 4
8  r < 16
“011”
4
Case 5
16  r < 32
“100”
5
Case 6
32  r < 64
“101”
6
Case 7
64  r < 128
“110”
7
Case 8
r  128
“111”
9
4.5 Vector QuantizationeIndex CodingeBased Schemes
263

Assume N ¼ 512, the detailed decoding and extracting process can be described as
follows.
Step 1: Read the next 3 bits into wran from the codestream, ﬁnd the corresponding
case in Table 4.19, and look up the value m in Table 4.19.
Step 2: Read the next 11 bits from the codestream. Get the ﬁrst 2 bits w1 and w2
as the reference location bits wref, append them to the output secret bit sequence.
Transform the last 9 bits into the reference index pref, and put this index in the
current index block according to the location bits wref.
Step 3: Read the next 3 bits from the codestream. Get the ﬁrst bit w3, append it to
the output secret bit sequence. Get the last 2 bits as the comparison location bits
wcom.
Step 4: Read the next 1 þ 3m bits from the codestream. Get the ﬁrst bit w4,
append it to the output secret bit sequence. Transform the following three m bits
into three positive difference values dAþ, dBþ, and dCþ. If w4 ¼ 0, dA ¼ dAþ,
dB ¼ dBþ, and dC ¼ dCþ; otherwise, dA ¼ dAþ, dB ¼ dBþ, and dC ¼ dCþ.
Step 5: Except for the reference index, recover the other three indices in the
current 2  2 index block. Here, we should consider two cases:
Case 1: wref ¼ wcom. In this case, the reference index is just the comparison
index, and thus pcom ¼ pref. If w4 ¼ 0 and w3 ¼ 0, then pA ¼ dA þ pcom,
pB ¼ dB þ pcom, and pC ¼ dC þ pcom. If w4 ¼ 0 and w3 ¼ 1, then
pA ¼ pcom  dA, pB ¼ pcom  dB, and pC ¼ pcom  dC. If w4 ¼ 1 and w3 ¼ 0,
Three 
range 
bits 
wran
Two 
reference 
location bits 
wref=w1||w2
9-bit 
reference 
index pref
Two 
comparison 
location 
bits wcom
The 
third 
secret 
bit w3
The 
fourth 
secret 
bit w4
3m bits 
for 
coding 
dA,dB
and dC
FIGURE 4.28
The bit string structure for encoding each index block (N ¼ 512).
Index block
412
407
407
405
pmax-pmin=7, wran
m=3
wref =w1||w2
pref=407
*
407(5)
5
7
w3=1,pcom=pmax=412, wcom
w4=0,
wcom wref, 
dA=pcom-pref =5, 
dB=pcom-407=5, dC=pcom-405=7
Secret bits
Output bits=010||01||110010111||1||00||0||101||101||111
FIGURE 4.29
A detailed example to hide 4 bits and encode an index block.
264
CHAPTER 4 Lossless Information Hiding in Vector Quantization

then pA ¼ pcom  dA, pB ¼ pcom  dB, and pC ¼ pcom  dC. If w4 ¼ 1 and
w3 ¼ 1, then pA ¼ dA þ pcom, pB ¼ dB þ pcom, and pC ¼ dC þ pcom. Put pA,
pB, and pC at the remainder three locations in the raster-scan order.
Case 2: wref s wcom. In this case, pA is the difference between pcom and pref. If
w4 ¼ 0 and w3 ¼ 0, then pcom ¼ dA  pref. If w4 ¼ 0 and w3 ¼ 1, then
pcom ¼ pref þ dA. If w4 ¼ 1 and w3 ¼ 0, then pcom ¼ pref þ dA. If w4 ¼ 1 and
w3 ¼ 1, then pcom ¼ dA  pref. Put pcom in the current 2  2 index block
according to the location bits wcom. Now turn to recover left two indices. If
w4 ¼ 0 and w3 ¼ 0, then pB ¼ dB þ pcom and pC ¼ dC þ pcom. If w4 ¼ 0 and
w3 ¼ 1, then pB ¼ pcom  dB and pC ¼ pcom  dC. If w4 ¼ 1 and w3 ¼ 0,
then pB ¼ pcom  dB and pC ¼ pcom  dC. If w4 ¼ 1 and w3 ¼ 1, then
pB ¼ dB þ pcom and pC ¼ dC þ pcom. Put pB and pC at the remainder two
locations in the raster-scan order.
Repeatedly perform Steps 1e5 for all 2  2 index blocks; we can recover the
original VQ index table and output the whole secret bit sequence. Fig. 4.30 gives
an example to show the decoding and data extraction process for an index block.
According to the restored VQ indices and the sorted codebook, we can reconstruct
the original VQ-compressed image. In this way, the whole lossless process is
realized.
412 407
407 405
wref
pref=407, 
w1=0,w2=1
*
407
*
*
w3=1, wcom
Index block
Secret bits
Input bits=01001110010111
wran
m=3
Input bits=
1000101101111
w4=0,dA=5, dB=5, dC=7
*
407(5)
5
7
w3=1,w4=0, wcom wref, 
pmax=pcom=407+5=412
pB=pcom-dB=407, 
pC=pcom-dC=405
FIGURE 4.30
A detailed example to extract secret data and decode an index block.
4.5 Vector QuantizationeIndex CodingeBased Schemes
265

4.5.4.4 Experimental Results
To evaluate the IJNC-based scheme, we use six test images, Lena, Peppers,
Mandrill, Boat, Goldhill, and Jet_F16, of the same size 512  512 with 256 gray-
scales. The 512-sized master codebook C is generated by the LBG algorithm based
on two training images, Lena and Peppers, where the dimension of each codeword is
4  4. Comparisons among the IJNC-based algorithm, the MFCVQ-based algorithm
[13], the SMVQ-based algorithm [17], and the JNC-based algorithm [19] are per-
formed. For SMVQ, we set the state codebook size to be 128. For MFCVQ, we
set the threshold to be 324 (in this chapter we use the squared Euclidean distance;
if the normal Euclidean distance is used then the threshold is 18). For JNC, we adopt
m ¼ 6 as given in Ref. [19].
To show the distribution of 2  2 index blocks for different images, Table 4.20
lists the number of index blocks belonging to each case of Table 4.19. Because the
total number of bits required to encode an index block based on the IJNC-based al-
gorithm is 18 þ 3m, whereas the number of bits required to encode four indices
based on the BVQ (N ¼ 512) is 36; to reduce the bit rate, we expect to have
18 þ 3m  36, i.e., m  6, for most index blocks. From Table 4.20, we can see
that, for all images except for the Mandrill image, most index blocks belong to
the ﬁrst 6 cases, thus the IJNC-based scheme can reduce the bit rate as shown in
Table 4.21. The Mandrill image is very complex with high detail and is outside
the training set, which makes the variation of indices in most index blocks to be
large, and thus most index blocks belong to Case 7 and the bit rate is somewhat
larger than that of the normal VQ.
To show the superiority of the IJNC-based algorithm, we compare it with the
MFCVQ-based algorithm [13], the SMVQ-based algorithm [17], and the JNC-
based algorithm [19]. Four aspects of performance are adopted in the experiments
to evaluate an information hiding scheme, i.e., the capacity representing the
maximum number of secret bits that can be hidden, the PSNR representing the qual-
ity of the stego image, the bit rate representing the performance of the compression
efﬁciency whose unit is bpp, and the embedding efﬁciency indicating the number of
embedded secret data when a bit of the binary code stream has been transmitted.
Table 4.20 The Number of 2  2 Index Blocks Belonging to Each Case in
Table 4.19
Image
Case 1
(m [ 1)
Case 2
(m [ 2)
Case 3
(m [ 3)
Case 4
(m [ 4)
Case 5
(m [ 5)
Case 6
(m [ 6)
Case 7
(m [ 7)
Case 8
(m [ 9)
Lena
162
51
362
782
890
738
622
489
Peppers
211
147
376
756
928
599
505
574
Mandrill
2
2
55
216
597
1216
1502
506
Boat
283
70
217
698
887
843
638
460
Glodhill
227
42
140
474
1010
1189
812
202
Jet_F16
678
286
638
512
402
438
591
551
266
CHAPTER 4 Lossless Information Hiding in Vector Quantization

Obviously,
the
embedding
efﬁciency
can
be
calculated
as
capacity/(bit
rate  P  Q). Because the VQ codebook is generated from the Lena and Peppers
images, their PSNRs based on any scheme are much higher than those of other test
images outside the training set. Because the Mandrill image is a high-detail image
outside the training set, its encoding quality is far worse than any other image. As
shown in Table 4.21, the PSNRs of stego images in the IJNC-based scheme and
the JNC-based method are exactly equal to those of the original VQ-compressed im-
ages; the reason is that the IJNC-based scheme and the JNC-based scheme reversibly
hide data during the coding of the VQ index table and no distortions are introduced
in the index coding and information hiding process. The MFCVQ-based and SMVQ-
based methods reversibly hide data during the VQ encoding, no operations are per-
formed on the consequent VQ-index coding process, and their reversibility means
that they can recover the original MFCVQ-encoded image and the SMVQ-
encoded image, respectively. However, the MFCVQ- and SMVQ-based encoding
methods obtain worse image quality by around 2 dB, although they obtain relatively
lower bit rates.
With respect to the embedding capacity, the IJNC-based scheme achieves the
highest embedding capacity. Compared with the SMVQ-based scheme and the
Table 4.21 Comparisons of IJNC-Based, MFCVQ-Based, SMVQ-Based, and
JNC-Based Algorithms
Algorithm
Performance
Lena
Peppers
Mandrill
Boat
Goldhill
Jet_F16
VQ
(N ¼ 512)
PSNR (dB)
30.860
30.428
22.070
28.184
29.618
28.014
Bit rate (bpp)
0.563
0.563
0.563
0.563
0.563
0.563
IJNC-
based
(N ¼ 512)
PSNR (dB)
30.860
30.428
22.070
28.184
29.618
28.014
Capacity
16,384
16,384
16,384
16,384
16,384
16,384
Bit rate (bpp)
0.534
0.528
0.583
0.532
0.537
0.498
Efﬁciency
0.117
0.118
0.107
0.117
0.116
0.126
JNC-
based
(N ¼ 512,
m ¼ 6)
PSNR (dB)
30.860
30.428
22.070
28.184
29.618
28.014
Capacity
16,129
16,129
16,129
16,129
16,129
16,129
Bit rate (bpp)
0.574
0.573
0.606
0.567
0.567
0.572
Efﬁciency
0.107
0.107
0.102
0.109
0.109
0.108
MFCVQ-
based
(N ¼ 512,
TH ¼ 324)
PSNR (dB)
28.443
28.139
21.412
26.148
27.823
26.079
Capacity
7435
6875
957
7107
2304
8175
Bit rate (bpp)
0.425
0.440
0.599
0.434
0.563
0.406
Efﬁciency
0.067
0.059
0.006
0.062
0.016
0.076
SMVQ-
based
(N ¼ 512,
Ns ¼ 128)
PSNR (dB)
28.192
27.947
21.042
25.881
27.422
25.832
Capacity
16,129
16,129
16,129
16,129
16,129
16,129
Bit rate (bpp)
0.44
0.44
0.44
0.44
0.44
0.44
Efﬁciency
0.140
0.140
0.140
0.140
0.140
0.140
IJNC, improved joint neighboring coding; JNC, joint neighboring coding; MFCVQ, modiﬁed fast cor-
relation vector quantization; PSNR, peak signal-to-noise ratio; SMVQ, side match vector quantization;
VQ, vector quantization.
4.5 Vector QuantizationeIndex CodingeBased Schemes
267

JNC-based scheme, the IJNC-based scheme embeds information in all indices
without the seed area, so we can embed 255 more bits in the index table. The
IJNC-based scheme achieves signiﬁcantly better embedding capacity compared
with the MFCVQ-based method. The embedding capacity of the MFCVQ-based
method is quite low because this method just embeds the secret data into smooth im-
age blocks outside the seed area.
With regard to the bit rate, from Table 4.21, we can see that the MFCVQ- and
SMVQ-based methods obtain relatively lower bit rates, whereas the IJNC-based
scheme and the JNC-based scheme achieve relatively higher bit rates. This is
because the MFCVQ scheme only uses 3 bits to encode one embeddable VQ-
compressed index, whereas the SMVQ only uses 7 bits (Ns ¼ 128) to denote each
index outside the seed area. Anyhow, compared with the ordinary VQ, the IJNC-
based scheme not only can hide information but also can compress indices, because
the IJNC-based scheme can get lower bit rates by around 0.02 bpp for most images
except the Mandrill image. Compared with the JNC-based scheme, the IJNC-based
scheme can achieve lower bit rates for all test images by around 0.04 bpp.
In terms of embedding efﬁciency, the SMVQ-based scheme has the highest ef-
ﬁciency values, and the MFCVQ-based method has the lowest efﬁciency values.
This means that the SMVQ can transmit the most number of embedded secret
data when a bit of the binary code stream has been transmitted, whereas the
MFCVQ-based method can transmit the least number of embedded secret data.
The IJNC-based scheme has the second highest efﬁciency values, which are higher
than those of the JNC-based scheme by around 0.01.
With regard to the embedding and extracting speed, because the IJNC-based
scheme and the JNC-based scheme are based on the index table, if we ignore the
VQ encoding process, the IJNC-based scheme and the JNC-based scheme are
much faster than the MFCVQ-based and SMVQ-based schemes. Taking the afore-
mentioned ﬁve attributes into comprehensive consideration, the IJNC-based scheme
is a more effective method for its high capacity, high PSNR, high embedding efﬁ-
ciency, and low bit rate.
From this discussion, we can conclude that the main features of the IJNC-based
scheme are as follows: (1) The IJNC-based scheme can obtain the same PSNR
values as the JNC-based scheme. (2) The IJNC-based scheme does not need the
seed area, so it can achieve higher information hiding capacity compared with other
algorithms that require the seed area. (3) The IJNC-based scheme is based on 2  2
index blocks, which can make full use of the correlation between indices, thus it can
reduce the bit rate compared with the ordinary VQ. (4) The IJNC-based scheme is
separated into the VQ encoding process for generating the index table and the infor-
mation hiding process to embed secret data into the output codestream. Obviously,
the IJNC-based algorithm realizes the desired “separation of the encoder and the
embedder” requirement stated in Ref. [3], which facilitates the individual processing
of the encoder and the watermark embedder and the controlling of the corresponding
performance.
268
CHAPTER 4 Lossless Information Hiding in Vector Quantization

4.5.6 LOSSLESS HIDING SCHEME FOR TWO-STAGE VECTOR
QUANTIZATION COMPRESSED IMAGES
The BVQ system has a simple decoding structure but the encoding complexity is
high. To release the complexity, multistage vector quantization (MSVQ) is intro-
duced to divide the encoding task into successive stages, where the ﬁrst stage per-
forms a relatively crude quantization of the input vector using a small codebook.
Then, a second stage quantizer operates on the error vector between the original
and quantized ﬁrst stage output. The quantized error vector then provides a second
approximation to the original input vector thereby leading to a reﬁned or more ac-
curate representation of the input. A third stage quantizer may then be used to quan-
tize the second stage error to provide a further reﬁnement, and so on. Here, each
stage generates its codebook based on the corresponding training vectors in advance.
As shown in Fig. 4.31, VQi (i ¼ 1, 2,., p) represents the ith VQ operation. Source
S(0) denotes the input image, and p is the total number of stages. D(i) (i ¼ 1, 2,.,
p  1) denotes the ith version encoded image. S(i) (i ¼ 2, 3,., p  1) is the residue
of S(i1) subtracting D(i). I(i) (i ¼ 1, 2,., p) is the ith output index table.
Compared with the traditional VQ, MSVQ is a more attractive data compression
scheme with lower complexity and less encoding time due to the reduced codebook
size. TSVQ with two codebooks is the simplest MSVQ. Based on TSVQ, Zhao et al.
proposed a lossless information hiding scheme [15] in 2014 as illustrated in
Fig. 4.32. This scheme can be divided into three stages, namely, the preprocessing
stage, the data embedding stage, and the decoding and extraction stage, which
can be expressed in detail as follows.
4.5.6.1 The Preprocessing Stage
The aim of this step is to obtain the cover image to be embedded with secret data.
First, the two-stage codebooks, N1-sized C1 and N2-sized C2, with 4  4-
dimensional codewords, are generated ofﬂine based on the TSVQ codebook gener-
ation algorithm. Second, the codewords in each VQ stage are sorted in the ascending
order of their mean values to make neighboring codewords close to each other.
Third, based on the sorted TSVQ codebooks, the P  Q-sized original image is
encoded as two (P/4)  (Q/4)-sized index matrices I(s) (s ¼ 1 or two) for the ﬁrst
and second VQ stages, respectively. With these two-stage index tables in hand,
the secret data can then be hidden by encoding I(s) jointly to achieve a high payload
+
+
_
S(0)
VQ1
VQp-1
S(p-2)
S( p-1)
I(1)
I (p-1)
I (p)
S(1)
D(1)
Source
Source
VQ1
VQp
VQp
Q
D(p-1)
VQp
Q -1
_
+
+
FIGURE 4.31
The ﬂowchart of the multistage vector quantization.
4.5 Vector QuantizationeIndex CodingeBased Schemes
269

and obtain a more secure bitstream. The bitstream of Zhao et al.’s algorithm consists
of three parts including the head information HI, the bitstream CS1 of the ﬁrst stage,
and the bitstream CS2 of the second stage. CS1 and CS2 are generated from the index
tables I(1) and I(2), respectively. HI provides the basic information of the bitstream,
such as the length of CS1, the length of CS2, the length of the secret data, the param-
eters m and n, and the cover image sizes.
4.5.6.2 The Data Embedding Process
For the sake of convenience, the parameter set {m, n} is adopted, where the values of
m and n have the same meaning as that in Section 4.5.3.2. Given the TSVQ code-
books, the current indices to be encoded in the index tables I(1) and I(2) are denoted
as Ic1 and Ic2, respectively. Similarly, the reference indices to predict Ic1 and Ic2 in the
index tables I(1) and I(2) are denoted as Ir1 and Ir2, respectively. Since the initial loca-
tion bits of the indices used to predict Ic1 and Ic2 are the same, the term bi is not
changed and it plays the same role as that in Section 4.5.3.2. However, bo and br
have to be changed into bo
(s) and br
(s), respectively, where s ¼ 1 or 2. The differences
between the current index and the reference index for I(1) and I(2) are denoted as E1
and E2, respectively.
Suppose an M-sequence is generated with an initial key in advance. Its length
should be not less than twice the length of secret data, since Zhao et al.’s scheme
needs exactly twice the length as long as that of the secret data for encoding. During
the embedding stage, the input are two index tables I(1) and I(2), the M-sequence, and
the secret data, while the output is the stego bitstream. Zhao et al.’s data embedding
process can be illustrated in detail as follows.
M-sequence
Initial key
I(1)
I(2)
Path 
selection
Joint 
embedding
Encoding process
Decoding process
Original
Image
TSVQ
Cover Image represented by two 
index tables
Secret data
FIGURE 4.32
The ﬂowchart of the two-stage vector quantizationebased algorithm.
270
CHAPTER 4 Lossless Information Hiding in Vector Quantization

Step 1: Parameter selection. Before embedding, {m, n} should be appropriately
selected. Here, we adopt two optional paths, namely, n ¼ 8 and n ¼ 4. Usually,
the larger the n value is, the higher is the payload. If n ¼ 4, then the topmost row
and the leftmost and right-most columns in the index tables I(1) and I(2) are
viewed as the seed area and kept unchanged. If n ¼ 8, then the topmost two
rows and the leftmost and rightmost two columns in the index tables I(1) and I(2)
are viewed as the seed area and kept unchanged. Suppose r is deﬁned as the
number of bits read from the M-sequence or secret data each time. Obviously,
the r value can be computed as
r ¼ log2 n
(4.18)
That is, r is set as 2 for n ¼ 4, whereas r ¼ 3 for n ¼ 8.
Step 2: Difference computation. From this step on, we turn to encoding the
current indices Ic1 and Ic2 in the index tables I(1) and I(2), respectively. First, we
get r bits from the M-sequence as the initial location bits bi of the reference
indices in the I(1) and I(2), respectively. Second, we get 2r bits from the secret
data, where the ﬁrst r bits are adopted as the offset bits bo
(1) for I(1) and the
second r bits bo
(2) for I(2). Third, we compute br
(1) ¼ bi þ bo
(1) for I(1) and
br
(2) ¼ bi þ bo
(2) for I(2). Fourth, according to br
(1) and br
(2), we ﬁnd the neigh-
boring reference indices Ir1 and Ir2 in I(1) and I(2), respectively. Finally, we
compute the differences E1 ¼ Ic1  Ir1 and E2 ¼ Ic2  Ir2, respectively.
Step 3: E2 encoding. Obviously, E2 takes values in the interval [N2 þ 1,
N2  1], and there are four cases to encode E2 into E0
2 according to either Eq.
(4.19) or Eq. (4.20). If E1 s 0, we encode E2 into
E02 ¼
8
>
>
>
>
>
>
>
>
<
>
>
>
>
>
>
>
>
:
11

ðE2ÞðmÞ
2
if 0  E2  ð2m  1Þ
10

ðE2ÞðmÞ
2
if  ð2m  1Þ  E2 < 0
01

ðE2Þðdlog2N2eÞ
2
if E2 > ð2m  1Þ
00

ðE2Þðdlog2N2eÞ
2
if E2 < ð2m  1Þ
(4.19)
If E1 ¼ 0, we encode E2 as
E0
2 ¼
8
>
>
>
>
<
>
>
>
>
:
ð11Þ2
if 0  E2  ð2m  1Þ
ð10Þ2
if  ð2m  1Þ  E2 < 0
ð01Þ2
if E2 > ð2m  1Þ
ð00Þ2
if E2 < ð2m  1Þ
(4.20)
4.5 Vector QuantizationeIndex CodingeBased Schemes
271

Step 4: E1 encoding. In this chapter, we consider ﬁve cases for E1 encoding as
follows.
Case 1: E1 ¼ 0. In this case, E1 is not encoded in CS1, whereas E2 is encoded
in CS1. In the ﬁrst stage of VQ, there is high correlation among the neigh-
boring indices. Accordingly, it is reasonable that E1 ¼ 0 for most Ic1 indices.
This property can be employed to reduce the length of output bitstream.
Here, we use 3 bits to encode this case as (100)2. If E2 belongs to its Case 1
or Case 2, 3 bits are used to represent the case of E1 and m bits are used to
represent E2. Thus, the binary stream is encoded as 100jj(jE2j)2, where jCj
denotes the absolute value of its element. If E2 belongs to its Case 3 or Case
4, 3 bits are used to represent the case of E1 and Ceil(log2N2) bits are used to
represent E2. Thus, the binary stream is encoded as 100jj(jE2j)2. This case
can be summarized as Eq. (4.21), where E0
1 represents the encoded version
of E1, (X)2 denotes the binary code of X, and AjjB stands for the concate-
nation of A and B.
E0
1 ¼
8
>
>
>
>
>
>
>
>
<
>
>
>
>
>
>
>
>
:
ð100Þ2

ðE2ÞðmÞ
2
if 0  E2  ð2m  1Þ
ð100Þ2

ðE2ÞðmÞ
2
if  ð2m  1Þ  E2 < 0
ð100Þ2

ðE2Þðdlog2N2eÞ
2
if E2 > ð2m  1Þ
ð100Þ2

ðE2Þðdlog2N2eÞ
2
if E2 < ð2m  1Þ
(4.21)
Cases 2e5: For E1 s 0, we can classify E1 into four cases and encode E1 as follows:
E0
1 ¼
8
>
>
>
>
>
>
>
>
<
>
>
>
>
>
>
>
>
:
ð011Þ2

ðE1ÞðmÞ
2
if 0 < E1  ð2m  1Þ
ð010Þ2

ðE1ÞðmÞ
2
if  ð2m  1Þ  E1 < 0
ð001Þ2

ðE1Þðdlog2N1eÞ
2
if E1 > ð2m  1Þ
ð000Þ2

ðE1Þðdlog2N1eÞ
2
if E1 < ð2m  1Þ
(4.22)
Step 5: CS1 encoding. To encode CS1, we just append E0
1 to br
(1). For example,
assume br
(1) ¼ (01)2, E1 ¼ 0 and the case of E2 is (11)2, then the ﬁnal bitstream
for the current index is 01jj000jj(jE2j)2.
Step 6: CS2 encoding. To encode CS2, we just append E0
2 to br
(2). For example,
assume br
(2) ¼ (00)2, E1 ¼ 0 and the case of E2 is (11)2, then the ﬁnal bitstream
for the current index is 00jj11. If E1 s 0, and the case of E2 is (11)2, then the
ﬁnal bitstream for the current index is 00jj11jj(jE2j)2.
Step 7: If all secret data have been embedded or all the indices outside the seed
area have been processed, we append CS1 and CS2 to the head information HI to
obtain the ﬁnal bitstream. Otherwise, we go to Step 2.
272
CHAPTER 4 Lossless Information Hiding in Vector Quantization

In sum, the ﬁnal bitstream consists of three parts, namely, the head information
of the stream, the ﬁrst encoded index table (bitstream1, CS1) and the second encoded
index table (bitstream2, CS2). The head information of the stream embodies the size
of the original image, the length of the secret data, {m, n}, and the lengths of second
and third parts sequentially. CS1 is encoded as the binary form “br
(1)jjcasejj(jE1j)2” or
“br
(1)jjcasejj(jE2j)2” depending on whether E1 equals 0 or not. If E1 s 0, CS1 is
encoded as the former, otherwise as the latter. CS2 is encoded as the binary form
“br
(2)jjcasejj(jE2j)2” or “br
(2)jjcase” depending on whether E1 equals 0 or not. If
E1 s 0, CS2 is encoded as the former, otherwise as the latter.
Here, we take a concrete example as shown in Fig. 4.33 to explain Zhao et al.’s
embedding scheme. Suppose N1 ¼ 16, N2 ¼ 32, n ¼ 4, and m ¼ 2. At each time, we
read 2 bits from the M-sequence while obtaining 4 bits from the secret data. To deal
with the index Ic1 ¼ “12” ¼ in the second row and the second column of I(1), the four
neighbors (14)00, (13)01, (12)10, and (14)11 are taken into account. At the same time,
the index Ic2 ¼ “26” in the second row and the second column of I(2) is also pro-
cessed. “00” Is ﬁrst read from the M-sequence as bi, and then four bits “1000”
are obtained from the secret data, where bo
(1) ¼ “10” and bo
(2) ¼ “00”. Then we
compute br
(1) ¼ “00” þ “10” ¼ “10” and br
(2) ¼ “00”þ “00” ¼ “00” and locate the
reference indices Ir1 ¼ “12” and Ir2 ¼ “30”respectively. Thus, we can compute
E1 ¼ 12  12 ¼ 0 and E2 ¼ 26  30 ¼ 4. Since E1 ¼ 0, according to Eqs.
(4.20) and (4.21), CS1 and CS2 can be encoded as 10jj100jj00,100 and 00jj00,
respectively.
4.5.6.3 The Decoding and Extraction Process
Assume that the bitstream received by the decoder does not suffer any attack, then
the original TSVQ-compressed image can be completely recovered without the aid
of the input M-sequence. Here, the input is the received bitstream, which can be
12
13
14
15
14
12
14
11
13
10
9
11
9
9
8
8
16
20
15
21
30
26
31
18
15
20
17
30
31
26
13
11
M-sequence
Secret data
I(1)
I(2)
FIGURE 4.33
An example to explain the two-stage vector quantizationebased data embedding
scheme.
4.5 Vector QuantizationeIndex CodingeBased Schemes
273

divided into three parts, namely, HI, CS1, and CS2, whereas the output is the two
TSVQ index tables. The decoding process can be illustrated in detail as follows.
Step 1: Obtain the head information HI from the bitstream to get the cover image
size, the length of CS1, the length of CS2, and the values of n and m.
Step 2: Input r bits from CS1 to obtain br
(1), and input r bits from CS2 to get br
(2).
Based on br
(1) and br
(2), we obtain their corresponding indices Ir1 and Ir2,
respectively.
Step 3: Obtain the case information from CS1 and CS2, and get the difference
values E1 and E2 from CS1 and CS2 based on the case information.
Step 4: Compute the current two-stage indices Ic1 and Ic2 as follows.
 Ic1 ¼ Ir1 þ E1
Ic2 ¼ Ir2 þ E2
(4.23)
Step 5: Perform Steps 2 to 4 over and over again until two index tables are
generated.
With regard to extracting the secret data, one input is the received bitstream,
which can be divided into three parts, namely, HI, CS1, and CS2, and the other input
is the key for generating the same M-sequence as used in the embedding process,
while the output is the secret data. The same key as used in the embedding process
is applied to generate the M-sequence, and the secret data can be obtained as
follows.
Step 1: Read the head information HI from the received bitstream.
Step 2: Input r bits of the M-sequence to obtain the initial location bits bi.
Step 3: Input r bits of CS1 to get br
(1), and input r bits of CS2 to obtain br
(2). Then
retrieve the corresponding indices Ir1 and Ir2, respectively. Then, compute the
offset bits bo
(1) ¼ br
(1)

bi and bo
(2) ¼ br
(2)

bi. Append bo
(1) and bo
(2) to
the extracted secret data.
Step 4: Perform Steps 2 and 3 over and over again until two index tables are
generated. In this way, we can obtain the ﬁnal secret data.
It should be noted that the complexity of Zhao et al.’s decoding and extraction
stage is very low, and the decoding process and the extraction process can be abso-
lutely detached.
4.5.6.4 Experimental Results
A set of experiments is carried out to evaluate the performance of Zhao et al.’s
scheme. The performance indicators used include PSNR, payload, bit rate (bit_rate),
and transmission efﬁciency. A higher PSNR indicates a better image quality. The
bit_rate means the average number of bits required for representing one pixel.
Payload stands for the maximum number of secret bits that can be embedded in
the cover image. Transmission efﬁciency is deﬁned as the ratio of payload to the
274
CHAPTER 4 Lossless Information Hiding in Vector Quantization

bitstream length. For the TSVQ-based scheme (i.e., Zhao et al.’s scheme), we take
m ¼ 2 in comparisons with previous algorithms, namely, the path optional lossless
information hiding scheme [11] and the VQIRVC-based lossless information hiding
scheme [10]. The TSVQ-based algorithm adopts the codebook size N ¼ (32,64),
whereas the two previous algorithms have the codebook size 512.
Based on six test images of size 512  512 as given in Fig. 4.22, Table 4.22 lists
the comparison results of PSNR, payload, bit rate, and efﬁciency among Zhao et al.’s
[15], Wang and Lu [11], and Lu et al.’s [10] schemes. From Table 4.22, we can see that
Zhao et al.’s scheme can obtain larger PSNR values. Also, the payload and bit rate of
Zhao et al.’s algorithm are improved to some extent. Especially, Zhao et al.’s scheme
achieves the payload twice larger than Wang et al.’s scheme and nearly four times
larger than Lu et al.’s scheme. From Table 4.22, we can also see that Zhao et al.’s
scheme obtains higher efﬁciency values than Wang et al.’s and Lu et al.’s schemes
for both n ¼ 4 and n ¼ 8. In a word, Zhao et al.’s scheme can not only improve the
payload with a higher PSNR but also enhance the transmission efﬁciency.
From this, we can conclude that the TSVQ-based algorithm enhances the perfor-
mance in three aspects. (1) Since Zhao et al.’s scheme can losslessly recover the
original index tables and secret data from the bitstream, the process of encoding
and decoding is lossless. (2) Given the two index tables, double payload of Wang
Table 4.22 Comparison of Zhao et al.’s, Wang et al.’s, and Lu et al.’s
Schemes for Six Test Images
Scheme
N
n
Indicators
Lena
F16
Peppers
Baboon
Boat
Goldhill
Zhao
et al.’s
(32,64)
4
Payload
64,008
64,008
64,008
64,008
64,008
64,008
Bit rate
0.979
0.956
0.965
1.049
0.996
0.994
Efﬁciency
0.249
0.256
0.253
0.233
0.245
0.246
8
Payload
93,744
93,744
93,744
93,744
93,744
93,744
Bit rate
1.093
1.067
1.079
1.151
1.105
1.108
Efﬁciency
0.327
0.335
0.332
0.311
0.324
0.323
e
PSNR_v
32.26
31.62
31.74
24.73
30.14
31.28
PSNR_e
32.26
31.62
31.74
24.73
30.14
31.28
Wang
et al.’s
512
4
Payload
32,004
32,004
32,004
32,004
32,004
32,004
Bit rate
0.641
0.649
0.632
0.691
0.665
0.644
Efﬁciency
0.188
0.173
0.181
0.188
0.163
0.173
8
Payload
47,250
47,250
47,250
47,250
47,250
47,250
Bit rate
0.706
0.722
0.701
0.751
0.732
0.731
Efﬁciency
0.251
0.249
0.250
0.252
0.241
0.248
e
PSNR_v
31.22
31.61
30.56
23.89
30.04
31.23
PSNR_e
31.22
31.61
30.56
23.89
30.04
31.23
Lu et al.’s
512
e
Payload
14,954
13,588
14,784
15,662
14,785
15,104
Bit rate
0.569
0.589
0.632
0.691
0.665
0.664
Efﬁciency
0.100
0.088
0.089
0.086
0.084
0.086
PSNR_v
31.22
31.61
30.56
23.89
30.04
31.23
PSNR_e
31.22
31.61
30.56
23.89
30.04
31.23
PSNR, peak signal-to-noise ratio.
4.5 Vector QuantizationeIndex CodingeBased Schemes
275

et al.’s scheme and more than four times payload of Lu et al.’s scheme can be ob-
tained in Zhao et al.’s scheme. (3) The transmission efﬁciency is greatly enhanced
with the strategy of embedding secret data in two index tables.
4.6 SUMMARY
This chapter discusses lossless information hiding schemes for VQ-compressed im-
age. These schemes can be broadly classiﬁed into two categories, i.e., information
hiding during VQ encoding and information hiding during VQ-index coding. The
ﬁrst category mainly includes MFCVQ-based and SMVQ-based schemes. The ﬁrst
category embeds information during VQ encoding, which can recover the VQ-
compressed version after extraction of the embedded information. The second cate-
gory views the index table as the cover object and embeds information during loss-
less index coding. In general, the schemes in the ﬁrst category obtain worse stego
images than index codingebased schemes. Furthermore, most of the index codinge
based schemesnot only can further compress the bit rate but also can embed larger
amount of secret information. In a word, index codingebased schemes perform bet-
ter than the algorithms in the ﬁrst category. In the second category, the TSVQ-based
scheme can embed large amount of data in the cost of a bit worse stego image qual-
ity. Since VQ is not a compression standard for images, the application ﬁeld of
VQ-based lossless information hiding may be very limited.
REFERENCES
[1] Y. Linde, A. Buzo, R.M. Gray, An algorithm for vector quantizer design, IEEE Trans-
actions on Communications 28 (1) (1980) 84e95.
[2] E.J. Delp, O.R. Mitchell, Image compression using block truncation coding, IEEE
Transactions on Communications 27 (9) (1979) 1335e1342.
[3] B. Yang, Z.M. Lu, S.H. Sun, Lossless watermarking in the VQ-compressed domain, in:
Proceedings of the 5th IASTED International Conference on Visualization, Imaging,
and Image Processing(VIIP’2005), Benidorm, Spain, September 7e9, 2005, pp.
298e303.
[4] C.C. Chang, W.C. Wu, A steganographic method for hiding secret data using side match
vector quantization, IEICE Transactions on Information and Systems E88-D (9) (2005)
2159e2167.
[5] C.C. Chang, T.C. Lu, Lossless index-domain information hiding scheme based on side-
match vector quantization, Journal of Systems and Software 79 (8) (2006) 1120e1129.
[6] C.C. Chang, W.L. Tai, C.C. Lin, A lossless information hiding scheme based on side
match vector quantization, IEEE Transactions on Circuits and Systems for Video Tech-
nology 16 (10) (2006) 1301e1308.
[7] C.C. Chang, C.Y. Lin, Lossless steganography for VQ-compressed images using side
matching and relocation, IEEE Transactions on Information Forensics and Security 1
(4) (2006) 493e501.
276
CHAPTER 4 Lossless Information Hiding in Vector Quantization

[8] C.C. Chang, W.C. Wu, Y.C. Hu, Lossless recovery of a VQ index table with embedded
secret data, Journal of Visual Communication and Image Representation 18 (3) (2007)
207e216.
[9] C.C. Chang, T.D. Kieu, W.C. Wu, A lossless data embedding technique by joint neigh-
boring coding, Pattern Recognition 42 (7) (2009) 1597e1603.
[10] Z.M. Lu, J.X. Wang, B.B. Liu, An improved lossless information hiding scheme based
on image VQ-index residual value coding, Journal of Systems and Software 82 (6)
(2009) 1016e1024.
[11] J.X. Wang, Z.M. Lu, A path optional lossless information hiding scheme based on VQ
joint neighboring coding, Information Sciences 179 (19) (2009) 3332e3348.
[12] D.H. Chu, Z.M. Lu, J.X. Wang, A high capacity lossless information hiding algorithm
based on difference coding of VQ indices, ICIC Express Letters, Part B: Applications 3
(4) (2012) 701e706.
[13] Z.M. Lu, H. Chen, F.X. Yu, Lossless information hiding based on improved vq index
joint neighboring coding, International Journal of Innovative Computing, Information
and Control 9 (9) (2013) 3851e3861.
[14] J.X. Wang, J.Q. Ni, Z.M. Lu, Hybrid matrix coding and error-correction scheme for
lossless information hiding in binary VQ index codestream, International Journal of
Innovative Computing, Information and Control 9 (6) (2013) 2021e2031.
[15] D.-N. Zhao, W.-X. Xie, Z.-M. Lu, High efﬁciency lossless information hiding for two-
stage vector quantization compressed images, Journal of Information Hiding and Multi-
media Signal Processing 5 (4) (2014) 625e641.
[16] W.J. Chen, W.T. Huang, VQ indexes compression and information hiding using hybrid
lossless index coding, Digital Signal Processing 19 (3) (2009) 433e443.
[17] Z.M. Lu, S.H. Sun, Image coding using fast correlation based VQ, Chinese Journal of
Image and Graphics 5A (6) (2000) 489e492.
[18] T. Kim, Side match and overlap match vector quantizers for images, IEEE Transactions
on Image Processing 1 (2) (1992) 170e185.
[19] Z.M. Lu, J.S. Pan, S.H. Sun, Image coding based on classiﬁed side-match vector
quantization, IEICE Transactions on Information and Systems E83-D (12) (2000)
2189e2192.
[20] Z. Sun, Y.N. Li, Z.M. Lu, Side-match predictive vector quantization, in: Lecture Notes
in Artiﬁcial Intelligence, 2005 International Workshop on Intelligent Information Hid-
ing and Multimedia Signal Processing, September 14e16, 2005, vol. 3683, Hilton Ho-
tel, Melbourne, Australia, August 2005, pp. 405e410.
[21] Z.M. Lu, S.H. Sun, Digital image watermarking technique based on vector quantisation,
Electronics Letters 36 (4) (2000) 303e305.
[22] Z.M. Lu, J.S. Pan, S.H. Sun, VQ-based digital image watermarking method, Electronics
Letters 36 (14) (2000) 1201e1202.
[23] Z.M. Lu, C.H. Liu, S.H. Sun, Digital image watermarking technique based on block
truncation coding with vector quantization, Chinese Journal of Electronics 11 (2)
(2002) 152e157.
[24] Y. Bao, Z.M. Lu, D.G. Xu, A tree-structured codebook partitioning technique for VQ-
based image watermarking, in: The 5th International Symposium on Test and Measure-
ment (ISTM’2003), Shenzhen, China, June 1e5, 2003, pp. 2541e2544.
[25] Z.M. Lu, W. Xing, D.G. Xu, S.H. Sun, Digital image watermarking method based on
vector quantization with labeled codewords, IEICE Transactions on Information and
Systems E86-D (12) (2003) 2786e2789.
References
277

[26] J. Minho, K. HyoungDo, A digital image watermarking scheme based on vector
quantisation, IEICE Transactions on Information and Systems E85-D (6) (2002)
1054e1056.
[27] A.
Makur,
S.S.
Selvi,
Variable
dimension vector
quantization
based
image
watermarking, Signal Processing 81 (4) (2001) 889e893.
[28] H.C. Huang, F.H. Wang, J.S. Pan, A VQ-based robust multi-watermarking algorithm,
IEICE Transactions on Fundamentals E85-A (7) (2002) 1719e1726.
[29] H.C. Huang, F.H. Wang, J.S. Pan, Efﬁcient and robust watermarking algorithm with
vector quantisation, Electronics Letters 37 (13) (2001) 826e828.
[30] Z.M. Lu, D.G. Xu, S.H. Sun, Multipurpose image watermarking algorithm based on
multistage vector quantization, IEEE Transactions on Image Processing 14 (6) (2005)
822e831.
[31] W. Xing, Z.M. Lu, Multipurpose image watermarking based on vector quantization in
DCT domain, in: The 5th International Symposium on Test and Measurement
(ISTM’2003), Shenzhen, China, June 1e5, 2003, pp. 2057e2061.
[32] C.C. Chang, Y.C. Chou, Y.P. Hsieh, Search-order coding method with indicator-
elimination property, Journal of Systems and Software 82 (2009) 516e525.
[33] B. Chen, G.W. Wornell, Quantization index modulation: a class of provably good
methods for digital watermarking and information embedding, IEEE Transactions on
Information Theory 47 (4) (2001) 1423e1443.
[34] J. Tian, Lossless watermarking by difference expansion, in: Proceedings of Workshop
on Multimedia and Security, Dec. 2002, pp. 19e22.
[35] B. Yang, M. Schmucker, W. Funk, C. Busch, S. Sun, Integer DCT-based lossless water-
marking for images using companding technique, in: Proc. SPIE-EI, San Jose, USA,
2004.
[36] G. Xuan, C. Yang, Y. Zhen, Y. Shi, Z. Ni, Lossless information hiding using integer
wavelet transform and companding technique, IWDW (2004).
[37] M. Thodi, J.J. Rodrı´guez, Lossless watermarking by prediction-error expansion, in: The
6th IEEE Southwest Symposium on Image Analysis and Interpretation, Lake Tahoe,
USA, March 2004.
[38] B. Yang, M. Schmucker, X. Niu, C. Busch, S. Sun, Approaching optimal value expan-
sion for lossless watermarking, in: ACM Multimedia and Security Workshop 2005,
New York, USA, 2005.
278
CHAPTER 4 Lossless Information Hiding in Vector Quantization

Lossless Information
Hiding in Block Truncation
CodingeCompressed
Images
5
5.1 BLOCK TRUNCATION CODING
5.1.1 ORIGINAL BLOCK TRUNCATION CODING ALGORITHM
Block truncation coding (BTC) is a simple lossy image compression technique to
compress monochrome image data, originally introduced by Delp and Mitchell
[1]. It achieves 2 bits per pixel (bpp) with low computational complexity. The key
idea of BTC is to perform moment-preserving quantization for each nonoverlapping
block of pixels so that the image quality will remain acceptable and simultaneously
the demand for the storage space will decrease. The quantizer of the original algo-
rithm of BTC retains standard arithmetic mean and standard deviation for each
nonoverlapping block as 1-bit quantized output. The statistical overhead is that
each block needs to keep mean and standard deviation. The BTC algorithm can
be illustrated as follows:
After dividing a 256-grayscale image into blocks of size  n (typically n ¼ 4),
the blocks are coded individually, each into a two-level signal. The levels for each
block are chosen such that the ﬁrst two sample moments are preserved. Let
m ¼ n2 and let x1, x2,.,xm be the values of the pixels in a block of the original image.
Then the ﬁrst moment x, the second moment x2 and the variance s2 can be calcu-
lated as follows:
x ¼ 1
m
X
m
i¼1
xi
(5.1)
x2 ¼ 1
m
X
m
i¼1
x2
i
(5.2)
s2 ¼ x2  ðxÞ2
(5.3)
CHAPTER
Lossless Information Hiding in Images. http://dx.doi.org/10.1016/B978-0-12-812006-4.00005-X
Copyright © 2017 Zhejiang University Press Co., Ltd., published by Elsevier Inc. All rights reserved.
279

As with the design of any 1-bit quantizer, we ﬁnd a threshold, xth, and two output
levels, a and b, such that
 if xi  xth
output ¼ b
if xi < xth
output ¼ a
(5.4)
In the original BTC, we set xth ¼x, then the output levels a and b are found by
solving the following equations. Let q ¼ number of xi’s greater than xthð¼ xÞ, to pre-
serve x and x2, we have
(
mx ¼ ðm  qÞa þ qb
mx2 ¼ ðm  qÞa2 þ qb2
(5.5)
Solving for a and b:
8
>
>
>
>
>
<
>
>
>
>
>
:
a ¼ x  s
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
q
m  q
r
b ¼ x þ s
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
m  q
q
r
(5.6)
Each block is then described by the values of a, b and an n  n bitplane P con-
sisting of 1s and 0s indicating whether the pixels are above or below xth. For n ¼ 4,
assigning 8 bits each to a and b results in a data rate of 2 bits per pixel. The receiver
reconstructs the image block by calculating a and b from Eq. (5.6) and assigning
these values to pixels in accordance with the code in the bitplane. An example of
coding a 4  4 image block is presented in Fig. 5.1.
From this description, we can see that, in the original BTC, for each block we
have to compute the value of a and b. So it is time consuming. To overcome the
this problem, Lema and Mitchell introduced the concept of absolute moment block
truncation as given in the next subsection.
121
114
56
47
37
200
247
255
16
0
12
169
43
5
7
251
=
x
1
1
0
0
0
1
1
1
0
0
0
1
0
0
0
1
=
P
204
204
17
17
17
204
204
204
ˆ
17
17
17
204
17
17
17
204
=
x
Original
Bitplane
Reconstructed
98.75,
,
x
q = 7
σ
=
= 92.95
17,b = 204.2
204
a = 16.7 ≅
≅
FIGURE 5.1
Block truncation coding by the triple (a, b, P).
280
CHAPTER 5 Lossless Information Hiding in BTCeCompressed Images

5.1.2 ABSOLUTE MOMENT BLOCK TRUNCATION CODING
In the original absolute moment block truncation coding (AMBTC) method, the image
is ﬁrst divided into blocks of size m ¼ 4  4. The pixels in each block are individually
quantized into two-level outputs in such a way that the mean value and the ﬁrst
absolute central moment are preserved in the reconstructed block. The mean value
of pixels in each block x is taken as the 1-bit quantizer threshold xth, i.e.,
xth ¼ 1
m
X
m
i¼1
xi
(5.7)
The two output quantization level values are directly calculated from
a ¼
1
m  q
X
xixth
xi
(5.8)
b ¼ 1
q
X
xi>xth
xi
(5.9)
where a and b denote the lower and higher means of block x, respectively and q
stands for the number of pixels having value higher than the mean value. If q ¼ 0,
one can deﬁne a ¼ b ¼ xth. Then a two-level quantization is performed for all the
pixels in the block to form a bitplane so that “0” is stored for the pixels with values
not larger than the mean and the rest of the pixels are presented by “1.” The image is
reconstructed at the decoding phase from the bitplane by assigning the value a to “0”
and b to “1.” Thus a compressed block appears as a triple (a,b, P), where a, b, and P
denote the lower mean, the higher mean, and the bitplane, respectively. Fig. 5.2
shows an example of a compressed image block by AMBTC, and Fig. 5.3 shows
the AMBTC-compressed Lena image with peak signal-to-noise ratio (PSNR) ¼
32.041 dB.
AMBTC is very fast, is easy to implement, and has low computational demands.
It preserves the quality of the reconstructed image and retains the edges. However, in
the AMBTC, the lower and higher means are coded separately with 8 bits each, and
the bitplane needs 16 bits, so the bit rate of AMBTC is 2 bits/pixel. How to reduce
121
114
56
47
37
200
247
255
16
0
12
169
43
5
7
251
x =
x = 98.75,q = 7
a = 24.78≅25,b=193.86≅194
1
1
0
0
0
1
1
1
0
0
0
1
0
0
0
1
=
P
194
194
25
25
25
194
194
194
ˆ
25
25
25
194
25
25
25
194
=
x
Original
Bitplane
Reconstructed
FIGURE 5.2
Absolute moment block truncation coding by the triple (a, b, P).
5.1 Block Truncation Coding
281

the bit rate and at the same time losslessly embed secret information is our main
concern in this chapter.
5.2 OVERVIEW OF BLOCK TRUNCATION CODINGeBASED
INFORMATION HIDING
In the 2000s, several watermarking and data hiding schemes for BTC-compressed
gray-level images have been proposed. We overview them in two categories, i.e.,
watermarking schemes and lossless information hiding schemes.
5.2.1 OVERVIEW OF BLOCK TRUNCATION CODINGeBASED IMAGE
WATERMARKING
The ﬁrst watermarking method [3] based on BTC was proposed by Lu et al. in 2002,
where the robust watermark is embedded by modifying the vector quantization
(VQ)-BTC encoding process according to the watermark bits. In 2004, Lin and
Chang [4] proposed a data hiding scheme for BTC-compressed images by perform-
ing least signiﬁcant bit (LSB) substitution operations on BTC high and low means
and performing the minimum distortion algorithm on BTC bitplanes. In 2006,
Chuang and Chang proposed a hiding scheme to embed data in the BTC bitplanes
of smooth regions [5]. In 2011, Yang and Lu proposed a fragile image watermarking
scheme [6] whose main idea is to apply VQ or BTC to encode each block according
to the watermark bit. In the same year, Yang and Lu also proposed another blind
semifragile image watermarking scheme [7] by using BTC to guide the watermark
embedding and extraction processes. The central idea is to force the number of “1s”
FIGURE 5.3
Absolute moment block truncation coding (AMBTC) on Lena image. (a) Original image
and (b) AMBTC-reconstructed image.
282
CHAPTER 5 Lossless Information Hiding in BTCeCompressed Images

(or “0s”) in each bitplane to be odd for the watermark bit “1” or to be even for the
watermark bit “0.” In 2012, Zhang et al. proposed an oblivious image watermarking
scheme [8] by exploiting BTC bitmaps. Unlike the traditional schemes, this
approach does not really perform the BTC compression on images during the
embedding process but utilizes the parity of the number of horizontal edge transi-
tions in each BTC bitmap to guide the watermark embedding and extraction pro-
cesses. In the following subsections, we introduce several typical BTC-based
watermarking schemes.
5.2.1.1 Chuang and Chang’s Scheme
It is well known that for the smooth block xi whose ai and bi are highly close, its
bitplane pi will be less signiﬁcant in the AMBTC decoding process. In this case,
some suitable locations in pi may be replaced with the secret bit. Based on this
idea, Chuang and Chang [5] proposed the data hiding scheme for BTC-
compressed images that embeds data in the smooth blocks’ bitplanes.
The embedding process can be divided into two steps. The ﬁrst step segments the
image into blocks and computes the quantized data for each block, and the second
step embeds the secret data in the bitplanes of smooth blocks that are determined by
the difference between bi and ai. If biai is not greater than the preset threshold TH,
then the block xi is classiﬁed as a smooth block; otherwise, the block is a complex
block. The embedding method is very simple, i.e., a suitable location in the smooth
block’s bitplane pi is selected to be replaced with the secret bit. The smooth blocks
are selected because even after the bit replacement in their bitplanes, less distortion
will be introduced in the BTC-compressed image.
The extraction process is also very simple. From each compressed BTC block,
the difference biai is ﬁrst calculated, and then whether the difference is less than
TH or not is determined. Once conﬁrmed, the secret bit in the bitplane pi is extracted.
One obvious drawback of Chuang and Chang’s scheme is that the capacity is deter-
mined by the number of smooth blocks. In the embedding process, the threshold TH
is used to select the embeddable locations. The higher the threshold value is, the
more data may be hidden, but the more distortion will be introduced.
5.2.1.2 Yang and Lu’s Method 1
Yang and Lu [6] proposed a very simple BTC-domain watermarking scheme. Let X
be a 512  512-sized original image, and W be a 128  128-sized binary water-
mark, which can be viewed as a 16,384-lengthed binary string W ¼ {wi,
i ¼ 1,2,.,16,384}. The VQ codebook C contains 1024 codewords ci, i ¼ 1,
2,.,1024, each being a 4  4-sized block. Their embedding procedure can be
detailed as follows: the original image X is ﬁrst divided into non-overlapping blocks
of size 4  4, denoted as xi, i ¼ 1, 2,.,16,384. For each image block xi, if the water-
mark bit to be embedded wi ¼ 1, then VQ is used to encode the block xi by searching
its best-matched codeword cj in the codebook C, satisfying
dðxi; cjÞ ¼
min
1l1024 dðxi; clÞ
(5.10)
5.2 Overview of Block Truncation CodingeBased Information Hiding
283

where d(xi, cl) denotes the Euclidean distance between the input vector xi and the
codeword cl. If the watermark bit to be embedded wi ¼ 0, then the AMBTC is
used to encode the block xi by replacing the pixels that are not less than the mean
value mi with the high mean bi and replacing the pixels that are smaller than the
mean value mi with the low mean ai. Finally, all encoded image blocks are pieced
together to obtain the ﬁnal watermarked image Xw.
The extraction process is just the reverse process of the embedding process. Let
Y be a 512  512-sized suspicious image to be detected, and C contain 1024 code-
words ci, i ¼ 1, 2,.,1024, each being a 4  4-sized block. The extraction procedure
can be described in detail as follows: the suspicious image Y is ﬁrst divided into
nonoverlapping blocks of size 4  4, denoted as yi, i ¼ 1, 2,.,16,384. For each im-
age block yi, it is encoded with VQ and BTC to obtain their corresponding mean
squared error (MSE) MSEVQ and MSEBTC, respectively. If MSEVQ < MSEBTC,
then the extracted watermark wi ¼ 1. If MSEVQ > MSEBTC, then the extracted
watermark bit wi ¼ 0. If MSEVQ ¼ MSEBTC, then wi is randomly set to be 0 or 1.
All obtained watermark bits are pieced together to obtain the ﬁnal extracted water-
mark We.
5.2.1.3 Yang and Lu’s Method 2
From the previous sections, we saw that Chuang and Chang’s scheme [5] and Yang
and Lu’s method 1 [6] actually embed the watermark or hide the information in the
BTC-compressed image or VQ-compressed image. Thus, the stego image or the
watermarked image is usually of a poor quality. To improve the image quality while
preserving the embedding capacity, Yang and Lu (the author of this book) provide a
new train of thought [7], where we still utilize the BTC, but we do not perform the
watermark embedding on the BTC-compressed image. Here, BTC is only used to
guide the watermark embedding and extraction process. Yang and Lu’s method 2
consists of three processes, i.e., the preprocessing stage, the watermark embedding
stage, and the watermark extraction stage.
5.2.1.3.1 Preprocessing
The preprocessing stage is the common stage for watermark embedding and extrac-
tion processes. The aim of this stage is to obtain the BTC bitplanes as the control
parameter. To explain the watermarking scheme more intuitively, assume the input
image X (or Y) is 512  512 sized, the block size is 4  4, and the watermark W is
128  128-sized binary image. Thus, the preprocessing stage is just a BTC coding
process as follows:
Step 1: The input image X (or Y) is divided into nonoverlapping 4  4-sized
blocks xi (or yi), i ¼ 1, 2,.,16,384.
Step 2: Each image block xi (or yi) is encoded by AMBTC, obtaining its bitplane pi.
Step 3: All bitplanes are composed to obtain the bitplane sequence
P ¼ {pi ji ¼ 1,2,.,16,384}.
284
CHAPTER 5 Lossless Information Hiding in BTCeCompressed Images

5.2.1.3.2 Watermark Embedding
With the bitplanes P ¼ {pi ji ¼ 1,2,.,16,384} in hand as the guider, now we turn to
the watermark embedding process. Before embedding, the raster scanning is per-
formed on the original watermark W, obtaining the watermark bit sequence
W ¼ (w1, w2,.,w16,384). The purpose of this embedding process is to ensure the
blind extraction such that we can extract the watermark from the watermarked image
only based on its bitplane information. The central idea is to force the number of
“1s” (or “0s”) in each bitplane to be odd for the watermark bit “1” or to be even
for the watermark bit “0.” The embedding process can be illustrated in detailed as
follows:
Step 1: The original image X is divided into nonoverlapping 4  4-sized blocks
xi, i ¼ 1, 2,.,16,384.
Step 2: The embedding process is performed block by block. For each block xi,
the embedding procedure is controlled by the bitplane pi as the following
substeps.
Step 2.1: The number of “1s” in pi is counted and denoted as qi. Obviously,
according to the deﬁnition of qi as mentioned in Eqs. (5.7) and (5.8), for a
k ¼ 4  4-sized block, we have 1  qi  16.
Step 2.2: We ﬁnd all the pixels in xi that correspond to “1” in the bitplanes, and
then arrange them in descending order, obtaining a “high: set H. In the set H, we
denote the last element as min1. That is, min1 is the minimal pixel that is not less
than the mean value mi of xi.
Step 2.3: Similarly, we ﬁnd all the pixels in xi that correspond to “0s” in the
bitplanes, and then arrange them in descending order, obtaining a “low” set L. In
the set L, we denote the ﬁrst element as max0 and the last element as min0. That
is, max0 is the maximal pixel that is less than the mean value mi, whereas min0 is
the minimal pixel that is less than the mean value mi.
Step 2.4: We check the parity of qi and compare it with the watermark bit wi.
Here, we deﬁne Parity(qi) ¼ 1 if qi is an odd number and Parity(qi) ¼ 0 if qi is
an even number. If Parity(qi) ¼ wi, we do not change any pixel in the block xi,
which can be summarized as Eq. (5.11), and go to Step 3. Otherwise, we go to
Step 2.5.
xi is not changed
ðParityðqiÞ ¼ wiÞ
(5.11)
Step 2.5: We change some pixels in xi to force the number of “1s” (or “0s”) in the
renewed bitplane to be odd for the watermark bit “1” or to be even for the
watermark bit “0.” There are two cases:
Case 1: qi ¼ 16. In this case, Parity(qi) ¼ 0 and wi ¼ 1. In fact, this case corre-
sponds to a block with uniform pixel values. Thus, we only need to randomly
select a pixel and modify it. If the selected pixel is larger than u, we subtract a
proper positive integer u from this pixel. Otherwise, we add a proper positive
integer u to this pixel. Here, we adopt u ¼ 4. Assume we select the ﬁrst pixel
5.2 Overview of Block Truncation CodingeBased Information Hiding
285

(this process can be determined by a key), then we can summarize the modi-
ﬁcation rule for this case as:
 xi1)xi1 þ u
xi1  u
xi1)xi1  u
xi1 > u
ðqi ¼ 16; wi ¼ 1Þ
(5.12)
Case 2: qi < 16. In this case, we should consider two subcases according to the
sum “min1 þ max0.” In the ﬁrst subcase, Parity(min1 þ max0) ¼ 0, we perform
the following modiﬁcation rule:
min1; max0)ðmin1 þ max0Þ=2
ðqi < 16 and ParityðqiÞswi and Parityðmin1 þ max0Þ ¼ 0Þ
(5.13)
That is, we replace the original min1 and max0 in the block xi with their mean
value (here, if there is more than one pixel with the same value of min1 or max0,
then we can randomly select one among them by a key). By this way, we do not
change the mean value mi of the block xi, but the number of “1s” in the renewed
bitplane will either increase or decrease by 1. In the second subcase,
Parity(min1 þ max0) ¼ 1; in order not to change the mean value mi of xi, we
perform the following modiﬁcation rule:
(
min1; max0)ðmin1 þ max0  1Þ=2
min0)min0 þ 1
ðqi < 16 and ParityðqiÞswi and Parityðmin1 þ max0Þ ¼ 1Þ
(5.14)
From Eq. (5.14), we can see that the sum “min1 þ max0 þ min0” is not
changed after modiﬁcation, thus the mean value mi is unchanged, but the number
of “1s” in the renewed bitplane will either increase or decrease by 1.
Step 3: Steps 2.1e2.5 are performed on following blocks. If all blocks have been
embedded with watermark bits, then the algorithm is terminated. Otherwise, go
to Step 2.1.
From these steps, we can see that the embedding process modiﬁes at most three
pixels in each original image block, thus the watermarked image should be very
similar to the original one.
5.2.1.3.3 Watermark Extraction
The watermark extraction process is a blind process such that we do not require the
original image in the extraction process. It is very simple because we can get the
watermark bit only based on checking the parity of qi (the number of “1s” in each
bitplane pi). Before extraction, the same preprocessing step is performed on the sus-
picious image Y to obtain its bitplane sequence P ¼ {pi ji ¼ 1,2,.,16,384}. For
each block yi, If the number of “1s” in the bitplane pi is odd, then we can extract
286
CHAPTER 5 Lossless Information Hiding in BTCeCompressed Images

the watermark bit “1.” Otherwise, we can extract the watermark bit “0.” This rule can
be described as follows:
 wei ¼ 1
ParityðqiÞ ¼ 1
wei ¼ 0
ParityðqiÞ ¼ 0
(5.15)
After all blocks are performed, we piece these bits together to obtain the ﬁnal
extracted watermark We ¼ {we1,we2,.,we16,384}.
5.2.1.4 Zhang et al.’s Method
The existing BTC-based watermarking or hiding approaches essentially embed the
secret data in the BTC-compressed image. Thus, the watermarked image usually has
a poor quality, at most the same as the BTC-compressed image. To increase the im-
age quality while preserving the embedding capacity, Yang and Lu [7] have provided
a new train of thought. That is, we still apply the BTC technique. However, instead
of embedding the watermark in the BTC compressed image, similar to Yang and
Lu’s method [7], Zhang et al. [8] also exploited the BTC bitmap to guide the water-
mark embedding and extraction process as follows.
5.2.1.4.1 Watermark Embedding
Assume the cover image X consists of N blocks and the watermark is a binary image
W with N bits. Before embedding, we perform the following preprocessing steps:
Step 1: Perform the raster scanning on the original watermark W to obtain the
watermark bit sequence W ¼ (w1, w2,.,w2N).
Step 2: Divide the input image X (or Y) into nonoverlapping k-dimensional
blocks xi (or yi), i ¼ 1, 2,.,N.
Step 3: Encode each image block xi (or yi) by AMBTC to obtain its mean value
mi and its bitmap bi.
Step 4: All bitmaps are composed of the bitmap sequence B ¼ {biji ¼ 1, 2,.,N}.
With the bitmaps B ¼ {bi ji ¼ 1,2,.,N} in hand as the guider, now we can
describe the watermark embedding process. The purpose of the embedding process
is to ensure blind extraction so that we can extract the watermark from the water-
marked image only based on its bitmap. The central idea is to force the parity of
the number of horizontal edge transitions in bi to be equal to the watermark bit.
That is, we embed one watermark bit in each block.
The embedding process can be illustrated in detail as follows:
Step 1: The original image X is segmented into nonoverlapping k-dimensional
blocks xi, i ¼ 1, 2,.,N.
Step 2: The embedding process is performed block by block. For each block xi,
the watermark bit to be embedded is wi, and the embedding procedure is
controlled by the bitmap bi in following substeps.
Substep 2.1: Count the number of horizontal edge transitions (from 0 to 1 or from
1 to 0) in bi, and denote it by ni. For example, for the block in Fig. 5.1, we have
5.2 Overview of Block Truncation CodingeBased Information Hiding
287

ni ¼ 4. Deﬁne Parity(ni) ¼ 1 if ni is an odd number and Parity(ni) ¼ 0 if ni is an
even number. Count the number of pixels corresponding to “1” and denote it by
qi; thus the number of pixels corresponding to “0” is k-qi. Obviously, we have
1  qi  k.
Substep 2.2: If Parity(ni) ¼ wi is satisﬁed, we do not change any pixel in the
block xi, and go to Step 3. Otherwise, go to Substep 2.3.
Substep 2.3: If li < hi, go to Substep 2.4. Otherwise, we have a special case
li ¼ hi ¼ mi (equivalently, qi ¼ k). In fact, this case corresponds to a block with
uniform pixel values. Simply select the ﬁrst pixel xi1 and modify it based on
Eq. (5.16), and go to Step 3.

bxi1 ¼ xi1 þ 4
xi1  4
bxi1 ¼ xi1  4
xi1 > 4
(5.16)
Substep 2.4: It is well known that if we increase or decrease the number of
horizontal edge transitions by 1, then the parity of ni will be changed. Based on
this idea, we only need to scan the block xi row by row to ﬁnd a suitable row in
which the modiﬁcation of pixels will introduce less distortion. For k ¼ 4  4,
there are 16 row patterns as shown in the ﬁrst column of Table 5.1. To increase
or decrease the number of horizontal edge transitions by 1, the candidate
resulting patterns are shown in the second column of Table 5.1. From each case
Table 5.1 The Candidate Changes in Edge
Transitions for the 16 Row Patterns for k ¼ 4  4
The Original
Row Pattern
The Candidate Resulting
Row Patterns
0000
1000,0001
0001
1001,0000
0010
1010,0011
0011
1011,0010
0100
1100,0101
0101
1101,0100
0110
1110,0111
0111
1111,0110
1000
0000,1001
1001
0001,1000
1010
0010,1011
1011
0011,1010
1100
0100,1101
1101
0101,1100
1110
0110,1111
1111
0111,1110
288
CHAPTER 5 Lossless Information Hiding in BTCeCompressed Images

in Table 5.1, we can ﬁnd that we only need to change the ﬁrst bit or the last bit in
a row to achieve our goal. For example, for “0000,” we only need to change it
into “1000” or “0001” to increase the number of edge transitions by 1. Based on
this idea, we ﬁrst ﬁnd all the rows whose ﬁrst and last bits are different, i.e.,
whose row pattern is “0.1” or “1.0,” where “x” denotes the bit we do
not care about. For the ﬁrst and last pixels in the row with pattern “0.1” or
“1.0,” we denote the pixel value corresponding to 1 by v1 and the pixel
value corresponding to 0 by v0. If we can ﬁnd one or more such rows, then we
select the row with the least value of v1v0, and we change this row based on
either of the following two rules Eqs. (5.17) and (5.18):
8
>
<
>
:
bv1 ¼ bv0 ¼ ðv1 þ v0Þ=2
if v1 þ v0 is even
bv1 ¼ bv0 ¼ ðv1 þ v0 þ 1Þ=2; bvmax0 ¼ vmax0  1
if v1 þ v0 is odd and vmax0 > 0
bv1 ¼ bv0 ¼ ðv1 þ v0 þ 1Þ=2
if v1 þ v0 is odd and vmax0 ¼ 0
(5.17)
or
8
>
<
>
:
bv1 ¼ bv0 ¼ ðv1 þ v0Þ=2
if v1 þ v0 is even
bv1 ¼ bv0 ¼ ðv1 þ v0  1Þ=2; bvmin1 ¼ vmin1 þ 1
if v1 þ v0 is odd and vmin1 < 255
bv1 ¼ bv0 ¼ ðv1 þ v0  1Þ=2
if v1 þ v0 is odd and vmin1 ¼ 255
(5.18)
where vmax0 denotes the maximal pixel value corresponding to “0” in the block xi
excluding v0, while vmin1 denotes the minimal pixel value corresponding to “1” in
the block xi excluding v1. If we cannot ﬁnd the pattern “0.1” or “1.0,”
we must have found the pattern “0.0” or “1.1.” In this case, assume we
can ﬁnd a row with a bit in the middle different from the ﬁrst bit, and then denote
the corresponding pixel value by vm, the ﬁrst pixel value by vf, and the last pixel
value by vl. Then we just exchange vf with vm or exchange vl with vm, depending
on which exchange will result in less distortion. On the other hand, if we cannot
ﬁnd these kinds of rows, we must have met the extreme case where each row is
either “00.00” or “11.11,” and then we select two pixels: one is the ﬁrst pixel
v0 from one of the rows with pattern “00.00,” and the other is the ﬁrst pixel v1
from one of the rows with pattern “11.11.” Finally, we use Eq. (5.17) or Eq.
(5.18) to modify them.
Step 3: If every block has been embedded with one watermark bit, then the al-
gorithm is terminated with the watermarked image Xw. Otherwise, go to Step
2.1 for next block.
5.2.1.4.2 Watermark Extraction
Our watermark extraction process is very simple. Before extraction, we perform the
following preprocessing steps:
Step 1: The suspicious image Y is divided into nonoverlapping k-dimensional
blocks yi, i ¼ 1, 2,.,N.
5.2 Overview of Block Truncation CodingeBased Information Hiding
289

Step 2: Each image block yi is encoded by AMBTC, obtaining its mean value mi
and its two quantization levels li and hi.
Step 3: All bitmaps are composed of the bitmap sequence B ¼ {biji ¼ 1, 2,.,N}.
With the bitmaps B ¼ {bij i ¼ 1,2,.,N } in hand as the guider, now we can
describe our watermark extraction process. The watermark extraction process is
an oblivious process and therefore we no longer require the original image during
the extraction process. For each block yi, if the number of horizontal edge transitions
(from 1 to 0 or from 0 to 1) ni in bi is odd, then we can extract the watermark bit
wi ¼ 1. Otherwise, we can extract the watermark bit wi ¼ 0. After all the blocks
are performed, we piece these bits together to obtain the ﬁnal extracted watermark
We ¼ {we1, we2,., weN}.
5.2.2 OVERVIEW OF BLOCK TRUNCATION CODINGeBASED
LOSSLESS INFORMATION HIDING
The ﬁrst reversible data hiding scheme for BTC-compressed gray-level images was
proposed in 2008 by Hong et al. [9]. In their work, the secret data are embedded by
toggling or preserving the BTC bitplane according to the secret bit and the relation-
ship between the high mean and low mean. Although this scheme is reversible, when
the high mean equals the low mean, there will be some problem in secret data extrac-
tion. To overcome this problem, Chen et al. [10] has recently proposed an improved
reversible hiding scheme. In their work, the difference between the high mean and
low mean for each block is used to determine whether only to hide 1-bit secret bit for
the block or to toggle bits in the bitplane to hide more bits.
To improve the hiding capacity, in 2011, Chen et al. proposed two high-capacity
reversible data hiding scheme for BTC-compressed color images [11,12]. In the
same year, Li et al. proposed a reversible data hiding scheme [13] for BTC-
compressed images based on bitplane ﬂipping and histogram shifting of mean tables
and Luo et al. proposed a joint secret sharing and data hiding for BTC-compressed
image transmission [14]. In 2012, Wang et al. presented a reversible data hiding
scheme for BTC-compressed images based on prediction-error expansion [15]. In
2013, Zhang et al. proposed a reversible data hiding scheme for BTC-compressed
images based on lossless coding of mean tables [16]. In the same year, Sun et al. pro-
posed a high-performance reversible data hiding for BTC-compressed images [17].
From next section, we will introduce the aforementioned techniques in detail,
which are divided into three classes, bitplane ﬂippingebased schemes for BTC com-
pressed grayscale images, mean codingebased schemes for BTC-compressed gray-
scale images, and lossless data hiding in BTC-compressed color images.
5.3 BITPLANE FLIPPINGeBASED LOSSLESS HIDING
SCHEMES
In this section, we introduce the ﬁrst reversible data hiding scheme for BTC-
compressed gray-level images proposed by Hong et al. [9], and its improved scheme
290
CHAPTER 5 Lossless Information Hiding in BTCeCompressed Images

by Chen et al. [10]. Then, the reversible data hiding scheme [13] for BTC-
compressed images based on bitplane ﬂipping together with histogram shifting of
mean tables is introduced, which is proposed by the author of this book.
Here, the original AMBTC method is used in all these methods, assuming that
the
M  N-sized
256-gray-level
image
X
is
divided
into
nonoverlapping
m  n-sized blocks, i.e., X ¼ {x(ij), 1  i  M/m, 1  j  N/n}. The pixels in each
block are individually quantized into two-level outputs in such a way that the
mean value and the ﬁrst absolute central moment are preserved in the reconstructed
block. The mean value of pixels in each block xðijÞ ¼
n
xðijÞ
uv ; 1  u  m; 1  v  n
o
is taken as the 1-bit quantizer threshold tij, i.e.,
tij ¼
1
m  n
X
m
u¼1
X
n
v¼1
xðijÞ
uv
(5.19)
The two output quantization level values are calculated as
lij ¼
8
>
>
>
<
>
>
>
:
1
m  n  qij
X
xðijÞ
uv <tij
xðijÞ
uv
qij < m  n
tij
qij ¼ m  n
(5.20)
hij ¼ 1
qij
X
xðijÞ
uv tij
xðijÞ
uv
(5.21)
where lij and hij denote the low and the high means of block x(ij), respectively, and qij
stands for the number of pixels having a value not less than the mean value tij. If
qij ¼ m  n, we have lij ¼ hij ¼ tij. Then a two-level quantization is performed for
all the pixels in the block to form a bitplane pij such that “0” is stored for the pixels
with values less than the mean and the rest of the pixels are presented by “1.” The
image is reconstructed at the decoding phase from the bitplane by assigning
the value lij to “0” and hij to “1.” Thus a compressed block appears as a triple
(lij, hij, pij), where lij, hij and pij denote the low mean, the high mean, and the bitplane
of block x(ij), respectively. In fact, if we gather all high means of all blocks, we can
obtain a matrix that is called high mean table H ¼ {hij, 1  i  M/m, 1  j  N/n} in
this chapter. Similarly, we can obtain the low mean table L ¼ {lij, 1  i  M/m,
1  j  N/n} by gathering all low means, whereas all bitplanes can construct a
bitplane sequence P ¼ {pij, 1  i  M/m, 1  j  N/n}.
5.3.1 ORIGINAL BITPLANE FLIPPINGeBASED SCHEME
As we know, if we exchange lij and hij in the compressed triple of block x(ij), we only
need to ﬂip the bitplane pij into pij to obtain the same reconstructed block. Based on
this idea, Hong et al. proposed a reversible data hiding scheme [10] based on bit-
plane ﬂipping according to the corresponding secret bit.
5.3 Bitplane FlippingeBased Lossless Hiding Schemes
291

The embedding process of Hong et al.’s scheme can be illustrated as follows.
First, each image block is compressed by AMBTC resulting in the compressed codes
(lij, hij, pij). Second, all embeddable blocks with lij < hij are found, that is to say, the
block with lij ¼ hij is nonembeddable. Third, for each embeddable block, if the bit to
be embedded is “1,” then the compressed code is changed from (lij, hij, pij) into

hij; lij; pij

. Otherwise, if the bit to be embedded is “0,” then no operation is
required. In other words, the secret bit “0” corresponds to the code (lij, hij, pij)
and the secret bit “1” corresponds to the code

hij; lij; pij

.
The secret data extraction process is very simple. Assume we receive the code
(l’ij, h’ij, p’ij), then we only need to judge the relationship between l’ij and h’ij. If
l’ij > h’ij, then the secret bit is 1; if l’ij < h’ij, the secret bit is 0; otherwise, no secret
bit is embedded. Although Hong et al.’s scheme [10] is reversible, it does not
consider hiding data in the blocks with lij ¼ hij.
5.3.2 IMPROVED BITPLANE FLIPPINGeBASED SCHEME
To embed secret data in the blocks with lij ¼ hij, Chen et al. proposed an improved
reversible data hiding algorithm [11] by introducing Chuang and Chang’s bitplane
replacement idea to deal with the case lij ¼ hij in Hong et al.’s bitplane ﬂipping
scheme. The purpose of this scheme is to increase the payload compared with
Hong et al.’s bitplane ﬂipping scheme while improving the stego image quality
compared with Chuang and Chang’s scheme.
The embedding process of Chen et al.’s scheme can be illustrated as follows:
each image block is compressed by AMBTC resulting in the compressed codes
(lij, hij, pij). For each block with lij < hij, if the bit to be embedded is “1,” then the
compressed code is changed from (lij, hij, pij) into

hij; lij; pij

. Otherwise, if the
bit to be embedded is “0,” then no operation is required. For the block with
lij ¼ hij, since the bitplane has no use in the reconstruction process, the whole bit-
plane can be replaced with m  n secret bits.
The secret data extraction process is also very simple. Assume we receive the
code (l’ij, h’ij, p’ij), we only need to judge the relationship between l’ij and h’ij. If
l’ij > h’ij, then the secret bit is 1; if l’ij < h’ij, the secret bit is 0; otherwise, all
m  n bits in the bitplane p’ij are extracted as the secret bits. Obviously, the
improved scheme can increase the payload compared with the original scheme.
5.3.3 BITPLANE FLIPPINGeBASED SCHEME WITH HISTOGRAM
SHIFTING OF MEAN TABLES
From the previous section, we can see that Hong et al.’s bitplane ﬂipping scheme and
Chen et al.’s scheme can embed 1-bit information per block if there is no block with
lij ¼ hij. To embed more secret bits, after using Chen et al.’s scheme, we can further
compose all high/low means as a high/low mean table and then introduce the
292
CHAPTER 5 Lossless Information Hiding in BTCeCompressed Images

histogram shifting technique to high and low mean tables. Our algorithm [13] con-
sists of three stages, i.e., the AMBTC compression stage, the data hiding stage, and
the data extraction and image recovery stage, which can be illustrated as follows.
5.3.3.1 The Absolute Moment Block Truncation Coding Compression Stage
This stage is a preprocessing stage before data hiding. The aim of this stage is to
obtain the two mean tables and the bitplane sequence for later use. Given an
M  N-sized 256-grayscale original image X, this stage can be expressed as follows:
Step 1: The original image X is divided into nonoverlapping m  n-sized blocks
x(ij), i ¼ 1, 2,., M/m, j ¼ 1, 2, ., N/n.
Step 2: Encode each image block x(ij) by AMBTC, obtaining the compressed
triple (lij, hij, pij).
Step 3: Compose all high and low means to obtain the high mean table
H ¼ {hij ji ¼ 1,2,.,M/m; j ¼ 0,1,.,N/n} and the low mean table
L ¼ {lij ji ¼ 1,2,.,M/m; j ¼ 0,1,.,N/n}, respectively. Similarly, compose
all bitplanes to obtain the bitplane sequence P ¼ {pij ji ¼ 1,2,.,M/m;
j ¼ 0,1,.,N/n}.
5.3.3.2 The Data Hiding Stage
With the mean tables H and L and the bitplane sequence P in hand, now we can
introduce our reversible data hiding algorithm. Assume the secret bit sequence to
be embedded is W ¼ {w1,w2,.}. Before embedding, we perform the permutation
operation on the secret bit sequence to enhance the security. Our embedding method
is performed in two main steps, i.e., bitplane ﬂipping and histogram shifting, which
can be illustrated in detailed as follows:
Step 1: We ﬁrst perform the bitplane ﬂipping technique on H, L, and P to embed
the ﬁrst part of secret bits. For each image block with lij < hij, if the bit to be
embedded is “1,” then the element hij in H and the element lij in L are swapped,
and the bitplane pij in P is replaced by pij. Otherwise, if the bit to be embedded is
“0,” then no operation is required. For the block with lij ¼ hij, since the bitplane
has no use in the reconstruction process, the whole bitplane pij in P can be
replaced with m  n secret bits. After this step, we get the modiﬁed mean tables
and bitplane sequence denoted as H0, L0, and P0, respectively.
Step 2: We further perform the histogram shifting technique on H0 and L0,
respectively, to embed the second part of secret bits. The detailed substeps can
be illustrated as follows:
Step 2.1: Generate the histogram from H0.
Step 2.2: In the histogram, we ﬁrst ﬁnd a zero point and then a peak point. A zero
point corresponds to the grayscale value v, which does not exist in the given
image. A peak point corresponds to the grayscale value u, which has the
maximum number of pixels in the given image.
Step 2.3: The whole mean table is scanned in a sequential order. Assume u < v,
the grayscale value of pixels between u (including u) and v (including v) is
5.3 Bitplane FlippingeBased Lossless Hiding Schemes
293

incremented by “1.” This step is equivalent to shifting the range of the histo-
gram, [u, v], to the right-hand side by 1 unit, leaving the grayscale value u
empty.
Step 2.4: The whole mean table is scanned once again in the same sequential
order. Once a pixel with grayscale value of u is encountered, we check the secret
bit to be embedded. If this bit is binary “1,” the pixel value is incremented by 1.
Otherwise, the pixel value remains intact.
Step 2.5 After above substeps, we can get the ﬁnal marked high mean table H00.
Similarly, perform above substeps on the low mean table L0 to get the ﬁnal
marked low mean table L00. Note that we should record the u, v values for H and
L, respectively, as the overhead information.
5.3.3.3 The Decoding and Extracting Stage
Our data hiding scheme is reversible because we can recover the original mean ta-
bles and the bitplane sequence after data extraction, and thus the original BTC-
compressed image can be losslessly recovered. Given the marked mean tables Hw
and Lw and the marked bitplane sequence Pw, our purpose is to extract the secret
bit sequence and recover the original BTC-compressed image, the extraction process
as follows:
Step 1: Perform the reverse histogram shifting technique on Hw and Lw to extract
the second part of secret bits and get the intermediate result Hr and Lr,
respectively. The detailed substeps can be illustrated as follows:
Step 1.1: Scan the marked table Hw in the same sequential order as that used in
the embedding procedure. If a pixel with its grayscale value v þ 1 is encoun-
tered, the secret bit “1” is extracted. If a pixel with its value v is encountered, a
secret bit “0” is extracted.
Step 1.2: Scan the image again, for any pixel whose grayscale value is in the
interval [u, v], the pixel value is subtracted by 1.
Step 1.3: After these substeps, we can get the intermediate high mean table Hr.
Similarly, perform these substeps on the marked low mean table Lw to get the
intermediate low mean table Lr.
Step 2: Perform the reverse bitplane ﬂipping technique on Hr, Lr, and Pw to
extract the ﬁrst part of secret bits and recover the BTC-compressed image data.
For each triple (lr
ij, hr
ij, pw
ij), we only need to judge the relationship between lr
ij
and hr
ij. If lr
ij > hr
ij, then the secret bit is 1, and lr
ij and hr
ij are swapped and the
bitplane pw
ij is replaced by pw
ij; if lr
ij < hr
ij, the secret bit is 0; otherwise, all
m  n bits in the bitplane pw
ij are extracted as the secret bits. Replace the bit-
plane pw
ij with m  n ‘1’s.
Based on these two steps, we can extract all secret bits and reconstruct the orig-
inal BTC-compressed image, thus the whole reversible process is realized.
Obviously, the improved scheme can increase the payload compared with Chen
et al.’s scheme.
294
CHAPTER 5 Lossless Information Hiding in BTCeCompressed Images

5.3.3.4 Experimental Results and Discussion
To evaluate our scheme, we use six test images, Lena, Peppers, Bridge, Boat, Gold-
hill, and Jet_F16, of the same size 512  512 with 256 grayscales, as shown in
Fig. 5.4. Comparisons among our algorithm, Hong et al.’s algorithm, and Chen
et al.’s algorithm are performed under the same block size 4  4. Table 5.2 lists
the number of image blocks whose low mean equals its high mean (i.e., lij ¼ hij)
for different images. From Table 5.2, we can see that, for Lena, Boat, Goldhill,
and Jet_F16 images, there is no image block with lij ¼ hij, thus both Hong et al.’s
FIGURE 5.4
Six test images.
Table 5.2 The Number of 4  4 Pixel Blocks
Whose High Mean Equals its Low Mean (EB)
Image
EB
Lena
0
Peppers
285
Bridge
54
Boat
0
Goldhill
0
Jet_F16
0
5.3 Bitplane FlippingeBased Lossless Hiding Schemes
295

algorithm and Chen et al.’s algorithm can embed 16,384 bits in each 512  512 im-
age. However, for the Bridge image and the Peppers image, since there are some
blocks with lij ¼ hij, Chen et al.’s algorithm can embed more bits, whereas Hong
et al.’s algorithm can embed less bits.
To show the superiority of our proposed algorithm, we compare it with Hong
et al.’s scheme and Chen et al.’s scheme. Three aspects of performance are adopted
in the experiments to evaluate a data hiding scheme, i.e., the capacity representing
the maximum number of secret bits that can be hidden, the PSNR representing the
quality of the stego image, and the embedding efﬁciency indicating the number of
embedded secret data when a bit of the binary code stream has been transmitted.
Obviously,
the
embedding
efﬁciency
can
be
calculated
as
Capacity/(bit
rate  M  N). As shown in Table 5.3, the PSNRs of stego images based on our,
Hong et al.’s, and Chen et al.’s schemes are exactly the same as those of the original
AMBTC-compressed images, the reason being that these three schemes are
reversible.
With respect to the embedding capacity, our scheme achieves the highest embed-
ding capacity. Compared with the other two schemes, our scheme can embed more
secret bits because we adopt the histogram shifting technique in addition to Chen
et al.’s scheme. The capacity of Hong et al.’s and Chen et al.’s schemes is normally
1 bit in each 4  4 pixel block. However, if there are some blocks with the same high
and low means, then Hong et al.’s scheme will have less capacity and Chen et al.’s
scheme will have more capacity. As shown in Tables 5.2 and 5.3, for the Peppers
image, because EB ¼ 285, Hong et al.’s scheme can only embed 16,384  285 ¼
16,099 bits, whereas Chen et al.’s scheme can embed 16,384  285 þ 285 
4  4 ¼ 20,659 bits.
In terms of embedding efﬁciency, our scheme has the highest efﬁciency values.
Our scheme can transmit the most number of embedded secret data when a bit of the
Table 5.3 Comparisons of Our, Hong et al.’s, and Chen et al.’s Schemes (m  n ¼ 4  4)
Algorithm
Performance
Lena
Peppers
Bridge
Boat
Goldhill
Jet_F16
AMBTC
PSNR (dB)
32.041
31.595
28.585
31.151
33.163
31.033
Bit rate (bpp)
2.000
2.000
2.000
2.000
2.000
2.000
Proposed
PSNR (dB)
32.041
31.595
28.585
31.151
33.163
31.033
Capacity (bits)
16,684
21,969
17,548
17,061
16,770
17,375
Efﬁciency
0.032
0.042
0.034
0.033
0.032
0.033
Hong et al.’s
PSNR (dB)
32.041
31.595
28.585
31.151
33.163
31.033
Capacity (bits)
16,384
16,099
16,330
16,384
16,384
16,384
Efﬁciency
0.031
0.030
0.031
0.031
0.031
0.031
Chen et al.’s
PSNR (dB)
32.041
31.595
28.585
31.151
33.163
31.033
Capacity (bits)
16,384
20,659
17,194
16,384
16,384
16,384
Efﬁciency
0.031
0.039
0.033
0.031
0.031
0.031
AMBTC, absolute moment block truncation coding; PSNR, peak signal-to-noise ratio.
296
CHAPTER 5 Lossless Information Hiding in BTCeCompressed Images

binary code stream has been transmitted. Taking these three attributes into compre-
hensive consideration, our scheme is a more effective method because of its high ca-
pacity, high PSNR, and high embedding efﬁciency.
5.4 MEAN CODINGeBASED LOSSLESS HIDING SCHEMES
The aforementioned data hiding schemes in the BTC domain modify either the BTC
encoding stage or the BTC-compressed data according to the secret bits, and they
have no ability to reduce the bit rate but may reduce the image quality. To reduce
the bit rate and increase the hiding capacity, this section introduces our three revers-
ible data hiding schemes for BTC-compressed images, which can further losslessly
encode the BTC-compressed data according to secret data.
5.4.1 PREDICTION-ERROR EXPANSIONeBASED SCHEME
In 2012, we proposed a reversible data hiding scheme for BTC-compressed images
by introducing the prediction-error expansion technique [15]. For the purpose of
increasing the capacity, all high and low mean values are composed as a low and
a high mean table, respectively. Then prediction-error expansion is applied on these
two tables. This operation enables one block of the image to embed two secret bits.
However, as mentioned in Chapter 2, it also may lead to the overﬂow or under-
ﬂow of mean values. To solve this problem, the original low and high mean values
are swapped and the binary bitmap is ﬂipped, i.e., the original AMBTC code turns
into ðl0; h0; B0Þ ¼

h; l; B

, where B is the result of performing a logical NOT opera-
tion on binary bitmap B. Reconstruction of this image block will remain the same for
the inherent property of AMBTC decompression procedure [9]. Thus, whether
certain blocks have hidden bits or not can be determined by comparing the modiﬁed
low and high mean values and no additional overﬂow/underﬂow location map is
required.
For some cases the new low mean value is greater than the new high mean value
after prediction-error expansion; we also keep the original mean values and apply
the previously mentioned mean value swapping and bitmap ﬂipping operations.
To further increase the capacity, prediction-error expansion would not be applied
to those blocks with equal values of low and high means. Instead, n  n secret
bits are directly embedded into the binary bitmap B by replacing bits, since the bit-
map is of no use for reconstruction in the decompression process [10]. Take this into
consideration, it may cause the conﬂict in the data extracting phase. Therefore,
blocks with same new mean values need keeping original mean values and applying
mean value swapping and bitmap ﬂipping operations as well.
Our algorithm can be divided into two phases: the data hiding phase and the data
extracting and image restoring phase, which are illustrated in the following
subsections.
5.4 Mean CodingeBased Lossless Hiding Schemes
297

5.4.1.1 Data Hiding Phase
The detailed data hiding phase is given step by step as follows.
Step 1: Decode the original M  N-sized BTC-compressed image to get all BTC
codes (l, h, B) of nonoverlapping n  n-sized blocks.
Step 2: Compose all low and high mean values to obtain the low mean table
L ¼ {L(i, j) ji ¼ 1, 2,.,M/n; j ¼ 1, 2,.,N/n} and the high mean table
H ¼ {H(i, j) ji ¼ 1, 2,.,M/n; j ¼ 1, 2,.,N/n}, respectively.
Step 3: Encrypt the secret data, then start to hide secret bits.
Step 3.1: Scan two mean tables in right-to-left and bottom-to-top manner with an
eye on the property of the predictor. For each block, go to Step 3.2 if L(i, j) is not
equal to H(i, j); otherwise go to Step 3.3.
Step 3.2: Apply prediction-error expansion as described in Section 2.3.1 to L(i, j)
and H(i, j), and then embed 2 bits into current block if the prediction-error pl
e for
L(i, j), ph
e for H(i, j), the new low mean value L0(i, j) and high mean value H0(i, j)
satisfy the following requirements:
( pl
e
 þ
ph
e
  TH
0  L0ði; jÞ < H0ði; jÞ  255
(5.22)
where TH represents a threshold balancing the embedding capacity and image
quality of the output image; or else no bit could be embedded and label the block
as no hidden data block

h; l; B

. Repeat Step 3.1 until every block is scanned.
Step 3.3: Directly embed n  n bits into the bitmap B of the current block by
replacing bits. Repeat Step 3.1 until every block is scanned.
5.4.1.2 Data Extracting and Image Restoring Phase
Data extracting and image restoring phase is the inverse process of data hiding phase
and described as follows:
Step 1: Decode the received BTC-compressed image to get all BTC codes of
blocks.
Step 2: Compose all low and high mean values to obtain the low mean table L0
and the high mean table H0, respectively.
Step 3: Scan two mean tables in left-to-right and top-to-bottom manner. For each
block, go to Step 3.1 if L0(i, j) is smaller than H0(i, j), go to Step 3.2 if L0(i, j) is
equal to H0(i, j), otherwise go to Step 3.3.
Step 3.1: Extract two secret bits from the prediction- error p0l
e for L0’(i, j) and p0h
e
for H0(i, j) by applying prediction-error expansion technique and restore the
original mean values. Repeat Step 3 until every block is scanned.
Step 3.2: Directly extract n  n bits of secret data from the bitmap B0 of the
current block and set all elements of bitmap B0 to 1 for restoring. Repeat Step 3
until every block is scanned.
Step 3.3: No bit is hidden for this case. Apply mean value swapping and bitmap
ﬂipping operations

h0; l0; B0
to restore the original BTC codes. Repeat Step 3
until every block is scanned.
298
CHAPTER 5 Lossless Information Hiding in BTCeCompressed Images

Step 4: Rearrange the secret bits in reverse order because the scan orders of data
hiding phase and data extracting and image restoring phase are reversed. Then
decrypt the secret bits to obtain the original secret data.
5.4.1.3 Experimental Results
In this section, six grayscale test images of size 512  512 shown in Fig. 5.5 are used
to evaluate the performance of our scheme. The block size of AMBTC compression
is 4  4. We analyze the properties of it and compare it with other scheme. Two as-
pects, image quality and capacity, are discussed. Here, PSNR is adopted to measure
the impact of data hiding on image quality.
Experimental results of our scheme with threshold TH ¼ 12 are shown in
Table 5.4, which also contains the result of Li et al.’s scheme [13]. As shown in
Table 5.4, the proposed scheme has a higher capacity when compared with Li
et al.’s. Even though the PSNR values of the proposed scheme are lower than those
of Li et al.’s, they are still very closed to those of original BTC-compressed images
and the image quality is acceptable. The prediction-error expansion technique en-
ables the proposed scheme to hide two secret bits into one block, which improves
the capacity signiﬁcantly. Images F16 and Tiffany have higher capacity than other
test images for the proposed scheme, since the prediction-error expansion takes
Boat
F16
Goldhill
Lena
Peppers
Tiffany
(a)
(d)
(e)
(f)
(b)
(c)
FIGURE 5.5
Six grayscale test images.
5.4 Mean CodingeBased Lossless Hiding Schemes
299

advantage of the correlation of adjacent blocks and smooth blocks help to increase
the capacity. Image F16 and Tiffany have more smooth blocks.
The superiority of the proposed scheme lies in the capacity and the tuning param-
eter TH. TH could be set to a smaller value when data that need hiding are less and
better image quality could be achieved; when the data that need hiding are more, TH
could be set to a larger value, which satisﬁes the embedding requirement. Fig. 5.6
demonstrates the average capacity and PSNR across six test images with different
thresholds TH; the dotted line is the average PSNR value of six original BTC-
compressed images for reference. When TH ¼ 20, the average capacity exceeds
Table 5.4 Comparison of Algorithm Performance
AMBTC
Li et al.’s [13]
Proposed (TH [ 12)
Image
PSNR (dB)
Capacity (Bit)
PSNR (dB)
Capacity (Bit)
PSNR (dB)
Boat
31.14
17,089
31.13
18,490
30.63
F16
31.02
22,656
31.01
24,620
30.67
Goldhill
33.10
16,883
33.09
19,386
32.18
Lena
33.91
16,968
33.90
22,062
33.14
Peppers
33.63
16,826
33.62
22,230
32.78
Tiffany
35.08
19,878
35.08
24,878
33.93
PSNR, peak signal-to-noise ratio.
10
12
14
16
18
20
16000
17000
18000
19000
20000
21000
22000
23000
24000
25000
26000
27000
28000
Threshold Parameter TH
Capacity (bit)
10
12
14
16
18
20
30
31
32
33
34
35
36
37
38
39
40
41
42
PSNR (dB)
Capacity
PSNR
FIGURE 5.6
Average capacity and peak signal-to-noise ratio (PSNR) with different thresholds TH.
300
CHAPTER 5 Lossless Information Hiding in BTCeCompressed Images

25,000 bits, whereas the average PSNR is still greater than 31 dB. Fig. 5.6 reveals
that the capacity becomes higher with the increase of TH, and the decrease of
PSNR value is slow and acceptable.
5.4.2 JOINT NEIGHBORING CODINGeBASED SCHEME
5.4.2.1 Brief Introduction to Joint Neighboring Coding
The joint neighboring coding (JNC) data hiding algorithm used here is derived from
the VQ-based data hiding algorithm in Section 4.5.1 in Chapter 4. In short, the VQ
algorithm divides the input image into nonoverlapping blocks, and each block is
substituted by the matched block in a designated codebook. In this way the output
data for the input image are just the indices of the matched blocks. The indices
are nearly the same for the neighboring blocks and they are the embedding objects
of the JNC-based data hiding algorithm.
Fig. 5.7 shows the composition of neighboring indices with location bits marked
as darker areas around the center index Icur. Here, Icur is the current index to be
encoded. Evidently, there are four neighboring indices as shown in Fig. 5.7 that
are selected to encode Icur, and their location bits are denoted as (00)2, (01)2,
(10)2 and (11)2, respectively. Given the secret data, an M-sequence is generated
with the same length as that of the secret data for encoding. Here, M-sequence is
a kind of pseudorandom sequence, which plays an important role in keeping the
security of secret data.
To describe the encoding process clearly, we give some deﬁnition of the terms used
in the following illustration: (1) bi Stands for the initial location of the reference index
for encoding Icur, and it is read from the M-sequence. (2) bo Denotes the offset of the
reference index used to encode Icur, and it is read from the secret data. (3) br Denotes
the actual location of the reference index to encode Icur, and we have br ¼ bi þ bo. (4)
n denotes the number of neighboring indices considered, and thus the number of bits
in bi, bo, and br are all log2 n. (5) Iref Stands for the index corresponding to br, and it is
the reference index used to encode Icur. (6) D denotes the difference between Icur and
Iref, i.e., D ¼ Icur  Iref. (7) N Is deﬁned as the codebook size. (8) The function dxe
denotes the least integer not less than x. (9) m ð1  m  dlog2 NeÞ is deﬁned as
the truncation integer that is used to distinguish the range of D.
(00)
(01)
(10)
(11)
Icur
FIGURE 5.7
The neighboring indices of the current index Icur.
5.4 Mean CodingeBased Lossless Hiding Schemes
301

With these deﬁnitions in hand, the JNC encoding process can be described as
follows. First, 2 bits from the M-sequence and 2 bits from the secret data are read
as bi and bo, respectively. Next, they are added together to determine br, and thus
Iref can be found. Second, D is calculated as D ¼ Icur  Iref. Here, the encoding
mode for D is classiﬁed by the parameter m ð1  m  dlog2 NeÞ into four cases.
Next, D is encoded into its binary form D0 by one of four cases, which can be sum-
marized as follows.
D0 ¼
8
>
>
>
>
>
>
>
>
>
<
>
>
>
>
>
>
>
>
>
:
ð11Þ2



DðmÞ
2
case“11”
0  D  ð2m  1Þ
ð10Þ2



 DðmÞ
2
case“10”
ð2m  1Þ  D < 0
ð01Þ2



Dðdlog2 NeÞ
2
case“01”
D > ð2m  1Þ
ð00Þ2



 Dðdlog2 NeÞ
2
case“00”
D < ð2m  1Þ
(5.23)
where “UjjV” stands for the concatenation of U and Vand (D(m))2 denotes the m bits
binary code of D. Finally, the output codestream for the current index is encoded into
the binary form as “(br)jjcasejj(jDj)2.” Repeat the this process for all the indices
outside the seed area (here the seed area includes the ﬁrst row and the ﬁrst column
in the index table) and the ﬁnal output codestream can be produced.
5.4.2.2 The Hiding Scheme
As we know, the existing data hiding schemes in the BTC domain modify either the
BTC encoding stage or the BTC-compressed data according to the secret bits, and
they are weak to embed more secret data and may reduce the image quality. To
improve the embedding capacity and image quality, we proposed a novel reversible
data hiding for AMBTC-compressed image by further losslessly encoding the
AMBTC-compressed data according to the relation among neighboring mean values
in the high and low mean tables. First, one high mean table, one low mean table, and
one bitplane sequence are generated by performing the AMBTC method on the input
image. The high and low mean tables are used for hiding information, whereas the
bitplane sequence is reserved unchanged. Second, the M-sequence is generated with
the double length of secret data. Third, the high and low mean tables are embedded
with secret data by the JNC technique and the bitplane sequences are added to the
end of the stream. For instance, the A  B-sized image is encoded as an
(A/4)  (B/4)-sized high mean table H and an (A/4)  (B/4)-sized low mean table
L. With these two mean tables in hand, the secret data can then be embedded by
encoding H and L jointly to achieve a high capacity and generate a more secure
codestream. The codestream of the proposed algorithm is composed of three parts,
i.e., the head information HI, the codestream CSH and CSL of the two embedded
mean tables, and the bitplane BP. HI provides the basic information of the code-
stream, such as the total lengths of codestream, the length of the secret data, CSH
and CSL, and the cover image size. The ﬂowchart of our scheme is shown in
302
CHAPTER 5 Lossless Information Hiding in BTCeCompressed Images

Fig. 5.8. We can see clearly that not only the encoding and decoding processes are
reversible but also the mean tables and the secret data can be retrieved accurately.
The proposed scheme is illustrated in the following two subsections.
5.4.2.2.1 Embedding Process
Suppose the high mean table, low mean table, and bitplane sequence are obtained by
compressing the original image based on the AMBTC method. An M-sequence is
generated with an initial key in advance. For clarity, some terms used in the embed-
ding process are deﬁned in advance. The current high and low mean values in H and
L to be encoded are denoted as hcur and lcur, respectively. The initial location read
from the M-sequence is denoted as bi. The offsets read from the secret data for
encoding hcur and lcur are denoted as bo
(H) and bo
(L), respectively. The ﬁnal reference
locations for encoding hcur and lcur are denoted as br
(H) and br
(L), respectively. Here,
br
(H) ¼ bi þ bo
(H) and br
(L) ¼ bi þ bo
(L). DH is the difference between hcur and href, that
is, DH ¼ hcur  href. Similarly, DL is the difference between lcur and lref, that is,
DL ¼ lcur  lref. The detailed data embedding process can be described by the
following steps.
Step 1: Difference calculation.
First, read 2 bits from the M-sequence as bi. Second, read 4 bits from the secret data,
where the ﬁrst 2 bits serves as bo
(H) for hcur and the latter 2 bits as bo
(L) for lcur. Third,
calculate the reference location br
(H) ¼ bi þ bo
(H) for hcur and br
(L) ¼ bi þ bo
(L) for lcur.
Low mean table 
(A/4×B/4)
High mean table 
(A/4×B/4) 
Embedded high 
mean table 
(A/4×B/4) 
Embedding
M-sequence 
AMBTC 
Original 
image 
(A×B) 
Bitplane 
(A×B) 
00 01 01 10 11 01…
Secret data 
Embedded low 
mean table 
(A/4×B/4)
Bitplane 
(A×B) 
Unchanged 
Output 
stream 
10 11 00 10 01 11…
Decoding 
&recovery
0101… 
FIGURE 5.8
The ﬂow chart of the proposed algorithm.
5.4 Mean CodingeBased Lossless Hiding Schemes
303

Fourth, based on br
(H) and br
(L), ﬁnd href and lref in H and L, respectively. Finally,
calculate DH and DL, i.e., DH ¼ hcur  href and DL ¼ lcur  lref.
Step 2: DH and DL encoding.
Obviously, both dynamic ranges of DH and DL fall in the interval [N þ 1, N  1].
The embedding process for DH and DL are the same, hence we take the DH embed-
ding process as the example to illustrate the encoding process. We can classify it into
four cases, and encode DH into DH0 as follows:
DH0 ¼
8
>
>
>
>
>
>
>
>
>
<
>
>
>
>
>
>
>
>
>
:
11



DðmÞ
H

2
case“11”
0  DH  ð2m  1Þ
10



DðmÞ
H

2
case“10”
ð2m  1Þ  DH < 0
01



Dðdlog2 NeÞ
H

2
case“01”
DH > ð2m  1Þ
00



 Dðdlog2 NeÞ
H

2
case“00”
DH < ð2m  1Þ
(5.24)
That is, for 0  DH  (2m  1), the case is represented by (11)2 and
DH0 ¼ 11jj(DH)2, where DH requires m bits to represent. For (2m1)  DH < 0,
the case is represented by (10)2 and DH0 ¼ 10jj(DH)2, where DH requires m
bits. For DH > (2m  1), the case is represented by (01)2 and DH0 ¼ 01jj(DH)2,
where DH requires dlog2 Ne bits. For DH < (2m  1), the case is represented by
(00)2 and DH0 ¼ 00jj(DH)2, where DH requires dlog2 Ne bits. Similarly, the same
process is performed on DL to obtain DL0.
Step 3: CSH and CSL encoding.
Append DH0 and DL0 to the reference index location bits br
(H) and br
(L), respectively.
For example, assuming br
(H) ¼ (01)2, the case of DH is (11)2, then the ﬁnal code-
stream of CSH for the current high mean is 01jj11jj(DH)2, where DH requires m bits.
Step 4: CS combination.
If all the secret data or all indices outside the seed area have been processed, append
CSH and CSL and the bitplane sequence P to the head information HI to obtain the
ﬁnal codestream. Otherwise, go to step 1.
We take an example to illustrate the embedding process as shown in Fig. 5.9, where
we suppose m ¼ 4. Each time, we obtain 2 bits from the M-sequence and 4 bits from
the secret data. To encode the high mean hcur ¼ “251” located in the second row and
the second column of H, its four neighbors, (254)00, (255)01, (242)10, and (251)11 are
considered. Meanwhile, the low mean lcur ¼ “57” located in the second row and the
second column of L is also encoded. “00” in the M-sequence is ﬁrst read as bi,
and then “1000” is read from the secret data, where bo
(H) ¼ “10” and bo
(L) ¼ “00”.
Next, we calculate the reference location bits br
(H) ¼ “00” ¼ þ“10” ¼ “10”
and br
(L) ¼ “00” ¼ þ“00” ¼ “00,” and then we can ﬁnd the reference indices
304
CHAPTER 5 Lossless Information Hiding in BTCeCompressed Images

href ¼ “242” and lref ¼ “63”, respectively. Thus, we can obtain DH ¼ 251242 ¼
9 < 24, DL ¼ 57  63 ¼  6 >24. Obviously, DH and DL belong to their corre-
sponding Case “11” and Case “10,” respectively. Therefore, CSH and CSL can be
encoded as 10jj11jj1001 and 00jj10jj0110, respectively. For the next high and low
means to be encoded, i.e., hcur ¼ “248” in H and lcur ¼ “56” in L, we read the initial
location bits bi ¼ “01” the offset bits bo
(H) ¼ “00” bo
(L) ¼ “01”, respectively. By
calculating br
(H) ¼ “01”þ“00” ¼ “01” and br
(L) ¼ “01”þ“01” ¼ “10”, we can ﬁnd
href ¼ “220” and lref ¼ “75”, respectively. Thus, we have DH ¼ 248  220 ¼ 28
and DL ¼ 56  75 ¼ 19, and DH and DL belong to their corresponding Case
“01” and Case “00”, respectively. Consequently, CSH and CSL are encoded as
01jj01jj10 and 10jj00jj10,000, respectively.
5.4.2.2.2 Decoding and Extraction Process
Suppose the codestream obtained by the decoder suffers no alterations, then the
AMBTC-compressed image can be precisely recovered without the M-sequence.
The detailed decoding operations can be described as follows.
Step 1: Read the head information HI of the codestream. From HI, we can get the
cover image size, the lengths of CSH and CSL, and the value of m.
Step 2: Read r bits from CSH as br
(H) and r bits from CSL as br
(L). Then retrieve the
corresponding high and low means href and lref, respectively.
Step 3: Read the case information from CSH and CSL. Also, read DH and DL from
CSH and CSL according to the case information.
Step 4: Calculate the current high and low means hcur and lcur as follows:
 hcur ¼ href þ DH
lcur ¼ lref þ DL
(5.25)
220
255
251 249
254 251
248 245
252
243 241
239
246
249 246
247
70
67
75
82
63
57
56
68
72
82
55
60
45
78
76
71
00 01
M-sequence
10 00 00 01 11 10 10 
00 
Secret data
H
L
FIGURE 5.9
An example to explain our data embedding scheme.
5.4 Mean CodingeBased Lossless Hiding Schemes
305

Step 5: Repeat Steps 2e4 until two mean tables are reconstructed.
The same key as used in the embedding process is applied to generate the
M-sequence, and the secret data can be extracted with the following steps.
Step 1: Obtain the head information HI of the codestream.
Step 2: Read r bits from the M-sequence as the initial location bits bi.
Step 3: Read r bits from CSH as br
(H) and r bits from CSL as br
(L). Then calculate
the offset bits bo
(H) by bo
(H) ¼ br
(H)  bi and bo
(L) by bo
(L) ¼ br
(L)  bi, respectively.
Append these offset bits to the extracted secret data.
Step 4: Repeat Steps 2 and 3 until all secret bits are extracted. In this way, the
secret data can be ﬁnally obtained.
Obviously, the complexity of the decoding and extraction process is quite low,
and these two processes can be detached if necessary.
5.4.2.3 Experimental Results
Now we turn to evaluate the proposed scheme using six test images, Lena, Peppers,
Mandrill, Boat, Goldhill, and Jet_F16, of the same size 512  512 with 256 gray-
scales, as shown in Fig. 5.10. First, we test the performance of our algorithm under
different m values. Afterward, under the same block size 4  4, we compare our
algorithm with Chuang and Chang’s algorithm [5], Hong et al.’s algorithm [9],
and Chen et al.’s algorithm [10].
FIGURE 5.10
Six test images.
306
CHAPTER 5 Lossless Information Hiding in BTCeCompressed Images

The performance indicators used in this chapter include PSNR, hiding capacity,
bit rate (bit_rate) and transmission efﬁciency. For an A  B-sized 256 gray-level im-
age, the PSNR is deﬁned as Eq. (5.26), where the MSE is computed by Eq. (5.27)
and the bit rate is computed by Eq. (5.28). The higher the PSNR value is, the better
quality the stego image has. The bit_rate indicator means the number of bits required
for encoding one pixel. Hiding capacity denotes the length of the binary secret data
that can be hidden in the host media. Transmission efﬁciency stands for the ratio of
capacity to codestream length.
PSNR ¼ 10 log10
255  255
MSE
(5.26)
MSE ¼
1
A  B
X
A
i¼1
X
B
j¼1

xi;j  x0
i;j
2
(5.27)
bit rate ¼
L
A  B
(5.28)
where xi,j and x0i,j are the original and stego grayscale pixel values located at (i,j)
respectively, and L is the codestream length.
5.4.2.3.1 Performance of Our Algorithm
To evaluate the average performance of our scheme, a set of experiments are per-
formed on six test images as shown in Fig. 5.10. In the experiments, the block
size is set to be 4  4, and four aspects of performance are adopted to evaluate a
data hiding scheme, i.e., the capacity, representing the maximum number of secret
bits that can be hidden; the PSNR, representing the quality of the stego image; the bit
rate, representing the performance of the compression efﬁciency whose unit is bpp;
and the embedding efﬁciency, indicating the amount of embedded secret data when a
bit of the binary code stream has been transmitted. Obviously, the embedding efﬁ-
ciency can be obtained by Capacity/(bit rate  A  B).
In fact, m is the only parameter that affects the performance of our scheme, hence
we just test the performance indicators for different m values. As shown in Fig. 5.11,
the PSNR value does not change with m (m ¼ 1,2,.,7), while the capacity remains
the same (64,008 bits) for all test images with different m values. Hereby, the param-
eter m does not affect the PSNR and capacity, and the capacity only relates to the
image size, which can also be inferred from the method itself. The bit_rate values
with different m values are shown in Fig. 5.12. The bit rate when m ¼ 3 or 4 is
much lower than that with other m values. Similarly, m ¼ 3 or 4 brings the highest
efﬁciency performance, as shown in Fig. 5.13. Lower bit_rate and higher efﬁciency
indicate better performance. We should note that the optimal value m ¼ 3 or 4 is ob-
tained based on a number of experimental results, which show that for most natural
images the difference between the neighboring pixels mainly falls into [8, 8] or
[16, 16]. If we adopt a large value of m > 4, then we will waste much more bits
to describe the difference, resulting in a higher bit rate. On the other hand, if we
5.4 Mean CodingeBased Lossless Hiding Schemes
307

36
34
32
30
28
26
24
22
Lena
Peppers Baboon
Boat
Goldhill
F16
m=1,2,...,7
PSNR(dB)
FIGURE 5.11
Peak signal-to-noise ratio (PSNR) values under different m values for six test images.
Lena
Peppers Baboon
Boat
Goldhill
F16
2
2.05
2.1
2.15
2.2
2.25
2.3
2.35
2.4
bit_rate
m=1
m=2
m=3
m=4
m=5
m=6
m=7
FIGURE 5.12
Bit_rate values under different m values for six test images.
308
CHAPTER 5 Lossless Information Hiding in BTCeCompressed Images

use a small value of m ¼ 1 or 2, then many differences will be out of the range
[(2m  1), (2m  1)], which also results in a higher bit rate. Since we cannot
conﬁrm under which m value (m ¼ 3 or m ¼ 4) our scheme can obtain the best per-
formance from Fig. 5.12, we have to calculate the mean bit_rate value and the mean
efﬁciency value over all test images to achieve the best m value, and the result shows
that our algorithm can obtain a better performance when m ¼ 4.
5.4.2.3.2 Comparison of Our Algorithm With Those of Others
To show the superiority of our proposed algorithm, we compare it with Chuang and
Chang’s scheme [5], Hong et al.’s scheme [9], and Chen et al.’s scheme [10]. As
shown in Table 5.5, the PSNRs of stego images based on our, Hong et al.’s, and
Chen et al.’s schemes are exactly the same as those of the original AMBTC-
compressed images, since these three schemes do not change the AMBTC-
compressed image quality during the data hiding process. However, Chuang and
Chang’s method obtains worse image quality as it is not a reversible data hiding
scheme.
With respect to the embedding capacity, the proposed scheme achieves the high-
est embedding capacity. Compared with other three schemes, our scheme embeds
2 bits in each mean value, including the low and high mean tables, so we can embed
4 bits in each 4  4 pixel block. The capacity of Chuang and Chang’s scheme is
determined by the number of smooth blocks. The capacity of Hong et al.’s and
Chen et al.’s schemes is normally 1 bit in each 4  4 pixel block. However, if there
are some blocks with the same high and low mean, then Hong et al.’s scheme will
Lena
Peppers Baboon
Boat
Goldhill
F16
0.1
0.105
0.11
0.115
Efficiency
0.12
0.125
m=1
m=2
m=3
m=4
m=5
m=6
m=7
FIGURE 5.13
Efﬁciency values under different m values for six test images.
5.4 Mean CodingeBased Lossless Hiding Schemes
309

have less capacity and Chen et al.’s scheme will have more capacity. As shown in
Table 5.5, the capacity in our scheme is nearly twice higher than that in the other
schemes, with a bit higher bit_rate. With high capacity and acceptable bit_rate,
our scheme has much higher efﬁciency, as shown in Fig. 5.14. We can see that
the efﬁciency of our scheme is nearly four times larger than that of the other
schemes.
5.4.3 BLOCKWISE CODINGeBASED SCHEME
As we know, Chuang and Chang’s scheme is not a reversible scheme, while Hong
et al.’s bitplane ﬂipping scheme and Chen et al.’s scheme can embed 1 bit informa-
tion per block if there is no block with lij ¼ hij. To both embed more secret bits and
reduce the coding bit rate, we can view all high/low means as a high/low mean table
and then make full use of the correlation among the neighboring high/low means to
encode the high/low mean table with less bits based on the secret data. To make use
of the correlation among neighboring high/low means, we can perform the high/low
mean table coding process on each 2  2 high/low mean block rather than one by
one. Based on these considerations, we proposed a novel data hiding scheme for
BTC-compressed images based on lossless encoding of the high and low mean ta-
bles [16]. The main idea of our scheme is to ﬁrst perform AMBTC on the original
image, obtaining one high mean table, one low mean table, and one bitplane
sequence, and then divide the high and low mean tables into nonoverlapping
2  2 blocks. Finally, we encode the mean values in each 2  2 block according
Table 5.5 Comparisons of the Proposed, Chuang and Chang’s, Hong et al.’s, and
Chen et al.’s Schemes (a  b ¼ 4  4)
Algorithm
Performance
Lena
Peppers
Baboon
Boat
Goldhill
Jet_F16
AMBTC
PSNR (dB)
33.971
33.400
25.995
31.147
33.161
31.949
Bit rate (bpp)
2.000
2.000
2.000
2.000
2.000
2.000
Proposed
PSNR (dB)
33.971
33.400
25.995
31.147
33.161
31.949
Capacity (bits)
64,008
64,008
64,008
64,008
64,008
64,008
Bit rate (bpp)
2.060
2.067
2.164
2.086
2.072
2.069
Chuang
and
Chang’s
PSNR (dB)
31.659
31.233
25.912
30.789
32.534
30.849
Capacity (bits)
13,048
13,464
5168
11,981
12,487
12,631
Bit rate (bpp)
2.000
2.000
2.000
2.000
2.000
2.000
Hong
et al.’s
PSNR (dB)
33.971
33.400
25.995
31.147
33.161
31.949
Capacity (bits)
16,384
16,099
16,384
16,384
16,384
16,384
Bit rate (bpp)
2.000
2.000
2.000
2.000
2.000
2.000
Chen
et al.’s
PSNR (dB)
33.971
33.400
25.995
31.147
33.161
31.949
Capacity (bits)
16,384
20,944
16,384
16,384
16,384
16,384
Bit rate (bpp)
2.000
2.000
2.000
2.000
2.000
2.000
AMBTC, absolute moment block truncation coding; PSNR, peak signal-to-noise ratio.
310
CHAPTER 5 Lossless Information Hiding in BTCeCompressed Images

to four input secret bits and the dynamic range evaluated by the difference between
the maximal mean value and the minimal mean value in the mean block. The pro-
posed algorithm consists of three stages, i.e., the AMBTC compression stage, the
data hiding & mean table coding stage and the data extraction and decoding stage,
which can be illustrated as follows:
5.4.3.1 The Absolute Moment Block Truncation Coding Compression Stage
This stage is a preprocessing stage before data hiding and mean table coding. The
aim of this stage is to obtain the two mean tables for later use. Given an M  N-sized
256 grayscale original image X, this stage can be expressed as follows:
Step 1: The original image X is divided into nonoverlapping m  n-sized blocks
x(ij), i ¼ 1, 2,.,M/m, j ¼ 1, 2,.,N/n.
Step 2: Encode each image block x(ij) by AMBTC, obtaining the compressed
triple (lij, hij, pij).
Step 3: Compose all high means and low means to obtain the high mean table
H ¼ {hij ji ¼ 1,2,.,M/m; j ¼ 0,1,.,N/n} and the low mean table L ¼ {lij
ji ¼ 1,2,.,M/m; j ¼ 0,1,.,N/n}, respectively. Compose all bitplanes to obtain
the bitplane sequence P ¼ {pij ji ¼ 1,2,.,M/m; j ¼ 0,1,.,N/n}.
5.4.3.2 The Data Hiding and Mean Table Coding Stage
With the mean tables H and L in hand, now we can introduce our reversible data
hiding and mean table coding algorithm. Assume the secret bit sequence is of length
Lena
Peppers Baboon
Boat
Goldhill
F16
0
0.05
0.1
Comparison of efficiency
Proposed
Chuang et al.’s
Hong et al.’s
Chen et al.’s
FIGURE 5.14
Comparisons of the proposed, Chuang and Chang’s, Hong et al.’s, and Chen et al.’s
schemes in terms of efﬁciency (a  b ¼ 4  4).
5.4 Mean CodingeBased Lossless Hiding Schemes
311

2  M  N/(m  n), which is equal to the total number of mean values in two mean
tables. That is to say, our scheme can embed 2 bits in each m  n-sized image block.
Here, we adopt m ¼ 4 and n ¼ 4, which is derived from conventional BTC compres-
sion schemes. The visual effect of the stego image is determined by the BTC
compression. A larger m and n will result in a larger compression ratio, but worse
image quality with more visible blocking effect. On the other hand, a smaller m
and n will result in better image quality, but a smaller compression ratio, which
will further keep it back from application in image compression. Before embedding,
we perform the permutation operation on the secret bit sequence to enhance the se-
curity. Our embedding method is performed not mean by mean but on each 2  2
mean block to make full use of the correlation between neighboring mean values,
and thus the encoding bit rate can be reduced. Since the data hiding process for
the low mean table is the same as that for the high mean table, here we take the
high mean table H to describe the lossless embedding process. Assume the high
mean table H is segmented into nonoverlapping 2  2-sized blocks, huv,
u ¼ 1,2,.,M/(2m);
v ¼ 1,2,.,N/(2n).
Here,
huv ¼ {h2u,2v,
h2u,2vþ1,
h2uþ1,2v,
h2uþ1,2vþ1}, and we adopt {“00,” “01,” “10,” “11”} to denote their locations accord-
ingly. For each 2  2 high mean block huv, assume the corresponding four secret bits
to be embedded are {w1, w2, w3, w4}; the data hiding and high mean table coding
process can be illustrated in detailed as follows.
Step 1: Find the maximal and minimal mean values hmax and hmin in huv, and
record their location bits wmax ˛ {“00,” “01,” “10,” “11”} and wmin ˛ {“00,”
“01,” “10,” “11”}, respectively.
Step 2: Calculate the dynamic range r ¼ hmax  hmin. For 256-gray-level images,
since the dynamic range r belongs to the interval [0,255], we consider eight
cases as shown in Table 5.6. Obviously, it requires 3 bits to denote each case.
Table 5.6 Eight Cases Considered for Coding the Mean Differences
Case
Dynamic Range r
(r [ hmax L hmin for High Means,
Whereas r [ lmax L lmin for Low
Means)
Range Bits wran
c (Number of Bits
Required to Code
Each Difference)
1
0  r < 2
“000”
1
2
2  r < 4
“001”
2
3
4  r < 8
“010”
3
4
8  r < 16
“011”
4
5
16  r < 32
“100”
5
6
32  r < 64
“101”
6
7
64  r < 128
“110”
7
8
r  128
“111”
8
312
CHAPTER 5 Lossless Information Hiding in BTCeCompressed Images

Append these 3 bits (they are called range bits wran in this chapter) to the
codestream.
Step 3: Viewing the ﬁrst two secret bits w1 and w2 as the location bits; ﬁnd the
reference high mean href in huv. (e.g., if the ﬁrst two secret bits are “01,” then
href ¼ h2u,2vþ1). Append the two secret bits wref ¼ w1jjw2 (they are called
reference location bits) followed by the 8 bits (href)2 to the codestream. Here, jj
denotes the concatenation operation and ($)2 denotes the operation to get the
binary description of a number.
Step 4: According to the third secret bit w3, select the comparison high mean hcom
out of {hmax, hmin}. If w3 ¼ 1, then set hcom ¼ hmax and wcom ¼ wmax; otherwise,
if w3 ¼ 0, then set hcom ¼ hmin and wcom ¼ wmin. Here we should consider two
cases. In Case 1, the reference high mean and the comparison high mean are
located at the same position, i.e., href ¼ hcom and wref ¼ wcom. Denote the
remainder three high mean values in huv as hA, hB, and hC (in the raster-scan
order). In Case 2, the reference high mean and the comparison high mean are
located at different positions, i.e., wref s wcom. Except for hcom, we deﬁne
hA ¼ href and denote the remainder two high mean values in huv as hB and hC (in
the raster-scan order). Append the third secret bit w3 followed by the two
comparison location bits wcom to the codestream.
Step 5: According to the secret bits w3 and w4, calculate the differences
among hcom, hA, hB and hC. If w4 ¼ 0 and w3 ¼ 0, then dA ¼ hA  hcom,
dB ¼ hB  hcom, and dC ¼ hC  hcom. If w4 ¼ 0 and w3 ¼ 1, then dA ¼ hcom  hA,
dB ¼ hcom  hB, and dC ¼ hcom  hC. If w4 ¼ 1 and w3 ¼ 0, then dA ¼ hcom  hA,
dB ¼ hcom  hB, and dC ¼ hcom  hC. If w4 ¼ 1 and w3 ¼ 1, then dA ¼ hA  hcom,
dB ¼ hB  hcom, and dC ¼ hC  hcom. We easily ﬁnd that w4 can indicate the sign
of the differences, i.e., if w4 ¼ 0, the sign is positive; otherwise, the sign is
negative.
Step 6: According to the dynamic range r given in Table 5.6, look up the number
of bits (it is denoted by c) required to encode each difference. If w4 ¼ 0, 3c bits
are used to denote (dA)2, (dB)2, and (dC)2. Otherwise, if w4 ¼ 1, 3c bits are used
to denote (dA)2, (dB)2, and (dC)2. Append the fourth secret bit w4 followed
by the 3c bits of dA, dB, and dC to the codestream.
Perform Steps 1e6 for each 2  2 high mean block huv; we can hide 4 bits in
each high mean block and output a bit string whose length is 17 þ 3c. Similarly,
by performing Steps 1e6 for each low mean block luv, we can also hide 4 bits in
each low mean block. Here, c is different from block to block. If most of the
mean blocks are with c  5, then the bit rate can be reduced compared with the orig-
inal mean table that requires 32 bits to denote four mean values in each mean block.
An example of high mean coding and data hiding for a typical 2  2 high mean
block is shown in Fig. 5.15.
5.4.3.3 The Decoding and Extracting Stage
Our data hiding scheme is reversible because we can recover the original mean ta-
bles after data extraction, and thus the original BTC-compressed image can be
5.4 Mean CodingeBased Lossless Hiding Schemes
313

losslessly recovered. Given the codestream, our purpose is to extract the secret bit
sequence and recover the original BTC-compressed image. Since the reconstruction
process for the low mean table is the same as that for the high mean table, here we
take the reconstruction process for the high mean table to describe the extraction
process as follows.
Step 1: Read the next 3 bits into wran from the codestream of the high mean table,
ﬁnd the corresponding case and look up the value c in Table 5.6.
Step 2: Read the next 10 bits from the codestream of the high mean table. Get the
ﬁrst 2 bits w1 and w2 as the reference location bits wref, and append them to the
output secret bit sequence. Transform the last 8 bits into the reference high
mean href, and put this mean in the current mean block according to the location
bits wref.
Step 3: Read the next 3 bits from the codestream of the high mean table. Get the
ﬁrst bit w3, and append it to the output secret bit sequence. Get the last 2 bits as
the comparison location bits wcom.
Step 4: Read the next 1 þ 3c bits from the codestream of the high mean table. Get
the ﬁrst bit w4, append it to the output secret bit sequence. Transform the
following three c bits into three positive difference values dAþ, dBþ, and dCþ. If
w4 ¼ 0, dA ¼ dAþ, dB ¼ dBþ, and dC ¼ dCþ; otherwise, dA ¼ dAþ, dB ¼  dBþ
and dC ¼ dCþ.
Step 5: Except for the reference high mean, recover the other three mean values
in the current 2  2 high mean block. Here, we should consider two cases:
Case 1: wref ¼ wcom. In this case, the reference high mean is just the comparison
high mean, and thus hcom ¼ href. If w4 ¼ 0 and w3 ¼ 0, then hA ¼ dA þ hcom,
hB ¼ dB þ hcom, and hC ¼ dC þ hcom. If w4 ¼ 0 and w3 ¼ 1, then hA ¼ hcom  dA,
212
207
207
205
0110
hmax-hmin=7, wran= 010 ,
c=3, wref=w1||w2= 01 ,
href=207,w3=1,
hcom=hmax=212, 
wcom= 00
*
207(5)
5
7
w4=0, wcom wref,
dA=hcom-href=5,
dB=hcom-207=5,
dC=hcom-205=7
Mean 
Secret bits
Output bits=010||01||11001111||1||00||0||101||101||111
FIGURE 5.15
An example to hide 4 bits and encode a high mean block.
314
CHAPTER 5 Lossless Information Hiding in BTCeCompressed Images

hB ¼ hcom  dB, and hC ¼ hcom  dC. If w4 ¼ 1 and w3 ¼ 0, then hA ¼ hcom  dA,
hB ¼ hcom  dB, and hC ¼ hcom  dC. If w4 ¼ 1 and w3 ¼ 1, then hA ¼ dA þ hcom,
hB ¼ dB þ hcom, and hC ¼ dC þ hcom. Put hA, hB, and hC at the remainder three
locations in the raster-scan order.
Case 2: wref s wcom. In this case, dA is the difference between hcom and href. If
w4 ¼ 0 and w3 ¼ 0, then hcom ¼ dA  href. If w4 ¼ 0 and w3 ¼ 1, then
hcom ¼ href þ dA. If w4 ¼ 1 and w3 ¼ 0, then hcom ¼ href þ dA. If w4 ¼ 1 and
w3 ¼ 1, then hcom ¼ dA  href. Put hcom in the current 2  2 high mean block
according to the location bits wcom. Now turn to recover left two indices. If
w4 ¼ 0 and w3 ¼ 0, then hB ¼ dB þ hcom and hC ¼ dC þ hcom. If w4 ¼ 0 and
w3 ¼ 1, then hB ¼ hcom  dB and hC ¼ hcom  dC. If w4 ¼ 1 and w3 ¼ 0, then
hB ¼ hcom  dB and hC ¼ hcom  dC. If w4 ¼ 1 and w3 ¼ 1, then hB ¼ dB þ hcom
and hC ¼ dC þ hcom. Put hB and hC at the remainder two locations in the raster-
scan order.
Repeatedly perform Steps 1e5 for all 2  2 high mean blocks; we can recover
the original high mean table and output the ﬁrst half sequence of secret bits. Simi-
larly, by performing Steps 1e for all 2  2 low mean blocks, we can recover the
original low mean table and output the second half sequence of secret bits.
Fig. 5.16 gives an example to show the decoding and data extraction process for a
212
207
207
205
0110
*
207
*
*
w3=1, wcom= 00 ,w4=0,dA=5, dB=5, 
Mean block
Secret bits
Input bits=01001110011111000101101111
wran= 010 ,c=3,wref= 01 ,href=207, 
Input 
*
207(5)
5
7
w3=1,w4=0,
wcom wref, 
hmax=hcom=207+5=212,
FIGURE 5.16
An example to extract secret data and decode a mean block.
5.4 Mean CodingeBased Lossless Hiding Schemes
315

high mean block. Based on the two decoded mean tables together with the un-
changed bitplane sequence, we can reconstruct the original BTC-compressed image.
In this way, the whole reversible process is realized.
5.4.3.4 Experimental Results
To evaluate the proposed scheme, we use six test images, Lena, Peppers, Mandrill,
Boat, Goldhill, and Jet_F16, of the same size 512  512 with 256 grayscales.
Comparisons among our algorithm, Chuang and Chang’s algorithm [5], Hong
et al.’s algorithm [9], and Chen et al.’s algorithm [10] are performed under the
same block size 4  4. Besides BTC-based schemes, we also compare our scheme
with a JPEG-based lossless data hiding scheme presented in 2012 [18] with
QF ¼ 50. Because the total number of bits required to encode a mean block based
on our algorithm is 17 þ 3c, whereas the number of bits required to encode four
mean values based on the original AMBTC is 32, to reduce the bit rate, we expect
to have 17 þ 3c  32, i.e., c  5, for most mean blocks. To explain the capacity of
three existing schemes more clearly, for six test images, we list the number
of 4  4 pixel blocks whose high mean equals its low mean and the number of
4  4 smooth pixel blocks with jhij  lijj TH in Table 5.7. In our experiment, we
can ﬁnd that, for all images except for the Mandrill image, most high/low mean
blocks belong to the ﬁrst 4 cases, thus our scheme can reduce the bit rate as shown
in Table 5.8. The Mandrill image is very complex with high detail, which makes the
variation of mean values in most mean blocks be large, and thus most mean blocks
belong to cases 5 and 6 and the bit rate is a bit larger than that of the original
AMBTC.
To show the superiority of our proposed algorithm over the other BTC-based
methods, we compare it with Chuang and Chang’s scheme [5], Hong et al.’s scheme
[9], and Chen et al.’s scheme [10]. Five aspects of performance are adopted in the
experiments to evaluate a data hiding scheme, i.e., the capacity, representing the
maximum number of secret bits that can be hidden; the PSNR, representing the qual-
ity of the stego image; the bit rate, representing the performance of the compression
efﬁciency whose unit is bpp; the embedding efﬁciency, indicating the number of
Table 5.7 The Number of 4  4 Pixel Blocks Whose High Mean Equals Its
Low Mean (Denoted by EB) and the Number of 4  4 Smooth Pixel Blocks With
jhij  lijj < TH (Denoted by SB, TH ¼ 20)
Image
SB
EB
Lena
13,048
0
Peppers
13,464
285
Mandrill
5168
0
Boat
11,981
0
Goldhill
12,487
0
Jet_F16
12,631
0
316
CHAPTER 5 Lossless Information Hiding in BTCeCompressed Images

embedded secret data when a bit of the binary code stream has been transmitted; and
the time complexity, indicating the ratio of the time cost by a data hiding scheme to
the time cost by the standard BTC compression. Obviously, the embedding efﬁ-
ciency can be calculated as Capacity/(bit rate  M  N). As shown in Table 5.8,
the PSNRs of stego images based on our, Hong et al.’s, and Chen et al.’s schemes
are exactly the same as those of the original AMBTC-compressed images, the reason
being is that these three schemes are reversible. However, Chuang and Chang’s
method obtains worse image quality, because it is not a reversible data hiding
scheme. Fig. 5.17 shows the original Lena image, BTC-compressed Lena image
and stego Lena images by various BTC-based methods.
Table 5.8 Comparisons of the Proposed, Chuang and Chang’s, Hong et al.’s, and
Chen et al.’s Schemes (m  n ¼ 4  4) and the JPEG-Based Scheme (QF ¼ 50)
Algorithm
Performance
Lena
Peppers
Mandrill
Boat
Goldhill
Jet_F16
AMBTC
PSNR (dB)
32.034
31.595
25.995
31.147
33.162
31.031
Bit rate (bpp)
2.000
2.000
2.000
2.000
2.000
2.000
Complexity
1.000
1.000
1.000
1.000
1.000
1.000
Proposed
PSNR (dB)
32.034
31.595
25.995
31.147
33.162
31.031
Capacity (bits)
32,768
32,768
32,768
32,768
32,768
32,768
Bit rate (bpp)
1.917
1.916
2.009
1.934
1.932
1.892
Efﬁciency
0.065
0.065
0.062
0.065
0.065
0.066
Complexity
1.010
1.011
1.014
1.011
1.011
1.012
Chuang
and
Chang’s
PSNR (dB)
31.659
31.233
25.912
30.789
32.534
30.849
Capacity (bits)
13,048
13,464
5168
11,981
12,487
12,631
Bit rate (bpp)
2.000
2.000
2.000
2.000
2.000
2.000
Efﬁciency
0.025
0.026
0.010
0.023
0.024
0.024
Complexity
1.000
1.001
1.001
1.000
1.001
1.001
Hong
et al.’s
PSNR (dB)
32.034
31.595
25.995
31.147
33.162
31.031
Capacity (bits)
16,384
16,099
16,384
16,384
16,384
16,384
Bit rate (bpp)
2.000
2.000
2.000
2.000
2.000
2.000
Efﬁciency
0.031
0.030
0.031
0.031
0.031
0.031
Complexity
1.000
1.001
1.000
1.000
1.001
1.000
Chen
et al.’s
PSNR (dB)
32.034
31.595
25.995
31.147
33.162
31.031
Capacity (bits)
16,384
20,944
16,384
16,384
16,384
16,384
Bit Rate(bpp)
2.000
2.000
2.000
2.000
2.000
2.000
Efﬁciency
0.031
0.040
0.031
0.031
0.031
0.031
Complexity
1.001
1.001
1.002
1.001
1.002
1.001
JPEG-
based
method
PSNR (dB)
35.235
35.077
28.426
34.433
36.429
34.034
Capacity (bits)
364
389
1080
522
810
760
Bit rate (bpp)
1.654
1.656
3.109
1.811
1.750
1.597
Efﬁciency
0.0008
0.0009
0.0013
0.0011
0.0020
0.0018
Complexity
18.231
18.874
30.012
19.245
20.532
19.429
AMBTC, absolute moment block truncation coding; PSNR, peak signal-to-noise ratio.
5.4 Mean CodingeBased Lossless Hiding Schemes
317

With respect to the embedding capacity, the proposed scheme achieves the high-
est embedding capacity. Compared with other three schemes, our scheme embeds
information in all mean values, so we can embed 2 bits in each 4  4 pixel block.
The capacity of Chuang and Chang’s scheme is determined by the number of smooth
blocks as given in Table 5.7. The capacity of Hong et al.’s and Chen et al.’s schemes
is normally 1 bits in each 4  4 pixel block. However, if there are some blocks with
the same high and low means, then Hong et al.’s scheme will have less capacity and
Chen et al.’s scheme will have more capacity. As shown in Table 5.7, for the
Peppers
image,
because
EB ¼ 285,
Hong
et
al.’s
scheme
can
only
embed 16,384  285 ¼ 16,099 bits, whereas while Chen et al.’s scheme can embed
16,384 þ 285  4  4 ¼ 20,944 bits. In fact, the reason why our scheme can embed
more bits is that our scheme further losslessly compresses the BTC data and releases
room for data hiding. In other words, Hong et al.’s method and Chen et al.’s method
only exploit the BTC data (that is, they retain the bit rate 2.0 bpp), whereas our
method further losslessly compresses the BTC data based on the correlation between
neighboring high and low means, and thus we have more room for data hiding.
(a)
(b)
(c)
(d)
(e)
(f)
FIGURE 5.17
The original Lena image, the AMBTC-compressed image, and stego images by various
hiding schemes. (a) The original image; (b) the AMBTC-compressed image,
PSNR ¼ 32.034 dB; (c) the stego image by our scheme, PSNR ¼ 32.034 dB; (d) the
stego image by Chuang and Chang’s scheme, PSNR ¼ 31.659 dB; (e) the stego image by
Hong et al.’s scheme, PSNR ¼ 32.034 dB; (f) the stego image by Chen et al.’s scheme,
PSNR ¼ 32.034 dB. AMBTC, absolute moment block truncation coding; PSNR, peak
signal-to-noise ratio.
318
CHAPTER 5 Lossless Information Hiding in BTCeCompressed Images

With regard to the bit rate, from Table 5.8, we can see that only our scheme can
reduce the bit rate by around 0.1 bpp, whereas the other three BTC-based schemes
have the same bit rate as the original AMBTC scheme. That is to say, our scheme can
not only hide information but also further compress BTC-compressed data for most
images. However, for the Mandrill image, because it is too complex, our scheme gets
a bit higher bit rate of 2.009 bpp.
In terms of embedding efﬁciency, our scheme has the highest efﬁciency values,
and Chuang and Chang’s method has the lowest efﬁciency values among various
BTC-based schemes. This means that our scheme can transmit the most amount
of embedded secret data when a bit of the binary code stream has been transmitted,
whereas Chuang and Chang’s scheme can transmit the least amount of embedded
secret data. Our scheme has the efﬁciency values that are approximately one time
higher than those of Hong et al.’s and Chen et al.’s schemes.
In terms of time complexity, we can see that all BTC-based schemes have very
low complexity since the BTC compression process is very fast, and the hiding pro-
cedure is relatively simple. Compared with the two existing BTC-based reversible
data hiding schemes, our scheme has a bit higher complexity since our hiding pro-
cedure is a bit more complicated.
We also compared our scheme with the JPEG-based reversible data hiding
scheme [18] when QF ¼ 50. From Table 5.8, we can see that the JPEG-based scheme
can only hide few bits, whereas our algorithm can hide 32e90 times as many secret
bits as the JPEG-based scheme. Thus, although the bit rate of the JPEG-based
scheme is less than our scheme, the resulting embedding efﬁciency of the JPEG-
based scheme is much less than ours. On the other hand, the time complexity of
the JPEG-based scheme is about 18e30 times as high as that of our scheme. How-
ever, the image quality of the JPEG-based scheme is much higher than ours.
Taking the above ﬁve attributes into comprehensive consideration, compared
with other BTC-based schemes, the proposed scheme is a more effective method
for its high capacity, high PSNR, high embedding efﬁciency, low bit rate, and rela-
tively low complexity. In addition, our scheme is also superior to the JPEG-based
scheme in terms of embedding efﬁciency and complexity. Since our scheme is
very fast and its capacity is high, it can be used to transmit a great deal of secret in-
formation real time by embedding them in images, which has a potential value in
military and business ﬁelds.
5.5 LOSSLESS DATA HIDING IN BLOCK TRUNCATION
CODINGeCOMPRESSED COLOR IMAGES
As we know, BTC [1] is a lossy compression technique that can signiﬁcantly reduce
the size of digital images with acceptable visual quality. The traditional color BTC
method compresses each color image block (typically 4  4) into three high means,
three low means, and three bitplanes. To conceal secret data into color BTC
5.5 Lossless Data Hiding in BTCeCompressed Color Images
319

compression codes as well as reducing the number of bitplanes, Chang et al. [5] used
the genetic algorithm (GA) to generate an optimal common bitplane (replacing the
traditional three bitplanes) to reduce the bit rate, and then utilized the side match
distortion concept to increase the embedding capacity. However, Chang et al.’s
method is time consuming for generating a common bitplane. Recently, Chou and
Chang [6] proposed an improved data hiding method to save the computation cost
during common bitplane generation. However, Both Chang et al.’s algorithm and
Chou and Chang’s scheme increase the bit rate because of the additional bits
required to recognize the irreplaceable blocks. To both increase the hiding capacity
and reduce the bit rate, this section introduces two reversible data hiding for BTC-
compressed color images, one is to further losslessly encoding the high mean tables
and low mean tables based on the secret data, and the other is using the difference
expansion (DE) technique. Before introducing these two methods, we ﬁrst introduce
the BTC compression technique for color images.
5.5.1 BLOCK TRUNCATION CODING COMPRESSION FOR COLOR
IMAGES
5.5.1.1 Traditional Color Block Truncation Coding
The traditional color BTC applies the grayscale BTC three times on red, green, and
blue planes. Therefore, every compressed color image block requires three bitplanes
together with three high means and three low means. The key steps of the color BTC
compression are as following. First, a color image I is divided into nonoverlapping
blocks of size 4  4. For each block Bi, the mean values Mi,r, Mi,g, and Mi,b are
calculated for red, green, and blue components, respectively. After that, Mi,r is
compared with every red component in Bi; if a red component is not less than
Mi,r, then the corresponding element in the red bitplane BPi,r is set to “1,” otherwise
it is set to “0.” At the same time, the high mean Hi,r and the low mean Li,r are ob-
tained by calculating the mean value for all red components not less than Mi,r and
the mean value for all red components less than Mi,r, respectively. Similarly, the
green bitplane BPi,g and the blue bitplane BPi,b can be also obtained, together
with the green mean pair (Hi,g, Li,g) and the blue mean pair (Hi,b, Li,b). Thus, the
compressed code for each block Bi can be represented as (BPi,r, Hi,r, Li,r, BPi,g,
Hi,g, Li,g, BPi,b, Hi,b, Li,b).
5.5.1.2 Common Bitplane Color Block Truncation Coding
The traditional color BTC method encodes each block with three bitplanes (BPi,r,
BPi,g, BPi,b) together with three mean pairs. To reduce the bit rate, a good way is
to ﬁnd an optimal common bitplane BPi,c to replace the original three bitplanes,
i.e., BPi,r ¼ BPi,g ¼ BPi,b ¼ BPi,c. Thus, in this case, the compressed code for
each block Bi can be represented as (BPi,c, Hi,r, Li,r, Hi,g, Li,g, Hi,b, Li,b). Now the
remaining problem is how to ﬁnd the optimal common bitplane. A natural idea is
to use an optimization technique. In Chang et al.’s method [19], they adopted the
GA to ﬁnd the approximate optimal bitplane. In fact, there are only 16 pixels in
320
CHAPTER 5 Lossless Information Hiding in BTCeCompressed Images

each block, we can absolutely use an exhausted search algorithm to ﬁnd the optimal
bitplane. Based on this simple idea, Chou and Chang’s scheme [20] generated the
optimal common bitplane BPi,c ¼ {y1, y2,.,y16} from the block Bi ¼ {x1, x2, .,
x16} by Eq. (5.29).
yk ¼
 1
ifjxk  pHj  jxk  pLj
0
otherwise
;
k ¼ 1; 2; .; 16
(5.29)
where, pH ¼ (Hi,r, Hi,g, Hi,b) and pL ¼ (Li,r, Li,g, Li,b) are two virtual color pixels.
5.5.2 DIFFERENCE EXPANSIONeBASED SCHEME
5.5.2.1 The Difference Expansion Technique
The DE technique for reversible data hiding was ﬁrst proposed by Tian [21]. Given a
pair of 256-grayscale image pixel values (x, y), 0  x, y  255, their integer average
c and difference d are computed as
c ¼
	x þ y
2

; d ¼ x  y
(5.30)
where PzR denotes the ﬂoor function that seeks the greatest integer less than or equal
to z. The inverse transform of Eq. (5.30) is
x ¼ c þ
	d þ 1
2

; y ¼ c 
	d
2

(5.31)
The reversible transforms denoted by Eqs. (5.30) and (5.31) are called the integer
Haar wavelet transform. Tian [21] embedded a binary bit b into d based on the
following rule:
d0 ¼ 2d þ b
(5.32)
For both b ¼ 0 and b ¼ 1, if the difference value d satisﬁes Eq. (5.33), it is a
changeable difference value
2$
	d
2

þ b
  minð2$ð255  cÞ; 2c þ 1Þ
(5.33)
Furthermore, for both b ¼ 0 and b ¼ 1, if the difference value d satisﬁes
Eq. (5.34), it is an expandable difference value
j2d þ bj  minð2$ð255  cÞ; 2c þ 1Þ
(5.34)
In the DE method, data embedding and extraction rely on expendable and
changeable differences. The expandable differences provide space for data embed-
ding, and the changeable differences are used to guarantee blind data extraction. All
difference values in the difference image are classiﬁed into three categories: expand-
able, changeable but nonexpandable, and nonchangeable. For a pure payload (the
secret bits to be hidden), a number of expandable differences should be selected
5.5 Lossless Data Hiding in BTCeCompressed Color Images
321

and their locations should be stored into a binary-type location map, which can be
losslessly compressed by run-length coding. All the LSBs of changeable but nonex-
pandable differences are recorded as an original bitstream. The compressed location
map, the original bitstream, and the pure payload are embedded into the difference
image together.
The secret data extraction process is simple. The LSBs of all changeable differ-
ences in the image compose a bitstream, from which we can extract the location
map, the original bitstream, and the pure payload. To restore the image, all previous
expandable differences divide by two integrally. The LSBs of all changeable but not
expandable differences are reset with the original bitstream.
5.5.2.2 The Proposed Scheme
For convenience, let X be the color image with M rows and N columns:
X ¼ fR; G; Bg
R ¼ frijj1  i  M; 1  j  Ng
G ¼

gij
1  i  M; 1  j  N

B ¼ fbijj1  i  M; 1  j  Ng
(5.35)
where R, G, and B denote as the three components of the RGB color space of the X.
In our scheme, we perform the same process on R, G, and B separately. Without loss
of generality, we take the R channel, for example, to illustrate the data hiding and
extraction processes. The data hiding process consists of two main steps, one is to
obtain the BTC-compressed image data, and the other is to perform the DE tech-
nique on the obtained compressed data, which can be illustrated as follows:
Step 1. Perform AMBTC on the R component.
Step 1.1. The R image is divided into nonoverlapping m  n-sized blocks r(uv),
1  u  M/m, 1  v  N/n.
Step 1.2. Encode each block r(uv) by AMBTC to obtain the compressed triple
(luv, huv, puv).
Step 1.3. Collect all high means and low means to obtain the high mean table
Hr ¼ {huv, 1  u  M/m, 1  v  N/n} and the low mean table Lr ¼ {luv,
1  u  M/m, 1  v  N/n}. Finally, compose all bitplanes to obtain the bit-
plane sequence Pr ¼ {puv, 1  u  M/m, 1  v  N/n}.
Step 2. Hide data in (Hr, Lr) using the DE technique.
Step 2.1: Encode each pair (huv, luv) ˛ (Hr, Lr) by the integer Haar transform to
obtain the difference sequence Dr ¼ {duv, 1  u  M/m, 1  v  N/n} and the
mean sequence Er ¼ {euv, 1  u  M/m, 1  v  N/n}.
Step 2.2. Embed the secret data into the difference sequence Dr by the DE
technique as described in Section 2.2 to obtain the watermarked compressed
data

Hw
r ; Lw
r ; Pw
r

which can be used to reconstruct the watermarked R image.
Here, Pw
r ¼ Pr, which means that the bitplane is unchanged during the data
hiding process.
322
CHAPTER 5 Lossless Information Hiding in BTCeCompressed Images

Assume we have received the watermarked compressed data

Hw
r ; Lw
r ; Pr

of the
R image; our data extraction and image recovery process is very simple, which can
be illustrated as follows.
Step 1. Perform the integer Haar transform on each pair

hw
uv; lw
uv

˛

Hw
r ; Lw
r

to
obtain the difference sequence Dw
r ¼

dw
uv
u ¼ 1; 2; :::; M=m; v ¼ 1; 2; :::; N=n

and the mean sequence Ew
r ¼

ew
uv
u ¼ 1; 2; :::; M=m; v ¼ 1; 2; :::; N=n

.
Step 2. Extract the pure payload from Dw
r by the DE technique as shown in Section
2.2. Meanwhile, Hr and Lr can be also losslessly recovered from Dw
r and Ew
r .
Step 3. Reconstruct the R component of the BTC-compressed color image from
ðHr; Lr; PrÞ.
Based on these steps, we can extract all secret data and reconstruct the original
BTC-compressed color image, thus the whole reversible hiding process is realized.
5.5.2.3 Experimental Results
To evaluate the performance of the proposed scheme, we use six test color images,
Lena, Peppers, Sailboat, Goldhill, Zelda, and Jet_F16, of the same size 512  512,
as shown in Fig. 5.18. We choose three aspects of performance in the experiments to
evaluate our data hiding method, i.e., the capacity, representing the maximum num-
ber of secret bits that can be hidden; the PSNR, representing the quality of the stego
image; and the number of secret bits per pixel on average. In DE, a number of
FIGURE 5.18
Six test images.
5.5 Lossless Data Hiding in BTCeCompressed Color Images
323

changeable but nonexpendable differences should be recorded to avoid the overﬂow.
This recording information reduces the capacity for secret data. Table 5.9 shows the
number of this kind of differences in each image. Table 5.10 shows the evaluation
results.
5.5.3 BLOCKWISE CODINGeBASED SCHEME
To both embed more secret bits and reduce the coding bit rate, we can piece all high
(low) means as a high(low) mean table and then make full use of the correlation
among the neighboring high (low) means to encode the high (low) mean table
with less bits based on the secret data. The main idea of our blockwise scheme is
to ﬁrst perform the common bitplane color BTC on the original color image, obtain-
ing three high mean tables (Hr, Hg, Hb), three low mean tables (Lr, Lg, Lb), and one
bitplane sequence BPc, and then divide each mean table into nonoverlapping 2  2
blocks. Here, BPc ¼ {BPi,c}, Ht ¼ {Hi,t}, and Lt ¼ {Li,t}, where t ¼ r,g,b. Finally,
we encode the mean values in each 2  2 block according to four input secret bits
and the dynamic range evaluated by the difference between the maximal mean value
and the minimal mean value in the mean block. The proposed data embedding
scheme and extraction process can be illustrated in Sections 5.5.3.1 and 5.5.3.2,
respectively.
Table 5.9 Number of Overﬂow Differences in Each Image
Image
Number of Overﬂow
Lena
669
Peppers
3496
Sailboat
1628
Goldhill
24
Zelda
135
Jet_F16
736
Table 5.10 Evaluation Results
Image
Capacity
(Bits)
AMBTC
Compressed (dB)
Watermarked
(dB)
Recovered
(dB)
SBPP
Lena
37,955
33.22
26.94
33.22
0.14
Peppers
21,772
32.82
27.20
32.82
0.08
Sailboat
28,012
29.62
23.98
29.62
0.10
Goldhill
45,680
32.29
25.84
32.29
0.17
Zelda
44,377
35.56
29.42
35.56
0.17
Jet_F16
40,744
32.68
26.12
32.68
0.16
AMBTC, absolute moment block truncation coding; SBPP, secret bits per pixel.
324
CHAPTER 5 Lossless Information Hiding in BTCeCompressed Images

5.5.3.1 Data Embedding Process
With the six mean tables (Hr, Hg, Hb, Lr, Lg, Lb) in hand, now we can introduce our
reversible data hiding algorithm. Assume the secret bit sequence has length
6  M  N/(4  4), which is equal to the total number of mean values in six
mean tables, where M  N denotes the image size. That is to say, our scheme can
embed 6 bits in each 4  4-sized color image block. Before embedding, we perform
the permutation operation on the secret bit sequence to enhance the security. Our
embedding method is performed not mean by mean but on each 2  2 mean block
to make full use of the correlation between neighboring mean values, and thus the
encoding bit rate can be reduced. Since the data hiding process for each mean table
is the same, here we take the high mean table Hr to describe the lossless embedding
process. For convenience, we let H ¼ Hr in the following description. Assume the
high mean table H is segmented into nonoverlapping 2  2-sized blocks, huv,
where u ¼ 1, 2,.,M/8 and v ¼ 1, 2,.,N/8. Here, huv ¼ {h2u,2v, h2u,2vþ1, h2uþ1,2v,
h2uþ1,2vþ1}, and we adopt {“00,” “01,” “10,” “11”} to denote their locations accord-
ingly. For each 2  2 high mean block huv, assume the corresponding four secret bits
to be embedded are {w1, w2, w3, w4}, the data hiding process can be illustrated in
detail as follows.
Step 1: Find the maximal and minimal mean values hmax and hmin in huv, and
record their location bits wmax ˛ {“00,” “01,” “10,” “11”} and wmin ˛ {“00,”
“01,” “10,” “11”}.
Step 2: Calculate the dynamic range r ¼ hmax  hmin. Since the dynamic range r
belongs to the interval [0,255], we consider eight cases as shown in Table 5.11.
Obviously, it requires 3 bits to denote each case. Append these 3 bits (called
range bits wran) to the codestream.
Step 3: Viewing the ﬁrst two secret bits w1 and w2 as the location bits, ﬁnd the
reference high mean href in huv. (e.g., if the ﬁrst two secret bits are “01,” then
href ¼ h2u,2vþ1). Append the two secret bits wref ¼ w1jjw2 (called reference
Table 5.11 Eight Cases Considered for Coding the Mean Differences
Case
Dynamic range r (r [ hmaxLhmin
for High Means, While r
[ lmaxLlmin for Low Means)
Range Bits wran
c (Number of Bits
Required to Code
Each Difference)
Case 1
0  r < 2
“000”
1
Case 2
2  r < 4
“001”
2
Case 3
4  r < 8
“010”
3
Case 4
8  r < 16
“011”
4
Case 5
16  r < 32
“100”
5
Case 6
32  r < 64
“101”
6
Case 7
64  r < 128
“110”
7
Case 8
r  128
“111”
8
5.5 Lossless Data Hiding in BTCeCompressed Color Images
325

location bits) followed by the eight bits (href)2 to the codestream. Here, jj
denotes the concatenation operation and ($)2 denotes the operation to get the
binary description of a number.
Step 4: According to the third secret bit w3, select the comparison high mean hcom
out of {hmax, hmin}. If w3 ¼ 1, then set hcom ¼ hmax and wcom ¼ wmax; otherwise,
if w3 ¼ 0, then set hcom ¼ hmin and wcom ¼ wmin. Here we should consider two
cases. In Case 1, the reference and comparison high means are located at the
same position, i.e., href ¼ hcom and wref ¼ wcom. Denote the remainder three high
mean values in huv as hA, hB, and hC, respectively (in the raster-scan order). In
Case 2, the reference and comparison high means are located at different po-
sitions, i.e., wref s wcom. Except for hcom, we deﬁne hA ¼ href and denote the
remainder two high mean values in huv as hB and hC, respectively (in the raster-
scan order). Append the third secret bit w3 followed by the two comparison
location bits wcom to the codestream.
Step 5: According to the secret bits w3 and w4, we calculate the differences
among hcom, hA, hB, and hC. If w4 ¼ 0 and w3 ¼ 0, then dA ¼ hA  hcom,
dB ¼ hB  hcom, and dC ¼ hC  hcom. If w4 ¼ 0 and w3 ¼ 1, then dA ¼ hcom  hA,
dB ¼ hcom  hB, and dC ¼ hcom  hC. If w4 ¼ 1 and w3 ¼ 0, then dA ¼ hcom  hA,
dB ¼ hcom  hB, and dC ¼ hcom  hC. If w4 ¼ 1 and w3 ¼ 1, then dA ¼ hA  hcom,
dB ¼ hB  hcom, and dC ¼ hC  hcom. We easily ﬁnd that w4 can indicate the sign
of the differences, i.e., if w4 ¼ 0, the sign is positive; otherwise, the sign is
negative.
Step 6: According to the dynamic range r given in Table 5.11, we look up the
number of bits (denoted by c) required to encode each difference. If w4 ¼ 0, 3c
bits are used to denote (dA)2, (dB)2, and (dC)2. Otherwise, if w4 ¼ 1, 3c bits are
used to denote (dA)2, (dB)2, and (dC)2. Append the fourth secret bit w4
followed by the 3c bits of dA, dB, and dC to the codestream.
Performing Steps 1e6 for each 2  2 high mean block huv, we can hide 4 bits in
each high mean block and output a bit string whose length is 17 þ 3c, as given in
Fig. 5.19. Similarly, by performing Steps 1e6 for each low mean block luv, we
can also hide 4 bits in each low mean block. Here, we should note that c is different
from block to block. If most of the mean blocks are with c  5, then the bit rate can
be reduced compared to the original mean table where 32 bits are required to denote
four mean values in each mean block.
Three range 
bits wran
Two reference location 
bits wref =w1||w2
8-bit reference 
mean h ref (or  ref)
Two comparison 
location bits wcom
The third 
secret bit w3
The fourth 
secret bit w4
l
FIGURE 5.19
The bit string structure for encoding each mean block.
326
CHAPTER 5 Lossless Information Hiding in BTCeCompressed Images

5.5.3.2 The Data Extraction Process
Our data hiding scheme is reversible because we can recover the original mean ta-
bles after data extraction, and thus the original BTC-compressed image can be loss-
lessly recovered. Given the codestream, our purpose is to extract the secret bit
sequence and recover the original BTC-compressed image. Since the reconstruction
process for each mean table is the same, here we take the reconstruction process for
each high mean table H to describe the extraction process as follows.
Step 1: Read the next 3 bits into wran from the codestream of the high mean table
H, ﬁnd the corresponding case in Table 5.11, and look up the value c in
Table 5.11.
Step 2: Read the next 10 bits from the codestream of the high mean table. Get the
ﬁrst 2 bits w1 and w2 as the reference location bits wref, append them to the
output secret bit sequence. Transform the last 8 bits into the reference high
mean href, and put this mean in the current mean block according to the location
bits wref.
Step 3: Read the next 3 bits from the codestream of the high mean table. Get the
ﬁrst bit w3, and append it to the output secret bit sequence. Get the last 2 bits as
the comparison location bits wcom.
Step 4: Read the next 1 þ 3c bits from the codestream of the high mean table. Get
the ﬁrst bit w4, append it to the output secret bit sequence. Transform the
following three c bits into three positive difference values dAþ, dBþ, and dCþ. If
w4 ¼ 0, dA ¼ dAþ, dB ¼ dBþ, and dC ¼ dCþ; otherwise, dA ¼ dAþ, dB ¼ dBþ,
and dC ¼ dCþ.
Step 5: Except for the reference high mean, recover the other three mean values
in the current 2  2 high mean block. Here, we should consider two cases:
Case 1: wref ¼ wcom. In this case, the reference high mean is just the comparison
high mean, and thus hcom ¼ href. If w4 ¼ 0 and w3 ¼ 0, then hA ¼ dA þ hcom,
hB ¼ dB þ hcom, and hC ¼ dC þ hcom. If w4 ¼ 0 and w3 ¼ 1, then hA ¼ hcom  dA,
hB ¼ hcom  dB, and hC ¼ hcom  dC. If w4 ¼ 1 and w3 ¼ 0, then hA ¼ hcom  dA,
hB ¼ hcom  dB, and hC ¼ hcom  dC. If w4 ¼ 1 and w3 ¼ 1, then hA ¼ dA þ hcom,
hB ¼ dB þ hcom, and hC ¼ dC þ hcom. Put hA, hB, and hC at the remainder three
locations in the raster-scan order.
Case 2: wref s wcom. In this case, hA is the difference between hcom and href. If
w4 ¼ 0 and w3 ¼ 0, then hcom ¼ dA  href. If w4 ¼ 0 and w3 ¼ 1, then
hcom ¼ href þ dA. If w4 ¼ 1 and w3 ¼ 0, then hcom ¼ href þ dA. If w4 ¼ 1 and
w3 ¼ 1, then hcom ¼ dA  href. Put hcom in the current 2  2 high mean block
according to the location bits wcom. Now turn to recover left two indices. If
w4 ¼ 0 and w3 ¼ 0, then hB ¼ dB þ hcom and hC ¼ dC þ hcom. If w4 ¼ 0 and
w3 ¼ 1, then hB ¼ hcom  dB and hC ¼ hcom  dC. If w4 ¼ 1 and w3 ¼ 0, then
hB ¼ hcom  dB and hC ¼ hcom  dC. If w4 ¼ 1 and w3 ¼ 1, then hB ¼ dB þ hcom
and hC ¼ dC þ hcom. Put hB and hC at the remainder two locations in the raster-
scan order.
5.5 Lossless Data Hiding in BTCeCompressed Color Images
327

By repeatedly performing Steps 1e5 for all 2  2 high mean blocks, we can
recover three high mean tables and output the half secret bit sequence. Similarly,
by performing Steps 1e5 for all 2  2 low mean blocks, we can recover three
low mean tables and output another half secret bit sequence.
5.5.3.3 Experimental Results
To evaluate the proposed scheme, we use six color images, i.e., Lena, Baboon,
Jet_F16, Goldhill, Sailboat, and Zelda of the same size 512  512. Comparisons
among our algorithm, Chang et al.’s algorithm [19], and Chou and Chang’s algo-
rithm [20] are performed under the same block size 4  4. Four aspects of perfor-
mance are adopted in the experiments to evaluate a data hiding scheme, i.e., the
capacity representing the maximum number of secret bits that can be hidden; the
PSNR, representing the quality of the stego image; the bit rate, representing the per-
formance of the compression efﬁciency whose unit is bpp; and the embedding efﬁ-
ciency, indicating the number of embedded secret data when a bit of the binary code
stream has been transmitted. Obviously, the embedding efﬁciency can be calculated
as Capacity/(bit rate  M  N). As shown in Table 5.12, the PSNRs of stego images
based on our, Chang et al.’s, and Chou and Chang’s schemes are exactly the same as
those of the common bitplane color BTC-compressed images, the reason being that
these three schemes are reversible. From Table 5.12, we can obviously see that the
proposed scheme is a more effective method for its high capacity, high embedding
efﬁciency, and low bit rate.
Table 5.12 Comparisons of the Proposed, Chang et al.’s, and Chou and Chang’s
Schemes
Algorithm
Performance
Lena
Baboon
F16
Goldhill
Sailboat
Zelda
Common
bitplane
color BTC
PSNR (dB)
31.52
22.88
31.99
31.50
27.71
34.81
Bit rate (bpp)
4.000
4.000
4.000
4.000
4.000
4.000
Proposed
PSNR (dB)
31.52
22.88
31.99
31.50
27.71
34.81
Capacity (bits)
98,304
98,304
98,304
98,304
98,304
98,304
Bit rate (bpp)
3.500
3.828
3.433
3.619
3.625
3.604
Efﬁciency
0.107
0.098
0.109
0.104
0.103
0.104
Chang
et al.’s
PSNR (dB)
31.52
22.79
31.93
31.50
27.69
34.81
Bit rate (bpp)
4.162
4.291
4.141
4.169
4.150
4.061
Capacity (bits)
60,771
59,265
62,493
62,209
62,420
63,926
Efﬁciency
0.056
0.053
0.058
0.0570
0.057
0.060
Chou and
Chang’s
PSNR (dB)
31.52
22.88
31.99
31.50
27.71
34.81
Bit rate (bpp)
4.351
4.375
4.257
4.281
4.378
4.445
Capacity (bits)
57,876
58,072
60,778
60,574
58,887
57,834
Efﬁciency
0.051
0.051
0.055
0.054
0.051
0.050
BTC, block truncation coding; PSNR, peak signal-to-noise ratio.
328
CHAPTER 5 Lossless Information Hiding in BTCeCompressed Images

5.6 SUMMARY
This chapter discusses lossless information hiding schemes for BTC-compressed
image. These schemes can be broadly classiﬁed into three categories, i.e., bitplane
ﬂippingebased schemes for BTC-compressed grayscale images, mean codinge
based schemes for BTC-compressed grayscale images, and lossless data hiding
schemes in BTC-compressed color images.
The ﬁrst category includes three schemes, i.e., original bitplane ﬂippingebased
scheme, improved bitplane ﬂippingebased scheme, and bitplane ﬂippingebased
scheme with histogram shifting of mean tables. The third method is proposed by
us. Through histogram shifting of mean tables, our scheme can maintain the same
PSNR values as the original AMBTC technique. We embed secret bits in two
mean tables, and also more secret bits in bitplanes if there are some blocks whose
high mean equals its low mean; thus our scheme can obtain higher capacity. Further-
more, our scheme is separated into the AMBTC compression process for generating
two mean tables together with one bitplane sequence and the data hiding process to
embed secret data into the output codestream, which facilitates the individual pro-
cessing of the encoder and the watermark embedder and the controlling of the cor-
responding performance.
The second category includes three methods, i.e., prediction-error expansione
based scheme, JNC-based scheme, and blockwise codingebased scheme, and all
of them are proposed by us. All these methods are separated into the AMBTC
compression process for generating two mean tables and the data hiding process
to embed secret data into the output codestream, which facilitates the individual pro-
cessing of the encoder and the watermark embedder and the control of overall per-
formance. In the ﬁrst method, by introducing the prediction-error expansion
technique, both high and low means of one BTC image block could hide one secret
bit, thus one block could hide 2 bits. Moreover, additional overﬂow/underﬂow loca-
tion map, which is generally needed in other algorithms is not required. Further-
more, the blocks whose high and low means are equal can embed much more
secret bits. Through tuning parameter the proposed scheme balances the embedding
capacity and image quality of the output image. In the second method, we embed
secret data in two mean tables and each value in the table can embed two secret
data, thus our scheme can obtain capacity four times as large as the number of blocks
in the input image. In the decoding part, the AMBTC-compressed image and the se-
cret data can be recovered separately, which not only can further protect the secret
data but also makes the decoding of the compressed image public. The third method
is based on 2  2 mean blocks, which can make full use of the correlation among
mean values, thus it can reduce the bit rate compared with the original AMBTC.
On the other hand, we embed secret data in two mean tables, thus our scheme can
obtain double capacity.
The third category includes DE-based scheme and blockwise codingebased
scheme. The main idea of the ﬁrst scheme is to apply the DE technique to BTC-
compressed data. Experimental results demonstrate that the ﬁrst scheme can embed
5.6 Summary
329

a large amount of secret data reversibly while maintaining perfect visual quality. The
main idea of the second scheme is to encode the mean values in each 2  2 block
according to four input secret bits and the dynamic range evaluated by the difference
between the maximal mean value and the minimal mean value in the mean block.
Experimental results demonstrate that the second scheme can embed a large amount
of secret data reversibly while reducing the bit rate.
REFERENCES
[1] E.J. Delp, O.R. Mitchell, Image compression using block truncation coding, IEEE
Transactions on Communications 27 (9) (1979) 1335e1342. COM.
[2] M.D. Lema, O.R. Mitchell, Absolute moment block truncation coding and its applica-
tion to color images, IEEE Transactions on Communications 32 (10) (1984)
1148e1157. COM.
[3] Z.M. Lu, C.H. Liu, S.H. Sun, Digital image watermarking technique based on block
truncation coding with vector quantization, Chinese Journal of Electronics 11 (2002)
152e157.
[4] M.H. Lin, C.C. Chang, A novel information hiding scheme based on BTC, in: Proceed-
ings of the 4th International Conference on Computer and Information Technology,
Wuhan, China, 2004.
[5] J.C. Chuang, C.C. Chang, Using a simple and fast image compression algorithm to hide
secret information, International Journal of Computers and Applications 28 (2006)
329e333.
[6] C.N. Yang, Z.M. Lu, Blind fragile image watermarking based on vector quantization
and block truncation coding, ICIC Express Letters Part B: Applications 2 (4) (2011)
905e910.
[7] C.N. Yang, Z.M. Lu, A blind image watermarking scheme utilizing BTC bitplanes, In-
ternational Journal of Digital Crime and Forensics 3 (4) (2011) 42e53.
[8] Y. Zhang, Z.M. Lu, D.N. Zhao, An oblivious fragile watermarking scheme for images
utilizing edge transitions in BTC bitmaps, Science China Information Sciences 55 (11)
(2012) 2570e2581.
[9] W. Hong, T.S. Chen, C.W. Shiu, Lossless steganography for AMBTC compressed im-
ages, in: Proceedings of the First International Congress on Image and Signal Process-
ing, vol. 2, 2008, pp. 13e17.
[10] J. Chen, W. Hong, T.S. Chen, C.W. Shiu, Steganography for BTC compressed images
using no distortion technique, The Imaging Science Journal 58 (4) (2010) 177e185.
[11] Z.F. Chen, Z.M. Lu, Y.X. Su, High-capacity reversible data hiding scheme for optimal
common-bitplane BTC-compressed color images, ICIC Express Letters 5 (12) (2011)
4251e4256.
[12] Z.F. Chen, Y.X. Su, Z.M. Lu, Reversible data hiding for BTC-compressed color images
using difference expansion, ICIC Express Letters Part B: Applications 2 (5) (2011)
1213e1218.
[13] C.H. Li, Z.M. Lu, Y.X. Su, Reversible data hiding for BTC-compressed images based
on bitplane ﬂipping and histogram shifting of mean tables, Information Technology
Journal 10 (3) (2011) 1421e1426.
330
CHAPTER 5 Lossless Information Hiding in BTCeCompressed Images

[14] H. Luo, Z.F. Zhao, Z.M. Lu, Joint secret sharing and data hiding for block truncation
coding compressed image transmission, Information Technology Journal 10 (3)
(2011) 681e685.
[15] K. Wang, Y.J. Hu, Z.M. Lu, Reversible data hiding for block truncation coding com-
pressed images based on prediction-error expansion, in: The 2012 Eighth International
Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-
MSP 2012), July 18e20, 2012, pp. 317e320. Piraeus-Athens, Greece.
[16] Y. Zhang, S.Z. Guo, Z.M. Lu, H. Luo, Reversible data hiding for BTC-compressed im-
ages based on lossless coding of mean tables, IEICE Transactions on Communications
E96-B (2) (2013) 624e631.
[17] W. Sun, Z.M. Lu, Y.C. Wen, F.X. Yu, R.J. Shen, High performance reversible data hid-
ing for block truncation coding compressed images, Signal, Image and Video Process-
ing 7 (2) (2013) 297e306.
[18] Z. Qian, X. Zhang, Lossless data hiding in JPEG bitstream, The Journal of Systems and
Software 85 (2) (2012) 309e313.
[19] C.C. Chang, C.Y. Lin, Y.H. Fan, Lossless data hiding for color images based on block
truncation coding, Pattern Recognition 41 (7) (2008) 2347e2357.
[20] Y.C. Chou, H.H. Chang, A data hiding scheme for color image using BTC compression
technique, in: Proceedings of the 9th IEEE International Conference on Cognitive Infor-
matics, 2010, pp. 845e850.
[21] J. Tian, Reversible data embedding using a difference expansion, IEEE Transactions on
Circuits System for Video Technology 13 (8) (2003) 890e896.
References
331

Lossless Information
Hiding in JPEG- and
JPEG2000-Compressed
Images
6
6.1 INTRODUCTION
6.1.1 JPEG
In this section, a brief introduction to the JPEG concept and the JPEG compression
process is given. JPEG is a common lossy compression method for digital images.
The JPEG standard consists of two types of compression methods, i.e., discrete
cosine transform (DCT)ebased methods and prediction-based methods given by
Wallace [3]. The former are designed for lossy compression, whereas the latter
are designed for lossless compression. JPEG features a simple lossy mode known
as the baseline method, which is a subset of the other DCT-based modes of opera-
tion. The baseline method has been the most widely used JPEG method so far, thus
this chapter focuses on the baseline method.
Fig. 6.1 shows the main steps of the baseline method. An input image is ﬁrst
divided into 8  8 nonoverlapping blocks, and then each block is applied by the for-
ward DCT (FDCT) to get a set of 64 DCT coefﬁcients. Mathematical deﬁnitions of
8  8 FDCT and 8  8 inverse DCT (IDCT) are as follows:
Fðu; vÞ ¼ 1
4 CðuÞCðvÞ
2
4 X
7
x¼0
X
7
y¼0
fðx; yÞcos ð2x þ 1Þup
16
cos ð2y þ 1Þvp
16
3
5
(6.1)
CHAPTER
FDCT
Quantizer
Entropy
Coder
Compressed
Data Stream
Input
Image
Quantization
Table
Huffman
Table
FIGURE 6.1
The block diagram of the JPEG encoder. FDCT, forward discrete cosine transform.
Lossless Information Hiding in Images. http://dx.doi.org/10.1016/B978-0-12-812006-4.00006-1
Copyright © 2017 Zhejiang University Press Co., Ltd., published by Elsevier Inc. All rights reserved.
333

fðx; yÞ ¼ 1
4
" X
7
u¼0
X
7
v¼0
CðuÞCðvÞFðu; vÞcos ð2x þ 1Þup
16
cos ð2y þ 1Þvp
16
#
(6.2)
where: CðuÞ ¼
8
>
<
>
:
1ﬃﬃﬃ
2
p
u ¼ 0
1
otherwise
To compress the image data, these coefﬁcients are then quantized by using a
quantization table with 64 entries. The standard quantization table is shown in
Fig. 6.2. The quantized coefﬁcients are all integers, which are obtained by dividing
each DCT coefﬁcient by its corresponding value in the quantization table and round-
ing to the nearest integer as follows:
Dðu; vÞ ¼ IntegerRound
Fðu; vÞ
Qðu; vÞ

(6.3)
where F(u,v) means the original DCT coefﬁcient, Q(u,v) means the corresponding
value in the quantization table, and D(u,v) means the quantized DCT coefﬁcient.
Because of the rounding loss, the quantization step is not lossless. The ﬁnal data
stored in the JPEG ﬁle are the quantized DCT coefﬁcients, which are entropy coded
and saved in the entropy-coded segment of the JPEG ﬁle. The quantization table is
stored in the Deﬁne Quantization Table (DQT) segment. In this chapter, our exper-
iment is done with the JPEG library “Libjpeg” developed by the Independent JPEG
Group (IJG) (http://www.ijg.org/). The quantization table in Libjpeg is controlled by
14
14
18
24
49
72
12
13
17
22
35
64
92
16
12
16
22
37
55
78
95
11
14
24
29
56
64
87
98
10
19
40
51
68
81
103
112
16
26
57
87
109
104
121
100
24
58
69
56
80
62
103
77
113
92
120
101
103
99
40
60
51
55
61
FIGURE 6.2
The JPEG standard quantization table.
334
CHAPTER 6 Lossless Information Hiding

the quality factor (QF), which is an integer in the interval [1100]. Libjpeg adopts the
following transformation to get the scale factor to form a new quantization table:
ScaleFactor ¼
8
>
<
>
:
5000
QF
QF < 50
200  2QF
otherwise
(6.4)
Then it multiplies every entry of the standard quantization table by ScaleFactor/
100 and then rounds the resulting value to its nearest integer. If the result is smaller
than 1, then it is set to 1.
Qnewðu; vÞ ¼ max

IntegerRound
Qstandardðu; vÞ$ScaleFactor
100

; 1

(6.5)
From Eqs. (6.4) and (6.5), we can see that when the image QF equals 50, the
standard quantization table is used.
The ﬁnal step is the lossless step called entropy coding. The quantized coefﬁ-
cients are ﬁrst scanned in the zigzag manner as shown in Fig. 6.3. For natural im-
ages, there are a lot of consecutive zeros in the high-frequency portion, which
helps to further compress the image using entropy coding. Thus, AC (alternating
current) coefﬁcients can be encoded by zero run length coding (ZRLC). The DC
(direct current) coefﬁcient corresponds to the lowest frequency in an 8  8 block,
which is the average value over the 64 pixels. Usually there is a very close correla-
tion between the DCT coefﬁcients of adjacent blocks, thus the encoding of the quan-
tized DC coefﬁcient is performed on the difference between the quantized DC
DC
AC
AC
FIGURE 6.3
The zigzag sequence.
6.1 Introduction
335

coefﬁcients of the two consecutive blocks. Finally, the intermediate sequence of
symbols is converted to a data stream by Huffman coding.
The JPEG decoding process shown in Fig. 6.4 is the inverse process of JPEG
encoding. The decoding process mainly consists of three steps, i.e., entropy decod-
ing, dequantization, and IDCT. The decoder reads the quantization table and the
quantized DCT coefﬁcients from the DQT segment and entropy-coded segment,
respectively. The decoder then multiplies the quantized DCT coefﬁcients by corre-
sponding elements in the quantization table and applies IDCT to the results to obtain
uncompressed image.
If an input grayscale image is compressed into the JPEG format by the JPEG
encoder, it is saved in the form of bitstream. Fig. 6.5 shows the structure of the
JPEG bitstream. It starts with an SOI (start of image) marker and ends with an
EOI (end of image) marker. There is one frame containing several segments between
the two markers. Among these segments, the DHT (Deﬁne Huffman Table) and SOS
(start of scan) segments are shown in Fig. 6.5. The data in the DHT segment are used
to generate the Huffman table. For example, the AC coefﬁcients are coded in a spe-
ciﬁc run length encoding (RLE) format as intermediate symbols (variable length
code (VLC), variable length integer (VLI)). Each VLC is deﬁned as (run, size) and
encoded by a Huffman code. Here, run denotes the zero run length, and each
nonzero AC coefﬁcient can be obtained by its corresponding size and VLI values.
Li in the DHT segment stands for the number of VLCs whose code length is i,
and Vi,j is the (run, size) value of the jth code whose code length is i. According
to a speciﬁc rule, the Huffman table can be established itself with these aforemen-
tioned data. The SOS segment has a scan header and an entropy-coded segment. The
image content is saved in the entropy-coded segment, and particularly the AC coef-
ﬁcients are represented in the form of several (VLC, VLI)s. More details can be seen
in the JPEG guidelines [4].
6.1.2 JPEG2000
The block diagram of the JPEG2000 codec [1,2] is shown in Fig. 6.6. In the
JPEG2000 encoder, image preprocessing is performed at ﬁrst. Here, image prepro-
cessing includes image tiling, DC level shifting, and component transformation. Im-
age tiling is applied to the original image by dividing it into rectangular
IDCT
Dequantizer
Entropy
Decoder
Compressed
Data Stream
Output
Image
Quantization
Table
Huffman
Table
FIGURE 6.4
The block diagram of the JPEG decoder. IDCT, inverse discrete cosine transform.
336
CHAPTER 6 Lossless Information Hiding

nonoverlapping blocks (tiles). These blocks can be processed independently. DC
level shifting can ensure that the input sample data has a nominal dynamic range
that is approximately centered about 0. Then component transformation or color
transformation is performed on the tile-component data. Only two component trans-
formations are deﬁned in the baseline JPEG2000 codec, i.e., irreversible component
transform (ICT) and reversible component transform (RCT). Both of them can map
the image data from the RGB color space to the YCbCr color space. Next, these tiles
are decomposed into different decomposition levels by the forward discrete wavelet
transform (FDWT). After N levels of discrete wavelet transform (DWT), we can get
the decomposed image, which is made up of a low-frequency subband called LLN
and 3  N high-frequency subbands referred to as HLi, LHi, HHi, where i ¼ 1, 2,
.N. Fig. 6.7 shows the subband structure after three levels of DWT. Then the result-
ing wavelet coefﬁcients in all subbands are quantized. Next, entropy coding
including tier-1 coding and tier-2 coding is applied to the quantized blocks to
generate JPEG2000-ompressed bitstream. With this step, the encoding process is
ﬁnished. The decoding process of the JPEG2000 codec is just the reverse of the
encoding process.
FIGURE 6.5
JPEG bitstream structure. DHT, Deﬁne Huffman Table; EOI, end of image; SOI, start of
scan; SOS, start of scan.
Preprocessing
FDWT
Quantization
Tier-1
Encoder
Tier-2
Encoder
Rate Control
Original
Image
Compressed
Bitstream
Encoder
Tier-2
Decoder
Tier-1
Decoder
De-quantization
IDWT
Postprocessing
Compressed
Bitstream
Decoder
Reconstructed
Image
(a)
(b)
FIGURE 6.6
Block diagram of JPEG2000 codec. FDWT, forward discrete wavelet transform; IDWT,
inverse discrete wavelet transform.
6.1 Introduction
337

6.1.3 CHALLENGES
Among various data hiding techniques, the reversible ones for the JPEG domain are
still only a few and there is a huge margin for improvement in both the stego image
quality and the capacity. For the purpose of making the inﬂuence caused by data hid-
ing as small as possible, the selection of embedding positions should be carefully
considered. As Huang et al. [5] said, traditional data hiding techniques tended to
choose the midfrequency DCT coefﬁcients in the DCT transform domain. However,
when considering the quantization stage, things may be different. Thus, the earlier
techniques might affect the researchers’ choice on embedding positions in the
JPEG-compressed domain. Most existing lossless data hiding techniques increase
the ﬁle size after embedding the secret data, which negates the advantages of the
lossless data hiding scheme. Lossless data hiding with ﬁle size preservation is
now a new important research subarea. Embedding data into the JPEG bitstream,
which is one of the open compression standards, has two limitations of weak security
and fragility [6]. The JPEG bitstream must be viewable by normal viewers, and it is
also available for the third party. Attackers may reencode the JPEG image to erase
the embedded data or replace it using the open algorithm.
Embedding data into JPEG2000 images has some differences from embedding
data into other types of images. The differences will lead to some difﬁculties. As
a compressed image, the redundancy of a JPEG2000 image is smaller than that of
an uncompressed image such as a BMP image. So the space for data hiding is
limited. This will increase the difﬁculty of data hiding. In addition, the encoding pro-
cess of JPEG2000 is more complex. Some encoding operations such as quantization
and bitstream layering probably destroy the hidden data. It requires that data hiding
should be coordinated with the encoding process of JPEG2000. So selecting a suit-
able embedding position is important and difﬁcult.
HH1
HL1
LH1
HH2
HL2
LH2
HL3
HH3
LH3
LL3
FIGURE 6.7
The subband structure.
338
CHAPTER 6 Lossless Information Hiding

6.2 LOSSLESS INFORMATION HIDING IN JPEG IMAGES
6.2.1 OVERVIEW OF INFORMATION HIDING IN JPEG IMAGES
The JPEG image format is a widely used compressed format. For JPEG images, as
early as in 1997, Upham [7] ﬁrst developed a famous hiding tool for JPEG images
named Jpeg-Jsteg, where the secret data are embedded into the least signiﬁcant bits
(LSBs) of the quantized DCT coefﬁcients whose values are not 0, 1 or 1. Westfeld
[8] developed the so-called F5 algorithm, which implements matrix encoding to
improve the embedding efﬁciency. In addition, F5 also employs permutative strad-
dling to uniformly spread out the changes over the whole steganogram. Both these
methods are irreversible with a low capacity. In the same year, Fridrich et al. [9] pre-
sented for the ﬁrst time two invertible watermarking methods for authentication of
digital images in the JPEG domain, where they modiﬁed the quantization matrix to
enable lossless embedding of 1 bit per DCT coefﬁcient. Fridrich et al. [10] proposed
a new idea to losslessly compress the LSB plane of some selected JPEG mode
coefﬁcients to make space for reversible data embedding. Later, Chang et al. [11]
presented a reversible hiding scheme to modify the quantization table and hide
the secret data in the cover image based on the midfrequency-quantized DCT coef-
ﬁcients. Iwata et al. [12] proposed a hiding scheme by modifying the boundaries be-
tween zero and nonzero quantized DCT coefﬁcients in each block. However, it is
irreversible with a low capacity. Inspired by Iwata et al.’s scheme, Chang et al.
[13] proposed a lossless steganography scheme to hide secret data in the quantized
DCT coefﬁcients of each block in JPEG images. In the same year, Xuan et al. [14]
proposed a scheme to shift the quantized DCT coefﬁcient histogram and then embed
data based on histogram pairs. Later, Sakai et al. [15] improved Xuan et al.’s scheme
and yielded better image quality by judging whether a block is suitable for embed-
ding data or not. Almohammad et al. [16] extended the method of Chang et al. [11]
by using an optimized 16  16 quantization table and improved the stego image
quality and the embedding capacity. Later, Cheng and Yoo [17] proposed a revers-
ible scheme, which is similar to the schemes of Iwata and Chang et al. [13], and per-
formed multilevel embedding to reach a higher capacity. Zhang et al. [18] proposed
a reversible data hiding method to carry the watermark for JPEG image
authentication.
With regard to existing reversible data hiding techniques for JPEG domain, the
stego image quality and the capacity should be further improved. The method of Fri-
drich et al. [10] divided some elements of the quantization table by a factor; at the
same time, the corresponding quantized DCT coefﬁcients were simply multiplied by
the same factor to make space for embedding. Lin and Chan [19] proposed an invert-
ible secret image sharing with a steganography scheme. The secret pixels are ﬁrst
transformed into k-ary notational numbers, then encrypted into shared data, and
ﬁnally shared along with the information data based on the (t,n)-threshold sharing
scheme with a modulo operation.
6.2 Lossless Information Hiding in JPEG Images
339

Most existing lossless data hiding techniques, including those mentioned previ-
ously, increase the ﬁle size after embedding the secret data, which negates the advan-
tages of the lossless data hiding scheme. Lossless data hiding with ﬁle size
preservation is now a new important research subarea. In 2004, Fridrich et al.
[20] introduced a lossless watermarking technique that preserves the ﬁle size for
the ﬁrst time. In their work, the watermark is embedded into the VLI codes of AC
coefﬁcients encoded by RLE. Mobasseri et al. [6] proposed an algorithm to embed
data directly into the bitstream of JPEG image by ﬂipping 1 bit of the VLC or the
appended bits and applying an error concealment technique to minimize the image
quality loss. Inspired by Mobasseri et al.’s method, Qian and Zhang [21] presented a
method to embed the secret data into the JPEG bitstream by Huffman code mapping,
guaranteeing no quality distortion while providing more embedding capacity. Their
method maps several unused codes to one used code instead of ﬂipping bits and con-
cealing errors in the used codes.
In the following six subsections, seven typical methods (note that Fridrich et al.
presented two schemes for image authentication) including two schemes from the
authors are introduced. For the ﬁrst ﬁve schemes, we only introduce the basic ideas,
whereas for the schemes from the authors, we provide a detailed introduction with
experimental results.
6.2.2 FRIDRICH ET AL.’S INVERTIBLE WATERMARKING METHODS
FOR IMAGE AUTHENTICATION
Fridrich et al. presented two reversible watermarking methods for JPEG image
authentication in 2001 [9]. The ﬁrst one is based on lossless compression of biased
bitstreams of the quantized coefﬁcients. The second one modiﬁes the quantization
matrix to enable lossless embedding of 1 bit per DCT coefﬁcient. Both methods
are fast and can be used for general lossless data embedding. They provide informa-
tion assurance tools for integrity protection of sensitive imagery, such as medical
images or military images.
6.2.2.1 Method 1
Assume that there is a JPEG ﬁle X represented in a discrete form using bits. Let us
identify a subset E3X that can be randomized without changing the essential prop-
erties of X. For authentication, the subset E needs to have enough structure to allow
lossless compression by at least 128 bits (e.g., the hash of X). We can then authen-
ticate X in a lossless manner by replacing the subset E with an encrypted version of
its compressed form concatenated with the hash H(X).
Note that if the set E is easily compressible, we do not need to work with the
whole set E but only with a smaller portion of it, which would give us enough space
for the hash after lossless compression. Fridrich et al. used this general authentica-
tion principle to develop lossless authentication of JPEG ﬁles. JPEG compression
starts with dividing the image into disjoint blocks of 8  8 pixels. For each block,
DCT is performed, obtaining 64 DCT coefﬁcients. Let us denote the (i, j)th DCT
340
CHAPTER 6 Lossless Information Hiding

coefﬁcient of the kth block as dk(i, j), 0  i, j  7, k ¼ 1, 2, ., B, where B is the
total number of blocks in the image. In each block, all 64 coefﬁcients are further
quantized to integers Dk(i, j) with a JPEG quantization matrix Q:
Dkði; jÞ ¼ IntegerRound
dkði; jÞ
Qði; jÞ

(6.6)
The quantized coefﬁcients are arranged in a zigzag manner and then compressed
using the Huffman coder. The compressed stream together with a header forms the
ﬁnal JPEG ﬁle. The largest DCT coefﬁcients occur for the lowest frequencies (small
i and j). Owing to properties of typical images and due to quantization, the quantized
DCT coefﬁcients corresponding to higher frequencies have a large number of zeros
or small integers, such as 1s or -1s. For example, for the classical grayscale image
“Lena” of size 256  256, the DCT coefﬁcient in the position (5, 5) is 0 in 94.14%
blocks. For 2.66% cases, it is equal to 1, and for 2.81% cases, it is equal to 1, with
less than 1% of 2s and 2s. Thus, the sequence Dk(5, 5) forms a subset E that is
easily compressible with a simple Huffman or arithmetic coder. Furthermore, if
the message bits (the hash) are embedded into the LSBs of the coefﬁcients
Dk(5,5), we only need to compress the original LSBs of the sequence Dk(5,5) instead
of the whole sequence. The efﬁciency of the algorithm can be further improved if the
LSB of negative integers Dk < 0 is deﬁned as LSB(Dk) ¼ 1  (jDkj mod 2). Thus,
LSB(1) ¼ LSB(3) ¼ 0, and LSB(2) ¼ LSB(4) ¼ 1, etc. Because DCT coef-
ﬁcients Dk have a symmetrical distribution with zero mean, this simple measure will
increase the bias between 0s and 1s in the LSB bitstream of original DCT
coefﬁcients.
DCT coefﬁcients Dk(i, j) corresponding to higher frequencies will produce a set
E with a larger bias between 0s and 1s, but because the quantization factor Q(i,j) is
also higher for such coefﬁcients, the distortion in each modiﬁed block will also be
higher. To obtain the best results, we should use different DCT coefﬁcients for
different JPEG QFs to minimize the overall distortion and avoid introducing easily
detectable artifacts.
Following is the pseudocode for lossless authentication of grayscale JPEG ﬁles.
6.2.2.1.1 Algorithm for Lossless Authentication of JPEG Files
Step 1. According to the JPEG QF, select the set of L authentication pairs (i1, j1),
(i2, j2), ., (iL, jL), 0  il, jl  7, 1  l  L, in middle frequencies.
Step 2. Parse the JPEG ﬁle and adopt the Huffman decompressor to obtain the
quantized DCT coefﬁcients, Dk(i, j), 0  i, j  7, k ¼ 1, 2, ., B, where B is the
total number of blocks in the image.
Step 3. Calculate the hash H of the Huffman decompressed stream Dk(i, j).
Step 4. Seed a pseudo-random number generator (PRNG) with a secret key and
follow a random nonintersecting walk through the set E ¼ {D1(i1, j1), .,
DB(i1, j1), D1(i2, j2), ., DB(i2, j2), ., D1(iL, jL), ., DB(iL, jL)}. There are
L  B elements in the set E.
6.2 Lossless Information Hiding in JPEG Images
341

Step 5. While following the random walk, run the adaptive context-free lossless
arithmetic compression algorithm for the LSBs of the coefﬁcients from E.
While compressing, check for the difference between the length of the
compressed bitstream C and the number of processed coefﬁcients. Once there is
enough space to insert the hash H, stop running the compression algorithm.
Denote the set of visited coefﬁcients as E1, E1 4 E.
Step 6. Concatenate the compressed bitstream C and the hash H and insert the
resulting bitstream into the LSBs of the coefﬁcients from E1. Compress all DCT
coefﬁcients Dk(i, j) including the modiﬁed ones using the Huffman coder and
store the authenticated image as a JPEG ﬁle on a disk.
6.2.2.1.2 Algorithm for Integrity Veriﬁcation Process
Step 1. According to the JPEG QF, ﬁnd the set of L authentication pairs (i1,j1),
(i2,j2), ., (iL,jL), where 0  il, jl  7, 1  l  L.
Step 2. Parse the JPEG ﬁle and adopt the Huffman decompressor to obtain the
quantized DCT coefﬁcients Dk(i,j), where 0  i, j  7, k ¼ 1, 2, ., B.
Step 3. Seed a PRNG with a secret key and follow a random nonintersecting walk
through the set E ¼ {D1(i1,j1), ., DB(i1,j1), D1(i2,j2), ., DB(i2,j2), .,
D1(iL,jL), ., DB(iL,jL)}.
Step 4. While following the random walk, run the context-free lossless arithmetic
decompression algorithm for the LSBs of the coefﬁcients visited during the
random walk. Once the length of the decompressed bitstream reaches B jHj
(that is, the number of 8  8 blocks in the image plus the hash length), stop the
procedure.
Step 5. Separate the decompressed bitstream into the LSBs of visited DCT co-
efﬁcients and the extracted candidate for hash H0. Replace the LSBs of all
visited coefﬁcients with the decompressed bitstream and compute the hash H of
the resulting stream of all quantized DCT coefﬁcients Dk(i,j), 0  i, j  7,
k ¼ 1, 2, ., B.
Step 6. Compare H0 with H. If they are the same, the JPEG ﬁle is authentic and
the original JPEG image is obtained. If H s H0, the image is deemed
nonauthentic.
The selection of the L authentication coefﬁcients can be adjusted according to
the QF to minimize the distortion and other artifacts. For example, for L ¼ 3, using
coefﬁcients (5,5), (4,6), and (6,3) in a random fashion will contribute to the overall
security of the scheme because the statistical artifacts due to lossless authentication
will be more difﬁcult to detect.
6.2.2.2 Method 2
The idea of the second method of Fridrich et al. is simple. For a given DCT coefﬁ-
cient position (i,j), if the corresponding quantization factor Q(i,j) is even, it can be
divided by 2 and all coefﬁcients Dk(i,j) can be multiplied by 2 without changing the
visual appearance of the image at all. Because now all Dk(i,j) are even, any binary
342
CHAPTER 6 Lossless Information Hiding

message can be embedded into the LSBs of Dk(i,j) and this LSB embedding is obvi-
ously reversible.
If Q(i,j) is odd, it is replaced with ﬂoor (Q(i,j)/2) and all Dk(i,j) are multiplied by
2. In this case, it is required to include a ﬂag in the hash to indicate that Q(i,j) was
originally odd in order that the original JPEG stream can be reconstructed during
veriﬁcation. Because this method uses a nonstandard quantization table, this table
should be included in the header of the authenticated image. Because the table entry
Q(i,j) is not compatible with the rest of the table, this authentication method is steg-
anographically obvious.
In fact, we can have several other possible realizations of the aforementioned
idea. For example, Q(i,j) could be replaced with 1 instead of its half and each
Dk(i,j) is multiplied by Q(i,j). This version may introduce very small distortion since
the DCT coefﬁcients used for embedding have a quantization factor equal to 1. On
the other hand, the modiﬁed stream will be less compressible using the Huffman
code and thus reduce the overall compression ratio.
6.2.3 FRIDRICH ET AL.’S LOSSLESS EMBEDDING METHOD WITH FILE
SIZE PRESERVATION
The aforementioned two lossless embedding schemes for JPEG images do not pre-
serve the JPEG ﬁle size, and in some cases the ﬁle size increase can be quite dispro-
portional to the embedded message size. This partially negates the advantages of
embedding data rather than appending. In this subsection, we introduce Fridrich
et al.’s another scheme to address this issue, which is a lossless embedding technique
for sequentially encoded JPEG images that preserves their ﬁle size [20] (within a few
bytes).
The JPEG encoder consists of three fundamental components (see Fig. 6.8):
FDCT, a scalar quantizer, and an entropy-encoder. After the DCT is applied to a
block of 8  8 pixels to transform it from the spatial domain to the frequency
domain, DCT coefﬁcients are quantized according to the quantization table. The
quantized coefﬁcients are arranged in a zigzag order and precompressed by perform-
ing the differential pulse code modulation (DPCM) on DC coefﬁcients and RLE on
8x8 blocks
FDCT
Quantizer
Message
JPEG file
Compressed
Image Data
Entropy
Encoder
Table
specifications
Table
specifications
Source
Image Data
FIGURE 6.8
Lossless embedding in JPEG ﬁles. FDCT, forward discrete cosine transform.
6.2 Lossless Information Hiding in JPEG Images
343

AC coefﬁcients. Finally, the symbol string is Huffman-coded to obtain the ﬁnal com-
pressed bitstream. After prepending the header, the ﬁnal JPEG ﬁle is obtained.
The lossless embedding scheme with ﬁle size preservation works with the
Huffman-decompressed stream of intermediate symbols. This bitstream is modiﬁed
in a careful manner to guarantee that the ﬁnal ﬁle size after Huffman compression
keeps the same within a few bytes. To understand the embedding principles, we ﬁrst
describe the lossless part of JPEG compression in more detail.
6.2.3.1 The JPEG Entropy Coder
The entropy coder is composed of two steps: (1) DPCM encoding of the DC term
and RLE of the AC coefﬁcients and (2) Huffman coding. The purpose of the
DPCM is to decorrelate the DC term because DC coefﬁcients from neighboring
blocks still have signiﬁcant local correlations. The AC coefﬁcients, on the other
hand, contain long runs of 0s because of the quantization. Thus, AC coefﬁcients
are conveniently encoded using the RLE. The DPCM coding of DC coefﬁcients
and the run length coding of AC coefﬁcients produce a sequence of intermediate
symbols, which is ﬁnally entropy-coded to a data stream in which the symbols no
longer have externally identiﬁable boundaries. The embedding technique works
with the sequence of intermediate symbols and usually ignores the DC coefﬁcients
because their modiﬁcations may lead to visible artifacts. To explain how to modify
the run lengtheencoded AC coefﬁcients, it is required to describe run length coding
in more detail.
6.2.3.2 Run Length Encoding of AC Coefﬁcients
RLE is a simple lossless compression technique that assigns short codes to long runs
of identical symbols. As mentioned earlier, the majority of quantized AC coefﬁ-
cients in each block are usually 0s. To efﬁciently utilize this fact, the AC coefﬁcients
are coded in a special RLE format as pairs of intermediate symbols (S1, S2). The
codeword S1 represents both the number of zeros before the next nonzero DCT co-
efﬁcient and the category (the number of bits required to represent its amplitude).
The symbol S2 deﬁnes the amplitude and sign of the nonzero coefﬁcient. The sym-
bol S1, S1 ¼ (Run/Category) is a composite 8-bit value of the form S1 ¼ binary
“RRRRCCCC.” The four LSBs, “CCCC,” deﬁne a category for the amplitude of
the next nonzero coefﬁcient in the block. The four most signiﬁcant bits (MSBs),
“RRRR,” give the position of the coefﬁcient in the block relative to the previous
nonzero coefﬁcient (i.e., the run length of zero coefﬁcients between nonzero
coefﬁcients):
1. Run (RRRR): the length of the consecutive zero-valued AC coefﬁcients pre-
ceding the next nonzero AC coefﬁcient, 0  Run  15.
2. Category (CCCC): the number of bits needed to represent the amplitude of the
next nonzero AC coefﬁcient, 0  Category  15.
3. S2 (amplitude): S2 represents the amplitude of the next nonzero AC coefﬁcient
by a signed integer.
344
CHAPTER 6 Lossless Information Hiding

Once the quantized coefﬁcient data from each 8  8 block is represented in the
intermediate symbol sequence described earlier, variable-length codes are assigned.
Each S1 (Run/Category) is encoded with a VLC from a Huffman table. Each S2
(amplitude) is encoded with a VLI code, which is an index into the amplitude value
ﬁeld whose length in bits is given in the second column of Fig. 6.9.
Both VLCs (S1) and VLIs (S2) are codes with variable lengths, but VLIs are not
Huffman coded. They are appended to the Huffman coded S1 to form the ﬁnal JPEG
bitstream. Thus, we can change a particular VLI as long as the modiﬁed value is
from the same category (has the same length) without changing the JPEG ﬁle
size. Consequently, if all the embedding changes have this property, the JPEG ﬁle
size will be preserved.
6.2.3.3 Lossless Embedding With File Size Preservation
As explained in the previous subsection, to preserve the ﬁle size, a given DCT
coefﬁcient d from the category C can only be changed to another coefﬁcient d0 from
the same category C. To minimize the embedding distortion, this change should be
as small as possible. Also, changes to DC coefﬁcients usually introduce visible
distortion, so we only perform the embedding modiﬁcations on AC coefﬁcients.
Considering these requirements, we further limit the embedding changes to the
same category, swapping values of AC coefﬁcients within the following pairs:
(2,e3), (2,3) from the category 2, (7,e6), (5,e4), (4,5), (6,7) from the category
3, etc. During the embedding process, one value from the pair may be changed to
another from the same pair. The value pairs are called embedding pairs. If we assign
the parity 0 to all even-valued coefﬁcients and the parity 1 to odd-valued
Amplitude value field
0
0
N/A
N/A
1
1
2
2
3
3
4
4
5
5
6
6
7
7
8
8
9
9
A
B
C
D
E
10
11
12
13
14
15
–1, 1
–3, –2, 2, 3
–7,...,–4, 4,..., 7
–15,...,–8, 8,..., 15
–31,...,–16, 16,..., 31
–63,...,–32, 32,..., 63
–127,...,–64, 64,..., 127
–255,...,–128, 128,..., 255
–511,...,–256, 256,..., 511
–1023,...,–512, 512,..., 1023
–2047,...,–1024, 1024,..., 2047
–4095,...,–2048, 2048,..., 4095
–8191,...,–4096, 4096,..., 8191
–16383,...,–8192, 8192, 16383
–32767,...,–16384, 16384, 32767
Category
AC size
FIGURE 6.9
Run length coding category and amplitude of AC coefﬁcients.
6.2 Lossless Information Hiding in JPEG Images
345

coefﬁcients, then the parities of the DCT coefﬁcients that participate in embedding
pairs in the original JPEG ﬁle is a binary sequence T that is losslessly compressible.
This is because in natural images the distribution of DCT coefﬁcients is generalized
Gaussian centered at 0 and thus the sequence T contains more 0’s in T than 1’s.
The rest of the embedding process follows the RS method. We ﬁrst losslessly
compress the sequence T, obtaining the compressed bitstream C(T), jC(T)j < jTj;
append the message bits M to the compressed bitstream, C(T)&M; and embed this
composite message as the parities of DCT coefﬁcients participating in embedding
pairs (the capacity of this scheme is jTj e jC(T)j). Due to the generalized Gaussian
distribution of DCT coefﬁcients, the coefﬁcients occur with highly uneven probabil-
ities. Thus, to obtain a more efﬁcient lossless compression result of the sequence T,
we divide T into several subsequences (each subsequence corresponding to one cate-
gory) and perform the arithmetic compression technique on the coefﬁcients from
each category separately.
6.2.3.3.1 Encoder
Step 1. Huffman-decode the original JPEG ﬁle.
Step 2. Either sequentially, or along a key-dependent path, read all DCT co-
efﬁcients di belonging to embedding pairs from all Huffman-decoded data.
Form the sequence T ¼ {ti}, ti ¼ parity(di).
Step 3. Compress T using the arithmetic encoder to obtain the compressed
bitstream C(T).
Step 4. Concatenate m message bits M, m < jTj e jC(T)j, to the compressed
bitstream, obtaining T0 ¼ C(T)&M.
Step 5. For each i, if ti s

ti0
, modify di to di0, where (di,di0) is an embedding
pair.
Step 6. Using the same Huffman code table, reencode the modiﬁed Huffman-
decoded data to obtain the embedded JPEG ﬁle.
6.2.3.3.2 Decoder
Step 1. Perform the Huffman decoder on the JPEG ﬁle.
Step 2. Either sequentially, or along a key-dependent path, read all DCT co-
efﬁcients di0 belonging to embedding pairs from all Huffman-decoded data,
obtaining the sequence T0 ¼

ti0
, where

ti0
¼ parity

di0
.
Step 3. Read the message M from T0 and decompress C(T).
Step 4. Either sequentially, or along a key-dependent path, modify all DCT
coefﬁcients di0 belonging to the embedding pairs so that their parities match the
decompressed sequence T, i.e., parity(di) ¼ ti. After reencoding the modiﬁed
Huffman-decompressed coefﬁcients, the original JPEG ﬁle can be obtained.
6.2.4 XUAN ET AL.’S HISTOGRAM PAIReBASED LOSSLESS DATA
EMBEDDING SCHEME
Xuan et al. presented a technique based on histogram pairs applied to some mid- and
low-frequency JPEG quantized 8  8 block DCT coefﬁcients for reversible data
346
CHAPTER 6 Lossless Information Hiding

hiding [14]. The block diagram of data embedding and extraction is shown in
Fig. 6.10. The data embedding capacity ranges from 0.0004, to 0.001, 0.1, up to
0.5 bpp for one-time (or, one-loop) reversible data hiding, whereas the visual quality
of images with hidden data measured by both subjective and objective ways remains
high. The increase in the size of image ﬁle due to data hiding is not noticeable, and
the shape of histogram of the mid- and lower frequency DCT coefﬁcients keeps
similar. This technique can work for various Q-factors. In the following parts, we
ﬁrst introduce the principle of the histogram pairebased lossless data hiding
scheme, and then the concept of thresholding is discussed. The lossless data embed-
ding and extraction algorithm is ﬁnally described.
6.2.4.1 Principles
6.2.4.1.1 Deﬁnitions
Histogram h(x) is the number of occurrences of feature x within a set of samples X.
Here the samples X are some selected JPEG-quantized 8  8 DCT coefﬁcients, and
the feature x is one of the JPEG coefﬁcient values. The x is either positive, or nega-
tive integer, or 0, such as x ˛ {2,1, 0, 1, 2, 3}.
A histogram pair is deﬁned as a part of the histogram, denoted by h ¼ [m, n],
where m and n are, respectively, the occurrences of two immediately neighboring
feature values x ˛ {a, b} with a < b, i.e., b ¼ a þ 1, and one of the two frequencies
(m and n) is 0. The histogram pair can be formulated by histogram expansion. For
example, the histogram pair h ¼ [m, 0] can be produced by expanding. Here, the un-
derline is used to mark the histogram pair. The feature value whose occurrence
(h value) is not 0 is called the feature’s original position. The feature value whose
h value is 0 is called the feature’s expansion position. Here, it is deﬁned that
(b)
Extracted
Data
Original JPEG
image
Data extraction followed by entropy
encoding
JPEG quantized block DCT coeff.
after entropy decoding
JPEG with
hidden data
Data extraction
Original JPEG
image
(a)
JPEG quantized block DCT
coefficients after entropy decoding
Lossless data embedding followed by
entropy encoding
Payload
JPEG with
hidden data
Data embedding
FIGURE 6.10
Block diagram of the lossless data embedding for JPEG image. DCT, discrete cosine
transform.
6.2 Lossless Information Hiding in JPEG Images
347

when the feature value x is greater or equal to 0, the histogram pair is of the format
h ¼ [m, 0], which means h(a) ¼ m and h(b) ¼ 0; when the feature value x is less than
0, the histogram pair is of h ¼ [0, n], which means h(a) ¼ 0 and h(b) ¼ n.
After the histogram pair is produced, lossless data embedding can be developed.
We can use the following data embedding rule. If the bit to be embedded is 0, the
feature’s original position is used. If the bit to be embedded is 1, the feature’s expan-
sion position is used. It is observed that after data embedding the histogram becomes
more ﬂat. When the histogram is completely ﬂat, it is impossible to further embed
data.
6.2.4.1.2 First Example: Using Single Histogram Pair
Assume the samples are X ¼ [a, a, a, a], i.e., the number of samples is M ¼ 4, and
the feature values x ˛ {a, b} are greater than 0. There is one histogram pair h ¼
[4, 0]. Assume the bit sequence to be embedded is D ¼ [1, 0, 0, 1] whose length
L ¼ 4. During data embedding, we scan the sequence X ¼ [a, a, a, a] in a certain
order. When we meet the ﬁrst “a,” since we need to embed the bit “1,” we change
it to its expansion position “b.” For the next 2 bits to be embedded, since they are
bit “0,” we keep it in its original position as “a.” For the last bit to be embedded
“1,” we change “a” to “b.” Therefore, after the embedding process, we obtain
X ¼ [b, a, a, b] with the new histogram h ¼ [2, 2]. Obviously, the embedding capac-
ity is C ¼ L ¼ 4. Data extraction or the histogram pair recovery is the reverse
process of the aforementioned data embedding process. After extracting the data
D ¼ [1, 0, 0, 1], the histogram pair becomes [4, 0] and we can recover X ¼ [a, a,
a, a] losslessly. Note that after data embedding, the histogram is changed from
h ¼ [4, 0] to h ¼ [2, 2], since the histogram is completely ﬂat and hence we cannot
embed data any more.
6.2.4.1.3 Second Example: Using Two Loops
Given an image of size 3  3, the feature values are x ˛ {a, b, c, d}, where the fea-
tures are all greater than 0. According to the scan order, the samples become X ¼ [a,
a, a, a, a, a, a, a, a], where the total number of samples M ¼ 9 and the histogram is
h ¼ [9, 0, 0, 0], as shown in Fig. 6.11a. The histogram pair is h ¼ [9, 0]. Assume the
to-be embedded bit sequence is D ¼ [0, 1, 0, 0, 1, 0, 1, 1, 0] and L ¼ 9.
For the ﬁrst data embedding “Loop 1,” since the ﬁrst bit to be embedded is 0, we
use the original feature position “a,” whereas since the second bit is 1, we use the
expansion position “b.” In this way, we can embed 9 bits in total; after data embed-
ding, the samples become X ¼ [a, b, a, a, b, a, b, b, a] as shown in Fig. 6.11b. After
the ﬁrst embedding loop, the histogram h ¼ [9, 0, 0, 0] becomes h ¼ [5, 4, 0, 0]. The
payload is C1 ¼ L ¼ 9 bits.
For the second data embedding “Loop 2,” we expand ﬁrst, i.e., the histogram pair
h ¼ [4, 0] is right shifted by one position, thus producing the histogram with two
histogram pairs h ¼ [5, 0, 4, 0], and the samples become X ¼ [a, c, a, a, c, a, c, c,
a]; refer to Fig. 6.11c. Thus, the second embedding loop will separately use the
two histogram pairs in h ¼ [5, 0, 4, 0], x ˛ {a, b, c, d} to avoid conﬂiction. That
348
CHAPTER 6 Lossless Information Hiding

is, it ﬁrst uses the histogram pair with larger absolute feature values, and then uses
the histogram pair with smaller absolute feature values. In this example, we ﬁrst
embed data into the right histogram pair, and then into the left histogram pair.
The to-be-embedded bit sequence D ¼ [0, 1, 0, 0, 1, 0, 1, 1, 0] is separated into
two parts accordingly. That is, we ﬁrst embed the front portion of data D1 ¼ [0, 1,
0, 0] into the histogram pair at the right side h ¼ [4, 0], x ˛ {c, d}, resulting in
the corresponding samples X1 ¼ [c, d, c, c]. Then, we embed the remaining data
D2 ¼ [1, 0, 1, 1, 0] into the left histogram pair h ¼ [5, 0], x ˛ {a, b}, resulting in
the corresponding samples X2 ¼ [b, a, b, b, a]. After Loop2, the histogram becomes
h ¼ [2, 3, 3, 1] and the samples become X ¼ [b, c, a, b, d, b, c, c, a] as given in
Fig. 6.11d. Thus the embedding capacity in Loop 2 is C2 ¼ L ¼ 9 bits.
The total capacity after two embedding loops is C ¼ 18 bits. After two embed-
ding loops, histogram changes from h ¼ [9, 0, 0, 0] to h ¼ [2, 3, 3, 1]. It is observed
that the histogram has changed from rather sharp ([9, 0, 0, 0]) to relatively
ﬂat ([2, 3, 3, 1]).
6.2.4.2 Thresholding
The histogram pairebased lossless data hiding scheme seeks for not only a higher
embedding capacity but also a higher visual quality of stego images. For example,
we may embed data with sufﬁcient payload for annotation or for security with
reversibility as well as the highest visual quality of the stego image with respect
to the cover image.
To obtain the optimal performance, we need the so-called thresholding tech-
nique. The thresholding method involves ﬁrst setting a threshold T, and then embed-
ding data into those JPEG coefﬁcients x with jxj  T. That is, it does not embed data
into the JPEG coefﬁcients with jxj > T. In addition, it makes sure that the small
JPEG coefﬁcients after data embedding will not conﬂict with the large JPEG coef-
ﬁcients with (jxj > T). That is, for the JPEG coefﬁcients satisfying jxj  T, the his-
togram pairebased data embedding is applied. It requires that after data embedding,
the coefﬁcients between T  x  T will be separable from the coefﬁcients with
jxj > T. The simple thresholding will divide the whole histogram into two parts:
(1) the data-to-be embedded region, where the JPEG coefﬁcients’ absolute value
FIGURE 6.11
Bit sequence D ¼ [0, 1, 0, 0, 1, 0, 1, 1, 0] embedded in two loops.
6.2 Lossless Information Hiding in JPEG Images
349

is small and (2) no data-to-be embedded region named end regions, where the JPEG
coefﬁcients’ absolute value is large.
In fact, the smallest threshold T does not necessarily lead to the highest PSNR for
a given data embedding capacity. Instead, it is found that for a given data embedding
capacity there is an optimum value of T. This can be justiﬁed as follows. If a smaller
threshold T is selected, the number of coefﬁcients with jxj > T will be larger. This
implies that more coefﬁcients with jxj > T need to be moved away from 0 to create
histogram pair(s) to losslessly embed data. This may lead to a lower PSNR and more
side information. Therefore the best threshold T for a given data embedding capacity
is selected to achieve the highest PSNR.
6.2.4.3 Hiding Algorithm
6.2.4.3.1 Data Embedding
Assume the length of the data to be embedded is L. The data embedding steps are
listed below (see Fig. 6.12a).
1. Select a threshold T > 0, to make sure that the number of the mid- and low-
frequency JPEG coefﬁcients within [T, T] is greater than L, and P ) T.
2. In the JPEG coefﬁcient histogram, move the portion of histogram with the
coefﬁcient value greater than P to the right-hand side by one unit to make the
histogram at P þ 1 equal to 0 (call P þ 1 as a zero-point). Then embed data into
P and P þ 1 according to the bit to be embedded (0 or 1).
3. If some of the bits to be embedded have not been embedded at this point, let
P ) (P), and move the histogram (less than P) to the left-hand side by one
(a)
Choose T
P ← T
P ← (-P-1)
P ← (-P)
P ← (-P-1)
No
No
No
No
Yes
Yes
Yes
Yes
P ← (-P)
embedding
extracting
S ← P
P ← S
Extract data and
backfill zero point
Expanded a zero point
and Embedding Data
Finished?
Finished?
P>0?
P>0?
(b)
FIGURE 6.12
Flowchart of proposed lossless data embedding and extracting. (a) embedding,
(b) extracting
350
CHAPTER 6 Lossless Information Hiding

unit to leave a zero-point at the value (P  1). Embed data into P and (P  1)
according to the bit to be embedded (0 or 1).
4. If all data have been embedded, then stop the embedding process and record the
P value as the stop value S. Otherwise, P ) (P  1); go back to Step (2) to
continue to embed the remaining data to be embedded.
6.2.4.3.2 Data Extraction
The data extraction process is the reverse process of the data embedding process.
Without loss of generality, assume the stop position of data embedding is S (posi-
tive). The data extraction steps are as follows (Refer to Fig. 6.12b).
1. Set P ) S.
2. Decode with the stopping value P and the value (P þ 1). Extract all the data until
P þ 1 becomes a zero-point. Move all the DCT coefﬁcients’ histogram (greater
than P þ 1) toward the left-hand side by one unit to eliminate the zero-point.
3. If the amount of extracted data is less than C, set P ) (P  1). Continue to
extract data until (P  1) becomes a zero-point. Then move the histogram (less
than P  1) to the right-hand side by one unit to eliminate the zero-pint.
4. If all the hidden bits have been extracted, stop the process. Otherwise, set
P )P, go back to Step 2 to continue to extract the following data.
6.2.4.3.3 Formulae of Lossless Data Hiding Based on Histogram Pairs
In summary, the aforementioned method divides the whole histogram into three
parts: the part where data are to be embedded; the central part, where no data are
embedded and the absolute value of coefﬁcients is small; and the end part, where
no are data embedded and the absolute value of coefﬁcients is large. The whole
embedding and extraction procedure can be expressed by the formulae in
Fig. 6.13, where T is the selected threshold, i.e., the start position, S is the stop po-
sition, x is the feature value before embedding, x0 is the feature value after
FIGURE 6.13
Formulae of lossless data hiding based on histogram pairs.
6.2 Lossless Information Hiding in JPEG Images
351

embedding, u(S) is unit step function (when S  0, u(S) ¼ 1, when S < 0, u(S) ¼ 0),
and PxR rounds x to the largest integer not larger than x.
6.2.5 QIAN AND ZHANG’S SCHEME
Qian and Zhang found that, in Mobasseri et al.’s method [6], ﬂipping one or more
bits of VLC in a JPEG image to hide secret bits usually would cause collision in
the decoding process and thus error concealment steps are required to minimize
the decrease of output JPEG image quality. Therefore, they mapped VLCs by direct
VLC replacement in the JPEG bitstream and the image quality can be kept the same
as the original [21]. Their scheme can be described as follows.
Step 1: Parse the JPEG bitstream and read all the VLCs to get the used and
unused ones.
Step 2: Establish mapping relationships based on the number of the used VLCs
and the number of the unused VLCs.
Step 3: Modify the Vi,j value in the ﬁle header according to the mapping
relationships.
Step 4: Replace the VLCs in the bitstream to embed the secret data.
All the VLCs can be classiﬁed into 16 categories {C1, C2, ., C16} and Category
Ci has Li codes of length i(i ¼ 1, 2, ., 16). Thus, the used and unused VLCs in each
category Ci can be expressed as follows:
Ci ¼
n
VLCðuÞ
i;1 ; .; VLCðuÞ
i;pi; VLCðnÞ
i;1 ; .; VLCðnÞ
i;qi
o
(6.7)
where VLCðuÞ
i;1 ; .; VLCðuÞ
i;pi are pi used codes, VLCðnÞ
i;1 ; .; VLCðnÞ
i;qi are qi unused
codes, and pi þ qi Li. Here we brieﬂy introduce the method they adopted to establish
the mapping relationships. If pi  qi > 0, VLCs in each category are mapped by a
one-to-one manner:
Mi ¼
nn
VLCðuÞ
i;1 4VLCðnÞ
i;1
o
; .;
n
VLCðuÞ
i;qi4VLCðnÞ
i;qi
oo
(6.8)
where “4” stands for the mapping relationship. If 0 < pi < qi, VLCs are mapped by
one-to-many manner for each category:
Mi ¼
8
<
:
n
VLCðuÞ
i;1 4
n
VLCðnÞ
i;1 ; .; VLCðnÞ
i;ki
oo
; .;
n
VLCðuÞ
i;pi4
n
VLCðnÞ
i;ðpi1Þkiþ1; .; VLCðnÞ
piki
oo
9
=
;
(6.9)
where ki ¼ 2blog2ðqi=piþ1Þc  1 and PxR stands for the ﬂoor function. For Eq. (6.8),
each code in the mapping relationship presents one secret bit “0” or “1”, and for
Eq. (6.9) each code can present
	
log2ðqi=pi þ 1Þ

secret bits.
For example, assume there are four VLCs (VLCm, VLCn, VLCk, and VLCl) and
they are listed in the order in which they appear in the DHT segment. If the three
unused VLCs (VLCn, VLCk, and VLCl) are mapped to the same used VLCm, then
352
CHAPTER 6 Lossless Information Hiding

the mapping set is {VLCm 4 {VLCn, VLCk, VLCl}}. To map codes, the (run, size)
values of VLCn, VLCk, and VLCl are all modiﬁed to that of VLCm, then the four
VLCs present secret bits “00,” “01,” “10,” and “11,” respectively. When scanning
the entropy-coded segment in the data hiding phase, if VLCm is met and the secret
bits to be embedded are “01,”, then VLCm is replaced with VLCn.
Qian and Zhang successfully hide data into the JPEG bitstream by VLC mapping
and replacement. After data are embedded, both the image quality and the ﬁle size of
the stego image are kept the same as the original JPEG image. However, the statistical
results of the used and unused codes are not made full use of. Thus, the code mapping
relationships could be able to be better explored to further increase the capacity.
6.2.6 JOINT MODIFICATION OF QUANTIZATION TABLE AND DISCRETE
COSINE TRANSFORM COEFFICIENTSeBASED SCHEME
To make the distortion smaller, the authors of this book proposed a high-capacity
reversible data hiding scheme utilizing the k-aryebased modulo operation [22].
The data are hidden in the space made by lowering certain quantization table entries
and lifting the corresponding quantized DCT coefﬁcients with an adjustment value
added. The embedding strategy and sequence are optimized to get a better stego im-
age. In our scheme, a cover JPEG image is ﬁrst decoded to get the quantization table
and quantized DCT coefﬁcients; then some entries of the quantization table are
divided by an integer and the corresponding quantized DCT coefﬁcients are multi-
plied by the same integer and added by an adjustment value to make space for
embedding the data. After extracting secret bits from the stego image, the original
JPEG image can be recovered at the same time. Our algorithm can be divided
into two phases: the data hiding phase and the extracting and restoring phase, which
are illustrated in the following subsections. To reduce the distortion caused by
embedding and control the increase of the ﬁle size, the selection of embedding po-
sitions should be discussed ﬁrst.
6.2.6.1 The Selection of Embedding Positions
For the purpose of making the inﬂuence caused by data hiding as small as possible,
the selection of embedding positions should be carefully considered. As Huang et al.
[5] said, traditional data hiding techniques tended to choose the midfrequency DCT
coefﬁcients in the DCT transform domain. However, when considering the quanti-
zation stage, things may be different. Thus, the earlier techniques might affect the
researchers’ choice on embedding positions in the JPEG-compressed domain.
Xuan et al. [14] did some simple experimental investigation to decide their optimum
parameters. To test the effect of every single quantized DCT coefﬁcient on image
quality in much more detail, theoretical analysis and experimental investigation
are done in this chapter. Here the peak signal-to-noise ratio (PSNR) is adopted to
evaluate the impact:
PSNR ¼ 10 log10
2552
MSE

(6.10)
6.2 Lossless Information Hiding in JPEG Images
353

where mean squared error (MSE) for an M  N grayscale image is deﬁned as:
MSE ¼
1
M$N
X
M1
x¼0
X
N1
y¼0
½Dfðx; yÞ2 ¼
1
M$N
X
M1
x¼0
X
N1
y¼0
½ f 0ðx; yÞ  fðx; yÞ2
(6.11)
where f 0(x,y) and f(x,y) are the pixel values of the distorted image and the original
image, respectively.
In fact, the data stored in the JPEG image are the quantization table and quan-
tized DCT coefﬁcients; thus we can calculate the reconstructed DCT coefﬁcient
by eFðu; vÞ ¼ Dðu; vÞ$Qðu; vÞ. When we add a number a to the quantized DCT coef-
ﬁcient D(u,v), it is equivalent to adding the number a multiplied by the correspond-
ing quantization table entry to eFðu; vÞ. From the JPEG standard quantization table
shown in Fig. 6.2, we can see the entries vary a lot. The low-frequency entries are
smaller than the midfrequency ones, which in turn are smaller than the high-
frequency ones. For example, when adding 2 to D(i,j) ð0  i; j < 8Þ, we have
eF
0ði; jÞ ¼ eFði; jÞ þ 2Qði; jÞ. In this case, from Eq. (6.2), we can see that the differ-
ence Dfðx; yÞ ¼ f 0ðx; yÞ  fðx; yÞ can be uniquely determined by the difference
D eFði; jÞ ¼ eF
0ði; jÞ  eFði; jÞ since D eFðu; vÞ ¼ 0 for u s i or v s j. Based on this
fact, the impact of every single DCT coefﬁcient can be tested as follows.
In one block, if we add 1 to D(i,j) and keep other D(u,v) the same as its original
value, then we can obtain the introduced error as below:
Dfðx; yÞ ¼ f 0ðx; yÞ  fðx; yÞ
¼ 1
4
" X
7
u¼0
X
7
v¼0
CðuÞCðvÞD eFðu; vÞcos ð2x þ 1Þup
16
cos ð2y þ 1Þvp
16
#
¼ 1
4 CðiÞCðjÞQði; jÞcos ð2x þ 1Þip
16
cos ð2y þ 1Þjp
16
(6.12)
Theoretical results are calculated according to Eqs. (6.10)e(6.12) on condition
that the standard quantization table is used. Substitute Df(x,y) into Eq. (6.11) and
set M ¼ N ¼ 8 to get the MSE value and then get the corresponding PSNR value.
The experiments for real cases are also performed, where six test images Baboon,
Boat, F16, Goldhill, Lena, and Pepper, of size 512  512 with 256 grayscales are
adopted, as shown in Fig. 6.14. In real cases, to test the impact of quantized DCT
coefﬁcient D(i,j), the LSB of D(i,j) in every block of the image is ﬂipped. The cor-
responding experimental results calculated between original JPEG images and stego
JPEG images are shown in Fig. 6.15. Every DCT coefﬁcient is tested in the zigzag
sequence. In Fig. 6.15, the blue solid line with circles is the theoretical results and
other colorful solid lines are the results for real cases.
From Fig. 6.15 we can see that the results for the real cases are almost the same
and overlap with each other. The theoretical result is very similar in general trends to
the ones for the real cases. The little difference is introduced by fast implementations
of FDCT and IDCT rather than the mathematical deﬁnitions. Fig. 6.16 shows the
354
CHAPTER 6 Lossless Information Hiding

Baboon
Boat
F16
Goldhill
Lena
Pepper
(a)
(b)
(c)
(d)
(e)
(f)
FIGURE 6.14
Six grayscale test images. (a) Baboon, (b) Boat, (c) F16, (d) Goldhill, (e) Lena, (f) Pepper.
0 2
4
6
8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62
20
25
30
35
40
45
50
DCT coefficient position
PSNR (dB)
Theoretical
Baboon
Boat
F16
Goldhill
Lena
Pepper
FIGURE 6.15
The impact of every quantized discrete cosine transform (DCT) coefﬁcient in zigzag
sequence on peak signal-to-noise transform (PSNR) calculated between original JPEG
images and stego JPEG images.
6.2 Lossless Information Hiding in JPEG Images
355

PSNR results calculated between original uncompressed images and stego JPEG im-
ages. The PSNR results of original JPEG images for Baboon, Boat, F16, Goldhill,
Lena, and Pepper are 27.4883, 33.4953, 35.3906, 33.7908, 34.4441, and
33.5518 dB, respectively. Fig. 6.16 has the similar trends with Fig. 6.15. Because
of the complex texture, the image Baboon has a lower PSNR than others. Based
on these charts, we can conclude that quantized low-frequency DCT coefﬁcients,
even the quantized DC coefﬁcient, have less inﬂuence on the image quality than
quantized midfrequency and high-frequency DCT coefﬁcients when considering
the quantization process. Since the quantized DC coefﬁcient is encoded based on
the difference between the one in the current block and the one in the previous block,
when the quantized DC coefﬁcient is modiﬁed, the ﬁle size after data hiding will not
increase too much. However, since quantized AC coefﬁcients in a block are encoded
by ZRLC, when the change is performed on the quantized midfrequency and high-
frequency AC coefﬁcients, things may be totally different, i.e., the ﬁle size may in-
crease a lot along with the increase of nonzero AC coefﬁcients. Therefore, when
high capacity is required, it is recommended to give priority to hiding data in the
quantized DC coefﬁcient and low-frequency coefﬁcients in the zigzag order, which
will also help to achieve higher image quality and less ﬁle size. Based on the previ-
ous experiment and the actual visual effect by comparing images between the orig-
inal image and stego image, we choose the third to the fourteenth (zero-based)
quantized DCT coefﬁcients to embed data.
0 2 4
6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62
22
24
26
28
30
32
34
36
DCT coefficient position
PSNR (dB)
Baboon
Boat
F16
Goldhill
Lena
Pepper
FIGURE 6.16
The impact of every quantized discrete cosine transform (DCT) coefﬁcient in zigzag
sequence on peak signal-to-noise ratio (PSNR) calculated between the original
uncompressed images and stego JPEG images.
356
CHAPTER 6 Lossless Information Hiding

6.2.6.2 The Data Hiding Phase
To make space for embedding the data into quantized DCT coefﬁcients, some quan-
tization table entries are divided by an integer and the quantized DCT coefﬁcients
are lifted correspondingly. When an integer number M is multiplied by an integer
k, the result is the multiple of k that allows secret data and additional information
(k-ary: 0, 1, ., k1) to be embedded into and to be extracted from by applying
the modulo operation: M mod k.
Assume the original quantization table entry at (u,v) is Q(u,v), we divide it by k to
get a new quantization entry. For the reason that the entry is an integer, to make the
variation as small as possible, we take the largest integer not greater than it, i.e.,
Q0ðu; vÞ ¼ PQðu; vÞ=kR
(6.13)
where P$R stands for the ﬂoor function. Then the quantized DCT coefﬁcient D(u,v) is
multiplied by k, i.e., D0ðu; vÞ ¼ k$Dðu; vÞ, and thus the embedding space is made.
Note that this may result in more information loss because of the ﬂoor function;
an adjustment value X should be added to make D0(u,v)*Q0(u,v) as close as possible
to the original reconstructed DCT coefﬁcient eFðu; vÞ. Assuming that r(u,v) is the
remainder of the expression Q(u,v)/k, we have rðu; vÞ ¼ Qðu; vÞ  k$PQðu; vÞ=kR.
To obtain the relationship eFðu; vÞ ¼ Dðu; vÞ$Qðu; vÞ ¼ D0ðu; vÞ$Q0ðu; vÞ, we should
let
Dðu; vÞ$½k$Q0ðu; vÞ þ rðu; vÞ ¼ ½k$Dðu; vÞ þ X$Q0ðu; vÞ,
which
results
in
X ¼ rðu;vÞ$Dðu;vÞ
Q0ðu;vÞ
. However, this X may not be the multiple of k. To obtain a multiple
of k, we set X ¼ k$round

rðu;vÞ$Dðu;vÞ
k$Q0ðu;vÞ

. Finally, we have D0(u,v) as follows:
D0ðu; vÞ ¼ k$Dðu; vÞ þ k$round
rðu; vÞ$Dðu; vÞ
k$Q0ðu; vÞ

(6.14)
A block diagram illustrating this phase is shown in Fig. 6.17, and the detailed
data hiding phase is given step by step as follows.
Step 1: Partially decode the original JPEG image I to get the quantization table
and quantized DCT coefﬁcients, as well as get the width and height of the image
so that the total number of 8  8 blocks NI can be calculated.
Step 2: Encrypt the original secret data and then convert them into a series of
k-ary digits. In fact, the embedding capacity increases a lot because of this step.
Count the total number of digits ND after conversion.
Step 3: Calculate the number of elements in the quantization table NQ which we
need to apply Eq. (6.13) to. A quantized DCT coefﬁcient can embed one k-ary
digit, and an element of the quantization table corresponds to NI-quantized DCT
coefﬁcients. NQ can be calculated by NQ ¼ dðND þ 24Þ=NIe, where Q$Q is the
ceiling function that maps a real number to the smallest following integer and 24
is the number of digits for additional information to be mentioned later. Then
apply Eq. (6.13) to the quantization table in the zigzag sequence, starting from
the third coefﬁcient till NQ elements of the quantization table are applied. The
6.2 Lossless Information Hiding in JPEG Images
357

Permutator
Multiplier
Entropy
Decoder
Original
JPEG Image
Quantization
Table
Embed
Entropy
Coder
Stego JPEG
Image
Divider
Secret
Data
Preprocess
Extraction
Key
Depermutator
Input
Output
FIGURE 6.17
The block diagram of our data hiding phase.
358
CHAPTER 6 Lossless Information Hiding

remainder r(u,v) needs to be recorded as additional information for the restoring
step, which occupies 12 digits. Sometimes the result is 0, the element should be
skipped and kept as its original value and a ﬂag also should be recorded as
additional information to tell that this element is not modiﬁed, which also
occupies 12 digits. The ﬁrst modiﬁed quantization table entry position should be
saved and can be regarded as an extraction key. Fig. 6.18 shows two examples
of modifying the quantization tables. Fig. 6.18a is the original quantization
table for QF ¼ 70 and we need to modify nine elements with k ¼ 2. We apply
Eq. (6.13) from the third element in the zigzag sequence and get the modiﬁed
8
8
11
14
29
43
7
8
10
13
21
38
55
10
7
10
13
22
33
47
57
7
8
14
17
34
38
52
59
6
11
24
31
41
49
62
67
10
16
34
52
65
62
73
60
14
35
41
34
48
37
62
46
68
55
72
61
62
59
24
36
31
33
37
4
4
5
14
29
43
7
4
5
13
21
38
55
10
3
10
13
22
33
47
57
7
4
14
17
34
38
52
59
3
11
24
31
41
49
62
67
5
16
34
52
65
62
73
60
14
35
41
34
48
37
62
46
68
55
72
61
62
59
24
36
31
33
37
Original quantization table (QF= 70)
Modified quantization table (QF= 70)
3
3
4
5
10
14
2
3
3
4
7
13
18
3
2
3
4
7
11
16
19
2
3
5
6
11
13
17
20
2
4
8
10
14
16
21
22
3
5
11
17
22
21
24
20
5
12
14
11
16
12
21
15
23
18
24
20
21
20
8
12
10
11
12
1
1
5
10
14
2
1
3
1
4
7
13
18
3
2
3
4
7
11
16
19
2
1
5
6
11
13
17
20
2
4
8
10
14
16
21
22
1
5
11
17
22
21
24
20
5
12
14
11
16
12
21
15
23
18
24
20
21
20
8
12
10
11
12
Original quantization table (QF= 90)
Modifiedquantizationtable(QF= 90)
(a)
(b)
(c)
(d)
FIGURE 6.18
The examples of modifying the quantization tables. (a) Original quantization table
(QF ¼ 70), (b) modiﬁed quantization table (QF ¼ 70), (c) original quantization table
(QF 90), and (d) modiﬁed quantization table (QF ¼ 90). QF, quality factor.
6.2 Lossless Information Hiding in JPEG Images
359

quantization table in Fig. 6.18b. Fig. 6.18c is the original quantization table
for QF ¼ 90 and we need to modify six elements with k ¼ 3. For the fourth and
ﬁfth elements, the results of applying Eq. (6.13) are 0. Thus, they are skipped
and kept as their original value and we continue to modify elements from the
sixth one.
Step 4: Permute the DCT blocks (each 8  8 DCT block is regarded as a whole,
no permutation is applied inside it) and then embed the additional information
generated in Step 3 together with the converted secret digits block by block.
Permutation shufﬂes the blocks, and then data are embedded into the permuted
sequence. After blocks are permuted back to original positions, the changes
could be distributed over the whole image. The straddling mechanism scatters
the changes and avoids concentrating changes in certain part of the image.
Quality degradation concentrating in certain part of the image may make the
image look strange. That is, we ﬁrst embed one secret digit into the ith quantized
DCT coefﬁcient of the jth block and then embed the next digit into the ith
quantized DCT coefﬁcient of the (j þ 1)th block. After all the ith quantized
DCT coefﬁcients from every block have been embedded, we start to embed
secret digits into the (i þ 1)th quantized DCT coefﬁcient of each block.
Fig. 6.19 illustrates the embedding sequence of a 16  16 JPEG image, starting
9
...
5
1
8
...
4
0
10
...
6
2
11
...
7
3
FIGURE 6.19
An example of embedding sequence for a 16  16 JPEG image.
360
CHAPTER 6 Lossless Information Hiding

from Position 3 of the ﬁrst block. The converted digit W is a k-ary number (i.e.,
W ˛ {0, 1, ., k1}), and to make the distortion smaller, the embedding rule is
as follows:
D00ðu; vÞ ¼

D0ðu; vÞ þ W
W  k=2
D0ðu; vÞ þ W  k
otherwise
(6.15)
After embedding, all blocks are permuted back to their original positions.
Step 5: Save the modiﬁed quantization table in the header of the JPEG ﬁle and
apply entropy coding to the modiﬁed quantized DCT blocks, obtaining the stego
JPEG image.
6.2.6.3 The Extraction and Restoration Phase
Fig. 6.20 illustrates the block diagram of extraction and restoration phase. The
detailed steps of this phase can be described as follows:
Step 1: Decode the stego JPEG image to get the quantization table and quantized
DCT blocks.
Step 2: Permute the quantized DCT blocks by the same key as used in the
embedding phase, and then use the extraction key to determine the ﬁrst entry for
extraction. The Mod function is applied to extract the secret digits:
W ¼ D00ðu; vÞmodk
(6.16)
The additional information (ﬂags and r(u,v)) is extracted ﬁrst, and then followed
by the secret data. At the same time, the quantized DCT coefﬁcients are restored us-
ing the equations below:
D0ðu; vÞ ¼

D00ðu; vÞ  W
W  k=2
D00ðu; vÞ  W þ k
otherwise
(6.17)
Dðu; vÞ ¼ round

D0ðu; vÞ
k þ rðu; vÞ=Q0ðu; vÞ

(6.18)
The proof of Eq. (6.18) is as follows: From Eq. (6.14) and the deﬁnition of round
function we have D0ðu; vÞ ¼ k$Dðu; vÞ þ rðu;vÞ$Dðu;vÞ
Q0ðu;vÞ
þ k$R, where R ˛

1
2; 1
2

.
Namely,
Dðu; vÞ ¼
D0ðu;vÞk$R
k þ rðu;vÞ=Q0ðu;vÞ.
This
equation
is
equivalent
to
Dðu; vÞ
þ
k$R
k þ rðu;vÞ=Q0ðu;vÞ ¼
D0ðu;vÞ
k þ rðu;vÞ=Q0ðu;vÞ because
k$R
k þ rðu;vÞ=Q0ðu;vÞ ˛

1
2; 1
2

, that is to say
Dðu; vÞ  1
2 <
D0ðu;vÞ
k þ rðu;vÞ=Q0ðu;vÞ < Dðu; vÞ þ 1
2. Note that the deﬁnition of the rounding
function is roundðxÞ ¼ n5n  1
2  x < n þ 1
2, hence Eq. (6.18) is ﬁnally
established.
6.2 Lossless Information Hiding in JPEG Images
361

Permutator
Divider
Entropy
Decoder
Stego JPEG
Image
Quantization
Table
Extract
Entropy
Coder
Original
JPEG Image
Multiplier
Secret
Data
Extraction
Key
Depermutator
Additional
Information
Input
Output
FIGURE 6.20
The block diagram of our extraction and restoration phase.
362
CHAPTER 6 Lossless Information Hiding

Step 3: Convert each k-ary secret digit extracted in Step 2 to the binary bits and
decrypt them back to achieve the original secret data. Thus the extraction part is
complete.
Step 4: Utilize the additional information r(u,v) to restore the quantization table
as follows:
Qðu; vÞ ¼ k$Q0ðu; vÞ þ rðu; vÞ
(6.19)
Step 5: Save the recovered quantization table in the header of the JPEG ﬁle and
apply entropy coding to the restored quantized DCT blocks; then the original
JPEG image is restored.
6.2.6.4 Experimental Results
To evaluate the performance of our scheme, we analyze properties of our scheme
and compare it with those of other schemes. Six test images mentioned in Section
6.2.6.1 are shown in Fig. 6.14. In the experiment, the JPEG library Libjpeg devel-
oped by IJG is utilized. The three aspects, namely, the stego JPEG image quality,
hiding capacity, and ﬁle size are discussed. The PSNR, which has been mentioned
in Section 6.2.6.1, is used as a measure to evaluate the quality of stego JPEG images.
PSNR is calculated between the original uncompressed image and the stego JPEG
image.
6.2.6.4.1 The Performance of Our Algorithm
Since the conversion of secret data into a series of k-ary digits makes the capacity
increase signiﬁcantly, thus the performance for different k may vary largely. The
experiments are performed based on different values of k. For k ¼ 3, we take three
binary bits to convert them into two ternary digits, that is to say, embedding 1 ternary
digit is equivalent to embedding 1.5 binary bits. For k ¼ 4, 1 quaternary digit is
equivalent to 2 binary bits for the same reason. Similar explanations can be given
for other values of k.
Table 6.1 shows the performance of capacity, distortion, and ﬁle size under
different k values. The experiments are tested on the JPEG image Lena with the
QF ¼ 70. Observing the maximum capacity, as k becomes larger, the capacity
increases at the beginning. However, when k is larger than 6, the capacity does
not increase with the increasing k value, and even ﬂuctuates instead. For some en-
tries of the quantization table, they are not large enough to apply Eq. (6.13) if k is
too large, and thus they are kept as their original values. These unaltered entries
result in that the corresponding quantized DCT coefﬁcients are unaltered and the
corresponding space cannot be made to hide the data. Thus, the choice of k cannot
be too large, and thus we select 2, 3, and 4 as the possible values of k to test in the
following experiments. The deep explanation about the effect of different k values
on the performance is provided later.
6.2 Lossless Information Hiding in JPEG Images
363

The experimental results tested on the JPEG image Lena with different embed-
ding rates and QFs are listed in Tables 6.2e6.4. The left slash (/) in the tables means
that the corresponding embedding rate cannot be reached because some quantization
table entries are not large enough to apply Eq. (6.13). The results of all test images
Table 6.1 Performance for Lena Image With Quality Factor QF ¼ 70 Under
Different Values of k
k
Capacity (bit)
PSNR (dB)
File Size (KB)
0.125 bpp
Fully Embedded
0.125 bpp
Fully Embedded
2
49,128
35.61
35.39
38.2
40.4
3
73,692
35.80
35.64
39.0
45.0
4
98,256
35.80
35.58
40.9
49.6
5
112,000
35.82
35.60
39.8
52.9
6
126,252
35.83
35.63
40.4
55.1
7
113,477
35.84
35.60
38.5
53.5
8
122,808
35.82
35.63
39.0
52.8
PSNR, peak signal-to-noise ratio.
Table 6.2 PSNRs Tested on Lena Image With Different Embedding Rates
and QFs (k ¼ 2)
Embedding Rate (31 bpp)
QF
0.031
0.062
0.094
0.125
0.156
0.187
50
34.32
34.20
34.07
33.90
33.74
33.48
60
34.97
34.89
34.80
34.69
34.55
34.37
70
35.84
35.76
35.70
35.63
35.53
35.39
80
37.00
36.97
36.93
36.89
36.83
36.73
90
39.43
39.41
39.39
39.36
39.34
39.29
PSNR, peak signal-to-noise ratio; QF, quality factor.
Table 6.3 PSNRs Tested on Lena Image With Different Embedding Rates
and QFs (k ¼ 3)
QF
Embedding Rate (3 1.5 bpp)
0.031
0.062
0.094
0.125
0.156
0.187
50
34.38
34.31
34.24
34.14
34.06
33.89
60
35.01
34.96
34.92
34.87
34.80
34.68
70
35.86
35.82
35.80
35.76
35.71
35.64
80
37.02
37.00
36.98
36.96
36.92
36.88
90
39.43
39.42
39.40
39.39
39.36
/
PSNR, peak signal-to-noise ratio; QF, quality factor.
364
CHAPTER 6 Lossless Information Hiding

with QF ¼ 70 and different embedding rates are displayed in Fig. 6.21. From
Tables 6.2e6.4, it can be seen that the bigger the embedding rate is or the smaller
the QF is, the lower the PSNR is. Upon Comparison between these tables, it is
observed that the PSNRs of the stego images obtained by modifying the same
amount of digits are similar, while the embedding rates are multiplied for the exis-
tence of the parameter k. To check the impact of the parameter k on the image qual-
ity, we test on the JPEG image Lena with QF ¼ 70 and the PSNR trends with the
increases in embedding rate are illustrated in Fig. 6.22. When the embedding rate
is the same, the results of k ¼ 3 and k ¼ 4 are better than that of k ¼ 2.
Table 6.4 PSNRs Tested on Lena Image With Different Embedding Rates
and QFs (k ¼ 4)
QF
Embedding Rate (32 bpp)
0.031
0.062
0.094
0.125
0.156
0.187
50
34.36
34.26
34.19
34.09
33.97
33.77
60
35.00
34.94
34.90
34.83
34.75
34.62
70
35.85
35.80
35.75
35.71
35.66
35.58
80
37.00
36.98
36.94
36.90
36.86
36.79
90
39.41
/
/
/
/
/
PSNR, peak signal-to-noise ratio; QF, quality factor.
0.031
0.062
0.094
0.125
0.156
0.187
29
30
31
32
33
34
35
36
37
38
Embedding Rate (bpp)
PSNR (dB)
Baboon
Boat
F16
Goldhill
Lena
Pepper
FIGURE 6.21
The performance of all test images with quality factor (QF) ¼ 70. PSNR, peak signal-to-
noise ratio.
6.2 Lossless Information Hiding in JPEG Images
365

Table 6.5 and Fig. 6.23 present the embedding capacity for the Lena image with
different values of k and QFs. Obviously, the embedding capacity for higher value of
k is larger. However, the capacity decreases when the QF becomes very big. When
the QF becomes bigger, the quantization table entries become smaller so that some
entries are not large enough to apply Eq. (6.9) and kept as their original values.
These unaltered entries result in that the corresponding quantized DCT coefﬁcients
are unaltered and the corresponding space cannot be made to hide the data.
The comparison between the size of the original JPEG ﬁle and the size of the
stego JPEG ﬁle with different values of k and embedding rates is shown in
Fig. 6.24. The general trends are increasing linearly as the embedding rate increases.
In general, the more data we embed, the more quantization entries and quantized
DCT coefﬁcients we modify. In fact, the size of JPEG image ﬁle is signiﬁcantly
compressed by encoding the AC coefﬁcients using ZRLC. We choose the third to
0.031
0.062
0.094
0.125
0.156
0.187
35
35.1
35.2
35.3
35.4
35.5
35.6
35.7
35.8
35.9
36
Embedding Rate (bpp)
PSNR (dB)
k = 2
k = 3
k = 4
FIGURE 6.22
The peak signal-to-noise ratio (PSNR)trends ofthe Lena image withquality factor(QF) ¼ 70.
Table 6.5 Capacity for the Lena Image With Different Values of k and QFs
QF
70
75
80
85
90
k ¼ 2
49,128
49,128
49,128
49,128
49,128
k ¼ 3
73,692
73,692
73,692
73,692
61,404
k ¼ 4
98,256
98,256
98,256
90,064
24,528
QF, quality factor.
366
CHAPTER 6 Lossless Information Hiding

the fourteenth (zero based) quantized DCT coefﬁcients to embed data, therefore the
consecutive zero AC coefﬁcients of midfrequency and high-frequency will not be
broken. The ﬁle size growth is acceptable when the embedding rate is not too high.
From this discussion, we can see that the bigger the parameter k is, the better the
stego image quality is, and the more capacity can be achieved under the same
45
50
55
60
65
70
75
80
85
90
95
0
1
2
3
4
5
6
7
8
9
10
11x 10
4
Quality Factor
Capacity (bit)
k = 2
k = 3
k = 4
FIGURE 6.23
The capacity of the Lena image with different values of k and quality factors.
0.031
0.062
0.094
0.125
0.156
0.187
10
15
20
25
30
35
40
45
50
55
60
Embedding Rate (bpp)
File Size (KB)
Original
k = 2
k = 3
k = 4
FIGURE 6.24
Comparison between the original JPEG ﬁle size and the stego ﬁle size with QF ¼ 70. QF,
quality factor.
6.2 Lossless Information Hiding in JPEG Images
367

conditions. However, the ﬁle size increases more when k is bigger. Thus, the choice
of k needs to balance the image quality and ﬁle size growth. Note that k cannot be too
large or the capacity will decrease when the cover JPEG image has a very high QF.
Table 6.6 shows the improvement of our method in image quality. However, Fri-
drich et al.’s method embedded only 4000-bit message in a certain high-frequency
quantized DCT coefﬁcient and did not offer the choice of the quantized DCT coef-
ﬁcients for high-capacity embedding. Here, we test their method in the same quan-
tized DCT coefﬁcients as our method. From Table 6.6, we can see that the
optimization of multiplying quantized DCT coefﬁcients and embedding rule makes
the distortion smaller and improves the image quality after embedding the same
amount of data. To directly display the subjective quality, we give two stego Lena
images of our method and Fridrich et al.’s method with QF ¼ 70, k ¼ 4, and embed-
ding rate 0.125 in Fig. 6.25. We observe that both stego images are almost identical
with the original one. Moreover, ours is close to the original one on comparing both
stego images with the original one. It can be seen more clearly from the areas near
the hair and the brim of Lena’s hat in Fig. 6.25def; the corresponding areas of Fri-
drich et al.’s are coarser than those of ours.
6.2.6.4.2 Comparisons Between Our Method and Former Methods
To demonstrate that our method is superior to some existing methods, we compare
our proposed method with the methods of Chang et al. [13] and Xuan et al. [14] in
terms of stego image quality and ﬁle size. To ensure that all schemes can be fairly
compared, the test JPEG image Lena is used and the QF for both algorithms is ﬁxed
to 70. Our algorithm is performed with k ¼ 2.
Fig. 6.26 shows the comparison of the stego image quality under different
embedding rates. From Fig. 6.26, we can see that the PSNR values of our method
are much larger than those of Chang et al.’s method and Xuan et al.’s method, which
means that our scheme has a better stego image quality. One reason is that the actual
variation of the original DCT coefﬁcient will not be larger than 1
2 Qðu; vÞ, whereas
the variations of both Chang et al.’s method and Xuan et al.’s method are Q(u,v).
Another reason is that zero coefﬁcients of the midfrequency components in each
block are used to hide the secret data in Chang et al.’s method, whereas our method
embeds data in low-frequency components. As analyzed in Section 6.2.6.1, the
change of low-frequency quantized DCT coefﬁcients have less inﬂuence on the im-
age quality than the change of midfrequency and high-frequency coefﬁcients.
Table 6.6 PSNR Results Tested on the Lena Image With QF ¼ 70 (k ¼ 4)
PSNR
Embedding Rate
0.062
0.125
0.187
0.250
0.312
0.375
Proposed method
35.85
35.80
35.75
35.71
35.66
35.58
Fridrich et al.’s method
34.72
33.98
33.91
33.84
33.71
33.54
PSNR, peak signal-to-noise ratio; QF, quality factor.
368
CHAPTER 6 Lossless Information Hiding

0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
20
22
24
26
28
30
32
34
36
38
40
Embedding Rate (bpp)
PSNR (dB)
Proposed method
Xuan et al.'s method
Chang et al.'s method
FIGURE 6.26
Comparison of the stego image quality with quality factor (QF) ¼ 70 and k ¼ 2. PSNR,
peak signal-to-noise ratio.
Our stego image Lena
(a)
(b)
(c)
(d)
(e)
(f)
Original image Lena
Fridrich et al.'s Stego image
Local area of image (a) 
Local area of image (b)    
Local area of image (c)
FIGURE 6.25
The results of stego images of our method and Fridrich et al.’s method. (a) Our stego
image Lena, (b) original image Lena, (c) Fridrich et al.’s stego image, (d) local area of
image (a), (e) local area of image (b), and (f) local area of image (c).
6.2 Lossless Information Hiding in JPEG Images
369

Xuan et al. also chose low-frequency and midfrequency components to embed data.
However, they need to modify more components because of the histogram pairs
expanding technique. When a high embedding rate is required, their method makes
more histogram pairs which causes the fast decrease of image quality.
Fig. 6.27 shows the comparison of the ﬁle size among the stego images obtained
by our method, by Xuan et al.’s method, and by Chang et al.’s method and the orig-
inal JPEG image on the condition that the embedding rate is 0.125 bpp. For
QF ¼ 70, the original and modiﬁed quantization tables in the experiment are shown
in Fig. 6.18a and b. For different QFs, the ﬁle size of the stego images obtained by
our method and Xuan et al.’s method are much closer to the original one. By
contrast, the ﬁle size of the stego image obtained by Chang et al.’s method is bigger
than the original one. Because the low and midfrequency components are chosen to
embed data, our method and Xuan et al.’s method could restrain the growth of ﬁle
size. However, the ﬁle sizes obtained by the three methods and the ﬁle size of the
original image tend to be equal when the QF becomes very high. High QF means
less compression ratio, which leads to the aforementioned results.
6.2.7 VARIABLE LENGTH CODE MAPPINGeBASED SCHEME
Although Qian and Zhang [21] have made use of the little redundancy existing in the
JPEG bitstream, there is still potential free space that can be explored to hide data. In
this section, the authors improve their scheme and provide a lossless data hiding
scheme in the JPEG bitstream that improves the hiding capacity. By analyzing the
50
55
60
65
70
75
80
85
90
10
20
30
40
50
60
70
80
90
100
Quality Factor
File Size (KB)
Original file size
Proposed method
Xuan et al.'s method
Chang et al.'s method
FIGURE 6.27
Comparison of the stego image ﬁle size with k ¼ 2 and embedding rate 0.125 bpp.
370
CHAPTER 6 Lossless Information Hiding

statistics of both used and unused VLCs, a speciﬁc mapping strategy is produced and
the unused VLCs can be taken full advantage of. The code mapping relationships are
well designed, and the unused VLCs can be properly utilized. The optimization of
mapping relationships can further increase the capacity. The detailed optimization
algorithm as well as embedding and extracting procedures are presented in the
following subsections.
6.2.7.1 Optimization Algorithm to Establish Mapping Relationships
Take AC coefﬁcients for instance; there are 162 predeﬁned VLCs in total. However,
not all the codes are used in a normal JPEG image. For this reason, the unused VLCs
can be mapped to the used VLCs to present secret bits. Mapping codes must observe
certain rules, else the standard JPEG image viewers used by normal users will be
unable to decode and display the stego image properly. As mentioned in Section
6.1.1, VLC corresponds to the (run, size) value, which means one VLC indicates
the current zero run length and the size of appending VLI. The arbitrary mapping
VLC may lead to the misunderstanding of zero run length or the incorrect reading
of appending VLI. To preserve the ﬁle size, we adopt the following code mapping
rules: (1) the length of every code in the mapping set {VLCm, VLCn, ., VLCl}
should be the same and (2) all codes should correspond to the same (run, size) value.
Thus, the mapping relationships can be established inside each category Ci.
These rules are the same as those used in Qian and Zhang’s scheme. Now we turn
to explain our optimization scheme for establishing optimal mapping relationships.
We notice that the statistics of both used and unused VLCs can help design the map-
ping relationships to increase the capacity. Thus, the JPEG bitstream is parsed and
the number of occurrences of every VLC is recorded ﬁrst. A zero number of occur-
rences means that the corresponding VLC is unused. The VLCs in each category Ci
are then sorted in the descending order according to their numbers of occurrences,
which can be presented in the following form:
Ci ¼
n
VLCðuÞ0
i;1 ; .; VLCðuÞ0
i;pi ; VLCðnÞ
i;1 ; .; VLCðnÞ
i;qi
o
(6.20)
where VLCðuÞ0
i;1 ; .; VLCðuÞ0
i;pi are pi-sorted used codes, VLCðnÞ
i;1 ; .; VLCðnÞ
i;qi are qi un-
used codes, and pi þ qi ¼ Li.
If we go along with Qian and Zhang’s way of thinking, we can develop a map-
ping method that takes the above statistics into consideration and call it mapping
method 1. For the case 0 < qi  pi, the VLCs in each category are mapped by a
one-to-one manner similar to Eq. (6.8) as follows:
Mi ¼
nn
VLCðuÞ0
i;1 4VLCðnÞ
i;1
o
; .;
n
VLCðuÞ0
i;qi 4VLCðnÞ
i;qi
oo
(6.21)
In this case, not all used VLCs could be utilized for the reason pi  qi, thus the
sorting keeps the qi frequently appearing used VLCs and abandons the (pi  qi) rela-
tively seldom appearing used VLCs. It avoids easily abandoning the last (pi  qi)
6.2 Lossless Information Hiding in JPEG Images
371

used VLCs in the original order, which may contain the frequently- appearing ones,
and therefore helps to increase the capacity.
For the case 0 < pi < qi, VLCs are mapped by the combination of one-to-many
manner and one-to-one manner. One-to-k manner, for example, can present
log2(k þ 1) secret bits, where k satisﬁes the restrictive condition that log2(k þ 1)
is a positive integer. In other words, one-to-(2j  1) manner can present j secret
bits. For AC coefﬁcients, there are 162 VLCs in total, and the largest category is
C16, which has 125 VLCs, i.e., L16 ¼ 125. The maximum j that satisﬁes
2j  1  125 is 6, thus j could be 1, 2, 3, 4, 5, and 6, which means the parameter
of one-to-k manner could be 1, 3, 7, 15, 31, and 63, respectively. In each category
Ci,
assuming
the
number
of
one-to-(2j  1)
manner
mapping
sets
is
mi,j (1  j  6). To efﬁciently utilize the unused VLCs in this case, the selection
of mi,j should satisfy the following condition:
maxZ ¼ P
6
j¼1
j$mi; j
s.t.
8
>
>
>
>
>
>
>
>
>
>
<
>
>
>
>
>
>
>
>
>
>
:
P
6
j¼1
mi; j  pi
X
6
j¼1

2j  1

$mi; j  qi
mi; j  0; j ¼ 1; 2; .; 6
mi; j integer; j ¼ 1; 2; .; 6
(6.22)
This is an integer linear programming problem. After Eq. (6.22) is solved, all
code mapping relationships can be expressed as:
Mi ¼
8
>
<
>
:
n
VLCðuÞ0
i;1 4
n
VLCðnÞ
i;1 ; .; VLCðnÞ
i;63
oo
; .;
n
VLCðuÞ0
i;mi;64
n
VLCðnÞ
i;63$ðmi;61Þþ1; .; VLCðnÞ
i;63$mi;6
oo
;
n
VLCðuÞ0
i;mi;6þ14
n
VLCðnÞ
i;63$mi;6þ1; .; VLCðnÞ
i;63$mi;6þ31
oo
; .;
(
VLCðuÞ0
i;P6
j¼1mi;j4VLCðnÞ
i;P6
j¼1½ð2j1Þ$mi;j
)
9
>
>
=
>
>
;
(6.23)
That is to say, the ﬁrst mi,6 sorted used VLCs are mapped by the one-to-63
manner, the next mi,5 sorted used VLCs are mapped by the one-to-31 manner, and
so on, and the last mi,1 sorted used VLCs are mapped by the one-to-one manner.
This mapping method only makes the unused VLCs be able to be mapped to as
many used VLCs as possible. In fact, there is still certain potential space to further
increase the capacity. In real cases, some used VLCs may appear with a very high
frequency. Thus, it is even worth abandoning parts of the used VLCs and mapping
372
CHAPTER 6 Lossless Information Hiding

more unused VLCs to the frequently used VLCs, which can help to carry more secret
bits. The following method, which considers these situations, is called mapping
method 2. For the case pi > 0 and qi > 0, VLCs are mapped by the combination
of one-to-many manner and one-to-one manner. Thus, in mapping method 2, we
adopt the same code mapping relationships as given in Eq. (6.23); however the se-
lection of mi,j should satisfy the following condition:
maxZ ¼ 6$
Xmi;6
v¼1countði; vÞ þ 5$
Xmi;6þmi;5
v¼mi;6þ1countði; vÞ
þ 4$
Xmi;6þmi;5þmi;4
v¼mi;6þmi;5þ1countði; vÞ þ 3$
Xmi;6þmi;5þmi;4þmi;3
v¼mi;6þmi;5þmi;4þ1countði; vÞ
þ 2$
Xmi;6þmi;5þmi;4þmi;3þmi;2
v¼mi;6þmi;5þmi;4þmi;3þ1countði; vÞ þ
Xmi;6þmi;5þmi;4þmi;3þmi;2þmi;1
v¼mi;6þmi;5þmi;4þmi;3þmi;2þ1countði; vÞ
s.t.
8
>
>
>
>
>
>
>
>
>
>
>
>
<
>
>
>
>
>
>
>
>
>
>
>
>
:
P
6
j¼1
mi;j  pi
X
6
j¼1

2j  1

$mi;j  qi
mi;j  0; j ¼ 1; 2; .; 6
mi;j are integers; j ¼ 1; 2; .; 6
(6.24)
where the function count(i,v) presents the number of times that the vth sorted used
code in category Ci appears in the entropy-coded segment. After Eq. (6.24) is solved,
by substituting them into Eq. (6.23), we can get the optimal code mapping
relationships.
6.2.7.2 Extension to the Application Case Where File Size Increase
is Acceptable
From Section 6.2.7.1, we establish the mapping relationships inside each category Ci
to preserve the original ﬁle size. In fact, we can extend the earlier scheme to the sit-
uations where slight ﬁle size increase is allowed. In this case, the mapping relation-
ships are not required to be established inside each category. They can be established
among all categories. The ﬁle size increase is induced by mapping the short used
VLCs to long unused VLCs, and a threshold TH could be set to constrain the selec-
tion of used VLCs. The search of used VLCs can be performed among a limited
number of categories, i.e., those categories Ci whose index i is not smaller than
TH, so that certain shortest VLCs will not be chosen. However, the selection of un-
used VLCs is not restrained. Suppose the number of selected used VLCs is p and the
number of unused ones is q. For the case 0 < p  q, VLCs can be mapped by
the combination of one-to-many manner and one-to-one manner. However, for the
case p > q > 0, even all unused codes are mapped by one-to-one manner, and no
6.2 Lossless Information Hiding in JPEG Images
373

more than q used codes will be utilized. Thus, p0 used codes and q unused codes will
be chosen. The deﬁnition of p0 is as follows:
p0 ¼
 p; 0 < p  q
q; p > q > 0
(6.25)
The ﬁrst p0 most frequently appearing used codes are selected and sorted. Like-
wise, the q unused codes are sorted in the ascending order of their lengths for the
purpose that the shorter unused codes could be mapped to the more frequently
appearing used codes:
C ¼
n
VLCðuÞ0
1
; .; VLCðuÞ0
p0 ; VLCðnÞ0
1
; .; VLCðnÞ0
q
o
(6.26)
It helps to control the increase of ﬁle size. Note that all VLCs are taken here, i.e.,
there are 162 VLCs in total for AC coefﬁcients. Hence, the maximum j that satisﬁes
2j e 1  162 is 7 and we suppose the number of one-to-(2je1) manner mapping sets
is mj (1  j  7). The rest part is similar to mapping method 2 as depicted in Section
6.3.1. The selection of mj should satisfy the following condition:
maxZ ¼ 7$
Xm7
v¼1countðvÞþ6$
Xm7þm6
v¼m7þ1countðvÞ þ 5$
Xm7þm6þm5
v¼m7þm6þ1countðvÞ
þ 4$
Xm7þm6þm5þm4
v¼m7þm6þm5þ1countðvÞ þ 3$
Xm7þm6þm5þm4þm3
v¼m7þm6þm5þm4þ1countðvÞ
þ 2$
Xm7þm6þm5þm4þm3þm2
v¼m7þm6þm5þm4þm3þ1countðvÞ þ
Xm7þm6þm5þm4þm3þm2þm1
v¼m7þm6þm5þm4þm3þm2þ1countðvÞ
s.t.
8
>
>
>
>
>
>
>
>
>
>
>
>
<
>
>
>
>
>
>
>
>
>
>
>
>
:
P
7
j¼1
mj  p0
X
7
j¼1

2j  1

$mj  q
mj  0; j ¼ 1; 2; .; 7
mj are integers; j ¼ 1; 2; .; 7
(6.27)
where the function count(v) stands for the number of times that the vth sorted used
code appears in the entropy-coded segment. After Eq. (6.27) is solved, the code
mapping relationships can be expressed as:
Mi ¼
8
>
<
>
:
n
VLCðuÞ0
1
4
n
VLCðnÞ
1 ; .; VLCðnÞ
127
oo
; .;
n
VLCðuÞ0
m7 4
n
VLCðnÞ
127$ðm71Þþ1; .; VLCðnÞ
127$m7
oo
;
n
VLCðuÞ0
m7þ14
n
VLCðnÞ
127$m7þ1; .; VLCðnÞ
127$m7þ63
oo
; .;
(
VLCðuÞ0
P7
j¼1mj4VLCðnÞ
P7
j¼1½ð2j1Þ$mj
)
9
>
>
=
>
>
;
(6.28)
374
CHAPTER 6 Lossless Information Hiding

That is to say, the ﬁrst m7 sorted used VLCs are mapped by the one-to-127
manner, the next m6 sorted used VLCs are mapped by the one-to-63 manner, and
so on, and the last m1 sorted used VLCs are mapped by the one-to-one manner.
6.2.7.3 Data Embedding and Extracting Procedures
Our scheme embeds data into the bitstream of JPEG images based on VLC mapping
and replacing. Our scheme can be divided into two procedures: the data embedding
procedure and the data extracting procedure. After collecting the VLC statistical in-
formation and establishing optimization mapping relationships, our scheme embeds
data into the VLCs in the entropy-coded segment. Fig. 6.28 shows how secret bits
are embedded by replacing VLCs. The detailed data embedding steps are as follows:
Step 1: Parse the JPEG bitstream, read all the VLCs in the entropy-coded
segment, and get statistical results of the number of occurrences for every used
VLC.
Step 2: According to the statistical results, establish the mapping relationships
based on the mapping method mentioned in Sections 6.2.7.1 and 6.2.7.2.
Step 3: Encrypt the original secret data and then modify the Vi,j(run, size) value
in the DHT segment in accordance with the mapping relationships.
Step 4: Replace the VLCs in the entropy-coded segment to embed secret bits.
Vi,l
Vi,k
Vi,n
Vi,m
VLCm
JPEG Bitstream
VLCn
Vi,m
Vi,m
Vi,m
DHT Segment
Entropy-coded Segment
VLC
(run, size)
VLC
(run, size)
Data
VLCm
Vi,m
VLCm
Vi,m
00
VLCn
Vi,n
VLCn
Vi,m
01
VLCk
Vi,k
VLCk
Vi,m
10
VLCl
Vi,l
VLCl
Vi,m
11
FIGURE 6.28
The sketch map of our data hiding scheme by replacing VLCs. DHT, Deﬁne Huffman
Table; VLC, variable length code.
6.2 Lossless Information Hiding in JPEG Images
375

Because the data embedding procedure will keep the original image content
without impacting the image quality, no restoring procedure is required. The data
hidden in the entropy-coded segment can be extracted according to a lookup table,
which is generated by scanning the Huffman table. Fig. 6.29 shows an example of
creating a lookup table. The VLCs with the same (run, size) value are divided
into groups, and the bits that each VLC could present can be calculated by counting
the number of occurrences of the same (run, size) value, i.e., the binary logarithm of
the number of occurrences. Four rows with gray background in Fig. 6.29 are the
VLCs with the same (run, size) value 83. Therefore each of them can present
log24 ¼ 2 bits and the data are listed in the column Value and recorded in decimal
No.
VLC
(run, size)
Bits
Value
1
00
1
0
-
2
01
2
0
-
3
100
3
0
-
4
1010
0
0
-
…
…
…
…
…
64
1111111110011100
147
4
3
65
1111111110011101
147
4
4
66
1111111110011110
83
2
0
67
1111111110011111
84
1
0
68
1111111110100000
85
3
0
…
…
…
…
…
154
1111111111110110
83
2
1
155
1111111111110111
83
2
2
156
1111111111111000
83
2
3
157
1111111111111001
84
1
1
158
1111111111111010
99
1
1
159
1111111111111011
23
1
1
160
1111111111111100
115
1
1
161
1111111111111101
131
1
1
162
1111111111111110
67
1
1
FIGURE 6.29
An example of creating a lookup table in the extracting phase. VLC, variable length code.
376
CHAPTER 6 Lossless Information Hiding

numbers. After a stego JPEG image is received, secret data can be extracted by the
following steps:
Step 1: Read the DHT segment of the stego JPEG image to reconstruct the
Huffman table.
Step 2: Scan the Huffman table and ﬁnd the VLC mapping sets with the same
(run, size) value to create a lookup table containing VLCs and corresponding
secret bits.
Step 3: Parse the JPEG bitstream, read the VLCs in the entropy-coded segment to
extract secret bits according to the lookup table, and then decrypt them back to
achieve original secret data.
6.2.7.4 Security Analysis
In our scheme, the mapping relationships are established by modifying the DHT
segment of the JPEG header. Because the JPEG bitstream must be viewable by com-
mon viewers, the mapping relationships cannot be concealed. The modiﬁed
Huffman table is viewable by the third party, thus careful observation may lead to
the identiﬁcation of the existence of mapping relationships. However, it could be
encrypted to further improve the security of embedded information. For example,
there is a mapping set {VLCm, VLCn, VLCk, VLCl} and the four VLCs are listed
in the order of their appearance in the DHT segment; they present secret bits
“00,” “01,” “10,” and “11,” respectively. If we use a secret key to shufﬂe the order
of the whole predeﬁned VLCs and generate a new order list, which leads to a
different lookup table, then VLCm, VLCn, VLCk, and VLCl may present “10,”
“00,” “11,” and “01” according to the lookup table. The shufﬂe is equivalent to
encrypting the mapping relationships. On the receiver side, the same secret key is
used to get the shufﬂed order and extract the secret data.
In the data embedding phase, a secret key k1 encrypting the secret information
and another secret key k2 encrypting the mapping relationships guarantee the secu-
rity of the embedded data. In some situations, attackers may even erase the
embedded data and replace them with other information. Thus, we can add the secret
information authentication part to the scheme by computing the message integrity
code (MIC) and storing it in the user ﬁelds of JPEG header. MIC is computed by
hashing the original embedded data with a secret key k3. For example, MD2 is
one of the useful hashing functions [11,12]. The receiver extracts the embedded
data and calculates the new MIC from them. By comparing the calculated and stored
MICs, the receiver can authenticate the embedded data.
6.2.7.5 Experimental Results
To evaluate the performance of our scheme, 10 test images obtained from the USC-
SIPI image database [14] are used. These images are the same as those are used in
Ref. [12] and provided in 512  512 TIFF format, which are further converted to
grayscale JPEG images with different QFs using the Netpbm image format conver-
sion program [15]. Comparisons of hiding capacity and embedding efﬁciency
6.2 Lossless Information Hiding in JPEG Images
377

between Qian and Zhang’s scheme and our scheme are discussed. Experimental re-
sults tested on 10 test images with different QFs are listed in Table 6.7, where the
results of Qian and Zhang’s method [12] are also listed. From Table 6.7, we can
see that the capacities of both our method 1 and method 2 are larger than those of
Qian and Zhang’s method and the capacity of our method 2 is larger than that of
our method 1. To demonstrate the capacity increase of our methods compared
with Qian’s methods more clearly, Table 6.8 presents the comparison results from
the perspective of average capacity across all QFs. Our method 1 increases the
embedding bits by 28e43% compared with Qian and Zhang’s method, whereas
our method 2 by 31e63%.
The capacities of our methods and Qian and Zhang’s method are not ﬁxed, and
they depend on the statistical results of the used and unused VLCs. Different image
contents lead to different statistical results. Table 6.8 reveals that the image with
more similar content blocks usually has higher capacity. Take the test JPEG image
F16 with QF ¼ 70, for example; there are 22 used VLCs and 103 unused VLCs in
Category C16. The occurrence distribution of the used VLCs in Category C16 appear-
ing in the entropy-coded segment is given in Fig. 6.30. The left blue bar in each bin is
in the original order (12, 4, 14, 1, 20, 3, 13, 1, 5, 5, 11, 5, 2, 4, 22, 4, 18, 33, 1, 36, 12,
and 2) and the right red one (36, 33, 22, 20, 18, 14, 13, 12, 12, 11, 5, 5, 5, 4, 4, 4, 3, 2,
2, 1, 1, and 1) is in the sorted order. For Qian and Zhang’s method, VLCs are mapped
in the original order, whereas they are mapped in the sorted order for our methods.
Priority in mapping by the one-to-many manner with higher capacity will be given to
those with larger occurrence, which helps to increase the embedding capacity. In
Qian and Zhang’s scheme, every used VLC in Category C16 can carry
k16 ¼
	
log2

q16=p16 þ 1

¼ blog2ð103=22 þ 1Þc ¼ 2 bits, thus all VLCs in Cate-
gory C16 in the entropy-coded segment can carry 456 bits. For our method 1, m16,1,
m16,2, m16,3, m16,4, m16,5, and m16,6 are 0, 13, 9, 0, 0, and 0, respectively, thus all
VLCs in Category C16 can carry 636 bits. For our method 2, m16,1, m16,2, m16,3,
m16,4, m16,5, and m16,6 are 6, 1, 7, 3, 0, and 0, respectively, thus all VLCs in Category
C16 can carry 699 bits. From Fig. 6.30 it can be seen that the values of ﬁrst several
red bars are much higher those of the last several ones, therefore our method 2 aban-
dons the last several ones and thus more unused VLCs can be mapped to the ﬁrst
several ones.
The numbers of VLC mapping sets generated by Qian and Zhang’s method and
our method 2 are compared in Fig. 6.31. Since the number of our method 1 is similar
to that of Qian and Zhang’s method, we do not present it in Fig. 6.31. The abandon-
ing of the last several sorted used VLCs and the mapping of more unused VLCs to
ﬁrst several sorted used VLCs makes the number of sets by our method 2 below that
of Qian and Zhang’s. Fig. 6.32 shows the comparison results of the embedding
efﬁciency, which is deﬁned as the capacity divide by the number of mapping sets.
It can be seen that our method 2 has higher efﬁciency for it can achieve higher ca-
pacity with the lower number of mapping sets.
Table 6.9 lists the performance of our method in terms of the image ﬁle size when
the ﬁle size change is allowed. Experiments are performed on ﬁve test images with
378
CHAPTER 6 Lossless Information Hiding

Table 6.7 Comparison of Embedding Capacity (bits) Between Qian and Zhang’s Method and Our Methods With Different
Quality Factors
Image
Method
Quality Factor
10
20
30
40
50
60
70
80
90
Baboon
Qian and Zhang’s
4954
2263
1278
1588
1080
1005
1082
615
346
Our method 1
6569
3463
1692
1746
1204
1172
1219
669
518
Our method 2
6576
3478
1758
1790
1268
1304
1353
757
681
Boat
Qian and Zhang’s
484
388
522
481
522
714
370
510
978
Our method 1
950
551
680
548
633
782
572
725
1408
Our method 2
950
551
691
571
687
811
679
1000
1929
Bridge
Qian and Zhang’s
733
675
614
755
781
501
436
306
350
Our method 1
1802
996
699
833
912
599
635
446
491
Our method 2
1802
999
713
860
1035
714
817
596
615
Elaine
Qian and Zhang’s
116
142
177
328
402
218
272
576
1002
Our method 1
341
264
200
414
531
302
365
662
1328
Our method 2
341
264
200
414
553
326
409
788
1745
F16
Qian and Zhang’s
615
639
722
737
760
536
487
404
464
Our method 1
791
729
865
881
812
763
678
507
493
Our method 2
791
764
904
961
886
860
741
553
595
Gray21
Qian and Zhang’s
201
447
694
640
767
796
913
1286
2154
Our method 1
235
502
865
987
900
897
1463
1616
2868
Our method 2
235
502
904
987
900
929
1510
1675
3207
Lena
Qian and Zhang’s
261
210
250
291
364
188
204
249
294
Our method 1
565
326
257
296
368
198
256
316
436
Our method 2
565
326
259
296
369
204
286
351
576
Continued
6.2 Lossless Information Hiding in JPEG Images
379

Table 6.7 Comparison of Embedding Capacity (bits) Between Qian and Zhang’s Method and Our Methods With Different Quality
Factorsdcont’d
Image
Method
Quality Factor
10
20
30
40
50
60
70
80
90
Peppers
Qian and Zhang’s
391
380
491
383
389
473
295
280
768
Our method 1
567
513
698
487
534
616
415
280
1065
Our method 2
567
517
717
493
557
652
455
374
1562
Splash
Qian and Zhang’s
330
481
632
724
871
1112
653
714
284
Our method 1
497
581
967
1147
1273
1334
979
953
566
Our method 2
497
597
1064
1345
1382
1547
1180
1147
710
Tiffany
Qian and Zhang’s
4404
500
345
485
467
563
724
590
256
Our method 1
4721
1138
663
888
705
803
920
742
506
Our method 2
4721
1153
681
907
786
875
1002
956
720
380
CHAPTER 6 Lossless Information Hiding

QF ¼ 70. The capacities are not ﬁxed, either. The image content will affect the ca-
pacity and ﬁle size. From Table 6.9 we can see that as the threshold TH increases, the
capacity decreases and so does the ﬁle size. For small THs, the capacity is very high.
Nonetheless, the ﬁle size growth after hiding data is not acceptable. Large THs result
Table 6.8 Comparison of Average Capacity (bits) Between Qian and Zhang’s
Method and Our Methods Across JPEG Quality Factors From 10 to 90
Image
Qian and Zhang’s
Method
Our Method 1
Our Method 2
Capacity
Increase
(%)
Capacity
Increase
(%)
Baboon
1579.00
2028.00
28.44
2107.22
33.45
Boat
552.11
761.00
37.83
874.33
58.36
Bridge
572.33
823.67
42.91
905.67
58.24
Elaine
359.22
489.67
36.31
560.00
55.89
F16
596.00
724.33
21.53
783.89
31.52
Gray21
877.56
1148.11
30.83
1205.44
37.36
Lena
256.78
335.33
30.59
359.11
39.85
Peppers
427.78
575.00
34.42
654.89
53.09
Splash
644.56
921.89
43.03
1052.11
63.23
Tiffany
926.00
1231.78
33.02
1311.22
41.06
10
5
0
1
2
3
4
5
6
7
8
9
10 11
12 13 14 15 16 17 18 19 20 21 22
15
20
25
30
35
40
Original
Sorted
FIGURE 6.30
Statistical results of 22 used VLCs in Category C16 (for the test image F16 with quality
factor 70). VLC, variable length code.
6.2 Lossless Information Hiding in JPEG Images
381

in a satisfactory ﬁle size growth at the expense of lowing capacity. A proper
threshold balances the capacity and the ﬁle size. Threshold could be selected accord-
ing to the data to be hidden. Suppose we need to hide 32,768 bits into the JPEG im-
age Lena, i.e., the embedding rate is 0.125 bpp, TH is recommended to be set to 4.
Fig. 6.33 compares our method with Chang et al.’s method [11] in terms of the
image ﬁle size and PSNR when the ﬁle size change is allowed. Experiments are per-
formed on the test image Lena with QFs ranging from 10 to 90. Fig. 6.33 shows the
results when hiding 32,768 bits. For each case, the ﬁle size of our method is similar
to that of Chang et al.’s and a little closer to the original ﬁle size. Note that the PSNR
Number of VLC Mapping Sets 
Quality Factor
0
10
20
30
40
50
60
70
80
90
5
10
15
20
25
30
35
40
Lena(Qian and Zhang's)
Lena(Our method 2)
Tiffany(Qian and Zhang's)
Tiffany(Our method 2)
FIGURE 6.31
Comparisons of the number of VLC mapping sets between our method 2 and Qian and
Zhang’s method with different quality factors. VLC, variable length code.
Efficiency
Quality Factor
Lena(Qian and Zhang's)
Lena(Our method 2)
Tiffany(Qian and Zhang's)
Tiffany(Our method 2)
10
0
50
100
150
200
250
300
350
400
450
20
30
40
50
60
70
80
90
FIGURE 6.32
Comparisons of embedding efﬁciency between Qian and Zhang’s method and our
method 2 with different quality factors.
382
CHAPTER 6 Lossless Information Hiding

Table 6.9 Performance of Our Scheme in the Application Case Where the File Size Increase is Allowed (Quality
Factor ¼ 70)
Image
Original File
Size (KB)
Evaluation
Criteria
TH
4
5
6
7
8
9
10
Baboon
61.0
Capacity (bit)
119,513
56,672
31,421
21,176
12,486
8436
3493
File size (KB)
113.0
84.6
73.0
68.6
65.1
63.6
61.9
Boat
36.6
Capacity (bit)
73,174
33,552
18,891
12,223
7223
5347
2925
File size (KB)
69.1
50.8
44.1
41.3
39.0
38.2
37.2
F16
30.0
Capacity (bit)
64,676
27,829
13,987
8252
3969
2520
1470
File size (KB)
58.6
41.6
35.3
33.0
31.3
30.7
30.3
Lena
28.6
Capacity (bit)
65,325
29,198
15,976
8879
4874
3010
1557
File size (KB)
56.7
40.4
34.6
31.8
30.1
29.5
28.9
6.2 Lossless Information Hiding in JPEG Images
383

of Chang et al.’s changes from 18 to 36 dB, whereas our method can keep the orig-
inal image’s content and quality. Therefore, our method can provide high capacity,
acceptable ﬁle size growth, and image quality preservation.
6.3 LOSSLESS INFORMATION HIDING IN JPEG2000 IMAGES
As an important branch of information security, information hiding in images has
been extensively studied in recent years. However, most schemes will introduce irre-
versible distortion to the original image. It is unallowable in some special applica-
tions such as legal imaging and medical imaging. So reversible information hiding
deserves us to study. In addition, most existing information hiding schemes are for
BMP and JPEG images. There are few related schemes for JPEG2000 images. So it
is very necessary for us to study reversible information hiding for JPEG2000 images.
6.3.1 OVERVIEW
To understand the following schemes better, we introduce the JPEG2000 codec ﬁrst.
The block diagram of the JPEG2000 codec is shown in Fig. 6.34. In the JPEG2000
encoder, image preprocessing is performed at ﬁrst. Here, image preprocessing in-
cludes image tiling, DC level shifting, and component transformation. Image tiling
is applied to the original image by dividing it into rectangular nonoverlapping blocks
(tiles). These blocks can be processed independently. DC level shifting can ensure
that the input sample data has a nominal dynamic range that is approximately
centered about 0. Then component transformation or color transformation is
Quality Factor
Original file size
File size (Proposed)
PSNR (Chang et al. s)
File size (Chang et
 al. s)
10
10
0
20
20
30
30
40
50
60
70
40
50
PSNR (dB)
File Size (KB)
60
70
80
80
90
0
5
10
15
20
25
30
35
40
'
'
FIGURE 6.33
Comparisons of image ﬁle size and PSNR between our method and Chang et al.’s method
when the ﬁle size change is allowed. PSNR, peak signal-to-noise ratio.
384
CHAPTER 6 Lossless Information Hiding

performed on the tile-component data. Only two component transformations are
deﬁned in the baseline JPEG2000 codec, i.e., ICT and RCT. Both of them can
map the image data from the RGB color space to the YCbCr color space. Next, these
tiles are decomposed into different decomposition levels by the FDWT. After N
levels of DWT, we can get the decomposed image, which is made up of a low-
frequency subband called LLN and 3  N high-frequency subbands referred to as
HLi, LHi, HHi, where i ¼ 1, 2, . N. Fig. 6.35 shows the subband structure after
three levels of DWT. Then the resulting wavelet coefﬁcients in all subbands are
quantized. Next, entropy coding including tier-1 coding and tier-2 coding is applied
to the quantized blocks to generate JPEG2000-compressed bitstream. Up to this
point, the encoding process is ﬁnished. The decoding process of the JPEG2000
codec is just the reverse of the encoding process.
Preprocessing
FDWT
Quantization
Tier-1
Encoder
Tier-2
Encoder
Rate Control
Original
Image
Compressed
Bitstream
Encoder
Tier-2
Decoder
Tier-1
Decoder
De-quantization
IDWT
Postprocessing
Compressed
Bitstream
Decoder
Reconstructed
Image
(a)
(b)
FIGURE 6.34
The block diagram of JPEG2000 codec. (a) Encoder, (b) Decoder
HH1
HL1
LH1
HH2
HL2
LH2
HL3
HH3
LH3
LL3
FIGURE 6.35
The subband structure.
6.3 Lossless Information Hiding in JPEG2000 Images
385

In the literature, many reversible information hiding schemes have been pro-
posed. These schemes can be broadly divided into three types: spatial domaine
based schemes, transform domainebased schemes, and compressed domainebased
schemes. In the spatial domain, there are many effective schemes. Ni et al. proposed
a classic lossless data hiding scheme based on histogram shifting [24]. The scheme
can embed data by shifting the image histogram. Leest et al. also proposed a lossless
scheme based on histogram [25]. They utilize a compression function to introduce
gaps for data hiding in the histogram. Compared with the former, this scheme can
increase the embedding capacity. Tian proposed another classic reversible data hid-
ing algorithm based on difference expansion [26]. The hidden data can be embedded
by expanding the difference between two adjacent pixels. But the embedded location
map takes up much space. In addition, in recent years, Wu et al. proposed a novel
data hiding algorithm with the property of contrast enhancement [27]. Luo et al. pro-
posed a scheme based on hybrid prediction and interleaving histogram modiﬁcation
with single-seed pixel recovery [28]. Shin et al. proposed a lossless data hiding tech-
nique using a reversible function and a pattern table [29]. In the transform domain,
Yang et al. proposed a good reversible watermarking scheme [30]. This scheme
takes advantage of integer DCT coefﬁcients’ Laplacian-shape-like distribution
and chooses AC coefﬁcients for the bit shift operation. In the compressed domain,
with regard to vector quantization (VQ)ecompressed images, Chu et al. proposed
a high-capacity reversible information hiding algorithm based on difference coding
of VQ indices [31]. Zhao et al. proposed a high-efﬁciency reversible data hiding
scheme for two-stage VQ-compressed images [32]. With regard to block truncation
codingecompressed images, Li et al. proposed a reversible data hiding scheme
based on bit-plane ﬂipping and histogram shifting of mean tables [33]. With regard
to JPEG-compressed images, Hu et al. proposed a lossless data hiding scheme based
on improved VLCs) [23]. Jung proposed a new data hiding algorithm of embedding
ﬁlter coefﬁcients in JPEG bitstream [34]. With regard to JPEG2000 compressed im-
ages, Ohyama et al. proposed a lossless data hiding scheme using bit-depth informa-
tion embedding [35].
6.3.2 CHEN ET AL.’S IRREVERSIBLE WATERMARKING SCHEME
Before introducing lossless data hiding schemes for JPEG2000 images, we ﬁrst
introduce an irreversible watermarking scheme proposed by Chen et al. [36]. This
scheme embeds and extracts information based on the JPEG2000 Codec process.
It applies the torus automorphisms (TA) technique to break up the watermark, which
are then embedded into the bitstreams after the JPEG2000 quantization step but
prior to entropy coding. During quantization, all the coefﬁcients would have been
normalized and easy to manipulate. Distortion reduction technique is used on the
compressed image to lessen image degradation caused by embedding. It is simple
and easy to implement. Furthermore, it is robust to attacks like blurring, edge
enhancement, and mosaic. In JPEG2000, we can use either 16 or 32 bits to be the
binary length for the coefﬁcients [1]. For convenience, this scheme uses 32 bits.
386
CHAPTER 6 Lossless Information Hiding

The MSB is the signed bit, and the remaining would be the absolute magnitude of
the coefﬁcient where embedding takes place (starting from the nonsigned high-
magnitude bits). This scheme is divided into the embedding and extracting pro-
cesses. More details are presented in the following subsections.
6.3.2.1 Embedding the Watermark
First, scattering is performed on a 32  32 binary watermark using the TA tech-
nique. The aim of this action is to cause the embedded watermark to be impercep-
tible. Assume that (x0,y0)T represents the original coordinate of the watermark and
(x1,y1)T denotes the coordinate after scattering. Assume that N is the breadth size
for the watermark and n is the overlap frequency for the transform matrix
 1
1
k
k þ 1

and (x0,y0)T, where the value of n is the private scattering key.
Then, using the single parameter TA, the scattering is performed according to
 x1
y1

¼
 1
1
k
k þ 1
n x0
y0

modN
(6.29)
For example, to scatter a 32  32 watermark we have
 x1
y1

¼
 1
1
1
2
n x0
y0

mod32
(6.30)
Here, for n ¼ 24, we have an image similar to that of the original. At this point
we say it has reached a cycle C. Therefore, by subtracting C from n we will get the
overlap frequency needed for restoring the watermark. This is the private restore key.
The scattered watermark will be embedded in the subbands after quantization.
The number of subbands used depends on the size of the watermark. The embedding
process is in the sequence of LL, LHj, HLj, HHj where j ¼ J, J1, ., 1 (J is the
integer number of frequency of decomposition in DWT). For example, in an image
of size 512  512 pixels, after being decomposed 5 times, the subbands LHj, HLj,
and HHj are of the size 512
2j  512
2j
where j ¼ 5, 4, 3, 2, 1. The size of LL is
512
25  512
25 ¼ 16  16. Thus, a 32  32 watermark requires four subbands: LL,
LH5, HL5, and HH5 to embed.
After quantization, all coefﬁcients are normalized in JPEG2000 as shown in
Fig. 6.36. The MSB is the sign bit and will not be used for embedding. The rest
sign bit
1 bit
dynamic
range
integer
32 bits
decimal
dynamic
range
FIGURE 6.36
Coefﬁcient after normalization.
6.3 Lossless Information Hiding in JPEG2000 Images
387

is the nonsigned absolute coefﬁcient used for embedding. The watermark is
embedded into the nondecimal integer portion of the coefﬁcient, whereas its decimal
fraction portion is discarded as insigniﬁcant. Next, embedding process begins by
inserting a value of either 0 or 1 into the Mb bit as follows:
Mb ¼ bIn  abc
where ab ˛½0; 1
(6.31)
where In are the nondecimal integer bits with the dynamic range as given in Fig. 6.36
and ab is the predeﬁned threshold value. The bigger the threshold is, the more robust
the embedding watermarks are. For example, when In ¼ 7 and ab ¼ 0.6, then
Mb ¼ P9  0:6R ¼ 5. Based on the embedding value, either 0 or 1 will be embedded
into the ﬁfth bit location. Thus, if the threshold ab is larger, the embedding position
is in the higher magnitude bit, implying stronger image robustness.
Since the watermark is embedded in the signiﬁcant subband (for example, LL),
this will affect the quality of the image. For this reason, the distortion reduction tech-
nique should be applied to help reduce the damage from image distortion. Assume
that there is a coefﬁcient with a whole number value of (314)10. Its binary form is
shown in Fig. 6.37. The LSB is the zeroth bit. The MSB is the eighth bit (excluding
the sign bit and the left 0-padded bits that make up 32 bits). The watermark is also
converted into the binary form. For this example, we will not use the Mb rule and
threshold ab to simplify the analysis process to choose the embedded value for
the coefﬁcient that is closest to the original value. Next, we introduce embedding
0 and 1.
6.3.2.1.1 Embedding Value 0
Suppose 0 is embedded into the ﬁfth bit of the coefﬁcient, the modiﬁed value and
original coefﬁcient might have the difference of 25 ¼ 32. As shown in Fig. 6.38,
value 1 is equal to (282)10. To lower the image distortion, a value 0 is chosen to
replace the ﬁfth bit. Since there are too many values to choose from, only three con-
ditions are considered as shown in Fig. 6.38. The ﬁrst one is value 1. The second one
is to change the sixth bit into 1 in Value 2, whereas the fourth, third, and second bits
are changed to 0 with the ﬁrst and zeroth bits ﬂipped from 0 to 1, or vice versa,
depending on its original value. Value 2 is equal to (321)10. The third one is to
change the fourth, third, and second to 1 with the ﬁrst and zeroth bits ﬂipped as
FIGURE 6.37
(314)10 In the binary form. LSB, least signiﬁcant bit; MSB, most signiﬁcant bit.
388
CHAPTER 6 Lossless Information Hiding

in Value 2. Here, Value 3 is equal to (317)10. Finally, a value closest to the original
coefﬁcient from those three conditions is chosen to replace and to get the smallest
image distortion possible.
6.3.2.1.2 Embedding Value 1
The rules for modiﬁcations here are similar to Eq. (6.30), as shown in Fig. 6.39. For
Value 1, it is embedded into the ﬁfth bit giving (314)10. It is coincidental that the
embedded value happens to be the original value. The test performs well for other
test data, too. The sixth bit in Value 2 is modiﬁed to 0 and the ﬁfth to second bits
are modiﬁed to 1 with the ﬁrst and zeroth bits ﬂipped between 0 and 1 depending
on its original values. This give the value (317)10. On the contrary, in Value 3, the
FIGURE 6.38
The three candidate conditions for embedding 0. LSB, least signiﬁcant bit; MSB, most
signiﬁcant bit.
FIGURE 6.39
The three candidate conditions for embedding 1. LSB, least signiﬁcant bit; MSB, most
signiﬁcant bit.
6.3 Lossless Information Hiding in JPEG2000 Images
389

ﬁfth bit is modiﬁed to 1 and the fourth to second bits are modiﬁed to 0, whereas the
ﬁrst and zeroth bits are ﬂipped giving (289)10. The one with the closest value to the
original coefﬁcient will be chosen.
Thus the whole embedding process can be described as follows. The original
watermark is ﬁrst scattered by using TA with a private key. Before embedding,
the scattered watermark will go through the process of distortion reduction to reduce
the loss. Embedding is then done after the JPEG2000 quantization stage and before
entropy coding, as given in Fig. 6.40.
6.3.2.2 Watermark Extraction Process
After the entropy decoding stage of the JPEG2000 decoder, the watermark is
extracted using the Mb rule as given in Eq. (6.31). Extraction will be performed in
the order of embedding in the subbands. The total number of subbands extracted rep-
resents the size of the watermark. Restoring is performed using TA and the private
restore key. Fig. 6.41 illustrates the ﬂowchart of the watermark extraction process.
6.3.3 BIT-DEPTH EMBEDDINGeBASED SCHEME
In 2007, Tanaka et al. proposed a reversible information hiding for binary images
[37]. Based on this article, Ohyama et al. presented a lossless data hiding method
for JPEG2000-compressed data based on the reversible information hiding [35].
In JPEG2000 compression, wavelet coefﬁcients of an image are quantized, there-
fore, the LSB plane can be extracted. Ohyama et al.’s method recovers the quantized
wavelet coefﬁcients of cover images from stego images. To realize this, Ohyama
et al. embedded not only secret data and the JBIG2 bitstream of a part of the LSB
Original 
image
Tiling
Component
Transform
FDWT
Compressed
Image
(Hidden image)
Quantization
Entropy
Coding
Scattered watermark
Distortion
Reduction
Original
 watermark
Torus
Automorphisms
+
private scatter key
Rate Allocation
FIGURE 6.40
The ﬂowchart for the watermark embedding. FDWT, forward discrete wavelet transform.
390
CHAPTER 6 Lossless Information Hiding

plane but also the bit-depth of the quantized coefﬁcients on some code-blocks.
Experimental results demonstrate the feasibility of application of this method to im-
age alteration detection for JPEG2000-compressed data.
6.3.3.1 Reversible Information Hiding for Binary Images
In Tanaka et al.’s scheme [37], the data to be embedded is hidden into the noisy
blocks on cover binary images. The noisy blocks are extracted by the simple thresh-
olding with threshold aTH of the measure called complexity deﬁned for binary im-
ages. Only half of the pixels in noisy blocks are replaced with the bitstream of
embedded data. Pixels used in the embedding are corresponding to white pixels
(or block pixels) on checkerboard patterns. In other words, cover binary images
are regarded as consisting two types of pixels: replaceable pixels and unusable pixels
which correspond to white pixels and black pixels on checkerboard patterns,
respectively.
In order to recover original images, it is required to embed the original informa-
tion of replaceable pixels and make space for secret data, therefore cover binary im-
ages are compressed that all unusable pixels are set to 0 (or one) using the JBIG2
compression scheme. The compressed data and secret data are embedded into cover
binary images.
The embedding process of this method is performed by replacing replaceable
pixels with the embedded bitstream. The complexity of the noisy block may become
smaller than aTH by the embedding. In that case, the conjugate operation is applied
Compressed image
(hidden image)
Reconstructed image
(no hidden image)
Reconstructed
watermark
Extracted watermark
Inverse
Component
Transform
Entropy
Decoding
Torus
Automorphisms
+
private restore key
Dequantization
IDWT
FIGURE 6.41
Flowchart for watermark extraction. IDWT, inverse discrete wavelet transform.
6.3 Lossless Information Hiding in JPEG2000 Images
391

to it to keep the complexity of the block from being greater than aTH. It is required to
keep track, for each block, of whether the conjugate operation had been applied us-
ing a conjugation ﬂag. The value of 1 of replaceable pixels is made to the ﬂag.
At the receiver side, one can extract the embedded bitstream from noisy blocks
by scanning the image in the same order in embedding. For the blocks to which con-
jugate operation applied, the conjugate operation prior to extracting embedded infor-
mation is applied. The extracted bitstream is separated into the bits of secret data and
the JBIG2 bitstream. The bitstream is decompressed to reveal the original pixel. The
original binary image can be completely restored by replacing the replaceable pixels
of the stego image with one of the decompressed image.
6.3.3.2 Reversible Information Hiding for JPEG2000 Images
In Ohyama et al.’s method, they assume that the data of cover image is given as a
JPEG2000-compressed bitstream and the embedding procedures are performed to
the bitstream; as a consequence of this, stego images are produced as a JPEG2000-
compressed bitstream. The quantized wavelet coefﬁcients in the cover image are
completely recovered from the stego image.
6.3.3.2.1 Embedding
The block diagram of the encoding in Ohyama et al.’s method is illustrated in
Fig. 6.42. In JPEG2000, the bit-depth to represent quantized wavelet coefﬁcients
is allowed for code-blocks to vary within 32 bits including plus minus sign, and
this depth is determined after the tier-2 encoding. Therefore, by using the bit-
depth information, we can extract the LSB from each wavelet coefﬁcient encoded
in the JPEG2000 bitstream.
Basically, Ohyama et al.’s method applies Tanaka et al.’s reversible information
hiding method for binary images described before to the LSB plane extracted from
quantized wavelet coefﬁcients, which is regarded as a binary image. However,
Tanaka et al. have found a problem that the bit-depth of code-blocks containing
wavelet coefﬁcients value of 0, 1 or 1 increases by the embedding through several
experiments. This makes us to extract embedded information incorrectly. To solve
the problem, it is required to embed not only JBIG2 bitstream and secret data but
also the bit-depth of the code-blocks. The embedding procedures in detail are as fol-
lows. Firstly, the bit-depth information of code-blocks on all resolution of subbands
Tier-2
Decoder
Decode
MQ-code
Decode
bit-plane
code
bit-plane
coding
bit-plane structure
(LSB plane)
Embedded data
Embedding
MQ-
coder
Tier-2
Encoder
Compressed Data
of cover image
Compressed Data
of stego image
FIGURE 6.42
The ﬂowchart for watermark extraction. LSB, least signiﬁcant bit; MQ-coder, binary
adaptive multiplication-free arithmetic entropy coder used in JPEG2000.
392
CHAPTER 6 Lossless Information Hiding

except for the lowest one is collected, and then it is embedded into the region where
code-blocks are on the lowest resolution of subbands. For the rest of pixels, the
JBIG2 bitstream and secret data are embedded.
6.3.3.2.2 Extraction and Recovering Original Wavelet Coefﬁcients
After tier-1 decoding, quantized wavelet coefﬁcients are reconstructed, and then the
coefﬁcients are divided into code-blocks with the same size as in encoding. From the
code-blocks that are on the lowest resolution of subbands, the original bit-depth in-
formation of the rest of code-blocks is extracted, and then, by using the bit-depth
information, the embedded bitstream consisting of secret data and JBIG2 bitstream
is extracted. The recovering of the original wavelet coefﬁcients is as follows. The
extract JBIG2 bitstream is ﬁrst decoded, and then the pixel value located on change-
able pixels of the decoded image is replaced. After this replacement, the original
quantized wavelet coefﬁcients are completely reconstructed.
6.3.3.3 Experimental Results
Ohyama et al. have implemented their algorithm in the JJ2000 software. To illustrate
the performance of Ohyama et al.’s method, they embedded four JPEG2000 test im-
ages Airplane, Bridge, Barbara, and Lena (8 bpp, 512  512) with 8  8 block size
used to calculate the complexity of binary images, 5/112 complexity threshold
(¼aTH), and a random bit sequence embedded as a secret data. A 5-scale wavelet
transform with the Daubechies 9/7 ﬁlter was applied to the images, therefore
64  64 and 32  32 of code-blocks in size were selected. The number of code-
blocks on the images was 70. The four code-blocks on the lowest resolution of sub-
band were used to embed the bit-depth of the rest of code-blocks. Therefore, it is
required to embed 330 bits (¼ 66  5 bits) to keep the depth information.
Table 6.10 shows the results obtained by the experiment. PSNRc and PSNRs
represent PSNR of cover image and that of the stego image with the JPEG2000
compression, respectively. The quality of the whole image is almost acceptable
for the test images that Ohyama et al. used in the experiments. However, uniform
regions could be slightly distorted with sandy noise added. In addition, the image
degradation of zoomed regions may be recognized. The embedded information
Table 6.10 Experimental Results for Five Test Images
Image
Cover
Size
(byte)
Stego
Size
(byte)
PSNRc
(dB)
PSNRs
(dB)
JBIG2 of
LSB Plane
(byte)
Secret
Data
(bit)
Hiding
Rate
(%)
Airplane
33,467
49,394
41.39
36.84
6230
9166
22.16
Bridge
32,604
49,394
30.53
27.02
8276
9502
29.15
Barbara
32,641
49,014
37.96
33.61
7294
4198
24.08
Lena
33,150
50,471
40.43
36.38
6195
11,814
23.26
LSB, least signiﬁcant bit; PSNRc, peak signal-to-noise ratio of cover image; PSNRs, peak signal-to-
noise ratio of stego image with JPEG compression.
6.3 Lossless Information Hiding in JPEG2000 Images
393

used in the experiments is quite large compared with the number of bits to represent
hash value, such as SHA-1, which produces a message digest that is 160 bits long.
Because whole LSB plane was used in the experiments, Ohyama et al. certainly
avoid the image degradation by using only a part of the LSB plane for the
embedding.
6.3.4 REVERSIBLE INFORMATION HIDING BASED ON HISTOGRAM
SHIFTING FOR JPEG2000 IMAGES
6.3.4.1 Introduction
Recently, the authors of this book have proposed a reversible information hiding
scheme for JPEG2000-compressed images. In our scheme, high-frequency subbands
of the cover image are divided into blocks. In each block, the histogram generated by
the quantized wavelet coefﬁcients of the block is shifted to create gaps for embed-
ding data. Experimental results show that our scheme has satisfactory performance.
Compared with other schemes, our scheme has higher embedding capacity and bet-
ter visual quality of the stego image.
Embedding data into JPEG2000 images has some differences from embedding
data into other types of images. The differences will lead to some difﬁculties. As
a compressed image, the redundancy of a JPEG2000 image is smaller than that of
an uncompressed image such as a BMP image. So the space for data hiding is
limited. This will increase the difﬁculty of data hiding. In addition, the encoding pro-
cess of JPEG2000 is more complex. Some encoding operations such as quantization
and bitstream layering probably destroy the hidden data. It requires that data hiding
should be coordinated with the encoding process of JPEG2000. So selecting suitable
embedding position is important and difﬁcult. To realize reversible data hiding, our
scheme utilizes histogram shifting technique to embed data into quantized wavelet
coefﬁcients in high-frequency subbands of the cover image. Our shifting scheme is
different from Ni et al.’s scheme [24]. In Ref. [24], the histogram is generated from
the pixel values in the image. However, in our scheme, the histogram is generated
from the quantized wavelet coefﬁcients in the small block. In addition, the way
we shift the histogram is also different. In their scheme, the histogram is always
shifting toward the zero-point. However, in our scheme, we introduce a direction
sign ﬁrst. The value of the sign depends on the distribution of the histogram.
Then the histogram of the block is shifted to the left or right adaptively according
to the value of the direction sign. This can reduce the impact of histogram shifting
on image visual quality to some extent. Moreover, the histogram will be shifted by
three units in our work instead of one unit in their scheme. So every coefﬁcient that
is associated with the peak point can embed 2 bits instead of 1 bit. This can increase
the embedding capacity.
To embed data into a JPEG2000 image and recover the image without any distor-
tion, a reversible information hiding scheme based on histogram shifting is pre-
sented. Our scheme is different from Ohyama et al.’s scheme [35]. In their
scheme, the low-frequency subband is also used for embedding data. However,
394
CHAPTER 6 Lossless Information Hiding

we embed data into the high-frequency subbands only. In addition, they utilize the
LSB plane of wavelet coefﬁcients to embed data, whereas we adopt a method
different from theirs. We use a new histogram shifting method to create space for
embedding data. In our scheme, we introduce a direction sign ﬁrst. The value of
the sign depends on the distribution of the local histogram. Then the local histogram
is shifted to the left or right adaptively according to the direction sign. Every coef-
ﬁcient that is associated with the peak point of the histogram can embed 2 bits. The
detailed procedure of our scheme is described as follows.
6.3.4.2 Data Embedding
The block diagram of data embedding is shown in Fig. 6.43. In the embedding pro-
cess, high-frequency subbands of the cover image are divided into blocks. For each
block, a new histogram shifting method is applied to the local histogram generated
from all quantized wavelet coefﬁcients in the block. The detailed embedding process
is described as follows.
Step 1: The original JPEG2000 image is partially decoded ﬁrst. The decoding
process stops before the dequantization stage. So we can get the quantized
wavelet coefﬁcients of all subbands.
Step 2: Divide the high-frequency subbands into m  m blocks. The number of
the blocks is denoted by N.
Step 3: For each block Bi (i ¼ 1, 2, ., N), all coefﬁcients in Bi are used to
generate the local histogram of the block. Denote the peak point in the
histogram as Pi. The number of times Pi occurs in the block is denoted by Ci.
Then calculate T (the number of blocks that need to be used for embedding data)
according to the number of hidden data bits and the values of Ci.
Step 4: For each needed block Bi (i ¼ 1, 2, ., T), calculate Li (the number of
values that are distributed in the left side of Pi) and Ri (the number of values that
are distributed in the right side of Pi). Deﬁne a direction sign Si to mark the
direction that the histogram shifts toward: Si ¼ 1 denotes that the histogram
shifts to the right, whereas Si ¼ 0 denotes that the histogram shifts to the left.
Then compare Li with Ri. If Li  Ri, Si ¼ 1; otherwise, Si ¼ 0.
Step 5: If Si ¼ 1, shift the right side of Pi to the right by three units. It means that
all coefﬁcients in the right side of Pi are added by 3. If Si ¼ 0, shift the left side
of Pi to the left by three units. It means that all coefﬁcients in the left side of Pi
are subtracted by 3. This step is used to create gaps for embedding data.
Divide subbands
into blocks
Generate the
histogram of
each block
Shift histogram
and embed data
Decode
the image
Encode
the image
Original
Image
Stego
Image
FIGURE 6.43
The block diagram of data embedding.
6.3 Lossless Information Hiding in JPEG2000 Images
395

Step 6: Scan the coefﬁcients of each block Bi (i ¼ 1, 2, ., T) in a sequential
order (row by row, from top to bottom). Once we encounter the coefﬁcient
whose value is Pi, check the hidden binary sequence and perform embedding
operations until all data bits are embedded. There are four possible cases as
follows:
Case 1: If the hidden bit string is “00,” the coefﬁcient remains unchanged.
Case 2: If the hidden bit string is “01,” 1 is added to the coefﬁcient while
Si ¼ 1 or 1 is subtracted from the coefﬁcient while Si ¼ 0.
Case 3: If the hidden bit string is “10,” 2 is added to the coefﬁcient while
Si ¼ 1 or 2 is subtracted from the coefﬁcient while Si ¼ 0.
Case 4: If the hidden bit string is “11”, 3 is added to the coefﬁcient while
Si ¼ 1 or 3 is subtracted from the coefﬁcient while Si ¼ 0.
Step 7: After all data bits have been embedded, perform encoding operations to
generate the stego JPEG2000 image.
The values of Pi and Si of block Bi (i ¼ 1, 2, ., T ) and the size of hidden data
serve as a key. The sender can send the stego JPEG2000 image to the receiver in the
public channel. Only on getting the key can the receiver extract the hidden data from
the image and recover the image.
6.3.4.3 Data Extraction and Original Image Restoration
The block diagram of data extraction and image restoration is shown in Fig. 6.44.
The detailed process can be described as follows.
Step 1: At ﬁrst, decode the stego JPEG2000 image partially. The decoding
process stops before the dequantization stage. So the modiﬁed quantized
wavelet coefﬁcients can be obtained.
Step 2: Divide the high-frequency subbands into m  m blocks. For each block Bi
(i ¼ 1, 2, ., T), scan the coefﬁcients of the block in the same sequential order
as that used in the aforementioned embedding process and perform the corre-
sponding operations according to the value of Si. If all hidden data bits have
been extracted, stop extracting data and just shift the histogram of the block
back. The corresponding operations are as follows.
(1) If Si ¼ 1, perform the following operations:
Scan the block. Once the coefﬁcient between Pi and Pi þ 3 is encountered
(including Pi and Pi þ 3), extract data from this coefﬁcient. There are also four
possible cases as follows:
Divide subbands
into blocks
Scan the
values in
the block
Extract data
and shift
histogram back
Decode
the image
Encode
the image
Stego
Image
Recovered
Image
FIGURE 6.44
The block diagram of data extraction and image restoration.
396
CHAPTER 6 Lossless Information Hiding

Case 1: If the coefﬁcient is equal to Pi, extract bit string “00.” The coefﬁcient
remains unchanged.
Case 2: If the coefﬁcient is equal to Pi þ 1, extract bit string “01” and set it
to Pi.
Case 3: If the coefﬁcient is equal to Pi þ 2, extract bit string “10” and set it
to Pi.
Case 4: If the coefﬁcient is equal to Pi þ 3, extract bit string “11” and set it
to Pi.
Scan the block again. If a coefﬁcient is below Pi  3, add 3 to it. The goal is to shift
the histogram back. Other coefﬁcients remain unchanged.
(2) If Si ¼0, perform the following operations:
Scan the block. If the coefﬁcient is between Pi  3 and Pi (including Pi  3 and Pi),
extract data from the value. In this case, Pi corresponds to “00,” Pi  1 corresponds
to “01,” Pi  2 corresponds to “10,” and Pi  3 corresponds to “11.” After the bit
string is extracted from the coefﬁcient, the coefﬁcient will be set to Pi.
Scan the block again. If a coefﬁcient is above Pi þ 3, subtract 3 from it. The goal is
to shift the histogram back. Other coefﬁcients remain unchanged.
Step 3: After all data bits have been extracted, perform encoding operations to
reconstruct the original image.
6.3.4.4 Experimental Results
In this section, some experimental results are given to evaluate the performance of
our scheme. The implementation of our scheme is based on JasPer [16] and Visual
Studio 2010. The JasPer software is speciﬁed by the JPEG2000 standard. It can pro-
vide the implementation of the JPEG2000 codec. Some 512  512 JPEG2000 gray-
scale images are used as test images, as shown in Fig. 6.45. The hidden data are a
block of secret text. The text will be converted to a binary sequence. The number
of levels of DWT we performed is ﬁve. To evaluate the similarity between the orig-
inal image and the stego image, we choose their PSNR as the indicator. A larger
PSNR value indicates a higher similarity and less image distortion. Generally, the
stego image with 30 dB PSNR or above will be regarded as visually acceptable.
In our scheme, high-frequency subbands are divided into m  m blocks. The
choice of the block size is an important issue. So we need to analyze the relationship
between the block size and the embedding capacity ﬁrst. The block size is typically
set to a power of 2. The results are shown in Table 6.11.
From Table 6.11, we can ﬁnd that the embedding capacity of the scheme de-
creases with the increase of block size on the one hand. On the other hand, for con-
venience, the block size should not be too small. So a good choice is 8  8. In the
following experiments, the block size is 8  8.
For information hiding, the embedding capacity and the visual quality of stego
image are both important indicators to measure the performance of the scheme.
Table 6.12 shows the PSNR values of stego images after embedding different
amounts of data. From Table 6.12, we can see that our scheme achieves satisfactory
PSNR values. In addition, in the experiments, the hidden data can be exactly
6.3 Lossless Information Hiding in JPEG2000 Images
397

extracted and the PSNR between the recovered image and the original image is inﬁn-
ite, which means that the cover image can be totally restored.
Next, we compare our scheme with the scheme proposed by Ohyama et al. [35].
The results of the comparison are shown in Table 6.13. From the table we can see
that our scheme can embed more secret data bits for the same image.
Then we further compare our scheme with the scheme proposed by Chen et al.
[36]. The results of the comparison with their scheme are shown in Table 6.14
Table 6.11 The Relationship Between Block Size and Embedding Capacity
Image
Capacity (bit) (Block
Size [ 8 3 8)
Capacity (bit) (Block
Size [ 16 3 16)
Capacity (bit) (Block
Size [ 32 3 32)
Lena
95,172
82,052
77,288
Barbaba
79,662
67,084
61,948
Boat
66,824
53,788
48,454
Goldhill
68,246
55,038
49,632
Bridge
53,118
40,494
35,632
FIGURE 6.45
Five test images. (a) Lena, (b) Barbara, (c) Boat, (d) Goldhill, (e) Bridge.
398
CHAPTER 6 Lossless Information Hiding

Compared with their scheme, we can see that our scheme has higher PSNR value
after embedding equivalent amounts of data into the same image. It proves that
our scheme has better invisibility of hidden data.
6.4 SUMMARY
This chapter focuses on the lossless information hiding in JPEG and JPEG2000
images.
For JPEG images, seven typical methods including two schemes from the authors
were introduced. For the ﬁrst ﬁve schemes, we introduced the basic ideas, whereas
for the schemes from the authors, we provided a detailed introduced detail with
experimental results. In the ﬁrst method of ours, our high-capacity reversible
JPEG-to-JPEG data hiding scheme is introduced. Through lowering certain
Table 6.13 The Results of the Comparison
Image
Embedded Secret Data Bits
of Our Scheme (bit)
Embedded Secret Data Bits
of Reference [35] (bit)
Lena
95,172
11,814
Barbaba
79,662
4198
Bridge
53,118
9502
Table 6.14 The Comparison of PSNR
Image
Embedded Bits (bit)
PSNR of Our Scheme (dB)
PSNR of Ref. [36] (dB)
Lena
1024
66.03
45.23
Boat
1024
62.76
44.80
Goldhill
1024
65.83
43.90
PSNR, peak-signal-to-noise ratio.
Table 6.12 PSNR Values After Embedding Different Amounts of Data
Image
PSNR (dB) (0.5 KB)
PSNR (dB) (1.0 KB)
PSNR (dB) (1.5 KB)
Lena
59.05
55.59
53.67
Barbaba
57.96
55.16
53.19
Boat
56.39
53.36
51.92
Goldhill
58.65
54.56
52.44
Bridge
55.62
53.07
51.59
PSNR, peak-signal-to-noise ratio.
6.4 Summary
399

quantization table entries and lifting corresponding quantized DCT coefﬁcients,
space is made for embedding data. Using the proposed embedding strategy, our
scheme can achieve high embedding capacity and keep the distortion introduced
by embedding very low; meanwhile the original cover JPEG image can be restored
after the secret data are extracted. Experiments results demonstrate that the proposed
scheme maintains the image quality of a stego JPEG image when the embedding ca-
pacity is high. Besides, the ﬁle size after embedding with not too huge data is accept-
able. Compared with Chang et al.’s method and Xuan et al.’s method, the proposed
method is superior in terms of the image quality, hiding capacity, and ﬁle size. Our
scheme is very practical for image ﬁles stored and transmitted in the JPEG format. In
the second method of ours, a lossless data hiding scheme with ﬁle size preservation
is proposed. Through analyzing the code space and the statistics of both used and
unused VLCs, we ﬁnd there is still potential free space in the JPEG bitstream that
can be explored to hide data. The best of unused VLCs are made and mapped to
the used VLCs in speciﬁc mapping manners. The proposed scheme embeds data
into the VLC codes and whatever mapped VLCs are present are not changed, there-
fore the image content after data hiding is exactly the same as the original one.
Experimental results demonstrate that the proposed scheme can reach better perfor-
mance irrespective of whether ﬁle size preservation is required or not.
For JPEG2000 images, we ﬁrst introduced two schemes from the literature, and
then introduce our scheme. In our scheme, high-frequency subbands of the cover im-
age are divided into blocks. In each block, a new histogram shifting method is
applied to the histogram of the block for embedding data. Every coefﬁcient that is
associated with the peak point embeds 2 bits of data. In addition, we shift the histo-
gram to the left or right adaptively according to a direction sign. Experimental
results show that the proposed scheme has high embedding capacity and good invis-
ibility of hidden data.
REFERENCES
[1] ISO/JEC FCD 15444-1, JPEG2000 Part 1, Final Committee Draft Version1.0, 2000.
[2] ISO/JEC FCD 15444-2, JPEG2000 Part 2, Final Committee Draft, 2000.
[3] G.K. Wallace, The JPEG still picture compression standard, Communications of the
ACM 34 (4) (1991) 30e44.
[4] International Telecommunication Union, CCITT Recommendation T.81, Information
Technology- Digital Compression and Coding of Continuous-Tone Still Images-
Requirements and Guidelines, 1992.
[5] J. Huang, Y.Q. Shi, Y. Shi, Embedding image watermarks in DC components, IEEE
Transactions on Circuits and Systems for Video Technology 10 (6) (2000) 974e979.
[6] B.G. Mobasseri, R.J. Berger, M.P. Marcinak, Y.J. NaikRaikar, Data embedding in JPEG
bitstream by code mapping, IEEE Transactions on Image Processing 19 (4) (2010)
958e966.
[7] D. Upham, JPEG-JSteg, 1997. http://www.funet.ﬁ/pub/crypt/steganography/jpeg-jsteg-
v4.diff.gz.
400
CHAPTER 6 Lossless Information Hiding

[8] A. Westfeld, F5-a steganographic algorithm: high capacity despite better steganalysis,
in: Proceedings of the 4th International Workshop on Information Hiding, Pittsburgh,
PA, USA, 2001, pp. 289e302.
[9] J. Fridrich, M. Goljan, R. Du, Invertible authentication watermark for JPEG images, in:
Proceedings of IEEE International Conference on Information Technology: Coding and
Computing, Las Vegas, Nevada, USA, 2001, pp. 223e227.
[10] J. Fridrich, M. Goljan, R. Du, Lossless data embedding for all image formats, in: Pro-
ceedings of SPIE, Electronic Imaging 2002, Security and Watermarking of Multimedia
Contents IV, San Jose, California, vol. 4675, 2002, pp. 572e583.
[11] C.C. Chang, T.S. Chen, L.Z. Chung, A steganographic method based upon JPEG and
quantization table modiﬁcation, Information Sciences 141 (1e2) (2002) 123e138.
[12] M. Iwata, K. Miyake, A. Shiozaki, Digital steganography utilizing features of JPEG
images, IEICE Transactions on Fundamentals of Electronics, Communications and
Computer Sciences E87-A (4) (2004) 929e936.
[13] C.C. Chang, C.C. Lin, C.S. Tseng, W.L. Tai, Reversible hiding in DCT-based com-
pressed images, Information Sciences 177 (13) (2007) 2768e2786.
[14] G.R. Xuan, Y.Q. Shi, Z.C. Ni, P.Q. Chai, X. Cui, X.F. Tong, Reversible data hiding for
JPEG images based on histogram pairs, in: Proceedings of International Conference on
Image Analysis and Recognition, Montreal, Canada, 2007, pp. 715e727.
[15] H. Sakai, M. Kuribayashi, M. Morii, Adaptive reversible data hiding for JPEG images,
in: Proceedings of International Symposium on Information Theory and Its Applica-
tions, Auckland, New Zealand, 2008, pp. 1e6.
[16] A. Almohammad, G. Ghinea, R.M. Hierons, JPEG steganography: a performance eval-
uation of quantization tables, in: Proceedings of IEEE International Conference on
Advanced Information Networking and Applications, Bradford, United Kingdom,
2009, pp. 471e478.
[17] Z. Cheng, K.Y. Yoo, A reversible JPEG-to-JPEG data hiding technique, in: Proceedings
of 2009 Fourth International Conference on Innovative Computing, Information and
Control, Kaohsiung, Taiwan, 2009, pp. 635e638.
[18] X. Zhang, S. Wang, Z. Qian, G. Feng, Reversible fragile watermarking for locating
tampered blocks in JPEG images, Signal Processing 90 (12) (2010) 3026e3036.
[19] P. Lin, C. Chan, Invertible secret image sharing with steganography, Pattern Recogni-
tion Letters 31 (13) (2010) 1887e1893.
[20] J. Fridrich, M. Goljan, Q. Chen, V. Pathak, Lossless data embedding with ﬁle size
preservation, in: Proceedings of SPIE, Security and Watermarking of Multimedia Con-
tents VI, San Jose, California, vol. 5306, 2004, pp. 354e365.
[21] Z. Qian, X. Zhang, Lossless data hiding in JPEG bitstream, The Journal of Systems and
Software 85 (2) (2012) 309e313.
[22] K. Wang, Z.M. Lu, Y.J. Hu, A high capacity lossless data hiding scheme for JPEG
images, Journal of Systems and Software 86 (7) (2013) 1965e1975.
[23] Y.J. Hu, K. Wang, Z.M. Lu, An improved VLC-based lossless data hiding scheme for
JPEG images, Journal of Systems and Software 86 (8) (2013) 2166e2173.
[24] Z. Ni, Y.Q. Shi, N. Ansari, W. Su, Reversible data hiding, in: Proceedings of 2003 In-
ternational Symposium on Circuits and Systems, Bangkok, Thailand, vol. 2, 2003, pp.
912e915.
[25] A. Leest, M. Veen, F. Bruekers, Reversible image watermarking, in: Proceedings of
2003 International Conference on Image Processing, vol. 2, 2003, pp. 731e734.
References
401

[26] J. Tian, Reversible data embedding using a difference expansion, IEEE Transactions on
Circuits and Systems for Video Technology 13 (8) (2003) 890e896.
[27] H.T. Wu, J.L. Dugelay, Y.Q. Shi, Reversible image data hiding with contrast
enhancement, IEEE Signal Processing Letters 22 (1) (2015) 81e85.
[28] H. Luo, F.X. Yu, Z.L. Huang, H. Chen, Z.M. Lu, Reversible data hiding based on hybrid
prediction and interleaving histogram modiﬁcation with single seed pixel recovery,
Signal, Image and Video Processing 8 (1) (2014) 813e818.
[29] S.H. Shin, J.C. Jeon, Lossless data hiding technique using reversible function, Interna-
tional Journal of Security and Its Application 8 (1) (2014) 389e400.
[30] B. Yang, M. Schmucker, W. Funk, C. Busch, S. Sun, Integer DCT-based reversible
watermarking for image using companding technique, Proceedings of the SPIE 5306
(2004) 405e415.
[31] D.H. Chu, Z.M. Lu, J.X. Wang, A high capacity reversible information hiding algorithm
based on difference coding of VQ indices, ICIC Express Letters, Part B: Applications
3 (4) (2012) 701e706.
[32] D.N. Zhao, W.X. Xie, Z.M. Lu, High efﬁciency reversible data hiding for two-stage vec-
tor quantization compressed images, Journal of Information Hiding and Multimedia
Signal Processing 5 (4) (2014) 625e641.
[33] C.H. Li, Z.M. Lu, Y.X. Su, Reversible data hiding for BTC-compressed images based
on bitplane ﬂipping and histogram shifting of mean tables, Information Technology
Journal 10 (3) (2013) 1421e1426.
[34] S.W. Jung, Adaptive post-ﬁltering of JPEG compressed images considering compressed
domain lossless data hiding, Information Sciences 281 (2014) 355e364.
[35] S. Ohyama, M. Niimi, K. Yamawaki, H. Noda, Lossless data hiding using bit-depth
embedding for JPEG2000 compressed bit-stream, in: International Conference on Intel-
ligent Information Hiding and Multimedia Signal Processing, 2008, pp. 151e154.
[36] T.S. Chen, J. Chen, J.G. Chen, A simple and efﬁcient watermarking technique based on
JPEG2000 codec, Multimedia Systems 10 (1) (2004) 16e26.
[37] S. Tanaka, M. Niimi, H. Noda, A study on reversible information hiding using
complexity measure for binary images, in: Proceedings of Intelligent Information Hid-
ing and Multimedia Signal Processing, vol. II, 2007, pp. 29e32.
402
CHAPTER 6 Lossless Information Hiding

Index
‘Note: Page numbers followed by “f” indicate ﬁgures, “t” indicate tables.’
A
Absolute moment block truncation coding
(AMBTC), 31e32, 33f, 281,
281fe282f
compression stage, 311, 318f
Adaptive coefﬁcient modiﬁcation
experimental results and performance analysis,
184e189
algorithm complexity, 188
algorithm security, 188e189
performance scalability, 188
performance stability, 188
watermarking capacity vs. distortion,
185e188
GCDS, 179e181
LFCP, 182e184
lossless information hiding by, 179e189
ZTDCT, 181e182
Adaptive dictionary algorithms, 28
Adaptive steganography, 49
Additional information (AI), 74
Adjacent pixel difference (APD), 80
AI. See Additional information (AI)
Alatter’s scheme, 76e79
Algorithm. See also Fast algorithm
adaptive dictionary, 28
BTC, 279e280
complexity, 188
correlation-based, 214f
F5 algorithm, 339
security, 188e189
watermarking, 209e210
AMBTC. See Absolute moment block truncation
coding (AMBTC)
Analog image, 1
processing, 5
Annotation, 26
Anonymous communication, 21e22
APD. See Adjacent pixel difference (APD)
Asymmetric information hiding, 15
Audit, 9e10
Authentication
mark, 25e26
mechanism, 9e10, 71
watermark embedding, 44
extraction and veriﬁcation, 44
Author right. See Copyright
B
Baseline method, 333
Basic VQ (BVQ), 212e213
lossless information hiding for, 213e214
Bijection, 143e144, 144f
Bilevel. See Binary images
Binary images, 3e4, 3f
reversible information hiding for, 391e392
Bit string structure, 326f
Bit-depth embeddingebased scheme, 390e394
experimental results, 393e394, 393t
reversible information hiding
for binary images, 391e392
for JPEG2000 images, 392e393
Bit-shift-based reversible watermarking tech-
nique, 159e160
Bitmap format (BMP), 48
Bitplane ﬂippingebased lossless hiding schemes,
290e297
bitplane ﬂippingebased scheme with histogram
shifting, 292e297
absolute moment block truncation coding
compression stage, 293
data hiding stage, 293e294
decoding and extracting stage, 294
experimental results and discussion, 295e297
improved bitplane ﬂippingebased scheme, 292
original bitplane ﬂippingebased scheme,
291e292
Bitplanes (BP), 320
color BTC, 320e321
bits per pixel (bpp), 55e56, 57f, 76, 185e186,
221, 279
Block truncation coding (BTC), 31e32, 129e130,
279, 280f
algorithm, 279e280
AMBTC, 281e282, 281fe282f
bitplane ﬂippingebased lossless hiding schemes,
290e297
BTCebased information hiding, 282e290
BTCebased image watermarking, 282e290
BTCebased lossless information hiding,
290
compression technique, 131e132
lossless data hiding in, 319e328
mean codingebased lossless hiding schemes,
297e319
403

Block-based encoding method, 207e208
Blockwise codingebased scheme, 310e319,
324e328, 325t. See also Histogram
modiﬁcationebased schemes
AMBTC compression stage, 311
data embedding process, 325e326
data extraction process, 327e328
data hiding and mean table coding stage,
311e313, 312t
decoding and extracting stage, 313e316, 315f
experimental results, 316e319, 316te317t, 328,
328t
BMP. See Bitmap format (BMP)
BP. See Bitplanes (BP)
bpp. See bits per pixel (bpp)
Broadcast monitoring, 24
BTC. See Block truncation coding (BTC)
BVQ. See Basic VQ (BVQ)
C
Capacity, 40
estimation, 90
CDF(2,2) wavelet, 189, 194
CH sets. See Changeable sets (CH sets)
Chameleon method, 47
Chang and Lu’s scheme, 222e232, 222f. See also
ChangeTaieLin’s scheme
embedding phase, 222e226
experimental results, 226e232
Chang and Wu’s and Chang and Lu’s scheme
comparison, 232t
compression rate, 228f
execution time, 231t
hiding capacity, 229f
image quality, 228fe229f
performance, 230t
state codebook, 225t
stego images and recovered images, 229f
test images, 227f
extraction phase, 226
Chang and Wu’s scheme, 221, 232t, 237t
Changeable sets (CH sets), 75
ChangeTaieLin’s scheme, 232e238. See also
Chang and Lu’s scheme
experimental results, 235e238
ChangeTaieLin’s and Chang and Wu’s
scheme comparison, 237t
hiding results, 236t
PSNRs for SMVQ-compressed cover image, 235t
extracting and reversing phases, 234e235
hiding phase, 233e234
preprocessing phase, 233
Chroma subsampling, 29
Chuang and Chang’s scheme, 283, 311f. See also
Yang and Lu’s Method 2; Zhang et al.’s
Method
Codebook, 207e208, 217e218
N-sized, 214
in SMVQ, 219e220
watermarking algorithms based on codebook
partition, 209e210
Codestream decoding process, 253e254
Coding, 37e38
Coefﬁcients’ magnitude prediction technique,
193e195. See also Value expansion
technique
spaceefrequency zero-tree structure, 194f
Color component transformation, 35e36
Color images, 3e4, 3f
BTC compression
common BP color BTC, 320e321
traditional color BTC, 320
lossless data hiding in BTCecompressed,
319e328
blockwise codingebased scheme, 324e328
difference expansionebased scheme, 321e324
Color space reduction, 29
Communication-based models, 18e19, 19f
Companding technique
companding error, 192e193
IntDCTebased lossless information hiding
scheme, 157e172
basic embedding and extracting processes,
162
bit-shift-based reversible watermarking
technique, 159e160
distribution of 8  8 DCT coefﬁcients, 157e158
error estimation, 163e165
improved embedding and extracting processes,
169e170
IntDCT and left and right invertible mapping,
160e162
simulation results, 170e172, 171t
twice-try structures for block discrimination,
165e169
watermarked Lena image and original Lena
comparison, 160f
integer DWT domain coefﬁcient, 195e197
Compressed domain, 23, 386
compressed domainebased schemes, 386
JPEG-compressed domain, 353e354
lossless information hiding in
basic framework of, 205
requirements of, 205e207
404
Index

Compression
error, 192e193
function for value expansion, 191e192
integer DWT domain coefﬁcient compression
scheme, 195e197
Computer(s), 7e8
graphics, 5
image analysis, 7e8
vision, 5
Conﬁdentiality, 8e9
Content authentication, 25e26
Contrast sensitivity function (CSF), 117e118
Controllability, 8e9
Copy control, 26
Copyright, 9
marking, 20e21
Correlation-based algorithms, 214f
Cover media
ﬁdelity control, 59e60
status recovery, 60e62
Cover object, 14e15, 22
Cover signal, 39
Covert channel, 21
Covert communication, 24
Cryptography, 8, 13e14
CSF. See Contrast sensitivity function (CSF)
D
Data
acquisition process, 6
compression, 27
embedding, 83e84, 87e88, 87f, 89f, 98e99,
128f, 325e326, 350e351, 395e396, 395f
and extracting procedures, 375e377
extraction, 116, 116f, 129f, 327e328, 351
image recovery, 85e89, 88f, 90f, 99e101
and image restoring phase, 298e299
and original image restoration, 396e397
Data hiding. See also Information hiding
and mean table coding stage, 311e313, 312t
phase, 298, 357e361, 358f
proposed scheme, 120e128, 121f
decoding stage, 124e127
encoding stage, 121e124
example, 127e128
in reversible secret sharing, 120e129
experimental results, 128e129
related work, 120
DCT. See Discrete cosine transform (DCT)
DCT coefﬁcientsebased scheme, 353e370
data hiding phase, 357e361, 358f
embedding sequence for 16  16 JPEG image,
360f
experimental results, 363e370
capacity for Lena image, 366t
comparisons between method and former
methods, 368e370
performance of algorithm, 363e368
PSNRs testing on Lena image, 364te365t,
366f
stego image quality with QF, 369f
extraction and restoration phase, 361e363
modifying quantization tables, 359f
selection of embedding positions, 353e356
DE technique. See Difference expansion tech-
nique (DE technique)
Decoder, 346
Decoding and extraction
process, 305e306
stage, 313e316, 315f
Deﬁne Huffman Table (DHT), 336
Deﬁne Quantization Table (DQT), 334e335
Deﬂation, 29
Device control, 26
DFT. See Discrete Fourier transform (DFT)
DHT. See Deﬁne Huffman Table (DHT)
Difference codingebased scheme, 257e260
experimental results, 260
extracting process, 259
hiding process, 257e259
Difference expansion technique (DE technique),
52e53, 69, 319e322
Difference expansionebased scheme. See also
Prediction-error expansion based algo-
rithm (PEE algorithm)
Alatter’s scheme, 76e79
experimental results, 323e324, 323f, 324t
proposed scheme, 322e323
Tian’s scheme, 73e76, 75t
Differential pulse-code modulation (DPCM), 28,
343e344
Digital images, 2e4
analysis, 7
processing, 5, 7
Digital right management systems (DRMS), 11
Digital signature, 25e26
image authentication schemes, 12
Digital watermarking, 9e10
image authentication schemes, 12
schemes, 209
Digitization, 2e3
Discrete cosine transform
Index
405

Discrete cosine transform (DCT), 23, 145, 209,
333
DCTebased information hiding, 147e148
IntDCT vs., 156e157
Discrete Fourier transform (DFT), 148
DFTebased information hiding, 148e149
Discrete wavelet transform (DWT), 23, 145,
336e337
DWTebased information hiding, 149e150
DPCM. See Differential pulse-code modulation
(DPCM)
DQT. See Deﬁne Quantization Table (DQT)
DRMS. See Digital right management systems
(DRMS)
DWT. See Discrete wavelet transform (DWT)
E
EBCOT scheme. See Embedded Block Coding
with Optimal Truncation scheme (EBCOT
scheme)
8  8 DCT coefﬁcients
coefﬁcient grouping, 174f
DC and AC coefﬁcient groups distribution shape,
158f
distribution, 157e158
grouping, 158f
histogram modiﬁcation, 175f
EL. See Embedding level (EL)
Embedded Block Coding with Optimal Truncation
scheme (EBCOT scheme), 37
Embedding, 71, 72f, 79, 114e115, 115f, 162,
162f, 303e305, 305f, 392e393
algorithm, 14e15
CS combination, 304
CSH and CSL encoding, 304
DH and DL encoding, 304
difference calculation, 303
domains, 23
efﬁciency, 319
embedded object, 14e15
embedding positions, selection of, 353e356
improved processes, 169e170
lossless data, 350f
pairs, 345e346
twice-try-based block discrimination structure
for, 167f
watermark, 387e390
embedding value 0, 388e389
embedding value 1, 389e390
Yang et al.’s scheme, 169f
Embedding level (EL), 83e84, 84fe85f
Encoder, 346
End of ﬁle tag (EOF tag), 48
Entropy
coding, 335e336
encoding, 28
EOF tag. See End of ﬁle tag (EOF tag)
Error estimation, 163e165, 163f
Extracting/extraction, 162, 162f, 283
algorithm, 14e15
improved processes, 169e170
lossless data, 350f
and restoration phase, 361e363, 362f
twice-try-based block discrimination structure
for, 168f
Yang et al.’s scheme, 170f
F
Fast algorithm
for inverse 2D-IntDCT, 155e156
one-dimensional IntDCT, 151e153
two-dimensional IntDCT, 154e156
Fast correlationebased VQ (FCVQ), 212e213.
See also Side match VQ (SMVQ)
FCVQebased image compression, 214e215
decoding process, 215
encoding process, 214
Fast Fourier transform (FFT), 23
FCVQ. See Fast correlationebased VQ (FCVQ)
FDCT. See Forward discrete cosine transform
(FDCT)
FDWT. See Forward discrete wavelet transform
(FDWT)
Feature’s expansion position, 347e348
Feature’s original position, 347e348
FFT. See Fast Fourier transform (FFT)
Fidelity control for cover media, 59e60
visual quality scalable reﬁnement of TV program,
61f
File size preservation. See Fridrich et al.’s lossless
embedding method
Fingerprinting, 46
differences with watermarking, 46
Forward discrete cosine transform (FDCT),
333e334, 333f
lossless embedding in JPEG ﬁles, 343f
Forward discrete wavelet transform (FDWT),
336e337
Fourier-related transform, 29
Fractal compression, 30
Fragile image watermarking. See also Robust
image watermarking
background, 43
classiﬁcation, 43
406
Index

fragile watermarks, 12
requirements, 43
techniques, 44e45
watermarking-based authentication system, 44
Frequency domain methods, 6
Fridrich et al.’s invertible watermarking methods,
340e343
method 1, 340e342
algorithm for integrity veriﬁcation process, 342
algorithm for lossless authentication of JPEG
ﬁles, 341e342
method 2, 342e343
Fridrich et al.’s lossless embedding method,
343e346
JPEG entropy coder, 344
lossless embedding with ﬁle size preservation,
345e346
decoder, 346
encoder, 346
run length encoding of AC coefﬁcients, 344e345
G
G-LSB. See Generalized least signiﬁcant bit
(G-LSB)
GA. See Genetic algorithm (GA)
GCDS. See Global coefﬁcient-group distortion
sorting (GCDS)
General model, 17e18, 18f
Generalized, reversible, integer transform
(GRIT), 76
Generalized least signiﬁcant bit (G-LSB), 69
embedding, 107e108, 108f
Generalized Lloyd algorithm, 207e208
Generalized lossless compressionebased scheme
and value expansionebased scheme
comparisons, 195e197
generalized least signiﬁcant bit lossless
compression scheme, 195
integer DWT domain
coefﬁcient companding and compression
scheme, 195e197
histogram shift scheme, 197
lossless bit-plane compression scheme, 195
performance
of histogram shifting, 199t
of method, 198t
reversible watermarking algorithms, 200f
Genetic algorithm (GA), 319e320
GIF ﬁles. See Graphics interchange format ﬁles
(GIF ﬁles)
Global coefﬁcient-group distortion sorting
(GCDS), 179e181
Graphics interchange format ﬁles (GIF ﬁles), 2
Grayscale images, 3e4, 3fe4f
GRIT. See Generalized, reversible, integer trans-
form (GRIT)
H
Hiding algorithm. See also Fast algorithm
data embedding, 350e351
data extraction, 351
formulae of lossless data hiding, 351e352
Hiding capacity, 16
Hiding scheme, 302e306. See also Bitplane
ﬂippingebased lossless hiding schemes
decoding and extraction process, 305e306
embedding process, 303e305
Hierarchical mode, 32
Histogram bins, 94f
Histogram expansion, 347e348
Histogram modiﬁcationebased schemes,
81fe82f. See also Blockwise codinge
based scheme
APDebased scheme, 80e82
histogram shiftingebased scheme, 80
hybrid prediction and interleaving, 93e101
data embedding, 98e99
data extraction and image recovery,
99e101
experimental results and comparisons, 101,
102f, 103t
multilevel, 82e93
Histogram pair, 347e348
formulae of lossless data hiding, 351e352
Histogram shifting, 172e179
bitplane ﬂippingebased scheme with,
292e297
absolute moment block truncation coding
compression stage, 293
data hiding stage, 293e294
decoding and extracting stage, 294
experimental results and discussion, 295e297
experimental results, 177e179, 178t
histogram shiftingebased scheme, 80
reversible information hiding, 394e395
data embedding, 395e396, 395f
data extraction and original image restoration,
396e397
experimental results, 397e399
Yang et al.’s scheme, 173e176
Histogram-based methods, 70
Human perceptual system, 147, 150
Human visual system characteristics
(HVS characteristics), 110e112
Index
407

Hybrid prediction
and interleaving histogram modiﬁcationebased
schemes, 93e101
data embedding, 98e99
data extraction and image recovery, 99e101
experimental results and comparisons, 101,
102f, 103t
I
ICT. See Irreversible component transform (ICT)
IDCT. See Inverse discrete cosine transform
(IDCT)
IEC. See International Electrotechnical Commis-
sion (IEC)
IJG. See Independent JPEG Group (IJG)
IJNC. See Improved JNC (IJNC)
Image authentication
Fridrich et al.’s invertible watermarking methods
for, 340e343
method 1, 340e342
algorithm for integrity veriﬁcation process, 342
algorithm for lossless authentication of JPEG
ﬁles, 341e342
method 2, 342e343
Image ﬁngerprinting
background and concept, 45e46
differences between watermarking and ﬁnger-
printing, 46
requirements, 46
techniques, 46e47
Image watermarking
BTCebased, 282e290
Chuang and Chang’s scheme, 283
Yang and Lu’s Method 1, 283e284
Yang and Lu’s Method 2, 284e287
Zhang et al.’s Method, 287e290
system, 39e40
VQebased, 209e211
algorithms based on codebook partition,
209e210
algorithms based on index properties, 210e211
Image(s), 1e2
analysis, 7e8
authentication, 11e12
coding and compression techniques
BTC, 31e32
JPEG, 32e35, 33f
JPEG2000, 35e38
lossless image coding techniques, 27e29
lossy image coding techniques, 29e30
source coding and data compression, 27
VQ, 30e31, 31f
digital, 2e4
information hiding techniques, 38e57
fragile image watermarking, 43e45
image ﬁngerprinting, 45e47
image steganography, 47e49
lossless information hiding in images, 50e57
robust image watermarking, 38e42
network information security, 8e10
preprocessing, 336e337
processing in broad sense, 4e5
processing in narrow sense, 6e7
compression, 6e7
enhancement, 6
restoration, 6
protection, 10e11
tiling, 336e337
Imperceptibility, 40
Improved JNC (IJNC), 211e212
IJNCebased scheme, 261e268
decoding and extracting stage, 263e265
experimental results, 266e268
information hiding and index coding stage,
262e263
VQ encoding stage, 261e262
In-network ﬁngerprinting, 47
Independent JPEG Group (IJG), 334e335
Information
embedding, 14e15
encryption and hiding mechanism, 9e10
network, 8
security protection methods, 9e10
Information hiding, 12e26. See also Data hiding
applications, 24e26
annotation, 26
broadcast monitoring, 24
content authentication, 25e26
copy control, 26
covert communication, 24
device control, 26
owner identiﬁcation, 25
ownership veriﬁcation, 25
transaction tracking, 25
classiﬁcation, 22e24
embedding domains, 23
symmetry of keys, 22e23
types of cover object, 22
ways, 23e24
concepts, 13e15
for images, 38e57
models, 17e19
communication-based, 18e19, 19f
general, 17e18, 18f
408
Index

prisoner’s, 17, 18f
properties and requirements, 15e17
research branches of information hiding, 19e22,
20f
anonymous communication, 21e22
copyright marking, 20e21
covert channel, 21
steganography, 19e20
subliminal channel, 21
VQebased, 208e212
image watermarking, 209e211
lossless information hiding, 209e210
Injection, 143e144, 144f
Integer discrete cosine transform (IntDCT), 146.
See also Transform domains
DCT vs., 156e157
fast algorithm for, 153
histogram shift technique, 172e179
IntDCTebased lossless information hiding
scheme, 157e172
basic embedding and extracting processes, 162
bit-shift-based reversible watermarking
technique, 159e160
distribution of 8  8 DCT coefﬁcients,
157e158
error estimation, 163e165
improved embedding and extracting processes,
169e170
IntDCT and left and right invertible mapping,
160e162
simulation results, 170e172, 171t
twice-try structures for block discrimination,
165e169
watermarked Lena image and original Lena
comparison, 160f
lifting step, 156f
lossless information hiding by adaptive coefﬁ-
cient modiﬁcation in, 179e189
one-dimensional IntDCT and fast algorithm,
151e153
two-dimensional IntDCT and fast algorithm,
154e156
Integer discrete wavelet transform (Integer DWT),
146
domain coefﬁcient companding and compression
scheme, 195e197
domain histogram shift scheme, 197
domain lossless bit-plane compression scheme,
195
Integer Haar wavelet transform, 321
Integer transforms, reversible information hiding
to, 145e146
Integer wavelet transform domain, 193e195
Integer wavelet transformebased schemes,
189e197
lossless compressionebased and value
expansionebased scheme comparisons,
195e197
value expansion technique in, 190e193
Integrity, 8e9
algorithm for integrity veriﬁcation process, 342
protection, 9e10
International Electrotechnical Commission
(IEC), 32
International Organization for Standardization
(ISO), 32
International Telecommunication Union (ITU), 32
Inverse 2D-IntDCT, fast algorithm for, 155e156
Inverse discrete cosine transform (IDCT),
333e334, 336f
Invertible mapping, 143e144
functions, 143
injection, surjection, and bijection, 143e144
left and right inverses, 144
Invisibility, 43
Irreversible component transform (ICT), 336e337
Irreversible watermarking scheme, Chen et al.’s,
386e390
coefﬁcient after normalization, 387f
embedding watermark, 387e390
watermark extraction process, 390
ISO. See International Organization for Stan-
dardization (ISO)
ITU. See International Telecommunication Union
(ITU)
J
JBIG
algorithm, 78e79
JBIG2 compression, 74e75
JBIG2 decoder, 75
JNC. See Joint neighboring coding (JNC)
Joint BTC and secret sharing, 134e135
Joint data encryption and data hiding model,
132e133, 133f
Joint modiﬁcation of quantization table, 353e370
data hiding phase, 357e361, 358f
embedding sequence for 16  16 JPEG image,
360f
experimental results, 363e370
capacity for Lena image, 366t
comparisons between method and former
methods, 368e370
performance of algorithm, 363e368
Index
409

Joint modiﬁcation of quantization table (Continued)
PSNRs testing on Lena image, 364te365t,
366f
stego image quality with QF, 369f
extraction and restoration phase, 361e363, 362f
modifying quantization tables, 359f
selection of embedding positions, 353e356
Joint neighboring coding (JNC), 211e212,
238e239, 301e302. See also Block trun-
cation coding (BTC); VQeindex residual
value coding (VQIRVC)
JNCebased scheme, 238e242
embedding process, 239e241, 241t
extracting process, 241e242
JNCebased scheme
experimental results, 306e310, 306f
hiding scheme, 302e306
Joint Photographic Experts Group (JPEG), 2,
32e35, 33f, 333e336
bitstream structure, 337f
challenges, 338
compression, 209e210
encoder, 333f
entropy coder, 344
lossless information hiding in, 339e384
DCT coefﬁcientsebased scheme, 353e370
Fridrich et al.’s invertible watermarking
method, 340e343
Fridrich et al.’s lossless embedding method,
343e346
information hiding in, 339e340
joint modiﬁcation of quantization table,
353e370
Qian and Zhang’s scheme, 352e353
variable length code mappingebased scheme,
370e384
Xuan et al.’s histogram pairebased lossless
data embedding scheme, 346e352
standard quantization table, 334f
zigzag reordering matrix, 35f
zigzag sequence, 335f
Joint secret sharing and data hiding for BTC-
compressed images, 129e137
discussions, 137
experimental results, 135e137,
135fe136f
joint BTC and secret sharing, 134e135
joint data encryption and data hiding model,
132e133, 133f
related work, 131e132
JPEG. See Joint Photographic Experts Group
(JPEG)
JPEG2000, 35e38, 336e337
challenges, 338
coding, 37e38
color component transformation, 35e36
decoder, 336f
JPEG2000 codec, 337f, 384e385, 385f
lossless information hiding in, 384e399
bit-depth embeddingebased scheme, 390e394
Chen et al.’s irreversible watermarking scheme,
386e390
reversible information hiding based on histo-
gram shifting for, 394e399
subband structure, 385f
quantization, 36e37
subband structure, 338f
tiling, 36
wavelet transform, 36
K
Kundur’s scheme, 150
L
Lagrange multiplier method, 37e38
Least signiﬁcant bit (LSB), 44, 69e70, 282e283, 339
Left and right inverses, 144
Left and right invertible mapping, IntDCT and,
160e162
LFCP. See Low-frequency coefﬁcients-based
prediction (LFCP)
LGLSB. See Lossless generalized least signiﬁcant
bit (LGLSB)
Linguistic steganography, 19e20
Look-up table (LUT), 110
construction, 112e113, 113fe114f
data extraction, 116, 116f
data hiding, 113e114, 114f, 119f
embedding, 114e115, 115f
experimental results, 116e118
HVS characteristics, 110e112
PH, 110, 111f
Lossless
compression, 6e7
algorithms, 27
embedding with ﬁle size preservation, 345e346
hiding authentication, 57e58, 59f
mode, 32
RS-data embedding method, 104e106, 106f
Lossless compressionebased schemes
LGLSB data embedding method, 106e110
G-LSB embedding, 107e108, 108f
LGLSB data embedding and extraction,
108e110, 109f
410
Index

lossless bit-plane compression in spatial domain,
102e103
lossless RS-data embedding method, 104e106,
106f
Lossless data hiding
BTC compression for color images
common BP color BTC, 320e321
traditional color BTC, 320
in BTCecompressed color images, 319e328
blockwise codingebased scheme, 324e328
difference expansionebased scheme, 321e324
formulae, 351e352
Lossless generalized least signiﬁcant bit
(LGLSB), 109e110
data embedding method, 106e110
and extraction, 108e110, 109f
G-LSB embedding, 107e108, 108f
Lossless image coding techniques, 27e29
adaptive dictionary algorithms, 28
deﬂation, 29
DPCM and predictive coding, 28
entropy encoding, 28
RLE, 28
Lossless information hiding. See also Reversible
information hiding
by adaptive coefﬁcient modiﬁcation,
179e189
experimental results and performance analysis,
184e189
GCDS, 179e181
LFCP, 182e184
ZTDCT, 181e182
applications, 57e62
ﬁdelity control for cover media, 59e60
lossless hiding authentication, 57e58, 59f
status recovery for cover media, 60e62
background and concepts, 50e52
BTCebased, 290
for BVQ, 213e214
classiﬁcations, 52e53
in compressed domain
framework, 205
requirements, 205e207
in images, 52f
IntDCTebased lossless information hiding
scheme, 157e172
basic embedding and extracting processes, 162
bit-shift-based reversible watermarking tech-
nique, 159e160
distribution of 8  8 DCT coefﬁcients,
157e158
error estimation, 163e165
improved embedding and extracting processes,
169e170
IntDCT and left and right invertible mapping,
160e162
simulation results, 170e172, 171t
twice-try structures for block discrimination,
165e169
watermarked Lena image and original Lena
comparison, 160f
in JPEG images, 339e384
in JPEG2000 images, 384e399
MFCVQebased lossless information hiding,
215e218
performance evaluation criteria, 55e57
research on, 70
techniques, 53e55
for two-stage VQ compressed images, 269e276,
270f, 273f
data embedding process, 270e273
decoding and extraction process, 273e274
experimental results, 274e276
preprocessing stage, 269e270
VQebased lossless information hiding, 209e210
Lossy compression methods, 6e7
Lossy data compression, 27
Lossy image coding techniques, 29e30
chroma subsampling, 29
color space reduction, 29
fractal compression, 30
transform coding, 29
Low-frequency coefﬁcients-based prediction
(LFCP), 182e184, 187
LSB. See Least signiﬁcant bit (LSB)
LUT. See Look-up table (LUT)
LZW algorithm, 28e29
M
Many-to-one mapping, 143
Mathematical microscope, 149
Mean codingebased lossless hiding schemes,
297e319
blockwise codingebased scheme, 310e319
JNCebased scheme, 301e310
prediction-error expansionebased scheme,
297e301
data extracting and image restoring phase,
298e299
data hiding phase, 298
experimental results, 299e301
Mean square error (MSE), 37e38
Message integrity code (MIC), 377. See also
Variable length code (VLC)
Index
411

MFCVQ. See Modiﬁed fast correlation VQ
(MFCVQ)
MIC. See Message integrity code (MIC)
Modern warfare, 12e13
Modiﬁed fast correlation VQ (MFCVQ), 211.
See also Side match VQ (SMVQ)
FCVQebased image compression, 214e215
lossless information hiding for BVQ, 213e214
MFCVQebased lossless information hiding,
215e218
decoding process, 215e218
encoding process, 215
MFCVQebased scheme, 212e218
Modulo additionebased scheme, 71e73
authentication process, 71
embedding process, 71, 72f
operation, 71e73
Most signiﬁcant bits (MSBs), 344
MSBs. See Most signiﬁcant bits (MSBs)
MSE. See Mean square error (MSE)
MSVQ. See Multistage vector quantization
(MSVQ)
Multilevel histogram modiﬁcationebased
scheme, 82e93
capacity estimation, 90
data embedding, 83e84
data extraction and image recovery, 85e87
examples, 87e90
experimental results and comparison with other
schemes, 91e93, 92f, 92t
overﬂow and underﬂow prevention, 90e91
Multistage vector quantization (MSVQ), 269,
269f
N
NC values. See Not changeable values (NC values)
Network information security, 8e10
Nonrepudiation, 8e9
Not changeable values (NC values), 74e75
O
Ohyama et al.’s method, 393
One-dimensional IntDCT, 151e153
One-to-one mapping. See Injection
Optimization algorithm, 371e373
Overﬂow prevention, 90e91, 163e165
Owner identiﬁcation, 25
Ownership veriﬁcation, 25
P
Path optional lossless information hiding scheme,
247e257
decoding and extraction phases, 253e254
codestream decoding process, 253e254
secret data extracting process, 254
experimental results, 254e257
Wang and Lu’s, MFCVQ-based and SMVQ-
based scheme comparisons, 256t
hiding phase, 248e253
path 1ebased scheme, 249e252
path 2ebased scheme, 252e253
preprocessing phase, 248
Pattern histogram (PH), 110, 111f
Pattern index (PI), 110
Peak signal-to-noise ratio (PSNR), 36, 74,
211e212, 281, 308f, 353e354
for SMVQ-compressed cover image, 235t
PEE algorithm. See Prediction-error expansion
based algorithm (PEE algorithm)
Performance scalability, 188
Performance stability, 56, 188
PH. See Pattern histogram (PH)
Physical image, 1e2
PI. See Pattern index (PI)
Pixels, 2, 2f
value error estimation scheme, 163f
Portable network graphics (PNG), 29
Power control and access control, 9e10
Prediction-error expansion based algorithm (PEE
algorithm), 184, 297e301. See also Dif-
ference expansionebased scheme
data extracting and image restoring phase,
298e299
data hiding phase, 298
experimental results, 299e301
Predictive coding, 28
Preprocessing, 284
Prisoner’s model, 17
Progressive mode, 32
PSNR. See Peak signal-to-noise ratio (PSNR)
Q
Qian and Zhang’s scheme, 352e353
QIM. See Quantization index modulation (QIM)
Quad, 77, 78fe79f
Quantization, 36e37
Quantization index modulation (QIM), 54,
212e213
R
Raster images, 2
two-dimensional, 2e3
RCT. See Reversible color transform (RCT);
Reversible component transform (RCT)
412
Index

Receiver-side ﬁngerprinting, 47
Reconstruction algorithm for two-dimensional
IntDCT, 155e156
Red, green, and blue (RGB), 2e3
Reference location bits, 325e326
Regions, 1e2
Reversible color transform (RCT), 35e36
Reversible component transform (RCT), 336e337
Reversible information hiding, 50
for binary images, 391e392
on histogram shifting for JPEG2000 images,
394e395
data embedding, 395e396, 395f
data extraction and original image restoration,
396e397
experimental results, 397e399
to integer transforms, 145e146
for JPEG2000 images, 392e393
embedding, 392e393
extraction and recovering original wavelet
coefﬁcients, 393
Reversible scheme, 339
Reversible secret sharingebased schemes,
119e137
data hiding in, 120e129
joint secret sharing and data hiding for
BTC-compressed images, 129e137
Reversible watermarking system, 50, 51f
RGB. See Red, green, and blue (RGB)
RLE. See Run-length encoding (RLE)
Robust image watermarking. See also Fragile
image watermarking
background, 38e39
characteristics, 40e41
deﬁnitions, 39
image watermarking system, 39e40
techniques, 41e42
Robust lossless information hiding approaches,
70
Robustness, 16, 40
Rowecolumn method, 154
Run-length encoding (RLE), 28, 344
AC coefﬁcients, 344e345
amplitude of AC coefﬁcients, 345f
format, 336
S
Scientiﬁc visualization, 5
Second-embedding process, 166e167
Secret data extraction process, 75, 254, 322
Security, 16, 41, 43
analysis, 377
mechanisms. See Information security protection
methods
Self-recoverability, 16
Semifragile watermarks, 12
Sequential modess, 32
Sequential Quantization Strategy (SQS), 54
Shannon’s source coding theorem, 28
Side match VQ (SMVQ), 211, 219e221, 220f.
See also Fast correlationebased VQ
(FCVQ); Modiﬁed fast correlation VQ
(MFCVQ)
Chang and Lu’s scheme, 222e232
Chang and Wu’s scheme, 221
ChangeTaieLin’s scheme, 232e238
SMVQebased scheme, 219e238
SMVQ. See Side match VQ (SMVQ)
SOI. See Start of image (SOI)
Source coding, 27
Spatial domain
difference expansionebased schemes, 73e79
histogram modiﬁcationebased schemes, 80e101
information hiding, 69e70
lossless compressionebased schemes, 102e118
lossless information hiding methods, 69
methods, 6, 49
modulo additionebased scheme, 71e73
authentication process, 71
embedding process, 71, 72f
modulo addition operation, 71e73
reversible secret sharingebased schemes,
119e137
schemes, 386
Spread spectrum algorithm (SS algorithm), 184,
187
SQS. See Sequential Quantization Strategy (SQS)
SS algorithm. See Spread spectrum algorithm
(SS algorithm)
Standard deviation (STD), 31e32
Start of image (SOI), 336
Status recovery for cover media, 60e62
STD. See Standard deviation (STD)
Steganography, 13e14, 19e20. See also Infor-
mation hiding
adaptive, 49
image
background and concept, 47
system, 47e48, 48f
techniques, 48e49
Stego
capacity, 19e20
images, 8
object, 14e15
Index
413

Still image, 1
Subband structure, 336e337, 338f
Subliminal channel, 21
Surjection, 143e144, 144f
Symmetric information hiding, 15
Symmetry of keys, 22e23
T
TA. See Torus automorphisms (TA)
Tampering detection, 43
Technical steganography, 19e20
Thresholding technique, 349e350
Tian’s scheme, 73e76, 75t
Tiling, 36
Time complexity, 319
Torus automorphisms (TA), 386e387
Transaction tracking, 25
Transform coding, 29
Transform domains, 23. See also Integer DCT
(IntDCT)
integer wavelet transformebased schemes,
189e197
invertible mapping, 143e144
reversible information hiding to integer
transforms, 145e146
transform domainebased schemes, 386
transform-based information hiding, 146e150
Transform-based information hiding, 146e150
DCTebased information hiding, 147e148
DFTebased information hiding, 148e149
DWTebased information hiding, 149e150
two-level discrete wavelet transform decomposi-
tion, 150f
Transmitter-side ﬁngerprinting, 47
Transparency, 16
TSVQ. See Two-stage VQ (TSVQ)
Twice-try structures for block discrimination, 165e169
for embedding process, 167f
for extracting process, 168f
Two-dimensional images, 7e8
Two-dimensional IntDCT, 154e156
reconstruction algorithm for, 155e156
Two-stage VQ (TSVQ), 211e212
U
Underﬂow prevention, 90e91, 163e165
Undetectability, 16
V
Value expansion technique in integer wavelet
transform, 190e193
compression and companding error, 192e193
compression function for value expansion,
191e192
value companding functions, 192f
Value expansionebased scheme, 195e197
Variable length code (VLC), 336, 370e371
data hiding scheme by replacing, 375f
mappingebased scheme, 370e384
comparison of average capacity, 381t
comparison of embedding capacity, 379te380t
data embedding and extracting procedures,
375e377
experimental results, 377e384
extension to application, 373e375
optimization algorithm, 371e373
performance of scheme in application, 383t
security analysis, 377
Variable length integer (VLI), 336
Vector images, 2
Vector quantization (VQ), 30e31, 31f, 207e208,
208f, 282e283, 386
encoding and decoding processes, 208f
MFCVQ, 212e218
SMVQ, 219e238
VQebased information hiding, 208e212
VQebased image watermarking, 209e211
VQebased lossless information hiding,
209e210
VQeindex codingebased schemes, 238e276
difference codingebased scheme, 257e260
IJNCebased scheme, 261e268
JNCebased scheme, 238e242
lossless hiding scheme for two-stage,
269e276, 270f
path optional lossless information hiding
scheme, 247e257
Video, 1
Visually lossless, 6e7
VLC. See Variable length code (VLC)
VLI. See Variable length integer (VLI)
VQ. See Vector quantization (VQ)
VQeindex residual value coding (VQIRVC),
211e212. See also Joint neighboring
coding (JNC)
VQIRVCebased scheme, 242e247
decoding and extracting phase, 244e245
experimental results, 245e247
information hiding phase, 242e244
preprocessing phase, 242
VQIRVC-based, MFCVQ-based, and
SMVQ-based algorithms comparison, 246t
VQIRVC. See VQeindex residual value coding
(VQIRVC)
414
Index

W
Watermark/watermarking
algorithms
based on codebook partition, 209e210
based on index properties, 210e211
authentication system, 44
authentication watermark embedding, 44
extraction and veriﬁcation, 44
capacity vs. distortion, 185e188
differences with ﬁngerprinting, 46
embedding, 175, 175f, 387e390, 390f
Yang and Lu’s Method 2, 285e286
Zhang et al.’s Method, 287e289, 288t
extraction, 390, 392f
Yang and Lu’s Method 2, 286e287
Zhang et al.’s Method, 289e290
Wavelet transform, 36, 149
Weighted Quantization Method approach
(WQM approach), 54
Weighted signal-to-noise ratio (WSNR), 117e118
WQM approach. See Weighted Quantization
Method approach (WQM approach)
WSNR. See Weighted signal-to-noise ratio
(WSNR)
X
Xuan et al.’s histogram pairebased lossless data
embedding scheme, 346e352
hiding algorithm, 350e352
lossless data embedding for JPEG image, 347f
principles, 347e349
using single histogram pair, 348
using two loops, 348e349
thresholding, 349e350
Y
Yang and Lu’s Method 1, 283e284
Yang and Lu’s Method 2, 284e287
preprocessing, 284
watermark embedding, 285e286
watermark extraction, 286e287
Yang et al.’s scheme, 173e176
embedding processes for, 169f
extracting processes for, 170f
Z
Zero run length coding (ZRLC), 335e336
Zero-tree DCT prediction (ZTDCT prediction),
179, 181e182
Zhang et al.’s Method, 287e290
watermark embedding, 287e289, 288t
watermark extraction, 289e290
Zigzag sequence, 335f
ZRLC. See Zero run length coding (ZRLC)
ZTDCT prediction. See Zero-tree DCT prediction
(ZTDCT prediction)
Index
415

