A Typed Lambda Calculus
with
Categorical Type Constructors
Tatsuya Hagino
LFCS, Department of Computer Science, University of Edinburgh
James Clerk Maxwell Building, King’s Buildings, Mayﬁeld Road
Edinburgh EH9 3JZ, United Kingdom.
Abstract
A typed lambda calculus with categorical type constructors is introduced. It has a uniform
category theoretic mechanism to declare new types.
Its type structure includes categorical
objects like products and coproducts as well as recursive types like natural numbers and lists.
It also allows duals of recursive types, i.e. lazy types, like inﬁnite lists.
It has generalized
iterators for recursive types and duals of iterators for lazy types. We will give reduction rules
for this simply typed lambda calculus and show that they are strongly normalizing even though
it has inﬁnite things like inﬁnite lists.
1
Introduction
The type structure of a simply typed lambda calculus is generally constructed from some base types
using the arrow type constructor σ →τ. Since a pure lambda calculus is nothing but about lambda
abstraction and application of lambda terms, the arrow type is more important than base types.
However, if we do not have any base types, the type structure is empty and there is no point in
discussing such a typed lambda calculus because there are no typed lambda terms. Therefore, we
need some base types when developing a theory of a simply typed lambda calculus, but the choice
of base types may vary from one calculus to another: some choose the type of natural numbers as
the only base type or others, like [11], choose the type of ordinals as well. We have to be careful
about choosing base types because a bad choice may ruin the whole calculus, e.g. lose the strong
normalization property.
A typed lambda calculus can be regarded as a model of typed functional programming languages,
so obviously the richer the type structure is, the closer to real programming languages the calculus
is. Some programming languages now have quite powerful mechanisms of creating new types from
existing ones, and we would naturally like to see those mechanisms in typed lambda calculi as well.
From a category theoretic point of view, the arrow type constructor is just one of the functors which
can be deﬁned by adjunctions. There is no reason why we should not have other functors in typed
lambda calculi. In [4], the author introduced a category theoretic datatype declaration mechanism,
by which we can deﬁne categorical objects like products and coproducts, ordinary datatypes in most
of programming languages like natural numbers and lists, those datatypes which can be deﬁned
by solving recursive datatype equations, and lazy datatypes like inﬁnite lists. All these datatypes

are declared uniformly by means of generalized adjunctions. In this paper, we give a simply typed
lambda calculus which incorporates this uniform categorical datatype declaration mechanism. This
lambda calculus no longer needs base types. We can introduce almost all the datatypes we need
in ordinary programming languages by this mechanism. Furthermore, the calculus is still strongly
normalizing even though it has inﬁnite lists and others.
In section 2, we introduce our (simply) typed lambda calculus: its type structure, its terms, its
typing system and its reduction rules. In section 3, we see some types we can deﬁne in our typed
lambda calculus, and, in section 4, we compare our typed lambda calculus with other typed lambda
calculi. Finally, in section 5 we see the connection between our lambda calculus and the functional
programming language ML.
2
A Typed Lambda Calculus with Categorical Type Con-
structions
2.1
Types
The type structure Type of an ordinary simply typed lambda calculus can be given in general by the
following two rules:
σ ∈BaseType
σ ∈Type
σ ∈Type
τ ∈Type
σ →τ ∈Type
where BaseType is the set of base types available to this typed lambda calculus. This lambda calculus
has only one way of constructing types, i.e. σ →τ is the only type constructor. We can enrich the
type structure by introducing new type constructors.
For example, if we want the product and
coproduct type constructors, we may add the following two rules:
σ ∈Type
τ ∈Type
σ × τ ∈Type
σ ∈Type
τ ∈Type
σ + τ ∈Type
Of course, we have to introduce new terms which belong to these new types and new reduction rules
concerning the new terms. Although this approach is ﬂexible to have any kind of type constructors,
every time we introduce a new type constructor, we get a new typed lambda calculus and we have
to prove all the properties of this calculus from the very beginning.
One way of getting out of this problem is to have a mechanism to introduce new type constructors.
In domain theory, we can deﬁne domains by solving recursive domain equations and in some pro-
gramming languages, e.g. ML [5], we can deﬁne datatypes (or datatype constructors as polymorphic
types) in a similar manner by giving recursive datatype equations. Therefore, it is natural to intro-
duce recursive types to a typed lambda calculus. The type structure of such a lambda calculus may
be given by the following rules:
ρ ∈TVar
ρ ∈Γ
Γ ⊢ρ ∈Type
Γ ⊢σ ∈Type
Γ ⊢τ ∈Type
Γ ⊢σ →τ ∈Type
ρ ∈TVar
Γ ∪{ ρ } ⊢σ ∈Type
Γ ⊢µρ.σ ∈Type
where TVar is a set of type variables and Γ is an environment under which types are checked to be
well-formed. The type introduced by µρ.σ should have terms corresponding recursively to that of

σ[µρ.σ/ρ], where σ[τ/ρ] denotes the type obtained by replacing the type variable ρ in σ by a type τ.
In this way, we can get rid of some basic types. For example, the type for natural numbers can now
be deﬁned as
nat ≡µρ.1 + ρ
where 1 is the type of one element and + is the coproduct type constructor. This is like in domain
theory where the domain N of natural numbers is the least ﬁxed point of N ∼= 1 + N. Similarly
we can deﬁne most of ordinary datatypes in today’s programming languages in this way. However,
there are still some problems about this approach. Firstly, we need to select some base types, like
1, and some type constructors, like + and ×, to start with. Secondly, the reduction rules for this
calculus may not be normalizing. Of course, it depends on the choice of terms and reduction rules in
the calculus, but we would like to have a ﬁxed point operator or something which enables us to write
terms for addition, multiplication and so on. If we have a ﬁxed point operator, reductions may not
terminate. In case of an ordinary simply typed lambda calculus with the type of natural numbers, it
has iterators (often denoted by J) which allows us to deﬁne these terms by primitive recursion and
because we only use primitive recursion the reductions always terminate, but we still do not know
what is the general operator for primitive recursion for µρ.σ.
From a category theoretic point of view, the types deﬁned by µρ.σ exactly correspond to initial T-
algebras. Initial T-algebras cannot deﬁne the coproduct type constructor, but, as the author showed
in [4], their extension, initial and ﬁnal F, G-dialgebras, can deﬁne the coproduct type constructor as
well as the product one.
Deﬁnition 2.1: Let C and D be categories and both F and G be functors from C to D. We deﬁne
the category of F, G-dialgebras as
1. its objects are pairs ⟨A, f⟩where A is a C object and f is a D morphism of F(A) →G(A), and
2. its morphisms h: ⟨A, f⟩→⟨B, g⟩are C morphisms h: A →B such that the following diagram
commutes.
F(A)
f
G(A)
-
F(h)
¥
¨§?
G(h)
?
?
F(B)
g
-G(B)
It is easy to show that it is a category; let us write DAlg(F, G) for it. []
It is also easy to see that the deﬁnition of F, G-dialgebra is an extension of the deﬁnition of T-
algebras as well as that of T-coalgebras: DAlg(T, I) is the category of T-algebras and DAlg(I, T)
is the category of T-coalgebras.
The extension is a very simple one, yet its symmetry and dividing the source category from the target
one give us greater freedom. With T-algebras, we need the coproduct functor to deﬁne the domain
of natural numbers, but with F, G-dialgebra we do not. Let C be any category and D be its product
category C × C. We deﬁne the functors F and G as
F(A) ≡⟨1, A⟩
and
G(A) ≡⟨A, A⟩.
Let ⟨nat, ⟨zero, succ⟩⟩be the initial F, G-dialgebra.
The unique DAlg(F, G) morphism h from

⟨nat, ⟨zero, succ⟩⟩to a DAlg(F, G) object ⟨A, ⟨f, g⟩⟩makes the following diagram commute.
⟨nat, ⟨zero, succ⟩⟩
h
⟨A, ⟨f, g⟩⟩
⟨1, nat⟩
⟨I, h⟩
⟨1, A⟩
⟨zero, succ⟩
¥
¨§?
⟨f, g⟩
⟨nat, nat⟩
⟨h, h⟩
⟨A, A⟩
-
-
?
?
?
If we redraw the diagram, we get a more familiar diagram of deﬁning ‘nat’ as the natural number
object.
1
zero
nat
succ
nat
f
¥
¨§?
h
¥
¨§?
h
A
A
g
-
-
@
@
@
@
@
@
@
@
R
-
?
?
We can also demonstrate that left adjoint functors can be expressed by initial F, G-dialgebras and
right adjoint functors can be expressed by ﬁnal F, G-dialgebras. Let us, as an example, deﬁne the
product of two C objects A and B. Remember that the product functor is the right adjoint of the
diagonal functor. We set the functors F and G from C to C × C as
F(C) ≡⟨C, C⟩
and
G(C) ≡⟨A, B⟩.
Let ⟨A × B, ⟨π1, π2⟩⟩be the ﬁnal F, G-dialgebra. Then, from the deﬁnition, the unique DAlg(F, G)
morphism h from a DAlg(F, G) object ⟨C, ⟨f, g⟩⟩to ⟨A × B, ⟨π1, π2⟩⟩should commute the following
diagram.
⟨C, ⟨f, g⟩⟩
h
⟨A × B, ⟨π1, π2⟩⟩
⟨C, C⟩
⟨h, h⟩
⟨A × B, A × B⟩
⟨f, g⟩
¥
¨§?
⟨π1, π2⟩
⟨A, B⟩
⟨I, I⟩
⟨A, B⟩
-
-
?
?
?
We can redraw the diagram to get an ordinary diagram for products.
A
A × B
B
π1
π2
¥
¨§?
¥
¨§?
f
g
h
C

-
¡
¡
¡
¡
¡
¡
¡
¡
ª
@
@
@
@
@
@
@
@
R
?

As we extended T-algebras to F, G-dialgebras, we can extend µρ.σ into something more powerful: we
use not only least ﬁxed points but also greatest ﬁxed points which correspond to ﬁnal T-coalgebras;
we allow a sequence of types instead of a single type when we take ﬁxed points. The type structure
of our lambda calculus is:
Deﬁnition 2.2: Let TVar be a set of type variables. We use ρ, ν, . . . for the meta-variables of TVar.
The set Type of types is deﬁned by the following rules:
ρ ∈TVar
ρ ∈Γ
Γ ⊢ρ ∈Type
Γ ⊢σ ∈Type
Γ ⊢τ ∈Type
Γ ⊢σ →τ ∈Type
Γ ∪{ ρ } ⊢σi ∈Type
Pos(ρ, σi)
(i = 1, . . . , n)
Γ ⊢µρ.(σ1, . . . , σn) ∈Type
Γ ∪{ ρ } ⊢σi ∈Type
Pos(ρ, σi)
(i = 1, . . . , n)
Γ ⊢µρ.(σ1, . . . , σn) ∈Type
where Pos(ρ, σ) is the predicate which is true when ρ occurs only positively in σ. Pos can be deﬁned
as follows together with the predicate Neg(ρ, σ) for negative occurrences of ρ in σ:
Pos(ρ, ρ)
Pos(ρ, ν)
Neg(ρ, ν)
Neg(ρ, σ)
Pos(ρ, τ)
Pos(ρ, σ →τ)
Pos(ρ, σ)
Neg(ρ, τ)
Neg(ρ, σ →τ)
Pos(ρ, σi)
(i = 1, . . . , n)
Pos(ρ, µν.(σ1, . . . , σn))
Neg(ρ, σi)
(i = 1, . . . , n)
Neg(ρ, µν.(σ1, . . . , σn))
Pos(ρ, σi)
(i = 1, . . . , n)
Pos(ρ, µν.(σ1, . . . , σn))
Neg(ρ, σi)
(i = 1, . . . , n)
Neg(ρ, µν.(σ1, . . . , σn))
We use σ, τ, . . . for the meta-variables of Type. []
The type µρ.(σ1, . . . , σn) corresponds to the initial F, G-dialgebra where F and G are functors from
C to C × · · · × C such that
F(A) ≡⟨F1(A), . . . , Fn(A)⟩
and
G(A) ≡⟨A, . . . , A⟩
where F1, . . . , Fn are functors corresponding to σ1, . . . , σn. On the other hand, µρ.(σ1, . . . , σn) corre-
sponds to the ﬁnal G, F-dialgebra for the same F and G as above.
Note that we restricted type variables to occur only positively in µρ.(σ1, . . . , σn) and µρ.(σ1, . . . , σn).
Therefore, we can have neither µρ.(ρ →σ) nor µρ.(ρ →ρ), but we can have µρ.((ρ →σ) →ρ) if we
want. Note also that we do not have any base types. We will show that various types we can deﬁne
in this lambda calculus in section 3.
2.2
Terms and Their Types
Terms of our lambda calculus are deﬁned as follows:

Deﬁnition 2.3: We have an enumerable set Var of variables and a set of terms is given by the
following BNF expression.
L : : = x | λxσ.L | L1L2 | Cµρ.(σ1,...,σn),i | Jµρ.(σ1,...,σn),τ |
Dµρ.(σ1,...,σn),i | Pµρ.(σ1,...,σn),τ | σ[L/ρ]
where C, J, D and P are constants and we use x, y, z, . . . for meta-variables for variables and
L, M, N, . . . for meta-variables for terms. We may omit type subscripts or superscripts (e.g. µρ.(σ1, . . . , σn)
of Cµρ.(σ1,...,σn),i) if they are obvious. []
Cµρ.(σ1,...,σn),i and Jµρ.(σ1,...,σn),τ are associated with µρ.(σ1, . . . , σn). Remember that µρ.(σ1, . . . , σn) is
the initial F, G-dialgebra where F and G are
F(A) ≡⟨σ1[A/ρ], . . . , σn[A/ρ]⟩
and
G(A) ≡⟨A, . . . , A⟩.
Cµρ.(σ1,...,σn),i (i = 1, . . . , n) are morphisms such that
⟨µρ.(σ1, . . . , σn), ⟨Cµρ.(σ1,...,σn),1, . . . , Cµρ.(σ1,...,σn),n⟩⟩
is the initial F, G-dialgebra. Therefore, the type of Cµρ.(σ1,...,σn),i is
Cµρ.(σ1,...,σn),i : σi[µρ.(σ1, . . . , σn)/ρ] →µρ.(σ1, . . . , σn).
Given a term M of type σi[µρ.(σ1, . . . , σn)/ρ], Cµρ.(σ1,...,σn),iM constructs a term of µρ.(σ1, . . . , σn).
Cµρ.(σ1,...,σn),i are constructors. In addition, Jµρ.(σ1,...,σn),τ is the mediating morphism such that for any
morphisms M1, . . . , Mn of type σ1[τ/ρ] →τ, . . . , σn[τ/ρ] →τ, respectively, Jµρ.(σ1,...,σn),τM1 . . . Mn
gives a unique morphism from µρ.(σ1, . . . , σn) to τ such that the following digrams (i = 1, . . . , n)
commute.
σi[τ/ρ]
σi[Jµρ.(σ1,...,σn),τM1 . . . Mn/ρ]
σi[µρ.(σ1, . . . , σn)/ρ]
Mi
Cµρ.(σ1,...,σn),i
¥
¨§?
τ
Jµρ.(σ1,...,σn),τM1 . . . Mn
µρ.(σ1, . . . , σn)
-
-
?
?
Therefore, the type of Jµρ.(σ1,...,σn),τ is
Jµρ.(σ1,...,σn),τ : (σ1[τ/ρ] →τ) →· · · →(σn[τ/ρ] →τ) →µρ.(σ1, . . . , σn) →τ.
As is well-known, Jµρ.(σ1,...,σn) can be used to deﬁne primitive recursive functions.
Dually, Dµρ.(σ1,...,σn),i and Pµρ.(σ1,...,σn),τ are associated with the type µρ.(σ1, . . . , σn).
⟨µρ.(σ1, . . . , σn), ⟨Dµρ.(σ1,...,σn),1, . . . , Dµρ.(σ1,...,σn),n⟩⟩
gives the ﬁnal G, F-dialgebra and Pµρ.(σ1,...,σn),τ is its mediating morphism. Given a term M of type
µρ.(σ1, . . . , σn), it can be decomposed into a term Dµρ.(σ1,...,σn),iM of type σi[µρ.(σ1, . . . , σn)/ρ] and
Pµρ.(σ1,...,σn),τM1 . . . Mn can be used to construct a term of type µρ.(σ1, . . . , σn) from a term of type
τ.
For a type σ with a free type variable ρ, a term σ[M/ρ] denotes the result of applying the functor
corresponding to σ to a term M.

Deﬁnition 2.4: Types of terms in our lambda calculus is given by the following rules:
x ∈Var
x : σ ∈Γ
Γ ⊢x : σ
Γ ∪{ x : σ } ⊢M : τ
Γ ⊢λxσ.M : σ →τ
Γ ⊢M : σ →τ
Γ ⊢N : σ
Γ ⊢MN : τ
Γ ⊢Cµρ.(σ1,...,σn),i : σi[µρ.(σ1, . . . , σn)/ρ] →µρ.(σ1, . . . , σn)
Γ ⊢Jµρ.(σ1,...,σn),τ : (σ1[τ/ρ] →τ) →. . . →(σn[τ/ρ] →τ)
→µρ.(σ1, . . . , σn) →τ
Γ ⊢Dµρ.(σ1,...,σn),i : µρ.(σ1, . . . , σn) →σi[µρ.(σ1, . . . , σn)/ρ]
Γ ⊢Pµρ.(σ1,...,σn),τ : (τ →σ1[τ/ρ]) →. . . →(τ →σn[τ/ρ])
→τ →µρ.(σ1, . . . , σn)
Pos(ρ, σ)
Γ ⊢M : τ →τ ′
Γ ⊢σ[M/ρ] : σ[τ/ρ] →σ[τ ′/ρ]
Neg(ρ, σ)
Γ ⊢M : τ →τ ′
Γ ⊢σ[M/ρ] : σ[τ ′/ρ] →σ[τ/ρ]
[]
2.3
Reduction rules
Let us consider the reduction rules for our typed lambda calculus. In the following we do not handle
α conversions explicitly. We regard terms which can be transformed each other by α conversions
are essentially the same. We assume that the necessary renaming of variables when substituting a
variable by a term is done implicitly.
We have the β and η reduction rules from ordinary lambda calculi.
(λxσ.M)N ⇒M[N/x]
λxσ.Mx ⇒M
where x needs to be free in M for the η reductions.
Since µρ.(σ1, . . . , σn) corresponds to the initial F, G-dialgebra for
F(A) ≡⟨σ1[A/ρ], . . . , σn[A/ρ]⟩
and
G(A) ≡⟨A, . . . , A⟩,
for any type τ and any terms Mi : σ[τ/ρ] →τ (i = 1, . . . , n) there exists a unique morphism N
which make the following diagrams (i = 1, . . . , n) commute.
σi[τ/ρ]
σi[N/ρ]
σi[µρ.(σ1, . . . , σn)/ρ]
Mi
Cµρ.(σ1,...,σn),i
¥
¨§?
τ
N
µρ.(σ1, . . . , σn)
-
-
?
?
N is given by the iterator as Jµρ.(σ1,...,σn),τM1 . . . Mn. From the commutativity, we have the following
equality.
Jµρ.(σ1,...,σn),τM1 . . . Mn(Cµρ.(σ1,...,σn),iL) = Mi(σ[Jµρ.(σ1,...,σn),τM1 . . . Mn/ρ]L)

where L is a term of type σi[µρ.(σ1, . . . , σn)/ρ]. Reducing the number of constructors is a good
strategy for normalizing terms, so we have a reduction rule of rewriting the left-hand side by the
right-hand side.
Jµρ.(σ1,...,σn),τM1 . . . Mn(Cµρ.(σ1,...,σn),iL) ⇒Mi(σ[Jµρ.(σ1,...,σn),τM1 . . . Mn/ρ]L)
When τ is µρ.(σ1, . . . , σn) and Mi is Cµρ.(σ1,...,σn),i, the commutative diagram is
σi[µρ.(σ1, . . . , σn)/ρ]
σi[N/ρ]
σi[µρ.(σ1, . . . , σn)/ρ]
Cµρ.(σ1,...,σn),i
Cµρ.(σ1,...,σn),i
¥
¨§?
µρ.(σ1, . . . , σn)
N
µρ.(σ1, . . . , σn)
-
-
?
?
N should be the identity morphism, so we have the following reduction rule.
Jµρ.(σ1,...,σn),τCµρ.(σ1,...,σn),1 . . . Cµρ.(σ1,...,σn),n ⇒λxµρ.(σ1,...,σn).x
The two reduction rules cannot exactly characterize µρ.(σ1, . . . , σn) to be the initial F, G-dialgebra
since the uniqueness condition is essentially a conditional equation, but as far as its computational
aspect is concerned they seems to be enough.
Dually, for µρ.(σ1, . . . , σn), we have the following two reduction rules:
Dµρ.(σ1,...,σn),i(Pµρ.(σ1,...,σn),τM1 . . . MnL) ⇒σi[Pµρ.(σ1,...,σn),τM1 . . . Mn/ρ](MiL)
and
Pµρ.(σ1,...,σn),τDµρ.(σ1,...,σn),1 . . . Dµρ.(σ1,...,σn),n ⇒λxµρ.(σ1,...,σn).x.
Finally, we have some reduction rules for functors σ[M/ρ]. Like the product functor f × g can be
expressed by ⟨f ◦π1, g ◦π2⟩, we transform σ[M/ρ] into terms containing J, C, P and D. In the
following rules, let M be a term of type τ →τ ′.
ρ[M/ρ] ⇒M
ν[M/ρ] ⇒λxσ.x
(where ρ ̸≡ν)
(σ →σ′)[M/ρ] ⇒λxσ[τ/ρ]→σ′[τ/ρ].λyσ[τ ′/rho].σ′[M/ρ](x (σ[M/ρ] y))
µν.(σ1, . . . , σn)[M/ρ] ⇒Jµν.(σ1[τ/ρ],...),µν.(σ1[τ ′/ρ],...)M1 . . . Mn
(where Mi is λxσi[τ/ρ][µν.(σ1[τ ′/ρ],...)/ν].Cµν.(σ1[τ/ρ],...),i(σi[µν.(σ1[τ ′/ρ], . . .)/ν][M/ρ] x))
µν.(σ1, . . . , σn)[M/ρ] ⇒Pµν.(σ1[τ ′/ρ],...),µν.(σ1[τ/ρ],...)M1 . . . Mn
(where Mi is λxµν.(σ1[τ/ρ],...).σi[µν.(σ1[τ/ρ], . . .)/ν][M/ρ](Dµν.(σ1[τ/ρ],...),ix))
We have some obvious propositions.
Proposition 2.5: For a term L of type σ, if there is a reduction L
∗⇒M, M also has the type σ,
where
∗⇒is the transitive version of ⇒. []
Proposition 2.6: If ρ does not occur in σ, then σ[M/ρ]
∗⇒λxσ.x for any term M. []

This means that constant functors always give identities.
Proposition 2.7: For any type σ with a free variable ρ, σ[λxτ.x/ρ]
∗⇒λyσ[τ/ρ].y. []
This means that identities are always mapped to identities by σ, which is one of the conditions for
σ being a functor.
Now, we have two important theorems about our reduction system: strong normalization and Church-
Rosser. Because we only use primitive recursions, any term can be reduced to a normal term which
cannot be reduced any more. In fact, any reduction leads to a normal term.
Theorem 2.8: (Strong Normalization Theorem) The reduction is strongly normalizing, that
is, there is no inﬁnite reduction sequence L1 ⇒L2 ⇒L3 ⇒· · · ⇒Ln ⇒· · · . []
Furthermore, any reduction leads to a unique normal term.
Theorem 2.9: (Church-Rosser Theorem) The reduction is Church-Rosser, that is, if L
∗⇒M
and L
∗⇒N, there exists a term K such that M
∗⇒K and N
∗⇒K. []
Because we have the strong normalization theorem, the Church-Rosser theorem follows from the
following lemma (see [6] proposition 13.1).
Lemma 2.10: If L ⇒M and L ⇒N, there exists a term K such that M
∗⇒K and N
∗⇒K.
Proof: All we have to do is to check any overlapping of two reduction rules. For example,
Jµρ.(σ1,...,σn),τM1 . . . Mn(Cµρ.(σ1,...,σn),iL) ⇒Mi(σ[Jµρ.(σ1,...,σn),τM1 . . . Mn/ρ]L)
and
Jµρ.(σ1,...,σn),τCµρ.(σ1,...,σn),1 . . . Cµρ.(σ1,...,σn),n ⇒λxµρ.(σ1,...,σn).x
overlap, that is, there a term to which both rules can be applied, but we can easily show that two
resulting terms can be reduced to the same term.
JC1 . . . Cn(CiL)
Ci(σi[JC1 . . . Cn/ρ]L)
(λx.x)(CiL)
CiL
¡
¡
¡
¡
¡
¡
@
@
@
@
@
@
@
@
@
@
@
@
¡
¡
¡
¡
¡
¡
∗
∗
Ci(σi[JC1 . . . Cn/ρ]L)
∗⇒CiL follows from JC1 . . . Cn ⇒λx.x and proposition 2.7. We can check all
the other overlappings similarly. []
The strong normalization theorem follows intuitively from the fact that we use only primitive recur-
sion. In the reduction of Jµρ.(σ1,...,σn),τ we reduce the number of constructors Cµρ.(σ1,...,σn),i, whereas
in the reduction of Pµρ.(σ1,...,σn),τ we reduce the number of destructors Dµρ.(σ1,...,σn),i. Therefore, there
is no way we can continue reducing any terms. Formally, we prove the normalization theorem by
Tait’s computability method [6, 12]. First, we deﬁne the notion of computable terms by induction on
types.
Deﬁnition 2.11: (Computability)

1. M : σ →τ is computable if MN : τ is computable for any computable term N : σ
2. M : µρ.(σ1, . . . , σn) is computable if M is strongly normalizing and M
∗⇒Cµρ.(σ1,...,σn),iL such
that L : σi[µρ.(σ1, . . . , σn)/ρ] is computable.
3. M : µρ.(σ1, . . . , σn) is computable if M is strongly normalizing and
M
∗⇒Pµρ.(σ1,...,σn),τN1 . . . NnL
such that for any i
Dµρ.(σ1,...,σn),i(Pµρ.(σ1,...,σn),τN1 . . . NnL) : σi[µρ.(σ1, . . . , σn)/ρ]
is computable. []
Note that the deﬁnition is inductive in another sense as well. The deﬁnition of computable terms of
µρ.(σ1, . . . , σn) depends on itself. We take the least ﬁxed point of this self recursive deﬁnition, i.e.
starting with the empty set of computable terms, we increase the set by applying the deﬁnition.
∅⊆S1 ⊆S2 ⊆· · · ⊆Sn ⊆Sn+1 ⊆· · ·
where Sn+1 is obtained by applying the deﬁnition to Sn. Since the deﬁnition is monotonic, there is a
least ﬁxed point. This process also provides the measure function over the computable terms which
assigns for each computable term M an ordinal α where Sα is the ﬁrst set which contains M. On the
other hand, we take the greatest ﬁxed point for the deﬁnition of computable terms of µρ.(σ1, . . . , σn).
It is easy to see that
Lemma 2.12: If M is computable, M is strongly normalizing. []
Therefore, all we have to prove is that any typed term is computable. This is proved by structural
induction. One of the lemmas we need is the following.
Lemma 2.13: Jµρ.(σ1,...,σn),τM1 . . . MnN is computable if M1, . . . , Mn and N are computable
Proof: N is a computable term of µρ.(σ1, . . . , σn). We prove the lemma by induction on the ordinal
associated with N. Because N is computable, N
∗⇒CiL. Therefore, any reduction sequence of
JM1 . . . MnN should be
JM1 . . . MnN
∗⇒JM ′
1 . . . M ′
n(CiL) ⇒M ′
i(σi[JM ′
1 . . . M ′
n/ρ]L).
Because the functor σi only applies JM ′
1 . . . M ′
n to a term of µρ.(σ1, . . . , σn) in L whose ordinal is
smaller than that of N (formally, we have to prove this), from induction hypothesis σi[JM ′
1 . . . M ′
n/ρ]L
is computable and M ′
i(σi[JM ′
1 . . . M ′
n/ρ]L) is computable as well. Therefore, JM1 . . . MnN is com-
putable. []
We have the similar lemmas for Pµρ.(σ1,...,σn),τ and λxσ.M. From these lemmas,
Lemma 2.14: Any typed term is computable. []
Hence, we have proved the strong normalization theorem.
Although we have the strong normalization theorem and the Church-Rosser theorem and, therefore,
the equality of two terms is decidable, this does not mean that the equality of two computable (or
more weakly, primitive recursive) functions is decidable. The equality of lambda terms are deﬁned by
“two lambda terms reduce to the same lambda term”, but the reduction rules do not capture all the
equality of computable (or primitive recursive) functions. Remember that we deﬁned µρ.(σ1, . . . , σn)

to be the initial F, G-dialgebra and we put the commutativity of diagrams, but we did not put the
uniqueness, or we could not put it. Therefore, the equality derived from the reduction is weaker. In
other words, if we regard the reduction rules as the operational semantics of our lambda calculus
and the initial and ﬁnal F, G-dialgebras as the denotational semantics, the denotational semantics is
not fully abstract.
3
Examples
In this section, we show some types which we can deﬁne in our lambda calculus.
Example 3.1: The type corresponding to the initial object is deﬁned by ∅≡µρ.(). There are
no constructors and J∅,σ : ∅→σ gives the unique morphism from ∅to any type σ. Dually, the
type corresponding to the terminal object is deﬁned by 1 ≡µρ.(). There are no destructors and
P1,σ : σ →1 gives the unique morphism from σ to 1. There is an element in 1. In fact, there is only
one element in 1 in some sense. Let us write ∗for P1,1→1λx1.x which is an element of 1. Actually,
we can use any element of 1. The choice does not aﬀect the computation. []
Example 3.2: The product of two types, σ and τ can be deﬁned as σ × τ ≡µρ.(σ, τ). We have two
projections.
π1 ≡Dσ×τ,1
: σ × τ →σ
π2 ≡Dσ×τ,2
: σ × τ →τ
If M is a term of type σ and N is a term of type τ, we can deﬁne a term ⟨M, N⟩of type σ × τ.
⟨M, N⟩≡Pσ×τ(λx1.M)(λx1.N)∗
: σ × τ
We have the following reduction.
π1⟨M, N⟩≡Dσ×τ,1(Pσ×τ,1(λx.M)(λx.N)∗) ⇒(λx.x)((λx.M)∗)
∗⇒M
Similarly, we can show that π2⟨M, N⟩
∗⇒N. However, we do not have
⟨π1M, π2M⟩
∗⇒M
because we did not code the uniqueness condition in our reduction rules. We could have coded
products specially, but then, we lose the generality of our lambda calculus. []
Example 3.3: Dually, the coproduct of σ and τ is deﬁned as σ + τ ≡µρ.(σ, τ). Two injections are
deﬁned as follows.
ι1 ≡Cσ+τ,1
: σ →σ + τ
ι2 ≡Cσ+τ,2
: τ →σ + τ
Jσ+τ,ν satisﬁes the following reductions.
Jσ+τ,νMN(ι1L) ≡Jσ+τ,νMN(Cσ+τ,1L) ⇒M((λx.x)L) ⇒ML
Jσ+τ,νMN(ι2L)
∗⇒NL
[]
Example 3.4: Let us deﬁne the natural numbers in our lambda calculus. The type is deﬁned by
ω ≡µρ.(1, ρ).
This deﬁnition is closely connected to the deﬁnition in domain theory where the domain of natural
numbers is deﬁned as the least ﬁxed point of N ∼= 1 + N. Our µ is the least ﬁxed point operator.

The only diﬀerence is that we use a sequence (1, ρ) instead of coproduct 1 + ρ. Our approach is in
this way connected to algebraic speciﬁcation methods where the type of natural numbers is deﬁned
as the initial algebra of one constant and one operator. The elements are generated by zero and the
successor function which are deﬁned in our lambda calculus as follows:
0 ≡Cω,1∗
: ω
succ ≡Cω,2
: ω →ω
Jω,σ gives us almost the ordinary iterator but its type is
Jω,σ
: (1 →σ) →(σ →σ) →ω →σ.
We can deﬁne the ordinary one by this Jω,σ as follows.
˜Jσ ≡λx.λy.λn.Jω,σ(λz.x)yn
: σ →(σ →σ) →ω →σ
It satisﬁes the usual reductions:
˜JσMN0
∗⇒Jω,σ(λz.M)N(Cω,1∗) ⇒(λz.M)((λx.x)∗)
∗⇒M
and
˜JσMN(succL)
∗⇒Jω,σ(λz.M)N(Cω,2L) ⇒b(Jω,σ(λz.M)NL) ≈N( ˜JσMNL)
where ≈is the equivalence relation generated by
∗⇒.
Using ˜Jσ, we can deﬁne all the primitive
recursive functions. For example, the addition function can be deﬁne as
add ≡λn.λm. ˜Jωm succ n
: ω →ω →ω.
We can demonstrate, for example, add(succ zero)(succ zero)
∗⇒succ(succ zero). []
Example 3.5: As [11] and [13], we can deﬁne the type for ordinals by Ω≡µρ.(1, ω →ρ). We only
check whether our deﬁnition of the iterator coincides with the ordinary one.
Ω≡µρ.(1, ω →ρ)
0Ω≡CΩ,1∗
: Ω
sup ≡CΩ,2
: (ω →Ω) →ω
JΩ,σ
: (1 →σ) →((ω →σ) →σ) →Ω→σ
JΩ,σ(λx.M)N0Ω⇒(λx.a)((λx.x)∗)
∗⇒M
JΩ,σ(λx.M)N(sup L) ⇒N((ω →ρ)[JΩ,σ(λx.M)N/ρ]L)
⇒N((λy.λz.JΩ,σ(λx.M)N(yz))L) ⇒b(λz.JΩ,σ(λx.M)N(Lz))
[]
Example 3.6: Finally, the type for ﬁnite lists can be deﬁned by Lσ ≡µρ.(1, σ × ρ) with
nil ≡CLσ,1∗
: Lσ
cons ≡CLσ,2
: σ × Lσ →Lσ
JLσ,τ
: (1 →τ) →(σ × τ →τ) →Lσ →τ
whereas the type for inﬁnite lists can be deﬁned by Iσ ≡µρ.(σ, ρ) with
head ≡DIσ,1
: Iσ →σ
tail ≡DIσ,2
: Iσ →Iσ
PIσ,τ
: (τ →σ) →(τ →τ) →τ →Iσ
head(PIσ,τMNL)
∗⇒ML
tail(PIσ,τMNL)
∗⇒PIσ,τMN(NL).

The type for inﬁnite lists is quite exciting to play with. The following lambda term gives us the
inﬁnite sequence of zeros
inf ≡PIω,ω(λxω.x)(λxω.x)zero,
whereas the following gives us the inﬁnite increasing sequence 0, 1, 2, 3, . . ..
inc ≡PIω,ω(λxω.x)succ zero
We can merge two inﬁnite sequences by choosing elements alternatively by the following function.
comb ≡PIσ,Iσ×Iσ(head ◦π1)(PIσ×Iσ,Iσ×Iσπ2(tail ◦π1))
where M ◦N is λx.(M(Nx)). We can demonstrate, for example, that
head(tail(tail(tail(comb inf inc))))
∗⇒succ(succ zero)
[]
We could give many other examples: boolean, trees, automata, co-natural numbers, . . . .
4
Comparison with Other Lambda Calculi
While writing this paper, the author was communicated to [8, 9] where recursive types are introduced
into ﬁrst-order and second-order typed lambda calculi. They use least ﬁxed points and greatest ﬁxed
points as we do, but their recursion combinator R has a diﬀerent type from ours.
M : (ρ →τ) →σ →τ
Rσ,τ(M[µρ.σ/ρ]) : µρ.σ →τ
The author cannot give a clear connection between our iterator and theirs. In addition, they take
ﬁxed points over a single type expression and, therefore, they need some basic type constructors like
1 and +, whereas in our lambda calculus there are no basic type constructors.
Although we discarded the coproduct and product type constructors from basic type constructors, we
still have one basic type constructor, namely the arrow type constructor σ →τ. Since typed lambda
calculi are all about arrow types, it seems impossible to start calculi without it, but from a category
theoretic point of view, the arrow type constructor can be deﬁned as the right adjoint functor of the
product type constructor so it might possible to start calculi without the arrow type constructor. In
[4], the author showed that the arrow typed constructor can be deﬁned by F, G-dialgebras, but how
it can be deﬁned in lambda calculi still has to be investigated.
The second order lambda calculus can be started without basic type constructors and it has been
shown that recursive types which can be deﬁned by least ﬁxed points of type expressions can be
deﬁned in the calculus. The coding of recursive types is a generalization of the coding of Church
numerals in untyped lambda calculus. The author does not know whether it is possible to code up
greatest ﬁxed points as well.
5
New ML?
We might say that ML is based on a simply typed lambda calculus as we might say that LISP is
based on the untyped lambda calculus. The type structure of ML depends on the version of ML we
are talking about. If we are talking about the original ML developed with LCF [3], it has some base
types, product, disjoint sum, integer, etc. , and has ability to introduce new types via recursively
deﬁned type equations. For example, the data type for binary trees whose leaves are integers is
deﬁned as

absrectype btree = int + (btree # btree)
with leaf n = absbtree(inl n)
and node(t1,t2) = absbtree(inr(t1,t2))
and isleaf t = isl(repbtree t)
and leafvalue t = outl(repbtree t)
and left t = fst(outr(repbtree t))
and right t = snd(outr(repbtree t));;
Here, we need the coproduct type constructor ‘+’ as a primitive. We cannot do without it, whereas
‘int’ can be deﬁned in terms of others primitives (ML has it as a primitive type just because of
eﬃciency).
At the next evolution of ML which yielded the current Standard ML [5], we discovered that the
coproduct type constructor is no longer needed as a primitive.
Standard ML has a ‘datatype’
declaration mechanism by which the coproduct type constructor can be deﬁned as follows:
datatype ’a + ’b = inl of ’a | inr of ’b;
A datatype declaration lists the constructors of the deﬁning type. An element of ‘’a + ’b’ can be
obtained by either applying ‘inl’ to an element of ‘’a’ or applying ‘inr’ to an element of ‘’b’. Data
type declarations exactly correspond to our µρ.(σ1, . . . , σn).
datatype ’a + ’b =
inl of ’a | inr of ’b ⇐⇒σ + τ ≡µρ.(σ, τ)
inl
⇐⇒
Cσ+τ,1
inr
⇐⇒
Cσ+τ,2
We can deﬁne the data type for binary trees in Standard ML as follows.
datatype btree = leaf of int | node of btree * btree;
The symbol ‘|’ is just like ‘+’, but we shifted from the object level of the language to the syntax
level. Note that we no longer need the separate deﬁnition of ‘leaf’ or ‘node’. We can deﬁne the
other functions using case statements.
exception btree;
fun isleaf t = case t of
leaf _ => true
| node _ => false;
fun leafvalue t = case t of
leaf n => n
| node _ => raise btree;
fun left t = case t of
leaf _ => raise btree
| node(t1,t2) => t1;
fun right t = case t of
leaf _ => raise btree
| node(t1,t2) => t2;

We get rid of the coproduct type constructor from the primitives, but Standard ML still needs the
product type constructor.
From a category theoretic point of view, we can sense asymmetry in
the type structure of Standard ML. Let us remember that our lambda calculus needs neither the
coproduct type constructor nor the product type constructor as a primitive. We should be able to
introduce the symmetry of our lambda calculus into ML. Let us imagine the next stage of the ML
evolution and deﬁne Symmetric ML.
Primitives
Declaration Mechanism
ML
->, unit, #, +
abstype
Standard ML
->, unit, *
datatype
Symmetric ML
->
datatype, codatatype
CPL in [4]
left object, right object
ML Evolution
Remember that datatype declarations correspond to µρ.(σ1, . . . , σn). We list constructors for types.
In order to get rid of the product type constructor from primitives, we should have a declaration
mechanism which corresponds to µρ.(σ1, . . . , σn). Its syntax is
codatatype TypeParam TypeId =
Id is TypeExp & ... & Id is TypeExp;
A codatatype declaration introduces a type by listing its destructors. The product type constructor
can now be deﬁned as follows:
codatatype ’a * ’b = fst is ’a & snd is ’b;
where ‘fst : ’a * ’b -> ’a’ gives the projection function to the ﬁrst component and ‘snd : ’a * ’b ->
gives the projection function to the second component. If the declaration is recursive, we do not
take the initial ﬁxed point of the type equation but the ﬁnal ﬁxed point. This is ﬁrstly because of
symmetry and secondly because the initial ﬁxed points are often trivial. Because of this, we can
deﬁne inﬁnite objects by codatatype declarations. For example, the following declaration gives us
the data type for inﬁnite lists.
codatatype ’a inflist = head is ’a & tail is ’a inflist;
If we took the initial ﬁxed point, we would get the empty data type.
The deﬁnition is exactly
corresponds to Iσ ≡µρ.(σ, ρ).
Obviously we have destructors for co-data types because we declare them, but how can we construct
data for co-data types? We had case statements for data types, so we have ‘merge’ statements as
dual. Its syntax is
merge Destructor <= Exp & ... & Destructor <= Exp
For example, the function ‘pair’ which makes a pair of given two elements can be deﬁned as follows.
fun pair(x,y) = merge fst <= x & snd <= y;
As a more complicated example, we might deﬁne a function which combines two inﬁnite lists together.
fun comb(l1,l2) = merge head <= head l1

& tail <= comb(l2,tail l1);
As we use pattern matching to declare functions over data types, we can also use it to declare
functions over co-data types. For example, an alternative deﬁnition of ‘comb’ may be
fun head comb(l1,_) = head l1
& tail comb(l1,l2) = comb(l2,tail l1);
Conclusions
We have introduced a simply typed lambda calculus with categorical type constructors and demon-
strated that we can deﬁne various types which had been deﬁned as primitives before. Therefore, our
normalization theorem covers the normalization theorems for other simply typed lambda calculi: a
typed lambda calculus with natural numbers, a typed lambda calculus with ordinals, and so on.
The lambda calculus we presented in this paper is a direct derivation of author’s work on a Categorical
Programming language [4] where a functional programming language CPL has been introduced. CPL
is a categorical-combinator-style programming language which has a uniform categorical datatype
declaration mechanism. CPL is more general than the lambda calculus we presented here in a sense
that CPL does not need →to be a primitive type constructor. It can deﬁne it as the right adjoint of
the product functor. It seems that the diﬀerence comes out from the fact that the category theory
distinguish morphisms from elements of exponential types, whereas lambda calculi not. In lambda
calculi (or functional programming languages based on lambda calculi), functions are always treated
as closures.
An experimental version of CPL has been implemented. Whether the codatatype declaration mech-
anism will be adopted to ML or not remains to be seen, but the author believes that it is an elegant
answer to lazy types in ML.
The connection between initial ﬁxed points and ﬁnal ﬁxed points is quite interesting to investigate.
For example, the type of natural numbers as the initial ﬁxed point of N ∼= 1 + N is associated with
primitive recursion, whereas the type of natural number as the ﬁnal ﬁxed point of the same equation
(we call it co-natural number object) is associated with general recursion.
Neither the lambda calculus we deﬁned here nor CPL has not yet been mixed with dependent types.
This has to be investigated in the future.
Acknowledgements
The author would like to thank Furio Honsell who led me to the world of lambda calculi from the
world of category theory.
References
[1] Arbib, M. A. and Manes, E. G.: The Greatest Fixed Points Approach to Data Types. In proceed-
ings of Third Workshop Meeting on Categorical and Algebraic Methods in Computer Science and
System Theory, Dortmund, West Germany, 1980.

[2] Curien, P-L.: Categorical Combinators, Sequential Algorithms and Functional Programming. Re-
search Notes in Theoretical Computer Science, Pitman, 1986.
[3] Gordon, M. J., Milner, A. J. and Wordsworth, C. P.: Edinburgh LCF. Lecture Notes in Computer
Science, Volume 78, 1979.
[4] Hagino, T.: Category Theoretic Approach to Data Types. Ph. D. thesis, University of Edinburgh,
1987.
[5] Harper, R., MacQueen, D. and Milner, R.: Standard ML. LFCS Report Series, ECS-LFSC-86-2.
Department of Computer Science, University of Edinburgh, 1986.
[6] Lambek, J. and Scott, P. J.: Introduction on Higher-Order Categorical Logic. Cambridge Studies
in Advanced Mathematics, Volume 7, 1986.
[7] Lehmann, D. and Smyth, M.: Algebraic Speciﬁcation of Data Types – A Synthetic Approach –.
Mathematical System Theory, Volume 14, pp. 97–139, 1981.
[8] Mendler N. P.: First- and Second-Order Lambda Calculi with Recursive Types. Technical Report
TR 86-764, Department of Computer Science, Cornell University, 1986.
[9] Mendler N. P.: Recursive Types and Type Constraints in Second-Order Lambda Calculus. 1986.
[10] Smyth, M. B. and Plotkin, G. D.: The Category-Theoretic Solution of Recursive Domain Equa-
tions. SIAM Journal of Computing, Volume 11, 1982.
[11] Stenlund, S.: Combinators, λ-Terms and Proof Theory. D. Reidel, Dordrecht, 1972.
[12] Tait, W.: Intentional Interpretation of Functionals of Finite Type I. Journal of Symbolic Logic,
32, pp. 198–212, 1967.
[13] Troelstra, A. S.: Mathematical Investigation of Intuitionistic Arithmetic and Analysis. Lecture
Notes in Mathematics, Volume 344, Springer-Verlag, 1973.

