Control Engineering Series 84
Nonlinear and 
Adaptive Control 
Systems
Zhengtao Ding

IET CONTROL ENGINEERING SERIES 84
Nonlinear and
Adaptive Control
Systems

Other volumes in this series:
Volume 8
A history of control engineering, 1800–1930 S. Bennett
Volume 18
Applied control theory, 2nd Edition J.R. Leigh
Volume 20
Design of modern control systems D.J. Bell, P.A. Cook and N. Munro (Editors)
Volume 28
Robots and automated manufacture J. Billingsley (Editor)
Volume 33
Temperature measurement and control J.R. Leigh
Volume 34
Singular perturbation methodology in control systems D.S. Naidu
Volume 35
Implementation of self-tuning controllers K. Warwick (Editor)
Volume 37
Industrial digital control systems, 2nd Edition K. Warwick and D. Rees (Editors)
Volume 39
Continuous time controller design R. Balasubramanian
Volume 40
Deterministic control of uncertain systems A.S.I. Zinober (Editor)
Volume 41
Computer control of real-time processes S. Bennett and G.S. Virk (Editors)
Volume 42
Digital signal Processing: principles, devices and applications N.B. Jones and
J.D.McK. Watson (Editors)
Volume 44
Knowledge-based systems for industrial control J. McGhee, M.J. Grimble and A. Mowforth
(Editors)
Volume 47
A History of control engineering, 1930–1956 S. Bennett
Volume 49
Polynomial methods in optimal control and ﬁltering K.J. Hunt (Editor)
Volume 50
Programming industrial control systems using IEC 1131-3 R.W. Lewis
Volume 51
Advanced robotics and intelligent machines J.O. Gray and D.G. Caldwell (Editors)
Volume 52
Adaptive prediction and predictive control P.P. Kanjilal
Volume 53
Neural network applications in control G.W. Irwin, K. Warwick and K.J. Hunt (Editors)
Volume 54
Control engineering solutions: a practical approach P. Albertos, R. Strietzel and N. Mort
(Editors)
Volume 55
Genetic algorithms in engineering systems A.M.S. Zalzala and P.J. Fleming (Editors)
Volume 56
Symbolic methods in control system analysis and design N. Munro (Editor)
Volume 57
Flight control systems R.W. Pratt (Editor)
Volume 58
Power-plant control and instrumentation: the control of boilers and HRSG systems
D. Lindsley
Volume 59
Modelling control systems using IEC 61499 R. Lewis
Volume 60
People in control: human factors in control room design J. Noyes and M. Bransby (Editors)
Volume 61
Nonlinear predictive control: theory and practice B. Kouvaritakis and M. Cannon (Editors)
Volume 62
Active sound and vibration control M.O. Tokhi and S.M. Veres
Volume 63
Stepping motors, 4th edition P.P. Acarnley
Volume 64
Control theory, 2nd Edition J.R. Leigh
Volume 65
Modelling and parameter estimation of dynamic systems J.R. Raol, G. Girija and J. Singh
Volume 66
Variable structure systems: from principles to implementation A. Sabanovic, L. Fridman
and S. Spurgeon (Editors)
Volume 67
Motion vision: design of compact motion sensing solution for autonomous systems
J. Kolodko and L. Vlacic
Volume 68
Flexible robot manipulators: modelling, simulation and control M.O. Tokhi and
A.K.M. Azad (Editors)
Volume 69
Advances in unmanned marine vehicles G. Roberts and R. Sutton
(Editors)
Volume 70
Intelligent control systems using computational intelligence techniques A. Ruano
(Editor)
Volume 71
Advances in cognitive systems S. Nefti and J. Gray (Editors)
Volume 72
Control theory: a guided tour, 3rd Edition J.R. Leigh
Volume 73
Adaptive sampling with Mobile WSN K. Sreenath, M.F. Mysorewala, D.O. Popa
and F.L. Lewis
Volume 74
Eigenstructure control algorithms: applications to aircraft/rotorcraft handling
qualities design S. Srinathkumar
Volume 75
Advanced control for constrained processes and systems F. Garelli, R.J. Mantz and
H. De Battista
Volume 76
Developments in control theory towards glocal control L. Qiu, J. Chen, T. Iwasaki and
H. Fujioka
Volume 77
Further advances in unmanned marine vehicles G.N. Roberts and R. Sutton (Editors)
Volume 78
Frequency-domain control design for high-performance systems J. O’Brien

Nonlinear and
Adaptive Control
Systems
Zhengtao Ding
The Institution of Engineering and Technology

Published by The Institution of Engineering and Technology, London, United Kingdom
The Institution of Engineering and Technology is registered as a Charity in England &
Wales (no. 211014) and Scotland (no. SC038698).
© 2013 The Institution of Engineering and Technology
First published 2013
This publication is copyright under the Berne Convention and the Universal Copyright
Convention. All rights reserved. Apart from any fair dealing for the purposes of research or
private study, or criticism or review, as permitted under the Copyright, Designs and Patents Act
1988, this publication may be reproduced, stored or transmitted, in any form or by any means,
only with the prior permission in writing of the publishers, or in the case of reprographic
reproduction in accordance with the terms of licences issued by the Copyright Licensing
Agency. Enquiries concerning reproduction outside those terms should be sent to the
publisher at the undermentioned address:
The Institution of Engineering and Technology
Michael Faraday House
Six Hills Way, Stevenage
Herts, SG1 2AY, United Kingdom
www.theiet.org
While the author and publisher believe that the information and guidance given in
this work are correct, all parties must rely upon their own skill and judgement when
making use of them. Neither the author nor the publisher assumes any liability to
anyone for any loss or damage caused by any error or omission in the work, whether
such an error or omission is the result of negligence or any other cause. Any and all
such liability is disclaimed.
The moral rights of the author to be identiﬁed as author of this work have been
asserted by him in accordance with the Copyright, Designs and Patents Act 1988.
British Library Cataloguing in Publication Data
A catalogue record for this product is available from the British Library
ISBN 978-1-84919-574-4 (hardback)
ISBN 978-1-84919-575-1 (PDF)
Typeset in India by MPS Limited
Printed in the UK by CPI Group (UK) Ltd, Croydon

To my family, Yinghong, Guangyue and Xiang


Contents
Preface
ix
1
Introduction to nonlinear and adaptive systems
1
1.1
Nonlinear functions and nonlinearities
1
1.2
Common nonlinear systems behaviours
4
1.3
Stability and control of nonlinear systems
5
2
State space models
9
2.1
Nonlinear systems and linearisation around an operating point
9
2.2
Autonomous systems
11
2.3
Second-order nonlinear system behaviours
12
2.4
Limit cycles and strange attractors
18
3
Describing functions
25
3.1
Fundamentals
26
3.2
Describing functions for common nonlinear components
29
3.3
Describing function analysis of nonlinear systems
34
4
Stability theory
41
4.1
Basic deﬁnitions
41
4.2
Linearisation and local stability
45
4.3
Lyapunov’s direct method
46
4.4
Lyapunov analysis of linear time-invariant systems
51
5 Advanced stability theory
55
5.1
Positive real systems
55
5.2
Absolute stability and circle criterion
59
5.3
Input-to-state stability and small gain theorem
65
5.4
Differential stability
71
6
Feedback linearisation
75
6.1
Input–output linearisation
75
6.2
Full-state feedback linearisation
83
7 Adaptive control of linear systems
89
7.1
MRAC of ﬁrst-order systems
90
7.2
Model reference control
94
7.3
MRAC of linear systems with relative degree 1
99
7.4
MRAC of linear systems with high relatives
102
7.5
Robust adaptive control
103

viii
Nonlinear and adaptive control systems
8
Nonlinear observer design
109
8.1
Observer design for linear systems
109
8.2
Linear observer error dynamics with output injection
111
8.3
Linear observer error dynamics via direct state transformation
120
8.4
Observer design for Lipschitz nonlinear systems
122
8.5
Reduced-order observer design
127
8.6
Adaptive observer design
136
9
Backstepping design
141
9.1
Integrator backstepping
141
9.2
Iterative backstepping
144
9.3
Observer backstepping
147
9.4
Backstepping with ﬁltered transformation
152
9.5
Adaptive backstepping
159
9.6
Adaptive observer backstepping
167
10
Disturbance rejection and output regulation
175
10.1
Asymptotic rejection of sinusoidal disturbances
175
10.2
Adaptive output regulation
186
10.3
Output regulation with nonlinear exosystems
194
10.4
Asymptotic rejection of general periodic disturbances
204
11
Control applications
219
11.1
Harmonics estimation and rejection in power distribution
systems
219
11.1.1
System model
220
11.1.2
Iterative observer design for estimating frequency
modes in input
224
11.1.3
Estimation of speciﬁc frequency modes in input
232
11.1.4
Rejection of frequency modes
234
11.1.5
Example
235
11.2
Observer and control design for circadian rhythms
238
11.2.1
Circadian model
239
11.2.2
Lipschitz observer design
241
11.2.3
Phase control of circadian rhythms
243
11.3
Sampled-data control of nonlinear systems
247
11.3.1
System model and sampled-data control
249
11.3.2
Stability analysis of sampled-data systems
251
11.3.3
Simulation
260
Bibliographical Notes
263
References
268
Index
275

Preface
This book is intended for the use as a textbook at MSc and senior undergraduate
level in control engineering and related disciplines such as electrical, mechanical,
chemical and aerospace engineering and applied mathematics. It can also be used as
a reference book by control engineers in industry and research students in automation
and control. It is largely, although not entirely, based on the course unit bearing the
same name as the book title that I have been teaching for several years for the MSc
course at Control Systems Centre, School of Electrical and Electronic Engineering,
The University of Manchester. The beginning chapters cover fundamental concepts
in nonlinear control at moderate mathematical level suitable for students with a ﬁrst
degree in engineering disciplines. Simple examples are used to illustrate important
concepts, such as the difference between exponential stability and asymptotic stability.
Some advanced and recent stability concepts such as input-to-state stability are also
included, mainly as an introduction at a less-demanding mathematical level compared
with their normal descriptions in the existing books, to research students who may
encounter those concepts in literature. Most of the theorems in the beginning chapters
are introduced with the proofs, and some of the theorems are simpliﬁed with less
general scopes, but without loss of rigour. The later chapters cover several topics
which are closely related to my own research activities, such as nonlinear observer
design and asymptotic disturbance rejection of nonlinear systems. They are included
to demonstrate the applications of fundamental concepts in nonlinear and adaptive
control to MSc and research students, and to bridge the gap between a normal textbook
treatment of control concepts and that of research articles published in academic
journals. They can also be used as references for the students who are working on
the related topics. At the end of the book, applications to less traditional areas such
as control of circadian rhythms are also shown, to encourage readers to explore new
applied areas of nonlinear and adaptive control.
This book aims at a uniﬁed treatment of adaptive and nonlinear control.
It is well known that the dynamics of an adaptive control system for a linear dynamic
system with unknown parameters are nonlinear. The analysis of such adaptive sys-
tems requires similar techniques to the analysis for nonlinear systems. Some more
recent control design techniques such as backstepping relies on Lyapunov functions
to establish the stability, and they can be directly extended to adaptive control of non-
linear systems. These techniques further reduce the traditional gap between adaptive
control and nonlinear control. Therefore, it is now natural to treat adaptive control
as a part of nonlinear control systems. The foundation for linear adaptive control
and nonlinear adaptive control is the positive real lemma, which is related to passive
systems in nonlinear control and Lyapunov analysis. It is decided to use the positive

x
Nonlinear and adaptive control systems
real lemma and related results in adaptive control and nonlinear control as the
main theme of the book, together with Lyapunov analysis. Other important results
such as circle criterion and backstepping are introduced as extensions and further
developments from this main theme.
For a course unit of 15 credits on nonlinear and adaptive control at the Control
Systems Centre, I normally cover Chapters 1–4, 6 and 7, and most of the contents of
Chapter 5, and about half of the materials in Chapter 9. Most of the topics covered
in Chapters 8, 10 and 11 have been used as MSc dissertation projects and some of
them as PhD projects. The contents may also be used for an introductory course
on nonlinear control systems, by including Chapters 1–5, 8 and the ﬁrst half of
Chapter 9, and possibly Chapter 6. For a course on adaptive control of nonlinear
systems, an instructor may include Chapters 1, 2, 4, 5, 7 and 9. Chapter 8 may be
used alone as a brief introduction course to nonlinear observer design. Some results
shown in Chapters 8, 10 and 11 are recently published, and can be used as references
for the latest developments in related areas.
Nonlinear and adaptive control is still a very active research area in automation
and control, with many new theoretic results and applications continuing to merge.
I hope that the publication of this work will have a good impact, however small,
on students’ interests to the subject. I have been beneﬁted from my students, both
undergraduate and MSc students, through my teaching and other interactions with
them, in particular, their questions to ask me to explain many of the topics covered
in this book with simple languages and examples. My research collaborators and
PhD students have contributed to several topics covered in the book through joint
journal publications, whose names may be found in the references cited at the end of
the book. I would like to thank all the researchers in the area who contributed to the
topics covered in the book, who are the very people that make this subject fascinating.

Chapter 1
Introduction to nonlinear and adaptive systems
Nonlinearity is ubiquitous, and almost all the systems are nonlinear systems. Many
of them can be approximated by linear dynamic systems, and signiﬁcant amount of
analysis and control design tools can then be applied. However, there are intrinsic
nonlinear behaviours which cannot be described using linear systems, and analysis
and control are necessarily based on nonlinear systems. Even for a linear system,
if there are uncertainties, nonlinear control strategies such as adaptive control may
have to be used. In the last two decades, there have been signiﬁcant developments in
nonlinear system analysis and control design. Some of them are covered in this book.
In this chapter, we will discuss typical nonlinearities and nonlinear behaviours, and
introduce some basic concepts for nonlinear system analysis and control.
1.1
Nonlinear functions and nonlinearities
A dynamic system has its origin from dynamics in classic mechanics.The behaviour of
a dynamic system is often speciﬁed by differential equations. Variables in a dynamic
system are referred to as states, and they can be used to determine the status of a
system. Without external inﬂuences, the state variables are sufﬁcient to determine the
future status for a dynamic system. For a dynamic system described by continuous
differential equations, state variables cannot be changed instantly, and this reﬂects the
physical reality. Many physical and engineering systems can be modelled as dynamic
systems, using ordinary differential equations. Application areas of dynamic systems
have expanded rapidly to other areas such as biological systems, ﬁnancial systems,
etc. Analysis of the behaviours of dynamic systems is essential to the understanding
of various applications in many science and engineering disciplines. The behaviour
of a dynamic system may be altered by exerting external inﬂuences, and quite often
this kind of inﬂuences is based on knowledge of the current state. In this sense, the
dynamic system is controlled to achieve certain behaviours.
State variables are denoted by a vector in an appropriate dimension for conve-
nience, and the dynamic systems are described by ﬁrst-order differential equations of
the state vector. A linear dynamic system is described by
˙x = Ax + Bu
y = Cx + Du,
(1.1)

2
Nonlinear and adaptive control systems
where x ∈Rn is the state, u ∈Rm is the external inﬂuence, which is referred to as
the input, and y ∈Rs is a vector that contains the variables for measurement, which
is referred to as the output, and A ∈Rn×n, B ∈Rn×m, C ∈Rs×n and D ∈Rs×m are
matrices that may depend on time. If the system matrices A, B, C and D are constant
matrices, the system (1.1) is a linear time-invariant system. For a given input, the state
and the output can be computed using the system equation (1.1). More importantly,
the superposition principle holds for linear dynamic systems.
Nonlinear dynamic systems are the dynamic systems that contain at least one
nonlinear component, or in other words, the functions in the differential equations
contain nonlinear functions. For example we consider a Single-Input-Single-Output
(SISO) system with input saturation
˙x = Ax + Bσ(u)
y = Cx + Du,
(1.2)
where σ : R →R is a saturation function deﬁned as
σ(u) =
⎧
⎨
⎩
−1
for u < −1,
u
otherwise,
1
for u > 1.
(1.3)
The only difference between the systems (1.2) and (1.1) is the saturation function σ.
It is clear that the saturation function σ is a nonlinear function, and therefore this
system is a nonlinear system. Indeed, it can be seen that the superposition principle
does not apply, because after the input saturation, any increase in the input amplitude
does not change the system response at all.
A general nonlinear system is often described by
˙x = f (x, u, t)
y = h(x, u, t),
(1.4)
where x ∈Rn, u ∈Rm and y ∈Rs are the system state, input and output respectively,
and f : Rn × Rm × R →Rn and h : Rn × Rm × R →Rs are nonlinear functions.
Nonlinearities of a dynamic system are described by nonlinear functions. We may
roughly classify nonlinear functions in nonlinear dynamic systems into two types.
The ﬁrst type of nonlinear functions are analytical functions such as polynomials,
sinusoidal functions and exponential functions, or composition of these functions.
The derivatives of these functions exist, and their Taylor series can be used to obtain
good approximations at any points. These nonlinearities may arise from physical
modelling of actual systems, such as nonlinear springs and nonlinear resistors, or due
to nonlinear control design, such as nonlinear damping and parameter adaptation law
for adaptive control. There are nonlinear control methods such as backstepping which
requires the existence of derivatives up to certain orders.

Introduction to nonlinear and adaptive systems
3
Other nonlinearities may be described by piecewise linear functions, but with a
ﬁnite number of points where the derivatives do not exist or the functions are not even
continuous. The saturation function mentioned earlier is a piecewise linear function
that is continuous, but not smooth at the two joint points. A switch, or an idea relay,
can be modelled using a signum function which is not continuous. There may also be
nonlinearities which are multi-valued, such as relay with hysteresis, which is described
in Chapter 3 in detail. A nonlinear element with multi-valued nonlinearity returns a
single value at any instance, depending on the history of the input. In this sense,
the multi-valued nonlinearities have memory. Other single-valued nonlinearities are
memoryless.The nonlinearities described by piecewise linear functions are also called
hardnonlinearities, andthecommonhardnonlinearitiesincludesaturation, relay, dead
zone, relay with hysteresis, backlash, etc. One useful way to study hard nonlinearities
is by describing functions. Hard nonlinearities are also used in control design, for
example signum function is used in siding mode control, and saturation functions
are often introduced for control inputs to curb the peaking phenomenon for the semi-
global stability. In the following example, we show a nonlinearity that arises from
adaptive control of a linear system.
Example 1.1. Consider a ﬁrst-order linear system
˙x = ax + u,
where a is an unknown parameter. How to design a control system to ensure the
stability of the system? If a range a−< a < a+ is known, we can design a control
law as
u = −cx −a+x
with c > 0, which results in the closed-loop system
˙x = −cx + (a −a+)x.
Adaptive control can be used in the case of completely unknown a,
u = −cx −ˆax
˙ˆa = x2.
If we let ˜a = a −ˆa, the closed-loop system is described by
˙x = −cx + ˜ax
˙˜a = −x2.
This adaptive system is nonlinear, even though the original uncertain system is linear.
This adaptive system is stable, and it does need the stability theory introduced later
in Chapter 7 of the book.

4
Nonlinear and adaptive control systems
1.2
Common nonlinear systems behaviours
Many nonlinear systems may be approximated by linearised systems around operating
points, and their behaviours in close neighbourhoods can be predicted from the linear
dynamics. This is the justiﬁcation of applying linear system theory to control study,
as almost all the practical systems are nonlinear systems.
There are many nonlinear features that do not exist in linear dynamic systems,
and therefore linearised dynamic models cannot describe the behaviours associated
with these nonlinear features. We will discuss some of those nonlinear features in the
following text.
Multiple equilibrium points are common for nonlinear systems, unlike the linear
system. For example
˙x = −x + x2.
This system has two equilibria at x = 0 and x = 1. The behaviours around these equi-
librium points are very different, and they cannot be described by a single linearised
model.
Limit cycles are a phenomenon that periodic solutions exist and attract nearby
trajectories in positive or negative time. Closed curve solutions may exist for linear
systems, such as solution to harmonic oscillators. But they are not attractive to nearby
trajectories and not robust to any disturbances. Heart beats of human body can be
modelled as limit cycles of nonlinear systems.
High-orderharmonicsandsubharmonicsoccurinthesystemoutputwhensubject
to a harmonic input. For linear systems, if the input is a harmonic function, the
output is a harmonic function, with the same frequency, but different amplitude
and phase. For nonlinear systems, the output may even have harmonic functions with
fractional frequency of the input or multiples of the input frequency.This phenomenon
is common in power distribution networks.
Finite time escape can happen in a nonlinear system, i.e., the system state tends
to inﬁnity at a ﬁnite time. This will never happen for linear systems. Even for an
unstable linear system, the system state can only grow at an exponential rate. The
ﬁnite time escape can cause a problem in nonlinear system design, as a trajectory
may not exist.
Finite time convergence to an equilibrium point can happen to nonlinear systems.
Indeed, we can design nonlinear systems in this way to achieve fast convergence.
This, again, cannot happen for linear systems, as the convergence rate can only be
exponential, i.e., a linear system can only converge to its equilibrium asymptotically.
Chaos can only happen in nonlinear dynamic systems. For some class of non-
linear systems, the trajectories are bounded, but not converge to any equilibrium
or limit cycles. They may have quasi-periodic solutions, and the behaviour is very
difﬁcult to predict.
There are other nonlinear behaviours such as bifurcation, etc., which cannot
happen in linear systems. Some of the nonlinear behaviours are covered in detail in
this book, such as limit cycles and high-order harmonics. Limit cycles and chaos are

Introduction to nonlinear and adaptive systems
5
discussed in Chapter 2, and limit cycles also appear in other problems considered
in this book. High-order harmonics are discussed in disturbance rejection. When the
disturbance is a harmonic signal, the internal model for disturbance rejection has to
consider the high-order harmonics generated due to nonlinearities.
1.3
Stability and control of nonlinear systems
Nonlinear system behaviours are much more complex than those of linear systems.
The analytical tools for linear systems often cannot be applied to nonlinear systems.
For linear systems, the stability of a system can be decided by eigenvalues of system
matrix A, and obviously for nonlinear systems, this is not the case. For some nonlinear
systems, a linearised model cannot be used to determine the stability even in a very
small neighbourhood of the operating point. For example for a ﬁrst-order system
˙x = x3,
linearised model around the origin is ˙x = 0. This linearised model is critically stable,
but the system is unstable. In fact, if we consider another system
˙x = −x3,
which is stable, but the linearised model around the origin is still ˙x = 0. Frequency
domain methods also cannot be directly applied to analysing input–output relationship
for nonlinear systems, as we cannot deﬁne a transfer function for a general nonlinear
system.
Of course, some basic concept may still be applicable to nonlinear systems,
such as controllability, but these systems are often in different formulation and
use different mathematical tools. Frequency response method can be applied to
analysing a nonlinear system with one nonlinear component based on approximation
in frequency domain using describing function method. High gain control and zero
dynamics for nonlinear systems originate from their counterparts in linear systems.
One important concept that we need to address is stability. As eigenvalues are
no longer a suitable method for nonlinear systems, stability concepts and methods
to check stability for nonlinear systems are necessary. Among various deﬁnition,
Lyapunov stability is perhaps the most fundamental one. It can be checked by using a
Lyapunov function for stability analysis. Some of the other stability concepts such as
input-to-state stability may also be interpreted using Lyapunov functions. Lyapunov
functions can also provide valid information in control design. Lyapunov stability
will be the main stability concept used in this book.
Compared with the stability concepts of nonlinear systems, control design meth-
ods for nonlinear systems are even more diversiﬁed. Unlike control design for linear
systems, there is a lack of systematic design methods for nonlinear systems. Most of
the design methods can only apply to speciﬁc classes of nonlinear systems. Because
of this, nonlinear control is often more challenging and interesting. It is impossible
for the author to cover all the major areas of nonlinear control design and analysis,
partially to author’s knowledge base, and partially due to the space constraint.

6
Nonlinear and adaptive control systems
People often start with linearisation of a nonlinear system. If the control design
based on a linearised model works, then there is no need to worry about nonlinear
control design. Linearised models depend on operating points, and a switching strat-
egy might be needed to move from one operating point to the others. Gain scheduling
and linear parameter variation (LPV) methods are also closely related to linearisation
around operating points.
Linearisation can also be achieved for certain class of nonlinear systems through
a nonlinear state transformation and feedback. This linearisation is very much differ-
ent from linearisation around operating points. As shown later in Chapter 6, a number
of geometric conditions must be satisﬁed for the existence of such a nonlinear trans-
formation. The linearisation obtained in this way works globally in the state space,
not just at one operating point. Once the linearised model is obtained, further control
design can be carried out using design methods for linear systems.
Nonlinear functions can be approximated using artiﬁcial neuron networks, and
fuzzy systems and control methods have been developed using these approximation
methods. The stability analysis of such systems is often similar to Lyapunov function-
based design method and adaptive control. We will not cover them in this book. Other
nonlinear control design methods such as band–band control and sliding mode control
are also not covered.
In the last two decades, there were developments for some more systematic
controldesignmethods, suchasbacksteppingandforwarding.Theyrequirethesystem
to have certain structures so that these iterative control designs can be carried out.
Among them, backstepping method is perhaps the most popular one. As shown in
Chapter 9 in the book, it requires the system state space function in a sort of lower-
triangular form so that at each step a virtual control input can be designed. Signiﬁcant
amount of coverage of this topic can be found in this book. Forwarding control design
can be interpreted as a counterpart of backstepping in principle, but it is not covered
in this book.
When there are parametric uncertainties, adaptive control can be introduced to
tackle the uncertainty. As shown in a simple example earlier, an adaptive control sys-
tem is nonlinear, even for a linear system. Adaptive technique can also be introduced
together with other nonlinear control design methods, such as backstepping method.
In such a case, people often give it a name, adaptive backstepping. Adaptive control
for linear systems and adaptive backstepping for nonlinear systems are covered in
details in Chapter 7 and Chapter 9 in this book.
Similar to linear control system design, nonlinear control design methods can
also be grouped as state-feedback control design and output-feedback control design.
The difference is that the separation principle is not valid for nonlinear control design
in general, that is if we replace the state in the control input by its estimate, we would
not be able to guarantee the stability of the closed-loop system using state estimate.
Often state estimation must be integrated in the control design, such as observer
backstepping method.
State estimation is an important topic for nonlinear systems on its own. Over the
last three decades, various observer design methods have been introduced. Some of
them may have their counterparts in control design. Design methods are developed

Introduction to nonlinear and adaptive systems
7
for different nonlinearities. One of them is for systems with Lipschitz nonlinearity,
as shown in Chapter 8. A very neat nonlinear observer design is the observer design
with output injection, which can be applied to a class of nonlinear systems whose
nonlinearities are only of the system output.
In recent years, the concept of semi-global stability is getting more popular.
Semi-global stability is not as good as global stability, but the domain of attraction
can be as big as you can specify. The relaxation in the global domain of attraction does
give control design more freedom in choosing control laws. One common strategy is
to use high gain control together with saturation. We will not cover it in this book,
but the design methods in semi-global stability can be easily followed once a reader
is familiar with the control design and analysis methods introduced in this book.


Chapter 2
State space models
The nonlinear systems under consideration in this book are described by differential
equations. In the same way as for linear systems, we have system state variables, inputs
and outputs. In this chapter, we will provide basic deﬁnitions for state space models of
nonlinear systems, and tools for preliminary analysis, including linearisation around
operating points. Typical nonlinear behaviours such as limit cycles and chaos will
also be discussed with examples.
2.1
Nonlinear systems and linearisation around
an operating point
A system is called a dynamic system if its behaviours depend on its history. States
of a system are the variables that represent the information of history. At any time
instance, the current state value decides the system’s future behaviours. In this sense,
the directives of the state variables decide the system’s behaviours, and hence we
describe a dynamic system by a set of ﬁrst-order differential equations in vector
form as
˙x = f (x, u, t),
x(0) = x0,
(2.1)
where x ∈Rn is the state of the system, f : Rn →Rn is a continuous function and
u ∈Rm denotes the external inﬂuence, which is usually referred to as the input to the
system.
For the differential equation (2.1) to exist as a unique solution for a given initial
condition, we need to impose a restriction on the nonlinear function f that f must be
Lipschitz with respect to the variable x. The deﬁnition of Lipschitz condition is given
below.
Deﬁnition 2.1. A function f : Rn × Rm × R →Rn is Lipschitz with a Lipschitz
constant γ if for any vectors x, ˆx ∈Dx ⊂Rn, and u ∈Du ⊂Rm and t ∈It ⊂R, with
Dx, Du being the regions of interest and It being an time interval,
∥f (x, u, t) −f (ˆx, u, t)∥≤γ ∥x −ˆx∥,
(2.2)
with γ > 0.
Note that Lipschitz condition implies continuity with respect to x. The existence
and uniqueness of a solution for (2.1) are guaranteed by the function f being Lipschitz
and being continuous with respect to t.

10
Nonlinear and adaptive control systems
Remark 2.1. The continuity of f with respect to t and state variable x might be
stronger than we have in real applications. For example, a step function is not con-
tinuous in time. In the case that there are ﬁnite number of discontinuities in a given
interval, we can solve the equation of a solution in each of the continuous region, and
join them together. There are situations of discontinuity with state variable, such as
an ideal relay. In such a case, the uniqueness of the solution can be an issue. Further
discussion on this is beyond the scope of this book. In the systems considered in
the book, we would assume that there would be no problem with the uniqueness of
a solution.
◁
The system state contains the whole information of the behaviour. However,
for a particular application, only a subset of the state variables or a function of state
variables is of interest, which can be denoted as y = h(x, u, t) with h : Rn × Rm ×
R →Rs, normally with s < n. We often refer to y as the output of the system. To
write them together with the system dynamics, we have
˙x = f (x, u, t),
x(0) = x0
y = h(x, u, t).
In this book, we mainly deal with time-invariant systems. Hence, we can drop the
variable t in f and h and write the system as
˙x = f (x, u),
x(0) = x0
y = h(x, u),
(2.3)
where x ∈Rn is the state of the system, y ∈Rs and u ∈Rm are the output and the
input of the system respectively, and f : Rn × Rm →Rn and h : Rn × Rm →Rs are
continuous functions.
Nonlinear system dynamics are much more complex than linear systems in
general. However, when the state variables are subject to small variations, we would
expect the behaviours for small variations to be similar to linear systems, based on
the fact that
f (x + δx, u + δu) ≈f (x, u) + ∂f
∂x (x, u)δx + ∂f
∂u(x, u)δu,
when δx and δu are very small.
An operating point at (xe, ue) is taken with x = xe and u = ue being constants
such that f (xe, ue) = 0. A linearised model around the operation point can then be
obtained. Let
¯x = x −xe,
¯u = u −ue,
¯y = h(x, u) −h(xe, ue),
then the linearised model is given by

State space models
11
˙¯x = A¯x + B¯u
¯y = C¯x + D¯u,
(2.4)
where A ∈Rn×n, B ∈Rn×m, C ∈Rs×n, D ∈Rs×m matrices with elements ai,j, bi,j, ci,j
and di,j respectively shown by, assuming that f and h are differentiable,
ai,j = ∂fi
∂xj
(xe, ue),
bi,j = ∂fi
∂uj
(xe, ue),
ci,j = ∂hi
∂xj
(xe, ue),
di,j = ∂hi
∂uj
(xe, ue).
Remark 2.2. For a practical system, a control input can keep the state in an equilib-
rium point, i.e., at a point such that ˙x = 0, and therefore it is natural to look at the
linearisation around this point. However, we can obtain linearised model at points that
are not at equilibrium. If (xe, ue) is not an equilibrium point, we have f (xe, ue) ̸= 0.
We can carry out the linearisation in the same way, but the resultant linearised system
is given by
˙¯x = A¯x + B¯u + d
¯y = C¯x + D¯u,
where d = f (xe, ue) is a constant vector.
◁
2.2
Autonomous systems
For a system in (2.3), the external inﬂuence can only be exerted through the input u.
If a system does not take any input, its future state only depends on the initial state.
It means that the system is not inﬂuenced by external factors, and the behaviours are
completely determined by the system state. Such a system is often referred to as an
autonomous system. A deﬁnition is given below.
Deﬁnition 2.2. An autonomous system is a dynamic system whose behaviour does
not explicitly depend on time.
In terms of differential equations, an autonomous system can be expressed as
˙x = f (x),
(2.5)
where x ∈Rn is the state of the system, and f : Rn →Rn.

12
Nonlinear and adaptive control systems
Remark 2.3. It is easy to see that for a system in (2.3), if the control input remains
constant, then it is an autonomous system. We only need to re-deﬁne the function f as
fa(x) := f (x, uc) where uc is a constant input. Even if the inputs are polynomials and
sinusoidal functions of time, we can convert the system to the autonomous system by
modelling the sinusoidal and polynomial functions as the state variables of a linear
dynamic system, and integrate this system into the original system. The augmented
system is then an autonomous system.
◁
Deﬁnition 2.3. For an autonomous system (2.5), a point xe ∈Rn is a singular point
if f (xe) = 0.
It is easy to see that singular points are equilibrium points. Singular points are
more preferred for autonomous systems, especially for second-order systems.
Since autonomous system do not have external input, the set of all the tra-
jectories provides a complete geometrical representation of the dynamic behaviour.
This is often referred to as the phase portrait, especially for second-order systems
in the format
˙x1 = x2
˙x2 = φ(x1, x2).
In the above system, if we interpret x1 as the displacement, then x2 is the velocity. The
state variables often have clear physical meanings. Phase portraits can be obtained by
a number of methods, including analysing the behaviours near the singular points. In
fact, singular points might get the name from their positions in the phase portrait. In a
phase portrait, the lines usually do not intercept each other due to the uniqueness of the
solutions. However, they meet at the points where f (x) = 0, seemingly intercepting
each other. Those points are singular in this sense.
2.3
Second-order nonlinear system behaviours
For a second-order system, we can write the system equation as
˙x1 = f1(x1, x2)
˙x2 = f2(x1, x2).
For an equilibrium point (x1e, x2e), the linearised model is given by
 ˙¯x1
˙¯x2

= Ae
 ¯x1
¯x2

,
(2.6)
where
Ae =
⎡
⎢⎢⎣
∂f1
∂x1
(x1e, x2e)
∂f1
∂x2
(x1e, x2e)
∂f2
∂x1
(x1e, x2e)
∂f2
∂x2
(x1e, x2e)
⎤
⎥⎥⎦.

State space models
13
Therefore, the behaviour about this equilibrium or singular point is determined by
the properties of matrix Ae. Based on the eigenvalues of Ae, we can classify the
singular points in the following six different cases. We use λ1 and λ2 to denote the
two eigenvalues of Ae.
Stable node, for λ1 < 0, λ2 < 0. This is a case when both eigenvalues are negative
real numbers. The linearised model is stable, and a typical phase portrait around this
singular point is shown below.
x1
x2
Stable node
Unstable node, for λ1 > 0, λ2 > 0.This singular point is unstable, and the trajectories
diverge from the point, but not spiral around it.
x1
x2
Unstable node
Saddle point, for λ1 < 0, λ2 > 0. With one positive and one negative eigenvalues, the
hyperplane in three dimensions may look like a saddle. Some trajectories converge
to the singular point, and others diverge, depending on the directions of approaching
the point.
x1
x2
Saddle point
Stable focus, for λ1,2 = μ ± jν, (μ < 0). With a negative real part for a pair of con-
jugate poles, the singular point is stable. Trajectories converge to the singular point,

14
Nonlinear and adaptive control systems
spiralling around. In time domain, the solutions are similar to decayed sinusoidal
functions.
x1
x2
Stable focus
Unstable focus, for λ1,2 = μ ± jν, (μ > 0). The real part is positive, and therefore
the singular point is unstable, with the trajectories spiralling out from the singular
point.
x1
x2
Unstable focus
Centre, for λ1,2 = ±jν, (ν > 0). For the linearised model, when the real part is zero,
the norm of the state is constant. In phase portrait, there are closed orbits around the
singular point.
x1
x2
Centre
To draw a phase portrait, the analysis of singular points is the ﬁrst step. Based
on the classiﬁcation of the singular points, the behaviours in neighbourhoods of these
points are more or less determined. For other regions, we can calculate the directions
of the movement from the directives.
At any point, the slope of trajectory can be computed by
dx2
dx1
= f2(x1, x2)
f1(x1, x2).

State space models
15
With enough points in the plane, we should be able to sketch phase portraits connect-
ing the points in the directions determined by the slopes.
Indeed, we can even obtain curves with constant slopes, which are named as
isoclines.An isocline is a curve on which (f2(x1, x2)/f1(x1, x2)) is constant. This, again,
can be useful in sketching a phase portrait for a second-order nonlinear system.
It should be noted that modern computer simulation can provide accurate solu-
tions to many nonlinear differential equations. For this reason, we will not go to
further details of drawing phase portraits based on calculating slope of trajectories
and isoclines.
Example 2.1. Consider a second-order nonlinear system
˙x1 = x2
˙x2 = −x2 −2x1 + x2
1.
Setting
0 = x2,
0 = −x2 −2x1 + x2
1,
we obtain two singular points (0, 0) and (−2, 0).
Linearised system matrix for the singular point (0, 0) is obtained as
A =
 0
1
−1
−2

,
and the eigenvalues are obtained as λ1 = λ2 = −1. Hence, this singular point is a
stable node.
For the singular point (−2, 0), the linearised system matrix is obtained as
A =
 0
1
2
−1

,
and the eigenvalues are λ1 = −2 and λ2 = 1. Hence, this singular point is a saddle
point. It is useful to obtain the corresponding eigenvectors to determine which direc-
tion is converging and which is diverging. The eigenvalues v1 and v2, for λ1 = −2
and λ2 = 1, are obtained as
v1 =
 1
−2

,
v2 =
 1
1

This suggests that along the direction of v1, relative to the singular point, the state
converges to the singular point, while along v2, the state diverges. We can clearly
see from Figure 2.1 that there is a stable region near the singular point (0, 0).
However, in the neighbourhood of (−2, 1) one part of it is stable, and the other part
is unstable.
◁

16
Nonlinear and adaptive control systems
−4
−3
−2
−1
0
1
2
3
−4
−3.5
−3
−2.5
−2
−1.5
−1
−0.5
0
0.5
1
x1
x2
Figure 2.1
Phase portrait of Example 2.1
Example 2.2. Consider the swing equation of a synchronous machine
H ¨δ = Pm −Pe sin (δ),
(2.7)
where H is the inertia, δ is the rotor angle, Pm is the mechanical power and Pe is the
maximum electrical power generated. We may view Pm as the input and Pe sin δ as
the output. For the convenience of presentation, we take H = 1, Pm = 1 and Pe = 2.
The state space model is obtained by letting x1 = δ and x2 = ˙δ as
˙x1 = x2
˙x2 = 1 −2 sin (x1).
For the singular points, we obtain
x1e = 1
6π or 5
6π,
x2e = 0.
Note that there are an inﬁnite number of singular points, as x1e = 2kπ + 1
6π and
x1e = 2kπ + 5
6π are also solutions for any integer value of k.

State space models
17
Let us concentrate on the analysis of the two singular points ( 1
6π, 0) and ( 5
6π, 0).
The linearised system matrix is obtained as
A =

0
1
−2 cos (x1e)
0

.
For ( 1
6π, 0), the eigenvalues are λ1,2 = ±31/4j, and therefore this singular point it a
centre.
For ( 5
6π, 0), the eigenvalues are λ1 = −31/4 and λ2 = 31/4. Hence, this singular
point it a saddle point. The eigenvalues v1 and v2, for λ1 = −31/4 and λ2 = 31/4, are
obtained as
v1 =

1
−31/4

,
v2 =
 1
31/4

.
−2
0
2
4
6
8
−3
−2
−1
0
1
2
3
x1
x2
Figure 2.2
Phase portrait of Example 2.2
Figure 2.2 shows a phase portrait obtained from computer simulation. The centre at
( 1
6π, 0) and the saddle point at ( 5
6π, 0) are clearly shown in the ﬁgure. The directions
of the ﬂow can be determined from the eigenvectors of the saddle point. For example
the trajectories start from the points around (5, −3) and move upwards and to the left,
along the direction pointed by the eigenvector v1 towards the saddle point. Along the
direction pointed by v2, the trajectories depart from the saddle point.
◁

18
Nonlinear and adaptive control systems
2.4
Limit cycles and strange attractors
Some trajectories appear as closed curves in phase portrait. For autonomous systems,
they represent periodic solutions, as the solutions only depend on the states, and they
are referred to as cycles. For linear systems, periodic solutions appear in harmonic
oscillators. For example a harmonic oscillator described by
˙x1 = x2
˙x2 = −x1
has solutions as sinusoidal functions, and the amplitude is determined by the initial
values. It is easy to see that the function V = x2
1 + x2
2 remains a constant, as we have
˙V = 2x1(−x2) + 2x2x1 = 0.
Therefore, the solutions of this oscillator are circles around the origin. For a given
initial state, the radius does not change. When two initial points are very close, their
solutions will be very close, but they will not converge to one cycle, no matter how
close the initial values. Also the solution for this harmonic oscillator is not robust, as
any small disturbance will destroy the cycle.
There are cycles in the phase portrait shown in Figure 2.2. Even though they are
solutions to a nonlinear dynamic system, they are similar to the cycles obtained from
the harmonic oscillator in the sense that cycles depend on the initial values and they
do not converge or attract to each other, no matter how close the two cycles are.
The cycles discussed above are not limit cycles. For limit cycles we have the
following deﬁnition.
Deﬁnition 2.4. A closed curve solution, or in other word, a cycle, of an autonomous
system is a limit cycle, if some non-periodic solutions converge to the cycle as t →∞
or t →−∞.
A limit cycle is stable if nearby trajectories converge to it asymptotically, unstable
if move away. One property of a limit cycle is that amplitude of the oscillation may
not depend on the initial values. A limit cycle may be attractive to the nearby region.
One of the most famous ones is van der Pol oscillator. This oscillator does have a
physical meaning. It can be viewed as a mathematical model of an RLC circuit, with
the resistor being possible to take negative values in certain regions.
Example 2.3. One form of van der Pol oscillator is described in the following
differential equation:
¨y −ϵ(1 −y2)˙y + y = 0,
(2.8)
where ϵ is a positive real constant.
If we take x1 = y and x2 = ˙y, we obtain the state space equation
˙x1 = x2
˙x2 = −x1 + ϵ(1 −x2
1)x2.

State space models
19
From this state space realisation, it can be seen that when ϵ = 0, van der Pol oscillator
is the same as a harmonic oscillator. For ϵ with small values, one would expect that
it behaves like a harmonic oscillator.
A more revealing state transformation for ϵ with big values is given by
x1 = y
x2 = 1
ϵ ˙y + f (y),
where f (y) = y3/3 −y. Under the above transformation, we have the system as
˙x1 = ϵ(x2 −f (x1))
˙x2 = −1
ϵ x1.
(2.9)
It can be obtained that
dx2
dx1
(x2 −f (x1)) = x1
ϵ2
(2.10)
This equation suggests that as ϵ →∞, we have dx2
dx1 = 0 or x2 = f (x1). This can be
seen from the phase portrait for very big values of ϵ in Figure 2.4.
Let us stick with the state space model (2.9). The only singular point is at the
origin (0, 0). The linearised system matrix at the origin is obtained as
A =
 ϵ
1
−1
ϵ
0

.
From the eigenvalues of A, we can see that this singular point is either an unstable
node or an unstable focus, depending on the value of ϵ. Phase portrait of van der
Pol oscillator with ϵ = 1 is shown in Figure 2.3 for two trajectories, one with initial
condition outside the limit cycle and one from inside. The broken line shows x2 =
f (x1). Figure 2.4 shows the phase portrait with ϵ = 10. It is clear from Figure 2.4 that
the trajectory sticks with the line x2 = f (x1) along the outside and then moves almost
horizontally to the other side, as predicted in the analysis earlier.
◁
Limit cycles also exist in high-order nonlinear systems. As seenlater in Chap-
ter 11, circadian rhythms can also be modelled as limit cycles of nonlinear dynamic
systems. For second-order autonomous systems, limit cycles are very typical trajec-
tories. The following theorem, Poincare–Bendixson theorem, describes the features
of trajectories of the second-order systems, from which a condition on the existence
of a limit cycle can be drawn.
Theorem 2.1. If a trajectory of the second-order autonomous system remains in a
ﬁnite region, then one of the following is true:

20
Nonlinear and adaptive control systems
−2.5
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
2.5
−3
−2
−1
0
1
2
3
x1
x2
Figure 2.3
Phase portrait of van der Pol oscillator with ϵ = 1
−2.5
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
2.5
−3
−2
−1
0
1
2
3
x2
x1
Figure 2.4
Phase portrait of van der Pol oscillator with ϵ = 10

State space models
21
●
The trajectory goes to an equilibrium point.
●
The trajectory tends to an asymptotically stable limit cycle.
●
The trajectory is itself a cycle.
For high-order nonlinear systems, there are more complicated features if the
trajectories remain in a bounded region. For the asymptotic behaviours of dynamic
systems, we deﬁne positive limit sets.
Deﬁnition 2.5. Positive limit set of a trajectory is the set of all the points for which
the trajectory converges to, as t →∞.
Positive limit sets are also referred to as ω-limit sets, as ω is the last letter of
Greek letters. Similarly, we can deﬁne negative limit sets, and they are called α-limit
sets accordingly. Stable limit cycles are positive limit sets, so do stable equilibrium
points. The dimension for ω-limit sets is zero or one, depending on singular points or
limit cycles.
Strange limit sets are those limit sets which may or may not be asymptotically
attractive to the neighbouring trajectories. The trajectories they contain may be locally
divergent from each other, within the attracting set. Their dimensions might be frac-
tional. Such structures are associated with the quasi-random behaviour of solutions
called chaos.
Example 2.4. The Lorenz attractor. This is one of the most widely studied examples
of strange behaviour in ordinary differential equations, which is originated from
studies of turbulent convection by Lorenz. The equation is in the form
˙x1 = σ(x2 −x1)
˙x2 = (1 + λ −x3)x1 −x2
˙x3 = x1x2 −bx3,
(2.11)
where σ, λ and b are positive constants. There are three equilibrium points (0, 0, 0),
(
√
bλ,
√
bλ, λ) and (−
√
bλ, −
√
bλ, λ).The linearised system matrix around the origin
is obtained as
A =
⎡
⎣
−σ
σ
0
λ + 1
−1
0
0
0
−b
⎤
⎦,
and its eigenvalues are obtained as λ1,2 = −(σ −1) ±

(σ −1)2 + 4σλ/2 and
λ3 = −b. Since the ﬁrst eigenvalue is positive, this equilibrium is unstable. It can
be shown that the other equilibrium points are unstable when the parameters satisﬁes
σ > b + 1,
λ > (σ + 1)(σ + b + 1)
σ −b −1
.

22
Nonlinear and adaptive control systems
−15
−10
−5
0
5
10
15
−20
−10
0
10
20
0
5
10
15
20
25
30
35
x1
x2
x3
Figure 2.5
A typical trajectory of Lorenz attractor
−15
−10
−5
0
5
10
15
−20
−15
−10
−5
0
5
10
15
20
x1
x2
Figure 2.6
Projection to (x1, x2)

State space models
23
−15
−10
−5
0
5
10
15
0
5
10
15
20
25
30
35
x1
x3
Figure 2.7
Projection to (x1, x3)
0
20
40
60
80
100
−15
−10
−5
0
5
10
15
x1
Time (s)
Figure 2.8
Time trajectory of x1

24
Nonlinear and adaptive control systems
It can be established that the trajectories converge to a bounded region speciﬁed by
(λ + 1)x2
1 + σx2
2 + σ(x3 −2(λ + 1))2 ≤C
for a positive constant C. When all the three equilibria are unstable, the behaviour of
Lorenz system is chaotic. A trajectory is plotted in Figure 2.5 for b = 2, σ = 10 and
λ = 20. Projections to (x1, x2) and (x1, x3) are shown in Figures 2.6 and 2.7. The time
trajectory of x1 is shown in Figure 2.8.
◁

Chapter 3
Describing functions
In classical control, frequency response is a powerful tool for analysis and control
design of linear dynamic systems. It provides graphical presentation of system dynam-
ics and often can reﬂect certain physical features of engineering systems. The basic
concept of frequency response is that for a linear system, if the input is a sinusoidal
function, the steady-state response will still be a sinusoidal function, but with a
different amplitude and a different phase. The ratio of the input and output ampli-
tudes and the difference in the phase angles are determined by the system dynamics.
When there is a nonlinear element in a control loop, frequency response methods
cannot be directly applied. When a nonlinear element is a static component, i.e., the
input and output relationship can be described by an algebraic function, its output
to any periodic function will be a periodic function, with the same period as the
input signal. Hence, the output of a static nonlinear element is a periodic function
when the input is a sinusoidal function. It is well known that any periodic func-
tion with piece-wise continuity has its Fourier series which consists of sinusoidal
functions with the same period or frequency as the input with a constant bias, and
other sinusoidal functions with high multiple frequencies. If we take the term with
the fundamental frequency, i.e., the same frequency as the input, as an approxima-
tion, the performance of the entire dynamic system may be analysed using frequency
response techniques. Describing functions are the frequency response functions of
nonlinear components with their fundamental frequency terms as their approximate
outputs. In this sense, describing functions are ﬁrst-order approximation in frequency
domain. It can also be viewed as a linearisation method in frequency domain for
nonlinear components.
Describing function analysis remains as an important tool for analysis of non-
linear systems with static components despite several more recent developments in
nonlinear control and design. It is relatively easy to use, and closely related to fre-
quency response analysis of linear systems. It is often used to predict the existence
of limit cycles in a nonlinear system, and it can also be used for prediction of subhar-
monics and jump phenomena of nonlinear systems. In this chapter, we will present
basic concept of describing functions, calculation of describing functions of common
nonlinear elements and how to use describing functions to predict the existence of
limit cycles.

26
Nonlinear and adaptive control systems
3.1
Fundamentals
For a nonlinear component described by a nonlinear function f : R →R, its
f(x)
A sin(wt)
w(t)
output
w(t) = f (A sin(ωt))
to a sinusoidal input A sin (ωt) is a periodical function, although it may not be sinu-
soidal in general. Assuming that the function f is piecewise-continuous, w(t) is a
piecewise-continuous periodic function with the same period as the input signal. A
piecewise periodical function can be expanded in Fourier series
w(t) = a0
2 +
∞

n=1
(an cos(nωt) + bn sin(nωt)),
(3.1)
where
a0 = 1
π
 π
−π
w(t)d(ωt)
an = 1
π
 π
−π
w(t) cos(nωt)d(ωt)
bn = 1
π
 π
−π
w(t) sin(nωt)d(ωt).
Remark 3.1. For a piecewise-continuous function w(t), the Fourier series on the
right-hand side of (3.1) converges to w(t) at any continuous point, and to the average
of two values obtained by taking limits from both sides at a dis-continuous point. If
we truncate the series up to order k,
wk(t) = a0
2 +
k

n=1
(an cos(nωt) + bn sin(nωt)),
where wk is the best approximation in least squares, i.e., in L2.
◁
Taking the approximation to the ﬁrst order, we have
w1 = a0
2 + a1 cos(ωt) + b1 sin(ωt).
If a0 = 0, which can be guaranteed by setting the nonlinear function f to an odd
function, we have the approximation
w1 = a1 cos(ωt) + b1 sin(ωt)
(3.2)
which is an approximation at the fundamental frequency. The above discussion shows
that for a nonlinear component described by the nonlinear function f , the approxima-
tion at the fundamental frequency, i.e., the frequency of the input signal, to an input

Describing functions
27
signal A sin(ωt), is a sinusoidal function in (3.2) with the Fourier coefﬁcients a1 and
b1 shown in (3.1). Hence, we can analyse the frequency response of this nonlinear
component.
We can rewrite w1 in (3.2) as
w1 = M sin(ωt + φ),
(3.3)
where
M(A, ω) =

a2
1 + b2
1,
φ(A, ω) = arctan(a1/b1).
In complex expression, we have
w1 = Mej(ωt+φ) = (b1 + ja1)ejωt.
The describing function is deﬁned, similar to frequency response, as the complex ratio
of the fundamental component of the nonlinear element against the input by
N(A, ω) = Mejωt+φ
Aejωt
= b1 + ja1
A
.
(3.4)
Remark 3.2. A clear difference between the describing function of a nonlinear ele-
ment and the frequency response of a linear system is that the describing function
depends on the input amplitude. This reﬂects the nonlinear nature of the describing
function.
◁
Remark 3.3. If f is a single-valued odd function, i.e., f (−x) = f (x), we have
a1 = 1
π
 π
−π
f (A sin(ωt)) cos(ωt)d(ωt)
= 1
π
 0
−π
f (A sin(ωt) cos(ωt)d(ωt) + 1
π
 π
0
f (A sin(ωt) cos(ωt)d(ωt)
= 1
π
 π
0
f (A sin(−ωt) cos(−ωt)d(ωt) + 1
π
 π
0
f (A sin(ωt) cos(ωt)d(ωt)
= 0.
If a1 = 0, the describing function is a real value.
◁
Example 3.1. The characteristics of a hardening spring are given by
f (x) = x + x3
2 .
Given the input A sin(ωt), the output is
w(t) = f (A sin(ωt))
= A sin(ωt) + A3
2 sin3(ωt).

28
Nonlinear and adaptive control systems
Since f is an odd function, we have a1 = 0. The coefﬁcient b1 is given by
b1 = 1
π
 π
−π

A sin(ωt) + A3
2 sin3(ωt)

sin(ωt)d(ωt)
= 4
π
 π/2
0

A sin2(ωt) + A3
2 sin4(ωt)

d(ωt).
Using the integral identity
 π/2
0
sinn(ωt)d(ωt) = n −1
n
 π/2
0
sinn−2(ωt)d(ωt)
for n > 2,
we have
b1 = A + 3
8A3.
Therefore, the describing function is
N(A, ω) = N(A) = b1
A = 1 + 3
8A2.
Alternatively, we can also use the identity
sin(3ωt) = 3 sin(ωt) −4 sin3(ωt)
to obtain
w(t) = A sin(ωt) + A3
2 sin3(ωt)
= A sin(ωt) + A3
2
3
4 sin(ωt) −1
4 sin(3ωt)

=

A + 3
8A3

sin(ωt) −1
8A3 sin(3ωt).
Hence, we obtain b1 = A + 3
8A3 from the ﬁrst term.
◁
Through the above discussion, describing functions are well deﬁned for nonlinear
components whose input–output relationship can be well deﬁned by piecewise-
continuous functions. These functions are time-invariant, i.e., the properties of
nonlinear elements do not vary with time. This is in line with the assumption for fre-
quency response analysis, which can only be applied to time-invariant linear systems.
We treat describing functions as the approximations at the fundamental frequencies,
and therefore in our analysis, we require a0 = 0 which is guaranteed by odd functions
for the nonlinear components. With the describing function of a nonlinear compo-
nent, we can then apply analysis in frequency responses for the entire system. For the
convenience of this kind of analysis, we often assume that the nonlinear component
for which the describing function is used to approximate its behaviours is the only

Describing functions
29
r
x
w
y
f(x)
G(s)
Σ
–
+
Figure 3.1
Block diagram for describing function analysis
nonlinear component in the system, as shown in Figure 3.1. Hence, in the remain-
ing part of this chapter, we use the following assumptions for describing function
analysis:
●
There is only a single nonlinear component in the entire system.
●
The nonlinear component is time-invariant.
●
The nonlinearity is odd.
3.2
Describing functions for common nonlinear components
In this section, we will calculate the describing functions of common nonlinear
elements in a number of examples.
Example 3.2. Saturation. A saturation function shown in Figure 3.2 is described by
f (x) =
	
kx,
for |x| < a,
sign(x)ka,
otherwise.
(3.5)
The output to the input A sin(ωt), for A > a, is symmetric over quarters of a period,
and in the ﬁrst quarter,
f(x)
a
–a
x
Figure 3.2
Saturation
w(t) =
	
kA sin(ωt),
0 ≤ωt ≤γ ,
ka,
γ < ωt ≤π/2,
(3.6)
where γ = sin−1(a/A). The function is odd, hence we have a1 = 0, and the symmetry
of w1(t) implies that

30
Nonlinear and adaptive control systems
b1 = 4
π
 π/2
0
w1 sin(ωt)d(ωt)
= 4
π
 γ
0
kA sin2(ωt)d(ωt) + 4
π
 π/2
γ
ka sin(ωt)d(ωt)
= 2kA
π

γ −1
2 sin(2γ )

+ 4ka
π cos(γ )
= 2kA
π

γ −a
A cos(γ )

+ 4ka
π cos(γ )
= 2kA
π

γ + a
A cos(γ )

= 2kA
π

γ + a
A

1 −a2
A2

.
Note that we have used sin γ = a
A and cos γ =

1 −a2
A2 . Therefore, the
describing function is given by
N(A) = b1
A = 2k
π

sin−1 a
A + a
A

1 −a2
A2

.
(3.7)
◁
Example 3.3. Ideal relay. The output from the ideal relay shown in Figure 3.3
(signum function) is described by, with M > 0,
w(t) =
	
−M,
−π ≤ωt < 0,
M,
0 ≤ωt < π.
(3.8)
It is again an odd function, hence we have a1 = 0. The coefﬁcient b1 is given by
b1 = 2
π
 π
0
M sin(ωt)d(ωt) = 4M
π
f(x)
x
M
–M
Figure 3.3
Ideal relay

Describing functions
31
f(x)
a
–a
x
Figure 3.4
Dead zone
and therefore the describing function is given by
N(A) = 4M
πA .
(3.9)
◁
Example 3.4. Dead zone. A dead zone is a complement to saturation. A dead zone
shown in Figure 3.4 can be described by a nonlinear function
f (x) =
⎧
⎪⎨
⎪⎩
k(x −a),
for x > a,
0,
for |x| < a,
k(x + a),
for x < −a.
(3.10)
The output to the input A sin(ωt), for A > a, is symmetric over quarters of a
period, and in the ﬁrst quarter,
w(x) =
	 0,
0 ≤ωt ≤γ ,
k(A sin(ωt) −a),
γ < ωt ≤π/2,
(3.11)
where γ = sin−1(a/A). The function is odd, hence we have a1 = 0, and the symmetry
of w(t) implies that
b1 = 4
π
 π/2
0
w(t) sin(ωt)d(ωt)
= 4
π
 π/2
γ
k(A sin(ωt) −a)d(ωt)
= 2kA
π

π
2 −γ

+ 1
2 sin(2γ )

−4ka
π cos(γ )
= kA −2kA
π

γ + a
A cos(γ )

= kA −2kA
π

γ + a
A

1 −a2
A2

.

32
Nonlinear and adaptive control systems
Similar to the calculation of the describing function for saturation, we have used
sin γ = a
A and cos γ =

1 −a2
A2 . The describing function for a dead zone is given by
N(A) = b1
A = k −2k
π

sin−1 a
A + a
A

1 −a2
A2

.
(3.12)
◁
Remark 3.4. The dead-zone function shown in (3.10) complements the saturation
function shown in (3.5) in the sense that if we use fs and fd to denote the saturation
function and dead-zone function, we have fs + fd = k for the describing functions
shown in (3.7) and (3.12), the same relationship holds.
◁
Example 3.5. Relay with hysteresis. Consider a case when there is a delay in the
ideal relay as shown in Figure 3.5. The nonlinear function for relay with hysteresis
can be described by
f (x) =
⎧
⎪⎪⎨
⎪⎪⎩
M,
for x ≥a,
−M,
for |x| < a,
˙x > 0,
M,
for |x| < a,
˙x < 0,
−M,
for x ≤−a.
(3.13)
When this nonlinear component takes A sin (ωt) as the input with A > a, the
output w(t) is given by
w(t) =
⎧
⎨
⎩
M,
for −π ≤ωt < (π −γ ),
−M,
for −(π −γ ) ≤ωt < γ ,
M,
for γ ≤ωt < π,
(3.14)
where γ = sin−1( a
A). In this case, we still have a0 = 0, but not a1. For a1 we have
f(x)
x
M
–M
Figure 3.5
Relay with hysteresis

Describing functions
33
a1 = 1
π
 −(π−γ )
−π
M cos(ωt)d(ωt) + 1
π
 γ
−(π−γ )
−M cos(ωt)d(ωt)
+ 1
π
 π
γ
M cos(ωt)d(ωt)
= −4M
π sin(γ )
= −4M
π
a
A.
Similarly, we have
b1 = 1
π
 −(π−γ )
−π
M sin(ωt)d(ωt) + 1
π
 γ
−(π−γ )
−M sin(ωt)d(ωt)
+ 1
π
 π
γ
M sin(ωt)d(ωt)
= 4M
π cos(γ )
= 4M
π

1 −a2
A2 .
From
N(A, ω) = b1 + ja1
A
,
we have
N(A) = 4M
πA

1 −a2
A2 −j a
A

.
(3.15)
Using the identity cos(γ ) + j sin(γ ) = ejr, we can rewrite the describing function as
N(A) = 4M
πA e−j arcsin(a/A).
◁
Remark 3.5. Comparing the describing function of the relay with hysteresis with
that of ideal relay in (3.9), the describing functions indicate that there is a delay in the
relay with hysteresis by arcsin(a/A) in terms of phase angle. There is indeed a delay
of γ = arcsin(a/A) in the time response w(t) shown in (3.14) with that of the ideal
relay. In fact, we could use this fact to obtain the describing function for the relay
with hysteresis.
◁

34
Nonlinear and adaptive control systems
3.3
Describing function analysis of nonlinear systems
One of the most important applications of describing functions is to predict the exis-
tence of a limit cycle in a closed-loop system that contains a nonlinear component
with a linear transfer function, as shown in Figure 3.1. Consider a system with a lin-
ear transfer function G(s) and a nonlinear element with describing function N(A, ω)
in the forward path, under unit feedback. The input–output relations of the system
component by setting r = 0 can be described by
w = N(A, ω)x
y = G(jω)w
x = −y,
with y as the output and x as the input to the nonlinear component. From the above
equations, it can be obtained that
y = G(jω)N(A, ω)(−y),
and it can be arranged as
(G(jω)N(A, ω) + 1)y = 0.
If there exists a limit cycle, then y ̸= 0, which implies that
G(jω)N(A, ω) + 1 = 0,
(3.16)
or
G(jω) = −
1
N(A, ω).
(3.17)
Therefore, the amplitude A and frequency ω of the limit cycle must satisfy the above
equation. Equation (3.17) is difﬁcult to solve in general. Graphic solutions can be
found by plotting G(jω) and −1/N(A, ω) on the same graph to see if they intersect
each other. The intersection points are the solutions, from which the amplitude and
frequency of the oscillation can be obtained.
Remark 3.6. The above discussion is based on the assumption that the oscillation,
or limit cycle, can be well approximated by a sinusoidal function, and the nonlinear
component is well approximated by its describing function. The describing function
analysis is an approximate method in nature.
◁
Only a stable limit cycle may exist in real applications. When we say stable limit
cycle, we mean that if the state deviates a little from the limit cycle, it should come
back. With the amplitude as an example, if A is perturbed from its steady condition,
say with a very small increase in the amplitude, for a stable limit cycle, the system
will decay to its steady condition.

Describing functions
35
As describing functions are ﬁrst-order approximations in the frequency domain,
stability criteria in the frequency domain may be used for the stability analysis of
limit cycles. Nyquist criterion can be extended to give the conditions for stability of
limit cycles.
Recall the case for a linear system with the forward transfer function G(s) with
unit feedback. The characteristic equation is given by
G(s) + 1 = 0, or G(s) = −1.
The Nyquist criterion determines stability of the closed-loop system from the number
of encirclements of the Nyquist plot around point −1, or (−1, 0) in the complex plain.
In the case that there is a control gain K in the forward transfer function, the
characteristic equation is given by
KG(s) + 1 = 0, or G(s) = −1
K .
In this case, the Nyquist criterion can be extended to determine the stability of the
closed loop by counting the encirclements of the Nyquist plot around (−1/K, 0) in the
complex plain in the same way as around (−1, 0). The Nyquist criterion for non-unity
forward path gain K is also referred to as the extended Nyquist criterion. The same
argument holds when k is a complex number.
We can apply the extended Nyquist criterion to determine the stability of a limit
cycle. When the condition speciﬁed in (3.17) is satisﬁed for some (A0, ω0), A0 and
ω0 are the amplitude and frequency of the limit cycle respectively, and N(A0, ω0)
is a complex number. We can use the extended Nyquist criterion to determine the
stability of the limit cycle with the amplitude A0 and frequency ω0 by considering a
perturbation of A around A0.
To simplify our discussion, let us assume that G(s) is stable and minimum phase.
It is known from the Nyquist criterion that the closed-loop system with constant
gain K is stable if the Nyquist plot does not encircle (−1/K, 0). Let us consider a
perturbation in A to A+ with A+ > A0. In such a case, −1/N(A+, ω0) is a complex
number in general. If the Nyquist plot does not encircle the point −1/N(A+, ω0), we
conclude that the closed-loop system is stable with the complex gain −1/N(A+, ω0).
Therefore, in a stable closed-loop system, the oscillation amplitude decays, which
makes A+ return to A0.This implies that the limit cycle (A0, ω0) is stable.Alternatively,
if the Nyquist plot encircles the point −1/N(A+, ω0), we conclude that the closed-
loop system is unstable with the complex gain −1/N(A+, ω0). In such a case, the
oscillation amplitude may grow even further, and does not return to A0. Therefore,
the limit cycle is unstable.
Similar arguments can be made for the perturbation to a smaller amplitude. For
an A−< A0, if the Nyquist plot does encircle the point −1/N(A−, ω0), the limit cycle
is stable. If the Nyquist plot does not encircle the point −1/N(A−, ω0), the limit cycle
is unstable.
When we plot −1/N(A, ω0) in the complex plane with A as a variable, we obtain
a line with direction of the increment of A. Based on the discussion above, the way

36
Nonlinear and adaptive control systems
Im
Re
Stable
1
–
A–
A+
N(A,w0)
G(jw)
Figure 3.6
Digram for stable limit cycle
Im
Re
Unstable
1
–
A–
A+
N(A,w0)
G(jw)
Figure 3.7
Digram for unstable limit cycle
of the line for −1/N(A, ω0) intersects with the Nyquist plot determines the stability
of the limit cycle. Typical Nyquist plots of stable minimum-phase systems are shown
in Figures 3.6 and 3.7 for stable and unstable limit cycles with nonlinear elements
respectively.
We can summarise the above discussion for the stability criterion of limit cycles
using describing function.
Theorem 3.1. Consider a unity-feedback system with the forward path with stable
minimum phase transfer function G(s) and a nonlinear component with the describing
function N(A, ω), and suppose that the plots, −1/N and G(jω) intersect at the point
with A = A0 and ω = ω0.The limit cycle at (A0, ω0) is stable if the plot of −1/N(A, ω0)
crosses the Nyquist plot from the inside of the encirclement to the outside of the
encirclement as A increases. The limit cycle at (A0, ω0) is unstable if the plot of
−1/N(A, ω0) crosses the Nyquist plot from the outside of the encirclement to the
inside of the encirclement as A increases.
Remark 3.7. Theorem 3.1 requires the transfer function to be stable and minimum
phase, for the simplicity of the presentation. This theorem can be easily extended to

Describing functions
37
the case when G(s) is unstable or has unstable zeros by using corresponding stability
conditions based on the Nyquist criterion. For example if G(s) is stable and has one
unstable zero, then the stability criterion for the limit cycle will be opposite to the
condition stated in the theorem, i.e., the limit cycle is stable if the plot of −1/N(A, ω0)
crosses the Nyquist plot from the outside of the encirclement to the inside of the
encirclement as A increases.
◁
Example 3.6. Consider a linear transfer function G(s) =
K
s(s + 1)(s + 2) with K a
positive constant and an ideal relay in a closed loop, as shown in Figure 3.8. We will
determine if there exists a limit cycle and analyse the stability of the limit cycle.
r
x
w
y
Σ
–
+
K
s(s + 1)(s + 2)
Figure 3.8
Closed-loop system for Example 3.6
For the ideal relay, we have N = 4M
πA . For the transfer function, we can
obtain that
G(jω) =
K
jω(jω + 1)(jω + 2)
= K
−3ω2 −jω(2 −ω2)
(−3ω2)2 + ω2(2 −ω2)2 .
From
G(jω) = −1
N ,
we obtain two equations for real and imaginary parts respectively as
ℑ(G(jω)) = 0,
ℜ(G(jω)) = −πA
4M .
From the equation of the imaginary part, we have
K
−ω(2 −ω2)
(−3ω2)2 + ω2(2 −ω2)2 = 0,
which gives ω =
√
2. From the equation of the real part, we have
K
−3ω2
(−3ω2)2 + ω2(2 −ω2)2 = −πA
4M ,
which gives A = 2KM/3π.

38
Nonlinear and adaptive control systems
Hence, we have shown that there exists a limit cycle with amplitude and frequency
at (A, ω) = (2KM/3π,
√
2).
The plot of −(1/N(A)) = −(πA/4M) overlaps with the negative side of the real
axis.As A increases from 0, −(1/N(A)) moves from the origin towards left.Therefore,
as A increases, −(1/N(A)) moves from inside of the encirclement of the Nyquist plot
to outside of the encirclement, and the limit cycle is stable, based on Theorem 3.1.
A simulation result for K = M = 1 is shown in Figure 3.9 with the amplitude
A = 0.22 and period T = 4.5 s, not far from the values A = 0.2212 and T = 4.4429,
predicted from the describing function analysis.
◁
Example 3.7. In this example, we consider a van der Pol oscillator described by
¨y + ϵ(3y2 −1)˙y + y = 0.
(3.18)
We will use describing function analysis to predict the existence of a limit cycle, and
compare the predicted amplitudes and periods for different ϵ values with the simulated
ones.
To use the describing analysis, we need to formulate the system in the format of
one linear transfer function and a nonlinear element. Rearranging (3.18), we have
¨y −ϵ˙y + y = −ϵ d
dt y3.
34
36
38
40
42
44
46
−0.25
−0.2
−0.15
−0.1
−0.05
0
0.05
0.1
0.15
0.2
0.25
Time (s)
y
Figure 3.9
The simulated output for Example 3.6

Describing functions
39
Hence, the system (3.18) can be described by a closed-loop system with a nonlinear
component
f (x) = x3
and a linear transfer function
G(s) =
ϵs
s2 −ϵs + 1.
Using the identity
sin(3ωt) = 3 sin(ωt) −4 sin3(ωt)
in a similar way as in Example 3.1, we obtain the describing function for
f (x) = x3 as
N(A) = 3
4A2.
Setting
ℑG(jω) = −ℑ
 1
N

= 0,
we have
ϵω(1 −ω2)
(1 −ω2)2 + ϵ2ω2 = 0,
which gives ω = 1. From the equation for the real part, we obtain
−ϵ2ω2
(1 −ω2)2 + ϵ2ω2 = −4
3A2
which gives A = 2
√
3/3.
The linear part of the transfer function has one unstable pole. We need to take
this into consideration for the stability of the limit cycle. As A increases, −1/N(A)
moves from the left to the right along the negative part of the real axis, basically
from the outside of the encirclement of the Nyquist plot to the inside of the encir-
clement. This suggests that the limit cycle is stable, as there is an unstable pole in
the linear transfer function. The simulation results for ϵ = 1 and ϵ = 30 are shown in
Figures 3.10 and 3.11. In both cases, the amplitudes are very close to the predicted
one from the describing function analysis. For the period, the simulation result for
ϵ = 1 in Figure 3.10 is very close to 2π, but the period for ϵ = 30 is much better than
2π. This suggests that the describing function analysis gives a better approximation
for the case of ϵ = 1 than ϵ = 30. In fact, for a small value of ϵ the oscillation is
very similar to a sinusoidal function. With a big value of ϵ, the wave form is very
different from a sinusoidal function, and therefore the describing function method
cannot provide a good approximation.
◁

40
Nonlinear and adaptive control systems
10
15
20
25
30
35
−1
−0.5
0
0.5
1
Time (s)
y
Figure 3.10
The simulated output for Example 3.7 with ϵ = 1
30
40
50
60
70
80
90
100
110
120
−1
−0.5
0
0.5
1
y
Figure 3.11
The simulated output for Example 3.7 with ϵ = 30

Chapter 4
Stability theory
For control systems, design, one important objective is to ensure the stability of the
closed-loop system. For a linear system, the stability can be evaluated in time domain
or frequency domain, by checking the eigenvalues of the system matrix or the poles
of the transfer function. For nonlinear systems, the dynamics of the system cannot be
described by equations in linear state space or transfer functions in general. We need
more general deﬁnitions about the stability of nonlinear systems. In this chapter, we
will introduce basic concepts of stability theorems based on Lyapunov functions.
4.1
Basic deﬁnitions
Consider a nonlinear system
˙x = f (x),
(4.1)
where x ∈D ⊂Rn is the state of the system, and f : D ⊂Rn −→Rn is a continuous
function, with x = 0 as an equilibrium point, that is f (0) = 0, and with x = 0 as an
interior point of D. Here we use D to denote a domain around the equilibrium x = 0.
This domain can be interpreted as a set with 0 as its interior point, or it can also
be simpliﬁed as D = {x|∥x∥< r} for some positive r. In the remaining part of this
chapter, we will use D in this way.
When we say the stability of the system, we refer to the behaviour of the system
around the equilibrium point. Here we assume that x = 0 is an equilibrium point
without loss of generality. In case that the system has an equilibrium point at x0, we
can always deﬁne a state transformation with x −x0 as the new state, to shift the
equilibrium point to the origin.
The system in (4.1) is referred to as an autonomous system, as it does not depend
on the signals other than the system state. For nonlinear control systems, we can write
˙x = f (x, u),
(4.2)
where u ∈Rm is the control input. With u as an external signal, the system (4.2) is
not autonomous. However, for such a system, if we design a feedback control law
u = g(x) with g : Rn −→Rm as a continuous function, the closed-loop system
˙x = f (x, g(x))
becomes an autonomous system.

42
Nonlinear and adaptive control systems
In this chapter, we will present basic deﬁnitions and results for stability of
autonomous systems. As discussed above, control systems can be converted to
autonomous systems by state feedback control laws.
There are many different deﬁnitions of stability for dynamics systems. Often
different deﬁnitions are needed for different purposes, and many of them are actually
the same when the system is linear.Among different deﬁnitions, the most fundamental
one is the Lyapunov stability.
Deﬁnition 4.1 (Lyapunov stability). For the system (4.1), the equilibrium point x = 0
is said to be Lyapunov stable if for any given positive real number R, there exists a
positive real number r to ensure that ∥x(t)∥< R for all t ≥0 if ∥x(0)∥< r. Otherwise
the equilibrium point is unstable.
x(t)
x(0)
r
R
Figure 4.1
Lyapunov stability
The deﬁnition of Lyapunov stability concerns with the behaviours of a dynamic
system with respect to the initial state. If a system is Lyapunov stable, we can impose
a restriction on the initial state of the system to make sure that the state variables stay
in a certain region. For the two positive numbers in the deﬁnition, R and r, the deﬁ-
nition did not explicitly require R ≥r. However, if we set r > R, from the continuity
of the solution, we cannot ensure ∥x(t)∥< R for t close to 0, because of ∥x(0)∥> R.
Therefore, when using this deﬁnition, we need r ≤R.
Example 4.1. Consider a linear system
˙x = Ax,
x(0) = x0,
where
A =
 0
ω
−ω
0

with ω > 0. For this linear system, we can explicitly solve the differential equation
to obtain
x(t) =
 cos ωt
sin ωt
−sin ωt
cos ωt

x0.

Stability theory
43
It is easy to check that we have ∥x(t)∥= ∥x0∥. Hence, to ensure that ∥x(t)∥≤R, we
only need to set r = R, i.e., if ∥x0∥≤R, we have ∥x(t)∥≤R for all t > 0.
◁
Note that for the system in Example 4.1, the system matrix has two eigenvalues
on the imaginary axis, and this kind of systems is referred to as critically stable in
many undergraduate texts. As shown in the example, this system is Lyapunov stable.
It can also be shown that for a linear system, if all the eigenvalues of the system
matrix A are in the closed left half of the complex plane, and the eigenvalues on the
imaginary axis are simple, the system is Lyapunov stable. However, if the system
matrix has multiple poles on the imaginary axis, the system is not Lyapunov stable.
For example let ˙x1 = x2, and ˙x2 = 0 with x1(0) = x1,0, x2(0) = x2,0. It is easy to obtain
that x1(t) = x1,0 + x2,0t and x2(t) = x2,0. If we want ∥x(t)∥≤R, there does not exist
a positive r for ∥x(0)∥≤r to guarantee ∥x(t)∥≤R. Therefore, this system is not
Lyapunov stable.
For linear systems, when a system is stable, the solution will converge to the equi-
librium point. This is not required by Lyapunov stability. For more general dynamic
systems, we have the following deﬁnition concerning with the convergence to the
equilibrium.
Deﬁnition 4.2 (Asymptotic stability). For the system (4.1), the equilibrium point
x = 0 is asymptotically stable if it is stable (Lyapunov) and furthermore limt→∞
x(t) = 0.
x(t)
x(0)
r
R
Figure 4.2
Asymptotic stability
Linear systems with poles in the open left half of the complex plane are asymp-
totically stable. The asymptotic stability only requires that a solution converges the
equilibrium point, but it does not specify the rate of convergence. In the following
deﬁnition, we specify a stability property with an exponential rate of convergence.
Deﬁnition 4.3 (Exponential stability). For the system (4.1), the equilibrium point
x = 0 is exponentially stable if there exist two positive real numbers a and λ such that
the following inequality holds:
∥x(t)∥< a∥x(0)∥e−λt
(4.3)
for t > 0 in some neighbourhood D ⊂Rn containing the equilibrium point.

44
Nonlinear and adaptive control systems
For linear systems, the stability properties are relatively simple. If a linear system
is asymptotically stable, it can be shown that it is exponentially stable. Of course,
for nonlinear systems, we may have a system that is asymptotically stable, but not
exponentially stable.
Example 4.2. Consider a nonlinear system
˙x = −x3,
x(0) = x0 > 0,
where x ∈R. Let us solve this differential equation. From the system equation we
have
−dx
x3 = dt,
which gives
1
x2(t) −1
x2
0
= 2t
and
x(t) =
x0

1 + 2x2
0t
.
It is easy to see that x(t) decreases as t increases, and also limt→∞x(t) = 0. Therefore,
this system is asymptotically stable. However, this system is not exponentially stable,
as there does not exist a pair of a and γ to satisfy
x0

1 + 2x2
0t
≤ax0e−γ t.
Indeed, if there exist such constants a and γ , we have

1 + 2x2
0te−γ t ≥1
a,
which is not satisﬁed for any choices of a and γ , because the left-hand side converges
to zero. Hence, the system considered in this example is asymptotically stable, but
not exponentially stable.
◁
Lyapunov, asymptotic and exponential, stabilities are deﬁned around equilibrium
points. If the properties hold for any initial points in the entire state space, they are

Stability theory
45
referred to as global stability properties. In the following deﬁnitions, we give their
global versions.
Deﬁnition 4.4 (Globally asymptotic stability). If the asymptotic stability deﬁned in
Deﬁnition 4.2 holds for any initial state in Rn, the equilibrium point is said to be
globally asymptotically stable.
Deﬁnition 4.5 (Globally exponential stability). If the exponential stability deﬁned
in Deﬁnition 4.3 holds for any initial state in Rn, the equilibrium point is said to be
globally exponentially stable.
The stability property discussed in Example 4.2 is globally and asymptotically
stable. In the two examples shown in this section, the stability properties are checked
based on the actual solutions of the systems. In general, explicit solutions of nonlinear
systems are difﬁcult to obtain, and it is expected to check the stability properties of
nonlinear systems without knowing the solutions. In the later part of this chapter, we
will show a number of results to establish stability properties without their solutions.
4.2
Linearisation and local stability
In this section, we introduce a result for checking the stability of nonlinear systems
based on its linearised model.
Theorem 4.1 (Lyapunov’s linearisation method). For a linearised model, there are
three cases:
●
Ifthelinearisedsystemhasallthesystem’spolesintheopenlefthalfofthecomplex
plane, the equilibrium point is asymptotically stable for the actual nonlinear
system.
●
If the linearised system has poles in the open right half of the complex plane, then
the equilibrium point is unstable.
●
If the linearised system has poles on the imaginary axis, then the stability of the
original system cannot be concluded using the linearised model.
We do not show a proof of this theorem here. It is clear that this theorem can
be applied to check local stabilities of nonlinear systems around equilibrium points.
For the case that the linearised model has poles on the imaginary axis, this theorem
cannot give conclusive result about the stability. This is not a surprise, because stable
and unstable systems can have the same linearised model. For example the systems
˙x = −x3 and ˙x = x3 have the same linearised model at x = 0, that is ˙x = 0, which is
marginally stable. However, as we have seen in Example 4.2, the system ˙x = −x3 is
asymptotically stable, and it is not difﬁcult to see that ˙x = x3 is unstable. For both the
stable and unstable cases of linearised models, the linearised model approximates the
original system better when the domain around the equilibrium point gets smaller.
Hence, the linearised model is expected to reﬂect on the stability behaviours around
the equilibrium point.

46
Nonlinear and adaptive control systems
Example 4.3. Consider a nonlinear system
˙x1 = x2 + x1 −x3
1,
˙x2 = −x1.
It can be seen that x = (0, 0) is an equilibrium point of the system. The linearised
model around x = (0, 0) is given by
˙x = Ax
where
A =
 1
1
−1
0

The linearised system is unstable as λ(A) = 1±
√
3j
2
. Indeed, this nonlinear system is a
van der Pols system, and the origin is unstable. Any trajectories that start from initial
point close to the origin and within the limit cycle will spiral out, and converge to the
limit cycle.
◁
4.3
Lyapunov’s direct method
Lyapunov’s linearisation method can only be used to check local stabilities, and also
there is a limitation in the case of marginal stability. Fortunately, there is a direct
method to check the stability of dynamic systems. This method is based on Lyapunov
functions. We need a few deﬁnitions before we can show some of the results on
stability based on Lyapunov functions.
Deﬁnition 4.6 (Positive deﬁnite function). A function V(x) : D ⊂Rn →R is said to
be locally positive deﬁnite if V(x) > 0 for x ∈D except at x = 0 where V(0) = 0. If
D = Rn, i.e., the above property holds for the entire state space, V(x) is said to be
globally positive deﬁnite.
There are many examples of positive deﬁnite functions, such as xTPx for P being
a positive deﬁnite matrix, or even ∥x∥.
Deﬁnition 4.7 (Lyapunov function). If in D ⊂Rn containing the equilibrium point
x = 0, the function V(x) is positive deﬁnite and has continuous partial derivatives,
and if its time derivative along any state trajectory of system (4.1) is non-positive,
i.e.,
˙V(x) ≤0
(4.4)
then V(x) is a Lyapunov function.

Stability theory
47
Stability analysis based on a Lyapunov function is probably the most commonly
used method to establish the stability of nonlinear dynamic systems. A fundamental
theorem on Lyapunov function is given below.
Theorem 4.2 (Lyapunov theorem forlocalstability). Consider the system (4.1). If
in D ⊂Rn containing the equilibrium point x = 0, there exists a function V(x) :
D ⊂Rn →R with continuous ﬁrst-order derivatives such that
●
V(x) is positive deﬁnite in D
●
˙V(x) is non-positive deﬁnite in D
then the equilibrium point x = 0 is stable. Furthermore, if ˙V(x) is negative deﬁnite,
i.e., −˙V(x) is positive deﬁnite in D, then the stability is asymptotic.
Proof. We need to ﬁnd a value for r such that when ∥x(0)∥< r, we have ∥x(t)∥< R.
Deﬁne
BR := {x|∥x∥≤R} ⊂D,
and let
a = min
∥x∥=R V(x).
Since V(x) is positive deﬁnite, we have a > 0. We then deﬁne the level set within BR
c := {x ∈BR|V(x) < c},
where c is a positive real constant and c < a. The existence of such a positive real
constant c is guaranteed by the continuity and positive deﬁniteness of V. From the
deﬁnition of c, x ∈c implies that ∥x∥< R. Since ˙V ≤0, we have V(x(t)) ≤
V(x(0)). Hence, for any x(0) ∈c, we have
V(x(t)) ≤V(x(0)) < c,
which implies
∥x(t)∥< R.
Since c contains 0 as an interior point, and V is a continuous function, there
must exist a positive real r such that
Br := {x|∥x∥< r} ⊂c.
Hence, we have
Br ⊂c ⊂BR.

48
Nonlinear and adaptive control systems
Therefore, for any x(0) ∈Br, we have
V(x(t)) ≤V(x(0)) < c,
and ∥x(t)∥< R. We have established that if ˙V is non-positive, the system is Lyapunov
stable.
Next, we will establish the asymptotic stability from the negative deﬁniteness of
˙V. For any initial point in D, V(x(t)) monotonically decreases with time t. Therefore,
there must be a lower limit such that
lim
t→∞V(x(t)) = β ≥0.
The asymptotic stability can be established if we can show that β = 0. We can
prove it by seeking a contradiction. Suppose β > 0. Let
α =
min
x∈D−β (−˙V(x)),
where β := {x ∈D|V(x) < β}. Since ˙V is negative deﬁnite, we have α > 0. From
the deﬁnition of α, we have
V(x(t)) ≤V(x(0)) −αt.
The right-hand side turns to negative when t is big enough, which is a contradiction.
Therefore, we can conclude that limt→∞V(x(t)) = 0, which implies limt→∞x(t) = 0.
2
Example 4.4. A pendulum can be described by
¨θ + ˙θ + sin θ = 0,
where θ is the angle. If we let x1 = θ and x2 = ˙θ, we re-write the dynamic system as
˙x1 = x2
˙x2 = −sin x1 −x2.
Consider the scalar function
V(x) = (1 −cos x1) + x2
2
2 .
(4.5)
The ﬁrst term (1 −cos x1) in (4.5) can be viewed as the potential energy and the
second term
x2
2
2 as the kinetic energy. This function is positive deﬁnite in the domain
D = {|x1| ≤π, x2 ∈R}. A direct evaluation gives

Stability theory
49
˙V(x) = −sin x1˙x1 + x2˙x2
= −x2
2.
Hence, the system is stable at x = 0. However, we cannot conclude the asymptotic
stability of the system from Theorem 4.2. This system is in fact asymptotically stable
by using more advanced stability theorem such as invariant set theorem, which is not
covered in this book.
◁
When establishing global stability using Lyapunov functions, we need the func-
tion V(x) to be unbounded as x tends to inﬁnity. This may sound strange. The reason
behind this point is that we need the property that if V(x) is bounded, then x is
bounded, in order to conclude the boundedness of x from the boundedness of V(x).
This property is deﬁned in the following function as the radial unboundedness of V.
Deﬁnition 4.8 (Radially unbounded function). A positive deﬁnite function V(x) :
Rn →R is said to be radially unbounded if V(x) →∞as ∥x∥→∞.
Theorem 4.3 (Lyapunov theorem for global stability). For the system (4.1) with D =
Rn, if there exists a function V(x) : Rn →R with continuous ﬁrst order derivatives
such that
●
V(x) is positive deﬁnite
●
˙V(x) is negative deﬁnite
●
V(x) is radially unbounded
then the equilibrium point x = 0 is globally asymptotically stable.
Proof. The proof is similar to the proof of Theorem 4.2, except that for any given
point in Rn, we need to show that there is a level set deﬁned by
c = {x ∈Rn|V(x) < c}
to contain it.
Indeed, since the function V is radially unbounded, for any point in Br with any
positive real r, there exists a positive real constant c such that Br ⊂c. It is clear
that the level set c is invariant for any c, that is, for any trajectory that starts in c
remains in c. The rest of the proof follows the same argument as in the proof of
Theorem 4.2.
2
Example 4.5. Consider the nonlinear system
˙x = −x3,
x(0) = x0 > 0,

50
Nonlinear and adaptive control systems
where x ∈R. In Example 4.2, we have shown that the equilibrium point x = 0 is
asymptotically stable by checking the solution of the differential equation. In this
example, we use a Lyapunov function.
Let
V = 1
2x2
and it is easy to see that this function is globally positive deﬁnite. Its derivative is
given by
˙V = −x4
which is negative deﬁnite. Hence, from Theorem 4.3, we conclude x = 0 is
asymptotically stable.
◁
To conclude this section, we have another result for exponential stability.
Theorem 4.4 (Exponential stability). For the system (4.1), if there exists a function
V(x) : D ⊂Rn →R with continuous ﬁrst-order derivatives such that
a1∥x∥b ≤V(x) ≤a2∥x∥b,
(4.6)
∂V
∂x f (x) ≤−a3∥x∥b,
(4.7)
where a1, a2, a3 and b are positive real constants, the equilibrium point x = 0 is
exponentially stable. Furthermore, the conditions hold for the entire state space, then
the equilibrium point x = 0 is globally exponentially stable.
The proof of this theorem is relatively simple, and we are going to show it here.
We need a technical lemma, which is also needed later for stability analysis of robust
adaptive control systems.
Lemma 4.5 (Comparison lemma). Let g, V : [0, ∞) →R. Then
˙V(t) ≤−aV(t) + g(t),
∀t ≥0
(4.8)
implies that
V(t) ≤e−atV(0) +
 t
0
e−α(t−τ)g(τ)dτ,
∀t ≥0
(4.9)
for any ﬁnite constant a.

Stability theory
51
Proof. From the derivative of Veat, we have
d
dt (Veat) = ˙Veat + aVeat.
Substituting ˙V from (4.8) in the above equation, we have
d
dt (Veat) ≤eatg(t).
(4.10)
Integrating (4.10), we have
V(t)eat ≤V(0) +
 t
0
eaτg(τ)dτ.
(4.11)
Multiplying both sides of (4.11) by e−aτ gives (4.8). This completes the proof.
2
Now we are ready to prove Theorem 4.4.
Proof. From (4.6) and (4.7), we have
˙V ≤−a3
a2
V.
Applying the comparison lemma (Lemma 4.5), we have
V(t) ≤V(0)e−(a3/a2)t.
(4.12)
Then from (4.6) and (4.12), we have
∥x(t)∥≤
 1
a1
V(t)
1/b
≤
 1
a1
V(0)
1/b
e−(a3/a2b)t
≤
a2
a1
1/b
∥x(0)∥e−(a3/a2b)t.
Hence, (4.3) is satisﬁed with a =
	
a2
a1

1/b
and λ =
a3
a2b, and the equilibrium point is
exponentially stable.
2
4.4
Lyapunov analysis of linear time-invariant systems
In this section, we will apply Lyapunov stability analysis to linear time-invariant (LTI)
systems. Consider an LTI system
˙x = Ax
(4.13)

52
Nonlinear and adaptive control systems
where x ∈Rn and A ∈Rn×n, x is the state variable, and A is a constant matrix. From
linear system theory, we know that this system is stable if all the eigenvalues of A are
in the open left half of the complex plane. Such a matrix is referred to as a Hurwitz
matrix. Here, we would like to carry out the stability analysis using a Lyapunov
function. We can state the stability in the following theorem.
Theorem 4.6. For the linear system shown in (4.13), the equilibrium x = 0 is globally
and exponentially stable if and only if there exist positive deﬁnite matrices P and Q
such that
ATP + PA = −Q
(4.14)
holds.
Proof. For sufﬁciency, let
V(x) = xTPx,
(4.15)
and then the direct evaluation gives
˙V = xTATPx + xTPAx = −xTQx.
(4.16)
Let us use λmax(·) and λmin(·) to denote maximum and minimum eigenvalues of a
positive deﬁnite matrix. From (4.15), we have
λmin(P)∥x∥2 ≤V(x) ≤λmax(P)∥x∥2.
(4.17)
From (4.17) and (4.16), we obtain
˙V ≤−λmin(Q)∥x∥2
≤−λmin(Q)
λmax(P)∥x∥2.
(4.18)
Now we can applyTheorem 4.4 with (4.17) and (4.18) to conclude that the equilibrium
point is globally and exponentially stable. Furthermore, we can identify a1 = λmin(P),
a2 = λmax(P), a3 = λmin(Q) and b = 2. Following the proof of Theorem 4.4, we have
∥x(t)∥≤

λmax(P)
λmin(P) ∥x(0)∥e−λmin(Q)
2λmax(P) t.
(4.19)
For the necessary part, we have
∥x(t)∥≤a∥x(0)∥e−λt

Stability theory
53
for some positive real constants a and λ, which implies limt→∞x(t) = 0. Since
x(t) = eAtx(0),
we can conclude limt→∞eAt = 0. In such a case, for a positive deﬁnite matrix Q, we
can write
 ∞
0
d[exp (ATt)Q exp (At)] = −Q.
(4.20)
For the left-hand side, we can obtain
 ∞
0
d[exp (ATt)Q exp (At)]
= AT
 ∞
0
exp (ATt)Q exp (At)t +
 ∞
0
exp (ATt)Q exp (At)tA
Let
P =
 ∞
0
exp (ATt)Q exp (At)t
and if we can show that P is positive deﬁnite, then we obtain (4.14), and hence
complete the proof. Indeed, for any z ∈Rn ̸= 0, we have
zTPz =
 ∞
0
zT exp (ATt)Q exp (At)zdt.
Since Q is positive deﬁnite, and eAt is non-singular for any t, we have zTPz > 0, and
therefore P is positive deﬁnite.
2


Chapter 5
Advanced stability theory
Lyapunov direct method provides a tool to check the stability of a nonlinear system
if a Lyapunov function can be found. For linear systems, a Lyapunov function can
always be constructed if the system is asymptotically stable. In many nonlinear sys-
tems, a part of the system may be linear, such as linear systems with memoryless
nonlinear components and linear systems with adaptive control laws. For such a sys-
tem, a Lyapunov function for the linear part may be very useful in the construction
for the Lyapunov function for the entire nonlinear system. In this chapter, we will
introduce one speciﬁc class of linear systems, strict positive real systems, for which,
an important result, Kalman–Yakubovich lemma, is often used to guarantee a choice
of the Lyapunov function for stability analysis of several types of nonlinear systems.
The application of Kalman–Yakubovich lemma to analysis of adaptive control sys-
tems will be shown in later chapters, while in this chapter, this lemma is used for
stability analysis of systems containing memoryless nonlinear components and the
related circle criterion. In Section 5.3 of this chapter, input-to-state stability (ISS) is
brieﬂy introduced.
5.1
Positive real systems
Consider a ﬁrst-order system
˙y = −ay + u,
where a > 0 is a constant, and y and u ∈R are the output and input respectively. This
is perhaps the simplest dynamic system we could possibly have. The performance
of such a system is desirable in control design. One of the characteristics for such a
system is that its transfer function
1
s+a is with positive real part if s = σ + jω with
σ > 0. If such a property holds for other rational transfer functions, they are referred
to as positive real transfer functions. For this, we have the following deﬁnition.
Deﬁnition 5.1. A rational transfer function G(s) is positive real if
●
G(s) is real for real s
●
ℜ(G(s)) ≥0 for s = σ + jω with σ ≥0
For analysis of adaptive control systems, strictly positive real systems are more
widely used than the positive real systems.

56
Nonlinear and adaptive control systems
Deﬁnition 5.2. A proper rational transfer function G(s) is strictly positive real if
there exists a positive real constant ϵ such that G(s −ϵ) is positive real.
Example 5.1. For the transfer function G(s) =
1
s+a, with a > 0, we have, for
s = σ + jω,
G(s) =
1
a + σ + jω =
a + σ −jω
(a + σ)2 + ω2
and
ℜ(G(s)) =
a + σ
(a + σ)2 + ω2 > 0.
Hence, G(s) =
1
s+a is positive real. Furthermore, for any ϵ ∈(0, a), we have
ℜ(G(s −ϵ)) =
a −ϵ + σ
(a −ϵ + σ)2 + ω2 > 0
and therefore G(s) =
1
s+a is also strictly positive real.
◁
Deﬁnition 5.1 shows that a positive real transfer function maps the closed right
half of the complex plane to itself. Based on complex analysis, we can obtain the
following result.
Proposition 5.1. A proper rational transfer function G(s) is positive real if
●
all the poles of G(s) are in the closed left half of the complex plane
●
any poles on the imaginary axis are simple and their residues are non-negative
●
for all ω ∈R, ℜ(G(jω)) ≥0 when jω is not a pole of G(s)
It can be seen that G(s) =
1
s+a, with a < 0, is not positive real. If G(s) is posi-
tive real, we must have ℜ(G(jω)) ≥0. Similarly, other necessary conditions can be
obtained for a transfer function G(s) to be positive real. We can state those conditions
in an opposite way.
Proposition 5.2. A transfer function G(s) cannot be positive real if one of the
following conditions is satisﬁed:
●
The relative degree of G(s) is greater than 1.
●
G(s) is unstable.
●
G(s) is non-minimum phase (i.e., with unstable zero).
●
The Nyquist plot of G(jω) enters the left half of the complex plane.

Advanced stability theory
57
Based on this proposition, the transfer functions G1 =
s −1
s2 + as + b, G2 =
s + 1
s2 −s + 1 and G3 =
1
s2 + as + b are not positive real, for any real numbers a
and b, because they are non-minimum phase, unstable, and with relative degree 2
respectively. It can also be shown that G(s) =
s + 4
s2 + 3s + 2 is not positive real as
G(jω) < 0 for ω > 2
√
2.
One difference between strictly positive real transfer functions and positive real
transfer functions arises due to the poles on imaginary axis.
Example 5.2. Consider G(s) = 1
s . For s = σ + jω, we have?
ℜ(G(s)) = ℜ

1
σ + jω

=
σ
σ 2 + ω2 .
Therefore, G(s) = 1
s is positive real. However, G(s) = 1
s is not strictly positive real.
◁
For the stability analysis later in the book, we only need the result on strictly
positive real transfer functions.
Lemma 5.3. A proper rational transfer function G(s) is strictly positive real if and
only if
●
G(s) is Hurwitz, i.e., all the poles of G(s) are in the open left half of the complex
plane.
●
The real part of G(s) is strictly positive along the jω axis, i.e.,
∀ω ≥0,
ℜ(G(jω)) > 0,
●
lims→∞G(s) > 0, or in case of lims→∞G(s) = 0, limω→∞ω2ℜ(G(jω)) > 0.
Proof. We show the proof for sufﬁciency here, and omit the necessity, as it is more
involved. For sufﬁciency, we only need to show that there exists a positive real constant
ϵ such that G(s −ϵ) is positive real.
Since G(s) is Hurwitz, there must exist a positive real constant ¯δ such that for
δ ∈(0, ¯δ ], G(s −δ) is Hurwitz. Suppose (A, b, cT, d) is a minimum state space
realisation for G(s), i.e.,
G(s) = cT(sI −A)−1b + d.
We have
G(s −δ) = cT(sI −δI −A)−1b + d
= cT(sI −A)−1((sI −δI −A) + δI)(sI −δI −A)−1b + d
= G(s) + δE(s),
(5.1)

58
Nonlinear and adaptive control systems
where
E(s) = cT(sI −A)−1(sI −δI −A)−1b.
E(s) is Hurwitz, and strictly proper. Therefore, we have
ℜ(E(jω)) < r1,
∀ω ∈R, δ ∈(0, ¯δ ]
(5.2)
for some positive real r1 and the existence of limω→∞ω2ℜ(E(jω)), which implies
ω2ℜ(E(jω)) < r2,
for |ω| > ω1, δ ∈(0, ¯δ ]
(5.3)
for some ω1 > 0.
If limω→∞ℜ(G(jω)) > 0, we have
ℜ(G(jω)) > r3,
∀ω ∈R
(5.4)
for some r3 > 0. Hence, combining (5.2) and (5.4), we obtain, from (5.1), that
ℜ(G(jω −δ)) > r3 −δr1,
∀ω ∈R.
(5.5)
Then we have ℜ(G(jω −δ)) > 0, by setting δ < r3
r1 .
In the case that limω→∞ℜ(G(jω)) = 0, the condition
lim
ω→∞ω2ℜ(G(jω)) > 0
implies that
ω2ℜ(G(jω)) > r4,
for |ω| > ω2
(5.6)
for some positive reals r4 and ω2. From (5.1), (5.3) and (5.6), we obtain that
ω2ℜ(G(jω −δ)) > r4 −δr2,
for |ω| > ω3
(5.7)
where ω3 = max{ω1, ω2}. From the second condition of the lemma, we have, for some
positive real constant r5,
ℜ(G(jω)) > r5,
for |ω| ≤ω3.
(5.8)
Then from (5.1), (5.2) and (5.8), we obtain that
ℜ(G(jω −δ)) > r5 −δr1,
for |ω| ≤ω3.
(5.9)
Combining the results in (5.7) and (5.9), we obtain that ℜ(G(jω −δ)) > 0 by setting
δ = min{ r4
r2 , r5
r1 }. Therefore, we have shown that there exists a positive real δ such that
G(s −δ) is positive real.
2

Advanced stability theory
59
The main purpose of introducing strictly positive real systems is for the following
result, which characterises the systems using matrices in time domain.
Lemma 5.4 (Kalman–Yakubovich lemma). Consider a dynamic system
˙x = Ax + bu
y = cTx,
(5.10)
where x ∈Rn is the state variable; y and u ∈R are the output and input respectively;
and A, b and c are constant matrices with proper dimensions, and (A, b, cT) is
controllable and observable. Its transfer function G(s) = cT(sI −A)−1b is strictly
positive real if and only if there exist positive deﬁnite matrices P and Q such that
ATP + PA = −Q,
Pb = c.
(5.11)
Remark 5.1. We do not provide a proof here, because the technical details in the
proof such as ﬁnding the positive deﬁnite P and the format of Q are beyond the scope
of this book. In the subsequent applications for stability analysis, we only need to
know the existence of P and Q, not their actual values for a given system. For example
in the stability analysis for adaptive control systems in Chapter 7, we only need to
make sure that the reference model is strictly positive real, which then implies the
existence of P and Q to satisfy (5.11).
◁
5.2
Absolute stability and circle criterion
In this section, we will consider a dynamic system which consists of a linear part
and a memoryless nonlinear component. Surely some engineering systems can be
modelled in this format, such as linear systems with nonlinearity in sensors. Let us
consider a closed-loop system
˙x = Ax + bu
y = cTx
u = −F(y)y,
(5.12)
where x ∈Rn is the state variable; y and u ∈R are the output and input respectively;
and A, b and c are constant matrices with proper dimensions.The nonlinear component
is in the feedback law. Similar systems have been considered earlier using describing
functions for approximation to predict the existence of limit cycles. Nonlinear ele-
ments considered in this section are sector-bounded, i.e., the nonlinear feedback gain
can be expressed as
α < F(y) < β
(5.13)
for some constants α and β, as shown in Figure 5.2.

60
Nonlinear and adaptive control systems
F(y)
u
.x = Ax + bu
y = cTx
r = 0
Σ
+
–
y
Figure 5.1
Block digram of system (5.12)
F(y)y
b
a
y
Figure 5.2
Sector-bounded nonlinear feedback gain
The absolute stability refers to the globally asymptotic stability of the equilib-
rium point at the origin for the system shown in (5.12) for a class of sector-bounded
nonlinearities shown in (5.13). We will use Kalman–Yakubovich lemma for the sta-
bility analysis. If the transfer function for the linear part is strictly positive real, we
can establish the stability by imposing a restriction on the nonlinear element.
Lemma 5.5. For the system shown in (5.12), if the transfer function cT(sI −A)−1b
is strictly positive real, the system is absolutely stable for F(y) > 0.
Proof. The proof is straightforward by invoking Kalman–Yakubovich lemma. Since
the linear part of the system is strictly positive real, then there exist positive deﬁnite
matrices P and Q such that (5.11) is satisﬁed.
Consider a Lyapunov function candidate
V = xTPx.

Advanced stability theory
61
Its derivative is given by
˙V = xT(ATP + PA)x + 2xTPBbu
= −xTQx −2xTPbF(y)y
= −xTQx −2xTcF(y)y
= −xTQx −2F(y)y2,
where in obtaining the third line of equation, we used Pb = c from the Kalman–
Yakubovich lemma. Therefore, if F(y) > 0, we have
˙V ≤−xTQx,
and then system is exponentially stable by Theorem 4.4.
2
Note that the conditions speciﬁed in Lemma 5.4 are the sufﬁcient conditions.
With the result shown in Lemma 5.5, we are ready to consider the general case
for α < F(y) < β. Consider the function deﬁned by
˜F = F −α
β −F
(5.14)
and obviously we have ˜F > 0. How to use this transformation for analysis of systems
stability?
With G(s) = cT(sI −A)−1b,
the characteristic equation of (5.12) can be
written as
G(s)F + 1 = 0.
(5.15)
Manipulating (5.15) by adding and subtracting suitable terms, we have
G(s)(F −α) = −αG −1,
(5.16)
G(s)(β −F) = βG + 1.
(5.17)
With (5.16) being divided by (5.17), we can obtain that
1 + βG
1 + αG · F −α
β −F + 1 = 0.
(5.18)
Let
˜G := 1 + βG
1 + αG
(5.19)
and we can write (5.18) as
˜G ˜F + 1 = 0
(5.20)

62
Nonlinear and adaptive control systems
which implies that the stability of the system (5.12) with the nonlinear gain shown in
(5.13) is equivalent to the stability of the system with the forward transfer function ˜G
and the feedback gain ˜F. Based on Lemma 5.5 and (5.20), we can see that the system
(5.12) is stable if ˜G is strictly positive real.
The expressions of ˜F in (5.14) and ˜G in (5.19) cannot deal with the case β = ∞.
In such a case, we re-deﬁne
˜F = F −α
(5.21)
which ensures that ˜F > 0. With this ˜F, we can obtain the manipulated characteristic
equation as
G
1 + αG · (F −α) + 1 = 0
which enables us to re-deﬁne
˜G :=
G
1 + αG .
(5.22)
We summarise the results in the following theorem.
Theorem 5.6 (Circle criterion). For the system (5.12) with the feedback gain satisfying
the condition in (5.13), if the transfer function ˜G deﬁned by
˜G(s) = 1 + βG(s)
1 + αG(s)
or in case of β = ∞, by
˜G(s) =
G(s)
1 + αG(s)
is strictly positive real, with G(s) = cT(sI −A)−1b, the system is absolutely stable.
What is the condition of G if ˜G is strictly positive real? Let us assume that
β > α > 0. Other cases can be analysed similarly. From Lemma 5.3, we know that
for ˜G to be strictly positive real, we need ˜G to be Hurwitz, and ℜ( ˜G(jω)) > 0, that is
ℜ
1 + βG(jω)
1 + αG(jω)

> 0,
∀ω ∈R,
which is equivalent to
ℜ
1/β + G(jω)
1/α + G(jω)

> 0,
∀ω ∈R.
(5.23)

Advanced stability theory
63
If 1
β + G(jω) = r1ejθ1 and 1
α + G(jω) = r2ejθ2, the condition in (5.23) is satisﬁed by
−π
2 < θ1 −θ2 < π
2 ,
which is equivalent to the point G(jω) that lies outside the circle centered at
(−1
2(1/α + 1/β), 0) with radius of 1
2(1/α −1/β) in the complex plane. This cir-
cle intersects the real axis at (−1
α, 0) and (−1
β , 0). Indeed, 1
β + G(jω) is represented
as a vector from the point (−1
β , 0) to G(jω), and 1
α + G(jω) as a vector from the
point (−1
α, 0) to G(jω). The angle between the two vectors will be less than π
2 when
G(jω) is outside the circle, as shown in Figure 5.3. Since the condition must hold
for all ω ∈R, the condition ℜ( ˜G(jω)) > 0 is equivalent to the Nyquist plot of G(s)
that lies outside the circle. The condition that ˜G is strictly positive real requires that
the Nyquist plot of G(s) does not intersect with the circle and encircles the circle
counterclockwise the same number of times as the number of unstable poles of G(s),
as illustrated in Figure 5.4.
Alternatively, the circle can also be interpreted from complex mapping. From
(5.19), it can be obtained that
G =
˜G −1
β −α ˜G
.
(5.24)
The mapping shown in (5.24) is a bilinear transformation, and it maps a line to a line
or circle. For the case of β > α > 0, we have
G = −1
α −
 1
α −1
β

β/α
˜G −β/α
.
(5.25)
The function
β/α
˜G −β/α
– 1
Im
Re
G(jw)
a
b
– 1
q2
q1
Figure 5.3
Diagram of |θ1 −θ2| < π
2

64
Nonlinear and adaptive control systems
– 1
Im
Re
G(jw)
a
– 1
b
Figure 5.4
Circle criterion
maps the imaginary axis to a circle centred as (−1/2, 0) with the radius 1/2, i.e., the
line from (−1, 0) to (0, 0) on the complex plane is the diameter of the circle. Then
the function
−
 1
α −1
β

β/α
˜G −β/α
maps the imaginary axis to a circle with the diameter on the line from (0, 0) to
( 1
α −1
β , 0) on the complex plane. Finally, it can be seen from (5.25) that this map of ˜G
to G maps the imaginary axis to the circle with the diameter on the line from (−1
α, 0)
to (−1
β , 0), or in other words, the circle centered as (−1
2(1/α + 1/β), 0) with radius
of 1
2(1/α −1/β). It can also be shown that the function maps the open left-hand
complex plane to the domain inside the circle.
Indeed, we can evaluate the circle directly from (5.24). Let u and v denote the
real and imaginary parts of the mapping of the imaginary axis, and we have
u = ℜjω −1
β −αjω = −α + βω2
α2 + β2ω2 ,
v = ℑjω −1
β −αjω = (α −β)ω
α2 + β2ω2 .
Denoting μ = β
α ω, we obtain
u = −1/α + (1/β)μ2
1 + μ2
= −1
2
 1
α + 1
β

+ 1
2
 1
β −1
α
 1 −μ2
1 + μ2 ,
v = (1/β −1/α)μ
1 + μ2
= 1
2
 1
β −1
α

2μ
1 + μ2 .

Advanced stability theory
65
It is now easy to see that

u + 1
2
 1
α + 1
β
2
+ v2 =
1
2
 1
α −1
β
2
.
which describes the circle that is discussed before.
5.3
Input-to-state stability and small gain theorem
In this section, we continue to consider the stability properties for systems with inputs.
For linear systems, if a system is asymptotically stable, the state will remain bounded
when the input is bounded. Does this property still hold for nonlinear systems?
Consider a nonlinear system
˙x = f (x, u)
(5.26)
where x ∈Rn is the state of the system, and u ∈Rm is a bounded input, and f :
Rn × Rm −→Rn is a continuous and locally Lipschitz function. If the autonomous
system
˙x = f (x, 0)
is asymptotically stable, will the state remain bounded for a bounded input signal u?
Example 5.3. Consider a nonlinear system
˙x = −x + (1 + 2x)u,
x(0) = 0
where x ∈R. When u = 0, we have
˙x = −x
which is asymptotically (exponentially) stable. However, the state of this system may
not remain bounded for a bounded input. For example if we let u = 1, we have
˙x = x + 1
of which the state variable x is unbounded.
◁
From the above example, it can be seen that even the corresponding autonomous
systemis asymptoticallystable, thestatemaynotremainboundedsubjecttoabounded
input. We introduce a deﬁnition for systems with the property of bounded state with
bounded input.
To show a deﬁnition of input-to-state stable (ISS), we need to use comparison
functions, which are deﬁned below.

66
Nonlinear and adaptive control systems
Deﬁnition 5.3. A function γ : [0, a) →[0, ∞) is a class K function if γ is contin-
uous, and strictly increasing with γ (0) = 0. If a = ∞and limr→∞γ (r) = ∞, the
function is a class K∞function.
Deﬁnition 5.4. A function β : [0, a) × [0, ∞) →[0, ∞) is a class KL function if it
is continuous, for a ﬁxed t = t0, β(·, t0) is a class K function, and for a ﬁxed x(0),
limt→∞β(x(0), t) = 0.
Deﬁnition 5.5. The system (5.26) is ISS if there exist a class KL function β and a
class K function γ such that
∥x(t)∥≤β(∥x(0)∥, t) + γ (∥u∥∞),
∀t > 0.
(5.27)
There is an alternative deﬁnition, which may be convenient to use in some
situations. Here, we state it as a proposition.
Proposition 5.7. The system shown in (5.26) is ISS if and only if there exist a class
KL function β and a class K function γ such that
∥x(t)∥≤max{β(∥x(0)∥, t), γ (∥u∥∞)},
∀t > 0.
(5.28)
Proof. From (5.28), we have
∥x(t)∥≤β(∥x(0)∥, t) + γ (∥u∥∞)
and hence the system is ISS. From (5.27), there exist a class KL function β1 and a
class K function γ1
∥x(t)∥≤β1(∥x(0)∥, t) + γ1(∥u∥∞)
≤max{2β1(∥x(0)∥, t), 2γ1(∥u∥∞)}
and therefore the system satisﬁes (5.28) with β = 2β1 and γ = 2γ1.
2
Example 5.4. Consider a linear system
˙x = Ax + Bu,
where x ∈Rn and u ∈Rm are the state and input respectively, and A and B are matrices
with appropriate dimensions and A is Hurwitz. For this system, when u = 0, the
system is asymptotically stable, as A is Hurwitz. From its solution
x(t) = eAtx(0) +
 t
0
eA(t−τ)Bu(τ)dτ,

Advanced stability theory
67
we have
∥x(t)∥≤∥eAt∥∥x(0)∥+
 t
0
∥eA(t−τ)∥dτ∥B∥∥u∥∞.
Since A is Hurwitz, there exist positive real constants a and λ such that ∥eA(t)∥≤
ae−λt. Hence, we can obtain
∥x(t)∥≤ae−λt∥x(0)∥+
 t
0
ae−λ(t−τ)∥dτ∥B∥∥u∥∞
≤ae−λt∥x(0)∥+ a
λ∥B∥∥u∥∞
It is easy to see that the ﬁrst term in the above expression is a KL function of t and
∥x(0)∥and the second term is a K function of ∥u∥∞. Therefore, the linear system with
Hurwitz system matrix A is ISS.
◁
Next, we show a result on establishing ISS property from a Lyapunov function.
Theorem 5.8. For the system (5.26), if there exists a function V(x) : Rn →R with
continuous ﬁrst-order derivatives such that
a1∥x∥b ≤V(x) ≤a2∥x∥b,
(5.29)
∂V
∂x f (x, u) ≤−a3∥x∥b,
∀∥x∥≥ρ(∥u∥)
(5.30)
where a1, a2, a3 and b are positive real constants and ρ is a class K function, the
system (5.26) is ISS.
Proof. From Theorem 4.4, we can see that the system is exponentially stable when
u = 0, and V(x) is a Lyapunov function for the autonomous system ˙x = f (x, 0). To
consider the case for non-zero input, let us ﬁnd a level set based on V, deﬁned by
c := {x|V(x) ≤c}
and determine the constant c such that for x /∈c, we have ∥x∥> ρ(∥u∥∞). Indeed,
let
c = a2(ρ(∥u∥∞))b.
In this case, from V(x) > c, we have
V(x) > a2(ρ(∥u∥∞))b,
which implies that
a2∥x∥b > a2(ρ(∥u∥∞))b
and hence ∥x∥> ρ(∥u∥∞).

68
Nonlinear and adaptive control systems
Therefore, for any x outside c, we can obtain from (5.29) and (5.30), in a similar
way to the proof of Theorem 4.4,
˙V ≤−a3
a2
V
and then
∥x(t)∥≤
a2
a1
1/b
∥x(0)∥e
−a3
a2b t.
There will be a time, say t1, at which the trajectory enters c.
We can show that c is invariant, i.e., the trajectory starts from c will remain
in c, and this is shown by the fact that on the boundary of c, ˙V ≤0. Therefore,
after t1, the trajectory will remain in c. Furthermore, for x ∈c, we have,
V(x) < a2(ρ(∥u∥∞))b
which implies that
∥x∥≤
a2
a1
1/b
ρ(∥u∥∞).
Combining the cases for x outside and in c, we conclude that
∥x∥≤max
a2
a1
1/b
∥x(0)∥e
−a3
a2b t,
a2
a1
1/b
ρ(∥u∥∞)

.
Hence, the system is ISS with the gain function γ (·) = ( a2
a1 )1/bρ(·).
There is a more general result than Theorem 5.8 that requires ˙x = f (x, 0) to be
asymptotically stable, not necessarily exponential stable. The proof of that theorem
is beyond the level of this text, and we include it here for completeness.
Theorem 5.9. For the system (5.26), if there exists a function V(x) : Rn →R with
continuous ﬁrst-order derivatives such that
α1(∥x∥) ≤V(x) ≤α2(∥x∥),
(5.31)
∂V
∂x f (x, u) ≤−α3(∥x∥),
∀∥x∥≥ρ(∥u∥),
(5.32)
where α1, α2, α3 are K∞functions and ρ is a class K function, the system (5.26) is
ISS with the gain function γ (·) = α−1
1 (α2(ρ(·))).
Note that class K∞functions are class K functions that satisfy the property
lim
r→∞α(r) = ∞.

Advanced stability theory
69
There is a slightly different version of Theorem 5.9 which is shown below.
Corollary 5.10. For the system (5.26), if there exists a function V(x) : Rn →R with
continuous ﬁrst-order derivatives such that
α1(∥x∥) ≤V(x) ≤α2(∥x∥),
(5.33)
∂V
∂x f (x) ≤−α(∥x∥) + σ(∥u∥),
(5.34)
where α1, α2, α are K∞functions and σ is a class K function, the system (5.26)
is ISS.
The function which satisﬁes (5.31) and (5.32) or (5.33) and (5.34) is referred to as
ISS-Lyapunov function. In fact, it can be shown that the existence of an ISS-Lyapunov
function is also a necessary condition for the system to be ISS. Referring to (5.34),
the gain functions α and σ characterise the ISS property of the system, and they are
also referred to as an ISS pair. In other words, if we say a system is ISS with ISS pair
(α, σ), we mean that there exists an ISS-Lyapunov function that satisﬁes (5.34).
Example 5.5. Consider a nonlinear system
˙x = −x3 + u,
where x ∈R is the state, and u is input. The autonomous part ˙x = −x3 is considered
in Example 4.2, and it is asymptotically stable, but not exponentially stable. Consider
an ISS-Lyapunov function candidate
V = 1
2x2.
Its derivative is given by
˙V = −x4 −xu
≤−1
2x4 −1
2|x|(|x|3 −2|u|)
≤−1
2x4,
for|x| ≥(2|u|)1/3.
Hence the system is ISS with the gain function ρ(|u|) = (2|u|)1/3, based on
Theorem 5.9. Alternatively, using Young’s inequality, we have
|x||u| ≤1
4|x|4 + 3
4|u|4/3

70
Nonlinear and adaptive control systems
which gives
˙V ≤−3
4x4 + 3
4|u|4/3.
Therefore, the system is ISS based on Corollary 5.10 with α(·) = 3
4(·)4 and
σ(·) = 3
4(·)4/3.
◁
ISS property is useful in establishing the stability of interconnected systems. We
include two results here to end this section.
Theorem 5.11. If for the cascade connected system
˙x1 = f1(x1, x2),
(5.35)
˙x2 = f1(x2, u),
(5.36)
the subsystem (5.35) is ISS with x2 as the input, and the subsystem (5.36) is ISS with
u as input, the overall system with state x = [xT
1 , xT
2 ]T and input u is ISS.
Theorem 5.12 (ISS small gain theorem). If for the interconnected system
˙x1 = f1(x1, x2),
(5.37)
˙x2 = f1(x2, x2, u),
(5.38)
the subsystem (5.37) is ISS with x2 as the input with γ1 as the ISS gain for x2, and
the subsystem (5.38) is ISS by viewing x1 and u as the inputs, with the ISS input gain
function γ2 for x1, the overall system with state x = [xT
1 , xT
2 ]T and input u is ISS if
γ1(γ2(r)) < r,
∀r > 0.
(5.39)
From Theorem 5.11, it can be seen that if the subsystem x2 is globally asymptoti-
callystablewhenu = 0, theoverallsystemisgloballyasymptoticallystable. Similarly,
Theorem 5.12 can be used to establish the stability of the following system:
˙x1 = f1(x1, x2)
˙x2 = f1(x2, x2),
and the global and asymptotic stability of the entire system can be concluded if the
gain condition shown in Theorem 5.12 is satisﬁed.
Example 5.6. Consider the second-order nonlinear system
˙x1 = −x3
1 + x2,
˙x2 = x1x2/3
2
−3x2.

Advanced stability theory
71
From Example 5.5, we know that x1-subsystem is ISS with the gain function
γ1(·) = (2·)1/3. For the x2-subsystem, we choose
V2 = 1
2x2
2
and we have
˙V2 = −3x2
2 + x1x5/3
2
≤−x2
2 −|x2|5/3(2|x2|1/3 −|x1|)
≤−x2
2,
for |x2| >
|x1|
2
3
Hence, the x2-subsystem is ISS with the gain function γ2(·) = ( ·
2)3. Now we have,
for r > 0,
γ1(γ2(r)) =

2
 r
2
31/3
=
1
4
1/3
r < r.
Therefore, the system is globally asymptotically stable.
◁
5.4
Differential stability
Consider a nonlinear system
˙x = f (x, u),
(5.40)
where x ∈Rn is the state vector, u ∈Rs is the input and f : Rn × Rs →Rn is a
nonlinear smooth vector ﬁeld with f (0, u) = 0.
Deﬁnition 5.6. This system (5.40) has differential stability if there exists a Lyapunov
function V(x) such that V : Rn →R for all x, ˆx ∈Rn, u ∈Rs, satisﬁes
γ1(∥x∥) ≤V(x) ≤γ2(∥x∥),
∂V(x −ˆx)
∂x
(f (x, u) −f (ˆx, u)) ≤−γ3(∥x −ˆx∥),
c1
				
∂V(x)
∂x
				
c2
≤γ3(∥x∥),
(5.41)
where γi, i = 1, 2, 3, are K∞functions and ci, i = 1, 2, are positive real constants with
c2 > 1.

72
Nonlinear and adaptive control systems
Remark 5.2. The conditions speciﬁed in (5.41) are useful for observer design, in
particular, for the stability analysis of the reduced-order observers in Chapter 8.
A similar deﬁnition to differential stability is incremental stability. However, the
conditions speciﬁed in (5.41) are not always satisﬁed by the systems with incremental
stability. When ˆx = 0, i.e., in the case for one system only, the conditions speciﬁed
in (5.41) are then similar to the properties of the nonlinear systems with exponential
stability. The last condition in (5.41) is speciﬁed for interactions with other systems.
This condition is similar to the conditions for the existence of changing the supply
functions for inter-connection of ISS systems.
◁
We include two illustrative examples below for the properties of differential
stability.
Example 5.7. A linear system is differentially stable if the system is asymptotically
stable. Consider
˙x = Ax,
where A ∈Rn×n. If the system is asymptotically stable, A must be Hurwitz. Therefore
there exist positive deﬁnite matrices P and Q such that
ATP + PA = −Q.
Let V(x) = xTPx. In this case, the conditions (5.41) are satisﬁed with
γ1(∥x∥) = λmin(P)∥x∥2,
γ2(∥x∥) = λmax(P)∥x∥2,
γ3(∥x∥) = λmin(Q)∥x∥2,
c1 =
λmin(Q)
4(λmax(P))2 ,
c2 = 2,
where λmin(·) and λmax(·) denote the minimum and maximum eigenvalues of a
positive deﬁnite matrix.
◁
The differential stability is closely related to observer design. Consider a system
with input u ∈Rs
˙x = Ax + Bu.
(5.42)
If ˙x = Ax is differentially stable, an observer for (5.42) can be designed as
˙ˆx = Aˆx + Bu,
ˆx(0) = 0.
(5.43)
It is easy to see that x −ˆx converges to 0 exponentially.
However, for nonlinear systems, differential stability is not guaranteed by the
asymptotic or even exponential stability of a system.

Advanced stability theory
73
Example 5.8. We consider a ﬁrst-order nonlinear system
˙x = −x −2 sin x.
Take V = 1
2x2, and we have
˙V = −x2 −2x sin x.
For |x| ≤π, we have x sin x ≥0, and therefore
˙V ≤−x2.
For |x| > π, we have
˙V ≤−x2 −2x sin x
≤−x2 + 2|x|
= −

1 −2
π

x2 −2|x|
|x|
π −1

≤−

1 −2
π

x2.
Combining both the cases, we have
˙V ≤−

1 −2
π

x2.
Hence, the system is exponentially stable. But this system is not differentially stable.
Indeed, let e = x −ˆx. We have
˙e = −e −2( sin (x) −sin (x + e)).
By linearising the system at x = π and ˆx = π, and denoting the error at this point by
el, we have
˙el = −el −2 cos (x)|x=π(x −π) + 2 cos (ˆx)|ˆx=π(ˆx −π)
= el
and the system is unstable in a neighbourhood of this point.
◁


Chapter 6
Feedback linearisation
Nonlinear systems can be linearised around operating points and the behaviours in
the neighbourhoods of the operating points are then approximated by their linearised
models. The domain for a locally linearised model can be fairly small, and this may
result in that a number of linearised models are needed to cover an operating range
of a system. In this chapter, we will introduce another method to obtain a linear
model for nonlinear systems via feedback control design. The aim is to convert a
nonlinear system to a linear one by state transformation and redeﬁning the control
input. The resultant linear model describes the system dynamics globally. Of course,
there are certain conditions for the nonlinear systems to satisfy so that this feedback
linearisation method can be applied.
6.1
Input–output linearisation
The basic idea for input–output linearisation is fairly straightforward. We use an
example to demonstrate this.
Example 6.1. Consider the nonlinear system
˙x1 = x2 + x3
1
˙x2 = x2
1 + u
y = x1.
(6.1)
For this system, taking the derivatives of y, we have
˙y = x2 + x3
1,
¨y = 3x2
1(x2 + x3
1) + x2
1 + u.
Now, let us deﬁne
v = 3x2
1(x2 + x3
1) + x2
1 + u,
and we obtain
¨y = v.

76
Nonlinear and adaptive control systems
Viewing v as the new control input, we see that the system is linearised. Indeed, let
us introduce a state transformation
ξ1 := y = x1,
ξ2 := ˙y = x2 + x3
1.
We then obtain a linear system
˙ξ1 = ξ2
˙ξ2 = v.
We can design a state feedback law as
v = −a1ξ1 −a2ξ2
to stabilise the system with a1 > 0 and a2 > 0.The control input of the original system
is given by
u = −3x2
1(x2 −x3
1) −x2
1 + v.
(6.2)
We say that the system (6.1) is linearised by the feedback control law (6.2). Notice
that this linearisation works for the entire state space.
◁
As shown in the previous example, we can keep taking the derivatives of the
output y until the input u appears in the derivative, and then a feedback linearisation
law can be introduced. The derivatives of the output also introduce a natural state
transformation.
Consider a nonlinear system
˙x = f (x) + g(x)u
y = h(x),
(6.3)
where x ∈D ⊂Rn is the state of the system; y and u ∈R are output and input respec-
tively; and f and g : D ⊂Rn →Rn are smooth functions and h : D ⊂Rn →R is a
smooth function.
Remark 6.1. The functions f (x) and g(x) are vectors for a given point x in the state
space, and they are often referred to as vector ﬁelds. All the functions in (6.3) are
required to be smooth in the sense that they have continuous derivatives up to certain
orders when required. We use the smoothness of functions in the remaining part of
the chapter in this way.
◁
The input–output feedback linearisation problem is to design a feedback control
law
u = α(x) + β(x)v
(6.4)
with β(x) ̸= 0 for x ∈D such that the input–output dynamics of the system

Feedback linearisation
77
˙x = f (x) + g(x)α(x) + g(x)β(x)v
y = h(x)
(6.5)
are described by
y(ρ) = v
(6.6)
for 1 ≤ρ ≤n.
For the system (6.3), the ﬁrst-order derivative of the output y is given by
˙y = ∂h(x)
∂x (f (x) + g(x)u)
:= Lf h(x) + Lgh(x)u,
where the notations Lf h and Lgh(x) are Lie derivatives.
For
any
smooth
function
f : D ⊂Rn →Rn
and
a
smooth
function
h : D ⊂Rn →R, the Lie derivative Lf h, referred to as the derivative of h along
f , is deﬁned by
Lf h(x) = ∂h(x)
∂x f (x).
This notation can be used iteratively, that is
Lf (Lf h(x)) = L2
f h(x),
Lk
f (h(x)) = Lf (Lk−1
f
(h(x))),
where k ≥0 is an integer.
The solution to this problem depends on the appearance of the control input in
the derivatives of the output, which is described by the relative degree of the dynamic
system.
Deﬁnition 6.1. The dynamic system (6.3) has relative degree ρ at a point x if the
following conditions are satisﬁed:
LgLk
f h(x) = 0,
for k = 0, . . . , ρ −2,
LgLρ−1
f
h(x) ̸= 0.
Example 6.2. Consider the system (6.1). Comparing it with the format shown in
(6.3), we have
f (x) =
 x3
1 + x2
x2
1

,
g(x) =
 0
1

, h(x) = x1.

78
Nonlinear and adaptive control systems
Direct evaluation gives
Lgh(x) = 0,
Lf Lgh(x) = 1.
Therefore, the relative degree of the system (6.1) is 2.
◁
For SISO linear systems, the relative degree is the difference between the orders
of the polynomials in the numerator and denominator of the transfer function. With
the deﬁnition of the relative degree, we can present the input–output feedback
linearisation using Lie derivatives.
Example 6.3. Consider the system (6.1) again, and continue from Example 6.2. With
Lgh(x) = 0, we have
˙y = Lf h(x)
where
Lf h(x) = x3
1 + x2.
Taking the derivative of Lf h(x), we have
¨y = L2
f h(x) + LgLf h(x)u
where
L2
f h(x) = 3x2
1(x2 + x3
1) + x2
1,
LgLf h(x) = 1.
Therefore, we have
v = L2
f h(x) + LgLf h(x)u
or
u = −
L2
f h(x)
LgLf h(x) +
1
LgLf h(x)v
which gives the same result as in Example 6.1.
◁
The procedure shown in Example 6.3 works for systems with any relative degrees.
Suppose that the relative degree for (6.3) is ρ, which implies that LgLk
f h(x) = 0 for
k = 0, . . . , ρ −2. Therefore, we have the derivatives of y expressed by
y(k) = Lk
f h(x),
for k = 0, . . . , ρ −1,
(6.7)
y(ρ) = Lρ
f h(x) + LgLρ−1
f
h(x)u.
(6.8)

Feedback linearisation
79
If we deﬁne the input as
u =
1
LgLρ−1
f
h(x)
(−Lρ
f h(x) + v)
it results in
y(ρ) = v.
We can consider to use ξi := y(i−1) = Li−1
f
h as coordinates for the linearised
input–output dynamics. The only remaining issue is to establish that ∂ξ
∂x has full
rank. To do that, we need to introduce a few notations.
For any smooth functions f , g : D ⊂Rn →Rn, the Lie bracket [f , g] is
deﬁned by
[f , g](x) = ∂g(x)
∂x f (x) −∂g(x)
∂x f (x)
and we can introduce a notation which is more convenient for high-order Lie
brackets as
ad0
f g(x) = g(x),
ad1
f g(x) = [f , g](x),
adk
f g(x) = [f , adk−1
f
g](x).
For the convenient of presentation, let us denote
dh = ∂h
∂x
which is a row vector. With this notation, we can write
Lf h = < dh, f >.
Based on the deﬁnition of Lie Bracket, it can be obtained by a direct evaluation
that, for a smooth function h : Rn →R,
L[f , g]h = Lf Lgh −LgLf h = Lf < dh, g > −< dLf h, g >,
that is
< dh, [f , g] > = Lf < dh, g > −< dLf h, g > .
Similarly it can be obtained that, for any non-negative integers k and l,
< dLk
f h, adl+1
f
g > = Lf < dLk
f h, adl
f g > −< dLk+1
f
h, adl
f g >
(6.9)

80
Nonlinear and adaptive control systems
By now, we have enough tools and notations to show that ∂ξ
∂x has full rank. From
the deﬁnition of the relative degree,
< dLk
f h, g > = 0,
for k = 0, . . . , ρ −2
and by using (6.9) iteratively, we can show that
< dLk
f h, adl
f g > = 0,
for k + l ≤ρ −2,
(6.10)
and
< dLk
f h, adl
f g > = (−1)l < dLρ−1
f
h, g >,
for k + l = ρ −1.
(6.11)
From (6.10) and (6.11), we have
⎡
⎢⎢⎢⎢⎣
dh(x)
dLf h(x)
...
dLρ−1
f
h
⎤
⎥⎥⎥⎥⎦

g(x)
adf g(x)
. . .
adρ−1
f
g(x)

=
⎡
⎢⎢⎢⎣
0
. . .
0
(−1)ρ−1r(x)
0
. . .
(−1)ρ−2r(x)
∗
...
...
...
...
r(x)
. . .
∗
∗
⎤
⎥⎥⎥⎦
(6.12)
where r(x) = < dLρ−1
f
h, g >. Therefore, we conclude that
∂ξ
∂x =
⎡
⎢⎢⎢⎣
dh(x)
dLf h(x)
...
dLρ−1
f
h
⎤
⎥⎥⎥⎦
has full rank. We summarise the result about input–output feedback linearisation in
the following theorem.
Theorem 6.1. If the system in (6.3) has a well-deﬁned relative degree ρ in D, the
input–output dynamics of the system can be linearised by the feedback control law
u =
1
LgLρ−1
f
h(x)
(−Lρ
f h(x) + v)
(6.13)
and the linearised input–output dynamics are described by

Feedback linearisation
81
˙ξ1 = ξ2
...
˙ξρ−1 = ξρ
˙ξρ = v
(6.14)
with a partial state transformation
ξi = Li−1
f
h(x)
for i = 1, . . . , ρ.
(6.15)
When ρ = n, the whole nonlinear system dynamics are fully linearised.
The results shown in (6.10) and (6.11) can also be used to conclude the following
result which is needed in the next section.
Lemma 6.2. For any functions f , g : D ⊂Rn →Rn, and h : D ⊂Rn →R, all
differentiable to certain orders, the following two statements are equivalent for r > 0:
●
Lgh(x) = LgLf h(x) = · · · = LgLr
f h(x) = 0,
●
Lgh(x) = L[f , g]h(x) = · · · = Ladr
f gh(x) = 0.
Remark 6.2. The input–output dynamics can be linearised based on Theorem 6.1. In
the case of ρ < n, the system for ρ < n can be transformed under certain conditions
to the normal form
˙z = f0(z, ξ),
˙ξ1 = ξ2,
...
˙ξρ−1 = ξρ,
˙ξρ = Lρ
f h + uLgLρ−1
f
h,
y = ξ1
where z ∈Rn−ρ is the part of the state variables which are not in the input–output
dynamics of the system, and f0 : Rn →Rn−ρ is a smooth function. It is clear that
when ρ < n,
the input–output linearisation does not linearise the dynamics
˙z = f0(z, ξ). Also note that the dynamics ˙z = f0(z, 0) are referred to as the zero
dynamics of the system.
◁
To conclude this section, we use an example to demonstrate the input–output
linearisation for the case ρ < n.

82
Nonlinear and adaptive control systems
Example 6.4. Consider the nonlinear system
˙x1 = x3
1 + x2
˙x1 = x2
1 + x3 + u
˙x2 = x2
1 + u
y = x1.
For this system we have
f (x) =
⎡
⎣
x3
1 + x2
x2
1 + x3
x2
1
⎤
⎦,
g(x) =
⎡
⎣
0
1
1
⎤
⎦,
h(x) = x1.
It is easy to check that
Lf h = x3
1 + x2,
Lgh = 0,
LgLf h = 1,
L2
f h = 3x2
1(x3
1 + x2) + x2
1 + x3
and therefore the relative degree ρ = 2. For input–output linearisation, we set
u =
1
LgLf h(−L2
f h + v)
= −3x2
1(x3
1 + x2) −x2
1 −x3 + v.
Introduce the partial state transformation
ξ1 = h = x1,
ξ2 = Lf h = x3
1 + x2,
and it is easy to see that dh and dLf h are linearly independent. The linearised
input–output dynamics are described by
˙ξ1 = ξ2,
˙ξ2 = v.
If we like to transform the system to the normal form shown in Remark 6.2, we need
to introduce another state, in addition to ξ1 and ξ2. For this, we have the additional
state
z = x3 −x2.
The inverse transformation is given by
x1 = ξ1,
x2 = ξ2 −ξ 3
1 ,
x3 = z + ξ2 −ξ 3
1 .

Feedback linearisation
83
With the coordinates z, ξ1 and ξ2, we have the system in the normal form
˙z = −z −ξ2 + ξ 3
1
˙ξ1 = ξ2
˙ξ2 = z + ξ2 + ξ 2
1 −ξ 3
1 + 3ξ 2
1 ξ2 + u.
It is clear that the input–output linearisation does not linearise the dynamics of z. Also
note that the zero dynamics for this system are described by
˙z = −z.
◁
6.2
Full-state feedback linearisation
Consider a nonlinear system
˙x = f (x) + g(x)u,
(6.16)
where x ∈D ⊂Rn is the state of the system; u ∈R is the input; and f , g :
D ⊂Rn →Rn are smooth functions. The full-state linearisation problem is to ﬁnd a
feedback control design
u = α(x) + β(x)v
(6.17)
with β(x) ̸= 0 for x ∈D such that the entire system dynamics are linearised by a state
transformation with v as the new control input.
It is clear from the results shown in the input–output linearisation that the com-
plete linearisation can only be achieved when the relative degree of the system equals
the order of the system. If we can ﬁnd an output function h(x) for the system (6.16),
the input–output linearisation result shown in the previous section can be applied
to solve the full-state feedback linearisation problem. Therefore, we need to ﬁnd an
output function h(x) such that
LgLk
f h(x) = 0
for k = 0, . . . , n −2
(6.18)
LgLn−1
f
h(x) ̸= 0
(6.19)
Based on Lemma 6.2, the condition speciﬁed in (6.18) is equivalent to the condition
Ladk
f gh(x) = 0
for k = 0, . . . , n −2
(6.20)
and furthermore, the condition in (6.19) is equivalent to
Ladn−1
f
gh(x) ̸= 0.
(6.21)
The output function h(x) that satisﬁes the condition shown in (6.20) is a solution of
the partial differential equation
[g, adf g, . . . , adn−2
f
g]∂h
∂x = 0.
(6.22)

84
Nonlinear and adaptive control systems
Todiscussthesolutionofthispartialdifferentialequation, weneedafewnotations
and results. We refer to a collection of vector ﬁelds as a distribution. For example if
f1(x), . . . , fk(x) are vector ﬁelds, with k a positive integer,
 = span{f1(x), . . . , fk(x)}
is a distribution. The dimension of distribution is deﬁned as
dim ((x)) = rank[f1(x), . . . , fn(x)].
A distribution  is said to be involutive, if for any two vector ﬁelds f1, f2 ∈, we
have [f1, f2] ∈. Note that not all the distributions are involutive, as shown in the
following example.
Example 6.5. Consider the distribution
 = span{f1(x), f2(x)}
where
f1(x) =
⎡
⎣
2x2
1
0
⎤
⎦,
f2(x) =
⎡
⎣
1
0
x2
⎤
⎦.
A direct evaluation gives
[f1, f2] = ∂f2
∂x f1 −∂f1
∂x f2
=
⎡
⎣
0
0
0
0
0
0
0
1
0
⎤
⎦
⎡
⎣
2x2
1
0
⎤
⎦−
⎡
⎣
0
2
0
0
0
0
0
0
0
⎤
⎦
⎡
⎣
1
0
x2
⎤
⎦
=
⎡
⎣
0
0
1
⎤
⎦.
It can be shown that [f1, f2] /∈, and therefore  is not involutive. Indeed, the rank
of the matrix [f1, f2, [f1, f2]] is 3, which means that [f1, f2] is linearly independent of f1
and f2, and it cannot be a vector ﬁeld in . The rank of [f1, f2, [f1, f2]] can be veriﬁed
by its non-zero determinant as
|[f1, f2, [f1, f2]]| =

⎡
⎣
2x2
1
0
1
0
0
0
x2
1
⎤
⎦

= −1.
◁

Feedback linearisation
85
We say that a distribution  is integrable if there exists a non-trivial h(x) such
that for any vector ﬁeld f ∈, < dh, f > = 0.The relationship between an involutive
distribution and its integrability is stated in the following theorem.
Theorem 6.3 (Frobenius theorem). A distribution is integrable if and only if it is
involutive.
Now we are ready to state the main result for full-state feedback linearisation.
Theorem 6.4. The system (6.16) is full-state feedback linearisable if and only if
∀x ∈D
●
the matrix G = [g(x), adf g(x), . . . , adn−1
f
g(x)] has full rank
●
the distribution Gn−1 = span{g(x), adf g(x), . . . , adn−2
f
g(x)} is involutive
Proof. For the sufﬁciency, we only need to show that there exists a function h(x) such
that the relative degree of the system by viewing h(x) as the output is n, and the rest
follows from Theorem 6.1. From the second condition that Gn−1 is involutive, and
Frobenius theorem, there exists a function h(x) such that
∂h
∂x [g, adf g, . . . , adn−2
f
g] = 0
which is equivalent to, from Lemma 6.2,
LgLk
f h(x) = 0,
for
k = 0, . . . , n −2.
From the condition that G is full rank, we can establish
LgLn−1
f
h(x) ̸= 0.
In fact, if LgLn−1
f
h(x) = 0, then from Lemma 6.2, we have
∂h
∂x G = 0
which is a contradiction as G has full rank.
For necessity, we show that if the system is full-state feedback linearisable, then
the two conditions hold. From the problem formulation, we know that the full-state
linearisability is equivalent to the existence of an output function h(x) with relative
degree n. From the deﬁnition of the relative degree and Lemma 6.2, we have
Ladk
f gh(x) = 0,
for
k = 0, . . . , n −2,
which implies
∂h
∂x [g, adf g, . . . , adn−2
f
g] = 0.

86
Nonlinear and adaptive control systems
From Frobenius theorem, we conclude that Gn−1 is involutive. Furthermore, from the
fact that the system with h(x) as the output has a relative degree n, we can show, in
the same way as the discussion that leading to Lemma 6.2, that
⎡
⎢⎢⎢⎣
dh(x)
dLf h(x)
...
dLn−1
f
h
⎤
⎥⎥⎥⎦

 g(x) adf g(x) · · · adn−1
f
g(x) 
=
⎡
⎢⎢⎢⎣
0
. . .
0
(−1)n−1r(x)
0
. . .
(−1)n−2r(x)
∗
...
...
...
...
r(x)
. . .
∗
∗
⎤
⎥⎥⎥⎦
where r(x) = LgLn−1
f
h(x). This implies that G has rank n. This concludes the
proof.
2
Remark 6.3. Let us see the conditions in Theorem 6.4 for linear systems with
f (x) = Ax,
g(x) = b.
where A is a constant matrix and b is a constant vector. A direct evaluation gives
[f , g] = −Ab,
and
adk
f g = (−1)kAkb
for k > 0. Therefore, we have
G = [b, −Ab, . . . , (−1)n−1An−1b].
It can be seen that the full rank condition of G is equivalent to the full controllability
of the linear system.
◁
In the next example, we consider the dynamics of the system that was consid-
ered in Example 6.4 for input–output linearisation for the input h(x) = x1. We will
show that the full-state linearisation can be achieved by ﬁnding a suitable output
function h(x).

Feedback linearisation
87
Example 6.6. Consider the nonlinear system
˙x1 = x3
1 + x2
˙x1 = x2
1 + x3 + u
˙x2 = x2
1 + u,
for full-state feedback linearisation. With
f (x) =
⎡
⎣
x3
1 + x2
x2
1 + x3
x2
1
⎤
⎦,
g(x) =
⎡
⎣
0
1
1
⎤
⎦,
we have
[f , g] =
⎡
⎣
−1
−1
0
⎤
⎦,
and
ad2
f g =
⎡
⎣
3x2
1 + 1
2x1
2x1
⎤
⎦.
Hence, we have
G2 = span
⎧
⎨
⎩
⎡
⎣
0
1
1
⎤
⎦,
⎡
⎣
−1
−1
0
⎤
⎦
⎫
⎬
⎭
and
G =
⎡
⎣
0
−1
3x2
1 + 1
1
−1
2x1
1
0
2x1
⎤
⎦.
The distribution G2 is involutive, as it is spanned by constant vectors. The matrix G
has full rank, as shown by its determinant
|G| = 3x2
1 + 1 ̸= 0.
Hence, the conditions in Theorem 6.4 are all satisﬁed, and the system is full-state
linearisable. Indeed, we can ﬁnd
h(x) = x1 −x2 + x3
by solving
∂h
∂x
⎡
⎣
0
−1
1
−1
1
0
⎤
⎦= 0.
For this h(x), it is easy to check that

88
Nonlinear and adaptive control systems
Lgh = 0,
Lf h = x2 + x3
1 −x3,
LgLf h = 0,
L2
f h = 3x2
1(x3
1 + x2) + x3,
LgL2
f h = 3x2
1 + 1,
L3
f h = (15x4
1 + 6x1x2)(x3
1 + x2) + 3x2
1(x3 + x2
1) + x2
1.
It can be seen that the relative degree, indeed, equals 3 as
LgL2
f h = 3x2
1 + 1 ̸= 0.
For the full-state linearisation, we have the state transformation
ξ1 = x1 −x2 + x3,
ξ2 = x2 + x3
1 −x3,
ξ2 = 3x2
1(x3
1 + x2) + x3,
and the feedback law
u =
1
3x2
1 + 1

v −(15x4
1 + 6x1x2)(x3
1 + x2) −3x2
1(x3 + x2
1) −x2
1

.
◁

Chapter 7
Adaptive control of linear systems
The principle of feedback control is to maintain a consistent performance when there
are uncertainties in the system or changes in the setpoints through a feedback con-
troller using the measurements of the system performance, mainly the outputs. Many
controllers are with ﬁxed controller parameters, such as the controllers designed by
normal state feedback control, and H∞control methods. The basic aim of adaptive
control also is to maintain a consistent performance of a system in the presence of
uncertainty or unknown variation in plant parameters, but with changes in the con-
troller parameters, adapting to the changes in the performance of the control system.
Hence, there is an adaptation in the controller setting subject to the performance of the
closed-loop system. How the controller parameters change is decided by the adaptive
laws, which are often designed based on the stability analysis of the adaptive control
system.
A number of design methods have been developed for adaptive control. Model
Reference Adaptive Control (MRAC) consists of a reference model which pro-
duces the desired output, and the difference between the plant output and the
reference output is then used to adjust the control parameters and the control
input directly. MRAC is often in continuous-time domain, and for deterministic
plants. Self-Tuning Control (STC) estimates system parameters and then computes
the control input from the estimated parameters. STC is often in discrete-time and for
stochastic plants. Furthermore, STC often has a separate identiﬁcation procedure for
estimation of the system parameters, and is referred to as indirect adaptive control,
while MRAC adapts to the changes in the controller parameters, and is referred to
as direct adaptive control. In general, the stability analysis of direct adaptive con-
trol is less involved than that of indirect adaptive control, and can often be carried
out using Lyapunov functions. In this chapter, we focus on the basic design method
of MRAC.
Compared with the conventional control design, adaptive control is more
involved, with the need to design the adaptation law. MRAC design usually involves
the following three steps:
●
Choose a control law containing variable parameters.
●
Design an adaptation law for adjusting those parameters.
●
Analyse the stability properties of the resulting control system.

90
Nonlinear and adaptive control systems
7.1
MRAC of ﬁrst-order systems
The basic design idea can be clearly demonstrated by ﬁrst-order systems. Consider a
ﬁrst-order system
˙y + apy = bpu,
(7.1)
where y and u ∈R are the system output and input respectively, and ap and bp are
unknown constant parameters with sgn(bp) known.The output y is to follow the output
of the reference model
˙ym + amym = bmr.
(7.2)
The reference model is stable, i.e., am > 0. The signal r is the reference input. The
design objective is to make the tracking error e = y −ym converge to 0.
Let us ﬁrst design a Model Reference Control (MRC), that is, the control design
assuming all the parameters are known, to ensure that the output y follows ym.
Rearrange the system model as
˙y + amy = bp

u −ap −am
bp
y

and therefore we obtain
˙e + ame = bp

u −ap −am
bp
y −bm
bp
r

:= bp (u −auy −arr) ,
where
ay = ap −am
bp
,
ar = bm
bp
.
If all the parameters are known, the control law is designed as
u = arr + ayy
(7.3)
and the resultant closed-loop system is given by
˙e + ame = 0.
The tracking error converges to zero exponentially.
One important design principle in adaptive control is the so-called the certainty
equivalence principle, which suggests that the unknown parameters in the control
design are replaced by their estimates. Hence, when the parameters are unknown,
let ˆar and ˆay denote their estimates of ar and ay, and the control law, based on the
certainty equivalence principle, is given by
u = ˆarr + ˆayy.
(7.4)

Adaptive control of linear systems
91
Note that the parameters ar and ay are the parameters of the controllers, and they
are related to the original system parameters ap and bp, but not the original system
parameters themselves.
The certainty equivalence principle only suggests a way to design the adaptive
control input, not how to update the parameter estimates. Stability issues must be
considered when deciding the adaptive laws, i.e., the way how estimated parameters
are updated. For ﬁrst-order systems, the adaptive laws can be decided from Lyapunov
function analysis.
With the proposed adaptive control input (7.4), the closed-loop system dynamics
are described by
˙e + ame = bp(−˜ayy −˜arr),
(7.5)
where ˜ar = ar −ˆar and ˜ay = ay −ˆay. Consider the Lyapunov function candidate
V = 1
2e2 + |bp|
2γr
˜a2
r + |bp|
2γy
˜a2
y,
(7.6)
where γr and γy are constant positive real design parameters. Its derivative along the
trajectory (7.5) is given by
˙V = −ame2 + ˜ar

|bp|
˙˜ar
γr
−ebpr

+ ˜ay

|bp|
˙˜ay
γy
−ebpy

.
If we can set
|bp|
˙˜ar
γr
−ebpr = 0,
(7.7)
|bp|
˙˜ay
γy
−ebpy = 0,
(7.8)
we have
˙V = −ame2.
(7.9)
Noting that ˙ˆar = −˙˜ar and ˙ˆay = −˙˜ay, the conditions in (7.7) and (7.8) can be satisﬁed
by setting the adaptive laws as
˙ˆar = −sgn(bp)γrer,
(7.10)
˙ˆay = −sgn(bp)γyey.
(7.11)
The positive real design parameters γr and γy are often referred to as adaptive gains,
as they can affect the speed of parameter adaptation.
From (7.9) and Theorem 4.2, we conclude that the system is Lyapunov stable
with all the variables e, ˜ar and ˜ay bounded, and hence the boundedness of ˆar and ˆay.
However, based on the stability theorems introduced in Chapter 4, we cannot
conclude anything about the tracking error e other than its boundedness. In order
to do it, we need to introduce an important lemma for stability analysis of adaptive
control systems.

92
Nonlinear and adaptive control systems
Lemma 7.1 (Barbalat’s lemma). If a function f (t) : R −→R is uniformly continuous
for t ∈[0, ∞), and
 ∞
0 f (t)dt exists, then limt→∞f (t) = 0.
From (7.9), we can show that
 ∞
0
e2(t)dt = V(0) −V(∞)
am
< ∞.
(7.12)
Therefore, we have established that e ∈L2 ∩L∞and ˙e ∈L∞. Since ˙e and e are
bounded, e2 is uniformly continuous. Therefore, we can conclude from Barbalat’s
lemma that limt→∞e2(t) = 0, and hence limt→∞e(t) = 0.
We summarise the stability result in the following lemma.
Lemma 7.2. For the ﬁrst-order system (7.1) and the reference model (7.2), the adap-
tive control input (7.4) together with the adaptive laws (7.10) and (7.11) ensures the
boundedness of all the variables in the closed-loop system, and the convergence to
zero of the tracking error.
Remark 7.1. The stability analysis ensures the convergence to zero of the tracking
error, but nothing can be told about the convergence of the estimated parameters. The
estimated parameters are assured to be bounded from the stability analysis. In general,
the convergence of the tracking error to zero and the boundedness of the adaptive
parameters are stability results that we can establish for MRAC. The convergence
of the estimated parameters may be achieved by imposing certain conditions of the
reference signal to ensure the system is excited enough. This is similar to the concept
of persistent excitation for system identiﬁcation.
◁
Example 7.1. Consider a ﬁrst-order system
Gp =
b
s + a,
where b = 1 and a is an unknown constant parameter. We will design an adaptive
controller such that the output of the system follows the output of the reference model
Gm =
1
s + 2.
We can directly use the result presented in Lemma 7.2, i.e., we use the adaptive
laws (7.10) and (7.11) and the control input (7.4). Since b is known, we only have one
unknown parameter, and it is possible to design a simpler control based on the same
design principle.
From the system model, we have
˙y + ay = u,
which can be changed to
˙y + 2y = u −(a −2)y.

Adaptive control of linear systems
93
Subtracting the reference model
˙ym + 2ym = r,
we obtain that
˙e + 2e = u −ayy −r.
where ay = a −2. We then design the adaptive law and control input as
˙ˆay = −γyey,
u = ˆayy + r.
The stability analysis follows the same discussion that leads to Lemma 7.2. Simulation
study has been carried out with a = −1, γ = 10 and r = 1. The simulation results are
shown in Figure 7.1. The ﬁgure shows that the estimated parameter converges to the
true value ay = −3. The convergence of the estimated parameters is not guaranteed
by Lemma 7.2. Indeed, some strong conditions on the input or reference signal are
needed to generate enough excitation for the parameter estimation to achieve the
convergence of the estimated parameters in general.
◁
0
2
4
6
8
10
0
0.2
0.4
0.6
0.8
1
t (s)
y and ym
y
ym
0
2
4
6
8
10
−4
−3
−2
−1
0
t (s)
Estimated parameter
Figure 7.1
Simulation results of Example 7.1

94
Nonlinear and adaptive control systems
7.2
Model reference control
It is clear from MRAC design for ﬁrst-order systems that an MRC input is designed
ﬁrst which contains unknown parameters, and the adaptive control input is then
obtained based on the certainty equivalence principle. Hence, MRC design is the
ﬁrst step for MRAC. Furthermore, MRC itself deserves a brief introduction, as it is
different from the classical control design methods shown in standard undergraduate
texts. In this section, we will start with MRC for systems with relative degree 1, and
then move on to MRC of systems with high-order relative degrees.
Consider an nth-order system with the transfer function
y(s) = kp
Zp(s)
Rp(s)u(s),
(7.13)
where y(s) and u(s) denote the system output and input in frequency domain; kp is the
high frequency gain; and Zp and Rp are monic polynomials with orders of n −ρ and
n respectively with ρ as the relative degree. The reference model is chosen to have
the same relative degree of the system, and is described by
ym(s) = km
Zm(s)
Rm(s)r(s),
(7.14)
where ym(s) is the reference output for y(s) to follow; r(s) is a reference input; and
km > 0 and Zm and Rm are monic Hurwitz polynomials.
Remark 7.2. A monic polynomial is a polynomial whose leading coefﬁcient, the
coefﬁcient of the highest power, is 1. A polynomial is said to be Hurwitz if all its roots
are with negative real parts, i.e., its roots locate in the open left half of the complex
plane. The high-frequency gain is the leading coefﬁcient of the numerator of a transfer
function.
◁
The objective of MRC is to design a control input u such that the output of the
system asymptotically follows the output of the reference model, i.e., limt→∞(y(t) −
ym(t)) = 0.
Note that in this chapter, we abuse the notations of y, u and r by using same
notations for the functions in time domain and their Laplace transformed functions
in the frequency domain. It should be clear from the notations that y(s) is the Laplace
transform of y(t) and similarly for u and r.
To design MRC for systems with ρ = 1, we follow a similar manipulation to the
ﬁrst-order system by manipulating the transfer functions. We start with
y(s)Rp(s) = kpZp(s)u(s)
and then
y(s)Rm(s) = kpZp(s)u(s) −(Rp(s) −Rm(s))y(s).

Adaptive control of linear systems
95
Note that Rp(s) −Rm(s) is a polynomial with order n −1, and
Rm(s) −Rp(s)
Zm(s)
is a proper
transfer function, as Rp(s) and Rm(s) are monic polynomials. Hence, we can write
y(s)Rm(s) = kpZm(s)
 Zp(s)
Zm(s)u(s) + Rm(s) −Rp(s)
Zm(s)
y(s)

.
If we parameterise the transfer functions as
Zp(s)
Zm(s) = 1 −θ T
1 α(s)
Zm(s) ,
Rm(s) −Rp(s)
Zm(s)
y(s) = −θT
2 α(s)
Zm(s) y(s) −θ3,
where θ1 ∈Rn−1, θ2 ∈Rn−1 and θ3 ∈R are constants and
α(s) = [sn−2, . . . , 1]T,
we obtain that
y(s) = kp
Zm(s)
Rm(s)

u(s) −θ T
1 α(s)
Zm(s) u(s) −θ T
2 α(s)
Zm(s) y(s) −θ3y(s)

.
(7.15)
Hence, we have the dynamics of tracking error given by
e1(s) = kp
Zm(s)
Rm(s)

u(s) −θ T
1 α(s)
Zm(s) u(s) −θ T
2 α(s)
Zm(s) y(s) −θ3y(s) −θ4r

,
(7.16)
where e1 = y −ym and θ4 = km
kp .
The control input for MRC is given by
u(s) = θ T
1 α(s)
Zm(s) u(s) + θ T
2 α(s)
Zm(s) y + θ3y + θ4r(s)
:= θTω,
(7.17)
where
θT = [θT
1 , θT
4 , θ3, θ4],
ω = [ωT
1 , ωT
2 , y, r]T,
with
ω1 = α(s)
Zm(s)u,
ω2 = α(s)
Zm(s)y.

96
Nonlinear and adaptive control systems
Remark 7.3. The control design shown in (7.17) is a dynamic feedback con-
troller.
Each element in the transfer matrix
α(s)
Zm(s)
is strictly proper,
i.e.,
with relative degree greater than or equal to 1. The total number of parameters in
θ equals 2n.
◁
Lemma 7.3. For the system (7.13) with relative degree 1, the control input (7.17)
solves MRC problem with the reference model (7.14) and limt→∞(y(t) −ym(t)) = 0.
Proof. With the control input (7.17), the closed-loop dynamics are given by
e1(s) = kp
Zm(s)
Rm(s)ϵ(s),
where ϵ(s) denotes exponentially convergent signals due to non-zero initial values.
The reference model is stable, and then the track error e1(t) converges to zero
exponentially.
2
Example 7.2. Design MRC for the system
y(s) =
s + 1
s2 −2s + 1u(s)
with the reference model
ym(s) =
s + 3
s2 + 2s + 3r(s).
We follow the procedures shown early to obtain the MRC control. From the transfer
function of the system, we have
y(s)(s2 + 2s + 3) = (s + 1)u(s) + (4s + 2)y(s),
which leads to
y(s) =
s + 3
s2 + 2s + 3
s + 1
s + 3u(s) + 4s + 2
s + 3 y(s)

=
s + 3
s2 + 2s + 3

u(s) −
2
s + 3u(s) −
10
s + 3y(s) + 4y(s)

.
Subtracting it by the reference model, we have
e1(s) =
s + 3
s2 + 2s + 3

u(s) −
2
s + 3u(s) −
10
s + 3y(s) + 4y(s) −r(s)

,
which leads to the MRC control input
u(s) =
2
s + 3u(s) +
10
s + 3y(s) −4y(s) + r(s)
= [2 10 −4 1][ω1(s) ω2(s) y(s) r(s)]T,

Adaptive control of linear systems
97
where
ω1(s) =
1
s + 3u(s),
ω2(s) =
1
s + 3y(s).
Note that the control input in the time domain is given by
u(s) = [2 10 −4 1][ω1(t) ω2(t) y(t) r(t)]T,
where
˙ω1 = −3ω1 + u,
˙ω2 = −3ω2 + y.
◁
For a system with ρ > 1, the input in the same format as (7.17) can be obtained.
The only difference is that Zm is of order n −ρ < n −1. In this case, we let P(s) be a
monic and Hurwitz polynomial with order ρ −1 so that Zm(s)P(s) is of order n −1.
We adopt a slightly different approach from the case of ρ = 1.
Consider the identity
y(s) = Zm(s)
Rm(s)
Rm(s)P(s)
Zm(s)P(s)y(s)

= Zm(s)
Rm(s)
Q(s)Rp(s) + (s)
Zm(s)P(s)
y(s)

.
(7.18)
Note that the second equation in (7.18) follows from the identity
Rm(s)P(s) = Q(s)Rp(s) + (s),
where Q(s) is a monic polynomial with order n −ρ −1, and (s) is a polynomial
with order n −1. In fact Q(s) can be obtained by dividing Rm(s)P(s) by Rp(s) using
long division, and (s) is the remainder of the polynomial division. From the transfer
function of the system, we have
Rp(s)y(s) = kpZp(s)u(s).
Substituting it into (7.18), we have
y(s) = kp
Zm(s)
Rm(s)

Q(s)Zp(s)
Zm(s)P(s)u +
k−1
p (s)
Zm(s)P(s)y(s)

.
Similar to the case for ρ = 1, if we parameterise the transfer functions as
Q(s)Zp(s)
Zm(s)P(s) = 1 −
θ T
1 α(s)
Zm(s)P(s),
k−1
p 
Zm(s)P(s) = −θT
2 α(s)
Zm(s)P(s) −θ3

98
Nonlinear and adaptive control systems
where θ1 ∈Rn−1 and θ2 ∈Rn−1 and θ3 ∈R are constants and
α(s) = [sn−2, . . . , 1]T,
we obtain that
y(s) = kp
Zm(s)
Rm(s)

u(s) −
θT
1 α(s)
Zm(s)P(s)u(s) −
θ T
2 α(s)
Zm(s)P(s)y(s) −θ3y(s)

.
Hence, we have the dynamics of tracking error given by
e1(s) = kp
Zm(s)
Rm(s)

u(s) −
θT
1 α(s)
Zm(s)P(s)u(s) −
θT
2 α(s)
Zm(s)P(s)y(s) −θ3y(s) −θ4r

,
where e1 = y −ym and θ4 = km
kp . The control input is designed as
u =
θT
1 α(s)
Zm(s)P(s)u +
θ T
2 α(s)
Zm(s)P(s)y + θ3y + θ4r
:= θTω
(7.19)
with the same format as (7.17) except
ω1 =
α(s)
Zm(s)P(s)u,
ω2 =
α(s)
Zm(s)P(s)y.
Remark 7.4. The ﬁnal control input is in the same format as shown for the case
ρ = 1. The ﬁlters for w1 and w2 are in the same order as in the case for ρ = 1, as the
order of Zm(s)P(s) is still n −1.
◁
Lemma 7.4. For the system (7.13) with relative degree ρ > 1, the control input (7.19)
solves MRC problem with the reference model (7.14) and limt→∞(y(t) −ym(t)) = 0.
The proof is the same as the proof for Lemma 7.3.
Example 7.3. Design MRC for the system
y(s) =
1
s2 −2s + 1u
with the reference model
ym(s) =
1
s2 + 2s + 3r.
The relative degree of the system is 2. We set P = s + 1. Note that
(s2 + 2s + 3)(s + 1) = (s + 5)(s2 −2s + 1) + (14s −2).

Adaptive control of linear systems
99
From the reference model, we have
y(s) =
1
s2 + 2s + 3
(s2 + 2s + 3)(s + 1)
s + 1
y(s)

=
1
s2 + 2s + 3
(s + 5)(s2 −2s + 1)y(s) + (14s −2)y(s)
s + 1

=
1
s2 + 2s + 3
(s + 5)u(s) + (14s −2)y(s)
s + 1

=
1
s2 + 2s + 3

u(s) +
4
s + 1u(s) −16
1
s + 1y(s) + 14y(s)

.
The dynamics of the tacking error are given by
e1(s) =
1
s2 + 2s + 3

u(s) +
4
s + 1u(s) −16
1
s + 1y(s) + 14y(s) −r(s)

.
We can then design the control input as
u = [−1, −16, 14, 1][ω1, ω2, y, r]T
with
ω1 =
1
s + 1u,
ω2 =
1
s + 1y.
◁
7.3
MRAC of linear systems with relative degree 1
Adaptive control deals with uncertainties in terms of unknown constant parameters.
It may be used to tackle some changes or variations in model parameters in adaptive
control application, but the stability analysis will be carried under the assumption the
parameters are constants. There are other common assumptions for adaptive control
which are listed below:
●
the known system order n
●
the known relative degree ρ
●
the minimum phase of the plant
●
the known sign of the high frequency gain sgn(kp)
In this section, we present MRAC design for linear systems with relative
degree 1.
Consider an nth-order system with the transfer function
y(s) = kp
Zp(s)
Rp(s)u(s),
(7.20)

100
Nonlinear and adaptive control systems
where y(s) and u(s) denote the system output and input in frequency domain; kp is
the high frequency gain; and Zp and Rp are monic polynomials with orders of n −1
and n respectively. This system is assumed to be minimum phase, i.e., Zp(s) is a
Hurwitz polynomial, and the sign of the high-frequency gain, sgn(kp), is known. The
coefﬁcients of the polynomials and the value of kp are constants and unknown. The
reference model is chosen to have the relative degree 1 and strictly positive real, and
is described by
ym(s) = km
Zm(s)
Rm(s)r(s),
(7.21)
where ym(s) is the reference output for y(s) to follow, r(s) is a reference input, and
Zm(s) and Rm(s) are monic polynomials and km > 0. Since the reference model is
strictly positive real, Zm and Rm are Hurwitz polynomials.
MRC shown in the previous section gives the control design in (7.17). Based on
the certainty equivalence principle, we design the adaptive control input as
u(s) = ˆθ Tω,
(7.22)
where ˆθ is an estimate of the unknown vector θ ∈R2n, and ω is given by
ω = [ωT
1 , ωT
2 , y, r]T
with
ω1 = α(s)
Zm(s)u,
ω2 = α(s)
Zm(s)y.
With the designed adaptive control input, it can be obtained, from the tracking
error dynamics shown in (7.16), that
e1(s) = kp
Zm(s)
Rm(s)( ˆθ Tω −θ Tω)
= km
Zm(s)
Rm(s)

−kp
km
˜θ Tω

(7.23)
where ˜θ = θ −ˆθ.
To analyse the stability using a Lyapunov function, we put the error dynamics in
the state space form as
˙e = Ame + bm

−
kp
km ˜θ Tω
	
e1 = cT
me
(7.24)
where (Am, bm, cm) is a minimum state space realisation of km
Zm(s)
Rm(s), i.e.,
cT
m(sI −Am)−1bm = km
Zm(s)
Rm(s).

Adaptive control of linear systems
101
Since (Am, bm, cm) is a strictly positive real system, from Kalman–Yakubovich lemma
(Lemma 5.4), there exist positive deﬁnite matrices P and Q such that
AT
mPm + PmAm = −Qm,
(7.25)
Pmbm = cm.
(7.26)
Deﬁne a Lyapunov function candidate as
V = 1
2eTPme + 1
2




kp
km




 ˜θ T	−1 ˜θ,
where 	 ∈R2n is a positive deﬁnite matrix. Its derivative is given by
˙V = 1
2eT(AT
mPm + PmAm)e + eTPmbm

−kp
km
˜θ Tω

+




kp
km




 ˜θ T	−1 ˙˜θ
Using the results from (7.25) and (7.26), we have
˙V = −1
2eTQme + e1

−kp
km
˜θ Tω

+




kp
km




 ˜θ T	−1 ˙˜θ
= −1
2eTQme +




kp
km




 ˜θ T 
	−1 ˙˜θ −sgn(kp)e1ω
	
.
Hence, the adaptive law is designed as
˙ˆθ = −sgn(kp)	e1ω,
(7.27)
which results in
˙V = −1
2eTQme.
We can now conclude the boundedness of e and ˆθ. Furthermore it can be shown that
e ∈L2 and ˙e1 ∈L∞. Therefore, from Barbalat’s lemma we have limt→∞e1(t) = 0.
Theboundednessofothersystemstatevariablescanbeestablishedfromtheminimum-
phase property of the system.
We summarise the stability analysis for MRAC of linear systems with relative
degree 1 in the following theorem.
Theorem 7.5. For the ﬁrst-order system (7.20) and the reference model (7.21), the
adaptive control input (7.22) together with the adaptive law (7.27) ensures the bound-
edness of all the variables in the closed-loop system, and the convergence to zero of
the tracking error.
Remark 7.5. The stability result shown in Theorem 7.5 only guarantees the conver-
gence of the tracking error to zero, not the convergence of the estimated parameters.
In the stability analysis, we use Kalman–Yakubovich lemma for the deﬁnition of
Lyapunov function and the stability proof. That is why we choose the reference model
to be strictly positive real. From the control design point of view, we do not need
to know the actual values of Pm and Qm, as long as they exist, which is guaranteed

102
Nonlinear and adaptive control systems
by the selection of a strictly positive real model. Also it is clear from the stability
analysis, that the unknown parameters must be constant. Otherwise, we would not
have ˙ˆθ = −˙˜θ.
◁
7.4
MRAC of linear systems with high relatives
In this section, we will introduce adaptive control design for linear systems with their
relative degrees higher than 1. Similar to the case for relative degree 1, the certainty
equivalence principle can be applied to the control design, but the designs of the
adaptive laws and the stability analysis are much more involved, due to the higher
relative degrees. One difﬁculty is that there is not a clear choice of Lyapunov function
candidate as in the case of ρ = 1.
Consider an nth-order system with the transfer function
y(s) = kp
Zp(s)
Rp(s)u(s),
(7.28)
where y(s) and u(s) denote the system output and input in frequency domain, kp is
the high frequency gain, Zp and Rp are monic polynomials with orders of n −ρ and
n respectively, with ρ > 1 being the relative degree of the system. This system is
assumed to be minimum phase, i.e., Zp(s) is Hurwitz polynomial, and the sign of the
high-frequency gain, sgn(kp), is known. The coefﬁcients of the polynomials and the
value of kp are constants and unknown. The reference model is chosen as
ym(s) = km
Zm(s)
Rm(s)r(s)
(7.29)
where ym(s) is the reference output for y(s) to follow; r(s) is a reference input; and
Zm(s) and Rm(s) are monic polynomials with orders n −ρ and n respectively and
km > 0. The reference model (7.29) is required to satisfy an additional condition that
there exists a monic and Hurwitz polynomial P(s) of order n −ρ −1 such that
ym(s) = km
Zm(s)P(s)
Rm(s)
r(s)
(7.30)
is strictly positive real. This condition also implies that Zm and Rm are Hurwitz
polynomials.
MRC shown in the previous section gives the control design in (7.19). We design
the adaptive control input, again using the certainty equivalence principle, as
u = ˆθ Tω,
(7.31)
where ˆθ is an estimate of the unknown vector θ ∈R2n, and ω is given by
ω = [ωT
1 , ωT
2 , y, r]T

Adaptive control of linear systems
103
with
ω1 =
α(s)
Zm(s)P(s)u,
ω2 =
α(s)
Zm(s)P(s)y.
Thedesignofadaptivelawismoreinvolved, andweneedtoexaminethedynamics
of the tacking error, which are given by
e1 = kp
Zm
Rm
(u −θ Tφ)
= km
ZmP(s)
Rm

k(uf −θ Tφ)

,
(7.32)
where
k = kp
km
,
uf =
1
P(s)u
and
φ =
1
P(s)ω.
An auxiliary error is constructed as
ϵ = e1 −km
ZmP(s)
Rm

ˆk(uf −ˆθ Tφ)
	
−km
ZmP(s)
Rm

ϵn2
s

,
(7.33)
where ˆk is an estimate of k, n2
s = φTφ + u2
f . The adaptive laws are designed as
˙ˆθ = −sgn(bp)	ϵφ,
(7.34)
˙ˆk = γ ϵ(uf −ˆθ Tφ).
(7.35)
With these adaptive laws, a stability result can be obtained for the boundedness of
parameter estimates and the convergence of the tracking error. For the completeness,
we state the theorem below without giving the proof.
Theorem 7.6. For the system (7.28) and the reference model (7.29), the adaptive
control input (7.31) together with the adaptive laws (7.34) and (7.35) ensures the
boundedness of all the variables in the closed-loop system, and the convergence to
zero of the tracking error.
7.5
Robust adaptive control
Adaptive control design and its stability analysis have been carried out under the
condition that there is only parametric uncertainty in the system. However, many
types of non-parametric uncertainties do exist in practice. These include
●
high-frequency unmodelled dynamics, such as actuator dynamics or structural
vibrations
●
low-frequency unmodelled dynamics, such as Coulomb frictions

104
Nonlinear and adaptive control systems
●
measurement noise
●
computation roundoff error and sampling delay
Such non-parametric uncertainties will affect the performance of adaptive control
systems when they are applied to practical systems. They may cause instability. The
difference between adaptive control of linear systems and other design methods is
parameter estimation. Without speciﬁc requirement for input signals, such as persis-
tent excitation, we can only establish the boundedness of estimated parameters, and
the asymptotic convergence to zero of the output error. Therefore, the closed-loop
adaptive system is not even asymptotically stable. For other design methods for linear
systems without parameter adaptation, the closed-loop systems are normally expo-
nentially stable. For a linear system with exponential stability, the state inherently
remain bounded under any bounded input. This is not the case for a linear system
under adaptive control, due to the difference in the stability properties.
Many non-parametric uncertainties can be represented by a bounded disturbance
to the nominal system. Even a bounded disturbance can cause serious problem in
parameter adaptation. Let us consider a simple example.
Consider the system output is described by
y = θω.
(7.36)
The adaptive law
˙ˆθ = γ ϵω,
(7.37)
where
ϵ = y −ˆθω
will render the convergence of the estimate ˆθ by taking
V = 1
2γ
˜θ 2
as a Lyapunov function candidate and the analysis
˙V = −˜θ(y −ˆθω)ω
= −˜θ2ω2.
(7.38)
The boundedness of ˆθ can then be concluded, no matter what the signal ω is.
Now, if the signal is corrupted by some unknown bounded disturbance d(t),
i.e.,
y = θω + d(t).

Adaptive control of linear systems
105
the same adaptive will have a problem. In this case,
˙V = −˜θ(y −ˆθω)ω
= −˜θ(θω + d −ˆθω)ω
= −˜θ 2ω2 −˜θdω
= −
˜θ2ω2
2
−1
2( ˜θω + d)2 + d2
2 .
From the above analysis, we cannot conclude the boundedness of ˜θ even though ω is
bounded. In fact, if we take θ = 2, γ = 1 and ω = (1 + t)−1/2 ∈L∞and let
d(t) = (1 + t)−1/4
5
4 −2(1 + t)−1/4

,
it can then be obtained that
y(t) = 5
4(1 + t)−1/4, →0 as t →∞,
˙ˆθ = 5
4(1 + t)−3/4 −ˆθ(1 + t)−1
which has a solution
ˆθ = (1 + t)1/4 →∞as t →∞.
(7.39)
In this example, we have observed that adaptive law designed for the disturbance-
free system fails to remain bounded even though the disturbance is bounded and
converges to zero as t tends to inﬁnity.
Remark 7.6. If ω is a constant, then from (7.38) we can show that the estimate
exponentially converges to the true value. In this case, there is only one unknown
parameter. If θ is a vector, the requirement for the convergence is much stronger. In
the above example, ω is bounded, but not in a persistent way. It does demonstrate that
even a bounded disturbance can cause the estimated parameter divergent.
◁
Robust adaptive control issue is often addressed by modifying parameter adaptive
laws to ensure the boundedness of estimated parameters. It is clear from the example
shown above that bounded disturbance can cause estimated parameters unbounded.
Various robust adaptive laws have been introduced to keep estimated parameters
bounded in the presence of bounded disturbances. We will show two strategies using
the following simple model:
y = θω + d(t)
(7.40)
with d as a bounded disturbance. In the following we keep using ϵ = y −ˆθω and
V =
˜θ2
2γ . Once the basic ideas are introduced, it is not difﬁcult to extend the robust
adaptive laws to adaptive control of dynamic systems.
Dead-zone modiﬁcation is a modiﬁcation to the parameter adaptive law to stop
parameter adaptation when the error is very close to zero. The adaptive law is
modiﬁed as

106
Nonlinear and adaptive control systems
˙ˆθ =
 γ ϵω
|ϵ| > g
0
|ϵ| ≤g
(7.41)
where g is a constant satisfying g > |d(t)| for all t. For ϵ > g, we have
˙V = −˜θϵω
= −(θω −ˆθω)ϵ
= −(y −d(t) −ˆθω)ϵ
= −(ϵ −d(t))ϵ
< 0.
Therefore, we have
˙V
 < 0,
|ϵ| > g
= 0,
|ϵ| ≤g
and we can conclude that V is bounded. Intuitively, when the error ϵ is small, the
bounded disturbance can be more dominant, and therefore, the correct adaptation
direction is corrupted by the disturbance. In such a case, a simple strategy would be
just to stop parameter adaptation. The parameter adaptation stops in the range |ϵ| ≤g,
and for this reason, this modiﬁcation takes the name ‘dead-zone’ modiﬁcation. The
size of the dead zone depends on the size of the bounded disturbances. One problem
with the dead-zone modiﬁcation is that the adaptive law is discontinuous, and this
may not be desirable in some applications.
σ-Modiﬁcation is another strategy to ensure the boundedness of estimated param-
eters. The adaptive law is modiﬁed by adding an additional term −γ σ ˆθ to the normal
adaptive law as
˙ˆθ = γ ϵω −γ σ ˆθ
(7.42)
where σ is a positive real constant. In this case, we have
˙V = −(ϵ −d(t))ϵ + σ ˜θ ˆθ
= −ϵ2 + d(t)ϵ −σ ˜θ 2 + σ ˜θθ
≤−ϵ2
2 + d2
0
2 −σ
˜θ 2
2 + σ θ 2
2
≤−σγ V + d2
0
2 + σ θ 2
2 ,
(7.43)
where d0 ≥|d(t)|, ∀t ≥0. Applying Lemma 4.5 (comparison lemma) to (7.43),
we have
V(t) ≤e−σγ t + V(0)
 t
0
e−σγ (t−τ)
d2
0
2 + σ θ 2
2

dτ,

Adaptive control of linear systems
107
and therefore we can conclude that V ∈L∞, which implies the boundedness of the
estimated parameter. A bound can be obtained for the bounded parameter as
V(∞) ≤
1
σγ
d2
0
2 + σ θ 2
2

.
(7.44)
Note that this modiﬁcation does not need a bound for the bounded disturbances, and
also it provides a continuous adaptive law. For these reasons, σ-modiﬁcation is one
of the most widely used modiﬁcations for parameter adaptation.
Remark 7.7. We re-arrange the adaptive law (7.42) as
˙ˆθ + γ σ ˆθ = γ ϵω.
Since (γ σ) is a positive constant, the adaptive law can be viewed as a stable ﬁrst-order
dynamic system with (ϵω) as the input and ˆθ as the output. With a bounded input,
obviously ˆθ remains bounded.
◁
The robust adaptive laws introduced here can be applied to various adaptive
control schemes. We demonstrate the application of a robust adaptive law to MRAC
with ρ = 1. We start directly from the error model (7.24) with an additional bounded
disturbance
˙e = Ame + bm(−k ˜θ Tω + d(t))
e1 = cT
me,
(7.45)
where k = kp/km and d(t) are a bounded disturbance with the bound d0, which rep-
resents the non-parametric uncertainty in the system. As discussed earlier, we need a
robust adaptive law to deal with the bounded disturbances. If we take σ-modiﬁcation,
then the robust adaptive law is
˙ˆθ = −sgn(kp)	e1ω −σ	 ˆθ.
(7.46)
We will show that this adaptive law will ensure the boundedness of the variables.
Let
V = 1
2eTPe + 1
2|k| ˜θT	−1 ˜θ.
Similar to the analysis leading to Theorem 7.5, the derivative of V is obtained as
˙V = −1
2eTQe + e1( −k ˜θ Tω + d) + |k| ˜θ T	−1 ˙˜θ
≤−1
2λmin(Q)∥e∥2 + e1d + |k|σ ˜θ T ˆθ
≤−1
2λmin(Q)∥e∥2 + |e1d| −|k|σ∥˜θ∥2 + |k|σ ˜θ Tθ.

108
Nonlinear and adaptive control systems
Note that
|e1d| ≤1
4λmin(Q)∥e∥2 +
d2
0
λmin(Q),
| ˜θTθ| ≤1
2∥˜θ∥2 + 1
2∥θ∥2.
Hence, we have
˙V ≤−1
4λmin(Q)∥e∥2 −|k|σ
2 ∥˜θ∥2 +
d2
0
λmin(Q) + |k|σ
2 ∥θ∥2
≤−αV +
d2
0
λmin(Q) + |k|σ
2 ∥θ∥2,
where α is a positive real and
α =
min{(1/2)λmin(Q), |k|σ}
max{λmax(P), |k|/λmin(	)}.
Therefore, we can conclude the boundedness of V from Lemma 4.5 (comparison
lemma), which further implies the boundedness of the tracking error e1 and the
estimate ˆθ.
From the above analysis, it is clear that the adaptive law with σ-modiﬁcation
ensurestheboundednessofallthevariablesintheclosed-loopadaptivecontrolsystem.
It is worth noting that the output tracking error e1 will not asymptotically converge
to zero, even though the bounded disturbance d(t) becomes zero. That is the price to
pay for the robust adaptive scheme.

Chapter 8
Nonlinear observer design
Observers are needed to estimate unmeasured state variables of dynamic systems.
They are often used for output feedback control design when only the outputs are
available for the control design. Observers can also be used for other estimation pur-
poses such as fault detection and diagnostics. There are many results on nonlinear
observer design in literature, and in this chapter, we can introduce only a number of
results. Observer design for linear systems is brieﬂy reviewed before the introduction
of observers with linear error dynamics. We then introduce another observer design
method based on Lyapunov’s auxiliary theorem, before the observer design for sys-
tems with Lipschitz nonlinearities. At the end of this chapter, adaptive observers are
brieﬂy described.
8.1
Observer design for linear systems
We brieﬂy review the results for linear systems. Consider
˙x = Ax
y = Cx,
(8.1)
where x ∈Rn is the state; y ∈Rm is the system output with m < n; and A ∈Rn×n
and C ∈Rm×n are constant matrices. From linear system theory, we know that this
system, or the pair (A, C), is observable if the matrix
Po =
⎡
⎢⎢⎢⎣
C
CA
...
CAn−1
⎤
⎥⎥⎥⎦
has rank n. The observability condition is equivalent to that the matrix
 λI −A
C
	
has rank n for any value of λ ∈C.
When the system is observable, an observer can be designed as
˙ˆx = Aˆx + L(y −Cˆx),
(8.2)

110
Nonlinear and adaptive control systems
where ˆx ∈Rn is the estimate of the state x, and L ∈Rn×m is the observer gain such
that (A −LC) is Hurwitz.
For the observer (8.2), it is easy to see the estimate ˆx converges to x asymptoti-
cally. Let ˜x = x −ˆx, and we can obtain
˙˜x = (A −LC)˜x.
Remark 8.1. In the observer design, we do not consider control input terms in the
system in (8.1), as they do not affect the observer design for linear systems. In fact, if
Bu term is added to the right-hand side of the system (8.1), for the observer design,
we can simply add it to the right-hand side of the observer in (8.2), and the observer
error will still converge to zero exponentially.
◁
Remark 8.2. The observability condition for the observer design of (8.1) can be
relaxed to the detectability of the system, or the condition that (A, C) is detectable,
for the existence of an observer gain L such that (A −LC) is Hurwitz. Detectability is
weaker than observability, and it basically requires the unstable modes of the system
observable. The pair (A, C) is detectable if the matrix
 λI −A
C
	
has rank n for any λ in the closed right half of the complex plan. Some other design
methods shown in this chapter also need only the condition of detectability, although,
for simplicity, we state the requirement for the observability.
◁
There is another approach to full-state observer design for linear systems (8.1).
Consider a dynamic system
˙z = Fz + Gy,
(8.3)
where z ∈Rn is the state; F ∈Rn×n is Hurwitz; and G ∈Rn×m. If there exists an
invertible matrix T ∈Rn×n such that Z converges to Tx, then (8.3) is an observer with
the state estimate given by ˆx = T −1z. Let
e = Tx −z.
A direction evaluation gives
˙e = TAx −(Fz + GCx)
= F(Tx −z) + (TA −FT −GC)x
= Fe + (TA −FT −GC)x.
If we have
TA −FT −GC = 0,
the system (8.3) is an observer with an exponentially convergent estimation error. We
have the following lemma to summarise this observer design.

Nonlinear observer design
111
Lemma 8.1. The dynamic system (8.3) is an observer for the system (8.1) if and only
if F is Hurwitz and there exists an invertible matrix T such that
TA −FT = GC.
(8.4)
Proof. The sufﬁciency has been shown in the above analysis. For necessity, we only
need to observe that if any of the conditions is not satisﬁed, we cannot guaran-
tee the convergence of e to zero for a general linear system (8.1). Indeed, if (8.4)
is not satisﬁed, then e will be a state variable with a non-zero input, and we can set
up a case such that e does not converge to zero. So does for the condition that F is
Hurwitz.
2
How to ﬁnd matrices F and G such that the condition (8.4) is satisﬁed? We list
the result in the following lemma without the proof.
Lemma 8.2. Suppose that F and A have exclusively different eigenvalues. The nec-
essary condition for the existence of a non-singular solution T to the matrix equation
(8.4) is that the pair (A, C) is observable and the pair (F, G) is controllable. This
condition is also sufﬁcient when the system (8.1) is single output, i.e., m = 1.
This lemma suggests that we can choose a controllable pair (F, G) and make sure
that the eigenvalues of F are different from those of A. An observer can be designed if
there is a solution of T from (8.4). For single output system, the solution is guaranteed.
8.2
Linear observer error dynamics with output injection
Now consider
˙x = Ax + φ(y, u)
y = Cx,
(8.5)
where x ∈Rn is the state, y ∈Rm is the system output with m < n, u ∈Rs is the
control input, or other known variables, A ∈Rn×n and C ∈Rm×n are constant matrices
and φ : Rm × Rs →Rn is a continuous function. This system is a nonlinear system.
However, comparing with the system (8.1), the only difference is the additional term
φ(y, u). The system (8.5) can be viewed as the linear system (8.1) perturbed by the
nonlinear term φ(y, u).
If the pair (A, C) is observable, we can design an observer as
˙ˆx = Aˆx + L(y −Cˆx) + φ(y, u),
(8.6)
where ˆx ∈Rn is the estimate of the state x and L ∈Rn×m is the observer gain such
that (A −LC) is Hurwitz. The only difference between this observer and the one in
(8.2) is the nonlinear term φ(y, u). It can be seen that the observer error still satisﬁes
˙˜x = (A −LC)˜x.

112
Nonlinear and adaptive control systems
Note that even the system (8.5) is nonlinear, the observer error dynamics are
linear. The system in the format of (8.5) is referred to as the system with linear
observer errors. More speciﬁcally, if we drop the control input u in the function φ,
the system is referred to as the output injection form for observer design.
Let us summarise the result in the following proposition.
Proposition 8.3. For the nonlinear system (8.5), a full-state observer can be designed
as in (8.6) if (A, C) is observable. Furthermore, the observer error dynamics are linear
and exponentially stable.
For a nonlinear system in a more general form, there may exist a state transfor-
mation to put the system in the format of (8.5), and then the proposed observer can
be applied.
We will introduce the conditions for the existence of a nonlinear state transfor-
mation to put the system in the format shown in (8.6). Here, we only consider single
output case, and for the simplicity, we do not consider the system with a control input.
The system under consideration is described by
˙x = f (x)
y = h(x),
(8.7)
where x ∈Rn is the state vector, y ∈R is the output, f : Rn →Rn and h : Rn →R
are continuous nonlinear functions with f (0) = 0, and h(0) = 0. We will show that
under what conditions there exists a state transformation
z = (x),
(8.8)
where  : Rn →Rn, such that the transformed system is in format
˙z = Az + φ(Cz)
y = Cz,
(8.9)
where A ∈Rn×n, C ∈R1×n, (A, C) is observable and φ : R →Rn. Without loss of
generality, we take the transformed system (8.9) as
˙z1 = z2 + φ1(y)
˙z2 = z3 + φ2(y)
. . .
˙zn−1 = zn + φn−1(y)
˙zn = φn(y)
y = z1.
(8.10)
This system is in the output injection form for nonlinear observer design.
Remark 8.3. Assume that the system (8.9) is different from (8.10) with (A, C) as
a general observable pair, instead of having the special format implied by (8.10).

Nonlinear observer design
113
In this case, we use a different variable ¯z to denote the state for (8.10), and it can be
written as
˙¯z = ¯A¯z + ¯φ(y)
y = ¯C¯z.
(8.11)
It is clear that there exists a linear transformation
¯z = Tz,
which transforms the system (8.9) to the system (8.11), because (A, C) is observable.
The transformation from (8.7) to (8.11) is given by
¯z = Tφ(x) := ¯(x).
Therefore, if there exists a nonlinear transformation from (8.7) to (8.9), there must
exist a nonlinear transformation from (8.7) to (8.11), and vise versa. That is why
we can consider the transformed system in the format of (8.10) without loss of
generality.
◁
If the state transformation transforms the system (8.7) to (8.9), we must have
∂(x)
∂x
f (x)
	
x=(z)
= Az + φ(Cz)
h((z)) = Cz,
(8.12)
where  = −1. For notational convenience, let us denote
¯f (z) = Az + φ(Cz)
¯h(z) = Cz.
From the structure shown in (8.10), we can obtain
¯h(z) = z1,
L¯f ¯h(z) = z2 + φ1(z1),
L2
¯f ¯h(z) = z3 + ∂φ1
∂z1
(z2 + φ1(z1))
:= z3 + ¯φ2(z1, z2),
. . .
Ln−1
¯f
¯h(z) = zn +
n−2

k=1
∂¯φn−2
∂zk
(zk+1 + φk(z1))
:= zn + ¯φn−1(z1, . . . , zn−1).

114
Nonlinear and adaptive control systems
From the above expression, it is clear that
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
∂¯h
∂z
∂L¯f ¯h(z)
∂z...
∂Ln−1
¯f
¯h(z)
∂z
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎣
1
0
. . .
0
∗
1
. . .
0
...
...
...
...
∗
∗
. . .
1
⎤
⎥⎥⎥⎦
This implies that
d ¯h, dL¯f ¯h, . . . , dLn−1
¯f
¯h
are linearly independent. This property is invariant under state transformation, and
therefore, we need the condition under the coordinate x, that is
dh, dLf h, . . . , dLn−1
f
h
are linearly independent. Indeed, we have
Ln−1
f
h(x) = (Ln−1
¯f
¯h(z))z=(x),
for k = 0, 1, . . . , n −1
and therefore
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
∂h(x)
∂x
∂Lf h(x)
∂x...
∂Ln−1
f
h(x)
∂x
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
∂¯h(z)
∂z
∂L¯f ¯h(z)
∂z...
∂Ln−1
¯f
¯h(z)
∂z
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
z=(x)
∂(x)
∂x
.
The linear independence of dh, dLf h, . . . , dLn−1
f
h is a consequence of the observ-
ability of (A, C) in (8.9). In some literature, this linear independence condition is
deﬁned as the observability condition for nonlinear system (8.7). Unlike linear sys-
tems, this condition is not enough to design a nonlinear observer. We state necessary
and sufﬁcient conditions for the transformation to the output injection form in the
following theorem.
Theorem 8.4. The nonlinear system (8.7) can be transformed to the output injection
form in (8.10) if and only if
●
the differentials dh, dLf h, . . . , dLn−1
f
h are linearly independent
●
there exists a map  : Rn →Rn such that

Nonlinear observer design
115
∂(z)
∂z
=

adn−1
−f r, . . . , ad−f r, r

x=(z) ,
(8.13)
where r is a vector ﬁeld solved from
⎡
⎢⎢⎢⎣
dh
dLf h
...
dLn−1
f
h
⎤
⎥⎥⎥⎦r =
⎡
⎢⎢⎢⎣
0
...
0
1
⎤
⎥⎥⎥⎦.
(8.14)
Proof. Sufﬁciency. From the ﬁrst condition and (8.14), we can show, in a similar way
as for (6.12), that
⎡
⎢⎢⎢⎣
dh(x)
dLf h(x)
...
dLρ−1
f
h
⎤
⎥⎥⎥⎦
 adn−1
−f r(x) . . . ad−f r(x) r(x) 
=
⎡
⎢⎢⎢⎣
1
0
. . .
0
∗
1
. . .
0
...
...
...
...
∗
∗
. . .
1
⎤
⎥⎥⎥⎦.
(8.15)
Therefore,
adn−1
−f r(x) . . . ad−f r(x) r(x)
has full rank. This implies that there exists
an inverse mapping for . Let us denote it as  = −1, and hence we have
∂(x)
∂x
 adn−1
−f r(x) . . . ad−f r(x) r(x) 
= I.
(8.16)
Let us deﬁne the state transformation as z = (x) and denote the functions after this
transformation as
¯f (z) =
∂(x)
∂x
f (x)
	
x=(z)
,
¯h(z) = h((z)).
We need to show that the functions ¯f and ¯h are in the format of the output injection
form as in (8.10). From (8.16), we have
∂(x)
∂x
adn−k
−f r(x) = ek,
for k = 1, . . . , n,
where ek denotes the kth column of the identity matrix. Hence, we have, for
k = 1, . . . , n −1,

116
Nonlinear and adaptive control systems
∂(x)
∂x
adn−k
−f r(x)
	
x=(z)
=
∂(x)
∂x
[−f (x), adn−(k+1)
−f
r(x)]
	
x=(z)
=

−∂(x)
∂x
f (x), ∂(x)
∂x
adn−(k+1)
−f
r(x)
	
x=(z)
=

−¯f (z), ek+1

= ∂¯f (z)
∂zk+1
.
This implies that
∂¯f (z)
∂zk+1
= ek,
for k = 1, . . . , n −1,
i.e.,
∂¯f (z)
∂z
=
⎡
⎢⎢⎢⎢⎢⎣
∗
1
0
. . .
0
∗
0
1
. . .
0
...
...
...
...
...
∗
0
0
. . .
1
∗
0
0
. . .
0
⎤
⎥⎥⎥⎥⎥⎦
.
Therefore, we have shown that ¯f is in the output injection form.
From the second condition, we have
∂(z)
∂zk
= [adn−k
−f (x)r(x)]x=(z)
for k = 1, . . . , n.
Hence, we obtain that, for k = 1, . . . , n,
∂¯h(z)
∂zk
=
∂h(x)
∂x
	
x=(z)
∂(z)
∂zk
=
∂h(x)
∂x
	
x=(z)
[adn−k
−f (x)r(x)]x=(z)
= [Ladn−k
−f (x)r(x)h(x)]x=(z).
Furthermore from (8.15), we have
Ladn−1
−f (x)r(x)h(x) = 1,
Ladn−k
−f (x)r(x)h(x) = 0,
for k = 2, . . . , n.
Therefore, we have
∂¯h(z)
∂z
= [1, 0, . . . , 0].
This concludes the proof for sufﬁciency.

Nonlinear observer design
117
Necessity. The discussion prior to this theorem shows that the ﬁrst condition is
necessary. Assume that there exists a state transformation z = (x) to put the system
in the output injection form, and once again, we denote
¯f (z) =
∂(x)
∂x
f (x)
	
x=(z)
¯h(z) = h((z)),
where  = −1. We need to show that when the functions ¯f and ¯h are in the format
of the output injection form, the second condition must hold. Let
g(x) =
∂(z)
∂zn
	
z=(x)
.
From the state transformation, we have
f (x) =
∂(z)
∂z
¯f (z)
	
z=(x)
.
Therefore, we can obtain
[−f (x), g(x)] =

−
∂(z)
∂z
¯f (z)
	
z=(x)
,
∂(z)
∂zn
	
z=(x)

=
∂(z)
∂z
	
z=(x)

−¯f (z), en

z=(x)
=
∂(z)
∂z
	
z=(x)
∂¯f (z)
∂zn
=
∂(z)
∂z
	
z=(x)
en−1
=
∂(z)
∂zn−1
	
z=(x)
.
Similarly, we can show that
adn−k
−f g =
∂(z)
∂zn−k
	
z=(x)
,
for k = n −2, . . . , 1.
Hence, we have established that
∂(z)
∂z
=

adn−1
−f g, . . . , ad−f g, g

x=(z).
(8.17)

118
Nonlinear and adaptive control systems
The remaining part of the proof is to show that g(x) coincides with r(x) in (8.14).
From (8.17), we have
∂¯h(z)
∂z
= ∂h(x)
∂x
∂(z)
∂z
= ∂h(x)
∂x

adn−1
−f g, . . . , ad−f g, g

x=(z)
= [Ladn−1
−f gh(x), . . . , Lad−f gh(x), Lgh(x)]x=(z).
Since ¯h(z) is in the output feedback form, the above expression implies that
Ladn−1
−f gh(x) = 1,
Ladn−k
−f gh(x) = 0,
for k = 2, . . . , n,
which further imply that
LgLn−1h(x) = 1,
LgLn−kh(x) = 0,
for k = 2, . . . , n,
i.e.,
⎡
⎢⎢⎢⎣
dh
dLf h
...
dLn−1
f
h
⎤
⎥⎥⎥⎦g =
⎡
⎢⎢⎢⎣
0
...
0
1
⎤
⎥⎥⎥⎦.
This completes the proof of necessity.
2
Remark 8.4. It would be interesting to revisit the transformation for linear single-
output systems to the observer canonical form, to reveal the similarities between the
linear case and the conditions stated in Theorem 8.4. For a single output system
˙x = Ax
y = Cx,
(8.18)
where x ∈Rn is the state; y ∈R is the system output; and A ∈Rn×n and C ∈R1×n
are constant matrices. When the system is observable, we have Po full rank.
Solving r from Por = e1, i.e.,
⎡
⎢⎢⎢⎣
C
CA
...
CAn−1
⎤
⎥⎥⎥⎦r =
⎡
⎢⎢⎢⎣
0
...
0
1
⎤
⎥⎥⎥⎦,
and the state transformation matrix T is then given by
T −1 = [An−1r, . . . , Ar, r].
(8.19)

Nonlinear observer design
119
We can show that the transformation z = Tx which transforms the system to the
observer canonical form
˙z = TAT −1z := ¯Az
y = CT −1z := ¯Cz
where
¯A =
⎡
⎢⎢⎢⎢⎢⎣
−a1
1
0
. . .
0
−a2
0
1
. . .
0
...
...
...
...
...
−an−1
0
0
. . .
1
−an
0
0
. . .
0
⎤
⎥⎥⎥⎥⎥⎦
,
¯C = [1 0 . . . 0 0],
with constants ai, i = 1, . . . , n, being the coefﬁcients of the characteristic polynomial
|sI −A| = sn + a1sn−1 + · · · + an−1s + an.
Indeed, from (8.19), we have
AT −1 = [Anr, . . . , A2r, Ar]
(8.20)
Then from Cayley–Hamilton theorem, we have
An = −a1An−1 −· · · −an−1A −anI.
Substituting this into the previous equation, we obtain that
AT −1 = [An−1r, . . . , Ar, r]
⎡
⎢⎢⎢⎢⎢⎣
−a1
1
0
. . .
0
−a2
0
1
. . .
0
...
...
...
...
...
−an−1
0
0
. . .
1
−an
0
0
. . .
0
⎤
⎥⎥⎥⎥⎥⎦
= T −1 ¯A,
which gives
TAT −1 = ¯A.
Again from (8.19), we have
CT −1 = [CAn−1r, . . . , CAr, Cr] = [1, 0, . . . , 0] = ¯C.
If we identify f (x) = Ax and h(x) = Cx, the ﬁrst condition of Theorem 8.4 is that Po
has full rank, and the condition in (8.13) is identical as (8.19).
◁
When the conditions for Theorem 8.4 are satisﬁed, the transformation z = (x)
exists. In such a case, an observer can be designed for the nonlinear system (8.7) as
˙ˆz = Aˆz + L(y −Cˆz) + φ(y)
ˆx = (ˆz),
(8.21)

120
Nonlinear and adaptive control systems
where ˆx ∈Rn is the estimate of the state x of (8.7); ˆz ∈Rn is an estimate of z in (8.10);
and L ∈Rn is the observer gain such that (A −LC) is Hurwitz.
Corollary 8.5. For nonlinear system (8.7), if the conditions for Theorem 8.4 are
satisﬁed, the observer in (8.21) provides an asymptotic state estimate of the system.
Proof. From Theorem 8.4, we conclude that (A, C) is observable, and there exists an
L such that (A −LC) is Hurwitz. From (8.21) and (8.10), we can easily obtain that
˙˜z = (A −LC)˜z
where ˜z = z −ˆz. We conclude that ˆx asymptotically converges to x as limt→∞
˜z(t) = 0.
2
8.3
Linear observer error dynamics via direct state
transformation
Observers presented in the last section achieve the linear observer error dynamics by
transforming the nonlinear system to the output injection form, for which an observer
with linear observer error dynamics can be designed to estimate the transformed state,
andtheinversetransformationisusedtotransformtheestimatefortheoriginalstate. In
this section, we take a different approach by introducing a state transformation which
directly leads to a nonlinear observer design with linear observer error dynamics, and
show that this observer can be directly implemented in the original state space.
We consider the same system (8.7) as in the previous section, and describe it here
under a different equation number for the convenience of presentation
˙x = f (x)
y = h(x),
(8.22)
where x ∈Rn is the state vector, y ∈R is the output, f : Rn →Rn and h : Rn →R
are continuous nonlinear functions with f (0) = 0, and h(0) = 0. We now consider if
there exists a state transformation
z = (x),
(8.23)
where  : Rn →Rn, such that the transformed system is in format
˙z = Fz + Gy,
(8.24)
for a chosen controllable pair (F, G) with F ∈Rn×n Hurwitz, and G ∈Rn. Comparing
(8.24) with (8.9), the matrices F and G in (8.24) are chosen for the observer design,
while in (8.9), A and C are any observable pair which depends on the original system.
Therefore, the transformation in (8.24) is more speciﬁc. There is an extra beneﬁt
gained from this restriction in the observer design as shown later.

Nonlinear observer design
121
From (8.22) and (8.24), the nonlinear transformation must satisfy the following
partial differential equation
∂(x)
∂x
f (x) = F(x) + Gh(x).
(8.25)
Our discussion will be based on a neighbourhood around the origin.
Deﬁnition 8.1. Let λi(A) for i = 1, . . . , n are the eigenvalues of a matrix A ∈Rn. For
another matrix F ∈Rn, an eigenvalue of F is resonant with the eigenvalues of A if
there exists an integer q = n
i=1 qi > 0 with qi being non-negative integers such that
for some j with 1 ≤j ≤n
λj(F) =
n

i=1
qiλi(A).
The following theorem states a result concerning with the existence of a nonlinear
state transformation around the origin for (8.22).
Theorem 8.6. For the nonlinear system (8.22), there exists a state transformation,
i.e., a locally invertible solution to the partial differential equation (8.25) if
●
the linearised model of (8.22) around the origin is observable
●
the eigenvalues of F are not resonant with the eigenvalues of ∂f
∂x(0)
●
the convex hall of

λ1

∂f
∂x(0)

, . . . , λn

∂f
∂x(0)

does not contain the origin
Proof. From the non-resonant condition and the exclusion of the origin of the convex
hall of the eigenvalues of ∂f
∂x(0), we can establish the existence of a solution to the
partial differential equation (8.25) by invoking Lyapunov Auxiliary Theorem. That
the function  is invertible around the origin is guaranteed by the observability of the
linearised model and the the controllability of (F, G). Indeed, with the observability of

∂f
∂x(0), ∂h
∂x(0)

and the controllability of (F, G), we can apply Lemma 8.2 to establish
that ∂
∂x (0) is invertible.
2
With the existence of the nonlinear transformation to put the system in the form
of (8.24), an observer can be designed as
˙ˆz = Fˆz + Gy
ˆx = −1(ˆz),
(8.26)
where  is the inverse transformation of . It is easy to see that the observer error
dynamics are linear as
˙˜z = F˜z.

122
Nonlinear and adaptive control systems
Note that once the transformation is obtained, the observer is directly given without
designing observer gain, unlike the observer design based on the output injection
form.
The observer can also be implemented directly in the original state as
˙ˆx = f (ˆx) +
∂
∂ˆx (ˆx)
−1
G(y −h(ˆx)),
(8.27)
which is in the same structure as the standard Luenberger observer for linear systems
by viewing
 ∂
∂ˆx (ˆx)
−1 G as the observer gain. In the following theorem, we show that
this observer also provides an asymptotic estimate of the system state.
Theorem 8.7. For the nonlinear system (8.22), if the state transformation in (8.25)
exists, the observer (8.27) provides an asymptotic estimate. Furthermore, the
dynamics of the transformed observer error ((x) −(ˆx)) are linear.
Proof. Let e = (x) −(ˆx). Direct evaluation gives
˙e = ∂(x)
∂x
f (x) −∂(ˆx)
∂ˆx

f (ˆx) +
∂
∂ˆx (ˆx)
−1
G(y −h(ˆx))

= ∂(x)
∂x
f (x) −∂(ˆx)
∂ˆx
f (ˆx) −G(y −h(ˆx))
= F(x) + Gy −(F(ˆx) + Gh(ˆx)) −G(y −h(ˆx))
= F((x) −(ˆx))
= Fe.
Therefore, the dynamics of the transformed observer error are linear, and the trans-
formed observer error converges to zero exponentially, which implies the asymptotic
convergence of ˆx to x.
2
Remark 8.5. For linear systems, we have brieﬂy introduced two ways to design
observers. For the observer shown in (8.2), we have introduced the observer shown
in (8.6) to deal with nonlinear systems. The nonlinear observer in (8.27) can be
viewed as a nonlinear version of (8.3). For both cases, the observer error dynamics
are linear.
◁
8.4
Observer design for Lipschitz nonlinear systems
In this section, we will deal with observer design for nonlinear systems with Lipschitz
nonlinearity. We introduced this deﬁnition for a time-varying function in Chapter 2 for
the existence of a unique solution for a nonlinear system. For a time-invariant function,
the deﬁnition is similar, and we list below for the convenience of presentation.

Nonlinear observer design
123
Deﬁnition 8.2. A function φ : Rn × Rs →Rn is Lipschitz with a Lipschitz constant
γ if for any vectors x, ˆx ∈Rn and u ∈Rs
∥φ(x, u) −φ(ˆx, u)∥≤γ ∥x −ˆx∥,
(8.28)
with γ > 0.
Once again we consider linear systems perturbed by nonlinear terms as
˙x = Ax + φ(x, u)
y = Cx,
(8.29)
wherex ∈Rn isthestate; y ∈Rm isthesystemoutputwithm < n; u ∈Rs isthecontrol
input, or other known variables, A ∈Rn×n and C ∈Rm×n are constant matrices with
(A, C) observable; and φ : Rn × Rs →Rn is a continuous function with Lipschitz
constant γ with respect to the state variable x. Comparing with the system (8.5), the
only difference is the nonlinear term φ(x, u). Here, it is a function of state variable,
not only the output, as in (8.5), and therefore the observer design by output injection
does not work.
We can still design an observer based on the linear part of the system, and replace
the unknown state in the nonlinear function by its estimate, that is,
˙ˆx = Aˆx + L(y −Cˆx) + φ(ˆx, u),
(8.30)
where ˆx ∈Rn is the estimate of the state x and L ∈Rn×m is the observer gain. However,
the condition that (A −LC) is Hurwitz is not enough to guarantee the convergence
of the observer error to zero. Indeed, a stronger condition is needed, as shown in the
following theorem.
Theorem 8.8. The observer (8.30) provides an exponentially convergent state esti-
mate if for the observer gain L, there exists a positive deﬁnite matrix P ∈Rn×n such
that
(A −LC)TP + P(A −LC) + γ 2PP + I + ϵI = 0,
(8.31)
where γ is the Lipschitz constant of φ and ϵ is any positive real constant.
Proof. Let ˜x = x −ˆx. From (8.29) and (8.31), we have
˙˜x = (A −LC)˜x + φ(x, u) −φ(ˆx, u).
Let
V = ˜xTP˜x.
Its derivative along the observer error dynamics is obtained as
˙V = ˜xT((A −LC)TP + P(A −LC))˜x + 2˜xTP(φ(x, u) −φ(ˆx, u)).

124
Nonlinear and adaptive control systems
For the term involved with the nonlinear function φ, we have
2˜xTP(φ(x, u) −φ(ˆx, u))
≤γ 2˜xTPP˜x + 1
γ 2 (φ(x, u) −φ(ˆx, u))T(φ(x, u) −φ(ˆx, u))
= γ 2˜xTPP˜x + 1
γ 2 ∥φ(x, u) −φ(ˆx, u)∥2
≤γ 2˜xTPP˜x + ∥˜x∥2
= ˜xT(γ 2PP + I)˜x.
Applying the condition shown in (8.31), we have the derivative of V satisfying
˙V ≤˜xT((A −LC)TP + P(A −LC) + γ 2PP + I)˜x
= −ϵ˜xT ˜x.
This implies that the observer error converges to zero exponentially.
2
In the condition (8.31), ϵ is an arbitrary positive real number. In this case, we
can use inequality to replace the equality, that is
(A −LC)TP + P(A −LC) + γ 2PP + I < 0.
(8.32)
Using the same Lyapunov function candidate as in the proof of Theorem 8.8, we can
show that
˙V < 0
which implies that the observer error converges to zero asymptotically. We summarise
this result below.
Corollary 8.9. The observer (8.30) provides an asymptotically convergent state esti-
mate if for the observer gain L, there exists a positive deﬁnite matrix P ∈Rn×n that
satisﬁes the inequality (8.32).
Remark 8.6. By using the inequality (8.32) instead of the equality (8.31), we only
establish the asymptotic convergence to zero of the observer error, not the exponential
convergencethatisestablishedinTheorem8.8using(8.31). Furthermore, establishing
the asymptotic convergence of the observer error from ˙V < 0 requires the stability
theorems based on invariant sets, which are not covered in this book.
◁
The condition shown in (8.32) can be relaxed if one-side Lipschitz constant is
used instead of the Lipschitz constant.
Deﬁnition 8.3. A function φ : Rn × Rs →Rn is one-sided Lipschitz with respect to
P and one-sided Lipschitz constant ν if for any vectors x, ˆx ∈Rn and u ∈Rs
(x −ˆx)TP(φ(x, u) −φ(ˆx, u)) ≤ν∥x −ˆx∥2
(8.33)
where P ∈Rn×n is a positive real matrix, and ν is a real number.

Nonlinear observer design
125
Note that the one-sided Lipschitz constant ν can be negative. It is easy to see from
the deﬁnition of the one-sided Lipschitz condition that the term (x −ˆx)TP(φ(x, u) −
φ(ˆx, u)) is exactly the cross-term in the proof Theorem 8.8 which causes the term
γ 2PP + I in (8.32). Hence, with the Lipschitz constant ν with respect to P, the
condition shown in (8.32) can be replaced by
(A −LC)TP + P(A −LC) + 2νI < 0.
(8.34)
This condition can be further manipulated to obtain the result shown in the following
theorem.
Theorem 8.10. The observer (8.30) provides an asymptotically convergent state
estimate if the following conditions hold:
L = σP−1CT,
(8.35)
ATP + PA + 2νI −2σCTC < 0,
(8.36)
where P ∈Rn×n is a positive real matrix, σ is a positive real constant and ν is the
one-sided Lipschitz constant of φ with respect to x and P.
Proof. From (8.35), we have
√σCP−1 −LT
√σ
T √σCP−1 −LT
√σ

= 0,
which gives
P−1CTLT + LCP−1 = σP−1CTCP−1 + LLT
σ .
Using (8.35) and multiplying the above equation by P on both sides, we obtain the
identity
CTLTP + PLC = 2σCTC.
From this identity and (8.36), we can easily obtain the inequality (8.34). Similar to
the proof of Theorem 8.8, we let
V = ˜xTP˜x,
and obtain, using the one-sided Lipschitz condition of φ,
˙V = ˜xT((A −LC)TP + P(A −LC))˜x + 2˜xTP(φ(x, u) −φ(ˆx, u))
≤˜xT((A −LC)TP + P(A −LC))˜x. + 2ν˜xT ˜x.
Applying the inequality (8.34) to the above expression, we have
˙V < 0,
which implies that the observer error asymptotically converges to zero.
2

126
Nonlinear and adaptive control systems
To end this section, we consider a class of systems with nonlinear Lipschitz output
function
˙x = Ax
y = h(x),
(8.37)
where x ∈Rn is the state vector, y ∈Rm is the output, A ∈Rn×n is a constant matrix
and h : Rn →Rm is a continuous function. We can write the nonlinear function h as
h = Hx + h1(x) with Hx denoting a linear part of the output, and the nonlinear part
h1 with Lipschitz constant γ .
An observer can be designed as
˙ˆx = Aˆx + L(y −h(ˆx)),
(8.38)
where the observer gain L ∈Rn×m is a constant matrix.
Theorem 8.11. The observer (8.38) provides an exponentially convergent state
estimate of (8.37) if the observer gain L can be chosen to satisfy the following
conditions:
L = 1
γ 2 P−1H T,
(8.39)
PA + ATP −H TH
γ 2
+ (1 + ϵ)I = 0,
(8.40)
where P ∈Rn×n is a positive deﬁnite matrix and ϵ is a positive real constant.
Proof. Let ˜x = x −ˆx. From (8.37) and (8.38), we have
˙˜x = (A −LH)˜x + L(h1(x) −h1(ˆx)).
Let
V = ˜xTP˜x,
where ˜x = x −ˆx. It can be obtained that
˙V = ˜xT((A −LH)TP + P(A −LH))˜x + 2˜xTPL(h1(x) −h1(ˆx))
≤˜xT((A −LH)TP + P(A −LH))˜x + ˜xT(I + γ 2PLLTP)˜x
= ˜xT

ATP + PA −H TH
γ 2
+ I

˜x + ˜xT
H
γ −γ LTP
T H
γ −γ LTP

˜x
= −ϵ˜xT ˜x.
Therefore, we can conclude that ˜x converges to zero exponentially.
2
Remark 8.7. The nonlinearity in the output function with linear dynamics may
occur in some special cases such as modelling a periodic signal as the output of a
second-order linear system. This kind of formulation is useful for internal model
design to asymptotically reject some general periodic disturbances, as shown in
Chapter 10.
◁

Nonlinear observer design
127
8.5
Reduced-order observer design
The observers introduced in the previous sections all have the same order as the
original systems. One might have noticed that an observer provides estimate of the
entire state variables, which include the system output. Only the variables which
are not contained in the output are needed for state estimation from an observer.
This was noticed at the very early stage of the development of observer design of
linear systems, and leads to the design of observers with less order than the original
systems. The observers with less order than the original system are referred to as
reduced-order observers. This section devotes to reduced-order observer design for
nonlinear systems.
Consider a nonlinear system
˙x = f (x, u)
y = h(x),
(8.41)
where x ∈Rn is the state vector, u ∈Rs is the known input, y ∈Rm is the output
and f : Rn × Rs →Rn is a nonlinear smooth vector ﬁeld. To design a reduced-order
observer, we need to study the dynamics of other state variables other than the output.
We can deﬁne a partial-state transformation.
Deﬁnition 8.4. A function g : Rn →Rn−m is an output-complement transformation
if the function T given by
T(x) :=
 h(x)
g(x)
	
is a diffeomorphism, where h(x) is the output function. The transformed states are
referred to as output-complement states.
Clearly an output-complement transformation deﬁnes a state transformation
together with the output function. If the output-complement states are known, then
the state variables can be fully determined. In fact, if we can design an observer for
the output-complement state, this observer is a reduced-order observer.
Deﬁnition 8.5. The dynamic model
˙z = p(z, y) + q(y, u)
(8.42)
is referred to as reduced-order observer form for the system (8.41) if the z = g(x) is
output-complement transformation, and the dynamic system
˙z = p(z, y)
is differentially stable.

128
Nonlinear and adaptive control systems
For a system which can be transformed to a reduced-order observer form, we can
propose a reduced-order observer design as
˙ˆz = p(ˆz, y) + q(y, u)
ˆx = T −1
 y
ˆz
	
.
(8.43)
Theorem 8.12. If the system (8.41) can be transformed to the reduced-order observer
form (8.42), the state estimate ˆx provided by the reduced-order observer in (8.43)
asymptotically converges to the state variable of (8.41).
Proof. First, let us establish the boundedness of z. Since ˙z = p(z, y) is differentially
stable, from the deﬁnition of the differential stability in Chapter 5, there exists a
Lyapunov function, V(z), such that the conditions (5.41) are satisﬁed. Take the same
function V(z) here as the Lyapunov function candidate with ˆz = 0. From (5.41) and
(8.42), we have
˙V ≤−γ3(∥z∥) + ∂V
∂z q(y, u)
≤−γ3(∥z∥) + ∥∂V
∂z ∥∥q(y, u)∥.
(8.44)
Let us recallYoung’s inequality in a simpliﬁed form that for any a ∈R and b ∈R,
and a pair of constants p > 1 and q > 1 with 1
p + 1
q = 1, we have
|ab| ≤ϵp
p |a|p + 1
qϵq |b|q
for any positive real constant ϵ.
Applying Young’s inequality to the second term on the right-hand side of (8.44)
gives

∂V(z)
∂z

q(y, u)
 ≤cc2
4
c2

∂V(z)
∂z

c2
+
1
c3cc3
4
∥q(y, u)∥c3 ,
(8.45)
where c3 =
c2
c2−1, and c4 is an arbitrary positive real constant. We set c4 = ( c1c2
2 )1/c2,
which results in

∂V(z)
∂x
 ∥q(y, u)∥≤c1
2

∂V(z)
∂z

c2
+ 1
2c5∥q(y, u)∥c3,
(8.46)
where c5 =
1
c3 ( 1
2c1c2)−c3
c2 . Substituting (8.46) into (8.44), we have
˙V ≤−1
2γ3(∥z∥) + 1
2c5∥q(y, u)∥c3.
(8.47)
Since q(y, u) is continuous, there exists a class K function ¯g such that, for all y ∈Rm
and u ∈Rs, we have
∥q(y, u)∥≤¯g(∥y∥+ ∥u∥).

Nonlinear observer design
129
We then choose χ(·) = γ −1
3 (2c5(¯g(·))c3). For ∥z∥≥χ(∥y∥+ ∥u∥), we have
γ3(∥z∥) ≥2c5(¯g(∥y∥+ ∥u∥))c3
≥2c5∥q(y, u)∥c3,
which further implies that
˙V ≤−1
4γ3(∥z∥).
(8.48)
Hence, V(z) is an ISS-Lyapunov function, and therefore z is bounded when y is
bounded.
The dynamics of e are given by
˙e = p(z(t), y) −p((z(t) −e), y).
Taking V(e) as the Lyapunov function candidate, we have
˙V = ∂V
∂e (p(z(t), y) −p((z(t) −e), y))
≤−γ3(∥e∥).
Therefore, we can conclude that the estimation error asymptotically converges to zero.
With ˆz as a convergent estimate of z, we can further conclude that ˆx is an asymptotic
estimate of x.
2
To demonstrate the proposed reduced-order observer design, let us consider an
example.
Example 8.1. Consider a second-order system
˙x1 = x2
1 −3x2
1x2 −x3
1
˙x2 = −x2 + x2
1 −6x2x2
1 + 3x2
2x1 −x3
2
y = x1.
Let us check if the system can be transformed to the reduced-order observer
form. For this, we need to ﬁnd g(x). Take
z = g(x) = x2 −x1.
We have
˙z = −x2 −(x2 −x1)3
= −(1 + z2)z + y.
Comparing with the format shown in (8.42), we have p(z, y) = −(1 + z2)z + y. Note
that for the system without input, we always have ˙z = p(z, y). Let V = 1
2z2. It is easy
to see the ﬁrst and the third conditions in (5.41) are satisﬁed. For the second condition,
we have

130
Nonlinear and adaptive control systems
∂V(z −ˆz)
∂z
(p(z) −p(ˆz))
= −(z −ˆz)(z −ˆz + z3 −ˆz3)
= −(z −ˆz)2(1 + z2 −zˆz + ˆz2)
= −(z −ˆz)2(1 + 1
2(z2 + ˆz2 + (z −ˆz)2))
≤−(z −ˆz)2.
Therefore, the system satisﬁes the conditions speciﬁed in (5.41). We design the
reduced-order observer as
˙ˆz = −(1 + ˆz2)ˆz + y
ˆx2 = ˆz + y.
Simulation study has been carried out, and the simulation results are shown in
Figures 8.1 and 8.2.
◁
0
1
2
3
4
5
6
7
8
9
10
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
Time (s)
x1 and x2
x1
x2
Figure 8.1
State variables

Nonlinear observer design
131
0
1
2
3
4
5
6
7
8
9
10
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
Time (s)
x2 and estimate
x2
Estimate of x2
Figure 8.2
Unmeasured state and its estimate
There are lack of systematic design methods for nonlinear observers with global
convergence when there are general nonlinear terms of unmeasured state variables
in the systems. With the introduction of the reduced-order observer form, we like to
further explore the class of nonlinear systems which can be transformed to the format
shown in (8.42), and therefore a nonlinear observer can then be designed accordingly.
We consider a multi-output (MO) nonlinear system
˙x = Ax + φ(y, u) + Eϕ(x, u)
y = Cx,
(8.49)
where x ∈Rn is the state; y ∈Rm is the output; u ∈Rs is the control; φ is a known
nonlinear smooth vector ﬁeld; ϕ : Rn × Rs →Rm is a smooth nonlinear function;
C ∈Rm×n, E ∈Rn×m and A ∈Rn×n are constant matrices, with (A, C) observable.
When ϕ = 0, the system (8.49) degenerates to the well-known form of the non-
linear systems with the linear observer error dynamics, and nonlinear observer can be
easily designed by using nonlinear output injection. With this additional term ϕ, the
nonlinear output injection term can no longer be used to generate a linear observer
error dynamics. We will convert the system to the reduced-order observer form
considered, and then apply the reduced-order observer design for state observation.

132
Nonlinear and adaptive control systems
Without loss of generality, we can assume that C has full row rank. There exists
a nonsingular state transformation M such that
CM −1 = [Im, 0m×(n−m)].
If span{E} is a complement subspace of ker{C} in Rn, we have (CM −1)(ME) = CE
invertible. If we partition the matrix ME as
ME :=
 E1
E2
	
with E1 ∈Rm×m, then we have CE = E1. Furthermore, if we partition Mx as
Mx :=
 χ1
χ2
	
with χ1 ∈Rm, we have
z = g(x) = χ2 −E2E−1
1 χ1.
(8.50)
Note that we have χ1 = y. With the partition of
MAM −1 :=
 A1,1 A1,2
A2,1 A2,2
	
and
Mφ :=
 φ1
φ2
	
,
we can write the dynamics χ1 and χ2 as
˙χ1 = A1,1χ1 + A1,2χ2 + φ1 + E1ϕ
˙χ2 = A2,1χ1 + A2,2χ2 + φ2 + E2ϕ.
Then we can obtain the dynamics of z as
˙z = A2,1χ1 + A2,2χ2 + φ2 −E2E−1
1 (A1,1χ1 + A1,2χ2 + φ1)
= (A2,2 −E2E−1
1 A1,2)χ2 + (A2,1 −E2E−1
1 A1,1)χ1 + φ2 −E2E−1
1 φ1
= (A2,2 −E2E−1
1 A1,2)z + q(y, u),
(8.51)
where
q(y, u) = (A2,2 −E2E−1
1 A1,2)E2E−1
1 y + (A2,1 −E2E−1
1 A1,1)y
+ φ2(y, u) −E2E−1
1 φ1(y, u).
Note that the nonlinear function ϕ(x, u) does not appear in the dynamics of z
in (8.51) due to the particular choice of z in (8.50).
Remark 8.8. After the state transformation, (8.51) is in the same format as (8.42).
Therefore, we can design a reduced-order observer if ˙z = (A2,2 −E2E−1
1 A1,2)z is dif-
ferentially stable. Notice that it is a linear system. Hence, it is differentially stable if it

Nonlinear observer design
133
is asymptotically stable, which means the eigenvalues of (A2,2 −E2E−1
1 A1,2) are with
negative real parts.
◁
Following the format shown in (8.43), a reduced-order observer can then be
designed as
˙ˆz = (A2,2 −E2E−1
1 A1,2)ˆz + q(y, u)
(8.52)
and the estimate of x is given by
ˆx = M −1

y
z + E2E−1
1 y
	
.
(8.53)
Theorem 8.13. For a system (8.49), if
●
C has full row rank, and span{E} is a complement subspace of ker{C} in Rn
●
all the invariant zeros of (A, E, C) are with negative real parts
it can be transformed to the reduced-order observer form. The estimates ˆz given in
(8.52) and ˆx (8.53) converge to the respective state variables z and x exponentially.
Proof. We only need to show that ˙z = p(z, y) is differentially stable, and then we can
apply Theorem 8.12 to conclude the asymptotic convergence of the reduced-order
observer error. The exponential convergence comes as a consequence of the linearity
in the reduced-order observer error dynamics. For (8.52), we have
p(z, y) = (A2,2 −E2E−1
1 A1,2)z,
which is linear in z. Therefore, the proof can be completed by proving that the
matrix (A2,2 −E2E−1
1 A1,2) is Hurwitz. It can be shown that the eigenvalues of
(A2,2 −E2E−1
1 A1,2) are the invariant zeros of (A, E, C). Indeed, we have
 M
0
0
Im
	  sI −A
E
C
0
	  M −1
0
0
Im
	
=
 sI −MAM −1
ME
CM −1
0
	
=
⎡
⎣
sIm −A1,1
−A1,2
E1
−A2,1
sIn−m −A2,2
E2
Im
0
0
⎤
⎦.
(8.54)
Let us multiply the above matrix in the left by the following matrix to perform a row
operation:
⎡
⎣
Im
0
0
−E2E−1
1
In−m
0
0
0
Im
⎤
⎦,

134
Nonlinear and adaptive control systems
we result in the following matrix:
⎡
⎣
sIm −A1,1
−A1,2
E1

sIn−m −(A2,2 −E2E−1
1 A1,2)
0
Im
0
0
⎤
⎦
with
 = −E2E−1
1 (sIm −A1,1) −A2,1.
Since E1 is invertible, any values of s which make the matrix
 sI −A
E
C
0
	
rank deﬁcient must be the eigenvalues of (A2,2 −E2E−1
1 A1,2). From the second condi-
tion that all the invariant zeros of (A, E, C) are with negative real part, we can conclude
that (A2,2 −E2E−1
1 A1,2) is Hurwitz.
2
Example 8.2. Consider a third-order system
˙x1 = −x1 + x2 −y1 + u + x2x3 −x1x3
˙x2 = −x1 + x2 + x3 −2y1 + u + y1y2 + x2x3
˙x3 = −y2
1 + x1x3 + x2x3
y1 = x1
y2 = −x1 + x2.
We can identify
φ =
⎡
⎣
−y1 + u
−2y1 + y1y2 + u
−y2
1
⎤
⎦,
ϕ =
 x2x3 −x1x3
x1x3
	
,
(8.55)
and we have
A =
⎡
⎣
−1
1
0
−1
1
1
0
0
0
⎤
⎦,
E =
⎡
⎣
1
0
1
1
1
2
⎤
⎦,
C =
 1
0
0
−1
1
0
	
.
(8.56)
It can be easily checked that (A, C) is observable and the invariant zero of
(A, E, C) is at −2. Therefore, the conditions in Theorem 8.13 are satisﬁed. It is
also easy to see that x2 = y2 + y1. Therefore, the only unmeasured state variable is
x3. Indeed, following the procedures introduced earlier, we have
M =
⎡
⎣
1
0
0
−1
1
0
0
0
1
⎤
⎦,
E1 =
 1
0
0
1
	
,
E2
 1 2 
,
χ1 =

x1
x2 −x1
	
,
χ2 = x3,

Nonlinear observer design
135
and
z = x3 −y1 −2y2 = x3 + x1 −2x2.
With
A1,1 =
 0
1
0
0
	
,
A1,2 =
 0
1
	
,
A2,1
 0
0 
,
A2,2 = 0,
φ1 =
 −y1 + u
−y1 + y1y2
	
,
φ2 = −y2
1,
we have the dynamics of z as
˙z = −2z + q(y, u),
where
q(y, u) = y1 −5y2 −y2
1 −2y1y2 −u.
A reduced-order observer can then be designed as
˙ˆz = −2ˆz + q(y, u)
ˆx3 = ˆz + y1 + 2y2.
0
2
4
6
8
10
12
14
16
18
20
−6
−5
−4
−3
−2
−1
0
1
Time (s)
x
x1
x2
x3
Figure 8.3
State variables

136
Nonlinear and adaptive control systems
0
2
4
6
8
10
12
14
16
18
20
−1.2
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
Time (s)
x3 and estimate
x3
Estimate of x3
Figure 8.4
Unmeasured state and its estimate
Simulation study has been carried with x(0) = [1, 0, 0.5]T and u = sin t. The
plots of the state variables are shown in Figure 8.3 and the estimated state is shown
in Figure 8.4 .
◁
8.6
Adaptive observer design
When there are unknown parameters in dynamic systems, observers can still be
designed under certain conditions to provide estimates of unknown states by using
adaptive parameters.These observers are referred to as adaptive observers. One would
expect more stringent conditions imposed on nonlinear systems for which adaptive
observers can be designed. In this section, we will consider two classes of nonlinear
systems. The ﬁrst one is based on the nonlinear systems in the output injection form
or output feedback form with unknown parameters and the other class of the systems
is nonlinear Lipschitz systems with unknown parameters.
Consider nonlinear systems which can be transformed to a single-output
system
˙x = Ax + φ0(y, u) + bφT(y, u)θ
y = Cx,
(8.57)

Nonlinear observer design
137
where x ∈Rn is the state, y ∈R is the system output, u ∈Rs is the control input, or
other known variables, A ∈Rn×n, b ∈Rn×1 and C ∈R1×n are constant matrices, with
(A, C) observable, θ ∈Rr is an unknown constant vector, φ0 : Rm × Rs →Rn and
φ : Rm × Rs →Rr are continuous functions. If the parameter vector θ is known, the
system is in the output-injection form.
One would expect that additional conditions are required for the design of
an adaptive observer. If the linear system characterised by (A, b, C) is of relative
degree 1 and minimum phase, we can design an observer gain L ∈Rn such that the
linear system characterised by (A −LC, b, C) is a positive real system. In such a case,
there exist positive real matrices P and Q such that
(A −LC)TP + P(A −LC) = −Q
Pb = CT.
(8.58)
Let us consider the observer designed as
˙ˆx = Aˆx + φ0(y, u) + bφT(y, u) ˆθ + L(y −Cˆx),
(8.59)
where ˆx is the estimate of x and ˆθ is the estimate of θ. We need to design an adaptive
law for ˆθ. Let ˜x = x −ˆx. The observer error dynamics are obtained as
˙˜x = (A −LC)˜x + bφT(y, u) ˜θ,
(8.60)
where ˜θ = θ −ˆθ.
Consider a Lyapunov function candidate
V = ˜xTP˜x + ˜θ T−1 ˜θ,
where  ∈Rn×n is a positive deﬁnite matrix. From (8.58) and (8.60), we have
˙V = ˜xT((A −LC)TP + P(A −LC))˜x + 2˜xTPbφ(y, u)T ˜θ + 2 ˙˜θ T−1 ˜θ
= −˜xTQ˜x + 2˜xTCTφ(y, u)T ˜θ −2 ˙ˆθ T−1 ˜θ
= −˜xTQ˜x −2( ˙ˆθ −(y −Cˆx)φ(y, u))T−1 ˜θ
If we set the adaptive law as
˙ˆθ = (y −Cˆx)φ(y, u),
we obtain
˙V = −˜xTQ˜x.
Then similar to stability analysis of adaptive control systems, we can conclude that
limt→∞˜x(t) = 0, and ˆθ is bounded.The above analysis leads to the following theorem.
Theorem 8.14. For the observable single-output system (8.57), if the linear system
characterised by (A, b, C) is minimum phase and has relative degree 1, there exists an

138
Nonlinear and adaptive control systems
observer gain L ∈Rn that satisﬁes the conditions in (8.58) and an adaptive observer
designed as
˙ˆx = Aˆx + φ0(y, u) + bφT(y, u) ˆθ + L(y −Cˆx)
˙ˆθ = (y −Cˆx)φ(y, u),
(8.61)
where  ∈Rn×n is a positive deﬁnite matrix and provides an asymptotically
convergent state estimate with adaptive parameter vector remaining bounded.
Remark 8.9. In this remark, we will show a particular choice of the observer
gain for the adaptive control observer for a system that satisﬁes the conditions in
Theorem 8.14. Without loss of generality, we assume
A =
⎡
⎢⎢⎢⎢⎢⎣
0
1
0
. . .
0
0
0
1
. . .
0
...
...
...
...
...
0
0
0
. . .
1
0
0
0
. . .
0
⎤
⎥⎥⎥⎥⎥⎦
,
b =
⎡
⎢⎢⎢⎢⎢⎣
b1
b2
...
bn−1
bn
⎤
⎥⎥⎥⎥⎥⎦
,
C = [1
0
. . .
0
0],
where b1 ̸= 0, since the relative degree is 1. Indeed, for an observer system {A, b, C}
with relative degree 1, there exists a state transformation, as shown in Remark 8.4, to
transform the system to the observable canonical form. Furthermore, if we move the
ﬁrst column of A in the canonical form, and combine it with φ0(y, u), we have A as in
the format shown above. Since the system is minimum phase, b is Hurwitz, i.e.,
B(s) := b1sn−1 + b2sn−2 + · · · + bn−1s + bn = 0
has all the solutions in the left half of the complex plane. In this case, we can design
the observer gain to cancel all the zeros of the system. If we denote L = [l1, l2, . . . , ln],
we can choose L to satisfy
sn + l1sn−1 + l2sn−2 + · · · + ln−1s + ln = B(s)(s + λ),
where λ is a positive real constant. The above polynomial equation implies
L = (λI + A)b.
This observer gain ensures
C (sI −(A −LC))−1 b =
1
s + λ,
which is a strict positive real transfer function.
◁
Now we will consider adaptive observer design for a class of Lipschitz nonlinear
systems. Consider
˙x = Ax + φ0(x, u) + bφT(x, u)θ
y = Cx,
(8.62)

Nonlinear observer design
139
where x ∈Rn is the state, y ∈R is the system output, u ∈Rs is the control input,
or other known variables, A ∈Rn×n, b ∈Rn×1 and C ∈R1×n are constant matrices,
with (A, C) observable, θ ∈Rr is an unknown constant vector, φ0 : Rn × Rs →Rn
and φ : Rm × Rs →Rr are Lipschitz nonlinear functions with Lipschitz constants γ1
and γ2 with respect to x.
This system is only different in nonlinear functions from the system (8.57) consid-
ered earlier for adaptive observer design, where the nonlinear functions are restricted
to the functions of the system output only, but the functions do not have to be globally
Lipschitz for a globally convergent observer.
We propose an adaptive observer for (8.62) as
˙ˆx = Aˆx + φ0(ˆx, u) + bφT(ˆx, u) ˆθ + L(y −Cˆx)
˙ˆθ = (y −Cˆx)φ(ˆx, u),
(8.63)
where L ∈Rn is an observer gain and  ∈Rn×n is a positive deﬁnite matrix.
When state variables other than the system output are involved in the nonlinear
functions, we often impose the conditions that the nonlinear function are Lipschitz,
and the conditions are more stringent for designing an observer than the nonlinear
systems with only nonlinear functions of the system output. We have considered
adaptiveobserverdesignforaclassofnonlinearsystems(8.57)withonlythenonlinear
functions of the system output. For the adaptive observer (8.63) to work for the system
(8.62), we will expect stronger conditions for adaptive observer design. For this, we
state the following result.
Theorem 8.15. The adaptive observer proposed in (8.63) provides an asymptotically
convergent state estimate for the system (8.62) if there exists a positive deﬁnite matrix
P such that
(A −LC)TP + P(A −LC) + (γ1 + γ2γ3∥b∥)(PP + I) + ϵI ≤0
Pb = CT,
(8.64)
where γ3 ≥∥θ∥, and ϵ is a positive real constant.
Proof. Let ˜x = x −ˆx. The observer error dynamics are obtained as
˙˜x = (A −LC)˜x + φ0(x, u) −φ0(ˆx, u) + b(φT(y, u)θ −φT(ˆx, u)T ˆθ)
= (A −LC)˜x + φ0(x, u) −φ0(ˆx, u) + b(φ(x, u) −φ(ˆx, u))Tθ
+ bφT(ˆx, u) ˜θ,
(8.65)
where ˜θ = θ −ˆθ. Consider a Lyapunov function candidate
V = ˜xTP˜x + ˜θ T−1 ˜θ.
Its derivative along the dynamics in (8.65) is obtained as
˙V = ˜xT((A −LC)TP + P(A −LC))˜x + 2˜xTP(φ0(x, u) −φ0(ˆx, u))
+ 2˜xTPb(φ(x, u) −φ(ˆx, u))Tθ + 2˜xTPbφT(ˆx, u) ˜θ + 2 ˙˜θ T−1 ˜θ.

140
Nonlinear and adaptive control systems
From the Lipschitz constants of φ0 and φ, we have
2˜xTP(φ0(x, u) −φ0(ˆx, u)) ≤γ1˜xT(PP + I)˜x,
2˜xTPb(φ(x, u) −φ(ˆx, u))Tθ ≤γ2γ3∥b∥˜xT(PP + I)˜x.
Then from the adaptive law and (8.64), we have
˙V ≤˜xT((A −LC)TP + P(A −LC) + (γ1 + γ2γ3∥b∥)(PP + I))˜xT
+ 2˜xTCTφT(ˆx, u) ˜θ −2 ˙ˆθ T−1 ˜θ
≤−ϵ˜xT ˜x.
This implies that the variables ˜x and ˜θ are bounded, and furthermore ˜x ∈L2 ∩L∞.
Since all the variables are bounded, ˙˜x is bounded, from ˜x ∈L2 ∩L∞and the
boundedness of ˙˜x, we conclude limt→∞˜x(t) = 0 by invoking Babalat’s Lemma.
2

Chapter 9
Backstepping design
For a nonlinear system, the stability around an equilibrium point can be established
if one can ﬁnd a Lyapunov function. Nonlinear control design can be carried out by
exploring the possibility of making a Lyapunov function candidate as a Lyapunov
function through control design. In Chapter 7, parameter adaptive laws are designed
in this way by setting the parameter adaptive laws to make the derivative of a Lyapunov
function candidate negative semi-deﬁnite. Backstepping is a nonlinear control design
method based on Lyapunov functions. It enables a designed control to be extended to
an augmented system, provided that the system is augmented in some speciﬁc way.
One scheme is so-called adding an integrator in the sense that if a control input is
designed for a nonlinear system, then one can design a control input for the augmented
system of which an integrator is added between the original system input and the
input to be designed. This design strategy can be applied iteratively. There are a few
systematic control design methods for nonlinear systems, and backstepping is one
of them. In this chapter, we start with the fundamental form of adding an integrator,
and then introduce the method for iterative backstepping with state feedback. We also
introduce backstepping using output feedback, and adaptive backstepping for certain
nonlinear systems with unknown parameters.
9.1
Integrator backstepping
Consider
˙x = f (x) + g(x)ξ
˙ξ = u,
(9.1)
where x ∈Rn and ξ ∈R are the state variables; u ∈R is the control input; and f :
Rn →Rn with f (0) = 0 and g : Rn →Rn are continuous functions. Viewing the
ﬁrst equation of (9.1) as the original system with x as the state and ξ as the input,
the integration of u gives ξ, which means that an integrator is added to the original
system.
We consider the control design problem under the assumption that a known
control input exists for the original system. Furthermore, we assume that the Lyapunov
function is also known, associated with the known control for x-subsystem. Suppose
that control input for the x-subsystem is α(x) with α differentiable and α(0) = 0, and
the associated Lyapunov function is V(x). We assume that

142
Nonlinear and adaptive control systems
∂V
∂x (f (x) + g(x)α(x)) ≤−W(x),
(9.2)
where W(x) is positive deﬁnite.
Condition (9.2) implies that the system ˙x = f (x) + g(x)α(x) is asymptotically
stable. Consider
˙x = f (x) + g(x)α(x) + g(x)(ξ −α(x)).
Intuitively, if we can design a control input u = u(x, ξ) to force ξ to converge to α(x),
we have a good chance to ensure the stability of the entire system. Let us deﬁne
z = ξ −α(x).
It is easy to obtain the dynamics under the coordinates (x, z) as
˙x = f (x) + g(x)α(x) + g(x)z
˙z = u −˙α = u −∂α
∂x (f (x) + g(x)ξ).
Consider a Lyapunov function candidate
Vc(x, z) = V(x) + 1
2z2.
(9.3)
Its derivative is given by
˙Vc = ∂V
∂x (f (x) + g(x)α(x)) + ∂V
∂x g(x)z
+ z

u −∂α
∂x (f (x) + g(x)ξ)

= −W(x) + z

u + ∂V
∂x g(x) −∂α
∂x (f (x) + g(x)ξ)

.
Let
u = −cz −∂V
∂x g(x) + ∂α
∂x (f (x) + g(x)ξ)
(9.4)
with c > 0 which results in
˙Vc = −W(x) −cz2.
(9.5)
It is clear that −W(x) −cz2 is negative deﬁnite with respect to variables (x, z). Hence,
we can conclude that Vc(x, z) is a Lyapunov function, and that (0, 0) in the coordinates
(x, z) is a globally asymptotic equilibrium. From α(0) = 0, we can conclude that (0, 0)
in the coordinates (x, ξ) is also a globally asymptotic equilibrium, which means that
the system (9.1) is globally asymptotically stable under the control input (9.4). We
summarise the above result in the following lemma.
Lemma 9.1. For a system described in (9.1), if there exist differentiable function α(x)
and a positive-deﬁnite function V(x) such that (9.2) holds, the control design given
in (9.4) ensures the global asymptotic stability of the closed-loop system.

Backstepping design
143
Remark 9.1. Considering the structure of (9.1), if ξ is viewed as the control input for
the x-subsystem, ξ = α(x) is the desired control, ignoring the ξ-system. This is why
ξ can be referred to as a virtual control input for the x-subsystem. The control input
u for the overall system is designed with the consideration of the dynamics back to
the control design for the x-subsystem, and it may suggest the name of this particular
design method as backstepping.
◁
Example 9.1. Consider
˙x1 = x2
1 + x2
˙x2 = u.
We design a control input using backstepping. Comparing with (9.1), we can identify
x ⇒x1,
ξ ⇒x2,
f (x) ⇒x2
1,
g(x) ⇒1.
First, we need to design α(x1) to stabilise
˙x1 = x2
1 + α(x1).
An obvious choice is
α(x1) = −c1x1 −x2
1
with c1 > 0 a constant. This design leads to
˙x1 = x2
1 + α(x1) = −c1x1.
Hence, we take
V(x1) = 1
2x2
1
with
˙V(x1) = −c1x2
1.
Therefore, the condition speciﬁed in Lemma 9.1 is satisﬁed with α(x1) = −c1x1 −
x2
1, V(x1) = 1
2x2
1 and W(x1) = −c1x2
1. The control input u can then be obtained
from (9.4) by substituting proper functions in the equation. Alternatively, we can
obtain the control input by directly following the backstepping method. Indeed, let
z = x2 −α(x1). The dynamics of the system in coordinate (x1, z) are obtained as
˙x1 = −c1x1 + z
˙z = u −∂α(x1)
∂x1
(x2
1 + x2),
where
∂α(x1)
∂x1
= −c1 −2x1.
Let
Vc(x1, z) = 1
2x2
1 + 1
2z2.

144
Nonlinear and adaptive control systems
Its derivative along the system dynamics is obtained as
˙Vc(x1, z) = −c1x2
1 + x1z + z

u −∂α(x1)
∂x1
(x2
1 + x2)

.
Designing the control u as
u = −x1 −c2z + ∂α(x1)
∂x1
(x2
1 + x2)
results in
˙Vc(x1, z) = −c1x2
1 −c2z2.
Hence, the system is asymptotically stable with (x1, z). As α(0) = 0, we con-
clude limt→∞x2(t) = limt→∞(z(t) + α(x1(t))) = 0, which implies that the system
is asymptotically stable in the equilibrium (0, 0) in (x1, x2). Note that the closed-loop
system in (x1, z) is written as

˙x1
˙z

=

−c1
1
−1
−c2
 
x1
z

.
◁
In Example 9.1, backstepping design has been used to design a control input for a
nonlinear system with unmatched nonlinearities. When a nonlinear function appears
in the same line as the control input, it is referred as a matched nonlinear function,
and it can be cancelled by adding the same term in u with an opposite sign. From the
system considered in Example 9.1, the nonlinear function x2
1 does not appear in the
same line as the control input u, and therefore it is unmatched. However, it is in the
same line as x2, which is viewed as a virtual control. As a consequence, α(x1), which
is often referred to as a stabilising function, can be designed to cancel the nonlinearity
which matches with the virtual control, and backstepping method enables the control
in the next line to be designed to stabilise the entire system. This process can be
repeated by identifying a virtual control, designing a stabilising function and using
backstepping to design control input for more complicated nonlinear systems.
9.2
Iterative backstepping
Consider a nonlinear system
˙x1 = x2 + φ1(x1)
˙x2 = x3 + φ2(x1, x2)
. . .
(9.6)
˙xn−1 = xn + φn−1(x1, x2, . . . , xn−1)
˙xn = u + φn(x1, x2, . . . , xn)

Backstepping design
145
where xi ∈R for i = 1, . . . , n are state variables;
φi :
i

	

R × · · · × R →R for
i = 1, . . . , n are differentiable functions up to the order n −i with φi(0, . . . , 0) = 0;
and u ∈R is the control input.
When xi+1 in the ith equation of (9.6) is identiﬁed as the virtual control, the non-
linear function φi is then matched with respect to the virtual control, and backstepping
method can be applied to move down the control design to (i + 1)th equation with
xi+2 as the next virtual control. This process starts from i = 1 and can be repeated
until i = n −1 when u is reached. We will present this iterative backstepping design
for the system (9.6) in n steps. In each step, we could show the Lyapunov function
and other details for which Lemma 9.1 can be applied to. Although, for the simplicity
of the control design, we leave the stability analysis to the end, stability is considered
in designing the stabilising function at each step. The control design will be shown
in n steps.
Let
z1 = x1,
zi = xi −αi−1(x1, . . . , xi−1),
for i = 2, . . . , n,
where αi−1 for i = 2, . . . , n are stabilising functions obtained in the iterative
backstepping design.
Step 1. For the design of the stabilising function, we arrange the dynamics of z1 as
˙z1 = (x2 −α1) + α1 + φ1(x1)
= z2 + α1 + φ1(x1).
Let
α1 = −c1z1 −φ1(x1).
(9.7)
The resultant dynamics of z1 are
˙z1 = −c1z1 + z2.
(9.8)
Step 2. The dynamics of z2 are obtained as
˙z2 = ˙x2 −˙α1
= x3 + φ2(x1, x2) −∂α1
∂x1
(x2 + φ1(x1))
= z3 + α2 + φ2(x1, x2) −∂α1
∂x1
(x2 + φ1(x1)).
Design α2 as
α2 = −z1 −c2z2 −φ2(x1, x2) + ∂α1
∂x1
(x2 + φ1(x1)).
(9.9)
The resultant dynamics of z2 are given by
˙z2 = −z1 −c2z2 + z3.
(9.10)

146
Nonlinear and adaptive control systems
Note that the term −z1 in α2 is used to tackle a cross-term caused by z2 in the dynamics
of z1 in the stability analysis. Other terms in α2 are taken to cancel the nonlinear terms
and stabilise the dynamics of z2.
Step i. For 2 < i < n, the dynamics of zi are given by
˙zi = ˙xi −˙αi−1(x1, . . . , xi−1)
= xi+1 + φi(x1, . . . , xi)
−
i−1

j=1
∂αi−1
∂xj
(xj+1 + φj(x1, . . . , xj))
= zi+1 + αi + φi(x1, . . . , xi)
−
i−1

j=1
∂αi−1
∂xj
(xj+1 + φj(x1, . . . , xj)).
Design αi as
αi = −zi−1 −cizi −φi(x1, . . . , xi)
+
i−1

j=1
∂αi−1
∂xj
(xj+1 + φj(x1, . . . , xj)).
(9.11)
The resultant dynamics of zi are given by
˙zi = −zi−1 −cizi + zi+1.
(9.12)
Note that similar to the design of α2, the term −zi−1 is used to tackle a cross-term
caused by zi in the dynamics of zi−1 in the stability analysis, and the other terms in αi
are used to stabilise the dynamics of zi.
Step n. At the ﬁnal step, we have
˙zn = ˙xn −˙αn−1(x1, . . . , xn−1)
= u + φn(x1, . . . , xn)
−
n−1

j=1
∂αn−1
∂xj
(xj+1 + φj(x1, . . . , xj)).
Design the control input as
u = −zn−1 −cnzn −φn(x1, . . . , xn)
+
n−1

j=1
∂αn−1
∂xj
(xj+1 + φj(x1, . . . , xj)).
(9.13)
The resultant dynamics of zn are given by
˙zn = −zn−1 −cnzn.
(9.14)

Backstepping design
147
Note that we can write u = αn by setting i = n in the expression of αi in (9.11).
Let us establish the stability of the closed-loop system under the proposed
control. The closed-loop dynamics of the system in coordinate z = [z1, . . . , zn]T can
be written as
˙z =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
−c1
1
0
. . .
0
−1
−c2
1
...
0
0
−1
−c3
...
0
...
...
...
...
1
0
0
0
...
−cn
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
z := Azz.
Notice that all the off-diagonal Az are skew symmetric. Let
V = 1
2zTz.
(9.15)
Its derivative along the dynamics of z is obtained as
˙V = −
n

i=1
ciz2
i ≤−2
n
min
i=1 ciV.
(9.16)
Therefore, we can conclude that the system is exponentially stable in z-coordinate.
From the property that φi(0, . . . , 0) = 0 for i = 1, . . . , n, we can establish that
αi(0, . . . , 0) = 0 for i = 1, . . . , n −1 and u(0, . . . , 0) = 0,
which implies that
limt→∞xi(t) = 0 for i = 1, . . . , n. Hence, we have established the following result.
Theorem 9.2. For a system in the form of (9.6), the control input (9.13) renders the
closed-loop system asymptotically stable.
9.3
Observer backstepping
We have presented integrator backstepping and iterative backstepping based on state
feedback. In this section, we present a control design for nonlinear systems using
output feedback. An observer is designed, and the observer state, or estimate of the
state variables of the original system, is then used for backstepping design.
Consider a nonlinear system which can be transformed to
˙x = Acx + bu + φ(y)
y = Cx
(9.17)
with

148
Nonlinear and adaptive control systems
Ac =
⎡
⎢⎢⎢⎢⎢⎣
0
1
0
. . .
0
0
0
1
. . .
0
...
...
...
...
...
0
0
0
. . .
1
0
0
0
. . .
0
⎤
⎥⎥⎥⎥⎥⎦
,
C =
⎡
⎢⎢⎢⎣
1
0
...
0
⎤
⎥⎥⎥⎦
T
,
b =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
...
0
bρ
...
bn
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
,
where x ∈Rn is the state vector; u ∈R is the control; φ : R →Rn with φ(0) = 0 is
a nonlinear function with element φi being differentiable up to the (n −i)th order;
and b ∈Rn is a known constant Hurwitz vector with bρ ̸= 0, which implies that the
relative degree of the system is ρ. This form of the system is often referred to as the
output feedback form. Since b is Hurwitz, the linear system characterised by (Ac, b, C)
is minimum phase. Note that a vector is said Hurwitz if its corresponding polynomial
is Hurwitz.
Remark 9.2. For a system in the output feedback form, if the input is zero, the
system is in exactly the same form as (8.10). We have shown the geometric conditions
in Chapter 8 for systems to be transformed to the output injection form (8.10), and
similar geometric conditions can be speciﬁed for nonlinear systems to be transformed
to the output feedback form. Clearly we can see that for the system (9.17) with any
observable pair (A, C), there exists a linear transformation to put the system in the
form of (9.17) with the speciﬁc (Ac, C).
◁
Since the system (9.17) is in the output injection form, we design an observer as
˙ˆx = Acx + bu + φ(y) + L(y −Cˆx),
(9.18)
where ˆx ∈Rn is the state estimate and L ∈Rn is an observer gain designed such that
(A −LC) is Hurwitz. Let ˜x = x −ˆx, and it is easy to see
˙˜x = (Ac −LC)˜x.
(9.19)
The backstepping design can be carried out with the state estimate ˆx in ρ steps.
From the structure of the system (9.17) we have y = x1. The backstepping design will
start with the dynamics of y. In the following design, we assume ρ > 1. In the case
of ρ = 1, control input can be designed directly without using backstepping.
To apply the observer backstepping through ˆx in (9.18), we deﬁne
z1 = y,
zi = ˆxi −αi−1,
i = 2, . . . , ρ,
(9.20)
zρ+1 = ˆxρ+1 + bρu −αρ,
where αi, i = 1, . . . , ρ, are stabilising functions decided in the control design.
Consider the dynamics of z1
˙z1 = x2 + φ1(y).
(9.21)

Backstepping design
149
We use ˆx2 to replace the unmeasurable x2 in (9.21), resulting at
˙z1 = ˆx2 + ˜x2 + φ1(y)
= z2 + α1 + ˜x2 + φ1(y).
(9.22)
We design α1 as
α1 = −c1z1 −k1z1 −φ1(y),
(9.23)
where ci and ki for i = 1, . . . , ρ are positive real design parameters. Comparing the
backstepping design using the output feedback with the one using state feedback, we
have one additional term, −k1z1, which is used to tackle the observer error ˜x2 in the
closed-loop system dynamics. Then from (9.22) and (9.23), we have
˙z1 = z2 −c1z1 −k1z1 + ˜x2.
(9.24)
Note that α1 is a function of y, i.e., α1 = α1(y).
For the dynamics of z2, we have
˙z2 = ˙ˆx2 −˙α1
= ˆx3 + φ2(y) + l2(y −ˆx1) −∂α1
∂y (x2 + φ1(y))
= z3 + α2 + φ2(y) + l2(y −ˆx1) −∂α1
∂y (ˆx2 + ˜x2 + φ1(y)).
where l2 is the second element of the observer gain L, and in the subsequent design,
li is the ith element of L. We design α2 as
α2 = −z1 −c2z2 −k2
∂α1
∂y
2
z2 −φ2(y) −l2(y −ˆx1)
+∂α1(y)
∂y
(ˆx2 + φ1(y)).
(9.25)
Note that α2 = α2(y, ˆx1, ˆx2). The resultant dynamics of z2 are given by
˙z2 = −z1 −c2z2 −k2
∂α1
∂y
2
z2 + z3 −∂α1
∂y ˜x2.
For the dynamics of zi, 2 < i ≤ρ, we have
˙zi = ˙ˆxi −˙αi−1
= zi+1 + αi + φi(y) + li(y −ˆx1)
−∂αi−1
∂y (ˆx2 + ˜x2 + φ1(y)) −
i−1

j=1
∂αi−1
∂ˆxj
˙ˆxj.

150
Nonlinear and adaptive control systems
We design αi, 2 < i ≤ρ, as
αi = −zi−1 −cizi −ki
∂αi−1
∂y
2
zi −φi(y) −li(y −ˆx1)
+ ∂αi−1
∂y (ˆx2 + φ1(y)) +
i−1

j=1
∂αi−1
∂ˆxj
˙ˆxj.
(9.26)
Note that αi = αi(y, ˆx1, . . . , ˆxi). The resultant dynamics of zi, 2 < i ≤ρ, are given by
˙zi = −zi−1 −cizi −ki
∂αi−1
∂y
2
zi + zi+1 −∂αi−1
∂y
˜x2.
(9.27)
When i = ρ, the control input appears in the dynamics of zi, and it is included in zρ+1,
as shown in the deﬁnition (9.20). We design the control input by setting zρ+1 = 0,
which gives
u = αρ(y, ˆx1, . . . , ˆxρ) −ˆxρ+1
bρ
.
(9.28)
The stability result of the above control design is given in the following theorem.
Theorem 9.3. For a system in the form of (9.17), the dynamic output feedback control
with the input (9.28) and the observer (9.18) asymptotically stabilise the system.
Proof. From the observer error dynamics, we know that the error exponentially con-
verges to zero. Since (Ac −LC) is Hurwitz, there exists a positive deﬁnite matrix
P ∈Rn×n such that
(Ac −LC)TP + P(Ac −LC) = −I.
This implies that for
Ve = ˜xTP˜x,
we have
˙Ve = −∥˜x∥2.
(9.29)
Let
Vz =
ρ

i=1
z2
i .
From the dynamics of z1, z2 and zi, we can obtain that
˙Vz =
ρ

i=1

−ciz2
i −ki
∂αi−1
∂y
2
z2
i −∂αi−1
∂y zi˜x2

,
where we deﬁne α0 = y for notational convenience. Note that if we ignore the two
terms concerning with ki and ˜x2 in the dynamics of zi, the evaluation of the derivative

Backstepping design
151
of Vz will be exactly the same as the stability analysis that leads to Theorem 9.2. For
the cross-term concerning with ˜x2, we have, from Young’s inequality,

∂αi−1
∂y zi˜x2
 ≤ki
∂αi−1
∂y
2
z2
i + 1
4ki
˜x2
2.
Hence, we obtain that
˙Vz ≤
ρ

i=1

−ciz2
i + 1
4ki
˜x2
2

.
(9.30)
Let
V = Vz +

1 + 1
4d

Ve,
where d = minρ
i=1 ki. From (9.29) and (9.30), we have
˙V ≤
ρ

i=1

−ciz2
i + 1
4ki
˜x2
2

−

1 + 1
4d

∥˜x∥2
≤−
ρ

i=1
ciz2
i −∥˜x∥2.
Therefore, we can conclude that zi for i = 1, . . . , ρ and ˜x exponentially converge to
zero. Noticing that y = z1, and α1(0) = 0, we can conclude that limt→∞ˆx2(t) = 0,
which further implies that limt→∞x2(t) = 0. Following the same process, we can
show that limt→∞xi(t) = 0 for i = 1, . . . , ρ.
We still need to establish the stability property for xi, with i = ρ + 1, . . . , n. Let
ξ =
⎡
⎢⎣
xρ+1
...
xn
⎤
⎥⎦−
⎡
⎢⎣
bρ+1
...
bn
⎤
⎥⎦xρ
bρ
,
and from the system dynamics (9.17), it can be shown that
˙ξ = Bξ +
⎡
⎢⎣
φρ+1(y)
...
φn(y)
⎤
⎥⎦−
⎡
⎢⎣
bρ+1
...
bn
⎤
⎥⎦φρ(y)
bρ
+ B
⎡
⎢⎣
bρ+1
...
bn
⎤
⎥⎦xρ
bρ
,
(9.31)
where
B =
⎡
⎢⎢⎢⎢⎢⎢⎣
−bρ+1/bρ
1
. . .
0
−bρ+2/bρ
0
...
0
...
...
...
...
−bn−1/bρ
0
. . .
1
−bn/bρ
0
. . .
0
⎤
⎥⎥⎥⎥⎥⎥⎦

152
Nonlinear and adaptive control systems
is a companion matrix associated with vector b. Since b is Hurwitz, the matrix B is
Hurwitz. All the terms other than Bξ in the right-hand side of (9.31) converge to zero,
which implies that limt→∞ξ(t) = 0. Therefore, we can conclude limt→∞xi(t) = 0 for
i = ρ + 1, . . . , n. This concludes the proof.
2
9.4
Backstepping with ﬁltered transformation
We have presented backstepping design for a class of dynamic systems using output
feedback in the previous section. The control design starts from the system output
and the subsequent steps in the backstepping design are carried out with estimates of
state variables provided by an observer. The backstepping design, often referred to
as observer backstepping, completes in ρ steps, with ρ being the relative degree of
the system, and other state estimates of xi for i > ρ are not used in the design. Those
estimates are redundant, and make the dynamic order of the controller higher. There
is an alternative design method to observer backstepping for nonlinear systems in the
output feedback form, of which the resultant order of the controller is exactly ρ −1.
In this section, we present backstepping design with ﬁltered transformation for the
system (9.17), of which the main equations are shown here again for the convenience
of presentation,
˙x = Acx + bu + φ(y)
y = Cx.
(9.32)
Deﬁne an input ﬁlter
˙ξ1 = −λ1ξ1 + ξ2
...
(9.33)
˙ξρ−1 = −λρ−1ξρ−1 + u,
where λi > 0 for i = 1, . . . , ρ −1 are the design parameters. Deﬁne the ﬁltered
transformation
¯ζ = x −
ρ−1

i=1
¯diξi,
(9.34)
where ¯di ∈Rn for i = 1, . . . , ρ −1 and they are generated recursively by
¯dρ−1 = b,
¯di = (Ac + λi+1I)¯di+1
for i = ρ −2, . . . , 1.
We also denote
d = (Ac + λ1I)¯d1.

Backstepping design
153
From the ﬁltered transformation, we have
˙¯ζ = Acx + bu + φ(y) −
ρ−2

i=1
¯di(−λiξi + ξi+1) −¯dρ−1(−λiξρ−1 + u)
= Ac ¯ζ +
ρ−1

i=1
A¯diξi + φ(y) +
ρ−1

i=1
¯diλiξi −
ρ−2

i=1
¯diξi+1
= Ac ¯ζ +
ρ−1

i=1
(A + λiI)¯diξi + φ(y) −
ρ−2

i=1
¯diξi+1
= Ac ¯ζ + φ(y) + dξ1.
The output under the coordinate ¯ζ is given by
y = C ¯ζ +
ρ−1

i=1
C ¯diξi
= C ¯ζ
because C ¯di = 0 for i = 1, . . . , ρ −1, from the fact that ¯di,j = 0 for i = 1, . . . ,
ρ −1, 1 ≤j ≤i. Hence, under the ﬁltered transformation, the system (9.32) is then
transformed to
˙¯ζ = Ac ¯ζ + φ(y) + dξ1,
y = C ¯ζ.
(9.35)
Let us ﬁnd a bit more information of d. From the deﬁnition
¯dρ−2 = (Ac + λρ−1I)b
we have
n

i=ρ−1
¯dρ−2,isn−i = (s + λρ−1)
n

ρ
bisn−i.
Repeating the process iteratively, we can obtain
n

i=1
disn−i =
ρ−1

i=1
(s + λi)
n

ρ
bisn−i
(9.36)
which implies that d1 = bρ and that d is Hurwitz if b Hurwitz. In the special form
of Ac and C used here, b and d decide the zeros of the linear systems characterised
by (Ac, b, C) and (Ac, d, C) respectively as the solutions to the following polynomial
equations:

154
Nonlinear and adaptive control systems
n

ρ
bisn−i = 0,
n

i=1
disn−i = 0.
Hence, the invariant zeros of (Ac, d, C) are the invariant zeros of (Ac, b, C) plus λi for
i = 1, . . . , ρ −1. For the transformed system, ξ1 can be viewed as the new input. In
this case, the relative degree with ξ1 as the input is 1. The ﬁltered transformation lifts
the relative degree from ρ to 1.
As the ﬁltered transformation may have its use independent of backstepping
design shown here, we summarise the property of the ﬁltered transformation in the
following lemma.
Lemma 9.4. For a system in the form of (9.32) with relative degree ρ, the ﬁltered
transformation deﬁned in (9.34) transforms the system to (9.35) of relative degree 1,
with the same high frequency gain. Furthermore, the zeros of (9.35) consist of the
zeros of the original system (9.32) and λi for i = 1, . . . , ρ −1.
We introduce another state transform to extract the internal dynamics of (9.35)
with ζ ∈Rn−1 given by
ζ = ¯ζ2:n −d2:n
d1
y,
(9.37)
where ζ ∈Rn−1 forms the state variable of the transformed system together with y,
the notation (·)2:n refers to the vector or matrix formed by the 2nd row to the nth row.
With the coordinates (ζ, y), (9.35) is rewritten as
˙ζ = Dζ + ψ(y)
˙y = ζ1 + ψy(y) + bρξ1,
(9.38)
where D is the companion matrix of d given by
D =
⎡
⎢⎢⎢⎢⎢⎢⎣
−d2/d1
1
. . .
0
−d3/d1
0
...
0
...
...
...
...
−dn−1/d1
0
. . .
1
−dn/d1
0
. . .
0
⎤
⎥⎥⎥⎥⎥⎥⎦
,
and
ψ(y) = Dd2:n
d1
y + φ2:n(y) −d2:n
d1
φ1(y),
ψy(y) = d2
d1
y + φ1(y).

Backstepping design
155
If we view ξ1 as the input, the system (9.35) is of relative degree 1 with the stable
zero dynamics. For such a system, there exists an output feedback law to globally and
exponentially stabilise the system.
For this, we have the following lemma, stating in a more stand alone manner.
Lemma 9.5. For a nonlinear system (9.32), if the relative degree is 1, there exist
a continuous function ϕ : R →R with ϕ(0) = 0 and a positive real constant c such
that the control input in the form of
u = −cy −ϕ(y)
(9.39)
globally and asymptotically stabilises the system.
Proof. Introducing the same transformation as (9.37), i.e.,
ζ = x2:n −b2:n
b1
y,
we can obtain exactly the same transformed system as in (9.38) with d being replaced
by b and ξ1 by u. Since D is Hurwitz, there exists a positive deﬁnite matrix P such
that
DTP + PD = −3I.
(9.40)
We set
ϕ(y) = ψy(y) + ∥P∥2∥ψ(y)∥2
y
.
(9.41)
Note that ψ(0) = 0, and therefore ∥ψ(y)∥2/y is well deﬁned. The closed-loop system
is then obtained as
˙ζ = Dζ + ψ(y),
˙y = ζ1 −cy −∥P∥2∥ψ(y)∥2
y
.
Let
V = ζ TPζ + 1
2y2.
We have
˙V = −cy2 −3∥ζ∥2 + 2ζ TPψ(y) + yζ1 −∥P∥2∥ψ(y)∥2.
With the inequalities of the cross terms
|2ζ TPψ(y)| ≤∥ζ∥2 + ∥P∥2∥ψ(y)∥2,
|yζ1| ≤1
4y2 + ∥ζ∥2,
we have
˙V ≤−

c −1
4

y2 −∥ζ∥2.

156
Nonlinear and adaptive control systems
Therefore, the proposed control design with c > 1
4 and (9.41) exponentially stabilises
the system in the coordinate (ζ, y), which implies the exponential stability of the
closed-loop system in x coordinate, because the transformation from (ζ, y) to x is
linear.
2
From Lemma 9.5, we know the desired value of ξ1. But we cannot directly assign
a function to ξ1 as it is not the actual control input. Here backstepping can be applied
to design control input based on the desired function of ξ1. Together with the ﬁltered
transformation, the overall system is given by
˙ζ = Dζ + ψ(y)
˙y = ζ1 + ψy(y) + bρξ1
˙ξ1 = −λ1ξ1 + ξ2
(9.42)
. . .
˙ξρ−1 = −λρ−1ξρ−1 + u,
to which the backstepping design is then applied. Indeed, in the backstepping design,
ξi for i = 1, . . . , ρ −1 can be viewed as virtual controls.
Let
z1 = y,
zi = ξi−1 −αi−1,
for i = 2, . . . , ρ
zρ+1 = u −αρ,
where αi for i = 2, . . . , ρ are stabilising functions to be designed. We also use the
positive real design parameters ci and ki for i = 1, . . . , ρ and γ > 0.
Based on the result shown in Lemma 9.5, we have
α1 = −c1z1 −k1z1 + ψy(y) −γ ∥P∥2∥ψ(y)∥2
y
(9.43)
and
˙z1 = z2 −c1z1 −k1z1 −γ ∥P∥2∥ψ(y)∥2.
(9.44)
For the dynamics of z2, we have
˙z2 = −λ1ξ1 + ξ2 −∂α1
∂y ˙y
= z3 + α2 −λ1ξ1 −∂α1
∂y (ζ1 + ψ(y)).
The design of α2 is then given by
α2 = −z1 −c2z2 −k2
∂α1
∂y
2
z2 + ∂α1
∂y ψ(y) + λ1ξ1.
(9.45)

Backstepping design
157
The resultant dynamics of z2 is obtained as
˙z2 = −z1 −c2z2 −k2
∂α1
∂y
2
z2 + z3 −∂α1
∂y ζ1.
(9.46)
Note that α2 = α2(y, ξ1).
For the subsequent steps for i = 3, . . . , ρ, we have
˙zi = −λi−1ξi−1 + ξi −∂αi−1
∂y
˙y −
i−2

j=1
∂αi−1
∂ξj
˙ξj
= zi+1 + αi −λi−1ξi−1 −∂αi−1
∂y (ζ1 + ψ(y))
−
i−2

j=1
∂αi−1
∂ξj
(−λjξi−1 + ξj+1).
The design of αi is given by
αi = −zi−1 −cizi −ki
∂αi−1
∂y
2
zi + ∂αi−1
∂y ψ(y)
+
i−2

j=1
∂αi−1
∂ξj
(−λjξj + ξj+1) + λi−1ξi−1.
(9.47)
The resultant dynamics of zi is obtained as
˙zi = −zi−1 −cizi −ki
∂αi−1
∂y
2
zi + zi+1 −∂αi−1
∂y ζ1.
(9.48)
Note that αi = αi(y, ξ1, . . . , ξi−1).
When i = ρ, the control input appears in the dynamics of zi, through the term
zρ+1. We design the control input by setting zρ+1 = 0, which gives u = αρ, that is
u = −zρ−1 −cρzρ −kρ
∂αρ−1
∂y
2
zρ + ∂αρ−1
∂y
ψ(y)
+
i−2

j=1
∂αρ−1
∂ξj
(−λjξj + ξj+1) + λρ−1ξρ−1.
(9.49)
For the control design parameters, ci, i = 1, . . . , ρ and γ can be any positive, and for
di, the following condition must be satisﬁed:
ρ

1=1
1
4ki
≤γ.
The stability result of the above control design is given in the following
theorem.

158
Nonlinear and adaptive control systems
Theorem 9.6. For a system in the form of (9.32), the dynamic output feedback
control (9.49) obtained through backstepping with the input ﬁltered transformation
asymptotically stabilises the system.
Proof. Let
Vz =
ρ

i=1
z2
i .
From the dynamics for zi shown in (9.44), (9.46) and (9.48) we can obtain that
˙Vz =
ρ

i=1

−ciz2
i −ki
∂αi−1
∂y
2
z2
i −∂αi−1
∂y ziζ1

−γ ∥P∥2∥ψ(y)∥2,
where we deﬁne α0 = y for notational convenience. For the cross-term concerning
with ζ1, we have

∂αi−1
∂y ziζ1
 ≤ki
∂αi−1
∂y
2
z2
i + 1
4ki
ζ 2
1 .
Hence, we obtain that
˙Vz ≤
ρ

i=1

−ciz2
i + 1
4ki
ζ 2
1

−γ ∥P∥2∥ψ(y)∥2.
(9.50)
Let
Vζ = ζ TPζ
and we can obtain, similar to the proof of Lemma 9.5,
˙Vζ ≤−2∥ζ∥2 + ∥P∥2∥ψ(y)∥2.
Let
V = Vz + γ Vζ.
and we have
˙V ≤
ρ

i=1

−ciz2
i + 1
4ki
ζ 2
1

−2γ ∥ζ∥2
(9.51)
≤−
ρ

i=1
ciz2
i −γ ∥ζ∥2.
(9.52)
Therefore, we have shown that the system (9.42) is exponentially stable under the
coordinate (ζ, z1, . . . , zρ−1). With y = z1, we can conclude limt→∞¯ζ(t) = 0. From
y = z1, and α1(0) = 0, we can conclude that limt→∞ξ1(t) = 0. Following the same
process, we can show that limt→∞ξ(t) = 0 for i = 1, . . . , ρ −1. Finally from the
ﬁltered transformation (9.34), we can establish limt→∞x(t) = 0.
2

Backstepping design
159
9.5
Adaptive backstepping
We have shown backstepping design for two classes of systems with state feedback
and output feedback respectively. In this section, we will show the nonlinear adaptive
control design for a class of system of which there are unknown parameters.
Consider a ﬁrst-order nonlinear system described by
˙y = u + φT(y)θ
(9.53)
where φ : R →Rp is a smooth nonlinear function, and θ ∈Rp is an unknown vector
of constant parameters. For this system, adaptive control law can be designed as
u = −cy −φT(y) ˆθ
(9.54)
˙ˆθ = yφ(y)
(9.55)
where c is a positive real constant, and  ∈Rp×p is a positive deﬁnite gain matrix.
The closed-loop dynamics is given by
˙y = −cy + φT(y) ˜θ
with the usual notation ˜θ = θ −ˆθ.
For stability analysis, let
V = 1
2y2 + 1
2
˜θ T−1 ˜θ
and its derivative is obtained as
˙V = −cy2,
which ensures the boundedness of y and ˆθ. We can show limt→∞y(t) = 0 in the same
way by invoking Babalat’s Lemma as in the stability analysis of adaptive control
systems shown in Chapter 7.
Remark 9.3. The system considered above is nonlinear with unknown parameters.
However, the unknown parameters are linearly parameterised, i.e., the terms relating
to the unknown parameters, φT(y)θ are linear with the unknown parameters, instead of
some nonlinear functions φ(y, θ), which are referred to as nonlinearly parameterised.
Obviously, nonlinear parameterised unknown parameters are much more difﬁcult to
deal with in adaptive control. In this book, we only consider linearly parameterised
unknown parameters.
◁
For the ﬁrst-order system, the control input is matched with the uncertainty and
the nonlinear function. Backstepping can also be used with adaptive control to deal
with nonlinear and unknown parameters which are not in line with the input, or,
unmatched.

160
Nonlinear and adaptive control systems
Consider a nonlinear system
˙x1 = x2 + φ1(x1)Tθ
˙x1 = x3 + φ2(x1, x2)Tθ
. . .
(9.56)
˙xn−1 = xn + φn−1(x1, x1, . . . , xn−1)Tθ
˙xn = u + φn(x1, x2, . . . , xn)Tθ,
where xi ∈R for i = 1, . . . , n are state variables; θ ∈Rp is an unknown vector of
constant parameters; φi :
i

	

R × · · · × R →Rp for i = 1, . . . , n are differentiable
functions up to the order n −i with φi(0, . . . , 0) = 0; and u ∈R is the control input.
Note that this system is exactly the same as (9.6) if the parameter vector θ is
known.
The backstepping design method will be applied iteratively in a similar way to
the control design for (9.6), with only difference of including adaptive parameters in
the control design.
Let
z1 = x1,
zi = xi −αi−1(xi, . . . , xi−1, ˆθ),
for i = 2, . . . , n,
zn+1 = u −αn(xi, . . . , xn, ˆθ),
ϕ1 = φ1,
ϕi = φi −
i−1

j=1
∂αi−1
∂xj
φj,
for i = 2, . . . , n,
where αi−1, for i = 2, . . . , n, are stabilising functions obtained in the adaptive
beackstepping design, and ˆθ denotes an estimate of θ.
We start the adaptive backstepping from the dynamics of z1
˙z1 = z2 + α1 + ϕT
1 θ.
Design α1 as
α1 = −c1z1 −ϕT
1 ˆθ,
(9.57)
where ci, for i = 1, . . . , n, are set of positive design parameters. The closed-loop
dynamics are obtained as
˙z1 = −c1z1 + z2 + ϕT
1 ˜θ,
where ˜θ = θ −ˆθ.

Backstepping design
161
For the dynamics of z2, we have
˙z2 = ˙x2 −˙α1
= x3 + φT
2 θ −∂α1
∂x1
˙x1 −∂α1
∂ˆθ
˙ˆθ
= z3 + α2 + ϕT
2 θ −∂α1
∂x1
x2 −∂α1
∂ˆθ
˙ˆθ.
The dynamics of z2 involve the adaptive law ˙ˆθ. Even though the adaptive law has
not been designed, it is surely known to the control design, and can be used in the
control input. However, the dynamics of zi with i > 2 will also affect the design of the
adaptive law. For this reason, we would like to leave the design of the adaptive law to
the end. Inevitably, the adaptive law will include zi for i > 2. This causes a problem,
if we use α2 to cancel ˙ˆθ at this step, because z3 depends on α2. Instead, we only deal
with the part of the adaptive law that depends on z1 and z2 at this step, and we denote
that as τ2, which is a function of z1, z2 and ˆθ. In the subsequent steps, we use notations
τi = τi(z1, . . . , zi, ˆθ) for i = 3, . . . , n, which are often referred to as tuning functions.
Based on the above discussion, we design α2 as
α2 = −z1 −c2z2 −ϕT
2 ˆθ + ∂α1
∂x1
x2 + ∂α1
∂ˆθ
τ2.
(9.58)
The closed-loop dynamics are obtained as
˙z2 = −z1 −c2z2 + z3 + ϕT
2 ˜θ −∂α1
∂ˆθ
( ˙ˆθ −τ2).
Then the adaptive backstepping can be carried on for zi with 2 < i ≤n. The
dynamics of zi can be written as
˙zi = ˙xi −˙αi−1
= xi+1 + φT
i θ −
i−1

j=1
∂αi−1
∂xj
˙xj −∂αi−1
∂ˆθ
˙ˆθ
= zi+1 + αi + ϕT
i θ −
i−1

j=1
∂αi−1
∂xj
xj+1 −∂αi−1
∂ˆθ
˙ˆθ.
The stabilising function αi, for 2 < i ≤n, are designed as
αi = −zi−1 −cizi −ϕT
i ˆθ +
i−1

j=1
∂αi−1
∂xj
xj+1 + ∂αi−1
∂ˆθ
τi + βi,
(9.59)
where βi = βi(z1, . . . , zi, ˆθ), for i = 3, . . . , n, are functions to be designed later to
tackle the terms ( ˙ˆθ −τi) in stability analysis. The closed-loop dynamics are obtained
as, for 2 < i ≤n,
˙zi = −zi−1 −cizi + zi+1 + ϕT
i ˜θ −∂αi−1
∂ˆθ
( ˙ˆθ −τi) + βi.

162
Nonlinear and adaptive control systems
The control input u appears in the dynamics zn, in the term zn+1. When i = n,
we have τi = ˙ˆθ by deﬁnition. We obtain the control input by setting zn+1 = 0, which
gives
u = αn
= −zn−1 −cnzn −ϕT
n ˆθ
+
n−1

j=1
∂αn−1
∂xj
xj+1 + ∂αn−1
∂ˆθ
˙ˆθ + βn.
(9.60)
We need to design the adaptive law, tuning functions and βi to complete the
control design. We will do it based on Lyapunov analysis. For notational convenience,
we set β1 = β2 = 0.
Let
V = 1
2
n

i=1
z2
i + 1
2
˜θ T−1 ˜θ,
(9.61)
where  ∈Rp×p is a positive deﬁnite matrix. From the closed-loop dynamics of zi,
for i = 1, . . . , n, we obtain
˙V =
n

i=1
(−ciz2
i + ziϕT
i ˜θ + ziβi) −
n

i=2
zi
∂αi−1
∂ˆθ
( ˙ˆθ −τi) + ˙˜θ T−1 ˜θ
= −
n

i=1
ciz2
i +
n

i=2

ziβi −zi
∂αi−1
∂ˆθ
( ˙ˆθ −τi)

+

n

i=1
ziϕi −−1 ˙ˆθ
T
˜θ.
We set the adaptive law as
˙ˆθ = 
n

i=1
ziϕi.
(9.62)
We can conclude the design by setting the tuning functions to satisfy
n

i=2

ziβi −zi
∂αi−1
∂ˆθ
( ˙ˆθ −τi)

= 0.
Substituting the adaptive law in the above equation, and with some manipulation of
index, we obtain that
0 =
n

i=2
⎛
⎝ziβi −zi
∂αi−1
∂ˆθ
⎛
⎝
n

j=1
zjϕj −τi
⎞
⎠
⎞
⎠
=
n

i=2
ziβi −
n

i=2
n

j=2
zizj
∂αi−1
∂ˆθ
ϕj +
n

i=2
zi
∂αi−1
∂ˆθ
(τi −z1ϕ1)

Backstepping design
163
=
n

i=2
ziβi −
n

i=2
n

j=i+1
zizj
∂αi−1
∂ˆθ
ϕj
−
n

i=2
i
j=2
zizj
∂αi−1
∂ˆθ
ϕj +
n

i=2
zi
∂αi−1
∂ˆθ
(τi −z1ϕ1)
=
n

i=2
ziβi −
n

j=3
j−1

i=2
zizj
∂αi−1
∂ˆθ
ϕj
+
n

i=2
zi
∂αi−1
∂ˆθ
⎛
⎝τi −z1ϕ1 −
i
j=2
zjϕj
⎞
⎠
=
n

i=3
zi
⎛
⎝βi −
i−1

j=2
zj
∂αj−1
∂ˆθ
ϕi
⎞
⎠
+
n

i=2
zi
∂αi−1
∂ˆθ
⎛
⎝τi −z1ϕ1 −
i
j=2
zjϕj
⎞
⎠.
Hence, we obtain
βi =
i−1

j=2
zj
∂αj−1
∂ˆθ
ϕi,
for i = 3, . . . , n,
(9.63)
τi =
i
j=1
zjϕj,
for i = 2, . . . , n.
(9.64)
With the complete design of u and ˙ˆθ, we ﬁnally obtain that
˙V = −
n

i=1
ciz2
i .
from which we can deduce that zi ∈L2 ∩L∞, i = 1, . . . , n, and ˆθ is bounded. Since
all the variables are bounded, we have ˙zi bounded. From Barbalat’s Lemma, we have
limt→∞zi(t) = 0, i = 1, . . . , n. Noticing that x1 = z1 and φ1(0) = 0, we can conclude
that α1 converges to zero, which further implies that limt→∞x2(t) = 0. Repeating the
same process, we can show that limt→∞xi(t) = 0 for i = 1, . . . , n.
Theorem 9.7. For a system in the form of (9.57), the control input (9.60) and adaptive
law (9.62) designed by adaptive backstepping ensure the boundedness of all the
variables and limt→∞xi(t) = 0 for i = 1, . . . , n.

164
Nonlinear and adaptive control systems
Example 9.2. Consider a second-order system
˙x1 = x2 + (ex1 −1)θ
˙x2 = u,
where θ ∈R is the only unknown parameter. We will follow the presented design
procedure to design an adaptive control input to stabilise the system.
Let z1 = x1 and z2 = x2 −α1. We design the stabilising function α1 as
α1 = −c1z1 −(ex1 −1) ˆθ.
The resultant dynamics of z1 are given by
˙z1 = −c1z1 + z2 + (ex1 −1) ˜θ.
The dynamics of z2 are obtained as
˙z2 = u −∂α1
∂x1
(x2 + (ex1 −1)θ) −∂α1
∂ˆθ
˙ˆθ,
where
∂α1
∂x1
= −c1 −ex1 ˆθ,
∂α1
∂ˆθ
= −(ex1 −1).
Therefore, we design the control input u as
u = −z1 −c2z2 + ∂α1
∂x1
(x2 + (ex1 −1) ˆθ) + ∂α1
∂ˆθ
˙ˆθ.
Note that the control input u contains ˙ˆθ, which is to be designed later, as a function
of the state variables and ˆθ. The resultant dynamics of z2 are obtained as
˙z2 = −z1 −c2z2 −∂α1
∂x1
(ex1 −1) ˜θ.
Let
V = 1
2

z2
1 + z2
2 +
˜θ 2
γ

.
We obtain that
˙V = −c1z2
1 −c2z2
2 +

z1(ex1 −1) −z2
∂α1
∂x1
(ex1 −1)

˜θ −1
γ
˜θ ˙ˆθ.
Therefore, an obvious choice of the adaptive law is
˙ˆθ = γ z1(ex1 −1) −γ z2
∂α1
∂x1
(ex1 −1)
which gives
˙V = −c1z2
1 −c2z2
2.
The rest part of the stability analysis follows Theorem 9.7.
◁

Backstepping design
165
Example 9.3. In Example 9.2, the nonlinear system is in the standard format as
shown in (9.56). In this example, we show adaptive control design for a system which
is slightly different from the standard form (9.56), but the same design procedure can
be applied with some modiﬁcations.
Consider a second-order nonlinear system
˙x1 = x2 + x3
1θ + x2
1
˙x2 = (1 + x2
1)u + x2
1θ,
where θ ∈R is the only unknown parameter.
Let z1 = x1 and z2 = x2 −α1. The stabilising function α1 is designed as
α1 = −c1z1 −x3
1 ˆθ −x2
1,
which results in the dynamics of z1 as
˙z1 = −c1z1 + z2 + x3
1 ˜θ.
The dynamics of z2 are obtained as
˙z2 = (1 + x2
1)u + x2
1θ −∂α1
∂x1
(x2 + x3
1θ + x2
1) −∂α1
∂ˆθ
˙ˆθ,
where
∂α1
∂x1
= −c1 −3x2
1 ˆθ −2x1, ∂α1
∂ˆθ
= −x3
1.
Therefore, we design the control input u as
u =
1
1 + x2
1

−z1 −c2z2 −x2
1 ˆθ + ∂α1
∂x1
(x2 + x3
1 ˆθ + x2
1) + ∂α1
∂ˆθ
˙ˆθ

.
The resultant dynamics of z2 are obtained as
˙z2 = −z1 −c2z2 + x2
1 ˜θ −∂α1
∂x1
x3
1 ˜θ.
Let
V = 1
2

z2
1 + z2
2 +
˜θ 2
γ

.
We obtain that
˙V = −c1z2
1 −c2z2
2 +

z1x1
3 + z2

x2
1 −∂α1
∂x1
x3
1

˜θ −1
γ
˜θ ˙ˆθ.
We can set the adaptive law as
˙ˆθ = γ z1x1
3 + γ z2

x2
1 −∂α1
∂x1
x3
1

to obtain
˙V = −c1z2
1 −c2z2
2.

166
Nonlinear and adaptive control systems
0
2
4
6
8
10
−6
−5
−4
−3
−2
−1
0
1
2
t (s)
State variables
x1
x2
Figure 9.1
State variables
0
2
4
6
8
10
0
0.5
1
1.5
2
2.5
3
3.5
4
t (s)
Estimated parameter
Figure 9.2
Estimated parameter ˆθ

Backstepping design
167
The rest part of the stability analysis follows Theorem 9.7. Simulation results are
shown in Figures 9.1 and 9.2 with x(0) = [1, 1]T, c1 = c2 = γ = θ = 1. The state
variables converge to zero as expected, and the estimated parameter converges to
a constant, but not to the correct value θ = 1. In general, estimated parameters in
adaptive control are not guaranteed to converge to their actual values.
◁
9.6
Adaptive observer backstepping
Backstepping can also be used to design control input for a class of nonlinear systems
with unknown parameters using output feedback. We consider a system which can be
transformed to the output feedback form with unknown parameters
˙x = Acx + bσ(y)u + φ0(y) +
p

i=1
φi(y)ai
:= Acx + bσ(y)u + φ0(y) + (y)a
(9.65)
y = Cx
with
Ac =
⎡
⎢⎢⎢⎢⎢⎣
0
1
0
. . .
0
0
0
1
. . .
0
...
...
...
...
...
0
0
0
. . .
1
0
0
0
. . .
0
⎤
⎥⎥⎥⎥⎥⎦
,
C =
⎡
⎢⎢⎢⎣
1
0
...
0
⎤
⎥⎥⎥⎦
T
,
a =
⎡
⎢⎢⎢⎣
a1
a2
...
ap
⎤
⎥⎥⎥⎦,
b =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
...
0
bρ
...
bn
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
:=
 0(ρ−1)×1
¯b

,
where x ∈Rn is the state vector, u ∈R is the control and b ∈Rn is an unknown
constant Hurwitz vector with bρ ̸= 0, which implies that the relative degree of the
system is ρ, a denotes unknown system parameters, φi : R →Rn for 0 ≤i ≤p
are nonlinear functions with their elements being differentiable up to the ρth order,
σ : R →R is a continuous function and σ(y) ̸= 0, ∀y ∈R.
For the system (9.65), we assume that only the system output is available for
control design. Both observer backstepping and backstepping with ﬁltered transfor-
mation design methods presented earlier can be applied for the control design of
(9.65) if there are no unknown parameters. Even with the unknown parameters, the
same ﬁltered transformation introduced earlier in (9.34) can still be applied to the
system (9.65), and adaptive backstepping can then be applied to design the control
input. Here we take an approach similar to observer backstepping. Because there

168
Nonlinear and adaptive control systems
are unknown parameters, we will not be able to design an observer in the same way
as in the observer backstepping. Instead, we can design ﬁlters similar to observers,
and obtain an expression of state estimation which contains unknown parameters. The
unknown parameters in the state estimation are then tackled by adaptive backstepping.
For the state estimation, we re-arrange the system as
˙x = Acx + φ0(y) + FT(y, u)θ,
(9.66)
where the vector θ ∈Rq, with q = n −ρ + 1 + p, is deﬁned by
θ =
 ¯b
a

and
F(y, u)T =
 0(ρ−1)×(n−ρ+1)
In−ρ+1

σ(y)u, (y)

.
Similar to observer design, we design the following ﬁlters:
˙ξ = A0ξ + Ly + φ0(y),
(9.67)
˙T = A0T + F(y, u)T,
(9.68)
where ξ ∈Rn, T ∈Rn×q and
L = [l1, . . . , ln]T,
A0 = Ac −LC
with L being chosen so that A0 is Hurwitz. An estimate of the state is then given by
ˆx = ξ + Tθ.
(9.69)
Let
ϵ = x −ˆx
and from direct evaluation, we have
˙ϵ = A0ϵ.
(9.70)
Therefore, the state estimate shown in (9.69) is an exponentially convergent one.
Notice that this estimate contains unknown parameter vector θ, and therefore ˆx cannot
be directly used in control design. The relationship between an convergent estimate
ˆx and the unknown parameter vector can be used in adaptive backstepping control
design.
We can reduce the order of the ﬁlters. Let us partition T as T = [v, ] with
v ∈Rn×(n−ρ+1) and  ∈Rn×p. We then obtain, from (9.68), that
˙ = A0 + (y),
vj = A0vj + ejσ(y)u,
for j = ρ, . . . , n,
where ej denotes jth column of identity matrix I in Rn. For 1 < j < n, we have
A0ej = (Ac −LC)ej = Acej = ej+1.

Backstepping design
169
This implies that
vj = An−j
0 vn.
Finally, we summarise the ﬁlters for T as
T = [vρ, . . . , vn, ],
˙ = A0 + (y),
˙λ = A0λ + enσ(y)u,
vj = An−j
0 λ,
for j = ρ, . . . , n.
(9.71)
With the ﬁlters being designed, control design can be carried out using adaptive
backstepping in a similar way as the observer backstepping, by combining the design
of tuning functions in parameter adaptation. During the control design, the state
variable x will be replaced by
x = ξ + Tθ + ϵ,
and in particular, whenever we encounter x2, we will replace it by
x2 = ξ2 + T
(2)θ + ϵ2,
where the subscript (i) denotes the ith row of a matrix. In the following control design,
we will consider the tracking control instead of stabilisation. The output y is designed
to track a trajectory yr with its derivatives available for the control design.
Let us deﬁne a number of notations:
z1 = y −yr,
zi = vρ,i −ˆϱy(i−1)
r
−αi−1,
i = 2, . . . , ρ,
zρ+1 = σ(y)u + vρ,ρ+1 −ˆϱy(ρ)
r
−αρ,
ϕ0 = ξ2 + φ0,1,
ϕ = [vρ,2, . . . , vn,2, (1) + (2)]T,
¯ϕ = [0, vρ+1,2, . . . , vn,2, (1) + (2)]T,
¯λi = [λ1, . . . , λi]T,
¯yi = [yr, ˙yr, . . . , y(i)
r ]T,
Xi = [ξ T, vec()T, ˆϱ, ¯λT
i , ¯yT
i ]T,
σj,i = ∂αj−1
∂ˆθ
 ∂αi−1
∂y ϕ,
where ˆϱ, an estimate of ϱ = 1/bρ, and αi, i = 1, . . . , ρ, are the stabilising functions
to be designed.
Consider the dynamics of z1
˙z1 = x2 + φ0,1(y) + (1)θ −˙yr
= ξ2 + T
(2)θ + ϵ2 + φ0,1(y) + (1)θ −˙yr
= bρvρ,2 + ϕ0 + ¯ϕTθ + ϵ2 −˙yr.
(9.72)

170
Nonlinear and adaptive control systems
Note that bρ is unknown. To deal with unknown control coefﬁcient, we often estimate
its reciprocal, instead of itself, to avoid using the reciprocal of an estimate. This is the
reason why we deﬁne
z2 = vρ,2 −α1 −ˆϱ˙yr
:= vρ,2 −ˆϱ ¯α1 −ˆϱ˙yr.
From bρϱ = 1, we have
bρ ˆϱ = 1 −bρ ˜ϱ,
where ˜ϱ = ϱ −ˆϱ. Then from (9.72), we have
˙z1 = bρ(z2 + ˆϱ ¯α1 + ˆϱ˙yr) + ϕ0 + ¯ϕTθ + ϵ2 −˙yr
= bρz2 −bρ ˜ϱ(¯α1 + ˙yr) + ¯α1 + ϕ0 + ¯ϕTθ + ϵ2.
(9.73)
Hence, we design
¯α1 = −c1z1 −k1z1 −ϕ0 −¯ϕT ˆθ,
(9.74)
where ci and ki for i = 1, . . . , ρ are positive real design parameters. Note that with
α = ˆϱ ¯α1, we have α1 = α1(y, X1, ˆθ).
The resultant closed-loop dynamics are obtained as
˙z1 = −c1z1 −k1z1 + bρz2 −bρ ˜ϱ(¯α1 + ˙yr) + ¯ϕT ˜θ + ϵ2
= −c1z1 −k1z1 + ˆbρz2 + ˜bρz2 −bρ ˜ϱ(¯α1 + ˙yr) + ¯ϕT ˜θ + ϵ2
= −c1z1 −k1z1 + ˆbρz2 −bρ ˜ϱ(¯α1 + ˙yr)
+ (ϕ −ˆϱ(¯α1 + ˙yr)e1)T ˜θ + ϵ2,
(9.75)
where ˜θ = θ −ˆθ. Note that bρ = θTe1.
As shown in the observer backstepping, the term −k1z1 is used to tackle the
error term ϵ2. In the subsequent steps, the terms headed by ki are used to deal with
the terms caused by ϵ2 in stability analysis. Indeed, the method of tackling observer
errors is exactly the same as in the observer backstepping when all the parameters are
known. The adaptive law for ˆϱ can be designed in this step, as it will not appear in
the subsequent steps,
˙ˆϱ = −γ sgn(bρ)(¯α1 + ˙yr))z1,
(9.76)
where γ is a positive real constant.
Similar to adaptive backstepping shown in the previous section, the unknown
parameter vector θ will appear in the subsequent steps, and tuning functions can be
introduced in a similar way. We deﬁne the tuning functions τi as
τ1 = (ϕ −ˆϱ(˙yr + ¯α1)e1)z1,
τi = τi−1 − ∂αi−1
∂y ϕzi,
i = 2, . . . , ρ,
(9.77)
where αi are the stabilising functions to be designed, and  ∈Rq×q is a positive
deﬁnite matrix, as the adaptive gain.

Backstepping design
171
For the dynamics of z2, we have
˙z2 = ˙vρ,2 −˙α1 −˙ˆϱ˙yr −ˆϱ¨yr
= vρ,3 −l2vρ,1 −∂α1
∂X1
˙X1 −∂α1
∂y ˙y −∂α1
∂ˆθ
˙ˆθ −˙ˆϱ˙yr −ˆϱ¨yr.
With
˙y = ϕ0 + ϕTθ + ϵ2,
z3 = vρ,3 −α2 −ˆϱ¨yr,
we obtain that
˙z2 = z3 + α2 −l2vρ,1 −∂α1
∂X1
˙X1 −∂α1
∂y (ϕ0 + ϕTθ + ϵ2) −∂α1
∂ˆθ
˙ˆθ −˙ˆϱ˙yr,
from which the stabilising function α2 is deﬁned as
α2 = −ˆbρz1 −c2z2 −k2
∂α1
∂y
2
z2 + l2vρ,1 + ˙ˆϱ˙yr
+∂α1
∂X1
˙X1 + ∂α1
∂y (ϕ0 + ϕT ˆθ) + ∂α1
∂ˆθ
τ2.
(9.78)
The resultant dynamics of z2 are obtained as
˙z2 = −ˆbρz1 −c2z2 −k2
∂α1
∂y
2
z2 + z3
−∂α1
∂y ϕT ˜θ −∂α1
∂y ϵ2 −∂α1
∂θ ( ˙ˆθ −τ2).
(9.79)
For the dynamics of zi, 2 < i ≤ρ, we have
˙zi = zi+1 + αi −livρ,1 −∂αi−1
∂Xi−1
˙Xi−1 −∂αi−1
∂y (ϕ0 + ϕTθ + ϵ2)
−∂αi−1
∂ˆθ
˙ˆθ −˙ˆϱy(i−1)
r
.
We design αi, 2 < i ≤ρ, as
αi = −zi−1 −cizi −ki
∂αi−1
∂y
2
zi + livρ,1
+ ˙ˆϱy(i−1)
r
+ ∂αi−1
∂Xi−1
˙Xi−1 + ∂αi−1
∂y (ϕ0 + ϕT ˆθ)
+ ∂αi−1
∂ˆθ
τi −
i−1

j=2
σj,izj,
i = 3, . . . , ρ,
(9.80)
where the last term −i−1
j=2 σj,izj is similar to the term βi in the adaptive backstepping
with tuning functions. The resultant dynamics of zi are obtained as

172
Nonlinear and adaptive control systems
˙zi = −zi−1 −cizi −ki
∂αi−1
∂y
2
zi + zi+1
−∂αi−1
∂y ϕT ˜θ −∂αi−1
∂y ϵ2 −
i−1

j=2
σj,izj
−∂αi−1
∂ˆθ
( ˙ˆθ −τi)
i = 3, . . . , ρ.
(9.81)
Now we design the adaptive law for ˆθ as
˙ˆθ = τρ.
(9.82)
The control input is obtained by setting zρ+1 = 0 as
u =
1
σ(y)(αρ −vρ,ρ+1 + ˆϱy(ρ)
r ).
(9.83)
For the adaptive observer backstepping, we have the following stability result.
Theorem 9.8. For a system in the form of (9.65), the control input (9.83) and adap-
tive laws (9.76) and (9.82) designed by adaptive observer backstepping ensure the
boundedness of all the variables and limt→∞(y(t) −yr(t)) = 0.
Proof. With the control design and adaptive laws presented earlier for the case ρ > 1,
the dynamics of zi, for i = 1, . . . , ρ can be written as
˙z1 = −c1z1 −k1z1 + ϵ2 + (ϕ −ˆϱ(˙yr + ¯α1)e1)T ˜θ
−bρ(˙yr + ¯α1)˜ϱ + ˆbρz2,
(9.84)
˙z2 = −ˆbρz1 −c2z2 −k2
∂α1
∂y
2
z2 + z3
−∂α1
∂y ϕT ˜θ −∂α1
∂y ϵ2 +
ρ

j=3
σ2,jzj,
(9.85)
˙zi = −zi−1 −cizi −ki
∂αi−1
∂y
2
zi + zi+1
−∂αi−1
∂y ϕT ˜θ −∂αi−1
∂y ϵ2 +
ρ

j=i+1
σi,jzj
−
i−1

j=2
σj,izj
i = 3, . . . , ρ.
(9.86)

Backstepping design
173
Let
Vρ = 1
2
ρ

i=1
z2
i + 1
2
˜θ T−1 ˜θ + |bρ|
2γ ˜ϱ2 +
ρ

i=1
1
4ki
ϵTPϵ,
(9.87)
where P is a positive deﬁnite matrix that satisﬁes
AT
0 P + PA0 = −I.
From (9.84)–(9.86), (9.82) and (9.76), it can be shown that
˙Vρ = −
ρ

i=1

ci + ki
∂αi−1
∂y
2
z2
i −
ρ

i=1
zi
∂αi−1
∂y ϵ2 −
ρ

i=1
1
4ki
∥ϵ∥2,
(9.88)
where we set ∂α0
∂y = −1. Noting
zi
∂αi−1
∂y ϵ2
 ≤1
4ki
∥ϵ2∥2 + ki
∂αi−1
∂y
2
z2
i ,
(9.89)
we have
˙Vρ ≤−
ρ

i=1
ciz2
i .
(9.90)
This implies that zi, i = 1, . . . , ρ, ˜θ, ˜ϱ and ϵ are bounded. The boundedness of ˜θ
further implies that ˆθ is bounded. The boundedness of ˆϱ follows from the fact that
ϱ = 1/bρ is a constant. Since y = z1 + yr, the boundedness of ξ and  follows the
boundedness of y. The boundedness of λ can be established from the minimum phase
property of the system. Therefore, u is bounded and we can conclude that all the
variables of the feedback control system are bounded. From the above analysis, we
can deduce that zi ∈L2 ∩L∞, i = 1, . . . , ρ and ˆθ are bounded. Since all the variables
are bounded, we have ˙zi bounded. From Barbalat’s Lemma, we have limt→∞zi(t) =
0, i = 1, . . . , ρ, of which the result for z1 means the asymptotic output tracking,
limt→∞(y(t) −yr(t)) = 0.
2


Chapter 10
Disturbance rejection and output regulation
Disturbances are often inevitable in control system design. A well-performed con-
troller is expected to suppress undesirable effects of the disturbances in the system.
There are various types of disturbances in physical systems, from random distur-
bances, wide-band, narrow-band disturbances, in terms of disturbance power spectra,
to deterministic disturbances that include harmonic disturbances, i.e., sinusoidal func-
tions, general periodic disturbances and other deterministic signals generated from
nonlinear dynamic systems such as limit cycles. The spectral information of random
disturbances may be considered in loop-shaping and other conventional design meth-
ods. In this chapter, we concentrate on suppression and rejection of deterministic
periodic disturbances. One control design objective is to track a speciﬁc signal. If we
take the tracking error as the state variable, the tracking problem could be converted
to a stabilisation problem. Indeed, we can formulate both the disturbance rejection
and output tracing problems in terms of output regulation. This will be discussed later
in this chapter.
Disturbance rejection and output regulation are big topics in control systems,
design. We have to be selective to limit the contents in one chapter. In this chapter, we
will concentrate on rejection of deterministic disturbances in a class of nonlinear out-
put feedback systems. As for disturbances, we will start from sinusoidal disturbances
with unknown frequencies, then disturbances generated from nonlinear exosystems
and then general periodical disturbances, etc. Adaptive control techniques are used
to deal with the unknown disturbance frequencies and unknown parameters in the
system. The presented design concepts can be applied to other classes of nonlinear
systems.
10.1
Asymptotic rejection of sinusoidal disturbances
In this section, we consider asymptotic rejection of sinusoidal disturbances with
unknown frequencies for dynamic systems in the output feedback form.
We consider a SISO nonlinear system which can be transformed into the output
feedback form
˙ζ = Acζ + bu + φ(y) + Ew
y = Cζ,
(10.1)

176
Nonlinear and adaptive control systems
with
Ac =
⎡
⎢⎢⎢⎢⎢⎣
0
1
0
. . .
0
0
0
1
. . .
0
...
...
...
...
...
0
0
0
. . .
1
0
0
0
. . .
0
⎤
⎥⎥⎥⎥⎥⎦
,
C =
⎡
⎢⎢⎢⎣
1
0
...
0
⎤
⎥⎥⎥⎦
T
,
b =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
...
0
bρ
...
bn
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
,
where ζ ∈Rn is the state vector; u ∈R is the control; φ : R →Rn with φ(0) = 0 is
a nonlinear function with element φi being differentiable up to the (n −i)th order;
b ∈Rn is a known constant Hurwitz vector with bρ ̸= 0, which implies the relative
degree of the system is ρ; E ∈Rn×m is a constant matrix; and w ∈Rm are disturbances,
and they are generated from an unknown exosystem
˙w = Sw
of which, S is a constant matrix with distinct eigenvalues of zero real parts.
Remark 10.1. For the system (10.1), if the disturbance w = 0, it is exactly same
as (9.17), of which observer backstepping can be used to design a control input.
Due to the unknown disturbance, although the observer backstepping presented in
Chapter 9 cannot be applied directly for control design, a similar technique can be
developed using an observer and an adaptive internal model. Also note that the
linear system characterised by (Ac, b, C) is minimum phase.
◁
Remark 10.2. The dynamic model ˙w = Sw is referred to as an exosystem, because
w is a disturbance, not a part of the system state. This is a convention adopted for
disturbance rejection and output regulation. Of course, one could argue that w could
be considered as a part of the system state, or at least, of an augmented system. In
such a case, w is not controllable.
◁
Remark 10.3. With the assumption that S has distinct eigenvalues with zero real
parts, w is restrict to sinusoidal signals (sinusoidal disturbances) with a possible
constant bias. This is a common assumption for disturbance rejection. Roughly
speaking, all the periodic signal can be approximated by ﬁnite number of sinusoidal
functions.
◁
The disturbance rejection problem to be solved here is to design a control input
that ensures the boundedness of the variables in the closed-loop system, and the
convergence to zero of the system output.
To solve the problem, we start from state transformation, based on an invariant
manifold. The basic idea for disturbance suppression or output regulation is the inter-
nal model principle. A controller for disturbance rejection or output regulation should
generate a feedforward input term to cancel the inﬂuence caused by the disturbance or
to track a desired trajectory. This feedforward term is also referred to as the equivalent

Disturbance rejection and output regulation
177
input disturbance. For nonlinear systems, asymptotic disturbance rejection depends
on the existence of an invariant manifold. We shall show that there exists an invariant
manifold for any exosystem speciﬁed in (10.1). This invariant manifold is then used
in the state transformation. The following lemma summarises the results.
Lemma 10.1. For the system (10.1) with an exosystem whose eigenvalues are distinct
and with zero real parts, there exist π(w) ∈Rn with π1(w) = 0 and α(w) ∈R such
that
∂π(w)
∂w
Sw = Acπ(w) + Ew + bα(w).
(10.2)
Proof. Asymptotic disturbance rejection aims at y = 0, which implies that π1 = 0.
The manifold π is invariant and it should satisfy the system equation (10.1) with
y ≡0. From the ﬁrst equation of (10.1), we have
π2 = −E1w
(10.3)
where E1 denotes the ﬁrst row of E. Furthermore, we have, for 2 ≤i ≤ρ,
πi = d
dt πi−1 −Ei−1w.
(10.4)
From equations ρ to n of (10.1), we obtain
n

i=ρ
dn−i
dtn−i biα(w) = dn−ρ+1
dtn−ρ+1 πρ −
n

i=ρ
dn−i
dtn−i Eiw.
(10.5)
A solution of α(w) can always be found from (10.5). With α(w), we can write, for
ρ < i ≤n,
πi = d
dt πi−1 −Ei−1w −bi−1α(w).
(10.6)
2
With the invariant manifold π(w), we deﬁne a transformation of state as
x = ζ −π(w).
(10.7)
It can be easily shown from (10.1) and (10.2) that
˙x = Acx + b(u −α) + φ(y)
y = Cx.
(10.8)
The stabilisation and disturbance suppression problem of (10.1) degenerates to the
stabilisation problem of (10.8).
For dynamic output feedback control, state variables need to be estimated for
the control design directly or indirectly. The difﬁculty for designing a state estimator
for (10.8) is that α(w), the feedforward control input for disturbance suppression, is
unknown. Let us consider the observers
˙p = (Ac −LC)p + φ(y) + bu + Ly
(10.9)
˙q = (Ac −LC)q + bα(w),
(10.10)

178
Nonlinear and adaptive control systems
where L ∈Rn is chosen so that Ac −LC is Hurwitz, and q denotes the steady-state
contribution of α(w) to the state variable. Notice that the observer (10.10) cannot be
implemented because α(w) is unknown, due to the unknown exosystem. Nevertheless,
if we deﬁne
ˆx = p −q
(10.11)
then the error of the observer deﬁned by ϵ = x −ˆx is an exponentially decaying signal
with the dynamics
˙ϵ = (Ac −LC)ϵ,
(10.12)
which can be obtained by a direct evaluation from (10.8) to (10.10).
Observe from (10.5) that α(w) is a linear combination of w. Since the ﬁlter
(10.10) is just a stable linear system, the steady-state solution of state variables is
linear combinations of w as well. Therefore, there exists an l ∈Rm for q2, and we can
write
˙w = Sw
q2 = lTw.
(10.13)
Were-parameterise(10.13)forstateestimationherefor q2. Foranyknowncontrollable
pair (F, G) with F ∈Rm×m being Hurwitz and G ∈Rm, there exists a ψ ∈Rm so that
˙η = (F + GψT)η
q2 = ψTη,
(10.14)
with the initial value η(0) dependent on exogenerous variables.
Remark10.4. Theimportanceof(10.14)comparedwith(10.13)isthere-formulation
of the uncertainty caused by the unknown exosystem. The uncertainty in (10.13)
parameterised by unknown S and l is represented by a single vector ψ in (10.14). The
relation between the two parameterisations is discussed here. Suppose that M ∈Rm×m
is the unique solution of
MS −FM = GlT.
(10.15)
The existence of a non-singular M is ensured by the fact that S and F have exclu-
sively different eigenvalues, and (S, l) and (F, G) are observable and controllable
respectively. From (10.15), we have
MSM −1 = F + GlTM −1,
(10.16)
which implies η = Mw and ψT = lTM −1
To achieve asymptotic rejection with global stability using output feedback, an
asymptotic state estimator, probably depending on unknown parameters, is instru-
mental. In the control design shown later for the problem considered, the estimate of
state variable x2 is crucial, and therefore we introduce the internal model (10.14) to
describe the inﬂuence of disturbance w on this state.
◁
The following lemma summarises the results on state observation.

Disturbance rejection and output regulation
179
Lemma 10.2. The state variable x can be expressed as
x = p −q + ϵ,
(10.17)
where p is generated from (10.9) with q and ϵ satisfying (10.10) and (10.12)
respectively. In particular,
x2 = p2 −ψTη + ϵ2,
(10.18)
where η satisﬁes (10.14).
Remark 10.5. The expression (10.18) cannot be directly implemented, because ψ
and η are not available. The relation shown in (10.18) is very useful in the control
design, and it allows adaptive control technique to be introduced to deal with the
unknown parameter ψ later.
◁
Based on the parameterisation (10.14) of the internal model, we design an
estimator of η as
˙ξ = (F + G ˆψT)ξ + ι(y)
ˆq2 = ˆψTξ,
(10.19)
where ι(y) is an interlace function to be designed later.
With the state estimation introduced in previous chapter, in particular, the ﬁlter
(10.9), the relation (10.18) and estimator (10.19), the control design can be carried out
using adaptive observer backstepping technique described in previous chapter. In the
backstepping design, ci, for i = 1, . . . , ρ, denote constant design parameters which
can be set in the design, while ki, for i = 1, . . . , ρ, denote the unknown parameters
depending on an upper bound of ∥ψ∥. The estimates, ˆki, for i = 1, . . . , ρ, are then
used. To apply the observer backstepping through p in (10.9), we deﬁne
z1 = y,
(10.20)
zi = pi −αi−1,
i = 2, . . . , ρ,
(10.21)
zρ+1 = bρu + pρ+1 −αρ,
(10.22)
where αi, for i = 1, . . . , ρ, are stabilising functions decided in the control design.
Consider the dynamics of z1
˙z1 = x2 + φ1(y).
(10.23)
We use (10.18) to replace the unmeasurable x2 in (10.23), resulting at
˙z1 = p2 −ψTη + ϵ2 + φ1(y)
= z2 + α1 −ψTη + ϵ2 + φ1(y).
(10.24)
We design α1 as
α1 = −c1z1 −ˆk1z1 −φ1(y) + ˆψTξ.
(10.25)

180
Nonlinear and adaptive control systems
Then from (10.25) and (10.24), we have
˙z1 = z2 −c1z1 −ˆk1z1 + ϵ2 + ( ˆψTξ −ψTη).
(10.26)
After the design of α1, the remaining stabilising functions can be designed in a similar
way to the standard adaptive backstepping with tuning functions shown in the previous
chapter. Omitting the deriving procedures, we brieﬂy describe the ﬁnal results
αi = −zi−1 −cizi −ˆki
	∂αi−1
∂y

2
zi −li(y −p1) −φi(y)
+∂αi−1
∂y (p2 −ˆψTξ + φ1) +
i−1

j=1
∂αi−1
∂pj
˙pj +
i−1

j=1
∂αi−1
∂ˆkj
˙ˆkj + ∂αi−1
∂ξ
˙ξ
+∂αi−1
∂ˆψ
τi +
i−1

j=2
∂αj−1
∂ˆψ
 ∂αi−1
∂y ξzj,
i = 2, . . . , ρ,
(10.27)
where li are the ith element of the observer gain L in (10.9),  is a positive deﬁnite
matrix, τi, i = 2, . . . , ρ, are the tuning functions deﬁned by
τi =
i
j=1
 ∂αj−1
∂y ξzj,
i = 2, . . . , ρ,
(10.28)
where we set ∂α0
∂y = −1. The adaptive law for ˆψ is set as
˙ˆψ = τρ.
(10.29)
The adaptive laws for ˆki, i = 1, . . . , ρ, are given by
˙ˆki = γi
	∂αi−1
∂y

2
z2
i ,
(10.30)
where γi is a positive real design parameter. The control input is obtained by setting
zρ+1 = 0 as
u = 1
bρ
(αρ −pρ+1).
(10.31)
Considering the stability, we set a restriction on c2 by
c2 > ∥PG∥2,
(10.32)
where P is a positive deﬁnite matrix, satisfying
FTP + PF = −2I.
(10.33)
To end the control design, we set the interlace function in (10.19) by
ι(y) = −(FG + c1G + ˆk1G)y.
(10.34)
Remark 10.6. The adaptive coefﬁcients ˆki, i = 1, . . . , ρ, are introduced to allow the
exosystem to be truly unknown. It implies that the proposed control design can reject

Disturbance rejection and output regulation
181
disturbances completely at any frequency. If an upper bound of ∥ψ∥is known, we
can replace ˆki, i = 1, . . . , ρ, by constant positive real parameters.
◁
Remark 10.7. The ﬁnal control u in (10.31) does not explicitly contain α(w), the
feedforward control term for disturbance rejection. Instead, the proposed control
design considers q2, the contribution of the inﬂuence of α(w) to x2, from the ﬁrst step
in α1 throughout to the ﬁnal step in αρ.
◁
Theorem 10.3. For the system (10.1), the control input (10.31) ensures the bound-
edness of all the variables, and asymptotically rejects the unknown disturbances in
the sense that limt→∞y(t) = 0. Furthermore, if w(0) ∈Rm is such that w(t) contains
the components at m/2 distinct frequencies, then limt→∞ˆψ(t) = ψ.
Proof. We start from the analysis of the internal model. Deﬁne
e = ξ −η −Gy.
(10.35)
From (10.14), (10.19), (10.34) and (10.26), it can be obtained that
˙e = Fe −G(z2 + ϵ2).
(10.36)
Based on the stabilising functions shown in (10.27), the dynamics of zi, for
i = 2, . . . , ρ, can be written as
˙zi = −zi−1 −cizi −ˆki
	∂αi−1
∂y

2
zi + zi+1 −∂αi−1
∂y ( ˆψTξ −ψTη)
−∂αi−1
∂y ϵ2 −
ρ

j=i+1
∂αi−1
∂ˆψ
 ∂αj
∂y ξzj
+
i−1

j=2
∂αj−1
∂ˆψ
 ∂αi−1
∂y ξzj,
i = 2, . . . , ρ,
(10.37)
where the term ˆψTξ −ψTη can be rephrased by
ˆψTξ −ψTη = ψTe −˜
ψTξ + ψTGz1
(10.38)
with ˜ψ = ψ −ˆψ.
In the following analysis, we denote κ0, κi,j, i = 1, . . . , 3, and j = 1, . . . , ρ, as
constant positive reals, which satisfy
κ0 +
ρ

j=1
κ3,j < 1
2.
(10.39)

182
Nonlinear and adaptive control systems
Furthermore, we set constant positive reals ki, i = 1, . . . , ρ, satisfying the following
conditions:
k1 > |ψTG| + κ1,1 +
ρ

j=2
κ2,i|ψTG|2 + ∥ψ∥2
4κ3,1
,
(10.40)
ki > κ1,i +
1
4κ2,i
+ ∥ψ∥2
4κ3,i
i = 2, . . . , ρ.
(10.41)
Deﬁne a Lyapunov function candidate
V = 1
2

eTPe +
ρ

i=1
z2
i +
ρ

i=1
γ −1
i
˜k2
i + ˜ψT−1 ˜ψ + βϵTPϵϵ

,
(10.42)
where ˜ki = ki −ˆki, i = 1, . . . , ρ, Pϵ is a positive deﬁnite matrix satisfying
(Ac −LC)TPϵ + Pϵ(Ac −LC) = −2I,
and β is a constant positive real satisfying
β > ∥PG∥2
4κ0
+
ρ

j=1
1
4κ1,i
.
(10.43)
Evaluating the derivative of V along the dynamics in (10.12), (10.26), (10.36)
and (10.37) together with adaptive laws in (10.29) and (10.30), we have
˙V = −
ρ

i=1

ci + ki
	∂αi−1
∂y

2
z2
i −
ρ

i=1
zi
∂αi−1
∂y ϵ2
−
ρ

i=1
zi
∂αi−1
∂y (ψTe + ψTGz1)
−eTe −eTPG(z2 + ϵ2) −βϵTϵ.
(10.44)
For the cross-terms in (10.44), we have
eTPGϵ2
 < κ0eTe + 1
4κ0
∥PG∥2ϵ2
2,
zi
∂αi−1
∂y ϵ2
 < κ1,i
	∂αi−1
∂y

2
z2
i +
1
4κ1,i
ϵ2
2,
i = 1, . . . , ρ,

∂αi−1
∂y ψTGz1zi
 < κ2,i|ψTG|2z2
1 +
1
4κ2,i
	∂αi−1
∂y

2
z2
i ,
i = 2, . . . , ρ,

∂αi−1
∂y ψTezi
 < κ3,ieTe + ∥ψ∥2
4κ3,i
	∂αi−1
∂y

2
z2
i ,
i = 1, . . . , ρ,
|eTPGz2| < eT e
2 + ∥PG∥2z2
2/2.

Disturbance rejection and output regulation
183
Then based on the conditions speciﬁed in (10.32), (10.39), (10.40), (10.41) and
(10.43), we can conclude that there exist positive real constants δi, for i = 1, 2, 3,
such that
˙V ≤−δ1
ρ

i=1
z2
i −δ2eTe −δ3ϵTϵ.
(10.45)
We conclude zi ∈L2 ∩L∞, i = 1, . . . , ρ, and ∥e∥∈L2 ∩L∞and the boundedness
of the variables ˆψ, and ˆki, i = 1, . . . , ρ. With y = z1 ∈L∞, the boundedness of p
can be established from the minimum phase property of the system and the neutral
stability of w. Therefore, we can conclude that all the variables in the proposed
closed-loop system are bounded. Since the derivatives of zi and e are bounded, from
zi ∈L2 ∩L∞, i = 1, . . . , ρ, ∥e∥∈L2 ∩L∞and Babalat’s lemma, we further conclude
that limt→∞zi = 0, i = 1, . . . , ρ, and limt→∞∥e∥= 0.
From (10.35), we have limt→∞∥ξ(t) −η(t)∥= 0, which means that ξ asymptot-
ically converges to η. From the boundedness of all the variables and limt→∞zi = 0,
i = 1, . . . , ρ, we can conclude that limt→∞˙ˆψ = 0 and limt→∞˙ˆki = 0, i = 1, . . . , ρ,
which implies that the adaptive controller will converge to a ﬁxed-parameter type.
We now establish the convergence of ˆψ. Since limt→∞˙ˆψ = 0, there exists a
ψ∞= limt→∞ˆψ(t). From (10.14), (10.19) and (10.35), we obtain
d
dt (η −ξ) = F(η −ξ) + G(ψ −ψ∞)Tη + ε(t),
(10.46)
where
ε(t) = G(ψ∞−ˆψ)Tξ + GψT
∞(e + Gy) −ι.
From limt→∞(η −ξ) = 0 and limt→∞ε(t) = 0, we can conclude that
(ψ −ψ∞)Tη = 0,
(10.47)
because, if otherwise, (ψ −ψ∞)Tη would be a persistently excited signal, and we
could never have limt→∞(η −ξ) = 0. If the disturbance w(t) contains components
at m/2 distinct frequencies, the signal η(t) is persistently excited, and from (10.47)
we have ψ −ψ∞= 0, i.e., limt→∞ˆψ(t) = ψ.
2
Remark 10.8. The condition imposed on w(0) does not really affect the convergence
of ˆψ. It is added to avoid the situation that w(t) degenerates to have less independent
frequency components. In that situation, we can reform the exosystem and E in (10.1)
with a smaller dimension ¯m such that the reformed w(t) is persistently excited in
reduced space R ¯m and accordingly we have η, ψ ∈R ¯m. With the estimate ˆψ, together
with (F, G), the disturbance frequencies can be estimated.
◁
Example 10.1. Consider the nonlinear system
˙ζ1 = ζ2 + (ey −1) + w1
˙ζ2 = u + w1
y = ζ1,

184
Nonlinear and adaptive control systems
where w1 ∈R is a disturbance with two sinusoidal components at unknown frequen-
cies ω1 and ω2. An augmented disturbance vector w = [w1, w2, w3, w4]T satisﬁes
˙w = Sw with eigenvalues of S at {±jω1, ±jω2}. It is easy to obtain that π = [0, −w1]T
and α = −w1 −˙w1. Using the state transform x = ζ −π, we have
˙x1 = x2 + (ey −1)
˙x2 = u −α
(10.48)
y = x1.
A transform w = T ¯w can also be introduced to the disturbance model so that the
disturbance is generated by
˙¯w =
⎡
⎢⎢⎣

0
ω1
−ω1
0

02×2
02×2

0
ω2
−ω2
0

⎤
⎥⎥⎦¯w := ¯S ¯w
w1 = [t11, t12, t13, t14] ¯w,
where T, ω1 and ω2 are unknown. With the coordinate ¯w, we have
α(w) = [−t11 + ω1t12, −t12 −ω1t11, −t13 + ω2t14, −t14 −ω2t13, ] ¯w.
The steady-state contribution of w to x2 is given by q2 = Q2 ¯w, i.e., lT = Q2T −1, where
Q2 is the second row of Q which satisﬁes
Q¯S = (Ac + kC)Q + [0, 1]T[−t11 + ω1t12, −t12 −ω1t11, −t13 + ω2t14, −t14 −ω2t13].
The system (10.48) is of relative degree 2, and the control input and parameter
estimator can be designed by following the steps presented earlier.
In the simulation study, we chose the pair
F =
⎡
⎢⎢⎣
0
1
0
0
0
0
1
0
0
0
0
1
−1
−4
−6
−4
⎤
⎥⎥⎦,
G =
⎡
⎢⎢⎣
0
0
0
1/10
⎤
⎥⎥⎦,
which is controllable with the eigenvalues of F at {−1, −1, −1, −1} and ∥PG∥< 1.
We set c1 = c2 = 10, with the condition (10.32) being satisﬁed. Other parameters
in the control design were set as γ1 = γ2 = 1,  = 1000I, L1 = 3 and L2 = 2. The
disturbance was set as
w1 = 4 sin ω1t + 4 sin ω2t
with ω1 = 1 and
ω2 =
 2,
250 > t ≥0,
1.5,
t ≥250.
A set of simulation results are presented here. Figure 10.1 shows the system output
together with the control input. Figure 10.2 shows the estimates of ψ. The ideal values
of ψ are [−30, 40, 10, 40]T and [−12.5, 40, 27.5, 40]T for ω1 = 1, ω2 = 2 and ω1 = 1,

Disturbance rejection and output regulation
185
0
50
100
150
200
250
300
350
400
450
500
−0.2
0
0.2
0.4
0.6
Time (s)
y
0
50
100
150
200
250
300
350
400
450
500
−20
−10
0
10
20
30
Time (s)
u
Figure 10.1
System output and control input
0
50
100
150
200
250
300
350
400
450
500
−80
−60
−40
−20
0
20
40
60
80
Time (s)
Estimated parameters
Figure 10.2
Estimated parameters ˆψ1 (dashed), ˆψ2 (dotted), ˆψ3 (dashdot) and
ˆψ4 (solid)

186
Nonlinear and adaptive control systems
ω2 = 1.5 respectively. Under both sets of the frequencies, ˆψ converged to the ideal
values. It can be seen through this example that the disturbance of two unknown
frequencies has been rejected completely.
◁
10.2
Adaptive output regulation
In the previous section, we presented a control design for asymptotic rejection of
harmonic disturbances in nonlinear systems when the disturbance frequencies are
unknown. When the measurement, or the output, does not explicitly contain the
disturbances, the control design is referred to as asymptotic rejection problem for
the boundedness of the signals and the asymptotic convergence to zero. When the
measurement contains the disturbance or exogenous signals, the control design to
ensure the measurement converge to zero asymptotically is often referred to as the
output regulation problem. When the measurement contains the exogenous signal, the
output is normally different from the measurement, and in such a case, the output can
be viewed as to track an exogenous signal. In this section, we will present a control
design for output regulation when the measurement is different from the controlled
output.
We consider a SISO nonlinear system which can be transformed into the output
feedback form
˙x = Acx + φ(y, w, a) + bu
y = Cx
e = y −q(w),
(10.49)
with
Ac =
⎡
⎢⎢⎢⎢⎢⎣
0
1
0
. . .
0
0
0
1
. . .
0
...
...
...
...
...
0
0
0
. . .
1
0
0
0
. . .
0
⎤
⎥⎥⎥⎥⎥⎦
,
C =
⎡
⎢⎢⎢⎣
1
0
...
0
⎤
⎥⎥⎥⎦
T
,
b =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
...
0
bρ
...
bn
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
,
where x ∈Rn is the state vector; u ∈R is the control; y ∈R is the output; e is
the measurement output; a ∈Rq and b ∈Rn are vectors of unknown parameters,
with b being a Hurwitz vector with bρ ̸= 0, which implies the relative degree of the
system is ρ; φ : R × Rm × Rq →Rn is a smooth vector ﬁeld with each element being
polynomials with a known upper order of its variables and satisfying φ(0, w, a) = 0;
q is an unknownpolynomialofw; and w ∈Rm aredisturbances, andtheyaregenerated
from an unknown exosystem
˙w = S(σ)w

Disturbance rejection and output regulation
187
with unknown σ ∈Rs, of which, S ∈Rm×m is a constant matrix with distinct
eigenvalues of zero real parts.
The control design problem considered in this section is to design a control input
using the measurement feedback to ensure that the regulated measurement converges
to zero asymptotically while keeping all other variables bounded.
The system (10.1) has unknown parameters in the system and in the exosystem,
and therefore adaptive control techniques are used to tackle the uncertainties. For this
reason, the problem under consideration is referred to as adaptive output regulation.
Remark 10.9. Different from (10.1), the system (10.49) has a measurement e that is
perturbed by an unknown polynomial of the unknown disturbance. This is the reason
why the problem to be solved is an output regulation problem, rather than a disturbance
rejection problem.
◁
Remark 10.10. The nonlinear functions in (10.49) are restricted to be polynomials
of its variables, to guarantee the existence of invariant manifold for the solution
of output regulation problem. Comparing with (10.1), the nonlinear term φ(y, w, a)
has a more complicated structure, containing the output, disturbance, and unknown
parameters all together. Assuming the nonlinear functions to be polynomials also
allows that the nonlinear terms in the control design can be bounded by polynomials
of the measurement.
◁
Remark 10.11. In the system, all the parameters are assumed unknown, including
the sign of the high-frequency gain, bρ, and the parameters of the exosystem. A
Nussbaum gain is used to deal with the unknown sign of the high-frequency gain.
The adaptive control techniques presented in this control design can be easily applied
to other adaptive control schemes introduced in this book. The nonlinear functions
φ(y, w, a) and q(w) are only assumed to have known upper orders. This class of
nonlinear systems perhaps remains as the largest class of uncertain nonlinear systems
of which global output regulation problem can be solved with unknown disturbance
frequencies.
◁
When we set the unknown disturbance w and unknown parameter a to zero,
the system (10.49) is in exactly the same format as (9.32), to which backstepping
with ﬁltered transformation has been applied. With unknown parameters, adaptive
backstepping with ﬁltered transformation can be applied to solve the problem here.
One reason for us to use backstepping with ﬁltered transformation is due to the
uncertainty in the nonlinear function φ(y, w, a), which prevents the application of
adaptive observer backstepping. In the following design, we only consider the case
for relative degree greater than 1.
For the system (10.49) with relative degree ρ > 1, we introduce the same ﬁltered
transformation as in Section 9.3 with the ﬁlter
˙ξ1 = −λ1ξ1 + ξ2
. . .
˙ξρ−1 = −λρ−1ξρ−1 + u,
(10.50)

188
Nonlinear and adaptive control systems
where λi > 0, for i = 1, . . . , ρ −1, are the design parameters, and the ﬁltered
transformation
¯z = x −[¯d1, . . . , ¯dρ−1]ξ,
(10.51)
where ξ = [ξ1, . . . , ξρ−1]T and ¯di ∈Rn for i = 1, . . . , ρ −1, and they are generated
recursively by ¯dρ−1 = b and ¯di = (Ac + λi+1I)¯di+1 for i = ρ −2, . . . , 1. The system
(10.49) is then transformed to
˙¯z = Ac¯z + φ(y, w, a) + dξ1
y = C¯z,
(10.52)
where d = (Ac + λ1I)¯d1. It has been shown in (9.36) that d1 = bρ and
n

i=1
disn−i =
ρ−1

i=1
(s + λi)
n

ρ
bisn−i.
(10.53)
With ξ1 as the input, the system (10.52) is with relative degree 1 and minimum phase.
We introduce another state transform to extract the internal dynamics of (10.52) with
z ∈Rn−1 given by
z = ¯z2:n −d2:n
d1
y,
(10.54)
where (·)2:n refers to the vector or matrix formed by the 2nd row to the nth row. With
the coordinates (z, y), (10.52) is rewritten as
˙z = Dz + ψ(y, w, θ)
˙y = z1 + ψy(y, w, θ) + bρξ1,
(10.55)
where the unknown parameter vector θ = [aT, bT]T, and D is the left companion
matrix of d given by
D =
⎡
⎢⎢⎢⎢⎢⎢⎣
−d2/d1
1
. . .
0
−d3/d1
0
...
0
...
...
...
...
−dn−1/d1
0
. . .
1
−dn/d1
0
. . .
0
⎤
⎥⎥⎥⎥⎥⎥⎦
,
(10.56)
and
ψ(y, w, θ) = Dd2:n
d1
y + φ2:n(y, w, a) −d2:n
d1
φ1(y, w, a),
ψy(y, w, θ) = d2
d1
y + d2:n
d1
φ1(y, w, a).
Notice that D is Hurwitz, from (9.36), and that the dependence of d on b is reﬂected in
the parameter θ in ψ(y, w, θ) and ψy(y, w, θ), and it is easy to check that ψ(0, w, θ) = 0
and ψy(0, w, θ) = 0.

Disturbance rejection and output regulation
189
The solution of the output regulation problem depends on the existence of certain
invariant manifold and feedforward input. For this problem, we have the following
result.
Proposition 10.4. Suppose that an invariant manifold π(w) ∈Rn−1 satisﬁes
∂π(w)
∂w
S(σ)w = Dπ(w) + ψ(q(w), w, θ).
(10.57)
Then there exists an immersion for the feedforward control input
∂τ(w, θ, σ)
∂w
S(σ)w = (σ)τ(w, θ, σ)
α(w, θ, σ) = τ(w, θ, σ),
where
α(w, θ, σ) = b−1
ρ
	∂q(w)
∂w S(σ)w −π1(w) −ψy(q(w), w, θ)

.
Furthermore, this immersion can be re-parameterised as
˙η = (F + GlT)η
α = lTη,
(10.58)
where (F, G) is a controllable pair with compatible dimensions, η = Mτ and
l = M −1 with M satisfying
M(σ)(σ) −FM(σ) = G.
(10.59)
Proof. With ξ1 being viewed as the input, α is the feedforward term used for output
regulation to tackle the disturbances, and from the second equation of (10.55), we
have
α(w, θ, σ) = b−1
ρ
	∂q(w)
∂w S(σ)w −π1(w) −ψy(q(w), w, θ)

.
From the structure of the exosystem, the disturbances are sinusoidal functions.
Polynomials of sinusoidal functions are still sinusoidal functions, but with some high-
frequency terms. Since all the nonlinear functions involved in the system (10.49) are
polynomials of their variables, the immersion in (10.58) always exists. For a control-
lable pair (F, G), M is an invertible solution of (10.59) if (, ) is observable, which
is guaranteed by the immersion.
2
We now introduce the last transformation based on the invariant manifold with
˜z = z −π
(10.60)

190
Nonlinear and adaptive control systems
Finally we have the model for the control design
˙˜z = D˜z + ˜ψ
˙e = ˜z1 + ˜ψy + bρ(ξ −lTη)
˙ξ1 = −λ1ξ1 + ξ2
. . .
˙ξρ−1 = −λρ−1ξρ−1 + u,
(10.61)
where
˜ψ = ψ(y, w, θ) −ψ(q(w), w, θ)
and
˜ψy = ψy(y, w, θ) −ψy(q(w), w, θ).
Since the state in the internal model η is unknown, we design the adaptive internal
model
˙ˆη = F ˆη + Gξ1.
(10.62)
If we deﬁne the auxiliary error
˜η = η −ˆη + b−1
ρ Ge,
(10.63)
it can be shown that
˙˜η = F ˜η −FGb−1
ρ e + b−1
ρ G˜z1 + b−1
ρ G ˜ψy.
(10.64)
If the system (10.49) is of relative degree 1, then ξ1 in (10.61) is the control
input. For the systems with higher relative degrees, adaptive backstepping will be
used to ﬁnd the ﬁnal control input u from the desirable value of ξ1. Supposing that ˆξ1
is desirable value for ξ1, we introduce a Nussbaum gain N(κ) such that
ˆξ1 = N(κ)¯ξ1
˙κ = e¯ξ1,
(10.65)
where the Nussbaum gain N is a function (e.g. N(κ) = κ2 cos κ) which satisﬁes the
two-sided Nussbaum properties
lim
κ→±∞sup 1
κ
 κ
0
N(s)ds = +∞,
(10.66)
lim
κ→±∞inf 1
κ
 κ
0
N(s)ds = −∞,
(10.67)
where κ →±∞denotes κ →+∞and κ →−∞respectively. From (10.61)
and the deﬁnition of the Nussbaum gain, we have
˙e = ˜z1 + (bρN −1)¯ξ1 + ¯ξ1 + ˜bρ ˜ξ1 + ˆbρ ˜ξ1 −lT
b η + ˜ψy,

Disturbance rejection and output regulation
191
where lb = bρl, ˆbρ is an estimate of bρ and ˜bρ = bρ −ˆbρ, and ˜ξ1 = ξ1 −ˆξ1. Sine the
nonlinear functions involved in ˜ψ and ˜ψy are polynomials with ˜ψ(0, w, θ, σ) = 0 and
˜ψy(0, w, θ, σ) = 0, w is bounded, and the unknown parameters are constants, it can
be shown that
| ˜ψ| < ¯rz(|e| + |e|p),
| ˜ψy| < ¯ry(|e| + |e|p),
where p is a known positive integer, depending on the polynomials in ˜ψ and ˜ψy, and
¯rz and ¯ry are unknown positive real constants. We now design the virtual control ˆξ1
as, with c0 > 0,
¯ξ1 = −c0e −ˆk0(e + e2p−1) + ˆlT
b ˆη.
Using (10.63), we have the resultant error dynamics
˙e = −c0e −ˆk0(e + e2p−1) + ˜z1 + (bρN −1)¯ξ1 + ˜bρ ˜ξ1 + ˆbρ ˜ξ1
−lT
b ˜η −˜lT
b ˆη + lTGe + ˜ψy.
(10.68)
The adaptive laws are given by
˙ˆk0 = e2 + e2p,
τb,0 = ˜ξ1e,
(10.69)
τl,0 = −ˆηe,
where τb,0 and τl,0 denote the ﬁrst tuning functions in adaptive backstepping design
for the ﬁnal adaptive laws for ˆbρ and ˆlb. If the relative degree ρ = 1, we set u = ˆξ1.
For ρ > 1, adaptive backstepping can be used to obtain the following results:
ˆξ2 = −ˆbρe −c1 ˜ξ1 −k1

∂ˆξ1
∂e
2
˜ξ1
+ ∂ˆξ1
∂e (ˆbρξ1 −ˆlT
b ˆη) + ∂ˆξ1
∂ˆη
˙ˆη
+ ∂ˆξ1
∂ˆk0
˙ˆk0 + ∂ˆξ1
∂ˆlb
τl,1,
(10.70)

192
Nonlinear and adaptive control systems
ˆξi = −˜ξi−2 −ci−1 ˜ξi−1 −ki−1

∂ˆξi−1
∂e
2
˜ξi−1
+ ∂ˆξi−1
∂e (ˆbρξ1 −ˆlT
b ˆη) + ∂ˆξi−1
∂ˆη
˙ˆη
+ ∂ˆξi−1
∂ˆk0
˙ˆk0 + ∂ˆξi−1
∂ˆbρ
τb,i−1 + ∂ˆξi−1
∂ˆlb
τl,1
−
i
j=4
∂ˆξi−1
∂e
∂ˆξj−2
∂ˆbρ
ξ1 ˜ξj−2
+
i
j=3
∂ˆξi−1
∂e
∂ˆξj−2
∂ˆlb
ˆη˜ξj−2
for i = 2, . . . , ρ,
(10.71)
where ˜ξi = ξi −ˆξi for i = 1, . . . , ρ −2, ci and ki, i = 2, . . . , ρ −1, are positive real
design parameters, and τb,i and τl,i, for i = 1, . . . , ρ −2, are tuning functions. The
adaptive law and tuning functions are given by
τb,i = τb,i−1 −∂ˆξi
∂e ξ1 ˜ξi,
for i = 1, . . . , ρ −1,
τl,i = τl,i−1 + ∂ˆξi
∂e ˆη˜ξi,
for i = 1, . . . , ρ −1,
˙ˆbρ = τb,ρ−1,
(10.72)
˙ˆlb = τl,ρ−1.
(10.73)
Finally we design the control input as
u = ˆξρ.
(10.74)
For the proposed control design, we have the following result for stability.
Theorem 10.5. For a system (10.49) satisfying the invariant manifold condition
(10.57), the adaptive output regulation problem is globally solved by the feedback
control system consisting the ξ-ﬁlters (10.50), the adaptive internal model (10.62),
Nussbaum gain parameter (10.65), the parameter adaptive laws (10.69), (10.72),
(10.73) and the feedback control (10.74), which ensures the convergence to zero of
theregulatedmeasurement, andtheboundednessofallthevariablesintheclosed-loop
system.
Proof. Deﬁne a Lyapunov function candidate
V = β1 ˜ηTPη ˜η + β2˜zTPz˜z
+ 1
2

e2 +
ρ−1

i=1
˜ξ 2
i + (k0 −ˆk0)2 + ˜b2
ρ + ˜lT
b ˜lb

,

Disturbance rejection and output regulation
193
where β1 and β2 are two positive reals and Pz and Pη are positive deﬁnite matrices
satisfying
PzD + DTPz = −I,
PηF + FTPη = −I.
With the design of ˆξi, for i = 1, . . . , ρ, the dynamics of ˜ξi can be easily evaluated.
From the dynamics of ˜z in (10.61) and the dynamics of ˜η in (10.64), virtual controls
and adaptive laws designed earlier, we have the derivative of V as
˙V = β1(−˜ηT ˜η −2˜ηTPηFb−1
ρ Ge + 2˜ηTPηb−1
ρ G˜z1 + 2˜ηTPηb−1
ρ G ˜ψy)
+ β2(−˜zT ˜z + 2˜zTPz ˜ψ) + (ˆk0 −k0)(e2 + e2p)
−c0e2 −ˆk0(e2 + e2p) + (bρN −1)e¯ξ1
+ e˜z1 + e ˜ψy −elT
b ˜η + lTGe2
+
ρ−1

i=1
⎛
⎝−ci ˜ξ 2
i −ki

∂ˆAξ i
∂e
2
˜ξ 2
i −˜ξi
∂ˆξi
∂e ˜z1
−˜ξi
∂ˆξi
∂e
˜ψy + ˜ξi
∂ˆξi
∂e lT
b ˜η −˜ξi
∂ˆξi
∂e lTGe

.
The stability analysis can be proceeded by using the inequalities 2xy < rx2 + y2/r
or xy < rx2 + y2/(4r) for x > 0, y > 0 and r being any positive real, to tackle the
cross-terms between the variables ˜z, ˜η, e, ˜ξi, for i = 1, . . . , ρ −1. It can be shown
that there exist sufﬁciently big positive real β1, and then sufﬁciently big positive real
β2, and ﬁnally the sufﬁcient big k0 such that the following result holds:
˙V ≤(bρN(κ) −1)˙κ −1
3β1 ˜ηT ˜η −1
4β2˜zT ˜z −c0e2 −
ρ−1

i=1
ci ˜ξ 2
i .
(10.75)
The boundedness of V can be established based on the Nussbaum gain properties
(10.66) and (10.67) via an argument of contradiction. In fact, integrating (10.75) gives
V(t) +
 t
0

1
3β1 ˜ηT ˜η + 1
4β2˜zT ˜z + c0e2 +
ρ−1

i=1
ci ˜ξ 2
i

dt
≤bρ
 κ(t)
0
N(s)ds −κ(t) + V(0).
(10.76)
If κ(t), ∀t ∈R+, is not bounded from above or below, then from (10.66) and (10.67)
it can be shown that the right-hand side of (10.76) will be negative at some instances
of time, which is a contradiction, since the left-hand side of (10.76) is non-negative.

194
Nonlinear and adaptive control systems
Therefore, κ is bounded, which implies the boundedness of V. The boundedness of
V further implies ˜η, ˜z, e, ˜ξi ∈L2 ∩L∞for i = 1, . . . , ρ −1, and the boundedness
of ˆk0, ˆbρ and ˆlb. Since the disturbance w is bounded, e, ˜z, ˜η ∈L∞implies the
boundedness of y, z and ˆη, which further implies the boundedness of ˆξ1 and then
the boundedness of ξ1. The boundedness of ˆξ1 and ξ1, together with the boundedness
of e, ˆη, ˆk0, ˆbρ and ˆlb, implies the boundedness of ˆξ2, and then the boundedness of
ξ2 follows the boundedness of ˜ξ2. Applying the above reasoning recursively, we can
establish the boundedness of ˆξi for i > 2 to i = ρ −1. We then conclude that all the
variables are bounded.
The boundedness of all the variables implies the boundedness of ˙˜η, ˙˜z, ˙e and
˙˜ξi, which further implies, together with ˜η, ˜z, e, ˜ξi ∈L2 ∩L∞and Barbalat’s
lemma, limt→∞˜η = 0, limt→∞˜z = 0, limt→∞e(t) = 0 and limt→∞˜ξi = 0 for
i = 1, . . . , ρ −1.
2
10.3
Output regulation with nonlinear exosystems
In the previous sections, the disturbances are sinusoidal functions which are generated
from linear exosystems with the restriction that the eigenvalues of the exosystem
matrix are distinct and with zero real parts. Sinusoidal disturbances are important as
disturbances in practical systems can often be approximated by a ﬁnite number of
sinusoidal functions. However, there are situations where disturbances are generated
from nonlinear exosystems, such as nonlinear vibration, etc. Such disturbances can
still be approximated by a ﬁnite number of sinusoidal functions, possibly with a big
number of sinusoidal functions for a good accuracy. The more sinusoidal functions
involved in the approximation of a periodic signal, the higher order will be the
corresponding system matrix for the linear exosystem. If an internal model can
be designed directly based on the nonlinear exosystem, it is possible to achieve
asymptotic rejection of the disturbances, which cannot be achieved by approximation
using sinusoidal functions, and the order of the internal model can also remain much
lower. Of course, it is expected to be a very difﬁcult problem to directly design
an internal model to deal with nonlinear exosystems, even though there exists an
invariant manifold for output regulation. In this section, we will show nonlinear
internal model design for a class of nonlinear exosystem to achieve output regulation.
For the internal model design, we exploit a technique for nonlinear observer design
based on conditions similar to circle criteria. The dynamic model considered for
output regulation is still the class of output feedback form.
We consider a SISO nonlinear system
˙x = Acx + φ(y)a + E(w) + bu
y = Cx
(10.77)
e = y −q(w),

Disturbance rejection and output regulation
195
with
Ac =
⎡
⎢⎢⎢⎢⎢⎣
0
1
0
. . .
0
0
0
1
. . .
0
...
...
...
...
...
0
0
0
. . .
1
0
0
0
. . .
0
⎤
⎥⎥⎥⎥⎥⎦
,
C =
⎡
⎢⎢⎢⎣
1
0
...
0
⎤
⎥⎥⎥⎦
T
,
b =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
...
0
bρ
...
bn
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
,
where x ∈Rn is the state vector; u ∈R is the control; y ∈R is the output; e is the
measurement output; a ∈Rq and b ∈Rn are vectors of unknown parameters, with b
being a Hurwitz vector with bρ ̸= 0, which implies the relative degree of the system
is ρ, and with known sign of bρ, E : Rm →Rn, φ : R →Rn×q with φ(0) = 0 and
|φ(y1) −φ(y2)| ≤1(|y1|)δ1(|y1 −y2|) and δ1(·) ∈K and 1(·) is non-decreasing
and the function δ1(·) is a known smooth function; and w ∈Rm are disturbances, and
they are generated from a nonlinear exosystem
˙w = s(w)
(10.78)
of which the ﬂows are bounded and converge to periodic solutions.
Remark 10.12. The assumption about the function φ is satisﬁed for many kinds of
functions, for example polynomial functions.
◁
Remark 10.13. The nonlinear exosystem (10.78) includes nonlinear systems that
have limit cycles.
◁
Remark 10.14. The system (10.78) is very similar to the system (10.49) considered
in the previous section. The main difference is that the exosystem is nonlinear.
◁
The system (10.78) has the same structure of Ac, bu and C as in (10.49), and
therefore the same ﬁltered transformation as in the previous section can be used here.
We can use the same ﬁltered transformation, and the transformation for extracting
the zero dynamics of the system as in the previous section. Using the transformations
(10.51) and (10.54), the system (10.78) is put in the coordinate (z, y) as
˙zi = −di+1
d1
z1 + zi+1 +
	di+2
d1
−di+1d2
d2
1

y + (φi+1(y) −di+1
d1
φ1(y))a
+ Ei+1(w) −di+1
d1
E1(w),
i = 1, . . . , n −2,
(10.79)
˙zn−1 = −dn
d1
z1 −dnd2
d2
1
y +
	
φn(y) −dn
d1
φ1(y)

a + En(w) −dn
d1
E1(w),
˙y = z1 + d2
d1
y + φ1(y)a + E1(w) + bρξ1
where di are deﬁned in (10.53).

196
Nonlinear and adaptive control systems
It is necessary to have the existence of certain invariant manifolds for a solution
to the output regulation problem. When the exosystem is nonlinear, it is even more
challenging to have the necessary conditions for invariant manifold to exist.
Proposition 10.6. Suppose that there exist ϖ(w) ∈Rn and ι(w) with ϖ1(w) = q(w)
for each a, b such that
∂ϖ
∂w s(w) = Acϖ + φ(q(w))a + E(w) + bι(w).
(10.80)
Then there exists π(w) ∈Rn−1 along the trajectories of exosystem satisfying
∂πi(w)
∂w
s(w) = −di+1
d1
π1(w) + πi+1(w) + q(w)
	di+2
d1
−di+1d2
d2
1

+ Ei+1(w) −E1(w)di+1
d1
+ (φi+1(q(w))
−di+1
d1
φ1(q(w)))a,
i = 1, . . . , n −2,
∂πn−1(w)
∂w
s(w) = −dn
d1
π1(w) −dnd2
d2
1
q(w) + (φn(q(w))
−dn
d1
φ1(q(w)))a + En(w) −dn
d1
E1(w).
Proof. Since the last equation of input ﬁlter (10.50) used for the ﬁltered transformation
is an asymptotically stable linear system, there is a static response for every external
input u(w), i.e., there exists a function χρ−1(w) such that
∂χρ−1(w)
∂w
s(w) = −λρ−1χρ−1(w) + ι(w).
Recursively, if there exists χi(w) such that
∂χi(w)
∂w
s(w) = −λiχi(w) + χi+1(w),
then there exists χi−1(w) such that
∂χi−1(w)
∂w
s(w) = −λi−1χi−1(w) + χi(w).
Deﬁne
 π(w)
q(w)

= Da(ϖ(w) −[¯d1, . . . , ¯dρ−1]χ),
where χ = [χ1, . . . , χρ−1]T and
Da =
⎡
⎢⎢⎢⎣
−d2/d1
1
. . .
0
...
...
...
...
−dn/d1
0
. . .
1
1
0
. . .
0
⎤
⎥⎥⎥⎦.

Disturbance rejection and output regulation
197
It can be seen that π(w) satisﬁes the dynamics of z along the trajectories of (10.78)
as shown in (10.80), and hence the proposition is proved.
2
Based on the above lemma, we have
∂q(w)
∂w s(w) = π1(w) + d2
d1
q(w) + φ1(q(w))a + E1(w) + bρα(w),
where α(w) = χ1(w). With ξ1 being viewed as the input, α(w) is the feedforward term
used for output regulation to tackle the disturbances, and it is given by
α = b−1
ρ
	∂q(w)
∂w s(w) −π1(w) −d2
d1
q(w) −φ1(q(w))a −E1(w)

.
We now introduce the last transformation based on the invariant manifold with
˜z = z −π(w(t)).
Finally we have the model for the control design
˙˜zi = −di+1
d1
˜z1 + ˜zi+1 +
	di+2
d1
−di+1d2
d2
1

e
+ (φi+1(y) −φi+1(q(w)))a
−di+1
d1
(φ1(y) −φ1(q(w)))a,
i = 1, . . . , n −2
˙˜zn−1 = −dn
d1
˜z1 −dnd2
d2
1
e + (φn(y) −φn(q(w)))a
−dn
d1
(φ1(y) −φ1(q(w)))a
˙e = ˜z1 + d2
d1
e + (φ1(y) −φ1(q(w)))a + bρ(ξ1 −α(w)),
i.e., the system can be represented as
˙˜z = D˜z + e + (y, w, d)a
˙e = ˜z1 + d2
d1
e + (φ1(y) −φ1(q(w)))a + bρ(ξ1 −α(w)),
(10.81)
where D is a companion matrix of d shown in (10.56), and
 =
	d3
d1
−d2
2
d2
1
, . . . , dn
d1
−dn−1d2
d2
1
, −dnd2
d2
1

T
,
(y, w, d) =
⎛
⎜⎜⎜⎜⎝
φ2(y) −φ2(q(w)) −d2
d1
(φ1(y) −φ1(q(w)))
...
φn(y) −φn(q(w)) −dn
d1
(φ1(y) −φ1(q(w)))
⎞
⎟⎟⎟⎟⎠
.

198
Nonlinear and adaptive control systems
Lemma 10.7. There exists a known function ζ(·) which is non-decreasing and an
unknown constant , which is dependent on the initial state w0 of exosystem, such that
|(y, w, d)| ≤|e|ζ(|e|),
|φ1(y) −φ1(q(w))| ≤|e|ζ(|e|).
Proof. From the assumption of φ we can see that
|φ(y) −φ(q(w))| ≤1(|q(w)|)δ1(|e|).
Since the trajectories of exosystem are bounded and δ1(·) is smooth there exist smooth
nondecreasing known function ζ(·) and a nondecreasing known function 2(|w0|),
such that
δ1(|e|) ≤|e|ζ(|e|),
1(|q(w)|) ≤2(|w0|).
From previous discussion the result of the lemma is obtained.
2
Let
Vz = ˜zTPd˜z,
where
PdD + DTPd = −I.
Then using 2ab ≤ca2 + c−1b2 and ζ 2(|e|) ≤ζ 2(1 + e2), there exist unknown positive
real constants 1 and 2 such that
˙Vz = −˜zT ˜z + 2˜zTPd(e + (y, w, d)a)
≤−3
4 ˜zT ˜z + 1e2 + 2e2ζ 2(1 + e2),
(10.82)
noting that
2˜zTPde ≤1
8 ˜zT ˜z + 8eTTP2
de
≤1
8 ˜zT ˜z + 1e2,
and
2˜zTPd(y, w, d)a ≤1
8 ˜zT ˜z + 8aTTP2
da
≤1
8 ˜zT ˜z + 1
2||2
≤1
8 ˜zT ˜z + 1
22|e|2ζ 2(|e|)
≤1
8 ˜zT ˜z + 2e2ζ 2(1 + e2),
where 1
2 is an unknown positive real constant.

Disturbance rejection and output regulation
199
Now let us consider the internal model design. We need an internal model to
produce a feedforward input that converges to the ideal feedforward control term
α(w), which can be viewed as the output of the exosystem as
˙w = s(w)
α = α(w).
Suppose that there exists an immersion of the exosystem
˙η = Fη + Gγ (Jη)
α = Hη,
(10.83)
where η ∈Rr, H = [1, 0, . . . , 0], (H, F) is observable
(v1 −v2)T(γ (v1) −γ (v2)) ≥0,
and G and J are some appropriate dimensional matrices. We then design an internal
model as
˙ˆη = (F −KH)( ˆη −b−1
ρ Ke) + Gγ (J( ˆη −b−1
ρ Ke)) + Kξ1,
(10.84)
where K ∈Rr is chosen such that F0 = F −KH is Hurwitz and there exist a positive
deﬁnite matrix Pf and a semi-positive deﬁnite matrix Q satisfying
⎧
⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎩
Pf F0 + FT
0 Pf = −Q
Pf G + J T = 0
ηTQη ≥γ0|η1|2,
γ0 > 0, η ∈Rr
span(PFK) ⊆span(Q).
(10.85)
Remark 10.15. It reminds us a challenging problem to design internal models for
output regulation with nonlinear exosystems. It is not clear at the moment what
general conditions are needed to guarantee the existence of an internal model for
output regulation of nonlinear systems with nonlinear internal models. Here we use
the condition of the existence of an immersion (10.83) for the internal model design.
Also note that even when the exosystem is linear, an internal model can be nonlinear
for a nonlinear dynamic system.
◁
Remark 10.16. Note the condition speciﬁed in (10.85) is weaker than the condition
that there exist Pf > 0 and Q > 0 satisfying

PFF0 + FT
0 PF = −Q
PFG + J T = 0,
(10.86)
which can be checked by LMI.This will be seen in the example later in this section. In
particular, if G and J T are two column vectors, (F0, G) controllable, (J, F0) observable
and Re[−J(jωI −F0)−1G] > 0, ∀ω ∈R, then there exists a solution of (10.86) from
Kalman–Yacubovich lemma.
◁

200
Nonlinear and adaptive control systems
If we deﬁne the auxiliary error
˜η = η −ˆη + b−1
ρ Ke,
it can be shown that
˙˜η = F0 ˜η + G(γ (Jη) −γ (J( ˆη −b−1
ρ Ke)))
+ b−1
ρ K
	
˜z1 + d2
d1
e + (φ1(y) −φ1(q(w)))a

.
Let
Vη = ˜ηPF ˜η.
Then following the spirit of (10.82), there exist unknown positive real constants 1
and 2 such that
˙Vη = −˜ηTQ ˜η + 2˜ηTPFb−1
ρ K
	
˜z1 + d2
d1
e

+ 2˜ηTPFb−1
ρ K(φ1(y) −φ1(q(w)))a
+ 2˜ηTPFG(γ (Jη) −γ (J( ˆη −b−1
ρ Ke))
≤−3
4γ0|˜η1|2 + 12
γ0
b−2
ρ ˜z2
1 + 1e2 + 2e2ζ 2(1 + e2).
(10.87)
Let us proceed with the control design. From (10.81) and
α = η1 = ˆη1 + ˜η1 −b−1
ρ K1e,
we have
˙e = ˜z1 + d2
d1
e + (φ1(y) −φ1(q(w)))a + ¯ξ1 + bρ(˜ξ1 −˜η1 −ˆη1 + b−1
ρ K1e),
where ˜ξ1 = ξ1 −ˆξ1 and
ˆξ1 = b−1
ρ ¯ξ1.
(10.88)
For the virtual control ˆξ1, we design ¯ξ1 as, with c0 > 0,
¯ξ1 = −c0e + bρ ˆη1 −K1e −ˆle(1 + ζ 2(1 + e2)),
(10.89)
where ˆl is an adaptive coefﬁcient. Then we have the resultant error dynamics
˙e = ˜z1 −c0e + d2
d1
e −ˆle(1 + ζ 2(1 + e2)) + (φ1(y) −φ1(q(w)))a + bρ(˜ξ1 −˜η1).
Then for
Ve = 1
2e2,

Disturbance rejection and output regulation
201
there exist unknown positive real constants  1 and  2, and a sufﬁciently large
unknown positive constant β such that
˙Ve = −c0e2 + e˜z1 + d2
d1
e2 + ebρ(˜ξ1 −˜η1)
+ e(φ1(y) −φ1(q(w)))a −ˆle2(1 + ζ 2(1 + e2))
≤−c0e2 + 1
8β˜z2
1 + 1
4γ0 ˜η2
1 +  1e2 +  2e2ζ(1 + e2)
−ˆle2(1 + ζ 2(1 + e2)) + bρe˜ξ1.
(10.90)
Let
V0 = βVz + Vη + Ve + 1
2γ −1(ˆl −l)2,
where β ≥96
γ0 b−2
ρ
is chosen and l =  1 +  2 + 1 + 2 + β(1 + 2) is an
unknown constant. Let
˙ˆl = γ e2(1 + ζ 2(1 + e2)).
Then, it can be obtained that
˙V0 ≤−1
2β˜zT ˜z −1
2γ0|˜η1|2 −c0e2 + bρe˜ξ1.
If the system (10.78) has relative degree 1, the virtual control ˆξ1 shown in (10.88)
together with ¯ξ1 in (10.88) gives the input, i.e., u = ˆξ1. For the system with higher
relative degrees, the control design can be proceeded with backstepping using (10.50)
in the same way as the adaptive backstepping with ﬁltered transformation shown in the
previous section for adaptive output regulation with linear exosystems. We summarise
the stability result in the following theorem.
Theorem 10.8. For the system (10.78) with the nonlinear exosystem (10.78), if there
exists an invariant manifold (10.80) and an immersion (10.83), then there exists
K ∈Rr suchthatF0 = F −KH isHurwitzandthereexistapositivedeﬁnitematrixPF
and a semi-positive deﬁnite matrix Q satisfying (10.85), and there exists a controller
to solve the output regulation in the sense the regulated measurement converges to
zero asymptotically while other variables remain bounded.
We use an example to illustrate the proposed control design, concentrating on
the design of nonlinear internal model.
Example 10.2. Consider a ﬁrst-order system
˙y = 2y + θ sin y −y3 −θ sin w1 + w2 + u
e = y −w1,

202
Nonlinear and adaptive control systems
where θ is an unknown parameter, and the disturbance w is generated by
˙w1 = w1 + w2 −w3
1
˙w2 = −w1 −w3
2.
It is easy to see that V(w) = 1
2w2
1 + 1
2w2
2 satisﬁes
dV
dt = w2
1 −w4
1 −w4
2 ≤0,
when |w1| ≥1,
and that
q(w) = w1,
π = w1,
α(w) = −w1.
From the exosystem and the desired feedforward input α, it can be seen that the
condition speciﬁed in (10.85) is satisﬁed with η = −w and
⎧
⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩
F =

1
1
−1
0

,
G =

−1
0
0
−1

γ1(s) = γ2(s) = s3,
J =

1
0
0
1

.
Let K = [2, 0]T. Then with
F0 =
	 −1
1
−1
0

,
PF = I,
Q = diag(2, 0),
the internal model is designed as the following:
˙ˆη1 = −( ˆη1 −2e) + ˆη2 −( ˆη1 −2e)3 + 2u
˙ˆη2 = −( ˆη1 −2e) −ˆη3
2.
The control input and the adaptive law are given by
u = −ce + ˆη1 −ˆle(1 + (e2 + 1)2),
˙ˆl = γ e2(1 + (e2 + 1)2).
For simulation study, we set c = 1, θ = 1, γ = 1, and the initial states are
y(0) = 1, w1(0) = 2 and w2(0) = 2. The initial state of dynamic controller is zero.
The system output and input are shown in Figure 10.3, while the feedforward term
and its estimation are shown in Figure 10.4 and the portrait of the exosystem is
shown in Figure 10.5. As shown in the ﬁgures, the internal model successfully repro-
duces the feedforward control needed after a transient period, and the system output
measurement is regulated to zero, as required.
◁

Disturbance rejection and output regulation
203
0
5
10
15
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
Time t (s)
Tracking error e
0
5
10
15
−2
−1
0
1
2
3
4
5
Time t (s)
Control u
Figure 10.3
The system’s output e and input u
0
5
10
15
−2
−1.5
−1
−0.5
0
0.5
1
Time t (s)
h1 and h1
Figure 10.4
The systems’s feedforward control η1 and its estimation ˆη1

204
Nonlinear and adaptive control systems
−1
−0.5
0
0.5
1
1.5
2
−1
−0.5
0
0.5
1
1.5
2
w1
w2
Figure 10.5
The portrait of exosystems
10.4
Asymptotic rejection of general periodic disturbances
We have presented design methods for asymptotic rejection and output regulation
of disturbances generated from linear exosystems, i.e., sinusoidal functions and dis-
turbances from a speciﬁc class of nonlinear exosystems, which generally produce
non-harmonic but still periodic disturbances. For disturbances from linear exosys-
tem, internal models can normally be designed under some mild assumptions, while
for nonlinear exosystems, the conditions are more restrictive for designing an inter-
nal model for asymptotic rejection and output regulation. The difﬁculty lies in the
guaranteed existence of the invariant manifold, and then the nonlinear internal model
design, which is often more involved even than nonlinear observers for nonlinear
systems.
We consider some more general periodic disturbances than harmonic distur-
bances in this section. These general periodic disturbances can be modelled as outputs
of nonlinear systems, and in particular, as the outputs of linear dynamic systems with
nonlinear output functions. For the systems with Lipschitz nonlinearities, nonlinear
observers can be designed as shown in Section 8.4 and other results in literature. Of
course, the problem addressed in this chapter cannot be directly solved by nonlinear
observer design, not even the state estimation of the disturbances system, as the dis-
turbance is not measured. However, there is an intrinsic relationship between observer
design and internal model design, as evidenced in the previous results of disturbance
rejection and output regulation in the earlier sections in this chapter.

Disturbance rejection and output regulation
205
With the formulation of general periodic disturbances as the nonlinear outputs
of a linear dynamic system, the information of the phase and amplitude of a general
periodic disturbance is then embedded in the state variables, and the information of
the wave proﬁle in the nonlinear output function. The nonlinear output functions are
assumed to be Lipschitz. By formulating the general periodic disturbances in this way,
we are able to explore nonlinear observer design of nonlinear systems with output
Lipschitz nonlinearities shown in Section 8.4. We will show that general periodic
disturbances can be modelled as nonlinear outputs of a second-order linear system
with a pair of pure imaginary poles which depend on the frequencies. For this speciﬁc
system with Lipschitz nonlinear output, a reﬁned condition on the Lipschitz constant
will be given by applying the proposed method in this section, and observer gain will
be explicitly expressed in terms of the Lipschitz constant and the period or frequency
of the disturbance.
An internal model design is then introduced based on the proposed Lipschitz
output observer for a class of nonlinear systems. Conditions are identiﬁed for the
nonlinear system, and control design is carried out using the proposed internal model.
Two examples are included to demonstrate the proposed internal model and control
design procedures. These examples also demonstrate that some other problems can
be converted to the problem addressed in this section.
We consider a nonlinear system
˙y = a(z) + ψ0(y) + ψ(y, v) + b(u −μ(v))
˙z = f (z, v, y),
(10.91)
where y ∈R is the output; a and ψ0 : Rn →R are continuous functions; v ∈Rm
denotes general periodic disturbances; μ : Rm →R is a continuous function; ψ :
R × Rm →R is a continuous function and satisﬁes the condition that |ψ(y, v)|2 ≤
y ¯ψ(y) with ¯ψ being a continuous function; b is a known constant; u ∈R is the input;
z ∈Rn is the internal state variable; and f : Rn × Rm × R →Rn is a continuous
function.
Remark 10.17. For the convenience of presentation, we only consider the system
with relative degree 1 as in (10.91). The systems with higher relative degrees
can be dealt with similarly by invoking backstepping. The second equation in
(10.91) describes the internal dynamics of the system states, and if we set v = 0
and y = 0, ˙z = f (z, 0, 0) denotes the zero dynamics of this system.
◁
Remark 10.18. The system in (10.91) speciﬁes a kind of standard form for
asymptotic rejection of general periodic disturbances. For example, consider
˙x = Ax + φ(y, v) + bu
y = cTx,

206
Nonlinear and adaptive control systems
with b, c ∈Rn and
A =
⎡
⎢⎢⎢⎢⎣
−a1
1
. . .
0
−a2
0
...
0
...
...
...
...
−an
. . .
. . .
0
⎤
⎥⎥⎥⎥⎦
,
b =
⎡
⎢⎢⎢⎣
b1
b2
...
bn
⎤
⎥⎥⎥⎦,
c =
⎡
⎢⎢⎢⎣
1
0
...
0
⎤
⎥⎥⎥⎦,
where x ∈Rn is the state vector; y and u ∈R are the output and input respectively
of the system; v ∈Rm denotes general periodic disturbances; and φ : R × Rm →Rn
is a nonlinear smooth vector ﬁeld in Rn with φ(0, 0) = 0. This system is similar to
the system (10.49) with q(w) = 0. For this class of nonlinear systems, the asymptotic
disturbance rejection depends on the existence of state transform to put the systems
in the form shown in (10.91), and it has been shown in Section 10.2 that such a
transformation exists under some mild assumptions.
◁
The wave proﬁle information of a general periodic disturbance is used to construct
a nonlinear function as the output function for a linear exosystem, for the generation
of the desired feedforward input. By doing that, an observer with nonlinear output
function can be designed, viewing the feedforward input as the output, and an internal
model can then be designed based on the nonlinear observer. The problem to solve in
this section is to design a control scheme, using a nonlinear observer-based internal
model, to asymptotically reject a class of general periodic disturbances for the system
in (10.91).
We start with modelling general periodic disturbances as the outputs of a linear
oscillator with nonlinear output functions, and then propose nonlinear observer design
for such a system, for the preparation of internal model design.
Many periodic functions with period T can be modelled as outputs of a second-
order system
˙w = Aw,
with A =
 0
ω
−ω
0

μ(v) = h(w),
where ω = 2π
T . Here, the desired feedforward input μ(v) is modelled as the nonlinear
output h(w) of the second-order system. With
eAt =
 cos ωt
sin ωt
−sin ωt
cos ωt

,
the linear part of the output h(w), Hw, is always in the form of a sin (ωt + φ) where
a and φ denote the amplitude and phase respectively. Hence, we can set H = [1 0]
without loss of generality, as the amplitude and the phase can be decided by the initial
value with
w(0) = [a sin (φ) a cos (φ)]T.

Disturbance rejection and output regulation
207
Based on the above discussion, the dynamic model for general periodic disturbance
is described by
˙w1 = ωw2
˙w2 = −ωw1
(10.92)
μ = w1 + h1(w1, w2),
where h1(w1, w2) is a Lipschitz nonlinear function with Lipschitz constant γ .
Remark 10.19. General periodic disturbances can be modelled as af (t + φ) with a
and φ for the amplitude and phase of a disturbance, and the wave proﬁle is speciﬁed by
a periodic function f . In the model shown in (10.93), the amplitude and phase of the
disturbance are determined by the system state variables w1 and w2, and the proﬁle is
determined by the nonlinear output function. In some results shown in literature, the
phase and amplitude are obtained by delay and half-period integral operations. Here,
we use nonlinear observers for the estimation of phases and amplitudes of general
periodic disturbances.
◁
For the model shown in (10.93), the dynamics are linear, but the output function
is nonlinear. Many results in literature on observer design for nonlinear Lipschitz
systems are for the system with nonlinearities in the system dynamics while the output
functions are linear. Here we need the results for observer design with nonlinear output
functions. Similar techniques to the observer design of nonlinearities in dynamics can
be applied to the case when the output functions are nonlinear.
We have shown the observer design for a linear dynamic system with a nonlinear
Lipschitz output function in Section 8.4 with the observer format in (8.38) and gain
in Theorem 8.11. Now we can apply this result to observer design for the model of
general periodic disturbances. For the model shown in (10.93), the observer shown
in (8.38) can be applied with A =
 0
ω
−ω
0

and H = [1 0]. We have the following
lemma for the stability of this observer.
Lemma 10.9. An observer in the form of (8.38) can be designed to provide an expo-
nentially convergent state estimate for the general periodic disturbance model (10.93)
if the Lipschitz constant γ for h1 satisﬁes γ <
1
√
2.
Proof. Our proof is constructive. Let
P =
⎡
⎢⎢⎣
p
−
1
4γ 2ω
−
1
4γ 2ω
p
⎤
⎥⎥⎦,
where p >
1
4γ 2ω. It is easy to see that P is positive deﬁnite. A direct evaluation gives
PA + ATP −H TH
γ 2
= −1
2γ 2 I.

208
Nonlinear and adaptive control systems
Therefore, the second condition in (8.40) is satisﬁed. Following the ﬁrst condition
speciﬁed in (8.39), we set
L =
⎡
⎢⎢⎣
4ω(4pγ 2ω)
(4pγ 2ω)2 −1
4ω
(4pγ 2ω)2 −1
⎤
⎥⎥⎦.
(10.93)
The rest part of the proof can be completed by invoking Theorem 8.11.
2
Hence from the above lemma, we design the observer for the general disturbance
model as
˙ˆx = Aˆx + L(y −h(ˆx)),
(10.94)
where A =
 0
ω
−ω
0

and H = [1 0] with the observer gain L as shown in (10.93).
Before introducing the control design, we need to examine the stability issues of
the z−subsystem, and hence introduce a number of functions that are needed later
for the control design and stability analysis of the entire system.
Lemma 10.10. Assuming that the subsystem
˙z = f (z, v, y)
is ISS with state z and input y, characterised by an ISS pair (α, σ), and furthermore,
α(s) = O(a2(s)) as s →0, there exist a differentiable positive deﬁnite function ˜V(z)
and a K∞function β satisfying β(∥z∥) ≥a2(z) such that
˙˜V(z) ≤−β(∥z∥) + ¯σ(y).
(10.95)
where ¯σ is a continuous function.
Proof. From Corollary 5.10, there exists a Lyapunov function Vz(z) that satisﬁes that
α1(∥z∥) ≤Vz(z) ≤α2(∥z∥)
˙Vz(z) ≤−α(∥z∥) + σ(|y|),
(10.96)
where α, α1 and α2 are class K∞functions, and σ is a class K function. Let β
be a K∞function such that β(∥z∥) ≥a2(z) and β(s) = O(a2(s)) as s →0. Since
β(s) = O(a2(s)) = O(α(s)) as s →0, there exists a smooth nondecreasing (SN)
function ˜q such that, ∀r ∈R+
1
2 ˜q(r)α(r) ≥β(r).
Let us deﬁne two functions
q(r) := ˜q(α−1
1 (r)),
ρ(r) :=
 r
0
q(t)dt.

Disturbance rejection and output regulation
209
Deﬁne
˜V(z) := ρ(V(z)),
and it can be obtained that
˙˜V(z) ≤−q(V(z))α(z) + q(V(z))σ(|y|)
≤−1
2q(V(z))α(z) + q(θ(|y|))σ(|y|)
≤−1
2q(α1(∥z∥))α(z) + q(θ(|y|))σ(|y|)
= −1
2 ˜q(∥z∥)α(z) + q(θ(|y|))σ(|y|),
where θ is deﬁned as
θ(r) := α2(α−1(2σ(r))
for r ∈R+. Let us deﬁne a smooth function ¯σ such that
¯σ(r) ≥q(θ(|r|))σ(|r|)
for r ∈R and ¯σ(0) = 0, and then we have established (10.95).
2
Based on observer design presented in (10.94), we design the following internal
model:
˙η = Aη + b−1Lψ0(y) + Lu −b−1ALy −Lh(η −b−1Ly),
(10.97)
where L is designed as in (10.93).
The control input is then designed as
u = −b−1
	
ψ0(y) + k0y + k1y + k2
¯σ(y)
y
+ k3 ¯ψ(y)

+ h(η −b−1Ly), (10.98)
where k0 is a positive real constant, and
k1 = κ−1b2(γ + ∥H∥)2 + 3
4,
k2 = 4κ−1||b−1PL∥2 + 2,
k3 = 4κ−1||b−1PL∥2 + 1
2.
For the stability of the closed-loop system, we have the following theorem.
Theorem 10.11. For a system in the form shown in (10.91), if
●
feedforward term μ(v) can be modelled as the output of a system in the format
shown in (10.93) and the Lipschitz constant of the output nonlinear function γ
satisﬁes γ <
1
√
2

210
Nonlinear and adaptive control systems
●
the subsystem ˙z = f (z, v, y) is ISS with state z and input y, characterized by ISS
pair (α, σ), and furthermore, α(s) = O(a2(s)) as s →0
the output feedback control design with the internal model (10.97) and the control
input (10.98) ensures the boundedness of all the variables of the closed-loop system
and the asymptotic convergence to zero of the state variables z and y and the estimation
error (w −η + b−1Ly).
Proof. Let
ξ = w −η + b−1Ly.
It can be obtained from (10.97) that
˙ξ = (A −LH)ξ + b−1L(h1(w) −h1(w −ξ)) + b−1La(z) + b−1Lψ(y, v).
Let Vw = ξ TPξ. It can be obtained that
˙Vw(ξ) ≤−κ∥ξ∥2 + 2|ξ Tb−1PLa(z)| + 2|ξ Tb−1PLψ(y, v)|
≤−1
2κ∥ξ∥2 + 2κ−1||b−1PL∥2(a2(z) + ψ(y, v)|2)
≤−1
2κ∥ξ∥2 + (k2 −2)β(∥z∥) +
	
k3 −1
2

y ¯ψ(y)
(10.99)
where κ =
1
2γ 2 −1.
Based on the control input (10.98), we have
˙y = −k0y −k1y −k2
¯σ(y)
y
−k3 ¯ψ(y) + a(z) + ψ(y, v) + b(h(w −ξ) −h(w)).
Let Vy = 1
2y2. It follows from the previous equation that
˙Vy = −(k0 + k1)y2 −k2 ¯σ(y) −k3y ¯ψ(y) + ya(z) + yψ(y, v) + yb(h(w −ξ) −h(w))
≤−k0y2 −k2 ¯σ(y) −
	
k3 −1
2

y ¯ψ(y) + β(∥z∥) + 1
4κ∥ξ∥2.
(10.100)
Let us deﬁne a Lyapunov function candidate for the entire closed-loop system as
V = Vy + Vw + k2 ˜Vz.
Following the results shown in (10.96), (10.99) and (10.100), we have
˙V ≤−k0y2 −1
4κ∥ξ∥2 −β(∥z∥).
Therefore, we can conclude that closed-loop system is asymptotically stable with
respect to the state variables y, z and the estimation error ξ.
Several types of disturbance rejection and output regulation problems can be
converted to the form (10.91). In this section, we show two examples. The ﬁrst
example deals with rejection of general periodic disturbances, and the second example
demonstrates how the proposed method can be used for output regulation.

Disturbance rejection and output regulation
211
Example 10.3. Consider
˙x1 = x2 + φ1(x1) + b1u
˙x2 = φ2(x1) + ν(w) + b2u
˙w = Aw
y = x1,
(10.101)
where y ∈R is the measurement output; φi : R →R, for i = 1, 2, are continuous
nonlinear functions; ν : R2 →R is a nonlinear function which produces a periodic
disturbance from the exosystem state w; and b1 and b2 are known constants with the
same sign, which ensures that stability of the zero dynamics. The control objective
is to design an output feedback control input to ensure the overall stability of the
entire system, and the asymptotic convergence to zero of the measurement output.
The system shown in (10.101) is not in the form of (10.91) and the disturbance is not
matched. We will show that the problem can be transformed to the problem considered
in the previous section.
Let
¯z = x2 −b2
b1
x1.
In the coordinates (y, ¯z), we have
˙y = ¯z + b2
b1
y + φ1(y) + b1u
˙¯z = −b2
b1
¯z + φ2(y) −b2
b1
φ1(y) −
	b2
b1

2
y + ν(w).
Consider
˙πz = −b2
b1
πz + ν(w).
It can be shown that there exists a steady-state solution, and furthermore, we can
express the solution as a nonlinear function of w, denoted by πz(w). Let us introduce
another state transformation with z = ¯z −πz(w). We then have
˙y = z + b2
b1
y + φ1(y) + b1(u + b−1
1 πz(w))
˙z = −b2
b1
z + φ2(y) −b2
b1
φ1(y) −
	b2
b1

2
y.
(10.102)

212
Nonlinear and adaptive control systems
Comparing (10.102) with (10.91), we have
a(z) = z,
ψ(y) = b2
b1
y + φ1(y),
b = b1,
h(w) = −b−1
1 πz(w),
f (z, v, y) = φ2(y) −b2
b1
φ1(y) −
	b2
b1

2
y.
From a(z) = z, we can set β(∥z∥) = ∥z∥2 = z2.
It can be shown that the second condition of Theorem 10.11 is satisﬁed by
(10.102). Indeed, let V(z) = 1
2z2, and we have
˙Vz = −b2
b1
z2 + z

φ2(y) −b2
b1
φ1(y) −
	b2
b1

2
y

≤−1
2
b2
b1
z2 + 1
2
b1
b2

φ2(y) −b2
b1
φ1(y) −
	b2
b1

2
y
2
.
Let
˜Vz = 2b1
b2
Vz
and ﬁnally we have
˙˜Vz ≤−β(|z|) +
	b1
b2

2 
φ2(y) −b2
b1
φ1(y) −
	b2
b1

2
y
2
.
(10.103)
It can be seen that there exists a class K function σ(|y|) to dominate the second term
on the right-hand side of (10.103), and the z-subsystem is ISS. For the control design,
we can take
¯σ(y) =
	b1
b2

2 
φ2(y) −b2
b1
φ1(y) −
	b2
b1

2
y
2
.
The rest part of the control design follows the steps shown earlier.
For the simulation study, we set the periodic disturbance as a square wave. For
convenience, we abuse the notations of ν(w(t)) and h(w(t)) as ν(t) and h(t). For ν
with t in one period, we have
ν =
⎧
⎪⎨
⎪⎩
d,
0 ≤t < T
2 ,
−d,
T
2 ≤t < T,
(10.104)

Disturbance rejection and output regulation
213
where d is an unknown positive constant, denoting the amplitude. It can be obtained
that
h = d ¯h(t),
where
¯h(t) =
⎧
⎪⎪⎪⎨
⎪⎪⎪⎩
−1
b2
(1 −e
−b2
b1 t) + 1
b2
e
−b2
b1 t tanh
	T
4
b2
b1

,
0 ≤t < T
2,
1
b2
(1 + e
−b2
b1 t −2e
b2
b1 ( T
2 −t)) + 1
b2
e
−b2
b1 t tanh
	T
4
b2
b1

,
T
2 ≤t < T.
(10.105)
Eventually we have the matched periodic disturbance h(w) given by
h(w) =

w2
1 + w2
2 ¯h
	
arctan
	w2
w1


.
Note that

w2
1 + w2
2 decides the amplitude, which can be determined by the initial
state of w.
In the simulation study, we set T = 1, d = 10, φ1 = y3, φ2 = y2 and b1 = b2 = 1.
The simulation results are shown in Figures 10.6–10.9. It can be seen from Figure 10.6
that the measurement output converges to zero and the control input converges to a
periodic function. In fact, the control input converges to h(w) as shown in Figure 10.7.
0
5
10
15
−0.05
0
0.05
0.1
0.15
0.2
Time (s)
y
0
5
10
15
−20
−15
−10
−5
0
5
Time (s)
u
Figure 10.6
The system input and output

214
Nonlinear and adaptive control systems
0
5
10
15
−20
−15
−10
−5
0
5
Time (s)
u and h
u
h
Figure 10.7
Control input and the equivalent input disturbance
0
5
10
15
−4
−2
0
2
4
6
8
Time (s)
h and estimate
h
Estimate of h
Figure 10.8
The equivalent input disturbance and its estimate

Disturbance rejection and output regulation
215
0
5
10
15
−20
−10
0
10
20
30
40
Time (s)
w and estimates
w1
w2
h1
h2
Figure 10.9
The exosystem states and the internal model states
As for the internal model and state estimation, it is clear from Figure 10.8 that the
estimated equivalent input disturbance converges to h(w), and η converges to w.
◁
Example 10.4. In this example, we brieﬂy show that an output regulation problem
can also be converted to the form in (10.91). Consider
˙x1 = x2 + (ey −1) + u
˙x2 = (ey −1) + 2w1 + u
˙w = Aw
y = x1 −w1,
(10.106)
where y ∈R is the measurement output and w1 = [1 0]w. In this example, the mea-
sured output contains the unknown disturbance, unlike Example 10.3. The control
objective remains the same, to design an output feedback control law to ensure the
overall stability of the system and the convergence to zero of the measured output.
The key step in the control design is to show that the system shown in (10.106) can
be converted to the form as shown in (10.91).
Let
πz =
1
1 + ω2 [1 −ω]w,

216
Nonlinear and adaptive control systems
and it is easy to check that πz satisﬁes
˙πz = −πz + [1 0]w.
Let z = x2 −πz −x1. It can be obtained that
˙y = z + y + ew1(ey −1) + (u −h(w))
˙z = −z −y + 2w1,
where
h(w) = 2 + ω2
1 + ω2 [−1 ω]w −(ew1 −1).
It can be seen that we have transformed the system to the format as shown in
(10.91) with ψ(y, v) = ew1(ey −1).
To make H = [1 0], we introduce a state transform for the disturbance model as
ζ = 2 + ω2
1 + ω2
 −1
ω
−ω
−1

w.
It can be easily checked that ˙ζ = Aζ. The inverse transformation is given as
w =
1
2 + ω2
 −1 −ω
ω
−1

ζ.
With ζ as the disturbance state, we can write the transformed system as
˙y = z + y + e1/(2+ω2)[−1−ω]ζ(ey −1) + (u −h(ζ))
˙z = −z −y +
2
2 + ω2 [−1 −ω]ζ
(10.107)
˙ζ = Aζ,
where
h(ζ) = ζ1 −(e1/(2+ω2)[−1−ω]ζ −1).
Note that ey−1
y
is a continuous function, and we can take ¯ψ(y) = d0y( ey−1
y )2 where
d0 is a positive real constant depending on the frequency and the knowledge of an
upper limit of the disturbance amplitude. The control design presented in the previous
section can then be applied to (10.108). Simulation studies were carried out with the
results shown in Figures 10.10–10.13.
◁

Disturbance rejection and output regulation
217
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
−0.05
0
0.05
0.1
0.15
0.2
Time (s)
y
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
−300
−250
−200
−150
−100
−50
0
50
Time (s)
u
Figure 10.10
The system input and output
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
−300
−250
−200
−150
−100
−50
0
50
Time (s)
u and h
u
h
Figure 10.11
Control input and the equivalent input disturbance

218
Nonlinear and adaptive control systems
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
−25
−20
−15
−10
−5
0
5
10
15
20
Time (s)
h and estimate
h
Estimate of h
Figure 10.12
The equivalent input disturbance and its estimate
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
−30
−20
−10
0
10
20
30
40
Time (s)
m and estimates
m1
m2
h1
h2
Figure 10.13
The exosystem states and the internal model states

Chapter 11
Control applications
In this chapter, we will address a few issues about control applications. Several
methods of disturbance rejection are presented in Chapter 10, including rejection
of general periodic disturbances. A potential application can be the estimation and
rejection of undesirable harmonics in power systems. Harmonics, often referred to
high-orderharmonicsinpowersystems, arecausedbynonlinearitiesinpowersystems,
and the successful rejection depends on accurate estimation of amplitudes and phase
of harmonics. We will show an iterative estimation method based on a new observer
design method.
There are tremendous nonlinearities in biological systems, and there have been
some signiﬁcant applications of nonlinear system analysis and control methods in
system biology. We will show a case that nonlinear observer and control are applied
to circadian rhythms. A Lipschitz observer is used to estimate unknown states, and
backstepping control design is then applied to restore circadian rhythms.
Most of the control systems are implemented in computers or other digital devices
which are in discrete-time in nature. Control implementation using digital devices
inevitably ends with sample-data control. For linear systems, the sampled systems are
still linear, and the stability of the sampled-date system can be resolved in stability
analysis using standard tools of linear systems in discrete-time. However, when a
nonlinear system is sampled, the system description may not have a closed form, and
the structure cannot be preserved. The stability cannot be assumed for a sampled-data
implementation of nonlinear control strategy. We will show that for certain nonlinear
control schemes, the stability can be preserved by fast sampling in the last section.
11.1
Harmonics estimation and rejection in power
distribution systems
There is a steady increase in nonlinear loading in power distribution networks due to
the increase in the use of electrical cars, solar panels for electricity generation, etc.
Nonlinear loading distorts the sinusoidal waveforms of voltage and current in net-
works. The distorted waveforms are normally still periodic, and they can be viewed as
general periodic disturbances. Based on Fourier series, a general periodic signal can
be decomposed into sinusoidal functions with multiple frequencies of the base fre-
quency. The components with high frequencies are referred to as harmonics. In other
words, they are individual frequency modes at frequencies which are multiples of the
base frequency.

220
Nonlinear and adaptive control systems
Harmonics are undesirable in power distribution networks for various reasons.
They occupy the limited power capacity, and can be harmful to electrical and elec-
tronic devices. Often in power distribution networks, active and passive power ﬁlters
are used to reduce the undesired harmonics. Effective rejection of harmonics depends
on accurate phase and amplitude estimation of individual frequency modes. In a power
distributionnetwork, harmonicswithcertainfrequenciesaremorecriticalforrejection
than others. For example the double frequency harmonics normally disappear in the
system due to a particular connection in power distribution networks, and third-order
harmonicswouldbemostimportanttoreject, perhapsduetohigh-attenuationhighfre-
quencies of distribution networks. Based on this discussion, estimation and rejection
of speciﬁc frequency modes will be of interest to power distribution networks.
As explained above, harmonics appear as general periodic signals. Rejection of
general periodic disturbances is discussed in Chapter 10, for matched cases, i.e., the
input is in exactly the same location as the disturbances, which is a restriction to
certain applications, even though we may be able to convert an unmatched case to a
matched one for a certain class of nonlinear systems. The method in Chapter 10 does
not apply to rejection of individual frequency modes. We will show the conversion
of an unmatched disturbance to a matched one, and show how individual frequency
modes can be estimated and rejected.
We will consider a class of nonlinear systems that has a similar structure to
the systems considered in the earlier chapters, but with unmatched general periodic
disturbances. We will show how an equivalent input, also a periodic disturbance, can
be obtained for this system, and then propose an estimation and rejection method
for the system. The presentation at this stage is not exactly based on power systems,
but the proposed methods can be directly applied to power distribution systems. We
will show an example of estimation of harmonics using the proposed method for
individual frequency modes.
11.1.1
System model
Consider a SISO nonlinear system which can be transformed into the output feedback
form
˙ζ = Acζ + φ(y) + bu + dw
y = Cζ,
(11.1)
with
Ac =
⎡
⎢⎢⎢⎢⎢⎣
0
1
0
. . .
0
0
0
1
. . .
0
...
...
...
...
...
0
0
0
. . .
1
0
0
0
. . .
0
⎤
⎥⎥⎥⎥⎥⎦
,
b =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
...
0
bρ
...
bn
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
,
C =
⎡
⎢⎢⎢⎣
1
0
...
0
⎤
⎥⎥⎥⎦
T
,
d =
⎡
⎢⎣
d1
...
dn
⎤
⎥⎦,
where ζ ∈Rn is the state vector; u ∈R is the control input; φ : R →Rn with φ(0) = 0
is a nonlinear function with element φi being differentiable up to the (n −i)th order;

Control applications
221
b ∈Rn is a known constant Hurwitz vector, with bρ ̸= 0, which implies the relative
of the system is ρ; d is an unknown constant vector; and w ∈R is a bounded periodic
disturbance, which has continuous derivative up to the order of max{ρ −ι, 0} with ι
being the index of the ﬁrst non-zero element of vector d.
Remark 11.1. The disturbance-free system of (11.1) is in the output feedback form
discussed in the previous chapters. With the disturbance, it is similar to the system
(10.1), with the only difference that w is a general periodic disturbance. It is also
different from the system (10.91) of which the disturbance is in the matched form.
◁
Remark 11.2. The continuity requirement speciﬁed for the general periodic distur-
bance w in (11.1) is for the existence of a continuous input equivalent disturbance
and a continuous invariant manifold in the state space. For the case of ρ < ι, we may
allow disturbance to have ﬁnite discontinuous points within each period, and for each
of the discontinuous points, the left and right derivatives exist.
◁
Remark 11.3. The minimum phase assumption is needed for the convenience of
presentation of the equivalent input disturbance and the control design based on
backstepping. Itisnotessentialforcontroldesign, disturbancerejectionordisturbance
estimation. We could allow the system to be non-minimum phase, provided that there
exists a control design for the disturbance-free system which renders the closed-loop
system exponentially stable.
◁
The zero dynamics of (11.1) is linear. To obtain the equivalent input disturbance,
we need a result for steady-state response for stable linear systems.
Lemma 11.1. For a linear system
˙x = Ax + bw,
(11.2)
where x ∈Rn is the system state, A is Hurwitz, b ∈Rn is a constant vector and w is the
periodic disturbance with period T, the steady state under the input of the periodic
disturbance w is given by
xs(t) =
 t
0
eA(t−τ)bw(τ)dτ + eAt(I −eAT)−1eATWT,
(11.3)
where WT is a constant vector in Rn given by
WT =
 T
0
e−Aτbw(τ)dτ.
Proof. The state response to the input w is given by
x(t) = eAtx(0) +
 t
0
eA(t−τ)bw(τ)dτ.

222
Nonlinear and adaptive control systems
Considering the response after a number of periods, we have
x(NT + t) = eA(NT+t)x(0) + eA(NT+t)
 NT+t
0
e−Aτbw(τ)dτ
= eA(NT+t)x(0) + eA(NT+t)
N−1
	
i=0
 (i+1)T
iT
e−Aτbw(τ)dτ
+eA(NT+t)
 NT+t
NT
e−Aτbw(τ)dτ,
where N is a positive integer. Since w(t) is a periodic function, we have
 (i+1)T
iT
e−Aτbw(τ)dτ =
 (i+1)T
iT
e−Aτbw(τ −iT)dτ
=
 T
0
e−A(iT+τ)bw(τ)dτ
= e−iAT
 T
0
e−Aτbw(τ)dτ.
Therefore, we have
x(NT + t) = eA(NT+t)x(0) + eAt
N−1
	
i=0
eA(N−i)T
 T
0
e−Aτbw(τ)dτ
+
 t
0
eA(t−τ)bw(τ)dτ.
(11.4)
The steady-state response in (11.3) is obtained by taking the limit of (11.4) for
t →∞.
2
To obtain the equivalent input disturbance, we need to introduce state trans-
formation to (11.1). To extract the zero dynamics, we introduce a partial state
transformation for system (11.1) as
z =
⎡
⎢⎣
ζρ+1
...
ζn
⎤
⎥⎦−
ρ
	
i=1
Bρ−i¯bζi,
where
B =
⎡
⎢⎢⎢⎢⎣
−bρ+1/bρ
1
. . .
0
...
...
...
...
−bn−1/bρ
0
. . .
1
−bn/bρ
0
. . .
0
⎤
⎥⎥⎥⎥⎦
,
¯b =
⎡
⎢⎣
bρ+1/bρ
...
bn/bρ
⎤
⎥⎦.

Control applications
223
The dynamics with the coordinates (ζ1, . . . , ζρ, z) can be obtained as
˙ζi = ζi+1 + φi(y) + diw,
i = 1, . . . , ρ −1
˙ζρ = z1 +
ρ
	
i=1
riζi + φρ(y) + dρw + bρu
(11.5)
˙z = Bz + φz(y) + dzw,
where
ri = (Bρ−i¯b)i,
for i = 1, . . . , ρ,
φz(y) =
⎡
⎢⎣
φρ+1
...
φn
⎤
⎥⎦−
ρ
	
i=1
Bρ−i¯bφi + Bρ ¯by,
and
dz =
⎡
⎢⎣
dρ+1
...
dn
⎤
⎥⎦−
ρ
	
i=1
Bρ−i¯bdi.
The periodic trajectory and the equivalent input disturbance can be found using
the system in the coordinate (ζ1, . . . , ζρ, z). Since the system output y does not
contain the periodic disturbance, we have the invariant manifold for π1 = 0. From
Lemma 11.1 which is used for the result of the steady-state response of linear systems
to the periodic input, we have, for 0 ≤t < T,
πz(t) =
 t
0
eB(t−τ)dzw(τ)dτ + eBt(I −eBT)−1eBTWT
with WT =

 T
0 e−Bτdzw(τ)dτ. From the ﬁrst equation of (11.6), we have, for
i = 1, . . . , ρ −1
πi+1(t) = dπi(t)
dt
−diw.
Based on the state transformation introduced earlier, we can use its inverse
transformation to obtain
⎡
⎢⎣
πρ+1
...
πn
⎤
⎥⎦= πz +
ρ
	
i=1
Bρ−i¯bπi.
Therefore, the periodic trajectory in the state space is obtained as
π = [π, . . . , πn]T.
(11.6)

224
Nonlinear and adaptive control systems
Finally, the equivalent input disturbance μ is given by
μ = 1
bρ

dπρ(t)
dt
−πz,1 −
ρ
	
i=1
riπz,i −dρw

.
(11.7)
Let x = ζ −π denote the difference between the state variable ζ and the periodic
trajectory.
The periodic trajectory, π, plays a similar role as the invariant manifold in the
set-up for the rejection of disturbances generated from linear exosystems. For this,
we have the following result.
Theorem 11.2. For the general periodic disturbance w in (11.1), the periodic tra-
jectory given in (11.6) and the equivalent input disturbance given in (11.7) are well
deﬁned and continuous, and the difference between the state variable (11.1) and the
periodic trajectory, denoted by x = ζ −π, satisﬁes the following equation:
˙x = Acx + φ(y) + b(u −μ)
y = Cx.
(11.8)
The control design and disturbance rejection will be based on (11.8) instead
of (11.1).
Remark 11.4. The control design and disturbance rejection only use the output y,
with no reference to any of other state of the system. Therefore, there is no difference
whether we refer to (11.1) or (11.8) for the system, because they have the same output.
The format in (11.8) shows that there exist an invariant manifold and an equivalent
input disturbance. However, the proposed control design does not depend on any
information of μ, other than its period, which is the same as the period of w. In other
words, control design only relies on the form shown in (11.1). The form shown in
(11.8) is useful for the analysis of the performance of the proposed control design,
including the stability. In this section, we start our presentation from (11.1) rather
than (11.8) in order to clearly indicate the class of the systems to which the proposed
control design can be applied, without the restriction to the rejection of matched
disturbances.
◁
11.1.2
Iterative observer design for estimating frequency
modes in input
We will propose an iterative observer design method to estimate speciﬁc frequency
modesintheinputtoalinearsystemfromitsoutput. Fortheconvenienceofdiscussion,
we have the following deﬁnitions.

Control applications
225
Deﬁnition 11.1. A T-periodic function f is said to be orthogonal to a frequency mode
with frequency ωk if
 T
0
f (τ) sin ωkτdτ = 0,
(11.9)
 T
0
f (τ) cos ωkτdτ = 0.
(11.10)
Deﬁnition 11.2. A function f is said to be asymptotically orthogonal to a frequency
mode with frequency ωk if
lim
t→∞
 t+T
t
f (τ) sin ωkτdτ = 0,
(11.11)
lim
t→∞
 t+T
t
f (τ) cos ωkτdτ = 0.
(11.12)
We consider a stable linear system
˙x = Ax + bμ
y = Cx,
(11.13)
where x ∈Rn is the state variable; and y and u ∈R are output and input, the matrices
A, b and C are with proper dimensions; and the system is stable and observable with
the transfer function Q(s) = C(sI −A)−1b.The problem considered in this subsection
is to create a signal such that speciﬁc frequency modes can then be removed from the
input μ, which is a general periodic disturbance described by
μ(t) =
∞
	
k=1
ak sin (ωkt + φk),
where ωk = 2πk
T
and ak and φk are the amplitude and phase angle of the mode for
frequency ωk. The dynamics for a single frequency mode can be described as
˙wk = Skwk,
(11.14)
where
Sk =

0
ωk
−ωk
0

.
For a single frequency mode with the frequency ωk as the input denoted by
μk = ak sin (ωkt + φk), its output in y, denoted by yk, is a sinusoidal function with
the same frequency, if we only consider the steady-state response. In fact, based on
the frequency response, we have the following result.
Lemma 11.3. Consider a stable linear system (A, b, C) with no zero at jωk for any
integer k. For the output yk of a single frequency mode with the frequency ωk, there
exists an initial state wk(0) such that
yk = gTwk,
(11.15)

226
Nonlinear and adaptive control systems
where g = [1 0]T and wk is the state of (11.14). Furthermore, the input μk for this
frequency mode can be expressed by
μk = gT
k wk,
(11.16)
where
gk = 1
mk

cos θk
sin θk
−sin θk
cos θk

g := Qkg
(11.17)
with θk = ∠Q(jωk) and mk = |Q(jωk)|.
Proof. For the state model (11.14), we have
eSkt =
 1
1
j
−j
  ejωkt
ejωkt
  1
1
j
−j
−1
=
 cos (ωkt)
sin (ωkt)
−sin (ωkt)
cos (ωkt)

.
For the single frequency mode ωk, the output is given by
yk = mkak sin (ωkt + φk + θk).
With g = [1 0]T, we have
wk(0) =
 mkak sin (φk + θk)
mkak cos (φk + θk)

and
wk(t) = eSktwk(0) =
 mkak sin (ωkt + φk + θk)
mkak cos (ωkt + φk + θk)

such that
yk = gTeSktwk(0) = gTwk(t).
Considering the gain and phase shift of Q(s), we have
μk =
1
mk
gTeSk(t−(θk/ωk))wk(0)
=
1
mk
gTe−(θk/ωk)SkeSktwk(0).
Hence, we have
gk = 1
mk
e−(θk/ωk)ST
k g
and therefore
Qk = 1
mk
e−(θk/ωk)ST
k = 1
mk
e(θk/ωk)Sk = 1
mk
 cos θk
sin θk
−sin θk
cos θk

.

Control applications
227
For a stable single-input linear system, if the input is a T-periodic signal that is
orthogonal to a frequency ωk, the steady state, as shown earlier, is also T-periodic.
Furthermore, we have the following results.
Lemma 11.4. If the input to a stable single-input linear system (A, b) is T-periodic
signal that is orthogonal to a frequency mode ωk, for any positive integer k, the steady
state is orthogonal to the frequency mode and the state variable is asymptotically
orthogonal to the frequency mode. Furthermore, if the linear system (A, b, C) has
no zero at jωk, the steady-state output is orthogonal to the frequency mode ωk if and
only if the input to the system is orthogonal to the frequency mode.
Proof. We denote the input as μ, and the state variable x satisﬁes
˙x = Ax + bμ.
Since μ is T-periodic, the steady-state solution of the above state equation, denoted
by xs, is also T-periodic and
˙xs = Axs + bμ.
Let
Jk =
 T
0
xs(τ) sin ωkτdτ.
Using integration by part, we have
Jk = −ω−1
k
 T
0
xsd cos ωkτ
= ω−1
k
 T
0
˙xs cos ωkdτ
= ω−1
k
 T
0
(Axs + bμ(t)) cos ωkτdτ
= ω−1
k A
 T
0
xs cos ωkτdτ
= ω−2
k A
 T
0
xsd sin ωkτ
= −ω−2
k A
 T
0
(Axs + bμ(t)) sin ωkτdτ
= −ω−2
k A2
kJk.
Hence, we have
(ω2
kI + A2)Jk = 0.

228
Nonlinear and adaptive control systems
Since A is a Hurwitz matrix which cannot have ±ωkj as its eigenvalues, we conclude
Jk = 0. Similarly we can establish
 T
0
xs(τ) cos ωkτdτ = 0
and therefore xs is orthogonal to the frequency mode ωk.
If we denote ex = x −xs, we have ˙ex = Aex. It is clear that ex exponentially
converges to zero, and therefore we can conclude that x is asymptotically orthogonal
to the frequency mode ωk. This completes the proof of the ﬁrst part.
For the second part of the lemma, the ‘if’ part follows directly from the ﬁrst part
of the lemma, and we now establish the ‘only if’ part by seeking a contradiction.
Suppose that the output y is orthogonal to the frequency mode ωk, and the input μ is
not. In this case, it can be shown in a similar way as in the proof Lemma 11.3, that
there exists a proper initial condition for wk(0) such that μ −gT
k wk is orthogonal to
ωk. Since the system is linear, we can write
y = y⊥+ yw,
where y⊥denotes the steady-state output generated by μ −gT
k wk and yw generated
by gT
k wk. We have y⊥orthogonal to the frequency mode ωk. However, yw would be
a sinusoidal function with frequency ωk and it is deﬁnitely not orthogonal. Thus we
conclude y is not orthogonal to ωk, which is a contradiction. Therefore, μ must be
orthogonal to ωk if y is. This completes the proof.
2
To remove frequency modes in the input μ is to ﬁnd an estimate ˆμ such that μ −ˆμ
does not contain those frequency modes asymptotically. For a single frequency mode
with frequency ωk, the task to obtain a ˆμ is accomplished by
˙ˆwk = Sk ˆwk + lk(y(t) −gT ˆwk)
ˆμ = (Qkg)T ˆwk = gT
k ˆwk,
(11.18)
where lk is chosen such that Sk −lkgT is Hurwitz. For this observer, we have a useful
result stated in the following lemma.
Lemma 11.5. For any positive integer k, with the observer as designed in (11.18),
(μ(τ) −gT
k ˆwk) is asymptotically orthogonal to the frequency mode ωk, i.e.,
lim
t→∞
 t+T
t
(μ(τ) −gT
k ˆwk) sin ωkτdτ = 0,
(11.19)
lim
t→∞
 t+T
t
(μ(τ) −gT
k ˆwk) cos ωkτdτ = 0.
(11.20)

Control applications
229
Proof. Consider the steady-state output y of input μ. From Lemma 11.3, there exists
an initial state wk(0) such that
 T
0
(y(τ) −gTwk(τ)) sin ωkτdτ = 0,
 T
0
(y(τ) −gTwk(τ)) cos ωkτdτ = 0,
which implies that μ −gT
k wk is orthogonal to the frequency mode ωk, again based on
Lemma 11.3.
Let ˜wk = wk −ˆwk. The dynamics of ˜wk can be obtained from (11.14) and
(11.18) as
˙˜wk = ¯Sk ˜wk −lk(y −gTwk),
(11.21)
where ¯Sk = Sk −lkgT. Note that ¯Sk is a Hurwitz matrix and (y −gTwk) is a
T-periodic signal. There exists a periodic steady-state solution of (11.21) such that
˙πk = ¯Skπk −lk(y −gTwk).
From Lemma 11.4, πk is orthogonal to the frequency mode ωk because (y −gTwk)
is. Let ek = ˜wk −πk. We have
˙ek = ¯Skek,
which implies that ek exponentially converges to zero. The observer state ˆwk can be
expressed as
ˆwk = wk −πk −ek.
Therefore, (11.19) and (11.20) can be established, and this completes the proof.
2
The result in Lemma 11.5 shows how an individual frequency mode can be
removed with the observer designed in the way as if the output would not contain
other frequency modes. From the proof of Lemma 11.5, it can be seen that there
is an asymptotic error, πk, between the observer state and the actual state variables
associated with the frequency mode ωk. Although πk is orthogonal to the frequency
mode ωk, it does in general contain components generated from all the other frequency
modes. Because of this, a set of observers of the same form as shown in (11.18) would
not be able to extract multiple frequency modes simultaneously. To remove multiple
frequency modes, it is essential to ﬁnd an estimate which is asymptotically orthogonal
to the multiple frequency modes. For this, the interactions between the observers must
be dealt with.
Suppose that we need to remove a number of frequency modes ωk for all the k
in a ﬁnite set of positive integers K = {ki}, for = 1, . . . , m. To estimate the frequency
modes for ωk,i, i = 1, . . . , m, we propose a sequence of observers,
˙ˆwk,1 = Sk,1 ˆwk,1 + lk,1(y −gT ˆwk,1)
(11.22)

230
Nonlinear and adaptive control systems
and, for i = 2, . . . , m,
˙ηk,i−1 = Aηk,i−1 + bgT
k,i−1 ˆwk,i−1
(11.23)
˙ˆwk,i = Sk,i ˆwk,i + lk,i
⎛
⎝y −
i−1
	
j=1
Cηk,j −gT ˆwk,i
⎞
⎠,
(11.24)
where lk,i, for i = 1, . . . , m, are designed such that ¯Sk,i := Sk,i −lk,igT are Hurwitz,
and
gk,i =
1
mk,i
 cos φk,i
sin φk,i
−sin φk,i
cos φk,i

g := Qk,ig
with mk,i = |C(jwk,i −A)−1b| and φk,i = ∠C(jwk,i −A)−1b.
The estimate for the input disturbance which contains the required frequency
modes for asymptotic rejection is given by
ˆμm =
m
	
i=1
gT
k,i ˆwk,i.
(11.25)
The estimate ˆμm contains all the frequency modes ωk,i, for i = 1, . . . , m. The useful
property of the estimate is given in the following theorem.
Theorem 11.6. For the estimate ˆμm given in (11.25), μ −ˆμm is asymptotically
orthogonal to the frequency modes ωk,i for i = 1, . . . , m.
Proof. In the proof, we will show how to establish the asymptotic orthogonality in
detail by induction.
We introduce the notations ˜wk,i = wk,i −ˆwk,i. We use πk,i to denote the steady-
state solutions of ˜wk,i and ek,i = ˜wk,i −πk,i, for i = 1, . . . , m.
Lemma 11.5 shows that the results hold for m = 1. Let
μ1 = gT
k,1(wk,1 −πk,1)
and μ −μ1 is orthogonal to the frequency mode ωk,1.
We now establish the result for m = 2. From Lemma 11.3, there exists an initial
state variable wk,2(0) for the dynamic system
˙wk,2 = Sk,2wk,2
(11.26)
such that y −Cqk,1 −gTwk,2 is orthogonal to the frequency mode ωk,2 where qk,i, for
i = 1, . . . , m −1, denote the steady-state solution of
˙qk,i = Aqk,i + bgT
k,i(wk,i −πk,i).
Note that gTwk,2 can be viewed as the output for the input gT
k,2wk,2 to the system
(A, b, C), based on Lemma 11.3. Hence, y −Cqk,1 −gTwk,2 is the output for the input
μ −gT
k,1(wk,1 −πk,1) −gT
k,2wk,2 to the system (A, b, C).Therefore, from Lemma 11.4,
μ −gT
k,1(wk,1 −πk,1) −gT
k,2wk,2 is orthogonal to ωk,2. Furthermore, from the previous

Control applications
231
step πk,1 is orthogonal to ωk,1. Hence, μ −gT
k,1(wk,1 −πk,1) −gT
k,2wk,2 is orthogonal
to the frequency modes ωk,j for j = 1, 2.
The dynamics of ˜wk,2 and πk,2 are obtained as
˙˜wk,2 = ¯Sk,2 ˜wk,2 −lk,2(y −Cηk,1 −gTwk,2),
(11.27)
˙πk,2 = ¯Sk,2πk,2 −lk,2(y −Cqk,1 −gTwk,2),
(11.28)
and the error ek,2 = ˜wk,2 −πk,2 satisﬁes
˙ek,2 = ¯Sk,2ek,2 −lk,2C(qk,1 −ηk,1).
Since qk,1 −ηk,1 exponentially converges to zero, so does ek,2. From (11.28) and
Lemma 11.4, πk,2 is orthogonal to the frequency modes ωk,j for j = 1, 2. Therefore,
by letting
μ2 = gT
k,1(wk,1 −πk,1) + gT
k,2(wk,2 −πk,2),
μ −μ2 is orthogonal to the frequency modes ωk,j for j = 1, 2.
Notice that
μ2 −ˆμ2 =
2
	
j=1
gT
k,j(wk,j −πk,j −ˆwk,j)
=
2
	
j=1
gT
k,1ek,j.
Hence μ2 −ˆμ2 converges to zero exponentially. Therefore, we conclude that μ −ˆμ2
is asymptotically orthogonal to the frequency modes ωk,j for j = 1, 2.
Now suppose that the result holds for m = i and therefore μ −μi is orthogonal
to the frequency modes ωk,j for j = 1, . . . , i, with
μi =
i	
j=1
gT
k,j(wk,j −πk,j).
We need to establish that the result holds for m = i + 1.
For the frequency mode ωk,i+1, there exists an initial state variable wk,i(0) for the
dynamic system
˙wk,i+1 = Sk,iwk,i+1
such that y −C i
j=1 qk,j −gTwk,i+1 is orthogonal to the frequency mode ωk,i+1. Note
that y −C i
j=1 qk,j −gTwk,i+1 is the output for the input μ −μi −gT
k,i+1wk,i+1 to the
system (A, b, C). Therefore from Lemma 11.4, μ −μi −gT
k,i+1wk,i+1 is orthogonal
to ωk,i+1. Since μ −μi is orthogonal to the frequency modes ωk,j for j = 1, . . . , i,
μ −μi −gT
k,i+1wk,i+1 is orthogonal to the frequency modes ωk,j for j = 1, . . . , i + 1
and so is (y −C i
j=1 qk,j −gTwk,i+1).

232
Nonlinear and adaptive control systems
The dynamics of ˜wk,i+1 and πk,i+1 are obtained as
˙˜wk,i+1 = ¯Sk,i+1 ˜wk,i+1
−lk,i+1
⎛
⎝y −C
i	
j=1
ηk,j −gTwk,i+1
⎞
⎠,
(11.29)
˙πk,i+1 = ¯Sk,i+1πk,i+1
−lk,i+1
⎛
⎝y −C
i	
j=1
qk,j −gTwk,i+1
⎞
⎠.
(11.30)
Since the input is orthogonal to the frequency modes ωk,j for j = 1, . . . , i + 1, we
conclude from Lemma 11.4 that πk+i+1 is orthogonal to ωk,j for j = 1, . . . , i + 1, and
therefore μ −μi+1 is orthogonal to the frequency modes ωk,j for j = 1, . . . , i + 1 with
μi+1 = μi + gT
k,i+1(wk,i+1 −πk+i+1).
The error ek,i+1 = ˜wk,i+1 −πk,i+1 satisﬁes
˙ek,i+1 = ¯Sk,i+1ek,i+1 −lk,i+1C
i	
j=1
(qk,j −ηk,j).
Since qk,j −ηk,j, for j = 1, . . . , i, exponentially converge to zero, so does ek,i+1. With
μi+1 −ˆμi+1 =
i+1
	
j=1
gT
k,j(wk,j −πk,j −ˆwk,j)
=
i	
j=1
gT
k,jek,j,
μi+1 −ˆμi+1 converges to zero exponentially. Therefore, we conclude that μ −ˆμi+1
is asymptotically orthogonal to the frequency modes ωk,j for j = 1, . . . , i + 1.
Since i is an arbitrary integer between 1 and m, the result holds for i = m −1,
and this completes the proof.
2
11.1.3
Estimation of speciﬁc frequency modes in input
From the previous analysis on the equivalent input disturbance, we can convert the
unmatched disturbance case to the matched one. Therefore, we can now carry on the
disturbance rejection based on the matched case:
˙x = Acx + φ(y) + b(u −μ)
y = Cx.
(11.31)

Control applications
233
If the disturbance does not exist in (11.31), the system (11.31) is in the linear
observer error with output injection that is shown in Chapter 8. In that case, we can
design a state observer as
˙p = (Ac −LC)p + φ(y) + bu + Ly,
(11.32)
where p ∈Rn, L ∈Rn is chosen so that Ac −LC is Hurwitz. The difﬁculty in the state
estimation is due to the unknown disturbance μ. Consider
˙q = (Ac −LC)q + bμ,
(11.33)
where q denotes the steady-state solution. Such a solution exists, and an explicit
solution is given earlier. Each element of q is a periodic function, as μ is periodic.
We have an important property for p and q stated in the following lemma.
Lemma 11.7. The state variable x can be expressed as
x = p −q + ϵ,
(11.34)
where p is generated from (11.32) with q satisfying (11.33) and ϵ satisfying
˙ϵ = (Ac −LC)ϵ.
(11.35)
From (11.33), we have Cq as the steady-state output of the system ((Ac −
kC), b, C) for the equivalent input disturbance μ. If Cq is available, we are ready to use
the results presented in the previous section for disturbance estimation of the speciﬁed
frequency modes.The result shown in Lemma 11.7 indicates that Cq = Cp −y −Cϵ,
and hence Cp −y exponentially converges to Cq. Therefore, we now propose an
observer for frequency modes in the input disturbances using Cp −y. To estimate the
frequency modes for ωk,i i = 1, . . . , m, we have
˙ˆwk,1 = Sk,1 ˆwk,1 + lk,1(Cp −y −gT ˆwk,1)
(11.36)
and, for i = 2, . . . , m,
˙ηk,i−1 = (Ac −kC)ηk,i−1 + bgT
k,i−1 ˆwk,i−1,
(11.37)
˙ˆwk,i = Sk,i ˆwk,i + lk,i
⎛
⎝Cp −y −
i−1
	
j=1
Cηk,j −gT ˆwk,i
⎞
⎠,
(11.38)
where lk,i, for i = 1, . . . , m, are designed such that ¯Sk,i := Sk,i −lk,igT are Hurwitz,
and
gk,i =
1
mk,i

cos φk,i
sin φk,i
−sin φk,i
cos φk,i

g := Qk,ig
(11.39)
with mk,i = |C(jwk,i −(A −kC))−1b| and φk,i = ∠C(jwk,i −(A −kC))−1b.

234
Nonlinear and adaptive control systems
The estimate for the input disturbance which contains the required frequency
modes for asymptotic rejection is given by
ˆμm =
m
	
i=1
gT
k,i ˆwk,i.
(11.40)
The estimate ˆμm contains all the frequency modes ωk,i, for i = 1, . . . , m. The useful
property of the estimate is given in the following theorem.
Theorem 11.8. The estimate ˆμm given in (11.40) is bounded and satisﬁes the
following:
lim
t→∞
 t+T
t
[μ(τ) −ˆμm(τ)] sin ωk,iτdτ = 0,
(11.41)
lim
t→∞
 t+T
t
[μ(τ) −ˆμm(τ)] cos ωk,iτdτ = 0,
(11.42)
for i = 1, . . . , m.
Proof. From Theorem 11.6, the results in (11.41) and (11.42) hold if the input
Cp −y in (11.36), (11.37) and (11.38) equals Cq. Since Cp −y −Cq converges
exponentially to 0, and (11.36)–(11.38) are stable linear systems, the errors in
the estimation of ˆμ caused by replacing Cq by Cp −y in (11.36)–(11.38) are also
exponentially convergent to zero. Therefore, (11.41) and (11.42) can be established
from Theorem 11.6.
2
11.1.4
Rejection of frequency modes
With the estimated frequency modes ˆμm, we set the control input as
u = v + ˆμm,
where v is designed based on backstepping design which is shown in Chapter 9. Due
to the involvements of disturbance in the system, we need certain details of stability
analysis with explicit expression of Lyapunov functions. For the convenience of sta-
bility analysis, we adopt an approach using backstepping with ﬁltered transformation
shown in Section 9.4. The control input v can be designed as a function
v = v(y, ξ),
where ξ is the state variable of the input ﬁlter for the ﬁltered transformation. The ﬁnal
control input is designed as
u = v(y, ξ) + ˆμ.
(11.43)
For the stability of the closed-loop system with disturbance rejection, we have the
following theorem.

Control applications
235
Theorem 11.9. The closed-loop system of (11.1) under the control input (11.43)
ensures the boundedness of all the state variables, and the disturbance modes of
speciﬁed frequencies ωk,i, for i = 1, . . . , m, are asymptotically rejected from the
system in the sense that all the variables of the closed-loop system is bounded and
the system is asymptotically driven by the frequency modes other than the speciﬁed
modes.
Proof. For the standard backstepping design for the nonlinear systems, we establish
the stability by considering the Lyapunov function
V = βzTPz + 1
2y2 + 1
2
ρ−1
	
i=1
˜ξ 2
i ,
(11.44)
where β is a constant and ˜ξi = ξi −ˆξi and P is a positive deﬁnite matrix satisfy-
ing DTP + PD = −I. The standard backstepping design ensures that there exists a
positive real constant γ1 such that
˙V ≤−γ1V −[2βzTPbz + yby] ˜μ
≤−γ1V −γ2
√
V ˜μ
≤−γ3V + γ4 ˜μ2
(11.45)
for some positive real constants γi, i = 2, 3, 4. Hence, the boundedness of ˜μ ensures
the boundedness of all the state variables. It is clear from Theorem 11.8 that all the
speciﬁed frequency modes are asymptotically removed from ˜μ. This completes the
proof.
Remark 11.5. In the control design, we have used the control input obtained with the
backstepping design for the proof of Theorem 11.9. In case that there exists a known
control design for the disturbance-free system which ensures exponential stability of
the disturbance-free case, we can pursue the proof of Theorem 11.9 in a similar way
to obtain the result shown in (11.45). This is very useful in particular for the case of
non-minimum phase systems, to which the standard backstepping presented earlier
does not apply.
◁
11.1.5
Example
In this section, we use a simple example to demonstrate estimation of harmonics using
the method proposed earlier in this section.
We consider a voltage signal with diados as shown in Figure 11.1. We are
going to use iterative observers to estimate harmonics in this signal. To simplify
the presentation, we assume that the signal is directly measurable. In this case,
there are no dynamics between the measurement and the point of estimation.
Hence, we can simplify the algorithms presented in Subsection 11.1.2 ((11.22),

236
Nonlinear and adaptive control systems
0.7
0.72
0.74
0.76
0.78
0.8
–1
–0.5
0
0.5
1
1.5
t (s)
Voltage
Figure 11.1
Voltage signal of a nonlinear load
(11.23) and (11.24)). In this case, there is no need to use the observer model in
(11.23). The simpliﬁed algorithm for direct estimation of harmonics is presented
below.
To estimate the frequency modes for ωk,i, i = 1, . . . , m, the iterative observers
are given by
˙ˆwk,1 = Sk,1 ˆwk,1 + lk,1(y −gT ˆwk,1)
(11.46)
and, for i = 2, . . . , m,
˙ˆwk,i = Sk,i ˆwk,i + lk,i
⎛
⎝y −
i	
j=1
gT ˆwk,j
⎞
⎠,
(11.47)
where lk,i, for i = 1, . . . , m, are designed such that ¯Sk,i := Sk,i −lk,igT are Hurwitz.
For the electricity, the base frequency is 50 Hz. We will show the estimates
of harmonics from the base frequency, that is, we set ωk,1 = 100π, ωk,2 = 200π,
ωk,3 = 300π, etc. For these frequency modes, we have
Sk,i =

0
i100π
−i100π
0

.

Control applications
237
The observer gain lk,i can be easily designed to place the close-loop poles at any
speciﬁed positions. For the simulation study, we place the poles at {−200, −200}. For
such pole positions, we have
lk,i =

400
40000
i100π −200π

.
The harmonics of second and third orders are plotted with the original signal and
the estimated base frequency component in Figure 11.2. The approximations of
accumulative harmonics to the original signal are shown in Figure 11.3.
In this example, we have shown the estimation of harmonics from direct
measurements. The advantage of this estimation is that the estimation is on-line
and can be implemented in real time. Also, the estimation using the proposed
method can provide the phase information, which is very important for harmonic
rejection. We did not show the rejection of harmonics in this example. However,
it is not difﬁcult to see that rejection can be simulated easily with the proposed
method.
0.74
0.745
0.75
0.755
0.76
0.765
0.77
0.775
0.78
–1
–0.5
0
0.5
1
1.5
t (s)
Signal & harmonics
Original
1st order
2nd order
3rd order
Figure 11.2
Estimated harmonics

238
Nonlinear and adaptive control systems
Original
1st order
Up to 2nd order
Up to 3rd order
0.74
0.745
0.75
0.755
0.76
0.765
0.77
0.775
0.78
–1
–0.5
0
0.5
1
1.5
t (s)
Signal & approximation
Figure 11.3
Approximation using harmonic components
11.2
Observer and control design for circadian rhythms
Circadian rhythms play an important role in daily biological activities of living
species. Circadian rhythms, or biological clocks, normally have a period of 24 h, and
changes to the rhythms can be referred to as changes in phases. Circadian disorder is
a phenomenon of circadian rhythms which occurs when internal rhythms cannot keep
up with the changes of external environmental rhythms. Changes of environmental
rhythms, presented by the change of light/dark cycles or by irregular rhythms, result
in phase shifts between internal and external rhythms. For example, jet lags are
caused when people travel from one time zone to another. The existence of these
phase shifts in longer term has negative effect to health. Therefore, in biological
study of circadian rhythms, it is important to ﬁnd methods to recover the shifted
phases, such as jet lags, to their normal rhythms. These methods could then lead to
treatments of circadian disorder, like sleep disorder and jet lag. Circadian rhythms can
be accurately modelled as limit cycles of nonlinear dynamic systems. We will apply
the observer and control design shown in earlier chapters for analysis and control
of circadian rhythms. The phase restoration is carried out by the synchronisation of
trajectories generated from a controlled model with the trajectories of a reference
system via nonlinear control design. Both reference and controlled systems are based

Control applications
239
on a given third-order model of Neurospora circadian rhythms. An observer is also
designed to estimate two unknown states from the measurement of a single state.
11.2.1
Circadian model
For almost every living organism on the Earth, their daily biological activities are
governed by rhythms. These biological rhythms are called circadian rhythms. The
circadian rhythms exist as self-sustained and periodic oscillations, and they are also
known with their entrainment to 24-h day/night cycle. The entrainment is based on
the activity of a circadian clock gene. For mammals, the circadian clock gene, also
known as the circadian pacemaker, is found in the suprachiasmatic nuclei (SCN) of
the anterior hypothalamus. The circadian pacemaker captures information sent from
an external environment cue such as light, and then coordinates the timing of other
slave clocks or slave oscillators in other parts of the body.Any changes of environment
cues which cause the mismatch between external and internal rhythms can lead to
disruption of circadian rhythms. This phenomenon is known as circadian disorders.
Jet lags due to trans-continent ﬂights and sleeping disorders due to irregular sleep–
wake cycles are two typical examples of circadian disorders. In practice, one of the
known medical treatments for circadian disorders is the application of light. Light is
major external environmental cue, and with light input, the circadian phase can be
adjusted to the light/dark rhythms at destination.
In this section, we aim for the restoration of circadian phase using nonlinear
control. In order to achieve this objective, we propose an alternative control design
method which synchronises trajectories generated from a controlled model with the
trajectories generated from a reference model via backstepping approach. Both ref-
erence system and controlled system are based on a third-order mathematical model
of Neurospora circadian rhythms. The trajectories generated by controlled system
represent the altered rhythms. Meanwhile, the reference trajectories represent the
desired rhythms which the trajectories of controlled system are adjusted to match. We
also present an observer design for this circadian rhythm based on observer design
presented in Chapter 8 for nonlinear systems with Lipschitz nonlinearities.
A third-order mathematical model is developed to describe molecular mechanism
of circadian rhythms in Neurospora. Its molecular mechanism is based on the negative
feedback exerted by FRQ proteins on the expression of frq gene. Transcription of frq
gene yields messenger RNA (mRNA), and the translation of which synthesises FRQ
protein. These synthesised FRQ proteins are then transferred back into nucleus where
they inhibit the transcription of frq gene. A new activation of frq gene transcription
will restart the cycle. Dynamics of these variables, frq mRNA, FRQ protein and
nuclear FRQ protein, are by the following dynamic model:
˙x1 = vs
Kn
i
Kn
i + xn
3
−vm
x1
KM + x1
˙x2 = ksx1 −vd
x2
Kd + x2
−k1x2 + k2x3
(11.48)
˙x3 = k1x2 −k2x3,

240
Nonlinear and adaptive control systems
where x1, x2 and x3 denote concentration of frq mRNA, concentration of FRQ protein
outside nucleus and concentration of nucleus FRQ protein respectively. Values of
three state variables x1, x2 and x3 are assumed to be positive values. In system
(11.49), the parameter vs denotes the transcription rate of frq gene. The other
parameters involved in system (11.49) are Ki, n, vm, KM, ks, k1, k2, vd and Kd. The
parameters Ki, n, vm, KM represent the threshold constant beyond which nuclear FRQ
protein inhibits the transcription of frq, the Hill coefﬁcient showing the degree of
co-operativity of the inhibition process, the maximum rate of frq mRNA degradation
and the Michaelis constant related to the latter process respectively. The parameters
ks, k1 and k2 denote the rate constant measuring the rate of FRQ synthesis, the rate con-
stants of the transport of FRQ into and out of the nucleus respectively. The parameter
vd denotes maximum rate of FRQ degradation and Kd is the Michaelis constant related
to this process. For the third-order Neurospora model, the parameters have their typ-
ical values as vs = 1.6 nM h−1, Ki = 1 nM, n = 4, vm = 0.7 nM h−1, KM = 0.4 nM,
ks = 1 h−1, vd = 4 nMh−1, Kd = 1.4 nM, k1 = 0.3 h−1, k2 = 0.15 h−1.
Circadian rhythms are self-sustained and periodic oscillations. With the set
parameters as above, dynamics of state variables of (11.48) can sustain periodic oscil-
lations, and in fact, a limit cycle. Figure 11.4 shows the plots of three state variables
obtained in simulation with the model (11.48). For simulation study, we choose the
initial values x(0) =
 5
1
1 T. This particular initial value is actual a point on the
limit cycle. If the initial value starts from a point outside the limit cycle, then there
trajectory will converge to the limit cycle. There can be other selections for values of
initial conditions.
0
10
20
30
40
50
60
70
80
90
100
110
120
0
1
2
3
4
5
6
Time (h)
State variables of Neurospora model
x1
x2
x3
Figure 11.4
Circadian rhythm of Neurospora

Control applications
241
The model (11.48) is not in the right format for control and observer design. We
introduce a state transformation as
z = Tx
(11.49)
with
T =
⎡
⎣
0
0
1
0
k1
0
k1ks
0
0
⎤
⎦,
and the transformed system is described by
˙z1 = z2 −k2z1
˙z2 = z3 −k1z2 + k1k2z1 −vd
k1z2
k1Kd + z2
(11.50)
˙z3 = vs
k1ksKn
i
Kn
i + zn
1
−vm
k1ksz3
KMk1ks + z3
.
Now the transformed model (11.50) is in the lower-triangular format.
11.2.2
Lipschitz observer design
We have presented observer design for nonlinear dynamic systems with Lipschitz
nonlinearity in Section 8.4. Basically, for a nonlinear system described by (8.29)
˙x = Ax + φ(x, u)
y = Cx,
a nonlinear observer can be designed as in (8.30)
˙ˆx = Aˆx + L(y −Cˆx) + φ(ˆx, u),
(11.51)
provided that the conditions speciﬁed in Theorem 8.10 are satisﬁed. That suggests
that we need ﬁnd the Lipschitz constant ν together with a positive deﬁnite matrix P
for nonlinearities in the circadian model (11.48) such that the inequality (8.36)
ATP + PA + 2νI −2σCTC < 0
is satisﬁed, and then we obtain the observer gain as
L = σP−1CT.
The one-sided Lipschitz condition shown in (8.36) can be checked using the
Lipschitz constant for individual elements in the vector φ. Let us denote the Lipschitz
constants of φi by γi. The condition shown in (8.36) can be guaranteed by
ATP + PA + 2n
n
	
i=1
γiλiI −2σCTC < 0,
(11.52)

242
Nonlinear and adaptive control systems
where λi are positive real constants, and P ∈∩n
i=1Pn(i, λi). The deﬁnition of
P ∈∩n
i=1Pn(i, λi) is given by
Pn(i, λi) = {P : |pji| < λi, for j = 1, 2, . . . , n}.
For the system (11.50), we set
C1 =
 1
0
0 
and therefore state variables z2 and z3 are unknown. Comparing with the structure in
(8.29), we have
φ(z, u) =
⎡
⎣
0
φ2
φ3a + φ3b
⎤
⎦,
where clearly φ1 = 0, and
φ2 = −vd
k1z2
k1Kd + z2
,
φ3a = vs
k1ksKn
i
Kn
i + zn
1
,
φ3b = −vm
k1ksz3
KMk1ks + z3
.
From the deﬁnition of Lipschitz constant in Deﬁnition 8.2, we have

−vdk1z2
k1Kd + z2
+
vdk1ˆz2
k1Kd + ˆz2
 ≤vd
Kd
z2 −ˆz2
 ,

−vmk1ksz3
KMk1ks + z3
+
vmk1ksˆz3
KMk1ks + ˆz3
 ≤vm
KM
z3 −ˆz3
 ,
and therefore we obtain the Lipschitz constants as γ2 = vd
Kd =10.7962 for ϕ2(z2), and
γ3b =
vm
KM =1.01 for ϕ3b(z3). For nonlinear function ϕ3a(z1), its Lipschitz constant can
be computed by using mean value theorem which is described by
f ′(ζ)
 =

f (x) −f (ˆx)
x −ˆx
 ,
where ζ ∈[x, ˆx]. Setting f = φ3a, we have
f ′(ζ)
 =
−nvsk1ksKn
i ζ n−1

Kn
i + ζ n2
 =

φ3a(z1) −φ3a(ˆz1)
z1 −ˆz1
 ,
where ζ ∈[min (z1, ˆz1), max (z1, ˆz1)]. We ﬁnd maximum value of |f ′(ζ)| by solving
|f ′′(ζ)| = 0, and obtain the result as 0.325. Since the value of Lipschitz constant is
equivalent to maximum value of f ′(ζ), the Lipschitz constant is given by γ3a = 0.325.
The Lipschitz constant λ3 is given by λ3 = λ3a + λ3b = 1.326.

Control applications
243
After the Lipschitz constants are found, we solve (11.52) to obtain
σ = 67.8032,
L =
⎡
⎣
3.9887
2.6067
1.3469
⎤
⎦
for the observer (11.51). Simulation study for the observer has been carried out with
the results shown in Figures 11.5 and 11.6.
0
10
20
30
40
50
60
70
80
90
100
110
120
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
Time (h)
Transformed state z2 and its estimate
z2
Estimate of z2
Figure 11.5
Observer state for circadian model
11.2.3
Phase control of circadian rhythms
The objective of phase control is to reset a distorted phase. Our strategy is to control
the distorted circadian rhythm to follow a target rhythm. In order to design a control
strategy, we need to deﬁne a sensible control input for the circadian model. Among
the parameters appeared in (11.48), parameter vs, which denotes the rate of frq mRNA
transcription, is sensitive to light input. Therefore, for Neurospora circadian rhythms,
this parameter is usually used as control input in many results which have been
presented in literature. If vs is taken as the control input, the circadian model (11.48)
is rewritten as
˙x1 = (vs + u)
Kn
i
Kn
i + xn
3
−vm
x1
KM + x1
˙x2 = ksx1 −vd
x2
Kd + x2
−k1x2 + k2x3
˙x3 = k1x2 −k2x3,

244
Nonlinear and adaptive control systems
z3
Estimate of z3
0
10
20
30
40
50
60
70
80
90
100
110
120
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
Time (h)
Transformed state z3 and its estimate
Figure 11.6
Observer state for circadian model
where u is the control input. The system model after the state transformation (11.49)
is then obtained as
˙z1 = z2 −k2z1
˙z2 = z3 −k1z2 + k1k2z1 −vd
k1z2
k1Kd + z2
˙z3 = vs
k1ksKn
i
Kn
i + zn
1
−vm
k1ksz3
KMk1ks + z3
+ u k1ksKn
i
Kn
i + zn
1
.
(11.53)
This model (11.53) is then used for phase control design. We use q to denote the state
variable for the target circadian model
˙q1 = q2 −k2q1
˙q2 = q3 −k1q2 + k1k2q1 −vd
k1q2
k1Kd + q2
˙q3 = vs
k1ksKn
i
Kn
i + qn
1
−vm
k1ksq3
KMk1ks + q3
,
(11.54)
to which the variable z is controlled to follow.
The transformed dynamic models (11.53) and (11.54) are in the triangular form,
and therefore the iterative backstepping method shown in Section 9.2 can be applied.
There is a slight difference in the control objective here from the convergence to zero

Control applications
245
in Section 9.2. For this, we deﬁne
e1 = z1 −q1,
e2 = z2 −q2,
(11.55)
e3 = z3 −q3,
where ei, for i = 1, 2 and 3, are the tracking errors.The error dynamics are obtained as
˙e1 = e2 −k2e1
˙e2 = e3 −k1e2 + k1k2e1 −
vdk2
1Kde2
(k1Kd + z2) (k1Kd + q2)
˙e3 = vs
k1ksKn
i
Kn
i + zn
1
−vs
k1ksKn
i
Kn
i + qn
1
−
vmKM (k1ks)2 e3
(KMk1ks + z3) (KMk1ks + q3) + u k1ksKn
i
Kn
i + zn
1
.
(11.56)
It is easy to see that the model (11.56) is still in the triangular form.The phase resetting
is achieved if we can ensure that the errors ei, i = 1, 2, 3, converge to zero. To the
model (11.56), iterative backstepping can be applied. Following the procedures shown
in Section 9.2, we deﬁne
w1 = e1,
w2 = e2 −α1,
(11.57)
w3 = e3 −α2,
where α1 and α2 are stabilising functions to be designed.
From the ﬁrst equation of (11.56), we obtain dynamics of w1 as
˙w1 = e2 −k2e1
= w2 + α1 −k2e1.
The stabilising function α1 is then designed as
α1 = −c1w1 + k2e1,
(11.58)
where c1 is a positive real constant. The resultant dynamics of w1 are given by
˙w1 = −c1w1 + w2.
(11.59)
The dynamics of w2 are obtained as
˙w2 = e3 −k1e2 + k1k2e1 −
vdk2
1Kde2
(k1Kd + z2) (k1Kd + q2) −∂α1
∂e1
˙e1
= w3 + α2 −k1e2 + k1k2e1 −
vdk2
1Kde2
(k1Kd + z2) (k1Kd + q2) −∂α1
∂e1
˙e1.
The stabilising function α2 can be designed as
α2 = −w1 −c2w2 + k1e2 −k1k2e1 + vdk1
k1Kde2
(k1Kd + z2) (k1Kd + q2) + ∂α1
∂e1
˙e1

246
Nonlinear and adaptive control systems
with c2 being a positive real constant, which results in the dynamics of w2
˙w2 = −w1 −c2w2 + w3.
(11.60)
From the dynamics of w3
˙w3 = vs
k1ksKn
i
Kn
i + zn
1
−vs
k1ksKn
i
Kn
i + qn
1
+ u k1ksKn
i
Kn
i + zn
1
−
vmKM (k1ks)2 e3
(KMk1ks + z3) (KMk1ks + q3) −∂α2
∂e1
˙e1 −∂α2
∂e2
˙e2,
we design the control input u as
u = Kn
i + zn
1
k1ksKn
i

−w2 −c3w3 −vs
k1ksKn
i
Kn
i + zn
1
+ vs
k1ksKn
i
Kn
i + qn
1
+ ∂α2
∂e1
(e2 −k2e1)
+ ∂α2
∂e2
(e3 −k1e2 + k1k2e1) −∂α2
∂e2
vdk2
1Kde2
(k1Kd + z2) (k1Kd + q2)

,
(11.61)
with c3 as a positive real constant. The resultant dynamics of w3 are then obtained as
˙w3 = −w2 −c3w3.
(11.62)
The stability analysis of the proposed control design can be established in the
same way as the proof shown in Section 9.2 for iterative backstepping control design.
Indeed, consider a Lyapunov function candidate
V = 1
2

w2
1 + w2
2 + w2
3

.
(11.63)
Using the dynamics of wi, i = 1, 2, 3, in (11.59), (11.60) and (11.62), we obtain
˙V = w1 ˙w1 + w2 ˙w2 + w3 ˙w3
= w1 (−c1w1 + w2) + w2 (−w1 −c2w2 + w3) + w3 (−w2 −c3w3)
= −c1w2
1 −c2w2
2 −c3w2
3.
Therefore, we can conclude that the closed-loop system under the control of u in
(11.61) is exponentially stable with respect to the variables wi, i = 1, 2, 3, which
suggests that the controlled circadian rhythm asymptotically tracks the targeted one.
Simulation study of the control design proposed above has been carried with the
control parameters c1 = c2 = c3 = 0.1. The states z2 and z3 are shown in Figures 11.7
and 11.8 when the control input is applied at t = 50 h, and the control input is shown
in Figure 11.9. The plot of z1 is very similar to the plot of z2, and it is omitted. It can
be seen from the ﬁgures that there is a phase difference before the control input is
applied, and the control input resets the phase of the control circadian rhythm to the
targeted one.

Control applications
247
q2
z2
0
10
20
30
40
50
60
70
80
90
100
110
120
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
Time (h)
q2 and z2
Control input applied
Figure 11.7
Circadian phase reset for state 2
q3
z3
q3 and z3
0
10
20
30
40
50
60
70
80
90
100
110
120
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
Time (h)
Control input applied
Figure 11.8
Circadian phase reset for state 3
11.3
Sampled-data control of nonlinear systems
A practical issue of applying nonlinear control strategies is to implement them in
computers or microprocessors which are discrete-time in nature. For a continuous-
time system with a discrete-time controller, inevitably we end with a sampled-data

248
Nonlinear and adaptive control systems
0
10
20
30
40
50
60
70
80
90
100
110
120
–30
–25
–20
–15
–10
–5
0
5
Time (h)
Control input
Control input u
Figure 11.9
Control input for circadian phase reset
control system. It is well known for linear systems, we can use emulation method,
that is, to design a controller in continuous-time and then implement its discrete-time
version.Alternative to emulation method is the direct design in discrete-time. Stability
analysis for sampled-data control of linear dynamic systems can then be carried out in
the framework of linear systems in discrete-time. Sampled-data control of nonlinear
systems is a much more challenging task.
For a nonlinear system, it is difﬁcult or even impossible to obtain a nonlinear
discrete-time model after sampling. Even with a sampled-data model in discrete-
time, the nonlinear model structure cannot be preserved in general. It is well known
that nonlinear control design methods do require certain structures. For example
backstepping can be applied to lower-triangular systems, but a lower-triangular system
in continuous-time will not have its discrete-time model in the triangular structure in
generalaftersampling. Hence, itisdifﬁculttocarryoutdirectlydesignindiscrete-time
for continuous-time nonlinear systems.
Foracontrolinputdesignedbasedonthecontinuous-timemodel, itcanbesampled
and implemented in discrete-time. However, the stability cannot be automatically
guaranteed for the sampled-data system resulted from emulation method. The stability
analysis is challenging because there is no corresponding method in discrete-time for
nonlinear systems after sampling, unlike linear systems. One would expect that if the
sampling is fast enough, the stability of the sampled-data system might be guaranteed
by the stability of the continuous-time system. In fact, there is a counter example to
this claim. Therefore, it is important to analyse the stability of sampled-data system
in addition to the stability of the continuous-time control, for which the stability is
guaranteed in control design.
In this section, we will show the stability analysis of sampled-data control for a
class of nonlinear systems in the output feedback form. A link between the sampling

Control applications
249
period and initial condition is established, which suggests that for a given domain
of initial conditions, there always exists a sampling time such that if the sampling is
faster than that time, the stability of the sampled-data system is guaranteed.
11.3.1
System model and sampled-data control
In this section, we consider sampled-data control for a class of nonlinear systems in
the output feedback form. This class of nonlinear systems (9.17) has been considered
for control design in continuous-time in Chapter 9, using observer backstepping in
Section 9.3 and using backstepping with ﬁltered transformation in Section 9.4. We will
present sampled-data control based on the control input in continuous-time obtained
using backstepping with ﬁltered transformation. For the convenience of presentation,
we will show the system again and outline the key steps in the continuous-time here.
The system, as shown in (9.17) and (9.32), is described as
˙x = Acx + bu + φ(y)
y = Cx,
(11.64)
with
Ac =
⎡
⎢⎢⎢⎢⎢⎣
0
1
0
. . .
0
0
0
1
. . .
0
...
...
...
...
...
0
0
0
. . .
1
0
0
0
. . .
0
⎤
⎥⎥⎥⎥⎥⎦
,
C =
⎡
⎢⎢⎢⎣
1
0
...
0
⎤
⎥⎥⎥⎦
T
,
b =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
...
0
bρ
...
bn
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
,
where x ∈Rn is the state vector; u ∈R is the control input; φ : R →Rn with φ(0) = 0
is a nonlinear function with element φi being differentiable up to the (n −i)th order;
and b ∈Rn is a known constant Hurwitz vector with bρ ̸= 0, which implies the relative
of the system is ρ.
We design an output feedback control for the system in (11.64). As shown in
Chapter 9, the continuous-time control input can be designed using the backstep-
ping with ﬁltered transformation in Section 9.4. In this section, we carry out the
stability analysis based on the control input obtained using backstepping with ﬁltered
transformation.
In this section, we need to deal with control in continuous-time and discrete-time.
For notation, we use uc for the control input obtained in continuous-time and ud for
the resultant sampled-data control input. For notational convenience, we re-write the
ﬁlter (9.33) as
˙ξ = ξ + bf u
(11.65)
u = uc(y, ξ),
(11.66)

250
Nonlinear and adaptive control systems
where
 =
⎡
⎢⎢⎢⎣
−λ1
1
0
. . .
0
0
−λ2
1
. . .
0
...
...
...
...
...
0
0
0
. . .
−λρ−1
⎤
⎥⎥⎥⎦,
bf =
⎡
⎢⎢⎢⎣
0
...
0
1
⎤
⎥⎥⎥⎦.
For a given uc, the sampled-data controller based on emulation method is given as
ud(t) = uc(y(mT), ξ(mT)),
∀t ∈[mT, mT + T),
(11.67)
ξ(mT) = eTξ((m −1)T) + bf uc(y((m −1)T), ξ((m −1)T))
 T
0
eτdτ,
(11.68)
where y(mT) is obtained by sampling y(t) at each sampling instant; ξ(mT) is the
discrete-time implementation of the ﬁlter shown in (11.65); T is the ﬁxed sampling
period; and m is the discrete-time index, starting from 0.
Before the analysis of the sampled-data control, we brieﬂy review the control
design in continuous-time.
As shown in Section 9.4, through the state transformations, we obtain
˙ζ = Dζ + ψ(y)
˙y = ζ1 + ψy(y) + bρξ1.
(11.69)
For the system with relative degree ρ = 1, as shown in Lemma 9.5 and its proof,
the continuous-time control uc1 can be designed as
uc1 = −

c0 + 1
4

y −ψy(y) −∥P∥2∥ψ(y)∥2
y
,
(11.70)
where c0 is a positive real constant and P is a positive real constant that satisﬁes
DTP + PD = −3I.
For the control (11.70), the stability of the continuous-time system can be established
with the Lyapunov function
V = ζ TPζ + 1
2y2
and its derivative
˙V ≤−c0y2 −∥ζ∥2.
For the case of ρ > 1, backstepping is used to obtain the ﬁnal control input uc2.
We introduce the same notations zi, for i = 1, . . . , ρ, as in Section 9.4 for backstepping
z1 = y,
(11.71)
zi = ξi−1 −αi−1,
for i = 2, . . . , ρ,
(11.72)
zρ+1 = u −αρ,
(11.73)
where αi for i = 2, . . . , ρ are stabilising functions to be designed. We also use the
positive real design parameters ci and ki for i = 1, . . . , ρ and γ > 0.

Control applications
251
The control design has been shown in Section 9.4. We list a few key steps here
for the convenience of the stability analysis. The stabilising functions are designed as
α1 = −c1z1 −k1z1 + ψy(y) −γ ∥P∥2∥ψ(y)∥2
y
,
α2 = −z1 −c2z2 −k2
∂α1
∂y
2
z2 + ∂α1
∂y ψ(y) + λ1ξ1
αi = −zi−1 −cizi −ki
∂αi−1
∂y
2
zi + ∂αi−1
∂y ψ(y) + λi−1ξi−1
+ i−2
j=1
∂αi−1
∂ξj
(−λjξj + ξj+1)
for i = 3, . . . , ρ.
(11.74)
The continuous-time control input is given by uc2 = αρ, that is
uc2 = −zρ−1 −cρzρ −kρ
∂αρ−1
∂y
2
zρ + ∂αρ−1
∂y
ψ(y)
+
i−2
	
j=1
∂αρ−1
∂ξj
(−λjξj + ξj+1) + λρ−1ξρ−1.
(11.75)
For the control input (11.75) in the continuous-time, the stability result has been
shown in Theorem 9.6. In the stability analysis, the Lyapunov function candidate is
chosen as
V =
ρ
	
i=1
z2
i + γ ζ TPζ
and its derivative is shown to satisfy
˙V ≤−
ρ
	
i=1
ciz2
i −γ ∥ζ∥2.
(11.76)
11.3.2
Stability analysis of sampled-data systems
The following lemma is needed for stability analysis in sampled-data case.
Lemma 11.10. Let V : Rn →R+ be a continuously differentiable,
radially
unbounded, positive deﬁnite function. Deﬁne D := {χ ∈Rn|V(χ) ≤r} with r > 0.
Suppose
˙V ≤−μV + βVm,
∀t ∈(mT, (m + 1)T],
(11.77)

252
Nonlinear and adaptive control systems
holdforallχ(mT) ∈D, whereμ, β areanygivenpositiverealswith μ > β, T > 0the
ﬁxed sampling period and Vm := V(χ(mT)). If χ(0) ∈D, then the following holds:
lim
t→∞χ(t) = 0.
Proof. Since χ(0) ∈D, then (11.77) holds for t ∈(0, T ] with the following form:
˙V ≤−μV + βV(χ(0)).
Using the comparison lemma (Lemma 4.5), it is easy to obtain from the above that
for t ∈(0, T]
V(χ(t)) ≤e−μtV0 + 1 −e−μt
μ
βV0 = q(t)V0,
(11.78)
where q(t) := (e−μt + β
μ(1 −e−μt)). Since μ > β > 0, then q(t) ∈(0, 1), ∀t ∈
(0, T ]. Then we have
V(χ(t)) < V0,
∀t ∈(0, T ].
(11.79)
Particularly, setting t = T in (11.78) leads to
V1 ≤q(T)V0,
(11.80)
which means that χ(T) ∈D. Therefore, (11.77) holds for t ∈(T, 2T]. By induction,
we have
V(χ(t)) < Vm,
∀t ∈(mT, (m + 1)T].
(11.81)
which states inter-sample behaviour of the sampled-data system concerned, and in
particular
Vm+1 ≤q(T)Vm
(11.82)
indicating that V decreases at two consecutive sampling points with a ﬁxed ratio.
From (11.82),
Vm ≤q(T)Vm−1 ≤qm(T)V0,
(11.83)
which implies that limm→∞Vm = 0. The conclusion then follows from (11.81), which
completes the proof.
2
Remark 11.6. Lemma 11.10 plays an important role in stability analysis for the
sampled-data system considered in this section. When sampled-data systems are
analysed in discrete-time in literature, only the performances at sampling instances are
considered. In this section, Lemma 11.10 provides an integrated analysis framework
where the behaviour of the sampled-data system both at and between sampling instants
can be characterised. In particular, the system’s behaviour at sampling instants is
portrayed in (11.82), and (11.81) shows that the inter-sample behaviour of the system
is well bounded by a compact set deﬁned by Vm.
◁

Control applications
253
For the case of relative degree 1, the sampled-data system takes the following
form:
˙ζ = Dζ + ψ(y)
˙y = ζ1 + ψy(y) + ud1,
(11.84)
where ud1 is the sampled-data controller and can be simply implemented via a zero-
order hold device as the following:
ud1(t) = uc1(y(m)),
∀t ∈[mT, mT + T).
(11.85)
Deﬁne χ := [ζ T, yT]T and we have the following result.
Theorem 11.11. For system (11.84) and the sampled-data controller ud1 shown in
(11.85), and a given neighbourhood of the origin Br := {χ ∈Rn| ∥χ∥≤r} with r
any given positive real, there exists a constant T1 > 0 such that, for all 0 < T < T1
and for all χ(0) ∈Br, the system is asymptotically stable.
Proof. We choose
V(χ) = ζ TPζ + 1
2y2
as the Lyapunov function candidate for the sampled-data system. We start with some
sets used throughout the proof. Deﬁne
c := max
χ∈Br V(χ)
and the level set
c := {x ∈Rn|V(χ) ≤c}.
There exist two class K functions ϱ1 and ϱ2 such that
ϱ1(∥χ∥) ≤V(χ) ≤ϱ2(∥χ∥).
Let l > ϱ−1
1 (c), and deﬁne Bl := {χ ∈Rn| ∥χ∥≤l}. Then we have
Br ⊂c ⊂Bl.
The constants Lu1, L1 and L2 are Lipschitz constants of the functions uc1 and ψy and
ψ with respect to Bl.
TheselocalLipschitzconditionsestablishthatfortheoverallsampled-datasystem
with χ(0) ∈c, there exists a unique solution χ(t) over some interval [0, t1). Notice
that t1 might be ﬁnite. However, later analysis shows that the solution can be extended
one sampling interval after another, and thus exists for all t ≥0 with the property
that limt→∞χ(t) = 0. Particularly, we intend to formulate the time derivative of the
Lyapunov function V into the form shown in (11.77) or (11.93), which is shown below.
Consider the case when t = 0, χ(0) ∈Br ⊂c. First, choose a sufﬁciently large
l such that there exists a T ∗
1 > 0, and for all T ∈(0, T ∗
1 ), the following holds:
χ(t) ∈Bl,
∀t ∈[0, T], χ(0) ∈c.
(11.86)

254
Nonlinear and adaptive control systems
The existence of T ∗
1 is ensured by continuous dependency of the solution χ(t) on the
initial conditions.
Next, calculate the estimate of |y(t) −y(0)| forced by the sampled-data control
ud1 during the interval [0, T], provided that χ(0) ∈Br ⊂c and T ∈(0, T ∗
1 ). From
the second equation of (11.84), the dynamics of y are given by
˙y = ζ1 + ψy(y) + ud1.
It follows that
y(t) = y(0) +
 t
0
ζ1(τ)dτ +
 t
0
ud1(τ)dτ
+
 t
0

ψy(y) −ψy (y(0))

dτ +
 t
0
ψy (y(0)) dτ.
Then we have
|y(t) −y(0)| ≤
 t
0
∥ζ(τ)∥dτ

 
!
1
+
 t
0
Lu1|y(0)|dτ
+
 t
0
L1|y(τ) −y(0)|dτ +
 t
0
L1|y(0)|dτ.
(11.87)
We ﬁrst calculate the integral 1. From the ﬁrst equation of system (11.69), we obtain
ζ(t) = eDtζ(0) +
 t
0
eDtψ(y(τ))dτ.
(11.88)
Since D is a Hurwitz matrix, there exist positive reals κ1 and σ1 such that ∥eDt∥≤
κ1e−σ1t. Thus, from (11.88)
∥ζ(t)∥≤κ1e−σ1t∥ζ(0)∥+
 t
0
κ1e−σ1(t−τ)∥ψ(y(τ)) −ψ(y(0))∥dτ
+
 t
0
κ1e−σ1(t−τ)∥ψ(y(0))∥dτ
≤κ1e−σ1t∥ζ(0)∥+ L2
 t
0
κ1e−σ1(t−τ)|y(τ) −y(0)|dτ
+ L2
 t
0
κ1e−σ1(t−τ)|y(0)|dτ.
Then the following inequality holds:
1 ≤κ1∥ζ(0)∥
σ1
(1 −e−σ1t) + κ1L2
σ1
|y(0)|t
+ κ1L2
σ1
 t
0
|y(τ) −y(0)|dτ.
(11.89)

Control applications
255
Now we are ready to compute |y(t) −y(0)|. In fact, we have from (11.87) and (11.89)
|y(t) −y(0)| ≤A1(1 −e−σ1t) + B1t + H
 t
0
|y(τ) −y(0)|dτ,
(11.90)
where
A1 = σ −1
1 κ1∥ζ(0)∥,
B1 = Lu1|y(0)| + L1|y(0)| + σ −1
1 κ1L2|y(0)|,
H = σ −1
1 κ1L2 + L1.
Applying Gronwall–Bellman inequality to (11.90) produces
|y(t) −y(0)| ≤A1(1 −e−σ1t) + B1
H (eHt −1)
+ A1(σ1eHt + He−σ1t −(H + σ1))(H + σ1)−1
(11.91)
Setting t = T on the right side of (11.91) leads to
|y(t) −y(0)| ≤δ1(T)|y(0)| + δ2(T)∥ζ(0)∥,
where
δ1(T) = H −1(Lu1 + L1 + σ −1
1 κ1L2)(eHT −1)
δ2(T) = σ −1
1 κ1(σ1eHT + He−σ1T −(H + σ1))(H + σ1)−1
+ σ −1
1 κ1(1 −e−σ1T).
(11.92)
Note that δ1(T) and δ2(T) only depend on the sampling period T once the Lipschitz
constants and the control parameters are chosen.
Next we shall study the behaviour of the sampled-data system during each inter-
val using a Lyapunov function candidate V(y, ζ) = ζ TPζ + 1
2y2. Consider χ(0) =
[ζ(0), y(0)]T ∈Br. When t ∈(0, T], its time derivative satisﬁes
˙V = −3∥ζ∥2 + 2ζ TPψ + y(ζ1 + ψy + ud1)
≤−c0y2 −∥ζ∥2 + |y||ud1(y(0)) −uc1|
≤−c0y2 −∥ζ∥2 + Lu1|y −y(0)||y|
≤−

c0 −Lu1
2 (δ1(T) + δ2(T))

y2 −∥ζ∥2
+ Lu1
2 δ1(T)|y(0)|2 + Lu1
2 δ2(T)∥ζ(0)∥2
≤−μ1(T)V + β1(T)V(ζ(0), y(0)),
(11.93)

256
Nonlinear and adaptive control systems
where
μ1 = min
"
2c0 −Lu1δ1 −Lu1δ2(T),
1
λmax(P)
#
,
β1 = max
"
Lu1δ1(T), Lu1δ2(T)
2λmin(P)
#
,
(11.94)
with λmax( · ) and λmin( · ) denoting the maximum and minimum eigenvalues of a matrix
respectively.
Next we shall show that there exists a constant T ∗
2 > 0 such that the condi-
tion μ1(T) > β1(T) > 0 is satisﬁed for all 0 < T < T ∗
2 . Note from (11.92) that both
δ1(T) and δ2(T) are actually the continuous functions of T with δ1(0) = δ2(0). Deﬁne
e1(T) := μ1(T) −β1(T) and we have e1(0) > 0. It can also be established from
(11.94) that e1(T) is a decreasing and continuous function of T, which asserts by
the continuity of e1(T) the existence of T ∗
2 so that for 0 < T < T ∗
2 , e1(T) > 0, that is
0 < β1(T) < μ1(T).
Finally, set T1 = min (T ∗
1 , T ∗
2 ), and from Lemma 11.10, it is known that V1 ≤c,
which means χ(T) ∈c, and subsequently, all the above analysis can be repeated for
every interval [mT, mT + T]. Applying Lemma 11.10 completes the proof.
2
For systems with relative degree ρ > 1, the implementation of the sampled-data
controller ud2 is given in (11.67) and (11.68). It is easy to see from (11.68) that ξ(mT)
is the exact, discrete-time model of the ﬁlter
˙ξ = −ξ + bf ud2
(11.95)
due to the fact that ud remains constant during each interval and the dynamics of ξ
shown in (11.95) is linear. Then (11.68) and (11.95) are virtually equivalent at each
sampling instant. This indicates that we can use (11.95) instead of (11.68) for stability
analysis of the sampled-data system.
Let χ := [ζ T, zT]T and we have the following result.
Theorem 11.12. For the extended system consisting (11.65), (11.69) and the
sampled-data controller ud2 shown in (11.67) and (11.68), and a given neighbour-
hood of the origin Br := {χ ∈Rn| ∥χ∥≤r} with r any given positive real, there exists
a constant T2 > 0 such that, for all 0 < T < T2 and for all χ(0) ∈Br, the system is
asymptotically stable.
Proof. The proof can be carried out in a similar way to that for the case ρ = 1,
except that the effect of the dynamic ﬁlter of ξ has to be dealt with.
For the overall sampled-data system, a Lyapunov function candidate is chosen
the same as for continuous-time case, that is
V = γ ζ TPζ + 1
2
ρ
	
i=1
z2
i .

Control applications
257
Similar to the case of ρ = 1, the sets Br, c and Bl can also be deﬁned such that
Br ⊂c ⊂Bl, and there exists a T ∗
3 > 0 such that for all T ∈(0, T ∗
3 ), the following
holds:
χ(t) ∈Bl,
∀t ∈(0, T],
χ(0) ∈c.
As in the proof for Theorem 11.11, we also aim to formulate the time derivative
of V(χ) into form (11.77). Next we shall derive the bounds for ∥ξ(t) −ξ(0)∥and
|y(t) −y(0)| during t ∈[0, T] with 0 < T < T ∗
3 . Consider the case where χ(0) ∈Br.
We have from (11.95)
ξ(t) = etξ(0) +
 t
0
e(t−τ)bf ud2dτ.
(11.96)
Since  is a Hurwitz matrix, there exist positive reals κ2, κ3 and σ2 such, that
∥et∥≤κ2e−σ2t,
∥et −I∥≤κ3(1 −e−σ2t),
where I is the identity matrix. Then, using the Lipschitz property of uc2 with respect
to the set Bl and the fact that ud2(0, 0) = 0, it can be obtained from (11.96) that
 t
0
∥ξ(τ)∥dτ ≤κ2∥ξ(0)∥
σ2

1 −e−σ2t
+ κ2Lu2
σ2
(|y(0)| + ∥ξ(0)∥)t
(11.97)
and
∥ξ(t) −ξ(0)∥≤κ3∥ξ(0)∥(1 −e−σ2t) + ∥ud2 (y(0), ξ(0)) ∥
 t
0
κ2e−σ2(t−τ)dτ
≤δ3(T)|y(0)| + δ4(T)∥ξ(0)∥,
(11.98)
where
δ3(T) = σ −1
2 κ2Lu2(1 −e−σ2T),
δ4(T) = (κ3 + σ −1
2 κ2Lu2)(1 −e−σ2T),
and Lu2 is a Lipschitz constant of uc2. As for |y −y(0)|, we have from (11.69)
y(t) = y(0) +
 t
0
ζ1(τ)dτ +
 t
0
ξ(τ)dτ
+
 t
0

ψy(y) −ψy(y(0))

dτ +
 t
0
ψy(y(0))dτ.
It can then be shown that
|y(t) −y(0)| ≤
 t
0
∥z(τ)∥dτ

 
!
1
+
 t
0
∥ξ(τ)∥dτ

 
!
2
+
 t
0
L1|y(τ) −y(0)|dτ +
 t
0
L1|y(0)|dτ,
(11.99)

258
Nonlinear and adaptive control systems
where 1 is already shown in (11.89) and 2 in (11.97). With (11.89), (11.97) and
(11.99), it follows that
|y(t) −y(0)| ≤A1(1 −e−σ1t) + A2(1 −e−σ2t) + B2t
+ H
 t
0
|y(τ) −y(0)|dτ
(11.100)
where A1 and H are deﬁned in (11.90)
A2 = σ −1
2 κ2∥ξ(0)∥,
B2 = L1|y(0)| + σ −1
1 κ1L2|y(0)| + σ −1
2 κ2Lu2|y(0)| + σ −1
2 κ2Lu2∥ξ(0)∥.
Deﬁning A3 := A1 + A2 and σ0 := max (σ1, σ2), we have
|y(t) −y(0)| ≤A3(1 −e−σ0t) + B2t + H
 t
0
|y(τ) −y(0)|dτ.
Applying the Gronwall–Bellman lemma produces
|y(t) −y(0)| ≤δ5(T)|y(0)| + δ6(T)∥z(0)∥+ δ7(T)∥ξ(0)∥,
(11.101)
where
δ5(T) = H −1(L1 + σ −1
1 κ1L2 + σ2κ−1
2 Lu2)(eHT −1),
δ6(T) = σ −1
1 κ1(σ0eHT + He−σ0T −(H + σ0))(H + σ0)−1 + σ −1
1 κ1(1 −e−σ0T),
δ7(T) = σ −1
2 κ2(1 −e−σ0T) + σ −1
2 κ2Lu2(eHT −1)
+ σ −1
2 κ2Lu2(σ0eHT + He−σ0T −(H + σ0))(H + σ0)−1.
Note that ∥ξ(0)∥appearsin(11.98)and(11.101) whilefortheanalysisusingLyapunov
function to carry on, ∥z(0)∥is needed. Therefore, it is necessary to ﬁnd out an
expression of ∥ξ(0)∥that exclusively involves ∥z(0)∥, which is shown below.
Notice that due to the special structure of the ﬁlter (11.65) and the backstepping
technique, each stabilising function has the property that α1 = α1(y), α1(0) = 0, and
αi = αi(y, ξ1, . . . , ξi−1) and αi(0, . . . , 0) = 0, i = 2, . . . , ρ −1. From (11.74) we have
|ξ1(0)| ≤|z2(0)| + |α1(0)| ≤z2(0)| + L1|y(0)|
|ξ2(0)| ≤|z3(0)| + |α2(0)| ≤|z3(0)| + L2|y(0)| + L2|ξ1(0)|
...
|ξρ−1(0)| ≤|zρ(0)| + |αρ−1(0)| ≤|zρ(0)| + Lρ−1|y(0)| + Lρ−1
ρ−2
	
i=1
|ξi(0)|
where with a bit abuse of notation, Li is the Lipschitz constant of ˆξi with respect to
the set Bl. Thus, a constant L0 can be found such that the following holds:
∥ξ(0)∥≤L0(∥¯z(0)∥+ |y(0)|).
(11.102)

Control applications
259
with ¯z = [z2, . . . , zρ]T,
which implies that if [ζ(0)T, y(0)T, ¯z(0)T]T ∈Bl,
then
[ζ(0)T, y(0)T, ξ(0)T]T will be conﬁned in a bounded set, denoted by B′
l.
Then the time derivative of
Vd2 = γ ζ TPζ + 1
2y2 + 1
2
ρ
	
i=2
z2
i
during the interval (0, T] satisﬁes
˙Vd2 ≤−γ ∥ζ∥2 −
ρ
	
i=1
ciz2
i + zρ(ud2 −uc2)
≤−c1y2 −γ ∥ζ∥2 −λ0
ρ
	
i=2
z2
i + ∥¯z∥|ud2 −uc2|,
(11.103)
where λ0 = min{c2, . . . , cρ}. In addition, we have
∥ξ∥|ud2 −uc2| ≤Lu2∥ξ∥(|y −y(0)| + ∥ξ −ξ(0)∥)
≤Lu2∥ξ∥(δ3(T) + δ5(T))|y(0)| + Lu2∥ξ∥δ6(T)∥ζ(0)∥
+ Lu2∥ξ∥(δ4(T) + δ7(T))∥ξ(0)∥
≤ε1(T)|y(0)|2 + ε2(T)∥ζ(0)∥2 + ε3(T)∥ξ(0)∥2
+ ε4(T)∥¯z∥2,
(11.104)
where ε1(T) = Lu2
2 (δ3(T) + δ5(T)), ε2 = Lu2
2 δ6(T), ε3 = Lu2
2 (δ4(T) + δ7(T)), ε4 =
Lu2
2
7
i=3 δi(T) and Lu2 is a Lipschitz constant of uc2 with respect to the set B′
l
dependent on Bl.
From (11.102) to (11.103), we then have
˙Vd2 ≤−c1y2 −γ ∥ζ∥2 −(λ0 −ε4)¯z2
+ (ε1(T) + 2L2
0ε3(T))|y(0)|2 + ε2(T)∥ζ(0)∥2 + 2L2
0ε3(T)∥¯z(0)∥2
= −α2(T)Vd2 + β2(T)Vd2(ζ(0), y(0), ¯z(0)),
where
α2(T) = min
"
2c1,
γ
λmax(P), 2(λ0 −ε4(T))
#
,
β2(T) = max
"
2(ε1(T) + 2L2
0ε3(T)), ε2(T)
λmin(P), 4L2
0ε3(T)
#
.

260
Nonlinear and adaptive control systems
Note from (11.98), (11.101) and (11.104) that each εi (1 ≤i ≤4) is a continuous
function of T with εi(0) = 0. Then, as shown in the analysis for the case ρ = 1, it
can be claimed that given arbitrary positive reals c1, γ and λ, there exists a constant
T ∗
4 > 0 such that for all 0 < T < T ∗
4 , α2(T) > β2(T) > 0.
Finally, letting T2 := min (T ∗
3 , T ∗
4 ) proves the theorem.
2
Remark 11.7. In the results shown in Theorems 11.11 and 11.12, the radius r of Br
can be any positive value. It means that we can set the stability region as large as we
like, and the stability can still be guaranteed by determining a fast enough sampling
time. Therefore, Theorems 11.11 and 11.12 establish the semi-global stability of the
sampled-data control of nonlinear systems in the output feedback form.
◁
11.3.3
Simulation
The following example is a simpliﬁed model of a jet engine without stall:
˙φm = ψ + 3
2φ2
m −1
2φ3
m
˙ψ = u,
where φm is the mass ﬂow and ψ the pressure rise. Take φm as the output and then the
above system is in the output feedback form. The ﬁlter ˙ξ = −λξ + u is introduced so
that the ﬁltered transformation y = x1 and ¯ζ = x2 −ξ, and the state transformation
ζ = ¯ζ −λy can render the system into the following form:
˙ζ = −λζ −λ
3
2y2 −1
2y3

−λ2y
˙y = ζ + λy +
3
2y2 −1
2y3

+ ξ.
Finally, the stabilising function
α1 = −y −
3
2y2 −1
2y3

−λ2y
3
2y −1
2y2 + λ
2
with P = 1, and the control uc can be obtained using α2 as shown in (11.74). For
simulation, we choose λ = 0.5.
Simulations are carried out with the initial values set as x1(0) = 1 and
x2(0) = 1, which are for simulation purpose only and have no physical meaning.
Results shown in Figures 11.10 and 11.11 indicate that the sampled-data system
is asymptotically stable when T = 0.01 s, which is conﬁrmed by a closer look
at the convergence of V shown in Figure 11.12. Further simulations show that
the overall system is unstable if T = 0.5 s. In summary, the example illustrates
that for a range of sampling period T, the sampled-data control design presented
earlier in this section can asymptotically stabilise the sampled-data system.

Control applications
261
0
1
2
3
4
5
6
7
8
9
10
–0.2
0
0.2
0.4
0.6
0.8
1
1.2
t (s)
x1
Figure 11.10
The time response of x1 for T = 0.01 s
–0.2
0
0.2
0.4
0.6
0.8
1
1.2
–2
–1.5
–1
–0.5
0
0.5
1
x1
x2
Figure 11.11
Phase portrait of the system for T = 0.01 s

262
Nonlinear and adaptive control systems
–0.01
0
0.01
0.02
0.03
0.04
0.05
0.06
0.5
1
1.5
2
2.5
3
3.5
4
4.5
t (s)
V
Figure 11.12
The convergence of V for T = 0.01 s

Bibliographical Notes
Chapter 1.
The basic concepts of systems and states of nonlinear systems dis-
cussed in this chapter can be found in many books on nonlinear systems and
nonlinear control systems, for example Cook [1], Slotine and Li [2], Vidyasagar
[3], Khalil [4] and Verhulst [5]. For the background knowledge of linear systems,
readers can consult Ogata [6], Kailth [7]. Antsaklis and Michel [8], Zheng [9],
and Chen, Lin and Shamash [10]. The existence of unique solutions of differen-
tial equations is discussed in the references such as Arnold [11] and Borrelli and
Coleman [12]. Many concepts such as stability and backstepping control design are
covered in detail in later chapters of the book. For system with saturation, read-
ers may consult Hu and Lin [13]. Sliding mode control is covered in detail in
Edwards and Spurgeon [14] and feedforward control in Isidori [15]. Limit cycles
and chaos are further discussed in Chapter 2. Semi-global stability is often related
to systems with saturation, as discussed in Hu and Lin [13], and Isidori [15].
Chapter 2.
Lipschitz conditions and the existence of solutions for differential
equations are covered in detail in Arnold [11] and Borrelli and Coleman [12]. Classi-
ﬁcations of singular points of second-order nonlinear systems are covered in almost
all the introductory texts on nonlinear control systems, Cook [1], Slotine and Li
[2], Vidyasagar [3] and Khalil [4]. More phase portraits of systems similar to the
one in Example 2.1 can be found in Slotine and Li [2], Khalil [4] and Verhulst [5].
The swing machine equation in Example 2.2 was a simpliﬁed model of the system
shown in Elgerd [16] and a similar treatment is shown in Cook [1]. More examples
of similar systems can also be found in Verhulst [5]. The van der Pol oscillator was
ﬁrst discussed in his publication van der Pol [17], and perhaps it is one of the best
known systems with limit cycles. Detailed coverage of van der Pol oscillator can be
found in several books, including Verhulst [5] and Borrelli and Coleman [12]. Lorenz
attractor was ﬁrst shown in Lorenz [18] for his research on heat transfer. The bound-
edness of the trajectory shown in the book was taken from Borrelli and Coleman [12].
Chapter 3.
Describing function analysis is covered in many classic texts on non-
linear control, such as Cook [1], Slotine and Li [2], Vidyasagar [3], and Khalil [4].
The stability criterion of limit cycles with describing functions is inﬂuenced by the
treatment in Slotine and Li [2]. The describing function analysis for van der Pol sys-
tems is adapted from Cook [1]. More results on describing functions are to be found
in Atherton [19] and Gelb and Velde [20].

264
Nonlinear and adaptive control systems
Chapter 4.
Lyapunov’s work on stability was published in Russian in 1892 and
was translated in French in 1907 [21]. Lyapunov stability is covered in almost all the
books on nonlinear systems and control. One of the early books on motion stability is
published by Hahn [22]. Example 4.4 is adapted from Slotine and Li [2], and a more
general form is shown in Reference [5]. More discussions on radially unbounded
functions and global stability can be found in Khalil [4] and in Slotine and Li [2].
Further results on comparison lemma and its applications are to be found in Khalil
[4] and Vidyasagar [3].
Chapter 5.
The deﬁnition of positive real systems are common in many books
such as Slotine and Li [2], Khalil [4] and Vidyasagar [3]. For strictly positive real
systems, there may have some variations in deﬁnitions. A discussion on the varia-
tions can be found in Narendra and Annaswamy [23]. The deﬁnition in this book
follows Slotine and Li [2], Khalil [4]. Lemma 5.3 was adapted from Khalil [4],
where a poof of necessity can also be found. Kalman–Yakubovich Lemma can appear
in different variations. A proof of it can be found in Khalil [4] and Marino and
Tomei [24]. A book on absolute stability was published by Narendra and Taylor [25].
Circle criterion is covered in a number of books such as Cook [1], Slotine and Li
[2], Vidyasagar [3] and Khalil [4]. The treatment of loop-transformation to obtain
the condition of circle criterion is similar to Cook [1]. The interpretation based on
Figure 5.3 is adapted from Khalil [4]. Complex bilinear mapping is also used to
justify the circle interpretation. Basic concepts of complex bilinear mapping can
be found from text books on complex analysis, such as Brown and Churchill [26].
Input-to-state stability was ﬁrst introduced by Sontag [27]. For the use of comparison
functions of classes K and K∞, more are to be found in Khalil [4]. The deﬁni-
tions for ISS are adapted from Isidori [15]. Theorem 5.8 is a simpliﬁed version, by
using powers of the state norm, rather than K∞to characterise the stability for the
convenience of presentation. The original result of Theorem 5.8 was shown by Son-
tag and Wang [28]. Using ISS pair (α, σ) for interconnected systems is based on
a technique, changing supply functions, which is shown in Sontag and Teel [29].
The small gain theorem for ISS was shown in Jiang, Teel and Praly [30]. A sys-
tematic presentation of ISS stability issues can be found in Isidori [15]. Differential
stability describes the stability issue of nonlinear systems for observer design. It is
introduced in Ding [31], and the presentation in Section 5.4 is adapted from that
paper.
Chapter 6.
Fundamentals of Lie derivatives and differential manifolds can be
found in Boothby [32]. A brief description of these concepts, sufﬁcient for the
concepts used in this book, is presented in Isidori [33]. Early results on exact lineari-
sation in state space started from Brockett [34], and the presentation in this chapter
was greatly inﬂuenced by the work of Isidori [33] and Marino and Tomei [24]. A
proof of Frobenius Theorem can be found in Isidori [33].
Chapter 7.
For self-tuning control, readers can refer to the textbooks such as
Astrom and Wittenmark [35] and Wellstead and Zarrop [36]. The approach to obtain

Bibliographical Notes
265
the model reference control is based on Ding [37]. Early work of using Lyapunov
function for stability analysis can be found in Parks [38]. A complete treatment of
MRAC of linear systems with high relative degrees can be found in Narendra and
Annaswamy [23] and Ioannou and Sun [39]. The example to show the divergence
of parameter estimation under a bounded disturbance is adapted from Ioannou and
Sun [39], where more robust adaptive laws for linear systems are to be found. Results
on robust adaptive control and on relaxing assumptions of the sign of high-frequency
gain, minimum-phase, etc., for nonlinear systems can be found in Ding [37, 40–45].
Chapter 8.
Linear observer design is covered in many books on linear systems.
A proof of Lemma 8.2 can be found in Zheng [9]. Early results on nonlinear
observer design can be traced back to 1970s, for example in Thau [46], and Kou,
Ellitt and Tarn [47]. The result on the output injection form was shown in Krener
and Isidori [48]. The geometric conditions for the existence of a state transforma-
tion to the output injection form can also be found in Isidori [33] and Marino and
Tomei [24]. Basic knowledge of differential manifolds can be found in Boothby
[32]. Linear observer error dynamics via direct state transformation was initially
shown by Kazantzis and Kravaris [49]. Further results on this topic can be found
in Xiao [50] and Ding [51]. In the latter one, polynomial approximation to non-
linear functions for a solution to a nonlinear state transformation is discussed and
an explicit region of convergence of such an approximation is given. The basic
idea of observer design for systems with Lipschitz nonlinearities is to use the lin-
ear part of the observer dynamics to dominate the nonlinear terms. This idea was
shown in some of the early results on nonlinear observers, but the systematic intro-
duction to the topic was due to Rajamani [52], in which the condition (8.31) was
shown. Some later results on this topic are shown in Zhu and Han [53]. One-
sided Lipschtiz condition for nonlinear observer design was shown in Zhao, Tao
and Shi [54]. The result on observer design for systems with Lipschitz output non-
linearities is adapted from Ding [55]. The result on reduced-order observer of linear
systems can be traced back to the very early stage of observer design in Luenberger
[56]. Early results on this topic were discussed in Kailath [7]. The reduced-order
observer design is closely related to observer design for systems with unknown
inputs, of which some results may be found in Hou and Muller [57]. For nonlin-
ear systems, a reduced-order observer was used for estimation of unknown states
for control design of a class of nonlinear systems with nonlinearities of unmea-
sured states by Ding [58]. The result shown here is based on Ding [31]. An
early result on adaptive observer for nonlinear systems is reported in Bastin and
Gevers [59]. Results on adaptive observers with output nonlinearities are covered
in Marino and Tomei [24]. The results shown in Section 8.6 is mainly based on Cho
and Rajamani [60]. The method to construct a ﬁrst-order positive real system in
Remark 8.9 is based on Ding [40].
Chapter 9.
Early ideas of backstepping appeared in a number of papers, such
as Tsinias [61]. Iterative backstepping for state feedback is shown in Kanella-
kopoulos, Kokotovic and Morse [62] with adaptive laws for unknown parameters.

266
Nonlinear and adaptive control systems
Backstepping designs without adaptive laws shown in this chapter are basically sim-
pliﬁed versions of their adaptive counterparts. Filtered transformations were used for
backstepping in Marino and Tomei [63], and the presentation in this chapter is dif-
ferent from the forms used in [63]. Initially, multiple estimation parameters are used
for adaptive control with backstepping, for example the adaptive laws in [63]. Tun-
ing function method was ﬁrst introduced in Krstic, Kanellakopoulos and Kokotovic
[64] to remove multiple adaptive parameters for one unknown parameter vector with
backstepping. Adaptive backstepping with ﬁltered transformation was based on Ding
[65], without the disturbance rejection part.Adaptive observer backstepping is largely
based on the presentation in Krstic, Kanellakopoulos and Kokotovic [66]. Nonlinear
adaptive control with backstepping is also discussed in details in Marino and Tomei
[24]. Somefurtherdevelopmentsofnonlinearadaptivecontrolusingbacksteppingcan
be found in Ding [40] for robust adaptive control with dead-zone modiﬁcation, robust
adaptive control with σ-modiﬁcation in Ding [67], with unknown control directions
and unknown high-frequency gains in Ding [41, 42]. Adaptive backstepping was also
applied to nonlinear systems with nonlinear parameterisation in Ding [68].
Chapter 10.
Early results on rejection of sinusoidal disturbances can be found
in Bodson, Sacks and Khosla [69] and Bodson and Douglas [70]. Asymptotic
rejection of sinusoidal disturbances for nonlinear systems in the output feedback
form is reported in Ding [71] when the frequencies are known. The result shown
in Section 10.1 is adapted mainly from Ding [72]. Asymptotic rejection of peri-
odic disturbances can be formulated as an output regulation problem when the
periodic disturbances are generated from a dynamic system, which is known as
an exosystem. Output regulation for linear systems is shown in Davison [73]
and Francis [74], and for nonlinear systems with local stability in Huang and
Rugh [75], and Isidori and Byrnes [76]. More results on output regulation with
local stability can be found in the books by Isidori [33] and Huang [77]. The
result shown in Section 10.2 is based on Ding [65]. The format of the exosys-
tem for internal model design was inspired by Nikiforov [78]. The Nussbaum
gain was ﬁrst used by Nussbaum [79], and the treatment here is similar to Ye
and Ding [80] used in the control design to tackle the unknown sign of high fre-
quency gain. Early results on output regulation with nonlinear exosystems can
be found in Ding [81, 82], and Chen and Huang [83]. The result shown in
Section 10.3 is based on Xi and Ding [84]. Asymptotic rejection of general dis-
turbances was studied as an extension of output regulation of nonlinear exosystems.
Waveform proﬁles of the general periodic disturbances were used to estimate the
equivalent input disturbance in some early results in Ding [85–87]. The approach
for asymptotic rejection with an observer-like internal model is adapted from
Ding [55, 88].
Chapter 11.
Harmonic estimation is treated as a special case of state estimation.
The recursive estimation and rejection method in Section 11.1 is based on Ding
[89]. Practical issues on harmonics estimation and rejections are covered inArrillaga,
Watson and Chen [90] and Wakileh [91].

Bibliographical Notes
267
Clock gene was reported in 1994 by Takahashi et al. [92]. Reports on key genes
in circadian oscillators are inAlbrecht et al. [93], van der Horst et al. [94] and Bunger
et al. [95]. The effects of jet lags and sleep disorders to circadian rhythms are reported
in Sack et al. [96] and Sack et al. [97]. The effects of light and light treatments
to disorders of circadian rhythms are shown by Boulos et al. [98], Kurosawa and
Goldbeter [99] and Geier et al. [100]. The circadian model (11.48) is adapted from
Gonze, Leloup and Goldbeter [101]. The condition (11.52) is shown by Zhao, Tao
and Shi [54]. The observer design is adapted from That and Ding [102], and the con-
trol design is different from the version shown in that paper. More results on observer
design for a seventh-order circadian model are published by That and Ding [103].
There are many results in literature on sampled-data control of linear systems,
for example see Chen and Francis [104] and the references therein. The difﬁculty
of obtaining exact discrete-time model for nonlinear systems is shown by Nesic and
Teel [105]. Structures in nonlinear systems cannot be preserved as shown in Grizzle
and Kokotovic [106]. Approximation to nonlinear discrete-time models is shown
by several results, for example Nesic, Teel and Kokotovic [107] and Nesic and Laila
[108]. The effect on fast-sampling of nonlinear static controllers is reported in Owens,
Zheng and Billings [109]. Several other results on emulation method for nonlinear
systems are shown in Laila, Nesic and Teel [110], Shim and Teel [111] and Bian
and French [112]. The results presented in Section 10.3 are mainly based on Wu and
Ding [113]. Sampled-data control for disturbance rejection of nonlinear systems is
shown by Wu and Ding [114]. A result on sampled-data adaptive control of a class of
nonlinear systems is to be found in Wu and Ding [115].

References
[1]
Cook, P. A. Nonlinear Dynamic Systems. London: Prentice-Hall, 1986.
[2]
Slotine, J.-J. E. and Li, W. Applied Nonlinear Control. London: Prentice-
Hall, 1991.
[3]
Vidyasagar, M. Nonlinear Systems Analysis, 2nd ed. Englewood Cliffs,
New Jersey: Prentice-Hall International, 1993.
[4]
Khalil, H. K. Nonlinear Systems, 3rd ed. Upper Saddle River, New Jersey:
Prentice Hall, 2002.
[5]
Verhulst, F. Nonlinear Differential Equations and Dynamic Systems. Berlin:
Springer-Verlag, 1990.
[6]
Ogata, K. Modern Control Engineering, 3rd ed. London: Prentice-Hall,
1997.
[7]
Kailath, T. Linear Systems. London: Prentice-Hall, 1980.
[8]
Antsaklis, P. J. and Michel, A. N. Linear Systems. NewYork: McGraw-Hill,
1997.
[9]
Zheng, D. Z. Linear Systems Theory (in Chinese). Beijing: Tsinghua
University Press, 1990.
[10]
Chen, B. M., Lin, Z. and Shamash, Y. Linear Systems Theory. Boston:
Birkhauser, 2004.
[11]
Arnold,V. I. Ordinary Differential Equations. Berlin: Springer International,
1994.
[12]
Borrelli, R. L. and Coleman, C. S. Differential Equations. New York: John
Wiley & Sons, 1998.
[13]
Hu, T. and Lin, Z. Control Systems With Actuator Saturation: Analysis And
Design. Boston, MA: Birhäuser, 2001.
[14]
Edwards, C. and Spurgeon, S. Sliding Mode Control. London: Taylor &
Francis, 1998.
[15]
Isidori, A. Nonlinear Control Systems II. London: Springer-Verlag, 1999.
[16]
Elgerd, O. I. Electric Energy Systems Theory. New York: McGraw-Hill,
1971.
[17]
van der Pol, B. ‘On relaxation oscillations,’ Phil. Mag., vol. 2, pp. 978–992,
1926.
[18]
Lorenz, E. N. ‘Deterministic nonperiodic ﬂow,’ J. Atmos. Sci., vol. 20,
pp. 130–141, 1963.
[19]
Atherton, D. P. Nonlinear Control Engineering. Workingham:Van Nostraind
Reinhold, 1975.

References
269
[20]
Gelb,A.andVelde,W.E.V.Multi-InputDescribingFunctionsandNonlinear
System Design. New York: McGraw-Hill, 1963.
[21]
Lyapunov, A. M. ‘The general problem of motion stability (translated in
french),’ Ann. Fac. Sci. Toulouse, vol. 9, pp. 203–474, 1907.
[22]
Hahn, W. Stability of Motion. Berlin: Springer, 1967.
[23]
Narendra, K. S. andAnnaswamy,A. M. StableAdaptive Systems. Englewood
Cliffs, New Jersey: Prentice-Hall, 1989.
[24]
Marino, R. and Tomei, P. Nonlinear Control Design: Geometric, Adaptive,
and Robust. London: Prentice-Hall, 1995.
[25]
Narendra, K. S. and Taylor, J. H. Frequency Domain Stability for Absolute
Stability. New York: Academic Press, 1973.
[26]
Brown, J.W. and Churchill, R.V. ComplexVariables andApplications, 7th ed.
New York: McGraw-Hill, 2004.
[27]
Sontag, E. D. ‘Smooth stabilization implies coprime factorization,’ IEEE
Transaction on Automatic Control, vol. 34, pp. 435–443, 1989.
[28]
Sontag, E.D. andWang,Y. ‘On characterization of the input-to-state stability
properties,’ Syst. Contr. Lett., vol. 24, pp. 351–359, 1995.
[29]
Sontag, E. and Teel, A. ‘Changing supply functions input/state stable
systems,’ IEEE Trans. Automat. Control, vol. 40, no. 8, pp. 1476–1478,
1995.
[30]
Jiang, Z. -P., Teel, A. R. and Praly, L. ‘Small-gain theorem for iss systems
and applications,’ Math. Contr. Sign. Syst., vol. 7, pp. 95–120, 1994.
[31]
Ding, Z. ‘Differential stability and design of reduced-order observers for
nonlinear systems,’ IET Control Theory and Applications, vol. 5, no. 2,
pp. 315–322, 2011.
[32]
Boothby, W. A. An Introduction to Differential Manifolds and Riemaniann
Geometry. London: Academic Press, 1975.
[33]
Isidori, A. Nonlinear Control Systems, 3rd ed. Berlin: Springer-Verlag,
1995.
[34]
Brockett,
R. W. ‘Feedback invariants for non-linear systems,’
in
The Proceedings of 7th IFAC Congress, vol. 6, Helsinki, Finland.
[35]
Astrom, K. J. and Wittenmark, B. Adaptive Control, 2nd ed. Reading, MA:
Addison-Wesley, 1995.
[36]
Wellstead, P. E. and Zarrop, M. B. Self-Tuning Systems: Control and Signal
Processing. New York: John Wiley & Sons, 1991.
[37]
Ding, Z. ‘Model reference adaptive control of dynamic feedback linearis-
able systems with unknown high frequency gain,’ IEE Proceedings Control
Theory and Applications, vol. 144, pp. 427–434, 1997.
[38]
Parks, P. C. ‘Lyapunov redesign of model reference adaptive control
systems,’ IEEE Trans. Automat. Contr., vol. 11, pp. 362–367, 1966.
[39]
Ioannou, P. A. and Sun, J. Robust Adaptive Control. Upper Saddle River,
New Jersey: Prentice Hall, 1996.
[40]
Ding, Z. ‘Robust adaptive control of nonlinear output-feedback systems
under bounded disturbances,’ IEE Proc. Control Theory Appl., vol. 145,
pp. 323–329, 1998.

270
Nonlinear and adaptive control systems
[41]
Ding, Z. ‘Global adaptive output feedback stabilization of nonlinear systems
of any relative degree with unknown high frequency gain,’ IEEE Trans.
Automat. Control, vol. 43, pp. 1442–1446, 1998.
[42]
Ding, Z. ‘Adaptive control of nonlinear systems with unknown virtual con-
trol coefﬁcients,’ Int. J. Adaptive Control Signal Proc., vol. 14, no. 5,
pp. 505–517, 2000.
[43]
Ding, Z. ‘Analysis and design of robust adaptive control for nonlinear output
feedback systems under disturbances with unknown bounds,’ IEE Proc.
Control Theory Appl., vol. 147, no. 6, pp. 655–663, 2000.
[44]
Ding, Z. and Ye, X. ‘A ﬂat-zone modiﬁcation for robust adaptive control
of nonlinear output feedback systems with unknown high frequency gains,’
IEEE Trans. Automat. Control, vol. 47, no. 2, pp. 358–363, 2002.
[45]
Ding, Z. ‘Adaptive stabilization of a class of nonlinear systems with unsta-
ble internal dynamics,’ IEEE Trans. Automat. Control, vol. 48, no. 10,
pp. 1788–1792, 2003.
[46]
Thau, F. ‘Observing the states of nonlinear dynamical systems,’ Int. J.
Control, vol. 18, pp. 471–479, 1973.
[47]
Kou, S., Ellitt, D. and Tarn, T. ‘Exponential observers for nonlinear
dynamical systems,’ Inf. Control, vol. 29, pp. 204–216, 1975.
[48]
Krener, A. J. and Isidori, A. ‘Linearization by output injection and nonlinear
observers,’ Syst. Control Lett., vol. 3, pp. 47–52, 1983.
[49]
Kazantzis, M. and Kravaris, C. ‘Nonlinear observer design using lyapunov’s
auxiliary theorem,’ Syst. Control Lett., vol. 34, pp. 241–247, 1998.
[50]
Xiao, M. ‘The global existence of nonlinear observers with linear error
dynamics: A topological point of view,’ Syst. Control Lett., vol. 55, no. 10,
pp. 849–858, 2006.
[51]
Ding, Z. ‘Observer design in convergent series for a class of nonlinear
systems,’ IEEE Trans. Automat. Control, vol. 57, no. 7, pp. 1849–1854,
2012.
[52]
Rajamani, R. ‘Observers for Lipschitz nonlinear systems,’ IEEE Trans.
Automat. Control, vol. 43, no. 3, pp. 397–401, 1998.
[53]
Zhu, F. and Han, Z. ‘A note on observer design for Lipschitz nonlinear
systems,’ IEEE Trans. Automat. Control, vol. 47, no. 10, pp. 1751–1754,
2002.
[54]
Zhao, Y., Tao, J. and Shi, N. ‘A note on observer design for one-sided
Lipschitz nonlinear systems,’ Syst. Control Lett., vol. 59, pp. 66–71, 2010.
[55]
Ding, Z. ‘Asymptotic rejection of unmatched general periodic disturbances
with nonlinear Lipschitz internal model,’ Int. J. Control, vol. 86, no. 2,
pp. 210–221, 2013.
[56]
Luenberger, D. G. ‘Observing the state of a linear system,’ IEEE Trans. Mil.
Electron., vol. 8, pp. 74–80, 1964.
[57]
Hou, M.andMuller, P.‘Designofobserversforlinearsystemswithunknown
inputs,’ IEEE Trans. Automat. Control, vol. 37, no. 6, pp. 871–875, 1992.
[58]
Ding, Z. ‘Global output feedback stabilization of nonlinear systems with
nonlinearity of unmeasured states,’ IEEE Trans. Automat. Control, vol. 54,
no. 5, pp. 1117–1122, 2009.

References
271
[59]
Bastin, G. and Gevers, M. ‘Stable adaptive observers for nonlinear time
varying systems,’IEEETrans.Automat. Control, vol. 33, no. 7, pp. 650–658,
1988.
[60]
Cho, Y. M. and Rajamani, R. ‘A systematic approach to adaptive observer
synthesis for nonlinear systems,’ IEEE Trans. Automat. Control, vol. 42,
no. 4, pp. 534–537, 1997.
[61]
Tsinias, J., ‘Sufﬁcient lyapunov-like conditions for stabilization,’ Math.
Control Signals Systems, vol. 2, pp. 343–357, 1989.
[62]
Kanellakopoulos, I., Kokotovic, P. V. and Morse, A. S. ‘Systematic design
of adaptive controllers for feedback linearizable systems,’ IEEE Trans.
Automat. Control, vol. 36, pp. 1241–1253, 1991.
[63]
Marino, R. andTomei, P. ‘Global adaptive output feedback control of nonlin-
ear systems, part i: Linear parameterization,’IEEETrans. Automat. Control,
vol. 38, pp. 17–32, 1993.
[64]
Krstic, M., Kanellakopoulos, I. and Kokotovic, P. V. ‘Adaptive nonlinear
control without overparametrization,’ Syst. Control Lett., vol. 19, pp. 177–
185, 1992.
[65]
Ding, Z. ‘Adaptive output regulation of class of nonlinear systems with
completely unknown parameters,’in Proceedings of 2003American Control
Conference, Denver, CO, 2003, pp. 1566–1571.
[66]
Krstic, M., Kanellakopoulos, I. and Kokotovic, P.V. Nonlinear andAdaptive
Control Design. New York: John Wiley & Sons, 1995.
[67]
Ding, Z. ‘Almost disturbance decoupling of uncertain output feedback
systems,’ IEE Proc. Control Theory Appl., vol. 146, pp. 220–226, 1999.
[68]
Ding, Z. ‘Adaptive control of triangular systems with nonlinear parameter-
ization,’ IEEE Trans. Automat. Control, vol. 46, no. 12, pp. 1963–1968,
2001.
[69]
Bodson, M., Sacks, A. and Khosla, P. ‘Harmonic generation in adaptive
feedforward cancellation schemes,’ IEEE Trans. Automat. Control, vol. 39,
no. 9, pp. 1939–1944, 1994.
[70]
Bodson, M. and Douglas, S. C. ‘Adaptive algorithms for the rejection of
sinusoidal disturbances with unknown frequencies,’ Automatica, vol. 33,
no. 10, pp. 2213–2221, 1997.
[71]
Ding, Z. ‘Global output regulation of uncertain nonlinear systems with
exogenous signals,’Automatica, vol. 37, pp. 113–119, 2001.
[72]
Ding, Z. ‘Global stabilization and disturbance suppression of a class of
nonlinear systems with uncertain internal model,’Automatica, vol. 39, no. 3,
pp. 471–479, 2003.
[73]
Davison, E. J. ‘The robust control of a servomechanism problem for lin-
ear time-invariant multivariable systems,’ IEEE Trans. Automat. Control,
vol. 21, no. 1, pp. 25–34, 1976.
[74]
Francis, B. A. ‘The linear multivariable regulator problem,’ SIAM J. Control
Optimiz., vol. 15, pp. 486–505, 1977.
[75]
Huang, J. and Rugh, W. J. ‘On a nonlinear multivariable servomechanism
problem,’Automatica, vol. 26, no. 6, pp. 963–972, 1990.

272
Nonlinear and adaptive control systems
[76]
Isidori, A. and Byrnes, C. I. ‘Output regulation of nonlinear systems,’ IEEE
Trans. Automat. Control, vol. 35, no. 2, pp. 131–140, 1990.
[77]
Huang, J. Nonlinear Output Regulation Theory and Applications. Philadel-
phia, PA: SIAM, 2004.
[78]
Nikiforov, V. O. ‘Adaptive non-linear tracking with complete compensation
of unknown disturbances,’ Eur. J. Control, vol. 4, pp. 132–139, 1998.
[79]
Nussbaum, R. D. ‘Some remarks on a conjecture in parameter adaptive
control,’ Syst. Control Lett., vol. 3, pp. 243–246, 1983.
[80]
Ye, X. and Ding, Z. ‘Robust tracking control of uncertain nonlinear systems
with unknown control directions,’ Syst. Control Lett., vol. 42, pp. 1–10,
2001.
[81]
Ding, Z. ‘Output regulation of uncertain nonlinear systems with nonlin-
ear exosystems,’ in Proceeding of the 2004 American Control Conference,
Boston, MA, 2004, pp. 3677–3682.
[82]
Ding, Z. ‘Output regulation of uncertain nonlinear systems with nonlinear
exosystems,’ IEEE Trans. Automat. Control, vol. 51, no. 3, pp. 498–503,
2006.
[83]
Chen, Z. and Huang, J. ‘Robust output regulation with nonlinear exosys-
tems,’Automatica, vol. 41, pp. 1447–1454, 2005.
[84]
Xi, Z. and Ding, Z. ‘Global adaptive output regulation of a class of
nonlinear systems with nonlinear exosystems,’ Automatica, vol. 43, no. 1,
pp. 143–149, 2007.
[85]
Ding, Z. ‘Asymptotic rejection of general periodic disturbances in output-
feedback nonlinear systems,’ IEEE Trans. Automat. Control, vol. 51, no. 2,
pp. 303–308, 2006.
[86]
Ding,
Z. ‘Asymptotic rejection of asymmetric periodic disturbances
in output-feedback nonlinear systems,’ Automatica, vol. 43, no. 3,
pp. 555–561, 2007.
[87]
Ding, Z. ‘Asymptotic rejection of unmatched general periodic disturbances
in a class of nonlinear systems,’ IET Control Theory Appl., vol. 2, no. 4,
pp. 269–276, 2008.
[88]
Ding, Z. ‘Observer design of Lipschitz output nonlinearity with application
to asymptotic rejection of general periodic disturbances,’inThe Proceedings
of The 18th IFAC Congress, vol. 8, Milan, Italy, 2011.
[89]
Ding, Z. ‘Asymptotic rejection of ﬁnite frequency modes of general periodic
disturbances in output-feedback nonlinear systems,’ Automatica, vol. 44,
no. 9, pp. 2317–2325, 2008.
[90]
Arrillaga, J., Watson, N. R. and Chen, S. Power System Quality Assessment.
Chichester: John Wiley & Sons, 2000.
[91]
Wakileh,
G. J. Power Systems Harmonics.
Berlin:
Springer-Verlag,
2010.
[92]
Takahashi, J., Vitaterna, M., King, D., Chang, A., Kornhauser, J., Lowrey, P.,
McDonald, J., Dove, W., Pinto, L., and Turek, F. ‘Mutagenesis and mapping
of a mouse gene, clock, essential for circadian behaviour,’Science, vol. 264,
pp. 719–725, 1994.

References
273
[93]
Albrecht, U., Sun, Z., Eichele, G. and Lee, C. ‘A differential response of two
putative mammalian circadian regulators, mper1 and mper2 to light,’ Cell
Press, vol. 91, pp. 1055–1064, 1997.
[94]
van der Horst, G., Muijtjens, M., Kobayashi, K., Takano, R., Kanno,
S., Takao, M., de Wit, J., Verkerk, A., Eker, A., van Leenen, D., Buijs,
R., Bootsma, D., Hoeijmakers, J., and Yasui, A. ‘Mammalian cry1 and
cry2 are essential for maintenance of circadian rhythms,’ Nature, vol. 398,
pp. 627–630, 1999.
[95]
Bunger, M., Wilsbacher, L., Moran, S., Clendenin, C., Radcliffe, L.,
Hogenesch, J., Simon, M., Takahashi, J., and Bradﬁeld, C., ‘Mop3 is an
essential component of the master circadian pacemaker in mammals,’ Cell,
vol. 103, pp. 1009–1017, 2000.
[96]
Sack, R., Auckley, D., Auger, R., Carskadon, M., Wright, K., Vitiello, M.,
and Zhdanova, I. ‘Circadian rhythm sleep disorders: part i, basic principles,
shift work and jet lag disorders,’ Sleep, vol. 30, pp. 1460–1483, 2007.
[97]
Sack, R., Auckley, D., Auger, R., Carskadon, M., Wright, K., Vitiello, M.,
and Zhdanova, I. ‘Circadian rhythm sleep disorders: Part ii, advanced sleep
phase disorder, delayed sleep phase disorder, free-running disorder, and
irregular sleep-wake rhythm,’ Sleep, vol. 30, pp. 1484–1501, 2007.
[98]
Boulos, Z., Macchi, M., Sturchler, M., Stewart, K., Brainard, G., Suhner,A.,
Wallace, G., and Steffen, R., ‘Light visor treatment for jet lag after west
ward travel across six time zones,’ Aviat. Space Environ. Med., vol. 73,
pp. 953–963, 2002.
[99]
Kurosawa, G. and Goldbeter, A. ‘Amplitude of circadian oscillations
entrained by 24-h light-dark cycles,’ J. Theor. Biol., vol. 242, pp. 478–488,
2006.
[100]
Geier, F., Becker-Weimann, S., Kramer, K., and Herzel, H. ‘Entrainment in
a model of the mammalian circadian oscillator,’ J. Biol. Rhythms, vol. 20,
pp. 83–93, 2005.
[101]
Gonze, D., Leloup, J., and Goldbeter, A., ‘Theoretical models for circadian
rhythms in neurospora and drosophila,’ Comptes Rendus de l’Academie des
Sciences -Series III -Sciences de la Vie, vol. 323, pp. 57–67, 2000.
[102]
That, L. T. and Ding, Z. ‘Circadian phase re-setting using nonlinear output-
feedback control,’ J. Biol. Syst., vol. 20, no. 1, pp. 1–19, 2012.
[103]
That, L. T. and Ding, Z. ‘Reduced-order observer design of multi-output
nonlinear systems with application to a circadian model,’Trans. Inst. Meas.
Control, to appear, 2013.
[104]
Chen, T. and Francis, B. Optimal Sampled-Data Control Systems. London:
Springer-Verlag, 1995.
[105]
Nesic, D. and Teel, A. ‘A framework for stabilization of nonlinear sampled-
data systems based on their approximate discrete-time models,’IEEETrans.
Automat. Control, vol. 49, pp. 1103–1122, 2004.
[106]
Grizzle, J. W. and Kokotovic, P. V. ‘Feedback linearization of sampled-data
systems,’ IEEE Trans. Automat. Control, vol. 33, pp. 857–859, 1988.

274
Nonlinear and adaptive control systems
[107]
Nesic, D., Teel, A., and Kokotovic, P.V. ‘Sufﬁcient conditions for stabiliza-
tion of sampled-data nonlinear systems via discrete-time approximations,’
Syst. Control Lett., vol. 38, pp. 259–270, 1999.
[108]
Nesic, D. and Laila, D. ‘A note on input-to-state stabilization for nonlinear
sampled-data systems,’ IEEE Trans. Automat. Control, vol. 47, pp. 1153–
1158, 2002.
[109]
Owens, D. H., Zheng, Y. and Billings, S. A. ‘Fast sampling and stability of
nonlinear sampled-data systems: Part 1. Existing theorems,’ IMA J. Math.
Control Inf., vol. 7, pp. 1–11, 1990.
[110]
Laila, D. S., Nesic, D. and Teel, A. R. ‘Open-and closed-loop dissipa-
tion inequalities under sampling and controller emulation,’ Eur. J. Control,
vol. 18, pp. 109–125, 2002.
[111]
Shim, H. and Teel, A. R. ‘Asymptotic controllability and observability
implysemiglobalpracticalasymptoticstabilizabilitybysampled-dataoutput
feedback,’Automatica, vol. 39, pp. 441–454, 2003.
[112]
Bian, W. and French, M. ‘General fast sampling theorems for nonlinear
systems,’ Syst. Control Lett., vol. 54, pp. 1037–1050, 2005.
[113]
Wu, B.andDing, Z.‘Asymptoticstablilisationofaclassofnonlinearsystems
via sampled-data output feedback control,’ Int. J. Control, vol. 82, no. 9,
pp. 1738–1746, 2009.
[114]
Wu, B. and Ding, Z. ‘Practical disturbance rejection of a class of nonlin-
ear systems via sampled output,’ J. Control Theory Appl., vol. 8, no. 3,
pp. 382–389, 2010.
[115]
Wu, B. and Ding, Z. ‘Sampled-data adaptive control of a class of nonlinear
systems,’ Int. J. Adapt. Control Signal Process., vol. 25, pp. 1050–1060,
2011.

Index
σ-modiﬁcation, 106
absolute stability, 60
adaptive control
direct, 89
indirect, 89
model reference, 89
nonlinear, 159
adaptive law
linear system, 101
nonlinear, 162, 172
robust, 107
asymptotic stability, 43
autonomous system, 11
backstepping
adaptive, 159
adaptive observer, 167
ﬁltered transformation, 152
integrator, 141
iterative, 144
observer, 147
Barbalat’s lemma, 92
centre, 14
certainty equivalence principle, 90
chaos, 4, 21
circadian disorders, 238
circadian rhythm, 239
Neurospora control input, 246
Neurospora model, 239
circle criterion, 62
comparison functions
class K 66
class KL 66
class K∞, 66
comparison lemma, 50
dead zone, 31
dead-zone modiﬁcation, 105
describing function, 27
dead zone, 32
ideal relay, 30
relay with hysteresis, 32
saturation, 30
stability of limit cycle, 35
detectability
linear system, 110
differential stability, 71
distribution, 84
involutive, 84
disturbance
bounded, 104, 107
equivalent input, 176–77
general periodic, 204, 205
dynamic model, 207
generated from nonlinear
exosystem, 194
sinusoidal, 175
disturbance rejection
general periodic, 204
sinusoidal, 175
eigenvalue
resonant, 121
equivalent input disturbance, 176–77
exosystem, 175, 176
linear, 176, 186
nonlinear, 195
exponential stability, 43
feedback linearisation, 76
feedforward

276
Nonlinear and adaptive control systems
control, 181, 189, 199
input, 176, 189, 206
term, 189, 197, 209
ﬁnite time convergence, 4
ﬁnite time escape, 4
frequency mode, 219, 224
asymptotically orthogonal, 225
asymptotically rejected, 235
multiple, 229
Frobenius theorem, 85
full state feedback linearisable, 85
global stability properties, 45
globally asymptotic stability, 45
globally exponential stability, 45
harmonics, 4
estimation, 235
power system, 219
high-frequency gain, 94, 100, 102, 187
Hurwitz
matrix, 52
polynomial, 94
transfer function, 57
vector, 148
ideal relay, 30
immersion, 189, 199
inter-sample behaviour, 252
internal model, 199
adaptive, 179, 190
nonlinear, 199, 201
observer based, 209
internal model principle, 176
invariant manifold, 177, 189, 196
invariant zero, 133, 134
ISS pair (α, σ), 69, 208
ISS stability, 66
ISS-Lyapunov function, 69
jet engine model, 260
Kalman Yakubovich lemma, 59
level set, 47, 49, 253
Lie bracket, 79
Lie derivative, 77
limit cycle, 4, 18, 34, 175, 195, 238, 240
linear observer error dynamics, 112,121
linearisation
around operation point, 10
feedback, 75, 76, 80
full state, 83, 85
linearised model, 10
Lipschitz constant, 9, 123, 207, 241
one-sided, 124, 241
Lorenz attractor, 21
Lyapunov function, 46
adaptive control, 101
adaptive observer, 139
ISS, 67–70
linear systems, 52
Lyapunov stability, 42
Lyapunov theorem
global stability, 49
local stability, 47
Lyapunov’s direct method, 46
Lyapunov’s linearisation method, 45
model reference control
relative degree ρ > 1, 97–98
relative degree one, 94–96
monic polynomial, 94
MRAC, 89
multiple equilibrium points, 4
nonlinearity, 1, 3
dead zone, 31
hard, 3
ideal relay, 30
Lipschitz, 7, 122
multi-valued, 3
relay with hysteresis, 32
saturation, 29
sector-bounded, 59
normal form, 81
Nussbaum gain, 190
observability
linear system, 109

Index
277
observer
general periodic disturbance, 207
observer canonical form
linear system, 118
observer design
adaptive, 137
direct state transformation, 121
Lipschitz nonlinearity, 122
output injection, 112
output nonlinearity, 126
reduced-order, 127
output feedback form, 148, 152
with disturbance, 175, 186, 194
with unknown parameter, 167
output feedback stabilisation, 158
output injection form, 112
state transformation, 114
output regulation, 186
adaptive, 186
nonlinear exosystem, 194
output-complement transformation, 127
pendulum model, 48
phase portrait, 12
Poincare-Bendixson theorem, 19
positive deﬁnite function, 46
positive limit set, 21
positive real transfer function, 55
strictly, 56
radially unbounded function, 49
relative degree, 77
relay with hysteresis, 32
robust adaptive law, 107
σ-modiﬁcation, 106
dead-zone modiﬁcation, 105
saddle point, 13
sampled-data
emulation method, 248
sampled-data controller, 250
saturation, 2, 29
sector-bounded nonlinearity, 59
self-tuning control, 89
semi-global stability, 3, 260
singular point, 12
small gain theorem
ISS, 70
stability
absolute, 60
asymptotic, 43
differential, 71
exponential, 43
globally asymptotic, 45
globally exponential, 45
ISS, 66
Lyapunov, 42
semi-global, 3, 260
stable focus, 13–14
stable node, 13
STC, 89
transformation
ﬁltered, 152, 187
output-complement, 127
tuning function, 161
unstable focus, 14
unstable node, 13
van der Pol oscillator, 18, 38
Young’s inequality, 128
zero dynamics, 81, 155


The Institution of Engineering and Technology
www.theiet.org 
978-1-84919-574-4
Nonlinear and Adaptive  
Control Systems
Zhengtao Ding is a Senior Lecturer in Control 
Engineering and Director for MSc in Advanced Control 
and Systems Engineering at the Control Systems 
Centre, School of Electrical and Electronic Engineering, 
The University of Manchester, UK. His research interests 
focus on nonlinear and adaptive control design. He 
pioneered research in asymptotic rejection of general 
periodic disturbances in nonlinear systems and 
produced a series of results to systematically solve this 
problem in various situations. He also made significant 
contributions in output regulation and adaptive control 
of nonlinear systems with some more recent results on 
observer design and output feedback control as well. 
Dr Ding has been teaching ‘Nonlinear and Adaptive 
Control Systems’ to MSc students for 9 years, and he 
has accumulated tremendous experiences in explaining 
difficult control concepts to students.
An adaptive system for linear systems with unknown parameters is a 
nonlinear system. The analysis of such adaptive systems requires similar 
techniques to analyse nonlinear systems. Therefore it is natural to treat 
adaptive control as a part of nonlinear control systems. 
Nonlinear and Adaptive Control Systems treats nonlinear control 
and adaptive control in a unified framework, presenting the major 
results at a moderate mathematical level, suitable for MSc students 
and engineers with undergraduate degrees. Topics covered include 
introduction to nonlinear systems; state space models; describing 
functions for common nonlinear components; stability theory; feedback 
linearization; adaptive control; nonlinear observer design; backstepping 
design; disturbance rejection and output regulation; and control 
applications, including harmonic estimation and rejection in power 
distribution systems, observer and control design for circadian rhythms, 
and discrete-time implementation of continuous-time nonlinear control 
 laws.

